- en: Chapter 10\. Working with Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 10 章。处理数据
- en: Experts often possess more data than judgment.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 专家往往拥有比判断更多的数据。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Colin Powell
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 科林·鲍威尔
- en: Working with data is both an art and a science. We’ve mostly been talking about
    the science part, but in this chapter we’ll look at some of the art.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 处理数据既是一门艺术，也是一门科学。我们主要讨论科学部分，但在本章中我们将探讨一些艺术方面。
- en: Exploring Your Data
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索您的数据
- en: After you’ve identified the questions you’re trying to answer and have gotten
    your hands on some data, you might be tempted to dive in and immediately start
    building models and getting answers. But you should resist this urge. Your first
    step should be to *explore* your data.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定您要回答的问题并获取到数据之后，您可能会有冲动立即开始构建模型和获取答案。但您应该抑制这种冲动。您的第一步应该是 *探索* 您的数据。
- en: Exploring One-Dimensional Data
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索一维数据
- en: The simplest case is when you have a one-dimensional dataset, which is just
    a collection of numbers. For example, these could be the daily average number
    of minutes each user spends on your site, the number of times each of a collection
    of data science tutorial videos was watched, or the number of pages of each of
    the data science books in your data science library.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的情况是您有一个一维数据集，它只是一组数字。例如，这些可能是每个用户每天在您的网站上花费的平均分钟数，一系列数据科学教程视频的观看次数，或者您的数据科学图书馆中每本数据科学书籍的页数。
- en: An obvious first step is to compute a few summary statistics. You’d like to
    know how many data points you have, the smallest, the largest, the mean, and the
    standard deviation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 显而易见的第一步是计算一些摘要统计信息。您想知道有多少数据点，最小值，最大值，均值和标准差。
- en: 'But even these don’t necessarily give you a great understanding. A good next
    step is to create a histogram, in which you group your data into discrete *buckets*
    and count how many points fall into each bucket:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但即使这些也不一定能给您带来很好的理解。一个很好的下一步是创建直方图，将数据分组为离散的 *桶* 并计算落入每个桶中的点数：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For example, consider the two following sets of data:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下两组数据：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Both have means close to 0 and standard deviations close to 58. However, they
    have very different distributions. [Figure 10-1](#histogram_uniform) shows the
    distribution of `uniform`:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 两者的均值接近 0，标准差接近 58。然而，它们的分布却非常不同。 [第 10-1 图](#histogram_uniform) 显示了 `uniform`
    的分布：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'while [Figure 10-2](#histogram_normal) shows the distribution of `normal`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 而 [第 10-2 图](#histogram_normal) 显示了 `normal` 的分布：
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Histogram of uniform](assets/dsf2_1001.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![均匀分布直方图](assets/dsf2_1001.png)'
- en: Figure 10-1\. Histogram of uniform
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 第 10-1 图。均匀分布直方图
- en: In this case the two distributions have a pretty different `max` and `min`,
    but even knowing that wouldn’t have been sufficient to understand *how* they differed.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，两个分布的 `max` 和 `min` 相差很大，但即使知道这一点也不足以理解它们的 *差异*。
- en: Two Dimensions
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 两个维度
- en: Now imagine you have a dataset with two dimensions. Maybe in addition to daily
    minutes you have years of data science experience. Of course you’d want to understand
    each dimension individually. But you probably also want to scatter the data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下，您有一个具有两个维度的数据集。除了每天的分钟数，您可能还有数据科学经验的年数。当然，您希望单独了解每个维度。但您可能还想散点数据。
- en: 'For example, consider another fake dataset:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑另一个虚构数据集：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If you were to run `plot_histogram` on `ys1` and `ys2`, you’d get similar-looking
    plots (indeed, both are normally distributed with the same mean and standard deviation).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对 `ys1` 和 `ys2` 运行 `plot_histogram`，你会得到类似的图表（实际上，两者均为具有相同均值和标准差的正态分布）。
- en: '![Histogram of normal](assets/dsf2_1002.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![正态分布直方图](assets/dsf2_1002.png)'
- en: Figure 10-2\. Histogram of normal
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 第 10-2 图。正态分布直方图
- en: 'But each has a very different joint distribution with `xs`, as shown in [Figure 10-3](#scatter_ys1_ys2):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 但每个维度与 `xs` 的联合分布非常不同，如 [第 10-3 图](#scatter_ys1_ys2) 所示：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Scattering two different ys''s](assets/dsf2_1003.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![散射两个不同 ys 的图](assets/dsf2_1003.png)'
- en: Figure 10-3\. Scattering two different ys
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 第 10-3 图。散射两个不同的 ys
- en: 'This difference would also be apparent if you looked at the correlations:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看相关性，这种差异也会显现：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Many Dimensions
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多维度
- en: 'With many dimensions, you’d like to know how all the dimensions relate to one
    another. A simple approach is to look at the *correlation matrix*, in which the
    entry in row *i* and column *j* is the correlation between the *i*th dimension
    and the *j*th dimension of the data:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多维度，您可能想了解所有维度之间的关系。一个简单的方法是查看 *相关矩阵*，其中第 *i* 行和第 *j* 列的条目是数据的第 *i* 维和第 *j*
    维之间的相关性：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'A more visual approach (if you don’t have too many dimensions) is to make a
    *scatterplot matrix* ([Figure 10-4](#scatterplot_matrix)) showing all the pairwise
    scatterplots. To do that we’ll use `plt.subplots`, which allows us to create subplots
    of our chart. We give it the number of rows and the number of columns, and it
    returns a `figure` object (which we won’t use) and a two-dimensional array of
    `axes` objects (each of which we’ll plot to):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更直观的方法（如果维度不多）是制作一个*散点图矩阵*（参见[图 10-4](#scatterplot_matrix)），显示所有成对的散点图。为此，我们将使用`plt.subplots`，它允许我们创建图表的子图。我们给它行数和列数，它返回一个`figure`对象（我们将不使用它）和一个二维数组的`axes`对象（我们将每个都绘制）：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Scatterplot matrix](assets/dsf2_1004.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![散点图矩阵](assets/dsf2_1004.png)'
- en: Figure 10-4\. Scatterplot matrix
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-4\. 散点图矩阵
- en: Looking at the scatterplots, you can see that series 1 is very negatively correlated
    with series 0, series 2 is positively correlated with series 1, and series 3 only
    takes on the values 0 and 6, with 0 corresponding to small values of series 2
    and 6 corresponding to large values.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 从散点图中可以看出，系列1与系列0之间存在非常负相关的关系，系列2与系列1之间存在正相关的关系，而系列3只取值0和6，其中0对应于系列2的小值，6对应于系列2的大值。
- en: This is a quick way to get a rough sense of which of your variables are correlated
    (unless you spend hours tweaking matplotlib to display things exactly the way
    you want them to, in which case it’s not a quick way).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是快速了解哪些变量相关的一种粗略方法（除非你花费数小时调整matplotlib以完全按照你想要的方式显示，否则这不是一个快速方法）。
- en: Using NamedTuples
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用NamedTuples
- en: 'One common way of representing data is using `dict`s:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 表示数据的一种常见方式是使用`dict`s：
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: There are several reasons why this is less than ideal, however. This is a slightly
    inefficient representation (a `dict` involves some overhead), so that if you have
    a lot of stock prices they’ll take up more memory than they have to. For the most
    part, this is a minor consideration.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这不太理想的几个原因。这是一种略微低效的表示形式（一个`dict`涉及一些开销），因此如果你有很多股价，它们将占用比它们应该占用的更多内存。在大多数情况下，这只是一个小考虑。
- en: 'A larger issue is that accessing things by `dict` key is error-prone. The following
    code will run without error and just do the wrong thing:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更大的问题是通过`dict`键访问事物容易出错。以下代码将不会报错，但会执行错误的操作：
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, while we can type-annotate uniform dictionaries:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，虽然我们可以为统一的字典进行类型注释：
- en: '[PRE11]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: there’s no helpful way to annotate dictionaries-as-data that have lots of different
    value types. So we also lose the power of type hints.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一种有用的方法来注释具有许多不同值类型的字典数据。因此，我们也失去了类型提示的力量。
- en: 'As an alternative, Python includes a `namedtuple` class, which is like a `tuple`
    but with named slots:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种替代方案，Python包含一个`namedtuple`类，它类似于一个`tuple`，但具有命名的槽位：
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Like regular `tuple`s, `namedtuple`s are immutable, which means that you can’t
    modify their values once they’re created. Occasionally this will get in our way,
    but mostly that’s a good thing.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 像常规的`tuples`一样，`namedtuple`s是不可变的，这意味着一旦创建就无法修改它们的值。偶尔这会成为我们的障碍，但大多数情况下这是件好事。
- en: 'You’ll notice that we still haven’t solved the type annotation issue. We do
    that by using the typed variant, `NamedTuple`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到我们还没有解决类型注解的问题。我们可以通过使用类型化的变体`NamedTuple`来解决：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: And now your editor can help you out, as shown in [Figure 10-5](#helpful_editor).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你的编辑器可以帮助你，就像在[图 10-5](#helpful_editor)中显示的那样。
- en: '![Helpful editor](assets/dsf2_1005.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![有用的编辑器](assets/dsf2_1005.png)'
- en: Figure 10-5\. Helpful editor
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-5\. 有用的编辑器
- en: Note
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Very few people use `NamedTuple` in this way. But they should!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有人以这种方式使用`NamedTuple`。但他们应该！
- en: Dataclasses
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Dataclasses
- en: Dataclasses are (sort of) a mutable version of `NamedTuple`. (I say “sort of”
    because `NamedTuple`s represent their data compactly as tuples, whereas dataclasses
    are regular Python classes that simply generate some methods for you automatically.)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Dataclasses是`NamedTuple`的一种（某种程度上）可变版本。（我说“某种程度上”，因为`NamedTuple`s将它们的数据紧凑地表示为元组，而dataclasses是常规的Python类，只是为您自动生成了一些方法。）
- en: Note
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Dataclasses are new in Python 3.7. If you’re using an older version, this section
    won’t work for you.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Dataclasses在Python 3.7中是新功能。如果你使用的是旧版本，则本节对你无效。
- en: 'The syntax is very similar to `NamedTuple`. But instead of inheriting from
    a base class, we use a decorator:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 语法与`NamedTuple`非常相似。但是，我们使用装饰器而不是从基类继承：
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As mentioned, the big difference is that we can modify a dataclass instance’s
    values:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，最大的区别在于我们可以修改dataclass实例的值：
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If we tried to modify a field of the `NamedTuple` version, we’d get an `AttributeError`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试修改`NamedTuple`版本的字段，我们会得到一个`AttributeError`。
- en: 'This also leaves us susceptible to the kind of errors we were hoping to avoid
    by not using `dict`s:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这也使我们容易受到我们希望通过不使用`dict`来避免的错误的影响：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We won’t be using dataclasses, but you may encounter them out in the wild.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会使用dataclasses，但你可能会在野外遇到它们。
- en: Cleaning and Munging
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清洁和操纵
- en: Real-world data is *dirty*. Often you’ll have to do some work on it before you
    can use it. We saw examples of this in [Chapter 9](ch09.html#getting_data). We
    have to convert strings to `float`s or `int`s before we can use them. We have
    to check for missing values and outliers and bad data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的数据*脏*。通常你需要在使用之前对其进行一些处理。我们在[第9章](ch09.html#getting_data)中看到了这方面的例子。在使用之前，我们必须将字符串转换为`float`或`int`。我们必须检查缺失值、异常值和错误数据。
- en: 'Previously, we did that right before using the data:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，我们在使用数据之前就这样做了：
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'But it’s probably less error-prone to do the parsing in a function that we
    can test:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 但是在一个我们可以测试的函数中进行解析可能更少出错：
- en: '[PRE18]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: What if there’s bad data? A “float” value that doesn’t actually represent a
    number? Maybe you’d rather get a `None` than crash your program?
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有错误数据怎么办？一个不实际代表数字的“浮点”值？也许你宁愿得到一个`None`而不是使程序崩溃？
- en: '[PRE19]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'For example, if we have comma-delimited stock prices with bad data:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，如果我们有用逗号分隔的股票价格数据有错误：
- en: '[PRE20]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'we can now read and return only the valid rows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以只读取并返回有效的行了：
- en: '[PRE21]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: and decide what we want to do about the invalid ones. Generally speaking, the
    three options are to get rid of them, to go back to the source and try to fix
    the bad/missing data, or to do nothing and cross our fingers. If there’s one bad
    row out of millions, it’s probably okay to ignore it. But if half your rows have
    bad data, that’s something you need to fix.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 并决定我们想要如何处理无效数据。一般来说，三个选择是摆脱它们，返回到源头并尝试修复错误/丢失的数据，或者什么也不做，只是交叉手指。如果数百万行中有一行错误的数据，那么忽略它可能没问题。但是如果一半的行都有错误数据，那就是你需要解决的问题。
- en: A good next step is to check for outliers, using techniques from [“Exploring
    Your Data”](#exploring_your_data) or by ad hoc investigating. For example, did
    you notice that one of the dates in the stocks file had the year 3014? That won’t
    (necessarily) give you an error, but it’s quite plainly wrong, and you’ll get
    screwy results if you don’t catch it. Real-world datasets have missing decimal
    points, extra zeros, typographical errors, and countless other problems that it’s
    your job to catch. (Maybe it’s not officially your job, but who else is going
    to do it?)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个好的步骤是检查异常值，使用[“探索您的数据”](#exploring_your_data)中的技术或通过临时调查来进行。例如，你是否注意到股票文件中的一个日期的年份是3014年？这不会（必然）给你一个错误，但很明显是错误的，如果你不注意到它，你会得到混乱的结果。现实世界的数据集有缺失的小数点、额外的零、排版错误以及无数其他问题，你需要解决。（也许官方上不是你的工作，但还有谁会做呢？）
- en: Manipulating Data
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据操作
- en: One of the most important skills of a data scientist is *manipulating data*.
    It’s more of a general approach than a specific technique, so we’ll just work
    through a handful of examples to give you the flavor of it.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家最重要的技能之一是*数据操作*。这更像是一种通用方法而不是特定的技术，所以我们只需通过几个示例来让你了解一下。
- en: 'Imagine we have a bunch of stock price data that looks like this:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 想象我们有一堆股票价格数据，看起来像这样：
- en: '[PRE22]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Let’s start asking questions about this data. Along the way we’ll try to notice
    patterns in what we’re doing and abstract out some tools to make the manipulation
    easier.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始对这些数据提出问题。在此过程中，我们将尝试注意到我们正在做的事情，并抽象出一些工具，使操纵更容易。
- en: 'For instance, suppose we want to know the highest-ever closing price for AAPL.
    Let’s break this down into concrete steps:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想知道AAPL的最高收盘价。让我们将这个问题分解成具体的步骤：
- en: Restrict ourselves to AAPL rows.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 限制自己只看AAPL的行。
- en: Grab the `closing_price` from each row.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从每行中获取`closing_price`。
- en: Take the `max` of those prices.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取那些价格的最大值。
- en: 'We can do all three at once using a comprehension:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以一次完成所有三个任务使用推导：
- en: '[PRE23]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'More generally, we might want to know the highest-ever closing price for each
    stock in our dataset. One way to do this is:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地，我们可能想知道数据集中每支股票的最高收盘价。做到这一点的一种方法是：
- en: Create a `dict` to keep track of highest prices (we’ll use a `defaultdict` that
    returns minus infinity for missing values, since any price will be greater than
    that).
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`dict`来跟踪最高价格（我们将使用一个`defaultdict`，对于缺失值返回负无穷大，因为任何价格都将大于它）。
- en: Iterate over our data, updating it.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迭代我们的数据，更新它。
- en: 'Here’s the code:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码：
- en: '[PRE24]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We can now start to ask more complicated things, like what are the largest
    and smallest one-day percent changes in our dataset. The percent change is `price_today
    / price_yesterday - 1`, which means we need some way of associating today’s price
    and yesterday’s price. One approach is to group the prices by symbol, and then,
    within each group:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始询问更复杂的问题，比如数据集中最大和最小的单日百分比变化是多少。百分比变化是`price_today / price_yesterday
    - 1`，这意味着我们需要一种将今天价格和昨天价格关联起来的方法。一种方法是按符号分组价格，然后在每个组内：
- en: Order the prices by date.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按日期排序价格。
- en: Use `zip` to get (previous, current) pairs.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`zip`获取（前一个，当前）对。
- en: Turn the pairs into new “percent change” rows.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些对转换为新的“百分比变化”行。
- en: 'Let’s start by grouping the prices by symbol:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从按符号分组的价格开始：
- en: '[PRE25]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Since the prices are tuples, they’ll get sorted by their fields in order: first
    by symbol, then by date, then by price. This means that if we have some prices
    all with the same symbol, `sort` will sort them by date (and then by price, which
    does nothing, since we only have one per date), which is what we want.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于价格是元组，它们将按字段顺序排序：首先按符号，然后按日期，最后按价格。这意味着如果我们有一些价格具有相同的符号，`sort`将按日期排序（然后按价格排序，但由于每个日期只有一个价格，所以这没有什么效果），这正是我们想要的。
- en: '[PRE26]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'which we can use to compute a sequence of day-over-day changes:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用它来计算一系列日对日的变化：
- en: '[PRE27]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'and then collect them all:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然后收集它们全部：
- en: '[PRE28]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'At which point it’s easy to find the largest and smallest:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，找到最大值和最小值很容易：
- en: '[PRE29]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can now use this new `all_changes` dataset to find which month is the best
    to invest in tech stocks. We’ll just look at the average daily change by month:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用这个新的`all_changes`数据集来找出哪个月份最适合投资科技股。我们只需查看每月的平均每日变化：
- en: '[PRE30]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We’ll be doing these sorts of manipulations throughout the book, usually without
    calling too much explicit attention to them.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们将会进行这些操作，通常不会过多显式地提及它们。
- en: Rescaling
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新缩放
- en: Many techniques are sensitive to the *scale* of your data. For example, imagine
    that you have a dataset consisting of the heights and weights of hundreds of data
    scientists, and that you are trying to identify *clusters* of body sizes.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 许多技术对您数据的*尺度*很敏感。例如，想象一下，您有一个由数百名数据科学家的身高和体重组成的数据集，您试图识别体型的*聚类*。
- en: Intuitively, we’d like clusters to represent points near each other, which means
    that we need some notion of distance between points. We already have a Euclidean
    `distance` function, so a natural approach might be to treat (height, weight)
    pairs as points in two-dimensional space. Consider the people listed in [Table 10-1](#heights-and-weights).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 直觉上，我们希望聚类表示彼此附近的点，这意味着我们需要某种点之间距离的概念。我们已经有了欧氏`distance`函数，因此一个自然的方法可能是将（身高，体重）对视为二维空间中的点。考虑[表 10-1](#heights-and-weights)中列出的人员。
- en: Table 10-1\. Heights and weights
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10-1\. 身高和体重
- en: '| Person | Height (inches) | Height (centimeters) | Weight (pounds) |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 人员 | 身高（英寸） | 身高（厘米） | 体重（磅） |'
- en: '| --- | --- | --- | --- |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| A | 63 | 160 | 150 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| A | 63 | 160 | 150 |'
- en: '| B | 67 | 170.2 | 160 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| B | 67 | 170.2 | 160 |'
- en: '| C | 70 | 177.8 | 171 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| C | 70 | 177.8 | 171 |'
- en: 'If we measure height in inches, then B’s nearest neighbor is A:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们用英寸测量身高，那么B的最近邻是A：
- en: '[PRE31]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'However, if we measure height in centimeters, then B’s nearest neighbor is
    instead C:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们用厘米测量身高，那么B的最近邻将变为C：
- en: '[PRE32]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Obviously it’s a problem if changing units can change results like this. For
    this reason, when dimensions aren’t comparable with one another, we will sometimes
    *rescale* our data so that each dimension has mean 0 and standard deviation 1\.
    This effectively gets rid of the units, converting each dimension to “standard
    deviations from the mean.”
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，如果改变单位会导致结果发生变化，这是一个问题。因此，当维度不可比较时，我们有时会*重新缩放*我们的数据，使得每个维度的均值为0，标准差为1。这实际上消除了单位，将每个维度转换为“均值的标准偏差数”。
- en: 'To start with, we’ll need to compute the `mean` and the `standard_deviation`
    for each position:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要计算每个位置的`mean`和`standard_deviation`：
- en: '[PRE33]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We can then use them to create a new dataset:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以用它们创建一个新的数据集：
- en: '[PRE34]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Of course, let’s write a test to conform that `rescale` does what we think
    it should:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，让我们写一个测试来确认`rescale`是否按我们想的那样工作：
- en: '[PRE35]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: As always, you need to use your judgment. If you were to take a huge dataset
    of heights and weights and filter it down to only the people with heights between
    69.5 inches and 70.5 inches, it’s quite likely (depending on the question you’re
    trying to answer) that the variation remaining is simply *noise*, and you might
    not want to put its standard deviation on equal footing with other dimensions’
    deviations.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如常，您需要根据自己的判断。例如，如果您将一个大量的身高和体重数据集筛选为只有身高在 69.5 英寸和 70.5 英寸之间的人，剩下的变化很可能（取决于您试图回答的问题）只是*噪声*，您可能不希望将其标准差与其他维度的偏差平等看待。
- en: 'An Aside: tqdm'
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 旁注：tqdm
- en: Frequently we’ll end up doing computations that take a long time. When you’re
    doing such work, you’d like to know that you’re making progress and how long you
    should expect to wait.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 经常我们会进行需要很长时间的计算。当您进行这样的工作时，您希望知道自己在取得进展并且预计需要等待多长时间。
- en: One way of doing this is with the `tqdm` library, which generates custom progress
    bars. We’ll use it some throughout the rest of the book, so let’s take this chance
    to learn how it works.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是使用 `tqdm` 库，它生成自定义进度条。我们将在本书的其他部分中多次使用它，所以现在让我们学习一下它是如何工作的。
- en: 'To start with, you’ll need to install it:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用，您需要安装它：
- en: '[PRE36]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'There are only a few features you need to know about. The first is that an
    iterable wrapped in `tqdm.tqdm` will produce a progress bar:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需要知道几个特性。首先是，在 `tqdm.tqdm` 中包装的可迭代对象会生成一个进度条：
- en: '[PRE37]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'which produces an output that looks like this:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成一个类似于以下输出的结果：
- en: '[PRE38]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: In particular, it shows you what fraction of your loop is done (though it can’t
    do this if you use a generator), how long it’s been running, and how long it expects
    to run.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，它会显示循环的完成部分百分比（尽管如果您使用生成器，它无法这样做），已运行时间以及预计的剩余运行时间。
- en: In this case (where we are just wrapping a call to `range`) you can just use
    `tqdm.trange`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下（我们只是包装了对 `range` 的调用），您可以直接使用 `tqdm.trange`。
- en: 'You can also set the description of the progress bar while it’s running. To
    do that, you need to capture the `tqdm` iterator in a `with` statement:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在其运行时，您还可以设置进度条的描述。要做到这一点，您需要在 `with` 语句中捕获 `tqdm` 迭代器：
- en: '[PRE39]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This adds a description like the following, with a counter that updates as
    new primes are discovered:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这会添加一个如下描述，其中计数器会随着新的质数被发现而更新：
- en: '[PRE40]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Using `tqdm` will occasionally make your code flaky—sometimes the screen redraws
    poorly, and sometimes the loop will simply hang. And if you accidentally wrap
    a `tqdm` loop inside another `tqdm` loop, strange things might happen. Typically
    its benefits outweigh these downsides, though, so we’ll try to use it whenever
    we have slow-running computations.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `tqdm` 有时会使您的代码变得不稳定——有时屏幕重绘不良，有时循环会简单地挂起。如果您意外地将 `tqdm` 循环包装在另一个 `tqdm`
    循环中，可能会发生奇怪的事情。尽管如此，通常它的好处超过这些缺点，因此在我们有运行缓慢的计算时，我们将尝试使用它。
- en: Dimensionality Reduction
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 降维
- en: Sometimes the “actual” (or useful) dimensions of the data might not correspond
    to the dimensions we have. For example, consider the dataset pictured in [Figure 10-6](#scatter_pca_data).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 有时数据的“实际”（或有用）维度可能与我们拥有的维度不对应。例如，请考虑图示的数据集 [Figure 10-6](#scatter_pca_data)。
- en: '![Data with the ''wrong'' axes](assets/dsf2_1006.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![带有“错误”轴的数据](assets/dsf2_1006.png)'
- en: Figure 10-6\. Data with the “wrong” axes
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-6\. 带有“错误”轴的数据
- en: Most of the variation in the data seems to be along a single dimension that
    doesn’t correspond to either the x-axis or the y-axis.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中的大部分变化似乎沿着一个不对应于 x 轴或 y 轴的单一维度发生。
- en: When this is the case, we can use a technique called *principal component analysis*
    (PCA) to extract one or more dimensions that capture as much of the variation
    in the data as possible.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 当情况如此时，我们可以使用一种称为*主成分分析*（PCA）的技术来提取尽可能多地捕获数据变化的一个或多个维度。
- en: Note
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In practice, you wouldn’t use this technique on such a low-dimensional dataset.
    Dimensionality reduction is mostly useful when your dataset has a large number
    of dimensions and you want to find a small subset that captures most of the variation.
    Unfortunately, that case is difficult to illustrate in a two-dimensional book
    format.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，您不会在这样低维度的数据集上使用此技术。当您的数据集具有大量维度并且您希望找到捕获大部分变化的小子集时，降维大多数时候非常有用。不幸的是，在二维书籍格式中很难说明这种情况。
- en: 'As a first step, we’ll need to translate the data so that each dimension has
    mean 0:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们需要转换数据，使得每个维度的均值为 0：
- en: '[PRE41]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: (If we don’t do this, our techniques are likely to identify the mean itself
    rather than the variation in the data.)
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: （如果我们不这样做，我们的技术可能会识别出均值本身，而不是数据中的变化。）
- en: '[Figure 10-7](#pca_data_mean_removed) shows the example data after de-meaning.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 10-7](#pca_data_mean_removed) 显示了去均值后的示例数据。'
- en: '![PCA data with mean removed.](assets/dsf2_1007.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![去均值后的PCA数据。](assets/dsf2_1007.png)'
- en: Figure 10-7\. Data after de-meaning
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-7\. 去均值后的数据
- en: Now, given a de-meaned matrix *X*, we can ask which is the direction that captures
    the greatest variance in the data.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，给定一个去均值的矩阵 *X*，我们可以问哪个方向捕捉了数据中的最大方差。
- en: 'Specifically, given a direction `d` (a vector of magnitude 1), each row `x`
    in the matrix extends `dot(x, d)` in the `d` direction. And every nonzero vector
    `w` determines a direction if we rescale it to have magnitude 1:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，给定一个方向 `d`（一个大小为1的向量），矩阵中的每一行 `x` 在 `d` 方向上延伸 `dot(x, d)`。并且每个非零向量 `w`
    确定一个方向，如果我们重新缩放它使其大小为1：
- en: '[PRE42]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Therefore, given a nonzero vector `w`, we can compute the variance of our dataset
    in the direction determined by `w`:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，给定一个非零向量 `w`，我们可以计算由 `w` 确定的数据集在方向上的方差：
- en: '[PRE43]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We’d like to find the direction that maximizes this variance. We can do this
    using gradient descent, as soon as we have the gradient function:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望找到最大化这种方差的方向。我们可以使用梯度下降来实现这一点，只要我们有梯度函数：
- en: '[PRE44]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'And now the first principal component that we have is just the direction that
    maximizes the `directional_variance` function:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们拥有的第一个主成分就是最大化`directional_variance`函数的方向：
- en: '[PRE45]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: On the de-meaned dataset, this returns the direction `[0.924, 0.383]`, which
    does appear to capture the primary axis along which our data varies ([Figure 10-8](#pca_data_with_first_principal_component)).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在去均值的数据集上，这将返回方向 `[0.924, 0.383]`，看起来捕捉了数据变化的主轴（[图 10-8](#pca_data_with_first_principal_component)）。
- en: '![PCA data with first component.](assets/dsf2_1008.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![带有第一个成分的PCA数据。](assets/dsf2_1008.png)'
- en: Figure 10-8\. First principal component
  id: totrans-183
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-8\. 第一个主成分
- en: 'Once we’ve found the direction that’s the first principal component, we can
    project our data onto it to find the values of that component:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦找到了第一个主成分的方向，我们可以将数据投影到这个方向上，以找到该成分的值：
- en: '[PRE46]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'If we want to find further components, we first remove the projections from
    the data:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想找到更多的成分，我们首先要从数据中移除投影：
- en: '[PRE47]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Because this example dataset is only two-dimensional, after we remove the first
    component, what’s left will be effectively one-dimensional ([Figure 10-9](#pca_data_with_first_component_removed)).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这个示例数据集仅有二维，在移除第一个成分后，剩下的有效是一维的（[图 10-9](#pca_data_with_first_component_removed)）。
- en: '![Data after removing first principal component](assets/dsf2_1009.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![移除第一个主成分后的数据](assets/dsf2_1009.png)'
- en: Figure 10-9\. Data after removing the first principal component
  id: totrans-190
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-9\. 移除第一个主成分后的数据
- en: At that point, we can find the next principal component by repeating the process
    on the result of `remove_projection` ([Figure 10-10](#second_principal_component)).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在那一点上，通过在 `remove_projection` 的结果上重复这个过程，我们可以找到下一个主成分（[图 10-10](#second_principal_component)）。
- en: 'On a higher-dimensional dataset, we can iteratively find as many components
    as we want:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个高维数据集上，我们可以迭代地找到我们想要的许多成分：
- en: '[PRE48]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We can then *transform* our data into the lower-dimensional space spanned by
    the components:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以将我们的数据*转换*到由这些成分张成的低维空间中：
- en: '[PRE49]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: This technique is valuable for a couple of reasons. First, it can help us clean
    our data by eliminating noise dimensions and consolidating highly correlated dimensions.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术有几个原因很有价值。首先，它可以通过消除噪声维度和整合高度相关的维度来帮助我们清理数据。
- en: '![First two principal components.](assets/dsf2_1010.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![前两个主成分。](assets/dsf2_1010.png)'
- en: Figure 10-10\. First two principal components
  id: totrans-198
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-10\. 前两个主成分
- en: Second, after extracting a low-dimensional representation of our data, we can
    use a variety of techniques that don’t work as well on high-dimensional data.
    We’ll see examples of such techniques throughout the book.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，当我们提取出数据的低维表示后，我们可以使用多种在高维数据上效果不佳的技术。本书中将展示此类技术的示例。
- en: At the same time, while this technique can help you build better models, it
    can also make those models harder to interpret. It’s easy to understand conclusions
    like “every extra year of experience adds an average of $10k in salary.” It’s
    much harder to make sense of “every increase of 0.1 in the third principal component
    adds an average of $10k in salary.”
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，尽管这种技术可以帮助你建立更好的模型，但也可能使这些模型更难以解释。理解“每增加一年经验，平均增加1万美元的薪水”这样的结论很容易。但“第三主成分每增加0.1，平均薪水增加1万美元”则更难理解。
- en: For Further Exploration
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步探索
- en: As mentioned at the end of [Chapter 9](ch09.html#getting_data), [pandas](http://pandas.pydata.org/)
    is probably the primary Python tool for cleaning, munging, manipulating, and working
    with data. All the examples we did by hand in this chapter could be done much
    more simply using pandas. [*Python for Data Analysis*](https://learning.oreilly.com/library/view/python-for-data/9781491957653/)
    (O’Reilly), by Wes McKinney, is probably the best way to learn pandas.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如在 [第9章](ch09.html#getting_data) 结尾提到的，[pandas](http://pandas.pydata.org/)
    可能是清洗、处理和操作数据的主要 Python 工具。本章我们手动完成的所有示例，使用 pandas 都可以更简单地实现。《*Python 数据分析*》(O’Reilly)
    由 Wes McKinney 编写，可能是学习 pandas 最好的方式。
- en: scikit-learn has a wide variety of [matrix decomposition](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition)
    functions, including PCA.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn 提供了各种[矩阵分解](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition)函数，包括
    PCA。
