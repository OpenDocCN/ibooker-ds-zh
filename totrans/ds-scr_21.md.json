["```py\nfrom scratch.linear_algebra import Vector\n\ndef num_differences(v1: Vector, v2: Vector) -> int:\n    assert len(v1) == len(v2)\n    return len([x1 for x1, x2 in zip(v1, v2) if x1 != x2])\n\nassert num_differences([1, 2, 3], [2, 1, 3]) == 2\nassert num_differences([1, 2], [1, 2]) == 0\n```", "```py\nfrom typing import List\nfrom scratch.linear_algebra import vector_mean\n\ndef cluster_means(k: int,\n                  inputs: List[Vector],\n                  assignments: List[int]) -> List[Vector]:\n    # clusters[i] contains the inputs whose assignment is i\n    clusters = [[] for i in range(k)]\n    for input, assignment in zip(inputs, assignments):\n        clusters[assignment].append(input)\n\n    # if a cluster is empty, just use a random point\n    return [vector_mean(cluster) if cluster else random.choice(inputs)\n            for cluster in clusters]\n```", "```py\nimport itertools\nimport random\nimport tqdm\nfrom scratch.linear_algebra import squared_distance\n\nclass KMeans:\n    def __init__(self, k: int) -> None:\n        self.k = k                      # number of clusters\n        self.means = None\n\n    def classify(self, input: Vector) -> int:\n        \"\"\"return the index of the cluster closest to the input\"\"\"\n        return min(range(self.k),\n                   key=lambda i: squared_distance(input, self.means[i]))\n\n    def train(self, inputs: List[Vector]) -> None:\n        # Start with random assignments\n        assignments = [random.randrange(self.k) for _ in inputs]\n\n        with tqdm.tqdm(itertools.count()) as t:\n            for _ in t:\n                # Compute means and find new assignments\n                self.means = cluster_means(self.k, inputs, assignments)\n                new_assignments = [self.classify(input) for input in inputs]\n\n                # Check how many assignments changed and if we're done\n                num_changed = num_differences(assignments, new_assignments)\n                if num_changed == 0:\n                    return\n\n                # Otherwise keep the new assignments, and compute new means\n                assignments = new_assignments\n                self.means = cluster_means(self.k, inputs, assignments)\n                t.set_description(f\"changed: {num_changed} / {len(inputs)}\")\n```", "```py\nrandom.seed(12)                   # so you get the same results as me\nclusterer = KMeans(k=3)\nclusterer.train(inputs)\nmeans = sorted(clusterer.means)   # sort for the unit test\n\nassert len(means) == 3\n\n# Check that the means are close to what we expect\nassert squared_distance(means[0], [-44, 5]) < 1\nassert squared_distance(means[1], [-16, -10]) < 1\nassert squared_distance(means[2], [18, 20]) < 1\n```", "```py\nrandom.seed(0)\nclusterer = KMeans(k=2)\nclusterer.train(inputs)\nmeans = sorted(clusterer.means)\n\nassert len(means) == 2\nassert squared_distance(means[0], [-26, -5]) < 1\nassert squared_distance(means[1], [18, 20]) < 1\n```", "```py\nfrom matplotlib import pyplot as plt\n\ndef squared_clustering_errors(inputs: List[Vector], k: int) -> float:\n    \"\"\"finds the total squared error from k-means clustering the inputs\"\"\"\n    clusterer = KMeans(k)\n    clusterer.train(inputs)\n    means = clusterer.means\n    assignments = [clusterer.classify(input) for input in inputs]\n\n    return sum(squared_distance(input, means[cluster])\n               for input, cluster in zip(inputs, assignments))\n```", "```py\n# now plot from 1 up to len(inputs) clusters\n\nks = range(1, len(inputs) + 1)\nerrors = [squared_clustering_errors(inputs, k) for k in ks]\n\nplt.plot(ks, errors)\nplt.xticks(ks)\nplt.xlabel(\"k\")\nplt.ylabel(\"total squared error\")\nplt.title(\"Total Error vs. # of Clusters\")\nplt.show()\n```", "```py\npython -m pip install pillow\n```", "```py\nimage_path = r\"girl_with_book.jpg\"    # wherever your image is\nimport matplotlib.image as mpimg\nimg = mpimg.imread(image_path) / 256  # rescale to between 0 and 1\n```", "```py\ntop_row = img[0]\ntop_left_pixel = top_row[0]\nred, green, blue = top_left_pixel\n```", "```py\n# .tolist() converts a NumPy array to a Python list\npixels = [pixel.tolist() for row in img for pixel in row]\n```", "```py\nclusterer = KMeans(5)\nclusterer.train(pixels)   # this might take a while\n```", "```py\ndef recolor(pixel: Vector) -> Vector:\n    cluster = clusterer.classify(pixel)        # index of the closest cluster\n    return clusterer.means[cluster]            # mean of the closest cluster\n\nnew_img = [[recolor(pixel) for pixel in row]   # recolor this row of pixels\n           for row in img]                     # for each row in the image\n```", "```py\nplt.imshow(new_img)\nplt.axis('off')\nplt.show()\n```", "```py\nfrom typing import NamedTuple, Union\n\nclass Leaf(NamedTuple):\n    value: Vector\n\nleaf1 = Leaf([10,  20])\nleaf2 = Leaf([30, -15])\n```", "```py\nclass Merged(NamedTuple):\n    children: tuple\n    order: int\n\nmerged = Merged((leaf1, leaf2), order=1)\n\nCluster = Union[Leaf, Merged]\n```", "```py\ndef get_values(cluster: Cluster) -> List[Vector]:\n    if isinstance(cluster, Leaf):\n        return [cluster.value]\n    else:\n        return [value\n                for child in cluster.children\n                for value in get_values(child)]\n\nassert get_values(merged) == [[10, 20], [30, -15]]\n```", "```py\nfrom typing import Callable\nfrom scratch.linear_algebra import distance\n\ndef cluster_distance(cluster1: Cluster,\n                     cluster2: Cluster,\n                     distance_agg: Callable = min) -> float:\n    \"\"\"\n compute all the pairwise distances between cluster1 and cluster2\n and apply the aggregation function _distance_agg_ to the resulting list\n \"\"\"\n    return distance_agg([distance(v1, v2)\n                         for v1 in get_values(cluster1)\n                         for v2 in get_values(cluster2)])\n```", "```py\ndef get_merge_order(cluster: Cluster) -> float:\n    if isinstance(cluster, Leaf):\n        return float('inf')  # was never merged\n    else:\n        return cluster.order\n```", "```py\nfrom typing import Tuple\n\ndef get_children(cluster: Cluster):\n    if isinstance(cluster, Leaf):\n        raise TypeError(\"Leaf has no children\")\n    else:\n        return cluster.children\n```", "```py\ndef bottom_up_cluster(inputs: List[Vector],\n                      distance_agg: Callable = min) -> Cluster:\n    # Start with all leaves\n    clusters: List[Cluster] = [Leaf(input) for input in inputs]\n\n    def pair_distance(pair: Tuple[Cluster, Cluster]) -> float:\n        return cluster_distance(pair[0], pair[1], distance_agg)\n\n    # as long as we have more than one cluster left...\n    while len(clusters) > 1:\n        # find the two closest clusters\n        c1, c2 = min(((cluster1, cluster2)\n                      for i, cluster1 in enumerate(clusters)\n                      for cluster2 in clusters[:i]),\n                      key=pair_distance)\n\n        # remove them from the list of clusters\n        clusters = [c for c in clusters if c != c1 and c != c2]\n\n        # merge them, using merge_order = # of clusters left\n        merged_cluster = Merged((c1, c2), order=len(clusters))\n\n        # and add their merge\n        clusters.append(merged_cluster)\n\n    # when there's only one cluster left, return it\n    return clusters[0]\n```", "```py\nbase_cluster = bottom_up_cluster(inputs)\n```", "```py\n  0  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18\n──┬──┬─────┬────────────────────────────────┬───────────┬─ [19, 28]\n  │  │     │                                │           └─ [21, 27]\n  │  │     │                                └─ [20, 23]\n  │  │     └─ [26, 13]\n  │  └────────────────────────────────────────────┬─ [11, 15]\n  │                                               └─ [13, 13]\n  └─────┬─────┬──┬───────────┬─────┬─ [-49, 0]\n        │     │  │           │     └─ [-46, 5]\n        │     │  │           └─ [-41, 8]\n        │     │  └─ [-49, 15]\n        │     └─ [-34, 1]\n        └───────────┬──┬──┬─────┬─ [-22, -16]\n                    │  │  │     └─ [-19, -11]\n                    │  │  └─ [-25, -9]\n                    │  └─────────────────┬─────┬─────┬─ [-11, -6]\n                    │                    │     │     └─ [-12, -8]\n                    │                    │     └─ [-14, 5]\n                    │                    └─ [-18, -3]\n                    └─────────────────┬─ [-13, -19]\n                                      └─ [-9, -16]\n```", "```py\ndef generate_clusters(base_cluster: Cluster,\n                      num_clusters: int) -> List[Cluster]:\n    # start with a list with just the base cluster\n    clusters = [base_cluster]\n\n    # as long as we don't have enough clusters yet...\n    while len(clusters) < num_clusters:\n        # choose the last-merged of our clusters\n        next_cluster = min(clusters, key=get_merge_order)\n        # remove it from the list\n        clusters = [c for c in clusters if c != next_cluster]\n\n        # and add its children to the list (i.e., unmerge it)\n        clusters.extend(get_children(next_cluster))\n\n    # once we have enough clusters...\n    return clusters\n```", "```py\nthree_clusters = [get_values(cluster)\n                  for cluster in generate_clusters(base_cluster, 3)]\n```", "```py\nfor i, cluster, marker, color in zip([1, 2, 3],\n                                     three_clusters,\n                                     ['D','o','*'],\n                                     ['r','g','b']):\n    xs, ys = zip(*cluster)  # magic unzipping trick\n    plt.scatter(xs, ys, color=color, marker=marker)\n\n    # put a number at the mean of the cluster\n    x, y = vector_mean(cluster)\n    plt.plot(x, y, marker='$' + str(i) + '$', color='black')\n\nplt.title(\"User Locations -- 3 Bottom-Up Clusters, Min\")\nplt.xlabel(\"blocks east of city center\")\nplt.ylabel(\"blocks north of city center\")\nplt.show()\n```"]