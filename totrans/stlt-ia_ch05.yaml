- en: 6 A dashboard fit for a CEO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Building an interactive metrics dashboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wrangling data using the Pandas library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caching the results of functions to improve Streamlit app performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating filters, panels and other widgets in a dashboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing data visualizations and charts using Plotly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ever wondered how executives at large companies are able to stay on top of the
    business they run? Imagine the complexity and the sheer *number* of products and
    services offered by a company like Amazon, 3M, or Google. How can one person make
    sense of it all? How do they know if their business is meeting expectations and
    what areas need their focus?
  prefs: []
  type: TYPE_NORMAL
- en: In well-run companies, the answer—or part of it—is metrics. Executives rely
    on a carefully curated set of metrics, or numbers that give them a high-level
    overview of the company’s performance. Metrics help leaders make informed decisions,
    identify potential issues before they become major problems, and pinpoint areas
    where the company can improve or innovate.
  prefs: []
  type: TYPE_NORMAL
- en: But metrics alone are not enough—they need to be presented in a clear, digestible
    way. That's where dashboards come into play. A good dashboard allows users to
    explore various cuts of data, transforming raw data into a story, highlighting
    what's important and helping leaders stay focused on the bigger picture.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll develop such a dashboard designed for a CEO to monitor
    key performance indicators (KPIs) for their business. By its end, you'll not only
    know how to build a robust, interactive metrics dashboard using Streamlit, but
    also understand how to present data in a way that empowers decision-makers to
    focus on what truly matters.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 A metrics dashboard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Change is afoot at Note n' Nib Inc., everyone's favorite fictional online shopping
    site for stationery! The founder-CEO has retired to enjoy his millions in Ibiza,
    and his successor, a data-obsessed bigwig from Silicon Valley, has big plans for
    the company.
  prefs: []
  type: TYPE_NORMAL
- en: His enthusiasm is punctured a little when, in his first staff meeting, he asks
    the VP of Sales where he can look up the latest sales numbers and the VP fishes
    into his suitcase and retrieves a *paper* report from two months ago.
  prefs: []
  type: TYPE_NORMAL
- en: '"Don''t we have a dashboard where we keep track of daily sales data?", the
    CEO asks, dreading the answer. His fears are confirmed when the VP mutters something
    about the *old* CEO having possessed a marvelous *intuition* that he frequently
    relied upon to make decisions—and pen-and-paper being the core of the business
    after all.'
  prefs: []
  type: TYPE_NORMAL
- en: An hour later, the VP of Sales summons you, a rising star in the department
    (and his go-to for stuff he doesn't want to deal with himself) and tasks you with
    building "one of those fancy metrics pages with line charts" for his boss.
  prefs: []
  type: TYPE_NORMAL
- en: You know Engineering is busy with a major overhaul of the website, so you don't
    want to drop this on their plate. Luckily, you've been experimenting with this
    cool new Python framework called Streamlit and you're raring to use it at work.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.1 Stating the concept
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The VP didn''t give you a lot to work with, but you''ve been around long enough
    to have a pretty good idea of what the boss wants. As always, let''s start by
    spelling this out:'
  prefs: []
  type: TYPE_NORMAL
- en: Concept
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A dashboard that lets executives view various cuts of sales data and track key
    metrics to make decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.2 Defining the requirements
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have our work cut out for us to translate the concept into concrete requirements.
    Specifically, the phrases "sales data", "various cuts", and "key metrics" need
    to be expanded upon.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You've managed to get Engineering to export key data fields from their systems
    that you think will be relevant to your project into a Comma-Separated Values
    (CSV) file. You can download this file from the GitHub repo for this book (the
    file is called `sales_data.csv` and is in the `chapter_6` directory).
  prefs: []
  type: TYPE_NORMAL
- en: Once you've downloaded it, open it up in a spreadsheet program like Microsoft
    Excel or Numbers on macOS, and inspect the first few lines (shown in Figure 6.1)
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image001.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 The first two rows of the CSV data we'll work with
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The data represents the sales of various products sold by Note n' Nib, broken
    out by various *dimensions* such as segment and category. It also has demographic
    information about the kind of people who bought these products—specifically their
    gender and age group, as well as the state they hailed from. The file has data
    from January 2019 to August 2024, and contains *measures* such as sales (how much
    revenue did Note n' Nib make), gross margin (how much of the sales was profit,
    accounting for the cost), and the number of transactions covered by each row.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, here''s how we would interpret the first row: On Jan 1 2019,
    men aged 18-25 from California buying Inkstream fountain pens (classified as "writing
    tools") made 8 transactions on the Note n'' Nib website, bringing in $134.91 in
    sales to the company, of which $83.91 remained after subtracting costs.'
  prefs: []
  type: TYPE_NORMAL
- en: The *primary key* (the set of columns that uniquely identify a row) here is
    the combination of `date`, `product_name`, `segment`, `category`, `gender`, `age_group`,
    and `state`.
  prefs: []
  type: TYPE_NORMAL
- en: 'After speaking to the CEO, you also determine that he cares primarily about
    the following numbers: **total sales**, **gross margin**, **margin percentage**,
    and **average transaction value**. We''ll dive into these and how they''re calculated
    later in the chapter, but these are the "key metrics" from our stated concept.'
  prefs: []
  type: TYPE_NORMAL
- en: The CEO wants to be able to see how these numbers differ across different **products**,
    **categories**, **age groups**, **genders**, and **states**—the "various cuts"
    from the concept—as well as across time.
  prefs: []
  type: TYPE_NORMAL
- en: You also do some thinking about *how* the data should be represented, and finally
    come up with an initial set of requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Requirements
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The user should be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: view in aggregate the total sales, gross margin, margin percentage, and average
    transaction value of products sold on Note n' Nib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: view how these numbers differ across different years, products, categories,
    age groups, genders, and states
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: filter data by these dimensions to explore cross-sections of the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: visualize the trends and breakdowns of the metrics over time, broken down by
    each dimension
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to deliver an initial version of the dashboard quickly without getting
    bogged down in additional feature requests, so you clearly define what's out of
    scope too.
  prefs: []
  type: TYPE_NORMAL
- en: What's out of scope
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'At first launch, the dashboard will *not* support:'
  prefs: []
  type: TYPE_NORMAL
- en: Drilling down into the data to view specific rows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forecasting future values of any metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing explanations about why a metric has changed over time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some of these can be future expansions to the dashboard, but for now we'll try
    and limit its functionality to *observing* data as opposed to actively *analyzing*
    or *predicting* it.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.3 Visualizing the user experience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The next step in the app development flow we explored in Chapter 3 is to visualize
    the user experience. From the requirements, it's evident that the four key metrics
    are of vital importance, so we should display them prominently, ideally in such
    a way that the user's eye is immediately drawn towards them. The requirements
    also mention filtering the data based on the dimensions and cuts we discussed.
    It seems reasonable to include a panel where users can do this.
  prefs: []
  type: TYPE_NORMAL
- en: A picture speaks a thousand words, so we want to provide clear visualizations
    of the data; the trends and breakdowns indicated in the requirements could be
    realized through *time series charts,* which show the progression of a number
    over time, and *pie charts*, which tell you how a whole quantity breaks down into
    its components.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.2 shows a mock interface designed based on the above.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image002.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 A UI mock for the dashboard
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'As you can see, this design incorporates everything we discussed: the four
    key metrics are shown in a large unmissable font, and their values correspond
    to a slice of the data that is controlled by the filters at the top and a date
    range selector on the left.'
  prefs: []
  type: TYPE_NORMAL
- en: There's a line chart that shows how any selected metric has changed over time,
    and a pie chart that breaks down the total sales or gross margin by a selected
    dimension, like the product category.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.4 Brainstorming the implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we get started with actually writing code, let's map out the flow of
    logic and data in our dashboard at a high level. Figure 6.3 shows one way we might
    choose to structure this.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image003.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 Flow of logic and data in the dashboard
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The first step is to read the raw data from our CSV file and to load it into
    memory. There may be some basic data "preparation" or "cleaning" we want to perform
    next, such as renaming columns for convenience.
  prefs: []
  type: TYPE_NORMAL
- en: In our mock UI in figure 6.2, the filter bar at the top and the date range selectors
    to the side are meant to be *global*, i.e. they affect all of the widgets in the
    dashboard. So it stands to reason that we should apply the filters and select
    just the range we need before we pass the data around to the other parts of the
    dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three sections in the dashboard where we''ll display data in some
    form: the metric bar with the overall metric values, the change-over-time line
    chart, and the pie chart. To obtain the content to show in each of these, we need
    to apply *transformations* to the filtered data, meaning we''ll need to group,
    aggregate and otherwise *transform* it.'
  prefs: []
  type: TYPE_NORMAL
- en: The line and pie charts have additional options (you need to choose a metric
    to display in both charts, and a breakdown dimension—like the product category
    or gender—in the pie chart), which will serve as inputs to the transformations
    we'll apply.
  prefs: []
  type: TYPE_NORMAL
- en: This hopefully gave you an overview of the design we'll be implementing in the
    rest of the chapter. Don't worry if some of these parts aren't quite clear to
    you yet; we're about to explore each part in a lot more detail.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Loading the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In any application that presents or visualizes data, the first step involves
    obtaining data from some source. Sometimes this source is simply information entered
    by the user, but often it's an external source such as a database or a file. We'll
    talk about connecting to databases in later chapters, but for now we'll use the
    CSV file we reviewed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll walk through how to load data into your app from an external
    file, keep it in memory, and display it in Streamlit. Along the way, we'll introduce
    Pandas, the quintessential Python library for data manipulation. We'll also discuss
    how to improve your app's performance through caching when the data you need to
    load is very large.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1 The Pandas library
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I mentioned Pandas in passing in Chapter 1, describing it as a popular library
    for working with tabular data. In truth, Pandas has become such an integral part
    of the data ecosystem that it’s hard to imagine working with data in Python without
    it (or something like it at any rate).
  prefs: []
  type: TYPE_NORMAL
- en: Installing Pandas
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You can install Pandas the same way you would install any other Python library:
    using `pip`. Type the following to set it up now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Once that finishes running, verify that everything's set up right by running
    `pip show pandas`, which should display some information about the library.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring our sales data in Pandas
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Pandas revolves around the concept of the dataframe, which is a two-dimensional,
    tabular data structure similar to a table in a spreadsheet. It consists of rows
    and columns, where each column holds data of a specific type (eg. integer, float,
    string). Dataframes allow for efficient data manipulation and analysis, making
    them a versatile tool for handling structured data.
  prefs: []
  type: TYPE_NORMAL
- en: To see dataframes in action, let's load our sales data CSV into a Pandas dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the local directory where you downloaded `sales_data.csv`, open
    a Python shell and type the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `import pandas as pd` is a regular Python import statement. It's conventional
    to refer to the Pandas module as `pd` (just as we use `st` for Streamlit).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This is where we actually load the CSV file. Pandas makes this incredibly easy
    using the `read_csv` method. `read_csv` actually has a ton of parameters you can
    pass it (such as whether the file contains a header, what column names and types
    to use, and so on), but since all of these have sensible default values, you can
    also just pass it the path to the file and nothing else.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this, we have a variable `df` that holds a Pandas dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s verify this using Python''s built-in `type` function, which returns
    the type of the object that a particular variable holds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also get more information about the dataframe using its `info()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This tells us a variety of things. The dataframe has more than a million rows,
    numbered from 0 to 1034999\. It has ten columns, with the first seven being of
    the `object` type (strings, essentially) and the last three being `float64s` (or
    floating-point numbers).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: These names may be confusing to you since they're not the regular Python types
    (str, float, etc.) that you're likely used to. This is because Pandas uses its
    own data types (or dtypes), derived from a related Python library called `numpy`,
    for efficient computations.
  prefs: []
  type: TYPE_NORMAL
- en: 'You also have the option of having Pandas use the Apache Arrow format, which
    can be more performant for large datasets. To do so, while reading the CSV, add
    a `dtype_backend` parameter like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: If you do this, you'll notice that the data types shown by .info() are `string[pyarrow]`
    and `double[pyarrow]` rather than `object` and `float64`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at some of the content in the dataframe next. Since we don''t have
    enough space on this page to print all the columns, we first select a subset of
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You can create a new Pandas dataframe by performing some operation on another
    dataframe. That's essentially what happened here. When we pass a list of columns
    to a dataframe using Pandas' user-friendly square-bracket notation (`df[<list
    of column names>]`), we get a new dataframe containing only the columns we passed,
    which we can then assign to another variable (`only_some_cols` in this case).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to see the first few rows, we use the `.head()` method on our smaller
    dataframe, which shows us the values in the first five rows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We'll learn more Pandas as we go along, so let's stop here for now and get back
    to building our dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2 Reading and displaying a dataframe
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our dashboard app is going to involve a lot more code than some of the previous
    apps we've written, so it would be a good idea to spread it across multiple modules
    or `.py` files.
  prefs: []
  type: TYPE_NORMAL
- en: Loading data from the right file path
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We'll start with a dedicated Python script file to read in the data from our
    CSV. Copy `sales_data.csv` to the folder where you intend to keep your code files,
    and then create `data_loader.py` with the content shown in listing 6.1.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.1 data_loader.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `load_data` function simply uses Pandas to read in the CSV as we saw in
    the last section, but there seems to be more going on here. How are we populating
    the `SALES_DATA_PATH` variable? Why couldn't we just set it to `"sales_data.csv"`
    directly, given that `data_loader.py` is in the same directory as `sales_data.csv`?
  prefs: []
  type: TYPE_NORMAL
- en: The trouble here is that file paths in Python are considered to be relative
    to the *working directory you're executing a script from*, not the directory that
    the file containing the line currently being executed is located in.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if you're currently in `'/Users/alice/'`, your `.py` file and
    CSV are in the folder `'/Users/alice/streamlit_project/'` and you write `pd.read_csv('sales_data.csv')`,
    Python will look for the path `'/Users/alice/sales_data.csv'`, which doesn't exist.
  prefs: []
  type: TYPE_NORMAL
- en: You could hardcode the absolute path to the CSV and pass `'/Users/alice/streamlit_project/sales_data.csv'`,
    but that will obviously create issues when your app is deployed on a different
    computer where it won't be in that exact path.
  prefs: []
  type: TYPE_NORMAL
- en: No, what we need is a way to refer to the current `.py` file and construct a
    path relative to that file's path.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what the two lines near the top do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '`__file__` is a special variable in Python that contains the path of the file
    currently being executed.'
  prefs: []
  type: TYPE_NORMAL
- en: '`Path` is a class from the `pathlib` module (which comes built-in with Python)
    that lets you work with file paths in a user-friendly, object-oriented way. `Path(__file__)`
    creates a Path object corresponding to the current Python script, `data_loader.py`,
    and `.resolve()` dynamically generates the absolute path to `data_loader.py` (regardless
    of whether it''s in your local machine or a production deployment). The `.parent`
    then refers to the directory `data_loader.py` is in.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we use the `'/'` operator which works with `Path` objects (and is *not*
    the mathematical divided-by operator in this context) to generate the final path
    to our CSV, stored in `SALES_DATA_PATH`.
  prefs: []
  type: TYPE_NORMAL
- en: It's worth noting that `SALES_DATA_PATH` is not a string, it's still a `Path`
    object. Fortunately, Pandas' `read_csv` knows how to handle those, so we can pass
    it directly to that function.
  prefs: []
  type: TYPE_NORMAL
- en: Using st.write to display the dataframe
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let's now use the `load_data` function we just created in our Streamlit app.
    Create an entrypoint (the file we'll use with `streamlit run`) to the app called
    `dashboard.py`, shown in listing 6.2.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.2 dashboard.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This part is fairly straightforward. `data` is a Pandas dataframe with data
    from our CSV (since that's what `load_data` returns).
  prefs: []
  type: TYPE_NORMAL
- en: The last line, `st.write(data.head(5))`, is interesting. We've briefly encountered
    `st.write` before, in Chapter 2\. Streamlit's docs describe `st.write` as "the
    Swiss Army knife of Streamlit commands" and that's fairly accurate.
  prefs: []
  type: TYPE_NORMAL
- en: You can basically pass pretty much any kind of object to `st.write` and it'll
    display the passed object in a graceful and sensible way. This means you can pass
    it a string and it'll write the string to the screen, but you can also pass it
    a dictionary and it'll print out the contents of the dictionary in a well-formatted
    way (try it out!). You can even pass it internal Python objects like classes or
    functions and it'll display information about them.
  prefs: []
  type: TYPE_NORMAL
- en: '`st.write` works well for our purposes because we can pass it a Pandas dataframe
    and it''ll show the data on the screen. `data.head(5)` returns a dataframe with
    only the first 5 rows of the data, and using `st.write` on it helps us verify
    that the data was loaded correctly, as shown in figure 6.4—which is what you''ll
    get if you execute `streamlit run dashboard.py`.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image004.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 Streamlit can display Pandas dataframes natively
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You may notice that it takes a few seconds for the app to load. This is because
    our CSV file is rather large (more than 90 megabytes) and reading it takes a while.
    At first glance, this might not sound like a huge deal, but recall once again
    that Streamlit reruns your *entire* script every time anything needs to change
    on the screen.
  prefs: []
  type: TYPE_NORMAL
- en: That means that each time the user changes a selection or clicks out of a textbox,
    your app will re-read the CSV, slowing down the whole app. Besides being incredibly
    wasteful, that would degrade your dashboard's user experience, so let's address
    that next.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3 Caching data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the effects of Streamlit's execution model is that, without intervention,
    expensive operations such as reading a file or performing a complex computation
    are executed over and over again to get the same results every time. This can
    be problematic for data apps like the one we're building now since they frequently
    rely upon such operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In prior chapters, we''ve seen one way to deal with the problem: we could save
    the data into `st.session_state`. That way the data would only have to be read
    once per user session, and the app wouldn''t slow down during user interactions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is an *okay* solution, but doesn''t solve a couple of issues:'
  prefs: []
  type: TYPE_NORMAL
- en: The data would still need to be loaded every time the web page is refreshed.
    If the user opens the dashboard in multiple tabs—and given the number of browser
    tabs the average person has open at any point, they probably will—it would take
    a while to load each time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dashboard would have to read the data from scratch for *each* user even
    though it's the exact same data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streamlit offers a better way to deal with this situation, in the form of `st.cache_data`.
  prefs: []
  type: TYPE_NORMAL
- en: st.cache_data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`st.cache_data` is Streamlit''s way of *caching* or storing the results of
    a slow function call so that the next time the function is called with the same
    parameters, it can simply look up the stored result of the *last* call rather
    than actually executing the function again.'
  prefs: []
  type: TYPE_NORMAL
- en: For our use case, we can simply cache the result of the `load_data` function
    we wrote earlier. Streamlit would then store the Pandas dataframe it returns,
    and subsequent app reruns or even page refreshes wouldn't cause the function to
    be executed again.
  prefs: []
  type: TYPE_NORMAL
- en: '`st.cache_data` uses a different Python construct from the Streamlit elements
    we''ve seen so far: it''s a *decorator,* which you can think of as something that
    takes a function or a class and adds some new feature to it without you having
    to rewrite the function or class.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply `st.cache_data` on the `load_data` function (in `data_loader.py`),
    simply write `@st.cache_data` above it, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here, `st.cache_data` is *decorating* the `load_data` function, transforming
    it with the caching feature so that when it's called again, it'll return the previous
    cached result rather than executing its logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we''re now referring to a Streamlit element within `data_loader.py`,
    we also need to include the Streamlit import at the top:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If you run the app now, you'll briefly see a spinning icon with the text "Running
    `load_data()."` (see figure 6.5) before your dataframe is displayed, but if you
    reload the page your data should now load instantly.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image005.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 By default, st.cache_data shows a spinner with a function name when
    actually running the function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Looks like the caching is working! Here''s a question though: what happens
    when the data changes? The CEO wants a dashboard with *up-to-date* sales data,
    so we can assume that the source data will change periodically—at least daily
    if not more frequently than that. For our example, let''s assume that Engineering
    will overwrite the existing CSV with a version with newer data every day.'
  prefs: []
  type: TYPE_NORMAL
- en: If the data is cached the way we've set it up, Streamlit won't pull in the updated
    CSV when it changes. It will just see that the return value of `load_data` is
    cached from the first run (perhaps several days ago) and use that.
  prefs: []
  type: TYPE_NORMAL
- en: We need a way to set an *expiry date* for the cache, essentially telling it
    that if the cached data is older than a certain threshold, the function needs
    to actually be executed and the results re-cached.
  prefs: []
  type: TYPE_NORMAL
- en: We achieve this using the `ttl` argument of `st.cache_data`. `ttl` stands for
    "time-to-live" and sets the amount of time that the cached data is valid for before
    Streamlit will re-execute the function during a rerun.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we assume that our CSV data will change every day, we could set a `ttl`
    of 1 day like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This way, the loaded data will be pulled once every day when a user runs the
    app. That run will take a while, but all subsequent runs in the following 24 hours
    will use the newly cached data and therefore be quick.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.6 illustrates how this works.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image006.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 How st.cache_data works
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Another thing we probably want to change is the message displayed with the
    spinning icon. The name `load_data` is internal to our code and we don''t want
    it exposed to users. We can change this message using the `show_spinner` argument
    of `st.cache_data` so our code becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Run the app again and you'll notice the loading indicator has changed to figure
    6.7.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image007.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 Setting the show_spinner parameter in st.cache_data displays a user-friendly
    message when the data is loading
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: It's valuable to realize that when a user runs the app and the data is cached,
    the cached values are available to *all* users of the app, not just the current
    one. There are times when this can lead to unexpected results (we'll probably
    encounter some of these in later chapters), but in this case, since we want to
    show all users the same data, it's desirable behavior.
  prefs: []
  type: TYPE_NORMAL
- en: With the data loaded and available within our app, let's move on to constructing
    the dashboard itself.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Prepping and filtering the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A key requirement our dashboard needs to meet is the ability to inspect various
    *slices* of the data, as opposed to its entirety. This is quite logical; our source
    data runs across 5+ years. A user today would probably be more interested in the
    most recent year of data than older years. Similarly, a user may only be interested
    in sales related to the "Paper products" category.
  prefs: []
  type: TYPE_NORMAL
- en: '*Filtering* a table of data is the act of considering only the rows of data
    that we care about, and excluding everything else. Our envisioned dashboard has
    two areas that enable this: a *filter panel* where users can choose the values
    of each field they want to consider, and a *date range selector*.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section we'll build both of these components visually, and perform the
    Pandas data wrangling that enables their functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1 Creating a filter panel
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's revisit our UI mock, focusing on the filter panel at the top, reproduced
    in figure 6.8.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image008.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 The filter panel from our UI mock
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The panel is essentially a collection of dropdown menus, one for each field
    that we want to filter by.
  prefs: []
  type: TYPE_NORMAL
- en: Each menu presumably contains the unique values corresponding to each field
    as options, and the user can choose multiple options (eg. in figure 6.8, the "State"
    filter has CA, TX and FL all selected). Also, the user can choose not to select
    *any* option (eg. "Gender" in figure 6.8), which we should probably treat as there
    not being any filter on that field.
  prefs: []
  type: TYPE_NORMAL
- en: The selections shown in figure 6.8 should cut the data down to rows corresponding
    to the 18-25 and 26-35 age groups for customers in CA, TX or FL. Since there's
    no filter on, say, "Product name", the data should include all products sold by
    Note n' Nib.
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining the list of unique values for a field
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Clearly, we need a way to populate the options in the dropdowns when we create
    them. A plausible way to do this might be to hardcode the list of possible values
    for each field, but this presents some glaring issues: we would need to change
    our code every time there''s a new product or category, or if the way we''re grouping
    ages changes, or for plenty of other reasons.'
  prefs: []
  type: TYPE_NORMAL
- en: A better approach is to get the list of options dynamically, from the data *itself*.
    Start a new Python file called `data_wrangling.py` and add a function to do this,
    as shown in listing 6.3.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.3 data_wrangling.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The `get_unique_values` function accepts a Pandas dataframe `df` and a column
    name `column`. It returns a list of unique values for that column in the dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: When you pass a column name to a Pandas dataframe within square brackets (an
    operation named *column selection*), you get a Pandas *series*, which is a one-dimensional
    array-like object (you could think of it as a single-column dataframe).
  prefs: []
  type: TYPE_NORMAL
- en: For instance, `df['age_group']` would return a series with the same number of
    elements as there are rows in `df`, with each element being the `age_group` corresponding
    to a row.
  prefs: []
  type: TYPE_NORMAL
- en: Calling `.unique()` on it dedupes the elements and gives you a new series with
    just the five or six distinct age groups in the data. We finally convert it into
    a regular Python list with the `list` function.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the dropdowns with st.multiselect
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As we've seen, the user should be able to select any combination of options
    in each filter. Streamlit provides this functionality through `st.multiselect`,
    which is quite similar to `st.selectbox`, which we've come across before. As in
    the case of `st.selectbox`, the first two parameters (the only required ones)
    that you pass to `st.multiselect` are the label and the list of options.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you could write `st.multiselect('Color', ['blue', 'green', 'red'])`
    to display a dropdown labeled "Color" from which you can select one or more colors.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping with our approach of spreading our code into several modules, we'll
    create a new one for the filter panel and call it `filter_panel.py`.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.4 shows a starting draft of `filter_panel.py`.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.4 dashboard.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`filter_dims` holds the list of fields from the dataframe that we want to filter
    on.'
  prefs: []
  type: TYPE_NORMAL
- en: The `filter_panel` function is what actually displays the dropdowns. It takes
    a dataframe as input and renders the dropdowns using the unique values for each
    field.
  prefs: []
  type: TYPE_NORMAL
- en: Some of this code should look familiar by this point. We want to display the
    dropdowns side by side, so we use `st.columns(len(filter_dims))` to create as
    many display columns as there are fields we want to filter on.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each field, we obtain the unique values using our `get_unique_values` function
    from `data_wrangling.py`, and use them to populate the dropdown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Listing 6.4 also shows the use of a new Streamlit widget called `st.expander`,
    which is a collapsible box that users can expand or contract as needed. This makes
    sense because the user probably doesn't want to see the filters all the time.
    It's a good idea to have the option of hiding them so they can focus on the actual
    displayed data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s include the `filter_panel` in our main dashboard by editing `dashboard.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This should yield the output in figure 6.9.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image009.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 By default, our Streamlit app's layout is centered, which can be
    problematic if there's a lot to display horizontally
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: One issue we can see immediately is that with six fields to filter on, each
    individual filter seems to be squished against its neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the filter field names are currently the raw column names from
    the CSV, including underscores. A more polished design would present these as
    user-friendly labels, such as "Age group," instead of technical identifiers like
    "age_group."
  prefs: []
  type: TYPE_NORMAL
- en: Fixing the width issue
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Notice in figure 6.9 that there's a lot of unused whitespace to the sides of
    the filter panel. By default, Streamlit apps have a "centered" layout where the
    body of the app is rendered horizontally at the center of the window, and the
    sides are blank.
  prefs: []
  type: TYPE_NORMAL
- en: This is usually fine, but with a UI as dense as what we're building, screen
    real estate comes at a premium. Thankfully, Streamlit allows us to change this
    and use more of the screen. We can do this using the `st.set_page_config` method
    in `dashboard.py`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Importantly, this only works if it's the very first Streamlit command executed
    in an app, so make sure it's at the top of `dashboard.py`, right after the imports.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying user-friendly labels for fields
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To swap out the raw field names for labels, we could retain a mapping between
    the raw names and their associated labels in a dictionary, and look up the label
    every time we needed to display the name of a field. That sounds quite tedious
    though, so instead let's just rename the fields in the data frame to be user-friendly
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'There will probably be a bunch of similar "cleaning-up" modifications we''ll
    need to make to the data. We''ll bundle these up into a `prep_data` function in
    `data_wrangling.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '#A Don''t forget to import the functions we need from other modules'
  prefs: []
  type: TYPE_NORMAL
- en: '#B Move the st.cache_data decorator so it applies to prep_data instead of load_data'
  prefs: []
  type: TYPE_NORMAL
- en: Here we define a function called `clean_column_names` that replaces the underscores
    in each column name of a dataframe with spaces and capitalizes it. `df.columns`
    returns the dataframe column names, and `.str.replace()` and `.str.capitalize()`
    are the respective string operations. We use `.str` to apply the replace and capitalize
    operations to each element in `df.columns` in one go, which is something which
    you'll see quite frequently in Pandas.
  prefs: []
  type: TYPE_NORMAL
- en: For now, the `prep_data` function calls `load_data` internally and then simply
    returns the result of applying `clean_column_names` to the returned dataframe,
    but we'll add more logic to it later.
  prefs: []
  type: TYPE_NORMAL
- en: We've also moved `st.cache_data` decorator to the `prep_data` function (remove
    it from `load_data` in `data_loader.py`) because `prep_data` is supposed to contain
    basic operations we always want done on the data. After this, Streamlit will cache
    the result only after prepping the data, not immediately after loading it.
  prefs: []
  type: TYPE_NORMAL
- en: To close the loop, in `dashboard.py`, replace the line `data = load_data()`
    with `data = prep_data()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, in `filter_panel.py`, modify `filter_dims` to use the newly polished
    field names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Save and re-run to see the result shown in figure 6.10
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image010.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 Filter panel with user-friendly field names and a wide layout
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The dashboard now uses up the full width of the screen, and we're using labels
    for the filters.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Due to the amount of code in this chapter and the limited amount of space available
    on the printed page, while providing code snippets here, we'll focus primarily
    on how the code in a particular file has *changed* rather than reproducing the
    entire file as we did in previous chapters. However, at any point, if you're stuck
    and would like to compare your code to what it should be at that point, you can
    see complete in-progress snapshots of the code in the GitHub repo for this book
    (github.com/aneevdavis/streamlit-in-action), under the chapter_6 folder. For instance,
    the code files you should be comparing to at the moment are in the in_progress_4
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the filters to the data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: So far, we've created the UI elements corresponding to the filters, but we haven't
    actually applied them to the data.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, let's first think of how we should represent the output we get from
    the filter panel. To be able to apply the filters, we need to look up the values
    the user has selected in the filter for each dimension. This is a good use case
    for a dictionary that has each field name as a key and the list of selected options
    as the value for the key.
  prefs: []
  type: TYPE_NORMAL
- en: Our current `filter_panel` function (from `filter_panel.py`) simply displays
    the filter bar, but we want to modify it so that it actually returns such a dictionary
    that we can use for further processing.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Though we weren't making use of this earlier, `st.multiselec`t actually returns
    the list of options a user has selected in the UI. As the highlighted lines show,
    we're now storing this returned value in the `filters` dictionary using `dim`
    (the field name) as the key, and returning filters at the end.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we need to use the dictionary to produce the slice of the data the user
    wants. Since this involves data manipulation operations, let's put this functionality
    in `data_wrangling.py`, in a function called `apply_filters`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '`apply_filters` takes `df`—a Pandas dataframe—and the filters dictionary returned
    by `filter_panel`. It goes through each of the key-value pairs in filters and
    iteratively modifies the dataframe by filtering it using the statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This is worth breaking down a little. The square brackets are quite versatile
    in Pandas. When you pass a column name in the brackets following a dataframe variable
    (like `df['Age group']`), it returns that column as a Pandas series—as we've seen
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: If, instead, you pass a Pandas boolean series (a series where each item is a
    boolean) instead, it will match the numbered elements of the series against the
    ordered rows of the dataframe, returning only the rows where the corresponding
    boolean value is `True`. This is called *boolean indexing*.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see both of these usages in the line above:'
  prefs: []
  type: TYPE_NORMAL
- en: '`df[col]` does column selection, selecting the col (the column to filter) in
    df.'
  prefs: []
  type: TYPE_NORMAL
- en: The `.isin(values)` applies an element-wise operation on the column, checking
    whether each value in it is present in values, the list of dropdown options selected
    by the user. This returns another series with a `True`/`False` value for every
    corresponding item in `df[col]`. This is an example of a *vectorized* calculation,
    which is responsible for much of Pandas' performance.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we perform boolean indexing, using the boolean series obtained in the
    previous step to produce a new filtered dataframe and assign *that* to df.
  prefs: []
  type: TYPE_NORMAL
- en: Effectively, each time it executes, the line `df = df[df[col].isin(values)]`
    filters the dataframe to include only rows where the column we're currently looking
    at contains one of the values the user selected.
  prefs: []
  type: TYPE_NORMAL
- en: The `if values` part ensures that we don't do the filtering if the user hasn't
    selected any values for a field, thus correctly implementing our requirement.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see this in action, make the required modifications to `dashboard.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '#A We now put the dictionary returned by filter_panel(data) in a variable'
  prefs: []
  type: TYPE_NORMAL
- en: We're now capturing the dictionary of filters, using `apply_filters` to create
    a new dataframe called `main_df`, and displaying that instead of data. This should
    give us the result in figure 6.11.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image011.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.11 The selections in the filter panel correctly filter the displayed
    rows (see chapter_6/in_progress_5 in the GitHub repo for a snapshot of the full
    code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As you can see, the displayed dataframe only shows rows corresponding to the
    user's selections in the filter panel (18-25, M, Staples, CA).
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s still one more kind of filter to apply: the date range! Let''s deal
    with that next.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2 Creating a date range selector
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As usual, Streamlit offers an easy way to enable users to select a date range.
    In its typical intuitive naming fashion, the widget we want is called `st.date_input`.
  prefs: []
  type: TYPE_NORMAL
- en: '`st.date_input` accepts a label, a default value, minimum and maximum values
    and more. You can have the user select a single date or a range of dates.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, to allow the user to select a single date with today''s date
    as the default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'To enable a date range selection between a default start and end date:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We'll put our date range selector in a new file called `date_range_panel.py`,
    shown in listing 6.5.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.5 date_range_panel.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The `date_range_panel` function displays two date selector widgets—one each
    for the start and end of the range—and returns the dates selected by the user.
    We're opting to use two separate single-date inputs here instead of a single range
    input to prevent temporary errors when the end of the range hasn't been selected
    yet.
  prefs: []
  type: TYPE_NORMAL
- en: For the default date range values, we show a start date of one month ago and
    an end date of today, using the variables `THIRTY_DAYS_AGO` and `LATEST_DATE`.
    Since we're dealing with a static dataset, we hardcode `LATEST_DATE` to a particular
    date that's available in the CSV. If we were working with real-time or regularly
    updated data, we would have replaced this with `LATEST_DATE = date.today()`. `THIRTY_DAYS_AGO`
    is obtained by subtracting 30 days from `LATEST_DATE` using the `timedelta` class
    from the `datetime` module.
  prefs: []
  type: TYPE_NORMAL
- en: The values `LATEST_DATE` and `THIRTY_DAYS_AGO` are of the type `date`, from
    the built-in `datetime` module. `st.date_input` understands this type and even
    returns it. The variables `start` and `end` returned by `date_range_panel` are
    thus both also of type `date`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, let''s make use of those values presently by editing `data_wrangling.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve made a few changes here:'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to cleaning up the column names, `prep_data` adds a new column called
    'Day', the result of applying `pd.to_datetime()` to the existing 'Date' column.
    Recall that the 'Date' column is currently an opaque "object" type. `pd.to_datetime()`
    converts it to `datetime[ns]` which can be optimized by Pandas.
  prefs: []
  type: TYPE_NORMAL
- en: We've wrapped a call to `apply_filters` within the `get_filtered_data_within_date_range`
    function, which first accepts the start and end dates of the date range and uses
    them to call `get_data_within_date_range`.
  prefs: []
  type: TYPE_NORMAL
- en: '`get_data_within_date_range` is the function that actually applies the date
    range filter on our dataframe. The first line in this function does a date format
    conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This is because Pandas uses a `datetime[ns]` type to represent dates. This is
    different from Python's `date` type that `start` and `end` are in, and is more
    efficient for use in dataframe operations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: This is boolean indexing again, similar to what we encountered in the `apply_filters`
    function, but we're using a combination of two conditions (`df['Day'] >= dt_start
    and df['Day'] <= dt_end`) to filter the dataframe, joining them with `&`, which
    is Pandas' element-wise logical `AND` operator.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to update dashboard.py again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We place the date range panel in a sidebar (which you should be quite comfortable
    with by now).
  prefs: []
  type: TYPE_NORMAL
- en: And since `apply_data` is now contained within `get_filtered_data_within_date_range`,
    we assign the result of this wrapping function to `main_df`.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.12 shows our new date range panel.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image012.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.12 Date range inputs displayed in a sidebar (see chapter_6/in_progress_6
    in the GitHub repo for a full code snapshot)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Our dashboard is slowly starting to take form! It's not very useful to the CEO
    at the moment, however, since it doesn't show any summary information or metrics.
    That's up next!
  prefs: []
  type: TYPE_NORMAL
- en: 6.4 Calculating and displaying metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine you're running a business. How do you know if it's thriving or struggling,
    whether it's about to go through the roof or come crashing down?
  prefs: []
  type: TYPE_NORMAL
- en: One obvious answer is that you'd look at how much the company is earning and
    the amount of profit it's making. You'll likely also want to know the rate at
    which your revenue is growing. If you're a fan of Shark Tank's Mr. Wonderful,
    you probably also keep track of more esoteric numbers such as how much it costs
    you to acquire a customer.
  prefs: []
  type: TYPE_NORMAL
- en: All of these numbers are called *metrics*. Metrics are useful because they help
    you boil down all the complexity of a vast business (or any project, really) into
    a few figures. If a positive metric (like profit) is going up or a negative metric
    (like cost) is going down, that means things are going well. If the opposite is
    happening, something likely needs to change.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll calculate and display the metrics that Note n' Nib's
    CEO cares about. To do this, we'll first understand what the metrics mean and
    how to calculate them. We'll then set up a scalable way to define new metrics
    for our dashboard to use, and display them prominently in the dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.1 Calculating the metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Referring back to our requirements, there are four metrics we care about: *total
    sales*, *gross margin*, *margin percentage*, and *average transaction value*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try and understand these in reference to our data. Recall that our source
    CSV has one row for every combination of date, product (and its associated segment
    and category), gender, age group and state. For each row, it gives us three numeric
    fields: *sales*, *gross margin*, and *transactions*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A transaction refers to a single purchase of some number of items, and the
    figure "transactions" refers to the number of them represented by a row. Sales
    is pretty easy to understand: it''s the amount in dollars Note n'' Nib collected
    from those transactions. Gross margin is the profit, or sales minus the cost that
    the company paid to acquire what the items it sold.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given this, let''s figure out how to calculate our metrics for any given slice
    of our CSV:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Total sales** is simply the sum of the sales column'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, **gross margin** is the sum of the gross margin column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Margin percentage** is the gross margin expressed as a percentage of total
    sales, so it''s calculated as total sales / gross margin * 100'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Average transaction value** is the what Note n'' Nib earned per transaction,
    so we can calculate it as total sales / sum of the transactions column'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s consider a quick example to crystallize this. Imagine you have the following
    rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '*Total sales* is $500 + $300 + $200 = $1000'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Gross margin* is $200 + $120 + $80 = $400'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Margin percentage* is $400 / $1000 = 0.4 = 40%'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Average transaction value* is $1000 / (10 + 5 + 8) = $1000 / 23 = $43.48'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.4.2 Setting up the metrics configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A recurring theme you'll come across in software development is that it's a
    good idea to keep your design reasonably *general*. By this, I mean that if you
    have a choice between coding something in a very specific way (hardcoding a list
    of values, for instance) and coding it in a flexible way (populating the list
    from a configuration file), it's often better practice to do the latter.
  prefs: []
  type: TYPE_NORMAL
- en: A more general design makes your code more adaptable to future changes, and
    easier to maintain. We saw this when we developed a unit converter app in Chapter
    3, where rather than putting the conversion factors directly in our code, we opted
    to use a configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly what we'll do to set up the metrics in our dashboard—define
    a configuration file that defines how to calculate them.
  prefs: []
  type: TYPE_NORMAL
- en: As we did in Chapter 3, we'll start by creating a dataclass—`Metric`—to hold
    the object we want to configure. Let's put this in a new file called `metric.py`
    (see listing 6.6).
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.6 metric.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The `Metric` class contains a title, which is the label we'll display on the
    interface, and a type, which indicates how it should be formatted (eg. "dollars"
    as the type would instruct our app to prefix a '$' sign before the number).
  prefs: []
  type: TYPE_NORMAL
- en: It also has a member called `func` which is apparently a *callable.* Callables
    are essentially just functions, and `func` is meant to be a function that accepts
    a Pandas dataframe object and calculates the value of the metric.
  prefs: []
  type: TYPE_NORMAL
- en: To truly understand this, let's see how objects of the `Metric` class are defined
    in our configuration file, `metric_config.py`, shown in listing 6.7.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.7 metric_config.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Turn your attention to the variable `metrics`, a dictionary with the names of
    each of our metrics as keys, and their corresponding `Metric` objects as values.
    Again, this is reminiscent of `unit_config.py` from Chapter 3, where we did essentially
    the same thing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s inspect the first item in the dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the "total sales" metric, which has a sensible display label as its
    `title`, and "dollars" as its `type`. `func` here is a lambda (which, you might
    remember from Chapter 2, is an anonymous one-line function). It accepts a single
    argument—`df`, a Pandas dataframe-~-and calculates total sales using the expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '`df["Sales"]`, as we''ve discussed before, selects just the "Sales" column
    from `df`, and `.sum()` adds up all the values in it to obtain the final value
    of the metric.'
  prefs: []
  type: TYPE_NORMAL
- en: The other metrics defined in the dictionary are fairly similar, and their calculations
    should make sense after the discussion in the previous section. The "Margin %"
    and "ATV" metrics *don't* use a lambda for their funcs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rather, in each of these cases, `func` points to a regular function (`margin_percent`
    and `average_transaction_value`) defined above. Since these metrics are both ratios,
    we need to handle the possibility that the denominator is zero, preventing a division-by-zero
    error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The bottom of our configuration file has the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The variable is meant to hold the metrics we'll actually display in our metric
    bar. This may seem kind of pointless since we're just listing out all of the keys
    in the `metrics` dictionary. However, this might come in handy if we ever decided
    to include more metrics and don't want to display all of them, or want to display
    them in a specific order. We'll see in a bit how `display_metrics` is actually
    used.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.3 Formatting the metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the pieces of information we capture in the `Metric` class is the "type"
    of the metric, used primarily for formatting.
  prefs: []
  type: TYPE_NORMAL
- en: In our configuration file, three of our metrics are of the "dollars" type, while
    Margin % is of the "percent" type.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now define the formatting logic in its own module, `formatting.py` (see
    listing 6.8). For this, we'll be using a third-party library called `humanize`
    (install it the usual way, i.e. by running `pip install humanize`), which provides
    some nice formatting features.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.8 formatting.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The `format_metric` function takes a numeric value and a metric type, and returns
    a formatted display string.
  prefs: []
  type: TYPE_NORMAL
- en: The `humanize` library we just installed comes into play while formatting a
    dollar-type metric. Since Note n' Nib is such a popular retailer, its sales figures
    are in the millions. If the raw revenue number we're tasked with displaying is
    $25,125,367, we'd rather not show the precise value to the CEO. An abbreviated
    version like "$25.1m" will do the trick while reducing cognitive load for the
    user.
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly what the `humanize.metric` method does. Given a raw number,
    it will return a rounded number with a sensible lower precision and a suffix ("k"
    for thousands, "m" for millions, etc). We add the "$" sign manually to get the
    f-string `f'${humanize.metric(value)}'`.
  prefs: []
  type: TYPE_NORMAL
- en: For percent-metrics, we multiply the actual value by 100 to convert it from
    a fraction to a percentage, and round it to a single decimal point before adding
    the "%" sign.
  prefs: []
  type: TYPE_NORMAL
- en: For anything else, we don't do any formatting and just print the value as-is.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.4 Displaying the metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With all the building blocks in place, we can now go ahead and create the metric
    bar in Streamlit. To do this, create yet another Python module, called `metric_bar.py`,
    with the code from listing 6.9
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.9 metric_bar.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The `metric_bar` function iterates through the list of metrics we flagged for
    display (`display_metrics` from `metric_config.p`y), adding an `st.metric` element
    within a display column for each of them.
  prefs: []
  type: TYPE_NORMAL
- en: That's the gist of it, but there are a few interesting bits here.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first is the use of `st.container`, a new Streamlit element. Here we''re
    just using it to put the metric bar within a box with a border:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: There is more to `st.container`, however. One use case for it is when we want
    to display elements "out of order", or in a different order than they are written
    in the code. We'll come across this later in the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `get_metric` function to extract the value of a metric, given a
    dataframe and a Metric object. Since each Metric object already has a `func` member
    that defines how to do this, the body of `get_metric` is as simple as calling
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The last interesting bit is this part:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: You may find this rather strange. We've already defined a column for the metric
    (`metric_cols[idx]`), but it seems like we're splitting that column into three
    *sub*-columns, and then putting the `st.metric` widget in only the second one!
    What's the point of this?
  prefs: []
  type: TYPE_NORMAL
- en: Well, this is actually a layout hack. Unfortunately, as of time of writing,
    Streamlit doesn't offer a great way of horizontally centering items within a column
    without HTML. So instead, here we're creating three columns within the main column,
    with the first and third being equal-width blank ones and the second holding the
    actual content. The overall effect is that the content of the second sub-column
    appears centered within the main column.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that, all we need is a quick update to `dashboard.py` and we should be
    good to move on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: We've removed the sample dataframe rows from the display and replaced it with
    the metric bar. Re-run the dashboard to find the output in figure 6.13.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image013.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.13 Metrics bar showing key metrics in aggregate (see chapter_6/in_progress_7
    in the GitHub repo for the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let's tackle some of the visualization components of the dashboard next.
  prefs: []
  type: TYPE_NORMAL
- en: 6.5 Constructing visualizations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Humans are intuitively visual beings. When you're trying to convey a message
    through data, it's usually more memorable and *clicks* much faster when you use
    a graph rather than a table of numbers. This is especially important for busy
    executives who may have to deal with a breadth of matters and need to develop
    an understanding of the business so they can make decisions quickly.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll add visualizations to our dashboard in the form of a
    line chart to show how the metrics we're tracking have changed over time, and
    a pie chart to show the breakdown of those metrics across a chosen dimension.
    In each case, we'll use Pandas to wrangle the data into a form we can visualize
    easily, whip up the actual images using a library called Plotly, and display them
    using Streamlit.
  prefs: []
  type: TYPE_NORMAL
- en: 6.5.1 Creating a time series chart
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A time series is simply a sequence of data points recorded at regular time intervals,
    showing how a particular metric or variable changes over time. This is crucial
    for spotting trends, seasonality, and outliers, which can inform decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: You can think of a simple time series as a series of data with two variables—one
    representing a date or time, and another representing the measure we're tracking.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, this is a time series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Obtaining a time series from our dataframe
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Recall that the data we're dealing with have many different fields—date, product
    name, gender, sales, and so on. We're going to have to transform it into the specific
    shape of a time series before we can pass it to the visualization we'll build.
  prefs: []
  type: TYPE_NORMAL
- en: We have a "Day" field in our data, but one particular row in our dataframe represents
    the value for a particular combination of gender, age group, product name, etc.
    What we need is something that, given any particular slice of our full dataframe
    (which is what our filters give us), *aggregates* the data up to the "Day" level.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a user may have applied the filters "State = CA" giving us the
    following slice of data (simplified for clarity, excluding the other fields):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Our time series should contain only "Day" and "Total sales", so we need to
    add up the sales for each date across state, gender and product:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'To do this in Pandas, assuming our dataframe is called `df`, we could write
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s break this down. `df.groupby(''Day'')` would give us a grouped dataframe,
    which you can imagine as being represented internally like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, consider the line `grouped.apply(lambda df: df[''Sales''].sum(), include_groups=False)`'
  prefs: []
  type: TYPE_NORMAL
- en: The apply method is an extremely powerful Pandas construct that lets you apply
    a function to each row or column of a dataframe or to the values of a series.
    When used on a grouped dataframe like the one above, it allows you to perform
    operations on each group separately.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the lambda function `lambda df: df[''Sales''].sum()` takes each
    group (which corresponds to a specific day) and calculates the total sales for
    that day by summing the `Sales` values. In the example above, the day 2024-08-01
    would have a total `Sales` value of 2800, adding up the sales for the RoyalQuill
    and GripLink rows.'
  prefs: []
  type: TYPE_NORMAL
- en: The `include_groups = False` bit indicates that we don't want the function to
    also operate on group labels (the `Day` values). It's kind of redundant here as
    our lambda function specifically refers to the `"Sales"` column, but if you don't
    include this, Pandas will whine about it.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `reset_index()` method converts the results back to a standard
    DataFrame format. An *index* is a Pandas concept referring to a unique identifier
    column for each row, enabling efficient data retrieval and alignment; after summing,
    the `Day` column becomes the index. By calling reset_index(), we restore `Day`
    as a regular column and create a new index that ranges from 0 to n-1, where n
    is the number of unique days.
  prefs: []
  type: TYPE_NORMAL
- en: We need a slightly more generalized version of the above code for our dashboard,
    as our line chart may need to show any of our four key metrics, not just sales
    (see figure 6.14 from our UI mock).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image014.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.14 The time series chart from our UI mock
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: So rather than passing in `df["Sales"].sum()` as the function to apply, we'll
    obtain this function from the `func` attribute of the `Metric` class we defined
    in `metric.py` and instantiated in `metric_config.py`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Our function accepts a dataframe `df` and `metric`, one of the `Metric` objects
    from `metric_config.py`. As you can see, we pass `metric.func` to `grouped.apply`
    to make it general.
  prefs: []
  type: TYPE_NORMAL
- en: The line `data.columns = ['Day', 'Value']` resets the column names of the resultant
    dataframe to new ones.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our time series, let's build our line chart.
  prefs: []
  type: TYPE_NORMAL
- en: Using Plotly to build a line chart with our time series
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As we touched upon briefly in Chapter 1, Streamlit supports many different data
    visualization libraries. Plotly is one such library that tends to be fairly easy
    to use and offers a range of engaging interactive visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: To use it, you first need to install it with `pip install plotly.`
  prefs: []
  type: TYPE_NORMAL
- en: The flavor of Plotly we'll use is called Plotly Graph Objects (GO for short).
    GO allows you to construct plots with a high degree of control and customization,
    making it ideal for interactive charts where you can define every detail.
  prefs: []
  type: TYPE_NORMAL
- en: Create a new Python module named `time_series_chart.py` with the code in listing
    6.10.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.10 time_series_chart.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The import statement at the top makes Plotly Graph Objects available; the abbreviation
    `go` is conventionally used to refer to it.
  prefs: []
  type: TYPE_NORMAL
- en: The `get_time_series_chart` metric takes our dataframe as well as an object
    of type `Metric` and returns the line chart (a Plotly `Figure` object) that we
    can pass later to a Streamlit widget for display.
  prefs: []
  type: TYPE_NORMAL
- en: We first obtain our time series data by calling the `get_metric_time_series`
    function we defined earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Plotly charts are constructed incrementally. We start with an empty chart and
    add the components we need bit-by-bit. Here, the line `fig = go.Figure()` initializes
    the chart and assigns it to `fig`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next part adds the actual line to the chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: We're creating a `go.Scatter` object here, which represents a scatterplot. A
    scatterplot simply plots points on a graph with two axes (the x-axis and the y-axis).
    Each point has a pair of coordinates. In this case, the x-coordinates are supplied
    by `data['Day']`, or the dates we want to show in the chart, and the y-coordinates
    are in `data['Value']`, which will be the values of one of our key metrics (depending
    on which one the variable `metric` contains).
  prefs: []
  type: TYPE_NORMAL
- en: We also pass `mode='lines+markers'`, which makes it so that in addition to plotting
    the points (using "markers"), Plotly also puts lines between them. The effect
    is that every (`Day`, `Value`) pair in our dataframe has a marker, and all the
    markers are connected by lines, forming the line chart we need.
  prefs: []
  type: TYPE_NORMAL
- en: We then add the plot we just created to our `Figure` object by passing it to
    `fig.add_trace()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The last part, shown above, simply adds some text to our graph, such as a title
    (which we get from our `Metric` object's `title` attribute, defined in `metric_config.py`),
    and the titles of the x- and y-axes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now know how to create the chart we require. We still need to actually display
    it though, so go ahead and update `time_series_chart.py`, adding a `time_series_chart`
    function at the bottom and the corresponding imports at the top:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Once again, we use `st.container(border=True)` to make a box to put our line
    chart in.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next bit, `chart_tabs = st.tabs(display_metrics)`, introduces a new Streamlit
    UI widget: `st.tabs`.'
  prefs: []
  type: TYPE_NORMAL
- en: As the name suggests, `st.tabs` creates a tabbed area in your app that lets
    users switch between pieces of content by clicking tabs at the top. The argument
    to `st.tabs` is the list of tab titles to use.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, `st.tabs(["Home", "About us", "Careers"])` would create three
    tabs with the titles "Home", "About us", and "Careers".
  prefs: []
  type: TYPE_NORMAL
- en: We're trying to create one tab for each metric with its respective line chart,
    so we can pass the variable `display_metrics` from `metric_config.py`—which, you
    may recall, is a list of the metrics we care about that we can use as tab titles.
  prefs: []
  type: TYPE_NORMAL
- en: 'We define the content within a tab in the same way that we would do it for
    `st.column`: using the with context manager. Since `chart_tabs` now contains the
    list of tabs (returned by `st.tabs`), we can iterate through each list index/metric
    name pair (`idx, met`) in `display_metrics` and use `chart_tabs[idx]` to refer
    to the corresponding tab, calling `get_time_series_chart` to create the Plotly
    line chart for that metric.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we pass the created chart to the `st.plotly_chart` element to render
    it on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The `use_container_width=True` ensures that the line chart expands to fill the
    width of the box that contains it. This prevents weird layout issues where the
    chart ends up being larger than the container or leaves a lot of whitespace around
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now include the line chart in our main app by updating `dashboard.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: If you save and re-run the app now, you'll see your first Streamlit visualization
    (see figure 6.15)
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image015.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.15 Time series chart created using Plotly (chapter_6/in_progress_8
    in the GitHub repo has the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Pretty, ce n'est pas? You can see the tabs and switch between them to see how
    each metric has changed over the given data range. Visualizations created using
    `st.plotly_chart` throw in a lot of useful functionality for free, such as the
    ability to zoom in to specific points in the chart, tooltips when you hover over
    specific data points, a full-screen mode, and a download button to save the image.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We could have used radio buttons as our metric selection widget as our UI mock
    indicates, but I didn''t want to pass up the chance to introduce st.tabs. Also,
    there is one important difference in how selection via st.radio and that via st.tabs
    works: switching between tabs does not trigger an app rerun while changing between
    radio button options does. This makes using tabs faster and more efficient with
    the tradeoff that charts for all the metrics need to be created at once, during
    the initial load.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.5.2 Creating a pie chart
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The time series chart we just created lets us identify trends over time, but
    we also need to be able to break a particular data point down and see what contributes
    to it. For instance, if we know that the total sales for the "Fountain pens" segment
    are $500k, it would be helpful to know that 70% of that was driven by the RoyalQuill
    brand, while Inkstream only accounted for 30%, or that 45% of stapler sales are
    from the 56+ age group.
  prefs: []
  type: TYPE_NORMAL
- en: Pie charts, which illustrate the percentage breakdown of a whole into its component
    parts, are a good way to instantly form a picture of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.16 shows the pie chart from our UI mock again.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image016.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.16 The pie chart from our UI mock
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'There are two selections you can make here: a metric for the pie chart to display,
    and a breakdown dimension. The metric can only be "Total sales" or "Gross margin",
    not "Margin %" or ATV. This is because the latter two metrics are ratios, and
    the corresponding dimension-wise ratios won''t add up to 100%—so a pie chart does
    not apply.'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, let's say the average transaction value (sales divided by transaction
    count) for fountain pens is $50\. We can't break this down by gender and say that
    60% ($30) of that comes from males and 40% ($20) comes from females. To get the
    ATV for males, we have to calculate the ratio by dividing total sales for males
    by the corresponding transaction count.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s record this smaller list of pie-chart-applicable metrics in a new variable
    at the bottom of metric_config.py:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Getting data into the right shape
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Just as we wrangled our data into a date/value time series to feed it to the
    time series chart, we need to prepare our data for the pie chart too. The pie
    chart needs to know the value of our metric corresponding to each dimension value;
    it will do the conversion to percentages on its own.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider the earlier sample data we processed into a time series
    earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to show a breakdown of the total sales by product, you would group
    by product and add up the sales:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: This is remarkably similar to what we did earlier; the only difference is that
    instead of grouping by the date field, we're grouping by a particular dimension
    ("Product") instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function we''ll include at the bottom of `data_wrangling.py` is thus also
    very similar to `get_metric_time_series`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: The sole distinction between the newly added `get_metric_grouped_by_dimension`
    and `get_metric_time_series` is that in the former, we're accepting dimension
    as an input and grouping by that instead of `Day`.
  prefs: []
  type: TYPE_NORMAL
- en: A Plotly pie chart
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The ever-versatile Plotly Graph Objects can also be used to create the pie
    chart we want. In fact, the code you''ll put in `pie_chart.py` (a new file shown
    in listing 6.11), is closely related to that in `time_series_chart.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.11 pie_chart.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The differences should be fairly obvious: we use `get_metric_grouped_by_dimension`
    in the place of `get_metric_time_series`, and `go.Pie` instead of `go.Scatter`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`go.Pie` accepts `labels`, which will be displayed in a color legend, `values`,
    and `hole`, which indicates how large the "donut hole" in the pie chart should
    be.'
  prefs: []
  type: TYPE_NORMAL
- en: We're not using `fig.update_layout()` here to set any text in the chart, since
    the title will simply be the tab header (which we'll get to in a second), and
    there are no x- or y-axes.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we did previously, we also need to write another function in `pie_chart.py`
    to render the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: The `pie_chart` function, too, is similar to its counterpart—`time_series_chart`—from
    `time_series.chart.py`.
  prefs: []
  type: TYPE_NORMAL
- en: The key difference is the added `split_dimension` variable (the dimension to
    break down the metric for) that we need to collect from users using `st.selectbox`.
  prefs: []
  type: TYPE_NORMAL
- en: Everything else stays more or less analogous; we create a tab for each metric
    in `pie_chart_display_metrics` (that we defined in `metric_config.py`), iterate
    through those metrics, create the Plotly object with `get_pie_chart`, and display
    it using `st.plotly_chart`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `dashboard.py`, we want to display the line and pie charts side-by-side,
    so we use `st.columns`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: With this, our dashboard's UI is complete! Re-run to see figure 6.17.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/06__image017.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.17 Our completed app, with the newly-added pie chart at the bottom
    right (chapter_6/in_progress_9 in the GitHub repo has the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We've covered a lot of ground in this chapter, and we're ready to launch our
    dashboard. We're not quite done with Note n' Nib though. In the next chapter,
    we'll see several ways in which our app can be improved-~-including usability
    tweaks and shifting from a static CSV file to a data warehouse.
  prefs: []
  type: TYPE_NORMAL
- en: 6.6 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A metrics dashboard is an essential decision-making tool for executives.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas is a popular Python library for manipulating tabular data in dataframes.
    Streamlit can display Pandas dataframes natively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Pandas' `read_csv` function to load data from a comma-separated values (CSV)
    file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `st.cache_data` decorator can be used to cache the results of functions
    to improve performance. Its `ttl` parameter sets the time period for which a cached
    result is valid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dataframe square bracket notation is quite versatile in Pandas; you can
    use them to select columns, filter rows, and more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`st.container` can be used to hold other Streamlit widgets, displaying them
    out of order or with a border around them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`st.multiselect` creates a dropdown menu where you can select multiple options.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`st.set_page_config` can set app configurations in Streamlit, including switching
    from a centered layout to a maximized one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`st.date_input` can be used to display date selectors in your app.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `humanize` library is useful for formatting numbers in a user-friendly way.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A time series is a sequence of data points, each with a date and a value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `groupby` method on Pandas dataframes can aggregate data across dimensions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plotly Graph Objects (abbreviated to `go`) is a Python library used to create
    visualizations that can be displayed directly by Streamlit.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`go.Scatter` can be used to create scatterplots and line charts, while `go.Pie`
    can make pie charts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A data warehouse is a specialized system designed to store and retrieve large
    amounts of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google BigQuery—part of GCP—is an example of a data warehouse. To enable an
    app to connect to it, you need to create a service account with a key, and record
    the credentials in `st.secrets`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
