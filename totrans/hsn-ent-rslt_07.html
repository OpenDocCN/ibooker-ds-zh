<html><head></head><body><section data-pdf-bookmark="Chapter 7. Clustering" data-type="chapter" epub:type="chapter"><div class="chapter" id="chapter_7">&#13;
<h1><span class="label">Chapter 7. </span>Clustering</h1>&#13;
&#13;
<p>So far, we have considered the resolution of entities between two independent data sources: a smaller primary dataset that defines a target population to be matched and a much larger secondary dataset. We have also assumed that the entities in the primary dataset are present only once and there are no duplicates. Therefore, we have not sought to compare the entities in the primary dataset with each other.</p>&#13;
&#13;
<p>For example, in <a data-type="xref" href="ch05.html#chapter_5">Chapter 5</a>, we resolved UK MPs, as listed in Wikipedia, against PSCs of UK companies according to Companies House. We assumed that each MP would be present only once in the Wikipedia list but that they could have significant control over more than one company, i.e., a single Wikipedia entity could match against multiple PSC entities. For instance, the MP named in Wikipedia as Geoffrey Clifton-Brown is likely to be the same individual as the person with the same name listed as having significant control over the company with reference number 09199367. The same applies to the companies with references 02303726 and 13420433.</p>&#13;
&#13;
<p>We<a contenteditable="false" data-primary="entity relationships, representing" data-type="indexterm" id="id508"/> can represent these entity relationships as a simple network with the similarly named individuals represented as<a contenteditable="false" data-primary="nodes" data-type="indexterm" id="id509"/> <em>nodes</em> and the three<a contenteditable="false" data-primary="pairwise comparisons" data-type="indexterm" id="paircomp07"/> pairwise comparisons between them represented as<a contenteditable="false" data-primary="edges" data-type="indexterm" id="id510"/> <em>edges</em>, as shown in <a data-type="xref" href="#fig-7-1">Figure 7-1</a>.</p>&#13;
&#13;
<p>Note that we didn’t evaluate the pairwise equivalence of the three named individuals in the PSC data with each other—we were seeking only to identify links to the primary Wikipedia entity. But in the process we have, by association, concluded that all three PSC entries are likely to refer to the same single real-world individual.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-1"><img alt="" class="iimagesch07ch07chapter5examplepng" src="assets/hoer_0701.png"/>&#13;
<h6><span class="label">Figure 7-1. </span>Simple person match cluster</h6>&#13;
</div></figure>&#13;
&#13;
<p>In practice we are often faced with multiple data sources to resolve, as well as potential duplication within a single source. To produce a resolved view of an entity, we need to gather together all the pair-matched records, grouping them under a single uniquely identifiable reference.</p>&#13;
&#13;
<p>This process of assembling a collection of examples is called<a contenteditable="false" data-primary="clustering" data-secondary="definition of term" data-type="indexterm" id="id511"/> <em>clustering</em>. The clustering process doesn’t attempt to determine which example (if any) is correct but simply to identify the collection as a discrete bounded set whose members all have similar characteristics.</p>&#13;
&#13;
<p>In this chapter, we will examine how to employ basic clustering techniques to group entities together based on pairwise comparisons. We will reuse the PSC dataset we acquired in <a data-type="xref" href="ch05.html#chapter_5">Chapter 5</a>, but first, let’s shrink the problem to a small scale so that we can understand the steps we need to take.<a contenteditable="false" data-primary="" data-startref="paircomp07" data-type="indexterm" id="id512"/></p>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Simple Exact Match Clustering" data-type="sect1"><div class="sect1" id="id59">&#13;
<h1 class="less_space">Simple Exact Match Clustering</h1>&#13;
&#13;
<p>First, let’s<a contenteditable="false" data-primary="clustering" data-secondary="simple exact match clustering" data-type="indexterm" id="id513"/><a contenteditable="false" data-primary="exact match clustering" data-type="indexterm" id="id514"/><a contenteditable="false" data-primary="simple exact match clustering" data-type="indexterm" id="id515"/><a contenteditable="false" data-primary="match clustering" data-type="indexterm" id="matchclus07"/> consider a simple dataset of first names, last names, and year of birth, as shown in <a data-type="xref" href="#table-7-1">Table 7-1</a>. This table contains an exact duplicate (IDs 0 and 1) along with several other similar records.</p>&#13;
&#13;
<table id="table-7-1">&#13;
	<caption><span class="label">Table 7-1. </span>Simple clustering example dataset</caption>&#13;
	<thead>&#13;
		<tr>&#13;
			<th scope="col"><strong>ID</strong></th>&#13;
			<th scope="col"><strong>First name</strong></th>&#13;
			<th scope="col"><strong>Last name</strong></th>&#13;
			<th scope="col"><strong>Year of birth</strong></th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>0</td>&#13;
			<td>Michael</td>&#13;
			<td>Shearer</td>&#13;
			<td>1970</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>1</td>&#13;
			<td>Michael</td>&#13;
			<td>Shearer</td>&#13;
			<td>1970</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>2</td>&#13;
			<td>Mike</td>&#13;
			<td>Shearer</td>&#13;
			<td>1970</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>3</td>&#13;
			<td>Michael</td>&#13;
			<td>Shearer</td>&#13;
			<td>1971</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>4</td>&#13;
			<td>Michelle</td>&#13;
			<td>Shearer</td>&#13;
			<td>1971</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>5</td>&#13;
			<td>Mike</td>&#13;
			<td>Sheare</td>&#13;
			<td>1971</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>Does each ID represent a separate entity or do they refer to the same person?</p>&#13;
&#13;
<p>Based on the limited information we have, we can, for example, group by exact equivalence of first name and last name but not year of birth.</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
table = [&#13;
    [0,'Michael','Shearer',1970],&#13;
    [1,'Michael','Shearer',1970],&#13;
    [2,'Mike','Shearer',1970],&#13;
    [3,'Michael','Shearer',1971],&#13;
    [4,'Michelle','Shearer',1971],&#13;
    [5,'Mike','Sheare',1971]]&#13;
&#13;
clmns = ['ID','Firstname','Lastname','Year']&#13;
df_ms = pd.DataFrame(table, columns = clmns)&#13;
&#13;
df_ms['cluster'] =&#13;
   df_ms.groupby(['Firstname','Lastname']).ngroup()</pre>&#13;
&#13;
<p>This gives us four clusters. The entities associated with IDs 0, 1, and 3 are grouped together in cluster 0 as they have the exact same name spellings, whereas IDs 2, 4, and 5 have a unique spelling variation and are therefore assigned their own individual cluster, as we can see in <a data-type="xref" href="#fig-7-2">Figure 7-2</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-2"><img class="iimagesch07ch07simpletablepng" src="assets/hoer_0702.png"/>&#13;
<h6><span class="label">Figure 7-2. </span>Simple exact match cluster table</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Approximate Match Clustering" data-type="sect1"><div class="sect1" id="id60">&#13;
<h1>Approximate Match Clustering</h1>&#13;
&#13;
<p>Now<a contenteditable="false" data-primary="clustering" data-secondary="approximate match clustering" data-type="indexterm" id="Capprox07"/><a contenteditable="false" data-primary="approximate match clustering" data-type="indexterm" id="appmclust07"/> let’s consider what happens to our cluster groupings if we include approximate name matching, as introduced in <a data-type="xref" href="ch03.html#chapter_3">Chapter 3</a>. We can no longer use a simple <code>groupby</code> function to calculate our clusters, so we need to work through the comparison steps ourselves. This is a helpful exercise to illustrate the combined challenge that comes with comparing records within, and across, large datasets.</p>&#13;
&#13;
<p>Our first step is to generate a table with all the potential combinations of record comparisons. We want to compare the record ID 0 with each of the other records and then the record ID 1 with the remainder, but without duplicating the comparison with ID 0 again (directionality isn’t important in<a contenteditable="false" data-primary="pairwise comparisons" data-type="indexterm" id="id516"/> pairwise comparisons). In total we have 15 comparisons: 5 for ID 0 against its peers, 4 for ID 1, and so on.</p>&#13;
&#13;
<p>From our simple base table we can use the itertools package we introduced in <a data-type="xref" href="ch03.html#chapter_3">Chapter 3</a> to generate a DataFrame with composite columns A and B, each containing a list of the attributes to be compared drawn from our simple table:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
import itertools&#13;
&#13;
df_combs = pd.DataFrame(list(itertools.combinations(table,2)),&#13;
   columns=['A','B'])</pre>&#13;
&#13;
<p><a data-type="xref" href="#fig-7-3">Figure 7-3</a> shows the first few rows of the DataFrame.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-3"><img alt="" class="iimagesch07ch07approxcombspng" src="assets/hoer_0703.png"/>&#13;
<h6><span class="label">Figure 7-3. </span>Sample rows of composite match combinations</h6>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before">Next, we need to create the multilevel index columns to hold the individual attribute values under the A and B headings:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
clmnsA = pd.MultiIndex.from_arrays([['A']*len(clmns), clmns])&#13;
clmnsB = pd.MultiIndex.from_arrays([['B']*len(clmns), clmns])</pre>&#13;
&#13;
<p>Now we can split out the attributes and recombine the resulting columns, with their associated index labels, back to a single DataFrame:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
df_edges = pd.concat(&#13;
   [pd.DataFrame(df_combs['A'].values.tolist(),columns = clmnsA),&#13;
    pd.DataFrame(df_combs['B'].values.tolist(),columns = clmnsB)],&#13;
   axis=1)</pre>&#13;
&#13;
<p>The first few expanded rows are shown in <a data-type="xref" href="#fig-7-4">Figure 7-4</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-4"><img alt="" class="iimagesch07ch07approxtablepng" src="assets/hoer_0704.png"/>&#13;
<h6><span class="label">Figure 7-4. </span>Sample rows of approximate match combinations</h6>&#13;
</div></figure>&#13;
&#13;
<p>Now that we have our attributes prepared for<a contenteditable="false" data-primary="pairwise comparisons" data-type="indexterm" id="pairwisecomp07"/> pairwise evaluation, we can use the Jaro-Winkler similarity function<a contenteditable="false" data-primary="Jaro-Winkler similarity" data-type="indexterm" id="id517"/> introduced in <a data-type="xref" href="ch03.html#chapter_3">Chapter 3</a> to approximately compare the first names and last names between the A and B values. If both match, say with an equivalence score greater than 0.9, then we declare an overall match:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
import jellyfish as jf&#13;
&#13;
def is_match(row):&#13;
   firstname_match = jf.jaro_winkler_similarity(row['A'] &#13;
      ['Firstname'],row['B']['Firstname']) &gt; 0.9&#13;
   lastname_match = jf.jaro_winkler_similarity(row['A']&#13;
      ['Lastname'], row['B']['Lastname']) &gt; 0.9&#13;
   return firstname_match and lastname_match&#13;
&#13;
df_edges['Match'] = df_edges.apply(is_match, axis=1)&#13;
&#13;
df_edges</pre>&#13;
&#13;
<p>The resulting matches are listed in <a data-type="xref" href="#fig-7-5">Figure 7-5</a>. We can see that record ID 0 matches exactly with ID 1 and ID 3 on rows 0 and 2, respectively. A match is also declared on row 3 between ID 0 and ID 4 as there is sufficient similarity between “Michael” and “Michelle.” Note that rows 6, 7, and 12 also record direct matches between the remaining combinations of IDs 1, 3, and 4 independent of ID 0.</p>&#13;
&#13;
<p class="pagebreak-before">ID 2 also matches to ID 5 on row 11 with “Shearer” and “Sheare” being sufficiently similar.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-5"><img alt="" class="iimagesch07ch07approxmatchpng" src="assets/hoer_0705.png"/>&#13;
<h6><span class="label">Figure 7-5. </span>Approximate match table</h6>&#13;
</div></figure>&#13;
&#13;
<p>From these results we can manually identify two clusters, the first comprising IDs 0, 1, 3, and 4 and the second IDs 2 and 5.</p>&#13;
&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id518">&#13;
<h1>NetworkX</h1>&#13;
&#13;
<p>NetworkX<a contenteditable="false" data-primary="NetworkX" data-type="indexterm" id="id519"/><a contenteditable="false" data-primary="Python" data-secondary="NetworkX package" data-type="indexterm" id="id520"/><a contenteditable="false" data-primary="complex networks, studying" data-type="indexterm" id="id521"/> is an open source Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.</p>&#13;
&#13;
<p>We can use NetworkX to calculate our clusters. For this simple example, we map the entity IDs as the nodes of a network graph and the binary pairwise comparisons as the edges. From this graph object, we can use the connected components algorithm to derive the resulting clusters:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
import networkx as nx&#13;
G = nx.from_pandas_edgelist(df_edges[df_edges['Match']],&#13;
   source=('A','ID'), target=('B','ID'))&#13;
list(nx.connected_components(G))&#13;
&#13;
[{0, 1, 3, 4}, {2, 5}]</pre>&#13;
</div></aside>&#13;
&#13;
<p class="pagebreak-before">However, we are now faced with a problem. We have allowed nonexact matches to cluster as a single entity. What attribute values should we now use to describe that resolved entity? For the first cluster, comprising IDs 0, 1, 3, and 4, should the first name be “Michael” or “Michelle”? IDs 0, 1, and 3 have the first name as “Michael” but ID 4 has it listed as “Michelle.” Is the correct year of birth 1970 or 1971?</p>&#13;
&#13;
<p>For the second cluster, we face the same year of birth dilemma and the question of whether we should use “Sheare” or “Shearer”—it’s not clear. This challenge, of selecting the most representative values, sometimes known as<a contenteditable="false" data-primary="canonicalization" data-type="indexterm" id="id522"/> <em>canonicalization</em>, is a field of active study but beyond the scope of this book.</p>&#13;
&#13;
<p>Even with this simple example we can see a number of challenges and trade-offs we need to consider when clustering entities together. First, the number of pairwise comparisons grows very rapidly with number of records to be clustered. For a table of n rows there are n × (n–1)/2 combinations. If approximate matches are included, the resulting computational burden is significant and may be time-consuming to compute. Second, and most challenging, is how to settle on a single set of attributes to define a cluster when individual entities within the cluster have differing attribute values.</p>&#13;
&#13;
<p>Now that we have introduced some of the challenges associated with clustering, let’s return to the PSC dataset to consider a larger-scale example.<a contenteditable="false" data-primary="" data-startref="matchclus07" data-type="indexterm" id="id523"/><a contenteditable="false" data-primary="" data-startref="appmclust07" data-type="indexterm" id="id524"/><a contenteditable="false" data-primary="" data-startref="Capprox07" data-type="indexterm" id="id525"/><a contenteditable="false" data-primary="" data-startref="pairwisecomp07" data-type="indexterm" id="id526"/></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Sample Problem" data-type="sect1"><div class="sect1" id="id254">&#13;
<h1>Sample Problem</h1>&#13;
&#13;
<p>Returning to our example from <a data-type="xref" href="ch05.html#chapter_5">Chapter 5</a>, let’s imagine we wish to examine the concentration of control over UK companies, identifying individuals with influence over several companies. To do this, we need to cluster all the matching individual owner entities in the PSC dataset. Further, knowing the variable data quality of PSC entries, let’s consider that we want to incorporate approximate matches in our calculations.</p>&#13;
&#13;
<p>With approximately 11.5 million entries in our PSC dataset, the total number of comparisons we need to make is over 66 trillion. We have our work cut out here!</p>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Data Acquisition" data-type="sect2"><div class="sect2" id="id127">&#13;
<h2 class="less_space">Data Acquisition</h2>&#13;
&#13;
<p>Let’s<a contenteditable="false" data-primary="data, acquiring" data-secondary="for clustering problem" data-secondary-sortas="clustering problem" data-type="indexterm" id="id527"/> start by picking up the raw data we downloaded in <a data-type="xref" href="ch05.html#chapter_5">Chapter 5</a>. We’ll use a wider range of attributes for matching in this chapter:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
df_psc = pd.read_csv('psc_raw.csv',dtype=&#13;
   {'data.name_elements.surname':'string',&#13;
    'data.name_elements.forename':'string',&#13;
    'data.name_elements.middle_name':'string',&#13;
    'data.name_elements.title':'string',&#13;
    'data.nationality':'string'})</pre>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Data Standardization" data-type="sect2"><div class="sect2" id="id128">&#13;
<h2>Data Standardization</h2>&#13;
&#13;
<p>Now<a contenteditable="false" data-primary="data standardization" data-secondary="for clustering problem" data-secondary-sortas="clustering problem" data-type="indexterm" id="id528"/> that we have our raw data, our next step is to standardize and, for simplicity, rename the attributes. We also drop any records where the year or month of birth is missing because we’ll use these as blocking values to help reduce the number of comparisons we need to make:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
df_psc = df_psc.dropna(subset&#13;
   ['data.date_of_birth.year','data.date_of_birth.month'])&#13;
df_psc['Year'] = df_psc['data.date_of_birth.year'].astype('int64')&#13;
df_psc['Month'] =&#13;
   df_psc['data.date_of_birth.month'].astype('int64')&#13;
&#13;
df_psc = df_psc.rename(columns=&#13;
   {"data.name_elements.surname" : "Lastname",&#13;
    "data.name_elements.forename" : "Firstname",&#13;
    "data.name_elements.middle_name" : "Middlename",&#13;
    "data.name_elements.title" : "Title",&#13;
    "data.nationality" : "Nationality"})&#13;
&#13;
df_psc = df_psc[['Lastname','Middlename','Firstname',&#13;
   'company_number','Year','Month','Title','Nationality']]&#13;
df_psc['unique_id'] = df_psc.index</pre>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Record Blocking and Attribute Comparison" data-type="sect1"><div class="sect1" id="id129">&#13;
<h1>Record Blocking and Attribute Comparison</h1>&#13;
&#13;
<p>As<a contenteditable="false" data-primary="clustering" data-secondary="record blocking and attribute comparison" data-type="indexterm" id="Crecord07"/><a contenteditable="false" data-primary="record blocking" data-secondary="for clustering" data-secondary-sortas="clustering" data-type="indexterm" id="RBcluster07"/><a contenteditable="false" data-primary="attribute comparison" data-secondary="for clustering" data-secondary-sortas="clustering" data-type="indexterm" id="ACcluster07"/> before, we use the Splink framework to perform the comparisons, with exact equivalence on year, month, and last name as prediction blocking rules, i.e., we only compare records against each other if there are exact matches between the year, month, and last name fields. Clearly, this is a trade-off as we will potentially miss some matches with last name inconsistencies or spelling mistakes, for example.</p>&#13;
&#13;
<p>Note that for this single source example we set the <code>link_type</code> to <code>dedupe_only</code> instead of <code>link_only</code>. Splink supports <code>dedupe_only</code>, <code>link_only</code>, and <code>link_and_dedupe</code>.</p>&#13;
&#13;
<p class="pagebreak-before">We also specify a convergence tolerance for the EM algorithm and set a maximum number of iterations to run (even if convergence has not been reached):</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
from splink.duckdb.linker import DuckDBLinker&#13;
from splink.duckdb import comparison_library as cl&#13;
&#13;
settings = {&#13;
   "link_type": "dedupe_only",&#13;
   "blocking_rules_to_generate_predictions":&#13;
      [ "l.Year = r.Year and l.Month = r.Month and&#13;
          l.Lastname = r.Lastname" ],&#13;
   "comparisons":&#13;
      [ cl.jaro_winkler_at_thresholds("Firstname", [0.9]),&#13;
        cl.jaro_winkler_at_thresholds("Middlename", [0.9]),&#13;
        cl.exact_match("Lastname"),&#13;
        cl.exact_match("Title"),&#13;
        cl.exact_match("Nationality"),&#13;
        cl.exact_match("Month"),&#13;
        cl.exact_match("Year", term_frequency_adjustments=True), ],&#13;
   "retain_matching_columns": True,&#13;
   "retain_intermediate_calculation_columns": True,&#13;
   "max_iterations": 10,&#13;
   "em_convergence": 0.01,&#13;
   "additional_columns_to_retain": ["company_number"],&#13;
   }&#13;
linker = DuckDBLinker(df_psc, settings)</pre>&#13;
&#13;
<section data-pdf-bookmark="Data Analysis" data-type="sect2"><div class="sect2" id="id255">&#13;
<h2>Data Analysis</h2>&#13;
&#13;
<p>As before, it’s useful to have a look at the data distribution of our comparison attributes:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
linker.profile_columns(["Firstname","Middlename","Lastname",&#13;
   "Title","Nationality","Month","Year"], top_n=10, bottom_n=5)</pre>&#13;
&#13;
<p>As we can see in <a data-type="xref" href="#fig-7-6">Figure 7-6</a>, we have the expected distribution of first, middle, and last names. In <a data-type="xref" href="#fig-7-7">Figure 7-7</a>, we can also see that the distribution of title and nationality is skewed toward a small number of common values. <a data-type="xref" href="#fig-7-8">Figure 7-8</a> shows month of birth is fairly evenly distributed across the year, whereas year of birth is somewhat skewed toward the 1980s.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-6"><img class="iimagesch07ch07columns1png" src="assets/hoer_0706.png"/>&#13;
<h6><span class="label">Figure 7-6. </span>First name, middle name, and last name distribution</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="fig-7-7"><img class="iimagesch07ch07columns2png" src="assets/hoer_0707.png"/>&#13;
<h6><span class="label">Figure 7-7. </span>Title and nationality distribution</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="fig-7-8"><img class="iimagesch07ch07columns3png" src="assets/hoer_0708.png"/>&#13;
<h6><span class="label">Figure 7-8. </span>Year and month of birth distribution</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Expectation-Maximization Blocking Rules" data-type="sect2"><div class="sect2" id="id61">&#13;
<h2>Expectation-Maximization Blocking Rules</h2>&#13;
&#13;
<p>Given<a contenteditable="false" data-primary="EM (expectation-maximization) model" data-secondary="blocking rules" data-type="indexterm" id="id529"/><a contenteditable="false" data-primary="blocking rules" data-secondary="expectation-maximization" data-type="indexterm" id="id530"/> the very high number of potential combinations, we need to specify the  blocking rules for the EM algorithm as tightly as we can to allow the process to complete in a reasonable timeframe.</p>&#13;
&#13;
<p>We can test the volume of comparisons that a given blocking rule will generate using the <code>count_num_comparisons_from_blocking</code> function; for example:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
linker.count_num_comparisons_from_blocking_rule(&#13;
   "l.Lastname = r.Lastname and&#13;
    l.Month = r.Month and&#13;
    l.Title = r.Title and&#13;
    l.Nationality = r.Nationality")</pre>&#13;
&#13;
<p>Remember that every attribute comparison level must pass the blocking rules (i.e., not be blocked) in at least one of the estimate parameter steps so that <em>m</em> and <em>u</em> values can be generated for that attribute.</p>&#13;
&#13;
<p>The count of comparisons that would be generated for several combinations of attribute blocking rules is given in <a data-type="xref" href="#table-7-2">Table 7-2</a>.</p>&#13;
&#13;
<table id="table-7-2">&#13;
	<caption><span class="label">Table 7-2. </span>Blocking rule comparison count</caption>&#13;
	<thead>&#13;
		<tr>&#13;
			<th scope="col">Pair</th>&#13;
			<th scope="col">Attribute combination blocking rule</th>&#13;
			<th scope="col">Count of comparisons</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td colspan="1" rowspan="2">1</td>&#13;
			<td><code>l.Lastname = r.Lastname and</code> <br/>&#13;
		<code>l.Month = r.Month and</code> <br/>&#13;
		<code>l.Title = r.Title and</code> <br/>&#13;
			<code>l.Nationality = r.Nationality</code></td>&#13;
			<td>777.4M</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><span class="keep-together"><code>l.Firstname = r.Firstname and</code> </span><br/>&#13;
			<code>l.Year = r.Year and</code> <br/>&#13;
			<code>l.Middlename = r.Middlename</code></td>&#13;
			<td>69.7M</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td colspan="1" rowspan="2">2</td>&#13;
			<td><code>l.Lastname = r.Lastname and</code> <br/>&#13;
			<code>l.Middlename = r.Middlename</code></td>&#13;
			<td>119.9M</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><span class="keep-together"><code>l.Firstname = r.Firstname and</code> </span><br/>&#13;
			<code>l.Month = r.Month and</code> <br/>&#13;
			<code>l.Year = r.Year and</code> <br/>&#13;
		<code>l.Title = r.Title and</code> <br/>&#13;
			<code>l.Nationality = r.Nationality</code></td>&#13;
			<td>281M</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>We can see that the first pair of blocking rules requires evaluation of a large number of comparisons, whereas the second pair allows estimation of parameters for all the attributes but with a smaller overall comparison count.</p>&#13;
&#13;
<p>First name, middle name, and last name equivalences are the most discriminating in reducing the comparison volumes, followed by year of birth and to a lesser extent month of birth. Nationality and title are not particularly helpful due to limited cardinality of their values, as we saw in <a data-type="xref" href="#fig-7-6">Figure 7-6</a>.</p>&#13;
&#13;
<p>We can employ these blocking rules as:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
linker.estimate_parameters_using_expectation_maximisation(&#13;
   "l.Lastname = r.Lastname and l.Middlename = r.Middlename",&#13;
      fix_u_probabilities=False)&#13;
&#13;
linker.estimate_parameters_using_expectation_maximisation(&#13;
   "l.Firstname = r.Firstname and l.Month = r.Month and&#13;
    l.Year = r.Year and l.Title = r.Title and&#13;
    l.Nationality = r.Nationality",&#13;
      fix_u_probabilities=False)</pre>&#13;
&#13;
<div data-type="warning" epub:type="warning">&#13;
<h1>Computation Time</h1>&#13;
&#13;
<p>Even with these more optimized blocking rules, the execution of the expectation-maximization algorithm on a large dataset may take some time, especially if you’re running on a modest machine.</p>&#13;
&#13;
<p>Alternatively, if you want to skip the training step you can simply load the pretrained model<a contenteditable="false" data-primary="" data-startref="RBcluster07" data-type="indexterm" id="id531"/><a contenteditable="false" data-primary="" data-startref="Crecord07" data-type="indexterm" id="id532"/><a contenteditable="false" data-primary="" data-startref="ACcluster07" data-type="indexterm" id="id533"/> using:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
linker.load_settings("Chapter7_Splink_Settings.json")</pre>&#13;
</div>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Match Classification and Clustering" data-type="sect1"><div class="sect1" id="id62">&#13;
<h1>Match Classification and Clustering</h1>&#13;
&#13;
<p>Once<a contenteditable="false" data-primary="clustering" data-secondary="match classification and" data-type="indexterm" id="id534"/><a contenteditable="false" data-primary="match classification" data-type="indexterm" id="id535"/> the EM step (see <a data-type="xref" href="ch04.html#chapter_4">Chapter 4</a>) is completed, we have a trained model to assess the similarity between the record pairs in our single dataset. Remember that these pairs are selected using the prediction blocking rules (in this case, exact last name, year, and month of birth). The threshold for predicting a match is set at 0.9:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
df_predict = linker.predict(threshold_match_probability=0.9)</pre>&#13;
&#13;
<p>Following pairwise prediction, Splink offers a clustering function to group entity pairs together when the match probability to a shared entity exceeds a specified threshold. Note that the clustering threshold is applied to the full set of pairwise combinations, not the subset that exceeds the 0.9 prediction threshold; i.e., records that fell below the equivalence threshold in all their comparisons, and thus were not paired at all, will still be present in the output, assigned to their own cluster:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
clusters = linker.cluster_pairwise_predictions_at_threshold(&#13;
   df_predict, threshold_match_probability=0.9)&#13;
df_clusters = clusters.as_pandas_dataframe()&#13;
&#13;
df_clusters.head(n=5)</pre>&#13;
&#13;
<p>The resulting dataset of records, labeled with their parent cluster, can easily be converted to a DataFrame, the first few rows of which (sanitized to remove names and year and month of birth) are shown in <a data-type="xref" href="#fig-7-9">Figure 7-9</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-9"><img alt="" class="iimagesch07ch07clusterspng" src="assets/hoer_0709.png"/>&#13;
<h6><span class="label">Figure 7-9. </span>Sample rows</h6>&#13;
</div></figure>&#13;
&#13;
<p>We can then group these rows by <code>cluster_id</code>, retaining all the different attribute values from each source record in a list under the associated column. In our case, no variation is expected on last name, month, or year of birth as we generated our predictions using exact equivalence of these attributes as our blocking rules. This gives us approximately 6.8 million unique clusters:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
df_cgroup =&#13;
   df_clusters.groupby(['cluster_id'], sort=False)&#13;
      [['company_number','Firstname','Title','Nationality','Lastname']]&#13;
         .agg(lambda x: list(set(x)))&#13;
            .reset_index() </pre>&#13;
&#13;
<p>To illustrate the attribute variation we see within a cluster, we can select a subset of clusters where we have differing first names, titles, and nationalities. For ease of manual examination, we limit ourselves to clusters compromising exactly six records:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
df_cselect = df_cgroup[&#13;
   (df_cgroup['Firstname'].apply(len) &gt; 1) &amp;&#13;
   (df_cgroup['Title'].apply(len) &gt; 1) &amp;&#13;
   (df_cgroup['Nationality'].apply(len) &gt; 1) &amp;&#13;
   (df_cgroup['company_number'].apply(len) == 6)]&#13;
&#13;
df_cselect.head(n=5)</pre>&#13;
&#13;
<p>In the resulting sanitized table, shown in <a data-type="xref" href="#fig-7-10">Figure 7-10</a>, we can see a selection of these clusters in tabular form.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-10"><img alt="" class="iimagesch07ch07clustersize6png" src="assets/hoer_0710.png"/>&#13;
<h6><span class="label">Figure 7-10. </span>Sample rows showing attribution variation in clusters of size six</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Cluster Visualization" data-type="sect1"><div class="sect1" id="id63">&#13;
<h1>Cluster Visualization</h1>&#13;
&#13;
<p>Now<a contenteditable="false" data-primary="clustering" data-secondary="cluster visualization" data-type="indexterm" id="id536"/><a contenteditable="false" data-primary="graph visualizations" data-type="indexterm" id="id537"/> that we have our PSCs clustered together, we can perform a count of the number of companies each entity controls and then plot the distribution of these values in a histogram:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
import matplotlib.pyplot as plt&#13;
import numpy as np&#13;
&#13;
mybins =[1,2,10,100,1000,10000]&#13;
fig, ax = plt.subplots()&#13;
counts, bins, patches = ax.hist(df_cgroup['unique_id'].apply(len),&#13;
   bins=mybins )&#13;
bin_centers = 0.5 * np.diff(bins) + bins[:-1]&#13;
&#13;
for label, x in zip(['1','2-10','10-100','100-1000','1000+'],&#13;
   bin_centers):&#13;
   ax.annotate(label, xy=(x, 0), xycoords=('data', 'axes fraction'),&#13;
               xytext=(0,-10), textcoords='offset points', va='top',&#13;
               ha='right')&#13;
ax.tick_params(labelbottom=False)&#13;
ax.xaxis.set_label_coords(0,-0.1)&#13;
ax.xaxis.set_tick_params(which='minor', bottom=False)&#13;
&#13;
ax.set_xlabel('Number of controlled companies')&#13;
ax.set_ylabel('Count')&#13;
ax.set_title('Distribution of significant company control')&#13;
ax.set_yscale('log')&#13;
ax.set_xscale('log')&#13;
&#13;
fig.tight_layout()&#13;
plt.show()</pre>&#13;
&#13;
<p><a data-type="xref" href="#fig-7-11">Figure 7-11</a> shows the resulting plot, which allows us to begin to answer our sample question—how concentrated is the control of UK companies? We can see that the majority of individuals control only a single company, with a smaller, but still very significant, number having influence over between 2 and 10 firms. After that, the count falls dramatically until our data suggests that we have a handful of individuals with influence over more than 1,000 companies.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-11"><img alt="" class="iimagesch07ch07companydistributionpng" src="assets/hoer_0711.png"/>&#13;
<h6><span class="label">Figure 7-11. </span>Histogram distribution of significant company control</h6>&#13;
</div></figure>&#13;
&#13;
<p>If, like me, you think the significant control of over 1,000 companies sounds a little unlikely, then it’s time we examine our clustering results in a little more detail to see what may be going on. To get a feel for the issues, let’s look at the subset of clusters formed from exactly six records.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Cluster Analysis" data-type="sect1"><div class="sect1" id="id64">&#13;
<h1>Cluster Analysis</h1>&#13;
&#13;
<p>Splink<a contenteditable="false" data-primary="clustering" data-secondary="cluster analysis" data-type="indexterm" id="Canaly07"/><a contenteditable="false" data-primary="Splink" data-secondary="cluster analysis with" data-type="indexterm" id="Scanal07"/> provides us with a cluster studio dashboard, which we can interact with to explore the clusters we have generated to understand how they have been formed. The dashboard is persisted as an HTML page that we can display within the Jupyter environment as a Python inline frame (<code>IFrame</code>):</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
linker.cluster_studio_dashboard(df_predict, clusters,&#13;
   "Chapter7_cluster_studio.html",&#13;
   cluster_ids = df_cselect['cluster_id'].to_list(), overwrite=True)&#13;
&#13;
from IPython.display import IFrame&#13;
IFrame( src="Chapter7_cluster_studio.html", width="100%",&#13;
   height=1200) </pre>&#13;
&#13;
<p><a data-type="xref" href="#fig-7-12">Figure 7-12</a> shows an example of the studio dashboard.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-12"><img class="iimagesch07ch07clusterstudiopng" src="assets/hoer_0712.png"/>&#13;
<h6><span class="label">Figure 7-12. </span>Splink cluster studio dashboard</h6>&#13;
</div></figure>&#13;
&#13;
<p>Let’s consider an example cluster, reference: 766724.<sup><a data-type="noteref" href="ch07.html#id538" id="id538-marker">1</a></sup> Remember that all the nodes in this cluster share the exact matches on the same last name, month, and year of birth due to the blocking rules.</p>&#13;
&#13;
<p>The cluster studio provides a graph view of each cluster with the nodes labeled with their assigned unique identifier and linked together with edges associated with each of the<a contenteditable="false" data-primary="pairwise comparisons" data-type="indexterm" id="prwscmps07"/> pairwise comparisons that exceeded the set threshold. This is shown in <a data-type="xref" href="#fig-7-13">Figure 7-13</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-13"><img class="iimagesch07ch07exampleclusterpng" src="assets/hoer_0713.png"/>&#13;
<h6><span class="label">Figure 7-13. </span>Example cluster</h6>&#13;
</div></figure>&#13;
&#13;
<p>In this example, we can see that not all of the nodes are connected to each other. In fact, between the 6 nodes we have only 9 connected edges out of a possible 15. There are clearly two fully interconnected mini-clusters, linked together through node 766724. Let’s look at this in more detail.</p>&#13;
&#13;
<p>The cluster studio also provides a tabular view of the nodes so that we can examine the attributes in more detail, as shown sanitized in <a data-type="xref" href="#fig-7-14">Figure 7-14</a>. We have sanitized the <code>Firstname</code> column—in this case, the first and third rows have the same spelling, which is slightly different from the other four rows.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-14"><img alt="" class="iimagesch07ch07exampleclusternodespng" src="assets/hoer_0714.png"/>&#13;
<h6><span class="label">Figure 7-14. </span>Example cluster nodes</h6>&#13;
</div></figure>&#13;
&#13;
<p>The top mini-cluster of nodes 8261597, 4524351, and 766724 all have the same <code>Nationality</code> and are also missing a <code>Middlename</code>. The second mini-cluster of nodes 766724, 5702850, 4711461, and 9502305 all have exactly matching <code>Firstname</code> values.</p>&#13;
&#13;
<p>The sanitized tabular edge view, shown in <a data-type="xref" href="#fig-7-15">Figure 7-15</a>, gives us the match weights and associated probabilities for these pairwise comparisons.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-15"><img class="iimagesch07ch07exampleclusteredgespng" src="assets/hoer_0715.png"/>&#13;
<h6><span class="label">Figure 7-15. </span>Example cluster edges</h6>&#13;
</div></figure>&#13;
&#13;
<p>If we increase our match threshold to filter out edges with a match weight threshold below 3.4, we break the two lowest scoring pairwise links. As seen in <a data-type="xref" href="#fig-7-16">Figure 7-16</a>, our second mini-cluster remains intact but our first mini-cluster has broken apart, with nodes 8261597 and 4524351 now separate due to their different first name spelling.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-16"><img alt="" class="iimagesch07ch07examplecluster34png" src="assets/hoer_0716.png"/>&#13;
<h6><span class="label">Figure 7-16. </span>Example clusters—high match threshold</h6>&#13;
</div></figure>&#13;
&#13;
<p>Further increasing the match weight threshold to 8.7 breaks our first mini-cluster completely as the lack of <code>Middlename</code> becomes a deciding negative factor. This is shown in <a data-type="xref" href="#fig-7-17">Figure 7-17</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-17"><img alt="" class="iimagesch07ch07examplecluster87png" src="assets/hoer_0717.png"/>&#13;
<h6><span class="label">Figure 7-17. </span>Example clusters—higher match threshold</h6>&#13;
</div></figure>&#13;
&#13;
<p>Increasing the match weight to a very high threshold of 9.4 causes node 766724 to break apart due to its slightly different first name spelling, as shown in <a data-type="xref" href="#fig-7-18">Figure 7-18</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig-7-18"><img alt="" class="iimagesch07ch07examplecluster94png" src="assets/hoer_0718.png"/>&#13;
<h6><span class="label">Figure 7-18. </span>Example clusters—highest match threshold</h6>&#13;
</div></figure>&#13;
&#13;
<p>As we can see, the size and density of our clusters is highly dependent upon the thresholds we set for grouping pairwise comparisons together.</p>&#13;
&#13;
<p>The Companies House website gives us access to information on the address associated with these PSC records. Company numbers 8261597, 4711461, and 4524351 were all registered by an individual giving the same address, as were 5702850 and 9502305. This gives us more confidence that this cluster does indeed represent one individual.</p>&#13;
&#13;
<p>A wider review suggests that our first pass at assessing the concentration of control over UK companies was perhaps too optimistic. Setting our match and clustering thresholds at 0.9 has erred toward overlinking, resulting in larger clusters with weaker associations. This may go some way to explain the rather dubious assessment of several individuals with significant control of more than 1,000 companies.</p>&#13;
&#13;
<p>I hope that working through this sample problem has illustrated that entity resolution with messy real-world data is not an exact science. There is no single right answer, and judgment is needed to set the matching thresholds to the optimum values for the outcomes you are seeking to achieve.<a contenteditable="false" data-primary="" data-startref="Scanal07" data-type="indexterm" id="id539"/><a contenteditable="false" data-primary="" data-startref="Canaly07" data-type="indexterm" id="id540"/></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="id65">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>In this chapter, we have seen how entity resolution within and across multiple datasets can produce a large number of pairwise comparisons. We learned how to select and evaluate blocking rules to reduce these combinations to a more practical volume to allow us to train and then run our matching algorithm in a reasonable timeframe.</p>&#13;
&#13;
<p>Using approximate matching and probabilistic entity resolution, we were able to generate clusters from pairwise comparisons, allowing for variations in some of the attributes. However, we were left with the canonicalization challenge of how to decide which attribute values to use to describe our unified entity.<a contenteditable="false" data-primary="" data-startref="prwscmps07" data-type="indexterm" id="id541"/></p>&#13;
&#13;
<p>We also learned how to use graph visualizations to help us understand our clusters. We saw how cluster size and composition is strongly influenced by our choice of match threshold and that the risks of over- or underlinking need to be balanced in the context of a particular dataset and desired outcome.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id538"><sup><a href="ch07.html#id538-marker">1</a></sup> Note: If you are following along with your own notebook and PSC dataset, your cluster references may vary.</p></div></div></section></body></html>