["```py\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.clustering import LDA\n\ndf = spark.createDataFrame([[1, Vectors.dense([0.0, 1.0])],\n      [2, Vectors.dense([2.0, 3.0])],],\n      [\"id\", \"features\"])\n\nlda = LDA(k=2, seed=1) ![1](assets/1.png)\nlda.setMaxIter(10)\n\nmodel = lda.fit(df)\n\nmodel.vocabSize()\n2\n\nmodel.describeTopics().show() ![2](assets/2.png)\n+-----+-----------+--------------------+\n|topic|termIndices|         termWeights|\n+-----+-----------+--------------------+\n|    0|     [0, 1]|[0.53331100994293...|\n|    1|     [1, 0]|[0.50230220117597...|\n+-----+-----------+--------------------+\n```", "```py\n$ curl -s -L https://dumps.wikimedia.org/enwiki/latest/\\\n$ enwiki-latest-pages-articles-multistream.xml.bz2 \\\n$   | bzip2 -cd \\\n$   | hadoop fs -put - wikidump.xml\n```", "```py\n$ pip3 install wikiextractor\n```", "```py\n$ wikiextractor wikidump.xml\n```", "```py\n$ mv text wikidump ![1](assets/1.png)\n$ tree wikidump\n...\nwikidump\n└── AA\n    └── wiki_00\n\n...\n$ head -n 5 wikidump/AA/wiki_00\n...\n\n<doc id=\"18831\" url=\"?curid=18831\" title=\"Mathematics\">\nMathematics\n\nMathematics (from Greek: ) includes the study of such topics as numbers ...\n...\n```", "```py\npip3 install spark-nlp==3.2.3\n```", "```py\npyspark --packages com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.4\n```", "```py\nimport sparknlp\n\nspark = sparknlp.start()\n```", "```py\nfrom sparknlp.base import DocumentAssembler, Finisher\nfrom sparknlp.annotator import (Lemmatizer, Stemmer,\n                                Tokenizer, Normalizer,\n                                StopWordsCleaner)\nfrom sparknlp.pretrained import PretrainedPipeline\n```", "```py\ndata_source = 'wikidump/*/*'\n```", "```py\nraw_data = spark.sparkContext.wholeTextFiles(data_source).toDF()\nraw_data.show(1, vertical=True)\n...\n\n-RECORD 0-------------------\n _1  | file:/home/analyt...\n _2  | <doc id=\"18831\" u...\n```", "```py\nfrom pyspark.sql import functions as fun\ndf = raw_data.withColumn('content', fun.explode(fun.split(fun.col(\"_2\"),\n  \"</doc>\")))\ndf = df.drop(fun.col('_2')).drop(fun.col('_1'))\n\ndf.show(4, vertical=True)\n...\n-RECORD 0-----------------------\n content | <doc id=\"18831\" u...\n-RECORD 1-----------------------\n content |\n<doc id=\"5627588...\n-RECORD 2-----------------------\n content |\n<doc id=\"3354393...\n-RECORD 3-----------------------\n content |\n<doc id=\"5999808...\nonly showing top 4 rows\n```", "```py\ndf.show(1, truncate=False, vertical=True)\n...\n-RECORD 0\n\n-------------------------------------------------------------------\n content | <doc id=\"18831\" url=\"?curid=18831\" title=\"Mathematics\">\nMathematics\n\nMathematics (from Greek: ) includes the study of such topics as numbers...\n```", "```py\ndf = df.withColumn('title', fun.split(fun.col('content'), '\\n').getItem(2)) \\\n        .withColumn('content', fun.split(fun.col('content'), '\\n').getItem(4))\ndf.show(4, vertical=True)\n...\n-RECORD 0-----------------------\n content | In mathematics, a...\n title   | Tertiary ideal\n-RECORD 1-----------------------\n content | In algebra, a bin...\n title   | Binomial (polynom...\n-RECORD 2-----------------------\n content | Algebra (from ) i...\n title   | Algebra\n-RECORD 3-----------------------\n content | In set theory, th...\n title   | Kernel (set theory)\nonly showing top 4 rows\n...\n```", "```py\ndocument_assembler = DocumentAssembler() \\\n    .setInputCol(\"content\") \\\n    .setOutputCol(\"document\") \\\n    .setCleanupMode(\"shrink\")\n\ndocument_assembler.transform(df).select('document').limit(1).collect()\n...\n\nRow(document=[Row(annotatorType='document', begin=0, end=289, result='...',\n    metadata={'sentence': '0'}, embeddings=[])])\n```", "```py\n# Split sentence to tokens(array)\ntokenizer = Tokenizer() \\\n  .setInputCols([\"document\"]) \\\n  .setOutputCol(\"token\")\n```", "```py\n# clean unwanted characters and garbage\nnormalizer = Normalizer() \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"normalized\") \\\n    .setLowercase(True)\n```", "```py\n# remove stopwords\nstopwords_cleaner = StopWordsCleaner()\\\n      .setInputCols(\"normalized\")\\\n      .setOutputCol(\"cleanTokens\")\\\n      .setCaseSensitive(False)\n```", "```py\n# stem the words to bring them to the root form.\nstemmer = Stemmer() \\\n    .setInputCols([\"cleanTokens\"]) \\\n    .setOutputCol(\"stem\")\n```", "```py\nfinisher = Finisher() \\\n    .setInputCols([\"stem\"]) \\\n    .setOutputCols([\"tokens\"]) \\\n    .setOutputAsArray(True) \\\n    .setCleanAnnotations(False)\n```", "```py\nfrom pyspark.ml import Pipeline\nnlp_pipeline = Pipeline(\n    stages=[document_assembler,\n            tokenizer,\n            normalizer,\n            stopwords_cleaner,\n            stemmer,\n            finisher])\n```", "```py\nnlp_model = nlp_pipeline.fit(df) ![1](assets/1.png)\n\nprocessed_df  = nlp_model.transform(df) ![2](assets/2.png)\n\nprocessed_df.printSchema()\n...\n\nroot\n |-- content: string (nullable = true)\n |-- title: string (nullable = true)\n |-- document: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n |-- token: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n |-- normalized: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n |-- cleanTokens: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n |-- stem: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n |-- tokens: array (nullable = true)\n |    |-- element: string (containsNull = true)\n```", "```py\ntokens_df = processed_df.select('title','tokens')\ntokens_df.show(2, vertical=True)\n...\n\n-RECORD 0----------------------\n title  | Tertiary ideal\n tokens | [mathemat, tertia...\n-RECORD 1----------------------\n title  | Binomial (polynom...\n tokens | [algebra, binomi,...\nonly showing top 2 rows\n```", "```py\nimport math\n\ndef term_doc_weight(term_frequency_in_doc, total_terms_in_doc,\n                    term_freq_in_corpus, total_docs):\n  tf = term_frequency_in_doc / total_terms_in_doc\n  doc_freq = total_docs / term_freq_in_corpus\n  idf = math.log(doc_freq)\n  tf * idf\n}\n```", "```py\nfrom pyspark.ml.feature import CountVectorizer\ncv = CountVectorizer(inputCol=\"tokens\", outputCol=\"raw_features\")\n\n# train the model\ncv_model = cv.fit(tokens_df)\n\n# transform the data. Output column name will be raw_features.\nvectorized_tokens = cv_model.transform(tokens_df)\n```", "```py\nfrom pyspark.ml.feature import IDF\nidf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n\nidf_model = idf.fit(vectorized_tokens)\n\nvectorized_df = idf_model.transform(vectorized_tokens)\n```", "```py\nvectorized_df = vectorized_df.drop(fun.col('raw_features'))\n\nvectorized_df.show(6)\n...\n\n+--------------------+--------------------+--------------------+\n|               title|              tokens|            features|\n+--------------------+--------------------+--------------------+\n|      Tertiary ideal|[mathemat, tertia...|(2451,[1,6,43,56,...|\n|Binomial (polynom...|[algebra, binomi,...|(2451,[0,10,14,34...|\n|             Algebra|[algebra, on, bro...|(2451,[0,1,5,6,15...|\n| Kernel (set theory)|[set, theori, ker...|(2451,[2,3,13,19,...|\n|Generalized arith...|[mathemat, gener,...|(2451,[1,2,6,45,4...|\n+--------------------+--------------------+--------------------+\n```", "```py\nfrom pyspark.ml.clustering import LDA\n\nnum_topics = 5\nmax_iter = 50\n\nlda = LDA(k=num_topics, maxIter=max_iter)\nmodel = lda.fit(vectorized_df)\n\nlp = model.logPerplexity(vectorized_df)\n\nprint(\"The upper bound on perplexity: \" + str(lp))\n...\n\nThe upper bound on perplexity: 6.768323190833805\n```", "```py\nvocab = cv_model.vocabulary ![1](assets/1.png)\n\nraw_topics = model.describeTopics().collect() ![2](assets/2.png)\n\ntopic_inds = [ind.termIndices for ind in raw_topics] ![3](assets/3.png)\n\ntopics = []\nfor topic in topic_inds:\n    _topic = []\n    for ind in topic:\n        _topic.append(vocab[ind])\n    topics.append(_topic)\n```", "```py\nfor i, topic in enumerate(topics, start=1):\n    print(f\"topic {i}: {topic}\")\n...\n\ntopic 1: ['islam', 'health', 'drug', 'empir', 'medicin', 'polici',...\ntopic 2: ['formula', 'group', 'algebra', 'gener', 'transform',    ...\ntopic 3: ['triangl', 'plane', 'line', 'point', 'two', 'tangent',  ...\ntopic 4: ['face', 'therapeut', 'framework', 'particl', 'interf',  ...\ntopic 5: ['comput', 'polynomi', 'pattern', 'internet', 'network', ...\n```", "```py\nlda_df = model.transform(vectorized_df)\nlda_df.select(fun.col('title'), fun.col('topicDistribution')).\\\n                show(2, vertical=True, truncate=False)\n...\n-RECORD 0-------------------------------------\n title             | Tertiary ideal\n topicDistribution | [5.673953573608612E-4,...\n-RECORD 1----------------------------------...\n title             | Binomial (polynomial) ...\n topicDistribution | [0.0019374384060205127...\nonly showing top 2 rows\n```", "```py\nfrom pyspark.sql.types import IntegerType\nmax_index = fun.udf(lambda x: x.tolist().index(max(x)) + 1, IntegerType())\nlda_df = lda_df.withColumn('topic_index',\n                        max_index(fun.col('topicDistribution')))\n```", "```py\nlda_df.select('title', 'topic_index').show(10, truncate=False)\n...\n\n+----------------------------------+-----------+\n|title                             |topic_index|\n+----------------------------------+-----------+\n|Tertiary ideal                    |2          |\n|Binomial (polynomial)             |2          |\n|Algebra                           |2          |\n|Kernel (set theory)               |2          |\n|Generalized arithmetic progression|2          |\n|Schur algebra                     |2          |\n|Outline of algebra                |2          |\n|Recurrence relation               |5          |\n|Rational difference equation      |5          |\n|Polynomial arithmetic             |2          |\n+----------------------------------+-----------+\nonly showing top 11 rows\n```"]