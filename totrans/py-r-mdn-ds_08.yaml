- en: Chapter 5\. Workflow Context
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 章。工作流上下文
- en: Boyan Angelov
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Boyan Angelov
- en: A common source of frustration for data scientists is discussing their work
    with colleagues from adjacent fields. Let’s take the example of someone who has
    been working primarily in developing machine learning (ML) models, having a chat
    about their work with a colleague from the Business Intelligence (BI) team, more
    focused on reporting. More often than not, such a discussion can make both parties
    uncomfortable due to a perceived lack of knowledge about each other’s work domain
    (and associated workflows) - despite sharing the same job title. The ML person
    might wonder, what D3.js is, the grammar of graphics, and all that? On the other
    hand, the BI data scientist might feel insecure about not knowing how to build
    a deployable API. The feelings that might arise from such a situation have been
    termed “impostor syndrome,” where doubts about your competency arise. Such a situation
    is a by-product of the sheer volume of possible applications of data science.
    A single person is rarely familiar to the same extent with more than several sub-fields.
    Flexibility is still often required in this fast-evolving field.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家常见的挫败感来源于与邻域领域同事讨论工作。让我们以一个例子来说明，一个主要从事机器学习（ML）模型开发的人，与商业智能（BI）团队的同事交流。这种讨论往往会让双方感到不适，因为他们认为彼此对对方工作领域（及相关工作流程）了解不足，尽管拥有相同的职位头衔。ML
    的人可能会想知道 D3.js 是什么，图形语法是什么，等等？另一方面，BI 数据科学家可能会因不知如何构建可部署的 API 而感到不安。这种情况可能会引发“冒名顶替综合征”，即对自己能力的怀疑。这种情况是数据科学应用潜力巨大的副产品。一个人很少能对多个子领域有同样程度的熟悉。在这个快速发展的领域中，通常需要灵活性。
- en: This complexity sets the foundation for the workflow focus in this chapter.
    We’ll cover the primary data science workflows and how the languages’ different
    ecosystems support them. Much like [Chapter 4](ch04.xhtml#ch05), at the end of
    this chapter, you’ll have everything needed for making educated decisions regarding
    your workflows.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 此复杂性为本章工作流重点奠定了基础。我们将讨论主要的数据科学工作流以及语言的不同生态系统如何支持它们。就像[第 4 章](ch04.xhtml#ch05)一样，在本章末尾，您将拥有做出关于工作流的明智决策所需的一切。
- en: Defining workflows
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义工作流程
- en: 'Let’s take a step back, and define a workflow:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们退一步，定义一个工作流程：
- en: '**A workflow is a complete collection of tools and frameworks to perform all
    tasks required from a specific job function.**'
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**工作流是从特定职能角度执行所有任务所需的所有工具和框架的完整集合。**'
- en: For this example, let’s say you’re an ML engineer. Your daily tasks might include
    tools to obtain data, process it, train a model on it, and deployment frameworks.
    Those, collectively, represent the ML engineer workflow. An overview of the data
    workflows for this and other titles and their supporting tools, is presented in
    [Table 5-1](#workflows-table).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 以 ML 工程师为例，您的日常任务可能包括获取数据的工具、处理数据、在其上训练模型以及部署框架。这些集合共同代表了 ML 工程师的工作流程。关于此和其他职位的数据工作流程概述及其支持工具，见[表
    5-1](#workflows-table)。
- en: Table 5-1\. Common data science workflows and their enabling tools.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 第 5-1 表。常见数据科学工作流程及其支持工具。
- en: '| Method | Python package | R package |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | Python 软件包 | R 软件包 |'
- en: '| --- | --- | --- |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Data Munging^([a](ch05.xhtml#idm45127450466184)) | `pandas` | `dplyr` |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 数据整理^([a](ch05.xhtml#idm45127450466184)) | `pandas` | `dplyr` |'
- en: '| EDA | `matplotlib`, `seaborn`, `pandas` | `ggplot2`, `base-r`, `leaflet`
    |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| EDA | `matplotlib`, `seaborn`, `pandas` | `ggplot2`, `base-r`, `leaflet`
    |'
- en: '| Machine Learning | `scikit-learn` | `mlr`, `tidymodels`, `caret` |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习 | `scikit-learn` | `mlr`, `tidymodels`, `caret` |'
- en: '| Deep Learning | `keras`, `tensorflow`, `pytorch` | `keras`, `tensorflow`,
    `torch` |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 深度学习 | `keras`, `tensorflow`, `pytorch` | `keras`, `tensorflow`, `torch`
    |'
- en: '| Data Engineering^([b](ch05.xhtml#idm45127450450408)) | `flask`, `bentoML`,
    `fastapi` | `plumber` |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 数据工程^([b](ch05.xhtml#idm45127450450408)) | `flask`, `bentoML`, `fastapi`
    | `plumber` |'
- en: '| Reporting | `jupyter`, `streamlit` | `rmarkdown`, `shiny` |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 报告 | `jupyter`, `streamlit` | `rmarkdown`, `shiny` |'
- en: '| ^([a](ch05.xhtml#idm45127450466184-marker)) Data munging (or wrangling) is
    such a fundamental topic in data science that it was already covered in [Chapter 2](ch02.xhtml#ch03).^([b](ch05.xhtml#idm45127450450408-marker))
    There is much more to data engineering than model deployment, but we decided to
    focus on this subset to illustrate Python’s ability. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| ^([a](ch05.xhtml#idm45127450466184-marker)) 数据整理（或称为数据处理）是数据科学中如此基础的主题，以至于已在[第
    2 章](ch02.xhtml#ch03)中讨论过。^([b](ch05.xhtml#idm45127450450408-marker)) 数据工程不仅仅是模型部署，但我们决定聚焦于这一子集，以展示
    Python 的能力。 |'
- en: We omitted some areas in the hope that the listed ones are the most common and
    critical. Those selected workflows are related to each other, as presented on
    [Figure 5-1](#meta_workflow). This diagram borrows heavily from the [CRISP-DM](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining)
    framework, which shows all significant steps in a typical data science project.
    Each of the diagram’s steps has a separate workflow associated with it, generally
    assigned to an individual or a team.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们省略了一些领域，希望列出的是最常见和关键的。所选的工作流程彼此相关，如在[图 5-1](#meta_workflow)中所示。这个图表在很大程度上借鉴了[CRISP-DM](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining)框架，展示了典型数据科学项目中的所有重要步骤。图表中的每个步骤都有一个单独的工作流与之关联，通常分配给个人或团队。
- en: '![](Images/prds_0501.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0501.png)'
- en: Figure 5-1\. Meta-workflow in data science and engineering.
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-1\. 数据科学与工程中的元工作流。
- en: 'Now that we have defined a workflow, what are the defining properties of a
    “good” one? We can compile a checklist with three main factors to consider:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了一个工作流程，那么一个“好”的工作流程的定义属性是什么？我们可以编制一个包含三个主要因素的检查列表：
- en: It’s well established. It’s widely adopted by the community (also across different
    application domains, such as Computer Vision or Natural Language Processing).
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它已经被充分确立。它被社区广泛采纳（也跨越不同的应用领域，如计算机视觉或自然语言处理）。
- en: It’s supported by a well-maintained, open-source ecosystem and community. A
    workflow that relies heavily on closed-source and commercial applications (such
    as Matlab) is not considered acceptable.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它由一个维护良好的开源生态系统和社区支持。依赖于封闭源和商业应用程序（如Matlab）的工作流程不被认为是可接受的。
- en: It’s suitable for overlapping job functions. The best workflows are similar
    to lego bricks - their modular design and extensibility can support diverse tech
    stacks.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它适用于重叠的工作职能。最佳工作流程类似于乐高积木 - 它们的模块化设计和可扩展性可以支持各种技术堆栈。
- en: With the big picture and definitions out of the way, let’s dive deeper into
    the different workflows and how they are supported by R and Python!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通过全局视图和定义，让我们更深入地了解不同的工作流程及其在R和Python中的支持！
- en: Exploratory data analysis
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: Looking at numbers is *hard*. Looking at rows of data containing millions upon
    millions of them is even more challenging. Any person dealing with data faces
    this challenge daily. This need has led to considerable developments in data visualization
    (DV) tools. A recent trend in the area is the explosion of self-serving analytics
    tools, such as [Tableau](https://www.tableau.com/), [Alteryx](https://www.alteryx.com/),
    and [Microsoft PowerBI](https://powerbi.microsoft.com/en-us/). These are very
    useful, but the open-source world has many alternatives available, often rivaling
    or even exceeding their commercial counterparts’ capabilities (except, in some
    cases, ease of use). Such tools collectively represent the EDA workflow.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 查看数字是*困难的*。查看包含数以百万计数据的数据行更具挑战性。任何处理数据的人每天都面临这一挑战。这种需求促使数据可视化（DV）工具的显著发展。该领域的一个最新趋势是自助分析工具的爆炸性增长，例如[Tableau](https://www.tableau.com/)、[Alteryx](https://www.alteryx.com/)和[Microsoft
    PowerBI](https://powerbi.microsoft.com/en-us/)。这些工具非常有用，但开源世界中也有许多可用的替代品，通常能够竞争甚至超过其商业对手的能力（除了在某些情况下的易用性）。这些工具共同代表了EDA工作流。
- en: When to use a GUI for EDA
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用GUI进行EDA
- en: Many data scientists frown at the notion of using a graphical user interface
    (GUI) for their daily work. They would much rather prefer the flexibility and
    utility of command-line tools instead. Nevertheless, one area where using a GUI
    makes more sense (for productivity reasons) is EDA. It can be quite time-consuming
    to generate multiple plots, especially at the beginning of a data science project.
    Usually, one would need to create tens, if not hundreds of them. Imagine writing
    the code for each one (even if you improve your code’s organization by refactoring
    into functions). For some larger datasets, it’s sometimes much easier to use some
    GUI, such as AWS Quicksight or Google Data Studio. By using a GUI the data scientist
    can quickly generate a lot of plots first and only then write the code for the
    ones that make the cut after screening. There are a few good open-source GUI tools,
    for example [Orange](https://orange.biolab.si/).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据科学家对使用图形用户界面（GUI）进行日常工作持反感态度。他们更喜欢命令行工具的灵活性和效用。然而，在某些情况下，使用 GUI 更为合理（出于生产力考虑），例如在
    EDA 中。生成多个图表可能非常耗时，尤其是在数据科学项目的初期阶段。通常需要创建数十甚至数百个图表。想象一下为每个图表编写代码（即使通过重构代码为函数来改进代码的组织方式）。对于一些较大的数据集，使用一些
    GUI 工具，如 AWS Quicksight 或 Google Data Studio，通常更为便捷。通过使用 GUI，数据科学家可以快速生成大量图表，然后只需为通过筛选的图表编写代码。还有一些不错的开源
    GUI 工具，例如 [Orange](https://orange.biolab.si/)。
- en: EDA is a fundamental step at the beginning of the analysis of any data source.
    It is typically performed directly after data loading, at the stage where there’s
    a significant need for business understanding. This explains why it’s an essential
    step. You are probably familiar with the *garbage in*, *garbage out* paradigm
    - the quality of any data project depends on the quality of the input data and
    the domain knowledge behind it. EDA enables the success of the downstream workflows
    (such as ML), ensuring both the data and the assumptions behind it are correct
    and of sufficient quality.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: EDA 是对任何数据源进行分析的基础步骤。通常在数据加载后直接进行，在业务理解方面有显著需求的阶段。这解释了为什么它是一个必要的步骤。你可能熟悉 *垃圾进，垃圾出*
    的范式 - 任何数据项目的质量取决于输入数据的质量和背后的领域知识。EDA 促进了下游工作流程（如 ML）的成功，确保数据和其背后的假设都是正确且具有足够的质量。
- en: In EDA, R has far better tools available than Python. As we discussed in [Chapter 1](ch01.xhtml#ch01)
    and [Chapter 2](ch02.xhtml#ch03), R is a language made *by* statisticians and
    *for* statisticians (remember FUBU from [Chapter 2](ch02.xhtml#ch03)?), and data
    visualization (plotting) has been of great importance in statistics for decades.
    Python has made some forward strides in recent years but is still seen as lagging
    (you need just to look at example `matplotlib` plot to realize this fact^([1](ch05.xhtml#idm45127450420728))).
    Enough praise for R; let’s have a look at why it’s great for EDA!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在 EDA 中，R 拥有比 Python 更好的工具。正如我们在 [第一章](ch01.xhtml#ch01) 和 [第二章](ch02.xhtml#ch03)
    中讨论的，R 是一门由统计学家为统计学家开发的语言（还记得第二章中的 FUBU 吗？），在统计学中，数据可视化（绘图）几十年来一直非常重要。Python 在近年来取得了一些进展，但仍被认为是滞后的（只需看看例子
    `matplotlib` 绘图就能意识到这一事实^([1](ch05.xhtml#idm45127450420728))）。足够赞扬 R 了，让我们看看为什么它在
    EDA 中如此出色！
- en: Static visualizations
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 静态可视化
- en: You should already be acquainted with base R’s powers in terms of DV from [Chapter 4](ch04.xhtml#ch05),
    especially regarding time series plotting. Here we’ll take a step further and
    discuss one of the most famous R packages - `ggplot2`. It’s one of the main reasons
    why Pythonistas want to switch to R^([2](ch05.xhtml#idm45127450414536)). What
    makes `ggplot2` so successful in EDA work is that it’s based on a well thought-through
    methodology - the Grammar of Graphics (GoG). It was developed by L. Wilkinson,
    and the package by Hadley Wickham^([3](ch05.xhtml#idm45127450412248)).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该已经熟悉了基本 R 在 DV 方面的能力，特别是关于时间序列绘图的部分 [第四章](ch04.xhtml#ch05)。在这里，我们将进一步讨论并介绍最著名的
    R 包之一 - `ggplot2`。它是 Python 爱好者希望转向 R 的主要原因之一^([2](ch05.xhtml#idm45127450414536))。`ggplot2`
    在 EDA 工作中如此成功的原因在于它基于一个经过深思熟虑的方法论 - 图形语法（GoG）。这是由 L. Wilkinson 开发的，而包由 Hadley
    Wickham 开发^([3](ch05.xhtml#idm45127450412248))。
- en: What *is* the GoG? The [original paper](https://vita.had.co.nz/papers/layered-grammar.html)
    behind it has the title “A layered grammar of graphics,” and the word “layered”
    holds the key. Everything you see on a plot contributes to a larger stack or system.
    For example, the axes and grids form a separate layer compared to the lines, bars,
    and points. Those latter elements constitute the “data” layer. The complete stack
    of layers forms the result - a complete `ggplot`. Such a modular design pattern
    allows for great flexibility and provides a new way of thinking about data visualization.
    The logic behind GoG is illustrated in [Figure 5-2](#gog).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 什么*是* GoG？它的[原始论文](https://vita.had.co.nz/papers/layered-grammar.html)标题为“图形的分层语法”，而“分层”一词是关键。您在图上看到的每一样东西都对一个更大的堆栈或系统有所贡献。例如，坐标轴和网格形成一个单独的层，与线条、条形和点相比。后者构成“数据”层。所有图层的完整堆栈形成结果
    - 一个完整的`ggplot`。这种模块化的设计模式可以提供极大的灵活性，并提供了一种新的数据可视化思维方式。GoG背后的逻辑在[图 5-2](#gog)中说明。
- en: '![](Images/prds_0502.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0502.png)'
- en: Figure 5-2\. The layered Grammar of Graphics.
  id: totrans-36
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-2\. 图形语法的分层结构。
- en: To illustrate the different procedures for a regular EDA workflow we’ll use
    the `starwars` dataset (available from the `dplyr` package^([4](ch05.xhtml#idm45127450403976))).
    This dataset contains information on characters in the Star Wars movies, such
    as their gender, height and species. Let’s have a look!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明常规 EDA 工作流程的不同程序，我们将使用`dplyr`包中的`starwars`数据集^([4](ch05.xhtml#idm45127450403976))。这个数据集包含了关于星球大战电影中人物的信息，比如他们的性别、身高和物种。让我们来看一下！
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](Images/1.png)](#co_workflow_context_CO1-1)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_workflow_context_CO1-1)'
- en: This will make the dataset visible in your RStudio environment, but it’s not
    strictly necessary.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使数据集在您的 RStudio 环境中可见，但这并不是严格必要的。
- en: 'As a first step, let’s do a basic plot:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，让我们做一个基本的绘图：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This plots the counts of the hair color variable. Here, we see a familiar operator,
    `+`, used unconventionally. We use `+` in ggplot2 to *add* layers on top of each
    other in `ggplot2`. Let’s build on this with a more involved case. Note that we
    omitted a filtering step from the code here (there’s an outlier - Jabba the Hut):
    ^([5](ch05.xhtml#idm45127450350536)).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图绘制了头发颜色变量的计数。在这里，我们看到了一个熟悉的运算符，`+`，被不同寻常地使用。在`ggplot2`中，我们使用`+`来在图中*添加*图层。让我们在此基础上构建一个更复杂的案例。注意，我们在这里省略了代码中的一个过滤步骤（有一个离群值
    - 贾巴·赫特）：^([5](ch05.xhtml#idm45127450350536))。
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](Images/1.png)](#co_workflow_context_CO2-1)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_workflow_context_CO2-1)'
- en: Specify which data and features to use.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 指定要使用的数据和特征。
- en: '[![2](Images/2.png)](#co_workflow_context_CO2-2)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_workflow_context_CO2-2)'
- en: Select a points plot (the most suitable for continuous data).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个点图（最适合连续数据）。
- en: '[![3](Images/3.png)](#co_workflow_context_CO2-3)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_workflow_context_CO2-3)'
- en: Use a built-in `theme` - a collection of specific layer styles.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用内置的`theme` - 一组特定的图层样式。
- en: '[![4](Images/4.png)](#co_workflow_context_CO2-4)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_workflow_context_CO2-4)'
- en: Fit a linear model and show the results as a layer on the plot.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合一个线性模型并将结果显示为绘图的一层。
- en: '[![5](Images/5.png)](#co_workflow_context_CO2-5)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_workflow_context_CO2-5)'
- en: Add title and axes labels.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 添加标题和轴标签。
- en: The results of this plotting operation are shown on [Figure 5-3](#adv_ggplot_1).
    With just several lines of code, we created a beautiful plot, which can be extended
    even further.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此绘图操作的结果显示在[图 5-3](#adv_ggplot_1)中。仅用几行代码，我们就创建了一个漂亮的图，甚至可以进一步扩展。
- en: '![](Images/prds_0503.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0503.png)'
- en: Figure 5-3\. An advanced ggplot2 plot.
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-3\. 一个高级的 ggplot2 图。
- en: Now that we covered static visualizations let’s see how to make them more interesting
    by adding interactivity!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了静态可视化，让我们看看如何通过添加交互性使它们更有趣！
- en: Interactive visualizations
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交互式可视化
- en: 'Interactivity can be a great aid to exploratory plots. Two excellent R packages
    stand out: [`leaflet`](https://rstudio.github.io/leaflet/) and [`plotly`](https://plotly.com/).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 交互性可以极大地帮助探索性绘图。两个出色的 R 包脱颖而出：[`leaflet`](https://rstudio.github.io/leaflet/)
    和 [`plotly`](https://plotly.com/)。
- en: Beware of JavaScript
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小心 JavaScript
- en: Interactivity in Python and R is often based on an underlying JavaScript codebase.
    Packages like `leaflet` and `plotly` take care of this for us, but keen to learn
    pure JavaScript. Low-level packages for interactive graphics, like [D3.js](https://d3js.org/),
    can be overwhelming to learn for the novice. Thus, we’d encourage learning a high-level
    framework, such as [Dimple.js](http://dimplejs.org/) instead.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Python和R中的交互性通常基于底层的JavaScript代码库。像`leaflet`和`plotly`这样的包已经为我们处理了这些，但我们也可以学习纯JavaScript。对于初学者来说，像[D3.js](https://d3js.org/)这样的交互图形的低级包可能会感到无法掌握。因此，我们鼓励学习高级框架，比如[Dimple.js](http://dimplejs.org/)。
- en: Different datasets require different visualization methods. We covered the case
    of a standard tabular dataset (`starwars`), but how about something different?
    We’ll have a go at visualizing data with a spatial dimension and use it to show
    R’s excellent capabilities in producing interactive plots. For this, we selected
    the [Shared Cars Locations dataset](https://www.kaggle.com/gidutz/autotel-shared-car-locations).
    It provides the locations of car-sharing vehicles in Tel-Aviv, Israel. Can we
    show those on a map?
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的数据集需要不同的可视化方法。我们覆盖了标准的表格式数据集（`starwars`）案例，但还有其他不同的情况吗？我们将尝试使用具有空间维度的数据来展示R在生成交互式图表方面的优秀能力。为此，我们选择了[共享汽车位置数据集](https://www.kaggle.com/gidutz/autotel-shared-car-locations)。它提供了以色列特拉维夫市共享汽车位置的信息。我们可以在地图上显示这些位置吗？
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this case, we subset the data using the first 20 rows only (to make the visualization
    less cluttered). The `addTiles` function provides the map background, with the
    street and city names^([6](ch05.xhtml#idm45127450129960)). The next step is to
    add the markers which specify the car locations by using `addMarkers`. The result
    of this relatively simple operation is shown in [Figure 5-4](#leaflet).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们仅使用前20行数据（以减少可视化的混乱程度）。`addTiles`函数提供地图背景，并显示街道和城市名称^([6](ch05.xhtml#idm45127450129960))。下一步是通过使用`addMarkers`添加指定汽车位置的标记。这个相对简单的操作的结果如图[5-4](#leaflet)所示。
- en: '![](Images/prds_0504.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0504.png)'
- en: Figure 5-4\. An interactive map plot with leaflet
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-4\. 使用leaflet的交互地图绘图
- en: As with the best data science tools, packages like `leaflet` hide a lot of complexity
    under the hood. They do much of the heavy lifting necessary for advanced visualization
    and enable the data scientist to do what they do best - focus on the data. There
    are many more advanced features available in `leaflet`, and we encourage the motivated
    user to explore them.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 与最好的数据科学工具一样，像`leaflet`这样的包在幕后隐藏了大量复杂性。它们完成了高级可视化所需的大部分重活，并且使数据科学家可以专注于他们擅长的事情
    - 关注数据。`leaflet`中还有许多更高级的功能可供使用，我们鼓励有兴趣的用户去探索。
- en: Make ggplot2 interactive
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使ggplot2变得交互式
- en: As our book’s subtitle suggests, we are always attempting to take the best of
    both worlds. So one easy way to do it is to use the `ggplotly` command from the
    `plotly` package and pass it a `ggplot2` plot. This will make the plot interactive!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们书的副标题所示，我们总是试图兼顾两个世界中的最佳。因此，一个简单的方法是使用`plotly`包中的`ggplotly`命令，并将其传递给`ggplot2`绘图。这将使绘图变得交互！
- en: Hopefully, this section has made clear why the EDA workflow makes using R and
    tools such as `ggplot2` and `leaflet` the best options. We’ve just scratched the
    surface on what’s possible, and if one decides to go deeper into the data visualization
    aspects, there are a ton of great resources available.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 希望本节已经清楚地说明了为什么EDA工作流程使得使用R和像`ggplot2`、`leaflet`这样的工具成为最佳选择。我们只是浅尝辄止了可能性，如果决定深入探索数据可视化方面，会有大量优秀的资源可供利用。
- en: Machine learning
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: Nowadays, data science is used almost synonymously with machine learning (ML).
    While there are many different workflows necessary for a data science project
    ([Figure 5-1](#meta_workflow)), ML often steals the focus of aspiring data scientists.
    This is partly due to an increasing growth surge in recent years due to the availability
    of large amounts of data, better computing resources (such as better CPUs and
    GPUs), and the need for predictions and automation in modern business. In the
    early days of the field, it was known under a different name - statistical learning.
    As previously mentioned, statistics has been historically the primary domain of
    R. Thus there were good tools available early on for doing ML in it. However,
    this has changed in recent years, and Python’s tools have mostly overtaken its
    statistical competitor.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，数据科学几乎与机器学习（ML）同义使用。尽管数据科学项目需要许多不同的工作流程（[图5-1](#meta_workflow)），但ML往往吸引了渴望成为数据科学家的人们的注意力。这在一定程度上是由于近年来数据量大幅增长、计算资源更好（如更好的CPU和GPU）以及现代业务中预测和自动化的需求。在该领域的早期阶段，它以另一种名称——统计学习——而闻名。正如之前提到的，统计学一直是R的主要领域。因此，早期进行ML有很好的工具可用。然而，这在近年来已经改变，Python的工具大多数已经取代了它的统计竞争对手。
- en: One can trace Python’s ML ecosystem’s success to one specific package - [`scikit-learn`](https://scikit-learn.org/stable/).
    Since its early versions, the core development team has focused on designing an
    accessible and easy-to-use API. They supported this with some of the most complete
    and accessible documentation available in the open-source world. It’s not only
    a reference documentation but contains excellent tutorials on various specific
    modern ML applications, such as [working with text data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html).
    `scikit-learn` provides access to almost all common ML algorithms out of the box^([7](ch05.xhtml#idm45127450113112)).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 可以追溯到Python的ML生态系统成功的一个特定包——[`scikit-learn`](https://scikit-learn.org/stable/)。自其早期版本以来，核心开发团队一直致力于设计一个易于访问和使用的API。他们支持这一点的方式是提供了一些在开源世界中最完整和易于访问的文档。这不仅仅是一个参考文档，还包括关于各种特定现代ML应用的优秀教程，例如[处理文本数据](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)。`scikit-learn`提供了几乎所有常见的ML算法的开箱即用^([7](ch05.xhtml#idm45127450113112))。
- en: 'Let’s have a look at some proof of why `scikit-learn` is so great for ML. First,
    we can demonstrate the model imports:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看一些证据，证明`scikit-learn`在ML中的出色之处。首先，我们可以展示模型的导入：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here we can already see how consistently those models are designed - similar
    to books in a well-organized library; everything is at the right place. ML algorithms
    in `scikit-learn` are grouped based on their similarities. In this example, tree-based
    methods such as Decision Tree belong to the `tree` module. In contrast, linear
    algorithms can be found in the `linear_model` one (i.e., if you want to perform
    a Lasso model, you can predictably find it in `linear_model.Lasso`). Such hierarchical
    design makes it easier to focus on writing code and not to search for documentation
    since any good autocomplete engine will find the relevant model for you.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经可以看到这些模型设计是多么的一致 - 就像一个组织良好的图书馆里的书籍一样；一切都在正确的位置。`scikit-learn`中的ML算法根据它们的相似性进行分组。在这个例子中，基于树的方法如决策树属于`tree`模块。相反，线性算法可以在`linear_model`模块中找到（例如，如果你想执行Lasso模型，你可以在`linear_model.Lasso`中可预见地找到它）。这种分层设计使得更容易专注于编写代码，而不是搜索文档，因为任何良好的自动完成引擎都会为您找到相关的模型。
- en: Note
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We discussed modules in [Chapter 3](ch03.xhtml#ch04), but it’s a concept that
    bears repeating since it might be confusing for some R users. Modules in Python
    are nothing more than collections of organized scripts (based on some similarities,
    such as “data_processing” for example), which allows them to be imported into
    your applications, improving readability and making the codebase more organized.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第3章](ch03.xhtml#ch04)讨论了模块，但这是一个需要重复的概念，因为它可能对一些R用户来说很令人困惑。Python中的模块仅仅是组织良好的脚本集合（例如，“data_processing”），允许它们被导入到您的应用程序中，提高可读性并使代码库更加组织化。
- en: 'Next, we need to prepare the data for modeling. An essential element of any
    ML project is splitting the data into train and test sets. While newer R packages
    such as `mlr` improve on this as well, `scikit-learn` has better (in terms of
    both consistency and syntax) functions available:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要为建模准备数据。任何机器学习项目的重要组成部分是将数据分割为训练集和测试集。虽然像`mlr`这样的新的R软件包在这方面也有所改进，但`scikit-learn`提供了更好（在一致性和语法上）的函数：
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Suppose we have been consistent in the steps before and have followed traditional
    ML convention. In that case, we have the `X` object to store our features and
    ``y'' - the labels (in the case of a supervised learning problemfootnote:[For
    those readers new to ML, supervised learning is concerned with prediction tasks
    where a target is available (label), as compared to unsupervised learning where
    it''s missing, and the prediction task is on uncovering groups in the data.]).
    In this case, the data will be randomly split. The official way to do this in
    R''s `mlr`` is:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在之前的步骤中保持了一致，并遵循了传统的机器学习约定。在这种情况下，我们有`X`对象来存储我们的特征和``y' - 标签（在监督学习问题中的标签）。在这种情况下，数据将会被随机分割。在R的`mlr`中，官方的做法是：
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This can be harder to understand, and if one needs documentation on how to
    perform a more advanced split, such as by stratification, there’s little available,
    and another package might be required, increasing the learning curve and cognitive
    load on the data scientist. `scikit-learn`, on the other hand, provides a handy
    function in `StratifiedShuffleSplit`. The capabilities only increase further when
    we start to perform the actual modeling:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能更难理解，如果需要关于如何执行更高级分割（例如分层）的文档，则几乎没有可用的内容，可能需要另一个软件包，这会增加数据科学家的学习曲线和认知负荷。另一方面，`scikit-learn`在`StratifiedShuffleSplit`中提供了一个方便的函数。当我们开始执行实际建模时，其功能只会进一步增强：
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'These three code lines are all we need to initialize the model with default
    parameters, fit (train) it on the training dataset, and predict on the test one.
    This pattern is consistent across projects (except for the model initialization,
    where one selects their algorithm of choice and its parameters - those do differ,
    of course). A visual comparison between several different packages (from other
    developers and purposes) is shown in [Figure 5-6](#consistent_api_ml). Finally,
    let’s compute some performance metrics; many of them are handily available:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这三行代码是初始化模型并使用默认参数进行拟合（训练），然后在测试集上进行预测的全部内容。这种模式在项目中保持一致（除了模型初始化，其中选择了自己喜欢的算法及其参数
    - 当然会有所不同）。其他开发者和用途的几个不同软件包之间的视觉比较显示在[图 5-6](#consistent_api_ml)中。最后，让我们计算一些性能指标；其中许多指标都很方便地提供：
- en: '[PRE8]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `metrics` module contains everything needed to check our model’s performance,
    with a simple and predictable Application Programming Interface (API). The pattern
    of `fit` and `predict` we saw earlier has been so influential in the open-source
    world that it has been widely adopted by other packages, such as `yellowbrick`
    (a package for model performance visualization):'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`metrics`模块包含了检查我们模型性能所需的一切，具有简单和可预测的应用程序接口（API）。我们之前看到的`fit`和`predict`模式在开源世界中产生了如此大的影响，以至于被其他软件包广泛采纳，例如`yellowbrick`（用于模型性能可视化的软件包）：'
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: There are many other visualizations available in `yellowbrick`, all obtained
    with a similar procedure. Some are presented in [Figure 5-5](#yellowbrick).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`yellowbrick`中还有许多其他可视化，所有这些可视化都是通过类似的过程获得的。其中一些显示在[图 5-5](#yellowbrick)中。'
- en: '![](Images/prds_0505.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0505.png)'
- en: Figure 5-5\. Different possible `yellowbrick` regression plots.
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-5\. 不同的`yellowbrick`回归图。
- en: The consistency and ease of use are among the significant reasons users want
    to use Python for ML. It enables the user to focus on the task at hand and not
    on writing code and sifting through tedious documentation pages. There were changes
    in R packages in recent years aiming at reducing those deficiencies. Such packages
    most notably include `mlr` and `tidymodels`. Still, they are not widely used,
    but perhaps this pattern can change in the future. There is an additional factor
    to consider here, which is similar to the ecosystem interoperability we saw in
    [Chapter 4](ch04.xhtml#ch05). `scikit-learn` works very well with other tools
    Python, which are necessary for the development and deployment of ML models. Such
    tools include database connections, high-performance computing packages, testing
    frameworks, and deployment frameworks. Writing the ML code in `scikit-learn` will
    enable the data scientists to be a more productive part of a data team (just imagine
    the expression of your data engineering colleagues’ faces when you deliver an
    `mlr` model to them for deployment).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性和易用性是用户希望使用Python进行ML的重要原因之一。它使用户能够专注于手头的任务，而不是编写代码和翻阅乏味的文档页面。近年来，R软件包有所改变，旨在减少这些缺陷。这些软件包包括`mlr`和`tidymodels`，但它们的使用并不广泛，但也许这种模式将来会改变。这里还有一个要考虑的额外因素，类似于我们在[第4章](ch04.xhtml#ch05)中看到的生态系统互操作性。`scikit-learn`与Python的其他工具非常配合，这些工具对于开发和部署ML模型至关重要。这些工具包括数据库连接、高性能计算包、测试框架和部署框架。在`scikit-learn`中编写ML代码将使数据科学家成为数据团队中更有生产力的一部分（想象一下，当您向数据工程同事交付一个`mlr`模型用于部署时，他们的表情会是什么样子）。
- en: '![](Images/prds_0506.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0506.png)'
- en: Figure 5-6\. API consistency overview in the Python ML ecosystem.
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-6\. Python ML生态系统中的API一致性概述。
- en: 'To wrap up this section, we can summarize the main points about the ML workflow
    and why Python tools better support it:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 总结这一节，我们可以总结关于ML工作流程和为何Python工具更好支持它的主要观点：
- en: Focus has moved to real-time predictions and automation.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 焦点已转向实时预测和自动化。
- en: The Python ML workflow provides a more consistent and easy-to-use API.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python ML工作流提供了一个更一致且易于使用的API。
- en: Python is more of a glue language ^([8](ch05.xhtml#idm45127449767160)), ideal
    for combining different software components (i.e.,frontend/backend and databases).
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python更像是一种粘合语言 ^([8](ch05.xhtml#idm45127449767160))，非常适合组合不同的软件组件（即前端/后端和数据库）。
- en: In the next section, we’ll go deeper into the third part of this list and demonstrate
    the recommended Data Engineering workflow.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将深入探讨此列表的第三部分，并展示推荐的数据工程工作流程。
- en: Data engineering
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据工程
- en: Despite the ML tools’ advancements in recent years, the completion rate of such
    projects in companies remains low. One reason which is often credited for this
    is the lack of data engineering (DE) support. To apply ML and advanced analytics,
    companies need the infrastructural foundation provided by data engineers, including
    databases, data processing pipelines, testing, and deployment tools. Of course,
    this forms a separate job title - data engineer. Still, data scientists need to
    interface (and sometimes implement themselves) with those technologies to ensure
    data science projects are completed successfully.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管近年来ML工具取得了进展，但企业中此类项目的完成率仍然较低。其中一个常被归因的原因是缺乏数据工程（DE）支持。为了应用ML和高级分析，企业需要数据工程师提供的基础设施，包括数据库、数据处理管道、测试和部署工具。当然，这形成了一个单独的职位
    - 数据工程师。但数据科学家仍需要与这些技术进行交互（有时甚至是实施），以确保数据科学项目成功完成。
- en: While DE is a massive field, we’ll focus on a subset for this section. We selected
    model deployment for this since it’s the most common DE workflow that a data scientist
    might need to participate in. So what is ML deployment? Most of the time, this
    means creating an application programming interface (API) and making it available
    to other applications, either internally or externally (to customers, this is
    called “exposing” an API, to be “consumed”). Commonly ML models are deployed via
    a REST interface^([9](ch05.xhtml#idm45127449761224)).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然DE是一个庞大的领域，但我们将在本节中关注其子集。我们选择了模型部署，因为这是数据科学家可能需要参与的最常见DE工作流程。那么什么是ML部署？大多数情况下，这意味着创建一个应用程序接口（API）并使其可供其他应用程序使用，无论是内部还是外部（向客户，“暴露”API，以被“消耗”）。通常，ML模型通过REST接口进行部署^([9](ch05.xhtml#idm45127449761224))。
- en: ML model deployment, compared to the other topics in this chapter, requires
    interfacing with many different technologies, not directly related to data science.
    These include web frameworks, CSS, HTML, JavaScript, cloud servers, load balancers,
    and others. Thus it’s not surprising that Python tools dominate here^([10](ch05.xhtml#idm45127449733704))
    - as we covered before, it’s a fantastic glue language.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 与本章其他主题相比，机器学习模型部署需要与许多不直接与数据科学相关的技术进行接口。这些技术包括Web框架、CSS、HTML、JavaScript、云服务器、负载均衡器等。因此，Python工具在这里占据主导地位^([10](ch05.xhtml#idm45127449733704))
    - 正如我们之前所讨论的，它是一种出色的胶水语言。
- en: Note
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The model deployment workflow requires code to be executed on other machines
    rather than the local one where the data scientist performs their daily work.
    This hits “it works on my machine” problem right on the head. There are different
    ways to deal with managing different environments consistently, ranging from simple
    to complex. A simple way to do this is to use a `requirements.txt` file, where
    all dependencies are specified. A more complex option, which is often used in
    large-scale, critical deployments, uses container solutions such as [Docker](https://www.docker.com/).
    This dependency management is much easier to achieve in Python than in R.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署的工作流程需要在数据科学家进行日常工作的本地机器之外的其他机器上执行代码。这正是“在我的机器上运行正常”问题的核心。处理不同环境一致性管理的方法有多种，从简单到复杂不等。一个简单的方法是使用`requirements.txt`文件，其中指定了所有的依赖关系。在大规模、关键的部署中经常使用的更复杂的选项是使用像[Docker](https://www.docker.com/)这样的容器解决方案。在Python中，与R相比，这种依赖管理要容易得多。
- en: One of the most popular tools to create an API is Python’s [Flask](https://flask.palletsprojects.com/en/1.1.x/)
    - a [micro-framework](https://en.wikipedia.org/wiki/Microframework#:~:text=A%20microframework%20is%20a%20term,Accounts%2C%20authentication%2C%20authorization%2C%20roles).
    It provides a minimalist interface that is easy to extend with other tools, such
    as ones providing user authentication or better design. To get started, we’ll
    go through a small example. We would need a typical Python installation with some
    other additional configurations such as a virtual environment^([11](ch05.xhtml#idm45127449727448))
    and a GUI to query the API. Let’s get started!
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 创建API的最流行工具之一是Python的[Flask](https://flask.palletsprojects.com/en/1.1.x/) -
    一个[微框架](https://en.wikipedia.org/wiki/Microframework#:~:text=A%20microframework%20is%20a%20term,Accounts%2C%20authentication%2C%20authorization%2C%20roles)。它提供了一个简约的接口，可以轻松地通过其他工具进行扩展，例如提供用户认证或更好的设计。为了开始，我们将通过一个小例子进行演示。我们需要一个典型的Python安装，以及其他一些额外的配置，如虚拟环境^([11](ch05.xhtml#idm45127449727448))和一个GUI来查询API。让我们开始吧！
- en: ML-focused API frameworks
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 专注于机器学习API的框架
- en: Recently competitors to Flask have sprung up. They serve the same purpose but
    with an increased focus on ML. Two popular examples include [BentoML](https://www.bentoml.ai/)
    and [FastAPI](https://fastapi.tiangolo.com/). Those frameworks provide you with
    some additional options that make ML deployment easier. Remember that Flask was
    initially built for web development APIs, and the needs of an ML project can be
    different.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，出现了一些与Flask竞争的框架。它们有着相同的目标，但更加专注于机器学习。两个流行的例子包括[BentoML](https://www.bentoml.ai/)和[FastAPI](https://fastapi.tiangolo.com/)。这些框架为你提供了一些额外的选项，使得机器学习部署更加容易。请记住，Flask最初是为了Web开发API而构建的，而机器学习项目的需求可能有所不同。
- en: We’ll be building an API that predicts housing prices^([12](ch05.xhtml#idm45127449720408)).
    It’s always prudent to start with the end goal in mind and how we’d like such
    a predictive model to be used by an external application or an end-user. In this
    case, we can imagine our API to be integrated into an online house rental portal.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建一个API来预测房价^([12](ch05.xhtml#idm45127449720408))。始终明智的做法是从最终目标出发，思考我们希望这样的预测模型如何被外部应用程序或最终用户使用。在这种情况下，我们可以想象我们的API被集成到一个在线房屋租赁门户中。
- en: 'For brevity, we’ll omit the model training part. Imagine that you have followed
    a traditional `scikit-learn` model development. The results of the predictive
    model are stored in a `.pkl` (`Pickle` object, the standard Python way to store
    objects on disk). This process is called serialization, and we need to do it to
    use the model in the API later:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，我们将省略模型训练部分。想象一下，您已经按照传统的`scikit-learn`模型开发过程进行了操作。预测模型的结果存储在一个`.pkl`（`Pickle`对象，标准的Python对象存储方式）文件中。这个过程称为序列化，我们需要这样做以便稍后在API中使用模型：
- en: '[PRE10]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can save this code in a script called `train_model.py`. By running it: `python
    train_model.py`, the pickled model will be produced and saved. [Figure 5-7](#ml_api_diagram)
    provides an overview of how the different components fit.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这段代码保存在一个名为 `train_model.py` 的脚本中。通过运行它：`python train_model.py`，将会生成并保存序列化模型。图
    5-7 提供了不同组件的概述。
- en: '![](Images/prds_0507.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0507.png)'
- en: Figure 5-7\. Example architecture for an ML API.
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-7\. ML API 的示例架构。
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[![1](Images/1.png)](#co_workflow_context_CO3-1)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_workflow_context_CO3-1)'
- en: We use this function to specify that the payload string object is actually a
    dictionary.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个函数来指定载荷字符串对象实际上是一个字典。
- en: '[![2](Images/2.png)](#co_workflow_context_CO3-2)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_workflow_context_CO3-2)'
- en: Here we create an object that holds the app.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个持有应用程序的对象。
- en: '[![3](Images/3.png)](#co_workflow_context_CO3-3)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_workflow_context_CO3-3)'
- en: In those several lines we load the serialized model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在那几行代码中，我们加载了序列化模型。
- en: '[![4](Images/4.png)](#co_workflow_context_CO3-4)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_workflow_context_CO3-4)'
- en: This Python decorator creates an “end-point” (see info box below).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Python 装饰器创建了一个“端点”（见下面的信息框）。
- en: '[![5](Images/5.png)](#co_workflow_context_CO3-5)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_workflow_context_CO3-5)'
- en: At this step, the serialised model is used for inference.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步中，序列化模型用于推断。
- en: '[![6](Images/6.png)](#co_workflow_context_CO3-6)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_workflow_context_CO3-6)'
- en: The inference results are returned in a JSON format.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 推断结果以 JSON 格式返回。
- en: This code is added to a file `app.py`. Once you execute this script, the command
    line will output a local URL. We can then use a tool such as Postman to query
    it^([13](ch05.xhtml#idm45127449396760)). Have a look at [Figure 5-8](#postman)
    to see how such a query works. Voilà - we built an ML API!
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码被添加到一个名为 `app.py` 的文件中。一旦你执行此脚本，命令行将输出一个本地 URL。然后我们可以使用诸如 Postman 等工具来查询它^([13](ch05.xhtml#idm45127449396760))。看一看图
    5-8，看看这样的查询是如何工作的。哇 - 我们构建了一个 ML API！
- en: Note
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In our example, the API provides just one functionality - the ability to predict
    a housing price on a dataset. Often in the real world, the same application might
    need to do different things. This is organized by creating different end-points.
    For example, there might be an end-point for triggering a data preparation script
    and a separate inference one.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，API 只提供了一个功能 - 在数据集上预测房价的能力。在现实世界中，同一个应用程序可能需要执行不同的任务。这通过创建不同的端点来组织。例如，可能会有一个端点用于触发数据准备脚本，另一个用于推断。
- en: '![](Images/prds_0508.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0508.png)'
- en: Figure 5-8\. Querying the ML API with Postman.
  id: totrans-134
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-8\. 使用 Postman 查询 ML API。
- en: Cloud deployment
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云部署
- en: After you’re done with writing and testing the ML API code, the next phase would
    be to deploy it. Of course, you could use your computer as a server and expose
    it to the internet, but you can imagine that doesn’t scale very well (you have
    to keep your machine running, and it might run out of resources). One of the significant
    changes seen in recent years in terms of DE tools is the advent of cloud computing.
    Cloud platforms such as Amazon Web Services (AWS), or Google Cloud Provider (GCP)
    provide you with excellent opportunities and deploy your apps. Your Flask API
    can be deployed via a cloud service such as [Elastic Beanstalk](https://aws.amazon.com/elasticbeanstalk/)
    or [Google App Engine](https://cloud.google.com/appengine).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写和测试 ML API 代码完成后，下一阶段将是部署它。当然，你可以使用你的计算机作为服务器并将其暴露在互联网上，但你可以想象这并不是很好扩展的（你必须让你的机器运行，并且它可能会耗尽资源）。近年来在
    DE 工具方面看到的一项重大变化是云计算的出现。云平台如亚马逊网络服务 (AWS) 或谷歌云服务提供商 (GCP) 为你提供了出色的机会和部署应用程序。你的
    Flask API 可以通过云服务，比如 [弹性 Beanstalk](https://aws.amazon.com/elasticbeanstalk/)
    或 [谷歌应用引擎](https://cloud.google.com/appengine) 进行部署。
- en: Due to the “glue-like” nature of Python packages, they dominate the DE workflow.
    If a data scientist can write such applications on their own in Python, the success
    of the complete data project is ensured.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Python 包的“胶水”特性，它们主导了 DE 工作流程。如果数据科学家可以自己用 Python 编写这样的应用程序，那么完整数据项目的成功就得到了保证。
- en: Reporting
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 报告
- en: Every data scientist is aware (perhaps painfully so) of how vital communication
    is for their daily work. It’s also an often underrated skill, so this mantra bears
    repeating. So, what is more important than one of the essential deliverables of
    a data science project - reporting your results?
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据科学家都知道（也许痛苦地知道）沟通对他们的日常工作有多么重要。这也是一个常常被低估的技能，所以这句口号值得重复。那么，还有什么比数据科学项目的一个重要成果
    - 报告你的结果更重要呢？
- en: There are different reporting methods available. The most typical use case for
    a data scientist is to create a document, or a slide deck, containing the results
    of the analysis they have performed on a dataset. This is usually a collection
    of visualizations with an associated text and a consistent storyline (i.e., going
    through the different stages of a project lifecycle - data importing, cleaning,
    and visualization). There are other situations where the report has to be referred
    to often and updated in real-time - called dashboards. And finally, some reports
    allow the end-user to explore them more interactively. We’ll go through those
    three report types in the following subsections.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的报告方法可供选择。对于数据科学家而言，最典型的用例是创建一个文档或幻灯片，其中包含他们对数据集进行的分析结果。这通常是一系列可视化图表，附带相关文本和一致的故事线（即通过项目生命周期的不同阶段
    - 数据导入、清洗和可视化）。还有其他情况，报告必须经常参考并实时更新 - 称为仪表板。最后，某些报告允许最终用户以更交互的方式探索它们。我们将在下面的小节中详细介绍这三种报告类型。
- en: Static reporting
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 静态报告
- en: 'The popularization of the markdown (MD) language helps data scientists focus
    on writing code and associated thoughts instead of the tool itself. A flavor of
    this language - R Markdown (RMD) is widely used in the R community. This allows
    for the concept of “literate programming”, where the code is mixed with the analysis.
    The RStudio IDE provides even further functionality with tools such as [R notebooks](https://rmarkdown.rstudio.com/lesson-10.html).
    This is how easy writing an RMD report is:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Markdown（MD）语言的普及帮助数据科学家专注于编写代码和相关思想，而不是工具本身。这种语言的一种变体 - R Markdown（RMD）在R社区广泛使用。这允许实现“文学编程”的概念，其中代码与分析混合。RStudio
    IDE提供了进一步的功能，如[R笔记本](https://rmarkdown.rstudio.com/lesson-10.html)。编写RMD报告是如此简单：
- en: '[PRE13]{r}'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE13]{r}'
- en: library(dplyr)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: library(dplyr)
- en: data(starwars)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: data(starwars)
- en: '[PRE14]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This `.rmd` file can then be `knit` (compiled) into a `.pdf` or an `.html` (best
    for interactive plots), creating a beautiful report. There are additional templates
    to create even slides, dashboards and websites from RMD files. Have a look at
    [Figure 5-9](#example_rmd) to check it out in action.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`.rmd`文件可以被`knit`（编译）成`.pdf`或`.html`（适合交互式绘图），生成漂亮的报告。还有其他模板可以从RMD文件创建幻灯片、仪表板和网站。看看[图5-9](#example_rmd)来了解其运作方式。
- en: '![](Images/prds_0509.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0509.png)'
- en: Figure 5-9\. RMarkdown editing within RStudio
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-9\. 在RStudio内编辑RMarkdown
- en: As with everything in the open-source world, data scientists worldwide have
    contributed to the further development of RMD. There are many templates available
    for RMD, enabling users to create everything from a custom-styled report to a
    dynamically generated blogging website.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 就像开源世界中的所有事物一样，全球的数据科学家们为RMD的进一步发展做出了贡献。有许多RMD模板可供使用，使用户能够创建从定制样式报告到动态生成的博客网站的各种内容。
- en: Note
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The widely adopted alternative to RMD in the Python world is the [Jupyter](https://jupyter.org/)
    Notebook (along with its newer version - [Jupyter Lab](https://jupyterlab.readthedocs.io/en/stable/)).
    The “r” in Jupyter stands for R, and it is certainly possible to use that, but
    we argue that the RMD notebooks in RStudio provide a better interface, at least
    for R work.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python世界中广泛采用的RMD替代品是[Jupyter](https://jupyter.org/) Notebook（以及其更新版本 - [Jupyter
    Lab](https://jupyterlab.readthedocs.io/en/stable/)）。Jupyter中的“r”代表R语言，虽然可以使用它，但我们认为RStudio中的RMD笔记本提供了更好的界面，至少适用于R工作。
- en: Interactive reporting
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交互式报告
- en: What if we want to be able to let the recipients of our report do some work
    as well? If we allow for some interactivity, our end-users would answer questions
    for themselves without relying on us to go back, change the code and regenerate
    the graphs. There are several tools available^([14](ch05.xhtml#idm45127449354904)),
    but most of them pale in comparison to the ease of use and capabilities of R’s
    `shiny` package^([15](ch05.xhtml#idm45127449353176)).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望让报告的接收者也能做些工作怎么办？如果允许一些互动，我们的最终用户将能够自行回答问题，而无需依赖我们返回修改代码并重新生成图形。有几种工具可用^([14](ch05.xhtml#idm45127449354904))，但大多数与R的`shiny`包^([15](ch05.xhtml#idm45127449353176))相比显得逊色。
- en: 'Using this package requires a bit of a different way of writing R code, but
    you will create fantastic applications once you get used to it. Let’s go through
    a basic yet practical example. `shiny` apps consist of two fundamental elements:
    the user interface (UI) and the server logic. Those are often even separated into
    two files. For simplicity we’ll use the single file layout and use two functions
    for the app.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个包需要一种稍微不同的方式编写R代码，但一旦你习惯了，你将能够创建出色的应用程序。让我们通过一个基本但实用的例子来了解。`shiny`应用程序由两个基本元素组成：用户界面（UI）和服务器逻辑。通常这两者甚至分别放在两个文件中。为了简单起见，我们将使用单文件布局，并使用两个函数来构建应用程序。
- en: '[PRE15]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[![1](Images/1.png)](#co_workflow_context_CO4-1)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_workflow_context_CO4-1)'
- en: This function specifies that we want to have a “fluid” layout - that makes the
    app “responsive” - easy to read on a variety of devices, such as smartphones.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数指定了我们希望具有“流体”布局 - 这使得应用程序“响应式”，可以在各种设备上轻松阅读，例如智能手机。
- en: '[![2](Images/2.png)](#co_workflow_context_CO4-2)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_workflow_context_CO4-2)'
- en: Add the dynamic input for the user.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为用户添加动态输入。
- en: '[![3](Images/3.png)](#co_workflow_context_CO4-3)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_workflow_context_CO4-3)'
- en: Add a dedicated area for the output.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一个专门用于输出的区域。
- en: 'The `ui` object contains all the “frontend” parts of the application. The actual
    computation happens in the following function; we’ll be adding the `ggplot` from
    the DV section:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`ui`对象包含应用程序的所有“前端”部分。实际计算发生在以下函数中；我们将从DV部分添加`ggplot`：'
- en: '[PRE16]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[![1](Images/1.png)](#co_workflow_context_CO5-1)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_workflow_context_CO5-1)'
- en: 'The server needs two things: input and output.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器需要两样东西：输入和输出。
- en: '[![2](Images/2.png)](#co_workflow_context_CO5-2)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_workflow_context_CO5-2)'
- en: There is just one output in our case.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中只有一个输出。
- en: '[![3](Images/3.png)](#co_workflow_context_CO5-3)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_workflow_context_CO5-3)'
- en: We can add all kinds of R computations here, as in a regular R script.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这里添加各种R计算，就像在常规的R脚本中一样。
- en: '[![4](Images/4.png)](#co_workflow_context_CO5-4)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_workflow_context_CO5-4)'
- en: The most recent item (in this case, a plot) is returned for display in the frontend.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的项目（在本例中是图）被返回以在前端显示。
- en: The computation happens in this function. In the end, we need to pass those
    two functions here to start the app. The results of this are shown on [Figure 5-10](#shiny_example).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 计算发生在此函数中。最后，我们需要在这里传递这两个函数以启动应用程序。这些结果显示在[图5-10](#shiny_example)中。
- en: '[PRE17]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](Images/prds_0510.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0510.png)'
- en: Figure 5-10\. An interactive report with Shiny.
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-10\. 使用Shiny创建的交互式报告。
- en: One difference for our Shiny app that might make it tricky to use than our markdown
    files is that you would need to host the application on a remote machine. For
    a normal `.rmd` on the files, you need to knit the file into a PDF and then share
    it. How such applications are deployed is beyond this book’s scope.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的Shiny应用程序与Markdown文件的一个不同之处可能会让它比较难以使用，那就是你需要将应用程序托管在远程机器上。对于普通的`.rmd`文件，你需要将文件编织成PDF然后分享。这类应用程序的部署方式超出了本书的范围。
- en: Creating reports is a small but vital component of data science work. This is
    how your work is shown to the outside world, be it your manager or another department.
    Even if you have done a great job in your analysis, it will often be judged by
    how well you communicate the process and results. Tools of literate programming
    such as RMD and more advanced interactive reports in `shiny` can go a long way
    to creating a state of the art reports. In the final chapter of this book, [Chapter 7](ch07.xhtml#ch08),
    we’ll provide a great example of this in action.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 创建报告是数据科学工作的一个小但至关重要的组成部分。这是展示你的工作给外界的方式，无论是你的经理还是其他部门。即使你在分析上做得很出色，通常也会根据你如何有效地传达过程和结果来评判。文学编程工具如RMD和更高级的交互式报告在`shiny`中可以极大地帮助创建最先进的报告。在本书的最后一章，[第7章](ch07.xhtml#ch08)，我们将提供一个很好的实例。
- en: Final thoughts
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结思考
- en: In this chapter,, we went through the most essential workflows in a data science
    project and discovered the best tools in R and Python. In terms of EDA and reporting,
    R can be crowned the king. Packages such as `ggplot2` are peerless in the data
    science community, and `shiny` can allow for fascinating new ways to present data
    science results to stakeholders and colleagues. In the ML and DE worlds, Python’s
    glue-like nature provides fantastic options, enabling modern data scientists to
    focus on the work rather than the tools.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了数据科学项目中最基本的工作流程，并发现了在R和Python中最好的工具。在探索性数据分析（EDA）和报告方面，R可以称为王者。像`ggplot2`这样的包在数据科学社区中无与伦比，而`shiny`则可以以迷人的新方式呈现数据科学结果给利益相关者和同事们。在机器学习和数据工程领域，Python的类似胶水的特性提供了出色的选择，使现代数据科学家能够专注于工作而非工具。
- en: ^([1](ch05.xhtml#idm45127450420728-marker)) It’s a bit unfair to present `matplotlib`
    as the only viable alternative from Python. The [seaborn](https://seaborn.pydata.org/)
    package also enables the creation of beautiful plots quickly but still lags behind
    the `ggplot` features. It’s worth mentioning that newer versions of `pandas` have
    plotting capabilities as well, so we should watch this space.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch05.xhtml#idm45127450420728-marker)) 将`matplotlib`作为Python中唯一可行的替代方案显得有些不公平。`seaborn`包也能够快速创建漂亮的图表，但在`ggplot`功能方面仍有所不足。值得一提的是，`pandas`的新版本也具有绘图功能，因此我们应密切关注这一领域的发展。
- en: ^([2](ch05.xhtml#idm45127450414536-marker)) There have been attempts to recreate
    this package in Python, such as [ggplot](https://pypi.org/project/ggplot/) but
    they have not caught on in the community so far.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch05.xhtml#idm45127450414536-marker)) 已经有尝试在Python中重建这个包，比如[ggplot](https://pypi.org/project/ggplot/)，但目前在社区中并没有流行起来。
- en: ^([3](ch05.xhtml#idm45127450412248-marker)) He wrote many other packages, and
    in some ways almost single-handedly changed the way people use R in a modern context.
    Have a look at [Chapter 2](ch02.xhtml#ch03) for more information on his packages.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch05.xhtml#idm45127450412248-marker)) 他编写了许多其他包，并在某些方面几乎单枪匹马地改变了人们在现代环境中使用R的方式。详细信息请参阅[第2章](ch02.xhtml#ch03)了解他的包。
- en: ^([4](ch05.xhtml#idm45127450403976-marker)) More information on the dataset
    is available [here](https://rdrr.io/cran/dplyr/man/starwars.html).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch05.xhtml#idm45127450403976-marker)) 数据集的更多信息请参见[这里](https://rdrr.io/cran/dplyr/man/starwars.html)。
- en: ^([5](ch05.xhtml#idm45127450350536-marker)) Did you know that his real name
    is Jabba Desilijic Tiure?
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch05.xhtml#idm45127450350536-marker)) 你知道他的真名是贾巴·迪斯利吉克·提乌雷吗？
- en: ^([6](ch05.xhtml#idm45127450129960-marker)) Explore the official documentation
    [here](https://rstudio.github.io/leaflet/) for different map styles.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch05.xhtml#idm45127450129960-marker)) 探索不同地图样式的官方文档可以在[这里](https://rstudio.github.io/leaflet/)找到。
- en: ^([7](ch05.xhtml#idm45127450113112-marker)) An overview of those is available
    [here](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch05.xhtml#idm45127450113112-marker)) 可以在[这里](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)找到这些的概述。
- en: ^([8](ch05.xhtml#idm45127449767160-marker)) For a visual appreciation of the
    complexity of ML architectures, have a look at [this](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)
    MLOps document from Google.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch05.xhtml#idm45127449767160-marker)) 想要对机器学习架构的复杂性有更直观的了解，请查看来自Google的[这篇](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)MLOps文档。
- en: ^([9](ch05.xhtml#idm45127449761224-marker)) To learn more about what is REST,
    have a look at [this](https://en.wikipedia.org/wiki/Representational_state_transfer)
    resource.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch05.xhtml#idm45127449761224-marker)) 想要了解更多关于REST的信息，请参考[这个](https://en.wikipedia.org/wiki/Representational_state_transfer)资源。
- en: ^([10](ch05.xhtml#idm45127449733704-marker)) The R alternative to Flask is `plumber`.
    The RStudio IDE provides a friendly interface to use this tool, but still, it
    is lagging in options and adoption in the ML community.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch05.xhtml#idm45127449733704-marker)) Flask在R中的替代方案是`plumber`。RStudio
    IDE提供了友好的界面来使用这个工具，但在机器学习社区中仍然存在选项和采用上的差距。
- en: ^([11](ch05.xhtml#idm45127449727448-marker)) For brevity, we will not go deeper
    into setting up virtual environments here. We urge the dedicated reader to read
    up upon the [`virtualenv`](https://virtualenv.pypa.io/en/latest/) and [`renv`](https://rstudio.github.io/renv/articles/renv.html)
    tools, covered in [Chapter 3](ch03.xhtml#ch04).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch05.xhtml#idm45127449727448-marker)) 为了简洁起见，我们不会在这里深入探讨设置虚拟环境的问题。我们建议有兴趣的读者阅读[`virtualenv`](https://virtualenv.pypa.io/en/latest/)和[`renv`](https://rstudio.github.io/renv/articles/renv.html)工具的相关内容，这些内容在[第3章](ch03.xhtml#ch04)中有所涵盖。
- en: ^([12](ch05.xhtml#idm45127449720408-marker)) The dataset is “Boston Housing”,
    available [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch05.xhtml#idm45127449720408-marker)) 数据集是“波士顿房屋”，可以在[这里](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)找到。
- en: ^([13](ch05.xhtml#idm45127449396760-marker)) If you are more of a command-line
    person, have a look at `curl`.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch05.xhtml#idm45127449396760-marker)) 如果你更喜欢命令行，可以看看`curl`。
- en: ^([14](ch05.xhtml#idm45127449354904-marker)) There’s an advanced new tool in
    Python, called [streamlit](https://www.streamlit.io/), but it is yet to gain in
    popularity and adoption.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch05.xhtml#idm45127449354904-marker)) Python 中有一个先进的新工具，称为[streamlit](https://www.streamlit.io/)，但它还没有普及和广泛采用。
- en: ^([15](ch05.xhtml#idm45127449353176-marker)) To get inspired with what’s possible
    in Shiny, look at the gallery of use cases at the [RStudio website](https://shiny.rstudio.com/gallery/).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch05.xhtml#idm45127449353176-marker)) 要想了解 Shiny 的可能性，可以看看[RStudio 网站](https://shiny.rstudio.com/gallery/)上的使用案例库。
