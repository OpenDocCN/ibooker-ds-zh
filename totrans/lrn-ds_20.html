<html><head></head><body><section data-pdf-bookmark="Chapter 15. Linear Models" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch-linear">&#13;
<h1><span class="label">Chapter 15. </span>Linear Models</h1>&#13;
&#13;
<p>At this point in the book<a contenteditable="false" data-primary="linear modeling" data-type="indexterm" id="ix_lin_mod_ch15"/>, we’ve covered the four stages of the data science lifecycle to different extents. We’ve talked about formulating questions and obtaining and cleaning data, and we’ve used exploratory data analysis to better understand the data. In this chapter, we extend the constant model introduced in <a class="reference internal" data-type="xref" href="ch04.html#ch-modeling">Chapter 4</a> to the <em>linear model</em>. Linear models are a popular tool in the last stage of the lifecycle: understanding the world.</p>&#13;
&#13;
<p>Knowing how to fit linear models opens the door to all kinds of useful data analyses. We can use these models<a contenteditable="false" data-primary="predictions and predicting" data-type="indexterm" id="id1573"/> to make <em>predictions</em>—for example, environmental scientists developed a linear model to predict air quality based on air sensor measurements and weather conditions (see <a class="reference internal" data-type="xref" href="ch12.html#ch-pa">Chapter 12</a>). In that case study, understanding how measurements from two instruments varied enabled us to calibrate inexpensive sensors and improve their air quality readings. We can also use these models<a contenteditable="false" data-primary="inferences" data-seealso="theory for inference and prediction" data-type="indexterm" id="id1574"/> to make <em>inferences</em> about the form of a relationship between features—for example, in <a class="reference internal" data-type="xref" href="ch18.html#ch-donkey">Chapter 18</a> we’ll see how veterinarians used a linear model to infer the coefficients for length and girth for a donkey’s weight: <span><math> <mi>L</mi> <mi>e</mi> <mi>n</mi> <mi>g</mi> <mi>t</mi> <mi>h</mi> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <mn>2</mn> <mo>×</mo> <mi>G</mi> <mi>i</mi> <mi>r</mi> <mi>t</mi> <mi>h</mi> <mtext> </mtext> <mo>−</mo> <mtext> </mtext> <mn>175</mn> </math></span>. In that case study, the model enables vets working in the field to prescribe medication for sick donkeys. Models can also help <em>describe relationships</em> and provide insights—for example, in this chapter we explore relationships between factors correlated with upward mobility, such as commute time, income inequality, and the quality of K–12 education. We carry out a descriptive analysis that follows an analysis social scientists have used to shape public conversation and inform policy recommendations.</p>&#13;
&#13;
<p>We start by describing the simple linear model, which summarizes the relationship between two features with a line. We explain how to fit this line to data using the loss minimization approach introduced in <a class="reference internal" data-type="xref" href="ch04.html#ch-modeling">Chapter 4</a>. Then we introduce the multiple linear model, which models one feature using multiple other features. To fit such a model, we use linear algebra and reveal the geometry behind fitting a linear model with squared error loss. Finally, we cover feature engineering techniques that let us include categorical features and transformed features when building models.</p>&#13;
&#13;
&#13;
<section data-pdf-bookmark="Simple Linear Model" data-type="sect1"><div class="sect1" id="sec-linear-simple">&#13;
<h1>Simple Linear Model</h1>&#13;
&#13;
<p>Like with the constant model<a contenteditable="false" data-primary="simple linear model" data-type="indexterm" id="ix_sim_lin_mod"/><a contenteditable="false" data-primary="linear modeling" data-secondary="simple model" data-type="indexterm" id="ix_lin_mod_sim"/><a contenteditable="false" data-primary="linear modeling" data-secondary="fitting the model" data-type="indexterm" id="ix_lin_mod_fit_mod"/><a contenteditable="false" data-primary="fitting the model" data-secondary="simple linear model" data-type="indexterm" id="ix_fit_sim_lin_mod"/>, our goal is to approximate the signal in a feature by a constant. Now we have additional information from a second feature to help us. In short, we want to use information from a second feature to make a better model than the constant model. For example, we might describe the sale price of a house by its size or predict a donkey’s weight from its length. In each of these examples, we have an <em>outcome</em> feature (sale price, weight) that we want to explain, describe, or predict with the help of an <em>explanatory</em> feature (house size, length).</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>We use <em>outcome</em> to refer<a contenteditable="false" data-primary="outcome, model" data-type="indexterm" id="id1575"/> to the feature<a contenteditable="false" data-primary="machine learning" data-type="indexterm" id="id1576"/> that we are trying to model and <em>explanatory</em> for the feature that we are using to explain the outcome. Different fields have adopted conventions for describing this relationship. Some call the outcome the dependent variable and the explanatory the independent variable. Others use response and covariate; regress and regressor; explained and explanatory; endogenous and exogenous. In machine learning, <em>target</em> and <em>features</em> or <em>predicted</em> and <em>predictors</em> are common. Unfortunately, many of these pairs connote a causal relationship. The notion of explaining or predicting is not necessarily meant to imply that one causes the other. Particularly confusing is the independent-dependent usage, and we recommend avoiding it.</p>&#13;
</div>&#13;
&#13;
<p>One possible model we might use is a line. Mathematically, that means we have an intercept, <span><math> <msub> <mi>θ</mi> <mn>0</mn> </msub> </math></span>, and a slope, <span><math> <msub> <mi>θ</mi> <mn>1</mn> </msub> </math></span>, and we use the explanatory feature <span><math> <mi>x</mi> </math></span> to approximate the outcome, <span><math> <mi>y</mi> </math></span>, by a point on the line:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mi>y</mi> <mo>≈</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> </math></div>&#13;
</div>&#13;
&#13;
<p>As <span><math> <mi>x</mi> </math></span> changes, the estimate for <span><math> <mi>y</mi> </math></span> changes but still falls on the line. Typically, the estimate isn’t perfect, and there is some error in using the model; that’s why we use the symbol <span><math> <mo>≈</mo> </math></span> to mean “approximately.”</p>&#13;
&#13;
<p>To find<a contenteditable="false" data-primary="errors" data-secondary="linear model fitting" data-type="indexterm" id="id1577"/> a line that does a good job of capturing the signal in the outcome, we use the same approach introduced in <a class="reference internal" data-type="xref" href="ch04.html#ch-modeling">Chapter 4</a> and minimize the average squared loss. Specifically, we follow these steps:</p>&#13;
&#13;
<ol class="arabic simple">&#13;
	<li>&#13;
	<p>Find the errors: <span><math> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mo stretchy="false">(</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <mo>,</mo> <mtext> </mtext> <mi>i</mi> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo>…</mo> <mo>,</mo> <mi>n</mi> </math></span></p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Square the errors (i.e., use squared loss): <span><math> <mo stretchy="false">[</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mo stretchy="false">(</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <msup> <mo stretchy="false">]</mo> <mn>2</mn> </msup> </math></span></p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Calculate the average loss over the data:</p>&#13;
	<div data-type="equation">&#13;
	<div><math display="block"> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mo stretchy="false">[</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mo stretchy="false">(</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <msup> <mo stretchy="false">]</mo> <mn>2</mn> </msup> </math></div>&#13;
	</div>&#13;
	</li>&#13;
</ol>&#13;
&#13;
&#13;
<p>To fit the model, we find the slope and intercept that give us the smallest average loss; in other words, we minimize<a contenteditable="false" data-primary="mean squared error (MSE)" data-type="indexterm" id="id1578"/><a contenteditable="false" data-primary="MSE (mean squared error)" data-type="indexterm" id="id1579"/> the <em>mean squared error</em>, or MSE for short. We call the minimizing values for the intercept and slope <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> </math></span> and <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> </math></span>.</p>&#13;
&#13;
<p>Notice that the errors we calculate in step 1 are measured in the vertical direction, meaning for a specific <span><math> <mi>x</mi> </math></span>, the error is the vertical distance between the data point <span><math> <mo stretchy="false">(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> </math></span> and the point on the line <span><math> <mo stretchy="false">(</mo> <mi>x</mi> <mo>,</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> <mo stretchy="false">)</mo> </math></span>. <a class="reference internal" data-type="xref" href="#fig-slr">Figure 15-1</a> shows this notion. On the left is a scatterplot of points with a line used to estimate <span><math> <mi>y</mi> </math></span> from <span><math> <mi>x</mi> </math></span>. We have marked two specific points by squares and their corresponding approximations on the line by diamonds. The dotted segment from the actual point to the line shows the error. The plot on the right is a scatterplot of all the errors; for reference, we marked the errors corresponding to the two square points in the left plot with squares in the right plot as well.</p>&#13;
&#13;
<figure><div class="figure" id="fig-slr"><img src="assets/leds_1501.png"/>&#13;
<h6><span class="label">Figure 15-1. </span>On the left is a scatterplot of <span><math> <mo stretchy="false">(</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </math></span> pairs and a line that we use to estimate <span><math> <mi>y</mi> </math></span> from <span><math> <mi>x</mi> </math></span>. Two specific points are represented by squares and their estimates by diamonds. On the right is a scatterplot of the errors: <span><math> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mo stretchy="false">(</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </math></span>.</h6>&#13;
</div></figure>&#13;
&#13;
<p>Later in this chapter, we derive the values <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> </math></span> and <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> </math></span> that minimize the mean squared error. We show that these are:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> </mtd> <mtd> <mi/> <mo>=</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> </mtd> </mtr> <mtr> <mtd> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> </mtd> <mtd> <mi/> <mo>=</mo> <mi>r</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo>,</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> <mfrac> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> </mfrac> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>Here, <span><math> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> </math></span> represents the values <span><math> <msub> <mi>x</mi> <mn>1</mn> </msub> <mo>,</mo> <mo>…</mo> <mo>,</mo> <msub> <mi>x</mi> <mi>n</mi> </msub> </math></span> and <span><math> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> </math></span> is similarly defined; <span><math> <mi>r</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo>,</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </math></span> is the <a contenteditable="false" data-primary="correlation coefficient" data-type="indexterm" id="id1580"/>correlation coefficient of the <span><math> <mo stretchy="false">(</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </math></span> pairs.</p>&#13;
&#13;
<p>Putting the two together, the equation for the line becomes:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> <mo>+</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <mi>x</mi> </mtd> <mtd> <mi/> <mo>=</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>+</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <mi>x</mi> </mtd> </mtr> <mtr> <mtd/> <mtd> <mi/> <mo>=</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>+</mo> <mi>r</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo>,</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> <mfrac> <mrow> <mo stretchy="false">(</mo> <mi>x</mi> <mo>−</mo> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> </mrow> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> </mfrac> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>This equation has a nice interpretation: for a given <span><math> <mi>x</mi> </math></span> value, we find how many standard deviations above (or below) average it is, and then we predict (or explain, depending on the setting) <span><math> <mi>y</mi> </math></span> to be <span><math> <mi>r</mi> </math></span> times as many standard deviations above (or below) its average.</p>&#13;
&#13;
<p>We see from the expression<a contenteditable="false" data-primary="sample correlation coefficient" data-type="indexterm" id="id1581"/> for the optimal line that the <em>sample correlation coefficient</em> plays an important role. Recall that <span><math> <mi>r</mi> </math></span> measures the strength of the linear association and is defined as:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mi>r</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo>,</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> <mo>=</mo> <munder> <mo>∑</mo> <mi>i</mi> </munder> <mfrac> <mrow> <mo stretchy="false">(</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> </mrow> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> </mfrac> <mfrac> <mrow> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> </mrow> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> </mfrac> </math></div>&#13;
</div>&#13;
&#13;
<p>Here are a few important features of the correlation that help us fit linear models:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p><span><math> <mi>r</mi> </math></span> is unitless. Notice that <span><math> <mi>x</mi> </math></span>, <span><math> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> </math></span>, and <span><math> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </math></span> all have the same units, so the following ratio has no units (and likewise for the terms involving <span><math> <msub> <mi>y</mi> <mi>i</mi> </msub> </math></span>):</p>&#13;
&#13;
	<div data-type="equation">&#13;
		<math display="block"> <mfrac> <mrow> <mo stretchy="false">(</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> </mrow> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> </mfrac> </math>&#13;
		</div>&#13;
	</li>&#13;
	<li>&#13;
	<p><span><math> <mi>r</mi> </math></span> is between <span><math> <mo>−</mo> <mn>1</mn> </math></span> and <span><math> <mo>+</mo> <mn>1</mn> </math></span>. Only when all of the points fall exactly along a line is the correlation either <span><math> <mo>+</mo> <mn>1</mn> </math></span> or <span><math> <mo>−</mo> <mn>1</mn> </math></span>, depending on whether the slope of the line is positive or negative.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p><span><math> <mi>r</mi> </math></span> measures the strength of a linear association, not whether or not the data have a linear association. The four scatterplots<a contenteditable="false" data-primary="Anscombe’s quartet" data-type="indexterm" id="id1582"/> in <a class="reference internal" data-type="xref" href="#fig-anscombequartet">Figure 15-2</a> all have the same correlation coefficient of about <span><math> <mn>0.8</mn> </math></span> (as well as the same averages and standard <span class="keep-together">deviations</span>), but only one plot, the one on the top left, has what we think of as a linear association with random errors about the line.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<figure><div class="figure" id="fig-anscombequartet"><img src="assets/leds_1502.png"/>&#13;
<h6><span class="label">Figure 15-2. </span>These four sets of points, known as Anscombe’s quartet, have the same correlation of 0.8, and the same means and standard deviations. The plot in the top left exhibits a linear association; top right shows a perfect nonlinear association; bottom left, with the exception of one point, is a perfect linear association; and bottom right, with the exception of one point, has no association.</h6>&#13;
</div></figure>&#13;
&#13;
<p>Again, we do not expect the pairs of data points to fall exactly along a line, but we do expect the scatter of points to be reasonably described by the line, and we expect the deviations between <span><math> <msub> <mi>y</mi> <mi>i</mi> </msub> </math></span> and the estimate <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> <mo>+</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> </math></span> to be roughly symmetrically distributed about the line with no apparent patterns.</p>&#13;
&#13;
<p>Linear models were introduced in <a class="reference internal" data-type="xref" href="ch12.html#ch-pa">Chapter 12</a>, where we used the relationship between measurements from high-quality air monitors operated by the Environmental Protection Agency and neighboring inexpensive air quality monitors to calibrate the inexpensive monitors for more accurate predictions. We revisit that example to make the notion of a simple linear model more concrete<a contenteditable="false" data-primary="" data-startref="ix_fit_sim_lin_mod" data-type="indexterm" id="id1583"/><a contenteditable="false" data-primary="" data-startref="ix_lin_mod_fit_mod" data-type="indexterm" id="id1584"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Example: A Simple Linear Model for Air Quality" data-type="sect1"><div class="sect1" id="example-a-simple-linear-model-for-air-quality">&#13;
<h1>Example: A Simple Linear Model for Air Quality</h1>&#13;
&#13;
<p>Recall<a contenteditable="false" data-primary="air quality sensors study" data-secondary="linear model" data-type="indexterm" id="ix_aqs_lin_mod"/> from <a class="reference internal" data-type="xref" href="ch12.html#ch-pa">Chapter 12</a> that our aim is to use air quality measurements from the accurate Air Quality System (AQS) sensors operated by the US government to predict the measurements made by PurpleAir (PA) sensors. The pairs of data values come from neighboring instruments that measure the average daily concentration of particulate matter in the air on the same day. (The unit of measurement is an average count of particles under 2.5 mm in size per cubic liter of air in a 24-hour period.) In this section, we focus on air quality measurements at one location in Georgia. These are a subset of the data we examined in the case study in <a class="reference internal" data-type="xref" href="ch12.html#ch-pa">Chapter 12</a>. The measurements are daily averages from August 2019 to mid-November 2019:</p>&#13;
&#13;
&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>date</th>&#13;
			<th>id</th>&#13;
			<th>region</th>&#13;
			<th>pm25aqs</th>&#13;
			<th>pm25pa</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>5258</strong></td>&#13;
			<td>2019-08-02</td>&#13;
			<td>GA1</td>&#13;
			<td>Southeast</td>&#13;
			<td>8.65</td>&#13;
			<td>16.19</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>5259</strong></td>&#13;
			<td>2019-08-03</td>&#13;
			<td>GA1</td>&#13;
			<td>Southeast</td>&#13;
			<td>7.70</td>&#13;
			<td>13.59</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>5260</strong></td>&#13;
			<td>2019-08-04</td>&#13;
			<td>GA1</td>&#13;
			<td>Southeast</td>&#13;
			<td>6.30</td>&#13;
			<td>10.30</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>...</strong></td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>5439</strong></td>&#13;
			<td>2019-10-18</td>&#13;
			<td>GA1</td>&#13;
			<td>Southeast</td>&#13;
			<td>6.30</td>&#13;
			<td>12.94</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>5440</strong></td>&#13;
			<td>2019-10-21</td>&#13;
			<td>GA1</td>&#13;
			<td>Southeast</td>&#13;
			<td>7.50</td>&#13;
			<td>13.62</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>5441</strong></td>&#13;
			<td>2019-10-30</td>&#13;
			<td>GA1</td>&#13;
			<td>Southeast</td>&#13;
			<td>5.20</td>&#13;
			<td>14.55</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<pre>184 rows × 5 columns</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The feature <code>pm25aqs</code> contains measurements from the AQS sensor and <code>pm25pa</code> from the PurpleAir monitor. Since we are interested in studying how well the AQS measurements predict the PurpleAir measurements, our scatterplot places PurpleAir readings on the y-axis and AQS readings on the x-axis. We also add a trend line:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">scatter</code></span><span><code class="p">(</code></span><span><code class="n">GA</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s2">"</code><code class="s2">pm25aqs</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="s2">"</code><code class="s2">pm25pa</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">trendline</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">ols</code><code class="s1">'</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>           </code><span><code class="n">trendline_color_override</code></span><span><code class="o">=</code></span><span><code class="s2">"</code><code class="s2">darkorange</code><code class="s2">"</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>           </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="p">{</code></span><span><code class="s1">'</code><code class="s1">pm25aqs</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">AQS PM2.5</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">PurpleAir PM2.5</code><code class="s1">'</code></span><span><code class="p">}</code><code class="p">,</code></span><code>&#13;
</code><code>           </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">350</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">250</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_15in01.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>This scatterplot shows a linear relationship between the measurements from these two kinds of instruments. The model that we want to fit has the following form:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mi>P</mi> <mi>A</mi> <mo>≈</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>A</mi> <mi>Q</mi> </math></div>&#13;
</div>&#13;
&#13;
<p>where <span><math> <mi>P</mi> <mi>A</mi> </math></span> refers to the PurpleAir average daily measurement and <span><math> <mi>A</mi> <mi>Q</mi> </math></span> to its partner AQS measurement.</p>&#13;
&#13;
<p>Since <code>pandas.Series</code> objects have built-in methods to compute standard deviations (SDs) and correlation coefficients, we can quickly define functions that calculate the best-fitting line:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="k">def</code></span><code> </code><span><code class="nf">theta_1</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="n">r</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">.</code></span><span><code class="n">corr</code></span><span><code class="p">(</code></span><span><code class="n">y</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">r</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">.</code></span><span><code class="n">std</code></span><span><code class="p">(</code><code class="p">)</code></span><code> </code><span><code class="o">/</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">.</code></span><span><code class="n">std</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="k">def</code></span><code> </code><span><code class="nf">theta_0</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code><code class="p">)</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">theta_1</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Now we can fit the model by computing <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> </math></span> and <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> </math></span> for these data:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">t1</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">theta_1</code></span><span><code class="p">(</code></span><span><code class="n">GA</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25aqs</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">,</code></span><code> </code><span><code class="n">GA</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><span><code class="n">t0</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">theta_0</code></span><span><code class="p">(</code></span><span><code class="n">GA</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25aqs</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">,</code></span><code> </code><span><code class="n">GA</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Model: -3.36 + 2.10AQ&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>This model matches the trend line shown in the scatterplot. That’s not by accident. The parameter value for <code>trendline</code> in the call to <code>scatter()</code> is <code>"ols"</code>, which stands for <em>ordinary least squares</em>, another name for fitting a linear model by minimizing squared error.</p>&#13;
&#13;
<p>Let’s examine the errors<a contenteditable="false" data-primary="errors" data-secondary="air quality data" data-type="indexterm" id="ix_error_aqs"/>. First, we find the predictions for PA measurements given the AQS measurements, and then we calculate the errors—the difference between the actual PA measurements and the predictions:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">prediction</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">t0</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="n">t1</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="n">GA</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">pm25aqs</code><code class="s2">"</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="n">error</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">GA</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">pm25pa</code><code class="s2">"</code></span><span><code class="p">]</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">prediction</code></span><code>&#13;
</code><span><code class="n">fit</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">pd</code></span><span><code class="o">.</code></span><span><code class="n">DataFrame</code></span><span><code class="p">(</code></span><span><code class="nb">dict</code></span><span><code class="p">(</code></span><span><code class="n">prediction</code></span><span><code class="o">=</code></span><span><code class="n">prediction</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">error</code></span><span><code class="o">=</code></span><span><code class="n">error</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Let’s plot these errors against the predicted values:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">fig</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">scatter</code></span><span><code class="p">(</code></span><span><code class="n">fit</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">error</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">prediction</code><code class="s1">'</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="p">{</code></span><span><code class="s2">"</code><code class="s2">prediction</code><code class="s2">"</code></span><span><code class="p">:</code></span><code> </code><span><code class="s2">"</code><code class="s2">Prediction</code><code class="s2">"</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                         </code><span><code class="s2">"</code><code class="s2">error</code><code class="s2">"</code></span><span><code class="p">:</code></span><code> </code><span><code class="s2">"</code><code class="s2">Error</code><code class="s2">"</code></span><span><code class="p">}</code><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">350</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">250</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">add_hline</code></span><span><code class="p">(</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_width</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_dash</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">dash</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">opacity</code></span><span><code class="o">=</code></span><span><code class="mi">1</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">update_yaxes</code></span><span><code class="p">(</code></span><span><code class="nb">range</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="o">-</code></span><span><code class="mi">12</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">12</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_15in02.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>An error of 0 means<a contenteditable="false" data-primary="regression line" data-type="indexterm" id="id1585"/><a contenteditable="false" data-primary="least squares line" data-type="indexterm" id="id1586"/> that the actual measurement falls on the fitted line; we also call this line the <em>least squares line</em> or the <em>regression line</em>. A positive value means it is above the line, and negative means it’s below. You might be wondering how good this model is and what it says about our data. We consider these topics next.</p>&#13;
&#13;
<section data-pdf-bookmark="Interpreting Linear Models" data-type="sect2"><div class="sect2" id="interpreting-linear-models">&#13;
<h2>Interpreting Linear Models</h2>&#13;
&#13;
<p>The original<a contenteditable="false" data-primary="linear modeling" data-secondary="interpreting" data-type="indexterm" id="id1587"/> scatterplot of paired measurements shows that the PurpleAir recordings are often quite a bit higher than the more accurate AQS measurements. Indeed, the equation for our simple line model has a slope of about 2.1. We interpret the slope to mean that a change of 1 ppm measured by the AQS monitor is associated with a change of 2 ppm in the PA measurement, on average. So, if on one day the AQS sensor measures 10 ppm and on the next day it is 5 ppm higher, namely 15 ppm, then our prediction for the PA measurement increases from one day to the next by <span><math> <mn>2</mn> <mo>×</mo> <mn>5</mn> <mo>=</mo> <mn>10</mn> </math></span> ppm.</p>&#13;
&#13;
<p>Any change in the PurpleAir reading is not caused by the change in the AQS reading. Rather, they both reflect the air quality, and our model captures the relationship between the two devices. Oftentimes, the term <em>prediction</em> is taken to mean <em>causation</em>, but that is not the case here. Instead, the prediction just refers to our use of the <em>linear association</em> between PA and AQS measurements.</p>&#13;
&#13;
<p>As for the intercept in the model, we might expect it to be 0, since when there is no particulate matter in the air we would think that both instruments would measure 0 ppm. But for an AQS of 0, the model predicts <span><math> <mo>−</mo> <mn>3.4</mn> </math></span> ppm for PurpleAir, which doesn’t make sense. There can’t be negative amounts of particles in the air. This highlights the problem of using the model outside the range where measurements were taken. We observed AQS recordings between 3 and 18 ppm, and in this range the model fits well. While it makes sense for the line to have an intercept of 0, such a model doesn’t fit well in a practical sense and the predictions tend to be much worse.</p>&#13;
&#13;
<p>George Box, a renowned<a contenteditable="false" data-primary="Box, George" data-type="indexterm" id="id1588"/> statistician, famously said, “All models are wrong, but some are useful.” Here is a case where despite the intercept of the line not passing through 0, the simple linear model is useful in predicting air quality measurements for a PurpleAir sensor. Indeed, the correlation between our two features is very high:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">GA</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25aqs</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">]</code></span><span><code class="o">.</code></span><span><code class="n">corr</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>pm25aqs</th>&#13;
			<th>pm25pa</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>pm25aqs</strong></td>&#13;
			<td>1.00</td>&#13;
			<td>0.92</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>pm25pa</strong></td>&#13;
			<td>0.92</td>&#13;
			<td>1.00</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Aside from looking at correlation coefficients, there are other ways to assess the quality of a linear model.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Assessing the Fit" data-type="sect2"><div class="sect2" id="assessing-the-fit">&#13;
<h2>Assessing the Fit</h2>&#13;
&#13;
<p>The earlier<a contenteditable="false" data-primary="residuals" data-seealso="errors" data-type="indexterm" id="id1589"/><a contenteditable="false" data-primary="linear modeling" data-secondary="assessing the fit" data-type="indexterm" id="ix_lin_mod_fit1"/><a contenteditable="false" data-primary="fitting the model" data-secondary="assessing the fit" data-type="indexterm" id="ix_fit_mod_assess"/> plot of the errors against the fitted values gives a visual assessment of the quality of the fit. (This plot is called a <em>residual plot</em> because the errors are sometimes referred to as <em>residuals</em>.) A good fit should show a cloud of points around the horizontal line at 0 with no clear pattern. When there is a pattern, we can usually conclude that the simple linear model doesn’t entirely capture the signal. We saw earlier that there are no apparent patterns in the residual plot.</p>&#13;
&#13;
<p>Another type of residual plot that can be useful is a plot of the residuals against a feature that is not in the model. If we see a pattern, then we may want to include this feature in the model, in addition to the feature(s) already in the model. Also, when the data have a time component, we want to check for patterns in the residuals over time. For these particular data, since the measurements are daily averages over a four-month period, we plot the error against the date the measurement is recorded:</p>&#13;
&#13;
<figure class="informal width-75"><div class="figure"><img src="assets/leds_15in03.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>It looks like there are a few consecutive days near the end of August and again near the end of September where the data are far below what is expected. Looking back at the original scatterplot (and the first residual plot), we can see two small clusters of horizontal points below the main point cloud. The plot we just made indicates that we should check the original data and any available information about the equipment to determine whether it was properly functioning on those days.</p>&#13;
&#13;
<p>The residual plot can also give us a general sense of how accurate the model is in its predictions. Most of the errors lie between <span><math> <mo>±</mo> <mn>6</mn> </math></span> ppm of the line. And we find the standard deviation of the errors to be about 2.8 ppm:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">error</code></span><span><code class="o">.</code></span><span><code class="n">std</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
2.796095864304746&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>In comparison, the standard deviation of the PurpleAir measurements is quite a bit larger:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">GA</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">]</code></span><span><code class="o">.</code></span><span><code class="n">std</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
6.947418231019876&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The model error may be further reduced if we find the monitor wasn’t working on those days in late August and September and so exclude them from the dataset. In any event, for situations where the air is quite clean, the error is relatively large, but in absolute terms it is inconsequential. We are typically more concerned about the case when there is air pollution, and in that case, an error of 2.8 ppm seems reasonable.</p>&#13;
&#13;
<p>Let’s return to the process of how to find this line, the process of <em>model fitting</em>. In the next section, we derive the intercept and slope by minimizing the mean squared error<a contenteditable="false" data-primary="" data-startref="ix_fit_mod_assess" data-type="indexterm" id="id1590"/><a contenteditable="false" data-startref="ix_lin_mod_fit" data-type="indexterm" id="id1591"/><a contenteditable="false" data-primary="" data-startref="ix_error_aqs" data-type="indexterm" id="id1592"/>.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Fitting the Simple Linear Model" data-type="sect1"><div class="sect1" id="sec-linear-simple-fit">&#13;
<h1>Fitting the Simple Linear Model</h1>&#13;
&#13;
<p>We stated<a contenteditable="false" data-primary="fitting the model" data-secondary="simple linear model" data-type="indexterm" id="ix_fit_mod_simp"/><a contenteditable="false" data-primary="linear modeling" data-secondary="fitting the model" data-type="indexterm" id="ix_lin_mod_fit2"/> earlier in this chapter that when we minimize the average loss over the data:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mo stretchy="false">[</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mo stretchy="false">(</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <msup> <mo stretchy="false">]</mo> <mn>2</mn> </msup> </math></div>&#13;
</div>&#13;
&#13;
<p>the best-fitting line has intercept and slope:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> </mtd> <mtd> <mi/> <mo>=</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> </mtd> </mtr> <mtr> <mtd> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> </mtd> <mtd> <mi/> <mo>=</mo> <mi>r</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo>,</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> <mfrac> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> </mfrac> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>In this section, we use calculus to derive these results.</p>&#13;
&#13;
<p>With the simple linear model, the mean squared error is a function of two model parameters, the intercept and slope. This means that if we use calculus to find the minimizing parameter values, we need to find the partial derivatives of the MSE with respect to <span><math> <msub> <mi>θ</mi> <mn>0</mn> </msub> </math></span> and <span><math> <msub> <mi>θ</mi> <mn>1</mn> </msub> </math></span>. We can also find these minimizing values through other <span class="keep-together">techniques</span>:</p>&#13;
&#13;
<dl class="simple myst">&#13;
	<dt><em>Gradient descent</em></dt>&#13;
	<dd>&#13;
	<p>We can use numerical<a contenteditable="false" data-primary="gradient descent" data-type="indexterm" id="id1593"/> optimization techniques, such as gradient descent, when the loss function is more complex and it’s faster to find an approximate solution that’s pretty accurate (see <a class="reference internal" data-type="xref" href="ch20.html#ch-gd">Chapter 20</a>).</p>&#13;
	</dd>&#13;
	<dt><em>Quadratic formula</em></dt>&#13;
	<dd>&#13;
	<p>Since the average<a contenteditable="false" data-primary="quadratic function, linear model" data-type="indexterm" id="id1594"/> loss is a quadratic function of <span><math> <msub> <mi>θ</mi> <mn>0</mn> </msub> </math></span> and <span><math> <msub> <mi>θ</mi> <mn>1</mn> </msub> </math></span>, we can use the quadratic formula (along with some algebra) to solve for the minimizing parameter values.</p>&#13;
	</dd>&#13;
	<dt><em>Geometric argument</em></dt>&#13;
	<dd>&#13;
	<p>Later in this chapter<a contenteditable="false" data-primary="least squares method" data-type="indexterm" id="id1595"/>, we use a geometric interpretation of least squares to fit multiple linear models. This approach relates to the Pythagorean theorem and has several intuitive benefits.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>We choose calculus to optimize the simple linear model since it is quick and straightforward. To begin, we take the partial derivatives of the sum of squared errors with respect to each parameter (we can ignore the e<span><math> <mn>1</mn> <mrow> <mo>/</mo> </mrow> <mi>n</mi> </math></span> in the MSE because it doesn’t affect the location of the minimum):</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mfrac> <mi>∂</mi> <mrow> <mi>∂</mi> <msub> <mi>θ</mi> <mn>0</mn> </msub> </mrow> </mfrac> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mo stretchy="false">[</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mo stretchy="false">(</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <msup> <mo stretchy="false">]</mo> <mn>2</mn> </msup> </mtd> <mtd> <mi/> <mo>=</mo> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mn>2</mn> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>−</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <mo stretchy="false">(</mo> <mo>−</mo> <mn>1</mn> <mo stretchy="false">)</mo> </mtd> </mtr> <mtr> <mtd/> <mtd/> </mtr> <mtr> <mtd> <mfrac> <mi>∂</mi> <mrow> <mi>∂</mi> <msub> <mi>θ</mi> <mn>1</mn> </msub> </mrow> </mfrac> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mo stretchy="false">[</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mo stretchy="false">(</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <msup> <mo stretchy="false">]</mo> <mn>2</mn> </msup> <mo>,</mo> </mtd> <mtd> <mi/> <mo>=</mo> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mn>2</mn> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>−</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <mo stretchy="false">(</mo> <mo>−</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>Then we set the partial derivatives equal to 0 and simplify a bit by multiplying both sides of the equations by <span><math> <mo>−</mo> <mn>1</mn> <mrow> <mo>/</mo> </mrow> <mn>2</mn> </math></span> to get:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mn>0</mn> </mtd> <mtd> <mi/> <mo>=</mo> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> <mo>−</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </mtd> </mtr> <mtr> <mtd> <mn>0</mn> </mtd> <mtd> <mi/> <mo>=</mo> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> <mo>−</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>These equations<a contenteditable="false" data-primary="normal equations" data-type="indexterm" id="id1596"/> are called the <em>normal equations</em>. In the first equation, we see that <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> </math></span> can be represented as a function of <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> </math></span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> <mo>=</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> </math></div>&#13;
</div>&#13;
&#13;
<p>Plugging this value into the second equation gives us:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mn>0</mn> </mtd> <mtd> <mi/> <mo>=</mo> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>+</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> </mtd> </mtr> <mtr> <mtd/> <mtd> <mi/> <mo>=</mo> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mo stretchy="false">[</mo> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> <mo>−</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <mo stretchy="false">(</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> <mo stretchy="false">]</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> </mtd> </mtr> <mtr> <mtd> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> </mtd> <mtd> <mi/> <mo>=</mo> <mfrac> <mrow> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> </mrow> <mrow> <munder> <mo>∑</mo> <mrow> <mi>i</mi> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> </mrow> </mfrac> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>After some algebra, we can represent <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> </math></span> in terms of quantities that we are familiar with:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <mo>=</mo> <mi>r</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo>,</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> <mfrac> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> </mfrac> </math></div>&#13;
</div>&#13;
&#13;
<p>As shown earlier in this chapter, this representation says that a point on the fitted line at <span><math> <mi>x</mi> </math></span> can be written as follows:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> <mo>+</mo> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> <mi>x</mi> <mo>=</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>+</mo> <mi>r</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo>,</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> <mfrac> <mrow> <mo stretchy="false">(</mo> <mi>x</mi> <mo>−</mo> <mrow> <mover> <mi>x</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> </mrow> <mrow> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mrow> <mi mathvariant="bold">x</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </mrow> </mfrac> </math></div>&#13;
</div>&#13;
&#13;
<p>We have derived<a contenteditable="false" data-primary="scikit-learn library" data-secondary="linear modeling" data-type="indexterm" id="id1597"/> the equation for the least squares line that we used in the previous section. There, we used the <code>pandas</code> built-in methods to compute <span><math> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mo stretchy="false">)</mo> </math></span>, <span><math> <mi>S</mi> <mi>D</mi> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo stretchy="false">)</mo> </math></span>, and <span><math> <mi>r</mi> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mo>,</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo stretchy="false">)</mo> </math></span>, to easily calculate the equation for this line. However, in practice we recommend using the functionality provided in <code>scikit-learn</code> to do the model fitting:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">sklearn</code><code class="nn">.</code><code class="nn">linear_model</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">LinearRegression</code></span><code> </code><code>&#13;
</code><code>&#13;
</code><span><code class="n">y</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">GA</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="n">x</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">GA</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25aqs</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">]</code></span><code>&#13;
</code><span><code class="n">reg</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Our fitted model is:</p>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Model: PA estimate = -3.36 + 2.10AQS&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Notice<a contenteditable="false" data-primary="LinearRegression" data-type="indexterm" id="id1598"/> that we provided <code>y</code> as an array and <code>x</code> as a dataframe to <code>LinearRegression</code>. We will soon see why when we fit multiple explanatory features in a model.</p>&#13;
&#13;
<p>The <code>LinearRegression</code> method offers numerically stable algorithms to fit linear models by least squares. This is especially important when fitting multiple variables, which we introduce next<a contenteditable="false" data-primary="" data-startref="ix_fit_mod_simp" data-type="indexterm" id="id1599"/><a contenteditable="false" data-startref="ix_lin_mod_fit2" data-type="indexterm" id="id1600"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Multiple Linear Model" data-type="sect1"><div class="sect1" id="sec-linear-multi">&#13;
<h1>Multiple Linear Model</h1>&#13;
&#13;
<p>So far in this chapter<a contenteditable="false" data-primary="multiple linear model" data-type="indexterm" id="ix_multi_lin_mod"/><a contenteditable="false" data-primary="linear modeling" data-secondary="multiple linear model" data-type="indexterm" id="ix_lin_mod_multi"/>, we’ve used a single input variable to predict an outcome variable. Now we introduce the <em>multiple linear model</em> that uses more than one feature to predict (or describe or explain) the outcome. Having multiple explanatory features can improve our model’s fit to the data and improve predictions.</p>&#13;
&#13;
<p>We start by generalizing from a simple linear model to one that includes a second explanatory variable, called <span><math> <mi>v</mi> </math></span>. This model is linear in both <span><math> <mi>x</mi> </math></span> and <span><math> <mi>v</mi> </math></span>, meaning that for a pair of values for <span><math> <mi>x</mi> </math></span> and <span><math> <mi>v</mi> </math></span>, we can describe, explain, or predict <span><math> <mi>y</mi> </math></span> by the linear <span class="keep-together">combination</span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mi>y</mi> <mo>≈</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <mi>v</mi> </math></div>&#13;
</div>&#13;
&#13;
<p>Notice that for a particular value of <span><math> <mi>v</mi> </math></span>, say <span><math> <msup> <mi>v</mi> <mo>⋆</mo> </msup> </math></span>, we could express the preceding <span class="keep-together">equation</span> as:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mi>y</mi> <mo>≈</mo> <mo stretchy="false">(</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <msup> <mi>v</mi> <mo>⋆</mo> </msup> <mo stretchy="false">)</mo> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> </math></div>&#13;
</div>&#13;
&#13;
<p>In other words, when we hold <span><math> <mi>v</mi> </math></span> constant at <span><math> <msup> <mi>v</mi> <mo>⋆</mo> </msup> </math></span>, we have a simple linear relation between <span><math> <mi>x</mi> </math></span> and <span><math> <mi>y</mi> </math></span> with slope <span><math> <msub> <mi>θ</mi> <mn>1</mn> </msub> </math></span> and intercept <span><math> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <msup> <mi>v</mi> <mo>⋆</mo> </msup> </math></span>. For a different value of <span><math> <mi>v</mi> </math></span>, say <span><math> <msup> <mi>v</mi> <mo>†</mo> </msup> </math></span>, we again have a simple linear relationship between <span><math> <mi>x</mi> </math></span> and <span><math> <mi>y</mi> </math></span>. The slope for <span><math> <mi>x</mi> </math></span> remains the same and the only change is the intercept, which is now <span><math> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <msup> <mi>v</mi> <mo>†</mo> </msup> </math></span>.</p>&#13;
&#13;
<p>With multiple linear regression, we need to remember to interpret the coefficient <span><math> <msub> <mi>θ</mi> <mn>1</mn> </msub> </math></span> of <span><math> <mi>x</mi> </math></span> in the presence of the other variables in the model. Holding fixed the values of the other variables in the model (that’s just <span><math> <mi>v</mi> </math></span> in this case), an increase of 1 unit in <span><math> <mi>x</mi> </math></span> corresponds to a <span><math> <msub> <mi>θ</mi> <mn>1</mn> </msub> </math></span> change in <span><math> <mi>y</mi> </math></span>, on average. One way to visualize this kind of multiple linear relationship is to create facets of scatterplots of <span><math> <mo stretchy="false">(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> </math></span> where in each plot the values of <span><math> <mi>v</mi> </math></span> are roughly the same. We make such a scatterplot for the air quality measurements next, and provide examples of additional visualizations and statistics to examine when fitting a multiple linear model.</p>&#13;
&#13;
<p>The scientists who studied the air quality monitors (see <a class="reference internal" data-type="xref" href="ch12.html#ch-pa">Chapter 12</a>) were looking for an improved model that incorporated weather factors. One weather variable they examined was a daily measurement for relative humidity. Let’s consider a two-variable linear model to explain the PurpleAir measurements based on the AQS sensor measurements and relative humidity. This model has the following form:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mi>P</mi> <mi>A</mi> <mo>≈</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>A</mi> <mi>Q</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <mi>R</mi> <mi>H</mi> </math></div>&#13;
</div>&#13;
&#13;
<p>where <span><math> <mi>P</mi> <mi>A</mi> </math></span>, <span><math> <mi>A</mi> <mi>Q</mi> </math></span>, and <span><math> <mi>R</mi> <mi>H</mi> </math></span> refer to the variables: the PurpleAir average daily measurement, AQS measurement, and relative humidity, respectively.</p>&#13;
&#13;
<p>For a first step, we make a facet plot to compare the relationship between the two air quality measurements for fixed values of humidity. To do this, we transform relative humidity to a categorical variable so that each facet consists of observations with similar humidity:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">rh_cat</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">pd</code></span><span><code class="o">.</code></span><span><code class="n">cut</code></span><span><code class="p">(</code></span><span><code class="n">GA</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">rh</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">,</code></span><code> </code><span><code class="n">bins</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="mi">43</code></span><span><code class="p">,</code></span><span><code class="mi">50</code></span><span><code class="p">,</code></span><span><code class="mi">55</code></span><span><code class="p">,</code></span><span><code class="mi">60</code></span><span><code class="p">,</code></span><span><code class="mi">78</code></span><span><code class="p">]</code><code class="p">,</code></span><code> </code><code>&#13;
</code><code>                </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">&lt;50</code><code class="s1">'</code></span><span><code class="p">,</code></span><span><code class="s1">'</code><code class="s1">50-55</code><code class="s1">'</code></span><span><code class="p">,</code></span><span><code class="s1">'</code><code class="s1">55-60</code><code class="s1">'</code></span><span><code class="p">,</code></span><span><code class="s1">'</code><code class="s1">&gt;60</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Then we use this qualitative feature to subdivide the data into a two-by-two panel of scatterplots:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">fig</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">scatter</code></span><span><code class="p">(</code></span><span><code class="n">GA</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">pm25aqs</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><code>&#13;
</code><code>                 </code><span><code class="n">facet_col</code></span><span><code class="o">=</code></span><span><code class="n">rh_cat</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">facet_col_wrap</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">facet_row_spacing</code></span><span><code class="o">=</code></span><span><code class="mf">0.15</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="p">{</code></span><span><code class="s1">'</code><code class="s1">pm25aqs</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">AQS PM2.5</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">PurpleAir PM2.5</code><code class="s1">'</code></span><span><code class="p">}</code><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">550</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">350</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">update_layout</code></span><span><code class="p">(</code></span><span><code class="n">margin</code></span><span><code class="o">=</code></span><span><code class="nb">dict</code></span><span><code class="p">(</code></span><span><code class="n">t</code></span><span><code class="o">=</code></span><span><code class="mi">30</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">show</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_15in04.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>These four plots show a linear relationship between the two sources of air quality measurements. And the slopes appear to be similar, which means that a multiple linear model may fit well. It’s difficult to see from these plots if the relative humidity affects the intercept much.</p>&#13;
&#13;
<p>We also want to examine the pairwise scatterplots between the three features. When two explanatory features are highly correlated, their coefficients in the model may be unstable. While linear relationships between three or more features may not show up in pairwise plots, it’s still a good idea to check:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">fig</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">scatter_matrix</code></span><span><code class="p">(</code></span><code>&#13;
</code><code>    </code><span><code class="n">GA</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="s1">'</code><code class="s1">pm25aqs</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="s1">'</code><code class="s1">rh</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">]</code><code class="p">,</code></span><code>&#13;
</code><code>    </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="p">{</code></span><span><code class="s1">'</code><code class="s1">pm25aqs</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">AQS</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">PurpleAir</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="s1">'</code><code class="s1">rh</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">Humidity</code><code class="s1">'</code></span><span><code class="p">}</code><code class="p">,</code></span><code>&#13;
</code><code>    </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">550</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">400</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">update_traces</code></span><span><code class="p">(</code></span><span><code class="n">diagonal_visible</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_15in05.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The relationship between humidity and air quality does not appear to be particularly strong. Another pairwise measure we should examine is the correlations between <span class="keep-together">features</span>:</p>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>pm25pa</th>&#13;
			<th>pm25aqs</th>&#13;
			<th>rh</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>pm25pa</strong></td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.95</td>&#13;
			<td class="right">-0.06</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>pm25aqs</strong></td>&#13;
			<td class="right">0.95</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">-0.24</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>rh</strong></td>&#13;
			<td class="right">-0.06</td>&#13;
			<td class="right">-0.24</td>&#13;
			<td class="right">1.00</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>One small surprise is that relative humidity has a small negative correlation with the AQS measurement of air quality. This suggests that humidity might be helpful in the model.</p>&#13;
&#13;
<p>In the next section, we derive the equation for the fit. But for now, we use the functionality in <code>LinearRegression</code> to fit the model. The only change from earlier is that we provide two columns for the explanatory variables (that’s why the <code>x</code> input is a dataframe):</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">sklearn</code><code class="nn">.</code><code class="nn">linear_model</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">LinearRegression</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">y</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">GA</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25pa</code><code class="s1">'</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="n">X2</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">GA</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">pm25aqs</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="s1">'</code><code class="s1">rh</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">]</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">model2</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">X2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The fitted multiple linear model, including the coefficient units, is:</p>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
PA estimate = -15.8 ppm + 2.25 ppm/ppm x AQS +  0.21 ppm/percent x RH&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The coefficient for humidity in the model adjusts the air quality prediction by 0.21 ppm for each percentage point of relative humidity. Notice that the coefficient for AQS differs from the simple linear model that we fitted earlier. This happens because the coefficient reflects the additional information coming from relative humidity.</p>&#13;
&#13;
<p>Lastly, to check the quality<a contenteditable="false" data-primary="errors" data-secondary="air quality data" data-type="indexterm" id="id1601"/><a contenteditable="false" data-primary="LinearRegression" data-type="indexterm" id="id1602"/> of the fit, we make residual plots of the predicted values and the errors. This time, we use <code>LinearRegression</code> to compute the predictions for us:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">predicted_2var</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">model2</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">X2</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">error_2var</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">y</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">predicted_2var</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">fig</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">scatter</code></span><span><code class="p">(</code></span><span><code class="n">y</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">error_2var</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="n">predicted_2var</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="p">{</code></span><span><code class="s2">"</code><code class="s2">y</code><code class="s2">"</code></span><span><code class="p">:</code></span><code> </code><span><code class="s2">"</code><code class="s2">Error</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">x</code><code class="s2">"</code></span><span><code class="p">:</code></span><code> </code><span><code class="s2">"</code><code class="s2">Predicted PurpleAir measurement</code><code class="s2">"</code></span><span><code class="p">}</code><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">350</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">250</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">update_yaxes</code></span><span><code class="p">(</code></span><span><code class="nb">range</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="o">-</code></span><span><code class="mi">12</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">12</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">add_hline</code></span><span><code class="p">(</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_width</code></span><span><code class="o">=</code></span><span><code class="mi">3</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_dash</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">dash</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">opacity</code></span><span><code class="o">=</code></span><span><code class="mi">1</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">show</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_15in06.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The residual plot appears to have no clear patterns, which indicates that the model fits pretty well. Notice also that the errors nearly all fall within –4 and +4 ppm, a smaller range than in the simple linear model. And we find the standard deviation of the residuals is quite a bit smaller:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">error_2var</code></span><span><code class="o">.</code></span><span><code class="n">std</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
1.8211427707294048&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The residual standard deviation has been reduced from 2.8 ppm in the one variable model to 1.8 ppm, a good size reduction.</p>&#13;
&#13;
<p>The correlation coefficient can’t capture the strength of a linear association model when we have more than one explanatory variable. Instead, we adapt the MSE to give us a sense of model fit. In the next section, we describe how to fit a multiple linear model and use the MSE to assess fit<a contenteditable="false" data-startref="ix_sim_lin_mod" data-type="indexterm" id="id1603"/><a contenteditable="false" data-startref="ix_lin_mod_sim" data-type="indexterm" id="id1604"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Fitting the Multiple Linear Model" data-type="sect1"><div class="sect1" id="sec-linear-multi-fit">&#13;
<h1>Fitting the Multiple Linear Model</h1>&#13;
&#13;
<p>In the previous section<a contenteditable="false" data-primary="linear modeling" data-secondary="fitting the model" data-type="indexterm" id="ix_lin_mod_multi_fit"/><a contenteditable="false" data-primary="fitting the model" data-secondary="multiple linear model" data-type="indexterm" id="ix_fit_mod_multi"/>, we considered the case of two explanatory variables; one of these we called <span><math> <mi>x</mi> </math></span> and the other <span><math> <mi>v</mi> </math></span>. Now we want to generalize the approach to <span><math> <mi>p</mi> </math></span> explanatory variables. The idea of choosing different letters to represent variables quickly fails us. Instead, we use a more formal and general approach that represents multiple predictors as a matrix, as depicted in <a class="reference internal" data-type="xref" href="#fig-design-matrix">Figure 15-3</a>. We call<a contenteditable="false" data-primary="design matrix" data-type="indexterm" id="id1605"/> <span><math> <mtext mathvariant="bold">X</mtext> </math></span> the <em>design matrix</em>. Notice that <span><math> <mtext mathvariant="bold">X</mtext> </math></span> has shape <span><math> <mi>n</mi> <mo>×</mo> <mo stretchy="false">(</mo> <mi>p</mi> <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> </math></span>. Each column of <span><math> <mtext mathvariant="bold">X</mtext> </math></span> represents a feature, and each row represents an observation. That is, <span><math> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>j</mi> </mrow> </msub> </math></span> is the measurement taken on observation <span><math> <mi>i</mi> </math></span> for feature <span><math> <mi>j</mi> </math></span>.</p>&#13;
&#13;
<figure><div class="figure" id="fig-design-matrix"><img src="assets/leds_1503.png"/>&#13;
<h6><span class="label">Figure 15-3. </span>In this design matrix <span><math> <mi>X</mi> </math></span>, each row represents an observation/record and each column a feature/variable</h6>&#13;
</div></figure>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>One technicality: the design matrix is defined as a mathematical matrix, not a dataframe, so you might notice that a matrix doesn’t include the column or row labels that a dataframe has.</p>&#13;
&#13;
<p>That said, we usually don’t have to worry about converting dataframes into matrices since most Python libraries for modeling treat dataframes of numbers as if they were matrices.</p>&#13;
</div>&#13;
&#13;
<p>For a given observation, say, the second row in <span><math> <mtext mathvariant="bold">X</mtext> </math></span>, we approximate the outcome <span><math> <msub> <mi>y</mi> <mn>2</mn> </msub> </math></span> by the linear combination:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <msub> <mi>y</mi> <mn>2</mn> </msub> <mo>≈</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mrow> <mn>2</mn> <mo>,</mo> <mn>1</mn> </mrow> </msub> <mo>+</mo> <mo>…</mo> <mo>+</mo> <msub> <mi>θ</mi> <mi>p</mi> </msub> <msub> <mi>x</mi> <mrow> <mn>2</mn> <mo>,</mo> <mi>p</mi> </mrow> </msub> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>It’s more convenient to express the linear approximation in matrix notation. To do this, we write the model parameters as a <span><math> <mi>p</mi> <mo>+</mo> <mn>1</mn> </math></span> column vector <span><math> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> </math></span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mrow> <mi>θ</mi> </mrow> <mo>=</mo> <mrow> <mo>[</mo> <mtable columnalign="center" columnspacing="1em" rowspacing="4pt"> <mtr> <mtd> <msub> <mi>θ</mi> <mn>0</mn> </msub> </mtd> </mtr> <mtr> <mtd> <msub> <mi>θ</mi> <mn>1</mn> </msub> </mtd> </mtr> <mtr> <mtd> <mrow> <mo>⋮</mo> </mrow> </mtd> </mtr> <mtr> <mtd> <msub> <mi>θ</mi> <mi>p</mi> </msub> </mtd> </mtr> </mtable> <mo>]</mo> </mrow> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>Putting these notational<a contenteditable="false" data-primary="matrix multiplication" data-type="indexterm" id="id1606"/> definitions together, we can write the vector of predictions for the entire dataset using matrix multiplication:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> </math></div>&#13;
</div>&#13;
&#13;
<p>If we check the dimensions of <span><math> <mtext mathvariant="bold">X</mtext> </math></span> and <span><math> <mi mathvariant="bold-italic">θ</mi> </math></span>, we can confirm that <span><math> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> </math></span> is an <span><math> <mi>n</mi> </math></span>-dimensional column vector. So the error in using this linear prediction can be expressed as the vector:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mrow> <mi mathvariant="bold">e</mi> </mrow> <mo>=</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo>−</mo> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> </math></div>&#13;
</div>&#13;
&#13;
<p>where the outcome variable is also represented as a column vector:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo>=</mo> <mrow> <mo>[</mo> <mtable columnalign="center" columnspacing="1em" rowspacing="4pt"> <mtr> <mtd> <msub> <mi>y</mi> <mn>1</mn> </msub> </mtd> </mtr> <mtr> <mtd> <msub> <mi>y</mi> <mn>2</mn> </msub> </mtd> </mtr> <mtr> <mtd> <mrow> <mo>⋮</mo> </mrow> </mtd> </mtr> <mtr> <mtd> <msub> <mi>y</mi> <mi>n</mi> </msub> </mtd> </mtr> </mtable> <mo>]</mo> </mrow> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>This matrix<a contenteditable="false" data-primary="errors" data-secondary="linear model fitting" data-type="indexterm" id="id1607"/> representation of the multiple linear model can help us find the model that minimizes mean squared error. Our goal is to find the model parameters <span><math> <mo stretchy="false">(</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>,</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mo>,</mo> <mo>…</mo> <mo>,</mo> <msub> <mi>θ</mi> <mi>p</mi> </msub> <mo stretchy="false">)</mo> </math></span> that minimize the mean squared error:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munder> <mo>∑</mo> <mi>i</mi> </munder> <mo stretchy="false">[</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mo stretchy="false">(</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mn>1</mn> </mrow> </msub> <mo>+</mo> <mo>⋯</mo> <mo>+</mo> <msub> <mi>θ</mi> <mi>p</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>p</mi> </mrow> </msub> <mo stretchy="false">)</mo> <msup> <mo stretchy="false">]</mo> <mn>2</mn> </msup> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <mo fence="false" stretchy="false">‖</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo>−</mo> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> <msup> <mo fence="false" stretchy="false">‖</mo> <mn>2</mn> </msup> </math></div>&#13;
</div>&#13;
&#13;
<p>Here, we use<a contenteditable="false" data-primary="vector geometry" data-type="indexterm" id="id1608"/> the notation <span><math> <mo fence="false" stretchy="false">‖</mo> <mrow> <mi mathvariant="bold">v</mi> </mrow> <msup> <mo fence="false" stretchy="false">‖</mo> <mn>2</mn> </msup> </math></span> for a vector <span><math> <mrow> <mi mathvariant="bold">v</mi> </mrow> </math></span> as a shorthand for the sum of each vector element squared: <span><math> <mo fence="false" stretchy="false">‖</mo> <mrow> <mi mathvariant="bold">v</mi> </mrow> <msup> <mo fence="false" stretchy="false">‖</mo> <mn>2</mn> </msup> <mo>=</mo> <munder> <mo>∑</mo> <mi>i</mi> </munder> <msubsup> <mi>v</mi> <mi>i</mi> <mn>2</mn> </msubsup> </math></span>. The square root, <span><math> <msqrt> <mo fence="false" stretchy="false">‖</mo> <mrow> <mi mathvariant="bold">v</mi> </mrow> <msup> <mo fence="false" stretchy="false">‖</mo> <mn>2</mn> </msup> </msqrt> </math></span>, corresponds to the length of the vector <span><math> <mrow> <mi mathvariant="bold">v</mi> </mrow> </math></span> and is also called the <span><math> <msub> <mi>ℓ</mi> <mn>2</mn> </msub> </math></span> norm of <span><math> <mrow> <mi mathvariant="bold">v</mi> </mrow> </math></span>. So, minimizing the mean squared error is the same thing as finding the shortest error vector.</p>&#13;
&#13;
<p>We can fit our model using calculus as we did for the simple linear model. However, this approach gets cumbersome, and instead we use a geometric argument that is more intuitive and easily leads to useful properties of the design matrix, errors, and predicted values.</p>&#13;
&#13;
<p>Our goal is to find the parameter<a contenteditable="false" data-primary="vector space" data-type="indexterm" id="id1609"/> vector, which we call <span><math> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </math></span>, that minimizes our average squared loss—we want to make <span><math> <mo fence="false" stretchy="false">‖</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo>−</mo> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> <msup> <mo fence="false" stretchy="false">‖</mo> <mn>2</mn> </msup> </math></span> as small as possible for a given <span><math> <mtext mathvariant="bold">X</mtext> </math></span> and <span><math> <mrow> <mi mathvariant="bold">y</mi> </mrow> </math></span>. The key insight is that we can restate this goal in a geometric way. Since the model predictions and the true outcomes are both vectors, we can think of them as vectors in a <em>vector space</em>. When we change our model parameters <span><math> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> </math></span>, the model makes different predictions, but any prediction must be a linear combination of the column vectors of <span><math> <mrow> <mi mathvariant="bold">X</mi> </mrow> </math></span>; that is, the prediction must be in what is called <span><math> <mtext>span</mtext> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">X</mi> </mrow> <mo stretchy="false">)</mo> </math></span>. This notion is illustrated in <a class="reference internal" data-type="xref" href="#fig-spanx">Figure 15-4</a>, where the shaded region consists of the possible linear models. Notice that <span><math> <mrow> <mi mathvariant="bold">y</mi> </mrow> </math></span> is not entirely captured in <span><math> <mtext>span</mtext> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">X</mi> </mrow> <mo stretchy="false">)</mo> </math></span>; this is typically the case.</p>&#13;
&#13;
<figure><div class="figure" id="fig-spanx"><img src="assets/leds_1504.png"/>&#13;
<h6><span class="label">Figure 15-4. </span>In this simplified diagram, the space of all possible model prediction vectors <span><math> <mtext>span</mtext> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">X</mi> </mrow> <mo stretchy="false">)</mo> </math></span> is illustrated as a plane in three-dimensional space, and the observed <span><math> <mrow> <mi mathvariant="bold">y</mi> </mrow> </math></span> as a <span class="keep-together">vector</span></h6>&#13;
</div></figure>&#13;
&#13;
<p>Although the squared loss can’t be exactly zero because <span><math> <mrow> <mi mathvariant="bold">y</mi> </mrow> </math></span> isn’t in the <span><math> <mtext>span</mtext> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">X</mi> </mrow> <mo stretchy="false">)</mo> </math></span>, we can find the vector that lies as close to <span><math> <mrow> <mi mathvariant="bold">y</mi> </mrow> </math></span> as possible while still being in <span><math> <mtext>span</mtext> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">X</mi> </mrow> <mo stretchy="false">)</mo> </math></span>. This vector is called <span><math> <mrow> <mrow> <mover> <mi mathvariant="bold">y</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </mrow> </math></span>.</p>&#13;
&#13;
<p>The error is the vector <span><math> <mrow> <mi mathvariant="bold">e</mi> </mrow> <mo>=</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo>−</mo> <mrow> <mrow> <mover> <mi mathvariant="bold">y</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </mrow> </math></span>. Its length <span><math> <mo fence="false" stretchy="false">‖</mo> <mrow> <mi mathvariant="bold">e</mi> </mrow> <mo fence="false" stretchy="false">‖</mo> </math></span> represents the distance between the true outcome and our model’s prediction. Visually, <span><math> <mrow> <mi mathvariant="bold">e</mi> </mrow> </math></span> has the smallest magnitude when it is <em>perpendicular</em> to the <span><math> <mtext>span</mtext> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">X</mi> </mrow> <mo stretchy="false">)</mo> </math></span>, as shown in <a class="reference internal" data-type="xref" href="#fig-error-vector-optimal">Figure 15-5</a>. The proof of this fact is omitted, and we rely on the figures to convince you of it.</p>&#13;
&#13;
<figure><div class="figure" id="fig-error-vector-optimal"><img src="assets/leds_1505.png"/>&#13;
<h6><span class="label">Figure 15-5. </span>The mean squared error is minimized when the prediction <span><math> <mrow> <mrow> <mover> <mi mathvariant="bold">y</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </mrow> </math></span> lies in <span><math> <mtext>span</mtext> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">X</mi> </mrow> <mo stretchy="false">)</mo> </math></span> perpendicular to <span><math> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> </math></span></h6>&#13;
</div></figure>&#13;
&#13;
<p>The fact that the smallest error, <span><math> <mrow> <mi mathvariant="bold">e</mi> </mrow> </math></span>, must be perpendicular to <span><math> <mrow> <mrow> <mover> <mi mathvariant="bold">y</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </mrow> </math></span> lets us derive a formula for <span><math> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span> as follows:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left right" columnspacing="0em 2em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtext mathvariant="bold">X</mtext> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> <mo>+</mo> <mrow> <mi mathvariant="bold">e</mi> </mrow> </mtd> <mtd> <mi/> <mo>=</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mtd> <mtd> <mi/> <mo stretchy="false">(</mo> <mtext>the definition of </mtext> <mrow> <mi mathvariant="bold"> y</mi> </mrow> <mo>,</mo> <mrow> <mover> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo stretchy="false">^</mo> </mover> </mrow> <mo>,</mo> <mrow> <mi mathvariant="bold">e</mi> </mrow> <mo stretchy="false">)</mo> </mtd> </mtr> <mtr> <mtd> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mtext mathvariant="bold">X</mtext> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mo>+</mo> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mrow> <mi mathvariant="bold">e</mi> </mrow> </mtd> <mtd> <mi/> <mo>=</mo> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mtd> <mtd> <mi/> <mo stretchy="false">(</mo> <mtext>left-multiply by </mtext> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mo stretchy="false">)</mo> </mtd> </mtr> <mtr> <mtd> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mtext mathvariant="bold">X</mtext> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </mtd> <mtd> <mi/> <mo>=</mo> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mtd> <mtd> <mi/> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">e</mi> </mrow> <mo>⊥</mo> <mtext>span</mtext> <mo stretchy="false">(</mo> <mtext mathvariant="bold">X</mtext> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo> </mtd> </mtr> <mtr> <mtd> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </mtd> <mtd> <mi/> <mo>=</mo> <mo stretchy="false">(</mo> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mtext mathvariant="bold">X</mtext> <msup> <mo stretchy="false">)</mo> <mrow> <mo>−</mo> <mn>1</mn> </mrow> </msup> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mtd> <mtd> <mi/> <mo stretchy="false">(</mo> <mtext>left-multiply by </mtext> <mo stretchy="false">(</mo> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mtext mathvariant="bold">X</mtext> <msup> <mo stretchy="false">)</mo> <mrow> <mo>−</mo> <mn>1</mn> </mrow> </msup> <mo stretchy="false">)</mo> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>This general approach to derive <span><math> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </math></span> for the multiple linear model also gives us <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>0</mn> </msub> </math></span> and <span><math> <msub> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mn>1</mn> </msub> </math></span> for the simple linear model. If we set <span><math> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> </math></span> to be the two-column matrix that contains the intercept column and one feature column, this formula for <span><math> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </math></span> and some linear algebra gets the intercept and slope of the least-squares-fitted simple linear model. In fact, if <span><math> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> </math></span> is simply a single column of <span><math> <mn>1</mn> </math></span>s, then we can use this formula to show that <span><math> <mrow> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </mrow> </math></span> is just the mean of <span><math> <mrow> <mi mathvariant="bold">y</mi> </mrow> </math></span>. This nicely ties back to the constant model that we introduced in <a class="reference internal" data-type="xref" href="ch04.html#ch-modeling">Chapter 4</a>.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>While we can write a simple function to derive the <span><math> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </math></span> based on the formula</p>&#13;
&#13;
<div data-type="equation">&#13;
<math display="block"> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> <mo>=</mo> <mo stretchy="false">(</mo> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mtext mathvariant="bold">X</mtext> <msup> <mo stretchy="false">)</mo> <mrow> <mo>−</mo> <mn>1</mn> </mrow> </msup> <msup> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mi mathvariant="normal">⊤</mi> </msup> <mrow> <mi mathvariant="bold">y</mi> </mrow> </math>&#13;
</div>&#13;
&#13;
<p>we recommend leaving the calculation of <span><math> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </math></span> to the optimally tuned methods provided in the <code>scikit-learn</code> and <code>statsmodels</code> libraries. They handle cases where the design matrix is sparse, highly co-linear, and not invertible.</p>&#13;
</div>&#13;
&#13;
<p>This solution for <span><math> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </math></span> (along with the pictures) reveals some useful properties of the fitted coefficients and the predictions:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>The residuals, <span><math> <mrow> <mi mathvariant="bold">e</mi> </mrow> </math></span>, are orthogonal to the predicted values, <span><math> <mrow> <mover> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo stretchy="false">^</mo> </mover> </mrow> </math></span>.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>The average of the residuals is 0 if the model has an intercept term.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>The variance of the residuals is just the MSE.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>These properties explain why we examine plots of the residuals against the predictions. When we fit a multiple linear model, we also plot the residuals against variables that we are considering adding to the model. If they showed a linear pattern, then we would consider adding them to the model.</p>&#13;
&#13;
<p>In addition to examining<a contenteditable="false" data-primary="R² (coefficient of determination)" data-type="indexterm" id="id1610"/><a contenteditable="false" data-primary="multiple R²" data-type="indexterm" id="id1611"/> the SD of the errors, the ratio of the MSE for a multiple linear model to the MSE for the constant model gives a measure of the model fit. This is called the <em>multiple <span><math><msup><mi>R</mi> <mn>2</mn> </msup> </math></span></em> and is defined as:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <msup> <mi>R</mi> <mn>2</mn> </msup> <mo>=</mo> <mn>1</mn> <mo>−</mo> <mfrac> <mrow> <mo fence="false" stretchy="false">‖</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo>−</mo> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mrow> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </mrow> <msup> <mo fence="false" stretchy="false">‖</mo> <mn>2</mn> </msup> </mrow> <mrow> <mo fence="false" stretchy="false">‖</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <msup> <mo fence="false" stretchy="false">‖</mo> <mn>2</mn> </msup> </mrow> </mfrac> </math></div>&#13;
</div>&#13;
&#13;
<p>As the model fits the data closer and closer, the multiple <span><math> <msup> <mi>R</mi> <mn>2</mn> </msup> </math></span> gets nearer to 1. That might seem like a good thing, but there can be problems with this approach because <span><math> <msup> <mi>R</mi> <mn>2</mn> </msup> </math></span> continues to grow even as we add meaningless features to our model, as long as the features expand the <span><math> <mtext>span</mtext> <mo stretchy="false">(</mo> <mtext mathvariant="bold">X</mtext> <mo stretchy="false">)</mo> </math></span>. To account for the size of a model, we often adjust the numerator and denominator in <span><math> <msup> <mi>R</mi> <mn>2</mn> </msup> </math></span> by the number of fitted coefficients in the models. That is, we normalize the numerator by <span><math> <mn>1</mn> <mrow> <mo>/</mo> </mrow> <mo stretchy="false">[</mo> <mi>n</mi> <mo>−</mo> <mo stretchy="false">(</mo> <mi>p</mi> <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> <mo stretchy="false">]</mo> </math></span> and the denominator by <span><math> <mn>1</mn> <mrow> <mo>/</mo> </mrow> <mo stretchy="false">(</mo> <mi>n</mi> <mo>−</mo> <mn>1</mn> <mo stretchy="false">)</mo> </math></span>. Better approaches to selecting a model are covered in <a class="reference internal" data-type="xref" href="ch16.html#ch-risk">Chapter 16</a>.</p>&#13;
&#13;
<p>Next, we consider a social science example where there are many variables available to us for modeling<a contenteditable="false" data-primary="" data-startref="ix_fit_mod_multi" data-type="indexterm" id="id1612"/><a contenteditable="false" data-primary="" data-startref="ix_lin_mod_multi_fit" data-type="indexterm" id="id1613"/><a contenteditable="false" data-startref="ix_aqs_lin_mod" data-type="indexterm" id="id1614"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Example: Where Is the Land of Opportunity?" data-type="sect1"><div class="sect1" id="sec-linear-case">&#13;
<h1>Example: Where Is the Land of Opportunity?</h1>&#13;
&#13;
<p>The US is called<a contenteditable="false" data-primary="linear modeling" data-secondary="economic mobility example" data-type="indexterm" id="ix_lin_mod_mob"/><a contenteditable="false" data-primary="economic mobility example, linear models" data-type="indexterm" id="ix_eco_mob_lin_mod"/> “the land of opportunity” because people believe that even those with few resources can end up wealthy in the US—economists call this notion “economic mobility.” In one study, economist Raj Chetty and colleagues did a <a class="reference external" href="https://doi.org/10.1093/qje/qju022">large-scale data analysis on economic mobility in the US</a>. His basic question was whether the US is a land of opportunity. To answer this somewhat vague question, Chetty needed a way to measure economic mobility.</p>&#13;
&#13;
<p>Chetty had access to 2011–2012 federal income tax records for everyone born in the US between 1980 and 1982, along with their parents’ tax records filed in their birth year. They matched the 30-year-olds to their parents by finding the parents’ 1980–1982 tax records that listed them as dependents. In total, his dataset had about 10 million people. To measure economic mobility, Chetty grouped people born in a particular geographic region whose parents’ income was in the 25th income percentile in 1980–1982. He then found the group’s average income percentile in 2011. Chetty<a contenteditable="false" data-primary="AUM (absolute upward mobility)" data-type="indexterm" id="id1615"/><a contenteditable="false" data-primary="absolute upward mobility (AUM)" data-type="indexterm" id="id1616"/> calls this average <em>absolute upward mobility</em> (AUM). If a region’s AUM is 25, then people born into the 25th percentile generally stay in the 25th percentile—they remain where their parents were when they were born. High AUM values mean that the region has more upward mobility. Those born into the 25th income percentile in these regions generally wind up in a higher income bracket than their parents. For reference, the US average AUM is about 41 at the time of this writing. Chetty calculated the AUM for regions called commuting zones (CZs), which are roughly on the same scale as counties.</p>&#13;
&#13;
<p>While the granularity of the original data is at an individual level, the data Chetty analyzed has a granularity at the CZ level. Income records can’t be publicly available because of privacy laws, but the AUM for a commuting zone can be made available. However, even with the granularity of a commuting zone, not all commuting zones are included in the data set because with 40 features in the data, it might be possible to identify individuals in small CZs. This limitation points to a potential coverage bias. Measurement bias is another potential problem. For example, children born into the 25th income percentile who become extremely wealthy may not file income tax.</p>&#13;
&#13;
<p>We also point<a contenteditable="false" data-primary="ecological regression" data-type="indexterm" id="id1617"/> out the limitations of working with data that are regional averages rather than individual measurements. The relationships found among features are often more highly correlated at the aggregate level than at the individual level. This phenomenon is called <em>ecological regression</em>, and interpretations of findings from aggregated data need to be made with care.</p>&#13;
&#13;
<p>Chetty had a hunch that some places in the US have higher economic mobility than others. His analysis found this to be true. He found that some cities—such as San Jose, Calif.; Washington, DC; and Seattle—have higher mobility than others, such as Charlotte, N.C.; Milwaukee; and Atlanta. This means that, for example, people move from low to high income brackets in San Jose at a higher rate compared to Charlotte. Chetty used linear models to find that social and economic factors like segregation, income inequality, and local school systems are related to economic mobility.</p>&#13;
&#13;
<p>In this analysis, our outcome variable is the AUM for a commuting zone, since we are interested in finding features that correlate with AUM. There are many possible such features in Chetty’s data, but we first investigate one in particular: the fraction of people in a CZ who have a 15-minute or shorter commute to work.</p>&#13;
&#13;
<section data-pdf-bookmark="Explaining Upward Mobility Using Commute Time" data-type="sect2"><div class="sect2" id="explaining-upward-mobility-using-commute-time">&#13;
<h2>Explaining Upward Mobility Using Commute Time</h2>&#13;
&#13;
<p>We begin our investigation by loading the data into a dataframe called <code>cz_df</code>:</p>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>aum</th>&#13;
			<th>travel_lt15</th>&#13;
			<th>gini</th>&#13;
			<th>rel_tot</th>&#13;
			<th>...</th>&#13;
			<th>taxrate</th>&#13;
			<th>worked_14</th>&#13;
			<th>foreign</th>&#13;
			<th>region</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>0</strong></td>&#13;
			<td>38.39</td>&#13;
			<td>0.33</td>&#13;
			<td>0.47</td>&#13;
			<td>0.51</td>&#13;
			<td>...</td>&#13;
			<td>0.02</td>&#13;
			<td>3.75e-03</td>&#13;
			<td>1.18e-02</td>&#13;
			<td>South</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1</strong></td>&#13;
			<td>37.78</td>&#13;
			<td>0.28</td>&#13;
			<td>0.43</td>&#13;
			<td>0.54</td>&#13;
			<td>...</td>&#13;
			<td>0.02</td>&#13;
			<td>4.78e-03</td>&#13;
			<td>2.31e-02</td>&#13;
			<td>South</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2</strong></td>&#13;
			<td>39.05</td>&#13;
			<td>0.36</td>&#13;
			<td>0.44</td>&#13;
			<td>0.67</td>&#13;
			<td>...</td>&#13;
			<td>0.01</td>&#13;
			<td>2.89e-03</td>&#13;
			<td>7.08e-03</td>&#13;
			<td>South</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>...</strong></td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>702</strong></td>&#13;
			<td>44.12</td>&#13;
			<td>0.42</td>&#13;
			<td>0.42</td>&#13;
			<td>0.29</td>&#13;
			<td>...</td>&#13;
			<td>0.02</td>&#13;
			<td>4.82e-03</td>&#13;
			<td>9.85e-02</td>&#13;
			<td>West</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>703</strong></td>&#13;
			<td>41.41</td>&#13;
			<td>0.49</td>&#13;
			<td>0.41</td>&#13;
			<td>0.26</td>&#13;
			<td>...</td>&#13;
			<td>0.01</td>&#13;
			<td>4.39e-03</td>&#13;
			<td>4.33e-02</td>&#13;
			<td>West</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>704</strong></td>&#13;
			<td>43.20</td>&#13;
			<td>0.24</td>&#13;
			<td>0.42</td>&#13;
			<td>0.32</td>&#13;
			<td>...</td>&#13;
			<td>0.02</td>&#13;
			<td>3.67e-03</td>&#13;
			<td>1.13e-01</td>&#13;
			<td>West</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<pre>705 rows × 9 columns</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Each row represents one commuting zone. The column <code>aum</code> has the average AUM for people born in the commuting zone in 1980–1982 to parents in the 25th income <span class="keep-together">percentile</span>. There are many columns in this dataframe, but for now we focus on the fraction of people in a CZ that have a 15-minute or shorter commute time, which is called <code>travel_lt15</code>. We plot AUM against this fraction to look at the relationship between the two variables:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">scatter</code></span><span><code class="p">(</code></span><span><code class="n">cz_df</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">travel_lt15</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">aum</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">350</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">250</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>           </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="p">{</code></span><span><code class="s1">'</code><code class="s1">travel_lt15</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">Commute time under 15 min</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><code>&#13;
</code><code>                   </code><span><code class="s1">'</code><code class="s1">aum</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">Upward mobility</code><code class="s1">'</code></span><span><code class="p">}</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_15in07.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The scatterplot shows a rough linear association between AUM and commute time. Indeed, we find the correlation to be quite strong:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">cz_df</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">aum</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="s1">'</code><code class="s1">travel_lt15</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">]</code></span><span><code class="o">.</code></span><span><code class="n">corr</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>aum</th>&#13;
			<th>travel_lt15</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>aum</td>&#13;
			<td>1.00</td>&#13;
			<td>0.68</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>travel_lt15</td>&#13;
			<td>0.68</td>&#13;
			<td>1.00</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Let’s fit a simple linear model to explain AUM with commute time:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">sklearn</code><code class="nn">.</code><code class="nn">linear_model</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">LinearRegression</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">y</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">cz_df</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">aum</code><code class="s1">'</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="n">X</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">cz_df</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">travel_lt15</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">]</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">model_ct</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">X</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The coefficients from the MSE minimization are:</p>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Intercept: 31.3&#13;
    Slope: 28.7&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Interestingly, an increase in upward mobility of a CZ is associated with an increase in the fraction of people with a short commute time.</p>&#13;
&#13;
<p>We can compare<a contenteditable="false" data-primary="errors" data-secondary="linear model fitting" data-type="indexterm" id="id1618"/> the SD of the AUM measurements to the SD of the residuals. This comparison gives us a sense of how useful the model is in explaining the AUM:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">prediction</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">model_ct</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">X</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">error</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">y</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">prediction</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s2">"</code><code class="s2">SD(errors): </code></span><span><code class="si">{</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">std</code></span><span><code class="p">(</code></span><span><code class="n">error</code></span><span><code class="p">)</code></span><span><code class="si">:</code></span><span><code class="s2">.2f</code></span><span><code class="si">}</code></span><span><code class="s2">"</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s2">"</code><code class="s2">   SD(AUM): </code></span><span><code class="si">{</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">std</code></span><span><code class="p">(</code></span><span><code class="n">cz_df</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">aum</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">)</code></span><span><code class="si">:</code></span><span><code class="s2">.2f</code></span><span><code class="si">}</code></span><span><code class="s2">"</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
SD(errors): 4.14&#13;
   SD(AUM): 5.61&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The size of the errors about the regression line has decreased from the constant model by about 25%.</p>&#13;
&#13;
<p>Next, we examine the residuals for lack of fit since it can be easier to see potential problems with the fit in a residual plot:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">fig</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">scatter</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="n">prediction</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="n">error</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="nb">dict</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">Prediction for AUM</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">Error</code><code class="s1">'</code></span><span><code class="p">)</code><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">350</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">250</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">add_hline</code></span><span><code class="p">(</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_width</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_dash</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">dash</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">opacity</code></span><span><code class="o">=</code></span><span><code class="mi">1</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">update_yaxes</code></span><span><code class="p">(</code></span><span><code class="nb">range</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="o">-</code></span><span><code class="mi">20</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">15</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">show</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_15in08.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>It appears that the errors grow with AUM. We might try a transformation of the response variable, or fitting a model that is quadratic in the commute time fraction. We consider transformations and polynomials in the next section. First we see whether including additional variables offers a more accurate prediction of AUM.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Relating Upward Mobility Using Multiple Variables" data-type="sect2"><div class="sect2" id="relating-upward-mobility-using-multiple-variables">&#13;
<h2>Relating Upward Mobility Using Multiple Variables</h2>&#13;
&#13;
<p>In his original analysis, Chetty created several high-level features related to factors such as segregation, income, and K–12 education. We consider seven of Chetty’s predictors as we aim to build a more informative model for explaining AUM. These are described in <a class="reference internal" data-type="xref" href="#tbl-linear-predictors">Table 15-1</a>.</p>&#13;
&#13;
<table id="tbl-linear-predictors">&#13;
	<caption><span class="label">Table 15-1. </span><span>Potential explanation for modeling AUM</span></caption>&#13;
	<thead>&#13;
		<tr>&#13;
			<th class="head">Column name</th>&#13;
			<th class="head">Description</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><code>travel_lt15</code></td>&#13;
			<td>&#13;
			<p>Fraction of people with a ≤15-minute commute to work.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><code>gini</code></td>&#13;
			<td>&#13;
			<p>Gini coefficient, a measure of wealth inequality. Values are between 0 and 1, where small values mean wealth is evenly distributed and large values mean more inequality.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><code>rel_tot</code></td>&#13;
			<td>&#13;
			<p>Fraction of people who self-reported as religious.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><code>single_mom</code></td>&#13;
			<td>&#13;
			<p>Fraction of children with a single mother.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><code>taxrate</code></td>&#13;
			<td>&#13;
			<p>Local tax rate.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><code>worked_14</code></td>&#13;
			<td>&#13;
			<p>Fraction of 14- to 16-year-olds who work.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><code>foreign</code></td>&#13;
			<td>&#13;
			<p>Fraction of people born outside the US.</p>&#13;
			</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>Let’s first examine the correlations between AUM and the explanatory features and between the explanatory features themselves:</p>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>aum</th>&#13;
			<th>travel_lt15</th>&#13;
			<th>gini</th>&#13;
			<th>rel_tot</th>&#13;
			<th>single_mom</th>&#13;
			<th>taxrate</th>&#13;
			<th>worked_14</th>&#13;
			<th>foreign</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>aum</strong></td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.68</td>&#13;
			<td class="right">-0.60</td>&#13;
			<td class="right">0.52</td>&#13;
			<td class="right">-0.77</td>&#13;
			<td class="right">0.35</td>&#13;
			<td class="right">0.65</td>&#13;
			<td class="right">-0.03</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>travel_lt15</strong></td>&#13;
			<td class="right">0.68</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">-0.56</td>&#13;
			<td class="right">0.40</td>&#13;
			<td class="right">-0.42</td>&#13;
			<td class="right">0.34</td>&#13;
			<td class="right">0.60</td>&#13;
			<td class="right">-0.19</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>gini</strong></td>&#13;
			<td class="right">-0.60</td>&#13;
			<td class="right">-0.56</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">-0.29</td>&#13;
			<td class="right">0.57</td>&#13;
			<td class="right">-0.15</td>&#13;
			<td class="right">-0.58</td>&#13;
			<td class="right">0.31</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>rel_tot</strong></td>&#13;
			<td class="right">0.52</td>&#13;
			<td class="right">0.40</td>&#13;
			<td class="right">-0.29</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">-0.31</td>&#13;
			<td class="right">0.08</td>&#13;
			<td class="right">0.28</td>&#13;
			<td class="right">-0.11</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>single_mom</strong></td>&#13;
			<td class="right">-0.77</td>&#13;
			<td class="right">-0.42</td>&#13;
			<td class="right">0.57</td>&#13;
			<td class="right">-0.31</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">-0.26</td>&#13;
			<td class="right">-0.60</td>&#13;
			<td class="right">-0.04</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>taxrate</strong></td>&#13;
			<td class="right">0.35</td>&#13;
			<td class="right">0.34</td>&#13;
			<td class="right">-0.15</td>&#13;
			<td class="right">0.08</td>&#13;
			<td class="right">-0.26</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.35</td>&#13;
			<td class="right">0.26</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>worked_14</strong></td>&#13;
			<td class="right">0.65</td>&#13;
			<td class="right">0.60</td>&#13;
			<td class="right">-0.58</td>&#13;
			<td class="right">0.28</td>&#13;
			<td class="right">-0.60</td>&#13;
			<td class="right">0.35</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">-0.15</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>foreign</strong></td>&#13;
			<td class="right">-0.03</td>&#13;
			<td class="right">-0.19</td>&#13;
			<td class="right">0.31</td>&#13;
			<td class="right">-0.11</td>&#13;
			<td class="right">-0.04</td>&#13;
			<td class="right">0.26</td>&#13;
			<td class="right">-0.15</td>&#13;
			<td class="right">1.00</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We see that the fraction of single mothers in the commuting zone has the strongest correlation with AUM, which implies that it is also the single best feature to explain AUM. In addition, we see that several explanatory variables are highly correlated with each other; the Gini coefficient is highly correlated with the fraction of teenagers who work, the fraction of single mothers, and the fraction with less than a 15-minute commute. With such highly correlated features, we need to take care in interpreting the coefficients because several different models might equally explain AUM with the covariates standing in for one another.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The vector geometry<a contenteditable="false" data-primary="vector geometry" data-type="indexterm" id="id1619"/> perspective that we introduced earlier in this chapter can help us understand the problem. Recall that a feature corresponds to a column vector in <span><math> <mi>n</mi> </math></span>-dimensions, like <span><math> <mrow> <mi mathvariant="bold">x</mi> </mrow> </math></span>. With two highly correlated features, <span><math> <msub> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mn>1</mn> </msub> </math></span> and <span><math> <msub> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mn>2</mn> </msub> </math></span>, these vectors are nearly in alignment. So the projection of the response vector <span><math> <mrow> <mi mathvariant="bold">y</mi> </mrow> </math></span> onto one of these vectors is nearly the same as the projection onto the other. The situation gets even murkier when several features are correlated with one another.</p>&#13;
</div>&#13;
&#13;
<p>To begin, we can consider all possible two-feature models to see which one has the smallest prediction error. Chetty derived 40 potential variables to use as predictors, which would have us checking <span><math> <mo stretchy="false">(</mo> <mn>40</mn> <mo>×</mo> <mn>39</mn> <mo stretchy="false">)</mo> <mrow> <mo>/</mo> </mrow> <mn>2</mn> <mo>=</mo> <mn>780</mn> </math></span> models. Fitting models, with all pairs, triples, and so on, of variables quickly grows out of control. And it can lead to finding spurious correlations (see <a class="reference internal" data-type="xref" href="ch17.html#ch-inf-pred-theory">Chapter 17</a>).</p>&#13;
&#13;
<p>Here, we keep things a bit simpler and examine just one two-variable model that includes the travel time and single-mother features. After that, we look at the model that has all seven numeric explanatory features in our dataframe:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">X2</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">cz_df</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">travel_lt15</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="s1">'</code><code class="s1">single_mom</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">]</code></span><code>&#13;
</code><span><code class="n">y</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">cz_df</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">aum</code><code class="s1">'</code></span><span><code class="p">]</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">model_ct_sm</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">X2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Intercept: 49.0&#13;
Fraction with under 15 minute commute coefficient: 18.10&#13;
Fraction of single moms coefficient: 18.10&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Notice that the coefficient for travel time is quite different than the coefficient for this variable in the simple linear model. That’s because the two features in our model are highly correlated.</p>&#13;
&#13;
<p>Next we compare the errors from the two fits:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">prediction_ct_sm</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">model_ct_sm</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">X2</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">error_ct_sm</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">y</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">prediction_ct_sm</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
 SD(errors in model 1): 4.14&#13;
 SD(errors in model 2): 2.85&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The SD of the residuals have been reduced by another 30%. Adding a second variable to the model seems worth the extra complexity.</p>&#13;
&#13;
<p>Let’s again visually examine the residuals. We use the same scale on the y-axis to make it easier to compare this residual plot with the plot for the one-variable model:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">fig</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">scatter</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="n">prediction_ct_sm</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="n">error_ct_sm</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>           </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="nb">dict</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">Two-variable prediction for AUM</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">Error</code><code class="s1">'</code></span><span><code class="p">)</code><code class="p">,</code></span><code>&#13;
</code><code>           </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">350</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">250</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">add_hline</code></span><span><code class="p">(</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_width</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_dash</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">dash</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">opacity</code></span><span><code class="o">=</code></span><span><code class="mi">1</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">update_yaxes</code></span><span><code class="p">(</code></span><span><code class="nb">range</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="o">-</code></span><span><code class="mi">20</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">15</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">show</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_15in09.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The larger variability in the errors for higher AUM is even more evident. The implications are that the estimates, <span><math> <mrow> <mover> <mi>y</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span>, are unaffected, but their accuracy depends on AUM. This problem can be addressed with <em>weighted regression</em>.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Once again, we point out that data scientists from different backgrounds use different terminology<a contenteditable="false" data-primary="design matrix" data-type="indexterm" id="id1620"/><a contenteditable="false" data-primary="machine learning" data-type="indexterm" id="id1621"/> to refer to the same concept. For example, the terminology that calls each row in the design matrix <span><math> <mtext mathvariant="bold">X</mtext> </math></span> an observation and each column a variable is more common among people with backgrounds in statistics. Others say that each column of the design matrix represents a <em>feature</em> or that each row represents a <em>record</em>. Also, we say that our overall process of fitting and interpreting models is called <em>modeling</em>, while others call it <em>machine learning</em>.</p>&#13;
</div>&#13;
&#13;
<p>Now let’s fit a multiple linear model that uses all seven variables to explain upward mobility. After fitting the model, we again plot the errors using the same y-axis scale as in the previous two residual plots:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">X7</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">cz_df</code></span><span><code class="p">[</code></span><span><code class="n">predictors</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="n">model_7var</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">X7</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">prediction_7var</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">model_7var</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">X7</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">error_7var</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">y</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">prediction_7var</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">fig</code><code> </code><code class="o">=</code><code> </code><code class="n">px</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code>&#13;
</code><code>    </code><code class="n">x</code><code class="o">=</code><code class="n">prediction_7var</code><code class="p">,</code><code> </code><code class="n">y</code><code class="o">=</code><code class="n">error_7var</code><code class="p">,</code><code>&#13;
</code><code>    </code><code class="n">labels</code><code class="o">=</code><code class="nb">dict</code><code class="p">(</code><code class="n">x</code><code class="o">=</code><code class="s1">'</code><code class="s1">Seven-variable prediction for AUM</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">y</code><code class="o">=</code><code class="s1">'</code><code class="s1">Error</code><code class="s1">'</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>    </code><code class="n">width</code><code class="o">=</code><code class="mi">350</code><code class="p">,</code><code> </code><code class="n">height</code><code class="o">=</code><code class="mi">250</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">add_hline</code></span><span><code class="p">(</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_width</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_dash</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">dash</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">opacity</code></span><span><code class="o">=</code></span><span><code class="mi">1</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">update_yaxes</code></span><span><code class="p">(</code></span><span><code class="nb">range</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="o">-</code></span><span><code class="mi">20</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">15</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">show</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_15in10.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The model with seven features does not appear to be much better than the two-variable model. In fact, the standard deviation of the residuals has only decreased by 8%:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">error_7var</code></span><span><code class="o">.</code></span><span><code class="n">std</code></span><span><code class="p">(</code><code class="p">)</code></span><code> </code><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
2.588739233574256&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We can compare the multiple <span><math> <msup> <mi>R</mi> <mn>2</mn> </msup> </math></span> for these three models:</p>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
R² for 7-variable model: 0.79&#13;
R² for 2-variable model: 0.74&#13;
R² for 1-variable model: 0.46&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The adjustment for the number of features in the model makes little difference for us since we have over 700 observations. Now we have confirmed our earlier findings that using two variables greatly improves the explanatory capability of the model, and the seven-variable model offers little improvement over the two-variable model. The small gain is likely not worth the added complexity of the model.</p>&#13;
&#13;
<p>So far, our models have used only numeric predictor variables. But categorical data is often useful for model fitting as well. Additionally, in <a class="reference internal" data-type="xref" href="ch10.html#ch-eda">Chapter 10</a> we transformed variables and created new variables from combinations of variables. We address how to incorporate these variables into linear models next<a contenteditable="false" data-primary="" data-startref="ix_lin_mod_mob" data-type="indexterm" id="id1622"/><a contenteditable="false" data-primary="" data-startref="ix_eco_mob_lin_mod" data-type="indexterm" id="id1623"/><a contenteditable="false" data-startref="ix_lin_mod_multi" data-type="indexterm" id="id1624"/><a contenteditable="false" data-primary="" data-startref="ix_multi_lin_mod" data-type="indexterm" id="id1625"/>.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Feature Engineering for Numeric Measurements" data-type="sect1"><div class="sect1" id="feature-engineering-for-numeric-measurements">&#13;
<h1 class="less_space">Feature Engineering for Numeric Measurements</h1>&#13;
&#13;
<p>All of the models<a contenteditable="false" data-primary="features and feature types" data-secondary="feature engineering" data-type="indexterm" id="ix_feat_feat_engin2"/><a contenteditable="false" data-primary="numeric data" data-secondary="feature engineering for measuring" data-type="indexterm" id="ix_num_feat_engin"/><a contenteditable="false" data-primary="linear modeling" data-secondary="numeric measurements" data-type="indexterm" id="ix_lin_mod_num"/><a contenteditable="false" data-primary="feature engineering" data-secondary="numeric measurements" data-type="indexterm" id="ix_feat_engin_num"/> that we have fit so far in this chapter have used numeric features that were originally provided in the dataframe. In this section, we look at variables that are created from transformations of numeric features. Transforming variables to use in modeling is called <em>feature engineering</em>.</p>&#13;
&#13;
<p>We introduced feature engineering in Chapters <a class="reference internal" data-type="xref" data-xrefstyle="select:labelnumber" href="ch09.html#ch-wrangling">9</a> and <a class="reference internal" data-type="xref" data-xrefstyle="select:labelnumber" href="ch10.html#ch-eda">10</a>. There, we transformed features so that they had symmetric distributions. Transformations can capture more kinds of patterns in the data and lead to better and more accurate models.</p>&#13;
&#13;
<p>Let’s return to the dataset we used as an example in <a class="reference internal" data-type="xref" href="ch10.html#ch-eda">Chapter 10</a>: house sale prices in the San Francisco Bay Area. We restrict the data to houses sold in 2006, when sale prices were relatively stable, so we don’t need to account for trends in price.</p>&#13;
&#13;
<p>We wish to model sale price. Recall that visualizations in <a class="reference internal" data-type="xref" href="ch10.html#ch-eda">Chapter 10</a> showed us that sale price was related to several features, like the size of the house, size of the lot, number of bedrooms, and location. We log-transformed both sale price and the size of the house to improve their relationship, and we saw that box plots of sale price by the number of bedrooms and box plots by city revealed interesting relationships too. In this section, we include transformed numeric features in a linear model. In the next section, we also add an ordinal feature (the number of bedrooms) and a nominal feature (the city) to the model.</p>&#13;
&#13;
<p>To begin, we’ll model sale price on house size. The correlation matrix tell us which of our numeric explanatory variables (original and transformed) is most strongly correlated with sale price:</p>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>price</th>&#13;
			<th>br</th>&#13;
			<th>lsqft</th>&#13;
			<th>bsqft</th>&#13;
			<th>log_price</th>&#13;
			<th>log_bsqft</th>&#13;
			<th>log_lsqft</th>&#13;
			<th>ppsf</th>&#13;
			<th>log_ppsf</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>price</strong></td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.45</td>&#13;
			<td class="right">0.59</td>&#13;
			<td class="right">0.79</td>&#13;
			<td class="right">0.94</td>&#13;
			<td class="right">0.74</td>&#13;
			<td class="right">0.62</td>&#13;
			<td class="right">0.49</td>&#13;
			<td class="right">0.47</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>br</strong></td>&#13;
			<td class="right">0.45</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.29</td>&#13;
			<td class="right">0.67</td>&#13;
			<td class="right">0.47</td>&#13;
			<td class="right">0.71</td>&#13;
			<td class="right">0.38</td>&#13;
			<td class="right">-0.18</td>&#13;
			<td class="right">-0.21</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>lsqft</strong></td>&#13;
			<td class="right">0.59</td>&#13;
			<td class="right">0.29</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.46</td>&#13;
			<td class="right">0.55</td>&#13;
			<td class="right">0.44</td>&#13;
			<td class="right">0.85</td>&#13;
			<td class="right">0.29</td>&#13;
			<td class="right">0.27</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>bsqft</strong></td>&#13;
			<td class="right">0.79</td>&#13;
			<td class="right">0.67</td>&#13;
			<td class="right">0.46</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.76</td>&#13;
			<td class="right">0.96</td>&#13;
			<td class="right">0.52</td>&#13;
			<td class="right">-0.08</td>&#13;
			<td class="right">-0.10</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>log_price</strong></td>&#13;
			<td class="right">0.94</td>&#13;
			<td class="right">0.47</td>&#13;
			<td class="right">0.55</td>&#13;
			<td class="right">0.76</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.78</td>&#13;
			<td class="right">0.62</td>&#13;
			<td class="right">0.51</td>&#13;
			<td class="right">0.52</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>log_bsqft</strong></td>&#13;
			<td class="right">0.74</td>&#13;
			<td class="right">0.71</td>&#13;
			<td class="right">0.44</td>&#13;
			<td class="right">0.96</td>&#13;
			<td class="right">0.78</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.52</td>&#13;
			<td class="right">-0.11</td>&#13;
			<td class="right">-0.14</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>log_lsqft</strong></td>&#13;
			<td class="right">0.62</td>&#13;
			<td class="right">0.38</td>&#13;
			<td class="right">0.85</td>&#13;
			<td class="right">0.52</td>&#13;
			<td class="right">0.62</td>&#13;
			<td class="right">0.52</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.29</td>&#13;
			<td class="right">0.27</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>ppsf</strong></td>&#13;
			<td class="right">0.49</td>&#13;
			<td class="right">-0.18</td>&#13;
			<td class="right">0.29</td>&#13;
			<td class="right">-0.08</td>&#13;
			<td class="right">0.51</td>&#13;
			<td class="right">-0.11</td>&#13;
			<td class="right">0.29</td>&#13;
			<td class="right">1.00</td>&#13;
			<td class="right">0.96</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>log_ppsf</strong></td>&#13;
			<td class="right">0.47</td>&#13;
			<td class="right">-0.21</td>&#13;
			<td class="right">0.27</td>&#13;
			<td class="right">-0.10</td>&#13;
			<td class="right">0.52</td>&#13;
			<td class="right">-0.14</td>&#13;
			<td class="right">0.27</td>&#13;
			<td class="right">0.96</td>&#13;
			<td class="right">1.00</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Sale price correlates most highly with house size, called <code>bsqft</code> for building square feet. We make a scatterplot of sale price against house size to confirm the association is linear:</p>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_15in11.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The relationship does look roughly linear, but the very large and expensive houses are far from the center of the distribution and can overly influence the model. As shown in <a class="reference internal" data-type="xref" href="ch10.html#ch-eda">Chapter 10</a>, the log transformation makes the distributions of price and size more symmetric (both are log base 10 to make it easier to convert the values into the original units):</p>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_15in12.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>Ideally, a model that uses transformations should make sense in the context of the data. If we fit a simple linear model based on log(size), then when we examine the coefficient, we think in terms of a percentage increase. For example, a doubling of <span><math> <mi>x</mi> </math></span> increases the prediction by <span><math> <mi>θ</mi> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mn>2</mn> <mo stretchy="false">)</mo> </math></span>, since <span><math> <mi>θ</mi> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mn>2</mn> <mi>x</mi> <mo stretchy="false">)</mo> <mo>=</mo> <mi>θ</mi> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mn>2</mn> <mo stretchy="false">)</mo> <mo>+</mo> <mi>θ</mi> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo> </math></span>.</p>&#13;
&#13;
<p>Let’s begin by fitting a model that explains log-transformed price by the house’s log-transformed size. But first, we note that this model is still considered a linear model. If we represent sale price by <span><math> <mi>y</mi> </math></span> and house size by <span><math> <mi>x</mi> </math></span>, then the model is:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>=</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>(Note that we have ignored the approximation in this equation to make the linear relationship clearer.) This equation may not seem linear, but if we rename <span><math> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>y</mi> <mo stretchy="false">)</mo> </math></span> to <span><math> <mi>w</mi> </math></span> and <span><math> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo> </math></span> to <span><math> <mi>v</mi> </math></span>, then we can express this “log–log” relationship as a linear model in <span><math> <mi>w</mi> </math></span> and <span><math> <mi>v</mi> </math></span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mi>w</mi> <mtext> </mtext> <mo>=</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>v</mi> </math></div>&#13;
</div>&#13;
&#13;
<p>Other examples of models that can be expressed as linear combinations of transformed features are:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>=</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> </mtd> </mtr> <mtr> <mtd> <mi>y</mi> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>=</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <msup> <mi>x</mi> <mn>2</mn> </msup> </mtd> </mtr> <mtr> <mtd> <mi>y</mi> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>=</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <mi>z</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>3</mn> </msub> <mi>x</mi> <mi>z</mi> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>Again, if we rename <span><math> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>y</mi> <mo stretchy="false">)</mo> </math></span> to <span><math> <mi>w</mi> </math></span>, <span><math> <msup> <mi>x</mi> <mn>2</mn> </msup> </math></span> to <span><math> <mi>u</mi> </math></span>, and <span><math> <mi>x</mi> <mi>z</mi> </math></span> as <span><math> <mi>t</mi> </math></span>, then we can express each of these models as linear in these renamed features. In order, the preceding models are now:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mi>w</mi> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>=</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> </mtd> </mtr> <mtr> <mtd> <mi>y</mi> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>=</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <mi>u</mi> </mtd> </mtr> <mtr> <mtd> <mi>y</mi> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>=</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <mi>z</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>3</mn> </msub> <mi>t</mi> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>In short, we can think of models that include nonlinear transformations of features and/or combinations of features as linear in their derived features. In practice, we don’t rename the transformed features when we describe the model; instead, we write the model using the transformations of the original features because it’s important to keep track of them, especially when interpreting the coefficients and checking residual plots.</p>&#13;
&#13;
<p>When we refer to these models<a contenteditable="false" data-primary="polynomial features" data-type="indexterm" id="id1626"/><a contenteditable="false" data-primary="interaction term, log-log model" data-type="indexterm" id="id1627"/><a contenteditable="false" data-primary="log-log model" data-type="indexterm" id="id1628"/><a contenteditable="false" data-primary="log-linear" data-type="indexterm" id="id1629"/>, we include mention of the transformations. That is, we call a model <em>log–log</em> when both the outcome and explanatory variables are log-transformed; we say it’s <em>log–linear</em> when the outcome is log-transformed but not the explanatory variable; we describe a model as having <em>polynomial features</em> of, say, degree two when the first and second power transformations of the explanatory variable are included; and we say a model includes an <em>interaction term</em> between two explanatory features when the product of these two features is included in the model.</p>&#13;
&#13;
<p>Let’s fit a log–log model of price on size:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">X1_log</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">sfh</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">log_bsqft</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">]</code></span><code>    </code><code>&#13;
</code><span><code class="n">y_log</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">sfh</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">log_price</code><code class="s1">'</code></span><span><code class="p">]</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">model1_log_log</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">X1_log</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_log</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The coefficients and predicted values from this model cannot be directly compared to a model fitted using linear features because the units are the log of dollars and log of square feet, not dollars and square feet.</p>&#13;
&#13;
<p>Next, we examine the residuals and predicted values with a plot:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">prediction</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">model1_log_log</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">X1_log</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">error</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">y_log</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">prediction</code></span><code> </code><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">fig</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">scatter</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="n">prediction</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="n">error</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="nb">dict</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">Predicted sale price (log USD)</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">Error</code><code class="s1">'</code></span><span><code class="p">)</code><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">350</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">250</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">add_hline</code></span><span><code class="p">(</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_width</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">line_dash</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">dash</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">opacity</code></span><span><code class="o">=</code></span><span><code class="mi">1</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">show</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_15in13.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The residual plot looks reasonable, but it contains thousands of points, which makes it hard to see curvature.</p>&#13;
&#13;
<p>To see if additional variables might be helpful, we can plot the residuals from the fitted model against a variable that is not in the model. If we see patterns, that indicates we might want to include this additional feature or a transformation of it. Earlier, we found that the distribution of price was related to the city where the house is located, so let’s examine the relationship between the residuals and city:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_15in14.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>This plot shows us that the distribution of errors appears shifted by city. Ideally, the median of each city’s box plot lines up with 0 on the y-axis. Instead, more than 75% of the houses sold in Piedmont have positive errors, meaning the actual sale price is above the predicted value. And at the other extreme, more than 75% of sale prices in Richmond fall below their predicted values. These patterns suggest that we should include city in the model. From a context point of view, it makes sense for location to impact sale price. In the next section, we show how to incorporate a nominal variable into a linear model<a contenteditable="false" data-primary="" data-startref="ix_feat_engin_num" data-type="indexterm" id="id1630"/><a contenteditable="false" data-primary="" data-startref="ix_lin_mod_num" data-type="indexterm" id="id1631"/><a contenteditable="false" data-primary="" data-startref="ix_num_feat_engin" data-type="indexterm" id="id1632"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Feature Engineering for Categorical Measurements" data-type="sect1"><div class="sect1" id="feature-engineering-for-categorical-measurements">&#13;
<h1>Feature Engineering for Categorical Measurements</h1>&#13;
&#13;
<p>The first model<a contenteditable="false" data-primary="feature engineering" data-secondary="categorical measurements" data-type="indexterm" id="ix_feat_engin_cat_data"/><a contenteditable="false" data-primary="linear modeling" data-secondary="categorical measurements" data-type="indexterm" id="ix_lin_mod_cat_meas"/><a contenteditable="false" data-primary="categorical data" data-secondary="feature engineering for measuring" data-type="indexterm" id="ix_cat_data_feat_engin"/> we ever fit was the constant model in <a class="reference internal" data-type="xref" href="ch04.html#ch-modeling">Chapter 4</a>. There, we minimized squared loss to find the best-fitting constant:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <munder> <mo movablelimits="true">min</mo> <mi>c</mi> </munder> <munder> <mo>∑</mo> <mi>i</mi> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>c</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </math></div>&#13;
</div>&#13;
&#13;
<p>We can think of including a nominal feature in a model in a similar fashion. That is, we find the best-fitting constant to each subgroup of the data corresponding to a <span class="keep-together">category</span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <munder> <mo movablelimits="true">min</mo> <mrow> <msub> <mi>c</mi> <mi>B</mi> </msub> </mrow> </munder> <munder> <mo>∑</mo> <mrow> <mi>i</mi> <mo>∈</mo> <mtext>Berkeley</mtext> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>c</mi> <mi>B</mi> </msub> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mtext> </mtext> <mtext> </mtext> <mtext> </mtext> </mtd> <mtd> <mtext> </mtext> <mtext> </mtext> <mtext> </mtext> <munder> <mo movablelimits="true">min</mo> <mrow> <msub> <mi>c</mi> <mi>L</mi> </msub> </mrow> </munder> <munder> <mo>∑</mo> <mrow> <mi>i</mi> <mo>∈</mo> <mtext>Lamorinda</mtext> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>c</mi> <mi>L</mi> </msub> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </mtd> </mtr> <mtr> <mtd> <munder> <mo movablelimits="true">min</mo> <mrow> <msub> <mi>c</mi> <mi>P</mi> </msub> </mrow> </munder> <munder> <mo>∑</mo> <mrow> <mi>i</mi> <mo>∈</mo> <mtext>Piedmont</mtext> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>c</mi> <mi>P</mi> </msub> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mtext> </mtext> <mtext> </mtext> <mtext> </mtext> </mtd> <mtd> <mtext> </mtext> <mtext> </mtext> <mtext> </mtext> <munder> <mo movablelimits="true">min</mo> <mrow> <msub> <mi>c</mi> <mi>R</mi> </msub> </mrow> </munder> <munder> <mo>∑</mo> <mrow> <mi>i</mi> <mo>∈</mo> <mtext>Richmond</mtext> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>c</mi> <mi>R</mi> </msub> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>Another<a contenteditable="false" data-primary="one-hot encoding" data-type="indexterm" id="ix_one_hot_enc"/> way to describe this model is with <em>one-hot encoding</em>.</p>&#13;
&#13;
<p>One-hot encoding takes a categorical feature and creates multiple numeric features that have only the values 0 or 1. To one-hot encode a feature, we create new features, one for each unique category. In this case, since we have four cities—Berkeley, Lamorinda, Piedmont, and Richmond—we create four new features in a design matrix, called <span><math> <msub> <mi>X</mi> <mrow> <mi>c</mi> <mi>i</mi> <mi>t</mi> <mi>y</mi> </mrow> </msub> </math></span>. Each row in <span><math> <msub> <mi>X</mi> <mrow> <mi>c</mi> <mi>i</mi> <mi>t</mi> <mi>y</mi> </mrow> </msub> </math></span> contains one value of 1, and it appears in the column that corresponds to the city. All other columns contain 0 for that row. <a class="reference internal" data-type="xref" href="#fig-one-hot2">Figure 15-6</a> illustrates this notion.</p>&#13;
&#13;
<figure><div class="figure" id="fig-one-hot2"><img src="assets/leds_1506.png"/>&#13;
<h6><span class="label">Figure 15-6. </span>One-hot encoding for a categorical feature with six rows (left) and its resulting design matrix (right)</h6>&#13;
</div></figure>&#13;
&#13;
<p>Now we can concisely represent the model as follows:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <msub> <mi>θ</mi> <mi>B</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>B</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>L</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>L</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>P</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>P</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>R</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>R</mi> </mrow> </msub> </math></div>&#13;
</div>&#13;
&#13;
<p>Here, we have indexed the columns of the design matrix by <span><math> <mi>B</mi> </math></span>, <span><math> <mi>L</mi> </math></span>, <span><math> <mi>P</mi> </math></span>, and <span><math> <mi>R</mi> </math></span>, rather than <span><math> <mi>j</mi> </math></span>, to make it clear that each column represents a column of 0s and 1s where, say, a 1 appears for <span><math> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>P</mi> </mrow> </msub> </math></span> if the <span><math> <mi>i</mi> </math></span>th house is located in Piedmont.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>One-hot encoding creates features that have only 0-1 values. These features are also known as <em>dummy variable</em> or <em>indicator variable</em>. The term “dummy variable” is more common in econometrics, and the usage of “indicator variable” is more common in statistics.</p>&#13;
</div>&#13;
&#13;
<p>Our goal is to minimize least square loss over <span><math> <mi mathvariant="bold-italic">θ</mi> </math></span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mo fence="false" stretchy="false">‖</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo>−</mo> <mtext mathvariant="bold">X</mtext> <mi mathvariant="bold-italic">θ</mi> <msup> <mo fence="false" stretchy="false">‖</mo> <mn>2</mn> </msup> </mtd> <mtd> <mi/> <mo>=</mo> <munder> <mo>∑</mo> <mi>i</mi> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>θ</mi> <mi>B</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>B</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>L</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>L</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>P</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>P</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>R</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>R</mi> </mrow> </msub> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </mtd> </mtr> <mtr> <mtd/> <mtd> <mi/> <mo>=</mo> <munder> <mo>∑</mo> <mrow> <mi>i</mi> <mo>∈</mo> <mi>B</mi> <mi>e</mi> <mi>r</mi> <mi>k</mi> <mi>e</mi> <mi>l</mi> <mi>e</mi> <mi>y</mi> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>θ</mi> <mi>B</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>B</mi> </mrow> </msub> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <munder> <mo>∑</mo> <mrow> <mi>i</mi> <mo>∈</mo> <mi>L</mi> <mi>a</mi> <mi>m</mi> <mi>o</mi> <mi>r</mi> <mi>i</mi> <mi>n</mi> <mi>d</mi> <mi>a</mi> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>θ</mi> <mi>L</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>L</mi> </mrow> </msub> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </mtd> </mtr> <mtr> <mtd> <mtext> </mtext> <mtext> </mtext> <mtext> </mtext> <mtext> </mtext> <mtext> </mtext> <mtext> </mtext> <mtext> </mtext> <mtext> </mtext> </mtd> <mtd> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <munder> <mo>∑</mo> <mrow> <mi>i</mi> <mo>∈</mo> <mi>P</mi> <mi>i</mi> <mi>e</mi> <mi>d</mi> <mi>m</mi> <mi>o</mi> <mi>n</mi> <mi>t</mi> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>θ</mi> <mi>P</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>P</mi> </mrow> </msub> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <munder> <mo>∑</mo> <mrow> <mi>i</mi> <mo>∈</mo> <mi>R</mi> <mi>i</mi> <mi>c</mi> <mi>h</mi> <mi>m</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi> </mrow> </munder> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mi>θ</mi> <mi>R</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>R</mi> </mrow> </msub> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>where <span><math> <mi mathvariant="bold-italic">θ</mi> </math></span> is the column vector <span><math> <mo stretchy="false">[</mo> <msub> <mi>θ</mi> <mi>B</mi> </msub> <mo>,</mo> <msub> <mi>θ</mi> <mi>L</mi> </msub> <mo>,</mo> <msub> <mi>θ</mi> <mi>P</mi> </msub> <mo>,</mo> <msub> <mi>θ</mi> <mi>R</mi> </msub> <mo stretchy="false">]</mo> </math></span>. Notice that this minimization reduces to four minimizations, one for each city. That’s the idea that we started with at the beginning of this section.</p>&#13;
&#13;
<p>We can<a contenteditable="false" data-primary="OneHotEncoder" data-type="indexterm" id="id1633"/> use <code>OneHotEncoder</code> to create this design matrix:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">sklearn</code><code class="nn">.</code><code class="nn">preprocessing</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">OneHotEncoder</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">enc</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">OneHotEncoder</code></span><span><code class="p">(</code></span><code>&#13;
</code><code>    </code><span><code class="c1"># categories argument sets column order</code></span><code>&#13;
</code><code>    </code><span><code class="n">categories</code></span><span><code class="o">=</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">Berkeley</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">Lamorinda</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">Piedmont</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">Richmond</code><code class="s2">"</code></span><span><code class="p">]</code><code class="p">]</code><code class="p">,</code></span><code>&#13;
</code><code>    </code><span><code class="n">sparse</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">,</code></span><code>&#13;
</code><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">X_city</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">enc</code></span><span><code class="o">.</code></span><span><code class="n">fit_transform</code></span><span><code class="p">(</code></span><span><code class="n">sfh</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">city</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">categories_city</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">Berkeley</code><code class="s2">"</code></span><span><code class="p">,</code></span><span><code class="s2">"</code><code class="s2">Lamorinda</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">Piedmont</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">Richmond</code><code class="s2">"</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="n">X_city_df</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">pd</code></span><span><code class="o">.</code></span><span><code class="n">DataFrame</code></span><span><code class="p">(</code></span><span><code class="n">X_city</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">columns</code></span><span><code class="o">=</code></span><span><code class="n">categories_city</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">X_city_df</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>Berkeley</th>&#13;
			<th>Lamorinda</th>&#13;
			<th>Piedmont</th>&#13;
			<th>Richmond</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>0</strong></td>&#13;
			<td>1.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1</strong></td>&#13;
			<td>1.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2</strong></td>&#13;
			<td>1.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>...</strong></td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2664</strong></td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>1.0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2665</strong></td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>1.0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2666</strong></td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>1.0</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<pre>2667 rows × 4 columns</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Let’s fit a model using these one-hot encoded features:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">y_log</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">sfh</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">log_price</code><code class="s1">'</code></span><span><code class="p">]</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">model_city</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code></span><span><code class="n">fit_intercept</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">X_city_df</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_log</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>And examine the multiple <span><math> <msup> <mi>R</mi> <mn>2</mn> </msup> </math></span>:</p>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
R-square for city model: 0.57&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>If we only know the city where a house is located, the model does a reasonably good job of estimating its sale price. Here are the coefficients from the fit:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">model_city</code></span><span><code class="o">.</code></span><span><code class="n">coef_</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
array([5.87, 6.03, 6.1 , 5.67])&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p class="pagebreak-before less_space">As expected from the box plots, the estimated sale price (in log $) depends on the city. But if we know the size of the house as well as the city, we should have an even better model. We saw earlier that the simple log–log model that explains sale price by house size fits reasonably well, so we expect that the city feature (as one-hot encoded variables) should further improve the model.</p>&#13;
&#13;
<p>Such a model looks like this:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <msub> <mi>y</mi> <mi>i</mi> </msub> <mtext> </mtext> <mo>≈</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mi>B</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>B</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>L</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>L</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>P</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>P</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>R</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>R</mi> </mrow> </msub> </math></div>&#13;
</div>&#13;
&#13;
<p>Notice that this model describes the relationship between log(price), which is represented as <span><math> <mi>y</mi> </math></span>, and log(size), which is represented as <span><math> <mi>x</mi> </math></span>, as linear with the same coefficient for log(size) for each city. But the intercept term depends on the city:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left right" columnspacing="0em 2em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <msub> <mi>y</mi> <mi>i</mi> </msub> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>≈</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mi>B</mi> </msub> <mtext> </mtext> <mtext> </mtext> </mtd> <mtd> <mtext>for houses in Berkeley</mtext> </mtd> </mtr> <mtr> <mtd> <msub> <mi>y</mi> <mi>i</mi> </msub> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>≈</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mi>L</mi> </msub> <mtext> </mtext> <mtext> </mtext> </mtd> <mtd> <mtext>for houses in Lamorinda</mtext> </mtd> </mtr> <mtr> <mtd> <msub> <mi>y</mi> <mi>i</mi> </msub> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>≈</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mi>P</mi> </msub> <mtext> </mtext> <mtext> </mtext> </mtd> <mtd> <mtext>for houses in Piedmont</mtext> </mtd> </mtr> <mtr> <mtd> <msub> <mi>y</mi> <mi>i</mi> </msub> <mtext> </mtext> </mtd> <mtd> <mi/> <mo>≈</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mi>R</mi> </msub> <mtext> </mtext> <mtext> </mtext> </mtd> <mtd> <mtext>for houses in Richmond</mtext> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>We next make a facet of scatterplots, one for each city, to see if this relationship roughly holds:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">fig</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">scatter</code></span><span><code class="p">(</code></span><span><code class="n">sfh</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">log_bsqft</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">log_price</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><code>&#13;
</code><code>                 </code><span><code class="n">facet_col</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">city</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">facet_col_wrap</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="p">{</code></span><span><code class="s1">'</code><code class="s1">log_bsqft</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">Building size (log ft^2)</code><code class="s1">'</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                         </code><span><code class="s1">'</code><code class="s1">log_price</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">Sale price (log USD)</code><code class="s1">'</code></span><span><code class="p">}</code><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">500</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">400</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">update_layout</code></span><span><code class="p">(</code></span><span><code class="n">margin</code></span><span><code class="o">=</code></span><span><code class="nb">dict</code></span><span><code class="p">(</code></span><span><code class="n">t</code></span><span><code class="o">=</code></span><span><code class="mi">30</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code><span><code class="n">fig</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_15in15.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The shift is evident in the scatterplot. We concatenate our two design matrices together to fit the model that includes size and city:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">X_size</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">sfh</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">log_bsqft</code><code class="s1">'</code></span><span><code class="p">]</code></span><code> </code><code>&#13;
</code><code>&#13;
</code><span><code class="n">X_city_size</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">pd</code></span><span><code class="o">.</code></span><span><code class="n">concat</code></span><span><code class="p">(</code><code class="p">[</code></span><span><code class="n">X_size</code></span><span><code class="o">.</code></span><span><code class="n">reset_index</code></span><span><code class="p">(</code></span><span><code class="n">drop</code></span><span><code class="o">=</code></span><span><code class="kc">True</code></span><span><code class="p">)</code><code class="p">,</code></span><code> </code><span><code class="n">X_city_df</code></span><span><code class="p">]</code><code class="p">,</code></span><code> </code><span><code class="n">axis</code></span><span><code class="o">=</code></span><span><code class="mi">1</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">X_city_size</code></span><span><code class="o">.</code></span><span><code class="n">drop</code></span><span><code class="p">(</code></span><span><code class="mi">0</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>log_bsqft</th>&#13;
			<th>Berkeley</th>&#13;
			<th>Lamorinda</th>&#13;
			<th>Piedmont</th>&#13;
			<th>Richmond</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>1</strong></td>&#13;
			<td>3.14</td>&#13;
			<td>1.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2</strong></td>&#13;
			<td>3.31</td>&#13;
			<td>1.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>3</strong></td>&#13;
			<td>2.96</td>&#13;
			<td>1.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>...</strong></td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2664</strong></td>&#13;
			<td>3.16</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>1.0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2665</strong></td>&#13;
			<td>3.47</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>1.0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2666</strong></td>&#13;
			<td>3.44</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>0.0</td>&#13;
			<td>1.0</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<pre>2666 rows × 5 columns</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Now let’s fit a model that incorporates the quantitative feature, the house size, and the qualitative feature, location (city):</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">model_city_size</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code></span><span><code class="n">fit_intercept</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">X_city_size</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_log</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The intercepts reflect which cities have more expensive houses, even taking into account the size of the house:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">model_city_size</code></span><span><code class="o">.</code></span><span><code class="n">coef_</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
array([0.62, 3.89, 3.98, 4.03, 3.75])&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
R-square for city and log(size):  0.79&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>This fit, which includes the nominal variable <code>city</code> and the log-transformed house size, is better than both the simple log–log model with house size and the model that fits constants for each city.</p>&#13;
&#13;
<p>Notice that we dropped the intercept from the model so that each subgroup has its own intercept. However, a common practice is to remove one of the one-hot encoded features from the design matrix and keep the intercept. For example, if we drop the feature for Berkeley houses and add the intercept, then the model is:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>L</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>L</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>P</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>P</mi> </mrow> </msub> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mi>R</mi> </msub> <msub> <mi>x</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>R</mi> </mrow> </msub> </math></div>&#13;
</div>&#13;
&#13;
<p>The meaning of the coefficients for the dummy variables has changed in this representation. For example, consider this equation for a house in Berkeley and a house in Piedmont:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left right" columnspacing="0em 2em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <msub> <mi>θ</mi> <mn>0</mn> </msub> </mtd> <mtd> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mtext> </mtext> <mtext> </mtext> </mtd> <mtd> <mtext>for a house in Berkeley</mtext> </mtd> </mtr> <mtr> <mtd> <msub> <mi>θ</mi> <mn>0</mn> </msub> </mtd> <mtd> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <msub> <mi>θ</mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mi>P</mi> </msub> <mtext> </mtext> <mtext> </mtext> </mtd> <mtd> <mtext>for a house in Piedmont</mtext> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>In this representation, the intercept <span><math> <msub> <mi>θ</mi> <mn>0</mn> </msub> </math></span> is for Berkeley houses, and the coefficient <span><math> <msub> <mi>θ</mi> <mi>P</mi> </msub> </math></span> measures the typical difference between a Piedmont house and a Berkeley house. In this representation, we can more easily compare <span><math> <msub> <mi>θ</mi> <mi>P</mi> </msub> </math></span> to 0 to see if these two cities have essentially the same average price.</p>&#13;
&#13;
<p>If we include the intercept and all of the city variables, then the columns of the design matrix are linearly dependent, which means that we can’t solve for the coefficients. Our predictions will be the same in either case, but there will not be a unique solution to the minimization.</p>&#13;
&#13;
<p>We also prefer the representation of the model that drops one dummy variable and includes an intercept term when we include one-hot encodings of two categorical variables. This practice maintains consistency in the interpretation of the coefficients.</p>&#13;
&#13;
<p>We demonstrate<a contenteditable="false" data-primary="statsmodels library" data-type="indexterm" id="id1634"/> how to build a model with two sets of dummy variables, using the <code>statsmodels</code> library. This library uses a formula language to describe the model to fit, so we don’t need to create the design matrix ourselves. We import the formula API:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">import</code></span><code> </code><span><code class="nn">statsmodels</code><code class="nn">.</code><code class="nn">formula</code><code class="nn">.</code><code class="nn">api</code></span><code> </code><span><code class="k">as</code></span><code> </code><span><code class="nn">smf</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Let’s first repeat our fit of the model with the nominal variable <code>city</code> and house size to show how to use the formula language and compare the results:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">model_size_city</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">smf</code></span><span><code class="o">.</code></span><span><code class="n">ols</code></span><span><code class="p">(</code></span><span><code class="n">formula</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">log_price ~ log_bsqft + city</code><code class="s1">'</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                          </code><span><code class="n">data</code></span><span><code class="o">=</code></span><span><code class="n">sfh</code></span><span><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The string provided for the <code>formula</code> parameter describes the model to fit. The model has <code>log_price</code> as the outcome and fits a linear combination of <code>log_bsqft</code> and <code>city</code> as explanatory variables. Notice that we do not need to create dummy variables to fit the model. Conveniently, <code>smf.ols</code> does the one-hot encoding of the city feature for us. The fitted coefficients of the following model include an intercept term and drop the Berkeley indicator variable:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="n">model_size_city</code></span><span><code class="o">.</code></span><span><code class="n">params</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Intercept            3.89&#13;
city[T.Lamorinda]    0.09&#13;
city[T.Piedmont]     0.14&#13;
city[T.Richmond]    -0.15&#13;
log_bsqft            0.62&#13;
dtype: float64&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>If we want to drop the intercept, we can add –1 to the formula, which is a convention that indicates dropping the column of ones from the design matrix. In this particular example, the space spanned by all of the one-hot encoded features is equivalent to the space spanned by the 1 vector and all but one of the dummy variables, so the fit is the same. However, the coefficients are different as they reflect the different parameterization of the design matrix:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">smf</code></span><span><code class="o">.</code></span><span><code class="n">ols</code></span><span><code class="p">(</code></span><span><code class="n">formula</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">log_price ~ log_bsqft + city - 1</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">data</code></span><span><code class="o">=</code></span><span><code class="n">sfh</code></span><span><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">params</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
city[Berkeley]     3.89&#13;
city[Lamorinda]    3.98&#13;
city[Piedmont]     4.03&#13;
city[Richmond]     3.75&#13;
log_bsqft          0.62&#13;
dtype: float64&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Additionally, we can add interaction terms between the city and size variables to allow each city to have a different coefficient for size. We specify this in the formula by adding the term <code>log_bsqft:city</code>. We don’t go into details here.</p>&#13;
&#13;
<p>Now let’s fit a model with two categorical variables: the number of bedrooms and the city. Recall that we earlier reassigned the count of bedrooms that were above 6 to 6, which essentially collapses 6, 7, 8, … into the category 6+. We can see this relationship in the box plots of price (log $) by the number of bedrooms:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">box</code></span><span><code class="p">(</code></span><span><code class="n">sfh</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s2">"</code><code class="s2">br</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="s2">"</code><code class="s2">log_price</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">450</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">250</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>       </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="p">{</code></span><span><code class="s1">'</code><code class="s1">br</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">Number of bedrooms</code><code class="s1">'</code></span><span><code class="p">,</code></span><span><code class="s1">'</code><code class="s1">log_price</code><code class="s1">'</code></span><span><code class="p">:</code></span><span><code class="s1">'</code><code class="s1">Sale price (log USD)</code><code class="s1">'</code></span><span><code class="p">}</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-75"><div class="figure"><img src="assets/leds_15in16.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The relationship does not appear linear: for each additional bedroom, the sale price does not increase by the same amount. Given that the number of bedrooms is discrete, we can treat this feature as categorical, which allows each bedroom encoding to contribute a different amount to the cost:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">model_size_city_br</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">smf</code></span><span><code class="o">.</code></span><span><code class="n">ols</code></span><span><code class="p">(</code></span><span><code class="n">formula</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">log_price ~ log_bsqft + city + C(br)</code><code class="s1">'</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                             </code><span><code class="n">data</code></span><span><code class="o">=</code></span><span><code class="n">sfh</code></span><span><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We have used the term <code>C(br)</code> in the formula to indicate that we want the number of bedrooms, which is numeric, to be treated like a categorical variable.</p>&#13;
&#13;
<p>Let’s examine the multiple<a contenteditable="false" data-primary="R² (coefficient of determination)" data-type="indexterm" id="id1635"/><a contenteditable="false" data-primary="multiple R²" data-type="indexterm" id="id1636"/> <span><math> <msup> <mi>R</mi> <mn>2</mn> </msup> </math></span> from the fit:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">model_size_city_br</code></span><span><code class="o">.</code></span><span><code class="n">rsquared</code></span><span><code class="o">.</code></span><span><code class="n">round</code></span><span><code class="p">(</code></span><span><code class="mi">2</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
0.79&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The multiple <span><math> <msup> <mi>R</mi> <mn>2</mn> </msup> </math></span> has not increased even though we have added five more one-hot encoded features. The <span><math> <msup> <mi>R</mi> <mn>2</mn> </msup> </math></span> is adjusted for the number of parameters in the model and by this measure is no better than the earlier one that included only city and size.</p>&#13;
&#13;
<p>In this section, we introduced feature engineering for qualitative features. We saw how the one-hot encoding technique lets us include categorical data in linear models and gives a natural interpretation for model parameters<a contenteditable="false" data-primary="" data-startref="ix_lin_mod_cat_meas" data-type="indexterm" id="id1637"/><a contenteditable="false" data-primary="" data-startref="ix_cat_data_feat_engin" data-type="indexterm" id="id1638"/><a contenteditable="false" data-primary="" data-startref="ix_feat_engin_cat_data" data-type="indexterm" id="id1639"/><a contenteditable="false" data-primary="" data-startref="ix_feat_feat_engin2" data-type="indexterm" id="id1640"/><a contenteditable="false" data-primary="" data-startref="ix_one_hot_enc" data-type="indexterm" id="id1641"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="sec-linear-summary">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>Linear models help us describe relationships between features. We discussed the simple linear model and extended it to linear models in multiple variables. Along the way, we applied mathematical techniques that are widely useful in modeling—calculus to minimize loss for the simple linear model and matrix geometry for the multiple linear model.</p>&#13;
&#13;
<p>Linear models may seem basic, but they are used for all sorts of tasks today. And they are flexible enough to allow us to include categorical features as well as nonlinear transformations of variables, such as log transformations, polynomials, and ratios. Linear models have the advantage of being broadly interpretable for nontechnical people, yet sophisticated enough to capture many common patterns in data.</p>&#13;
&#13;
<p>It can be tempting to throw all of the variables available to us into a model to get the “best fit possible.” But we should keep in mind the geometry of least squares when fitting models. Recall that <span><math> <mi>p</mi> </math></span> explanatory variables can be thought of as <span><math> <mi>p</mi> </math></span> vectors in <span><math> <mi>n</mi> </math></span>-dimensional space, and if these vectors are highly correlated, then the projections onto this space will be similar to projections onto smaller spaces made up of fewer vectors. This implies that:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Adding more variables may not provide a large improvement in the model.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Interpretation of the coefficients can be difficult.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Several models can be equally effective in predicting/explaining the response variable.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>If we are concerned with making inferences, where we want to interpret/understand the model, then we should err on the side of simpler models. On the other hand, if our primary concern is the predictive ability of a model, then we tend not to concern ourselves with the number of coefficients and their interpretation. But this “black box” approach can lead to models that, say, overly depend on anomalous values in the data or models that are inadequate in other ways. So be careful with this approach, especially when the predictions may be harmful to people<a contenteditable="false" data-primary="" data-startref="ix_lin_mod_ch15" data-type="indexterm" id="id1642"/>.</p>&#13;
&#13;
<p>In this chapter, we used linear models in a descriptive way. We introduced a few notions for deciding when to include a feature in a model by examining residuals for patterns, comparing the size of standard errors and the change in the multiple <span><math> <msup> <mi>R</mi> <mn>2</mn> </msup> </math></span>. Oftentimes, we settled for a simpler model that was easier to interpret. In the next chapter, we look at other, more formal tools for choosing the features to include in a model.</p>&#13;
</div></section>&#13;
</div></section></body></html>