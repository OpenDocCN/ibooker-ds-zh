["```py\nraw_user_artist_path = \"data/audioscrobbler_data/user_artist_data.txt\"\nraw_user_artist_data = spark.read.text(raw_user_artist_path)\n\nraw_user_artist_data.show(5)\n\n...\n+-------------------+\n|              value|\n+-------------------+\n|       1000002 1 55|\n| 1000002 1000006 33|\n|  1000002 1000007 8|\n|1000002 1000009 144|\n|1000002 1000010 314|\n+-------------------+\n```", "```py\nraw_artist_data = spark.read.text(\"data/audioscrobbler_data/artist_data.txt\")\n\nraw_artist_data.show(5)\n\n...\n+--------------------+\n|               value|\n+--------------------+\n|1134999\\t06Crazy ...|\n|6821360\\tPang Nak...|\n|10113088\\tTerfel,...|\n|10151459\\tThe Fla...|\n|6826647\\tBodensta...|\n+--------------------+\nonly showing top 5 rows\n...\n\nraw_artist_alias = spark.read.text(\"data/audioscrobbler_data/artist_alias.txt\")\n\nraw_artist_alias.show(5)\n\n...\n+-----------------+\n|            value|\n+-----------------+\n| 1092764\\t1000311|\n| 1095122\\t1000557|\n| 6708070\\t1007267|\n|10088054\\t1042317|\n| 1195917\\t1042317|\n+-----------------+\nonly showing top 5 rows\n```", "```py\nfrom pyspark.ml.recommendation import ALS\n\nals = ALS(maxIter=5, regParam=0.01, userCol=\"user\",\n          itemCol=\"artist\", ratingCol=\"count\")\nmodel = als.fit(train)\n\npredictions = model.transform(test)\n```", "```py\nraw_user_artist_data.show(10)\n\n...\n+-------------------+\n|              value|\n+-------------------+\n|       1000002 1 55|\n| 1000002 1000006 33|\n|  1000002 1000007 8|\n|1000002 1000009 144|\n|1000002 1000010 314|\n|  1000002 1000013 8|\n| 1000002 1000014 42|\n| 1000002 1000017 69|\n|1000002 1000024 329|\n|  1000002 1000025 1|\n+-------------------+\n```", "```py\nfrom pyspark.sql.functions import split, min, max\nfrom pyspark.sql.types import IntegerType, StringType\n\nuser_artist_df = raw_user_artist_data.withColumn('user',\n                                    split(raw_user_artist_data['value'], ' ').\\\n                                    getItem(0).\\\n                                    cast(IntegerType()))\nuser_artist_df = user_artist_df.withColumn('artist',\n                                    split(raw_user_artist_data['value'], ' ').\\\n                                    getItem(1).\\\n                                    cast(IntegerType()))\nuser_artist_df = user_artist_df.withColumn('count',\n                                    split(raw_user_artist_data['value'], ' ').\\\n                                    getItem(2).\\\n                                    cast(IntegerType())).drop('value')\n\nuser_artist_df.select([min(\"user\"), max(\"user\"), min(\"artist\"),\\\n                                    max(\"artist\")]).show()\n...\n+---------+---------+-----------+-----------+\n|min(user)|max(user)|min(artist)|max(artist)|\n+---------+---------+-----------+-----------+\n|       90|  2443548|          1|   10794401|\n+---------+---------+-----------+-----------+\n```", "```py\nfrom pyspark.sql.functions import col\n\nartist_by_id = raw_artist_data.withColumn('id', split(col('value'), '\\s+', 2).\\\n                                                getItem(0).\\\n                                                cast(IntegerType()))\nartist_by_id = artist_by_id.withColumn('name', split(col('value'), '\\s+', 2).\\\n                                               getItem(1).\\\n                                               cast(StringType())).drop('value')\n\nartist_by_id.show(5)\n...\n+--------+--------------------+\n|      id|                name|\n+--------+--------------------+\n| 1134999|        06Crazy Life|\n| 6821360|        Pang Nakarin|\n|10113088|Terfel, Bartoli- ...|\n|10151459| The Flaming Sidebur|\n| 6826647|   Bodenstandig 3000|\n+--------+--------------------+\n```", "```py\nartist_alias = raw_artist_alias.withColumn('artist',\n                                          split(col('value'), '\\s+').\\\n                                                getItem(0).\\\n                                                cast(IntegerType())).\\\n                                withColumn('alias',\n                                            split(col('value'), '\\s+').\\\n                                            getItem(1).\\\n                                            cast(StringType())).\\\n                                drop('value')\n\nartist_alias.show(5)\n...\n+--------+-------+\n|  artist|  alias|\n+--------+-------+\n| 1092764|1000311|\n| 1095122|1000557|\n| 6708070|1007267|\n|10088054|1042317|\n| 1195917|1042317|\n+--------+-------+\n```", "```py\nartist_by_id.filter(artist_by_id.id.isin(1092764, 1000311)).show()\n...\n\n+-------+--------------+\n|     id|          name|\n+-------+--------------+\n|1000311| Steve Winwood|\n|1092764|Winwood, Steve|\n+-------+--------------+\n```", "```py\nfrom pyspark.sql.functions import broadcast, when\n\ntrain_data = train_data = user_artist_df.join(broadcast(artist_alias),\n                                              'artist', how='left').\\ train_data = train_data.withColumn('artist',\n                                    when(col('alias').isNull(), col('artist')).\\\n                                    otherwise(col('alias'))) ![1](assets/1.png)\ntrain_data = train_data.withColumn('artist', col('artist').\\\n                                             cast(IntegerType())).\\\n                                             drop('alias')\n\ntrain_data.cache()\n\ntrain_data.count()\n...\n24296858\n```", "```py\nfrom pyspark.ml.recommendation import ALS\n\nmodel = ALS(rank=10, seed=0, maxIter=5, regParam=0.1,\n            implicitPrefs=True, alpha=1.0, userCol='user',\n            itemCol='artist', ratingCol='count'). \\\n        fit(train_data)\n```", "```py\nmodel.userFactors.show(1, truncate = False)\n\n...\n+---+----------------------------------------------- ...\n|id |features                                        ...\n+---+----------------------------------------------- ...\n|90 |[0.16020626, 0.20717518, -0.1719469, 0.06038466 ...\n+---+----------------------------------------------- ...\n```", "```py\nuser_id = 2093760\n\nexisting_artist_ids = train_data.filter(train_data.user == user_id) \\ ![1](assets/1.png)\n  .select(\"artist\").collect() ![2](assets/2.png)\n\nexisting_artist_ids = [i[0] for i in existing_artist_ids]\n\nartist_by_id.filter(col('id').isin(existing_artist_ids)).show() ![3](assets/3.png)\n...\n+-------+---------------+\n|     id|           name|\n+-------+---------------+\n|   1180|     David Gray|\n|    378|  Blackalicious|\n|    813|     Jurassic 5|\n|1255340|The Saw Doctors|\n|    942|         Xzibit|\n+-------+---------------+\n```", "```py\nuser_subset = train_data.select('user').where(col('user') == user_id).distinct()\ntop_predictions = model.recommendForUserSubset(user_subset, 5)\n\ntop_predictions.show()\n...\n+-------+--------------------+\n|   user|     recommendations|\n+-------+--------------------+\n|2093760|[{2814, 0.0294106...|\n+-------+--------------------+\n```", "```py\ntop_predictions_pandas = top_predictions.toPandas()\nprint(top_prediction_pandas)\n...\n      user                                    recommendations\n0  2093760  [(2814, 0.029410675168037415), (1300642, 0.028...\n...\n\nrecommended_artist_ids = [i[0] for i in top_predictions_pandas.\\\n                                        recommendations[0]]\n\nartist_by_id.filter(col('id').isin(recommended_artist_ids)).show()\n...\n+-------+----------+\n|     id|      name|\n+-------+----------+\n|   2814|   50 Cent|\n|   4605|Snoop Dogg|\n|1007614|     Jay-Z|\n|1001819|      2Pac|\n|1300642|  The Game|\n+-------+----------+\n```", "```py\ndef area_under_curve(\n    positive_data,\n    b_all_artist_IDs,\n    predict_function):\n...\n\nall_data = user_artist_df.join(broadcast(artist_alias), 'artist', how='left') \\\n    .withColumn('artist', when(col('alias').isNull(), col('artist'))\\\n    .otherwise(col('alias'))) \\\n    .withColumn('artist', col('artist').cast(IntegerType())).drop('alias')\n\ntrain_data, cv_data = all_data.randomSplit([0.9, 0.1], seed=54321)\ntrain_data.cache()\ncv_data.cache()\n\nall_artist_ids = all_data.select(\"artist\").distinct().count()\nb_all_artist_ids = broadcast(all_artist_ids)\n\nmodel = ALS(rank=10, seed=0, maxIter=5, regParam=0.1,\n            implicitPrefs=True, alpha=1.0, userCol='user',\n            itemCol='artist', ratingCol='count') \\\n        .fit(train_data)\narea_under_curve(cv_data, b_all_artist_ids, model.transform)\n```", "```py\nfrom pyspark.sql.functions import sum as _sum\n\ndef predict_most_listened(train):\n    listen_counts = train.groupBy(\"artist\")\\\n                    .agg(_sum(\"count\").alias(\"prediction\"))\\\n                    .select(\"artist\", \"prediction\")\n\n    return all_data.join(listen_counts, \"artist\", \"left_outer\").\\\n                    select(\"user\", \"artist\", \"prediction\")\n\narea_under_curve(cv_data, b_all_artist_ids, predict_most_listened(train_data))\n```", "```py\nfrom pprint import pprint\nfrom itertools import product\n\nranks = [5, 30]\nreg_params = [4.0, 0.0001]\nalphas = [1.0, 40.0]\nhyperparam_combinations = list(product(*[ranks, reg_params, alphas]))\n\nevaluations = []\n\nfor c in hyperparam_combinations:\n    rank = c[0]\n    reg_param = c[1]\n    alpha = c[2]\n    model = ALS().setSeed(0).setImplicitPrefs(true).setRank(rank).\\\n                  setRegParam(reg_param).setAlpha(alpha).setMaxIter(20).\\\n                  setUserCol(\"user\").setItemCol(\"artist\").\\\n                  setRatingCol(\"count\").setPredictionCol(\"prediction\").\\\n        fit(trainData)\n\n    auc = area_under_curve(cv_aata, b_all_artist_ids, model.transform)\n\n    model.userFactors.unpersist() ![1](assets/1.png)\n    model.itemFactors.unpersist()\n\n    evaluations.append((auc, (rank, regParam, alpha)))\n\nevaluations.sort(key=lambda x:x[0], reverse=True) ![2](assets/2.png)\npprint(evaluations)\n\n...\n(0.8928367485129145,(30,4.0,40.0))\n(0.891835487024326,(30,1.0E-4,40.0))\n(0.8912376926662007,(30,4.0,1.0))\n(0.889240668173946,(5,4.0,40.0))\n(0.8886268430389741,(5,4.0,1.0))\n(0.8883278461068959,(5,1.0E-4,40.0))\n(0.8825350012228627,(5,1.0E-4,1.0))\n(0.8770527940660278,(30,1.0E-4,1.0))\n```", "```py\n+-----------+\n|       name|\n+-----------+\n|  [unknown]|\n|The Beatles|\n|     Eminem|\n|         U2|\n|  Green Day|\n+-----------+\n```", "```py\nsome_users = all_data.select(\"user\").distinct().limit(100) ![1](assets/1.png)\nval someRecommendations =\n  someUsers.map(userID => (userID, makeRecommendations(model, userID, 5)))\nsomeRecommendations.foreach { case (userID, recsDF) =>\n  val recommendedArtists = recsDF.select(\"artist\").as[Int].collect()\n  println(s\"$userID -> ${recommendedArtists.mkString(\", \")}\")\n}\n\n...\n1000190 -> 6694932, 435, 1005820, 58, 1244362\n1001043 -> 1854, 4267, 1006016, 4468, 1274\n1001129 -> 234, 1411, 1307, 189, 121\n...\n```"]