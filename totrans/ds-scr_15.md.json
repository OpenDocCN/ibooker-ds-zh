["```py\ndef predict(alpha: float, beta: float, x_i: float) -> float:\n    return beta * x_i + alpha\n```", "```py\ndef error(alpha: float, beta: float, x_i: float, y_i: float) -> float:\n    \"\"\"\n The error from predicting beta * x_i + alpha\n when the actual value is y_i\n \"\"\"\n    return predict(alpha, beta, x_i) - y_i\n```", "```py\nfrom scratch.linear_algebra import Vector\n\ndef sum_of_sqerrors(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n    return sum(error(alpha, beta, x_i, y_i) ** 2\n               for x_i, y_i in zip(x, y))\n```", "```py\nfrom typing import Tuple\nfrom scratch.linear_algebra import Vector\nfrom scratch.statistics import correlation, standard_deviation, mean\n\ndef least_squares_fit(x: Vector, y: Vector) -> Tuple[float, float]:\n    \"\"\"\n Given two vectors x and y,\n find the least-squares values of alpha and beta\n \"\"\"\n    beta = correlation(x, y) * standard_deviation(y) / standard_deviation(x)\n    alpha = mean(y) - beta * mean(x)\n    return alpha, beta\n```", "```py\nx = [i for i in range(-100, 110, 10)]\ny = [3 * i - 5 for i in x]\n\n# Should find that y = 3x - 5\nassert least_squares_fit(x, y) == (-5, 3)\n```", "```py\nfrom scratch.statistics import num_friends_good, daily_minutes_good\n\nalpha, beta = least_squares_fit(num_friends_good, daily_minutes_good)\nassert 22.9 < alpha < 23.0\nassert 0.9 < beta < 0.905\n```", "```py\nfrom scratch.statistics import de_mean\n\ndef total_sum_of_squares(y: Vector) -> float:\n    \"\"\"the total squared variation of y_i's from their mean\"\"\"\n    return sum(v ** 2 for v in de_mean(y))\n\ndef r_squared(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n    \"\"\"\n the fraction of variation in y captured by the model, which equals\n 1 - the fraction of variation in y not captured by the model\n \"\"\"\n    return 1.0 - (sum_of_sqerrors(alpha, beta, x, y) /\n                  total_sum_of_squares(y))\n\nrsq = r_squared(alpha, beta, num_friends_good, daily_minutes_good)\nassert 0.328 < rsq < 0.330\n```", "```py\nimport random\nimport tqdm\nfrom scratch.gradient_descent import gradient_step\n\nnum_epochs = 10000\nrandom.seed(0)\n\nguess = [random.random(), random.random()]  # choose random value to start\n\nlearning_rate = 0.00001\n\nwith tqdm.trange(num_epochs) as t:\n    for _ in t:\n        alpha, beta = guess\n\n        # Partial derivative of loss with respect to alpha\n        grad_a = sum(2 * error(alpha, beta, x_i, y_i)\n                     for x_i, y_i in zip(num_friends_good,\n                                         daily_minutes_good))\n\n        # Partial derivative of loss with respect to beta\n        grad_b = sum(2 * error(alpha, beta, x_i, y_i) * x_i\n                     for x_i, y_i in zip(num_friends_good,\n                                         daily_minutes_good))\n\n        # Compute loss to stick in the tqdm description\n        loss = sum_of_sqerrors(alpha, beta,\n                               num_friends_good, daily_minutes_good)\n        t.set_description(f\"loss: {loss:.3f}\")\n\n        # Finally, update the guess\n        guess = gradient_step(guess, [grad_a, grad_b], -learning_rate)\n\n# We should get pretty much the same results:\nalpha, beta = guess\nassert 22.9 < alpha < 23.0\nassert 0.9 < beta < 0.905\n```"]