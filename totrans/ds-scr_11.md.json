["```py\nfrom typing import List, Dict\nfrom collections import Counter\nimport math\n\nimport matplotlib.pyplot as plt\n\ndef bucketize(point: float, bucket_size: float) -> float:\n    \"\"\"Floor the point to the next lower multiple of bucket_size\"\"\"\n    return bucket_size * math.floor(point / bucket_size)\n\ndef make_histogram(points: List[float], bucket_size: float) -> Dict[float, int]:\n    \"\"\"Buckets the points and counts how many in each bucket\"\"\"\n    return Counter(bucketize(point, bucket_size) for point in points)\n\ndef plot_histogram(points: List[float], bucket_size: float, title: str = \"\"):\n    histogram = make_histogram(points, bucket_size)\n    plt.bar(histogram.keys(), histogram.values(), width=bucket_size)\n    plt.title(title)\n```", "```py\nimport random\nfrom scratch.probability import inverse_normal_cdf\n\nrandom.seed(0)\n\n# uniform between -100 and 100\nuniform = [200 * random.random() - 100 for _ in range(10000)]\n\n# normal distribution with mean 0, standard deviation 57\nnormal = [57 * inverse_normal_cdf(random.random())\n          for _ in range(10000)]\n```", "```py\nplot_histogram(uniform, 10, \"Uniform Histogram\")\n```", "```py\nplot_histogram(normal, 10, \"Normal Histogram\")\n```", "```py\ndef random_normal() -> float:\n    \"\"\"Returns a random draw from a standard normal distribution\"\"\"\n    return inverse_normal_cdf(random.random())\n\nxs = [random_normal() for _ in range(1000)]\nys1 = [ x + random_normal() / 2 for x in xs]\nys2 = [-x + random_normal() / 2 for x in xs]\n```", "```py\nplt.scatter(xs, ys1, marker='.', color='black', label='ys1')\nplt.scatter(xs, ys2, marker='.', color='gray',  label='ys2')\nplt.xlabel('xs')\nplt.ylabel('ys')\nplt.legend(loc=9)\nplt.title(\"Very Different Joint Distributions\")\nplt.show()\n```", "```py\nfrom scratch.statistics import correlation\n\nprint(correlation(xs, ys1))      # about 0.9\nprint(correlation(xs, ys2))      # about -0.9\n```", "```py\nfrom scratch.linear_algebra import Matrix, Vector, make_matrix\n\ndef correlation_matrix(data: List[Vector]) -> Matrix:\n    \"\"\"\n Returns the len(data) x len(data) matrix whose (i, j)-th entry\n is the correlation between data[i] and data[j]\n \"\"\"\n    def correlation_ij(i: int, j: int) -> float:\n        return correlation(data[i], data[j])\n\n    return make_matrix(len(data), len(data), correlation_ij)\n```", "```py\n# corr_data is a list of four 100-d vectors\nnum_vectors = len(corr_data)\nfig, ax = plt.subplots(num_vectors, num_vectors)\n\nfor i in range(num_vectors):\n    for j in range(num_vectors):\n\n        # Scatter column_j on the x-axis vs. column_i on the y-axis\n        if i != j: ax[i][j].scatter(corr_data[j], corr_data[i])\n\n        # unless i == j, in which case show the series name\n        else: ax[i][j].annotate(\"series \" + str(i), (0.5, 0.5),\n                                xycoords='axes fraction',\n                                ha=\"center\", va=\"center\")\n\n        # Then hide axis labels except left and bottom charts\n        if i < num_vectors - 1: ax[i][j].xaxis.set_visible(False)\n        if j > 0: ax[i][j].yaxis.set_visible(False)\n\n# Fix the bottom-right and top-left axis labels, which are wrong because\n# their charts only have text in them\nax[-1][-1].set_xlim(ax[0][-1].get_xlim())\nax[0][0].set_ylim(ax[0][1].get_ylim())\n\nplt.show()\n```", "```py\nimport datetime\n\nstock_price = {'closing_price': 102.06,\n               'date': datetime.date(2014, 8, 29),\n               'symbol': 'AAPL'}\n```", "```py\n# oops, typo\nstock_price['cosing_price'] = 103.06\n```", "```py\nprices: Dict[datetime.date, float] = {}\n```", "```py\nfrom collections import namedtuple\n\nStockPrice = namedtuple('StockPrice', ['symbol', 'date', 'closing_price'])\nprice = StockPrice('MSFT', datetime.date(2018, 12, 14), 106.03)\n\nassert price.symbol == 'MSFT'\nassert price.closing_price == 106.03\n```", "```py\nfrom typing import NamedTuple\n\nclass StockPrice(NamedTuple):\n    symbol: str\n    date: datetime.date\n    closing_price: float\n\n    def is_high_tech(self) -> bool:\n        \"\"\"It's a class, so we can add methods too\"\"\"\n        return self.symbol in ['MSFT', 'GOOG', 'FB', 'AMZN', 'AAPL']\n\nprice = StockPrice('MSFT', datetime.date(2018, 12, 14), 106.03)\n\nassert price.symbol == 'MSFT'\nassert price.closing_price == 106.03\nassert price.is_high_tech()\n```", "```py\nfrom dataclasses import dataclass\n\n@dataclass\nclass StockPrice2:\n    symbol: str\n    date: datetime.date\n    closing_price: float\n\n    def is_high_tech(self) -> bool:\n        \"\"\"It's a class, so we can add methods too\"\"\"\n        return self.symbol in ['MSFT', 'GOOG', 'FB', 'AMZN', 'AAPL']\n\nprice2 = StockPrice2('MSFT', datetime.date(2018, 12, 14), 106.03)\n\nassert price2.symbol == 'MSFT'\nassert price2.closing_price == 106.03\nassert price2.is_high_tech()\n```", "```py\n# stock split\nprice2.closing_price /= 2\nassert price2.closing_price == 51.03\n```", "```py\n# It's a regular class, so add new fields however you like!\nprice2.cosing_price = 75  # oops\n```", "```py\nclosing_price = float(row[2])\n```", "```py\nfrom dateutil.parser import parse\n\ndef parse_row(row: List[str]) -> StockPrice:\n    symbol, date, closing_price = row\n    return StockPrice(symbol=symbol,\n                      date=parse(date).date(),\n                      closing_price=float(closing_price))\n\n# Now test our function\nstock = parse_row([\"MSFT\", \"2018-12-14\", \"106.03\"])\n\nassert stock.symbol == \"MSFT\"\nassert stock.date == datetime.date(2018, 12, 14)\nassert stock.closing_price == 106.03\n```", "```py\nfrom typing import Optional\nimport re\n\ndef try_parse_row(row: List[str]) -> Optional[StockPrice]:\n    symbol, date_, closing_price_ = row\n\n    # Stock symbol should be all capital letters\n    if not re.match(r\"^[A-Z]+$\", symbol):\n        return None\n\n    try:\n        date = parse(date_).date()\n    except ValueError:\n        return None\n\n    try:\n        closing_price = float(closing_price_)\n    except ValueError:\n        return None\n\n    return StockPrice(symbol, date, closing_price)\n\n# Should return None for errors\nassert try_parse_row([\"MSFT0\", \"2018-12-14\", \"106.03\"]) is None\nassert try_parse_row([\"MSFT\", \"2018-12--14\", \"106.03\"]) is None\nassert try_parse_row([\"MSFT\", \"2018-12-14\", \"x\"]) is None\n\n# But should return same as before if data is good\nassert try_parse_row([\"MSFT\", \"2018-12-14\", \"106.03\"]) == stock\n```", "```py\nAAPL,6/20/2014,90.91\nMSFT,6/20/2014,41.68\nFB,6/20/3014,64.5\nAAPL,6/19/2014,91.86\nMSFT,6/19/2014,n/a\nFB,6/19/2014,64.34\n```", "```py\nimport csv\n\ndata: List[StockPrice] = []\n\nwith open(\"comma_delimited_stock_prices.csv\") as f:\n    reader = csv.reader(f)\n    for row in reader:\n        maybe_stock = try_parse_row(row)\n        if maybe_stock is None:\n            print(f\"skipping invalid row: {row}\")\n        else:\n            data.append(maybe_stock)\n```", "```py\ndata = [\n    StockPrice(symbol='MSFT',\n               date=datetime.date(2018, 12, 24),\n               closing_price=106.03),\n    # ...\n]\n```", "```py\nmax_aapl_price = max(stock_price.closing_price\n                     for stock_price in data\n                     if stock_price.symbol == \"AAPL\")\n```", "```py\nfrom collections import defaultdict\n\nmax_prices: Dict[str, float] = defaultdict(lambda: float('-inf'))\n\nfor sp in data:\n    symbol, closing_price = sp.symbol, sp.closing_price\n    if closing_price > max_prices[symbol]:\n        max_prices[symbol] = closing_price\n```", "```py\nfrom typing import List\nfrom collections import defaultdict\n\n# Collect the prices by symbol\nprices: Dict[str, List[StockPrice]] = defaultdict(list)\n\nfor sp in data:\n    prices[sp.symbol].append(sp)\n```", "```py\n# Order the prices by date\nprices = {symbol: sorted(symbol_prices)\n          for symbol, symbol_prices in prices.items()}\n```", "```py\ndef pct_change(yesterday: StockPrice, today: StockPrice) -> float:\n    return today.closing_price / yesterday.closing_price - 1\n\nclass DailyChange(NamedTuple):\n    symbol: str\n    date: datetime.date\n    pct_change: float\n\ndef day_over_day_changes(prices: List[StockPrice]) -> List[DailyChange]:\n    \"\"\"\n Assumes prices are for one stock and are in order\n \"\"\"\n    return [DailyChange(symbol=today.symbol,\n                        date=today.date,\n                        pct_change=pct_change(yesterday, today))\n            for yesterday, today in zip(prices, prices[1:])]\n```", "```py\nall_changes = [change\n               for symbol_prices in prices.values()\n               for change in day_over_day_changes(symbol_prices)]\n```", "```py\nmax_change = max(all_changes, key=lambda change: change.pct_change)\n# see e.g. http://news.cnet.com/2100-1001-202143.html\nassert max_change.symbol == 'AAPL'\nassert max_change.date == datetime.date(1997, 8, 6)\nassert 0.33 < max_change.pct_change < 0.34\n\nmin_change = min(all_changes, key=lambda change: change.pct_change)\n# see e.g. http://money.cnn.com/2000/09/29/markets/techwrap/\nassert min_change.symbol == 'AAPL'\nassert min_change.date == datetime.date(2000, 9, 29)\nassert -0.52 < min_change.pct_change < -0.51\n```", "```py\nchanges_by_month: List[DailyChange] = {month: [] for month in range(1, 13)}\n\nfor change in all_changes:\n    changes_by_month[change.date.month].append(change)\n\navg_daily_change = {\n    month: sum(change.pct_change for change in changes) / len(changes)\n    for month, changes in changes_by_month.items()\n}\n\n# October is the best month\nassert avg_daily_change[10] == max(avg_daily_change.values())\n```", "```py\nfrom scratch.linear_algebra import distance\n\na_to_b = distance([63, 150], [67, 160])        # 10.77\na_to_c = distance([63, 150], [70, 171])        # 22.14\nb_to_c = distance([67, 160], [70, 171])        # 11.40\n```", "```py\na_to_b = distance([160, 150], [170.2, 160])    # 14.28\na_to_c = distance([160, 150], [177.8, 171])    # 27.53\nb_to_c = distance([170.2, 160], [177.8, 171])  # 13.37\n```", "```py\nfrom typing import Tuple\n\nfrom scratch.linear_algebra import vector_mean\nfrom scratch.statistics import standard_deviation\n\ndef scale(data: List[Vector]) -> Tuple[Vector, Vector]:\n    \"\"\"returns the mean and standard deviation for each position\"\"\"\n    dim = len(data[0])\n\n    means = vector_mean(data)\n    stdevs = [standard_deviation([vector[i] for vector in data])\n              for i in range(dim)]\n\n    return means, stdevs\n\nvectors = [[-3, -1, 1], [-1, 0, 1], [1, 1, 1]]\nmeans, stdevs = scale(vectors)\nassert means == [-1, 0, 1]\nassert stdevs == [2, 1, 0]\n```", "```py\ndef rescale(data: List[Vector]) -> List[Vector]:\n    \"\"\"\n Rescales the input data so that each position has\n mean 0 and standard deviation 1\\. (Leaves a position\n as is if its standard deviation is 0.)\n \"\"\"\n    dim = len(data[0])\n    means, stdevs = scale(data)\n\n    # Make a copy of each vector\n    rescaled = [v[:] for v in data]\n\n    for v in rescaled:\n        for i in range(dim):\n            if stdevs[i] > 0:\n                v[i] = (v[i] - means[i]) / stdevs[i]\n\n    return rescaled\n```", "```py\nmeans, stdevs = scale(rescale(vectors))\nassert means == [0, 0, 1]\nassert stdevs == [1, 1, 0]\n```", "```py\npython -m pip install tqdm\n```", "```py\nimport tqdm\n\nfor i in tqdm.tqdm(range(100)):\n    # do something slow\n    _ = [random.random() for _ in range(1000000)]\n```", "```py\n 56%|████████████████████              | 56/100 [00:08<00:06,  6.49it/s]\n```", "```py\nfrom typing import List\n\ndef primes_up_to(n: int) -> List[int]:\n    primes = [2]\n\n    with tqdm.trange(3, n) as t:\n        for i in t:\n            # i is prime if no smaller prime divides it\n            i_is_prime = not any(i % p == 0 for p in primes)\n            if i_is_prime:\n                primes.append(i)\n\n            t.set_description(f\"{len(primes)} primes\")\n\n    return primes\n\nmy_primes = primes_up_to(100_000)\n```", "```py\n5116 primes:  50%|████████        | 49529/99997 [00:03<00:03, 15905.90it/s]\n```", "```py\nfrom scratch.linear_algebra import subtract\n\ndef de_mean(data: List[Vector]) -> List[Vector]:\n    \"\"\"Recenters the data to have mean 0 in every dimension\"\"\"\n    mean = vector_mean(data)\n    return [subtract(vector, mean) for vector in data]\n```", "```py\nfrom scratch.linear_algebra import magnitude\n\ndef direction(w: Vector) -> Vector:\n    mag = magnitude(w)\n    return [w_i / mag for w_i in w]\n```", "```py\nfrom scratch.linear_algebra import dot\n\ndef directional_variance(data: List[Vector], w: Vector) -> float:\n    \"\"\"\n Returns the variance of x in the direction of w\n \"\"\"\n    w_dir = direction(w)\n    return sum(dot(v, w_dir) ** 2 for v in data)\n```", "```py\ndef directional_variance_gradient(data: List[Vector], w: Vector) -> Vector:\n    \"\"\"\n The gradient of directional variance with respect to w\n \"\"\"\n    w_dir = direction(w)\n    return [sum(2 * dot(v, w_dir) * v[i] for v in data)\n            for i in range(len(w))]\n```", "```py\nfrom scratch.gradient_descent import gradient_step\n\ndef first_principal_component(data: List[Vector],\n                              n: int = 100,\n                              step_size: float = 0.1) -> Vector:\n    # Start with a random guess\n    guess = [1.0 for _ in data[0]]\n\n    with tqdm.trange(n) as t:\n        for _ in t:\n            dv = directional_variance(data, guess)\n            gradient = directional_variance_gradient(data, guess)\n            guess = gradient_step(guess, gradient, step_size)\n            t.set_description(f\"dv: {dv:.3f}\")\n\n    return direction(guess)\n```", "```py\nfrom scratch.linear_algebra import scalar_multiply\n\ndef project(v: Vector, w: Vector) -> Vector:\n    \"\"\"return the projection of v onto the direction w\"\"\"\n    projection_length = dot(v, w)\n    return scalar_multiply(projection_length, w)\n```", "```py\nfrom scratch.linear_algebra import subtract\n\ndef remove_projection_from_vector(v: Vector, w: Vector) -> Vector:\n    \"\"\"projects v onto w and subtracts the result from v\"\"\"\n    return subtract(v, project(v, w))\n\ndef remove_projection(data: List[Vector], w: Vector) -> List[Vector]:\n    return [remove_projection_from_vector(v, w) for v in data]\n```", "```py\ndef pca(data: List[Vector], num_components: int) -> List[Vector]:\n    components: List[Vector] = []\n    for _ in range(num_components):\n        component = first_principal_component(data)\n        components.append(component)\n        data = remove_projection(data, component)\n\n    return components\n```", "```py\ndef transform_vector(v: Vector, components: List[Vector]) -> Vector:\n    return [dot(v, w) for w in components]\n\ndef transform(data: List[Vector], components: List[Vector]) -> List[Vector]:\n    return [transform_vector(v, components) for v in data]\n```"]