- en: Chapter 4\. Regression and Prediction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章 回归与预测
- en: Perhaps the most common goal in statistics is to answer the question “Is the
    variable *X* (or more likely, <math alttext="upper X 1 comma ellipsis comma upper
    X Subscript p Baseline"><mrow><msub><mi>X</mi> <mn>1</mn></msub> <mo>,</mo> <mo>...</mo>
    <mo>,</mo> <msub><mi>X</mi> <mi>p</mi></msub></mrow></math> ) associated with
    a variable *Y*, and if so, what is the relationship and can we use it to predict
    *Y*?”
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学中最常见的目标之一是回答问题“变量*X*（或更可能是<math alttext="upper X 1 comma ellipsis comma upper
    X Subscript p Baseline"><mrow><msub><mi>X</mi> <mn>1</mn></msub> <mo>,</mo> <mo>...</mo>
    <mo>,</mo> <msub><mi>X</mi> <mi>p</mi></msub></mrow></math>）与变量*Y*是否相关，如果相关，它们之间的关系是什么，我们能否用它来预测*Y*？”
- en: Nowhere is the nexus between statistics and data science stronger than in the
    realm of prediction—specifically, the prediction of an outcome (target) variable
    based on the values of other “predictor” variables. This process of training a
    model on data where the outcome is known, for subsequent application to data where
    the outcome is not known, is termed *supervised learning*. Another important connection
    between data science and statistics is in the area of *anomaly detection*, where
    regression diagnostics originally intended for data analysis and improving the
    regression model can be used to detect unusual records.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学和数据科学之间的联系在预测领域尤为显著，特别是基于其他“预测”变量的值来预测结果（目标）变量。在这个过程中，通过已知结果的数据训练模型，然后应用于结果未知的数据，被称为*监督学习*。数据科学和统计学之间的另一个重要联系在于*异常检测*领域，其中最初用于数据分析和改进回归模型的回归诊断方法可以用于检测异常记录。
- en: Simple Linear Regression
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单线性回归
- en: Simple linear regression provides a model of the relationship between the magnitude
    of one variable and that of a second—for example, as *X* increases, *Y* also increases.
    Or as *X* increases, *Y* decreases.^([1](ch04.xhtml#idm46522856635400)) Correlation
    is another way to measure how two variables are related—see the section [“Correlation”](ch01.xhtml#Correlations).
    The difference is that while correlation measures the *strength* of an association
    between two variables, regression quantifies the *nature* of the relationship.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 简单线性回归提供了一个描述一个变量的大小与第二个变量的大小之间关系的模型，例如，随着*X*的增加，*Y*也增加。或者随着*X*的增加，*Y*减少^([1](ch04.xhtml#idm46522856635400))。相关性是衡量两个变量关系的另一种方法，请参见[“相关性”](ch01.xhtml#Correlations)部分。不同之处在于，相关性衡量了两个变量之间关系的*强度*，而回归则量化了这种关系的*性质*。
- en: The Regression Equation
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归方程
- en: 'Simple linear regression estimates how much *Y* will change when *X* changes
    by a certain amount. With the correlation coefficient, the variables *X* and *Y*
    are interchangeable. With regression, we are trying to predict the *Y* variable
    from *X* using a linear relationship (i.e., a line):'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 简单线性回归估计了*X*变化一定量时*Y*会如何变化。通过相关系数，变量*X*和*Y*是可以互换的。通过回归，我们尝试使用线性关系（即一条直线）来预测*Y*变量：
- en: <math display="block" alttext="upper Y equals b 0 plus b 1 upper X"><mrow><mi>Y</mi>
    <mo>=</mo> <msub><mi>b</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub>
    <mi>X</mi></mrow></math>
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block" alttext="upper Y equals b 0 plus b 1 upper X"><mrow><mi>Y</mi>
    <mo>=</mo> <msub><mi>b</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub>
    <mi>X</mi></mrow></math>
- en: We read this as “Y equals b[1] times X, plus a constant b[0].” The symbol <math
    alttext="b 0"><msub><mi>b</mi> <mn>0</mn></msub></math> is known as the *intercept*
    (or constant), and the symbol <math alttext="b 1"><msub><mi>b</mi> <mn>1</mn></msub></math>
    as the *slope* for *X*. Both appear in *R* output as *coefficients*, though in
    general use the term *coefficient* is often reserved for <math alttext="b 1"><msub><mi>b</mi>
    <mn>1</mn></msub></math> . The *Y* variable is known as the *response* or *dependent*
    variable since it depends on *X*. The *X* variable is known as the *predictor*
    or *independent* variable. The machine learning community tends to use other terms,
    calling *Y* the *target* and *X* a *feature* vector. Throughout this book, we
    will use the terms *predictor* and *feature* interchangeably.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个关系读作“Y等于b[1]乘以X，再加上一个常数b[0]”。符号<math alttext="b 0"><msub><mi>b</mi> <mn>0</mn></msub></math>被称为*截距*（或常数），符号<math
    alttext="b 1"><msub><mi>b</mi> <mn>1</mn></msub></math>被称为*X*的*斜率*。在*R*输出中，它们都显示为*系数*，尽管在一般用法中，术语*系数*通常保留给<math
    alttext="b 1"><msub><mi>b</mi> <mn>1</mn></msub></math>。*Y*变量被称为*响应*或*因变量*，因为它取决于*X*。*X*变量被称为*预测*或*自变量*。机器学习社区倾向于使用其他术语，称*Y*为*目标*，*X*为*特征*向量。在本书中，我们将*预测*和*特征*这两个术语互换使用。
- en: Consider the scatterplot in [Figure 4-1](#cotton) displaying the number of years
    a worker was exposed to cotton dust (`Exposure`) versus a measure of lung capacity
    (`PEFR` or “peak expiratory flow rate”). How is `PEFR` related to `Exposure`?
    It’s hard to tell based just on the picture.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑散点图 [Figure 4-1](#cotton)，显示工人暴露于棉尘的年数（`Exposure`）与肺活量的测量（`PEFR`或“呼气流量峰值”）。`PEFR`与`Exposure`有什么关系？仅凭图片很难判断。
- en: '![images/lung_scatter.png](Images/psd2_0401.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![images/lung_scatter.png](Images/psd2_0401.png)'
- en: Figure 4-1\. Cotton exposure versus lung capacity
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1\. 棉尘暴露与肺活量
- en: 'Simple linear regression tries to find the “best” line to predict the response
    `PEFR` as a function of the predictor variable `Exposure`:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 简单线性回归试图找到最佳线来预测响应变量`PEFR`与预测变量`Exposure`之间的关系：
- en: <math display="block" alttext="PEFR equals b 0 plus b 1 Exposure"><mrow><mtext>PEFR</mtext>
    <mo>=</mo> <msub><mi>b</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub>
    <mtext>Exposure</mtext></mrow></math>
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block" alttext="PEFR equals b 0 plus b 1 Exposure"><mrow><mtext>PEFR</mtext>
    <mo>=</mo> <msub><mi>b</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub>
    <mtext>Exposure</mtext></mrow></math>
- en: 'The `lm` function in *R* can be used to fit a linear regression:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在*R*中，`lm`函数可用于拟合线性回归：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`lm` stands for *linear model*, and the `~` symbol denotes that `PEFR` is predicted
    by `Exposure`. With this model definition, the intercept is automatically included
    and fitted. If you want to exclude the intercept from the model, you need to write
    the model definition as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`lm`代表*线性模型*，`~`符号表示`PEFR`由`Exposure`预测。在此模型定义中，截距自动包含并适合。如果要从模型中排除截距，需要将模型定义写成如下形式：'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Printing the `model` object produces the following output:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 打印`model`对象将产生以下输出：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The intercept, or <math alttext="b 0"><msub><mi>b</mi> <mn>0</mn></msub></math>
    , is 424.583 and can be interpreted as the predicted `PEFR` for a worker with
    zero years exposure. The regression coefficient, or <math alttext="b 1"><msub><mi>b</mi>
    <mn>1</mn></msub></math> , can be interpreted as follows: for each additional
    year that a worker is exposed to cotton dust, the worker’s `PEFR` measurement
    is reduced by –4.185.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 截距，即<math alttext="b 0"><msub><mi>b</mi> <mn>0</mn></msub></math>，为424.583，可解释为对于经历零年棉尘暴露的工人预测的`PEFR`。回归系数，或<math
    alttext="b 1"><msub><mi>b</mi> <mn>1</mn></msub></math>，可解释如下：每增加一年的棉尘暴露，工人的`PEFR`测量值减少了-4.185。
- en: 'In *Python*, we can use `LinearRegression` from the `scikit-learn` package.
    (the `statsmodels` package has a linear regression implementation that is more
    similar to *R* (`sm.OLS`); we will use it later in this chapter):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Python*中，我们可以使用`scikit-learn`包中的`LinearRegression`。（`statsmodels`包具有更类似于*R*的线性回归实现（`sm.OLS`）；我们稍后将在本章中使用它）：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The regression line from this model is displayed in [Figure 4-2](#lung_model).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的回归线显示在 [Figure 4-2](#lung_model) 中。
- en: '![images/lung_model.png](Images/psd2_0402.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![images/lung_model.png](Images/psd2_0402.png)'
- en: Figure 4-2\. Slope and intercept for the regression fit to the lung data
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. 适合肺活量数据的斜率和截距
- en: Fitted Values and Residuals
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拟合值和残差
- en: 'Important concepts in regression analysis are the *fitted values* (the predictions)
    and *residuals* (prediction errors). In general, the data doesn’t fall exactly
    on a line, so the regression equation should include an explicit error term <math
    alttext="e Subscript i"><msub><mi>e</mi> <mi>i</mi></msub></math> :'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析中的重要概念是*拟合值*（预测值）和*残差*（预测误差）。一般来说，数据不会完全落在一条直线上，因此回归方程应包括显式的误差项 <math alttext="e
    Subscript i"><msub><mi>e</mi> <mi>i</mi></msub></math>：
- en: <math display="block"><mrow><msub><mi>Y</mi> <mi>i</mi></msub> <mo>=</mo> <msub><mi>b</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub> <msub><mi>X</mi>
    <mi>i</mi></msub> <mo>+</mo> <msub><mi>e</mi> <mi>i</mi></msub></mrow></math>
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mi>Y</mi> <mi>i</mi></msub> <mo>=</mo> <msub><mi>b</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub> <msub><mi>X</mi>
    <mi>i</mi></msub> <mo>+</mo> <msub><mi>e</mi> <mi>i</mi></msub></mrow></math>
- en: 'The fitted values, also referred to as the *predicted values*, are typically
    denoted by <math alttext="ModifyingAbove upper Y With caret Subscript i"><msub><mover
    accent="true"><mi>Y</mi> <mo>^</mo></mover> <mi>i</mi></msub></math> (Y-hat).
    These are given by:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合值，也称为*预测值*，通常用<math alttext="ModifyingAbove upper Y With caret Subscript i"><msub><mover
    accent="true"><mi>Y</mi> <mo>^</mo></mover> <mi>i</mi></msub></math>（Y-hat）表示。这些值为：
- en: <math display="block"><mrow><msub><mover accent="true"><mi>Y</mi> <mo>^</mo></mover>
    <mi>i</mi></msub> <mo>=</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mn>0</mn></msub> <mo>+</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mn>1</mn></msub> <msub><mi>X</mi> <mi>i</mi></msub></mrow></math>
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mover accent="true"><mi>Y</mi> <mo>^</mo></mover>
    <mi>i</mi></msub> <mo>=</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mn>0</mn></msub> <mo>+</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mn>1</mn></msub> <msub><mi>X</mi> <mi>i</mi></msub></mrow></math>
- en: The notation <math alttext="ModifyingAbove b With caret Subscript 0"><msub><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mn>0</mn></msub></math> and <math
    alttext="ModifyingAbove b With caret Subscript 1"><msub><mover accent="true"><mi>b</mi>
    <mo>^</mo></mover> <mn>1</mn></msub></math> indicates that the coefficients are
    estimated versus known.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 符号 <math alttext="ModifyingAbove b With caret Subscript 0"><msub><mover accent="true"><mi>b</mi>
    <mo>^</mo></mover> <mn>0</mn></msub></math> 和 <math alttext="ModifyingAbove b
    With caret Subscript 1"><msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mn>1</mn></msub></math> 表示系数是根据已知值进行估计的。
- en: 'Hat Notation: Estimates Versus Known Values'
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 帽子符号：估计值与已知值
- en: The “hat” notation is used to differentiate between estimates and known values.
    So the symbol <math alttext="ModifyingAbove b With caret"><mover accent="true"><mi>b</mi>
    <mo>^</mo></mover></math> (“b-hat”) is an estimate of the unknown parameter <math
    alttext="b"><mi>b</mi></math> . Why do statisticians differentiate between the
    estimate and the true value? The estimate has uncertainty, whereas the true value
    is fixed.^([2](ch04.xhtml#idm46522856258456))
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: “帽子”符号用于区分估计值和已知值。因此，符号 <math alttext="ModifyingAbove b With caret"><mover accent="true"><mi>b</mi>
    <mo>^</mo></mover></math>（“b-hat”）是未知参数 <math alttext="b"><mi>b</mi></math> 的估计值。为什么统计学家要区分估计值和真实值？估计值具有不确定性，而真实值是固定的。^([2](ch04.xhtml#idm46522856258456))
- en: 'We compute the residuals <math alttext="ModifyingAbove e With caret Subscript
    i"><msub><mover accent="true"><mi>e</mi> <mo>^</mo></mover> <mi>i</mi></msub></math>
    by subtracting the *predicted* values from the original data:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过从原始数据中减去*预测*值来计算残差 <math alttext="ModifyingAbove e With caret Subscript
    i"><msub><mover accent="true"><mi>e</mi> <mo>^</mo></mover> <mi>i</mi></msub></math>：
- en: <math display="block"><mrow><msub><mover accent="true"><mi>e</mi> <mo>^</mo></mover>
    <mi>i</mi></msub> <mo>=</mo> <msub><mi>Y</mi> <mi>i</mi></msub> <mo>-</mo> <msub><mover
    accent="true"><mi>Y</mi> <mo>^</mo></mover> <mi>i</mi></msub></mrow></math>
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mover accent="true"><mi>e</mi> <mo>^</mo></mover>
    <mi>i</mi></msub> <mo>=</mo> <msub><mi>Y</mi> <mi>i</mi></msub> <mo>-</mo> <msub><mover
    accent="true"><mi>Y</mi> <mo>^</mo></mover> <mi>i</mi></msub></mrow></math>
- en: 'In *R*, we can obtain the fitted values and residuals using the functions `predict`
    and `residuals`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在*R*中，我们可以使用`predict`和`residuals`函数获取拟合值和残差：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'With `scikit-learn`’s `LinearRegression` model, we use the `predict` method
    on the training data to get the `fitted` values and subsequently the `residuals`.
    As we will see, this is a general pattern that all models in `scikit-learn` follow:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`scikit-learn`的`LinearRegression`模型，我们在训练数据上使用`predict`方法获取`fitted`值，然后获取`residuals`。正如我们将看到的，这是`scikit-learn`中所有模型遵循的通用模式：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[Figure 4-3](#residuals) illustrates the residuals from the regression line
    fit to the lung data. The residuals are the length of the vertical dashed lines
    from the data to the line.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-3](#residuals)展示了拟合到肺部数据的回归线的残差。残差是从数据点到回归线的垂直虚线的长度。'
- en: '![images/lung_residuals.png](Images/psd2_0403.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![images/lung_residuals.png](Images/psd2_0403.png)'
- en: Figure 4-3\. Residuals from a regression line (to accommodate all the data,
    the y-axis scale differs from [Figure 4-2](#lung_model), hence the apparently
    different slope)
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-3\. 回归线的残差（为了容纳所有数据，y 轴的比例与[图 4-2](#lung_model)不同，因此看起来斜率明显不同）
- en: Least Squares
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最小二乘法
- en: 'How is the model fit to the data? When there is a clear relationship, you could
    imagine fitting the line by hand. In practice, the regression line is the estimate
    that minimizes the sum of squared residual values, also called the *residual sum
    of squares* or *RSS*:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 数据如何拟合模型？当存在明显关系时，可以想象手动拟合线条。实际上，回归线是通过最小化残差平方和（也称为*残差平方和*或*RSS*）的估计来确定的：
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>R</mi>
    <mi>S</mi> <mi>S</mi></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><munderover><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></munderover> <msup><mfenced
    separators="" open="(" close=")"><msub><mi>Y</mi> <mi>i</mi></msub> <mo>-</mo><msub><mover
    accent="true"><mi>Y</mi> <mo>^</mo></mover> <mi>i</mi></msub></mfenced> <mn>2</mn></msup></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><munderover><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></munderover> <msup><mfenced
    separators="" open="(" close=")"><msub><mi>Y</mi> <mi>i</mi></msub> <mo>-</mo><msub><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mn>0</mn></msub> <mo>-</mo><msub><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mn>1</mn></msub> <msub><mi>X</mi>
    <mi>i</mi></msub></mfenced> <mn>2</mn></msup></mrow></mtd></mtr></mtable></math>
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>R</mi>
    <mi>S</mi> <mi>S</mi></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><munderover><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></munderover> <msup><mfenced
    separators="" open="(" close=")"><msub><mi>Y</mi> <mi>i</mi></msub> <mo>-</mo><msub><mover
    accent="true"><mi>Y</mi> <mo>^</mo></mover> <mi>i</mi></msub></mfenced> <mn>2</mn></msup></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><munderover><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></munderover> <msup><mfenced
    separators="" open="(" close=")"><msub><mi>Y</mi> <mi>i</mi></msub> <mo>-</mo><msub><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mn>0</mn></msub> <mo>-</mo><msub><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mn>1</mn></msub> <msub><mi>X</mi>
    <mi>i</mi></msub></mfenced> <mn>2</mn></msup></mrow></mtd></mtr></mtable></math>
- en: The estimates <math alttext="ModifyingAbove b With caret Subscript 0"><msub><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mn>0</mn></msub></math> and <math
    alttext="ModifyingAbove b With caret Subscript 1"><msub><mover accent="true"><mi>b</mi>
    <mo>^</mo></mover> <mn>1</mn></msub></math> are the values that minimize RSS.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 估计值 <math alttext="ModifyingAbove b With caret Subscript 0"><msub><mover accent="true"><mi>b</mi>
    <mo>^</mo></mover> <mn>0</mn></msub></math> 和 <math alttext="ModifyingAbove b
    With caret Subscript 1"><msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mn>1</mn></msub></math> 是使残差平方和最小化的值。
- en: The method of minimizing the sum of the squared residuals is termed *least squares*
    regression, or *ordinary least squares* (OLS) regression. It is often attributed
    to Carl Friedrich Gauss, the German mathematician, but was first published by
    the French mathematician Adrien-Marie Legendre in 1805. Least squares regression
    can be computed quickly and easily with any standard statistical software.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法回归，又称普通最小二乘（OLS）回归，是通过最小化残差平方和来估计拟合线的方法。虽然通常认为这个方法最早由德国数学家卡尔·弗里德里希·高斯提出，但实际上是由法国数学家阿德里安-玛丽·勒让德于1805年首次发表。任何标准统计软件都可以快速、轻松地计算最小二乘法回归。
- en: Historically, computational convenience is one reason for the widespread use
    of least squares in regression. With the advent of big data, computational speed
    is still an important factor. Least squares, like the mean (see [“Median and Robust
    Estimates”](ch01.xhtml#Median)), are sensitive to outliers, although this tends
    to be a significant problem only in small or moderate-sized data sets. See [“Outliers”](#regression_outliers)
    for a discussion of outliers in regression.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上，计算方便是广泛使用最小二乘法回归的原因之一。随着大数据的出现，计算速度仍然是一个重要因素。最小二乘法与均值（参见[“中位数和鲁棒估计”](ch01.xhtml#Median)）一样，对异常值敏感，尽管这通常只在小型或中型数据集中是一个显著问题。请参见[“异常值”](#regression_outliers)讨论回归中的异常值。
- en: Regression Terminology
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归术语
- en: When analysts and researchers use the term *regression* by itself, they are
    typically referring to linear regression; the focus is usually on developing a
    linear model to explain the relationship between predictor variables and a numeric
    outcome variable. In its formal statistical sense, regression also includes nonlinear
    models that yield a functional relationship between predictors and outcome variables.
    In the machine learning community, the term is also occasionally used loosely
    to refer to the use of any predictive model that produces a predicted numeric
    outcome (as opposed to classification methods that predict a binary or categorical
    outcome).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当分析师和研究人员单独使用术语*回归*时，他们通常是指线性回归；重点通常在于开发一个线性模型，以解释预测变量与数值结果变量之间的关系。在其正式统计意义上，回归还包括产生预测变量和结果变量之间功能关系的非线性模型。在机器学习社区中，这个术语偶尔也被宽泛地用来指代产生预测数值结果的任何预测模型（与预测二元或分类结果的方法相对）。
- en: Prediction Versus Explanation (Profiling)
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测与解释（分析）
- en: Historically, a primary use of regression was to illuminate a supposed linear
    relationship between predictor variables and an outcome variable. The goal has
    been to understand a relationship and explain it using the data that the regression
    was fit to. In this case, the primary focus is on the estimated slope of the regression
    equation, <math alttext="ModifyingAbove b With caret"><mover accent="true"><mi>b</mi>
    <mo>^</mo></mover></math> . Economists want to know the relationship between consumer
    spending and GDP growth. Public health officials might want to understand whether
    a public information campaign is effective in promoting safe sex practices. In
    such cases, the focus is not on predicting individual cases but rather on understanding
    the overall relationship among variables.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上，回归的主要用途是阐明预测变量与结果变量之间的假定线性关系。其目标是理解这种关系，并使用回归拟合的数据来解释它。在这种情况下，主要关注回归方程的估计斜率<math
    alttext="ModifyingAbove b With caret"><mover accent="true"><mi>b</mi> <mo>^</mo></mover></math>
    。经济学家想要了解消费者支出与GDP增长之间的关系。公共卫生官员可能希望了解公共信息宣传活动是否有效促进安全性行为实践。在这些情况下，重点不在于预测个别案例，而在于理解变量之间的整体关系。
- en: With the advent of big data, regression is widely used to form a model to predict
    individual outcomes for new data (i.e., a predictive model) rather than explain
    data in hand. In this instance, the main items of interest are the fitted values
    <math alttext="ModifyingAbove upper Y With caret"><mover accent="true"><mi>Y</mi>
    <mo>^</mo></mover></math> . In marketing, regression can be used to predict the
    change in revenue in response to the size of an ad campaign. Universities use
    regression to predict students’ GPA based on their SAT scores.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大数据的出现，回归广泛用于形成模型以预测新数据的个别结果（即预测模型），而不是解释手头的数据。在这种情况下，主要关注的是拟合值 <math alttext="ModifyingAbove
    upper Y With caret"><mover accent="true"><mi>Y</mi> <mo>^</mo></mover></math>
    。在营销中，回归可以用来预测广告活动规模对收入变化的影响。大学使用回归来预测学生的GPA，基于他们的SAT成绩。
- en: A regression model that fits the data well is set up such that changes in *X*
    lead to changes in *Y*. However, by itself, the regression equation does not prove
    the direction of causation. Conclusions about causation must come from a broader
    understanding about the relationship. For example, a regression equation might
    show a definite relationship between number of clicks on a web ad and number of
    conversions. It is our knowledge of the marketing process, not the regression
    equation, that leads us to the conclusion that clicks on the ad lead to sales,
    and not vice versa.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一个良好拟合数据的回归模型被设置为使*X*的变化导致*Y*的变化。然而，单独的回归方程并不能证明因果关系的方向。关于因果关系的结论必须来自对关系更广泛的理解。例如，回归方程可能显示网页广告点击次数与转化次数之间存在明确的关系。是我们对营销过程的了解，而不是回归方程，使我们得出点击广告导致销售而不是相反的结论。
- en: Further Reading
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: For an in-depth treatment of prediction versus explanation, see Galit Shmueli’s
    article [“To Explain or to Predict?”](https://oreil.ly/4fVUY).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 深入探讨预测与解释，请参阅加利特·舒默利的文章 [“解释还是预测？”](https://oreil.ly/4fVUY)。
- en: Multiple Linear Regression
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多元线性回归
- en: 'When there are multiple predictors, the equation is simply extended to accommodate
    them:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当存在多个预测变量时，方程式简单地扩展以适应它们：
- en: <math display="block"><mrow><mi>Y</mi> <mo>=</mo> <msub><mi>b</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub> <msub><mi>X</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>b</mi> <mn>2</mn></msub> <msub><mi>X</mi> <mn>2</mn></msub>
    <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>b</mi> <mi>p</mi></msub> <msub><mi>X</mi>
    <mi>p</mi></msub> <mo>+</mo> <mi>e</mi></mrow></math>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>Y</mi> <mo>=</mo> <msub><mi>b</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub> <msub><mi>X</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>b</mi> <mn>2</mn></msub> <msub><mi>X</mi> <mn>2</mn></msub>
    <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>b</mi> <mi>p</mi></msub> <msub><mi>X</mi>
    <mi>p</mi></msub> <mo>+</mo> <mi>e</mi></mrow></math>
- en: Instead of a line, we now have a linear model—the relationship between each
    coefficient and its variable (feature) is linear.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在不再是一条线，我们有一个线性模型—每个系数与其变量（特征）之间的关系是线性的。
- en: 'All of the other concepts in simple linear regression, such as fitting by least
    squares and the definition of fitted values and residuals, extend to the multiple
    linear regression setting. For example, the fitted values are given by:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在简单线性回归中的所有其他概念，如最小二乘法拟合以及拟合值和残差的定义，都扩展到多元线性回归设置中。例如，拟合值由以下公式给出：
- en: <math display="block"><mrow><msub><mover accent="true"><mi>Y</mi> <mo>^</mo></mover>
    <mi>i</mi></msub> <mo>=</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mn>0</mn></msub> <mo>+</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mn>1</mn></msub> <msub><mi>X</mi> <mrow><mn>1</mn><mo>,</mo><mi>i</mi></mrow></msub>
    <mo>+</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover> <mn>2</mn></msub>
    <msub><mi>X</mi> <mrow><mn>2</mn><mo>,</mo><mi>i</mi></mrow></msub> <mo>+</mo>
    <mo>...</mo> <mo>+</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mi>p</mi></msub> <msub><mi>X</mi> <mrow><mi>p</mi><mo>,</mo><mi>i</mi></mrow></msub></mrow></math>
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mover accent="true"><mi>Y</mi> <mo>^</mo></mover>
    <mi>i</mi></msub> <mo>=</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mn>0</mn></msub> <mo>+</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mn>1</mn></msub> <msub><mi>X</mi> <mrow><mn>1</mn><mo>,</mo><mi>i</mi></mrow></msub>
    <mo>+</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover> <mn>2</mn></msub>
    <msub><mi>X</mi> <mrow><mn>2</mn><mo>,</mo><mi>i</mi></mrow></msub> <mo>+</mo>
    <mo>...</mo> <mo>+</mo> <msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mi>p</mi></msub> <msub><mi>X</mi> <mrow><mi>p</mi><mo>,</mo><mi>i</mi></mrow></msub></mrow></math>
- en: 'Example: King County Housing Data'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例：King County房屋数据
- en: 'An example of using multiple linear regression is in estimating the value of
    houses. County assessors must estimate the value of a house for the purposes of
    assessing taxes. Real estate professionals and home buyers consult popular websites
    such as [Zillow](https://zillow.com) to ascertain a fair price. Here are a few
    rows of housing data from King County (Seattle), Washington, from the `house data.frame`:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 多元线性回归的一个例子是估算房屋价值。县评估员必须估算房屋的价值以进行税收评估。房地产专业人士和购房者参考流行的网站，如[Zillow](https://zillow.com)，以确定公正的价格。以下是华盛顿州西雅图市金县（King
    County）的几行住房数据，来自`house data.frame`：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `head` method of `pandas` data frame lists the top rows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`数据框的`head`方法列出了顶部几行：'
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The goal is to predict the sales price from the other variables. The `lm` function
    handles the multiple regression case simply by including more terms on the righthand
    side of the equation; the argument `na.action=na.omit` causes the model to drop
    records that have missing values:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是根据其他变量预测销售价格。`lm`函数通过在方程右侧包含更多项简单地处理多重回归情况；参数`na.action=na.omit`使得模型丢弃具有缺失值的记录：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`scikit-learn`’s `LinearRegression` can be used for multiple linear regression
    as well:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn`的`LinearRegression`也可以用于多元线性回归：'
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Printing `house_lm` object produces the following output:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 打印`house_lm`对象会产生以下输出：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'For a `LinearRegression` model, intercept and coefficients are the fields `intercept_`
    and `coef_` of the fitted model:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`LinearRegression`模型，截距和系数分别是拟合模型的`intercept_`和`coef_`字段：
- en: '[PRE11]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The interpretation of the coefficients is as with simple linear regression:
    the predicted value <math alttext="ModifyingAbove upper Y With caret"><mover accent="true"><mi>Y</mi>
    <mo>^</mo></mover></math> changes by the coefficient <math alttext="b Subscript
    j"><msub><mi>b</mi> <mi>j</mi></msub></math> for each unit change in <math alttext="upper
    X Subscript j"><msub><mi>X</mi> <mi>j</mi></msub></math> assuming all the other
    variables, <math alttext="upper X Subscript k"><msub><mi>X</mi> <mi>k</mi></msub></math>
    for <math alttext="k not-equals j"><mrow><mi>k</mi> <mo>≠</mo> <mi>j</mi></mrow></math>
    , remain the same. For example, adding an extra finished square foot to a house
    increases the estimated value by roughly $229; adding 1,000 finished square feet
    implies the value will increase by $228,800.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 系数的解释与简单线性回归相同：预测值<math alttext="ModifyingAbove upper Y With caret"><mover accent="true"><mi>Y</mi>
    <mo>^</mo></mover></math>在<math alttext="upper X Subscript j"><msub><mi>X</mi>
    <mi>j</mi></msub></math>每单位变化时变化<math alttext="b Subscript j"><msub><mi>b</mi>
    <mi>j</mi></msub></math>，假设所有其他变量<math alttext="upper X Subscript k"><msub><mi>X</mi>
    <mi>k</mi></msub></math>对于<math alttext="k不等于j"><mrow><mi>k</mi> <mo>≠</mo> <mi>j</mi></mrow></math>保持不变。例如，将房屋增加一个完工平方英尺大约会增加大约229美元的估值；增加1,000平方英尺则意味着价值将增加约228,800美元。
- en: Assessing the Model
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估模型
- en: 'The most important performance metric from a data science perspective is *root
    mean squared error*, or *RMSE*. RMSE is the square root of the average squared
    error in the predicted <math alttext="ModifyingAbove y With caret Subscript i"><msub><mover
    accent="true"><mi>y</mi> <mo>^</mo></mover> <mi>i</mi></msub></math> values:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据科学的角度来看，最重要的性能指标是*均方根误差*，或*RMSE*。RMSE是预测值<math alttext="ModifyingAbove y
    With caret Subscript i"><msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover>
    <mi>i</mi></msub></math>的平均平方误差的平方根：
- en: <math display="block"><mrow><mi>R</mi> <mi>M</mi> <mi>S</mi> <mi>E</mi> <mo>=</mo>
    <msqrt><mfrac><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <msup><mfenced separators="" open="(" close=")"><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>-</mo><msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover>
    <mi>i</mi></msub></mfenced> <mn>2</mn></msup></mrow> <mi>n</mi></mfrac></msqrt></mrow></math>
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>R</mi> <mi>M</mi> <mi>S</mi> <mi>E</mi> <mo>=</mo>
    <msqrt><mfrac><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <msup><mfenced separators="" open="(" close=")"><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>-</mo><msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover>
    <mi>i</mi></msub></mfenced> <mn>2</mn></msup></mrow> <mi>n</mi></mfrac></msqrt></mrow></math>
- en: 'This measures the overall accuracy of the model and is a basis for comparing
    it to other models (including models fit using machine learning techniques). Similar
    to RMSE is the *residual standard error*, or *RSE*. In this case we have *p* predictors,
    and the RSE is given by:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这衡量了模型的整体准确性，并且是与其他模型（包括使用机器学习技术拟合的模型）进行比较的基础。类似于RMSE的是*残差标准误差*，或者*RSE*。在这种情况下，我们有*p*个预测变量，RSE由以下公式给出：
- en: <math display="block"><mrow><mi>R</mi> <mi>S</mi> <mi>E</mi> <mo>=</mo> <msqrt><mfrac><mrow><msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup> <msup><mfenced
    separators="" open="(" close=")"><msub><mi>y</mi> <mi>i</mi></msub> <mo>-</mo><msub><mover
    accent="true"><mi>y</mi> <mo>^</mo></mover> <mi>i</mi></msub></mfenced> <mn>2</mn></msup></mrow>
    <mfenced separators="" open="(" close=")"><mi>n</mi><mo>-</mo><mi>p</mi><mo>-</mo><mn>1</mn></mfenced></mfrac></msqrt></mrow></math>
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>R</mi> <mi>S</mi> <mi>E</mi> <mo>=</mo> <msqrt><mfrac><mrow><msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup> <msup><mfenced
    separators="" open="(" close=")"><msub><mi>y</mi> <mi>i</mi></msub> <mo>-</mo><msub><mover
    accent="true"><mi>y</mi> <mo>^</mo></mover> <mi>i</mi></msub></mfenced> <mn>2</mn></msup></mrow>
    <mfenced separators="" open="(" close=")"><mi>n</mi><mo>-</mo><mi>p</mi><mo>-</mo><mn>1</mn></mfenced></mfrac></msqrt></mrow></math>
- en: The only difference is that the denominator is the degrees of freedom, as opposed
    to number of records (see [“Degrees of Freedom”](ch03.xhtml#DOF)). In practice,
    for linear regression, the difference between RMSE and RSE is very small, particularly
    for big data applications.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的区别在于分母是自由度，而不是记录数（参见[“自由度”](ch03.xhtml#DOF)）。实际上，对于线性回归，在大数据应用中，RMSE和RSE之间的差异非常小。
- en: 'The `summary` function in *R* computes RSE as well as other metrics for a regression
    model:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*R*中的`summary`函数计算了回归模型的RSE以及其他指标：'
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`scikit-learn` provides a number of metrics for regression and classification.
    Here, we use `mean_squared_error` to get RMSE and `r2_score` for the coefficient
    of determination:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn`提供了许多回归和分类的度量指标。这里，我们使用`mean_squared_error`来获取RMSE，使用`r2_score`来获取决定系数：'
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Use `statsmodels` to get a more detailed analysis of the regression model in
    *Python*:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`statsmodels`来获取*Python*中回归模型的更详细分析：
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `pandas` method `assign`, as used here, adds a constant column with value
    1 to the predictors. This is required to model the intercept.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里使用的`pandas`方法`assign`添加了一个值为1的常数列到预测因子中。这对于建模截距是必需的。
- en: 'Another useful metric that you will see in software output is the *coefficient
    of determination*, also called the *R-squared* statistic or <math alttext="upper
    R squared"><msup><mi>R</mi> <mn>2</mn></msup></math> . R-squared ranges from 0
    to 1 and measures the proportion of variation in the data that is accounted for
    in the model. It is useful mainly in explanatory uses of regression where you
    want to assess how well the model fits the data. The formula for <math alttext="upper
    R squared"><msup><mi>R</mi> <mn>2</mn></msup></math> is:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件输出中，您还会看到另一个有用的度量指标是*决定系数*，也称为*R平方*统计量或<math alttext="upper R squared"><msup><mi>R</mi>
    <mn>2</mn></msup></math>。R平方介于0到1之间，衡量了模型解释数据变异的比例。主要用于回归分析中，帮助评估模型对数据的拟合程度。*R平方*的公式如下：
- en: <math display="block"><mrow><msup><mi>R</mi> <mn>2</mn></msup> <mo>=</mo> <mn>1</mn>
    <mo>-</mo> <mfrac><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <msup><mfenced separators="" open="(" close=")"><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>-</mo><msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover>
    <mi>i</mi></msub></mfenced> <mn>2</mn></msup></mrow> <mrow><msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup> <msup><mfenced
    separators="" open="(" close=")"><msub><mi>y</mi> <mi>i</mi></msub> <mo>-</mo><mover
    accent="true"><mi>y</mi> <mo>¯</mo></mover></mfenced> <mn>2</mn></msup></mrow></mfrac></mrow></math>
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msup><mi>R</mi> <mn>2</mn></msup> <mo>=</mo> <mn>1</mn>
    <mo>-</mo> <mfrac><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <msup><mfenced separators="" open="(" close=")"><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>-</mo><msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover>
    <mi>i</mi></msub></mfenced> <mn>2</mn></msup></mrow> <mrow><msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup> <msup><mfenced
    separators="" open="(" close=")"><msub><mi>y</mi> <mi>i</mi></msub> <mo>-</mo><mover
    accent="true"><mi>y</mi> <mo>¯</mo></mover></mfenced> <mn>2</mn></msup></mrow></mfrac></mrow></math>
- en: The denominator is proportional to the variance of *Y*. The output from *R*
    also reports an *adjusted R-squared*, which adjusts for the degrees of freedom,
    effectively penalizing the addition of more predictors to a model. Seldom is this
    significantly different from *R-squared* in multiple regression with large data
    sets.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 分母与*Y*的方差成正比。*R*的输出还报告了*调整后的R平方*，该指标考虑了自由度，有效地惩罚了向模型添加更多预测因子的情况。在大数据集上，这通常与多元回归中的*R平方*没有显著不同。
- en: 'Along with the estimated coefficients, *R* and `statsmodels` report the standard
    error of the coefficients (SE) and a *t-statistic*:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 除了估计系数外，*R*和`statsmodels`还报告了系数的标准误差（SE）和*t统计量*：
- en: <math display="block"><mrow><msub><mi>t</mi> <mi>b</mi></msub> <mo>=</mo> <mfrac><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mrow><mtext>SE</mtext><mfenced separators=""
    open="(" close=")"><mover accent="true"><mi>b</mi> <mo>^</mo></mover></mfenced></mrow></mfrac></mrow></math>
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mi>t</mi> <mi>b</mi></msub> <mo>=</mo> <mfrac><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mrow><mtext>SE</mtext><mfenced separators=""
    open="(" close=")"><mover accent="true"><mi>b</mi> <mo>^</mo></mover></mfenced></mrow></mfrac></mrow></math>
- en: The t-statistic—and its mirror image, the p-value—measures the extent to which
    a coefficient is “statistically significant”—that is, outside the range of what
    a random chance arrangement of predictor and target variable might produce. The
    higher the t-statistic (and the lower the p-value), the more significant the predictor.
    Since parsimony is a valuable model feature, it is useful to have a tool like
    this to guide choice of variables to include as predictors (see [“Model Selection
    and Stepwise Regression”](#StepwiseRegression)).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: t统计量及其镜像，即p值，衡量了系数在统计上的显著性，即预测因子与目标变量的随机安排可能产生的范围之外的程度。t统计量越高（p值越低），预测因子越显著。由于简洁性是一个有价值的模型特征，因此有这样的工具来指导选择要包含为预测因子的变量是很有用的（参见[“模型选择和逐步回归”](#StepwiseRegression)）。
- en: Warning
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: In addition to the t-statistic, *R* and other packages will often report a *p-value*
    (`Pr(>|t|)` in the *R* output) and *F-statistic*. Data scientists do not generally
    get too involved with the interpretation of these statistics, nor with the issue
    of statistical significance. Data scientists primarily focus on the t-statistic
    as a useful guide for whether to include a predictor in a model or not. High t-statistics
    (which go with p-values near 0) indicate a predictor should be retained in a model,
    while very low t-statistics indicate a predictor could be dropped. See [“p-Value”](ch03.xhtml#p-value)
    for more discussion.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 除了t统计量外，*R*和其他包通常还报告*p值*（*R*输出中的`Pr(>|t|)`）和*F统计量*。数据科学家通常不会过多解释这些统计量，也不会过多关注统计显著性问题。数据科学家主要专注于t统计量作为是否在模型中包含预测因子的有用指南。较高的t统计量（与接近0的p值相对应）表明应保留预测因子在模型中，而非常低的t统计量表明可以删除预测因子。参见[“p-Value”](ch03.xhtml#p-value)以获取更多讨论。
- en: Cross-Validation
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证
- en: Classic statistical regression metrics (*R²*, F-statistics, and p-values) are
    all “in-sample” metrics—they are applied to the same data that was used to fit
    the model. Intuitively, you can see that it would make a lot of sense to set aside
    some of the original data, not use it to fit the model, and then apply the model
    to the set-aside (holdout) data to see how well it does. Normally, you would use
    a majority of the data to fit the model and use a smaller portion to test the
    model.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 经典统计回归指标（*R²*、F统计量和p值）都是“样本内”指标——它们适用于用于拟合模型的相同数据。直观地，您可以看到，将一些原始数据保留下来，不用于拟合模型，然后将模型应用于留出的（保留）数据，以查看其表现如何，这是非常有意义的。通常，您会使用大多数数据来拟合模型，并使用较小的部分来测试模型。
- en: This idea of “out-of-sample” validation is not new, but it did not really take
    hold until larger data sets became more prevalent; with a small data set, analysts
    typically want to use all the data and fit the best possible model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: “样本外”验证的这个想法并不新鲜，但直到较大的数据集变得更普遍之前，它并没有真正被接受；对于小数据集，分析师通常希望使用所有数据并拟合最佳的模型。
- en: Using a holdout sample, though, leaves you subject to some uncertainty that
    arises simply from variability in the small holdout sample. How different would
    the assessment be if you selected a different holdout sample?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用留出样本会使你受到一些不确定性的影响，这仅仅来自于小样本的变异性。如果选择不同的留出样本，评估结果会有多大不同？
- en: 'Cross-validation extends the idea of a holdout sample to multiple sequential
    holdout samples. The algorithm for basic *k-fold cross-validation* is as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证将留出样本的概念扩展到多个连续的留出样本。基本*k折交叉验证*算法如下：
- en: Set aside *1/k* of the data as a holdout sample.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将*1/k*的数据留出作为留出样本。
- en: Train the model on the remaining data.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在剩余数据上训练模型。
- en: Apply (score) the model to the *1/k* holdout, and record needed model assessment
    metrics.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型应用（评分）于*1/k*的留出样本，并记录所需的模型评估指标。
- en: Restore the first *1/k* of the data, and set aside the next *1/k* (excluding
    any records that got picked the first time).
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 恢复数据的第*1/k*部分，并留出接下来的*1/k*部分（不包括任何第一次被选中的记录）。
- en: Repeat steps 2 and 3.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤2和3。
- en: Repeat until each record has been used in the holdout portion.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直到每条记录都在留出部分中使用为止。
- en: Average or otherwise combine the model assessment metrics.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 平均或以其他方式组合模型评估指标。
- en: The division of the data into the training sample and the holdout sample is
    also called a *fold*.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据分成训练样本和留出样本也称为*折叠*。
- en: Model Selection and Stepwise Regression
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型选择和逐步回归
- en: 'In some problems, many variables could be used as predictors in a regression.
    For example, to predict house value, additional variables such as the basement
    size or year built could be used. In *R*, these are easy to add to the regression
    equation:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些问题中，可以使用许多变量作为回归的预测变量。例如，要预测房屋价值，可以使用额外的变量如地下室面积或建造年份。在*R*中，这些很容易添加到回归方程中：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In *Python*, we need to convert the categorical and boolean variables into
    numbers:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Python*中，我们需要将分类和布尔变量转换为数字：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Adding more variables, however, does not necessarily mean we have a better
    model. Statisticians use the principle of *Occam’s razor* to guide the choice
    of a model: all things being equal, a simpler model should be used in preference
    to a more complicated model.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，添加更多变量并不一定意味着我们拥有更好的模型。统计学家使用奥卡姆剃刀原则来指导模型的选择：其他条件相等时，应优先使用简单的模型而不是更复杂的模型。
- en: 'Including additional variables always reduces RMSE and increases <math alttext="upper
    R squared"><msup><mi>R</mi> <mn>2</mn></msup></math> for the training data. Hence,
    these are not appropriate to help guide the model choice. One approach to including
    model complexity is to use the adjusted <math alttext="upper R squared"><msup><mi>R</mi>
    <mn>2</mn></msup></math> :'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 添加额外变量总是降低RMSE并增加<math alttext="upper R squared"><msup><mi>R</mi> <mn>2</mn></msup></math>的训练数据。因此，这些不适合帮助指导模型选择。包含模型复杂性的一种方法是使用调整后的<math
    alttext="upper R squared"><msup><mi>R</mi> <mn>2</mn></msup></math>：
- en: <math><mstyle displaystyle="true"><mrow class="MJX-TeXAtom-ORD"><msubsup><mi>R</mi>
    <mrow class="MJX-TeXAtom-ORD"><mi>a</mi> <mi>d</mi> <mi>j</mi></mrow> <mn>2</mn></msubsup>
    <mo>=</mo> <mn>1</mn> <mo>−</mo> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo>
    <msup><mi>R</mi> <mn>2</mn></msup> <mo stretchy="false">)</mo> <mfrac><mrow><mi>n</mi>
    <mo>−</mo> <mn>1</mn></mrow> <mrow><mi>n</mi> <mo>−</mo> <mi>P</mi> <mo>−</mo>
    <mn>1</mn></mrow></mfrac></mrow></mstyle></math>
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mstyle displaystyle="true"><mrow class="MJX-TeXAtom-ORD"><msubsup><mi>R</mi>
    <mrow class="MJX-TeXAtom-ORD"><mi>a</mi> <mi>d</mi> <mi>j</mi></mrow> <mn>2</mn></msubsup>
    <mo>=</mo> <mn>1</mn> <mo>−</mo> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo>
    <msup><mi>R</mi> <mn>2</mn></msup> <mo stretchy="false">)</mo> <mfrac><mrow><mi>n</mi>
    <mo>−</mo> <mn>1</mn></mrow> <mrow><mi>n</mi> <mo>−</mo> <mi>P</mi> <mo>−</mo>
    <mn>1</mn></mrow></mfrac></mrow></mstyle></math>
- en: Here, *n* is the number of records and *P* is the number of variables in the
    model.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*n* 是记录数，*P* 是模型中的变量数。
- en: 'In the 1970s, Hirotugu Akaike, the eminent Japanese statistician, developed
    a metric called *AIC* (Akaike’s Information Criteria) that penalizes adding terms
    to a model. In the case of regression, AIC has the form:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪70年代，日本著名统计学家赤池弘次开发了一种叫做*AIC*（赤池信息准则）的度量，惩罚模型中增加的项。在回归的情况下，AIC的形式为：
- en: AIC = 2*P* + *n* log(`RSS`/*n*)
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AIC = 2*P* + *n* log(`RSS`/*n*)
- en: where *P* is the number of variables and *n* is the number of records. The goal
    is to find the model that minimizes AIC; models with *k* more extra variables
    are penalized by 2*k*.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*P*是变量数，*n*是记录数。目标是找到最小化AIC的模型；具有*k*个额外变量的模型会受到2*k*的惩罚。
- en: AIC, BIC, and Mallows Cp
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AIC，BIC和Mallows Cp
- en: 'The formula for AIC may seem a bit mysterious, but in fact it is based on asymptotic
    results in information theory. There are several variants to AIC:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: AIC的公式可能看起来有点神秘，但实际上是基于信息理论中的渐近结果。AIC有几个变体：
- en: AICc
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: AICc
- en: A version of AIC corrected for small sample sizes.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: AIC的小样本修正版本。
- en: BIC or Bayesian information criteria
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: BIC或贝叶斯信息准则
- en: Similar to AIC, with a stronger penalty for including additional variables to
    the model.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 与AIC类似，对于将额外变量包括在模型中，惩罚力度更强。
- en: Mallows Cp
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Mallows Cp
- en: A variant of AIC developed by Colin Mallows.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Colin Mallows开发的AIC的一个变体。
- en: These are typically reported as in-sample metrics (i.e., on the training data),
    and data scientists using holdout data for model assessment do not need to worry
    about the differences among them or the underlying theory behind them.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这些通常作为样本内度量报告（即在训练数据上），使用留出数据进行模型评估的数据科学家不需要担心它们之间的差异或其背后的理论。
- en: 'How do we find the model that minimizes AIC or maximizes adjusted <math alttext="upper
    R squared"><msup><mi>R</mi> <mn>2</mn></msup></math> ? One way is to search through
    all possible models, an approach called *all subset regression*. This is computationally
    expensive and is not feasible for problems with large data and many variables.
    An attractive alternative is to use *stepwise regression*. It could start with
    a full model and successively drop variables that don’t contribute meaningfully.
    This is called *backward elimination*. Alternatively one could start with a constant
    model and successively add variables (*forward selection*). As a third option
    we can also successively add and drop predictors to find a model that lowers AIC
    or adjusted <math alttext="upper R squared"><msup><mi>R</mi> <mn>2</mn></msup></math>
    . The `MASS` in *R* package by Venebles and Ripley offers a stepwise regression
    function called `stepAIC`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如何找到最小化AIC或最大化调整<math alttext="upper R squared"><msup><mi>R</mi> <mn>2</mn></msup></math>的模型？一种方法是搜索所有可能的模型，这称为*全子集回归*。这在具有大量数据和变量的问题中计算成本高昂，不可行。一个吸引人的替代方案是使用*逐步回归*。它可以从一个完整模型开始，并逐步删除没有意义的变量。这被称为*向后消除*。或者可以从一个常数模型开始，并逐步添加变量（*前向选择*）。作为第三个选择，我们还可以逐步添加和删除预测因子，以找到降低AIC或调整<math
    alttext="upper R squared"><msup><mi>R</mi> <mn>2</mn></msup></math>的模型。Venebles和Ripley的*R*软件包中的`MASS`提供了一个称为`stepAIC`的逐步回归函数：
- en: '[PRE17]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`scikit-learn` has no implementation for stepwise regression. We implemented
    functions `stepwise_selection`, `forward_selection`, and `backward_elimination`
    in our `dmba` package:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn`没有逐步回归的实现。我们在我们的`dmba`包中实现了`stepwise_selection`、`forward_selection`和`backward_elimination`函数：'
- en: '[PRE18]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[![1](Images/1.png)](#co_regression_and_prediction_CO1-1)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_regression_and_prediction_CO1-1)'
- en: Define a function that returns a fitted model for a given set of variables.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个返回给定变量集的拟合模型的函数。
- en: '[![2](Images/2.png)](#co_regression_and_prediction_CO1-2)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_regression_and_prediction_CO1-2)'
- en: Define a function that returns a score for a given model and set of variables.
    In this case, we use the `AIC_score` implemented in the `dmba` package.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个函数，为给定的模型和变量集返回一个分数。在这种情况下，我们使用`dmba`包中实现的`AIC_score`。
- en: 'The function chose a model in which several variables were dropped from `house_full`:
    `SqFtLot`, `NbrLivingUnits`, `YrRenovated`, and `NewConstruction`.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数选择了一个模型，其中从`house_full`中删除了几个变量：`SqFtLot`、`NbrLivingUnits`、`YrRenovated`和`NewConstruction`。
- en: Simpler yet are *forward selection* and *backward selection*. In forward selection,
    you start with no predictors and add them one by one, at each step adding the
    predictor that has the largest contribution to <math alttext="upper R squared"><msup><mi>R</mi>
    <mn>2</mn></msup></math> , and stopping when the contribution is no longer statistically
    significant. In backward selection, or *backward elimination*, you start with
    the full model and take away predictors that are not statistically significant
    until you are left with a model in which all predictors are statistically significant.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 更简单的方法是*前向选择*和*后向选择*。在前向选择中，你从零个预测变量开始逐个添加，每一步都添加对<math alttext="upper R squared"><msup><mi>R</mi>
    <mn>2</mn></msup></math> 贡献最大的预测变量，并在贡献不再具有统计显著性时停止。在后向选择或*后向消除*中，你从完整模型开始，并去掉不具有统计显著性的预测变量，直到剩下所有预测变量都具有统计显著性的模型。
- en: '*Penalized regression* is similar in spirit to AIC. Instead of explicitly searching
    through a discrete set of models, the model-fitting equation incorporates a constraint
    that penalizes the model for too many variables (parameters). Rather than eliminating
    predictor variables entirely—as with stepwise, forward, and backward selection—penalized
    regression applies the penalty by reducing coefficients, in some cases to near
    zero. Common penalized regression methods are *ridge regression* and *lasso regression*.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*Penalized regression*的灵感与AIC类似。与明确搜索离散模型集不同，模型拟合方程包含一个约束，对模型因过多变量（参数）而进行惩罚。与逐步、前向和后向选择完全消除预测变量不同，惩罚回归通过减少系数来施加惩罚，在某些情况下几乎降为零。常见的惩罚回归方法包括*岭回归*和*套索回归*。'
- en: Stepwise regression and all subset regression are *in-sample* methods to assess
    and tune models. This means the model selection is possibly subject to overfitting
    (fitting the noise in the data) and may not perform as well when applied to new
    data. One common approach to avoid this is to use cross-validation to validate
    the models. In linear regression, overfitting is typically not a major issue,
    due to the simple (linear) global structure imposed on the data. For more sophisticated
    types of models, particularly iterative procedures that respond to local data
    structure, cross-validation is a very important tool; see [“Cross-Validation”](#CrossValidation)
    for details.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 逐步回归和全子集回归是*样本内*方法，用于评估和调整模型。这意味着模型选择可能会受到过度拟合（拟合数据中的噪声）的影响，并且在应用于新数据时可能表现不佳。避免这种情况的一种常见方法是使用交叉验证来验证模型。在线性回归中，过度拟合通常不是一个主要问题，因为数据上强加了简单（线性）全局结构。对于更复杂类型的模型，特别是对局部数据结构响应的迭代过程，交叉验证是一个非常重要的工具；详见[“交叉验证”](#CrossValidation)。
- en: Weighted Regression
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加权回归
- en: 'Weighted regression is used by statisticians for a variety of purposes; in
    particular, it is important for analysis of complex surveys. Data scientists may
    find weighted regression useful in two cases:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学家使用加权回归来处理各种目的；特别是，在复杂调查分析中，这是很重要的。数据科学家可能会发现在两种情况下使用加权回归很有用：
- en: Inverse-variance weighting when different observations have been measured with
    different precision; the higher variance ones receiving lower weights.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当不同观察结果具有不同精度时，使用反方差加权；较高方差的观察结果获得较低的权重。
- en: Analysis of data where rows represent multiple cases; the weight variable encodes
    how many original observations each row represents.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析数据，其中行代表多个案例；权重变量编码每行代表多少个原始观测值。
- en: 'For example, with the housing data, older sales are less reliable than more
    recent sales. Using the `DocumentDate` to determine the year of the sale, we can
    compute a `Weight` as the number of years since 2005 (the beginning of the data):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在房屋数据中，较早的销售比较不可靠，而比较近期的销售则较为可靠。使用`DocumentDate`确定销售年份，我们可以计算`Weight`作为距离2005年（数据开始的时间）的年数：
- en: '*R*'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '*R*'
- en: '[PRE19]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '*Python*'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE20]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We can compute a weighted regression with the `lm` function using the `weight`
    argument:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`lm`函数中的`weight`参数计算加权回归：
- en: '[PRE21]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The coefficients in the weighted regression are slightly different from the
    original regression.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 加权回归中的系数与原始回归略有不同。
- en: 'Most models in `scikit-learn` accept weights as the keyword argument `sample_weight`
    in the call of the `fit` method:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 `scikit-learn` 中的模型在调用 `fit` 方法时接受权重作为关键字参数 `sample_weight`：
- en: '[PRE22]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Further Reading
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: An excellent treatment of cross-validation and resampling can be found in *An
    Introduction to Statistical Learning* by Gareth James, Daniela Witten, Trevor
    Hastie, and Robert Tibshirani (Springer, 2013).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在《统计学习导论》（Gareth James, Daniela Witten, Trevor Hastie 和 Robert Tibshirani
    著，Springer，2013）中找到关于交叉验证和重抽样的优秀处理。
- en: Prediction Using Regression
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用回归进行预测
- en: The primary purpose of regression in data science is prediction. This is useful
    to keep in mind, since regression, being an old and established statistical method,
    comes with baggage that is more relevant to its traditional role as a tool for
    explanatory modeling than to prediction.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，回归的主要目的是预测。这一点很重要，因为回归作为一种古老而成熟的统计方法，其背景更多与其作为解释建模工具的传统角色相关，而不是预测。
- en: The Dangers of Extrapolation
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 外推的危险
- en: Regression models should not be used to extrapolate beyond the range of the
    data (leaving aside the use of regression for time series forecasting.). The model
    is valid only for predictor values for which the data has sufficient values (even
    in the case that sufficient data is available, there could be other problems—see
    [“Regression Diagnostics”](#RegressionDiagnostics)). As an extreme case, suppose
    `model_lm` is used to predict the value of a 5,000-square-foot empty lot. In such
    a case, all the predictors related to the building would have a value of 0, and
    the regression equation would yield an absurd prediction of –521,900 + 5,000 ×
    –.0605 = –$522,202. Why did this happen? The data contains only parcels with buildings—there
    are no records corresponding to vacant land. Consequently, the model has no information
    to tell it how to predict the sales price for vacant land.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型不应用于超出数据范围之外的外推（不考虑用于时间序列预测的回归情况）。该模型仅对数据拥有足够观测值的预测变量值有效（即使在有足够数据的情况下，也可能存在其他问题—参见[“回归诊断”](#RegressionDiagnostics)）。举个极端的例子，假设使用`model_lm`来预测一个面积为5,000平方英尺的空地的价值。在这种情况下，所有与建筑相关的预测变量将为0，回归方程将给出一个荒谬的预测值为–521,900
    + 5,000 × –0.0605 = –$522,202。为什么会发生这种情况？数据仅包含具有建筑物的地块—没有对应于空地的记录。因此，模型无法通过数据告诉如何预测空地的销售价格。
- en: Confidence and Prediction Intervals
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 置信区间与预测区间
- en: 'Much of statistics involves understanding and measuring variability (uncertainty).
    The t-statistics and p-values reported in regression output deal with this in
    a formal way, which is sometimes useful for variable selection (see [“Assessing
    the Model”](#RMSE)). More useful metrics are confidence intervals, which are uncertainty
    intervals placed around regression coefficients and predictions. An easy way to
    understand this is via the bootstrap (see [“The Bootstrap”](ch02.xhtml#bootstrap)
    for more details about the general bootstrap procedure). The most common regression
    confidence intervals encountered in software output are those for regression parameters
    (coefficients). Here is a bootstrap algorithm for generating confidence intervals
    for regression parameters (coefficients) for a data set with *P* predictors and
    *n* records (rows):'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学的大部分内容涉及理解和衡量变异性（不确定性）。回归输出中报告的 t-统计量和 p-值以正式方式处理这一点，这在变量选择时有时是有用的（参见[“评估模型”](#RMSE)）。更有用的指标是置信区间，它是放置在回归系数和预测周围的不确定性区间。理解这一点的简单方法是通过自助法（更多关于一般自助法程序的详情，请参见[“自助法”](ch02.xhtml#bootstrap)）。在软件输出中遇到的最常见的回归置信区间是回归参数（系数）的置信区间。以下是用于生成数据集中
    *P* 个预测变量和 *n* 条记录的回归参数（系数）置信区间的自助法算法：
- en: Consider each row (including outcome variable) as a single “ticket” and place
    all the *n* tickets in a box.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每一行（包括结果变量）视为单独的“票据”，并将所有 *n* 张票据放入一个箱子中。
- en: Draw a ticket at random, record the values, and replace it in the box.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机抽取一张票据，记录其值，并将其放回箱中。
- en: Repeat step 2 *n* times; you now have one bootstrap resample.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤2 *n* 次，现在你有了一个自助法重采样。
- en: Fit a regression to the bootstrap sample, and record the estimated coefficients.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对Bootstrap样本拟合回归，并记录估计的系数。
- en: Repeat steps 2 through 4, say, 1,000 times.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤2到4，例如1,000次。
- en: You now have 1,000 bootstrap values for each coefficient; find the appropriate
    percentiles for each one (e.g., 5th and 95th for a 90% confidence interval).
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在每个系数都有1,000个自举值；找到每个系数的适当百分位数（例如，90% 置信区间的第5和第95百分位数）。
- en: 'You can use the `Boot` function in *R* to generate actual bootstrap confidence
    intervals for the coefficients, or you can simply use the formula-based intervals
    that are a routine *R* output. The conceptual meaning and interpretation are the
    same, and not of central importance to data scientists, because they concern the
    regression coefficients. Of greater interest to data scientists are intervals
    around predicted *y* values ( <math alttext="ModifyingAbove upper Y With caret
    Subscript i"><msub><mover accent="true"><mi>Y</mi> <mo>^</mo></mover> <mi>i</mi></msub></math>
    ). The uncertainty around <math alttext="ModifyingAbove upper Y With caret Subscript
    i"><msub><mover accent="true"><mi>Y</mi> <mo>^</mo></mover> <mi>i</mi></msub></math>
    comes from two sources:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 *R* 中的 `Boot` 函数生成系数的实际自举置信区间，或者简单地使用基于公式的区间，这是 *R* 输出的常规部分。概念意义和解释是相同的，对于数据科学家来说并不是核心问题，因为它们涉及回归系数。数据科学家更感兴趣的是围绕预测
    *y* 值（<math alttext="ModifyingAbove upper Y With caret Subscript i"><msub><mover
    accent="true"><mi>Y</mi> <mo>^</mo></mover> <mi>i</mi></msub></math>）的区间。对于 <math
    alttext="ModifyingAbove upper Y With caret Subscript i"><msub><mover accent="true"><mi>Y</mi>
    <mo>^</mo></mover> <mi>i</mi></msub></math> 的不确定性来自两个来源：
- en: Uncertainty about what the relevant predictor variables and their coefficients
    are (see the preceding bootstrap algorithm)
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对相关的预测变量及其系数的不确定性（见前述自举算法）
- en: Additional error inherent in individual data points
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个体数据点固有的附加误差
- en: 'The individual data point error can be thought of as follows: even if we knew
    for certain what the regression equation was (e.g., if we had a huge number of
    records to fit it), the *actual* outcome values for a given set of predictor values
    will vary. For example, several houses—each with 8 rooms, a 6,500-square-foot
    lot, 3 bathrooms, and a basement—might have different values. We can model this
    individual error with the residuals from the fitted values. The bootstrap algorithm
    for modeling both the regression model error and the individual data point error
    would look as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将个体数据点误差理解为：即使我们确定了回归方程是什么（例如，如果我们有大量记录来拟合它），给定一组预测变量的实际结果值也会有所不同。例如，几栋房子——每栋房子都有8个房间、6500平方英尺的地块、3间浴室和一个地下室——可能具有不同的价值。我们可以通过拟合值的残差来建模这个个体误差。用于模拟回归模型误差和个体数据点误差的自举算法如下所示：
- en: Take a bootstrap sample from the data (spelled out in greater detail earlier).
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据中进行自举抽样（在前文详细解释）。
- en: Fit the regression, and predict the new value.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合回归模型，并预测新值。
- en: Take a single residual at random from the original regression fit, add it to
    the predicted value, and record the result.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机从原始回归拟合中取一个单个残差，加到预测值上，并记录结果。
- en: Repeat steps 1 through 3, say, 1,000 times.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤1至3，比如说1,000次。
- en: Find the 2.5th and the 97.5th percentiles of the results.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到结果的第2.5和第97.5百分位数。
- en: Prediction Interval or Confidence Interval?
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测区间还是置信区间？
- en: A prediction interval pertains to uncertainty around a single value, while a
    confidence interval pertains to a mean or other statistic calculated from multiple
    values. Thus, a prediction interval will typically be much wider than a confidence
    interval for the same value. We model this individual value error in the bootstrap
    model by selecting an individual residual to tack on to the predicted value. Which
    should you use? That depends on the context and the purpose of the analysis, but,
    in general, data scientists are interested in specific individual predictions,
    so a prediction interval would be more appropriate. Using a confidence interval
    when you should be using a prediction interval will greatly underestimate the
    uncertainty in a given predicted value.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 预测区间涉及到单个数值的不确定性，而置信区间涉及到从多个数值计算得出的均值或其他统计量。因此，对于相同的数值来说，预测区间通常会比置信区间宽得多。我们在自举模型中模拟这个单个数值误差，通过选择一个个体残差来添加到预测值上。应该使用哪一个？这取决于上下文和分析的目的，但一般来说，数据科学家对特定的个体预测很感兴趣，因此预测区间更为合适。如果你应该使用预测区间而使用了置信区间，那么将极大地低估给定预测值的不确定性。
- en: Factor Variables in Regression
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归中的因子变量
- en: '*Factor* variables, also termed *categorical* variables, take on a limited
    number of discrete values. For example, a loan purpose can be “debt consolidation,”
    “wedding,” “car,” and so on. The binary (yes/no) variable, also called an *indicator*
    variable, is a special case of a factor variable. Regression requires numerical
    inputs, so factor variables need to be recoded to use in the model. The most common
    approach is to convert a variable into a set of binary *dummy* variables.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '*因子*变量，也称为*分类*变量，接受有限数量的离散值。例如，贷款目的可以是“债务合并”，“婚礼”，“汽车”等。二进制（是/否）变量，也称为*指示*变量，是因子变量的一种特殊情况。回归需要数值输入，因此因子变量需要被重新编码以在模型中使用。最常见的方法是将一个变量转换为一组二进制*虚拟*变量。'
- en: Dummy Variables Representation
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 虚拟变量表示
- en: 'In the King County housing data, there is a factor variable for the property
    type; a small subset of six records is shown below:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在 King County 房屋数据中，有一个属性类型的因子变量；下面展示了一个小的六条记录子集：
- en: '*R*:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '*R*:'
- en: '[PRE23]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '*Python*:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*:'
- en: '[PRE24]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'There are three possible values: `Multiplex`, `Single Family`, and `Townhouse`.
    To use this factor variable, we need to convert it to a set of binary variables.
    We do this by creating a binary variable for each possible value of the factor
    variable. To do this in *R*, we use the `model.matrix` function:^([3](ch04.xhtml#idm46522853979800))'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种可能的取值：`Multiplex`、`Single Family` 和 `Townhouse`。要使用这个因子变量，我们需要将其转换为一组二进制变量。在*R*中，我们使用
    `model.matrix` 函数来实现这一点：^([3](ch04.xhtml#idm46522853979800))
- en: '[PRE25]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The function `model.matrix` converts a data frame into a matrix suitable to
    a linear model. The factor variable `PropertyType`, which has three distinct levels,
    is represented as a matrix with three columns. In the machine learning community,
    this representation is referred to as *one hot encoding* (see [“One Hot Encoder”](ch06.xhtml#OneHotEncoder)).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `model.matrix` 将数据框转换为适合线性模型的矩阵。属性类型 `PropertyType` 是一个具有三个不同水平的因子变量，表示为一个有三列的矩阵。在机器学习社区中，这种表示称为*独热编码*（见[“独热编码器”](ch06.xhtml#OneHotEncoder)）。
- en: 'In *Python*, we can convert categorical variables to dummies using the `pandas`
    method `get_dummies`:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Python*中，我们可以使用 `pandas` 的 `get_dummies` 方法将分类变量转换为虚拟变量：
- en: '[PRE26]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[![1](Images/1.png)](#co_regression_and_prediction_CO2-1)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_regression_and_prediction_CO2-1)'
- en: By default, returns one hot encoding of the categorical variable.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，返回分类变量的独热编码。
- en: '[![2](Images/2.png)](#co_regression_and_prediction_CO2-2)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_regression_and_prediction_CO2-2)'
- en: The keyword argument `drop_first` will return *P* – 1 columns. Use this to avoid
    the problem of multicollinearity.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 关键字参数 `drop_first` 将返回 *P* - 1列。使用它来避免多重共线性问题。
- en: In certain machine learning algorithms, such as nearest neighbors and tree models,
    one hot encoding is the standard way to represent factor variables (for example,
    see [“Tree Models”](ch06.xhtml#TreeModels)).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些机器学习算法中，如最近邻居和树模型，独热编码是表示因子变量的标准方式（例如，见[“树模型”](ch06.xhtml#TreeModels)）。
- en: In the regression setting, a factor variable with *P* distinct levels is usually
    represented by a matrix with only *P* – 1 columns. This is because a regression
    model typically includes an intercept term. With an intercept, once you have defined
    the values for *P* – 1 binaries, the value for the *P*th is known and could be
    considered redundant. Adding the *P*th column will cause a multicollinearity error
    (see [“Multicollinearity”](#Multicollinearity)).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归设置中，一个具有*P*个不同水平的因子变量通常由一个只有*P* - 1列的矩阵表示。这是因为回归模型通常包括一个截距项。有了截距项后，一旦为*P*
    - 1个二进制变量定义了值，第*P*个的值就已知且可能被认为是冗余的。添加第*P*列将导致多重共线性错误（见[“多重共线性”](#Multicollinearity)）。
- en: 'The default representation in *R* is to use the first factor level as a *reference*
    and interpret the remaining levels relative to that factor:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在*R*中的默认表示是使用第一个因子水平作为*参考*，并将其余水平解释为相对于该因子的：
- en: '[PRE27]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The method `get_dummies` takes the optional keyword argument `drop_first` to
    exclude the first factor as *reference*:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 方法 `get_dummies` 可以通过可选的关键字参数 `drop_first` 来排除第一个因子作为*参考*：
- en: '[PRE28]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output from the *R* regression shows two coefficients corresponding to
    `PropertyType`: `PropertyTypeSingle Family` and `PropertyTypeTownhouse`. There
    is no coefficient of `Multiplex` since it is implicitly defined when `PropertyTypeSingle
    Family == 0` and `PropertyTypeTownhouse == 0`. The coefficients are interpreted
    as relative to `Multiplex`, so a home that is `Single Family` is worth almost
    $85,000 less, and a home that is `Townhouse` is worth over $150,000 less.^([4](ch04.xhtml#idm46522853557496))'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '*R*回归的输出显示了两个与`PropertyType`对应的系数：`PropertyTypeSingle Family`和`PropertyTypeTownhouse`。由于在`PropertyTypeSingle
    Family == 0`和`PropertyTypeTownhouse == 0`时它被隐含定义，所以没有`Multiplex`的系数。这些系数被解释为相对于`Multiplex`，因此一个`Single
    Family`的房屋价值减少了将近$85,000，而一个`Townhouse`的房屋价值减少了超过$150,000。^([4](ch04.xhtml#idm46522853557496))'
- en: Different Factor Codings
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同的因子编码方式
- en: There are several different ways to encode factor variables, known as *contrast
    coding* systems. For example, *deviation coding*, also known as *sum contrasts*,
    compares each level against the overall mean. Another contrast is *polynomial
    coding*, which is appropriate for ordered factors; see the section [“Ordered Factor
    Variables”](#OrderedFactorsRegression). With the exception of ordered factors,
    data scientists will generally not encounter any type of coding besides reference
    coding or one hot encoder.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 编码因子变量有几种不同的方法，被称为*对比编码*系统。例如，*偏差编码*，也称为*总和对比*，将每个水平与总体均值进行比较。另一种对比是*多项式编码*，适用于有序因子；参见章节[“有序因子变量”](#OrderedFactorsRegression)。除了有序因子外，数据科学家通常不会遇到除参考编码或独热编码之外的任何编码类型。
- en: Factor Variables with Many Levels
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 具有多个水平的因子变量
- en: Some factor variables can produce a huge number of binary dummies—zip codes
    are a factor variable, and there are 43,000 zip codes in the US. In such cases,
    it is useful to explore the data, and the relationships between predictor variables
    and the outcome, to determine whether useful information is contained in the categories.
    If so, you must further decide whether it is useful to retain all factors, or
    whether the levels should be consolidated.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 一些因子变量可以生成大量的二进制虚拟变量——邮政编码是一个因子变量，在美国有43,000个邮政编码。在这种情况下，探索数据及预测变量与结果之间的关系，以确定类别中是否包含有用信息是有用的。如果是，您必须进一步决定是保留所有因子还是合并水平。
- en: 'In King County, there are 80 zip codes with a house sale:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在金县，有80个房屋销售的邮政编码：
- en: '[PRE29]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The `value_counts` method of `pandas` data frames returns the same information:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`数据框的`value_counts`方法返回相同的信息：'
- en: '[PRE30]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '`ZipCode` is an important variable, since it is a proxy for the effect of location
    on the value of a house. Including all levels requires 79 coefficients corresponding
    to 79 degrees of freedom. The original model `house_lm` has only 5 degrees of
    freedom; see [“Assessing the Model”](#RMSE). Moreover, several zip codes have
    only one sale. In some problems, you can consolidate a zip code using the first
    two or three digits, corresponding to a submetropolitan geographic region. For
    King County, almost all of the sales occur in 980xx or 981xx, so this doesn’t
    help.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`ZipCode`是一个重要的变量，因为它是房屋价值上的地理位置影响的代理变量。包含所有水平需要79个与自由度对应的系数。原始模型`house_lm`只有5个自由度；参见[“评估模型”](#RMSE)。此外，一些邮政编码只有一个销售。在某些问题中，您可以使用前两位或三位数字合并一个邮政编码，对应一个次大都会地理区域。对于金县，几乎所有销售都发生在980xx或981xx，因此这并没有帮助。'
- en: 'An alternative approach is to group the zip codes according to another variable,
    such as sale price. Even better is to form zip code groups using the residuals
    from an initial model. The following `dplyr` code in *R* consolidates the 80 zip
    codes into five groups based on the median of the residual from the `house_lm`
    regression:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是根据另一个变量，如销售价格，对邮政编码进行分组。更好的方法是使用初始模型的残差形成邮政编码组。以下*R*中的`dplyr`代码基于`house_lm`回归的残差中位数将80个邮政编码合并为五组：
- en: '[PRE31]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The median residual is computed for each zip, and the `ntile` function is used
    to split the zip codes, sorted by the median, into five groups. See [“Confounding
    Variables”](#ConfoundingVariables) for an example of how this is used as a term
    in a regression improving upon the original fit.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个邮政编码，计算中位数残差，并使用`ntile`函数根据中位数对邮政编码进行分组。有关如何在回归中使用这作为改进术语的示例，请参见[“混杂变量”](#ConfoundingVariables)。
- en: 'In *Python* we can calculate this information as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Python*中，我们可以计算这些信息如下：
- en: '[PRE32]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The concept of using the residuals to help guide the regression fitting is a
    fundamental step in the modeling process; see [“Regression Diagnostics”](#RegressionDiagnostics).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 利用残差来辅助指导回归拟合的概念是建模过程中的一个基本步骤；请参阅[“回归诊断”](#RegressionDiagnostics)。
- en: Ordered Factor Variables
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有序因子变量
- en: Some factor variables reflect levels of a factor; these are termed *ordered
    factor variables* or *ordered categorical variables*. For example, the loan grade
    could be A, B, C, and so on—each grade carries more risk than the prior grade.
    Often, ordered factor variables can be converted to numerical values and used
    as is. For example, the variable `BldgGrade` is an ordered factor variable. Several
    of the types of grades are shown in [Table 4-1](#BldgGrade). While the grades
    have specific meaning, the numeric value is ordered from low to high, corresponding
    to higher-grade homes. With the regression model `house_lm`, fit in [“Multiple
    Linear Regression”](#MultipleLinearRegression), `BldgGrade` was treated as a numeric
    variable.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 一些因子变量反映了因子的水平；这些称为*有序因子变量*或*有序分类变量*。例如，贷款等级可以是A、B、C等，每个等级都比前一个等级更具风险性。通常，有序因子变量可以转换为数值并直接使用。例如，变量`BldgGrade`是一个有序因子变量。表4-1中显示了几种等级的类型。虽然等级具有特定的含义，但数值是按照从低到高的顺序排列的，对应于更高等级的房屋。在[“多元线性回归”](#MultipleLinearRegression)中拟合的回归模型`house_lm`中，`BldgGrade`被视为数值变量。
- en: Table 4-1\. Building grades and numeric equivalents
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-1\. 建筑等级及数值对应关系
- en: '| Value | Description |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 值 | 描述 |'
- en: '| --- | --- |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | Cabin |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 小木屋 |'
- en: '| 2 | Substandard |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 次标准 |'
- en: '| 5 | Fair |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 中等 |'
- en: '| 10 | Very good |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 很好 |'
- en: '| 12 | Luxury |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 豪华 |'
- en: '| 13 | Mansion |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 豪宅 |'
- en: Treating ordered factors as a numeric variable preserves the information contained
    in the ordering that would be lost if it were converted to a factor.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 将有序因子视为数值变量可以保留包含在排序中的信息，如果将其转换为因子，则会丢失这些信息。
- en: Interpreting the Regression Equation
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释回归方程
- en: In data science, the most important use of regression is to predict some dependent
    (outcome) variable. In some cases, however, gaining insight from the equation
    itself to understand the nature of the relationship between the predictors and
    the outcome can be of value. This section provides guidance on examining the regression
    equation and interpreting it.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，回归的最重要用途之一是预测某些依赖（结果）变量。然而，在某些情况下，从方程本身获取洞察力，以理解预测变量与结果之间的关系性质也是有价值的。本节提供了检查回归方程和解释它的指导。
- en: Correlated Predictors
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关的预测变量
- en: In multiple regression, the predictor variables are often correlated with each
    other. As an example, examine the regression coefficients for the model `step_lm`,
    fit in [“Model Selection and Stepwise Regression”](#StepwiseRegression).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在多元回归中，预测变量通常彼此相关。例如，检查在[“模型选择和逐步回归”](#StepwiseRegression)中拟合的模型`step_lm`的回归系数。
- en: '*R*:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '*R*：'
- en: '[PRE33]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '*Python*:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*：'
- en: '[PRE34]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The coefficient for `Bedrooms` is negative! This implies that adding a bedroom
    to a house will reduce its value. How can this be? This is because the predictor
    variables are correlated: larger houses tend to have more bedrooms, and it is
    the size that drives house value, not the number of bedrooms. Consider two homes
    of the exact same size: it is reasonable to expect that a home with more but smaller
    bedrooms would be considered less desirable.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`Bedrooms`的系数是负的！这意味着向房屋添加卧室会降低其价值。这怎么可能呢？这是因为预测变量是相关的：较大的房屋通常有更多的卧室，而房屋价值受大小驱动，而不是卧室数量。考虑两个完全相同大小的房屋：合理地期望拥有更多但更小的卧室的房屋会被认为不太理想。'
- en: 'Having correlated predictors can make it difficult to interpret the sign and
    value of regression coefficients (and can inflate the standard error of the estimates).
    The variables for bedrooms, house size, and number of bathrooms are all correlated.
    This is illustrated by the following example in *R*, which fits another regression
    removing the variables `SqFtTotLiving`, `SqFtFinBasement`, and `Bathrooms` from
    the equation:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有相关的预测变量可能会使回归系数的符号和数值难以解释（并可能使估计的标准误差增大）。卧室、房屋面积和浴室数量这些变量都是相关的。这在下面的*R*示例中得到了说明，该示例从方程中移除变量`SqFtTotLiving`、`SqFtFinBasement`和`Bathrooms`后拟合了另一个回归方程：
- en: '[PRE35]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The `update` function can be used to add or remove variables from a model. Now
    the coefficient for bedrooms is positive—in line with what we would expect (though
    it is really acting as a proxy for house size, now that those variables have been
    removed).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '`update`函数可用于向模型中添加或移除变量。现在卧室的系数为正——符合我们的预期（尽管现在这实际上是作为房屋尺寸的代理，因为这些变量已被移除）。'
- en: 'In *Python*, there is no equivalent to *R*’s `update` function. We need to
    refit the model with the modified predictor list:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Python*中，没有相当于*R*的`update`函数的功能。我们需要使用修改后的预测变量列表重新拟合模型：
- en: '[PRE36]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Correlated variables are only one issue with interpreting regression coefficients.
    In `house_lm`, there is no variable to account for the location of the home, and
    the model is mixing together very different types of regions. Location may be
    a *confounding* variable; see [“Confounding Variables”](#ConfoundingVariables)
    for further discussion.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 相关变量只是解释回归系数的一个问题。在`house_lm`中，没有变量来说明房屋的位置，模型将非常不同类型的地区混合在一起。位置可能是一个*混淆*变量；请参阅[“混淆变量”](#ConfoundingVariables)以进一步讨论。
- en: Multicollinearity
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多重共线性
- en: 'An extreme case of correlated variables produces multicollinearity—a condition
    in which there is redundance among the predictor variables. Perfect multicollinearity
    occurs when one predictor variable can be expressed as a linear combination of
    others. Multicollinearity occurs when:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 相关变量的一个极端情况产生了多重共线性——在预测变量之间存在冗余。完美多重共线性发生在一个预测变量可以表示为其他变量的线性组合时。多重共线性发生在以下情况下：
- en: A variable is included multiple times by error.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个变量因错误而多次被包含。
- en: '*P* dummies, instead of *P* – 1 dummies, are created from a factor variable
    (see [“Factor Variables in Regression”](#FactorsRegression)).'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从一个因子变量创建*P*个哑变量，而不是*P* - 1个哑变量（请参阅[“回归中的因子变量”](#FactorsRegression)）。
- en: Two variables are nearly perfectly correlated with one another.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个变量几乎完全与彼此相关。
- en: Multicollinearity in regression must be addressed—variables should be removed
    until the multicollinearity is gone. A regression does not have a well-defined
    solution in the presence of perfect multicollinearity. Many software packages,
    including *R* and *Python*, automatically handle certain types of multicollinearity.
    For example, if `SqFtTotLiving` is included twice in the regression of the `house`
    data, the results are the same as for the `house_lm` model. In the case of nonperfect
    multicollinearity, the software may obtain a solution, but the results may be
    unstable.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归中，多重共线性必须得到解决——变量应该被移除，直到多重共线性消失。在完美多重共线性存在的情况下，回归没有一个明确定义的解。许多软件包，包括*R*和*Python*，可以自动处理某些类型的多重共线性。例如，如果在`house`数据的回归中两次包含`SqFtTotLiving`，则结果与`house_lm`模型的结果相同。在非完美多重共线性的情况下，软件可能会得出一个解，但结果可能不稳定。
- en: Note
  id: totrans-255
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Multicollinearity is not such a problem for nonlinear regression methods like
    trees, clustering, and nearest-neighbors, and in such methods it may be advisable
    to retain *P* dummies (instead of *P* – 1). That said, even in those methods,
    nonredundancy in predictor variables is still a virtue.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 多重共线性对于树、聚类和最近邻等非线性回归方法并不是一个问题，在这些方法中保留*P*个哑变量（而不是*P* - 1个）可能是明智的选择。尽管如此，在这些方法中，预测变量的非冗余性仍然是一种美德。
- en: Confounding Variables
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆变量
- en: 'With correlated variables, the problem is one of commission: including different
    variables that have a similar predictive relationship with the response. With
    *confounding variables*, the problem is one of omission: an important variable
    is not included in the regression equation. Naive interpretation of the equation
    coefficients can lead to invalid conclusions.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 对于相关变量，问题是包含具有与响应变量类似的预测关系的不同变量。对于*混淆变量*，问题是省略了一个重要变量，该变量未包含在回归方程中。对方程系数的天真解释可能导致无效结论。
- en: 'Take, for example, the King County regression equation `house_lm` from [“Example:
    King County Housing Data”](#KingCountyHousingData). The regression coefficients
    of `SqFtLot`, `Bathrooms`, and `Bedrooms` are all negative. The original regression
    model does not contain a variable to represent location—a very important predictor
    of house price. To model location, include a variable `ZipGroup` that categorizes
    the zip code into one of five groups, from least expensive (1) to most expensive
    (5):^([5](ch04.xhtml#idm46522852564136))'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，来自[“示例：金县住房数据”](#KingCountyHousingData)的金县回归方程`house_lm`。`SqFtLot`，`Bathrooms`和`Bedrooms`的回归系数都为负。原始回归模型不包含代表位置的变量——房价的一个非常重要的预测因子。为了建模位置，包括一个将邮政编码分为五个组的变量`ZipGroup`，从最便宜（1）到最昂贵（5）：^([5](ch04.xhtml#idm46522852564136))
- en: '[PRE37]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The same model in *Python*:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Python*中相同的模型：
- en: '[PRE38]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '`ZipGroup` is clearly an important variable: a home in the most expensive zip
    code group is estimated to have a higher sales price by almost $340,000. The coefficients
    of `SqFtLot` and `Bathrooms` are now positive, and adding a bathroom increases
    the sale price by $5,928.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '`ZipGroup`显然是一个重要的变量：预计位于最昂贵邮政编码组的房屋销售价格较高，约为$340,000。`SqFtLot`和`Bathrooms`的系数现在为正，并且每增加一个浴室，销售价格增加$5,928。'
- en: The coefficient for `Bedrooms` is still negative. While this is unintuitive,
    this is a well-known phenomenon in real estate. For homes of the same livable
    area and number of bathrooms, having more and therefore smaller bedrooms is associated
    with less valuable homes.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '`Bedrooms`的系数仍然为负。尽管这听起来不直观，但这是房地产中众所周知的现象。对于具有相同可居住面积和浴室数量的房屋来说，拥有更多但因此更小的卧室与价值较低的房屋相关联。'
- en: Interactions and Main Effects
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交互作用和主效应
- en: Statisticians like to distinguish between *main effects*, or independent variables,
    and the *interactions* between the main effects. Main effects are what are often
    referred to as the *predictor variables* in the regression equation. An implicit
    assumption when only main effects are used in a model is that the relationship
    between a predictor variable and the response is independent of the other predictor
    variables. This is often not the case.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学家喜欢区分*主效应*或自变量和主效应之间的*交互*。主效应通常在回归方程中称为*预测变量*。当模型中仅使用主效应时的一个隐含假设是，预测变量与响应之间的关系独立于其他预测变量。这通常并非如此。
- en: 'For example, the model fit to the King County Housing Data in [“Confounding
    Variables”](#ConfoundingVariables) includes several variables as main effects,
    including `ZipCode`. Location in real estate is everything, and it is natural
    to presume that the relationship between, say, house size and the sale price depends
    on location. A big house built in a low-rent district is not going to retain the
    same value as a big house built in an expensive area. You include interactions
    between variables in *R* using the `*` operator. For the King County data, the
    following fits an interaction between `SqFtTotLiving` and `ZipGroup`:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，适用于[“混杂变量”](#ConfoundingVariables)中的金县住房数据的模型包括几个变量作为主要效应，包括`ZipCode`。在房地产中，位置至关重要，可以自然地假设，例如，房屋大小与销售价格之间的关系取决于位置。在低租金区建造的大房子不会像在昂贵地区建造的大房子一样保持相同的价值。在*R*中使用`*`运算符可以包括变量之间的交互。对于金县数据，以下内容适合于`SqFtTotLiving`和`ZipGroup`之间的交互：
- en: '[PRE39]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The resulting model has four new terms: `SqFtTotLiving:ZipGroup2`, `SqFtTotLiving:ZipGroup3`,
    and so on.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 结果模型有四个新项：`SqFtTotLiving:ZipGroup2`，`SqFtTotLiving:ZipGroup3`等等。
- en: 'In *Python*, we need to use the `statsmodels` package to train linear regression
    models with interactions. This package was designed similar to *R* and allows
    defining models using a formula interface:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Python*中，我们需要使用`statsmodels`包来训练具有交互效应的线性回归模型。该包设计类似于*R*，允许使用公式接口定义模型：
- en: '[PRE40]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The `statsmodels` package takes care of categorical variables (e.g., `ZipGroup[T.1]`,
    `PropertyType[T.Single Family]`) and interaction terms (e.g., `SqFtTotLiving:ZipGroup[T.1]`).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '`statsmodels`包处理分类变量（例如，`ZipGroup[T.1]`，`PropertyType[T.Single Family]`）和交互项（例如，`SqFtTotLiving:ZipGroup[T.1]`）。'
- en: Location and house size appear to have a strong interaction. For a home in the
    lowest `ZipGroup`, the slope is the same as the slope for the main effect `SqFtTotLiving`,
    which is $118 per square foot (this is because *R* uses *reference* coding for
    factor variables; see [“Factor Variables in Regression”](#FactorsRegression)).
    For a home in the highest `ZipGroup`, the slope is the sum of the main effect
    plus `SqFtTotLiving:ZipGroup5`, or $115 + $227 = $342 per square foot. In other
    words, adding a square foot in the most expensive zip code group boosts the predicted
    sale price by a factor of almost three, compared to the average boost from adding
    a square foot.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 地点和房屋大小似乎存在强烈的交互作用。对于位于最低`ZipGroup`的房屋，其斜率与主效应`SqFtTotLiving`的斜率相同，即每平方英尺118美元（这是因为*R*对因子变量使用*参照*编码；详见[“回归中的因子变量”](#FactorsRegression)）。对于位于最高`ZipGroup`的房屋，斜率为主效应加上`SqFtTotLiving:ZipGroup5`，即115美元加227美元
    = 每平方英尺342美元。换句话说，在最昂贵的邮政编码组中增加一个平方英尺几乎能使预测销售价格增加三倍，相比增加一个平方英尺的平均增幅。
- en: Model Selection with Interaction Terms
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用交互项进行模型选择
- en: 'In problems involving many variables, it can be challenging to decide which
    interaction terms should be included in the model. Several different approaches
    are commonly taken:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在涉及许多变量的问题中，决定应该包括哪些交互项在模型中可能具有挑战性。通常采用几种不同的方法：
- en: In some problems, prior knowledge and intuition can guide the choice of which
    interaction terms to include in the model.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在某些问题中，先验知识和直觉可以指导选择包括在模型中的交互项。
- en: Stepwise selection (see [“Model Selection and Stepwise Regression”](#StepwiseRegression))
    can be used to sift through the various models.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步选择（详见[“模型选择和逐步回归”](#StepwiseRegression)）可用于筛选各种模型。
- en: Penalized regression can automatically fit to a large set of possible interaction
    terms.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 惩罚回归可以自动适配大量可能的交互项。
- en: Perhaps the most common approach is to use *tree models*, as well as their descendants,
    *random forest* and *gradient boosted trees*. This class of models automatically
    searches for optimal interaction terms; see [“Tree Models”](ch06.xhtml#TreeModels).
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或许最常见的方法是使用*树模型*及其派生物*随机森林*和*梯度提升树*。这类模型会自动搜索最优的交互项；详见[“树模型”](ch06.xhtml#TreeModels)。
- en: Regression Diagnostics
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归诊断
- en: In explanatory modeling (i.e., in a research context), various steps, in addition
    to the metrics mentioned previously (see [“Assessing the Model”](#RMSE)), are
    taken to assess how well the model fits the data; most are based on analysis of
    the residuals. These steps do not directly address predictive accuracy, but they
    can provide useful insight in a predictive setting.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释建模（即在研究背景下），除了前面提到的度量标准之外（见[“评估模型”](#RMSE)），还采取各种步骤来评估模型与数据的拟合程度；大多数是基于残差分析的。这些步骤并不直接解决预测精度问题，但在预测设置中提供有用的见解。
- en: Outliers
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异常值
- en: Generally speaking, an extreme value, also called an *outlier*, is one that
    is distant from most of the other observations. Just as outliers need to be handled
    for estimates of location and variability (see [“Estimates of Location”](ch01.xhtml#Location)
    and [“Estimates of Variability”](ch01.xhtml#Variability)), outliers can cause
    problems with regression models. In regression, an outlier is a record whose actual
    *y* value is distant from the predicted value. You can detect outliers by examining
    the *standardized residual*, which is the residual divided by the standard error
    of the residuals.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，极端值，也称为*异常值*，是与大多数其他观测值远离的观测值。正如需要处理位置和变异估计（见[“位置估计”](ch01.xhtml#Location)和[“变异性估计”](ch01.xhtml#Variability)）中的异常值一样，异常值可能导致回归模型的问题。在回归中，异常值是其实际*y*值与预测值差异显著的记录。可以通过检查*标准化残差*来检测异常值，标准化残差是残差除以残差的标准误差。
- en: There is no statistical theory that separates outliers from nonoutliers. Rather,
    there are (arbitrary) rules of thumb for how distant from the bulk of the data
    an observation needs to be in order to be called an outlier. For example, with
    the boxplot, outliers are those data points that are too far above or below the
    box boundaries (see [“Percentiles and Boxplots”](ch01.xhtml#Boxplots)), where
    “too far” = “more than 1.5 times the interquartile range.” In regression, the
    standardized residual is the metric that is typically used to determine whether
    a record is classified as an outlier. Standardized residuals can be interpreted
    as “the number of standard errors away from the regression line.”
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 没有将异常值与非异常值分开的统计理论。相反，有关观察结果需要与数据主体有多远的（任意的）经验法则，才能称为异常值。例如，在箱线图中，异常值是那些远离箱体边界的数据点（见[“百分位数和箱线图”](ch01.xhtml#Boxplots)），其中“太远”=“超过四分位距的1.5倍”。在回归中，标准化残差是通常用于确定记录是否被分类为异常值的度量标准。标准化残差可以解释为“距离回归线的标准误差数”。
- en: 'Let’s fit a regression to the King County house sales data for all sales in
    zip code 98105 in *R*:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 *R* 中为98105邮政编码中所有销售的金县房屋销售数据拟合回归：
- en: '[PRE41]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In *Python*:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *Python* 中：
- en: '[PRE42]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We extract the standardized residuals in *R* using the `rstandard` function
    and obtain the index of the smallest residual using the `order` function:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `rstandard` 函数在 *R* 中提取标准化残差，并使用 `order` 函数获取最小残差的索引：
- en: '[PRE43]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'In `statsmodels`, use `OLSInfluence` to analyze the residuals:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `statsmodels` 中，使用 `OLSInfluence` 分析残差：
- en: '[PRE44]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The biggest overestimate from the model is more than four standard errors above
    the regression line, corresponding to an overestimate of $757,754. The original
    data record corresponding to this outlier is as follows in *R*:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 从模型中最大的高估是超过回归线四倍标准误差，对应于757,754美元的高估。这个异常值对应的原始数据记录在 *R* 中如下：
- en: '[PRE45]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'In *Python*:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *Python* 中：
- en: '[PRE46]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'In this case, it appears that there is something wrong with the record: a house
    of that size typically sells for much more than $119,748 in that zip code. [Figure 4-4](#StatutoryDeed)
    shows an excerpt from the statutory deed from this sale: it is clear that the
    sale involved only partial interest in the property. In this case, the outlier
    corresponds to a sale that is anomalous and should not be included in the regression.
    Outliers could also be the result of other problems, such as a “fat-finger” data
    entry or a mismatch of units (e.g., reporting a sale in thousands of dollars rather
    than simply in dollars).'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，似乎记录存在问题：在该邮政编码中，这种大小的房屋通常售价远高于119,748美元。[图4-4](#StatutoryDeed) 显示了这次销售的法定保证书摘录：显然，这次销售仅涉及部分产权。在这种情况下，异常值对应的是一笔异常的销售，不应包括在回归中。异常值也可能是其他问题的结果，如“手残”数据录入或单位不匹配（例如，报告销售额为千美元而不是美元）。
- en: '![Statutory warranty deed for the largest negative residual](Images/psd2_0404.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![最大负残差的法定保证书](Images/psd2_0404.png)'
- en: Figure 4-4\. Statutory warrany deed for the largest negative residual
  id: totrans-299
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-4。最大负残差的法定保证书
- en: For big data problems, outliers are generally not a problem in fitting the regression
    to be used in predicting new data. However, outliers are central to anomaly detection,
    where finding outliers is the whole point. The outlier could also correspond to
    a case of fraud or an accidental action. In any case, detecting outliers can be
    a critical business need.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大数据问题，异常值通常不是拟合回归用于预测新数据时的问题。然而，在异常检测中，异常值是核心，其目的就是找到异常值。异常值也可能对应于欺诈案例或意外行为。无论哪种情况，检测异常值都可能是业务上的关键需求。
- en: Influential Values
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有影响力的值
- en: A value whose absence would significantly change the regression equation is
    termed an *influential observation*. In regression, such a value need not be associated
    with a large residual. As an example, consider the regression lines in [Figure 4-5](#InfluenceExample).
    The solid line corresponds to the regression with all the data, while the dashed
    line corresponds to the regression with the point in the upper-right corner removed.
    Clearly, that data value has a huge influence on the regression even though it
    is not associated with a large outlier (from the full regression). This data value
    is considered to have high *leverage* on the regression.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 一个值，如果去掉会显著改变回归方程，被称为*有影响力的观测*。在回归中，这样的值不一定与大的残差相关联。例如，考虑[图 4-5](#InfluenceExample)中的回归线。实线对应于所有数据的回归，而虚线对应于移除右上角的点的回归。显然，即使与大的异常值（来自完整回归）无关，该数据值对回归的影响仍然巨大。认为这个数据值对回归具有很高的*杠杆*。
- en: In addition to standardized residuals (see [“Outliers”](#regression_outliers)),
    statisticians have developed several metrics to determine the influence of a single
    record on a regression. A common measure of leverage is the *hat-value*; values
    above <math alttext="2 left-parenthesis upper P plus 1 right-parenthesis slash
    n"><mrow><mn>2</mn> <mo>(</mo> <mi>P</mi> <mo>+</mo> <mn>1</mn> <mo>)</mo> <mo>/</mo>
    <mi>n</mi></mrow></math> indicate a high-leverage data value.^([6](ch04.xhtml#idm46522851692056))
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标准化残差（参见[“异常值”](#regression_outliers)），统计学家还开发了几个度量标准，以确定单个记录对回归的影响。一个常见的杠杆度量是*帽子值*；值大于<math
    alttext="2 左括号 上标 P 加 1 右括号 斜杠 n"><mrow><mn>2</mn> <mo>(</mo> <msup><mi>P</mi><mo>+</mo><mn>1</mn></msup>
    <mo>)</mo> <mo>/</mo> <mi>n</mi></mrow></math>表示高杠杆的数据值。^([6](ch04.xhtml#idm46522851692056))
- en: '![An example of an influential data point in regression](Images/psd2_0405.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![回归中有影响力的数据点的示例](Images/psd2_0405.png)'
- en: Figure 4-5\. An example of an influential data point in regression
  id: totrans-305
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-5 回归中有影响力的数据点的示例
- en: Another metric is *Cook’s distance*, which defines influence as a combination
    of leverage and residual size. A rule of thumb is that an observation has high
    influence if Cook’s distance exceeds <math alttext="4 slash left-parenthesis n
    minus upper P minus 1 right-parenthesis"><mrow><mn>4</mn> <mo>/</mo> <mo>(</mo>
    <mi>n</mi> <mo>-</mo> <mi>P</mi> <mo>-</mo> <mn>1</mn> <mo>)</mo></mrow></math>
    .
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个度量标准是*Cook 距离*，它将影响定义为杠杆和残差大小的组合。一个经验法则是，如果 Cook 距离超过<math alttext="4 斜杠
    左括号 n 减 上标 P 减 1 右括号"><mrow><mn>4</mn> <mo>/</mo> <mo>(</mo> <mi>n</mi> <mo>-</mo>
    <msup><mi>P</mi><mo>-</mo><mn>1</mn></msup> <mo>)</mo></mrow></math>，则观测具有很高的影响力。
- en: 'An *influence plot* or *bubble plot* combines standardized residuals, the hat-value,
    and Cook’s distance in a single plot. [Figure 4-6](#InfluencePlot) shows the influence
    plot for the King County house data and can be created by the following *R* code:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '*影响力图*或*气泡图*将标准化残差、帽子值和 Cook 距离结合在一个图中。[图 4-6](#InfluencePlot)显示了金县房屋数据的影响力图，并可以通过以下*R*代码创建：'
- en: '[PRE47]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Here is the *Python* code to create a similar figure:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是创建类似图形的*Python*代码：
- en: '[PRE48]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: There are apparently several data points that exhibit large influence in the
    regression. Cook’s distance can be computed using the function `cooks.distance`,
    and you can use `hatvalues` to compute the diagnostics. The hat values are plotted
    on the x-axis, the residuals are plotted on the y-axis, and the size of the points
    is related to the value of Cook’s distance.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 显然有几个数据点在回归中具有很大的影响。可以使用函数`cooks.distance`计算 Cook 距离，可以使用`hatvalues`计算诊断结果。帽子值绘制在
    x 轴上，残差绘制在 y 轴上，点的大小与 Cook 距离的值相关。
- en: '![A plot to determine which observations have high influence](Images/psd2_0406.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![一个绘图以确定哪些观测具有很高的影响力](Images/psd2_0406.png)'
- en: Figure 4-6\. A plot to determine which observations have high influence; points
    with Cook’s distance greater than 0.08 are highlighted in grey
  id: totrans-313
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-6 一个绘图以确定哪些观测具有很高的影响力；Cook 距离大于 0.08 的点以灰色突出显示
- en: '[Table 4-2](#InfluenceTable) compares the regression with the full data set
    and with highly influential data points removed (Cook’s distance > 0.08).'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 4-2](#InfluenceTable)比较了使用完整数据集和去除高度有影响力的数据点（Cook 距离 > 0.08）的回归。'
- en: The regression coefficient for `Bathrooms` changes quite dramatically.^([7](ch04.xhtml#idm46522851379304))
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '`Bathrooms`的回归系数发生了相当大的变化。^([7](ch04.xhtml#idm46522851379304))'
- en: Table 4-2\. Comparison of regression coefficients with the full data and with
    influential data removed
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-2 比较了使用完整数据和去除有影响力数据后的回归系数
- en: '|  | Original | Influential removed |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '|  | 原始数据 | 去除影响后 |'
- en: '| --- | --- | --- |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| (Intercept) | –772,550 | –647,137 |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| (Intercept) | –772,550 | –647,137 |'
- en: '| SqFtTotLiving | 210 | 230 |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| SqFtTotLiving | 210 | 230 |'
- en: '| SqFtLot | 39 | 33 |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| SqFtLot | 39 | 33 |'
- en: '| Bathrooms | 2282 | –16,132 |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| Bathrooms | 2282 | –16,132 |'
- en: '| Bedrooms | –26,320 | –22,888 |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| Bedrooms | –26,320 | –22,888 |'
- en: '| BldgGrade | 130,000 | 114,871 |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| BldgGrade | 130,000 | 114,871 |'
- en: For purposes of fitting a regression that reliably predicts future data, identifying
    influential observations is useful only in smaller data sets. For regressions
    involving many records, it is unlikely that any one observation will carry sufficient
    weight to cause extreme influence on the fitted equation (although the regression
    may still have big outliers). For purposes of anomaly detection, though, identifying
    influential observations can be very useful.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可靠地拟合可以预测未来数据的回归模型，识别具有影响力的观察结果仅在较小的数据集中有用。对于涉及大量记录的回归，单个观察结果不太可能对拟合方程产生极端影响（尽管回归仍可能存在极大的异常值）。然而，对于异常检测的目的，识别具有影响力的观察结果是非常有用的。
- en: Heteroskedasticity, Non-Normality, and Correlated Errors
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异方差性、非正态性和相关误差
- en: Statisticians pay considerable attention to the distribution of the residuals.
    It turns out that ordinary least squares (see [“Least Squares”](#OLS)) are unbiased,
    and in some cases are the “optimal” estimator, under a wide range of distributional
    assumptions. This means that in most problems, data scientists do not need to
    be too concerned with the distribution of the residuals.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学家非常关注残差的分布。事实证明，普通最小二乘法（见[“最小二乘法”](#OLS)）在广泛的分布假设下是无偏的，并且在某些情况下是“最优”的估计量。这意味着在大多数问题中，数据科学家不需要过于担心残差的分布。
- en: The distribution of the residuals is relevant mainly for the validity of formal
    statistical inference (hypothesis tests and p-values), which is of minimal importance
    to data scientists concerned mainly with predictive accuracy. Normally distributed
    errors are a sign that the model is complete; errors that are not normally distributed
    indicate the model may be missing something. For formal inference to be fully
    valid, the residuals are assumed to be normally distributed, have the same variance,
    and be independent. One area where this may be of concern to data scientists is
    the standard calculation of confidence intervals for predicted values, which are
    based upon the assumptions about the residuals (see [“Confidence and Prediction
    Intervals”](#RegressionCIs)).
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 残差的分布主要与正式统计推断（假设检验和 p 值）的有效性相关，这对主要关注预测准确性的数据科学家影响较小。正态分布的误差表明模型完整；不正态分布的误差表明模型可能存在遗漏。为了使正式推断完全有效，假设残差正态分布、方差相同且独立。数据科学家可能关注的一个领域是对预测值的置信区间的标准计算，这些置信区间基于对残差的假设（见[“置信区间与预测区间”](#RegressionCIs)）。
- en: '*Heteroskedasticity* is the lack of constant residual variance across the range
    of the predicted values. In other words, errors are greater for some portions
    of the range than for others. Visualizing the data is a convenient way to analyze
    residuals.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '*异方差性* 指的是在预测值范围内残差方差不恒定。换句话说，某些范围内的误差比其他范围大。可视化数据是分析残差的方便方式。'
- en: 'The following code in *R* plots the absolute residuals versus the predicted
    values for the `lm_98105` regression fit in [“Outliers”](#regression_outliers):'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *R* 中，以下代码绘制了`lm_98105`回归拟合中预测值的绝对残差与预测值的关系图，详见[“异常值”](#regression_outliers)：
- en: '[PRE49]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[Figure 4-7](#HouseHetero) shows the resulting plot. Using `geom_smooth`, it
    is easy to superpose a smooth of the absolute residuals. The function calls the
    `loess` method (locally estimated scatterplot smoothing) to produce a smoothed
    estimate of the relationship between the variables on the x-axis and y-axis in
    a scatterplot (see [“Scatterplot Smoothers”](#ScatterplotSmoothers)).'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-7](#HouseHetero) 展示了得到的图形。使用 `geom_smooth`，可以轻松叠加绝对残差的平滑曲线。该函数调用 `loess`
    方法（局部估计散点图平滑）生成 x 轴和 y 轴上变量关系的平滑估计散点图（见[“散点图平滑处理”](#ScatterplotSmoothers)）。'
- en: 'In *Python*, the `seaborn` package has the `regplot` function to create a similar
    figure:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *Python* 中，`seaborn`包中的`regplot`函数可以创建类似的图形：
- en: '[PRE50]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '![A plot of the absolute value of the residuals versus the predicted values](Images/psd2_0407.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![绘制残差绝对值与预测值关系图](Images/psd2_0407.png)'
- en: Figure 4-7\. A plot of the absolute value of the residuals versus the predicted
    values
  id: totrans-336
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-7\. 绘制残差绝对值与预测值关系图
- en: Evidently, the variance of the residuals tends to increase for higher-valued
    homes but is also large for lower-valued homes. This plot indicates that `lm_98105`
    has *heteroskedastic* errors.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，残差的方差在更高价值的房屋上倾向于增加，但在更低价值的房屋上也很大。此图表明`lm_98105`具有*异方差*的误差。
- en: Why Would a Data Scientist Care About Heteroskedasticity?
  id: totrans-338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学家为什么要关心异方差性？
- en: Heteroskedasticity indicates that prediction errors differ for different ranges
    of the predicted value, and may suggest an incomplete model. For example, the
    heteroskedasticity in `lm_98105` may indicate that the regression has left something
    unaccounted for in high- and low-range homes.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 异方差性表明不同预测值范围的预测误差不同，并且可能暗示模型不完整。例如，`lm_98105`中的异方差性可能表明回归在高价值和低价值房屋中留下了一些未解释的因素。
- en: '[Figure 4-8](#HistRegression) is a histogram of the standardized residuals
    for the `lm_98105` regression. The distribution has decidedly longer tails than
    the normal distribution and exhibits mild skewness toward larger residuals.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-8](#HistRegression)是对`lm_98105`回归的标准化残差的直方图。该分布的尾部明显比正态分布长，并且在较大残差方向上呈现轻微偏斜。'
- en: '![A histogram of the residuals from the regression of the housing data](Images/psd2_0408.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![房屋数据回归残差的直方图](Images/psd2_0408.png)'
- en: Figure 4-8\. A histogram of the residuals from the regression of the housing
    data
  id: totrans-342
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-8。房屋数据回归残差的直方图
- en: Statisticians may also check the assumption that the errors are independent.
    This is particularly true for data that is collected over time or space. The *Durbin-Watson*
    statistic can be used to detect if there is significant autocorrelation in a regression
    involving time series data. If the errors from a regression model are correlated,
    then this information can be useful in making short-term forecasts and should
    be built into the model. See *Practical Time Series Forecasting with R*, 2nd ed.,
    by Galit Shmueli and Kenneth Lichtendahl (Axelrod Schnall, 2018) to learn more
    about how to build autocorrelation information into regression models for time
    series data. If longer-term forecasts or explanatory models are the goal, excess
    autocorrelated data at the microlevel may distract. In that case, smoothing, or
    less granular collection of data in the first place, may be in order.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学家可能还会检查误差是否独立。这对于随时间或空间收集的数据尤为重要。 *德宾-沃森*统计量可用于检测涉及时间序列数据的回归中是否存在显著的自相关性。如果回归模型的误差相关，则此信息可以有助于进行短期预测，并应纳入模型中。请参阅Galit
    Shmueli和Kenneth Lichtendahl（Axelrod Schnall，2018）的*用R进行实用时间序列预测*第2版，以了解有关如何将自相关信息构建到用于时间序列数据的回归模型中的更多信息。如果目标是更长期的预测或解释模型，则微观层面上的过多自相关数据可能会分散注意力。在这种情况下，平滑处理或首先收集更少细粒度的数据可能是适当的。
- en: Even though a regression may violate one of the distributional assumptions,
    should we care? Most often in data science, the interest is primarily in predictive
    accuracy, so some review of heteroskedasticity may be in order. You may discover
    that there is some signal in the data that your model has not captured. However,
    satisfying distributional assumptions simply for the sake of validating formal
    statistical inference (p-values, F-statistics, etc.) is not that important for
    the data scientist.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 即使回归可能违反了分布假设之一，我们是否应该在意呢？在数据科学中，兴趣主要在于预测准确性，因此可能需要对异方差性进行一些审查。您可能会发现数据中存在一些模型未捕获的信号。然而，仅仅为了验证正式的统计推断（p值，F统计量等）而满足分布假设并不是对于数据科学家非常重要的。
- en: Scatterplot Smoothers
  id: totrans-345
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 散点平滑曲线
- en: Regression is about modeling the relationship between the response and predictor
    variables. In evaluating a regression model, it is useful to use a *scatterplot
    smoother* to visually highlight relationships between two variables.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是关于响应变量和预测变量之间关系建模的。在评估回归模型时，使用*散点平滑曲线*可以直观地突出两个变量之间的关系是很有用的。
- en: For example, in [Figure 4-7](#HouseHetero), a smooth of the relationship between
    the absolute residuals and the predicted value shows that the variance of the
    residuals depends on the value of the residual. In this case, the `loess` function
    was used; `loess` works by repeatedly fitting a series of local regressions to
    contiguous subsets to come up with a smooth. While `loess` is probably the most
    commonly used smoother, other scatterplot smoothers are available in *R*, such
    as super smooth (`supsmu`) and kernel smoothing (`ksmooth`). In *Python*, we can
    find additional smoothers in `scipy` (`wiener` or `sav`) and `statsmodels` (`kernel_regression`).
    For the purposes of evaluating a regression model, there is typically no need
    to worry about the details of these scatterplot smooths.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在 [图 4-7](#HouseHetero) 中，绝对残差与预测值之间关系的平滑显示出残差的方差取决于残差值。在这种情况下，使用了 `loess`
    函数；`loess` 的工作原理是通过反复拟合一系列局部回归来实现平滑。虽然 `loess` 可能是最常用的平滑方法，*R* 中还提供了其他散点图平滑方法，如超平滑
    (`supsmu`) 和核平滑 (`ksmooth`)。在 *Python* 中，我们可以在 `scipy` (`wiener` 或 `sav`) 和 `statsmodels`
    (`kernel_regression`) 中找到额外的平滑方法。对于评估回归模型，通常不需要担心这些散点图平滑方法的细节。
- en: Partial Residual Plots and Nonlinearity
  id: totrans-348
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局部残差图和非线性
- en: '*Partial residual plots* are a way to visualize how well the estimated fit
    explains the relationship between a predictor and the outcome. The basic idea
    of a partial residual plot is to isolate the relationship between a predictor
    variable and the response, *taking into account all of the other predictor variables*.
    A partial residual might be thought of as a “synthetic outcome” value, combining
    the prediction based on a single predictor with the actual residual from the full
    regression equation. A partial residual for predictor <math alttext="upper X Subscript
    i"><msub><mi>X</mi> <mi>i</mi></msub></math> is the ordinary residual plus the
    regression term associated with <math alttext="upper X Subscript i"><msub><mi>X</mi>
    <mi>i</mi></msub></math> :'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '*局部残差图* 是可视化估计拟合效果和预测变量与结果之间关系的一种方式。局部残差图的基本思想是隔离一个预测变量与响应之间的关系，*考虑所有其他预测变量*。局部残差可以被视为一个“合成结果”值，将基于单个预测变量的预测与全回归方程的实际残差结合起来。对于预测变量
    <math alttext="upper X Subscript i"><msub><mi>X</mi> <mi>i</mi></msub></math>
    的局部残差是普通残差加上与 <math alttext="upper X Subscript i"><msub><mi>X</mi> <mi>i</mi></msub></math>
    相关的回归项：'
- en: <math display="block" alttext="Partial residual equals Residual plus ModifyingAbove
    b With caret Subscript i Baseline upper X Subscript i Baseline"><mrow><mtext>Partial</mtext>
    <mtext>residual</mtext> <mo>=</mo> <mtext>Residual</mtext> <mo>+</mo> <msub><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mi>i</mi></msub> <msub><mi>X</mi>
    <mi>i</mi></msub></mrow></math>
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block" alttext="Partial residual equals Residual plus ModifyingAbove
    b With caret Subscript i Baseline upper X Subscript i Baseline"><mrow><mtext>Partial</mtext>
    <mtext>residual</mtext> <mo>=</mo> <mtext>Residual</mtext> <mo>+</mo> <msub><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mi>i</mi></msub> <msub><mi>X</mi>
    <mi>i</mi></msub></mrow></math>
- en: 'where <math alttext="ModifyingAbove b With caret Subscript i"><msub><mover
    accent="true"><mi>b</mi> <mo>^</mo></mover> <mi>i</mi></msub></math> is the estimated
    regression coefficient. The `predict` function in *R* has an option to return
    the individual regression terms <math alttext="ModifyingAbove b With caret Subscript
    i Baseline upper X Subscript i"><mrow><msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover>
    <mi>i</mi></msub> <msub><mi>X</mi> <mi>i</mi></msub></mrow></math> :'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 <math alttext="ModifyingAbove b With caret Subscript i"><msub><mover accent="true"><mi>b</mi>
    <mo>^</mo></mover> <mi>i</mi></msub></math> 是估计的回归系数。在 *R* 中的 `predict` 函数有一个选项可以返回单个回归项
    <math alttext="ModifyingAbove b With caret Subscript i Baseline upper X Subscript
    i"><mrow><msub><mover accent="true"><mi>b</mi> <mo>^</mo></mover> <mi>i</mi></msub>
    <msub><mi>X</mi> <mi>i</mi></msub></mrow></math> ：
- en: '[PRE51]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The partial residual plot displays the <math alttext="upper X Subscript i"><msub><mi>X</mi>
    <mi>i</mi></msub></math> predictor on the x-axis and the partial residuals on
    the y-axis. Using `ggplot2` makes it easy to superpose a smooth of the partial
    residuals:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 局部残差图显示了 <math alttext="upper X Subscript i"><msub><mi>X</mi> <mi>i</mi></msub></math>
    预测变量在 x 轴上和局部残差在 y 轴上。使用 `ggplot2` 能够轻松叠加局部残差的平滑曲线：
- en: '[PRE52]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The `statsmodels` package has the method `sm.graphics.plot_ccpr` that creates
    a similar partial residual plot:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '`statsmodels` 包中有一个名为 `sm.graphics.plot_ccpr` 的方法，可以创建类似的局部残差图：'
- en: '[PRE53]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The *R* and *Python* graphs differ by a constant shift. In *R*, a constant is
    added so that the mean of the terms is zero.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '*R* 和 *Python* 中的图表相差一个常数偏移量。在 *R* 中，添加一个常数以使项的平均值为零。'
- en: The resulting plot is shown in [Figure 4-9](#HousePartialResid). The partial
    residual is an estimate of the contribution that `SqFtTotLiving` adds to the sales
    price. The relationship between `SqFtTotLiving` and the sales price is evidently
    nonlinear (dashed line). The regression line (solid line) underestimates the sales
    price for homes less than 1,000 square feet and overestimates the price for homes
    between 2,000 and 3,000 square feet. There are too few data points above 4,000
    square feet to draw conclusions for those homes.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图显示在[图 4-9](#HousePartialResid)中。部分残差是对`SqFtTotLiving`对销售价格贡献的估计。`SqFtTotLiving`与销售价格之间的关系显然是非线性的（虚线）。回归线（实线）低估了小于1,000平方英尺的房屋的销售价格，并高估了2,000到3,000平方英尺之间的房屋价格。对于超过4,000平方英尺的房屋，数据点太少，无法得出结论。
- en: '![A partial residual plot of for the variable SqFtTotLiving](Images/psd2_0409.png)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![变量SqFtTotLiving的部分残差图](Images/psd2_0409.png)'
- en: Figure 4-9\. A partial residual plot for the variable `SqFtTotLiving`
  id: totrans-360
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-9\. 变量`SqFtTotLiving`的部分残差图
- en: 'This nonlinearity makes sense in this case: adding 500 feet in a small home
    makes a much bigger difference than adding 500 feet in a large home. This suggests
    that, instead of a simple linear term for `SqFtTotLiving`, a nonlinear term should
    be considered (see [“Polynomial and Spline Regression”](#NonlinearTerms)).'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，这种非线性是有道理的：在小房屋中增加500平方英尺会产生比在大房屋中增加500平方英尺更大的差异。这表明，与其对`SqFtTotLiving`使用简单的线性项，不如考虑非线性项（参见[“多项式和样条回归”](#NonlinearTerms)）。
- en: Polynomial and Spline Regression
  id: totrans-362
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多项式和样条回归
- en: 'The relationship between the response and a predictor variable isn’t necessarily
    linear. The response to the dose of a drug is often nonlinear: doubling the dosage
    generally doesn’t lead to a doubled response. The demand for a product isn’t a
    linear function of marketing dollars spent; at some point, demand is likely to
    be saturated. There are many ways that regression can be extended to capture these
    nonlinear effects.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 响应与预测变量之间的关系不一定是线性的。对药物剂量的反应通常是非线性的：加倍剂量通常不会导致加倍的反应。产品需求并非是营销投入的线性函数；在某些点上，需求可能会饱和。有许多方法可以扩展回归以捕捉这些非线性效应。
- en: Nonlinear Regression
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非线性回归
- en: When statisticians talk about *nonlinear regression*, they are referring to
    models that can’t be fit using least squares. What kind of models are nonlinear?
    Essentially all models where the response cannot be expressed as a linear combination
    of the predictors or some transform of the predictors. Nonlinear regression models
    are harder and computationally more intensive to fit, since they require numerical
    optimization. For this reason, it is generally preferred to use a linear model
    if possible.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 当统计学家谈论*非线性回归*时，他们指的是无法使用最小二乘法拟合的模型。哪些模型是非线性的？基本上所有响应不能表达为预测变量的线性组合或其某种变换的模型。非线性回归模型更难且计算量更大，因为它们需要数值优化。因此，如果可能的话，通常更倾向于使用线性模型。
- en: Polynomial
  id: totrans-366
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多项式
- en: '*Polynomial regression* involves including polynomial terms in a regression
    equation. The use of polynomial regression dates back almost to the development
    of regression itself with a paper by Gergonne in 1815. For example, a quadratic
    regression between the response *Y* and the predictor *X* would take the form:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '*多项式回归*涉及在回归方程中包含多项式项。使用多项式回归几乎可以追溯到回归本身的发展，比如Gergonne在1815年的一篇论文中。例如，响应*Y*与预测变量*X*之间的二次回归将采取以下形式：'
- en: <math display="block"><mrow><mi>Y</mi> <mo>=</mo> <msub><mi>b</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub> <mi>X</mi> <mo>+</mo> <msub><mi>b</mi>
    <mn>2</mn></msub> <msup><mi>X</mi> <mn>2</mn></msup> <mo>+</mo> <mi>e</mi></mrow></math>
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>Y</mi> <mo>=</mo> <msub><mi>b</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub> <mi>X</mi> <mo>+</mo> <msub><mi>b</mi>
    <mn>2</mn></msub> <msup><mi>X</mi> <mn>2</mn></msup> <mo>+</mo> <mi>e</mi></mrow></math>
- en: 'Polynomial regression can be fit in *R* through the `poly` function. For example,
    the following fits a quadratic polynomial for `SqFtTotLiving` with the King County
    housing data:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式回归可以通过*R*中的`poly`函数进行拟合。例如，以下示例使用King County房屋数据为`SqFtTotLiving`拟合二次多项式：
- en: '[PRE54]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'In `statsmodels`, we add the squared term to the model definition using `I(SqFtTotLiving**2)`:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在`statsmodels`中，我们使用`I(SqFtTotLiving**2)`将平方项添加到模型定义中：
- en: '[PRE55]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[![1](Images/1.png)](#co_regression_and_prediction_CO3-1)'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_regression_and_prediction_CO3-1)'
- en: The intercept and the polynomial coefficients are different compared to *R*.
    This is due to different implementations. The remaining coefficients and the predictions
    are equivalent.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 截距和多项式系数与*R*不同。这是由于不同的实现。其余系数和预测是等效的。
- en: 'There are now two coefficients associated with `SqFtTotLiving`: one for the
    linear term and one for the quadratic term.'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 现在与`SqFtTotLiving`相关联的系数有两个：一个是线性项，另一个是二次项。
- en: The partial residual plot (see [“Partial Residual Plots and Nonlinearity”](#PartialResidualPlots))
    indicates some curvature in the regression equation associated with `SqFtTotLiving`.
    The fitted line more closely matches the smooth (see [“Splines”](#Splines)) of
    the partial residuals as compared to a linear fit (see [Figure 4-10](#PolynomialRegressionPlot)).
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 局部残差图（请参阅 [“局部残差图和非线性”](#PartialResidualPlots)）表明回归方程与 `SqFtTotLiving` 相关的曲率。与线性拟合相比，拟合线更接近局部残差的平滑（请参阅
    [“样条”](#Splines)）而不是图 4-10 中的多项式回归拟合。
- en: The `statsmodels` implementation works only for linear terms. The accompanying
    source code gives an implementation that will work for polynomial regression as
    well.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '`statsmodels` 实现仅适用于线性项。附带的源代码提供了一个对多项式回归也适用的实现。'
- en: '![A polynomial regression fit for the variable SqFtTotLiving (solid line) versus
    a smooth (dashed line)](Images/psd2_0410.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![变量 SqFtTotLiving 的多项式回归拟合（实线）与平滑曲线（虚线）](Images/psd2_0410.png)'
- en: Figure 4-10\. A polynomial regression fit for the variable `SqFtTotLiving` (solid
    line) versus a smooth (dashed line; see the following section about splines)
  id: totrans-379
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-10\. 变量 `SqFtTotLiving` 的多项式回归拟合（实线）与平滑曲线（虚线；关于样条的详细内容请参见下一节）
- en: Splines
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 样条
- en: Polynomial regression captures only a certain amount of curvature in a nonlinear
    relationship. Adding in higher-order terms, such as a cubic quartic polynomial,
    often leads to undesirable “wiggliness” in the regression equation. An alternative,
    and often superior, approach to modeling nonlinear relationships is to use *splines*.
    *Splines* provide a way to smoothly interpolate between fixed points. Splines
    were originally used by draftsmen to draw a smooth curve, particularly in ship
    and aircraft building.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式回归仅捕捉非线性关系中的一定曲率。添加更高阶的项，如四次多项式，通常会导致回归方程中不期望的“波动”。对建模非线性关系的一种替代和通常更优越的方法是使用*样条*。*样条*提供了一种在固定点之间平滑插值的方法。样条最初由制图员用于绘制平滑曲线，特别是在船舶和飞机建造中。
- en: The splines were created by bending a thin piece of wood using weights, referred
    to as “ducks”; see [Figure 4-11](#SplineDucks).
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 样条是通过使用权重弯曲薄木片（称为“鸭子”）制作的；请参阅 [图 4-11](#SplineDucks)。
- en: '![Splines were originally created using bendable wood and ``ducks,'''' and
    were used as a draftsman''s tool to fit curves. Photo courtesy of Bob Perry.](Images/psd2_0411.png)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![样条最初是使用可弯曲的木材和“鸭子”制作的，并用作制图员用于拟合曲线的工具。照片由 Bob Perry 提供。](Images/psd2_0411.png)'
- en: Figure 4-11\. Splines were originally created using bendable wood and “ducks”
    and were used as a draftsman’s tool to fit curves (photo courtesy of Bob Perry)
  id: totrans-384
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-11\. 样条最初是使用可弯曲的木材和“鸭子”制作的，是制图员用来拟合曲线的工具（照片由 Bob Perry 提供）
- en: 'The technical definition of a spline is a series of piecewise continuous polynomials.
    They were first developed during World War II at the US Aberdeen Proving Grounds
    by I. J. Schoenberg, a Romanian mathematician. The polynomial pieces are smoothly
    connected at a series of fixed points in a predictor variable, referred to as
    *knots*. Formulation of splines is much more complicated than polynomial regression;
    statistical software usually handles the details of fitting a spline. The *R*
    package `splines` includes the function `bs` to create a *b-spline* (basis spline)
    term in a regression model. For example, the following adds a b-spline term to
    the house regression model:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 样条的技术定义是一系列分段连续的多项式。它们最早在二战期间由罗马尼亚数学家 I. J. Schoenberg 在美国阿伯丁试验场首次开发。多项式片段在预测变量的一系列固定点上平滑连接，称为*节点*。样条的制定比多项式回归复杂得多；统计软件通常处理样条拟合的详细信息。*R*
    软件包 `splines` 包括函数 `bs`，用于在回归模型中创建*b-样条*（基础样条）项。例如，以下向房屋回归模型添加了一个 b-样条项：
- en: '[PRE56]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Two parameters need to be specified: the degree of the polynomial and the location
    of the knots. In this case, the predictor `SqFtTotLiving` is included in the model
    using a cubic spline (`degree=3`). By default, `bs` places knots at the boundaries;
    in addition, knots were also placed at the lower quartile, the median quartile,
    and the upper quartile.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 需要指定两个参数：多项式的阶数和节点的位置。在本例中，预测变量 `SqFtTotLiving` 使用三次样条（`degree=3`）模型。默认情况下，`bs`
    将节点放置在边界；此外，还在下四分位数、中位数四分位数和上四分位数处放置了节点。
- en: 'The `statsmodels` formula interface supports the use of splines in a similar
    way to *R*. Here, we specify the *b-spline* using `df`, the degrees of freedom.
    This will create `df` – `degree` = 6 – 3 = 3 internal knots with positions calculated
    in the same way as in the *R* code above:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *statsmodels* 的公式接口中，支持类似于 *R* 的样条用法。这里，我们使用 `df` 指定 *b-样条*，其自由度为 `df`。这将创建
    `df` – `degree` = 6 – 3 = 3 个内部节点，其位置与上述 *R* 代码中计算的方式相同：
- en: '[PRE57]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'In contrast to a linear term, for which the coefficient has a direct meaning,
    the coefficients for a spline term are not interpretable. Instead, it is more
    useful to use the visual display to reveal the nature of the spline fit. [Figure 4-12](#SplineRegressionPlot)
    displays the partial residual plot from the regression. In contrast to the polynomial
    model, the spline model more closely matches the smooth, demonstrating the greater
    flexibility of splines. In this case, the line more closely fits the data. Does
    this mean the spline regression is a better model? Not necessarily: it doesn’t
    make economic sense that very small homes (less than 1,000 square feet) would
    have higher value than slightly larger homes. This is possibly an artifact of
    a confounding variable; see [“Confounding Variables”](#ConfoundingVariables).'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性项相比，样条项的系数没有直接含义。因此，使用视觉显示来揭示样条拟合的性质更为有用。图 4-12（#SplineRegressionPlot）显示了回归的部分残差图。与多项式模型相比，样条模型更接近平滑，展示了样条的更大灵活性。在这种情况下，曲线更贴近数据。这是否意味着样条回归是更好的模型？未必：经济上不合理的是，非常小的房屋（小于
    1,000 平方英尺）的价值可能比稍大的房屋高。这可能是混杂变量的结果；请参阅 [“混杂变量”](#ConfoundingVariables)。
- en: '![A spline regression fit for the variable SqFtTotLiving (solid line) compared
    to a smooth (dashed line)](Images/psd2_0412.png)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
  zh: '![变量 SqFtTotLiving 的样条回归拟合（实线）与平滑曲线（虚线）对比](Images/psd2_0412.png)'
- en: Figure 4-12\. A spline regression fit for the variable `SqFtTotLiving` (solid
    line) compared to a smooth (dashed line)
  id: totrans-392
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-12\. 变量 `SqFtTotLiving` 的样条回归拟合（实线）与平滑曲线（虚线）对比
- en: Generalized Additive Models
  id: totrans-393
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 广义可加模型
- en: 'Suppose you suspect a nonlinear relationship between the response and a predictor
    variable, either by a priori knowledge or by examining the regression diagnostics.
    Polynomial terms may not be flexible enough to capture the relationship, and spline
    terms require specifying the knots. *Generalized additive models*, or *GAM*, are
    a flexible modeling technique that can be used to automatically fit a spline regression.
    The `mgcv` package in *R* can be used to fit a GAM model to the housing data:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您怀疑响应与预测变量之间存在非线性关系，可以通过先验知识或检查回归诊断来确定。多项式项可能无法灵活捕捉关系，而样条项则需要指定节点。*广义可加模型*（*Generalized
    additive models*），简称*GAM*，是一种灵活的建模技术，可以用于自动拟合样条回归。在 *R* 中，`mgcv` 包可用于将 GAM 模型拟合到房屋数据中：
- en: '[PRE58]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The term `s(SqFtTotLiving)` tells the `gam` function to find the “best” knots
    for a spline term (see [Figure 4-13](#GAMPlot)).
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 术语 `s(SqFtTotLiving)` 告诉 `gam` 函数查找样条项的“最佳”节点（见 [图 4-13](#GAMPlot)）。
- en: '![A GAM regression fit for the variable SqFtTotLiving (solid line) compared
    to a smooth (dashed line)](Images/psd2_0413.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![变量 SqFtTotLiving 的 GAM 回归拟合（实线）与平滑曲线（虚线）对比](Images/psd2_0413.png)'
- en: Figure 4-13\. A GAM regression fit for the variable `SqFtTotLiving` (solid line)
    compared to a smooth (dashed line)
  id: totrans-398
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-13\. 变量 `SqFtTotLiving` 的 GAM 回归拟合（实线）与平滑曲线（虚线）对比
- en: 'In *Python*, we can use the `pyGAM` package. It provides methods for regression
    and classification. Here, we use `LinearGAM` to create a regression model:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *Python* 中，我们可以使用 `pyGAM` 包。它提供了回归和分类的方法。在这里，我们使用 `LinearGAM` 来创建回归模型：
- en: '[PRE59]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[![1](Images/1.png)](#co_regression_and_prediction_CO4-1)'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_regression_and_prediction_CO4-1)'
- en: The default value for `n_splines` is 20\. This leads to overfitting for larger
    `SqFtTotLiving` values. A value of 12 leads to a more reasonable fit.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_splines` 的默认值为 20\. 对于较大的 `SqFtTotLiving` 值，这会导致过拟合。值为 12 可以得到一个更合理的拟合。'
- en: Further Reading
  id: totrans-403
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: For more on spline models and GAMs, see *The Elements of Statistical Learning*,
    2nd ed., by Trevor Hastie, Robert Tibshirani, and Jerome Friedman (2009), and
    its shorter cousin based on *R*, *An Introduction to Statistical Learning* by
    Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani (2013); both
    are Springer books.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于样条模型和 GAM，请参阅《统计学习的要素》第二版（2009），作者 Trevor Hastie、Robert Tibshirani 和 Jerome
    Friedman，以及其基于 *R* 的较短版本，《统计学习导论》（2013），作者 Gareth James、Daniela Witten、Trevor
    Hastie 和 Robert Tibshirani，两者均为 Springer 出版。
- en: To learn more about using regression models for time series forecasting, see
    *Practical Time Series Forecasting with R* by Galit Shmueli and Kenneth Lichtendahl
    (Axelrod Schnall, 2018).
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欲了解更多关于使用回归模型进行时间序列预测的信息，请参阅Galit Shmueli和Kenneth Lichtendahl的《使用R进行实用时间序列预测》（Axelrod
    Schnall，2018）。
- en: Summary
  id: totrans-406
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'Perhaps no other statistical method has seen greater use over the years than
    regression—the process of establishing a relationship between multiple predictor
    variables and an outcome variable. The fundamental form is linear: each predictor
    variable has a coefficient that describes a linear relationship between the predictor
    and the outcome. More advanced forms of regression, such as polynomial and spline
    regression, permit the relationship to be nonlinear. In classical statistics,
    the emphasis is on finding a good fit to the observed data to explain or describe
    some phenomenon, and the strength of this fit is how traditional *in-sample* metrics
    are used to assess the model. In data science, by contrast, the goal is typically
    to predict values for new data, so metrics based on predictive accuracy for out-of-sample
    data are used. Variable selection methods are used to reduce dimensionality and
    create more compact models.'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 或许没有其他统计方法像回归那样多年来被广泛使用——建立多个预测变量与一个结果变量之间关系的过程。其基本形式为线性：每个预测变量都有一个系数，描述其与结果的线性关系。更高级的回归形式，如多项式和样条回归，允许关系是非线性的。在经典统计中，重点是找到与观察数据良好匹配的模型来解释或描述某一现象，模型的强度是通过传统的*样本内*指标来评估。相反，在数据科学中，目标通常是对新数据进行预测，因此使用基于预测精度的样本外数据指标。变量选择方法用于减少维度并创建更紧凑的模型。
- en: ^([1](ch04.xhtml#idm46522856635400-marker)) This and subsequent sections in
    this chapter © 2020 Datastats, LLC, Peter Bruce, Andrew Bruce, and Peter Gedeck;
    used by permission.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch04.xhtml#idm46522856635400-marker)) 本章及后续章节内容 © 2020 Datastats, LLC，Peter
    Bruce，Andrew Bruce和Peter Gedeck；经许可使用。
- en: ^([2](ch04.xhtml#idm46522856258456-marker)) In Bayesian statistics, the true
    value is assumed to be a random variable with a specified distribution. In the
    Bayesian context, instead of estimates of unknown parameters, there are posterior
    and prior distributions.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch04.xhtml#idm46522856258456-marker)) 在贝叶斯统计中，真实值被假定为具有特定分布的随机变量。在贝叶斯背景下，不是未知参数的估计，而是后验和先验分布。
- en: ^([3](ch04.xhtml#idm46522853979800-marker)) The `-1` argument in the `model.matrix`
    produces one hot encoding representation (by removing the intercept, hence the
    “-”). Otherwise, the default in *R* is to produce a matrix with *P* – 1 columns
    with the first factor level as a reference.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch04.xhtml#idm46522853979800-marker)) `model.matrix` 中的 `-1` 参数产生一种独热编码表示（通过删除截距，因此为“-”）。否则，在
    *R* 中默认生成一个具有 *P* - 1 列的矩阵，其中第一个因子水平作为参考。
- en: ^([4](ch04.xhtml#idm46522853557496-marker)) This is unintuitive, but can be
    explained by the impact of location as a confounding variable; see [“Confounding
    Variables”](#ConfoundingVariables).
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch04.xhtml#idm46522853557496-marker)) 这看起来不直观，但可以解释为位置作为混杂变量的影响；详见[“混杂变量”](#ConfoundingVariables)。
- en: ^([5](ch04.xhtml#idm46522852564136-marker)) There are 80 zip codes in King County,
    several with just a handful of sales. An alternative to directly using zip code
    as a factor variable, `ZipGroup` clusters similar zip codes into a single group.
    See [“Factor Variables with Many Levels”](#FactorVariablesManyLevels) for details.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch04.xhtml#idm46522852564136-marker)) 金县有80个邮政编码，其中几个只有少量销售。`ZipGroup`是将相似的邮政编码聚类到一个组中，作为因子变量的一种替代方案。详见[“具有多个水平的因子变量”](#FactorVariablesManyLevels)。
- en: ^([6](ch04.xhtml#idm46522851692056-marker)) The term *hat-value* comes from
    the notion of the hat matrix in regression. Multiple linear regression can be
    expressed by the formula <math alttext="ModifyingAbove upper Y With caret equals
    upper H upper Y"><mrow><mover accent="true"><mi>Y</mi> <mo>^</mo></mover> <mo>=</mo>
    <mi>H</mi> <mi>Y</mi></mrow></math> where <math alttext="upper H"><mi>H</mi></math>
    is the hat matrix. The hat-values correspond to the diagonal of <math alttext="upper
    H"><mi>H</mi></math> .
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch04.xhtml#idm46522851692056-marker)) 术语*帽值*源于回归中帽矩阵的概念。多元线性回归可以用公式表示为
    <math alttext="ModifyingAbove upper Y With caret equals upper H upper Y"><mrow><mover
    accent="true"><mi>Y</mi> <mo>^</mo></mover> <mo>=</mo> <mi>H</mi> <mi>Y</mi></mrow></math>
    其中 <math alttext="upper H"><mi>H</mi></math> 是帽矩阵。帽值对应于 <math alttext="upper H"><mi>H</mi></math>
    的对角线。
- en: ^([7](ch04.xhtml#idm46522851379304-marker)) The coefficient for `Bathrooms`
    becomes negative, which is unintuitive. Location has not been taken into account,
    and the zip code 98105 contains areas of disparate types of homes. See [“Confounding
    Variables”](#ConfoundingVariables) for a discussion of confounding variables.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch04.xhtml#idm46522851379304-marker)) `Bathrooms` 的系数变为负数，这是不直观的。没有考虑到地理位置，而且邮政编码98105包含了不同类型的住宅区域。参见[“混杂变量”](#ConfoundingVariables)讨论混杂变量。
