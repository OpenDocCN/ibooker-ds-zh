["```py\ntable = [\n    [0,'Michael','Shearer',1970],\n    [1,'Michael','Shearer',1970],\n    [2,'Mike','Shearer',1970],\n    [3,'Michael','Shearer',1971],\n    [4,'Michelle','Shearer',1971],\n    [5,'Mike','Sheare',1971]]\n\nclmns = ['ID','Firstname','Lastname','Year']\ndf_ms = pd.DataFrame(table, columns = clmns)\n\ndf_ms['cluster'] =\n   df_ms.groupby(['Firstname','Lastname']).ngroup()\n```", "```py\nimport itertools\n\ndf_combs = pd.DataFrame(list(itertools.combinations(table,2)),\n   columns=['A','B'])\n```", "```py\nclmnsA = pd.MultiIndex.from_arrays([['A']*len(clmns), clmns])\nclmnsB = pd.MultiIndex.from_arrays([['B']*len(clmns), clmns])\n```", "```py\ndf_edges = pd.concat(\n   [pd.DataFrame(df_combs['A'].values.tolist(),columns = clmnsA),\n    pd.DataFrame(df_combs['B'].values.tolist(),columns = clmnsB)],\n   axis=1)\n```", "```py\nimport jellyfish as jf\n\ndef is_match(row):\n   firstname_match = jf.jaro_winkler_similarity(row['A'] \n      ['Firstname'],row['B']['Firstname']) > 0.9\n   lastname_match = jf.jaro_winkler_similarity(row['A']\n      ['Lastname'], row['B']['Lastname']) > 0.9\n   return firstname_match and lastname_match\n\ndf_edges['Match'] = df_edges.apply(is_match, axis=1)\n\ndf_edges\n```", "```py\ndf_psc = pd.read_csv('psc_raw.csv',dtype=\n   {'data.name_elements.surname':'string',\n    'data.name_elements.forename':'string',\n    'data.name_elements.middle_name':'string',\n    'data.name_elements.title':'string',\n    'data.nationality':'string'})\n```", "```py\ndf_psc = df_psc.dropna(subset\n   ['data.date_of_birth.year','data.date_of_birth.month'])\ndf_psc['Year'] = df_psc['data.date_of_birth.year'].astype('int64')\ndf_psc['Month'] =\n   df_psc['data.date_of_birth.month'].astype('int64')\n\ndf_psc = df_psc.rename(columns=\n   {\"data.name_elements.surname\" : \"Lastname\",\n    \"data.name_elements.forename\" : \"Firstname\",\n    \"data.name_elements.middle_name\" : \"Middlename\",\n    \"data.name_elements.title\" : \"Title\",\n    \"data.nationality\" : \"Nationality\"})\n\ndf_psc = df_psc[['Lastname','Middlename','Firstname',\n   'company_number','Year','Month','Title','Nationality']]\ndf_psc['unique_id'] = df_psc.index\n```", "```py\nfrom splink.duckdb.linker import DuckDBLinker\nfrom splink.duckdb import comparison_library as cl\n\nsettings = {\n   \"link_type\": \"dedupe_only\",\n   \"blocking_rules_to_generate_predictions\":\n      [ \"l.Year = r.Year and l.Month = r.Month and\n          l.Lastname = r.Lastname\" ],\n   \"comparisons\":\n      [ cl.jaro_winkler_at_thresholds(\"Firstname\", [0.9]),\n        cl.jaro_winkler_at_thresholds(\"Middlename\", [0.9]),\n        cl.exact_match(\"Lastname\"),\n        cl.exact_match(\"Title\"),\n        cl.exact_match(\"Nationality\"),\n        cl.exact_match(\"Month\"),\n        cl.exact_match(\"Year\", term_frequency_adjustments=True), ],\n   \"retain_matching_columns\": True,\n   \"retain_intermediate_calculation_columns\": True,\n   \"max_iterations\": 10,\n   \"em_convergence\": 0.01,\n   \"additional_columns_to_retain\": [\"company_number\"],\n   }\nlinker = DuckDBLinker(df_psc, settings)\n```", "```py\nlinker.profile_columns([\"Firstname\",\"Middlename\",\"Lastname\",\n   \"Title\",\"Nationality\",\"Month\",\"Year\"], top_n=10, bottom_n=5)\n```", "```py\nlinker.count_num_comparisons_from_blocking_rule(\n   \"l.Lastname = r.Lastname and\n    l.Month = r.Month and\n    l.Title = r.Title and\n    l.Nationality = r.Nationality\")\n```", "```py\nlinker.estimate_parameters_using_expectation_maximisation(\n   \"l.Lastname = r.Lastname and l.Middlename = r.Middlename\",\n      fix_u_probabilities=False)\n\nlinker.estimate_parameters_using_expectation_maximisation(\n   \"l.Firstname = r.Firstname and l.Month = r.Month and\n    l.Year = r.Year and l.Title = r.Title and\n    l.Nationality = r.Nationality\",\n      fix_u_probabilities=False)\n```", "```py\nlinker.load_settings(\"Chapter7_Splink_Settings.json\")\n```", "```py\ndf_predict = linker.predict(threshold_match_probability=0.9)\n```", "```py\nclusters = linker.cluster_pairwise_predictions_at_threshold(\n   df_predict, threshold_match_probability=0.9)\ndf_clusters = clusters.as_pandas_dataframe()\n\ndf_clusters.head(n=5)\n```", "```py\ndf_cgroup =\n   df_clusters.groupby(['cluster_id'], sort=False)\n      [['company_number','Firstname','Title','Nationality','Lastname']]\n         .agg(lambda x: list(set(x)))\n            .reset_index() \n```", "```py\ndf_cselect = df_cgroup[\n   (df_cgroup['Firstname'].apply(len) > 1) &\n   (df_cgroup['Title'].apply(len) > 1) &\n   (df_cgroup['Nationality'].apply(len) > 1) &\n   (df_cgroup['company_number'].apply(len) == 6)]\n\ndf_cselect.head(n=5)\n```", "```py\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nmybins =[1,2,10,100,1000,10000]\nfig, ax = plt.subplots()\ncounts, bins, patches = ax.hist(df_cgroup['unique_id'].apply(len),\n   bins=mybins )\nbin_centers = 0.5 * np.diff(bins) + bins[:-1]\n\nfor label, x in zip(['1','2-10','10-100','100-1000','1000+'],\n   bin_centers):\n   ax.annotate(label, xy=(x, 0), xycoords=('data', 'axes fraction'),\n               xytext=(0,-10), textcoords='offset points', va='top',\n               ha='right')\nax.tick_params(labelbottom=False)\nax.xaxis.set_label_coords(0,-0.1)\nax.xaxis.set_tick_params(which='minor', bottom=False)\n\nax.set_xlabel('Number of controlled companies')\nax.set_ylabel('Count')\nax.set_title('Distribution of significant company control')\nax.set_yscale('log')\nax.set_xscale('log')\n\nfig.tight_layout()\nplt.show()\n```", "```py\nlinker.cluster_studio_dashboard(df_predict, clusters,\n   \"Chapter7_cluster_studio.html\",\n   cluster_ids = df_cselect['cluster_id'].to_list(), overwrite=True)\n\nfrom IPython.display import IFrame\nIFrame( src=\"Chapter7_cluster_studio.html\", width=\"100%\",\n   height=1200) \n```"]