- en: Chapter 8\. Probabilistic Generative Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*AI ties up all the mathematics that I know together, and I have been getting
    to know mathematics for years.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If machines are ever to be endowed with an understanding of the world around
    them, and an ability to recreate it, like we do when we imagine, dream, draw,
    create songs, movies, or write books, then generative models are one significant
    step in that direction. We need to get these models right if we are ever going
    to achieve general artificial intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Generative models are built on the assumption that we can only interpret input
    data correctly if our model has learned the underlying statistical structure of
    this data. This is loosely analogous to our dreaming process, which points to
    the possibility that our brain has learned a model that is able to virtually recreate
    our environment.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we still have the mathematical structure of training function,
    loss function, and optimization presented throughout the book. However, unlike
    in the first few chapters, we aim to learn probability distributions, instead
    of deterministic functions. The overarching theme is that there is training data,
    and we want to come up with a mathematical model that generates new data similar
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two quantities of interest:'
  prefs: []
  type: TYPE_NORMAL
- en: The true (and unknown) joint probability distribution of the features of the
    input data <math alttext="p Subscript d a t a Baseline left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    .
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The model joint probability distribution of the features of the data along
    with the parameters of the model: <math alttext="p Subscript m o d e l Baseline
    left-parenthesis ModifyingAbove x With right-arrow semicolon ModifyingAbove theta
    With right-arrow right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ideally, we want these two as close as possible. In practice, we settle for
    parameter values <math alttext="ModifyingAbove theta With right-arrow"><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover></math> that allow <math alttext="p
    Subscript m o d e l Baseline left-parenthesis ModifyingAbove x With right-arrow
    semicolon ModifyingAbove theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> to work well for our particular
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout the chapter, we make use of three rules for probability distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: The product rule that decomposes the multivariable joint probability distribution
    into a product of single variable conditional probability distributions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bayes rule that allows us to flip between variables seemlessly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Independence or conditional independence assumptions on the features or on latent
    (hidden) variables that allow us to simplify the product of single variable conditional
    probabilities even further.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In previous chapters we were minimizing the *loss function*. In this chapter
    the analogous function is the *log likelihood function*, and the optimization
    process always attempts to *maximize* this log likelihood (careful, we are not
    minimizing a loss function, we are maximizing an objective function instead).
    More on this soon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we dive in, let’s make a note that puts our previous deterministic machine
    learning models into probability language: Our previous models learned a training
    function that mapped the features of the input data <math alttext="ModifyingAbove
    x With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    to an output <math alttext="y"><mi>y</mi></math> (target or label), or <math alttext="f
    left-parenthesis ModifyingAbove x With right-arrow semicolon ModifyingAbove theta
    With right-arrow right-parenthesis equals y"><mrow><mi>f</mi> <mo>(</mo> <mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo> <mo>=</mo> <mi>y</mi></mrow></math> . When our goal
    was classification, *f* returned the label *y* that had the highest probability.
    That is, a classifier learns a direct map from input data <math alttext="ModifyingAbove
    x With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    to class labels *y*, in other words, they model the posterior probability <math
    alttext="p left-parenthesis y vertical-bar ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <mi>y</mi> <mo>|</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow></math> directly. We will elaborate on this later in the chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: What Are Generative Models Useful For?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generative models have made it possible to blurr the lines between true and
    computer generated data. They have been improving and are achieving impressive
    successes: Machine generated images, including those of humans, are increasingly
    more realistic. It is hard to tell whether an image of a model in the fashion
    industry is that of a real person or the output of a generative machine learnig
    model.'
  prefs: []
  type: TYPE_NORMAL
- en: The goal of a generative model is to use a machine to generate novel data, such
    as audio waveforms containing speech, images, videos, or natural language text.
    Generative models sample data from a learned probability distribution, where the
    samples mimic reality as much as possible. The assumption here is that there is
    some unknown probability distribution underlying the real life data that we want
    to mimic (otherwise our whole reality will be some random chaotic noise, lacking
    any coherence or structure), and the model’s goal is to learn an approximation
    of this probability distribution using the training data.
  prefs: []
  type: TYPE_NORMAL
- en: After collecting a large amount of data from a specific domain, we train a generative
    model to generate data similar to the collected data. The collected data can be
    millions of images or videos, thousands of audio recordings, or entire corpuses
    of natural language.
  prefs: []
  type: TYPE_NORMAL
- en: Generative models are useful for many applications, including data augmentation
    when data is scarce and more of it is needed, imputing missing values for higher
    resolution images, simulating new data for reinforcement learning, or for semisupervised
    learning when only few labels are available. Another application is image-to-image
    translation, such as converting aerial images into maps or converting hand drawn
    sketches to images. More applications include image denoising, inpainting, super-resolution,
    images editing such as making smiles wider, cheeckbones higher, faces slimmer
    and others.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, generative models are built to generate more than one acceptable output
    by drawing multiple samples from the desired probability distribution. This is
    different than our deterministic models that average over the output with different
    features during training using a mean squared error loss function or some other
    averaging loss function. The downside here is that a generative model can draw
    some bad samples as well.
  prefs: []
  type: TYPE_NORMAL
- en: One type of generative models, namely [*generative adversarial networks*](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)
    (invented in 2014 by Ian Goodfellow *et al*), are incredibly promising and have
    a wide range of applications, from augmenting data sets to completing masked human
    faces to astrophysics and high energy physics, such as simulating data sets similar
    to those produced at the CERN Large Hardon Collider, or simulating distribution
    of dark matter and predicting gravitational lensing. Generative adversarial models
    sets up two neural networks that compete against each other in a zero sum game
    (think game theory in mathematics), until the machine itself cannot tell the difference
    between a real image and a computer generated one. This is why their outputs seem
    very close to reality.
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous chapter, which was heavily geared towards natural language processing,
    flirted with generative models without explicitly pointing them out. Most applications
    of natural language processing, which are not simple classification models (spam
    or not spam, positive sentiment or negative sentiment, part of speech tagging),
    include language generation. Such examples are: Auto-complete on our smart phones
    or email, machine translation, text summarization, chatbots, and image captioning.'
  prefs: []
  type: TYPE_NORMAL
- en: The Typical Mathematics Of Generative Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The way generative models perceive and represent the world is through probability
    distributions. That is, a color image is one sample from the joint probability
    distribution of pixels that together form a meaningful image (try to count the
    dimensions of such a joint probability distribution with all the red, green and
    blue channels included), an audio wave is one sample from the joint probability
    distribution of audio signals that together make up meaningful sounds (these are
    also extremely high dimensional), and a sentence is one sample from the joint
    probability distribution of words or characters that together represent coherent
    sentences.
  prefs: []
  type: TYPE_NORMAL
- en: 'The glaring question is then: How do we compute these amazingly representative
    joint probability distributions, that are able to capture the complexity of the
    world around us, but sadly happen to be extremely high dimensional?'
  prefs: []
  type: TYPE_NORMAL
- en: 'The machine learning answer is predictable at this point: Start with an easy
    probability distribution that we know of, such as the Gaussian distribution, then
    find a way to mold it into another distribution that well approximates the emperical
    distribution of the data at hand. But how do we mold one distribution into another?
    We can apply a deterministic function to its probability density. So we must understand
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'How do we apply a deterministic function to a probability distribution, and
    what is the probability distribution of the resulting random variable? We use
    the following transformation formula:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign p Subscript x Baseline left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis equals p Subscript z Baseline left-parenthesis
    g Superscript negative 1 Baseline left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis right-parenthesis StartAbsoluteValue det left-parenthesis StartFraction
    normal partial-differential g Superscript negative 1 Baseline ModifyingAbove x
    With right-arrow Over normal partial-differential ModifyingAbove x With right-arrow
    EndFraction right-parenthesis EndAbsoluteValue dollar-sign"><mrow><msub><mi>p</mi>
    <mi>x</mi></msub> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <msub><mi>p</mi> <mi>z</mi></msub> <mrow><mo>(</mo>
    <msup><mi>g</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mrow><mo>(</mo> <mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mrow><mo>|</mo> <mo form="prefix" movablelimits="true">det</mo> <mrow><mo>(</mo>
    <mfrac><mrow><mi>∂</mi><msup><mi>g</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover></mrow> <mrow><mi>∂</mi><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></mfrac> <mo>)</mo></mrow> <mo>|</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This is very well documented in many probability books and we will extract what
    we need from there shortly. . What is the correct function that we must apply?
    One way is to train our model to *learn* it. We now know that neural networks
    have the capacity to represent a wide range of functions, so we can pass the simple
    probability distribution that we start with through a neural network (the neural
    network would be the formula of the deterministic function that we are looking
    for), then we learn the network’s parameters by minimizing the error between the
    emperical distribution of the given data, and the distribution output by the network.
  prefs: []
  type: TYPE_NORMAL
- en: How do we measure errors between probability distributions? Probability theory
    provides us with some measures of how two probability distributions diverge from
    each other, such as the Kullback–Leibler (KL) divergence. This is also related
    to cross-entropy from information theory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do all generative models work this way? Yes and no. *Yes* in the sense that
    they are all trying to learn the joint probability distribution that presumably
    generated the training data. In other words, generative models attempt to learn
    the formula and the parameters of a joint probability distribution that maximizes
    the likelihood of the training data (or maximize the probability that the model
    assigns to the training data). *No* in the sense that we only outlined an *explicit*
    way to approximate our desired joint probability distribution. This is one school
    of thought. In general, a model that defines an explicit and tractable probability
    density function allows us to operate directly on the log-likelihood of the training
    data, compute its gradient, and apply available optimization algorithms to search
    for the maximum. There are other models that provide an explicit but intractable
    probability density function, in which case we must use approximations to maximize
    the likelihood. How do we solve an optimization problem *approximately*? We can
    either use a deterministic approximation, relying on *variational methods* (variational
    autoencoder models), or use a stochastic approximation, relying on Markov chain
    Monte Carlo methods. Finally, there are *implicit* ways to approximate our desired
    joint probability distribution. Implicit models learn to sample from the unknown
    distribution without ever explicitly defining a formula for it. Generative adversarial
    networks fall into this category.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Nowadays, the three most popular approaches to generative modeling are:'
  prefs: []
  type: TYPE_NORMAL
- en: Generative adversarial networks, which are implicit density models;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variational models which provide an explicit but intractable probability density
    function. We approximate the solution of the optimization problem within the framework
    of probabilistic graphical models where we maximize a lower bound on the log likelihood
    of the data, since immediately maximizing the log likelihood of the data is intractable;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Fully visible belief networks*, which provide explicit and tractable probability
    density functions, such as [Pixel Convolutional Neural Networks (PixelCNN) 2016](https://arxiv.org/pdf/1606.05328.pdf)
    and [WaveNet (2016)](https://arxiv.org/abs/1609.03499). These models learn the
    joint probability distribution by decomposing it into a product of one dimensional
    probability distributions for each individual dimension, conditioned on those
    that preceded it, and learning each of these distributions one at a time. This
    decomposition is thanks to the product rule or chain rule for probabilities. For
    example, PixelCNN trains a network that learns the conditional probability distribution
    of every individual pixel in an image given previous pixels (to the left and to
    the top of it), and WaveNet trains a network that learns the conditional probability
    distribution of every individual audio signal in a sound wave conditioned on those
    that preceded it. The drawbacks here are that these models generate the samples
    only one entry at a time, and they disallow parallelization. This slows down the
    generation process considerably. For example, it takes WaveNet two minutes of
    computation time to generate one second of audio, so we cannot use it for live
    back and forth conversations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are other generative models that fall into the above categories but are
    less popular, due to expensive computational requirements or difficulties in selecting
    the density function and/or its transformations. These include models that require
    a change of variables, such as nonlinear independent component estimation (explicit
    and tractable density model), Boltzmann machine models (explicit and intractable
    density model, with a stochastic Markov chain approximation to the solution of
    the maximization problem), and generative stochastic network models (implicit
    density model again depending on a Markov chain to arrive at its approximate maximum
    likelihood). We survey these models briefly towards the end of this chapter. In
    practice and away from mathematical theory and analysis, Markov chain approaches
    are out of favor due their computational cost and relunctance to converge rapidly.
  prefs: []
  type: TYPE_NORMAL
- en: Shifting Our Brain From Deterministic Thinking To Probabilistic Thinking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we are slowly shifting our brain from deterministic thinking
    to probabilistic thinking. So far in this book, we have only used determinstic
    functions to make our predictions. The training functions were linear combinations
    of data features, sometimes composed with nonlinear activators, the loss functions
    were deterministic dicriminators between the true values and the predicted ones,
    and the optimization methods were based on deterministic gradient descent methods.
    Stochasticity, or randomness, was only introduced when we needed to make the computations
    of the deterministic components of our model less expensive, such as stochastic
    gradient descent or stochastic singular value decomposition, when we split our
    data sets into training, validation, and test subsets, when we selected our minibatches,
    when we traversed some hyper-parameter spaces, or when we passed the scores of
    data samples into the softmax function, which is a deterministic function, and
    interpreted the resulting values as probabilities. In all of these settings, stochasticity
    and the associated probability distributions related only to specific components
    of the model, serving only as a means to an end: Enabling the practical implementation
    and computation of the deterministic model. They never constituted a model’s core
    makeup.'
  prefs: []
  type: TYPE_NORMAL
- en: Generative models are different than the models that we have seen in previous
    chapters in the sense that they are probabilistic at their core. Nevertheless,
    we still have the training, loss, and optimization structure, except that now
    the model learns a probability distribution (explicitly or implicitly) as opposed
    to learning a deterministic function. Our loss function then measures the error
    between the true and the predicted probability distributions (at least for the
    explicit density models), so we must understand how to define and compute some
    sort of error function between probabilities instead of deterministic values.
    We must also learn how to optimize and take derivatives in this probabilistic
    setting.
  prefs: []
  type: TYPE_NORMAL
- en: 'In mathematics, it is a much easier problem to evaluate a given function (forward
    problem) than to find its inverse (inverse problem), let alone when we only have
    access to few observations of the function values, such as our data samples. In
    our probabilistic setting, the forward problem looks like: Given a certain probability
    distribution, sample some data. The inverse problem is the one we care for: Given
    this finite number of realizations (data samples) of a probability distribution
    that we do not know, find the probability distribution that most likely generated
    them. One first difficulty that comes to our mind is the issue of uniqueness:
    There could be more than one distribution that fit our data. Moreover, the inverse
    problem is usually much harder because in essence we have to act backwards and
    undo the process that the forward function followed to arrive at the given observations.
    The issue is that most processes cannot be undone, and this is somehow bigger
    than us, embedded in the laws of nature: The universe tends to increase entropy.
    On top of the hardship inherent to solving inverse problems, the probability distributions
    that we usually try to estimate for AI applications are high dimensional, with
    many variables, and we are not even sure that our probabilistic model has accounted
    for all the variables (but that is problematic for deterministic models as well).
    These difficulties should not deter us: Representing and manipulating high dimensional
    probability distributions is important for many math, science, finance, engineering
    and other applications. We must dive into generative models.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout the rest of this chapter, we will differentiate the case when our
    estimated probability distribution is given with an explicit formula, and when
    we do not have a formula but instead we numerically generate new data samples
    from an implicit distribution. Note that in the previous chapters, with all of
    our deterministic models, we always had explicit formulas for our training functions,
    including the ones given by decision trees, fully connected neural networks, and
    convolutional neural networks. Back then, once we estimated these deterministic
    functions from the data, we could answer questions like: What is the predicted
    value of the target variable? In probabilistic models, we answer a different question:
    What is the probability that the target variable assumes a certain value, or lies
    in a certain interval? The difference is that we do not know how our model combined
    the variables to produce our result, as in the deterministic case. What we try
    to estimate in probabilistic models is the probability that the model’s variables
    occur together with the target variable (their joint probability), ideally for
    all ranges of all variables. This will give us the probability distribution of
    the target variable, without having to explicitly formulate how the model’s variables
    interact to produce this result. This purely depends on observing the data.'
  prefs: []
  type: TYPE_NORMAL
- en: Maximum Likelihood Estimation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Many generative models either directly or indirectly rely on the *maximum likelihood
    principle*. For probabilistic models, the goal is to learn a probability distribution
    that approximates the true probability distribution of the observed data. One
    way to do this is to specify an explicit probability distribution <math alttext="p
    Subscript m o d e l Baseline left-parenthesis ModifyingAbove x With right-arrow
    semicolon ModifyingAbove theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> with some unknown parameters
    <math alttext="ModifyingAbove theta With right-arrow"><mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover></math> , then solve for the parameters <math alttext="ModifyingAbove
    theta With right-arrow"><mover accent="true"><mi>θ</mi> <mo>→</mo></mover></math>
    that make the training dataset as likely to be observed as possible. That is,
    we need to find the <math alttext="ModifyingAbove theta With right-arrow"><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover></math> that *maximizes the likelihood*
    of the training data, assigning a high probability for these samples. If there
    are *m* training data points, we assume that they are sampled independently, so
    that the probability of observing them together is just the product of the probabilities
    of all the individual samples. So we have:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ModifyingAbove theta With right-arrow Subscript o
    p t i m a l Baseline equals arg max Underscript ModifyingAbove theta With right-arrow
    Endscripts p Subscript m o d e l Baseline left-parenthesis ModifyingAbove x With
    right-arrow Superscript 1 Baseline semicolon ModifyingAbove theta With right-arrow
    right-parenthesis p Subscript m o d e l Baseline left-parenthesis ModifyingAbove
    x With right-arrow squared semicolon ModifyingAbove theta With right-arrow right-parenthesis
    ellipsis p Subscript m o d e l Baseline left-parenthesis ModifyingAbove x With
    right-arrow Superscript m Baseline semicolon ModifyingAbove theta With right-arrow
    right-parenthesis dollar-sign"><mrow><msub><mover accent="true"><mi>θ</mi> <mo>→</mo></mover>
    <mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>l</mi></mrow></msub>
    <mo>=</mo> <mo form="prefix">arg</mo> <msub><mo form="prefix" movablelimits="true">max</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover></msub> <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mn>1</mn></msup>
    <mo>;</mo> <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mn>2</mn></msup>
    <mo>;</mo> <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>⋯</mo> <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mi>m</mi></msup>
    <mo>;</mo> <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that each probability is a number between zero and one. If we multiply
    all of these probabilities together, we would obtain numbers extremely small in
    magnitude, which introduces numerical instabilities and we run the risk of underflow
    (when the machine stores a very small number as zero, essentially removing all
    significant digits). The *log* function always solves this problem, transforming
    all numbers whose magnitude are extremely large or extremely small back to the
    reasonable magnitude realm. The good news is that the *log* transformation for
    our probabilities does not affect the values of the optimal <math alttext="ModifyingAbove
    theta With right-arrow"><mover accent="true"><mi>θ</mi> <mo>→</mo></mover></math>
    , since the *log* function is an increasing function. That is, if <math alttext="f
    left-parenthesis ModifyingAbove theta With right-arrow Subscript o p t i m a l
    Baseline right-parenthesis greater-than-or-equal-to f left-parenthesis ModifyingAbove
    theta With right-arrow right-parenthesis"><mrow><mi>f</mi> <mrow><mo>(</mo> <msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>l</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>≥</mo> <mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> for all <math alttext="ModifyingAbove
    theta With right-arrow"><mover accent="true"><mi>θ</mi> <mo>→</mo></mover></math>
    , then <math alttext="log left-parenthesis f left-parenthesis ModifyingAbove theta
    With right-arrow Subscript o p t i m a l Baseline right-parenthesis right-parenthesis
    greater-than-or-equal-to log left-parenthesis f left-parenthesis ModifyingAbove
    theta With right-arrow right-parenthesis right-parenthesis"><mrow><mo form="prefix">log</mo>
    <mrow><mo>(</mo> <mi>f</mi> <mrow><mo>(</mo> <msub><mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>l</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>≥</mo> <mo form="prefix">log</mo> <mrow><mo>(</mo>
    <mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>θ</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math> for all <math alttext="ModifyingAbove
    theta With right-arrow"><mover accent="true"><mi>θ</mi> <mo>→</mo></mover></math>
    as well. Composing with increasing functions does not change the inequality sign.
    The point is that the maximum likelihood solution becomes equivalent to the maximum
    log likelhood solution. Now recall that the *log* function transforms products
    to sums, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ModifyingAbove theta With right-arrow Subscript o
    p t i m a l Baseline equals arg max Underscript ModifyingAbove theta With right-arrow
    Endscripts log left-parenthesis p Subscript m o d e l Baseline left-parenthesis
    ModifyingAbove x With right-arrow Superscript 1 Baseline semicolon ModifyingAbove
    theta With right-arrow right-parenthesis right-parenthesis plus log left-parenthesis
    p Subscript m o d e l Baseline left-parenthesis ModifyingAbove x With right-arrow
    squared semicolon ModifyingAbove theta With right-arrow right-parenthesis right-parenthesis
    plus ellipsis plus log left-parenthesis p Subscript m o d e l Baseline left-parenthesis
    ModifyingAbove x With right-arrow Superscript m Baseline semicolon ModifyingAbove
    theta With right-arrow right-parenthesis right-parenthesis dollar-sign"><mrow><msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>l</mi></mrow></msub>
    <mo>=</mo> <mo form="prefix">arg</mo> <msub><mo form="prefix" movablelimits="true">max</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover></msub> <mo form="prefix">log</mo>
    <mrow><mo>(</mo> <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mn>1</mn></msup>
    <mo>;</mo> <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>+</mo> <mo form="prefix">log</mo> <mrow><mo>(</mo> <msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mn>2</mn></msup> <mo>;</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>+</mo> <mo>⋯</mo> <mo>+</mo> <mo form="prefix">log</mo> <mrow><mo>(</mo> <msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mi>m</mi></msup> <mo>;</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the above expression wants to increase each of <math alttext="p Subscript
    m o d e l Baseline left-parenthesis ModifyingAbove x With right-arrow comma ModifyingAbove
    theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    for each data sample. That is, it prefers the values of <math alttext="ModifyingAbove
    theta With right-arrow"><mover accent="true"><mi>θ</mi> <mo>→</mo></mover></math>
    *push up* the graph of <math alttext="p Subscript m o d e l Baseline left-parenthesis
    ModifyingAbove x With right-arrow comma ModifyingAbove theta With right-arrow
    right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    above each data point <math alttext="ModifyingAbove x With right-arrow Superscript
    i"><msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mi>i</mi></msup></math>
    . However, we cannot push up indefinitely: There must be a downward compensation
    since the hyper-area of the region under the graph has to add up to one, knowing
    that <math alttext="p Subscript m o d e l Baseline left-parenthesis ModifyingAbove
    x With right-arrow comma ModifyingAbove theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> is a probability distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can reformulate the above expression in terms of expectation and conditional
    probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ModifyingAbove theta With right-arrow Subscript o
    p t i m a l Baseline equals arg max Underscript ModifyingAbove theta With right-arrow
    Endscripts double-struck upper E Subscript x tilde p Sub Subscript d a t a Baseline
    log left-parenthesis p Subscript m o d e l Baseline left-parenthesis ModifyingAbove
    x With right-arrow vertical-bar ModifyingAbove theta With right-arrow right-parenthesis
    right-parenthesis dollar-sign"><mrow><msub><mover accent="true"><mi>θ</mi> <mo>→</mo></mover>
    <mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>l</mi></mrow></msub>
    <mo>=</mo> <mo form="prefix">arg</mo> <msub><mo form="prefix" movablelimits="true">max</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover></msub> <msub><mi>𝔼</mi> <mrow><mi>x</mi><mo>∼</mo><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></mrow></msub> <mo
    form="prefix">log</mo> <mrow><mo>(</mo> <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>|</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The deterministic models that we discussed in the previous chapters find the
    models’ parameters (or weights) by minimizing a loss function that measures the
    error between the model’s predictions and the true values provided by the data
    labels, or in other words, between <math alttext="y Subscript m o d e l"><msub><mi>y</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    and <math alttext="y Subscript d a t a"><msub><mi>y</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    . In this chapter, we care to find the parameters that maximize the log-likelihood
    of the data. It would be nice if there is a formulation of log-likelihood maximization
    that is analogous to minimizing a quantity that measures an error between the
    probability distributions <math alttext="p Subscript m o d e l"><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    and <math alttext="p Subscript d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    , so that the analogy between this chapter and the previous chapters is obvious.
    Luckily, there is. The maximum likelihood estimation is the same as minimizing
    the [*Kullback Leibler (KL) divergence*](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)
    between the probability distribution that generated the data and the model’s probability
    distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ModifyingAbove theta With right-arrow Subscript o
    p t i m a l Baseline equals arg min Underscript ModifyingAbove theta With right-arrow
    Endscripts upper D i v e r g e n c e Subscript upper K upper L Baseline left-parenthesis
    p Subscript d a t a Baseline left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis StartAbsoluteValue EndAbsoluteValue p Subscript m o d e l Baseline
    left-parenthesis ModifyingAbove x With right-arrow semicolon ModifyingAbove theta
    With right-arrow right-parenthesis right-parenthesis dollar-sign"><mrow><msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>l</mi></mrow></msub>
    <mo>=</mo> <mo form="prefix">arg</mo> <msub><mo form="prefix" movablelimits="true">min</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover></msub> <mi>D</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>r</mi> <mi>g</mi> <mi>e</mi> <mi>n</mi> <mi>c</mi> <msub><mi>e</mi>
    <mrow><mi>K</mi><mi>L</mi></mrow></msub> <mrow><mo>(</mo></mrow> <msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mrow><mo>|</mo>
    <mo>|</mo></mrow> <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mrow><mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If <math alttext="p Subscript d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    happens to be a member of the family of distributions <math alttext="p Subscript
    m o d e l Baseline left-parenthesis ModifyingAbove x With right-arrow semicolon
    ModifyingAbove theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> and if we were able to perform
    the minimization precisely, then the we would recover the exact distribution that
    generated the data, namely <math alttext="p Subscript d a t a"><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math> . However,
    in practice, we do not have access to the data generating distribution, in fact
    it is the distribution that we are trying to approximate. We only have access
    to *m* samples from <math alttext="p Subscript d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    . These samples define the emperical distribution <math alttext="ModifyingAbove
    p With caret Subscript d a t a"><msub><mover accent="true"><mi>p</mi> <mo>^</mo></mover>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math> that places
    mass only on exactly these *m* samples. Now maximizing the log-likelihood of the
    training set is exactly equivalent to minimizing the KL divergence between <math
    alttext="ModifyingAbove p With caret Subscript d a t a"><msub><mover accent="true"><mi>p</mi>
    <mo>^</mo></mover> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    and <math alttext="p Subscript m o d e l Baseline left-parenthesis ModifyingAbove
    x With right-arrow semicolon ModifyingAbove theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> :'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ModifyingAbove theta With right-arrow Subscript o
    p t i m a l Baseline equals arg min Underscript ModifyingAbove theta With right-arrow
    Endscripts upper D i v e r g e n c e Subscript upper K upper L Baseline left-parenthesis
    ModifyingAbove p With caret Subscript d a t a Baseline left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis StartAbsoluteValue EndAbsoluteValue p Subscript
    m o d e l Baseline left-parenthesis ModifyingAbove x With right-arrow semicolon
    ModifyingAbove theta With right-arrow right-parenthesis right-parenthesis dollar-sign"><mrow><msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mrow><mi>o</mi><mi>p</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>l</mi></mrow></msub>
    <mo>=</mo> <mo form="prefix">arg</mo> <msub><mo form="prefix" movablelimits="true">min</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover></msub> <mi>D</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>r</mi> <mi>g</mi> <mi>e</mi> <mi>n</mi> <mi>c</mi> <msub><mi>e</mi>
    <mrow><mi>K</mi><mi>L</mi></mrow></msub> <mrow><mo>(</mo></mrow> <msub><mover
    accent="true"><mi>p</mi> <mo>^</mo></mover> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mrow><mo>|</mo> <mo>|</mo></mrow> <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mrow><mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point we might be confused between three optimization problems that
    are in fact mathematically equivalent, they just happen to come from different
    subdisciplines and subcultures of mathematics, statistics, natural sciences, and
    computer science:'
  prefs: []
  type: TYPE_NORMAL
- en: Maximizing the log-likelihood of the training data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Minimizing the KL divergence between the emperical distribution of the training
    data and the model’s distribution
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Minimizing the cross entropy loss function between the training data labels
    and the model outputs, when we are classifying into multiple classes using composition
    with the sotmax function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Do not be confused: The parameters that minimize the KL divergence are the
    same as the parameters that minimize the cross entropy and the negative log likelihood.'
  prefs: []
  type: TYPE_NORMAL
- en: Explicit And Implicit Density Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The goal of maximum log-likelihood estimation (or minimum KL-divergence) is
    to find a probability distribution <math alttext="p Subscript m o d e l Baseline
    left-parenthesis ModifyingAbove x With right-arrow semicolon ModifyingAbove theta
    With right-arrow right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    that best explains the observed data. Generative models use this learned <math
    alttext="p Subscript m o d e l Baseline left-parenthesis ModifyingAbove x With
    right-arrow semicolon ModifyingAbove theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> to generate new data. There
    are two approaches here, one explicit and the other implicit:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Explicit density models**: Define the formula for the probability distribution
    *explicitly* in terms of <math alttext="ModifyingAbove x With right-arrow"><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></math> and <math alttext="ModifyingAbove
    theta With right-arrow"><mover accent="true"><mi>θ</mi> <mo>→</mo></mover></math>
    , then find the values of <math alttext="ModifyingAbove theta With right-arrow"><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover></math> that maximize the log likelihood
    of the training data samples by following the gradient vector (the partial derivatives
    with respect to the components of <math alttext="ModifyingAbove theta With right-arrow"><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover></math> ) uphill. One glaring difficulty
    here is coming up with a formula for the probability density that is able to capture
    the complexity in the data, while at the same time staying amiable to computing
    the log likelihood with its gradient.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Implicit density models**: Sample directly from <math alttext="p Subscript
    m o d e l Baseline left-parenthesis ModifyingAbove x With right-arrow semicolon
    ModifyingAbove theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> without ever writing a formula
    for this distribution. Generative Stochastic Networks do this based on a Markov
    Chain framework, which is slow to converge and thus unpopular for practical applications.
    Using this approach, the model stochastically transforms an existing sample in
    order to obtain another sample from the same distribution. Generative Adversarial
    Networks interact indirectly with the model’s probability distribution without
    explicitly defining it. They set up a zero sum game between two networks, where
    one networks generates a sample and the other network acts like a classifier determining
    whether the generated sample is from the correct distribution or not.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Explicit Density- Tractable: Fully Visible Belief Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'These models admit an explicit probability density function with tractable
    log-likelihood optimization. They rely on the [chain rule of probability](https://en.wikipedia.org/wiki/Chain_rule_(probability))
    to decompose the joint probability distribution <math alttext="p Subscript m o
    d e l Baseline left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    into a product of one dimensional probability distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign p Subscript m o d e l Baseline left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis equals product Underscript i equals 1 Overscript
    n Endscripts p Subscript m o d e l Baseline left-parenthesis x Subscript i Baseline
    vertical-bar x 1 comma x 2 comma ellipsis comma x Subscript i minus 1 Baseline
    right-parenthesis dollar-sign"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>=</mo> <msubsup><mo>∏</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>|</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo>
    <mo>,</mo> <msub><mi>x</mi> <mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The main drawback here is that samples must be generated one component at a
    time (one pixel of an image, or one character of a word, or one entry of a discrete
    audio wave), therefore, the cost of generating one sample is *O(n)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Generating Images via PixelCNN And Machine Audio via WaveNet'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PixelCNN](https://arxiv.org/pdf/1606.05328.pdf) trains a convolutional neural
    network that models the conditional distribution of every individual pixel given
    previous pixels (to the left and to the top of the target pixel). [Figure 8-1](#Fig_PixelCNN)
    illustrates this.'
  prefs: []
  type: TYPE_NORMAL
- en: '![300](assets/emai_0801.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-1\. PixelCNN learning the conditional distribution of the nth pixel
    conditioned on the previous n-1 pixels [(image source)](https://arxiv.org/pdf/1606.05328.pdf).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: WaveNet trains a convolutional neural network that models the conditional distribution
    of each entry of an audiowave given the previous entries. We will only elaborate
    on WaveNet. It is the one dimensional analogue of PixelCNN and it captures the
    essential ideas.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of WaveNet is to generate wideband raw audio waveforms. So we must
    learn the joint probability distribution of an audio waveform <math alttext="ModifyingAbove
    x With right-arrow equals left-parenthesis x 1 comma x 2 comma ellipsis comma
    x Subscript upper T Baseline right-parenthesis"><mrow><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>=</mo> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo> <mo>,</mo>
    <msub><mi>x</mi> <mi>T</mi></msub> <mo>)</mo></mrow></mrow></math> from a certain
    genre.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the product rule to decompose the joint distribution into a product
    of single variable distributions where we condition each entry of the audio waveform
    on those that preceded it:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign p Subscript m o d e l Baseline left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis equals product Underscript t equals 1 Overscript
    upper T Endscripts p Subscript m o d e l Baseline left-parenthesis x Subscript
    t Baseline vertical-bar x 1 comma x 2 comma ellipsis comma x Subscript t minus
    1 Baseline right-parenthesis dollar-sign"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>=</mo> <msubsup><mo>∏</mo> <mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow> <mi>T</mi></msubsup>
    <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>t</mi></msub> <mo>|</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo>
    <mo>,</mo> <msub><mi>x</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: One difficulty is that audio waveforms have very high temporal resolution, with
    at least 16000 entries per one second of audio (so one data sample that is a minute
    long is a vector with *T*=960000 entries). Each of these entries represents one
    time step of discretized raw audio, and is usually stored as a 16 bit integer.
    That is, each entry can assume any value between zero and 65535\. If we keep this
    range, the network has to learn the probability for each entry so the softmax
    function at the output level has to output 65536 probability score for every single
    entry. The total number of entries we have to do this for, along with the computational
    complexity of the network itself, become very expensive. To make this more tractable,
    we must quantize, which in electronics means approximate a continuously varying
    signal by one whose amplitude is restricted to a prescribed set of values. WaveNet
    transforms the raw data to restrict the entries’ values to 256 options each, ranging
    from 0 to 255, similar to pixel range for digital images. Now, during training,
    the network must learn the probability distribution of each entry over these 256
    values, given the preceding entries, and during audio generation, it samples from
    these learned distributions one entry at a time.
  prefs: []
  type: TYPE_NORMAL
- en: The last complication is that if the audio signal represents anything meaningful,
    then the vector representing it has long range dependencies over multiple time
    scales. In order to capture these long-range dependencies, WaveNet uses dilated
    convolutions. These are one dimensional kernels or filters that skip some entries
    to cover wider range without increasing the number of parameters (see [Figure 8-2](#Fig_dilated_convolution)
    for illustration).
  prefs: []
  type: TYPE_NORMAL
- en: '![300](assets/emai_0802.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-2\. Dilated convolution with kernel size equals two. At each layer
    the kernel has only two parameters but it skips entries for larger coverage [(image
    source that has a nice animation)](https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note also that the network cannot peek into the future so the filters at each
    layer cannot use entries from the training sample that are ahead of the target
    entry. In one dimension we just stop filtering earlier at each convolutional layer,
    so it is a simple time shift. In two dimensions we use *masked* filters which
    have zeros to the right and to the bottom of the central entry.
  prefs: []
  type: TYPE_NORMAL
- en: 'WaveNet learns a total of *T* probability distributions, one for each entry
    of the audio waveform conditioned on those entries that preceded it: <math alttext="p
    Subscript m o d e l Baseline left-parenthesis x 1 right-parenthesis comma p Subscript
    m o d e l Baseline left-parenthesis x 2 vertical-bar x 1 right-parenthesis comma
    p Subscript m o d e l Baseline left-parenthesis x 3 vertical-bar x 1 comma x 2
    right-parenthesis comma d o t s"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>,</mo>
    <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>|</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow> <mo>,</mo> <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>|</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow>
    <mo>,</mo> <mi>d</mi> <mi>o</mi> <mi>t</mi> <mi>s</mi></mrow></math> and <math
    alttext="p Subscript m o d e l Baseline left-parenthesis x Subscript upper T Baseline
    vertical-bar x 1 comma x 2 comma ellipsis comma x Subscript upper T minus 1 Baseline
    right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>T</mi></msub> <mo>|</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo>
    <mo>,</mo> <msub><mi>x</mi> <mrow><mi>T</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>)</mo></mrow></mrow></math> . During training, these distributions can be
    computed in parallel.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now suppose we need to learn the probability distribution of the 100th entry,
    given the previous 99 entries. We input batches of audio samples from the training
    data, the convolutional network uses only the first 99 entries of each sample,
    computing linear combinations (the filters linearly combine), passing through
    nonlinear activation functions from one layer to the next to the next, and using
    some skip connections and residual layers to battle vanishing gradients, finally
    passing the result through a softmax function and outputing a vector of length
    256 containing probability scores for the value of the 100th entry. This is the
    probability distribution for the 100th entry output by the model. After comparing
    this output distribution with the emperical distribution of the data for the 100th
    entry from the training batch, the parameters of the network get adjusted to decrease
    the error (lower the cross entropy or increase the likelihood). As more batches
    of data and more epochs pass through the network, the probability distribution
    for the 100th entry given the previous 99 will appproach the emperical distribution
    from the training data. What we save within the network after training are the
    values of the parameters. Now we can use the trained network to generate machine
    audio, one entry at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: Sample a value <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    from the probability distribution late <math alttext="p Subscript m o d e l Baseline
    left-parenthesis x 1 right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow></mrow></math>
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Augment <math alttext="left-parenthesis x 1 right-parenthesis"><mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow></math> with zeros to establish
    the required length for the network’s input (check this) and pass the vector through
    the network. We will get as an output late <math alttext="p Subscript m o d e
    l Baseline left-parenthesis x 2 vertical-bar x 1 right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>|</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>)</mo></mrow></mrow></math> from which we can sample <math alttext="x 2"><msub><mi>x</mi>
    <mn>2</mn></msub></math> .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Augment <math alttext="left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></math> with zeros (check this) and pass the vector through the
    network. We will get as an output late <math alttext="p Subscript m o d e l Baseline
    left-parenthesis x 3 vertical-bar x 1 comma x 2 right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>3</mn></msub> <mo>|</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mrow></math>
    from which we can sample <math alttext="x 3"><msub><mi>x</mi> <mn>3</mn></msub></math>
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep going.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can condition WaveNet on a certain speaker identity, so we can generate different
    voices using one model.
  prefs: []
  type: TYPE_NORMAL
- en: The fact that we can train WaveNet in parallel but use it to generate audio
    only sequentially is a major shortcoming. This has been rectified since then with
    [Parallel WaveNet](https://arxiv.org/pdf/1711.10433.pdf) which is deployed online
    by Google Assistant, including serving multiple English and Japanese voices.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize and place the above discussion in the same mathematical context
    as this chapter, PixelCNN and WaveNet are models that aim to learn the joint probability
    distribution of image data or audio data from certain genres. They do so by decomposing
    the joint distribution into a product of one dimensional probability distributions
    for each entry of their data, conditioned on all the preceding entries. To find
    these one dimensional conditional distributions, they use a convolutional network
    to learn the way the observed entries interact together to produce a distribution
    of the next entry. This way, the input to the network is deterministic and its
    output is a probability mass function. The network itself is also a deterministic
    function. We can view the network together with its output as a probability distribution
    with parameters that we tweak. As the training evolves, the output gets adjusted
    until it reaches an acceptable agreement with the emperical distribution of the
    training data. Therefore, we are not applying a deterministic function to a probability
    distribution and tweaking the function’s parameters until we agree with the distribution
    of the training data. We are instead starting with an explicit formula for a probability
    distribution with many parameters (the network’s parameters), then tweaking the
    parameters until this explicit probability distribution reasonably agrees with
    training data. We do this for each conditional probability distribution corresponding
    to each entry.
  prefs: []
  type: TYPE_NORMAL
- en: 'Explicit Density- Tractable: Change of Variables Nonlinear Independent Component
    Analysis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main idea here is that we have the random variable representing the observed
    training data <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> and we want to learn the source random variable <math
    alttext="ModifyingAbove s With right-arrow"><mover accent="true"><mi>s</mi> <mo>→</mo></mover></math>
    that generated it. We assume that there is a deterministic transformation <math
    alttext="g left-parenthesis ModifyingAbove s With right-arrow right-parenthesis
    equals ModifyingAbove x With right-arrow"><mrow><mi>g</mi> <mrow><mo>(</mo> <mover
    accent="true"><mi>s</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>=</mo> <mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math> that is invertible and
    differentiable that transforms the unknown <math alttext="ModifyingAbove s With
    right-arrow"><mover accent="true"><mi>s</mi> <mo>→</mo></mover></math> to the
    observed <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> . Then <math alttext="ModifyingAbove s With right-arrow
    equals g Superscript negative 1 Baseline left-parenthesis ModifyingAbove x With
    right-arrow right-parenthesis"><mrow><mover accent="true"><mi>s</mi> <mo>→</mo></mover>
    <mo>=</mo> <msup><mi>g</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    . Now we need to find an appropriate *g* and to find the probability distribution
    of <math alttext="ModifyingAbove s With right-arrow"><mover accent="true"><mi>s</mi>
    <mo>→</mo></mover></math> . Moreover, we assume that <math alttext="ModifyingAbove
    s With right-arrow"><mover accent="true"><mi>s</mi> <mo>→</mo></mover></math>
    has independent entries, or components, so that its probability distribution is
    nothing but the product of the distributions of its components.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula that relates the probability distribution of a random variable
    with the probability distribution of a deterministic transformation of it is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartLayout 1st Row 1st Column p Subscript s Baseline
    left-parenthesis ModifyingAbove s With right-arrow right-parenthesis 2nd Column
    equals p Subscript x Baseline left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis times d e t e r m i n a n t left-parenthesis upper J a c o b
    i a n right-parenthesis 2nd Row 1st Column Blank 2nd Column equals p Subscript
    x Baseline left-parenthesis g left-parenthesis ModifyingAbove s With right-arrow
    right-parenthesis right-parenthesis StartAbsoluteValue det left-parenthesis StartFraction
    normal partial-differential g left-parenthesis ModifyingAbove s With right-arrow
    right-parenthesis Over normal partial-differential ModifyingAbove s With right-arrow
    EndFraction right-parenthesis EndAbsoluteValue EndLayout dollar-sign"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>p</mi> <mi>s</mi></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <msub><mi>p</mi> <mi>x</mi></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>×</mo>
    <mi>d</mi> <mi>e</mi> <mi>t</mi> <mi>e</mi> <mi>r</mi> <mi>m</mi> <mi>i</mi> <mi>n</mi>
    <mi>a</mi> <mi>n</mi> <mi>t</mi> <mrow><mo>(</mo> <mi>J</mi> <mi>a</mi> <mi>c</mi>
    <mi>o</mi> <mi>b</mi> <mi>i</mi> <mi>a</mi> <mi>n</mi> <mo>)</mo></mrow></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mrow><mo>=</mo> <msub><mi>p</mi> <mi>x</mi></msub>
    <mrow><mo>(</mo> <mi>g</mi> <mrow><mo>(</mo> <mover accent="true"><mi>s</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mrow><mo>|</mo> <mo form="prefix" movablelimits="true">det</mo>
    <mrow><mo>(</mo> <mfrac><mrow><mi>∂</mi><mi>g</mi><mo>(</mo><mover accent="true"><mi>s</mi>
    <mo>→</mo></mover><mo>)</mo></mrow> <mrow><mi>∂</mi><mover accent="true"><mi>s</mi>
    <mo>→</mo></mover></mrow></mfrac> <mo>)</mo></mrow> <mo>|</mo></mrow></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: Multiplying by the determinant of the Jacobian of the transformation accounts
    for the change in volume in space due to the transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '[Nonlinear independent component estimation](https://arxiv.org/pdf/1410.8516.pdf)
    models the joint probability distribution as the nonlinear transformation of the
    data <math alttext="ModifyingAbove s With right-arrow equals g Superscript negative
    1 Baseline left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><mover
    accent="true"><mi>s</mi> <mo>→</mo></mover> <mo>=</mo> <msup><mi>g</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    . The transformation *g* is learned such that <math alttext="g Superscript negative
    1"><msup><mi>g</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math> maps the data
    to a latent space where it conforms to a factorized distribution, that is, the
    mapping results in independent latent variables. The transformation <math alttext="g
    Superscript negative 1"><msup><mi>g</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    is parametrized in a way that allows for easy compution of the determinant of
    the Jacobian and the inverse Jacobian. <math alttext="g Superscript negative 1"><msup><mi>g</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup></math> is based on a deep neural network
    and its parameters are learned via optimizing the log-likelihood, which is tractable.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the requirement that the transformation *g* must be invertible means
    that the latent variables <math alttext="ModifyingAbove s With right-arrow"><mover
    accent="true"><mi>s</mi> <mo>→</mo></mover></math> must have the same dimension
    as the data features (length of <math alttext="ModifyingAbove x With right-arrow"><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></math> ). This imposes restrictions
    on the choice of the function *g* and it is a disadvanatage of nonlinear independent
    component analysis models.
  prefs: []
  type: TYPE_NORMAL
- en: In comparison, generative adversarial networks impose very few requirements
    on g, and, in particular, allow <math alttext="ModifyingAbove s With right-arrow"><mover
    accent="true"><mi>s</mi> <mo>→</mo></mover></math> to have more dimensions than
    <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> .
  prefs: []
  type: TYPE_NORMAL
- en: 'Explicit Density- Intractable: Variational Autoencoders- Approximation via
    Variational Methods'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deterministic autoencoders are composed of an encoder that maps the data from
    x space to latent z space of lower dimension, and a decoder that in turn maps
    the data from z space to <math alttext="ModifyingAbove x With caret"><mover accent="true"><mi>x</mi>
    <mo>^</mo></mover></math> space, with the objective of not losing much information,
    or reducing the reconstruction error, which means keeping x and <math alttext="ModifyingAbove
    x With caret"><mover accent="true"><mi>x</mi> <mo>^</mo></mover></math> close,
    for example in the Euclidean distance sense. In this sense, we can view *principal
    component analysis* which is based on the singular value decomposition <math alttext="upper
    X equals upper U normal upper Sigma upper V Superscript t"><mrow><mi>X</mi> <mo>=</mo>
    <mi>U</mi> <mi>Σ</mi> <msup><mi>V</mi> <mi>t</mi></msup></mrow></math> as a linear
    encoder, where the decoder is simply the transpose of the encoding matrix. Encoding
    and decoding functions can be nonlinear and/or neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: For deterministic autoencoders, we cannot use the decoder as a data generator.
    At least, if we do, then we have a to pick some z from latent z space and apply
    the decoder function to it. We are unlikely to get any <math alttext="ModifyingAbove
    x With caret"><mover accent="true"><mi>x</mi> <mo>^</mo></mover></math> that is
    close to how the desired data x looks, unless we picked a z which corresponds
    to a coded x, due to overfitting. We need a regularization that provides us with
    some control over z space, giving us the benefit of avoiding overfitting and using
    autoencoders as a data generator. We accomplish this by shifting from deterministic
    autoencoding to probabilistic autoencoding.
  prefs: []
  type: TYPE_NORMAL
- en: 'Variational autoencoders are probabilistic autoencoders: The encoder outputs
    probability distributions over the latent space z instead of single points. Moreover,
    during training, the loss function includes an extra regularization term that
    controls the distribution over the latent space. Therefore, the loss function
    for variational autoencoders contains a reconstruction term (such as mean squared
    distance) and a regularization term to control the probability distribution output
    by the encoder. The regularization term can be a KL divergence from a Gaussian
    distribution, since the underlying assumption is that simple probabilistic models
    best describe the training data. In other words, complex relationships can be
    probabilistically simple. We have to be careful here, since this introduces a
    bias: The simple assumption on the data distribution in the latent variable can
    be a drawback if it is too weak. That is, when the assumption on the prior distribution
    or the assumption on the approximate posterior distribution are too weak, even
    with a perfect optimization algorithm and infinite training data, the gap between
    the estimate <math alttext="script upper L"><mi>ℒ</mi></math> and the true log
    likelihood can lead to <math alttext="p Subscript m o d e l"><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    learning a completely different distribution than the true <math alttext="p Subscript
    d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    .'
  prefs: []
  type: TYPE_NORMAL
- en: Mathematically, we maximize a lower bound <math alttext="script upper L"><mi>ℒ</mi></math>
    on the log likelihood of the data. In science, variational methods define lower
    bounds on an energy functional that we want to maximize, or upper bounds on an
    energy functional that we want to minimize. These bounds are usually easier to
    obtain and have tractable optimization algorithms, even when the log likelihood
    does not. At the same time, they provide good estimates for the optimal values
    that we are searching for.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign script upper L left-parenthesis ModifyingAbove x
    With right-arrow comma ModifyingAbove theta With right-arrow right-parenthesis
    less-than-or-equal-to log p Subscript m o d e l Baseline left-parenthesis ModifyingAbove
    x With right-arrow comma ModifyingAbove theta With right-arrow right-parenthesis
    dollar-sign"><mrow><mi>ℒ</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><mi>θ</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>≤</mo> <mo form="prefix">log</mo> <msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Variational methods often achieve very good likelihood, but subjective evaluation
    of samples regard their generated samples as having lower quality. They are also
    considered more difficult to optimize than fully visible belief networks. Moreover,
    people find their mathematics more difficult than that of fully visible belief
    networks and of generative adversarial networks (discussed soon).
  prefs: []
  type: TYPE_NORMAL
- en: 'Explicit Density- Intractable: Boltzman Machine- Approximation via Markov Chain'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Boltzmann machines (1980’s) are a family of generative models that rely on
    Markov chains to train generative model. This is a sampling technique, that happens
    to be more expensive than the simple sampling of a minibatch from a data set to
    estimate a loss function. We will discuss Markov chains in the context of reinforcement
    learning in [Chapter 14](ch14.xhtml#ch14). In the context of data generation,
    they have many disadvantages that caused them to fall out of favor: High computational
    cost, impratical and less efficient to extend to higher dimensions, slow to converge,
    and no clear way to know whether the model has converged or not, even when the
    theory says it must converge. Markov scale methods have not scaled to problems
    like ImageNet generation.'
  prefs: []
  type: TYPE_NORMAL
- en: A Markov chain has a transition operator *q* that encodes the probability of
    transitioning from one state of the system to another. This transition operator
    *q* needs to be explicitly defined. We can generate data samples by repeatedly
    drawing a sample <math alttext="x prime tilde q left-parenthesis x prime vertical-bar
    x right-parenthesis"><mrow><msup><mi>x</mi> <mo>'</mo></msup> <mo>∼</mo> <mi>q</mi>
    <mrow><mo>(</mo> <msup><mi>x</mi> <mo>'</mo></msup> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    , updating <math alttext="x prime"><msup><mi>x</mi> <mo>'</mo></msup></math> sequentially
    according to the transition operator *q*. This sequential nature of generation
    is another disadvantage compared to single step generation. Markov chain methods
    can sometimes guarantee that x’ will eventually converge to a sample from <math
    alttext="p Subscript m o d e l Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math> , even though the convergence might
    be slow.
  prefs: []
  type: TYPE_NORMAL
- en: Some models, such as deep Boltzman machines, employ both Markov chain and variational
    approximations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Implicit Density- Markov Chain: Generative Stochastic Network'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative Stochastic Networks (Bengio et al., 2014) do not explicitly define
    a density function, and instead use a Markov chain transition operator interacts
    indirectly with <math alttext="p Subscript m o d e l Baseline left-parenthesis
    x right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math> by sampling from the
    training data. This Markov chain operator must be run several times to obtain
    a sample from <math alttext="p Subscript m o d e l Baseline left-parenthesis x
    right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math> . These methods still
    suffer from the shortcomings of Markov chain methods mentioned in the previous
    section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Implicit Density- Direct: Generative Adversarial Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Currently the most popular generative models are:'
  prefs: []
  type: TYPE_NORMAL
- en: Fully visible deep belief networks, such as PixelCNN, WaveNet, and their variations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variational autoencoders, consisting of a probabilistic encoder-decoder architecture.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative adversarial networks, which have recieved a lot of attention from
    the scientific community, due to the simplicity of their concept and the good
    quality of their generated samples. We discuss them now.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Generative Adversarial Networks*](https://arxiv.org/pdf/1406.2661.pdf) were
    introduced in 2014 by Ian Goodfellow, et al. The mathematics involved is a beautiful
    mixture between probability and game theory. Generative adversarial networks avoid
    some disadvantages associated with other generative models:'
  prefs: []
  type: TYPE_NORMAL
- en: Generating samples all at once, in parallel, as opposed to feeding a new pixel
    back into the network to predict the one, such as in PixelCNN.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The generator function has few restrictions. This is an advantage relative to
    Boltzmann machines, for which few probability distributions admit tractable Markov
    chain sampling, and relative to nonlinear independent component analysis, for
    which the generator must be invertible and the latent variables z must have the
    same dimension as the samples x.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative adversarial networks do not need Markov chains. This is an advantage
    relative to Boltzmann machines and to generative stochastic networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While variational autoencoders might never converge to the true data generating
    distribution if they assume prior or posterior distributions that are too weak,
    generative adversarial networks converge to the true <math alttext="p Subscript
    d Baseline a t a"><mrow><msub><mi>p</mi> <mi>d</mi></msub> <mi>a</mi> <mi>t</mi>
    <mi>a</mi></mrow></math> , given that we have infinite training data and a large
    enough model. Moreover, generative adversarial networks do not need variational
    bounds, and the specific model families used within the generative adversarial
    network framework are already known to be universal approximators. Thus, generative
    adversarial networks are already known to be asymptotically consistent. On the
    other hand, some variational autoencoders are conjectured to be asymptotically
    consistent, but this still needs to be proven (check this).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The disadvantage of generative adversarial networks is that training them requires
    spotting the Nash equilibrium of a game, which is more difficult than just optimizing
    an objective function. Moreover, the solution tends to be numerically unstable.
    This was improved in 2015 by Alec Radford, et al, [Deep Convolutional Generative
    Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf). This approach led
    to more stable models.
  prefs: []
  type: TYPE_NORMAL
- en: 'During training, generative adversarial networks formulate a game between two
    separate networks: A generator network and a discriminator network that tries
    to classify genrator samples as either coming from the true distribution <math
    alttext="p Subscript d a t a Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math> or from the model <math alttext="p
    Subscript m o d e l Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math> . The loss functions of the two networks
    are related, so that the discriminator communicates the discrepancy between the
    two distributions and the generator adjusts its parameters accordingly, until
    the generator exactly reproduces the true data distribution (in theory) so that
    the discriminator’s classifications are no better than random guesses.'
  prefs: []
  type: TYPE_NORMAL
- en: The generator network wants to maximize the probability that the discriminator
    assigns the wrong label in its classification whether the sample is from the training
    data or from the model, while the discriminator network wants to minimize that
    probability. This is a two player zero sum game, where one player’s gain is another’s
    loss. We end up solving a minimax problem instead of a purely maximizing or minimizing
    problem. A unique solution exists.
  prefs: []
  type: TYPE_NORMAL
- en: How Do Generative Adversarial Networks Work?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Keeping the goal of learning the generator’s probability distribution <math
    alttext="p Subscript g Baseline left-parenthesis ModifyingAbove x With right-arrow
    semicolon ModifyingAbove theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>g</mi></msub> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>;</mo> <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    over the data, here’s how the learning progresses for generative adversarial networks:'
  prefs: []
  type: TYPE_NORMAL
- en: Start with a random sample <math alttext="ModifyingAbove z With right-arrow"><mover
    accent="true"><mi>z</mi> <mo>→</mo></mover></math> from a prior probability distribution
    <math alttext="p Subscript z Baseline left-parenthesis ModifyingAbove z With right-arrow
    right-parenthesis"><mrow><msub><mi>p</mi> <mi>z</mi></msub> <mrow><mo>(</mo> <mover
    accent="true"><mi>z</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> ,
    which could be just uniform random noise for each component of <math alttext="ModifyingAbove
    z With right-arrow"><mover accent="true"><mi>z</mi> <mo>→</mo></mover></math>
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Start also with a random sample <math alttext="ModifyingAbove x With right-arrow"><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></math> from the training data, so
    it is a sample from the probability distribution <math alttext="p Subscript d
    a t a Baseline left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    that the generator is trying to learn.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply to <math alttext="ModifyingAbove z With right-arrow"><mover accent="true"><mi>z</mi>
    <mo>→</mo></mover></math> the deterministic function <math alttext="upper G left-parenthesis
    ModifyingAbove z With right-arrow comma ModifyingAbove theta With right-arrow
    Subscript g Baseline right-parenthesis"><mrow><mi>G</mi> <mo>(</mo> <mover accent="true"><mi>z</mi>
    <mo>→</mo></mover> <mo>,</mo> <msub><mover accent="true"><mi>θ</mi> <mo>→</mo></mover>
    <mi>g</mi></msub> <mo>)</mo></mrow></math> representing the generative neural
    network. The parameters <math alttext="ModifyingAbove theta With right-arrow Subscript
    g"><msub><mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mi>g</mi></msub></math>
    are the ones we need to tweak via backpropagation until the output <math alttext="upper
    G left-parenthesis ModifyingAbove z With right-arrow comma ModifyingAbove theta
    With right-arrow Subscript g Baseline right-parenthesis"><mrow><mi>G</mi> <mo>(</mo>
    <mover accent="true"><mi>z</mi> <mo>→</mo></mover> <mo>,</mo> <msub><mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mi>g</mi></msub> <mo>)</mo></mrow></math> looks similar to
    samples from the training data set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pass the output <math alttext="upper G left-parenthesis ModifyingAbove z With
    right-arrow comma ModifyingAbove theta With right-arrow Subscript g Baseline right-parenthesis"><mrow><mi>G</mi>
    <mo>(</mo> <mover accent="true"><mi>z</mi> <mo>→</mo></mover> <mo>,</mo> <msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mi>g</mi></msub> <mo>)</mo></mrow></math>
    into another deterministic function *D* representing the discriminative neural
    network. So now we have the new output <math alttext="upper D left-parenthesis
    upper G left-parenthesis ModifyingAbove z With right-arrow comma ModifyingAbove
    theta With right-arrow Subscript g Baseline right-parenthesis comma ModifyingAbove
    left-parenthesis With right-arrow theta right-parenthesis Subscript d Baseline
    right-parenthesis"><mrow><mi>D</mi> <msub><mrow><mo>(</mo><mi>G</mi><mrow><mo>(</mo><mover
    accent="true"><mi>z</mi> <mo>→</mo></mover><mo>,</mo><msub><mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mi>g</mi></msub> <mo>)</mo></mrow><mo>,</mo><mover accent="true"><mo>(</mo>
    <mo>→</mo></mover><mi>θ</mi><mo>)</mo></mrow> <mi>d</mi></msub> <mrow><mo>)</mo></mrow></mrow></math>
    that is just a number closer to one or to zero, signifying whether this sample
    came from the generator or from the training data. Thus, for this input from the
    generator <math alttext="upper D left-parenthesis upper G left-parenthesis ModifyingAbove
    z With right-arrow comma ModifyingAbove theta With right-arrow Subscript g Baseline
    right-parenthesis comma ModifyingAbove left-parenthesis With right-arrow theta
    right-parenthesis Subscript d Baseline right-parenthesis"><mrow><mi>D</mi> <msub><mrow><mo>(</mo><mi>G</mi><mrow><mo>(</mo><mover
    accent="true"><mi>z</mi> <mo>→</mo></mover><mo>,</mo><msub><mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mi>g</mi></msub> <mo>)</mo></mrow><mo>,</mo><mover accent="true"><mo>(</mo>
    <mo>→</mo></mover><mi>θ</mi><mo>)</mo></mrow> <mi>d</mi></msub> <mrow><mo>)</mo></mrow></mrow></math>
    must return a number close to one. The parameters <math alttext="ModifyingAbove
    theta With right-arrow Subscript d"><msub><mover accent="true"><mi>θ</mi> <mo>→</mo></mover>
    <mi>d</mi></msub></math> are the ones we need to tweak via backpropagation until
    *D* returns the wrong classification around half of the time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pass also the sample <math alttext="ModifyingAbove x With right-arrow"><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></math> from the training data to *D*,
    so we evaluate <math alttext="upper D left-parenthesis ModifyingAbove x With right-arrow
    comma ModifyingAbove theta With right-arrow Subscript d Baseline right-parenthesis"><mrow><mi>D</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo> <msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mi>d</mi></msub> <mo>)</mo></mrow></math>
    . For this input, <math alttext="upper D left-parenthesis ModifyingAbove x With
    right-arrow comma ModifyingAbove theta With right-arrow Subscript d Baseline right-parenthesis"><mrow><mi>D</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo> <msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mi>d</mi></msub> <mo>)</mo></mrow></math>
    must return a number close to zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What is the loss function for these two networks, that has in its formula both
    sets of parameters <math alttext="ModifyingAbove theta With right-arrow Subscript
    g"><msub><mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mi>g</mi></msub></math>
    and <math alttext="ModifyingAbove theta With right-arrow Subscript d"><msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mi>d</mi></msub></math> , along with
    the sampled vectors <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> and <math alttext="ModifyingAbove z With right-arrow"><mover
    accent="true"><mi>z</mi> <mo>→</mo></mover></math> ? The discriminator function
    *D* wants to get it right for both types of inputs, <math alttext="ModifyingAbove
    x With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    and <math alttext="upper G left-parenthesis ModifyingAbove z With right-arrow
    comma ModifyingAbove theta With right-arrow Subscript g Baseline right-parenthesis"><mrow><mi>G</mi>
    <mo>(</mo> <mover accent="true"><mi>z</mi> <mo>→</mo></mover> <mo>,</mo> <msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mi>g</mi></msub> <mo>)</mo></mrow></math>
    . So its parameters <math alttext="ModifyingAbove theta With right-arrow Subscript
    d"><msub><mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mi>d</mi></msub></math>
    must be selected so that a number close to one is assigned a large score when
    the input is <math alttext="upper G left-parenthesis ModifyingAbove z With right-arrow
    comma ModifyingAbove theta With right-arrow Subscript g Baseline right-parenthesis"><mrow><mi>G</mi>
    <mo>(</mo> <mover accent="true"><mi>z</mi> <mo>→</mo></mover> <mo>,</mo> <msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mi>g</mi></msub> <mo>)</mo></mrow></math>
    and a number close to zero is assigned a large value when the input is <math alttext="ModifyingAbove
    x With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    . In both cases, we can use the negative of the *log* function since that is a
    function that is large near zero and small near one. Therefore, *D* needs the
    parameters <math alttext="ModifyingAbove theta With right-arrow Subscript d"><msub><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover> <mi>d</mi></msub></math> that maximize:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign double-struck upper E Subscript ModifyingAbove x
    With right-arrow tilde p Sub Subscript d a t a Subscript left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis Baseline left-bracket log upper D left-parenthesis
    ModifyingAbove x With right-arrow comma ModifyingAbove theta With right-arrow
    Subscript d Baseline right-parenthesis right-bracket plus double-struck upper
    E Subscript ModifyingAbove z With right-arrow tilde p Sub Subscript z Subscript
    left-parenthesis ModifyingAbove z With right-arrow right-parenthesis Baseline
    left-bracket log left-parenthesis 1 minus upper D left-parenthesis upper G left-parenthesis
    ModifyingAbove z With right-arrow comma ModifyingAbove theta Subscript g Baseline
    With right-arrow right-parenthesis comma ModifyingAbove theta Subscript d Baseline
    With right-arrow right-parenthesis right-parenthesis right-bracket dollar-sign"><mrow><msub><mi>𝔼</mi>
    <mrow><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>∼</mo><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub> <mrow><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow></mrow></msub> <mrow><mo>[</mo>
    <mo form="prefix">log</mo> <mi>D</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>,</mo> <msub><mover accent="true"><mi>θ</mi> <mo>→</mo></mover>
    <mi>d</mi></msub> <mo>)</mo></mrow> <mo>]</mo></mrow> <mo>+</mo> <msub><mi>𝔼</mi>
    <mrow><mover accent="true"><mi>z</mi> <mo>→</mo></mover><mo>∼</mo><msub><mi>p</mi>
    <mi>z</mi></msub> <mrow><mo>(</mo><mover accent="true"><mi>z</mi> <mo>→</mo></mover><mo>)</mo></mrow></mrow></msub>
    <mrow><mo>[</mo> <mo form="prefix">log</mo> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo>
    <mi>D</mi> <mrow><mo>(</mo> <mi>G</mi> <mrow><mo>(</mo> <mover accent="true"><mi>z</mi>
    <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><msub><mi>θ</mi> <mi>g</mi></msub>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>,</mo> <mover accent="true"><msub><mi>θ</mi>
    <mi>d</mi></msub> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>]</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'At the same time, *G* needs the parameters <math alttext="ModifyingAbove theta
    With right-arrow Subscript g"><msub><mover accent="true"><mi>θ</mi> <mo>→</mo></mover>
    <mi>g</mi></msub></math> that minimize <math alttext="log left-parenthesis 1 minus
    upper D left-parenthesis upper G left-parenthesis ModifyingAbove z With right-arrow
    comma ModifyingAbove theta Subscript g Baseline With right-arrow right-parenthesis
    comma ModifyingAbove theta Subscript d Baseline With right-arrow right-parenthesis
    right-parenthesis"><mrow><mo form="prefix">log</mo> <mo>(</mo> <mn>1</mn> <mo>-</mo>
    <mi>D</mi> <mrow><mo>(</mo> <mi>G</mi> <mrow><mo>(</mo> <mover accent="true"><mi>z</mi>
    <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><msub><mi>θ</mi> <mi>g</mi></msub>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>,</mo> <mover accent="true"><msub><mi>θ</mi>
    <mi>d</mi></msub> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>)</mo></mrow></math>
    . Combined together, *D* and *G* engage in a two-player minimax game with value
    function V (G, D):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript upper G Endscripts max Underscript
    upper D Endscripts upper V left-parenthesis upper D comma upper G right-parenthesis
    equals double-struck upper E Subscript ModifyingAbove x With right-arrow tilde
    p Sub Subscript d a t a Subscript left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis Baseline left-bracket log upper D left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis right-bracket plus double-struck upper E
    Subscript ModifyingAbove z With right-arrow tilde p Sub Subscript z Subscript
    left-parenthesis ModifyingAbove z With right-arrow right-parenthesis Baseline
    left-bracket log left-parenthesis 1 minus upper D left-parenthesis upper G left-parenthesis
    ModifyingAbove z With right-arrow right-parenthesis right-parenthesis right-parenthesis
    right-bracket dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo>
    <mi>G</mi></msub> <msub><mo form="prefix" movablelimits="true">max</mo> <mi>D</mi></msub>
    <mi>V</mi> <mrow><mo>(</mo> <mi>D</mi> <mo>,</mo> <mi>G</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mi>𝔼</mi> <mrow><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>∼</mo><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub> <mrow><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow></mrow></msub> <mrow><mo>[</mo>
    <mo form="prefix">log</mo> <mi>D</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>]</mo></mrow> <mo>+</mo> <msub><mi>𝔼</mi>
    <mrow><mover accent="true"><mi>z</mi> <mo>→</mo></mover><mo>∼</mo><msub><mi>p</mi>
    <mi>z</mi></msub> <mrow><mo>(</mo><mover accent="true"><mi>z</mi> <mo>→</mo></mover><mo>)</mo></mrow></mrow></msub>
    <mrow><mo>[</mo> <mo form="prefix">log</mo> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo>
    <mi>D</mi> <mrow><mo>(</mo> <mi>G</mi> <mrow><mo>(</mo> <mover accent="true"><mi>z</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>]</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This is a very simple mathematical structure, where setting up a discriminator
    network allows us to get closer to the true data distribution without ever explicitly
    defining it or assuming anything about it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we note that generative adversarial networks are highly promising
    for many applications. One example is the dramatic enhancement they have for semi-supervised
    learning, where [NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160)
    reports: *We introduce an approach for semi-supervised learning with generative
    adversarial networks that involves the discriminator producing an additional output
    indicating the label of the input. This approach allows us to obtain state of
    the art results on MNIST, SVHN, and CIFAR-10 in settings with very few labeled
    examples. On MNIST, for example, we achieve 99.14% accuracy with only 10 labeled
    examples per class with a fully connected neural network — a result that’s very
    close to the best known results with fully supervised approaches using all 60,000
    labeled examples. This is very promising because labeled examples can be quite
    expensive to obtain in practice.*'
  prefs: []
  type: TYPE_NORMAL
- en: Another far reaching application of generative adversarial networks (and machine
    learning in general) is simulating data for high energy physics. We discuss this
    next.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Machine Learning And Generative Networks For High Energy Physics'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following discussion is inspired by and borrows from [Machine Learning For
    Jet Physics Workshop 2020](https://iris-hep.org/2020/01/17/ml4jets-workshop.xhtml)
    and the two articles [Deep Learning and Its Application to Large Hadron Collider
    Physics](https://arxiv.org/pdf/1806.11484.pdf), and [Graph Generative Adversarial
    Networks for Sparse Data Generation in High Energy Physics](https://arxiv.org/pdf/2012.00173.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Before the deep learning revolution since 2012, the field of high energy physics
    traditionally relied in its analyses and computations on physical considerations
    and human intuition, boosted decision trees, hand crafted data feature engineering
    and dimensionality reduction, and traditional statistical analysis. These techniques,
    while insightful, are naturally far from optimal and hard to automate or extend
    to higher dimensions. Several studies have demonstrated that traditional shallow
    networks based on physics-inspired engineered *high-level* features are outperformed
    by deep networks based on the higher dimensional *lower-level* features which
    receive less pre-processing. Many areas of the [Large Hadron Collider](https://en.wikipedia.org/wiki/Large_Hadron_Collider)
    data analysis have suffered from long-standing sub-optimal feature engineering,
    and deserve re-examination. Thus, the high energy physics field is a breeding
    ground ripe for machine learning learning applications. A lot of progress is taking
    place on this front. The field is employing several machine learning techniques,
    including artificial neural networks, kernel density estimation, support vector
    machines, genetic algorithms, boosted decision trees, random forests, and generative
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The experimental program of the Large Hadron Collider probes the most fundamental
    questions in modern physics: The nature of mass, the dimensionality of space,
    the unification of the fundamental forces, the particle nature of dark matter,
    and the fine-tuning of the [Standard Model](https://en.wikipedia.org/wiki/Standard_Model).
    One driving goal is to understand the most fundamental structure of matter. Part
    of that entails searching for and studying exotic particles, such as the top quark
    and Higgs boson, produced in collisions at accelerators such as the Large Hadron
    Collider. Specific benchmarks and challenges include: Mass resconstruction, jet
    substructure, and jet-flavor classification. For example, one can identify jets
    from heavy *(c, b, t)* or light *(u, d, s)* quarks, gluons, and *W*, *Z*, and
    *H* bosons.'
  prefs: []
  type: TYPE_NORMAL
- en: Running high energy particle experiments and collecting the resulting data is
    extremely expensive. The data collected is enormous in terms of the number of
    collisions and in the complexity of each collision. In addition, the bulk of accelerator
    events do not produce interesting particles (signal particles *vs* background
    particles). Signal particles are rare, so high data rates are necessary. For example,
    the Large Hadron Collidor detectors have O(108) sensors used to record the large
    number of particles produced after each collision. It is thus of paramount importance
    to extract maximal information from experimental data (think regression and classification
    models), to accurately select and identify events for effective measurements,
    and to produce reliable methods for simulating new data similar to data produced
    by experiments (think generative models). High energy physics data is characterized
    by its high dimensionality, along with the complex topologies of many signal events.
  prefs: []
  type: TYPE_NORMAL
- en: 'The way this discussion ties into our chapter is through the nature of collisions
    and the interaction of their products with Large Hadron Collider detectors: They
    are quantum-mechanical, therefore, the observations resulting from a particular
    interaction are fundamentally probabilistic. The resulting data analysis must
    then be framed in statistical and probabilistic terms.'
  prefs: []
  type: TYPE_NORMAL
- en: In our chapter, our aim is to learn the probability disribution <math alttext="p
    left-parenthesis ModifyingAbove theta With right-arrow vertical-bar ModifyingAbove
    x With right-arrow right-parenthesis"><mrow><mi>p</mi> <mo>(</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>|</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow></math> of the model’s parameters given the observed data. If
    the data was fairly low dimensional, such as less than five dimensions, the problem
    of estimating the unknown statistical model from the simulated samples would not
    be difficult, using histograms or kernel-based density estimates. However, we
    cannot easily extend these simple methods to higher dimensions, due to the curse
    of dimensionality. In a single dimension, we would need *N* samples to estimate
    the source probability density function, but in *d* dimensions, we would need
    <math alttext="upper O left-parenthesis upper N Superscript d Baseline right-parenthesis"><mrow><mi>O</mi>
    <mo>(</mo> <msup><mi>N</mi> <mi>d</mi></msup> <mo>)</mo></mrow></math> . The consequence
    is that if the dimension of the data is greater than ten or so, it is impractical
    or even impossible to use naive methods to estimate the probability distribution,
    requiring a prohibitive amount of computational resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'High energy physicists have traditionally dealt with the curse of dimensionality
    by reducing the dimension of the data through a series of steps that operate both
    on individual collision events and on collections of events. These established
    approaches were based on specific, hand engineered features in the data to a number
    small enough to allow the estimation of the unknown probability distribution <math
    alttext="p left-parenthesis x vertical-bar theta right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>θ</mi> <mo>)</mo></mrow></math> using samples
    generated by simulation tools. Obviously, due to complexity of the data and the
    rarity of potential new physics along with its subtle signatures, this traditional
    approach is probably sub-optimal. Machine learning eliminates the need for hand
    engineering features and manual dimensionality reduction, that can miss crucial
    information in the lower-level higher dimensional data. Moreover, the structure
    of lower-level data obtained directly from the sensors fits very well with well
    established neural network models, such as convolutional neural networks and graph
    neural networks: For example, the projective tower structure of calorimeters present
    in nearly all modern high energy physics detectors is similar to the pixels of
    an image.'
  prefs: []
  type: TYPE_NORMAL
- en: Note however that while the image-based approach has been successful, the actual
    detector geometry is not perfectly regular, thus, some data preprocessing is required
    to represent jets images. In addition, jet images are typically very sparse. Both
    irregular geometry and sparsity can be addressed using *graph based convolutional
    networks* instead of the usual convolutional networks for our particle data modeling.
    Graph convolutional networks extend the application of convolutional neural networks
    to irregularly sampled data. They are able to handle sparse, permutation invariant
    data with complex geometries. We will discuss graph networks in the next chapter.
    They always come with nodes, edges, and a matrix encoding the relationships in
    the graph, called *adjacency matrix*. In the context of high energy physics, the
    particles of a jet represent the nodes of the graph and the edges encode how close
    the particles are in a learned adjacency matrix. In high energy physics, graph
    based networks have been successfully applied to classification, reconstruction
    and generation tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The subject of our chapter is generative models, or generating data similar
    to a given data set. Generating or simulating data faithful to the experimental
    data collected in high energy physics is of great importance. In [Graph Generative
    Adversarial Networks for Sparse Data Generation in High Energy Physics](https://arxiv.org/pdf/2012.00173.pdf),
    the authors develop graph-based generative models, using a generative adversarial
    network framework, for simulating sparse datasets like those produced at the [CERN](https://home.cern)
    Large Hadron Collider.
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors illustrate their approach by training on and generating sparse
    representations of MNIST handwritten digit images and jets of particles in proton-proton
    collisions like those at the Large Hadron Collider. The model successfully generates
    sparse MNIST digits and particle jet data. The authors use two metrics to quantify
    agreement between real and generated data: A graph-based [Fréchet Inception distance](https://en.wikipedia.org/wiki/Fr%C3%A9chet_inception_distance),
    and the particle and jet feature-level [1-Wasserstein distance](https://en.wikipedia.org/wiki/Wasserstein_metric).'
  prefs: []
  type: TYPE_NORMAL
- en: Other Generative Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have discussed state of the art generative models (as of 2022), but this
    chapter will be incomplete if we do not go over Naive Bayes, Gaussian mixture,
    and Boltzmann machine models. There are many others. That being said, Yann LeCun
    (VP and Chief AI Scientist at Meta) offers [his perspective](https://www.linkedin.com/posts/yann-lecun_yann-lecun-activity-6931321709572603904-Mj3v?utm_source=linkedin_share&utm_medium=member_desktop_web)
    on some of these models:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Researchers in speech recognition, computer vision, and natural language processing
    in the 2000s were obsessed with accurate representations of uncertainty. This
    led to a flurry of work on probabilstic generative models such as Hidden Markov
    Models in speech, Markov random fields and constellation models in vision, and
    probabilistic topic models in NLP, e.g. with latent Dirichlet analysis. There
    were debates at computer vision workshops about generative models vs discriminative
    models. There were heroic-yet-futile attempts to build object recognition systems
    with non-parametric Bayesian methods. Much of this was riding on previous work
    on Bayesian networks, factor graphs and other graphical models. That’s how one
    learned about exponential family, belief propagation, loopy belief propagation,
    variational inference, etc, Chinese restaurant process, Indian buffet process,
    etc. But almost none of this work was concenred with the problem of learning representations.
    Features were assumed to be given. The structure of the graphical model, with
    its latent variables, was assumed to be given. All one had to do was to compute
    some sort of log likelihood by linearly combining features, and then use one of
    the above mentioned sophisticated inference methods to produce marginal distributions
    over the unknown variables, one of which being the answer, e.g. a category. In
    fact, exponential family pretty much means shallow: the log-likelihood can be
    expressed as a linearly parameterized function of features (or simple combinations
    thereof). Learning the parameters of the model was seen as just another variational
    inference problem. It’s interesting to observe that almost none of this is relevant
    to today’s top speech, vision, and NLP systems. As it turned out, solving the
    problem of learning hierarchical representations and complex functional dependencies
    was a much more important issue than being able to perform accurate probabilistic
    inference with shallow models. This is not to say that accurate probabilistic
    inference is not useful.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same vein, he continues: *Generative Adversial Networks are nice for
    producing pretty pictures (though they are being edged out by diffusion models,
    or “multistep denoising auto-encoders” as I like to call them), but for recognition
    and representation learning, GANs have been a big disappointment.*'
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, there is a lot of math to be learned from all these models. In
    my experience, we understand and retain math at a much deeper level when we see
    it developed and utilized for specific purposes, as opposed only to train the
    neurons of the brain. Many mathematicians claim to experience pleasure while proving
    theories that have yet to find applications. I was never one of those.
  prefs: []
  type: TYPE_NORMAL
- en: Naive Bayes Classification Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Naive Bayes model is a very simple classification model that we can also use
    as a generative model, since it ends up computing a joint probability distribution
    <math alttext="p left-parenthesis ModifyingAbove x With right-arrow comma y Subscript
    k Baseline right-parenthesis"><mrow><mi>p</mi> <mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>,</mo> <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow></math>
    for the data in order to determine its classification. The training data has features
    <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> and labels <math alttext="y Subscript k"><msub><mi>y</mi>
    <mi>k</mi></msub></math> . Therefore, we can use Naive Bayes model to generate
    new data points together with labels, by sampling from this joint probability
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of a Naive Bayes model is to compute the probability of the class
    <math alttext="y Subscript k"><msub><mi>y</mi> <mi>k</mi></msub></math> given
    the data features <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> , which is the conditional probability <math alttext="p
    left-parenthesis y Subscript k Baseline vertical-bar ModifyingAbove x With right-arrow
    right-parenthesis"><mrow><mi>p</mi> <mo>(</mo> <msub><mi>y</mi> <mi>k</mi></msub>
    <mo>|</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    . For data with many features (high dimensional <math alttext="ModifyingAbove
    x With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    ), this is expensive to compute, so we use Bayes rule and exploit the reverse
    conditional probability, which in turn leads to the joint probability distribution.
    That is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign p left-parenthesis y Subscript k Baseline vertical-bar
    ModifyingAbove x With right-arrow right-parenthesis equals StartFraction p left-parenthesis
    y Subscript k Baseline right-parenthesis p left-parenthesis ModifyingAbove x With
    right-arrow vertical-bar y Subscript k Baseline right-parenthesis Over p left-parenthesis
    ModifyingAbove x With right-arrow right-parenthesis EndFraction equals StartFraction
    p left-parenthesis ModifyingAbove x With right-arrow comma y Subscript k Baseline
    right-parenthesis Over p left-parenthesis ModifyingAbove x With right-arrow right-parenthesis
    EndFraction dollar-sign"><mrow><mi>p</mi> <mrow><mo>(</mo> <msub><mi>y</mi> <mi>k</mi></msub>
    <mo>|</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>p</mi><mrow><mo>(</mo><msub><mi>y</mi> <mi>k</mi></msub>
    <mo>)</mo></mrow><mi>p</mi><mrow><mo>(</mo><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>|</mo><msub><mi>y</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow></mrow> <mrow><mi>p</mi><mo>(</mo><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover><mo>)</mo></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>p</mi><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>,</mo><msub><mi>y</mi> <mi>k</mi></msub>
    <mo>)</mo></mrow> <mrow><mi>p</mi><mo>(</mo><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Naive Bayes model makes the very strong and naive assumption, which in practice
    works better than one might expect, that the data features are mutually independent,
    when conditioned on the class label <math alttext="y Subscript k"><msub><mi>y</mi>
    <mi>k</mi></msub></math> . This assumption helps simplify the joint probability
    distribution in the numerator tremendously, especially when we expand it as a
    product of single variable conditional probabilities. The feature independence
    assumptions conditional on the class label <math alttext="y Subscript k"><msub><mi>y</mi>
    <mi>k</mi></msub></math> means:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign p left-parenthesis x Subscript i Baseline vertical-bar
    x Subscript i plus 1 Baseline comma x Subscript i plus 2 Baseline comma ellipsis
    comma x Subscript n Baseline comma y Subscript k Baseline right-parenthesis equals
    p left-parenthesis x Subscript i Baseline vertical-bar y Subscript k Baseline
    right-parenthesis dollar-sign"><mrow><mi>p</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>|</mo> <msub><mi>x</mi> <mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub>
    <mo>,</mo> <msub><mi>x</mi> <mrow><mi>i</mi><mo>+</mo><mn>2</mn></mrow></msub>
    <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>,</mo>
    <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <mi>p</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>|</mo> <msub><mi>y</mi> <mi>k</mi></msub>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the joint probability distribution factors into:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartLayout 1st Row 1st Column p left-parenthesis
    ModifyingAbove x With right-arrow comma y Subscript k Baseline right-parenthesis
    2nd Column equals p left-parenthesis x 1 vertical-bar x 2 comma ellipsis comma
    x Subscript n Baseline comma y Subscript k Baseline right-parenthesis p left-parenthesis
    x 2 vertical-bar x 3 comma ellipsis comma x Subscript n Baseline comma y Subscript
    k Baseline right-parenthesis ellipsis p left-parenthesis x Subscript n Baseline
    vertical-bar y Subscript k Baseline right-parenthesis p left-parenthesis y Subscript
    k Baseline right-parenthesis 2nd Row 1st Column Blank 2nd Column equals p left-parenthesis
    x 1 vertical-bar y Subscript k Baseline right-parenthesis p left-parenthesis x
    2 vertical-bar y Subscript k Baseline right-parenthesis ellipsis p left-parenthesis
    x Subscript n Baseline vertical-bar y Subscript k Baseline right-parenthesis p
    left-parenthesis y Subscript k Baseline right-parenthesis EndLayout dollar-sign"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>p</mi> <mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo> <msub><mi>y</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mi>p</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>|</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>x</mi> <mi>n</mi></msub>
    <mo>,</mo> <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow> <mi>p</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>|</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>,</mo>
    <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow> <mo>⋯</mo> <mi>p</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>n</mi></msub> <mo>|</mo> <msub><mi>y</mi> <mi>k</mi></msub>
    <mo>)</mo></mrow> <mi>p</mi> <mrow><mo>(</mo> <msub><mi>y</mi> <mi>k</mi></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mo>=</mo>
    <mi>p</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>|</mo> <msub><mi>y</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow> <mi>p</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>|</mo> <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow>
    <mo>⋯</mo> <mi>p</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>|</mo>
    <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow> <mi>p</mi> <mrow><mo>(</mo>
    <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: We can now estimate these single feature probabilities conditioned on each category
    of the data easily from the training data. We can similarly estimate the probability
    of each class <math alttext="p left-parenthesis y Subscript k Baseline right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow></math> from the
    training data, or we can assume the classes are equally likely, so that <math
    alttext="p left-parenthesis y Subscript k Baseline right-parenthesis equals StartFraction
    1 Over number of classes EndFraction"><mrow><mi>p</mi> <mrow><mo>(</mo> <msub><mi>y</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mtext>number</mtext><mtext>of</mtext><mtext>classes</mtext></mrow></mfrac></mrow></math>
    .
  prefs: []
  type: TYPE_NORMAL
- en: Note that in general, generative models find the joint probability distibution
    <math alttext="p left-parenthesis ModifyingAbove x With right-arrow comma ModifyingAbove
    y Subscript k Baseline With right-arrow right-parenthesis"><mrow><mi>p</mi> <mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><msub><mi>y</mi>
    <mi>k</mi></msub> <mo>→</mo></mover> <mo>)</mo></mrow></math> , between labels
    <math alttext="y Subscript k"><msub><mi>y</mi> <mi>k</mi></msub></math> and data
    <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> . Classification models, on the other hand, calculate
    the conditional probabilities <math alttext="p left-parenthesis y Subscript k
    Baseline vertical-bar ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <msub><mi>y</mi> <mi>k</mi></msub> <mo>|</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> . They focus on calculating the decision
    boundaries between different classes in the data by returning the class <math
    alttext="y Subscript k"><msub><mi>y</mi> <mi>k</mi></msub></math> with the highest
    probability. So for Naive Bayes classifier, it returns the label <math alttext="y
    Subscript asterisk"><msub><mi>y</mi> <mo>*</mo></msub></math> with the highest
    value for <math alttext="p left-parenthesis y Subscript k Baseline vertical-bar
    ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>p</mi> <mo>(</mo>
    <msub><mi>y</mi> <mi>k</mi></msub> <mo>|</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> , which is the same as the highest
    value for <math alttext="p left-parenthesis x 1 vertical-bar y Subscript k Baseline
    right-parenthesis p left-parenthesis x 2 vertical-bar y Subscript k Baseline right-parenthesis
    ellipsis p left-parenthesis x Subscript n Baseline vertical-bar y Subscript k
    Baseline right-parenthesis p left-parenthesis y Subscript k Baseline right-parenthesis"><mrow><mi>p</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>|</mo> <msub><mi>y</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow> <mi>p</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>|</mo> <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow>
    <mo>⋯</mo> <mi>p</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>|</mo>
    <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow> <mi>p</mi> <mrow><mo>(</mo>
    <msub><mi>y</mi> <mi>k</mi></msub> <mo>)</mo></mrow></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian Mixture Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In a Gaussian mixture model, we assume that all the data points are generated
    from a mixture of a finite number of Gaussian distributions with unknown parameters
    (means and covariance matrices). We can think of mixture models as being similar
    to k-means clustering, but here we include information about the centers of the
    clusters (means of our Gaussians) along with the shape of the spread of the data
    in each cluster (determined by the covariance of the Gaussians). In order to determine
    the number of clusters in the data, Gaussian mixture models sometimes implement
    [the Bayesian information criterion](https://en.wikipedia.org/wiki/Bayesian_information_criterion).
    We can also retrict our model in order to control the covariance of the different
    Gaussians in the mixture: Full, Tied, Diagonal, Tied Diagonal, and Spherical (see
    [Figure 8-3](#Fig_Gaussian_covariance) for illustration).'
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_0803.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-3\. Gaussian mixture covariance types ([imagesource](https://i.stack.imgur.com/0zLpe.png)).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We finally need to maximize the likelihood of the data in order to estimate
    unknown parameters of the mixture (means and entries of the covariance matrices).
  prefs: []
  type: TYPE_NORMAL
- en: 'Maximum likelihood becomes intractable when there are latent or hidden variables
    in the data (variables that are not directly measured or observed). The way around
    this is to use an [expectation maximization (EM) algorithm](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm)
    in order to estimate the maximum likelihood. Expectation Maximization algorithm
    works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Estimate the values for the latent variables by creating a function for the
    expectation of the log-likelihood using the current estimate for the unknown parameters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Optimize: Compute new parameters that maximize the expected log-likelihood
    evaluated in the previous step.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat the above two steps until convergence.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can see how Gaussian Mixture models can be used as clustering, generative,
    or classification models. For clustering: This is the main part of the model build
    up. For generation: Sample new data points from the mixture after computing the
    unknown parameters via Expectation Maximization. For classification: Given a new
    data point, the model assigns it to the Gaussian it mostly probably belongs.'
  prefs: []
  type: TYPE_NORMAL
- en: The Evolution Of Generative Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we tell the story that contributed to ending the winter of
    neural networks, and ultimately led to modern probabilitistic deep learning models,
    such as variational autoencoders, fully visibile deep belief networks, and generative
    adversarial networks. We encounter the progression from Hopfield nets to Boltzmann
    Machines to Restricted Boltzmann Machines. I have a special affinity for these
    models: In addition to their historical value, learning the joint probability
    distribution of the features of the data by assembling a network of basic computional
    units, they employ the mathematical machinery of the extremely neat and well developed
    field of *statistical mechanics*, my initial area of research.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In statistical mechanics, we define probability distributions in terms of energy
    functions. The probability of us finding a system in a certain state <math alttext="ModifyingAbove
    x With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    depends on its energy <math alttext="upper E left-parenthesis ModifyingAbove x
    With right-arrow right-parenthesis"><mrow><mi>E</mi> <mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> at that state. More precisely, high
    energy states are less probable, which manifests itself in the negative sign in
    the exponential in the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign p left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis equals StartFraction e x p left-parenthesis minus upper E left-parenthesis
    ModifyingAbove x With right-arrow right-parenthesis right-parenthesis Over upper
    Z EndFraction period dollar-sign"><mrow><mi>p</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mo>-</mo><mi>E</mi><mrow><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow><mo>)</mo></mrow>
    <mi>Z</mi></mfrac> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The exponential function guarantees that *p* is positive, and the *partition
    function Z* in the denominator esures that the sum (or integral if *x* is continuous)
    of <math alttext="p left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    over all states <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> is one, making *p* a valid probability distribution.
    Machine learning models that define joint probability distributions this way are
    called *energy based models*, for the obvious reasons. They differ in how they
    assign the energy at each state, meaning in the specific formula they use for
    <math alttext="upper E left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>E</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    , which in turn affects the formula for the partition function *Z*. The formula
    for <math alttext="upper E left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis"><mrow><mi>E</mi> <mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> is the one that contains the paramters
    of the model <math alttext="ModifyingAbove theta With right-arrow"><mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover></math> , which we need to compute from the data using maximumum
    likelihood estimation. In fact, it is better if we have the dependence of *p*,
    *E*, and *Z* on <math alttext="ModifyingAbove theta With right-arrow"><mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover></math> explicit in the joint probability ditribution formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign p left-parenthesis ModifyingAbove x With right-arrow
    comma ModifyingAbove theta With right-arrow right-parenthesis equals StartFraction
    e x p left-parenthesis minus upper E left-parenthesis ModifyingAbove x With right-arrow
    comma ModifyingAbove theta With right-arrow right-parenthesis right-parenthesis
    Over upper Z left-parenthesis ModifyingAbove theta With right-arrow right-parenthesis
    EndFraction period dollar-sign"><mrow><mi>p</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><mi>θ</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mo>-</mo><mi>E</mi><mrow><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>,</mo><mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover><mo>)</mo></mrow><mo>)</mo></mrow> <mrow><mi>Z</mi><mo>(</mo><mover
    accent="true"><mi>θ</mi> <mo>→</mo></mover><mo>)</mo></mrow></mfrac> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'In most cases, it is not possible to compute a closed formula for the partition
    function *Z*, rendering the maximum likelihood estimation intractable. More precisely,
    when we maximize the loglikelihood, we need to compute its gradient, which includes
    computing its gradient with repect to the parameters <math alttext="ModifyingAbove
    theta With right-arrow"><mover accent="true"><mi>θ</mi> <mo>→</mo></mover></math>
    , which in turn forces us to compute the gradient of the partition function *Z*
    with repect to <math alttext="ModifyingAbove theta With right-arrow"><mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover></math> . The following quantity appears frequently in these
    computations:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign normal nabla Subscript ModifyingAbove theta With
    right-arrow Baseline log upper Z left-parenthesis ModifyingAbove theta With right-arrow
    right-parenthesis equals double-struck upper E Subscript ModifyingAbove x With
    right-arrow tilde p left-parenthesis ModifyingAbove x With right-arrow right-parenthesis
    Baseline left-parenthesis normal nabla Subscript ModifyingAbove theta With right-arrow
    Baseline log left-parenthesis n u m e r a t o r left-parenthesis ModifyingAbove
    x With right-arrow comma ModifyingAbove theta With right-arrow right-parenthesis
    right-parenthesis dollar-sign"><mrow><msub><mi>∇</mi> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover></msub> <mo form="prefix">log</mo> <mi>Z</mi> <mrow><mo>(</mo>
    <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>=</mo>
    <msub><mi>𝔼</mi> <mrow><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>∼</mo><mi>p</mi><mrow><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow></mrow></msub> <mrow><mo>(</mo></mrow>
    <msub><mi>∇</mi> <mover accent="true"><mi>θ</mi> <mo>→</mo></mover></msub> <mo
    form="prefix">log</mo> <mrow><mo>(</mo> <mi>n</mi> <mi>u</mi> <mi>m</mi> <mi>e</mi>
    <mi>r</mi> <mi>a</mi> <mi>t</mi> <mi>o</mi> <mi>r</mi> <mrow><mo>(</mo> <mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where in our case the numerator in the formula of the energy based joint probability
    distribution is <math alttext="e x p left-parenthesis minus upper E left-parenthesis
    ModifyingAbove x With right-arrow comma ModifyingAbove theta With right-arrow
    right-parenthesis right-parenthesis"><mrow><mi>e</mi> <mi>x</mi> <mi>p</mi> <mo>(</mo>
    <mo>-</mo> <mi>E</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>,</mo> <mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>)</mo></mrow></math> , but this can also differ among models.
  prefs: []
  type: TYPE_NORMAL
- en: The cases where the partition function is intractable urges us to resort to
    approximation methods such as stochastic maximum likelihood and contrastive divergence.
    Other methods, sidestep approximating the partition function and compute conditional
    probabilities without knowledge of the partition function. They take advantage
    of the ratio definition of conditional probabilities along with the ratio in the
    definition of an energy based joint probability distribution, effectively canceling
    out the partition function. These methods include score matching, ratio matching,
    and denoising score matching.
  prefs: []
  type: TYPE_NORMAL
- en: Other methods, such as noise contrastive estimation, annealed importance sampling,
    bridge sampling, or a combination of those relying on the strengths of each, approximate
    the partition function directly, not the log of its gradient.
  prefs: []
  type: TYPE_NORMAL
- en: We will not discuss any of these methods here. Instead we refer interested readers
    to [Deep Learning Book by Ian Goodfellow (2016)](https://www.deeplearningbook.org/contents/partition.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: 'Back to Hopfield nets and Boltzmann machines: These are the stepping stones
    to deep neural networks which are trained through back propagation that both recent
    deterministic and probabilistic deep learning models rely on. These methods form
    the original *connectionist* (of neurons) approach to learning arbitrary probability
    distributions, initially only over binary vectors of zeros and ones, and later
    over vectors with arbitrary real number values.'
  prefs: []
  type: TYPE_NORMAL
- en: Hopfield Nets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hopfield nets take advantage of the elegant mathematics of statistical mechanics
    by identifying the states of neurons of an artificial neural network with the
    states of elements in a physical system. Even though Hopfield nets eventually
    proved to be computationally expensive and of limited practical use, they are
    the founding fathers of the modern era of neural networks, and they are worth
    exploring if only to gauge the historical evolution of AI field. Hopfield nets
    have no hidden units, and all their (visible) units are connected to each other.
    Each unit can be found in an *on* or *off* state (one or zero), and collectively
    they encode information about the whole network (or the system).
  prefs: []
  type: TYPE_NORMAL
- en: Boltzmann Machine
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Boltzmann machine is a Hopfield net, but with the addition of hidden units.
    We are already familiar with the structure of input units and hidden units in
    neural networks, so no need to explain them, but this is where they started. Similar
    to Hopfield net, both input and hidden units are binary, where the states that
    are either 0 or 1 (modern versions implement units that take real number values
    not only binary values).
  prefs: []
  type: TYPE_NORMAL
- en: All Boltzmann machines have an intractable partition function, so we approximate
    the maximum likelihood gradient using the techniques surveyed at the introduction
    of this section.
  prefs: []
  type: TYPE_NORMAL
- en: Boltzmann machines rely only on the computationally intensive *Gibbs sampling*
    for their training. Gibbs is a name that appears repetitively in the statistical
    mechanics field. Gibbs sampling provides unbiased estimates of the weights of
    the network, but these estimates have high variance. In general, there is a tradeoff
    between bias and variance, and this tradeoff highlights the advantages and disadvantages
    of methods relying on each.
  prefs: []
  type: TYPE_NORMAL
- en: Restricted Boltzmann Machine (Explicit Density And Intractable)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Boltzmann machines have a very slow learning rate due to the many inter-connections
    within visible layers and within hidden layers (think a very messy backpropagation).
    This makes their training very slow and prohibits their application to practical
    problems. Restricted Boltzmann machines, which restrict connections only to those
    between different layers, solve this problem. That is, there are no connections
    within each layer of a restricted Boltzmann machine, allowing all of the units
    in each layer can be updated simultaneously. Therefore, for two connected layers,
    we can collect co-occurrence statistics by alternately updating all of the units
    in each layer. In practice, there are larger savings because of minimal sampling
    procedures such as contrastive divergence.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional Independence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The lack of connections within each layer means that the states of all units
    in the hidden layer do not depend on each other, but they do depend on the states
    of units in the previous layer. In other words, given the states of the previous
    layer’s units, the state of each hidden unit is independent of the states of the
    other units in the hidden layer. This conditional independence allows us to factorize
    the joint probability of the state of a hidden layer <math alttext="p left-parenthesis
    ModifyingAbove h With right-arrow vertical-bar ModifyingAbove h Subscript p r
    e v i o u s Baseline With right-arrow right-parenthesis"><mrow><mi>p</mi> <mo>(</mo>
    <mover accent="true"><mi>h</mi> <mo>→</mo></mover> <mo>|</mo> <mover accent="true"><msub><mi>h</mi>
    <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>v</mi><mi>i</mi><mi>o</mi><mi>u</mi><mi>s</mi></mrow></msub>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> as the product of individual hidden
    unit’s state’s conditional probabilities. For example, if we have three units
    in a hidden layer, <math alttext="p left-parenthesis ModifyingAbove h With right-arrow
    vertical-bar ModifyingAbove h Subscript p r e v i o u s Baseline With right-arrow
    right-parenthesis equals p left-parenthesis h Baseline 1 vertical-bar ModifyingAbove
    h Subscript p r e v i o u s Baseline With right-arrow right-parenthesis p left-parenthesis
    h Baseline 2 vertical-bar ModifyingAbove h Subscript p r e v i o u s Baseline
    With right-arrow right-parenthesis p left-parenthesis h Baseline 3 vertical-bar
    ModifyingAbove h Subscript p r e v i o u s Baseline With right-arrow right-parenthesis"><mrow><mi>p</mi>
    <mrow><mo>(</mo> <mover accent="true"><mi>h</mi> <mo>→</mo></mover> <mo>|</mo>
    <mover accent="true"><msub><mi>h</mi> <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>v</mi><mi>i</mi><mi>o</mi><mi>u</mi><mi>s</mi></mrow></msub>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>=</mo> <mi>p</mi> <mrow><mo>(</mo> <mi>h</mi>
    <mn>1</mn> <mo>|</mo> <mover accent="true"><msub><mi>h</mi> <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>v</mi><mi>i</mi><mi>o</mi><mi>u</mi><mi>s</mi></mrow></msub>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mi>p</mi> <mrow><mo>(</mo> <mi>h</mi> <mn>2</mn>
    <mo>|</mo> <mover accent="true"><msub><mi>h</mi> <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>v</mi><mi>i</mi><mi>o</mi><mi>u</mi><mi>s</mi></mrow></msub>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mi>p</mi> <mrow><mo>(</mo> <mi>h</mi> <mn>3</mn>
    <mo>|</mo> <mover accent="true"><msub><mi>h</mi> <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>v</mi><mi>i</mi><mi>o</mi><mi>u</mi><mi>s</mi></mrow></msub>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> . The other way is also true,
    the states of the units of a previous layer units are conditionally independent
    of each other given the states of the current layer. This conditional independence
    means that we can sample unit states instead of iteratively updating them for
    long periods of time.
  prefs: []
  type: TYPE_NORMAL
- en: Universal Approximation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The restricted connections in restricted Boltzmann machines allow for their
    stacking, that is, having a series of multiple hidden layers that are able to
    extract more complex features. We can see now how the architecture of the modern
    multilayer artificial neural network slowly emerged. Recall that in chapter four,
    we discussed the universal approximation of neural networks for a wide range of
    deterministic functions. In this chapter, we would like our networks to represent
    (or learn) joint probability distributions instead of deterministic function.
    In 2008, Le Roux and Bengio proved that Boltzmann machines can approximate any
    discrete probability distribution to an arbitrary accuracy. This result also applies
    to restricted Boltzmann machines. Moreover, under certain mild conditions, each
    additional hidden layer increases the value of the log likelihood function, thus
    gets allows the model distribution to be closer to the true joint probability
    distribution of the training set.
  prefs: []
  type: TYPE_NORMAL
- en: In 2015, Eldan and Shamir verified emperically that increasing the number of
    layers of the neural networks is exponentially more valuable than increasing the
    width of network layers the number of units in each layer (depth *vs* width).
    We also know from practice (without proofs) that it is possible to train a network
    with hundreds of hidden layers, where deeper layers represent higher-order features.
    Historically, the problem of vanishing gradients had to be overcome in order to
    train deep networks.
  prefs: []
  type: TYPE_NORMAL
- en: The Original Autoencoder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The autoencoder architecture aims to compress the information of the input
    into its lower dimensional hidden layers. The hidden layers should retain the
    same amount of information as the input layers, even when they have fewer units
    than the input layers. We have discussed modern variational autoencoders, which
    provide an efficient method for training autoencoder networks. During training,
    each vector should be mapped to itself (unsupervised), and the network tries to
    learn the best *encoding*. The input and the output layers must then have the
    same number of units. A Boltzman machine set up with a certain number of input
    units, fewer number of hidden units, and an output layer with the same number
    of units as the input layer, explains an original network autoencoder architecture.
    From a historical perspective this is significant: The autoencoder is of the first
    examples of a network successfully learning a code, implicit in the states of
    the hidden units, to represent its inputs. This made it possible to force a network
    to compress its input into a hidden layer with minimal loss of information. This
    is now an integral part of neural networks that we take for granted. The autoencoder
    architecture, with and without Boltzmann machines (with and without energy based
    joint probability distribution), is still very influential in the deep learning
    world.'
  prefs: []
  type: TYPE_NORMAL
- en: Earlier in this chapter, we discussed variational autoencoders. From a historical
    point of view, these synthesize the ideas of Boltzmann machine autoencoders, deep
    autoencoder networks, *denoising autoencoders*, and the information bottleneck
    (Tishby et al., 2000), which have their roots in the idea of analysis by synthesis
    (Selfridge, 1958). Variational autoencoders use fast variational methods for their
    learning. In the context of bias-variance tradeoff, variational methods provide
    biased estimates for the network’s weights that have low variance.
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic Language Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A natural connection between this chapter and [Chapter 6](ch06.xhtml#ch06),
    which focused almost exclusively on natural language processing and the various
    ways to extract meaning from natural language data, to this chapter, is to survey
    the fundamentals behind probabilistic language models, then to highlights the
    models from the previous chapter that adhere to these fundamentals.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter started with maximum likelihood estimation. One of the reasons
    this appears everywhere when we need to estimate probability distributions is
    that the probability distribution attained via maximum likelihood estimation is
    supported by mathematical theory, under couple conditions: Maximum likelihood
    estimation does converge to the true distribution <math alttext="p Subscript d
    a t a Baseline left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    that generated the data, in the limit as the number of data samples goes to infinity
    (that is, assuming we have a ton of data), and provided that the model probability
    distribution <math alttext="p Subscript m o d e l Baseline left-parenthesis ModifyingAbove
    x With right-arrow comma ModifyingAbove theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> already includes the true probability
    distribution. That is, in the limit as the number of samples goes to infinity,
    the model parameters <math alttext="ModifyingAbove theta With right-arrow Superscript
    asterisk"><msup><mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>*</mo></msup></math>
    that will maximize the likelihood of the data satisfy: <math alttext="p Subscript
    m o d e l Baseline left-parenthesis ModifyingAbove x With right-arrow comma ModifyingAbove
    theta With right-arrow Superscript asterisk Baseline right-parenthesis equals
    p Subscript d a t a Baseline left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo>
    <msup><mover accent="true"><mi>θ</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
    .'
  prefs: []
  type: TYPE_NORMAL
- en: In language models, the training data is samples of text from some corpus and/or
    genre, and we would like to learn its probability distribution so that we can
    generate similar text. It is important to keep in mind that the true data distribution
    is most likely *not* included in the family of distributions provided by <math
    alttext="p Subscript m o d e l Baseline left-parenthesis ModifyingAbove x With
    right-arrow comma ModifyingAbove theta With right-arrow right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> , so the theoretical result
    in the previous paragraph might never hold in practice, however, this doesn’t
    deter us and we usually settle for models that are useful enough for our purposes.
    Our goal is to build a model that assigns probabilities to pieces of language.
    If we randomly assemble some pieces of language, we most likely end up with gibberish.
    What we actually want is to find the distribution of those sentences that mean
    something. A good language model is one that assigns high probabilities to sentences
    that are meaningful, even when these sentences are not among the training data.
    People usually compute the *perplexity* of a language model on the training data
    set to evaluate its performance.
  prefs: []
  type: TYPE_NORMAL
- en: Language models are based on the assumption that the probability distribution
    of the next word depends on the *n-1* words that preceded it, for some fixed *n*,
    so we care about calculating <math alttext="p Subscript m o d e l Baseline left-parenthesis
    x Subscript n Baseline vertical-bar x 1 comma x 2 comma ellipsis comma x Subscript
    n minus 1 Baseline right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>|</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo>
    <mo>,</mo> <msub><mi>x</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>)</mo></mrow></mrow></math> . If we are using a word2vec model, that embeds
    the meaning of each word in vector, then each of these *x*’s is represented by
    a vector. Words which mean things or are frequently used in similar contexts tend
    to have similar vector values. We can use the transformer model from the previous
    chapter to predict the next word vector based on the preceding word vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Frequency based language models construct conditional probability tables by
    counting the number of times words appear together in the training corpus. For
    example, we can estimate the conditional probability p(morning|good) of the word
    *morning* appearing after the word *good*, by counting by the number of times
    *good morning* appears in the corpus divided by the number of times *good* appears
    in the corpus. That is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign p left-parenthesis m o r n i n g vertical-bar g o
    o d right-parenthesis equals StartFraction p left-parenthesis g o o d comma m
    o r n i n g right-parenthesis Over p left-parenthesis g o o d right-parenthesis
    EndFraction dollar-sign"><mrow><mi>p</mi> <mrow><mo>(</mo> <mi>m</mi> <mi>o</mi>
    <mi>r</mi> <mi>n</mi> <mi>i</mi> <mi>n</mi> <mi>g</mi> <mo>|</mo> <mi>g</mi> <mi>o</mi>
    <mi>o</mi> <mi>d</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>p</mi><mo>(</mo><mi>g</mi><mi>o</mi><mi>o</mi><mi>d</mi><mo>,</mo><mi>m</mi><mi>o</mi><mi>r</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo>)</mo></mrow>
    <mrow><mi>p</mi><mo>(</mo><mi>g</mi><mi>o</mi><mi>o</mi><mi>d</mi><mo>)</mo></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This breaks down for very large corpuses or for unstructured text data such
    as tweets, facebook comments, or sms messages where the usual rules of grammar/spelling,
    *etc.* are not totally adhered to.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can formalize the notion of a probabilistic language model this way:'
  prefs: []
  type: TYPE_NORMAL
- en: Specify the vocabulary *V* of your language. This could be a set of characters,
    spaces, punctuations, symbols, unique words, and/ or n-grams. Mathematically,
    it is a finite discrete set that includes a stopping symbol signifying the end
    of a thought or sentence, like a period in English (even though a period does
    not always mean the end of a sentence in English, such as when it is used for
    abbreviations).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a sentence (which could be meaningful or not) as a finite sequence of
    symbols <math alttext="ModifyingAbove x With right-arrow equals left-parenthesis
    x 1 comma x 2 comma ellipsis comma x Subscript m Baseline right-parenthesis"><mrow><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>=</mo> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo>
    <mo>,</mo> <msub><mi>x</mi> <mi>m</mi></msub> <mo>)</mo></mrow></mrow></math>
    from the vocabulary *V* ending in the stop symbol. Each <math alttext="x Subscript
    i"><msub><mi>x</mi> <mi>i</mi></msub></math> can assume any value from the vocabulary
    *V*. We can specify *m* as a maximum length for our sentences.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Define our language space <math alttext="l Superscript m Baseline equals StartSet
    left-parenthesis x 1 comma x 2 comma ellipsis comma x Subscript m Baseline right-parenthesis
    comma x Subscript i Baseline element-of upper V EndSet"><mrow><msup><mi>l</mi>
    <mi>m</mi></msup> <mo>=</mo> <mrow><mo>{</mo> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo>
    <mo>,</mo> <msub><mi>x</mi> <mi>m</mi></msub> <mo>)</mo></mrow> <mo>,</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>∈</mo> <mi>V</mi> <mo>}</mo></mrow></mrow></math> as the
    set of all sentences of length less than or equal to *m*. The overwhelming majority
    of these sentences will mean nothing, and we need to define a language model that
    only captures the sentences that mean something: High probabilities for meaningful
    sentences and low probabilities for unmeaningful ones.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let <math alttext="script upper L"><mi>ℒ</mi></math> be the collection of all
    subsets of <math alttext="l Superscript m"><msup><mi>l</mi> <mi>m</mi></msup></math>
    . This accounts for collections of all meaningful and meaningless sentences of
    maximal length *m*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In rigorous probability theory, we usually start with probability triples:
    A space, a *sigma algebra* containing some subsets of that space, and a probability
    measure assigned to each member of the chosen sigma algebra (do not worry about
    these details in this chapter). A language model, in this context, is the probability
    triple: The language space <math alttext="l Superscript m"><msup><mi>l</mi> <mi>m</mi></msup></math>
    , the sigma algebra made up of all the subsets of the language space <math alttext="script
    upper L"><mi>ℒ</mi></math> , and a probability measure *P* that we need to assign
    to each member of <math alttext="script upper L"><mi>ℒ</mi></math> . Since our
    language space is discrete and finite, it is easier to assign a probability *p*
    to each member of <math alttext="l Superscript m"><msup><mi>l</mi> <mi>m</mi></msup></math>
    instead, that is a probability to each sentence <math alttext="ModifyingAbove
    x With right-arrow equals left-parenthesis x 1 comma x 2 comma ellipsis comma
    x Subscript m Baseline right-parenthesis"><mrow><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>=</mo> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo> <mo>,</mo>
    <msub><mi>x</mi> <mi>m</mi></msub> <mo>)</mo></mrow></mrow></math> (since this
    will in turn induce a probability measure *P* on the collection of all subsets
    <math alttext="script upper L"><mi>ℒ</mi></math> , so we will never worry about
    this for language models). It is this *p* that we need to learn from the training
    data. The usual approach is to select a full family of probability distributions
    <math alttext="p left-parenthesis ModifyingAbove x With right-arrow semicolon
    ModifyingAbove theta With right-arrow right-parenthesis"><mrow><mi>p</mi> <mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo> <mover accent="true"><mi>θ</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> prametrized by <math alttext="ModifyingAbove
    theta With right-arrow"><mover accent="true"><mi>θ</mi> <mo>→</mo></mover></math>
    .'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we need to estimate the parameters <math alttext="ModifyingAbove theta
    With right-arrow"><mover accent="true"><mi>θ</mi> <mo>→</mo></mover></math> by
    maximizing the likelihood of the training dataset that contains many sentence
    samples from <math alttext="l Superscript m"><msup><mi>l</mi> <mi>m</mi></msup></math>
    . Since the probabilities of meaningful sentences are very small numbers, we use
    the logarithm of these probabilities instead in order to avoid the risk of underflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For consistency, it is a nice exercise to check Log-linear models and Log-bilinear
    models (GloVe) and latent Dirichlet allocation from [Chapter 7](ch07.xhtml#ch07)
    in the context of this section.
  prefs: []
  type: TYPE_NORMAL
- en: Summary And Looking Ahead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This was another foundational chapter in our journey to pinpointing the mathematics
    that is required for the state of the art AI models. We shifted from learning
    deterministic functions in earlier chapters to learning joint probability distributions
    of features of the data. The goal is to use those to generate new data similar
    to the training data. We learned, still without formalizing, a lot of properties
    and rules for probability distributions. We surveyed the most relevant models,
    along with some historical evolution that led us here. We made the distinction
    between models that provide explicit formulas for their joint distributions, and
    models which interact indirectly with the underlying distribution without explicitly
    writing down formulas. For models with explicit formulas, computing the log likelihood
    and its gradients can be tractable or intractable, each of which requires its
    own methods. The goal is always the same: Capture the underlying true joint probability
    ditribution of the data, by finding a model that maximizes its log likelihood.'
  prefs: []
  type: TYPE_NORMAL
- en: None of this would have been necessary if our data was low dimensional, with
    one or two features. Histograms and kernel density estimators do a good job estimating
    probability distributions for low dimensional data. One of the best accomplishments
    in machine learning is the ability to model high-dimensional joint probability
    distributions from a big volume of data.
  prefs: []
  type: TYPE_NORMAL
- en: All of the approaches that we presented in this chapter have their pros and
    cons. For example, variational autoencoders allow us to perform both learning
    and efficient Bayesian inference in probabilistic graphical models with hidden
    (latent) variables. However, they generate lower quality samples. Generative adversarial
    networks generate better samples, but they are more difficult to optimize due
    to their unstable training dynamics. They search for an unstable saddle point
    instead of a stable maximum or minimum. Deep belief networks such as PixelCNN
    and WaveNet have a stable training process, optimizing the softmax loss function.
    However, they are inefficient during sampling and don’t organically embed data
    into lower dimensions, as autoencoders do.
  prefs: []
  type: TYPE_NORMAL
- en: Two player zero sum games from Game Theory appeared naturally in this chapter
    due to the set up of generative adversarial networks.
  prefs: []
  type: TYPE_NORMAL
- en: Looking ahead into the next chapter on *graphical modeling*, we note that the
    connections in the graph of a neural network dictate the way we can write conditional
    probabilities, easily pointing out the various dependencies and conditional independences.
    We saw this while discussing restricted Boltzmann machines in this chapter. In
    the next chapter, we focus exclusively on graphical modeling, which we have managed
    to avoid for a good three quarters of the book.
  prefs: []
  type: TYPE_NORMAL
