<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 22. Conclusion" data-type="chapter" epub:type="chapter"><div class="chapter" id="chapter_conclusion">
<h1><span class="label">Chapter 22. </span>Conclusion</h1>
<p>Although this book had a guiding narrative—the transformation of some basic Wikipedia HTML pages into a modern, interactive JavaScript web visualization—it is meant to be dipped into as and when required. The different parts are self-contained, allowing for the existence of the dataset in its various stages, and can be used independently. Let’s have a short recap of what was covered before moving on to a few ideas for future visualization work.</p>
<section data-pdf-bookmark="Recap" data-type="sect1"><div class="sect1" id="idm45607734740096">
<h1>Recap</h1>
<p>This book was divided into five parts. The first part introduced a basic Python and JavaScript dataviz toolkit, while the next four showed how to retrieve raw data, clean it, explore it, and finally transform it into a modern web visualization. This process of refinement and transformation used as its backbone a dataviz challenge: to take a fairly basic Wikipedia Nobel Prize list and transform the dataset contained into something more engaging and informative. Let’s summarize the key lessons of each part now.</p>
<section data-pdf-bookmark="Part I: Basic Toolkit" data-type="sect2"><div class="sect2" id="idm45607734738464">
<h2>Part I: Basic Toolkit</h2>
<p>Our basic toolkit consisted of:</p>
<ul>
<li>
<p>A language-learning bridge between Python and JavaScript.<a data-primary="dataviz" data-secondary="basic toolkit" data-type="indexterm" id="idm45607734735984"/><a data-primary="tools" data-secondary="basic toolkit for data visualization" data-type="indexterm" id="idm45607734735008"/> This was designed to smooth the transition between the two languages, highlighting their many similarities and setting the scene for the bilingual process of modern dataviz. Python and JavaScript share even more in common, making switching between them that much less stressful.</p>
</li>
<li>
<p>Being able to read from and write to the key data formats (e.g., JSON and CSV) and databases (both SQL and NoSQL) with ease is one of Python’s great strengths. <a data-primary="Python" data-secondary="reading and writing to key data formats" data-type="indexterm" id="idm45607734733088"/><a data-primary="databases" data-type="indexterm" id="idm45607734732096"/><a data-primary="JSON" data-type="indexterm" id="idm45607734731424"/><a data-primary="CSV files" data-type="indexterm" id="idm45607734730752"/><a data-primary="SQL" data-type="indexterm" id="idm45607734730080"/>We saw how easy it is to pass data around in Python, translating formats and changing databases as we go. This fluid movement of data is the main lubricant of any dataviz toolchain.</p>
</li>
<li>
<p>We covered the basic web development (webdev) skills needed to start producing modern, interactive, browser-based dataviz. <a data-primary="web development (webdev)" data-type="indexterm" id="idm45607734728448"/>By focusing on the concept of the <a href="https://oreil.ly/v0vDP">single-page application</a> rather than building whole websites, we minimize conventional webdev and place the emphasis on programming your visual creations in JavaScript. An introduction to Scalable Vector Graphics (SVG), the chief building block of D3 visualizations, set the scene for the creation of our Nobel Prize visualization in <a data-type="xref" href="part05.xhtml#part_viz">Part V</a>.</p>
</li>
</ul>
</div></section>
<section data-pdf-bookmark="Part II: Getting Your Data" data-type="sect2"><div class="sect2" id="idm45607734725504">
<h2>Part II: Getting Your Data</h2>
<p>In this <a data-primary="data" data-secondary="getting" data-type="indexterm" id="idm45607734724160"/>part of the book, we looked at how to get data from the web using Python, assuming a nice, clean data file hasn’t been provided to the data visualizer:</p>
<ul>
<li>
<p>If you’re lucky, a clean file in an easily usable data format (i.e., JSON or CSV) is at an open URL, a simple HTTP request away. Alternatively, there may be a dedicated web API for your dataset, with any luck a RESTful one. As an example, we looked at using the Twitter API (via Python’s Tweepy library). We also saw how to use Google spreadsheets, a widely used data-sharing resource in dataviz.</p>
</li>
<li>
<p>Things get more involved when the data of interest is present on the web in human-readable form, often in HTML tables, lists, or hierarchical content blocks. <a data-primary="scraping data" data-type="indexterm" id="idm45607734721136"/>In this case, you have to resort to <em>scraping</em>, getting the raw HTML content and then using a parser to make its embedded content available. We saw how to use Python’s lightweight Beautiful Soup scraping library and the much more featureful and heavyweight Scrapy, the biggest star in the Python scraping firmament.</p>
</li>
</ul>
</div></section>
<section data-pdf-bookmark="Part III: Cleaning and Exploring Data with pandas" data-type="sect2"><div class="sect2" id="idm45607734719360">
<h2>Part III: Cleaning and Exploring Data with pandas</h2>
<p>In this part, we turned the big guns of pandas, Python’s powerful programmatic spreadsheet, on the problem of cleaning and then exploring datasets.<a data-primary="pandas" data-secondary="cleaning and exploring data with" data-type="indexterm" id="idm45607734718064"/><a data-primary="data" data-secondary="cleaning and exploring with pandas" data-type="indexterm" id="idm45607734717024"/> We first saw how pandas is part of Python’s NumPy ecosystem, leveraging the power of very fast, powerful low-level array processing libraries but making them accessible. The focus was on using pandas to clean and then explore our Nobel Prize dataset:</p>
<ul>
<li>
<p>Most data, even that which comes from official web APIs, is dirty. And making it clean and usable will occupy far more of your time as a data visualizer than you probably anticipated. Taking the Nobel dataset as an example, we progressively cleaned it, searching for dodgy dates, anomalous datatypes, missing fields, and all the common grime that needs cleaning before you can start to explore and then transform your data into a visualization.</p>
</li>
<li>
<p>With our clean (as we could make it) Nobel Prize dataset in hand, we saw how easy it is to use pandas and Matplotlib to interactively explore data, easily creating inline charts, slicing the data every which way, and generally getting a feel for it, while looking for those interesting nuggets you want to deliver with visualization.</p>
</li>
</ul>
</div></section>
<section data-pdf-bookmark="Part IV: Delivering the Data" data-type="sect2"><div class="sect2" id="idm45607734713536">
<h2>Part IV: Delivering the Data</h2>
<p>In this part, we saw how easy it is to create a minimal data API using Flask, to deliver data both statically and dynamically to the web browser.<a data-primary="delivering data" data-type="indexterm" id="idm45607734712080"/><a data-primary="data" data-secondary="delivering" data-type="indexterm" id="idm45607734711376"/></p>
<p>First, we saw how to use Flask to serve static files and then how to roll your own basic data API, serving data from a local database.<a data-primary="Flask" data-secondary="serving data with" data-type="indexterm" id="idm45607734710048"/> Flask’s minimalism allows you to create a very thin data-serving layer between the fruits of your Python data processing and their eventual visualization on the browser.
The glory of open source software is that you can often find robust, easy-to-use libraries that solve your problem better than you could. In the second chapter of this part, we saw how easy it is to use best-of-breed Python (Flask) libraries to craft a robust, flexible RESTful API, ready to server your data online.<a data-primary="Flask" data-secondary="creating a RESTful API" data-type="indexterm" id="idm45607734708944"/><a data-primary="RESTful APIs" data-secondary="creating with Flask" data-type="indexterm" id="idm45607734708000"/> We also covered the easy online deployment of this data server using Heroku, a favorite of Pythonistas.</p>
</div></section>
<section data-pdf-bookmark="Part V: Visualizing Your Data with D3 and Plotly" data-type="sect2"><div class="sect2" id="idm45607734706544">
<h2>Part V: Visualizing Your Data with D3 and Plotly</h2>
<p>In the first chapter of this part, we saw how to take the fruits of your pandas-driven exploration, in the form of charts or maps, and put them on the web, where they belong.<a data-primary="D3 library" data-secondary="visualizing data with" data-type="indexterm" id="idm45607734705280"/><a data-primary="Plotly charting library" data-secondary="visualizing data with" data-type="indexterm" id="idm45607734704304"/> Matplotlib can produce publication-standard static charts, while Plotly brings user controls and dynamic charts to the table. We saw how to take a Plotly chart directly from a Jupyter notebook and put it in a web page.</p>
<p>I think it’s fair to say that taking on D3 was the most ambitious part of this book, but I was determined to demonstrate the construction of a multielement visualization, such as the kind you may well end up being employed to make. One of the joys of D3 is the <a href="https://oreil.ly/nYKx8">huge number of examples</a> that can easily be found online, but most of them demonstrate a single technique and there are few showing how to orchestrate multiple visual elements. In these D3 chapters, we saw how to synchronize the update of a timeline (featuring all the Nobel Prizes), a map, a bar chart, and a list as the user filtered the Nobel Prize dataset or changed the prize-winning metric (absolute or per capita).</p>
<p>Mastery of the core themes demonstrated in these chapters should allow you to let loose your imagination and learn by doing. I’d recommend choosing some data close to your heart and designing a D3 creation around it.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Future Progress" data-type="sect1"><div class="sect1" id="idm45607734701360">
<h1>Future Progress</h1>
<p>As mentioned, the Python and JavaScript data-processing and visualization ecosystems are incredibly active right now and are building from a very solid base.<a data-primary="future progress in Python and JavaScript data visualization" data-type="indexterm" id="idm45607734699680"/><a data-primary="dataviz" data-secondary="future progress in Python and JavaScript" data-type="indexterm" id="idm45607734699040"/><a data-primary="JavaScript" data-secondary="future progress in data processing and visualization" data-type="indexterm" id="idm45607734698192"/><a data-primary="Python" data-secondary="future progress in data processing and visualization" data-type="indexterm" id="idm45607734697216"/><a data-primary="data processing" data-secondary="future progress in Python and JavaScript" data-type="indexterm" id="idm45607734696240"/></p>
<p>While the business of acquiring and cleaning datasets learned in <a data-type="xref" href="part02.xhtml#part_getting_data">Part II</a> and <a data-type="xref" href="ch09.xhtml#chapter_cleaning">Chapter 9</a> improves incrementally, getting a lot easier as your craft skills (e.g., your pandas fu) improve, Python is throwing out new and powerful data-processing tools with abandon. There’s a <a href="https://oreil.ly/ODNE1">fairly comprehensive list</a> at the Python wiki. Here are a few ideas you might want to use to create some visualizations.</p>
<section data-pdf-bookmark="Visualizing Social Media Networks" data-type="sect2"><div class="sect2" id="idm45607734692272">
<h2>Visualizing Social Media Networks</h2>
<p>The advent of social media has provided a huge amount of interesting data, often available from a web API or eminently scrapeable.<a data-primary="social media networks, visualizing" data-type="indexterm" id="idm45607734690960"/> There are also curated collections of social media data such as <a href="https://oreil.ly/2E02E">Stanford’s Large Network Dataset Collection</a> or the <a href="https://oreil.ly/x09oi">UCIrvine collection</a>.  These datasets can provide an easy testing ground for adventures in network visualization, an increasingly popular area.<a data-primary="Python" data-secondary="libraries for network analysis" data-type="indexterm" id="idm45607734688640"/></p>
<p>The two most popular Python libraries for network analysis are <a href="https://graph-tool.skewed.de">graph-tool</a> and <a href="https://networkx.org">NetworkX</a>. While graph-tool is more heavily optimized, NetworkX is arguably more user-friendly. <a data-primary="NetworkX package ( Python)" data-type="indexterm" id="idm45607734685424"/><a data-primary="graph-tool (Python)" data-type="indexterm" id="idm45607734684704"/><a data-primary="GraphML format" data-type="indexterm" id="idm45607734684032"/><a data-primary="GML format" data-type="indexterm" id="idm45607734683360"/>Both libraries produce graphs in the common <a href="http://graphml.graphdrawing.org">GraphML</a> and <a href="https://oreil.ly/18AUU">GML</a> formats. D3 cannot read GML files directly, but it’s easy enough to convert them to a JSON format it can read.<a data-primary="D3 library" data-secondary="GML files and" data-type="indexterm" id="idm45607734680976"/> You’ll find a nice example of that in this <a href="https://oreil.ly/thuBE">blog post</a>, with accompanying code on <a href="https://oreil.ly/3IHVR">GitHub</a>. Note that in D3 version 4, the forceSimulation API changed. <a data-primary="forceSimulation API (D3)" data-type="indexterm" id="idm45607734678464"/>You can find a gentle introduction to the new API, which uses a <code>forceSimulation</code> object to keep track of things, on <a href="https://oreil.ly/DZxAz">Pluralsight</a>.</p>
</div></section>
<section data-pdf-bookmark="Machine-Learning Visualizations" data-type="sect2"><div class="sect2" id="idm45607734676336">
<h2>Machine-Learning Visualizations</h2>
<p>Machine learning is more than a little in vogue at the moment, and Python offers a fantastic<a data-primary="machine learning visualizations" data-type="indexterm" id="idm45607734674576"/> set of tools to allow you to start analyzing and mining your data with a huge range of algorithms, from the supervised to unsupervised, from basic regression algorithms (such as linear or logistic regression) to more esoteric, cutting-edge stuff like the family of ensemble algorithms such as random forest. See this <a href="https://oreil.ly/IR8LZ">nice tour</a> of the different flavors of algorithm.</p>
<p>Premier among Python’s machine-learning stable is <a href="https://oreil.ly/gjAKs">scikit-learn</a>, which is part of the NumPy ecosystem, also building on SciPy and Matplotlib. <a data-primary="Matplotlib" data-type="indexterm" id="idm45607734671856"/><a data-primary="SciPy library (Python)" data-type="indexterm" id="idm45607734671152"/><a data-primary="scikit-learn" data-type="indexterm" id="idm45607734670480"/><a data-primary="Python" data-secondary="machine learning visualizations libraries" data-type="indexterm" id="idm45607734669808"/>scikit-learn provides an amazing resource for efficient data mining and data analysis. Algorithms that only a few years back would have taken days or weeks to craft are available with a single import, well designed, easy to use, and able to get useful results in a few lines of code.</p>
<p>Tools like scikit-learn enable you to discover deep correlations in your data, if they exist. There’s a <a href="https://oreil.ly/Q0GVd">nice demonstration</a> at R2D3 that both introduces some machine-learning techniques and uses D3 to visualize the process and results. It’s a great example of the creative freedom that mastery of D3 provides and the way in which good web dataviz is pushing the boundaries, making novel visualizations that engage in a way that hasn’t been possible before—and, of course, are available to everybody.</p>
<p>There’s a <a href="https://oreil.ly/wZ1bJ">great collection</a> of IPython (Jupyter) notebooks for statistics, machine learning, and data science at the IPython GitHub repo. <a data-primary="Jupyter notebooks" data-secondary="collection of IPython Jupyter notebooks" data-type="indexterm" id="idm45607734666176"/><a data-primary="IPython" data-secondary="Jupyter notebooks collection" data-type="indexterm" id="idm45607734665136"/>Many of these demonstrate visualization techniques that can be adapted and extended in your own works.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Final Thoughts" data-type="sect1"><div class="sect1" id="idm45607734663680">
<h1>Final Thoughts</h1>
<p>The suggestions in the previous section just scratch the surface of where you might take your new Python and JavaScript dataviz skills. <a data-primary="Python" data-secondary="data wrangling and data visualization capabilities, skills in" data-type="indexterm" id="idm45607734662256"/>Hopefully this book has provided a solid bedrock on which to build your web dataviz efforts for the many jobs now opening up in the field or just to scratch a personal itch. The ability to harness Python’s immensely powerful data wrangling and general-purpose abilities to <span class="keep-together">JavaScript’s</span> (D3 being prominent here) increasingly powerful and mature visualization libraries represents the richest dataviz stack I know. Skills in this area are already very bankable, but the pace of change and scale of interest is increasing at a rapid rate. I hope you find this exciting and emergent field as fulfilling as I do.</p>
</div></section>
</div></section></div></body></html>