<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 9. Analyzing Genomics Data &#10;and the BDG Project" data-type="chapter" epub:type="chapter"><div class="chapter" id="analyzing_genomics_data_and_and_the_bdg_project">
<h1><span class="label">Chapter 9. </span>Analyzing Genomics Data 
<span class="keep-together">and the BDG Project</span></h1>
<p>The advent of next-generation DNA sequencing (NGS) technology<a data-primary="genomics" data-secondary="overview" data-secondary-sortas="about" data-type="indexterm" id="idm46507966919440"/> has rapidly transformed the life sciences into a data-driven field.  However, making the best use of this data is butting up against a traditional computational ecosystem that builds on difficult-to-use, low-level primitives for distributed computing and a jungle of semistructured text-based file formats.</p>
<p>This chapter will serve two primary purposes. <a data-primary="Avro (Apache)" data-secondary="about" data-type="indexterm" id="idm46507966917680"/><a data-primary="Parquet data storage format" data-secondary="serialization tool" data-type="indexterm" id="idm46507966916704"/><a data-primary="serialization" data-secondary="about popular formats" data-type="indexterm" id="idm46507966915792"/><a data-primary="data serialization" data-see="serialization" data-type="indexterm" id="idm46507966914848"/><a data-primary="ADAM library" data-secondary="Parquet data storage format" data-tertiary="serialization tool" data-type="indexterm" id="idm46507966913904"/><a data-primary="genomics" data-secondary="Parquet data storage format" data-tertiary="serialization tool" data-type="indexterm" id="idm46507966912720"/>First, we introduce a set of popular serialization and file formats (Avro and Parquet) that simplify many problems in data management. These serialization technologies enable us to convert data into compact, machine-friendly binary representations. This helps with movement of data across networks and helps with cross-compatibility across programming languages. Although we will use data serialization techniques with genomics data, the concepts will be useful whenever processing large amounts of data.</p>
<p>Second, we show how to perform typical <a data-primary="genomics" data-secondary="ADAM library" data-tertiary="about" data-type="indexterm" id="idm46507966910800"/><a data-primary="ADAM library" data-secondary="about" data-type="indexterm" id="idm46507966909552"/>genomics tasks in the PySpark ecosystem. Specifically, we’ll use PySpark and the open source ADAM library to manipulate large quantities of genomics data and process data from multiple sources to <a data-primary="transcription factor (TF) binding sites" data-secondary="about" data-type="indexterm" id="idm46507966908480"/>create a dataset for predicting transcription factor (TF) binding sites. <a data-primary="ENCODE project" data-secondary="link" data-type="indexterm" id="idm46507966907440"/><a data-primary="online resources" data-secondary="genomics" data-tertiary="ENCODE project" data-type="indexterm" id="idm46507966906496"/><a data-primary="1000 Genomes Project" data-type="indexterm" id="idm46507966905280"/><a data-primary="1000 Genomes Project" data-primary-sortas="One Thousand Genomes" data-type="indexterm" id="idm46507966904608"/>For this, we will join genome annotations from the <a href="https://oreil.ly/h0yOq">ENCODE dataset</a>. This chapter will serve as a tutorial to the ADAM project, which comprises a set of genomics-specific Avro schemas, PySpark-based APIs, and command-line tools for large-scale genomics analysis.  <a data-primary="genomics" data-secondary="ADAM library" data-tertiary="Genome Analysis Toolkit" data-type="indexterm" id="idm46507966902880"/><a data-primary="Genome Analysis Toolkit (GATK; Broad Institute)" data-type="indexterm" id="idm46507966901632"/><a data-primary="ADAM library" data-secondary="about" data-tertiary="Genome Analysis Toolkit" data-type="indexterm" id="idm46507966900992"/><a data-primary="GATK (Genome Analysis Toolkit; Broad Institute)" data-type="indexterm" id="idm46507966899776"/>Among other applications, ADAM provides a natively distributed implementation of the <a href="https://oreil.ly/k2YZH">Genome Analysis Toolkit (GATK)</a> using PySpark.</p>
<p class="pagebreak-before">We’ll start by talking about the various data formats used in the bioinformatics domain, associated challenges, and how serialization formats can help. After that, we’ll install the ADAM project and explore its API using a sample dataset. We will then work with multiple genomics datasets to prepare a dataset that can be used for predicting binding sites in DNA sequences for a particular type of protein—CTCF transcription factor. The datasets will be obtained from the publicly available ENCODE dataset. Because the genome implies a 1D coordinate system, many genomics operations are spatial in nature. The ADAM project provides a genomics-targeted API for performing distributed spatial joins that we will use.</p>
<div data-type="note" epub:type="note">
<p>For those interested, a great introduction<a data-primary="biology EdX course" data-type="indexterm" id="idm46507966896560"/><a data-primary="online resources" data-secondary="genomics" data-tertiary="introduction to biology" data-type="indexterm" id="idm46507966895856"/><a data-primary="genomics" data-secondary="overview" data-secondary-sortas="about" data-tertiary="biology online course" data-type="indexterm" id="idm46507966894640"/><a data-primary="introduction to biology EdX course" data-type="indexterm" id="idm46507966893152"/> to biology is <a href="https://oreil.ly/WIky1">Eric Lander’s EdX course</a>. <a data-primary="bioinformatics book" data-type="indexterm" id="idm46507966891648"/><a data-primary="Introduction to Bioinformatics (Lesk)" data-type="indexterm" id="idm46507966890944"/><a data-primary="Lesk, Arthur" data-type="indexterm" id="idm46507966890208"/>For an introduction to 
<span class="keep-together">bioinformatics</span>, see Arthur Lesk’s <em>Introduction to Bioinformatics</em> (Oxford University Press).</p>
</div>
<section data-pdf-bookmark="Decoupling Storage from Modeling" data-type="sect1"><div class="sect1" id="idm46507966888080">
<h1>Decoupling Storage from Modeling</h1>
<p>Bioinformaticians spend a disproportionate<a data-primary="genomics" data-secondary="decoupling storage from modeling" data-type="indexterm" id="ch09-serial"/><a data-primary="serialization" data-secondary="decoupling storage from modeling" data-type="indexterm" id="ch09-serial2"/><a data-primary="models" data-secondary="decoupling storage from modeling" data-type="indexterm" id="ch09-serial3"/><a data-primary="persistent storage" data-secondary="decoupling storage from modeling" data-type="indexterm" id="ch09-serial4"/><a data-primary="Avro (Apache)" data-secondary="decoupling storage from modeling" data-type="indexterm" id="ch09-serial5"/> amount of time worrying about file formats—<em>.fasta</em>, <em>.fastq</em>, <em>.sam</em>, <em>.bam</em>, <em>.vcf</em>, <em>.gvcf</em>, <em>.bcf</em>, <em>.bed</em>, <em>.gff</em>, <em>.gtf</em>, <em>.narrowPeak</em>, <em>.wig</em>, <em>.bigWig</em>, <em>.bigBed</em>, <em>.ped</em>, and <em>.tped</em>, to name a few. Some scientists also feel it is necessary to specify their own custom format for their custom tool. On top of that, many of the format specifications are incomplete or ambiguous (which makes it hard to ensure implementations are consistent or compliant) and specify ASCII-encoded data. ASCII data is very common in bioinformatics, but it is inefficient and compresses relatively poorly. In addition, the data must always be parsed, necessitating additional compute cycles.</p>
<p>This is particularly troubling because all of these file formats essentially store just a few common object types: an aligned sequence read, a called genotype, a sequence feature, and a phenotype. <a data-primary="Apache Avro" data-see="Avro" data-type="indexterm" id="idm46507966872416"/><a data-primary="genomics" data-secondary="sequence feature" data-type="indexterm" id="idm46507966871056"/><a data-primary="sequence feature" data-type="indexterm" id="idm46507966870112"/>(The term <em>sequence feature</em> is slightly overloaded in genomics, but in this chapter we mean it in the sense of an element from a track of the UCSC Genome Browser.) <a data-primary="biopython library genomic parsers" data-type="indexterm" id="idm46507966868736"/><a data-primary="Python" data-secondary="biopython library genomic parsers" data-type="indexterm" id="idm46507966868064"/><a data-primary="genomics" data-secondary="overview" data-secondary-sortas="about" data-tertiary="biopython library genomic parsers" data-type="indexterm" id="idm46507966867152"/><a data-primary="online resources" data-secondary="genomics" data-tertiary="biopython library" data-type="indexterm" id="idm46507966865648"/>Libraries like <a href="http://biopython.org"><code>biopython</code></a> are popular because they are chock-full of parsers (e.g., <code>Bio.SeqIO</code>) that attempt to read all the file formats into a small number of common in-memory models (e.g., <code>Bio.Seq</code>, <code>Bio.SeqRecord</code>, <code>Bio.SeqFeature</code>).</p>
<p>We can solve all of these problems in one shot<a data-primary="Avro (Apache)" data-secondary="about" data-type="indexterm" id="idm46507966861456"/> using a serialization framework like Apache Avro. The key lies in Avro’s separation of the data model (i.e., an explicit schema) from the underlying storage file format and also the language’s in-memory representation.  Avro specifies how data of a certain type should be communicated between processes, whether that’s between running processes over the internet, or a process trying to write the data into a particular file format. For example, a Java program that uses Avro can write the data into multiple underlying file formats that are all compatible with Avro’s data model.  This allows each process to stop worrying about compatibility with multiple file formats: the process only needs to know how to read Avro, and the filesystem needs to know how to supply Avro.</p>
<p>Let’s take the sequence feature as an example.<a data-primary="sequence feature" data-secondary="Avro serialization of data" data-type="indexterm" id="idm46507966859872"/><a data-primary="Avro (Apache)" data-secondary="decoupling storage from modeling" data-tertiary="sequence feature serialization example" data-type="indexterm" id="idm46507966858928"/><a data-primary="genomics" data-secondary="decoupling storage from modeling" data-tertiary="sequence feature example" data-type="indexterm" id="idm46507966857680"/><a data-primary="schema of data serialization object" data-type="indexterm" id="idm46507966856432"/><a data-primary="Avro (Apache)" data-secondary="decoupling storage from modeling" data-tertiary="schema of data serialization object" data-type="indexterm" id="idm46507966855744"/><a data-primary="genomics" data-secondary="sequence feature" data-tertiary="example of data serialization" data-type="indexterm" id="idm46507966854496"/>  We begin by specifying the desired schema for the object using the Avro interface definition language (IDL):</p>
<pre data-code-language="c" data-type="programlisting"><code class="k">enum</code><code class="w"> </code><code class="n">Strand</code><code class="w"> </code><code class="p">{</code><code class="w">
</code><code class="w">  </code><code class="n">Forward</code><code class="p">,</code><code class="w">
</code><code class="w">  </code><code class="n">Reverse</code><code class="p">,</code><code class="w">
</code><code class="w">  </code><code class="n">Independent</code><code class="w">
</code><code class="p">}</code><code class="w">
</code><code class="w">
</code><code class="n">record</code><code class="w"> </code><code class="n">SequenceFeature</code><code class="w"> </code><code class="p">{</code><code class="w">
</code><code class="w">  </code><code class="n">string</code><code class="w"> </code><code class="n">featureId</code><code class="p">;</code><code class="w">
</code><code class="w">  </code><code class="n">string</code><code class="w"> </code><code class="n">featureType</code><code class="p">;</code><code class="w"> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO1-1" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO1-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code class="w">
</code><code class="w">  </code><code class="n">string</code><code class="w"> </code><code class="n">chromosome</code><code class="p">;</code><code class="w">
</code><code class="w">  </code><code class="kt">long</code><code class="w"> </code><code class="n">startCoord</code><code class="p">;</code><code class="w">
</code><code class="w">  </code><code class="kt">long</code><code class="w"> </code><code class="n">endCoord</code><code class="p">;</code><code class="w">
</code><code class="w">  </code><code class="n">Strand</code><code class="w"> </code><code class="n">strand</code><code class="p">;</code><code class="w">
</code><code class="w">  </code><code class="kt">double</code><code class="w"> </code><code class="n">value</code><code class="p">;</code><code class="w">
</code><code class="w">  </code><code class="n">map</code><code class="o">&lt;</code><code class="n">string</code><code class="o">&gt;</code><code class="w"> </code><code class="n">attributes</code><code class="p">;</code><code class="w">
</code><code class="p">}</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO1-1" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO1-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>For example, “conservation,” “centipede,” “gene”</p></dd>
</dl>
<p>This data type could be used to encode, for example, conservation level, the presence of a promoter or ribosome binding site, a TF binding site, and so on at a particular location in the genome.  One way to think about it is as a binary version of JSON, but more restricted and with higher performance.  Given a particular data schema, the Avro spec then determines the precise binary encoding for the object so that it can be easily communicated between processes (even if written in different programming languages), over the network, or onto disk for storage.  <a data-primary="Avro (Apache)" data-secondary="about" data-tertiary="language compatibility" data-type="indexterm" id="idm46507966754144"/>The Avro project includes modules for processing Avro-encoded data from many languages, including Java, C/C++, Python, and Perl; after that, the language is free to store the object in memory in whichever way is deemed most advantageous.  The separation of data modeling from the storage format provides another level of flexibility/abstraction; Avro data can be stored as Avro-serialized binary objects (Avro container file), <a data-primary="Parquet data storage format" data-secondary="serialization tool" data-tertiary="Avro data storage" data-type="indexterm" id="idm46507966752768"/><a data-primary="ADAM library" data-secondary="Parquet data storage format" data-tertiary="serialization tool" data-type="indexterm" id="idm46507966751584"/><a data-primary="genomics" data-secondary="Parquet data storage format" data-tertiary="serialization tool" data-type="indexterm" id="idm46507966750352"/>in a columnar file format for fast queries (Parquet file), or as text JSON data for maximum flexibility (minimum efficiency).  <a data-primary="Avro (Apache)" data-secondary="decoupling storage from modeling" data-tertiary="schema of object evolving" data-type="indexterm" id="idm46507966748992"/>Finally, Avro supports schema evolution, allowing the user to add new fields as they become necessary, while the software gracefully deals with new/old versions of the schema.</p>
<p>Overall, Avro is an efficient binary encoding that allows you to specify evolvable data schemas, process the same data from many programming languages, and store the data using many formats.  Deciding to store your data using Avro schemas frees you from perpetually working with more and more custom data formats, while simultaneously increasing the performance of your computations.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46507966705440">
<h5>Serialization/RPC Frameworks</h5>
<p>There are a large number of serialization<a data-primary="serialization" data-secondary="about popular frameworks" data-type="indexterm" id="idm46507966703920"/><a data-primary="RPC (remote procedure call) frameworks" data-type="indexterm" id="idm46507966702928"/><a data-primary="Thrift (Apache)" data-type="indexterm" id="idm46507966702240"/><a data-primary="Apache Thrift" data-type="indexterm" id="idm46507966701568"/><a data-primary="Protocol Buffers (protobuf; Google)" data-type="indexterm" id="idm46507966700896"/><a data-primary="Google Protocol Buffers (protobuf)" data-type="indexterm" id="idm46507966700208"/> and remote procedure call frameworks in the wild.  The most commonly used frameworks in the big data community are Apache Avro and Google’s Protocol Buffers (protobuf).  At the core, they all provide an interface definition language for specifying the schemas of object/message types, and they all compile into a variety of programming languages. <a data-primary="Google RPC as open source gRPC" data-type="indexterm" id="idm46507966699392"/><a data-primary="gRPC open source project" data-type="indexterm" id="idm46507966698704"/>(Google’s RPC framework for protobuf is now the open source project gRPC.) On top of IDL and RPC, Avro adds a file format specification for storing the data on-disk.</p>
<p>It’s difficult to make generalizations about which framework is appropriate in what circumstances because they all support different languages and have different performance characteristics for the various languages.</p>
</div></aside>
<p>The particular <code>SequenceFeature</code> model used in the preceding example is a bit simplistic for real data, <a data-primary="Big Data Genomics (BDG) project" data-secondary="Avro schemas" data-type="indexterm" id="idm46507966696512"/><a data-primary="genomics" data-secondary="decoupling storage from modeling" data-tertiary="Big Data Genomics Avro schemas" data-type="indexterm" id="idm46507966695520"/><a data-primary="Avro (Apache)" data-secondary="decoupling storage from modeling" data-tertiary="Big Data Genomics Avro schemas" data-type="indexterm" id="idm46507966694272"/><a data-primary="schema of data serialization object" data-secondary="Big Data Genomics Avro schemas" data-type="indexterm" id="idm46507966693024"/>but the Big Data Genomics (BDG) project has already defined Avro schemas to represent the following objects, as well as many others:</p>
<ul>
<li>
<p><code>AlignmentRecord</code> for reads</p>
</li>
<li>
<p><code>Variant</code> for known genome variants and metadata</p>
</li>
<li>
<p><code>Genotype</code> for a called genotype at a particular locus</p>
</li>
<li>
<p><code>Feature</code> for a sequence feature (annotation on a genome segment)</p>
</li>
</ul>
<p>The actual schemas can be found<a data-primary="online resources" data-secondary="genomics" data-tertiary="Big Data Genomics Avro schemas" data-type="indexterm" id="idm46507966686400"/> in <a href="https://oreil.ly/gCf1f">the <code>bdg-formats</code> GitHub repo</a>.  The BDG formats can function as a replacement of the ubiquitous “legacy” formats (like BAM and VCF), but more commonly function as high-performance “intermediate” formats. (The original goal of these BDG formats was to replace the use of BAM and VCF, but their stubborn ubiquity has proved this goal to be difficult to attain.) Avro provides many performance and data modeling benefits over the custom ASCII status quo.</p>
<p>In the remainder of the chapter, we’ll use some of the BDG schemas to accomplish some typical genomics tasks. Before we can do that, we will need to install the ADAM project. That’s what we’ll do in the next section.<a data-startref="ch09-serial" data-type="indexterm" id="idm46507966683408"/><a data-startref="ch09-serial2" data-type="indexterm" id="idm46507966682704"/><a data-startref="ch09-serial3" data-type="indexterm" id="idm46507966682032"/><a data-startref="ch09-serial4" data-type="indexterm" id="idm46507966681360"/><a data-startref="ch09-serial5" data-type="indexterm" id="idm46507966680688"/></p>
</div></section>
<section data-pdf-bookmark="Setting Up ADAM" data-type="sect1"><div class="sect1" id="idm46507966887488">
<h1>Setting Up ADAM</h1>
<p>BDG’s core set of genomics tools is called ADAM.<a data-primary="ADAM library" data-secondary="about" data-type="indexterm" id="idm46507966678256"/><a data-primary="genomics" data-secondary="ADAM library" data-tertiary="about" data-type="indexterm" id="idm46507966677280"/><a data-primary="genomics" data-secondary="ADAM library" data-tertiary="setting up" data-type="indexterm" id="idm46507966676064"/><a data-primary="ADAM library" data-secondary="setting up" data-type="indexterm" id="idm46507966674848"/><a data-primary="BDG" data-see="Big Data Genomics" data-type="indexterm" id="idm46507966673904"/><a data-primary="Big Data Genomics (BDG) project" data-secondary="ADAM library" data-seealso="ADAM library" data-type="indexterm" id="idm46507966672960"/><a data-primary="online resources" data-secondary="genomics" data-tertiary="ADAM library (BDG)" data-type="indexterm" id="idm46507966671776"/>  Starting from a set of mapped reads, this core includes tools that can perform mark-duplicates, base quality score recalibration, indel realignment, and variant calling, among other tasks. ADAM also contains a command-line interface that wraps the core for ease of use.  <a data-primary="parallelizing" data-secondary="ADAM parallelizing clusters" data-type="indexterm" id="idm46507966670432"/>In contrast to traditional HPC tools, ADAM can automatically parallelize across a cluster without having to split files or schedule jobs manually.</p>
<p>We can start by installing ADAM using pip:</p>
<pre data-code-language="shell" data-type="programlisting">pip3 install bdgenomics.adam</pre>
<p>Alternative installation methods can be found on the <a href="https://oreil.ly/4eFnX">GitHub page</a>.</p>
<p>ADAM also comes with a submission script that facilitates interfacing with Spark’s <code>spark-submit</code> script:<a data-primary="ADAM library" data-secondary="actions" data-type="indexterm" id="idm46507966636352"/><a data-primary="genomics" data-secondary="ADAM library" data-tertiary="actions" data-type="indexterm" id="idm46507966635504"/></p>
<pre data-code-language="shell" data-type="programlisting">adam-submit
...

Using <code class="nv">ADAM_MAIN</code><code class="o">=</code>org.bdgenomics.adam.cli.ADAMMain
Using spark-submit<code class="o">=</code>/home/analytical-monk/miniconda3/envs/pyspark/bin/spark-submit

       e        <code class="m">888</code>~-_         e            e    e
      d8b       <code class="m">888</code>   <code class="se">\ </code>      d8b          d8b  d8b
     /Y88b      <code class="m">888</code>    <code class="p">|</code>     /Y88b        d888bdY88b
    /  Y88b     <code class="m">888</code>    <code class="p">|</code>    /  Y88b      / Y88Y Y888b
   /____Y88b    <code class="m">888</code>   /    /____Y88b    /   YY   Y888b
  /      Y88b   888_-~    /      Y88b  /          Y888b

Usage: adam-submit <code class="o">[</code>&lt;spark-args&gt; --<code class="o">]</code> &lt;adam-args&gt;

Choose one of the following commands:

ADAM ACTIONS
          countKmers : Counts the k-mers/q-mers from a <code class="nb">read</code> dataset...
     countSliceKmers : Counts the k-mers/q-mers from a slice dataset...
 transformAlignments : Convert SAM/BAM to ADAM format and optionally...
   transformFeatures : Convert a file with sequence features into...
  transformGenotypes : Convert a file with genotypes into correspondi...
  transformSequences : Convert a FASTA file as sequences into corresp...
     transformSlices : Convert a FASTA file as slices into correspond...
   transformVariants : Convert a file with variants into correspondin...
         mergeShards : Merges the shards of a fil...
            coverage : Calculate the coverage from a given ADAM fil...
CONVERSION OPERATION
          adam2fastq : Convert BAM to FASTQ file
  transformFragments : Convert alignments into fragment records
PRIN
               print : Print an ADAM formatted fil
            flagstat : Print statistics on reads <code class="k">in</code> an ADAM file...
                view : View certain reads from an alignment-record file.</pre>
<p class="pagebreak-before">At this point, you should be able to run ADAM from the command line and get the usage message. As noted in the usage message, Spark arguments are given before ADAM-specific arguments.</p>
<p>With ADAM set up, we can start working with genomic data. We will explore ADAM’s API by working with a sample dataset next.</p>
</div></section>
<section data-pdf-bookmark="Introduction to Working with Genomics Data Using ADAM" data-type="sect1"><div class="sect1" id="idm46507966620480">
<h1>Introduction to Working with Genomics Data Using ADAM</h1>
<p>We’ll start by taking a <em>.bam</em> file containing some mapped<a data-primary="genomics" data-secondary="ADAM library" data-tertiary="genomics data analysis" data-type="indexterm" id="ch09-gedaan"/><a data-primary="ADAM library" data-secondary="genomics data analysis" data-type="indexterm" id="ch09-gedaan2"/><a data-primary="alignment dataset" data-type="indexterm" id="ch09-gedaan3"/> NGS reads, converting them to the corresponding BDG format (<code>AlignedRecord</code> in this case), and saving them to HDFS.  First, we get our hands on a suitable <em>.bam</em> file:</p>
<pre data-code-language="shell" data-type="programlisting"><code class="c1"># Note: this file is 16 GB</code>
curl -O ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/phase3/data<code class="se">\</code>
/HG00103/alignment/HG00103.mapped.ILLUMINA.bwa.GBR<code class="se">\</code>
.low_coverage.20120522.bam

<code class="c1"># or using Aspera instead (which is *much* faster)</code>
ascp -i path/to/asperaweb_id_dsa.openssh -QTr -l 10G <code class="se">\</code>
anonftp@ftp.ncbi.nlm.nih.gov:/1000genomes/ftp/phase3/data<code class="se">\</code>
/HG00103/alignment/HG00103.mapped.ILLUMINA.bwa.GBR<code class="se">\</code>
.low_coverage.20120522.bam .</pre>
<p>Move the downloaded file into a directory where we’ll store all data for this chapter:</p>
<pre data-code-language="shell" data-type="programlisting">mv HG00103.mapped.ILLUMINA.bwa.GBR<code class="se">\</code>
.low_coverage.20120522.bam data/genomics</pre>
<p>Next up, we’ll use the ADAM CLI.</p>
<section data-pdf-bookmark="File Format Conversion with the ADAM CLI" data-type="sect2"><div class="sect2" id="idm46507966573264">
<h2>File Format Conversion with the ADAM CLI</h2>
<p>We can then use the ADAM <code>transform</code> command<a data-primary="ADAM library" data-secondary="genomics data analysis" data-tertiary="file format conversion" data-type="indexterm" id="idm46507966571280"/><a data-primary="genomics" data-secondary="ADAM library" data-tertiary="file format conversion" data-type="indexterm" id="idm46507966570128"/><a data-primary="Parquet data storage format" data-secondary="ADAM file format conversion" data-type="indexterm" id="idm46507966568912"/><a data-primary="ADAM library" data-secondary="Parquet data storage format" data-tertiary="ADAM file format conversion" data-type="indexterm" id="idm46507966568032"/><a data-primary="genomics" data-secondary="Parquet data storage format" data-tertiary="ADAM file format conversion" data-type="indexterm" id="idm46507966566880"/> to convert the <em>.bam</em> file to Parquet format (described in <a data-type="xref" href="#parquet-format">“Parquet Format and Columnar Storage”</a>).  This would work both on a cluster and in <code>local</code> mode:</p>
<pre class="pagebreak-before" data-code-language="shell" data-type="programlisting"><code>adam-submit</code><code> </code><code class="se">\
</code><code>  </code><code>--master</code><code> </code><code>yarn</code><code> </code><code class="se">\ </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO2-1" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO2-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
  </code><code>--deploy-mode</code><code> </code><code>client</code><code> </code><code class="se">\
</code><code>  </code><code>--driver-memory</code><code> </code><code>8G</code><code> </code><code class="se">\
</code><code>  </code><code>--num-executors</code><code> </code><code class="m">6</code><code> </code><code class="se">\
</code><code>  </code><code>--executor-cores</code><code> </code><code class="m">4</code><code> </code><code class="se">\
</code><code>  </code><code>--executor-memory</code><code> </code><code>12G</code><code> </code><code class="se">\
</code><code>  </code><code>--</code><code> </code><code class="se">\
</code><code>  </code><code>transform</code><code> </code><code class="se">\ </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO2-2" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO2-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a><code>
  </code><code>data/genomics/HG00103.mapped.ILLUMINA.bwa.GBR</code><code class="se">\
</code><code>.low_coverage.20120522.bam</code><code> </code><code class="se">\
</code><code>  </code><code>data/genomics/HG00103</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO2-1" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO2-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>Example Spark args for running on YARN</p></dd>
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO2-2" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO2-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></dt>
<dd><p>The ADAM subcommand itself</p></dd>
</dl>
<p>This should kick off a pretty large amount of output to the console, including the URL to track the progress of the job.</p>
<p>The resulting dataset is the concatenation of all the files in the <em>data/genomics/reads/HG00103/</em> directory, where each <em>part-*.parquet</em> file is the output from one of the PySpark tasks. You’ll also notice that the data has been compressed more efficiently than the initial <em>.bam</em> file (which is gzipped underneath) thanks to the columnar storage (see <a data-type="xref" href="#parquet-format">“Parquet Format and Columnar Storage”</a>).</p>
<pre data-code-language="shell" data-type="programlisting">$ du -sh data/genomics/HG00103*bam
16G  data/genomics/HG00103. <code class="o">[</code>...<code class="o">]</code> .bam

$ du -sh data/genomics/HG00103/
13G  data/genomics/HG00103</pre>
<p>Let’s see what one of these objects looks like in an interactive session.</p>
</div></section>
<section data-pdf-bookmark="Ingesting Genomics Data Using PySpark and ADAM" data-type="sect2"><div class="sect2" id="idm46507966454944">
<h2>Ingesting Genomics Data Using PySpark and ADAM</h2>
<p>First, we start up the PySpark shell using<a data-primary="genomics" data-secondary="ADAM library" data-tertiary="ingesting data via PySpark" data-type="indexterm" id="ch09-ingest"/><a data-primary="ADAM library" data-secondary="genomics data analysis" data-tertiary="ingesting data via PySpark" data-type="indexterm" id="ch09-ingest2"/><a data-primary="DNA analysis" data-see="genomics" data-type="indexterm" id="idm46507966450496"/><a data-primary="chromosome analysis" data-see="genomics" data-type="indexterm" id="idm46507966449552"/> the ADAM helper command. It loads all of the JARs that are necessary.</p>
<pre data-code-language="shell" data-type="programlisting">pyadam

...

<code class="o">[</code>...<code class="o">]</code>
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _<code class="se">\ \/</code> _ <code class="se">\/</code> _  / __/   _/
   /__ / .__/<code class="se">\_</code>,_/_/ /_/<code class="se">\_\ </code>  version <code class="m">3</code>.2.1
      /_/

Using Python version <code class="m">3</code>.6.12 <code class="o">(</code>default, Sep  <code class="m">8</code> <code class="m">2020</code> <code class="m">23</code>:10:56<code class="o">)</code>
Spark context Web UI available at http://192.168.29.60:4040
Spark context available as <code class="s1">'sc'</code>.
SparkSession available as <code class="s1">'spark'</code>.

&gt;&gt;&gt;</pre>
<div data-type="note" epub:type="note">
<p>In some cases, you can encounter a TypeError error with a mention of JavaPackage object not being when trying to use ADAM with PySpark. It is a known issue and is documented <a href="https://oreil.ly/67uBd">here</a>.</p>
<p>In such a scenario, please try the solutions suggested in the thread. One could be running the following command to start PySpark shell with ADAM:</p>
<pre data-code-language="python" data-type="programlisting"><code class="err">!</code><code class="n">pyspark</code> <code class="o">--</code><code class="n">conf</code> <code class="n">spark</code><code class="o">.</code><code class="n">serializer</code><code class="o">=</code><code class="n">org</code><code class="o">.</code><code class="n">apache</code><code class="o">.</code><code class="n">spark</code><code class="o">.</code>
<code class="n">serializer</code><code class="o">.</code><code class="n">KryoSerializer</code> <code class="o">--</code><code class="n">conf</code> <code class="n">spark</code><code class="o">.</code><code class="n">kryo</code><code class="o">.</code><code class="n">registrator</code><code class="o">=</code>
<code class="n">org</code><code class="o">.</code><code class="n">bdgenomics</code><code class="o">.</code><code class="n">adam</code><code class="o">.</code><code class="n">serialization</code><code class="o">.</code><code class="n">ADAMKryoRegistrator</code>
<code class="o">--</code><code class="n">jars</code> <code class="err">`</code><code class="n">find</code><code class="o">-</code><code class="n">adam</code><code class="o">-</code><code class="n">assembly</code><code class="o">.</code><code class="n">sh</code><code class="err">`</code> <code class="o">--</code><code class="n">driver</code><code class="o">-</code><code class="n">class</code><code class="o">-</code><code class="n">path</code>
<code class="err">`</code><code class="n">find</code><code class="o">-</code><code class="n">adam</code><code class="o">-</code><code class="n">assembly</code><code class="o">.</code><code class="n">sh</code><code class="err">`</code></pre>
</div>
<p>Now we’ll load the aligned read data as an <code>AlignmentDataset</code>:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">bdgenomics.adam.adamContext</code> <code class="kn">import</code> <code class="n">ADAMContext</code>

<code class="n">ac</code> <code class="o">=</code> <code class="n">ADAMContext</code><code class="p">(</code><code class="n">spark</code><code class="p">)</code>

<code class="n">readsData</code> <code class="o">=</code> <code class="n">ac</code><code class="o">.</code><code class="n">loadAlignments</code><code class="p">(</code><code class="s2">"data/HG00103"</code><code class="p">)</code>

<code class="n">readsDataDF</code> <code class="o">=</code> <code class="n">readsData</code><code class="o">.</code><code class="n">toDF</code><code class="p">()</code>
<code class="n">readsDataDF</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="n">vertical</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>

<code class="o">...</code>

<code class="o">-</code><code class="n">RECORD</code> <code class="mi">0</code><code class="o">-----------------------------------------</code>
 <code class="n">referenceName</code>             <code class="o">|</code> <code class="n">hs37d5</code>
 <code class="n">start</code>                     <code class="o">|</code> <code class="mi">21810734</code>
 <code class="n">originalStart</code>             <code class="o">|</code> <code class="n">null</code>
 <code class="n">end</code>                       <code class="o">|</code> <code class="mi">21810826</code>
 <code class="n">mappingQuality</code>            <code class="o">|</code> <code class="mi">0</code>
 <code class="n">readName</code>                  <code class="o">|</code> <code class="n">SRR062640</code><code class="mf">.14600566</code>
 <code class="n">sequence</code>                  <code class="o">|</code> <code class="n">TCCATTCCACTCAGTTT</code><code class="o">...</code>
 <code class="n">qualityScores</code>             <code class="o">|</code> <code class="o">/</code><code class="n">MOONNCRQPIQIKRGL</code><code class="o">...</code>
 <code class="n">cigar</code>                     <code class="o">|</code> <code class="mi">92</code><code class="n">M8S</code>
 <code class="n">originalCigar</code>             <code class="o">|</code> <code class="n">null</code>
 <code class="n">basesTrimmedFromStart</code>     <code class="o">|</code> <code class="mi">0</code>
 <code class="n">basesTrimmedFromEnd</code>       <code class="o">|</code> <code class="mi">0</code>
 <code class="n">readPaired</code>                <code class="o">|</code> <code class="n">true</code>
 <code class="n">properPair</code>                <code class="o">|</code> <code class="n">false</code>
 <code class="n">readMapped</code>                <code class="o">|</code> <code class="n">false</code>
 <code class="n">mateMapped</code>                <code class="o">|</code> <code class="n">true</code>
 <code class="n">failedVendorQualityChecks</code> <code class="o">|</code> <code class="n">false</code>
 <code class="n">duplicateRead</code>             <code class="o">|</code> <code class="n">false</code>
 <code class="n">readNegativeStrand</code>        <code class="o">|</code> <code class="n">false</code>
 <code class="n">mateNegativeStrand</code>        <code class="o">|</code> <code class="n">false</code>
 <code class="n">primaryAlignment</code>          <code class="o">|</code> <code class="n">true</code>
 <code class="n">secondaryAlignment</code>        <code class="o">|</code> <code class="n">false</code>
 <code class="n">supplementaryAlignment</code>    <code class="o">|</code> <code class="n">false</code>
 <code class="n">mismatchingPositions</code>      <code class="o">|</code> <code class="n">null</code>
 <code class="n">originalQualityScores</code>     <code class="o">|</code> <code class="n">null</code>
 <code class="n">readGroupId</code>               <code class="o">|</code> <code class="n">SRR062640</code>
 <code class="n">readGroupSampleId</code>         <code class="o">|</code> <code class="n">HG00103</code>
 <code class="n">mateAlignmentStart</code>        <code class="o">|</code> <code class="mi">21810734</code>
 <code class="n">mateReferenceName</code>         <code class="o">|</code> <code class="n">hs37d5</code>
 <code class="n">insertSize</code>                <code class="o">|</code> <code class="n">null</code>
 <code class="n">readInFragment</code>            <code class="o">|</code> <code class="mi">1</code>
 <code class="n">attributes</code>                <code class="o">|</code> <code class="n">RG</code><code class="p">:</code><code class="n">Z</code><code class="p">:</code><code class="n">SRR062640</code>\<code class="n">tX</code><code class="o">...</code>
<code class="n">only</code> <code class="n">showing</code> <code class="n">top</code> <code class="mi">1</code> <code class="n">row</code></pre>
<p>You may get a different read because the partitioning of the data may be different on your system, so there is no guarantee which read will come back first.</p>
<p>Now we can interactively ask questions about our dataset, all while executing the computations across a cluster in the background. How many reads do we have in this dataset?</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">readsData</code><code class="o">.</code><code class="n">toDF</code><code class="p">()</code><code class="o">.</code><code class="n">count</code><code class="p">()</code>
<code class="o">...</code>
<code class="mi">160397565</code></pre>
<p>Do the reads in this dataset derive from all human chromosomes?</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">unique_chr</code> <code class="o">=</code> <code class="n">readsDataDF</code><code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s1">'referenceName'</code><code class="p">)</code><code class="o">.</code><code class="n">distinct</code><code class="p">()</code><code class="o">.</code><code class="n">collect</code><code class="p">()</code>
<code class="n">unique_chr</code> <code class="o">=</code> <code class="p">[</code><code class="n">u</code><code class="o">.</code><code class="n">referenceName</code> <code class="k">for</code> <code class="n">u</code> <code class="ow">in</code> <code class="n">unique_chr</code><code class="p">]</code>

<code class="n">unique_chr</code><code class="o">.</code><code class="n">sort</code><code class="p">()</code>
<code class="o">...</code>
<code class="mi">1</code>
<code class="mi">10</code>
<code class="mi">11</code>
<code class="mi">12</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code>
<code class="n">GL000249</code><code class="mf">.1</code>
<code class="n">MT</code>
<code class="n">NC_007605</code>
<code class="n">X</code>
<code class="n">Y</code>
<code class="n">hs37d5</code></pre>
<p class="pagebreak-before">Yep, we observe reads from chromosomes 1 through 22, X and Y, along with some other chromosomal chunks that are not part of the “main” chromosomes or whose locations are unknown. Let’s analyze the code a little more closely:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">readsData</code><code> </code><code class="o">=</code><code> </code><code class="n">ac</code><code class="o">.</code><code class="n">loadAlignments</code><code class="p">(</code><code class="s2">"</code><code class="s2">data/HG00103</code><code class="s2">"</code><code class="p">)</code><code> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-1" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code>
</code><code class="n">readsDataDF</code><code> </code><code class="o">=</code><code> </code><code class="n">readsData</code><code class="o">.</code><code class="n">toDF</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-2" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a><code>
</code><code>
</code><code class="n">unique_chr</code><code> </code><code class="o">=</code><code> </code><code class="n">readsDataDF</code><code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s1">'</code><code class="s1">referenceName</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code class="n">distinct</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code> </code><code>\</code><code> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-3" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-3"><img alt="3" height="12" src="assets/3.png" width="12"/></a><code>
</code><code>              </code><code class="n">collect</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-4" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-4"><img alt="4" height="12" src="assets/4.png" width="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-1" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p><code>AlignmentDataset</code>: an ADAM type that contains all our data.</p></dd>
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-2" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></dt>
<dd><p><code>DataFrame</code>: the underlying Spark DataFrame.</p></dd>
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-3" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-3"><img alt="3" height="12" src="assets/3.png" width="12"/></a></dt>
<dd><p>This will aggregate all the distinct contig names; it will be small.</p></dd>
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-4" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO3-4"><img alt="4" height="12" src="assets/4.png" width="12"/></a></dt>
<dd><p>This triggers the computation and brings the data in the DataFrame back to the client app (the shell).</p></dd>
</dl>
<p>For a more clinical example, <a data-primary="genomics" data-secondary="ADAM library" data-tertiary="gene variants testing" data-type="indexterm" id="idm46507963895024"/><a data-primary="ADAM library" data-secondary="genomics data analysis" data-tertiary="gene variants testing" data-type="indexterm" id="idm46507963893520"/><a data-primary="cystic fibrosis (CF) gene variants testing" data-type="indexterm" id="idm46507963892368"/><a data-primary="false positives" data-secondary="gene variants manual analysis" data-type="indexterm" id="idm46507963891728"/><a data-primary="genomics" data-secondary="ADAM library" data-tertiary="false positive manual analysis" data-type="indexterm" id="idm46507963890816"/><a data-primary="ADAM library" data-secondary="genomics data analysis" data-tertiary="false positive manual analysis" data-type="indexterm" id="idm46507963889632"/>say we are testing an individual’s genome to check whether they carry any gene variants that put them at risk for having a child with cystic fibrosis (CF).  Our genetic test uses next-generation DNA sequencing to generate reads from multiple relevant genes, such as the CFTR gene (whose mutations can cause CF).  After running our data through our genotyping pipeline, we determine that the CFTR gene appears to have a premature stop codon that destroys its function. <a data-primary="datasets" data-secondary="genomics" data-tertiary="Human Gene Mutation Database" data-type="indexterm" id="idm46507963888320"/><a data-primary="datasets" data-secondary="genomics" data-tertiary="Sickkids CFTR database" data-type="indexterm" id="idm46507963887136"/><a data-primary="genomics" data-secondary="databases" data-tertiary="Human Gene Mutation Database" data-type="indexterm" id="idm46507963885920"/><a data-primary="online resources" data-secondary="genomics" data-tertiary="Human Gene Mutation Database" data-type="indexterm" id="idm46507963884736"/><a data-primary="genomics" data-secondary="databases" data-tertiary="Sickkids CFTR database" data-type="indexterm" id="idm46507963883552"/><a data-primary="online resources" data-secondary="genomics" data-tertiary="Sickkids CFTR database" data-type="indexterm" id="idm46507963882336"/><a data-primary="cystic fibrosis (CF) gene variants testing" data-secondary="Sickkids CFTR database" data-type="indexterm" id="idm46507963881120"/>However, this mutation has never been reported before in the <a href="https://oreil.ly/wULRR">Human Gene Mutation Database</a>, nor is it in the <a href="https://oreil.ly/u1L0j">Sickkids CFTR database</a>, which aggregates CF gene variants.  We want to go back to the raw sequencing data to see if the potentially deleterious genotype call is a false positive.  To do so, we need to manually analyze all the reads that map to that variant locus, say, chromosome 7 at 117149189 (see <a data-type="xref" href="#IGV_HG00103_CFTR">Figure 9-1</a>):</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.sql</code> <code class="kn">import</code> <code class="n">functions</code> <code class="k">as</code> <code class="n">fun</code>
<code class="n">cftr_reads</code> <code class="o">=</code> <code class="n">readsDataDF</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="s2">"referenceName == 7"</code><code class="p">)</code><code class="o">.</code>\
              <code class="n">where</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"start"</code><code class="p">)</code> <code class="o">&lt;=</code> <code class="mi">117149189</code><code class="p">)</code><code class="o">.</code>\
              <code class="n">where</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"end"</code><code class="p">)</code> <code class="o">&gt;</code> <code class="mi">117149189</code><code class="p">)</code>

<code class="n">cftr_reads</code><code class="o">.</code><code class="n">count</code><code class="p">()</code>
<code class="o">...</code>

<code class="mi">9</code></pre>
<p>It is now possible to manually inspect these nine reads, or process them through a custom aligner, for example, and check whether the reported pathogenic variant is a false positive.</p>
<figure><div class="figure" id="IGV_HG00103_CFTR">
<img alt="aaps 0901" height="499" src="assets/aaps_0901.png" width="1021"/>
<h6><span class="label">Figure 9-1. </span>Integrative Genomic Viewer visualization of the HG00103 at chr7:117149189 in the CFTR gene</h6>
</div></figure>
<p>Say we’re running a clinical lab that is performing such carrier screening as a service to clinicians.  <a data-primary="persistent storage" data-secondary="gene variants data archiving" data-type="indexterm" id="idm46507963835888"/>Archiving the raw data using a cloud storage system such as AWS S3 ensures that the data stays relatively warm (compared with, say, tape archive).  In addition to having a reliable system for actually performing the data processing, we can easily access all of the past data for quality control or for cases where there needs to be manual interventions, like the CFTR example presented earlier.  In addition to the rapid access to the totality of the data, the centrality also makes it easy to perform large analytical studies, like population genetics, large-scale quality-control analyses, and so on.</p>
<p>Now that we are familiar with the ADAM API, let’s start work on creation of our transcription factor prediction dataset.<a data-startref="ch09-ingest" data-type="indexterm" id="idm46507963834432"/><a data-startref="ch09-ingest2" data-type="indexterm" id="idm46507963833728"/></p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="parquet-format">
<h5>Parquet Format and Columnar Storage</h5>
<p>In the previous section, we saw how we can manipulate a potentially<a data-primary="Parquet data storage format" data-secondary="ADAM project use of" data-type="indexterm" id="idm46507963831152"/><a data-primary="ADAM library" data-secondary="Parquet data storage format" data-tertiary="ADAM project use of" data-type="indexterm" id="idm46507963830208"/><a data-primary="genomics" data-secondary="Parquet data storage format" data-tertiary="ADAM project use of" data-type="indexterm" id="idm46507963791456"/> large amount of sequencing data without worrying about the specifics of the underlying storage or the parallelization of the execution.  However, it’s worth noting that the ADAM project makes use of the Parquet file format, which confers some considerable performance advantages that we introduce here.</p>
<p>Parquet is an open source file format<a data-primary="Parquet data storage format" data-type="indexterm" id="idm46507963789856"/><a data-primary="ADAM library" data-secondary="Parquet data storage format" data-type="indexterm" id="idm46507963788832"/><a data-primary="genomics" data-secondary="Parquet data storage format" data-type="indexterm" id="idm46507963787984"/> specification and a set of reader/writer implementations that we recommend for general use for data that will be used in analytical queries (write once, read many times).  <a data-primary="Google Dremel system" data-type="indexterm" id="idm46507963787008"/>It is largely based on the underlying data storage format used in Google’s Dremel system (see <a href="https://oreil.ly/iObP5">“Dremel: Interactive Analysis of Web-scale Datasets”</a>, Proc. VLDB, 2010, by Melnik et al.) and has a data model that is compatible with Avro, Thrift, and Protocol Buffers.  Specifically, it supports most of the common database types (<code>int</code>, <code>double</code>, <code>string</code>, etc.), along with arrays and records, including nested types.  <a data-primary="persistent storage" data-secondary="Parquet columnar file format" data-seealso="Parquet" data-type="indexterm" id="idm46507963784224"/>Significantly, it is a columnar file format, meaning that values for a particular column from many records are stored contiguously on disk (see <a data-type="xref" href="#ColumnarStorage">Figure 9-2</a>).  This physical data layout allows for far more efficient data encoding/compression, and significantly reduces query times by <a href="https://oreil.ly/GciCh">minimizing the amount of data that must be read/deserialized</a>.  Parquet supports specifying different compression schemes for each column, as well as column-specific encoding schemes such as run-length encoding, dictionary encoding, and delta encoding.</p>
<figure><div class="figure" id="ColumnarStorage">
<img alt="aaps 0902" height="1001" src="assets/aaps_0902.png" width="1086"/>
<h6><span class="label">Figure 9-2. </span>Differences between a row-major and column-major data layout</h6>
</div></figure>
<p>Another useful feature of Parquet for increasing<a data-primary="Parquet data storage format" data-secondary="predicate pushdown" data-type="indexterm" id="idm46507963779088"/><a data-primary="predicate pushdown of Parquet" data-type="indexterm" id="idm46507963778176"/><a data-primary="binary predicates" data-type="indexterm" id="idm46507963777568"/> performance is <em>predicate pushdown</em>. A <em>predicate</em> is some expression or function that evaluates to <code>true</code> or <code>false</code> based on the data record (or equivalently, the expressions in a SQL <code>WHERE</code> clause). In our earlier CFTR query, Spark had to deserialize/materialize each <code>AlignmentRecord</code> before deciding whether or not it passed the predicate.  This leads to a significant amount of wasted I/O and CPU time.  The Parquet reader implementations allow us to provide a predicate class that only deserializes the necessary columns for making the decision, before materializing the full record.<a data-startref="ch09-gedaan" data-type="indexterm" id="idm46507963774320"/><a data-startref="ch09-gedaan2" data-type="indexterm" id="idm46507963773616"/><a data-startref="ch09-gedaan3" data-type="indexterm" id="idm46507963772944"/></p>
</div></aside>
</div></section>
</div></section>
<section data-pdf-bookmark="Predicting Transcription Factor Binding Sites from ENCODE Data" data-type="sect1"><div class="sect1" id="idm46507966454032">
<h1>Predicting Transcription Factor Binding Sites from <span class="keep-together">ENCODE Data</span></h1>
<p>In this example, we will use publicly available<a data-primary="genomics" data-secondary="transcription factor binding sites" data-type="indexterm" id="ch09-tf"/><a data-primary="transcription factor (TF) binding sites" data-type="indexterm" id="ch09-tf2"/><a data-primary="ADAM library" data-secondary="transcription factor binding sites" data-type="indexterm" id="ch09-tf3"/><a data-primary="ENCODE project" data-secondary="transcription factor binding sites" data-type="indexterm" id="ch09-tf4"/><a data-primary="models" data-secondary="transcription factor binding sites" data-type="indexterm" id="ch09-tf5"/><a data-primary="transcription factor (TF) binding sites" data-secondary="about transcription factors" data-type="indexterm" id="ch09-tf6"/> sequence feature data to build a simple model for transcription factor binding. TFs are proteins that bind to specific DNA sequences in the genome and help control the expression of different genes.  As a result, they are critical in determining the phenotype of a particular cell and are involved in many physiological and disease processes.  <a data-primary="next-generation DNA sequencing (NGS)" data-seealso="genomics" data-type="indexterm" id="idm46507963762960"/><a data-primary="ChIP-seq NGS-based assay" data-type="indexterm" id="idm46507963762000"/>ChIP-seq is an NGS-based assay that allows the genome-wide characterization of binding sites for a particular TF in a particular cell/tissue type.  However, in addition to ChIP-seq’s cost and technical difficulty, it requires a separate experiment for each tissue/TF pair.  <a data-primary="DNase-seq genomic assay" data-type="indexterm" id="ch09-tf7"/>In contrast, DNase-seq is an assay that finds regions of open chromatin genome-wide and needs to be performed only once per tissue type.  Instead of assaying TF binding sites by performing a ChIP-seq experiment for each tissue/TF combination, we’d like to predict TF binding sites in a new tissue type assuming only the availability of DNase-seq data.</p>
<p>In particular, we will predict the binding sites for the CTCF TF using DNase-seq data along with <a data-primary="online resources" data-secondary="genomics" data-tertiary="HT-SELEX sequence motif data" data-type="indexterm" id="idm46507963759520"/><a data-primary="HT-SELEX sequence motif data" data-type="indexterm" id="idm46507963758304"/>known sequence motif data (from <a href="https://oreil.ly/t5OEkL">HT-SELEX</a>) and other data<a data-primary="ENCODE project" data-secondary="link" data-type="indexterm" id="idm46507963756880"/><a data-primary="online resources" data-secondary="genomics" data-tertiary="ENCODE project" data-type="indexterm" id="idm46507963755872"/> from <a href="https://oreil.ly/eFJ9n">the publicly available ENCODE dataset</a>.  We have chosen six different cell types that have available DNase-seq and CTCF ChIP-seq data for training.  A training example will be a DNase hypersensitivity (HS) peak (a segment of the genome), and the binary label for whether the TF is bound/unbound will be derived from the ChIP-seq data.</p>
<p>To summarize the overall data flow: the main training/test examples will be derived from the DNase-seq data.  Each region of open chromatin (an interval on the genome) will be used to generate a prediction of whether a particular TF in a particular tissue type will be bound there.  To do so, we spatially join the ChIP-seq data to the DNase-seq data; every overlap is a positive label for the DNase seq objects.  Finally, to improve the prediction accuracy, we generate an additional feature at each interval in the DNase-seq data—distance to a transcription start site (using the GENCODE dataset). The feature is added into the training examples by performing a spatial join (with a possible aggregation).</p>
<p>We will use data from the following cell lines:<a data-primary="transcription factor (TF) binding sites" data-secondary="DNase data for cell lines" data-type="indexterm" id="idm46507963753152"/><a data-primary="genomics" data-secondary="transcription factor binding sites" data-tertiary="DNase data for cell lines" data-type="indexterm" id="idm46507963752112"/><a data-primary="ADAM library" data-secondary="transcription factor binding sites" data-tertiary="DNase data for cell lines" data-type="indexterm" id="idm46507963750864"/><a data-primary="datasets" data-secondary="genomics" data-tertiary="DNase data for cell lines" data-type="indexterm" id="idm46507963749616"/></p>
<dl>
<dt>GM12878</dt>
<dd>
<p>Commonly studied lymphoblastoid cell line</p>
</dd>
<dt>K562</dt>
<dd>
<p>Female chronic myelogenous leukemia</p>
</dd>
<dt>BJ</dt>
<dd>
<p>Skin fibroblast</p>
</dd>
<dt>HEK293</dt>
<dd>
<p>Embryonic kidney</p>
</dd>
<dt>H54</dt>
<dd>
<p>Glioblastoma</p>
</dd>
<dt>HepG2</dt>
<dd>
<p>Hepatocellular carcinoma</p>
</dd>
</dl>
<p>First, we download the DNase data for each cell line in <em>.narrowPeak</em> format:</p>
<pre data-code-language="shell" data-type="programlisting"><code>mkdir</code><code> </code><code>data/genomics/dnase</code><code>

</code><code>curl</code><code> </code><code>-O</code><code> </code><code>-L</code><code> </code><code class="s2">"https://www.encodeproject.org/ \
              files/ENCFF001UVC/@@download/ENCFF001UVC.bed.gz"</code><code> </code><code class="p">|</code><code> </code><code class="se">\
</code><code>              </code><code>gunzip</code><code> </code><code>&gt;</code><code> </code><code>data/genomics/dnase/GM12878.DNase.narrowPeak</code><code> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO4-1" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO4-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code>curl</code><code> </code><code>-O</code><code> </code><code>-L</code><code> </code><code class="s2">"https://www.encodeproject.org/ \
              files/ENCFF001UWQ/@@download/ENCFF001UWQ.bed.gz"</code><code> </code><code class="p">|</code><code> </code><code class="se">\
</code><code>              </code><code>gunzip</code><code> </code><code>&gt;</code><code> </code><code>data/genomics/dnase/K562.DNase.narrowPeak</code><code>
</code><code>curl</code><code> </code><code>-O</code><code> </code><code>-L</code><code> </code><code class="s2">"https://www.encodeproject.org/ \
              files/ENCFF001WEI/@@download/ENCFF001WEI.bed.gz"</code><code> </code><code class="p">|</code><code> </code><code class="se">\
</code><code>              </code><code>gunzip</code><code> </code><code>&gt;</code><code> </code><code>data/genomics/dnase/BJ.DNase.narrowPeak</code><code>
</code><code>curl</code><code> </code><code>-O</code><code> </code><code>-L</code><code> </code><code class="s2">"https://www.encodeproject.org/ \
              files/ENCFF001UVQ/@@download/ENCFF001UVQ.bed.gz"</code><code> </code><code class="p">|</code><code> </code><code class="se">\
</code><code>              </code><code>gunzip</code><code> </code><code>&gt;</code><code> </code><code>data/genomics/dnase/HEK293.DNase.narrowPeak</code><code>
</code><code>curl</code><code> </code><code>-O</code><code> </code><code>-L</code><code> </code><code class="s2">"https://www.encodeproject.org/ \
            files/ENCFF001SOM/@@download/ENCFF001SOM.bed.gz"</code><code> </code><code class="p">|</code><code> </code><code class="se">\
</code><code>            </code><code>gunzip</code><code> </code><code>&gt;</code><code> </code><code>data/genomics/dnase/H54.DNase.narrowPeak</code><code>
</code><code>curl</code><code> </code><code>-O</code><code> </code><code>-L</code><code> </code><code class="s2">"https://www.encodeproject.org/ \
            files/ENCFF001UVU/@@download/ENCFF001UVU.bed.gz"</code><code> </code><code class="p">|</code><code> </code><code class="se">\
</code><code>            </code><code>gunzip</code><code> </code><code>&gt;</code><code> </code><code>data/genomics/dnase/HepG2.DNase.narrowPeak</code><code>

</code><code class="o">[</code><code>...</code><code class="o">]</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO4-1" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO4-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>Streaming decompression</p></dd>
</dl>
<p>Next, we download the ChIP-seq data<a data-primary="transcription factor (TF) binding sites" data-secondary="ChIP-seq data for CTCF TF" data-type="indexterm" id="idm46507963637760"/><a data-primary="ADAM library" data-secondary="transcription factor binding sites" data-tertiary="ChIP-seq data for CTCF TF" data-type="indexterm" id="idm46507963636752"/><a data-primary="genomics" data-secondary="transcription factor binding sites" data-tertiary="ChIP-seq data for CTCF TF" data-type="indexterm" id="idm46507963655664"/><a data-primary="datasets" data-secondary="genomics" data-tertiary="ChIP-seq data for CTCF TF" data-type="indexterm" id="idm46507963654416"/> for the CTCF TF, also in <em>.narrowPeak</em> format, and the GENCODE data, in GTF format:</p>
<pre data-code-language="shell" data-type="programlisting">mkdir data/genomics/chip-seq

curl -O -L <code class="s2">"https://www.encodeproject.org/ \</code>
<code class="s2">            files/ENCFF001VED/@@download/ENCFF001VED.bed.gz"</code> <code class="p">|</code> <code class="se">\</code>
            gunzip &gt; data/genomics/chip-seq/GM12878.ChIP-seq.CTCF.narrowPeak
curl -O -L <code class="s2">"https://www.encodeproject.org/ \</code>
<code class="s2">            files/ENCFF001VMZ/@@download/ENCFF001VMZ.bed.gz"</code> <code class="p">|</code> <code class="se">\</code>
            gunzip &gt; data/genomics/chip-seq/K562.ChIP-seq.CTCF.narrowPeak
curl -O -L <code class="s2">"https://www.encodeproject.org/ \</code>
<code class="s2">            files/ENCFF001XMU/@@download/ENCFF001XMU.bed.gz"</code> <code class="p">|</code> <code class="se">\</code>
            gunzip &gt; data/genomics/chip-seq/BJ.ChIP-seq.CTCF.narrowPeak
curl -O -L <code class="s2">"https://www.encodeproject.org/ \</code>
<code class="s2">            files/ENCFF001XQU/@@download/ENCFF001XQU.bed.gz"</code> <code class="p">|</code> <code class="se">\</code>
            gunzip &gt; data/genomics/chip-seq/HEK293.ChIP-seq.CTCF.narrowPeak
curl -O -L <code class="s2">"https://www.encodeproject.org/ \</code>
<code class="s2">            files/ENCFF001USC/@@download/ENCFF001USC.bed.gz"</code> <code class="p">|</code> <code class="se">\</code>
            gunzip&gt; data/genomics/chip-seq/H54.ChIP-seq.CTCF.narrowPeak
curl -O -L <code class="s2">"https://www.encodeproject.org/ \</code>
<code class="s2">            files/ENCFF001XRC/@@download/ENCFF001XRC.bed.gz"</code> <code class="p">|</code> <code class="se">\</code>
            gunzip&gt; data/genomics/chip-seq/HepG2.ChIP-seq.CTCF.narrowPeak

curl -s -L <code class="s2">"http://ftp.ebi.ac.uk/pub/databases/gencode/\</code>
<code class="s2">            Gencode_human/release_18/gencode.v18.annotation.gtf.gz"</code> <code class="p">|</code> <code class="se">\</code>
            gunzip &gt; data/genomics/gencode.v18.annotation.gtf
<code class="o">[</code>...<code class="o">]</code></pre>
<p>Note how we unzip the stream of data with <code>gunzip</code> on the way to depositing it in our filesystem.</p>
<p>From all of this raw data, we want to generate a training set with a schema like the following:</p>
<ol>
<li>
<p>Chromosome</p>
</li>
<li>
<p>Start</p>
</li>
<li>
<p>End</p>
</li>
<li>
<p>Distance to closest transcription start site (TSS)</p>
</li>
<li>
<p>TF identity (always “CTCF” in this case)</p>
</li>
<li>
<p>Cell line</p>
</li>
<li>
<p>TF binding status (boolean; the target variable)</p>
</li>
</ol>
<p>This dataset can easily be converted into a DataFrame to carry into a machine learning library. Since we need to generate the data for multiple cell lines, we will define a DataFrame for each cell line individually and concatenate them at the end:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">cell_lines</code> <code class="o">=</code> <code class="p">[</code><code class="s2">"GM12878"</code><code class="p">,</code> <code class="s2">"K562"</code><code class="p">,</code> <code class="s2">"BJ"</code><code class="p">,</code> <code class="s2">"HEK293"</code><code class="p">,</code> <code class="s2">"H54"</code><code class="p">,</code> <code class="s2">"HepG2"</code><code class="p">]</code>
<code class="k">for</code> <code class="n">cell</code> <code class="ow">in</code> <code class="n">cell_lines</code><code class="p">:</code>
<code class="c1">## For each cell line…</code>
  <code class="c1">## …generate a suitable DataFrame</code>
<code class="c1">## Concatenate the DataFrames and carry through into MLlib, for example</code></pre>
<p>We define a utility function and a broadcast variable that will be used to generate the features:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">local_prefix</code> <code class="o">=</code> <code class="s2">"data/genomics"</code>
<code class="kn">import</code> <code class="nn">pyspark.sql.functions</code> <code class="k">as</code> <code class="nn">fun</code>

<code class="c1">## UDF for finding closest transcription start site</code>
<code class="c1">## naive; exercise for reader: make this faster</code>
<code class="k">def</code> <code class="nf">distance_to_closest</code><code class="p">(</code><code class="n">loci</code><code class="p">,</code> <code class="n">query</code><code class="p">):</code>
  <code class="k">return</code> <code class="nb">min</code><code class="p">([</code><code class="nb">abs</code><code class="p">(</code><code class="n">x</code> <code class="o">-</code> <code class="n">query</code><code class="p">)</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">loci</code><code class="p">])</code>
<code class="n">distance_to_closest_udf</code> <code class="o">=</code> <code class="n">fun</code><code class="o">.</code><code class="n">udf</code><code class="p">(</code><code class="n">distance_to_closest</code><code class="p">)</code>


<code class="c1">## build in-memory structure for computing distance to TSS</code>
<code class="c1">## we are essentially implementing a broadcast join here</code>
<code class="n">tss_data</code> <code class="o">=</code> <code class="n">ac</code><code class="o">.</code><code class="n">loadFeatures</code><code class="p">(</code><code class="s2">"data/genomics/gencode.v18.annotation.gtf"</code><code class="p">)</code>
<code class="n">tss_df</code> <code class="o">=</code> <code class="n">tss_data</code><code class="o">.</code><code class="n">toDF</code><code class="p">()</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"featureType"</code><code class="p">)</code> <code class="o">==</code> <code class="s1">'transcript'</code><code class="p">)</code>
<code class="n">b_tss_df</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">sparkContext</code><code class="o">.</code><code class="n">broadcast</code><code class="p">(</code><code class="n">tss_df</code><code class="o">.</code><code class="n">groupBy</code><code class="p">(</code><code class="s1">'referenceName'</code><code class="p">)</code><code class="o">.</code>\
                <code class="n">agg</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">collect_list</code><code class="p">(</code><code class="s2">"start"</code><code class="p">)</code><code class="o">.</code><code class="n">alias</code><code class="p">(</code><code class="s2">"start_sites"</code><code class="p">)))</code></pre>
<p>Now that we have loaded the data necessary for defining our training examples, we define the body of the “loop” for computing the data on each cell line.  Note how we read the text representations of the ChIP-seq and DNase data, because the datasets are not so large that they will hurt performance.</p>
<p>To do so, we load the DNase and ChIP-seq data:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">current_cell_line</code><code> </code><code class="o">=</code><code> </code><code class="n">cell_lines</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code>
</code><code>
</code><code class="n">dnase_path</code><code> </code><code class="o">=</code><code> </code><code class="sa">f</code><code class="s1">'</code><code class="s1">data/genomics/dnase/</code><code class="si">{</code><code class="n">current_cell_line</code><code class="si">}</code><code class="s1">.DNase.narrowPeak</code><code class="s1">'</code><code>
</code><code class="n">dnase_data</code><code> </code><code class="o">=</code><code> </code><code class="n">ac</code><code class="o">.</code><code class="n">loadFeatures</code><code class="p">(</code><code class="n">dnase_path</code><code class="p">)</code><code> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO5-1" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO5-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code class="n">dnase_data</code><code class="o">.</code><code class="n">toDF</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code class="n">columns</code><code> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO5-2" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO5-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a><code>
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code>
</code><code class="p">[</code><code class="s1">'</code><code class="s1">featureId</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">sampleId</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">name</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">source</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">featureType</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">referenceName</code><code class="s1">'</code><code class="p">,</code><code>
</code><code class="s1">'</code><code class="s1">start</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">end</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">strand</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">phase</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">frame</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">score</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">geneId</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">transcriptId</code><code class="s1">'</code><code class="p">,</code><code>
</code><code class="s1">'</code><code class="s1">exonId</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">proteinId</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">aliases</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">parentIds</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">target</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">gap</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">derivesFrom</code><code class="s1">'</code><code class="p">,</code><code>
</code><code class="s1">'</code><code class="s1">notes</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">dbxrefs</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">ontologyTerms</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">circular</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">attributes</code><code class="s1">'</code><code class="p">]</code><code>
</code><code>
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code>
</code><code>
</code><code class="n">chip_seq_path</code><code> </code><code class="o">=</code><code> </code><code class="sa">f</code><code class="s1">'</code><code class="s1">data/genomics/chip-seq/ </code><code class="se">\
</code><code class="s1">                  </code><code class="si">{</code><code class="n">current_cell_line</code><code class="si">}</code><code class="s1">.ChIP-seq.CTCF.narrowPeak</code><code class="s1">'</code><code>
</code><code class="n">chipseq_data</code><code> </code><code class="o">=</code><code> </code><code class="n">ac</code><code class="o">.</code><code class="n">loadFeatures</code><code class="p">(</code><code class="n">chipseq_path</code><code class="p">)</code><code> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO5-1" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO5-3"><img alt="1" height="12" src="assets/1.png" width="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO5-1" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO5-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p><code>FeatureDataset</code></p></dd>
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO5-2" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO5-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></dt>
<dd><p>Columns in Dnase DataFrame</p></dd>
</dl>
<p>Sites that overlap a ChIP-seq peak, as defined by a <code>ReferenceRegion</code> in <code>chipseq_data</code>, have TF binding sites and are therefore labeled <code>true</code>, while the rest of the sites are labeled <code>false</code>. This is accomplished using the 1D spatial join primitives provided in the ADAM API. The join functionality requires an RDD that is keyed by a <code>ReferenceRegion</code> and will produce tuples that have overlapping regions, according to usual join semantics (e.g., inner versus outer).</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">dnase_with_label</code> <code class="o">=</code> <code class="n">dnase_data</code><code class="o">.</code><code class="n">leftOuterShuffleRegionJoin</code><code class="p">(</code><code class="n">chipseq_data</code><code class="p">)</code>
<code class="n">dnase_with_label_df</code> <code class="o">=</code> <code class="n">dnase_with_label</code><code class="o">.</code><code class="n">toDF</code><code class="p">()</code>
<code class="o">...</code>

<code class="o">-</code><code class="n">RECORD</code> <code class="mi">0</code><code class="o">----------------------------------------------------------------------..</code>
 <code class="n">_1</code>  <code class="o">|</code> <code class="p">{</code><code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">chr1</code><code class="mf">.1</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">chr1</code><code class="p">,</code> <code class="mi">713841</code><code class="p">,</code> <code class="mi">714424</code><code class="p">,</code> <code class="n">INDEPENDENT</code><code class="p">,</code> <code class="n">null</code><code class="o">..</code>
 <code class="n">_2</code>  <code class="o">|</code> <code class="p">{</code><code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">chr1</code><code class="p">,</code> <code class="mi">713945</code><code class="p">,</code> <code class="mi">714492</code><code class="p">,</code> <code class="n">INDEPENDENT</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="o">..</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">1</code><code class="o">----------------------------------------------------------------------..</code>
 <code class="n">_1</code>  <code class="o">|</code> <code class="p">{</code><code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">chr1</code><code class="mf">.2</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">chr1</code><code class="p">,</code> <code class="mi">740179</code><code class="p">,</code> <code class="mi">740374</code><code class="p">,</code> <code class="n">INDEPENDENT</code><code class="p">,</code> <code class="n">null</code><code class="o">..</code>
 <code class="n">_2</code>  <code class="o">|</code> <code class="p">{</code><code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">chr1</code><code class="p">,</code> <code class="mi">740127</code><code class="p">,</code> <code class="mi">740310</code><code class="p">,</code> <code class="n">INDEPENDENT</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="o">..</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">2</code><code class="o">----------------------------------------------------------------------..</code>
 <code class="n">_1</code>  <code class="o">|</code> <code class="p">{</code><code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">chr1</code><code class="mf">.3</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">null</code><code class="p">,</code> <code class="n">chr1</code><code class="p">,</code> <code class="mi">762054</code><code class="p">,</code> <code class="mi">763213</code><code class="p">,</code> <code class="n">INDEPENDENT</code><code class="p">,</code> <code class="n">null</code><code class="o">..</code>
 <code class="n">_2</code>  <code class="o">|</code> <code class="n">null</code><code class="o">...</code>
<code class="n">only</code> <code class="n">showing</code> <code class="n">top</code> <code class="mi">3</code> <code class="n">rows</code>
<code class="o">...</code>

<code class="n">dnase_with_label_df</code> <code class="o">=</code> <code class="n">dnase_with_label_df</code><code class="o">.</code>\
                        <code class="n">withColumn</code><code class="p">(</code><code class="s2">"label"</code><code class="p">,</code> \
                                    <code class="o">~</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"_2"</code><code class="p">)</code><code class="o">.</code><code class="n">isNull</code><code class="p">())</code>
<code class="n">dnase_with_label_df</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code></pre>
<p>Now we compute the final set of features on each DNase peak:</p>
<pre data-code-language="python" data-type="programlisting"><code class="c1">## build final training DF</code><code>
</code><code class="n">training_df</code><code> </code><code class="o">=</code><code> </code><code class="n">dnase_with_label_df</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code>
</code><code>    </code><code class="s2">"</code><code class="s2">contig</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"</code><code class="s2">_1</code><code class="s2">"</code><code class="p">)</code><code class="o">.</code><code class="n">referenceName</code><code class="p">)</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code>
</code><code>    </code><code class="s2">"</code><code class="s2">start</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"</code><code class="s2">_1</code><code class="s2">"</code><code class="p">)</code><code class="o">.</code><code class="n">start</code><code class="p">)</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code>
</code><code>    </code><code class="s2">"</code><code class="s2">end</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"</code><code class="s2">_1</code><code class="s2">"</code><code class="p">)</code><code class="o">.</code><code class="n">end</code><code class="p">)</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code>
</code><code>    </code><code class="s2">"</code><code class="s2">tf</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="n">fun</code><code class="o">.</code><code class="n">lit</code><code class="p">(</code><code class="s2">"</code><code class="s2">CTCF</code><code class="s2">"</code><code class="p">)</code><code class="p">)</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code>
</code><code>    </code><code class="s2">"</code><code class="s2">cell_line</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="n">fun</code><code class="o">.</code><code class="n">lit</code><code class="p">(</code><code class="n">current_cell_line</code><code class="p">)</code><code class="p">)</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="s2">"</code><code class="s2">_1</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="s2">"</code><code class="s2">_2</code><code class="s2">"</code><code class="p">)</code><code>
</code><code>
</code><code class="n">training_df</code><code> </code><code class="o">=</code><code> </code><code class="n">training_df</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">b_tss_df</code><code class="p">,</code><code>
</code><code>                               </code><code class="n">training_df</code><code class="o">.</code><code class="n">contig</code><code> </code><code class="o">==</code><code> </code><code class="n">b_tss_df</code><code class="o">.</code><code class="n">referenceName</code><code class="p">,</code><code>
</code><code>                               </code><code class="s2">"</code><code class="s2">inner</code><code class="s2">"</code><code class="p">)</code><code> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO6-1" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO6-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code>
</code><code class="n">training_df</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s2">"</code><code class="s2">closest_tss</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                      </code><code class="n">fun</code><code class="o">.</code><code class="n">least</code><code class="p">(</code><code class="n">distance_to_closest_udf</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"</code><code class="s2">start_sites</code><code class="s2">"</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                                                        </code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"</code><code class="s2">start</code><code class="s2">"</code><code class="p">)</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                          </code><code class="n">distance_to_closest_udf</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"</code><code class="s2">start_sites</code><code class="s2">"</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                                                  </code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"</code><code class="s2">end</code><code class="s2">"</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO6-2" id="co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO6-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO6-1" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO6-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>Left join with <code>tss_df</code> created earlier.</p></dd>
<dt><a class="co" href="#co_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO6-2" id="callout_analyzing_genomics_data___span_class__keep_together__and_the_bdg_project__span__CO6-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></dt>
<dd><p>Get the closest TSS distance.</p></dd>
</dl>
<p>This final DF is computed in each pass of the loop over the cell lines.  Finally, we union each DF from each cell line and cache this data in memory in preparation for training models off of it:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">preTrainingData</code> <code class="o">=</code> <code class="n">data_by_cellLine</code><code class="o">.</code><code class="n">union</code><code class="p">(</code><code class="o">...</code><code class="p">)</code>
<code class="n">preTrainingData</code><code class="o">.</code><code class="n">cache</code><code class="p">()</code>

<code class="n">preTrainingData</code><code class="o">.</code><code class="n">count</code><code class="p">()</code>
<code class="n">preTrainingData</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"label"</code><code class="p">)</code> <code class="o">==</code> <code class="n">true</code><code class="p">)</code><code class="o">.</code><code class="n">count</code><code class="p">()</code></pre>
<p>At this point, the data in <code>preTrainingData</code> can be normalized and converted into a DataFrame for training a classifier, as described in <a data-type="xref" href="ch04.xhtml#RandomDecisionForests">“Random Forests”</a>.  Note that you should perform cross-validation, where in each fold, you hold out the data from one of the cell lines.<a data-startref="ch09-tf" data-type="indexterm" id="idm46507962601536"/><a data-startref="ch09-tf2" data-type="indexterm" id="idm46507962600896"/><a data-startref="ch09-tf3" data-type="indexterm" id="idm46507962600224"/><a data-startref="ch09-tf4" data-type="indexterm" id="idm46507962599552"/><a data-startref="ch09-tf5" data-type="indexterm" id="idm46507962598880"/><a data-startref="ch09-tf6" data-type="indexterm" id="idm46507962598208"/><a data-startref="ch09-tf7" data-type="indexterm" id="idm46507962553648"/></p>
</div></section>
<section data-pdf-bookmark="Where to Go from Here" data-type="sect1"><div class="sect1" id="idm46507963771488">
<h1>Where to Go from Here</h1>
<p>Many computations in genomics fit nicely into the PySpark computational paradigm.  When you’re performing ad hoc analysis, the most valuable contribution that projects like ADAM provide is the set of Avro schemas that represents the underlying analytical objects (along with the conversion tools).  We saw how once data is converted into the corresponding Avro schemas, many large-scale computations become relatively easy to express and distribute.</p>
<p>While there may still be a relative dearth of tools for performing scientific research on PySpark, there do exist a few projects that could help avoid reinventing the wheel.  We explored the core functionality implemented in ADAM, but the project already has implementations for the entire GATK best-practices pipeline, including indel realignment, and deduplication.  <a data-primary="Genome Analysis Toolkit (GATK; Broad Institute)" data-type="indexterm" id="idm46507962551792"/><a data-primary="genomics" data-secondary="Broad Institute Spark projects" data-type="indexterm" id="idm46507962551184"/><a data-primary="Broad Institute genomic Spark projects" data-type="indexterm" id="idm46507962550336"/><a data-primary="GATK (Genome Analysis Toolkit; Broad Institute)" data-type="indexterm" id="idm46507962549728"/><a data-primary="Hail population genetics tool (Broad Institute)" data-type="indexterm" id="idm46507962549120"/><a data-primary="online resources" data-secondary="genomics" data-tertiary="GATK4 (Broad Institute)" data-type="indexterm" id="idm46507962548512"/><a data-primary="online resources" data-secondary="genomics" data-tertiary="Hail (Broad Institute)" data-type="indexterm" id="idm46507962547424"/><a data-primary="ADAM library" data-secondary="about" data-tertiary="Genome Analysis Toolkit" data-type="indexterm" id="idm46507962546336"/><a data-primary="genomics" data-secondary="ADAM library" data-tertiary="Genome Analysis Toolkit" data-type="indexterm" id="idm46507962545248"/>In addition to ADAM, the Broad Institute is now developing major software projects using Spark, including the newest version of the <a href="https://oreil.ly/hGR87">GATK4</a> and a project called <a href="https://oreil.ly/V6Wpl">Hail</a> for large-scale population genetics computations. All of these tools are open source, so if you start using them in your own work, please consider contributing improvements!</p>
</div></section>
</div></section></div></body></html>