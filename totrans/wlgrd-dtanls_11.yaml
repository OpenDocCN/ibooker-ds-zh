- en: '12 Iterating on someone else’s work: Data preparation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Continuing the work of another analyst
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Investigating and verifying an existing analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing event-level data to be suitable for user-level segmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every analyst will need to continue someone else’s work at some point. This
    “someone” might be a past version of you from months ago. The process for working
    on the second version of a project is the same as starting from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Because we will own this new version, we still need to understand the problem,
    look at the available data, and so on, even if someone else has already done it.
    In this project, you will get the opportunity to practice taking over from someone
    else. Another analyst has prepared the minimum viable answer to a stakeholder
    question, on which you will iterate.
  prefs: []
  type: TYPE_NORMAL
- en: 'The specific topic of this chapter is one that is also common in the real world:
    segmentation. Most businesses have questions in the form of “How are some things
    similar to other things?” where the thing in question could be anything from a
    product to a customer to an entire geographic area.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Real business case: Segmenting customers based on buying activity'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The specific methods required to segment customers will come in handy for segmenting
    anything. For example, one project I worked on was identifying customers who bought
    similar used cars at auction. Having a notion of buyer similarity meant we could
    find more buyers to whom we could proactively recommend upcoming auctions. Being
    able to invite buyers to an auction because we know they buy similar stock led
    to more productive conversations and more eyes on our auctioned cars.
  prefs: []
  type: TYPE_NORMAL
- en: The process for finding similar entities, what we refer to here as “segmentation,”
    is the same regardless of the type of entity. In this chapter specifically, you
    will practice segmenting mobile users into groups based on their app usage activity.
    You will work with event-level data and continue the work of another analyst who
    has already completed an iteration of the project.
  prefs: []
  type: TYPE_NORMAL
- en: 12.1 Finding similar entities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The problem of segmentation appears in many places. The typical use case is
    finding customers who are similar to each other based on characteristics such
    as demographics or behavior. A business may also want to apply segmentation to
    its product catalog to categorize and simplify its offering.
  prefs: []
  type: TYPE_NORMAL
- en: In each case, the outcome is that different actions will be taken for different
    segments. Users in different financial segments will be targeted with different
    banking products. Products that are grouped into a segment may be recommended
    alongside each other to the end user. Recommendation engines make heavy use of
    the notion of user and product similarity.
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, segmentation, or clustering, is an example of unsupervised
    learning. This means that, unlike supervised prediction problems, we don’t have
    examples of the “truth,” that is, actual customer segments against which to compare
    our results. Our ability to measure how good our segments are is, therefore, limited.
    The evaluation of these segments is usually done subjectively by human experts
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised vs. unsupervised learning
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In machine learning, the difference between supervised and unsupervised learning
    is whether we have historical examples of correct predictions against which to
    compare our model’s predictions.
  prefs: []
  type: TYPE_NORMAL
- en: If we are predicting the price of a house based on its properties, we need training
    data that includes both the properties of the houses and the prices they sold
    for. This is *supervised* learning because we can compare our model’s predictions
    to actual values, thus supervising our prediction model.
  prefs: []
  type: TYPE_NORMAL
- en: In *unsupervised* learning, we do not have such past examples. There are no
    correct answers to compare against. Instead, we are trying to find patterns of
    some sort in
  prefs: []
  type: TYPE_NORMAL
- en: our data, which we then evaluate more subjectively. Customer segmentation falls
    neatly into this latter category.
  prefs: []
  type: TYPE_NORMAL
- en: 'In any similarity problem, there are certain factors to consider when deciding
    on our approach:'
  prefs: []
  type: TYPE_NORMAL
- en: What action will we take when we have our groups? This is the most important
    question to ask since it motivates the entire project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What features are important when determining similarity? Do we care about users
    who live in the same area or who have similar purchasing patterns?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On a related note, do we have redundant features? If we’re segmenting cars,
    we don’t want to include their top speed in both kilometers and miles per hour.
    One variable to measure a particular concept is enough.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many groups do we believe we will find? We may not have an exact number,
    but even a ballpark will help.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will we evaluate the outcome of the segmentation? Usually, this is done
    with the help of domain experts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this project, in addition to these factors, we will also want a checklist
    of actions for how to continue the previous analyst’s work.
  prefs: []
  type: TYPE_NORMAL
- en: 12.2 Continuing someone else’s work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a situation where we are continuing someone else’s work, the first step should
    be to replicate their findings whether or not the original source code is available.
    The reasons for this are
  prefs: []
  type: TYPE_NORMAL
- en: Having our own version of the previous pipeline means we can more easily make
    changes to it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recreating someone else’s work checks for mistakes, not with the purpose of
    blaming anyone, but to verify that their steps did what they said they did.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also want to verify the assumptions present in the previous analyst’s work.
    It’s possible they made incorrect assumptions or even just different assumptions
    to the ones we’d make. Being explicit about these assumptions gives everyone clarity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replicating the work puts us in a better position to understand the details
    of the project, the limitations, and what further steps are possible. Looking
    at someone else’s work briefly is not the same as getting into the weeds ourselves.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we consider these factors before we start work, then, combined with our results-driven
    approach, we will be well equipped for the project to succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborating with others
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this project, you are indirectly collaborating with another analyst by continuing
    their work. You won’t always be the only analyst on a project; there will be times
    when you share the work with other analysts. Being an effective collaborator means
  prefs: []
  type: TYPE_NORMAL
- en: Communicating your work to other technical colleagues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying best practices to your work to make your code easier to work with
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consistently looking for ways to improve and learn from others
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To hone these skills, you can contribute to open source projects or spend time
    looking at other people’s work.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now take a look at this chapter’s project.
  prefs: []
  type: TYPE_NORMAL
- en: '12.3 Project 8: Finding customer segments from mobile activity'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this project, we will look at mobile phone activity to identify groups of
    similar customers. We will examine the problem statement, the available data,
    the project deliverables, and the tools you will need to attempt the project.
  prefs: []
  type: TYPE_NORMAL
- en: The data is available for you to attempt the project yourself at [https://davidasboth.com/book-code](https://davidasboth.com/book-code).
    You will find the files that you can use for the project, including the previous
    analyst’s work on which we will build, as well as the example solution in the
    form of a Jupyter notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 12.3.1 Problem statement
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’re working for AppEcho Insights, an analytics company focused on mobile
    user behavior. They analyze data on how users use their phones and provide insights
    to mobile phone manufacturers and app developers. Their latest initiative is customer
    segmentation. They want to understand whether there are groups of users who behave
    in a similar way. Knowing these user segments would be useful as their clients
    could target entire user bases with different initiatives. For example, they could
    market productivity tips to casual users or insights on extending battery life
    to heavy users.
  prefs: []
  type: TYPE_NORMAL
- en: A previous analyst already performed a basic segmentation of the user base and
    presented their findings to the stakeholders. Unfortunately, they left the company
    after that, and their code was lost. Your manager has asked you to work on a second
    version of the analysis, using the results of the first as a starting point.
  prefs: []
  type: TYPE_NORMAL
- en: 'The conclusion of the first version was that it is possible to segment customers
    based on the number of apps they use and the average length of their browsing
    sessions. The analyst proposed six unique customer categories and assigned them
    personas, such as “casual users” and “power users.” Your stakeholders want the
    second version of the segmentation to be more complex and include more features.
    They’d like to focus on the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The types of apps that people use. For example, do some customers use their
    phones more for social media than others?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Look at temporal patterns. Do users prefer to browse their phones at different
    times of the day?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Potentially use a more suitable segmentation method (e.g., an algorithm that
    can handle grouping users based on multiple dimensions).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They have provided you with the dataset of mobile events and the presentation
    the initial analyst delivered. The dataset consists of individual mobile events,
    such as a user opening or closing a mobile app. There are only a few columns,
    but it is possible to extract rich behavioral information. The events are timestamped,
    so the temporal element can also be analyzed. See chapters 8 and 9 for more details
    about working with time data.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  The data was originally taken from [https://github.com/aliannejadi/LSApp](https://github.com/aliannejadi/LSApp).
    Thank you to Mohammad Aliannejadi for permission to use the data.
  prefs: []
  type: TYPE_NORMAL
- en: Both the data and presentation files are in the supplementary materials. Your
    task will be to review the analyst’s work and continue the project to answer your
    stakeholders’ questions.
  prefs: []
  type: TYPE_NORMAL
- en: 12.3.2 Data dictionary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As always, a key initial step is to take a look at the available data. Table
    12.1 shows the data dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: Table 12.1 Data dictionary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Column | Definition |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| User ID  | A user’s unique identifier.  |'
  prefs: []
  type: TYPE_TB
- en: '| Session ID  | Uniquely identifies a user’s activity session.  |'
  prefs: []
  type: TYPE_TB
- en: '| Timestamp  | Date and time of an individual event.  |'
  prefs: []
  type: TYPE_TB
- en: '| App name  | The name of the app in use.  |'
  prefs: []
  type: TYPE_TB
- en: '| Event type  | The type of the event that took place. Values are one of the
    following: “Opened,” “Closed,” “User Interaction,” or “Broken.”  |'
  prefs: []
  type: TYPE_TB
- en: Now that we have seen what’s available, let’s look at the outcomes of this project.
  prefs: []
  type: TYPE_NORMAL
- en: 12.3.3 Desired outcomes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our stakeholders want a more in-depth analysis and customer segments based on
    more dimensions. Our solution should consist of a recreation of the initial analysis
    followed by our own improvements. The final output is the definition of our user
    segments, meaning what factors describe each segment and which users belong to
    which group.
  prefs: []
  type: TYPE_NORMAL
- en: 12.3.4 Required tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the example solution, I use Python and the `pandas` library for data exploration,
    `matplotlib` for visualization, and `scikit-learn` for clustering. To complete
    this project, you will need a tool that can
  prefs: []
  type: TYPE_NORMAL
- en: Load a dataset from a CSV or similar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform basic data manipulation tasks, such as sorting, grouping, and reshaping
    data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create data visualizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform segmentation (e.g., with a clustering algorithm)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can decide to perform the segmentation “by hand,” meaning decide on what
    values of your dimensions make up the groups. However, this becomes increasingly
    difficult to do manually after two to three dimensions, which is why I recommend
    choosing a tool that can apply a relevant algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now see how we might approach this problem step by step using our results-driven
    framework.
  prefs: []
  type: TYPE_NORMAL
- en: 12.4 Applying the results-driven method to creating the second iteration of
    a customer segmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s look at a results-driven approach to this problem and formulate our action
    plan.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-unnumb-1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The problem statement is clear: allocate users to distinct segments. Beyond
    this, what we also need to understand is the work the previous analyst has already
    done. Only then can we understand exactly what our task is. Recreating the analyst’s
    work is also crucial. First, we need to ensure we can replicate their results
    and verify their assumptions, but in this case, we also need to have the code
    available as the original was lost.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-unnumb-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Starting at the end, in this case, means answering the questions posed in section
    12.1\. How many groups should there be? What kind of groups make sense in light
    of what our stakeholders want to do with the output? They want to be able to target
    different user groups with different offerings, so our evaluation of the user
    groups should be made with that in mind.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-unnumb-3.png)'
  prefs: []
  type: TYPE_IMG
- en: In this instance, the data has been identified for us. However, we should also
    think about ways to enhance this data. Can we extract more information from the
    data, or are there external sources we could join on?
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-unnumb-4.png)'
  prefs: []
  type: TYPE_IMG
- en: The data has been downloaded for us in its raw form. Again, however, we could
    enhance it. We will review some ideas for enhancement in the example solution.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-unnumb-5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The segmentation process resembles any data analysis problem, for the most
    part:'
  prefs: []
  type: TYPE_NORMAL
- en: We will start by exploring the data, looking for missing and incorrect values,
    outliers, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we will investigate which features our records vary along. That is, do
    some features have more variance than others? If all customers live in the same
    geographic area, there is no need to include geography as one of the dimensions
    on which to segment them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also want to visualize our data along the different dimensions in the hope
    of discovering obvious groups. In large, complex datasets, this is unlikely, but
    we might find outlier groups, such as a few customers who spend a lot more than
    the others.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final two steps are unique to the segmentation problem. First, we will choose
    which dimensions to segment on and apply a clustering algorithm. Different algorithms
    exist for different use cases, some of which are discussed in the example solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we will evaluate the results. We will do this by analyzing the groups
    to see if they meaningfully differ from one another. One way to do this is to
    assign group labels or personas to each group. If we can give each group a unique
    description, the results will be more useful than if we have created multiple
    segments with the same characteristics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This step will be done once we have an allocation for each user, that is, know
    which of our newly created groups they belong to.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-unnumb-6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The presentation from the previous iteration was a short slide deck. We could
    consider creating a similar presentation as an output. At the very least, we should
    have all the same ingredients to hand: a list of the final groups, the number
    of users in each group, and what characteristics describe each group.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-unnumb-7.png)'
  prefs: []
  type: TYPE_IMG
- en: Since this will be the second iteration of the project, we should make recommendations
    to our stakeholders about additional steps that could be taken after our version
    is finished. Clearly, this is an important company initiative, which we can support
    by providing suggestions for further work if our stakeholders decide to allocate
    more resources.
  prefs: []
  type: TYPE_NORMAL
- en: '12.5 An example solution: Creating customer segments'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let’s walk through an example solution. As always, I strongly recommend
    attempting the project yourself first.
  prefs: []
  type: TYPE_NORMAL
- en: As for the action plan, first, we will attempt to recreate the initial analysis.
    Next, we will investigate the additional features requested by our stakeholders
    before finally grouping our customers into new segments and analyzing these groups.
  prefs: []
  type: TYPE_NORMAL
- en: 12.5.1 Recreating someone else’s analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this first part, we will review the slides presented by the previous analyst
    and attempt to replicate their findings. Slide 4 contains some summary metrics,
    which is where we should start. Figure 12.1 shows the slide in question.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 Slide 4 from the original presentation, showing summary metrics
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Our first task is to verify that we can recreate these metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying reported metrics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'First, we’ll read in the data with the following code, and a preview of the
    rows is shown in figure 12.2\. Note that the data is in the .tsv format, meaning
    values are separated by a tab character, not a comma:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Specifies the separator as the tab character'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Gives the data specific column names'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Explicitly converts the timestamp column to a date type'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Ignores the original column headers since we’re supplying our own'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 A snapshot of the raw data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The output of the code tells us that there are over three million rows of data,
    and the snapshot tells us that we have one row per app event, which is when the
    user opens or closes an app. Let’s now investigate the claims on the appendix
    slide, which say that missing data and events tagged as broken were dropped. The
    slide in question is shown in figure 12.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 The relevant part of the appendix from the slides, showing additional
    data cleaning steps
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'To investigate these additional data cleaning steps, the following code investigates
    missing data and produces the output in figure 12.4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-4.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 The result of investigating missing data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This figure shows there is one missing value in each column. Regardless of
    whether those missing values are in the same record, it’s safe to drop missing
    data as it makes up a negligible percentage of our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Figure 12.2 also shows that user ID and session ID, which should typically
    be integers, are treated as decimal values. This is because the version of the
    `pandas` library I’m using does not have a nullable integer type. It is not crucial
    to convert this column to an integer, but we will do it to be explicit and avoid
    any confusion. Figure 12.5 verifies that all the columns have the correct data
    type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-5.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.5 The corrected data types in our dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Before verifying the summary metrics on the slides, let’s investigate the “Broken”
    event type that, according to the appendix, was dropped. The following code looks
    at the distribution of event type as a percentage of the entire data, and the
    result is shown in figure 12.6:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 Percentage breakdown of each event type
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This figure tells us that only 0.1% of our data is a “Broken” event. We don’t
    have a lot of context about what this means, so we will agree with the initial
    analysis and drop these records using the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Before we go further, let’s start building up our diagram of the process we
    are following. Figure 12.7 shows what we have done so far and where the analysis
    might have diverged.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-7.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.7 The first step in recreating the initial analysis
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s now verify that, as per the “Dataset at a glance” slide in figure 12.1,
    we have 292 users, 87 unique apps, events spanning eight months, and three distinct
    event types. First, we verify the number of users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This code returns 292, as expected. Now, we verify the number of distinct apps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we get the expected value of 87\. Let’s now look at the date range in
    our data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The output tells us the data spans September 2017 to May 2018, which is approximately
    eight months, as stated on the slides. We also know there are three event types
    since there were four when we first investigated them, and we dropped one of them
    entirely. The next step is to recreate some of the underlying data behind the
    charts in the slides.
  prefs: []
  type: TYPE_NORMAL
- en: First, there is a slide showing the number of sessions per user, as shown in
    figure 12.8.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.8 A slide from the original presentation showing the distribution
    of the number of sessions per user
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Number of sessions per user seems like a useful metric to calculate as it is
    a proxy for how active a user is. To do this, we’ll create a DataFrame where,
    for each user, we count how many unique sessions they have in the data. We will
    then explore the distribution of this measure. The following code creates this
    DataFrame, and the output showing its descriptive statistics is presented in figure
    12.9:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-9.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.9 Descriptive statistics of the number of sessions per user
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This tells us that the median number of sessions per user is 95, but there
    were users with a single session all the way to a user with over 5,000\. Let’s
    see this distribution visually to better understand both the spread and where
    the data is concentrated. The following code creates the histogram shown in figure
    12.10:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-10.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.10 Distribution of number of sessions per user
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As we might have expected from the descriptive statistics, the distribution
    tells us most users have few sessions, with a long tail stretching to users with
    thousands. The initial analysis didn’t mention what the profiles of those prolific
    users look like, so let’s investigate them. Before we do that, let’s update our
    diagram to document the process so far. Figure 12.11 shows the latest version.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-11.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.11 The steps we have taken so far
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'From this point, we will go beyond the results presented in the slides and
    into our own analysis. Let’s now look at the data for the user with the highest
    number of sessions. The following code finds the users with the most sessions,
    and the output is shown in figure 12.12:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-12.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.12 The users with the most unique sessions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The following code extracts the raw data for the user with the most sessions:
    user 138\. A snapshot of their data is shown in figure 12.13:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-13.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.13 A snapshot of the activity of the user with the most sessions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: It looks like the data for this user starts with them using various apps at
    around 5:30 a.m. One noticeable aspect of this data is that it starts with an
    “Opened” event followed immediately by a “Closed” event and then another “Opened”
    event, all for the same app. Is this information relevant or redundant? In the
    example in figure 12.13, we have some exact duplicates, namely, the first and
    third rows. Let’s see how big this problem is.
  prefs: []
  type: TYPE_NORMAL
- en: Investigating duplicate event records
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following code calculates the proportion of records that are exact duplicates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The output is 0.597, meaning nearly 60% of our data is an exact duplicate of
    another row. That means a record with the same user ID, same session ID, and the
    same event type occurring for the same app at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: This result could potentially require a lot of work to investigate and clear
    up, so before we do anything, let’s consider whether duplicates are a problem
    for the specific analysis we want to conduct. We are interested in
  prefs: []
  type: TYPE_NORMAL
- en: What types of apps do people use? If we are counting things like the number
    of unique apps per user, duplicates won’t be a problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When do people use their phones? Unfortunately, having duplicate records would
    skew the results because we may accidentally inflate some parts of the day versus
    others if there happen to be more duplicates at different times of the day.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We, therefore, can’t ignore the fact there are duplicates. We need to take
    stock of our possible options instead:'
  prefs: []
  type: TYPE_NORMAL
- en: We could simply drop duplicate records. What would happen if we did this for
    the example in figure 12.13? We would end up with an “Opened” event followed by
    two “Closed” events. The “Closed” events wouldn’t be duplicates as they occurred
    at different times. Dropping exact duplicates is too basic and would cause additional
    problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another option is to drop pairs of “Opened” and “Closed” events that occurred
    at the same time. However, this assumes that an “Opened” event always has a corresponding
    “Closed” event, which may not hold in practice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We could also think about the problem differently. As it stands, we are not
    interested in the single-event level but in summarizing behavior at the user level.
    This means that we could say that “Closed” events are less informative. If a user
    opens five apps in a browsing session, we would know that even without the presence
    of “Closed” events.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The idea that “Closed” events are informationally redundant is quite appealing,
    so let’s go with that approach. The following code drops events that are “Closed”
    and calculates the percentage of records we dropped, as well as the percentage
    of exact duplicates in the remaining data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The outputs of these three commands are 1,987,090, 0.54, and 0.599\. This means
    we have just under 2 million records remaining out of an initial 3.7 million,
    which is about half our original data. It also tells us that we still have nearly
    60% exact duplicates. Now, an exact duplicate is entirely redundant for our purposes,
    so we can drop those, too. The following code does this and calculates how much
    data we have left:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We are left with just under 800,000 records. It is unusual to drop so much data
    as part of an analysis, but in this case, it was justified. Figure 12.14 shows
    the process so far, including the choices we have just made.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-14.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.14 The process so far, including choices about handling duplicate
    data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Having cleaned up a lot of duplication, let’s reexamine our data. The following
    code examines the first few rows, which are shown in figure 12.15:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-15.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.15 Example events after duplicate records were removed
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This latest figure shows a new challenge. There are sequential instances of
    a user opening Minesweeper, sometimes only a few seconds apart. What could this
    mean?
  prefs: []
  type: TYPE_NORMAL
- en: Was the user constantly changing their mind about whether they wanted to play?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Was the user trying to open the app, but it kept crashing?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are these artifacts of how the data was collected/collated?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We would need more information to know for sure.
  prefs: []
  type: TYPE_NORMAL
- en: Handling related pairs of event records
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As it stands, we must make a choice about what, if anything, to do about this
    kind of repetition:'
  prefs: []
  type: TYPE_NORMAL
- en: We could assume that multiple repeated events related to an app are actually
    a single instance of the user using that app. In the case of someone opening Minesweeper
    10 times in the data followed by opening another app, we could treat that as 2
    events instead of 11\.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We could look at the time difference between interactions of the same app and
    remove interactions that are too short. This requires us to strictly define “too
    short,” which is a strong built-in assumption.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We could also ignore this problem entirely. Again, we are interested in user-level
    and session-level metrics, not individual event-level ones. If we define the length
    of a user session by the difference between when it started and ended, it doesn’t
    matter what happened in between as the user was interacting with their phone one
    way or another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thinking about this in a results-driven way, we can answer our stakeholders’
    questions about app types and user browsing times without explicitly handling
    these instances of users opening and closing apps in quick succession. Since we’re
    making another choice, we’ll add that to our diagram, the latest version of which
    is shown in figure 12.16.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-16.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.16 Our latest progress after investigating various types of duplicate
    event
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now that we’ve handled the duplication issue, we can recreate the chart from
    the slides relating to the average session length of each user. This is shown
    in figure 12.17.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-17.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.17 A slide from the original presentation showing the distribution
    of users’ average session length
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'To recreate this, we need to create a DataFrame of individual sessions and
    their length. First, we need to establish whether a session ID is unique to a
    user. If session 1 can only ever relate to user 0, we can simply group by the
    session ID; otherwise, we must include the user ID to distinguish between two
    different users’ sessions, both with an ID of 1\. The following code looks for
    session IDs that belong to more than one user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this code is an empty `pandas` `Series`, meaning there are no
    session IDs across multiple users. Therefore, the session ID is unique to a user.
    Now, we can create the DataFrame of sessions that we need. The following code
    does this and produces the DataFrame, which is previewed in figure 12.18:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-18.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.18 A snapshot of user sessions and their duration in minutes
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This DataFrame contains one row per user session, so grouping by user ID and
    averaging the session duration gives us the data we need to produce the chart
    from the slides. The following code does this and produces the chart in figure
    12.19:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-19.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.19 The distribution of users’ average session lengths
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This result tells us that most users’ sessions last less than 2 minutes but
    with a long tail. There are sessions that are even over 10 minutes in duration.
    You might notice that this chart doesn’t exactly match the one in the slides,
    as shown by the difference between figures 12.17 and 12.19\. That is because we
    have chosen to drop “Closed” events and have therefore already diverged from the
    initial analysis. That’s fine because we are making different assumptions and
    thus coming to different conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: Our particular approach might skew results slightly if there are sessions that
    end in a “Closed” event because we’d underestimate how long those sessions are.
    However, since our primary goal is to look at what kinds of apps people use in
    a session and what time those sessions occur, the initial “Opened” event is sufficient.
  prefs: []
  type: TYPE_NORMAL
- en: We have recreated the relevant parts of the original analysis, but before moving
    on to our stakeholders’ questions, let’s recap the process. The latest diagram
    is shown in figure 12.20.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-20.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.20 The process of reproducing the original analysis
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s move on to the next part of the analysis, answering our stakeholders’
    new questions about the users.
  prefs: []
  type: TYPE_NORMAL
- en: 12.5.2 Analyzing event data to learn about customer behavior
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we have verified the findings of the original analysis, we can move
    on to our stakeholders’ new questions. The first one was about what time people
    use their phones and whether this would be a useful dimension for clustering.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing timestamps to learn about browsing behavior
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To investigate when people use their phones, we need a definition of what counts
    as “usage time.” That is, do we care about the times that every single data point
    occurred? Probably not because a group of “Opened” and “Closed” events close together
    in time should count as one example of a user using their phone around that time.
  prefs: []
  type: TYPE_NORMAL
- en: 'That means we could use the start time from the session-level DataFrame created
    earlier. The following code creates a column to extract the hour component of
    the dates so we can isolate just the hour in which browsing began. Then, we plot
    the distribution of these “start hours,” the result of which is shown in figure
    12.21:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-21.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.21 The distribution of when users start their browsing sessions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This chart tells us that most browsing sessions start in the late afternoon/early
    evening, with a dip in the early hours of the day. What it doesn’t tell us is
    whether there are users who behave differently to this general trend. For that,
    we need to calculate what the most common starting hour, or part of the day, is
    for each user.
  prefs: []
  type: TYPE_NORMAL
- en: Note  In this section, we will explore the temporal aspect of this data. If
    you’re interested in more examples of working with time series data, see chapters
    8 and 9.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now calculate the most common starting hour for each user. We can use
    the statistical mode for this, which simply returns the most common value. However,
    we need to decide what happens if there is a tie. What if someone’s most common
    browsing time is both 8 a.m. and 5 p.m.? There is no reason to prefer one or the
    other, so we will leave both values in. Therefore, that user will be represented
    twice, which may skew the results by overrepresenting some users, but it will
    also retain valuable information.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code defines a function to return possibly multiple values of
    the mode for each user and then applies it to the DataFrame. A snapshot of the
    resulting DataFrame is shown in figure 12.22:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Calculates the mode, possibly returning multiple values'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Applies this function and extracts all the most common starting hours'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Cleans up unnecessary columns created by grouping and aggregating'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-22.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.22 A snapshot of the most common starting hour for users’ browsing
    sessions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'As shown in figure 12.22, there are instances of a user having multiple most
    frequent start times, such as user 0, who browses equally frequently around 4
    p.m. and 10 p.m. From this data, we can now look at the distribution of the newly
    created `most_ frequent_hour` column to understand whether there are users who
    prefer different times in the day for using their phones. The following code investigates
    this and produces the chart in figure 12.23:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-23.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.23 Distribution of users’ most common browsing times
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: What this chart tells us is that there are distinct groups of users who prefer
    to browse in the morning around 6 a.m., at lunchtime around 1 p.m., or at 5 p.m.
    in the evening, with another peak starting at midnight.
  prefs: []
  type: TYPE_NORMAL
- en: Before we move on to decide how to use this information in our user segments,
    let’s add this to our growing diagram of our analysis, which is shown in figure
    12.24.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-24.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.24 The process diagram, including the start of part 2 of the analysis
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We could use the data shown in figure 12.22 as a dimension in our segments,
    that is, the actual most common start hour for a user. However, there would be
    two problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Some users would have multiple rows, which will not work for a segmentation
    problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some hours of the day are very similar, that is, it doesn’t matter if a user
    started their browsing at 4 p.m. or 5 p.m.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want to find distinct user groups so we can group these similar times together
    instead. We could have done this up front, that is, grouped different parts of
    the day together into “morning,” “midday,” and so on, and investigated the distribution
    of those categories. However, we would have made assumptions about which hours
    are similar in terms of mobile usage. By looking at the distribution of individual
    hours first, we can create groups that closely match what we find in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Creating customer labels based on browsing patterns
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Looking at the chart in figure 12.23, we could conclude there are anywhere between
    two and five “peaks,” which could act as different parts of the day. The choice
    of how many categories to use will be somewhat subjective. Let’s go with four
    categories, as this might fit the data best without creating too many user segments
    down the line. Our groups will be
  prefs: []
  type: TYPE_NORMAL
- en: Night owls, who tend to browse between 9 p.m. and 3 a.m. (inclusive)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Early morning users, who tend to browse between 4 a.m. and 9 a.m. (inclusive)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Midday users, who tend to browse between 10 a.m. and 2 p.m. (inclusive)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Late-day users, who tend to browse between 3 p.m. and 8 p.m. (inclusive)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s create these groups and investigate how many users are in each group.
    The following code does the categorization and produces the output in figure 12.25:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Fixes additional night owl values'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-25.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.25 Users’ most common browsing hours grouped into four categories
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now, we can investigate the membership in these groups. The following code calculates
    the distribution and produces the output shown in figure 12.26.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-26.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.26 Distribution of the categories of users’ browsing sessions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s now use this dataset to create a one-hot encoded representation of these
    categories, that is, one binary column to indicate membership in each category.
    Crucially, a user can be in multiple categories, as shown in figure 12.25\. See
    chapter 6 for more examples of this in practice. The following code creates the
    one-hot encoding and produces the start of a user-level dataset, which we will
    use for segmentation. A snapshot of this new dataset is shown in figure 12.27:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '#1 get_dummies created the one-hot encoded columns.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-27.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.27 A snapshot of user-level data showing which browsing time categories
    users belong to
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We have now created a dataset that we can add additional columns to and run
    the segmentation algorithm on. Before we move on to the next stakeholder question,
    which is about what types of apps people use, let’s update our diagram of the
    work done so far. The latest version is shown in figure 12.28.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-28.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.28 The process so far, including grouping people into categories based
    on when they browse
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We can now move on to our next stakeholder question about what types of apps
    people use.
  prefs: []
  type: TYPE_NORMAL
- en: Using AI to label data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Our stakeholders want us to investigate what types of apps people use and potentially
    use that information in the segmentation. However, we do not have data on app
    type directly, just a list of app names. This is a clear example of more information
    being contained in the raw data than we might think at first. A domain expert
    could easily categorize each app name into some broader category. This is a perfect
    use case for AI to augment our work.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are over 80 distinct app names to categorize. It’s doable but repetitive
    to do by hand, so let’s ask an AI to do it. We can use the following code snippet
    to get the app names as a list to pass to the AI tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The following prompt, asking ChatGPT to categorize the app names for us, generates
    the output shown in figure 12.29.
  prefs: []
  type: TYPE_NORMAL
- en: 'I will provide a list of mobile application names. To the best of your ability,
    group them into logical categories, e.g., email, social media, web browser, mobile
    games, etc. I’d like the response as a table with columns *''app_name''* and *''category''*.
    If you are unsure what category an app belongs to, put “Unknown.” Here is the
    list of app names: <app names follow>.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![figure](../Images/12-29.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.29 Part of ChatGPT’s response to categorize app names into broader
    categories
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Note  It is important to note that these tools don’t always produce the same
    output for the same prompt. They are also evolving all the time, so you will almost
    certainly get a different output than I do for the same prompt. This is a feature
    of the analytics process, not a bug.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we are satisfied with the output, we can specifically request the data
    as a CSV file and merge it into our own data. The following code achieves this,
    and a snapshot is shown in figure 12.30:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-30.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.30 A snapshot of the categorization data produced by ChatGPT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s add this latest step to our process diagram, the latest version of which
    is shown in figure 12.31.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-31.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.31 The latest diagram of our steps, including ChatGPT’s categorization
    of apps
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s now see the distribution of this category data. The following code calculates
    this and produces the output in figure 12.32:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-32.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.32 Distribution of newly created app categories
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'There are a couple of things to notice here. One is that there are a few “Unknown”
    values, which we should investigate and manually categorize. The second is that
    there are quite a lot of categories, probably too many to be useful. First, let’s
    resolve the “Unknown” values. The following code investigates these values, and
    they are shown in figure 12.33:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-33.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.33 App names that ChatGPT could not categorize
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We can manually categorize these with a bit of research and some code snippets.
    The following code updates the category of these specific app names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s handle the second problem, which is that ChatGPT created too many
    categories. We can choose to ask ChatGPT to revise its categorization and ask
    for fewer columns, or we could use ChatGPT’s categories as subcategories and define
    main categories ourselves. It’s a personal choice, but it shouldn’t take too long
    to do this ourselves, and that way, we have the categorization code ready if we
    decide to change the categories later.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing AI-created data labels
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One `pandas` trick is to use the `map` method to map categories to new ones
    based on a dictionary. We don’t want to type this dictionary out ourselves, but
    we can write a bit of code to print the categories in the required format, which
    we copy and paste into our main mapping code. The following code prints the existing
    categories in the right format, leaving space for the new category alongside.
    The output is shown in figure 12.34, so you can see how it would be pasted to
    create the code snippet that follows later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-34.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.34 Our categories in a format required by a Python dictionary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Now, we can use this output to create the following code, which updates each
    existing category with its new categorization. We will keep the existing category
    column as a subcategory, so we have two levels of app category hierarchy. Figure
    12.35 shows a snapshot of the categories dataset after these updates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-35.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.35 A snapshot of the categories data after applying our new categorization
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Before we merge this back into the main app data, let’s review our process by
    updating our diagram. The latest version is shown in figure 12.36.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-36.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.36 The latest process, including a review of ChatGPT’s categorization
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now, it’s time to merge these categories back to our original data and see how
    people use these various app types. The following code joins the event-level app
    data to the app categories, creating merged data, a snapshot of which is shown
    in figure 12.37.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Raises an error message if we don’t have the same number of rows after the
    merge'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-37.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.37 A snapshot of the app data merged with app categories
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: From this data, we want to find each user’s most common app category. After
    that, we will investigate whether there are ties, that is, users who have more
    than one category as their most common.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing newly created category labels
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following code calculates the top categories per user, and a snapshot of
    the output is shown in figure 12.38\. Note that `pandas` creates a column called
    `level_1` because the mode function could return multiple values, as it did when
    we looked at app usage times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-38.png)![figure](../Images/12-38.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.38 A snapshot of the “most common category per user” dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'From this data, we can investigate whether there are users with multiple categories
    as their most common. We can use this `level_1` column that `pandas` created to
    filter our data. Anything with a value of zero means the user’s top category,
    so values greater than zero mean a user has multiple top categories. The following
    code investigates this and produces the output in figure 12.39:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-39.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.39 Users with more than one top app category
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s examine these users in more detail and see if we can decide how to proceed.
    The following code retrieves all records for these users and produces the output
    in figure 12.40:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-40.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.40 All category data for users with more than one top category
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We can either remove one of those categories per user or record our data the
    same way we did with app times, that is, users would be allowed more than one
    top category. As there are only three affected users in this case, we will investigate
    whether we could drop one of their top categories. How do we decide which of the
    two categories to drop? Let’s first look at the underlying data for the user with
    ID 35\. The following code retrieves the data for that user at an individual app
    level, which is then shown in figure 12.41:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-41.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.41 User 35’s app usage by category and app name
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This user used the Settings app quite heavily, which contributed to the “Utility”
    category being joint top for them. We don’t have more detailed information about
    why this user kept opening their phone settings. We can use what we have to decide
    if it’s more relevant that the user uses the “Social” apps most frequently. We
    will drop the necessary record for this user to have “Social” as their only top
    category. User 132 also had “Utility” as their joint top category, so for the
    same reason, we’ll drop that record as well. The following code cleans up the
    data for these two users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let’s look at user 223 and decide whether they better fit a “Social”
    or “Browsing” category. The following code looks at their data at an app level
    and produces the output shown in figure 12.42:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-42.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.42 App-level usage data for user 223
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This one is trickier to categorize because they make heavy use of social apps
    but also frequently use the Google app. However, that could mean multiple things,
    some of which might not fit under “Browsing,” so we’ll decide that this user better
    fits the “Social” label. The following code removes the necessary record. We then
    retest the data to verify there are no users with multiple “top app category”
    records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of that latest snippet is an empty list, meaning we no longer have
    users with multiple top app categories. We can now create the indicator variables
    required for our clustering algorithm. The following code creates these indicator
    variables and produces the output in figure 12.43:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-43.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.43 The one-hot encoded version of our “top app category by user” data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The data in this format is ready to be joined to the user-level data that we
    created in figure 12.27\. Before merging the two datasets, let’s review our progress
    so far. The latest diagram of our analysis is shown in figure 12.44.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-44.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.44 The latest progress in our analysis
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We have investigated the data relating to our stakeholder questions. Now, we
    will merge the most frequent app category data and the most frequent browsing
    time data to build up our user-level dataset. We will also create and include
    columns from the initial analysis and have a user-level dataset ready for segmentation.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a user-level dataset for segmentation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'So far, we have one user-level dataset of what times people tend to use their
    phones the most and another that contains the most frequent app category per user.
    We’ll join these together and then add other metrics. The following code merges
    the two datasets, and a snapshot of the merged data is shown in figure 12.45:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-45.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.45 A snapshot of the user-level data so far
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The initial analysis involved the number of unique apps used per user and the
    average length of their browsing sessions to segment the users. There is no reason
    not to keep these metrics in there, so let’s recreate them and join them to our
    current dataset. We will also add “number of sessions” as a proxy for how heavily
    a user uses their phone since, otherwise, that aspect of usage is not captured
    in any of our variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we can add columns relating to the number of apps and sessions straight
    from the raw app data. The following code counts the number of unique apps and
    sessions per user and produces a dataset, a snapshot of which is shown in figure
    12.46:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-46.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.46 A user-level dataset counting the number of unique apps and sessions
    per user
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s now join this table to the dataset we created in figure 12.45\. The following
    code achieves this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'To add the average session length, we need to turn to the session-level data
    we created earlier in section 12.5.1\. We will group it by user ID and calculate
    the median duration of each session per user. The following code does this and
    produces a dataset, a snapshot of which is shown in figure 12.47:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-47.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.47 Average session duration per user
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Our final step before segmentation is to merge this table into the main user-level
    data. The following code does this, and figure 12.48 shows all the columns in
    the data we will use for segmentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/12-48.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.48 All the columns we will use to segment users
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s export this user-level data directly to the next chapter’s folder so
    we can start the segmentation process directly from this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Before moving on to the segmentation part in the next chapter, let’s review
    everything we’ve done so far.
  prefs: []
  type: TYPE_NORMAL
- en: 12.5.3 Project progress so far
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s recap the progress on this project:'
  prefs: []
  type: TYPE_NORMAL
- en: We started by investigating the work behind the initial presentation and verified
    the summary statistics that were presented.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We continued the analysis by diving deeper into user behavior and concluded
    that there are distinct groups of people who use their phones at different times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We used generative AI to categorize app names into broader app categories.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We used these app categories to identify different user behaviors based on what
    apps a user uses the most.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we exported a user-level dataset ready for segmentation in the next
    phase.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 12.49 shows the entire process up to this point.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/12-49.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.49 Parts 1 and 2 of the analysis before segmentation starts
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In the following chapter, we will use the exported user-level data to segment
    users into distinct groups to answer our stakeholders’ questions.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Continuing someone else’s work starts with retracing their steps.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recreating the initial analysis helps us understand the problem and find any
    errors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When continuing someone else’s work, their assumptions and decisions should
    be checked and verified.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
