["```py\nfrom typing import NamedTuple\n\nclass User(NamedTuple):\n    id: int\n    name: str\n\nusers = [User(0, \"Hero\"), User(1, \"Dunn\"), User(2, \"Sue\"), User(3, \"Chi\"),\n         User(4, \"Thor\"), User(5, \"Clive\"), User(6, \"Hicks\"),\n         User(7, \"Devin\"), User(8, \"Kate\"), User(9, \"Klein\")]\n```", "```py\nfriend_pairs = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n                (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]\n```", "```py\nfrom typing import Dict, List\n\n# type alias for keeping track of Friendships\nFriendships = Dict[int, List[int]]\n\nfriendships: Friendships = {user.id: [] for user in users}\n\nfor i, j in friend_pairs:\n    friendships[i].append(j)\n    friendships[j].append(i)\n\nassert friendships[4] == [3, 5]\nassert friendships[8] == [6, 7, 9]\n```", "```py\nfrom collections import deque\n\nPath = List[int]\n\ndef shortest_paths_from(from_user_id: int,\n                        friendships: Friendships) -> Dict[int, List[Path]]:\n    # A dictionary from user_id to *all* shortest paths to that user.\n    shortest_paths_to: Dict[int, List[Path]] = {from_user_id: [[]]}\n\n    # A queue of (previous user, next user) that we need to check.\n    # Starts out with all pairs (from_user, friend_of_from_user).\n    frontier = deque((from_user_id, friend_id)\n                     for friend_id in friendships[from_user_id])\n\n    # Keep going until we empty the queue.\n    while frontier:\n        # Remove the pair that's next in the queue.\n        prev_user_id, user_id = frontier.popleft()\n\n        # Because of the way we're adding to the queue,\n        # necessarily we already know some shortest paths to prev_user.\n        paths_to_prev_user = shortest_paths_to[prev_user_id]\n        new_paths_to_user = [path + [user_id] for path in paths_to_prev_user]\n\n        # It's possible we already know a shortest path to user_id.\n        old_paths_to_user = shortest_paths_to.get(user_id, [])\n\n        # What's the shortest path to here that we've seen so far?\n        if old_paths_to_user:\n            min_path_length = len(old_paths_to_user[0])\n        else:\n            min_path_length = float('inf')\n\n        # Only keep paths that aren't too long and are actually new.\n        new_paths_to_user = [path\n                             for path in new_paths_to_user\n                             if len(path) <= min_path_length\n                             and path not in old_paths_to_user]\n\n        shortest_paths_to[user_id] = old_paths_to_user + new_paths_to_user\n\n        # Add never-seen neighbors to the frontier.\n        frontier.extend((user_id, friend_id)\n                        for friend_id in friendships[user_id]\n                        if friend_id not in shortest_paths_to)\n\n    return shortest_paths_to\n```", "```py\n# For each from_user, for each to_user, a list of shortest paths.\nshortest_paths = {user.id: shortest_paths_from(user.id, friendships)\n                  for user in users}\n```", "```py\nbetweenness_centrality = {user.id: 0.0 for user in users}\n\nfor source in users:\n    for target_id, paths in shortest_paths[source.id].items():\n        if source.id < target_id:      # don't double count\n            num_paths = len(paths)     # how many shortest paths?\n            contrib = 1 / num_paths    # contribution to centrality\n            for path in paths:\n                for between_id in path:\n                    if between_id not in [source.id, target_id]:\n                        betweenness_centrality[between_id] += contrib\n```", "```py\ndef farness(user_id: int) -> float:\n    \"\"\"the sum of the lengths of the shortest paths to each other user\"\"\"\n    return sum(len(paths[0])\n               for paths in shortest_paths[user_id].values())\n```", "```py\ncloseness_centrality = {user.id: 1 / farness(user.id) for user in users}\n```", "```py\nfrom scratch.linear_algebra import Matrix, make_matrix, shape\n\ndef matrix_times_matrix(m1: Matrix, m2: Matrix) -> Matrix:\n    nr1, nc1 = shape(m1)\n    nr2, nc2 = shape(m2)\n    assert nc1 == nr2, \"must have (# of columns in m1) == (# of rows in m2)\"\n\n    def entry_fn(i: int, j: int) -> float:\n        \"\"\"dot product of i-th row of m1 with j-th column of m2\"\"\"\n        return sum(m1[i][k] * m2[k][j] for k in range(nc1))\n\n    return make_matrix(nr1, nc2, entry_fn)\n```", "```py\nfrom scratch.linear_algebra import Vector, dot\n\ndef matrix_times_vector(m: Matrix, v: Vector) -> Vector:\n    nr, nc = shape(m)\n    n = len(v)\n    assert nc == n, \"must have (# of cols in m) == (# of elements in v)\"\n\n    return [dot(row, v) for row in m]  # output has length nr\n```", "```py\nfrom typing import Tuple\nimport random\nfrom scratch.linear_algebra import magnitude, distance\n\ndef find_eigenvector(m: Matrix,\n                     tolerance: float = 0.00001) -> Tuple[Vector, float]:\n    guess = [random.random() for _ in m]\n\n    while True:\n        result = matrix_times_vector(m, guess)    # transform guess\n        norm = magnitude(result)                  # compute norm\n        next_guess = [x / norm for x in result]   # rescale\n\n        if distance(guess, next_guess) < tolerance:\n            # convergence so return (eigenvector, eigenvalue)\n            return next_guess, norm\n\n        guess = next_guess\n```", "```py\nrotate = [[ 0, 1],\n          [-1, 0]]\n```", "```py\nflip = [[0, 1],\n        [1, 0]]\n```", "```py\ndef entry_fn(i: int, j: int):\n    return 1 if (i, j) in friend_pairs or (j, i) in friend_pairs else 0\n\nn = len(users)\nadjacency_matrix = make_matrix(n, n, entry_fn)\n```", "```py\neigenvector_centralities, _ = find_eigenvector(adjacency_matrix)\n```", "```py\nmatrix_times_vector(adjacency_matrix, eigenvector_centralities)\n```", "```py\ndot(adjacency_matrix[i], eigenvector_centralities)\n```", "```py\nendorsements = [(0, 1), (1, 0), (0, 2), (2, 0), (1, 2),\n                (2, 1), (1, 3), (2, 3), (3, 4), (5, 4),\n                (5, 6), (7, 5), (6, 8), (8, 7), (8, 9)]\n```", "```py\nfrom collections import Counter\n\nendorsement_counts = Counter(target for source, target in endorsements)\n```", "```py\nimport tqdm\n\ndef page_rank(users: List[User],\n              endorsements: List[Tuple[int, int]],\n              damping: float = 0.85,\n              num_iters: int = 100) -> Dict[int, float]:\n    # Compute how many people each person endorses\n    outgoing_counts = Counter(target for source, target in endorsements)\n\n    # Initially distribute PageRank evenly\n    num_users = len(users)\n    pr = {user.id : 1 / num_users for user in users}\n\n    # Small fraction of PageRank that each node gets each iteration\n    base_pr = (1 - damping) / num_users\n\n    for iter in tqdm.trange(num_iters):\n        next_pr = {user.id : base_pr for user in users}  # start with base_pr\n\n        for source, target in endorsements:\n            # Add damped fraction of source pr to target\n            next_pr[target] += damping * pr[source] / outgoing_counts[source]\n\n        pr = next_pr\n\n    return pr\n```", "```py\npr = page_rank(users, endorsements)\n\n# Thor (user_id 4) has higher page rank than anyone else\nassert pr[4] > max(page_rank\n                   for user_id, page_rank in pr.items()\n                   if user_id != 4)\n```"]