- en: Chapter 7\. Measuring Uncertainty with the Bootstrap
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章。用自助法测量不确定性
- en: With ideal data, you are now able to draw robust conclusions from behavioral
    data and measure the causal impact of a business/environment change on human behaviors.
    But how can you proceed if you have suboptimal data? In academic research, one
    can always fall back to the null hypothesis when faced with inconclusive data
    and refuse to pass judgment. But in applied research there is no null hypothesis,
    only alternative courses of action to choose from.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 有了理想的数据，您现在能够从行为数据中得出坚固的结论，并衡量业务/环境变化对人类行为的因果影响。但如果您有次优数据，该如何继续呢？在学术研究中，面对不确定的数据，人们总是可以回到零假设，并拒绝做出判断。但在应用研究中，没有零假设，只有可以选择的替代行动方案。
- en: Small sample sizes, weirdly shaped variables, or situations that require advanced
    analytical tools (e.g., hierarchical modeling, which we’ll see later in the book)
    can all result in shaky conclusions. Certainly, a linear regression algorithm
    will spit out a coefficient under all but the most extreme cases, but should you
    trust it? Can you confidently advise your boss to stake millions of dollars on
    it?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 小样本量、形状奇特的变量或需要高级分析工具的情况（例如我们将在本书后面看到的层次建模）都可能导致不稳定的结论。当然，线性回归算法几乎在所有但极端情况下都会输出系数，但您应该信任它吗？您能否自信地建议您的老板将数百万美元押在它上面？
- en: 'In this chapter, I’ll introduce you to an extremely powerful and general simulation
    tool, the Bootstrap, which will allow us to draw robust conclusions from any data,
    however small or weird. It works by creating and analyzing slightly different
    versions of your data based on random numbers. A great feature of the Bootstrap
    is that you literally can never go wrong by applying it: in situations that are
    best-case scenarios for traditional statistical methods (e.g., running a basic
    linear regression on a large and well-behaved data set), the Bootstrap is slower
    and less accurate, but it is still in the ballpark. But as soon as you move away
    from such best-case scenarios, the Bootstrap quickly outperforms traditional statistical
    methods, often by a wide margin.^([1](ch07.xhtml#ch01fn10)) Therefore, we’ll rely
    on it extensively throughout the rest of the book. In particular, we’ll use it
    when designing and analyzing experiments in [Part IV](part04.xhtml#designing_and_analyzing_experiments),
    to build simulated equivalents of p-values that are more intuitive than the traditional,
    statistical, ones.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将向您介绍一种非常强大且通用的模拟工具——**自助法（Bootstrap）**，它将使我们能够从任何数据中得出坚固的结论，无论数据多么少或奇特。它的工作原理是基于随机数创建和分析您数据的稍微不同的版本。自助法的一个伟大特性是，通过应用它，您绝对不会出错：在传统统计方法最理想的情况下（例如对大型和表现良好的数据集运行基本线性回归），自助法可能速度较慢且不够准确，但仍然在接近范围内。但一旦您远离这种最理想的情况，自助法往往会迅速超越传统统计方法，常常优势明显。^([1](ch07.xhtml#ch01fn10))
    因此，在本书的其余部分中，我们将广泛依赖它。特别是在设计和分析[第四部分](part04.xhtml#designing_and_analyzing_experiments)中的实验时，我们将使用它来构建比传统统计方法更直观的模拟p值等效物。
- en: In the first section, we’ll focus on exploratory/descriptive data analysis,
    and we’ll see that the Bootstrap can already be of use at that stage. In the second
    section, we’ll use the Bootstrap in the context of regression. We’ll then broaden
    our perspective to discuss when to use the Bootstrap and what tools you can use
    to make your life easier with it.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一节中，我们将集中进行探索性/描述性数据分析，并且我们将看到自助法在这个阶段已经可以派上用场。在第二节中，我们将在回归的背景下使用自助法。然后，我们将扩展我们的视角，讨论何时使用自助法以及您可以使用哪些工具来简化生活。
- en: 'Intro to the Bootstrap: “Polling” Oneself Up'
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自助法简介：“自我拉抬”
- en: 'While our ultimate goal is to use the Bootstrap for regression, we can start
    with the simpler example of descriptive statistics: getting the mean of a sample
    data set.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们的最终目标是将自助法用于回归分析，但我们可以从更简单的描述统计的例子开始：获取样本数据集的均值。
- en: Packages
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 包
- en: 'In this chapter, we’ll use the following packages in addition to the common
    ones:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，除了常见的包外，我们还将使用以下包：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The Business Problem: Small Data with an Outlier'
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 商业问题：带有异常值的小数据
- en: C-Mart’s management is interested in understanding how long it takes its bakers
    to prepare made-to-order cakes, for the purpose of possibly revising its pricing
    structure. To that end, they have asked C-Mart’s industrial engineer to do a time
    study. As its name indicates, a time study (a.k.a. time-and-motion study) is the
    direct observation of a production process to measure the duration of the tasks
    involved. Given that the process is time-consuming (pun intended), the engineer
    has selected ten different stores that are somewhat representative of C-Mart’s
    business. In each store they observed one baker preparing one cake. They also
    recorded each baker’s work experience, measured in months on the job.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: C-Mart 的管理层有兴趣了解其烘焙师准备定制蛋糕的时间，以便可能修订其定价结构。为此，他们要求 C-Mart 的工业工程师进行时间研究。正如其名称所示，时间研究（又称时间与动作研究）是直接观察生产过程以测量涉及任务的持续时间。考虑到这个过程耗时（故意的双关语），工程师选择了十家不同的店铺，这些店铺在某种程度上代表了
    C-Mart 的业务。在每家店铺，他们观察一位烘焙师准备一块蛋糕。他们还记录了每位烘焙师的工作经验，以月计算。
- en: All together the engineer has 10 observations, which is not a very large sample
    size to begin with. Even if all of the data conformed very consistently to a clear
    relationship, the sample size alone would suggest using the Bootstrap. However,
    when exploring their data, the engineer observed the presence of an outlier ([Figure 7-1](#experience_and_preparation_time_by_bake)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，工程师有 10 个观察结果，并不是一个非常大的样本量。即使所有数据都非常一致地符合明确的关系，仅样本量就建议使用 Bootstrap。然而，在探索他们的数据时，工程师观察到存在一个异常值（[图
    7-1](#experience_and_preparation_time_by_bake)）。
- en: We have one extreme point in the upper left corner, corresponding to a new employee
    who spent most of a day on a complex cake for a corporate retreat. How should
    the engineer report the data from their study? They might be tempted to treat
    the largest observation as an outlier, which is the polite way of saying “discard
    it and pretend it didn’t happen.” But that observation, while unusual, is not
    an aberration per se. There was no measurement error, and those circumstances
    probably occur from time to time. An alternative would be to only report the overall
    mean duration, 56 minutes, but that would also be misleading because it would
    not convey the variability and uncertainty in the data. The traditional recommendation
    in that situation would be to use a confidence interval around the mean. Let’s
    calculate the normal 95% confidence interval through a regression. (Using a regression
    is overkill in this case—there are much simpler ways to calculate a mean—but it
    will serve as a gentle introduction to the process we’ll use later in the chapter.)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在左上角有一个极端点，对应于一位新员工为企业撤退复杂蛋糕花了大部分时间的情况。工程师该如何报告他们研究的数据呢？他们可能会倾向于将最大的观测值视为异常值，这是委婉地说“丢弃它并假装它没有发生”的方式。但是，虽然这个观测结果不寻常，但并不是本质上的偏差。没有测量误差，并且这种情况可能偶尔发生。另一个选择是仅报告整体平均持续时间，为
    56 分钟，但这样也会误导，因为它无法传达数据的变异性和不确定性。在这种情况下的传统建议是使用均值周围的置信区间。让我们通过回归来计算正常的 95% 置信区间。（在这种情况下使用回归是杀鸡用牛刀——有更简单的方法来计算平均值——但它将作为本章后续过程的温和介绍。）
- en: '![Experience and preparation time by baker](Images/BEDA_0701.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![烘焙师的经验和准备时间](Images/BEDA_0701.png)'
- en: Figure 7-1\. Experience and preparation time by baker
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-1\. 烘焙师经验与准备时间
- en: 'We first run the regression `times~1`, i.e., with only the intercept. We then
    extract the resulting estimate for the intercept coefficient that, in case you’re
    not familiar with that calculation, is equal to the mean of our dependent variable.
    We also extract the standard error for that coefficient. As you’ll learn in any
    stats class, the lower limit of a normal 95%-CI is equal to the mean minus 1.96
    times the standard error, and the upper limit is equal to the mean plus 1.96 times
    the standard error:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先运行回归 `times~1`，即仅带截距。然后我们提取该系数的估计结果，如果你对这个计算不熟悉，它等于我们因变量的平均值。我们还提取该系数的标准误差。正如你在任何统计课上学到的那样，正常
    95% 置信区间的下限等于平均值减去 1.96 倍标准误差，上限等于平均值加上 1.96 倍标准误差：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Unfortunately, the 95%-CI in this case is [−23; 135], which is obviously nonsensical
    because duration times can’t be negative. This happened because traditional CIs
    assume that the variable at hand follows a normal distribution around its mean,
    which in this case is incorrect. We can imagine that the engineer’s audience would
    not take too kindly to negative durations, but that is one of the problems that
    the Bootstrap can solve.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，本例中的95%置信区间是[−23; 135]，这显然是荒谬的，因为持续时间不能是负数。这是因为传统的置信区间假设手头的变量围绕其均值呈正态分布，而在这种情况下是不正确的。我们可以想象，工程师的观众对负持续时间可能并不感兴趣，但这是Bootstrap可以解决的问题之一。
- en: Bootstrap Confidence Interval for the Sample Mean
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 样本均值的Bootstrap置信区间
- en: The Bootstrap allows us to make full use of the data that we do have available
    and to draw reasonable conclusions regardless of sample size or data shape challenges.
    It does so by creating multiple imaginary data sets based on the data that we
    have available. Comparing these data sets with each other allows us to cut through
    noise and more accurately represent the importance of outlier values. It can also
    provide tighter confidence intervals, since it removes some of the uncertainty
    created by noise.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Bootstrap允许我们充分利用我们可用的数据，并在样本大小或数据形状挑战的情况下得出合理的结论。它通过基于我们可用的数据创建多个虚构数据集来实现这一目的。比较这些数据集可以帮助我们去除噪音，并更准确地表示离群值的重要性。它还可以提供更紧密的置信区间，因为它消除了噪音造成的一些不确定性。
- en: This is different from just choosing a narrower range from the start (e.g.,
    selecting the 80%-CI instead of the 95%-CI) because the Bootstrap’s generated
    data sets reflect true probability distributions given the available data. There
    will be no generated data set with a negative duration because the data does not
    reflect that possibility, but there will be data sets that reflect very long durations
    because the original data does include that as a possibility. So a confidence
    interval generated using the Bootstrap would be expected to remove more from the
    negative side of the range, but it might not remove as much (or might even add
    to) the positive side of the range.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这与从一开始就选择较窄范围（例如选择80%置信区间而不是95%置信区间）不同，因为Bootstrap生成的数据集反映了给定可用数据的真实概率分布。不会有生成的数据集显示负持续时间，因为数据不反映这种可能性，但原始数据确实包含非常长的持续时间。因此，使用Bootstrap生成的置信区间预计将从范围的负侧去除更多内容，但可能不会从正侧去除或者甚至可能增加。
- en: 'The process to build a Bootstrap CI is conceptually simple:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 建立Bootstrap置信区间的过程在概念上很简单：
- en: We simulate new samples of the same size by drawing with replacement from our
    observed sample.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过从我们观察到的样本中有放回抽样来模拟相同大小的新样本。
- en: Then, for each simulated sample we calculate our statistic of interest (here
    the mean, which is what our industrial engineer wants to measure).
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，对于每一个模拟样本，我们计算我们感兴趣的统计量（这里是均值，这是我们的工业工程师想要测量的量）。
- en: Finally, we build our CI by looking at the percentiles of the values obtained
    in step 2.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们通过查看第2步得到的数值的百分位数来构建我们的置信区间。
- en: Drawing with replacement means that each value has the same probability of being
    drawn each time, regardless of whether or not it has already been drawn.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有放回抽样意味着每个值每次被抽中的概率都是相同的，无论它之前是否已经被抽中。
- en: For example, drawing with replacement from (A, B, C) is equally likely to yield
    (B, C, C) or (A, C, B) or (B, B, B), etc. Because there are three possibilities
    for each of the three positions, there are 3 x 3 x 3 = 27 possible simulated samples.
    If we drew without replacement, this would mean that a value cannot be drawn more
    than once, and the only possible combinations would be permutations of the original
    sample, such as (A, C, B) or (B, A, C). This would simply amount to shuffling
    the values around, which would be pointless because the mean (or any other statistic
    of interest) would remain exactly the same.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，从（A，B，C）有放回抽样等可能地产生（B，C，C）或（A，C，B）或（B，B，B），等等。因为每个位置有三种可能性，所以每个位置有3 x 3 x
    3 = 27种可能的模拟样本。如果我们不进行放回抽样，这意味着一个值不能被抽取超过一次，唯一可能的组合将是原始样本的排列组合，如（A，C，B）或（B，A，C）。这将简单地意味着将值重新洗牌，这将是毫无意义的，因为均值（或任何其他感兴趣的统计量）将保持完全相同。
- en: 'Drawing with replacement is very simple in both R and Python:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在R和Python中，有放回抽样非常简单：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The beauty of generating new samples by drawing only from our observed sample
    is that it avoids making any distributional assumption about data outside of the
    sample we observed. To see what this means, let’s simulate B = 2,000 Bootstrap
    samples (to avoid confusion, I’ll always use B for the number of Bootstrap samples
    and N for the sample size) and calculate the mean of each. Our code proceeds as
    follows (the callout numbers are shared between R and Python):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仅从我们观察到的样本中抽取新样本的美妙之处在于，它避免了对我们观察到的样本之外的数据做出任何分布假设。为了看到这意味着什么，让我们模拟 B = 2,000
    个 Bootstrap 样本（为了避免混淆，我将始终使用 B 表示 Bootstrap 样本数量，N 表示样本大小），并计算每个样本的均值。我们的代码如下（R
    和 Python 之间的调用号码是共享的）：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](Images/1.png)](#comarker71)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#comarker71)'
- en: First I initialize an empty list for the results, as well as B and N.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我初始化了一个空列表用于结果，以及 B 和 N。
- en: '[![2](Images/2.png)](#comarker72)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#comarker72)'
- en: Then I use a `for` loop to generate the Bootstrap samples by drawing with replacement
    from the original data, each time calculating the mean and adding it to the list
    of results.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用 `for` 循环从原始数据中有放回地抽取 Bootstrap 样本，每次计算均值并将其添加到结果列表中。
- en: '[![3](Images/3.png)](#comarker73)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#comarker73)'
- en: Finally, in R I reformat the list into a tibble, for ease of use with `ggplot2`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 R 中，我将列表重新格式化为 tibble，以便与 `ggplot2` 更轻松地使用。
- en: '[Figure 7-2](#distribution_of_the_means_of_twocommaz) shows the distribution
    of the means.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 7-2](#distribution_of_the_means_of_twocommaz) 显示了均值的分布情况。'
- en: '![Distribution of the means of 2,000 samples](Images/BEDA_0702.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![2,000 个样本均值的分布情况](Images/BEDA_0702.png)'
- en: Figure 7-2\. Distribution of the means of 2,000 samples
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-2\. 2,000 个样本均值的分布情况
- en: 'As you can see, the histogram is very irregular: there is a big peak close
    to the mean of our original data set along with smaller peaks corresponding to
    certain patterns. Given how extreme our outlier is, each of the seven peaks corresponds
    to its number of repetitions in the Bootstrap sample, from zero to six. In other
    words, it doesn’t appear at all in the samples whose means are in the first (leftmost)
    peak, it appears exactly once in the samples whose means are in the second peak,
    and so on. It’s worth noting that even if we increased the number of Bootstrap
    samples, the irregularity of the histogram would not disappear (i.e., the “valleys”
    between the peaks would not get filled), because it reflects the roughness of
    our data and not the limitations of our random process. The range of values within
    our data is so extreme that the highest possible means when the outlier is excluded
    are still rarely high enough to meet the lowest possible means when the outlier
    is included. If the value of the outlier were cut in half, and thus were closer
    to the rest of the population, the histogram would appear to smooth out considerably
    because the edges of the outlier count peaks would overlap each other.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，直方图非常不规则：靠近原始数据集均值的大峰以及与某些模式对应的较小峰。鉴于我们的异常值有多极端，每个七个峰对应于它在 Bootstrap 样本中的重复次数，从零到六。换句话说，在第一个（最左边）峰的样本中没有出现它，在第二个峰的样本中出现一次，依此类推。值得注意的是，即使我们增加
    Bootstrap 样本的数量，直方图的不规则性也不会消失（即，“峰谷”之间的低谷不会填满），因为它反映了我们数据的粗糙性，而不是我们随机过程的限制。在我们的数据内部的值范围如此极端，以至于当排除异常值时可能的最高均值仍然很少高到足以满足包含异常值时可能的最低均值。如果异常值的值减半，因此接近人群的其余部分，则直方图将显着平滑化，因为异常值计数峰的边缘将彼此重叠。
- en: 'The number of Bootstrap samples matters nonetheless, but for a different reason:
    the higher that number, the more you’ll be able to see very unlikely samples and
    therefore extreme values. Here, the absolute highest possible value for a sample
    mean would be 413 if we drew the outlier 10 times. This has a probability of (0.1)^(10)
    (one-tenth to the power of 10), meaning it will happen about one time per 10 billion
    samples. With our mere 2,000 samples, we are barely seeing values around 200\.
    But the overall mean or median of our samples would remain the same plus or minus
    negligible sampling variations.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Bootstrap 样本数量仍然很重要，但原因不同：数量越多，您将能够看到非常不太可能的样本，因此极端值更多。例如，如果我们抽取了异常值 10 次，那么样本均值的绝对最大可能值将为
    413，其概率为 (0.1)^(10)（十分之一的十次方），这意味着大约每 100 亿个样本中会发生一次。通过我们仅有的 2,000 个样本，我们几乎看不到大约
    200 左右的值。但是我们的样本的整体均值或中位数仍将保持相同，加上或减去可忽略的抽样变化。
- en: 'Here are some general guidelines for number of samples:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些关于样本数量的一般指导原则：
- en: 100 to 200 samples to get an accurate central estimate (e.g., a coefficient
    in a regression; it’s called “central” because it’s roughly speaking at the center
    of a CI, as opposed to the CI’s bounds or limits)
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 100 到 200 个样本才能得到准确的中心估计（例如回归中的系数；它被称为“中心”，因为它大致处于置信区间的中心，与置信区间的边界或限制相反）
- en: 1,000 to 2,000 samples to get accurate 90%-CI bounds
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1,000 到 2,000 个样本才能获得准确的 90% 置信区间边界
- en: 5,000 samples to get accurate 99%-CI bounds
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5,000 个样本才能获得准确的 99% 置信区间边界
- en: In general, start low, and if in doubt increase the number and try again. This
    is fundamentally different from, for example, running multiple analyses on your
    data until you get numbers you like (a.k.a. “p-value hacking” or “p-hacking”);
    it’s more like changing the resolution of your screen when looking at a figure.
    It entails no risk for your analyses; it simply takes more or less of your time,
    depending on the size of your data and the computational power of your machine.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，从低处开始，如果有疑问增加数量然后再试一次。这与例如在数据上运行多次分析直到得到你喜欢的数字（也称为“ p 值破解”或“ p 破解”）根本不同；这更像是在查看图形时更改屏幕的分辨率。这对你的分析没有风险；它只是花费更多或更少的时间，这取决于你的数据量和计算机的计算能力。
- en: Given the data that we have, the only way we could increase the smoothness of
    the histogram would be to increase the sample size. However, we would have to
    increase the size of the original sample from the real world, not the size of
    the Bootstrap samples. Why can’t we increase the size of the Bootstrap samples
    (e.g., drawing 100 values with replacement from our sample of 10 values)? Because
    our goal is not to create new samples but to determine how far off our estimate
    of the mean could be when we make the assumption that the population is proportionately
    identical to our original sample. To do this we need to use all the information
    in the original sample—no less and no more. Creating larger samples from our 10
    original values would be “pretending” that we have more information than we actually
    have.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们拥有的数据，我们增加直方图的平滑度的唯一方法就是增加样本大小。然而，我们必须增加真实世界原始样本的大小，而不是自举样本的大小。为什么我们不能增加自举样本的大小（例如，从我们的
    10 个值的样本中有放回地抽取 100 个值）？因为我们的目标不是创建新的样本，而是确定我们对均值的估计可能有多大偏差，当我们假设总体与我们的原始样本相似时。为了做到这一点，我们需要使用原始样本中的所有信息——不多不少。从我们的
    10 个原始值中创建更大的样本将“假装”我们拥有比实际更多的信息。
- en: 'The engineer is ready to use the Bootstrap to determine the bounds of the CI
    for the duration of cake preparation. These bounds are determined from the *empirical*
    distribution of the preceding means. This means that instead of trying to fit
    a statistical distribution (e.g., normal), they can simply order the values from
    smallest to largest and then look at the 2.5% quantile and the 97.5% quantile
    to find the two-tailed 95%-CI. With 2,000 samples, the 2.5% quantile is equal
    to the value of the 50th smallest mean (because 2,000 * 0.025 = 50), and the 97.5%
    quantile is equal to the value of the 1950th mean from smaller to larger, or the
    50th largest mean (because both tails have the same number of values). Fortunately,
    we don’t have to calculate these by hand:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 工程师准备使用自举确定蛋糕制作持续时间的置信区间边界。这些边界是根据先前均值的*经验*分布确定的。这意味着他们不试图拟合统计分布（例如正态分布），而是可以简单地按大小顺序排列值，然后查看
    2.5% 分位数和 97.5% 分位数，以找到双尾 95% 置信区间。使用 2,000 个样本，2.5% 分位数等于第 50 个最小均值的值（因为 2,000
    * 0.025 = 50），而 97.5% 分位数等于较小到较大的第 1950 个均值的值，或第 50 个最大均值的值（因为两个尾部具有相同数量的值）。幸运的是，我们不必手动计算这些：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The Bootstrap 95%-CI is [7.50; 140.80] (plus or minus some sampling difference),
    which is much more realistic. [Figure 7-3](#distribution_of_the_means_of_twocommaze)
    shows the same histogram as [Figure 7-2](#distribution_of_the_means_of_twocommaz)
    but adds the mean of the means, the normal CI bounds and the Bootstrap CI bounds.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 自举 95% 置信区间是 [7.50; 140.80]（加减一些抽样差异），这更加现实。[图 7-3](#distribution_of_the_means_of_twocommaze)
    显示了与 [图 7-2](#distribution_of_the_means_of_twocommaz) 相同的直方图，但添加了均值的均值、正常置信区间边界和自举置信区间边界。
- en: '![Distribution of the means of 2,000 samples, with mean of the means (thick
    line), normal 95%-CI bounds (dotted lines), and Bootstrap CI bounds (dashed lines)](Images/BEDA_0703.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![2,000 个样本均值的分布，均值的均值（粗线），正常 95% 置信区间边界（虚线），和自举置信区间边界（虚线）的分布](Images/BEDA_0703.png)'
- en: Figure 7-3\. Distribution of the means of 2,000 samples, with mean of the means
    (thick line), normal 95%-CI bounds (dotted lines), and Bootstrap CI bounds (dashed
    lines)
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-3\. 2,000个样本均值分布，均值均值（粗线）、正常95%置信区间界限（虚线）和Bootstrap置信区间界限（虚线）
- en: In addition to the Bootstrap lower bound being above zero, we can also note
    that the Bootstrap upper bound is slightly higher than the normal upper bound,
    which better reflects the asymmetry of the distribution toward the right.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Bootstrap下限高于零之外，我们还可以注意到Bootstrap上限略高于正常上限，更好地反映了分布向右的不对称性。
- en: Bootstrap Confidence Intervals for Ad Hoc Statistics
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自适应统计量的Bootstrap置信区间
- en: 'Using the Bootstrap has allowed us to build a reasonable CI when the traditional
    statistical approach was failing. We can also use it to build CIs in situations
    where there is no other way to do so. Let’s imagine, for example, that C-Mart’s
    management is considering instituting a time promise—“your cake in three hours
    or 50% off”—and wants to know how often a cake currently takes more than three
    hours to be baked. Our estimate would be the sample percentage: it happens in
    1 of the 10 observed cases, or 10%. But we can’t leave it at that, because there
    is significant uncertainty around that estimate, which we need to convey. Ten
    percent out of 10 observations is much more uncertain than 10% out of 100 or 1,000
    observations.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当传统统计方法失效时，使用Bootstrap使我们能够建立合理的置信区间。我们还可以在没有其他方法的情况下使用它来建立置信区间。例如，让我们假设C-Mart的管理层正在考虑实施时间承诺——“三小时内完成蛋糕或打五折”，并想知道目前有多少蛋糕需要超过三小时烘焙。我们的估计将是样本百分比：在观察到的10个案例中有1个，即10%。但我们不能就此打住，因为这个估计存在显著不确定性，我们需要传达这一点。10次观察中的10%比起100次或1000次观察中的10%更不确定。
- en: 'So how can we build a CI around that 10% value? With the Bootstrap, of course.
    The process is exactly the same as earlier, except that instead of taking the
    mean of each simulated sample, we’ll measure the percentage of the values in the
    sample that are above 180 minutes:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何围绕那个10%的值建立置信区间？当然是使用Bootstrap。这个过程与之前完全相同，只是我们不再取每个模拟样本的平均值，而是测量样本中超过180分钟值的百分比：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The histogram of the results is shown in [Figure 7-4](#histogram_of_count_of_samples_with_a_gi).
    There’s “white space” between the bars again because we have only 10 data points,
    so percentages are multiples of 10%. That would not be the case with more data
    points; in general percentages will be multiples of 1/N with N the sample size
    (e.g., with 20 points, percentages would be multiples of 5%).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的直方图显示在[图 7-4](#histogram_of_count_of_samples_with_a_gi)中。由于我们只有10个数据点，所以条形之间有“白色空间”，因此百分比是10%的倍数。如果数据点更多，情况将不同；通常情况下，百分比将是1/N的倍数，其中N为样本大小（例如，如果有20个点，百分比将是5%的倍数）。
- en: '![Histogram of count of samples with a given proportion of durations above
    180 minutes](Images/BEDA_0704.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![有超过180分钟准备时间的样本计数直方图](Images/BEDA_0704.png)'
- en: Figure 7-4\. Histogram of count of samples with a given proportion of durations
    above 180 minutes
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-4\. 有超过180分钟准备时间的样本计数直方图
- en: 'In about 700 of the 2,000 simulated samples, there was no cake with a preparation
    time above 180 minutes. In about 750, there was exactly one such cake, and so
    on. The corresponding 95%-CI is [0; 0.3]: the 50th lowest value is 0 and the 50th
    highest value is 0.3.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在2000个模拟样本中的约700个样本中，没有蛋糕的准备时间超过180分钟。约750个样本中，恰好有一个这样的蛋糕，依此类推。相应的95%置信区间是[0;
    0.3]：第50个最低值为0，第50个最高值为0.3。
- en: In other words, even with such limited data, we can quite confidently say that
    it’s very unlikely (although not impossible) that more than 30% of the cakes take
    more than three hours to prepare. That’s still a pretty large confidence interval,
    but not too shabby for only 10 observations and such a unique statistic!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，即使数据受限，我们也可以相当自信地说，超过三小时准备的蛋糕比例超过30%的可能性非常低（尽管不是不可能）。对于仅有10次观察和如此独特的统计数据来说，这仍然是一个相当大的置信区间！
- en: Note
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If this is hard to wrap your mind around, you can reframe the preceding problem
    by calculating the confidence interval for a binomial distribution with 1 success
    in 10 observations. Approximation methods are available in R and Python to calculate
    CIs in that case. These tend to be more conservative (i.e., broader) than our
    Bootstrap CI, but not vastly so.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个概念难以理解，您可以通过计算具有 10 次观察中 1 次成功的二项分布的置信区间来重新构思前述问题。在这种情况下，R 和 Python 提供了近似方法来计算置信区间。这些方法通常比我们的自举置信区间更保守（即更广），但差距不会很大。
- en: By using the Bootstrap, the engineer can sharpen the analyses they would regularly
    want to perform with their data. They’re able to use limited data to answer a
    variety of questions with a reasonable amount of certainty (and correspondingly
    tolerable uncertainty).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自举法，工程师可以加强他们通常希望通过数据执行的分析。他们能够用有限的数据回答多种问题，并且具有相对可接受的确定性（和相应的可容忍不确定性）。
- en: The Bootstrap for Regression Analysis
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归分析的自举法
- en: While building a confidence interval around the mean can be useful, regression
    is really what this book is about, so let’s see how we can use the Bootstrap for
    that purpose. Our industrial engineer at C-Mart wants to determine the effect
    of experience on baking time using the same data about cake preparation. The corresponding
    CD is very simple ([Figure 7-5](#causal_diagram_for_our_relationship_of)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管围绕均值建立置信区间可能很有用，但回归才是本书的重点，所以让我们看看如何利用自举法来实现这一目的。我们在 C-Mart 的工业工程师想要使用有关蛋糕准备的同一数据来确定经验对烘焙时间的影响。相应的因果图非常简单（[图 7-5](#causal_diagram_for_our_relationship_of)）。
- en: '![Causal diagram for our relationship of interest](Images/BEDA_0705.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![我们感兴趣关系的因果图](Images/BEDA_0705.png)'
- en: Figure 7-5\. Causal diagram for our relationship of interest
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-5\. 我们感兴趣关系的因果图
- en: 'Running a regression on our data is straightforward, given that the causal
    diagram did not reveal any confounder. However, the resulting coefficient is not
    significant:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有显示任何混杂变量的因果图的情况下，对我们的数据进行回归是直接的。然而，得到的系数并不显著：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Our estimated coefficient is −9.8, meaning that every additional month of experience
    is expected to remove 9.8 minutes of preparation time. However, the traditional
    CI based on the regression standard error would be [–22.2; 2.5]. From a traditional
    perspective, this would be game over: the CI includes zero, meaning that months
    of experience could have a positive, negative, or zero effect on baking time,
    so we would decline to draw any substantive conclusion. Let’s see instead what
    the Bootstrap tells us. The process is exactly the same as before: we simulate
    samples of 10 data points by drawing with replacement from our original sample
    a large number of times, then save the regression coefficient. Last time we used
    B = 2,000 samples. This time let’s use B = 4,000, as it makes the corresponding
    histogram look smoother ([Figure 7-6](#distribution_of_the_regression_coeffic)):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的估计系数为 −9.8，这意味着每增加一个月的经验，准备时间预计会减少 9.8 分钟。然而，基于回归标准误差的传统置信区间为 [–22.2; 2.5]。从传统的角度来看，这将是游戏结束：置信区间包含零，这意味着经验月份可能对烘焙时间有正面、负面或零影响，因此我们不会得出任何实质性结论。让我们看看自举法告诉我们的是什么。过程与之前完全相同：我们通过从原始样本中有放回地抽取大量次数的样本来模拟
    10 个数据点的样本，然后保存回归系数。上次我们使用了 B = 2,000 个样本。这次让我们使用 B = 4,000，因为这使得相应的直方图看起来更加平滑（[图 7-6](#distribution_of_the_regression_coeffic)）：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![Distribution of the regression coefficients of preparation time on experience,
    with their mean (thick line), Bootstrap CI bounds (thick dashed lines), and normal
    CI bounds (thin dotted lines) (B=4,000 Bootstrap samples)](Images/BEDA_0706.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![准备时间对经验的回归系数分布，显示其均值（粗线）、自举置信区间边界（粗虚线）和正常置信区间边界（细点线）（B=4,000 自举样本）](Images/BEDA_0706.png)'
- en: Figure 7-6\. Distribution of the regression coefficients of preparation time
    on experience, with their mean (thick line), Bootstrap CI bounds (thick dashed
    lines), and normal CI bounds (thin dotted lines) (B = 4,000 Bootstrap samples)
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-6\. 准备时间对经验的回归系数分布，显示其均值（粗线）、自举置信区间边界（粗虚线）和正常置信区间边界（细点线）（B = 4,000 自举样本）
- en: 'The Bootstrap CI is [–28; –0.2]. As you can see in [Figure 7-6](#distribution_of_the_regression_coeffic),
    it’s again asymmetric compared to the symmetric normal bounds, with a long tail
    to the left of the mean. The highly irregular shape of the distribution reflects
    the existence of two competing hypotheses:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Bootstrap的置信区间是[–28; –0.2]。正如您在[图7-6](#distribution_of_the_regression_coeffic)中看到的那样，与对称正态边界相比，它再次是不对称的，左侧有一个长尾。分布的高度不规则形状反映了存在两个竞争假设：
- en: The tall and narrow peak near zero is made of samples that don’t include the
    outlier, and as such it corresponds with the view that the outlier is a freak
    accident that won’t repeat itself. That’s the confidence interval you would get
    if you discarded the outlier.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 靠近零的高而窄的峰是由不包含异常值的样本组成，因此它对应于异常值是不会重复的意外事件的观点。这是如果丢弃异常值时得到的置信区间。
- en: The broad and flat hump to the left is made of samples that include the outlier
    one or several times. It reflects the hypothesis that the outlier is truly representative
    of our data and that its true frequency may be even higher than in our small sample.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左侧宽阔的平台是由包含异常值一次或多次的样本组成。它反映了异常值真正代表我们数据的假设，并且其真实频率可能甚至高于我们的小样本。
- en: You can think of this as data-driven scenario analysis. What if this pattern
    didn’t exist? What if it dominated our data? Instead of having to choose between
    discarding the outlier or letting it drive our results, the Bootstrap allows us
    to consider all possibilities at once.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将其视为数据驱动的场景分析。如果不存在这种模式会怎样？如果它主导了我们的数据会怎样？与其在丢弃异常值或让其驱动我们的结果之间做出选择，Bootstrap允许我们一次考虑所有可能性。
- en: In addition to building a CI, we can use the Bootstrap to determine the equivalent
    of a p-value. If you look at the output of our regression at the beginning of
    this section, you’ll see the value 0.16 for experience in the column for the p-values
    (i.e., the column with the label Pr(>|t|)). You have probably already been told
    that a coefficient is statistically significant (i.e., statistically significantly
    different from zero) if its p-value is less than 0.05, or 0.01 in more stringent
    cases. Mathematically speaking, the p-value is such that the (1 minus p-value)-CI
    has zero as one of its bounds. In the case of the normal regression, zero is the
    upper bound of the 84%-CI. Because 84% is less than 95% or 99%, the coefficient
    for experience would not be considered statistically significant. The exact same
    logic can be used with the Bootstrap; we just have to calculate the fraction of
    the Bootstrap sample whose coefficient is above zero, and multiply it by 2 because
    it’s a two-tailed test:^([2](ch07.xhtml#ch01fn11))
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 除了构建置信区间外，我们还可以使用Bootstrap来确定等效的p值。如果您查看本节开头回归的输出，您将看到经验列中p值为0.16（即具有标签Pr(>|t|)的列）。您可能已经被告知，如果系数的p值小于0.05（或在更严格的情况下为0.01），则系数在统计上显著（即与零显著不同）。从数学上讲，p值是这样的，即(1减去p值)-置信区间的上界为零。在正常回归的情况下，零是84%置信区间的上界。因为84%小于95%或99%，经验不会被认为在统计上显著。相同的逻辑也可以用于Bootstrap；我们只需计算Bootstrap样本中系数高于零的分数，并乘以2，因为这是一个双侧检验:^([2](ch07.xhtml#ch01fn11))
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This means that our empirical Bootstrap p-value^([3](ch07.xhtml#ch01fn12)) is
    about 0.04, as opposed to the traditional p-value of 0.16 rooted in statistical
    assumptions. This is helpful because people are often familiar with statistical
    p-values, and Bootstrap p-values can be used instead. From a business perspective,
    we can now be confident that the regression coefficient is between null and strongly
    negative. In addition, we could easily calculate the equivalent of a p-value for
    any other threshold (e.g., if we wanted to use −1 instead of zero as a threshold),
    or for any interval, such as [−1; +1], if we wanted.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们的经验性Bootstrap p值^([3](ch07.xhtml#ch01fn12))约为0.04，而不是基于统计假设的传统p值0.16。这是有帮助的，因为人们通常熟悉统计p值，而Bootstrap
    p值可以替代使用。从商业角度来看，我们现在可以确信回归系数在零和强负之间。此外，我们可以轻松计算任何其他阈值的等效p值（例如，如果我们想要使用−1而不是零作为阈值），或者任何区间，例如[−1;
    +1]。
- en: When to Use the Bootstrap
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用Bootstrap
- en: 'Hopefully, by now you’re convinced of the virtues of the Bootstrap for small
    and oddly shaped data sets. But what about large or evenly shaped data sets? Should
    you always use the Bootstrap? The short answer is that it is never wrong to use
    it, but it can be impractical or overkill. For experimental data, we’ll rely extensively
    on the Bootstrap, as we’ll see in [Part IV](part04.xhtml#designing_and_analyzing_experiments)
    of the book. For observational data analysis, which is the focus of this chapter,
    things are more complicated. [Figure 7-7](#decision_tree_to_use_the_bootstrap)
    presents the decision tree we’ll use. It may look a bit intimidating, but it can
    be broken down conceptually into three blocks:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 希望到目前为止，你已经被 Bootstrap 在小型和奇异数据集上的优点所说服。但是对于大型或均匀形状的数据集，应该总是使用 Bootstrap 吗？简短的答案是，使用它永远不会错，但可能不切实际或过度复杂。对于实验数据，我们将大量依赖于
    Bootstrap，正如我们将在本书的第四部分 [Part IV](part04.xhtml#designing_and_analyzing_experiments)
    中看到的那样。对于本章节的观察数据分析，情况更为复杂。[Figure 7-7](#decision_tree_to_use_the_bootstrap) 展示了我们将使用的决策树。它可能看起来有点吓人，但在概念上可以分解为三个块：
- en: If you only want a central estimate (e.g., a regression coefficient) and the
    conditions for the traditional estimate to be sufficient are fulfilled, you can
    use it.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你只需要一个中心估计（例如回归系数），并且传统估计的条件已经满足，你可以使用它。
- en: If you want a CI and the conditions for the traditional CI to be sufficient
    are fulfilled, you can use it.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要一个置信区间（CI），并且传统 CI 的条件已经满足，你可以使用它。
- en: In any other case or when in doubt, use the Bootstrap CI.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何其他情况或疑问时，请使用 Bootstrap CI。
- en: Let’s review these blocks in turn.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们依次回顾这些块。
- en: '![Decision tree to use the Bootstrap](Images/BEDA_0707.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Bootstrap 的决策树](Images/BEDA_0707.png)'
- en: Figure 7-7\. Decision tree to use the Bootstrap
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-7\. 使用 Bootstrap 的决策树
- en: Conditions for the Traditional Central Estimate to Be Sufficient
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传统中心估计条件的充分性
- en: The first thing to keep in mind is that the Bootstrap yields a central estimate
    or coefficient that is very close to the one obtained by traditional methods (i.e.,
    whatever you would have done if you didn’t know about the Bootstrap). Therefore,
    it never makes sense to start directly with the Bootstrap, when a traditional
    estimate is one line of code away.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要记住的是，Bootstrap 产生的中心估计或系数非常接近传统方法得到的估计（即如果你不知道 Bootstrap，你会做的那种）。因此，当传统估计只需一行代码时，直接从
    Bootstrap 开始从来都没有意义。
- en: However, if your data is small (typically less than 100 rows) or in any regard
    weird (e.g., it has multiple peaks or is asymmetric), then that central estimate
    can be misleading. In that case, you should really use the Bootstrap to calculate
    a confidence interval instead, ideally displaying its results in the form of a
    histogram as we did in [Figure 7-6](#distribution_of_the_regression_coeffic).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你的数据很小（通常少于 100 行）或在任何方面都很奇怪（例如有多个峰值或不对称），那么中心估计可能会误导。在这种情况下，你应该真正使用 Bootstrap
    来计算置信区间，最好将其结果显示为直方图，就像我们在 [Figure 7-6](#distribution_of_the_regression_coeffic)
    中所做的那样。
- en: Similarly, if the coefficient is close to a boundary or threshold, and therefore
    not economically clear-cut, you’ll need to use a CI and the central estimate won’t
    be sufficient.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，如果系数接近边界或阈值，因此经济上不明确，你将需要使用一个 CI，中心估计将不足以满足需求。
- en: Even when things are as clean and clear-cut as they can be, you may still want
    to have a CI, for example because your boss or your business partner required
    it.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 即使事情如此清晰和明确，你可能仍然想要一个 CI，例如因为你的老板或商业伙伴要求它。
- en: Conditions for the Traditional CI to Be Sufficient
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传统 CI 的充分性条件
- en: 'If you want to have a CI but your data is not so small or weird that the Bootstrap
    CI is required, the question becomes whether a traditional CI would be reliable
    and sufficient for your purpose. There are two tests you need to run in that situation:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要一个 CI，但你的数据并非如此小或奇怪，以至于需要 Bootstrap CI，那么问题就变成了传统 CI 是否可靠并且足够满足你的目的。在这种情况下，你需要运行两个测试：
- en: Check the presence or not of influential points.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查是否存在影响力点。
- en: Check the normality of the regression residuals (only if the regression is linear).
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查回归残差的正态性（仅当回归是线性的时候）。
- en: Only if your data is devoid of influential points and you don’t see any issue
    with the residuals can you use the traditional CI.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当你的数据没有影响力点，并且残差没有问题时，你才能使用传统 CI。
- en: 'Influential points are points whose deletion would substantially modify the
    regression, and there is a statistic, [Cook’s distance](https://oreil.ly/0OS4s),
    which measures precisely that. For our purposes here, it’s enough to know that
    a data point is considered influential if its Cook’s distance is more than one.
    R and Python have one-liners to calculate Cook’s distance for points with respect
    to a regression model:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有影响力的点是指删除它将大幅改变回归结果的点，而[Cook's distance](https://oreil.ly/0OS4s)这一统计量精确地测量了这一点。对于我们这里的目的，知道数据点的Cook's
    distance超过一就被认为有影响力就足够了。R和Python都有一行代码来计算关于回归模型的Cook's distance：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-113
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: 'By definition, an influential point doesn’t follow the same pattern as the
    other points (otherwise deleting it would not drastically change the results of
    our regression). This means that an influential point is always an outlier, but
    an outlier is not always an influential point: an outlier lies far out from the
    cloud that the other points form, but it could still be close to the regression
    line calculated without it and have a small Cook’s distance. In our baking example,
    the outlier point is also an influential point.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 按定义，影响力点不遵循其他点的相同模式（否则删除它不会显著改变回归结果）。这意味着影响力点总是一个异常值，但异常值并不总是一个影响力点：异常值远离其他点形成的云团，但仍可能接近没有它计算的回归线，并且具有较小的Cook's
    distance。在我们的烘焙示例中，异常值点也是一个影响力点。
- en: If you have any influential point in your data, it suggests that the standard
    distributional assumptions are not met, and using the Bootstrap may be wiser.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据中有任何影响力点，表明标准的分布假设未被满足，使用Bootstrap方法可能更明智。
- en: 'If you don’t have influential points in your data, there is a second check
    you need to do in the case of a linear regression: you need to make sure that
    the regression residuals are approximately normal. This doesn’t apply to logistic
    regression because its residuals follow a Bernoulli distribution and not a normal
    distribution. This check answers both the questions of “How non-normal is non-normal?”
    and “How large is large?” because they are related: larger data dampens minor
    deviations from normality, so a degree of non-normality that would be problematic
    with a hundred points might be OK with a hundred thousand.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据中没有影响力点，那么在线性回归情况下还需要进行第二项检查：确保回归残差近似正态分布。这不适用于逻辑回归，因为它的残差遵循伯努利分布而不是正态分布。这一检查同时回答了“非正态有多非正态？”和“大有多大？”这两个问题，因为它们是相关的：更大的数据可以抑制对正态性的轻微偏差，所以对于一百个数据点来说可能会有问题的非正态度，在十万个数据点的情况下可能就可以接受了。
- en: 'Let’s extract the regression residuals and visually assess their normality.
    In R, we obtain the residuals by applying the function `resid()` to our linear
    regression model:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 提取回归残差并直观评估其正态性。在R中，我们通过应用函数`resid()`到我们的线性回归模型来获得残差：
- en: '[PRE19]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The syntax in Python is also straightforward: we first get the residuals from
    the model, then draw a density plot from the Seaborn package, and draw the QQ-plot
    with the statsmodels package:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Python中的语法同样简单：首先从模型中获取残差，然后使用Seaborn包绘制密度图，再使用statsmodels包绘制QQ图：
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[Figure 7-8](#density_plot_left_parenthesisleftright) displays the two plots
    we created in R, a density plot and a QQ-plot.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7-8](#density_plot_left_parenthesisleftright)展示了我们在R中创建的两个图，一个是密度图，一个是QQ图。'
- en: '![Density plot (left) and QQ-plot (right) of regression residuals](Images/BEDA_0708.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![回归残差的密度图（左）和QQ图（右）](Images/BEDA_0708.png)'
- en: Figure 7-8\. Density plot (left) and QQ-plot (right) of regression residuals
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-8\. 回归残差的密度图（左）和QQ图（右）
- en: Let’s first look at the density plot on the left. For a normal density, we would
    expect to see a curve with a single peak centered on zero and with smoothly decreasing,
    symmetric left and right tails. This is clearly not the case here due to the presence
    of an outlier with a large residual, so we conclude that the residuals are not
    normally distributed.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看左边的密度图。对于正态密度，我们期望看到一个以零为中心的单峰曲线，左右对称的光滑递减的尾部。由于存在一个具有较大残差的异常值，显然这里并非如此，因此我们得出结论残差不是正态分布的。
- en: The plot on the right is a QQ-plot (QQ stands for Quantile-Quantile), plotted
    with `geom_qq()` or `qqplot()`, which shows the values of our residuals on the
    x-axis and a theoretical normal distribution on the y-axis. For a normal density,
    we would expect all the points to be on the line or very close to it, which is
    again not the case here because of the outlier.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 右侧的图是一个QQ图（QQ代表分位数-分位数），用`geom_qq()`或`qqplot()`绘制，显示了我们残差的值在x轴上和理论正态分布在y轴上。对于正态密度，我们期望所有点都在直线上或非常靠近直线，但由于异常值的存在，这里并非如此。
- en: Whenever the residuals of a linear regression are not normally distributed,
    the Bootstrap will give you better results for CIs and p-values than the traditional
    approach.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 每当线性回归的残差不服从正态分布时，Bootstrap将比传统方法提供更好的置信区间和p值结果。
- en: To recap, it is never wrong to build Bootstrap CIs and you can always fall back
    on them. But when you only need the central estimate and you can safely rely on
    it, or when you can safely rely on a traditional CI, it can be overkill to jump
    to the Bootstrap.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，构建Bootstrap置信区间从来不会错，而且你总能依靠它们。但是当你只需要中心估计并且可以安全依赖它时，或者可以安全地依赖传统的置信区间时，就不必盲目地转向Bootstrap了。
- en: Finally, let’s see in a bit more detail how you can determine the number of
    Bootstrap samples to use.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们稍微详细地看看如何确定要使用的Bootstrap样本数量。
- en: Determining the Number of Bootstrap Samples
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定Bootstrap样本数量
- en: Once you have decided to use the Bootstrap, you need to determine the number
    of samples to use in your simulation. If you just want to get a broad sense of
    the variability of an estimate, B = 25 to 200 gives reasonably robust results
    for main estimates, according to Efron, the “inventor” of the Bootstrap. Think
    of it as a 75%-CI. You wouldn’t bet the farm on it, but it tells you more than
    just a mean.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦决定使用Bootstrap，你需要确定模拟中使用的样本数量。如果你只是想大致了解估计值的变异性，那么根据Bootstrap的“发明者”埃弗隆，B =
    25到200可以给出对主要估计值相当健壮的结果。把它看作是一个75%的置信区间。你不会把它套上赌场，但它告诉你的不仅仅是一个平均值。
- en: On the other hand, let’s say you want a precise p-value or 95%-CI because there
    is uncertainty as to whether or not a critical threshold, usually zero, is in
    it or not. Then you’ll need a much larger B, because we’re typically looking at
    the 2.5% smallest or 2.5% highest values of the Bootstrap distribution. With B
    = 200, the lower bound of a two-tailed 95%-CI is equal to 200 * 2.5%, or the fifth-smallest
    value, and similarly the upper bound is equal to the fifth-largest value. Five
    is a pretty small number. You can pretty easily get unlucky and get five numbers
    that are smaller or larger than expected, and throw off your CI bound. Let’s visualize
    that by repeating the Bootstrap regression from the previous section with only
    200 samples. As you can see in [Figure 7-9](#distribution_of_the_regression_coeffici),
    the shape of the distribution is overall similar to [Figure 7-5](#causal_diagram_for_our_relationship_of),
    but now the upper bound for our CI is *above* zero.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，假设你想要一个精确的p值或95%的置信区间，因为不确定是否有关键阈值（通常为零）在其中或不在其中。那么你需要更大的B，因为我们通常在Bootstrap分布的2.5%最小值或最大值上看。使用B
    = 200时，双尾95%置信区间的下限等于200 * 2.5%，或第五小的值，同样地，上限等于第五大的值。五是一个相当小的数字。你很容易运气不好，得到五个比预期更小或更大的数字，从而打乱了你的置信区间边界。让我们通过仅使用200个样本重复上一节的Bootstrap回归来可视化这一点。如你在[图7-9](#distribution_of_the_regression_coeffici)中看到的，分布的形状整体上与[图7-5](#causal_diagram_for_our_relationship_of)相似，但现在我们的置信区间的上限是*大于*零。
- en: '![Distribution of the regression coefficients of preparation time on experience,
    with their mean (thick line), the Bootstrap CI bounds (thick dashed lines) and
    the normal CI bounds (thin dotted lines) (B=200 Bootstrap samples)](Images/BEDA_0709.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![准备时间对经验的回归系数分布，包括其均值（粗线）、Bootstrap置信区间边界（粗虚线）和正态置信区间边界（细虚线）（B=200 Bootstrap样本）](Images/BEDA_0709.png)'
- en: Figure 7-9\. Distribution of the regression coefficients of preparation time
    on experience, with their mean (thick line), the Bootstrap CI bounds (thick dashed
    lines) and the normal CI bounds (thin dotted lines) (B = 200 Bootstrap samples)
  id: totrans-133
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-9\. 准备时间对经验的回归系数分布，包括其均值（粗线）、Bootstrap置信区间边界（粗虚线）和正态置信区间边界（细虚线）（B = 200 Bootstrap样本）
- en: Therefore, if a business decision hinges on where that bound is in relation
    to zero, you’ll need to make sure that you estimate it accurately by increasing
    B. Having 1,000 or even 2,000 samples is a generally accepted guideline in such
    circumstances. At B = 2,000 the 2.5% quantile is equal to the 50th value, so the
    odds are much more in your favor. In addition, with very small data sets such
    as the one used in this chapter, even simulating 4,000 samples takes no more than
    a few seconds, which is why I have used such a large B.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果业务决策依赖于该边界与零点的关系，您需要通过增加B来确保准确估计。在这种情况下，通常接受使用1,000或甚至2,000个样本的指导方针。在B
    = 2,000时，2.5%分位数等于第50个值，因此成功的机会大得多。此外，在本章中使用的非常小的数据集中，即使模拟4,000个样本也不超过几秒钟，这就是我为什么使用了这么大的B。
- en: 'Let’s recap when to use the Bootstrap with observational data, bringing together
    the test conditions and the number of samples:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结何时使用Bootstrap处理观测数据，结合测试条件和样本数量：
- en: Always start with your traditional regression model to get the main estimate.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 始终从传统的回归模型开始获取主要估计值。
- en: If you have less than 100 points in your data, always use the Bootstrap with
    B between 25 and 200 to assess the uncertainty around that estimate.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果数据中少于100个数据点，则始终使用B在25到200之间的Bootstrap来评估该估计的不确定性。
- en: With N > 100, check your data for signs of influential points (with Cook’s distance)
    or non-normality (with the density plot and QQ-plot of residuals). If anything
    looks fishy, use the Bootstrap, again with B between 25 and 200 for main estimates.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于N > 100的情况，请检查数据是否存在异常点（使用Cook距离）或非正态性（使用残差的密度图和QQ图）。如果有任何可疑情况，请再次使用Bootstrap，主要估计使用25到200之间的B。
- en: Regardless of N, if you need a precise confidence interval or achieved significance
    level (a.k.a. p-value), do another Bootstrap simulation with B between 1,000 and
    2,000.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无论N如何，如果需要精确的置信区间或达到的显著性水平（又称p值），请使用1,000到2,000之间的B进行另一次Bootstrap模拟。
- en: Once you’ve gotten a sense of how long it takes to run a Bootstrap simulation
    on your data with a small to medium B, and what the corresponding histogram or
    CI looks like, always feel free to push the dial on B. Feel free to run a simulation
    with B = 10,000 overnight to get a nicely dented graph and an exactingly precise
    CI bound.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦您对在数据上运行Bootstrap模拟所需的时间有了大致了解，并且对应的直方图或置信区间看起来如何，随时随地都可以增加B值。可以在夜间使用B = 10,000运行模拟，以获得一个精确的图表和精确的置信区间边界。
- en: Optimizing the Bootstrap in R and Python
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在R和Python中优化Bootstrap
- en: I have shown you how to apply the Bootstrap algorithm “by hand,” so that you
    can understand what it does, but there are packages that will do it in fewer lines
    of code and will run faster. They will also allow you to use improved versions
    of the Bootstrap that would be impractical to code manually.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我已向您展示了如何“手动”应用Bootstrap算法，以便您了解其作用，但有些包可以用更少的代码行数运行得更快。它们还允许您使用改进版本的Bootstrap，手动编码将变得不切实际。
- en: 'R: The boot Package'
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: R：Bootstrap包
- en: The `boot` package and its `boot()` function provide a one-stop shop for Bootstrap
    analyses. For all its simplicity, the way it generates Bootstrap samples is not
    intuitive, so it’s worth looking at that feature separately first.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`boot`包及其`boot()`函数为Bootstrap分析提供了一站式服务。尽管其简单性，它生成Bootstrap样本的方式并不直观，因此最好先单独查看该特性。'
- en: 'Remember that in the earlier section on Bootstrap for regression analysis,
    I generated Bootstrap samples with the `slice_sample()` function before running
    our regression of interest on them:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在早期关于回归分析Bootstrap的章节中，我在运行我们感兴趣的回归之前使用`slice_sample()`函数生成Bootstrap样本：
- en: '[PRE21]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'An alternative approach to generate Bootstrap samples is to take a list of
    indices, sample from it with replacement, then subset our data based on that list:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 生成Bootstrap样本的另一种方法是获取索引列表，使用替换抽样，然后根据该列表对数据进行子集操作：
- en: '[PRE22]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This is the approach used in the `boot()` function. We must create a function
    taking as arguments our original data and a list of index J and returning our
    variable of interest (here, the regression estimate for experience). The `boot()`
    function will take care of generating that list for each iteration; we only need
    to subset our data with it within our function:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`boot()`函数中使用的方法。我们必须创建一个函数，该函数以我们的原始数据和索引列表J作为参数，并返回我们感兴趣的变量（这里是经验的回归估计）。`boot()`函数将负责为每次迭代生成该列表；我们只需在我们的函数中使用它来对数据进行子集操作：
- en: '[PRE23]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'After creating that function, we pass it to the `boot()` function as the argument
    `statistic`, as well as our original data as `data`, and the number of Bootstrap
    samples as `R` (for replications). The `boot()` function returns an object that
    we then pass to the `boot.ci()` function to get our CI:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 创建该函数后，我们将其作为参数 `statistic` 传递给 `boot()` 函数，以及我们的原始数据作为 `data`，以及自举样本的数量作为 `R`（用于复制）。`boot()`
    函数返回一个对象，然后我们将该对象传递给 `boot.ci()` 函数以获取我们的置信区间：
- en: '[PRE24]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `boot.ci()` function can return a variety of CIs, as determined by the parameter
    `type`. “norm” is the traditional CI based on a normal distribution. “perc” is
    the percentile, or quantile, Bootstrap that we calculated by hand previously.
    “bca” is the bias-corrected and accelerated percentile Bootstrap (BC[a]). The
    BC[a] Bootstrap refines the percentile Bootstrap by leveraging some of its statistical
    properties; these are beyond our scope here. You can learn more about them in
    any of the sources listed as references; suffice it to say that the BC[a] Bootstrap
    is considered best practice when using Bootstrap simulations. It can be pretty
    demanding in terms of computations however, so I would recommend using the percentile
    Bootstrap first, and once you have a reasonably final version of your code, try
    switching to the BC[a] Bootstrap.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`boot.ci()` 函数可以根据参数 `type` 返回各种置信区间。“norm”是基于正态分布的传统置信区间。“perc”是我们之前手工计算的百分位或分位数自举法。“bca”是偏差校正和加速的百分位自举法（BC[a]）。BC[a]
    自举法通过利用部分统计特性改进了百分位自举法；这些超出了我们的范围。您可以在任何列出的参考资料中了解更多信息；总之，BC[a] 自举法被认为是使用自举模拟时的最佳实践。然而，从计算的角度来看，它可能相当苛刻，因此我建议先使用百分位自举法，一旦代码基本完成，再尝试切换到BC[a]
    自举法。'
- en: In the present case, the normal and percentile CIs are very close to what we
    calculated by hand, as expected. The BC[a] CI shifts to the left, strengthening
    our original conclusions that the coefficient is most likely strongly negative.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在目前的情况下，正态和百分位数置信区间与我们之前手工计算的结果非常接近，这是预期的。BC[a] 置信区间向左偏移，进一步加强了我们最初的结论，即系数很可能是强负数。
- en: 'Now that you understand the intuition behind the use of the `boot` package,
    let’s create a reusable function:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经理解了使用 `boot` 包背后的直觉，让我们创建一个可重复使用的函数：
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `boot_CI_fun()` function takes as arguments a data set and a metric function
    and returns a 90% confidence interval for that metric function on that data set,
    based on 100 Bootstrap samples and the percentile approach.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`boot_CI_fun()` 函数接受数据集和度量函数作为参数，并基于 100 个自举样本和百分位方法返回该数据集上该度量函数的 90% 置信区间。'
- en: Python Optimization
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python 优化
- en: 'Python offers very different trade-offs to the analyst compared to R: on the
    one hand, it has fewer statistical packages and there is no equivalent of the
    R `boot` package that would implement the Bootstrap algorithm directly. On the
    other hand, I find it to be more forgiving of beginners in terms of performance.
    This is especially true for bootstrapping, because `for` loops, which beginners
    tend to use a lot, are comparatively much less costly. Therefore, I expect Python
    users to get much more mileage out of the naive implementation we started with.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 与 R 相比，Python 对分析师提供了非常不同的权衡：一方面，它具有较少的统计包，没有直接实现自举算法的 R `boot` 包的等价物。另一方面，从性能的角度来看，我发现它对初学者更加宽容。特别是对于自举法来说，因为初学者经常大量使用的
    `for` 循环成本相对较低。因此，我预计 Python 用户能更充分地利用我们起步时的朴素实现。
- en: 'Still, should you need to add computational oomph to your Bootstrap implementation
    in Python, you can do so by going “full NumPy”:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果您需要在 Python 中为自举实现增加计算性能，可以全面采用“NumPy”：
- en: '[PRE26]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[![1](Images/1.png)](#comarker771)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#comarker771)'
- en: We convert our original pandas dataframe to a NumPy array.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将原始的 pandas 数据框转换为 NumPy 数组。
- en: '[![2](Images/2.png)](#comarker772)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#comarker772)'
- en: We initialize the NumPy random number generator only once, outside of the loop.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅在循环外部初始化 NumPy 随机数生成器一次。
- en: '[![3](Images/3.png)](#comarker773)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#comarker773)'
- en: We create our bootstrapped data set by using the NumPy random number generator,
    which is significantly faster than the pandas `.sample()` method for dataframes.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用 NumPy 随机数生成器来创建我们的自举数据集，这比 pandas 的 `.sample()` 方法快得多。
- en: '[![4](Images/4.png)](#comarker774)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#comarker774)'
- en: We extract the predictor columns from our array and in the following line manually
    add a constant column for the intercept (whereas `statsmodel` was previously handling
    that under the hood for us).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从数组中提取预测列，并在接下来的一行中手动添加一个常数列作为截距（而`statsmodel`在此之前在后台为我们处理了这个）。
- en: '[![5](Images/5.png)](#comarker775)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#comarker775)'
- en: We extract the column for the dependent variable from our array.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从数组中提取因变量列。
- en: '[![6](Images/6.png)](#comarker776)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#comarker776)'
- en: 'Reading the function calls from the right to the left: we fit the linear regression
    model with the `np.linalg.lstsq()` function to the predictor and dependent variable
    data. The `rcond=-1` parameter removes an unimportant warning. The value we want
    is in the `[0][0]` cell for this particular model; you can find the specific cell
    you need by running `np.linalg.lstsq(X, Y, rcond=-1)` once and inspecting its
    output. Finally, we append the value to our result list.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 从右向左读取函数调用：我们使用`np.linalg.lstsq()`函数对预测变量和因变量数据进行线性回归模型拟合。参数`rcond=-1`消除了一个不重要的警告。对于这个特定模型，我们想要的值在`[0][0]`单元格中；您可以通过运行一次`np.linalg.lstsq(X,
    Y, rcond=-1)`并检查其输出来找到您需要的特定单元格。最后，我们将值附加到我们的结果列表中。
- en: Going full NumPy can significantly improve your performance, to the order of
    fifty times faster or so for larger data sets. However, our original code did
    just fine for our small data set, and it was more readable and less error-prone.
    Moreover, if you go beyond straightforward linear or logistic regressions, you’ll
    have to search on the Internet for a NumPy implementation of the algorithm you
    want. But should you need to improve the performance of your Bootstrap code in
    Python, you now know how to do so.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 完全采用NumPy可以显著提高性能，对于较大的数据集可能提高约50倍。然而，我们的原始代码对于小数据集表现良好，并且更易读且更少出错。此外，如果您超越了简单的线性或逻辑回归，您将不得不在互联网上搜索您想要的算法的NumPy实现。但是，如果您需要在Python中改进您的Bootstrap代码的性能，现在您知道该如何做了。
- en: Conclusion
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Behavioral data analyses often have to deal with smaller or weirder data. Fortunately,
    the advent of computer simulations has given us in the Bootstrap a great tool
    to deal with such situations. Bootstrap confidence intervals allow us to correctly
    assess the uncertainty in our estimates without relying on potentially faulty
    statistical assumptions about the distribution of our data. With observational
    data, the Bootstrap is most useful when our data exhibits signs of influential
    points or non-normality; otherwise, it is often overkill. With experimental data,
    however, the heavy reliance on p-values to make decisions means that we’ll use
    it extensively, as we’ll see in the next part of the book.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 行为数据分析通常需要处理较小或较奇怪的数据。幸运的是，随着计算机模拟的出现，我们在Bootstrap中有了一个很好的工具来处理这种情况。Bootstrap置信区间使我们能够正确评估估计值的不确定性，而无需依赖于关于数据分布的可能存在问题的统计假设。对于观测数据，当我们的数据表现出有影响力点或非正态性的迹象时，Bootstrap是最有用的；否则，它通常是多余的。然而，对于实验数据，由于过度依赖于p值来做出决策，我们将会广泛使用它，正如我们将在本书的下一部分中看到的。
- en: ^([1](ch07.xhtml#ch01fn10-marker)) See Wilcox (2010), which shows the danger
    of assuming normality as a matter of course.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch07.xhtml#ch01fn10-marker)) 请参阅Wilcox（2010），其中显示了默认假设正态性的危险性。
- en: ^([2](ch07.xhtml#ch01fn11-marker)) To see why, note that if you have a 90%-CI,
    you’ll have 5% of values remaining on each side out of it because (1 − 0.9) /
    2 = 0.05\. Conversely, if you see that you have 5% of values on one side out of
    a CI, then it’s the 90%-CI, because (1 − 2 * 0.05) = 0.9.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch07.xhtml#ch01fn11-marker)) 要了解原因，请注意，如果您有一个90%的置信区间，那么每一侧将有5%的值保留在外面，因为（1
    − 0.9）/ 2 = 0.05。相反，如果您看到在一个置信区间上有5%的值在一侧，则这是90%的置信区间，因为（1 − 2 * 0.05）= 0.9。
- en: ^([3](ch07.xhtml#ch01fn12-marker)) To be fully accurate, our Bootstrap p-value
    would better be called the Bootstrap achieved significance level (ASL).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch07.xhtml#ch01fn12-marker)) 要完全准确，我们的Bootstrap p值最好称为Bootstrap实现的显著水平（ASL）。
