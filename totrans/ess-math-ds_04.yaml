- en: Chapter 4\. Linear Algebra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Changing gears a little bit, let’s venture away from probability and statistics
    and into linear algebra. Sometimes people confuse linear algebra with basic algebra,
    thinking maybe it has to do with plotting lines using the algebraic function *y*
    = *mx* + *b*. This is why linear algebra probably should have been called “vector
    algebra” or “matrix algebra” because it is much more abstract. Linear systems
    play a role but in a much more metaphysical way.
  prefs: []
  type: TYPE_NORMAL
- en: So, what exactly is linear algebra? Well, *linear algebra* concerns itself with
    linear systems but represents them through vector spaces and matrices. If you
    do not know what a vector or a matrix is, do not worry! We will define and explore
    them in depth. Linear algebra is hugely fundamental to many applied areas of math,
    statistics, operations research, data science, and machine learning. When you
    work with data in any of these areas, you are using linear algebra and perhaps
    you may not even know it.
  prefs: []
  type: TYPE_NORMAL
- en: You can get away with not learning linear algebra for a while, using machine
    learning and statistics libraries that do it all for you. But if you are going
    to get intuition behind these black boxes and be more effective at working with
    data, understanding the fundamentals of linear algebra is inevitable. Linear algebra
    is an enormous topic that can fill thick textbooks, so of course we cannot gain
    total mastery in just one chapter of this book. However, we can learn enough to
    be more comfortable with it and navigate the data science domain effectively.
    There will also be opportunities to apply it in the remaining chapters in this
    book, including Chapters [5](ch05.xhtml#ch05) and [7](ch07.xhtml#ch07).
  prefs: []
  type: TYPE_NORMAL
- en: What Is a Vector?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Simply put, a *vector* is an arrow in space with a specific direction and length,
    often representing a piece of data. It is the central building block of linear
    algebra, including matrices and linear transformations. In its fundamental form,
    it has no concept of location so always imagine its tail starts at the origin
    of a Cartesian plane (0,0).
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-1](#IcpsmEJwfp) shows a vector <math alttext="ModifyingAbove v With
    right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math> that moves
    three steps in the horizontal direction and two steps in the vertical direction.'
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0401](Images/emds_0401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-1\. A simple vector
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To emphasize again, the purpose of the vector is to visually represent a piece
    of data. If you have a data record for the square footage of a house 18,000 square
    feet and its valuation $260,000, we could express that as a vector [18000, 2600000],
    stepping 18,000 steps in the horizontal direction and 260,000 steps in the vertical
    direction.
  prefs: []
  type: TYPE_NORMAL
- en: 'We declare a vector mathematically like this:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr>
    <mtr><mtd><mi>y</mi></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>3</mn></mtd></mtr>
    <mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: We can declare a vector using a simple Python collection, like a Python list
    as shown in [Example 4-1](#BlpnGwdoVc).
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-1\. Declaring a vector in Python using a list
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: However, when we start doing mathematical computations with vectors, especially
    when doing tasks like machine learning, we should probably use the NumPy library
    as it is more efficient than plain Python. You can also use SymPy to perform linear
    algebra operations, and we will use it occasionally in this chapter when decimals
    become inconvenient. However, NumPy is what you will likely use in practice so
    that is what we will mainly stick to.
  prefs: []
  type: TYPE_NORMAL
- en: To declare a vector, you can use NumPy’s `array()` function and then can pass
    a collection of numbers to it as shown in [Example 4-2](#kAgRAsEUac).
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-2\. Declaring a vector in Python using NumPy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Python Is Slow, Its Numerical Libraries Are Not
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is a computationally slow language platform, as it does not compile to
    lower-level machine code and bytecode like Java, C#, C, etc. It is dynamically
    interpreted at runtime. However, Python’s numeric and scientific libraries are
    not slow. Libraries like NumPy are typically written in low-level languages like
    C and C++, hence why they are computationally efficient. Python really acts as
    “glue code” integrating these libraries for your tasks.
  prefs: []
  type: TYPE_NORMAL
- en: A vector has countless practical applications. In physics, a vector is often
    thought of as a direction and magnitude. In math, it is a direction and scale
    on an XY plane, kind of like a movement. In computer science, it is an array of
    numbers storing data. The computer science context is the one we will become the
    most familiar with as data science professionals. However, it is important we
    never forget the visual aspect so we do not think of vectors as esoteric grids
    of numbers. Without a visual understanding, it is almost impossible to grasp many
    fundamental linear algebra concepts like linear dependence and determinants.
  prefs: []
  type: TYPE_NORMAL
- en: Here are some more examples of vectors. In [Figure 4-2](#pHSCTHSSvm) note that
    some of these vectors have negative directions on the X and Y scales. Vectors
    with negative directions will have an impact when we combine them later, essentially
    subtracting rather than adding them together.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0402](Images/emds_0402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-2\. A sampling of different vectors
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Note also vectors can exist on more than two dimensions. Next we declare a
    three-dimensional vector along axes x, y, and z:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="ModifyingAbove v With right-arrow equals Start 3 By 1 Matrix
    1st Row  x 2nd Row  y 3rd Row  z EndMatrix equals Start 3 By 1 Matrix 1st Row  4
    2nd Row  1 3rd Row  2 EndMatrix" display="block"><mrow><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr>
    <mtr><mtd><mi>y</mi></mtd></mtr> <mtr><mtd><mi>z</mi></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>4</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'To create this vector, we are stepping four steps in the x direction, one in
    the y direction, and two in the z direction. Here it is visualized in [Figure 4-3](#JQBuLSITaf).
    Note that we no longer are showing a vector on a two-dimensional grid but rather
    a three-dimensional space with three axes: x, y, and z.'
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0403](Images/emds_0403.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-3\. A three-dimensional vector
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Naturally, we can express this three-dimensional vector in Python using three
    numeric values, as declared in [Example 4-3](#eQMUWBhCIB).
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-3\. Declaring a three-dimensional vector in Python using NumPy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Like many mathematical models, visualizing more than three dimensions is challenging
    and something we will not expend energy doing in this book. But numerically, it
    is still straightforward. [Example 4-4](#onWRdWVGdW) shows how we declare a five-dimensional
    vector mathematically in Python.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="ModifyingAbove v With right-arrow equals Start 5 By 1 Matrix
    1st Row  6 2nd Row  1 3rd Row  5 4th Row  8 5th Row  3 EndMatrix" display="block"><mrow><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover> <mo>=</mo> <mfenced separators=""
    open="[" close="]"><mtable><mtr><mtd><mn>6</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>5</mn></mtd></mtr> <mtr><mtd><mn>8</mn></mtd></mtr> <mtr><mtd><mn>3</mn></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-4\. Declaring a five-dimensional vector in Python using NumPy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Adding and Combining Vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On their own, vectors are not terribly interesting. You express a direction
    and size, kind of like a movement in space. But when you start combining vectors,
    known as *vector addition*, it starts to get interesting. We effectively combine
    the movements of two vectors into a single vector.
  prefs: []
  type: TYPE_NORMAL
- en: Say we have two vectors <math alttext="ModifyingAbove v With right-arrow"><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover></math> and <math alttext="ModifyingAbove
    w With right-arrow"><mover accent="true"><mi>w</mi> <mo>→</mo></mover></math>
    as shown in [Figure 4-4](#NDAOFFKCBg). How do we add these two vectors together?
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0404](Images/emds_0404.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-4\. Adding two vectors together
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We will get to why adding vectors is useful in a moment. But if we wanted to
    combine these two vectors, including their direction and scale, what would that
    look like? Numerically, this is straightforward. You simply add the respective
    x-values and then the y-values into a new vector as shown in [Example 4-5](#bvfoUpUGnc).
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>3</mn></mtd></mtr>
    <mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover
    accent="true"><mi>w</mi> <mo>→</mo></mover> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>2</mn></mtd></mtr>
    <mtr><mtd><mrow><mo>-</mo> <mn>1</mn></mrow></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover> <mo>+</mo> <mover accent="true"><mi>w</mi>
    <mo>→</mo></mover> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mn>3</mn>
    <mo>+</mo> <mn>2</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mn>2</mn> <mo>+</mo>
    <mo>-</mo> <mn>1</mn></mrow></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced
    open="[" close="]"><mtable><mtr><mtd><mn>5</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-5\. Adding two vectors in Python using NumPy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: But what does this mean visually? To visually add these two vectors together,
    connect one vector after the other and walk to the tip of the last vector ([Figure 4-5](#jHAeQufeOr)).
    The point you end at is a new vector, the result of summing the two vectors.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0405](Images/emds_0405.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-5\. Adding two vectors into a new vector
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As seen in [Figure 4-5](#jHAeQufeOr), when we walk to the end of the last vector
    <math alttext="ModifyingAbove w With right-arrow"><mover accent="true"><mi>w</mi>
    <mo>→</mo></mover></math> we end up with a new vector [5, 1]. This new vector
    is the result of summing <math alttext="ModifyingAbove v With right-arrow"><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover></math> and <math alttext="ModifyingAbove
    w With right-arrow"><mover accent="true"><mi>w</mi> <mo>→</mo></mover></math>
    . In practice, this can be simply adding data together. If we were totaling housing
    values and their square footage in an area, we would be adding several vectors
    into a single vector in this manner.
  prefs: []
  type: TYPE_NORMAL
- en: Note that it does not matter whether we add <math alttext="ModifyingAbove v
    With right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math> before
    <math alttext="ModifyingAbove w With right-arrow"><mover accent="true"><mi>w</mi>
    <mo>→</mo></mover></math> or vice versa, which means it is *commutative* and order
    of operation does not matter. If we walk <math alttext="ModifyingAbove w With
    right-arrow"><mover accent="true"><mi>w</mi> <mo>→</mo></mover></math> before
    <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover></math> we end up with the same resulting vector [5, 1] as visualized
    in [Figure 4-6](#CvgeFbUEet).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0406](Images/emds_0406.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-6\. Adding vectors is commutative
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Scaling Vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Scaling* is growing or shrinking a vector’s length. You can grow/shrink a
    vector by multiplying or scaling it with a single value, known as a *scalar*.
    [Figure 4-7](#TDiKegoNgG) is vector <math alttext="ModifyingAbove v With right-arrow"><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover></math> being scaled by a factor of
    2, which doubles it.'
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0407](Images/emds_0407.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-7\. Scaling a vector
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Mathematically, you multiply each element of the vector by the scalar value:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>3</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mn>2</mn>
    <mover accent="true"><mi>v</mi> <mo>→</mo></mover> <mo>=</mo> <mn>2</mn> <mfenced
    open="[" close="]"><mtable><mtr><mtd><mn>3</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mn>3</mn> <mo>×</mo>
    <mn>2</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mn>1</mn> <mo>×</mo> <mn>2</mn></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>6</mn></mtd></mtr>
    <mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: Performing this scaling operation in Python is as easy as multiplying a vector
    by the scalar, as coded in [Example 4-6](#bFNICSfEJu).
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-6\. Scaling a number in Python using NumPy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here in [Figure 4-8](#wfUpJAIJuR) <math alttext="ModifyingAbove v With right-arrow"><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover></math> is being scaled down by factor
    of .5, which halves it.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0408](Images/emds_0408.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-8\. Scaling down a vector by half
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: An important detail to note here is that scaling a vector does not change its
    direction, only its magnitude. But there is one slight exception to this rule
    as visualized in [Figure 4-9](#FhcgmMWkaq). When you multiply a vector by a negative
    number, it flips the direction of the vector as shown in the image.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0409](Images/emds_0409.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-9\. A negative scalar flips the vector direction
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When you think about it, though, scaling by a negative number has not really
    changed direction in that it still exists on the same line. This segues to a key
    concept called linear dependence.
  prefs: []
  type: TYPE_NORMAL
- en: Span and Linear Dependence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These two operations, adding two vectors and scaling them, brings about a simple
    but powerful idea. With these two operations, we can combine two vectors and scale
    them to create any resulting vector we want. [Figure 4-10](#RkeRvAFrnW) shows
    six examples of taking two vectors <math alttext="ModifyingAbove v With right-arrow"><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover></math> and <math alttext="ModifyingAbove
    w With right-arrow"><mover accent="true"><mi>w</mi> <mo>→</mo></mover></math>
    , and scaling and combining. These vectors <math alttext="ModifyingAbove v With
    right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math> and <math
    alttext="ModifyingAbove w With right-arrow"><mover accent="true"><mi>w</mi> <mo>→</mo></mover></math>
    , fixed in two different directions, can be scaled and added to create *any* new
    vector <math alttext="ModifyingAbove v plus w With right-arrow"><mover accent="true"><mrow><mi>v</mi><mo>+</mo><mi>w</mi></mrow>
    <mo>→</mo></mover></math> .
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0410](Images/emds_0410.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-10\. Scaling two added vectors allows us to create any new vector
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Again, <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover></math> and <math alttext="ModifyingAbove w With right-arrow"><mover
    accent="true"><mi>w</mi> <mo>→</mo></mover></math> are fixed in direction, except
    for flipping with negative scalars, but we can use scaling to freely create any
    vector composed of <math alttext="ModifyingAbove v plus w With right-arrow"><mover
    accent="true"><mrow><mi>v</mi><mo>+</mo><mi>w</mi></mrow> <mo>→</mo></mover></math>
    .
  prefs: []
  type: TYPE_NORMAL
- en: This whole space of possible vectors is called *span*, and in most cases our
    span can create unlimited vectors off those two vectors, simply by scaling and
    summing them. When we have two vectors in two different directions, they are *linearly
    independent* and have this unlimited span.
  prefs: []
  type: TYPE_NORMAL
- en: But in what case are we limited in the vectors we can create? Think about it
    and read on.
  prefs: []
  type: TYPE_NORMAL
- en: What happens when two vectors exist in the same direction, or exist on the same
    line? The combination of those vectors is also stuck on the same line, limiting
    our span to just that line. No matter how you scale it, the resulting sum vector
    is also stuck on that same line. This makes them *linearly dependent*, as shown
    in [Figure 4-11](#WgWduALDRL).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0411](Images/emds_0411.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-11\. Linearly dependent vectors
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The span here is stuck on the same line as the two vectors it is made out of.
    Because the two vectors exist on the same underlying line, we cannot flexibly
    create any new vector through scaling.
  prefs: []
  type: TYPE_NORMAL
- en: In three or more dimensions, when we have a linearly dependent set of vectors,
    we often get stuck on a plane in a smaller number of dimensions. Here is an example
    of being stuck on a two-dimensional plane even though we have three-dimensional
    vectors as declared in [Figure 4-12](#NqKDEfAlvb).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0412](Images/emds_0412.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-12\. Linear dependence in three dimensions; note our span is limited
    to a flat plane
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Later we will learn a simple tool called the determinant to check for linear
    dependence, but why do we care whether two vectors are linearly dependent or independent?
    A lot of problems become difficult or unsolvable when they are linearly dependent.
    For example, when we learn about systems of equations later in this chapter, a
    linearly dependent set of equations can cause variables to disappear and make
    the problem unsolvable. But if you have linear independence, that flexibility
    to create any vector you need from two or more vectors becomes invaluable to solve
    for a solution!
  prefs: []
  type: TYPE_NORMAL
- en: Linear Transformations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This concept of adding two vectors with fixed direction, but scaling them to
    get different combined vectors, is hugely important. This combined vector, except
    in cases of linear dependence, can point in any direction and have any length
    we choose. This sets up an intuition for linear transformations where we use a
    vector to transform another vector in a function-like manner.
  prefs: []
  type: TYPE_NORMAL
- en: Basis Vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine we have two simple vectors <math alttext="ModifyingAbove i With caret"><mover
    accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math alttext="ModifyingAbove
    j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math> (“i-hat”
    and “j-hat”). These are known as *basis vectors*, which are used to describe transformations
    on other vectors. They typically have a length of 1 and point in perpendicular
    positive directions as visualized in [Figure 4-13](#sEddcHheJh).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0413](Images/emds_0413.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-13\. Basis vectors <math alttext="ModifyingAbove i With caret"><mover
    accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math alttext="ModifyingAbove
    j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math>
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Think of the basis vectors as building blocks to build or transform any vector.
    Our basis vector is expressed in a 2 × 2 matrix, where the first column is <math
    alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math>
    and the second column is <math alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi>
    <mo>^</mo></mover></math> :'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover
    accent="true"><mi>i</mi> <mo>^</mo></mover> <mo>=</mo> <mfenced separators=""
    open="[" close="]"><mtable><mtr><mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover
    accent="true"><mi>j</mi> <mo>^</mo></mover> <mo>=</mo> <mfenced separators=""
    open="[" close="]"><mtable><mtr><mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mtext>basis</mtext>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd></mtr>
    <mtr><mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: A *matrix* is a collection of vectors (such as <math alttext="ModifyingAbove
    i With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math> , <math
    alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math>
    ) that can have multiple rows and columns and is a convenient way to package data.
    We can use <math alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi>
    <mo>^</mo></mover></math> and <math alttext="ModifyingAbove j With caret"><mover
    accent="true"><mi>j</mi> <mo>^</mo></mover></math> to create any vector we want
    by scaling and adding them. Let’s start with each having a length of 1 and showing
    the resulting vector <math alttext="ModifyingAbove v With right-arrow"><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover></math> in [Figure 4-14](#MvKpOBjCEA).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0414](Images/emds_0414.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-14\. Creating a vector from basis vectors
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'I want vector <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover></math> to land at [3, 2]. What happens to <math alttext="ModifyingAbove
    v With right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math>
    if we stretch <math alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi>
    <mo>^</mo></mover></math> by a factor of 3 and <math alttext="ModifyingAbove j
    With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math> by a factor
    of 2? First we scale them individually as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mn>3</mn>
    <mover accent="true"><mi>i</mi> <mo>^</mo></mover> <mo>=</mo> <mn>3</mn> <mfenced
    open="[" close="]"><mtable><mtr><mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>3</mn></mtd></mtr>
    <mtr><mtd><mn>0</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mn>2</mn>
    <mover accent="true"><mi>j</mi> <mo>^</mo></mover> <mo>=</mo> <mn>2</mn> <mfenced
    open="[" close="]"><mtable><mtr><mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>0</mn></mtd></mtr>
    <mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: If we stretched space in these two directions, what does this do to <math alttext="ModifyingAbove
    v With right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math>
    ? Well, it is going to stretch with <math alttext="ModifyingAbove i With caret"><mover
    accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math alttext="ModifyingAbove
    j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math> . This
    is known as a *linear transformation*, where we transform a vector with stretching,
    squishing, sheering, or rotating by tracking basis vector movements. In this case
    ([Figure 4-15](#ioUOiIisaH)), scaling <math alttext="ModifyingAbove i With caret"><mover
    accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math alttext="ModifyingAbove
    j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math> has stretched
    space along with our vector <math alttext="ModifyingAbove v With right-arrow"><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover></math> .
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0415](Images/emds_0415.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-15\. A linear transformation
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'But where does <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover></math> land? It is easy to see where it lands here, which is
    [3, 2]. Recall that vector <math alttext="ModifyingAbove v With right-arrow"><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover></math> is composed of adding <math
    alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math>
    and <math alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi>
    <mo>^</mo></mover></math> . So we simply take the stretched <math alttext="ModifyingAbove
    i With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math
    alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math>
    and add them together to see where vector <math alttext="ModifyingAbove v With
    right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math> has landed:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="ModifyingAbove v With right-arrow Subscript n e w Baseline equals
    StartBinomialOrMatrix 3 Choose 0 EndBinomialOrMatrix plus StartBinomialOrMatrix
    0 Choose 2 EndBinomialOrMatrix equals StartBinomialOrMatrix 3 Choose 2 EndBinomialOrMatrix"
    display="block"><mrow><msub><mover accent="true"><mi>v</mi> <mo>→</mo></mover>
    <mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub> <mo>=</mo> <mfenced open="["
    close="]"><mtable><mtr><mtd><mn>3</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd></mtr></mtable></mfenced>
    <mo>+</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>0</mn></mtd></mtr>
    <mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced open="["
    close="]"><mtable><mtr><mtd><mn>3</mn></mtd></mtr> <mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Generally, with linear transformations, there are four movements you can achieve,
    as shown in [Figure 4-16](#FFQRVdcspb).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0416](Images/emds_0416.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-16\. Four movements can be achieved with linear transformations
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: These four linear transformations are a central part of linear algebra. Scaling
    a vector will stretch or squeeze it. Rotations will turn the vector space, and
    inversions will flip the vector space so that <math alttext="ModifyingAbove i
    With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math
    alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math>
    swap respective places.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that you cannot have transformations that are nonlinear,
    resulting in curvy or squiggly transformations that no longer respect a straight
    line. This is why we call it linear algebra, not nonlinear algebra!
  prefs: []
  type: TYPE_NORMAL
- en: Matrix Vector Multiplication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This brings us to our next big idea in linear algebra. This concept of tracking
    where <math alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi>
    <mo>^</mo></mover></math> and <math alttext="ModifyingAbove j With caret"><mover
    accent="true"><mi>j</mi> <mo>^</mo></mover></math> land after a transformation
    is important because it allows us not just to create vectors but also to transform
    existing vectors. If you want true linear algebra enlightenment, think why creating
    vectors and transforming vectors are actually the same thing. It’s all a matter
    of relativity given your basis vectors being a starting point before and after
    a transformation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula to transform a vector <math alttext="ModifyingAbove v With right-arrow"><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover></math> given basis vectors <math alttext="ModifyingAbove
    i With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math
    alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math>
    packaged as a matrix is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mfenced
    open="[" close="]"><mtable><mtr><mtd><msub><mi>x</mi> <mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mtd></mtr>
    <mtr><mtd><msub><mi>y</mi> <mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>a</mi></mtd> <mtd><mi>b</mi></mtd></mtr>
    <mtr><mtd><mi>c</mi></mtd> <mtd><mi>d</mi></mtd></mtr></mtable></mfenced> <mfenced
    open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr> <mtr><mtd><mi>y</mi></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mfenced
    open="[" close="]"><mtable><mtr><mtd><msub><mi>x</mi> <mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mtd></mtr>
    <mtr><mtd><msub><mi>y</mi> <mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mi>a</mi> <mi>x</mi>
    <mo>+</mo> <mi>b</mi> <mi>y</mi></mrow></mtd></mtr> <mtr><mtd><mrow><mi>c</mi>
    <mi>x</mi> <mo>+</mo> <mi>d</mi> <mi>y</mi></mrow></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi>
    <mo>^</mo></mover></math> is the first column [*a, c*] and <math alttext="ModifyingAbove
    j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math> is the
    column [*b, d*]. We package both of these basis vectors as a matrix, which again
    is a collection of vectors expressed as a grid of numbers in two or more dimensions.
    This transformation of a vector by applying basis vectors is known as *matrix
    vector multiplication*. This may seem contrived at first, but this formula is
    a shortcut for scaling and adding <math alttext="ModifyingAbove i With caret"><mover
    accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math alttext="ModifyingAbove
    j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math> just like
    we did earlier adding two vectors, and applying the transformation to any vector
    <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover></math> .
  prefs: []
  type: TYPE_NORMAL
- en: So in effect, a matrix really is a transformation expressed as basis vectors.
  prefs: []
  type: TYPE_NORMAL
- en: To execute this transformation in Python using NumPy, we will need to declare
    our basis vectors as a matrix and then apply it to vector <math alttext="ModifyingAbove
    v With right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math>
    using the `dot()` operator ([Example 4-7](#CHJGoFdTjq)). The `dot()` operator
    will perform this scaling and addition between our matrix and vector as we just
    described. This is known as the *dot product*, and we will explore it throughout
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-7\. Matrix vector multiplication in NumPy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: When thinking in terms of basis vectors, I prefer to break out the basis vectors
    and then compose them together into a matrix. Just note you will need to *transpose*,
    or swap the columns and rows. This is because NumPy’s `array()` function will
    do the opposite orientation we want, populating each vector as a row rather than
    a column. Transposition in NumPy is demonstrated in [Example 4-8](#RCsLehHkev).
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-8\. Separating the basis vectors and applying them as a transformation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s another example. Let’s start with vector <math alttext="ModifyingAbove
    v With right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math>
    being [2, 1] and <math alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi>
    <mo>^</mo></mover></math> and <math alttext="ModifyingAbove j With caret"><mover
    accent="true"><mi>j</mi> <mo>^</mo></mover></math> start at [1, 0] and [0, 1],
    respectively. We then transform <math alttext="ModifyingAbove i With caret"><mover
    accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math alttext="ModifyingAbove
    j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math> to [2,
    0] and [0, 3]. What happens to vector <math alttext="ModifyingAbove v With right-arrow"><mover
    accent="true"><mi>v</mi> <mo>→</mo></mover></math> ? Working this out mathematically
    by hand using our formula, we get this:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartBinomialOrMatrix x Subscript n e w Baseline Choose y Subscript
    n e w Baseline EndBinomialOrMatrix equals Start 2 By 2 Matrix 1st Row 1st Column
    a 2nd Column b 2nd Row 1st Column c 2nd Column d EndMatrix StartBinomialOrMatrix
    x Choose y EndBinomialOrMatrix equals StartBinomialOrMatrix a x plus b y Choose
    c x plus d y EndBinomialOrMatrix" display="block"><mrow><mfenced open="[" close="]"><mtable><mtr><mtd><msub><mi>x</mi>
    <mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mtd></mtr> <mtr><mtd><msub><mi>y</mi>
    <mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>a</mi></mtd> <mtd><mi>b</mi></mtd></mtr>
    <mtr><mtd><mi>c</mi></mtd> <mtd><mi>d</mi></mtd></mtr></mtable></mfenced> <mfenced
    open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr> <mtr><mtd><mi>y</mi></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mi>a</mi> <mi>x</mi>
    <mo>+</mo> <mi>b</mi> <mi>y</mi></mrow></mtd></mtr> <mtr><mtd><mrow><mi>c</mi>
    <mi>x</mi> <mo>+</mo> <mi>d</mi> <mi>y</mi></mrow></mtd></mtr></mtable></mfenced></mrow></math><math
    alttext="StartBinomialOrMatrix x Subscript n e w Baseline Choose y Subscript n
    e w Baseline EndBinomialOrMatrix equals Start 2 By 2 Matrix 1st Row 1st Column
    2 2nd Column 0 2nd Row 1st Column 0 2nd Column 3 EndMatrix StartBinomialOrMatrix
    2 Choose 1 EndBinomialOrMatrix equals StartBinomialOrMatrix left-parenthesis 2
    right-parenthesis left-parenthesis 2 right-parenthesis plus left-parenthesis 0
    right-parenthesis left-parenthesis 1 right-parenthesis Choose left-parenthesis
    2 right-parenthesis left-parenthesis 0 right-parenthesis plus left-parenthesis
    3 right-parenthesis left-parenthesis 1 right-parenthesis EndBinomialOrMatrix equals
    StartBinomialOrMatrix 4 Choose 3 EndBinomialOrMatrix" display="block"><mrow><mfenced
    open="[" close="]"><mtable><mtr><mtd><msub><mi>x</mi> <mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mtd></mtr>
    <mtr><mtd><msub><mi>y</mi> <mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>2</mn></mtd> <mtd><mn>0</mn></mtd></mtr>
    <mtr><mtd><mn>0</mn></mtd> <mtd><mn>3</mn></mtd></mtr></mtable></mfenced> <mfenced
    open="[" close="]"><mtable><mtr><mtd><mn>2</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mo>(</mo> <mn>2</mn>
    <mo>)</mo> <mo>(</mo> <mn>2</mn> <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>0</mn> <mo>)</mo>
    <mo>(</mo> <mn>1</mn> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mo>(</mo>
    <mn>2</mn> <mo>)</mo> <mo>(</mo> <mn>0</mn> <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>3</mn>
    <mo>)</mo> <mo>(</mo> <mn>1</mn> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>4</mn></mtd></mtr>
    <mtr><mtd><mn>3</mn></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 4-9](#glJhkqdFVq) shows this solution in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-9\. Transforming a vector using NumPy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The vector <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover></math> now lands at [4, 3]. [Figure 4-17](#wOOmFvfSph) shows
    what this transformation looks like.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0417](Images/emds_0417.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-17\. A stretching linear transformation
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Here is an example that jumps things up a notch. Let’s take vector <math alttext="ModifyingAbove
    v With right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math>
    of value [2, 1]. <math alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi>
    <mo>^</mo></mover></math> and <math alttext="ModifyingAbove j With caret"><mover
    accent="true"><mi>j</mi> <mo>^</mo></mover></math> start at [1, 0] and [0, 1],
    but then are transformed and land at [2, 3] and [2, -1]. What happens to <math
    alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math>
    ? Let’s look in [Figure 4-18](#BFAJsJbkfa) and [Example 4-10](#JcsfGNwpLU).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0418](Images/emds_0418.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-18\. A linear transformation that does a rotation, shear, and flipping
    of space
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Example 4-10\. A more complicated transformation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: A lot has happened here. Not only did we scale <math alttext="ModifyingAbove
    i With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math
    alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math>
    and elongate vector <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover></math> . We actually sheared, rotated, and flipped space, too.
    You know space was flipped when <math alttext="ModifyingAbove i With caret"><mover
    accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math alttext="ModifyingAbove
    j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math> change
    places in their clockwise orientation, and we will learn how to detect this with
    determinants later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix Multiplication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We learned how to multiply a vector and a matrix, but what exactly does multiplying
    two matrices accomplish? Think of *matrix multiplication* as applying multiple
    transformations to a vector space. Each transformation is like a function, where
    we apply the innermost first and then apply each subsequent transformation outward.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how we apply a rotation and then a shear to any vector <math alttext="ModifyingAbove
    v With right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math>
    with value [*x, y*]:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="Start 2 By 2 Matrix 1st Row 1st Column 1 2nd Column 1 2nd Row
    1st Column 0 2nd Column 1 EndMatrix Start 2 By 2 Matrix 1st Row 1st Column 0 2nd
    Column negative 1 2nd Row 1st Column 1 2nd Column 0 EndMatrix StartBinomialOrMatrix
    x Choose y EndBinomialOrMatrix" display="block"><mrow><mfenced open="[" close="]"><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced>
    <mfenced open="[" close="]"><mtable><mtr><mtd><mn>0</mn></mtd> <mtd><mrow><mo>-</mo>
    <mn>1</mn></mrow></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd></mtr></mtable></mfenced>
    <mfenced open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr> <mtr><mtd><mi>y</mi></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'We can actually consolidate these two transformations by using this formula,
    applying one transformation onto the last. You multiply and add each row from
    the first matrix to each respective column of the second matrix, in an “over-and-down!
    over-and-down!” pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="Start 2 By 2 Matrix 1st Row 1st Column a 2nd Column b 2nd Row
    1st Column c 2nd Column d EndMatrix Start 2 By 2 Matrix 1st Row 1st Column e 2nd
    Column f 2nd Row 1st Column g 2nd Column h EndMatrix equals Start 2 By 2 Matrix
    1st Row 1st Column a e plus b g 2nd Column a f plus b h 2nd Row 1st Column c e
    plus d y 2nd Column c f plus d h EndMatrix" display="block"><mrow><mfenced open="["
    close="]"><mtable><mtr><mtd><mi>a</mi></mtd> <mtd><mi>b</mi></mtd></mtr> <mtr><mtd><mi>c</mi></mtd>
    <mtd><mi>d</mi></mtd></mtr></mtable></mfenced> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>e</mi></mtd>
    <mtd><mi>f</mi></mtd></mtr> <mtr><mtd><mi>g</mi></mtd> <mtd><mi>h</mi></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mi>a</mi> <mi>e</mi>
    <mo>+</mo> <mi>b</mi> <mi>g</mi></mrow></mtd> <mtd><mrow><mi>a</mi> <mi>f</mi>
    <mo>+</mo> <mi>b</mi> <mi>h</mi></mrow></mtd></mtr> <mtr><mtd><mrow><mi>c</mi>
    <mi>e</mi> <mo>+</mo> <mi>d</mi> <mi>y</mi></mrow></mtd> <mtd><mrow><mi>c</mi>
    <mi>f</mi> <mo>+</mo> <mi>d</mi> <mi>h</mi></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'So we can actually consolidate these two separate transformations (rotation
    and shear) into a single transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mfenced
    open="[" close="]"><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced> <mfenced
    open="[" close="]"><mtable><mtr><mtd><mn>0</mn></mtd> <mtd><mrow><mo>-</mo> <mn>1</mn></mrow></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd></mtr></mtable></mfenced> <mfenced
    open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr> <mtr><mtd><mi>y</mi></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mo>=</mo>
    <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mo>(</mo> <mn>1</mn> <mo>)</mo>
    <mo>(</mo> <mn>0</mn> <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>1</mn> <mo>)</mo> <mo>(</mo>
    <mn>1</mn> <mo>)</mo></mrow></mtd> <mtd><mrow><mo>(</mo> <mo>-</mo> <mn>1</mn>
    <mo>)</mo> <mo>(</mo> <mn>1</mn> <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>1</mn> <mo>)</mo>
    <mo>(</mo> <mn>0</mn> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mo>(</mo>
    <mn>0</mn> <mo>)</mo> <mo>(</mo> <mn>0</mn> <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>1</mn>
    <mo>)</mo> <mo>(</mo> <mn>1</mn> <mo>)</mo></mrow></mtd> <mtd><mrow><mo>(</mo>
    <mn>0</mn> <mo>)</mo> <mo>(</mo> <mo>-</mo> <mn>1</mn> <mo>)</mo> <mo>+</mo> <mo>(</mo>
    <mn>1</mn> <mo>)</mo> <mo>(</mo> <mn>0</mn> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced>
    <mfenced open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr> <mtr><mtd><mi>y</mi></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mo>=</mo>
    <mfenced open="[" close="]"><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mrow><mo>-</mo>
    <mn>1</mn></mrow></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd></mtr></mtable></mfenced>
    <mfenced open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr> <mtr><mtd><mi>y</mi></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: To execute this in Python using NumPy, you can combine the two matrices simply
    using the `matmul()` or `@` operator ([Example 4-11](#kobdVPLRAh)). We will then
    turn around and use this consolidated tranformation and apply it to a vector [1,
    2].
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-11\. Combining two transformations
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Using `dot()` Versus `matmul()` and `@`
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In general, you want to prefer `matmul()` and its shorthand `@` to combine matrices
    rather than the `dot()` operator in NumPy. The former generally has a preferable
    policy for higher-dimensional matrices and how the elements are broadcasted.
  prefs: []
  type: TYPE_NORMAL
- en: If you like diving into these kinds of implementation details, [this StackOverflow
    question is a good place to start](https://oreil.ly/YX83Q).
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we also could have applied each transformation individually to vector
    <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover></math> and still have gotten the same result. If you replace
    the last line with these three lines applying each transformation, you will still
    get [-1, 1] on that new vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Note that the order you apply each transformation matters! If we apply `transformation1`
    on `transformation2`, we get a different result of [-2, 3] as calculated in [Example 4-12](#IOcCtlSitO).
    So matrix dot products are not commutative, meaning you cannot flip the order
    and expect the same result!
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-12\. Applying the transformations in reverse
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Think of each transformation as a function, and we apply them from the innermost
    to outermost just like nested function calls.
  prefs: []
  type: TYPE_NORMAL
- en: Determinants
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we perform linear transformations, we sometimes “expand” or “squish” space
    and the degree this happens can be helpful. Take a sampled area from the vector
    space in [Figure 4-20](#LvCkMSfcus): what happens to it after we scale <math alttext="ModifyingAbove
    i With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math> and <math
    alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math>
    ?'
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0420](Images/emds_0420.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-20\. A determinant measures how a linear transformation scales an area
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note it increases in area by a factor of 6.0, and this factor is known as a
    *determinant*. Determinants describe how much a sampled area in a vector space
    changes in scale with linear transformations, and this can provide helpful information
    about the transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 4-13](#PAtNLPvfAr) shows how to calculate this determinant in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-13\. Calculating a determinant
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Simple shears and rotations should not affect the determinant, as the area will
    not change. [Figure 4-21](#NKgNjQhHDF) and [Example 4-14](#jglHQIPrRe) shows a
    simple shear and the determinant remains a factor 1.0, showing it is unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0421](Images/emds_0421.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-21\. A simple shear does not change the determinant
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Example 4-14\. A determinant for a shear
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: But scaling will increase or decrease the determinant, as that will increase/decrease
    the sampled area. When the orientation flips ( <math alttext="ModifyingAbove i
    With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math> , <math
    alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math>
    swap clockwise positions), then the determinant will be negative. [Figure 4-22](#LgGdleomel)
    and [Example 4-15](#DUDwHbbBQL) illustrate a determinant showing a transformation
    that not only scaled but also flipped the orientation of the vector space.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0422](Images/emds_0422.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-22\. A determinant on a flipped space is negative
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Example 4-15\. A negative determinant
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Because this determinant is negative, we quickly see that the orientation has
    flipped. But by far the most critical piece of information the determinant tells
    you is whether the transformation is linearly dependent. If you have a determinant
    of 0, that means all of the space has been squished into a lesser dimension.
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 4-23](#VBGcgBScmp) we see two linearly dependent transformations,
    where a 2D space is compressed into one dimension and a 3D space is compressed
    into two dimensions. The area and volume respectively in both cases are 0!
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0423](Images/emds_0423.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-23\. Linear dependence in 2D and 3D
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Example 4-16](#gvdhUhSoVO) shows the code for the preceding 2D example squishing
    an entire 2D space into a single one-dimensional number line.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-16\. A determinant of zero
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: So testing for a 0 determinant is highly helpful to determine if a transformation
    has linear dependence. When you encounter this you will likely find a difficult
    or unsolvable problem on your hands.
  prefs: []
  type: TYPE_NORMAL
- en: Special Types of Matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a few notable cases of matrices that we should cover.
  prefs: []
  type: TYPE_NORMAL
- en: Square Matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The *square matrix* is a matrix that has an equal number of rows and columns:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="Start 3 By 3 Matrix 1st Row 1st Column 4 2nd Column 2 3rd Column
    7 2nd Row 1st Column 5 2nd Column 1 3rd Column 9 3rd Row 1st Column 4 2nd Column
    0 3rd Column 1 EndMatrix" display="block"><mfenced separators="" open="[" close="]"><mtable><mtr><mtd><mn>4</mn></mtd>
    <mtd><mn>2</mn></mtd> <mtd><mn>7</mn></mtd></mtr> <mtr><mtd><mn>5</mn></mtd> <mtd><mn>1</mn></mtd>
    <mtd><mn>9</mn></mtd></mtr> <mtr><mtd><mn>4</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></math>
  prefs: []
  type: TYPE_NORMAL
- en: They are primarily used to represent linear transformations and are a requirement
    for many operations like eigendecomposition.
  prefs: []
  type: TYPE_NORMAL
- en: Identity Matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The *identity matrix* is a square matrix that has a diagonal of 1s while the
    other values are 0:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="Start 3 By 3 Matrix 1st Row 1st Column 1 2nd Column 0 3rd Column
    0 2nd Row 1st Column 0 2nd Column 1 3rd Column 0 3rd Row 1st Column 0 2nd Column
    0 3rd Column 1 EndMatrix" display="block"><mfenced separators="" open="[" close="]"><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></math>
  prefs: []
  type: TYPE_NORMAL
- en: What’s the big deal with identity matrices? Well, when you have an identity
    matrix, you essentially have undone a transformation and found your starting basis
    vectors. This will play a big role in solving systems of equations in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Inverse Matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An *inverse matrix* is a matrix that undoes the transformation of another matrix.
    Let’s say I have matrix *A*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper A equals Start 3 By 3 Matrix 1st Row 1st Column 4 2nd Column
    2 3rd Column 4 2nd Row 1st Column 5 2nd Column 3 3rd Column 7 3rd Row 1st Column
    9 2nd Column 3 3rd Column 6 EndMatrix" display="block"><mrow><mi>A</mi> <mo>=</mo>
    <mfenced open="[" close="]"><mtable><mtr><mtd><mn>4</mn></mtd> <mtd><mn>2</mn></mtd>
    <mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>5</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>7</mn></mtd></mtr>
    <mtr><mtd><mn>9</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>6</mn></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The inverse of matrix *A* is called <math alttext="upper A Superscript negative
    1"><msup><mi>A</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math> . We will
    learn how to calculate the inverse using Sympy or NumPy in the next section, but
    this is what the inverse of matrix *A* is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper A Superscript negative 1 Baseline equals Start 3 By 3 Matrix
    1st Row 1st Column negative one-half 2nd Column 0 3rd Column one-third 2nd Row
    1st Column 5.5 2nd Column negative 2 3rd Column four-thirds 3rd Row 1st Column
    negative 2 2nd Column 1 3rd Column one-third EndMatrix" display="block"><mrow><msup><mi>A</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mo>-</mo>
    <mfrac><mn>1</mn> <mn>2</mn></mfrac></mrow></mtd> <mtd><mn>0</mn></mtd> <mtd><mfrac><mn>1</mn>
    <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd><mrow><mn>5</mn> <mo>.</mo> <mn>5</mn></mrow></mtd>
    <mtd><mrow><mo>-</mo> <mn>2</mn></mrow></mtd> <mtd><mfrac><mn>4</mn> <mn>3</mn></mfrac></mtd></mtr>
    <mtr><mtd><mrow><mo>-</mo> <mn>2</mn></mrow></mtd> <mtd><mn>1</mn></mtd> <mtd><mfrac><mn>1</mn>
    <mn>3</mn></mfrac></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: When we perform matrix multiplication between <math alttext="upper A Superscript
    negative 1"><msup><mi>A</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math> and
    *A*, we end up with an identity matrix. We will see this in action with NumPy
    and Sympy in the next section on systems of equations.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="Start 3 By 3 Matrix 1st Row 1st Column negative one-half 2nd
    Column 0 3rd Column one-third 2nd Row 1st Column 5.5 2nd Column negative 2 3rd
    Column four-thirds 3rd Row 1st Column negative 2 2nd Column 1 3rd Column one-third
    EndMatrix Start 3 By 3 Matrix 1st Row 1st Column 4 2nd Column 2 3rd Column 4 2nd
    Row 1st Column 5 2nd Column 3 3rd Column 7 3rd Row 1st Column 9 2nd Column 3 3rd
    Column 6 EndMatrix equals Start 3 By 3 Matrix 1st Row 1st Column 1 2nd Column
    0 3rd Column 0 2nd Row 1st Column 0 2nd Column 1 3rd Column 0 3rd Row 1st Column
    0 2nd Column 0 3rd Column 1 EndMatrix" display="block"><mrow><mfenced open="["
    close="]"><mtable><mtr><mtd><mrow><mo>-</mo> <mfrac><mn>1</mn> <mn>2</mn></mfrac></mrow></mtd>
    <mtd><mn>0</mn></mtd> <mtd><mfrac><mn>1</mn> <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd><mrow><mn>5</mn>
    <mo>.</mo> <mn>5</mn></mrow></mtd> <mtd><mrow><mo>-</mo> <mn>2</mn></mrow></mtd>
    <mtd><mfrac><mn>4</mn> <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd><mrow><mo>-</mo>
    <mn>2</mn></mrow></mtd> <mtd><mn>1</mn></mtd> <mtd><mfrac><mn>1</mn> <mn>3</mn></mfrac></mtd></mtr></mtable></mfenced>
    <mfenced open="[" close="]"><mtable><mtr><mtd><mn>4</mn></mtd> <mtd><mn>2</mn></mtd>
    <mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>5</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>7</mn></mtd></mtr>
    <mtr><mtd><mn>9</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>6</mn></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced separators="" open="[" close="]"><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Diagonal Matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to the identity matrix is the *diagonal matrix*, which has a diagonal
    of nonzero values while the rest of the values are 0\. Diagonal matrices are desirable
    in certain computations because they represent simple scalars being applied to
    a vector space. It shows up in some linear algebra operations.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="Start 3 By 3 Matrix 1st Row 1st Column 4 2nd Column 0 3rd Column
    0 2nd Row 1st Column 0 2nd Column 2 3rd Column 0 3rd Row 1st Column 0 2nd Column
    0 3rd Column 5 EndMatrix" display="block"><mfenced separators="" open="[" close="]"><mtable><mtr><mtd><mn>4</mn></mtd>
    <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>2</mn></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>5</mn></mtd></mtr></mtable></mfenced></math>
  prefs: []
  type: TYPE_NORMAL
- en: Triangular Matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to the diagonal matrix is the *triangular matrix*, which has a diagonal
    of nonzero values in front of a triangle of values, while the rest of the values
    are 0.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="Start 3 By 3 Matrix 1st Row 1st Column 4 2nd Column 2 3rd Column
    9 2nd Row 1st Column 0 2nd Column 1 3rd Column 6 3rd Row 1st Column 0 2nd Column
    0 3rd Column 5 EndMatrix" display="block"><mfenced separators="" open="[" close="]"><mtable><mtr><mtd><mn>4</mn></mtd>
    <mtd><mn>2</mn></mtd> <mtd><mn>9</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd>
    <mtd><mn>6</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>5</mn></mtd></mtr></mtable></mfenced></math>
  prefs: []
  type: TYPE_NORMAL
- en: Triangular matrices are desirable in many numerical analysis tasks, because
    they typically are easier to solve in systems of equations. They also show up
    in certain decomposition tasks like [LU Decomposition](https://oreil.ly/vYK8t).
  prefs: []
  type: TYPE_NORMAL
- en: Sparse Matrix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Occasionally, you will run into matrices that are mostly zeroes and have very
    few nonzero elements. These are called *sparse matrices*. From a pure mathematical
    standpoint, they are not terribly interesting. But from a computing standpoint,
    they provide opportunities to create efficiency. If a matrix has mostly 0s, a
    sparse matrix implementation will not waste space storing a bunch of 0s, and instead
    only keep track of the cells that are nonzero.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sparse colon Start 4 By 3 Matrix 1st Row 1st Column 0 2nd Column
    0 3rd Column 0 2nd Row 1st Column 0 2nd Column 0 3rd Column 2 3rd Row 1st Column
    0 2nd Column 0 3rd Column 0 4th Row 1st Column 0 2nd Column 0 3rd Column 0 EndMatrix"
    display="block"><mrow><mtext>sparse:</mtext> <mfenced separators="" open="[" close="]"><mtable><mtr><mtd><mn>0</mn></mtd>
    <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd>
    <mtd><mn>2</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd></mtr>
    <mtr><mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: When you have large matrices that are sparse, you might explicitly use a sparse
    function to create your matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Systems of Equations and Inverse Matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the basic use cases for linear algebra is solving systems of equations.
    It is also a good application to learn about inverse matrices. Let’s say you are
    provided with the following equations and you need to solve for *x*, *y*, and
    *z*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mn>4</mn> <mi>x</mi> <mo>+</mo> <mn>2</mn> <mi>y</mi>
    <mo>+</mo> <mn>4</mn> <mi>z</mi> <mo>=</mo> <mn>44</mn></mrow></math> <math display="block"><mrow><mn>5</mn>
    <mi>x</mi> <mo>+</mo> <mn>3</mn> <mi>y</mi> <mo>+</mo> <mn>7</mn> <mi>z</mi> <mo>=</mo>
    <mn>56</mn></mrow></math> <math display="block"><mrow><mn>9</mn> <mi>x</mi> <mo>+</mo>
    <mn>3</mn> <mi>y</mi> <mo>+</mo> <mn>6</mn> <mi>z</mi> <mo>=</mo> <mn>72</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'You can try manually experimenting with different algebraic operations to isolate
    the three variables, but if you want a computer to solve it you will need to express
    this problem in terms of matrices as shown next. Extract the coefficients into
    matrix *A*, the values on the right side of the equation into matrix *B*, and
    the unknown variables into matrix *X*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>A</mi>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>4</mn></mtd> <mtd><mn>2</mn></mtd>
    <mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>5</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>7</mn></mtd></mtr>
    <mtr><mtd><mn>9</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>6</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>B</mi>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>44</mn></mtd></mtr>
    <mtr><mtd><mn>56</mn></mtd></mtr> <mtr><mtd><mn>72</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>X</mi>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr>
    <mtr><mtd><mi>y</mi></mtd></mtr> <mtr><mtd><mi>z</mi></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The function for a linear system of equations is *AX* = *B*. We need to transform
    matrix *A* with some other matrix *X* that will result in matrix *B*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>A</mi>
    <mi>X</mi> <mo>=</mo> <mi>B</mi></mrow></mtd></mtr></mtable></math> <math display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><mfenced open="[" close="]"><mtable><mtr><mtd><mn>4</mn></mtd>
    <mtd><mn>2</mn></mtd> <mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>5</mn></mtd> <mtd><mn>3</mn></mtd>
    <mtd><mn>7</mn></mtd></mtr> <mtr><mtd><mn>9</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>6</mn></mtd></mtr></mtable></mfenced>
    <mo>·</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr>
    <mtr><mtd><mi>y</mi></mtd></mtr> <mtr><mtd><mi>z</mi></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>44</mn></mtd></mtr>
    <mtr><mtd><mn>56</mn></mtd></mtr> <mtr><mtd><mn>72</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to “undo” *A* so we can isolate *X* and get the values for *x*, *y*,
    and *z*. The way you undo *A* is to take the inverse of *A* denoted by <math alttext="upper
    A Superscript negative 1"><msup><mi>A</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    and apply it to *A* via matrix multiplication. We can express this algebraically:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>A</mi> <mi>X</mi> <mo>=</mo> <mi>B</mi></mrow></math>
    <math display="block"><mrow><msup><mi>A</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mi>A</mi> <mi>X</mi> <mo>=</mo> <msup><mi>A</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mi>B</mi></mrow></math> <math display="block"><mrow><mi>X</mi> <mo>=</mo> <msup><mi>A</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>B</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'To calculate the inverse of matrix *A*, we probably use a computer rather than
    searching for solutions by hand using Gaussian elimination, which we will not
    venture into in this book. Here is the inverse of matrix *A*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper A Superscript negative 1 Baseline equals Start 3 By 3 Matrix
    1st Row 1st Column negative one-half 2nd Column 0 3rd Column one-third 2nd Row
    1st Column 5.5 2nd Column negative 2 3rd Column four-thirds 3rd Row 1st Column
    negative 2 2nd Column 1 3rd Column one-third EndMatrix" display="block"><mrow><msup><mi>A</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mo>-</mo>
    <mfrac><mn>1</mn> <mn>2</mn></mfrac></mrow></mtd> <mtd><mn>0</mn></mtd> <mtd><mfrac><mn>1</mn>
    <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd><mrow><mn>5</mn> <mo>.</mo> <mn>5</mn></mrow></mtd>
    <mtd><mrow><mo>-</mo> <mn>2</mn></mrow></mtd> <mtd><mfrac><mn>4</mn> <mn>3</mn></mfrac></mtd></mtr>
    <mtr><mtd><mrow><mo>-</mo> <mn>2</mn></mrow></mtd> <mtd><mn>1</mn></mtd> <mtd><mfrac><mn>1</mn>
    <mn>3</mn></mfrac></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Note when we matrix multiply <math alttext="upper A Superscript negative 1"><msup><mi>A</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup></math> against *A* it will create an
    identity matrix, a matrix of all zeroes except for 1s in the diagonal. The identity
    matrix is the linear algebra equivalent of multiplying by 1, meaning it essentially
    has no effect and will effectively isolate values for *x*, *y*, and *z*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>A</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mrow><mo>-</mo>
    <mfrac><mn>1</mn> <mn>2</mn></mfrac></mrow></mtd> <mtd><mn>0</mn></mtd> <mtd><mfrac><mn>1</mn>
    <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd><mrow><mn>5</mn> <mo>.</mo> <mn>5</mn></mrow></mtd>
    <mtd><mrow><mo>-</mo> <mn>2</mn></mrow></mtd> <mtd><mfrac><mn>4</mn> <mn>3</mn></mfrac></mtd></mtr>
    <mtr><mtd><mrow><mo>-</mo> <mn>2</mn></mrow></mtd> <mtd><mn>1</mn></mtd> <mtd><mfrac><mn>1</mn>
    <mn>3</mn></mfrac></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>A</mi>
    <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mn>4</mn></mtd> <mtd><mn>2</mn></mtd>
    <mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>5</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>7</mn></mtd></mtr>
    <mtr><mtd><mn>9</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>6</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>A</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>A</mi> <mo>=</mo> <mfenced open="["
    close="]"><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd></mtr>
    <mtr><mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd>
    <mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: To see this identity matrix in action in Python, you will want to use SymPy
    instead of NumPy. The floating point decimals in NumPy will not make the identity
    matrix as obvious, but doing it symbolically in [Example 4-17](#chOOTGrRCm) we
    will see a clean, symbolic output. Note that to do matrix multiplication in SymPy
    we use the asterisk *** rather than *@*.
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-17\. Using SymPy to study the inverse and identity matrix
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In practice, the lack of floating point precision will not affect our answers
    too badly, so using NumPy should be fine to solve for *x*. [Example 4-18](#wqpBKiRBAT)
    shows a solution with NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-18\. Using NumPy to solve a system of equations
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: So *x* = 2, *y* = 34, and *z* = –8\. [Example 4-19](#dpclnceGpV) shows the full
    solution in SymPy as an alternative to NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-19\. Using SymPy to solve a system of equations
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the solution in mathematical notation:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>A</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>B</mi> <mo>=</mo> <mi>X</mi></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mfenced
    open="[" close="]"><mtable><mtr><mtd><mrow><mo>-</mo> <mfrac><mn>1</mn> <mn>2</mn></mfrac></mrow></mtd>
    <mtd><mn>0</mn></mtd> <mtd><mfrac><mn>1</mn> <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd><mrow><mn>5</mn>
    <mo>.</mo> <mn>5</mn></mrow></mtd> <mtd><mrow><mo>-</mo> <mn>2</mn></mrow></mtd>
    <mtd><mfrac><mn>4</mn> <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd><mrow><mo>-</mo>
    <mn>2</mn></mrow></mtd> <mtd><mn>1</mn></mtd> <mtd><mfrac><mn>1</mn> <mn>3</mn></mfrac></mtd></mtr></mtable></mfenced>
    <mfenced open="[" close="]"><mtable><mtr><mtd><mn>44</mn></mtd></mtr> <mtr><mtd><mn>56</mn></mtd></mtr>
    <mtr><mtd><mn>72</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced open="["
    close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr> <mtr><mtd><mi>y</mi></mtd></mtr>
    <mtr><mtd><mi>z</mi></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mfenced
    open="[" close="]"><mtable><mtr><mtd><mn>2</mn></mtd></mtr> <mtr><mtd><mn>34</mn></mtd></mtr>
    <mtr><mtd><mrow><mo>-</mo> <mn>8</mn></mrow></mtd></mtr></mtable></mfenced> <mo>=</mo>
    <mfenced open="[" close="]"><mtable><mtr><mtd><mi>x</mi></mtd></mtr> <mtr><mtd><mi>y</mi></mtd></mtr>
    <mtr><mtd><mi>z</mi></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, this gave you an intuition for inverse matrices and how they can
    be used to solve a system of equations.
  prefs: []
  type: TYPE_NORMAL
- en: Systems of Equations in Linear Programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This method of solving systems of equations is used for linear programming as
    well, where inequalities define constraints and an objective is minimized/maximized.
  prefs: []
  type: TYPE_NORMAL
- en: '[PatrickJMT has a lot of good videos on Linear Programming](https://bit.ly/3aVyrD6).
    We also cover it briefly in [Appendix A](app01.xhtml#appendix).'
  prefs: []
  type: TYPE_NORMAL
- en: In practicality, you should rarely find it necessary to calculate inverse matrices
    by hand and can have a computer do it for you. But if you have a need or are curious,
    you will want to learn about Gaussian elimination. [PatrickJMT on YouTube](https://oreil.ly/RfXAv)
    has a number of videos demonstrating Gaussian elimination.
  prefs: []
  type: TYPE_NORMAL
- en: Eigenvectors and Eigenvalues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Matrix decomposition* is breaking up a matrix into its basic components, much
    like factoring numbers (e.g., 10 can be factored to 2 × 5).'
  prefs: []
  type: TYPE_NORMAL
- en: Matrix decomposition is helpful for tasks like finding inverse matrices and
    calculating determinants, as well as linear regression. There are many ways to
    decompose a matrix depending on your task. In [Chapter 5](ch05.xhtml#ch05) we
    will use a matrix decomposition technique, QR decomposition, to perform a linear
    regression.
  prefs: []
  type: TYPE_NORMAL
- en: But in this chapter let’s focus on a common method called eigendecomposition,
    which is often used for machine learning and principal component analysis. At
    this level we do not have the bandwidth to dive into each of these applications.
    For now, just know eigendecomposition is helpful for breaking up a matrix into
    components that are easier to work with in different machine learning tasks. Note
    also it only works on square matrices.
  prefs: []
  type: TYPE_NORMAL
- en: 'In eigendecomposition, there are two components: the eigenvalues denoted by
    lambda <math alttext="lamda"><mi>λ</mi></math> and eigenvector by *v* shown in
    [Figure 4-24](#mFUgimEtDa).'
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0424](Images/emds_0424.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-24\. The eigenvector and eigenvalues
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If we have a square matrix *A*, it has the following eigenvalue equation:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper A v equals lamda v dollar-sign"><mrow><mi>A</mi>
    <mi>v</mi> <mo>=</mo> <mi>λ</mi> <mi>v</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: If *A* is the original matrix, it is composed of eigenvector <math alttext="v"><mi>v</mi></math>
    and eigenvalue <math alttext="lamda"><mi>λ</mi></math> . There is one eigenvector
    and eigenvalue for each dimension of the parent matrix, and not all matrices can
    be decomposed into an eigenvector and eigenvalue. Sometimes complex (imaginary)
    numbers will even result.
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 4-20](#QVjawvbekH) is how we calculate eigenvectors and eigenvalues
    in NumPy for a given matrix <math alttext="upper A"><mi>A</mi></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-20\. Performing eigendecomposition in NumPy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'So how do we rebuild matrix *A* from the eigenvectors and eigenvalues? Recall
    this formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper A v equals lamda v dollar-sign"><mrow><mi>A</mi>
    <mi>v</mi> <mo>=</mo> <mi>λ</mi> <mi>v</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to make a few tweaks to the formula to reconstruct *A*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper A equals upper Q normal upper Lamda upper Q
    Superscript negative 1 dollar-sign"><mrow><mi>A</mi> <mo>=</mo> <mi>Q</mi> <mi>Λ</mi>
    <msup><mi>Q</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: In this new formula, <math alttext="upper Q"><mi>Q</mi></math> is the eigenvectors,
    <math alttext="normal upper Lamda"><mi>Λ</mi></math> is the eigenvalues in diagonal
    form, and <math alttext="upper Q Superscript negative 1"><msup><mi>Q</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    is the inverse matrix of <math alttext="upper Q"><mi>Q</mi></math> . Diagonal
    form means the vector is padded into a matrix of zeroes and occupies the diagonal
    line in a similar pattern to an identity matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 4-21](#dJbWIrPcEW) brings the example full circle in Python, starting
    with decomposing the matrix and then recomposing it.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 4-21\. Decomposing and recomposing a matrix in NumPy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the matrix we rebuilt is the one we started with.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear algebra can be maddeningly abstract and it is full of mysteries and ideas
    to ponder. You may find the whole topic is one big rabbit hole, and you would
    be right! However, it is a good idea to continue being curious about it if you
    want to have a long, successful data science career. It is the foundation for
    statistical computing, machine learning, and other applied data science areas.
    Ultimately, it is the foundation for computer science in general. You can certainly
    get away with not knowing it for a while but you will encounter limitations in
    your understanding at some point.
  prefs: []
  type: TYPE_NORMAL
- en: You may wonder how these ideas are practical as they may feel theoretical. Do
    not worry; we will see some practical applications throughout this book. But the
    theory and geometric interpretations are important to have intuition when you
    work with data, and by understanding linear transformations visually you are prepared
    to take on more advanced concepts that may be thrown at you later in your pursuits.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to learn more about linear programming, there is no better place
    than [3Blue1Brown’s YouTube playlist “Essence of Linear Algebra”](https://oreil.ly/FSCNz).
    The [linear algebra videos from PatrickJMT](https://oreil.ly/Hx9GP) are helpful
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to get more comfortable with NumPy, the O’Reilly book *Python for
    Data Analysis* (2nd edition) by Wes McKinney is a recommended read. It does not
    focus much on linear algebra, but it does provide practical instruction on using
    NumPy, Pandas, and Python on datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vector <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover></math> has a value of [1, 2] but then a transformation happens.
    <math alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math>
    lands at [2, 0] and <math alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi>
    <mo>^</mo></mover></math> lands at [0, 1.5]. Where does <math alttext="ModifyingAbove
    v With right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math>
    land?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Vector <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>→</mo></mover></math> has a value of [1, 2] but then a transformation happens.
    <math alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi> <mo>^</mo></mover></math>
    lands at [-2, 1] and <math alttext="ModifyingAbove j With caret"><mover accent="true"><mi>j</mi>
    <mo>^</mo></mover></math> lands at [1, -2]. Where does <math alttext="ModifyingAbove
    v With right-arrow"><mover accent="true"><mi>v</mi> <mo>→</mo></mover></math>
    land?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A transformation <math alttext="ModifyingAbove i With caret"><mover accent="true"><mi>i</mi>
    <mo>^</mo></mover></math> lands at [1, 0] and <math alttext="ModifyingAbove j
    With caret"><mover accent="true"><mi>j</mi> <mo>^</mo></mover></math> lands at
    [2, 2]. What is the determinant of this transformation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can two or more linear transformations be done in single linear transformation?
    Why or why not?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Solve the system of equations for *x*, *y*, and *z*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mn>3</mn> <mi>x</mi> <mo>+</mo> <mn>1</mn> <mi>y</mi>
    <mo>+</mo> <mn>0</mn> <mi>z</mi> <mo>=</mo> <mo>=</mo> <mn>54</mn></mrow></math>
    <math display="block"><mrow><mn>2</mn> <mi>x</mi> <mo>+</mo> <mn>4</mn> <mi>y</mi>
    <mo>+</mo> <mn>1</mn> <mi>z</mi> <mo>=</mo> <mn>12</mn></mrow></math> <math display="block"><mrow><mn>3</mn>
    <mi>x</mi> <mo>+</mo> <mn>1</mn> <mi>y</mi> <mo>+</mo> <mn>8</mn> <mi>z</mi> <mo>=</mo>
    <mn>6</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Is the following matrix linearly dependent? Why or why not?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="Start 2 By 2 Matrix 1st Row 1st Column 2 2nd Column 1 2nd Row
    1st Column 6 2nd Column 3 EndMatrix" display="block"><mfenced open="[" close="]"><mtable><mtr><mtd><mn>2</mn></mtd>
    <mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>6</mn></mtd> <mtd><mn>3</mn></mtd></mtr></mtable></mfenced></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers are in [Appendix B](app02.xhtml#exercise_answers).
  prefs: []
  type: TYPE_NORMAL
