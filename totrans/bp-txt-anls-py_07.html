<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 7. How to Explain a Text Classifier"><div class="chapter" id="ch-explain">
<h1><span class="label">Chapter 7. </span>How to Explain a Text Classifier</h1>

<p>In the previous chapters, we have learned a lot about advanced analytical methods for unstructured text data. Starting with statistics and using NLP, we have found interesting insights from text.</p>

<p>Using supervised methods for classification, we have assigned text documents to already-given categories by training algorithms. Although we have checked the quality of the classification process, we have skipped an important aspect: we have no idea <em>why</em> the model has decided to assign a category to a text.</p>

<p>This might sound unimportant if the category was correct. <a contenteditable="false" data-type="indexterm" data-primary="transparency of models" id="idm45634192579240"/>However, in daily life you often have to <em>explain</em> your own decisions and make them <em>transparent</em> to others. The same is true for machine learning algorithms.</p>

<p>In real-life projects, you will more often than not hear the question “Why has the algorithm assigned this category/sentiment?” Even before that, understanding how the algorithm has learned something will help you to improve the classification by using different algorithms, adding features, changing weights, and so on. Compared to structured data, the question is much more important with text as humans can interpret the text itself. Moreover, text has many artifacts such as signatures in emails that you better avoid and make sure that they are not the dominant features in your classification.</p>

<p>In addition to the technological perspective, there are also some legal aspects to keep in mind. You might be responsible for proving that your algorithm is not biased or does not discriminate. The GDPR in the European Union even demands that <span class="keep-together">for algorithms</span> that make decisions (like allowing only certain kinds of payment) on <span class="keep-together">public websites</span>.</p>

<p>Last but not least, trust needs information. If you make your results as transparent as possible, you will enormously increase the confidence and trust that somebody has in your method.</p>

<section data-type="sect1" data-pdf-bookmark="What You’ll Learn and What We’ll Build"><div class="sect1" id="idm45634192573032">
<h1>What You’ll Learn and What We’ll Build</h1>


<p>In this chapter, we will take a look at several methods for explaining the results of a supervised machine learning model. Wherever possible, we will build on classification examples that have been part of the previous chapters.</p>

<p>We will start by revisiting the classification of the bug reports from <a data-type="xref" href="ch06.xhtml#ch-classification">Chapter 6</a>. Some reports were classified correctly, some not. We will take a step back and analyze whether classification is always a binary decision. For some models, it is not, and we will calculate the probabilities of bug reports belonging to a certain class and check with the correct values (the so-called <em>ground</em> <em>truth</em>).</p>

<p>In the next section, we will analyze which features were responsible for the decision of the model. We can calculate this using support vector machines. We will try to interpret the results and see if we can use that knowledge to improve the method.</p>

<p>Afterward, we will take a more general approach and <a contenteditable="false" data-type="indexterm" data-primary="LIME (local interpretable model-agnostic explanations) algorithm" id="idm45634192567416"/>introduce <em>local interpretable model-agnostic explanations</em> (LIME). LIME is (almost) agnostic to the specific machine learning model and can explain the results of many algorithms.</p>

<p>People have been researching explainable AI a lot in recent years and came up with a more sophisticated model called <em>Anchor</em>, which we will present in the last part of this chapter.</p>

<p>After studying this chapter, you will <a contenteditable="false" data-type="indexterm" data-primary="supervised learning models" id="idm45634192564008"/>know different methods for explaining the results of supervised machine learning models. You will be able to use this for your own projects and decide which of the methods is best suited for your specific requirements. You will be able to interpret the results and create intuitive visualizations to make them easily understandable for nonexperts.</p>
</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Determining Classification Confidence Using Prediction Probability"><div class="sect1" id="idm45634192562216">
<h1>Blueprint: Determining Classification Confidence Using Prediction Probability</h1>

<p>You might remember <a contenteditable="false" data-type="indexterm" data-primary="text classification results, explaining" data-secondary="prediction probability for" id="ch7_term4"/><a contenteditable="false" data-type="indexterm" data-primary="prediction probability for explaining classifiers" id="ch7_term2"/><a contenteditable="false" data-type="indexterm" data-primary="probability, prediction" id="ch7_term3"/>the example from <a data-type="xref" href="ch06.xhtml#ch-classification">Chapter 6</a> where we tried to classify the bug reports according to their component. We will now <a contenteditable="false" data-type="indexterm" data-primary="vectorizers/vectorization" data-secondary="with text classification" data-secondary-sortas="text classification" id="idm45634192553704"/>train a support vector machine with the optimal parameters found in that chapter. The rest of the notation stays the same:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">svc</code> <code class="o">=</code> <code class="n">SVC</code><code class="p">(</code><code class="n">kernel</code><code class="o">=</code><code class="s2">"linear"</code><code class="p">,</code> <code class="n">C</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">probability</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">svc</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_tf</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">)</code>
</pre>

<p>If you recall the classification report, we had a <a contenteditable="false" data-type="indexterm" data-primary="precision and recall" id="idm45634192523480"/><a contenteditable="false" data-type="indexterm" data-primary="recall" id="idm45634192522504"/>good average precision and recall of 75%, so the classification worked rather well. But there were some cases where the prediction differed from the actual value. We will try to look at the results of these predictions in more detail now to understand if there is a pattern that we can use to distinguish between “good” and “bad” prediction without taking a look at the actual results as those will be unknown in real classification scenarios.</p>

<p>For this, we will use the <a contenteditable="false" data-type="indexterm" data-primary="predict_proba function" id="idm45634192520200"/>function <code>predict_proba</code> of the support vector machine model, which tells us about <a contenteditable="false" data-type="indexterm" data-primary="SVM (support vector machine) algorithm" id="idm45634192518520"/>the internals of the SVM, namely, the probabilities it calculated for the respective classes (obviously the prediction itself has the highest probability).<sup><a data-type="noteref" id="idm45634192517144-marker" href="ch07.xhtml#idm45634192517144">1</a></sup> As a parameter, it expects a matrix consisting of document vectors. The result is the probability for the different classes. As a first step, we are going to construct a <code>DataFrame</code> from the prediction results:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">X_test_tf</code> <code class="o">=</code> <code class="n">tfidf</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code>
<code class="n">Y_pred</code> <code class="o">=</code> <code class="n">svc</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test_tf</code><code class="p">)</code>
<code class="n">result</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code> <code class="s1">'text'</code><code class="p">:</code> <code class="n">X_test</code><code class="o">.</code><code class="n">values</code><code class="p">,</code> <code class="s1">'actual'</code><code class="p">:</code> <code class="n">Y_test</code><code class="o">.</code><code class="n">values</code><code class="p">,</code>
                        <code class="s1">'predicted'</code><code class="p">:</code> <code class="n">Y_pred</code> <code class="p">})</code>
</pre>

<p>Let’s try it with one document of the test dataset and assume that we want to optimize our classification and are mainly interested in cases where the predictions are wrong:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">result</code><code class="p">[</code><code class="n">result</code><code class="p">[</code><code class="s2">"actual"</code><code class="p">]</code> <code class="o">!=</code> <code class="n">result</code><code class="p">[</code><code class="s2">"predicted"</code><code class="p">]]</code><code class="o">.</code><code class="n">head</code><code class="p">()</code>
</pre>

<p><code>Out:</code></p>

<table class="dataframe">
	<thead>
		<tr>
			<th> </th>
			<th>text</th>
			<th>actual</th>
			<th>predicted</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>2</th>
			<td>NPE in Delta processor while executing JDT/UI ...</td>
			<td>Core</td>
			<td>UI</td>
		</tr>
		<tr>
			<th>15</th>
			<td>Inserting a block of text in editor badly alig...</td>
			<td>UI</td>
			<td>Text</td>
		</tr>
		<tr>
			<th>16</th>
			<td>Differences when debugging identical objects W...</td>
			<td>Debug</td>
			<td>Core</td>
		</tr>
		<tr>
			<th>20</th>
			<td>Foreach template doesnt work for class members...</td>
			<td>Core</td>
			<td>UI</td>
		</tr>
		<tr>
			<th>21</th>
			<td>exchange left and right operands for compariso...</td>
			<td>UI</td>
			<td>Core</td>
		</tr>
	</tbody>
</table>

<p>Document 21 looks like a good candidate. The predicted class “Core” is wrong, but “left” and “right” also sound like UI (which would be correct). Let’s take a deeper look at that:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="n">result</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="mi">21</code><code class="p">][</code><code class="s2">"text"</code><code class="p">]</code>
<code class="k">print</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>

</pre>

<p class="pagebreak-before"><code>Out:</code></p>

<pre data-type="programlisting">
exchange left and right operands for comparison operators changes semantics
Fix for Bug 149803 was not good.; ; The right fix should do the following;
if --&gt; if --&gt; if ; if ; if</pre>

<p>This looks like a good candidate for a more detailed analysis as it contains words that would naively speak for both Core and for UI. Maybe we can understand that in more detail if we look at the probabilities. Calculating this is quite easy:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="err"> </code><code class="n">svc</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">X_test_tf</code><code class="p">[</code><code class="mi">21</code><code class="p">])</code>
</pre>

<p><code>Out:</code></p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">array</code><code class="p">([[</code><code class="mf">0.002669</code><code class="p">,</code> <code class="mf">0.46736578</code><code class="p">,</code> <code class="mf">0.07725225</code><code class="p">,</code> <code class="mf">0.00319434</code><code class="p">,</code> <code class="mf">0.06874877</code><code class="p">,</code>
<code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="mf">0.38076986</code><code class="p">]])</code>
</pre>

<p>Remembering that the classes had the order APT, Core, Debug,  Doc, Text, and UI, the algorithm was a bit more convinced of Core compared to UI, which would have been its second choice.</p>
<p>Is this always the case? We will try to find out and calculate the decision probability for all documents in the test dataset and add it to a <code>DataFrame</code>:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">class_names</code> <code class="o">=</code> <code class="p">[</code><code class="s2">"APT"</code><code class="p">,</code> <code class="s2">"Core"</code><code class="p">,</code> <code class="s2">"Debug"</code><code class="p">,</code> <code class="s2">"Doc"</code><code class="p">,</code> <code class="s2">"Text"</code><code class="p">,</code> <code class="s2">"UI"</code><code class="p">]</code>
<code class="n">prob</code> <code class="o">=</code> <code class="n">svc</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">X_test_tf</code><code class="p">)</code>
<code class="c1"># new dataframe for explainable results</code>
<code class="n">er</code> <code class="o">=</code> <code class="n">result</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code><code class="o">.</code><code class="n">reset_index</code><code class="p">()</code>
<code class="k">for</code> <code class="n">c</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">class_names</code><code class="p">):</code>
<code class="err"> </code> <code class="err"> </code> <code class="n">er</code><code class="p">[</code><code class="n">c</code><code class="p">]</code> <code class="o">=</code> <code class="n">prob</code><code class="p">[:,</code> <code class="n">i</code><code class="p">]</code>
</pre>

<p>Let’s take a look at some samples of the data frame and find out whether the predictions are better if the algorithm was quite convinced about its decision (i.e., the probability for the chosen category was much higher than the others):</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">er</code><code class="p">[[</code><code class="s2">"actual"</code><code class="p">,</code> <code class="s2">"predicted"</code><code class="p">]</code> <code class="o">+</code> <code class="n">class_names</code><code class="p">]</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">5</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">99</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<table class="dataframe">
	<thead>
		<tr>
			<th> </th>
			<th>actual</th>
			<th>predicted</th>
			<th>APT</th>
			<th>Core</th>
			<th>Debug</th>
			<th>Doc</th>
			<th>Text</th>
			<th>UI</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>266</th>
			<td>UI</td>
			<td>UI</td>
			<td>0.000598</td>
			<td>0.000929</td>
			<td>0.000476</td>
			<td>0.001377</td>
			<td>0.224473</td>
			<td>0.772148</td>
		</tr>
		<tr>
			<th>835</th>
			<td>Text</td>
			<td>Text</td>
			<td>0.002083</td>
			<td>0.032109</td>
			<td>0.001481</td>
			<td>0.002085</td>
			<td>0.696666</td>
			<td>0.265577</td>
		</tr>
		<tr>
			<th>998</th>
			<td>Text</td>
			<td>Text</td>
			<td>0.000356</td>
			<td>0.026525</td>
			<td>0.003425</td>
			<td>0.000673</td>
			<td>0.942136</td>
			<td>0.026884</td>
		</tr>
		<tr>
			<th>754</th>
			<td>Core</td>
			<td>Text</td>
			<td>0.003862</td>
			<td>0.334308</td>
			<td>0.011312</td>
			<td>0.015478</td>
			<td>0.492112</td>
			<td>0.142927</td>
		</tr>
		<tr>
			<th>686</th>
			<td>UI</td>
			<td>UI</td>
			<td>0.019319</td>
			<td>0.099088</td>
			<td>0.143744</td>
			<td>0.082969</td>
			<td>0.053174</td>
			<td>0.601705</td>
		</tr>
	</tbody>
</table>

<p>Looking at the table, there is only one wrong prediction (754). In this case, the algorithm was quite “unsure” and decided for the category with a probability of less than 50%.  Can we find a pattern for this?</p>
<p>Let’s try to build two <code>DataFrame</code>s, one with correct and another with wrong predictions. Afterward, we will analyze the distribution of the highest probability and see whether we can find any differences:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">er</code><code class="p">[</code><code class="s1">'max_probability'</code><code class="p">]</code> <code class="o">=</code> <code class="n">er</code><code class="p">[</code><code class="n">class_names</code><code class="p">]</code><code class="o">.</code><code class="n">max</code><code class="p">(</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="n">correct</code> <code class="o">=</code> <code class="p">(</code><code class="n">er</code><code class="p">[</code><code class="n">er</code><code class="p">[</code><code class="s1">'actual'</code><code class="p">]</code> <code class="o">==</code> <code class="n">er</code><code class="p">[</code><code class="s1">'predicted'</code><code class="p">]])</code>
<code class="n">wrong</code><code class="err"> </code> <code class="err"> </code><code class="o">=</code> <code class="p">(</code><code class="n">er</code><code class="p">[</code><code class="n">er</code><code class="p">[</code><code class="s1">'actual'</code><code class="p">]</code> <code class="o">!=</code> <code class="n">er</code><code class="p">[</code><code class="s1">'predicted'</code><code class="p">]])</code>
</pre>

<p>We will now plot this as a histogram:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">correct</code><code class="p">[</code><code class="s2">"max_probability"</code><code class="p">]</code><code class="o">.</code><code class="n">plot</code><code class="o">.</code><code class="n">hist</code><code class="p">(</code><code class="n">title</code><code class="o">=</code><code class="s2">"Correct"</code><code class="p">)</code>
<code class="n">wrong</code><code class="p">[</code><code class="s2">"max_probability"</code><code class="p">]</code><code class="o">.</code><code class="n">plot</code><code class="o">.</code><code class="n">hist</code><code class="p">(</code><code class="n">title</code><code class="o">=</code><code class="s2">"Wrong"</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<figure class="width-75"><div class="figure"><img src="Images/btap_07in01.jpg" width="1442" height="952"/><h6/></div></figure>

<figure class="width-75"><div class="figure"><img src="Images/btap_07in02.jpg" width="1401" height="940"/><h6/></div></figure>

<p>We can see that in the case of correct predictions, the model often decided with high probabilities, whereas the probabilities were considerably lower when the decision was wrong. As we will see later, the small peak in the wrong category with high probability is due to short texts or missing words.</p>

<p>Finally, we will take a look at whether we can improve the results if we only consider decisions that have been made with a probability of more than 80%:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">high</code> <code class="o">=</code> <code class="n">er</code><code class="p">[</code><code class="n">er</code><code class="p">[</code><code class="s2">"max_probability"</code><code class="p">]</code> <code class="o">&gt;</code> <code class="mf">0.8</code><code class="p">]</code>
<code class="k">print</code><code class="p">(</code><code class="n">classification_report</code><code class="p">(</code><code class="n">high</code><code class="p">[</code><code class="s2">"actual"</code><code class="p">],</code> <code class="n">high</code><code class="p">[</code><code class="s2">"predicted"</code><code class="p">]))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
                precision    recall  f1-score   support

         APT       0.90      0.75      0.82        12
        Core       0.94      0.89      0.92       264
       Debug       0.94      0.99      0.96       202
         Doc       1.00      0.67      0.80         3
        Text       0.78      0.75      0.77        72
          UI       0.90      0.92      0.91       342

    accuracy                           0.91       895
   macro avg       0.91      0.83      0.86       895
weighted avg       0.91      0.91      0.91       895
</pre>

<p>Compare this to the original result, shown here:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="k">print</code><code class="p">(</code><code class="n">classification_report</code><code class="p">(</code><code class="n">er</code><code class="p">[</code><code class="s2">"actual"</code><code class="p">],</code> <code class="n">er</code><code class="p">[</code><code class="s2">"predicted"</code><code class="p">]))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
              precision    recall  f1-score   support

         APT       0.90      0.56      0.69        16
        Core       0.76      0.77      0.76       546
       Debug       0.90      0.78      0.84       302
         Doc       1.00      0.25      0.40        12
        Text       0.64      0.51      0.57       236
          UI       0.72      0.82      0.77       699

    accuracy                           0.75      1811
   macro avg       0.82      0.62      0.67      1811
weighted avg       0.75      0.75      0.75      1811
</pre>

<p>We can see that we have considerably improved the <a contenteditable="false" data-type="indexterm" data-primary="precision and recall" id="idm45634191928216"/><a contenteditable="false" data-type="indexterm" data-primary="recall" id="idm45634191927144"/>precision for predicting the components Core, Debug, Text, and UI while at the same time increasing the recall. This is great, as the explanation of the SVM has led us to a smaller subset of data in which the classifier works better. However, in the components with few samples (Apt, Doc), the result has actually only improved the recall. It seems that there are just too few samples in these categories, and the algorithm has too little information to decide based on the text. In the case of Doc, we just removed most of the documents belonging to this class and so increased the recall.</p>

<p>The improvement came with a price, though. We have excluded more than 900 documents, roughly half of the dataset. So, overall, we have actually found fewer documents in the smaller dataset! In some projects, it might be useful to let the model only decide in cases where it is quite “sure” and discard ambiguous cases (or classify them by hand). This often depends on the business requirements.</p>

<p>In this section, we have found a correlation between the predicting probability and the quality of results. However, we have not yet understood how the model predicts (i.e., which words are used). We will analyze this in the <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term2" id="idm45634191923816"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term3" id="idm45634191916936"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term4" id="idm45634191894600"/>next section.</p>
</div></section>

<section data-type="sect1" class="blueprint pagebreak-after" data-pdf-bookmark="Blueprint: Measuring Feature Importance of Predictive Models"><div class="sect1" id="idm45634192560664">
<h1>Blueprint: Measuring Feature Importance of Predictive Models</h1>

<p>In this section, we want to <a contenteditable="false" data-type="indexterm" data-primary="feature importance, predicting" id="ch7_term9"/><a contenteditable="false" data-type="indexterm" data-primary="SVM (support vector machine) algorithm" id="ch7_term10"/><a contenteditable="false" data-type="indexterm" data-primary="coefficients in predictive models" id="ch7_term11"/><a contenteditable="false" data-type="indexterm" data-primary="predictive models, measuring feature importance of" id="ch7_term12"/><a contenteditable="false" data-type="indexterm" data-primary="text classification results, explaining" data-secondary="predictive models, measuring feature importance of" id="ch7_term13"/>find out which features were relevant for the model to find the correct class. Fortunately, our SVM class can tell us the necessary parameters (called <em>coefficients</em>):</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">svc</code><code class="o">.</code><code class="n">coef_</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
&lt;15x6403 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
       with 64451 stored elements in Compressed Sparse Row format&gt;
</pre>

<p>6403 is the size of the vocabulary (check with <code>len(tfidf.get_feature_names()</code>), but where does the 15 originate from? That is a bit more complicated. Technically, the coefficients are organized in a matrix as each class competes against each other in a one-to-one way. As we have six classes and classes do not have to compete against themselves, there are 15 combinations (the binomial coefficient 6 over 2). The 15 coefficients are <a contenteditable="false" data-type="indexterm" data-primary="multiclass classification" id="idm45634191859032"/>organized as described in <a data-type="xref" href="#tab-coefficients">Table 7-1</a>.</p>

<table id="tab-coefficients">
	<caption><span class="label">Table 7-1. </span>Coefficient layout for a multiclass SVC classifier</caption>
	<tbody>
		<tr>
			<th> </th>
			<th>APT</th>
			<th>Core</th>
			<th>Debug</th>
			<th>Doc</th>
			<th>Text</th>
			<th>UI</th>
		</tr>
		<tr>
			<th>APT</th>
			<td> </td>
			<td>0</td>
			<td>1</td>
			<td>2</td>
			<td>3</td>
			<td>4</td>
		</tr>
		<tr>
			<th>Core</th>
			<td> </td>
			<td> </td>
			<td>5</td>
			<td>6</td>
			<td>7</td>
			<td>8</td>
		</tr>
		<tr>
			<th>Debug</th>
			<td> </td>
			<td> </td>
			<td> </td>
			<td>9</td>
			<td>10</td>
			<td>11</td>
		</tr>
		<tr>
			<th>Doc</th>
			<td> </td>
			<td> </td>
			<td> </td>
			<td> </td>
			<td>12</td>
			<td>13</td>
		</tr>
		<tr>
			<th>Text</th>
			<td> </td>
			<td> </td>
			<td> </td>
			<td> </td>
			<td> </td>
			<td>14</td>
		</tr>
		<tr>
			<th>UI</th>
			<td> </td>
			<td> </td>
			<td> </td>
			<td> </td>
			<td> </td>
			<td> </td>
		</tr>
	</tbody>

</table>

<div data-type="warning" epub:type="warning">
<h1>Coefficient Structure Depends on Machine Learning Model</h1>

<p>The coefficients might have a completely different organization if you use other classifiers. Even for SVM, using a nonlinear model (created by SGDClassifier) creates only one coefficient set per class. We will see some examples of this when we talk about ELI5.</p>
</div>

<p>The rows should be read first, so if we want to find out how the model distinguishes APT from Core, we should take index 0 of the coefficients. However, we are more interested in the difference of Core and UI, so we take index 8. In the first step, we sort the coefficients by their values and keep the indices, which are the vocabulary positions:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="c1"># coef_[8] yields a matrix, A[0] converts to array and takes first row</code>
<code class="n">coef</code> <code class="o">=</code> <code class="n">svc</code><code class="o">.</code><code class="n">coef_</code><code class="p">[</code><code class="mi">8</code><code class="p">]</code><code class="o">.</code><code class="n">A</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>
<code class="n">vocabulary_positions</code> <code class="o">=</code> <code class="n">coef</code><code class="o">.</code><code class="n">argsort</code><code class="p">()</code>
<code class="n">vocabulary</code> <code class="o">=</code> <code class="n">tfidf</code><code class="o">.</code><code class="n">get_feature_names</code><code class="p">()</code>
</pre>

<p>Afterward, we now take the top positive and negative contributions:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">top_words</code> <code class="o">=</code> <code class="mi">10</code>
<code class="n">top_positive_coef</code> <code class="o">=</code> <code class="n">vocabulary_positions</code><code class="p">[</code><code class="o">-</code><code class="n">top_words</code><code class="p">:]</code><code class="o">.</code><code class="n">tolist</code><code class="p">()</code>
<code class="n">top_negative_coef</code> <code class="o">=</code> <code class="n">vocabulary_positions</code><code class="p">[:</code><code class="n">top_words</code><code class="p">]</code><code class="o">.</code><code class="n">tolist</code><code class="p">()</code>
</pre>

<p>Then we will aggregate this to a <code>DataFrame</code> to make it easier to display the results:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">core_ui</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">([[</code><code class="n">vocabulary</code><code class="p">[</code><code class="n">c</code><code class="p">],</code>
                  <code class="n">coef</code><code class="p">[</code><code class="n">c</code><code class="p">]]</code> <code class="k">for</code> <code class="n">c</code> <code class="ow">in</code> <code class="n">top_positive_coef</code> <code class="o">+</code> <code class="n">top_negative_coef</code><code class="p">],</code>
      <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s2">"feature"</code><code class="p">,</code> <code class="s2">"coefficient"</code><code class="p">])</code><code class="o">.</code><code class="n">sort_values</code><code class="p">(</code><code class="s2">"coefficient"</code><code class="p">)</code>
</pre>

<p>We would like to visualize the contributions of the coefficients to make it easy to understand. Positive values favor the Core component, and negative values prefer UI, as shown in <a data-type="xref" href="#fig-coefficients-core-ui">Figure 7-1</a>. To obtain this, we use the following:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">core_ui</code><code class="o">.</code><code class="n">set_index</code><code class="p">(</code><code class="s2">"feature"</code><code class="p">)</code><code class="o">.</code><code class="n">plot</code><code class="o">.</code><code class="n">barh</code><code class="p">()</code>
</pre>

<!-- <p><code>Out:</code></p> -->

<p>These results are quite easy to interpret. The SVM model has nicely learned that the words <em>compiler</em> and <em>ast</em> are specific to the Core component, whereas <em>wizard</em>, <em>ui</em>, and <em>dialog</em> are used to identify bugs in the UI component. It seems a quick fix is more popular in the UI, which emphasizes the long-term stability of the core.</p>

<p>We have just found the features that are important for the whole SVM model to choose between Core and UI. But this does not indicate which features are important to identify a bug that can be categorized as Core given any bug report. If we want to get these features for the Core component and consider the previous matrix, we need indices 5, 6, 7, and 8. With this strategy, we have ignored the difference between APT and Core. To take this into account, we need to subtract index 0:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">c</code> <code class="o">=</code> <code class="n">svc</code><code class="o">.</code><code class="n">coef_</code>
<code class="n">coef</code> <code class="o">=</code> <code class="p">(</code><code class="n">c</code><code class="p">[</code><code class="mi">5</code><code class="p">]</code> <code class="o">+</code> <code class="n">c</code><code class="p">[</code><code class="mi">6</code><code class="p">]</code> <code class="o">+</code> <code class="n">c</code><code class="p">[</code><code class="mi">7</code><code class="p">]</code> <code class="o">+</code> <code class="n">c</code><code class="p">[</code><code class="mi">8</code><code class="p">]</code> <code class="o">-</code> <code class="n">c</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code><code class="o">.</code><code class="n">A</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>
<code class="n">vocabulary_positions</code> <code class="o">=</code> <code class="n">coef</code><code class="o">.</code><code class="n">argsort</code><code class="p">()</code>
</pre>

<figure><div id="fig-coefficients-core-ui" class="figure"><img src="Images/btap_07in03.jpg" width="1412" height="745"/>
	<!-- <figcaption></figcaption> -->
	<h6><span class="label">Figure 7-1. </span>Word contributions to UI (negative) and Core (positive).</h6>
</div></figure>

<p>The rest of the code is almost identical to the previous code. We now extend the diagram to 20 words (<a data-type="xref" href="#fig-coefficients-core">Figure 7-2</a>):</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">top_words</code> <code class="o">=</code> <code class="mi">20</code>
<code class="n">top_positive_coef</code> <code class="o">=</code> <code class="n">vocabulary_positions</code><code class="p">[</code><code class="o">-</code><code class="n">top_words</code><code class="p">:]</code><code class="o">.</code><code class="n">tolist</code><code class="p">()</code>
<code class="n">top_negative_coef</code> <code class="o">=</code> <code class="n">vocabulary_positions</code><code class="p">[:</code><code class="n">top_words</code><code class="p">]</code><code class="o">.</code><code class="n">tolist</code><code class="p">()</code>
<code class="n">core</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">([[</code><code class="n">vocabulary</code><code class="p">[</code><code class="n">c</code><code class="p">],</code> <code class="n">coef</code><code class="p">[</code><code class="n">c</code><code class="p">]]</code>
<code class="err"> </code>                     <code class="k">for</code> <code class="n">c</code> <code class="ow">in</code> <code class="n">top_positive_coef</code> <code class="o">+</code> <code class="n">top_negative_coef</code><code class="p">],</code><code class="err"> </code>
<code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s2">"feature"</code><code class="p">,</code> <code class="s2">"coefficient"</code><code class="p">])</code><code class="o">.</code>\
<code class="err"> </code>         <code class="n">sort_values</code><code class="p">(</code><code class="s2">"coefficient"</code><code class="p">)</code>
<code class="n">core</code><code class="o">.</code><code class="n">set_index</code><code class="p">(</code><code class="s2">"feature"</code><code class="p">)</code><code class="o">.</code><code class="n">plot</code><code class="o">.</code><code class="n">barh</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">6</code><code class="p">,</code> <code class="mi">10</code><code class="p">),</code>
<code class="err"> </code>             <code class="n">color</code><code class="o">=</code><code class="p">[[</code><code class="s1">'red'</code><code class="p">]</code><code class="o">*</code><code class="n">top_words</code> <code class="o">+</code> <code class="p">[</code><code class="s1">'green'</code><code class="p">]</code><code class="o">*</code><code class="n">top_words</code><code class="p">])</code>
</pre>


<p>In the diagram, you can see a lot of words that the model uses to identify the Core component and in the lower part those that are used to primarily identify other components.</p>

<p>You can use the methods described in this blueprint to <a contenteditable="false" data-type="indexterm" data-primary="SVM (support vector machine) algorithm" id="idm45634191547624"/>make the results of the SVM model transparent and explainable. In many projects, this has proved to be valuable as it takes away the “magic” and the subjectivity of machine learning.</p>

<p>This works quite well, but we do not yet know how sensitive the model is to changes in certain <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term9" id="idm45634191415224"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term10" id="idm45634191413880"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term11" id="idm45634191412504"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term12" id="idm45634191411128"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term13" id="idm45634191409752"/>words. This is a more complicated question that we will try to answer in the next section.</p>


<figure><div id="fig-coefficients-core" class="figure">
	<img src="Images/btap_07in04.jpg" width="1420" height="1878"/>
	<h6><span class="label">Figure 7-2. </span>Coefficients favoring or opposing the Core component.</h6>
	<!-- If figcaption needed: Coefficients favoring or opposing the Core component -->
  </div></figure>

</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Using LIME to Explain the Classification Results"><div class="sect1" id="idm45634191892840">
<h1>Blueprint: Using LIME to Explain the Classification Results</h1>

<p>LIME is an <a contenteditable="false" data-type="indexterm" data-primary="LIME (local interpretable model-agnostic explanations) algorithm" id="ch7_term14"/><a contenteditable="false" data-type="indexterm" data-primary="text classification results, explaining" data-secondary="LIME for" id="ch7_term15"/><a contenteditable="false" data-type="indexterm" data-primary="prediction probability for explaining classifiers" id="ch7_term20"/><a contenteditable="false" data-type="indexterm" data-primary="text classification results, explaining" data-secondary="prediction probability for" id="ch7_term21"/><a contenteditable="false" data-type="indexterm" data-primary="probability, prediction" id="ch7_term34"/>acronym for <a href="https://oreil.ly/D8cIN">“Local Interpretable Model-Agnostic Explanations”</a> and is a popular framework for explainable machine learning. It was conceived at the <a href="https://oreil.ly/Q8zly">University of Washington</a> and is publicly available <a contenteditable="false" data-type="indexterm" data-primary="GitHub API" data-secondary="LIME on" id="idm45634191394472"/><a href="https://oreil.ly/bErrv">on GitHub</a>.</p>

<p>Let’s take a look at the defining features of LIME. It works <em>locally</em> by taking a look at each prediction separately. This is achieved by modifying the input vector to find the local components that the predictions are sensitive to.</p>

<div data-type="warning" epub:type="warning">
<h1>Explainability Needs Computation Time</h1>

<p>Running the <a contenteditable="false" data-type="indexterm" data-primary="execution time" id="idm45634191390104"/><a contenteditable="false" data-type="indexterm" data-primary="time, execution" id="idm45634191388968"/>explainer code can take considerable time. We tried to tailor the examples in a way that you don’t have to wait for more than 10 minutes on normal computers. However, by increasing the sample size, this can easily take hours.</p>
</div>

<p>From the <a contenteditable="false" data-type="indexterm" data-primary="vectorizers/vectorization" data-secondary="with text classification" data-secondary-sortas="text classification" id="idm45634191386952"/>behavior in the vicinity of the vector, it will draw conclusions about which components are more or less important. LIME will visualize the contributions and explain the decision mechanism of the algorithm <em>for individual documents</em>.</p>

<p>LIME does not depend on a specific machine learning model and can be applied to a multitude of problems. Not every model qualifies; the model needs to predict the probabilities of the categories. Not all support vector machine models can do that. In addition, using complicated models where predictions take considerable time is not very practical in high-dimensional feature spaces like those common in text analytics. As LIME attempts to locally modify the <a contenteditable="false" data-type="indexterm" data-primary="feature vectors" id="idm45634191383528"/>feature vectors, it needs to perform a lot of predictions and in this case takes a long time to finish.</p>

<p>Finally, LIME will generate an explanation for the model on a per-sample basis and allow you to understand the model. You can use this to improve your model but also to explain how a classification works. Although the model will still be a black box, you will gain some knowledge of what might be going on in the box.</p>

<p>Let’s get back to the <a contenteditable="false" data-type="indexterm" data-primary="explainer in LIME and Anchor" id="ch7_term19"/>classification problem of the previous section and try to find a LIME explanation for a few samples. As LIME wants text as input and classification probabilities as output, we arrange the vectorizer and classifier in a <em>pipeline</em>:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sklearn.pipeline</code> <code class="kn">import</code> <code class="n">make_pipeline</code>
<code class="n">pipeline</code> <code class="o">=</code> <code class="n">make_pipeline</code><code class="p">(</code><code class="n">tfidf</code><code class="p">,</code> <code class="n">best_model</code><code class="p">)</code>
</pre>

<p class="pagebreak-before">The pipeline should be able to make predictions if we give it some text, as done here:</p>

<pre class="pre" data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">pipeline</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">([</code><code class="s2">"compiler not working"</code><code class="p">])</code>
</pre>

<p><code>Out:</code></p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">array</code><code class="p">([[</code><code class="mf">0.00240522</code><code class="p">,</code> <code class="mf">0.95605684</code><code class="p">,</code> <code class="mf">0.00440957</code><code class="p">,</code> <code class="mf">0.00100242</code><code class="p">,</code> <code class="mf">0.00971824</code><code class="p">,</code>
<code class="err">       </code> <code class="mf">0.02640771</code><code class="p">]])</code>
</pre>

<p>The classifier suggests with very high probability to put this in class 2, which is Core. So, our pipeline works exactly in the way we want it: we can give it text documents as parameters, and it returns the probabilities for the documents belonging to each category. Now it’s time to turn on LIME by first importing the package (you might have to install the package first with <code>pip</code> or <code>conda</code>). Afterward, we will create an explainer, which is one of the central elements of LIME and is responsible for explaining individual predictions:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="kn">from</code> <code class="nn">lime.lime_text</code> <code class="kn">import</code> <code class="n">LimeTextExplainer</code>
<code class="n">explainer</code> <code class="o">=</code> <code class="n">LimeTextExplainer</code><code class="p">(</code><code class="n">class_names</code><code class="o">=</code><code class="n">class_names</code><code class="p">)</code>
</pre>

<p>We check the <code>DataFrame</code> for classes that have been wrongly predicted in the <span class="keep-together">following</span>:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">er</code><code class="p">[</code><code class="n">er</code><code class="p">[</code><code class="s2">"predicted"</code><code class="p">]</code> <code class="o">!=</code> <code class="n">er</code><code class="p">[</code><code class="s2">"actual"</code><code class="p">]]</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<table class="dataframe">
	<thead>
		<tr>
			<th> </th>
			<th>index</th>
			<th>text</th>
			<th>actual</th>
			<th>predicted</th>
			<th>APT</th>
			<th>Core</th>
			<th>Debug</th>
			<th>Doc</th>
			<th>Text</th>
			<th>UI</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>2</th>
			<td>2</td>
			<td>NPE in Delta processor while executing JDT/UI ...</td>
			<td>Core</td>
			<td>UI</td>
			<td>0.003357</td>
			<td>0.309548</td>
			<td>0.046491</td>
			<td>0.002031</td>
			<td>0.012309</td>
			<td>0.626265</td>
		</tr>
		<tr>
			<th>15</th>
			<td>15</td>
			<td>Inserting a block of text in editor badly alig...</td>
			<td>UI</td>
			<td>Text</td>
			<td>0.001576</td>
			<td>0.063076</td>
			<td>0.034610</td>
			<td>0.003907</td>
			<td>0.614473</td>
			<td>0.282356</td>
		</tr>
		<tr>
			<th>16</th>
			<td>16</td>
			<td>Differences when debugging identical objects W...</td>
			<td>Debug</td>
			<td>Core</td>
			<td>0.002677</td>
			<td>0.430862</td>
			<td>0.313465</td>
			<td>0.004193</td>
			<td>0.055838</td>
			<td>0.192965</td>
		</tr>
		<tr>
			<th>20</th>
			<td>20</td>
			<td>Foreach template doesnt work for class members...</td>
			<td>Core</td>
			<td>UI</td>
			<td>0.000880</td>
			<td>0.044018</td>
			<td>0.001019</td>
			<td>0.000783</td>
			<td>0.130766</td>
			<td>0.822535</td>
		</tr>
		<tr>
			<th>21</th>
			<td>21</td>
			<td>exchange left and right operands for compariso...</td>
			<td>UI</td>
			<td>Core</td>
			<td>0.002669</td>
			<td>0.467366</td>
			<td>0.077252</td>
			<td>0.003194</td>
			<td>0.068749</td>
			<td>0.380770</td>
		</tr>
	</tbody>
</table>

<p>Take a look at the corresponding record (row 21 in our case):</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="nb">id</code> <code class="o">=</code> <code class="mi">21</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Document id: </code><code class="si">%d</code><code class="s1">'</code> <code class="o">%</code> <code class="nb">id</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Predicted class ='</code><code class="p">,</code> <code class="n">er</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="nb">id</code><code class="p">][</code><code class="s2">"predicted"</code><code class="p">])</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'True class: </code><code class="si">%s</code><code class="s1">'</code> <code class="o">%</code> <code class="n">er</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="nb">id</code><code class="p">][</code><code class="s2">"actual"</code><code class="p">])</code>
</pre>

<p><code>Out:</code></p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">Document</code> <code class="nb">id</code><code class="p">:</code> <code class="mi">21</code>
<code class="n">Predicted</code> <code class="k">class</code> <code class="err">= </code><code class="nc">Core</code>
<code class="bp">True</code> <code class="n">class</code><code class="p">:</code> <code class="n">UI</code>
</pre>

<p>Now it’s time for LIME to explain this to us!</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">exp</code> <code class="o">=</code> <code class="n">explainer</code><code class="o">.</code><code class="n">explain_instance</code><code class="p">(</code><code class="n">result</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="nb">id</code><code class="p">][</code><code class="s2">"text"</code><code class="p">],</code>
      <code class="n">pipeline</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">,</code> <code class="n">num_features</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code> <code class="n">labels</code><code class="o">=</code><code class="p">[</code><code class="mi">1</code><code class="p">,</code> <code class="mi">5</code><code class="p">])</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Explanation for class </code><code class="si">%s</code><code class="s1">'</code> <code class="o">%</code> <code class="n">class_names</code><code class="p">[</code><code class="mi">1</code><code class="p">])</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="nb">map</code><code class="p">(</code><code class="nb">str</code><code class="p">,</code> <code class="n">exp</code><code class="o">.</code><code class="n">as_list</code><code class="p">(</code><code class="n">label</code><code class="o">=</code><code class="mi">1</code><code class="p">))))</code>
<code class="k">print</code><code class="p">()</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Explanation for class </code><code class="si">%s</code><code class="s1">'</code> <code class="o">%</code> <code class="n">class_names</code><code class="p">[</code><code class="mi">5</code><code class="p">])</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="nb">map</code><code class="p">(</code><code class="nb">str</code><code class="p">,</code> <code class="n">exp</code><code class="o">.</code><code class="n">as_list</code><code class="p">(</code><code class="n">label</code><code class="o">=</code><code class="mi">5</code><code class="p">))))</code>
</pre>

<p><code>Out:</code></p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">Explanation</code> <code class="k">for</code> <code class="k">class</code> <code class="nc">Core</code>
<code class="p">(</code><code class="s1">'fix'</code><code class="p">,</code> <code class="o">-</code><code class="mf">0.14306948642919184</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'Bug'</code><code class="p">,</code> <code class="mf">0.14077384623641856</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'following'</code><code class="p">,</code> <code class="mf">0.11150012169630388</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'comparison'</code><code class="p">,</code> <code class="mf">0.10122423126000728</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'Fix'</code><code class="p">,</code> <code class="o">-</code><code class="mf">0.0884162779420967</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'right'</code><code class="p">,</code> <code class="mf">0.08315255286108318</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'semantics'</code><code class="p">,</code> <code class="mf">0.08143857054730141</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'changes'</code><code class="p">,</code> <code class="o">-</code><code class="mf">0.079427782008582</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'left'</code><code class="p">,</code> <code class="mf">0.03188240169394561</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'good'</code><code class="p">,</code> <code class="o">-</code><code class="mf">0.0027133756042246504</code><code class="p">)</code>

<code class="n">Explanation</code> <code class="k">for</code> <code class="k">class</code> <code class="nc">UI</code>
<code class="p">(</code><code class="s1">'fix'</code><code class="p">,</code> <code class="mf">0.15069083664026453</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'Bug'</code><code class="p">,</code> <code class="o">-</code><code class="mf">0.14853911521141774</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'right'</code><code class="p">,</code> <code class="mf">0.11283930406785869</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'comparison'</code><code class="p">,</code> <code class="o">-</code><code class="mf">0.10654654371478504</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'left'</code><code class="p">,</code> <code class="o">-</code><code class="mf">0.10391669738035045</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'following'</code><code class="p">,</code> <code class="o">-</code><code class="mf">0.1003931859632352</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'semantics'</code><code class="p">,</code> <code class="o">-</code><code class="mf">0.056644426928774076</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'Fix'</code><code class="p">,</code> <code class="mf">0.05365037666619837</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'changes'</code><code class="p">,</code> <code class="mf">0.040806391076561165</code><code class="p">)</code>
<code class="p">(</code><code class="s1">'good'</code><code class="p">,</code> <code class="mf">0.0401761761717476</code><code class="p">)</code>
</pre>

<p>LIME shows us which words it thinks are in favor (positive) or against (negative) a certain class. This is quite easy and similar to what we have achieved in the SVM example. Even better, now it’s independent of the model itself; it just <a contenteditable="false" data-type="indexterm" data-primary="predict_proba function" id="idm45634190917144"/>needs to support <code>predict_proba</code> (which is also true for Random Forest and so on).</p>

<p class="pagebreak-before">With LIME, you can extend the analysis to more classes and create a graphics representation of their specific words:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">exp</code> <code class="o">=</code> <code class="n">explainer</code><code class="o">.</code><code class="n">explain_instance</code><code class="p">(</code><code class="n">result</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="nb">id</code><code class="p">][</code><code class="s2">"text"</code><code class="p">],</code>
<code class="err"> </code>           <code class="n">pipeline</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">,</code> <code class="n">num_features</code><code class="o">=</code><code class="mi">6</code><code class="p">,</code> <code class="n">top_labels</code><code class="o">=</code><code class="mi">3</code><code class="p">)</code>
<code class="n">exp</code><code class="o">.</code><code class="n">show_in_notebook</code><code class="p">(</code><code class="n">text</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<figure><div class="figure">
    <img src="Images/btap_07_svgcombo_1.jpg" alt="" width="1778" height="570"/>
    <h6/>
</div></figure>

<figure><div class="figure">
    <img src="Images/btap_07_svgcombo_2.jpg" alt="" width="2304" height="808"/>
    <h6/>
</div></figure>
<!-- <div class="lime top_div" id="top_divZW00GZ6KFQOFKJ8">
<div class="lime predict_proba">
<figure>
  <img src="images/btap_07_svg_0.jpg" />
  <figcaption></figcaption>
</figure>
</div>

<div class="lime explanation">
  <figure>
    <img src="images/btap_07_svg_1.jpg" />
    <figcaption></figcaption>
  </figure>
</div>

<div class="lime explanation">
  <figure>
    <img src="images/btap_07_svg_2.jpg" />
    <figcaption></figcaption>
  </figure>
</div>

<div class="lime explanation">
  <figure>
    <img src="images/btap_07_svg_3.jpg" />
    <figcaption></figcaption>
  </figure>
</div>
</div>-->

<p>This looks  intuitive and much more suitable for interpretation and even inclusion in a presentation. We can clearly see that <em>fix</em> and <em>right</em> are crucial for assigning the UI class and at the same time against Core. Bug, however, speaks for Core, as do <em>comparison</em> and <em>semantics</em>. Unfortunately, this is not what a human would accept as rules for classification; they seem too specific, and there is no abstraction. In other words, our <a contenteditable="false" data-type="indexterm" data-primary="overfitting of trained model" id="idm45634190769800"/>model looks <em>overfitted</em>.</p>

<div data-type="note" epub:type="note">
<h1>Improving Models</h1>

<p>With this knowledge and the expertise of people familiar with the tickets, you could improve the model. We could, for example, ask if <em>Bug</em> is really specific to Core or if we’d better make it a stop word. It might also prove useful to convert everything to lowercase.</p>
</div>

<p>LIME <a contenteditable="false" data-type="indexterm" data-primary="submodular picks with LIME" id="idm45634190765576"/>can even support you in finding representative samples that help you interpret the model performance as a whole. The feature is called <em>submodular picks</em> and works like this:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="kn">from</code> <code class="nn">lime</code> <code class="kn">import</code> <code class="n">submodular_pick</code>
<code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>
<code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>
<code class="n">lsm</code> <code class="o">=</code> <code class="n">submodular_pick</code><code class="o">.</code><code class="n">SubmodularPick</code><code class="p">(</code><code class="n">explainer</code><code class="p">,</code> <code class="n">er</code><code class="p">[</code><code class="s2">"text"</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code class="p">,</code>
                                        <code class="n">pipeline</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">,</code>
<code class="err">                                       </code> <code class="n">sample_size</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code>
<code class="err">                                       </code> <code class="n">num_features</code><code class="o">=</code><code class="mi">20</code><code class="p">,</code>
<code class="err">                                       </code> <code class="n">num_exps_desired</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code>
</pre>

<p>The individual “picks” can be <a contenteditable="false" data-type="indexterm" data-primary="visualization of data" data-secondary="with highlighted text" data-secondary-sortas="highlighted text" id="idm45634190762712"/>visualized as shown previously in the notebook and are even more complete now with highlighting. We show only the first of the picks here:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">lsm</code><code class="o">.</code><code class="n">explanations</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">show_in_notebook</code><code class="p">()</code>
</pre>

<p><code>Out:</code></p>

<figure class="width-80"><div class="figure">
    <img src="Images/btap_07_svgcombo_3.jpg" alt="" width="1699" height="1942"/>
    <h6/>
</div></figure>

<!-- <div class="lime predict_proba">
  <figure>
    <img src="images/btap_07_svg_4.jpg" />
    <figcaption></figcaption>
  </figure>
</div>

<div class="lime explanation">
  <figure>
    <img src="images/btap_07_svg_5.jpg" />
    <figcaption></figcaption>
  </figure>
</div> -->


<p>In the following <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term19" id="idm45634190567480"/>case, we can interpret the results, but it <a contenteditable="false" data-type="indexterm" data-primary="overfitting of trained model" id="idm45634190565944"/>does not look like the model learned the abstraction, which is again a sign of <em>overfitting</em>.</p>

<figure><div class="figure">
  <img src="Images/btap_07_highlightwords.jpg" alt="" width="905" height="201"/>
  <h6/>
</div></figure>


<p>The LIME <a contenteditable="false" data-type="indexterm" data-primary="scikit-learn" data-secondary="vectorization with" id="idm45634190562344"/>software module works for linear support vector machines in scikit-learn but not for those with more complex kernels. The graphical presentation is nice but is not directly suitable for presentations. Therefore, we will take a look at ELI5, which is an alternative implementation and tries to overcome <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term14" id="idm45634190560488"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term15" id="idm45634190559112"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term20" id="idm45634190557736"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term21" id="idm45634190556360"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term34" id="idm45634190554984"/>these problems.</p>
</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Using ELI5 to Explain the Classification Results"><div class="sect1" id="idm45634191404568">
<h1>Blueprint: Using ELI5 to Explain the Classification Results</h1>

<p>ELI5 (“Explain it to me like I’m 5”) is another <a contenteditable="false" data-type="indexterm" data-primary="ELI5 (&quot;Explain it to me like I'm 5&quot;) library" id="ch7_term24"/><a contenteditable="false" data-type="indexterm" data-primary="text classification results, explaining" data-secondary="ELI5 for" id="ch7_term25"/>popular software library for machine learning explanation also using the LIME algorithm. As it can be used for <a contenteditable="false" data-type="indexterm" data-primary="nonlinear SVMs" id="ch7_term23"/><a contenteditable="false" data-type="indexterm" data-primary="SVM (support vector machine) algorithm" id="ch7_term22"/>nonlinear SVMs and has a different API, we will take a short look at it and show how to use it in our case.</p>

<p>ELI5 needs a <a contenteditable="false" data-type="indexterm" data-primary="libsvm model" id="idm45634190494008"/>model that has been trained with <code>libsvm</code>, which our SVC model from before unfortunately is not. Luckily, training an SVM is really fast, so we can create a new classifier with the same data, but with a <code>libsvm</code>-based model, and check its performance. You might remember the classification report from <a data-type="xref" href="ch06.xhtml#ch-classification">Chapter 6</a>, which gives a good summary about the quality of the model:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">SGDClassifier</code>
<code class="n">svm</code> <code class="o">=</code> <code class="n">SGDClassifier</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="s1">'hinge'</code><code class="p">,</code> <code class="n">max_iter</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code> <code class="n">tol</code><code class="o">=</code><code class="mf">1e-3</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">svm</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_tf</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">)</code>
<code class="n">Y_pred_svm</code> <code class="o">=</code> <code class="n">svm</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test_tf</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">classification_report</code><code class="p">(</code><code class="n">Y_test</code><code class="p">,</code> <code class="n">Y_pred_svm</code><code class="p">))</code>
</pre>

<p><code>Out:</code></p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="err"> </code> <code class="n">precision</code><code class="err">   </code> <code class="n">recall</code><code class="err"> </code> <code class="n">f1</code><code class="o">-</code><code class="n">score</code><code class="err">  </code> <code class="n">support</code>

<code class="err">        </code> <code class="n">APT</code><code class="err">      </code> <code class="mf">0.89</code><code class="err">     </code> <code class="mf">0.50</code><code class="err">     </code> <code class="mf">0.64</code><code class="err">       </code> <code class="mi">16</code>
<code class="err">       </code> <code class="n">Core</code><code class="err">      </code> <code class="mf">0.77</code><code class="err">     </code> <code class="mf">0.78</code><code class="err">     </code> <code class="mf">0.77</code><code class="err">      </code> <code class="mi">546</code>
<code class="err">      </code> <code class="n">Debug</code><code class="err">      </code> <code class="mf">0.85</code><code class="err">     </code> <code class="mf">0.84</code><code class="err">     </code> <code class="mf">0.85</code><code class="err">      </code> <code class="mi">302</code>
<code class="err">        </code> <code class="n">Doc</code><code class="err">      </code> <code class="mf">0.75</code><code class="err">     </code> <code class="mf">0.25</code><code class="err">     </code> <code class="mf">0.38</code><code class="err">       </code> <code class="mi">12</code>
<code class="err">       </code> <code class="n">Text</code><code class="err">      </code> <code class="mf">0.62</code><code class="err">     </code> <code class="mf">0.59</code><code class="err">     </code> <code class="mf">0.60</code><code class="err">      </code> <code class="mi">236</code>
<code class="err">         </code> <code class="n">UI</code><code class="err">      </code> <code class="mf">0.76</code><code class="err">     </code> <code class="mf">0.79</code><code class="err">     </code> <code class="mf">0.78</code><code class="err">      </code> <code class="mi">699</code>

<code class="err">   </code> <code class="n">accuracy</code><code class="err">                          </code> <code class="mf">0.76</code><code class="err">     </code> <code class="mi">1811</code>
<code class="err">  </code> <code class="n">macro</code> <code class="n">avg</code><code class="err">      </code> <code class="mf">0.77</code><code class="err">     </code> <code class="mf">0.62</code><code class="err">     </code> <code class="mf">0.67</code><code class="err">     </code> <code class="mi">1811</code>
<code class="n">weighted</code> <code class="n">avg</code><code class="err">      </code> <code class="mf">0.76</code><code class="err">     </code> <code class="mf">0.76</code><code class="err">     </code> <code class="mf">0.76</code><code class="err">     </code> <code class="mi">1811</code>
</pre>

<p>Taking a look at the last line, this is roughly as good as what we have achieved with SVC. Thus, it makes sense to explain it! Using ELI5, finding explanations for this model is easy:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="kn">import</code> <code class="nn">eli5</code>
<code class="n">eli5</code><code class="o">.</code><code class="n">show_weights</code><code class="p">(</code><code class="n">svm</code><code class="p">,</code> <code class="n">top</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code> <code class="n">vec</code><code class="o">=</code><code class="n">tfidf</code><code class="p">,</code> <code class="n">target_names</code><code class="o">=</code><code class="n">class_names</code><code class="p">)</code>
</pre>

<figure><div class="figure">
  <img src="Images/btap_07_eli5_1.jpg" alt="" width="1716" height="495"/>
  <h6/>
</div></figure>

<p>The positive features (i.e., words) are shown in green. More intense shades of green mean a larger contribution of the word to the corresponding class. The red colors work exactly opposite: words appearing in red “repel” the classes (for example, “refactoring” in the lower part of the second row strongly rejects class <code>Core</code>). <code>&lt;BIAS&gt;</code> is a special case and contains the so-called <em>intercept</em>, i.e., systematic failures of the model.</p>

<p>As you can see, we now get weights for the individual classes. This is due to the non-linear SVM model <a contenteditable="false" data-type="indexterm" data-primary="multiclass classification" id="idm45634190284760"/>working differently in multiclass scenarios compared to SVC. Each class is “scored” on its own, and there is no competition. At first sight, the words look very <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term22" id="idm45634190281000"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term23" id="idm45634190279624"/>plausible.</p>

<p>ELI5 can also explain individual observations:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">eli5</code><code class="o">.</code><code class="n">show_prediction</code><code class="p">(</code><code class="n">svm</code><code class="p">,</code> <code class="n">X_test</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="mi">21</code><code class="p">],</code><code class="err"> </code> <code class="n">vec</code><code class="o">=</code><code class="n">tfidf</code><code class="p">,</code> <code class="n">target_names</code><code class="o">=</code><code class="n">class_names</code><code class="p">)</code>
</pre>

<figure><div class="figure">
  <img src="Images/btap_07_eli5_2.jpg" alt="" width="901" height="224"/>
  <h6/>
</div></figure>
<figure><div class="figure">
  <img src="Images/btap_07_eli5_3.jpg" alt="" width="901" height="225"/>
  <h6/>
</div></figure>
<figure><div class="figure">
  <img src="Images/btap_07_eli5_4.jpg" alt="" width="901" height="224"/>
  <h6/>
</div></figure>
<figure><div class="figure">
  <img src="Images/btap_07_eli5_5.jpg" alt="" width="901" height="225"/>
  <h6/>
</div></figure>
<figure><div class="figure">
  <img src="Images/btap_07_eli5_6.jpg" alt="" width="901" height="224"/>
  <h6/>
</div></figure>
<figure><div class="figure">
  <img src="Images/btap_07_eli5_7.jpg" alt="" width="901" height="226"/>
  <h6/>
</div></figure>

<p>This is a nice visualization for understanding which words contribute to the algorithm deciding the categories. Compared to the <a contenteditable="false" data-type="indexterm" data-primary="LIME (local interpretable model-agnostic explanations) algorithm" id="idm45634190167896"/>original LIME package, with ELI5 you need considerably less code, and you can use ELI5 for nonlinear SVM models. Depending on your classifier and use case, you might decide on LIME or ELI5. Due to the same method, the results should be comparable (if not identical). </p>

<div data-type="warning" epub:type="warning">
<h1>Work in Progress</h1>

<p>ELI5 is still under heavy development, and you might experience difficulties with new scikit-learn versions. We have used ELI5 version 0.10.1 in this chapter.</p>
</div>

<p>ELI5 is an easy-to-use software library for understanding and visualizing the decision logic of classifiers, but it also suffers from the shortcomings of the underlying LIME algorithm, such as explainability by example only. To make the black-box classification more transparent, it would be insightful to gain access to the “rules” that a model uses. That was the motivation for the group at Washington University to create a follow-up project <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term24" id="idm45634190163768"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term25" id="idm45634190162392"/>called Anchor.</p>
</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Using Anchor to Explain the Classification Results"><div class="sect1" id="idm45634190553224">
<h1>Blueprint: Using Anchor to Explain the Classification Results</h1>

<p>Like LIME, <a href="https://oreil.ly/qSDMl">Anchor</a> is model <a contenteditable="false" data-type="indexterm" data-primary="Anchor model" id="ch7_term28"/><a contenteditable="false" data-type="indexterm" data-primary="text classification results, explaining" data-secondary="Anchor for" id="ch7_term29"/>agnostic and works for any black-box model. As a tool for explanations, it creates rules, the so-called <em>anchors</em>, which explain the behavior of the model. Reading these rules, you will not only be able to explain a prediction of the model but also predict in the same way as the model has learned to.</p>

<p>Compared to LIME, Anchor has considerable advantages for better explaining the models with the rules. However, the software itself is quite new and still a work in progress. Not all examples were working for us, so we chose a selection of methods that help in interpreting the classification model.</p>

<section data-type="sect2" data-pdf-bookmark="Using the Distribution with Masked Words"><div class="sect2" id="idm45634190130200">
<h2>Using the Distribution with Masked Words</h2>

<p>There are different ways Anchor can be used. We <a contenteditable="false" data-type="indexterm" data-primary="masked words" id="ch7_term26"/><a contenteditable="false" data-type="indexterm" data-primary="unknown distribution with Anchor" id="ch7_term27"/>start with the so-called <em>unknown</em> distribution. Anchor will explain how a model makes a decision by replacing existing tokens that are supposed to be unimportant for the prediction with the word <em>unknown</em>.</p>

<p>Again, we will use the document with an ID of 21. In this case, the classifier has the difficult task of choosing between two categories that have roughly the same probability. This should make it an interesting example for studying.</p>

<p>To create (semantic) variance in the text, Anchor <a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for word vectors" data-secondary-sortas="word vectors" id="idm45634190123176"/><a contenteditable="false" data-type="indexterm" data-primary="word vectors" data-secondary="in text classification" data-secondary-sortas="text classification" id="idm45634190121464"/><a contenteditable="false" data-type="indexterm" data-primary="vectorizers/vectorization" data-secondary="with text classification" data-secondary-sortas="text classification" id="idm45634190119816"/>uses spaCy’s word vectors and needs a spaCy model that includes these vectors, like <code>en_core_web_lg</code>.</p>

<p>As a prerequisite, you should therefore install <code>anchor-exp</code> and <code>spacy</code> (using either <code>conda</code> or <code>pip</code>) and load the model with the following:</p>

<pre data-type="programlisting">
python -m spacy download en_core_web_lg</pre>

<p>In the first step, we can then <a contenteditable="false" data-type="indexterm" data-primary="explainer in LIME and Anchor" id="idm45634190114088"/>instantiate our explainer. The explainer has some probabilistic elements, so it’s better to restart the random-number generator at the same time:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>
<code class="n">explainer_unk</code> <code class="o">=</code> <code class="n">anchor_text</code><code class="o">.</code><code class="n">AnchorText</code><code class="p">(</code><code class="n">nlp</code><code class="p">,</code> <code class="n">class_names</code><code class="p">,</code> \
                <code class="n">use_unk_distribution</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
</pre>

<p>Let’s check the <a contenteditable="false" data-type="indexterm" data-primary="prediction probability for explaining classifiers" id="ch7_term31"/><a contenteditable="false" data-type="indexterm" data-primary="text classification results, explaining" data-secondary="prediction probability for" id="ch7_term32"/><a contenteditable="false" data-type="indexterm" data-primary="probability, prediction" id="ch7_term35"/>predicted results and alternatives and compare them to the ground truth. <code>predicted_class_ids</code> contains the indices of the predicted classes with decreasing probability, so the element 0 is the prediction, and element 1 is its closest competitor:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="n">er</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="mi">21</code><code class="p">][</code><code class="s2">"text"</code><code class="p">]</code>
<code class="n">actual</code> <code class="o">=</code> <code class="n">er</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="mi">21</code><code class="p">][</code><code class="s2">"actual"</code><code class="p">]</code>
<code class="c1"># we want the class with the highest probability and must invert the order</code>
<code class="n">predicted_class_ids</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">argsort</code><code class="p">(</code><code class="n">pipeline</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">([</code><code class="n">text</code><code class="p">])[</code><code class="mi">0</code><code class="p">])[::</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
<code class="n">pred</code> <code class="o">=</code> <code class="n">explainer_unk</code><code class="o">.</code><code class="n">class_names</code><code class="p">[</code><code class="n">predicted_class_ids</code><code class="p">[</code><code class="mi">0</code><code class="p">]]</code>
<code class="n">alternative</code> <code class="o">=</code> <code class="n">explainer_unk</code><code class="o">.</code><code class="n">class_names</code><code class="p">[</code><code class="n">predicted_class_ids</code><code class="p">[</code><code class="mi">1</code><code class="p">]]</code>
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'predicted {pred}, alternative {alternative}, actual {actual}'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">predicted</code> <code class="n">Core</code><code class="p">,</code> <code class="n">alternative</code> <code class="n">UI</code><code class="p">,</code> <code class="n">actual</code> <code class="n">UI</code>
</pre>

<p>In the next step, we will let the algorithm find the rules for the predictions. The parameters are the same as for LIME earlier:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">exp_unk</code> <code class="o">=</code> <code class="n">explainer_unk</code><code class="o">.</code><code class="n">explain_instance</code><code class="p">(</code><code class="n">text</code><code class="p">,</code> <code class="n">pipeline</code><code class="o">.</code><code class="n">predict</code><code class="p">,</code> <code class="n">threshold</code><code class="o">=</code><code class="mf">0.95</code><code class="p">)</code>
</pre>

<p>The calculation can take up to 60 minutes depending on the speed of your CPU.</p>

<p>Everything is now contained in the explainer, so we can query the explainer to find out about the inner workings of the model:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'Rule: {" AND ".join(exp_unk.names())}'</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'Precision: {exp_unk.precision()}'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">Rule</code><code class="p">:</code> <code class="n">following</code> <code class="n">AND</code> <code class="n">comparison</code> <code class="n">AND</code> <code class="n">Bug</code> <code class="n">AND</code> <code class="n">semantics</code> <code class="n">AND</code> <code class="k">for</code>
<code class="n">Precision</code><code class="p">:</code> <code class="mf">0.9865771812080537</code>
</pre>

<p>So, the rule tells us that an occurrence of the words <em>following</em> and <em>comparison</em> combined with <em>Bug</em> and <em>semantic</em> leads to a prediction of “Core” with more than 98% precision, which is unfortunately wrong. We can now also find typical examples that the model would classify as Core:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'Made-up examples where anchor rule matches and model predicts {pred}</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="o">.</code><code class="n">join</code><code class="p">([</code><code class="n">x</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">exp_unk</code><code class="o">.</code><code class="n">examples</code><code class="p">(</code><code class="n">only_same_prediction</code><code class="o">=</code><code class="bp">True</code><code class="p">)]))</code>
</pre>

<p>The UNK <a contenteditable="false" data-type="indexterm" data-primary="UNK token" id="idm45634189783832"/><a contenteditable="false" data-type="indexterm" data-primary="unknown distribution with Anchor" id="idm45634189782856"/>token shown next stands for “unknown” and means that the word at the corresponding position is not important:</p>

<pre data-type="programlisting">
Made-up examples where anchor rule matches and model predicts Core

UNK left UNK UNK UNK UNK comparison operators UNK semantics Fix for Bug UNK UNK
exchange left UNK UNK operands UNK comparison operators changes semantics Fix fo
exchange UNK and UNK operands UNK comparison UNK UNK semantics UNK for Bug UNK U
exchange UNK and right UNK for comparison UNK UNK semantics UNK for Bug 149803 U
UNK left UNK UNK operands UNK comparison UNK changes semantics UNK for Bug 14980
exchange left UNK right UNK UNK comparison UNK changes semantics Fix for Bug UNK
UNK UNK and right operands for comparison operators UNK semantics Fix for Bug 14
UNK left and right operands UNK comparison operators changes semantics UNK for B
exchange left UNK UNK operands UNK comparison operators UNK semantics UNK for Bu
UNK UNK UNK UNK operands for comparison operators changes semantics Fix for Bug
</pre>

<p>We can also ask for examples where the rule matches but the model predicts the wrong class:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'Made-up examples where anchor rule matches and model predicts </code><code class="se">\</code>
<code class="s1">        {alternative}</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="o">.</code><code class="n">join</code><code class="p">([</code><code class="n">x</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">exp_unk</code><code class="o">.</code><code class="n">examples</code><code class="p">(</code><code class="n">partial_index</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> \
      <code class="n">only_different_prediction</code><code class="o">=</code><code class="bp">True</code><code class="p">)]))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Made-up examples where anchor rule matches and model predicts UI

exchange left and right UNK for UNK UNK UNK UNK Fix for UNK 149803 was not UNK .
exchange left UNK UNK UNK for UNK UNK UNK semantics Fix for Bug 149803 UNK not U
exchange left UNK UNK operands for comparison operators UNK UNK Fix UNK Bug 1498
exchange left UNK right operands UNK comparison UNK UNK UNK Fix for UNK UNK UNK
exchange left and right operands UNK UNK operators UNK UNK Fix UNK UNK UNK UNK U
UNK UNK and UNK UNK UNK comparison UNK UNK UNK Fix for UNK UNK was not good UNK
exchange left and UNK UNK UNK UNK operators UNK UNK Fix UNK Bug 149803 was not U
exchange left and right UNK UNK UNK operators UNK UNK UNK for Bug 149803 UNK UNK
exchange left UNK right UNK for UNK operators changes UNK Fix UNK UNK UNK was no
UNK left UNK UNK operands UNK UNK operators changes UNK UNK for UNK 149803 was n
</pre>

<p>To be honest, this is not a good result for the model. We would have expected that the underlying rules learned by the models would be sensitive to words specific to the different components. However, there is no obvious reason why <em>following</em> and <em>Bug</em> would be specific to Core. More or less these are generic words that are not very characteristic of either of the categories.</p>

<p>The UNK tokens are a bit misleading. Even if they are not important in this sample, they might be replaced by other, realistic words that would influence the decision of the algorithm. Anchor can also help us <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term26" id="idm45634189707912"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term27" id="idm45634189706536"/>illustrate that.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Working with Real Words"><div class="sect2" id="idm45634190129288">
<h2>Working with Real Words</h2>

<p>By substituting <code>use_unk_distribution=False</code> in the original constructor of the explainer, we can tell Anchor to use real words (similar to the one it is substituting by using the word vectors from spaCy) and observe the behavior of the model:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>
<code class="n">explainer_no_unk</code> <code class="o">=</code> <code class="n">anchor_text</code><code class="o">.</code><code class="n">AnchorText</code><code class="p">(</code><code class="n">nlp</code><code class="p">,</code> <code class="n">class_names</code><code class="p">,</code>
                   <code class="n">use_unk_distribution</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code> <code class="n">use_bert</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>
<code class="n">exp_no_unk</code> <code class="o">=</code> <code class="n">explainer_no_unk</code><code class="o">.</code><code class="n">explain_instance</code><code class="p">(</code><code class="n">text</code><code class="p">,</code> <code class="n">pipeline</code><code class="o">.</code><code class="n">predict</code><code class="p">,</code>
             <code class="n">threshold</code><code class="o">=</code><code class="mf">0.95</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'Rule: {" AND ".join(exp_no_unk.names())}'</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'Precision: {exp_no_unk.precision()}'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">Rule</code><code class="p">:</code> <code class="n">following</code> <code class="n">AND</code> <code class="n">Bug</code> <code class="n">AND</code> <code class="n">comparison</code> <code class="n">AND</code> <code class="n">semantics</code> <code class="n">AND</code> <code class="n">left</code> <code class="n">AND</code> <code class="n">right</code>
<code class="n">Precision</code><code class="p">:</code> <code class="mf">0.9601990049751243</code>
</pre>

<p>The rules are a bit different from the earlier unknown distribution. It seems that some of the words have become a bit more specific for the Core, like <em>left</em> and <em>right</em>, whereas other words like <em>for</em> have vanished.</p>

<p>Let’s also ask Anchor to generate alternative texts that would also be (wrongly) classified as Core as the previous rule applies:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">Examples</code> <code class="n">where</code> <code class="n">anchor</code> <code class="n">applies</code> <code class="ow">and</code> <code class="n">model</code> <code class="n">predicts</code> <code class="n">Core</code><code class="p">:</code>

<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">suffixes</code> <code class="k">for</code> <code class="n">comparison</code> <code class="n">operators</code> <code class="n">affects</code> <code class="n">semantics</code> <code class="n">NEED</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="k">for</code> <code class="n">comparison</code> <code class="n">operators</code> <code class="n">depends</code> <code class="n">semantics</code> <code class="n">UPDA</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="k">for</code> <code class="n">comparison</code> <code class="n">operators</code> <code class="n">indicates</code> <code class="n">semantics</code> <code class="n">so</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="k">for</code> <code class="n">comparison</code> <code class="n">operators</code> <code class="n">changes</code> <code class="n">semantics</code> <code class="n">Firm</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="n">into</code> <code class="n">comparison</code> <code class="n">dispatchers</code> <code class="n">changes</code> <code class="n">semantics</code> <code class="n">F</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="k">with</code> <code class="n">comparison</code> <code class="n">operators</code> <code class="n">changes</code> <code class="n">semantics</code> <code class="n">Fix</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="n">beyond</code> <code class="n">comparison</code> <code class="n">operators</code> <code class="n">changes</code> <code class="n">semantics</code> <code class="n">M</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="n">though</code> <code class="n">comparison</code> <code class="n">representatives</code> <code class="n">changes</code> <code class="n">seman</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="n">before</code> <code class="n">comparison</code> <code class="n">operators</code> <code class="n">depends</code> <code class="n">semantics</code> <code class="n">M</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="k">as</code> <code class="n">comparison</code> <code class="n">operators</code> <code class="n">changes</code> <code class="n">semantics</code> <code class="n">THING</code>
</pre>

<p>Some words have changed and have not affected the result of the classification. In some cases, it is only prepositions, and normally this should not have an effect on the results. However, <em>operators</em> can also be replaced by <em>dispatchers</em> without affecting the results. Anchor shows you that it is stable against these modifications.</p>

<p>Compare the previous results to those where the model would (correctly) predict “UI.” Again, the difference affects single words like <em>changes</em>, <em>metaphors</em>, and so on, which definitely carry more meaning than the smaller modifications in the previous example, but it is highly unlikely that you as a human would interpret these words as signals for a different category:</p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">Examples</code> <code class="n">where</code> <code class="n">anchor</code> <code class="n">applies</code> <code class="ow">and</code> <code class="n">model</code> <code class="n">predicts</code> <code class="n">UI</code><code class="p">:</code>

<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">good</code> <code class="n">operands</code> <code class="k">for</code> <code class="n">comparison</code> <code class="n">operators</code> <code class="n">changes</code> <code class="n">metaphors</code> <code class="n">Fix</code> <code class="n">i</code>
<code class="n">exchange</code> <code class="n">landed</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="k">for</code> <code class="n">comparison</code> <code class="n">supervisors</code> <code class="n">changes</code> <code class="n">derivation</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">happy</code> <code class="n">operands</code> <code class="k">for</code> <code class="n">correlation</code> <code class="n">operators</code> <code class="n">changes</code> <code class="n">equivalences</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="k">for</code> <code class="n">scenario</code> <code class="n">operators</code> <code class="n">changes</code> <code class="n">paradigms</code> <code class="n">Fix</code> <code class="n">be</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="k">for</code> <code class="n">trade</code> <code class="n">customers</code> <code class="n">occurs</code> <code class="n">semantics</code> <code class="n">Fix</code> <code class="k">as</code> <code class="n">BoT</code>
<code class="n">exchange</code> <code class="n">did</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="n">than</code> <code class="n">consumer</code> <code class="n">operators</code> <code class="n">changes</code> <code class="n">analogies</code> <code class="n">Instal</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">few</code> <code class="n">operands</code> <code class="k">for</code> <code class="n">reason</code> <code class="n">operators</code> <code class="n">depends</code> <code class="n">semantics</code> <code class="n">Fix</code> <code class="k">for</code> <code class="n">Bu</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="k">for</code> <code class="n">percentage</code> <code class="n">operators</code> <code class="n">changes</code> <code class="n">semantics</code> <code class="n">MESS</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">pathnames</code> <code class="n">after</code> <code class="n">comparison</code> <code class="n">operators</code> <code class="n">depends</code> <code class="n">fallacies</code> <code class="n">F</code>
<code class="n">exchange</code> <code class="n">left</code> <code class="ow">and</code> <code class="n">right</code> <code class="n">operands</code> <code class="n">of</code> <code class="n">selection</code> <code class="n">operators</code> <code class="n">changes</code> <code class="n">descriptors</code> <code class="n">Fix</code>
</pre>

<p>Anchor also has an <a contenteditable="false" data-type="indexterm" data-primary="visualization of data" data-secondary="with highlighted text" data-secondary-sortas="highlighted text" id="idm45634189446504"/>intuitive way of showing the results with the important words highlighted in the notebook and also includes the rules it has calculated:<sup><a data-type="noteref" id="idm45634189444808-marker" href="ch07.xhtml#idm45634189444808">2</a></sup></p>

<pre data-code-language="python" data-executable="true" data-type="programlisting">
<code class="n">exp_unk</code><code class="o">.</code><code class="n">show_in_notebook</code><code class="p">()</code>
</pre>

<p><code>Out:</code></p>

<figure><div class="figure">
  <img src="Images/btap_07_highlightwords2.jpg" alt="" width="895" height="304"/>
  <h6/>
</div></figure>

<p>As it’s quite likely that you are also familiar with software development, it would be hard to determine the correct category from the rules alone. In other words, this means the model seems to be quite fragile when trained with the corpus. The “correct” category can probably be determined only by a project contributor who has a lot of context knowledge (which we will revisit later in <a data-type="xref" href="ch11.xhtml#ch-sentiment">Chapter 11</a>). So, finding that a classifier works does not necessarily mean that it has really learned in a way that is transparent for us.</p>

<p>To summarize this section, Anchor is quite interesting. The authors of Anchor did not choose version number 0.0.1 by chance; the program is still in its infancy. During our experiments, we have seen quite a few quirks, and to make it work in production, a lot of things have to be improved. Conceptually, however, it is already really convincing for explaining single predictions and making models transparent. The calculated rules especially are almost unique and cannot be created by any <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term28" id="idm45634189220200"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term29" id="idm45634189218824"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term31" id="idm45634189217448"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term32" id="idm45634189216072"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch7_term35" id="idm45634189213592"/>other solution.</p>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Closing Remarks"><div class="sect1" id="idm45634189704776">
<h1>Closing Remarks</h1>

<p>Using the <a contenteditable="false" data-type="indexterm" data-primary="text classification results, explaining" data-secondary="use cases for" id="idm45634189210696"/><a contenteditable="false" data-type="indexterm" data-primary="text classification results, explaining" data-secondary="for transparency and trust" data-secondary-sortas="transparency and trust" id="idm45634189209320"/><a contenteditable="false" data-type="indexterm" data-primary="transparency of models" id="idm45634189207736"/>techniques presented in this chapter will help make your model predictions more transparent.</p>

<p>From a technical perspective, this transparency can be a great help as it supports you in choosing among competing models or improving your feature models. The techniques presented in this chapter give you insights into the “inner workings” of a model and help to detect and improve untrustworthy models.</p>

<p>Considering the business perspective, explainability is a great selling proposition for projects. It is much easier to talk about models and present them if you don’t exclusively pursue the black-box model but rather make your models transparent. Recent articles in <a href="https://oreil.ly/Xcfjx">Forbes</a> and <a href="https://oreil.ly/SIa-R">VentureBeat</a> have focused on this interesting development. Being able to “trust” a model will be more and more important when you want to build trustable machine learning solutions.</p>

<p>Explainable AI is a young field. We can expect to see tremendous progress, better algorithms, and improved tooling in the future.</p>

<p>For most of the book, machine learning methods have worked nicely as black-box models. This is fine, as long as the results are consistent and we don’t have to justify the models. If either is challenged, as is becoming more common, then the time for explainable AI has arrived.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="idm45634192517144"><sup><a href="ch07.xhtml#idm45634192517144-marker">1</a></sup> Graphically, you can think of the probabilities as the distance of the samples to the hyperplane defined by the SVM.</p><p data-type="footnote" id="idm45634189444808"><sup><a href="ch07.xhtml#idm45634189444808-marker">2</a></sup> We had a hard time getting this to work, as it was suited only for numerical categories. We plan to make some pull requests to get the upstream working for textual categories as well.</p></div></div></section></div>



  </body></html>