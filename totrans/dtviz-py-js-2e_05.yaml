- en: Chapter 3\. Reading and Writing Data with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the fundamental skills of any data visualizer is the ability to move
    data around. Whether your data is in an SQL database, a comma-separated value
    (CSV) file, or in some more esoteric form, you should be comfortable reading the
    data, converting it, and writing it into a more convenient form if need be. One
    of Python’s great strengths is how easy it makes manipulating data in this way.
    The focus of this chapter is to bring you up to speed with this essential aspect
    of our dataviz toolchain.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is part tutorial, part reference, and sections of it will be referred
    to in later chapters. If you know the fundamentals of reading and writing Python
    data, you can cherry-pick parts of the chapter as a refresher.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Easy Does It
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I remember when I started programming back in the day (using low-level languages
    like C) how awkward data manipulation was. Reading from and writing to files was
    an annoying mixture of boilerplate code, hand-rolled improvisations, and the like.
    Reading from databases was equally difficult, and as for serializing data, the
    memories are still painful. Discovering Python was a breath of fresh air. It wasn’t
    a speed demon, but opening a file was pretty much as simple as it could be:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Back then, Python made reading from and writing to files refreshingly easy,
    and its sophisticated string processing made parsing the data in those files just
    as easy. It even had an amazing module called Pickle that could serialize pretty
    much any Python object.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: In the years since, Python has added robust, mature modules to its standard
    library that make dealing with CSV and JSON files, the standard for web dataviz
    work, just as easy. There are also some great libraries for interacting with SQL
    databases such as SQLAlchemy, my thoroughly recommended go-to. The newer NoSQL
    databases are also well served. MongoDB is the most popular of these newer document-based
    databases, and Python’s PyMongo library, which is demonstrated later in the chapter,
    makes interacting with it a relative breeze.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Passing Data Around
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good way to demonstrate how to use the key data-storage libraries is to pass
    a single data packet among them, reading and writing it as we go. This will give
    us an opportunity to see in action the key data formats and databases employed
    by data visualizers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: The data we’ll be passing around is probably the most commonly used in web visualizations,
    a list of dictionary-like objects (see [Example 3-1](#data_dummydata)). This dataset
    is transferred to the browser in [JSON form](https://oreil.ly/JgjAp), which is,
    as we’ll see, easily converted from a Python dictionary.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-1\. Our target list of data objects
  id: totrans-11
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We’ll start by creating a CSV file from the Python list shown in [Example 3-1](#data_dummydata)
    as a demonstration of reading (opening) and writing system files.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: The following sections assume you’re in a working (root) directory with a *data*
    subdirectory at hand. You can run the code from a Python interpreter or file.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Working with System Files
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll create a CSV file from a Python list of dictionaries
    ([Example 3-1](#data_dummydata)). Typically, you would do this using the `csv`
    module, which we’ll demonstrate after this section, so this is just a way of demonstrating
    basic Python file manipulation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s open a new file, using `w` as a second argument to indicate we’ll
    be writing data to it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now we’ll create our CSV file from the `nobel_winners` dictionary ([Example 3-1](#data_dummydata)):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO1-1)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Gets our data columns from the keys of the first object (i.e., `['category',
    'name', ... ]`).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO1-2)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Sorts the columns in alphabetical order.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO1-3)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Uses Python’s `with` statement to guarantee the file is closed on leaving the
    block or if any exceptions occur.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO1-4)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '`join` creates a concatenated string from a list of strings (`cols` here),
    joined by the initial string (i.e., “category,name,..”).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO1-5)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Creates a list using the column keys to the objects in `nobel_winners`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve created our CSV file, let’s use Python to read it and make sure
    everything is correct:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As the previous output shows, our CSV file is well formed. Let’s use Python’s
    built-in `csv` module to first read it and then create a CSV file the right way.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: CSV, TSV, and Row-Column Data Formats
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Comma-separated values (CSV) or their tab-separated cousins (TSV) are probably
    the most ubiquitous file-based data formats and, as a data visualizer, these will
    often be the forms you’ll receive to work your magic with. Being able to read
    and write CSV files and their various quirky variants, such as pipe- or semicolon-separated
    or those using *`* in place of the standard double quotes, is a fundamental skill;
    Python’s `csv` module is capable of doing pretty much all your heavy lifting here.
    Let’s put it through its paces reading and writing our `nobel_winners` data:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Writing our `nobel_winners` data (see [Example 3-1](#data_dummydata)) to a
    CSV file is a pretty simple affair. `csv` has a dedicated `DictWriter` class that
    will turn our dictionaries into CSV rows. The only piece of explicit bookkeeping
    we have to do is write a header to our CSV file, using the keys of our dictionaries
    as fields (i.e., “category, name, nationality, gender”):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO2-1)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: You need to explicitly tell the writer which `fieldnames` to use (in this case,
    the `'category'`, `'name'`, etc., keys).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO2-2)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: We’ll sort the CSV header fields alphabetically for readability.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO2-3)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Writes the CSV-file header (“category, name,…​”).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: You’ll probably be reading CSV files more often than writing them.^([1](ch03.xhtml#idm45607798394048))
    Let’s read back the *nobel_winners.csv* file we just wrote.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'If you just want to use `csv` as a superior and eminently adaptable file line
    reader, a couple of lines will produce a handy iterator, which can deliver your
    CSV rows as lists of strings:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO3-1)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Iterates over the `reader` object, consuming the lines in the file.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Note that the numbers are read in string form. If you want to manipulate them
    numerically, you’ll need to convert any numeric columns to their respective type,
    which is integer years in this case.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'A more convenient way to consume CSV data is to convert the rows into Python
    dictionaries. This *record* form is also the one we are using as our conversion
    target (a `list` of `dict`s). `csv` has a handy `DictReader` for just this purpose:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO4-1)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Inserts all of the `reader` items into a list.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'As the output shows, we just need to cast the `dict`s year attributes to integers
    to make `nobel_winners` conform to the chapter’s target data ([Example 3-1](#data_dummydata)),
    thus:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'For more flexibility we can easily create a Python `datetime` from the year
    column:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `csv` readers don’t infer datatypes from your file, and instead interpret
    everything as a string. pandas, Python’s preeminent data-hacking library, will
    try to guess the correct type of the data columns, usually successfully. We’ll
    see this in action in the later dedicated pandas chapters.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '`csv` has a few useful arguments to help parse members of the CSV family:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '`dialect`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: By default, `'excel'`; specifies a set of dialect-specific parameters. `excel-tab`
    is a sometimes-used alternative.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '`delimiter`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Files are usually comma-separated, but they could use `|`, `:` or `' '` instead.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '`quotechar`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: By default, double quotes are used, but you occasionally find `|` or `` ` ``
    instead.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: You can find the full set of `csv` parameters in the [online Python docs](https://oreil.ly/9zZvt).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve successfully written and read our target data using the `csv`
    module, let’s pass on our CSV-derived `nobel_winners` `dict` to the `json` module.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: JSON
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we’ll write and read our `nobel_winners` data using Python’s
    `json` module. Let’s remind ourselves of the data we’re using:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'For data primitives such as strings, integers, and floats, Python dictionaries
    are easily saved (or *dumped*, in the JSON vernacular) into JSON files, using
    the `json` module. The `dump` method takes a Python container and a file pointer,
    saving the former to the latter:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Reading (or loading) a JSON file is just as easy. We just pass the opened JSON
    file to the `json` module’s `load` method:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO5-1)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Note that, unlike in our CSV file conversion, the integer type of the year column
    is preserved.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '`json` has the methods `loads` and `dumps`, which are counterparts to the file
    access methods, loading JSON strings to Python containers and dumping Python containers
    to JSON strings.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with Dates and Times
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Trying to dump a `datetime` object to `json` produces a `TypeError`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When serializing simple datatypes such as strings or numbers, the default `json`
    encoders and decoders are fine. But for more specialized data such as dates, you
    will need to do your own encoding and decoding. This isn’t as hard as it sounds
    and quickly becomes routine. Let’s first look at encoding your Python [`datetime`s](https://oreil.ly/aHI4h)
    into sensible JSON strings.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to encode Python data containing `datetime`s is to create a
    custom encoder like the one shown in [Example 3-2](#data_json_time), which is
    provided to the `json.dumps` method as a `cls` argument. This encoder is applied
    to each object in your data in turn and converts dates or datetimes to their ISO-format
    string (see [“Dealing with Dates, Times, and Complex Data”](#sect_datetimes)).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-2\. Encoding a Python `datetime` to JSON
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO6-1)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Subclasses a `JSONEncoder` in order to create a customized date-handling one.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO6-2)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Tests for a `datetime` object and if true, returns the `isoformat` of any dates
    or datetimes (e.g., 2021-11-16T16:41:14.650802).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO6-3)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Uses the `cls` argument to set a custom date encoder.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see how our new `dumps` method copes with some `datetime` data:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `time` field is correctly converted into an ISO-format string, ready to
    be decoded into a JavaScript `Date` object (see [“Dealing with Dates, Times, and
    Complex Data”](#sect_datetimes) for a demonstration).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: While you could write a generic decoder to cope with date strings in arbitrary
    JSON files,^([2](ch03.xhtml#idm45607797415616)) it’s probably not advisable. Date
    strings come in so many weird and wonderful varieties that this is a job best
    done by hand on what is pretty much always a known dataset.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'The venerable `strptime` method, part of the `datetime.datetime` package, is
    good for the job of turning a time string in a known format into a Python `datetime`
    instance:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO7-1)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '`strptime` tries to match the time string to a format string using various
    directives such as `%Y` (year with century) and `%H` (hour as a zero-padded decimal
    number). If successful, it creates a Python `datetime` instance. See [the Python
    docs](https://oreil.ly/Fi40k) for a full list of the directives available.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'If `strptime` is fed a time string that does not match its format, it throws
    a handy `ValueError`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'So to convert date fields of a known format into `datetime`s for a `data` list
    of dictionaries, you could do something like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now that we’ve dealt with the two most popular data file formats, let’s shift
    to the big guns and see how to read our data from and write our data to SQL and
    NoSQL databases.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: SQL
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For interacting with an SQL database, SQLAlchemy is the most popular and, in
    my opinion, best Python library. It allows you to use raw SQL instructions if
    speed and efficiency is an issue, but also provides a powerful object-relational
    mapping (ORM) that allows you to operate on SQL tables using a high-level, Pythonic
    API, treating them essentially as Python classes.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'Reading and writing data using SQL while allowing the user to treat that data
    as a Python container is a complicated process, and though SQLAlchemy is considerably
    more user-friendly than a low-level SQL engine, it is still a fairly complex library.
    I’ll cover the basics here, using our data as a target, but encourage you to spend
    a little time reading some of the rather excellent documentation on [SQLAlchemy](https://oreil.ly/mCHr8).
    Let’s remind ourselves of the `nobel_winners` dataset we’re aiming to write and
    read:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Let’s first write our target data to an SQLite file using SQLAlchemy, starting
    by creating the database engine.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Database Engine
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first thing you need to do when starting an SQLAlchemy session is to create
    a database engine. This engine will establish a connection with the database in
    question and perform any conversions needed to the generic SQL instructions generated
    by SQLAlchemy and the data being returned.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: There are engines for pretty much every popular database, as well as a *memory*
    option, which holds the database in RAM, allowing fast access for testing.^([3](ch03.xhtml#idm45607796976800))
    The great thing about these engines is that they are interchangeable, which means
    you could develop your code using the convenient file-based SQLite database and
    then switch during production to something a little more industrial, such as PostgreSQL,
    by changing a single config string. Check [SQLAlchemy](https://oreil.ly/QmIj6)
    for the full list of engines available.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'The form for specifying a database URL is:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: So, to connect to a `'nobel_winners'` MySQL database running on localhost requires
    something like the following. Note that `create_engine` does not actually make
    any SQL requests at this point, but merely sets up the framework for doing so:^([4](ch03.xhtml#idm45607796966400))
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，要连接到运行在本地主机上的 `'nobel_winners'` MySQL 数据库，需要类似以下方式。请注意，在此时 `create_engine`
    并没有真正发出任何 SQL 请求，而只是为执行这些请求设置了框架:^([4](ch03.xhtml#idm45607796966400))
- en: '[PRE23]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We’ll use a file-based SQLite database, setting the `echo` argument to `True`,
    which will output any SQL instructions generated by SQLAlchemy. Note the use of
    three backslashes after the colon:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用基于文件的 SQLite 数据库，并将 `echo` 参数设置为 `True`，这样 SQLAlchemy 生成的任何 SQL 指令都会输出。请注意冒号后面的三个反斜杠的用法：
- en: '[PRE24]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: SQLAlchemy offers various ways to engage with databases, but I recommend using
    the more recent declarative style unless there are good reasons to go with something
    more low-level and fine-grained. In essence, with declarative mapping, you subclass
    your Python SQL-table classes from a base, and SQLAlchemy introspects their structure
    and relationships. See [SQLAlchemy](https://oreil.ly/q3IZf) for more details.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: SQLAlchemy 提供了多种与数据库交互的方式，但我建议使用更近代的声明式风格，除非有充分理由选择更低级和细粒度的方法。本质上，使用声明式映射，您可以从一个基类子类化您的
    Python SQL 表类，并让 SQLAlchemy 自动检查它们的结构和关系。详细信息请参阅 [SQLAlchemy](https://oreil.ly/q3IZf)。
- en: Defining the Database Tables
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义数据库表
- en: 'We first create a `Base` class using `declarative_base`. This base will be
    used to create table classes, from which SQLAlchemy will create the database’s
    table schemas. You can use these table classes to interact with the database in
    a fairly Pythonic fashion:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用 `declarative_base` 创建一个 `Base` 类。这个基类将用于创建表类，从而让 SQLAlchemy 创建数据库的表结构。您可以使用这些表类以相当
    Pythonic 的方式与数据库交互：
- en: '[PRE25]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note that most SQL libraries require you to formally define table schemas. This
    is in contrast to such schema-less NoSQL variants as MongoDB. We’ll take a look
    at the Dataset library later in this chapter, which enables schemaless SQL.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，大多数 SQL 库要求您正式定义表结构。这与无模式 NoSQL 变体如 MongoDB 相反。本章后面我们将看到 Dataset 库，它支持无模式
    SQL。
- en: Using this `Base`, we define our various tables—in our case, a single `Winner`
    table. [Example 3-3](#data_sql_base) shows how to subclass `Base` and use SQLAlchemy’s
    datatypes to define a table schema. Note the `__tablename__` member, which will
    be used to name the SQL table and as a keyword to retrieve it, and the optional
    custom `__repr__` method, which will be used when printing a table row.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个 `Base`，我们定义我们的各种表，例如我们的单个 `Winner` 表。[示例 3-3](#data_sql_base) 展示了如何子类化
    `Base` 并使用 SQLAlchemy 的数据类型来定义表结构。请注意 `__tablename__` 成员，它将用于命名 SQL 表和作为检索它的关键字，还有可选的自定义
    `__repr__` 方法，用于在打印表行时使用。
- en: Example 3-3\. Defining an SQL database table
  id: totrans-126
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-3\. 定义 SQL 数据库表
- en: '[PRE26]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Having declared our `Base` subclass in [Example 3-3](#data_sql_base), we supply
    its `metadata` `create_all` method with our database engine to create our database.^([5](ch03.xhtml#idm45607796702064))
    Because we set the `echo` argument to `True` when creating the engine, we can
    see the SQL instructions generated by SQLAlchemy from the command line:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 3-3](#data_sql_base) 中声明了我们的 `Base` 子类后，我们使用其 `metadata` 的 `create_all`
    方法和我们的数据库引擎来创建我们的数据库。因为在创建引擎时设置了 `echo` 参数为 `True`，所以我们可以从命令行看到 SQLAlchemy 生成的
    SQL 指令：
- en: '[PRE27]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: With our new `winners` table declared, we can start adding winner instances
    to it.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们新声明的 `winners` 表，我们可以开始向其中添加获奖者实例。
- en: Adding Instances with a Session
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用会话添加实例
- en: 'Now that we have created our database, we need a session to interact with:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了我们的数据库，我们需要一个会话来进行交互：
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We can now use our `Winner` class to create instances and table rows and add
    them to the session:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用我们的 `Winner` 类创建实例和表行，并将它们添加到会话中：
- en: '[PRE29]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO8-1)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO8-1)'
- en: 'Python’s handy ** operator unpacks our first `nobel_winners` member into key-value
    pairs: `(name=''Albert Einstein'', category=''Physics''...)`.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的便捷 ** 操作符将我们的第一个 `nobel_winners` 成员解包为键值对：`(name='Albert Einstein',
    category='Physics'...)`。
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO8-2)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO8-2)'
- en: '`new` is the set of any items that have been added to this session.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`new` 是任何已添加到此会话中的项目的集合。'
- en: Note that all database insertions and deletions take place in Python. It’s only
    when we use the `commit` method that the database is altered.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Use as few commits as possible, allowing SQLAlchemy to work its magic behind
    the scenes. When you commit, your various database manipulations should be summarized
    by SQLAlchemy and communicated in an efficient fashion. Commits involve establishing
    a database handshake and negotiating transactions, which is often a slow process
    and one you want to limit as much as possible, leveraging SQLAlchemy’s bookkeeping
    abilities to full advantage.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'As the `new` method shows, we have added a `Winner` to the session. We can
    remove the object using `expunge`, leaving an empty `IdentitySet`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO9-1)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Removes the instance from the session (there is an `expunge_all` method that
    removes all new objects added to the session).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, no database insertions or deletions have taken place. Let’s
    add all the members of our `nobel_winners` list to the session and commit them
    to the database:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Now that we’ve committed our `nobel_winners` data to the database, let’s see
    what we can do with it and how to re-create the target list in [Example 3-1](#data_dummydata).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Querying the Database
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To access data, you use the `session`’s `query` method, the result of which
    can be filtered, grouped, and intersected, allowing the full range of standard
    SQL data retrieval. You can check out available querying methods in the [SQLAlchemy
    docs](https://oreil.ly/2rEB4). For now, I’ll quickly run through some of the most
    common queries on our Nobel dataset.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first count the number of rows in our winners table:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, let’s retrieve all Swiss winners:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO10-1)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '`filter_by` uses keyword expressions; its SQL expressions counterpart is `filter`—for
    example, `filter(Winner.nationality == *Swiss*)`. Note the Boolean equivalence
    `==` used in `filter`.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s get all non-Swiss physics winners:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Here’s how to get a row based on ID number:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now let’s retrieve winners ordered by year:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: To reconstruct our target list requires a little effort when converting the
    `Winner` objects returned by our session query into Python `dict`s. Let’s write
    a little function to create a `dict` from an SQLAlchemy class. We’ll use a little
    table introspection to get the column labels (see [Example 3-4](#data_to_dict)).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-4\. Converts an SQLAlchemy instance to a `dict`
  id: totrans-165
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO11-1)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Accesses the instance’s table class to get a list of column objects.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO11-2)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: If `delete_id` is true, remove the SQL primary ID field.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use [Example 3-4](#data_to_dict) to reconstruct our `nobel_winners`
    target list:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'You can update database rows easily by changing the property of their reflected
    objects:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO12-1)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Fetches Marie Curie, nationality Polish.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO12-2)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '`dirty` shows any changed instances not yet committed to the database.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s commit `Marie`’s changes and check that her nationality has changed from
    Polish to French:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'In addition to updating database rows, you can delete the results of a query:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'You can also drop the whole table if required, using the declarative class’s
    `__table__` attribute:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In this section, we’ve dealt with a single winners table, without any foreign
    keys or relationship to any other tables, akin to a CSV or JSON file. SQLAlchemy
    adds the same level of convenience in dealing with many-to-one, one-to-many, and
    other database table relationships as it does to basic querying using implicit
    joins, by supplying the `query` method with more than one table class or explicitly
    using the query’s `join` method. Check out the examples [in the SQLAlchemy docs](https://oreil.ly/6KFCf)
    for more details.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Easier SQL with Dataset
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One library I’ve found myself using a fair deal recently is [Dataset](https://oreil.ly/aGqTL),
    a module designed to make working with SQL databases a little easier and more
    Pythonic than existing powerhouses like SQLAlchemy.^([6](ch03.xhtml#idm45607795314160))
    Dataset tries to provide the same degree of convenience you get when working with
    schema-less NoSQL databases such as MongoDB by removing a lot of the formal boilerplate,
    such as schema definitions, which are demanded by the more conventional libraries.
    Dataset is built on top of SQLAlchemy, which means it works with pretty much all
    major databases and can exploit the power, robustness, and maturity of that best-of-breed
    library. Let’s see how it deals with reading and writing our target dataset (from
    [Example 3-1](#data_dummydata)).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use the SQLite *nobel_winners.db* database we’ve just created to put
    Dataset through its paces. First, we connect to our SQL database, using the same
    URL/file format as SQLAlchemy:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'To get our list of winners, we grab a table from our `db` database, using its
    name as a key, and then use the `find` method without arguments to return all
    winners:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Note that the instances returned by Dataset’s `find` method are `OrderedDict`s.
    These useful containers are an extension of Python’s `dict` class and behave just
    like dictionaries except that they remember the order in which items were inserted,
    meaning you can guarantee the result of iteration, pop the last item inserted,
    and more. This is a very handy additional functionality.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-193
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: One of the most useful Python “batteries” for data manipulators is `collections`,
    which is where Dataset’s `OrderedDict`s come from. The `defaultdict` and `Counter`
    classes are particularly useful. Check out what’s available in the [Python docs](https://oreil.ly/Vh4EF).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据处理者来说，最有用的Python“内置工具”之一是`collections`，其中包括数据集的`OrderedDict`。`defaultdict`和`Counter`类特别有用。请查看[Python文档](https://oreil.ly/Vh4EF)中提供的内容。
- en: 'Let’s re-create our winners table with Dataset, first dropping the existing
    one:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Dataset重新创建我们的获奖者表，首先删除现有表：
- en: '[PRE45]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: To re-create our dropped winners table, we don’t need to define a schema as
    with SQLAlchemy (see [“Defining the Database Tables”](#sql_schema)). Dataset will
    infer that from the data we add, doing all the SQL creation implicitly. This is
    the kind of convenience one is used to when working with collection-based NoSQL
    databases. Let’s use our `nobel_winners` dataset ([Example 3-1](#data_dummydata))
    to insert some winner dictionaries. We use a database transaction and the `with`
    statement to efficiently insert our objects and then commit them:^([7](ch03.xhtml#idm45607795163536))
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 要重新创建我们删除的获奖者表，我们不需要像SQLAlchemy那样定义模式（请参阅[“定义数据库表”](#sql_schema)）。Dataset将从我们添加的数据中推断出模式，并隐式执行所有SQL创建。这是在使用基于集合的NoSQL数据库时所习惯的方便之一。让我们使用我们的`nobel_winners`数据集（[示例 3-1](#data_dummydata)）来插入一些获奖者字典。我们使用数据库事务和`with`语句来高效地插入对象，然后提交它们：^([7](ch03.xhtml#idm45607795163536))
- en: '[PRE46]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO13-1)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO13-1)'
- en: Use the `with` statement to guarantee the transaction `tx` is committed to the
    database.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`with`语句确保事务`tx`提交到数据库。
- en: 'Let’s check that everything has gone well:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一切是否顺利进行：
- en: '[PRE47]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The winners have been correctly inserted and their order of insertion preserved
    by the `OrderedDict`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 获奖者已经被正确插入，并且它们的插入顺序被`OrderedDict`保留。
- en: Dataset is great for basic SQL-based work, particularly retrieving data you
    might wish to process or visualize. For more advanced manipulation, it allows
    you to drop down into SQLAlchemy’s core API using the `query` method.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集非常适合基于SQL的基本工作，特别是检索您可能希望处理或可视化的数据。对于更高级的操作，它允许您使用`query`方法进入SQLAlchemy的核心API。
- en: Now that we’ve covered the basics of working with SQL databases, let’s see how
    Python makes working with the most popular NoSQL database just as painless.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了使用SQL数据库的基础知识，让我们看看Python如何使得与最流行的NoSQL数据库一样轻松。
- en: MongoDB
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MongoDB
- en: Document-centric datastores like MongoDB offer a lot of convenience to data
    wranglers. As with all tools, there are good and bad use cases for NoSQL databases.
    If you have data that has already been refined and processed and don’t anticipate
    needing SQL’s powerful query language based on optimized table joins, MongoDB
    will probably prove easier to work with initially. MongoDB is a particularly good
    fit for web dataviz because it uses binary JSON (BSON) as its data format. An
    extension of JSON, BSON can deal with binary data and `datetime` objects, and
    plays very nicely with JavaScript.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 像MongoDB这样以文档为中心的数据存储为数据处理者提供了很多便利。与所有工具一样，NoSQL数据库有好的和坏的用例。如果您的数据已经经过精炼和处理，并且不预期需要基于优化表连接的SQL强大查询语言，那么MongoDB可能最初会更容易使用。MongoDB非常适合Web数据可视化，因为它使用二进制JSON（BSON）作为其数据格式。BSON是JSON的扩展，可以处理二进制数据和`datetime`对象，并且与JavaScript非常兼容。
- en: 'Let’s remind ourselves of the target dataset we’re aiming to write and read:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次回顾一下我们要写入和读取的目标数据集：
- en: '[PRE48]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Creating a MongoDB collection with Python is the work of a few lines:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python创建MongoDB集合只需几行代码：
- en: '[PRE49]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO14-1)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO14-1)'
- en: Creates a Mongo client, using the default host and ports.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 创建Mongo客户端，使用默认主机和端口。
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO14-2)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO14-2)'
- en: Creates or accesses the `nobel_prize` database.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 创建或访问`nobel_prize`数据库。
- en: '[![3](assets/3.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO14-3)'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO14-3)'
- en: If a winners collection exists, this will retrieve it; otherwise (as in our
    case), it creates it.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果获奖者集合存在，则将其检索出来；否则（如我们的情况），它会创建它。
- en: MongoDB databases run on localhost port 27017 by default but could be anywhere
    on the web. They also take an optional username and password. [Example 3-5](#data_get_mongo)
    shows how to create a simple utility function to access our database, with standard
    defaults.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-5\. Accessing a MongoDB database
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO15-1)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: We specify the database name in the MongoDB URI (Uniform Resource Identifier)
    as the user may not have general privileges for the database.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now create a Nobel Prize database and add our target dataset ([Example 3-1](#data_dummydata)).
    Let’s first get a winners collection, using the string constants for access:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Inserting our Nobel Prize dataset is then as easy as can be:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: The resulting array of `ObjectId`s can be used for future retrieval, but MongoDB
    has already left its stamp on our `nobel_winners` list, adding a hidden `id` property.^([8](ch03.xhtml#idm45607794582448))
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'MongoDB’s `ObjectId`s have quite a bit of hidden functionality, being a lot
    more than a simple random identifier. You can, for example, get the generation
    time of the `ObjectId`, which gives you access to a handy timestamp:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Find the full details in the [MongoDB BSON documentation](https://oreil.ly/NBwsk).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve got some items in our winners collection, MongoDB makes finding
    them very easy, with its `find` method taking a dictionary query:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'There are a number of special dollar-prefixed operators that allow for sophisticated
    querying. Let’s find all the winners after 1930 using the `$gt` (greater-than)
    operator:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'You can also use a Boolean expression, for instance, to find all winners after
    1930 or all female winners:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: You can find the full list of available query expressions in the [MongoDB documentation](https://oreil.ly/1D2Sr).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final test, let’s turn our new winners collection back into a Python list
    of dictionaries. We’ll create a utility function for the task:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO16-1)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: An empty `query dict {}` will find all documents in the collection. `del_id`
    is a flag to remove MongoDB’s `ObjectId`s from the items by default.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now create our target dataset:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: MongoDB’s schema-less databases are great for fast prototyping in solo work
    or small teams. There will probably come a point, particularly with large codebases,
    when a formal schema becomes a useful reference and sanity check; when you are
    choosing a data model, the ease with which document forms can be adapted is a
    bonus. Being able to pass Python dictionaries as queries to PyMongo and having
    access to client-side generated `ObjectId`s are a couple of other conveniences.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now passed the `nobel_winners` data in [Example 3-1](#data_dummydata)
    through all our required file formats and databases. Let’s consider the special
    case of dealing with dates and times before summing up.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with Dates, Times, and Complex Data
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The ability to deal comfortably with dates and times is fundamental to dataviz
    work but can be quite tricky. There are many ways to represent a date or datetime
    as a string, each one requiring a separate encoding or decoding. For this reason
    it’s good to settle on one format in your own work and encourage others to do
    the same. I recommend using the [International Standard Organization (ISO) 8601
    time format](https://oreil.ly/HePpN) as your string representation for dates and
    times, and using the [Coordinated Universal Time (UTC) form](https://oreil.ly/neP2I).^([9](ch03.xhtml#idm45607794006016))
    Here are a few examples of ISO 8601 date and datetime strings:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '| 2021-09-23 | A date (Python/C format code `''%Y-%m-%d''`) |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
- en: '| 2021-09-23T16:32:35Z | A UTC (*Z* after time) date and time (`''T%H:%M:%S''`)
    |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
- en: '| 2021-09-23T16:32+02:00 | A positive two-hour (+02:00) offset from UTC (e.g.,
    Central European Time) |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
- en: Note the importance of being prepared to deal with different time zones. These
    are not always on lines of longitude (see [Wikipedia’s Time Zone entry](https://oreil.ly/NZyE4)),
    and often the best way to derive an accurate time is by using UTC time plus a
    geographic location.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: ISO 8601 is the standard used by JavaScript and is easy to work with in Python.
    As web data visualizers, our key concern is in creating a string representation
    that can be passed between Python and JavaScript using JSON and encoded and decoded
    easily at both ends.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a date and time in the shape of a Python `datetime`, convert it into
    a string, and then see how that string can be consumed by JavaScript.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we produce our Python `datetime`:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'This string can then be saved to JSON or CSV, read by JavaScript, and used
    to create a `Date` object:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'We can return the datetime to ISO 8601 string form with the `toISOString` method:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Finally, we can read the string back into Python.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: 'If you know that you’re dealing with an ISO-format time string, Python’s `dateutil`
    module should do the job.^([10](ch03.xhtml#idm45607793910272)) But you’ll probably
    want to sanity check the result:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Note that we’ve lost some resolution in the trip from Python to JavaScript and
    back again, the latter dealing in milliseconds, not microseconds. This is unlikely
    to be an issue in any dataviz work but is good to bear in mind just in case some
    strange temporal errors occur.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter aimed to make you comfortable using Python to move data around
    the various file formats and databases that a data visualizer might expect to
    bump into. Using databases effectively and efficiently is a skill that takes a
    while to learn, but you should now be comfortable with basic reading and writing
    for the large majority of dataviz use cases.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the vital lubrication for our dataviz toolchain, let’s get
    up to scratch on the basic web development skills you’ll need for the chapters
    ahead.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch03.xhtml#idm45607798394048-marker)) I recommend using JSON over CSV
    as your preferred data format.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.xhtml#idm45607798394048-marker)) 我建议您将JSON作为首选数据格式，而不是CSV。
- en: ^([2](ch03.xhtml#idm45607797415616-marker)) The Python module `dateutil` has
    a parser that will parse most dates and times sensibly, and might be a good basis
    for this.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch03.xhtml#idm45607797415616-marker)) Python模块`dateutil`有一个解析器，可以合理地解析大多数日期和时间，可能是此操作的良好基础。
- en: ^([3](ch03.xhtml#idm45607796976800-marker)) On a cautionary note, it is probably
    a bad idea to use different database configurations for testing and production.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch03.xhtml#idm45607796976800-marker)) 值得注意的是，在测试和生产环境中使用不同的数据库配置可能是个坏主意。
- en: ^([4](ch03.xhtml#idm45607796966400-marker)) See details on [SQLAlchemy](https://oreil.ly/winYu)
    of this *lazy initialization*.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch03.xhtml#idm45607796966400-marker)) 查看关于[SQLAlchemy](https://oreil.ly/winYu)的详细信息，了解*延迟初始化*。
- en: ^([5](ch03.xhtml#idm45607796702064-marker)) This assumes the database doesn’t
    already exist. If it does, `Base` will be used to create new insertions and to
    interpret retrievals.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch03.xhtml#idm45607796702064-marker)) 这假设数据库尚不存在。如果存在，则将使用`Base`来创建新的插入和解释检索。
- en: '^([6](ch03.xhtml#idm45607795314160-marker)) Dataset’s official motto is “Databases
    for lazy people.” It is not part of the standard Anaconda package, so you’ll want
    to install it using `pip` from the command line: `$ pip install dataset`.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch03.xhtml#idm45607795314160-marker)) Dataset的官方座右铭是“懒人数据库”。它不是标准Anaconda包的一部分，因此您需要通过命令行使用`pip`进行安装：`$
    pip install dataset`。
- en: ^([7](ch03.xhtml#idm45607795163536-marker)) See [this documentation](https://oreil.ly/vqvbv)
    for further details of how to use transactions to group updates.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch03.xhtml#idm45607795163536-marker)) 详细了解如何使用事务来分组更新，请参阅[此文档](https://oreil.ly/vqvbv)。
- en: ^([8](ch03.xhtml#idm45607794582448-marker)) One of the cool things about MongoDB
    is that the `ObjectId`s are generated on the client side, removing the need to
    quiz the database for them.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch03.xhtml#idm45607794582448-marker)) MongoDB的一个很酷的特性是`ObjectId`在客户端生成，无需查询数据库获取它们。
- en: ^([9](ch03.xhtml#idm45607794006016-marker)) To get the actual local time from
    UTC, you can store a time zone offset or, better still, derive it from a geocoordinate;
    this is because time zones do not follow lines of longitude very exactly.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch03.xhtml#idm45607794006016-marker)) 要从UTC获取实际本地时间，可以存储时区偏移量或更好地从地理坐标派生；这是因为时区并不完全按经度线精确地遵循。
- en: ^([10](ch03.xhtml#idm45607793910272-marker)) To install, just run `pip install
    python-dateutil`. `dateutil` is a pretty powerful extension of Python’s `datetime`;
    check it out on [Read the Docs](https://oreil.ly/y6YWS).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch03.xhtml#idm45607793910272-marker)) 要安装，只需运行`pip install python-dateutil`。`dateutil`是Python的`datetime`的一个相当强大的扩展；详细信息请查看[Read
    the Docs](https://oreil.ly/y6YWS)。
