- en: Chapter 3\. Reading and Writing Data with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the fundamental skills of any data visualizer is the ability to move
    data around. Whether your data is in an SQL database, a comma-separated value
    (CSV) file, or in some more esoteric form, you should be comfortable reading the
    data, converting it, and writing it into a more convenient form if need be. One
    of Python’s great strengths is how easy it makes manipulating data in this way.
    The focus of this chapter is to bring you up to speed with this essential aspect
    of our dataviz toolchain.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is part tutorial, part reference, and sections of it will be referred
    to in later chapters. If you know the fundamentals of reading and writing Python
    data, you can cherry-pick parts of the chapter as a refresher.
  prefs: []
  type: TYPE_NORMAL
- en: Easy Does It
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I remember when I started programming back in the day (using low-level languages
    like C) how awkward data manipulation was. Reading from and writing to files was
    an annoying mixture of boilerplate code, hand-rolled improvisations, and the like.
    Reading from databases was equally difficult, and as for serializing data, the
    memories are still painful. Discovering Python was a breath of fresh air. It wasn’t
    a speed demon, but opening a file was pretty much as simple as it could be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Back then, Python made reading from and writing to files refreshingly easy,
    and its sophisticated string processing made parsing the data in those files just
    as easy. It even had an amazing module called Pickle that could serialize pretty
    much any Python object.
  prefs: []
  type: TYPE_NORMAL
- en: In the years since, Python has added robust, mature modules to its standard
    library that make dealing with CSV and JSON files, the standard for web dataviz
    work, just as easy. There are also some great libraries for interacting with SQL
    databases such as SQLAlchemy, my thoroughly recommended go-to. The newer NoSQL
    databases are also well served. MongoDB is the most popular of these newer document-based
    databases, and Python’s PyMongo library, which is demonstrated later in the chapter,
    makes interacting with it a relative breeze.
  prefs: []
  type: TYPE_NORMAL
- en: Passing Data Around
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good way to demonstrate how to use the key data-storage libraries is to pass
    a single data packet among them, reading and writing it as we go. This will give
    us an opportunity to see in action the key data formats and databases employed
    by data visualizers.
  prefs: []
  type: TYPE_NORMAL
- en: The data we’ll be passing around is probably the most commonly used in web visualizations,
    a list of dictionary-like objects (see [Example 3-1](#data_dummydata)). This dataset
    is transferred to the browser in [JSON form](https://oreil.ly/JgjAp), which is,
    as we’ll see, easily converted from a Python dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-1\. Our target list of data objects
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We’ll start by creating a CSV file from the Python list shown in [Example 3-1](#data_dummydata)
    as a demonstration of reading (opening) and writing system files.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections assume you’re in a working (root) directory with a *data*
    subdirectory at hand. You can run the code from a Python interpreter or file.
  prefs: []
  type: TYPE_NORMAL
- en: Working with System Files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll create a CSV file from a Python list of dictionaries
    ([Example 3-1](#data_dummydata)). Typically, you would do this using the `csv`
    module, which we’ll demonstrate after this section, so this is just a way of demonstrating
    basic Python file manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s open a new file, using `w` as a second argument to indicate we’ll
    be writing data to it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we’ll create our CSV file from the `nobel_winners` dictionary ([Example 3-1](#data_dummydata)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Gets our data columns from the keys of the first object (i.e., `['category',
    'name', ... ]`).
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Sorts the columns in alphabetical order.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Uses Python’s `with` statement to guarantee the file is closed on leaving the
    block or if any exceptions occur.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO1-4)'
  prefs: []
  type: TYPE_NORMAL
- en: '`join` creates a concatenated string from a list of strings (`cols` here),
    joined by the initial string (i.e., “category,name,..”).'
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO1-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Creates a list using the column keys to the objects in `nobel_winners`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve created our CSV file, let’s use Python to read it and make sure
    everything is correct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As the previous output shows, our CSV file is well formed. Let’s use Python’s
    built-in `csv` module to first read it and then create a CSV file the right way.
  prefs: []
  type: TYPE_NORMAL
- en: CSV, TSV, and Row-Column Data Formats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Comma-separated values (CSV) or their tab-separated cousins (TSV) are probably
    the most ubiquitous file-based data formats and, as a data visualizer, these will
    often be the forms you’ll receive to work your magic with. Being able to read
    and write CSV files and their various quirky variants, such as pipe- or semicolon-separated
    or those using *`* in place of the standard double quotes, is a fundamental skill;
    Python’s `csv` module is capable of doing pretty much all your heavy lifting here.
    Let’s put it through its paces reading and writing our `nobel_winners` data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Writing our `nobel_winners` data (see [Example 3-1](#data_dummydata)) to a
    CSV file is a pretty simple affair. `csv` has a dedicated `DictWriter` class that
    will turn our dictionaries into CSV rows. The only piece of explicit bookkeeping
    we have to do is write a header to our CSV file, using the keys of our dictionaries
    as fields (i.e., “category, name, nationality, gender”):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: You need to explicitly tell the writer which `fieldnames` to use (in this case,
    the `'category'`, `'name'`, etc., keys).
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll sort the CSV header fields alphabetically for readability.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO2-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Writes the CSV-file header (“category, name,…​”).
  prefs: []
  type: TYPE_NORMAL
- en: You’ll probably be reading CSV files more often than writing them.^([1](ch03.xhtml#idm45607798394048))
    Let’s read back the *nobel_winners.csv* file we just wrote.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you just want to use `csv` as a superior and eminently adaptable file line
    reader, a couple of lines will produce a handy iterator, which can deliver your
    CSV rows as lists of strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Iterates over the `reader` object, consuming the lines in the file.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the numbers are read in string form. If you want to manipulate them
    numerically, you’ll need to convert any numeric columns to their respective type,
    which is integer years in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'A more convenient way to consume CSV data is to convert the rows into Python
    dictionaries. This *record* form is also the one we are using as our conversion
    target (a `list` of `dict`s). `csv` has a handy `DictReader` for just this purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO4-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Inserts all of the `reader` items into a list.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the output shows, we just need to cast the `dict`s year attributes to integers
    to make `nobel_winners` conform to the chapter’s target data ([Example 3-1](#data_dummydata)),
    thus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'For more flexibility we can easily create a Python `datetime` from the year
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `csv` readers don’t infer datatypes from your file, and instead interpret
    everything as a string. pandas, Python’s preeminent data-hacking library, will
    try to guess the correct type of the data columns, usually successfully. We’ll
    see this in action in the later dedicated pandas chapters.
  prefs: []
  type: TYPE_NORMAL
- en: '`csv` has a few useful arguments to help parse members of the CSV family:'
  prefs: []
  type: TYPE_NORMAL
- en: '`dialect`'
  prefs: []
  type: TYPE_NORMAL
- en: By default, `'excel'`; specifies a set of dialect-specific parameters. `excel-tab`
    is a sometimes-used alternative.
  prefs: []
  type: TYPE_NORMAL
- en: '`delimiter`'
  prefs: []
  type: TYPE_NORMAL
- en: Files are usually comma-separated, but they could use `|`, `:` or `' '` instead.
  prefs: []
  type: TYPE_NORMAL
- en: '`quotechar`'
  prefs: []
  type: TYPE_NORMAL
- en: By default, double quotes are used, but you occasionally find `|` or `` ` ``
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the full set of `csv` parameters in the [online Python docs](https://oreil.ly/9zZvt).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve successfully written and read our target data using the `csv`
    module, let’s pass on our CSV-derived `nobel_winners` `dict` to the `json` module.
  prefs: []
  type: TYPE_NORMAL
- en: JSON
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we’ll write and read our `nobel_winners` data using Python’s
    `json` module. Let’s remind ourselves of the data we’re using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'For data primitives such as strings, integers, and floats, Python dictionaries
    are easily saved (or *dumped*, in the JSON vernacular) into JSON files, using
    the `json` module. The `dump` method takes a Python container and a file pointer,
    saving the former to the latter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Reading (or loading) a JSON file is just as easy. We just pass the opened JSON
    file to the `json` module’s `load` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO5-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Note that, unlike in our CSV file conversion, the integer type of the year column
    is preserved.
  prefs: []
  type: TYPE_NORMAL
- en: '`json` has the methods `loads` and `dumps`, which are counterparts to the file
    access methods, loading JSON strings to Python containers and dumping Python containers
    to JSON strings.'
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with Dates and Times
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Trying to dump a `datetime` object to `json` produces a `TypeError`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: When serializing simple datatypes such as strings or numbers, the default `json`
    encoders and decoders are fine. But for more specialized data such as dates, you
    will need to do your own encoding and decoding. This isn’t as hard as it sounds
    and quickly becomes routine. Let’s first look at encoding your Python [`datetime`s](https://oreil.ly/aHI4h)
    into sensible JSON strings.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to encode Python data containing `datetime`s is to create a
    custom encoder like the one shown in [Example 3-2](#data_json_time), which is
    provided to the `json.dumps` method as a `cls` argument. This encoder is applied
    to each object in your data in turn and converts dates or datetimes to their ISO-format
    string (see [“Dealing with Dates, Times, and Complex Data”](#sect_datetimes)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-2\. Encoding a Python `datetime` to JSON
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO6-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Subclasses a `JSONEncoder` in order to create a customized date-handling one.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO6-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Tests for a `datetime` object and if true, returns the `isoformat` of any dates
    or datetimes (e.g., 2021-11-16T16:41:14.650802).
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO6-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Uses the `cls` argument to set a custom date encoder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see how our new `dumps` method copes with some `datetime` data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `time` field is correctly converted into an ISO-format string, ready to
    be decoded into a JavaScript `Date` object (see [“Dealing with Dates, Times, and
    Complex Data”](#sect_datetimes) for a demonstration).
  prefs: []
  type: TYPE_NORMAL
- en: While you could write a generic decoder to cope with date strings in arbitrary
    JSON files,^([2](ch03.xhtml#idm45607797415616)) it’s probably not advisable. Date
    strings come in so many weird and wonderful varieties that this is a job best
    done by hand on what is pretty much always a known dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The venerable `strptime` method, part of the `datetime.datetime` package, is
    good for the job of turning a time string in a known format into a Python `datetime`
    instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO7-1)'
  prefs: []
  type: TYPE_NORMAL
- en: '`strptime` tries to match the time string to a format string using various
    directives such as `%Y` (year with century) and `%H` (hour as a zero-padded decimal
    number). If successful, it creates a Python `datetime` instance. See [the Python
    docs](https://oreil.ly/Fi40k) for a full list of the directives available.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If `strptime` is fed a time string that does not match its format, it throws
    a handy `ValueError`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'So to convert date fields of a known format into `datetime`s for a `data` list
    of dictionaries, you could do something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now that we’ve dealt with the two most popular data file formats, let’s shift
    to the big guns and see how to read our data from and write our data to SQL and
    NoSQL databases.
  prefs: []
  type: TYPE_NORMAL
- en: SQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For interacting with an SQL database, SQLAlchemy is the most popular and, in
    my opinion, best Python library. It allows you to use raw SQL instructions if
    speed and efficiency is an issue, but also provides a powerful object-relational
    mapping (ORM) that allows you to operate on SQL tables using a high-level, Pythonic
    API, treating them essentially as Python classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reading and writing data using SQL while allowing the user to treat that data
    as a Python container is a complicated process, and though SQLAlchemy is considerably
    more user-friendly than a low-level SQL engine, it is still a fairly complex library.
    I’ll cover the basics here, using our data as a target, but encourage you to spend
    a little time reading some of the rather excellent documentation on [SQLAlchemy](https://oreil.ly/mCHr8).
    Let’s remind ourselves of the `nobel_winners` dataset we’re aiming to write and
    read:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Let’s first write our target data to an SQLite file using SQLAlchemy, starting
    by creating the database engine.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Database Engine
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first thing you need to do when starting an SQLAlchemy session is to create
    a database engine. This engine will establish a connection with the database in
    question and perform any conversions needed to the generic SQL instructions generated
    by SQLAlchemy and the data being returned.
  prefs: []
  type: TYPE_NORMAL
- en: There are engines for pretty much every popular database, as well as a *memory*
    option, which holds the database in RAM, allowing fast access for testing.^([3](ch03.xhtml#idm45607796976800))
    The great thing about these engines is that they are interchangeable, which means
    you could develop your code using the convenient file-based SQLite database and
    then switch during production to something a little more industrial, such as PostgreSQL,
    by changing a single config string. Check [SQLAlchemy](https://oreil.ly/QmIj6)
    for the full list of engines available.
  prefs: []
  type: TYPE_NORMAL
- en: 'The form for specifying a database URL is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: So, to connect to a `'nobel_winners'` MySQL database running on localhost requires
    something like the following. Note that `create_engine` does not actually make
    any SQL requests at this point, but merely sets up the framework for doing so:^([4](ch03.xhtml#idm45607796966400))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll use a file-based SQLite database, setting the `echo` argument to `True`,
    which will output any SQL instructions generated by SQLAlchemy. Note the use of
    three backslashes after the colon:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: SQLAlchemy offers various ways to engage with databases, but I recommend using
    the more recent declarative style unless there are good reasons to go with something
    more low-level and fine-grained. In essence, with declarative mapping, you subclass
    your Python SQL-table classes from a base, and SQLAlchemy introspects their structure
    and relationships. See [SQLAlchemy](https://oreil.ly/q3IZf) for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Database Tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We first create a `Base` class using `declarative_base`. This base will be
    used to create table classes, from which SQLAlchemy will create the database’s
    table schemas. You can use these table classes to interact with the database in
    a fairly Pythonic fashion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Note that most SQL libraries require you to formally define table schemas. This
    is in contrast to such schema-less NoSQL variants as MongoDB. We’ll take a look
    at the Dataset library later in this chapter, which enables schemaless SQL.
  prefs: []
  type: TYPE_NORMAL
- en: Using this `Base`, we define our various tables—in our case, a single `Winner`
    table. [Example 3-3](#data_sql_base) shows how to subclass `Base` and use SQLAlchemy’s
    datatypes to define a table schema. Note the `__tablename__` member, which will
    be used to name the SQL table and as a keyword to retrieve it, and the optional
    custom `__repr__` method, which will be used when printing a table row.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-3\. Defining an SQL database table
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Having declared our `Base` subclass in [Example 3-3](#data_sql_base), we supply
    its `metadata` `create_all` method with our database engine to create our database.^([5](ch03.xhtml#idm45607796702064))
    Because we set the `echo` argument to `True` when creating the engine, we can
    see the SQL instructions generated by SQLAlchemy from the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: With our new `winners` table declared, we can start adding winner instances
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: Adding Instances with a Session
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have created our database, we need a session to interact with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now use our `Winner` class to create instances and table rows and add
    them to the session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO8-1)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Python’s handy ** operator unpacks our first `nobel_winners` member into key-value
    pairs: `(name=''Albert Einstein'', category=''Physics''...)`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO8-2)'
  prefs: []
  type: TYPE_NORMAL
- en: '`new` is the set of any items that have been added to this session.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that all database insertions and deletions take place in Python. It’s only
    when we use the `commit` method that the database is altered.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Use as few commits as possible, allowing SQLAlchemy to work its magic behind
    the scenes. When you commit, your various database manipulations should be summarized
    by SQLAlchemy and communicated in an efficient fashion. Commits involve establishing
    a database handshake and negotiating transactions, which is often a slow process
    and one you want to limit as much as possible, leveraging SQLAlchemy’s bookkeeping
    abilities to full advantage.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the `new` method shows, we have added a `Winner` to the session. We can
    remove the object using `expunge`, leaving an empty `IdentitySet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO9-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Removes the instance from the session (there is an `expunge_all` method that
    removes all new objects added to the session).
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, no database insertions or deletions have taken place. Let’s
    add all the members of our `nobel_winners` list to the session and commit them
    to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Now that we’ve committed our `nobel_winners` data to the database, let’s see
    what we can do with it and how to re-create the target list in [Example 3-1](#data_dummydata).
  prefs: []
  type: TYPE_NORMAL
- en: Querying the Database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To access data, you use the `session`’s `query` method, the result of which
    can be filtered, grouped, and intersected, allowing the full range of standard
    SQL data retrieval. You can check out available querying methods in the [SQLAlchemy
    docs](https://oreil.ly/2rEB4). For now, I’ll quickly run through some of the most
    common queries on our Nobel dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first count the number of rows in our winners table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let’s retrieve all Swiss winners:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO10-1)'
  prefs: []
  type: TYPE_NORMAL
- en: '`filter_by` uses keyword expressions; its SQL expressions counterpart is `filter`—for
    example, `filter(Winner.nationality == *Swiss*)`. Note the Boolean equivalence
    `==` used in `filter`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s get all non-Swiss physics winners:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s how to get a row based on ID number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s retrieve winners ordered by year:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: To reconstruct our target list requires a little effort when converting the
    `Winner` objects returned by our session query into Python `dict`s. Let’s write
    a little function to create a `dict` from an SQLAlchemy class. We’ll use a little
    table introspection to get the column labels (see [Example 3-4](#data_to_dict)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-4\. Converts an SQLAlchemy instance to a `dict`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO11-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Accesses the instance’s table class to get a list of column objects.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO11-2)'
  prefs: []
  type: TYPE_NORMAL
- en: If `delete_id` is true, remove the SQL primary ID field.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use [Example 3-4](#data_to_dict) to reconstruct our `nobel_winners`
    target list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'You can update database rows easily by changing the property of their reflected
    objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO12-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Fetches Marie Curie, nationality Polish.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO12-2)'
  prefs: []
  type: TYPE_NORMAL
- en: '`dirty` shows any changed instances not yet committed to the database.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s commit `Marie`’s changes and check that her nationality has changed from
    Polish to French:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to updating database rows, you can delete the results of a query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also drop the whole table if required, using the declarative class’s
    `__table__` attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we’ve dealt with a single winners table, without any foreign
    keys or relationship to any other tables, akin to a CSV or JSON file. SQLAlchemy
    adds the same level of convenience in dealing with many-to-one, one-to-many, and
    other database table relationships as it does to basic querying using implicit
    joins, by supplying the `query` method with more than one table class or explicitly
    using the query’s `join` method. Check out the examples [in the SQLAlchemy docs](https://oreil.ly/6KFCf)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Easier SQL with Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One library I’ve found myself using a fair deal recently is [Dataset](https://oreil.ly/aGqTL),
    a module designed to make working with SQL databases a little easier and more
    Pythonic than existing powerhouses like SQLAlchemy.^([6](ch03.xhtml#idm45607795314160))
    Dataset tries to provide the same degree of convenience you get when working with
    schema-less NoSQL databases such as MongoDB by removing a lot of the formal boilerplate,
    such as schema definitions, which are demanded by the more conventional libraries.
    Dataset is built on top of SQLAlchemy, which means it works with pretty much all
    major databases and can exploit the power, robustness, and maturity of that best-of-breed
    library. Let’s see how it deals with reading and writing our target dataset (from
    [Example 3-1](#data_dummydata)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use the SQLite *nobel_winners.db* database we’ve just created to put
    Dataset through its paces. First, we connect to our SQL database, using the same
    URL/file format as SQLAlchemy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'To get our list of winners, we grab a table from our `db` database, using its
    name as a key, and then use the `find` method without arguments to return all
    winners:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Note that the instances returned by Dataset’s `find` method are `OrderedDict`s.
    These useful containers are an extension of Python’s `dict` class and behave just
    like dictionaries except that they remember the order in which items were inserted,
    meaning you can guarantee the result of iteration, pop the last item inserted,
    and more. This is a very handy additional functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: One of the most useful Python “batteries” for data manipulators is `collections`,
    which is where Dataset’s `OrderedDict`s come from. The `defaultdict` and `Counter`
    classes are particularly useful. Check out what’s available in the [Python docs](https://oreil.ly/Vh4EF).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s re-create our winners table with Dataset, first dropping the existing
    one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: To re-create our dropped winners table, we don’t need to define a schema as
    with SQLAlchemy (see [“Defining the Database Tables”](#sql_schema)). Dataset will
    infer that from the data we add, doing all the SQL creation implicitly. This is
    the kind of convenience one is used to when working with collection-based NoSQL
    databases. Let’s use our `nobel_winners` dataset ([Example 3-1](#data_dummydata))
    to insert some winner dictionaries. We use a database transaction and the `with`
    statement to efficiently insert our objects and then commit them:^([7](ch03.xhtml#idm45607795163536))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO13-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Use the `with` statement to guarantee the transaction `tx` is committed to the
    database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check that everything has gone well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: The winners have been correctly inserted and their order of insertion preserved
    by the `OrderedDict`.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset is great for basic SQL-based work, particularly retrieving data you
    might wish to process or visualize. For more advanced manipulation, it allows
    you to drop down into SQLAlchemy’s core API using the `query` method.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve covered the basics of working with SQL databases, let’s see how
    Python makes working with the most popular NoSQL database just as painless.
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Document-centric datastores like MongoDB offer a lot of convenience to data
    wranglers. As with all tools, there are good and bad use cases for NoSQL databases.
    If you have data that has already been refined and processed and don’t anticipate
    needing SQL’s powerful query language based on optimized table joins, MongoDB
    will probably prove easier to work with initially. MongoDB is a particularly good
    fit for web dataviz because it uses binary JSON (BSON) as its data format. An
    extension of JSON, BSON can deal with binary data and `datetime` objects, and
    plays very nicely with JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s remind ourselves of the target dataset we’re aiming to write and read:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Creating a MongoDB collection with Python is the work of a few lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO14-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Creates a Mongo client, using the default host and ports.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO14-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Creates or accesses the `nobel_prize` database.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO14-3)'
  prefs: []
  type: TYPE_NORMAL
- en: If a winners collection exists, this will retrieve it; otherwise (as in our
    case), it creates it.
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB databases run on localhost port 27017 by default but could be anywhere
    on the web. They also take an optional username and password. [Example 3-5](#data_get_mongo)
    shows how to create a simple utility function to access our database, with standard
    defaults.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-5\. Accessing a MongoDB database
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO15-1)'
  prefs: []
  type: TYPE_NORMAL
- en: We specify the database name in the MongoDB URI (Uniform Resource Identifier)
    as the user may not have general privileges for the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now create a Nobel Prize database and add our target dataset ([Example 3-1](#data_dummydata)).
    Let’s first get a winners collection, using the string constants for access:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Inserting our Nobel Prize dataset is then as easy as can be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The resulting array of `ObjectId`s can be used for future retrieval, but MongoDB
    has already left its stamp on our `nobel_winners` list, adding a hidden `id` property.^([8](ch03.xhtml#idm45607794582448))
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'MongoDB’s `ObjectId`s have quite a bit of hidden functionality, being a lot
    more than a simple random identifier. You can, for example, get the generation
    time of the `ObjectId`, which gives you access to a handy timestamp:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Find the full details in the [MongoDB BSON documentation](https://oreil.ly/NBwsk).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve got some items in our winners collection, MongoDB makes finding
    them very easy, with its `find` method taking a dictionary query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a number of special dollar-prefixed operators that allow for sophisticated
    querying. Let’s find all the winners after 1930 using the `$gt` (greater-than)
    operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also use a Boolean expression, for instance, to find all winners after
    1930 or all female winners:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: You can find the full list of available query expressions in the [MongoDB documentation](https://oreil.ly/1D2Sr).
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final test, let’s turn our new winners collection back into a Python list
    of dictionaries. We’ll create a utility function for the task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_reading_and_writing_data__span_class__keep_together__with_python__span__CO16-1)'
  prefs: []
  type: TYPE_NORMAL
- en: An empty `query dict {}` will find all documents in the collection. `del_id`
    is a flag to remove MongoDB’s `ObjectId`s from the items by default.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now create our target dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: MongoDB’s schema-less databases are great for fast prototyping in solo work
    or small teams. There will probably come a point, particularly with large codebases,
    when a formal schema becomes a useful reference and sanity check; when you are
    choosing a data model, the ease with which document forms can be adapted is a
    bonus. Being able to pass Python dictionaries as queries to PyMongo and having
    access to client-side generated `ObjectId`s are a couple of other conveniences.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now passed the `nobel_winners` data in [Example 3-1](#data_dummydata)
    through all our required file formats and databases. Let’s consider the special
    case of dealing with dates and times before summing up.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with Dates, Times, and Complex Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The ability to deal comfortably with dates and times is fundamental to dataviz
    work but can be quite tricky. There are many ways to represent a date or datetime
    as a string, each one requiring a separate encoding or decoding. For this reason
    it’s good to settle on one format in your own work and encourage others to do
    the same. I recommend using the [International Standard Organization (ISO) 8601
    time format](https://oreil.ly/HePpN) as your string representation for dates and
    times, and using the [Coordinated Universal Time (UTC) form](https://oreil.ly/neP2I).^([9](ch03.xhtml#idm45607794006016))
    Here are a few examples of ISO 8601 date and datetime strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 2021-09-23 | A date (Python/C format code `''%Y-%m-%d''`) |'
  prefs: []
  type: TYPE_TB
- en: '| 2021-09-23T16:32:35Z | A UTC (*Z* after time) date and time (`''T%H:%M:%S''`)
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2021-09-23T16:32+02:00 | A positive two-hour (+02:00) offset from UTC (e.g.,
    Central European Time) |'
  prefs: []
  type: TYPE_TB
- en: Note the importance of being prepared to deal with different time zones. These
    are not always on lines of longitude (see [Wikipedia’s Time Zone entry](https://oreil.ly/NZyE4)),
    and often the best way to derive an accurate time is by using UTC time plus a
    geographic location.
  prefs: []
  type: TYPE_NORMAL
- en: ISO 8601 is the standard used by JavaScript and is easy to work with in Python.
    As web data visualizers, our key concern is in creating a string representation
    that can be passed between Python and JavaScript using JSON and encoded and decoded
    easily at both ends.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a date and time in the shape of a Python `datetime`, convert it into
    a string, and then see how that string can be consumed by JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we produce our Python `datetime`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'This string can then be saved to JSON or CSV, read by JavaScript, and used
    to create a `Date` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We can return the datetime to ISO 8601 string form with the `toISOString` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we can read the string back into Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you know that you’re dealing with an ISO-format time string, Python’s `dateutil`
    module should do the job.^([10](ch03.xhtml#idm45607793910272)) But you’ll probably
    want to sanity check the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Note that we’ve lost some resolution in the trip from Python to JavaScript and
    back again, the latter dealing in milliseconds, not microseconds. This is unlikely
    to be an issue in any dataviz work but is good to bear in mind just in case some
    strange temporal errors occur.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter aimed to make you comfortable using Python to move data around
    the various file formats and databases that a data visualizer might expect to
    bump into. Using databases effectively and efficiently is a skill that takes a
    while to learn, but you should now be comfortable with basic reading and writing
    for the large majority of dataviz use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the vital lubrication for our dataviz toolchain, let’s get
    up to scratch on the basic web development skills you’ll need for the chapters
    ahead.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch03.xhtml#idm45607798394048-marker)) I recommend using JSON over CSV
    as your preferred data format.
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch03.xhtml#idm45607797415616-marker)) The Python module `dateutil` has
    a parser that will parse most dates and times sensibly, and might be a good basis
    for this.
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch03.xhtml#idm45607796976800-marker)) On a cautionary note, it is probably
    a bad idea to use different database configurations for testing and production.
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch03.xhtml#idm45607796966400-marker)) See details on [SQLAlchemy](https://oreil.ly/winYu)
    of this *lazy initialization*.
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch03.xhtml#idm45607796702064-marker)) This assumes the database doesn’t
    already exist. If it does, `Base` will be used to create new insertions and to
    interpret retrievals.
  prefs: []
  type: TYPE_NORMAL
- en: '^([6](ch03.xhtml#idm45607795314160-marker)) Dataset’s official motto is “Databases
    for lazy people.” It is not part of the standard Anaconda package, so you’ll want
    to install it using `pip` from the command line: `$ pip install dataset`.'
  prefs: []
  type: TYPE_NORMAL
- en: ^([7](ch03.xhtml#idm45607795163536-marker)) See [this documentation](https://oreil.ly/vqvbv)
    for further details of how to use transactions to group updates.
  prefs: []
  type: TYPE_NORMAL
- en: ^([8](ch03.xhtml#idm45607794582448-marker)) One of the cool things about MongoDB
    is that the `ObjectId`s are generated on the client side, removing the need to
    quiz the database for them.
  prefs: []
  type: TYPE_NORMAL
- en: ^([9](ch03.xhtml#idm45607794006016-marker)) To get the actual local time from
    UTC, you can store a time zone offset or, better still, derive it from a geocoordinate;
    this is because time zones do not follow lines of longitude very exactly.
  prefs: []
  type: TYPE_NORMAL
- en: ^([10](ch03.xhtml#idm45607793910272-marker)) To install, just run `pip install
    python-dateutil`. `dateutil` is a pretty powerful extension of Python’s `datetime`;
    check it out on [Read the Docs](https://oreil.ly/y6YWS).
  prefs: []
  type: TYPE_NORMAL
