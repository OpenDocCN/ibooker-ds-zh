- en: 6 Categorical data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Determining the best approach to handle categorical data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to avoid common mistakes when working with categorical data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing categorical data with the right methods to investigate patterns and
    associations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sometimes, you may encounter data that is not numeric, and your typical analysis
    methods won’t apply. Instead, this data represents groups or categories with values
    limited to a set number of options. Customer locations, departments, and demographics
    are typical sources of such discrete values. We call this *categorical* data,
    and it is common in most datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Methods suitable for numeric or continuous data are not appropriate for categorical
    data. Knowing the correct way to handle categorical data will broaden your toolbox
    and ensure you use the right tool for the job when your data is mostly categorical.
    In this chapter, we will review common tools for handling categorical data before
    diving into the project.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Working with categorical data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the first tasks in any analysis is understanding your data. In a tabular
    dataset, every column of data will be one of two types: continuous or categorical.
    This distinction doesn’t apply to unstructured data, such as audio or video files,
    but most analysts work mostly with tabular data. Regardless of what the values
    in these columns represent, they will either be on a continuous scale or part
    of a discrete set. Sometimes, it is not even obvious whether a column is categorical
    if the entries are numeric. Let’s look at an example dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 shows a snapshot of a dataset used widely in the machine learning
    community for teaching purposes. The original data was created by Jánosi et al.
    (1988) and is available at [https://mng.bz/vKo7](https://mng.bz/vKo7). It is a
    medical dataset of different patient measurements, also showing whether the patients
    had coronary heart disease. The associated data problem is to use the measurements
    to predict whether a patient has coronary heart disease.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 A preview of the UCI heart disease dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The first two columns, `age` and `sex`, are easier to identify as continuous
    and categorical, respectively. Even though `sex` is numeric, we treat it the same
    as if the values were text (e.g., “male” or “female”). For example, taking a numeric
    average of this column is not the same as calculating the average age of our patients
    would be. We call this type of categorical column *nominal* because there is no
    natural ordering among the categories. Other examples include color or political
    parties.
  prefs: []
  type: TYPE_NORMAL
- en: Categorical data can also be *ordinal*, where categories do have a natural order
    but are not on a numerical scale. Examples include sizes (e.g., small, medium,
    and large) or survey responses (e.g., values between “strongly disagree” and “strongly
    agree”). For completeness, table 6.1 shows the breakdown of the different types
    of data we can encounter.
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.1 An overview of the different types of data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Name | Categorical or continuous? | Properties | Example |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Nominal  | Categorical  | Data has discrete values, and categories are not
    ordered.  | Colors, political parties  |'
  prefs: []
  type: TYPE_TB
- en: '| Ordinal  | Categorical  | Data has discrete values, and categories have a
    natural order, but spacing is uneven between categories.  | T-shirt sizes (S/M/L),
    survey responses (good versus bad)  |'
  prefs: []
  type: TYPE_TB
- en: '| Interval  | Continuous  | Values are spaced evenly, but zero is not an absence
    of the measurement.  | Temperature  |'
  prefs: []
  type: TYPE_TB
- en: '| Ratio  | Continuous  | Values are spaced evenly, and zero means an absence
    of the measurement.  | Height, weight  |'
  prefs: []
  type: TYPE_TB
- en: Note  The word “ratio” in these definitions is not to be confused with the meaning
    where two measurements are compared to each other, like the ratio of new versus
    returning customers. In this case, “ratio” is the technical term for a continuous
    variable that starts at zero, where zero indicates an absence of that quantity.
    You can have a negative temperature but not a negative height, which is the distinction
    between “interval” and “ratio” quantities.
  prefs: []
  type: TYPE_NORMAL
- en: Back to the heart disease example. What about the other columns beyond `age`
    and `sex`? If we just inspect the data types when importing it, we observe that
    all columns are numeric. Figure 6.2 shows sample Python output to verify this.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 The data types in the heart disease data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: From this information so far, we might conclude that because our columns are
    numeric, all of our data must be continuous. However, upon closer inspection,
    we find that a few of our columns only take a small number of discrete values.
    For example, figure 6.3 shows the breakdown of values in the `slope` column.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 Breakdown of values of the `slope` column in the heart disease dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Although this is an integer column, there are only three discrete values. These
    values correspond to whether a patient’s exercise-related tests were done on an
    upward or downward slope or none at all. This column is, therefore, categorical,
    specifically, nominal.
  prefs: []
  type: TYPE_NORMAL
- en: This might seem like a trivial finding, but if we were to treat this column
    as continuous, we might perform erroneous calculations with it, such as taking
    an average. We might get an average slope value of 0.6, but it would be meaningless.
    It does not represent a value halfway between 0, upsloping, and 1, flat, because
    the numbering is arbitrary. Changing the numbers we assign to each category would
    change this result and its interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Real business case: Enhancing analyses with categorical data'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Used cars that go through auctions have all sorts of data entered about them,
    and a lot of them are categorical. Transmission type, fuel type, make, and model
    are all categorical values and are fundamental to understanding the used car market.
    The models I built for predicting the price of a used car or the likelihood that
    it will sell all heavily relied on these categorical values.
  prefs: []
  type: TYPE_NORMAL
- en: Our team was also periodically asked to look at whether the color of a car had
    any effect on its value. This not only involved manipulating a categorical `color`
    column but also extracting those categories from a free text field where people
    could enter anything for the color of the car!
  prefs: []
  type: TYPE_NORMAL
- en: How do we then treat categorical data? Let’s review some differences between
    methods for continuous versus categorical data.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.1 Methods for handling categorical data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s look at some key methods for analyzing continuous and categorical data.
    When we are working with continuous data, we are specifically interested in
  prefs: []
  type: TYPE_NORMAL
- en: The range of our values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The distribution of our values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The presence of outliers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Associations between continuous values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To explore these properties, the tools we have at our disposal are
  prefs: []
  type: TYPE_NORMAL
- en: Summary statistics (minimum, maximum, mean, median, etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Histograms and box plots to investigate range and distribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scatter plots and correlation measures to investigate relationships between
    continuous variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When it comes to categorical data, not all of these methods apply. Let’s revisit
    the heart disease dataset for an example where treating categorical values as
    continuous leads us astray.
  prefs: []
  type: TYPE_NORMAL
- en: One mistake we might make is to use the categorical `slope` variable in a regression
    model as if it were continuous, that is, in a scenario where we try to predict
    someone’s risk of heart disease based on the slope of the apparatus while testing
    them. We might end up with a result that would be interpreted as “for every unit
    increase in slope, the likelihood of our patient having heart disease goes up
    by 7%.” This is a valid interpretation for continuous measures like age, where
    every additional year of someone’s age increases the risk of heart disease. However,
    what does a “unit increase” in the slope value mean? Since the numbering is arbitrary,
    it doesn’t actually mean anything, and the whole problem is formulated incorrectly.
  prefs: []
  type: TYPE_NORMAL
- en: The correct treatment of the `slope` column for regression would be to convert
    it to binary indicator variables, each column representing one of the possible
    discrete values in a categorical column. In our slope example, we would create
    columns that represent whether each patient had a 0, 1, or 2 for their slope value,
    so we would create three columns, one for each possible slope value. The value
    of these columns would be 0 or 1, depending on whether the slope value was 0,
    1, or 2\. These binary columns would, therefore, be mutually exclusive since the
    `slope` column could only ever be one value. This is also referred to as *one-hot
    encoding*, and the results of this in our scenario are shown in figure 6.4 alongside
    the original `slope` column.
  prefs: []
  type: TYPE_NORMAL
- en: Note  You might have also seen the term “dummy variables” to describe this format.
    Technically, dummy variables are one-hot encodings with one of the columns dropped,
    but the idea is the same.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-4.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 The original slope column and three new columns created by applying
    one-hot encoding
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: From this format, we can still infer the value of the `slope` column for each
    patient, but now, these columns are also valid as inputs to a regression model.
    This is just one example where there is a method specifically suited for categorical
    data. In general, for categorical data, we are interested in
  prefs: []
  type: TYPE_NORMAL
- en: The frequency distribution of our values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Associations between our categorical values and other values, both continuous
    and categorical
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some methods that specifically tackle these attributes for categorical data
    are
  prefs: []
  type: TYPE_NORMAL
- en: Grouping and aggregation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bar charts to visualize the frequency distribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pivot tables and crosstabs to compare cooccurrences of two categorical columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Histograms and box plots colored by a categorical column to show the distribution
    of a continuous variable across different categories
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many other methods to investigate continuous and categorical data,
    some of which we will explore in more detail in the chapter. One common source
    of categorical values, which we will work with, is survey response data.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.2 Working with survey data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Survey data has its own specific considerations beyond the fact that it is
    a common source of categorical columns. As we’re doing our analysis, we will need
    to consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Survey data is self-reported, meaning it will have special kinds of biases.
    People might choose to omit answers for personal reasons or answer untruthfully.
    Participants who answer the survey are likely the kinds of people who willingly
    answer surveys, which again means a biased sample.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data might be missing for different reasons than in other datasets. Missing
    data could indicate an unwillingness to answer specific questions, users exiting
    the survey halfway through, or questions that are unavailable to the user based
    on answers to other questions (e.g. follow-ups to elaborate if they answered yes
    to something).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many answers will be on a Likert scale, where participants choose one of typically
    five answers ranging from “strongly disagree” to “strongly agree.” This means
    we will be working with ordinal values—categories that have a natural order but
    not a consistent numeric scale.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The takeaway is that we should not underestimate the importance of knowing our
    data, and a key aspect of that is knowing the correct type of each of our columns
    and the source of the data itself. Let’s now put this to the test in this chapter’s
    project.
  prefs: []
  type: TYPE_NORMAL
- en: '6.2 Project 5: Analyzing a survey to understand developer attitudes toward
    AI tools'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s now look at our project, in which we will analyze survey responses to
    understand how software developers are using AI tools. Most of the data is categorical
    because the source is a survey that contained lots of multiple-choice questions
    resulting in categorical values. We will look at the problem statement, the data
    dictionary, the outputs we should aim for, and what capabilities our tools need
    to tackle this problem. We will then go through a detailed plan using our results-oriented
    framework before diving into an example solution.
  prefs: []
  type: TYPE_NORMAL
- en: The data is available for you to attempt it yourself at [https://davidasboth.com/book-code](https://davidasboth.com/book-code).
    You will find the files with which you can attempt the project, as well as the
    example solution in the form of a Jupyter notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1 Problem statement
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this scenario, you are working as an analyst for AI Dev Elite, an AI startup
    focused on creating generative AI tools for people who write code, such as software
    developers. They are struggling to focus their product idea, so they have asked
    you to research how coders are currently using generative AI tools. They want
    to identify people’s pain points and find a market gap to exploit.
  prefs: []
  type: TYPE_NORMAL
- en: 'They have two hypotheses they would like you to test:'
  prefs: []
  type: TYPE_NORMAL
- en: New versus experienced coders are using these tools differently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: People’s opinions on the usefulness and trustworthiness of current AI tools
    depend on their experience, job role, and what specifically they use the tools
    for.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As much as they would love to access the queries people are typing into these
    tools directly, they have identified the Stack Overflow Developer Survey as a
    good source of information for the first iteration of this project. In this survey,
    developers disclosed details about their jobs, current tools, and usage of and
    attitudes toward generative AI tools. It is from these survey results that they
    want us to test their hypotheses.
  prefs: []
  type: TYPE_NORMAL
- en: 'NOTE  Thank you to Stack Overflow for making their Developer Survey results
    available here: [https://insights.stackoverflow.com/survey](https://insights.stackoverflow.com/survey),
    under the Open Database License (ODbL).'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2 Data dictionary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The data dictionary for this dataset comes in two parts, both included in the
    supplementary materials:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a question-by-question breakdown, `survey_results_schema.csv`, documenting
    which question a column contains answers for. Some questions’ answers are spread
    across multiple columns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is also a PDF copy of the survey itself. With this, you can directly observe
    the data-generating process, which is rare.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I recommend looking at the survey to start with because that will put the columns
    in both the data dictionary and the data itself into context. Seeing the survey
    questions directly will help identify the questions of interest for the analysis.
    Then, you can use the `survey_results_schema.csv` file to find the associated
    column name(s) in the answer data. Figure 6.5 shows an excerpt of this lookup
    file.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-5.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 An excerpt of the mapping document used as a data dictionary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As figure 6.5 shows, the question about how many years someone has coded professionally
    is referenced in the answer data as `YearsCodePro`. This is how we identify all
    the relevant columns for analysis in the example solution.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3 Desired outcomes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since our stakeholders have specific hypotheses, our analysis should focus on
    these. We need to do some general exploration of the data to identify missing
    values and so on, but our focus is on the specifics of the request. Our minimum
    viable answer should be evidence to support or refute these hypotheses. Therefore,
  prefs: []
  type: TYPE_NORMAL
- en: Our conclusions should include whether there is a difference in the use of AI
    across different levels of experience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We should communicate the factors that affect a person’s opinion of, and trust
    in, AI tools, as supported by the survey data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.2.4 Required tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As with most chapters, as long as your toolkit can read, explore, and visualize
    data, it will be suitable to complete this project. In the example solution, I
    use Python, the `pandas` library for data exploration, and `matplotlib` and `seaborn`
    for visualization. I also introduce some statistical functions from the `scipy`
    library when investigating associations within the data. The checklist for this
    project is, therefore, that your tool can
  prefs: []
  type: TYPE_NORMAL
- en: Load multiple datasets from CSV or Excel files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combine two or more datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform basic data manipulation tasks, such as sorting, grouping, and reshaping
    data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create data visualizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Produce statistical analysis, specifically of categorical data, but this is
    optional
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6.3 Applying the results-driven method to analyzing the developer survey
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s now see how we keep our result in focus and formulate a results-oriented
    action plan. We can follow the steps of the results-driven process to explore
    the data with our stakeholders’ requests and hypotheses in mind.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-unnumb-1.png)'
  prefs: []
  type: TYPE_IMG
- en: First, we need to understand what our stakeholders want from this analysis.
    Their initial aim is to find evidence to support or contradict their initial theories,
    but their ultimate goal is to find a market gap to exploit with an AI product.
    We can keep these two aims in mind when analyzing the data to ensure our results
    are valuable.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-unnumb-2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From our stakeholders’ request, we know there are two kinds of output to create:'
  prefs: []
  type: TYPE_NORMAL
- en: Evidence for whether there is a difference in the use of AI tools between developers
    of different experience levels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysis of the factors that determine someone’s score when assessing the usefulness
    and trust of AI tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As always, having a results-oriented focus means we can ignore certain paths
    our analysis could take if those paths do not serve us in finding an answer to
    our specific questions. In practice, this means ignoring questions in the survey
    that are not related to experience, usefulness, or trust in AI tools or a factor
    that could likely be linked to these.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-unnumb-3.png)'
  prefs: []
  type: TYPE_IMG
- en: In this project, the identification of the data source has been done for us.
    This is not an uncommon scenario, and as ever, we are working within the limitations
    of the available data.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-unnumb-4.png)'
  prefs: []
  type: TYPE_IMG
- en: There is one question to resolve at this stage, which is whether we want to
    look at surveys that happened before 2023 (currently the latest version). We have
    more than a single survey available to us, so we could choose to include past
    years as well. However, there are two arguments against doing this. First, we
    want a minimum viable answer, which means erring on the side of using less data
    to start with. Second, the use of AI tools has only really taken off in 2023,
    so earlier data may not give us more information to help our specific analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-unnumb-5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Having thought about the problem before diving in, this is the part where we
    formulate the action plan for the analysis. We broadly want to take the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Read the survey to ascertain the exact questions that were asked.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examine the data dictionary and our data to see how questions relate to columns
    in the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explore the data by looking at the usual properties, such as missing data, outliers,
    and similar.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the questions and columns that relate to our research questions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyze the relationship between our variables and the AI-related outcomes we
    are interested in.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarize our findings in light of our stakeholders’ hypotheses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip  This is a project where statistical tests might be useful since we have
    specific hypotheses to investigate. Rightly or not, stakeholders like asking whether
    something is statistically significant, and this is a chance to provide them with
    an actual answer.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-unnumb-6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this step, we want to present the evidence to support or refute our stakeholders’
    hypotheses, which were the following:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a difference in the use of AI across different levels of experience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The factors that affect a person’s opinion of and trust in AI tools are their
    level of experience, job role, and what specifically they use the tools for.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We specifically want to provide the most complete answer that can still be supported
    by our data. We do not want our stakeholders to take action on recommendations
    that are not based on robust findings, so unless we are confident in an association
    that we found, we should use appropriate language. Phrases such as “the data suggests”
    are generally preferred over words like “prove” or “shows.”
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-unnumb-7.png)'
  prefs: []
  type: TYPE_IMG
- en: Once we have presented our findings, a discussion with our stakeholders will
    likely lead to further questions to explore in the data, as well as additional
    data sources that would help our analysis. Our goal is to get to this point sooner
    rather than later, so we should only include the minimum amount of complexity
    in our first iteration.
  prefs: []
  type: TYPE_NORMAL
- en: '6.4 An example solution: How do developers use AI?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s now step through an example solution for this problem. As always, if you
    attempt the project yourself before reading this section, you will find it more
    valuable since you can compare the two solutions, with the usual caveat that our
    solutions may differ simply due to the choices we made.
  prefs: []
  type: TYPE_NORMAL
- en: The first order of business is to decide which columns represent the questions
    we’re interested in and, therefore, which we will focus on. Next, we will look
    at a high-level, general exploration of the data before looking at what affects
    developers’ attitudes toward AI.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.1 Exploring categorical data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Usually, in an analytical project, the first step is to look at the available
    data. However, we have a rare opportunity to see the data-generating process itself
    by looking at the survey that generated our dataset. Upon scrolling through it,
    here are some initial observations:'
  prefs: []
  type: TYPE_NORMAL
- en: Most questions are not mandatory, which means we can expect lots of missing
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are questions about age, number of years of experience coding, and job
    title, which look immediately relevant.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every question relating to a specific tool or technology includes options to
    mark them as “currently using” and “hoping to use next year,” and AI-related questions
    also include “interested in using” and “not interested in using,” as well as just
    “currently using.” Having all these options means we can cross-reference answers
    to find deeper relationships.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The way that participants can mark how favorable and trustworthy they deem AI
    tools to be is to use a Likert scale, which is the technical name for survey questions
    that allow positive, neutral, and negative answers and that represent ordinal
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The README file states that “Free response submissions have been removed,” which
    is unfortunate as we will be missing answers to the survey question “Please describe
    how you would expect your workflow to be different, if at all, in one year as
    a result of AI advancements.” Also, we will not see answers to questions that
    have an “other” option where participants can elaborate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will no doubt revisit the survey itself when we have questions about the
    data, but for now, we have enough of a sense of it to start our exploration. Let’s
    see a snapshot of how the survey questions relate to rows in our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The output of this code tells us that we are working with 89,000 survey responses,
    a sample of which is shown in figure 6.6.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 A snapshot of the raw survey data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: From this snapshot, we can already see that
  prefs: []
  type: TYPE_NORMAL
- en: There will be missing values, as predicted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most answers, even age, are categorical data represented as text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answers to multiple-choice questions are stored as semicolon-separated strings.
    There are multiple ways this kind of data could have been stored, so it’s good
    to establish which representation we’re facing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s dig into the missing data a bit more.
  prefs: []
  type: TYPE_NORMAL
- en: Investigating missing data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Ideally, we should find that only nonmandatory questions will have missing
    answers. Is this the case? Figure 6.7 shows a snapshot of the table showing the
    number of missing values for each column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-7.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 Missing values for each column
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This shows us that, for example, the participant unique identifier and the
    age columns both have no missing data. The `MainBranch` column represents the
    answer to the survey question, “Which of the following options best describes
    you today? For the purpose of this survey, a developer is ‘someone who writes
    code.’” Age was one of the questions we were interested in and was mandatory in
    the survey. So far, so good. As it happens, we have the data dictionary in a machine-readable
    format, so we can cross-reference it with the data to see which mandatory questions
    actually have missing data. Figure 6.8 is a snapshot of the data dictionary dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 A snapshot of the data dictionary dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We have a `qname` column, which should match the column names in our answer
    data. We also have the question itself, seemingly in either text or HTML form,
    and whether the question was mandatory, represented in the `force_resp` column.
    Looks like we have enough to cross-reference these files, but it’s worth checking
    our assumption about the `qname` column. A neat trick in Python is to compare
    the column names using sets.
  prefs: []
  type: TYPE_NORMAL
- en: Set theory does not often appear in a data science curriculum, but knowing a
    couple of tricks with sets, which are collections that only contain unique values,
    can help in specific cases like this one. We will create a set of both the column
    names in our answer data and the values in the `qname` column of the data dictionary
    dataset and see where they overlap.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is 50, meaning there are 50 columns that appear in both sets. That’s
    promising, but we also want to know which columns don’t overlap. Subtracting one
    set from another in Python actually gives us this difference. The output of this
    code is a collection of 34 columns in our answer data that are unaccounted for
    in the data dictionary, a sample of which is shown in figure 6.9:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-9.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 A sample of columns unaccounted for in the data dictionary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: On inspection, a lot of these look like multiple-choice options for the same
    questions. For example, the survey question, “Which parts of your development
    workflow are you currently using AI tools for, and which are you interested in
    using AI tools for over the next year? Please select all that apply,” has checkbox
    options for “Currently using,” “Interested in using,” and “Not interested in using,”
    the answers to which are recorded across the three columns. Figures 6.10 and 6.11
    show the format of the question as it appears in the survey and how the answers
    are represented in the data, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-10.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 The question about AI tools as it appears in the survey
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For each column of checkboxes in the survey, there is a corresponding column
    in the data, the value of which is all the AI use cases that were ticked for that
    column. That is, the participant represented in the second row in figure 6.11
    said they are currently using AI tools for writing code and committing and reviewing
    code.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-11.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.11 The same question represented in the survey answer data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'It looks like we cannot easily match all our columns to the data dictionary,
    so another option is to look at what is mandatory according to the data dictionary
    and check whether all the related columns have any missing answer data. Figure
    6.12 shows the mandatory columns according to the data dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-12.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.12 The mandatory columns according to the data dictionary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'At a minimum, each row in our answer data should have a value for age, highest
    education level, country, currency, and whether the participant currently uses
    AI tools in their workflow. Therefore, we should have no missing data in the `EdLevel`
    column. Is this the case? Figure 6.13 shows the output of the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-13.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.13 Rows where the education level is missing, which should never be
    the case
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Clearly, there are missing answers to mandatory questions. One suspicious element
    here is that where `EdLevel` is missing, every answer seems to be missing. Perhaps
    these are completely erroneous examples. Let’s identify how many missing columns
    there are for each participant that has a missing value for the `EdLevel` column.
    Figure 6.14 shows the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-14.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.14 The number of missing values per row where EdLevel is missing
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This tells us that wherever `EdLevel` is missing, there are precisely 80 missing
    values, which implies that these are survey responses with all answers missing
    and can be safely removed. Specifically, anywhere with all survey answer columns
    missing can be dropped:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s revisit our cross-referencing and look at all columns in our answer data
    that have no missing values. We can manually cross-check this against the mandatory
    questions, using figure 6.12, and see whether there are any questions whose corresponding
    columns have missing data. The following code produces the output shown in figure
    6.15:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-15.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.15 The list of columns with no missing data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'If we cross-reference this with the table in figure 6.12, it appears that the
    `Currency` column is the only mandatory question left that has missing data. Let’s
    again see if there is a pattern in the missingness. Are there the same number
    of missing values when `Currency` is missing? Figure 6.16 shows the output of
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-16.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.16 The number of missing values for each row where `Currency` is missing
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: There does not appear to be a pattern here. It suggests that although there
    are over 20,000 missing answers for the mandatory `Currency` question, this might
    be a technical error of some sort. Perhaps there could be other factors influencing
    this, such as certain countries where the currency data is missing more often.
    Either way, our initial research questions do not rely on this column, so this
    is a good place to decide not to pursue this line of inquiry further for now.
    Let’s summarize our process so far. Our first decision point was to investigate
    and drop missing values, as illustrated by figure 6.17.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-17.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.17 The first step of our analysis, visualized
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s now explore our AI-related columns in a bit more detail.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.2 Analyzing categorical survey data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, we should understand what proportion of people are even using AI tools.
    A quick chart reveals the answer to this, shown in figure 6.18:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-18.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.18 The distribution of answers to whether participants use AI tools
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: There are many directions we could continue from here. We could, for example,
    find out what demographics or job roles AI tool users have versus those who don’t
    use them. However, since we are focused on our end result, we can realize that
    this is not the question we are trying to answer. We are only interested in the
    subpopulations that already use AI tools, and we are more focused on how they
    use them. Having said that, an angle we are interested in is how people view the
    trustworthiness of AI tools, so it might be interesting to see if there is a difference
    in attitudes between participants who use AI and those who don’t.
  prefs: []
  type: TYPE_NORMAL
- en: Investigating Likert data in survey answers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the question of how AI users feel about the tools, we first want to use
    the `AISent` column, which reveals the answer to the question shown in figure
    6.19.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-19.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.19 The question about AI sentiment
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Now, we can look at the distribution of the `AISent` column to identify how
    people answered. Since this question is not mandatory, we expect to find some
    missing data. The following code produces the output shown in figure 6.20:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-20.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.20 Breakdown of answers to the AI sentiment question
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'As expected, there are lots of missing answers. These are not bad data; by
    and large, they represent a participant who chose not to answer this question,
    so we can fill this value in with a placeholder, such as “no answer given.” Another,
    more Python-specific, step we can take is to make the data type of this column
    explicitly categorical. This will allow us to set the ordering of the values so
    that whenever they appear in a data table or a chart, they are not ordered alphabetically.
    We do all this using the `pandas` `Categorical` data type. The output of the following
    code is shown in figure 6.21:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-21.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.21 Breakdown of AI sentiment answers after converting to a `Categorical`
    data type
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: One choice I had to make was what order the values appear in. It is mostly my
    personal preference that I chose to put the “no answer given” option first and
    start the remaining answers from negative to positive sentiment. However, it is
    still a choice we have to make at this point. Now, we can compare the distribution
    of these answers across the groups of AI tool users, nonusers, and aspiring users.
  prefs: []
  type: TYPE_NORMAL
- en: Using pivot tables to cross-reference categorical values
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Comparing answers about favorability across different groups of AI tool users
    involves cross-referencing two categorical variables. In `pandas`, one appropriate
    method is `crosstab`, and the following code produces the output in figure 6.22:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Rows represent whether the participant is an AI tool user.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Columns represent answers to the AI sentiment question.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-22.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.22 Comparing whether AI users or non-users view AI tools favorably
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We can immediately notice that whoever said they don’t use AI did not give a
    follow-up answer either because the follow-up didn’t make sense, or the survey
    actively hid the option. We could stop here and try to make further sense of this
    table, as it’s not too large. However, I would err on the side of not staring
    at tables of numbers for very long and creating visualizations instead.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing pivot tables with heatmaps
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Visualizing a table of numbers is usually a good opportunity for a heatmap,
    which the `seaborn` library can provide. I have chosen a grayscale option that
    translates to print, but any sequential colormap would do.
  prefs: []
  type: TYPE_NORMAL
- en: A note on color scale terminology
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When deciding on colors for a visualization and multiple colors are involved,
    we need to make a choice of colormap, that is, the range of colors present in
    the visualization. Our choices are sequential, diverging, or categorical (also
    called nominal or qualitative).
  prefs: []
  type: TYPE_NORMAL
- en: Sequential colormaps gradually change in lightness to represent a continuous
    scale. The lightness is proportional to the size of the measurement; an example
    is the greyscale colormap, such as the one used in figure 6.23\. The darker colors
    indicate more people falling into a category.
  prefs: []
  type: TYPE_NORMAL
- en: Diverging colormaps include multiple colors, which gradually change in lightness
    depending on the direction. Lightness is still used to indicate strength, but
    the hue also indicates direction. An example is negative values being red and
    positives being blue, with larger values being darker red or blue, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Categorical colormaps are used when different parts of a visualization need
    to be distinct colors. They are usually used in pie or bar charts where each slice
    or bar is a completely different color. The colors are purely for visual separation
    and are not to be interpreted numerically.
  prefs: []
  type: TYPE_NORMAL
- en: 'I have also anchored the minimum and maximum points at 0 and 1, respectively,
    because that is the scale we are working with. Figure 6.23 shows the generated
    heatmap:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-23.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.23 Heatmap showing the favorability of AI tools among users and aspiring
    users
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Note  This is a good opportunity to incorporate some programming best practices
    into our analysis. We will undoubtedly create more heatmaps like this, and the
    difference between them will be the data and the axis labels. The other options
    will remain the same, so we should create a reusable function that can generate
    a heatmap without duplicating our code. Problems of code quality are generally
    beyond the scope of these projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'The modified code to produce the heatmap from figure 6.23 looks like the following.
    We will reuse this `create_heatmap` method throughout the solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '#1 The function only needs the data table and an optional way to make the heatmap
    square or not.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 We return the Figure and Axis objects to allow custom axis labels and titles.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, back to interpreting the heatmap. There seem to be a couple of noticeable
    differences between current and aspiring AI users. First, those who use AI tools
    view them more favorably than aspiring users, and those who do not yet use AI
    tools are more likely to be indifferent about them. This is perhaps not surprising.
    The lack of cynicism about the tools is interesting; it seems very few developers
    view the tools unfavorably. This might be selection bias; developers filling in
    this survey might already be more likely to have good use cases for AI tools and,
    therefore, higher opinions. Let us see how these groups fare with the question
    about the trustworthiness of the tools’ outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `AIBen` column also has missing data, so we choose to fill these in and
    create an ordered `Categorical` column again. The following code then produces
    the output in figure 6.24:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-24.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.24 The distribution of trust in AI tools
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Although most participants viewed AI tools favorably, there is more of a spread
    when it comes to trusting their outputs. The crosstab comparing these answers
    across AI users and aspiring users is achieved with the following code and shown
    in figure 6.25:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-25.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.25 Comparing AI trustworthiness across different users
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Again, we can exclude nonusers and generate a heatmap of the crosstab, as shown
    in figure 6.26:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-26.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.26 Heatmap comparing AI trustworthiness across AI tool users and aspiring
    users
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Active users of AI tools trust their outputs more and distrust them less, although
    very few people are comfortable saying they *highly* trust them. Aspiring users
    are more on the fence and have answered “neither trust nor distrust” more often.
    Again, it is not surprising, but it validates some basic assumptions.
  prefs: []
  type: TYPE_NORMAL
- en: Before moving on to investigate different aspects of the data, let’s review
    our process so far. Figure 6.27 shows the steps taken so far.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-27.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.27 Visualizing our analysis so far
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now, it’s time to dive deeper into what people are using AI tools for.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming categorical data into indicator variables
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For this portion, we will focus only on those who answered yes to the question
    about whether they use the tools. Let’s remind ourselves about the format of the
    answers to the question about which parts of the development workflow they are
    using AI tools for. Figure 6.28 shows part of the related survey question.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-28.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.28 A snapshot of the survey question about what participants are using
    AI tools for
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Figure 6.29 shows a snapshot of the column that represents the answers in semicolon-delimited
    string form. The data was selected with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-29.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.29 A snapshot of the data used to store answers to how people use AI
    tools
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This is not a format we can work with directly. Typically, we would spread the
    available answers out as indicator variables, binary columns to represent whether
    each possible answer was checked. This next step, one-hot encoding, where we convert
    this string column into indicator variables, is a purely technical one, which
    makes it a perfect place to turn to AI tools if you don’t already know how to
    do the transformation with your existing tools. Let’s see this in action.
  prefs: []
  type: TYPE_NORMAL
- en: 'I asked ChatGPT the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*I have a pandas DataFrame that contains a column of values corresponding to
    multiple choice options from a survey question. The values are not exclusive,
    so they can contain multiple answers delimited by a semicolon. A sample value
    would be “option 1; option 2; option 3.” I want to turn this into multiple indicator
    columns, one for each value, so I should have columns called “option 1,” “option
    2,” etc., each being a binary indicator of whether that value was present in the
    original column. What is the pandas code for this?*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Its answer started with, “You can achieve this by using the `str.get_dummies`
    method in pandas to create indicator columns for each option in the multiple-choice
    column,” which turned out to be exactly the method I was after. It also suggested
    some code snippets, as shown in figure 6.30.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-30.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.30 Code snippets suggested by ChatGPT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'One tweak I had to make was changing the separator from “; ” to “;” because
    our data doesn’t have the trailing space between the semicolon-delimited values.
    Other than that, the `str.get_dummies` function is exactly what we are after.
    The following code generates the indicator columns shown in figure 6.31:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-31.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.31 A snapshot of the newly created indicator columns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: To reiterate, each column represents one of the checkbox rows from figure 6.28,
    and a value of 1 means that the checkbox was ticked under the “Currently using”
    column. If we were to repeat this for “Interested in using” and “Not interested
    in using,” we would end up with three times as many indicator variables, essentially
    one column per checkbox under that question.
  prefs: []
  type: TYPE_NORMAL
- en: 'Experience might tell us that when separating delimited strings, we could end
    up with trailing spaces in column names, so let’s check and fix that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'One benefit of indicator variables is that the sum of each column represents
    the number of people who ticked a particular checkbox, and the mean of each column
    represents the percentage. Let’s look at the percentage of participants who checked
    each option. Remember, this is now only AI users telling us what they currently
    use AI tools for. The following code produces the chart in figure 6.32:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-32.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.32 Bar chart showing what percentage of AI users ticked each “Currently
    using” option
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Most developers are using AI tools to write and debug code, but there are other
    tangential use cases that are popular, such as testing code, project planning,
    and even documenting code. We can add the indicator columns to our original data
    and keep a filtered dataset of only AI users for use in the remaining investigations.
    Figure 6.33 shows a snapshot of the data after the following manipulations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '#1 concat will, by default, match on indices.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-33.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.33 A snapshot of the combined data of AI users
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s see how favorable and trustworthy participants judge AI to be depending
    on what they use the tools for. Our “start at the end” philosophy is helpful here.
    We want a table where each row is one of the AI tool use cases (e.g., “Writing
    code”), and each column is one of the favorability options. Each cell then represents
    the count, or better, the percentage, of those who said they use AI tools for
    a particular purpose and answered a particular way for favorability. This should
    show us whether there is a difference in opinion across different users’ profiles.
  prefs: []
  type: TYPE_NORMAL
- en: Converting data to a long format for easier analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Cross-referencing the different use cases with favorability opinions requires
    some reshaping of our data. This is another use case for an AI tool to tell us
    how to do this, but this time, let’s attempt it ourselves and compare notes with
    our AI tool afterward. What we want is data in a long format, which will make
    it easier to generate the right crosstab. See chapter 3 for more details on wide
    versus long data in the context of data modeling. The following code creates a
    long-form version of one of the multiple-choice options cross-referenced against
    favorability, and the output is shown in figure 6.34:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-34.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.34 AI tools favorability across people who use them for collaboration
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'If we had this dataset for every option combined into one long table, we could
    reshape it into the crosstab we need. Let’s loop through the options and build
    up this long table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Loops through all indicators'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Generates the aggregation similar to figure 6.32 and tracks in a list'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Combines the list into one DataFrame'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output is `(70,` `3)`, meaning we have 70 rows now, corresponding to the
    10 indicator columns with seven possible favorability answers each. We can now
    use this data to create a crosstab of percentages, as planned. The following code
    does this and produces the crosstab in figure 6.35:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-35.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.35 Crosstab of favorability vs. different AI tool use cases
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This is now a table that is hard to interpret in its current form, so let’s
    generate a heatmap of this, too. The final heatmap is shown in figure 6.36:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-36.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.36 Heatmap comparing favorability across different AI tool use cases
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This is much easier to interpret than the raw data table. There does not seem
    to be a big difference across use cases, but there are some observations we can
    make:'
  prefs: []
  type: TYPE_NORMAL
- en: Even when we break the data out into use cases, AI users generally view their
    tools favorably.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Those who use the tools for project planning, collaborating, committing and
    reviewing code, and deployment and monitoring grade the AI tools as “very favorable”
    the most.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The biggest “indifferent” category is “Other,” but we do not have the underlying
    data, so we cannot investigate this further.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before moving on, let’s briefly look at how ChatGPT suggested we solve this
    particular technical challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Using AI tools to improve our analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Whenever something takes two or three discrete steps, I get the feeling that
    there is an easier way to do it, which is where AI tools can help improve our
    technical knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Note  It is important to remember that AI tools like ChatGPT are just that—tools.
    This makes them interchangeable over time. You might not use this specific AI
    tool, and there will undoubtedly be more advanced ones created in the future.
    Feel free to substitute all references to ChatGPT with whichever AI tool you prefer.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, ChatGPT’s answer was very similar; it suggested building up a
    DataFrame by looping through the options. Figure 6.37 shows ChatGPT’s answer.
    I did not integrate its suggestion or dig into the specific differences between
    it and my code; all I was looking for was whether there was a single `pandas`
    method I overlooked for doing this transformation. As it turns out, AI tools can
    do no better than looping through the different options.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-37.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.37 ChatGPT’s approach to creating the options vs. favorability crosstab
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Previously, the question about the trustworthiness of the output generated
    more interesting findings, so let us repeat this latest crosstab and heatmap process
    for the `AIBen` column as well. The following code generates the long-format data,
    a snapshot of which is shown in figure 6.38:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-38.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.38 A snapshot of long-format data comparing AI tool use case options
    with trustworthiness
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This generates 60 rows of data, 10 use cases with six trustworthiness options
    each. Now, we can create the crosstab and heatmap generated by the following code.
    The final heatmap is shown in figure 6.39:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-39.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.39 Heatmap of different AI tool use cases vs. view on trustworthiness
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: From this heatmap, it appears that most users “somewhat trust” the AI tools’
    outputs, with not much difference across use cases. Having the data about the
    “Other” category would be interesting, as that is where the trustworthiness varies
    the most.
  prefs: []
  type: TYPE_NORMAL
- en: Note  One limitation of using this multiple-choice data is we are double-counting
    anyone who said they use AI for more than one purpose. It’s not a deal breaker
    for our analysis, but it’s good to be aware that our categories are not mutually
    exclusive.
  prefs: []
  type: TYPE_NORMAL
- en: Before continuing our analysis, let’s recap the steps so far, including the
    latest one, where we investigated opinions of AI across different use cases. Our
    latest steps are shown in figure 6.40.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-40.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.40 Steps taken in the analysis up to investigating AI tool usage
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Next, we are interested in the profiles of AI tool users (e.g., what job titles
    they have).
  prefs: []
  type: TYPE_NORMAL
- en: Recategorizing data for clarity
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There are further nuances we can explore in this data. People who said they
    use AI to write code may use it for very different purposes. Despite the name,
    the survey was not just completed by developers. Other job roles are also included,
    so it’s worth exploring whether attitudes toward AI vary along those roles. First,
    let’s look at the distribution of values in the `DevType` column, but only for
    people who are using AI tools. The results produced by the following code are
    shown in figure 6.41:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-41.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.41 Distribution of job roles among participants who use AI tools
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'As we’d expect, most participants are developers with a long tail of other
    jobs ranging from data roles to research, marketing, and even management. For
    our purposes, we can probably combine a few of these categories, at least for
    our first iteration. To identify if different job roles use AI differently, we
    can get away with grouping all developers into a single group to start with. Let’s
    see which of these groups could go into our larger “developer” group. The result
    of the following code is shown in figure 6.42:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-42.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.42 Distribution of different developer roles among AI tool users
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Most of these roles can go in a single “Developer” category, except the last
    two: “Developer experience” and “Developer advocate.” These are developer-adjacent
    roles with more of a people focus with responsibilities such as creating and engaging
    with communities and not necessarily writing a lot of code. Let’s group the rest
    of the developer roles into a single category. Specifically, in Python, we can
    create a dictionary that matches each of these roles with the “new” category they
    should belong to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Looking at our list in figure 6.42 again, we see a few engineering roles that
    could be grouped together, so let’s also do that. The following code produces
    the output in figure 6.43:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-43.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.43 Distribution of engineering roles among AI tool users
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'All of these roles can go under one “Engineer” category for now, except the
    management one. Let’s make that change and then look at the distribution of our
    new, more compact job category column. The following code produces the result
    in figure 6.44:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/6-44.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.44 Distribution of a new `job_category` column
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Now, we can create a crosstab similar to those we created previously, this
    time, to cross-reference job roles with AI use cases. First, we transform the
    data to a long format and then create our crosstab. Finally, we create a heatmap
    to make the results easier to investigate. The following code goes through these
    steps and produces the heatmap in figure 6.45:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Cross-reference job categories with AI use cases.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Reshapes into a crosstab'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Finally, plots the heatmap'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-45.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.45 Heatmap showing AI use cases across different job roles
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The heatmap gives us some insights into usage patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: About 30% of people use AI tools for writing code, with database administrators,
    marketing and sales professionals, and designers being exceptions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database administrators use AI for learning about a codebase more than others.
    Apart from them, other job roles that use AI for this the most are the ones that
    generally write less code, such as marketing or product functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While developer advocates also use AI for writing code, they also score the
    highest in using it for documentation, which can be an important aspect of the
    role.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These few observations aside, participants seem to use AI tools more or less
    in the same way. Let’s recap our steps again, including this latest step for investigating
    job roles. Figure 6.46 shows the latest step diagram.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/6-46.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.46 The latest diagram of the steps taken in our analysis
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Note that once we clean up the AI sentiment and trust-related columns, certain
    parts of our analysis can be done in parallel. Figure 6.46 illustrates this since
    it is not necessary to compare AI tool usage and trust and favorability before
    investigating AI users’ job roles. This highlights the fact that sometimes an
    analysis is not completely linear.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s export the data we will need to explore the questions further in the
    next chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Let’s now review everything that we have accomplished so far and identify what
    else we need to do to finish getting to a minimum viable answer in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.3 Project progress so far
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we have answered one of the two main stakeholder questions, namely,
    whether developers’ opinions on the usefulness and trustworthiness of current
    AI tools depend on their experience, job role, and what specifically they use
    the tools for. We have analyzed the survey to conclude that
  prefs: []
  type: TYPE_NORMAL
- en: Users of AI tools generally view them more favorably than nonusers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Users of AI tools also trust the tools’ outputs more than nonusers say they
    would.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Help with writing and debugging code is the most popular use case for AI tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: People in different job roles report using AI tools for different purposes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following chapter, we will continue the project by addressing the second
    stakeholder hypothesis, which is that new and experienced coders use these tools
    differently. For this, we will need methods that combine continuous and categorical
    data and perform appropriate statistical tests.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Categorical data is prevalent in the real world.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methods for continuous data are often not appropriate for categorical data;
    therefore, knowing methods to handle categorical data is important for analysts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methods like one-hot encoding transform categorical data into a format better
    suited for analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
