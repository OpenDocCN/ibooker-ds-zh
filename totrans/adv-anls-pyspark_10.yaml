- en: Chapter 10\. Image Similarity Detection with Deep Learning and PySpark LSH
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章。深度学习与PySpark LSH的图像相似性检测
- en: Whether you encounter them on social media or e-commerce stores, images are
    integral to our digital lives. In fact, it was an image dataset—ImageNet—which
    was a key component for sparking the current deep learning revolution. A remarkable
    performance by a classification model in the ImageNet 2012 challenge was an important
    milestone and led to widespread attention. It is no wonder then that you are likely
    to encounter image data at some point as a data science practitioner.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您在社交媒体还是电子商务店铺上遇到它们，图像对于我们的数字生活至关重要。事实上，正是一个图像数据集——ImageNet——引发了当前深度学习革命的关键组成部分。在ImageNet
    2012挑战中，分类模型的显著表现是重要的里程碑，并引起了广泛关注。因此，作为数据科学从业者，您很可能会在某个时刻遇到图像数据。
- en: In this chapter, you will gain experience scaling a deep learning workflow for
    a visual task, namely, image similarity detection, with PySpark. The task of identifying
    images that are similar to each other comes intuitively to humans, but it is a
    complex computational task. At scale, it becomes even more difficult. In this
    chapter, we will introduce an approximate method for finding similar items called
    locality sensitive hashing, or LSH, and apply it to images. We’ll use deep learning
    to convert image data into a numerical vector representation. PySpark’s LSH algorithm
    will be applied to the resulting vectors, which will allow us to find similar
    images given a new input image.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，你将通过使用PySpark来扩展深度学习工作流程，针对视觉任务——即图像相似性检测，获得经验。识别相似图像对于人类来说是直观的，但对计算机来说是一项复杂的任务。在大规模情况下，这变得更加困难。在本章中，我们将介绍一种用于查找相似项的近似方法，称为局部敏感哈希（LSH），并将其应用于图像。我们将使用深度学习将图像数据转换为数值向量表示。PySpark的LSH算法将应用于生成的向量，这将使我们能够在给定新输入图像时找到相似图像。
- en: On a high level, this example mirrors one of the approaches used by photo sharing
    apps such as Instagram and Pinterest for image similarity detection. This helps
    their users make sense of the deluge of visual data that exists on their platforms.
    This also depicts how a deep learning workflow can benefit from PySpark’s scalability.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，这个例子反映了像Instagram和Pinterest等照片分享应用程序用于图像相似性检测的方法之一。这有助于他们的用户理解其平台上存在的大量视觉数据。这也展示了一个深度学习工作流程如何从PySpark的可扩展性中受益。
- en: We’ll start by briefly introducing PyTorch, a deep learning framework. It has
    gained prominence in recent years for its relatively easier learning curve compared
    to other major low-level deep learning libraries. Then we’ll download and prepare
    our dataset. The dataset being used for our task is the Cars dataset released
    in 2013 by Stanford AI Lab. PyTorch will be used for image preprocessing. This
    will be followed by conversion of our input image data into a vector representation
    (image embeddings). We’ll then import the resulting embeddings into PySpark and
    transform them using the LSH algorithm. We’ll finish up by taking a new image
    and performing a nearest neighbors search using our LSH-transformed dataset to
    find similar images.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将简要介绍PyTorch，一个深度学习框架。近年来，它因其相对于其他主要低级深度学习库更易学习的曲线而备受关注。然后，我们将下载和准备我们的数据集。用于我们任务的数据集是由斯坦福人工智能实验室于2013年发布的Cars数据集。PyTorch将用于图像预处理。接下来，我们将把输入图像数据转换为向量表示（图像嵌入）。然后，我们将导入结果嵌入到PySpark中，并使用LSH算法进行转换。最后，我们将采用新图像，并使用我们的LSH转换数据集进行最近邻搜索，以找到相似的图像。
- en: Let’s start by introducing and setting up PyTorch.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从介绍和设置PyTorch开始。
- en: PyTorch
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch
- en: PyTorch is a library for building deep learning projects. It emphasizes flexibility
    and allows deep learning models to be expressed in idiomatic Python. It found
    early adopters in the research community. Recently, it has grown into one of the
    most prominent deep learning tools across a broad range of applications due to
    its ease of use. Along with TensorFlow, it is the most popular library for deep
    learning as of now.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是一个用于构建深度学习项目的库。它强调灵活性，并允许使用Python来表达深度学习模型的习惯用语。它早期被研究社区早期采用。最近，由于其易用性，它已成为广泛应用的主要深度学习工具之一。与TensorFlow一起，它是目前最流行的深度学习库之一。
- en: PyTorch’s simple and flexible interface enables fast experimentation. You can
    load data, apply transforms, and build models with a few lines of code. Then,
    you have the flexibility to write customized training, validation, and test loops
    and deploy trained models with ease. It is consistently being used in professional
    contexts for real-world, mission-critical work. Being able to use GPUs (graphical
    processing units) for training resource-intensive models has been a big factor
    for making deep learning popular. PyTorch provides great GPU support, although
    we won’t need that for our task.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的简单灵活接口支持快速实验。您可以加载数据，应用转换并用几行代码构建模型。然后，您可以灵活编写定制的训练、验证和测试循环，并轻松部署训练模型。它始终在专业环境中用于实际的关键任务。能够利用GPU（图形处理单元）训练资源密集型模型是使深度学习流行的重要因素。PyTorch提供出色的GPU支持，尽管我们不需要在我们的任务中使用它。
- en: Installation
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装
- en: On the [PyTorch website](https://oreil.ly/CHkJo), you can easily obtain the
    installation instructions based on your system configuration, as shown in [Figure 10-1](#pytorch_installation_cpu_support).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[PyTorch网站](https://oreil.ly/CHkJo)上，您可以根据系统配置轻松获取安装说明，如[图10-1](#pytorch_installation_cpu_support)所示。
- en: '![PyTorch installation CPU support](assets/aaps_1001.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![PyTorch安装CPU支持](assets/aaps_1001.png)'
- en: Figure 10-1\. PyTorch installation, CPU support
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-1. PyTorch安装，CPU支持
- en: 'Execute the provided command and follow the instructions for your configuration:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 执行提供的命令并按照您的配置说明操作：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We will not be relying on a GPU and, hence, will choose CPU as a compute platform.
    If you have a GPU setup that you want to use, choose options accordingly to obtain
    the required instructions. We will not be needing Torchaudio for this chapter
    either, so we skip its installation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会依赖GPU，因此将选择CPU作为计算平台。如果您有要使用的GPU设置，请根据需要选择选项以获取所需的说明。我们在本章中也不需要Torchaudio，因此跳过其安装。
- en: Preparing the Data
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据
- en: We will be using the [Stanford Cars dataset](https://oreil.ly/gxo8Q). It was
    released as part of the ICCV 2013 paper “3D Object Representations for Fine-Grained
    Categorization” by Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用[斯坦福汽车数据集](https://oreil.ly/gxo8Q)。它是由Jonathan Krause、Michael Stark、Jia
    Deng和Li Fei-Fei在ICCV 2013年论文“3D对象表示用于细粒度分类”中发布的。
- en: You can download the images from Kaggle or using the source link provided by
    Stanford AI Lab.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从Kaggle下载图像，或使用斯坦福人工智能实验室提供的源链接下载。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once it’s downloaded, unzip the train and test image directories and place
    them in a directory called *cars_data*:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 下载完成后，解压缩训练和测试图像目录，并将它们放在名为*cars_data*的目录中：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can get a CSV file containing labels for the training dataset [here](https://oreil.ly/UoHXh).
    Download it, rename it to *cars_train_data.csv*, and place it in the data directory.
    Let’s have a look at it:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这里获取包含训练数据集标签的CSV文件[here](https://oreil.ly/UoHXh)。下载它，将其重命名为*cars_train_data.csv*，并将其放在数据目录中。让我们来看一下它：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Ignore all columns other than `Class` and `image`. The other columns are related
    to the original research project that this dataset was derived from and will not
    be used for our task.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略除了`Class`和`image`之外的所有列。其他列与此数据集衍生自的原始研究项目相关，不会在我们的任务中使用。
- en: Resizing Images Using PyTorch
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PyTorch调整图像大小
- en: Before we head further, we’ll need to preprocess our images. Preprocessing data
    is very common in machine learning since deep learning models (neural networks)
    expect the input to meet certain requirements.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进一步之前，我们需要预处理我们的图像。在机器学习中，预处理数据非常普遍，因为深度学习模型（神经网络）希望输入满足某些要求。
- en: 'We need to apply a series of preprocessing steps, called *transforms*, to convert
    input images into the proper format for the models. In our case, we need them
    to be 224 x 224-pixel JPEG-formatted images, since that is a requirement for the
    ResNet-18 model that we’ll use in the next section. We perform this transformation
    using PyTorch’s Torchvision package in the following code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要应用一系列预处理步骤，称为*转换*，将输入图像转换为模型所需的正确格式。在我们的案例中，我们需要它们是224 x 224像素的JPEG格式图像，因为这是我们将在下一节中使用的ResNet-18模型的要求。我们使用PyTorch的Torchvision包执行此转换的代码如下：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here we use a single transformation that resizes the image to fit within the
    neural networks. However, we can use the `Compose` transform to define a series
    of transforms used to preprocess our image too.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用单一转换来调整图像大小以适应神经网络。然而，我们也可以使用`Compose`转换来定义一系列用于预处理图像的转换。
- en: Our dataset is in place now. In the next section, we will convert our image
    data into a vector representation fit for use with PySpark’s LSH algorithm.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的数据集已经准备就绪。在下一节中，我们将把图像数据转换为适用于 PySpark LSH 算法的向量表示。
- en: Deep Learning Model for Vector Representation of Images
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像的深度学习模型用于向量表示
- en: Convolutional neural networks, or CNNs, are the standard neural network architectures
    used for prediction when the input observations are images. We won’t be using
    them for any prediction task but rather for generating a vector representation
    of images. Specifically, we will use the ResNet-18 architecture.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN），在输入观察数据为图像时，是用于预测的标准神经网络架构。我们不会将其用于任何预测任务，而是用于生成图像的向量表示。具体来说，我们将使用
    ResNet-18 架构。
- en: Residual Network (ResNet) was introduced by Shaoqing Ren, Kaiming He, Jian Sun,
    and Xiangyu Zhang in their 2015 paper “Deep Residual Learning for Image Recognition.”
    The 18 in ResNet-18 stands for the number of layers that exist in the neural network
    architecture. Other popular variants of ResNet include 34 and 50 layers. A larger
    number of layers results in improved performance at the cost of increased computation.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 残差网络（ResNet）由Shaoqing Ren、Kaiming He、Jian Sun和Xiangyu Zhang在其2015年的论文“Deep Residual
    Learning for Image Recognition”中引入。ResNet-18 中的 18 表示神经网络架构中存在的层数。ResNet 的其他流行变体包括
    34 和 50 层。层数越多，性能提高，但计算成本也增加。
- en: Image Embeddings
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像嵌入
- en: An *image embedding* is a representation of an image in a vector space. The
    basic idea is that if a given image is close to another image, their embedding
    will also be similar and close in the spatial dimension.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*图像嵌入* 是图像在向量空间中的表示。基本思想是，如果给定图像接近另一图像，则它们的嵌入也会相似且在空间维度上接近。'
- en: The image in [Figure 10-2](#ILSVRC_2012), [released by Andrej Karpathy](https://oreil.ly/YRhhT),
    shows how images can be represented in a lower dimensional space. As an example,
    you can notice vehicles near the top and birds in the bottom-left space.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 10-2](#ILSVRC_2012)中的图像，[由Andrej Karpathy发布](https://oreil.ly/YRhhT)，展示了图像如何在较低维度空间中表示。例如，您可以注意到顶部附近的车辆和左下角空间中的鸟类。'
- en: '![ILSVRC 2012 image embeddings in a 2-D space](assets/aaps_1002.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![ILSVRC 2012 图像嵌入在二维空间中的表示](assets/aaps_1002.png)'
- en: Figure 10-2\. ILSVRC 2012 image embeddings in a 2-D space
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-2\. ILSVRC 2012 图像嵌入在二维空间中的表示
- en: We can obtain image embeddings from ResNet-18 by taking the output of its second-to-last,
    fully connected layer, which has a dimension of 512\. Next, we create a class
    that, provided an image, can return its numeric vector form representation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过取其倒数第二个全连接层的输出来从 ResNet-18 获取图像的嵌入。接下来，我们创建一个类，该类可以在提供图像的情况下返回其数值向量形式的表示。
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_image_similarity_detection_with___span_class__keep_together__deep_learning__span__and_pyspark_lsh_CO1-1)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_image_similarity_detection_with___span_class__keep_together__deep_learning__span__and_pyspark_lsh_CO1-1)'
- en: Convert images into the PyTorch tensor format.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像转换为 PyTorch 张量格式。
- en: '[![2](assets/2.png)](#co_image_similarity_detection_with___span_class__keep_together__deep_learning__span__and_pyspark_lsh_CO1-2)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_image_similarity_detection_with___span_class__keep_together__deep_learning__span__and_pyspark_lsh_CO1-2)'
- en: Rescale the range of pixel values between 0 and 1\. The values for the mean
    and standard deviation (std) were precomputed based on the data used to train
    the model. Normalizing the image improves the accuracy of the classifier.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将像素值范围重新缩放到 0 到 1 之间。均值和标准差（std）的值是基于用于训练模型的数据预先计算的。对图像进行标准化可以提高分类器的准确性。
- en: We now initialize the `Img2VecResnet18` class and apply the `getVec` method
    to all of the images to obtain their image embeddings.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们初始化 `Img2VecResnet18` 类，并对所有图像应用 `getVec` 方法以获取它们的图像嵌入。
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For a larger dataset, you may want to sequentially write the vector output
    to a file rather than keeping it in memory to avoid an out-of-memory error. The
    data is manageable here, so we create a dictionary, which we save as a CSV file
    in the next step:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更大的数据集，您可能希望顺序写入向量输出到文件，而不是将其保留在内存中，以避免内存溢出错误。这里的数据可以管理，因此我们创建一个字典，并将其保存为
    CSV 文件：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Since we are working locally, we went with the CSV format for saving the vector
    output. However, Parquet format is more appropriate for data of this nature. You
    could easily save the data in Parquet format by replacing `to_csv` with `to_parquet`
    in the previous code.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们是在本地工作，我们选择了 CSV 格式来保存向量输出。然而，Parquet 格式更适合这种类型的数据。您可以通过在前面的代码中用 `to_parquet`
    替换 `to_csv` 来轻松将数据保存为 Parquet 格式。
- en: Now that we have the required image embeddings, we can import them into PySpark.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了所需的图像嵌入，我们可以将它们导入到PySpark中。
- en: Import Image Embeddings into PySpark
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将图像嵌入导入到PySpark中
- en: 'Start the PySpark shell:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 启动PySpark shell：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Import the image embeddings:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 导入图像嵌入：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'PySpark’s LSH implementation requires a vector column as an input. We can create
    one by combining the relevant columns in our dataframe using the `VectorAssembler`
    transform:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: PySpark的LSH实现需要一个向量列作为输入。我们可以通过使用`VectorAssembler`转换将数据框中的相关列组合成一个向量列：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the next section, we will use the LSH algorithm to create a way for us to
    find similar images from our dataset.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将使用LSH算法创建一种从数据集中查找相似图像的方法。
- en: Image Similarity Search Using PySpark LSH
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PySpark LSH进行图像相似性搜索
- en: Locality sensitive hashing is an important class of hashing techniques, which
    is commonly used in clustering, approximate nearest neighbor search, and outlier
    detection with large datasets. Locality sensitive functions take two data points
    and decide whether or not they should be a candidate pair.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 局部敏感哈希是一类重要的哈希技术，通常用于具有大型数据集的聚类、近似最近邻搜索和异常值检测。局部敏感函数接受两个数据点并决定它们是否应该成为候选对。
- en: The general idea of LSH is to use a family of functions (“LSH families”) to
    hash data points into buckets so that the data points that are close to each other
    are in the same buckets with high probability, while data points that are far
    away from each other are very likely in different buckets. The data points that
    map to the same buckets are considered a candidate pair.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: LSH的一般思想是使用一组函数家族（“LSH家族”）将数据点哈希到桶中，以便彼此接近的数据点具有高概率地位于相同的桶中，而相距较远的数据点很可能位于不同的桶中。映射到相同桶的数据点被认为是候选对。
- en: In PySpark, different LSH families are implemented in separate classes (e.g.,
    `MinHash` and `BucketedRandomProjection`), and APIs for feature transformation,
    approximate similarity join, and approximate nearest neighbor are provided in
    each class.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在PySpark中，不同的LSH家族由不同的类实现（例如`MinHash`和`BucketedRandomProjection`），并且在每个类中提供了用于特征转换、近似相似性连接和近似最近邻的API。
- en: We’ll use the BucketedRandomProjection implementation of LSH.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用LSH的BucketedRandomProjection实现。
- en: 'Let’s first create our model object:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先创建我们的模型对象：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the BucketedRandomProjection LSH implementation, the bucket length can be
    used to control the average size of hash buckets (and thus the number of buckets).
    A larger bucket length (i.e., fewer buckets) increases the probability of features
    being hashed to the same bucket (increasing the number of true and false positives).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在BucketedRandomProjection LSH实现中，桶长度可用于控制哈希桶的平均大小（从而控制桶的数量）。较大的桶长度（即较少的桶）增加了特征被哈希到同一桶中的概率（增加真正和假正例的数量）。
- en: 'We now transform the input DataFrame using the newly created LSH model object.
    The resulting DataFrame will contain a `hashes` column containing hashed representation
    of the image embeddings:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用新创建的LSH模型对象转换输入DataFrame。生成的DataFrame将包含一个`hashes`列，其中包含图像嵌入的哈希表示：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: With our LSH-transformed dataset ready, we’ll put our work to the test in the
    next section.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好我们的LSH转换数据集后，在下一节中我们将测试我们的工作。
- en: Nearest Neighbor Search
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最近邻搜索
- en: 'Let’s try to find a similar image using a new image. For now, we will pick
    one from the input dataset itself ([Figure 10-3](#random-car)):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用新图像找到相似的图像。暂时，我们将从输入数据集中选择一个（[图10-3](#random-car)）：
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Randomly picked car image](assets/aaps_1003.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![从数据集中随机选择的汽车图像](assets/aaps_1003.png)'
- en: Figure 10-3\. Randomly picked car image from our dataset
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-3。从我们的数据集中随机选择的汽车图像
- en: 'First, we’ll need to convert the input image into a vector format using our
    `I⁠m⁠g⁠2⁠V⁠e⁠c​R⁠e⁠s⁠n⁠e⁠t⁠1⁠8` class:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要使用我们的`Img2VecResnet18`类将输入图像转换为向量格式：
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now we perform an approximate nearest neighbor search:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们执行近似最近邻搜索：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'You can check the images in Figures [10-4](#result-image1) through [10-8](#result-image5)
    to see that the model gets it somewhat right already:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看图10-4到图10-8中的图像（链接：[#result-image1](#result-image1) 至 [#result-image5](#result-image5)），看看模型已经有了一些正确的结果：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Result image 1](assets/aaps_1003.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![结果图像1](assets/aaps_1003.png)'
- en: Figure 10-4\. Result image 1
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-4。结果图像1
- en: '![Result image 2](assets/aaps_1005.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![结果图像2](assets/aaps_1005.png)'
- en: Figure 10-5\. Result image 2
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-5。结果图像2
- en: '![Result image 3](assets/aaps_1006.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![结果图像3](assets/aaps_1006.png)'
- en: Figure 10-6\. Result image 3
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-6。结果图像3
- en: '![Result image 4](assets/aaps_1007.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![结果图像4](assets/aaps_1007.png)'
- en: Figure 10-7\. Result image 4
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-7。结果图像4
- en: '![Result image 5](assets/aaps_1008.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![结果图像 5](assets/aaps_1008.png)'
- en: Figure 10-8\. Result image 5
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-8\. 结果图像 5
- en: The input image is on top of the list as one would expect.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像位于列表顶部，正如人们所预期的那样。
- en: Where to Go from Here
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下一步怎么走
- en: In this chapter, we learned how PySpark can be combined with a modern deep learning
    framework to scale an image similarity detection workflow.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何将 PySpark 与现代深度学习框架结合起来，以扩展图像相似性检测工作流程。
- en: There are multiple ways to improve this implementation. You can try using a
    better model or improving the preprocessing to get better quality of embeddings.
    Further, the LSH model can be tweaked. In a real-life setting, you may need to
    update the reference dataset consistently to account for new images coming into
    the system. The simplest way to do this is by running a batch job at periodic
    intervals to create new LSH models. You can explore all of these depending on
    your need and interest.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以改进这个实现。你可以尝试使用更好的模型或者改进预处理以获得更好的嵌入质量。此外，LSH 模型也可以进行调整。在实际环境中，你可能需要定期更新参考数据集，以适应系统中新图像的到来。最简单的方法是定期运行批处理作业，创建新的
    LSH 模型。你可以根据自己的需求和兴趣来探索所有这些方法。
