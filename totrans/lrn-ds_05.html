<html><head></head><body><section data-pdf-bookmark="Chapter 4. Modeling with Summary Statistics" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch-modeling">&#13;
<h1><span class="label">Chapter 4. </span>Modeling with Summary Statistics</h1>&#13;
&#13;
<p>We saw in <a class="reference internal" data-type="xref" href="ch02.html#ch-data-scope">Chapter 2</a> the importance of data scope and in <a class="reference internal" data-type="xref" href="ch03.html#ch-theory-datadesign">Chapter 3</a> the importance of data<a contenteditable="false" data-primary="lifecycle, data science" data-secondary="modeling with summary statistics" data-type="indexterm" id="ix_lifecycle_mod_stat"/> generation mechanisms, such as one that can be represented by an urn model. Urn models<a contenteditable="false" data-primary="signal in data" data-type="indexterm" id="id777"/> address one aspect of modeling: they describe chance variation and ensure that the data are representative of the target. Good scope and representative data lay the groundwork for extracting useful information from data, which is the other part of modeling. This information is often referred to as the <em>signal</em> in the data. We use models to approximate the signal, with the simplest of these being the constant model, where the signal is approximated by a single number, like the mean or median. Other, more complex models summarize relationships between features in the data, such as humidity and particulate matter in air quality (<a class="reference internal" data-type="xref" href="ch12.html#ch-pa">Chapter 12</a>), upward mobility and commute time in communities (<a class="reference internal" data-type="xref" href="ch15.html#ch-linear">Chapter 15</a>), and height and weight of animals (<a class="reference internal" data-type="xref" href="ch18.html#ch-donkey">Chapter 18</a>). These more complex models are also approximations built from data. When a model fits the data well, it can provide a useful approximation to the world or simply a helpful description of the data.</p>&#13;
&#13;
<p>In this chapter, we introduce the basics of model fitting through a <em>loss</em> formulation. We demonstrate how to model patterns in the data by considering the loss that arises from using a simple summary to describe the data, the constant model. We delve deeper into the connections between the urn model and the fitted model in <a class="reference internal" data-type="xref" href="ch16.html#ch-risk">Chapter 16</a>, where we examine the balance between signal and noise when fitting models, and in <a class="reference internal" data-type="xref" href="ch17.html#ch-inf-pred-theory">Chapter 17</a>, where we tackle the topics of inference, prediction, and hypothesis testing.</p>&#13;
&#13;
<p>The constant<a contenteditable="false" data-primary="loss functions" data-secondary="minimizing loss" data-type="indexterm" id="id778"/><a contenteditable="false" data-primary="fitting the model" data-type="indexterm" id="ix_fit_mod_ch4"/> model lets us introduce model fitting from the perspective of <em>loss minimization</em> in a simple context, and it helps us connect summary statistics, like the mean and median, to more complex modeling scenarios in later chapters. We begin with an example that uses data about the late arrival of a bus to introduce the constant model.</p>&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Constant Model" data-type="sect1"><div class="sect1" id="the-constant-model">&#13;
<h1>The Constant Model</h1>&#13;
&#13;
<p>A transit<a contenteditable="false" data-primary="bus arrival times dataset" data-secondary="and constant model" data-secondary-sortas="constant model" data-type="indexterm" id="id779"/><a contenteditable="false" data-primary="constant model" data-type="indexterm" id="ix_const_mod"/> rider, Jake, often takes the northbound C bus at the 3rd &amp; Pike bus stop in downtown Seattle.<sup><a data-type="noteref" href="ch04.html#id780" id="id780-marker">1</a></sup> The bus is supposed to arrive every 10 minutes, but Jake notices that he sometimes waits a long time for the bus. He wants to know how late the bus usually is. Jake was able to acquire the scheduled arrival and actual arrival times for his bus from the Washington State Transportation Center. From these data, he can calculate the number of minutes that each bus is late to arrive at his stop:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">times</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">pd</code></span><span><code class="o">.</code></span><span><code class="n">read_csv</code></span><span><code class="p">(</code></span><span><code class="s1">'</code><code class="s1">data/seattle_bus_times_NC.csv</code><code class="s1">'</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">times</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>route</th>&#13;
			<th>direction</th>&#13;
			<th>scheduled</th>&#13;
			<th>actual</th>&#13;
			<th>minutes_late</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>0</strong></td>&#13;
			<td>C</td>&#13;
			<td>northbound</td>&#13;
			<td>2016-03-26 06:30:28</td>&#13;
			<td>2016-03-26 06:26:04</td>&#13;
			<td class="right">-4.40</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1</strong></td>&#13;
			<td>C</td>&#13;
			<td>northbound</td>&#13;
			<td>2016-03-26 01:05:25</td>&#13;
			<td>2016-03-26 01:10:15</td>&#13;
			<td class="right">4.83</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2</strong></td>&#13;
			<td>C</td>&#13;
			<td>northbound</td>&#13;
			<td>2016-03-26 21:00:25</td>&#13;
			<td>2016-03-26 21:05:00</td>&#13;
			<td class="right">4.58</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>...</strong></td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1431</strong></td>&#13;
			<td>C</td>&#13;
			<td>northbound</td>&#13;
			<td>2016-04-10 06:15:28</td>&#13;
			<td>2016-04-10 06:11:37</td>&#13;
			<td class="right">-3.85</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1432</strong></td>&#13;
			<td>C</td>&#13;
			<td>northbound</td>&#13;
			<td>2016-04-10 17:00:28</td>&#13;
			<td>2016-04-10 16:56:54</td>&#13;
			<td class="right">-3.57</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1433</strong></td>&#13;
			<td>C</td>&#13;
			<td>northbound</td>&#13;
			<td>2016-04-10 20:15:25</td>&#13;
			<td>2016-04-10 20:18:21</td>&#13;
			<td class="right">2.93</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<pre>1434 rows × 5 columns</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The <code>minutes_late</code> column in the data table records how late each bus was. Notice that some of the times are negative, meaning that the bus arrived early. Let’s examine a histogram of the number of minutes each bus is late:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">fig</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">histogram</code></span><span><code class="p">(</code></span><span><code class="n">times</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">minutes_late</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">450</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">250</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">fig</code></span><span><code class="o">.</code></span><span><code class="n">update_xaxes</code></span><span><code class="p">(</code></span><span><code class="nb">range</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="o">-</code></span><span><code class="mi">12</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">60</code></span><span><code class="p">]</code><code class="p">,</code></span><code> </code><span><code class="n">title_text</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">Minutes late</code><code class="s1">'</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">fig</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_04in01.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>We can already see some interesting patterns in the data. For example, many buses arrive earlier than scheduled, but some are well over 20 minutes late. We also see a clear mode (high point) at 0, meaning many buses arrive roughly on time.</p>&#13;
&#13;
<p>To understand<a contenteditable="false" data-primary="mean, median, or mode, summary statistics" data-type="indexterm" id="ix_mean_med_mode"/> how late a bus on this route typically is, we’d like to summarize lateness by a constant—this is a statistic, a single number, like the mean, median, or mode. Let’s find each of these summary statistics for the <code>minutes_late</code> column in the data table.</p>&#13;
&#13;
<p>From the histogram, we estimate the mode of the data to be 0, and we use Python to compute the mean and median:</p>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
mean:    1.92 mins late&#13;
median:  0.74 mins late&#13;
mode:    0.00 mins late&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Naturally, we want<a contenteditable="false" data-primary="θ (theta, parameter), in model fitting" data-type="indexterm" id="ix_theta_param"/> to know which of these numbers best represents a summary of lateness. Rather than relying on rules of thumb, we take a more formal approach. We make a constant model for bus lateness. Let’s call this constant <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> (in modeling, <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> is often referred to as a <em>parameter</em>). For example, if we consider <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>5</mn> </math></span>, then our model approximates the bus to typically be five minutes late.</p>&#13;
&#13;
<p>Now, <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>5</mn> </math></span> isn’t a particularly good guess. From the histogram of minutes late, we saw that there are many more points closer to 0 than 5. But it isn’t clear that <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>0</mn> </math></span> (the mode) is a better choice than <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>0.74</mn> </math></span> (the median), <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>1.92</mn> </math></span> (the mean), or something else entirely. To make choices between different values of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>, we would like to assign any value of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> a score that measures how well that constant fits the data. That is, we want to assess the loss involved in approximating the data by a constant, like <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>5</mn> </math></span>. And ideally, we want to pick the constant that best fits our data, meaning the constant that has the smallest loss. In the next section, we describe more formally what we mean by loss and show how to use it to fit a model.<a contenteditable="false" data-primary="" data-startref="ix_const_mod" data-type="indexterm" id="id781"/></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Minimizing Loss" data-type="sect1"><div class="sect1" id="minimizing-loss">&#13;
<h1>Minimizing Loss</h1>&#13;
&#13;
<p>We want to model how late the northbound C bus is by a constant, which we call <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>, and we want to use the data of actual number of minutes each bus is late to figure out a good value for <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>. To do this, we use a <em>loss function</em>—a function that measures how far away our constant, <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>, is from the actual data.</p>&#13;
&#13;
<p>A loss function is a mathematical function that takes in <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> and a data value <span class="math notranslate nohighlight"><math> <mi>y</mi> </math></span>. It outputs a single number, the <em>loss</em>, that measures how far away <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> is from <span class="math notranslate nohighlight"><math> <mi>y</mi> </math></span>. We write the loss function as <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> </math></span>.</p>&#13;
&#13;
<p>By convention, the loss function outputs lower values for better values of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> and larger values for worse <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>. To fit a constant to our data, we select the particular <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> that produces the lowest average loss across all choices for <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>. In other words, we find the <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> that <em>minimizes the average loss</em> for our data, <span class="math notranslate nohighlight"><math> <msub> <mi>y</mi> <mn>1</mn> </msub> <mo>,</mo> <mo>…</mo> <mo>,</mo> <msub> <mi>y</mi> <mi>n</mi> </msub> </math></span>. More formally, we write the average loss as <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <msub> <mi>y</mi> <mn>1</mn> </msub> <mo>,</mo> <msub> <mi>y</mi> <mn>2</mn> </msub> <mo>,</mo> <mo>…</mo> <mo>,</mo> <msub> <mi>y</mi> <mi>n</mi> </msub> <mo stretchy="false">)</mo> </math></span>, where:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <msub> <mi>y</mi> <mn>1</mn> </msub> <mo>,</mo> <msub> <mi>y</mi> <mn>2</mn> </msub> <mo>,</mo> <mo>…</mo> <mo>,</mo> <msub> <mi>y</mi> <mi>n</mi> </msub> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mtext>mean</mtext> <mrow> <mo>{</mo> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <msub> <mi>y</mi> <mn>1</mn> </msub> <mo stretchy="false">)</mo> <mo>,</mo> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <msub> <mi>y</mi> <mn>2</mn> </msub> <mo stretchy="false">)</mo> <mo>,</mo> <mo>…</mo> <mo>,</mo> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <msub> <mi>y</mi> <mi>n</mi> </msub> <mo stretchy="false">)</mo> <mo>}</mo> </mrow> </mtd> </mtr> <mtr> <mtd/> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>As a shorthand, we often use the vector <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo>=</mo> <mo stretchy="false">[</mo> <msub> <mi>y</mi> <mn>1</mn> </msub> <mo>,</mo> <msub> <mi>y</mi> <mn>2</mn> </msub> <mo>,</mo> <mo>…</mo> <mo>,</mo> <msub> <mi>y</mi> <mi>n</mi> </msub> <mo stretchy="false">]</mo> </math></span>. Then we can write the average loss as:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo stretchy="false">)</mo> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mrow> <msub> <mi>y</mi> <mi>i</mi> </msub> </mrow> <mo stretchy="false">)</mo> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Notice that <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> </math></span> tells us the model’s loss for a single data point while <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo stretchy="false">)</mo> </math></span> gives the model’s average loss for all the data points. The capital <span class="math notranslate nohighlight"><math> <mi>L</mi> </math></span> helps us remember that the average loss combines multiple smaller <span class="math notranslate nohighlight"><math> <mi mathvariant="script">l</mi> </math></span> values.</p>&#13;
</div>&#13;
&#13;
<p>Once we define a loss function<a contenteditable="false" data-primary="modeling" data-secondary="loss minimization" data-type="indexterm" id="ix_mod_loss_func_min"/><a contenteditable="false" data-primary="loss functions" data-secondary="minimizing loss" data-type="indexterm" id="ix_loss_func_min"/><a contenteditable="false" data-primary="optimization" data-secondary="and model fitting" data-secondary-sortas="model fitting" data-type="indexterm" id="id782"/><a contenteditable="false" data-primary="fitting the model" data-secondary="as optimization process" data-secondary-sortas="optimization process" data-type="indexterm" id="id783"/>, we can find the value of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> that produces the smallest average loss. We call this minimizing value <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span>. In other words, of all the possible <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> values, <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span> is the one that produces the smallest average loss for our data. We call this optimization process <em>model fitting</em>; it finds the best constant model for our data.</p>&#13;
&#13;
<p>Next, we look at two particular loss functions: absolute error and squared error. Our goal is to fit the model and find <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span> for each of these loss functions.</p>&#13;
&#13;
<section data-pdf-bookmark="Mean Absolute Error" data-type="sect2"><div class="sect2" id="mean-absolute-error">&#13;
<h2>Mean Absolute Error</h2>&#13;
&#13;
<p>We start with the <em>absolute error</em> loss<a contenteditable="false" data-primary="MAE (mean absolute error)" data-type="indexterm" id="ix_mae_mean_absol"/><a contenteditable="false" data-primary="mean absolute error (MAE)" data-type="indexterm" id="ix_mean_absol_mae"/><a contenteditable="false" data-primary="absolute error loss function" data-type="indexterm" id="id784"/><a contenteditable="false" data-primary="errors" data-secondary="mean absolute error" data-type="indexterm" id="ix_error_mean_abs"/> function. Here’s the idea behind absolute loss. For some value of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> and data value <span class="math notranslate nohighlight"><math> <mi>y</mi> </math></span>:</p>&#13;
&#13;
<ol class="arabic simple">&#13;
	<li>&#13;
	<p>Find the error, <span class="math notranslate nohighlight"><math> <mi>y</mi> <mo>−</mo> <mi>θ</mi> </math></span>.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Take the absolute value of the error, <span class="math notranslate nohighlight"><math> <mo stretchy="false">|</mo> <mi>y</mi> <mo>−</mo> <mi>θ</mi> <mo stretchy="false">|</mo> </math></span>.</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>So the loss function is <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mo>=</mo> <mrow> <mo stretchy="false">|</mo> </mrow> <mi>y</mi> <mo>−</mo> <mi>θ</mi> <mo stretchy="false">|</mo> </math></span>.</p>&#13;
&#13;
<p>Taking the absolute value of the error is a simple way to convert negative errors into positive ones. For instance, the point <span class="math notranslate nohighlight"><math> <mi>y</mi> <mo>=</mo> <mn>4</mn> </math></span> is equally far away from <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>2</mn> </math></span> and <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>6</mn> </math></span>, so the errors are equally “bad.”</p>&#13;
&#13;
<p>The average of the absolute errors is called the <em>mean absolute error</em> (MAE). The MAE is the average of each of the individual absolute errors:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mrow> <mo stretchy="false">|</mo> </mrow> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>θ</mi> <mo stretchy="false">|</mo> </math></div>&#13;
</div>&#13;
&#13;
<p>Notice that the name MAE tells you how to compute it: take the Mean of the Absolute value of the Errors, <span class="math notranslate nohighlight"><math> <mo fence="false" stretchy="false">{</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>θ</mi> <mo fence="false" stretchy="false">}</mo> </math></span>.</p>&#13;
&#13;
<p>We can write a simple Python function to compute this loss:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="k">def</code></span><code> </code><span><code class="nf">mae_loss</code></span><span><code class="p">(</code></span><span><code class="n">theta</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_vals</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">abs</code></span><span><code class="p">(</code></span><span><code class="n">y_vals</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">theta</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Let’s see how this loss function behaves when we have just five data points <span class="math notranslate nohighlight"><math> <mo stretchy="false">[</mo> <mrow> <mo>–</mo> </mrow> <mn>1</mn> <mo>,</mo> <mn>0</mn> <mo>,</mo> <mn>2</mn> <mo>,</mo> <mn>5</mn> <mo>,</mo> <mn>10</mn> <mo stretchy="false">]</mo> </math></span>. We can try different values of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> and see what the MAE outputs for each value:</p>&#13;
&#13;
<figure class="informal width-75"><div class="figure"><img src="assets/leds_04in02.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>We suggest verifying some of these loss values by hand to check that you understand how the MAE is computed.</p>&#13;
&#13;
<p>Of the values of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> that we tried, we found that <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>2</mn> </math></span> has the lowest mean absolute error. For this simple example, 2 is the median of the data values. This isn’t a coincidence. Let’s now check what the average loss is for the original dataset of bus late times. We find the MAE when we set <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> to the mode, median, and mean of the minutes late, respectively:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_04in03.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>We see again that the median (middle plot) gives a smaller loss than the mode and mean (left and right plots). In fact, for absolute loss, the minimizing <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span> is the <span class="math notranslate nohighlight"><math> <mtext>median</mtext> <mo fence="false" stretchy="false">{</mo> <msub> <mi>y</mi> <mn>1</mn> </msub> <mo>,</mo> <msub> <mi>y</mi> <mn>2</mn> </msub> <mo>,</mo> <mo>…</mo> <mo>,</mo> <msub> <mi>y</mi> <mi>n</mi> </msub> <mo fence="false" stretchy="false">}</mo> </math></span>.</p>&#13;
&#13;
<p>So far, we have found the best value of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> by simply trying out a few values and then picking the one with the smallest loss. To get a better sense of the MAE as a function of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>, we can try many more values of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> and plot a curve that shows how <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> </math></span> changes as <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> changes. We draw the curve for the preceding example with the five data values <span class="math notranslate nohighlight"><math> <mo stretchy="false">[</mo> <mrow> <mo>–</mo> </mrow> <mn>1</mn> <mo>,</mo> <mn>0</mn> <mo>,</mo> <mn>2</mn> <mo>,</mo> <mn>5</mn> <mo>,</mo> <mn>10</mn> <mo stretchy="false">]</mo> </math></span>:</p>&#13;
&#13;
<figure class="informal width-55"><div class="figure"><img src="assets/leds_04in04.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The preceding plot shows that in fact, <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>2</mn> </math></span> is the best choice for this small dataset of five values. Notice the shape of the curve. It is piecewise linear, where the line <span class="keep-together">segments</span> connect at the location of the data values (–1, 0, 2, and 5). This is a property of the absolute value function. With a lot of data, the flat pieces are less obvious. Our bus data have over 1,400 points and the MAE curve appears smoother:</p>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_04in05.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>We can use this plot to help confirm that the median of the data is the minimizing value; in other words, <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> <mo>=</mo> <mn>0.74</mn> </math></span>. This plot is not really a proof, but hopefully it’s convincing enough for you.</p>&#13;
&#13;
<p>Next, let’s look at another loss function that squares error<a contenteditable="false" data-primary="" data-startref="ix_mean_absol_mae" data-type="indexterm" id="id785"/><a contenteditable="false" data-primary="" data-startref="ix_error_mean_abs" data-type="indexterm" id="id786"/><a contenteditable="false" data-primary="" data-startref="ix_mae_mean_absol" data-type="indexterm" id="id787"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Mean Squared Error" data-type="sect2"><div class="sect2" id="mean-squared-error">&#13;
<h2>Mean Squared Error</h2>&#13;
&#13;
<p>We have fitted<a contenteditable="false" data-primary="mean squared error (MSE)" data-type="indexterm" id="ix_mean_sq_mse"/><a contenteditable="false" data-primary="MSE (mean squared error)" data-type="indexterm" id="ix_mse_mean_sq"/><a contenteditable="false" data-primary="errors" data-secondary="mean squared error" data-type="indexterm" id="ix_error_mean_sq"/> a constant model to our data and found that with mean absolute error, the minimizer is the median. Now we’ll keep our model the same but switch to a different loss function: squared error. Instead of taking the absolute difference between each data value <span class="math notranslate nohighlight"><math> <mi>y</mi> </math></span> and the constant <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>, we’ll square the error. That is, for some value of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> and data value <span class="math notranslate nohighlight"><math> <mi>y</mi> </math></span>:</p>&#13;
&#13;
<ol class="arabic simple">&#13;
	<li>&#13;
	<p>Find the error, <span class="math notranslate nohighlight"><math> <mi>y</mi> <mo>−</mo> <mi>θ</mi> </math></span>.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Take the square of the error, <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <mi>y</mi> <mo>−</mo> <mi>θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </math></span>.</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>This gives the loss function <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mo>=</mo> <mo stretchy="false">(</mo> <mi>y</mi> <mo>−</mo> <mi>θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </math></span>.</p>&#13;
&#13;
<p>As before, we want to use all of our data to find the best <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>, so we compute the mean squared error, or MSE for short:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mrow> <mrow> <mi mathvariant="bold">y</mi> </mrow> </mrow> <mo stretchy="false">)</mo> <mo>=</mo> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <msub> <mi>y</mi> <mn>1</mn> </msub> <mo>,</mo> <msub> <mi>y</mi> <mn>2</mn> </msub> <mo>,</mo> <mo>…</mo> <mo>,</mo> <msub> <mi>y</mi> <mi>n</mi> </msub> <mo stretchy="false">)</mo> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </math></div>&#13;
</div>&#13;
&#13;
<p>We can write a simple Python function to compute the MSE:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="k">def</code></span><code> </code><span><code class="nf">mse_loss</code></span><span><code class="p">(</code></span><span><code class="n">theta</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_vals</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code><code class="p">(</code></span><span><code class="n">y_vals</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">theta</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">*</code><code class="o">*</code></span><code> </code><span><code class="mi">2</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Let’s again try the mean, median, and mode as potential minimizers of the MSE:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_04in06.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>Now when we fit the constant model using MSE loss, we find that the mean (right plot) has a smaller loss than the mode and the median (left and middle plots).</p>&#13;
&#13;
<p>Let’s plot the MSE curve for different values of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> given our data. The curve shows that the minimizing value <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span> is close to 2:</p>&#13;
&#13;
<figure class="informal width-55"><div class="figure"><img src="assets/leds_04in07.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>One feature of this curve that is quite noticeable is how rapidly the MSE grows compared to the MAE (note the range on the vertical axis). This growth has to do with the nature of squaring errors; it places a much higher loss on data values further away from <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>. If <span class="math notranslate nohighlight"><math> <mi>θ</mi> <mo>=</mo> <mn>10</mn> </math></span> and <span class="math notranslate nohighlight"><math> <mi>y</mi> <mo>=</mo> <mn>110</mn> </math></span>, the squared loss is <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <mn>10</mn> <mo>−</mo> <mn>110</mn> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mo>=</mo> <mn>10</mn> <mo>,</mo> <mn>000</mn> </math></span> whereas the absolute loss is <span class="math notranslate nohighlight"><math> <mo stretchy="false">|</mo> <mn>10</mn> <mo>−</mo> <mn>110</mn> <mrow> <mo stretchy="false">|</mo> </mrow> <mo>=</mo> <mn>100</mn> </math></span>. For this reason, the MSE is more sensitive to unusually large data values than the MAE.</p>&#13;
&#13;
<p>From the MSE curve, it appears that the minimizing <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span> is the mean of <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="bold">y</mi> </mrow> </math></span>. Again, this is no mere coincidence; the mean of the data always coincides with <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span> for squared error. We show how this comes about from the quadratic nature of the MSE. Along the way, we demonstrate a common representation of squared loss as a sum of variance and bias terms, which is at the heart of model fitting with squared loss. To begin, we add and subtract <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> </math></span> in the loss function and expand the square as follows:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </mtd> </mtr> <mtr> <mtd/> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">[</mo> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> <mo>+</mo> <mo stretchy="false">(</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <mi>θ</mi> <mo stretchy="false">)</mo> <msup> <mo stretchy="false">]</mo> <mn>2</mn> </msup> </mtd> </mtr> <mtr> <mtd/> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">[</mo> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mo>+</mo> <mn>2</mn> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> <mo stretchy="false">(</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <mi>θ</mi> <mo stretchy="false">)</mo> <mo>+</mo> <mo stretchy="false">(</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <mi>θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mo stretchy="false">]</mo> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>Next, we split the MSE into the sum of these three terms and note that the middle term is 0, due to the simple property of the average: <span class="math notranslate nohighlight"><math> <mo>∑</mo> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> <mo>=</mo> <mn>0</mn> </math></span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> </mtd> <mtd> <mi/> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mo>+</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mn>2</mn> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> <mo stretchy="false">(</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <mi>θ</mi> <mo stretchy="false">)</mo> <mo>+</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">(</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <mi>θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </mtd> </mtr> <mtr> <mtd/> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mo>+</mo> <mn>2</mn> <mo stretchy="false">(</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <mi>θ</mi> <mo stretchy="false">)</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo stretchy="false">)</mo> <mo>+</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">(</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <mi>θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </mtd> </mtr> <mtr> <mtd/> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mo>+</mo> <mo stretchy="false">(</mo> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> <mo>−</mo> <mi>θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>Of the remaining<a contenteditable="false" data-primary="variance" data-secondary="and MSE" data-secondary-sortas="MSE" data-type="indexterm" id="id788"/> two terms, the first does not involve <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span>. You probably recognize it as the variance of the data. The second term is always non-negative. It is called<a contenteditable="false" data-primary="bias squared" data-type="indexterm" id="id789"/> the <em>bias squared</em>. This second term, the bias squared, is 0 when <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> is <span class="math notranslate nohighlight"><math> <mrow> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> </mrow> </math></span>, so <span class="math notranslate nohighlight"><math> <mrow> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </mrow> <mo>=</mo> <mrow> <mrow> <mover> <mi>y</mi> <mo stretchy="false">¯</mo> </mover> </mrow> </mrow> </math></span> gives the smallest MSE for any dataset.</p>&#13;
&#13;
<p>We have seen that for absolute loss, the best constant model is the median, but for squared error, it’s the mean. The choice of the loss function is an important aspect of model fitting.<a contenteditable="false" data-primary="" data-startref="ix_mse_mean_sq" data-type="indexterm" id="id790"/><a contenteditable="false" data-startref="ix_theta_param" data-type="indexterm" id="id791"/><a contenteditable="false" data-primary="" data-startref="ix_error_mean_sq" data-type="indexterm" id="id792"/><a contenteditable="false" data-primary="" data-startref="ix_mean_sq_mse" data-type="indexterm" id="id793"/></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Choosing Loss Functions" data-type="sect2"><div class="sect2" id="choosing-loss-functions">&#13;
<h2>Choosing Loss Functions</h2>&#13;
&#13;
<p>Now that we’ve worked with two loss functions, we can return to our original question: how do we choose whether to use the median, mean, or mode? Since these <span class="keep-together">statistics</span> minimize different loss functions,<sup><a data-type="noteref" href="ch04.html#id794" id="id794-marker">2</a></sup> we can equivalently ask: what is the most appropriate loss function for our problem? To answer this question, we look at the context of our problem.</p>&#13;
&#13;
<p>Compared to the MAE, the MSE gives especially large losses when the bus is much later (or earlier) than expected. A bus rider who wants to understand the typical late times would use the MAE and the median (0.74 minutes late), but a rider who despises unexpected large late times might summarize the data using the MSE and the mean (1.92 minutes late).</p>&#13;
&#13;
<p>If we want to refine the model even more, we can use a more specialized loss function. For example, suppose that when a bus arrives early, it waits at the stop until the scheduled time of departure; then we might want to assign an early arrival 0 loss. And if a really<a contenteditable="false" data-primary="asymmetric loss function" data-type="indexterm" id="id795"/> late bus is a larger aggravation than a moderately late one, we might choose an <em>asymmetric loss function</em> that gives a larger penalty to super-late arrivals.</p>&#13;
&#13;
<p>In essence, context matters when choosing a loss function. By thinking carefully about how we plan to use the model, we can pick a loss function that helps us make good data-driven decisions.<a contenteditable="false" data-primary="" data-startref="ix_loss_func_min" data-type="indexterm" id="id796"/><a contenteditable="false" data-primary="" data-startref="ix_mod_loss_func_min" data-type="indexterm" id="id797"/><a contenteditable="false" data-primary="" data-startref="ix_mean_med_mode" data-type="indexterm" id="id798"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="sec-modeling-summary">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>We introduced the constant model: a model that summarizes the data by a single value. To fit the constant model, we chose a loss function that measured how well a given constant fits a data value, and we computed the average loss over all of the data values. We saw that depending on the choice of loss function, we get a different minimizing value: we found that the mean minimizes the average squared error (MSE), and the median minimizes the average absolute error (MAE). We also discussed how we can incorporate context and knowledge of our problem to pick a loss function.</p>&#13;
&#13;
<p>The idea of fitting models through loss minimization ties simple summary statistics—like the mean, median, and mode—to more complex modeling situations. The steps we took to model our data apply to many modeling scenarios:</p>&#13;
&#13;
<ol class="arabic simple">&#13;
	<li>&#13;
	<p>Select the form of a model (such as the constant model).</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Select a loss function (such as absolute error).</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Fit the model by minimizing the loss over all the data (such as average loss).</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>For the rest of this book, our modeling techniques expand upon one or more of these steps. We introduce new models, new loss functions, and new techniques for <span class="keep-together">minimizing</span> loss.<a contenteditable="false" data-primary="" data-startref="ix_lifecycle_mod_stat" data-type="indexterm" id="id799"/><a contenteditable="false" data-primary="" data-startref="ix_fit_mod_ch4" data-type="indexterm" id="id800"/> <a data-type="xref" href="ch05.html#ch-bus">Chapter 5</a> revisits the study of a bus arriving late at its stop. This time, we present the problem as a case study and visit all stages of the data science lifecycle. By going through these stages, we make some unusual discoveries; when we augment our analysis by considering data scope and using an urn to simulate a rider arriving at the bus stop, we find that modeling bus lateness is not the same as modeling the rider’s experience waiting for a bus.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id780"><sup><a href="ch04.html#id780-marker">1</a></sup> We (the authors) first learned of the bus arrival time data from an analysis by a data scientist named Jake VanderPlas. We’ve named the protagonist of this section in his honor. </p><p data-type="footnote" id="id794"><sup><a href="ch04.html#id794-marker">2</a></sup> The mode minimizes a loss function called 0-1 loss. Although we haven’t covered this specific loss, the procedure is identical: pick the loss function, then find what minimizes the loss.</p></div></div></section></body></html>