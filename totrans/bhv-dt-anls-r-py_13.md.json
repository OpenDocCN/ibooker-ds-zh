["```py\n## R\nlibrary(blockTools) # For function block()\nlibrary(caret) # For one-hot encoding function dummyVars()\nlibrary(scales) # For function rescale()\n```", "```py\n## Python\nimport random # For functions sample() and shuffle()\n# To rescale numeric variables\nfrom sklearn.preprocessing import MinMaxScaler\n# To one-hot encode cat. variables\nfrom sklearn.preprocessing import OneHotEncoder\n```", "```py\n## R\nno_strat_assgnt_fun <- function(dat, Nexp){\n  K <- 3  \n  dat <- dat %>%\n    distinct(ID) %>%\n    slice_sample(n=Nexp) %>%\n    mutate(assgnt = runif(Nexp,0,1)) %>%\n    mutate(group = case_when(\n      assgnt < = 1/K ~ \"ctrl\",\n      assgnt > 1/K & assgnt < = 2/K ~ \"treat1\",\n      assgnt > 2/K ~ \"treat2\")) %>%\n    mutate(group = as.factor(group)) %>%\n    select(-assgnt)\n  return(dat)\n}\nno_strat_assgnt <- no_strat_assgnt_fun(hist_data, Nexp = 5000)\n```", "```py\n## Python\ndef no_strat_assgnt_fun(dat_df, Nexp, K):\n    dat_df = pd.DataFrame({'ID': dat_df.ID.unique()})\n    dat_df = dat_df.sample(Nexp)\n    dat_df['assgnt'] = np.random.uniform(0,1,Nexp)\n    dat_df['group'] = 'ctrl'\n    dat_df.loc[dat_df['assgnt'].between(0, 1/K, inclusive=True), \n               'group'] = 'treat1'\n    dat_df.loc[dat_df['assgnt'].between(1/K, 2/K, inclusive=False), \n               'group'] = 'treat2'\n    del(dat_df['assgnt'])\n    return dat_df\nno_strat_assgnt = no_strat_assgnt_fun(hist_data_df, Nexp = 5000, K = 3)\n```", "```py\n## R\nno_strat_assgnt_fun <- function(dat, Nexp, K){\n  dat <- dat %>%\n    distinct(ID) %>%\n    slice_sample(n=Nexp) %>%\n    mutate(assgnt = runif(Nexp,0,1)) %>%\n    mutate(group = -1) # initializing the “group” variable\n  for(i in seq(1,K)){\n    dat$group = ifelse(dat$assgnt >= (i-1)/K & dat$assgnt < i/K,i-1,dat$group)} \n  dat <- dat %>%\n    mutate(group = as.factor(group)) %>%\n    select(-assgnt)\n  return(dat)\n}\nno_strat_assgnt <- no_strat_assgnt_fun(hist_data, Nexp = 5000, K = 4)\n```", "```py\n## Python\ndef no_strat_assgnt_fun(dat_df, Nexp, K):\n    dat_df = pd.DataFrame({'ID': dat_df.ID.unique()})\n    dat_df = dat_df.sample(Nexp)\n    dat_df['assgnt'] = np.random.uniform(0,1,Nexp)\n    dat_df['group'] = -1 # initializing the “group” variable\n    for i in range(K):\n        dat_df.loc[dat_df['assgnt'].between(i/K, (i+1)/K, inclusive=True), \n               'group'] = i\n    del(dat_df['assgnt'])\n    return dat_df   \nno_strat_assgnt = no_strat_assgnt_fun(hist_data_df, Nexp = 5000, K = 4)\n```", "```py\n## Python code (output not shown)\ndef strat_prep_fun(dat_df):\n    # Extracting property-level variables\n    dat_df = dat_df.groupby(['ID']).agg(\n        tier = ('tier', 'mean'),\n        avg_review = ('avg_review', 'mean'),\n        sq_ft = ('sq_ft', 'mean'),\n        BPday = ('BPday', 'mean')).reset_index()\n    dat_df['tier'] = pd.Categorical(dat_df.tier, categories=[3,2,1], \n                                    ordered = True)\n    dat_df['ID'] = dat_df.ID.astype(str)\n    num_df = dat_df.copy().loc[:,dat_df.dtypes=='float64'] #Numeric vars \n    cat_df = dat_df.copy().loc[:,dat_df.dtypes=='category'] #Categorical vars\n\n    # Normalizing all numeric variables to [0,1]\n    scaler = MinMaxScaler()\n    scaler.fit(num_df)\n    num_np = scaler.transform(num_df)\n\n    # One-hot encoding all categorical variables\n    enc = OneHotEncoder(handle_unknown='ignore')\n    enc.fit(cat_df)\n    cat_np = enc.transform(cat_df).toarray()\n\n    #Binding arrays\n    data_np = np.concatenate((num_np, cat_np), axis=1)\n    del num_df, num_np, cat_df, cat_np, enc, scaler\n    return data_np\nprepped_data_np = strat_prep_fun(hist_data_df)\n```", "```py\n## R\n> strat_prep_fun <- function(dat){\n    # Extracting property-level variables\n    dat <- dat %>%\n      group_by(ID, tier) %>%\n      summarise(sq_ft = mean(sq_ft),\n                avg_review = mean(avg_review),\n                BPday = mean(BPday)) %>%\n      ungroup()\n\n    # Isolating the different components of our data\n    ID <- dat$ID  # Owner identifier\n    dat <- dat %>% select(-ID)\n    cat_vars <- dat %>%\n      #Selecting categorical variables\n      select_if(is.factor) \n    num_vars <- dat %>%\n      #Selecting numeric variables\n      select_if(function(x) is.numeric(x)|is.integer(x)) \n\n    #One-hot encoding categorical variables\n    cat_vars_out <- data.frame(predict(dummyVars(\" ~.\", data=cat_vars), \n                                       newdata = cat_vars))\n\n    # Normalizing numeric variables\n    num_vars_out <- num_vars %>%\n      mutate_all(rescale)\n\n    # Putting the variables back together\n    dat_out <- cbind(ID, num_vars_out, cat_vars_out)  %>%\n      mutate(ID = as.character(ID)) %>%\n      mutate_if(is.numeric, function(x) round(x, 4)) #Rounding for readability\n\n    return(dat_out)}\n> prepped_data <- strat_prep_fun(hist_data)\n`summarise()` regrouping output by 'ID' (override with `.groups` argument)\n> head(prepped_data, 5)\n    ID  sq_ft avg_review  BPday tier.3 tier.2 tier.1\n1    1 0.3321     0.3514 0.2365      1      0      0\n2   10 0.3802     0.7191 0.5231      1      0      0\n3  100 0.8370     0.6105 0.6603      0      0      1\n4 1000 0.4476     0.4882 0.3843      1      0      0\n5 1001 0.3323     0.7276 0.4316      0      1      0\n```", "```py\n## R\nstratified_data <- block(prepped_data, id.vars = c(\"ID\"), n.tr = 3, \n                         algorithm = \"naiveGreedy\", distance = \"euclidean\")\n```", "```py\n## R\n> Nexp <- 4998 #Restricting our data to a multiple of 3\n> stratified_data <- block_wrapper_fun(prepped_data, Nexp)\nWarning message:\nattributes are not identical across measure variables;\nthey will be dropped \n> head(stratified_data,3)\n    ID  sq_ft avg_review  BPday tier.3 tier.2 tier.1  group\n1  224 0.6932     0.8167 0.4964      1      0      0 treat1\n2 3627 0.4143     0.9290 0.6084      1      0      0 treat1\n3 4190 0.6686     0.5976 0.2820      1      0      0 treat1\n```", "```py\n## R\ntreat2_metric_fun <- function(dat){\n  lin_model <- lm(BPday~sq_ft+tier+avg_review+group, data = dat)\n  summ <- summary(lin_model)\n  coeff <- summ$coefficients['grouptreat2', 'Estimate']\n  return(coeff)}\n```", "```py\n## Python\n def treat2_metric_fun(dat_df):\n    model = ols(\"BPday~sq_ft+tier+avg_review+group\", data=dat_df)\n    res = model.fit(disp=0)\n    coeff = res.params['group[T.treat2]']\n    return coeff\n```", "```py\n## R\n> boot_CI_fun <- function(dat, metric_fun, B = 100, conf.level = 0.9){\n    #Setting the number of bootstrap samples\n    boot_metric_fun <- function(dat, J){\n      boot_dat <- dat[J,]\n      return(metric_fun(boot_dat))}\n    boot.out <- boot(data=dat, statistic=boot_metric_fun, R=B)\n    confint <- boot.ci(boot.out, conf = conf.level, type = c('perc'))\n    CI <- confint$percent[c(4,5)]\n\n    return(CI)}\n> decision_fun <- function(dat, metric_fun){\n    boot_CI <- boot_CI_fun(dat, metric_fun)\n    decision <- ifelse(boot_CI[1]>0,1,0)\n    return(decision)}\n```", "```py\n## Python\ndef boot_CI_fun(dat_df, metric_fun, B = 100, conf_level = 0.9):\n  #Setting sample size\n  N = len(dat_df)\n  coeffs = []\n\n  for i in range(B):\n      sim_data_df = dat_df.sample(n=N, replace = True)\n      coeff = metric_fun(sim_data_df)\n      coeffs.append(coeff)\n\n  coeffs.sort()\n  start_idx = round(B * (1 - conf_level) / 2)\n  end_idx = - round(B * (1 - conf_level) / 2)\n  confint = [coeffs[start_idx], coeffs[end_idx]]  \n  return(confint)\n\ndef decision_fun(dat_df, metric_fun, B = 100, conf_level = 0.9):\n    boot_CI = boot_CI_fun(dat_df, metric_fun, B = B, conf_level = conf_level)\n    decision = 1 if boot_CI[0] > 0  else 0\n    return decision\n```", "```py\n## R\nsingle_sim_fun <- function(dat, Nexp, eff_size){\n\n  #Filter the data down to a random month ![1](Images/1.png)          \n  per <- sample(1:35, size=1)\n  dat <- dat %>%\n    filter(period == per)\n\n  #Prepare the stratified assignment for a random sample of desired size ![2](Images/2.png) \n  stratified_assgnt <- dat %>%\n    slice_sample(n=Nexp) %>%\n    #Stratified assignment\n    block_wrapper_fun() %>%\n    #extract the ID and group assignment\n    select(ID, group)\n\n  sim_data <- dat %>%\n    #Apply assignment to full data ![3](Images/3.png)                           \n    inner_join(stratified_assgnt) %>%\n    #Add target effect size\n    mutate(BPday = ifelse(group == 'treat2', BPday + eff_size, BPday))\n\n  #Calculate the decision (we want it to be 1) ![4](Images/4.png)    \n  decision <- decision_fun(sim_data, treat2_metric_fun)\n  return(decision)}\n```", "```py\n## Python\ndef single_sim_fun(dat_df, metric_fun, Nexp, eff_size, B = 100, \n                   conf_level = 0.9):\n\n    #Filter the data down to a random month ![1](Images/1.png) \n    per = random.sample(range(35), 1)[0] + 1\n    dat_df = dat_df.loc[dat_df.period == per]\n    dat_df = dat_df.sample(n=Nexp)\n\n    #Prepare the stratified assignment for a random sample of desired size ![2](Images/2.png)\n    assgnt = strat_assgnt_fun(dat_df, Nexp = Nexp)\n    sim_data_df = dat_df.merge(assgnt, on='ID', how='inner')\n\n    #Add target effect size ![3](Images/3.png)\n    sim_data_df.BPday = np.where(sim_data_df.group == 'treat2', \n                                 sim_data_df.BPday + eff_size, sim_data_df.BPday)\n\n    #Calculate the decision (we want it to be 1) ![4](Images/4.png)  \n    decision = decision_fun(sim_data_df, metric_fun, B = B, \n                            conf_level = conf_level)\n    return decision\n```", "```py\n## R\npower_sim_fun <- function(dat, Nexp, eff_size, Nsim){\n  power_list <- vector(mode = \"list\", length = Nsim)\n  for(i in 1:Nsim){\n    power_list[[i]] <- single_sim_fun(dat, Nexp, eff_size)}\n  power <- mean(unlist(power_list))\n  return(power)}\n```", "```py\n## Python\ndef power_sim_fun(dat_df, metric_fun, Nexp, eff_size, Nsim, B = 100, \n                  conf_level = 0.9):\n    power_lst = []\n    for i in range(Nsim):\n        power_lst.append(single_sim_fun(dat_df, metric_fun = metric_fun, \n                                        Nexp = Nexp, eff_size = eff_size, \n                                        B = B, conf_level = conf_level))\n    power = np.mean(power_lst)\n    return(power)\n```", "```py\n## Python (output not shown)\nexp_data_reg_df = exp_data_df.copy()\nexp_data_reg_df.BPday = np.where((exp_data_reg_df.compliant == 1) & \\\n                                 (exp_data_reg_df.group == 'treat2'), \n                                 exp_data_reg_df.BPday -10, \n                                 exp_data_reg_df.BPday)\nprint(ols(\"BPday~sq_ft+tier+avg_review+group\", \n          data=exp_data_reg_df).fit(disp=0).summary())\n```", "```py\n## R\n> exp_data_reg <- exp_data %>%\n    mutate(BPday = BPday - ifelse(group==\"treat2\" & compliant, 10,0))\n> lin_model <- lm(BPday~sq_ft+tier+avg_review+group, data = exp_data_reg)\n> summary(lin_model)\n\n...\nCoefficients:\n             Estimate Std. Error t value        Pr(>|t|)    \n(Intercept) 19.232831   3.573522   5.382 0.0000000854103 ***\nsq_ft        0.006846   0.003726   1.838          0.0663 .  \ntier2        1.059599   0.840598   1.261          0.2077    \ntier1        5.170473   1.036066   4.990 0.0000006728868 ***\navg_review   1.692557   0.253566   6.675 0.0000000000347 ***\n`grouptreat1`  `0.966938`   `0.888683`   `1.088`          `0.2767`\n`grouptreat2` `-0.172594`   `0.888391`  `-0.194`          `0.8460`\n...\n```", "```py\n## R (output not shown)\n> exp_data_reg %>%\n    group_by(group) %>%\n    summarise(compliance_rate = mean(compliant))\n```", "```py\n## Python\nexp_data_reg_df.groupby('group').agg(compliance_rate = ('compliant', 'mean'))\nOut[15]: \n        compliance_rate\ngroup                  \nctrl              1.000\ntreat1            0.238\ntreat2            0.166\n```"]