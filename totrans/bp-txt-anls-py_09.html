<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 9. Text Summarization"><div class="chapter" id="ch-summarization">
<h1><span class="label">Chapter 9. </span>Text Summarization</h1>

<p>There is a massive amount of information on the internet on every topic. A Google search returns millions of search results containing text, images, videos, and so on. Even if we consider only the text content, it’s not possible to read through it all. Text <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="about" id="ch9_term1"/>summarization methods are able to condense text information to a short summary of a few lines or a paragraph and make it digestible to most users. Applications of text summarization can be found not just on the internet but also in fields like paralegal case summaries, book synopses, etc.</p>

<section data-type="sect1" data-pdf-bookmark="What You’ll Learn and What We’ll Build"><div class="sect1" id="idm45634184785624">
<h1>What You’ll Learn and What We’ll Build</h1>

<p>In this chapter, we will start with an introduction to text summarization and provide an overview of the methods used. We will analyze different types of text data and their specific characteristics that are useful in determining the choice of summarization method. We will provide blueprints that apply these methods to different use cases and analyze their performance. At the end of this chapter, you will have a good understanding of different text summarization methods and be able to choose the right approach for any application.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Text Summarization"><div class="sect1" id="idm45634184783512">
<h1>Text Summarization</h1>

<p>It is likely that you have undertaken a summarization task knowingly or unknowingly at some point in life. Examples are telling a friend about a movie you watched last night and trying to explain your work to your family. We all like to provide a brief summary of our experiences to the rest of the world to share our feelings and motivate others. <em>Text summarization</em> is defined as the method used for generating a concise summary of longer text while still conveying useful information and without losing the overall context. This is a method that we are quite familiar with: when reading course textbooks, lecture notes, or even this book, many students will try to highlight important sentences or make short notes to capture the important concepts. Automatic text summarization methods allow us to use computers to do this task.</p>

<p>Summarization methods can be broadly classified into <em>extraction</em> and <em>abstraction</em> methods. In <a contenteditable="false" data-type="indexterm" data-primary="extractive methods for text summarization" id="idm45634184779240"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="extractive methods for" id="idm45634184778136"/>extractive summarization, important phrases or sentences are identified in a given body of text and combined to form the summary of the entire text. Such methods identify the important parts of text by assigning weights correctly, remove sentences that might convey redundant information, rank different parts of the text, and combine the most important ones as the summary. These methods select a part of the original text as the summary, so while each sentence would be grammatically accurate, it may not form a cohesive paragraph.</p>

<p>Abstractive <a contenteditable="false" data-type="indexterm" data-primary="abstractive methods for text summarization" id="idm45634184775672"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="abstractive methods for" id="idm45634184774504"/>summarization methods, on the other hand, try to paraphrase and generate a summary just like a human would. This typically involves the use of deep neural networks that are capable of generating phrases and sentences that provide a grammatically accurate summary of the text and not just picking out important words or sentences. However, the <a contenteditable="false" data-type="indexterm" data-primary="neural networks" id="idm45634184772648"/>process of training deep neural networks requires a lot of training data and addresses multiple subdomains within NLP, like natural language generation, semantic segmentation, etc.</p>

<p>Abstractive summarization methods are an area of active research with several <a href="https://oreil.ly/DxXd1">approaches</a> looking to improve the state of the art. The <a contenteditable="false" data-type="indexterm" data-primary="Transformers library" id="idm45634184769896"/><a href="https://oreil.ly/JS-x8"><code>Transformers</code> library</a> from <a contenteditable="false" data-type="indexterm" data-primary="Hugging Face" id="idm45634184767816"/>Hugging Face provides an implementation that <a contenteditable="false" data-type="indexterm" data-primary="pretrained models" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634184766488"/>uses a pre-trained model to perform the summarization task. We explore the concept of pre-trained models and the Transformers library in more detail in <a data-type="xref" href="ch11.xhtml#ch-sentiment">Chapter 11</a>. Extractive summarization is preferred in many use cases because these methods are simple to implement and fast to run. In this chapter, we will focus on blueprints using extractive summarization.</p>

<p>Let’s say you <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="use cases for" id="idm45634184763080"/><a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634184761672"/>are working with a legal firm that wants to review historical cases to help prepare for a current case. Since case proceedings and judgments are very long, they want to generate summaries and review the entire case only if it’s relevant. Such a summary helps them to quickly look at multiple cases and allocate their time efficiently. We can consider this an example of text summarization applied to long-form text. Another use case might be a media company that wants to send a newsletter to its subscribers every morning highlighting the important events of the previous day. Customers don’t appreciate long emails, and therefore creating a short summary of each article is important to keep them engaged. In this use case, you need to summarize shorter pieces of text. While working on these projects, maybe you have to work in a team that uses a chat communication tool like Slack or Microsoft Teams. There are shared chat groups (or channels) where all team members can communicate with each other. If you are away for a few hours in a meeting, it can quickly get flooded with multiple messages and discussions. As a user, it’s hard to go through 100+ unread messages, and you can’t be sure if you missed something important. In such a situation, it can be beneficial to have a way to summarize these missed discussions with the help of an automated bot.</p>

<p>In each of the use cases, we see a <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="for different types of text data" data-secondary-sortas="different types of text data" id="idm45634184758104"/>different type of text that we are looking to summarize. Let’s briefly present them again:</p>

<ul>
	<li>Long-form text written in a structured manner, containing paragraphs, and spread across multiple pages. Examples include case proceedings, research papers, textbooks, etc.</li>
	<li>Short-form text such as news articles, and blogs where images, data, and other graphical elements might be present.</li>
	<li>Multiple, short pieces of text in the form of conversations that can contain special characters such as emojis and are not very structured. Examples include Twitter threads, online discussion forums, and group messaging applications.</li>
</ul>

<p>Each of these types of text data presents information differently, and therefore the method used to summarize one may not work for the other. In our blueprints we present methods that work for these text types and provide guidance to determine the <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term1" id="idm45634184753272"/>appropriate method.</p>

<section data-type="sect2" data-pdf-bookmark="Extractive Methods"><div class="sect2" id="idm45634184751640">
<h2>Extractive Methods</h2>

<p>All extractive <a contenteditable="false" data-type="indexterm" data-primary="extractive methods for text summarization" id="idm45634184750280"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="extractive methods for" id="idm45634184749048"/>methods follow these three basic steps:</p>

<ol>
	<li>Create an intermediate representation of the text.</li>
	<li>Score the sentences/phrases based on the chosen representation.</li>
	<li>Rank and choose sentences to create a summary of the text.</li>
</ol>

<p>While most blueprints will follow these steps, the specific method that they use to create the intermediate representation or score will vary.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Data Preprocessing"><div class="sect2" id="idm45634184745016">
<h2>Data Preprocessing</h2>

<p>Before proceeding to the actual blueprint, we will <a contenteditable="false" data-type="indexterm" data-primary="data preprocessing" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634184743224"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="data preprocessing for" id="idm45634184741576"/>reuse the blueprint from <a data-type="xref" href="ch03.xhtml#ch-scraping">Chapter 3</a> to read a given URL that we would like to summarize. In this blueprint we will focus on generating a summary using the text, but you can study <a data-type="xref" href="ch03.xhtml#ch-scraping">Chapter 3</a> to get a detailed overview of extracting data from a URL. The <a contenteditable="false" data-type="indexterm" data-primary="datasets, examples of" data-secondary="Reuters News Archive" id="ch9_term4"/><a contenteditable="false" data-type="indexterm" data-primary="Reuters News Archive" id="ch9_term6"/>output of the article has been shortened for brevity; to view the entire article, you can follow the URL:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code> <code class="nn">reprlib</code>
<code class="n">r</code> <code class="o">=</code> <code class="n">reprlib</code><code class="o">.</code><code class="n">Repr</code><code class="p">()</code>
<code class="n">r</code><code class="o">.</code><code class="n">maxstring</code> <code class="o">=</code> <code class="mi">800</code>

<code class="n">url1</code> <code class="o">=</code> <code class="s2">"https://www.reuters.com/article/us-qualcomm-m-a-broadcom-5g/</code><code class="se">\</code>
<code class="s2">        what-is-5g-and-who-are-the-major-players-idUSKCN1GR1IN"</code>
<code class="n">article_name1</code> <code class="o">=</code> <code class="n">download_article</code><code class="p">(</code><code class="n">url1</code><code class="p">)</code>
<code class="n">article1</code> <code class="o">=</code> <code class="n">parse_article</code><code class="p">(</code><code class="n">article_name1</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Article Published on'</code><code class="p">,</code> <code class="n">r</code><code class="o">.</code><code class="n">repr</code><code class="p">(</code><code class="n">article1</code><code class="p">[</code><code class="s1">'time'</code><code class="p">]))</code>
<code class="k">print</code> <code class="p">(</code><code class="n">r</code><code class="o">.</code><code class="n">repr</code><code class="p">(</code><code class="n">article1</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Article Published on '2018-03-15T11:36:28+0000'
'LONDON/SAN FRANCISCO (Reuters) - U.S. President Donald Trump has blocked
microchip maker Broadcom Ltd’s (AVGO.O) $117 billion takeover of rival Qualcomm
(QCOM.O) amid concerns that it would give China the upper hand in the next
generation of mobile communications, or 5G. A 5G sign is seen at the Mobile
World Congress in Barcelona, Spain February 28, 2018. REUTERS/Yves HermanBelow
are some facts... 4G wireless and looks set to top the list of patent holders
heading into the 5G cycle. Huawei, Nokia, Ericsson and others are also vying to
amass 5G patents, which has helped spur complex cross-licensing agreements like
the deal struck late last year Nokia and Huawei around handsets. Editing by Kim
Miyoung in Singapore and Jason Neely in LondonOur Standards:The Thomson Reuters
Trust Principles.'
</pre>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>We make use of the <code>reprlib</code> package, which allows us to customize the output of the print statement. In this case, printing the contents of the full article would not make sense. We limit the size of the output to 800 characters, and the <code>reprlib</code> package reformats the output to show a selected sequence of words from the beginning and end of the article.</p>
</div>
</div></section>
</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Summarizing Text Using Topic Representation"><div class="sect1" id="idm45634184782888">
<h1>Blueprint: Summarizing Text Using <span class="keep-together">Topic Representation</span></h1>

<p>Let’s first try to <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="topic representation for" id="ch9_term2"/><a contenteditable="false" data-type="indexterm" data-primary="topic representation for text summarization" id="ch9_term3"/>summarize the example Reuters article ourselves. Having read through it, we could provide the following manually generated summary:</p>

<blockquote>5G is the next generation of wireless technology that will rely on denser arrays of small antennas to offer data speeds up to 50 or 100 times faster than current 4G networks. These new networks are supposed to deliver faster data not just to phones and computers but to a whole array of sensors in cars, cargo, crop equipment, etc. Qualcomm is the dominant player in smartphone communications chips today, and the concern is that a takeover by Singapore-based Broadcom could see the firm cut research and development spending by Qualcomm or hive off strategically important parts of the company to other buyers, including in China. This risked weakening Qualcomm, which would boost China over the United States in the 5G race.</blockquote>

<p class="pagebreak-before">As humans, we understand what the article is conveying and then generate a summary of our understanding. However, an algorithm doesn’t have this understanding and therefore has to rely on the identification of important topics to determine whether a sentence should be included in the summary. In the example article, topics could be broad themes like technology, telecommunications, and 5G, but to an algorithm this is nothing but a collection of important words. Our first method tries to distinguish between important and not-so-important words that allows us to then give a higher rank to sentences that contain important words.</p>

<section data-type="sect2" data-pdf-bookmark="Identifying Important Words with TF-IDF Values"><div class="sect2" id="idm45634184629080">
<h2>Identifying Important Words with TF-IDF Values</h2>

<p>The simplest approach would be to identify important sentences based on an aggregate of the TF-IDF values of the words in that sentence. A detailed explanation of TF-IDF is provided in <a data-type="xref" href="ch05.xhtml#ch-vectorization">Chapter 5</a>, but for <a contenteditable="false" data-type="indexterm" data-primary="TF-IDF (Term-Frequency Inverse Document Frequency) weighting" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634184626376"/><a contenteditable="false" data-type="indexterm" data-primary="words" data-secondary="identification of important" id="idm45634184624728"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="TF-IDF method for" id="idm45634184623384"/>this blueprint, we apply the TF-IDF vectorization and then aggregate the values to a sentence level. We can generate a score for each sentence as a sum of the TF-IDF values for each word in that sentence. This would mean that a sentence with a high score contains many important words as compared to other sentences in the article:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sklearn.feature_extraction.text</code> <code class="kn">import</code> <code class="n">TfidfVectorizer</code>
<code class="kn">from</code> <code class="nn">nltk</code> <code class="kn">import</code> <code class="n">tokenize</code>

<code class="n">sentences</code> <code class="o">=</code> <code class="n">tokenize</code><code class="o">.</code><code class="n">sent_tokenize</code><code class="p">(</code><code class="n">article1</code><code class="p">[</code><code class="s1">'text'</code><code class="p">])</code>
<code class="n">tfidfVectorizer</code> <code class="o">=</code> <code class="n">TfidfVectorizer</code><code class="p">()</code>
<code class="n">words_tfidf</code> <code class="o">=</code> <code class="n">tfidfVectorizer</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">sentences</code><code class="p">)</code>
</pre>

<p>In this case, there are approximately 20 sentences in the article, and we chose to create a condensed summary that is only 10% of the size of the original article (approximately two to three sentences). We sum up the TF-IDF values for each sentence and use <code>np.argsort</code> to sort them. This method sorts the indices of each sentence in ascending order, and we reverse the returned indices using <code>[::-1]</code>. To ensure the same flow of thoughts as presented in the article, we print the chosen summarized sentences in the same order in which they appear. We can see the results of our generated summary, as shown here:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="c1"># Parameter to specify number of summary sentences required</code>
<code class="n">num_summary_sentence</code> <code class="o">=</code> <code class="mi">3</code>

<code class="c1"># Sort the sentences in descending order by the sum of TF-IDF values</code>
<code class="n">sent_sum</code> <code class="o">=</code> <code class="n">words_tfidf</code><code class="o">.</code><code class="n">sum</code><code class="p">(</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="n">important_sent</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">argsort</code><code class="p">(</code><code class="n">sent_sum</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">)[::</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>

<code class="c1"># Print three most important sentences in the order they appear in the article</code>
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">sentences</code><code class="p">)):</code>
    <code class="k">if</code> <code class="n">i</code> <code class="ow">in</code> <code class="n">important_sent</code><code class="p">[:</code><code class="n">num_summary_sentence</code><code class="p">]:</code>
        <code class="k">print</code> <code class="p">(</code><code class="n">sentences</code><code class="p">[</code><code class="n">i</code><code class="p">])</code>
</pre>

<p class="pagebreak-before"><code>Out:</code></p>

<pre data-type="programlisting">
LONDON/SAN FRANCISCO (Reuters) - U.S. President Donald Trump has blocked
microchip maker Broadcom Ltd’s (AVGO.O) $117 billion takeover of rival Qualcomm
(QCOM.O) amid concerns that it would give China the upper hand in the next
generation of mobile communications, or 5G.
5G networks, now in the final testing stage, will rely on denser arrays of
small antennas and the cloud to offer data speeds up to 50 or 100 times faster
than current 4G networks and serve as critical infrastructure for a range of
industries.
The concern is that a takeover by Singapore-based Broadcom could see the firm
cut research and development spending by Qualcomm or hive off strategically
important parts of the company to other buyers, including in China, U.S.
officials and analysts have said.
</pre>

<p>In this method, we create an intermediate representation of the text using TF-IDF values, score the sentences based on this, and pick three sentences with the highest score. The sentences selected using this method agree with the manual summary we wrote earlier and capture the main points covered by the article. Some nuances like the importance of Qualcomm in the industry and the specific applications of 5G technology are missing. But this method serves as a good blueprint to quickly identify important sentences and automatically generate the summary for news articles. We <a contenteditable="false" data-type="indexterm" data-primary="tfidf_summary function" id="idm45634184476920"/>wrap this blueprint into a function <code>tfidf_summary</code> that is defined in the accompanying notebook and reused later in the chapter.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="LSA Algorithm"><div class="sect2" id="idm45634184475176">
<h2>LSA Algorithm</h2>

<p>One of the <a contenteditable="false" data-type="indexterm" data-primary="Latent Semantic Analysis/Indexing (LSA)" id="ch9_term7"/><a contenteditable="false" data-type="indexterm" data-primary="LSA (latent semantic analysis) algorithm" id="ch9_term8"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="LSA algorithm for" id="ch9_term9"/>modern methods used <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="extractive methods for" id="idm45634184468664"/><a contenteditable="false" data-type="indexterm" data-primary="extractive methods for text summarization" id="idm45634184467256"/>in extractive-based summarization is <em>latent semantic analysis</em> (LSA). LSA is a general-purpose method that is used for topic modeling, document similarity, and other tasks. LSA assumes that words that are close in meaning will occur in the same documents. In the LSA algorithm, we first represent the entire article in the <a contenteditable="false" data-type="indexterm" data-primary="sentence-term matrix" id="idm45634184465304"/>form of a sentence-term matrix. The concept of a document-term matrix has been introduced in <a data-type="xref" href="ch08.xhtml#ch-topicmodels">Chapter 8</a>, and we can adapt the concept to fit a sentence-term matrix. Each row represents a sentence, and each column represents a word. The value of each cell in this matrix is the word frequency often scaled as TF-IDF weights. The objective of this method is to reduce all the words to a few topics by creating a modified representation of the sentence-term matrix. To create the modified representation, we apply the method <a contenteditable="false" data-type="indexterm" data-primary="NMF (Nonnegative Matrix Factorization) for topic modeling" id="idm45634184462600"/>of nonnegative matrix factorization that expresses this matrix as the product of two new decomposed matrices that have fewer rows/columns. You can refer to <a data-type="xref" href="ch08.xhtml#ch-topicmodels">Chapter 8</a> for a more detailed understanding of this method. After the matrix decomposition step, we can generate the summary by choosing the top N important topics and then picking the most important sentences for each of these topics to form our summary.</p>

<p>Instead of applying LSA from scratch, we make <a contenteditable="false" data-type="indexterm" data-primary="sumy library for text summarization" id="idm45634184459720"/>use of the package <code>sumy</code>, which can be installed using the command <code><strong>pip install sumy</strong></code>. It provides multiple summarization methods within the same library. This library uses an integrated stop words list along with the tokenizer and stemmer functionality from NLTK but makes this configurable. In addition, it is also able to read input from plain text, HTML, and files. This gives us the ability to quickly test different summarization methods and change the default configurations to suit specific use cases. For now, we will go with the default options, including identifying the top three sentences:<sup><a data-type="noteref" id="idm45634184456856-marker" href="ch09.xhtml#idm45634184456856">1</a></sup></p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sumy.parsers.plaintext</code> <code class="kn">import</code> <code class="n">PlaintextParser</code>
<code class="kn">from</code> <code class="nn">sumy.nlp.tokenizers</code> <code class="kn">import</code> <code class="n">Tokenizer</code>
<code class="kn">from</code> <code class="nn">sumy.nlp.stemmers</code> <code class="kn">import</code> <code class="n">Stemmer</code>
<code class="kn">from</code> <code class="nn">sumy.utils</code> <code class="kn">import</code> <code class="n">get_stop_words</code>

<code class="kn">from</code> <code class="nn">sumy.summarizers.lsa</code> <code class="kn">import</code> <code class="n">LsaSummarizer</code>

<code class="n">LANGUAGE</code> <code class="o">=</code> <code class="s2">"english"</code>
<code class="n">stemmer</code> <code class="o">=</code> <code class="n">Stemmer</code><code class="p">(</code><code class="n">LANGUAGE</code><code class="p">)</code>

<code class="n">parser</code> <code class="o">=</code> <code class="n">PlaintextParser</code><code class="o">.</code><code class="n">from_string</code><code class="p">(</code><code class="n">article1</code><code class="p">[</code><code class="s1">'text'</code><code class="p">],</code> <code class="n">Tokenizer</code><code class="p">(</code><code class="n">LANGUAGE</code><code class="p">))</code>
<code class="n">summarizer</code> <code class="o">=</code> <code class="n">LsaSummarizer</code><code class="p">(</code><code class="n">stemmer</code><code class="p">)</code>
<code class="n">summarizer</code><code class="o">.</code><code class="n">stop_words</code> <code class="o">=</code> <code class="n">get_stop_words</code><code class="p">(</code><code class="n">LANGUAGE</code><code class="p">)</code>

<code class="k">for</code> <code class="n">sentence</code> <code class="ow">in</code> <code class="n">summarizer</code><code class="p">(</code><code class="n">parser</code><code class="o">.</code><code class="n">document</code><code class="p">,</code> <code class="n">num_summary_sentence</code><code class="p">):</code>
    <code class="k">print</code> <code class="p">(</code><code class="nb">str</code><code class="p">(</code><code class="n">sentence</code><code class="p">))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
LONDON/SAN FRANCISCO (Reuters) - U.S. President Donald Trump has blocked
microchip maker Broadcom Ltd’s (AVGO.O) $117 billion takeover of rival Qualcomm
(QCOM.O) amid concerns that it would give China the upper hand in the next
generation of mobile communications, or 5G.
Moving to new networks promises to enable new mobile services and even whole
new business models, but could pose challenges for countries and industries
unprepared to invest in the transition.
The concern is that a takeover by Singapore-based Broadcom could see the firm
cut research and development spending by Qualcomm or hive off strategically
important parts of the company to other buyers, including in China, U.S.
officials and analysts have said.
</pre>

<p>By analyzing the results, we see that there is a <a contenteditable="false" data-type="indexterm" data-primary="TF-IDF (Term-Frequency Inverse Document Frequency) weighting" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634184338904"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="TF-IDF method for" id="idm45634184337320"/>difference in only one sentence from the results of the TF-IDF, and that is sentence 2. While the LSA method chose to highlight a sentence that captures the topic about challenges, the TF-IDF method chose a sentence that provides more information about 5G. In this scenario, the summaries generated by the two methods are not very different, but let’s analyze how this method works on a longer article.</p>

<p class="pagebreak-before">We wrap this blueprint into a function <code>lsa_summary</code>, which is defined in the accompanying notebook and can be reused:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">r</code><code class="o">.</code><code class="n">maxstring</code> <code class="o">=</code> <code class="mi">800</code>
<code class="n">url2</code> <code class="o">=</code> <code class="s2">"https://www.reuters.com/article/us-usa-economy-watchlist-graphic/</code><code class="se">\</code>
<code class="s2">        predicting-the-next-u-s-recession-idUSKCN1V31JE"</code>
<code class="n">article_name2</code> <code class="o">=</code> <code class="n">download_article</code><code class="p">(</code><code class="n">url2</code><code class="p">)</code>
<code class="n">article2</code> <code class="o">=</code> <code class="n">parse_article</code><code class="p">(</code><code class="n">article_name2</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Article Published'</code><code class="p">,</code> <code class="n">r</code><code class="o">.</code><code class="n">repr</code><code class="p">(</code><code class="n">article1</code><code class="p">[</code><code class="s1">'time'</code><code class="p">]))</code>
<code class="k">print</code> <code class="p">(</code><code class="n">r</code><code class="o">.</code><code class="n">repr</code><code class="p">(</code><code class="n">article2</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Article Published '2018-03-15T11:36:28+0000'
'NEW YORK A protracted trade war between China and the United States, the
world’s largest economies, and a deteriorating global growth outlook has left
investors apprehensive about the end to the longest expansion in American
history. FILE PHOTO: Ships and shipping containers are pictured at the port of
Long Beach in Long Beach, California, U.S., January 30, 2019.   REUTERS/Mike
BlakeThe recent ...hton wrote in the June Cass Freight Index report.  12.
MISERY INDEX The so-called Misery Index adds together the unemployment rate and
the inflation rate. It typically rises during recessions and sometimes prior to
downturns. It has slipped lower in 2019 and does not look very miserable.
Reporting by Saqib Iqbal Ahmed; Editing by Chizu NomiyamaOur Standards:The
Thomson Reuters Trust Principles.'
</pre>

Then:

<pre data-code-language="python" data-type="programlisting">
<code class="n">summary_sentence</code> <code class="o">=</code> <code class="n">tfidf_summary</code><code class="p">(</code><code class="n">article2</code><code class="p">[</code><code class="s1">'text'</code><code class="p">],</code> <code class="n">num_summary_sentence</code><code class="p">)</code>
<code class="k">for</code> <code class="n">sentence</code> <code class="ow">in</code> <code class="n">summary_sentence</code><code class="p">:</code>
    <code class="k">print</code> <code class="p">(</code><code class="n">sentence</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
REUTERS/Mike BlakeThe recent rise in U.S.-China trade war tensions has brought
forward the next U.S. recession, according to a majority of economists polled
by Reuters who now expect the Federal Reserve to cut rates again in September
and once more next year.
On Tuesday, U.S. stocks jumped sharply higher and safe-havens like the Japanese
yen and Gold retreated after the U.S. Trade Representative said additional
tariffs on some Chinese goods, including cell phones and laptops, will be
delayed to Dec. 15.
ISM said its index of national factory activity slipped to 51.2 last month, the
lowest reading since August 2016, as U.S. manufacturing activity slowed to a
near three-year low in July and hiring at factories shifted into lower gear,
suggesting a further loss of momentum in economic growth early in the third
quarter.
</pre>

And finally:

<pre data-code-language="python" data-type="programlisting">
<code class="n">summary_sentence</code> <code class="o">=</code> <code class="n">lsa_summary</code><code class="p">(</code><code class="n">article2</code><code class="p">[</code><code class="s1">'text'</code><code class="p">],</code> <code class="n">num_summary_sentence</code><code class="p">)</code>
<code class="k">for</code> <code class="n">sentence</code> <code class="ow">in</code> <code class="n">summary_sentence</code><code class="p">:</code>
    <code class="k">print</code> <code class="p">(</code><code class="n">sentence</code><code class="p">)</code>
</pre>

<p class="pagebreak-before"><code>Out:</code></p>

<pre data-type="programlisting">
NEW YORK A protracted trade war between China and the United States, the
world’s largest economies, and a deteriorating global growth outlook has left
investors apprehensive about the end to the longest expansion in American
history.
REUTERS/Mike BlakeThe recent rise in U.S.-China trade war tensions has brought
forward the next U.S. recession, according to a majority of economists polled
by Reuters who now expect the Federal Reserve to cut rates again in September
and once more next year.
Trade tensions have pulled corporate confidence and global growth to multi-year
lows and U.S. President Donald Trump’s announcement of more tariffs have raised
downside risks significantly, Morgan Stanley analysts said in a recent note.
</pre>

<p>The difference in the chosen summarized sentences becomes more evident here. The main topic of the trade war tensions is captured by both methods, but the LSA summarizer also highlights important topics such as the apprehensiveness of investors and corporate confidence. While <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="TF-IDF method for" id="idm45634184150360"/><a contenteditable="false" data-type="indexterm" data-primary="TF-IDF (Term-Frequency Inverse Document Frequency) weighting" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634184148984"/>the TF-IDF tries to express the same idea in its chosen sentences, it does not pick the right sentences and therefore fails to convey the idea. There are other topic-based summarization methods, but we have chosen to highlight LSA as a simple and widely used method.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>It’s interesting to note that the <code>sumy</code> library also provides the implementation of <a contenteditable="false" data-type="indexterm" data-primary="Luhn, Hans Peter" id="idm45634184145240"/>one of the oldest methods for automatic text summarization (<code>LuhnSummarizer</code>), which was created by <a href="https://oreil.ly/j6cQI">Hans Peter Luhn in 1958</a>. This method is also based on topic representation by identifying important words using their counts and setting thresholds to get rid of extremely frequent and infrequent words. You can use this as a baseline method for your summarization experiments and compare improvements provided <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term2" id="idm45634184142600"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term3" id="idm45634184141224"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term7" id="idm45634184139848"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term8" id="idm45634184138472"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term9" id="idm45634184137096"/>by other methods.</p>
</div>
</div></section>
</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Summarizing Text Using an Indicator Representation"><div class="sect1" id="idm45634184474552">
<h1>Blueprint: Summarizing Text Using an Indicator Representation</h1>

<p>Indicator representation <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="indicator representation (TextRank) for" id="ch9_term11"/>methods aim to create the intermediate representation of a sentence by using features of the sentence and its relationship to others in the document rather than using only the words in the sentence. <a contenteditable="false" data-type="indexterm" data-primary="TextRank method" id="idm45634184107448"/><a href="https://oreil.ly/yY29h">TextRank</a> is one of the most popular examples of an indicator-based method. TextRank is inspired by PageRank, a “graph-based ranking algorithm that was originally used by Google to rank search results. As per the authors of the TextRank paper, graph-based algorithms rely on the collective knowledge of web architects rather than individual content analysis of web pages,” which leads to improved performance. Applied to our context, we will rely on the features of a sentence and the linkages between them rather than on topics contained in each sentence.</p>

<p>We will first try to <a contenteditable="false" data-type="indexterm" data-primary="PageRank algorithm" id="idm45634184104904"/>understand how the PageRank algorithm works and then adapt the methodology to the text summarization problem. Let’s consider a list of web pages—(A, B, C, D, E, and F) and their links to one another. In <a data-type="xref" href="#fig-pagerank-graph">Figure 9-1</a>, page A contains a link to page D. Page B contains links to A and D and so on. We can also represent this in the form of a matrix with rows referring to each page and with columns referring to incoming links from other pages. The matrix shown in the figure represents our graph with rows representing each node, columns referring to incoming links from other nodes, and the value of the cell representing the weight of the edge between them. We start with a simple representation (1 indicates an incoming link, 0 indicates none). We can then normalize these values by dividing by the total number of outgoing links for each web page. For example, page C has two outgoing links (to pages E and F), and therefore the value of each outgoing link is 0.5.</p>

<figure><div id="fig-pagerank-graph" class="figure"><img src="Images/btap_0901.jpg" width="979" height="610"/>
<h6><span class="label">Figure 9-1. </span>Web page links and corresponding PageRank matrix.</h6>
</div></figure>

<p>The PageRank for a given page is a weighted sum of the PageRank for all other pages that have a link to it. This also means that calculating the PageRank is an iterative function where we must start with some assumed values of PageRank for each page. If we assume all initial values to be 1 and multiply the matrices as shown in <a data-type="xref" href="#fig-pagerank-results">Figure 9-2</a>, we arrive at the PageRank for each page after one iteration (not taking into consideration the damping factor for this illustration).</p>



<p>The <a href="https://oreil.ly/WjjFv">research paper by Brin and Page</a> showed that after repeating this calculation for many iterations the values stabilize, and hence we get the PageRank or importance for each page. <a contenteditable="false" data-type="indexterm" data-primary="TextRank method" id="ch9_term12"/><span class="keep-together">TextRank</span> adapts the previous approach by considering each sentence in the text to be analogous to a page and therefore a node in the graph. The weight of the edges between nodes is determined by the similarity between sentences, and the authors of TextRank suggest a simple approach by counting the number of shared lexical tokens, normalized by the size of both sentences. There are other similarity measures such as cosine distance and longest common substring that can also be used.</p>

<figure><div id="fig-pagerank-results" class="figure"><img src="Images/btap_0902.jpg" width="1076" height="553"/>
	<h6><span class="label">Figure 9-2. </span>Application of one iteration of PageRank algorithm.</h6>
</div></figure>

<p>Since the <a contenteditable="false" data-type="indexterm" data-primary="sumy library for text summarization" id="idm45634184092440"/>sumy package also provides a TextRank implementation, we will use it to generate the summarized sentences for the article on the US recession that we saw previously:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sumy.summarizers.text_rank</code> <code class="kn">import</code> <code class="n">TextRankSummarizer</code>

<code class="n">parser</code> <code class="o">=</code> <code class="n">PlaintextParser</code><code class="o">.</code><code class="n">from_string</code><code class="p">(</code><code class="n">article2</code><code class="p">[</code><code class="s1">'text'</code><code class="p">],</code> <code class="n">Tokenizer</code><code class="p">(</code><code class="n">LANGUAGE</code><code class="p">))</code>
<code class="n">summarizer</code> <code class="o">=</code> <code class="n">TextRankSummarizer</code><code class="p">(</code><code class="n">stemmer</code><code class="p">)</code>
<code class="n">summarizer</code><code class="o">.</code><code class="n">stop_words</code> <code class="o">=</code> <code class="n">get_stop_words</code><code class="p">(</code><code class="n">LANGUAGE</code><code class="p">)</code>

<code class="k">for</code> <code class="n">sentence</code> <code class="ow">in</code> <code class="n">summarizer</code><code class="p">(</code><code class="n">parser</code><code class="o">.</code><code class="n">document</code><code class="p">,</code> <code class="n">num_summary_sentence</code><code class="p">):</code>
    <code class="k">print</code> <code class="p">(</code><code class="nb">str</code><code class="p">(</code><code class="n">sentence</code><code class="p">))</code>
</pre>

<pre data-type="programlisting">
REUTERS/Mike BlakeThe recent rise in U.S.-China trade war tensions has brought
forward the next U.S. recession, according to a majority of economists polled
by Reuters who now expect the Federal Reserve to cut rates again in September
and once more next year.
As recession signals go, this so-called inversion in the yield curve has a
solid track record as a predictor of recessions.
Markets turned down before the 2001 recession and tumbled at the start of the
2008 recession.
</pre>

<p>While one of the summarized sentences remains the same, this method has chosen to return two other sentences that are probably linked to the main conclusions drawn in this article. While these sentences themselves may not seem important, the use of a graph-based method resulted in selecting highly linked sentences that support the main theme of the article. We wrap this blueprint as a <a contenteditable="false" data-type="indexterm" data-primary="textrank_summary function" id="idm45634184037608"/>function <code>textrank_summary</code>, allowing us to reuse it.</p>

<p>We also want to see how this method works on the shorter article on 5G technology that we looked at previously:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">parser</code> <code class="o">=</code> <code class="n">PlaintextParser</code><code class="o">.</code><code class="n">from_string</code><code class="p">(</code><code class="n">article1</code><code class="p">[</code><code class="s1">'text'</code><code class="p">],</code> <code class="n">Tokenizer</code><code class="p">(</code><code class="n">LANGUAGE</code><code class="p">))</code>
<code class="n">summarizer</code> <code class="o">=</code> <code class="n">TextRankSummarizer</code><code class="p">(</code><code class="n">stemmer</code><code class="p">)</code>
<code class="n">summarizer</code><code class="o">.</code><code class="n">stop_words</code> <code class="o">=</code> <code class="n">get_stop_words</code><code class="p">(</code><code class="n">LANGUAGE</code><code class="p">)</code>

<code class="k">for</code> <code class="n">sentence</code> <code class="ow">in</code> <code class="n">summarizer</code><code class="p">(</code><code class="n">parser</code><code class="o">.</code><code class="n">document</code><code class="p">,</code> <code class="n">num_summary_sentence</code><code class="p">):</code>
    <code class="k">print</code> <code class="p">(</code><code class="nb">str</code><code class="p">(</code><code class="n">sentence</code><code class="p">))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Acquiring Qualcomm would represent the jewel in the crown of Broadcom’s
portfolio of communications chips, which supply wi-fi, power management, video
and other features in smartphones alongside Qualcomm’s core baseband chips -
radio modems that wirelessly connect phones to networks.
Qualcomm (QCOM.O) is the dominant player in smartphone communications chips,
making half of all core baseband radio chips in smartphones.
Slideshow (2 Images)The standards are set by a global body to ensure all phones
work across different mobile networks, and whoever’s essential patents end up
making it into the standard stands to reap huge royalty licensing revenue
streams.
</pre>

<p>We see that the results capture the central idea of the Qualcomm acquisition but do not contain any mention of 5G as a technology that was selected by the LSA method. TextRank generally works better in the case of longer text content as it is able to identify the most important sentences using the graph linkages. In the case of shorter text content, the graphs are not very large, and therefore the wisdom of the network <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term4" id="idm45634183952648"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term6" id="idm45634183951304"/>plays a smaller role. Let’s use an example of even <a contenteditable="false" data-type="indexterm" data-primary="datasets, examples of" data-secondary="Wikipedia articles" id="idm45634183949800"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="datasets for" id="idm45634183948424"/><a contenteditable="false" data-type="indexterm" data-primary="Wikipedia articles" id="idm45634183947048"/>longer content from Wikipedia to highlight this point further. We will reuse the blueprint from <a data-type="xref" href="ch02.xhtml#ch-api">Chapter 2</a> to download the text content of a Wikipedia article. In this case, we choose an article that describes a historical event or series of events: the Mongol invasion of Europe. And since this is much longer text, we choose to summarize about 10 sentences to provide a better summary:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">p_wiki</code> <code class="o">=</code> <code class="n">wiki_wiki</code><code class="o">.</code><code class="n">page</code><code class="p">(</code><code class="s1">'Mongol_invasion_of_Europe'</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="n">r</code><code class="o">.</code><code class="n">repr</code><code class="p">(</code><code class="n">p_wiki</code><code class="o">.</code><code class="n">text</code><code class="p">))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
'The Mongol invasion of Europe in the 13th century occurred from the 1220s into
the 1240s. In Eastern Europe, the Mongols destroyed Volga Bulgaria, Cumania,
Alania, and the Kievan Rus\' federation. In Central Europe, the Mongol armies
launched a tw...tnotes\nReferences\nSverdrup, Carl (2010). "Numbers in Mongol
Warfare". Journal of Medieval Military History. Boydell Press. 8: 109–17 [p.
115]. ISBN 978-1-84383-596-7.\n\nFurther reading\nExternal links\nThe Islamic
World to 1600: The Golden Horde'
</pre>

Then:

<pre data-code-language="python" data-type="programlisting">
<code class="n">r</code><code class="o">.</code><code class="n">maxstring</code> <code class="o">=</code> <code class="mi">200</code>

<code class="n">num_summary_sentence</code> <code class="o">=</code> <code class="mi">10</code>

<code class="n">summary_sentence</code> <code class="o">=</code> <code class="n">textrank_summary</code><code class="p">(</code><code class="n">p_wiki</code><code class="o">.</code><code class="n">text</code><code class="p">,</code> <code class="n">num_summary_sentence</code><code class="p">)</code>

<code class="k">for</code> <code class="n">sentence</code> <code class="ow">in</code> <code class="n">summary_sentence</code><code class="p">:</code>
    <code class="k">print</code> <code class="p">(</code><code class="n">sentence</code><code class="p">)</code>
</pre>


<p>We illustrate the results as highlighted sentences in the original Wikipedia page (<a data-type="xref" href="#fig-wikipedia-summary">Figure 9-3</a>) to show that using the TextRank algorithm provides an almost accurate summarization of the article by picking the most important sentences from each section of the article. We can compare how this works with an LSA method, but we leave this as an exercise to the reader using the previous blueprint. Based on our experiences, when we want to <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="use cases for" id="idm45634183841432"/><a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634183840152"/>summarize a large piece of text content, for example, scientific research papers, collection of writings, and speeches by world leaders or multiple web pages, then we would choose a graph-based method <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term11" id="idm45634183838152"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term12" id="idm45634183836776"/>like TextRank.</p>

<figure><div id="fig-wikipedia-summary" class="figure"><img src="Images/btap_0903.jpg" width="3039" height="1125"/>
	<h6><span class="label">Figure 9-3. </span>Wikipedia page with selected summary sentences highlighted.</h6>
	</div></figure>

</div></section>

<section data-type="sect1" data-pdf-bookmark="Measuring the Performance of Text Summarization Methods"><div class="sect1" id="idm45634184134680">
<h1>Measuring the Performance of Text Summarization Methods</h1>

<p>In the blueprints so far, we have seen many methods that produce summaries of some given text. Each summary differs from the other in subtle ways, and we have to rely on our subjective evaluation. This is certainly a challenge in selecting a method that works best for a given use case. In this section, we will <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="measuring" id="ch9_term14"/>introduce commonly used accuracy metrics and show how they can be used to empirically select the best method for summarization.</p>

<p>We must understand that to automatically evaluate the summary of some given text, there must be a reference summary that it can be compared with. Typically, this is a summary written by a human and is referred to as the <em>gold standard</em>. Every automatically generated summary can be compared with the gold standard to get an accuracy measure. This also gives us the opportunity to easily compare multiple methods and choose the best one. However, we will often run into the issue that a human-generated summary may not exist for every use case. In such situations, we can choose a proxy measure to be considered as the gold standard. An example in the case of a news article would be the headline. While it is written by a human, it is a poor proxy as it can be quite short and is not an accurate summary but more of a leading statement to draw users. While this may not give us the best results, it is still useful to compare the performance of different summarization methods.</p>

<p><em>Recall-Oriented</em> <a contenteditable="false" data-type="indexterm" data-primary="ROUGE (Recall-Oriented Understudy for Gisting Evaluation) score" id="ch9_term15"/><em>Understudy for Gisting Evaluation</em> (ROUGE) is one of the most commonly used methods to measure the accuracy of a summary. There are several types of ROUGE metrics, but the basic idea is simple. It arrives at the measure of accuracy by comparing the number of shared terms between the automatically generated summary and the gold standard. ROUGE-N is a metric that measures the number of common n-grams (ROUGE-1 compares individual words, ROUGE-2 compares bigrams, and so on).</p>

<p>The original <a href="https://oreil.ly/Tsncq">ROUGE paper</a> <a contenteditable="false" data-type="indexterm" data-primary="recall" id="ch9_term16"/>compared how many of the words that appear in the gold standard also appear in the automatically generated summary. This is what we introduced in <a data-type="xref" href="ch06.xhtml#ch-classification">Chapter 6</a> as <em>recall</em>. So if most of the words present in the gold standard were also present in the generated summary, we would achieve a high score. However, this metric alone does not tell the whole story. Consider that we generate a verbose summary that is long but includes most of the words in the gold standard. This summary would have a high score, but it would not be a good summary since it doesn’t provide a concise representation. This is why the ROUGE measure has been extended to compare the number of shared words to the total number of words in the generated summary as well. This indicates the precision: the number of words in the generated summary that are actually useful. We can combine these measures to generate the F-score.</p>

<p>Let’s see an example of ROUGE for one of our generated summaries. Since we do not have a gold standard human-generated summary, we use the headline of the article as a proxy for the gold standard. While it is simple to calculate this independently, we make use of the <a contenteditable="false" data-type="indexterm" data-primary="rouge_scorer package (Python)" id="idm45634183795576"/>Python package called <code>rouge_scorer</code> to make our life easier. This package implements all the ROUGE measures that we will use later, and it can be installed by executing the command <code><strong>pip install rouge_scorer</strong></code>. We make use of a print utility function <code>print_rouge_score</code> to present a concise view of the scores:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">num_summary_sentence</code> <code class="o">=</code> <code class="mi">3</code>
<code class="n">gold_standard</code> <code class="o">=</code> <code class="n">article2</code><code class="p">[</code><code class="s1">'headline'</code><code class="p">]</code>
<code class="n">summary</code> <code class="o">=</code> <code class="s2">""</code>

<code class="n">summary</code> <code class="o">=</code> <code class="s1">''</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">textrank_summary</code><code class="p">(</code><code class="n">article2</code><code class="p">[</code><code class="s1">'text'</code><code class="p">],</code> <code class="n">num_summary_sentence</code><code class="p">))</code>
<code class="n">scorer</code> <code class="o">=</code> <code class="n">rouge_scorer</code><code class="o">.</code><code class="n">RougeScorer</code><code class="p">([</code><code class="s1">'rouge1'</code><code class="p">],</code> <code class="n">use_stemmer</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">scores</code> <code class="o">=</code> <code class="n">scorer</code><code class="o">.</code><code class="n">score</code><code class="p">(</code><code class="n">gold_standard</code><code class="p">,</code> <code class="n">summary</code><code class="p">)</code>
<code class="n">print_rouge_score</code><code class="p">(</code><code class="n">scores</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
rouge1 Precision: 0.06 Recall: 0.83 fmeasure: 0.11
</pre>

<p>The previous result shows us that the <a contenteditable="false" data-type="indexterm" data-primary="TextRank method" id="idm45634183737848"/><a contenteditable="false" data-type="indexterm" data-primary="precision and recall" id="idm45634183736776"/>summary generated by TextRank has a high recall but low precision. This is an artifact of our gold standard being an extremely short headline, which is itself not the best choice but used here for illustration. The most important use of our metric is a comparison with another summarization method, and in this case, let’s compare this with the LSA-generated summary:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">summary</code> <code class="o">=</code> <code class="s1">''</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">lsa_summary</code><code class="p">(</code><code class="n">article2</code><code class="p">[</code><code class="s1">'text'</code><code class="p">],</code> <code class="n">num_summary_sentence</code><code class="p">))</code>
<code class="n">scores</code> <code class="o">=</code> <code class="n">scorer</code><code class="o">.</code><code class="n">score</code><code class="p">(</code><code class="n">gold_standard</code><code class="p">,</code> <code class="n">summary</code><code class="p">)</code>
<code class="n">print_rouge_score</code><code class="p">(</code><code class="n">scores</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
rouge1 Precision: 0.04 Recall: 0.83 fmeasure: 0.08
</pre>

<p>The above result shows us that TextRank was the superior method in this case because it had a higher precision, while the recall of both methods was the same. We can easily extend ROUGE-1 to ROUGE-2, which would compare the number of common sequences of two words (bigrams). Another important metric is ROUGE-L, which measures the number of common sequences between the reference summary and the generated summary by identifying the longest common subsequences. A subsequence of a sentence is a new sentence that can be generated from the original sentence with some words deleted without changing the relative order of the remaining words. The advantage of this metric is that it does not focus on exact sequence matches but in-sequence matches that reflect sentence-level word order. Let’s analyze the ROUGE-2 and ROUGE-L metrics for the <a contenteditable="false" data-type="indexterm" data-primary="datasets, examples of" data-secondary="Wikipedia articles" id="idm45634183669576"/><a contenteditable="false" data-type="indexterm" data-primary="Wikipedia articles" id="idm45634183668232"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="datasets for" id="ch9_term17"/>Wikipedia page. Again, we do not have a gold standard, and therefore we will use the introductory paragraph as the proxy for our gold standard:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">num_summary_sentence</code> <code class="o">=</code> <code class="mi">10</code>
<code class="n">gold_standard</code> <code class="o">=</code> <code class="n">p_wiki</code><code class="o">.</code><code class="n">summary</code>

<code class="n">summary</code> <code class="o">=</code> <code class="s1">''</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">textrank_summary</code><code class="p">(</code><code class="n">p_wiki</code><code class="o">.</code><code class="n">text</code><code class="p">,</code> <code class="n">num_summary_sentence</code><code class="p">))</code>

<code class="n">scorer</code> <code class="o">=</code> <code class="n">rouge_scorer</code><code class="o">.</code><code class="n">RougeScorer</code><code class="p">([</code><code class="s1">'rouge2'</code><code class="p">,</code><code class="s1">'rougeL'</code><code class="p">],</code> <code class="n">use_stemmer</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">scores</code> <code class="o">=</code> <code class="n">scorer</code><code class="o">.</code><code class="n">score</code><code class="p">(</code><code class="n">gold_standard</code><code class="p">,</code> <code class="n">summary</code><code class="p">)</code>
<code class="n">print_rouge_score</code><code class="p">(</code><code class="n">scores</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
rouge2 Precision: 0.18 Recall: 0.46 fmeasure: 0.26
rougeL Precision: 0.16 Recall: 0.40 fmeasure: 0.23
</pre>

Then:

<pre data-code-language="python" data-type="programlisting">
<code class="n">summary</code> <code class="o">=</code> <code class="s1">''</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">lsa_summary</code><code class="p">(</code><code class="n">p_wiki</code><code class="o">.</code><code class="n">text</code><code class="p">,</code> <code class="n">num_summary_sentence</code><code class="p">))</code>

<code class="n">scorer</code> <code class="o">=</code> <code class="n">rouge_scorer</code><code class="o">.</code><code class="n">RougeScorer</code><code class="p">([</code><code class="s1">'rouge2'</code><code class="p">,</code><code class="s1">'rougeL'</code><code class="p">],</code> <code class="n">use_stemmer</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">scores</code> <code class="o">=</code> <code class="n">scorer</code><code class="o">.</code><code class="n">score</code><code class="p">(</code><code class="n">gold_standard</code><code class="p">,</code> <code class="n">summary</code><code class="p">)</code>
<code class="n">print_rouge_score</code><code class="p">(</code><code class="n">scores</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
rouge2 Precision: 0.04 Recall: 0.08 fmeasure: 0.05
rougeL Precision: 0.12 Recall: 0.25 fmeasure: 0.16
</pre>

<p>Based on the results, we see that TextRank proves to be more accurate than LSA. We can use the same method as shown earlier to see which method works best for shorter Wikipedia entries, which we will leave as an exercise for the reader. When <a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634183505544"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="use cases for" id="idm45634183503928"/>applying this to your use case, it is important that you choose the right summary for comparison. For instance, when working with news articles, instead of using the headline, you could look for a summary section contained within the article or generate one yourself for a small number of articles. This would allow you to have a fair comparison <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term14" id="idm45634183502056"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term15" id="idm45634183500680"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term16" id="idm45634183499304"/>between different methods.</p>
</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Summarizing Text Using Machine Learning"><div class="sect1" id="idm45634183832792">
<h1>Blueprint: Summarizing Text Using <span class="keep-together">Machine Learning</span></h1>

<p>Many of you might have participated in <a contenteditable="false" data-type="indexterm" data-primary="datasets, examples of" data-secondary="travel forum" id="ch9_term18"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning models" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="ch9_term19"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="machine learning for" id="ch9_term20"/><a contenteditable="false" data-type="indexterm" data-primary="travel forum threads" id="ch9_term21"/>online discussion forums for topics such as travel planning, programming, etc. Users on these platforms communicate in the form of threads. Anybody can start a thread, and other members provide their responses on this thread. Threads can become long, and the key message might be lost. In this blueprint, we will use data extracted from a travel forum used in the research paper,<sup><a data-type="noteref" id="idm45634183488696-marker" href="ch09.xhtml#idm45634183488696">2</a></sup> which contains the text for all posts in a thread along with the summary for that thread, as shown in <a data-type="xref" href="#fig-thread-illustration">Figure 9-4</a>.</p>



<p>In this blueprint, we are going to use machine learning to help us automatically identify the most important posts across the entire thread that accurately summarize it. We will first use the summary by the annotator to create target labels for our dataset. We will then generate features that can be useful to determine whether a particular post should be in the summary and finally train a model and evaluate the accuracy. The task at hand is similar to text classification but performed at a post level.</p>


<p>While the forum threads are used to illustrate this blueprint, it can easily be used for other <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="use cases for" id="idm45634183483064"/><a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634183481688"/>use-cases. For example, consider the <a href="https://oreil.ly/T_RNc">CNN and Daily Mail news summarization task</a>, <a href="https://oreil.ly/0Hlov">DUC</a>, or <a href="https://oreil.ly/Wg322">SUMMAC</a> datasets. In each of these datasets, you will find the text of each article and the highlighted summary sentences. These are analogous to the text of each thread and the summary as presented in this blueprint.</p>


<figure><div id="fig-thread-illustration" class="figure"><img src="Images/btap_0904.jpg" width="1296" height="839"/>
	<h6><span class="label">Figure 9-4. </span>Posts in a thread and the corresponding summary from a travel forum.</h6>
	</div></figure>

<section data-type="sect2" data-pdf-bookmark="Step 1: Creating Target Labels"><div class="sect2" id="idm45634183475880">
<h2>Step 1: Creating Target Labels</h2>

<p>The first <a contenteditable="false" data-type="indexterm" data-primary="data preprocessing" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="ch9_term22"/><a contenteditable="false" data-type="indexterm" data-primary="target labels for text summarization" id="ch9_term23"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="data preprocessing for" id="ch9_term24"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="machine learning for" data-tertiary="step 1: target labels" id="ch9_term25"/>step is to load the dataset, understand its structure, and create target labels using the provided summary. We have performed the initial data preparation steps to create a well-formatted <code>DataFrame</code>, shown next. Please refer to the <code>Data_Preparation</code> notebook in the GitHub repo of the book for a detailed look at the steps:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code>
</code><code class="kn">import</code><code> </code><code class="nn">numpy</code><code> </code><code class="kn">as</code><code> </code><code class="nn">np</code><code>
</code><!-- pd.set_option('display.max_colwidth', 500)
pd.set_option('display.max_rows',1000) --><code>
</code><code>
</code><code class="n">df</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">travel_threads.csv</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">sep</code><code class="o">=</code><code class="s1">'</code><code class="s1">|</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">dtype</code><code class="o">=</code><code class="p">{</code><code class="s1">'</code><code class="s1">ThreadID</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="s1">'</code><code class="s1">object</code><code class="s1">'</code><code class="p">}</code><code class="p">)</code><code>
</code><code class="n">df</code><code class="p">[</code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">ThreadID</code><code class="s1">'</code><code class="p">]</code><code class="o">==</code><code class="s1">'</code><code class="s1">60763_5_3122150</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code><code class="o">.</code><code class="n">T</code><code>
</code></pre>

<table class="dataframe">
	<thead>
		<tr>
			<th> </th>
			<th>170</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>Date</th>
			<td>29 September 2009, 1:41</td>
		</tr>
		<tr>
			<th>Filename</th>
			<td>thread41_system20</td>
		</tr>
		<tr>
			<th>ThreadID</th>
			<td>60763_5_3122150</td>
		</tr>
		<tr>
			<th>Title</th>
			<td>which attractions need to be pre booked?</td>
		</tr>
		<tr>
			<th>postNum</th>
			<td>1</td>
		</tr>
		<tr>
			<th>text</th>
			<td>Hi I am coming to NY in Oct! So excited&amp;quot; Have wanted to visit for years. We are planning on doing all the usual stuff so wont list it all but wondered which attractions should be pre booked and which can you just turn up at&gt; I am plannin on booking ESB but what else? thanks x</td>
		</tr>
		<tr>
			<th>userID</th>
			<td>musicqueenLon...</td>
		</tr>
		<tr>
			<th>summary</th>
			<td>A woman was planning to travel NYC in October and needed some suggestions about attractions in the NYC. She was planning on booking ESB.Someone suggested that the TOTR was much better compared to ESB. The other suggestion was to prebook the show to avoid wasting time in line.Someone also suggested her New York Party Shuttle tours.</td>
		</tr>
	</tbody>
</table>

<p>Each row in this dataset refers to a post in a thread. Each thread is identified by a unique <code>ThreadID</code>, and it’s possible that multiple rows in the <code>DataFrame</code> have the same <code>ThreadID</code>. The column <code>Title</code> refers to the name with which the user started the thread. The content of each post is in the <code>text</code> column, along with additional details like the name of the user who created the post (<code>userID</code>), the time when the post was created (<code>Date</code>), and its position in the thread (<code>postNum</code>). For this dataset, human-generated summaries for each thread are provided in the <code>summary</code> column.</p>

<p>We will reuse the <a contenteditable="false" data-type="indexterm" data-primary="cleaning text data" id="idm45634183298408"/><a contenteditable="false" data-type="indexterm" data-primary="data cleaning" id="idm45634183297432"/><a contenteditable="false" data-type="indexterm" data-primary="lemmatization" id="idm45634183296456"/><a contenteditable="false" data-type="indexterm" data-primary="regular expressions" id="idm45634183295480"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="NLP pipeline for" id="idm45634183294504"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for lemmas with part-of-speech, extracting" data-secondary-sortas="lemmas with part-of-speech, extracting" id="idm45634183293288"/><a contenteditable="false" data-type="indexterm" data-primary="text data preparation" data-secondary="cleaning processes for" id="idm45634183291832"/>regular expression cleaning and spaCy pipeline blueprints from <a data-type="xref" href="ch04.xhtml#ch-preparation">Chapter 4</a> to remove special formatting, URLs, and other punctuation from the posts. We will also generate the lemmatized representation of the text, which we will use for prediction. You can find the function definitions in the accompanying notebook for this chapter. Since we are making use of the spaCy lemmatization function, it might take a couple of minutes to complete execution:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="c1"># Applying regex based cleaning function</code>
<code class="n">df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code> <code class="o">=</code> <code class="n">df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">regex_clean</code><code class="p">)</code>
<code class="c1"># Extracting lemmas using spacy pipeline</code>
<code class="n">df</code><code class="p">[</code><code class="s1">'lemmas'</code><code class="p">]</code> <code class="o">=</code> <code class="n">df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">clean</code><code class="p">)</code>
</pre>

<p>Each observation in our dataset contains a post that is part of a thread. If we were to apply a <a contenteditable="false" data-type="indexterm" data-primary="train-test split" id="idm45634183260936"/>train-test split at this level, it is possible that two posts belonging to the same thread would end up in the train and test datasets, which would lead to inaccurate training. As a result, <a contenteditable="false" data-type="indexterm" data-primary="GroupShuffleSplit function" id="idm45634183259624"/>we use <code>GroupShuffleSplit</code> to group all posts into their respective threads and then randomly select 80% of the threads to create the training dataset, with the rest of the threads forming part of the test dataset. This function ensures that posts belonging to the same thread are part of the same dataset. The <code>GroupShuffleSplit</code> function does not actually split the data but provides a set of indices that split the data identified by <code>train_split</code> and <code>test_split</code>. We use these indices to create the two datasets:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">GroupShuffleSplit</code>

<code class="n">gss</code> <code class="o">=</code> <code class="n">GroupShuffleSplit</code><code class="p">(</code><code class="n">n_splits</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">test_size</code><code class="o">=</code><code class="mf">0.2</code><code class="p">)</code>
<code class="n">train_split</code><code class="p">,</code> <code class="n">test_split</code> <code class="o">=</code> <code class="nb">next</code><code class="p">(</code><code class="n">gss</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="n">df</code><code class="p">,</code> <code class="n">groups</code><code class="o">=</code><code class="n">df</code><code class="p">[</code><code class="s1">'ThreadID'</code><code class="p">]))</code>
</pre>

<pre data-code-language="python" data-type="programlisting">
<code class="n">train_df</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">train_split</code><code class="p">]</code>
<code class="n">test_df</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">test_split</code><code class="p">]</code>

<code class="k">print</code> <code class="p">(</code><code class="s1">'Number of threads for Training '</code><code class="p">,</code> <code class="n">train_df</code><code class="p">[</code><code class="s1">'ThreadID'</code><code class="p">]</code><code class="o">.</code><code class="n">nunique</code><code class="p">())</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Number of threads for Testing '</code><code class="p">,</code> <code class="n">test_df</code><code class="p">[</code><code class="s1">'ThreadID'</code><code class="p">]</code><code class="o">.</code><code class="n">nunique</code><code class="p">())</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Number of threads for Training  559
Number of threads for Testing  140
</pre>

<p>Our next step is to determine the target label for each of our posts. The target label defines whether a particular post should be included in the summary. We determine this by comparing each post to the annotator summary and picking posts that are most similar to be included in the summary. There are several metrics that can be used to determine the similarity of two sentences, but in our use case we are <a contenteditable="false" data-type="indexterm" data-primary="Jaro-Winkler distance" id="idm45634183125144"/>working with short texts and therefore choose the <a href="https://oreil.ly/b5q0B">Jaro-Winkler distance</a>. We <a contenteditable="false" data-type="indexterm" data-primary="textdistance package" id="idm45634183123192"/>use the <code>textdistance</code> package that also <a contenteditable="false" data-type="indexterm" data-primary="distance metrics" id="idm45634183121480"/>provides implementations of other distance metrics. This can be easily installed using the command <code><strong>pip install textdistance</strong></code>. You can also easily modify the blueprint and choose a metric based on your use case.</p>

<p>In the following step, we determine the similarity and rank all the posts within a thread based on the chosen metric. We then create our target label named <code>summaryPost</code> that contains a True or False value indicating whether this post is part of the summary. This is based on the rank of the post and the compression factor. We choose a compression factor of 30%, which means that we pick the top 30% of all posts ordered by their similarity to be included in the summary:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code> <code class="nn">textdistance</code>

<code class="n">compression_factor</code> <code class="o">=</code> <code class="mf">0.3</code>

<code class="n">train_df</code><code class="p">[</code><code class="s1">'similarity'</code><code class="p">]</code> <code class="o">=</code> <code class="n">train_df</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code>
    <code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">textdistance</code><code class="o">.</code><code class="n">jaro_winkler</code><code class="p">(</code><code class="n">x</code><code class="o">.</code><code class="n">text</code><code class="p">,</code> <code class="n">x</code><code class="o">.</code><code class="n">summary</code><code class="p">),</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="n">train_df</code><code class="p">[</code><code class="s2">"rank"</code><code class="p">]</code> <code class="o">=</code> <code class="n">train_df</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s2">"ThreadID"</code><code class="p">)[</code><code class="s2">"similarity"</code><code class="p">]</code><code class="o">.</code><code class="n">rank</code><code class="p">(</code>
    <code class="s2">"max"</code><code class="p">,</code> <code class="n">ascending</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>

<code class="n">topN</code> <code class="o">=</code> <code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">x</code> <code class="o">&lt;=</code> <code class="n">np</code><code class="o">.</code><code class="n">ceil</code><code class="p">(</code><code class="n">compression_factor</code> <code class="o">*</code> <code class="n">x</code><code class="o">.</code><code class="n">max</code><code class="p">())</code>
<code class="n">train_df</code><code class="p">[</code><code class="s1">'summaryPost'</code><code class="p">]</code> <code class="o">=</code> <code class="n">train_df</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s1">'ThreadID'</code><code class="p">)[</code><code class="s1">'rank'</code><code class="p">]</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">topN</code><code class="p">)</code>
</pre>

<pre data-code-language="python" data-type="programlisting">
<code class="n">train_df</code><code class="p">[[</code><code class="s1">'text'</code><code class="p">,</code><code class="s1">'summaryPost'</code><code class="p">]][</code><code class="n">train_df</code><code class="p">[</code><code class="s1">'ThreadID'</code><code class="p">]</code><code class="o">==</code><code class="s1">'60763_5_3122150'</code><code class="p">]</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="mi">3</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<table class="dataframe">
	<thead>
		<tr>
			<th> </th>
			<th>text</th>
			<th>summaryPost</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>170</th>
			<td>Hi I am coming to NY in Oct! So excited” Have wanted to visit for years. We are planning on doing all the usual stuff so wont list it all but wondered which attractions should be pre booked and which can you just turn up at&gt; I am plannin on booking ESB but what else? thanks x</td>
			<td>True</td>
		</tr>
		<tr>
			<th>171</th>
			<td>I wouldnt bother doing the ESB if I was you TOTR is much better. What other attractions do you have in mind?</td>
			<td>False</td>
		</tr>
		<tr>
			<th>172</th>
			<td>The Statue of Liberty, if you plan on going to the statue itself or to Ellis Island (as opposed to taking a boat past): http://www.statuecruises.com/ Also, we prefer to book shows and plays in advance rather than trying for the same-day tickets, as that allows us to avoid wasting time in line. If that sounds appealing to you, have a look at http://www.broadwaybox.com/</td>
			<td>True</td>
		</tr>
	</tbody>
</table>

<p>As you can see in the previous results for a given thread, the first and third posts are tagged as <code>summaryPost</code>, but the second post is not considered important and would not be included in the summary. Because of the way we defined our target label, it is possible in rare situations that very short posts are also included in the summary. This might happen when a short post contains the same words as the thread title. This is not useful to the summary, and we correct this by setting all posts containing 20 words or less to not be included <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term22" id="idm45634182972232"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term23" id="idm45634182970856"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term24" id="idm45634182969480"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term25" id="idm45634182968104"/>in the summary:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">train_df</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">train_df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code><code class="o">.</code><code class="n">str</code><code class="o">.</code><code class="n">len</code><code class="p">()</code> <code class="o">&lt;=</code> <code class="mi">20</code><code class="p">,</code> <code class="s1">'summaryPost'</code><code class="p">]</code> <code class="o">=</code> <code class="bp">False</code>
</pre>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Step 2: Adding Features to Assist Model Prediction"><div class="sect2" id="idm45634182870520">
<h2>Step 2: Adding Features to Assist Model Prediction</h2>

<p>Since we are dealing with forum threads in this blueprint, there are some additional <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="machine learning for" data-tertiary="step 2: features for model prediction" id="idm45634182891560"/>features that we can generate to help our model in the prediction. The <a contenteditable="false" data-type="indexterm" data-primary="titleSimilarity function" id="idm45634182889848"/>title of the thread conveys the topic succinctly and can be helpful in identifying which post should actually be selected in the summary. We cannot directly include the title as a feature since it would be the same for each post in the thread, but instead we calculate the similarity between the post and the title as one of the features:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">train_df</code><code class="p">[</code><code class="s1">'titleSimilarity'</code><code class="p">]</code> <code class="o">=</code> <code class="n">train_df</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code>
    <code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">textdistance</code><code class="o">.</code><code class="n">jaro_winkler</code><code class="p">(</code><code class="n">x</code><code class="o">.</code><code class="n">text</code><code class="p">,</code> <code class="n">x</code><code class="o">.</code><code class="n">Title</code><code class="p">),</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
</pre>

<p>Another useful feature could be the length of the post. Short posts could be asking clarifying questions and would not capture the most useful knowledge of the thread. Longer posts could indicate that a lot of useful information is being shared. The position of where the post appears in the thread could also be a useful indicator of whether it should be in the summary. This might vary depending on the way in which the forum threads are organized. In the case of the travel forum, the posts are chronologically ordered, and the occurrence of the post is given by the column <code>postNum</code>, which we can readily use as a feature:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="c1"># Adding post length as a feature</code>
<code class="n">train_df</code><code class="p">[</code><code class="s1">'textLength'</code><code class="p">]</code> <code class="o">=</code> <code class="n">train_df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code><code class="o">.</code><code class="n">str</code><code class="o">.</code><code class="n">len</code><code class="p">()</code>
</pre>

<p>As a final step, let’s create the <a contenteditable="false" data-type="indexterm" data-primary="lemmatization" id="idm45634182775064"/><a contenteditable="false" data-type="indexterm" data-primary="TfidfVectorizer" id="idm45634182774088"/><a contenteditable="false" data-type="indexterm" data-primary="scikit-learn" data-secondary="TfidfVectorizer of" id="idm45634182773016"/>vectorized representation of the lemmas that we extracted earlier using the <em>TfidfVectorizer</em>. We then create a new <code>DataFrame</code>, <code>train_df_tf</code>, which contains the vectorized lemmas and the additional features that we created <span class="keep-together">earlier</span>:</p>

<pre data-code-language="python" data-type="programlisting" class="pagebreak-before">
<code class="n">feature_cols</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'titleSimilarity'</code><code class="p">,</code><code class="s1">'textLength'</code><code class="p">,</code><code class="s1">'postNum'</code><code class="p">]</code>
</pre>

<pre data-code-language="python" data-type="programlisting">
<code class="n">train_df</code><code class="p">[</code><code class="s1">'combined'</code><code class="p">]</code> <code class="o">=</code> <code class="p">[</code>
    <code class="s1">' '</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="nb">map</code><code class="p">(</code><code class="nb">str</code><code class="p">,</code> <code class="n">l</code><code class="p">))</code> <code class="k">for</code> <code class="n">l</code> <code class="ow">in</code> <code class="n">train_df</code><code class="p">[</code><code class="s1">'lemmas'</code><code class="p">]</code> <code class="k">if</code> <code class="n">l</code> <code class="ow">is</code> <code class="ow">not</code> <code class="s1">''</code><code class="p">]</code>
<code class="n">tfidf</code> <code class="o">=</code> <code class="n">TfidfVectorizer</code><code class="p">(</code><code class="n">min_df</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code> <code class="n">ngram_range</code><code class="o">=</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">),</code> <code class="n">stop_words</code><code class="o">=</code><code class="s2">"english"</code><code class="p">)</code>
<code class="n">tfidf_result</code> <code class="o">=</code> <code class="n">tfidf</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">train_df</code><code class="p">[</code><code class="s1">'combined'</code><code class="p">])</code><code class="o">.</code><code class="n">toarray</code><code class="p">()</code>

<code class="n">tfidf_df</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">tfidf_result</code><code class="p">,</code> <code class="n">columns</code><code class="o">=</code><code class="n">tfidf</code><code class="o">.</code><code class="n">get_feature_names</code><code class="p">())</code>
<code class="n">tfidf_df</code><code class="o">.</code><code class="n">columns</code> <code class="o">=</code> <code class="p">[</code><code class="s2">"word_"</code> <code class="o">+</code> <code class="nb">str</code><code class="p">(</code><code class="n">x</code><code class="p">)</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">tfidf_df</code><code class="o">.</code><code class="n">columns</code><code class="p">]</code>
<code class="n">tfidf_df</code><code class="o">.</code><code class="n">index</code> <code class="o">=</code> <code class="n">train_df</code><code class="o">.</code><code class="n">index</code>
<code class="n">train_df_tf</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">train_df</code><code class="p">[</code><code class="n">feature_cols</code><code class="p">],</code> <code class="n">tfidf_df</code><code class="p">],</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
</pre>

<p>This step of adding features can be <a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634182737624"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="use cases for" id="idm45634182736360"/>extended or customized depending on the use case. For example, if we are looking to summarize longer text, then the paragraph that a sentence belongs to will be important. Normally, each paragraph or section tries to capture an idea, and sentence similarity metrics at that level would be relevant. If we are looking at generating summaries of scientific papers, then the number of citations and the sentences used for those citations have proven to be useful. We must also repeat the same feature engineering steps on the test dataset, which we show in the accompanying notebook but exclude here.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Step 3: Build a Machine Learning Model"><div class="sect2" id="idm45634182600520">
<h2>Step 3: Build a Machine Learning Model</h2>

<p>Now that we’ve generated features, we will <a contenteditable="false" data-type="indexterm" data-primary="text classification algorithms" data-secondary="system for" id="idm45634182598280"/>reuse the text classification blueprint from <a data-type="xref" href="ch06.xhtml#ch-classification">Chapter 6</a> but <a contenteditable="false" data-type="indexterm" data-primary="RandomForestClassifier model" id="idm45634182595784"/>use a <code>RandomForestClassifier</code> model <a contenteditable="false" data-type="indexterm" data-primary="SVM (support vector machine) algorithm" id="idm45634182594104"/>instead of the SVM model. While building a <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="machine learning for" data-tertiary="step 3: building model" id="ch9_term26"/>machine learning model for summarization, we might have additional features other than the vectorized text representation. Particularly in situations where a combination of numeric and categorical features are present, a <a contenteditable="false" data-type="indexterm" data-primary="tree-based classifiers" id="idm45634182590520"/>tree-based classifier might perform better:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sklearn.ensemble</code> <code class="kn">import</code> <code class="n">RandomForestClassifier</code>

<code class="n">model1</code> <code class="o">=</code> <code class="n">RandomForestClassifier</code><code class="p">()</code>
<code class="n">model1</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train_df_tf</code><code class="p">,</code> <code class="n">train_df</code><code class="p">[</code><code class="s1">'summaryPost'</code><code class="p">])</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=None, oob_score=False, random_state=20, verbose=0,
                       warm_start=False)
</pre>

<p>Let’s apply this model on the test threads and predict the summary posts. To determine the accuracy, we concatenate all identified summary posts and generate the <a contenteditable="false" data-type="indexterm" data-primary="rouge_scorer package (Python)" id="idm45634182567864"/>ROUGE-1 score by comparing it with the annotator summary:</p>

<pre data-code-language="python" data-type="programlisting" class="pagebreak-before">
<code class="c1"># Function to calculate rouge_score for each thread</code>
<code class="k">def</code> <code class="nf">calculate_rouge_score</code><code class="p">(</code><code class="n">x</code><code class="p">,</code> <code class="n">column_name</code><code class="p">):</code>
    <code class="c1"># Get the original summary - only first value since they are repeated</code>
    <code class="n">ref_summary</code> <code class="o">=</code> <code class="n">x</code><code class="p">[</code><code class="s1">'summary'</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>

    <code class="c1"># Join all posts that have been predicted as summary</code>
    <code class="n">predicted_summary</code> <code class="o">=</code> <code class="s1">''</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">x</code><code class="p">[</code><code class="s1">'text'</code><code class="p">][</code><code class="n">x</code><code class="p">[</code><code class="n">column_name</code><code class="p">]])</code>

    <code class="c1"># Return the rouge score for each ThreadID</code>
    <code class="n">scorer</code> <code class="o">=</code> <code class="n">rouge_scorer</code><code class="o">.</code><code class="n">RougeScorer</code><code class="p">([</code><code class="s1">'rouge1'</code><code class="p">],</code> <code class="n">use_stemmer</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
    <code class="n">scores</code> <code class="o">=</code> <code class="n">scorer</code><code class="o">.</code><code class="n">score</code><code class="p">(</code><code class="n">ref_summary</code><code class="p">,</code> <code class="n">predicted_summary</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">scores</code><code class="p">[</code><code class="s1">'rouge1'</code><code class="p">]</code><code class="o">.</code><code class="n">fmeasure</code>
</pre>

<pre data-code-language="python" data-type="programlisting">
<code class="n">test_df</code><code class="p">[</code><code class="s1">'predictedSummaryPost'</code><code class="p">]</code> <code class="o">=</code> <code class="n">model1</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">test_df_tf</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Mean ROUGE-1 Score for test threads'</code><code class="p">,</code>
      <code class="n">test_df</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s1">'ThreadID'</code><code class="p">)[[</code><code class="s1">'summary'</code><code class="p">,</code><code class="s1">'text'</code><code class="p">,</code><code class="s1">'predictedSummaryPost'</code><code class="p">]]</code> \
      <code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">calculate_rouge_score</code><code class="p">,</code> <code class="n">column_name</code><code class="o">=</code><code class="s1">'predictedSummaryPost'</code><code class="p">)</code><code class="o">.</code><code class="n">mean</code><code class="p">())</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Mean ROUGE-1 Score for test threads 0.3439714323225145
</pre>

<p>We see that the <a contenteditable="false" data-type="indexterm" data-primary="ROUGE (Recall-Oriented Understudy for Gisting Evaluation) score" id="idm45634182329992"/>mean ROUGE-1 score for all threads in the test set is 0.34, which is comparable with extractive summarization scores on other <a href="https://oreil.ly/SaCk2">public summarization tasks</a>. You will also notice on the leaderboard that the <a contenteditable="false" data-type="indexterm" data-primary="BERT (Bidirectional Encoder Representations from Transformers) model" id="idm45634182327896"/>use of pretrained models such as BERT improves the score, and we explore this technique in detail in <a data-type="xref" href="ch11.xhtml#ch-sentiment">Chapter 11</a>.</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>
<code class="n">random</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">test_df</code><code class="p">[</code><code class="s1">'ThreadID'</code><code class="p">]</code><code class="o">.</code><code class="n">unique</code><code class="p">()</code><code class="o">.</code><code class="n">tolist</code><code class="p">(),</code> <code class="mi">1</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
['60974_588_2180141']
</pre>

<p>Let’s also take a look at one of the summarized results produced by this model to understand how useful it might be:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">example_df</code> <code class="o">=</code> <code class="n">test_df</code><code class="p">[</code><code class="n">test_df</code><code class="p">[</code><code class="s1">'ThreadID'</code><code class="p">]</code> <code class="o">==</code> <code class="s1">'60974_588_2180141'</code><code class="p">]</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Total number of posts'</code><code class="p">,</code> <code class="n">example_df</code><code class="p">[</code><code class="s1">'postNum'</code><code class="p">]</code><code class="o">.</code><code class="n">max</code><code class="p">())</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Number of summary posts'</code><code class="p">,</code>
      <code class="n">example_df</code><code class="p">[</code><code class="n">example_df</code><code class="p">[</code><code class="s1">'predictedSummaryPost'</code><code class="p">]]</code><code class="o">.</code><code class="n">count</code><code class="p">()</code><code class="o">.</code><code class="n">values</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Title: '</code><code class="p">,</code> <code class="n">example_df</code><code class="p">[</code><code class="s1">'Title'</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>
<code class="n">example_df</code><code class="p">[[</code><code class="s1">'postNum'</code><code class="p">,</code> <code class="s1">'text'</code><code class="p">]][</code><code class="n">example_df</code><code class="p">[</code><code class="s1">'predictedSummaryPost'</code><code class="p">]]</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Total number of posts 9
Number of summary posts 2
Title:  What's fun for kids?
</pre>

<table class="dataframe">
	<thead>
		<tr>
			<th> </th>
			<th>postNum</th>
			<th>text</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>551</th>
			<td>4</td>
			<td>Well, you’re really in luck, because there’s a lot going on, including the Elmwood Avenue Festival of the Arts (http://www.elmwoodartfest.org), with special activities for youngsters, performances (including one by Nikki Hicks, one of my favorite local vocalists), and food of all kinds. Elmwood Avenue is one of the area’s most colorful and thriving neighborhoods, and very walkable. The Buffalo Irish Festival is also going on that weekend in Hamburg, as it happens, at the fairgrounds: www.buf...</td>
		</tr>
		<tr>
			<th>552</th>
			<td>5</td>
			<td>Depending on your time frame, a quick trip to Niagara Falls would be great. It is a 45 minute drive from Hamburg and well worth the investment of time. Otherwise you have some beaches in Angola to enjoy. If the girls like to shop you have the Galleria, which is a great expansive Mall. If you enjoy a more eclectic afternoon, lunch on Elmwood Avenue, a stroll through the Albright Know Art gallery, and hitting some of the hip shops would be a cool afternoon. Darien Lake Theme Park is 40 minutes...</td>
		</tr>
	</tbody>
</table>

<p>In the previous example, the original thread consisted of nine posts, two of which have been picked to summarize the thread, as shown earlier. Reading through the summary posts shows that the thread is about activities for youngsters, and there are already some specific suggestions, such as Elmwood Avenue, Darien Lake Theme Park, etc. Imagine that while scrolling through the forum search results, this information is provided on a mouse hover. It gives the user an accurate enough summary to decide whether it’s interesting and click through for more details or continue looking at other search results. You could also easily reuse this blueprint with other datasets as mentioned at the start and customize the distance function, introduce additional features, and then <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term17" id="idm45634182203064"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term18" id="idm45634182201688"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term19" id="idm45634182200312"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term20" id="idm45634182198936"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term21" id="idm45634182197560"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch9_term26" id="idm45634182196184"/>train the model.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Closing Remarks"><div class="sect1" id="idm45634182599576">
<h1>Closing Remarks</h1>

<p>In this chapter, we <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="about" id="idm45634182193432"/>introduced the concept of text summarization and provided blueprints that can be used to generate summaries for different <a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for text summarization" data-secondary-sortas="text summarization" id="idm45634182191752"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="use cases for" id="idm45634182190104"/>use cases. If you are looking to generate summaries from short text such as web pages, blogs, and news articles, then the first blueprint based on topic representation using the <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="LSA algorithm for" id="idm45634182188408"/>LSA summarizer would be a good choice. If you are working with much larger text such as speeches, book chapters, or scientific articles, then the <a contenteditable="false" data-type="indexterm" data-primary="TextRank method" id="idm45634182186744"/><a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="indicator representation (TextRank) for" id="idm45634182185640"/>blueprint using TextRank would be a better choice. These blueprints are great as the first step in your journey toward automatic text summarization as they are simple and fast. However, the third blueprint using machine learning provides a more custom solution for your specific use case. Provided you have the necessary annotated data, this method can be tailored by adding features and optimizing the machine learning model to improve performance. For example, your company or product might have multiple policy documents that govern user data, terms and conditions, and other such processes that you want to summarize for a new user or employee. You could start with the third blueprint and customize the second step by adding features such as the number of clauses, usage of block letters, presence of bold or underlined text, etc., that will help the model summarize the important points in the <a contenteditable="false" data-type="indexterm" data-primary="text summarization" data-secondary="further reading on" id="idm45634182183256"/>policy documents.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Further Reading"><div class="sect1" id="idm45634182181624">
<h1>Further Reading</h1>

<ul class="author-date-bib">
	<li>Allahyari, Mehdi, et al. “Text Summarization Techniques: A Brief Survey.”
    <a href="https://arxiv.org/pdf/1707.02268.pdf"><em>https://arxiv.org/pdf/1707.02268.pdf</em></a>.</li>
	<li>Bhatia, Sumit, et al. “Summarizing Online Forum Discussions—Can Dialog Acts of Individual Messages Help?”
    <a href="http://sumitbhatia.net/papers/emnlp14.pdf"><em>http://sumitbhatia.net/papers/emnlp14.pdf</em></a>.</li>
	<li>Collins, Ed, et al. “A Supervised Approach to Extractive Summarisation of Scientific Papers.”
    <a href="https://arxiv.org/pdf/1706.03946.pdf"><em>https://arxiv.org/pdf/1706.03946.pdf</em></a>.</li>
	<li>Tarnpradab, Sansiri, et al. “Toward Extractive Summarization of Online ForumDiscussions via Hierarchical Attention Networks.”
    <a href="https://aaai.org/ocs/index.php/FLAIRS/FLAIRS17/paper/viewFile/15500/14945"><em>https://aaai.org/ocs/index.php/FLAIRS/FLAIRS17/paper/viewFile/15500/14945</em></a>.</li>
</ul>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="idm45634184456856"><sup><a href="ch09.xhtml#idm45634184456856-marker">1</a></sup> You can find more information about the package, including the usage guidelines that we used while designing this blueprint on <a href="https://oreil.ly/I0FMA">GitHub</a>.</p><p data-type="footnote" id="idm45634183488696"><sup><a href="ch09.xhtml#idm45634183488696-marker">2</a></sup> Sansiri Tarnpradab, et al. “Toward Extractive Summarization of Online ForumDiscussions via Hierarchical Attention Networks.” <a href="https://arxiv.org/abs/1805.10390"><em>https://arxiv.org/abs/1805.10390</em></a>. See the <a href="https://oreil.ly/cqU_O">data set (<em>.zip</em>)</a> as well.</p></div></div></section></div>



  </body></html>