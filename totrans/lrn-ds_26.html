<html><head></head><body><section data-pdf-bookmark="Chapter 20. Numerical Optimization" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch-gd">&#13;
<h1><span class="label">Chapter 20. </span>Numerical Optimization</h1>&#13;
&#13;
<p>At this point in the book, our modeling<a contenteditable="false" data-primary="optimization" data-secondary="numerical" data-type="indexterm" id="ix_optimiz_num"/><a contenteditable="false" data-primary="numerical optimization" data-type="indexterm" id="ix_num_optim"/> procedure should feel familiar: we define a model, choose a loss function, and fit the model by minimizing the average loss over our training data. We’ve seen several techniques to minimize loss. For example, we used both calculus and a geometric argument in <a class="reference internal" data-type="xref" href="ch15.html#ch-linear">Chapter 15</a> to find a simple expression for fitting linear models using squared loss.</p>&#13;
&#13;
<p>But empirical loss minimization isn’t always so straightforward. Lasso regression, with the addition of the <span class="math notranslate nohighlight"><math> <msub> <mi>L</mi> <mn>1</mn> </msub> </math></span> penalty to the average squared loss, no longer has a closed-form solution, and logistic regression uses cross-entropy loss to fit a nonlinear model. In these cases, we use <em>numerical optimization</em> to fit the model, where we systematically choose parameter values to evaluate the average loss in search of the minimizing value.</p>&#13;
&#13;
<p>When we introduced loss functions in <a class="reference internal" data-type="xref" href="ch04.html#ch-modeling">Chapter 4</a>, we performed a simple numerical optimization to find the minimizer of the average loss. We created a grid of <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> values and evaluated the average loss at all points in the grid (see <a class="reference internal" data-type="xref" href="#grid-diagram">Figure 20-1</a>). The grid point with the smallest average loss we took as the best fit. Unfortunately, this sort of grid search quickly becomes impractical, for the following reasons:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>For complex models with many features, the grid becomes unwieldy. With only four features and a grid of 100 values for each feature, we must evaluate the average loss at <span class="math notranslate nohighlight"><math> <msup> <mn>100</mn> <mn>4</mn> </msup> <mo>=</mo> <mn>100,000,000</mn> </math></span> grid points.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>The range of parameter values to search over must be specified in advance to create the grid, and when we don’t have a good sense of the range, we need to start with a wide grid and possibly repeat the grid search over narrower ranges.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>With a large number of observations, the evaluation of the average loss over the grid points can be slow.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<figure><div class="figure" id="grid-diagram"><img src="assets/leds_2001.png"/>&#13;
<h6><span class="label">Figure 20-1. </span>Searching over a grid of points can be computationally slow or inexact</h6>&#13;
</div></figure>&#13;
&#13;
<p>In this chapter, we introduce numerical optimization techniques that take advantage of the shape and smoothness of the loss function in the search for the minimizing parameter values. We first introduce the basic idea behind the technique of gradient descent, then we give an example and describe the properties of the loss function that make gradient descent work, and finally, we provide a few extensions of gradient descent.</p>&#13;
&#13;
<section data-pdf-bookmark="Gradient Descent Basics" data-type="sect1"><div class="sect1" id="gradient-descent-basics">&#13;
<h1>Gradient Descent Basics</h1>&#13;
&#13;
<p>Gradient descent<a contenteditable="false" data-primary="numerical optimization" data-secondary="gradient descent" data-type="indexterm" id="ix_num_optim_grad"/><a contenteditable="false" data-primary="loss functions" data-secondary="and gradient descent" data-secondary-sortas="gradient descent" data-type="indexterm" id="ix_loss_func_grad"/><a contenteditable="false" data-primary="gradient descent" data-type="indexterm" id="ix_grad_desc_ch20"/> is based on the notion that for many loss functions, the function is roughly linear in small neighborhoods of the parameter. <a class="reference internal" data-type="xref" href="#gd-diagram">Figure 20-2</a> gives a diagram of the basic idea.</p>&#13;
&#13;
<figure><div class="figure" id="gd-diagram"><img src="assets/leds_2002.png"/>&#13;
<h6><span class="label">Figure 20-2. </span>The technique of gradient descent moves in small increments toward the minimizing parameter value</h6>&#13;
</div></figure>&#13;
&#13;
<p>In the diagram, we have drawn the tangent line to the loss curve <span class="math notranslate nohighlight"><math> <mi>L</mi> </math></span> at some point <span class="math notranslate nohighlight"><math> <mrow> <mi>θ</mi> </mrow> </math></span> to the left of the minimizing value, <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span>. Notice that the slope of the tangent line is negative. A short step to the right of <span class="math notranslate nohighlight"><math> <mrow> <mi>θ</mi> </mrow> </math></span> to <span class="math notranslate nohighlight"><math> <mrow> <mi>θ</mi> </mrow> <mo>+</mo> <mtext>s</mtext> </math></span>, for some small amount <span class="math notranslate nohighlight"><math> <mtext>s</mtext> </math></span>, gives a point on the tangent line close to the loss at <span class="math notranslate nohighlight"><math> <mrow> <mi>θ</mi> </mrow> <mo>+</mo> <mtext>s</mtext> </math></span>, and this loss is smaller than <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">~</mo> </mover> </mrow> <mo stretchy="false">)</mo> </math></span>. That is, since the slope, <span class="math notranslate nohighlight"><math> <mi>b</mi> </math></span>, is negative, and the tangent line approximates the loss function in a neighborhood of <span class="math notranslate nohighlight"><math> <mrow> <mi>θ</mi> </mrow> </math></span>, we have:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mi>L</mi> <mo stretchy="false">(</mo> <mrow> <mi>θ</mi> </mrow> <mo>+</mo> <mtext>s</mtext> <mo stretchy="false">)</mo> <mo>≈</mo> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo stretchy="false">)</mo> <mo>+</mo> <mi>b</mi> <mo>×</mo> <mtext>s</mtext> <mo>&lt;</mo> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo stretchy="false">)</mo> </math></div>&#13;
</div>&#13;
&#13;
<p>So, taking a small step to the right of this <span class="math notranslate nohighlight"><math> <mrow> <mi>θ</mi> </mrow> </math></span> decreases the loss. On the other hand, on the other side of <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span> in the diagram in <a class="reference internal" data-type="xref" href="#gd-diagram">Figure 20-2</a>, the slope is positive, and taking a small step to the left decreases the loss.</p>&#13;
&#13;
<p>When we take repeated small steps in the direction indicated by whether the slope of the tangent line is positive or negative at each new step, this leads to smaller and smaller values of the average loss and eventually brings us to the minimizing value <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span> (or very close to it). This is the basic idea behind gradient descent.</p>&#13;
&#13;
<p>More formally, to minimize <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span> for a general vector of parameters, <span class="math notranslate nohighlight"><math> <mi mathvariant="bold-italic">θ</mi> </math></span>, the gradient (first-order partial derivative) determines the direction and size of the step to take. If we write the gradient, <span class="math notranslate nohighlight"><math> <msub> <mi mathvariant="normal">∇</mi> <mi>θ</mi> </msub> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span>, as simply <span class="math notranslate nohighlight"><math> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span>, then gradient descent says the increment or step is <span class="math notranslate nohighlight"><math> <mo>−</mo> <mi>α</mi> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span> for some small positive <span class="math notranslate nohighlight"><math> <mi>α</mi> </math></span>. Then the average loss at the new position is:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>+</mo> <mo stretchy="false">(</mo> <mo>−</mo> <mi>α</mi> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>≈</mo> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo stretchy="false">)</mo> <mo>−</mo> <mi>α</mi> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <msup> <mo stretchy="false">)</mo> <mi>T</mi> </msup> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </mtd> </mtr> <mtr> <mtd/> <mtd> <mi/> <mo>&lt;</mo> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo stretchy="false">)</mo> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>Note that <span class="math notranslate nohighlight"><math> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span> is a <span class="math notranslate nohighlight"><math> <mi>p</mi> <mo>×</mo> <mn>1</mn> </math></span> vector and <span class="math notranslate nohighlight"><math> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <msup> <mo stretchy="false">)</mo> <mi>T</mi> </msup> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span> is positive.</p>&#13;
&#13;
<p>The steps in the gradient descent algorithm go as follows:</p>&#13;
&#13;
<ol class="arabic simple">&#13;
	<li>&#13;
	<p>Choose a starting value, called <span class="math notranslate nohighlight"><math> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mn>0</mn> <mo stretchy="false">)</mo> </mrow> </msup> </math></span> (a common choice is <span class="math notranslate nohighlight"><math> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mn>0</mn> <mo stretchy="false">)</mo> </mrow> </msup> <mo>=</mo> <mn>0</mn> </math></span>).</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Compute <span class="math notranslate nohighlight"><math> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> </mrow> </msup> <mo>=</mo> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> <mo>−</mo> <mi>α</mi> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span>.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Repeat step 2 until <span class="math notranslate nohighlight"><math> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> </mrow> </msup> </math></span> doesn’t change (or changes little) between iterations.</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>The quantity <span class="math notranslate nohighlight"><math> <mi>α</mi> </math></span> is called the <em>learning rate</em>. <a contenteditable="false" data-primary="α (learning rate)" data-type="indexterm" id="id1849"/><a contenteditable="false" data-primary="learning rate (α)" data-type="indexterm" id="id1850"/>Setting <span class="math notranslate nohighlight"><math> <mi>α</mi> </math></span> can be tricky. It needs to be small enough to not overshoot the minimum but large enough to arrive at the minimum in reasonably few steps (see <a class="reference internal" data-type="xref" href="#gd-learning-rate">Figure 20-3</a>). There are many strategies for setting <span class="math notranslate nohighlight"><math> <mi>α</mi> </math></span>. For example, it can be useful to decrease <span class="math notranslate nohighlight"><math> <mi>α</mi> </math></span> over time. When <span class="math notranslate nohighlight"><math> <mi>α</mi> </math></span> changes between iterations, we use the notation <span class="math notranslate nohighlight"><math> <msup> <mi>α</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> </math></span> to indicate that the learning rate varies during the search.</p>&#13;
&#13;
<figure><div class="figure" id="gd-learning-rate"><img src="assets/leds_2003.png"/>&#13;
<h6><span class="label">Figure 20-3. </span>A small learning rate requires many steps to converge (left), and a large learning rate can diverge (right); choosing the learning rate well leads to fast convergence on the minimizing value (middle)</h6>&#13;
</div></figure>&#13;
&#13;
<p>The gradient descent algorithm is simple yet powerful since we can use it for many types of models and many types of loss functions. It is the computational tool of choice for fitting many models, including linear regression on large datasets and logistic regression. We demonstrate the algorithm to fit a constant to the bus delay data (from <a class="reference internal" data-type="xref" href="ch04.html#ch-modeling">Chapter 4</a>) next<a contenteditable="false" data-primary="" data-startref="ix_loss_func_grad" data-type="indexterm" id="id1851"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Minimizing Huber Loss" data-type="sect1"><div class="sect1" id="minimizing-huber-loss">&#13;
<h1>Minimizing Huber Loss</h1>&#13;
&#13;
<p><em>Huber loss</em> combines absolute loss<a contenteditable="false" data-primary="numerical optimization" data-secondary="Huber loss, minimizing" data-type="indexterm" id="ix_num_optim_huber"/><a contenteditable="false" data-primary="Huber loss, minimizing" data-type="indexterm" id="ix_huber_loss"/> and squared loss to get a function that is differentiable (like squared loss) and less sensitive to outliers (like absolute loss):</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mtext mathvariant="bold">y</mtext> <mo stretchy="false">)</mo> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mi>n</mi> </munderover> <mrow> <mo>{</mo> <mtable columnalign="left left" columnspacing="1em" rowspacing=".2em"> <mtr> <mtd> <mfrac> <mn>1</mn> <mn>2</mn> </mfrac> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> </mtd> <mtd> <mo stretchy="false">|</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>θ</mi> <mrow> <mo stretchy="false">|</mo> </mrow> <mo>≤</mo> <mi>γ</mi> </mtd> </mtr> <mtr> <mtd> <mi>γ</mi> <mo stretchy="false">(</mo> <mrow> <mo stretchy="false">|</mo> </mrow> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>θ</mi> <mrow> <mo stretchy="false">|</mo> </mrow> <mo>−</mo> <mfrac> <mn>1</mn> <mn>2</mn> </mfrac> <mi>γ</mi> <mo stretchy="false">)</mo> </mtd> <mtd> <mtext>otherwise</mtext> </mtd> </mtr> </mtable> <mo fence="true" stretchy="true" symmetric="true"/> </mrow> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>Since Huber loss is differentiable, we can use gradient descent. We first find the gradient of the average Huber loss:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mi>L</mi> <mo stretchy="false">(</mo> <mi>θ</mi> <mo>,</mo> <mtext mathvariant="bold">y</mtext> <mo stretchy="false">)</mo> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mi>n</mi> </munderover> <mrow> <mo>{</mo> <mtable columnalign="left left" columnspacing="1em" rowspacing=".2em"> <mtr> <mtd> <mo>−</mo> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>θ</mi> <mo stretchy="false">)</mo> </mtd> <mtd> <mo stretchy="false">|</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>θ</mi> <mrow> <mo stretchy="false">|</mo> </mrow> <mo>≤</mo> <mi>γ</mi> </mtd> </mtr> <mtr> <mtd> <mo>−</mo> <mi>γ</mi> <mo>⋅</mo> <mtext>sign</mtext> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>θ</mi> <mo stretchy="false">)</mo> </mtd> <mtd> <mtext>otherwise</mtext> </mtd> </mtr> </mtable> <mo fence="true" stretchy="true" symmetric="true"/> </mrow> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>We create the functions <code>huber_loss</code> and <code>grad_huber_loss</code> to compute the average loss and its gradient. We write these functions to have signatures that enable us to specify the parameter as well as the observed data that we average over and the transition point of the loss function:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre class="pre" data-code-language="python" data-type="programlisting">&#13;
<span><code class="k">def</code></span><code> </code><span><code class="nf">huber_loss</code></span><span><code class="p">(</code></span><span><code class="n">theta</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">dataset</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">gamma</code></span><span><code class="o">=</code></span><span><code class="mi">1</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="n">d</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">abs</code></span><span><code class="p">(</code></span><span><code class="n">theta</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">dataset</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><code>&#13;
</code><code>        </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">where</code></span><span><code class="p">(</code></span><span><code class="n">d</code></span><code> </code><span><code class="o">&lt;</code><code class="o">=</code></span><code> </code><span><code class="n">gamma</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="p">(</code></span><span><code class="n">theta</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">dataset</code></span><span><code class="p">)</code></span><span><code class="o">*</code><code class="o">*</code></span><span><code class="mi">2</code></span><code> </code><span><code class="o">/</code></span><code> </code><span><code class="mf">2.0</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="n">gamma</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">d</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">gamma</code></span><code> </code><span><code class="o">/</code></span><code> </code><span><code class="mf">2.0</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="k">def</code></span><code> </code><span><code class="nf">grad_huber_loss</code></span><span><code class="p">(</code></span><span><code class="n">theta</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">dataset</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">gamma</code></span><span><code class="o">=</code></span><span><code class="mi">1</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="n">d</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">abs</code></span><span><code class="p">(</code></span><span><code class="n">theta</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">dataset</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><code>&#13;
</code><code>        </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">where</code></span><span><code class="p">(</code></span><span><code class="n">d</code></span><code> </code><span><code class="o">&lt;</code><code class="o">=</code></span><code> </code><span><code class="n">gamma</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="o">-</code></span><span><code class="p">(</code></span><span><code class="n">dataset</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">theta</code></span><span><code class="p">)</code><code class="p">,</code></span><code>&#13;
</code><code>                 </code><span><code class="o">-</code></span><span><code class="n">gamma</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">sign</code></span><span><code class="p">(</code></span><span><code class="n">dataset</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">theta</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Next, we write a simple implementation of gradient descent. The signature of our function includes the loss function, its gradient, and the data to average over. We also supply the learning rate.</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="k">def</code></span><code> </code><span><code class="nf">minimize</code></span><span><code class="p">(</code></span><span><code class="n">loss_fn</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">grad_loss_fn</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">dataset</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">alpha</code></span><span><code class="o">=</code></span><span><code class="mf">0.2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">progress</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="sd">'''</code></span><code class="sd">&#13;
</code><span><code class="sd">    Uses gradient descent to minimize loss_fn. Returns the minimizing value of</code></span><code class="sd">&#13;
</code><span><code class="sd">    theta_hat once theta_hat changes less than 0.001 between iterations.</code></span><code class="sd">&#13;
</code><span><code class="sd">    '''</code></span><code>&#13;
</code><code>    </code><span><code class="n">theta</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="mi">0</code></span><code>&#13;
</code><code>    </code><span><code class="k">while</code></span><code> </code><span><code class="kc">True</code></span><span><code class="p">:</code></span><code>&#13;
</code><code>        </code><span><code class="k">if</code></span><code> </code><span><code class="n">progress</code></span><span><code class="p">:</code></span><code>&#13;
</code><code>            </code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s1">'</code><code class="s1">theta: </code></span><span><code class="si">{</code></span><span><code class="n">theta</code></span><span><code class="si">:</code></span><span><code class="s1">.2f</code></span><span><code class="si">}</code></span><span><code class="s1"> | loss: </code></span><span><code class="si">{</code></span><span><code class="n">loss_fn</code></span><span><code class="p">(</code></span><span><code class="n">theta</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">dataset</code></span><span><code class="p">)</code></span><span><code class="si">:</code></span><span><code class="s1">.3f</code></span><span><code class="si">}</code></span><span><code class="s1">'</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>        </code><span><code class="n">gradient</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">grad_loss_fn</code></span><span><code class="p">(</code></span><span><code class="n">theta</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">dataset</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>        </code><span><code class="n">new_theta</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">theta</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">alpha</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="n">gradient</code></span><code>&#13;
</code><code>        </code><code>&#13;
</code><code>        </code><span><code class="k">if</code></span><code> </code><span><code class="nb">abs</code></span><span><code class="p">(</code></span><span><code class="n">new_theta</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">theta</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">&lt;</code></span><code> </code><span><code class="mf">0.001</code></span><span><code class="p">:</code></span><code>&#13;
</code><code>            </code><span><code class="k">return</code></span><code> </code><span><code class="n">new_theta</code></span><code>&#13;
</code><code>        </code><code>&#13;
</code><code>        </code><span><code class="n">theta</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">new_theta</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Recall that the bus delays dataset consists of over 1,000 measurements of how many minutes late the northbound C-line buses are in arriving at the stop at 3rd Avenue and Pike Street in Seattle:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">delays</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">pd</code></span><span><code class="o">.</code></span><span><code class="n">read_csv</code></span><span><code class="p">(</code></span><span><code class="s1">'</code><code class="s1">data/seattle_bus_times_NC.csv</code><code class="s1">'</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>In <a class="reference internal" data-type="xref" href="ch04.html#ch-modeling">Chapter 4</a>, we fit a constant model to these data for absolute loss and squared loss. We found that absolute loss yielded the median and square the mean of the data:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s2">"</code><code class="s2">Mean:   </code></span><span><code class="si">{</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><span><code class="n">delays</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">minutes_late</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">)</code></span><span><code class="si">:</code></span><span><code class="s2">.3f</code></span><span><code class="si">}</code></span><span><code class="s2">"</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s2">"</code><code class="s2">Median: </code></span><span><code class="si">{</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">median</code></span><span><code class="p">(</code></span><span><code class="n">delays</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">minutes_late</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">)</code></span><span><code class="si">:</code></span><span><code class="s2">.3f</code></span><span><code class="si">}</code></span><span><code class="s2">"</code></span><span><code class="p">)</code></span><code>    </code><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Mean:   1.920&#13;
Median: 0.742&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Now we use the gradient descent algorithm to find the minimizing constant model for Huber loss:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="o">%</code><code class="o">%</code><code class="n">time</code></span><code>&#13;
</code><span><code class="n">theta_hat</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">minimize</code></span><span><code class="p">(</code></span><span><code class="n">huber_loss</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">grad_huber_loss</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">delays</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">minutes_late</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s1">'</code><code class="s1">Minimizing theta: </code></span><span><code class="si">{</code></span><span><code class="n">theta_hat</code></span><span><code class="si">:</code></span><span><code class="s1">.3f</code></span><span><code class="si">}</code></span><span><code class="s1">'</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Minimizing theta: 0.701&#13;
&#13;
CPU times: user 93 ms, sys: 4.24 ms, total: 97.3 ms&#13;
Wall time: 140 ms&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The optimizing constant for Huber loss is close to the value that minimizes absolute loss. This comes from the shape of the Huber loss function. It is linear in the tails and so is not affected by outliers like with absolute loss and unlike with squared loss.</p>&#13;
&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>We wrote our <code>minimize</code> function<a contenteditable="false" data-primary="minimize() method" data-type="indexterm" id="id1852"/> to demonstrate the idea behind the algorithm. In practice, you will want to use well-tested, numerically sound implementations of an optimization algorithm. For example, the <code>scipy</code> package has a <code>minimize</code> method that we can use to find the minimizer of average loss, and we don’t even need to compute the gradient. This algorithm is likely to be much faster than any one that we might write. In fact, we used it in <a class="reference internal" data-type="xref" href="ch18.html#ch-donkey">Chapter 18</a> when we created our own asymmetric modification of quadratic loss for the special case where we wanted the loss to be greater for errors on one side of the minimum than the other.</p>&#13;
</div>&#13;
&#13;
<p>More generally, we typically stop the algorithm when <span class="math notranslate nohighlight"><math> <msup> <mi>θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> </math></span> doesn’t change much between iterations. In our function, we stop when <span class="math notranslate nohighlight"><math> <msup> <mi>θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> </mrow> </msup> <mo>−</mo> <msup> <mi>θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> </math></span> is less than 0.001. It is also common to stop the search after a large number of steps, such as 1,000. If the algorithm has not arrived at the minimizing value after 1,000 iterations, then the algorithm might be diverging because the learning rate is too large or the minimum might exist in the limit at <span class="math notranslate nohighlight"><math> <mo>±</mo> <mi mathvariant="normal">∞</mi> </math></span>.</p>&#13;
&#13;
<p>Gradient descent gives us a general way to minimize average loss when we cannot easily solve for the minimizing value analytically or when the minimization is computationally expensive. The algorithm relies on two important properties of the average loss function: it is both convex and differentiable in <span class="math notranslate nohighlight"><math> <mi mathvariant="bold-italic">θ</mi> </math></span>. We discuss how the algorithm relies on these properties next<a contenteditable="false" data-primary="" data-startref="ix_num_optim_huber" data-type="indexterm" id="id1853"/><a contenteditable="false" data-startref="ix_huber_loss" data-type="indexterm" id="id1854"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Convex and Differentiable Loss Functions" data-type="sect1"><div class="sect1" id="convex-and-differentiable-loss-functions">&#13;
<h1>Convex and Differentiable Loss Functions</h1>&#13;
&#13;
<p>As its name<a contenteditable="false" data-primary="numerical optimization" data-secondary="loss functions, convex and differentiable" data-type="indexterm" id="ix_num_loss_conv_diff"/><a contenteditable="false" data-primary="differentiable and convex loss functions" data-type="indexterm" id="ix_diff_convex"/><a contenteditable="false" data-primary="loss functions" data-secondary="convex and differentiable" data-type="indexterm" id="ix_loss_conv_diff"/><a contenteditable="false" data-primary="convex and differentiable loss functions" data-type="indexterm" id="ix_convex_diff"/> suggests, the gradient descent algorithm requires the function being minimized to be differentiable. The gradient, <span class="math notranslate nohighlight"><math> <msub> <mi mathvariant="normal">∇</mi> <mi>θ</mi> </msub> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span>, allows us to make a linear approximation to the average loss in small neighborhoods of <span class="math notranslate nohighlight"><math> <mi mathvariant="bold-italic">θ</mi> </math></span>. This approximation gives us the direction (and size) of the step, and as long as we don’t overshoot the minimum, <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </math></span>, we are bound to eventually reach it. Well, as long as the loss function is also convex.</p>&#13;
&#13;
<p>The step-by-step search for the minimum also relies on the loss function being convex. The function in the diagram on the left in <a class="reference internal" data-type="xref" href="#gd-convex">Figure 20-4</a> is convex, but the function on the right is not. The function on the right has a local minimum, and depending on where the algorithm starts, it might converge to this local minimum and miss the real minimum entirely. The property of convexity avoids this problem. A <em>convex function</em> avoids the problem of local minima. So, with an appropriate step size, gradient descent finds the globally optimal <span class="math notranslate nohighlight"><math> <mi>θ</mi> </math></span> for any convex, differentiable function.</p>&#13;
&#13;
<figure><div class="figure" id="gd-convex"><img src="assets/leds_2004.png"/>&#13;
<h6><span class="label">Figure 20-4. </span>With nonconvex functions (right), gradient descent might locate a local minimum rather than a global minimum, which is not possible with convex functions (left)</h6>&#13;
</div></figure>&#13;
&#13;
<p>Formally, a function <span class="math notranslate nohighlight"><math> <mi>f</mi> </math></span> is convex if for any two input values, <span class="math notranslate nohighlight"><math> <msub> <mi mathvariant="bold-italic">θ</mi> <mi>a</mi> </msub> </math></span> and <span class="math notranslate nohighlight"><math> <msub> <mi mathvariant="bold-italic">θ</mi> <mi>b</mi> </msub> </math></span>, and any <span class="math notranslate nohighlight"><math> <mi>q</mi> </math></span> between 0 and 1:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mi>q</mi> <mi>f</mi> <mo stretchy="false">(</mo> <msub> <mi mathvariant="bold-italic">θ</mi> <mi>a</mi> </msub> <mo stretchy="false">)</mo> <mo>+</mo> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>q</mi> <mo stretchy="false">)</mo> <mi>f</mi> <mo stretchy="false">(</mo> <msub> <mi mathvariant="bold-italic">θ</mi> <mi>b</mi> </msub> <mo stretchy="false">)</mo> <mo>≥</mo> <mi>f</mi> <mo stretchy="false">(</mo> <mi>q</mi> <msub> <mi mathvariant="bold-italic">θ</mi> <mi>a</mi> </msub> <mo>+</mo> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>q</mi> <mo stretchy="false">)</mo> <msub> <mi mathvariant="bold-italic">θ</mi> <mi>b</mi> </msub> <mo stretchy="false">)</mo> </math></div>&#13;
</div>&#13;
&#13;
<p>This inequality implies that any line segment that connects two points of the function must reside on or above the function itself. Heuristically, this means that whenever we take a small enough step to the right when the gradient is negative or to the left when the gradient is positive, we will head in the direction of the function’s <span class="keep-together">minimum</span>.</p>&#13;
&#13;
<p>The formal definition of convexity gives us a precise way to determine whether a function is convex. And we can use this definition to connect the convexity of the average loss <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span> to the loss function <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo mathvariant="script" stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="script" stretchy="false">)</mo> </math></span>. We have so far in this chapter simplified the representation of <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span> by not mentioning the data. Recall:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>,</mo> <mtext mathvariant="bold">X</mtext> <mo>,</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>,</mo> <msub> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mi>i</mi> </msub> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>where <span class="math notranslate nohighlight"><math> <mtext mathvariant="bold">X</mtext> </math></span> is an <span class="math notranslate nohighlight"><math> <mi>n</mi> <mo>×</mo> <mi>p</mi> </math></span> design matrix and <span class="math notranslate nohighlight"><math> <msub> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mi>i</mi> </msub> </math></span> is the <span class="math notranslate nohighlight"><math> <mi>i</mi> </math></span>th row of the design matrix, which corresponds to the <span class="math notranslate nohighlight"><math> <mi>i</mi> </math></span>th observation in the dataset. This means that the gradient can be expressed as follows:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>,</mo> <mtext mathvariant="bold">X</mtext> <mo>,</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>,</mo> <msub> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mi>i</mi> </msub> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>If <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo mathvariant="script" stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="script">,</mo> <msub> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mi mathvariant="script">i</mi> </msub> <mo mathvariant="script">,</mo> <msub> <mi mathvariant="script">y</mi> <mi mathvariant="script">i</mi> </msub> <mo mathvariant="script" stretchy="false">)</mo> </math></span> is a convex function of <span class="math notranslate nohighlight"><math> <mi mathvariant="bold-italic">θ</mi> </math></span>, then the average loss is also convex. And similarly for the derivative: the derivative of <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo mathvariant="script" stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="script">,</mo> <msub> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mi mathvariant="script">i</mi> </msub> <mo mathvariant="script">,</mo> <msub> <mi mathvariant="script">y</mi> <mi mathvariant="script">i</mi> </msub> <mo mathvariant="script" stretchy="false">)</mo> </math></span> is averaged over the data to evaluate the derivative of <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>,</mo> <mtext mathvariant="bold">X</mtext> <mo>,</mo> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mo stretchy="false">)</mo> </math></span>. We walk through a proof of the convexity property in the exercises.</p>&#13;
&#13;
<p>Now, with a large amount of data, calculating <span class="math notranslate nohighlight"><math> <msup> <mi>θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> </math></span> can be computationally expensive since it involves the average of the gradient <span class="math notranslate nohighlight"><math> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mrow> <mi mathvariant="script">l</mi> </mrow> </math></span> over all the <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <msub> <mtext mathvariant="bold">x</mtext> <mi>i</mi> </msub> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </math></span>. We next consider variants of gradient descent that can be computationally faster because they don’t average over all of the data<a contenteditable="false" data-primary="" data-startref="ix_num_loss_conv_diff" data-type="indexterm" id="id1855"/><a contenteditable="false" data-primary="" data-startref="ix_loss_conv_diff" data-type="indexterm" id="id1856"/><a contenteditable="false" data-startref="ix_convex_diff" data-type="indexterm" id="id1857"/><a contenteditable="false" data-primary="" data-startref="ix_diff_convex" data-type="indexterm" id="id1858"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Variants of Gradient Descent" data-type="sect1"><div class="sect1" id="variants-of-gradient-descent">&#13;
<h1>Variants of Gradient Descent</h1>&#13;
&#13;
<p>Two variants of gradient descent, stochastic gradient descent and mini-batch gradient descent, use subsets of the data when computing the gradient of the average loss and are useful for optimization problems with large datasets. A third alternative, Newton’s method, assumes the loss function is twice differentiable and uses a quadratic approximation to the loss function, rather than the linear approximation used in gradient descent.</p>&#13;
&#13;
<p>Recall that gradient descent takes steps based on the gradient. At step <span class="math notranslate nohighlight"><math> <mi>t</mi> </math></span>, we move from <span class="math notranslate nohighlight"><math> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> </math></span> to:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <msup> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> </mrow> </msup> <mo>=</mo> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> <mo>−</mo> <mi>α</mi> <mo>⋅</mo> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mi>L</mi> <mo stretchy="false">(</mo> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> <mo>,</mo> <mtext mathvariant="bold">X</mtext> <mo>,</mo> <mtext mathvariant="bold">y</mtext> <mo stretchy="false">)</mo> </math></div>&#13;
</div>&#13;
&#13;
<p>And since <span class="math notranslate nohighlight"><math> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>,</mo> <mtext mathvariant="bold">X</mtext> <mo>,</mo> <mtext mathvariant="bold">y</mtext> <mo stretchy="false">)</mo> </math></span> can be expressed as the average gradient of the loss function <span class="math notranslate nohighlight"><math> <mi mathvariant="script">l</mi> </math></span>, we have:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right left" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>,</mo> <mtext mathvariant="bold">X</mtext> <mo>,</mo> <mtext mathvariant="bold">y</mtext> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>,</mo> <msub> <mtext mathvariant="bold">x</mtext> <mi>i</mi> </msub> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>This representation<a contenteditable="false" data-primary="batch gradient descent" data-type="indexterm" id="id1859"/> of the gradient of the average loss in terms of the average of the gradient of loss at each point in the data shows why the algorithm is also called <em>batch gradient descent</em>. Two variants to batch gradient descent use smaller amounts of the data rather than the complete “batch.” The first, stochastic gradient descent, uses only one observation in each step of the algorithm.</p>&#13;
&#13;
<section data-pdf-bookmark="Stochastic Gradient Descent" data-type="sect2"><div class="sect2" id="stochastic-gradient-descent">&#13;
<h2>Stochastic Gradient Descent</h2>&#13;
&#13;
<p>Although batch gradient<a contenteditable="false" data-primary="stochastic gradient descent" data-type="indexterm" id="id1860"/> descent can often find an optimal <span class="math notranslate nohighlight"><math> <mi mathvariant="bold-italic">θ</mi> </math></span> in relatively few iterations, each iteration can take a long time to compute if the dataset contains many observations. To get around this difficulty, stochastic gradient descent approximates the overall gradient by a single, randomly chosen data point. Since this observation is chosen randomly, we expect that using the gradient at randomly chosen observations will, on average, move in the correct direction and so eventually converge to the minimizing parameter.</p>&#13;
&#13;
<p>In short, to conduct stochastic gradient descent, we replace the average gradient with the gradient at a single data point. So, the updated formula is just:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <msup> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> </mrow> </msup> <mo>=</mo> <msup> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> <mo>−</mo> <mi>α</mi> <mo>⋅</mo> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <msup> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> <mo>,</mo> <msub> <mtext mathvariant="bold">x</mtext> <mi>i</mi> </msub> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </math></div>&#13;
</div>&#13;
&#13;
<p>In this formula, the <span class="math notranslate nohighlight"><math> <msup> <mi>i</mi> <mrow> <mi>t</mi> <mi>h</mi> </mrow> </msup> </math></span> observations <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <msub> <mtext mathvariant="bold">x</mtext> <mi>i</mi> </msub> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </math></span> are chosen randomly from the data. Choosing the points randomly is critical to the success of stochastic gradient descent. If the points are not chosen randomly, the algorithm may produce significantly worse results than batch gradient descent.</p>&#13;
&#13;
<p>We most commonly<a contenteditable="false" data-primary="epoch" data-type="indexterm" id="id1861"/> run stochastic gradient descent by randomly shuffling all of the data points and using each point in its shuffled order until we complete one entire pass through the data. If the algorithm hasn’t converged yet, then we reshuffle the points and run another pass through the data. Each <em>iteration</em> of stochastic gradient descent looks at one data point; each complete pass through the data is called an <em>epoch</em>.</p>&#13;
&#13;
<p>Since stochastic descent only examines a single data point at a time, at times it takes steps away from the minimizer, <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span>, but on average these steps are in the right direction. And since the algorithm computes an update much more quickly than batch gradient descent, it can make significant progress toward the optimal <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> </math></span> by the time batch gradient descent finishes a single update.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Mini-Batch Gradient Descent" data-type="sect2"><div class="sect2" id="mini-batch-gradient-descent">&#13;
<h2>Mini-Batch Gradient Descent</h2>&#13;
&#13;
<p>As its name suggests<a contenteditable="false" data-primary="mini-batch gradient descent" data-type="indexterm" id="id1862"/>, <em>mini-batch gradient descent</em> strikes a balance between batch gradient descent and stochastic gradient descent by increasing the number of observations selected at random in each iteration. In mini-batch gradient descent, we average the gradient of the loss function at a few data points instead of at a single point or all the points. We let <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">B</mi> </mrow> </math></span> represent the mini-batch of data points that are randomly sampled from the dataset, and we define the algorithm’s next step as:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <msup> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> </mrow> </msup> <mo>=</mo> <msup> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> <mo>−</mo> <mi>α</mi> <mo>⋅</mo> <mfrac> <mn>1</mn> <mrow> <mo stretchy="false">|</mo> <mrow> <mi mathvariant="script">B</mi> </mrow> <mo stretchy="false">|</mo> </mrow> </mfrac> <munder> <mo>∑</mo> <mrow> <mrow> <mi>i</mi> <mo>∈</mo> <mrow> <mi mathvariant="script">B</mi> </mrow> </mrow> </mrow> </munder> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mrow> <mi mathvariant="script">l</mi> </mrow> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>,</mo> <msub> <mtext mathvariant="bold">x</mtext> <mi>i</mi> </msub> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </math></div>&#13;
</div>&#13;
&#13;
<p>As with stochastic gradient descent, we perform mini-batch gradient descent by randomly shuffling the data. Then we split the data into consecutive mini-batches and iterate through the batches in sequence. After each epoch, we reshuffle our data and select new mini-batches.</p>&#13;
&#13;
<p>While we have made the distinction between stochastic and mini-batch gradient descent, <em>stochastic gradient descent</em> is sometimes used as an umbrella term that encompasses the selection of a mini-batch of any size.</p>&#13;
&#13;
<p>Another common optimization technique is Newton’s method.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Newton’s Method" data-type="sect2"><div class="sect2" id="newtons-method">&#13;
<h2>Newton’s Method</h2>&#13;
&#13;
<p>Newton’s method<a contenteditable="false" data-primary="Newton’s method, optimization with" data-type="indexterm" id="id1863"/> uses the second derivative to optimize the loss. The basic idea is to approximate the average loss, <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span>, in small neighborhoods of <span class="math notranslate nohighlight"><math> <mi mathvariant="bold-italic">θ</mi> </math></span>, with a quadratic curve rather than a linear approximation. The approximation looks as follows for a small step <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="bold">s</mi> </mrow> </math></span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>+</mo> <mrow> <mi mathvariant="bold">s</mi> </mrow> <mo stretchy="false">)</mo> <mo>≈</mo> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> <mo>+</mo> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <msup> <mo stretchy="false">)</mo> <mi>T</mi> </msup> <mrow> <mi mathvariant="bold">s</mi> </mrow> <mo>+</mo> <mfrac> <mn>1</mn> <mn>2</mn> </mfrac> <msup> <mrow> <mi mathvariant="bold">s</mi> </mrow> <mi>T</mi> </msup> <mi>H</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> <mrow> <mi mathvariant="bold">s</mi> </mrow> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>where <span class="math notranslate nohighlight"><math> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> <mo>=</mo> <msub> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> </msub> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span> is the gradient and <span class="math notranslate nohighlight"><math> <mi>H</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> <mo>=</mo> <msubsup> <mi mathvariant="normal">∇</mi> <mrow> <mi>θ</mi> </mrow> <mn>2</mn> </msubsup> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span> is the Hessian of <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span>. More specifically, <span class="math notranslate nohighlight"><math> <mi>H</mi> </math></span> is a <span class="math notranslate nohighlight"><math> <mi>p</mi> <mo>×</mo> <mi>p</mi> </math></span> matrix of second-order partial derivatives in <span class="math notranslate nohighlight"><math> <mi mathvariant="bold-italic">θ</mi> </math></span> with <span class="math notranslate nohighlight"><math> <mi>i</mi> </math></span>, <span class="math notranslate nohighlight"><math> <mi>j</mi> </math></span> <span class="keep-together">elements</span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <msub> <mi>H</mi> <mrow> <mi>i</mi> <mo>,</mo> <mi>j</mi> </mrow> </msub> <mo>=</mo> <mfrac> <mrow> <msup> <mi>∂</mi> <mn>2</mn> </msup> <mrow> <mi mathvariant="script">l</mi> </mrow> </mrow> <mrow> <mi>∂</mi> <msub> <mi>θ</mi> <mi>i</mi> </msub> <mi>∂</mi> <msub> <mi>θ</mi> <mi>j</mi> </msub> </mrow> </mfrac> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>This quadratic approximation to <span class="math notranslate nohighlight"><math> <mi>L</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo>+</mo> <mrow> <mi mathvariant="bold">s</mi> </mrow> <mo stretchy="false">)</mo> </math></span> has a minimum at <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="bold">s</mi> </mrow> <mo>=</mo> <mo>−</mo> <mo stretchy="false">[</mo> <msup> <mi>H</mi> <mrow> <mo>−</mo> <mn>1</mn> </mrow> </msup> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> <mo stretchy="false">]</mo> <mi>g</mi> <mo stretchy="false">(</mo> <mi mathvariant="bold-italic">θ</mi> <mo stretchy="false">)</mo> </math></span>. (Convexity implies that <span class="math notranslate nohighlight"><math> <mi>H</mi> </math></span> is a symmetric square matrix that can be inverted.) Then a step in the algorithm moves from <span class="math notranslate nohighlight"><math> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> </math></span> to:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> </mrow> </msup> <mo>=</mo> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> <mo>+</mo> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo>−</mo> <mo stretchy="false">[</mo> <msup> <mi>H</mi> <mrow> <mo>−</mo> <mn>1</mn> </mrow> </msup> <mo stretchy="false">(</mo> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> <mo stretchy="false">]</mo> <mi>g</mi> <mo stretchy="false">(</mo> <msup> <mi mathvariant="bold-italic">θ</mi> <mrow> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo> </mrow> </msup> <mo stretchy="false">)</mo> </math></div>&#13;
</div>&#13;
&#13;
<p><a class="reference internal" data-type="xref" href="#newton-diagram">Figure 20-5</a> gives the idea behind Newton’s method of optimization.</p>&#13;
&#13;
<figure><div class="figure" id="newton-diagram"><img src="assets/leds_2005.png"/>&#13;
<h6><span class="label">Figure 20-5. </span>Newton’s method uses a local quadratic approximation to the curve to take steps toward the minimizing value of a convex, twice-differentiable function</h6>&#13;
</div></figure>&#13;
&#13;
<p>This technique converges quickly if the approximation is accurate and the steps are small. Otherwise, Newton’s method can diverge, which often happens if the function is nearly flat in a dimension. When the function is relatively flat, the derivative is near zero and its inverse can be quite large. Large steps can move to <span class="math notranslate nohighlight"><math> <mi mathvariant="bold-italic">θ</mi> </math></span> that are far from where the approximation is accurate. (Unlike with gradient descent, there is no learning rate that keeps steps small.)</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="sec-optimization-summary">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>In this chapter, we introduced several techniques for numerical optimization that take advantage of the shape and smoothness of the loss function in the search for the minimizing parameter values. We first introduced gradient descent, which relies on the differentiability of loss function. Gradient descent, also called batch gradient descent, iteratively improves model parameters until the model achieves minimal loss. Since batch gradient descent is computationally intractable with large datasets, we often instead use stochastic gradient descent to fit models.</p>&#13;
&#13;
<p>Mini-batch gradient descent is most optimal when running on a graphical processing unit (GPU) chip found in some computers. Since computations on these types of hardware can be executed in parallel, using a mini-batch can increase the accuracy of the gradient without increasing computation time. Depending on the memory size of the GPU, the mini-batch size is often set between 10 and 100 observations.</p>&#13;
&#13;
<p>Alternatively, if the loss function is twice differentiable, then Newton’s method can converge very quickly, even though it is more expensive to compute one step in the iteration. A hybrid approach is also popular, beginning with gradient descent (of some kind) and then switching the algorithm to Newton’s method. This approach can avoid divergence and be faster than gradient descent alone. Typically, the second-order approximation used by Newton’s method is more appropriate near the optimum and converges quickly.</p>&#13;
&#13;
<p>Lastly, another option is to set the step size adaptively. Additionally, setting different learning rates for different features can be important if they are of different scale or vary in frequency. For example, word counts can differ a lot across common words and rare words<a contenteditable="false" data-primary="" data-startref="ix_grad_desc_ch20" data-type="indexterm" id="id1864"/><a contenteditable="false" data-primary="" data-startref="ix_num_optim_grad" data-type="indexterm" id="id1865"/><a contenteditable="false" data-primary="" data-startref="ix_num_optim" data-type="indexterm" id="id1866"/><a contenteditable="false" data-primary="" data-startref="ix_optimiz_num" data-type="indexterm" id="id1867"/>.</p>&#13;
&#13;
<p>The logistic regression model introduced in <a class="reference internal" data-type="xref" href="ch19.html#ch-logistic">Chapter 19</a> is fitted using numerical optimization methods like those described in this chapter. We wrap up with one final case study that uses logistic regression to fit a complex model with thousands of features.</p>&#13;
</div></section>&#13;
</div></section></body></html>