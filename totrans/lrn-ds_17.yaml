- en: Chapter 13\. Working with Text
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data can reside not just as numbers but also in words: names of dog breeds,
    restaurant violation descriptions, street addresses, speeches, blog posts, internet
    reviews, and much more. To organize and analyze information contained in text,
    we often need to do some of the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert text into a standard format
  prefs: []
  type: TYPE_NORMAL
- en: This is also referred to as *canonicalizing text*. For example, we might need
    to convert characters to lowercase, use common spellings and abbreviations, or
    remove punctuation and blank spaces.
  prefs: []
  type: TYPE_NORMAL
- en: Extract a piece of text to create a feature
  prefs: []
  type: TYPE_NORMAL
- en: As an example, a string might contain a date embedded in it, and we want to
    pull it out from the string to create a date feature.
  prefs: []
  type: TYPE_NORMAL
- en: Transform text into features
  prefs: []
  type: TYPE_NORMAL
- en: We might want to encode particular words or phrases as 0-1 features to indicate
    their presence in a string.
  prefs: []
  type: TYPE_NORMAL
- en: Analyze text
  prefs: []
  type: TYPE_NORMAL
- en: In order to compare entire documents at once, we can transform a document into
    a vector of word counts.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter introduces common techniques for working with text data. We show
    how simple string manipulation tools are often all we need to put text in a standard
    form or extract portions of strings. We also introduce regular expressions for
    more general and robust pattern matching. To demonstrate these text operations
    we use several examples. We first introduce these examples and describe the work
    we want to do to prepare the text for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of Text and Tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For each type of task just introduced, we provide a motivating example. These
    examples are based on real tasks that we have carried out, but to focus on the
    concept, we’ve reduced the data to snippets.
  prefs: []
  type: TYPE_NORMAL
- en: Convert Text into a Standard Format
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s say we want to study connections between population demographics and
    election results. To do this, we’ve taken election data from Wikipedia and population
    data from the US Census Bureau. The granularity of the data is at the county level,
    and we need to use the county names to join the tables. Unfortunately, the county
    names in these two tables don’t always match:'
  prefs: []
  type: TYPE_NORMAL
- en: '|   | County | State | Voted |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | De Witt County | IL | 97.8 |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | Lac qui Parle County | MN | 98.8 |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | Lewis and Clark County | MT | 95.2 |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | St John the Baptist Parish | LA | 52.6 |'
  prefs: []
  type: TYPE_TB
- en: '|   | County | State | Population |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | DeWitt | IL | 16,798 |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | Lac Qui Parle | MN | 8,067 |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | Lewis & Clark | MT | 55,716 |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | St. John the Baptist | LA | 43,044 |'
  prefs: []
  type: TYPE_TB
- en: We can’t join the tables until we clean the strings to have a common format
    for county names. We need to change the case of characters, use common spellings
    and abbreviations, and address punctuation.
  prefs: []
  type: TYPE_NORMAL
- en: Extract a Piece of Text to Create a Feature
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Text data  sometimes has a lot of structure, especially when it was generated
    by a computer. As an example, the following is a web server’s log entry. Notice
    how the entry has multiple pieces of data, but the pieces don’t have a consistent
    delimiter—for instance, the date appears in square brackets, but other parts of
    the data appear in quotes and parentheses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Even though the file format doesn’t align with one of the simple formats we
    saw in [Chapter 8](ch08.html#ch-files), we can use text processing techniques
    to extract pieces of text to create features.
  prefs: []
  type: TYPE_NORMAL
- en: Transform Text into Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [Chapter 9](ch09.html#ch-wrangling), we created a categorical feature based
    on the content of the strings. There, we examined the descriptions of restaurant
    violations and we created nominal variables for the presence of particular words.
    We’ve displayed a few example violations here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: These new features can be used in an analysis of food safety scores. Previously,
    we made simple features that marked whether a description contained a word like
    *glove* or *hair*. In this chapter, we more formally introduce the regular expression
    tools that we used to create these features.
  prefs: []
  type: TYPE_NORMAL
- en: Text Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sometimes we want to compare entire documents. For example, the US president
    gives a State of the Union speech every year. Here are the first few lines of
    the very first speech:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We might wonder: How have the State of the Union speeches changed over time?
    Do different political parties focus on different topics or use different language
    in their speeches? To answer these questions, we can transform the speeches into
    a numeric form that lets us use statistics to compare them.'
  prefs: []
  type: TYPE_NORMAL
- en: These examples serve to illustrate the ideas of string manipulation, regular
    expressions, and text analysis. We start with describing simple string manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: String Manipulation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a handful of basic string manipulation tools that we use a lot when
    we work with text:'
  prefs: []
  type: TYPE_NORMAL
- en: Transform uppercase characters to lowercase (or vice versa).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace a substring with another or delete the substring.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Split a string into pieces at a particular character.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slice a string at specified locations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We show how we can combine these basic operations to clean up the county names
    data. Remember that we have two tables that we want to join, but the county names
    are written inconsistently.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by converting the county names to a standard format.
  prefs: []
  type: TYPE_NORMAL
- en: Converting Text to a Standard Format with Python String Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We need to address the following inconsistencies between the county names in
    the two tables:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Capitalization: `qui` versus `Qui`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Omission of words: `County` and `Parish` are absent from the `census` table.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Different abbreviation conventions: `&` versus `and`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Different punctuation conventions: `St.` versus `St`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use of whitespace: `DeWitt` versus `De Witt`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we clean text, it’s often easiest to first convert all of the characters
    to lowercase. It’s easier to work entirely with lowercase characters than to try
    to track combinations of uppercase and lowercase. Next, we want to fix inconsistent
    words by replacing `&` with `and` and removing `County` and `Parish`. Finally,
    we need to fix up punctuation and whitespace inconsistencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'With just two Python string methods, `lower` and `replace`, we can take all
    of these actions and clean the county names. These are combined into a method
    called `clean_county`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Although simple, these methods are the primitives that we can piece together
    to form more complex string operations. These methods are conveniently defined
    on all Python strings and do not require importing other modules. It is worth
    familiarizing yourself with [the complete list of string methods](https://oreil.ly/YWl9d),
    but we describe a few of the most commonly used methods in [Table 13-1](#string-methods).
  prefs: []
  type: TYPE_NORMAL
- en: Table 13-1\. String methods
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `str.lower()` | Returns a copy of a string with all letters converted to
    lowercase |'
  prefs: []
  type: TYPE_TB
- en: '| `str.replace(a, b)` | Replaces all instances of the substring `a` in `str`
    with substring `b` |'
  prefs: []
  type: TYPE_TB
- en: '| `str.strip()` | Removes leading and trailing whitespace from `str` |'
  prefs: []
  type: TYPE_TB
- en: '| `str.split(a)` | Returns substrings of `str` split at a substring `a` |'
  prefs: []
  type: TYPE_TB
- en: '| `str[x:y]` | Slices `str`, returning indices x (inclusive) to y (not inclusive)
    |'
  prefs: []
  type: TYPE_TB
- en: 'We next verify that the `clean_county` method produces matching county names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Since the county names now have consistent representations, we can successfully
    join the two tables.
  prefs: []
  type: TYPE_NORMAL
- en: String Methods in pandas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the preceding code, we used a loop to transform each county name. The `pandas`
    `Series` objects provide a convenient way to apply string methods to each item
    in the series.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `.str` property on `pandas` `Series` exposes the same Python string methods.
    Calling a method on the `.str` property calls the method on each item in the series.
    This allows us to transform each string in the series without using a loop. We
    save the transformed counties back into their originating tables. First we transform
    the county names in the election table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We also transform the names in the census table so that the two tables contain
    the same representations of the county names. We can join these tables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '|   | County | State | Voted | Population |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | dewitt | IL | 97.8 | 16,798 |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | lacquiparle | MN | 98.8 | 8,067 |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | lewisandclark | MT | 95.2 | 55,716 |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | stjohnthebaptist | LA | 52.6 | 43,044 |'
  prefs: []
  type: TYPE_TB
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Note that we merged on two columns: the county name and the state. We did this
    because some states have counties with the same name. For example, California
    and New York both have a county called King.'
  prefs: []
  type: TYPE_NORMAL
- en: To see the complete list of string methods, we recommend looking at the [Python
    documentation on `str` methods](https://oreil.ly/Fb34C) and the [`pandas` documentation
    for the `.str` accessor](https://oreil.ly/njVi3). We did the canonicalization
    task using only `str.lower()` and multiple calls to `str.replace()`. Next, we
    extract text with another string method, `str.split()`.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting Strings to Extract Pieces of Text
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s say we want to extract the date from the web server’s log entry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'String splitting can help us home in on the pieces of information that form
    the date. For example, when we split the string on the left bracket, we get two
    strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The second string has the date information, and to get the day, month, and
    year, we can split that string on a colon:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'To separate out the day, month, and year, we can split on the forward slash.
    Altogether we split the original string three times, each time keeping only the
    pieces we are interested in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'By repeatedly using `split()`, we can extract many of the parts of the log
    entry. But this approach is complicated—if we wanted to also get the hour, minute,
    second, and time zone of the activity, we would need to use `split()` six times
    in total. There’s a simpler way to extract these parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This alternative approach uses a powerful tool called a regular expression,
    which we cover in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Regular Expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Regular expressions* (or *regex* for short) are special patterns that we use
    to match parts of strings. Think about the format of a Social Security number
    (SSN) like `134-42-2012`. To describe this format, we might say that SSNs consist
    of three digits, then a dash, two digits, another dash, then four digits. Regexes
    let us capture this pattern in code. Regexes give us a compact and powerful way
    to describe this pattern of digits and dashes. The syntax of regular expressions
    is fortunately quite simple to learn; we introduce nearly all of the syntax in
    this section alone.'
  prefs: []
  type: TYPE_NORMAL
- en: As we introduce the concepts, we tackle some of the examples described in an
    earlier section and show how to carry out the tasks with regular expressions.
    Almost all programming languages have a library to match patterns using regular
    expressions, making regular expressions useful in any programming language. We
    use some of the common methods available in the Python built-in `re` module to
    accomplish the tasks from the examples. These methods are summarized in [Table 13-7](#regex-methods)
    at the end of this section, where the basic usage and return value are briefly
    described. Since we only cover a few of the most commonly used methods, you may
    find it useful to consult [the official documentation on the `re` module](https://oreil.ly/IXWol)
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: Regular expressions are based on searching a string one character (aka *literal*)
    at a time for a pattern. We call this notion *concatenation of literals*.
  prefs: []
  type: TYPE_NORMAL
- en: Concatenation of Literals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Concatenation is best explained with a basic example. Suppose we are looking
    for the pattern `cat` in the string `cards scatter!`. [Figure 13-1](#fig-regex-literals)
    contains a diagram that shows how the search proceeds through the string one character
    at a time. Notice that a “c” is found in the first position, followed by “a,”
    but not “t,” so the search backs up to the second character in the string and
    begins searching for a “c” again. The pattern “cat” is found within the string
    `cards scatter!` in positions 8–10\. Once you get the hang of this process, you
    can move on to the richer set of patterns; they all follow this basic paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_1301.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13-1\. To match literal patterns, the regex engine moves along the string
    and checks one literal at a time for a match of the entire pattern. Notice that
    the pattern is found within the word `scatters` and that a partial match is found
    in `cards`.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the preceding example, we observe that regular expressions can match patterns
    that appear anywhere in the input string. In Python, this behavior differs depending
    on the method used to match the regex—some methods only return a match if the
    regex appears at the start of the string; other methods return a match anywhere
    in the string.
  prefs: []
  type: TYPE_NORMAL
- en: These richer patterns are made of character classes and metacharacters like
    wildcards. We describe them in the subsections that follow.
  prefs: []
  type: TYPE_NORMAL
- en: Character classes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can make patterns more flexible by using a *character class* (also known
    as a *character set*), which lets us specify a collection of equivalent characters
    to match. This allows us to create more relaxed matches. To create a character
    class, wrap the set of desired characters in brackets `[ ]`. For example, the
    pattern `[0123456789]` means “match any literal within the brackets”—in this case,
    any single digit. Then, the following regular expression matches three digits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This is such a commonly used character class that there is a shorthand notation
    for the range of digits, `[0-9]`. Character classes allow us to create a regex
    for SSNs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Two other ranges that are commonly used in character classes are `[a-z]` for
    lowercase and `[A-Z]` for uppercase letters. We can combine ranges with other
    equivalent characters and use partial ranges. For example, `[a-cX-Z27]` is equivalent
    to the character class `[abcXYZ27]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s return to our original pattern `cat` and modify it to include two character
    classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This pattern matches `cat`, but it also matches `cot`, `cad`, and `cod`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The idea of moving through the string one character at a time still remains
    the core notion, but now there’s a bit more flexibility in which literal is considered
    a match.
  prefs: []
  type: TYPE_NORMAL
- en: Wildcard character
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we really don’t care what the literal is, we can specify this with `.`,
    the period character. This matches any character except a newline.
  prefs: []
  type: TYPE_NORMAL
- en: Negated character classes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *negated character class* matches any character *except* those between the
    square brackets. To create a negated character class, place the caret symbol as
    the first character after the left square bracket. For example, `[^0-9]` matches
    any character except a digit.
  prefs: []
  type: TYPE_NORMAL
- en: Shorthands for character classes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some character sets are so common that there are shorthands for them. For example,
    `\d` is short for `[0-9]`. We can use this shorthand to simplify our search for
    SSN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Our regular expression for SSNs isn’t quite bulletproof. If the string has
    extra digits at the beginning or end of the pattern we’re looking for, then we
    still get a match. Note that we add the `r` character before the quotes to create
    a raw string, which makes regexes easier to write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We can remedy the situation with a different sort of metacharacter: one that
    matches a word boundary.'
  prefs: []
  type: TYPE_NORMAL
- en: Anchors and boundaries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At times we want to match a position before, after, or between characters.
    One example is to locate the beginning or end of a string; these are called *anchors*.
    Another is to locate the beginning or end of a word, which we call a *boundary*.
    The metacharacter `\b` denotes the boundary of a word. It has 0 length, and it
    matches whitespace or punctuation on the boundary of the pattern. We can use it
    to fix our regular expression for SSNs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Escaping metacharacters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have now seen several special characters, called *metacharacters*: `[` and
    `]` denote a character class, `^` switches to a negated character class, `.` represents
    any character, and `-` denotes a range. But sometimes we might want to create
    a pattern that matches one of these literals. When this happens, we must escape
    it with a backslash. For example, we can match the literal left bracket character
    using the regex `\[`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Next, we show how quantifiers can help create a more compact and clear regular
    expression for SSNs.
  prefs: []
  type: TYPE_NORMAL
- en: Quantifiers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create a regex to match SSNs, we wrote:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This matches a “word” consisting of three digits, a dash, two more digits, a
    dash, and four more digits.
  prefs: []
  type: TYPE_NORMAL
- en: Quantifiers allow us to match multiple consecutive appearances of a literal.
    We specify the number of repetitions by placing the number in curly braces `{
    }`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use Python’s built-in `re` module for matching this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Our pattern shouldn’t match phone numbers. Let’s try it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: A quantifier always modifies the character or character class to its immediate
    left. [Table 13-2](#quantifier-ex) shows the complete syntax for quantifiers.
  prefs: []
  type: TYPE_NORMAL
- en: Table 13-2\. Quantifier examples
  prefs: []
  type: TYPE_NORMAL
- en: '| Quantifier | Meaning |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| {m, n} | Match the preceding character m to n times. |'
  prefs: []
  type: TYPE_TB
- en: '| {m} | Match the preceding character exactly m times. |'
  prefs: []
  type: TYPE_TB
- en: '| {m,} | Match the preceding character at least m times. |'
  prefs: []
  type: TYPE_TB
- en: '| {,n} | Match the preceding character at most n times. |'
  prefs: []
  type: TYPE_TB
- en: Some commonly used quantifiers have a shorthand, as shown in [Table 13-3](#short-quantifiers).
  prefs: []
  type: TYPE_NORMAL
- en: Table 13-3\. Shorthand quantifiers
  prefs: []
  type: TYPE_NORMAL
- en: '| Symbol | Quantifier | Meaning |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `*` | {0,} | Match the preceding character 0 or more times. |'
  prefs: []
  type: TYPE_TB
- en: '| `+` | {1,} | Match the preceding character 1 or more times. |'
  prefs: []
  type: TYPE_TB
- en: '| `?` | {0,1} | Match the preceding character 0 or 1 time. |'
  prefs: []
  type: TYPE_TB
- en: Quantifiers are greedy and will return the longest match possible. This sometimes
    results in surprising behavior. Since an SSN starts and ends with a digit, we
    might think the following shorter regex will be a simpler approach for finding
    SSNs. Can you figure out what went wrong in the matching?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we use the metacharacter `.` to match any character. In many cases,
    using a more specific character class prevents these false “overmatches.” Our
    earlier pattern that includes word boundaries does this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Some platforms allow you to turn off greedy matching and use *lazy* matching,
    which returns the shortest string.
  prefs: []
  type: TYPE_NORMAL
- en: 'Literal concatenation and quantifiers are two of the core concepts in regular
    expressions. Next, we introduce two more core concepts: alternation and grouping.'
  prefs: []
  type: TYPE_NORMAL
- en: Alternation and Grouping to Create Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Character classes let us match multiple options for a single literal. We can
    use alternation to match multiple options for a group of literals. For instance,
    in the food safety example in [Chapter 9](ch09.html#ch-wrangling), we marked violations
    related to body parts by seeing if the violation had the substring `hand`, `nail`,
    `hair`, or `glove`. We can use the `|` character in a regex to specify this alteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'With parentheses we can locate parts of a pattern, which are called *regex
    groups*. For example, we can use regex groups to extract the day, month, year,
    and time from the web server log entry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, `re.findall` returns a list of tuples containing the individual
    components of the date and time of the web log.
  prefs: []
  type: TYPE_NORMAL
- en: We have introduced a lot of terminology, so in the next section we bring it
    all together into a set of tables for easy reference.
  prefs: []
  type: TYPE_NORMAL
- en: Reference Tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We conclude this section with a few tables that summarize order of operation,
    metacharacters, and shorthands for character classes. We also provide tables summarizing
    the handful of methods in the `re` Python library that we have used in this section.
  prefs: []
  type: TYPE_NORMAL
- en: The four basic operations for regular expressions—concatenation, quantifying,
    alternation, and grouping—have an order of precedence, which we make explicit
    in [Table 13-4](#regex-order).
  prefs: []
  type: TYPE_NORMAL
- en: Table 13-4\. Order of operations
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Order | Example | Matches |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Concatenation | 3 | `cat` | `cat` |'
  prefs: []
  type: TYPE_TB
- en: '| Alternation | 4 | `cat&#124;mouse` | `cat` and `mouse` |'
  prefs: []
  type: TYPE_TB
- en: '| Quantifying | 2 | `cat?` | `ca` and `cat` |'
  prefs: []
  type: TYPE_TB
- en: '| Grouping | 1 | c(at)? | `c` and `cat` |'
  prefs: []
  type: TYPE_TB
- en: '[Table 13-5](#regex-meta) provides a list of the metacharacters introduced
    in this section, plus a few more. The column labeled “Doesn’t match” gives examples
    of strings that the example regexes don’t match.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 13-5\. Metacharacters
  prefs: []
  type: TYPE_NORMAL
- en: '| Char | Description | Example | Matches | Doesn’t match |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| . | Any character except \n | `...` | abc | ab |'
  prefs: []
  type: TYPE_TB
- en: '| [ ] | Any character inside brackets | `[cb.]ar` | car .ar | jar |'
  prefs: []
  type: TYPE_TB
- en: '| [^ ] | Any character *not* inside brackets | `[^b]ar` | car par | bar ar
    |'
  prefs: []
  type: TYPE_TB
- en: '| * | ≥ 0 or more of previous symbol, shorthand for {0,} | `[pb]*ark` | bbark
    ark | dark |'
  prefs: []
  type: TYPE_TB
- en: '| + | ≥ 1 or more of previous symbol, shorthand for {1,} | `[pb]+ark` | bbpark
    bark | dark ark |'
  prefs: []
  type: TYPE_TB
- en: '| ? | 0 or 1 of previous symbol, shorthand for {0,1} | `s?he` | she he | the
    |'
  prefs: []
  type: TYPE_TB
- en: '| {*n*} | Exactly *n* of previous symbol | `hello{3}` | hellooo | hello |'
  prefs: []
  type: TYPE_TB
- en: '| &#124; | Pattern before or after bar | `we&#124;[ui]s` | we us'
  prefs: []
  type: TYPE_NORMAL
- en: is | es e
  prefs: []
  type: TYPE_NORMAL
- en: s |
  prefs: []
  type: TYPE_NORMAL
- en: '| \ | Escape next character | `\[hi\]` | [hi] | hi |'
  prefs: []
  type: TYPE_TB
- en: '| ^ | Beginning of line | `^ark` | ark two | dark |'
  prefs: []
  type: TYPE_TB
- en: '| $ | End of line | `ark$` | noahs ark | noahs arks |'
  prefs: []
  type: TYPE_TB
- en: '| \b | Word boundary | `ark\b` | ark of noah | noahs arks |'
  prefs: []
  type: TYPE_TB
- en: Additionally, in [Table 13-6](#regex-shorthand), we provide shorthands for some
    commonly used character sets. These shorthands don’t need `[ ]`.
  prefs: []
  type: TYPE_NORMAL
- en: Table 13-6\. Character class shorthands
  prefs: []
  type: TYPE_NORMAL
- en: '| Description | Bracket form | Shorthand |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Alphanumeric character | `[a-zA-Z0-9_]` | `\w` |'
  prefs: []
  type: TYPE_TB
- en: '| Not an alphanumeric character | `[^a-zA-Z0-9_]` | `\W` |'
  prefs: []
  type: TYPE_TB
- en: '| Digit | `[0-9]` | `\d` |'
  prefs: []
  type: TYPE_TB
- en: '| Not a digit | `[^0-9]` | `\D` |'
  prefs: []
  type: TYPE_TB
- en: '| Whitespace | `[\t\n\f\r\p{Z}]` | `\s` |'
  prefs: []
  type: TYPE_TB
- en: '| Not whitespace | `[^\t\n\f\r\p{z}]` | `\S` |'
  prefs: []
  type: TYPE_TB
- en: 'We used the following methods in `re` in this chapter. The names of the methods
    are indicative of the functionality they perform: *search* or *match* a pattern
    in a string; *find all* cases of a pattern in a string; *sub*stitute all occurrences
    of a pattern with a substring; and *split* a string into pieces at the pattern.
    Each requires a pattern and string to be specified, and some have extra arguments.
    [Table 13-7](#regex-methods) provides the format of the method usage and a description
    of the return value.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 13-7\. Regular expression methods
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Return value |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `re.search(pattern, string)` | Match object if the pattern is found anywhere
    in the string, otherwise `None` |'
  prefs: []
  type: TYPE_TB
- en: '| `re.match(pattern, string)` | Match object if the pattern is found at the
    beginning of the string, otherwise `None` |'
  prefs: []
  type: TYPE_TB
- en: '| `re.findall(pattern, string)` | List of all matches of `pattern` in `string`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `re.sub(pattern, replacement, string)` | String where all occurrences of
    `pattern` are replaced by `replacement` in the `string` |'
  prefs: []
  type: TYPE_TB
- en: '| `re.split(pattern, string)` | List of the pieces of `string` around the occurrences
    of `pattern` |'
  prefs: []
  type: TYPE_TB
- en: As we saw in the previous section, `pandas` `Series` objects have a `.str` property
    that supports string manipulation using Python string methods. Conveniently, the
    `.str` property also supports some functions from the `re` module. [Table 13-8](#regex-pandas)
    shows the analogous functionality from [Table 13-7](#regex-methods) of the `re`
    methods. Each requires a pattern. See [the `pandas` docs](https://oreil.ly/aHJRz)
    for a complete list of string methods.
  prefs: []
  type: TYPE_NORMAL
- en: Table 13-8\. Regular expressions in `pandas`
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Return value |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `str.contains(pattern, regex=True)` | Series of booleans indicating whether
    the `pattern` is found |'
  prefs: []
  type: TYPE_TB
- en: '| `str.findall(pattern, regex=True)` | List of all matches of `pattern` |'
  prefs: []
  type: TYPE_TB
- en: '| `str.replace(pattern, replacement, regex=True)` | Series with all matching
    occurrences of `pattern` replaced by `replacement` |'
  prefs: []
  type: TYPE_TB
- en: '| `str.split(pattern, regex=True)` | Series of lists of strings around given
    `pattern` |'
  prefs: []
  type: TYPE_TB
- en: 'Regular expressions are a powerful tool, but they’re somewhat notorious for
    being difficult to read and debug. We close with some advice for using regexes:'
  prefs: []
  type: TYPE_NORMAL
- en: Develop your regular expression on simple test strings to see what the pattern
    matches.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a pattern matches nothing, try weakening it by dropping part of the pattern.
    Then tighten it incrementally to see how the matching evolves. (Online regex-checking
    tools can be very helpful here.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make the pattern only as specific as it needs to be for the data at hand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use raw strings whenever possible for cleaner patterns, especially when a pattern
    includes a backslash.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you have lots of long strings, consider using compiled patterns because
    they can be faster to match (see `compile()` in the `re` library).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we carry out an example text analysis. We clean the data
    using regular expressions and string manipulation, convert the text into quantitative
    data, and analyze the text via these derived quantities.
  prefs: []
  type: TYPE_NORMAL
- en: Text Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we’ve used Python methods and regular expressions to clean short text
    fields and strings. In this section, we analyze entire documents using a technique
    called *text mining*, which transforms free-form text into a quantitative representation
    to uncover meaningful patterns and insights.
  prefs: []
  type: TYPE_NORMAL
- en: Text mining is a deep topic. Instead of a comprehensive treatment, we introduce
    a few key ideas through an example, where we analyze the State of the Union speeches
    from 1790 to 2022\. Every year, the US president gives a State of the Union speech
    to Congress. These speeches talk about current events in the country and make
    recommendations for Congress to consider. [The American Presidency Project](https://oreil.ly/JbpO4)
    makes these speeches available online.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin by opening the file that has all of the speeches:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'At the beginning of this chapter, we saw that each speech in the data begins
    with a line with three asterisks: `***`. We can use a regular expression to count
    the number of times the string `***` appears:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'In text analysis, a *document* refers to a single piece of text that we want
    to analyze. Here, each speech is a document. We split apart the `text` variable
    into its individual documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can put the speeches into a dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '|   | name | date | text |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | George Washington | January 8, 1790 | Fellow-Citizens of the Senate
    and House of Rep... |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | George Washington | December 8, 1790 | Fellow-Citizens of the Senate
    and House of Rep... |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | George Washington | October 25, 1791 | Fellow-Citizens of the Senate
    and House of Rep... |'
  prefs: []
  type: TYPE_TB
- en: '| **...** | ... | ... | ... |'
  prefs: []
  type: TYPE_TB
- en: '| **229** | Donald J. Trump | February 4, 2020 | Thank you very much. Thank
    you. Thank you very... |'
  prefs: []
  type: TYPE_TB
- en: '| **230** | Joseph R. Biden, Jr. | April 28, 2021 | Thank you. Thank you. Thank
    you. Good to be ba... |'
  prefs: []
  type: TYPE_TB
- en: '| **231** | Joseph R. Biden, Jr. | March 1, 2022 | Madam Speaker, Madam Vice
    President, our First... |'
  prefs: []
  type: TYPE_TB
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have the speeches loaded into a dataframe, we want to transform
    the speeches to see how they have changed over time. Our basic idea is to look
    at the words in the speeches—if two speeches contain very different words, our
    analysis should tell us that. With some kind of measure of document similarity,
    we can see how the speeches differ from one another.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few problems in the documents that we need to take care of first:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Capitalization shouldn’t matter: `Citizens` and `citizens` should be considered
    the same word. We can address this by lowercasing the text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are unspoken remarks in the text: `[laughter]` points out where the audience
    laughed, but these shouldn’t count as part of the speech. We can address this
    by using a regex to remove text within brackets: `\[[^\]]+\]`. Remember that `\[`
    and `\]` match the literal left and right brackets, and `[^\]]` matches any character
    that isn’t a right bracket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We should take out characters that aren’t letters or whitespace: some speeches
    talk about finances, but a dollar amount shouldn’t count as a word. We can use
    the regex `[^a-z\s]` to remove these characters. This regex matches any character
    that isn’t a lowercase letter (`a-z`) or a whitespace character (`\s`):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '|   | name | date | text |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 0 | George Washington | January 8, 1790 | fellow citizens of the senate and
    house of rep... |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 1 | George Washington | December 8, 1790 | fellow citizens of the senate
    and house of rep... |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 2 | George Washington | October 25, 1791 | fellow citizens of the senate
    and house of rep... |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| ... | ... | ... | ... |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 229 | Donald J. Trump | February 4, 2020 | thank you very much thank you
    thank you very... |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 230 | Joseph R. Biden, Jr. | April 28, 2021 | thank you thank you thank you
    good to be ba... |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 231 | Joseph R. Biden, Jr. | March 1, 2022 | madam speaker madam vice president
    our first... |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we look at some more complex issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Stop words* like `is`, `and`, `the`, and `but` appear so often that we would
    like to just remove them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`argue` and `arguing` should count as the same word, even though they appear
    differently in the text. To address this, we’ll use *word stemming*, which transforms
    both words to `argu`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To handle these issues, we can use built-in methods from [the `nltk` library](https://www.nltk.org).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we transform the speeches into *word vectors*. A word vector represents
    a document using a vector of numbers. For example, one basic type of word vector
    counts up how many times each word appears in the text, as depicted in [Figure 13-2](#fig-word-vectors).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_1302.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13-2\. Bag-of-words vectors for three small example documents
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This simple transform is called *bag-of-words*, and we apply it on all of our
    speeches. Then we calculate the *term frequency-inverse document frequency* (*tf-idf*
    for short) to normalize the counts and measure the rareness of a word. The tf-idf
    puts more weight on words that only appear in a few documents. The idea is that
    if just a few documents mention the word *sanction*, say, then this word is extra
    useful for distinguishing documents from each other. [The `scikit-learn` library](https://oreil.ly/3A6a5)
    has a complete description of the transform and an implementation, which we use.
  prefs: []
  type: TYPE_NORMAL
- en: 'After applying these transforms, we have a two-dimensional array, `speech_vectors`.
    Each row of this array is one speech transformed into a vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: We have 232 speeches, and each speech was transformed into a length-13,211 vector.
    To visualize these speeches, we use a technique called *principal component analysis*
    to represent the data table of 13,211 features by a new set of features that are
    orthogonal to one another. The first vector accounts for the maximum variation
    in the original features, the second for the maximum variance that is orthogonal
    to the first, and so on. Often the first two components, which we can plot as
    pairs of points, reveal clusters and outliers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we plot the first two principal components. Each point is one speech,
    and we’ve colored the points according to the year of the speech. Points that
    are close together represent similar speeches, and points that are far away from
    one another represent dissimilar speeches:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_13in01.png)'
  prefs: []
  type: TYPE_IMG
- en: We see a clear difference in speeches over time—speeches given in the 1800s
    used very different words than speeches given after 2000\. It’s also interesting
    to see that the speeches cluster tightly in the same time period. This suggests
    that speeches within the same period sound relatively similar, even though the
    speakers were from different political parties.
  prefs: []
  type: TYPE_NORMAL
- en: This section gave a whirlwind introduction to text analysis. We used text manipulation
    tools from previous sections to clean up the presidential speeches. Then we used
    more advanced techniques like stemming, the tf-idf transform, and principal component
    analysis to compare speeches. Although we don’t have enough space in this book
    to cover all of these techniques in detail, we hope that this section piqued your
    interest in the exciting world of text analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduced techniques for working with text to clean and analyze
    data, including string manipulation, regular expressions, and document analysis.
    Text data has rich information about how people live, work, and think. But this
    data is also hard for computers to use—think about all the creative ways people
    manage to spell the same word. The techniques in this chapter let us correct typos,
    extract features from logs, and compare documents.
  prefs: []
  type: TYPE_NORMAL
- en: 'We don’t recommend you use regular expressions to:'
  prefs: []
  type: TYPE_NORMAL
- en: Parse hierarchical structures such as JSON or HTML; use a parser instead
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Search for complex properties, like palindromes and balanced parentheses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validate a complex feature, such as a valid email address
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regular expressions, while powerful, are terrible at these types of tasks. However,
    in our experience, even the basics of text manipulation can enable all sorts of
    interesting analyses—a little bit goes a long way.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have one final caution about regular expressions: they can be computationally
    expensive. You will want to consider the trade-offs between these concise, clear
    expressions and the overhead they create if they’re being put into production
    code.'
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter considers other sorts of data, such as data in binary formats,
    and the highly structured text of JSON and HTML. Our focus will be on loading
    these data into dataframes and other Python data structures.
  prefs: []
  type: TYPE_NORMAL
