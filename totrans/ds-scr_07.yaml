- en: Chapter 6\. Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The laws of probability, so true in general, so fallacious in particular.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Edward Gibbon
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is hard to do data science without some sort of understanding of *probability*
    and its mathematics. As with our treatment of statistics in [Chapter 5](ch05.html#statistics),
    we’ll wave our hands a lot and elide many of the technicalities.
  prefs: []
  type: TYPE_NORMAL
- en: For our purposes you should think of probability as a way of quantifying the
    uncertainty associated with *events* chosen from some *universe* of events. Rather
    than getting technical about what these terms mean, think of rolling a die. The
    universe consists of all possible outcomes. And any subset of these outcomes is
    an event; for example, “the die rolls a 1” or “the die rolls an even number.”
  prefs: []
  type: TYPE_NORMAL
- en: Notationally, we write *P*(*E*) to mean “the probability of the event *E*.”
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use probability theory to build models. We’ll use probability theory to
    evaluate models. We’ll use probability theory all over the place.
  prefs: []
  type: TYPE_NORMAL
- en: One could, were one so inclined, get really deep into the philosophy of what
    probability theory *means*. (This is best done over beers.) We won’t be doing
    that.
  prefs: []
  type: TYPE_NORMAL
- en: Dependence and Independence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Roughly speaking, we say that two events *E* and *F* are *dependent* if knowing
    something about whether *E* happens gives us information about whether *F* happens
    (and vice versa). Otherwise, they are *independent*.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if we flip a fair coin twice, knowing whether the first flip is
    heads gives us no information about whether the second flip is heads. These events
    are independent. On the other hand, knowing whether the first flip is heads certainly
    gives us information about whether both flips are tails. (If the first flip is
    heads, then definitely it’s not the case that both flips are tails.) These two
    events are dependent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, we say that two events *E* and *F* are independent if the probability
    that they both happen is the product of the probabilities that each one happens:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper E comma upper F right-parenthesis
    equals upper P left-parenthesis upper E right-parenthesis upper P left-parenthesis
    upper F right-parenthesis" display="block"><mrow><mi>P</mi> <mo>(</mo> <mi>E</mi>
    <mo>,</mo> <mi>F</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>E</mi> <mo>)</mo>
    <mi>P</mi> <mo>(</mo> <mi>F</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: In the example, the probability of “first flip heads” is 1/2, and the probability
    of “both flips tails” is 1/4, but the probability of “first flip heads *and* both
    flips tails” is 0.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When two events *E* and *F* are independent, then by definition we have:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper E comma upper F right-parenthesis
    equals upper P left-parenthesis upper E right-parenthesis upper P left-parenthesis
    upper F right-parenthesis" display="block"><mrow><mi>P</mi> <mo>(</mo> <mi>E</mi>
    <mo>,</mo> <mi>F</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>E</mi> <mo>)</mo>
    <mi>P</mi> <mo>(</mo> <mi>F</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If they are not necessarily independent (and if the probability of *F* is not
    zero), then we define the probability of *E* “conditional on *F*” as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper E vertical-bar upper F right-parenthesis
    equals upper P left-parenthesis upper E comma upper F right-parenthesis slash
    upper P left-parenthesis upper F right-parenthesis" display="block"><mrow><mi>P</mi>
    <mo>(</mo> <mi>E</mi> <mo>|</mo> <mi>F</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo>
    <mi>E</mi> <mo>,</mo> <mi>F</mi> <mo>)</mo> <mo>/</mo> <mi>P</mi> <mo>(</mo> <mi>F</mi>
    <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: You should think of this as the probability that *E* happens, given that we
    know that *F* happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'We often rewrite this as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper E comma upper F right-parenthesis
    equals upper P left-parenthesis upper E vertical-bar upper F right-parenthesis
    upper P left-parenthesis upper F right-parenthesis" display="block"><mrow><mi>P</mi>
    <mo>(</mo> <mi>E</mi> <mo>,</mo> <mi>F</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo>
    <mi>E</mi> <mo>|</mo> <mi>F</mi> <mo>)</mo> <mi>P</mi> <mo>(</mo> <mi>F</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'When *E* and *F* are independent, you can check that this gives:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper E vertical-bar upper F right-parenthesis
    equals upper P left-parenthesis upper E right-parenthesis" display="block"><mrow><mi>P</mi>
    <mo>(</mo> <mi>E</mi> <mo>|</mo> <mi>F</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo>
    <mi>E</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: which is the mathematical way of expressing that knowing *F* occurred gives
    us no additional information about whether *E* occurred.
  prefs: []
  type: TYPE_NORMAL
- en: 'One common tricky example involves a family with two (unknown) children. If
    we assume that:'
  prefs: []
  type: TYPE_NORMAL
- en: Each child is equally likely to be a boy or a girl.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The gender of the second child is independent of the gender of the first child.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then the event “no girls” has probability 1/4, the event “one girl, one boy”
    has probability 1/2, and the event “two girls” has probability 1/4.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can ask what is the probability of the event “both children are girls”
    (*B*) conditional on the event “the older child is a girl” (*G*)? Using the definition
    of conditional probability:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper B vertical-bar upper G right-parenthesis
    equals upper P left-parenthesis upper B comma upper G right-parenthesis slash
    upper P left-parenthesis upper G right-parenthesis equals upper P left-parenthesis
    upper B right-parenthesis slash upper P left-parenthesis upper G right-parenthesis
    equals 1 slash 2" display="block"><mrow><mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>|</mo>
    <mi>G</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>,</mo> <mi>G</mi>
    <mo>)</mo> <mo>/</mo> <mi>P</mi> <mo>(</mo> <mi>G</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi>
    <mo>(</mo> <mi>B</mi> <mo>)</mo> <mo>/</mo> <mi>P</mi> <mo>(</mo> <mi>G</mi> <mo>)</mo>
    <mo>=</mo> <mn>1</mn> <mo>/</mo> <mn>2</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: since the event *B* and *G* (“both children are girls *and* the older child
    is a girl”) is just the event *B*. (Once you know that both children are girls,
    it’s necessarily true that the older child is a girl.)
  prefs: []
  type: TYPE_NORMAL
- en: Most likely this result accords with your intuition.
  prefs: []
  type: TYPE_NORMAL
- en: We could also ask about the probability of the event “both children are girls”
    conditional on the event “at least one of the children is a girl” (*L*). Surprisingly,
    the answer is different from before!
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, the event *B* and *L* (“both children are girls *and* at least one
    of the children is a girl”) is just the event *B*. This means we have:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper B vertical-bar upper L right-parenthesis
    equals upper P left-parenthesis upper B comma upper L right-parenthesis slash
    upper P left-parenthesis upper L right-parenthesis equals upper P left-parenthesis
    upper B right-parenthesis slash upper P left-parenthesis upper L right-parenthesis
    equals 1 slash 3" display="block"><mrow><mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>|</mo>
    <mi>L</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>,</mo> <mi>L</mi>
    <mo>)</mo> <mo>/</mo> <mi>P</mi> <mo>(</mo> <mi>L</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi>
    <mo>(</mo> <mi>B</mi> <mo>)</mo> <mo>/</mo> <mi>P</mi> <mo>(</mo> <mi>L</mi> <mo>)</mo>
    <mo>=</mo> <mn>1</mn> <mo>/</mo> <mn>3</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: How can this be the case? Well, if all you know is that at least one of the
    children is a girl, then it is twice as likely that the family has one boy and
    one girl than that it has both girls.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check this by “generating” a lot of families:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Bayes’s Theorem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the data scientist’s best friends is Bayes’s theorem, which is a way
    of “reversing” conditional probabilities. Let’s say we need to know the probability
    of some event *E* conditional on some other event *F* occurring. But we only have
    information about the probability of *F* conditional on *E* occurring. Using the
    definition of conditional probability twice tells us that:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper E vertical-bar upper F right-parenthesis
    equals upper P left-parenthesis upper E comma upper F right-parenthesis slash
    upper P left-parenthesis upper F right-parenthesis equals upper P left-parenthesis
    upper F vertical-bar upper E right-parenthesis upper P left-parenthesis upper
    E right-parenthesis slash upper P left-parenthesis upper F right-parenthesis"
    display="block"><mrow><mi>P</mi> <mo>(</mo> <mi>E</mi> <mo>|</mo> <mi>F</mi> <mo>)</mo>
    <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>E</mi> <mo>,</mo> <mi>F</mi> <mo>)</mo> <mo>/</mo>
    <mi>P</mi> <mo>(</mo> <mi>F</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>F</mi>
    <mo>|</mo> <mi>E</mi> <mo>)</mo> <mi>P</mi> <mo>(</mo> <mi>E</mi> <mo>)</mo> <mo>/</mo>
    <mi>P</mi> <mo>(</mo> <mi>F</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The event *F* can be split into the two mutually exclusive events “*F* and
    *E*” and “*F* and not *E*.” If we write <math><mrow><mo>¬</mo> <mi>E</mi></mrow></math>
    for “not *E*” (i.e., “*E* doesn’t happen”), then:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper F right-parenthesis equals upper
    P left-parenthesis upper F comma upper E right-parenthesis plus upper P left-parenthesis
    upper F comma normal not-sign upper E right-parenthesis" display="block"><mrow><mi>P</mi>
    <mo>(</mo> <mi>F</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>F</mi> <mo>,</mo>
    <mi>E</mi> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>F</mi> <mo>,</mo> <mo>¬</mo>
    <mi>E</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'so that:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper E vertical-bar upper F right-parenthesis
    equals upper P left-parenthesis upper F vertical-bar upper E right-parenthesis
    upper P left-parenthesis upper E right-parenthesis slash left-bracket upper P
    left-parenthesis upper F vertical-bar upper E right-parenthesis upper P left-parenthesis
    upper E right-parenthesis plus upper P left-parenthesis upper F vertical-bar normal
    not-sign upper E right-parenthesis upper P left-parenthesis normal not-sign upper
    E right-parenthesis right-bracket" display="block"><mrow><mi>P</mi> <mo>(</mo>
    <mi>E</mi> <mo>|</mo> <mi>F</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>F</mi>
    <mo>|</mo> <mi>E</mi> <mo>)</mo> <mi>P</mi> <mo>(</mo> <mi>E</mi> <mo>)</mo> <mo>/</mo>
    <mo>[</mo> <mi>P</mi> <mo>(</mo> <mi>F</mi> <mo>|</mo> <mi>E</mi> <mo>)</mo> <mi>P</mi>
    <mo>(</mo> <mi>E</mi> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>F</mi> <mo>|</mo>
    <mo>¬</mo> <mi>E</mi> <mo>)</mo> <mi>P</mi> <mo>(</mo> <mo>¬</mo> <mi>E</mi> <mo>)</mo>
    <mo>]</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: which is how Bayes’s theorem is often stated.
  prefs: []
  type: TYPE_NORMAL
- en: This theorem often gets used to demonstrate why data scientists are smarter
    than doctors. Imagine a certain disease that affects 1 in every 10,000 people.
    And imagine that there is a test for this disease that gives the correct result
    (“diseased” if you have the disease, “nondiseased” if you don’t) 99% of the time.
  prefs: []
  type: TYPE_NORMAL
- en: 'What does a positive test mean? Let’s use *T* for the event “your test is positive”
    and *D* for the event “you have the disease.” Then Bayes’s theorem says that the
    probability that you have the disease, conditional on testing positive, is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper D vertical-bar upper T right-parenthesis
    equals upper P left-parenthesis upper T vertical-bar upper D right-parenthesis
    upper P left-parenthesis upper D right-parenthesis slash left-bracket upper P
    left-parenthesis upper T vertical-bar upper D right-parenthesis upper P left-parenthesis
    upper D right-parenthesis plus upper P left-parenthesis upper T vertical-bar normal
    not-sign upper D right-parenthesis upper P left-parenthesis normal not-sign upper
    D right-parenthesis right-bracket" display="block"><mrow><mi>P</mi> <mo>(</mo>
    <mi>D</mi> <mo>|</mo> <mi>T</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>T</mi>
    <mo>|</mo> <mi>D</mi> <mo>)</mo> <mi>P</mi> <mo>(</mo> <mi>D</mi> <mo>)</mo> <mo>/</mo>
    <mo>[</mo> <mi>P</mi> <mo>(</mo> <mi>T</mi> <mo>|</mo> <mi>D</mi> <mo>)</mo> <mi>P</mi>
    <mo>(</mo> <mi>D</mi> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>T</mi> <mo>|</mo>
    <mo>¬</mo> <mi>D</mi> <mo>)</mo> <mi>P</mi> <mo>(</mo> <mo>¬</mo> <mi>D</mi> <mo>)</mo>
    <mo>]</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we know that <math><mrow><mi>P</mi> <mo>(</mo> <mi>T</mi> <mo>|</mo> <mi>D</mi>
    <mo>)</mo></mrow></math> , the probability that someone with the disease tests
    positive, is 0.99\. *P*(*D*), the probability that any given person has the disease,
    is 1/10,000 = 0.0001\. <math><mrow><mi>P</mi> <mo>(</mo> <mi>T</mi> <mo>|</mo>
    <mo>¬</mo> <mi>D</mi> <mo>)</mo></mrow></math> , the probability that someone
    without the disease tests positive, is 0.01\. And <math><mrow><mi>P</mi> <mo>(</mo>
    <mo>¬</mo> <mi>D</mi> <mo>)</mo></mrow></math> , the probability that any given
    person doesn’t have the disease, is 0.9999\. If you substitute these numbers into
    Bayes’s theorem, you find:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper D vertical-bar upper T right-parenthesis
    equals 0.98 percent-sign" display="block"><mrow><mi>P</mi> <mo>(</mo> <mi>D</mi>
    <mo>|</mo> <mi>T</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>98</mn>
    <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: That is, less than 1% of the people who test positive actually have the disease.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This assumes that people take the test more or less at random. If only people
    with certain symptoms take the test, we would instead have to condition on the
    event “positive test *and* symptoms” and the number would likely be a lot higher.
  prefs: []
  type: TYPE_NORMAL
- en: A more intuitive way to see this is to imagine a population of 1 million people.
    You’d expect 100 of them to have the disease, and 99 of those 100 to test positive.
    On the other hand, you’d expect 999,900 of them not to have the disease, and 9,999
    of those to test positive. That means you’d expect only 99 out of (99 + 9999)
    positive testers to actually have the disease.
  prefs: []
  type: TYPE_NORMAL
- en: Random Variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A *random variable* is a variable whose possible values have an associated probability
    distribution. A very simple random variable equals 1 if a coin flip turns up heads
    and 0 if the flip turns up tails. A more complicated one might measure the number
    of heads you observe when flipping a coin 10 times or a value picked from `range(10)`
    where each number is equally likely.
  prefs: []
  type: TYPE_NORMAL
- en: The associated distribution gives the probabilities that the variable realizes
    each of its possible values. The coin flip variable equals 0 with probability
    0.5 and 1 with probability 0.5\. The `range(10)` variable has a distribution that
    assigns probability 0.1 to each of the numbers from 0 to 9.
  prefs: []
  type: TYPE_NORMAL
- en: We will sometimes talk about the *expected value* of a random variable, which
    is the average of its values weighted by their probabilities. The coin flip variable
    has an expected value of 1/2 (= 0 * 1/2 + 1 * 1/2), and the `range(10)` variable
    has an expected value of 4.5.
  prefs: []
  type: TYPE_NORMAL
- en: Random variables can be *conditioned* on events just as other events can. Going
    back to the two-child example from [“Conditional Probability”](#conditional_probability),
    if *X* is the random variable representing the number of girls, *X* equals 0 with
    probability 1/4, 1 with probability 1/2, and 2 with probability 1/4.
  prefs: []
  type: TYPE_NORMAL
- en: We can define a new random variable *Y* that gives the number of girls conditional
    on at least one of the children being a girl. Then *Y* equals 1 with probability
    2/3 and 2 with probability 1/3\. And a variable *Z* that’s the number of girls
    conditional on the older child being a girl equals 1 with probability 1/2 and
    2 with probability 1/2.
  prefs: []
  type: TYPE_NORMAL
- en: For the most part, we will be using random variables *implicitly* in what we
    do without calling special attention to them. But if you look deeply you’ll see
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A coin flip corresponds to a *discrete distribution*—one that associates positive
    probability with discrete outcomes. Often we’ll want to model distributions across
    a continuum of outcomes. (For our purposes, these outcomes will always be real
    numbers, although that’s not always the case in real life.) For example, the *uniform
    distribution* puts *equal weight* on all the numbers between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: Because there are infinitely many numbers between 0 and 1, this means that the
    weight it assigns to individual points must necessarily be zero. For this reason,
    we represent a continuous distribution with a *probability density function* (PDF)
    such that the probability of seeing a value in a certain interval equals the integral
    of the density function over the interval.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If your integral calculus is rusty, a simpler way of understanding this is that
    if a distribution has density function *f*, then the probability of seeing a value
    between *x* and *x + h* is approximately *h * f(x)* if *h* is small.
  prefs: []
  type: TYPE_NORMAL
- en: 'The density function for the uniform distribution is just:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The probability that a random variable following that distribution is between
    0.2 and 0.3 is 1/10, as you’d expect. Python’s `random.random` is a (pseudo)random
    variable with a uniform density.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will often be more interested in the *cumulative distribution function*
    (CDF), which gives the probability that a random variable is less than or equal
    to a certain value. It’s not hard to create the CDF for the uniform distribution
    ([Figure 6-1](#uniform_cdf)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Uniform CDF.](assets/dsf2_0601.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-1\. The uniform CDF
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The Normal Distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The normal distribution is the classic bell curve–shaped distribution and is
    completely determined by two parameters: its mean *μ* (mu) and its standard deviation
    *σ* (sigma). The mean indicates where the bell is centered, and the standard deviation
    how “wide” it is.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It has the PDF:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="f left-parenthesis x vertical-bar mu comma sigma right-parenthesis
    equals StartFraction 1 Over StartRoot 2 pi EndRoot sigma EndFraction exp left-parenthesis
    minus StartFraction left-parenthesis x minus mu right-parenthesis squared Over
    2 sigma squared EndFraction right-parenthesis" display="block"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>μ</mi> <mo>,</mo> <mi>σ</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mn>1</mn> <mrow><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt><mi>σ</mi></mrow></mfrac>
    <mo form="prefix">exp</mo> <mo>(</mo> <mrow><mo>-</mo> <mfrac><msup><mrow><mo>(</mo><mi>x</mi><mo>-</mo><mi>μ</mi><mo>)</mo></mrow>
    <mn>2</mn></msup> <mrow><mn>2</mn><msup><mi>σ</mi> <mn>2</mn></msup></mrow></mfrac>
    <mrow><mo>)</mo></mrow></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'which we can implement as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In [Figure 6-2](#various_normal_pdfs), we plot some of these PDFs to see what
    they look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Various normal pdfs.](assets/dsf2_0602.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-2\. Various normal PDFs
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When *μ* = 0 and *σ* = 1, it’s called the *standard normal distribution*. If
    *Z* is a standard normal random variable, then it turns out that:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper X equals sigma upper Z plus mu" display="block"><mrow><mi>X</mi>
    <mo>=</mo> <mi>σ</mi> <mi>Z</mi> <mo>+</mo> <mi>μ</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: is also normal but with mean <math alttext="mu"><mi>μ</mi></math> and standard
    deviation <math alttext="sigma"><mi>σ</mi></math> . Conversely, if *X* is a normal
    random variable with mean <math alttext="mu"><mi>μ</mi></math> and standard deviation
    <math alttext="sigma"><mi>σ</mi></math> ,
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper Z equals left-parenthesis upper X minus mu right-parenthesis
    slash sigma" display="block"><mrow><mi>Z</mi> <mo>=</mo> <mo>(</mo> <mi>X</mi>
    <mo>-</mo> <mi>μ</mi> <mo>)</mo> <mo>/</mo> <mi>σ</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: is a standard normal variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The CDF for the normal distribution cannot be written in an “elementary” manner,
    but we can write it using Python’s `math.erf` [error function](http://en.wikipedia.org/wiki/Error_function):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, in [Figure 6-3](#various_normal_cdfs), we plot a few CDFs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![Various normal cdfs.](assets/dsf2_0603.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-3\. Various normal CDFs
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Sometimes we’ll need to invert `normal_cdf` to find the value corresponding
    to a specified probability. There’s no simple way to compute its inverse, but
    `normal_cdf` is continuous and strictly increasing, so we can use a [*binary search*](http://en.wikipedia.org/wiki/Binary_search_algorithm):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The function repeatedly bisects intervals until it narrows in on a *Z* that’s
    close enough to the desired probability.
  prefs: []
  type: TYPE_NORMAL
- en: The Central Limit Theorem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One reason the normal distribution is so useful is the *central limit theorem*,
    which says (in essence) that a random variable defined as the average of a large
    number of independent and identically distributed random variables is itself approximately
    normally distributed.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, if <math><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo>
    <mo>...</mo> <mo>,</mo> <msub><mi>x</mi> <mi>n</mi></msub></mrow></math> are random
    variables with mean *μ* and standard deviation *σ*, and if *n* is large, then:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mn>1</mn> <mi>n</mi></mfrac> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>x</mi>
    <mi>n</mi></msub> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: is approximately normally distributed with mean *μ* and standard deviation <math
    alttext="sigma slash StartRoot n EndRoot"><mrow><mi>σ</mi> <mo>/</mo> <msqrt><mi>n</mi></msqrt></mrow></math>
    . Equivalently (but often more usefully),
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartFraction left-parenthesis x 1 plus ellipsis plus x Subscript
    n Baseline right-parenthesis minus mu n Over sigma StartRoot n EndRoot EndFraction"
    display="block"><mfrac><mrow><mo>(</mo><msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo><mo>...</mo><mo>+</mo><msub><mi>x</mi>
    <mi>n</mi></msub> <mo>)</mo><mo>-</mo><mi>μ</mi><mi>n</mi></mrow> <mrow><mi>σ</mi><msqrt><mi>n</mi></msqrt></mrow></mfrac></math>
  prefs: []
  type: TYPE_NORMAL
- en: is approximately normally distributed with mean 0 and standard deviation 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'An easy way to illustrate this is by looking at *binomial* random variables,
    which have two parameters *n* and *p*. A Binomial(*n*,*p*) random variable is
    simply the sum of *n* independent Bernoulli(*p*) random variables, each of which
    equals 1 with probability *p* and 0 with probability 1 – *p*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The mean of a Bernoulli(*p*) variable is *p*, and its standard deviation is
    <math alttext="StartRoot p left-parenthesis 1 minus p right-parenthesis EndRoot"><msqrt><mrow><mi>p</mi>
    <mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>p</mi> <mo>)</mo></mrow></msqrt></math> .
    The central limit theorem says that as *n* gets large, a Binomial(*n*,*p*) variable
    is approximately a normal random variable with mean <math alttext="mu equals n
    p"><mrow><mi>μ</mi> <mo>=</mo> <mi>n</mi> <mi>p</mi></mrow></math> and standard
    deviation <math alttext="sigma equals StartRoot n p left-parenthesis 1 minus p
    right-parenthesis EndRoot"><mrow><mi>σ</mi> <mo>=</mo> <msqrt><mrow><mi>n</mi>
    <mi>p</mi> <mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>p</mi> <mo>)</mo></mrow></msqrt></mrow></math>
    . If we plot both, you can easily see the resemblance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: For example, when you call `make_hist(0.75, 100, 10000)`, you get the graph
    in [Figure 6-4](#make_hist_result).
  prefs: []
  type: TYPE_NORMAL
- en: '![The result of calling binomial_histogram.](assets/dsf2_0604.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-4\. The output from binomial_histogram
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The moral of this approximation is that if you want to know the probability
    that (say) a fair coin turns up more than 60 heads in 100 flips, you can estimate
    it as the probability that a Normal(50,5) is greater than 60, which is easier
    than computing the Binomial(100,0.5) CDF. (Although in most applications you’d
    probably be using statistical software that would gladly compute whatever probabilities
    you want.)
  prefs: []
  type: TYPE_NORMAL
- en: For Further Exploration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html) contains
    PDF and CDF functions for most of the popular probability distributions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember how, at the end of [Chapter 5](ch05.html#statistics), I said that it
    would be a good idea to study a statistics textbook? It would also be a good idea
    to study a probability textbook. The best one I know that’s available online is
    [*Introduction to Probability*](http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/book.html),
    by Charles M. Grinstead and J. Laurie Snell (American Mathematical Society).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
