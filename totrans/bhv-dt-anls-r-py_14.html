<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 10. Cluster Randomization and Hierarchical Modeling"><div class="chapter" id="cluster_randomization_and_hierarchical">
<h1><span class="label">Chapter 10. </span>Cluster Randomization and <span class="keep-together">Hierarchical Modeling</span></h1>
<p>Our last experiment, while conceptually simple, will illustrate some of the logistical and statistical difficulties of experimenting in business. <a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="hierarchical linear modeling" data-tertiary="about business problem" id="idm45968147309992"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="call center problem-solving mode" data-tertiary="about business problem" id="idm45968147308376"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="about call center problem-solving mode" id="idm45968147306792"/><a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="about business problem" id="idm45968147305448"/>AirCnC has 10 customer call centers spread across the country, where representatives handle any issue that might come up in the course of a booking (e.g., the payment did not go through, the property doesn’t look like the pictures, etc.). Having read an article in the <em>Harvard Business Review</em> (HBR) about customer service,<sup><a data-type="noteref" id="ch01fn22-marker" href="ch10.xhtml#ch01fn22">1</a></sup> the VP of customer service has decided to implement a change in standard operating procedures (SOP): instead of apologizing repeatedly when something went wrong, the call center reps should apologize at the beginning of the interaction, then get into “problem-solving mode,” then end up offering several options to the customer.</p>
<p>This experiment presents multiple challenges: due to logistical constraints, we’ll be able to randomize treatment only at the level of call centers and not reps, and we’ll have difficulties enforcing and measuring compliance. This certainly doesn’t mean that we can’t or shouldn’t run an experiment!</p>
<p>Regarding the randomization constraint, we’ll see that this makes the standard linear regression algorithm inappropriate and that we should use hierarchical linear modeling (HLM) instead.</p>
<p class="pagebreak-before less_space">As before, our approach will be:</p>
<ul>
<li><p>Planning the experiment</p></li>
<li><p>Determining random assignment and sample size/power</p></li>
<li><p>Analyzing the experiment</p></li>
</ul>
<section data-type="sect1" data-pdf-bookmark="Planning the Experiment"><div class="sect1" id="planning_the_experimen">
<h1>Planning the Experiment</h1>
<p>In this section, I’ll go briskly through our theory of change<a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="call center problem-solving mode" data-tertiary="planning the experiment" id="ch10-plex5"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" id="ch10-plex"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="hierarchical linear modeling" data-tertiary="planning the experiment" id="ch10-plex2"/><a contenteditable="false" data-type="indexterm" data-primary="theory of change (ToC)" data-secondary="call center problem-solving mode" id="ch10-plex3"/><a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="planning the experiment" id="ch10-plex4"/> to provide you with some necessary context and behavioral grounding:</p>
<ol>
<li><p>First, the business goal and target metric</p></li>
<li><p>Next, the definition of our intervention</p></li>
<li><p>Finally, the behavioral logic that connects them</p></li>
</ol>
<section data-type="sect2" data-pdf-bookmark="Business Goal and Target Metric"><div class="sect2" id="business_goal_and_target_metr">
<h2>Business Goal and Target Metric</h2>
<p>Based on the HBR article, our criterion for <a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="planning the experiment" data-tertiary="business goal and target metric" id="idm45968147282312"/><a contenteditable="false" data-type="indexterm" data-primary="business goals" data-secondary="call center problem-solving mode" id="idm45968147554920"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" data-tertiary="business goal" id="idm45968147553528"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" data-tertiary="target metric" id="idm45968147551880"/><a contenteditable="false" data-type="indexterm" data-primary="target metrics" data-secondary="call center problem-solving mode" id="idm45968147550232"/><a contenteditable="false" data-type="indexterm" data-primary="customer satisfaction (CSAT)" data-secondary="call center target metric" id="idm45968147548840"/><a contenteditable="false" data-type="indexterm" data-primary="surveys" data-secondary="call center CSAT target metric" id="idm45968147547432"/>success or target metric appears straightforward: customer satisfaction as measured by a one-question survey administered by email after the phone call. However, we’ll see in a minute that there are complications, so we’ll need to revisit it after discussing what we’re testing.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Definition of the Intervention"><div class="sect2" id="definition_of_the_intervention-id00029">
<h2>Definition of the Intervention</h2>
<p>The treatment we’re testing will be whether the reps have been trained in the new SOP and instructed to implement it.<a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="planning the experiment" data-tertiary="intervention" id="idm45968147543400"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" data-tertiary="intervention" id="idm45968147541688"/><a contenteditable="false" data-type="indexterm" data-primary="interventions" data-secondary="call center problem-solving mode" id="idm45968147540040"/></p>
<p>The first difficulty is in the implementation of the treatment. We know from past experience that asking the reps to apply different SOPs to different customers is very challenging: asking reps to switch processes at random between calls increases their cognitive load and the risk of noncompliance. Therefore, we’ll have to train some reps and instruct them to use the new SOP for all of their calls, while keeping other reps on the old SOP.</p>
<p>Even with that correction, compliance remains at risk: reps in the treatment group may implement the new SOP inconsistently or even not at all, while reps in the control group may also apply the old SOP inconsistently. Obviously, this would muddle our analysis and make the treatment appear less different from the control group than it is. One way to mitigate this issue is to first observe current compliance with the SOP in place by listening to calls, then run a pilot study, where we select a few reps, train them, and observe compliance with the new SOP. Debriefing the reps in the pilot study after the fact can help identify misunderstandings and obstacles to compliance. Unfortunately, it is generally impossible to have 100% compliance in an experiment where human beings are delivering or choosing the treatment. The best we can do is to try to measure compliance and take it into account when drawing conclusions.</p>
<p>Finally, there is a risk of “leakage” between our control and our treatment groups. Reps are human beings, and reps in a given call center interact and chat. <a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="call center problem-solving mode" data-tertiary="hierarchical modeling" id="idm45968147535816"/><a contenteditable="false" data-type="indexterm" data-primary="customer satisfaction (CSAT)" data-secondary="call center target metric" data-tertiary="incentivization muddying" id="idm45968147534136"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="hierarchical linear modeling" data-tertiary="about" id="idm45968147532440"/><a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="about" id="idm45968147530776"/>Given that reps are incentivized on the average monthly customer satisfaction (CSAT) for their calls, if reps in the treatment group started seeing significantly better results, there is a risk that reps in the control group of the same call center would start changing their procedure. Having some people in the control group apply the treatment would muddle the comparison for the two groups and make the difference appear smaller than it really is. Therefore, we’ll apply the treatment at the call center level: all reps in a given call center will either be in the treatment group or in the control group.</p>
<p>Applying the treatment at the call center level instead of at the call level has implications for our criterion for success. If our unit of randomization is the call center, should we measure the CSAT at the call center level? This would seem logical, but it would mean that we can’t use any information about individual reps or individual calls. On the other hand, measuring average CSAT at the rep level or even CSAT at the call level would allow us to use more information, but it is problematic for two reasons:</p>
<ul>
<li><p>First, if we were to disregard the fact that randomization was not done at the call level and use standard power analysis, our results would be biased because randomization is unavoidably correlated with the call center variable; adding more calls in our sample would not change the fact that we have only 10 call centers and therefore only 10 randomization units.</p></li>
<li><p>Second, in our data analysis, we would run into trouble due to the nested nature of the data: assuming that each rep belongs to one and only one call center, there will be multicollinearity between our call center variable and our rep variable (e.g., we can add 1 to the coefficient for the first call center and subtract 1 from the coefficients for all the reps in that call center without changing the results of the regression; therefore the coefficients for the regression are essentially <span class="keep-together">undetermined).</span></p></li>
</ul>
<p>Fortunately, there is a simple solution to this problem: we’ll use a hierarchical model, which recognizes the nested structure of our data and handles it appropriately, while allowing us to use explanatory variables down to the call level.<sup><a data-type="noteref" id="ch01fn23-marker" href="ch10.xhtml#ch01fn23">2</a></sup> For our purposes, we won’t get into statistical details and we’ll only see how to run the corresponding code and interpret the results. A hierarchical model is a general framework that can be applied to linear and logistic regression, so we’ll still be in known territory.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Behavioral Logic"><div class="sect2" id="behavioral_logic-id00002">
<h2>Behavioral Logic</h2>
<p>Finally, the logic for success for this experiment is simple: <a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="planning the experiment" data-tertiary="behavioral logic" id="idm45968147520824"/><a contenteditable="false" data-type="indexterm" data-primary="behavioral logic" data-secondary="call center problem-solving mode" id="idm45968147519208"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" data-tertiary="behavioral logic" id="idm45968147517816"/><a contenteditable="false" data-type="indexterm" data-primary="theory of change (ToC)" data-secondary="behavioral logic" id="idm45968147516168"/>the new SOP will make customers feel better during the interaction, which will translate into a higher measured CSAT (<a data-type="xref" href="#causal_logic_for_our_experiment">Figure 10-1</a>).<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-plex" id="idm45968147513560"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-plex2" id="idm45968147512184"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-plex3" id="idm45968147510808"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-plex4" id="idm45968147509432"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-plex5" id="idm45968147508056"/></p>
<figure><div id="causal_logic_for_our_experiment" class="figure">
<img src="Images/BEDA_1001.png" alt="Causal logic for our experiment" width="1157" height="139"/>
<h6><span class="label">Figure 10-1. </span>Causal logic for our experiment</h6>
</div></figure>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Data and Packages"><div class="sect1" id="data_and_libraries-id00026">
<h1>Data and Packages</h1>
<p>The <a href="https://oreil.ly/BehavioralDataAnalysisCh10">GitHub folder for this chapter</a> <a contenteditable="false" data-type="indexterm" data-primary="libraries" data-see="packages" id="idm45968147501784"/><a contenteditable="false" data-type="indexterm" data-primary="GitHub" data-secondary="experimental design data" data-tertiary="call center as problem solvers" id="idm45968147500408"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="call center problem-solving mode" data-tertiary="data and packages for example" id="idm45968147498728"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="data and packages for examples" id="idm45968147497032"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="hierarchical linear modeling" data-tertiary="data and packages for example" id="idm45968147093192"/><a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="data and packages for example" id="idm45968147091736"/><a contenteditable="false" data-type="indexterm" data-primary="cluster randomization" id="idm45968147090520"/>contains two CSV files with the variables listed in <a data-type="xref" href="#variables_in_our_data-id00083">Table 10-1</a>. The check mark (✓) indicates the variables present in that file, while the cross (☓) indicates the variables that are not present.</p>
<table class="border" id="variables_in_our_data-id00083">
<caption><span class="label">Table 10-1. </span>Variables in our data</caption>
<thead>
<tr>
<th/>
<th>Variable description</th>
<th>chap10-historical_data.csv</th>
<th>chap10-experimental_data.csv</th>
</tr>
</thead>
<tbody>
<tr>
<td><em>Center_ID</em></td>
<td>Categorical variable for the 10 call centers</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>Rep_ID</em></td>
<td>Categorical variable for the 193 call center reps</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>Age</em></td>
<td>Age of customer calling, 20-60</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>Reason</em></td>
<td>Reason for call, “payment”/“property”</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>Call_CSAT</em></td>
<td>Customer satisfaction with call, 0-10</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>Group</em></td>
<td>Experimental assignment, “ctrl”/“treat”</td>
<td>☓</td>
<td>✓</td>
</tr>
</tbody>
</table>
<p>Note that the two data sets also contain the binary variable <em>M6Spend</em>, the amount spent on subsequent bookings within six months of a given booking. This variable will be used in <a data-type="xref" href="ch11.xhtml#introduction_to_moderation">Chapter 11</a> only.</p>
<p>In this chapter, we’ll use the following packages in addition to the common ones:<a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="block() function" id="idm45968147070184"/><a contenteditable="false" data-type="indexterm" data-primary="block() function" data-secondary="package" id="idm45968147068552"/><a contenteditable="false" data-type="indexterm" data-primary="dummyVars()" data-secondary="package" id="idm45968147067304"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="dummyVars() one-hot encoding" id="idm45968147065928"/><a contenteditable="false" data-type="indexterm" data-primary="one-hot encoding" data-secondary="dummyVars() function" data-tertiary="package" id="idm45968147064488"/><a contenteditable="false" data-type="indexterm" data-primary="rescale() function package" id="idm45968147062840"/><a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="package for HLM" id="idm45968147061720"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="hierarchical linear modeling" id="idm45968147060328"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="rescale() function" id="idm45968147058936"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="optimal algorithm" data-tertiary="package" id="idm45968147057560"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="optimal algorithm" id="idm45968147055896"/><a contenteditable="false" data-type="indexterm" data-primary="optimal algorithm for stratified randomization" data-secondary="package" id="idm45968147054232"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="optimal algorithm for stratified randomization" id="idm45968147052760"/><a contenteditable="false" data-type="indexterm" data-primary="as.binary() function" data-secondary="package" id="idm45968147051352"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="as.binary() function" id="idm45968147049976"/><a contenteditable="false" data-type="indexterm" data-primary="MinMaxScaler" data-secondary="package" id="idm45968147048600"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="MinMaxScaler" id="idm45968147047224"/><a contenteditable="false" data-type="indexterm" data-primary="OneHotEncoder" data-secondary="package" id="idm45968147045848"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="OneHotEncoder" id="idm45968147044472"/><a contenteditable="false" data-type="indexterm" data-primary="one-hot encoding" data-secondary="OneHotEncoder" data-tertiary="package" id="idm45968147043096"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="nf">library</code><code class="p">(</code><code class="n">blockTools</code><code class="p">)</code> <code class="c1"># For function block()</code>
<code class="nf">library</code><code class="p">(</code><code class="n">caret</code><code class="p">)</code> <code class="c1"># For one-hot encoding function dummyVars()</code>
<code class="nf">library</code><code class="p">(</code><code class="n">scales</code><code class="p">)</code> <code class="c1"># For function rescale()</code>
<code class="nf">library</code><code class="p">(</code><code class="n">lme4</code><code class="p">)</code> <code class="c1"># For hierarchical modeling</code>
<code class="nf">library</code><code class="p">(</code><code class="n">lmerTest</code><code class="p">)</code> <code class="c1"># For additional diagnostics of hierarchical modeling</code>
<code class="nf">library</code><code class="p">(</code><code class="n">nbpMatching</code><code class="p">)</code> <code class="c1"># To use 'optimal' algorithm in stratified randomization</code>
<code class="nf">library</code><code class="p">(</code><code class="n">binaryLogic</code><code class="p">)</code> <code class="c1"># For function as.binary()</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
<code class="s2">"# To rescale numeric variables</code>
<code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="kn">import</code> <code class="n">MinMaxScaler</code>
<code class="c1"># To one-hot encode cat. variables</code>
<code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="kn">import</code> <code class="n">OneHotEncoder</code><code class="s2">"</code></pre>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Introduction to Hierarchical Modeling"><div class="sect1" id="introduction_to_hierarchical_modeling">
<h1>Introduction to Hierarchical Modeling</h1>
<p>Hierarchical models (HMs) can be used when you have categorical variables in your data:<a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="call center problem-solving mode" data-tertiary="hierarchical modeling" id="ch10-hlmabt4"/><a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="about" id="ch10-hlmabt"/><a contenteditable="false" data-type="indexterm" data-primary="categorical variables" data-secondary="hierarchical linear modeling for" id="ch10-hlmabt2"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="hierarchical linear modeling" data-tertiary="about" id="ch10-hlmabt3"/></p>
<ul>
<li><p>Customer transactions across multiple stores</p></li>
<li><p>Rental properties across multiple states</p></li>
<li><p>Etc.</p></li>
</ul>
<p>Some situations call for HMs because you can’t use traditional categorical variables. The main one is if you have a categorical variable that is dependent on another categorical variable (e.g., Vegetarian = {“yes,” “no”} and Flavor = {“ham,” “turkey,” “tofu,” “cheese”}), a.k.a. “nested” categorical variables. Then, multicollinearity issues make HMs the way to go. That’s also why they are called “hierarchical” models, even though they can be applied to non-nested categories as well.</p>
<p>Beyond that, HMs also offer a more robust alternative if you have a categorical variable with a large number of categories, such as the call center rep ID in our example, and especially if some of the categories have very few rows in your data. Without getting into too much detail, this robustness comes from the way coefficients in HMs incorporate some information from other rows, which brings them closer to the overall average. <a contenteditable="false" data-type="indexterm" data-primary="outliers" data-secondary="hierarchical linear modeling handling" id="idm45968146976328"/>Let’s imagine that we had in our data a call center rep having answered only one call, with an exceptionally bad CSAT that is clearly an outlier. With only one call for that rep, we don’t know whether the rep or the call is the outlier. A categorical variable would assign 100% of the “outlier-ness” to the rep, whereas an HM would split it between the rep and the call, i.e., we would expect the rep to have lower-than-average CSAT with other calls, but not as extreme as the observed call.</p>
<p>Finally, in situations where both categorical variables and HMs could be applied (which is basically any situation where you have a categorical variable with a few, non-nested, categories!), there are some nuances in interpretation that may make you prefer one or the other. Conceptually, a categorical variable is a partition of your data into groups with intrinsic differences between them that we want to understand, whereas an HM treats groups as random draws from a potentially infinite distribution of groups. AirCnC has 30 call centers, but it could have been 10 or 50 instead, and we’re not interested in the differences between call center number 3 and call center number 28. On the other hand, we’d like to know whether calls for payment <span class="keep-together">reasons</span> have a higher or lower average CSAT than calls related to property issues, and we wouldn’t be satisfied with just knowing that the standard deviation between groups is 0.3. But again, these are nuances of interpretation, so don’t think too much about it.</p>
<section data-type="sect2" data-pdf-bookmark="R Code"><div class="sect2" id="r_code-id00059">
<h2>R Code</h2>
<p>Let’s review the syntax for hierarchical modeling in a simple<a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="about" data-tertiary="R code" id="ch10-hlmR"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="hierarchical linear modeling" data-tertiary="about syntax" id="idm45968146968088"/> context, by looking at the determinants of call CSAT in our historical data, leaving the <em>Rep_ID</em> variable aside for now. The R code is as follows:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="o">&gt;</code> <code class="n">hlm_mod</code> <code class="o">&lt;-</code> <code class="nf">lmer</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">hist_data</code><code class="p">,</code> <code class="n">call_CSAT</code> <code class="o">~</code> <code class="n">reason</code> <code class="o">+</code> <code class="n">age</code> <code class="o">+</code> <code class="p">(</code><code class="m">1</code><code class="o">|</code><code class="n">center_ID</code><code class="p">))</code>
<code class="o">&gt;</code> <code class="nf">summary</code><code class="p">(</code><code class="n">hlm_mod</code><code class="p">)</code>
<code class="n">Linear</code> <code class="n">mixed</code> <code class="n">model</code> <code class="n">fit</code> <code class="n">by</code> <code class="n">REML.</code> <code class="n">t</code><code class="o">-</code><code class="n">tests</code> <code class="n">use</code> <code class="n">Satterthwaite</code><code class="s">'s method</code>
<code class="s">   ['</code><code class="n">lmerModLmerTest</code><code class="s">'</code><code class="err">]</code>
<code class="n">Formula</code><code class="o">:</code> <code class="n">call_CSAT</code> <code class="o">~</code> <code class="n">reason</code> <code class="o">+</code> <code class="n">age</code> <code class="o">+</code> <code class="p">(</code><code class="m">1</code> <code class="o">|</code> <code class="n">center_ID</code><code class="p">)</code>
   <code class="n">Data</code><code class="o">:</code> <code class="n">hist_data</code>

<code class="n">REML</code> <code class="n">criterion</code> <code class="n">at</code> <code class="n">convergence</code><code class="o">:</code> <code class="m">2052855</code>

<code class="n">Scaled</code> <code class="n">residuals</code><code class="o">:</code> 
    <code class="n">Min</code>      <code class="m">1</code><code class="n">Q</code>  <code class="n">Median</code>      <code class="m">3</code><code class="n">Q</code>     <code class="n">Max</code> 
<code class="m">-4.3238</code> <code class="m">-0.6627</code> <code class="m">-0.0272</code>  <code class="m">0.6351</code>  <code class="m">4.3114</code> 

<code class="n">Random</code> <code class="n">effects</code><code class="o">:</code>
 <code class="n">Groups</code>    <code class="n">Name</code>        <code class="n">Variance</code> <code class="n">Std.Dev.</code>
 <code class="nf">center_ID </code><code class="p">(</code><code class="n">Intercept</code><code class="p">)</code> <code class="m">1.406</code>    <code class="m">1.186</code>   
 <code class="n">Residual</code>              <code class="m">1.122</code>    <code class="m">1.059</code>   
<code class="n">Number</code> <code class="n">of</code> <code class="n">obs</code><code class="o">:</code> <code class="m">695205</code><code class="p">,</code> <code class="n">groups</code><code class="o">:</code>  <code class="n">center_ID</code><code class="p">,</code> <code class="m">10</code>

<code class="n">Fixed</code> <code class="n">effects</code><code class="o">:</code>
                   <code class="n">Estimate</code>     <code class="n">Std.</code> <code class="n">Error</code>       <code class="n">df</code>      <code class="n">t</code> <code class="n">value</code>   <code class="nf">Pr</code><code class="p">(</code><code class="o">&gt;|</code><code class="n">t</code><code class="o">|</code><code class="p">)</code>    
<code class="p">(</code><code class="n">Intercept</code><code class="p">)</code>       <code class="m">3.8990856</code>    <code class="m">0.3749857</code>      <code class="m">9.0938797</code>   <code class="m">10.40</code> <code class="m">0.00000238</code> <code class="o">***</code>
<code class="n">reasonproperty</code>    <code class="m">0.1994487</code>    <code class="m">0.0026669</code> <code class="m">695193.0006122</code>   <code class="m">74.79</code>    <code class="o">&lt;</code> <code class="m">2e-16</code> <code class="o">***</code>
<code class="n">age</code>               <code class="m">0.0200043</code>    <code class="m">0.0001132</code> <code class="m">695193.0008798</code>  <code class="m">176.75</code>    <code class="o">&lt;</code> <code class="m">2e-16</code> <code class="o">***</code>
<code class="o">---</code>
<code class="n">Signif.</code> <code class="n">codes</code><code class="o">:</code>  <code class="m">0</code> ‘<code class="o">***</code>’ <code class="m">0.001</code> ‘<code class="o">**</code>’ <code class="m">0.01</code> ‘<code class="o">*</code>’ <code class="m">0.05</code> ‘<code class="n">.’</code> <code class="m">0.1</code> ‘ ’ <code class="m">1</code>

<code class="n">Correlation</code> <code class="n">of</code> <code class="n">Fixed</code> <code class="n">Effects</code><code class="o">:</code>
            <code class="p">(</code><code class="n">Intr</code><code class="p">)</code> <code class="n">rsnprp</code>
<code class="n">reasnprprty</code>  <code class="m">0.000</code>       
<code class="n">age</code>         <code class="m">-0.011</code> <code class="m">-0.236</code></pre>
<p>The <code>lmer</code><code>()</code> function has a similar syntax to the traditional <code>lm</code><code>()</code> function, with one exception: <a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="about" data-tertiary="clustering variable" id="idm45968146908312"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="hierarchical linear modeling" data-tertiary="clustering variable" id="idm45968146737896"/>we need to enter the clustering variable, here <code>center_ID</code>, between parentheses and preceded by <code>1|</code>. This allows the intercept of our regression to vary from one call center to another. Therefore, we have one coefficient for each call center; you can think of these coefficients as similar to the coefficients we would get in a standard linear regression with a dummy for each call center.<sup><a data-type="noteref" id="ch01fn24-marker" href="ch10.xhtml#ch01fn24">3</a></sup></p>
<p>The “Random effects” section of the results refers to the clustering variable(s). The coefficients for each call center ID are not displayed in the summary results (they can be accessed with the command <code>coef(hlm_mod)</code>). Instead, we get measures of the variability of our data within call centers and between call centers, in the form of variance and standard deviation. Here, the standard deviation of our data between call centers is 1.185; in other words, if we were to calculate the mean CSAT for each call center and then calculate the standard deviation of the means, we would get the same value as you can check for yourself:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="o">&gt;</code> <code class="n">hist_data</code> <code class="o">%&gt;%</code>
    <code class="nf">group_by</code><code class="p">(</code><code class="n">center_ID</code><code class="p">)</code><code class="o">%&gt;%</code>
    <code class="nf">summarize</code><code class="p">(</code><code class="n">call_CSAT</code> <code class="o">=</code> <code class="nf">mean</code><code class="p">(</code><code class="n">call_CSAT</code><code class="p">))</code> <code class="o">%&gt;%</code>
    <code class="nf">summarize</code><code class="p">(</code><code class="n">sd</code> <code class="o">=</code> <code class="nf">sd</code><code class="p">(</code><code class="n">call_CSAT</code><code class="p">))</code>
<code class="nf">`summarise</code><code class="p">()</code><code class="n">` ungrouping output (override with `.groups`</code> <code class="n">argument</code><code class="p">)</code>
<code class="c1"># A tibble: 1 x 1</code>
     <code class="n">sd</code>
  <code class="o">&lt;</code><code class="n">dbl</code><code class="o">&gt;</code>
<code class="m">1</code>  <code class="m">1.18</code></pre>
<p>The standard deviation of the residuals, here 1.059, indicates how much variability there is left in our data after accounting for the effect of call centers. Comparing the two standard deviations, we can see that the call center effects represent more than half of the variability in our data.</p>
<p>The “Fixed effects” section of the results should look familiar: it indicates the coefficients for the call level variables. Here, we can see that customers calling for a “property” issue have on average a CSAT 0.199 higher than customers calling for a “payment” issue, and that each year of additional age for our customers adds on average 0.020 to the call CSAT.</p>
<p>Let’s then include the <code>r</code><code>ep_ID</code> variable as a clustering variable nested under the <span class="keep-together"><code>center_ID</code></span> variable:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="o">&gt;</code> <code class="n">hlm_mod2</code> <code class="o">&lt;-</code> <code class="nf">lmer</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">hist_data</code><code class="p">,</code> 
                   <code class="n">call_CSAT</code> <code class="o">~</code> <code class="n">reason</code> <code class="o">+</code> <code class="n">age</code> <code class="o">+</code> <code class="p">(</code><code class="m">1</code><code class="o">|</code><code class="n">center_ID</code><code class="o">/</code><code class="n">rep_ID</code><code class="p">),</code>
                   <code class="n">control</code> <code class="o">=</code> <code class="nf">lmerControl</code><code class="p">(</code><code class="n">optimizer</code> <code class="o">=</code><code class="s">"Nelder_Mead"</code><code class="p">))</code>
<code class="o">&gt;</code> <code class="nf">summary</code><code class="p">(</code><code class="n">hlm_mod2</code><code class="p">)</code>
<code class="n">Linear</code> <code class="n">mixed</code> <code class="n">model</code> <code class="n">fit</code> <code class="n">by</code> <code class="n">REML.</code> <code class="n">t</code><code class="o">-</code><code class="n">tests</code> <code class="n">use</code> <code class="n">Satterthwaite</code><code class="s">'s method</code>
<code class="s">   ['</code><code class="n">lmerModLmerTest</code><code class="s">'</code><code class="err">]</code>
<code class="n">Formula</code><code class="o">:</code> <code class="n">call_CSAT</code> <code class="o">~</code> <code class="n">reason</code> <code class="o">+</code> <code class="n">age</code> <code class="o">+</code> <code class="p">(</code><code class="m">1</code> <code class="o">|</code> <code class="n">center_ID</code><code class="o">/</code><code class="n">rep_ID</code><code class="p">)</code>
   <code class="n">Data</code><code class="o">:</code> <code class="n">hist_data</code>
<code class="n">Control</code><code class="o">:</code> <code class="nf">lmerControl</code><code class="p">(</code><code class="n">optimizer</code> <code class="o">=</code> <code class="s">"Nelder_Mead"</code><code class="p">)</code>

<code class="n">REML</code> <code class="n">criterion</code> <code class="n">at</code> <code class="n">convergence</code><code class="o">:</code> <code class="m">1320850</code>

<code class="n">Scaled</code> <code class="n">residuals</code><code class="o">:</code> 
    <code class="n">Min</code>      <code class="m">1</code><code class="n">Q</code>  <code class="n">Median</code>      <code class="m">3</code><code class="n">Q</code>     <code class="n">Max</code> 
<code class="m">-5.0373</code> <code class="m">-0.6712</code> <code class="m">-0.0003</code>  <code class="m">0.6708</code>  <code class="m">4.6878</code> 

<code class="n">Random</code> <code class="n">effects</code><code class="o">:</code>
 <code class="n">Groups</code>           <code class="n">Name</code>        <code class="n">Variance</code> <code class="n">Std.Dev.</code>
 <code class="n">rep_ID</code><code class="o">:</code><code class="nf">center_ID </code><code class="p">(</code><code class="n">Intercept</code><code class="p">)</code> <code class="m">0.7696</code>   <code class="m">0.8772</code>  
 <code class="nf">center_ID        </code><code class="p">(</code><code class="n">Intercept</code><code class="p">)</code> <code class="m">1.3582</code>   <code class="m">1.1654</code>  
 <code class="n">Residual</code>                     <code class="m">0.3904</code>   <code class="m">0.6249</code>  
<code class="n">Number</code> <code class="n">of</code> <code class="n">obs</code><code class="o">:</code> <code class="m">695205</code><code class="p">,</code> <code class="n">groups</code><code class="o">:</code>  <code class="n">rep_ID</code><code class="o">:</code><code class="n">center_ID</code><code class="p">,</code> <code class="m">193</code><code class="p">;</code> <code class="n">center_ID</code><code class="p">,</code> <code class="m">10</code>

<code class="n">Fixed</code> <code class="n">effects</code><code class="o">:</code>
                  <code class="n">Estimate</code>   <code class="n">Std.</code> <code class="n">Error</code>            <code class="n">df</code> <code class="n">t</code> <code class="n">value</code>   <code class="nf">Pr</code><code class="p">(</code><code class="o">&gt;|</code><code class="n">t</code><code class="o">|</code><code class="p">)</code>    
<code class="p">(</code><code class="n">Intercept</code><code class="p">)</code>     <code class="m">3.90099487</code>   <code class="m">0.37397956</code>      <code class="m">8.73974599</code>   <code class="m">10.43</code> <code class="m">0.00000316</code> <code class="o">***</code>
<code class="n">reasonproperty</code>  <code class="m">0.19952547</code>   <code class="m">0.00157368</code> <code class="m">695010.05594912</code>  <code class="m">126.79</code>    <code class="o">&lt;</code> <code class="m">2e-16</code> <code class="o">***</code>
<code class="n">age</code>             <code class="m">0.01992162</code>   <code class="m">0.00006678</code> <code class="m">695010.05053170</code>  <code class="m">298.30</code>    <code class="o">&lt;</code> <code class="m">2e-16</code> <code class="o">***</code>
<code class="o">---</code>
<code class="n">Signif.</code> <code class="n">codes</code><code class="o">:</code>  <code class="m">0</code> ‘<code class="o">***</code>’ <code class="m">0.001</code> ‘<code class="o">**</code>’ <code class="m">0.01</code> ‘<code class="o">*</code>’ <code class="m">0.05</code> ‘<code class="n">.’</code> <code class="m">0.1</code> ‘ ’ <code class="m">1</code>

<code class="n">Correlation</code> <code class="n">of</code> <code class="n">Fixed</code> <code class="n">Effects</code><code class="o">:</code>
            <code class="p">(</code><code class="n">Intr</code><code class="p">)</code> <code class="n">rsnprp</code>
<code class="n">reasnprprty</code>  <code class="m">0.000</code>       
<code class="n">age</code>         <code class="m">-0.007</code> <code class="m">-0.236</code></pre>
<p>As you can see, this is done by adding <code>rep_ID</code> as a clustering variable after <code>center_ID</code>, separating them with <code>/</code>. Also note that I was getting a warning that the model had failed to converge, so I changed the optimizer algorithm to "<code>Nelder_Mead"</code>.<sup><a data-type="noteref" id="ch01fn25-marker" href="ch10.xhtml#ch01fn25">4</a></sup> The coefficients for the fixed effects are slightly different, but not that much.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmR" id="idm45968146606312"/></p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Python Code"><div class="sect2" id="python_cod">
<h2>Python Code</h2>
<p>Though it’s more concise, Python code works<a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="about" data-tertiary="Python code" id="idm45968146303480"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="hierarchical linear modeling" data-tertiary="about syntax" id="idm45968146301864"/> similarly. The main difference is that the groups are expressed with  <code>groups = hist_data_df["center_ID"]</code>:</p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python </code>
<code class="n">mixed</code> <code class="o">=</code> <code class="n">smf</code><code class="o">.</code><code class="n">mixedlm</code><code class="p">(</code><code class="s2">"call_CSAT ~ reason + age"</code><code class="p">,</code> <code class="n">data</code> <code class="o">=</code> <code class="n">hist_data_df</code><code class="p">,</code> 
                   <code class="n">groups</code> <code class="o">=</code> <code class="n">hist_data_df</code><code class="p">[</code><code class="s2">"center_ID"</code><code class="p">])</code>
<code class="k">print</code><code class="p">(</code><code class="n">mixed</code><code class="o">.</code><code class="n">fit</code><code class="p">()</code><code class="o">.</code><code class="n">summary</code><code class="p">())</code>
            <code class="n">Mixed</code> <code class="n">Linear</code> <code class="n">Model</code> <code class="n">Regression</code> <code class="n">Results</code>
<code class="o">=============================================================</code>
<code class="n">Model</code><code class="p">:</code>              <code class="n">MixedLM</code> <code class="n">Dependent</code> <code class="n">Variable</code><code class="p">:</code> <code class="n">call_CSAT</code>    
<code class="n">No</code><code class="o">.</code> <code class="n">Observations</code><code class="p">:</code>   <code class="mi">695205</code>  <code class="n">Method</code><code class="p">:</code>             <code class="n">REML</code>         
<code class="n">No</code><code class="o">.</code> <code class="n">Groups</code><code class="p">:</code>         <code class="mi">10</code>      <code class="n">Scale</code><code class="p">:</code>              <code class="mf">1.1217</code>       
<code class="n">Min</code><code class="o">.</code> <code class="n">group</code> <code class="n">size</code><code class="p">:</code>    <code class="mi">54203</code>   <code class="n">Log</code><code class="o">-</code><code class="n">Likelihood</code><code class="p">:</code>     <code class="o">-</code><code class="mf">1026427.7247</code>
<code class="n">Max</code><code class="o">.</code> <code class="n">group</code> <code class="n">size</code><code class="p">:</code>    <code class="mi">79250</code>   <code class="n">Converged</code><code class="p">:</code>          <code class="n">Yes</code>          
<code class="n">Mean</code> <code class="n">group</code> <code class="n">size</code><code class="p">:</code>    <code class="mf">69520.5</code>                                  
<code class="o">-------------------------------------------------------------</code>
                   <code class="n">Coef</code><code class="o">.</code> <code class="n">Std</code><code class="o">.</code><code class="n">Err</code><code class="o">.</code>    <code class="n">z</code>    <code class="n">P</code><code class="o">&gt;|</code><code class="n">z</code><code class="o">|</code> <code class="p">[</code><code class="mf">0.025</code> <code class="mf">0.975</code><code class="p">]</code>
<code class="o">-------------------------------------------------------------</code>
<code class="n">Intercept</code>          <code class="mf">3.899</code>    <code class="mf">0.335</code>  <code class="mf">11.641</code> <code class="mf">0.000</code>  <code class="mf">3.243</code>  <code class="mf">4.556</code>
<code class="n">reason</code><code class="p">[</code><code class="n">T</code><code class="o">.</code><code class="n">property</code><code class="p">]</code> <code class="mf">0.199</code>    <code class="mf">0.003</code>  <code class="mf">74.786</code> <code class="mf">0.000</code>  <code class="mf">0.194</code>  <code class="mf">0.205</code>
<code class="n">age</code>                <code class="mf">0.020</code>    <code class="mf">0.000</code> <code class="mf">176.747</code> <code class="mf">0.000</code>  <code class="mf">0.020</code>  <code class="mf">0.020</code>
<code class="n">Group</code> <code class="n">Var</code>          <code class="mf">1.122</code>    <code class="mf">0.407</code>                            
<code class="o">=============================================================</code></pre>
<p>The coefficients for the fixed effects (i.e., the intercept, the reason for the call and age) are identical to the R code. The coefficient for the variance of the random effect is expressed at the bottom of the fixed effects. At 1.122, it’s slightly different from the R value, due to differences in algorithms, but it won’t affect the coefficients we care about.</p>
<p>Using nested clustering variables also has a different syntax in Python. We need to express the lower-level, nested, variable in a separate formula (the “variance components formula,” which I abbreviated as <code>vcf</code>):</p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python</code>
<code class="n">vcf</code> <code class="o">=</code> <code class="p">{</code><code class="s2">"rep_ID"</code><code class="p">:</code> <code class="s2">"0+C(rep_ID)"</code><code class="p">}</code>
<code class="n">mixed2</code> <code class="o">=</code> <code class="n">smf</code><code class="o">.</code><code class="n">mixedlm</code><code class="p">(</code><code class="s2">"call_CSAT ~ reason + age"</code><code class="p">,</code> 
                   <code class="n">data</code> <code class="o">=</code> <code class="n">hist_data_df</code><code class="p">,</code> 
                   <code class="n">groups</code> <code class="o">=</code> <code class="n">hist_data_df</code><code class="p">[</code><code class="s2">"center_ID"</code><code class="p">],</code>
                   <code class="n">vc_formula</code><code class="o">=</code><code class="n">vcf</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">mixed2</code><code class="o">.</code><code class="n">fit</code><code class="p">()</code><code class="o">.</code><code class="n">summary</code><code class="p">())</code>
            <code class="n">Mixed</code> <code class="n">Linear</code> <code class="n">Model</code> <code class="n">Regression</code> <code class="n">Results</code>
<code class="o">=============================================================</code>
<code class="n">Model</code><code class="p">:</code>             <code class="n">MixedLM</code>  <code class="n">Dependent</code> <code class="n">Variable</code><code class="p">:</code>  <code class="n">call_CSAT</code>   
<code class="n">No</code><code class="o">.</code> <code class="n">Observations</code><code class="p">:</code>  <code class="mi">695205</code>   <code class="n">Method</code><code class="p">:</code>              <code class="n">REML</code>        
<code class="n">No</code><code class="o">.</code> <code class="n">Groups</code><code class="p">:</code>        <code class="mi">10</code>       <code class="n">Scale</code><code class="p">:</code>               <code class="mf">0.3904</code>      
<code class="n">Min</code><code class="o">.</code> <code class="n">group</code> <code class="n">size</code><code class="p">:</code>   <code class="mi">54203</code>    <code class="n">Log</code><code class="o">-</code><code class="n">Likelihood</code><code class="p">:</code>      <code class="o">-</code><code class="mf">660498.6462</code>
<code class="n">Max</code><code class="o">.</code> <code class="n">group</code> <code class="n">size</code><code class="p">:</code>   <code class="mi">79250</code>    <code class="n">Converged</code><code class="p">:</code>           <code class="n">Yes</code>         
<code class="n">Mean</code> <code class="n">group</code> <code class="n">size</code><code class="p">:</code>   <code class="mf">69520.5</code>                                   
<code class="o">-------------------------------------------------------------</code>
                   <code class="n">Coef</code><code class="o">.</code> <code class="n">Std</code><code class="o">.</code><code class="n">Err</code><code class="o">.</code>    <code class="n">z</code>    <code class="n">P</code><code class="o">&gt;|</code><code class="n">z</code><code class="o">|</code> <code class="p">[</code><code class="mf">0.025</code> <code class="mf">0.975</code><code class="p">]</code>
<code class="o">-------------------------------------------------------------</code>
<code class="n">Intercept</code>          <code class="mf">3.874</code>    <code class="mf">0.099</code>  <code class="mf">38.992</code> <code class="mf">0.000</code>  <code class="mf">3.679</code>  <code class="mf">4.069</code>
<code class="n">reason</code><code class="p">[</code><code class="n">T</code><code class="o">.</code><code class="n">property</code><code class="p">]</code> <code class="mf">0.200</code>    <code class="mf">0.002</code> <code class="mf">126.789</code> <code class="mf">0.000</code>  <code class="mf">0.196</code>  <code class="mf">0.203</code>
<code class="n">age</code>                <code class="mf">0.020</code>    <code class="mf">0.000</code> <code class="mf">298.301</code> <code class="mf">0.000</code>  <code class="mf">0.020</code>  <code class="mf">0.020</code>
<code class="n">rep_ID</code> <code class="n">Var</code>         <code class="mf">1.904</code>    <code class="mf">0.303</code>                            
<code class="o">=============================================================</code></pre>
<p>The syntax for the variance components formula is a bit esoteric but the intuition is straightforward. The formula itself is a dictionary with each of the nested variables as key. The value attached to each key indicates whether we want that variable to have a random intercept or a random slope (random here means “varying by category”). A random intercept is the HM equivalent of a <em>categorical</em> variable and is expressed as <code>"0+C(var)"</code>, where <code>var</code> is the name of the nested variable, i.e., the same as the key. Random slopes are beyond the scope of this book, but for example if you wanted the relationship between age and call satisfaction to have a different slope for each rep, the variance component formula would be <code>vcf = {"rep_ID": "0+C(rep_ID)", "age":"0+age"}</code>, without a <code>C()</code> in the second case.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmabt" id="idm45968145887352"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmabt2" id="idm45968145885944"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmabt3" id="idm45968145884568"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmabt4" id="idm45968145883192"/></p>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Determining Random Assignment and Sample Size/Power"><div class="sect1" id="determining_random_assignment_and_sam">
<h1>Determining Random Assignment and Sample Size/Power</h1>
<p>Now that we have planned the qualitative aspects of our experiment, <a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="stratified randomization" data-tertiary="hierarchical linear modeling" id="ch10-hlmsr4"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="hierarchical linear modeling" data-tertiary="stratified randomization" id="ch10-hlmsr5"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="hierarchical linear modeling" data-tertiary="random assignment" id="ch10-hlmsr"/><a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="random assignment" id="ch10-hlmsr2"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="hierarchical linear modeling" id="ch10-hlmsr3"/>we need to determine the random assignment we’ll use as well as our sample size and power. In our two previous experiments (<a data-type="xref" href="ch08.xhtml#experimental_design_the_basics">Chapter 8</a> and <a data-type="xref" href="ch09.xhtml#stratified_randomizatio">Chapter 9</a>), we had some target effect size and statistical power, and we chose our sample size accordingly. Here, we’ll add a wrinkle by assuming that our business partners are willing to run the experiment only for a month,<sup><a data-type="noteref" id="ch01fn26-marker" href="ch10.xhtml#ch01fn26">5</a></sup> and the minimum detectable effect they’re interested in capturing is 0.6 (i.e., they want to make sure that you have sufficient power to capture an effect of that size, but they’re willing to take the risk that the effect size will be lower).</p>
<p>Under these constraints, the question becomes: how much power do we have to capture a difference of that amount with that sample? In other words, assuming that the difference is indeed equal to 0.6, what is the probability that our decision rule will conclude that the treatment is indeed better than the control?</p>
<p>As mentioned earlier, we’ll be using a hierarchical regression to analyze our data and that will complicate our power analysis a bit, but let’s first briefly review the process for random assignment.</p>
<section data-type="sect2" data-pdf-bookmark="Random Assignment"><div class="sect2" id="random_assignme">
<h2>Random Assignment</h2>
<p>Even though we don’t know ahead of time which customers are going to call, it doesn’t matter for the random assignment because we’ll do it at the call center level. Therefore, we can do it in advance, assigning control and treatment groups all at once. With clustered experiments like this one, stratification is especially useful because we have so few actual units to randomize. Here, we’re randomizing at the level of call centers, so we would want to stratify based on the centers’ characteristics, such as number of reps and average values of the call metrics. The code to do so is a straightforward version of the code in <a data-type="xref" href="ch09.xhtml#stratified_randomizatio">Chapter 9</a>, split between a data prep function and a wrapper for the blocking function (<a data-type="xref" href="#stratified_random_assignment_of_call_centers">Example 10-1</a>).</p>

<div data-type="example" id="stratified_random_assignment_of_call_centers">
<h5><span class="label">Example 10-1. </span>Stratified random assignment of call centers</h5>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code><code>

</code><code class="c1"># Function to prep the data</code><code>
</code><code class="n">strat_prep_fun</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">)</code><code class="p">{</code><code>
  </code><code class="c1"># Extracting property-level variables</code><code>
  </code><code class="n">dat</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">dat</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="nf">group_by</code><code class="p">(</code><code class="n">center_ID</code><code class="p">)</code><code> </code><code class="o">%&gt;%</code><code>   </code><a class="co" id="comarker101" href="#c011"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>                                  
    </code><code class="nf">summarise</code><code class="p">(</code><code class="n">nreps</code><code> </code><code class="o">=</code><code> </code><code class="nf">n_distinct</code><code class="p">(</code><code class="n">rep_ID</code><code class="p">)</code><code class="p">,</code><code>
              </code><code class="n">avg_call_CSAT</code><code> </code><code class="o">=</code><code> </code><code class="nf">mean</code><code class="p">(</code><code class="n">call_CSAT</code><code class="p">)</code><code class="p">,</code><code> 
              </code><code class="n">avg_age</code><code> </code><code class="o">=</code><code> </code><code class="nf">mean</code><code class="p">(</code><code class="n">age</code><code class="p">)</code><code class="p">,</code><code>
              </code><code class="n">pct_reason_pmt</code><code> </code><code class="o">=</code><code> </code><code class="nf">sum</code><code class="p">(</code><code class="n">reason</code><code> </code><code class="o">==</code><code> </code><code class="s">'</code><code class="s">payment'</code><code class="p">)</code><code class="o">/</code><code class="nf">n</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="nf">ungroup</code><code class="p">(</code><code class="p">)</code><code>
  
  </code><code class="c1">#Isolating the different components of our data</code><code>
  </code><code class="n">center_ID</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">dat</code><code class="o">$</code><code class="n">center_ID</code><code>  </code><code class="c1"># Center identifier</code><code>
  </code><code class="n">dat</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">dat</code><code> </code><code class="o">%&gt;%</code><code> </code><code class="nf">select</code><code class="p">(</code><code class="o">-</code><code class="n">center_ID</code><code class="p">)</code><code>
  </code><code class="n">num_vars</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">dat</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="c1">#Selecting numeric variables</code><code>
    </code><code class="nf">select_if</code><code class="p">(</code><code class="nf">function</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code> </code><code class="nf">is.numeric</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code class="o">|</code><code class="nf">is.integer</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code class="p">)</code><code> 
  
  </code><code class="c1">#Normalizing numeric variables </code><a class="co" id="comarker102" href="#c021"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code class="c1">                                  </code><code>
  </code><code class="n">num_vars_out</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">num_vars</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="nf">mutate_all</code><code class="p">(</code><code class="n">rescale</code><code class="p">)</code><code>
  
  </code><code class="c1">#Putting the variables back together</code><code>
  </code><code class="n">dat_out</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">cbind</code><code class="p">(</code><code class="n">center_ID</code><code class="p">,</code><code> </code><code class="n">num_vars_out</code><code class="p">)</code><code>  </code><code class="o">%&gt;%</code><code>
    </code><code class="nf">mutate</code><code class="p">(</code><code class="n">center_ID</code><code> </code><code class="o">=</code><code> </code><code class="nf">as.character</code><code class="p">(</code><code class="n">center_ID</code><code class="p">)</code><code class="p">)</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="nf">mutate_if</code><code class="p">(</code><code class="n">is.numeric</code><code class="p">,</code><code> </code><code class="nf">function</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code> </code><code class="nf">round</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code> </code><code class="m">4</code><code class="p">)</code><code class="p">)</code><code> </code><code class="c1">#Rounding for readability</code><code>
  </code><code class="nf">return</code><code class="p">(</code><code class="n">dat_out</code><code class="p">)</code><code class="p">}</code><code>

</code><code class="n">block_wrapper_fun</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">)</code><code class="p">{</code><code>
  
  </code><code class="n">prepped_data</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">strat_prep_fun</code><code class="p">(</code><code class="n">dat</code><code class="p">)</code><code>
  
  </code><code class="c1">#Getting stratified assignment</code><code>
  </code><code class="n">assgt</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">prepped_data</code><code> </code><code class="o">%&gt;%</code><code> </code><a class="co" id="comarker103" href="#c031"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>                                  
    </code><code class="nf">block</code><code class="p">(</code><code class="n">id.vars</code><code> </code><code class="o">=</code><code> </code><code class="nf">c</code><code class="p">(</code><code class="s">"</code><code class="s">center_ID"</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">n.tr</code><code> </code><code class="o">=</code><code> </code><code class="m">2</code><code class="p">,</code><code> 
          </code><code class="n">algorithm</code><code> </code><code class="o">=</code><code> </code><code class="s">"</code><code class="s">optimal"</code><code class="p">,</code><code> </code><code class="n">distance</code><code> </code><code class="o">=</code><code> </code><code class="s">"</code><code class="s">euclidean"</code><code class="p">)</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="nf">assignment</code><code class="p">(</code><code class="p">)</code><code> 
  </code><code class="n">assgt</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">assgt</code><code class="o">$</code><code class="n">assg</code><code class="o">$</code><code class="n">`1`</code><code> 
  </code><code class="n">assgt</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">assgt</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="nf">select</code><code class="p">(</code><code class="o">-</code><code class="s">'</code><code class="s">Distance'</code><code class="p">)</code><code>
  
  </code><code class="n">assgt</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">as.matrix</code><code class="p">(</code><code class="n">assgt</code><code class="p">)</code><code> </code><code class="o">%&gt;%</code><code> </code><code class="nf">apply</code><code class="p">(</code><code class="m">2</code><code class="p">,</code><code> </code><code class="nf">function</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code> </code><code class="nf">as.integer</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code class="p">)</code><code>
  </code><code class="nf">return</code><code class="p">(</code><code class="n">assgt</code><code class="p">)</code><code class="p">}</code><code> </code><a class="co" id="comarker104" href="#c041"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code> </code></pre>                                    
<dl class="calloutlist">
 <dt><a class="co" id="c011" href="#comarker101"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>We group by <code>center_ID</code> and summarize our clustering variable: we take the number of reps by center, calculate the average call CSAT and customer age, and determine the percentage of calls whose reason is '<code>payment'</code>.</p></dd> 
 <dt><a class="co" id="c021" href="#comarker102"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
  <dd><p>We rescale all clustering variables to between 0 and 1.</p></dd> 
   <dt><a class="co" id="c031" href="#comarker103"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
  <dd><p>We use the <code>block()</code> function from<a contenteditable="false" data-type="indexterm" data-primary="block() function" id="idm45968145437096"/><a contenteditable="false" data-type="indexterm" data-primary="optimal algorithm for stratified randomization" id="idm45968145533832"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="optimal algorithm" id="idm45968145532760"/> <code>blockTools</code>, using the '<code>optimal'</code> algorithm from the <code>nbpMatching</code> package (we can afford the extra computation with so few call centers).</p></dd> 
   <dt><a class="co" id="c041" href="#comarker104"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
  <dd><p>We extract the pairing from the output of <code>block()</code>.</p></dd>
</dl>
<p>The resulting pairing is:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
     <code class="n">Treatment</code> <code class="m">1</code> <code class="n">Treatment</code> <code class="m">2</code>
<code class="p">[</code><code class="m">1</code><code class="p">,]</code>           <code class="m">2</code>           <code class="m">3</code>
<code class="p">[</code><code class="m">2</code><code class="p">,]</code>           <code class="m">8</code>           <code class="m">9</code>
<code class="p">[</code><code class="m">3</code><code class="p">,]</code>           <code class="m">7</code>           <code class="m">6</code>
<code class="p">[</code><code class="m">4</code><code class="p">,]</code>           <code class="m">1</code>           <code class="m">5</code>
<code class="p">[</code><code class="m">5</code><code class="p">,]</code>          <code class="m">10</code>           <code class="m">4</code></pre>
</div>
<p>As mentioned in the previous chapter, there’s no equivalent to the <code>block</code> package in Python, so we’ll use the two functions for that purpose I have described in the previous chapter, with minor adjustments (e.g., we don’t have categorical variables at the center level, so we don’t need to one-hot encode them):<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmsr" id="idm45968145371208"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmsr2" id="idm45968145369960"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmsr3" id="idm45968145600200"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmsr4" id="idm45968145598824"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmsr5" id="idm45968145597448"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="stratified randomization" data-tertiary="hierarchical linear modeling" id="idm45968145596072"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="hierarchical linear modeling" data-tertiary="stratified randomization" id="idm45968145594488"/></p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python</code>
<code class="k">def</code> <code class="nf">strat_prep_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">):</code>
  <code class="o">...</code>

<code class="k">def</code> <code class="nf">stratified_assgnt_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">,</code> <code class="n">K</code> <code class="o">=</code> <code class="mi">2</code><code class="p">):</code>
  <code class="o">...</code>
  
<code class="n">stratified_assgnt_df</code> <code class="o">=</code> <code class="n">stratified_assgnt_fun</code><code class="p">(</code><code class="n">hist_data_df</code><code class="p">,</code> <code class="n">K</code><code class="o">=</code><code class="mi">2</code><code class="p">)</code></pre>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Power Analysis"><div class="sect2" id="power_analysis">
<h2>Power Analysis</h2>
<p>Using a standard statistical formula for power analysis<a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="hierarchical linear modeling" data-tertiary="power analysis" id="ch10-hlmpo"/><a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="power analysis" id="ch10-hlmpo2"/><a contenteditable="false" data-type="indexterm" data-primary="power analysis" data-secondary="hierarchical linear modeling" id="ch10-hlmpo3"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="call center problem-solving mode" data-tertiary="power analysis" id="ch10-hlmpo4"/> (in this case it would be the formula for the T-test) would be highly misleading because it would not take into account the correlation that exists in the data. Gelman and Hill (2006) provide some specific statistical formulas for hierarchical models, but I don’t want to go down the rabbit hole of accumulating increasingly complex and narrow formulas. As usual, we’ll be running simulations as our foolproof approach to power analysis.</p>
<p>Let’s first define our metric function:<a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="hierarchical linear modeling" data-tertiary="power analysis" id="idm45968145321192"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="hierarchical linear modeling" data-tertiary="power analysis" id="idm45968145319528"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">hlm_metric_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">){</code>
  <code class="c1">#Estimating treatment coefficient with hierarchical regression</code>
  <code class="n">hlm_mod</code> <code class="o">&lt;-</code> <code class="nf">lmer</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">dat</code><code class="p">,</code> 
                  <code class="n">call_CSAT</code> <code class="o">~</code> <code class="n">reason</code> <code class="o">+</code> <code class="n">age</code> <code class="o">+</code> <code class="n">group</code> <code class="o">+</code> <code class="p">(</code><code class="m">1</code><code class="o">|</code><code class="n">center_ID</code><code class="o">/</code><code class="n">rep_ID</code><code class="p">)</code>
                  <code class="p">,</code><code class="n">control</code> <code class="o">=</code> <code class="nf">lmerControl</code><code class="p">(</code><code class="n">optimizer</code> <code class="o">=</code><code class="s">"Nelder_Mead"</code><code class="p">)</code>
                  <code class="p">)</code>
  <code class="n">metric</code> <code class="o">&lt;-</code> <code class="nf">fixef</code><code class="p">(</code><code class="n">hlm_mod</code><code class="p">)[</code><code class="s">"grouptreat"</code><code class="p">]</code>
  <code class="nf">return</code><code class="p">(</code><code class="n">metric</code><code class="p">)}</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
<code class="k">def</code> <code class="nf">hlm_metric_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">):</code>
    <code class="n">vcf</code> <code class="o">=</code> <code class="p">{</code><code class="s2">"rep_ID"</code><code class="p">:</code> <code class="s2">"0+C(rep_ID)"</code><code class="p">}</code>
    <code class="n">h_mod</code> <code class="o">=</code> <code class="n">smf</code><code class="o">.</code><code class="n">mixedlm</code><code class="p">(</code><code class="s2">"call_CSAT ~ reason + age + group"</code><code class="p">,</code> 
                    <code class="n">data</code> <code class="o">=</code> <code class="n">dat_df</code><code class="p">,</code> 
                    <code class="n">groups</code> <code class="o">=</code> <code class="n">dat_df</code><code class="p">[</code><code class="s2">"center_ID"</code><code class="p">],</code>
                    <code class="n">re_formula</code><code class="o">=</code><code class="s1">'1'</code><code class="p">,</code>
                    <code class="n">vc_formula</code><code class="o">=</code><code class="n">vcf</code><code class="p">)</code>
    <code class="n">coeff</code> <code class="o">=</code> <code class="n">h_mod</code><code class="o">.</code><code class="n">fit</code><code class="p">()</code><code class="o">.</code><code class="n">fe_params</code><code class="o">.</code><code class="n">values</code><code class="p">[</code><code class="mi">2</code><code class="p">]</code>
    <code class="k">return</code> <code class="n">coeff</code></pre>
<p>This function returns the coefficient for the treatment group from our hierarchical model. As we did in the previous chapters, let’s now run the simulations for our power analysis, which you should hopefully be familiar with by now. <a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="power analysis" data-tertiary="clustered data" id="ch10-clus"/>The only additional thing we need to take into account here is that our data is stratified, a.k.a. clustered. This has two implications.</p>
<p>First, we can’t just draw calls from historical data at random. In our experiment, we expect reps to have almost exactly the same number of calls each; on the other hand, a truly random draw would generate some significant variation in the number of calls per rep. We expect reps to handle around 1,200 calls a month; having one rep handle 1,000 calls and another handle 1,400 is much more likely with a truly random draw than in reality. Fortunately, from a programming standpoint, this can easily be resolved by grouping our historical data at the call center and rep level before making a random draw:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">sample_data</code> <code class="o">%&lt;%-</code> <code class="nf">filter</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">month</code><code class="o">==</code><code class="n">m</code><code class="p">)</code> <code class="o">%&gt;%</code><code class="n">dplyr</code><code class="o">::</code><code class="nf">group_by</code><code class="p">(</code><code class="n">rep_ID</code><code class="p">)</code> <code class="o">%&gt;%</code>
      <code class="nf">slice_sample</code><code class="p">(</code><code class="n">n</code> <code class="o">=</code> <code class="n">Nexp</code><code class="p">)</code> <code class="o">%&gt;%</code> <code class="n">dplyr</code><code class="o">::</code><code class="nf">ungroup</code><code class="p">()</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
<code class="n">sample_data_df</code> <code class="o">=</code> <code class="n">sample_data_df</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s1">'rep_ID'</code><code class="p">)</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">n</code><code class="o">=</code><code class="n">Ncalls_rep</code><code class="p">)</code>\
            <code class="o">.</code><code class="n">reset_index</code><code class="p">(</code><code class="n">drop</code> <code class="o">=</code> <code class="bp">True</code><code class="p">)</code></pre>
<section data-type="sect3" data-pdf-bookmark="Using permutations when randomness is “limited”"><div class="sect3" id="using_permutations_when_randomness_is_q">
<h3>Using permutations when randomness is “limited”</h3>
<p>The second implication is at the statistical level and is more profound. <a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="power analysis" data-tertiary="permutations for limited randomness" id="ch10-perm"/>We’re using stratification to pair similar call centers and assign one from each pair to the control group and the other to the treatment group. This is good, because we reduce the risk that some call center characteristics will bias our analysis. But at the same time, this introduces a fixed effect in our simulations: let’s say that call centers 1 and 5 are paired together because they’re very similar. Then, however many simulations we run, one of them will be in the control group and the other one will be in the treatment group; we’ve reduced the total number of possible combinations. <a contenteditable="false" data-type="indexterm" data-primary="factorials" id="idm45968145142728"/><a contenteditable="false" data-type="indexterm" data-primary="combinations via factorials" id="idm45968145141624"/>With a completely free randomization, there are 10!/(5! * 5!) ≈ 252 different assignments of 10 call centers in equally sized experimental groups, which is already not that many.<sup><a data-type="noteref" id="ch01fn27-marker" href="ch10.xhtml#ch01fn27">6</a></sup> With stratification, there are only 2^5 ≈ 32 different assignments, because there are two possible assignments for each of the five pairs: (control, treatment) and (treatment, control). This means that even if you were to run 32,000 simulations, you would only see 32 different random allocations at the call center level. Moreover, with only three months worth of historical data, we can only generate three completely different (i.e., mutually exclusive) samples per rep, for a total of 32 * 3 = 96 different simulations.</p>
<p>This doesn’t mean that we should not use stratification; on the contrary, stratification is even more crucial the smaller our experimental population gets! This does imply however that it is pretty much pointless and potentially misleading to run many more simulations than you have truly different assignments.</p>
<p>To understand why, let’s use a metaphor: imagine a student who decides to increase their vocabulary ahead of a test (e.g., the LSAT). They buy a learner’s dictionary and plan to read the definition of a random word in it ten times a day until they’ve done it a thousand times, to learn a thousand words. But here’s the catch: their dictionary has only 96 words in it! This means that however many times the student looks up a random word, their vocabulary cannot increase by more than 96 words. There’s certainly value in reading a word’s definition more than once, to better understand and memorize it, but that’s different from reading the definition of more words. This also means that looking at definitions at random is a very inefficient way to proceed. It is much better to simply go through the 96 words in order.</p>
<p>That logic applies in the same way to simulations: we usually draw at random from our historical data to build a simulated experimental data set, and we (correctly) treat as negligible the probability of several simulations being identical. In the present case, if we had a hundred call centers, each with a thousand reps and ten years of data, we could confidently simulate hundreds, or even thousands, of experiments without worrying. With our limited number of call centers and reps, we’re better off going systematically through the limited number of possibilities.</p>
<p>Let’s see how to do this in code. We have the call-center pairings (see <a data-type="xref" href="#ninezeropercent_confidence_intervals_wi">Figure 10-2</a> in the previous subsection) and we need to go through the 32 possible permutations of those pairs. The first pair is made up of call centers #7 and #2, so half of the simulations will have #7 in control group and #2 in treatment group, while the other half will have #2 in control group and #7 in the treatment group, and so on. So the first simulation might have as control group the call centers (7, 9, 3, 10, 4) while the second simulation has as control group (2, 9, 3, 10, 4).</p>
<p>We’ll use a trick to help us go through the permutations easily. It is not really complex, but it relies on properties of binary numbers that are not intuitive, so brace yourself and bear with me. Any integer can be expressed in binary base as a sequence of zeros and ones. 0 is 0, 1 is 1, 2 is 10, 3 is 11, and so on. These can be left-padded with zeros to have a constant number of digits. We want the number of digits to be equal to the number of pairs, here 5. This means that 0 is 00000, 1 is 00001, 2 is 00010, and 3 is 00011. The largest integer we can express with 5 digits is 31. Note that, and this is not a coincidence, including 0 as 00000, we can express 32 different integers with 5 binary digits, and that 32 is the number of permutations we want to implement. Therefore, we can decide that the first simulation, which we’ll call “simulation 00000,” has as control group (7, 9, 3, 10, 4) from <a data-type="xref" href="#ninezeropercent_confidence_intervals_wi">Figure 10-2</a>. From there, we’ll swap a pair between the control and the treatment groups whenever the digit corresponding to the pair in the binary form of the simulation number is a 1. So for example, for simulation 10000, we would swap call centers #7 and #2, giving us the control group (2, 9, 3, 10, 4). Here’s where the magic happens: by going from 00000 to 11111, we’ll see all the possible permutations of the 5 pairs!</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Code for permutations"><div class="sect3" id="code_for_permutations">
<h3>Code for permutations</h3>
<p>Because of the differences in indexing between Python and R (the former starting at 0 and the latter at 1), <a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="hierarchical linear modeling" data-tertiary="permutations" id="idm45968145050264"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="hierarchical linear modeling" data-tertiary="permutations" id="idm45968145048648"/>the code is a bit simpler in Python, so let’s start with the corresponding snippet of code:</p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python</code><code>
</code><code class="k">for</code><code> </code><code class="n">perm</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="n">Nperm</code><code class="p">)</code><code class="p">:</code><code>
</code><code>    </code><code class="n">bin_str</code><code> </code><code class="o">=</code><code> </code><code class="n">f</code><code class="s1">'</code><code class="s1">{perm:0{Npairs}b}</code><code class="s1">'</code><code>   </code><a class="co" id="comarker1001" href="#c012"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>         </code><code>
</code><code>    </code><code class="n">idx</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="p">[</code><code class="n">i</code><code> </code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="n">Npairs</code><code class="p">)</code><code class="p">]</code><code class="p">,</code><code> </code><a class="co" id="comarker1002" href="#c022"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>                    </code><code>
</code><code>                    </code><code class="p">[</code><code class="nb">int</code><code class="p">(</code><code class="n">d</code><code class="p">)</code><code> </code><code class="k">for</code><code> </code><code class="n">d</code><code> </code><code class="ow">in</code><code> </code><code class="n">bin_str</code><code class="p">]</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">T</code><code>
</code><code>    </code><code class="n">treat</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">stratified_pairs</code><code class="p">[</code><code class="nb">tuple</code><code class="p">(</code><code class="n">idx</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code class="p">)</code><code class="p">]</code><code> </code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="n">Npairs</code><code class="p">)</code><code class="p">]</code><code> </code><a class="co" id="comarker1003" href="#c032"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>    </code><code>
</code><code>    </code><code class="n">sim_data_df</code><code> </code><code class="o">=</code><code> </code><code class="n">sample_data_df</code><code class="o">.</code><code class="n">copy</code><code class="p">(</code><code class="p">)</code><code>
</code><code>    </code><code class="n">sim_data_df</code><code class="p">[</code><code class="s1">'</code><code class="s1">group</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">ctrl</code><code class="s1">'</code><code> </code><a class="co" id="comarker1004" href="#c042"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>   </code><code>
</code><code>    </code><code class="n">sim_data_df</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="p">(</code><code class="n">sim_data_df</code><code class="o">.</code><code class="n">center_ID</code><code class="o">.</code><code class="n">isin</code><code class="p">(</code><code class="n">treat</code><code class="p">)</code><code class="p">)</code><code class="p">,</code><code class="s1">'</code><code class="s1">group</code><code class="s1">'</code><code class="p">]</code><code>\
</code><code>        </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">treat</code><code class="s1">'</code></pre>
<dl class="calloutlist">
 <dt><a class="co" id="c012" href="#comarker1001"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
  <dd><p>We convert the permutation counter <code>perm</code> to a binary string. In Python, there are several ways to do it. I did it here with an F-string. The syntax of an F-string is <code>f'{exp}'</code>, where the expression <code>exp</code> is evaluated before getting formatted as a string. Within the expression, <code>Npairs</code> is also between curly braces, so it’s evaluated first before being passed to the expression; after that first evaluation, <code>exp</code> is equal to <code>perm:05b</code>. The first term on the left of the colon is the number to format; the letter after the colon indicates the format to use, here <code>b</code> for binary; the number immediately to the left of the letter indicates the total number of digits to use (here 5); and finally, any character to the left of that number is to be used for padding (here 0).</p></dd> 
 <dt><a class="co" id="c022" href="#comarker1002"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
  <dd><p>We match the digits of the binary string with a counter for the pairs within the <code>idx</code> matrix. So “00000” becomes <math><mrow><mrow><mo>(</mo><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>3</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>4</mn></mtd><mtd><mn>0</mn></mtd></mtr></mtable><mo>)</mo></mrow></mrow></math> in Python after transposing.</p></dd> 
 <dt><a class="co" id="c032" href="#comarker1003"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
  <dd><p>We pass the rows of <code>idx</code> as indices to indicate which element of each pair goes into the treatment group. That is, to indicate that the first element of the first pair should go into the treatment group, we pass [0, 0]. With 00000, we always put the first element of each pair in the treatment group. With the last permutation, 11111, we put the second element of each pair in the treatment group, mirroring the allocation for 00000. Taking a more complicated example, for permutation number 7, whose binary format is 00111, we would put in the control group the first element for the first two pairs, and the second element for the last three pairs.</p></dd> 
 <dt><a class="co" id="c042" href="#comarker1004"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
  <dd><p>Finally, we update our simulated experimental data set, assigning each row to either the control or treatment group based on its center ID.</p></dd> 
</dl>

<p>The process is identical in R with a few differences in syntax:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code><code>
</code><code class="n">permutation_gen_fun</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">function</code><code class="p">(</code><code class="n">i</code><code class="p">,</code><code> </code><code class="n">stratified_pairs</code><code class="p">)</code><code class="p">{</code><code>
  </code><code class="n">Npairs</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">nrow</code><code class="p">(</code><code class="n">stratified_pairs</code><code class="p">)</code><code>
  </code><code class="n">bin_str</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">as.binary</code><code class="p">(</code><code class="n">i</code><code class="p">,</code><code> </code><code class="n">n</code><code class="o">=</code><code class="n">Npairs</code><code class="p">)</code><code> </code><a class="co" id="comarker10001" href="#c013"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>  
  </code><code class="n">idx</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">matrix</code><code class="p">(</code><code class="nf">c</code><code class="p">(</code><code class="m">1</code><code class="o">:</code><code class="n">Npairs</code><code class="p">,</code><code> </code><code class="n">bin_str</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">nrow</code><code> </code><code class="o">=</code><code> </code><code class="n">Npairs</code><code class="p">)</code><code>
  </code><code class="n">idx</code><code class="p">[</code><code class="p">,</code><code class="m">2</code><code class="p">]</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">idx</code><code class="p">[</code><code class="p">,</code><code class="m">2</code><code class="p">]</code><code> </code><code class="o">+</code><code> </code><code class="m">1</code><code>  </code><a class="co" id="comarker10002" href="#c023"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>                                        
  </code><code class="n">treat</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">stratified_pairs</code><code class="p">[</code><code class="n">idx</code><code class="p">]</code><code> </code><a class="co" id="comarker10003" href="#c033"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>                           
  </code><code class="nf">return</code><code class="p">(</code><code class="n">treat</code><code class="p">)</code><code class="p">}</code></pre>

<dl class="calloutlist">
 <dt><a class="co" id="c013" href="#comarker10001"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
  <dd><p>Converting <code>perm</code> to a binary format is <a contenteditable="false" data-type="indexterm" data-primary="as.binary() function" id="idm45968144741720"/>done in R with the <code>as.binary()</code> function, which takes as first argument the number to convert and as second argument the total number of digits we want (i.e., the number of pairs, here 5).</p></dd> 
 <dt><a class="co" id="c023" href="#comarker10002"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
  <dd><p>Because the indexing starts with 1 and not 0 in R, we need to add 1 to all the elements of the second column in the <code>idx</code> matrix. Thus, for the first permutation, 00000, where the first element of each pair goes into the control group, the <code>idx</code> matrix is <math><mrow><mrow><mo>(</mo><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>3</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>4</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>5</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable><mo>)</mo></mrow></mrow></math>. For permutation 11111, the second column would be made up of 2s, and for 00111 it would be 11222.</p></dd> 
 <dt><a class="co" id="c033" href="#comarker10003"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
  <dd><p>We pass the rows of <code>idx</code> as indices to indicate which element of each pair goes into the treatment group.</p></dd> 
</dl>

<p>The <code>permutation_gen_fun()</code> function returns a list of the center IDs for the treatment group, which can then be used in the random assignment function.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-clus" id="idm45968144682712"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-perm" id="idm45968144681608"/></p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Power curve"><div class="sect3" id="power_curve">
<h3>Power curve</h3>
<p>Now that we have a solution to the problem of limited possible samples, we can get back to our power analysis. <a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="power analysis" data-tertiary="power curve" id="idm45968144678328"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="hierarchical linear modeling" data-tertiary="power curve" id="idm45968144676872"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="call center problem-solving mode" data-tertiary="power curve" id="idm45968144675416"/>Remember that business partners want to run the experiment for no longer than a month, meaning a sample size of about 230,000 calls. Instead of calculating the required sample size for the threshold value of 0.6 points of CSAT and the desired power, we need to take the sample size as given and calculate what power we have for this threshold value.</p>
<p>Let’s first look at statistical significance. Remember that in the previous chapter, our estimator was “underconfident”: the 90%-CI included zero more than 90% of the time. Even using a 40%-CI led only to a small number of false positives. Here, we have the opposite problem: our estimator is “overconfident” as the 90%-CI includes zero much less than 90% of the time, and indeed it never includes it: our coverage is null. <a data-type="xref" href="#ninezeropercent_confidence_intervals_wi">Figure 10-2</a> shows the 96 confidence intervals ranked from lowest to highest.</p>
<figure><div id="ninezeropercent_confidence_intervals_wi" class="figure">
<img src="Images/BEDA_1002.png" alt="90% confidence intervals with no effect" width="1906" height="1166"/>
<h6><span class="label">Figure 10-2. </span>90% confidence intervals with no effect</h6>
</div></figure>
<p>The situation we can see in <a data-type="xref" href="#power_curve_with_decision_threshold_of">Figure 10-3</a> is similar to what we saw in <a data-type="xref" href="ch07.xhtml#measuring_uncertainty_with_the_bootstra">Chapter 7</a>, where having very limited data led to discontinuities in our graphs. Here, the random errors never quite line up in the way that would result in a CI including zero. Instead, we have four tight clusters of CIs, even though the distribution of our CIs is symmetric around zero (i.e., our estimator is unbiased) and half of them are very close to it. From a practical perspective, that means that if we run our experiment, we shouldn’t expect the true value to be included in our CI.</p>
<p>This doesn’t mean that our experiment is doomed, but that we shouldn’t trust our CI bounds and we should rely on our decision rule instead. With the default decision rule of accepting any CI that is strictly positive, our significance is 50%: because half of our CIs are below zero and half above, in half of the cases we would observe a negative coefficient and rightly conclude that the treatment group is no better than the control group. <a data-type="xref" href="#power_curve_with_decision_threshold_of">Figure 10-3</a> plots the power curve with this decision rule for different effect sizes.</p>
<figure><div id="power_curve_with_decision_threshold_of" class="figure">
<img src="Images/BEDA_1003.png" alt="Power curve with decision threshold of 0 for different effect sizes" width="1898" height="1158"/>
<h6><span class="label">Figure 10-3. </span>Power curve with decision threshold of 0 for different effect sizes</h6>
</div></figure>
<p>As you can see, our power reaches 75% very quickly, basically as soon as the cluster of CIs that was just below zero gets shifted just above it. After that, our power remains constant for a range of values including our threshold effect size of 0.6, until the cluster of strongly negative CIs gets shifted above zero in turn. Then our power is close to 100% for effect sizes of 1 or above. That is, if the true effect is 1 or higher, we’re extremely unlikely to see a negative CI.</p>
<p>We could go back to our business partners and tell them that our CIs are unreliable and therefore our risk of false positives is large, but our risk of false negatives is very low. In the present case, we can do better by setting a more stringent decision rule and implementing the intervention only if we observe an effect size of 0.25 or above. <a data-type="xref" href="#power_curve_for_different_effect_sizes">Figure 10-4</a> shows the power curve for that decision rule.</p>
<figure><div id="power_curve_for_different_effect_sizes" class="figure">
<img src="Images/BEDA_1004.png" alt="Power curve for different effect sizes with decision threshold of 0.25" width="1898" height="1158"/>
<h6><span class="label">Figure 10-4. </span>Power curve for different effect sizes with decision threshold of 0.25</h6>
</div></figure>
<p>As we can see in <a data-type="xref" href="#power_curve_for_different_effect_sizes">Figure 10-4</a>, by increasing our decision threshold, we’ve lowered the left side of our power curve. This implies a lower significance (i.e., lower risk of false positives) at the cost of a lower power (i.e., higher risk of false negatives) for small effect sizes. However, the right side of our power curve remains mostly unchanged, meaning that our power to detect an effect of 0.6 remains at 75%.</p>
<p>Let’s recap what our power analysis told us. Because we plan to use a stratified random assignment with a limited number of effective experimental units (i.e., call centers), our experiment has a rigid structure that constrains possible outcomes. This makes our CIs unreliable by themselves. However, we can adjust our decision rule to a higher threshold (i.e., we’ll implement our intervention only if we observe an effect of 0.25 or higher). By doing so, we can reduce the risk of false positives for a null effect size while keeping our power for the target effect size high enough. This remains an underpowered experiment but this is the best we can offer as experimentalists, and our business partners will have to decide how they feel about these odds.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmpo" id="idm45968144656904"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmpo2" id="idm45968144655688"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmpo3" id="idm45968144654472"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch10-hlmpo4" id="idm45968144653256"/></p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
Note the difference between our decision threshold, 0.25, and our target effect, 0.6. By definition, the power at the decision threshold is always 0.5 and we set out to get as much power as possible for an effect size of 0.6.
</div>
</div></section>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Analyzing the Experiment"><div class="sect1" id="analyzing_the_experiment">
<h1>Analyzing the Experiment</h1>
<p>Once we have run our experiment, we can collect and analyze the data. <a contenteditable="false" data-type="indexterm" data-primary="hierarchical linear modeling (HLM)" data-secondary="analyzing the experiment" id="idm45968144649864"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="hierarchical linear modeling" data-tertiary="analyzing the experiment" id="idm45968144648648"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="call center problem-solving mode" data-tertiary="analyzing the experiment" id="idm45968144647192"/>Having defined our metric function previously, the analysis is now as simple as applying it to our experimental data, then obtaining a Bootstrap 90%-CI of its value for our experimental data:<a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="hierarchical linear modeling" data-tertiary="analyzing the experiment" id="idm45968144645400"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="hierarchical linear modeling" data-tertiary="analyzing the experiment" id="idm45968144643944"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R (output not shown)</code>
<code class="o">&gt;</code> <code class="n">coeff</code> <code class="o">&lt;-</code> <code class="nf">hlm_metric_fun</code><code class="p">(</code><code class="n">exp_data</code><code class="p">)</code>
<code class="o">&gt;</code> <code class="nf">print</code><code class="p">(</code><code class="n">coeff</code><code class="p">)</code>
<code class="o">&gt;</code> <code class="n">hlm_CI</code> <code class="o">&lt;-</code> <code class="nf">boot_CI_fun</code><code class="p">(</code><code class="n">exp_data</code><code class="p">,</code> <code class="n">hlm_metric_fun</code><code class="p">)</code>
<code class="o">&gt;</code> <code class="nf">print</code><code class="p">(</code><code class="n">hlm_CI</code><code class="p">)</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
<code class="n">coeff</code> <code class="o">=</code> <code class="n">hlm_metric_fun</code><code class="p">(</code><code class="n">exp_data_df</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">coeff</code><code class="p">)</code>
<code class="n">hlm_CI</code> <code class="o">=</code> <code class="n">boot_CI_fun</code><code class="p">(</code><code class="n">exp_data_df</code><code class="p">,</code> <code class="n">hlm_metric_fun</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">hlm_CI</code><code class="p">)</code>
<code class="mf">0.477903237163797</code>
<code class="p">[</code><code class="mf">0.47434045128179986</code><code class="p">,</code> <code class="mf">0.4815858577196438</code><code class="p">]</code></pre>
<p>Our confidence interval is very narrow and squarely above 0.25. Based on our power analysis, the true effect size is unlikely to be actually within that CI, but it is as likely to be lower as it is to be higher, so our expected effect size is equal to 0.48. Because that is above our decision threshold, we would implement the intervention, even though the expected effect size is less than our target. Interestingly, that confidence interval is much smaller than the one we would obtain based on the normal approximation (i.e., coefficient +/− 1.96 * coefficient standard error), in part because of the stratified randomization.</p>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="conclusion-id00015">
<h1>Conclusion</h1>
<p>This concludes our tour of experimental design. In the last part of the book, we’ll see advanced tools that will allow us to dig deeper in the analysis of experimental data, but the call center experiment we’ve just seen is about as complex as experiments get in real life. Being unable to randomize at the lowest level and having a predetermined amount of time to run an experiment are unpleasant but not infrequent circumstances. Randomizing at the level of an office or a store instead of customers or employees is common, to avoid logistical complications and “leakage” between experimental groups. Leveraging simulations for power analysis and stratification for random assignment becomes pretty much unavoidable if you want to get useful results out of your experiment; hopefully you should now be fully equipped to do so.</p>
<p>Designing and running experiments is in my opinion one of the most fun parts of behavioral science. When everything goes well, you get to measure with clarity the impact of a business initiative or a behavioral science intervention. But getting everything to go well is no small feat in itself. Popular media and business vendors often feed the impression that experimentation can be as simple as “plug and play, check for 5% significance and you’re done!” but this is misleading, and I’ve tried to address several misconceptions that come out of this.</p>
<p>First of all, statistical significance and power are often misunderstood, which can lead to wasted experiments and suboptimal decisions. I believe that eschewing p-values in favor of Bootstrap confidence intervals leads to results and interpretations that are both more correct and more relevant to applied settings.</p>
<p>Second, treating experiments as a pure technology and data analysis problem is easier but less fruitful than adopting a causal-behavioral approach. Using causal diagrams allows you to articulate more clearly what would be a success and what makes you believe your treatment would be successful.</p>
<p>Implementing an experiment in the field is fraught with difficulties (see <a data-type="xref" href="bibliography01.xhtml#bibliography">Bibliography</a> for further resources), and unfortunately each experiment is different, therefore I can only give you some generic advice:</p>
<ul>
<li><p>Running field experiments is an art and science, and nothing can replace experience with a specific context. Start with smaller and simpler experiments at first.</p></li>
<li><p>Start by implementing the treatment on a small pilot group that you then observe for a little while and extensively debrief. This will allow you to ensure as much as possible that people understand the treatment and apply it somewhat correctly and consistently.</p></li>
<li><p>Try to imagine all the ways things could go wrong and to prevent them from <span class="keep-together">happening.</span></p></li>
<li><p>Recognize that things will go wrong nonetheless, and build flexibility into your experiment (e.g., plan for “buffers” of time, because things will take longer than you think—people might take a week to settle into implementing the treatment correctly, data might come in late, etc.).</p></li>
</ul>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="ch01fn22"><sup><a href="ch10.xhtml#ch01fn22-marker">1</a></sup> “‘Sorry’ Is Not Enough,” <em>Harvard Business Review</em>, Jan.–Feb. 2018.</p><p data-type="footnote" id="ch01fn23"><sup><a href="ch10.xhtml#ch01fn23-marker">2</a></sup> If you want to learn more about this type of models, Gelman and Hill (2006) is the classic reference on the topic.</p><p data-type="footnote" id="ch01fn24"><sup><a href="ch10.xhtml#ch01fn24-marker">3</a></sup> If you really want to know, these coefficients are calculated as a weighted average of the mean CSAT in a call center and the mean CSAT across our whole data.</p><p data-type="footnote" id="ch01fn25"><sup><a href="ch10.xhtml#ch01fn25-marker">4</a></sup> As always with numerical simulations, your mileage may vary. Thanks to Jessica Jakubowski for suggesting an alternative specification: <code>lmerControl(optimizer ="bobyqa", optCtrl=list(maxfun=2e5))</code>.</p><p data-type="footnote" id="ch01fn26"><sup><a href="ch10.xhtml#ch01fn26-marker">5</a></sup> Does that suck for your experimental design? Totally. Is that unrealistic? Absolutely not, unfortunately. As we used to say when I was a consultant, the client is always the client.</p><p data-type="footnote" id="ch01fn27"><sup><a href="ch10.xhtml#ch01fn27-marker">6</a></sup> The exclamation mark indicates the mathematical operator factorial. See <a href="https://oreil.ly/I5PTW">this Wikipedia page</a> if you want to better understand the underlying math.</p></div></div></section></div></body></html>