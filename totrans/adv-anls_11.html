<html><head></head><body><section data-pdf-bookmark="Chapter 9. Capstone: R for Data Analytics" data-type="chapter" epub:type="chapter"><div class="chapter" id="r-capstone">&#13;
<h1><span class="label">Chapter 9. </span>Capstone: R for Data Analytics</h1>&#13;
&#13;
&#13;
<p>In this chapter, we’ll apply what we’ve learned about data analysis and visualization in R to explore and test relationships in the <a data-primary="datasets" data-secondary="mpg example" data-type="indexterm" id="idm46274540660280"/><a data-primary="mpg dataset example" data-type="indexterm" id="idm46274540659304"/><a data-primary="vehicle mileage (mpg) dataset example" data-type="indexterm" id="idm46274540658632"/>familiar <em>mpg</em> dataset. You’ll learn a couple of new R techniques here, including how to conduct a t-test and linear regression. We’ll begin by calling up the necessary <a data-primary="R programming language" data-secondary="packages" data-seealso="dplyr, R" data-type="indexterm" id="idm46274540657272"/><a data-primary="installation of packages" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="idm46274540656024"/><a data-primary="packages" data-secondary="R" data-type="indexterm" id="idm46274540654792"/><a data-primary="packages" data-secondary="R installation and calling of" data-type="indexterm" id="idm46274540653848"/><a data-primary="tidyverse packages, R" data-type="indexterm" id="idm46274540652888"/><a data-primary="psych package, R" data-type="indexterm" id="idm46274540652216"/><a data-primary="tidymodels package, R" data-type="indexterm" id="idm46274540651544"/>packages, reading in <em>mpg.csv</em> from the <em>mpg</em> subfolder of the book repository’s <em>datasets</em> folder, and selecting the columns of interest. We’ve not used <code>tidymodels</code> so far in this book, so you may need to install it.</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">library</code><code class="p">(</code><code class="n">tidyverse</code><code class="p">)</code>&#13;
<code class="nf">library</code><code class="p">(</code><code class="n">psych</code><code class="p">)</code>&#13;
<code class="nf">library</code><code class="p">(</code><code class="n">tidymodels</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Read in the data, select only the columns we need</code>&#13;
<code class="n">mpg</code> <code class="o">&lt;-</code> <code class="nf">read_csv</code><code class="p">(</code><code class="s">'datasets/mpg/mpg.csv'</code><code class="p">)</code> <code class="o">%&gt;%</code>&#13;
  <code class="nf">select</code><code class="p">(</code><code class="n">mpg</code><code class="p">,</code> <code class="n">weight</code><code class="p">,</code> <code class="n">horsepower</code><code class="p">,</code> <code class="n">origin</code><code class="p">,</code> <code class="n">cylinders</code><code class="p">)</code>&#13;
&#13;
<code class="c1">#&gt; -- Column specification -----------------------------------------------------</code>&#13;
<code class="c1">#&gt; cols(</code>&#13;
<code class="c1">#&gt;  mpg = col_double(),</code>&#13;
<code class="c1">#&gt;  cylinders = col_double(),</code>&#13;
<code class="c1">#&gt;  displacement = col_double(),</code>&#13;
<code class="c1">#&gt;  horsepower = col_double(),</code>&#13;
<code class="c1">#&gt;  weight = col_double(),</code>&#13;
<code class="c1">#&gt;  acceleration = col_double(),</code>&#13;
<code class="c1">#&gt;  model.year = col_double(),</code>&#13;
<code class="c1">#&gt;  origin = col_character(),</code>&#13;
<code class="c1">#&gt;  car.name = col_character()</code>&#13;
<code class="c1">#&gt; )</code>&#13;
&#13;
<code class="nf">head</code><code class="p">(</code><code class="n">mpg</code><code class="p">)</code>&#13;
<code class="c1">#&gt; # A tibble: 6 x 5</code>&#13;
<code class="c1">#&gt;     mpg weight horsepower origin cylinders</code>&#13;
<code class="c1">#&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;</code>&#13;
<code class="c1">#&gt; 1    18   3504        130 USA            8</code>&#13;
<code class="c1">#&gt; 2    15   3693        165 USA            8</code>&#13;
<code class="c1">#&gt; 3    18   3436        150 USA            8</code>&#13;
<code class="c1">#&gt; 4    16   3433        150 USA            8</code>&#13;
<code class="c1">#&gt; 5    17   3449        140 USA            8</code>&#13;
<code class="c1">#&gt; 6    15   4341        198 USA            8</code></pre>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exploratory Data Analysis" data-type="sect1"><div class="sect1" id="idm46274540627096">&#13;
<h1>Exploratory Data Analysis</h1>&#13;
&#13;
<p>Descriptive <a data-primary="descriptive statistics" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="ch9_term1"/><a data-primary="psych package, R" data-type="indexterm" id="ch9_term2"/><a data-primary="exploratory data analysis (EDA)" data-secondary="with R capstone" data-secondary-sortas="R capstone" data-type="indexterm" id="ch9_term3"/><a data-primary="R programming language" data-secondary="exploratory data analysis with" data-type="indexterm" id="ch9_term4"/>statistics are a good place to start when exploring data. We’ll do so <a data-primary="describe() function, R" data-type="indexterm" id="idm46274540565048"/>with the <code>describe()</code> function from <code>psych</code>:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">describe</code><code class="p">(</code><code class="n">mpg</code><code class="p">)</code>&#13;
<code class="c1">#&gt;            vars   n    mean     sd  median trimmed    mad  min</code>&#13;
<code class="c1">#&gt; mpg           1 392   23.45   7.81   22.75   22.99   8.60    9</code>&#13;
<code class="c1">#&gt; weight        2 392 2977.58 849.40 2803.50 2916.94 948.12 1613</code>&#13;
<code class="c1">#&gt; horsepower    3 392  104.47  38.49   93.50   99.82  28.91   46</code>&#13;
<code class="c1">#&gt; origin*       4 392    2.42   0.81    3.00    2.53   0.00    1</code>&#13;
<code class="c1">#&gt; cylinders     5 392    5.47   1.71    4.00    5.35   0.00    3</code>&#13;
<code class="c1">#&gt;               max  range  skew kurtosis    se</code>&#13;
<code class="c1">#&gt; mpg          46.6   37.6  0.45    -0.54  0.39</code>&#13;
<code class="c1">#&gt; weight     5140.0 3527.0  0.52    -0.83 42.90</code>&#13;
<code class="c1">#&gt; horsepower  230.0  184.0  1.08     0.65  1.94</code>&#13;
<code class="c1">#&gt; origin*       3.0    2.0 -0.91    -0.86  0.04</code>&#13;
<code class="c1">#&gt; cylinders     8.0    5.0  0.50    -1.40  0.09</code></pre>&#13;
&#13;
<p>Because <em>origin</em> is a <a data-primary="categorical variables" data-secondary="in R" data-secondary-sortas="R" data-type="indexterm" id="idm46274540541784"/>categorical variable, we should be careful to interpret its descriptive statistics. (In fact, <code>psych</code> uses <code>*</code> to signal this warning.) We are, however, safe to <a data-primary="one-way frequency tables" data-type="indexterm" id="idm46274540539464"/><a data-primary="frequency tables" data-type="indexterm" id="idm46274540538792"/>analyze its one-way frequency table, which we’ll do <a data-primary="count() function, R and Python" data-type="indexterm" id="idm46274540537928"/><a data-primary="dplyr, R" data-secondary="data analysis with" data-type="indexterm" id="idm46274540537288"/>using a new <code>dplyr</code> function, <code>count()</code>:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="n">mpg</code> <code class="o">%&gt;%</code>&#13;
  <code class="nf">count</code><code class="p">(</code><code class="n">origin</code><code class="p">)</code>&#13;
<code class="c1">#&gt; # A tibble: 3 x 2</code>&#13;
<code class="c1">#&gt;   origin     n</code>&#13;
<code class="c1">#&gt;   &lt;chr&gt;  &lt;int&gt;</code>&#13;
<code class="c1">#&gt; 1 Asia      79</code>&#13;
<code class="c1">#&gt; 2 Europe    68</code>&#13;
<code class="c1">#&gt; 3 USA      245</code></pre>&#13;
&#13;
<p>We learn from the resulting count column <em>n</em> that while the majority of observations are American cars, the observations of Asian and European cars are still likely to be representative samples of their subpopulations.</p>&#13;
&#13;
<p>Let’s further break these counts down by <code>cylinders</code> to <a data-primary="two-way frequency tables" data-type="indexterm" id="idm46274540524440"/>derive a two-way frequency table. I will <a data-primary="pivot_wider() function, R" data-type="indexterm" id="idm46274540523752"/>combine <code>count()</code> with <code>pivot_wider()</code> to display <code>cylinders</code> along the columns:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="n">mpg</code> <code class="o">%&gt;%</code>&#13;
  <code class="nf">count</code><code class="p">(</code><code class="n">origin</code><code class="p">,</code> <code class="n">cylinders</code><code class="p">)</code> <code class="o">%&gt;%</code>&#13;
  <code class="nf">pivot_wider</code><code class="p">(</code><code class="n">values_from</code> <code class="o">=</code> <code class="n">n</code><code class="p">,</code> <code class="n">names_from</code> <code class="o">=</code> <code class="n">cylinders</code><code class="p">)</code>&#13;
<code class="c1">#&gt; # A tibble: 3 x 6</code>&#13;
<code class="c1">#&gt;   origin   `3`   `4`   `6`   `5`   `8`</code>&#13;
<code class="c1">#&gt;   &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;</code>&#13;
<code class="c1">#&gt; 1 Asia       4    69     6    NA    NA</code>&#13;
<code class="c1">#&gt; 2 Europe    NA    61     4     3    NA</code>&#13;
<code class="c1">#&gt; 3 USA       NA    69    73    NA   103</code></pre>&#13;
&#13;
<p>Remember <a data-primary="NA (missing  observations), R" data-type="indexterm" id="idm46274540373960"/>that <code>NA</code> indicates a missing value in R, in this case because no observations were found for some of these cross-sections.</p>&#13;
&#13;
<p>Not many cars have three- or five-cylinder engines, and <em>only</em> American cars have eight cylinders. It’s common when <a data-primary="datasets" data-secondary="imbalanced" data-type="indexterm" id="idm46274540403880"/><a data-primary="imbalanced datasets" data-type="indexterm" id="idm46274540402904"/>analyzing data to have <em>imbalanced</em> datasets where there is a disproportionate number of observations in some levels. Special techniques are often needed to model such data. To <a data-primary="statistics" data-secondary="further reading on" data-type="indexterm" id="idm46274540401528"/>learn more about working with imbalanced data, check out <a class="orm:hideurl" href="https://oreil.ly/jv8RS"><em>Practical Statistics for Data Scientists</em></a>, 2nd edition by Peter Bruce et al. (O’Reilly).</p>&#13;
&#13;
<p>We can also find the descriptive statistics for each level of <em>origin</em>. First, we’ll use <code>select()</code> to choose the variables of interest, then we can <a data-primary="describeBy() function, R" data-type="indexterm" id="idm46274540397752"/>use <code>psych</code>’s <code>describeBy()</code> function, <a data-startref="ch9_term1" data-type="indexterm" id="idm46274540396088"/><a data-startref="ch9_term2" data-type="indexterm" id="idm46274540395352"/>setting <code>groupBy</code> to <code>origin</code>:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="n">mpg</code> <code class="o">%&gt;%</code>&#13;
  <code class="nf">select</code><code class="p">(</code><code class="n">mpg</code><code class="p">,</code> <code class="n">origin</code><code class="p">)</code> <code class="o">%&gt;%</code>&#13;
  <code class="nf">describeBy</code><code class="p">(</code><code class="n">group</code> <code class="o">=</code> <code class="s">'origin'</code><code class="p">)</code>&#13;
&#13;
<code class="c1">#&gt;  Descriptive statistics by group</code>&#13;
<code class="c1">#&gt; origin: Asia</code>&#13;
        <code class="n">vars</code>  <code class="n">n</code>  <code class="n">mean</code>   <code class="n">sd</code> <code class="n">median</code> <code class="n">trimmed</code>  <code class="n">mad</code> <code class="n">min</code>  <code class="n">max</code> <code class="n">range</code>&#13;
<code class="c1">#&gt; mpg        1 79 30.45 6.09   31.6   30.47 6.52  18 46.6  28.6</code>&#13;
<code class="c1">#&gt; origin*    2 79  1.00 0.00    1.0    1.00 0.00   1  1.0   0.0</code>&#13;
        <code class="n">skew</code> <code class="n">kurtosis</code>   <code class="n">se</code>&#13;
<code class="c1">#&gt; mpg     0.01    -0.39 0.69</code>&#13;
<code class="c1">#&gt; origin*  NaN      NaN 0.00</code>&#13;
&#13;
<code class="c1">#&gt; origin: Europe</code>&#13;
        <code class="n">vars</code>  <code class="n">n</code> <code class="n">mean</code>   <code class="n">sd</code> <code class="n">median</code> <code class="n">trimmed</code>  <code class="n">mad</code>  <code class="n">min</code>  <code class="n">max</code> <code class="n">range</code>&#13;
<code class="c1">#&gt; mpg        1 68 27.6 6.58     26    27.1 5.78 16.2 44.3  28.1</code>&#13;
<code class="c1">#&gt; origin*    2 68  1.0 0.00      1     1.0 0.00  1.0  1.0   0.0</code>&#13;
        <code class="n">skew</code> <code class="n">kurtosis</code>  <code class="n">se</code>&#13;
<code class="c1">#&gt; mpg     0.73     0.31 0.8</code>&#13;
<code class="c1">#&gt; origin*  NaN      NaN 0.0</code>&#13;
&#13;
<code class="c1">#&gt; origin: USA</code>&#13;
        <code class="n">vars</code>   <code class="n">n</code>  <code class="n">mean</code>   <code class="n">sd</code> <code class="n">median</code> <code class="n">trimmed</code>  <code class="n">mad</code> <code class="n">min</code> <code class="n">max</code> <code class="n">range</code>&#13;
<code class="c1">#&gt; mpg        1 245 20.03 6.44   18.5   19.37 6.67   9  39    30</code>&#13;
<code class="c1">#&gt; origin*    2 245  1.00 0.00    1.0    1.00 0.00   1   1     0</code>&#13;
        <code class="n">skew</code> <code class="n">kurtosis</code>   <code class="n">se</code>&#13;
<code class="c1">#&gt; mpg     0.83     0.03 0.41</code>&#13;
<code class="c1">#&gt; origin*  NaN      NaN 0.00</code></pre>&#13;
&#13;
<p>Let’s learn more about the potential relationship between <em>origin</em> and <em>mpg</em>. We’ll get started by <a data-primary="histograms" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="idm46274540270184"/><a data-primary="distributions" data-secondary="visualizations of" data-type="indexterm" id="ch9_term6"/><a data-primary="R programming language" data-secondary="visualization of data in" data-type="indexterm" id="ch9_term7"/><a data-primary="visualization of data" data-secondary="distributions with" data-type="indexterm" id="ch9_term8"/><a data-primary="visualization of data" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="ch9_term9"/>visualizing the distribution of <em>mpg</em> with a histogram, which is shown in <a data-type="xref" href="#mpg-hist">Figure 9-1</a>:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">ggplot</code><code class="p">(</code><code class="n">data</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">,</code> <code class="nf">aes</code><code class="p">(</code><code class="n">x</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">))</code> <code class="o">+</code>&#13;
  <code class="nf">geom_histogram</code><code class="p">()</code>&#13;
<code class="c1">#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>&#13;
&#13;
<figure><div class="figure" id="mpg-hist">&#13;
<img alt="Histogram" src="assets/aina_0901.png"/>&#13;
<h6><span class="label">Figure 9-1. </span>Distribution of <em>mpg</em></h6>&#13;
</div></figure>&#13;
&#13;
<p>We can now hone in on visualizing the distribution of <em>mpg</em> by <em>origin</em>. Overlaying all three levels of <em>origin</em> on one histogram could get cluttered, so a <a data-primary="boxplots" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="idm46274540251016"/>boxplot like what’s shown in <a data-type="xref" href="#mpg-box">Figure 9-2</a> may be a better fit:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">ggplot</code><code class="p">(</code><code class="n">data</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">,</code> <code class="nf">aes</code><code class="p">(</code><code class="n">x</code> <code class="o">=</code> <code class="n">origin</code><code class="p">,</code> <code class="n">y</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">))</code> <code class="o">+</code>&#13;
  <code class="nf">geom_boxplot</code><code class="p">()</code></pre>&#13;
&#13;
<figure><div class="figure" id="mpg-box">&#13;
<img alt="Boxplot" src="assets/aina_0902.png"/>&#13;
<h6><span class="label">Figure 9-2. </span>Distribution of <em>mpg</em> by <em>origin</em></h6>&#13;
</div></figure>&#13;
&#13;
<p>If we’d rather visualize these as <a data-primary="histograms" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="idm46274540171128"/>histograms, and not make a mess, we <a data-primary="facet_wrap() function, R" data-type="indexterm" id="idm46274540169368"/><a data-primary="facet plots" data-type="indexterm" id="idm46274540168728"/><a data-primary="visualization of data" data-secondary="facet plots" data-type="indexterm" id="idm46274540168056"/>can do so in R with a <em>facet</em> plot. Use <code>facet_wrap()</code> to split the <code>ggplot2</code> plot into subplots, or <em>facets</em>. We’ll&#13;
<a data-primary="~ tilde" data-type="indexterm" id="idm46274540165256"/><a data-primary="tilde (~), R operator" data-type="indexterm" id="idm46274540164520"/>start with a <code>~</code>, or tilde operator, followed by the variable name. When you see the tilde used in R, think of it as the word “by.” For example, here we are faceting a histogram by <code>origin</code>, which <a data-startref="ch9_term3" data-type="indexterm" id="idm46274540162696"/><a data-startref="ch9_term4" data-type="indexterm" id="idm46274540161960"/>results in the histograms shown in <a data-type="xref" href="#mpg-facet">Figure 9-3</a>:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="c1"># Histogram of mpg, facted by origin</code>&#13;
<code class="nf">ggplot</code><code class="p">(</code><code class="n">data</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">,</code> <code class="nf">aes</code><code class="p">(</code><code class="n">x</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">))</code> <code class="o">+</code>&#13;
  <code class="nf">geom_histogram</code><code class="p">()</code> <code class="o">+</code>&#13;
  <code class="nf">facet_grid</code><code class="p">(</code><code class="o">~</code> <code class="n">origin</code><code class="p">)</code>&#13;
<code class="c1">#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>&#13;
&#13;
<figure><div class="figure" id="mpg-facet">&#13;
<img alt="Faceted histogram" src="assets/aina_0903.png"/>&#13;
<h6><span class="label">Figure 9-3. </span>Distribution of <em>mpg</em> by <em>origin</em></h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Hypothesis Testing" data-type="sect1"><div class="sect1" id="idm46274540571016">&#13;
<h1>Hypothesis Testing</h1>&#13;
&#13;
<p>You could <a data-startref="ch9_term6" data-type="indexterm" id="idm46274540108120"/><a data-startref="ch9_term7" data-type="indexterm" id="idm46274540107384"/><a data-startref="ch9_term8" data-type="indexterm" id="idm46274540106712"/><a data-startref="ch9_term9" data-type="indexterm" id="idm46274540106040"/>continue to explore the data using these methods, but let’s move into <a data-primary="hypothesis testing" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="ch9_term11"/><a data-primary="R programming language" data-secondary="hypothesis testing with" data-type="indexterm" id="ch9_term12"/>hypothesis testing. In particular, I would like to know whether there is a significant difference in mileage between American and European cars. Let’s create a new data frame containing just these observations; we’ll use it to conduct a t-test.</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="n">mpg_filtered</code> <code class="o">&lt;-</code> <code class="nf">filter</code><code class="p">(</code><code class="n">mpg</code><code class="p">,</code> <code class="n">origin</code><code class="o">==</code><code class="s">'USA'</code> <code class="o">|</code> <code class="n">origin</code><code class="o">==</code><code class="s">'Europe'</code><code class="p">)</code></pre>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46274540096888">&#13;
<h5>Testing Relationships Across Multiple Groups</h5>&#13;
<p>We could indeed use hypothesis testing to look for a difference in mileage across American, European, and Asian cars; this is a different <a data-primary="analysis of variance (ANOVA)" data-type="indexterm" id="idm46274540092792"/><a data-primary="variance, analysis of (ANOVA)" data-type="indexterm" id="idm46274540092152"/>statistical test called <em>analysis of variance</em>, or ANOVA. It’s worth exploring next on your analytics journey.</p>&#13;
</div></aside>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Independent Samples t-test" data-type="sect2"><div class="sect2" id="idm46274540090744">&#13;
<h2>Independent Samples t-test</h2>&#13;
&#13;
<p>R includes <a data-primary="t.test() function, R" data-type="indexterm" id="idm46274540056792"/><a data-primary="independent samples t-tests" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="ch9_term10"/>a <code>t.test()</code> function out of the box: we need to specify where our data comes from with the <code>data</code> argument, and we’ll also need to specify what <em>formula</em> to test. To do that, we’ll set the <a data-primary="dependent variables" data-secondary="in independent samples t-test" data-secondary-sortas="independent samples t-test" data-type="indexterm" id="idm46274540052840"/><a data-primary="independent variables" data-secondary="in independent samples t-test" data-secondary-sortas="independent samples t-test" data-type="indexterm" id="idm46274540051560"/>relationship between independent and dependent variables with&#13;
<a data-primary="~ tilde" data-type="indexterm" id="idm46274540050184"/><a data-primary="tilde (~), R operator" data-type="indexterm" id="idm46274540049512"/>the <code>~</code> operator. The dependent variable comes in front of the <code>~</code>, with independent variables following. Again, you interpret this notation as analyzing the effect of <code>mpg</code> “by” <code>origin</code>.</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="c1"># Dependent variable ~ ("by") independent variable</code>&#13;
<code class="nf">t.test</code><code class="p">(</code><code class="n">mpg</code> <code class="o">~</code> <code class="n">origin</code><code class="p">,</code> <code class="n">data</code> <code class="o">=</code> <code class="n">mpg_filtered</code><code class="p">)</code>&#13;
<code class="c1">#&gt; 	Welch Two Sample t-test</code>&#13;
<code class="c1">#&gt;</code>&#13;
<code class="c1">#&gt;     data:  mpg by origin</code>&#13;
<code class="c1">#&gt;     t = 8.4311, df = 105.32, p-value = 1.93e-13</code>&#13;
<code class="c1">#&gt;     alternative hypothesis: true difference in means is not equal to 0</code>&#13;
<code class="c1">#&gt;     95 percent confidence interval:</code>&#13;
<code class="c1">#&gt;     5.789361 9.349583</code>&#13;
<code class="c1">#&gt;     sample estimates:</code>&#13;
<code class="c1">#&gt;     mean in group Europe    mean in group USA</code>&#13;
<code class="c1">#&gt;                 27.60294             20.03347</code></pre>&#13;
&#13;
<p>Isn’t it great that R even explicitly states what our <a data-primary="alternative (Ha) hypothesis" data-type="indexterm" id="idm46274540011544"/>alternative hypothesis is, <em>and</em> includes the <a data-primary="confidence intervals" data-secondary="in R" data-secondary-sortas="R" data-type="indexterm" id="idm46274540010328"/><a data-primary="p-values" data-secondary="in R" data-secondary-sortas="R" data-type="indexterm" id="idm46274540009144"/>confidence interval along with the p-value? (You can tell this program was built for statistical analysis.) Based on the p-value, we will <a data-primary="null, rejection of" data-type="indexterm" id="idm46274540006456"/><a data-primary="rejection of null" data-type="indexterm" id="idm46274540005784"/>reject the null; there does appear to be evidence of a difference in means.</p>&#13;
&#13;
<p>Let’s now turn our attention to <a data-primary="continuous variables" data-secondary="relationships between" data-type="indexterm" id="idm46274540004504"/>relationships between continuous variables. First, we’ll <a data-primary="cor() function, R" data-type="indexterm" id="idm46274540003400"/>use the <code>cor()</code> function from <a data-primary="base R" data-type="indexterm" id="ch9_term13"/><a data-primary="R programming language" data-secondary="base R" data-type="indexterm" id="ch9_term14"/>base R to print a <a data-primary="correlation matrices" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="idm46274539999832"/>correlation matrix. We’ll do this only for the continuous variables in <em>mpg</em>:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">select</code><code class="p">(</code><code class="n">mpg</code><code class="p">,</code> <code class="n">mpg</code><code class="o">:</code><code class="n">horsepower</code><code class="p">)</code> <code class="o">%&gt;%</code>&#13;
  <code class="nf">cor</code><code class="p">()</code>&#13;
<code class="c1">#&gt;                   mpg     weight horsepower</code>&#13;
<code class="c1">#&gt; mpg         1.0000000 -0.8322442 -0.7784268</code>&#13;
<code class="c1">#&gt; weight     -0.8322442  1.0000000  0.8645377</code>&#13;
<code class="c1">#&gt; horsepower -0.7784268  0.8645377  1.0000000</code></pre>&#13;
&#13;
<p>We can <a data-primary="ggplot2, R" data-type="indexterm" id="idm46274539991416"/><a data-primary="visualization of data" data-secondary="with ggplot2" data-secondary-sortas="ggplot2" data-type="indexterm" id="idm46274539990808"/>use <code>ggplot2</code> to <a data-primary="R programming language" data-secondary="visualization of data in" data-type="indexterm" id="ch9_term15"/><a data-primary="visualization of data" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="ch9_term16"/><a data-primary="visualization of data" data-secondary="relationships with" data-type="indexterm" id="ch9_term17"/>visualize, for example, the relationship between weight and mileage, as in <a data-type="xref" href="#mpg-scatter">Figure 9-4</a>:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">ggplot</code><code class="p">(</code><code class="n">data</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">,</code> <code class="nf">aes</code><code class="p">(</code><code class="n">x</code> <code class="o">=</code> <code class="n">weight</code><code class="p">,</code><code class="n">y</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">))</code> <code class="o">+</code>&#13;
  <code class="nf">geom_point</code><code class="p">()</code> <code class="o">+</code> <code class="nf">xlab</code><code class="p">(</code><code class="s">'weight (pounds)'</code><code class="p">)</code> <code class="o">+</code>&#13;
  <code class="nf">ylab</code><code class="p">(</code><code class="s">'mileage (mpg)'</code><code class="p">)</code> <code class="o">+</code> <code class="nf">ggtitle</code><code class="p">(</code><code class="s">'Relationship between weight and mileage'</code><code class="p">)</code></pre>&#13;
&#13;
<figure><div class="figure" id="mpg-scatter">&#13;
<img alt="Scatterplot" src="assets/aina_0904.png"/>&#13;
<h6><span class="label">Figure 9-4. </span>Scatterplot of <em>weight</em> by <em>mpg</em></h6>&#13;
</div></figure>&#13;
&#13;
<p>Alternatively, we <a data-primary="scatterplots" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="idm46274539872824"/><a data-primary="pairplots" data-type="indexterm" id="idm46274539871544"/><a data-primary="pairs() function, R" data-type="indexterm" id="idm46274539870872"/><a data-primary="visualization of data" data-secondary="pairplots" data-type="indexterm" id="idm46274539870200"/>could use the <code>pairs()</code> function from base R to produce a pairplot of all combinations of variables, laid out similarly to a correlation matrix. <a data-type="xref" href="#pairplot">Figure 9-5</a> is a pairplot of selected variables from <em>mpg</em>:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">select</code><code class="p">(</code><code class="n">mpg</code><code class="p">,</code> <code class="n">mpg</code><code class="o">:</code><code class="n">horsepower</code><code class="p">)</code> <code class="o">%&gt;%</code>&#13;
  <code class="nf">pairs</code><code class="p">()</code></pre>&#13;
&#13;
<figure class="width-80"><div class="figure" id="pairplot">&#13;
<img alt="Pairplot" src="assets/aina_0905.png"/>&#13;
<h6><span class="label">Figure 9-5. </span>Pairplot</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Linear Regression" data-type="sect2"><div class="sect2" id="idm46274540090120">&#13;
<h2>Linear Regression</h2>&#13;
&#13;
<p>We’re ready <a data-startref="ch9_term10" data-type="indexterm" id="idm46274539813080"/>now for <a data-primary="lm() function, R" data-type="indexterm" id="idm46274539812216"/><a data-primary="regression model" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="idm46274539861704"/><a data-primary="linear regression" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="ch9_term18"/>linear regression, using base R’s <code>lm()</code> function (this is short for <em>linear model</em>). Similar to <code>t.test()</code>, we will specify a dataset and a formula. Linear regression returns a fair amount more output than a t-test, so it’s common to assign the results to a new object in R first, then explore its various elements separately. In <a data-primary="summary() function, R" data-type="indexterm" id="idm46274539857384"/>particular, the <code>summary()</code> function provides a helpful overview of the regression model:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="n">mpg_regression</code> <code class="o">&lt;-</code> <code class="nf">lm</code><code class="p">(</code><code class="n">mpg</code> <code class="o">~</code> <code class="n">weight</code><code class="p">,</code> <code class="n">data</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">)</code>&#13;
<code class="nf">summary</code><code class="p">(</code><code class="n">mpg_regression</code><code class="p">)</code>&#13;
&#13;
<code class="c1">#&gt;     Call:</code>&#13;
<code class="c1">#&gt;     lm(formula = mpg ~ weight, data = mpg)</code>&#13;
<code class="c1">#&gt;</code>&#13;
<code class="c1">#&gt;     Residuals:</code>&#13;
<code class="c1">#&gt;         Min       1Q   Median       3Q      Max</code>&#13;
<code class="c1">#&gt;     -11.9736  -2.7556  -0.3358   2.1379  16.5194</code>&#13;
<code class="c1">#&gt;</code>&#13;
<code class="c1">#&gt;     Coefficients:</code>&#13;
<code class="c1">#&gt;                 Estimate Std. Error t value Pr(&gt;|t|)</code>&#13;
<code class="c1">#&gt;     (Intercept) 46.216524   0.798673   57.87   &lt;2e-16 ***</code>&#13;
<code class="c1">#&gt;     weight      -0.007647   0.000258  -29.64   &lt;2e-16 ***</code>&#13;
<code class="c1">#&gt;     ---</code>&#13;
<code class="c1">#&gt;     Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</code>&#13;
<code class="c1">#&gt;</code>&#13;
<code class="c1">#&gt;     Residual standard error: 4.333 on 390 degrees of freedom</code>&#13;
<code class="c1">#&gt;     Multiple R-squared:  0.6926,	Adjusted R-squared:  0.6918</code>&#13;
<code class="c1">#&gt;     F-statistic: 878.8 on 1 and 390 DF,  p-value: &lt; 2.2e-16</code></pre>&#13;
&#13;
<p>This output should look familiar. Here you’ll see the coefficients, p-values, and R-squared, among other figures. Again, there does appear to be a significant influence of weight on <a data-startref="ch9_term14" data-type="indexterm" id="idm46274539793464"/><a data-startref="ch9_term13" data-type="indexterm" id="idm46274539772040"/>mileage.</p>&#13;
&#13;
<p>Last but not least, we can <a data-primary="regression line, fitting" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="idm46274539770888"/><a data-primary="fitting regression line" data-type="indexterm" id="idm46274539769288"/>fit this regression line over the scatterplot by <a data-primary="geom_smooth() function, R" data-type="indexterm" id="idm46274539768488"/><a data-primary="ggplot() function, R" data-type="indexterm" id="idm46274539767848"/><a data-primary="lm method, R" data-type="indexterm" id="idm46274539767176"/><a data-primary="scatterplots" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="idm46274539766504"/><a data-primary="ggplot2, R" data-type="indexterm" id="idm46274539765288"/><a data-primary="visualization of data" data-secondary="with ggplot2" data-secondary-sortas="ggplot2" data-type="indexterm" id="idm46274539764616"/>including <code>geom_smooth()</code> in our <code>ggplot()</code> function, setting <code>method</code> to <code>lm</code>. This results in <a data-type="xref" href="#mpg-fit-scatter">Figure 9-6</a>:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">ggplot</code><code class="p">(</code><code class="n">data</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">,</code> <code class="nf">aes</code><code class="p">(</code><code class="n">x</code> <code class="o">=</code> <code class="n">weight</code><code class="p">,</code> <code class="n">y</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">))</code> <code class="o">+</code>&#13;
  <code class="nf">geom_point</code><code class="p">()</code> <code class="o">+</code> <code class="nf">xlab</code><code class="p">(</code><code class="s">'weight (pounds)'</code><code class="p">)</code> <code class="o">+</code>&#13;
  <code class="nf">ylab</code><code class="p">(</code><code class="s">'mileage (mpg)'</code><code class="p">)</code> <code class="o">+</code> <code class="nf">ggtitle</code><code class="p">(</code><code class="s">'Relationship between weight and mileage'</code><code class="p">)</code> <code class="o">+</code>&#13;
  <code class="nf">geom_smooth</code><code class="p">(</code><code class="n">method</code> <code class="o">=</code> <code class="n">lm</code><code class="p">)</code>&#13;
<code class="c1">#&gt; `geom_smooth()` using formula 'y ~ x'</code></pre>&#13;
&#13;
<figure><div class="figure" id="mpg-fit-scatter">&#13;
<img alt="Fit scatterplot" src="assets/aina_0906.png"/>&#13;
<h6><span class="label">Figure 9-6. </span>Scatterplot with fit regression line of <em>weight</em> by <em>mpg</em></h6>&#13;
</div></figure>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46274539680360">&#13;
<h5>Confidence Intervals and Linear Regression</h5>&#13;
<p>Take a look at the shaded area along the fit line in <a data-type="xref" href="#mpg-fit-scatter">Figure 9-6</a>. This is the <a data-primary="confidence intervals" data-secondary="in R" data-secondary-sortas="R" data-type="indexterm" id="idm46274539677880"/>confidence interval of the regression slope, indicating with 95% confidence where we believe the true population <a data-startref="ch9_term15" data-type="indexterm" id="idm46274539676376"/><a data-startref="ch9_term16" data-type="indexterm" id="idm46274539675704"/><a data-startref="ch9_term17" data-type="indexterm" id="idm46274539675032"/><a data-startref="ch9_term18" data-type="indexterm" id="idm46274539674360"/>estimate might be for each value of <em>x</em>.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Train/Test Split and Validation" data-type="sect2"><div class="sect2" id="idm46274539673048">&#13;
<h2>Train/Test Split and Validation</h2>&#13;
&#13;
<p><a data-type="xref" href="ch05.html#data-analytics-stack">Chapter 5</a> briefly reviewed how machine learning relates to working with data more broadly. A technique popularized by <a data-primary="machine learning" data-type="indexterm" id="idm46274539669944"/>machine learning that you may encounter in your <a data-primary="subsetting" data-secondary="with train/test splits" data-secondary-sortas="train/test splits" data-type="indexterm" id="ch9_term20"/><a data-primary="train/test split and validation" data-type="indexterm" id="ch9_term21"/><a data-primary="splitting data" data-type="indexterm" id="ch9_term22"/><a data-primary="datasets" data-secondary="training and testing" data-type="indexterm" id="ch9_term23"/><a data-primary="testing and training datasets" data-type="indexterm" id="ch9_term24"/><a data-primary="training and testing datasets" data-type="indexterm" id="ch9_term25"/>data analytics work is the <em>train/test split</em>. The idea here is to <em>train</em> the model on a subset of your data, then <em>test</em> it on another subset. This provides assurance that the model doesn’t just work on one particular sampling of observations, but can generalize to the wider population. Data scientists are often especially interested in how well the model does at making predictions on the testing data.</p>&#13;
&#13;
<p>Let’s <a data-primary="datasets" data-secondary="mpg example" data-type="indexterm" id="idm46274539660504"/><a data-primary="mpg dataset example" data-type="indexterm" id="idm46274539659496"/><a data-primary="vehicle mileage (mpg) dataset example" data-type="indexterm" id="idm46274539658824"/><a data-primary="linear regression" data-secondary="mpg dataset example for" data-type="indexterm" id="idm46274539658184"/>split our <em>mpg</em> dataset in R, train the <a data-primary="regression model" data-secondary="with R" data-secondary-sortas="R" data-type="indexterm" id="idm46274539656696"/>linear regression model on part of the data, and then test it on the remainder. To do so, we’ll <a data-primary="tidymodels package, R" data-type="indexterm" id="ch9_term19"/>use the <code>tidymodels</code> package. While not part of the <code>tidyverse</code>, this package is built along the same principles and thus works well with it.</p>&#13;
&#13;
<p>You may remember in <a data-type="xref" href="ch02.html#foundations-of-probability">Chapter 2</a> that, because we were using random numbers, the results you saw in your workbook were different than what was documented in the book. Because we’ll again be splitting our dataset randomly here, we could encounter that same problem. To avoid that, we can <a data-primary="set.seed() function, R" data-type="indexterm" id="idm46274539651640"/>set the <em>seed</em> of R’s random number generator, which results in the same series of random numbers being generated each time. This can be done with the <code>set.seed()</code> function. You can set it to any number; <code>1234</code> is common:</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">set.seed</code><code class="p">(</code><code class="m">1234</code><code class="p">)</code></pre>&#13;
&#13;
<p>To begin the split, we can <a data-primary="initial_split() function, R" data-type="indexterm" id="idm46274539595160"/>use the aptly named <code>initial_split()</code> function; from there, we’ll <a data-primary="testing() function, R" data-type="indexterm" id="idm46274539594040"/><a data-primary="training() function, R" data-type="indexterm" id="idm46274539593400"/>subset our data into training and testing datasets with the <code>training()</code> and <code>testing()</code> functions, respectively.</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="n">mpg_split</code> <code class="o">&lt;-</code> <code class="nf">initial_split</code><code class="p">(</code><code class="n">mpg</code><code class="p">)</code>&#13;
<code class="n">mpg_train</code> <code class="o">&lt;-</code> <code class="nf">training</code><code class="p">(</code><code class="n">mpg_split</code><code class="p">)</code>&#13;
<code class="n">mpg_test</code> <code class="o">&lt;-</code> <code class="nf">testing</code><code class="p">(</code><code class="n">mpg_split</code><code class="p">)</code></pre>&#13;
&#13;
<p>By default, <code>tidymodels</code> splits the data’s observations into two groups at random: 75% of the observations went to the training group, the remainder to the test. We can <a data-primary="dim() function, R" data-type="indexterm" id="idm46274539571304"/>confirm that with the <code>dim()</code> function from <a data-primary="base R" data-type="indexterm" id="idm46274539570152"/><a data-primary="R programming language" data-secondary="base R" data-type="indexterm" id="idm46274539569416"/>base R to get the number of rows and columns in each dataset, respectively:</p>&#13;
&#13;
<pre class="pagebreak-before" data-code-language="r" data-type="programlisting"><code class="nf">dim</code><code class="p">(</code><code class="n">mpg_train</code><code class="p">)</code>&#13;
<code class="c1">#&gt; [1] 294   5</code>&#13;
<code class="nf">dim</code><code class="p">(</code><code class="n">mpg_test</code><code class="p">)</code>&#13;
<code class="c1">#&gt; [1] 98  5</code></pre>&#13;
&#13;
<p>At 294 and 98 observations, our training and testing <a data-primary="sample size" data-secondary="in train/test splits" data-secondary-sortas="train/test splits" data-type="indexterm" id="idm46274539565672"/>sample sizes should be sufficiently large for reflective statistical inference. While it’s not often a consideration for the massive datasets used in machine learning, adequate sample size can be a limitation when splitting data.</p>&#13;
&#13;
<p>It’s possible to split the data into other proportions than 75/25, to use special techniques for splitting the data, and so forth. For more information, check the <code>tidymodels</code> documentation; until you become more comfortable with regression analysis, the <a data-startref="ch9_term20" data-type="indexterm" id="idm46274539561848"/><a data-startref="ch9_term21" data-type="indexterm" id="idm46274539561144"/><a data-startref="ch9_term22" data-type="indexterm" id="idm46274539560472"/>defaults are fine.</p>&#13;
&#13;
<p>To build our training model, we’ll <a data-primary="linear_reg() function, R" data-type="indexterm" id="idm46274539559032"/>first <em>specify</em> what type of model it is with the &#13;
<span class="keep-together"><code>linear_reg()</code></span> function, then <em>fit</em> it. The inputs of <a data-primary="fit() function, R" data-type="indexterm" id="idm46274539556552"/>the <code>fit()</code> function should look familiar to you, except this time we are using the training subset of <em>mpg</em> only.</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="c1"># Specify what kind of model this is</code>&#13;
<code class="n">lm_spec</code> <code class="o">&lt;-</code> <code class="nf">linear_reg</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># Fit the model to the data</code>&#13;
<code class="n">lm_fit</code> <code class="o">&lt;-</code> <code class="n">lm_spec</code> <code class="o">%&gt;%</code>&#13;
  <code class="nf">fit</code><code class="p">(</code><code class="n">mpg</code> <code class="o">~</code> <code class="n">weight</code><code class="p">,</code> <code class="n">data</code> <code class="o">=</code> <code class="n">mpg_train</code><code class="p">)</code>&#13;
<code class="c1">#&gt; Warning message:</code>&#13;
<code class="c1">#&gt; Engine set to `lm`.</code></pre>&#13;
&#13;
<p>You will see from your console output <a data-primary="lm() function, R" data-type="indexterm" id="idm46274539480664"/>that the <code>lm()</code> function from base R, which you’ve used before, was used as the <em>engine</em> to fit the model.</p>&#13;
&#13;
<p>We can get the coefficients and <a data-primary="p-values" data-secondary="in R" data-secondary-sortas="R" data-type="indexterm" id="idm46274539478488"/>p-values of our training model <a data-primary="tidy() function, R" data-type="indexterm" id="idm46274539477112"/>with the <code>tidy()</code> function, and its <a data-primary="glance() function, R" data-type="indexterm" id="idm46274539475896"/>performance metrics (such as R-squared) with <code>glance()</code>.</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">tidy</code><code class="p">(</code><code class="n">lm_fit</code><code class="p">)</code>&#13;
<code class="c1">#&gt; # A tibble: 2 x 5</code>&#13;
<code class="c1">#&gt;   term        estimate std.error statistic   p.value</code>&#13;
<code class="c1">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</code>&#13;
<code class="c1">#&gt; 1 (Intercept) 47.3      0.894         52.9 1.37e-151</code>&#13;
<code class="c1">#&gt; 2 weight      -0.00795  0.000290     -27.5 6.84e- 83</code>&#13;
<code class="c1">#&gt;</code>&#13;
<code class="nf">glance</code><code class="p">(</code><code class="n">lm_fit</code><code class="p">)</code>&#13;
<code class="c1">#&gt; # A tibble: 1 x 12</code>&#13;
<code class="c1">#&gt;   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC</code>&#13;
<code class="c1">#&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;</code>&#13;
<code class="c1">#&gt; 1     0.721         0.720  4.23      754. 6.84e-83     1  -840. 1687.</code>&#13;
<code class="c1">#&gt; # ... with 4 more variables: BIC &lt;dbl&gt;, deviance &lt;dbl&gt;,</code>&#13;
<code class="c1">#&gt; #   df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>&#13;
&#13;
<p>This is great, but what we <em>really</em> want to know is how well this model performs when we apply it to a new dataset; this is where the test split comes in. To make <a data-primary="predict() function, R and Python" data-type="indexterm" id="idm46274539463992"/>predictions on <code>mpg_test</code>, we’ll use the <code>predict()</code> function. I will also <a data-primary="bind_cols() function, R" data-type="indexterm" id="idm46274539462456"/>use <code>bind_cols()</code> to add the column of predicted Y-values to the data frame. This column by default will be called <code>.pred</code>.</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="n">mpg_results</code> <code class="o">&lt;-</code> <code class="nf">predict</code><code class="p">(</code><code class="n">lm_fit</code><code class="p">,</code> <code class="n">new_data</code> <code class="o">=</code> <code class="n">mpg_test</code><code class="p">)</code> <code class="o">%&gt;%</code>&#13;
  <code class="nf">bind_cols</code><code class="p">(</code><code class="n">mpg_test</code><code class="p">)</code>&#13;
&#13;
<code class="n">mpg_results</code>&#13;
<code class="c1">#&gt; # A tibble: 98 x 6</code>&#13;
<code class="c1">#&gt;    .pred   mpg weight horsepower origin cylinders</code>&#13;
<code class="c1">#&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;</code>&#13;
<code class="c1">#&gt;  1  20.0    16   3433        150 USA            8</code>&#13;
<code class="c1">#&gt;  2  16.7    15   3850        190 USA            8</code>&#13;
<code class="c1">#&gt;  3  25.2    18   2774         97 USA            6</code>&#13;
<code class="c1">#&gt;  4  30.3    27   2130         88 Asia           4</code>&#13;
<code class="c1">#&gt;  5  28.0    24   2430         90 Europe         4</code>&#13;
<code class="c1">#&gt;  6  21.0    19   3302         88 USA            6</code>&#13;
<code class="c1">#&gt;  7  14.2    14   4154        153 USA            8</code>&#13;
<code class="c1">#&gt;  8  14.7    14   4096        150 USA            8</code>&#13;
<code class="c1">#&gt;  9  29.6    23   2220         86 USA            4</code>&#13;
<code class="c1">#&gt; 10  29.2    24   2278         95 Asia           4</code>&#13;
<code class="c1">#&gt; # ... with 88 more rows</code></pre>&#13;
&#13;
<p>Now that we’ve applied the model to this new data, let’s <a data-primary="evaluation metrics" data-type="indexterm" id="idm46274539309688"/>evaluate its performance. We can, for example, find its <a data-primary="R-squared (coefficient of determination)" data-type="indexterm" id="idm46274539358488"/><a data-primary="coefficient of determination (R-squared)" data-type="indexterm" id="idm46274539357752"/><a data-primary="rsq() function, R" data-type="indexterm" id="idm46274539357080"/>R-squared with the <code>rsq()</code> function. From our <code>mpg_results</code> data frame, we’ll need to specify which column contains the actual Y values with the <code>truth</code> argument, and which are predictions with the <code>estimate</code> column.</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">rsq</code><code class="p">(</code><code class="n">data</code> <code class="o">=</code> <code class="n">mpg_results</code><code class="p">,</code> <code class="n">truth</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">,</code> <code class="n">estimate</code> <code class="o">=</code> <code class="n">.pred</code><code class="p">)</code>&#13;
<code class="c1">#&gt; # A tibble: 1 x 3</code>&#13;
<code class="c1">#&gt;   .metric .estimator .estimate</code>&#13;
<code class="c1">#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;</code>&#13;
<code class="c1">#&gt; 1 rsq     standard       0.606</code></pre>&#13;
&#13;
<p>At an R-squared of 60.6%, the model derived from the training dataset explains a fair amount of variability in the testing data.</p>&#13;
&#13;
<p>Another common evaluation metric is the <a data-primary="RMSE (root mean square error)" data-type="indexterm" id="idm46274539280680"/>root mean square error (RMSE). You learned about the <a data-primary="residuals" data-type="indexterm" id="idm46274539348536"/>concept of <em>residuals</em> in <a data-type="xref" href="ch04.html#foundations-of-data-analytics">Chapter 4</a> as the difference between actual and predicted values; RMSE is the <a data-primary="standard deviations" data-type="indexterm" id="idm46274539346552"/><a data-primary="descriptive statistics" data-secondary="for standard deviations" data-secondary-sortas="standard deviations" data-type="indexterm" id="idm46274539345880"/>standard deviation of the residuals and thus an estimate of how spread errors tend to be. The <code>rmse()</code> function returns the RMSE.</p>&#13;
&#13;
<pre data-code-language="r" data-type="programlisting"><code class="nf">rmse</code><code class="p">(</code><code class="n">data</code> <code class="o">=</code> <code class="n">mpg_results</code><code class="p">,</code> <code class="n">truth</code> <code class="o">=</code> <code class="n">mpg</code><code class="p">,</code> <code class="n">estimate</code> <code class="o">=</code> <code class="n">.pred</code><code class="p">)</code>&#13;
<code class="c1">#&gt; # A tibble: 1 x 3</code>&#13;
<code class="c1">#&gt;   .metric .estimator .estimate</code>&#13;
<code class="c1">#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;</code>&#13;
<code class="c1">#&gt; 1 rmse    standard        4.65</code></pre>&#13;
&#13;
<p>Because it’s <a data-primary="dependent variables" data-secondary="root mean square error and" data-type="indexterm" id="idm46274539259560"/>relative to the scale of the dependent variable, there’s no one-size-fits-all way to evaluate RMSE, but between two competing models using the same data, a smaller RMSE is preferred.</p>&#13;
&#13;
<p><code>tidymodels</code> makes numerous techniques available for fitting and evaluating models in <a data-startref="ch9_term19" data-type="indexterm" id="idm46274539257512"/><a data-startref="ch9_term23" data-type="indexterm" id="idm46274539256808"/><a data-startref="ch9_term24" data-type="indexterm" id="idm46274539256136"/><a data-startref="ch9_term25" data-type="indexterm" id="idm46274539255464"/>R. We’ve looked at a regression model, which takes a continuous dependent variable, but it’s also possible to <a data-primary="classification models" data-type="indexterm" id="idm46274539254536"/>build <em>classification</em> models, where the dependent variable is <a data-primary="categorical variables" data-secondary="in R" data-secondary-sortas="R" data-type="indexterm" id="idm46274539253256"/>categorical. This package is a relative newcomer to R, so there is somewhat less literature available, but expect more to come as the package grows in popularity.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm46274539672072">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>There is, of course, much more you could do to explore and test the relationships in this and other datasets, but the steps we’ve taken here serve as a solid opening. Earlier, you were able to conduct and interpret this work in Excel, and now you’ve leaped <a data-startref="ch9_term11" data-type="indexterm" id="idm46274539250664"/><a data-startref="ch9_term12" data-type="indexterm" id="idm46274539249960"/>into doing it in R.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exercises" data-type="sect1"><div class="sect1" id="idm46274539248904">&#13;
<h1>Exercises</h1>&#13;
&#13;
<p>Take a moment to try your <a data-primary="R programming language" data-secondary="exercises" data-type="indexterm" id="idm46274539247352"/>hand at analyzing a familiar dataset with familiar steps, now using R. At the end of <a data-type="xref" href="ch04.html#foundations-of-data-analytics">Chapter 4</a>, you practiced analyzing <a data-primary="ais dataset example" data-type="indexterm" id="idm46274539245480"/><a data-primary="datasets" data-secondary="ais example" data-type="indexterm" id="idm46274539244808"/>data from the <code>ais</code> dataset in the <a href="https://oreil.ly/egOx1">book repository</a>. This data is available in the R package <code>DAAG</code>; try installing and loading it from there (it is available as the object <code>ais</code>). Do the following:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Visualize the distribution of red blood cell count (<em>rcc</em>) by sex (<em>sex</em>).</p>&#13;
</li>&#13;
<li>&#13;
<p>Is there a significant difference in red blood cell count between the two groups of sex?</p>&#13;
</li>&#13;
<li>&#13;
<p>Produce a correlation matrix of the relevant variables in this dataset.</p>&#13;
</li>&#13;
<li>&#13;
<p>Visualize the relationship of height (<em>ht</em>) and weight (<em>wt</em>).</p>&#13;
</li>&#13;
<li>&#13;
<p>Regress <em>ht</em> on <em>wt</em>. Find the equation of the fit regression line. Is there a significant relationship? What percentage of the variance in <em>ht</em> is explained by <em>wt</em>?</p>&#13;
</li>&#13;
<li>&#13;
<p>Split your regression model into training and testing subsets. What is the R-squared and RMSE on your test model?</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>