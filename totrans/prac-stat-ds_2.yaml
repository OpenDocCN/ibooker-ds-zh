- en: Chapter 2\. Data and Sampling Distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A popular misconception holds that the era of big data means the end of a need
    for sampling. In fact, the proliferation of data of varying quality and relevance
    reinforces the need for sampling as a tool to work efficiently with a variety
    of data and to minimize bias. Even in a big data project, predictive models are
    typically developed and piloted with samples. Samples are also used in tests of
    various sorts (e.g., comparing the effect of web page designs on clicks).
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 2-1](#sampling_schematic) shows a schematic that underpins the concepts
    we will discuss in this chapter—data and sampling distributions. The lefthand
    side represents a population that, in statistics, is assumed to follow an underlying
    but *unknown* distribution. All that is available is the *sample* data and its
    empirical distribution, shown on the righthand side. To get from the lefthand
    side to the righthand side, a *sampling* procedure is used (represented by an
    arrow). Traditional statistics focused very much on the lefthand side, using theory
    based on strong assumptions about the population. Modern statistics has moved
    to the righthand side, where such assumptions are not needed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, data scientists need not worry about the theoretical nature of
    the lefthand side and instead should focus on the sampling procedures and the
    data at hand. There are some notable exceptions. Sometimes data is generated from
    a physical process that can be modeled. The simplest example is flipping a coin:
    this follows a binomial distribution. Any real-life binomial situation (buy or
    don’t buy, fraud or no fraud, click or don’t click) can be modeled effectively
    by a coin (with modified probability of landing heads, of course). In these cases,
    we can gain additional insight by using our understanding of the population.'
  prefs: []
  type: TYPE_NORMAL
- en: '![images/sampling_schematic.png](Images/psd2_0201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. Population versus sample
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Random Sampling and Sample Bias
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A *sample* is a subset of data from a larger data set; statisticians call this
    larger data set the *population*. A population in statistics is not the same thing
    as in biology—it is a large, defined (but sometimes theoretical or imaginary)
    set of data.
  prefs: []
  type: TYPE_NORMAL
- en: '*Random sampling* is a process in which each available member of the population
    being sampled has an equal chance of being chosen for the sample at each draw.
    The sample that results is called a *simple random sample*. Sampling can be done
    *with replacement*, in which observations are put back in the population after
    each draw for possible future reselection. Or it can be done *without replacement*,
    in which case observations, once selected, are unavailable for future draws.'
  prefs: []
  type: TYPE_NORMAL
- en: Data quality often matters more than data quantity when making an estimate or
    a model based on a sample. Data quality in data science involves completeness,
    consistency of format, cleanliness, and accuracy of individual data points. Statistics
    adds the notion of *representativeness*.
  prefs: []
  type: TYPE_NORMAL
- en: The classic example is the *Literary Digest* poll of 1936 that predicted a victory
    of Alf Landon over Franklin Roosevelt. The *Literary Digest*, a leading periodical
    of the day, polled its entire subscriber base plus additional lists of individuals,
    a total of over 10 million people, and predicted a landslide victory for Landon.
    George Gallup, founder of the Gallup Poll, conducted biweekly polls of just 2,000
    people and accurately predicted a Roosevelt victory. The difference lay in the
    selection of those polled.
  prefs: []
  type: TYPE_NORMAL
- en: The *Literary Digest* opted for quantity, paying little attention to the method
    of selection. They ended up polling those with relatively high socioeconomic status
    (their own subscribers, plus those who, by virtue of owning luxuries like telephones
    and automobiles, appeared in marketers’ lists). The result was *sample bias*;
    that is, the sample was different in some meaningful and nonrandom way from the
    larger population it was meant to represent. The term *nonrandom* is important—hardly
    any sample, including random samples, will be exactly representative of the population.
    Sample bias occurs when the difference is meaningful, and it can be expected to
    continue for other samples drawn in the same way as the first.
  prefs: []
  type: TYPE_NORMAL
- en: Self-Selection Sampling Bias
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The reviews of restaurants, hotels, cafés, and so on that you read on social
    media sites like Yelp are prone to bias because the people submitting them are
    not randomly selected; rather, they themselves have taken the initiative to write.
    This leads to self-selection bias—the people motivated to write reviews may have
    had poor experiences, may have an association with the establishment, or may simply
    be a different type of person from those who do not write reviews. Note that while
    self-selection samples can be unreliable indicators of the true state of affairs,
    they may be more reliable in simply comparing one establishment to a similar one;
    the same self-selection bias might apply to each.
  prefs: []
  type: TYPE_NORMAL
- en: Bias
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Statistical bias refers to measurement or sampling errors that are systematic
    and produced by the measurement or sampling process. An important distinction
    should be made between errors due to random chance and errors due to bias. Consider
    the physical process of a gun shooting at a target. It will not hit the absolute
    center of the target every time, or even much at all. An unbiased process will
    produce error, but it is random and does not tend strongly in any direction (see
    [Figure 2-2](#gun1)). The results shown in [Figure 2-3](#gun2) show a biased process—there
    is still random error in both the x and y direction, but there is also a bias.
    Shots tend to fall in the upper-right quadrant.
  prefs: []
  type: TYPE_NORMAL
- en: '![images/Target-scatter.png](Images/psd2_0202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-2\. Scatterplot of shots from a gun with true aim
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![images/Target-scatter-bias.png](Images/psd2_0203.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-3\. Scatterplot of shots from a gun with biased aim
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Bias comes in different forms, and may be observable or invisible. When a result
    does suggest bias (e.g., by reference to a benchmark or actual values), it is
    often an indicator that a statistical or machine learning model has been misspecified,
    or an important variable left out.
  prefs: []
  type: TYPE_NORMAL
- en: Random Selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To avoid the problem of sample bias that led the *Literary Digest* to predict
    Landon over Roosevelt, George Gallup (shown in [Figure 2-4](#Gallup)) opted for
    more scientifically chosen methods to achieve a sample that was representative
    of the US voting electorate. There are now a variety of methods to achieve representativeness,
    but at the heart of all of them lies *random sampling*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Gallup](Images/psd2_0204.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-4\. George Gallup, catapulted to fame by the *Literary Digest’s* “big
    data” failure
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Random sampling is not always easy. Proper definition of an accessible population
    is key. Suppose we want to generate a representative profile of customers and
    we need to conduct a pilot customer survey. The survey needs to be representative
    but is labor intensive.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to define who a customer is. We might select all customer records
    where purchase amount > 0. Do we include all past customers? Do we include refunds?
    Internal test purchases? Resellers? Both billing agent and customer?
  prefs: []
  type: TYPE_NORMAL
- en: Next, we need to specify a sampling procedure. It might be “select 100 customers
    at random.” Where a sampling from a flow is involved (e.g., real-time customer
    transactions or web visitors), timing considerations may be important (e.g., a
    web visitor at 10 a.m. on a weekday may be different from a web visitor at 10
    p.m. on a weekend).
  prefs: []
  type: TYPE_NORMAL
- en: In *stratified sampling*, the population is divided up into *strata*, and random
    samples are taken from each stratum. Political pollsters might seek to learn the
    electoral preferences of whites, blacks, and Hispanics. A simple random sample
    taken from the population would yield too few blacks and Hispanics, so those strata
    could be overweighted in stratified sampling to yield equivalent sample sizes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Size Versus Quality: When Does Size Matter?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the era of big data, it is sometimes surprising that smaller is better. Time
    and effort spent on random sampling not only reduces bias but also allows greater
    attention to data exploration and data quality. For example, missing data and
    outliers may contain useful information. It might be prohibitively expensive to
    track down missing values or evaluate outliers in millions of records, but doing
    so in a sample of several thousand records may be feasible. Data plotting and
    manual inspection bog down if there is too much data.
  prefs: []
  type: TYPE_NORMAL
- en: So when *are* massive amounts of data needed?
  prefs: []
  type: TYPE_NORMAL
- en: The classic scenario for the value of big data is when the data is not only
    big but sparse as well. Consider the search queries received by Google, where
    columns are terms, rows are individual search queries, and cell values are either
    0 or 1, depending on whether a query contains a term. The goal is to determine
    the best predicted search destination for a given query. There are over 150,000
    words in the English language, and Google processes over one trillion queries
    per year. This yields a huge matrix, the vast majority of whose entries are “0.”
  prefs: []
  type: TYPE_NORMAL
- en: This is a true big data problem—only when such enormous quantities of data are
    accumulated can effective search results be returned for most queries. And the
    more data accumulates, the better the results. For popular search terms this is
    not such a problem—effective data can be found fairly quickly for the handful
    of extremely popular topics trending at a particular time. The real value of modern
    search technology lies in the ability to return detailed and useful results for
    a huge variety of search queries, including those that occur with a frequency,
    say, of only one in a million.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the search phrase “Ricky Ricardo and Little Red Riding Hood.” In the
    early days of the internet, this query would probably have returned results on
    the bandleader Ricky Ricardo, the television show *I Love Lucy* in which that
    character appeared, and the children’s story *Little Red Riding Hood*. Both of
    those individual items would have had many searches to refer to, but the combination
    would have had very few. Later, now that trillions of search queries have been
    accumulated, this search query returns the exact *I Love Lucy* episode in which
    Ricky narrates, in dramatic fashion, the *Little Red Riding Hood* story to his
    infant son in a comic mix of English and Spanish.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the number of actual *pertinent* records—ones in which this
    exact search query, or something very similar, appears (together with information
    on what link people ultimately clicked on)—might need only be in the thousands
    to be effective. However, many trillions of data points are needed to obtain these
    pertinent records (and random sampling, of course, will not help). See also [“Long-Tailed
    Distributions”](#LongTailedData).
  prefs: []
  type: TYPE_NORMAL
- en: Sample Mean Versus Population Mean
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The symbol <math alttext="x overbar"><mover accent="true"><mi>x</mi> <mo>¯</mo></mover></math>
    (pronounced “x-bar”) is used to represent the mean of a sample from a population,
    whereas <math alttext="mu"><mi>μ</mi></math> is used to represent the mean of
    a population. Why make the distinction? Information about samples is observed,
    and information about large populations is often inferred from smaller samples.
    Statisticians like to keep the two things separate in the symbology.
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A useful review of sampling procedures can be found in Ronald Fricker’s chapter
    “Sampling Methods for Online Surveys” in *The SAGE Handbook of Online Research
    Methods*, 2nd ed., edited by Nigel G. Fielding, Raymond M. Lee, and Grant Blank
    (SAGE Publications, 2016). This chapter includes a review of the modifications
    to random sampling that are often used for practical reasons of cost or feasibility.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The story of the *Literary Digest* poll failure can be found on the [Capital
    Century website](https://oreil.ly/iSoQT).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selection Bias
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To paraphrase Yogi Berra: if you don’t know what you’re looking for, look hard
    enough and you’ll find it.'
  prefs: []
  type: TYPE_NORMAL
- en: Selection bias refers to the practice of selectively choosing data—consciously
    or unconsciously—in a way that leads to a conclusion that is misleading or ephemeral.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you specify a hypothesis and conduct a well-designed experiment to test
    it, you can have high confidence in the conclusion. This is frequently not what
    occurs, however. Often, one looks at available data and tries to discern patterns.
    But are the patterns real? Or are they just the product of *data snooping*—that
    is, extensive hunting through the data until something interesting emerges? There
    is a saying among statisticians: “If you torture the data long enough, sooner
    or later it will confess.”'
  prefs: []
  type: TYPE_NORMAL
- en: The difference between a phenomenon that you verify when you test a hypothesis
    using an experiment and a phenomenon that you discover by perusing available data
    can be illuminated with the following thought experiment.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that someone tells you they can flip a coin and have it land heads on
    the next 10 tosses. You challenge them (the equivalent of an experiment), and
    they proceed to toss the coin 10 times, with all flips landing heads. Clearly
    you ascribe some special talent to this person—the probability that 10 coin tosses
    will land heads just by chance is 1 in 1,000.
  prefs: []
  type: TYPE_NORMAL
- en: Now imagine that the announcer at a sports stadium asks the 20,000 people in
    attendance each to toss a coin 10 times, and to report to an usher if they get
    10 heads in a row. The chance that *somebody* in the stadium will get 10 heads
    is extremely high (more than 99%—it’s 1 minus the probability that nobody gets
    10 heads). Clearly, selecting after the fact the person (or persons) who gets
    10 heads at the stadium does not indicate they have any special talent—it’s most
    likely luck.
  prefs: []
  type: TYPE_NORMAL
- en: Since repeated review of large data sets is a key value proposition in data
    science, selection bias is something to worry about. A form of selection bias
    of particular concern to data scientists is what John Elder (founder of Elder
    Research, a respected data mining consultancy) calls the *vast search effect*.
    If you repeatedly run different models and ask different questions with a large
    data set, you are bound to find something interesting. But is the result you found
    truly something interesting, or is it the chance outlier?
  prefs: []
  type: TYPE_NORMAL
- en: We can guard against this by using a holdout set, and sometimes more than one
    holdout set, against which to validate performance. Elder also advocates the use
    of what he calls *target shuffling* (a permutation test, in essence) to test the
    validity of predictive associations that a data mining model suggests.
  prefs: []
  type: TYPE_NORMAL
- en: Typical forms of selection bias in statistics, in addition to the vast search
    effect, include nonrandom sampling (see [“Random Sampling and Sample Bias”](#randomSampling_bias)),
    cherry-picking data, selection of time intervals that accentuate a particular
    statistical effect, and stopping an experiment when the results look “interesting.”
  prefs: []
  type: TYPE_NORMAL
- en: Regression to the Mean
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Regression to the mean* refers to a phenomenon involving successive measurements
    on a given variable: extreme observations tend to be followed by more central
    ones. Attaching special focus and meaning to the extreme value can lead to a form
    of selection bias.'
  prefs: []
  type: TYPE_NORMAL
- en: Sports fans are familiar with the “rookie of the year, sophomore slump” phenomenon.
    Among the athletes who begin their career in a given season (the rookie class),
    there is always one who performs better than all the rest. Generally, this “rookie
    of the year” does not do as well in his second year. Why not?
  prefs: []
  type: TYPE_NORMAL
- en: 'In nearly all major sports, at least those played with a ball or puck, there
    are two elements that play a role in overall performance:'
  prefs: []
  type: TYPE_NORMAL
- en: Skill
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luck
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression to the mean is a consequence of a particular form of selection bias.
    When we select the rookie with the best performance, skill and good luck are probably
    contributing. In his next season, the skill will still be there, but very often
    the luck will not be, so his performance will decline—it will regress. The phenomenon
    was first identified by Francis Galton in 1886 [[Galton-1886]](bibliography01.xhtml#Galton-1886),
    who wrote of it in connection with genetic tendencies; for example, the children
    of extremely tall men tend not to be as tall as their father (see [Figure 2-5](#Galton)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Galton](Images/psd2_0205.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-5\. Galton’s study that identified the phenomenon of regression to
    the mean
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Regression to the mean, meaning to “go back,” is distinct from the statistical
    modeling method of linear regression, in which a linear relationship is estimated
    between predictor variables and an outcome variable.
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Christopher J. Pannucci and Edwin G. Wilkins’ article “Identifying and Avoiding
    Bias in Research” in (surprisingly not a statistics journal) *Plastic and Reconstructive
    Surgery* (August 2010) has an excellent review of various types of bias that can
    enter into research, including selection bias.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Michael Harris’s article [“Fooled by Randomness Through Selection Bias”](https://oreil.ly/v_Q0u)
    provides an interesting review of selection bias considerations in stock market
    trading schemes, from the perspective of traders.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sampling Distribution of a Statistic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term *sampling distribution* of a statistic refers to the distribution of
    some sample statistic over many samples drawn from the same population. Much of
    classical statistics is concerned with making inferences from (small) samples
    to (very large) populations.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, a sample is drawn with the goal of measuring something (with a *sample
    statistic*) or modeling something (with a statistical or machine learning model).
    Since our estimate or model is based on a sample, it might be in error; it might
    be different if we were to draw a different sample. We are therefore interested
    in how different it might be—a key concern is *sampling variability*. If we had
    lots of data, we could draw additional samples and observe the distribution of
    a sample statistic directly. Typically, we will calculate our estimate or model
    using as much data as is easily available, so the option of drawing additional
    samples from the population is not readily available.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It is important to distinguish between the distribution of the individual data
    points, known as *the data distribution*, and the distribution of a sample statistic,
    known as the *sampling distribution*.
  prefs: []
  type: TYPE_NORMAL
- en: The distribution of a sample statistic such as the mean is likely to be more
    regular and bell-shaped than the distribution of the data itself. The larger the
    sample the statistic is based on, the more this is true. Also, the larger the
    sample, the narrower the distribution of the sample statistic.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is illustrated in an example using annual income for loan applicants to
    LendingClub (see [“A Small Example: Predicting Loan Default”](ch06.xhtml#LoanExampleKNN)
    for a description of the data). Take three samples from this data: a sample of
    1,000 values, a sample of 1,000 means of 5 values, and a sample of 1,000 means
    of 20 values. Then plot a histogram of each sample to produce [Figure 2-6](#loans-mean-hist).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Loans histogram](Images/psd2_0206.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-6\. Histogram of annual incomes of 1,000 loan applicants (top), then
    1,000 means of n=5 applicants (middle), and finally 1,000 means of n=20 applicants
    (bottom)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The histogram of the individual data values is broadly spread out and skewed
    toward higher values, as is to be expected with income data. The histograms of
    the means of 5 and 20 are increasingly compact and more bell-shaped. Here is the
    *R* code to generate these histograms, using the visualization package `ggplot2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The *Python* code uses `seaborn`’s `FacetGrid` to show the three histograms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Central Limit Theorem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The phenomenon we’ve just described is termed the *central limit theorem*. It
    says that the means drawn from multiple samples will resemble the familiar bell-shaped
    normal curve (see [“Normal Distribution”](#NormalDist)), even if the source population
    is not normally distributed, provided that the sample size is large enough and
    the departure of the data from normality is not too great. The central limit theorem
    allows normal-approximation formulas like the t-distribution to be used in calculating
    sampling distributions for inference—that is, confidence intervals and hypothesis
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: The central limit theorem receives a lot of attention in traditional statistics
    texts because it underlies the machinery of hypothesis tests and confidence intervals,
    which themselves consume half the space in such texts. Data scientists should
    be aware of this role; however, since formal hypothesis tests and confidence intervals
    play a small role in data science, and the *bootstrap* (see [“The Bootstrap”](#bootstrap))
    is available in any case, the central limit theorem is not so central in the practice
    of data science.
  prefs: []
  type: TYPE_NORMAL
- en: Standard Error
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The *standard error* is a single metric that sums up the variability in the
    sampling distribution for a statistic. The standard error can be estimated using
    a statistic based on the standard deviation *s* of the sample values, and the
    sample size *n*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mtext>Standard</mtext> <mtext>error</mtext> <mo>=</mo>
    <mi>S</mi> <mi>E</mi> <mo>=</mo> <mfrac><mi>s</mi> <msqrt><mi>n</mi></msqrt></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'As the sample size increases, the standard error decreases, corresponding to
    what was observed in [Figure 2-6](#loans-mean-hist). The relationship between
    standard error and sample size is sometimes referred to as the *square root of
    n* rule: to reduce the standard error by a factor of 2, the sample size must be
    increased by a factor of 4.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The validity of the standard error formula arises from the central limit theorem.
    In fact, you don’t need to rely on the central limit theorem to understand standard
    error. Consider the following approach to measuring standard error:'
  prefs: []
  type: TYPE_NORMAL
- en: Collect a number of brand-new samples from the population.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each new sample, calculate the statistic (e.g., mean).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the standard deviation of the statistics computed in step 2; use this
    as your estimate of standard error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In practice, this approach of collecting new samples to estimate the standard
    error is typically not feasible (and statistically very wasteful). Fortunately,
    it turns out that it is not necessary to draw brand new samples; instead, you
    can use *bootstrap* resamples. In modern statistics, the bootstrap has become
    the standard way to estimate standard error. It can be used for virtually any
    statistic and does not rely on the central limit theorem or other distributional
    assumptions.
  prefs: []
  type: TYPE_NORMAL
- en: Standard Deviation Versus Standard Error
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Do not confuse standard deviation (which measures the variability of individual
    data points) with standard error (which measures the variability of a sample metric).
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: David Lane’s [online multimedia resource in statistics](https://oreil.ly/pe7ra)
    has a useful simulation that allows you to select a sample statistic, a sample
    size, and the number of iterations and visualize a histogram of the resulting
    frequency distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The Bootstrap
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One easy and effective way to estimate the sampling distribution of a statistic,
    or of model parameters, is to draw additional samples, with replacement, from
    the sample itself and recalculate the statistic or model for each resample. This
    procedure is called the *bootstrap*, and it does not necessarily involve any assumptions
    about the data or the sample statistic being normally distributed.
  prefs: []
  type: TYPE_NORMAL
- en: Conceptually, you can imagine the bootstrap as replicating the original sample
    thousands or millions of times so that you have a hypothetical population that
    embodies all the knowledge from your original sample (it’s just larger). You can
    then draw samples from this hypothetical population for the purpose of estimating
    a sampling distribution; see [Figure 2-7](#bootstrap-schematic-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![images/Bootstrap-schematic-1.png](Images/psd2_0207.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-7\. The idea of the bootstrap
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In practice, it is not necessary to actually replicate the sample a huge number
    of times. We simply replace each observation after each draw; that is, we *sample
    with replacement*. In this way we effectively create an infinite population in
    which the probability of an element being drawn remains unchanged from draw to
    draw. The algorithm for a bootstrap resampling of the mean, for a sample of size
    *n*, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Draw a sample value, record it, and then replace it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *n* times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Record the mean of the *n* resampled values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat steps 1–3 *R* times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the *R* results to:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate their standard deviation (this estimates sample mean standard error).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Produce a histogram or boxplot.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Find a confidence interval.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '*R*, the number of iterations of the bootstrap, is set somewhat arbitrarily.
    The more iterations you do, the more accurate the estimate of the standard error,
    or the confidence interval. The result from this procedure is a bootstrap set
    of sample statistics or estimated model parameters, which you can then examine
    to see how variable they are.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The *R* package `boot` combines these steps in one function. For example, the
    following applies the bootstrap to the incomes of people taking out loans:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The function `stat_fun` computes the median for a given sample specified by
    the index `idx`. The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The original estimate of the median is $62,000. The bootstrap distribution indicates
    that the estimate has a *bias* of about –$70 and a standard error of $209\. The
    results will vary slightly between consecutive runs of the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The major *Python* packages don’t provide implementations of the bootstrap
    approach. It can be implemented using the `scikit-learn` method `resample`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The bootstrap can be used with multivariate data, where the rows are sampled
    as units (see [Figure 2-8](#bootstrap-multivariate)). A model might then be run
    on the bootstrapped data, for example, to estimate the stability (variability)
    of model parameters, or to improve predictive power. With classification and regression
    trees (also called *decision trees*), running multiple trees on bootstrap samples
    and then averaging their predictions (or, with classification, taking a majority
    vote) generally performs better than using a single tree. This process is called
    *bagging* (short for “bootstrap aggregating”; see [“Bagging and the Random Forest”](ch06.xhtml#Bagging)).
  prefs: []
  type: TYPE_NORMAL
- en: '![images/Bootstrap-multivariate-schematic.png](Images/psd2_0208.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-8\. Multivariate bootstrap sampling
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The repeated resampling of the bootstrap is conceptually simple, and Julian
    Simon, an economist and demographer, published a compendium of resampling examples,
    including the bootstrap, in his 1969 text *Basic Research Methods in Social Science*
    (Random House). However, it is also computationally intensive and was not a feasible
    option before the widespread availability of computing power. The technique gained
    its name and took off with the publication of several journal articles and a book
    by Stanford statistician Bradley Efron in the late 1970s and early 1980s. It was
    particularly popular among researchers who use statistics but are not statisticians,
    and for use with metrics or models where mathematical approximations are not readily
    available. The sampling distribution of the mean has been well established since
    1908; the sampling distribution of many other metrics has not. The bootstrap can
    be used for sample size determination; experiment with different values for *n*
    to see how the sampling distribution is affected.
  prefs: []
  type: TYPE_NORMAL
- en: The bootstrap was met with considerable skepticism when it was first introduced;
    it had the aura to many of spinning gold from straw. This skepticism stemmed from
    a misunderstanding of the bootstrap’s purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The bootstrap does not compensate for a small sample size; it does not create
    new data, nor does it fill in holes in an existing data set. It merely informs
    us about how lots of additional samples would behave when drawn from a population
    like our original sample.
  prefs: []
  type: TYPE_NORMAL
- en: Resampling Versus Bootstrapping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes the term *resampling* is used synonymously with the term *bootstrapping*,
    as just outlined. More often, the term *resampling* also includes permutation
    procedures (see [“Permutation Test”](ch03.xhtml#Permutation)), where multiple
    samples are combined and the sampling may be done without replacement. In any
    case, the term *bootstrap* always implies sampling with replacement from an observed
    data set.
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*An Introduction to the Bootstrap* by Bradley Efron and Robert Tibshirani (Chapman
    & Hall, 1993) was the first book-length treatment of the bootstrap. It is still
    widely read.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The retrospective on the bootstrap in the May 2003 issue of *Statistical Science*
    (vol. 18, no. 2), discusses (among other antecedents, in Peter Hall’s “A Short
    Prehistory of the Bootstrap”) Julian Simon’s initial publication of the bootstrap
    in 1969.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See *An Introduction to Statistical Learning* by Gareth James, Daniela Witten,
    Trevor Hastie, and Robert Tibshirani (Springer, 2013) for sections on the bootstrap
    and, in particular, bagging.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Confidence Intervals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Frequency tables, histograms, boxplots, and standard errors are all ways to
    understand the potential error in a sample estimate. Confidence intervals are
    another.
  prefs: []
  type: TYPE_NORMAL
- en: There is a natural human aversion to uncertainty; people (especially experts)
    say “I don’t know” far too rarely. Analysts and managers, while acknowledging
    uncertainty, nonetheless place undue faith in an estimate when it is presented
    as a single number (a *point estimate*). Presenting an estimate not as a single
    number but as a range is one way to counteract this tendency. Confidence intervals
    do this in a manner grounded in statistical sampling principles.
  prefs: []
  type: TYPE_NORMAL
- en: 'Confidence intervals always come with a coverage level, expressed as a (high)
    percentage, say 90% or 95%. One way to think of a 90% confidence interval is as
    follows: it is the interval that encloses the central 90% of the bootstrap sampling
    distribution of a sample statistic (see [“The Bootstrap”](#bootstrap)). More generally,
    an *x*% confidence interval around a sample estimate should, on average, contain
    similar sample estimates *x*% of the time (when a similar sampling procedure is
    followed).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a sample of size *n*, and a sample statistic of interest, the algorithm
    for a bootstrap confidence interval is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Draw a random sample of size *n* with replacement from the data (a resample).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Record the statistic of interest for the resample.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat steps 1–2 many (*R*) times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For an *x*% confidence interval, trim [(100-*x*) / 2]% of the *R* resample results
    from either end of the distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The trim points are the endpoints of an *x*% bootstrap confidence interval.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 2-9](#bootstrap-ci) shows a 90% confidence interval for the mean annual
    income of loan applicants, based on a sample of 20 for which the mean was $62,231.'
  prefs: []
  type: TYPE_NORMAL
- en: '![images/bootstrap-CI.png](Images/psd2_0209.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-9\. Bootstrap confidence interval for the annual income of loan applicants,
    based on a sample of 20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The bootstrap is a general tool that can be used to generate confidence intervals
    for most statistics, or model parameters. Statistical textbooks and software,
    with roots in over a half century of computerless statistical analysis, will also
    reference confidence intervals generated by formulas, especially the t-distribution
    (see [“Student’s t-Distribution”](#t-distribution)).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Of course, what we are really interested in when we have a sample result is,
    “What is the probability that the true value lies within a certain interval?”
    This is not really the question that a confidence interval answers, but it ends
    up being how most people interpret the answer.
  prefs: []
  type: TYPE_NORMAL
- en: The probability question associated with a confidence interval starts out with
    the phrase “Given a sampling procedure and a population, what is the probability
    that…” To go in the opposite direction, “Given a sample result, what is the probability
    that (something is true about the population)?” involves more complex calculations
    and deeper imponderables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The percentage associated with the confidence interval is termed the *level
    of confidence*. The higher the level of confidence, the wider the interval. Also,
    the smaller the sample, the wider the interval (i.e., the greater the uncertainty).
    Both make sense: the more confident you want to be, and the less data you have,
    the wider you must make the confidence interval to be sufficiently assured of
    capturing the true value.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For a data scientist, a confidence interval is a tool that can be used to get
    an idea of how variable a sample result might be. Data scientists would use this
    information not to publish a scholarly paper or submit a result to a regulatory
    agency (as a researcher might) but most likely to communicate the potential error
    in an estimate, and perhaps to learn whether a larger sample is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For a bootstrap approach to confidence intervals, see *Introductory Statistics
    and Analytics: A Resampling Perspective* by Peter Bruce (Wiley, 2014) or *Statistics:
    Unlocking the Power of Data*, 2nd ed., by Robin Lock and four other Lock family
    members (Wiley, 2016).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Engineers, who have a need to understand the precision of their measurements,
    use confidence intervals perhaps more than most disciplines, and *Modern Engineering
    Statistics* by Thomas Ryan (Wiley, 2007) discusses confidence intervals. It also
    reviews a tool that is just as useful and gets less attention: *prediction intervals*
    (intervals around a single value, as opposed to a mean or other summary statistic).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normal Distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The bell-shaped normal distribution is iconic in traditional statistics.^([1](ch02.xhtml#idm46522862237288))
    The fact that distributions of sample statistics are often normally shaped has
    made it a powerful tool in the development of mathematical formulas that approximate
    those distributions.
  prefs: []
  type: TYPE_NORMAL
- en: In a normal distribution ([Figure 2-10](#normal-curve)), 68% of the data lies
    within one standard deviation of the mean, and 95% lies within two standard deviations.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'It is a common misconception that the normal distribution is called that because
    most data follows a normal distribution—that is, it is the normal thing. Most
    of the variables used in a typical data science project—in fact, most raw data
    as a whole—are *not* normally distributed: see [“Long-Tailed Distributions”](#LongTailedData).
    The utility of the normal distribution derives from the fact that many statistics
    *are* normally distributed in their sampling distribution. Even so, assumptions
    of normality are generally a last resort, used when empirical probability distributions,
    or bootstrap distributions, are not available.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Normal_dist.PNG](Images/psd2_0210.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-10\. Normal curve
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The normal distribution is also referred to as a *Gaussian* distribution after
    Carl Friedrich Gauss, a prodigious German mathematician from the late 18th and
    early 19th centuries. Another name previously used for the normal distribution
    was the “error” distribution. Statistically speaking, an *error* is the difference
    between an actual value and a statistical estimate like the sample mean. For example,
    the standard deviation (see [“Estimates of Variability”](ch01.xhtml#Variability))
    is based on the errors from the mean of the data. Gauss’s development of the normal
    distribution came from his study of the errors of astronomical measurements that
    were found to be normally distributed.
  prefs: []
  type: TYPE_NORMAL
- en: Standard Normal and QQ-Plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *standard normal* distribution is one in which the units on the x-axis are
    expressed in terms of standard deviations away from the mean. To compare data
    to a standard normal distribution, you subtract the mean and then divide by the
    standard deviation; this is also called *normalization* or *standardization* (see
    [“Standardization (Normalization, z-Scores)”](ch06.xhtml#Standardization)). Note
    that “standardization” in this sense is unrelated to database record standardization
    (conversion to a common format). The transformed value is termed a *z-score*,
    and the normal distribution is sometimes called the *z-distribution*.
  prefs: []
  type: TYPE_NORMAL
- en: 'A *QQ-Plot* is used to visually determine how close a sample is to a specified
    distribution—in this case, the normal distribution. The QQ-Plot orders the *z*-scores
    from low to high and plots each value’s *z*-score on the y-axis; the x-axis is
    the corresponding quantile of a normal distribution for that value’s rank. Since
    the data is normalized, the units correspond to the number of standard deviations
    away from the mean. If the points roughly fall on the diagonal line, then the
    sample distribution can be considered close to normal. [Figure 2-11](#qqnorm)
    shows a QQ-Plot for a sample of 100 values randomly generated from a normal distribution;
    as expected, the points closely follow the line. This figure can be produced in
    *R* with the `qqnorm` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In *Python*, use the method `scipy.stats.probplot` to create the QQ-Plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![qqnorm.png](Images/psd2_0211.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-11\. QQ-Plot of a sample of 100 values drawn from a standard normal
    distribution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Converting data to *z*-scores (i.e., standardizing or normalizing the data)
    does *not* make the data normally distributed. It just puts the data on the same
    scale as the standard normal distribution, often for comparison purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Long-Tailed Distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Despite the importance of the normal distribution historically in statistics,
    and in contrast to what the name would suggest, data is generally not normally
    distributed.
  prefs: []
  type: TYPE_NORMAL
- en: While the normal distribution is often appropriate and useful with respect to
    the distribution of errors and sample statistics, it typically does not characterize
    the distribution of raw data. Sometimes, the distribution is highly *skewed* (asymmetric),
    such as with income data; or the distribution can be discrete, as with binomial
    data. Both symmetric and asymmetric distributions may have *long tails*. The tails
    of a distribution correspond to the extreme values (small and large). Long tails,
    and guarding against them, are widely recognized in practical work. Nassim Taleb
    has proposed the *black swan* theory, which predicts that anomalous events, such
    as a stock market crash, are much more likely to occur than would be predicted
    by the normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'A good example to illustrate the long-tailed nature of data is stock returns.
    [Figure 2-12](#nflx_qnorm) shows the QQ-Plot for the daily stock returns for Netflix
    (NFLX). This is generated in *R* by:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding *Python* code is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![nflx_qnorm.png](Images/psd2_0212.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-12\. QQ-Plot of the returns for Netflix (NFLX)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In contrast to [Figure 2-11](#qqnorm), the points are far below the line for
    low values and far above the line for high values, indicating the data are not
    normally distributed. This means that we are much more likely to observe extreme
    values than would be expected if the data had a normal distribution. [Figure 2-12](#nflx_qnorm)
    shows another common phenomenon: the points are close to the line for the data
    within one standard deviation of the mean. Tukey refers to this phenomenon as
    data being “normal in the middle” but having much longer tails (see [[Tukey-1987]](bibliography01.xhtml#Tukey-1987)).'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: There is much statistical literature about the task of fitting statistical distributions
    to observed data. Beware an excessively data-centric approach to this job, which
    is as much art as science. Data is variable, and often consistent, on its face,
    with more than one shape and type of distribution. It is typically the case that
    domain and statistical knowledge must be brought to bear to determine what type
    of distribution is appropriate to model a given situation. For example, we might
    have data on the level of internet traffic on a server over many consecutive five-second
    periods. It is useful to know that the best distribution to model “events per
    time period” is the Poisson (see [“Poisson Distributions”](#Poisson)).
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*The Black Swan*, 2nd ed., by Nassim Nicholas Taleb (Random House, 2010)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Handbook of Statistical Distributions with Applications*, 2nd ed., by K. Krishnamoorthy
    (Chapman & Hall/CRC Press, 2016)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Student’s t-Distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *t-distribution* is a normally shaped distribution, except that it is a
    bit thicker and longer on the tails. It is used extensively in depicting distributions
    of sample statistics. Distributions of sample means are typically shaped like
    a t-distribution, and there is a family of t-distributions that differ depending
    on how large the sample is. The larger the sample, the more normally shaped the
    t-distribution becomes.
  prefs: []
  type: TYPE_NORMAL
- en: The t-distribution is often called *Student’s t* because it was published in
    1908 in *Biometrika* by W. S. Gosset under the name “Student.” Gosset’s employer,
    the Guinness brewery, did not want competitors to know that it was using statistical
    methods, so it insisted that Gosset not use his name on the article.
  prefs: []
  type: TYPE_NORMAL
- en: Gosset wanted to answer the question “What is the sampling distribution of the
    mean of a sample, drawn from a larger population?” He started out with a resampling
    experiment—drawing random samples of 4 from a data set of 3,000 measurements of
    criminals’ height and left-middle-finger length. (This being the era of eugenics,
    there was much interest in data on criminals, and in discovering correlations
    between criminal tendencies and physical or psychological attributes.) Gosset
    plotted the standardized results (the *z*-scores) on the x-axis and the frequency
    on the y-axis. Separately, he had derived a function, now known as *Student’s
    t*, and he fit this function over the sample results, plotting the comparison
    (see [Figure 2-13](#Gosset-curve)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Gosset-curve](Images/psd2_0213.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-13\. Gosset’s resampling experiment results and fitted t-curve (from
    his 1908 *Biometrika* paper)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'A number of different statistics can be compared, after standardization, to
    the t-distribution, to estimate confidence intervals in light of sampling variation.
    Consider a sample of size *n* for which the sample mean <math alttext="x overbar"><mover
    accent="true"><mi>x</mi> <mo>¯</mo></mover></math> has been calculated. If *s*
    is the sample standard deviation, a 90% confidence interval around the sample
    mean is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x overbar plus-or-minus t Subscript n minus 1 Baseline left-parenthesis
    0.05 right-parenthesis dot StartFraction s Over StartRoot n EndRoot EndFraction"
    display="block"><mrow><mover accent="true"><mi>x</mi> <mo>¯</mo></mover> <mo>±</mo>
    <msub><mi>t</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub> <mrow><mo>(</mo>
    <mn>0</mn> <mo>.</mo> <mn>05</mn> <mo>)</mo></mrow> <mo>·</mo> <mfrac><mi>s</mi>
    <msqrt><mi>n</mi></msqrt></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="t Subscript n minus 1 Baseline left-parenthesis .05 right-parenthesis"><mrow><msub><mi>t</mi>
    <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub> <mrow><mo>(</mo> <mo>.</mo>
    <mn>05</mn> <mo>)</mo></mrow></mrow></math> is the value of the t-statistic, with
    (*n* – 1) degrees of freedom (see [“Degrees of Freedom”](ch03.xhtml#DOF)), that
    “chops off” 5% of the t-distribution at either end. The t-distribution has been
    used as a reference for the distribution of a sample mean, the difference between
    two sample means, regression parameters, and other statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Had computing power been widely available in 1908, statistics would no doubt
    have relied much more heavily on computationally intensive resampling methods
    from the start. Lacking computers, statisticians turned to mathematics and functions
    such as the t-distribution to approximate sampling distributions. Computer power
    enabled practical resampling experiments in the 1980s, but by then, use of the
    t-distribution and similar distributions had become deeply embedded in textbooks
    and software.
  prefs: []
  type: TYPE_NORMAL
- en: The t-distribution’s accuracy in depicting the behavior of a sample statistic
    requires that the distribution of that statistic for that sample be shaped like
    a normal distribution. It turns out that sample statistics *are* often normally
    distributed, even when the underlying population data is not (a fact which led
    to widespread application of the t-distribution). This brings us back to the phenomenon
    known as the *central limit theorem* (see [“Central Limit Theorem”](#central-limit-theorem)).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: What do data scientists need to know about the t-distribution and the central
    limit theorem? Not a whole lot. The t-distribution is used in classical statistical
    inference but is not as central to the purposes of data science. Understanding
    and quantifying uncertainty and variation are important to data scientists, but
    empirical bootstrap sampling can answer most questions about sampling error. However,
    data scientists will routinely encounter t-statistics in output from statistical
    software and statistical procedures in *R*—for example, in A/B tests and regressions—so
    familiarity with its purpose is helpful.
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The original W.S. Gosset paper as published in *Biometrika* in 1908 is available
    [as a PDF](https://oreil.ly/J6gDg).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A standard treatment of the t-distribution can be found in David Lane’s [online
    resource](https://oreil.ly/QxUkA).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binomial Distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Yes/no (binomial) outcomes lie at the heart of analytics since they are often
    the culmination of a decision or other process; buy/don’t buy, click/don’t click,
    survive/die, and so on. Central to understanding the binomial distribution is
    the idea of a set of *trials*, each trial having two possible outcomes with definite
    probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: For example, flipping a coin 10 times is a binomial experiment with 10 trials,
    each trial having two possible outcomes (heads or tails); see [Figure 2-14](#nickel).
    Such yes/no or 0/1 outcomes are termed *binary* outcomes, and they need not have
    50/50 probabilities. Any probabilities that sum to 1.0 are possible. It is conventional
    in statistics to term the “1” outcome the *success* outcome; it is also common
    practice to assign “1” to the more rare outcome. Use of the term *success* does
    not imply that the outcome is desirable or beneficial, but it does tend to indicate
    the outcome of interest. For example, loan defaults or fraudulent transactions
    are relatively uncommon events that we may be interested in predicting, so they
    are termed “1s” or “successes.”
  prefs: []
  type: TYPE_NORMAL
- en: '![images/Indian_Head_Buffalo_Nickel.png](Images/psd2_0214.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-14\. The tails side of a buffalo nickel
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The binomial distribution is the frequency distribution of the number of successes
    (*x*) in a given number of trials (*n*) with specified probability (*p*) of success
    in each trial. There is a family of binomial distributions, depending on the values
    of *n* and *p*. The binomial distribution would answer a question like:'
  prefs: []
  type: TYPE_NORMAL
- en: If the probability of a click converting to a sale is 0.02, what is the probability
    of observing 0 sales in 200 clicks?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The *R* function `dbinom` calculates binomial probabilities. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: would return 0.0729, the probability of observing exactly *x* = 2 successes
    in *size* = 5 trials, where the probability of success for each trial is *p* =
    0.1\. For our example above, we use *x* = 0, *size* = 200, and *p* = 0.02\. With
    these arguments, `dbinom` returns a probability of 0.0176.
  prefs: []
  type: TYPE_NORMAL
- en: 'Often we are interested in determining the probability of *x* or fewer successes
    in *n* trials. In this case, we use the function `pbinom`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This would return 0.9914, the probability of observing two or fewer successes
    in five trials, where the probability of success for each trial is 0.1.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `scipy.stats` module implements a large variety of statistical distributions.
    For the binomial distribution, use the functions `stats.binom.pmf` and `stats.binom.cdf`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The mean of a binomial distribution is <math alttext="n times p"><mrow><mi>n</mi>
    <mo>×</mo> <mi>p</mi></mrow></math> ; you can also think of this as the expected
    number of successes in *n* trials, for success probability = *p*.
  prefs: []
  type: TYPE_NORMAL
- en: The variance is <math alttext="n times p left-parenthesis 1 minus p right-parenthesis"><mrow><mi>n</mi>
    <mo>×</mo> <mi>p</mi> <mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>p</mi> <mo>)</mo></mrow></math>
    . With a large enough number of trials (particularly when *p* is close to 0.50),
    the binomial distribution is virtually indistinguishable from the normal distribution.
    In fact, calculating binomial probabilities with large sample sizes is computationally
    demanding, and most statistical procedures use the normal distribution, with mean
    and variance, as an approximation.
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Read about [the “quincunx”](https://oreil.ly/nmkcs), a pinball-like simulation
    device for illustrating the binomial distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The binomial distribution is a staple of introductory statistics, and all introductory
    statistics texts will have a chapter or two on it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chi-Square Distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An important idea in statistics is *departure from expectation*, especially
    with respect to category counts. Expectation is defined loosely as “nothing unusual
    or of note in the data” (e.g., no correlation between variables or predictable
    patterns). This is also termed the “null hypothesis” or “null model” (see [“The
    Null Hypothesis”](ch03.xhtml#Null_hypothesis)). For example, you might want to
    test whether one variable (say, a row variable representing gender) is independent
    of another (say, a column variable representing “was promoted in job”), and you
    have counts of the number in each of the cells of the data table. The statistic
    that measures the extent to which results depart from the null expectation of
    independence is the chi-square statistic. It is the difference between the observed
    and expected values, divided by the square root of the expected value, squared,
    then summed across all categories. This process standardizes the statistic so
    it can be compared to a reference distribution. A more general way of putting
    this is to note that the chi-square statistic is a measure of the extent to which
    a set of observed values “fits” a specified distribution (a “goodness-of-fit”
    test). It is useful for determining whether multiple treatments (an “A/B/C… test”)
    differ from one another in their effects.
  prefs: []
  type: TYPE_NORMAL
- en: The chi-square distribution is the distribution of this statistic under repeated
    resampled draws from the null model—see [“Chi-Square Test”](ch03.xhtml#chi-square)
    for a detailed algorithm, and the chi-square formula for a data table. A low chi-square
    value for a set of counts indicates that they closely follow the expected distribution.
    A high chi-square indicates that they differ markedly from what is expected. There
    are a variety of chi-square distributions associated with different degrees of
    freedom (e.g., number of observations—see [“Degrees of Freedom”](ch03.xhtml#DOF)).
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The chi-square distribution owes its place in modern statistics to the great
    statistician Karl Pearson and the birth of hypothesis testing—read about this
    and more in David Salsburg’s *The Lady Tasting Tea: How Statistics Revolutionized
    Science in the Twentieth Century* (W. H. Freeman, 2001).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a more detailed exposition, see the section in this book on the chi-square
    test ([“Chi-Square Test”](ch03.xhtml#chi-square)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: F-Distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A common procedure in scientific experimentation is to test multiple treatments
    across groups—say, different fertilizers on different blocks of a field. This
    is similar to the A/B/C test referred to in the chi-square distribution (see [“Chi-Square
    Distribution”](#chi-square-dist)), except we are dealing with measured continuous
    values rather than counts. In this case we are interested in the extent to which
    differences among group means are greater than we might expect under normal random
    variation. The F-statistic measures this and is the ratio of the variability among
    the group means to the variability within each group (also called residual variability).
    This comparison is termed an *analysis of variance* (see [“ANOVA”](ch03.xhtml#ANOVA)).
    The distribution of the F-statistic is the frequency distribution of all the values
    that would be produced by randomly permuting data in which all the group means
    are equal (i.e., a null model). There are a variety of F-distributions associated
    with different degrees of freedom (e.g., numbers of groups—see [“Degrees of Freedom”](ch03.xhtml#DOF)).
    The calculation of F is illustrated in the section on ANOVA. The F-statistic is
    also used in linear regression to compare the variation accounted for by the regression
    model to the overall variation in the data. F-statistics are produced automatically
    by *R* and *Python* as part of regression and ANOVA routines.
  prefs: []
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: George Cobb’s *Introduction to Design and Analysis of Experiments* (Wiley, 2008)
    contains an excellent exposition of the decomposition of variance components,
    which helps in understanding ANOVA and the F-statistic.
  prefs: []
  type: TYPE_NORMAL
- en: Poisson and Related Distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many processes produce events randomly at a given overall rate—visitors arriving
    at a website, or cars arriving at a toll plaza (events spread over time); imperfections
    in a square meter of fabric, or typos per 100 lines of code (events spread over
    space).
  prefs: []
  type: TYPE_NORMAL
- en: Poisson Distributions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From prior aggregate data (for example, number of flu infections per year),
    we can estimate the average number of events per unit of time or space (e.g.,
    infections per day, or per census unit). We might also want to know how different
    this might be from one unit of time/space to another. The Poisson distribution
    tells us the distribution of events per unit of time or space when we sample many
    such units. It is useful when addressing queuing questions such as “How much capacity
    do we need to be 95% sure of fully processing the internet traffic that arrives
    on a server in any five-second period?”
  prefs: []
  type: TYPE_NORMAL
- en: The key parameter in a Poisson distribution is <math alttext="lamda"><mi>λ</mi></math>
    , or lambda. This is the mean number of events that occurs in a specified interval
    of time or space. The variance for a Poisson distribution is also <math alttext="lamda"><mi>λ</mi></math>
    .
  prefs: []
  type: TYPE_NORMAL
- en: 'A common technique is to generate random numbers from a Poisson distribution
    as part of a queuing simulation. The `rpois` function in *R* does this, taking
    only two arguments—the quantity of random numbers sought, and lambda:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding `scipy` function is `stats.poisson.rvs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This code will generate 100 random numbers from a Poisson distribution with
    <math alttext="lamda"><mi>λ</mi></math> = 2. For example, if incoming customer
    service calls average two per minute, this code will simulate 100 minutes, returning
    the number of calls in each of those 100 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: Exponential Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the same parameter <math alttext="lamda"><mi>λ</mi></math> that we used
    in the Poisson distribution, we can also model the distribution of the time between
    events: time between visits to a website or between cars arriving at a toll plaza.
    It is also used in engineering to model time to failure, and in process management
    to model, for example, the time required per service call. The *R* code to generate
    random numbers from an exponential distribution takes two arguments: `n` (the
    quantity of numbers to be generated) and `rate` (the number of events per time
    period). For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In the function `stats.expon.rvs`, the order of the arguments is reversed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This code would generate 100 random numbers from an exponential distribution
    where the mean number of events per time period is 0.2. So you could use it to
    simulate 100 intervals, in minutes, between service calls, where the average rate
    of incoming calls is 0.2 per minute.
  prefs: []
  type: TYPE_NORMAL
- en: A key assumption in any simulation study for either the Poisson or exponential
    distribution is that the rate, <math alttext="lamda"><mi>λ</mi></math> , remains
    constant over the period being considered. This is rarely reasonable in a global
    sense; for example, traffic on roads or data networks varies by time of day and
    day of week. However, the time periods, or areas of space, can usually be divided
    into segments that are sufficiently homogeneous so that analysis or simulation
    within those periods is valid.
  prefs: []
  type: TYPE_NORMAL
- en: Estimating the Failure Rate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In many applications, the event rate, <math alttext="lamda"><mi>λ</mi></math>
    , is known or can be estimated from prior data. However, for rare events, this
    is not necessarily so. Aircraft engine failure, for example, is sufficiently rare
    (thankfully) that, for a given engine type, there may be little data on which
    to base an estimate of time between failures. With no data at all, there is little
    basis on which to estimate an event rate. However, you can make some guesses:
    if no events have been seen after 20 hours, you can be pretty sure that the rate
    is not 1 per hour. Via simulation, or direct calculation of probabilities, you
    can assess different hypothetical event rates and estimate threshold values below
    which the rate is very unlikely to fall. If there is some data but not enough
    to provide a precise, reliable estimate of the rate, a goodness-of-fit test (see
    [“Chi-Square Test”](ch03.xhtml#chi-square)) can be applied to various rates to
    determine how well they fit the observed data.'
  prefs: []
  type: TYPE_NORMAL
- en: Weibull Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many cases, the event rate does not remain constant over time. If the period
    over which it changes is much longer than the typical interval between events,
    there is no problem; you just subdivide the analysis into the segments where rates
    are relatively constant, as mentioned before. If, however, the event rate changes
    over the time of the interval, the exponential (or Poisson) distributions are
    no longer useful. This is likely to be the case in mechanical failure—the risk
    of failure increases as time goes by. The *Weibull* distribution is an extension
    of the exponential distribution in which the event rate is allowed to change,
    as specified by a *shape parameter*, <math alttext="beta"><mi>β</mi></math> .
    If <math alttext="beta"><mi>β</mi></math> > 1, the probability of an event increases
    over time; if <math alttext="beta"><mi>β</mi></math> < 1, the probability decreases.
    Because the Weibull distribution is used with time-to-failure analysis instead
    of event rate, the second parameter is expressed in terms of characteristic life,
    rather than in terms of the rate of events per interval. The symbol used is <math
    alttext="eta"><mi>η</mi></math> , the Greek letter eta. It is also called the
    *scale* parameter.
  prefs: []
  type: TYPE_NORMAL
- en: With the Weibull, the estimation task now includes estimation of both parameters,
    <math alttext="beta"><mi>β</mi></math> and <math alttext="eta"><mi>η</mi></math>
    . Software is used to model the data and yield an estimate of the best-fitting
    Weibull distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *R* code to generate random numbers from a Weibull distribution takes three
    arguments: `n` (the quantity of numbers to be generated), `shape`, and `scale`.
    For example, the following code would generate 100 random numbers (lifetimes)
    from a Weibull distribution with shape of 1.5 and characteristic life of 5,000:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'To achieve the same in *Python*, use the function `stats.weibull_min.rvs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Further Reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Modern Engineering Statistics* by Thomas Ryan (Wiley, 2007) has a chapter
    devoted to the probability distributions used in engineering applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read an engineering-based perspective on the use of the Weibull distribution
    [here](https://oreil.ly/1x-ga) and [here](https://oreil.ly/9bn-U).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the era of big data, the principles of random sampling remain important when
    accurate estimates are needed. Random selection of data can reduce bias and yield
    a higher quality data set than would result from just using the conveniently available
    data. Knowledge of various sampling and data-generating distributions allows us
    to quantify potential errors in an estimate that might be due to random variation.
    At the same time, the bootstrap (sampling with replacement from an observed data
    set) is an attractive “one size fits all” method to determine possible error in
    sample estimates.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch02.xhtml#idm46522862237288-marker)) The bell curve is iconic but perhaps
    overrated. George W. Cobb, the Mount Holyoke statistician noted for his contribution
    to the philosophy of teaching introductory statistics, argued in a November 2015
    editorial in the *American Statistician* that the “standard introductory course,
    which puts the normal distribution at its center, had outlived the usefulness
    of its centrality.”
  prefs: []
  type: TYPE_NORMAL
