- en: 'Chapter 19\. Blastomatic: Parsing Delimited Text Files'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Delimited text files are a standard way to encode columnar data. You are likely
    familiar with spreadsheets like Microsoft Excel or Google Sheets, where each worksheet
    may hold a dataset with columns across the top and records running down. You can
    export this data to a text file where the columns of data are *delimited*, or
    separated by a character. Quite often the delimiter is a comma, and the file will
    have an extension of *.csv*. This format is called *CSV*, for *comma-separated
    values*. When the delimiter is a tab, the extension may be *.tab*, *.txt*, or
    *.tsv* for *tab-separated values*. The first line of the file usually will contain
    the names of the columns. Notably, this is not the case with the tabular output
    from BLAST (Basic Local Alignment Search Tool), one of the most popular tools
    in bioinformatics used to compare sequences. In this chapter, I will show you
    how to parse this output and merge the BLAST results with metadata from another
    delimited text file using the `csv` and `pandas` modules.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this exercise, you will learn:'
  prefs: []
  type: TYPE_NORMAL
- en: How to use `csvkit` and `csvchk` to view delimited text files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use the `csv` and `pandas` modules to parse delimited text files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to BLAST
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The BLAST program is one of the most ubiquitous tools in bioinformatics for
    determining sequence similarity. In [Chapter 6](ch06.html#ch06), I showed how
    the Hamming distance between two sequences is one measure of similarity and compared
    this to the concept of alignment. Whereas the Hamming distance compares both sequences
    starting from the beginning, an alignment with BLAST starts wherever both sequences
    begin to overlap and will allow for insertions, deletions, and mismatches to find
    the longest possible areas of similarity.
  prefs: []
  type: TYPE_NORMAL
- en: I’ll show you the National Center for Biotechnology (NCBI) BLAST web interface,
    but you can use `blastn` if you have BLAST installed locally. I will compare 100
    sequences from the [Global Ocean Sampling Expedition (GOS)](https://oreil.ly/POkOV)
    to a sequence database at NCBI. GOS is one of the earliest metagenomic studies,
    dating from the early 2000s when Dr. Craig Venter funded a two-year expedition
    to collect and analyze ocean samples from around the globe. It’s a *metagenomic*
    project because the genetic material was taken directly from an environmental
    sample. The purpose of using BLAST is to compare the unknown GOS sequences to
    known sequences at NCBI to determine their possible taxonomic classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'I used the FASTX sampler from [Chapter 18](ch18.html#ch18) to randomly select
    the 100 input sequences in *tests/inputs/gos.fa*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: I used [the NCBI BLAST tool](https://oreil.ly/gXErw) to compare these sequences
    to the *nr/nt* (nonredundant nucleotide) database using the `blastn` program to
    compare nucleotides. The results page allows me to select the detailed results
    for each of the 100 sequences. As shown in [Figure 19-1](#fig_19.1), the first
    sequence has four *hits* or matches to known sequences. The first and best hit
    is about 93% identical over 99% of its length to a portion of the genome of [*Candidatus
    Pelagibacter*](https://oreil.ly/qywN2), a marine bacteria of the SAR11 clade.
    Given that the GOS query sequence came from the ocean, this seems a likely match.
  prefs: []
  type: TYPE_NORMAL
- en: '![mpfb 1901](assets/mpfb_1901.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 19-1\. The first GOS sequence has four possible matches from nr/nt
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 19-2](#fig_19.2) shows how similar the query sequence is to a region
    of the *Candidatus Pelagibacter* genome. Notice how the alignment allows for single-nucleotide
    variations (SNVs) and gaps caused by deletions or insertions between the sequences.
    If you want to challenge yourself, try writing a sequence aligner. You can see
    an example in [Figure 19-2](#fig_19.2).'
  prefs: []
  type: TYPE_NORMAL
- en: '![mpfb 1902](assets/mpfb_1902.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 19-2\. The alignment of the top BLAST hit
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As interesting as it is to explore each individual hit, I want to download
    a table of all the hits. There is a Download All menu with 11 download formats.
    I chose the “Hit table(csv)” format and split this data into *hits1.csv* and *hits2.csv*
    in the *tests/inputs* directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If you open these files with a text editor, you’ll see they contain comma-separated
    values. You can also open a file with a spreadsheet program like Excel to see
    the data in columnar format, and you may notice that the columns are not named.
    If you were on a remote machine like a cluster node, you would likely not have
    access to a graphical program like Excel to inspect the results. Further, Excel
    is limited to about 1 million rows and 16,000 columns. In real-world bioinformatics,
    it’s pretty easy to exceed both of those values, so I’ll show you command-line
    tools you can use to look at delimited text files.
  prefs: []
  type: TYPE_NORMAL
- en: Using csvkit and csvchk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, I’d like to introduce the `csvkit` module, “a suite of command-line
    tools for converting to and working with CSV.” The *requirements.txt* file for
    the repo lists this as a dependency, so it’s probably installed. If not, you can
    use this command to install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will install several useful utilities, and I encourage you to read [the
    documentation](https://oreil.ly/QDAn2) to learn about them. I want to highlight
    `csvlook`, which “renders a CSV file in the console as a Markdown-compatible,
    fixed-width table.” Run **`csvlook --help`** to view the usage and notice there
    is an `-H|--no-header-row` option to view files that have no header row. The following
    command will display the first three rows of the hits table. Depending on the
    size of your screen, this might be unreadable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The [`csvchk` program](https://oreil.ly/T2QSo) will transpose a wide record
    like this to a tall one vertically oriented with the column names on the left
    rather than across the top. This, too, should have been installed with other module
    dependencies, but you can use `pip` to install it if needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If you read the usage, you’ll see that this tool also has an `-N|--noheaders`
    option. Use `csvchk` to inspect the first record in the same hits file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output files you can download from NCBI BLAST match the output formats
    from the command-line versions of the BLAST programs, like `blastn` for comparing
    nucleotides, `blastp` for comparing proteins, etc. The help documentation for
    `blastn` includes an `-outfmt` option to specify the output format using a number
    between 0 and 18. The preceding output file format is the “Tabular” option 6:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You may find yourself wondering why the tabular output file does not contain
    the column headers. If you read through all the formatting options, you may notice
    that output format 7 is “Tabular with comment lines,” and you may ask yourself:
    Is this the option that will include the column names? Dear reader, you will be
    sorely disappointed to learn it does not.^([1](ch19.html#idm45963626663048)) Option
    7 is the same as the “Hits table(text)” option on the NCBI BLAST page. Download
    and open that file to see that it contains metadata about the search as unstructured
    text on lines that begin with the `#` character. Because so many languages (including
    Python) use this as a comment character to indicate a line that should be ignored,
    it’s common to say that the metadata is *commented out*, and many delimited text
    parsers will skip these lines.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So what are the column names? I must parse through hundreds of lines of the
    `blastn` usage to find that “Options 6, 7, 10 and 17 can be additionally configured”
    to include any of 53 optional fields. If the fields are not specified, then the
    default fields are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`qaccver`: Query sequence accession/ID'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`saccver`: Subject sequence accession/ID'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pident`: Percentage of identical matches'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`length`: Alignment length'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mismatch`: Number of mismatches'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gapopen`: Number of gap openings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`qstart`: Start of alignment in query'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`qend`: End of alignment in query'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sstart`: Start of alignment in subject'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`send`: End of alignment in subject'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`evalue`: Expect value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bitscore`: Bit score'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you look again at the usage for `csvchk`, you’ll find there is an option
    to name the `-f|--fieldnames` for the record. Following is how I could view the
    first record from a hits file and specify column names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a much more useful output. If you like this command, you can create
    an alias called `blstchk` in `bash`, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Most shells allow you to define aliases like this in a file that is read each
    time you start a new shell. In `bash`, you could add this line to a file in your
    `$HOME` directory, like *.bash_profile*, *.bashrc*, or *.profile*. Other shells
    have similar properties. Aliases are a handy way to create global shortcuts for
    common commands. If you wish to create a command shortcut inside a particular
    project or directory, consider using a target in a *Makefile*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how I use the `blstchk` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The goal of the program in this chapter is to link the BLAST hits to the depth
    and location of the GOS sequences found in the file *tests/inputs/meta.csv*. I
    will use the `-g|--grep` option to `csvchk` to find the preceding query sequence,
    *CAM_READ_0234442157*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The BLAST results can be joined to the metadata where the former’s `qseqid`
    is equal to the latter’s `seq_id`. There is a command-line tool called `join`
    that will do exactly this. The inputs must both be sorted, and I will use the
    `-t` option to indicate that the comma is the field delimiter. By default, `join`
    assumes the first column in each file is the common value, which is true here.
    The output is a comma-separated union of the fields from both files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The two positional inputs to `join` use shell redirection `<` to read in the
    results of sorting the two input files. The output from `join` is piped to `csvchk`.
  prefs: []
  type: TYPE_NORMAL
- en: Although it’s good to know how to use `join`, this output is not particularly
    useful because it does not have the column headers. (Also, the point is to learn
    how to do this in Python.) How might you add headers to this information? Would
    you cobble together some shell commands in a `bash` script or a *Makefile* target,
    or would you write a Python program? Let’s keep moving, shall we? Next, I’ll show
    you how the program should work and the output it will create.
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All the code and tests for this exercise can be found in the *19_blastomatic*
    directory of the repository. Change to this directory and copy the second solution
    to the program `blastomatic.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The program will accept the BLAST hits and the metadata file and will produce
    an output file showing the sequence ID, the percent identity match, the depth,
    and the latitude and longitude of the sample. Optionally, the output can be filtered
    by the percent identity. Request help from the program to see the options:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The tabular output file from a BLAST search in `-outfmt 6`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: An annotations file with metadata about the sequences.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO2-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The name of the output file, which defaults to *out.csv*.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO2-4)'
  prefs: []
  type: TYPE_NORMAL
- en: The output file delimiter, which defaults to a guess based on the output file
    extension.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO2-5)'
  prefs: []
  type: TYPE_NORMAL
- en: The minimum percent identity, which defaults to `0`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If I run the program using the first hits file, it will write 500 sequences
    to the output file *out.csv*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'I can use `csvlook` with the `--max-rows` option to view the first two rows
    of the table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Or I can use `csvchk` with `-l|--limit` to do the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'If I want to only export hits with a percent identity greater than or equal
    to 90%, I can use the `-p|--pctid` option to find that only 190 records are found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'I can peek at the file to see that it appears to have selected the correct
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The `blastomatic.py` program defaults to writing the output to the comma-separated
    file *out.csv*. You can use the `-d|--delimiter` option to specify a different
    delimiter and the `-o|--outfile` option to specify a different file. Note that
    the delimiter will be guessed from the extension of the output filename if it
    is not specified. The extension *.csv* will be taken to mean commas, and otherwise
    tabs will be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run **`make test`** to see the full test suite. When you think you understand
    how the program should work, start anew:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Defining the Arguments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is the class I used to define my arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The BLAST hits file will be an open filehandle.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO3-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The metadata file will be an open filehandle.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO3-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The output file will be an open filehandle.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO3-4)'
  prefs: []
  type: TYPE_NORMAL
- en: The output file delimiter will be a string.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO3-5)'
  prefs: []
  type: TYPE_NORMAL
- en: The percent identity will be a floating-point number.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how I parse and validate the arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO4-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The BLAST file must be a readable text file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO4-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The metadata file must be a readable text file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO4-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The output file must be a writable text file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO4-4)'
  prefs: []
  type: TYPE_NORMAL
- en: The output field delimiter is a string that defaults to the empty string I will
    guess from the output filename.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO4-5)'
  prefs: []
  type: TYPE_NORMAL
- en: The minimum percent identity should be a floating-point number that defaults
    to `0`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](assets/6.png)](#co_blastomatic__parsing_delimited_text_files_CO4-6)'
  prefs: []
  type: TYPE_NORMAL
- en: Create the `Args` object. Note that the fields of `Args` do not need to match
    the parameter names.
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](assets/7.png)](#co_blastomatic__parsing_delimited_text_files_CO4-7)'
  prefs: []
  type: TYPE_NORMAL
- en: I wrote a function to guess the delimiter from the output filename.
  prefs: []
  type: TYPE_NORMAL
- en: 'This program has two required file arguments: the BLAST hits, and the annotations.
    I don’t want to make these positional arguments because then my user would have
    to remember the order. It’s better to have these as named options, but then they
    become optional, which I don’t want either. To overcome this, I use `required=True`
    for both the file parameters to ensure the user supplies them.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You might like to start with the `guess_delimiter()` function. Here is the
    test I wrote:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Start your `main()` with some minimal code that will work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify that this works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: At this point, you should be able to pass several tests when you run **`make
    test`**. Next, I’ll show you how to parse the delimited text files.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing Delimited Text Files Using the csv Module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Python has a `csv` module that will handle delimited text files easily, but
    I would first like to show you exactly what it’s doing so you can appreciate how
    much effort it saves. To begin, I will open the metadata file and read the headers
    from the first line. I can call the `fh.readline()` method on a filehandle to
    read one line of text. This will still have the newline attached, so I call `str.rstrip()`
    to remove any whitespace from the right side of the string. Finally, I call `str.split('','')`
    to break the line on the delimiting comma:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'So far, so good. I’ll try parsing the next line of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Can you see a problem here? I have split the `lat_lon` field, which contains
    a comma, into two values, giving me eight values for seven fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `str.split()` will not work because it fails to consider when the separator
    is part of the field value. That is, when the field separator is enclosed in quotes,
    it’s not a field separator. Notice that the `lat_lon` value is properly quoted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'One way to correctly parse this line uses the `pyparsing` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'That’s close, but the `lat_lon` field still has the quotes around it. I can
    use a regular expression to remove them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO5-1)'
  prefs: []
  type: TYPE_NORMAL
- en: This regular expression replaces a quote anchored to either the beginning or
    the end of a string with the empty string.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that I have a list of the `headers` and a list of the `data` for a given
    record, I could create a dictionary by zipping these together. I’ve used the `zip()`
    function in Chapters [6](ch06.html#ch06) and [13](ch13.html#ch13) to join two
    lists into a list of tuples. Because `zip()` is a lazy function, I must use the
    `list()` function in the REPL to force the evaluation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'I can change the `list()` function to `dict()` to turn this into a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'I could iterate through each line of the file and create a dictionary of the
    records by zipping the headers and data. That would work just fine, but all this
    work has already been done for me in the `csv` module. Following is how I can
    parse the same file into a list of dictionaries using `csv.DictReader()`. By default,
    it will use the comma as the delimiter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'That’s much easier. Here’s how I might use this to create a dictionary of all
    the annotations keyed on the sequence ID. Be sure to add `from pprint import pprint`
    for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO6-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Use `csv.DictReader()` to parse the CSV data in the annotations filehandle.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO6-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Use a dictionary comprehension to create a dictionary keyed on the `seq_id`
    field from each record.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run this with the input files and see if you get a reasonable-looking data
    structure. Here I’ll redirect `STDOUT` to a file called *out* and use `head` to
    inspect it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Before I move on to reading the BLAST hits, I’d like to open the output filehandle.
    The format of the output file should be another delimited text file. By default
    it will be a CSV file, but the user may choose something else, like a tab separator.
    The first line of the file should be the headers, so I’ll immediately write those:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO7-1)'
  prefs: []
  type: TYPE_NORMAL
- en: These are the output file’s column names.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO7-2)'
  prefs: []
  type: TYPE_NORMAL
- en: '`args.outfile` is a filehandle opened for writing text. Write the headers joined
    on the `args.delimiter` string. Be sure to add a newline.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, you could use `print()` with a `file` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, I’ll cycle through the BLAST hits. It’s necessary to supply the `fieldnames`
    to `csv.DictReader()` since the first line of the file is missing the column names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO8-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Parse the BLAST CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO8-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Iterate through each BLAST hit.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO8-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Skip those hits where the percent ID is less than the minimum. Use the `float()`
    function to convert the text to a floating-point value.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO8-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Print the query sequence ID.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run this version of the program with a minimum percent ID of 90, and verify
    that you get 190 hits from the first file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: If the BLAST hit’s `qseqid` value is found as a `seq_id` in the metadata file,
    then print to the output file the sequence ID, the percent ID from the BLAST hit,
    and the depth and latitude/longitude values from the metadata file. That should
    be enough to get you rolling on this program. Be sure to run the tests to verify
    that your program is correct.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing Delimited Text Files Using the pandas Module
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The pandas module presents another effective way to read a delimited file. This
    module, along with NumPy, is one of the foundational Python libraries used in
    data science. I’ll use the `pd.read_csv()` function, which closely resembles the
    `read_csv()` function from the R programming language, if you are familiar with
    that. Note that the function can read text delimited by any delimiter you specify
    using a `sep` field separator, but the default is a comma.
  prefs: []
  type: TYPE_NORMAL
- en: 'Normally the delimiter is a single character, but it’s possible to split text
    using a string. If you do this, you may encounter the warning “ParserWarning:
    Falling back to the *python* engine because the *c* engine does not support regex
    separators (separators > 1 char and different from *\s+* are interpreted as regex);
    you can avoid this warning by specifying engine=*python*.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s common to import pandas with the alias `pd`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Much of pandas is based on ideas from R. A pandas dataframe is a two-dimensional
    object that holds all the columns and rows of the metadata file in a single object,
    just like a dataframe in R. That is, the `reader` in the previous example is an
    interface used to sequentially retrieve each of the records, but the pandas dataframe
    is a full representation of all the data from the file. As such, the size of a
    dataframe will be limited to the amount of memory on your computer. Just as I’ve
    warned about using `fh.read()` to read an entire file into memory, you must be
    judicious about which files can be practically read using pandas. If you must
    process millions of rows of delimited text in gigabyte-sized files, I would recommend
    using `cvs.DictReader()` to process one record at a time.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you evaluate the `meta` object in the REPL, a sample of the table will be
    shown. You can see that pandas used the first row of the file for the column headers.
    As indicated by ellipses, some of the columns have been elided due to the constrained
    width of the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'To find the number of rows and columns in a dataframe, inspect the `meta.shape`
    attribute. Note that this is not followed by parentheses because it is not a method
    call. This dataframe has 100 rows and 7 columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'I can inspect the `meta.columns` attribute for the column names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'One advantage to dataframes is that you can query all the values from a column
    using a syntax that looks like accessing a field in a dictionary. Here I’ll select
    the salinity values, and note that pandas has converted the values from text to
    floating-point values, with missing values represented, with `NaN` (not a number):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'I can find the rows with a salinity greater than 50 using syntax almost identical
    to that in R. This returns an array of Boolean values based on the predicate *salinity
    is greater than 50*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'I can use these Booleans values as a mask to only select the rows where this
    condition is `True`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is a new dataframe, so I could then look at the salinity values
    that were found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'If you read the BLAST hits file with pandas, you will need to supply the column
    names as you did in the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'One element of this program is to select only those hits with a percent ID
    greater than or equal to some minimum. pandas will automatically convert the `pident`
    column to a floating-point value. Here I will select those hits with a percent
    ID greater than or equal to `90`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'To iterate over the rows in a dataframe, use the `wanted.iterrows()` method.
    Note that this works like the `enumerate()` function in that it returns a tuple
    of the row index and the row value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'To print a single field from a record in the dataframe, you can treat the record
    like a dictionary using field access through square brackets or by using the familiar
    `dict.get()` method. As with dictionaries, the first method will create an exception
    if you misspell a field name, while the latter method will quietly return `None`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'As in the previous example, I recommend you first read the metadata and then
    iterate through the BLAST hits. You can look up the metadata from the `meta` dataframe
    by searching over the `seq_id` field. The sequence IDs in the metadata file are
    unique, so you should only find at most one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'You can either iterate over the matches or use the `iloc` accessor to get the
    first (zeroth) record:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'If you fail to find any matches, you will get an empty dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'You can inspect the `seqs.empty` attribute to see if it’s empty:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'or inspect the rows value from `seqs.shape`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Dataframes can also write their values to a file using the `to_csv()` method.
    As with `read_csv()`, you can specify any `sep` field separator, and the default
    is the comma. Note that by default pandas will include the row index as the first
    field of the output file. I generally use `index=False` to omit this. For example,
    I’ll save the metadata records with a salinity greater than 50 to the *salty.csv*
    file with one line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'I can verify that the data was written using `csvchk` or `csvlook`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: A thorough review of pandas is well beyond the scope of this book, but this
    should be enough for you to figure out a solution. If you would like to learn
    more, I recommend [*Python for Data Analysis*](https://oreil.ly/kAtUU) by Wes
    McKinney (O’Reilly, 2017) and [*Python Data Science Handbook*](https://oreil.ly/1V94U)
    by Jake VanderPlas (O’Reilly, 2016).
  prefs: []
  type: TYPE_NORMAL
- en: Solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I have four solutions, two using the `csv` module and two using pandas. All
    of the solutions use the same `guess_delimiter()` function, which I wrote like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO9-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Select the file extension from `os.path.splitext()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO9-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Return a comma if the file extension is *.csv* and the tab character otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Solution 1: Manually Joining the Tables Using Dictionaries'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This version closely follows all the suggestions from earlier in the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO10-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Create a parser for the annotations file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO10-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Read all the annotations into a dictionary keyed on the sequence ID.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO10-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Define the headers of the output file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO10-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Write the headers to the output file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO10-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Create a parser for the BLAST hits.
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](assets/6.png)](#co_blastomatic__parsing_delimited_text_files_CO10-6)'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize a counter for the number of records written.
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](assets/7.png)](#co_blastomatic__parsing_delimited_text_files_CO10-7)'
  prefs: []
  type: TYPE_NORMAL
- en: Iterate through the BLAST hits.
  prefs: []
  type: TYPE_NORMAL
- en: '[![8](assets/8.png)](#co_blastomatic__parsing_delimited_text_files_CO10-8)'
  prefs: []
  type: TYPE_NORMAL
- en: Skip records with a percent ID less than the minimum.
  prefs: []
  type: TYPE_NORMAL
- en: '[![9](assets/9.png)](#co_blastomatic__parsing_delimited_text_files_CO10-9)'
  prefs: []
  type: TYPE_NORMAL
- en: Attempt to get the BLAST query sequence ID.
  prefs: []
  type: TYPE_NORMAL
- en: '[![10](assets/10.png)](#co_blastomatic__parsing_delimited_text_files_CO10-10)'
  prefs: []
  type: TYPE_NORMAL
- en: Attempt to find this sequence ID in the annotations.
  prefs: []
  type: TYPE_NORMAL
- en: '[![11](assets/11.png)](#co_blastomatic__parsing_delimited_text_files_CO10-11)'
  prefs: []
  type: TYPE_NORMAL
- en: If found, increment the counter and write the output values.
  prefs: []
  type: TYPE_NORMAL
- en: '[![12](assets/12.png)](#co_blastomatic__parsing_delimited_text_files_CO10-12)'
  prefs: []
  type: TYPE_NORMAL
- en: Quote all the fields to ensure the delimiter is protected.
  prefs: []
  type: TYPE_NORMAL
- en: '[![13](assets/13.png)](#co_blastomatic__parsing_delimited_text_files_CO10-13)'
  prefs: []
  type: TYPE_NORMAL
- en: Close the output file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![14](assets/14.png)](#co_blastomatic__parsing_delimited_text_files_CO10-14)'
  prefs: []
  type: TYPE_NORMAL
- en: Print a final status to the user. The comma in the formatting for `num_written`
    will add a thousands separator to the number.
  prefs: []
  type: TYPE_NORMAL
- en: 'Solution 2: Writing the Output File with csv.DictWriter()'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This next solution differs from the first only in that I use `csv.DictWriter()`
    to write the output file. I generally prefer to use this method as it will handle,
    for instance, properly quoting fields that contain the field separator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO11-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Create a writer object to create the delimited text output file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO11-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Write the header row to the output file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO11-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Write a row of data, passing in a dictionary with the same keys as the `fieldnames`
    defined for the writer.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO11-4)'
  prefs: []
  type: TYPE_NORMAL
- en: The formatting instruction `{:,}` will cause the number to be printed with thousands
    separators.
  prefs: []
  type: TYPE_NORMAL
- en: 'Solution 3: Reading and Writing Files Using pandas'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The pandas version is a little simpler in some ways and a little more complicated
    in others. I chose to store all the output records in a Python list and instantiate
    a new dataframe from that to write the output file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO12-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Read the metadata file into a dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO12-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Read the BLAST hits into a dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO12-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize a list for the output data.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO12-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Select all the BLAST hits with a percent ID greater than or equal to the minimum
    percent.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO12-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Select the metadata for the given query sequence ID.
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](assets/6.png)](#co_blastomatic__parsing_delimited_text_files_CO12-6)'
  prefs: []
  type: TYPE_NORMAL
- en: Verify that the metadata is not empty.
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](assets/7.png)](#co_blastomatic__parsing_delimited_text_files_CO12-7)'
  prefs: []
  type: TYPE_NORMAL
- en: Iterate over the metadata records (even though there should only be one).
  prefs: []
  type: TYPE_NORMAL
- en: '[![8](assets/8.png)](#co_blastomatic__parsing_delimited_text_files_CO12-8)'
  prefs: []
  type: TYPE_NORMAL
- en: Store a new dictionary with the output data.
  prefs: []
  type: TYPE_NORMAL
- en: '[![9](assets/9.png)](#co_blastomatic__parsing_delimited_text_files_CO12-9)'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new dataframe from the output data.
  prefs: []
  type: TYPE_NORMAL
- en: '[![10](assets/10.png)](#co_blastomatic__parsing_delimited_text_files_CO12-10)'
  prefs: []
  type: TYPE_NORMAL
- en: Write the dataframe to the output file, omitting the dataframe index values.
  prefs: []
  type: TYPE_NORMAL
- en: '[![11](assets/11.png)](#co_blastomatic__parsing_delimited_text_files_CO12-11)'
  prefs: []
  type: TYPE_NORMAL
- en: Print the status to the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'Solution 4: Joining Files Using pandas'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this last solution, I use pandas to join the metadata and BLAST dataframes,
    much like the `join` program I illustrated earlier in the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO13-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Read the annotations file and set the index column to `seq_id`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO13-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Read the BLAST hits and set the index column to `qseqid`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO13-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Select the BLAST hits with the desired percent ID, and perform an inner join
    to the annotations using the index columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO13-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Write the desired columns of the `joined` dataframe to the output file using
    the indicated delimiter. Include the index and name it `qseqid`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The join operation is quite complex, so let me take a moment to explain this.
    First, each dataframe must have a unique index, which by default is the row index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead, I want pandas to use the `seq_id` column as the index, which I indicate
    with the `index_col` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'I can also indicate the zeroth field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the index is set to the `seq_id`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, I want the BLAST hits to be indexed on the query sequence ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'I can select the BLAST hits with `pident` greater than or equal to the minimum.
    For instance, I find 190 rows with a value of 90:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: The resulting dataframe is still indexed on the `qseqid` column, so I can join
    it to the annotations where the index values (the sequence IDs) are in common.
    By default, pandas will perform a *left* *join*, selecting all the rows from the
    first or *left* dataframe and substituting null values for rows that have no mate
    in the right dataframe. A *right join* is the opposite of a left join, selecting
    all the records from the *right* dataframe regardless of matches to the left.
    Since I only want the hits that have annotations, I use an *inner* *join*. [Figure 19-3](#fig_19.3)
    demonstrates the joins using Venn diagrams.
  prefs: []
  type: TYPE_NORMAL
- en: '![mpfb 1903](assets/mpfb_1903.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 19-3\. A left join selects all the records from the left table, a right
    joins selects all the records from the right table, and an inner join selects
    only those records present in both
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The join operation creates a new dataframe with the columns of both dataframes,
    just like the `join` tool I showed in [“Using csvkit and csvchk”](#ch19-using-csvkit-and-csvchk):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Another way to write this is to use the `pd.merge()` function, which will default
    to an inner join. I must indicate which columns to use for the joins from the
    left and right dataframes, which in this case are the indexes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'I can use the `joined.to_csv()` method to write the dataframe to the output
    file. Note that the common sequence IDs are the index, which has no column name.
    I want the index included in the output file, so I use `index=True` and `index_name=''qseqid''`
    so that the file matches the expected output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Going Further
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Add the options to filter by other fields like temperature, salinity, or BLAST
    e-value.
  prefs: []
  type: TYPE_NORMAL
- en: Default to including all the columns from both files in the output file, and
    add an option to select a subset of the columns.
  prefs: []
  type: TYPE_NORMAL
- en: Review
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Key points from this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Shell aliases can be used to create shortcuts for common commands.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delimited text files do not always have column headers. This is the case with
    BLAST’s tabular output formats.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `csv` and `pandas` modules can read and write delimited text files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Datasets can be joined on common columns using the `join` command-line tool
    or in Python by using common keys from dictionaries or common indexes in pandas
    dataframes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pandas is a good choice for reading delimited files if you need access to all
    the data in memory—for example, if you need to perform statistical analysis of
    the data or want to quickly access all the values for a column. If you need to
    parse very large delimited files and can process records independently, then use
    the `csv` module for better performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ^([1](ch19.html#idm45963626663048-marker)) You may say to yourself, “My God!
    What have they done?”
  prefs: []
  type: TYPE_NORMAL
