<html><head></head><body>
<div id="sbo-rt-content"><div data-pdf-bookmark="Part II. Getting Your Data" data-type="part" epub:type="part" id="part_getting_data">
<h1><span class="label">Part II. </span>Getting Your Data</h1>
<p>In this part of the book, we start our journey along the dataviz toolchain (see <a data-type="xref" href="#toolchain_scrape">Figure II-1</a>), beginning with a couple of chapters on how to get your data if it hasn’t been provided for you.</p>
<p>In <a data-type="xref" href="ch05.xhtml#chapter_getting_data">Chapter 5</a> we see how to get data off the web, using Python’s Requests library to grab web-based files and consume RESTful APIs. We also see how to use a couple of Python libraries that wrap more complex web APIs, namely Twitter (with Python’s Tweepy) and Google Docs. The chapter ends with an example of lightweight <a href="https://oreil.ly/fjBEA">web scraping</a> with the Beautiful Soup library.</p>
<p>In <a data-type="xref" href="ch06.xhtml#chapter_heavy_scraping">Chapter 6</a> we use Scrapy, Python’s industrial-strength web scraper, to get the Nobel Prize dataset we’ll be using for our web visualization. With this <em>dirty</em> dataset to hand, we’re ready for the next part of the book, <a data-type="xref" href="part03.xhtml#part_clean_explore">Part III</a>.</p>
<figure><div class="figure" id="toolchain_scrape">
<img alt="dpj2 p223" height="857" src="assets/dpj2_p223.png" width="1388"/>
<h6><span class="label">Figure II-1. </span>Our dataviz toolchain: getting the data</h6>
</div></figure>
<div data-type="tip"><h6>Tip</h6>
<p>You can find the code for this part of the book at the <a href="https://github.com/Kyrand/dataviz-with-python-and-js-ed-2">book’s GitHub repo</a>.</p>
</div>
</div></div></body></html>