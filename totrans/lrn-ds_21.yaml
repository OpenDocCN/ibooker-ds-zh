- en: Chapter 16\. Model Selection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第16章 模型选择
- en: 'So far when we fit models, we have used a few strategies to decide which features
    to include:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，当我们拟合模型时，我们已经采用了几种策略来决定包含哪些特征：
- en: Assess model fit with residual plots.
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用残差图评估模型拟合度。
- en: Connect the statistical model to a physical model.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将统计模型与物理模型连接起来。
- en: Keep the model simple.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持模型简单。
- en: Compare improvements in the standard deviation of the residuals and in the MSE
    between increasingly complex models.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较在日益复杂的模型之间残差标准差和MSE的改进。
- en: For example, when we examined the one-variable model of upward mobility in [Chapter 15](ch15.html#ch-linear),
    we found curvature in the residual plot. Adding a second variable greatly improved
    the fit in terms of average loss (MSE and, relatedly, multiple <math><msup><mi>R</mi>
    <mn>2</mn></msup></math> ), but some curvature remained in the residuals. A seven-variable
    model made little improvement over the two-variable model in terms of a decrease
    in MSE, so although the two-variable model still showed some patterns in the residuals,
    we opted for this simpler model.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在我们检查单变量模型中的上升流动性时，我们发现残差图中有曲率。增加第二个变量大大改善了平均损失（MSE以及相关的多个<math><msup><mi>R</mi>
    <mn>2</mn></msup></math>），但残差中仍然存在一些曲率。一个七变量模型在降低MSE方面几乎没有比两变量模型更多的改进，因此尽管两变量模型仍然显示出残差中的一些模式，我们选择了这个更简单的模型。
- en: As another example, when we model the weight of a donkey in [Chapter 18](ch18.html#ch-donkey),
    we will take guidance from a physical model. We’ll ignore the donkey’s appendages
    and draw on the similarity between a barrel and a donkey’s body to begin fitting
    a model that explains weight by its length and girth (comparable to a barrel’s
    height and circumference). We’ll then continue to adjust that model by adding
    categorical features related to the donkey’s physical condition and age, collapsing
    categories, and excluding other possible features to keep the model simple.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是，在我们建立一只驴的体重模型时，在[第18章](ch18.html#ch-donkey)中，我们将从物理模型中获取指导。我们将忽略驴的附肢，并借鉴桶和驴身体的相似性开始拟合一个模型，通过其长度和围度（类似于桶的高度和周长）来解释体重。然后，我们将继续通过添加与驴的物理状况和年龄相关的分类特征来调整该模型，合并类别，并排除其他可能的特征，以保持模型简单。
- en: The decisions we make in building these models are based on judgment calls,
    and in this chapter we augment these with more formal criteria. To begin, we provide
    an example that shows why it’s typically not a good idea to include too many features
    in a model. This phenomenon, called *overfitting*, often leads to models that
    follow the data too closely and capture some of the noise in the data. Then, when
    new observations come along, the predictions are worse than those from a simpler
    model. The remainder of the chapter provides techniques, such as the train-test
    split, cross-validation, and regularization, for limiting the impact of overfitting.
    These techniques are especially helpful when there are a large number of potential
    features to include in a model. We also provide a synthetic example, where we
    know the true model, to explain the concepts of model variance and bias and how
    they relate to over- and underfitting.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在构建这些模型时所做的决策基于判断，而在本章中，我们将这些决策与更正式的标准结合起来。首先，我们提供一个示例，说明为什么在模型中包含太多特征通常不是一个好主意。这种现象称为*过度拟合*，经常导致模型过于贴近数据并捕捉到数据中的一些噪音。然后，当新的观察到来时，预测结果比较简单模型更糟糕。本章的其余部分提供了一些技术，如训练集-测试集分割、交叉验证和正则化，来限制过度拟合的影响。当模型可能包含大量潜在特征时，这些技术尤为有用。我们还提供一个合成示例，我们在其中了解到真实模型，以解释模型方差和偏差的概念及其与过拟合和欠拟合的关系。
- en: Overfitting
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过度拟合
- en: When we have many features available to include in a model, choosing which ones
    to include or exclude rapidly gets complicated. In the upward mobility example
    in [Chapter 15](ch15.html#ch-linear), we chose two of the seven variables to fit
    the model, but there are 21 pairs of features that we could have examined and
    fitted for a two-variable model. And there are over one hundred models to choose
    from if we consider all one-, two-, …, seven-variable models. It can be hard to
    examine hundreds of residual plots to decide how simple is simple enough, and
    to settle on a model. Unfortunately, the notion of minimizing MSE isn’t entirely
    helpful either. With each variable that we add to a model, the MSE typically gets
    smaller. Recall from the geometric perspective of model fitting ([Chapter 15](ch15.html#ch-linear))
    that adding a feature to a model adds an <math><mi>n</mi></math> -dimensional
    vector to the feature space, and the error between the outcome vector and its
    projection into the space spanned by the explanatory variables shrinks. We might
    view this as a good thing because our model fits the data more closely, but there
    is a danger in overfitting.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有许多可用于模型的特征时，选择包括或排除哪些特征会迅速变得复杂。在上升移动性的例子中，在[第15章](ch15.html#ch-linear)中，我们选择了七个变量中的两个来拟合模型，但是对于一个双变量模型，我们可以检查并拟合21对特征。如果考虑所有一、二、...、七个变量模型，还有超过一百种模型可供选择。检查数百个残差图以决定何时简单到足够，以及确定一个模型是相当困难的。不幸的是，最小化均方误差的概念并非完全有用。当我们向模型添加一个变量时，均方误差通常会变小。回顾模型拟合的几何视角（[第15章](ch15.html#ch-linear)），添加一个特征到模型中会添加一个
    <math><mi>n</mi></math> -维向量到特征空间中，并且结果向量与其在由解释变量张成的空间内的投影之间的误差会减小。我们可能认为这是一件好事，因为我们的模型更接近数据，但过度拟合存在危险。
- en: Overfitting happens when the model follows the data too closely and picks up
    the variability in the random noise in the outcome. When this happens, new observations
    are not well-predicted. An example helps clarify this idea.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型过于紧密地跟随数据并捕捉到结果中的随机噪声变化时，就会发生过度拟合。当这种情况发生时，新的观察结果就无法很好地预测。举个例子可以帮助澄清这个概念。
- en: 'Example: Energy Consumption'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例：能源消耗
- en: 'In this example, we examine a [dataset you can download](https://oreil.ly/ngD4G)
    that contains information from utility bills for a private residence in Minnesota.
    We have records of the monthly gas usage in a home (cubic feet) and the average
    temperature that month (degrees Fahrenheit).^([1](ch16.html#id1643)) We first
    read in the data:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们研究一个可以下载的[数据集](https://oreil.ly/ngD4G)，其中包含明尼苏达州一个私人住宅的公用事业账单信息。我们记录了一个家庭每月的气体使用量（立方英尺）和该月的平均温度（华氏度）。^([1](ch16.html#id1643))
    我们首先读取数据：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '|   | temp | ccf |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '|   | 温度 | 立方英尺 |'
- en: '| --- | --- | --- |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **0** | 29 | 166 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 29 | 166 |'
- en: '| **1** | 31 | 179 |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 31 | 179 |'
- en: '| **2** | 15 | 224 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 15 | 224 |'
- en: '| **...** | ... | ... |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| **...** | ... | ... |'
- en: '| **96** | 76 | 11 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| **96** | 76 | 11 |'
- en: '| **97** | 55 | 32 |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| **97** | 55 | 32 |'
- en: '| **98** | 39 | 91 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| **98** | 39 | 91 |'
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will begin by looking at a scatterplot of gas consumption as a function
    of temperature:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从查看气体消耗作为温度函数的散点图开始：
- en: '![](assets/leds_16in01.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in01.png)'
- en: The relationship shows curvature (left plot), but when we try to straighten
    it with a log transformation (right plot), a different curvature arises in the
    low-temperature region. Additionally, there are two unusual points. When we refer
    back to the documentation, we find that these points represent recording errors,
    so we remove them.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这个关系显示了曲率（左图），但当我们尝试通过对数变换将其变成直线（右图）时，在低温区域出现了不同的曲率。此外，还有两个异常点。当我们查阅文档时，发现这些点代表记录错误，因此我们将它们移除。
- en: 'Let’s see if a quadratic curve can capture the relationship between gas usage
    and temperature. Polynomials are still considered linear models. They are linear
    in their polynomial features. For example, we can express a quadratic model as:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 看看二次曲线能否捕捉气体使用量和温度之间的关系。多项式仍然被认为是线性模型。它们在其多项式特征中是线性的。例如，我们可以将二次模型表示为：
- en: <math display="block"><msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi>
    <mn>1</mn></msub> <mi>x</mi> <mo>+</mo> <msub><mi>θ</mi> <mn>2</mn></msub> <msup><mi>x</mi>
    <mn>2</mn></msup></math>
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi>
    <mn>1</mn></msub> <mi>x</mi> <mo>+</mo> <msub><mi>θ</mi> <mn>2</mn></msub> <msup><mi>x</mi>
    <mn>2</mn></msup></math>
- en: 'This model is linear in the features <math><mi>x</mi></math> and <math><msup><mi>x</mi>
    <mn>2</mn></msup></math> , and in matrix notation we can write this model as <math><mrow><mtext
    mathvariant="bold">X</mtext></mrow> <mrow><mi mathvariant="bold-italic">θ</mi></mrow></math>
    , where <math><mtext mathvariant="bold">X</mtext></math> is the design matrix:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型对特征 <math><mi>x</mi></math> 和 <math><msup><mi>x</mi> <mn>2</mn></msup></math>
    是线性的，在矩阵表示中，我们可以将这个模型写成 <math><mrow><mtext mathvariant="bold">X</mtext></mrow>
    <mrow><mi mathvariant="bold-italic">θ</mi></mrow></math> ，其中 <math><mtext mathvariant="bold">X</mtext></math>
    是设计矩阵：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mrow><mo>⌈</mo> <mtable columnalign="center" columnspacing="1em"
    rowspacing="4pt"><mtr><mtd><mn>1</mn></mtd> <mtd><msub><mi>x</mi> <mn>1</mn></msub></mtd>
    <mtd><msubsup><mi>x</mi> <mn>1</mn> <mn>2</mn></msubsup></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd> <mtd><msubsup><mi>x</mi> <mn>2</mn>
    <mn>2</mn></msubsup></mtd></mtr> <mtr><mtd><mrow><mo>⋮</mo></mrow></mtd> <mtd><mrow><mo>⋮</mo></mrow></mtd>
    <mtd><mrow><mo>⋮</mo></mrow></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><msub><mi>x</mi>
    <mi>n</mi></msub></mtd> <mtd><msubsup><mi>x</mi> <mi>n</mi> <mn>2</mn></msubsup></mtd></mtr></mtable>
    <mo>⌉</mo></mrow></mtd></mtr></mtable></math>
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mrow><mo>⌈</mo> <mtable columnalign="center" columnspacing="1em"
    rowspacing="4pt"><mtr><mtd><mn>1</mn></mtd> <mtd><msub><mi>x</mi> <mn>1</mn></msub></mtd>
    <mtd><msubsup><mi>x</mi> <mn>1</mn> <mn>2</mn></msubsup></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd> <mtd><msubsup><mi>x</mi> <mn>2</mn>
    <mn>2</mn></msubsup></mtd></mtr> <mtr><mtd><mrow><mo>⋮</mo></mrow></mtd> <mtd><mrow><mo>⋮</mo></mrow></mtd>
    <mtd><mrow><mo>⋮</mo></mrow></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><msub><mi>x</mi>
    <mi>n</mi></msub></mtd> <mtd><msubsup><mi>x</mi> <mi>n</mi> <mn>2</mn></msubsup></mtd></mtr></mtable>
    <mo>⌉</mo></mrow></mtd></mtr></mtable></math>
- en: 'We can create the polynomial features of the design matrix with the `Polynomial​Fea⁠tures`
    tool in `scikit-learn`:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`scikit-learn`中的`Polynomial​Fea⁠tures`工具创建设计矩阵的多项式特征：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We set the parameter `include_bias` to `False` because we plan to fit the polynomial
    with the `LinearRegression` method in `scikit-learn`, and by default it includes
    the constant term in the model. We fit the polynomial with:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将参数`include_bias`设置为`False`，因为我们计划在`scikit-learn`中使用`LinearRegression`方法拟合多项式，默认情况下会在模型中包括常数项。我们用以下方法拟合多项式：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To get a quick idea as to the quality of the fit, let’s overlay the fitted
    quadratic on the scatterplot and also look at the residuals:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速了解拟合的质量，让我们在散点图上叠加拟合的二次曲线，并查看残差：
- en: '![](assets/leds_16in02.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in02.png)'
- en: The quadratic captures the curve in the data quite well, but the residuals show
    a slight upward trend in the temperature range of 70°F to 80°F, which indicates
    some lack of fit. There is also some funneling in the residuals, where the variability
    in gas consumption is greater in the colder months. We might expect this behavior
    since we have only the monthly average temperature.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 二次多项式很好地捕捉了数据中的曲线，但残差显示出在70°F到80°F温度范围内略微上升的趋势，这表明有些拟合不足。此外，残差中也有些漏斗形状，在较冷的月份中，燃气消耗的变化性更大。我们可能会预期这种行为，因为我们只有月均温度。
- en: 'For comparison, we fit a few more models with higher-degree polynomials and
    collectively examine the fitted curves:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较，我们使用更高阶的多项式拟合了几个模型，并集体检查拟合曲线：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Warning
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: We use the polynomial features in this section to demonstrate over-fitting,
    but directly fitting the <math><mi>x</mi> <mo>,</mo> <msup><mi>x</mi> <mn>2</mn></msup>
    <mo>,</mo> <msup><mi>x</mi> <mn>3</mn></msup> <mo>,</mo> <mo>…</mo></math> polynomials
    is not advisable in practice. Unfortunately, these polynomial features tend to
    be highly correlated. For example, the correlation between <math><mi>x</mi></math>
    and <math><msup><mi>x</mi> <mn>2</mn></msup></math> for the energy data is 0.98\.
    Highly correlated features give unstable coefficients, where a small change in
    an x-value can lead to a large change in the coefficients of the polynomial. Also,
    when the x-values are large, the normal equations are poorly conditioned and the
    coefficients can be difficult to interpret and compare.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中使用多项式特征来演示过拟合，但直接拟合<math><mi>x</mi> <mo>,</mo> <msup><mi>x</mi> <mn>2</mn></msup>
    <mo>,</mo> <msup><mi>x</mi> <mn>3</mn></msup> <mo>,</mo> <mo>…</mo></math>等多项式在实践中是不可取的。不幸的是，这些多项式特征往往高度相关。例如，能源数据中<math><mi>x</mi></math>和<math><msup><mi>x</mi>
    <mn>2</mn></msup></math>之间的相关性为0.98。高度相关的特征会导致不稳定的系数，即x值的微小变化可能会导致多项式系数的大幅变化。此外，当x值较大时，正规方程的条件很差，系数的解释和比较可能会很困难。
- en: A better practice is to use polynomials that have been constructed to be orthogonal
    to one another. These polynomials fill the same space as the original polynomials,
    but they are uncorrelated with one another and give a more stable fit.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的做法是使用构造成彼此正交的多项式。这些多项式填充与原始多项式相同的空间，但它们彼此不相关，并提供更稳定的拟合。
- en: 'Let’s place all of the polynomial fits on the same graph so that we can see
    how the higher-degree polynomials bend more and more strangely:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将所有的多项式拟合放在同一张图上，这样我们可以看到高阶多项式的弯曲越来越奇怪：
- en: '![](assets/leds_16in03.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in03.png)'
- en: 'We can also visualize the different polynomial fits in separate facets:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在单独的面板中可视化不同的多项式拟合：
- en: '![](assets/leds_16in04.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in04.png)'
- en: The degree 1 curve (the straight line) in the upper-left facet misses the curved
    pattern in the data. The degree 2 curve begins to capture it, and the degree 3
    curve looks like an improvement, but notice the upward bend at the right side
    of the plot. The polynomials of degrees 6, 8, and 12 follow the data increasingly
    closely, as they get increasingly curvy. These polynomials seem to fit spurious
    bumps in the data. Altogether, these six curves illustrate under- and overfitting.
    The fitted line in the upper left underfits and misses the curvature entirely.
    And the degree 12 polynomial in the bottom right definitely overfits with a wiggly
    pattern that we don’t think makes sense in this context.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 左上方面的一次曲线（直线）未能捕捉数据中的曲线模式。二次曲线开始捕捉，而三次曲线看起来有所改进，但请注意图表右侧的上升弯曲。六次、八次和十二次的多项式越来越贴近数据，因为它们变得越来越曲折。这些多项式似乎适应数据中的虚假波动。总体来看，这六条曲线说明了欠拟合和过拟合。左上角的拟合线欠拟合，完全错过了曲线。而右下角的十二次多项式明显过拟合，呈现了我们认为在这种情况下无意义的蜿蜒模式。
- en: In general, as we add more features, models get more complex and the MSE drops,
    but at the same time, the fitted model grows increasingly erratic and sensitive
    to the data. When we overfit, the model follows the data too closely, and predictions
    are poor for new observations. One simple technique to assess a fitted model is
    to compute the MSE on new data, data that were not used in building the model.
    Since we don’t typically have the capacity to acquire more data, we set aside
    some of the original data to evaluate the fitted model. This technique is the
    topic of the next section.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，随着特征的增加，模型变得更加复杂，均方误差（MSE）下降，但与此同时，拟合的模型变得越来越不稳定和对数据敏感。当我们过度拟合时，模型过于紧密地跟随数据，对新观测的预测效果很差。评估拟合模型的一种简单技术是在新数据上计算MSE，这些数据未用于建模。由于通常情况下我们无法获取更多数据，因此我们会保留一些原始数据来评估拟合的模型。这个技术是下一节的主题。
- en: Train-Test Split
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练-测试分离
- en: Although we want to use all of our data in building a model, we also want to
    get a sense of how the model behaves with new data. We often do not have the luxury
    of collecting additional data to assess a model, so instead we set aside a portion
    of our data, called the *test set*, to stand in for new data. The remainder of
    the data is called the *train set*, and we use this portion to build the model.
    Then, after we have chosen a model, we pull out the test set and see how well
    the model (fitted on the train set) predicts the outcomes in the test set. [Figure 16-1](#train-test-diagram)
    demonstrates this idea.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们希望在建立模型时使用所有数据，但我们也想了解模型在新数据上的表现。通常情况下，我们无法收集额外的数据来评估模型，因此我们会将部分数据保留下来，称为*测试集*，以代表新数据。其余的数据称为*训练集*，我们使用这部分数据来建立模型。然后，在选择了模型之后，我们提取测试集，并查看模型（在训练集上拟合）在测试集中预测结果的表现。[图 16-1](#train-test-diagram)
    演示了这个概念。
- en: '![](assets/leds_1601.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_1601.png)'
- en: 'Figure 16-1\. The train-test split divides the data into two parts: the train
    set is used to build the model and the test set evaluates that model'
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 16-1\. 训练-测试分离将数据分为两部分：训练集用于建立模型，测试集评估该模型
- en: Typically, the test set consists of 10% to 25% of the data. What might not be
    clear from the diagram is that this division into two parts is often made at random,
    so the train and test sets are similar to each other.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，测试集包含数据的10%到25%。从图表中可能不清楚的是，这种分割通常是随机进行的，因此训练集和测试集彼此相似。
- en: 'We can describe this process using the notion introduced in [Chapter 15](ch15.html#ch-linear).
    The design matrix, <math><mtext mathvariant="bold">X</mtext></math> , and outcome,
    <math><mrow><mi mathvariant="bold">y</mi></mrow></math> , are each divided into
    two parts; the design matrix, labeled <math><msub><mtext mathvariant="bold">X</mtext>
    <mi>T</mi></msub></math> , and corresponding outcomes, <math><msub><mrow><mi mathvariant="bold">y</mi></mrow>
    <mi>T</mi></msub></math> , form the train set. We minimize the average squared
    loss over <math><mi mathvariant="bold-italic">θ</mi></math> with these data:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用[第 15 章](ch15.html#ch-linear) 中介绍的概念来描述这个过程。设计矩阵，<math><mtext mathvariant="bold">X</mtext></math>
    ，和结果，<math><mrow><mi mathvariant="bold">y</mi></mrow></math> ，各自被分成两部分；标记为<math><msub><mtext
    mathvariant="bold">X</mtext> <mi>T</mi></msub></math> 的设计矩阵和相应的结果，标记为<math><msub><mrow><mi
    mathvariant="bold">y</mi></mrow> <mi>T</mi></msub></math> ，形成训练集。我们通过这些数据最小化<math><mi
    mathvariant="bold-italic">θ</mi></math> 的平均平方损失：
- en: <math display="block"><munder><mo movablelimits="true">min</mo> <mrow><mi mathvariant="bold-italic">θ</mi></mrow></munder>
    <mo fence="false" stretchy="false">‖</mo> <msub><mrow><mi mathvariant="bold">y</mi></mrow>
    <mi>T</mi></msub> <mo>−</mo> <mrow><msub><mtext mathvariant="bold">X</mtext> <mi>T</mi></msub></mrow>
    <mrow><mrow><mi mathvariant="bold-italic">θ</mi></mrow></mrow> <msup><mo fence="false"
    stretchy="false">‖</mo> <mn>2</mn></msup></math>
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><munder><mo movablelimits="true">min</mo> <mrow><mi mathvariant="bold-italic">θ</mi></mrow></munder>
    <mo fence="false" stretchy="false">‖</mo> <msub><mrow><mi mathvariant="bold">y</mi></mrow>
    <mi>T</mi></msub> <mo>−</mo> <mrow><msub><mtext mathvariant="bold">X</mtext> <mi>T</mi></msub></mrow>
    <mrow><mrow><mi mathvariant="bold-italic">θ</mi></mrow></mrow> <msup><mo fence="false"
    stretchy="false">‖</mo> <mn>2</mn></msup></math>
- en: 'The coefficient, <math><msub><mrow><mover><mi mathvariant="bold-italic">θ</mi>
    <mo mathvariant="bold" stretchy="false">^</mo></mover></mrow> <mi>T</mi></msub></math>
    , that minimizes the training error is used to predict outcomes for the test set,
    which is labeled <math><msub><mtext mathvariant="bold">X</mtext> <mi>S</mi></msub></math>
    and <math><msub><mrow><mi mathvariant="bold">y</mi></mrow> <mi>S</mi></msub></math>
    :'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化训练误差的系数<math><msub><mrow><mover><mi mathvariant="bold-italic">θ</mi> <mo
    mathvariant="bold" stretchy="false">^</mo></mover></mrow> <mi>T</mi></msub></math>
    用于预测测试集的结果，其中标记为<math><msub><mtext mathvariant="bold">X</mtext> <mi>S</mi></msub></math>
    和 <math><msub><mrow><mi mathvariant="bold">y</mi></mrow> <mi>S</mi></msub></math>：
- en: <math display="block"><mo fence="false" stretchy="false">‖</mo> <msub><mrow><mi
    mathvariant="bold">y</mi></mrow> <mi>S</mi></msub> <mo>−</mo> <mrow><msub><mtext
    mathvariant="bold">X</mtext> <mi>S</mi></msub></mrow> <mrow><msub><mrow><mover><mi
    mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo></mover></mrow>
    <mi>T</mi></msub></mrow> <msup><mo fence="false" stretchy="false">‖</mo> <mn>2</mn></msup></math>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mo fence="false" stretchy="false">‖</mo> <msub><mrow><mi
    mathvariant="bold">y</mi></mrow> <mi>S</mi></msub> <mo>−</mo> <mrow><msub><mtext
    mathvariant="bold">X</mtext> <mi>S</mi></msub></mrow> <mrow><msub><mrow><mover><mi
    mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo></mover></mrow>
    <mi>T</mi></msub></mrow> <msup><mo fence="false" stretchy="false">‖</mo> <mn>2</mn></msup></math>
- en: Since <math><msub><mtext mathvariant="bold">X</mtext> <mi>S</mi></msub></math>
    and <math><msub><mrow><mi mathvariant="bold">y</mi></mrow> <mi>S</mi></msub></math>
    are not used to build the model, they give a reasonable estimate of the loss we
    might expect for a new observation.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于<math><msub><mtext mathvariant="bold">X</mtext> <mi>S</mi></msub></math>和<math><msub><mrow><mi
    mathvariant="bold">y</mi></mrow> <mi>S</mi></msub></math>没有用于构建模型，它们可以合理估计我们可能对新观测到的损失。
- en: 'We demonstrate the train-test split with our polynomial model for gas consumption
    from the previous section. To do this, we carry out the following steps:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用上一节中的气耗多项式模型来演示训练-测试分离。为此，我们执行以下步骤：
- en: Split the data at random into two parts, the train and test sets.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据随机分为两部分，训练集和测试集。
- en: Fit several polynomial models to the train set and choose one.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对训练集拟合几个多项式模型并选择一个。
- en: Compute the MSE on the test set for the chosen polynomial (with coefficients
    fitted on the train set).
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算在所选多项式（其系数由训练集拟合）上的测试集的MSE。
- en: 'For the first step, we divide the data with the `train_test_split` method in
    `scikit-learn` and set aside 22 observations for model evaluation:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一步，我们使用`scikit-learn`中的`train_test_split`方法将数据随机分为两部分，并为模型评估设置了22个观测值：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As in the previous section, we fit models of gas consumption to various polynomials
    in temperature. But this time, we use only the training data:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一节类似，我们将气温与燃气消耗的模型拟合到各种多项式中。但这次，我们只使用训练数据：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We find the MSE for each of these models:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们找出了每个模型的MSE：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To visualize the change in MSE, we plot MSE for each fitted polynomial against
    its degree:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化MSE的变化，我们将每个拟合的多项式的MSE绘制成其次数的图：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](assets/leds_16in05.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in05.png)'
- en: Notice that the training error decreases with the additional model complexity.
    We saw earlier that the higher-order polynomials showed a wiggly behavior that
    we don’t think reflects the underlying structure in the data. With this in mind,
    we might choose a model that is simpler but shows a large reduction in MSE. That
    could be degree 3, 4, or 5\. Let’s go with degree 3 since the difference between
    these three models in terms of MSE is quite small and it’s the simplest.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到随着模型复杂度的增加，训练误差逐渐减小。我们之前看到高阶多项式显示出了我们认为不反映数据中潜在结构的起伏行为。考虑到这一点，我们可能会选择一个更简单但MSE显著减小的模型。这可能是3、4或5次方。让我们选择3次方，因为这三个模型在MSE方面的差异非常小，而且它是最简单的。
- en: 'Now that we have chosen our model, we provide an independent assessment of
    its MSE using the test set. We prepare the design matrix for the test set and
    use the degree 3 polynomial fitted on the train set to predict the outcome for
    each row in the test set. Lastly, we compute the MSE for the test set:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经选择了我们的模型，我们使用测试集提供了对其MSE的独立评估。我们为测试集准备设计矩阵，并使用在训练集上拟合的3次多项式来预测测试集中每一行的结果。最后，我们计算了测试集的MSE：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The MSE for this model is quite a bit larger than the MSE computed on the training
    data. This demonstrates the problem with using the same data to fit and evaluate
    a model: the MSE doesn’t adequately reflect the MSE for a new observation. To
    further demonstrate the problem with overfitting, we compute the error for the
    test for each of these models:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的均方误差（MSE）比在训练数据上计算的MSE要大得多。这说明了在使用相同数据来拟合和评估模型时所存在的问题：MSE并不充分反映出对新观测的MSE。为了进一步说明过拟合问题，我们计算了这些模型的测试误差：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In practice, we do not look at the test set until we have committed to a model.
    Alternating between fitting a model on the train set and evaluating it on the
    test set can lead to overfitting. But for demonstration purposes, we plot the
    MSE on the test set for all of the polynomial models we fitted:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们不会在承诺模型之前查看测试集。在训练集上拟合模型并在测试集上评估它之间交替可以导致过拟合。但出于演示目的，我们绘制了我们拟合的所有多项式模型在测试集上的MSE：
- en: '![](assets/leds_16in06.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in06.png)'
- en: Notice how the MSE for the test set is larger than the MSE for the train set
    for all models, not just the model that we selected. More importantly, notice
    how the MSE for the test set initially decreases as the model goes from underfitting
    to one that follows the curvature in the data a bit better. Then, as the model
    grows in complexity, the MSE for the test set increases. These more complex models
    overfit the training data and lead to large errors in predicting the test set.
    An idealization of this phenomenon is captured in the diagram in [Figure 16-2](#train-test-overfit).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于所有模型而言，测试集的均方误差（MSE）大于训练集的均方误差，而不仅仅是我们选择的模型。更重要的是，注意当模型从欠拟合到更好地拟合数据曲线时，测试集的均方误差最初是下降的。然后，随着模型复杂度的增加，测试集的均方误差增加。这些更复杂的模型对训练数据过拟合，导致预测测试集时出现较大的误差。这种现象的一个理想化示意图如[图
    16-2](#train-test-overfit)所示。
- en: '![](assets/leds_1602.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_1602.png)'
- en: Figure 16-2\. As the model grows in complexity, the train set error shrinks
    and the test set error increases
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 16-2\. 随着模型复杂度的增加，训练集的误差减少，而测试集的误差增加
- en: The test data provides an assessment of the prediction error for new observations.
    It is crucial to use the test set only once, after we have committed to a model.
    Otherwise, we fall into the trap of using the same data to choose and evaluate
    the model. When choosing the model, we fell back on the simplicity argument because
    we were aware that increasingly complex models tend to overfit. However, we can
    extend the train-test method to help select the model as well. This is the topic
    of the next section.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据提供新观察的预测误差评估。仅在我们已经选择了模型之后才使用测试集是至关重要的。否则，我们会陷入使用相同数据选择和评估模型的陷阱中。在选择模型时，我们回归到了简单性的论点，因为我们意识到越来越复杂的模型往往会过拟合。然而，我们也可以扩展训练-测试方法来帮助选择模型。这是下一节的主题。
- en: Cross-Validation
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证
- en: We can use the train-test paradigm to help us choose a model. The idea is to
    further divide the train set into separate parts where we fit the model on one
    part and evaluate it on another. This approach is called *cross-validation*. We
    describe one version, called <math><mi>k</mi></math> *-fold cross-validation*.
    [Figure 16-3](#cvdiagram) shows the idea behind this division of the data.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用训练-测试范式来帮助选择模型。其思想是进一步将训练集分成单独的部分，在其中一个部分上拟合模型，然后在另一个部分上评估模型。这种方法称为*交叉验证*。我们描述的是一种版本，称为<math><mi>k</mi></math>
    *-折叠交叉验证*。[图 16-3](#cvdiagram)展示了这种数据划分背后的思想。
- en: '![](assets/leds_1603.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_1603.png)'
- en: Figure 16-3\. An example of fivefold cross-validation in which the train set
    is divided into five parts that are used in turn to validate models built on the
    remainder of the data
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 16-3\. 一个例子展示了五折交叉验证，其中训练集被分为五部分，轮流用于验证在其余数据上构建的模型
- en: 'Cross-validation can help select the general form of a model. By this we mean
    the degree of the polynomial, the number of features in the model, or a cutoff
    for a regularization penalty (covered in the next section). The basic steps behind
    <math><mi>k</mi></math> -fold cross-validation are as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证可以帮助选择模型的一般形式。这包括多项式的阶数，模型中的特征数量，或者正则化惩罚的截止（在下一节中介绍）。<math><mi>k</mi></math>
    -折叠交叉验证的基本步骤如下：
- en: Divide the train set into <math><mi>k</mi></math> parts of roughly the same
    size; each part is called a *fold*. Use the same technique that was used to create
    the train and test sets to make the folds. Typically, we divide the data at random.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练集分成<math><mi>k</mi></math>个大致相同大小的部分；每部分称为一个*折叠*。使用与创建训练集和测试集相同的技术来创建这些折叠。通常情况下，我们随机划分数据。
- en: 'Set one fold aside to act as a test set:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将一个折叠保留作为测试集：
- en: Fit all models on the remainder of the training data (the training data less
    the particular fold).
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在剩余的训练数据上拟合所有模型（训练数据减去特定折叠的数据）。
- en: Use the fold you set aside to evaluate all of these models.
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用您保留的折叠来评估所有这些模型。
- en: Repeat this process for a total of <math><mi>k</mi></math> times, where each
    time you set aside one fold, use the rest of the train set to fit the models,
    and evaluate them on the fold that was set aside.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复此过程共<math><mi>k</mi></math>次，每次将一个折叠保留出来，使用剩余的训练集来拟合模型，并在保留的折叠上评估模型。
- en: Combine the error in fitting each model across the folds, and choose the model
    with the smallest error.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并每个模型在折叠中的拟合误差，并选择具有最小误差的模型。
- en: These fitted models will not have identical coefficients across folds. As an
    example, when we fit a polynomial of, say, degree 3, we average the MSE across
    the <math><mi>k</mi></math> folds to get an average MSE for the <math><mi>k</mi></math>
    fitted polynomials of degree 3\. We then compare the MSEs and choose the degree
    of the polynomial with the lowest MSE. The actual coefficients for the <math><mi>x</mi></math>
    , <math><msup><mi>x</mi> <mn>2</mn></msup></math> , and <math><msup><mi>x</mi>
    <mn>3</mn></msup></math> terms in the cubic polynomial are not the same in each
    of the <math><mi>k</mi></math> fits. Once the polynomial degree is selected, we
    refit the model using all of the training data and evaluate it on the test set.
    (We haven’t used the test set in any of the earlier steps to select the model.)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这些拟合模型在不同的折叠中不会具有相同的系数。例如，当我们拟合一个三次多项式时，我们对<math><mi>k</mi></math>个折叠中的MSE取平均值，得到三次拟合多项式的平均MSE。然后我们比较这些MSE，并选择具有最低MSE的多项式次数。在三次多项式中，<math><mi>x</mi></math>，<math><msup><mi>x</mi><mn>2</mn></msup></math>和<math><msup><mi>x</mi><mn>3</mn></msup></math>项的实际系数在每个<math><mi>k</mi></math>个拟合中是不同的。一旦选择了多项式次数，我们使用所有训练数据重新拟合模型，并在测试集上评估它。（在选择模型的任何早期步骤中，我们没有使用测试集。）
- en: Typically, we use 5 or 10 folds. Another popular choice puts one observation
    in each fold. This special case is called *leave-one-out cross-validation*. Its
    popularity stems from the simplicity in adjusting a least squares fit to have
    one fewer observation.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们使用5或10个折叠。另一种流行的选择是将一个观察结果放入每个折叠中。这种特殊情况称为*留一法交叉验证*。其流行之处在于调整最小二乘拟合以减少一个观察结果的简单性。
- en: Generally, <math><mi>k</mi></math> -fold cross-validation takes some computation
    time since we typically have to refit each model from scratch for each fold. The
    `scikit-learn` library provides a convenient [`sklearn.model_selection.KFold`](https://oreil.ly/tnHTv)
    class to implement <math><mi>k</mi></math> -fold cross-validation.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，<math><mi>k</mi></math>折交叉验证需要一些计算时间，因为我们通常必须为每个折叠从头开始重新拟合每个模型。`scikit-learn`库提供了一个方便的[`sklearn.model_selection.KFold`](https://oreil.ly/tnHTv)类来实现<math><mi>k</mi></math>折交叉验证。
- en: To give you an idea of how k-fold cross-validation works, we’ll demonstrate
    the technique on the gas consumption example. However, this time we’ll fit a different
    type of model. In the original scatterplot of the data, it looks like the points
    fall along two connected line segments. In cold temperatures, the relationship
    between gas consumption and temperature looks roughly linear with a negative slope
    of about <math><mo>−</mo> <mn>4</mn></math> cubic ft/degree, and in warmer months,
    the relationship appears nearly flat. So, rather than fitting a polynomial, we
    can fit a bent line to the data.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让你了解k折交叉验证的工作原理，我们将在燃气消耗示例上演示这种技术。但是，这次我们将拟合不同类型的模型。在数据的原始散点图中，看起来点落在两条连接的线段上。在寒冷的温度下，燃气消耗与温度之间的关系看起来大致是负斜率，约为<math><mo>−</mo><mn>4</mn></math>
    立方英尺/度，而在温暖的月份，关系则似乎几乎是平坦的。因此，我们可以拟合一条弯曲的线条而不是拟合多项式。
- en: 'Let’s start by fitting a line with a bend at 65 degrees. To do this, we create
    a feature that enables the points with temperatures above 65°F to have a different
    slope. The model is:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从65度处拟合一条有弯曲的线。为此，我们创建一个特征，使得温度高于65°F的点具有不同的斜率。该模型是：
- en: <math display="block"><mi>y</mi> <mo>=</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo>+</mo> <msub><mi>θ</mi>
    <mn>2</mn></msub> <mo stretchy="false">(</mo> <mi>x</mi> <mo>−</mo> <mn>65</mn>
    <msup><mo stretchy="false">)</mo> <mo>+</mo></msup></math>
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mi>y</mi> <mo>=</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo>+</mo> <msub><mi>θ</mi>
    <mn>2</mn></msub> <mo stretchy="false">(</mo> <mi>x</mi> <mo>−</mo> <mn>65</mn>
    <msup><mo stretchy="false">)</mo> <mo>+</mo></msup></math>
- en: 'Here, <math><mo stretchy="false">(</mo>  <msup><mo stretchy="false">)</mo>
    <mo>+</mo></msup></math> stands for “positive part,” so when <math><mi>x</mi></math>
    is less than 65 it evaluates to 0, and when <math><mi>x</mi></math> is 65 or greater
    it is just <math><mi>x</mi> <mo>−</mo> <mn>65</mn></math> . We create this new
    feature and add it to the design matrix:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，<math><mo stretchy="false">(</mo><msup><mo stretchy="false">)</mo><mo>+</mo></msup></math>代表“正部分”，所以当<math><mi>x</mi></math>小于65时，它评估为0，当<math><mi>x</mi></math>大于或等于65时，它就是<math><mi>x</mi><mo>−</mo><mn>65</mn></math>。我们创建这个新特征并将其添加到设计矩阵中：
- en: '[PRE14]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then we fit the model with these two features:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用这两个特征拟合模型：
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let’s overlay this fitted “curve” on the scatterplot to see how well it captures
    the shape of the data:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这条拟合的“曲线”叠加在散点图上，看看它如何捕捉数据的形状：
- en: '![](assets/leds_16in07.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in07.png)'
- en: 'This model appears to fit the data much better than a polynomial. But many
    bent line models are possible. The line might bend at 55 degrees or 60 degrees,
    and so on. We can use <math><mi>k</mi></math> -fold cross-validation to choose
    the temperature value at which the line bends. Let’s consider models with bends
    at <math><mn>40</mn> <mo>,</mo> <mn>41</mn> <mo>,</mo> <mn>42</mn> <mo>,</mo>
    <mo>…</mo> <mo>,</mo> <mn>68</mn> <mo>,</mo> <mn>69</mn></math> degrees. For each
    of these, we need to create the additional feature to enable the line to bend
    there:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型似乎比多项式更好地拟合了数据。但是可能有许多种弯线模型。线条可能在 55 度或 60 度处弯曲等。我们可以使用 <math><mi>k</mi></math>
    折交叉验证来选择线条弯曲的温度值。让我们考虑在 <math><mn>40</mn> <mo>,</mo> <mn>41</mn> <mo>,</mo> <mn>42</mn>
    <mo>,</mo> <mo>…</mo> <mo>,</mo> <mn>68</mn> <mo>,</mo> <mn>69</mn></math> 度处弯曲的模型。对于这些模型的每一个，我们需要创建额外的特征来使线条在那里弯曲：
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '|   | temp | ccf | temp40p | temp41p | ... | temp66p | temp67p | temp68p |
    temp69p |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|   | temp | ccf | temp40p | temp41p | ... | temp66p | temp67p | temp68p |
    temp69p |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| **0** | 29 | 166 | 0 | 0 | ... | 0 | 0 | 0 | 0 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 29 | 166 | 0 | 0 | ... | 0 | 0 | 0 | 0 |'
- en: '| **1** | 31 | 179 | 0 | 0 | ... | 0 | 0 | 0 | 0 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 31 | 179 | 0 | 0 | ... | 0 | 0 | 0 | 0 |'
- en: '| **2** | 15 | 224 | 0 | 0 | ... | 0 | 0 | 0 | 0 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 15 | 224 | 0 | 0 | ... | 0 | 0 | 0 | 0 |'
- en: '| **...** | ... | ... | ... | ... | ... | ... | ... | ... | ... |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| **...** | ... | ... | ... | ... | ... | ... | ... | ... | ... |'
- en: '| **96** | 76 | 11 | 36 | 35 | ... | 10 | 9 | 8 | 7 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| **96** | 76 | 11 | 36 | 35 | ... | 10 | 9 | 8 | 7 |'
- en: '| **97** | 55 | 32 | 15 | 14 | ... | 0 | 0 | 0 | 0 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| **97** | 55 | 32 | 15 | 14 | ... | 0 | 0 | 0 | 0 |'
- en: '| **98** | 39 | 91 | 0 | 0 | ... | 0 | 0 | 0 | 0 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| **98** | 39 | 91 | 0 | 0 | ... | 0 | 0 | 0 | 0 |'
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The first step in cross-validation is to create our train and test sets. Like
    before, we choose 22 observations at random to be placed in the test set. That
    leaves 75 for the train set:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证的第一步是创建我们的训练集和测试集。与之前一样，我们随机选择 22 个观测值放入测试集。这样剩下 75 个观测值作为训练集：
- en: '[PRE18]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now we can divide the train set into folds. We use three folds so that we have
    25 observations in each fold. For each fold, we fit 30 models, one for each bend
    in the line. For this step, we divide the data with the `KFold` method in `scikit-learn`:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将训练集分成折叠。我们使用三个折叠，以便每个折叠中有 25 个观测值。对于每个折叠，我们拟合 30 个模型，每个模型对应线条中的一个弯曲点。对于这一步骤，我们使用
    `scikit-learn` 中的 `KFold` 方法来划分数据：
- en: '[PRE19]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Then we find the mean validation error across the three folds and plot them
    against the location of the bend:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们找到三个折叠中的平均验证误差，并将它们绘制在弯曲位置的图表上：
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](assets/leds_16in08.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in08.png)'
- en: 'The MSE looks quite flat for 57 to 60 degrees. The minimum occurs at 58, so
    we choose that model. To assess this model on the test set, we first fit the bent
    line model at 58 degrees on the entire train set:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: MSE 在 57 到 60 度之间看起来相当平缓。最小值出现在 58 度，因此我们选择那个模型。为了评估这个模型在测试集上的表现，我们首先在整个训练集上以
    58 度拟合弯线模型：
- en: '[PRE21]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then we use the fitted model to predict gas consumption for the test set:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用拟合的模型来预测测试集的气体消耗：
- en: '[PRE22]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let’s overlay the bent-line fit on the scatterplot and examine the residuals
    to get an idea as to the quality of the fit:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将弯线拟合叠加到散点图上，并检查残差，以了解拟合质量：
- en: '![](assets/leds_16in09.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in09.png)'
- en: The fitted curve looks reasonable, and the residuals are much smaller than those
    from the polynomial fit.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合曲线看起来合理，并且残差比多项式拟合的要小得多。
- en: Note
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For teaching purposes in this section, we use `KFold` to manually split up the
    training data into three folds, then find the model validation errors using a
    loop. In practice, we suggest using `sklearn.model_selection.GridSearchCV` with
    an `sklearn.pipeline.Pipeline` object, which can automatically break the data
    into training and validation sets and find the model that has the lowest average
    validation error across the folds.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的教学目的上，我们使用 `KFold` 手动将训练数据分为三个折叠，然后使用循环找到模型验证误差。在实践中，我们建议使用 `sklearn.model_selection.GridSearchCV`
    与 `sklearn.pipeline.Pipeline` 对象，它可以自动将数据分成训练集和验证集，并找到在折叠中平均验证误差最低的模型。
- en: 'Using cross-validation to manage model complexity has a couple of critical
    limitations: typically it requires the complexity to vary discretely, and there
    may not be a natural way to order the models. Rather than changing the dimensions
    of a sequence of models, we can fit a large model and apply constraints on the
    size of the coefficients. This notion is called regularization and is the topic
    of the next section.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用交叉验证来管理模型复杂度有几个关键的限制：通常需要使复杂度离散变化，并且可能没有自然的方式来对模型进行排序。与其改变一系列模型的维度，我们可以拟合一个大模型并对系数的大小施加约束。这个概念被称为正则化，将在下一节讨论。
- en: Regularization
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则化
- en: 'We just saw how cross-validation can help find a dimension for a fitted model
    that balances under- and overfitting. Rather than selecting the dimension of the
    model, we can build a model with all of the features, but restrict the size of
    the coefficients. We keep from overfitting by adding to the MSE a penalty term
    on the size of the coefficients. The penalty, called a *regularization term*,
    is <math><mi>λ</mi> <munderover><mo>∑</mo> <mrow><mi>j</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mrow><mi>p</mi></mrow></munderover> <msubsup><mi>θ</mi> <mi>j</mi> <mn>2</mn></msubsup></math>
    . We fit the model by minimizing the combination of mean squared error plus this
    penalty:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到交叉验证如何帮助找到适合的模型维度，从而平衡欠拟合和过拟合。与其选择模型的维度，我们可以构建一个包含所有特征的模型，但限制系数的大小。通过在均方误差上添加一个系数大小的惩罚项来防止过拟合。这个惩罚项称为*正则化项*，表达式为<math><mi>λ</mi>
    <munderover><mo>∑</mo> <mrow><mi>j</mi> <mo>=</mo> <mn>1</mn></mrow> <mrow><mi>p</mi></mrow></munderover>
    <msubsup><mi>θ</mi> <mi>j</mi> <mn>2</mn></msubsup></math> 。我们通过最小化均方误差和这个惩罚项的组合来拟合模型：
- en: <math display="block"><mfrac><mn>1</mn> <mi>n</mi></mfrac> <munderover><mo>∑</mo>
    <mrow><mi>i</mi> <mo>=</mo> <mn>1</mn></mrow> <mrow><mi>n</mi></mrow></munderover>
    <mo stretchy="false">(</mo> <msub><mi>y</mi> <mi>i</mi></msub> <mo>−</mo> <msub><mrow><mi
    mathvariant="bold">x</mi></mrow> <mi>i</mi></msub> <mi mathvariant="bold-italic">θ</mi>
    <msup><mo stretchy="false">)</mo> <mn>2</mn></msup>  <mo>+</mo>  <mi>λ</mi> <munderover><mo>∑</mo>
    <mrow><mi>j</mi> <mo>=</mo> <mn>1</mn></mrow> <mrow><mi>p</mi></mrow></munderover>
    <msubsup><mi>θ</mi> <mi>j</mi> <mn>2</mn></msubsup></math>
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mfrac><mn>1</mn> <mi>n</mi></mfrac> <munderover><mo>∑</mo>
    <mrow><mi>i</mi> <mo>=</mo> <mn>1</mn></mrow> <mrow><mi>n</mi></mrow></munderover>
    <mo stretchy="false">(</mo> <msub><mi>y</mi> <mi>i</mi></msub> <mo>−</mo> <msub><mrow><mi
    mathvariant="bold">x</mi></mrow> <mi>i</mi></msub> <mi mathvariant="bold-italic">θ</mi>
    <msup><mo stretchy="false">)</mo> <mn>2</mn></msup>  <mo>+</mo>  <mi>λ</mi> <munderover><mo>∑</mo>
    <mrow><mi>j</mi> <mo>=</mo> <mn>1</mn></mrow> <mrow><mi>p</mi></mrow></munderover>
    <msubsup><mi>θ</mi> <mi>j</mi> <mn>2</mn></msubsup></math>
- en: When the *regularization parameter*, <math><mi>λ</mi></math> , is large, it
    penalizes large coefficients. (We typically choose it by cross-validation.)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当*正则化参数*<math><mi>λ</mi></math>很大时，会惩罚大的系数。（通常通过交叉验证来选择。）
- en: 'Penalizing the square of the coefficients is called <math><msub><mi>L</mi>
    <mn>2</mn></msub></math> regularization, or *ridge regression*. Another popular
    regularization penalizes the absolute size of the coefficients:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对系数的平方进行惩罚称为<math><msub><mi>L</mi> <mn>2</mn></msub></math>正则化，或称为*岭回归*。另一种流行的正则化方法惩罚系数的绝对大小：
- en: <math display="block"><mtable columnalign="right" displaystyle="true" rowspacing="3pt"><mtr><mtd><mfrac><mn>1</mn>
    <mi>n</mi></mfrac> <munderover><mo>∑</mo> <mrow><mi>i</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mrow><mi>n</mi></mrow></munderover> <mo stretchy="false">(</mo> <msub><mi>y</mi>
    <mi>i</mi></msub> <mo>−</mo> <msub><mrow><mi mathvariant="bold">x</mi></mrow>
    <mi>i</mi></msub> <mi mathvariant="bold-italic">θ</mi> <msup><mo stretchy="false">)</mo>
    <mn>2</mn></msup>  <mo>+</mo>  <mi>λ</mi> <munderover><mo>∑</mo> <mrow><mi>j</mi>
    <mo>=</mo> <mn>1</mn></mrow> <mrow><mi>p</mi></mrow></munderover> <mrow><mo stretchy="false">|</mo></mrow>
    <msub><mi>θ</mi> <mi>j</mi></msub> <mo stretchy="false">|</mo></mtd></mtr></mtable></math>
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" displaystyle="true" rowspacing="3pt"><mtr><mtd><mfrac><mn>1</mn>
    <mi>n</mi></mfrac> <munderover><mo>∑</mo> <mrow><mi>i</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mrow><mi>n</mi></mrow></munderover> <mo stretchy="false">(</mo> <msub><mi>y</mi>
    <mi>i</mi></msub> <mo>−</mo> <msub><mrow><mi mathvariant="bold">x</mi></mrow>
    <mi>i</mi></msub> <mi mathvariant="bold-italic">θ</mi> <msup><mo stretchy="false">)</mo>
    <mn>2</mn></msup>  <mo>+</mo>  <mi>λ</mi> <munderover><mo>∑</mo> <mrow><mi>j</mi>
    <mo>=</mo> <mn>1</mn></mrow> <mrow><mi>p</mi></mrow></munderover> <mrow><mo stretchy="false">|</mo></mrow>
    <msub><mi>θ</mi> <mi>j</mi></msub> <mo stretchy="false">|</mo></mtd></mtr></mtable></math>
- en: This <math><msub><mi>L</mi> <mn>1</mn></msub></math> regularized linear model
    is also called *lasso regression* (lasso stands for Least Absolute Shrinkage and
    Selection Operator).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这个<math><msub><mi>L</mi> <mn>1</mn></msub></math>正则化的线性模型也被称为*套索回归*（lasso代表最小绝对值收缩和选择运算符）。
- en: 'To get an idea about how regularization works, let’s think about the extreme
    cases: when <math><mi>λ</mi></math> is really large and when it’s close to 0 (
    <math><mi>λ</mi></math> is never negative). With a big regularization parameter,
    the coefficients are heavily penalized, so they shrink. On the other hand, when
    <math><mi>λ</mi></math> is tiny, the coefficients aren’t restricted. In fact,
    when <math><mi>λ</mi></math> is 0, we’re back in the world of ordinary least squares.
    A couple of issues crop up when we think about controlling the size of the coefficients
    through regularization:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解正则化的工作原理，让我们考虑极端情况：当<math><mi>λ</mi></math>非常大或接近0时（<math><mi>λ</mi></math>从不为负）。当正则化参数很大时，系数会受到严重的惩罚，因此它们会收缩。另一方面，当<math><mi>λ</mi></math>很小时，系数不受限制。实际上，当<math><mi>λ</mi></math>为0时，我们回到了普通最小二乘法的世界。当我们考虑通过正则化控制系数大小时，会遇到几个问题：
- en: We do not want to regularize the intercept term. This way, a large penalty fits
    a constant model.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不希望对截距项进行正则化。这样一来，一个大的惩罚就会拟合一个常数模型。
- en: When features have very different scales, the penalty can impact them differently,
    with large-valued features being penalized more than others. To avoid this, we
    standardize all of the features to have mean 0 and variance 1 before fitting the
    model.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当特征具有非常不同的尺度时，惩罚可能会对它们产生不同的影响，具有较大值的特征会比其他特征受到更多的惩罚。为了避免这种情况，我们在拟合模型之前将所有特征标准化，使它们的均值为0，方差为1。
- en: Let’s look at an example with 35 features.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个包含35个特征的例子。
- en: Model Bias and Variance
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型的偏差和方差
- en: In this section, we provide a different way to think about the problem of over-
    and underfitting. We carry out a simulation study where we generate synthetic
    data from a model of our design. This way, we know the true model, and we can
    see how close we get to the truth when we fit models to the data.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们提供了一种不同的思考过拟合和欠拟合问题的方式。我们进行了模拟研究，从我们设计的模型中生成了合成数据。这样，我们知道真实模型，并可以看到在拟合数据时我们离真实情况有多近。
- en: 'We concoct a general model of data as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以构建一个数据的通用模型如下：
- en: <math display="block"><mi>y</mi> <mo>=</mo> <mi>g</mi> <mo stretchy="false">(</mo>
    <mrow><mi mathvariant="bold">x</mi></mrow> <mo stretchy="false">)</mo> <mo>+</mo>
    <mrow><mi>ϵ</mi></mrow></math>
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mi>y</mi> <mo>=</mo> <mi>g</mi> <mo stretchy="false">(</mo>
    <mrow><mi mathvariant="bold">x</mi></mrow> <mo stretchy="false">)</mo> <mo>+</mo>
    <mrow><mi>ϵ</mi></mrow></math>
- en: 'This expression makes it easy to see the two components of the model: the signal
    <math><mi>g</mi> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo></math>
    and the noise <math><mi>ϵ</mi></math> . In our model, we assume the noise has
    no trend or pattern, constant variance, and each observation’s noise is independent
    of the others’.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表达式使得模型的两个组成部分很容易看出来：信号 <math><mi>g</mi> <mo stretchy="false">(</mo> <mi>x</mi>
    <mo stretchy="false">)</mo></math> 和噪声 <math><mi>ϵ</mi></math> 。在我们的模型中，我们假设噪声没有趋势或模式，方差恒定，并且每个观测值的噪声是独立的。
- en: 'As an example, let’s take <math><mi>g</mi> <mo stretchy="false">(</mo> <mi>x</mi>
    <mo stretchy="false">)</mo> <mo>=</mo> <mi>sin</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mi>x</mi> <mo stretchy="false">)</mo> <mo>+</mo> <mn>0.3</mn> <mi>x</mi></math>
    and the noise from a normal curve with center 0 and SD = 0.2\. We can generate
    data from this model with the following functions:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们取 <math><mi>g</mi> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo>
    <mo>=</mo> <mi>sin</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>x</mi> <mo
    stretchy="false">)</mo> <mo>+</mo> <mn>0.3</mn> <mi>x</mi></math> ，噪声来自均值为 0，标准差为
    0.2 的正态曲线。我们可以从这个模型生成数据，使用以下函数：
- en: '[PRE24]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s generate 50 data points <math><mo stretchy="false">(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>,</mo> <msub><mi>y</mi> <mi>i</mi></msub> <mo stretchy="false">)</mo></math>
    , <math><mi>i</mi> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo>…</mo> <mo>,</mo> <mn>50</mn></math>
    , from this model:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们生成 50 个数据点 <math><mo stretchy="false">(</mo> <msub><mi>x</mi> <mi>i</mi></msub>
    <mo>,</mo> <msub><mi>y</mi> <mi>i</mi></msub> <mo stretchy="false">)</mo></math>
    ，<math><mi>i</mi> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo>…</mo> <mo>,</mo> <mn>50</mn></math>
    ，从这个模型中：
- en: '[PRE25]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can plot our data, and since we know the true signal, we can find the errors
    and plot them too:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以绘制我们的数据，因为我们知道真实信号，我们可以找到错误并将它们绘制出来：
- en: '![](assets/leds_16in10.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in10.png)'
- en: The plot on the left shows <math><mi>g</mi></math> as a dashed curve. We can
    also see that the <math><mo stretchy="false">(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi>
    <mo stretchy="false">)</mo></math> pairs form a scatter of dots about this curve.
    The righthand plot shows the errors, <math><mi>y</mi> <mo>−</mo> <mi>g</mi> <mo
    stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo></math> , for the
    50 points. Notice that they do not form a pattern.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 左边的图显示 <math><mi>g</mi></math> 作为虚线曲线。我们还可以看到 <math><mo stretchy="false">(</mo>
    <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo></math> 对形成了这条曲线的散点分布。右边的图显示了
    50 个点的误差，<math><mi>y</mi> <mo>−</mo> <mi>g</mi> <mo stretchy="false">(</mo> <mi>x</mi>
    <mo stretchy="false">)</mo></math> 。请注意，它们没有形成模式。
- en: 'When we fit a model to the data, we minimize the mean squared error. Let’s
    write this minimization in generality:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对数据进行模型拟合时，我们最小化均方误差。让我们用一般性写出这个最小化：
- en: <math display="block"><munder><mo movablelimits="true">min</mo> <mrow><mi>f</mi>
    <mo>∈</mo> <mrow><mi mathvariant="script">F</mi></mrow></mrow></munder> <mfrac><mn>1</mn>
    <mi>n</mi></mfrac> <munderover><mo>∑</mo> <mrow><mi>i</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mrow><mi>n</mi></mrow></munderover> <mo stretchy="false">[</mo> <msub><mi>y</mi>
    <mi>i</mi></msub> <mo>−</mo> <mi>f</mi> <mo stretchy="false">(</mo> <msub><mrow><mi
    mathvariant="bold">x</mi></mrow> <mi>i</mi></msub> <mo stretchy="false">)</mo>
    <msup><mo stretchy="false">]</mo> <mn>2</mn></msup></math>
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><munder><mo movablelimits="true">min</mo> <mrow><mi>f</mi>
    <mo>∈</mo> <mrow><mi mathvariant="script">F</mi></mrow></mrow></munder> <mfrac><mn>1</mn>
    <mi>n</mi></mfrac> <munderover><mo>∑</mo> <mrow><mi>i</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mrow><mi>n</mi></mrow></munderover> <mo stretchy="false">[</mo> <msub><mi>y</mi>
    <mi>i</mi></msub> <mo>−</mo> <mi>f</mi> <mo stretchy="false">(</mo> <msub><mrow><mi
    mathvariant="bold">x</mi></mrow> <mi>i</mi></msub> <mo stretchy="false">)</mo>
    <msup><mo stretchy="false">]</mo> <mn>2</mn></msup></math>
- en: The minimization is over the collection of functions <math><mrow><mi mathvariant="script">F</mi></mrow></math>
    . We have seen in this chapter that this collection of functions might be polynomials
    of 12 degrees, or simply bent lines. An important point is that the true model,
    <math><mi>g</mi></math> , doesn’t have to be one of the functions in the collection.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化是对函数集合 <math><mrow><mi mathvariant="script">F</mi></mrow></math> 进行的。我们在本章中已经看到，这个函数集合可能是
    12 阶多项式，或者简单的弯曲线。一个重要的点是真实模型 <math><mi>g</mi></math> 不必是集合中的一个函数。
- en: Let’s take <math><mrow><mi mathvariant="script">F</mi></mrow></math> to be the
    collection of second-degree polynomials; in other words, functions that can be
    expressed as <math><msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi>
    <mn>1</mn></msub> <mi>x</mi> <mo>+</mo> <msub><mi>θ</mi> <mn>2</mn></msub> <msup><mi>x</mi>
    <mn>2</mn></msup></math> . Since <math><mi>g</mi> <mo stretchy="false">(</mo>
    <mi>x</mi> <mo stretchy="false">)</mo> <mo>=</mo> <mi>sin</mi> <mo>⁡</mo> <mo
    stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo> <mo>+</mo> <mn>0.3</mn>
    <mi>x</mi></math> , it doesn’t belong to the collection of functions that we are
    optimizing over.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把 <math><mrow><mi mathvariant="script">F</mi></mrow></math> 定为二次多项式的集合；换句话说，可以表示为
    <math><msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi> <mo>+</mo> <msub><mi>θ</mi> <mn>2</mn></msub> <msup><mi>x</mi> <mn>2</mn></msup></math>
    的函数。由于 <math><mi>g</mi> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo>
    <mo>=</mo> <mi>sin</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>x</mi> <mo
    stretchy="false">)</mo> <mo>+</mo> <mn>0.3</mn> <mi>x</mi></math> ，它不属于我们正在优化的函数集合。
- en: 'Let’s fit a polynomial to our 50 data points:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对我们的 50 个数据点进行多项式拟合：
- en: '[PRE26]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Again, we know the true model is not quadratic (because we built it). Let’s
    plot the data and the fitted curve:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们知道真实模型不是二次的（因为我们建立了它）。让我们绘制数据和拟合曲线：
- en: '![](assets/leds_16in11.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_16in11.png)'
- en: The quadratic doesn’t fit the data well, and it doesn’t represent the underlying
    curve well either because the set of models that we are choosing from (second-order
    polynomials) can’t capture the curvature in <math><mi>g</mi></math> .
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'If we repeat this process and generate another 50 points from the true model
    and fit a second-degree polynomial to these data, then the fitted coefficients
    of the quadratic will change because it depends on the new set of data. We can
    repeat this process many times, and average the fitted curves. This average curve
    will resemble the typical best fit of a second-degree polynomial to 50 points
    from our true model. To demonstrate this notion, let’s generate 25 sets of 50
    data points and fit a quadratic to each dataset:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can show on a plot all 25 fitted models along with the true function, <math><mi>g</mi></math>
    , and the average of the fitted curves, <math><mrow><mover><mi>f</mi> <mo stretchy="false">¯</mo></mover></mrow></math>
    . To do this, we use transparency for the 25 fitted models to distinguish overlapping
    curves:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_16in12.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
- en: We can see that the 25 fitted quadratics vary with the data. This concept is
    called *model variation*. The average of the 25 quadratics is represented by the
    solid black line. The difference between the average quadratic and the true curve
    is called the *model bias*.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: When the signal, <math><mi>g</mi></math> , does not belong to the model space,
    <math><mrow><mi mathvariant="script">F</mi></mrow></math> , we have model bias.
    If the model space can approximate <math><mi>g</mi></math> well, then the bias
    is small. For instance, a 10-degree polynomial can get pretty close to the <math><mi>g</mi></math>
    used in our example. On the other hand, we have seen earlier in this chapter that
    higher-degree polynomials can overfit the data and vary a lot trying to get close
    to the data. The more complex the model space, the greater the variability in
    the fitted model. Underfitting with too simple a model can lead to high model
    bias (the difference between <math><mi>g</mi></math> and <math><mrow><mover><mi>f</mi>
    <mo stretchy="false">¯</mo></mover></mrow></math> ), and overfitting with too
    complex a model can result in high model variance (the fluctuations of <math><mrow><mover><mi>f</mi>
    <mo stretchy="false">^</mo></mover></mrow></math> around <math><mrow><mover><mi>f</mi>
    <mo stretchy="false">¯</mo></mover></mrow></math> ). This notion is called the
    *bias-variance trade-off*. Model selection aims to balance these competing sources
    of a lack of fit.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw that problems arise when we minimize mean squared error
    to both fit a model and evaluate it. The train-test split helps us get around
    this problem, where we fit a model with the train set and evaluate our fitted
    model on test data that have been set aside.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to not “overuse” the test set, so we keep it separate until we
    have committed to a model. To help us commit, we might use cross-validation, which
    imitates the division of data into test and train sets. Again, it’s important
    to cross-validate using only the train set and keep the original test set away
    from any model selection process.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: “过度使用”测试集非常重要，因此我们保持其与模型分离直到我们决定了一个模型。为了帮助我们做出决定，我们可能使用交叉验证，模拟将数据分为测试和训练集。同样重要的是，只使用训练集进行交叉验证，并将原始测试集远离任何模型选择过程。
- en: Regularization takes a different approach and penalizes the mean squared error
    to keep the model from fitting the data too closely. In regularization, we use
    all of the data available to fit the model, but shrink the size of the coefficients.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化采取了不同的方法，通过惩罚均方误差来防止模型过度拟合数据。在正则化中，我们利用所有可用数据来拟合模型，但是缩小系数的大小。
- en: 'The bias-variance trade-off allows us to more precisely describe the modeling
    phenomena that we have seen in this chapter: underfitting relates to model bias;
    overfitting results in model variance. In [Figure 16-4](#model-bias-variance-diagram),
    the x-axis measures model complexity and the y-axis measures these two components
    of model misfit: model bias and model variance. Notice that as the complexity
    of the model being fit increases, model bias decreases and model variance increases.
    Thinking in terms of test error, we have seen this error first decrease and then
    increase as the model variance outweighs the decrease in model bias. To select
    a useful model, we must strike a balance between model bias and variance.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差-方差折衷使我们能够更准确地描述本章中看到的建模现象：拟合不足与模型偏差有关；过度拟合导致模型方差增大。在[图16-4](#model-bias-variance-diagram)中，x轴表示模型复杂度，y轴表示模型不适配的这两个组成部分：模型偏差和模型方差。请注意，随着拟合模型的复杂性增加，模型偏差减少，模型方差增加。从测试误差的角度来看，我们看到这种误差首先减少，然后由于模型方差超过模型偏差的减少而增加。为了选择一个有用的模型，我们必须在模型偏差和模型方差之间取得平衡。
- en: '![](assets/leds_1604.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_1604.png)'
- en: Figure 16-4\. Bias-variance trade-off
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图16-4\. 偏差-方差折衷
- en: Collecting more observations reduces bias if the model can fit the population
    process exactly. If the model is inherently incapable of modeling the population
    (as in our synthetic example), even infinite data cannot get rid of model bias.
    In terms of variance, collecting more data also reduces variance. One recent trend
    in data science is to select a model with low bias and high intrinsic variance
    (such as a neural network) but to collect many data points so that the model variance
    is low enough to make accurate predictions. While effective in practice, collecting
    enough data for these models tends to require large amounts of time and money.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型能够完全拟合人口过程，收集更多观察数据会减少偏差。如果模型本质上无法建模人口（如我们的合成示例），即使是无限数据也无法消除模型偏差。就方差而言，收集更多数据也会减少方差。数据科学的一个最新趋势是选择具有低偏差和高内在方差（例如神经网络）的模型，但收集许多数据点以使模型方差足够低以进行准确预测。虽然在实践中有效，但为这些模型收集足够的数据通常需要大量的时间和金钱。
- en: Creating more features, whether useful or not, typically increases model variance.
    Models with many parameters have many possible combinations of parameters and
    therefore have higher variance than models with few parameters. On the other hand,
    adding a useful feature to the model, such as a quadratic feature when the underlying
    process is quadratic, reduces bias. But even adding a useless feature rarely increases
    bias.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 创建更多的特征，无论其是否有用，通常会增加模型的方差。具有许多参数的模型具有许多可能的参数组合，因此比具有少量参数的模型具有更高的方差。另一方面，在模型中添加一个有用的特征（例如，当基础过程是二次的时添加二次特征），可以减少偏差。但即使添加一个无用的特征，很少会增加偏差。
- en: Being aware of the bias-variance trade-off can help you do a better job of fitting
    models. And using techniques like the train-test split, cross-validation, and
    regularization can ameliorate this issue.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉偏差-方差折衷可以帮助您更好地拟合模型。并且使用诸如训练-测试分割、交叉验证和正则化等技术可以改善这个问题。
- en: Another part of modeling considers the variation in the fitted coefficients
    and curve. We might want to provide a confidence interval for a coefficient or
    a prediction band for a future observation. These intervals and bands give a sense
    of the accuracy of the fitted model. We discuss this notion next.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 建模的另一个部分考虑了拟合系数和曲线的变化。我们可能希望为系数提供置信区间或未来观测的预测带。这些区间和带子给出了拟合模型准确性的感觉。接下来我们将讨论这个概念。
- en: ^([1](ch16.html#id1643-marker)) These data are from Daniel T. Kaplan (CreateSpace
    Independent Publishing Platform, 2009).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch16.html#id1643-marker)) 这些数据来自于丹尼尔·T·卡普兰（Daniel T. Kaplan）（CreateSpace
    Independent Publishing Platform, 2009）。
