["```py\n169.237.46.168 - -\n[26/Jan/2004:10:47:58 -0800]\"GET /stat141/Winter04 HTTP/1.1\" 301 328\n\"http://anson.ucdavis.edu/courses\"\n\"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0; .NET CLR 1.1.4322)\"\n\n```", "```py\n\tunclean or degraded floors walls or ceilings\n\tinadequate and inaccessible handwashing facilities\n\tinadequately cleaned or sanitized food contact surfaces\n\twiping cloths not clean or properly stored or inadequate sanitizer\n\tfoods not protected from contamination\n\tunclean nonfood contact surfaces\n\tunclean or unsanitary food contact surfaces\n\tunclean hands or improper use of gloves\n\tinadequate washing facilities or equipment\n\n```", "```py\n*** \n\nState of the Union Address\nGeorge Washington\nJanuary 8, 1790\n\nFellow-Citizens of the Senate and House of Representatives:\nI embrace with great satisfaction the opportunity which now presents itself\nof congratulating you on the present favorable prospects of our public …\n\n```", "```py\n`def` `clean_county``(``county``)``:`\n    `return` `(``county`\n            `.``lower``(``)`\n            `.``replace``(``'``county``'``,` `'``'``)`\n            `.``replace``(``'``parish``'``,` `'``'``)`\n            `.``replace``(``'``&``'``,` `'``and``'``)`\n            `.``replace``(``'``.``'``,` `'``'``)`\n            `.``replace``(``'` `'``,` `'``'``)``)`\n\n```", "```py\n`(``[``clean_county``(``county``)` `for` `county` `in` `election``[``'``County``'``]``]``,`\n `[``clean_county``(``county``)` `for` `county` `in` `census``[``'``County``'``]``]``)`\n\n```", "```py\n(['dewitt', 'lacquiparle', 'lewisandclark', 'stjohnthebaptist'],\n ['dewitt', 'lacquiparle', 'lewisandclark', 'stjohnthebaptist'])\n\n```", "```py\n`election``[``'``County``'``]` `=` `(``election``[``'``County``'``]`\n `.``str``.``lower``(``)`\n `.``str``.``replace``(``'``parish``'``,` `'``'``)`\n `.``str``.``replace``(``'``county``'``,` `'``'``)`\n `.``str``.``replace``(``'``&``'``,` `'``and``'``)`\n `.``str``.``replace``(``'``.``'``,` `'``'``,` `regex``=``False``)`\n `.``str``.``replace``(``'` `'``,` `'``'``)``)`\n\n```", "```py\n`election``.``merge``(``census``,` `on``=``[``'``County``'``,``'``State``'``]``)`\n\n```", "```py\n`log_entry`\n\n```", "```py\n169.237.46.168 - - [26/Jan/2004:10:47:58 -0800]\"GET /stat141/Winter04 HTTP/1.1\"\n301 328 \"http://anson.ucdavis.edu/courses\"\"Mozilla/4.0 (compatible; MSIE 6.0;\nWindows NT 5.0; .NET CLR 1.1.4322)\"\n\n```", "```py\n`log_entry``.``split``(``'``[``'``)`\n\n```", "```py\n['169.237.46.168 - - ',\n '26/Jan/2004:10:47:58 -0800]\"GET /stat141/Winter04 HTTP/1.1\" 301 328 \"http://anson.ucdavis.edu/courses\"\"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0; .NET CLR 1.1.4322)\"']\n\n```", "```py\n`log_entry``.``split``(``'``[``'``)``[``1``]``.``split``(``'``:``'``)``[``0``]`\n\n```", "```py\n'26/Jan/2004'\n\n```", "```py\n`(``log_entry``.``split``(``'``[``'``)``[``1``]`\n `.``split``(``'``:``'``)``[``0``]`\n `.``split``(``'``/``'``)``)`\n\n```", "```py\n['26', 'Jan', '2004']\n\n```", "```py\n`import` `re`\n\n`pattern` `=` `r``'``[` `\\``[/:``\\``]]``'` \n`re``.``split``(``pattern``,` `log_entry``)``[``4``:``11``]`\n\n```", "```py\n['26', 'Jan', '2004', '10', '47', '58', '-0800']\n\n```", "```py\n[0123456789][0123456789][0123456789]\n\n```", "```py\n[0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9][0-9][0-9]\n\n```", "```py\nc[oa][td]\n\n```", "```py\n  Regex: c[oa][td]\n   Text: The cat eats cod, cads, and cots, but not coats.\nMatches:     ***      ***  ***       ***                 \n\n```", "```py\n\\d\\d\\d-\\d\\d-\\d\\d\\d\\d\n\n```", "```py\n  Regex: \\d\\d\\d-\\d\\d-\\d\\d\\d\\d\n   Text: My other number is 6382-13-38420.\nMatches:                     ***********  \n\n```", "```py\n  Regex: \\d\\d\\d-\\d\\d-\\d\\d\\d\\\n   Text: My other number is 6382-13-38420.\nMatches:                                  \n\n```", "```py\n  Regex: \\b\\d\\d\\d-\\d\\d-\\d\\d\\d\\d\\b\n   Text: My reeeal number is 382-13-3842.\nMatches:                     *********** \n\n```", "```py\n  Regex: \\[\n   Text: Today is [2022/01/01]\nMatches:          *           \n\n```", "```py\n\\b[0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9][0-9][0-9]\\b\n\n```", "```py\n`import` `re`\n\n`ssn_re` `=` `r``'``\\``b[0-9]``{3}``-[0-9]``{2}``-[0-9]``{4}``\\``b``'`\n`re``.``findall``(``ssn_re``,` `'``My SSN is 382-34-3840.``'``)`\n\n```", "```py\n['382-34-3840']\n\n```", "```py\n`re``.``findall``(``ssn_re``,` `'``My phone is 382-123-3842.``'``)`\n\n```", "```py\n[]\n\n```", "```py\n`ssn_re_dot` `=` `r``'``[0-9].+[0-9]``'`\n`re``.``findall``(``ssn_re_dot``,` `'``My SSN is 382-34-3842 and hers is 382-34-3333.``'``)`\n\n```", "```py\n['382-34-3842 and hers is 382-34-3333']\n\n```", "```py\n`re``.``findall``(``ssn_re``,` `'``My SSN is 382-34-3842 and hers is 382-34-3333.``'``)`\n\n```", "```py\n['382-34-3842', '382-34-3333']\n\n```", "```py\n`body_re` `=` `r``\"``hand|nail|hair|glove``\"`\n`re``.``findall``(``body_re``,` `\"``unclean hands or improper use of gloves``\"``)`\n\n```", "```py\n['hand', 'glove']\n\n```", "```py\n`re``.``findall``(``body_re``,` `\"``Unsanitary employee garments hair or nails``\"``)`\n\n```", "```py\n['hair', 'nail']\n\n```", "```py\n`# This pattern matches the entire timestamp`\n`time_re` `=` `r``\"``\\``[[0-9]``{2}``/[a-zA-z]``{3}``/[0-9]``{4}``:[0-9:``\\``- ]*``\\``]``\"`\n`re``.``findall``(``time_re``,` `log_entry``)`\n\n```", "```py\n['[26/Jan/2004:10:47:58 -0800]']\n\n```", "```py\n`# Same regex, but we use parens to make regex groups...`\n`time_re` `=` `r``\"``\\``[([0-9]``{2}``)/([a-zA-z]``{3}``)/([0-9]``{4}``):([0-9:``\\``- ]*)``\\``]``\"`\n\n`# ...which tells findall() to split up the match into its groups`\n`re``.``findall``(``time_re``,` `log_entry``)`\n\n```", "```py\n[('26', 'Jan', '2004', '10:47:58 -0800')]\n\n```", "```py\n`from` `pathlib` `import` `Path`\n\n`text` `=` `Path``(``'``data/stateoftheunion1790-2022.txt``'``)``.``read_text``(``)`\n\n```", "```py\n`import` `re`\n`num_speeches` `=` `len``(``re``.``findall``(``r``\"``\\``*``\\``*``\\``*``\"``,` `text``)``)`\n`print``(``f``'``There are` `{``num_speeches``}` `speeches total``'``)`\n\n```", "```py\nThere are 232 speeches total\n\n```", "```py\n`records` `=` `text``.``split``(``\"``***``\"``)`\n\n```", "```py\n`def` `extract_parts``(``speech``)``:`\n    `speech` `=` `speech``.``strip``(``)``.``split``(``'``\\n``'``)``[``1``:``]`\n    `[``name``,` `date``,` `*``lines``]` `=` `speech`\n    `body` `=` `'``\\n``'``.``join``(``lines``)``.``strip``(``)`\n    `return` `[``name``,` `date``,` `body``]`\n\n`def` `read_speeches``(``)``:`\n    `return` `pd``.``DataFrame``(``[``extract_parts``(``l``)` `for` `l` `in` `records``[``1``:``]``]``,`\n                        `columns` `=` `[``\"``name``\"``,` `\"``date``\"``,` `\"``text``\"``]``)`\n\n`df` `=` `read_speeches``(``)`\n`df`\n\n```", "```py\n232 rows × 3 columns\n```", "```py\n    `def` `clean_text``(``df``)``:`\n        `bracket_re` `=` `re``.``compile``(``r``'``\\``[[^``\\``]]+``\\``]``'``)`\n        `not_a_word_re` `=` `re``.``compile``(``r``'``[^a-z``\\``s]``'``)`\n        `cleaned` `=` `(``df``[``'``text``'``]``.``str``.``lower``(``)`\n                   `.``str``.``replace``(``bracket_re``,` `'``'``,` `regex``=``True``)`\n                   `.``str``.``replace``(``not_a_word_re``,` `'` `'``,` `regex``=``True``)``)`\n        `return` `df``.``assign``(``text``=``cleaned``)`\n\n    `df` `=` `(``read_speeches``(``)`\n          `.``pipe``(``clean_text``)``)`\n    `df`\n\n    ```", "```py\n    232 rows × 3 columns\n    ```", "```py\n`import` `nltk`\n`nltk``.``download``(``'``stopwords``'``)`\n`nltk``.``download``(``'``punkt``'``)`\n\n`from` `nltk``.``stem``.``porter` `import` `PorterStemmer`\n`from` `sklearn``.``feature_extraction``.``text` `import` `TfidfVectorizer`\n\n`stop_words` `=` `set``(``nltk``.``corpus``.``stopwords``.``words``(``'``english``'``)``)`\n`porter_stemmer` `=` `PorterStemmer``(``)`\n\n`def` `stemming_tokenizer``(``document``)``:`\n    `return` `[``porter_stemmer``.``stem``(``word``)`\n            `for` `word` `in` `nltk``.``word_tokenize``(``document``)`\n            `if` `word` `not` `in` `stop_words``]`\n\n`tfidf` `=` `TfidfVectorizer``(``tokenizer``=``stemming_tokenizer``)`\n`speech_vectors` `=` `tfidf``.``fit_transform``(``df``[``'``text``'``]``)`\n\n```", "```py\n`speech_vectors``.``shape`\n\n```", "```py\n(232, 13211)\n\n```"]