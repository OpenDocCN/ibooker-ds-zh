- en: Chapter 2\. Data Standardization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed in [Chapter 1](ch01.html#chapter_1), before we can successfully
    match or deduplicate data sources we need to ensure our data is presented in a
    consistent manner and that any anomalies are removed or corrected. We will use
    the term *data standardization* to cover both the transformation of datasets into
    consistent formats and the cleansing of data to remove unhelpful extra characters
    that would otherwise interfere with the matching process.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will get hands on and work through a real-world example
    of this process. We will create our working environment, acquire the data we need,
    cleanse that data, and then perform a simple entity resolution exercise to allow
    us to perform some simple analysis. We will conclude by examining the performance
    of our data matching process and consider how we might improve it.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s introduce our example and why we need entity resolution to solve
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Sample Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s work through an example problem to illustrate some of the common challenges
    we see in resolving entities between data sources and why data cleansing is an
    essential first step. As we are constrained to use openly available public sources
    of data, the example is slightly contrived but hopefully illustrates the need
    for entity resolution.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s imagine we are researching factors that may influence whether members
    of the House of Commons, the lower house of the Parliament of the United Kingdom
    (UK), are reelected. We surmise that politicians with an active social media presence
    might be more successful in securing reelection. For the purposes of this example,
    we are going to consider Facebook presence, and so we look at the last UK general
    election and examine how many politicians who held onto their seat have Facebook
    accounts.
  prefs: []
  type: TYPE_NORMAL
- en: Wikipedia has a web page that lists the members of Parliament (MPs) returned
    at the 2019 general election, including whether they were reelected, but it lacks
    social media information for those individuals. However, the [TheyWorkForYou website](https://theyworkforyou.com)
    does record information on current MPs, including links to their Facebook accounts.
    So if we combine these datasets we can begin to test our hypothesis that reelection
    and social media presence are related.
  prefs: []
  type: TYPE_NORMAL
- en: TheyWorkForYou
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: TheyWorkForYou was founded to make Parliament more accessible and accountable.
    TheyWorkForYou is run by mySociety, a UK charity that puts power in more people’s
    hands through the use of digital tools and data.
  prefs: []
  type: TYPE_NORMAL
- en: How can we join these two datasets? Although both datasets include the name
    of the constituency that each MP represents, we can’t use this as a common key,
    because since the 2019 general election, a number of by-elections have taken place,
    returning new MPs.^([1](ch02.html#id309)) These new members may have Facebook
    accounts but should not be considered in the reelection population as this might
    skew our analysis. Therefore, we need to connect our data by matching the names
    of the MPs between the two sets of records, i.e., resolving these entities so
    that we can create a single combined record for each MP.
  prefs: []
  type: TYPE_NORMAL
- en: Environment Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our first task is to set up our entity resolution environment. In this book,
    we will be using Python and the JupyterLab IDE.
  prefs: []
  type: TYPE_NORMAL
- en: To begin, you’ll need Python installed on your machine. If you don’t already
    have it, you can download it from [their website](http://www.python.org).^([2](ch02.html#id312))
  prefs: []
  type: TYPE_NORMAL
- en: Add Python to PATH
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If installing Python for the first time, make sure to select the “Add Python
    to PATH” option to ensure you can run Python from your command line.
  prefs: []
  type: TYPE_NORMAL
- en: To download the code examples that accompany this book it is convenient to use
    the Git version control system. A guide to installing Git can be found on the
    [GitHub website](https://github.com/git-guides/install-git).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once Git is installed, you can clone (that is, take a copy of) the GitHub repository
    that accompanies this book onto your machine. Run this command from the parent
    directory of your choice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This will create a subdirectory called *HandsOnEntityResolution*.
  prefs: []
  type: TYPE_NORMAL
- en: Python Virtual Environment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'I recommend you use a virtual Python environment to work through the examples
    in this book. This will allow you to maintain the necessary Python package configuration
    without interfering with any other projects you may have. The following command
    creates a new environment in the *HandsOnEntityResolution* directory created by
    Git:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To activate the environment, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will prefix your command prompt to show the environment name based on
    the directory name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you’ve finished, it’s important to deactivate the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, change into this directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'To set up our JupyterLab code environment and the packages required, we will
    use the Python package manager pip, which should be included with your Python
    installation. You can check using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can then install the packages you will need throughout the book from the
    *requirements.txt* file using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, configure a Python kernel associated with our virtual environment for
    our notebooks to pick up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then start JupyterLab with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: While it’s pretty self-explanatory, instructions on how to get started with
    Jupyter are available in [the documentation](https://docs.jupyter.org/en/latest).
  prefs: []
  type: TYPE_NORMAL
- en: Acquiring Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have our environment configured, our next task is to acquire the
    data we need. It’s often the case that the data we need comes in a variety of
    formats and presentations. The examples included in this book will illustrate
    how to deal with some of the most common formats we encounter.
  prefs: []
  type: TYPE_NORMAL
- en: Wikipedia Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Opening *Chapter2.ipynb* in our Jupyter environment, we start by defining the
    Wikipedia URL for the list of MPs returned in the 2019 UK general election:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can import the requests and Beautiful Soup Python packages and use
    them to download a copy of the Wikipedia text. Then run an `html parser` to extract
    all the tables present on the page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Beautiful Soup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Beautiful Soup is a Python package that makes it easy to scrape information
    from web pages. More details are available [online](https://oreil.ly/YB8H3).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to find the table we want within the page. In this case we select
    the table that includes the text “Member returned” (a column name). Within this
    table, we extract the column names as headers and then iterate through all the
    remaining rows and elements, building a list of lists. These lists are then loaded
    into a pandas DataFrame, setting the extracted headers as DataFrame column names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The result is a pandas DataFrame, shown in [Figure 2-1](#fig-2-1), which we
    can examine using the `info` method.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. Wikipedia MP information
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We have 652 entries of 5 columns. This looks encouraging because in each column,
    650 rows have nonnull values, which matches the number of UK House of Commons
    parliamentary constituencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can simplify our dataset by retaining only the columns we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: TheyWorkForYou Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we can move on to downloading our second dataset and loading it into a
    separate DataFrame, as shown in [Figure 2-2](#fig-2-2):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/hoer_0202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-2\. TheyWorkForYou MP information
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Post 2024/25 UK General Election
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you’re reading this book after the 2024/25 UK general election, then the
    TheyWorkForYou website will likely be updated with the new MPs. If you’re following
    along on your own machine, then please use the *mps_they_raw.csv* file supplied
    in the GitHub repository that accompanies this book. The raw Wikipedia data *mps_wiki_raw.csv*
    is also provided.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 2-3](#fig-2-3) lists the first few rows of the DataFrame so that we
    can see information these fields typically contain.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0203.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-3\. First five rows of the TheyWorkForYou dataset
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To discover whether each MP has an associated Facebook account we need to follow
    the link in the URI column to look up their TheyWorkForYou homepage. We’ll need
    to do this for each row, so we define a function that we can apply along the axis
    of the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Adding Facebook links
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The function uses the same Beautiful Soup package we used to parse the Wikipedia
    web page. In this case, we extract all the links to *facebook.com*. We then examine
    the first link. If this link is the account of TheyWorkForYou, then the site doesn’t
    have a Facebook account listed for the MP, so we return a nil string; if it does,
    then we return that link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We can apply this function to every row in the DataFrame using the `apply` method
    to call the `facelink` function, passing the `URI` value as the URL. The value
    returned from the function is added to a new column that Flink appended to the
    DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Be patient—this function has to do quite a bit of work, so it may take a few
    minutes to run on your machine. Once this completes we can view the first few
    rows again, as shown in [Figure 2-4](#fig-2-4), to check if we are getting the
    Facebook links we expect.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0204.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-4\. First five rows of the TheyWorkForYou dataset with Facebook links
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Finally, we can simplify our dataset by retaining only the columns we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Cleansing Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have our raw datasets we can begin our data cleansing process. We
    will perform some initial cleansing on the Wikipedia dataset first and then the
    TheyWorkForYou data. We will then attempt to join these datasets and see what
    further inconsistencies are revealed that we need to standardize.
  prefs: []
  type: TYPE_NORMAL
- en: Wikipedia
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s have a look at the first and last few rows in the Wikipedia dataset, as
    shown in [Figure 2-5](#fig-2-5).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0205.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-5\. First and last 5 rows of the Wikipedia data
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The first task in our cleansing process is to standardize our column names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We can also see that the output of our parser has a blank row at the start and
    end of our DataFrame, and it appears we have `\n` characters appended to each
    element. These additions would clearly interfere with our match, so they need
    to be removed.
  prefs: []
  type: TYPE_NORMAL
- en: 'To remove the blank rows we can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'To remove the trailing `\n` characters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: To be sure we now have a clean `Fullname` we can check for any other `\n` characters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This simple check shows that we also have leading values that we need to remove:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Our next task is to split our `Fullname` into `Firstname` and `Lastname` so
    that we can match these values independently. For the purposes of this example,
    we are going to use a simple method, selecting the first substring as the `Firstname`
    and the remaining substrings, separated by spaces, as the `Lastname`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We can check how well this basic method has worked by looking for `Lastname`
    entries that contain spaces. [Figure 2-6](#fig-2-6) shows the remaining `Lastname`
    entries with spaces present.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0206.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-6\. Check for compound `Lastname` entries in Wikipedia data
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We now have a sufficiently clean dataset to attempt a first match, so we’ll
    move on to our second dataset.
  prefs: []
  type: TYPE_NORMAL
- en: TheyWorkForYou
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we saw earlier, the TheyWorkForYou data is already pretty clean, so at this
    stage all we need to do is standardize the column names with those of the previous
    DataFrame. This will make our life easier as we attempt to match:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Attribute Comparison
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have two similarly formatted DataFrames, we can experiment with
    the next stage of the entity resolution process. Because our datasets are small
    we don’t need to employ record blocking, and so we can proceed directly to try
    a simple exact match of `Firstname`, `Lastname`, and `Constituency`. The `merge`
    method (similar to a database `join`) does this exact matching for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We find that 599 of 650 are perfect matches of all three attributes—not bad!
    Matching on just `Constituency` and `Lastname` gives us 607 perfect matches, so
    we clearly have 8 mismatching `Firstname` entries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Repeating the process for the remaining permutations of `Firstname`, `Lastname`,
    and `Constituency` gives us the Venn diagram of match counts shown in [Figure 2-7](#fig-2-7).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0207.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-7\. Venn diagram
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A simple join on `Firstname` gives 2,663 matches and the equivalent match on
    `Lastname` has 982 matches. These counts exceed the number of MPs and arise because
    of repeated common names that match more than once between the two datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have 599 matches out of 650 so far, but can we do better? Let’s start with
    examining the `Constituency` attribute in our datasets. As a categorical variable,
    we would expect this to be pretty easy to match:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We have 623 matches, leaving 27 unmatched. Why? Surely we’d expect the same
    constituencies to be present in both datasets, so what is going wrong?
  prefs: []
  type: TYPE_NORMAL
- en: Constituency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s have a look at the first five of the unmatched population in both datasets.
    To do this we perform an outer join between the DataFrames using the `Constituency`
    attribute and then select those records found in either the right (Wikipedia)
    or left (TheyWorkForYou) DataFrame. The results are shown in [Figure 2-8](#fig-2-8).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0208.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-8\. Constituency mismatches
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can see that the first dataset from the TheyWorkForYou website has commas
    embedded in the constituency names, whereas the Wikipedia data does not. This
    explains why they don’t match. To ensure consistency, let’s remove any commas
    from both DataFrames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'After applying this cleansing we have a perfect match on all 650 constituencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Case Sensitivity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this simple example, we have matching case conventions (e.g., initial capitalization)
    between the two datasets. In many situations this won’t be the case, and you’ll
    need to standardize on upper- or lowercase characters. We’ll see how this can
    be done in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Repeating our perfect match on all three attributes, we can now match 624 records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: What about the other 26?
  prefs: []
  type: TYPE_NORMAL
- en: A little domain knowledge is useful here. As we considered at the start of the
    chapter, between the election in 2019 and the time of writing, a number of by-elections
    took place. If we look at constituencies where neither the first name nor the
    last name matches then, for this simple example at least, we can identify likely
    candidates, as shown in [Figure 2-9](#fig-2-9).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0209.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-9\. Potential by-elections
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Of our 14 by-election candidates, we have 13 cases where the names are entirely
    different, suggesting we are correct to discount them, but the candidate for Newton
    Abbot appears to be a potential match because the middle name “Morris” has been
    included in the last name in one dataset and in the first name in the other, frustrating
    our exact match on both attributes.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, we can verify our conclusion with data from the [UK Parliament website](https://oreil.ly/eWhWf).
    This confirms that by-elections have been held in the matching constituencies.
    So this explains 13 of our 26 unmatched records—what about the rest? Let’s pick
    out where either the first name or the last name matches but the other doesn’t.
    This subset is shown in [Figure 2-10](#fig-2-10).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0210.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-10\. Potential by-elections
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can see that the remaining 12 records, as listed in [Table 2-1](#table-2-1),
    display a variety of the matching issues that we discussed in [Chapter 1](ch01.html#chapter_1).
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-1\. Matching issues summary table
  prefs: []
  type: TYPE_NORMAL
- en: '| Matching issue | **TheyWorkForYou** | **Wikipedia** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Shortened names | Dan | Daniel |'
  prefs: []
  type: TYPE_TB
- en: '|   | Tan | Tanmanjeet |'
  prefs: []
  type: TYPE_TB
- en: '|   | Liz | Elizabeth |'
  prefs: []
  type: TYPE_TB
- en: '|   | Chris | Christopher |'
  prefs: []
  type: TYPE_TB
- en: '|   | Nus | Nusrat |'
  prefs: []
  type: TYPE_TB
- en: '| Middle initials included | Diana R. | Diana |'
  prefs: []
  type: TYPE_TB
- en: '|   | Jeffrey M. | Jeffrey |'
  prefs: []
  type: TYPE_TB
- en: '| Middle name included | Preet Kaur | Preet |'
  prefs: []
  type: TYPE_TB
- en: '|   | John Martin | John |'
  prefs: []
  type: TYPE_TB
- en: '| Last name suffix | Paisley Jnr | Paisley |'
  prefs: []
  type: TYPE_TB
- en: '| Double-barreled last names | Docherty | Docherty-Hughes |'
  prefs: []
  type: TYPE_TB
- en: 'There is one remaining mismatch that is really hard to resolve: a change of
    the last name Kniveton (previously Griffiths) in the Burton constituency. Now
    we have accounted for all 650 constituencies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we further cleanse the `Firstname` from the TheyWorkForYou data, removing
    any middle initials or names, we can improve our matches still further:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now match another four records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This brings us to end of our introduction to basic data cleansing techniques.
    We now have only nine unresolved records, as shown in [Figure 2-11](#fig-2-11). In
    the next chapter, we will see how more approximate text matching techniques can
    help us resolve some of these too.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0211.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-11\. Unresolved entities
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Measuring Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s evaluate our performance using a simple exact matching method based on
    the metrics we defined in [Chapter 1](ch01.html#chapter_1). Our total population
    size is 650, within which we have:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper T r u e p o s i t i v e m a t c h e s left-parenthesis
    upper T upper P right-parenthesis equals 628"><mrow><mi>T</mi> <mi>r</mi> <mi>u</mi>
    <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi> <mi>v</mi>
    <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi>
    <mo>(</mo> <mi>T</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo> <mn>628</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper F a l s e p o s i t i v e m a t c h e s left-parenthesis
    upper F upper P right-parenthesis equals 0"><mrow><mi>F</mi> <mi>a</mi> <mi>l</mi>
    <mi>s</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi>
    <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper T r u e n e g a t i v e m a t c h e s left-parenthesis
    upper T upper N right-parenthesis equals 13 left-parenthesis upper B y minus e
    l e c t i o n s right-parenthesis"><mrow><mi>T</mi> <mi>r</mi> <mi>u</mi> <mi>e</mi>
    <mi>n</mi> <mi>e</mi> <mi>g</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi> <mi>v</mi> <mi>e</mi>
    <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo>
    <mi>T</mi> <mi>N</mi> <mo>)</mo> <mo>=</mo> <mn>13</mn> <mo>(</mo> <mi>B</mi>
    <mi>y</mi> <mo>-</mo> <mi>e</mi> <mi>l</mi> <mi>e</mi> <mi>c</mi> <mi>t</mi> <mi>i</mi>
    <mi>o</mi> <mi>n</mi> <mi>s</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper F a l s e n e g a t i v e m a t c h e s left-parenthesis
    upper F upper N right-parenthesis equals 9"><mrow><mi>F</mi> <mi>a</mi> <mi>l</mi>
    <mi>s</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mi>g</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi>
    <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>N</mi> <mo>)</mo> <mo>=</mo> <mn>9</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'We can calculate our performance metrics as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P r e c i s i o n equals StartFraction upper T upper P
    Over left-parenthesis upper T upper P plus upper F upper P right-parenthesis EndFraction
    equals StartFraction 628 Over left-parenthesis 628 plus 0 right-parenthesis EndFraction
    equals 100 percent-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>e</mi> <mi>c</mi> <mi>i</mi>
    <mi>s</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>628</mn> <mrow><mo>(</mo><mn>628</mn><mo>+</mo><mn>0</mn><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mn>100</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper R e c a l l equals StartFraction upper T upper P Over left-parenthesis
    upper T upper P plus upper F upper N right-parenthesis EndFraction equals StartFraction
    628 Over left-parenthesis 628 plus 9 right-parenthesis EndFraction almost-equals
    98.6 percent-sign"><mrow><mi>R</mi> <mi>e</mi> <mi>c</mi> <mi>a</mi> <mi>l</mi>
    <mi>l</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow> <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>628</mn> <mrow><mo>(</mo><mn>628</mn><mo>+</mo><mn>9</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>98</mn> <mo>.</mo> <mn>6</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper A c c u r a c y equals StartFraction left-parenthesis upper
    T upper P plus upper T upper N right-parenthesis Over left-parenthesis upper T
    upper P plus upper T upper N plus upper F upper P plus upper F upper N right-parenthesis
    EndFraction equals StartFraction left-parenthesis 628 plus 13 right-parenthesis
    Over 650 EndFraction almost-equals 98.6 percent-sign"><mrow><mi>A</mi> <mi>c</mi>
    <mi>c</mi> <mi>u</mi> <mi>r</mi> <mi>a</mi> <mi>c</mi> <mi>y</mi> <mo>=</mo> <mfrac><mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>)</mo></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mo>(</mo><mn>628</mn><mo>+</mo><mn>13</mn><mo>)</mo></mrow>
    <mn>650</mn></mfrac> <mo>≈</mo> <mn>98</mn> <mo>.</mo> <mn>6</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Our precision is perfect because we are setting a very high bar—an exact match
    on first name, last name, and constituency; if we declare a match, we always get
    it right. Our recall is also extremely good; we rarely fail to find a match we
    should have found. Finally, our overall accuracy is also very high.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this is a simple example with relatively high-quality data and we
    have the advantage of a very strong categorical variable (constituency) to match
    against.
  prefs: []
  type: TYPE_NORMAL
- en: Sample Calculation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have successfully resolved the names between our two datasets, so now we
    can use the combined information to test our hypothesis about the correlation
    between social media presence and the likelihood of reelection. Our resolved data
    now has everything we need in one table. [Figure 2-12](#fig-2-12) shows the first
    few rows of this table.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0212.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-12\. Sample of resolved entities
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can calculate the number of MPs who currently have Facebook accounts who
    held their seats in the 2019 election:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'As a percentage: <math alttext="StartFraction 474 Over 628 EndFraction almost-equals
    75 percent-sign"><mrow><mfrac><mn>474</mn> <mn>628</mn></mfrac> <mo>≈</mo> <mn>75</mn>
    <mo>%</mo></mrow></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we’ll save our cleansed datasets locally so that we can use them in
    subsequent chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To summarize, we used five simple techniques to standardize and cleanse our
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: Removed null records
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed leading and trailing unwanted characters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Split full name into first name and last name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed commas from constituency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removed middle names and initials from first name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a result we were able to join our datasets and then calculate a simple metric
    that we otherwise could not. Alas, there is no ubiquitous cleansing process; it
    depends on the datasets you have.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter we will see how fuzzy matching techniques can improve our
    performance even more.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch02.html#id309-marker)) A by-election, also known as a special election
    in the United States, is an election used to fill an office that has become vacant
    between general elections. In the UK Parliament, a seat in the House of Commons
    can become vacant when an MP resigns or dies.
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch02.html#id312-marker)) Software products identified in this book are
    suggestions only. You are responsible for evaluating whether to use any particular
    software and accept its license terms.
  prefs: []
  type: TYPE_NORMAL
