<html><head></head><body><section data-pdf-bookmark="Chapter 3. Simulation and Data Design" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch-theory-datadesign">&#13;
<h1><span class="label">Chapter 3. </span>Simulation and Data Design</h1>&#13;
&#13;
<p>In this chapter<a contenteditable="false" data-primary="lifecycle, data science" data-secondary="simulation and data design" data-type="indexterm" id="ix_lifecycle_data_sci_sim"/>, we develop the basic theoretical foundation needed to reason about how data is sampled and the implications on bias and variance. We build this foundation not on the dry equations of classic statistics but on the story of an urn filled with marbles. We use the computational tools of simulation to reason about the properties of selecting marbles from the urn and what they tell us about data collection in the real world. We connect the simulation process to common statistical distributions (the dry equations), but the basic tools of simulation enable us to go beyond what can be directly modeled using equations.</p>&#13;
&#13;
<p>As an example<a contenteditable="false" data-primary="election outcome prediction" data-type="indexterm" id="id701"/><a contenteditable="false" data-primary="predictions and predicting" data-secondary="election outcomes" data-type="indexterm" id="id702"/><a contenteditable="false" data-primary="simulation studies" data-secondary="election poll bias and variance" data-type="indexterm" id="id703"/>, we study how the pollsters failed to predict the outcome of the US presidential election in 2016. Our simulation study uses the actual votes cast in Pennsylvania. We simulate the sampling variation for a poll of these six million voters to uncover how response<a contenteditable="false" data-primary="bias" data-secondary="response" data-type="indexterm" id="id704"/><a contenteditable="false" data-primary="response bias" data-type="indexterm" id="id705"/> bias can skew polls and see how simply collecting more data would not have helped.</p>&#13;
&#13;
<p>In a second simulation<a contenteditable="false" data-primary="simulation studies" data-secondary="vaccine randomized trial" data-type="indexterm" id="id706"/><a contenteditable="false" data-primary="vaccine randomized trial simulation" data-type="indexterm" id="id707"/><a contenteditable="false" data-primary="COVID-19 vaccine efficacy" data-type="indexterm" id="id708"/> study, we examine a controlled experiment that demonstrated the efficacy of a COVID-19 vaccine but also launched a heated debate on the relative efficacy of vaccines. Abstracting the experiment to an urn model gives us a tool for studying assignment variation in randomized controlled experiments. Through simulation, we find the expected outcome of the clinical trial. Our simulation, along with careful examination of the data scope, debunks claims of vaccine ineffectiveness.</p>&#13;
&#13;
<p>A third example<a contenteditable="false" data-primary="simulation studies" data-secondary="sampling distribution, urn model" data-type="indexterm" id="id709"/><a contenteditable="false" data-primary="air quality sensors study" data-type="indexterm" id="id710"/> uses simulation to imitate a measurement process. When we compare the fluctuations in our artificial measurements of air quality to real measurements, we can evaluate the appropriateness of the urn to model fluctuations in air quality measurements. This comparison creates the backdrop against which we calibrate PurpleAir monitors so that they can more accurately measure air quality in times of low humidity, like during fire season.</p>&#13;
&#13;
<p>However, before we tackle some of the most significant data debates of our time, we first start small, very small, with the story of a few marbles sitting in an urn.</p>&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Urn Model" data-type="sect1"><div class="sect1" id="sec-theory-urn">&#13;
<h1>The Urn Model</h1>&#13;
&#13;
<p>The urn model<a contenteditable="false" data-primary="urn model" data-type="indexterm" id="ix_urn_mod"/> was developed by Jacob<a contenteditable="false" data-primary="Bernoulli, Jacob" data-type="indexterm" id="id711"/> Bernoulli in the early 1700s as a way to model the process of selecting items from a population. The urn model shown in <a class="reference internal" data-type="xref" href="#sample-urn">Figure 3-1</a> gives a visual depiction of the process of randomly sampling marbles from an urn. Five marbles were originally in the urn: three black and two white. The diagram shows that two draws were made: first a white marble was drawn and then a black marble.</p>&#13;
&#13;
<figure><div class="figure" id="sample-urn"><img src="assets/leds_0301.png"/>&#13;
<h6><span class="label">Figure 3-1. </span>Diagram of two marbles being drawn, without replacement, from an urn</h6>&#13;
</div></figure>&#13;
&#13;
<p>To set up an urn model, we first need to make a few decisions:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>The number of marbles in the urn</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>The color (or label) on each marble</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>The number of marbles to draw from the urn</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Finally, we also need to decide on the sampling process. For our process, we mix the marbles in the urn, and as we select a marble for our sample, we can choose to record the color and return the marble to the urn (with replacement), or set aside the marble so that it cannot be drawn again (without replacement).</p>&#13;
&#13;
<p>These decisions<a contenteditable="false" data-primary="random.choice method" data-type="indexterm" id="ix_ran_choice_meth"/><a contenteditable="false" data-primary="numpy library" data-type="indexterm" id="ix_numpy_ran_choice"/> make up the parameters of our model. We can adapt the urn model to describe many real-world situations by our choice for these parameters. To illustrate, consider the example in <a class="reference internal" data-type="xref" href="#sample-urn">Figure 3-1</a>. We can <em>simulate</em> the draw of two marbles from our urn without replacement between draws using <code>numpy</code>’s <code>random.choice</code> method. The <code>numpy</code> library supports functions for arrays, which can be particularly useful for data science:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">import</code></span><code> </code><span><code class="nn">numpy</code></span><code> </code><span><code class="k">as</code></span><code> </code><span><code class="nn">np</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">urn</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">b</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">b</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">b</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">w</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">w</code><code class="s2">"</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="s2">"</code><code class="s2">Sample 1:</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">choice</code></span><span><code class="p">(</code></span><span><code class="n">urn</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">replace</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="s2">"</code><code class="s2">Sample 2:</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">choice</code></span><span><code class="p">(</code></span><span><code class="n">urn</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">replace</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Sample 1: ['b' 'w']&#13;
Sample 2: ['w' 'b']&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Notice that we set the <code>replace</code> argument to <code>False</code> to indicate that once we sample a marble, we don’t return it to the urn.</p>&#13;
&#13;
<p>With this basic setup, we can get approximate answers to questions about the kinds of samples we would expect to see. What is the chance that our sample contains marbles of only one color? Does the chance change if we return each marble after selecting it? What if we changed the number of marbles in the urn? What if we draw more marbles from the urn? What happens if we repeat the process many times?</p>&#13;
&#13;
<p>The answers to these questions are fundamental to our understanding of data collection. We can build from these basic skills to simulate the urn and apply simulation techniques to real-world problems that can’t be easily solved with classic probability equations.</p>&#13;
&#13;
<p>For example, we can use simulation to easily estimate the fraction of samples where both marbles that we draw match in color. In the following code, we run 10,000 rounds of sampling two marbles from our urn. Using these samples, we can directly compute the proportion of samples with matching marbles:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">n</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="mi">10_000</code></span><code>&#13;
</code><span><code class="n">samples</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">choice</code></span><span><code class="p">(</code></span><span><code class="n">urn</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">replace</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code></span><code> </code><span><code class="k">for</code></span><code> </code><span><code class="n">_</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">range</code></span><span><code class="p">(</code></span><span><code class="n">n</code></span><span><code class="p">)</code><code class="p">]</code></span><code>&#13;
</code><span><code class="n">is_matching</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">marble1</code></span><code> </code><span><code class="o">==</code></span><code> </code><span><code class="n">marble2</code></span><code> </code><span><code class="k">for</code></span><code> </code><span><code class="n">marble1</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">marble2</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="n">samples</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s2">"</code><code class="s2">Proportion of samples with matching marbles: </code></span><span><code class="si">{</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><span><code class="n">is_matching</code></span><span><code class="p">)</code></span><span><code class="si">}</code></span><span><code class="s2">"</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Proportion of samples with matching marbles: 0.4032&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We just carried<a contenteditable="false" data-primary="np.random.choice method" data-type="indexterm" id="id712"/><a contenteditable="false" data-primary="simulation studies" data-type="indexterm" id="id713"/> out a <em>simulation study</em>. Our call to <code>np.random.choice</code> imitates the chance process of drawing two marbles from the urn without replacement. Each call to <code>np.random.choice</code> gives us one possible sample. In a simulation study, we repeat this chance process many times (<code>10_000</code> in this case) to get a whole bunch of samples. Then we use the typical behavior of these samples to reason about what we might expect to get from the chance process. While this might seem like a contrived example (it is), consider if we replaced the marbles with people on a dating service, replaced the colors with more complex attributes, and perhaps used a neural network to score a match, and you can start to see the foundation of much more sophisticated analysis.</p>&#13;
&#13;
<p>So far we have focused<a contenteditable="false" data-primary="populations" data-secondary="versus sample" data-secondary-sortas="sample" data-type="indexterm" id="id714"/> on the sample, but we are often interested in the relationship between the sample we might observe and what it can tell us about the “population” of marbles that were originally in the urn.</p>&#13;
&#13;
<p>We can draw<a contenteditable="false" data-primary="samples and sampling" data-secondary="versus population" data-secondary-sortas="population" data-type="indexterm" id="id715"/><a contenteditable="false" data-primary="access frame" data-type="indexterm" id="id716"/><a contenteditable="false" data-primary="data scope" data-secondary="in urn model" data-secondary-sortas="urn model" data-type="indexterm" id="id717"/> an analogy to data scope from <a class="reference internal" data-type="xref" href="ch02.html#ch-data-scope">Chapter 2</a>: a set of marbles drawn from the urn is a <em>sample</em>, and the collection of all marbles placed in the urn is the <em>access frame</em>, which in this situation we take to be the same as the <em>population</em>. This blurring of the difference between the access frame and the population points to the gap between simulation and reality. Simulations tend to simplify models. Nonetheless, they can give helpful insights to real-world phenomena.</p>&#13;
&#13;
<p>The urn model, where we do not replace the marbles between draws, is a common selection method called the <em>simple random sample</em>. We describe this method and other sampling techniques based on it next.<a contenteditable="false" data-primary="" data-startref="ix_numpy_ran_choice" data-type="indexterm" id="id718"/><a contenteditable="false" data-primary="" data-startref="ix_ran_choice_meth" data-type="indexterm" id="id719"/></p>&#13;
&#13;
<section data-pdf-bookmark="Sampling Designs" data-type="sect2"><div class="sect2" id="sampling-designs">&#13;
<h2>Sampling Designs</h2>&#13;
&#13;
<p>The process<a contenteditable="false" data-primary="samples and sampling" data-secondary="urn model" data-type="indexterm" id="ix_sample_data_urn"/><a contenteditable="false" data-primary="chance mechanism" data-secondary="in simple random sample" data-secondary-sortas="simple random sample" data-type="indexterm" id="id720"/><a contenteditable="false" data-primary="random selection of data sample" data-type="indexterm" id="id721"/><a contenteditable="false" data-primary="simple random sample" data-type="indexterm" id="id722"/><a contenteditable="false" data-primary="urn model" data-secondary="sampling designs" data-type="indexterm" id="ix_urn_mod_samp"/> of drawing marbles without replacement from an urn is equivalent to a simple random sample. <em>In a simple random sample, every sample has the same chance of being selected.</em> While the method name has the word <em>simple</em> in it, constructing a simple random sample is often anything, but simple and in many cases is also the best sampling procedure. Plus, if we are being honest, it can also be a little confusing.</p>&#13;
&#13;
<p>To better understand this sampling method, we return to the urn model. Consider an urn with seven marbles. Instead of coloring the marbles, we label each uniquely with a letter <code>A</code> through <code>G</code>. Since each marble has a different label, we can more clearly identify all possible samples that we might get. Let’s select three marbles from the urn without replacement, and use the <code>itertools</code> library to generate the list of all <span class="keep-together">combinations</span>:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">itertools</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">combinations</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">all_samples</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">"</code></span><span><code class="o">.</code></span><span><code class="n">join</code></span><span><code class="p">(</code></span><span><code class="n">sample</code></span><span><code class="p">)</code></span><code> </code><span><code class="k">for</code></span><code> </code><span><code class="n">sample</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="n">combinations</code></span><span><code class="p">(</code></span><span><code class="s2">"</code><code class="s2">ABCDEFG</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">3</code></span><span><code class="p">)</code><code class="p">]</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="n">all_samples</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="s2">"</code><code class="s2">Number of Samples:</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="nb">len</code></span><span><code class="p">(</code></span><span><code class="n">all_samples</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
['ABC', 'ABD', 'ABE', 'ABF', 'ABG', 'ACD', 'ACE', 'ACF', 'ACG', 'ADE', 'ADF', 'ADG', 'AEF', 'AEG', 'AFG', 'BCD', 'BCE', 'BCF', 'BCG', 'BDE', 'BDF', 'BDG', 'BEF', 'BEG', 'BFG', 'CDE', 'CDF', 'CDG', 'CEF', 'CEG', 'CFG', 'DEF', 'DEG', 'DFG', 'EFG']&#13;
Number of Samples: 35&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Our list shows that there are 35 unique sets of three marbles. We could have drawn each of these sets six different ways. For example, the set <span class="math notranslate nohighlight"><math> <mo fence="false" stretchy="false">{</mo> <mi>A</mi> <mo>,</mo> <mi>B</mi> <mo>,</mo> <mi>C</mi> <mo fence="false" stretchy="false">}</mo> </math></span> can be sampled:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">itertools</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">permutations</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">"</code></span><span><code class="o">.</code></span><span><code class="n">join</code></span><span><code class="p">(</code></span><span><code class="n">sample</code></span><span><code class="p">)</code></span><code> </code><span><code class="k">for</code></span><code> </code><span><code class="n">sample</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="n">permutations</code></span><span><code class="p">(</code></span><span><code class="s2">"</code><code class="s2">ABC</code><code class="s2">"</code></span><span><code class="p">)</code><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
['ABC', 'ACB', 'BAC', 'BCA', 'CAB', 'CBA']&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>In this small example, we can get a complete picture of all the ways in which we can draw any three marbles from the urn.</p>&#13;
&#13;
<p>Since each set of three marbles from the population of seven is equally likely to occur, the chance of any one particular sample must be <span class="math notranslate nohighlight"><math> <mn>1</mn> <mrow> <mo>/</mo> </mrow> <mn>35</mn> </math></span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mi>A</mi> <mi>B</mi> <mi>C</mi> <mo stretchy="false">)</mo> <mo>=</mo> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mtext>ABD</mtext> <mo stretchy="false">)</mo> <mo>=</mo> <mo>⋯</mo> <mo>=</mo> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mtext>EFG</mtext> <mo stretchy="false">)</mo> <mo>=</mo> <mfrac> <mn>1</mn> <mn>35</mn> </mfrac> </math></div>&#13;
</div>&#13;
&#13;
<p>We use the special symbol <span class="math notranslate nohighlight"><math> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> </math></span> to stand for “probability” or “chance,” and we read the statement <span class="math notranslate nohighlight"><math> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mi>A</mi> <mi>B</mi> <mi>C</mi> <mo stretchy="false">)</mo> </math></span> as “the chance the sample contains the marbles labeled A, B, and C in any order.”</p>&#13;
&#13;
<p>We can use the enumeration of all of the possible samples from the urn to answer additional questions about this chance process. For example, to find the chance that marble <span class="math notranslate nohighlight"><math> <mi>A</mi> </math></span> is in the sample, we can add up the chance of all samples that contain <span class="math notranslate nohighlight"><math> <mi>A</mi> </math></span>. There are 15 of them, so the chance is:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mrow> <mi>A</mi> <mtext> </mtext> <mi>i</mi> <mi>s</mi> <mtext> </mtext> <mi>i</mi> <mi>n</mi> <mtext> </mtext> <mi>t</mi> <mi>h</mi> <mi>e</mi> <mtext> </mtext> <mi>s</mi> <mi>a</mi> <mi>m</mi> <mi>p</mi> <mi>l</mi> <mi>e</mi> </mrow> <mo stretchy="false">)</mo> <mo>=</mo> <mfrac> <mn>15</mn> <mn>35</mn> </mfrac> <mo>=</mo> <mfrac> <mn>3</mn> <mn>7</mn> </mfrac> </math></div>&#13;
</div>&#13;
&#13;
<p>When it’s too difficult to list and count all of the possible samples, we can use simulation to help understand this chance process.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Many people mistakenly think that the defining property of a simple random sample is that every unit has an equal chance of being in the sample. However, this is not the case. A simple random sample of <span class="math notranslate nohighlight"><math> <mi>n</mi> </math></span> units from a population of <span class="math notranslate nohighlight"><math> <mi>N</mi> </math></span> means that every possible collection of <span class="math notranslate nohighlight"><math> <mi>n</mi> </math></span> of the <span class="math notranslate nohighlight"><math> <mi>N</mi> </math></span> units has the same chance of being selected. A slight variant of this is the <em>simple random sample with replacement</em>, where the units/marbles are returned to the urn after each draw. This method also has the property that every sample of <span class="math notranslate nohighlight"><math> <mi>n</mi> </math></span> units from a population of <span class="math notranslate nohighlight"><math> <mi>N</mi> </math></span> is equally likely to be selected. The difference, though, is that there are more possible sets of <span class="math notranslate nohighlight"><math> <mi>n</mi> </math></span> units because the same marble can appear more than once in the sample.</p>&#13;
</div>&#13;
&#13;
<p>The simple random sample (and its corresponding urn) is the main building block for more complex survey designs. We briefly describe two of the more widely used designs:</p>&#13;
&#13;
<dl class="simple myst">&#13;
	<dt>Stratified sampling</dt>&#13;
	<dd>&#13;
	<p>Divide<a contenteditable="false" data-primary="stratified sampling" data-type="indexterm" id="id723"/> the population into nonoverlapping groups, called <em>strata</em> (one group is called a <em>stratum</em> and more than one are strata), and then take a simple random sample from each. This is like having a separate urn for each stratum and drawing marbles from each urn, independently. The strata do not have to be the same size, and we need not take the same number of marbles from each.</p>&#13;
	</dd>&#13;
	<dt>Cluster sampling</dt>&#13;
	<dd>&#13;
	<p>Divide<a contenteditable="false" data-primary="cluster sampling" data-type="indexterm" id="id724"/> the population into nonoverlapping subgroups, called <em>clusters</em>, take a simple random sample of the clusters, and include all of the units in a cluster in the sample. We can think of this as a simple random sample from one urn that contains large marbles that are themselves containers of small marbles. (The large marbles need not have the same number of marbles in them.) When opened, the sample of large marbles turns into the sample of small marbles. (Clusters tend to be smaller than strata.)</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>As an example, we might organize our seven marbles, labeled <span class="math notranslate nohighlight"><math> <mi>A</mi> </math></span>–<span class="math notranslate nohighlight"><math> <mi>G</mi> </math></span>, into three clusters, <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <mi>A</mi> <mo>,</mo> <mi>B</mi> <mo stretchy="false">)</mo> </math></span>, <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <mi>C</mi> <mo>,</mo> <mi>D</mi> <mo stretchy="false">)</mo> </math></span>, and <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <mi>E</mi> <mo>,</mo> <mi>F</mi> <mo>,</mo> <mi>G</mi> <mo stretchy="false">)</mo> </math></span>. Then, a cluster sample of size one has an equal chance of drawing any of the three clusters. In this scenario, each marble has the same chance of being in the sample:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mtable columnalign="right left right" columnspacing="0em 2em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mrow> <mi>A</mi> <mtext> </mtext> <mtext>in sample</mtext> </mrow> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mtext>cluster</mtext> <mtext> </mtext> <mrow> <mo stretchy="false">(</mo> <mi>A</mi> <mo>,</mo> <mi>B</mi> <mo stretchy="false">)</mo> <mtext> </mtext> <mtext>chosen</mtext> </mrow> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mn>3</mn> </mfrac> </mtd> </mtr> <mtr> <mtd> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mrow> <mi>B</mi> <mtext> </mtext> <mtext>in sample</mtext> </mrow> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mtext>cluster</mtext> <mtext> </mtext> <mrow> <mo stretchy="false">(</mo> <mi>A</mi> <mo>,</mo> <mi>B</mi> <mo stretchy="false">)</mo> <mtext> </mtext> <mtext>chosen</mtext> </mrow> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mn>3</mn> </mfrac> </mtd> </mtr> <mtr> <mtd> <mrow> <mo>⋮</mo> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mrow> <mi>G</mi> <mtext> </mtext> <mtext>in sample</mtext> </mrow> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mrow> <mrow> <mi mathvariant="double-struck">P</mi> </mrow> </mrow> <mo stretchy="false">(</mo> <mtext>cluster</mtext> <mtext> </mtext> <mrow> <mo stretchy="false">(</mo> <mi>E</mi> <mo>,</mo> <mi>F</mi> <mo>,</mo> <mi>G</mi> <mo stretchy="false">)</mo> <mtext> </mtext> <mtext>chosen</mtext> </mrow> <mo stretchy="false">)</mo> </mtd> <mtd> <mi/> <mo>=</mo> <mfrac> <mn>1</mn> <mn>3</mn> </mfrac> </mtd> </mtr> </mtable> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>But every combination of elements is not equally likely: it is not possible for the sample to include both <span class="math notranslate nohighlight"><math> <mi>A</mi> </math></span> and <span class="math notranslate nohighlight"><math> <mi>C</mi> </math></span>, because they are in different clusters.</p>&#13;
&#13;
<p>Often, we are interested in a summary of the sample; in other words, we are interested in a <em>statistic</em>. For any sample, we can calculate the statistic, and the urn model helps us find the distribution of possible values that statistic may take on. Next, we examine the distribution of a statistic for our simple example.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Sampling Distribution of a Statistic" data-type="sect2"><div class="sect2" id="sampling-distribution-of-a-statistic">&#13;
<h2>Sampling Distribution of a Statistic</h2>&#13;
&#13;
<p>Suppose<a contenteditable="false" data-primary="samples and sampling" data-secondary="distribution of statistic" data-type="indexterm" id="ix_sample_data_stat"/><a contenteditable="false" data-primary="urn model" data-secondary="sampling distribution of statistic" data-type="indexterm" id="ix_urn_mod_samp_stat"/> we are interested in testing the failure pressure of a new fuel tank design for a rocket. It’s expensive to carry out the pressure tests since we need to destroy the fuel tank, and we may need to test more than one fuel tank to address variations in <span class="keep-together">manufacturing</span>.</p>&#13;
&#13;
<p>We can use the urn model to choose the prototypes to be tested, and we can summarize our test results by the proportion of prototypes that fail the test. The urn model provides us the knowledge that each of the samples has the same chance of being selected, and so the pressure test results are representative of the population.</p>&#13;
&#13;
<p>To keep the example simple, let’s say we have seven fuel tanks that are labeled like the marbles from before. Let’s see what happens when tanks <span class="math notranslate nohighlight"><math> <mi>A</mi> </math></span>, <span class="math notranslate nohighlight"><math> <mi>B</mi> </math></span>, <span class="math notranslate nohighlight"><math> <mi>D</mi> </math></span>, and <span class="math notranslate nohighlight"><math> <mi>F</mi> </math></span> fail the pressure test, if chosen, and tanks <span class="math notranslate nohighlight"><math> <mi>C</mi> </math></span>, <span class="math notranslate nohighlight"><math> <mi>E</mi> </math></span>, and <span class="math notranslate nohighlight"><math> <mi>G</mi> </math></span> pass.</p>&#13;
&#13;
<p>For each sample of three marbles, we can find the proportion of failures according to how many of these four defective prototypes are in the sample. We give a few examples of this calculation:</p>&#13;
&#13;
<table>&#13;
	<thead>&#13;
		<tr>&#13;
			<th class="head">Sample</th>&#13;
			<th class="head">ABC</th>&#13;
			<th class="head">BCE</th>&#13;
			<th class="head">BDF</th>&#13;
			<th class="head">CEG</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>Proportion</td>&#13;
			<td>&#13;
			<p>2/3</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>1/3</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>1</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>0</p>&#13;
			</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>Since we are drawing three marbles from the urn, the only possible sample proportions are <span class="math notranslate nohighlight"><math> <mn>0</mn> </math></span>, <span class="math notranslate nohighlight"><math> <mn>1</mn> <mrow> <mo>/</mo> </mrow> <mn>3</mn> </math></span>, <span class="math notranslate nohighlight"><math> <mn>2</mn> <mrow> <mo>/</mo> </mrow> <mn>3</mn> </math></span>, and <span class="math notranslate nohighlight"><math> <mn>1</mn> </math></span>, and for each triple, we can calculate its corresponding proportion. There are four samples that give us all failed tests (a sample proportion of 1). These are <span class="math notranslate nohighlight"><math> <mi>A</mi> <mi>B</mi> <mi>D</mi> </math></span>, <span class="math notranslate nohighlight"><math> <mi>A</mi> <mi>B</mi> <mi>F</mi> </math></span>, <span class="math notranslate nohighlight"><math> <mi>A</mi> <mi>D</mi> <mi>F</mi> </math></span>, and <span class="math notranslate nohighlight"><math> <mi>B</mi> <mi>D</mi> <mi>F</mi> </math></span>, so the chance of observing a sample proportion of 1 is <span class="math notranslate nohighlight"><math> <mn>4</mn> <mrow> <mo>/</mo> </mrow> <mn>35</mn> </math></span>. We can summarize the distribution of values for the sample proportion into a table, which we call the <em>sampling distribution</em> of the proportion:</p>&#13;
&#13;
<table>&#13;
	<thead>&#13;
		<tr>&#13;
			<th>Proportion of failures</th>&#13;
			<th>No. of samples</th>&#13;
			<th>Fraction of samples</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>0</td>&#13;
			<td class="right">&#13;
			<p>1</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>1/35 <span class="math notranslate nohighlight"><math> <mo>≈</mo> <mn>0.03</mn> </math></span></p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>1/3</td>&#13;
			<td class="right">&#13;
			<p>12</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>12/35 <span class="math notranslate nohighlight"><math> <mo>≈</mo> <mn>0.34</mn> </math></span></p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>2/3</td>&#13;
			<td class="right">&#13;
			<p>18</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>18/35 <span class="math notranslate nohighlight"><math> <mo>≈</mo> <mn>0.51</mn> </math></span></p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>1</td>&#13;
			<td class="right">&#13;
			<p>4</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>4/35 <span class="math notranslate nohighlight"><math> <mo>≈</mo> <mn>0.11</mn> </math></span></p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>Total</td>&#13;
			<td class="right">&#13;
			<p>35</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>1</p>&#13;
			</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>While these calculations are relatively straightforward, we can approximate them through a simulation study. To do this, we take samples of three from our population over and over—say 10,000 times. For each sample, we calculate the proportion of failures. That gives us 10,000 simulated sample proportions. The table of the simulated proportions should come close to the sampling distribution. We confirm this with a simulation study.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Simulating the Sampling Distribution" data-type="sect2"><div class="sect2" id="simulating-the-sampling-distribution">&#13;
<h2>Simulating the Sampling Distribution</h2>&#13;
&#13;
<p>Simulation<a contenteditable="false" data-primary="data distributions" data-secondary="simulation and data design" data-type="indexterm" id="ix_distrib_sim_design"/><a contenteditable="false" data-primary="urn model" data-secondary="simulating sampling distribution" data-type="indexterm" id="ix_urn_sim_samp"/><a contenteditable="false" data-primary="simulation studies" data-secondary="sampling distribution, urn model" data-type="indexterm" id="ix_sim_stud_urn"/> can be a powerful tool to understand complex random processes. In our example of seven fuel tanks, we are able to consider all possible samples from the corresponding urn model. However, in situations with large populations and samples and more complex sampling processes, it may not be tractable to directly compute the chance of certain outcomes. In these situations, we often turn to simulation to provide accurate estimates of the quantities we can’t compute directly.</p>&#13;
&#13;
<p>Let’s set up the problem of finding the sampling distribution of the proportion of failures in a simple random sample of three fuel tanks as an urn model. Since we are interested in whether or not the tank fails, we use 1 to indicate a failure and 0 to indicate a pass, giving us an urn with marbles labeled as follows:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">urn</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="mi">1</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">1</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">1</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">1</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">0</code></span><span><code class="p">]</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We have encoded the tanks <span class="math notranslate nohighlight"><math> <mi>A</mi> </math></span> through <span class="math notranslate nohighlight"><math> <mi>G</mi> </math></span> using 1 for fail and 0 for pass, so we can take the mean of the sample to get the proportion of failures in a sample:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">sample</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">choice</code></span><span><code class="p">(</code></span><span><code class="n">urn</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="mi">3</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">replace</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s2">"</code><code class="s2">Sample: </code></span><span><code class="si">{</code></span><span><code class="n">sample</code></span><span><code class="si">}</code></span><span><code class="s2">"</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s2">"</code><code class="s2">Prop Failures: </code></span><span><code class="si">{</code></span><span><code class="n">sample</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="si">}</code></span><span><code class="s2">"</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Sample: [1 0 0]&#13;
Prop Failures: 0.3333333333333333&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>In a simulation study, we repeat the sampling process thousands of times to get thousands of proportions, and then we estimate the sampling distribution of the proportion from what we get in our simulation. Here, we construct 10,000 samples (and so 10,000 proportions):</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">samples</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">choice</code></span><span><code class="p">(</code></span><span><code class="n">urn</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="mi">3</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">replace</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code></span><code> </code><span><code class="k">for</code></span><code> </code><span><code class="n">_</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">range</code></span><span><code class="p">(</code></span><span><code class="mi">10_000</code></span><span><code class="p">)</code><code class="p">]</code></span><code>&#13;
</code><span><code class="n">prop_failures</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">s</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code><code class="p">)</code></span><code> </code><span><code class="k">for</code></span><code> </code><span><code class="n">s</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="n">samples</code></span><span><code class="p">]</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We can study these 10,000 sample proportions and match our findings against what we calculated already using the complete enumeration of all 35 possible samples. We expect the simulation results to be close to our earlier calculations because we have repeated the sampling process many, many times. That is, we want to compare the fraction of the 10,000-sample proportion that is 0, <span class="math notranslate nohighlight"><math> <mn>1</mn> <mrow> <mo>/</mo> </mrow> <mn>3</mn> </math></span>, <span class="math notranslate nohighlight"><math> <mn>2</mn> <mrow> <mo>/</mo> </mrow> <mn>3</mn> </math></span>, and 1 to those we computed exactly; those fractions are <span class="math notranslate nohighlight"><math> <mn>1</mn> <mrow> <mo>/</mo> </mrow> <mn>35</mn> </math></span>, <span class="math notranslate nohighlight"><math> <mn>12</mn> <mrow> <mo>/</mo> </mrow> <mn>35</mn> </math></span>, <span class="math notranslate nohighlight"><math> <mn>18</mn> <mrow> <mo>/</mo> </mrow> <mn>35</mn> </math></span>, and <span class="math notranslate nohighlight"><math> <mn>4</mn> <mrow> <mo>/</mo> </mrow> <mn>35</mn> </math></span>, or about <span class="math notranslate nohighlight"><math> <mn>0.03</mn> </math></span>, <span class="math notranslate nohighlight"><math> <mn>0.34</mn> </math></span>, <span class="math notranslate nohighlight"><math> <mn>0.51</mn> </math></span>, and <span class="math notranslate nohighlight"><math> <mn>0.11</mn> </math></span>:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">unique_els</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">counts_els</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">unique</code></span><span><code class="p">(</code></span><span><code class="n">prop_failures</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">return_counts</code></span><span><code class="o">=</code></span><span><code class="kc">True</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">pd</code></span><span><code class="o">.</code></span><span><code class="n">DataFrame</code></span><span><code class="p">(</code><code class="p">{</code></span><code>&#13;
</code><code>    </code><span><code class="s2">"</code><code class="s2">Proportion of failures</code><code class="s2">"</code></span><span><code class="p">:</code></span><code> </code><span><code class="n">unique_els</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>    </code><span><code class="s2">"</code><code class="s2">Fraction of samples</code><code class="s2">"</code></span><span><code class="p">:</code></span><code> </code><span><code class="n">counts_els</code></span><code> </code><span><code class="o">/</code></span><code> </code><span><code class="mi">10_000</code></span><span><code class="p">,</code></span><code>&#13;
</code><span><code class="p">}</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>Proportion of failures</th>&#13;
			<th>Fraction of samples</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>0</strong></td>&#13;
			<td>0.00</td>&#13;
			<td>0.03</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1</strong></td>&#13;
			<td>0.33</td>&#13;
			<td>0.35</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2</strong></td>&#13;
			<td>0.67</td>&#13;
			<td>0.51</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>3</strong></td>&#13;
			<td>1.00</td>&#13;
			<td>0.11</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The simulation results are very close to the exact chances that we calculated earlier.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Simulation studies leverage random number generators to sample many outcomes from a random process. In a sense, simulation studies convert complex random processes into data that we can readily analyze using the broad set of computational tools we cover in this book. While simulation studies typically do not provide definitive proof of a particular hypothesis, they can provide important evidence. In many situations, simulation is the most accurate estimation process we have.</p>&#13;
</div>&#13;
&#13;
<p>Drawing marbles from an urn with 0s and 1s is such a popular framework for understanding randomness that this chance process has been given a formal name, <em>hypergeometr</em><em>ic distribution</em>, and most software provides functionality to rapidly carry out simulations of this process. In the next section, we simulate the hypergeometric distribution of the fuel tank example.<a contenteditable="false" data-primary="" data-startref="ix_stat_sample_dist" data-type="indexterm" id="id725"/><a contenteditable="false" data-primary="" data-startref="ix_urn_mod_samp_stat" data-type="indexterm" id="id726"/><a contenteditable="false" data-startref="ix_urn_mod_samp" data-type="indexterm" id="id727"/><a contenteditable="false" data-primary="" data-startref="ix_sample_data_urn" data-type="indexterm" id="id728"/><a contenteditable="false" data-primary="" data-startref="ix_sample_data_stat" data-type="indexterm" id="id729"/></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Simulation with the Hypergeometric Distribution" data-type="sect2"><div class="sect2" id="simulation-with-the-hypergeometric-distribution">&#13;
<h2>Simulation with the Hypergeometric Distribution</h2>&#13;
&#13;
<p>Instead<a contenteditable="false" data-primary="urn model" data-secondary="simulation with hypergeometric distribution" data-type="indexterm" id="ix_urn_hyperg"/><a contenteditable="false" data-primary="simulation studies" data-secondary="with hypergeometric distribution" data-type="indexterm" id="ix_sim_stud_hyperg"/><a contenteditable="false" data-primary="random.hypergeometric method" data-type="indexterm" id="id730"/><a contenteditable="false" data-primary="numpy library" data-type="indexterm" id="id731"/><a contenteditable="false" data-primary="hypergeometric probability distribution" data-type="indexterm" id="ix_hyperg_prob_dist"/><a contenteditable="false" data-primary="probability" data-secondary="hypergeometric distribution" data-type="indexterm" id="ix_prob_hyperg_dist"/> of using <code>random.choice</code>, we can use <code>numpy</code>’s <code>random.hypergeometric</code> to simulate drawing marbles from the urn and counting the number of failures. The <code>random.hypergeometric</code> method is optimized for the 0-1 urn and allows us to ask for 10,000 simulations in one call. For completeness, we repeat our simulation study and calculate the empirical proportions:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">simulations_fast</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">hypergeometric</code></span><span><code class="p">(</code></span><code>&#13;
</code><code>    </code><span><code class="n">ngood</code></span><span><code class="o">=</code></span><span><code class="mi">4</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">nbad</code></span><span><code class="o">=</code></span><span><code class="mi">3</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">nsample</code></span><span><code class="o">=</code></span><span><code class="mi">3</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="mi">10_000</code></span><code>&#13;
</code><span><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="n">simulations_fast</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
[1 1 2 ... 1 2 2]&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>(We don’t think that a pass is “bad”; it’s just a naming convention to call the type you want to count “good” and the other “bad.”)</p>&#13;
&#13;
<p>We tally the fraction of the 10,000 samples with 0, 1, 2, or 3 failures:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">unique_els</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">counts_els</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">unique</code></span><span><code class="p">(</code></span><span><code class="n">simulations_fast</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">return_counts</code></span><span><code class="o">=</code></span><span><code class="kc">True</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">pd</code></span><span><code class="o">.</code></span><span><code class="n">DataFrame</code></span><span><code class="p">(</code><code class="p">{</code></span><code>&#13;
</code><code>    </code><span><code class="s2">"</code><code class="s2">Number of failures</code><code class="s2">"</code></span><span><code class="p">:</code></span><code> </code><span><code class="n">unique_els</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>    </code><span><code class="s2">"</code><code class="s2">Fraction of samples</code><code class="s2">"</code></span><span><code class="p">:</code></span><code> </code><span><code class="n">counts_els</code></span><code> </code><span><code class="o">/</code></span><code> </code><span><code class="mi">10_000</code></span><span><code class="p">,</code></span><code>&#13;
</code><span><code class="p">}</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>Number of failures</th>&#13;
			<th>Fraction of samples</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>0</strong></td>&#13;
			<td>0</td>&#13;
			<td>0.03</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1</strong></td>&#13;
			<td>1</td>&#13;
			<td>0.34</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2</strong></td>&#13;
			<td>2</td>&#13;
			<td>0.52</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>3</strong></td>&#13;
			<td>3</td>&#13;
			<td>0.11</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>You might have asked yourself already: since the hypergeometric is so popular, why not provide the exact distribution of the possible values? In fact, we can calculate these exactly:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">scipy</code><code class="nn">.</code><code class="nn">stats</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">hypergeom</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">num_failures</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">1</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">3</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="n">pd</code></span><span><code class="o">.</code></span><span><code class="n">DataFrame</code></span><span><code class="p">(</code><code class="p">{</code></span><code>&#13;
</code><code>    </code><span><code class="s2">"</code><code class="s2">Number of failures</code><code class="s2">"</code></span><span><code class="p">:</code></span><code> </code><span><code class="n">num_failures</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>    </code><span><code class="s2">"</code><code class="s2">Fraction of samples</code><code class="s2">"</code></span><span><code class="p">:</code></span><code> </code><span><code class="n">hypergeom</code></span><span><code class="o">.</code></span><span><code class="n">pmf</code></span><span><code class="p">(</code></span><span><code class="n">num_failures</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">7</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">4</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">3</code></span><span><code class="p">)</code><code class="p">,</code></span><code>&#13;
</code><span><code class="p">}</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>Number of failures</th>&#13;
			<th>Fraction of samples</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>0</strong></td>&#13;
			<td>0</td>&#13;
			<td>0.03</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1</strong></td>&#13;
			<td>1</td>&#13;
			<td>0.34</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2</strong></td>&#13;
			<td>2</td>&#13;
			<td>0.51</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>3</strong></td>&#13;
			<td>3</td>&#13;
			<td>0.11</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Whenever possible, it’s a good idea to use the functionality provided in a third-party package for simulating from a named distribution, such as the random number generators offered in <code>numpy</code>, rather than writing your own function. It’s best to take advantage of efficient and accurate code that others have developed. That said, building from scratch on occasion can help you gain an understanding of an algorithm, so we recommend trying it.</p>&#13;
</div>&#13;
&#13;
<p>Perhaps the two most common<a contenteditable="false" data-primary="probability" data-secondary="binomial distribution" data-type="indexterm" id="id732"/><a contenteditable="false" data-primary="binomial distribution" data-type="indexterm" id="id733"/> chance processes are those that arise from counting the number of 1s drawn from a 0-1 urn: drawing without replacement is the <em>hypergeometric</em> distribution and drawing with replacement is the <em>binomial</em> distribution.</p>&#13;
&#13;
<p>While this simulation<a contenteditable="false" data-primary="hypergeom.pmf" data-type="indexterm" id="id734"/> was so simple that we could have used <code>hypergeom.pmf</code> to directly compute our distribution, we wanted to demonstrate the intuition that a simulation study can reveal. The approach we take in this book is to develop an understanding of chance processes based on simulation studies. However, we do formalize the notion of a probability distribution of a statistic (like the proportion of fails in a sample) in <a class="reference internal" data-type="xref" href="ch17.html#ch-inf-pred-theory">Chapter 17</a>.</p>&#13;
&#13;
<p>Now that we have simulation as a tool for understanding accuracy, we can revisit the election example from <a class="reference internal" data-type="xref" href="ch02.html#ch-data-scope">Chapter 2</a> and carry out a post-election study of what might have gone wrong with the voter polls. This simulation study imitates drawing more than a thousand marbles (voters who participate in the poll) from an urn of six million. We can examine potential sources of bias and the variation in the polling results, and we can carry out a what-if analysis where we examine how the predictions might have gone if a larger number of draws from the urn were taken.<a contenteditable="false" data-primary="" data-startref="ix_hyperg_prob_dist" data-type="indexterm" id="id735"/><a contenteditable="false" data-primary="" data-startref="ix_sim_stud_urn" data-type="indexterm" id="id736"/><a contenteditable="false" data-primary="" data-startref="ix_urn_sim_samp" data-type="indexterm" id="id737"/><a contenteditable="false" data-primary="" data-startref="ix_urn_mod" data-type="indexterm" id="id738"/><a contenteditable="false" data-primary="" data-startref="ix_distrib_sim_design" data-type="indexterm" id="id739"/><a contenteditable="false" data-primary="" data-startref="ix_prob_hyperg_dist" data-type="indexterm" id="id740"/><a contenteditable="false" data-primary="" data-startref="ix_sim_stud_hyperg" data-type="indexterm" id="id741"/><a contenteditable="false" data-primary="" data-startref="ix_urn_hyperg" data-type="indexterm" id="id742"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Example: Simulating Election Poll Bias and Variance" data-type="sect1"><div class="sect1" id="sec-theory-electionpolls">&#13;
<h1>Example: Simulating Election Poll Bias and Variance</h1>&#13;
&#13;
<p>In 2016, nearly every prediction<a contenteditable="false" data-primary="lifecycle, data science" data-secondary="election poll bias and variance simulation" data-type="indexterm" id="ix_lifecycle_data_sci_elect"/><a contenteditable="false" data-primary="simulation studies" data-secondary="election poll bias and variance" data-type="indexterm" id="ix_sim_stud_elect"/><a contenteditable="false" data-primary="variance" data-secondary="election poll bias example" data-type="indexterm" id="ix_var_elect"/><a contenteditable="false" data-primary="election poll bias and variance simulation" data-type="indexterm" id="ix_elect_var_sim"/> for the outcome of the US presidential election was wrong. This was a historic level of prediction error that shocked the statistics and data science communities. Here, we examine why nearly every political poll was so confident and yet also so wrong. This story both illustrates the power of simulation and reveals the hubris of data and the challenge of bias.</p>&#13;
&#13;
<p>The president of the United States is chosen by the Electoral College, not by popular vote. Each state is allotted a certain number of votes to cast in the Electoral College according to the size of its population. Typically, whomever wins the popular vote in a state receives all of the Electoral College votes for that state. With the aid of polls conducted in advance of the election, pundits identify “battleground” states where the election is expected to be close and the Electoral College votes might swing the <span class="keep-together">election</span>.</p>&#13;
&#13;
<p>In 2016, pollsters correctly predicted the election outcome in 46 of the 50 states. Not bad! After all, for those 46 states, Donald Trump received 231 and Hillary Clinton received 232 Electoral College votes—nearly a tie, with Clinton having a very narrow lead. Unfortunately, the remaining four states, Florida, Michigan, Pennsylvania, and Wisconsin, were identified as battleground states and accounted for a total of 75 votes. The margins of the popular vote in these four states were narrow. For example, in Pennsylvania, Trump received 48.18% and Clinton received 47.46% of the 6,165,478 votes cast. Such narrow margins can make it hard to predict the outcome given the sample sizes that the polls used. But there was an even greater challenge hidden in the survey process itself.</p>&#13;
&#13;
<p>Many experts have studied the 2016 election results to dissect and identify what went wrong. According to the <a class="reference external" href="https://oreil.ly/4FWW2">American Association for Public Opinion Research</a>, one online, opt-in poll adjusted its polling results for the education of the respondents but used only three broad categories (high school or less, some college, and college graduate). The pollsters found that if they had separated out respondents with advanced degrees from those with college degrees, then they would have reduced Clinton’s estimated percentage by 0.5 points. In other words, after the fact, they were able to identify an education bias where highly educated voters tended to be more willing to participate in polls. This bias matters because these voters also tended to prefer Clinton over Trump.</p>&#13;
&#13;
<p>Now that we know how people actually voted, we can carry out a simulation study like <a class="reference external" href="https://oreil.ly/hOSC2">Manfred te Grotenhuis et al.’s</a>, which imitates election polling under different scenarios to help develop intuition for accuracy, bias, and variance.<sup><a data-type="noteref" href="ch03.html#id743" id="id743-marker">1</a></sup> We can simulate and compare the polls for Pennsylvania under two scenarios:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>People surveyed didn’t change their minds, didn’t hide who they voted for, and were representative of those who voted on election day.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>People with a higher education were more likely to respond, which led to a bias for Clinton.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p class="pagebreak-before less_space">Our ultimate goal is to understand the frequency with which a poll incorrectly calls the election for Hillary Clinton when a sample is collected with absolutely no bias and when there is a small amount of nonresponse bias. We begin by setting up the urn model for the first scenario.</p>&#13;
&#13;
<section data-pdf-bookmark="The Pennsylvania Urn Model" data-type="sect2"><div class="sect2" id="the-pennsylvania-urn-model">&#13;
<h2>The Pennsylvania Urn Model</h2>&#13;
&#13;
<p>Our urn<a contenteditable="false" data-primary="urn model" data-secondary="Pennsylvania poll voters" data-type="indexterm" id="ix_urn_mod_pa"/><a contenteditable="false" data-primary="Pennsylvania urn model, election polling example" data-type="indexterm" id="ix_pa_run_mod"/> model for carrying out a poll of Pennsylvania voters is an after-the-fact situation where we use the outcome of the election. The urn has 6,165,478 marbles in it, one for each voter. Like with our tiny population, we write on each marble the candidate that they voted for, draw 1,500 marbles from the urn (1,500 is a typical size for these polls), and tally the votes for Trump, Clinton, and any other candidate. From the tally, we can calculate Trump’s lead over Clinton.</p>&#13;
&#13;
<p>Since we care only about Trump’s lead over Clinton, we can lump together all votes for other candidates. This way, each marble has one of three possible votes: Trump, Clinton, or Other. We can’t ignore the “Other” category, because it impacts the size of the lead. Let’s divvy up the voter counts between these three groups:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">proportions</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">array</code></span><span><code class="p">(</code><code class="p">[</code></span><span><code class="mf">0.4818</code></span><span><code class="p">,</code></span><code> </code><span><code class="mf">0.4746</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">1</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="p">(</code></span><span><code class="mf">0.4818</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="mf">0.4746</code></span><span><code class="p">)</code><code class="p">]</code><code class="p">)</code></span><code>               </code><code>&#13;
</code><span><code class="n">n</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="mi">1_500</code></span><code> </code><code>&#13;
</code><span><code class="n">N</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="mi">6_165_478</code></span><code>&#13;
</code><span><code class="n">votes</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">trunc</code></span><span><code class="p">(</code></span><span><code class="n">N</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="n">proportions</code></span><span><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">astype</code></span><span><code class="p">(</code></span><span><code class="nb">int</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">votes</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
array([2970527, 2926135,  268814])&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>This version<a contenteditable="false" data-primary="probability" data-secondary="multivariate_hypergeom.rvs" data-type="indexterm" id="id744"/><a contenteditable="false" data-primary="data distributions" data-secondary="multivariate relationships" data-type="indexterm" id="id745"/><a contenteditable="false" data-primary="scipy.stats.multivariate_hypergeom.rvs method" data-type="indexterm" id="id746"/><a contenteditable="false" data-primary="multivariate_hypergeom.rvs method" data-type="indexterm" id="id747"/><a contenteditable="false" data-primary="multivariate distributions" data-type="indexterm" id="id748"/> of the urn model has three types of marbles in it. It is a bit more complex than the hypergeometric distribution, but it is still common enough to have a named distribution: the <em>multivariate hypergeometric</em>. In Python, the urn model with more than two types of marbles is implemented by the <code>scipy.stats.multivariate_hypergeom.rvs</code> method. The function returns the number of each type of marble drawn from the urn. We call the function as follows:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">scipy</code><code class="nn">.</code><code class="nn">stats</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">multivariate_hypergeom</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">multivariate_hypergeom</code></span><span><code class="o">.</code></span><span><code class="n">rvs</code></span><span><code class="p">(</code></span><span><code class="n">votes</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">n</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
array([727, 703,  70])&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>As before, each time we call <code>multivariate_hypergeom.rvs</code> we get a different sample and counts:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">multivariate_hypergeom</code></span><span><code class="o">.</code></span><span><code class="n">rvs</code></span><span><code class="p">(</code></span><span><code class="n">votes</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">n</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
array([711, 721,  68])&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We need to compute Trump’s lead for each sample: <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <msub> <mi>n</mi> <mi>T</mi> </msub> <mo>−</mo> <msub> <mi>n</mi> <mi>C</mi> </msub> <mo stretchy="false">)</mo> <mrow> <mo>/</mo> </mrow> <mi>n</mi> </math></span>, where <span class="math notranslate nohighlight"><math> <msub> <mi>n</mi> <mi>T</mi> </msub> </math></span> is the number of Trump votes in the sample and <span class="math notranslate nohighlight"><math> <msub> <mi>n</mi> <mi>C</mi> </msub> </math></span> the number for Clinton. If the lead is positive, then the sample shows a win for Trump.</p>&#13;
&#13;
<p>We know the actual lead was 0.4818 – 0.4746 = 0.0072. To get a sense of the variation in the poll, we can simulate the chance process of drawing from the urn over and over and examine the values that we get in return. Now we can simulate 100,000 polls of 1,500 voters from the votes cast in Pennsylvania:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="k">def</code></span><code> </code><span><code class="nf">trump_advantage</code></span><span><code class="p">(</code></span><span><code class="n">votes</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">n</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="n">sample_votes</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">multivariate_hypergeom</code></span><span><code class="o">.</code></span><span><code class="n">rvs</code></span><span><code class="p">(</code></span><span><code class="n">votes</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">n</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">sample_votes</code></span><span><code class="p">[</code></span><span><code class="mi">0</code></span><span><code class="p">]</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">sample_votes</code></span><span><code class="p">[</code></span><span><code class="mi">1</code></span><span><code class="p">]</code><code class="p">)</code></span><code> </code><span><code class="o">/</code></span><code> </code><span><code class="n">n</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">simulations</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">trump_advantage</code></span><span><code class="p">(</code></span><span><code class="n">votes</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">n</code></span><span><code class="p">)</code></span><code> </code><span><code class="k">for</code></span><code> </code><span><code class="n">_</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">range</code></span><span><code class="p">(</code></span><span><code class="mi">100_000</code></span><span><code class="p">)</code><code class="p">]</code></span><code> </code><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>On average, the polling results show Trump with close to a 0.7% lead, as expected given the composition of the more than six million votes cast:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><span><code class="n">simulations</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
0.007177066666666666&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>However, many times the lead in a sample was negative, meaning Clinton was the winner for that sample of voters. The following histogram shows the sampling distribution of Trump’s advantage in Pennsylvania for a sample of 1,500 voters. The vertical dashed line at 0 shows that more often than not, Trump is called, but there are many times when the poll of 1,500 shows Clinton in the lead:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_03in01.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>In the 100,0000 simulated polls, we find Trump a victor about 60% of the time:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">array</code></span><span><code class="p">(</code></span><span><code class="n">simulations</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">&gt;</code></span><code> </code><span><code class="mi">0</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
0.60613&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>In other words, a sample will correctly predict Trump’s victory <em>even if the sample was collected with absolutely no bias</em> about 60% of the time. And this unbiased sample will be wrong about 40% of the time.</p>&#13;
&#13;
<p>We have used the urn model to study the variation in a simple poll, and we found how a poll’s prediction might look if there was no bias in our selection process (the marbles are indistinguishable, and every possible collection of 1,500 marbles out of the more than six million marbles is equally likely). Next, we see what happens when a little bias enters the mix.<a contenteditable="false" data-primary="" data-startref="ix_var_elect" data-type="indexterm" id="id749"/><a contenteditable="false" data-primary="" data-startref="ix_pa_run_mod" data-type="indexterm" id="id750"/><a contenteditable="false" data-primary="" data-startref="ix_urn_mod_pa" data-type="indexterm" id="id751"/></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="An Urn Model with Bias" data-type="sect2"><div class="sect2" id="an-urn-model-with-bias">&#13;
<h2>An Urn Model with Bias</h2>&#13;
&#13;
<p>According<a contenteditable="false" data-primary="bias" data-secondary="urn model of election poll with" data-type="indexterm" id="ix_bias_urn_mod"/> to Grotenhuis, “In a perfect world, polls sample from the population of voters, who would state their political preference perfectly clearly and then vote accordingly.”<sup><a data-type="noteref" href="ch03.html#id752" id="id752-marker">2</a></sup> That’s the simulation study that we just performed. In reality, it is often difficult to control for every source of bias.</p>&#13;
&#13;
<p>We investigate here the effect of a small education bias on the polling results. Specifically, we examine the impacts of a 0.5% bias in favor of Clinton. This bias essentially means that we see a distorted picture of voter preferences in our poll. Instead of 47.46% votes for Clinton, we have 47.96%, and we have 48.18 – 0.5 = 47.68% for Trump. We adjust the proportions of marbles in the urn to reflect this change:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">bias</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="mf">0.005</code></span><code>&#13;
</code><span><code class="n">proportions_bias</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">array</code></span><span><code class="p">(</code><code class="p">[</code></span><span><code class="mf">0.4818</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">bias</code></span><span><code class="p">,</code></span><code> </code><span><code class="mf">0.4747</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="n">bias</code></span><span><code class="p">,</code></span><code> </code><code>&#13;
</code><code>                             </code><span><code class="mi">1</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="p">(</code></span><span><code class="mf">0.4818</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="mf">0.4746</code></span><span><code class="p">)</code><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><span><code class="n">proportions_bias</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
array([0.48, 0.48, 0.04])&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">votes_bias</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">trunc</code></span><span><code class="p">(</code></span><span><code class="n">N</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="n">proportions_bias</code></span><span><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">astype</code></span><span><code class="p">(</code></span><span><code class="nb">int</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">votes_bias</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
array([2939699, 2957579,  268814])&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>When we carry out the simulation study again, this time with the biased urn, we find a quite different result:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">simulations_bias</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">trump_advantage</code></span><span><code class="p">(</code></span><span><code class="n">votes_bias</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">n</code></span><span><code class="p">)</code></span><code> </code><span><code class="k">for</code></span><code> </code><span><code class="n">_</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">range</code></span><span><code class="p">(</code></span><span><code class="mi">100_000</code></span><span><code class="p">)</code><code class="p">]</code></span><code> </code><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_03in02.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">array</code></span><span><code class="p">(</code></span><span><code class="n">simulations_bias</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">&gt;</code></span><code> </code><span><code class="mi">0</code></span><span><code class="p">)</code></span><code> </code><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
0.44967&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Now, Trump would have a positive lead in about 45% of the polls. Notice that the histograms from the two simulations are similar in shape. They are symmetric with tails of reasonable length. That is, they appear to roughly follow the normal curve. The second histogram is shifted slightly to the left, which reflects the nonresponse bias we introduced. Would increasing the sample size have helped? We investigate this topic next.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Conducting Larger Polls" data-type="sect2"><div class="sect2" id="conducting-larger-polls">&#13;
<h2>Conducting Larger Polls</h2>&#13;
&#13;
<p>With our simulation<a contenteditable="false" data-primary="big data considerations" data-secondary="and persistence of bias" data-secondary-sortas="persistence of bias" data-type="indexterm" id="ix_big_data_poll"/> study we can gain insight on the impact of a larger poll on the sample lead. For example, we can try a sample size of 12,000, eight times the size of the actual poll, and run 100,000 simulations for both the unbiased and biased <span class="keep-together">scenarios</span>:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">simulations_big</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">trump_advantage</code></span><span><code class="p">(</code></span><span><code class="n">votes</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">12_000</code></span><span><code class="p">)</code></span><code> </code><span><code class="k">for</code></span><code> </code><span><code class="n">_</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">range</code></span><span><code class="p">(</code></span><span><code class="mi">100_000</code></span><span><code class="p">)</code><code class="p">]</code></span><code>&#13;
</code><span><code class="n">simulations_bias_big</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">trump_advantage</code></span><span><code class="p">(</code></span><span><code class="n">votes_bias</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">12_000</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>                        </code><span><code class="k">for</code></span><code> </code><span><code class="n">_</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">range</code></span><span><code class="p">(</code></span><span><code class="mi">100_000</code></span><span><code class="p">)</code><code class="p">]</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">scenario_no_bias</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">array</code></span><span><code class="p">(</code></span><span><code class="n">simulations_big</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">&gt;</code></span><code> </code><span><code class="mi">0</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">scenario_bias</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">array</code></span><span><code class="p">(</code></span><span><code class="n">simulations_bias_big</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">&gt;</code></span><code> </code><span><code class="mi">0</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="n">scenario_no_bias</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">scenario_bias</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
0.78968 0.36935&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p class="pagebreak-before less_space">The simulation shows that Trump’s lead is detected in only about one-third of the simulated biased scenario. The spread of the histogram of these results is narrower than the spread when only 1,500 voters were polled. Unfortunately, it has narrowed in on the wrong value. We haven’t overcome the bias; we just have a more accurate picture of the biased situation. Big data has not come to the rescue. Additionally, larger polls have other problems. They are often harder to conduct because pollsters are working with limited resources, and efforts that could go into improving the data scope are being redirected to expanding the poll:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_03in03.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>After the fact, with multiple polls for the same election, we can detect bias. In a <a class="reference external" href="http://dx.doi.org/10.1080/01621459.2018.1448823">post-election analysis</a> of over 4,000 polls for 600 state-level, gubernatorial, senatorial, and presidential elections, researchers found that, on average, election polls exhibit a bias of about 1.5 percentage points, which helps explain why so many polls got it wrong.</p>&#13;
&#13;
<p>When the margin of victory is relatively small, as it was in 2016, a larger sample size reduces the sampling error, but unfortunately, if there is bias, then the predictions are close to the biased estimate. If the bias pushes the prediction from one candidate (Trump) to another (Clinton), then we have a “surprise” upset. Pollsters develop voter selection schemes that attempt to reduce bias, like the separation of voters’ preference by education level. But, as in this case, it can be difficult, even impossible, to account for new, unexpected sources of bias. Polls are still useful, but we need to acknowledge the issues with bias and do a better job at reducing it.</p>&#13;
&#13;
<p>In this example, we used the urn model to study a simple random sample in polling. Another common use of the urn is in randomized controlled experiments.<a contenteditable="false" data-primary="" data-startref="ix_big_data_poll" data-type="indexterm" id="id753"/><a contenteditable="false" data-primary="" data-startref="ix_bias_urn_mod" data-type="indexterm" id="id754"/><a contenteditable="false" data-primary="" data-startref="ix_elect_var_sim" data-type="indexterm" id="id755"/><a contenteditable="false" data-primary="" data-startref="ix_lifecycle_data_sci_elect" data-type="indexterm" id="id756"/><a contenteditable="false" data-primary="" data-startref="ix_sim_stud_elect" data-type="indexterm" id="id757"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Example: Simulating a Randomized Trial for a Vaccine" data-type="sect1"><div class="sect1" id="sec-theory-randomassignment">&#13;
<h1 class="less_space">Example: Simulating a Randomized Trial for a Vaccine</h1>&#13;
&#13;
<p>In a drug<a contenteditable="false" data-primary="urn model" data-secondary="randomized controlled vaccine trial" data-type="indexterm" id="ix_urn_mod_vacc"/><a contenteditable="false" data-primary="vaccine randomized trial simulation" data-type="indexterm" id="ix_vacc_ran_trial"/><a contenteditable="false" data-primary="random selection of data sample" data-type="indexterm" id="ix_ran_select_data"/><a contenteditable="false" data-primary="simulation studies" data-secondary="vaccine randomized trial" data-type="indexterm" id="ix_sim_stud_vacc"/><a contenteditable="false" data-primary="lifecycle, data science" data-secondary="vaccine randomized trial simulation" data-type="indexterm" id="ix_lifecycle_data_sci_vacc"/><a contenteditable="false" data-primary="randomized controlled experiments" data-type="indexterm" id="ix_ran_control_exp"/><a contenteditable="false" data-primary="COVID-19 vaccine efficacy" data-type="indexterm" id="ix_covid_vacc_eff"/> trial, volunteers for the trial receive either the new treatment or a placebo (a fake treatment), and researchers control the assignment of volunteers to the treatment and placebo groups. In a <em>randomized controlled experiment</em>, they use a chance process to make this assignment. Scientists essentially use an urn model to select the subjects for the treatment and control (those given the placebo groups). We can simulate the chance mechanism of the urn to better understand variation in the outcome of an experiment and the meaning of efficacy in clinical trials.</p>&#13;
&#13;
<p>In March 2021, Detroit Mayor Mike Duggan made <a class="reference external" href="https://oreil.ly/kB757">national news</a> when he turned down a shipment of over 6,000 Johnson &amp; Johnson (J&amp;J) vaccine doses, stating that the citizens of his city should “get the best.” The mayor was referring to the efficacy rate of the vaccine, which was reported to be about 66%. In comparison, Moderna and Pfizer both reported efficacy rates of about 95% for their vaccines.</p>&#13;
&#13;
<p>On the surface, Duggan’s reasoning seems valid, but the scopes of the three clinical trials are not comparable, meaning direct comparisons of the experimental results are problematic. Moreover, the <a class="reference external" href="https://oreil.ly/25Pok">CDC</a> considers a 66% efficacy rate quite good, which is why it was given emergency approval.</p>&#13;
&#13;
<p>Let’s consider the points of scope and efficacy in turn.</p>&#13;
&#13;
<section data-pdf-bookmark="Scope" data-type="sect2"><div class="sect2" id="scope">&#13;
<h2>Scope</h2>&#13;
&#13;
<p>Recall<a contenteditable="false" data-primary="data scope" data-secondary="vaccine efficacy trial" data-type="indexterm" id="ix_data_scope_vacc_ran_trial"/> that when we evaluate the scope of the data, we consider the who, when, and where of the study. For the Johnson &amp; Johnson clinical trial, the participants:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Included adults age 18 and over, where roughly 40% had preexisting conditions associated with an increased risk for getting severe COVID-19</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Enrolled in the study from October to November 2020</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Came from eight countries across three continents, including the US and South Africa</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>The participants in the Moderna and Pfizer trials were primarily from the US, roughly 40% had preexisting conditions, and the trial took place earlier, over summer 2020. The timing and location of the trials make them difficult to compare. Cases of COVID-19 were at a low point in the summer in the US, but they rose rapidly in the late fall. Also, a variant of the virus that was more contagious was spreading rapidly in South Africa at the time of the J&amp;J trial.</p>&#13;
&#13;
<p>Each clinical trial was designed to test a vaccine against the situation of no vaccine under similar circumstances through the random assignment of subjects to treatment and control groups. While the scope from one trial to the next is quite different, the randomization within a trial keeps the scope of the treatment and control groups roughly the same. This enables meaningful comparisons between groups in the same trial. The scope was different enough across the three vaccine trials to make direct comparisons of the three trials problematic.</p>&#13;
&#13;
<p>In the trial carried out for the <a class="reference external" href="https://oreil.ly/epz0T">J&amp;J vaccine</a>, 43,738 people were enrolled. These participants were split into two groups at random. Half received the new vaccine, and the other half received a placebo, such as a saline solution. Then everyone was followed for 28 days to see whether they contracted COVID-19.</p>&#13;
&#13;
<p>A lot of information was recorded on each patient, such as their age, race, and sex, and in addition whether they caught COVID-19, including the severity of the disease. At the end of 28 days, the researchers found 468 cases of COVID-19, with 117 of these in the treatment group and 351 in the control group.</p>&#13;
&#13;
<p>The random assignment of patients to treatment and control gives the scientists a framework to assess the effectiveness of the vaccine. The typical reasoning goes as <span class="keep-together">follows</span>:</p>&#13;
&#13;
<ol>&#13;
	<li>&#13;
	<p>Begin with the assumption that the vaccine is ineffective.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>So the 468 who caught COVID-19 would have caught it whether or not they received the vaccine.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>And the remaining 43,270 people in the trial who did not get sick would have remained healthy whether or not they received the vaccine.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>The split of 117 sick people in treatment and 351 in control was solely due to the chance process in assigning participants to treatment or control.</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>We can set up an urn model that reflects this scenario and then study, via simulation, the behavior of the experimental results.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="The Urn Model for Random Assignment" data-type="sect2"><div class="sect2" id="the-urn-model-for-random-assignment">&#13;
<h2>The Urn Model for Random Assignment</h2>&#13;
&#13;
<p>Our urn has 43,738 marbles, one for each person in the clinical trial. Since there were 468 cases of COVID-19 among them, we label 468 marbles with a 1 and the remaining 43,270 with a 0. We draw half the marbles (21,869) from the urn to receive the treatment, and the remaining half receive the placebo. The key result of the experiment is simply the count of the number of marbles marked 1 that were randomly drawn from the urn.</p>&#13;
&#13;
<p>We can simulate this process to get a sense of how likely it would be under these assumptions to draw at most 117 marbles marked 1 from the urn. Since we draw half of the marbles from the urn, we would expect about half of the 468, or 234, to be drawn. The simulation study gives us a sense of the variation that might result from the random assignment process. That is, the simulation can give us an approximate chance that the trials would result in so few cases of the virus in the treatment group.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Several key assumptions enter into this urn model, such as the assumption that the vaccine is ineffective. It’s important to keep track of the reliance on these assumptions because our simulation study gives us an approximation of the rarity of an outcome like the one observed only under these key assumptions.</p>&#13;
</div>&#13;
&#13;
<p>As before, we can simulate<a contenteditable="false" data-primary="hypergeometric probability distribution" data-type="indexterm" id="id758"/><a contenteditable="false" data-primary="probability" data-secondary="hypergeometric distribution" data-type="indexterm" id="id759"/> the urn model using the hypergeometric probability distribution, rather than having to program the chance process from scratch:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">simulations_fast</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">hypergeometric</code></span><span><code class="p">(</code></span><span><code class="n">ngood</code></span><span><code class="o">=</code></span><span><code class="mi">468</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">nbad</code></span><span><code class="o">=</code></span><span><code class="mi">43270</code></span><span><code class="p">,</code></span><code> </code><code>&#13;
</code><code>                                            </code><span><code class="n">nsample</code></span><span><code class="o">=</code></span><span><code class="mi">21869</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="mi">500000</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_03in04.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>In our simulation, we repeated the process of random assignment to the treatment group 500,000 times. Indeed, we found that not one of the 500,000 simulations had 117 or fewer cases. It would be an extremely rare event to see so few cases of COVID-19 if in fact the vaccine was not effective.</p>&#13;
&#13;
<p>After the problems with comparing drug trials that have different scopes and the efficacy for preventing severe cases of COVID-19 was explained, Mayor Duggan retracted his original statement, saying, “I have full confidence that the Johnson &amp; Johnson vaccine is both safe and effective.”<sup><a data-type="noteref" href="ch03.html#id760" id="id760-marker">3</a></sup></p>&#13;
&#13;
<p class="pagebreak-before less_space">This example has shown that:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Using a chance process in the assignment of subjects to treatments in clinical trials can help us answer what-if scenarios.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Considering data scope can help us determine whether it is reasonable to compare figures from different datasets.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Simulating<a contenteditable="false" data-primary="chance mechanism" data-secondary="effectiveness from using" data-type="indexterm" id="id761"/> the draw of marbles from an urn is a useful abstraction for studying the possible outcomes from survey samples and controlled experiments. The simulation works because it imitates the chance mechanism used to select a sample or to assign people to a treatment. In settings where we measure natural phenomena, our measurements tend to follow a similar chance process. As described in <a class="reference internal" data-type="xref" href="ch02.html#ch-data-scope">Chapter 2</a>, instruments typically have an error associated with them, and we can use an urn to represent the variability in measuring an object.<a contenteditable="false" data-primary="" data-startref="ix_vacc_ran_trial" data-type="indexterm" id="id762"/><a contenteditable="false" data-primary="" data-startref="ix_data_scope_vacc_ran_trial" data-type="indexterm" id="id763"/><a contenteditable="false" data-primary="" data-startref="ix_sim_stud_vacc" data-type="indexterm" id="id764"/><a contenteditable="false" data-primary="" data-startref="ix_urn_mod_vacc" data-type="indexterm" id="id765"/><a contenteditable="false" data-primary="" data-startref="ix_ran_control_exp" data-type="indexterm" id="id766"/><a contenteditable="false" data-primary="" data-startref="ix_ran_select_data" data-type="indexterm" id="id767"/><a contenteditable="false" data-primary="" data-startref="ix_covid_vacc_eff" data-type="indexterm" id="id768"/><a contenteditable="false" data-primary="" data-startref="ix_lifecycle_data_sci_vacc" data-type="indexterm" id="id769"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Example: Measuring Air Quality" data-type="sect1"><div class="sect1" id="sec-theory-measurementerror">&#13;
<h1>Example: Measuring Air Quality</h1>&#13;
&#13;
<p>Across<a contenteditable="false" data-primary="lifecycle, data science" data-secondary="air quality measurement" data-type="indexterm" id="ix_lifecycle_data_sci_air"/><a contenteditable="false" data-primary="air quality sensors study" data-secondary="data science lifecycle" data-type="indexterm" id="ix_air_qual_lifecycle"/> the US, <a class="reference external" href="https://oreil.ly/t6JzZ">sensors to measure air pollution are widely used</a> by individuals, community groups, and state and local air monitoring agencies. For example, on two days in September 2020, approximately 600,000 Californians and 500,000 Oregonians viewed PurpleAir’s map as fire spread through their states and evacuations were planned. (<a class="reference external" href="https://www2.purpleair.com">PurpleAir</a> creates air quality maps from crowdsourced data that streams in from its sensors.)</p>&#13;
&#13;
<p>The sensors measure the amount of particulate matter in the air that has a diameter smaller than 2.5 micrometers (the unit of measurement is micrograms per cubic meter: μg/m<sup>3</sup>). The measurements recorded are the average concentrations over two minutes. While the level of particulate matter changes over the course of a day as, for example, people commute to and from work, there are certain times of the day, like at midnight, when we expect the two-minute averages to change little in a half hour. If we examine the measurements taken during these times of the day, we can get a sense of the combined variability in the instrument recordings and the mixing of particles in the air.</p>&#13;
&#13;
<p>Anyone can access sensor measurements from PurpleAir’s site. The site provides a download tool, and data are available for any sensor that appears on PurpleAir’s map. We downloaded data from one sensor over a 24-hour period and selected three half-hour time intervals spread throughout the day where the readings were roughly constant over the 30-minute period. This gave us three sets of 15 two-minute averages, for a total of 45 measurements:</p>&#13;
&#13;
<div class="cell tag_remove-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe pagebreak-before less_space">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>aq2.5</th>&#13;
			<th>time</th>&#13;
			<th>hour</th>&#13;
			<th>meds</th>&#13;
			<th>diff30</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>0</strong></td>&#13;
			<td>6.14</td>&#13;
			<td>2022-04-01 00:01:10 UTC</td>&#13;
			<td>0</td>&#13;
			<td>5.38</td>&#13;
			<td class="right">0.59</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1</strong></td>&#13;
			<td>5.00</td>&#13;
			<td>2022-04-01 00:03:10 UTC</td>&#13;
			<td>0</td>&#13;
			<td>5.38</td>&#13;
			<td class="right">-0.55</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2</strong></td>&#13;
			<td>5.29</td>&#13;
			<td>2022-04-01 00:05:10 UTC</td>&#13;
			<td>0</td>&#13;
			<td>5.38</td>&#13;
			<td class="right">-0.26</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>...</strong></td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>42</strong></td>&#13;
			<td>7.55</td>&#13;
			<td>2022-04-01 19:27:20 UTC</td>&#13;
			<td>19</td>&#13;
			<td>8.55</td>&#13;
			<td class="right">-1.29</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>43</strong></td>&#13;
			<td>9.47</td>&#13;
			<td>2022-04-01 19:29:20 UTC</td>&#13;
			<td>19</td>&#13;
			<td>8.55</td>&#13;
			<td class="right">0.63</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>44</strong></td>&#13;
			<td>8.55</td>&#13;
			<td>2022-04-01 19:31:20 UTC</td>&#13;
			<td>19</td>&#13;
			<td>8.55</td>&#13;
			<td class="right">-0.29</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<pre>45 rows × 5 columns</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Line plots can give us a sense of variation in the measurements. In one 30-minute period, we expect the measurements to be roughly the same, with the exception of minor variations from the particles moving in the air and the measurement error of the instrument:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_03in05.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The plot shows<a contenteditable="false" data-primary="data scope" data-secondary="air quality example" data-type="indexterm" id="id770"/> us how the air quality worsens throughout the day, but in each of these half-hour intervals, the air quality is roughly constant at 5.4, 6.6, and 8.6 μg/m<sup>3</sup> at midnight, 11 a.m., and 7 p.m., respectively. We can think of the data scope as follows: at this particular location in a specific half-hour time interval, there is an average particle concentration in the air surrounding the sensor. This concentration is our target, and our instrument, the sensor, takes many measurements that form a sample from the access frame. (See <a class="reference internal" data-type="xref" href="ch02.html#ch-data-scope">Chapter 2</a> for the dartboard analogy of this process.) If the instrument is working properly, the measurements are centered on the target: the 30-minute average.</p>&#13;
&#13;
<p>To get a better sense of the variation in a half-hour interval, we can examine the differences of the measurements from the median for the corresponding half hour. The distribution of these “errors” is as follows:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_03in06.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The histogram<a contenteditable="false" data-primary="standard deviation" data-type="indexterm" id="id771"/><a contenteditable="false" data-primary="relative standard error" data-type="indexterm" id="id772"/> shows us that the typical fluctuations in measurements are often less than 0.5 μg/m<sup>3</sup> and rarely greater than 1 μg/m<sup>3</sup>. With instruments, we often consider their <em>relative standard error</em>, which is the standard deviation as a percentage of the mean. The standard deviation of these 45 deviations is:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">std</code></span><span><code class="p">(</code></span><span><code class="n">pm</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">diff30</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
0.6870817156282193&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Given that the hourly measurements range from 5 to 9 μg/m<sup>3</sup>, the relative error is 8% to 12%, which is reasonably accurate.</p>&#13;
&#13;
<p>We can use the urn model<a contenteditable="false" data-primary="variation" data-secondary="air quality data" data-secondary-sortas="air quality data" data-type="indexterm" id="id773"/> to simulate the variability in this measurement process. We place in the urn the deviations of the measurements from their 30-minute medians for all 45 readings, and we simulate a 30-minute air quality sequence of measurements by drawing 15 times <em>with replacement</em> from the urn and adding the deviations drawn to a hypothetical 30-minute average:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">urn</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">pm</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">diff30</code><code class="s2">"</code></span><span><code class="p">]</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">seed</code></span><span><code class="p">(</code></span><span><code class="mi">221212</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">sample_err</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">choice</code></span><span><code class="p">(</code></span><span><code class="n">urn</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="mi">15</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">replace</code></span><span><code class="o">=</code></span><span><code class="kc">True</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">aq_imitate</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="mi">11</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="n">sample_err</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We can add a line plot for this artificial set of measurements to our earlier line plots, and compare it to the three real ones:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_03in07.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The shape of the line plot from the simulated data is similar to the others, which indicates that our model for the measurement process is reasonable. Unfortunately, what we don’t know is whether the measurements are close to the true air quality. To detect bias in the instrument, we need to make comparisons against a more accurate instrument or take measurements in a protected environment where the air has a known quantity of particulate matter. In fact, <a class="reference external" href="https://oreil.ly/Xkvh0">researchers</a> have found that low humidity can distort the readings so that they are too high. In <a class="reference internal" data-type="xref" href="ch12.html#ch-pa">Chapter 12</a>, we carry out a more comprehensive analysis of the PurpleAir sensor data and calibrate the instruments to improve their accuracy.<a contenteditable="false" data-primary="" data-startref="ix_air_qual_lifecycle" data-type="indexterm" id="id774"/><a contenteditable="false" data-primary="" data-startref="ix_lifecycle_data_sci_air" data-type="indexterm" id="id775"/></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="sec-theory-summary">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>In this chapter, we used the analogy of drawing marbles from an urn to model random sampling from populations and random assignment of subjects to treatments in experiments. This framework enables us to run simulation studies for hypothetical surveys, experiments, or other chance processes in order to study their behavior. We found the chance of observing particular results from a clinical trial under the assumption that the treatment was not effective, and we studied the support for Clinton and Trump with samples based on actual votes cast in the election. These simulation studies enabled us to quantify the typical deviations in the chance process and to approximate the distribution of summary statistics, like Trump’s lead over Clinton. These simulation studies revealed the sampling distribution of a statistic and helped us answer questions about the likelihood of observing results like ours under the urn model.</p>&#13;
&#13;
<p class="pagebreak-before less_space">The urn model reduces to a few basics: the number of marbles in the urn, what is written on each marble, the number of marbles to draw from the urn, and whether or not they are replaced between draws. From there, we can simulate increasingly <span class="keep-together">complex</span> data designs. However, the crux of the urn’s usefulness is the mapping from the data design to the urn. If samples are not randomly drawn, subjects are not randomly assigned to treatments, or measurements are not made on well-calibrated equipment, then this framework falls short in helping us understand our data and make decisions. On the other hand, we also need to remember that the urn is a simplification of the actual data collection process. If in reality there is bias in data collection, then the randomness we observe in the simulation doesn’t capture the complete picture. Too often, data scientists wave these annoyances aside and address only the variability described by the urn model. That was one of the main problems in the surveys predicting the outcome of the 2016 US presidential election.<a contenteditable="false" data-primary="" data-startref="ix_lifecycle_data_sci_sim" data-type="indexterm" id="id776"/></p>&#13;
&#13;
<p>In each of these examples, the summary statistics that we have studied were given to us as part of the example. In the next chapter, we address the question of how to choose a summary statistic to represent the data.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id743"><sup><a href="ch03.html#id743-marker">1</a></sup> Manfred te Grotenhuis et al., “Better Poll Sampling Would Have Cast More Doubt on the Potential for Hillary Clinton to Win the 2016 Election” <em>London School of Economics</em>, February 1, 2018.</p><p data-type="footnote" id="id752"><sup><a href="ch03.html#id752-marker">2</a></sup> Grotenhuis et al., “Better Poll Sampling Would Have Cast More Doubt on the Potential for Hillary Clinton to Win the 2016 Election.” </p><p data-type="footnote" id="id760"><sup><a href="ch03.html#id760-marker">3</a></sup> Unfortunately, despite the vaccine’s efficacy, the US Food and Drug Administration limited the use of the J&amp;J vaccine in May 2022 due to a heightened risk of developing rare and potentially life-threatening blood clots.</p></div></div></section></body></html>