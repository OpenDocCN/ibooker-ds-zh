<html><head></head><body><section data-pdf-bookmark="Chapter 9. Getting Data" data-type="chapter" epub:type="chapter"><div class="chapter" id="getting_data">&#13;
<h1><span class="label">Chapter 9. </span>Getting Data</h1>&#13;
&#13;
<blockquote data-type="epigraph" epub:type="epigraph">&#13;
    <p>To write it, it took three months; to conceive it, three minutes; to collect the data in it, all my life.</p>&#13;
    <p data-type="attribution">F. Scott Fitzgerald</p>&#13;
</blockquote>&#13;
&#13;
<p>In order to be a data scientist you need data.  In fact, as a data scientist you will spend an embarrassingly large fraction of your time acquiring, cleaning, and transforming data. In a pinch, you can always type the data in yourself (or if you have minions, make them do it), but usually this is not a good use of your time.  In this chapter, we’ll look at different ways of getting data into Python and into the right formats.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="stdin and stdout" data-type="sect1"><div class="sect1" id="idm45635751370392">&#13;
<h1>stdin and stdout</h1>&#13;
&#13;
<p>If<a data-primary="data" data-secondary="collecting" data-tertiary="piping data with stdin and stdout" data-type="indexterm" id="idm45635751368440"/><a data-primary="sys.stdin" data-type="indexterm" id="idm45635751367192"/><a data-primary="sys.stdout" data-type="indexterm" id="idm45635751366520"/> you run your Python scripts at the command line, you can <em>pipe</em> data through them using <code>sys.stdin</code> and <code>sys.stdout</code>.  For example, here is a script that reads in lines of text and spits back out the ones that match a regular expression:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="c1"># egrep.py</code>&#13;
<code class="kn">import</code> <code class="nn">sys</code><code class="o">,</code> <code class="nn">re</code>&#13;
&#13;
<code class="c1"># sys.argv is the list of command-line arguments</code>&#13;
<code class="c1"># sys.argv[0] is the name of the program itself</code>&#13;
<code class="c1"># sys.argv[1] will be the regex specified at the command line</code>&#13;
<code class="n">regex</code> <code class="o">=</code> <code class="n">sys</code><code class="o">.</code><code class="n">argv</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># for every line passed into the script</code>&#13;
<code class="k">for</code> <code class="n">line</code> <code class="ow">in</code> <code class="n">sys</code><code class="o">.</code><code class="n">stdin</code><code class="p">:</code>&#13;
    <code class="c1"># if it matches the regex, write it to stdout</code>&#13;
    <code class="k">if</code> <code class="n">re</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">regex</code><code class="p">,</code> <code class="n">line</code><code class="p">):</code>&#13;
        <code class="n">sys</code><code class="o">.</code><code class="n">stdout</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">line</code><code class="p">)</code></pre>&#13;
&#13;
<p>And here’s one that counts the lines it receives and then writes out the count:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="c1"># line_count.py</code>&#13;
<code class="kn">import</code> <code class="nn">sys</code>&#13;
&#13;
<code class="n">count</code> <code class="o">=</code> <code class="mi">0</code>&#13;
<code class="k">for</code> <code class="n">line</code> <code class="ow">in</code> <code class="n">sys</code><code class="o">.</code><code class="n">stdin</code><code class="p">:</code>&#13;
    <code class="n">count</code> <code class="o">+=</code> <code class="mi">1</code>&#13;
&#13;
<code class="c1"># print goes to sys.stdout</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">count</code><code class="p">)</code></pre>&#13;
&#13;
<p>You could then use these to count how many lines of a file contain numbers. In Windows, you’d use:</p>&#13;
&#13;
<pre data-code-language="dosbatch" data-type="programlisting">type SomeFile.txt <code class="p">|</code> <code class="n">python</code> egrep.py <code class="s2">"[0-9]"</code> <code class="p">|</code> <code class="n">python</code> line_count.py</pre>&#13;
&#13;
<p>whereas in a Unix system you’d use:</p>&#13;
&#13;
<pre data-code-language="shell-session" data-type="programlisting"><code class="go">cat SomeFile.txt | python egrep.py "[0-9]" | python line_count.py</code></pre>&#13;
&#13;
<p>The | is the pipe character, which means “use the output of the left command as the input of the right command.”  You can build pretty elaborate data-processing pipelines this way.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>If you are using Windows, you can probably leave out the <code>python</code> part of this command:</p>&#13;
<pre>type SomeFile.txt | egrep.py "[0-9]" | line_count.py</pre>&#13;
&#13;
<p>If you are on a Unix system, doing so requires <a href="https://stackoverflow.com/questions/15587877/run-a-python-script-in-terminal-without-the-python-command">a couple more steps</a>. First add a “shebang” as the first line of your script <code>#!/usr/bin/env python</code>. Then, at the command line, use <code>chmod </code>x<code> </code>egrep.py++ to make the file executable.</p>&#13;
</div>&#13;
&#13;
<p>Similarly, here’s a script that counts the words in its input and writes out the most common ones:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="c1"># most_common_words.py</code>&#13;
<code class="kn">import</code> <code class="nn">sys</code>&#13;
<code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">Counter</code>&#13;
&#13;
<code class="c1"># pass in number of words as first argument</code>&#13;
<code class="k">try</code><code class="p">:</code>&#13;
    <code class="n">num_words</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">sys</code><code class="o">.</code><code class="n">argv</code><code class="p">[</code><code class="mi">1</code><code class="p">])</code>&#13;
<code class="k">except</code><code class="p">:</code>&#13;
    <code class="k">print</code><code class="p">(</code><code class="s2">"usage: most_common_words.py num_words"</code><code class="p">)</code>&#13;
    <code class="n">sys</code><code class="o">.</code><code class="n">exit</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code>   <code class="c1"># nonzero exit code indicates error</code>&#13;
&#13;
<code class="n">counter</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">word</code><code class="o">.</code><code class="n">lower</code><code class="p">()</code>                      <code class="c1"># lowercase words</code>&#13;
                  <code class="k">for</code> <code class="n">line</code> <code class="ow">in</code> <code class="n">sys</code><code class="o">.</code><code class="n">stdin</code>&#13;
                  <code class="k">for</code> <code class="n">word</code> <code class="ow">in</code> <code class="n">line</code><code class="o">.</code><code class="n">strip</code><code class="p">()</code><code class="o">.</code><code class="n">split</code><code class="p">()</code>  <code class="c1"># split on spaces</code>&#13;
                  <code class="k">if</code> <code class="n">word</code><code class="p">)</code>                          <code class="c1"># skip empty 'words'</code>&#13;
&#13;
<code class="k">for</code> <code class="n">word</code><code class="p">,</code> <code class="n">count</code> <code class="ow">in</code> <code class="n">counter</code><code class="o">.</code><code class="n">most_common</code><code class="p">(</code><code class="n">num_words</code><code class="p">):</code>&#13;
    <code class="n">sys</code><code class="o">.</code><code class="n">stdout</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="nb">str</code><code class="p">(</code><code class="n">count</code><code class="p">))</code>&#13;
    <code class="n">sys</code><code class="o">.</code><code class="n">stdout</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="s2">"</code><code class="se">\t</code><code class="s2">"</code><code class="p">)</code>&#13;
    <code class="n">sys</code><code class="o">.</code><code class="n">stdout</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">word</code><code class="p">)</code>&#13;
    <code class="n">sys</code><code class="o">.</code><code class="n">stdout</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="s2">"</code><code class="se">\n</code><code class="s2">"</code><code class="p">)</code></pre>&#13;
&#13;
<p>after which you could do something like:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting"><code class="nv">$ </code>cat the_bible.txt <code class="p">|</code> python most_common_words.py 10&#13;
36397	the&#13;
30031	and&#13;
20163	of&#13;
7154	to&#13;
6484	in&#13;
5856	that&#13;
5421	he&#13;
5226	his&#13;
5060	unto&#13;
4297	shall</pre>&#13;
&#13;
<p>(If you are using Windows, then use <code>type</code> instead of <code>cat</code>.)</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>If you are a seasoned Unix programmer, you are probably familiar with a wide variety of command-line tools (for example, <code>egrep</code>) that are built into your operating system and are preferable to building your own from scratch. Still, it’s good to know you can if you need to.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Reading Files" data-type="sect1"><div class="sect1" id="idm45635751369768">&#13;
<h1>Reading Files</h1>&#13;
&#13;
<p>You<a data-primary="data" data-secondary="collecting" data-tertiary="reading files" data-type="indexterm" id="idm45635751006104"/> can also explicitly read from and write to files directly in your code.  Python makes working with files pretty simple.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Basics of Text Files" data-type="sect2"><div class="sect2" id="idm45635751004424">&#13;
<h2>The Basics of Text Files</h2>&#13;
&#13;
<p>The<a data-primary="files" data-secondary="basics of text files" data-type="indexterm" id="idm45635751002760"/><a data-primary="text files" data-type="indexterm" id="idm45635751000296"/> first step to working with a text file is to obtain a <em>file object</em> using <code>open</code>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="c1"># 'r' means read-only, it's assumed if you leave it out</code>&#13;
<code class="n">file_for_reading</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'reading_file.txt'</code><code class="p">,</code> <code class="s1">'r'</code><code class="p">)</code>&#13;
<code class="n">file_for_reading2</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'reading_file.txt'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># 'w' is write -- will destroy the file if it already exists!</code>&#13;
<code class="n">file_for_writing</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'writing_file.txt'</code><code class="p">,</code> <code class="s1">'w'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># 'a' is append -- for adding to the end of the file</code>&#13;
<code class="n">file_for_appending</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'appending_file.txt'</code><code class="p">,</code> <code class="s1">'a'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># don't forget to close your files when you're done</code>&#13;
<code class="n">file_for_writing</code><code class="o">.</code><code class="n">close</code><code class="p">()</code></pre>&#13;
&#13;
<p>Because it is easy to forget to close your files, you should always use them in a <code>with</code> block, at the end of which they will be closed automatically:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="n">filename</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>&#13;
    <code class="n">data</code> <code class="o">=</code> <code class="n">function_that_gets_data_from</code><code class="p">(</code><code class="n">f</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># at this point f has already been closed, so don't try to use it</code>&#13;
<code class="n">process</code><code class="p">(</code><code class="n">data</code><code class="p">)</code></pre>&#13;
&#13;
<p>If you need to read a whole text file,&#13;
you can just iterate over the lines of the file using <code>for</code>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">starts_with_hash</code> <code class="o">=</code> <code class="mi">0</code>&#13;
&#13;
<code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'input.txt'</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>&#13;
    <code class="k">for</code> <code class="n">line</code> <code class="ow">in</code> <code class="n">f</code><code class="p">:</code>                  <code class="c1"># look at each line in the file</code>&#13;
        <code class="k">if</code> <code class="n">re</code><code class="o">.</code><code class="n">match</code><code class="p">(</code><code class="s2">"^#"</code><code class="p">,</code><code class="n">line</code><code class="p">):</code>     <code class="c1"># use a regex to see if it starts with '#'</code>&#13;
            <code class="n">starts_with_hash</code> <code class="o">+=</code> <code class="mi">1</code>   <code class="c1"># if it does, add 1 to the count</code></pre>&#13;
&#13;
<p>Every line you get this way ends in a newline character, so you’ll often want to <code>strip</code> it before doing anything with it.</p>&#13;
&#13;
<p>For example, imagine you have a file full of email addresses, one per line, and you need to generate a histogram of the domains.  The rules for correctly extracting domains are somewhat subtle—see, e.g., the <a href="https://publicsuffix.org">Public Suffix List</a>—but a good first approximation is to just take the parts of the email addresses that come after the <em>@</em> (this gives the wrong answer for email addresses like <em>joel@mail.datasciencester.com</em>, but for the purposes of this example we’re willing to live with that):</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">get_domain</code><code class="p">(</code><code class="n">email_address</code><code class="p">:</code> <code class="nb">str</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">str</code><code class="p">:</code>&#13;
    <code class="sd">"""Split on '@' and return the last piece"""</code>&#13;
    <code class="k">return</code> <code class="n">email_address</code><code class="o">.</code><code class="n">lower</code><code class="p">()</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s2">"@"</code><code class="p">)[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># a couple of tests</code>&#13;
<code class="k">assert</code> <code class="n">get_domain</code><code class="p">(</code><code class="s1">'joelgrus@gmail.com'</code><code class="p">)</code> <code class="o">==</code> <code class="s1">'gmail.com'</code>&#13;
<code class="k">assert</code> <code class="n">get_domain</code><code class="p">(</code><code class="s1">'joel@m.datasciencester.com'</code><code class="p">)</code> <code class="o">==</code> <code class="s1">'m.datasciencester.com'</code>&#13;
&#13;
<code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">Counter</code>&#13;
&#13;
<code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'email_addresses.txt'</code><code class="p">,</code> <code class="s1">'r'</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>&#13;
    <code class="n">domain_counts</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">get_domain</code><code class="p">(</code><code class="n">line</code><code class="o">.</code><code class="n">strip</code><code class="p">())</code>&#13;
                            <code class="k">for</code> <code class="n">line</code> <code class="ow">in</code> <code class="n">f</code>&#13;
                            <code class="k">if</code> <code class="s2">"@"</code> <code class="ow">in</code> <code class="n">line</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Delimited Files" data-type="sect2"><div class="sect2" id="delimited_files">&#13;
<h2>Delimited Files</h2>&#13;
&#13;
<p>The<a data-primary="files" data-secondary="delimited files" data-type="indexterm" id="idm45635750706600"/><a data-primary="delimited files" data-type="indexterm" id="idm45635750705592"/><a data-primary="comma-separated files" data-type="indexterm" id="idm45635750704920"/><a data-primary="tab-separated files" data-type="indexterm" id="idm45635750704248"/> hypothetical email addresses file we just processed had one address per line.&#13;
More frequently you’ll work with files with lots of data on each line.&#13;
These files are very often either <em>comma-separated</em> or <em>tab-separated</em>: each line has several fields, with a comma or a tab indicating where one field ends and the next field starts.</p>&#13;
&#13;
<p>This starts to get complicated when you have fields with commas and tabs and newlines in them (which you inevitably will).  For this reason, you should never try to parse them yourself.&#13;
Instead, you should use<a data-primary="pandas" data-type="indexterm" id="idm45635750701640"/><a data-primary="Python" data-secondary="csv module" data-type="indexterm" id="idm45635750700936"/><a data-primary="csv module (Python)" data-type="indexterm" id="idm45635750699992"/> Python’s <code>csv</code> module (or the pandas library, or some other library&#13;
that’s designed to read comma-separated or tab-delimited files).</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Never parse a comma-separated file yourself. You will screw up the edge cases!</p>&#13;
</div>&#13;
&#13;
<p>If your file has no headers (which means you probably want each row as a <code>list</code>, and which places the burden on you to know what’s in each column), you can use <code>csv.reader</code> to iterate over the rows, each of which will be an appropriately split list.</p>&#13;
&#13;
<p>For example, if we had a tab-delimited file of stock prices:</p>&#13;
&#13;
<pre data-type="programlisting">6/20/2014   AAPL    90.91&#13;
6/20/2014   MSFT    41.68&#13;
6/20/2014   FB  64.5&#13;
6/19/2014   AAPL    91.86&#13;
6/19/2014   MSFT    41.51&#13;
6/19/2014   FB  64.34</pre>&#13;
&#13;
<p>we could process them with:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">csv</code>&#13;
&#13;
<code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'tab_delimited_stock_prices.txt'</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>&#13;
    <code class="n">tab_reader</code> <code class="o">=</code> <code class="n">csv</code><code class="o">.</code><code class="n">reader</code><code class="p">(</code><code class="n">f</code><code class="p">,</code> <code class="n">delimiter</code><code class="o">=</code><code class="s1">'</code><code class="se">\t</code><code class="s1">'</code><code class="p">)</code>&#13;
    <code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">tab_reader</code><code class="p">:</code>&#13;
        <code class="n">date</code> <code class="o">=</code> <code class="n">row</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>&#13;
        <code class="n">symbol</code> <code class="o">=</code> <code class="n">row</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code>&#13;
        <code class="n">closing_price</code> <code class="o">=</code> <code class="nb">float</code><code class="p">(</code><code class="n">row</code><code class="p">[</code><code class="mi">2</code><code class="p">])</code>&#13;
        <code class="n">process</code><code class="p">(</code><code class="n">date</code><code class="p">,</code> <code class="n">symbol</code><code class="p">,</code> <code class="n">closing_price</code><code class="p">)</code></pre>&#13;
&#13;
<p>If your file has headers:</p>&#13;
&#13;
<pre data-type="programlisting">date:symbol:closing_price&#13;
6/20/2014:AAPL:90.91&#13;
6/20/2014:MSFT:41.68&#13;
6/20/2014:FB:64.5</pre>&#13;
&#13;
<p>you can either skip the header row with an initial call to <code>reader.next</code>, or get each row as a <code>dict</code> (with the headers as keys) by using <code>csv.DictReader</code>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'colon_delimited_stock_prices.txt'</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>&#13;
    <code class="n">colon_reader</code> <code class="o">=</code> <code class="n">csv</code><code class="o">.</code><code class="n">DictReader</code><code class="p">(</code><code class="n">f</code><code class="p">,</code> <code class="n">delimiter</code><code class="o">=</code><code class="s1">':'</code><code class="p">)</code>&#13;
    <code class="k">for</code> <code class="n">dict_row</code> <code class="ow">in</code> <code class="n">colon_reader</code><code class="p">:</code>&#13;
        <code class="n">date</code> <code class="o">=</code> <code class="n">dict_row</code><code class="p">[</code><code class="s2">"date"</code><code class="p">]</code>&#13;
        <code class="n">symbol</code> <code class="o">=</code> <code class="n">dict_row</code><code class="p">[</code><code class="s2">"symbol"</code><code class="p">]</code>&#13;
        <code class="n">closing_price</code> <code class="o">=</code> <code class="nb">float</code><code class="p">(</code><code class="n">dict_row</code><code class="p">[</code><code class="s2">"closing_price"</code><code class="p">])</code>&#13;
        <code class="n">process</code><code class="p">(</code><code class="n">date</code><code class="p">,</code> <code class="n">symbol</code><code class="p">,</code> <code class="n">closing_price</code><code class="p">)</code></pre>&#13;
&#13;
<p>Even if your file doesn’t have headers, you can still use <code>DictReader</code> by passing it the keys as a <code>fieldnames</code> parameter.</p>&#13;
&#13;
<p>You can similarly write out delimited data using <code>csv.writer</code>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">todays_prices</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'AAPL'</code><code class="p">:</code> <code class="mf">90.91</code><code class="p">,</code> <code class="s1">'MSFT'</code><code class="p">:</code> <code class="mf">41.68</code><code class="p">,</code> <code class="s1">'FB'</code><code class="p">:</code> <code class="mf">64.5</code> <code class="p">}</code>&#13;
&#13;
<code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'comma_delimited_stock_prices.txt'</code><code class="p">,</code> <code class="s1">'w'</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>&#13;
    <code class="n">csv_writer</code> <code class="o">=</code> <code class="n">csv</code><code class="o">.</code><code class="n">writer</code><code class="p">(</code><code class="n">f</code><code class="p">,</code> <code class="n">delimiter</code><code class="o">=</code><code class="s1">','</code><code class="p">)</code>&#13;
    <code class="k">for</code> <code class="n">stock</code><code class="p">,</code> <code class="n">price</code> <code class="ow">in</code> <code class="n">todays_prices</code><code class="o">.</code><code class="n">items</code><code class="p">():</code>&#13;
        <code class="n">csv_writer</code><code class="o">.</code><code class="n">writerow</code><code class="p">([</code><code class="n">stock</code><code class="p">,</code> <code class="n">price</code><code class="p">])</code></pre>&#13;
&#13;
<p><code>csv.writer</code> will do the right thing if your fields themselves have commas in them. Your own hand-rolled writer probably won’t.  For example, if you attempt:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">results</code> <code class="o">=</code> <code class="p">[[</code><code class="s2">"test1"</code><code class="p">,</code> <code class="s2">"success"</code><code class="p">,</code> <code class="s2">"Monday"</code><code class="p">],</code>&#13;
           <code class="p">[</code><code class="s2">"test2"</code><code class="p">,</code> <code class="s2">"success, kind of"</code><code class="p">,</code> <code class="s2">"Tuesday"</code><code class="p">],</code>&#13;
           <code class="p">[</code><code class="s2">"test3"</code><code class="p">,</code> <code class="s2">"failure, kind of"</code><code class="p">,</code> <code class="s2">"Wednesday"</code><code class="p">],</code>&#13;
           <code class="p">[</code><code class="s2">"test4"</code><code class="p">,</code> <code class="s2">"failure, utter"</code><code class="p">,</code> <code class="s2">"Thursday"</code><code class="p">]]</code>&#13;
&#13;
<code class="c1"># don't do this!</code>&#13;
<code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'bad_csv.txt'</code><code class="p">,</code> <code class="s1">'w'</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>&#13;
    <code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">results</code><code class="p">:</code>&#13;
        <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="s2">","</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="nb">map</code><code class="p">(</code><code class="nb">str</code><code class="p">,</code> <code class="n">row</code><code class="p">)))</code> <code class="c1"># might have too many commas in it!</code>&#13;
        <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="s2">"</code><code class="se">\n</code><code class="s2">"</code><code class="p">)</code>                    <code class="c1"># row might have newlines as well!</code></pre>&#13;
&#13;
<p>You will end up with a <em>.csv</em> file that looks like this:</p>&#13;
&#13;
<pre data-type="programlisting">test1,success,Monday&#13;
test2,success, kind of,Tuesday&#13;
test3,failure, kind of,Wednesday&#13;
test4,failure, utter,Thursday</pre>&#13;
&#13;
<p>and that no one will ever be able to make sense of.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Scraping the Web" data-type="sect1"><div class="sect1" id="idm45635750707000">&#13;
<h1>Scraping the Web</h1>&#13;
&#13;
<p>Another<a data-primary="data" data-secondary="collecting" data-tertiary="web scraping" data-type="indexterm" id="idm45635750294760"/> way to get data is by scraping it from web pages.  Fetching web pages, it turns out, is pretty easy; getting meaningful structured information out of them less so.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="HTML and the Parsing Thereof" data-type="sect2"><div class="sect2" id="idm45635750293048">&#13;
<h2>HTML and the Parsing Thereof</h2>&#13;
&#13;
<p>Pages<a data-primary="web scraping" data-secondary="HTML parsing" data-type="indexterm" id="idm45635750291016"/><a data-primary="HTML parsing" data-type="indexterm" id="idm45635750290008"/> on the web are written in HTML, in which text is (ideally) marked up into elements and their attributes:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting"><code class="nt">&lt;html&gt;</code>&#13;
  <code class="nt">&lt;head&gt;</code>&#13;
    <code class="nt">&lt;title&gt;</code>A web page<code class="nt">&lt;/title&gt;</code>&#13;
  <code class="nt">&lt;/head&gt;</code>&#13;
  <code class="nt">&lt;body&gt;</code>&#13;
    <code class="nt">&lt;p</code> <code class="na">id=</code><code class="s">"author"</code><code class="nt">&gt;</code>Joel Grus<code class="nt">&lt;/p&gt;</code>&#13;
    <code class="nt">&lt;p</code> <code class="na">id=</code><code class="s">"subject"</code><code class="nt">&gt;</code>Data Science<code class="nt">&lt;/p&gt;</code>&#13;
  <code class="nt">&lt;/body&gt;</code>&#13;
<code class="nt">&lt;/html&gt;</code></pre>&#13;
&#13;
<p>In a perfect world, where all web pages were marked up semantically for our benefit, we would be able to extract data using rules like&#13;
“find the <code>&lt;p&gt;</code> element whose <code>id</code> is <code>subject</code> and return the text it contains.” In the actual world, HTML is not generally well formed, let alone annotated. This means we’ll need help making sense of it.</p>&#13;
&#13;
<p>To<a data-primary="Beautiful Soup library" data-type="indexterm" id="idm45635750277960"/> get data out of HTML, we will use the <a href="http://www.crummy.com/software/BeautifulSoup/">Beautiful Soup library</a>, which builds a tree out of the various elements on a web page and provides a simple interface for accessing them.  As I write this, the latest version is Beautiful Soup 4.6.0, which is what we’ll be using.  We’ll<a data-primary="requests library" data-type="indexterm" id="idm45635751188552"/> also be using the <a href="http://docs.python-requests.org/en/latest/">Requests library</a>, which is a much nicer way of making HTTP requests than anything that’s built into Python.</p>&#13;
&#13;
<p>Python’s built-in HTML parser is not that lenient, which means that it doesn’t always cope well with HTML that’s not perfectly formed.  For that reason, we’ll also install the <code>html5lib</code> parser.</p>&#13;
&#13;
<p>Making sure you’re in the correct virtual environment, install the libraries:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">python -m pip install beautifulsoup4 requests html5lib</pre>&#13;
&#13;
<p>To use Beautiful Soup, we pass a string containing HTML into the <code>BeautifulSoup</code> function. In our examples, this will be the result of a call to <code>requests.get</code>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
<code class="kn">import</code> <code class="nn">requests</code>&#13;
&#13;
<code class="c1"># I put the relevant HTML file on GitHub. In order to fit</code>&#13;
<code class="c1"># the URL in the book I had to split it across two lines.</code>&#13;
<code class="c1"># Recall that whitespace-separated strings get concatenated.</code>&#13;
<code class="n">url</code> <code class="o">=</code> <code class="p">(</code><code class="s2">"https://raw.githubusercontent.com/"</code>&#13;
       <code class="s2">"joelgrus/data/master/getting-data.html"</code><code class="p">)</code>&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">url</code><code class="p">)</code><code class="o">.</code><code class="n">text</code>&#13;
<code class="n">soup</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html5lib'</code><code class="p">)</code></pre>&#13;
&#13;
<p>after which we can get pretty far using a few simple methods.</p>&#13;
&#13;
<p>We’ll typically work with <code>Tag</code> objects, which correspond to the tags representing the structure of an HTML page.</p>&#13;
&#13;
<p>For example, to find the first <code>&lt;p&gt;</code> tag (and its contents), you can use:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">first_paragraph</code> <code class="o">=</code> <code class="n">soup</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'p'</code><code class="p">)</code>        <code class="c1"># or just soup.p</code></pre>&#13;
&#13;
<p>You can get the text contents of a <code>Tag</code> using its <code>text</code> property:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">first_paragraph_text</code> <code class="o">=</code> <code class="n">soup</code><code class="o">.</code><code class="n">p</code><code class="o">.</code><code class="n">text</code>&#13;
<code class="n">first_paragraph_words</code> <code class="o">=</code> <code class="n">soup</code><code class="o">.</code><code class="n">p</code><code class="o">.</code><code class="n">text</code><code class="o">.</code><code class="n">split</code><code class="p">()</code></pre>&#13;
&#13;
<p>And you can extract a tag’s attributes by treating it like a <code>dict</code>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">first_paragraph_id</code> <code class="o">=</code> <code class="n">soup</code><code class="o">.</code><code class="n">p</code><code class="p">[</code><code class="s1">'id'</code><code class="p">]</code>       <code class="c1"># raises KeyError if no 'id'</code>&#13;
<code class="n">first_paragraph_id2</code> <code class="o">=</code> <code class="n">soup</code><code class="o">.</code><code class="n">p</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'id'</code><code class="p">)</code>  <code class="c1"># returns None if no 'id'</code></pre>&#13;
&#13;
<p>You can get multiple tags at once as follows:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">all_paragraphs</code> <code class="o">=</code> <code class="n">soup</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'p'</code><code class="p">)</code>  <code class="c1"># or just soup('p')</code>&#13;
<code class="n">paragraphs_with_ids</code> <code class="o">=</code> <code class="p">[</code><code class="n">p</code> <code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">soup</code><code class="p">(</code><code class="s1">'p'</code><code class="p">)</code> <code class="k">if</code> <code class="n">p</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'id'</code><code class="p">)]</code></pre>&#13;
&#13;
<p>Frequently, you’ll want to find tags with a specific <code>class</code>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">important_paragraphs</code> <code class="o">=</code> <code class="n">soup</code><code class="p">(</code><code class="s1">'p'</code><code class="p">,</code> <code class="p">{</code><code class="s1">'class'</code> <code class="p">:</code> <code class="s1">'important'</code><code class="p">})</code>&#13;
<code class="n">important_paragraphs2</code> <code class="o">=</code> <code class="n">soup</code><code class="p">(</code><code class="s1">'p'</code><code class="p">,</code> <code class="s1">'important'</code><code class="p">)</code>&#13;
<code class="n">important_paragraphs3</code> <code class="o">=</code> <code class="p">[</code><code class="n">p</code> <code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">soup</code><code class="p">(</code><code class="s1">'p'</code><code class="p">)</code>&#13;
                         <code class="k">if</code> <code class="s1">'important'</code> <code class="ow">in</code> <code class="n">p</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'class'</code><code class="p">,</code> <code class="p">[])]</code></pre>&#13;
&#13;
<p>And you can combine these methods to implement more elaborate logic.  For example, if you want to find every <code>&lt;span&gt;</code> element that is contained&#13;
inside a <code>&lt;div&gt;</code> element, you could do this:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="c1"># Warning: will return the same &lt;span&gt; multiple times</code>&#13;
<code class="c1"># if it sits inside multiple &lt;div&gt;s.</code>&#13;
<code class="c1"># Be more clever if that's the case.</code>&#13;
<code class="n">spans_inside_divs</code> <code class="o">=</code> <code class="p">[</code><code class="n">span</code>&#13;
                     <code class="k">for</code> <code class="n">div</code> <code class="ow">in</code> <code class="n">soup</code><code class="p">(</code><code class="s1">'div'</code><code class="p">)</code>     <code class="c1"># for each &lt;div&gt; on the page</code>&#13;
                     <code class="k">for</code> <code class="n">span</code> <code class="ow">in</code> <code class="n">div</code><code class="p">(</code><code class="s1">'span'</code><code class="p">)]</code>   <code class="c1"># find each &lt;span&gt; inside it</code></pre>&#13;
&#13;
<p>Just this handful of features will allow us to do quite a lot. If you end up needing to do more complicated things (or if you’re just curious), check the <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">documentation</a>.</p>&#13;
&#13;
<p>Of course, the important data won’t typically be labeled as <code>class="important"</code>. You’ll need to carefully inspect the source HTML, reason through your selection logic, and worry about edge cases to make sure your data is correct. Let’s look at an example.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Example: Keeping Tabs on Congress" data-type="sect2"><div class="sect2" id="idm45635750292136">&#13;
<h2>Example: Keeping Tabs on Congress</h2>&#13;
&#13;
<p>The<a data-primary="web scraping" data-secondary="press release data example" data-type="indexterm" id="idm45635749757976"/> VP of Policy at DataSciencester is worried about potential&#13;
regulation of the data science industry and asks you to quantify what Congress&#13;
is saying on the topic. In particular, he wants you to find all&#13;
the representatives who have press releases about “data.”</p>&#13;
&#13;
<p>At the time of publication, there is a page with links to all of the representatives’ websites at <em><a href="https://www.house.gov/representatives"><em class="hyperlink">https://www.house.gov/representatives</em></a></em>.</p>&#13;
&#13;
<p>And if you “view source,” all of the links to the websites look like:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting"><code class="nt">&lt;td&gt;</code>&#13;
  <code class="nt">&lt;a</code> <code class="na">href=</code><code class="s">"https://jayapal.house.gov"</code><code class="nt">&gt;</code>Jayapal, Pramila<code class="nt">&lt;/a&gt;</code>&#13;
<code class="nt">&lt;/td&gt;</code></pre>&#13;
&#13;
<p>Let’s start by collecting all of the URLs linked to from that page:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
<code class="kn">import</code> <code class="nn">requests</code>&#13;
&#13;
<code class="n">url</code> <code class="o">=</code> <code class="s2">"https://www.house.gov/representatives"</code>&#13;
<code class="n">text</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">url</code><code class="p">)</code><code class="o">.</code><code class="n">text</code>&#13;
<code class="n">soup</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">text</code><code class="p">,</code> <code class="s2">"html5lib"</code><code class="p">)</code>&#13;
&#13;
<code class="n">all_urls</code> <code class="o">=</code> <code class="p">[</code><code class="n">a</code><code class="p">[</code><code class="s1">'href'</code><code class="p">]</code>&#13;
            <code class="k">for</code> <code class="n">a</code> <code class="ow">in</code> <code class="n">soup</code><code class="p">(</code><code class="s1">'a'</code><code class="p">)</code>&#13;
            <code class="k">if</code> <code class="n">a</code><code class="o">.</code><code class="n">has_attr</code><code class="p">(</code><code class="s1">'href'</code><code class="p">)]</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">all_urls</code><code class="p">))</code>  <code class="c1"># 965 for me, way too many</code></pre>&#13;
&#13;
<p>This returns way too many URLs.&#13;
If you look at them, the ones we want start with either <em>http://</em> or <em>https://</em>, have some kind of name, and end with either <em>.house.gov</em> or <em>.house.gov/</em>.</p>&#13;
&#13;
<p>This is a good place to use a regular expression:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">re</code>&#13;
&#13;
<code class="c1"># Must start with http:// or https://</code>&#13;
<code class="c1"># Must end with .house.gov or .house.gov/</code>&#13;
<code class="n">regex</code> <code class="o">=</code> <code class="s-Affix">r</code><code class="s2">"^https?://.*\.house\.gov/?$"</code>&#13;
&#13;
<code class="c1"># Let's write some tests!</code>&#13;
<code class="k">assert</code> <code class="n">re</code><code class="o">.</code><code class="n">match</code><code class="p">(</code><code class="n">regex</code><code class="p">,</code> <code class="s2">"http://joel.house.gov"</code><code class="p">)</code>&#13;
<code class="k">assert</code> <code class="n">re</code><code class="o">.</code><code class="n">match</code><code class="p">(</code><code class="n">regex</code><code class="p">,</code> <code class="s2">"https://joel.house.gov"</code><code class="p">)</code>&#13;
<code class="k">assert</code> <code class="n">re</code><code class="o">.</code><code class="n">match</code><code class="p">(</code><code class="n">regex</code><code class="p">,</code> <code class="s2">"http://joel.house.gov/"</code><code class="p">)</code>&#13;
<code class="k">assert</code> <code class="n">re</code><code class="o">.</code><code class="n">match</code><code class="p">(</code><code class="n">regex</code><code class="p">,</code> <code class="s2">"https://joel.house.gov/"</code><code class="p">)</code>&#13;
<code class="k">assert</code> <code class="ow">not</code> <code class="n">re</code><code class="o">.</code><code class="n">match</code><code class="p">(</code><code class="n">regex</code><code class="p">,</code> <code class="s2">"joel.house.gov"</code><code class="p">)</code>&#13;
<code class="k">assert</code> <code class="ow">not</code> <code class="n">re</code><code class="o">.</code><code class="n">match</code><code class="p">(</code><code class="n">regex</code><code class="p">,</code> <code class="s2">"http://joel.house.com"</code><code class="p">)</code>&#13;
<code class="k">assert</code> <code class="ow">not</code> <code class="n">re</code><code class="o">.</code><code class="n">match</code><code class="p">(</code><code class="n">regex</code><code class="p">,</code> <code class="s2">"https://joel.house.gov/biography"</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># And now apply</code>&#13;
<code class="n">good_urls</code> <code class="o">=</code> <code class="p">[</code><code class="n">url</code> <code class="k">for</code> <code class="n">url</code> <code class="ow">in</code> <code class="n">all_urls</code> <code class="k">if</code> <code class="n">re</code><code class="o">.</code><code class="n">match</code><code class="p">(</code><code class="n">regex</code><code class="p">,</code> <code class="n">url</code><code class="p">)]</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">good_urls</code><code class="p">))</code>  <code class="c1"># still 862 for me</code></pre>&#13;
&#13;
<p>That’s still way too many, as there are only 435 representatives.&#13;
If you look at the list, there are a lot of duplicates.&#13;
Let’s use <code>set</code> to get rid of them:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">good_urls</code> <code class="o">=</code> <code class="nb">list</code><code class="p">(</code><code class="nb">set</code><code class="p">(</code><code class="n">good_urls</code><code class="p">))</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">good_urls</code><code class="p">))</code>  <code class="c1"># only 431 for me</code></pre>&#13;
&#13;
<p>There are always a couple of House seats empty, or maybe there’s a representative without a website. In any case, this is good enough.&#13;
When we look at the sites, most of them have a link to press releases. For example:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">html</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'https://jayapal.house.gov'</code><code class="p">)</code><code class="o">.</code><code class="n">text</code>&#13;
<code class="n">soup</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html5lib'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Use a set because the links might appear multiple times.</code>&#13;
<code class="n">links</code> <code class="o">=</code> <code class="p">{</code><code class="n">a</code><code class="p">[</code><code class="s1">'href'</code><code class="p">]</code> <code class="k">for</code> <code class="n">a</code> <code class="ow">in</code> <code class="n">soup</code><code class="p">(</code><code class="s1">'a'</code><code class="p">)</code> <code class="k">if</code> <code class="s1">'press releases'</code> <code class="ow">in</code> <code class="n">a</code><code class="o">.</code><code class="n">text</code><code class="o">.</code><code class="n">lower</code><code class="p">()}</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="n">links</code><code class="p">)</code> <code class="c1"># {'/media/press-releases'}</code></pre>&#13;
&#13;
<p>Notice that this is a relative link, which means we need to remember the originating site.&#13;
Let’s do some scraping:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">Dict</code><code class="p">,</code> <code class="n">Set</code>&#13;
&#13;
<code class="n">press_releases</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">Set</code><code class="p">[</code><code class="nb">str</code><code class="p">]]</code> <code class="o">=</code> <code class="p">{}</code>&#13;
&#13;
<code class="k">for</code> <code class="n">house_url</code> <code class="ow">in</code> <code class="n">good_urls</code><code class="p">:</code>&#13;
    <code class="n">html</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">house_url</code><code class="p">)</code><code class="o">.</code><code class="n">text</code>&#13;
    <code class="n">soup</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html5lib'</code><code class="p">)</code>&#13;
    <code class="n">pr_links</code> <code class="o">=</code> <code class="p">{</code><code class="n">a</code><code class="p">[</code><code class="s1">'href'</code><code class="p">]</code> <code class="k">for</code> <code class="n">a</code> <code class="ow">in</code> <code class="n">soup</code><code class="p">(</code><code class="s1">'a'</code><code class="p">)</code> <code class="k">if</code> <code class="s1">'press releases'</code>&#13;
                                             <code class="ow">in</code> <code class="n">a</code><code class="o">.</code><code class="n">text</code><code class="o">.</code><code class="n">lower</code><code class="p">()}</code>&#13;
    <code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s2">"{house_url}: {pr_links}"</code><code class="p">)</code>&#13;
    <code class="n">press_releases</code><code class="p">[</code><code class="n">house_url</code><code class="p">]</code> <code class="o">=</code> <code class="n">pr_links</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Normally<a data-primary="robots.txt files" data-type="indexterm" id="idm45635749363416"/> it is impolite to scrape a site freely like this.&#13;
Most sites will have a <em>robots.txt</em> file that indicates how frequently&#13;
you may scrape the site (and which paths you’re not supposed to scrape),&#13;
but since it’s Congress we don’t need to be particularly polite.</p>&#13;
</div>&#13;
&#13;
<p>If you watch these as they scroll by, you’ll see a lot of <em>/media/press-releases</em> and <em>media-center/press-releases</em>, as well as various other addresses. One of these URLs is <em><a href="https://jayapal.house.gov/media/press-releases"><em class="hyperlink">https://jayapal.house.gov/media/press-releases</em></a></em>.</p>&#13;
&#13;
<p>Remember that our goal is to find out which congresspeople have press releases&#13;
mentioning “data.” We’ll write a slightly more general function that checks&#13;
whether a page of press releases mentions any given term.</p>&#13;
&#13;
<p>If you visit the site and view the source, it seems like there’s a snippet from each press release&#13;
inside a <code>&lt;p&gt;</code> tag, so we’ll use that as our first attempt:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">paragraph_mentions</code><code class="p">(</code><code class="n">text</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="n">keyword</code><code class="p">:</code> <code class="nb">str</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">bool</code><code class="p">:</code>&#13;
    <code class="sd">"""</code>&#13;
<code class="sd">    Returns True if a &lt;p&gt; inside the text mentions {keyword}</code>&#13;
<code class="sd">    """</code>&#13;
    <code class="n">soup</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">text</code><code class="p">,</code> <code class="s1">'html5lib'</code><code class="p">)</code>&#13;
    <code class="n">paragraphs</code> <code class="o">=</code> <code class="p">[</code><code class="n">p</code><code class="o">.</code><code class="n">get_text</code><code class="p">()</code> <code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">soup</code><code class="p">(</code><code class="s1">'p'</code><code class="p">)]</code>&#13;
&#13;
    <code class="k">return</code> <code class="nb">any</code><code class="p">(</code><code class="n">keyword</code><code class="o">.</code><code class="n">lower</code><code class="p">()</code> <code class="ow">in</code> <code class="n">paragraph</code><code class="o">.</code><code class="n">lower</code><code class="p">()</code>&#13;
               <code class="k">for</code> <code class="n">paragraph</code> <code class="ow">in</code> <code class="n">paragraphs</code><code class="p">)</code></pre>&#13;
&#13;
<p>Let’s write a quick test for it:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">text</code> <code class="o">=</code> <code class="s2">"""&lt;body&gt;&lt;h1&gt;Facebook&lt;/h1&gt;&lt;p&gt;Twitter&lt;/p&gt;"""</code>&#13;
<code class="k">assert</code> <code class="n">paragraph_mentions</code><code class="p">(</code><code class="n">text</code><code class="p">,</code> <code class="s2">"twitter"</code><code class="p">)</code>       <code class="c1"># is inside a &lt;p&gt;</code>&#13;
<code class="k">assert</code> <code class="ow">not</code> <code class="n">paragraph_mentions</code><code class="p">(</code><code class="n">text</code><code class="p">,</code> <code class="s2">"facebook"</code><code class="p">)</code>  <code class="c1"># not inside a &lt;p&gt;</code></pre>&#13;
&#13;
<p>At last we’re ready to find the relevant congresspeople&#13;
and give their names to the VP:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">for</code> <code class="n">house_url</code><code class="p">,</code> <code class="n">pr_links</code> <code class="ow">in</code> <code class="n">press_releases</code><code class="o">.</code><code class="n">items</code><code class="p">():</code>&#13;
    <code class="k">for</code> <code class="n">pr_link</code> <code class="ow">in</code> <code class="n">pr_links</code><code class="p">:</code>&#13;
        <code class="n">url</code> <code class="o">=</code> <code class="n">f</code><code class="s2">"{house_url}/{pr_link}"</code>&#13;
        <code class="n">text</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">url</code><code class="p">)</code><code class="o">.</code><code class="n">text</code>&#13;
&#13;
        <code class="k">if</code> <code class="n">paragraph_mentions</code><code class="p">(</code><code class="n">text</code><code class="p">,</code> <code class="s1">'data'</code><code class="p">):</code>&#13;
            <code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s2">"{house_url}"</code><code class="p">)</code>&#13;
            <code class="k">break</code>  <code class="c1"># done with this house_url</code></pre>&#13;
&#13;
<p>When I run this I get a list of about 20 representatives.&#13;
Your results will probably be different.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>If you look at the various “press releases” pages,&#13;
most of them are paginated with only 5 or 10 press releases per page.&#13;
This means that we only retrieved the few most recent press releases&#13;
for each congressperson. A more thorough solution would have iterated&#13;
over the pages and retrieved the full text of each press release.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Using APIs" data-type="sect1"><div class="sect1" id="idm45635749758664">&#13;
<h1>Using APIs</h1>&#13;
&#13;
<p>Many<a data-primary="web scraping" data-secondary="using APIs" data-type="indexterm" id="idm45635749046584"/> websites and web services provide <em>application programming interfaces</em> (APIs), which allow you to explicitly request data in a structured format. This saves you the trouble of having to scrape them!</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="JSON and XML" data-type="sect2"><div class="sect2" id="idm45635749044792">&#13;
<h2>JSON and XML</h2>&#13;
&#13;
<p>Because<a data-primary="serialization" data-type="indexterm" id="idm45635749043032"/><a data-primary="files" data-secondary="serialization of text files" data-type="indexterm" id="idm45635749042296"/><a data-primary="text files" data-type="indexterm" id="idm45635749041384"/> HTTP is a protocol for transferring <em>text</em>, the data you request through a web API needs to be <em>serialized</em> into a<a data-primary="strings" data-type="indexterm" id="idm45635749039784"/> string format.  Often<a data-primary="JavaScript Object Notation (JSON)" data-type="indexterm" id="idm45635749038920"/> this serialization uses <em>JavaScript Object Notation</em> (JSON).  JavaScript objects look quite similar to Python <code>dict</code>s, which makes their string representations easy to interpret:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="p">{</code> <code class="s2">"title"</code> <code class="p">:</code> <code class="s2">"Data Science Book"</code><code class="p">,</code>&#13;
  <code class="s2">"author"</code> <code class="p">:</code> <code class="s2">"Joel Grus"</code><code class="p">,</code>&#13;
  <code class="s2">"publicationYear"</code> <code class="p">:</code> <code class="mi">2019</code><code class="p">,</code>&#13;
  <code class="s2">"topics"</code> <code class="p">:</code> <code class="p">[</code> <code class="s2">"data"</code><code class="p">,</code> <code class="s2">"science"</code><code class="p">,</code> <code class="s2">"data science"</code><code class="p">]</code> <code class="p">}</code></pre>&#13;
&#13;
<p>We<a data-primary="Python" data-secondary="json module" data-type="indexterm" id="idm45635749018696"/> can parse JSON using Python’s <code>json</code> module.  In particular, we will use its <code>loads</code> function, which deserializes a string representing a JSON object into a Python object:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">json</code>&#13;
<code class="n">serialized</code> <code class="o">=</code> <code class="s2">"""{ "title" : "Data Science Book",</code>&#13;
<code class="s2">                  "author" : "Joel Grus",</code>&#13;
<code class="s2">                  "publicationYear" : 2019,</code>&#13;
<code class="s2">                  "topics" : [ "data", "science", "data science"] }"""</code>&#13;
&#13;
<code class="c1"># parse the JSON to create a Python dict</code>&#13;
<code class="n">deserialized</code> <code class="o">=</code> <code class="n">json</code><code class="o">.</code><code class="n">loads</code><code class="p">(</code><code class="n">serialized</code><code class="p">)</code>&#13;
<code class="k">assert</code> <code class="n">deserialized</code><code class="p">[</code><code class="s2">"publicationYear"</code><code class="p">]</code> <code class="o">==</code> <code class="mi">2019</code>&#13;
<code class="k">assert</code> <code class="s2">"data science"</code> <code class="ow">in</code> <code class="n">deserialized</code><code class="p">[</code><code class="s2">"topics"</code><code class="p">]</code></pre>&#13;
&#13;
<p>Sometimes an API provider hates you and provides only responses in XML:</p>&#13;
&#13;
<pre data-code-language="xml" data-type="programlisting"><code class="nt">&lt;Book&gt;</code>&#13;
  <code class="nt">&lt;Title&gt;</code>Data Science Book<code class="nt">&lt;/Title&gt;</code>&#13;
  <code class="nt">&lt;Author&gt;</code>Joel Grus<code class="nt">&lt;/Author&gt;</code>&#13;
  <code class="nt">&lt;PublicationYear&gt;</code>2014<code class="nt">&lt;/PublicationYear&gt;</code>&#13;
  <code class="nt">&lt;Topics&gt;</code>&#13;
    <code class="nt">&lt;Topic&gt;</code>data<code class="nt">&lt;/Topic&gt;</code>&#13;
    <code class="nt">&lt;Topic&gt;</code>science<code class="nt">&lt;/Topic&gt;</code>&#13;
    <code class="nt">&lt;Topic&gt;</code>data science<code class="nt">&lt;/Topic&gt;</code>&#13;
  <code class="nt">&lt;/Topics&gt;</code>&#13;
<code class="nt">&lt;/Book&gt;</code></pre>&#13;
&#13;
<p>You can use Beautiful Soup to get data from XML similarly to how we used it to get data from HTML; check its documentation for details.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Using an Unauthenticated API" data-type="sect2"><div class="sect2" id="idm45635748900600">&#13;
<h2>Using an Unauthenticated API</h2>&#13;
&#13;
<p>Most<a data-primary="unauthenticated APIs" data-type="indexterm" id="idm45635748899032"/> APIs these days require that you first authenticate yourself before you can use them. While we don’t begrudge them this policy, it creates a lot of extra boilerplate that muddies up our exposition. Accordingly, we’ll start by taking a look at <a href="http://developer.github.com/v3/">GitHub’s API</a>, with which you can do some simple things unauthenticated:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">requests</code><code class="o">,</code> <code class="nn">json</code>&#13;
&#13;
<code class="n">github_user</code> <code class="o">=</code> <code class="s2">"joelgrus"</code>&#13;
<code class="n">endpoint</code> <code class="o">=</code> <code class="n">f</code><code class="s2">"https://api.github.com/users/{github_user}/repos"</code>&#13;
&#13;
<code class="n">repos</code> <code class="o">=</code> <code class="n">json</code><code class="o">.</code><code class="n">loads</code><code class="p">(</code><code class="n">requests</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">endpoint</code><code class="p">)</code><code class="o">.</code><code class="n">text</code><code class="p">)</code></pre>&#13;
&#13;
<p>At this point <code>repos</code> is a <code>list</code> of Python <code>dict</code>s, each representing a public repository in my GitHub account.  (Feel free to substitute your username and get your GitHub repository data instead.  You do have a GitHub account, right?)</p>&#13;
&#13;
<p>We can use this to figure out which months and days of the week I’m most likely to create a repository.&#13;
The only issue is that the dates in the response are strings:</p>&#13;
&#13;
<pre data-code-language="json" data-type="programlisting"><code class="s2">"created_at"</code><code class="err">:</code> <code class="s2">"2013-07-05T02:02:28Z"</code></pre>&#13;
&#13;
<p>Python doesn’t come with a great date parser, so we’ll need to install one:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">python -m pip install python-dateutil</pre>&#13;
&#13;
<p>from which you’ll probably only ever need the <code>dateutil.parser.parse</code> function:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">Counter</code>&#13;
<code class="kn">from</code> <code class="nn">dateutil.parser</code> <code class="kn">import</code> <code class="n">parse</code>&#13;
&#13;
<code class="n">dates</code> <code class="o">=</code> <code class="p">[</code><code class="n">parse</code><code class="p">(</code><code class="n">repo</code><code class="p">[</code><code class="s2">"created_at"</code><code class="p">])</code> <code class="k">for</code> <code class="n">repo</code> <code class="ow">in</code> <code class="n">repos</code><code class="p">]</code>&#13;
<code class="n">month_counts</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">date</code><code class="o">.</code><code class="n">month</code> <code class="k">for</code> <code class="n">date</code> <code class="ow">in</code> <code class="n">dates</code><code class="p">)</code>&#13;
<code class="n">weekday_counts</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">date</code><code class="o">.</code><code class="n">weekday</code><code class="p">()</code> <code class="k">for</code> <code class="n">date</code> <code class="ow">in</code> <code class="n">dates</code><code class="p">)</code></pre>&#13;
&#13;
<p>Similarly, you can get the languages of my last five repositories:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">last_5_repositories</code> <code class="o">=</code> <code class="nb">sorted</code><code class="p">(</code><code class="n">repos</code><code class="p">,</code>&#13;
                             <code class="n">key</code><code class="o">=</code><code class="k">lambda</code> <code class="n">r</code><code class="p">:</code> <code class="n">r</code><code class="p">[</code><code class="s2">"pushed_at"</code><code class="p">],</code>&#13;
                             <code class="n">reverse</code><code class="o">=</code><code class="bp">True</code><code class="p">)[:</code><code class="mi">5</code><code class="p">]</code>&#13;
&#13;
<code class="n">last_5_languages</code> <code class="o">=</code> <code class="p">[</code><code class="n">repo</code><code class="p">[</code><code class="s2">"language"</code><code class="p">]</code>&#13;
                    <code class="k">for</code> <code class="n">repo</code> <code class="ow">in</code> <code class="n">last_5_repositories</code><code class="p">]</code></pre>&#13;
&#13;
<p>Typically we won’t be working with APIs at this low “make the requests and parse the responses ourselves” level.  One of the benefits of using Python is that someone has already built a library for pretty much any API you’re interested in accessing.  When they’re done well, these libraries can save you a lot of the trouble of figuring out the hairier details of API access.  (When they’re not done well, or when it turns out they’re based on defunct versions of the corresponding APIs, they can cause you enormous headaches.)</p>&#13;
&#13;
<p>Nonetheless, you’ll occasionally have to roll your own API access library (or, more likely, debug why someone else’s isn’t working), so it’s good to know some of the details.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Finding APIs" data-type="sect2"><div class="sect2" id="idm45635748900008">&#13;
<h2>Finding APIs</h2>&#13;
&#13;
<p>If you need data from a specific site, look for a “developers” or “API” section of the site for details, and try searching the web for “python &lt;sitename&gt; api” to find a library.</p>&#13;
&#13;
<p>There are libraries for the Yelp API, for the Instagram API, for the Spotify API, and so on.</p>&#13;
&#13;
<p>If you’re looking for a list of APIs that have Python wrappers, there’s a nice one from  <a href="https://github.com/realpython/list-of-python-api-wrappers">Real Python on GitHub</a>.</p>&#13;
&#13;
<p>And if you can’t find what you need, there’s always scraping, the last refuge of the data scientist.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Example: Using the Twitter APIs" data-type="sect1"><div class="sect1" id="idm45635749047624">&#13;
<h1>Example: Using the Twitter APIs</h1>&#13;
&#13;
<p>Twitter<a data-primary="data" data-secondary="collecting" data-tertiary="using Twitter APIs" data-type="indexterm" id="DCtwit09"/><a data-primary="Twitter APIs" data-type="indexterm" id="twitter09"/> is a fantastic source of data to work with.  You can use it to get real-time news.  You can use it to measure reactions to current events.  You can use it to find links related to specific topics.  You can use it for pretty much anything you can imagine, just as long as you can get access to its data.  And you can get access to its data through its APIs.</p>&#13;
&#13;
<p>To<a data-primary="Twython library" data-type="indexterm" id="twython09"/> interact with the Twitter APIs, we’ll be using the <a href="https://github.com/ryanmcgrath/twython">Twython library</a> (<code>python -m pip install twython</code>). There are quite a few Python Twitter libraries out there, but this is the one that I’ve had the most success working with.  You are encouraged to explore the others as well!</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Getting Credentials" data-type="sect2"><div class="sect2" id="idm45635748591208">&#13;
<h2>Getting Credentials</h2>&#13;
&#13;
<p>In order to use Twitter’s APIs, you need to get some credentials (for which you need a Twitter account, which you should have anyway so that you can be part of the lively and friendly Twitter #datascience community).</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>Like all instructions that relate to websites that I don’t control, these may become obsolete at some point but will hopefully work for a while. (Although they have already changed multiple times since I originally started writing this book, so good luck!)</p>&#13;
</div>&#13;
&#13;
<p>Here are the steps:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Go to <a href="https://developer.twitter.com/"><em class="hyperlink">https://developer.twitter.com/</em></a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>If you are not signed in, click “Sign in” and enter your Twitter username and password.</p>&#13;
</li>&#13;
<li>&#13;
<p>Click Apply to apply for a developer account.</p>&#13;
</li>&#13;
<li>&#13;
<p>Request access for your own personal use.</p>&#13;
</li>&#13;
<li>&#13;
<p>Fill out the application. It requires 300 words (really) on why you need access, so to get over the limit you could tell them about this book and how much you’re enjoying it.</p>&#13;
</li>&#13;
<li>&#13;
<p>Wait some indefinite amount of time.</p>&#13;
</li>&#13;
<li>&#13;
<p>If you know someone who works at Twitter, email them and ask them if they can expedite your application. Otherwise, keep waiting.</p>&#13;
</li>&#13;
<li>&#13;
<p>Once you get approved, go back to <a href="https://developer.twitter.com/">developer.twitter.com</a>, find the “Apps” section, and click “Create an app.”</p>&#13;
</li>&#13;
<li>&#13;
<p>Fill out all the required fields (again, if you need extra characters for the description, you could talk about this book and how edifying you’re finding it).</p>&#13;
</li>&#13;
<li>&#13;
<p>Click CREATE.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>Now your app should have a “Keys and tokens” tab with a “Consumer API keys” section that lists an “API key” and an “API secret key.” Take note of those keys; you’ll need them. (Also, keep them secret! They’re like passwords.)</p>&#13;
<div data-type="caution"><h6>Caution</h6>&#13;
<p>Don’t share the keys, don’t publish them in your book, and don’t check them into your public GitHub repository. One simple solution is to store them in a <em>credentials.json</em> file that doesn’t get checked in, and to have your code use <code>json.loads</code> to retrieve them.&#13;
Another solution is to store them in environment variables and use <code>os.environ</code> to retrieve them.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Using Twython" data-type="sect3"><div class="sect3" id="idm45635748572632">&#13;
<h3>Using Twython</h3>&#13;
&#13;
<p>The trickiest part of using the Twitter API is authenticating yourself.&#13;
(Indeed, this is the trickiest part of using a lot of APIs.)&#13;
API providers want to make sure that you’re authorized to access their data&#13;
and that you don’t exceed their usage limits. They also want to know&#13;
who’s accessing their data.</p>&#13;
&#13;
<p>Authentication is kind of a pain. There is a simple way, OAuth 2, that suffices when you just want to do simple searches. And there is a complex way, OAuth 1, that’s required when you want to perform actions (e.g., tweeting) or (in particular for us) connect to the Twitter stream.</p>&#13;
&#13;
<p>So we’re stuck with the more complicated way, which we’ll try&#13;
to automate as much as we can.</p>&#13;
&#13;
<p>First, you need your API key and API secret key (sometimes known as the consumer key and consumer secret, respectively).&#13;
I’ll be getting mine from environment variables, but feel&#13;
free to substitute in yours however you wish:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">os</code>&#13;
&#13;
<code class="c1"># Feel free to plug your key and secret in directly</code>&#13;
<code class="n">CONSUMER_KEY</code> <code class="o">=</code> <code class="n">os</code><code class="o">.</code><code class="n">environ</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s2">"TWITTER_CONSUMER_KEY"</code><code class="p">)</code>&#13;
<code class="n">CONSUMER_SECRET</code> <code class="o">=</code> <code class="n">os</code><code class="o">.</code><code class="n">environ</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s2">"TWITTER_CONSUMER_SECRET"</code><code class="p">)</code></pre>&#13;
&#13;
<p>Now we can instantiate the client:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">webbrowser</code>&#13;
<code class="kn">from</code> <code class="nn">twython</code> <code class="kn">import</code> <code class="n">Twython</code>&#13;
&#13;
<code class="c1"># Get a temporary client to retrieve an authentication URL</code>&#13;
<code class="n">temp_client</code> <code class="o">=</code> <code class="n">Twython</code><code class="p">(</code><code class="n">CONSUMER_KEY</code><code class="p">,</code> <code class="n">CONSUMER_SECRET</code><code class="p">)</code>&#13;
<code class="n">temp_creds</code> <code class="o">=</code> <code class="n">temp_client</code><code class="o">.</code><code class="n">get_authentication_tokens</code><code class="p">()</code>&#13;
<code class="n">url</code> <code class="o">=</code> <code class="n">temp_creds</code><code class="p">[</code><code class="s1">'auth_url'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Now visit that URL to authorize the application and get a PIN</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s2">"go visit {url} and get the PIN code and paste it below"</code><code class="p">)</code>&#13;
<code class="n">webbrowser</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="n">url</code><code class="p">)</code>&#13;
<code class="n">PIN_CODE</code> <code class="o">=</code> <code class="nb">input</code><code class="p">(</code><code class="s2">"please enter the PIN code: "</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Now we use that PIN_CODE to get the actual tokens</code>&#13;
<code class="n">auth_client</code> <code class="o">=</code> <code class="n">Twython</code><code class="p">(</code><code class="n">CONSUMER_KEY</code><code class="p">,</code>&#13;
                      <code class="n">CONSUMER_SECRET</code><code class="p">,</code>&#13;
                      <code class="n">temp_creds</code><code class="p">[</code><code class="s1">'oauth_token'</code><code class="p">],</code>&#13;
                      <code class="n">temp_creds</code><code class="p">[</code><code class="s1">'oauth_token_secret'</code><code class="p">])</code>&#13;
<code class="n">final_step</code> <code class="o">=</code> <code class="n">auth_client</code><code class="o">.</code><code class="n">get_authorized_tokens</code><code class="p">(</code><code class="n">PIN_CODE</code><code class="p">)</code>&#13;
<code class="n">ACCESS_TOKEN</code> <code class="o">=</code> <code class="n">final_step</code><code class="p">[</code><code class="s1">'oauth_token'</code><code class="p">]</code>&#13;
<code class="n">ACCESS_TOKEN_SECRET</code> <code class="o">=</code> <code class="n">final_step</code><code class="p">[</code><code class="s1">'oauth_token_secret'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># And get a new Twython instance using them.</code>&#13;
<code class="n">twitter</code> <code class="o">=</code> <code class="n">Twython</code><code class="p">(</code><code class="n">CONSUMER_KEY</code><code class="p">,</code>&#13;
                  <code class="n">CONSUMER_SECRET</code><code class="p">,</code>&#13;
                  <code class="n">ACCESS_TOKEN</code><code class="p">,</code>&#13;
                  <code class="n">ACCESS_TOKEN_SECRET</code><code class="p">)</code></pre>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>At this point you may want to consider saving the <code>ACCESS_TOKEN</code> and <code>ACCESS_TOKEN_SECRET</code>&#13;
somewhere safe, so that next time you don’t have to go through this rigmarole.</p>&#13;
</div>&#13;
&#13;
<p>Once we have an authenticated <code>Twython</code> instance, we can start performing searches:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="c1"># Search for tweets containing the phrase "data science"</code>&#13;
<code class="k">for</code> <code class="n">status</code> <code class="ow">in</code> <code class="n">twitter</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">q</code><code class="o">=</code><code class="s1">'"data science"'</code><code class="p">)[</code><code class="s2">"statuses"</code><code class="p">]:</code>&#13;
    <code class="n">user</code> <code class="o">=</code> <code class="n">status</code><code class="p">[</code><code class="s2">"user"</code><code class="p">][</code><code class="s2">"screen_name"</code><code class="p">]</code>&#13;
    <code class="n">text</code> <code class="o">=</code> <code class="n">status</code><code class="p">[</code><code class="s2">"text"</code><code class="p">]</code>&#13;
    <code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s2">"{user}: {text}</code><code class="se">\n</code><code class="s2">"</code><code class="p">)</code></pre>&#13;
&#13;
<p>If you run this, you should get some tweets back like:</p>&#13;
&#13;
<pre data-type="programlisting">haithemnyc: Data scientists with the technical savvy &amp;amp; analytical chops to&#13;
derive meaning from big data are in demand. http://t.co/HsF9Q0dShP&#13;
&#13;
RPubsRecent: Data Science http://t.co/6hcHUz2PHM&#13;
&#13;
spleonard1: Using #dplyr in #R to work through a procrastinated assignment for&#13;
@rdpeng in @coursera data science specialization. So easy and Awesome.</pre>&#13;
&#13;
<p>This isn’t that interesting, largely because the Twitter Search API just shows you whatever handful of recent results it feels like.  When you’re doing data science, more often you want a lot of tweets.  This is where the <a href="https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data">Streaming API</a> is useful.  It allows you to connect to (a sample of) the great Twitter firehose.  To use it, you’ll need to authenticate using your access tokens.</p>&#13;
&#13;
<p>In order to access the Streaming API with Twython, we need to define a class that inherits from <code>TwythonStreamer</code> and that overrides its <code>on_success</code> method, and possibly its <code>on_error</code> method:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">twython</code> <code class="kn">import</code> <code class="n">TwythonStreamer</code>&#13;
&#13;
<code class="c1"># Appending data to a global variable is pretty poor form</code>&#13;
<code class="c1"># but it makes the example much simpler</code>&#13;
<code class="n">tweets</code> <code class="o">=</code> <code class="p">[]</code>&#13;
&#13;
<code class="k">class</code> <code class="nc">MyStreamer</code><code class="p">(</code><code class="n">TwythonStreamer</code><code class="p">):</code>&#13;
    <code class="k">def</code> <code class="nf">on_success</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">data</code><code class="p">):</code>&#13;
        <code class="sd">"""</code>&#13;
<code class="sd">        What do we do when Twitter sends us data?</code>&#13;
<code class="sd">        Here data will be a Python dict representing a tweet.</code>&#13;
<code class="sd">        """</code>&#13;
        <code class="c1"># We only want to collect English-language tweets</code>&#13;
        <code class="k">if</code> <code class="n">data</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'lang'</code><code class="p">)</code> <code class="o">==</code> <code class="s1">'en'</code><code class="p">:</code>&#13;
            <code class="n">tweets</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">data</code><code class="p">)</code>&#13;
            <code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s2">"received tweet #{len(tweets)}"</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># Stop when we've collected enough</code>&#13;
        <code class="k">if</code> <code class="nb">len</code><code class="p">(</code><code class="n">tweets</code><code class="p">)</code> <code class="o">&gt;=</code> <code class="mi">100</code><code class="p">:</code>&#13;
            <code class="bp">self</code><code class="o">.</code><code class="n">disconnect</code><code class="p">()</code>&#13;
&#13;
    <code class="k">def</code> <code class="nf">on_error</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">status_code</code><code class="p">,</code> <code class="n">data</code><code class="p">):</code>&#13;
        <code class="k">print</code><code class="p">(</code><code class="n">status_code</code><code class="p">,</code> <code class="n">data</code><code class="p">)</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">disconnect</code><code class="p">()</code></pre>&#13;
&#13;
<p><code>MyStreamer</code> will connect to the Twitter stream and wait for Twitter to feed it data.  Each time it receives some data (here, a tweet represented as a Python object), it passes it to the <code>on_success</code> method, which appends it to our <code>tweets</code> list if its language is English, and then disconnects the streamer after it’s collected 1,000 tweets.</p>&#13;
&#13;
<p>All that’s left is to initialize it and start it running:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">stream</code> <code class="o">=</code> <code class="n">MyStreamer</code><code class="p">(</code><code class="n">CONSUMER_KEY</code><code class="p">,</code> <code class="n">CONSUMER_SECRET</code><code class="p">,</code>&#13;
                    <code class="n">ACCESS_TOKEN</code><code class="p">,</code> <code class="n">ACCESS_TOKEN_SECRET</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># starts consuming public statuses that contain the keyword 'data'</code>&#13;
<code class="n">stream</code><code class="o">.</code><code class="n">statuses</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">track</code><code class="o">=</code><code class="s1">'data'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># if instead we wanted to start consuming a sample of *all* public statuses</code>&#13;
<code class="c1"># stream.statuses.sample()</code></pre>&#13;
&#13;
<p>This will run until it collects 100 tweets (or until it encounters an error) and stop, at which point you can start analyzing those tweets.  For instance, you could find the most common hashtags with:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">top_hashtags</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">hashtag</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code><code class="o">.</code><code class="n">lower</code><code class="p">()</code>&#13;
                       <code class="k">for</code> <code class="n">tweet</code> <code class="ow">in</code> <code class="n">tweets</code>&#13;
                       <code class="k">for</code> <code class="n">hashtag</code> <code class="ow">in</code> <code class="n">tweet</code><code class="p">[</code><code class="s2">"entities"</code><code class="p">][</code><code class="s2">"hashtags"</code><code class="p">])</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="n">top_hashtags</code><code class="o">.</code><code class="n">most_common</code><code class="p">(</code><code class="mi">5</code><code class="p">))</code></pre>&#13;
&#13;
<p>Each tweet contains a lot of data. You can either poke around yourself or dig through the <a href="https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object">Twitter API documentation</a>.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>In a non-toy project, you probably wouldn’t want to rely on an in-memory <code>list</code> for storing the tweets.&#13;
Instead you’d want to save them to a file or a database, so that you’d have them permanently.<a data-primary="" data-startref="twitter09" data-type="indexterm" id="idm45635748163960"/><a data-primary="" data-startref="DCtwit09" data-type="indexterm" id="idm45635748162984"/><a data-primary="" data-startref="twython09" data-type="indexterm" id="idm45635748162040"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="For Further Exploration" data-type="sect1"><div class="sect1" id="idm45635748571528">&#13;
<h1>For Further Exploration</h1>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><a href="http://pandas.pydata.org/">pandas</a> is the<a data-primary="pandas" data-type="indexterm" id="idm45635748083880"/><a data-primary="data" data-secondary="collecting" data-tertiary="tools for" data-type="indexterm" id="idm45635748083144"/> primary library&#13;
that data science types use for working with—and, in particular, importing—data.</p>&#13;
</li>&#13;
<li>&#13;
<p><a href="http://scrapy.org/">Scrapy</a> is<a data-primary="Scrapy" data-type="indexterm" id="idm45635748080296"/> a full-featured library&#13;
for building complicated web scrapers that do things like follow unknown links.</p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://www.kaggle.com/datasets">Kaggle</a> hosts<a data-primary="" data-startref="Kaggle" data-type="indexterm" id="idm45635748077944"/> a large collection of datasets.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>