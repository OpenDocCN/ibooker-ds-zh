<html><head></head><body><section data-pdf-bookmark="Chapter 16. Model Selection" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch-risk">&#13;
<h1><span class="label">Chapter 16. </span>Model Selection</h1>&#13;
&#13;
<p>So far when we fit models<a contenteditable="false" data-primary="model selection" data-type="indexterm" id="ix_mod_sel_ch16"/>, we have used a few strategies to decide which features to include:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Assess model fit with residual plots.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Connect the statistical model to a physical model.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Keep the model simple.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Compare improvements in the standard deviation of the residuals and in the MSE between increasingly complex models.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>For example, when we examined the one-variable model of upward mobility in <a class="reference internal" data-type="xref" href="ch15.html#ch-linear">Chapter 15</a>, we found curvature in the residual plot. Adding a second variable greatly improved the fit in terms of average loss (MSE and, relatedly, multiple <span class="math notranslate nohighlight"><math> <msup> <mi>R</mi> <mn>2</mn> </msup> </math></span>), but some curvature remained in the residuals. A seven-variable model made little improvement over the two-variable model in terms of a decrease in MSE, so although the two-variable model still showed some patterns in the residuals, we opted for this simpler model.</p>&#13;
&#13;
<p>As another example, when we model the weight of a donkey in <a class="reference internal" data-type="xref" href="ch18.html#ch-donkey">Chapter 18</a>, we will take guidance from a physical model. We’ll ignore the donkey’s appendages and draw on the similarity between a barrel and a donkey’s body to begin fitting a model that explains weight by its length and girth (comparable to a barrel’s height and circumference). We’ll then continue to adjust that model by adding categorical features related to the donkey’s physical condition and age, collapsing categories, and excluding other possible features to keep the model simple.</p>&#13;
&#13;
<p>The decisions we make in building these models are based on judgment calls, and in this chapter we augment these with more formal criteria. To begin, we provide an example that shows why it’s typically not a good idea to include too many features in a model. This phenomenon, called <em>overfitting</em>, often leads to models that follow the data too closely and capture some of the noise in the data. Then, when new observations come along, the predictions are worse than those from a simpler model. The remainder of the chapter provides techniques, such as the train-test split, cross-validation, and regularization, for limiting the impact of overfitting. These techniques are especially helpful when there are a large number of potential features to include in a model. We also provide a synthetic example, where we know the true model, to explain the concepts of model variance and bias and how they relate to over- and underfitting.</p>&#13;
&#13;
&#13;
<section data-pdf-bookmark="Overfitting" data-type="sect1"><div class="sect1" id="overfitting">&#13;
<h1>Overfitting</h1>&#13;
&#13;
<p>When we have many features<a contenteditable="false" data-primary="overfitting" data-type="indexterm" id="ix_over_fit_ch16"/><a contenteditable="false" data-primary="fitting the model" data-secondary="overfitting" data-type="indexterm" id="ix_fit_mod_over"/><a contenteditable="false" data-primary="model selection" data-secondary="overfitting" data-type="indexterm" id="ix_mod_sel_over"/> available to include in a model, choosing which ones to include or exclude rapidly gets complicated. In the upward mobility example in <a class="reference internal" data-type="xref" href="ch15.html#ch-linear">Chapter 15</a>, we chose two of the seven variables to fit the model, but there are 21 pairs of features that we could have examined and fitted for a two-variable model. And there are over one hundred models to choose from if we consider all one-, two-, …, seven-variable models. It can be hard to examine hundreds of residual plots to decide how simple is simple enough, and to settle on a model. Unfortunately, the notion of minimizing MSE isn’t entirely helpful either. With each variable that we add to a model, the MSE typically gets smaller. Recall from the geometric perspective of model fitting (<a class="reference internal" data-type="xref" href="ch15.html#ch-linear">Chapter 15</a>) that adding a feature to a model adds an <span class="math notranslate nohighlight"><math> <mi>n</mi> </math></span>-dimensional vector to the feature space, and the error between the outcome vector and its projection into the space spanned by the explanatory variables shrinks. We might view this as a good thing because our model fits the data more closely, but there is a danger in overfitting.</p>&#13;
&#13;
<p>Overfitting happens when the model follows the data too closely and picks up the variability in the random noise in the outcome. When this happens, new observations are not well-predicted. An example helps clarify this idea.</p>&#13;
&#13;
<section data-pdf-bookmark="Example: Energy Consumption" data-type="sect2"><div class="sect2" id="example-energy-consumption">&#13;
<h2>Example: Energy Consumption</h2>&#13;
&#13;
<p>In this example<a contenteditable="false" data-primary="energy consumption overfitting dataset" data-type="indexterm" id="ix_energ_cons_over"/>, we examine a <a class="reference external" href="https://oreil.ly/ngD4G">dataset you can download</a> that contains information from utility bills for a private residence in Minnesota. We have records of the monthly gas usage in a home (cubic feet) and the average temperature that month (degrees Fahrenheit).<sup><a data-type="noteref" href="ch16.html#id1643" id="id1643-marker">1</a></sup> We first read in the data:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">heat_df</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">pd</code></span><span><code class="o">.</code></span><span><code class="n">read_csv</code></span><span><code class="p">(</code></span><span><code class="s2">"</code><code class="s2">data/utilities.csv</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">usecols</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">temp</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">ccf</code><code class="s2">"</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><span><code class="n">heat_df</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>temp</th>&#13;
			<th>ccf</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>0</strong></td>&#13;
			<td>29</td>&#13;
			<td>166</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1</strong></td>&#13;
			<td>31</td>&#13;
			<td>179</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2</strong></td>&#13;
			<td>15</td>&#13;
			<td>224</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>...</strong></td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>96</strong></td>&#13;
			<td>76</td>&#13;
			<td>11</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>97</strong></td>&#13;
			<td>55</td>&#13;
			<td>32</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>98</strong></td>&#13;
			<td>39</td>&#13;
			<td>91</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<pre>99 rows × 2 columns</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We will begin by looking at a scatterplot of gas consumption as a function of <span class="keep-together">temperature</span>:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_16in01.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The relationship<a contenteditable="false" data-primary="logarithm transformation" data-secondary="for revealing relationships" data-secondary-sortas="revealing relationships" data-type="indexterm" id="id1644"/><a contenteditable="false" data-primary="transformations" data-secondary="logarithm (log)" data-type="indexterm" id="id1645"/> shows curvature (left plot), but when we try to straighten it with a log transformation (right plot), a different curvature arises in the low-temperature region. Additionally, there are two unusual points. When we refer back to the documentation, we find that these points represent recording errors, so we remove them.</p>&#13;
&#13;
<p>Let’s see if a quadratic curve can capture the relationship between gas usage and temperature. Polynomials are still considered linear models. They are linear in their polynomial features. For example, we can express a quadratic model as:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <msup> <mi>x</mi> <mn>2</mn> </msup> </math></div>&#13;
</div>&#13;
&#13;
<p class="pagebreak-before less_space">This model is linear in the features <span class="math notranslate nohighlight"><math> <mi>x</mi> </math></span> and <span class="math notranslate nohighlight"><math> <msup> <mi>x</mi> <mn>2</mn> </msup> </math></span>, and in matrix notation we can write this model as <span class="math notranslate nohighlight"><math> <mrow> <mtext mathvariant="bold">X</mtext> </mrow> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> </math></span>, where <span class="math notranslate nohighlight"><math> <mtext mathvariant="bold">X</mtext> </math></span> is the design matrix:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" columnspacing="0em" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mrow> <mo>⌈</mo> <mtable columnalign="center" columnspacing="1em" rowspacing="4pt"> <mtr> <mtd> <mn>1</mn> </mtd> <mtd> <msub> <mi>x</mi> <mn>1</mn> </msub> </mtd> <mtd> <msubsup> <mi>x</mi> <mn>1</mn> <mn>2</mn> </msubsup> </mtd> </mtr> <mtr> <mtd> <mn>1</mn> </mtd> <mtd> <msub> <mi>x</mi> <mn>2</mn> </msub> </mtd> <mtd> <msubsup> <mi>x</mi> <mn>2</mn> <mn>2</mn> </msubsup> </mtd> </mtr> <mtr> <mtd> <mrow> <mo>⋮</mo> </mrow> </mtd> <mtd> <mrow> <mo>⋮</mo> </mrow> </mtd> <mtd> <mrow> <mo>⋮</mo> </mrow> </mtd> </mtr> <mtr> <mtd> <mn>1</mn> </mtd> <mtd> <msub> <mi>x</mi> <mi>n</mi> </msub> </mtd> <mtd> <msubsup> <mi>x</mi> <mi>n</mi> <mn>2</mn> </msubsup> </mtd> </mtr> </mtable> <mo>⌉</mo> </mrow> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>We can create the polynomial<a contenteditable="false" data-primary="scikit-learn library" data-secondary="PolynomialFeatures tool" data-type="indexterm" id="id1646"/><a contenteditable="false" data-primary="PolynomialFeatures tool" data-type="indexterm" id="id1647"/> features of the design matrix with the <code>Polynomial​Fea⁠tures</code> tool in <code>scikit-learn</code>:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">y</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">heat_df</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">ccf</code><code class="s1">'</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="n">X</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">heat_df</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">temp</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">]</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="kn">from</code></span><code> </code><span><code class="nn">sklearn</code><code class="nn">.</code><code class="nn">preprocessing</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">PolynomialFeatures</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">poly</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">PolynomialFeatures</code></span><span><code class="p">(</code></span><span><code class="n">degree</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">include_bias</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">poly_features</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">poly</code></span><span><code class="o">.</code></span><span><code class="n">fit_transform</code></span><span><code class="p">(</code></span><span><code class="n">X</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">poly_features</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
array([[  29.,  841.],&#13;
       [  31.,  961.],&#13;
       [  15.,  225.],&#13;
       ...,&#13;
       [  76., 5776.],&#13;
       [  55., 3025.],&#13;
       [  39., 1521.]])&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We set the parameter <code>include_bias</code> to <code>False</code> because we plan to fit the polynomial<a contenteditable="false" data-primary="LinearRegression" data-type="indexterm" id="id1648"/> with the <code>LinearRegression</code> method in <code>scikit-learn</code>, and by default it includes the constant term in the model. We fit the polynomial with:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">sklearn</code><code class="nn">.</code><code class="nn">linear_model</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">LinearRegression</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">model_deg2</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">poly_features</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>To get a quick idea as to the quality of the fit, let’s overlay the fitted quadratic on the scatterplot and also look at the residuals:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_16in02.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The quadratic captures the curve in the data quite well, but the residuals show a slight upward trend in the temperature range of 70°F to 80°F, which indicates some lack of fit. There is also some funneling in the residuals, where the variability in gas consumption is greater in the colder months. We might expect this behavior since we have only the monthly average temperature.</p>&#13;
&#13;
<p>For comparison, we fit a few more models with higher-degree polynomials and collectively examine the fitted curves:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">poly12</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">PolynomialFeatures</code></span><span><code class="p">(</code></span><span><code class="n">degree</code></span><span><code class="o">=</code></span><span><code class="mi">12</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">include_bias</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">poly_features12</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">poly12</code></span><span><code class="o">.</code></span><span><code class="n">fit_transform</code></span><span><code class="p">(</code></span><span><code class="n">X</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">degrees</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="mi">1</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">3</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">6</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">8</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">12</code></span><span><code class="p">]</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">mods</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">poly_features12</code></span><span><code class="p">[</code><code class="p">:</code><code class="p">,</code></span><code> </code><span><code class="p">:</code></span><span><code class="n">deg</code></span><span><code class="p">]</code><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>        </code><span><code class="k">for</code></span><code> </code><span><code class="n">deg</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="n">degrees</code></span><span><code class="p">]</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>We use the polynomial<a contenteditable="false" data-primary="polynomial features" data-type="indexterm" id="id1649"/> features in this section to demonstrate over-fitting, but directly fitting the <span class="math notranslate nohighlight"><math> <mi>x</mi> <mo>,</mo> <msup> <mi>x</mi> <mn>2</mn> </msup> <mo>,</mo> <msup> <mi>x</mi> <mn>3</mn> </msup> <mo>,</mo> <mo>…</mo> </math></span> polynomials is not advisable in practice. Unfortunately, these polynomial features tend to be highly correlated. For example, the correlation between <span class="math notranslate nohighlight"><math> <mi>x</mi> </math></span> and <span class="math notranslate nohighlight"><math> <msup> <mi>x</mi> <mn>2</mn> </msup> </math></span> for the energy data is 0.98. Highly correlated features give unstable coefficients, where a small change in an x-value can lead to a large change in the coefficients of the polynomial. Also, when the x-values are large, the normal equations are poorly conditioned and the coefficients can be difficult to interpret and compare.</p>&#13;
&#13;
<p>A better practice is to use polynomials that have been constructed to be orthogonal to one another. These polynomials fill the same space as the original polynomials, but they are uncorrelated with one another and give a more stable fit.</p>&#13;
</div>&#13;
&#13;
<p>Let’s place all of the polynomial fits on the same graph so that we can see how the higher-degree polynomials bend more and more strangely:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_16in03.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>We can also visualize the different polynomial fits in separate facets:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_16in04.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The degree 1 curve (the straight line) in the upper-left facet misses the curved pattern in the data. The degree 2 curve begins to capture it, and the degree 3 curve looks like an improvement, but notice the upward bend at the right side of the plot. The polynomials of degrees 6, 8, and 12 follow the data increasingly closely, as they get increasingly curvy. These polynomials seem to fit spurious bumps in the data. Altogether, these six curves illustrate under- and overfitting. The fitted line in the upper left underfits and misses the curvature entirely. And the degree 12 polynomial in the bottom right definitely overfits with a wiggly pattern that we don’t think makes sense in this context.</p>&#13;
&#13;
<p>In general, as we add more features, models get more complex and the MSE drops, but at the same time, the fitted model grows increasingly erratic and sensitive to the data. When we overfit, the model follows the data too closely, and predictions are poor for new observations. One simple technique to assess a fitted model is to compute the MSE on new data, data that were not used in building the model. Since we don’t typically have the capacity to acquire more data, we set aside some of the original data to evaluate the fitted model. This technique is the topic of the next section<a contenteditable="false" data-primary="" data-startref="ix_mod_sel_over" data-type="indexterm" id="id1650"/><a contenteditable="false" data-primary="" data-startref="ix_over_fit_ch16" data-type="indexterm" id="id1651"/><a contenteditable="false" data-primary="" data-startref="ix_energ_cons_over" data-type="indexterm" id="id1652"/><a contenteditable="false" data-primary="" data-startref="ix_fit_mod_over" data-type="indexterm" id="id1653"/>.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Train-Test Split" data-type="sect1"><div class="sect1" id="train-test-split">&#13;
<h1>Train-Test Split</h1>&#13;
&#13;
<p>Although we want<a contenteditable="false" data-primary="train-test split, model selection" data-type="indexterm" id="ix_ttsplit_mod_sel"/><a contenteditable="false" data-primary="test set" data-type="indexterm" id="id1654"/><a contenteditable="false" data-primary="model selection" data-secondary="train-test split" data-type="indexterm" id="ix_mod_sel_ttsplit"/><a contenteditable="false" data-primary="training set" data-type="indexterm" id="id1655"/> to use all of our data in building a model, we also want to get a sense of how the model behaves with new data. We often do not have the luxury of collecting additional data to assess a model, so instead we set aside a portion of our data, called the <em>test set</em>, to stand in for new data. The remainder of the data is called the <em>train set</em>, and we use this portion to build the model. Then, after we have chosen a model, we pull out the test set and see how well the model (fitted on the train set) predicts the outcomes in the test set. <a class="reference internal" data-type="xref" href="#train-test-diagram">Figure 16-1</a> demonstrates this idea.</p>&#13;
&#13;
<figure><div class="figure" id="train-test-diagram"><img src="assets/leds_1601.png"/>&#13;
<h6><span class="label">Figure 16-1. </span>The train-test split divides the data into two parts: the train set is used to build the model and the test set evaluates that model</h6>&#13;
</div></figure>&#13;
&#13;
<p>Typically, the test set consists of 10% to 25% of the data. What might not be clear from the diagram is that this division into two parts is often made at random, so the train and test sets are similar to each other.</p>&#13;
&#13;
<p>We can describe this process using the notion introduced in <a class="reference internal" data-type="xref" href="ch15.html#ch-linear">Chapter 15</a>. The design matrix, <span class="math notranslate nohighlight"><math> <mtext mathvariant="bold">X</mtext> </math></span>, and outcome, <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="bold">y</mi> </mrow> </math></span>, are each divided into two parts; the design matrix, labeled <span class="math notranslate nohighlight"><math> <msub> <mtext mathvariant="bold">X</mtext> <mi>T</mi> </msub> </math></span>, and corresponding outcomes, <span class="math notranslate nohighlight"><math> <msub> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mi>T</mi> </msub> </math></span>, form the train set. We minimize the average squared loss over <span class="math notranslate nohighlight"><math> <mi mathvariant="bold-italic">θ</mi> </math></span> with these data:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <munder> <mo movablelimits="true">min</mo> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> </munder> <mo fence="false" stretchy="false">‖</mo> <msub> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mi>T</mi> </msub> <mo>−</mo> <mrow> <msub> <mtext mathvariant="bold">X</mtext> <mi>T</mi> </msub> </mrow> <mrow> <mrow> <mi mathvariant="bold-italic">θ</mi> </mrow> </mrow> <msup> <mo fence="false" stretchy="false">‖</mo> <mn>2</mn> </msup> </math></div>&#13;
</div>&#13;
&#13;
<p>The coefficient, <span class="math notranslate nohighlight"><math> <msub> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> <mi>T</mi> </msub> </math></span>, that minimizes the training error is used to predict outcomes for the test set, which is labeled <span class="math notranslate nohighlight"><math> <msub> <mtext mathvariant="bold">X</mtext> <mi>S</mi> </msub> </math></span> and <span class="math notranslate nohighlight"><math> <msub> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mi>S</mi> </msub> </math></span>:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mo fence="false" stretchy="false">‖</mo> <msub> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mi>S</mi> </msub> <mo>−</mo> <mrow> <msub> <mtext mathvariant="bold">X</mtext> <mi>S</mi> </msub> </mrow> <mrow> <msub> <mrow> <mover> <mi mathvariant="bold-italic">θ</mi> <mo mathvariant="bold" stretchy="false">^</mo> </mover> </mrow> <mi>T</mi> </msub> </mrow> <msup> <mo fence="false" stretchy="false">‖</mo> <mn>2</mn> </msup> </math></div>&#13;
</div>&#13;
&#13;
<p>Since <span class="math notranslate nohighlight"><math> <msub> <mtext mathvariant="bold">X</mtext> <mi>S</mi> </msub> </math></span> and <span class="math notranslate nohighlight"><math> <msub> <mrow> <mi mathvariant="bold">y</mi> </mrow> <mi>S</mi> </msub> </math></span> are not used to build the model, they give a reasonable estimate of the loss we might expect for a new observation.</p>&#13;
&#13;
<p>We demonstrate the train-test split with our polynomial model for gas consumption from the previous section. To do this, we carry out the following steps:</p>&#13;
&#13;
<ol class="arabic simple">&#13;
	<li>&#13;
	<p>Split the data at random into two parts, the train and test sets.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Fit several polynomial models to the train set and choose one.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Compute the MSE on the test set for the chosen polynomial (with coefficients fitted on the train set).</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>For the first step, we divide<a contenteditable="false" data-primary="train_test_split() method" data-type="indexterm" id="id1656"/> the data with the <code>train_test_split</code> method in <code>scikit-learn</code> and set aside 22 observations for model evaluation:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">sklearn</code><code class="nn">.</code><code class="nn">model_selection</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">train_test_split</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">test_size</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="mi">22</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">X_train</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">X_test</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_train</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_test</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">train_test_split</code></span><span><code class="p">(</code></span><code>&#13;
</code><code>    </code><span><code class="n">X</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">test_size</code></span><span><code class="o">=</code></span><span><code class="n">test_size</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">random_state</code></span><span><code class="o">=</code></span><span><code class="mi">42</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s1">'</code><code class="s1">Training set size: </code></span><span><code class="si">{</code></span><span><code class="nb">len</code></span><span><code class="p">(</code></span><span><code class="n">X_train</code></span><span><code class="p">)</code></span><span><code class="si">}</code></span><span><code class="s1">'</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="nb">print</code></span><span><code class="p">(</code></span><span><code class="sa">f</code></span><span><code class="s1">'</code><code class="s1">Test set size: </code></span><span><code class="si">{</code></span><span><code class="nb">len</code></span><span><code class="p">(</code></span><span><code class="n">X_test</code></span><span><code class="p">)</code></span><span><code class="si">}</code></span><span><code class="s1">'</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Training set size: 75&#13;
Test set size: 22&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>As in the previous section, we fit models of gas consumption to various polynomials in temperature. But this time, we use only the training data:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">poly</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">PolynomialFeatures</code></span><span><code class="p">(</code></span><span><code class="n">degree</code></span><span><code class="o">=</code></span><span><code class="mi">12</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">include_bias</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">poly_train</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">poly</code></span><span><code class="o">.</code></span><span><code class="n">fit_transform</code></span><span><code class="p">(</code></span><span><code class="n">X_train</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">degree</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">arange</code></span><span><code class="p">(</code></span><span><code class="mi">1</code></span><span><code class="p">,</code></span><span><code class="mi">13</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">mods</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">poly_train</code></span><span><code class="p">[</code><code class="p">:</code><code class="p">,</code></span><code> </code><span><code class="p">:</code></span><span><code class="n">j</code></span><span><code class="p">]</code><code class="p">,</code></span><code> </code><span><code class="n">y_train</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>        </code><span><code class="k">for</code></span><code> </code><span><code class="n">j</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="n">degree</code></span><span><code class="p">]</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We find the MSE<a contenteditable="false" data-primary="errors" data-secondary="test set/training set differences" data-type="indexterm" id="id1657"/><a contenteditable="false" data-primary="mean squared error (MSE)" data-startref="ix_mean_sq_mse2" data-type="indexterm" id="id1658"/><a contenteditable="false" data-primary="MSE (mean squared error)" data-type="indexterm" id="ix_mse_mean_sq2"/> for each of these models:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">sklearn</code><code class="nn">.</code><code class="nn">metrics</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">mean_squared_error</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">error_train</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><code>&#13;
</code><code>    </code><span><code class="n">mean_squared_error</code></span><span><code class="p">(</code></span><span><code class="n">y_train</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">mods</code></span><span><code class="p">[</code></span><span><code class="n">j</code></span><span><code class="p">]</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">poly_train</code></span><span><code class="p">[</code><code class="p">:</code><code class="p">,</code></span><code> </code><span><code class="p">:</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">j</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="mi">1</code></span><span><code class="p">)</code><code class="p">]</code><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="k">for</code></span><code> </code><span><code class="n">j</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">range</code></span><span><code class="p">(</code></span><span><code class="mi">12</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="p">]</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>To visualize the change in MSE, we plot MSE for each fitted polynomial against its degree:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">px</code></span><span><code class="o">.</code></span><span><code class="n">line</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="n">degree</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="n">error_train</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">markers</code></span><span><code class="o">=</code></span><span><code class="kc">True</code></span><span><code class="p">,</code></span><code>&#13;
</code><code>        </code><span><code class="n">labels</code></span><span><code class="o">=</code></span><span><code class="nb">dict</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">Degree of polynomial</code><code class="s1">'</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="o">=</code></span><span><code class="s1">'</code><code class="s1">Train set MSE</code><code class="s1">'</code></span><span><code class="p">)</code><code class="p">,</code></span><code>&#13;
</code><code>        </code><span><code class="n">width</code></span><span><code class="o">=</code></span><span><code class="mi">350</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">height</code></span><span><code class="o">=</code></span><span><code class="mi">250</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_16in05.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>Notice that the training error decreases with the additional model complexity. We saw earlier that the higher-order polynomials showed a wiggly behavior that we don’t think reflects the underlying structure in the data. With this in mind, we might choose a model that is simpler but shows a large reduction in MSE. That could be degree 3, 4, or 5. Let’s go with degree 3 since the difference between these three models in terms of MSE is quite small and it’s the simplest.</p>&#13;
&#13;
<p>Now that we have chosen our model, we provide an independent assessment of its MSE using the test set. We prepare the design matrix for the test set and use the degree 3 polynomial fitted on the train set to predict the outcome for each row in the test set. Lastly, we compute the MSE for the test set:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">poly_test</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">poly</code></span><span><code class="o">.</code></span><span><code class="n">fit_transform</code></span><span><code class="p">(</code></span><span><code class="n">X_test</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">y_hat</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">mods</code></span><span><code class="p">[</code></span><span><code class="mi">2</code></span><span><code class="p">]</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">poly_test</code></span><span><code class="p">[</code><code class="p">:</code><code class="p">,</code></span><code> </code><span><code class="p">:</code></span><span><code class="mi">3</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">mean_squared_error</code></span><span><code class="p">(</code></span><span><code class="n">y_test</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_hat</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
307.44460133992294&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The MSE for this model is quite a bit larger than the MSE computed on the training data. This demonstrates the problem with using the same data to fit and evaluate a model: the MSE doesn’t adequately reflect the MSE for a new observation. To further demonstrate the problem with overfitting, we compute the error for the test for each of these models:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">error_test</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><code>&#13;
</code><code>    </code><span><code class="n">mean_squared_error</code></span><span><code class="p">(</code></span><span><code class="n">y_test</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">mods</code></span><span><code class="p">[</code></span><span><code class="n">j</code></span><span><code class="p">]</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">poly_test</code></span><span><code class="p">[</code><code class="p">:</code><code class="p">,</code></span><code> </code><span><code class="p">:</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">j</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="mi">1</code></span><span><code class="p">)</code><code class="p">]</code><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="k">for</code></span><code> </code><span><code class="n">j</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">range</code></span><span><code class="p">(</code></span><span><code class="mi">12</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="p">]</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>In practice<a contenteditable="false" data-primary="fitting the model" data-secondary="overfitting" data-type="indexterm" id="id1659"/><a contenteditable="false" data-primary="overfitting" data-type="indexterm" id="id1660"/>, we do not look at the test set until we have committed to a model. Alternating between fitting a model on the train set and evaluating it on the test set can lead to overfitting. But for demonstration purposes, we plot the MSE on the test set for all of the polynomial models we fitted:</p>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_16in06.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>Notice how the MSE for the test set is larger than the MSE for the train set for all models, not just the model that we selected. More importantly, notice how the MSE for the test set initially decreases as the model goes from underfitting to one that follows the curvature in the data a bit better. Then, as the model grows in complexity, the MSE for the test set increases. These more complex models overfit the training data and lead to large errors in predicting the test set. An idealization of this phenomenon is captured in the diagram in <a class="reference internal" data-type="xref" href="#train-test-overfit">Figure 16-2</a>.</p>&#13;
&#13;
<figure><div class="figure" id="train-test-overfit"><img src="assets/leds_1602.png"/>&#13;
<h6><span class="label">Figure 16-2. </span>As the model grows in complexity, the train set error shrinks and the test set error increases</h6>&#13;
</div></figure>&#13;
&#13;
<p>The test data provides an assessment of the prediction error for new observations. It is crucial to use the test set only once, after we have committed to a model. Otherwise, we fall into the trap of using the same data to choose and evaluate the model. When choosing the model, we fell back on the simplicity argument because we were aware that increasingly complex models tend to overfit. However, we can extend the train-test method to help select the model as well. This is the topic of the next section<a contenteditable="false" data-primary="" data-startref="ix_mod_sel_ttsplit" data-type="indexterm" id="id1661"/><a contenteditable="false" data-primary="" data-startref="ix_ttsplit_mod_sel" data-type="indexterm" id="id1662"/><a contenteditable="false" data-primary="" data-startref="ix_mse_mean_sq2" data-type="indexterm" id="id1663"/><a contenteditable="false" data-primary="" data-startref="ix_mean_sq_mse2" data-type="indexterm" id="id1664"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Cross-Validation" data-type="sect1"><div class="sect1" id="cross-validation">&#13;
<h1>Cross-Validation</h1>&#13;
&#13;
<p>We can use the train-test paradigm<a contenteditable="false" data-primary="model selection" data-secondary="cross-validation" data-type="indexterm" id="ix_mod_sel_cross_val"/><a contenteditable="false" data-primary="cross-validation, model selection" data-type="indexterm" id="ix_cross_val_mod_sel"/><a contenteditable="false" data-primary="k-fold cross-validation" data-type="indexterm" id="ix_kfold_cross_valid3"/> to help us choose a model. The idea is to further divide the train set into separate parts where we fit the model on one part and evaluate it on another. This approach is called <em>cross-validation</em>. We describe one version, called <span class="math notranslate nohighlight"><math> <mi>k</mi> </math></span><em>-fold cross-validation</em>. <a class="reference internal" data-type="xref" href="#cvdiagram">Figure 16-3</a> shows the idea behind this division of the data.</p>&#13;
&#13;
<figure><div class="figure" id="cvdiagram"><img src="assets/leds_1603.png"/>&#13;
<h6><span class="label">Figure 16-3. </span>An example of fivefold cross-validation in which the train set is divided into five parts that are used in turn to validate models built on the remainder of the data</h6>&#13;
</div></figure>&#13;
&#13;
<p>Cross-validation can help select the general form of a model. By this we mean the degree of the polynomial, the number of features in the model, or a cutoff for a regularization penalty (covered in the next section). The basic steps behind <span class="math notranslate nohighlight"><math> <mi>k</mi> </math></span>-fold cross-validation are as follows:</p>&#13;
&#13;
<ol class="arabic simple">&#13;
	<li>&#13;
	<p>Divide the train set into <span class="math notranslate nohighlight"><math> <mi>k</mi> </math></span> parts of roughly the same size; each part is called a <em>fold</em>. Use the same technique that was used to create the train and test sets to make the folds. Typically, we divide the data at random.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Set one fold aside to act as a test set:</p>&#13;
&#13;
	<ul>&#13;
		<li>&#13;
		<p>Fit all models on the remainder of the training data (the training data less the particular fold).</p>&#13;
		</li>&#13;
		<li>&#13;
		<p>Use the fold you set aside to evaluate all of these models.</p>&#13;
		</li>&#13;
	</ul>&#13;
	</li>&#13;
	<li>&#13;
	<p>Repeat this process for a total of <span class="math notranslate nohighlight"><math> <mi>k</mi> </math></span> times, where each time you set aside one fold, use the rest of the train set to fit the models, and evaluate them on the fold that was set aside.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Combine the error in fitting each model across the folds, and choose the model with the smallest error.</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>These fitted models will not have identical coefficients across folds. As an example, when we fit a polynomial of, say, degree 3, we average the MSE across the <span class="math notranslate nohighlight"><math> <mi>k</mi> </math></span> folds to get an average MSE for the <span class="math notranslate nohighlight"><math> <mi>k</mi> </math></span> fitted polynomials of degree 3. We then compare the MSEs and choose the degree of the polynomial with the lowest MSE. The actual coefficients for the <span class="math notranslate nohighlight"><math> <mi>x</mi> </math></span>, <span class="math notranslate nohighlight"><math> <msup> <mi>x</mi> <mn>2</mn> </msup> </math></span>, and <span class="math notranslate nohighlight"><math> <msup> <mi>x</mi> <mn>3</mn> </msup> </math></span> terms in the cubic polynomial are not the same in each of the <span class="math notranslate nohighlight"><math> <mi>k</mi> </math></span> fits. Once the polynomial degree is selected, we refit the model using all of the training data and evaluate it on the test set. (We haven’t used the test set in any of the earlier steps to select the model.)</p>&#13;
&#13;
<p>Typically, we use 5 or 10 folds. Another popular choice<a contenteditable="false" data-primary="leave-one-out cross-validation" data-type="indexterm" id="id1665"/> puts one observation in each fold. This special case is called <em>leave-one-out cross-validation</em>. Its popularity stems from the simplicity in adjusting a least squares fit to have one fewer observation.</p>&#13;
&#13;
<p>Generally, <span class="math notranslate nohighlight"><math> <mi>k</mi> </math></span>-fold cross-validation<a contenteditable="false" data-primary="scikit-learn library" data-secondary="KFold class" data-type="indexterm" id="ix_scikit_kfold"/><a contenteditable="false" data-primary="KFold class" data-type="indexterm" id="ix_kfold_class"/> takes some computation time since we typically have to refit each model from scratch for each fold. The <code>scikit-learn</code> library provides a convenient <a class="reference external" href="https://oreil.ly/tnHTv"><code>sklearn.model_selection.KFold</code></a> class to implement <span class="math notranslate nohighlight"><math> <mi>k</mi> </math></span>-fold cross-validation.</p>&#13;
&#13;
<p>To give you an idea of how k-fold cross-validation works, we’ll demonstrate the technique on the gas consumption example. However, this time we’ll fit a different type of model. In the original scatterplot of the data, it looks like the points fall along two connected line segments. In cold temperatures, the relationship between gas consumption and temperature looks roughly linear with a negative slope of about <span class="math notranslate nohighlight"><math> <mo>−</mo> <mn>4</mn> </math></span> cubic ft/degree, and in warmer months, the relationship appears nearly flat. So, rather than fitting a polynomial, we can fit a bent line to the data.</p>&#13;
&#13;
<p>Let’s start by fitting a line with a bend at 65 degrees. To do this, we create a feature that enables the points with temperatures above 65°F to have a different slope. The model is:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mi>y</mi> <mo>=</mo> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <mo stretchy="false">(</mo> <mi>x</mi> <mo>−</mo> <mn>65</mn> <msup> <mo stretchy="false">)</mo> <mo>+</mo> </msup> </math></div>&#13;
</div>&#13;
&#13;
<p>Here, <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <mtext> </mtext> <msup> <mo stretchy="false">)</mo> <mo>+</mo> </msup> </math></span> stands for “positive part,” so when <span class="math notranslate nohighlight"><math> <mi>x</mi> </math></span> is less than 65 it evaluates to 0, and when <span class="math notranslate nohighlight"><math> <mi>x</mi> </math></span> is 65 or greater it is just <span class="math notranslate nohighlight"><math> <mi>x</mi> <mo>−</mo> <mn>65</mn> </math></span>. We create this new feature and add it to the design matrix:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">y</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">heat_df</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">ccf</code><code class="s2">"</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="n">X</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">heat_df</code></span><span><code class="p">[</code><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">temp</code><code class="s2">"</code></span><span><code class="p">]</code><code class="p">]</code></span><code>&#13;
</code><span><code class="n">X</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">temp65p</code><code class="s2">"</code></span><span><code class="p">]</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">X</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">temp</code><code class="s2">"</code></span><span><code class="p">]</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="mi">65</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">X</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">temp</code><code class="s2">"</code></span><span><code class="p">]</code></span><code> </code><span><code class="o">&gt;</code><code class="o">=</code></span><code> </code><span><code class="mi">65</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Then we fit the model with these two features:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">bend_index</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">X</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Let’s overlay this fitted “curve” on the scatterplot to see how well it captures the shape of the data:</p>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_16in07.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>This model appears to fit the data much better than a polynomial. But many bent line models are possible. The line might bend at 55 degrees or 60 degrees, and so on. We can use <span class="math notranslate nohighlight"><math> <mi>k</mi> </math></span>-fold cross-validation to choose the temperature value at which the line bends. Let’s consider models with bends at <span class="math notranslate nohighlight"><math> <mn>40</mn> <mo>,</mo> <mn>41</mn> <mo>,</mo> <mn>42</mn> <mo>,</mo> <mo>…</mo> <mo>,</mo> <mn>68</mn> <mo>,</mo> <mn>69</mn> </math></span> degrees. For each of these, we need to create the additional feature to enable the line to bend there:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre class="pagebreak-before less_space" data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">bends</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">arange</code></span><span><code class="p">(</code></span><span><code class="mi">40</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">70</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">1</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="k">for</code></span><code> </code><span><code class="n">i</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="n">bends</code></span><span><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="n">col</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="s2">"</code><code class="s2">temp</code><code class="s2">"</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="n">i</code></span><span><code class="o">.</code></span><span><code class="n">astype</code></span><span><code class="p">(</code></span><span><code class="s2">"</code><code class="s2">str</code><code class="s2">"</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="s2">"</code><code class="s2">p</code><code class="s2">"</code></span><code>&#13;
</code><code>    </code><span><code class="n">heat_df</code></span><span><code class="p">[</code></span><span><code class="n">col</code></span><span><code class="p">]</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">heat_df</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">temp</code><code class="s2">"</code></span><span><code class="p">]</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">i</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">heat_df</code></span><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">temp</code><code class="s2">"</code></span><span><code class="p">]</code></span><code> </code><span><code class="o">&gt;</code><code class="o">=</code></span><code> </code><span><code class="n">i</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">heat_df</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_html">&#13;
<div>&#13;
<table class="dataframe">&#13;
	<thead>&#13;
		<tr>&#13;
			<th> </th>&#13;
			<th>temp</th>&#13;
			<th>ccf</th>&#13;
			<th>temp40p</th>&#13;
			<th>temp41p</th>&#13;
			<th>...</th>&#13;
			<th>temp66p</th>&#13;
			<th>temp67p</th>&#13;
			<th>temp68p</th>&#13;
			<th>temp69p</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td><strong>0</strong></td>&#13;
			<td>29</td>&#13;
			<td>166</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>...</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>1</strong></td>&#13;
			<td>31</td>&#13;
			<td>179</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>...</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>2</strong></td>&#13;
			<td>15</td>&#13;
			<td>224</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>...</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>...</strong></td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
			<td>...</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>96</strong></td>&#13;
			<td>76</td>&#13;
			<td>11</td>&#13;
			<td>36</td>&#13;
			<td>35</td>&#13;
			<td>...</td>&#13;
			<td>10</td>&#13;
			<td>9</td>&#13;
			<td>8</td>&#13;
			<td>7</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>97</strong></td>&#13;
			<td>55</td>&#13;
			<td>32</td>&#13;
			<td>15</td>&#13;
			<td>14</td>&#13;
			<td>...</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td><strong>98</strong></td>&#13;
			<td>39</td>&#13;
			<td>91</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>...</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
			<td>0</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<pre>97 rows × 32 columns</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>The first step in cross-validation is to create our train and test sets. Like before, we choose 22 observations at random to be placed in the test set. That leaves 75 for the train set:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">y</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">heat_df</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">ccf</code><code class="s1">'</code></span><span><code class="p">]</code></span><code>&#13;
</code><span><code class="n">X</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">heat_df</code></span><span><code class="o">.</code></span><span><code class="n">drop</code></span><span><code class="p">(</code></span><span><code class="n">columns</code></span><span><code class="o">=</code></span><span><code class="p">[</code></span><span><code class="s1">'</code><code class="s1">ccf</code><code class="s1">'</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">test_size</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="mi">22</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">X_train</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">X_test</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_train</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_test</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">train_test_split</code></span><span><code class="p">(</code></span><code>&#13;
</code><code>    </code><span><code class="n">X</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">test_size</code></span><span><code class="o">=</code></span><span><code class="n">test_size</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">random_state</code></span><span><code class="o">=</code></span><span><code class="mi">0</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Now we can divide the train set into folds. We use three folds so that we have 25 observations in each fold. For each fold, we fit 30 models, one for each bend in the line. For this step, we divide the data with the <code>KFold</code> method in <code>scikit-learn</code>:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="kn">from</code></span><code> </code><span><code class="nn">sklearn</code><code class="nn">.</code><code class="nn">model_selection</code></span><code> </code><span><code class="kn">import</code></span><code> </code><span><code class="n">KFold</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">kf</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">KFold</code></span><span><code class="p">(</code></span><span><code class="n">n_splits</code></span><span><code class="o">=</code></span><span><code class="mi">3</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">shuffle</code></span><span><code class="o">=</code></span><span><code class="kc">True</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">random_state</code></span><span><code class="o">=</code></span><span><code class="mi">42</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">validation_errors</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">zeros</code></span><span><code class="p">(</code><code class="p">(</code></span><span><code class="mi">3</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">30</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><span><code class="k">def</code></span><code> </code><span><code class="nf">validate_bend_model</code></span><span><code class="p">(</code></span><span><code class="n">X</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">X_valid</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_valid</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">bend_index</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="n">model</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">X</code></span><span><code class="o">.</code></span><span><code class="n">iloc</code></span><span><code class="p">[</code><code class="p">:</code><code class="p">,</code></span><code> </code><span><code class="p">[</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">bend_index</code></span><span><code class="p">]</code><code class="p">]</code><code class="p">,</code></span><code> </code><span><code class="n">y</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="n">predictions</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">model</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">X_valid</code></span><span><code class="o">.</code></span><span><code class="n">iloc</code></span><span><code class="p">[</code><code class="p">:</code><code class="p">,</code></span><code> </code><span><code class="p">[</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">bend_index</code></span><span><code class="p">]</code><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">mean_squared_error</code></span><span><code class="p">(</code></span><span><code class="n">y_valid</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">predictions</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><span><code class="k">for</code></span><code> </code><span><code class="n">fold</code></span><span><code class="p">,</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">train_idx</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">valid_idx</code></span><span><code class="p">)</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">enumerate</code></span><span><code class="p">(</code></span><span><code class="n">kf</code></span><span><code class="o">.</code></span><span><code class="n">split</code></span><span><code class="p">(</code></span><span><code class="n">X_train</code></span><span><code class="p">)</code><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="n">cv_X_train</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">cv_X_valid</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">X_train</code></span><span><code class="o">.</code></span><span><code class="n">iloc</code></span><span><code class="p">[</code></span><span><code class="n">train_idx</code></span><span><code class="p">,</code></span><code> </code><span><code class="p">:</code><code class="p">]</code><code class="p">,</code></span><code>&#13;
</code><code>                              </code><span><code class="n">X_train</code></span><span><code class="o">.</code></span><span><code class="n">iloc</code></span><span><code class="p">[</code></span><span><code class="n">valid_idx</code></span><span><code class="p">,</code></span><code> </code><span><code class="p">:</code><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="n">cv_Y_train</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">cv_Y_valid</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">(</code></span><span><code class="n">y_train</code></span><span><code class="o">.</code></span><span><code class="n">iloc</code></span><span><code class="p">[</code></span><span><code class="n">train_idx</code></span><span><code class="p">]</code><code class="p">,</code></span><code>&#13;
</code><code>                              </code><span><code class="n">y_train</code></span><span><code class="o">.</code></span><span><code class="n">iloc</code></span><span><code class="p">[</code></span><span><code class="n">valid_idx</code></span><span><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><code>    </code><span><code class="n">error_bend</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><code>&#13;
</code><code>        </code><span><code class="n">validate_bend_model</code></span><span><code class="p">(</code></span><code>&#13;
</code><code>            </code><span><code class="n">cv_X_train</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">cv_Y_train</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">cv_X_valid</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">cv_Y_valid</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">bend_index</code></span><code>&#13;
</code><code>        </code><span><code class="p">)</code></span><code>&#13;
</code><code>        </code><span><code class="k">for</code></span><code> </code><span><code class="n">bend_index</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">range</code></span><span><code class="p">(</code></span><span><code class="mi">1</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">31</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="p">]</code></span><code>&#13;
</code><code>&#13;
</code><code>    </code><span><code class="n">validation_errors</code></span><span><code class="p">[</code></span><span><code class="n">fold</code></span><span><code class="p">]</code><code class="p">[</code><code class="p">:</code><code class="p">]</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">error_bend</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Then we find the mean validation error across the three folds and plot them against the location of the bend:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">totals</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">validation_errors</code></span><span><code class="o">.</code></span><span><code class="n">mean</code></span><span><code class="p">(</code></span><span><code class="n">axis</code></span><span><code class="o">=</code></span><span><code class="mi">0</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<figure class="informal width-70"><div class="figure"><img src="assets/leds_16in08.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The MSE looks quite flat for 57 to 60 degrees. The minimum occurs at 58, so we choose that model. To assess this model on the test set, we first fit the bent line model at 58 degrees on the entire train set:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">bent_final</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><code>&#13;
</code><code>    </code><span><code class="n">X_train</code></span><span><code class="o">.</code></span><span><code class="n">loc</code></span><span><code class="p">[</code><code class="p">:</code><code class="p">,</code></span><code> </code><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">temp</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">temp58p</code><code class="s2">"</code></span><span><code class="p">]</code><code class="p">]</code><code class="p">,</code></span><code> </code><span><code class="n">y_train</code></span><code>&#13;
</code><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Then we use the fitted model to predict gas consumption for the test set:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">y_pred_test</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">bent_final</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">X_test</code></span><span><code class="o">.</code></span><span><code class="n">loc</code></span><span><code class="p">[</code><code class="p">:</code><code class="p">,</code></span><code> </code><span><code class="p">[</code></span><span><code class="s2">"</code><code class="s2">temp</code><code class="s2">"</code></span><span><code class="p">,</code></span><code> </code><span><code class="s2">"</code><code class="s2">temp58p</code><code class="s2">"</code></span><span><code class="p">]</code><code class="p">]</code><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">mean_squared_error</code></span><span><code class="p">(</code></span><span><code class="n">y_test</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">y_pred_test</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell_output docutils container">&#13;
<div class="output text_plain highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
71.40781435952441&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Let’s overlay the bent-line fit on the scatterplot and examine the residuals to get an idea as to the quality of the fit:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_16in09.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The fitted curve looks reasonable, and the residuals are much smaller than those from the polynomial fit.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>For teaching<a contenteditable="false" data-primary="GridSearchCV" data-type="indexterm" id="id1666"/><a contenteditable="false" data-primary="Pipeline object" data-type="indexterm" id="id1667"/> purposes in this section, we use <code>KFold</code> to manually split up the training data into three folds, then find the model validation errors using a loop. In practice, we suggest using <code>sklearn.model_selection.GridSearchCV</code> with an <code>sklearn.pipeline.Pipeline</code> object, which can automatically break the data into training and validation sets and find the model that has the lowest average validation error across the folds.</p>&#13;
</div>&#13;
&#13;
<p>Using cross-validation<a contenteditable="false" data-primary="errors" data-secondary="and cross-validation limitations" data-secondary-sortas="cross-validation limitations" data-type="indexterm" id="id1668"/> to manage model complexity has a couple of critical limitations: typically it requires the complexity to vary discretely, and there may not be a natural way to order the models. Rather than changing the dimensions of a sequence of models, we can fit a large model and apply constraints on the size of the coefficients. This notion is called regularization and is the topic of the next section<a contenteditable="false" data-primary="" data-startref="ix_scikit_kfold" data-type="indexterm" id="id1669"/><a contenteditable="false" data-primary="" data-startref="ix_cross_val_mod_sel" data-type="indexterm" id="id1670"/><a contenteditable="false" data-primary="" data-startref="ix_mod_sel_cross_val" data-type="indexterm" id="id1671"/><a contenteditable="false" data-primary="" data-startref="ix_kfold_class" data-type="indexterm" id="id1672"/><a contenteditable="false" data-primary="" data-startref="ix_kfold_cross_valid3" data-type="indexterm" id="id1673"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Regularization" data-type="sect1"><div class="sect1" id="regularization">&#13;
<h1>Regularization</h1>&#13;
&#13;
<p>We just saw how cross-validation<a contenteditable="false" data-primary="regularization" data-type="indexterm" id="id1674"/><a contenteditable="false" data-primary="model selection" data-secondary="regularization" data-type="indexterm" id="id1675"/><a contenteditable="false" data-primary="overfitting" data-type="indexterm" id="id1676"/><a contenteditable="false" data-primary="fitting the model" data-secondary="overfitting" data-type="indexterm" id="id1677"/> can help find a dimension for a fitted model that balances under- and overfitting. Rather than selecting the dimension of the model, we can build a model with all of the features, but restrict the size of the coefficients. We keep from overfitting by adding to the MSE a penalty term on the size of the coefficients. The penalty, called a <em>regularization term</em>, is <span class="math notranslate nohighlight"><math> <mi>λ</mi> <munderover> <mo>∑</mo> <mrow> <mi>j</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>p</mi> </mrow> </munderover> <msubsup> <mi>θ</mi> <mi>j</mi> <mn>2</mn> </msubsup> </math></span>. We fit the model by minimizing the combination of mean squared error plus this penalty:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mi>i</mi> </msub> <mi mathvariant="bold-italic">θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <mi>λ</mi> <munderover> <mo>∑</mo> <mrow> <mi>j</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>p</mi> </mrow> </munderover> <msubsup> <mi>θ</mi> <mi>j</mi> <mn>2</mn> </msubsup> </math></div>&#13;
</div>&#13;
&#13;
<p>When<a contenteditable="false" data-primary="regularization parameter (λ)" data-type="indexterm" id="id1678"/><a contenteditable="false" data-primary="λ (regularization parameter)" data-type="indexterm" id="id1679"/> the <em>regularization parameter</em>, <span class="math notranslate nohighlight"><math> <mi>λ</mi> </math></span>, is large, it penalizes large coefficients. (We typically choose it by cross-validation.)</p>&#13;
&#13;
<p>Penalizing the square<a contenteditable="false" data-primary="ridge regression" data-type="indexterm" id="id1680"/><a contenteditable="false" data-primary="L₂ regularization" data-type="indexterm" id="id1681"/> of the coefficients is called <span class="math notranslate nohighlight"><math> <msub> <mi>L</mi> <mn>2</mn> </msub> </math></span> regularization, or <em>ridge regression</em>. Another popular regularization penalizes the absolute size of the coefficients:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mtable columnalign="right" displaystyle="true" rowspacing="3pt"> <mtr> <mtd> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">(</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <msub> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mi>i</mi> </msub> <mi mathvariant="bold-italic">θ</mi> <msup> <mo stretchy="false">)</mo> <mn>2</mn> </msup> <mtext> </mtext> <mo>+</mo> <mtext> </mtext> <mi>λ</mi> <munderover> <mo>∑</mo> <mrow> <mi>j</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>p</mi> </mrow> </munderover> <mrow> <mo stretchy="false">|</mo> </mrow> <msub> <mi>θ</mi> <mi>j</mi> </msub> <mo stretchy="false">|</mo> </mtd> </mtr> </mtable> </math></div>&#13;
</div>&#13;
&#13;
<p>This <span class="math notranslate nohighlight"><math> <msub> <mi>L</mi> <mn>1</mn> </msub> </math></span> regularized linear model<a contenteditable="false" data-primary="lasso regression" data-type="indexterm" id="id1682"/> is also called <em>lasso regression</em> (lasso stands for Least Absolute Shrinkage and Selection Operator).</p>&#13;
&#13;
<p>To get an idea about how regularization works, let’s think about the extreme cases: when <span class="math notranslate nohighlight"><math> <mi>λ</mi> </math></span> is really large and when it’s close to 0 (<span class="math notranslate nohighlight"><math> <mi>λ</mi> </math></span> is never negative). With a big regularization parameter, the coefficients are heavily penalized, so they shrink. On the other hand, when <span class="math notranslate nohighlight"><math> <mi>λ</mi> </math></span> is tiny, the coefficients aren’t restricted. In fact, when <span class="math notranslate nohighlight"><math> <mi>λ</mi> </math></span> is 0, we’re back in the world of ordinary least squares. A couple of issues crop up when we think about controlling the size of the coefficients through regularization:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>We do not want to regularize the intercept term. This way, a large penalty fits a constant model.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>When features have very different scales, the penalty can impact them differently, with large-valued features being penalized more than others. To avoid this, we standardize all of the features to have mean 0 and variance 1 before fitting the model.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Let’s look at an example with 35 features.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Model Bias and Variance" data-type="sect1"><div class="sect1" id="model-bias-and-variance">&#13;
<h1>Model Bias and Variance</h1>&#13;
&#13;
<p>In this section<a contenteditable="false" data-primary="variance" data-secondary="and bias" data-secondary-sortas="bias" data-type="indexterm" id="ix_var_bias"/><a contenteditable="false" data-primary="model selection" data-secondary="bias and variance in model" data-type="indexterm" id="ix_mod_sel_bias_var"/><a contenteditable="false" data-primary="bias" data-secondary="and variance in model" data-secondary-sortas="variance in model" data-type="indexterm" id="ix_bias_var_mod"/>, we provide a different way to think about the problem of over- and underfitting. We carry out a simulation study where we generate synthetic data from a model of our design. This way, we know the true model, and we can see how close we get to the truth when we fit models to the data.</p>&#13;
&#13;
<p>We concoct a general model of data as follows:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <mi>y</mi> <mo>=</mo> <mi>g</mi> <mo stretchy="false">(</mo> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mo stretchy="false">)</mo> <mo>+</mo> <mrow> <mi>ϵ</mi> </mrow> </math></div>&#13;
</div>&#13;
&#13;
<p>This expression makes it easy to see the two components of the model: the signal <span class="math notranslate nohighlight"><math> <mi>g</mi> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo> </math></span> and the noise <span class="math notranslate nohighlight"><math> <mi>ϵ</mi> </math></span>. In our model, we assume the noise has no trend or pattern, constant variance, and each observation’s noise is independent of the others’.</p>&#13;
&#13;
<p>As an example, let’s take <span class="math notranslate nohighlight"><math> <mi>g</mi> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo> <mo>=</mo> <mi>sin</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo> <mo>+</mo> <mn>0.3</mn> <mi>x</mi> </math></span> and the noise from a normal curve with center 0 and SD = 0.2. We can generate data from this model with the following <span class="keep-together">functions</span>:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="k">def</code></span><code> </code><span><code class="nf">g</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">sin</code></span><span><code class="p">(</code></span><span><code class="n">x</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="mf">0.3</code></span><code> </code><span><code class="o">*</code></span><code> </code><span><code class="n">x</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="k">def</code></span><code> </code><span><code class="nf">gen_noise</code></span><span><code class="p">(</code></span><span><code class="n">n</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">normal</code></span><span><code class="p">(</code></span><span><code class="n">scale</code></span><span><code class="o">=</code></span><span><code class="mf">0.2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="n">n</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="k">def</code></span><code> </code><span><code class="nf">draw</code></span><span><code class="p">(</code></span><span><code class="n">n</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="n">points</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">choice</code></span><span><code class="p">(</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">arange</code></span><span><code class="p">(</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">10</code></span><span><code class="p">,</code></span><code> </code><span><code class="mf">0.05</code></span><span><code class="p">)</code><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="n">n</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">points</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">g</code></span><span><code class="p">(</code></span><span><code class="n">points</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="n">gen_noise</code></span><span><code class="p">(</code></span><span><code class="n">n</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Let’s generate 50 data points <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>,</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo stretchy="false">)</mo> </math></span>, <span class="math notranslate nohighlight"><math> <mi>i</mi> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo>…</mo> <mo>,</mo> <mn>50</mn> </math></span>, from this model:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">seed</code></span><span><code class="p">(</code></span><span><code class="mi">42</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">xs</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">ys</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">draw</code></span><span><code class="p">(</code></span><span><code class="mi">50</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">noise</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">ys</code></span><code> </code><span><code class="o">-</code></span><code> </code><span><code class="n">g</code></span><span><code class="p">(</code></span><span><code class="n">xs</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We can plot our data, and since we know the true signal, we can find the errors and plot them too:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_16in10.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The plot on the left shows <span class="math notranslate nohighlight"><math> <mi>g</mi> </math></span> as a dashed curve. We can also see that the <span class="math notranslate nohighlight"><math> <mo stretchy="false">(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> </math></span> pairs form a scatter of dots about this curve. The righthand plot shows the errors, <span class="math notranslate nohighlight"><math> <mi>y</mi> <mo>−</mo> <mi>g</mi> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo> </math></span>, for the 50 points. Notice that they do not form a pattern.</p>&#13;
&#13;
<p>When we fit a model to the data, we minimize the mean squared error. Let’s write this minimization in generality:</p>&#13;
&#13;
<div data-type="equation">&#13;
<div class="math notranslate nohighlight"><math display="block"> <munder> <mo movablelimits="true">min</mo> <mrow> <mi>f</mi> <mo>∈</mo> <mrow> <mi mathvariant="script">F</mi> </mrow> </mrow> </munder> <mfrac> <mn>1</mn> <mi>n</mi> </mfrac> <munderover> <mo>∑</mo> <mrow> <mi>i</mi> <mo>=</mo> <mn>1</mn> </mrow> <mrow> <mi>n</mi> </mrow> </munderover> <mo stretchy="false">[</mo> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo> <mi>f</mi> <mo stretchy="false">(</mo> <msub> <mrow> <mi mathvariant="bold">x</mi> </mrow> <mi>i</mi> </msub> <mo stretchy="false">)</mo> <msup> <mo stretchy="false">]</mo> <mn>2</mn> </msup> </math></div>&#13;
</div>&#13;
&#13;
<p>The minimization is over the collection of functions <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">F</mi> </mrow> </math></span>. We have seen in this chapter that this collection of functions might be polynomials of 12 degrees, or simply bent lines. An important point is that the true model, <span class="math notranslate nohighlight"><math> <mi>g</mi> </math></span>, doesn’t have to be one of the functions in the collection.</p>&#13;
&#13;
<p>Let’s take <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">F</mi> </mrow> </math></span> to be the collection of second-degree polynomials; in other words, functions that can be expressed as <span class="math notranslate nohighlight"><math> <msub> <mi>θ</mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>θ</mi> <mn>1</mn> </msub> <mi>x</mi> <mo>+</mo> <msub> <mi>θ</mi> <mn>2</mn> </msub> <msup> <mi>x</mi> <mn>2</mn> </msup> </math></span>. Since <span class="math notranslate nohighlight"><math> <mi>g</mi> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo> <mo>=</mo> <mi>sin</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>x</mi> <mo stretchy="false">)</mo> <mo>+</mo> <mn>0.3</mn> <mi>x</mi> </math></span>, it doesn’t belong to the collection of functions that we are optimizing over.</p>&#13;
&#13;
<p>Let’s fit a polynomial to our 50 data points:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">poly</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">PolynomialFeatures</code></span><span><code class="p">(</code></span><span><code class="n">degree</code></span><span><code class="o">=</code></span><span><code class="mi">2</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">include_bias</code></span><span><code class="o">=</code></span><span><code class="kc">False</code></span><span><code class="p">)</code></span><code>&#13;
</code><span><code class="n">poly_features</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">poly</code></span><span><code class="o">.</code></span><span><code class="n">fit_transform</code></span><span><code class="p">(</code></span><span><code class="n">xs</code></span><span><code class="o">.</code></span><span><code class="n">reshape</code></span><span><code class="p">(</code></span><span><code class="o">-</code></span><span><code class="mi">1</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">1</code></span><span><code class="p">)</code><code class="p">)</code></span><code>&#13;
</code><code>&#13;
</code><span><code class="n">model_deg2</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">poly_features</code></span><span><code class="p">,</code></span><code> </code><span><code class="n">ys</code></span><span><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell tag_hide-input docutils container">&#13;
<div class="cell_output docutils container">&#13;
<div class="output stream highlight-myst-ansi notranslate">&#13;
<div class="highlight">&#13;
<pre data-type="programlisting">&#13;
Fitted Model: 0.98 + -0.19x + 0.05x^2&#13;
</pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>Again, we know the true model is not quadratic (because we built it). Let’s plot the data and the fitted curve:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_16in11.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>The quadratic doesn’t fit the data well, and it doesn’t represent the underlying curve well either because the set of models that we are choosing from (second-order polynomials) can’t capture the curvature in <span class="math notranslate nohighlight"><math> <mi>g</mi> </math></span>.</p>&#13;
&#13;
<p>If we repeat this process and generate another 50 points from the true model and fit a second-degree polynomial to these data, then the fitted coefficients of the quadratic will change because it depends on the new set of data. We can repeat this process many times, and average the fitted curves. This average curve will resemble the typical best fit of a second-degree polynomial to 50 points from our true model. To demonstrate this notion, let’s generate 25 sets of 50 data points and fit a quadratic to each dataset:</p>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="k">def</code></span><code> </code><span><code class="nf">fit</code></span><span><code class="p">(</code></span><span><code class="n">n</code></span><span><code class="p">)</code><code class="p">:</code></span><code>&#13;
</code><code>    </code><span><code class="n">xs_new</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">random</code></span><span><code class="o">.</code></span><span><code class="n">choice</code></span><span><code class="p">(</code></span><span><code class="n">np</code></span><span><code class="o">.</code></span><span><code class="n">arange</code></span><span><code class="p">(</code></span><span><code class="mi">0</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">10</code></span><span><code class="p">,</code></span><code> </code><span><code class="mf">0.05</code></span><span><code class="p">)</code><code class="p">,</code></span><code> </code><span><code class="n">size</code></span><span><code class="o">=</code></span><span><code class="n">n</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="n">ys_new</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">g</code></span><span><code class="p">(</code></span><span><code class="n">xs_new</code></span><span><code class="p">)</code></span><code> </code><span><code class="o">+</code></span><code> </code><span><code class="n">gen_noise</code></span><span><code class="p">(</code></span><span><code class="n">n</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="n">X_new</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">xs_new</code></span><span><code class="o">.</code></span><span><code class="n">reshape</code></span><span><code class="p">(</code></span><span><code class="o">-</code></span><span><code class="mi">1</code></span><span><code class="p">,</code></span><code> </code><span><code class="mi">1</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="n">mod_new</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="n">LinearRegression</code></span><span><code class="p">(</code><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="n">poly</code></span><span><code class="o">.</code></span><span><code class="n">fit_transform</code></span><span><code class="p">(</code></span><span><code class="n">X_new</code></span><span><code class="p">)</code><code class="p">,</code></span><code> </code><span><code class="n">ys_new</code></span><span><code class="p">)</code></span><code>&#13;
</code><code>    </code><span><code class="k">return</code></span><code> </code><span><code class="n">mod_new</code></span><span><code class="o">.</code></span><span><code class="n">predict</code></span><span><code class="p">(</code></span><span><code class="n">poly_features_x_full</code></span><span><code class="p">)</code></span><span><code class="o">.</code></span><span><code class="n">flatten</code></span><span><code class="p">(</code><code class="p">)</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<div class="cell docutils container">&#13;
<div class="cell_input docutils container">&#13;
<div class="highlight-ipython3 notranslate">&#13;
<div class="highlight">&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<span><code class="n">fits</code></span><code> </code><span><code class="o">=</code></span><code> </code><span><code class="p">[</code></span><span><code class="n">fit</code></span><span><code class="p">(</code></span><span><code class="mi">50</code></span><span><code class="p">)</code></span><code> </code><span><code class="k">for</code></span><code> </code><span><code class="n">j</code></span><code> </code><span><code class="ow">in</code></span><code> </code><span><code class="nb">range</code></span><span><code class="p">(</code></span><span><code class="mi">25</code></span><span><code class="p">)</code><code class="p">]</code></span><code>&#13;
</code></pre>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
</div>&#13;
&#13;
<p>We can show on a plot all 25 fitted models along with the true function, <span class="math notranslate nohighlight"><math> <mi>g</mi> </math></span>, and the average of the fitted curves, <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>f</mi> <mo stretchy="false">¯</mo> </mover> </mrow> </math></span>. To do this, we use transparency for the 25 fitted models to distinguish overlapping curves:</p>&#13;
&#13;
<figure class="informal width-60"><div class="figure"><img src="assets/leds_16in12.png"/>&#13;
&#13;
</div></figure>&#13;
&#13;
<p>We can see that the 25 fitted quadratics vary with the data. This concept is called<a contenteditable="false" data-primary="variation" data-secondary="model" data-type="indexterm" id="id1683"/><a contenteditable="false" data-primary="model variation" data-type="indexterm" id="id1684"/><a contenteditable="false" data-primary="model bias" data-type="indexterm" id="id1685"/> <em>model variation</em>. The average of the 25 quadratics is represented by the solid black line. The difference between the average quadratic and the true curve is called the <em>model bias</em>.</p>&#13;
&#13;
<p>When the signal, <span class="math notranslate nohighlight"><math> <mi>g</mi> </math></span>, does not belong to the model space, <span class="math notranslate nohighlight"><math> <mrow> <mi mathvariant="script">F</mi> </mrow> </math></span>, we have model bias. If the model space can approximate <span class="math notranslate nohighlight"><math> <mi>g</mi> </math></span> well, then the bias is small. For instance, a 10-degree polynomial can get pretty close to the <span class="math notranslate nohighlight"><math> <mi>g</mi> </math></span> used in our example. On the other hand, we have seen earlier in this chapter that higher-degree polynomials can overfit the data and vary a lot trying to get close to the data. The more complex the model space, the greater the variability in the fitted model. Underfitting with too simple a model can lead to high model bias (the difference between <span class="math notranslate nohighlight"><math> <mi>g</mi> </math></span> and <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>f</mi> <mo stretchy="false">¯</mo> </mover> </mrow> </math></span>), and overfitting with too complex a model can result in high model variance (the fluctuations of <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>f</mi> <mo stretchy="false">^</mo> </mover> </mrow> </math></span> around <span class="math notranslate nohighlight"><math> <mrow> <mover> <mi>f</mi> <mo stretchy="false">¯</mo> </mover> </mrow> </math></span>). This notion<a contenteditable="false" data-primary="bias–variance trade-off" data-type="indexterm" id="ix_bias_var_trade"/> is called the <em>bias-variance trade-off</em>. Model selection aims to balance these competing sources of a lack of fit<a contenteditable="false" data-primary="" data-startref="ix_var_bias" data-type="indexterm" id="id1686"/><a contenteditable="false" data-primary="" data-startref="ix_bias_var_mod" data-type="indexterm" id="id1687"/><a contenteditable="false" data-primary="" data-startref="ix_mod_sel_bias_var" data-type="indexterm" id="id1688"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="sec-ms-summary">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>In this chapter, we saw that problems arise when we minimize mean squared error to both fit a model and evaluate it. The train-test split helps us get around this problem, where we fit a model with the train set and evaluate our fitted model on test data that have been set aside.</p>&#13;
&#13;
<p>It’s important to not “overuse” the test set, so we keep it separate until we have committed to a model. To help us commit, we might use cross-validation, which imitates the division of data into test and train sets. Again, it’s important to cross-validate using only the train set and keep the original test set away from any model selection process.</p>&#13;
&#13;
<p>Regularization takes a different approach<a contenteditable="false" data-primary="regularization" data-type="indexterm" id="id1689"/> and penalizes the mean squared error to keep the model from fitting the data too closely. In regularization, we use all of the data available to fit the model, but shrink the size of the coefficients.</p>&#13;
&#13;
<p>The bias-variance trade-off allows us to more precisely describe the modeling phenomena that we have seen in this chapter: underfitting relates to model bias; overfitting results in model variance. In <a class="reference internal" data-type="xref" href="#model-bias-variance-diagram">Figure 16-4</a>, the x-axis measures model complexity and the y-axis measures these two components of model misfit: model bias and model variance. Notice that as the complexity of the model being fit increases, model bias decreases and model variance increases. Thinking in terms of test error, we have seen this error first decrease and then increase as the model variance outweighs the decrease in model bias. To select a useful model, we must strike a balance between model bias and variance.</p>&#13;
&#13;
<figure><div class="figure" id="model-bias-variance-diagram"><img src="assets/leds_1604.png"/>&#13;
<h6><span class="label">Figure 16-4. </span>Bias-variance trade-off</h6>&#13;
</div></figure>&#13;
&#13;
<p>Collecting more observations reduces bias if the model can fit the population process exactly. If the model is inherently incapable of modeling the population (as in our synthetic example), even infinite data cannot get rid of model bias. In terms of variance, collecting more data also reduces variance. One recent trend in data science is to select a model with low bias and high intrinsic variance (such as a neural network) but to collect many data points so that the model variance is low enough to make accurate predictions. While effective in practice, collecting enough data for these models tends to require large amounts of time and money.</p>&#13;
&#13;
<p>Creating more features, whether useful or not, typically increases model variance. Models with many parameters have many possible combinations of parameters and therefore have higher variance than models with few parameters. On the other hand, adding a useful feature to the model, such as a quadratic feature when the underlying process is quadratic, reduces bias. But even adding a useless feature rarely increases bias.</p>&#13;
&#13;
<p>Being aware of the bias-variance trade-off can help you do a better job of fitting models. And using techniques like the train-test split, cross-validation, and regularization can ameliorate this issue<a contenteditable="false" data-primary="" data-startref="ix_mod_sel_ch16" data-type="indexterm" id="id1690"/><a contenteditable="false" data-primary="" data-startref="ix_bias_var_trade" data-type="indexterm" id="id1691"/>.</p>&#13;
&#13;
<p>Another part of modeling considers the variation in the fitted coefficients and curve. We might want to provide a confidence interval for a coefficient or a prediction band for a future observation. These intervals and bands give a sense of the accuracy of the fitted model. We discuss this notion next.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id1643"><sup><a href="ch16.html#id1643-marker">1</a></sup> These data are from Daniel T. Kaplan (CreateSpace Independent Publishing Platform, 2009).</p></div></div></section></body></html>