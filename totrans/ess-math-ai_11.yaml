- en: Chapter 11\. Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Probability theory is one of the most beautiful subjects in mathematics, moving
    us back and forth between the stochastic and deterministic realms in what should
    be magic but turns out to be mathematics and its wonders. Probability provides
    a systematic way to quantify randomness, control uncertainty, and extend logic
    and reasoning to situations which are of paramount importance in AI: When information
    and knowledge include uncertainties, and/or when the agent navigates unpredictable
    or partially observed environments. In such settings, an agent calculates probabilities
    about the unobserved aspects of a certain environment, then make decisions based
    on these probabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: Humans are uncomfortable with uncertainty, but are comfortable with approximations
    and expectations. They do not wake up knowing exactly how every moment of their
    day will play out, and they make decisions along the way. A probabilistic intelligent
    machine exists in a world of probabilities as opposed to deterministic and fully
    predetermined truths and falsehoods.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, we have used probability theory terms and techniques as
    they came along and only when we needed them. Through this process, we now realize
    that we need to be well versed in joint probability distributions (for example,
    of features of data), conditioning, independence, Bayes theorem, and Markov processes.
    We also realize that we can get back to the deterministic world via computing
    averages and expectations.
  prefs: []
  type: TYPE_NORMAL
- en: 'One feature of the chapters of this book is that each needs its own book to
    have an in-depth and comprehensive treatment. This couldn’t be more true than
    for a chapter on probability theory, where there are thousands of topics to include.
    I had to make choices, so I based the topics that I opted to cover in this chapter
    on three criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: What we already used in this book that has to do with probability.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What confused me the most in probability as a student (like why do we need measure
    theory when computing probabilities?).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What else we need to know from probability theory for AI applications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Where Did Probability Appear In This Book?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s make a fast list of the places where we used probability or resorted to
    stochastic methods in this book. We consider this list as the *essential probability
    for AI*. Note that *prior* probabilities are unconditional, because they are prior
    to observing the data, or the evidence, and *posterior* probabilities are conditional,
    because their value is conditioned on observing the relevant data. It makes sense
    that our degree of belief about something changes after receiving new and related
    evidence. The joint probability distribution of all the involved variables is
    what we are usually after, but it is generally too large and the information needed
    to fully construct it is not always available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the list:'
  prefs: []
  type: TYPE_NORMAL
- en: When minimizing the loss function of deterministic machine learning models,
    such as regression, support vector machines, neural networks, *etc.*, we use stochastic
    gradient descent and its variants, randomly choosing a subset of training data
    instances at each gradient descent step, as opposed to using the whole training
    data set, in order to speed up computations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In [Chapter 9](ch09.xhtml#ch09) on graph models, we utilized random walks on
    graphs on many occasions, implementing these walks via the weighted adjacency
    matrix of the graph.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specific probability distributions appeared in [Chapter 10](ch10.xhtml#ch10)
    on operations research, such as probability distributions for interarrival and
    service times for customers in a queue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Dynamic decision making and Markov processes also appeared in [Chapter 10](ch10.xhtml#ch10)
    on Operations research and are fundamental for reinforcement learning in AI. They
    will appear again in this chapter then once more in [Chapter 13](ch13.xhtml#ch13)
    in the context of the Hamilton Jacobi Bellman equation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For two person zero sum games in [Chapter 10](ch10.xhtml#ch10), each player
    had a probability of making a certain move, and we used that to compute the player’s
    optimal strategy and expected payoff.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Monte Carlo simulation methods are computational algorithms that rely on repeated
    random sampling to solve deterministic problems numerically. We illustrate an
    example of these in [Chapter 13](ch13.xhtml#ch13) on AI and PDEs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Universality theorem for neural networks: We mentioned this many times and
    we will prove it in this chapter. This proof is the only theoretical part in this
    book and it will give us a nice flavor of measure theory and functional analysis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Probabilistic machine learning models learn the joint probability distribution
    of the data features <math alttext="upper P r o b left-parenthesis x 1 comma x
    2 comma ellipsis comma x Subscript n Baseline comma y Subscript t a r g e t Baseline
    right-parenthesis"><mrow><mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>,</mo>
    <msub><mi>y</mi> <mrow><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi></mrow></msub>
    <mo>)</mo></mrow></math> instead of learning deterministic functions of these
    features. This joint probability distribution encodes the likelihood of these
    features occuring at the same time. Given the input data features <math alttext="left-parenthesis
    x 1 comma x 2 comma ellipsis comma x Subscript n Baseline right-parenthesis"><mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>)</mo></mrow></math>
    , the model outputs the conditional probability of the target variable given the
    data features <math alttext="upper P r o b left-parenthesis y Subscript p r e
    d i c t Baseline vertical-bar x 1 comma x 2 comma ellipsis comma x Subscript n
    Baseline right-parenthesis"><mrow><mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi>
    <mo>(</mo> <msub><mi>y</mi> <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>|</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>)</mo></mrow></math>
    as opposed to outputting <math alttext="y Subscript p r e d i c t"><msub><mi>y</mi>
    <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi></mrow></msub></math>
    as a deterministic function of the features: <math alttext="y Subscript p r e
    d i c t Baseline equals f left-parenthesis x 1 comma x 2 comma ellipsis comma
    x Subscript n Baseline right-parenthesis"><mrow><msub><mi>y</mi> <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>x</mi>
    <mi>n</mi></msub> <mo>)</mo></mrow></mrow></math> .'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Random variables and the two most important quantities associated with them,
    namely the expectation (expected average value of the random variable) and variance
    (a measure of the spread around the average): We have been using those without
    formally defining them. We will define them in this chapter.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The product rule or the chain rule for probability, namely
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis x 1 comma x 2 right-parenthesis
    equals upper P r o b left-parenthesis x 1 vertical-bar x 2 right-parenthesis upper
    P r o b left-parenthesis x 2 right-parenthesis equals upper P r o b left-parenthesis
    x 2 vertical-bar x 1 right-parenthesis upper P r o b left-parenthesis x 1 right-parenthesis
    dollar-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>|</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mi>r</mi>
    <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>|</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mi>P</mi> <mi>r</mi> <mi>o</mi>
    <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'or for more than two variables, say three without loss of generality:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartLayout 1st Row 1st Column upper P r o b left-parenthesis
    x 1 comma x 2 comma x 3 right-parenthesis 2nd Column equals upper P r o b left-parenthesis
    x 1 vertical-bar x 2 comma x 3 right-parenthesis upper P r o b left-parenthesis
    x 2 comma x 3 right-parenthesis 2nd Row 1st Column Blank 2nd Column equals upper
    P r o b left-parenthesis x 1 vertical-bar x 2 comma x 3 right-parenthesis upper
    P r o b left-parenthesis x 2 vertical-bar x 3 right-parenthesis upper P r o b
    left-parenthesis x 3 right-parenthesis EndLayout dollar-sign"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mrow><mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>|</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>3</mn></msub> <mo>)</mo></mrow> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>3</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mo>=</mo>
    <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>|</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>3</mn></msub> <mo>)</mo></mrow> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>|</mo> <msub><mi>x</mi>
    <mn>3</mn></msub> <mo>)</mo></mrow> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The concepts of independence and conditional independence are fundamental. Two
    events are independent if the occurrence of one does not affect the probability
    of occurrence of the other. Independence of the considered features is tremendously
    simplifying. It helps us disentangle complex joint distributions of many variables,
    reducing them to simple products of fewer variables, and rendering many previously
    intractable computations tractable. This greatly simplifies the probabilistic
    intrepretations of the world. Pay attention to the difference between independence
    of *only two events* ( <math alttext="upper P r o b left-parenthesis x 1 comma
    x 2 right-parenthesis equals upper P r o b left-parenthesis x 1 right-parenthesis
    upper P r o b left-parenthesis x 2 right-parenthesis"><mrow><mi>P</mi> <mi>r</mi>
    <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mi>r</mi>
    <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow>
    <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></mrow></math> ) and independence of *many
    events*, which is a strong assumption where every event is independent of any
    intersection of the other events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For probabilistic generative models for [Chapter 8](ch08.xhtml#ch08), we assumed
    a prior probability distribution, passed it through a neural network, and adjusted
    its parameters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Bayes theorem is essential when discussing joint and conditional probabilities.
    It helps us quantify an agent’s beliefs relative to evidence. We use it in many
    contexts, which immediately illustrate its usefulness, such as:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis d i s e a s e vertical-bar
    s y m p t o m s right-parenthesis equals StartFraction upper P r o b left-parenthesis
    s y m p t o m s vertical-bar d i s e a s e right-parenthesis upper P r o b left-parenthesis
    d i s e a s e right-parenthesis Over upper P r o b left-parenthesis s y m p t
    o m s right-parenthesis EndFraction dollar-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>o</mi>
    <mi>b</mi> <mrow><mo>(</mo> <mi>d</mi> <mi>i</mi> <mi>s</mi> <mi>e</mi> <mi>a</mi>
    <mi>s</mi> <mi>e</mi> <mo>|</mo> <mi>s</mi> <mi>y</mi> <mi>m</mi> <mi>p</mi> <mi>t</mi>
    <mi>o</mi> <mi>m</mi> <mi>s</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>s</mi><mi>y</mi><mi>m</mi><mi>p</mi><mi>t</mi><mi>o</mi><mi>m</mi><mi>s</mi><mo>|</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>e</mi><mi>a</mi><mi>s</mi><mi>e</mi><mo>)</mo><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>e</mi><mi>a</mi><mi>s</mi><mi>e</mi><mo>)</mo></mrow>
    <mrow><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>s</mi><mi>y</mi><mi>m</mi><mi>p</mi><mi>t</mi><mi>o</mi><mi>m</mi><mi>s</mi><mo>)</mo></mrow></mfrac></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: or
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis t a r g e t vertical-bar
    d a t a right-parenthesis equals StartFraction upper P r o b left-parenthesis
    d a t a vertical-bar t a r g e t right-parenthesis upper P r o b left-parenthesis
    t a r g e t right-parenthesis Over upper P r o b left-parenthesis d a t a right-parenthesis
    EndFraction dollar-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo>
    <mi>t</mi> <mi>a</mi> <mi>r</mi> <mi>g</mi> <mi>e</mi> <mi>t</mi> <mo>|</mo> <mi>d</mi>
    <mi>a</mi> <mi>t</mi> <mi>a</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>|</mo><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mo>)</mo><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mo>)</mo></mrow>
    <mrow><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>)</mo></mrow></mfrac></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: or
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis t a r g e t vertical-bar
    e v i d e n c e right-parenthesis equals StartFraction upper P r o b left-parenthesis
    e v i d e n c e vertical-bar t a r g e t right-parenthesis upper P r o b left-parenthesis
    t a r g e t right-parenthesis Over upper P r o b left-parenthesis e v i d e n
    c e right-parenthesis EndFraction period dollar-sign"><mrow><mi>P</mi> <mi>r</mi>
    <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <mi>t</mi> <mi>a</mi> <mi>r</mi> <mi>g</mi>
    <mi>e</mi> <mi>t</mi> <mo>|</mo> <mi>e</mi> <mi>v</mi> <mi>i</mi> <mi>d</mi> <mi>e</mi>
    <mi>n</mi> <mi>c</mi> <mi>e</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>e</mi><mi>v</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi><mo>|</mo><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mo>)</mo><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mo>)</mo></mrow>
    <mrow><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>e</mi><mi>v</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi><mo>)</mo></mrow></mfrac>
    <mo>.</mo></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: or
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis c a u s e vertical-bar
    e f f e c t right-parenthesis equals StartFraction upper P r o b left-parenthesis
    e f f e c t vertical-bar c a u s e right-parenthesis upper P r o b left-parenthesis
    c a u s e right-parenthesis Over upper P r o b left-parenthesis e f f e c t right-parenthesis
    EndFraction period dollar-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi>
    <mrow><mo>(</mo> <mi>c</mi> <mi>a</mi> <mi>u</mi> <mi>s</mi> <mi>e</mi> <mo>|</mo>
    <mi>e</mi> <mi>f</mi> <mi>f</mi> <mi>e</mi> <mi>c</mi> <mi>t</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>e</mi><mi>f</mi><mi>f</mi><mi>e</mi><mi>c</mi><mi>t</mi><mo>|</mo><mi>c</mi><mi>a</mi><mi>u</mi><mi>s</mi><mi>e</mi><mo>)</mo><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>c</mi><mi>a</mi><mi>u</mi><mi>s</mi><mi>e</mi><mo>)</mo></mrow>
    <mrow><mi>P</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>(</mo><mi>e</mi><mi>f</mi><mi>f</mi><mi>e</mi><mi>c</mi><mi>t</mi><mo>)</mo></mrow></mfrac>
    <mo>.</mo></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that in the last formula, <math alttext="upper P r o b left-parenthesis
    c a u s e vertical-bar e f f e c t right-parenthesis"><mrow><mi>P</mi> <mi>r</mi>
    <mi>o</mi> <mi>b</mi> <mo>(</mo> <mi>c</mi> <mi>a</mi> <mi>u</mi> <mi>s</mi> <mi>e</mi>
    <mo>|</mo> <mi>e</mi> <mi>f</mi> <mi>f</mi> <mi>e</mi> <mi>c</mi> <mi>t</mi> <mo>)</mo></mrow></math>
    quantifies the *diagonistic* direction, while <math alttext="upper P r o b left-parenthesis
    e f f e c t vertical-bar c a u s e right-parenthesis"><mrow><mi>P</mi> <mi>r</mi>
    <mi>o</mi> <mi>b</mi> <mo>(</mo> <mi>e</mi> <mi>f</mi> <mi>f</mi> <mi>e</mi> <mi>c</mi>
    <mi>t</mi> <mo>|</mo> <mi>c</mi> <mi>a</mi> <mi>u</mi> <mi>s</mi> <mi>e</mi> <mo>)</mo></mrow></math>
    quantifies the *causal* direction.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Bayesian networks are data structures that represent dependencies among variables.
    Here, we summarize the variable relationships in a directed graph and use that
    to determine which conditional probability tables we need to keep track of and
    update in the light of new evidence: We keep track of the probability of a child
    node conditional on observing its parents. The parents of a node are any variables
    that directly influence this node. In this sense, the Bayesian network is a represenation
    of the joint probability distribution, with the simplification that we know how
    the involved variables relate to each other (which variables are the parents of
    which variables):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis x 1 comma x 2 comma
    ellipsis comma x Subscript n Baseline right-parenthesis equals normal upper Pi
    Subscript i equals 1 Superscript n Baseline upper P r o b left-parenthesis x Subscript
    i Baseline vertical-bar p a r e n t s left-parenthesis upper X Subscript i Baseline
    right-parenthesis right-parenthesis dollar-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>o</mi>
    <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>x</mi> <mi>n</mi></msub>
    <mo>)</mo></mrow> <mo>=</mo> <msubsup><mi>Π</mi> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>|</mo> <mi>p</mi> <mi>a</mi> <mi>r</mi>
    <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>s</mi> <mrow><mo>(</mo> <msub><mi>X</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In machine learning we can draw a line between regression models and classification
    models. In [Chapter 8](ch08.xhtml#ch08) on probabilistic generative models, we
    encountered a popular probabilistic model for classification: Naive Bayes. In
    cause effects language, the *naive* assumption is that some observed multiple
    effects are independent given a cause, so that we can write:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis c a u s e vertical-bar
    e f f e c t 1 comma e f f e c t 2 comma e f f e c t 3 right-parenthesis equals
    upper P left-parenthesis c a u s e right-parenthesis upper P left-parenthesis
    e f f e c t 1 vertical-bar c a u s e right-parenthesis upper P left-parenthesis
    e f f e c t 2 vertical-bar c a u s e right-parenthesis upper P left-parenthesis
    e f f e c t 3 vertical-bar c a u s e right-parenthesis dollar-sign"><mrow><mi>P</mi>
    <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <mi>c</mi> <mi>a</mi> <mi>u</mi>
    <mi>s</mi> <mi>e</mi> <mo>|</mo> <mi>e</mi> <mi>f</mi> <mi>f</mi> <mi>e</mi> <mi>c</mi>
    <msub><mi>t</mi> <mn>1</mn></msub> <mo>,</mo> <mi>e</mi> <mi>f</mi> <mi>f</mi>
    <mi>e</mi> <mi>c</mi> <msub><mi>t</mi> <mn>2</mn></msub> <mo>,</mo> <mi>e</mi>
    <mi>f</mi> <mi>f</mi> <mi>e</mi> <mi>c</mi> <msub><mi>t</mi> <mn>3</mn></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>c</mi> <mi>a</mi>
    <mi>u</mi> <mi>s</mi> <mi>e</mi> <mo>)</mo></mrow> <mi>P</mi> <mrow><mo>(</mo>
    <mi>e</mi> <mi>f</mi> <mi>f</mi> <mi>e</mi> <mi>c</mi> <msub><mi>t</mi> <mn>1</mn></msub>
    <mo>|</mo> <mi>c</mi> <mi>a</mi> <mi>u</mi> <mi>s</mi> <mi>e</mi> <mo>)</mo></mrow>
    <mi>P</mi> <mrow><mo>(</mo> <mi>e</mi> <mi>f</mi> <mi>f</mi> <mi>e</mi> <mi>c</mi>
    <msub><mi>t</mi> <mn>2</mn></msub> <mo>|</mo> <mi>c</mi> <mi>a</mi> <mi>u</mi>
    <mi>s</mi> <mi>e</mi> <mo>)</mo></mrow> <mi>P</mi> <mrow><mo>(</mo> <mi>e</mi>
    <mi>f</mi> <mi>f</mi> <mi>e</mi> <mi>c</mi> <msub><mi>t</mi> <mn>3</mn></msub>
    <mo>|</mo> <mi>c</mi> <mi>a</mi> <mi>u</mi> <mi>s</mi> <mi>e</mi> <mo>)</mo></mrow></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When the above formula is used for classification given data features, the *cause*
    is the class. Moreover, we can draw a Bayesian network representing this setting.
    The cause variable is the parent node and all the effects are children nodes stemming
    from the one parent node ([Figure 11-1](#Fig_cause_effects)).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![300](assets/emai_1101.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-1\. Bayesian network representing three effects having a common cause.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: What More Do We Need To Know That Is Essential For AI?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need few extra topics that have either not gotten any attention in this
    book or were only mentioned casually and pushed to this chapter for more details.
    These include:'
  prefs: []
  type: TYPE_NORMAL
- en: Judea Pearl’s causal modeling and the do calculus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some Paradoxes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large random matrices and high dimensional probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stochastic processes such as random walks, Brownian motion, and more
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Markov decision processes and reinforcement learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Theory of probability and its use in AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rest of this chapter focuses on the above topics.
  prefs: []
  type: TYPE_NORMAL
- en: Causal Modeling And The Do Calculus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In principle, the arrows between related variables in a Bayesian network can
    point in any direction. They all eventually lead to the same joint probability
    distribution, albeit some in more complicated ways than others.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, causal networks are those special Bayesian networks where the directed
    edges of the graph cannot point in any direction other than the causal direction.
    For these, we have to be more mindful when constructing the connections and their
    directions. [Figure 11-2](#Fig_causal_bayes) shows an example of a causal Bayesian
    network.
  prefs: []
  type: TYPE_NORMAL
- en: '![300](assets/emai_1102.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-2\. Causal Bayesian network.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note that both Bayesian networks and causal networks make strong assumptions
    on which variables listen to which variables.
  prefs: []
  type: TYPE_NORMAL
- en: Agents endowed with causal reasoning are, in human terms, *higher functioning*,
    than those merely observing patterns in the data then making decisions based on
    the relevant patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following distinction is of paramount importance:'
  prefs: []
  type: TYPE_NORMAL
- en: In Bayesian networks, we suffice ourselves with knowing only whether two variables
    are probabilistically dependent. Are fire and smoke probabilistically dependent?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In causal networks, we go further and ask about *which variable responds to
    which variable*: Smoke to fire (so we draw an arrow from fire to smoke in the
    diagram); or fire to smoke (so we draw an arrow from smoke to fire in the diagram)?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What we need here is a mathematical framework for *intervention*, in order
    to quantify the effect of fixing the value of one variable. This is called the
    *do calculus* (as opposed to the statistical *observe and count* calculus). Let’s
    present two fundamental formulas of the *do calculus*:'
  prefs: []
  type: TYPE_NORMAL
- en: The adjustment formula
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The backdoor criterion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: According to [Judea Pearl](https://en.wikipedia.org/wiki/Judea_Pearl), the inventor
    of this wonderful way of causal reasoning, and whose *The Book of Why (2020)*
    inspires the discussion in this section and the next one, these *allow the researcher
    to explore and plot all possible routes up mount intervention, no matter how twisty,*
    and can save us the costs and difficulties of running randomized controlled trials,
    even when these are physically feasible and legally permissible.
  prefs: []
  type: TYPE_NORMAL
- en: 'An alternative: The do calculus'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Given a causal network, which we construct based on a combination of common
    sense and subject matter expertise, while at the same time throwing in extra unknown
    causes for each variable just to be sure that we are accounting for everything,
    the overarching formula is that of the joint probability distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis x 1 comma x 2 comma
    ellipsis comma x Subscript n Baseline right-parenthesis equals normal upper Pi
    Subscript i equals 1 Superscript n Baseline upper P r o b left-parenthesis x Subscript
    i Baseline vertical-bar p a r e n t s left-parenthesis upper X Subscript i Baseline
    right-parenthesis right-parenthesis period dollar-sign"><mrow><mi>P</mi> <mi>r</mi>
    <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>x</mi>
    <mi>n</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <msubsup><mi>Π</mi> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>|</mo> <mi>p</mi> <mi>a</mi> <mi>r</mi>
    <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>s</mi> <mrow><mo>(</mo> <msub><mi>X</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we *intervene*, applying <math alttext="d o left-parenthesis upper X Subscript
    j Baseline equals x Superscript asterisk Baseline right-parenthesis"><mrow><mi>d</mi>
    <mi>o</mi> <mo>(</mo> <msub><mi>X</mi> <mi>j</mi></msub> <mo>=</mo> <msup><mi>x</mi>
    <mo>*</mo></msup> <mo>)</mo></mrow></math> : This severs any edges pointing to
    <math alttext="upper X Subscript j"><msub><mi>X</mi> <mi>j</mi></msub></math>
    , and affects all the conditional probabilities of the descendants of <math alttext="upper
    X Subscript j"><msub><mi>X</mi> <mi>j</mi></msub></math> , leading to a new joint
    probability distribution, which wouldn’t include the conditional probability for
    the intervened variable anymore: We already set its value to <math alttext="upper
    X Subscript j Baseline equals x Superscript asterisk"><mrow><msub><mi>X</mi> <mi>j</mi></msub>
    <mo>=</mo> <msup><mi>x</mi> <mo>*</mo></msup></mrow></math> with probability one,
    and any other value would have probability zero. [Figure 11-2](#Fig_causal_bayes)
    shows how when we set the sprinkler on, all arrows leading to it in the original
    network get severed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus we have:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b Subscript i n t e r v e n e d Baseline
    left-parenthesis x 1 comma x 2 comma ellipsis comma x Subscript n Baseline right-parenthesis
    equals StartLayout 1st Row 1st Column Blank 2nd Column normal upper Pi Subscript
    i not-equals j Superscript n Baseline upper P r o b left-parenthesis x Subscript
    i Baseline vertical-bar p a r e n t s left-parenthesis upper X Subscript i Baseline
    right-parenthesis right-parenthesis if x Subscript j Baseline equals x Superscript
    asterisk Baseline 2nd Row 1st Column Blank 2nd Column 0 otherwise EndLayout dollar-sign"><mrow><mi>P</mi>
    <mi>r</mi> <mi>o</mi> <msub><mi>b</mi> <mrow><mi>i</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>d</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>x</mi> <mi>n</mi></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><msubsup><mi>Π</mi>
    <mrow><mi>i</mi><mo>≠</mo><mi>j</mi></mrow> <mi>n</mi></msubsup> <mi>P</mi> <mi>r</mi>
    <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>|</mo>
    <mi>p</mi> <mi>a</mi> <mi>r</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>s</mi> <mrow><mo>(</mo>
    <msub><mi>X</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow> <mtext>if</mtext>
    <msub><mi>x</mi> <mi>j</mi></msub> <mo>=</mo> <msup><mi>x</mi> <mo>*</mo></msup></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mrow><mn>0</mn> <mtext>otherwise</mtext></mrow></mtd></mtr></mtable></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The adjustment formula
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'What we truly care about is how does setting <math alttext="upper X Subscript
    j Baseline equals x Superscript asterisk"><mrow><msub><mi>X</mi> <mi>j</mi></msub>
    <mo>=</mo> <msup><mi>x</mi> <mo>*</mo></msup></mrow></math> affect the probability
    of every other variable in the network, and we want to compute these from the
    original unintervened network: In math words, without the do operator, since we
    can just observe the data to get these values, as opposed to running new experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To this end, we introduce the *adjustment formula*, or,_controlling for confounders
    (possible common causes): This is a weighted average of the influence of <math
    alttext="upper X Subscript j"><msub><mi>X</mi> <mi>j</mi></msub></math> and its
    parents on <math alttext="upper X Subscript i"><msub><mi>X</mi> <mi>i</mi></msub></math>
    . The weights are the priors on the parent values:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis x Subscript i Baseline
    vertical-bar d o left-parenthesis upper X Subscript j Baseline equals x Superscript
    asterisk Baseline right-parenthesis right-parenthesis equals upper P r o b Subscript
    i n t e r v e n e d Baseline left-parenthesis upper X Subscript i Baseline equals
    x Subscript i Baseline right-parenthesis equals sigma-summation Underscript p
    a r e n t s left-parenthesis upper X Subscript j Baseline right-parenthesis Endscripts
    upper P r o b left-parenthesis x Subscript i Baseline vertical-bar x Superscript
    asterisk Baseline comma p a r e n t s left-parenthesis upper X Subscript j Baseline
    right-parenthesis right-parenthesis upper P r o b left-parenthesis p a r e n t
    s left-parenthesis upper X Subscript j Baseline right-parenthesis right-parenthesis
    dollar-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>|</mo> <mi>d</mi> <mi>o</mi> <mrow><mo>(</mo>
    <msub><mi>X</mi> <mi>j</mi></msub> <mo>=</mo> <msup><mi>x</mi> <mo>*</mo></msup>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mi>r</mi> <mi>o</mi>
    <msub><mi>b</mi> <mrow><mi>i</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>d</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>X</mi> <mi>i</mi></msub> <mo>=</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <msub><mo>∑</mo> <mrow><mi>p</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi><mo>(</mo><msub><mi>X</mi>
    <mi>j</mi></msub> <mo>)</mo></mrow></msub> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>|</mo> <msup><mi>x</mi>
    <mo>*</mo></msup> <mo>,</mo> <mi>p</mi> <mi>a</mi> <mi>r</mi> <mi>e</mi> <mi>n</mi>
    <mi>t</mi> <mi>s</mi> <mrow><mo>(</mo> <msub><mi>X</mi> <mi>j</mi></msub> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo>
    <mi>p</mi> <mi>a</mi> <mi>r</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>s</mi> <mrow><mo>(</mo>
    <msub><mi>X</mi> <mi>j</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Note that the above formula achieves our goal of eliminating the *do* operator
    and gets us back to finding our conditional probabilities by observing the data,
    rather than running some costly intervention experiments, or randomized control
    trials.
  prefs: []
  type: TYPE_NORMAL
- en: The backdoor criterion, or controlling for confounders
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There is more to the causal diagrams story. We would like to know the effect
    of the intervention <math alttext="d o left-parenthesis upper X Subscript j Baseline
    equals x Superscript asterisk Baseline right-parenthesis"><mrow><mi>d</mi> <mi>o</mi>
    <mo>(</mo> <msub><mi>X</mi> <mi>j</mi></msub> <mo>=</mo> <msup><mi>x</mi> <mo>*</mo></msup>
    <mo>)</mo></mrow></math> on a certain *downstream* variable in the diagram <math
    alttext="upper X Subscript d o w n s t r e a m"><msub><mi>X</mi> <mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>m</mi></mrow></msub></math>
    . We should be able to condition on the values of any variable in the diagram
    that is *another ancestor*: This also leads down to the downstream variable that
    we care for. In causal modeling, we call this process *blocking the back doors*
    or the *backdoor criterion*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis x Subscript d o w
    n s t r e a m Baseline vertical-bar d o left-parenthesis upper X Subscript j Baseline
    equals x Superscript asterisk Baseline right-parenthesis right-parenthesis equals
    upper P r o b Subscript i n t e r v e n e d Baseline left-parenthesis upper X
    Subscript d o w n s t r e a m Baseline equals x Subscript d o w n s t r e a m
    Baseline right-parenthesis equals sigma-summation Underscript a n s c e s t o
    r left-parenthesis upper X Subscript d o w n s t r e a m Baseline right-parenthesis
    Endscripts upper P r o b left-parenthesis x Subscript d o w n s t r e a m Baseline
    vertical-bar x Superscript asterisk Baseline comma a n s c e s t o r left-parenthesis
    upper X Subscript d o w n s t r e a m Baseline right-parenthesis right-parenthesis
    upper P r o b left-parenthesis a n s c e s t o r left-parenthesis upper X Subscript
    d o w n s t r e a m Baseline right-parenthesis right-parenthesis dollar-sign"><mrow><mi>P</mi>
    <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>m</mi></mrow></msub>
    <mo>|</mo> <mi>d</mi> <mi>o</mi> <mrow><mo>(</mo> <msub><mi>X</mi> <mi>j</mi></msub>
    <mo>=</mo> <msup><mi>x</mi> <mo>*</mo></msup> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>=</mo> <mi>P</mi> <mi>r</mi> <mi>o</mi> <msub><mi>b</mi> <mrow><mi>i</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>d</mi></mrow></msub>
    <mrow><mo>(</mo> <msub><mi>X</mi> <mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>m</mi></mrow></msub>
    <mo>=</mo> <msub><mi>x</mi> <mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>m</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>=</mo> <msub><mo>∑</mo> <mrow><mi>a</mi><mi>n</mi><mi>s</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo>(</mo><msub><mi>X</mi>
    <mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>m</mi></mrow></msub>
    <mo>)</mo></mrow></msub> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>m</mi></mrow></msub>
    <mo>|</mo> <msup><mi>x</mi> <mo>*</mo></msup> <mo>,</mo> <mi>a</mi> <mi>n</mi>
    <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>o</mi> <mi>r</mi> <mrow><mo>(</mo>
    <msub><mi>X</mi> <mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>m</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mi>P</mi> <mi>r</mi> <mi>o</mi> <mi>b</mi>
    <mrow><mo>(</mo> <mi>a</mi> <mi>n</mi> <mi>s</mi> <mi>c</mi> <mi>e</mi> <mi>s</mi>
    <mi>t</mi> <mi>o</mi> <mi>r</mi> <mrow><mo>(</mo> <msub><mi>X</mi> <mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>m</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Controlling for confounders
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The most common way for scientists and statisticians to predict the effects
    of an intervention, so that they can make statements about causality, is to control
    for *possible common causes*, or confounders. [Figure 11-3](#Fig_confounder) shows
    the variable Z as a confounder of the suspected causal relationship between X
    and Y.
  prefs: []
  type: TYPE_NORMAL
- en: '![300](assets/emai_1103.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-3\. Z is a confounder of the suspected causal relationship between
    X and Y.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This is because, in general, confounding is a main source of confusion between
    mere observation and intervention. It is also the source of the famous *correlation
    is not causation*. This is where we see some bizarre and enternaining examples:
    High temperature is a confounder for ice cream sales and shark attacks (but why
    would anyone study any sort of relationship between ice cream and sharks to start
    with?). The back door criterion and the adjustment formula easily take care of
    confounder obstacles to stipulating about causality.'
  prefs: []
  type: TYPE_NORMAL
- en: We use the adjustment formula to control for confounders if we are confident
    that we have data on a sufficient set of *deconfounder* variables to block all
    the back-door paths between the intervention and the outcome. To do this, we estimate
    the causal effect stratum by stratum from the data, then we compute a weighted
    average of those strata, where each stratum is weighted according to its prevalence
    in the population.
  prefs: []
  type: TYPE_NORMAL
- en: Now without the back-door criterion, statisticians and scientists have no guarantee
    that any adjustment is legitimate. In other words, the back door criterion guarantees
    that the causal effect in each stratum of the deconfounder is in fact the observed
    trend in this stratum.
  prefs: []
  type: TYPE_NORMAL
- en: Are there more rules that eliminate the do operator?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Rules that are able to move us from an expression with the do operator (intervention)
    to an expression without the do operator (observation) are extremely desirable,
    since they eliminate the need to intervene: They allow us to estimate causal effects
    by mere data observation. The adjustment formula and the back door criterion did
    exactly that for us.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Are there more rules? The more ambitious question is: Is there a way to decide
    ahead of time whether a certain causal model lends itself to do operator elimination,
    so that we would know whether the assumptions of the model are sufficient to uncover
    the causal effect from observational data without any intervention? Knowing this
    is huge! For example, if the assumptions of the model are not sufficient to eliminate
    the do operator, then no matter how clever we are, there is no escape from running
    interventional experiment. On the other hand, if we do not have to intervene and
    still estimate causal effects, the savings are spectacular. These alone are worth
    digging more into probabilistic causal modeling and the do calculus.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the gist of Judea Pearl’s do calculus, we always start with a causal
    diagram, and think of conditioning criteria leading to the deletion of of edges
    pointing towards or out from the variable(s) of interest. Pearl’s three rules
    give us the conditions under which:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can insert or delete observations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis y vertical-bar d o
    left-parenthesis x right-parenthesis comma z comma w right-parenthesis equals
    upper P r o b left-parenthesis y vertical-bar d o left-parenthesis x right-parenthesis
    comma w right-parenthesis dollar-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>o</mi>
    <mi>b</mi> <mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>d</mi> <mi>o</mi> <mo>(</mo> <mi>x</mi>
    <mo>)</mo> <mo>,</mo> <mi>z</mi> <mo>,</mo> <mi>w</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi>
    <mi>r</mi> <mi>o</mi> <mi>b</mi> <mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>d</mi> <mi>o</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>,</mo> <mi>w</mi> <mo>)</mo></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can insert or delete interventions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis y vertical-bar d o
    left-parenthesis x right-parenthesis comma d o left-parenthesis z right-parenthesis
    comma w right-parenthesis equals upper P r o b left-parenthesis y vertical-bar
    d o left-parenthesis x right-parenthesis comma w right-parenthesis dollar-sign"><mrow><mi>P</mi>
    <mi>r</mi> <mi>o</mi> <mi>b</mi> <mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>d</mi> <mi>o</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>,</mo> <mi>d</mi> <mi>o</mi> <mo>(</mo> <mi>z</mi>
    <mo>)</mo> <mo>,</mo> <mi>w</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mi>r</mi> <mi>o</mi>
    <mi>b</mi> <mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>d</mi> <mi>o</mi> <mo>(</mo> <mi>x</mi>
    <mo>)</mo> <mo>,</mo> <mi>w</mi> <mo>)</mo></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can exchange interventions with observations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis y vertical-bar d o
    left-parenthesis x right-parenthesis comma d o left-parenthesis z right-parenthesis
    comma w right-parenthesis equals upper P r o b left-parenthesis y vertical-bar
    d o left-parenthesis x right-parenthesis comma z comma w right-parenthesis dollar-sign"><mrow><mi>P</mi>
    <mi>r</mi> <mi>o</mi> <mi>b</mi> <mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>d</mi> <mi>o</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>,</mo> <mi>d</mi> <mi>o</mi> <mo>(</mo> <mi>z</mi>
    <mo>)</mo> <mo>,</mo> <mi>w</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mi>r</mi> <mi>o</mi>
    <mi>b</mi> <mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>d</mi> <mi>o</mi> <mo>(</mo> <mi>x</mi>
    <mo>)</mo> <mo>,</mo> <mi>z</mi> <mo>,</mo> <mi>w</mi> <mo>)</mo></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For more details on the do calculus, see for example [The Do-Calculus Revisited,
    Judea Pearl, Keynote Lecture, August 17, 2012](https://ftp.cs.ucla.edu/pub/stat_ser/r402.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Paradoxes And Diagram Interpretations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI agents need to be able to handle paradoxes. We have all seen cartoons where
    a robot gets into a crazy loop or even physically self dismantles with screws
    and springs flying all around when its logic encounters a paradox. We cannot let
    that happen. Furthermore, paradoxes often appear in very consequential settings,
    such as in the pharmaceutical and medical fields, so it is crucial that we scrutinize
    them under the lens of mathematics and carefully unravel their mysteries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go over three famous paradoxes: *Monty Hall, Berkson, and Simpson*. We
    will view them in the light of diagrams and causal models: Monty Hall and Berkson
    type paradoxes cause confusion due to colliders, while Simpson type paradoxes
    cause confusion due to confounders. An AI agent should be equipped with these
    diagrams as part of its data structure (or with the ability to construct them
    and adjust them), in order to reason properly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Judea Pearl’s *The Book of Why (2020)* puts the following perfectly:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Paradoxes reflect the tensions between causation and association. The tension
    starts because they stand on two different rungs of the Ladder of Causation [observation,
    intervention, counterfactuals] and is aggravated by the fact that human intuition
    operates under the logic of causation, while data conform to the logic of probabilities
    and proportions. Paradoxes arise when we misapply the rules we have learned in
    one realm to the other.*'
  prefs: []
  type: TYPE_NORMAL
- en: Monty Hall Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Suppose you’re on a game show, and you’re given the choice of three doors.
    Behind one door is a car, behind the others, goats. You pick a door, say #1, and
    the host, who knows what’s behind the doors, opens another door, say #3, which
    has a goat. He says to you, ‘Do you want to pick door #2?’ Is it to your advantage
    to switch your choice of doors?*'
  prefs: []
  type: TYPE_NORMAL
- en: The answer is yes, switch doors, because without switching, your proability
    of getting the car is 1/3, and after switching, it jumps up to 2/3! The main thing
    to pay attention to here is that the host *knows* where the car is, and chooses
    to open a door that he knows does not have the car in it.
  prefs: []
  type: TYPE_NORMAL
- en: 'So why would the probability of winning double if we switch from our initial
    choice? Because the host offers new information which we would leverage only if
    we switch from our initial information-less choice:'
  prefs: []
  type: TYPE_NORMAL
- en: Under the no switch strategy
  prefs: []
  type: TYPE_NORMAL
- en: If we initially chose the winning door (probability 1/3), and we do not switch,
    the we win.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we initially chose a losing door (probability 2/3), and we do not switch,
    the we lose.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means that we would win only 1/3 of the time under the no switch strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Under the switch strategy
  prefs: []
  type: TYPE_NORMAL
- en: If we initially chose the winning door (probability 1/3), and we switch from
    it, then we would lose.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we initially chose a losing door (probability 2/3), new information comes
    *pointing to the other losing door*, and we switch, then we would win, because
    the only door left would be the winning door.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means that we would win 2/3 of the time under the switch strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we draw the diagram in [Figure 11-4](#Fig_monty_hall) to represent this
    game, we realize that the door that the host chooses to open has two parents pointing
    towards it: The door you chose and the location of the car.'
  prefs: []
  type: TYPE_NORMAL
- en: '![300](assets/emai_1104.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-4\. Causal diagram for the variables involved in the Monty Hall paradox.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Conditioning on this *collider* changes the probabilities of the parents. It
    creates a spurious dependency between originally independent parents! This is
    similar to us changing our beliefs about the genetic traits of parents once we
    meet one of their children. These are causless correlations, induced when we condition
    on colliders.
  prefs: []
  type: TYPE_NORMAL
- en: Now suppose that the host chooses their door *without knowing* whether it is
    a winning or a losing door. Then switching or nonswitching would not change the
    odds of winning the car, because in this case both you and the host have equal
    chances of winning 1/3 of the time and losing 2/3 of the time. Now when we draw
    the diagram for this totally random and no prior knowledge game, there is no arrow
    between the location of the car and the door that the host chooses to open, so
    your choice of the door and the location of the car *remain independent* even
    after conditioning on the host’s choice.
  prefs: []
  type: TYPE_NORMAL
- en: Berkson’s Paradox
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*In 1946, Joseph Berkson, a biostatistician at the Mayo Clinic, pointed out
    a peculiarity of observational studies conducted in a hospital setting: Even if
    two diseases have no relation to each other in the general population, they can
    appear to be associated among patients in a hospital. In 1979, David Sackett of
    McMaster University, an expert on all sorts of statistical bias, provided strong
    evidence that Berkson’s paradox is real. In one example, he studied two groups
    of diseases: Respiratory and bone. About 7.5 percent of people in the general
    population have a bone disease, and this percentage is independent of whether
    they have respiratory disease. But for hospitalized people with respiratory disease,
    the frequency of bone disease jumps to 25 percent! Sackett called this phenomenon
    “admission rate bias” or “Berkson bias”.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the Monty Hall case, the culprit for the appearance of Berkson paradox
    is a collider diagram, where both originally independent diseases point to hospitalization:
    A patient with both of these diseases is much more likely to be hospitalized than
    a patient with only one of them. When we condition on hospitalization, which is
    the collider, a case of causeless correlation between the initially independent
    variables appears. We are getting used to collider bias now.'
  prefs: []
  type: TYPE_NORMAL
- en: Simpson’s Paradox
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Imagine a paradox whose conclusion, if left to its own devices, is this absurd:
    *When we know the gender of the patient then we should not prescribe the drug,
    because the data shows that the drug is bad for males and is bad for females;
    but if the gender is unknown, then we should prescribe the drug, because the data
    shows that the drug is good for the general population!* This is obviously ridiculous,
    and our first instinct should be to protest: Show me the data!'
  prefs: []
  type: TYPE_NORMAL
- en: We recognize Simpson’s paradox when a trend appears in several groups of the
    population but disappears or reverses when the groups are combined.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first debunk the paradox. It is a simple numerical mistake of how to
    add fractions (or proportions). In summary, when we add fractions, we cannot simply
    add the respective numerators and the denominators:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartFraction upper A Over upper B EndFraction greater-than
    StartFraction a Over b EndFraction and StartFraction upper C Over upper D EndFraction
    greater-than StartFraction c Over d EndFraction right double arrow with stroke
    StartFraction upper A plus upper C Over upper B plus upper D EndFraction greater-than
    StartFraction a plus c Over b plus d EndFraction dollar-sign"><mrow><mfrac><mi>A</mi>
    <mi>B</mi></mfrac> <mo>></mo> <mfrac><mi>a</mi> <mi>b</mi></mfrac> <mtext>and</mtext>
    <mfrac><mi>C</mi> <mi>D</mi></mfrac> <mo>></mo> <mfrac><mi>c</mi> <mi>d</mi></mfrac>
    <mo>⇏</mo> <mfrac><mrow><mi>A</mi><mo>+</mo><mi>C</mi></mrow> <mrow><mi>B</mi><mo>+</mo><mi>D</mi></mrow></mfrac>
    <mo>></mo> <mfrac><mrow><mi>a</mi><mo>+</mo><mi>c</mi></mrow> <mrow><mi>b</mi><mo>+</mo><mi>d</mi></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, suppose that the data shows that:'
  prefs: []
  type: TYPE_NORMAL
- en: 3/40 of the women who took the drug got a heart attack, compared to only 1/20
    of the women who did not take the drug (3/40>1/20);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and that 8/20 of the men who took the drug got a heart attack, compared to 12/40
    of the men who did not take the drug (8/20>12/40).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now when we merge the data for women and men, the inequality reverses direction:
    3/40 > 1/20 and 8/20 > 12/40 but rightfully (3 + 8)/(40 + 20) < (1 + 12)/(20 +
    40). In words: Of the 60 men and women who took the drug, 11 had a heart attack,
    and of the 60 men and women who did not take the drug, 13 had a heart attack.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, we have committed a simple mistake with fractions when we merged the
    data this way. In other words, to solve Simpson’s paradox, we should not merge
    the data by simply adding the numerators and the denominators and expecting the
    inequality to hold. Note that of the 60 people who took the drug, 40 are women
    and 20 are men; while of the 60 people who did not take the drug, 20 are women
    and 40 are men. We are comparing apples and oranges and confounding with gender:
    The gender affects *both* whether the drug is administired and whether a heart
    attack happens. The diagram in [Figure 11-5](#Fig_simpson_paradox) illustrates
    this confounder relationship.'
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_1105.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-5\. Gender is a confounder for both taking the drug and heart attack.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Our strong intuition that something is wrong if we merge proportions naively
    is spot on: If things are fair on a local level everywhere then they are fair
    globally, or if things act a certain way on every local level then we should expect
    them to act that way globally.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is no surprise that this mistake happens so often, as humans did not get
    fractions right until relatively recently. There are ancient texts with mistakes
    manipulating fractions in domains such as inheritance and trade. Our brains’ resistence
    to fractions seems to persist: We learn fractions in seventh grade, and that also
    happens to be the time to which we can trace back the origin of many people’s
    legendary hatred for math.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So what is the correct way to merge the data? Our grade seven wisdom tells
    us to use the common denominator 40 and to condition on gender: For women 3/40>2/40
    and for men 16/40>12/40\. Now since in the general population men and women are
    equally distributed, we should take the average and rightfully conclude that (3/40+16/40)/2>(2/40+12/40)/2,
    that is, the rate of heart attacks in the general population is 23.75 percent
    with the drug, and 17.5 percent without the drug. No magical and illogical reversal
    happened here. Moreover, this drug is pretty bad!'
  prefs: []
  type: TYPE_NORMAL
- en: Large Random Matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most AI applications deal with a vast amount of high dimensional data (big data),
    organized in high dimensional vectors, matrices, or tensors, representing data
    tables, images, natural language, graph networks, and others. A lot of this data
    is noisy or has an intrinsic random nature. In order to process such data, we
    need a mathematical framework that combines probability and statistics, which
    usually deal with *scalar* random variables, with linear algebra, which deals
    with *vectors and matrices*.
  prefs: []
  type: TYPE_NORMAL
- en: The mean and variance are still central ideas, so we find many statements and
    results containing the expectation and variance (uncertainty) of the involved
    high dimensional random variables. Similar to the scalar case, the tricky part
    is controlling the variance, so a lot of work in the literature finds bounds (inequalities)
    on the tails of the random variables’ distributions or how likely it is to find
    a random variable within some distances from its mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we now have matrix valued random variables, many results seek to undertsand
    the behaviours (distributions) of their spectra: Eigenvalues and eigenvectors.'
  prefs: []
  type: TYPE_NORMAL
- en: Examples of random vectors and random matrices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is no wonder the study of large random matrices evolved into its own theory.
    They appear in all sorts of impactful applications, from finance to neuroscience
    to physics and the manufacture of technological devices. The following is only
    a sampling of examples. These are of great implications so there are large mathematical
    communities around each them.
  prefs: []
  type: TYPE_NORMAL
- en: Quantitative finance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One example of a random vector is an investment portfolio in quantitative finance.
    We often need to decide on how to invest in a large number of stocks, whose price
    movement is stochastic, for optimal performance. The investment portfolio itself
    is a large random vector that evolves with time. In the same spirit, the daily
    returns of *nasdaq* stocks (nasdaq contains more than 2500 stocks), is a time
    evolving large random vector.
  prefs: []
  type: TYPE_NORMAL
- en: Neuroscience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another example is from neuroscience: Random matrices appear when modeling
    a network of synaptic connections between neurons in the brain.The number of spikes
    fired by *n* neurons during *t* consecutive time intervals of a certain length
    is an <math alttext="n times t"><mrow><mi>n</mi> <mo>×</mo> <mi>t</mi></mrow></math>
    random matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematical physics: Wigner matrices'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In mathematical physics, particularly in nuclear physics, physicist Eugene Wigner
    introduced random matrices to model the nuclei of heavy atoms and their spectra.
    In a nutshell, he related the spacings between the lines in the spectrum of a
    heavy atom’s nucleus to the spacings between the eigenvalues of a random matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'The deterministic matrix that Wigner started with is the Hamiltonian of the
    system, which is a matrix describing all the interactions between the neutrons
    and protons contained in the nucleus. The task of diagonalizing the Hamiltonian
    to find the energy levels of the nucleus was impossible, so Wigner looked for
    an alternative. He abandoned exactness and determinism altogether and approached
    the question from a probabilistic perspective: Istead of asking *what precisely
    are the energy levels*, he asked questions like:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the probability to find an energy level within a certain interval?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the probability that the distance between two successive energy levels
    is within a certain range?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we replace the Hamiltonian of the system by a purely random matrix with
    the correct symmetry properties? For example, in the case of quantum systems invariant
    under time reversal, the Hamiltonian is a real symmetric matrix (of infinite size).
    In the presence of a magnetic field, the Hamiltonian is a complex, Hermitian matrix
    (the complex analogue of a real symmeteric matric). In the presence of *spin–orbit
    coupling* (a quantum physics term), the Hamiltonian is symplectic (another special
    type of symmetric matrix).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly Wigner type random matrices appear in condesed matter physics, where
    we model the interaction between pairs of atoms or pairs of spins using real symmetric
    Winger matrices. Overall, Wigner matrices are considered *classical* in random
    matrix theory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multivariate statistics: Wishart matrices and covariance'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In multivariate statistics, John Wishart introduced random matrices when he
    wanted to estimate sample covariance matrices of large random vectors. Wishart
    random matrices are also considered classical in random matrix theory. Note that
    a sample covariance matrix is an estimation for the population covariance matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'When dealing with sample covariance matrices, a common setting is that of *n*
    dimensional variables observed *t* times, that is, the original data set is a
    matrix of size <math alttext="n times t"><mrow><mi>n</mi> <mo>×</mo> <mi>t</mi></mrow></math>
    . For example, we might need to estimate the covariance matrix of the returns
    of a large number of assets (using a smaller sample) such as: The daily returns
    of the 2500 stocks of *nasdaq*. If we use 5 years of daily data, given that there
    are 252 trading days in a year, then we have 5 × 252 = 1260 data points for each
    of the 2500 stocks. The original data set would be a matrix of size <math alttext="2500
    times 1260"><mrow><mn>2500</mn> <mo>×</mo> <mn>1260</mn></mrow></math> . This
    is a case where the number of observations is smaller than the number of variables.
    We have other cases where it is the other way around, as well as limiting cases
    where the number of observations and the number of variables are of drastically
    different scales. In all cases, we are interested in the law (probability distribution)
    for the eigenvalues of the sample covariance matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s write the formulas for the entries of the covariance matrix. For one variable
    <math alttext="ModifyingAbove z With right-arrow Subscript 1"><msub><mover accent="true"><mi>z</mi>
    <mo>→</mo></mover> <mn>1</mn></msub></math> (say one stock) with *t* observations
    whose mean (average) is <math alttext="z overbar Subscript 1"><msub><mover accent="true"><mi>z</mi>
    <mo>¯</mo></mover> <mn>1</mn></msub></math> , we have the variance
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign sigma 1 squared equals StartFraction left-parenthesis
    z 1 left-parenthesis 1 right-parenthesis minus z overbar Subscript 1 Baseline
    right-parenthesis squared plus left-parenthesis z 1 left-parenthesis 2 right-parenthesis
    minus z overbar Subscript 1 Baseline right-parenthesis squared plus ellipsis plus
    left-parenthesis z 1 left-parenthesis t right-parenthesis minus z overbar Subscript
    1 Baseline right-parenthesis squared Over t EndFraction dollar-sign"><mrow><msubsup><mi>σ</mi>
    <mn>1</mn> <mn>2</mn></msubsup> <mo>=</mo> <mfrac><mrow><msup><mrow><mo>(</mo><msub><mi>z</mi>
    <mn>1</mn></msub> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow><mo>-</mo><msub><mover
    accent="true"><mi>z</mi> <mo>¯</mo></mover> <mn>1</mn></msub> <mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>+</mo><msup><mrow><mo>(</mo><msub><mi>z</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow><mo>-</mo><msub><mover accent="true"><mi>z</mi>
    <mo>¯</mo></mover> <mn>1</mn></msub> <mo>)</mo></mrow> <mn>2</mn></msup> <mo>+</mo><mo>⋯</mo><mo>+</mo><msup><mrow><mo>(</mo><msub><mi>z</mi>
    <mn>1</mn></msub> <mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>-</mo><msub><mover
    accent="true"><mi>z</mi> <mo>¯</mo></mover> <mn>1</mn></msub> <mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mi>t</mi></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, for each of the *n* variables <math alttext="ModifyingAbove z With
    right-arrow Subscript i"><msub><mover accent="true"><mi>z</mi> <mo>→</mo></mover>
    <mi>i</mi></msub></math> , we have their variance <math alttext="sigma Subscript
    i Superscript 2"><msubsup><mi>σ</mi> <mi>i</mi> <mn>2</mn></msubsup></math> .
    These sit on the diagonal of the covariance matrix. Now each off diagonal <math
    alttext="sigma Subscript i j"><msub><mi>σ</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub></math>
    entry is the covariance of the corresponding pair of variables:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign sigma Subscript i j Baseline equals StartFraction
    left-parenthesis z Subscript i Baseline left-parenthesis 1 right-parenthesis minus
    z overbar Subscript i Baseline right-parenthesis left-parenthesis z Subscript
    j Baseline left-parenthesis 1 right-parenthesis minus z overbar Subscript j Baseline
    right-parenthesis plus left-parenthesis z Subscript i Baseline left-parenthesis
    2 right-parenthesis minus z overbar Subscript i Baseline right-parenthesis left-parenthesis
    z Subscript j Baseline left-parenthesis 2 right-parenthesis minus z overbar Subscript
    j Baseline right-parenthesis plus ellipsis plus left-parenthesis z Subscript i
    Baseline left-parenthesis t right-parenthesis minus z overbar Subscript i Baseline
    right-parenthesis left-parenthesis z Subscript j Baseline left-parenthesis t right-parenthesis
    minus z overbar Subscript j Baseline right-parenthesis Over t EndFraction dollar-sign"><mrow><msub><mi>σ</mi>
    <mrow><mi>i</mi><mi>j</mi></mrow></msub> <mo>=</mo> <mfrac><mrow><mrow><mo>(</mo><msub><mi>z</mi>
    <mi>i</mi></msub> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow><mo>-</mo><msub><mover
    accent="true"><mi>z</mi> <mo>¯</mo></mover> <mi>i</mi></msub> <mo>)</mo></mrow><mrow><mo>(</mo><msub><mi>z</mi>
    <mi>j</mi></msub> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow><mo>-</mo><msub><mover
    accent="true"><mi>z</mi> <mo>¯</mo></mover> <mi>j</mi></msub> <mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><msub><mi>z</mi>
    <mi>i</mi></msub> <mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow><mo>-</mo><msub><mover
    accent="true"><mi>z</mi> <mo>¯</mo></mover> <mi>i</mi></msub> <mo>)</mo></mrow><mrow><mo>(</mo><msub><mi>z</mi>
    <mi>j</mi></msub> <mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow><mo>-</mo><msub><mover
    accent="true"><mi>z</mi> <mo>¯</mo></mover> <mi>j</mi></msub> <mo>)</mo></mrow><mo>+</mo><mo>⋯</mo><mo>+</mo><mrow><mo>(</mo><msub><mi>z</mi>
    <mi>i</mi></msub> <mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>-</mo><msub><mover
    accent="true"><mi>z</mi> <mo>¯</mo></mover> <mi>i</mi></msub> <mo>)</mo></mrow><mrow><mo>(</mo><msub><mi>z</mi>
    <mi>j</mi></msub> <mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>-</mo><msub><mover
    accent="true"><mi>z</mi> <mo>¯</mo></mover> <mi>j</mi></msub> <mo>)</mo></mrow></mrow>
    <mi>t</mi></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The covariance matrix is symmetric and positive definite (has positive eigenvalues).
    The randomness in a covariance matrix usually stems from noisy observations. Since
    measurement noise is inevitable, determining the covariance matrix becomes more
    involved mathematically. Another common issue is that often the samples are not
    independent. Correlated samples introduce some sort of redundancy, so we expect
    that the sample covariance matrix behaves as if we had observed less samples than
    we actually did. We must then analyze the sample covariance matrix in the presence
    of correlated samples.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamical systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Linearized dynamical systems near equilibria ( <math alttext="StartFraction
    d ModifyingAbove x With right-arrow left-parenthesis t right-parenthesis Over
    d t EndFraction equals upper A ModifyingAbove x With right-arrow left-parenthesis
    t right-parenthesis"><mrow><mfrac><mrow><mi>d</mi><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow> <mrow><mi>d</mi><mi>t</mi></mrow></mfrac>
    <mo>=</mo> <mi>A</mi> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mrow><mo>(</mo>
    <mi>t</mi> <mo>)</mo></mrow></mrow></math> ). In the context of chaotic systems,
    we want to understand how a small difference in initial conditions propagates
    as the dynamics unfolds. One approach is to linearize the dynamics in the vicinity
    of the unperturbed trajectory. The perturbation evolves as a product of matrices,
    corresponding to the linearized dynamics, applied on the initial perturbation.
  prefs: []
  type: TYPE_NORMAL
- en: Other equally important examples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are other examples. In number theory, we can model the distribution of
    zeros of the Riemann zeta function using the distribution of eigenvalues of certain
    random matrices. For those keeping an eye for quantum computing, here’s a historical
    note: Before Schrodinger’s equation, Heisenberg formulated quantum mechanics in
    terms of what he named *matrix mechanics*. Finally, we will encounter the *master
    equation for the evolution of probabilities* in [Chapter 13](ch13.xhtml#ch13).
    This involves a large matrix of transition probabilities from one state of a system
    to another state.'
  prefs: []
  type: TYPE_NORMAL
- en: Main considerations in random matrix theory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Depending on the formulation of the problem, the matrices that appear are either
    deterministic or random. For deterministic vectors and matrices, classical numerical
    linear algebra applies, but the extreme high dimensionality forces us to use randomization
    in order to efficiently do matrix multiplication (usually <math alttext="upper
    O left-parenthesis n cubed right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>n</mi>
    <mn>3</mn></msup> <mo>)</mo></mrow></math> ), decomposition, and compute the spectrum
    (eigenvalues and eigenvectors). A substantial amount of matrix properties is encapsulated
    in their spectra, so we learn a great deal about matrices by studying these eigenvalues
    and eigenvectors. In the stochastic realm, when the matrices are random, these
    are random as well. So how do we compute them and find their probability distributions
    (or even only their means and variances or bounds on those)? These are the types
    of questions that the field of large random matrices (or randomized linear algebra,
    or high dimensional probability) addresses. We usually focus on:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The involved stochastic math objects: Random vectors and random matrices. Each
    entry of a random vector or a random matrix is a random variable. These could
    either be static random variables or evolving with time. When a random variable
    evolves with time, it becomes *a random or stochastic process*. Obviously, stochastic
    processes are more involved mathematically than their static counterparts. For
    example, what can we say about variances that evolve with time?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Random projections: Our interest is always in projecting onto some lower dimensional
    spaces while preserving essential information. These usually involve either multiplying
    matrices with vectors or factorizing matrices into a product of simpler matrices,
    such as the singular value decomposition. How do we do these when not only the
    data is large but also the entries are random?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Adding and multiplying random matrices: Note that the sums and products of
    *scalar* random variables are also random variables, and their distributions are
    well studied. Similarly, the sums and products of *time evolving scalar* random
    variables, which are the foundation for Brownian motion and stochastic calculus,
    have a large body of literature supporting them. How does this theory transition
    to higher dimensions?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing the spectrum of a random matrix, and exploring the properties of its
    (random) eigenvalues and eigenvectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing the spectrum of sums and products of random matrices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiplying *many* random matrices, as opposed to only two. This problem appears
    in many contexts in the technological industry, for example, when studying the
    transmission of light in a succession of slabs of different optical indices, or
    the propagation of an electron in a disordered wire, or the way displacements
    propagate in granular media.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bayesian estimation for matrices (Bayesian *anything* always has to do with
    estimating the probability of something given some evidence): Here, the matrix
    we start with (the observations matrix) is a noisy version of the true matrix
    that we care for. The noise can be additive, so the observed matrix *E=true matrix+a
    random noise matrix*. The noise can also be multiplicative, so the observed matrix
    *E=true matrix* <math alttext="times"><mo>×</mo></math> *random noise matrix*.
    In general, we do not know the true matrix, and would like to know the probability
    of this matrix given that we have observed the noisy matrix. That is, we have
    to compute *Prob(true matrix|noisy matrix)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random matrix ensembles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In most applications, we encounter (stochastic or deterministic) large matrices
    with no particular structure. The main premise that underlies random matrix theory
    is that we can replace such a large complex matrix by a typical element (expected
    element) of a certain ensemble of random matrices. Most of the time we restrict
    our attention to symmetric matrices with real entries, since these are the ones
    that most commonly arise in data analysis and statistical physics. Thankfully,
    these are the ones that are easier to analyze mathematically.
  prefs: []
  type: TYPE_NORMAL
- en: 'Speaking of mathematics, we love polynomial functions. They are nonlinear so
    complex enough to capture enough complexities in the world around us, and are
    easy to evaluate and do computations with. When we study large random matrices,
    a special type of well studied polynomials appears: Orthogonal polynomials. An
    orthogonal polynomial sequence is a family of polynomials such that any two different
    polynomials in the sequence are orthogonal to each other under some inner product
    (their inner product is zero). The most widely used orthogonal polynomials sequences
    are: Hermite polynomials, the Laguerre polynomials and the Jacobi polynomials
    (these include the important classes of Chebyshev polynomials and Legendre polynomials).
    The famous names in the field of orthogonal polynomials, which was mostly developed
    in the late nineteenth century, are Chebyshev, Markov and Stieltjes. No wonder
    these names are everywhere in probability theory, from Chebyshev inequalities
    to Markov chains and processes to Stieltjes transforms.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following three fundamental random matrix ensembles are intimately related
    to orthogonal polynomials:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Wigner*: This is the matrix equivalent of the Gaussian distribution. A 1 ×
    1 Wigner matrix is a single Gaussian random number. This is intimately related
    to Hermite orthogonal polynomials. The Gaussian distribution and its associated
    Hermite polynomials appear very naturally in contexts where the underlying variable
    is unbounded above and below. The average of the characteristic polynomials of
    Wigner random matrices of obey simple recursion relations that allow us to express
    them as Hermite polynomials. Wigner ensemble is the simplest of all ensembles
    of random matrices. These are matrices where all elements are Gaussian random
    variables, with the only constraint that the matrix is real symmetric (the Gaussian
    orthogonal ensemble), complex Hermitian (the Gaussian unitary ensemble) or symplectic
    (the Gaussian symplectic ensemble).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Wishart*: This is the matrix equivalent of the gamma distribution. A 1 × 1
    Wishart is a gamma distributed number. This is intimately related to Laguerre
    orthogonal polynomials. Gamma distributions and Laguerre polynomials appear in
    problems where the variable is bounded from below (e.g. positive variables). The
    average of the characteristic polynomials of Wishart random matrices obey simple
    recursion relations that allow us to express them as Laguerre polynomials.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Jacobi*: This is the matrix equivalent of the beta distribution. A 1 × 1 Wishart
    is a beta distributed number. This is intimately related to Jacobi orthogonal
    polynomials. Beta distributions and Jacobi polynomials appear in problems where
    the variable is bounded from above and from below. A natural setting where Jacobi
    matrices appear is that of sample covariance matrices. They also show up in the
    simple problem of addition or multiplications of matrices with only two eigenvalues.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As for scalar random variables, we study the moments and the Stieltjes transform
    of random matrix ensembles. Moreover, since we are in the matrix realm, we study
    the joint probability distributions of the eigenvalues of these random matrices.
    For the ensembles mentioned above, the eigenvalues are strongly correlated and
    we can think of them as particles interacting through pairwise repulsion. These
    are called Coulomb repelling eigenvalues, and the idea here is borrowed from statistical
    physics (see for example [Patterns in Eigenvalues (2003)](https://www.ams.org/journals/bull/2003-40-02/S0273-0979-03-00975-3/S0273-0979-03-00975-3.pdf)
    for a deeper dive into the behavior of the eigenvalues of matrices with special
    structures). It turns out that the most probable positions of the Coulomb gas
    problem coincide with the zeros of Hermite polynomials in the Wigner case, and
    of Laguerre polynomials in the Wishart case. Moreover, the eigenvalues of these
    ensembles fluctuate very little around their most probable positions.
  prefs: []
  type: TYPE_NORMAL
- en: Eigenvalue density of the sum of two large random matrices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Other than finding the joint probability distribution of the eigenvalues of
    random matrix ensembles, we care for the eigenvalue density (probability distribution)
    of sums of large random matrices, in terms of that for each individual matrix
    in the sum. *Dyson Brownian motion* appears in this context. It is an extension
    of *Brownian motion* from scalar random variables to random matrices. Moreover,
    a Fourier transform for matrices allows us to define the analog of the generating
    function for scalar independent and identically distributed random variables,
    and use its logarithm to find the eigenvalue density of sums of carefully constructed
    random matrices. Finally, we can apply Chernoff, Bernstein, and Hoeffding type
    inequalities to the maximal eigenvalue of a finite sum of random Hermitian matrices.
  prefs: []
  type: TYPE_NORMAL
- en: Essential math for large random matrices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before leaving the discussion of large random matrices, let’s highlight the
    *must knows* if we want to dive deeply into this field. We touch on some of these
    in this chapter and leave the rest for your googling skills:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Computing the spectrum: Eigenvalues and eigenvectors of a matrix (solutions
    of <math alttext="upper A ModifyingAbove v With right-arrow equals lamda ModifyingAbove
    v With right-arrow"><mrow><mi>A</mi> <mover accent="true"><mi>v</mi> <mo>→</mo></mover>
    <mo>=</mo> <mi>λ</mi> <mover accent="true"><mi>v</mi> <mo>→</mo></mover></mrow></math>
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Characteristic polynomial of a matrix ( <math alttext="d e t left-parenthesis
    lamda upper I minus upper A right-parenthesis"><mrow><mi>d</mi> <mi>e</mi> <mi>t</mi>
    <mo>(</mo> <mi>λ</mi> <mi>I</mi> <mo>-</mo> <mi>A</mi> <mo>)</mo></mrow></math>
    )
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hermite, Laguerre, and Jacobi orthogonal polynomials
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Gaussian, gamma, and beta probability distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moments and moment generating function of a random variable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stieltjes transform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chebyshev everything
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Markov everything
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chernoff, Bernstein, and Hoeffding type inequalities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brownian motion and Dyson Brownian motion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As of 2022, the fastest supercomputer is *Frontier*, the world’s first exascale
    computer (1.102 exaFLOPS), at the Department of Energy’s Oak Ridge National Laboratory.
    When matrices are very large, even on such a supercomputer, we cannot apply numerical
    linear algebra (for example to solve systems of equations involving the matrix,
    to find its spectrum, or to find its singular value decomposition) as we know
    it. What we must do instead is *random sampling of the columns of the matrix*.
    It is best to sample the columns with probability that leads to the most faithful
    approximation, the one with the least variance. For example, if the problem is
    to multiply two large matrices *A* and *B* with each other, instead of sampling
    a column from *A* and a corresponding row from *B* uniformly, we choose the column
    from *A* and the corresponding row from *B* with a probability <math alttext="p
    Subscript j"><msub><mi>p</mi> <mi>j</mi></msub></math> proportional to *norm(column
    j of A)norm(row j of B)*. This means that we choose the columns and rows with
    large norms more often, leading to a higher probability of capturing the *important
    parts* of the product.
  prefs: []
  type: TYPE_NORMAL
- en: 'The column space of large and non-large matrices is so important. Keep in mind
    the three best bases for the column space of a given matrix *A*:'
  prefs: []
  type: TYPE_NORMAL
- en: The singular vectors from the singular value decomposition,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: the orthogonal vectors from the Gram Schmidt process (the famous *QR* decomposition
    of the matrix),
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: or linearly independent columns directly selected from the columns of *A*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stochastic Processes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rather than thinking of a static (scalar or vector or matrix or tensor) random
    variable, we now think of a time dependent random variable. Somehow the next step
    in math always ends up including time evolving entities. On a side note, humans
    have not yet fully understood the nature of time or have found a way to articulate
    its definition. We do however, understand movement and change, a system transitioning
    from one state to another, and we associate time with that. We also associate
    probabilities for transitioning from one state to another. Hold this thought for
    Markov chains, coming up in a bit.
  prefs: []
  type: TYPE_NORMAL
- en: 'A *stochastic process* is an *infinite* sequence <math alttext="upper X 0 comma
    upper X 1 comma upper X 2 comma period period period"><mrow><msub><mi>X</mi> <mn>0</mn></msub>
    <mo>,</mo> <msub><mi>X</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>X</mi> <mn>2</mn></msub>
    <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo></mrow></math> of random variables
    where we think of the index *t* in each <math alttext="upper X Subscript t"><msub><mi>X</mi>
    <mi>t</mi></msub></math> as discrete time. So <math alttext="upper X 0"><msub><mi>X</mi>
    <mn>0</mn></msub></math> is the process at time *0* (or the value of a random
    quantity at a certain time *0*), <math alttext="upper X 1"><msub><mi>X</mi> <mn>1</mn></msub></math>
    is the process at time *1* (or the value of a random quantity at a certain time
    *1*), and so on. To formally define a random variable, which we have not done
    yet, we usually fix it over what we call a probability triple composed of: *(a
    sample space, a sigma algebra, a probability measure)*. Do not fuss about the
    meaning of this triple yet, instead, fuss about the fact that all the random variables
    in one stochastic process <math alttext="upper X 0 comma upper X 1 comma upper
    X 2 comma period period period"><mrow><msub><mi>X</mi> <mn>0</mn></msub> <mo>,</mo>
    <msub><mi>X</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>X</mi> <mn>2</mn></msub>
    <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo></mrow></math> live over the *same*
    probability triple, in this sense belonging to one family. Moreover, these random
    variables are often not independent.'
  prefs: []
  type: TYPE_NORMAL
- en: Equally important (depending on the application) is a *continuous time* stochastic
    process, where <math alttext="upper X Subscript t"><msub><mi>X</mi> <mi>t</mi></msub></math>
    now encodes the value of a random quantity at *any* nonnegative time *t*. Moreover,
    this is easy to align with our intuitive perception of time, which is continuous.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, a stochastic process is a generalization of a finite dimensional
    multivariable distribution to infinite dimensions. This way of thinking about
    it comes in handy when trying to prove *existence* of a stochastic process, since
    then we can resort to theorems that allow us to *extend* to infinite dimensions
    by relying on finite dimensional collections of the constituent distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples of stochastic processes are all around us. We think of these whenever
    we encounter fluctuations: Movement of gas molecules, electrical current fluctuations,
    stock prices in financial markets, the number of phone calls to a call center
    in a certain time period, a gambler’s process, and this one is interesting from
    microbiology in the medical field, discussing bacteria found in the gut, [*the
    community assembly of blood, fleas or torsaloes is primarily governed by stochastic
    processes, while the gut microbiome is determined by deterministic processes*](https://academic.oup.com/femsec/article/94/6/fiy082/4990947).'
  prefs: []
  type: TYPE_NORMAL
- en: The stock market example is central in the theory of stochastic processes, because
    it is how Brownian motion (also called Wiener stochastic process) got popularized,
    with L. Bachelier studying price changes in the Paris Bourse. The phone calls
    to a call center example is also central in the theory, because it is how Poisson
    stochastic process got popularized, with A. K. Erlang modeling the number of phone
    calls occurring in a certain period of time.
  prefs: []
  type: TYPE_NORMAL
- en: These two processes, Brownian and Poisson, appear in many other settings that
    have nothing to do with the above examples. Maybe this tells us something deeper
    about nature and the unity of its underlying processes, but let’s not get philosophical
    and stay with mathematics. In general, we can group stochastic processes into
    few categories, depending on their mathematical properties. Some of these are
    discrete time processes and others are continuous time. The distinction between
    which one is which is pretty intuitive.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to derive conclusions about Brownian and Poisson processes, and the
    other stochastic processes that we are about to overview, we need to analyze them
    mathematically. In probability theory, we start with establishing the *existence*
    of a stochastic process: That is, we need to explicitly define the probability
    triple (sample space, sigma algebra, probability measure) where the discrete time
    *infinite* sequence of random variables <math alttext="upper X 0 comma upper X
    1 comma upper X 2 comma period period period"><mrow><msub><mi>X</mi> <mn>0</mn></msub>
    <mo>,</mo> <msub><mi>X</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>X</mi> <mn>2</mn></msub>
    <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo></mrow></math> or the continuous time
    <math alttext="upper X Subscript t"><msub><mi>X</mi> <mi>t</mi></msub></math>
    process lives, and prove that we can find such a set of random variables satisfying
    its characterizing properties. We will revisit this later in this chapter, but
    a big name we want to search for when proving existence of stochastic processes
    is A. Kolmogorov (1903-1987), namely, *Kolmogorov existence theorem*. This ensures
    the existence of a stochastic process having the same *finite dimensional* distributions
    as our desired processes. That is, we can get our desired stochastic process (infinite
    process, indexed on discrete or continuous time), by specifying all finite dimensional
    distributions in some *consistent* way.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s survey the most prominent stochastic processes:'
  prefs: []
  type: TYPE_NORMAL
- en: Bernoulli process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is the stochastic process mostly associated with repeatedly flipping a
    coin and any process in life that mimics that (at some airports custom officials
    make us press a button, if the light turns green we pass, if it turns red we get
    searched). Mathematically it is an infinite sequence of independent and identically
    distributed random variables <math alttext="upper X 0 comma upper X 1 comma upper
    X 2 comma period period period"><mrow><msub><mi>X</mi> <mn>0</mn></msub> <mo>,</mo>
    <msub><mi>X</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>X</mi> <mn>2</mn></msub>
    <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo></mrow></math> , where each random
    variable takes either the value zero with probability *p* or one with probability
    *1-p*. A sample realization of this process would look like <math alttext="0 comma
    1 comma 1 comma 0 comma period period period"><mrow><mn>0</mn> <mo>,</mo> <mn>1</mn>
    <mo>,</mo> <mn>1</mn> <mo>,</mo> <mn>0</mn> <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo></mrow></math>
    .
  prefs: []
  type: TYPE_NORMAL
- en: Poisson process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can think of Poisson process as a stochastic process whose underlying random
    variables are counting variables: These count how many interesting events happen
    within a set period of time. These events are either independent or are weakly
    dependent, and each has a small probability of occurence. They also happen at
    a set expected rate <math alttext="lamda"><mi>λ</mi></math> . This is the parameter
    that characterizes a Poisson random variable. For example, in queueing theory,
    we use it to model the arrival of customers at a store, or phone calls at a call
    center, or the occurrence of earthquakes, in a certain time interval. This process
    has the natural numbers as its state space and the non-negative numbers as its
    index set. The probability distribution underlying the random variables involved
    in a Poisson process has the formula'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis upper X equals n right-parenthesis
    equals StartFraction lamda Superscript n Baseline e Superscript negative lamda
    Baseline Over n factorial EndFraction dollar-sign"><mrow><mi>P</mi> <mi>r</mi>
    <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>=</mo> <mi>n</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><msup><mi>λ</mi> <mi>n</mi></msup> <msup><mi>e</mi> <mrow><mo>-</mo><mi>λ</mi></mrow></msup></mrow>
    <mrow><mi>n</mi><mo>!</mo></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The formula above gives the probability of *n* interesting events occuring in
    a unit period of time. Clearly within a fixed time interval it is not likely to
    have many rare events occur, which explains the rapid decay in the formula for
    large *n*. The expectation and the variance of a Poisson random variable is <math
    alttext="lamda"><mi>λ</mi></math> .
  prefs: []
  type: TYPE_NORMAL
- en: 'A Poisson *process* <math alttext="upper X Subscript t Baseline semicolon t
    greater-than-or-equal-to 0"><mrow><msub><mi>X</mi> <mi>t</mi></msub> <mo>;</mo>
    <mi>t</mi> <mo>≥</mo> <mn>0</mn></mrow></math> , indexed by continuous time, has
    the properties:'
  prefs: []
  type: TYPE_NORMAL
- en: X_0=0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the number of events (or points) in any interval of length *t* is a Poisson
    random variable with parameter <math alttext="lamda t"><mrow><mi>λ</mi> <mi>t</mi></mrow></math>
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A Poisson process has two important features:'
  prefs: []
  type: TYPE_NORMAL
- en: The number of events in each finite interval is a Poisson random variable (has
    a Poisson probability distribution).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The number of events in disjoint time intervals are independent random variables.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Poisson process is an example of a Levy stochatic process, which is a process
    with stationary independent increments.
  prefs: []
  type: TYPE_NORMAL
- en: Random walk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is easy to think of the simplest random walk as someone taking walking steps
    on a road where he starts somewhere, then moves forward (add one to his position)
    with probability *p* and backwards (subtract one from his position) with probability
    *1-p*. We can define resulting discrete time stochastic process <math alttext="upper
    X 0 comma upper X 1 comma ellipsis"><mrow><msub><mi>X</mi> <mn>0</mn></msub> <mo>,</mo>
    <msub><mi>X</mi> <mn>1</mn></msub> <mo>,</mo> <mo>⋯</mo></mrow></math> such that
    <math alttext="upper X 0 equals x 0"><mrow><msub><mi>X</mi> <mn>0</mn></msub>
    <mo>=</mo> <msub><mi>x</mi> <mn>0</mn></msub></mrow></math> , <math alttext="upper
    X 1 equals upper X 0 plus upper Z 1"><mrow><msub><mi>X</mi> <mn>1</mn></msub>
    <mo>=</mo> <msub><mi>X</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Z</mi> <mn>1</mn></msub></mrow></math>
    , <math alttext="upper X 2 equals upper X 1 plus upper Z 2 equals upper X 0 plus
    upper Z 1 plus upper Z 2"><mrow><msub><mi>X</mi> <mn>2</mn></msub> <mo>=</mo>
    <msub><mi>X</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>Z</mi> <mn>2</mn></msub>
    <mo>=</mo> <msub><mi>X</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Z</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Z</mi> <mn>2</mn></msub></mrow></math> , *etc.*, where <math
    alttext="upper Z 1 comma upper Z 2 comma d o t s"><mrow><msub><mi>Z</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>Z</mi> <mn>2</mn></msub> <mo>,</mo> <mi>d</mi> <mi>o</mi>
    <mi>t</mi> <mi>s</mi></mrow></math> is a Bernoulli process. If *p=0.5* this is
    a symmetric random walk.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 9](ch09.xhtml#ch09), we used random walks on graphs multiple times,
    where we start at a certain graph node then transition to one of its adjacent
    nodes with given probabilities. A normalized adjacency matrix of the graph would
    define the transition probabilities at all nodes. This is a neat example of how
    random walks on graphs ties to Markov chains, coming up soon. For more on this
    check this nice set of notes on [random walks on graphs](https://www.bowaggoner.com/courses/2019/csci5454/docs/spectral.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Weiner Process or Brownian Motion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can think of a Wiener process or a Brownian motion as a random walk with
    infinitesimally small steps, so discrete movements become infinitesimally small
    fluctuations, and we get a *continuous* random walk. A Brownian motion is a continuous
    time stochastic process <math alttext="upper X Subscript t Baseline semicolon
    t greater-than-or-equal-to 0"><mrow><msub><mi>X</mi> <mi>t</mi></msub> <mo>;</mo>
    <mi>t</mi> <mo>≥</mo> <mn>0</mn></mrow></math> . The random variables <math alttext="upper
    X Subscript t"><msub><mi>X</mi> <mi>t</mi></msub></math> are real valued, have
    independent increments, and the difference between <math alttext="upper X Subscript
    t"><msub><mi>X</mi> <mi>t</mi></msub></math> and <math alttext="upper X Subscript
    s"><msub><mi>X</mi> <mi>s</mi></msub></math> at two separate times *t* and *s*
    is normally distributed (follows a Gaussian bell shape distribution) with mean
    *0* and variance *t-s*. That is, <math alttext="upper X Subscript t Baseline minus
    upper X Subscript s"><mrow><msub><mi>X</mi> <mi>t</mi></msub> <mo>-</mo> <msub><mi>X</mi>
    <mi>s</mi></msub></mrow></math> are normally distributed based on the size of
    the increments.
  prefs: []
  type: TYPE_NORMAL
- en: The interesting thing about a real valued continuous time stochastic process
    is that they can move in continuous paths, giving rise to interesting random functions
    of time. For example, almost surely, a sample path of a Brownian motion (Weiner
    process) is continuous everywhere but nowhere differentiable (too many spikes).
  prefs: []
  type: TYPE_NORMAL
- en: 'Brownian motion is fundamental in the study of stochastic processes. It is
    the starting point of stochastic calculus, lying at the intersection of several
    important classes of processes: It a Gaussian Markov process, it is a Levy process
    (a process with stationary independent increments), and it is a martingale, discussed
    next.'
  prefs: []
  type: TYPE_NORMAL
- en: Martingale
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A discrete time martingale is a stochastic process <math alttext="upper X 0
    comma upper X 1 comma upper X 2 comma period period"><mrow><msub><mi>X</mi> <mn>0</mn></msub>
    <mo>,</mo> <msub><mi>X</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>X</mi> <mn>2</mn></msub>
    <mo>,</mo> <mo>.</mo> <mo>.</mo></mrow></math> that for any discrete time t,
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign double-struck upper E left-parenthesis upper X Subscript
    t plus 1 Baseline vertical-bar upper X 1 comma upper X 2 comma ellipsis comma
    upper X Subscript t Baseline right-parenthesis equals upper X Subscript t dollar-sign"><mrow><mi>𝔼</mi>
    <mrow><mo>(</mo> <msub><mi>X</mi> <mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub>
    <mo>|</mo> <msub><mi>X</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>X</mi> <mn>2</mn></msub>
    <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>X</mi> <mi>t</mi></msub> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mi>X</mi> <mi>t</mi></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'That is, the expected value of the next observation, given all the previous
    observations, is equal to the most recent observation. This is a weird way of
    defining something (sadly this is very common in this field) but let’s give a
    few brief examples os some contexts within which martingales appear:'
  prefs: []
  type: TYPE_NORMAL
- en: An unbiased random walk is an example of a martingale.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A gambler’s fortune is a martingale if all the betting games which the gambler
    plays are fair: Suppose a gambler wins $1 if a fair coin comes up heads and loses
    $1 if it comes up tails. If <math alttext="upper X Subscript n"><msub><mi>X</mi>
    <mi>n</mi></msub></math> is the gambler’s fortune after *n* tosses of the, then
    gambler’s conditional expected fortune after the next coin toss, given the history,
    is equal to their present fortune.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In an ecological community, where a group of species compete for few resources,
    we can model the number of individuals of any particular species as a stochastic
    process. This sequence is a martingale under the [unified neutral theory of biodiversity
    and biogeography](https://en.wikipedia.org/wiki/Unified_neutral_theory_of_biodiversity).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stopping times appear when discussing martingales. This is an interesting concept,
    capturing the idea that: *At any particular time t, you can look at the sequence
    so far and tell if it is time to stop*. A stopping time with respect to a stochastic
    process <math alttext="upper X 1 comma upper X 2 comma upper X 3 comma period
    period period"><mrow><msub><mi>X</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>X</mi>
    <mn>2</mn></msub> <mo>,</mo> <msub><mi>X</mi> <mn>3</mn></msub> <mo>,</mo> <mo>.</mo>
    <mo>.</mo> <mo>.</mo></mrow></math> is a random variable *S* (for *stop*) with
    the property that for each t, the occurrence or non-occurrence of the event *S=t*
    depends only on the values of <math alttext="upper X 1 comma upper X 2 comma upper
    X 3 comma period period period comma upper X Subscript t Baseline"><mrow><msub><mi>X</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>X</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>X</mi>
    <mn>3</mn></msub> <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>X</mi>
    <mi>t</mi></msub></mrow></math> . For example, the stopping time random variable
    models the time at which a gambler chooses to stop and leave a gambling table:
    This will depend on his previous winnings and losses, but not on the outcomes
    of games that he hasn’t yet played.'
  prefs: []
  type: TYPE_NORMAL
- en: Levy Process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have mentioned Poisson process and Brownian motion (Weiner process) as two
    of the most popular examples of a Levy process. This is a stochastic process with
    independent, stationary increments. It can model the motion of a particle whose
    successive displacements are random, in which displacements in pairwise disjoint
    time intervals are independent, and displacements in different time intervals
    of the same length have identical probability distributions. In this sense, it
    is the continuous time analog of a random walk.
  prefs: []
  type: TYPE_NORMAL
- en: Branching Process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A branching process splits into branches, randomly. For example, it models a
    certain population’s evolution (like bacteria, or neutrons in a nuclear reactor)
    where each individual in a given generation produces a random number of individuals
    in the next generation, according to some fixed probability distribution that
    does not vary from individual to individual. One of the main questions in the
    theory of branching processes is the probability of ultimate extinction, where
    the population dies out after a finite number of generations.
  prefs: []
  type: TYPE_NORMAL
- en: Markov Chain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s formally define a discrete time Markov chain since it is one of the most
    important stochastic processes, and because it comes up in the context of reinforcement
    learning in AI. To define a Markov chain, we need:'
  prefs: []
  type: TYPE_NORMAL
- en: A discrete set of possible states *S* (finite or infinite). Think of this as
    the set of states that a particle or an agent can occupy. At each step the Markov
    process randomly evolves from from one state to another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An initial distribution prescribing the probability <math alttext="nu Subscript
    i"><msub><mi>ν</mi> <mi>i</mi></msub></math> of each possible <math alttext="s
    t a t e Subscript i"><mrow><mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>t</mi> <msub><mi>e</mi>
    <mi>i</mi></msub></mrow></math> : Initially, how likely is it for a particle to
    be at a certain location or for an agent to be in a certain state?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transition probabilities <math alttext="p Subscript i j"><msub><mi>p</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub></math>
    specifying the probability that the particle or the agent transitions from <math
    alttext="s t a t e Subscript i"><mrow><mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>t</mi>
    <msub><mi>e</mi> <mi>i</mi></msub></mrow></math> to <math alttext="s t a t e Subscript
    j"><mrow><mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>t</mi> <msub><mi>e</mi> <mi>j</mi></msub></mrow></math>
    . Note that we have for each state *i*, the sum <math alttext="p Subscript i Baseline
    1 Baseline plus p Subscript i Baseline 2 Baseline plus ellipsis plus p Subscript
    i n Baseline equals 1"><mrow><msub><mi>p</mi> <mrow><mi>i</mi><mn>1</mn></mrow></msub>
    <mo>+</mo> <msub><mi>p</mi> <mrow><mi>i</mi><mn>2</mn></mrow></msub> <mo>+</mo>
    <mo>⋯</mo> <mo>+</mo> <msub><mi>p</mi> <mrow><mi>i</mi><mi>n</mi></mrow></msub>
    <mo>=</mo> <mn>1</mn></mrow></math> . Moreover, this process has no memory, because
    this transition probability depends only on <math alttext="s t a t e Subscript
    i"><mrow><mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>t</mi> <msub><mi>e</mi> <mi>i</mi></msub></mrow></math>
    and <math alttext="s t a t e Subscript j"><mrow><mi>s</mi> <mi>t</mi> <mi>a</mi>
    <mi>t</mi> <msub><mi>e</mi> <mi>j</mi></msub></mrow></math> , not on previously
    visited states.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now a Markov chain is a stochastic process <math alttext="upper X 0 comma upper
    X 1 comma ellipsis"><mrow><msub><mi>X</mi> <mn>0</mn></msub> <mo>,</mo> <msub><mi>X</mi>
    <mn>1</mn></msub> <mo>,</mo> <mo>⋯</mo></mrow></math> taking values in *S* such
    that
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis upper X 0 equals s
    t a t e Subscript i 0 Baseline comma upper X 1 equals s t a t e Subscript i 1
    Baseline comma ellipsis comma upper X Subscript n Baseline equals s t a t e Subscript
    i Sub Subscript n Subscript Baseline right-parenthesis equals nu Subscript i 0
    Baseline p Subscript i 0 i 1 Baseline p Subscript i 1 i 2 Baseline ellipsis p
    Subscript i Sub Subscript n minus 1 Subscript i Sub Subscript n dollar-sign"><mrow><mi>P</mi>
    <mi>r</mi> <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <msub><mi>X</mi> <mn>0</mn></msub>
    <mo>=</mo> <mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>t</mi> <msub><mi>e</mi> <msub><mi>i</mi>
    <mn>0</mn></msub></msub> <mo>,</mo> <msub><mi>X</mi> <mn>1</mn></msub> <mo>=</mo>
    <mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>t</mi> <msub><mi>e</mi> <msub><mi>i</mi>
    <mn>1</mn></msub></msub> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>X</mi> <mi>n</mi></msub>
    <mo>=</mo> <mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>t</mi> <msub><mi>e</mi> <msub><mi>i</mi>
    <mi>n</mi></msub></msub> <mo>)</mo></mrow> <mo>=</mo> <msub><mi>ν</mi> <msub><mi>i</mi>
    <mn>0</mn></msub></msub> <msub><mi>p</mi> <mrow><msub><mi>i</mi> <mn>0</mn></msub>
    <msub><mi>i</mi> <mn>1</mn></msub></mrow></msub> <msub><mi>p</mi> <mrow><msub><mi>i</mi>
    <mn>1</mn></msub> <msub><mi>i</mi> <mn>2</mn></msub></mrow></msub> <mo>⋯</mo>
    <msub><mi>p</mi> <mrow><msub><mi>i</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <msub><mi>i</mi> <mi>n</mi></msub></mrow></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: We can bundle up all the transition probabilities in a square matrix (a Markov
    matrix, with each row has nonnegative numbers adding up to one), and multiply
    by that matrix. This matrix summarizes the probabilities of transitioning from
    any <math alttext="s t a t e Subscript i"><mrow><mi>s</mi> <mi>t</mi> <mi>a</mi>
    <mi>t</mi> <msub><mi>e</mi> <mi>i</mi></msub></mrow></math> to <math alttext="s
    t a t e Subscript j"><mrow><mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>t</mi> <msub><mi>e</mi>
    <mi>j</mi></msub></mrow></math> in one step. The cool thing is that powers of
    a Markov matrix are also Markov, so for example the square of this matrix summarizes
    the probabilities of transitioning from any <math alttext="s t a t e Subscript
    i"><mrow><mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>t</mi> <msub><mi>e</mi> <mi>i</mi></msub></mrow></math>
    to <math alttext="s t a t e Subscript j"><mrow><mi>s</mi> <mi>t</mi> <mi>a</mi>
    <mi>t</mi> <msub><mi>e</mi> <mi>j</mi></msub></mrow></math> in two steps, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: Some fundamental notions related to Markov chains are transience, recurrence,
    and irreducibility. A <math alttext="s t a t e Subscript i"><mrow><mi>s</mi> <mi>t</mi>
    <mi>a</mi> <mi>t</mi> <msub><mi>e</mi> <mi>i</mi></msub></mrow></math> is recurrent
    if we start from it then we will certainly eventually return to it. It is called
    transient if it is not recurrent. A Markov chain is irreducible if it is possible
    for the chain to move from any state to any other state.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, a stationary probability vector, defining a probability distribution
    over the possible states, is one that does not change when we multiply it by the
    transition matrix. This ties straight into eigenvectors in linear algebra with
    corresponding eigenvalue one. The *feel good* high that we get when the math we
    know connects together is an addictive feeling and it is what keeps us trapped
    in a *love hate* relationship with this field. Thankfully the longer we stay the
    more *love love* it becomes.
  prefs: []
  type: TYPE_NORMAL
- en: Itô’s Lemma
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s tie a bit more math together. A stochastic process models a random quantity
    that evolves with time. A function of a stochastic process also evolves randomly
    with time. When deterministic functions evolve with time, the next question is
    usually, *how fast?*. To answer that, we take its derivative with repect to time,
    and develop calculus around derivatives (and integrals) of deterministic functions.
    The chain rule is of paramount importance, especially for training machine learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Itô’s lemma is the analogue of the chain rule for functions of stochastic processes.
    It is the stochastic calculus counterpart of the chain rule. We use it to find
    the differential of a time-dependent function of a stochastic process.
  prefs: []
  type: TYPE_NORMAL
- en: Markov Decision Processes and Reinforcement Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the AI community, Markov decision processes are associated with:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Dynamic programming and Richard Bellman: Bellman played a monumental role in
    the field, and his optimality condition is implemented in many algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reinforcement learning: Finding an optimal strategy via a sequence of actions
    which are associated with positive or negative rewards (trials and errors). The
    agent has choices between several actions and transition states, where the transition
    probabilities depend on the chosen actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deep reinforcement learning: Combining reinforcement learning with neural networks.
    Here, a neural network takes the observations as input, and outputs a probability
    for each of the possible actions that the agent can take (a probability distribution).
    The agent then decides on the next action randomly, according to the estimated
    probabilities. For example, if the agent has two choices, turn left or turn right,
    and the neural network outputs 0.7 for turn left, then the agent will turn left
    with 70% probability, and turn right with 30% probability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinforcement learning has a great potential to advance us towards general intelligence.
    Intelligent agents need to make rational decisions when payoffs from actions are
    not immediate but instead result from a series of actions taken sequentially.
    This is the epitome of reasoning under uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of reinforcement learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Examples of reinforcement learning are plentiful: Self-driving cars, recommender
    systems, thermostat at home (getting positive rewards whenever it is close to
    the target temperature and saves energy, and negative rewards when humans need
    to tweak the temperature), automatic investing in the stock market (the input
    is the stock prices and the output is how much of each stock to buy or sell, the
    rewards are the monetary gains or losses).'
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the most famous example for deep reinforcement learning success is [DeepMind’s
    AlphaGo](https://en.wikipedia.org/wiki/AlphaGo), the AI agent which in 2016 beat
    the world’s best human player in the ancient Chinese Go game. Thinking of reinforcement
    learning in terms of board games, such as chess or Go game, is intuitive, because
    at each step we decide on the sequence of actions that we must take, knowing very
    well that our current decision affects the whole outcome of the game. We better
    act optimally at each step. Moreover, at each step, our optimal strategy *evolves*,
    because it also depends on the actions of our opponent (who is solving the exact
    same problem but from his vantage point).
  prefs: []
  type: TYPE_NORMAL
- en: 'I am a bit biased against examples containing games since nowadays my daughter
    is addicted to PlayStation5\. I prefer the investment market example: Our financial
    advisor operates in a market that changes everyday, and he needs to make decisions
    on buying/selling certain stocks at each time step, with the long term goal of
    maximizing profit and minimizing losses. The market environment is stochastic
    and we do not know its rules, but we assume that we do for our modeling purposes.
    Now let’s switch our human financial advisor to an AI agent, and let’s see what
    kind of optimization problem this agent needs to solve at each time step in the
    constantly changing market environment.'
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning as a Markov decision process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s formulate reinforcement learning mathematically as a Markov decision
    process: The environment within which our agent exists is probabilistic, consisting
    of states and transition probabilities between these states. These transition
    probabilities *depend on the chosen actions*. Thus, the resulting Markov process
    which encodes the transitions from any state <math alttext="ModifyingAbove s t
    a t e With right-arrow"><mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover></math> to another state <math alttext="ModifyingAbove s t a
    t e With right-arrow prime"><msup><mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover> <mo>''</mo></msup></math> has an explicit depency on the action
    <math alttext="ModifyingAbove a With right-arrow"><mover accent="true"><mi>a</mi>
    <mo>→</mo></mover></math> taken while in state <math alttext="ModifyingAbove s
    t a t e With right-arrow"><mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main assumption here is that we *know* this process, which means that we
    know rules of the environment. In other words, we know the following probability
    for each <math alttext="ModifyingAbove s t a t e With right-arrow"><mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover></math> , <math alttext="ModifyingAbove s t a t e With right-arrow
    prime"><msup><mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover> <mo>''</mo></msup></math> , and action <math alttext="ModifyingAbove
    a With right-arrow"><mover accent="true"><mi>a</mi> <mo>→</mo></mover></math>
    :'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis next state equals
    ModifyingAbove s t a t e With right-arrow Superscript prime Baseline vertical-bar
    current state equals ModifyingAbove s t a t e With right-arrow comma action taken
    equals ModifyingAbove a With right-arrow right-parenthesis dollar-sign"><mrow><mi>P</mi>
    <mi>r</mi> <mi>o</mi> <mi>b</mi> <mo>(</mo> <mtext>next</mtext> <mtext>state</mtext>
    <mo>=</mo> <msup><mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover> <mo>'</mo></msup> <mo>|</mo> <mtext>current</mtext> <mtext>state</mtext>
    <mo>=</mo> <mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover> <mo>,</mo> <mtext>action</mtext> <mtext>taken</mtext> <mo>=</mo>
    <mover accent="true"><mi>a</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: We also know the reward system, which is
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper P r o b left-parenthesis next reward value
    vertical-bar current state equals ModifyingAbove s t a t e With right-arrow comma
    action taken equals ModifyingAbove a With right-arrow comma next state equals
    ModifyingAbove s t a t e With right-arrow prime right-parenthesis dollar-sign"><mrow><mi>P</mi>
    <mi>r</mi> <mi>o</mi> <mi>b</mi> <mo>(</mo> <mtext>next</mtext> <mtext>reward</mtext>
    <mtext>value</mtext> <mo>|</mo> <mtext>current</mtext> <mtext>state</mtext> <mo>=</mo>
    <mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover> <mo>,</mo> <mtext>action</mtext> <mtext>taken</mtext> <mo>=</mo>
    <mover accent="true"><mi>a</mi> <mo>→</mo></mover> <mo>,</mo> <mtext>next</mtext>
    <mtext>state</mtext> <mo>=</mo> <msup><mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover> <mo>'</mo></msup> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'This discussion now belongs in the realm of dynamic programming: We search
    for the *optimal policy* (sequence of good actions) leading to *optimal value*
    (maximal reward or minimal loss). This optimization problem is a bit more involved
    than the ones we have encountered so far, because it is a *sequence of actions*
    that leads to the optimal value. Therefore, we must divide the problem into steps,
    looking for the action at each step that *shoots for* the optimal reward *multiple
    steps ahead in the future*. *Bellman’s optimality equation* solves exactly this
    problem, simplifying it into the search for *only one optimal action* at the current
    state (as opposed to searching for all of them at once), given that we know what
    problem to optimize at each step. Bellman’s huge contribution is the following
    assertion: The optimal value of the current state is equal to the average reward
    after taking *one* optimal action, *plus* the *expected optimal value* of all
    possible next states that this action can lead to.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The agent interacts with its environment via an interative process. It starts
    with an initial state and a set of that state’s possible actions (the probability
    distribution for taking an action given that state), then computes the following,
    iteratively:'
  prefs: []
  type: TYPE_NORMAL
- en: The next optimal action to take (which transitions it to a new state with a
    new set of possible actions). This is called the *policy iteration*, and the optimization
    goal is to maximize future reward.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The expected value (rewards or losses) given that optimal action. This is called
    the *value iteration*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The value function adds up the agent’s expected future rewards given its current
    state and the optimal sequence of actions taken afterwards:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper V a l u e left-parenthesis ModifyingAbove s
    t a t e With right-arrow comma optimal sequence of actions right-parenthesis equals
    double-struck upper E left-parenthesis sigma-summation Underscript k Endscripts
    gamma Superscript k Baseline r e w a r d Subscript k Baseline right-parenthesis
    period dollar-sign"><mrow><mi>V</mi> <mi>a</mi> <mi>l</mi> <mi>u</mi> <mi>e</mi>
    <mrow><mo>(</mo> <mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover> <mo>,</mo> <mtext>optimal</mtext> <mtext>sequence</mtext> <mtext>of</mtext>
    <mtext>actions</mtext> <mo>)</mo></mrow> <mo>=</mo> <mi>𝔼</mi> <mrow><mo>(</mo>
    <msub><mo>∑</mo> <mi>k</mi></msub> <msup><mi>γ</mi> <mi>k</mi></msup> <mi>r</mi>
    <mi>e</mi> <mi>w</mi> <mi>a</mi> <mi>r</mi> <msub><mi>d</mi> <mi>k</mi></msub>
    <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The *discount factor* <math alttext="g a m m a"><mrow><mi>g</mi> <mi>a</mi>
    <mi>m</mi> <mi>m</mi> <mi>a</mi></mrow></math> is a number between 0 and 1\. It
    is useful to encourage taking actions that result in *sooner rather than later*
    positive rewards. Putting this factor in the optimization problem adjusts the
    importance of rewards over time, giving less weight to future rewards (if <math
    alttext="g a m m a"><mrow><mi>g</mi> <mi>a</mi> <mi>m</mi> <mi>m</mi> <mi>a</mi></mrow></math>
    is between 0 and 1 then <math alttext="g a m m a Superscript k"><mrow><mi>g</mi>
    <mi>a</mi> <mi>m</mi> <mi>m</mi> <msup><mi>a</mi> <mi>k</mi></msup></mrow></math>
    is small for large *k*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make the optimization in the value function explicit (we are choosing
    the sequence of actions that maximizes the rewards given the current state):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper V a l u e left-parenthesis ModifyingAbove s
    With right-arrow right-parenthesis equals max Underscript actions and states Endscripts
    double-struck upper E left-parenthesis sigma-summation Underscript k equals 0
    Overscript normal infinity Endscripts gamma Superscript k Baseline left-parenthesis
    r e w a r d right-parenthesis Subscript k Baseline vertical-bar ModifyingAbove
    s t a t e With right-arrow Subscript 0 Baseline equals ModifyingAbove s With right-arrow
    right-parenthesis dollar-sign"><mrow><mi>V</mi> <mi>a</mi> <mi>l</mi> <mi>u</mi>
    <mi>e</mi> <mrow><mo>(</mo> <mover accent="true"><mi>s</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <msub><mo form="prefix" movablelimits="true">max</mo>
    <mrow><mtext>actions</mtext><mtext>and</mtext><mtext>states</mtext></mrow></msub>
    <mi>𝔼</mi> <mrow><mo>(</mo> <msubsup><mo>∑</mo> <mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow>
    <mi>∞</mi></msubsup> <msup><mi>γ</mi> <mi>k</mi></msup> <msub><mrow><mo>(</mo><mi>r</mi><mi>e</mi><mi>w</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo>)</mo></mrow>
    <mi>k</mi></msub> <mo>|</mo> <msub><mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover> <mn>0</mn></msub> <mo>=</mo> <mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we break this up to make sure the agent’s current reward is explicit and
    separate from its future rewards:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper V a l u e left-parenthesis ModifyingAbove s
    With right-arrow right-parenthesis equals max Underscript actions and states Endscripts
    double-struck upper E left-parenthesis r e w a r d 0 plus sigma-summation Underscript
    k equals 1 Overscript normal infinity Endscripts gamma Superscript k Baseline
    left-parenthesis r e w a r d right-parenthesis Subscript k Baseline vertical-bar
    ModifyingAbove s t a t e With right-arrow Subscript 1 Baseline equals ModifyingAbove
    s With right-arrow Superscript prime Baseline right-parenthesis period dollar-sign"><mrow><mi>V</mi>
    <mi>a</mi> <mi>l</mi> <mi>u</mi> <mi>e</mi> <mrow><mo>(</mo> <mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>=</mo> <msub><mo form="prefix" movablelimits="true">max</mo>
    <mrow><mtext>actions</mtext><mtext>and</mtext><mtext>states</mtext></mrow></msub>
    <mi>𝔼</mi> <mrow><mo>(</mo> <mi>r</mi> <mi>e</mi> <mi>w</mi> <mi>a</mi> <mi>r</mi>
    <msub><mi>d</mi> <mn>0</mn></msub> <mo>+</mo> <msubsup><mo>∑</mo> <mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>∞</mi></msubsup> <msup><mi>γ</mi> <mi>k</mi></msup> <msub><mrow><mo>(</mo><mi>r</mi><mi>e</mi><mi>w</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo>)</mo></mrow>
    <mi>k</mi></msub> <mo>|</mo> <msub><mover accent="true"><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow>
    <mo>→</mo></mover> <mn>1</mn></msub> <mo>=</mo> <msup><mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mo>'</mo></msup> <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we find that the value function at the agent’s current state depends
    on its current reward and a discounted value function at its future states:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper V a l u e left-parenthesis ModifyingAbove s
    With right-arrow right-parenthesis equals max Underscript actions and states Endscripts
    double-struck upper E left-parenthesis r e w a r d 0 plus gamma upper V a l u
    e left-parenthesis ModifyingAbove s With right-arrow Superscript prime Baseline
    right-parenthesis right-parenthesis period dollar-sign"><mrow><mi>V</mi> <mi>a</mi>
    <mi>l</mi> <mi>u</mi> <mi>e</mi> <mrow><mo>(</mo> <mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>=</mo> <msub><mo form="prefix" movablelimits="true">max</mo>
    <mrow><mtext>actions</mtext><mtext>and</mtext><mtext>states</mtext></mrow></msub>
    <mi>𝔼</mi> <mrow><mo>(</mo> <mi>r</mi> <mi>e</mi> <mi>w</mi> <mi>a</mi> <mi>r</mi>
    <msub><mi>d</mi> <mn>0</mn></msub> <mo>+</mo> <mi>γ</mi> <mi>V</mi> <mi>a</mi>
    <mi>l</mi> <mi>u</mi> <mi>e</mi> <mrow><mo>(</mo> <msup><mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mo>'</mo></msup> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The above statement allows us to solve our main optimization problem iteratively
    (backwards in time). All the agent has to do now is to choose the action to get
    to the *next best state*. This expression for the value function is the powerful
    *Bellman’s equation* or *Bellman’s optimality condition* that breaks up the original
    optimization problem into a recursive sequence of much simpler optimization problems,
    optimizing locally at each state (finding <math alttext="upper V a l u e left-parenthesis
    ModifyingAbove s With right-arrow prime right-parenthesis"><mrow><mi>V</mi> <mi>a</mi>
    <mi>l</mi> <mi>u</mi> <mi>e</mi> <mo>(</mo> <msup><mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mo>'</mo></msup> <mo>)</mo></mrow></math> ) then putting the
    result into the next optimization subproblem (finding <math alttext="upper V a
    l u e left-parenthesis ModifyingAbove s With right-arrow right-parenthesis"><mrow><mi>V</mi>
    <mi>a</mi> <mi>l</mi> <mi>u</mi> <mi>e</mi> <mo>(</mo> <mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> ). The miracle is that working our
    way backwards this way from the desired ultimate reward to deciding what action
    to take now ends up given the overall optimal strategy along with the optimal
    value function at each state.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning in the context of optimal control and nonlinear dynamics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In [Chapter 13](ch13.xhtml#ch13) on PDEs, we revisit reinforcement learning
    in the context of nonlinear dynamics, optimal control, and the Hamilton Jacobi
    Bellman partial differential equation. Unlike the probabilistic Markov environment
    that our agent interacted with in the above discussion, the dynamic programming
    approach to reinforcement learning (which leads to the Hamilton Jacobi Bellman
    partial differential equation) is deterministic.
  prefs: []
  type: TYPE_NORMAL
- en: Pyhton library for reinforcement learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, a helpful library for implementing reinforcement learning algorithms
    is TF-Agents library (by Google, open sourced in 2018) is a reinforcement learning
    library based on TensorFlow (Python).
  prefs: []
  type: TYPE_NORMAL
- en: Theoretical And Rigorous Grounds
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rigorous, or mathematically precise, probability theory needs measure theory.
    *But why?* You might rightfully protest. After all, we have managed to avoid this
    for the longest time.
  prefs: []
  type: TYPE_NORMAL
- en: '*Because we cannot avoid it any longer.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s write this but never admit to it out loud: It is measure theory that
    turns off many students from pursuing further studies in math, mostly, because
    its story is never told in chronological order and how and why it came to be.
    Moreover, a lot of work in measure theoretic probability has to do with *proving*
    that a certain random variable *exists* (over some sample space, an event space
    or a sigma algebra, and a measure for each event or set in that sigma algebra),
    as if writing the random variable down and using it to model all sorts of random
    entities is not enough existence. This must be the reason why mathematicians and
    philosophers get along so well.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have already flown through many concepts in this chapter at lightening speed
    (my students accuse me of this all the time), but we need to start over, and give:'
  prefs: []
  type: TYPE_NORMAL
- en: A precise mathematical understanding of probabilities and sigma-algebras;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A precise mathematical definition of a random variable and a probability distribution,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A precise mathematical definition of an expected value of a random variable,
    and its connection to integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of probability inequalities (controlling uncertainty)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of the law of large numbers, the central limit theorem, and other
    convergence theorems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alright, that is too ambitious. We cannot give a full course on rigorous probability
    theory in one section of one chapter. What we will do instead is make a convincing
    case for it, and leave with a decent understanding of the fundamental ideas.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with two major limitations of non-rigorous probability (other than
    the fact that each of its math objects has countless inconsistent names, notations,
    and fuzzy definitions):'
  prefs: []
  type: TYPE_NORMAL
- en: Which events have a probability?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Given a sample space (a set which we can sample randomly from), can any subset
    have a probability defined on it? What if we are sampling numbers uniformly from
    the real line, and ask, what is the probability that we pick a rational number?
    An algebraic number (the solution to some polynomial equation with integer coefficients)?
    Or a member from some other complicated subset of the real line?
  prefs: []
  type: TYPE_NORMAL
- en: 'See how these questions are slowly drawing us into the details of set theory
    on the real line, which in turn pulls us straight into *measure theory*: The theory
    which addresses *which subsets of the real line we can measure, and which subsets
    we cannot*.'
  prefs: []
  type: TYPE_NORMAL
- en: Defining a probability for a subset of a sample space is starting to sound a
    lot like defining a measure of that set, and it seems like only subsets that are
    *measurable* can have a probability defined for them. How about the other *nonmeasurable*
    subsets of the sample space? Too bad for them, we cannot define a probability
    for them. To re-iterate, *Prob(A)* does not make sense for every subset A of a
    sample space, instead, it only makes sense for measurable subsets of that space.
    So we must harness all the measurable subsets together, abandon the rest and never
    think about them or their mathematics, and relax, because then we can act in a
    realm where all the events (subsets) that we harnessed have probabilities (measures)
    defined for them. The probability measure that we work with satisfies reasonable
    properties, in the sense that it is a nonnegative number in [0,1], and probabilities
    of complementary events (subsets) add up to one. This whole round about reveals
    the intricacies of the real line and its subsets, and more generally, the mysteries
    of the continuum and the wonders of the infinite.
  prefs: []
  type: TYPE_NORMAL
- en: It is rigorous probability theory helps us appreciate the properties of both
    discrete and continuous spaces, revealed in examples as simple as the contructing
    the discrete uniform distribution on a discrete set vs constructing the continuous
    uniform distribution on a given interval.
  prefs: []
  type: TYPE_NORMAL
- en: Can we talk about a wider range of random variables?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The other limitation of non-rigorous probability, meaning the one that avoids
    measure theory as we just described it, is the restriction on the kinds of random
    variables that it allows. In particular, where exactly do we draw the line between
    a discrete and continuous random variable? Is there really such a line? How about
    random variables that have both discrete and continuous aspects? As a simple example,
    suppose a random variable’s value is decided by a flip of a coin: It is Poisson
    distributed (discrete) if the coin comes up Heads, and normally disributed (continuous)
    if the coin comes up tails. This new random variable is neither fully discrete
    nor fully continuous in the non-rigorous sense that we understand either type.
    Then what is it? The rigorous answer is this: Of course there is no distinction
    between discrete and continuous random variables once we define the grounds that
    *any* random variable stands on. Here’s the rigorous ground it must stand on:
    What’s set formulates the sample space? What subsets of this sample space are
    measurable? What is the probability measure? What is the *distribution* of the
    random variable. This is the common ground, or the starting point for *any* random
    variable. Once we specify this ground, then discrete, continuous, or anything
    in between, becomes a small detail, as simple as answering: What set (or say product
    of sets) are we working with?'
  prefs: []
  type: TYPE_NORMAL
- en: A Probability Triple (sample space, sigma algebra, probability measure)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It all starts with a probability triple (not really, but this is where rigour
    starts). We call this a probability measure space, with the understanding that
    the measure of the whole sample space is equal to one. That is, the probability
    of the sample space is one. We are now feeling very advanced, using the words
    probability and measure interchangeably. The comfort that the word measure provides
    is that it brings up back to a deterministic realm. The sampling is random, but
    we can *measure* the likelihood of any occurence (that is measureable).
  prefs: []
  type: TYPE_NORMAL
- en: 'The three objects making up a probability measure space *(sample space, sigma
    algebra, probability measure)* are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The sample space**: the arbitrary nonempty set which we randomly pull samples
    from.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The sigma algebra**: A set of subsets of the sample space, which represent
    the allowed events (the events that we are allowed to talk to about their probability,
    because they are the only ones we are able to measure). A sigma algebra must contain
    the whole sample space, is closed under complements (meaning if a set is in the
    sigma algebra then so is its complement), and is closed under countable unions
    (meaning the union of countably many subsets of the sigma algebra is also a member
    of the sigma algebra). The corollary from the previous two properties and De Morgan’s
    law (that have to do with complements of unions and intersectons) is that the
    sigma algebra is also closed under countable intersections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The probability measure**: A number between zero and one (inclusive) associated
    with *each subset* of the sigma algebra, that satisfies the reasonable properties
    that we associate with non-rigorous probability:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prob(sample space)=1
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Prob(countable union of pairwise disjoint sets)=countable sum of probabilities
    of each set.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: This is very good, because as long as we are able to articulate the sample space
    set, the sigma algebra, and a function with the above properties mapping every
    member of the sigma algebra to its measure (probability), then we can start *building
    the theory* on solid grounds, defining all kinds of random variables, their expectations,
    variances, conditional probabilities, sums and products, limits of sequencesm,
    stochastic processes, time derivatives of functions of stochastic processes (Itô’s
    calculus), and so on. We would not run into problems of what type of events have
    probabilities defined for them (all the members of the sigma algebra of the probability
    triple), or what type of random variables we can consider (anyone which we can
    rigorously define over a probability triple).
  prefs: []
  type: TYPE_NORMAL
- en: Where is the difficulty?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Note that the limitations of non-rigorous probability that we discussed above
    *both* appear when we involve continuous variables, or when the sample space is
    in the continuum (uncountable). Had our world been only discrete we wouldn’t be
    going through all this trouble. When we move to rigorous probability, and attempt
    to construct probability triples for discrete sample spaces, we do not run into
    much trouble. The challenges appear in the continuum world, with uncountable sample
    spaces. Because suddenly we have to identify sigma algebras and associated probability
    measures on sets where the depth of the infinite continuum never ceases to fascinate.
    For example, this challenge appears even when we want to define a rigorous probability
    triple for the continuous uniform distribution on the interval [0,1].
  prefs: []
  type: TYPE_NORMAL
- en: 'The *extension theorem* runs to our aid and allows us to construct complicated
    probability triples: Instead of defining a probability measure over a massive
    sigma algebra, construct it on a simpler set of subsets, a *semialgebra*, then
    the theorem allows us to automatically extend the measure to a full sigma-algebra.
    This theorem allows us to construct Lebesgue measure on [0, 1] (which is exactly
    the continuous uniform distribution on [0,1]), product measures, the multi-dimensional
    Lebesgue measure, finite and infinite coin tossing.'
  prefs: []
  type: TYPE_NORMAL
- en: The worlds of set theory, real analysis, and probability have blended neatly
    together.
  prefs: []
  type: TYPE_NORMAL
- en: Random Variable, Expectation, and Integration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we can associate probability triple with a sample space, defining
    probabilities for a large amount of subsets of the sample space (all the members
    of the associated sigma algebra) we can rigorously define a random variable. As
    we know very well from non-rigorous probability: A random variable assigns a numerical
    value to each element of the sample space. So if we think of the sample space
    as all the possible random outcomes of some experiment (Heads and Tails of flipping
    a coin), then a random variable assigns a numerical value to each of these outcomes.'
  prefs: []
  type: TYPE_NORMAL
- en: To build on rigorous grounds, we must define how a random variable *Y* interacts
    with the whole probability triple associated with the sample space. The short
    answer is that it must be a *measurable* function from the sample space to the
    real line, in the sense that the set <math alttext="upper Y Superscript negative
    1 Baseline left-parenthesis negative normal infinity comma y right-parenthesis"><mrow><msup><mi>Y</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mrow><mo>(</mo> <mo>-</mo> <mi>∞</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow></mrow></math> ( <math alttext="upper Y
    Superscript negative 1"><msup><mi>Y</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    maps back from the real line a subset of the sample space), is a member of the
    sigma algebra, which means that it has a probability measure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like a random variable from non-rigorous probability turns out to be a
    measurable function (with respect to a triple) in rigorous probability theory,
    the expectation <math alttext="double-struck upper E left-parenthesis upper Y
    right-parenthesis"><mrow><mi>𝔼</mi> <mo>(</mo> <mi>Y</mi> <mo>)</mo></mrow></math>
    of a random variable turns out to be the same as the integral of the random variable
    (measurable function) with respect to the probability measure. We write:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign double-struck upper E left-parenthesis upper Y right-parenthesis
    equals integral Underscript normal upper Omega Endscripts upper Y d upper P equals
    integral Underscript normal upper Omega Endscripts upper Y left-parenthesis omega
    right-parenthesis upper P r o b left-parenthesis d omega right-parenthesis dollar-sign"><mrow><mi>𝔼</mi>
    <mrow><mo>(</mo> <mi>Y</mi> <mo>)</mo></mrow> <mo>=</mo> <msub><mo>∫</mo> <mi>Ω</mi></msub>
    <mi>Y</mi> <mi>d</mi> <mi>P</mi> <mo>=</mo> <msub><mo>∫</mo> <mi>Ω</mi></msub>
    <mi>Y</mi> <mrow><mo>(</mo> <mi>ω</mi> <mo>)</mo></mrow> <mi>P</mi> <mi>r</mi>
    <mi>o</mi> <mi>b</mi> <mrow><mo>(</mo> <mi>d</mi> <mi>ω</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the integral notation in the expectation formula
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is easy to understand the integral with respect to a probability measure,
    such as the one in the above formula, if we think of the meaning of the expectation
    of a random variable in a discrete setting, as the sum of the value of the random
    variable times the probability of the set over which it assumes that value:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign double-struck upper E left-parenthesis upper Y right-parenthesis
    equals sigma-summation Underscript i equals 1 Overscript n Endscripts y Subscript
    i Baseline upper P left-parenthesis omega element-of normal upper Omega such that
    upper Y left-parenthesis omega right-parenthesis equals y Subscript i Baseline
    right-parenthesis dollar-sign"><mrow><mi>𝔼</mi> <mrow><mo>(</mo> <mi>Y</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <msub><mi>y</mi> <mi>i</mi></msub> <mi>P</mi> <mrow><mo>(</mo> <mi>ω</mi> <mo>∈</mo>
    <mi>Ω</mi> <mtext>such</mtext> <mtext>that</mtext> <mi>Y</mi> <mrow><mo>(</mo>
    <mi>ω</mi> <mo>)</mo></mrow> <mo>=</mo> <msub><mi>y</mi> <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Now compare this discrete expression to the continuum integral above.
  prefs: []
  type: TYPE_NORMAL
- en: 'We rigorously build the above integral (expectation) up the exact same way
    we build up the Lebesgue integral in measure theory: First for simple random variables,
    then for nonnegative random variables, and finally for general random variables.
    We can easily prove basic properties for integrals such as linearity and order-preserving.
    Note that whether the sample space is discrete, continuous, or anything complicated,
    as long as we have our probability triple to build on, the above integral makes
    sense (in a much wider range of setting that we ever imagined for our basic calculus
    Reimann style integration). Once we encounter Lebesgue style integration, we sort
    of never look back.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the expectation, we can define the variance and covariance
    exactly the same way as non-rigorous probability theory.
  prefs: []
  type: TYPE_NORMAL
- en: Then we can talk about independence, and important properties such that if X
    and Y are independent, then E(XY) = E(X)E(Y) and Var(X + Y) = Var(X) + Var(Y).
  prefs: []
  type: TYPE_NORMAL
- en: Distribution of a Random Variable and the Change of Variable theorem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The distribution of a random variable *X* is *a corresponding probability triple*
    <math alttext="left-parenthesis double-struck upper R comma script upper B comma
    mu right-parenthesis"><mrow><mo>(</mo> <mi>ℝ</mi> <mo>,</mo> <mi>ℬ</mi> <mo>,</mo>
    <mi>μ</mi> <mo>)</mo></mrow></math> defined on the real line, such that for every
    subset *B* of the *Borel* sigma algebra defined on the real line, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign mu left-parenthesis upper B right-parenthesis equals
    upper P left-parenthesis upper X element-of upper B right-parenthesis equals upper
    P left-parenthesis upper X Superscript negative 1 Baseline left-parenthesis upper
    B right-parenthesis right-parenthesis dollar-sign"><mrow><mi>μ</mi> <mrow><mo>(</mo>
    <mi>B</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>X</mi>
    <mo>∈</mo> <mi>B</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mo>(</mo> <msup><mi>X</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mrow><mo>(</mo> <mi>B</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This is completely determined by the cumulative distribution function, <math
    alttext="upper F Subscript upper X Baseline left-parenthesis x right-parenthesis
    equals upper P left-parenthesis upper X less-than-or-equal-to x right-parenthesis"><mrow><msub><mi>F</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi>
    <mrow><mo>(</mo> <mi>X</mi> <mo>≤</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    , of *X*.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we have a real valued function *f* defined on the real line. Let *X*
    be a random variable on a probability triple <math alttext="left-parenthesis normal
    upper Omega comma s i g m a a l g e b r a comma upper P right-parenthesis"><mrow><mo>(</mo>
    <mi>Ω</mi> <mo>,</mo> <mi>s</mi> <mi>i</mi> <mi>g</mi> <mi>m</mi> <mi>a</mi> <mi>a</mi>
    <mi>l</mi> <mi>g</mi> <mi>e</mi> <mi>b</mi> <mi>r</mi> <mi>a</mi> <mo>,</mo> <mi>P</mi>
    <mo>)</mo></mrow></math> with distribution <math alttext="mu"><mi>μ</mi></math>
    . Note that for any real number *x*, f(x) is a real number, and for the random
    variable *X*, f(X) is a random variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The change of variable theorem says that the expected value of the random variable
    *f(X)* with respect to the probability measure *P* on a sample space <math alttext="normal
    upper Omega"><mi>Ω</mi></math> is equal to the expected value of the function
    *f* with respect to the measure <math alttext="mu"><mi>μ</mi></math> on <math
    alttext="double-struck upper R"><mi>ℝ</mi></math> . Let’s write this first in
    terms of expectation and then in terms of integrals:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign double-struck upper E Subscript upper P Baseline
    left-parenthesis f left-parenthesis upper X right-parenthesis right-parenthesis
    equals double-struck upper E Subscript mu Baseline left-parenthesis f right-parenthesis
    period dollar-sign"><mrow><msub><mi>𝔼</mi> <mi>P</mi></msub> <mrow><mo>(</mo>
    <mi>f</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo>
    <msub><mi>𝔼</mi> <mi>μ</mi></msub> <mrow><mo>(</mo> <mi>f</mi> <mo>)</mo></mrow>
    <mo>.</mo></mrow></math><math alttext="dollar-sign integral Underscript normal
    upper Omega Endscripts f left-parenthesis upper X left-parenthesis omega right-parenthesis
    right-parenthesis upper P left-parenthesis d omega right-parenthesis equals integral
    Subscript negative normal infinity Superscript normal infinity Baseline f left-parenthesis
    t right-parenthesis mu left-parenthesis d t right-parenthesis period dollar-sign"><mrow><msub><mo>∫</mo>
    <mi>Ω</mi></msub> <mi>f</mi> <mrow><mo>(</mo> <mi>X</mi> <mrow><mo>(</mo> <mi>ω</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mi>P</mi> <mrow><mo>(</mo> <mi>d</mi> <mi>ω</mi>
    <mo>)</mo></mrow> <mo>=</mo> <msubsup><mo>∫</mo> <mrow><mo>-</mo><mi>∞</mi></mrow>
    <mi>∞</mi></msubsup> <mi>f</mi> <mrow><mo>(</mo> <mi>t</mi> <mo>)</mo></mrow>
    <mi>μ</mi> <mrow><mo>(</mo> <mi>d</mi> <mi>t</mi> <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'A nice thing that comes handy from the above change of variables theorem is
    that we can switch between expectations, integrations, and probabilities: Let
    *f* be the indicator function of a measurable subset of <math alttext="double-struck
    upper R"><mi>ℝ</mi></math> , then the above formula gives us:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign integral Subscript negative normal infinity Superscript
    normal infinity Baseline bold 1 Subscript upper B Baseline mu left-parenthesis
    d t right-parenthesis equals mu left-parenthesis upper B right-parenthesis equals
    upper P left-parenthesis upper X element-of upper B right-parenthesis period dollar-sign"><mrow><msubsup><mo>∫</mo>
    <mrow><mo>-</mo><mi>∞</mi></mrow> <mi>∞</mi></msubsup> <msub><mn mathvariant="bold">1</mn>
    <mi>B</mi></msub> <mi>μ</mi> <mrow><mo>(</mo> <mi>d</mi> <mi>t</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mi>μ</mi> <mrow><mo>(</mo> <mi>B</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>∈</mo> <mi>B</mi> <mo>)</mo></mrow>
    <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Next Steps in Rigorous Probability Theory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next step in rigorous probability theory is to prove the famous inequalities
    (Markov, Chebyshev, Cauchy-Schwarz, Jensen’s), introduce sums and products of
    random variables, the laws of large numbers, and the central limit theorem. Then
    we move to sequences of random variables and limit theorems.
  prefs: []
  type: TYPE_NORMAL
- en: Limit theorems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If we have a sequence of random variables that converges to some limit random
    variable, does it follow that the expectations of the sequence converge to the
    expectation of the limit? In integral language, when can we exchange the limit
    and the integral?
  prefs: []
  type: TYPE_NORMAL
- en: This is when we prove the monotone convergence, the bounded convergence, Fatou’s
    lemma, the dominated convergence, and the uniformly integrable convergence theorems.
  prefs: []
  type: TYPE_NORMAL
- en: Finally we consider double or higher integrals, and conditions on when it is
    okay to flip integrals. Fubini’s theorem answers that, and we can apply it to
    give a convolution formula for the distribution of a sum of independent random
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: The universality theorem for neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rigorous measure theory (probability theory) helps us prove theorems for neural
    networks, which is an up-and-coming subfield of mathematics, aiming to provide
    theoretical grounds for many emperical AI successes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The universality theorem for neural networks is a starting point. We have referred
    to it multiple times in this book. Here’s the statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '*For any continuous function f on a compact set K, there exists a feed forward
    neural network, having only a single hidden layer, which uniformly approximates
    f to within an arbitrary <math alttext="epsilon greater-than 0"><mrow><mi>ϵ</mi>
    <mo>></mo> <mn>0</mn></mrow></math> on K.*'
  prefs: []
  type: TYPE_NORMAL
- en: This [webpage](https://mcneela.github.io/machine_learning/2017/03/21/Universal-Approximation-Theorem.xhtml)
    has a nice and easy to follow proof.
  prefs: []
  type: TYPE_NORMAL
- en: Summary And Looking Ahead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we surveyed concepts in probability that are important for
    AI, machine learning, and data science. We zipped through topics such as causal
    modeling, paradoxes, large random matrices, stochastic processes, and reinforcement
    learning in AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Often when we learn about probability, we fall into the *frequentist* vs. the
    *objectivist* positions regarding the definitions and the overall philosophy surrounding
    uncertainty. The following is a neat description of each viewpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: A *frequentist* position is that probabilities can only come from experiments
    and observing the results of repeated trials.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An *objectivisit* position is that probabilities are real aspects of the universe:
    A real inclination or natural tendency to behave in a particular way. For example
    a fair coin’s propensity to turn up Head fifty percent of the time is an intrinsic
    property of the fair coin iteself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A frequentist is then only attempting to measure these natural inclinations
    via experiments. Rigorous probability theory unifies disparate views of probability.
    We swiftly introduced rigorous probability theory and established that it is in
    essence the same as measure theory in real analysis. We ended with the universal
    approximation theorem for neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'We leave this chapter with a perfectly fitting tweet from [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun),
    which happens to touch on every topic we covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*I believe we need to find new concepts that would allow machines to:*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Learn how the world works by observing like babies.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Learn to predict how one can influence the world through taking actions.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Learn hierarchical representations that allows long-term predictions in abstract
    representation spaces.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Properly deal with the fact that the world is not completely predictable.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Enable agents to predict the effects of sequences of actions so as to be able
    to reason and planenable machines to plan hierarchically, decomposing a complex
    task into subtasks.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*All of this in ways that are compatible with gradient-based learning.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
