- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why I Wrote This Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI is built on mathematical models. We need to know how.
  prefs: []
  type: TYPE_NORMAL
- en: I wrote this book in purely colloquial language, leaving most of the technical
    details outside. It is a math book about AI, however, with very few mathematical
    formulas and equations, no theorems, no proofs, and no coding. My goal is not
    to keep this important knowledge in the hands of very few elite, and to attract
    more people to technical fields. I believe that many people get turned off by
    math before they ever get a chance to know that they might love it and be naturally
    good at it. This also happens in college or in graduate school, where many students
    switch their majors from math, or start a Ph.D. and never finish it. The reason
    is not because they do not have the ability, but because they saw no motivation
    or an end goal for learning torturous methods and techniques that did not seem
    to transfer to anything useful in their lives. It is like going to a brain gym
    everyday only for the sake of going there. No one even wants to go to the real
    gym everyday (this is a biased statement but you get the point). In math, formalizing
    objects into functions, spaces, measure spaces, and entire mathematical fields
    comes *after* motivation, not *before*. Unfortunately, it gets taught in reverse,
    with formality first and then, if we are lucky, some motivation.
  prefs: []
  type: TYPE_NORMAL
- en: The most beautiful thing about math is that it has the expressive ability to
    connect seemingly disparate things together. A field as big and as consequential
    as AI not only builds on math, as that is a given, but it needs the binding ability
    that only math can provide, in order to tell its big story concisely. In this
    book I will extract the math required for AI in a way that does not deviate at
    all from the real life AI application in mind. It is infeasible to go through
    existing tools in detail and not fall into an encyclopedic and overwhelming treatment.
    What I do instead is try to teach you *how to think* about these tools and *view
    them from above*, as a means to an end that we can tweak and adjust when we need
    to. I hope that what you will get out of this book is a way of seeing how things
    relate to each other and why we develop or use certain methods among others. In
    a way, this book provides a platform that launches you out to whatever area you
    find interesting or want to specialize in.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another goal of this book is to democratize mathematics, and to build more
    peoples’ confidence to ask about how things work. Common answers such as, “It’s
    complicated mathematics”, “It’s complicated technology”, or “It’s complex models”,
    are no longer satisfying, especially that the technologies that build on mathematical
    models currently affect every aspect of our lives. We do not need to be experts
    in every field in mathematics (no one is) in order to understand how things are
    built and why they operate the way they do. There is one thing about mathematical
    models that everyone needs to know: They *always* give an answer. They always
    spit out a number. A model that is vetted, validated, and backed with sound theory
    gives an answer. *Also*, a model that is *complete trash* gives an answer. Both
    compute mathematical functions. Saying that our decisions are based on mathematical
    models and algorithms does not make them sacred. What are the models built on?
    What are their assumptions? Limitations? Data they were trained on? Tested on?
    What variables did they take into account? And what did they leave out? Do they
    have a feedback loop for improvement, ground truths to compare to and improve
    on? Is there any theory backing them up? We need to be *transparent* with this
    information when the models are ours, and ask for it when the models are the ones
    deciding our livelihoods for us.'
  prefs: []
  type: TYPE_NORMAL
- en: The unorthodox organization of the topics in this book is intentional. I wanted
    to avoid getting stuck in math details before getting to the applicable stuff.
    My stand on this is that we do not ever need to dive into background material
    unless we happen to be personally practicing something and that background material
    becomes an unfulfilled gap in our knowledge that is stopping us from making progress.
    Only then it is worth investing serious time learning the intricate details of
    things. It is much more important to see how it all ties together and where everything
    fits. In other words, this book provides a map for how everything between math
    and AI interact nicely together.
  prefs: []
  type: TYPE_NORMAL
- en: 'I also want to make a note to new comers about the era of large data sets.
    Before working with large data, real or simulated, structured or unstructured,
    we might have taken computers and the internet for granted. If we came up with
    a model or needed to run analytics on small and curated data sets, we might have
    assumed that our machine’s hardware will handle the computations, or that the
    internet will just give more curated data when we needed it, or more information
    about similar models. The reality and limitations to access to data, errors in
    the data, errors in the outputs of queries, limitations of hardware, storage,
    data flow between devices, and vectorizing unstructured data such as natural language
    or images and movies, hits us really hard. That is when we start getting into
    parallel computing, cloud computing, data management, data bases, data structures,
    data architectures, and data engineering, in order to understand the infrastructure
    that allows us to run our models. What kind of infrastructure do we have? How
    is it structured? How did it evolve? Where it is headed? What materials does it
    use? How do these materials work? And what is all the fuss about quantum computing?
    We should not view the software as separate from the hardware, or our models separate
    from the infrastructure that allows us to simulate them. This book focuses only
    on the math, the AI models, and some data. There are neither exercises nor coding.
    In other words, we focus on the *soft, intellectual,* and the *I do not need to
    touch anything* side of things. But we need to keep learning until we are able
    to comrprehend the technology that powers many aspects of our lives as the one
    interconnected body that it actually is: Hardware, software, sensors and measuring
    devices, data warehouses, connecting cables, wireless hubs, satellites, communication
    centers, physical and software security measures, and mathematical models.'
  prefs: []
  type: TYPE_NORMAL
- en: Who Is This Book For?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a person who knows math but wants to get into AI, machine learning, and
    data science.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a person who practices AI, data science, and machine learning but wants
    to brush up on their mathematical thinking and gets up to date with the mathematical
    ideas behind the state of the art models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For undergraduate or early graduate students in math, data science, computer
    science, operations research, science, engineering, or other domains who have
    an interest in AI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a person in a management position who wants to integrate AI and data analytics
    into their operations but wants a deeper understanding of how the models that
    they might end up basing their decisions on actually work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For data analysts who are primarily doing business intelligence, and are now,
    like the rest of the world, driven into *AI-powered business intelligence*, so
    they want to know what that actually means before adopting it into business decisions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a person who cares about the ethical challenges that AI might pose to the
    world and want to understand the inner workings of the models so that they can
    argue for or against certain issues such as autonomous weapons, targeted advertising,
    data management, *etc.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For educators who want to put together courses on Math and AI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For any person who is curious about AI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who Is This Book Not For?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A person who likes to sit down and do many exercises to master a particular
    mathematical technique or method, a person who likes to write and prove theorems,
    or a person who wants to learn coding and development. This is not a math texbook.
    There are many excellent textbooks which teach calculus, linear algebra, and probability
    (but few books relate this math to AI). That said, this book has many in-text
    pointers to the relevant books and scientific publications for readers who want
    to dive into technicalities, rigorous statements, and proofs. This is also not
    a coding book. The emphasis is on concepts, intuition, and general understanding,
    rather than on implementing and developing the technology.
  prefs: []
  type: TYPE_NORMAL
- en: How Will The Math Be Presented In This Book?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Writing a book is ultimately a decision making process: How to organize the
    material of the subject matter in a way that is most insightful into the field,
    and how to choose what and what not to elaborate on. I will detail some math in
    few places and I will omit details in others. This is on purpose as my goal is
    not to get distracted from telling the story of:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Which math do we use, why do we need it, and where exactly do we use it in
    AI?*'
  prefs: []
  type: TYPE_NORMAL
- en: I always define the AI context, with many applications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then I talk about the related mathematics, sometimes with details and others
    only with the general way of thinking. Whenever I skip details, I point out the
    relevant questions that we should be asking and how to go about finding their
    answers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I showcase the math, the AI, and the models as one connected entity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'I dive deeper into math only if it must be part of the foundation. Even then,
    I favor intuition over formality. The price I pay here is that on very few occassions,
    I might use some technical terms before defining them, secretly hoping that you
    might have encountered these terms before. In this sense, I adopt AI’s *transformer
    (Google Brain, 2017)* philosophy for natural language understanding: The model
    learns word meanings from their context. So when you encounter a technical term
    that I have not defined before, focus on the term’s surrounding environment. Over
    the course of the section within which it appears, you will have a very good intuition
    about its meaning. The other option, of course, is to *google it*. Overall, I
    avoid *jargon* and I use zero acronyms.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since this book lies at the intersection of math, data science, AI, machine
    learning, and philosophy, I wrote it expecting a diverse audience with drastically
    different skill sets and backgrounds. For this reason, depending on the topic,
    the same material might feel trivial to some but complicated to others. I hope
    I do not insult anyone’s mind in the process. That said, this is a risk that I
    am willing to take, so that all readers will find useful things to learn from
    this book. For example, mathematicians will learn the AI application, and data
    scientists and AI practicioners will learn deeper math.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The sections go in and out of technical difficulty, so if a section gets too
    confusing, make a mental note of its existence and skip to the next section. You
    can come back to what you skipped at a later time.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the chapters are independent from each other, so readers can jump straight
    to their topics of interest. When chapters are related to other chapters, I point
    that out. Since I try to make each chapter as self contained as possible, I may
    repeat few explanations across different chapters. I push the probability chapter
    all the way near the end ([Chapter 11](ch11.xhtml#ch11)), but I use and talk about
    probability distributions all the time (especially the joint probability distribution
    of the features of a data set). The idea is to get used to the language of probability
    and how it relates to AI models before learning its grammar, so when we get to
    learning the grammar, we have a good idea of the context that it fits in.
  prefs: []
  type: TYPE_NORMAL
- en: 'I believe that there are two types of learners: Those who learn the specifics
    and the details, then slowly start formulating a bigger picture and a map for
    how things fit together; and those who first need to understand the big picture
    and how things relate to each other, then dive into the details only when needed.
    Both are equally important, and the difference is only in someone’s type of brain
    and natural inclination. I tend to fit more into the second category and this
    book is a reflection of that: How does it all look from above, and how do math
    and AI interact with each other? The result might feel like a *whirlwind* of topics,
    but you’ll come out on the other side with a great knowledge base for both math
    and AI, plus a good dose of confidence.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When my dad taught me to drive, he sat in the passenger’s seat and asked me
    to drive. Ten minutes in, the road became a cliffside road. He asked me to stop,
    got out of the car, then said: *Now drive, just try not to fall off the cliff,
    don’t be afraid, I am watching* (like that was going to help). I did not fall
    off the cliff, and in fact I love cliffside roads the most. Now tie this to training
    self driving cars by reinforcement learning, with the distinction that the cost
    of falling off the cliff would’ve been minus infinity for me. I could not afford
    that, I am a real person in a real car, not a simulation.'
  prefs: []
  type: TYPE_NORMAL
- en: This is how you’ll do math and AI in this book. There are no introductions,
    conclusions, definitions, theorems, exercises, or anything of the like. There
    is immersion.
  prefs: []
  type: TYPE_NORMAL
- en: '*You are already in it. You know it. Now drive.*'
  prefs: []
  type: TYPE_NORMAL
- en: Infographic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I accompany this book with an infographic, visually tying all the topics together.
    You can find this on the book’s github page: [*https://github.com/halanelson/Essential-Math-For-AI*](https://github.com/halanelson/Essential-Math-For-AI).'
  prefs: []
  type: TYPE_NORMAL
- en: What Math Background Is Expected From You To Be Able To Read This Book?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This book is self contained in the sense that we motivate everything that we
    need to use. I do hope that you have been exposed to Calculus and some Linear
    Algebra, including vector and matrix operations, such as addition, multiplication,
    and some matrix decompositions. I also hope that you know what a function is and
    how it maps an input to an output. Most of what we do mathematically in AI involves
    constructing a function, evaluating a function, optimizing a function, or composing
    a bunch of functions. You need to know about derivatives (these measure how fast
    things change) and the chain rule for derivatives. You do not necessarily need
    to know how to compute them for each function, as computers, Desmos, and MathWolfram
    Alpha do everything for us nowadays, but you need to know their meaning. Some
    exposure to probabilistic and statistical thinking are helpful as well. If you
    do not know any of the above, that is totally fine. You might have to sit down
    and do some examples (from some other books) on your own to familiarize yourself
    with certain concepts. The trick here is that you should know when to look up
    the things that you do not know: *Only when you need them*, meaning only when
    you encounter a term that you do not understand, and you have a good idea of the
    context within which it appeared. If you are truly starting from scratch, you
    are not too far behind. This book tries to avoid technicalities at all costs.'
  prefs: []
  type: TYPE_NORMAL
- en: Overview Of The Chapters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**We have a total of fourteen chapters.**'
  prefs: []
  type: TYPE_NORMAL
- en: If you are a person who cares for math and the AI technology as they relate
    to ethics, policy, societal impact, and the various implications, opportunities,
    and challenges, then read **Chapters [1](ch01.xhtml#ch01) and [14](ch14.xhtml#ch14)
    first**. If you do not care for those, then we make the case that you should.
    In this book, we treat math as the binding agent of seemingly disparate topics,
    rather than math’s usual presentation as an oasis of complicated formulas, theorems,
    and greek letters.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 13](ch13.xhtml#ch13)** might feel separate from the book if you
    never encountered differential equations (ODEs and PDEs), but you would appreciate
    it if you are into mathematical modeling, the physical and natural sciences, simulation,
    or mathematical analysis, and you would like to know how AI can benefit your field,
    and in turn how differential equations can benefit AI. Countless scientific feats
    build on differential equations, so we cannot leave them out when we are at a
    dawn of a computational technology that has the potential to address many of the
    field’s long standing problems. This chapter is not *essential for AI* per se,
    but it is essential for our general understanding of mathematics as a whole, and
    for building theoretical foundations for AI and neural operators.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the chapters are essential for AI, machine learning, and data science.
    There is no optimal location for **[Chapter 6](ch06.xhtml#ch06)** on the singular
    value decomposition (the essential math for principal component analysis and latent
    semantic analysis, and a great method for dimension reduction). Let your natural
    curiosity dictate when you read this chapter: Before or after whichever chapter
    you feel would be the most fitting. It all depends on your background and which
    industry or academic discipline you happen to come from.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s briefly overview Chapters [1](ch01.xhtml#ch01) and [14](ch14.xhtml#ch14):'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 1, “Why Learn the Mathematics of AI”](ch01.xhtml#ch01)**'
  prefs: []
  type: TYPE_NORMAL
- en: Artificial Intelligence is here. It has already penetrated many areas of our
    lives, is involved in making important decisions, and soon will be employed in
    every sector of our society and operations. The technology is advancing very fast
    and its investments are skyrocketing. What is Artificial Intelligence? What is
    it able to do? What are its limitations? Where is it headed? And most importantly,
    how does it work, and why should we really care about knowing how it works? In
    this introductory chapter we briefly survey important AI applications, the problems
    usually encountered by companies trying to integrate AI into their systems, incidents
    that happen when systems are not well implemented, and the math typically used
    in AI solutions.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 2, “Data, Data, Data”](ch02.xhtml#ch02)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter highights the fact that data is central to AI. It explains the
    differences between concepts that are usually a source of confusion: Structured
    and unstructured data, linear and nonlinear models, real and simulated data, deterministic
    functions and random variables, discrete and continuous distributions, prior probabilities,
    posterior probabilities and likelihood functions. It also provides a map for the
    probability and statistics needed for AI without diving into any details, and
    introduces the most popular probability distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 3, “Fitting Functions to Data”](ch03.xhtml#ch03)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'At the core of many popular machine learning models, including the highly successful
    neural networks that brought Artificial Intelligence back into the popular spotlight
    since 2012, lies a very simple mathematical problem: Fit a given set of data points
    into an appropriate function, then make sure this function performs well on new
    data. This chapter highlights this widely useful fact with a real data set and
    other simple examples. Regression, Logistic Regression, and some popular machine
    learning techniques are discussed here, with one unifying theme: Training function,
    loss function, and optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 4, “Optimization For Neural Networks”](ch04.xhtml#ch04)**'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks are modeled after the brain cortex, which involves millions
    of neurons arranged in a layered structure. The brain learns by reinforcing neuron
    connections when faced with a concept it has seen before and weakening connections
    if it learns new information that undoes or contradicts previously learned concepts.
    Machines only understand numbers. Mathematically, stronger connections correspond
    to larger numbers, and weaker connections correspond to smaller numbers. This
    chapter explains the optimization and backpropagation steps used when training
    neural networks similar to how learning happens in our brain (not that we fully
    understand this yet). It also walks through various regularization techniques,
    explaining their advantages, disadvantages, and use cases. Furthermore, we explain
    the intuition behind approximation theory and the universal approximation theorem
    for neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 5, “Convolutional Neural Networks and Computer Vision”](ch05.xhtml#ch05)**'
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional neural networks are widely popular for computer vision and natural
    language processing. In this chapter we start with the convolution and cross correlation
    operations then surveys their uses in systems design and filtering signals and
    images. Then we integrate convolution with neural networks in order to extract
    higher order features from images.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 6, “Singular Value Decomposition: Image Processing, Natural Language
    Processing and Social Media”](ch06.xhtml#ch06)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Diagonal matrices behave like scalar numbers and hence are highly desirable.
    Singular value decomposition is a crucially important mathematical method from
    linear algebra that transforms a dense matrix into a diagonal matrix. In the process
    it reveals the action of a matrix on space itself: rotating, stretching and squeezing.
    We can apply this simple process to *any* matrix of numbers. This wide applicability,
    along with its ability to dramatically reduce the dimensions while reatining essential
    information, made the singular value decomposition popular in the fields of data
    science, artificial intelligence and machine learning. It is the essential mathematics
    behind principal component analysis and latent semantic analysis. This chapter
    walks through singular value decomposition along with its most relevant and up
    to date applications.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 7, “Natural Language And Finance AI: Vectorization And Time Series”](ch07.xhtml#ch07)**'
  prefs: []
  type: TYPE_NORMAL
- en: We present the mathematics in this chapter in the context of natural language
    models, such as identifying topics, machine translation, and attention models.
    The main barrier to overcome is moving from words and sentences that carry meaning
    to low dimensional vectors of numbers that a machine can process. We discuss state
    of the art models such as Google Brain’s transformer (starting 2017), among others,
    while we keep the attention only the relevant math. Time series data and models
    (such as recurrent neural networks) appear naturally here. We briefly introduce
    finance AI, as it overlaps with natural language both in terms of modeling and
    in terms of how the two fields feed into each other.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 8, “Probabilistic Generative Models”](ch08.xhtml#ch08)**'
  prefs: []
  type: TYPE_NORMAL
- en: Machine generated images, including those of humans, are becoming increasingly
    more realistic. It is very hard nowadays to tell whether an image of a model in
    the fashion industry is that of a real person or a computer generated image. We
    have Generative Adversarial Networks to thank for this progress, where it is made
    harder to draw the line between the virtual and the real. These networks are designed
    in a way that repeats a simple mathematical process using two neural networks
    until the machine itself cannot tell the difference between a real image and a
    computer generated one, hence the ‘very close to reality’ success. Game theory
    and zero sum games occur naturally here, as the two neural networks ‘compete’
    against each other. This chapter surveys generative models, which imagination
    in the human mind. These networks have a wide range of applications, from augmenting
    data sets to completing masked human faces to high energy physics, such as simulating
    data sets similar to those produced at the CERN Large Hardon Collider.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 9, “Graph Models”](ch09.xhtml#ch09)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Graphs and networks are everywhere: Cities and roadmaps, airports and connecting
    flights, the world wide web, the cloud (in computing), molecular networks, our
    nervous system, social networks, terrorist organization networks, even various
    machine learning models and artificial neural networks. Data that has a natural
    graph structure can be better understood by a mechanism that exploits and preserves
    that structure, building functions that operate directly on graphs, as opposed
    to embedding graph data into existing machine learning models that attempt to
    artificially reshape it before analyzing it. This is the same reason convolutional
    neural networks are successful with image data, recurrent neural networks are
    successful with sequential data, and so on. The mathematics behind graph neural
    networks is a marriage between graph theory, computing, and neural networks. This
    chapter surveys this mathematics in the context of many applications.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 10, “Operations Research”](ch10.xhtml#ch10)**'
  prefs: []
  type: TYPE_NORMAL
- en: Another suitable name for operations research would be *optimization for logistics*.
    This chapter introduces the reader to problems at the intersection of AI and operations
    research, such as supply chain, traveling salesman, scheduling and staffing, queuing,
    and other problems whose defining feature is high dimensionality, complexity,
    and balancing competing interests and limited resources. The math required to
    address these problems draws from optimization, game theory, duality, graph theory,
    dynamic programming, and algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 11, “Probability”](ch11.xhtml#ch11)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Probability theory provides a systematic way to quantify randomness and uncertainty.
    It generalizes logic to situations which are of paramount importance in artificial
    intelligence: When information and knowledge are uncertain. This chapter highlights
    the essential probability used in AI applications: Bayes networks and causal modeling,
    paradoxes, large random matrices, stochastic processes, Markov chains, and reinforcement
    learning. It ends with rigorous probability theory, which demystifies measure
    theory and introduces interested readers to the proof of the universal approximation
    theorem for neural networks.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 12, “Mathematical Logic”](ch12.xhtml#ch12)**'
  prefs: []
  type: TYPE_NORMAL
- en: This important topic is positioned near the end in order not to interrupt the
    book’s natural flow. Designing agents who are able to gather knowledge, reason
    logically about the environment within which they exist, and make inferences and
    good decisions based on this logical reasoning is at the heart of artificial intelligence.
    This chapter briefly surveys propositional logic, first order logic, probabilistic
    logic, fuzzy logic, and temporal logic, within an intelligent knowledge-based
    agent.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 13, “Artificial Intelligence and Partial Differential Equations”](ch13.xhtml#ch13)**'
  prefs: []
  type: TYPE_NORMAL
- en: Differential equations model countless phenomena in the real world, from air
    turbulence to galaxies to the stock market to behavior of materials and population
    growth. Realistic models are usually very hard to solve and require a tremendous
    amount of computational power when we rely on traditional numerical techniques.
    AI has recently stepped in to accelerate solving PDEs. The first part of this
    chapter acts as a crash course on differential equations, highlighting the most
    important topics and arming the reader with a bird’s-eye view of the subject.
    The second part explores new AI based methods that simplify the whole process
    of solving differential equations. These have the potential to unlock long standing
    problems in the sciences, finance, and other fields.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Chapter 14, “Artificial Intelligence, Ethics, Mathematics, And Policy”](ch14.xhtml#ch14)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'I believe this chapter should be the first chapter in any book on artificial
    intelligence, however, this topic is so wide and deep that it needs multiple books
    to cover. This chapter only scratches the surface and summarizes various ethical
    issues associated with artificial intelligence, including: equity, fairness, bias,
    inclusivity, transparency, policy, regulation, privacy, weaponization, and security.
    It presents each problem along with possible solutions (mathematical or with policy
    and regulation).'
  prefs: []
  type: TYPE_NORMAL
- en: My Favorite Books on AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many excellent and incredibly insightful books on AI and on topics
    intimately related to the field. The following is not even close to being an exhaustive
    list. Some are technical books heavy on mathematics and others are either introductory
    or completely nontechnical. Some are code oriented (Python 3) and others are not.
    I have learned a lot from all:'
  prefs: []
  type: TYPE_NORMAL
- en: Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow, by Aurélien
    Géron, O’Reilly 2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear Algebra and Learning from Data, by Gilbert Strang, Wellesley Cambridge
    Press, 2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random Graphs and Complex Networks, by Remco van der Hofstad, Cambridge, 2017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine Learning Design Patterns, by Valliappa Lakshmanan, Sara Robinson and
    Michael Munn, O’Reilly 2020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computer Vision with TensorFlow2, Packt, 2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architects of Intelligence, by Martin Ford, Packt, 2018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artificial Intelligence for the IoT Cookbook, by Michael Roshak, Packt, 2021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Advancing Into Analytics: From Excel to Python and R, by George Mount, O’Reilly
    Media, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayes’ Rule, A Tutorial Introduction to Bayesian Analysis, by James V Stone,
    Sebtel Press, 2013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Information Theory: A Tutorial Introduction, by James V Stone, Sebtel Press,
    2015'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Atlas of AI, by Kate Crawford, Yale University Press, 2021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Thousand Brains, by Jeff Hawkins, Basic Books New York, 2021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI and Machine Learning for Coders, by Laurence Moroney, O’Reilly, 2021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A First Course in Random Matrix Theory for Physicists, Engineers, and Data Scientists,
    by Marc Potters and Jean-Philippe Bouchaud, Cambridge University Press, 2021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High Dimensional Probability, An Inroduction with Applications in Data Science,
    by Roman Vershynin, Cambridge University Press, 2018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practical Natural Language Processing, by Sowmya Vajjala, Bodhisattwa Majumder,
    Anuj Gupta, and Harshit Surana, O’Reilly, 2020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Artificial Intelligence: A Modern Approach, by Stuart Russell and Peter Norvig,
    Pearson, 2020'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artificial Intelligence in Practice, by Bernard Marr, Matt Ward- contributor,
    Gildan Media, 2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI Super Powers, by Kai-Fu Lee, Houghton Mifflin Harcourt, 2018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Natural Language Processing in Action, by Hobson Lane, Hannes Hapke, and Cole
    Howard, Manning Publications, 2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep Learning [*https://www.deeplearningbook.org*](https://www.deeplearningbook.org),
    by Ian Goodfellow, Yoshua Bengio, and Aaron Courville, MIT Press, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Science The Ultimate Guide to Data Analytics, Data Mining, Data Warehousing,
    Data Visualization, Regression Analysis, Database Querying, Big Data for Business
    and Machine Learning for Beginners, by Herbert Jones, 2018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Driven Science and Engineering, Machine Learning, Dynamical Systems and
    Control, by Steven L. Brunton and J. Nathan Kutz, Cambridge University Press,
    2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Science from Scratch, by Joel Grus, O’Reilly, 2019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 97 Things Every Data Engineer Should Know, edited by Tobias Macey, O’Reilly,
    2021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modern Multivariate Statistical Techniques, by Alan Julian Izenman, Springer,
    2013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A First Look at Rigorous Probability Theory, Second Edition, by Jeffrey S. Rosenthal,
    World Scientific Publishing, 2016
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing Data-Intensive Applications, by Martin Kleppmann, O’Reilly, 2017
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conventions Used in This Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following typographical conventions are used in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Italic*'
  prefs: []
  type: TYPE_NORMAL
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  prefs: []
  type: TYPE_NORMAL
- en: '`Constant width`'
  prefs: []
  type: TYPE_NORMAL
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  prefs: []
  type: TYPE_NORMAL
- en: '**`Constant width bold`**'
  prefs: []
  type: TYPE_NORMAL
- en: Shows commands or other text that should be typed literally by the user.
  prefs: []
  type: TYPE_NORMAL
- en: '*`Constant width italic`*'
  prefs: []
  type: TYPE_NORMAL
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  prefs: []
  type: TYPE_NORMAL
- en: This element signifies a tip or suggestion.
  prefs: []
  type: TYPE_NORMAL
- en: This element signifies a general note.
  prefs: []
  type: TYPE_NORMAL
- en: This element indicates a warning or caution.
  prefs: []
  type: TYPE_NORMAL
- en: Using Code Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The very few code examples that we have in this book are available for download
    at [*https://github.com/halanelson/Essential-Math-For-AI*](https://github.com/halanelson/Essential-Math-For-AI).
  prefs: []
  type: TYPE_NORMAL
- en: If you have a technical question or a problem using the code examples, please
    send email to [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing examples
    from O’Reilly books does require permission. Answering a question by citing this
    book and quoting example code does not require permission. Incorporating a significant
    amount of example code from this book into your product’s documentation does require
    permission.
  prefs: []
  type: TYPE_NORMAL
- en: 'We appreciate, but generally do not require, attribution. An attribution usually
    includes the title, author, publisher, and ISBN. For example: “*Essential Math
    for AI* by Hala Nelson (O’Reilly). Copyright 2023 Hala Nelson, 978-1-098-10763-5.”'
  prefs: []
  type: TYPE_NORMAL
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: O’Reilly Online Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For more than 40 years, [*O’Reilly Media*](https://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*https://oreilly.com*](https://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: How to Contact Us
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please address comments and questions concerning this book to the publisher:'
  prefs: []
  type: TYPE_NORMAL
- en: O’Reilly Media, Inc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1005 Gravenstein Highway North
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sebastopol, CA 95472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 800-998-9938 (in the United States or Canada)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-829-0515 (international or local)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-829-0104 (fax)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/essentialMathAI*](https://oreil.ly/essentialMathAI).
  prefs: []
  type: TYPE_NORMAL
- en: Email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com) to comment
    or ask technical questions about this book.
  prefs: []
  type: TYPE_NORMAL
- en: For news and information about our books and courses, visit [*https://oreilly.com*](https://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: 'Find us on LinkedIn: [*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow us on Twitter: [*https://twitter.com/oreillymedia*](https://twitter.com/oreillymedia)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Watch us on YouTube: [*https://www.youtube.com/oreillymedia*](https://www.youtube.com/oreillymedia)'
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'My dad, Yousef Zein, who taught me math, and made sure to always remind me:
    *Don’t think that the best thing we gave you in this life is land, or money, these
    come and go, humans create money, buy assets, and create more money. What we did
    give you is a brain, a really good brain, that’s your real asset, so go out and
    use it.* I love your brain, this book is for you, dad.'
  prefs: []
  type: TYPE_NORMAL
- en: My mom, Samira Hamdan, who taught me both English and philosophy, and who gave
    up everything to make sure we are happy and successful. I wrote this book in English,
    not my native language, thanks to you, mom.
  prefs: []
  type: TYPE_NORMAL
- en: My daughter, Sary, who kept me alive during the most vulnerable times, and who
    is the joy of my life.
  prefs: []
  type: TYPE_NORMAL
- en: My husband, Keith, who gives me the love, passion, and stability that allow
    me to be myself, and to do so many things, some of them unwise, like writing a
    five hundred page book on math and AI. I love you.
  prefs: []
  type: TYPE_NORMAL
- en: My sister, Rasha, who is my soulmate. This says it all.
  prefs: []
  type: TYPE_NORMAL
- en: My brother, Haitham, who went against all our cultural norms and traditions
    to support me.
  prefs: []
  type: TYPE_NORMAL
- en: My uncle, Omar Zein, who also taught me philosophy, and who made me fall in
    love with the mysteries of the human mind.
  prefs: []
  type: TYPE_NORMAL
- en: My friends Sharon and Jamie, who let me write massive portions of this book
    at their house, and were great editors any time I asked.
  prefs: []
  type: TYPE_NORMAL
- en: My lifetime friend Oren, who on top of being one of the best friends anyone
    can wish for, agreed to read and review this book.
  prefs: []
  type: TYPE_NORMAL
- en: My friend [Huan Nguyen](https://en.wikipedia.org/wiki/Huan_Nguyen), whose story
    should be its own book, and who also took the time to read and review this book.
    Thank you, Admiral.
  prefs: []
  type: TYPE_NORMAL
- en: My friend and colleague John Webb, who read every chapter word by word, and
    provided his invaluable pure math perspective.
  prefs: []
  type: TYPE_NORMAL
- en: My wonderful friends Deb, Pankaj, Jamie, Tamar, Sajida, Jamila, Jen, Mattias,
    and Karen, who are part of my family. I love life with you.
  prefs: []
  type: TYPE_NORMAL
- en: My mentors, Robert Kohn (New York University) and John Schotland (Yale University),
    to whom I owe reaching many milestones in my career. I learned a great deal from
    you.
  prefs: []
  type: TYPE_NORMAL
- en: The reviewers of this book, who took time and care despite their busy schedules
    to make it much better. Thank you for your great expertise and for generously
    giving me your unique perspectives from all your different domains.
  prefs: []
  type: TYPE_NORMAL
- en: The memory of Peter, whose impact was monumental, and who will forever inspire
    me.
  prefs: []
  type: TYPE_NORMAL
- en: All the waiters and waitresses in many cities in the world, who tolerated me
    sitting at my laptop at their restaurants for hours, and hours, and hours, writing
    this book. I got so much energy and happiness from you.
  prefs: []
  type: TYPE_NORMAL
- en: My incredible, *patient*, cheerful, and always supportive editor, Angela Rufino.
  prefs: []
  type: TYPE_NORMAL
