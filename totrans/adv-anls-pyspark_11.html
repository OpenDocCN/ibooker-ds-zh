<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 11. Managing the Machine Learning &#10;Lifecycle with MLflow" data-type="chapter" epub:type="chapter"><div class="chapter" id="idm46507962542192">
<h1><span class="label">Chapter 11. </span>Managing the Machine Learning 
<span class="keep-together">Lifecycle with MLflow</span></h1>
<p>As machine learning gains prominence across industries and is deployed in production environments, the level of collaboration and complexity surrounding it has increased as well. Thankfully, platforms and tools have cropped up to help manage the machine learning lifecycle in a structured manner. One such platform that works well with PySpark is MLflow. In this chapter, we will show how MLflow can be used with PySpark. Along the way, we’ll introduce key practices that you can incorporate in your data science workflow.</p>
<p>Rather than starting from scratch, we’ll build upon the work that we did in <a data-type="xref" href="ch04.xhtml#making_predictions_with_decision_trees_and_decision_forests">Chapter 4</a>. We will revisit our decision tree implementation using the Covtype dataset. Only this time, we’ll use MLflow for managing the machine learning lifecycle.</p>
<p>We’ll start by explaining the challenges and processes that encompass the machine learning lifecycle. We will then introduce MLflow and its components, as well as cover MLflow’s support for PySpark. This will be followed by an introduction to tracking machine learning training runs using MLflow. We’ll then learn how to manage machine learning models using MLflow Models. Then we’ll discuss deployment of our PySpark model and do an implementation for it. We’ll end the chapter by creating an MLflow Project. This will show how we can make our work so far reproducible for collaborators. Let’s get started by discussing the machine learning lifecycle.</p>
<section class="pagebreak-before less_space" data-pdf-bookmark="Machine Learning Lifecycle" data-type="sect1"><div class="sect1" id="idm46507960659968">
<h1>Machine Learning Lifecycle</h1>
<p>There are multiple ways to describe the<a data-primary="machine learning lifecycle" data-type="indexterm" id="ch11-cycle"/><a data-primary="MLflow" data-secondary="machine learning lifecycle" data-type="indexterm" id="ch11-cycle2"/> machine learning lifecycle. One simple way is to break it down into various components or steps, as shown in <a data-type="xref" href="#ml_lifecycle">Figure 11-1</a>. These steps may not necessarily be in sequence for every project, and the lifecycle is cyclic more often than not.</p>
<ul>
<li>
<p>Business project definition and stakeholder alignment</p>
</li>
<li>
<p>Data acquisition and exploration</p>
</li>
<li>
<p>Data modeling</p>
</li>
<li>
<p>Interpretation and communication of results</p>
</li>
<li>
<p>Model implementation and deployment</p>
</li>
</ul>
<figure><div class="figure" id="ml_lifecycle">
<img alt="machine learning lifecycle" height="635" src="assets/machine_learning_lifecycle.png" width="754"/>
<h6><span class="label">Figure 11-1. </span>ML lifecycle</h6>
</div></figure>
<p>The speed at which you can iterate through the ML lifecycle affects how fast you can put your work to practical use. For example, an implemented model can become outdated due to a change in underlying data. In that case, you will need to revisit past work and build upon it again.</p>
<p>Examples of challenges that can show up during a machine learning project’s lifecycle are:</p>
<dl>
<dt>Lack of reproducibility</dt>
<dd>
<p>Data scientists on the same team may not be able to reproduce each other’s results even if the code and parameters have been tracked. This can be a result of the execution environment (system configuration or library dependencies) being different.</p>
</dd>
<dt>Lack of standardization of models</dt>
<dd>
<p>Different teams may use different libraries and different conventions for storing machine learning models. This can become a problem when sharing work across teams.</p>
</dd>
</dl>
<p>Trying to structure your work while going through the ML lifecycle can quickly become overwhelming. In light of such challenges, multiple open source and proprietary platforms are available to help. One leading open source platform is MLflow, which we will introduce in the upcoming section.<a data-startref="ch11-cycle" data-type="indexterm" id="idm46507960643280"/><a data-startref="ch11-cycle2" data-type="indexterm" id="idm46507960642576"/></p>
</div></section>
<section data-pdf-bookmark="MLflow" data-type="sect1"><div class="sect1" id="idm46507960641648">
<h1>MLflow</h1>
<p>MLflow is an open source platform for managing<a data-primary="machine learning lifecycle" data-secondary="MLflow managing ML lifecycle" data-type="indexterm" id="idm46507960640016"/><a data-primary="MLflow" data-secondary="about" data-type="indexterm" id="idm46507960638960"/> the end-to-end machine learning lifecycle. It helps us reproduce and share experiments, manage models, and deploy models for end users. In addition to a REST API and CLI, it also provides APIs for Python, R, and Java/Scala.</p>
<p>It has four main components, as shown in <a data-type="xref" href="#mlflow_components">Figure 11-2</a>:</p>
<dl>
<dt>MLflow Tracking</dt>
<dd>
<p>This component records parameters, metrics, code versions, models, and artifacts such as plots and text.</p>
</dd>
<dt>MLflow Projects</dt>
<dd>
<p>This component provides you with a reusable, reproducible format to share with other data scientists or transfer to production. It helps you manage the model training process.</p>
</dd>
<dt>MLflow Models</dt>
<dd>
<p>This component enables you to package models to deploy to a variety of model serving and inference platforms. It provides a consistent API for loading and applying models, regardless of the underlying library used to build the model.</p>
</dd>
<dt>MLflow Registry</dt>
<dd>
<p>This component enables you to collaboratively keep track of model lineage, model versions, stage transitions, and annotations in a central store.</p>
</dd>
</dl>
<figure><div class="figure" id="mlflow_components">
<img alt="MLflow components" height="298" src="assets/aaps_1102.png" width="1370"/>
<h6><span class="label">Figure 11-2. </span>MLflow components</h6>
</div></figure>
<p>Let’s install MLflow. It’s straightforward to do so using pip:<a data-primary="MLflow" data-secondary="installing" data-type="indexterm" id="idm46507960628336"/><a data-primary="installing MLflow" data-type="indexterm" id="idm46507960627360"/><a data-primary="machine learning lifecycle" data-secondary="MLflow managing ML lifecycle" data-tertiary="installing MLflow" data-type="indexterm" id="idm46507960626688"/></p>
<pre data-code-language="shell" data-type="programlisting">$ pip3 install mlflow</pre>
<p>That’s it!</p>
<p>MLflow integrates with many popular machine learning frameworks such as Spark, TensorFlow, PyTorch, and others. We will be using its native support for Spark over the next few sections. <a data-primary="machine learning lifecycle" data-secondary="MLflow managing ML lifecycle" data-tertiary="importing Spark component" data-type="indexterm" id="idm46507960587776"/><a data-primary="MLflow" data-secondary="installing" data-tertiary="importing Spark component" data-type="indexterm" id="idm46507966409968"/>Importing the Spark-specific MLflow component is as easy as running <code>import mlflow.spark</code>.</p>
<p>In the next section, we’ll introduce MLflow Tracking and add it to our decision tree code from <a data-type="xref" href="ch04.xhtml#making_predictions_with_decision_trees_and_decision_forests">Chapter 4</a>.</p>
</div></section>
<section data-pdf-bookmark="Experiment Tracking" data-type="sect1"><div class="sect1" id="idm46507960589600">
<h1>Experiment Tracking</h1>
<p>A typical machine learning project involves<a data-primary="machine learning lifecycle" data-secondary="MLflow Tracking for experiments" data-type="indexterm" id="ch11-track"/><a data-primary="MLflow" data-secondary="Tracking for experiments" data-type="indexterm" id="ch11-track2"/><a data-primary="decision trees" data-secondary="MLflow Tracking added to" data-type="indexterm" id="ch11-track3"/><a data-primary="experiment tracking via MLflow Tracking" data-type="indexterm" id="ch11-track4"/><a data-primary="tracking ML experiments via MLflow Tracking" data-type="indexterm" id="ch11-track5"/><a data-primary="forest-covered land decision tree" data-secondary="MLflow Tracking added to" data-type="indexterm" id="ch11-track6"/> experimenting with several algorithms and models to solve a problem. The associated datasets, hyperparameters, and metrics need to be tracked. Typically, experiment tracking is done using makeshift tools such as spreadsheets and can be inefficient or, worse, unreliable.</p>
<p>MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and artifacts when running your machine learning code and for later visualizing the results. You can use MLflow Tracking in any environment (for example, a standalone script or a notebook) to log results to local files or to a server and then compare multiple runs. It is library-agnostic and integrates with multiple frameworks.</p>
<p>MLflow Tracking is organized around the <a data-primary="MLflow" data-secondary="Tracking for experiments" data-tertiary="runs" data-type="indexterm" id="idm46507960614112"/><a data-primary="machine learning lifecycle" data-secondary="MLflow Tracking for experiments" data-tertiary="runs" data-type="indexterm" id="idm46507960612848"/><a data-primary="runs in MLflow Tracking" data-type="indexterm" id="idm46507960611600"/>concept of <em>runs</em>, which are executions of some piece of data science code. MLflow Tracking provides a UI that lets you visualize, search, and compare runs, as well as download run artifacts or metadata for analysis in other tools. It contains the following key features:</p>
<ul>
<li>
<p>Experiment-based run listing and comparison</p>
</li>
<li>
<p>Searching for runs by parameter or metric value</p>
</li>
<li>
<p>Visualizing run metrics</p>
</li>
<li>
<p>Downloading run results</p>
</li>
</ul>
<p>Let’s add MLflow Tracking to our <a data-primary="datasets" data-secondary="forest-covered land parcels" data-type="indexterm" id="idm46507960582880"/><a data-primary="datasets" data-secondary="Covtype" data-type="indexterm" id="idm46507960581936"/><a data-primary="Covtype dataset" data-type="indexterm" id="idm46507960580992"/><a data-primary="decision trees" data-secondary="Covtype dataset" data-tertiary="preparing the data" data-type="indexterm" id="idm46507960580320"/><a data-primary="Colorado forest-covered land parcels dataset" data-type="indexterm" id="idm46507960579104"/><a data-primary="forest-covered land decision tree" data-secondary="Covtype dataset" data-tertiary="preparing the data" data-type="indexterm" id="idm46507960578464"/>decision tree code in the PySpark shell. It’s assumed that you have downloaded the <a href="https://oreil.ly/0xyky">Covtype dataset</a> and are familiar with it. The Covtype dataset is available online as a compressed CSV-format data file, <em>covtype.data.gz</em>, and accompanying info file, <em>covtype.info</em>.</p>
<p>Start <code>pyspark-shell</code>. As mentioned previously, <a data-primary="memory" data-secondary="driver-memory for large local memory" data-type="indexterm" id="idm46507960574608"/><a data-primary="decision trees" data-secondary="creating" data-tertiary="memory intensive" data-type="indexterm" id="idm46507960573536"/><a data-primary="installing PySpark API" data-secondary="driver-memory for large local memory" data-type="indexterm" id="idm46507960572320"/><a data-primary="PySpark API" data-secondary="driver-memory for large local memory" data-type="indexterm" id="idm46507960571360"/><a data-primary="Python" data-secondary="PySpark API" data-tertiary="driver-memory for large local memory" data-type="indexterm" id="idm46507960570400"/><a data-primary="Spark (Apache)" data-secondary="PySpark API" data-tertiary="driver-memory for large local memory" data-type="indexterm" id="idm46507960569168"/>building decision trees can be resource intensive. If you have the memory, specify <code>--driver-memory 8g</code> or similar.</p>
<p>We start by preparing the data and machine learning pipeline:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.ml</code> <code class="kn">import</code> <code class="n">Pipeline</code>
<code class="kn">from</code> <code class="nn">pyspark.sql.functions</code> <code class="kn">import</code> <code class="n">col</code>
<code class="kn">from</code> <code class="nn">pyspark.sql.types</code> <code class="kn">import</code> <code class="n">DoubleType</code>
<code class="kn">from</code> <code class="nn">pyspark.ml.feature</code> <code class="kn">import</code> <code class="n">VectorAssembler</code>
<code class="kn">from</code> <code class="nn">pyspark.ml.classification</code> <code class="kn">import</code> <code class="n">DecisionTreeClassifier</code>

<code class="n">data_without_header</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">read</code><code class="o">.</code><code class="n">option</code><code class="p">(</code><code class="s2">"inferSchema"</code><code class="p">,</code> <code class="kc">True</code><code class="p">)</code><code class="o">.</code>\
                                <code class="n">option</code><code class="p">(</code><code class="s2">"header"</code><code class="p">,</code> <code class="kc">False</code><code class="p">)</code><code class="o">.</code>\
                                <code class="n">csv</code><code class="p">(</code><code class="s2">"data/covtype.data"</code><code class="p">)</code>

<code class="n">colnames</code> <code class="o">=</code> <code class="p">[</code><code class="s2">"Elevation"</code><code class="p">,</code> <code class="s2">"Aspect"</code><code class="p">,</code> <code class="s2">"Slope"</code><code class="p">,</code>
            <code class="s2">"Horizontal_Distance_To_Hydrology"</code><code class="p">,</code>
            <code class="s2">"Vertical_Distance_To_Hydrology"</code><code class="p">,</code>
            <code class="s2">"Horizontal_Distance_To_Roadways"</code><code class="p">,</code>
            <code class="s2">"Hillshade_9am"</code><code class="p">,</code> <code class="s2">"Hillshade_Noon"</code><code class="p">,</code>
            <code class="s2">"Hillshade_3pm"</code><code class="p">,</code> <code class="s2">"Horizontal_Distance_To_Fire_Points"</code><code class="p">]</code> <code class="o">+</code> \
<code class="p">[</code><code class="sa">f</code><code class="s2">"Wilderness_Area_</code><code class="si">{</code><code class="n">i</code><code class="si">}</code><code class="s2">"</code> <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">4</code><code class="p">)]</code> <code class="o">+</code> \
<code class="p">[</code><code class="sa">f</code><code class="s2">"Soil_Type_</code><code class="si">{</code><code class="n">i</code><code class="si">}</code><code class="s2">"</code> <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">40</code><code class="p">)]</code> <code class="o">+</code> \
<code class="p">[</code><code class="s2">"Cover_Type"</code><code class="p">]</code>

<code class="n">data</code> <code class="o">=</code> <code class="n">data_without_header</code><code class="o">.</code><code class="n">toDF</code><code class="p">(</code><code class="o">*</code><code class="n">colnames</code><code class="p">)</code><code class="o">.</code>\
                            <code class="n">withColumn</code><code class="p">(</code><code class="s2">"Cover_Type"</code><code class="p">,</code>
                                        <code class="n">col</code><code class="p">(</code><code class="s2">"Cover_Type"</code><code class="p">)</code><code class="o">.</code>\
                                        <code class="n">cast</code><code class="p">(</code><code class="n">DoubleType</code><code class="p">()))</code>

<code class="p">(</code><code class="n">train_data</code><code class="p">,</code> <code class="n">test_data</code><code class="p">)</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">randomSplit</code><code class="p">([</code><code class="mf">0.9</code><code class="p">,</code> <code class="mf">0.1</code><code class="p">])</code>

<code class="n">input_cols</code> <code class="o">=</code> <code class="n">colnames</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
<code class="n">vector_assembler</code> <code class="o">=</code> <code class="n">VectorAssembler</code><code class="p">(</code><code class="n">inputCols</code><code class="o">=</code><code class="n">input_cols</code><code class="p">,</code><code class="n">outputCol</code><code class="o">=</code><code class="s2">"featureVector"</code><code class="p">)</code>

<code class="n">classifier</code> <code class="o">=</code> <code class="n">DecisionTreeClassifier</code><code class="p">(</code><code class="n">seed</code> <code class="o">=</code> <code class="mi">1234</code><code class="p">,</code>
                                    <code class="n">labelCol</code><code class="o">=</code><code class="s2">"Cover_Type"</code><code class="p">,</code>
                                    <code class="n">featuresCol</code><code class="o">=</code><code class="s2">"featureVector"</code><code class="p">,</code>
                                    <code class="n">predictionCol</code><code class="o">=</code><code class="s2">"prediction"</code><code class="p">)</code>

<code class="n">pipeline</code> <code class="o">=</code> <code class="n">Pipeline</code><code class="p">(</code><code class="n">stages</code><code class="o">=</code><code class="p">[</code><code class="n">vector_assembler</code><code class="p">,</code> <code class="n">classifier</code><code class="p">])</code></pre>
<p>To start logging with MLflow, we start<a data-primary="MLflow" data-secondary="Tracking for experiments" data-tertiary="starting a run" data-type="indexterm" id="idm46507960450048"/><a data-primary="decision trees" data-secondary="MLflow Tracking added to" data-tertiary="starting a run" data-type="indexterm" id="idm46507960448864"/><a data-primary="machine learning lifecycle" data-secondary="MLflow Tracking for experiments" data-tertiary="starting a run" data-type="indexterm" id="idm46507960350720"/><a data-primary="runs in MLflow Tracking" data-secondary="starting a run" data-type="indexterm" id="idm46507960349520"/> a run using <code>mlflow.start_run</code>. We will use a <code>with</code> clause to automatically end the run at the end of the block:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">mlflow</code>
<code class="kn">import</code> <code class="nn">mlflow.spark</code>
<code class="kn">import</code> <code class="nn">pandas</code> <code class="k">as</code> <code class="nn">pd</code>
<code class="kn">from</code> <code class="nn">pyspark.ml.evaluation</code> <code class="kn">import</code> <code class="n">MulticlassClassificationEvaluator</code>

<code class="k">with</code> <code class="n">mlflow</code><code class="o">.</code><code class="n">start_run</code><code class="p">(</code><code class="n">run_name</code><code class="o">=</code><code class="s2">"decision-tree"</code><code class="p">):</code>
    <code class="c1"># Log param: max_depth</code>
    <code class="n">mlflow</code><code class="o">.</code><code class="n">log_param</code><code class="p">(</code><code class="s2">"max_depth"</code><code class="p">,</code> <code class="n">classifier</code><code class="o">.</code><code class="n">getMaxDepth</code><code class="p">())</code>
    <code class="c1"># Log model</code>
    <code class="n">pipeline_model</code> <code class="o">=</code> <code class="n">pipeline</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train_data</code><code class="p">)</code>
    <code class="n">mlflow</code><code class="o">.</code><code class="n">spark</code><code class="o">.</code><code class="n">log_model</code><code class="p">(</code><code class="n">pipeline_model</code><code class="p">,</code> <code class="s2">"model"</code><code class="p">)</code>
    <code class="c1"># Log metrics: Accuracy and F1</code>
    <code class="n">pred_df</code> <code class="o">=</code> <code class="n">pipeline_model</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">test_data</code><code class="p">)</code>
    <code class="n">evaluator</code> <code class="o">=</code> <code class="n">MulticlassClassificationEvaluator</code><code class="p">(</code><code class="n">labelCol</code><code class="o">=</code><code class="s2">"Cover_Type"</code><code class="p">,</code>
                                                <code class="n">predictionCol</code><code class="o">=</code><code class="s2">"prediction"</code><code class="p">)</code>
    <code class="n">accuracy</code> <code class="o">=</code> <code class="n">evaluator</code><code class="o">.</code><code class="n">setMetricName</code><code class="p">(</code><code class="s2">"accuracy"</code><code class="p">)</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">pred_df</code><code class="p">)</code>
    <code class="n">f1</code> <code class="o">=</code> <code class="n">evaluator</code><code class="o">.</code><code class="n">setMetricName</code><code class="p">(</code><code class="s2">"f1"</code><code class="p">)</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">pred_df</code><code class="p">)</code>
    <code class="n">mlflow</code><code class="o">.</code><code class="n">log_metrics</code><code class="p">({</code><code class="s2">"accuracy"</code><code class="p">:</code> <code class="n">accuracy</code><code class="p">,</code> <code class="s2">"f1"</code><code class="p">:</code> <code class="n">f1</code><code class="p">})</code>
    <code class="c1"># Log artifact: feature importance scores</code>
    <code class="n">tree_model</code> <code class="o">=</code> <code class="n">pipeline_model</code><code class="o">.</code><code class="n">stages</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
    <code class="n">feature_importance_df</code> <code class="o">=</code> <code class="p">(</code><code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="nb">list</code><code class="p">(</code>
                                    <code class="nb">zip</code><code class="p">(</code><code class="n">vector_assembler</code><code class="o">.</code><code class="n">getInputCols</code><code class="p">(),</code>
                                    <code class="n">tree_model</code><code class="o">.</code><code class="n">featureImportances</code><code class="p">)),</code>
                            <code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s2">"feature"</code><code class="p">,</code> <code class="s2">"importance"</code><code class="p">])</code>
                <code class="o">.</code><code class="n">sort_values</code><code class="p">(</code><code class="n">by</code><code class="o">=</code><code class="s2">"importance"</code><code class="p">,</code> <code class="n">ascending</code><code class="o">=</code><code class="kc">False</code><code class="p">))</code>
    <code class="n">feature_importance_df</code><code class="o">.</code><code class="n">to_csv</code><code class="p">(</code><code class="s2">"feature-importance.csv"</code><code class="p">,</code> <code class="n">index</code><code class="o">=</code><code class="kc">False</code><code class="p">)</code>
    <code class="n">mlflow</code><code class="o">.</code><code class="n">log_artifact</code><code class="p">(</code><code class="s2">"feature-importance.csv"</code><code class="p">)</code></pre>
<p>We can now access our experiment data via the tracking UI. Start it by running the <code>mlflow ui</code> command. By default it starts on port 5000. You can use the <code>-p &lt;port_name&gt;</code> option to change the default port. Once you have successfully started the UI, go to <em><a href="http://localhost:5000/"><em class="hyperlink">http://localhost:5000/</em></a></em>. You will see a UI as shown in <a data-type="xref" href="#mlflow_ui">Figure 11-3</a>. You can search across all the runs, filter for those that meet particular criteria, compare runs side by side, etc. If you wish, you can also export the contents as a CSV file to analyze locally. Click the run in the UI named <code>decision-tree</code>.</p>
<figure><div class="figure" id="mlflow_ui">
<img alt="MLflow UI 1" height="351" src="assets/aaps_1103.png" width="1404"/>
<h6><span class="label">Figure 11-3. </span>MLflow UI 1</h6>
</div></figure>
<p>When viewing an individual run, as shown in <a data-type="xref" href="#mlflow_ui_2">Figure 11-4</a>, you’ll notice that MLflow stores all the corresponding parameters, metrics, etc. You can add notes about this run in free text, as well as tags.</p>
<figure><div class="figure" id="mlflow_ui_2">
<img alt="MLflow UI 2" height="893" src="assets/aaps_1104.png" width="1771"/>
<h6><span class="label">Figure 11-4. </span>MLflow UI 2</h6>
</div></figure>
<p>We are now able to track and reproduce our experiments. Let’s now discuss managing our models using MLflow.<a data-startref="ch11-track" data-type="indexterm" id="idm46507960109904"/><a data-startref="ch11-track2" data-type="indexterm" id="idm46507960109200"/><a data-startref="ch11-track3" data-type="indexterm" id="idm46507960108528"/><a data-startref="ch11-track4" data-type="indexterm" id="idm46507960107856"/><a data-startref="ch11-track5" data-type="indexterm" id="idm46507960107184"/><a data-startref="ch11-track6" data-type="indexterm" id="idm46507960106512"/></p>
</div></section>
<section data-pdf-bookmark="Managing and Serving ML Models" data-type="sect1"><div class="sect1" id="idm46507960622736">
<h1>Managing and Serving ML Models</h1>
<p>An MLflow Model is a standard format<a data-primary="machine learning lifecycle" data-secondary="MLflow Models serving" data-type="indexterm" id="ch11-manserv"/><a data-primary="MLflow" data-secondary="Models managing and serving" data-type="indexterm" id="ch11-manserv2"/><a data-primary="decision trees" data-secondary="ML models managed and served" data-type="indexterm" id="ch11-manserv3"/><a data-primary="forest-covered land decision tree" data-secondary="ML models managed and served" data-type="indexterm" id="ch11-manserv4"/><a data-primary="serving ML models via MLflow Model" data-type="indexterm" id="ch11-manserv5"/><a data-primary="models" data-secondary="serving ML models via MLflow Model" data-type="indexterm" id="ch11-manserv6"/> for packaging machine learning models that can be used in a variety of downstream tools—for example, real-time serving through a REST API or batch inference on Apache Spark. <a data-primary="serving ML models via MLflow Model" data-secondary="flavors" data-type="indexterm" id="idm46507960035872"/><a data-primary="MLflow" data-secondary="Models managing and serving" data-tertiary="flavors" data-type="indexterm" id="idm46507960034944"/><a data-primary="machine learning lifecycle" data-secondary="MLflow Models serving" data-tertiary="flavors" data-type="indexterm" id="idm46507960033712"/>The format defines a convention that lets you save a model in different “flavors” that can be understood by different libraries.</p>
<p>Flavors are the key concept that makes MLflow Models powerful. They make it possible to write tools that work with models from any ML library without having to integrate each tool with each library. MLflow defines several “standard” flavors that all of its built-in deployment tools support, such as a “Python function” flavor that describes how to run the model as a Python function. However, libraries can also define and use other flavors. For example, MLflow’s <code>mlflow.sklearn</code> library allows loading models back as a scikit-learn <code>Pipeline</code> object for use in code that is aware of scikit-learn, or as a generic Python function for use in tools that just need to apply the model (for example, the <code>mlflow.sagemaker</code> tool for deploying models to Amazon SageMaker).</p>
<p>An MLflow Model is a directory containing a set of files. We had earlier logged our model using the <code>log_model</code> API. This created a file called <em>MLmodel</em>. Open the decision-tree run and scroll down to the “Artifacts” section. Check out the <em>MLmodel</em> file. Its contents should be similar to what’s depicted in <a data-type="xref" href="#mlflow_model">Figure 11-5</a>.</p>
<figure><div class="figure" id="mlflow_model">
<img alt="MLflow Model" height="257" src="assets/aaps_1105.png" width="443"/>
<h6><span class="label">Figure 11-5. </span>MLflow Model</h6>
</div></figure>
<p>The file captures our model’s metadata, signature, and flavors. The Model signature defines the schema of a model’s inputs and outputs.</p>
<p>Our model file has two flavors: python_function and spark. <a data-primary="Python" data-secondary="MLflow Model deployment and serving" data-type="indexterm" id="idm46507960025136"/>The python_function flavor enables MLflow’s model deployment and serving tools to work with any Python model regardless of which ML library trained the model. As a result, any Python model can be easily productionalized in a variety of runtime environments.</p>
<p>The spark model flavor enables exporting<a data-primary="MLlib component of Spark" data-secondary="MLlib models as MLflow Models" data-type="indexterm" id="idm46507960023632"/><a data-primary="Spark (Apache)" data-secondary="MLlib models as MLflow Models" data-type="indexterm" id="idm46507960022624"/> Spark MLlib models as MLflow Models. For example, to make predictions on a Spark DataFrame using the logged model:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code><code> </code><code class="nn">mlflow</code><code>
</code><code>
</code><code class="n">run_id</code><code> </code><code class="o">=</code><code> </code><code class="s2">"</code><code class="s2">0433bb047f514e28a73109bbab767222</code><code class="s2">"</code><code> </code><a class="co" href="#callout_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO1-1" id="co_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO1-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code class="n">logged_model</code><code> </code><code class="o">=</code><code> </code><code class="sa">f</code><code class="s1">'</code><code class="s1">runs:/</code><code class="si">{</code><code class="n">run_id</code><code class="si">}</code><code class="s1">/model</code><code class="s1">'</code><code> </code><a class="co" href="#callout_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO1-2" id="co_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO1-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a><code>
</code><code>
</code><code class="c1"># Load model as a Spark UDF.</code><code>
</code><code class="n">loaded_model</code><code> </code><code class="o">=</code><code> </code><code class="n">mlflow</code><code class="o">.</code><code class="n">spark</code><code class="o">.</code><code class="n">load_model</code><code class="p">(</code><code class="n">model_uri</code><code class="o">=</code><code class="n">logged_model</code><code class="p">)</code><code>
</code><code>
</code><code class="c1"># Predict on a Spark DataFrame.</code><code>
</code><code class="n">preds</code><code> </code><code class="o">=</code><code> </code><code class="n">loaded_model</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">test_data</code><code class="p">)</code><code>
</code><code class="n">preds</code><code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s1">'</code><code class="s1">Cover_Type</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">rawPrediction</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">probability</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">prediction</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code>\
</code><code>        </code><code class="n">show</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">vertical</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code><code>
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code>
</code><code class="o">-</code><code class="n">RECORD</code><code> </code><code class="mi">0</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>
</code><code> </code><code class="n">Cover_Type</code><code>    </code><code class="o">|</code><code> </code><code class="mf">6.0</code><code>
</code><code> </code><code class="n">rawPrediction</code><code> </code><code class="o">|</code><code> </code><code class="p">[</code><code class="mf">0.0</code><code class="p">,</code><code class="mf">0.0</code><code class="p">,</code><code class="mf">605.0</code><code class="p">,</code><code class="mf">15.</code><code class="o">.</code><code class="o">.</code><code>
</code><code> </code><code class="n">probability</code><code>   </code><code class="o">|</code><code> </code><code class="p">[</code><code class="mf">0.0</code><code class="p">,</code><code class="mf">0.0</code><code class="p">,</code><code class="mf">0.024462</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code>
</code><code> </code><code class="n">prediction</code><code>    </code><code class="o">|</code><code> </code><code class="mf">3.0</code><code>
</code><code class="n">only</code><code> </code><code class="n">showing</code><code> </code><code class="n">top</code><code> </code><code class="mi">1</code><code> </code><code class="n">row</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO1-1" id="callout_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO1-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>This ID can be obtained from the tracking UI in the relevant <em>MLmodel</em> file.</p></dd>
<dt><a class="co" href="#co_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO1-2" id="callout_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO1-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></dt>
<dd><p>We use Python f-strings for adding the relevant run ID.</p></dd>
</dl>
<p>We can also use the <code>mlflow serve</code> command-line tool to serve the model corresponding to a particular run ID.</p>
<pre data-code-language="shell" data-type="programlisting">$ mlflow models serve --model-uri runs:/0433bb047f514e28a73109bbab767222/model <code class="se">\</code>
        -p <code class="m">7000</code>

...

<code class="m">2021</code>/11/13 <code class="m">12</code>:13:49 INFO mlflow.models.cli: Selected backend <code class="k">for</code>...
<code class="m">2021</code>/11/13 <code class="m">12</code>:13:52 INFO mlflow.utils.conda: <code class="o">===</code> Creating conda ...
Collecting package metadata <code class="o">(</code>repodata.json<code class="o">)</code>: <code class="k">done</code>
Solving environment: <code class="k">done</code> ...</pre>
<p>You have successfully deployed your model as a REST API!</p>
<p>We can now use this endpoint to perform inference. Let’s prepare and send a request to the endpoint to see it in action. We’ll use the <code>requests</code> library to do this. Install it using pip first if you don’t yet have it:</p>
<pre data-code-language="shell" data-type="programlisting">pip3 install requests</pre>
<p>Now we’ll send a request containing a JSON object in a pandas-split orientation to the model server.</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">requests</code>

<code class="n">host</code> <code class="o">=</code> <code class="s1">'0.0.0.0'</code>
<code class="n">port</code> <code class="o">=</code> <code class="s1">'7001'</code>

<code class="n">url</code> <code class="o">=</code> <code class="sa">f</code><code class="s1">'http://</code><code class="si">{</code><code class="n">host</code><code class="si">}</code><code class="s1">:</code><code class="si">{</code><code class="n">port</code><code class="si">}</code><code class="s1">/invocations'</code>

<code class="n">headers</code> <code class="o">=</code> <code class="p">{</code>
    <code class="s1">'Content-Type'</code><code class="p">:</code> <code class="s1">'application/json;'</code><code class="p">,</code>
    <code class="s1">'format'</code><code class="p">:</code> <code class="s1">'pandas-split'</code><code class="p">;</code>
<code class="p">}</code>

<code class="n">http_data</code> <code class="o">=</code> <code class="s1">'{"columns":["Elevation","Aspect","Slope", </code><code class="se">\</code>
<code class="s1">    "Horizontal_Distance_To_Hydrology", </code><code class="se">\</code>
<code class="s1">    "Vertical_Distance_To_Hydrology","Horizontal_Distance_To_Roadways", </code><code class="se">\</code>
<code class="s1">    "Hillshade_9am","Hillshade_Noon","Hillshade_3pm",</code><code class="se">\</code>
<code class="s1">    "Horizontal_Distance_To_Fire_Points",</code><code class="se">\</code>
<code class="s1">    "Wilderness_Area_0","Wilderness_Area_1","Wilderness_Area_2",</code><code class="se">\</code>
<code class="s1">    "Wilderness_Area_3","Soil_Type_0","Soil_Type_1","Soil_Type_2",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_3","Soil_Type_4","Soil_Type_5","Soil_Type_6",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_7","Soil_Type_8","Soil_Type_9","Soil_Type_10",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_11","Soil_Type_12","Soil_Type_13",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_14","Soil_Type_15","Soil_Type_16",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_17","Soil_Type_18","Soil_Type_19",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_20","Soil_Type_21","Soil_Type_22",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_23","Soil_Type_24","Soil_Type_25",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_26","Soil_Type_27","Soil_Type_28",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_29","Soil_Type_30","Soil_Type_31",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_32","Soil_Type_33","Soil_Type_34",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_35","Soil_Type_36","Soil_Type_37",</code><code class="se">\</code>
<code class="s1">    "Soil_Type_38","Soil_Type_39","Cover_Type"],</code><code class="se">\</code>
<code class="s1">    "index":[0],</code><code class="se">\</code>
<code class="s1">    "data":[[2596,51,3,258,0,510,221,232,148,6279,1,</code><code class="se">\</code>
<code class="s1">            0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,</code><code class="se">\</code>
<code class="s1">            0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,5.0]]'</code>\

<code class="n">r</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">post</code><code class="p">(</code><code class="n">url</code><code class="o">=</code><code class="n">url</code><code class="p">,</code> <code class="n">headers</code><code class="o">=</code><code class="n">headers</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">http_data</code><code class="p">)</code>

<code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s1">'Predictions: </code><code class="si">{</code><code class="n">r</code><code class="o">.</code><code class="n">text</code><code class="si">}</code><code class="s1">'</code><code class="p">)</code>
<code class="o">...</code>
<code class="n">Predictions</code><code class="p">:</code> <code class="p">[</code><code class="mf">2.0</code><code class="p">]</code></pre>
<p>We not only loaded a saved model but also deployed it as a REST API and performed inference in real time!</p>
<p>Let us now learn how to create an MLflow Project for the work we have done so far.<a data-startref="ch11-manserv" data-type="indexterm" id="idm46507959786512"/><a data-startref="ch11-manserv2" data-type="indexterm" id="idm46507959785904"/><a data-startref="ch11-manserv3" data-type="indexterm" id="idm46507959785264"/><a data-startref="ch11-manserv4" data-type="indexterm" id="idm46507959678768"/><a data-startref="ch11-manserv5" data-type="indexterm" id="idm46507959678096"/><a data-startref="ch11-manserv6" data-type="indexterm" id="idm46507959677424"/></p>
</div></section>
<section data-pdf-bookmark="Creating and Using MLflow Projects" data-type="sect1"><div class="sect1" id="idm46507960105248">
<h1>Creating and Using MLflow Projects</h1>
<p>MLflow Projects is a standard format for<a data-primary="machine learning lifecycle" data-secondary="MLflow Projects for packaging" data-type="indexterm" id="ch11-proj"/><a data-primary="MLflow" data-secondary="Projects for packaging" data-type="indexterm" id="ch11-proj2"/> reusable and reproducible packaging. It’s a self-contained unit that bundles all the machine code and dependencies required to execute a machine learning workflow and enables you to produce a particular model run on any system or environment. MLflow Projects includes an API and command-line tools for running projects. It can also be used to chain projects together into workflows.</p>
<p>Each project is simply a directory of files, or a Git repository, containing your code. MLflow can run some projects based on a convention for placing files in this directory (for example, a <em>conda.yml</em> file is treated as a Conda environment), but you can describe your project in more detail by adding an MLproject file, which is a YAML-formatted text file.</p>
<p>MLflow currently supports the following project environments: Conda environment, Docker container environment, and system environment. By default, MLflow uses the system path to find and run the Conda binary.</p>
<p>Creating a basic MLflow project is straightforward. The required steps are listed in <a data-type="xref" href="#how_to_build_an_mflow_project">Figure 11-6</a>.</p>
<figure><div class="figure" id="how_to_build_an_mflow_project">
<img alt="How to build an MLflow Project" height="357" src="assets/aaps_1106.png" width="1441"/>
<h6><span class="label">Figure 11-6. </span>How to build an MLflow Project</h6>
</div></figure>
<p>We will start by creating our project directory named <em>decision_tree_project</em>:</p>
<pre data-code-language="shell" data-type="programlisting">mkdir decision_tree_project
<code class="nb">cd</code> decision_tree_project</pre>
<p>Next, we’ll first create an MLproject file:</p>
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">decision_tree_project</code><code class="w"/>

<code class="nt">conda_env</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">conda.yml</code><code class="w"/>

<code class="nt">entry_points</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="nt">main</code><code class="p">:</code><code class="w"/>
<code class="w">    </code><code class="nt">command</code><code class="p">:</code><code class="w"> </code><code class="s">"python</code><code class="nv"> </code><code class="s">train.py"</code><code class="w"/></pre>
<p>We now need our <em>conda.yml</em> file. We can get this from the MLflow UI introduced in a previous section. Go inside the decision-tree run that we previously saw. Scroll down to the Artifacts, click the conda YAML file, and copy its contents into <em>conda.yml</em> in our project directory:</p>
<pre data-code-language="yaml" data-type="programlisting"><code class="nt">channels</code><code class="p">:</code><code class="w"/>
<code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">conda-forge</code><code class="w"/>
<code class="nt">dependencies</code><code class="p">:</code><code class="w"/>
<code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">python=3.6.12</code><code class="w"/>
<code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">pip</code><code class="w"/>
<code class="p-Indicator">-</code><code class="w"> </code><code class="nt">pip</code><code class="p">:</code><code class="w"/>
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">mlflow</code><code class="w"/>
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">pyspark==3.2.1</code><code class="w"/>
<code class="w">  </code><code class="p-Indicator">-</code><code class="w"> </code><code class="l-Scalar-Plain">scipy==1.5.3</code><code class="w"/>
<code class="nt">name</code><code class="p">:</code><code class="w"> </code><code class="l-Scalar-Plain">mlflow-env</code><code class="w"/></pre>
<p>We will now create the Python script that will be used to train a decision tree model upon the MLflow project being executed. For this, we’ll use the code from a previous section:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code><code> </code><code class="nn">pyspark</code><code class="nn">.</code><code class="nn">sql</code><code> </code><code class="kn">import</code><code> </code><code class="n">SparkSession</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">pyspark</code><code class="nn">.</code><code class="nn">ml</code><code> </code><code class="kn">import</code><code> </code><code class="n">Pipeline</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">pyspark</code><code class="nn">.</code><code class="nn">sql</code><code class="nn">.</code><code class="nn">functions</code><code> </code><code class="kn">import</code><code> </code><code class="n">col</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">pyspark</code><code class="nn">.</code><code class="nn">sql</code><code class="nn">.</code><code class="nn">types</code><code> </code><code class="kn">import</code><code> </code><code class="n">DoubleType</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">pyspark</code><code class="nn">.</code><code class="nn">ml</code><code class="nn">.</code><code class="nn">feature</code><code> </code><code class="kn">import</code><code> </code><code class="n">VectorAssembler</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">pyspark</code><code class="nn">.</code><code class="nn">ml</code><code class="nn">.</code><code class="nn">classification</code><code> </code><code class="kn">import</code><code> </code><code class="n">DecisionTreeClassifier</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">pyspark</code><code class="nn">.</code><code class="nn">ml</code><code class="nn">.</code><code class="nn">evaluation</code><code> </code><code class="kn">import</code><code> </code><code class="n">MulticlassClassificationEvaluator</code><code>
</code><code>
</code><code class="n">spark</code><code> </code><code class="o">=</code><code> </code><code class="n">SparkSession</code><code class="o">.</code><code class="n">builder</code><code class="o">.</code><code class="n">appName</code><code class="p">(</code><code class="s2">"</code><code class="s2">App</code><code class="s2">"</code><code class="p">)</code><code class="o">.</code><code class="n">getOrCreate</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="k">def</code><code> </code><code class="nf">main</code><code class="p">(</code><code class="p">)</code><code class="p">:</code><code>
</code><code>    </code><code class="n">data_without_header</code><code> </code><code class="o">=</code><code> </code><code class="n">spark</code><code class="o">.</code><code class="n">read</code><code class="o">.</code><code class="n">option</code><code class="p">(</code><code class="s2">"</code><code class="s2">inferSchema</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="kc">True</code><code class="p">)</code><code class="o">.</code><code>\
</code><code>                                    </code><code class="n">option</code><code class="p">(</code><code class="s2">"</code><code class="s2">header</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="kc">False</code><code class="p">)</code><code class="o">.</code><code>\
</code><code>                                    </code><code class="n">csv</code><code class="p">(</code><code class="s2">"</code><code class="s2">../data/covtype.data</code><code class="s2">"</code><code class="p">)</code><code> </code><a class="co" href="#callout_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO2-1" id="co_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO2-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code>
</code><code>    </code><code class="n">colnames</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s2">"</code><code class="s2">Elevation</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="s2">"</code><code class="s2">Aspect</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="s2">"</code><code class="s2">Slope</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                </code><code class="s2">"</code><code class="s2">Horizontal_Distance_To_Hydrology</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                </code><code class="s2">"</code><code class="s2">Vertical_Distance_To_Hydrology</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                </code><code class="s2">"</code><code class="s2">Horizontal_Distance_To_Roadways</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                </code><code class="s2">"</code><code class="s2">Hillshade_9am</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="s2">"</code><code class="s2">Hillshade_Noon</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                </code><code class="s2">"</code><code class="s2">Hillshade_3pm</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                </code><code class="s2">"</code><code class="s2">Horizontal_Distance_To_Fire_Points</code><code class="s2">"</code><code class="p">]</code><code> </code><code class="o">+</code><code> </code><code>\
</code><code>    </code><code class="p">[</code><code class="sa">f</code><code class="s2">"</code><code class="s2">Wilderness_Area_</code><code class="si">{</code><code class="n">i</code><code class="si">}</code><code class="s2">"</code><code> </code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="mi">4</code><code class="p">)</code><code class="p">]</code><code> </code><code class="o">+</code><code> </code><code>\
</code><code>    </code><code class="p">[</code><code class="sa">f</code><code class="s2">"</code><code class="s2">Soil_Type_</code><code class="si">{</code><code class="n">i</code><code class="si">}</code><code class="s2">"</code><code> </code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="mi">40</code><code class="p">)</code><code class="p">]</code><code> </code><code class="o">+</code><code> </code><code>\
</code><code>    </code><code class="p">[</code><code class="s2">"</code><code class="s2">Cover_Type</code><code class="s2">"</code><code class="p">]</code><code>
</code><code>
</code><code>    </code><code class="n">data</code><code> </code><code class="o">=</code><code> </code><code class="n">data_without_header</code><code class="o">.</code><code class="n">toDF</code><code class="p">(</code><code class="o">*</code><code class="n">colnames</code><code class="p">)</code><code class="o">.</code><code>\
</code><code>                                </code><code class="n">withColumn</code><code class="p">(</code><code class="s2">"</code><code class="s2">Cover_Type</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                                            </code><code class="n">col</code><code class="p">(</code><code class="s2">"</code><code class="s2">Cover_Type</code><code class="s2">"</code><code class="p">)</code><code class="o">.</code><code>\
</code><code>                                            </code><code class="n">cast</code><code class="p">(</code><code class="n">DoubleType</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="p">(</code><code class="n">train_data</code><code class="p">,</code><code> </code><code class="n">test_data</code><code class="p">)</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">randomSplit</code><code class="p">(</code><code class="p">[</code><code class="mf">0.9</code><code class="p">,</code><code> </code><code class="mf">0.1</code><code class="p">]</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="n">input_cols</code><code> </code><code class="o">=</code><code> </code><code class="n">colnames</code><code class="p">[</code><code class="p">:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code><code>
</code><code>    </code><code class="n">vector_assembler</code><code> </code><code class="o">=</code><code> </code><code class="n">VectorAssembler</code><code class="p">(</code><code class="n">inputCols</code><code class="o">=</code><code class="n">input_cols</code><code class="p">,</code><code>
</code><code>                                </code><code class="n">outputCol</code><code class="o">=</code><code class="s2">"</code><code class="s2">featureVector</code><code class="s2">"</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="n">classifier</code><code> </code><code class="o">=</code><code> </code><code class="n">DecisionTreeClassifier</code><code class="p">(</code><code class="n">seed</code><code> </code><code class="o">=</code><code> </code><code class="mi">1234</code><code class="p">,</code><code>
</code><code>                                        </code><code class="n">labelCol</code><code class="o">=</code><code class="s2">"</code><code class="s2">Cover_Type</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                                        </code><code class="n">featuresCol</code><code class="o">=</code><code class="s2">"</code><code class="s2">featureVector</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                                        </code><code class="n">predictionCol</code><code class="o">=</code><code class="s2">"</code><code class="s2">prediction</code><code class="s2">"</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="n">pipeline</code><code> </code><code class="o">=</code><code> </code><code class="n">Pipeline</code><code class="p">(</code><code class="n">stages</code><code class="o">=</code><code class="p">[</code><code class="n">vector_assembler</code><code class="p">,</code><code> </code><code class="n">classifier</code><code class="p">]</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="n">pipeline_model</code><code> </code><code class="o">=</code><code> </code><code class="n">pipeline</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train_data</code><code class="p">)</code><code>
</code><code>    </code><code class="c1"># Log metrics: Accuracy and F1</code><code>
</code><code>    </code><code class="n">pred_df</code><code> </code><code class="o">=</code><code> </code><code class="n">pipeline_model</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">test_data</code><code class="p">)</code><code>
</code><code>    </code><code class="n">evaluator</code><code> </code><code class="o">=</code><code> </code><code class="n">MulticlassClassificationEvaluator</code><code class="p">(</code><code class="n">labelCol</code><code class="o">=</code><code class="s2">"</code><code class="s2">Cover_Type</code><code class="s2">"</code><code class="p">,</code><code>
</code><code>                                                </code><code class="n">predictionCol</code><code class="o">=</code><code class="s2">"</code><code class="s2">prediction</code><code class="s2">"</code><code class="p">)</code><code>
</code><code>    </code><code class="n">accuracy</code><code> </code><code class="o">=</code><code> </code><code class="n">evaluator</code><code class="o">.</code><code class="n">setMetricName</code><code class="p">(</code><code class="s2">"</code><code class="s2">accuracy</code><code class="s2">"</code><code class="p">)</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">pred_df</code><code class="p">)</code><code>
</code><code>    </code><code class="n">f1</code><code> </code><code class="o">=</code><code> </code><code class="n">evaluator</code><code class="o">.</code><code class="n">setMetricName</code><code class="p">(</code><code class="s2">"</code><code class="s2">f1</code><code class="s2">"</code><code class="p">)</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">pred_df</code><code class="p">)</code><code>
</code><code>    </code><code class="nb">print</code><code class="p">(</code><code class="p">{</code><code class="s2">"</code><code class="s2">accuracy</code><code class="s2">"</code><code class="p">:</code><code> </code><code class="n">accuracy</code><code class="p">,</code><code> </code><code class="s2">"</code><code class="s2">f1</code><code class="s2">"</code><code class="p">:</code><code> </code><code class="n">f1</code><code class="p">}</code><code class="p">)</code><code>
</code><code>
</code><code>
</code><code class="k">if</code><code> </code><code class="vm">__name__</code><code> </code><code class="o">==</code><code> </code><code class="s2">"</code><code class="s2">__main__</code><code class="s2">"</code><code class="p">:</code><code>
</code><code>    </code><code class="n">main</code><code class="p">(</code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO2-1" id="callout_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO2-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>Data is assumed to be one directory level above the MLflow project directory being executed.</p></dd>
</dl>
<p>Data can also be included inside an MLflow project. In this case, we don’t do so because of the large size. In such a case, data can be shared using cloud storage such as AWS S3 or GCS.</p>
<p>You can simulate how it will work for a collaborator locally before sharing, too. We do that using the <code>mlflow run</code> command.</p>
<pre data-code-language="shell" data-type="programlisting">mlflow run decision_tree_project
...
<code class="o">[</code>...<code class="o">]</code>
<code class="o">{</code><code class="s1">'accuracy'</code>: <code class="m">0</code>.6988990605087336, <code class="s1">'f1'</code>: <code class="m">0</code>.6805617730220171<code class="o">}</code></pre>
<p>We now have a reproducible MLflow project. We can upload it to a GitHub repository and share it with a collaborator who will be able to reproduce our work.<a data-startref="ch11-proj" data-type="indexterm" id="idm46507959114624"/><a data-startref="ch11-proj2" data-type="indexterm" id="idm46507959114016"/></p>
</div></section>
<section data-pdf-bookmark="Where to Go from Here" data-type="sect1"><div class="sect1" id="idm46507959676288">
<h1>Where to Go from Here</h1>
<p>This chapter introduced the MLflow project and guided you through its implementation for a straightforward project. There is a lot to explore within the MLflow project itself. <a data-primary="MLflow" data-secondary="documentation online" data-type="indexterm" id="idm46507958786160"/><a data-primary="machine learning lifecycle" data-secondary="MLflow documentation online" data-type="indexterm" id="idm46507958785184"/><a data-primary="online resources" data-secondary="MLflow documentation" data-type="indexterm" id="idm46507958784208"/>You can find more information in the <a href="https://mlflow.org">official docs</a>. <a data-primary="machine learning lifecycle" data-secondary="MLflow managing ML lifecycle" data-tertiary="alternatives to MLflow" data-type="indexterm" id="idm46507958960208"/><a data-primary="MLflow" data-secondary="alternatives to" data-type="indexterm" id="idm46507958958848"/>There are other tools out there that can serve as alternatives as well. These include open source projects, such as Metaflow and Kubeflow, as well as proprietary offerings by big cloud providers including Amazon SageMaker and the Databricks platform.</p>
<p>Of course, tools are only part of the solution to the challenges that a real-world machine learning project offers. Processes need to be defined by the people working on any project. We hope that you will build upon the foundations offered in this chapter and contribute to successful machine learning projects in the wild.</p>
</div></section>
</div></section></div></body></html>