["```py\nimport nltk\nnltk.download('reuters')\n\n```", "```py\nUSAir Group Inc said a U.S. District Court in Pittsburgh issued a temporary\nrestraining order to prevent Trans World Airlines Inc from buying additional\nUSAir shares. USAir said the order was issued in response to its suit, charging\nTWA chairman Carl Icahn and TWA violated federal laws and made misleading\nstatements. TWA last week said it owned 15 % of USAir's shares. It also offered\nto buy the company for 52 dollars a share cash or 1.4 billion dollars.\n\n```", "```py\nnlp = spacy.load('en_core_web_sm')\nprint(*nlp.pipeline, sep='\\n')\n\n```", "```py\n('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f98ac6443a0>)\n('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f98ac7a07c0>)\n('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f98ac7a0760>)\n\n```", "```py\ntext = \"\"\"Hughes Tool Co Chairman W.A. Kistler said its merger with\nBaker International Corp was still under consideration.\nWe hope to come soon to a mutual agreement, Kistler said.\nThe directors of Baker filed a law suit in Texas to force Hughes\nto complete the merger.\"\"\"\ndoc = nlp(text)\n\nprint(*[(e.text, e.label_) for e in doc.ents], sep=' ')\n\n```", "```py\n(Hughes Tool Co, ORG) (W.A. Kistler, PERSON) (Baker International Corp, ORG)\n(Kistler, ORG) (Baker, PERSON) (Texas, GPE) (Hughes, ORG)\n\n```", "```py\nfrom spacy import displacy\ndisplacy.render(doc, style='ent')\n\n```", "```py\nfrom spacy.pipeline import EntityRuler\n\ndepartments = ['Justice', 'Transportation']\npatterns = [{\"label\": \"GOV\",\n             \"pattern\": [{\"TEXT\": \"U.S.\", \"OP\": \"?\"},\n                         {\"TEXT\": \"Department\"}, {\"TEXT\": \"of\"},\n                         {\"TEXT\": {\"IN\": departments}, \"ENT_TYPE\": \"ORG\"}]},\n             {\"label\": \"GOV\",\n              \"pattern\": [{\"TEXT\": \"U.S.\", \"OP\": \"?\"},\n                          {\"TEXT\": {\"IN\": departments}, \"ENT_TYPE\": \"ORG\"},\n                          {\"TEXT\": \"Department\"}]},\n             {\"label\": \"GOV\",\n              \"pattern\": [{\"TEXT\": \"Securities\"}, {\"TEXT\": \"and\"},\n                          {\"TEXT\": \"Exchange\"}, {\"TEXT\": \"Commission\"}]}]\n\n```", "```py\nentity_ruler = EntityRuler(nlp, patterns=patterns, overwrite_ents=True)\nnlp.add_pipe(entity_ruler)\n\n```", "```py\ntext = \"\"\"Justice Department is an alias for the U.S. Department of Justice.\nDepartment of Transportation and the Securities and Exchange Commission\nare government organisations, but the Sales Department is not.\"\"\"\n\ndoc = nlp(text)\ndisplacy.render(doc, style='ent')\n\n```", "```py\ntext = \"Baker International's shares climbed on the New York Stock Exchange.\"\n\ndoc = nlp(text)\nprint(*[([t.text for t in e], e.label_) for e in doc.ents], sep='\\n')\n\n```", "```py\n(['Baker', 'International', \"'s\"], 'ORG')\n(['the', 'New', 'York', 'Stock', 'Exchange'], 'ORG')\n\n```", "```py\nfrom spacy.tokens import Span\n\ndef norm_entities(doc):\n    ents = []\n    for ent in doc.ents:\n        if ent[0].pos_ == \"DET\": # leading article\n            ent = Span(doc, ent.start+1, ent.end, label=ent.label)\n        if ent[-1].pos_ == \"PART\": # trailing particle like 's\n            ent = Span(doc, ent.start, ent.end-1, label=ent.label)\n        ents.append(ent)\n    doc.ents = tuple(ents)\n    return doc\n\n```", "```py\nnlp.add_pipe(norm_entities)\n\n```", "```py\ndoc = nlp(text)\nprint(*[([t.text for t in e], e.label_) for e in doc.ents], sep='\\n')\n\n```", "```py\n(['Baker', 'International'], 'ORG')\n(['New', 'York', 'Stock', 'Exchange'], 'ORG')\n\n```", "```py\nfrom spacy.pipeline import merge_entities\nnlp.add_pipe(merge_entities)\n\ndoc = nlp(text)\nprint(*[(t.text, t.ent_type_) for t in doc if t.ent_type_ != ''])\n\n```", "```py\n('Baker International', 'ORG') ('New York Stock Exchange', 'ORG')\n\n```", "```py\nfrom spacy.tokens import Token\nToken.set_extension('ref_n', default='')\nToken.set_extension('ref_t', default='')\n\n```", "```py\ndef init_coref(doc):\n    for e in doc.ents:\n        if e.label_ in ['ORG', 'GOV', 'PERSON']:\n            e[0]._.ref_n, e[0]._.ref_t = e.text, e.label_\n    return doc\n\n```", "```py\nfrom blueprints.knowledge import alias_lookup\n\nfor token in ['Transportation Department', 'DOT', 'SEC', 'TWA']:\n    print(token, ':', alias_lookup[token])\n\n```", "```py\nTransportation Department : ('U.S. Department of Transportation', 'GOV')\nDOT : ('U.S. Department of Transportation', 'GOV')\nSEC : ('Securities and Exchange Commission', 'GOV')\nTWA : ('Trans World Airlines Inc', 'ORG')\n\n```", "```py\ndef alias_resolver(doc):\n    \"\"\"Lookup aliases and store result in ref_t, ref_n\"\"\"\n    for ent in doc.ents:\n        token = ent[0].text\n        if token in alias_lookup:\n            a_name, a_type = alias_lookup[token]\n            ent[0]._.ref_n, ent[0]._.ref_t = a_name, a_type\n    return propagate_ent_type(doc)\n\n```", "```py\ndef propagate_ent_type(doc):\n    \"\"\"propagate entity type stored in ref_t\"\"\"\n    ents = []\n    for e in doc.ents:\n        if e[0]._.ref_n != '': # if e is a coreference\n            e = Span(doc, e.start, e.end, label=e[0]._.ref_t)\n        ents.append(e)\n    doc.ents = tuple(ents)\n    return doc\n\n```", "```py\nnlp.add_pipe(alias_resolver)\n\n```", "```py\nfrom blueprints.knowledge import display_ner\ntext = \"\"\"The deal of Trans World Airlines is under investigation by the\nU.S. Department of Transportation.\nThe Transportation Department will block the deal of TWA.\"\"\"\ndoc = nlp(text)\ndisplay_ner(doc).query(\"ref_n != ''\")[['text', 'ent_type', 'ref_n', 'ref_t']]\n\n```", "```py\ndef name_match(m1, m2):\n    m2 = re.sub(r'[()\\.]', '', m2) # ignore parentheses and dots\n    m2 = r'\\b' + m2 + r'\\b' # \\b marks word boundary\n    m2 = re.sub(r'\\s+', r'\\\\b.*\\\\b', m2)\n    return re.search(m2, m1, flags=re.I) is not None\n\n```", "```py\ndef name_resolver(doc):\n    \"\"\"create name-based reference to e1 as primary mention of e2\"\"\"\n    ents = [e for e in doc.ents if e.label_ in ['ORG', 'PERSON']]\n    for i, e1 in enumerate(ents):\n        for e2 in ents[i+1:]:\n            if name_match(e1[0]._.ref_n, e2[0].text):\n                e2[0]._.ref_n = e1[0]._.ref_n\n                e2[0]._.ref_t = e1[0]._.ref_t\n    return propagate_ent_type(doc)\n\n```", "```py\nnlp.add_pipe(name_resolver)\n\ndoc = nlp(text)\ndisplacy.render(doc, style='ent')\n\n```", "```py\ndisplay_ner(doc).query(\"ref_n != ''\")[['text', 'ent_type', 'ref_n', 'ref_t']]\n\n```", "```py\ntext = \"\"\"Hughes Tool Co said its merger with Baker\nwas still under consideration. Hughes had a board meeting today.\nW.A. Kistler mentioned that the company hopes for a mutual agreement.\nHe is reasonably confident.\"\"\"\n\n```", "```py\nfrom neuralcoref import NeuralCoref\nneural_coref = NeuralCoref(nlp.vocab, greedyness=0.45)\nnlp.add_pipe(neural_coref, name='neural_coref')\n\n```", "```py\ndoc = nlp(text)\nprint(*doc._.coref_clusters, sep='\\n')\n\n```", "```py\nHughes Tool Co: [Hughes Tool Co, its]\nHughes: [Hughes, the company]\nW.A. Kistler: [W.A. Kistler, He]\n\n```", "```py\ndef anaphor_coref(doc):\n    \"\"\"anaphora resolution\"\"\"\n    for token in doc:\n        # if token is coref and not already dereferenced\n        if token._.in_coref and token._.ref_n == '':\n            ref_span = token._.coref_clusters[0].main # get referred span\n            if len(ref_span) <= 3: # consider only short spans\n                for ref in ref_span: # find first dereferenced entity\n                    if ref._.ref_n != '':\n                        token._.ref_n = ref._.ref_n\n                        token._.ref_t = ref._.ref_t\n                        break\n    return doc\n\n```", "```py\nnlp.add_pipe(anaphor_coref)\ndoc = nlp(text)\ndisplay_ner(doc).query(\"ref_n != ''\") \\\n  [['text', 'ent_type', 'main_coref', 'ref_n', 'ref_t']]\n\n```", "```py\ndef strip_legal_suffix(text):\n    return re.sub(r'(\\s+and)?(\\s+|\\b(Co|Corp|Inc|Plc|Ltd)\\b\\.?)*$', '', text)\n\nprint(strip_legal_suffix('Hughes Tool Co'))\n\n```", "```py\nHughes Tool\n\n```", "```py\ndef norm_names(doc):\n    for t in doc:\n        if t._.ref_n != '' and t._.ref_t in ['ORG']:\n            t._.ref_n = strip_legal_suffix(t._.ref_n)\n            if t._.ref_n == '':\n                t._.ref_t = ''\n    return doc\n\nnlp.add_pipe(norm_names)\n\n```", "```py\nfrom itertools import combinations\n\ndef extract_coocs(doc, include_types):\n    ents = set([(e[0]._.ref_n, e[0]._.ref_t)\n                for e in doc.ents if e[0]._.ref_t in include_types])\n    yield from combinations(sorted(ents), 2)\n\n```", "```py\nbatch_size = 100\n\ncoocs = []\nfor i in range(0, len(df), batch_size):\n    docs = nlp.pipe(df['text'][i:i+batch_size],\n                    disable=['neural_coref', 'anaphor_coref'])\n    for j, doc in enumerate(docs):\n        coocs.extend([(df.index[i+j], *c)\n                      for c in extract_coocs(doc, ['ORG', 'GOV'])])\n\n```", "```py\nprint(*coocs[:3], sep='\\n')\n\n```", "```py\n(10, ('Computer Terminal Systems', 'ORG'), ('Sedio N.V.', 'ORG'))\n(10, ('Computer Terminal Systems', 'ORG'), ('Woodco', 'ORG'))\n(10, ('Sedio N.V.', 'ORG'), ('Woodco', 'ORG'))\n\n```", "```py\ncoocs = [([id], *e1, *e2) for (id, e1, e2) in coocs]\ncooc_df = pd.DataFrame.from_records(coocs,\n             columns=('article_id', 'ent1', 'type1', 'ent2', 'type2'))\ncooc_df = cooc_df.groupby(['ent1', 'type1', 'ent2', 'type2'])['article_id'] \\\n                 .agg(['count', 'sum']) \\\n                 .rename(columns={'count': 'freq', 'sum': 'articles'}) \\\n                 .reset_index().sort_values('freq', ascending=False)\ncooc_df['articles'] = cooc_df['articles'].map(\n                        lambda lst: ','.join([str(a) for a in lst[:5]]))\n\n```", "```py\ncooc_df.head(3)\n\n```", "```py\nimport networkx as nx\n\ngraph = nx.from_pandas_edgelist(\n           cooc_df[['ent1', 'ent2', 'articles', 'freq']] \\\n           .query('freq > 3').rename(columns={'freq': 'weight'}),\n           source='ent1', target='ent2', edge_attr=True)\n\nnx.readwrite.write_gexf(graph, 'cooc.gexf', encoding='utf-8',\n                        prettyprint=True, version='1.2draft')\n\n```", "```py\ntext = \"\"\"Fujitsu plans to acquire 80% of Fairchild Corp, an industrial unit\nof Schlumberger.\"\"\"\n\n```", "```py\nORG {optional words, not ORG} acquire {optional words, not ORG} ORG\nORG {optional words, not ORG} unit of {optional words, not ORG} ORG \n```", "```py\nfrom spacy.matcher import Matcher\n\nmatcher = Matcher(nlp.vocab)\n\nacq_synonyms = ['acquire', 'buy', 'purchase']\npattern = [{'_': {'ref_t': 'ORG'}}, # subject\n           {'_': {'ref_t': {'NOT_IN': ['ORG']}}, 'OP': '*'},\n           {'POS': 'VERB', 'LEMMA': {'IN': acq_synonyms}},\n           {'_': {'ref_t': {'NOT_IN': ['ORG']}}, 'OP': '*'},\n           {'_': {'ref_t': 'ORG'}}] # object\nmatcher.add('acquires', None, pattern)\n\n```", "```py\nsubs_synonyms = ['subsidiary', 'unit']\npattern = [{'_': {'ref_t': 'ORG'}}, # subject\n           {'_': {'ref_t': {'NOT_IN': ['ORG']}},\n            'POS': {'NOT_IN': ['VERB']}, 'OP': '*'},\n           {'LOWER': {'IN': subs_synonyms}}, {'TEXT': 'of'},\n           {'_': {'ref_t': {'NOT_IN': ['ORG']}},\n            'POS': {'NOT_IN': ['VERB']}, 'OP': '*'},\n           {'_': {'ref_t': 'ORG'}}] # object\nmatcher.add('subsidiary-of', None, pattern)\n\n```", "```py\ndef extract_rel_match(doc, matcher):\n    for sent in doc.sents:\n        for match_id, start, end in matcher(sent):\n            span = sent[start:end]  # matched span\n            pred = nlp.vocab.strings[match_id] # rule name\n            subj, obj = span[0], span[-1]\n            if pred.startswith('rev-'): # reversed relation\n                subj, obj = obj, subj\n                pred = pred[4:]\n            yield ((subj._.ref_n, subj._.ref_t), pred,\n                   (obj._.ref_n, obj._.ref_t))\n\n```", "```py\npattern = [{'_': {'ref_t': 'ORG'}}, # subject\n           {'LOWER': {'IN': subs_synonyms}}, # predicate\n           {'_': {'ref_t': 'ORG'}}] # object\nmatcher.add('rev-subsidiary-of', None, pattern)\n\n```", "```py\ntext = \"\"\"Fujitsu plans to acquire 80% of Fairchild Corp, an industrial unit\nof Schlumberger. The Schlumberger unit Fairchild Corp received an offer.\"\"\"\ndoc = nlp(text)\nprint(*extract_rel_match(doc, matcher), sep='\\n')\n\n```", "```py\n(('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))\n(('Fairchild', 'ORG'), 'subsidiary-of', ('Schlumberger', 'ORG'))\n(('Fairchild', 'ORG'), 'subsidiary-of', ('Schlumberger', 'ORG'))\n\n```", "```py\ntext = \"Fairchild Corp was acquired by Fujitsu.\"\nprint(*extract_rel_match(nlp(text), matcher), sep='\\n')\n\n```", "```py\n(('Fairchild', 'ORG'), 'acquires', ('Fujitsu', 'ORG'))\n\n```", "```py\ntext = \"Fujitsu, a competitor of NEC, acquired Fairchild Corp.\"\nprint(*extract_rel_match(nlp(text), matcher), sep='\\n')\n\n```", "```py\n(('NEC', 'ORG'), 'acquires', ('Fairchild', 'ORG'))\n\n```", "```py\nif matcher.has_key(\"acquires\"):\n    matcher.remove(\"acquires\")\n\n```", "```py\ntext = \"Fujitsu, a competitor of NEC, acquired Fairchild Corp.\"\ndoc = nlp(text)\ndisplacy.render(doc, style='dep',\n                options={'compact': False, 'distance': 100})\n\n```", "```py\ndef extract_rel_dep(doc, pred_name, pred_synonyms, excl_prepos=[]):\n    for token in doc:\n        if token.pos_ == 'VERB' and token.lemma_ in pred_synonyms:\n            pred = token\n            passive = is_passive(pred)\n            subj = find_subj(pred, 'ORG', passive)\n            if subj is not None:\n                obj = find_obj(pred, 'ORG', excl_prepos)\n                if obj is not None:\n                    if passive: # switch roles\n                        obj, subj = subj, obj\n                    yield ((subj._.ref_n, subj._.ref_t), pred_name,\n                           (obj._.ref_n, obj._.ref_t))\n\n```", "```py\ntext = \"\"\"Fujitsu said that Schlumberger Ltd has arranged\nto sell its stake in Fairchild Inc.\"\"\"\ndoc = nlp(text)\nprint(*extract_rel_dep(doc, 'sells', ['sell']), sep='\\n')\n\n```", "```py\n(('Schlumberger', 'ORG'), 'sells', ('Fairchild', 'ORG'))\n\n```", "```py\nprint(\"A:\", *extract_rel_dep(doc, 'sells', ['sell']))\nprint(\"B:\", *extract_rel_dep(doc, 'sells', ['sell'], ['to', 'from']))\n\n```", "```py\nA: (('Schlumberger', 'ORG'), 'sells', ('Fujitsu', 'ORG'))\nB:\n\n```", "```py\ntexts = [\n     \"Fairchild Corp was bought by Fujitsu.\", # 1\n     \"Fujitsu, a competitor of NEC Co, acquired Fairchild Inc.\", # 2\n     \"Fujitsu is expanding.\" +\n     \"The company made an offer to acquire 80% of Fairchild Inc.\", # 3\n     \"Fujitsu plans to acquire 80% of Fairchild Corp.\", # 4\n     \"Fujitsu plans not to acquire Fairchild Corp.\", # 5\n     \"The competition forced Fujitsu to acquire Fairchild Corp.\" # 6\n]\n\nacq_synonyms = ['acquire', 'buy', 'purchase']\nfor i, text in enumerate(texts):\n    doc = nlp(text)\n    rels = extract_rel_dep(doc, 'acquires', acq_synonyms, ['to', 'from'])\n    print(f'{i+1}:', *rels)\n\n```", "```py\n1: (('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))\n2: (('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))\n3: (('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))\n4: (('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))\n5: (('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))\n6:\n\n```", "```py\nif spacy.prefer_gpu():\n    print(\"Working on GPU.\")\nelse:\n    print(\"No GPU found, working on CPU.\")\nnlp = spacy.load('en_core_web_lg')\n\n```", "```py\npipes = [entity_ruler, norm_entities, merge_entities,\n         init_coref, alias_resolver, name_resolver,\n         neural_coref, anaphor_coref, norm_names]\nfor pipe in pipes:\n    nlp.add_pipe(pipe)\n\n```", "```py\nceo_synonyms = ['chairman', 'president', 'director', 'ceo', 'executive']\npattern = [{'ENT_TYPE': 'PERSON'},\n           {'ENT_TYPE': {'NOT_IN': ['ORG', 'PERSON']}, 'OP': '*'},\n           {'LOWER': {'IN': ceo_synonyms}}, {'TEXT': 'of'},\n           {'ENT_TYPE': {'NOT_IN': ['ORG', 'PERSON']}, 'OP': '*'},\n           {'ENT_TYPE': 'ORG'}]\nmatcher.add('executive-of', None, pattern)\n\npattern = [{'ENT_TYPE': 'ORG'},\n           {'LOWER': {'IN': ceo_synonyms}},\n           {'ENT_TYPE': 'PERSON'}]\nmatcher.add('rev-executive-of', None, pattern)\n\n```", "```py\ndef extract_rels(doc):\n    yield from extract_rel_match(doc, matcher)\n    yield from extract_rel_dep(doc, 'acquires', acq_synonyms, ['to', 'from'])\n    yield from extract_rel_dep(doc, 'sells', ['sell'], ['to', 'from'])\n\n```"]