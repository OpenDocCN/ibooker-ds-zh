["```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\napp_data = pd.read_csv(\n    \"./data/lsapp.tsv.gz\",\n    sep=\"\\t\",      #1\n    names=[\"user_id\", \"session_id\", \"timestamp\",\n           \"app_name\", \"event_type\"],     #2\n    parse_dates=[\"timestamp\"],      #3\n    skiprows=1     #4\n)\nprint(app_data.shape)\napp_data.head()\n```", "```py\napp_data.isnull().sum()\n```", "```py\napp_data = app_data.dropna()\n```", "```py\napp_data[\"user_id\"] = app_data[\"user_id\"].astype(int)\napp_data[\"session_id\"] = app_data[\"session_id\"].astype(int)\n\napp_data.dtypes\n```", "```py\napp_data[\"event_type\"].value_counts(normalize=True)\n```", "```py\napp_data = app_data[app_data[\"event_type\"] != \"Broken\"]\n```", "```py\napp_data[\"user_id\"].nunique()\n```", "```py\napp_data[\"app_name\"].nunique()\n```", "```py\napp_data[\"timestamp\"].agg([\"min\", \"max\"])\n```", "```py\nsessions_per_user = (\n    app_data\n    .groupby(\"user_id\")\n    [\"session_id\"]\n    .nunique()    \n)\n\nsessions_per_user.describe()\n```", "```py\nfig, axis = plt.subplots()\n\nsessions_per_user.hist(bins=20, ax=axis)\n\naxis.set(\n    title=\"Sessions per user\",\n    xlabel=\"Number of sessions\",\n    ylabel=\"Frequency\"\n)\n\nplt.show()\n```", "```py\nsessions_per_user.sort_values(ascending=False).head(5)\n```", "```py\napp_data[app_data[\"user_id\"] == 138].head(10)\n```", "```py\napp_data.duplicated().sum() / len(app_data)\n```", "```py\nclosed_dropped = app_data.loc[app_data[\"event_type\"] != \"Closed\", :]\n\nprint(len(closed_dropped))\nprint(len(closed_dropped) / len(app_data))\nprint(closed_dropped.duplicated().sum() / len(closed_dropped))\n```", "```py\napp_data_reduced = closed_dropped.drop_duplicates()\nlen(app_data_reduced)\n```", "```py\napp_data_reduced.head(10)\n```", "```py\n(\n    app_data_reduced\n    .groupby(\"session_id\")\n    [\"user_id\"]\n    .nunique()\n    .loc[lambda x: x > 1]\n)\n```", "```py\nsessions = (\n    app_data_reduced\n    .groupby([\"user_id\", \"session_id\"])\n    .agg(start=(\"timestamp\", \"min\"),\n         end=(\"timestamp\", \"max\"))\n    .reset_index()\n    .assign(\n        duration_mins=lambda _df: (_df[\"end\"] - _df[\"start\"]).dt.seconds/60\n    )\n)\n\nsessions.head()\n```", "```py\nfig, axis = plt.subplots()\n\navg_session_by_user = (\n    sessions\n    .groupby(\"user_id\")\n    [\"duration_mins\"]\n    .median()\n)\n\n(\n    avg_session_by_user\n    .hist(bins=20, ax=axis)\n)\n\naxis.set(\n    title=\"Distribution of users' average session length \\\n(one data point = 1 user)\",\n    xlabel=\"Session duration (minutes)\",\n    ylabel=\"Frequency\"\n)\n\nplt.show()\n```", "```py\nsessions[\"hour\"] = sessions[\"start\"].dt.hour\n\n(\n    sessions[\"hour\"]\n    .value_counts()\n    .sort_index()\n    .plot(kind=\"bar\")\n)\n```", "```py\ndef get_modes(group):\n    mode_hours = group['hour'].mode()     #1\n    return pd.DataFrame(\n        {\n            'user_id': group['user_id'].iloc[0],\n            'most_frequent_hour': mode_hours\n        }\n    )\n\nmost_frequent_hours = (\n    sessions\n    .groupby(\"user_id\")\n    .apply(get_modes)     #2\n    .rename(columns={\"user_id\": \"duplicate_user_id\"})\n    .reset_index()\n    .drop(columns=[\"level_1\", \"duplicate_user_id\"])     #3\n)\n\nmost_frequent_hours.head()\n```", "```py\nfig, axis = plt.subplots()\n\n(\n    most_frequent_hours\n    [\"most_frequent_hour\"]\n    .value_counts()\n    .sort_index()\n    .plot\n    .bar(ax=axis)\n)\n\naxis.set(\n    title=\"Distribution of most common starting time\n↪ for users' browsing sessions\",\n    xlabel=\"Hour\",\n    ylabel=\"Frequency\"\n)\n\nplt.show()\n```", "```py\nbins = [-1, 3, 9, 14, 20]\nlabels = ['night_owl', 'early_morning_browser',\n          'midday_browser', 'late_day_browser']\n\nmost_frequent_hours[\"category\"] = (\n    pd.cut(\n        most_frequent_hours[\"most_frequent_hour\"],\n        bins=bins,\n        labels=labels,\n        ordered=True\n    )\n)\n\nmost_frequent_hours.loc[\n↪ most_frequent_hours[\"most_frequent_hour\"].isin([21, 22, 23]),\n↪ \"category\"] = \"night_owl\"   #1\n\nmost_frequent_hours.head()\n```", "```py\n(\n    most_frequent_hours[\"category\"]\n    .value_counts()\n    .sort_index()\n)\n```", "```py\nusers = (\n    pd.get_dummies(      #1\n        most_frequent_hours.drop(columns=[\"most_frequent_hour\"]),\n        columns=[\"category\"],\n        prefix=\"time\"\n    )\n    .groupby(\"user_id\")\n    .max()\n    .reset_index()\n)\n\nusers.head()\n```", "```py\nprint(app_data_reduced[\"app_name\"].unique())\n```", "```py\ncategories = pd.read_csv(\"./data/App_Categories.csv\",\n                         skiprows=1,\n                         names=[\"app_name\", \"app_category\"])\nprint(categories.shape)\ncategories.head()\n```", "```py\ncategories[\"app_category\"].value_counts()\n```", "```py\ncategories[categories[\"app_category\"] == \"Unknown\"]\n```", "```py\ncategories.loc[categories[\"app_name\"]==\"MUIQ Survey App\", \"app_category\"]\n↪ = \"Survey\"\ncategories.loc[categories[\"app_name\"]==\"SurveyCow\", \"app_category\"]\n↪ = \"Survey\"\ncategories.loc[categories[\"app_name\"]==\"Reward Stash\", \"app_category\"]\n↪ = \"Rewards\"\ncategories.loc[categories[\"app_name\"]==\"Movie Play Box\", \"app_category\"]\n↪ = \"Video Streaming\"\ncategories.loc[categories[\"app_name\"]==\"MetroZone\", \"app_category\"]\n↪ = \"Utility\"\n```", "```py\nfor category in sorted(categories[\"app_category\"].unique()):\n    print(f\"'{category}': '',\")\n```", "```py\ncategories = categories.rename(columns={\"app_category\": \"app_subcategory\"})\n\ncategory_map = {\n    'Advertising': 'Money',\n    'App Marketplace': 'Entertainment',\n    'Cloud Storage': 'Utility',\n    'Communication': 'Social',\n    'Email': 'Social',\n    'Finance': 'Money',\n    'Health': 'Social',\n    'Messaging': 'Social',\n    'Mobile Games': 'Entertainment',\n    'Music Streaming': 'Entertainment',\n    'Navigation': 'Utility',\n    'News': 'Social',\n    'Note Taking': 'Utility',\n    'Online Shopping': 'Money',\n    'Photo Editing': 'Utility',\n    'Photo Management': 'Utility',\n    'Podcasts': 'Entertainment',\n    'Productivity': 'Utility',\n    'Rewards': 'Money',\n    'Social Media': 'Social',\n    'Social Media/Messaging': 'Social',\n    'Survey': 'Money',\n    'Utility': 'Utility',\n    'Video Streaming': 'Entertainment',\n    'Web Browser': 'Browsing',\n    'Web Browser/Search Engine': 'Browsing'\n}\n\ncategories[\"app_category\"]\n↪ = categories[\"app_subcategory\"].map(category_map)\ncategories.head()\n```", "```py\napp_data_merged = app_data_reduced.merge(\n    categories,\n    on=\"app_name\")\nassert len(app_data_reduced) ==  len(app_data_merged)      #1\napp_data_merged.head()\n```", "```py\ntop_categories = (\n    app_data_merged\n    .groupby(\"user_id\")\n    [\"app_category\"]\n    .apply(pd.Series.mode)\n    .reset_index()\n)\n\ntop_categories.head()\n```", "```py\ntop_categories[top_categories[\"level_1\"] > 0]\n```", "```py\ntop_categories[top_categories[\"user_id\"].isin([35, 223, 132])]\n```", "```py\n(\n    app_data_merged[app_data_merged[\"user_id\"] == 35]\n    .groupby([\"app_category\", \"app_name\"])\n    .size()\n)\n```", "```py\ntop_categories = (\n    top_categories\n    .drop(\n        index=top_categories[\n            (top_categories[\"user_id\"].isin([35, 132]))\n            & (top_categories[\"app_category\"] == \"Utility\")\n            ].index\n    )\n)\n```", "```py\n(\n    app_data_merged[app_data_merged[\"user_id\"] == 223]\n    .groupby([\"app_category\", \"app_name\"])\n    .size()\n)\n```", "```py\ntop_categories = (\n    top_categories\n    .drop(\n        index=top_categories[\n            (top_categories[\"user_id\"] == 223)\n            & (top_categories[\"app_category\"] == \"Browsing\")\n            ].index\n    )\n)\ntop_categories[\"user_id\"].value_counts().loc[lambda x: x > 1]\n```", "```py\ntop_categories = (\n    pd.get_dummies(\n        top_categories,\n        columns=[\"app_category\"]\n    ).drop(\n        columns=[\"level_1\"]\n    )\n)\n\ntop_categories.head()\n```", "```py\nsize_before = len(users)\nusers = users.merge(top_categories, on=\"user_id\")\nsize_after = len(users)\nassert size_before == size_after\nusers.head()\n```", "```py\nuser_metrics = (\n    app_data_merged\n    .groupby([\"user_id\"])\n    .agg(\n        number_of_apps=(\"app_name\", \"nunique\"),\n        number_of_sessions=(\"session_id\", \"nunique\")\n    )\n    .reset_index()\n)\n\nuser_metrics.head()\n```", "```py\nsize_before = len(users)\nusers = users.merge(user_metrics, on=\"user_id\")\nsize_after = len(users)\nassert size_before == size_after\n```", "```py\navg_sessions = (\n    sessions\n    .groupby(\"user_id\")\n    .agg(avg_session_length=(\"duration_mins\", \"median\"))\n    .reset_index()\n)\n\navg_sessions.head()\n```", "```py\nsize_before = len(users)\nusers = users.merge(avg_sessions, on=\"user_id\")\nsize_after = len(users)\nassert size_before == size_after\n\nusers.columns\n```", "```py\nusers.to_parquet(\"../chapter-13/data/users.parquet\", index=False)\n```"]