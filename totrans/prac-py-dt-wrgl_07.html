<html><head></head><body><section data-pdf-bookmark="Chapter 7. Cleaning, Transforming, &#10;and Augmenting Data" data-type="chapter" epub:type="chapter"><div class="chapter" id="chapter7">&#13;
<h1><span class="label">Chapter 7. </span>Cleaning, Transforming, &#13;
<span class="keep-together">and Augmenting Data</span></h1>&#13;
&#13;
&#13;
<p>Most of the time, the data that we initially find, collect, or acquire doesn’t quite suit our needs in one way or another. The format is awkward, the data structure is wrong, or its units need to be adjusted. The data itself might contain errors, inconsistencies, or gaps. It may contain references we don’t understand or hint at additional possibilities that aren’t realized. Whatever the limitation may be, in our quest to use data as a source of insight, it is inevitable that we will have to clean, transform, and/or augment it in some way in order to get the most out of it.</p>&#13;
&#13;
<p>Up until now, we have put off most of this work because we had more urgent problems to solve. In <a data-type="xref" href="ch04.html#chapter4">Chapter 4</a>, our focus was on getting data out of a tricky file format and into something more accessible; in <a data-type="xref" href="ch06.html#chapter6">Chapter 6</a>, our priority was thoroughly assessing the quality of our data, so we could make an informed decision about whether it was worth the investment of augmentation and analysis at all.</p>&#13;
&#13;
<p>Now, however, it’s time to roll up our sleeves and begin what to me is sort of the second phase of data wrangling and quality work: preparing the data we have for the analysis we want to perform. Our data is in the table-type format we need, and we’ve determined that it’s of high enough quality to yield <em>some</em> useful insights—even if they are not precisely the ones we first imagined.</p>&#13;
&#13;
<p>Since it’s obviously impossible to identify and address every possible problem or technique related to cleaning, transforming, and/or augmenting data, my approach here will be to work through the actual examples we’ve already encountered where one or more of these tasks is required. For example, we’ll look at different ways we might need to transform date-type information using datasets we encountered in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch02.html#chapter2">2</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.html#chapter4">4</a>. We’ll also look at different ways we can clean up the “cruft” in data files that contain both structured data <em>and</em> metadata. We’ll even explore <em>regular expressions</em>, which offer us a powerful way to select only certain parts of a data field or match particular terms and patterns irrespective of capitalization and/or punctuation. In the process, we’ll manage to cover a decent range of the tools and strategies you’re likely to need when cleaning and transforming most datasets. At the very least, the approaches outlined in this chapter will give you a useful starting place if you encounter a challenge that’s truly gnarly or unique.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Selecting a Subset of Citi Bike Data" data-type="sect1"><div class="sect1" id="idm45143404318400">&#13;
<h1>Selecting a Subset of Citi Bike Data</h1>&#13;
&#13;
<p>Way back<a data-primary="Citi Bike dataset" data-secondary="subsets of" data-type="indexterm" id="citibike-subset"/><a data-primary="subsets of data" data-type="indexterm" id="subsets"/> in <a data-type="xref" href="ch02.html#hitting_the_road_intro">“Hitting the Road with Citi Bike Data”</a>, we used Citi Bike system data to test out some of our freshly unboxed Python concepts, like <code>for...in</code> loops and <code>if/else</code> conditionals. For the sake of convenience, we started with a sample dataset that I had excerpted from <a href="https://s3.amazonaws.com/tripdata/index.html">the September 2020 system data file</a>.</p>&#13;
&#13;
<p>There are any number of situations where we’ll want to segment large datasets for analysis—either because we don’t have the time or computational resources to process everything at once or because we’re only interested in a subset of the dataset to begin with. If all we wanted to do was select a specific number of rows, we could write a <code>for...in</code> loop using the <code>range()</code> function described in <a data-type="xref" href="ch04.html#add_iterators">“Adding Iterators: The range Function”</a>. But we might also want to excerpt the data based on its values as well. I did this in selecting all of the rides from September 1, 2020, but we might also want to do something a bit more nuanced, like evaluating weekday Citi Bike rides separately from those taken on weekends and holidays.</p>&#13;
&#13;
<p>Let’s start with the first task, of excerpting just the September 1, 2020, rides from the larger dataset.<sup><a data-type="noteref" href="ch07.html#idm45143404308272" id="idm45143404308272-marker">1</a></sup> Conceptually, this is simple enough: we just want to keep every row in our dataset containing a ride that started on the first day of September. If we briefly revisit the dataset, however, it becomes clear that even this task is not so simple.</p>&#13;
&#13;
<figure><div class="figure" id="citibike_sample_screengrab">&#13;
<img alt="Zoomed-in view of the first few lines of Citi Bike trip data." src="assets/ppdw_0701.png"/>&#13;
<h6><span class="label">Figure 7-1. </span>First few lines of Citi Bike trip data</h6>&#13;
</div></figure>&#13;
&#13;
<p>As you can see in <a data-type="xref" href="#citibike_sample_screengrab">Figure 7-1</a>, the <code>starttime</code> column is not simply a date but some kind of date/time format that includes not just the month, day, and year but also the hours, minutes, and seconds (to four decimal points!). The first entry in this data file, for example, the value of the <code>starttime</code>, looks like this:</p>&#13;
<pre>2020-09-01 00:00:01.0430</pre>&#13;
&#13;
<p>Obviously, if we want to analyze just the first day of rides—or just rides during the morning “rush hour” commute or just weekday rides—we need a way to effectively filter our data based on just <em>part</em> of the information that’s stored in this column. But what options do we have for accomplishing this? In the next few sections, we’ll look at each of these tasks—finding just rides on a particular date, in a particular time frame, and on a particular “type” of day—in turn. In the process, we’ll learn some of the tools Python offers for solving problems like these, as well as when and why we might choose one over another.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="A Simple Split" data-type="sect2"><div class="sect2" id="idm45143404300656">&#13;
<h2>A Simple Split</h2>&#13;
&#13;
<p>Solving <a data-primary="Citi Bike dataset" data-secondary="subsets of" data-tertiary="splitting strings" data-type="indexterm" id="citibike-subset-split-string"/><a data-primary="subsets of data" data-secondary="splitting strings" data-type="indexterm" id="subsets-split-string"/><a data-primary="strings" data-secondary="splitting" data-type="indexterm" id="strings-splitting"/><a data-primary="splitting strings" data-type="indexterm" id="split-strings"/><a data-primary="dates" data-secondary="separating from times" data-type="indexterm" id="dates-separate"/><a data-primary="timestamps" data-secondary="separating from dates" data-type="indexterm" id="times-separate"/><a data-primary="split() function" data-type="indexterm" id="split-function"/><a data-primary="Python" data-secondary="splitting strings" data-type="indexterm" id="python-split-strings"/>the first problem—excerpting just the rides that started on September 1, 2020—is actually relatively easy to do if we combine some of the tools that we’ve used already in some previous examples. It starts with recognizing that when we read in a basic CSV file with Python, most of our data will be treated as strings.<sup><a data-type="noteref" href="ch07.html#idm45143404288880" id="idm45143404288880-marker">2</a></sup> This means that, even though we humans clearly know that <code>2020-09-01 00:00:01.0430</code> is meant to be <em>interpreted</em> as a date and time, Python just sees it as a collection of numbers and characters.</p>&#13;
&#13;
<p>Looking at the <code>starttime</code> field this way, the question of how to find all the rides that started on September 1, 2020, becomes a bit more straightforward, because the part of our data that contains the “date” information is <em>always</em> separated from the “time” information by a single space. This means that if we can find a way to look only at what comes <em>before</em> that space, we can easily set up an <code>if/else</code> conditional to compare that to our target date string—in this case, <code>2020-09-01</code>—and use that comparison to keep only the rows we want.</p>&#13;
&#13;
<p>While it may not seem glamorous, the built-in string <code>split()</code> is going to be our hero here. It’s already played a supporting role in previous exercises when we needed to break up filenames or URLs; we actually used it way back in <a data-type="xref" href="ch02.html#verbs_are_functions">“Verbs ≈ Functions”</a> to illustrate the difference between functions and methods! As a refresher, this method lets us specify a single character that should be used to split a string into parts. The output of this method is a list, which contains the “leftover” pieces of the string in the order in which they appeared, with the character you <code>split()</code> on removed. So splitting the string <code>2020-09-01 00:00:01.0430</code> on a space will yield the list <code>['2020-09-01', '00:00:01.0430']</code>.</p>&#13;
&#13;
<p>To see how simple and effective this is, let’s modify our script from <a data-type="xref" href="ch02.html#hitting_the_road_intro">“Hitting the Road with Citi Bike Data”</a>. In <a data-type="xref" href="#citibike_september1_rides">Example 7-1</a>, I’ve edited down some of the comments because these tasks are much more familiar now, but it’s still a good idea to outline your script’s objective at the top.</p>&#13;
<div data-type="example" id="citibike_september1_rides">&#13;
<h5><span class="label">Example 7-1. </span>citibike_september1_rides.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># objectives: filter all September 2020 Citi Bike rides, and output a new</code>&#13;
<code class="c1">#             file containing only the rides from 2020-09-01</code>&#13;
&#13;
<code class="c1"># program outline:</code>&#13;
<code class="c1"># 1. read in the data file: 202009-citibike-tripdata.csv</code>&#13;
<code class="c1"># 2. create a new output file, and write the header row to it.</code>&#13;
<code class="c1"># 3. for each row in the file, split the `starttime` value on space:</code>&#13;
<code class="c1">#       a. if the first item in the resulting list is '2020-09-01', write</code>&#13;
<code class="c1">#          the row to our output file</code>&#13;
<code class="c1"># 4. close the output file</code>&#13;
&#13;
<code class="c1"># import the "csv" library</code>&#13;
<code class="kn">import</code> <code class="nn">csv</code>&#13;
&#13;
<code class="c1"># open our data file in "read" mode</code>&#13;
<code class="n">source_file</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="s2">"202009-citibike-tripdata.csv"</code><code class="p">,</code><code class="s2">"r"</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># open our output file in "write" mode</code>&#13;
<code class="n">output_file</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="s2">"2020-09-01-citibike-tripdata.csv"</code><code class="p">,</code><code class="s2">"w"</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># pass our source_file to the DictReader "recipe"</code>&#13;
<code class="c1"># and store the result in a variable called `citibike_reader`</code>&#13;
<code class="n">citibike_reader</code> <code class="o">=</code> <code class="n">csv</code><code class="o">.</code><code class="n">DictReader</code><code class="p">(</code><code class="n">source_file</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># create a corresponding DictWriter and specify that the</code>&#13;
<code class="c1"># header should be the same as the `citibike_reader` fieldnames</code>&#13;
<code class="n">output_writer</code> <code class="o">=</code> <code class="n">csv</code><code class="o">.</code><code class="n">DictWriter</code><code class="p">(</code><code class="n">output_file</code><code class="p">,</code> <code class="n">fieldnames</code><code class="o">=</code><code class="n">citibike_reader</code><code class="o">.</code><code class="n">fieldnames</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># write the header row to the output file</code>&#13;
<code class="n">output_writer</code><code class="o">.</code><code class="n">writeheader</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># use a `for...in` loop to go through our `citibike_reader` list of rows</code>&#13;
<code class="k">for</code> <code class="n">a_row</code> <code class="ow">in</code> <code class="n">citibike_reader</code><code class="p">:</code>&#13;
&#13;
    <code class="c1"># get the value in the 'starttime' column</code>&#13;
    <code class="n">start_timestamp</code> <code class="o">=</code> <code class="n">a_row</code><code class="p">[</code><code class="s2">"starttime"</code><code class="p">]</code>&#13;
&#13;
    <code class="c1"># split the value in 'starttime' on the space character</code>&#13;
    <code class="n">timelist</code> <code class="o">=</code> <code class="n">start_timestamp</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s2">" "</code><code class="p">)</code>&#13;
&#13;
    <code class="c1"># the "date" part of the string will be the first item, position 0</code>&#13;
    <code class="n">the_date</code> <code class="o">=</code> <code class="n">timelist</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>&#13;
&#13;
    <code class="c1"># if `the_date` matches our desired date</code>&#13;
    <code class="k">if</code> <code class="n">the_date</code> <code class="o">==</code> <code class="s2">"2020-09-01"</code><code class="p">:</code>&#13;
&#13;
        <code class="c1"># write that row of data to our output file</code>&#13;
        <code class="n">output_writer</code><code class="o">.</code><code class="n">writerow</code><code class="p">(</code><code class="n">a_row</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># close the output file</code>&#13;
<code class="n">output_file</code><code class="o">.</code><code class="n">close</code><code class="p">()</code></pre></div>&#13;
&#13;
<p>Pretty simple, right? Of course, you could easily modify this script to capture a different date, or even multiple dates if you wanted to. For example, you could modify the <code>if</code> statement to be something like:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting" id="match_multi_dates"> <code class="k">if</code> <code class="n">the_date</code> <code class="o">==</code> <code class="s2">"2020-09-01"</code> <code class="ow">or</code> <code class="n">the_date</code> <code class="o">==</code> <code class="s2">"2020-09-02"</code><code class="p">:</code></pre>&#13;
&#13;
<p>Of course, while this <code>or</code> statement works perfectly well if you’re looking for two or three specific dates, it starts to get <em>very</em> messy if you need to look for more than that (you may recall that we ended up with a similarly awkward conditional in <a data-type="xref" href="ch06.html#ppp_loan_uses">Example 6-12</a>). In order to filter our data with the precision we need without generating extraordinarily complex, awkward, and error-prone code, we’ll be better served by a whole different<a data-primary="Citi Bike dataset" data-secondary="subsets of" data-startref="citibike-subset-split-string" data-tertiary="splitting strings" data-type="indexterm" id="idm45143404099904"/><a data-primary="subsets of data" data-secondary="splitting strings" data-startref="subsets-split-string" data-type="indexterm" id="idm45143404098448"/><a data-primary="strings" data-secondary="splitting" data-startref="strings-splitting" data-type="indexterm" id="idm45143404097232"/><a data-primary="splitting strings" data-startref="split-strings" data-type="indexterm" id="idm45143404096016"/><a data-primary="dates" data-secondary="separating from times" data-startref="dates-separate" data-type="indexterm" id="idm45143404095072"/><a data-primary="timestamps" data-secondary="separating from dates" data-startref="times-separate" data-type="indexterm" id="idm45143404093856"/><a data-primary="split() function" data-startref="split-function" data-type="indexterm" id="idm45143404092640"/><a data-primary="Python" data-secondary="splitting strings" data-startref="python-split-strings" data-type="indexterm" id="idm45143404091696"/> toolkit: <em>regular expressions</em>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Regular Expressions: Supercharged String Matching" data-type="sect2"><div class="sect2" id="regex_example">&#13;
<h2>Regular Expressions: Supercharged String Matching</h2>&#13;
&#13;
<p>A <em>regular expression</em> (often shortened to <em>regex</em>),  allows <a data-primary="Citi Bike dataset" data-secondary="subsets of" data-tertiary="matching with regular expressions" data-type="indexterm" id="citibike-subset-regex"/><a data-primary="subsets of data" data-secondary="matching with regular expressions" data-type="indexterm" id="subsets-regex"/><a data-primary="strings" data-secondary="regular expressions" data-type="indexterm" id="strings-regex"/><a data-primary="regular expressions" data-type="indexterm" id="regex"/><a data-primary="Python" data-secondary="regular expressions" data-type="indexterm" id="python-regex"/>you to quickly and efficiently search for string patterns within a larger string or piece of text. In most cases, if you’re trying to solve a matching or filtering problem and find that the solution involves <em>lots</em> of <code>and</code> or <code>or</code> statements, it’s an early sign that what you really need is a regular expression.</p>&#13;
&#13;
<p>Regular expressions are found in most programming languages and are concise, powerful, and, at times, <em>extremely</em> tricky to work with. While a single regular expression can encapsulate even a very complex search pattern, designing regexes that work as expected can be extremely time-consuming, often requiring quite a bit of trial and error to get right. Since our goal is for our data wrangling work to be both efficient <em>and</em> comprehensible, we’ll focus here on short regexes that offer unique functionality not easily achieved through other means. While there are certain tasks where regular expressions are indispensable, they are not the tool for solving every problem and usually work best when paired with other techniques.</p>&#13;
&#13;
<p>To get started, let’s use a regular expression to tackle the problem of filtering out rides that take place within the typical “morning commute” hours, which we’ll estimate here as being from 7 a.m. to 9 a.m. Any regex process begins with distinguishing for ourselves what we <em>want</em> to match from what we <em>don’t</em>. Here, we’ll start with an example <code>starttime</code> entry that is <em>outside</em> of our identified time range (hence, something we <em>don’t</em> want to match):</p>&#13;
<pre> 2020-09-01 00:00:01.0430</pre>&#13;
&#13;
<p>Now let’s look at a <code>starttime</code> entry that falls <em>within</em> it:</p>&#13;
<pre> 2020-09-01 00:08:17.5150</pre>&#13;
&#13;
<p>Now, let’s acknowledge first that we <em>could</em> address this problem with the string-splitting method we saw previously. We could start by splitting on the <code>:</code> character, which would, in the second instance, give us this:</p>&#13;
<pre>['2020-09-01 00', '08', '17.5150']</pre>&#13;
&#13;
<p>Then we could take the middle item from the list and <a data-primary="compound conditionals" data-type="indexterm" id="idm45143404046240"/>use a <em>compound conditional</em>—that is, an <code>if</code> statement that joins two or more tests—to see if it matches the strings <code>'07'</code>, <code>'08'</code>, or <code>'09'</code>.</p>&#13;
&#13;
<p>This approach certainly <em>works</em>, but it feels a little awkward. It requires multiple steps and a three-part conditional that will quickly get difficult to read. A regular expression, meanwhile, will let us narrow in on those hour values in a single step while still being fairly readable. Before we dive into writing the regex itself, though, let’s do a quick overview of the vocabulary of Python regular expressions.</p>&#13;
&#13;
<p>Because a regular expression has to use characters and strings to describe <em>patterns</em> of characters and strings, the Python regular expression “language” uses a<a data-primary="metacharacters in regular expressions" data-type="indexterm" id="idm45143404041040"/> set of <em>metacharacters</em> and special sequences to make describing the pattern you’re searching for simpler. In <a data-type="xref" href="#regex_sequence_list">Table 7-1</a> I’ve included some of the most useful ones, drawn from a more complete list <a href="https://w3schools.com/python/python_regex.asp">on W3Schools</a>.</p>&#13;
<table id="regex_sequence_list">&#13;
<caption><span class="label">Table 7-1. </span>Common regular expression building blocks</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Expression</th>&#13;
<th>Description</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>[]</p></td>&#13;
<td><p>A set of characters</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>“\”</p></td>&#13;
<td><p>Signals a special sequence (can also be used to escape special characters)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>.</p></td>&#13;
<td><p>Any character (except newline character)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>*</p></td>&#13;
<td><p>Zero or more occurrences</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>+</p></td>&#13;
<td><p>One or more occurrences</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>{}</p></td>&#13;
<td><p>Exactly the specified number of occurrences</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>|</p></td>&#13;
<td><p>Either or</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>()</p></td>&#13;
<td><p>Capture and group</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>\d</p></td>&#13;
<td><p>Returns a match where the string contains digits (numbers from 0–9)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>\D</p></td>&#13;
<td><p>Returns a match where the string DOES NOT contain digits</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>\s</p></td>&#13;
<td><p>Returns a match where the string contains a whitespace character</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>\S</p></td>&#13;
<td><p>Returns a match where the string DOES NOT contain a whitespace character</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>\w</p></td>&#13;
<td><p>Returns a match where the string contains any word characters (characters from a to Z, digits from 0–9, and the underscore _ character)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>\W</p></td>&#13;
<td><p>Returns a match where the string DOES NOT contain any word characters</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>As always with writing, regular expressions give us more than one way to “capture” the pattern we’re looking for. In most cases, our goal is to define a pattern that will match what we need to find while avoiding <em>accidentally</em> matching on anything else. For our “rush hour” problem, we can take advantage of the fact that the “hours” digits in the <code>starttime</code> column are surrounded by colons (<code>:</code>), <em>and nothing else is</em>. This means that we can use this “surrounded by colons” pattern as part of our regular expression and feel confident that we won’t accidentally match some other part of the string. To see if this works as we hope, let’s set up a few sample regular expressions to test against some (real and constructed) sample data to see how they do, as shown in <a data-type="xref" href="#regex_tests">Example 7-2</a>.</p>&#13;
<div data-type="example" id="regex_tests">&#13;
<h5><span class="label">Example 7-2. </span>regex_tests.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># the goal of this script is to try out how a couple of regular expressions</code><code>&#13;
</code><code class="c1"># fare with some sample test data. </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO1-1" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO1-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># import the regular expression library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">re</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># using the `re.compile()` method is a helpful way of keeping a reference to</code><code>&#13;
</code><code class="c1"># our various regular expressions</code><code>&#13;
</code><code class="n">bookend_regex</code><code> </code><code class="o">=</code><code> </code><code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s2">"</code><code class="s2">\</code><code class="s2">s0[7-9]:</code><code class="s2">"</code><code class="p">)</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO1-2" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO1-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># always try to be descriptive with the variable names</code><code>&#13;
</code><code class="n">one_sided_regex</code><code> </code><code class="o">=</code><code> </code><code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s2">"</code><code class="s2">0[7-9]:</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># this example should *fail*</code><code>&#13;
</code><code class="n">sample1</code><code> </code><code class="o">=</code><code> </code><code class="s2">"</code><code class="s2">2020-09-01 00:00:01.0430</code><code class="s2">"</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># this example should *match*</code><code>&#13;
</code><code class="n">sample2</code><code> </code><code class="o">=</code><code> </code><code class="s2">"</code><code class="s2">2020-09-01 09:04:23.7930</code><code class="s2">"</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># this example should *fail*</code><code>&#13;
</code><code class="n">sample3</code><code> </code><code class="o">=</code><code> </code><code class="s2">"</code><code class="s2">2020-09-01 10:07:02.0510</code><code class="s2">"</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># let's see what happens!</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="s2">"</code><code class="s2">bookend_regex:</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">bookend_regex</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">sample1</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">bookend_regex</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">sample2</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">bookend_regex</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">sample3</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="s2">"</code><code class="s2">one_sided_regex:</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">one_sided_regex</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">sample1</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">one_sided_regex</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">sample2</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">one_sided_regex</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">sample3</code><code class="p">)</code><code class="p">)</code></pre></div>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO1-1" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>In addition to sample files like this, you can also test out your Python regex online using the <a href="https://w3schools.com/python/trypython.asp?filename=demo_regex">W3Schools regex demo</a>.</p></dd>&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO1-2" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO1-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Even if you only use them once in a script, I <em>strongly</em> recommend defining your regex at the top of your file using an aptly named variable. It is the simplest, most efficient way to keep track of their functionality, especially if you’re using more than one!</p></dd>&#13;
</dl>&#13;
&#13;
<p>When you run the script in <a data-type="xref" href="#regex_tests">Example 7-2</a>, your output should look something like this:</p>&#13;
<pre>bookend_regex:&#13;
None&#13;
&lt;re.Match object; span=(10, 14), match=' 09:'&gt;&#13;
None&#13;
one_sided_regex:&#13;
None&#13;
&lt;re.Match object; span=(11, 14), match='09:'&gt;&#13;
&lt;re.Match object; span=(14, 17), match='07:'&gt;</pre>&#13;
&#13;
<p>As you can see, the “bookended” regex, where we specified both of the colons, correctly matches (<em>and</em> fails to match) in all three cases; the “one-sided” regex, on the other hand, erroneously finds a match on the <em>seconds</em> value of <code>sample3</code>. This is precisely why defining the string you’re looking for as precisely as possible is important. If you look at the <code>Match object</code> printed out previously, you’ll see that it contains information about what was matched (e.g., <code>match='07:'</code>) and where (e.g., from index positions 14–17 in the string).</p>&#13;
&#13;
<p>So far, this seems pretty straightforward. Things can still get a little tricky, however, when the <em>structure</em> of the thing we want to match changes. For example, what if we wanted to expand the hours we’re interested in to range from 7 a.m. to 10 a.m.? Our <code>bookend_regex</code> won’t work as written, because it specifies that the first character after the colon has to be a <code>0</code>. We could try just adding the digits <code>1</code> and <code>0</code> as options to our digit ranges, like so:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">plus_ten</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s2">"\s[01][0789]:"</code><code class="p">)</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="s2">"plus_ten"</code><code class="p">)</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">plus_ten</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="s2">"2020-09-01 18:09:11.0980"</code><code class="p">))</code></pre>&#13;
&#13;
<p class="pagebreak-before less_space">which produces the output:</p>&#13;
<pre>plus_ten&#13;
&lt;re.Match object; span=(10, 14), match=' 18:'&gt;</pre>&#13;
&#13;
<p>The problem, as we can see from the output, is that our data uses a 24-hour clock and will end up matching on a whole range of times that we don’t want. That’s because regular expressions don’t “see” numbers in the way we think of them—all they see are sequences of characters. That’s why <code>18</code> comes back as a match—our regex allows any string that starts with a <code>0</code> or a <code>1</code> and is followed by a <code>0</code>, <code>7</code>, <code>8</code>, or <code>9</code>. While we obviously wrote it with the numbers <code>07</code>, <code>08</code>, <code>09</code>, and <code>10</code> in mind, our code opens the door to many more.</p>&#13;
&#13;
<p>The solution, in this case, is to use <a data-primary="| (pipe) either/or character" data-type="indexterm" id="idm45143403935504"/><a data-primary="pipe (|) either/or character" data-type="indexterm" id="idm45143403929552"/>the “either/or” <em>pipe</em> character (<code>|</code>), which we can use to combine to (otherwise) completely distinct regular expressions. In this case, that will look something like what’s shown in <a data-type="xref" href="#seven_to_ten">Example 7-3</a>.</p>&#13;
<div data-type="example" id="seven_to_ten">&#13;
<h5><span class="label">Example 7-3. </span>Capturing 7 to 10</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">seven_to_ten</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s2">"\s0[7-9]:|\s10:"</code><code class="p">)</code></pre></div>&#13;
&#13;
<p>Try it out yourself with a few sample data points, just to confirm that it captures what we’re looking for (and nothing else).</p>&#13;
&#13;
<p>I’m not going to go too much further with regular expressions than this; as with the web scraping we explored in <a data-type="xref" href="ch05.html#web_scraping">“Web Scraping: The Data Source of Last Resort”</a>, no two regular expression problems (or solutions) are alike. However, I hope you can see the potential these offer for doing pattern matching that would be very awkward with compound conditionals and basic string functions<a data-primary="Citi Bike dataset" data-secondary="subsets of" data-startref="citibike-subset-regex" data-tertiary="matching with regular expressions" data-type="indexterm" id="idm45143403752288"/><a data-primary="subsets of data" data-secondary="matching with regular expressions" data-startref="subsets-regex" data-type="indexterm" id="idm45143403750848"/><a data-primary="strings" data-secondary="regular expressions" data-startref="strings-regex" data-type="indexterm" id="idm45143403749616"/><a data-primary="regular expressions" data-startref="regex" data-type="indexterm" id="idm45143403748400"/><a data-primary="Python" data-secondary="regular expressions" data-startref="python-regex" data-type="indexterm" id="idm45143403747456"/> alone.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Making a Date" data-type="sect2"><div class="sect2" id="idm45143404088960">&#13;
<h2>Making a Date</h2>&#13;
&#13;
<p>One of the<a data-primary="Citi Bike dataset" data-secondary="subsets of" data-tertiary="datetime object" data-type="indexterm" id="citibike-subset-datetime"/><a data-primary="Python" data-secondary="datetime object" data-type="indexterm" id="python-datetime"/><a data-primary="datetime object" data-type="indexterm" id="datetime"/><a data-primary="weekday() function" data-type="indexterm" id="weekday-function"/><a data-primary="dates" data-secondary="datetime object" data-type="indexterm" id="date-datetime"/><a data-primary="timestamps" data-secondary="datetime object" data-type="indexterm" id="time-datetime"/> reasons it’s appealing to treat date-like data as strings is that, as we saw in our work with various source formats of unemployment data in <a data-type="xref" href="ch04.html#chapter4">Chapter 4</a>, the way they are interpreted can vary dramatically across data sources and even Python libraries. Still, there are situations and tasks where converting date-like data to an actual <code>datetime</code> type is very useful. For example, if we want to isolate the weekday rides from our Citi Bike data, we <em>could</em> try to essentially “brute force” it by looking at a calendar, identifying the dates of all the weekdays, and then creating a giant string comparison list or writing a regular expression to match them. In the case of the September 2020 data, such a regular expression object might look something what’s in <a data-type="xref" href="#weekday_regex">Example 7-4</a>.</p>&#13;
<div data-type="example" id="weekday_regex">&#13;
<h5><span class="label">Example 7-4. </span>Weekday regex for September 2020</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">september2020_weekday</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s2">"-0[123489]-|-1[0145678]-|-2[1234589]-|-30-"</code><code class="p">)</code></pre></div>&#13;
&#13;
<p>Ugh. This certainly <em>works</em>, but it’s nearly impossible to read and is still basically one giant compound conditional—even if it’s captured in fewer characters because it’s a regular expression. Moreover, it’s not a solution that scales very well. If we wanted to extend our analysis to any <em>other</em> month, it would mean getting out the calendar all over again.</p>&#13;
&#13;
<p>Fortunately, a well-constructed Python <code>datetime</code> object has a number of built-in methods that can help with exactly this kind of task. In fact there is a simple <code>weekday()</code> method that returns a number from 0 to 6 (<a href="https://docs.python.org/3/library/datetime.html#datetime.date.weekday">with 0 being Monday and 6 being Sunday</a>) based on the day of the week on which a certain date falls. This means that if we convert the contents of our <code>starttime</code> column to a date, as shown in <a data-type="xref" href="#weekday_rides">Example 7-5</a>, we can use this method to quickly identify the day of the week corresponding to <em>any</em> date. This will help us apply our code to additional data sources—say, a different month or year of ridership data—without having to do a thing!</p>&#13;
<div data-type="example" id="weekday_rides">&#13;
<h5><span class="label">Example 7-5. </span>weekday_rides.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># objectives: filter all September 2020 Citi Bike rides, and output a new</code><code>&#13;
</code><code class="c1">#             file containing only weekday rides</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># program outline:</code><code>&#13;
</code><code class="c1"># 1. read in the data file: 202009-citibike-tripdata.csv</code><code>&#13;
</code><code class="c1"># 2. create a new output file, and write the header row to it.</code><code>&#13;
</code><code class="c1"># 3. for each row in the file, make a date from the `starttime`:</code><code>&#13;
</code><code class="c1">#       a. if it's a weekday, write the row to our output file</code><code>&#13;
</code><code class="c1"># 4. close the output file</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># import the "csv" library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">csv</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># import the "datetime" library</code><code>&#13;
</code><code class="kn">from</code><code> </code><code class="nn">datetime</code><code> </code><code class="kn">import</code><code> </code><code class="n">datetime</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># open our data file in "read" mode</code><code>&#13;
</code><code class="n">source_file</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s2">"</code><code class="s2">202009-citibike-tripdata.csv</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">r</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># open our output file in "write" mode</code><code>&#13;
</code><code class="n">output_file</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s2">"</code><code class="s2">202009-citibike-weekday-tripdata.csv</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">w</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># convert source data to a DictReader; store the result in `citibike_reader`</code><code>&#13;
</code><code class="n">citibike_reader</code><code> </code><code class="o">=</code><code> </code><code class="n">csv</code><code class="o">.</code><code class="n">DictReader</code><code class="p">(</code><code class="n">source_file</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># create a corresponding DictWriter and specify its fieldnames</code><code>&#13;
</code><code class="n">output_writer</code><code> </code><code class="o">=</code><code> </code><code class="n">csv</code><code class="o">.</code><code class="n">DictWriter</code><code class="p">(</code><code class="n">output_file</code><code class="p">,</code><code> </code><code class="n">fieldnames</code><code class="o">=</code><code class="n">citibike_reader</code><code class="o">.</code><code class="n">fieldnames</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># actually write the header row to the output file</code><code>&#13;
</code><code class="n">output_writer</code><code class="o">.</code><code class="n">writeheader</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># use a `for...in` loop to go through our `citibike_reader` list of rows</code><code>&#13;
</code><code class="k">for</code><code> </code><code class="n">a_row</code><code> </code><code class="ow">in</code><code> </code><code class="n">citibike_reader</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># convert the value in the 'starttime' column to a date object</code><code>&#13;
</code><code>    </code><code class="n">the_date</code><code> </code><code class="o">=</code><code> </code><code class="n">datetime</code><code class="o">.</code><code class="n">strptime</code><code class="p">(</code><code class="n">a_row</code><code class="p">[</code><code class="s1">'</code><code class="s1">starttime</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="si">%Y</code><code class="s1">-</code><code class="si">%m</code><code class="s1">-</code><code class="si">%d</code><code class="s1"> </code><code class="si">%H</code><code class="s1">:</code><code class="si">%M</code><code class="s1">:</code><code class="si">%S</code><code class="s1">.</code><code class="si">%f</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO2-1" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO2-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># if `the_date` is a weekday</code><code>&#13;
</code><code>    </code><code class="k">if</code><code> </code><code class="n">the_date</code><code class="o">.</code><code class="n">weekday</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">&lt;</code><code class="o">=</code><code> </code><code class="mi">4</code><code class="p">:</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO2-2" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO2-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>        </code><code class="c1"># write that row of data to our output file</code><code>&#13;
</code><code>        </code><code class="n">output_writer</code><code class="o">.</code><code class="n">writerow</code><code class="p">(</code><code class="n">a_row</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># close the output file</code><code>&#13;
</code><code class="n">output_file</code><code class="o">.</code><code class="n">close</code><code class="p">(</code><code class="p">)</code></pre></div>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO2-1" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>As mentioned in <a data-type="xref" href="ch06.html#ppp_date_range">Example 6-1</a>, providing <a href="https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior">the format of our source data</a> will help our script run faster and more reliably.</p></dd>&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO2-2" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO2-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The <code>weekday()</code> method puts <a href="https://docs.python.org/3/library/datetime.html#datetime.date.weekday">Monday at position <code>0</code></a>, so looking for anything up to and including <code>4</code> will capture the values for Monday through Friday.</p></dd>&#13;
</dl>&#13;
&#13;
<p>Depending on your device, you may notice that the script in <a data-type="xref" href="#weekday_rides">Example 7-5</a> takes a while to run. For example, on my (not very powerful) device, it takes more than 85 seconds to complete. Accomplishing the same task using the regular expression in <a data-type="xref" href="#weekday_regex">Example 7-4</a>, meanwhile, takes only 45 seconds. I can also more easily tweak the regular expression to skip days that are officially weekdays but are also holidays (like Labor Day).</p>&#13;
&#13;
<p>So which approach is better? As usual, <em>it depends</em>. What will actually work best for your particular data wrangling/cleaning/transformation process will be specific to your needs and your resources. If answering your question means looking for weekday commute patterns in a decade’s worth of Citi Bike data, you’re probably better off using the <code>weekday()</code> method, because you don’t have to change your code to deal with different months or years. On the other hand, if you don’t have very many months to work with and execution speed (and absolute precision) is your top concern, you might prefer to go the regular expression route. You may also just find that regexes make you want to tear your hair out or that using multiple steps to get perfect results drives you crazy. As we’ll explore more in <a data-type="xref" href="ch08.html#chapter8">Chapter 8</a>, all of these can be legitimate reasons for a particular design choice—just make sure the<a data-primary="Citi Bike dataset" data-secondary="subsets of" data-startref="citibike-subset" data-type="indexterm" id="idm45143403653072"/><a data-primary="subsets of data" data-startref="subsets" data-type="indexterm" id="idm45143403651856"/><a data-primary="Citi Bike dataset" data-secondary="subsets of" data-startref="citibike-subset-datetime" data-tertiary="datetime object" data-type="indexterm" id="idm45143403650912"/><a data-primary="Python" data-secondary="datetime object" data-startref="python-datetime" data-type="indexterm" id="idm45143403649360"/><a data-primary="datetime object" data-startref="datetime" data-type="indexterm" id="idm45143403648144"/><a data-primary="weekday() function" data-startref="weekday-function" data-type="indexterm" id="idm45143403647200"/><a data-primary="dates" data-secondary="datetime object" data-startref="date-datetime" data-type="indexterm" id="idm45143403646256"/><a data-primary="timestamps" data-secondary="datetime object" data-startref="time-datetime" data-type="indexterm" id="idm45143403645040"/> choice is <em>yours</em>.<sup><a data-type="noteref" href="ch07.html#idm45143403643280" id="idm45143403643280-marker">3</a></sup></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="De-crufting Data Files" data-type="sect1"><div class="sect1" id="idm45143404317776">&#13;
<h1>De-crufting Data Files</h1>&#13;
&#13;
<p>In <a data-type="xref" href="ch04.html#chapter4">Chapter 4</a>, we <a data-primary="cleaning data" data-secondary="separating metadata" data-type="indexterm" id="clean-data-metadata"/><a data-primary="data cleaning" data-secondary="separating metadata" data-type="indexterm" id="data-clean-metadata"/><a data-primary="data quality" data-secondary="improving" data-tertiary="cleaning" data-type="indexterm" id="data-quality-improve-clean"/><a data-primary="improving data quality" data-secondary="cleaning" data-type="indexterm" id="improve-data-quality-clean"/><a data-primary="metadata" data-secondary="separating" data-type="indexterm" id="metadata-separate"/><a data-primary=".xls files (Microsoft Excel spreadsheets)" data-primary-sortas="xls files" data-secondary="cleaning data" data-type="indexterm" id="xls-clean"/><a data-primary="spreadsheets" data-secondary=".xls files (Microsoft Excel)" data-secondary-sortas="xls files" data-tertiary="cleaning data" data-type="indexterm" id="spreadsheet-xls-clean"/>encountered a number of instances where we needed to “clean up” a dataset that was otherwise awkward or unintelligible. When we went through the process of parsing an old-school-style <em>.xls</em> file in <a data-type="xref" href="ch04.html#xls_parsing">Example 4-6</a>, for example, we encountered a couple of distinct issues. First, the spreadsheet contained both table-type data <em>and</em> descriptive header information that, despite being useful in principle, will inevitably need to be relocated in order for us to analyze the rest of it. Second, the <em>.xls</em> format’s lack of support for “real” dates means that our initial transformation from <em>.xls</em> to <em>.csv</em> left us with a bunch of nonsense numbers where the dates should have been. While I chose to put off solving those problems at first, the time has come to confront them.</p>&#13;
&#13;
<p>In thinking about the first problem, I want to stress that we <em>definitely</em> don’t want to just “throw out” the information that’s currently stored at the top of the <em>fredgraph.xls</em> file. As is hopefully clear from our work in <a data-type="xref" href="ch06.html#chapter6">Chapter 6</a>, metadata is a precious resource, and we <em>never</em> want to discard metadata from a <a href="https://loc.gov/programs/teachers/getting-started-with-primary-sources">primary source</a>. Rather, my preference in cases like this is to turn one file into two. We’ll strip out the metadata and store it in a separate—but congruently named—text file while also parsing and saving the table-type data into an analysis-friendly <em>.csv</em> format.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45143403622096">&#13;
<h5>Convention over Configuration</h5>&#13;
<p>Even in this book’s <a data-primary="naming" data-secondary="files" data-type="indexterm" id="idm45143403614032"/><a data-primary="files" data-secondary="naming" data-type="indexterm" id="idm45143403613024"/>simplest examples, there are lots of decisions to be made—like naming variables, programming files, data output files, and more. While it may not be <a href="https://en.wikipedia.org/wiki/Convention_over_configuration">perfectly “Pythonic”</a>, I find that the concept of “convention over configuration” has a lot to offer when it comes to collecting, generating, and reorganizing files in the data wrangling process. In particular, using a shared naming convention, our metadata file and our table-type data file can save us headaches both when it comes to creating our files now and finding them again later. While you don’t have to follow the precise pattern I do here, choosing a consistent method for naming these files across your projects is something that will save you time, effort, and anxiety in the long run.</p>&#13;
</div></aside>&#13;
&#13;
<p>Looking at our source <em>.xls</em> file in a spreadsheet program, it’s easy enough to see visually where the metadata ends and the table-type data begins. The real question is: how will we detect this transition in our script? As is so often the case with data cleaning, the most effective solution is not always an elegant one. The metadata ends where the table-type data begins, in the row containing its column headers. If we look at the first value in each row as we work our way through the file, we can <em>stop</em> writing to the metadata file and <em>start</em> writing to the <em>.csv</em> as soon as we encounter the first column header. Since the value <code>observation_date</code> is the first column header for this dataset, we’ll make that transition as soon we find that at the beginning of our current row.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Before you begin, check your source file carefully to see <em>where</em> the metadata appears within it. Especially in cases where the data contains estimates or other qualifiers, you’re likely to find metadata both before and <em>after</em> the table-type data in your source file.</p>&#13;
</div>&#13;
&#13;
<p>To see what’s involved in creating these two purpose-built files from our single source file, take a look at the script in <a data-type="xref" href="#xls_meta_parsing">Example 7-6</a> (if you need a refresher on some of the code choices in this example, you may want to refer back to <a data-type="xref" href="ch04.html#xls_parsing">Example 4-6</a>).</p>&#13;
<div data-type="example" id="xls_meta_parsing">&#13;
<h5><span class="label">Example 7-6. </span>xls_meta_parsing.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># converting data in an .xls file with Python to csv + metadata file</code><code>&#13;
</code><code class="c1"># using the "xrld" library. First, pip install the xlrd library:</code><code>&#13;
</code><code class="c1"># https://pypi.org/project/xlrd/2.0.1/</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># import the "xlrd" library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">xlrd</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># import the `csv` library, to create our output file</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">csv</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># pass our filename as an ingredient to the `xlrd` library's</code><code>&#13;
</code><code class="c1"># `open_workbook()` "recipe"</code><code>&#13;
</code><code class="c1"># store the result in a variable called `source_workbook`</code><code>&#13;
</code><code class="n">source_workbook</code><code> </code><code class="o">=</code><code> </code><code class="n">xlrd</code><code class="o">.</code><code class="n">open_workbook</code><code class="p">(</code><code class="s2">"</code><code class="s2">fredgraph.xls</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># open and name a simple metadata text file</code><code>&#13;
</code><code class="n">source_workbook_metadata</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s2">"</code><code class="s2">fredgraph_metadata.txt</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">w</code><code class="s2">"</code><code class="p">)</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO3-1" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO3-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># an `.xls` workbook can have multiple sheets</code><code>&#13;
</code><code class="k">for</code><code> </code><code class="n">sheet_name</code><code> </code><code class="ow">in</code><code> </code><code class="n">source_workbook</code><code class="o">.</code><code class="n">sheet_names</code><code class="p">(</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># create a variable that points to the current worksheet by</code><code>&#13;
</code><code>    </code><code class="c1"># passing the current value of `sheet_name` to the `sheet_by_name` recipe</code><code>&#13;
</code><code>    </code><code class="n">current_sheet</code><code> </code><code class="o">=</code><code> </code><code class="n">source_workbook</code><code class="o">.</code><code class="n">sheet_by_name</code><code class="p">(</code><code class="n">sheet_name</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># create "xls_"+sheet_name+".csv" as an output file for the current sheet</code><code>&#13;
</code><code>    </code><code class="n">output_file</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s2">"</code><code class="s2">xls_</code><code class="s2">"</code><code class="o">+</code><code class="n">sheet_name</code><code class="o">+</code><code class="s2">"</code><code class="s2">.csv</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">w</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># use the `csv` library's "writer" recipe to easily write rows of data</code><code>&#13;
</code><code>    </code><code class="c1"># to `output_file`, instead of reading data *from* it</code><code>&#13;
</code><code>    </code><code class="n">output_writer</code><code> </code><code class="o">=</code><code> </code><code class="n">csv</code><code class="o">.</code><code class="n">writer</code><code class="p">(</code><code class="n">output_file</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># create a Boolean variable to detect if we've hit our table-type data yet</code><code>&#13;
</code><code>    </code><code class="n">is_table_data</code><code> </code><code class="o">=</code><code> </code><code class="bp">False</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO3-2" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO3-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># now, we need to loop through every row in our sheet</code><code>&#13;
</code><code>    </code><code class="k">for</code><code> </code><code class="n">row_num</code><code class="p">,</code><code> </code><code class="n">row</code><code> </code><code class="ow">in</code><code> </code><code class="nb">enumerate</code><code class="p">(</code><code class="n">current_sheet</code><code class="o">.</code><code class="n">get_rows</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># pulling out the value in the first column of the current row</code><code>&#13;
</code><code>        </code><code class="n">first_entry</code><code> </code><code class="o">=</code><code> </code><code class="n">current_sheet</code><code class="o">.</code><code class="n">row_values</code><code class="p">(</code><code class="n">row_num</code><code class="p">)</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># if we've hit the header row of our data table</code><code>&#13;
</code><code>        </code><code class="k">if</code><code> </code><code class="n">first_entry</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">observation_date</code><code class="s1">'</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># it's time to switch our "flag" value to "True"</code><code>&#13;
</code><code>            </code><code class="n">is_table_data</code><code> </code><code class="o">=</code><code> </code><code class="bp">True</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># if `is_table_data` is True</code><code>&#13;
</code><code>        </code><code class="k">if</code><code> </code><code class="n">is_table_data</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># write this row to the data output file</code><code>&#13;
</code><code>            </code><code class="n">output_writer</code><code class="o">.</code><code class="n">writerow</code><code class="p">(</code><code class="n">current_sheet</code><code class="o">.</code><code class="n">row_values</code><code class="p">(</code><code class="n">row_num</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># otherwise, this row must be metadata</code><code>&#13;
</code><code>        </code><code class="k">else</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># since we'd like our metadata file to be nicely formatted, we</code><code>&#13;
</code><code>            </code><code class="c1"># need to loop through the individual cells of each metadata row</code><code>&#13;
</code><code>            </code><code class="k">for</code><code> </code><code class="n">item</code><code> </code><code class="ow">in</code><code> </code><code class="n">current_sheet</code><code class="o">.</code><code class="n">row</code><code class="p">(</code><code class="n">row_num</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>                    </code><code class="c1"># write the value of the cell</code><code>&#13;
</code><code>                    </code><code class="n">source_workbook_metadata</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">item</code><code class="o">.</code><code class="n">value</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>                    </code><code class="c1"># separate it from the next cell with a tab</code><code>&#13;
</code><code>                    </code><code class="n">source_workbook_metadata</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="s1">'</code><code class="se">\t</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># at the end of each line of metadata, add a newline</code><code>&#13;
</code><code>            </code><code class="n">source_workbook_metadata</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># just for good measure, let's close our output files</code><code>&#13;
</code><code>    </code><code class="n">output_file</code><code class="o">.</code><code class="n">close</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>    </code><code class="n">source_workbook_metadata</code><code class="o">.</code><code class="n">close</code><code class="p">(</code><code class="p">)</code></pre></div>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO3-1" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO3-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>While we’re only creating a single metadata file here, we could easily move this part of the process inside the <code>for</code> loop and create a unique metadata file for every worksheet, if necessary.</p></dd>&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO3-2" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO3-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>This type of Boolean (True/False) variable is often described as a <em>flag</em> variable. The idea is that we set its value <em>outside</em> of a loop and then “flip” its value when some particular thing has happened—this saves us from having to loop through all our data twice. Here, we’ll use it to check when we should start writing to our “data” file instead of our “metadata” file.</p></dd>&#13;
</dl>&#13;
&#13;
<p>Before we move on to dealing with the (still inexplicable) dates in this file, I want to highlight a <a data-primary="flag variables" data-type="indexterm" id="idm45143402902128"/>new technique introduced in <a data-type="xref" href="#xls_meta_parsing">Example 7-6</a>: the use of a so-called <em>flag variable</em>. This term typically refers to any Boolean (True/False) variable that is used to keep track of whether a certain event has taken place or condition has been met, especially within a loop. In <a data-type="xref" href="#xls_meta_parsing">Example 7-6</a>, for example, we are using the <code>is_table_data</code> variable as a way to keep track of whether we have yet encountered the row of data that marks the beginning of our table data. Since a given row of data in our <code>for...in</code> loop is essentially “forgotten” as soon as the next one is read, we need to create this variable <em>before</em> our loop. This keeps the <code>is_table_data</code> variable available beyond the <em>scope</em> of our loop—a concept we’ll look at more <a data-primary="cleaning data" data-secondary="separating metadata" data-startref="clean-data-metadata" data-type="indexterm" id="idm45143403241856"/><a data-primary="data cleaning" data-secondary="separating metadata" data-startref="data-clean-metadata" data-type="indexterm" id="idm45143403240608"/><a data-primary="data quality" data-secondary="improving" data-startref="data-quality-improve-clean" data-tertiary="cleaning" data-type="indexterm" id="idm45143403217616"/><a data-primary="improving data quality" data-secondary="cleaning" data-startref="improve-data-quality-clean" data-type="indexterm" id="idm45143403216064"/><a data-primary="metadata" data-secondary="separating" data-startref="metadata-separate" data-type="indexterm" id="idm45143403233216"/><a data-primary=".xls files (Microsoft Excel spreadsheets)" data-primary-sortas="xls files" data-secondary="cleaning data" data-startref="xls-clean" data-type="indexterm" id="idm45143403232000"/><a data-primary="spreadsheets" data-secondary=".xls files (Microsoft Excel)" data-secondary-sortas="xls files" data-startref="spreadsheet-xls-clean" data-tertiary="cleaning data" data-type="indexterm" id="idm45143403224032"/>closely in <a data-type="xref" href="ch08.html#chapter8">Chapter 8</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Decrypting Excel Dates" data-type="sect1"><div class="sect1" id="decrypting_excel_dates">&#13;
<h1>Decrypting Excel Dates</h1>&#13;
&#13;
<p>We can <a data-primary=".xls files (Microsoft Excel spreadsheets)" data-primary-sortas="xls files" data-secondary="dates in" data-type="indexterm" id="xls-dates"/><a data-primary="spreadsheets" data-secondary=".xls files (Microsoft Excel)" data-secondary-sortas="xls files" data-tertiary="dates in" data-type="indexterm" id="spreadsheet-xls-dates"/><a data-primary="dates" data-secondary="in .xls files (Microsoft Excel)" data-secondary-sortas="xls files" data-type="indexterm" id="dates-xls"/><a data-primary="numbers library" data-type="indexterm" id="numbers-library"/><a data-primary="Python" data-secondary="numbers library for Excel dates" data-type="indexterm" id="python-numbers"/>avoid the issue of those Excel dates no longer. While hopefully you will not encounter this situation often, I’m including it here for completeness and because it illustrates a few different ways that code tends to evolve—usually getting more complicated and less readable—as we add even seemingly small bits of functionality to it. For example, in <a data-type="xref" href="#xls_meta_and_date_parsing">Example 7-7</a>, we’ll need to check whether a variable contains a number or not, and believe it or not, we need a library for this—it is aptly called <em>numbers</em>. While that part is fundamentally straightforward, you’ll quickly see in <a data-type="xref" href="#xls_meta_and_date_parsing">Example 7-7</a> how the need to transform these date values requires adapting our approach to writing the table-type data to our output file.</p>&#13;
<div data-type="example" id="xls_meta_and_date_parsing">&#13;
<h5><span class="label">Example 7-7. </span>xls_meta_and_date_parsing.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># converting data in an .xls file with Python to csv + metadata file, with</code><code>&#13;
</code><code class="c1"># functional date values using the "xrld" library.</code><code>&#13;
</code><code class="c1"># first, pip install the xlrd library:</code><code>&#13;
</code><code class="c1"># https://pypi.org/project/xlrd/2.0.1/</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># then, import the `xlrd` library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">xlrd</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># import the csv library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">csv</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># needed to test if a given value is *some* type of number</code><code>&#13;
</code><code class="kn">from</code><code> </code><code class="nn">numbers</code><code> </code><code class="kn">import</code><code> </code><code class="n">Number</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># for parsing/formatting our newly interpreted Excel dates</code><code>&#13;
</code><code class="kn">from</code><code> </code><code class="nn">datetime</code><code> </code><code class="kn">import</code><code> </code><code class="n">datetime</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># pass our filename as an ingredient to the `xlrd` library's</code><code>&#13;
</code><code class="c1"># `open_workbook()` "recipe"</code><code>&#13;
</code><code class="c1"># store the result in a variable called `source_workbook`</code><code>&#13;
</code><code class="n">source_workbook</code><code> </code><code class="o">=</code><code> </code><code class="n">xlrd</code><code class="o">.</code><code class="n">open_workbook</code><code class="p">(</code><code class="s2">"</code><code class="s2">fredgraph.xls</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># open and name a simple metadata text file</code><code>&#13;
</code><code class="n">source_workbook_metadata</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s2">"</code><code class="s2">fredgraph_metadata.txt</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">w</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># an `.xls` workbook can have multiple sheets</code><code>&#13;
</code><code class="k">for</code><code> </code><code class="n">sheet_name</code><code> </code><code class="ow">in</code><code> </code><code class="n">source_workbook</code><code class="o">.</code><code class="n">sheet_names</code><code class="p">(</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># create a variable that points to the current worksheet by</code><code>&#13;
</code><code>    </code><code class="c1"># passing the current value of `sheet_name` to the `sheet_by_name` recipe</code><code>&#13;
</code><code>    </code><code class="n">current_sheet</code><code> </code><code class="o">=</code><code> </code><code class="n">source_workbook</code><code class="o">.</code><code class="n">sheet_by_name</code><code class="p">(</code><code class="n">sheet_name</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># create "xls_"+sheet_name+".csv" as an output file for the current sheet</code><code>&#13;
</code><code>    </code><code class="n">output_file</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s2">"</code><code class="s2">xls_</code><code class="s2">"</code><code class="o">+</code><code class="n">sheet_name</code><code class="o">+</code><code class="s2">"</code><code class="s2">_dates.csv</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">w</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># use the `csv` library's "writer" recipe to easily write rows of data</code><code>&#13;
</code><code>    </code><code class="c1"># to `output_file`, instead of reading data *from* it</code><code>&#13;
</code><code>    </code><code class="n">output_writer</code><code> </code><code class="o">=</code><code> </code><code class="n">csv</code><code class="o">.</code><code class="n">writer</code><code class="p">(</code><code class="n">output_file</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># create a Boolean variable to detect if we've hit our table-type data yet</code><code>&#13;
</code><code>    </code><code class="n">is_table_data</code><code> </code><code class="o">=</code><code> </code><code class="bp">False</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># now, we need to loop through every row in our sheet</code><code>&#13;
</code><code>    </code><code class="k">for</code><code> </code><code class="n">row_num</code><code class="p">,</code><code> </code><code class="n">row</code><code> </code><code class="ow">in</code><code> </code><code class="nb">enumerate</code><code class="p">(</code><code class="n">current_sheet</code><code class="o">.</code><code class="n">get_rows</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># pulling out the value in the first column of the current row</code><code>&#13;
</code><code>        </code><code class="n">first_entry</code><code> </code><code class="o">=</code><code> </code><code class="n">current_sheet</code><code class="o">.</code><code class="n">row_values</code><code class="p">(</code><code class="n">row_num</code><code class="p">)</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># if we've hit the header row of our data table</code><code>&#13;
</code><code>        </code><code class="k">if</code><code> </code><code class="n">first_entry</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">observation_date</code><code class="s1">'</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># it's time to switch our "flag" value to "True"</code><code>&#13;
</code><code>            </code><code class="n">is_table_data</code><code> </code><code class="o">=</code><code> </code><code class="bp">True</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># if `is_table_data` is True</code><code>&#13;
</code><code>        </code><code class="k">if</code><code> </code><code class="n">is_table_data</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># extract the table-type data values into separate variables</code><code>&#13;
</code><code>            </code><code class="n">the_date_num</code><code> </code><code class="o">=</code><code> </code><code class="n">current_sheet</code><code class="o">.</code><code class="n">row_values</code><code class="p">(</code><code class="n">row_num</code><code class="p">)</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code>&#13;
</code><code>            </code><code class="n">U6_value</code><code> </code><code class="o">=</code><code> </code><code class="n">current_sheet</code><code class="o">.</code><code class="n">row_values</code><code class="p">(</code><code class="n">row_num</code><code class="p">)</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># create a new row object with each of the values</code><code>&#13;
</code><code>            </code><code class="n">new_row</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">the_date_num</code><code class="p">,</code><code> </code><code class="n">U6_value</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># if the `the_date_num` is a number, then the current row is *not*</code><code>&#13;
</code><code>            </code><code class="c1"># the header row. We need to transform the date.</code><code>&#13;
</code><code>            </code><code class="k">if</code><code> </code><code class="nb">isinstance</code><code class="p">(</code><code class="n">the_date_num</code><code class="p">,</code><code> </code><code class="n">Number</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>                </code><code class="c1"># use the xlrd library's `xldate_as_datetime()` to generate</code><code>&#13;
</code><code>                </code><code class="c1"># a Python datetime object</code><code>&#13;
</code><code>                </code><code class="n">the_date_num</code><code> </code><code class="o">=</code><code> </code><code class="n">xlrd</code><code class="o">.</code><code class="n">xldate</code><code class="o">.</code><code class="n">xldate_as_datetime</code><code class="p">(</code><code>&#13;
</code><code>                    </code><code class="n">the_date_num</code><code class="p">,</code><code> </code><code class="n">source_workbook</code><code class="o">.</code><code class="n">datemode</code><code class="p">)</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO4-1" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO4-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code>                </code><code class="c1"># overwrite the first value in the new row with</code><code>&#13;
</code><code>                </code><code class="c1"># the reformatted date</code><code>&#13;
</code><code>                </code><code class="n">new_row</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">the_date_num</code><code class="o">.</code><code class="n">strftime</code><code class="p">(</code><code class="s1">'</code><code class="si">%m</code><code class="s1">/</code><code class="si">%d</code><code class="s1">/</code><code class="si">%Y</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO4-2" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO4-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># write this new row to the data output file</code><code>&#13;
</code><code>            </code><code class="n">output_writer</code><code class="o">.</code><code class="n">writerow</code><code class="p">(</code><code class="n">new_row</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># otherwise, this row must be metadata</code><code>&#13;
</code><code>        </code><code class="k">else</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># since we'd like our metadata file to be nicely formatted, we</code><code>&#13;
</code><code>            </code><code class="c1"># need to loop through the individual cells of each metadata row</code><code>&#13;
</code><code>            </code><code class="k">for</code><code> </code><code class="n">item</code><code> </code><code class="ow">in</code><code> </code><code class="n">current_sheet</code><code class="o">.</code><code class="n">row</code><code class="p">(</code><code class="n">row_num</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>                    </code><code class="c1"># write the value of the cell</code><code>&#13;
</code><code>                    </code><code class="n">source_workbook_metadata</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">item</code><code class="o">.</code><code class="n">value</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>                    </code><code class="c1"># separate it from the next cell with a tab</code><code>&#13;
</code><code>                    </code><code class="n">source_workbook_metadata</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="s1">'</code><code class="se">\t</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># at the end of each line of metadata, add a newline</code><code>&#13;
</code><code>            </code><code class="n">source_workbook_metadata</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># just for good measure, let's close our output files</code><code>&#13;
</code><code>    </code><code class="n">output_file</code><code class="o">.</code><code class="n">close</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>    </code><code class="n">source_workbook_metadata</code><code class="o">.</code><code class="n">close</code><code class="p">(</code><code class="p">)</code></pre></div>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO4-1" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO4-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Converting these <em>.xls</em> “dates” using the <em>xlrd</em> library’s <code>xldate_as_datetime()</code> method requires both the number value <em>and</em> <a href="https://xlrd.readthedocs.io/en/latest/api.html#xlrd.book.Book.datemode">the workbook’s <code>datemode</code></a> in order to generate the Python datetime object correctly.<sup><a data-type="noteref" href="ch07.html#idm45143403085296" id="idm45143403085296-marker">4</a></sup></p></dd>&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO4-2" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO4-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Here, I’ve decided to write the date to my table-type data file as <code>MM/DD/YYYY</code> using the appropriate <code>strftime()</code> format, but you could use another format if you prefer.</p></dd>&#13;
</dl>&#13;
&#13;
<p>While the <em>xlrd</em> library<a data-primary="xlrd library" data-type="indexterm" id="idm45143403079824"/> makes the process of converting our strange Excel dates to something understandable relatively straightforward, I think the code in <a data-type="xref" href="#xls_meta_and_date_parsing">Example 7-7</a> demonstrates how the idiosyncrasies of wrangling a particular dataset can quickly add complexity—especially in the form of additional, nested <code>if</code> statements—to what started as a very simple program. This is just one of the reasons why we’ll spend <a data-type="xref" href="ch08.html#chapter8">Chapter 8</a> exploring strategies and techniques for effectively and efficiently streamlining our code: we want to make sure it does everything we need but <em>also</em> that it is sufficiently readable and reusable to stand the<a data-primary=".xls files (Microsoft Excel spreadsheets)" data-primary-sortas="xls files" data-secondary="dates in" data-startref="xls-dates" data-type="indexterm" id="idm45143403076000"/><a data-primary="spreadsheets" data-secondary=".xls files (Microsoft Excel)" data-secondary-sortas="xls files" data-startref="spreadsheet-xls-dates" data-tertiary="dates in" data-type="indexterm" id="idm45143403074512"/><a data-primary="dates" data-secondary="in .xls files (Microsoft Excel)" data-secondary-sortas="xls files" data-startref="dates-xls" data-type="indexterm" id="idm45143403072784"/><a data-primary="numbers library" data-startref="numbers-library" data-type="indexterm" id="idm45143403071328"/><a data-primary="Python" data-secondary="numbers library for Excel dates" data-startref="python-numbers" data-type="indexterm" id="idm45143403070384"/> test of time.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Generating True CSVs from Fixed-Width Data" data-type="sect1"><div class="sect1" id="idm45143402366224">&#13;
<h1>Generating True CSVs from Fixed-Width Data</h1>&#13;
&#13;
<p>Another <a data-primary="comma-separated value (.csv) files" data-secondary="converting fixed-width files to" data-type="indexterm" id="comma-separate-fixed-width2"/><a data-primary=".csv files (comma-separated values)" data-primary-sortas="csv files" data-secondary="converting fixed-width files to" data-type="indexterm" id="csv-convert-fixed-width"/><a data-primary="fixed-width files" data-type="indexterm" id="fixed-width-convert"/><a data-primary="data cleaning" data-secondary="converting fixed-width to .csv files" data-type="indexterm" id="data-clean-convert"/><a data-primary="cleaning data" data-secondary="converting fixed-width to .csv files" data-type="indexterm" id="clean-data-convert"/><a data-primary="strip() function" data-type="indexterm" id="strip-function"/><a data-primary="whitespace" data-secondary="stripping" data-type="indexterm" id="whitespace-stripping"/>instance where we also had only moderate success in transforming our data was in <a data-type="xref" href="ch04.html#fixed_width_parsing">Example 4-7</a>, where we converted our fixed-width source data into a <em>.csv</em>. While technically we succeeded in creating an output file that was comma separated, the result was honestly pretty unsatisfactory: it retained many of the formatting artifacts of the original file that could easily stymie our future efforts at data analysis.</p>&#13;
&#13;
<p>Fortunately, the specific problem we encountered—that of “leading” and/or “trailing” whitespace—is very well-known, since the data technologies that typically generate it have been around for a long time. As a result, fixing this problem is pretty simple: the solution exists in the form of the built-in Python <code>strip()</code> function, as illustrated in <a data-type="xref" href="#fixed_width_strip_parsing">Example 7-8</a>.</p>&#13;
<div data-type="example" id="fixed_width_strip_parsing">&#13;
<h5><span class="label">Example 7-8. </span>fixed_width_strip_parsing.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># an example of reading data from a fixed-width file with Python.</code><code>&#13;
</code><code class="c1"># the source file for this example comes from the NOAA and can be accessed here:</code><code>&#13;
</code><code class="c1"># https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt</code><code>&#13;
</code><code class="c1"># the metadata for the file can be found here:</code><code>&#13;
</code><code class="c1"># https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># import the `csv` library, to create our output file</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">csv</code><code>&#13;
</code><code>&#13;
</code><code class="n">filename</code><code> </code><code class="o">=</code><code> </code><code class="s2">"</code><code class="s2">ghcnd-stations</code><code class="s2">"</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># reading from a basic text file doesn't require any special libraries</code><code>&#13;
</code><code class="c1"># so we'll just open the file in read format ("r") as usual</code><code>&#13;
</code><code class="n">source_file</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="n">filename</code><code class="o">+</code><code class="s2">"</code><code class="s2">.txt</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="s2">"</code><code class="s2">r</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># the built-in "readlines()" method does just what you'd think:</code><code>&#13;
</code><code class="c1"># it reads in a text file and converts it to a list of lines</code><code>&#13;
</code><code class="n">stations_list</code><code> </code><code class="o">=</code><code> </code><code class="n">source_file</code><code class="o">.</code><code class="n">readlines</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># create an output file for our transformed data</code><code>&#13;
</code><code class="n">output_file</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="n">filename</code><code class="o">+</code><code class="s2">"</code><code class="s2">.csv</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">w</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># use the `csv` library's "writer" recipe to easily write rows of data</code><code>&#13;
</code><code class="c1"># to `output_file`, instead of reading data *from* it</code><code>&#13;
</code><code class="n">output_writer</code><code> </code><code class="o">=</code><code> </code><code class="n">csv</code><code class="o">.</code><code class="n">writer</code><code class="p">(</code><code class="n">output_file</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># create the header list</code><code>&#13;
</code><code class="n">headers</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s2">"</code><code class="s2">ID</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">LATITUDE</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">LONGITUDE</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">ELEVATION</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">STATE</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">NAME</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">GSN_FLAG</code><code class="s2">"</code><code class="p">,</code><code>&#13;
</code><code>           </code><code class="s2">"</code><code class="s2">HCNCRN_FLAG</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">WMO_ID</code><code class="s2">"</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># write our headers to the output file</code><code>&#13;
</code><code class="n">output_writer</code><code class="o">.</code><code class="n">writerow</code><code class="p">(</code><code class="n">headers</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># loop through each line of our file (multiple "sheets" are not possible)</code><code>&#13;
</code><code class="k">for</code><code> </code><code class="n">line</code><code> </code><code class="ow">in</code><code> </code><code class="n">stations_list</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># create an empty list, to which we'll append each set of characters that</code><code>&#13;
</code><code>    </code><code class="c1"># makes up a given "column" of data</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># ID: positions 1-11</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="n">line</code><code class="p">[</code><code class="mi">0</code><code class="p">:</code><code class="mi">11</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">strip</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO5-1" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO5-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># LATITUDE: positions 13-20</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="n">line</code><code class="p">[</code><code class="mi">12</code><code class="p">:</code><code class="mi">20</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">strip</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># LONGITUDE: positions 22-30</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="n">line</code><code class="p">[</code><code class="mi">21</code><code class="p">:</code><code class="mi">30</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">strip</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># ELEVATION: positions 32-37</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="n">line</code><code class="p">[</code><code class="mi">31</code><code class="p">:</code><code class="mi">37</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">strip</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># STATE: positions 39-40</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="n">line</code><code class="p">[</code><code class="mi">38</code><code class="p">:</code><code class="mi">40</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">strip</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># NAME: positions 42-71</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="n">line</code><code class="p">[</code><code class="mi">41</code><code class="p">:</code><code class="mi">71</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">strip</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># GSN_FLAG: positions 73-75</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="n">line</code><code class="p">[</code><code class="mi">72</code><code class="p">:</code><code class="mi">75</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">strip</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># HCNCRN_FLAG: positions 77-79</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="n">line</code><code class="p">[</code><code class="mi">76</code><code class="p">:</code><code class="mi">79</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">strip</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># WMO_ID: positions 81-85</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="n">line</code><code class="p">[</code><code class="mi">80</code><code class="p">:</code><code class="mi">85</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">strip</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># now all that's left is to use the</code><code>&#13;
</code><code>    </code><code class="c1"># `writerow` function to write new_row to our output file</code><code>&#13;
</code><code>    </code><code class="n">output_writer</code><code class="o">.</code><code class="n">writerow</code><code class="p">(</code><code class="n">new_row</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># just for good measure, let's close the `.csv` file we just created</code><code>&#13;
</code><code class="n">output_file</code><code class="o">.</code><code class="n">close</code><code class="p">(</code><code class="p">)</code></pre></div>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO5-1" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO5-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>If you compare this code with the code in <a data-type="xref" href="ch04.html#fixed_width_parsing">Example 4-7</a>, you’ll see that it’s identical apart from our having applied the <code>strip()</code> method to each string before appending it to our data row.</p></dd>&#13;
</dl>&#13;
&#13;
<p>Once again, we see that modifying our original code to solve a formatting or “cleaning” issue isn’t necessarily that hard, but the resulting script isn’t <em>exactly</em> elegant, either. Stripping the whitespace from our output with the <code>strip()</code> method is definitely straightforward, but we’ve had to add a whole lot of parentheses in the process—leaving us with code that is far less readable than we’d like.</p>&#13;
&#13;
<p>This illustrates yet another way in which creating good, quality Python code mirrors more typical writing processes. If we view our first efforts in <a data-type="xref" href="ch04.html#chapter4">Chapter 4</a> as something like the “outline” of our final program—where we solve the high-level problem of getting the data format we have into at least the table-type <em>structure</em> that we’re after—it gives us space to come back later and revise that work, filling in the details that allow it to be more nuanced in its handling of the specific dataset we’re working with.</p>&#13;
&#13;
<p>Similarly, in <a data-type="xref" href="ch08.html#chapter8">Chapter 8</a> we’ll take that revision process one step further, refining these programs—which already do everything we need them to do—so that they are more concise and easier to understand, just as we might do with any piece of writing. This iterative approach to programming not only means that we eventually end up with better, more useful code; it also helps us break down big, complicated programming problems into a series of less intimidating ones that we can solve one step at a time. Equally important, no matter what stage of the process we’re in, we have a functioning program we can fall back on if needed. This incremental approach is especially useful when we take on more complex data-cleaning tasks like the one we’ll look at next: resolving the unintentional <a data-primary="comma-separated value (.csv) files" data-secondary="converting fixed-width files to" data-startref="comma-separate-fixed-width2" data-type="indexterm" id="idm45143401866176"/><a data-primary=".csv files (comma-separated values)" data-primary-sortas="csv files" data-secondary="converting fixed-width files to" data-startref="csv-convert-fixed-width" data-type="indexterm" id="idm45143401864880"/><a data-primary="fixed-width files" data-startref="fixed-width-convert" data-type="indexterm" id="idm45143402279968"/><a data-primary="data cleaning" data-secondary="converting fixed-width to .csv files" data-startref="data-clean-convert" data-type="indexterm" id="idm45143402279024"/><a data-primary="cleaning data" data-secondary="converting fixed-width to .csv files" data-startref="clean-data-convert" data-type="indexterm" id="idm45143401852176"/><a data-primary="strip() function" data-startref="strip-function" data-type="indexterm" id="idm45143401850944"/><a data-primary="whitespace" data-secondary="stripping" data-startref="whitespace-stripping" data-type="indexterm" id="idm45143401850000"/>spelling differences.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Correcting for Spelling Inconsistencies" data-type="sect1"><div class="sect1" id="correcting_inconsistencies">&#13;
<h1>Correcting for Spelling Inconsistencies</h1>&#13;
&#13;
<p>In <a data-type="xref" href="ch06.html#chapter6">Chapter 6</a>, we <a data-primary="data cleaning" data-secondary="spelling inconsistencies" data-type="indexterm" id="data-clean-spelling"/><a data-primary="cleaning data" data-secondary="spelling inconsistencies" data-type="indexterm" id="clean-data-spelling"/><a data-primary="spelling inconsistencies, fixing" data-type="indexterm" id="spelling-fix"/><a data-primary="data transformation" data-type="indexterm" id="data-transform"/><a data-primary="transforming data" data-type="indexterm" id="transform-data"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="spelling inconsistencies" data-type="indexterm" id="ppp-spelling"/><a data-primary="fingerprinting" data-type="indexterm" id="fingerprinting-spelling"/>used a “fingerprinting” process to help address the possibility that information about banks in our Paycheck Protection Program (PPP) data might have spelling inconsistencies—a common issue in <em>any</em> dataset that relies on human data entry. Of course, the code we wrote in <a data-type="xref" href="ch06.html#ppp_lender_names">Example 6-11</a> only estimated the number of genuinely unique entries in the <code>OriginatingLender</code> column by counting how many of them resulted in a distinct fingerprint. We found that our dataset contained 4,337 unique bank names but only 4,242 unique fingerprints—an indicator that as many as 95 bank names might actually <em>be</em> the same but contain typos because they generated the same fingerprint.</p>&#13;
&#13;
<p>Because those 95 potential typos could affect thousands of rows of data, we need a way to transform our dataset so that we can confidently aggregate it by lender. At the same time, we also don’t want to <em>overcorrect</em> by grouping together entries that don’t actually belong together.</p>&#13;
&#13;
<p>This is an instance where <em>transforming</em> our data is invaluable: we don’t want to risk losing any of our original data (retaining it is essential for validation and spot-checking), but we <em>also</em> need to transform it in order to support our future analysis efforts. Because our dataset is large, grouping and filtering it to meet our needs is likely to be time-consuming, so we want to preserve the results of that work by actually <em>adding</em> new columns to the dataset. This lets us both preserve our original data <em>and</em> the benefits of our transformation work in a single file.</p>&#13;
&#13;
<p>Fortunately, we’ve got some go-to libraries that will make this process pretty straightforward. Since we already know how to aggregate names using the fingerprinting process from <a data-type="xref" href="ch06.html#ppp_lender_names">Example 6-11</a>, the trickier piece may be determining when banks that share the same fingerprint should actually be treated as distinct organizations. Looking back at the output from <a data-type="xref" href="ch06.html#ppp_columns_review">Example 6-7</a> (reproduced in <a data-type="xref" href="#transposed_sample_recent_again">Example 7-9</a> for convenience), we see that there are not a lot of fields that contain “originating” lender information, so our most likely option for deciding if two originating banks whose names share all the same words (and will therefore have the same fingerprint, e.g., “First Bank Texas” and “Texas First Bank”) will be to compare the value included in <code>OriginatingLenderLocationID</code>.</p>&#13;
<div data-type="example" id="transposed_sample_recent_again">&#13;
<h5><span class="label">Example 7-9. </span>Recent sample data transposed</h5>&#13;
&#13;
<pre data-type="programlisting">LoanNumber                                          9547507704&#13;
DateApproved                                        05/01/2020&#13;
SBAOfficeCode                                              464&#13;
ProcessingMethod                                           PPP&#13;
BorrowerName                             SUMTER COATINGS, INC.&#13;
BorrowerAddress                          2410 Highway 15 South&#13;
BorrowerCity                                            Sumter&#13;
BorrowerState                                             &lt;NA&gt;&#13;
BorrowerZip                                         29150-9662&#13;
LoanStatusDate                                      12/18/2020&#13;
LoanStatus                                        Paid in Full&#13;
Term                                                        24&#13;
SBAGuarantyPercentage                                      100&#13;
InitialApprovalAmount                                769358.78&#13;
CurrentApprovalAmount                                769358.78&#13;
UndisbursedAmount                                            0&#13;
FranchiseName                                             &lt;NA&gt;&#13;
ServicingLenderLocationID                                19248&#13;
ServicingLenderName                               Synovus Bank&#13;
ServicingLenderAddress                           1148 Broadway&#13;
ServicingLenderCity                                   COLUMBUS&#13;
ServicingLenderState                                        GA&#13;
ServicingLenderZip                                  31901-2429&#13;
RuralUrbanIndicator                                          U&#13;
HubzoneIndicator                                             N&#13;
LMIIndicator                                              &lt;NA&gt;&#13;
BusinessAgeDescription       Existing or more than 2 years old&#13;
ProjectCity                                             Sumter&#13;
ProjectCountyName                                       SUMTER&#13;
ProjectState                                                SC&#13;
ProjectZip                                          29150-9662&#13;
CD                                                       SC-05&#13;
JobsReported                                                62&#13;
NAICSCode                                               325510&#13;
RaceEthnicity                                       Unanswered&#13;
UTILITIES_PROCEED                                         &lt;NA&gt;&#13;
PAYROLL_PROCEED                                      769358.78&#13;
MORTGAGE_INTEREST_PROCEED                                 &lt;NA&gt;&#13;
RENT_PROCEED                                              &lt;NA&gt;&#13;
REFINANCE_EIDL_PROCEED                                    &lt;NA&gt;&#13;
HEALTH_CARE_PROCEED                                       &lt;NA&gt;&#13;
DEBT_INTEREST_PROCEED                                     &lt;NA&gt;&#13;
BusinessType                                       Corporation&#13;
OriginatingLenderLocationID                              19248&#13;
OriginatingLender                                 Synovus Bank&#13;
OriginatingLenderCity                                 COLUMBUS&#13;
OriginatingLenderState                                      GA&#13;
Gender                                              Unanswered&#13;
Veteran                                             Unanswered&#13;
NonProfit                                                 &lt;NA&gt;</pre></div>&#13;
&#13;
<p>Before we proceed, of course, we want to make sure that we understand what the data in <code>OriginatingLenderLocationID</code> actually <em>means</em>. Lucky for us, a web search for the words “originating lender location id” brings up <a href="https://sba.gov/sites/default/files/articles/ETran_Origination_01_2014.pdf">yet another document from the SBA website</a> as the first result. Searching through this PDF for the term “location” brings us to the page shown in <a data-type="xref" href="#ppp_lender_location_info">Figure 7-2</a>, which reassures us that the “Location ID” value entered should not change from branch to branch of the same bank but indicates the <em>main</em> branch of a given bank.</p>&#13;
&#13;
<figure><div class="figure" id="ppp_lender_location_info">&#13;
<img alt="Information about lender location ID" src="assets/ppdw_0702.png"/>&#13;
<h6><span class="label">Figure 7-2. </span>Information about lender location ID</h6>&#13;
</div></figure>&#13;
&#13;
<p>With this additional information, we can go about creating a version of our PPP loan data that includes a new column, <code>OriginatingLenderFingerprint</code>, that contains a combination of the <code>OriginatingLender</code> fingerprint and the <code>OriginatingLenderLocationID</code>, as shown in <a data-type="xref" href="#ppp_add_fingerprints">Example 7-10</a>. Later on, we can then use this value to quickly aggregate our data by originating lender while being (reasonably) confident that we are neither failing to match entries due to typos <em>nor</em> treating what should be two separate banks as one.</p>&#13;
<div data-type="example" id="ppp_add_fingerprints">&#13;
<h5><span class="label">Example 7-10. </span>ppp_add_fingerprints.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for adding a "fingerprint" column to our loan data, which will</code><code>&#13;
</code><code class="c1"># help us confirm/correct for any typos or inconsistencies in, e.g., bank names</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># import the csv library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">csv</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># importing the `fingerprints` library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">fingerprints</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># read the recent data sample into a variable</code><code>&#13;
</code><code class="n">ppp_data</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s1">'</code><code class="s1">public_150k_plus_recent.csv</code><code class="s1">'</code><code class="p">,</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># the DictReader function makes our source data more usable</code><code>&#13;
</code><code class="n">ppp_data_reader</code><code> </code><code class="o">=</code><code> </code><code class="n">csv</code><code class="o">.</code><code class="n">DictReader</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># create an output file to write our modified dataset to</code><code>&#13;
</code><code class="n">augmented_ppp_data</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s1">'</code><code class="s1">public_150k_plus_fingerprints.csv</code><code class="s1">'</code><code class="p">,</code><code class="s1">'</code><code class="s1">w</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># create a "writer" so that we can output whole rows at once</code><code>&#13;
</code><code class="n">augmented_data_writer</code><code> </code><code class="o">=</code><code> </code><code class="n">csv</code><code class="o">.</code><code class="n">writer</code><code class="p">(</code><code class="n">augmented_ppp_data</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># because we're adding a column, we need to create a new header row as well</code><code>&#13;
</code><code class="n">header_row</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># for every column header</code><code>&#13;
</code><code class="k">for</code><code> </code><code class="n">item</code><code> </code><code class="ow">in</code><code> </code><code class="n">ppp_data_reader</code><code class="o">.</code><code class="n">fieldnames</code><code class="p">:</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO6-1" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO6-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># append the existing column header</code><code>&#13;
</code><code>    </code><code class="n">header_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">item</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># if we're at 'OriginatingLender'</code><code>&#13;
</code><code>    </code><code class="k">if</code><code> </code><code class="n">item</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">OriginatingLender</code><code class="s1">'</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># it's time to add a new column</code><code>&#13;
</code><code>        </code><code class="n">header_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="s1">'</code><code class="s1">OriginatingLenderFingerprint</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># now we can write our expanded header row to the output file</code><code>&#13;
</code><code class="n">augmented_data_writer</code><code class="o">.</code><code class="n">writerow</code><code class="p">(</code><code class="n">header_row</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># iterate through every row in our data</code><code>&#13;
</code><code class="k">for</code><code> </code><code class="n">row</code><code> </code><code class="ow">in</code><code> </code><code class="n">ppp_data_reader</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># create an empty list to hold our new data row</code><code>&#13;
</code><code>    </code><code class="n">new_row</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO6-2" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO6-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># for each column of data in the *original* dataset</code><code>&#13;
</code><code>    </code><code class="k">for</code><code> </code><code class="n">column_name</code><code> </code><code class="ow">in</code><code> </code><code class="n">ppp_data_reader</code><code class="o">.</code><code class="n">fieldnames</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># first, append this row's value for that column</code><code>&#13;
</code><code>        </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">row</code><code class="p">[</code><code class="n">column_name</code><code class="p">]</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="c1"># when we get to the 'OriginatingLender' column, it's time</code><code>&#13;
</code><code>        </code><code class="c1"># to add our new "fingerprint" value</code><code>&#13;
</code><code>        </code><code class="k">if</code><code> </code><code class="n">column_name</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">OriginatingLender</code><code class="s1">'</code><code class="p">:</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># our fingerprint will consist of the generated fingerprint PLUS</code><code>&#13;
</code><code>            </code><code class="c1"># the OriginatingLenderLocationID</code><code>&#13;
</code><code>            </code><code class="n">the_fingerprint</code><code> </code><code class="o">=</code><code> </code><code class="n">fingerprints</code><code class="o">.</code><code class="n">generate</code><code class="p">(</code><code class="n">row</code><code class="p">[</code><code class="n">column_name</code><code class="p">]</code><code class="p">)</code><code> </code><code class="o">+</code><code> </code><code>\&#13;
</code><code>                              </code><code class="s2">"</code><code class="s2"> </code><code class="s2">"</code><code> </code><code class="o">+</code><code> </code><code class="n">row</code><code class="p">[</code><code class="s1">'</code><code class="s1">OriginatingLenderLocationID</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>            </code><code class="c1"># append the compound fingerprint value to our row</code><code>&#13;
</code><code>            </code><code class="n">new_row</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">the_fingerprint</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>    </code><code class="c1"># once the whole row is complete, write it to our output file</code><code>&#13;
</code><code>    </code><code class="n">augmented_data_writer</code><code class="o">.</code><code class="n">writerow</code><code class="p">(</code><code class="n">new_row</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># close both files</code><code>&#13;
</code><code class="n">augmented_ppp_data</code><code class="o">.</code><code class="n">close</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code class="n">ppp_data</code><code class="o">.</code><code class="n">close</code><code class="p">(</code><code class="p">)</code></pre></div>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO6-1" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO6-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>While it may seem excessive, this first loop actually exists <em>only</em> to create our new header row. As always, we want to avoid introducing typos whenever and wherever possible, so in this instance, the whole extra loop is worth it (<em>way</em> better than typing out this list by hand).</p></dd>&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO6-2" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO6-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Since we’re adding a column of data, we need to build the new data row as a list, item by item—just as we did with the header row.</p></dd>&#13;
</dl>&#13;
&#13;
<p>The structure of the resulting file is the same as the original, except that a new &#13;
<span class="keep-together"><code>OriginatingLenderFingerprint</code></span> column has now been added between &#13;
<span class="keep-together"><code>OriginatingLender</code></span> and <code>OriginatingLenderCity</code>, as you can see in <a data-type="xref" href="#ppp_data_w_fingerprints">Example 7-11</a>.</p>&#13;
<div data-type="example" id="ppp_data_w_fingerprints">&#13;
<h5><span class="label">Example 7-11. </span>PPP data with fingerprints</h5>&#13;
&#13;
<pre data-type="programlisting">LoanNumber                                           9547507704&#13;
DateApproved                                         05/01/2020&#13;
SBAOfficeCode                                               464&#13;
ProcessingMethod                                            PPP&#13;
BorrowerName                              SUMTER COATINGS, INC.&#13;
BorrowerAddress                           2410 Highway 15 South&#13;
BorrowerCity                                             Sumter&#13;
BorrowerState                                               NaN&#13;
BorrowerZip                                          29150-9662&#13;
LoanStatusDate                                       12/18/2020&#13;
LoanStatus                                         Paid in Full&#13;
Term                                                         24&#13;
SBAGuarantyPercentage                                       100&#13;
InitialApprovalAmount                                 769358.78&#13;
CurrentApprovalAmount                                 769358.78&#13;
UndisbursedAmount                                           0.0&#13;
FranchiseName                                               NaN&#13;
ServicingLenderLocationID                                 19248&#13;
ServicingLenderName                                Synovus Bank&#13;
ServicingLenderAddress                            1148 Broadway&#13;
ServicingLenderCity                                    COLUMBUS&#13;
ServicingLenderState                                         GA&#13;
ServicingLenderZip                                   31901-2429&#13;
RuralUrbanIndicator                                           U&#13;
HubzoneIndicator                                              N&#13;
LMIIndicator                                                NaN&#13;
BusinessAgeDescription        Existing or more than 2 years old&#13;
ProjectCity                                              Sumter&#13;
ProjectCountyName                                        SUMTER&#13;
ProjectState                                                 SC&#13;
ProjectZip                                           29150-9662&#13;
CD                                                        SC-05&#13;
JobsReported                                               62.0&#13;
NAICSCode                                              325510.0&#13;
RaceEthnicity                                        Unanswered&#13;
UTILITIES_PROCEED                                           NaN&#13;
PAYROLL_PROCEED                                       769358.78&#13;
MORTGAGE_INTEREST_PROCEED                                   NaN&#13;
RENT_PROCEED                                                NaN&#13;
REFINANCE_EIDL_PROCEED                                      NaN&#13;
HEALTH_CARE_PROCEED                                         NaN&#13;
DEBT_INTEREST_PROCEED                                       NaN&#13;
BusinessType                                        Corporation&#13;
OriginatingLenderLocationID                               19248&#13;
OriginatingLender                                  Synovus Bank&#13;
OriginatingLenderFingerprint                 bank synovus 19248&#13;
OriginatingLenderCity                                  COLUMBUS&#13;
OriginatingLenderState                                       GA&#13;
Gender                                               Unanswered&#13;
Veteran                                              Unanswered&#13;
NonProfit                                                   NaN</pre></div>&#13;
&#13;
<p>While this transformation will help us easily aggregate our data by a particular “originating” lender, we could quickly duplicate it with the “servicing” lender as well. We could <em>even</em> write a script that compares the value of these two resulting fingerprints to create a “flag” column indicating whether the servicing and originating banks for a particular loan<a data-primary="data cleaning" data-secondary="spelling inconsistencies" data-startref="data-clean-spelling" data-type="indexterm" id="idm45143401993504"/><a data-primary="cleaning data" data-secondary="spelling inconsistencies" data-startref="clean-data-spelling" data-type="indexterm" id="idm45143401992240"/><a data-primary="spelling inconsistencies, fixing" data-startref="spelling-fix" data-type="indexterm" id="idm45143401991008"/><a data-primary="data transformation" data-startref="data-transform" data-type="indexterm" id="idm45143402999008"/><a data-primary="transforming data" data-startref="transform-data" data-type="indexterm" id="idm45143402998064"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="spelling inconsistencies" data-startref="ppp-spelling" data-type="indexterm" id="idm45143402997120"/><a data-primary="fingerprinting" data-startref="fingerprinting-spelling" data-type="indexterm" id="idm45143402972560"/> are the same.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Circuitous Path to “Simple” Solutions" data-type="sect1"><div class="sect1" id="not_so_fast">&#13;
<h1>The Circuitous Path to “Simple” Solutions</h1>&#13;
&#13;
<p>While I <a data-primary="data cleaning" data-secondary="problem-solving approaches" data-type="indexterm" id="data-clean-problem-solve"/><a data-primary="cleaning data" data-secondary="problem-solving approaches" data-type="indexterm" id="clean-data-problem-solve"/><a data-primary="data wrangling" data-secondary="problem-solving approaches" data-type="indexterm" id="data-wrangling-problem-solve"/><a data-primary="problem-solving approaches" data-type="indexterm" id="problem-solving-approach"/>hope that you found the <a data-type="xref" href="#ppp_add_fingerprints">Example 7-10</a> exercise simple to follow, I want you know that the preceding script was <em>not</em> the first solution I tried—it wasn’t even the second or third. In fact, I probably spent about a dozen hours, all told, thinking, hacking, wrangling, and failing before I <em>finally</em> realized  that my eventual approach to the problem was the fastest, simplest, and most effective way to strike a balance between making sure that loans from the same bank were grouped together without accidentally conflating two different institutions.</p>&#13;
&#13;
<p>I’m going to describe how I actually worked my way through this process because—as is hopefully <em>also</em> starting to become clear—data wrangling (and programming in general) is not so much about coding as it is about reasoning and problem-solving. This means that thinking through the problem in front of you, trying different solutions, and, perhaps most importantly, being willing to change course even if it feels like “throwing out” a bunch of work are <em>all</em> much more important to data wrangling than being able to write more than two lines of Python code from memory.<sup><a data-type="noteref" href="ch07.html#idm45143403010368" id="idm45143403010368-marker">5</a></sup> So in an effort to illustrate what just one of these problem-solving efforts entails, I’m going &#13;
<span class="keep-together">to (comparatively)</span> briefly give you an overview here of the different approaches I &#13;
<span class="keep-together">tried before</span> settling on the solution in <a data-type="xref" href="#correcting_inconsistencies">“Correcting for Spelling Inconsistencies”</a>.</p>&#13;
&#13;
<p>At first, I started out by minimally adapting the script from <a data-type="xref" href="ch06.html#ppp_lender_names">Example 6-11</a>, creating a new column that contained <em>just</em> those fingerprints and writing a new CSV that added this new column. But I realized that there was a strong likelihood that some banks with similar names would share the same “fingerprint,” so I wrote a script that did the following:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Created a list of the unique fingerprints.</p>&#13;
</li>&#13;
<li>&#13;
<p>For every unique fingerprint, created a new list (actually a <code>pandas</code> DataFrame) of all the unique <code>OriginatingLenderLocationID</code> values.</p>&#13;
</li>&#13;
<li>&#13;
<p>If there was more than one distinct <code>OriginatingLenderLocationID</code> value, I then <em>updated</em> the “fingerprint” column to incorporate the <code>OriginatingLenderLocationID</code>, much as we ended up doing for <em>all</em> the entries in <a data-type="xref" href="#ppp_add_fingerprints">Example 7-10</a>.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>Even creating <em>that</em> script, however, was much more involved than this numbered synopsis would make it seem. The first step was easy, of course—we’d pretty much done that already. But when it came time to working with the new file in <code>pandas</code>, my scrappy little Chromebook didn’t have enough memory, so I moved my work to Google Colab. This gave me more memory to work with (sort of), but now every time I stepped away for more than a few minutes, I had to authenticate and reload the data from my Google Drive file all over again—that took an additional couple of minutes every time. Also, while I was <em>pretty</em> confident that I had figured out how to update the values in my DataFrame correctly, attempting to check my work by searching for a new fingerprint that I was sure should exist wasn’t working reliably: sometimes I got matches, and sometimes I got an empty DataFrame! Add to this that it took about 3 or more minutes to run step 3 each time, and you can imagine how many hours (and how much frustration!) it took to be sure my code actually worked as intended.</p>&#13;
&#13;
<p>Of course, once I had managed to code up (and check) that multistep solution, I realized that the result wasn’t all that different from what I’d started with. In fact, it was a little <em>less</em> satisfying because now the format of my new <code>OriginatingLenderFingerprint</code> column was inconsistent: some had the <code>OriginatingLenderLocationID</code> appended, some didn’t. But since the actual <em>value</em> of the fingerprint didn’t matter—only that it could be used accurately to both aggregate and disambiguate banks—why was I going to all the trouble of only adding location IDs to the ones that had several entries? Couldn’t they <em>all</em> just have the location IDs appended?</p>&#13;
&#13;
<p>Well, of course it was only at <em>that</em> point that I bothered to look up the documentation shown in <a data-type="xref" href="#ppp_lender_location_info">Figure 7-2</a>, which confirmed that adding location IDs wouldn’t break up fingerprints that should be the same.<sup><a data-type="noteref" href="ch07.html#idm45143402992928" id="idm45143402992928-marker">6</a></sup> And that’s how I came full circle: rather than assigning potentially overlapping fingerprints and then trying to “weed out” the problems with an awkward and time-consuming search process, the best solution was just to make the <code>OriginatingLenderLocationID</code> part of the new “fingerprint” column right from the start.</p>&#13;
&#13;
<p>Having spent hours working out how to “fix” the original fingerprints—and in the process, contending with the limits of my device, the vagaries of Google Colab, and the tedium of making a small change to a script and then having to wait several minutes for it to run—I won’t pretend that it didn’t feel like a bit of a letdown to realize that the best solution really just involved a small tweak on my original script (though not the one I had started with).</p>&#13;
&#13;
<p>But if there’s one thing that I’ve learned after years of data wrangling, it’s that learning when to let go and start over (or go back to the beginning) is one of the most important skills you can develop. Sometimes you have to let go of a dataset, even if you’ve sunk hours into researching, evaluating, and cleaning it. Likewise, sometimes you have to let go of a programming approach, even if you’ve spent hours reading documentation and experimenting with new methods just to get the result you’re after. Because in the end, the goal is <em>not</em> to use a particular dataset, or to use a particular library or coding method. <em>It’s to use data to understand something about the world.</em> And if you can keep your focus on that, letting go when you need to will be much easier.</p>&#13;
&#13;
<p>You will also probably find it easier to accept this process—whether it involves letting go of a dataset or a scripting solution you’ve already spent hours on—when you start to experience firsthand that you have learned something valuable even from something you eventually “abandon.” Before my detour into “fixing” my original, text-only fingerprints, for example, I didn’t really know how to update values within a <code>pandas</code> DataFrame; now I do (I <em>really</em> do). I also now know a bit more about Google Colab’s strengths and inconsistencies and was reminded about some key “gotchas” to working with diverse datasets (more on that in the next section).</p>&#13;
&#13;
<p>The same goes for datasets that might not turn out to be usable for answering a particular question: just because they aren’t right for your current project doesn’t mean they might not be for another one. But whether or not you ever look at them again, working with those datasets will teach you so many things: about the subject of the data, about the pitfalls and possibilities of certain data types, about experts on the topic, and more. In other words, letting go of a dataset or a coding approach is <em>never</em> a “waste”: the experience you gain will only make your next effort better, if <a data-primary="data cleaning" data-secondary="problem-solving approaches" data-startref="data-clean-problem-solve" data-type="indexterm" id="idm45143402890528"/><a data-primary="cleaning data" data-secondary="problem-solving approaches" data-startref="clean-data-problem-solve" data-type="indexterm" id="idm45143402889200"/><a data-primary="data wrangling" data-secondary="problem-solving approaches" data-startref="data-wrangling-problem-solve" data-type="indexterm" id="idm45143402887952"/><a data-primary="problem-solving approaches" data-startref="problem-solving-approach" data-type="indexterm" id="idm45143402886704"/>you let it.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Gotchas That Will Get Ya!" data-type="sect1"><div class="sect1" id="gotchas">&#13;
<h1>Gotchas That Will Get Ya!</h1>&#13;
&#13;
<p>One of the <a data-primary="Python" data-secondary="errors" data-tertiary="common" data-type="indexterm" id="python-errors-common"/><a data-primary="errors" data-secondary="common" data-type="indexterm" id="errors-common"/><a data-primary="data wrangling" data-secondary="common errors" data-type="indexterm" id="data-wrangling-errors"/>reasons why it is so important to document your work is that very often the person you’re writing that documentation for is really just “future you,” who may be returning to a particular dataset or script—or even Python altogether—after days, weeks, or months away. In that time, things that were once obvious will seem confusing and obscure unless you document them thoroughly, and even common “lessons” can get overlooked when you’re in a hurry or focused on something else. I had that experience myself as I worked through the exercises in the last few chapters, especially as I made an effort to check my own work. For me, that experience was just another reminder that when something’s wrong with your script, it’s usually something simple ;-)</p>&#13;
&#13;
<p>Here are some common gotchas to keep in mind:</p>&#13;
<dl>&#13;
<dt class="horizontal">Confirm the case</dt>&#13;
<dd>&#13;
<p>Anytime you are checking to see if two strings are the same, remember that capitalization matters! When I was working on <a data-type="xref" href="ch06.html#ppp_find_waterford">Example 6-16</a>, I at first overlooked that all of the business names (but not the bank names!) were in all caps. I had a frustrating few minutes thinking that my dataset did <em>not</em> contain the <code>WATERFORD RECEPTIONS</code> example, until I finally looked at the data again and realized my error.</p>&#13;
</dd>&#13;
<dt class="horizontal">Insist on the data type</dt>&#13;
<dd>&#13;
<p>As I worked my way through the process described in <a data-type="xref" href="#not_so_fast">“The Circuitous Path to “Simple” Solutions”</a>, I once <a data-primary="data types" data-secondary="common errors" data-type="indexterm" id="idm45143402872304"/>again had trouble finding matches for values that I felt certain should be in the dataset. I had forgotten, however, that the <em>pandas</em> library (unlike the <em>csv</em> library) actually tries to apply data types to &#13;
<span class="keep-together">the columns</span> of data it reads into a DataFrame. In this case, that meant that &#13;
<span class="keep-together"><code>OriginatingLenderLocationID</code></span> became a number (instead of a string), so my efforts to find particular values for that column were failing because I was trying to match, for example, the number <code>71453</code> to the string <code>"71453"</code>—which definitely doesn’t work!</p>&#13;
&#13;
<p>In that instance, I found the simplest solution was simply to add a parameter to the <code>read_csv()</code> function call, specifying that all the data should be read as strings (e.g., <code>fingerprinted_data1 = pd.read_csv('public_150k_plus_fingerprints.csv', dtype='string')</code>).<sup><a data-type="noteref" href="ch07.html#idm45143402866320" id="idm45143402866320-marker">7</a></sup> This also prevented some of the larger dollar amounts in the data from being converted to scientific notation (e.g., <code>1.21068e+06</code> rather than <code>1210681</code>).</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>After basic typos, the sort of data-type “gotchas” described here are probably the next most common data wrangling “errors” you’re likely to encounter. So if you find you’ve made an oversight like these at some point, try not to be too frustrated. It’s really just a sign that your programming logic is good and some of your formatting needs to <a data-primary="Python" data-secondary="errors" data-startref="python-errors-common" data-tertiary="common" data-type="indexterm" id="idm45143402861616"/><a data-primary="errors" data-secondary="common" data-startref="errors-common" data-type="indexterm" id="idm45143402860096"/><a data-primary="data wrangling" data-secondary="common errors" data-startref="data-wrangling-errors" data-type="indexterm" id="idm45143402858880"/>be fixed.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Augmenting Your Data" data-type="sect1"><div class="sect1" id="augmenting_data">&#13;
<h1>Augmenting Your Data</h1>&#13;
&#13;
<p>Adding<a data-primary="augmenting data" data-type="indexterm" id="augment-data2"/><a data-primary="data augmentation" data-type="indexterm" id="data-augment2"/><a data-primary="data quality" data-secondary="improving" data-tertiary="augmenting" data-type="indexterm" id="data-quality-improve-augment2"/><a data-primary="improving data quality" data-secondary="augmenting" data-type="indexterm" id="improve-data-quality-augment2"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="augmenting data" data-type="indexterm" id="ppp-augment"/> the <code>OriginatingLenderFingerprint</code> column in <a data-type="xref" href="#ppp_add_fingerprints">Example 7-10</a> was a valuable way to increase the utility and usability of the PPP loan data, but another good way to add value to a dataset is to look for <em>other</em> datasets that you can use to augment it. This is usually easiest when the dataset is <em>dimensionally structured</em>, in that it already references a widely used standard of some kind. In the case of our PPP loan data, we have an example of this in the column called <code>NAICSCode</code>, which a quick web search<sup><a data-type="noteref" href="ch07.html#idm45143402846432" id="idm45143402846432-marker">8</a></sup> confirms is the:</p>&#13;
<blockquote>&#13;
<p>…North American Industry Classification System. The NAICS System was developed for use by Federal Statistical Agencies for the collection, analysis and publication of statistical data related to the US Economy.</p></blockquote>&#13;
&#13;
<p>Given this, we can probably find a way to augment our data by adding more information about the NAICS code for each entry, which might, for example, help us understand more about what industries and types of businesses are participating in the PPP loan program. While we could probably pull a comprehensive list of NAICS codes from the main website, a web search for <code>naics sba</code> brings up some interesting options. Specifically, the SBA offers a PDF that provides <a href="https://sba.gov/sites/default/files/2019-08/SBA%20Table%20of%20Size%20Standards_Effective%20Aug%2019%2C%202019.pdf">information about Small Business Administration size guidelines for businesses by NAICS code</a>, in either millions of dollars or number of employees. In addition to providing us with more human-readable descriptions of the NAICS codes themselves, augmenting our PPP loan data with this additional information can help us answer more general questions about what actually qualifies as a “small business.”</p>&#13;
&#13;
<p>Our process for this won’t be too much different from data merges we’ve done previously, both in the process we’ll follow <em>and</em> the issues it introduces. To start off with, we’ll look for a non-PDF version of the SBA size guidelines. Clicking on the “SBA’s Size Standards Webpage” link on the first page of the PDF brings us to a more <a href="https://sba.gov/federal-contracting/contracting-guide/size-standards">general page on the SBA website</a>, where in the “Numerical Requirements” section we find a link labeled <a href="https://sba.gov/document/support-object-object-table-size-standards">“table of small business size standards”</a>. Scrolling down that page turns up a downloadable <a href="https://sba.gov/sites/default/files/2019-08/SBA%20Table%20of%20Size%20Standards_Effective%20Aug%2019%2C%202019.xlsx">XLSX version</a> of the earlier PDF document. From there, we can export the second sheet (which contains the actual codes and descriptions) as a CSV file. Now, we can import and match this with our PPP loan data.</p>&#13;
&#13;
<p>As you’ll see in <a data-type="xref" href="#ppp_adding_naics">Example 7-12</a>, anytime we integrate a new data source, it means we have to evaluate, clean, and transform it just as we have our “primary” dataset. In this case, that means that we want to proactively update any <code>&lt;NA&gt;</code> values in the <code>NAICSCode</code> column of our PPP loan data to a flag value (I have chosen the string “None”), in order to prevent their being matched with essentially random <code>&lt;NA&gt;</code> values in our SBA NAICS code file. Similarly, once we’ve done our merge, we still want to see what codes from our PPP loan file <em>didn’t</em> get matched successfully. For now, we’ll leave open the decision about how to handle these until we’ve done a bit more digging around in our analysis phase to see whether we want to “fill them in” (e.g., with the regular NAICS values/interpretations), flag them as being atypical for the SBA, or some combination thereof.</p>&#13;
<div class="pagebreak-before less_space" data-type="example" id="ppp_adding_naics">&#13;
<h5><span class="label">Example 7-12. </span>ppp_adding_naics.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># script to merge our PPP loan data with information from the SBA's NAICS</code><code>&#13;
</code><code class="c1"># size requirements, found here:</code><code>&#13;
</code><code class="c1"># https://www.sba.gov/document/support--table-size-standards</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># import pandas to facilitate the merging and sorting</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># read our PPP loan data into a new DataFrame</code><code>&#13;
</code><code class="n">ppp_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">public_150k_plus_fingerprints.csv</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">dtype</code><code class="o">=</code><code class="s1">'</code><code class="s1">string</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO7-1" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO7-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># read the NAICS data into a separate DataFrame</code><code>&#13;
</code><code class="n">sba_naics_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">SBA-NAICS-data.csv</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">dtype</code><code class="o">=</code><code class="s1">'</code><code class="s1">string</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># if there's no value in the 'NAICSCode' column, replace it with "None"</code><code>&#13;
</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">NAICSCode</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">NAICSCode</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">fillna</code><code class="p">(</code><code class="s2">"</code><code class="s2">None</code><code class="s2">"</code><code class="p">)</code><code> </code><a class="co" href="#callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO7-2" id="co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO7-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># merge the two datasets using a "left" merge</code><code>&#13;
</code><code class="n">merged_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">merge</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">,</code><code> </code><code class="n">sba_naics_data</code><code class="p">,</code><code> </code><code class="n">how</code><code class="o">=</code><code class="s1">'</code><code class="s1">left</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                      </code><code class="n">left_on</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">NAICSCode</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">right_on</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">NAICS Codes</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>&#13;
</code><code>                      </code><code class="n">indicator</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># open a file to save our merged data to</code><code>&#13;
</code><code class="n">merged_data_file</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s1">'</code><code class="s1">ppp-fingerprints-and-naics.csv</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">w</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># write the merged data to an output file as a CSV</code><code>&#13;
</code><code class="n">merged_data_file</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">merged_data</code><code class="o">.</code><code class="n">to_csv</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># print out the values in the '_merge' column to see how many</code><code>&#13;
</code><code class="c1"># entries in our loan data don't get matched to an NAICS code</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">merged_data</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="s1">'</code><code class="s1">_merge</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># create a new DataFrame that is *just* the unmatched rows</code><code>&#13;
</code><code class="n">unmatched_values</code><code> </code><code class="o">=</code><code> </code><code class="n">merged_data</code><code class="p">[</code><code class="n">merged_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">_merge</code><code class="s1">'</code><code class="p">]</code><code class="o">==</code><code class="s1">'</code><code class="s1">left_only</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># open a file to write the unmatched values to</code><code>&#13;
</code><code class="n">unmatched_values_file</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s1">'</code><code class="s1">ppp-unmatched-naics-codes.csv</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">w</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># write a new CSV file that contains all the unmatched NAICS codes in our</code><code>&#13;
</code><code class="c1"># PPP loan data, along with how many times it appears</code><code>&#13;
</code><code class="n">unmatched_values_file</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">unmatched_values</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="s1">'</code><code class="s1">NAICSCode</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code class="n">to_csv</code><code class="p">(</code><code class="p">)</code><code class="p">)</code></pre></div>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO7-1" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO7-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Use the <code>dtype='string'</code> parameter to force <code>pandas</code> to treat our entire dataset as strings; this will make later matching and comparison tasks more predictable.</p></dd>&#13;
<dt><a class="co" href="#co_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO7-2" id="callout_cleaning__transforming____span_class__keep_together__and_augmenting_data__span__CO7-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>If we don’t do this replacement, our data will match to unpredictable <code>NA</code> values from the <em>SBA-NAICS-data.csv</em> file.</p></dd>&#13;
</dl>&#13;
&#13;
<p>Augmenting a dataset as we have in <a data-type="xref" href="#ppp_adding_naics">Example 7-12</a> can help us expand the types of questions we can use it to answer, as well as helping support faster, more comprehensive data analysis and interpretation. At the same time, anytime we introduce new data, we need to complete the same life cycle of evaluation, cleaning, transformation, and (maybe even) augmentation that we applied to our “primary” dataset. This means that we’ll always need to strike a balance between making our primary data more elaborate (and possibly useful) with the time and effort involved in finding and wrangling the “secondary” data that we use to<a data-primary="augmenting data" data-startref="augment-data2" data-type="indexterm" id="idm45143401426176"/><a data-primary="data augmentation" data-startref="data-augment2" data-type="indexterm" id="idm45143401425232"/><a data-primary="data quality" data-secondary="improving" data-startref="data-quality-improve-augment2" data-tertiary="augmenting" data-type="indexterm" id="idm45143401424288"/><a data-primary="improving data quality" data-secondary="augmenting" data-startref="improve-data-quality-augment2" data-type="indexterm" id="idm45143401422736"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="augmenting data" data-startref="ppp-augment" data-type="indexterm" id="idm45143401421504"/> augment it.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm45143402856944">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>While the variety of data cleaning, transformation, and augmentation possibilities is as varied as both datasets and analysis possibilities, the primary goal of this chapter was to illustrate common issues in data cleaning, transformation, and augmentation and introduce some key methods for resolving them.</p>&#13;
&#13;
<p>Before we move on to actually trying to generate insights with our data, however, we’re going to take a small “detour” in <a data-type="xref" href="ch08.html#chapter8">Chapter 8</a>, which will focus on some programming best practices that can help us make sure our code is as clear, efficient, and effective as possible. Because while using Python to do data wrangling already lets us do things that would be impossible with other tools, optimizing our code for both use and reuse is another way to make sure we get the most out of each program and piece of code we write, too. In most cases, this means structuring our files so that they are more versatile, composable, and readable, as we’ll see right now!</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45143404308272"><sup><a href="ch07.html#idm45143404308272-marker">1</a></sup> While the data format for Citi Bike data files changed in early 2021, files from before that date still follow the format in these examples.</p><p data-type="footnote" id="idm45143404288880"><sup><a href="ch07.html#idm45143404288880-marker">2</a></sup> And even if they weren’t, we could always convert them to strings.</p><p data-type="footnote" id="idm45143403643280"><sup><a href="ch07.html#idm45143403643280-marker">3</a></sup> Unless, of course, you’re working in a team—then you need to consider everyone’s needs. You’ll be glad when it’s your turn to work with <em>their</em> code.</p><p data-type="footnote" id="idm45143403085296"><sup><a href="ch07.html#idm45143403085296-marker">4</a></sup> Of course, Macs and PCs use a different “base” date because…<em>reasons</em>.</p><p data-type="footnote" id="idm45143403010368"><sup><a href="ch07.html#idm45143403010368-marker">5</a></sup> Believe me, most professional programmers are looking things up online every five minutes.</p><p data-type="footnote" id="idm45143402992928"><sup><a href="ch07.html#idm45143402992928-marker">6</a></sup> At first I was concerned that the <code>OriginatingLenderLocationID</code> might refer to an individual bank branch, for example.</p><p data-type="footnote" id="idm45143402866320"><sup><a href="ch07.html#idm45143402866320-marker">7</a></sup> As a case in point, I didn’t even end up using this approach in the final code for <a data-type="xref" href="#ppp_add_fingerprints">Example 7-10</a>, but I <em>did</em> find a use for it in <a data-type="xref" href="#ppp_adding_naics">Example 7-12</a>!</p><p data-type="footnote" id="idm45143402846432"><sup><a href="ch07.html#idm45143402846432-marker">8</a></sup> Which leads us to <a href="https://naics.com/what-is-a-naics-code-why-do-i-need-one"><em class="hyperlink">https://naics.com/what-is-a-naics-code-why-do-i-need-one</em></a>.</p></div></div></section></body></html>