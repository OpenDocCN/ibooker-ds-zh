<html><head></head><body><section data-pdf-bookmark="Chapter 22. Network Analysis" data-type="chapter" epub:type="chapter"><div class="chapter" id="network_analysis">&#13;
<h1><span class="label">Chapter 22. </span>Network Analysis</h1>&#13;
&#13;
<blockquote data-type="epigraph" epub:type="epigraph">&#13;
    <p>Your connections to all the things around you literally define who you are.</p>&#13;
    <p data-type="attribution">Aaron O’Connell</p>&#13;
</blockquote>&#13;
&#13;
<p>Many<a data-primary="network analysis" data-secondary="nodes and edges in" data-type="indexterm" id="idm45635714745880"/><a data-primary="nodes" data-type="indexterm" id="idm45635714744872"/><a data-primary="edges" data-type="indexterm" id="idm45635714744200"/> interesting data problems can be fruitfully thought of in terms of <em>networks</em>, consisting of <em>nodes</em> of some type and the <em>edges</em> that join them.</p>&#13;
&#13;
<p>For instance, your Facebook friends form the nodes of a network whose edges are friendship relations.  A less obvious example is the World Wide Web itself,&#13;
with each web page a node and each hyperlink from one page to another an edge.</p>&#13;
&#13;
<p>Facebook friendship is mutual—if I am Facebook friends with you, then necessarily you are friends with me.  In this case, we say that the<a data-primary="undirected edges" data-type="indexterm" id="idm45635714740744"/> edges are <em>undirected</em>.  Hyperlinks are not—my website links to <em>whitehouse.gov</em>, but (for reasons inexplicable to me) <em>whitehouse.gov</em> refuses to link to my website.  We<a data-primary="directed edges" data-type="indexterm" id="idm45635714738664"/> call these types of edges <em>directed</em>.  We’ll look at both kinds of networks.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Betweenness Centrality" data-type="sect1"><div class="sect1" id="centrality">&#13;
<h1>Betweenness Centrality</h1>&#13;
&#13;
<p>In <a data-type="xref" href="ch01.html#introduction">Chapter 1</a>, we<a data-primary="network analysis" data-secondary="betweenness centrality" data-type="indexterm" id="NAbetween22"/><a data-primary="betweenness centrality" data-type="indexterm" id="betcen22"/><a data-primary="centrality" data-secondary="betweenness" data-type="indexterm" id="Cbet22"/><a data-primary="key connectors, finding" data-type="indexterm" id="idm45635714730920"/> computed the key connectors in the DataSciencester network by counting the number of friends each user had. Now we have enough machinery to take a look at other approaches. We will use the same network, but now we’ll use <code>NamedTuple</code>s for the data.</p>&#13;
&#13;
<p>Recall that the network (<a data-type="xref" href="#datasciencester_network_ch21">Figure 22-1</a>) comprised users:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">NamedTuple</code>&#13;
&#13;
<code class="k">class</code> <code class="nc">User</code><code class="p">(</code><code class="n">NamedTuple</code><code class="p">):</code>&#13;
    <code class="nb">id</code><code class="p">:</code> <code class="nb">int</code>&#13;
    <code class="n">name</code><code class="p">:</code> <code class="nb">str</code>&#13;
&#13;
<code class="n">users</code> <code class="o">=</code> <code class="p">[</code><code class="n">User</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="s2">"Hero"</code><code class="p">),</code> <code class="n">User</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="s2">"Dunn"</code><code class="p">),</code> <code class="n">User</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="s2">"Sue"</code><code class="p">),</code> <code class="n">User</code><code class="p">(</code><code class="mi">3</code><code class="p">,</code> <code class="s2">"Chi"</code><code class="p">),</code>&#13;
         <code class="n">User</code><code class="p">(</code><code class="mi">4</code><code class="p">,</code> <code class="s2">"Thor"</code><code class="p">),</code> <code class="n">User</code><code class="p">(</code><code class="mi">5</code><code class="p">,</code> <code class="s2">"Clive"</code><code class="p">),</code> <code class="n">User</code><code class="p">(</code><code class="mi">6</code><code class="p">,</code> <code class="s2">"Hicks"</code><code class="p">),</code>&#13;
         <code class="n">User</code><code class="p">(</code><code class="mi">7</code><code class="p">,</code> <code class="s2">"Devin"</code><code class="p">),</code> <code class="n">User</code><code class="p">(</code><code class="mi">8</code><code class="p">,</code> <code class="s2">"Kate"</code><code class="p">),</code> <code class="n">User</code><code class="p">(</code><code class="mi">9</code><code class="p">,</code> <code class="s2">"Klein"</code><code class="p">)]</code></pre>&#13;
&#13;
<p>and friendships:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">friend_pairs</code> <code class="o">=</code> <code class="p">[(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">),</code> <code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">2</code><code class="p">),</code> <code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">),</code> <code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">3</code><code class="p">),</code> <code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="mi">3</code><code class="p">),</code> <code class="p">(</code><code class="mi">3</code><code class="p">,</code> <code class="mi">4</code><code class="p">),</code>&#13;
                <code class="p">(</code><code class="mi">4</code><code class="p">,</code> <code class="mi">5</code><code class="p">),</code> <code class="p">(</code><code class="mi">5</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="p">(</code><code class="mi">5</code><code class="p">,</code> <code class="mi">7</code><code class="p">),</code> <code class="p">(</code><code class="mi">6</code><code class="p">,</code> <code class="mi">8</code><code class="p">),</code> <code class="p">(</code><code class="mi">7</code><code class="p">,</code> <code class="mi">8</code><code class="p">),</code> <code class="p">(</code><code class="mi">8</code><code class="p">,</code> <code class="mi">9</code><code class="p">)]</code></pre>&#13;
&#13;
<figure><div class="figure" id="datasciencester_network_ch21">&#13;
<img alt="The DataSciencester network." src="assets/dsf2_0101.png"/>&#13;
<h6><span class="label">Figure 22-1. </span>The DataSciencester network</h6>&#13;
</div></figure>&#13;
&#13;
<p>The friendships will be easier to work with as a <code>dict</code>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">Dict</code><code class="p">,</code> <code class="n">List</code>&#13;
&#13;
<code class="c1"># type alias for keeping track of Friendships</code>&#13;
<code class="n">Friendships</code> <code class="o">=</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">int</code><code class="p">,</code> <code class="n">List</code><code class="p">[</code><code class="nb">int</code><code class="p">]]</code>&#13;
&#13;
<code class="n">friendships</code><code class="p">:</code> <code class="n">Friendships</code> <code class="o">=</code> <code class="p">{</code><code class="n">user</code><code class="o">.</code><code class="n">id</code><code class="p">:</code> <code class="p">[]</code> <code class="k">for</code> <code class="n">user</code> <code class="ow">in</code> <code class="n">users</code><code class="p">}</code>&#13;
&#13;
<code class="k">for</code> <code class="n">i</code><code class="p">,</code> <code class="n">j</code> <code class="ow">in</code> <code class="n">friend_pairs</code><code class="p">:</code>&#13;
    <code class="n">friendships</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">j</code><code class="p">)</code>&#13;
    <code class="n">friendships</code><code class="p">[</code><code class="n">j</code><code class="p">]</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">i</code><code class="p">)</code>&#13;
&#13;
<code class="k">assert</code> <code class="n">friendships</code><code class="p">[</code><code class="mi">4</code><code class="p">]</code> <code class="o">==</code> <code class="p">[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">5</code><code class="p">]</code>&#13;
<code class="k">assert</code> <code class="n">friendships</code><code class="p">[</code><code class="mi">8</code><code class="p">]</code> <code class="o">==</code> <code class="p">[</code><code class="mi">6</code><code class="p">,</code> <code class="mi">7</code><code class="p">,</code> <code class="mi">9</code><code class="p">]</code></pre>&#13;
&#13;
<p>When we left off we were dissatisfied with our notion of <em>degree centrality</em>, which didn’t really agree with our intuition about who the key connectors of the network were.</p>&#13;
&#13;
<p>An alternative metric is <em>betweenness centrality</em>, which identifies people who frequently are on the shortest paths between pairs of other people.  In particular, the betweenness centrality of node <em>i</em> is computed by adding up, for every other pair of nodes <em>j</em> and <em>k</em>, the proportion of shortest paths between node <em>j</em> and node <em>k</em> that pass through <em>i</em>.</p>&#13;
&#13;
<p>That is, to figure out Thor’s betweenness centrality, we’ll need to compute all the shortest paths between all pairs of people who aren’t Thor.  And then we’ll need to count how many of those shortest paths pass through Thor.  For instance, the only shortest path between Chi (<code>id</code> 3) and Clive (<code>id</code> 5) passes through Thor, while neither of the two shortest paths between Hero (<code>id</code> 0) and Chi (<code>id</code> 3) does.</p>&#13;
&#13;
<p>So, as a first step, we’ll need to figure out the shortest paths between all pairs of people.  There are some pretty sophisticated algorithms for doing so efficiently, but (as is almost always the case) we will use a less efficient, easier-to-understand algorithm.</p>&#13;
&#13;
<p>This<a data-primary="breadth-first search" data-type="indexterm" id="idm45635714310536"/> algorithm (an implementation of breadth-first search) is one of the more complicated ones in the book, so let’s talk through it carefully:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Our goal is a function that takes a <code>from_user</code> and finds <em>all</em> shortest paths to every other user.</p>&#13;
</li>&#13;
<li>&#13;
<p>We’ll represent a path as a <code>list</code> of user IDs.  Since every path starts at <code>from_user</code>, we won’t include her ID in the list.  This means that the length of the list representing the path will be the length of the path itself.</p>&#13;
</li>&#13;
<li>&#13;
<p>We’ll maintain a dictionary called <code>shortest_paths_to</code> where the keys are user IDs and the values are lists of paths that end at the user with the specified ID.  If there is a unique shortest path, the list will just contain that one path.  If there are multiple shortest paths, the list will contain all of them.</p>&#13;
</li>&#13;
<li>&#13;
<p>We’ll also maintain a queue called <code>frontier</code> that contains the users we want to explore in the order we want to explore them. We’ll store them as pairs <code>(prev_user, user)</code> so that we know how we got to each one.  We initialize the queue with all the neighbors of <code>from_user</code>.  (We haven’t talked about queues, which are data structures optimized for “add to the end” and “remove from the front” operations. In Python, they are implemented as <code>collections.deque</code>, which is actually a double-ended queue.)</p>&#13;
</li>&#13;
<li>&#13;
<p>As we explore the graph, whenever we find new neighbors that we don’t already know the shortest paths to, we add them to the end of the queue to explore later, with the current user as <code>prev_user</code>.</p>&#13;
</li>&#13;
<li>&#13;
<p>When we take a user off the queue, and we’ve never encountered that user before, we’ve definitely found one or more shortest paths to him—each of the shortest paths to <code>prev_user</code> with one extra step added.</p>&#13;
</li>&#13;
<li>&#13;
<p>When we take a user off the queue and we <em>have</em> encountered that user before, then either we’ve found another shortest path (in which case we should add it) or we’ve found a longer path (in which case we shouldn’t).</p>&#13;
</li>&#13;
<li>&#13;
<p>When no more users are left on the queue, we’ve explored the whole graph (or, at least, the parts of it that are reachable from the starting user) and we’re done.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>We can put this all together into a (large) function:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">deque</code>&#13;
&#13;
<code class="n">Path</code> <code class="o">=</code> <code class="n">List</code><code class="p">[</code><code class="nb">int</code><code class="p">]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">shortest_paths_from</code><code class="p">(</code><code class="n">from_user_id</code><code class="p">:</code> <code class="nb">int</code><code class="p">,</code>&#13;
                        <code class="n">friendships</code><code class="p">:</code> <code class="n">Friendships</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">int</code><code class="p">,</code> <code class="n">List</code><code class="p">[</code><code class="n">Path</code><code class="p">]]:</code>&#13;
    <code class="c1"># A dictionary from user_id to *all* shortest paths to that user.</code>&#13;
    <code class="n">shortest_paths_to</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">int</code><code class="p">,</code> <code class="n">List</code><code class="p">[</code><code class="n">Path</code><code class="p">]]</code> <code class="o">=</code> <code class="p">{</code><code class="n">from_user_id</code><code class="p">:</code> <code class="p">[[]]}</code>&#13;
&#13;
    <code class="c1"># A queue of (previous user, next user) that we need to check.</code>&#13;
    <code class="c1"># Starts out with all pairs (from_user, friend_of_from_user).</code>&#13;
    <code class="n">frontier</code> <code class="o">=</code> <code class="n">deque</code><code class="p">((</code><code class="n">from_user_id</code><code class="p">,</code> <code class="n">friend_id</code><code class="p">)</code>&#13;
                     <code class="k">for</code> <code class="n">friend_id</code> <code class="ow">in</code> <code class="n">friendships</code><code class="p">[</code><code class="n">from_user_id</code><code class="p">])</code>&#13;
&#13;
    <code class="c1"># Keep going until we empty the queue.</code>&#13;
    <code class="k">while</code> <code class="n">frontier</code><code class="p">:</code>&#13;
        <code class="c1"># Remove the pair that's next in the queue.</code>&#13;
        <code class="n">prev_user_id</code><code class="p">,</code> <code class="n">user_id</code> <code class="o">=</code> <code class="n">frontier</code><code class="o">.</code><code class="n">popleft</code><code class="p">()</code>&#13;
&#13;
        <code class="c1"># Because of the way we're adding to the queue,</code>&#13;
        <code class="c1"># necessarily we already know some shortest paths to prev_user.</code>&#13;
        <code class="n">paths_to_prev_user</code> <code class="o">=</code> <code class="n">shortest_paths_to</code><code class="p">[</code><code class="n">prev_user_id</code><code class="p">]</code>&#13;
        <code class="n">new_paths_to_user</code> <code class="o">=</code> <code class="p">[</code><code class="n">path</code> <code class="o">+</code> <code class="p">[</code><code class="n">user_id</code><code class="p">]</code> <code class="k">for</code> <code class="n">path</code> <code class="ow">in</code> <code class="n">paths_to_prev_user</code><code class="p">]</code>&#13;
&#13;
        <code class="c1"># It's possible we already know a shortest path to user_id.</code>&#13;
        <code class="n">old_paths_to_user</code> <code class="o">=</code> <code class="n">shortest_paths_to</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">user_id</code><code class="p">,</code> <code class="p">[])</code>&#13;
&#13;
        <code class="c1"># What's the shortest path to here that we've seen so far?</code>&#13;
        <code class="k">if</code> <code class="n">old_paths_to_user</code><code class="p">:</code>&#13;
            <code class="n">min_path_length</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">old_paths_to_user</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>&#13;
        <code class="k">else</code><code class="p">:</code>&#13;
            <code class="n">min_path_length</code> <code class="o">=</code> <code class="nb">float</code><code class="p">(</code><code class="s1">'inf'</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># Only keep paths that aren't too long and are actually new.</code>&#13;
        <code class="n">new_paths_to_user</code> <code class="o">=</code> <code class="p">[</code><code class="n">path</code>&#13;
                             <code class="k">for</code> <code class="n">path</code> <code class="ow">in</code> <code class="n">new_paths_to_user</code>&#13;
                             <code class="k">if</code> <code class="nb">len</code><code class="p">(</code><code class="n">path</code><code class="p">)</code> <code class="o">&lt;=</code> <code class="n">min_path_length</code>&#13;
                             <code class="ow">and</code> <code class="n">path</code> <code class="ow">not</code> <code class="ow">in</code> <code class="n">old_paths_to_user</code><code class="p">]</code>&#13;
&#13;
        <code class="n">shortest_paths_to</code><code class="p">[</code><code class="n">user_id</code><code class="p">]</code> <code class="o">=</code> <code class="n">old_paths_to_user</code> <code class="o">+</code> <code class="n">new_paths_to_user</code>&#13;
&#13;
        <code class="c1"># Add never-seen neighbors to the frontier.</code>&#13;
        <code class="n">frontier</code><code class="o">.</code><code class="n">extend</code><code class="p">((</code><code class="n">user_id</code><code class="p">,</code> <code class="n">friend_id</code><code class="p">)</code>&#13;
                        <code class="k">for</code> <code class="n">friend_id</code> <code class="ow">in</code> <code class="n">friendships</code><code class="p">[</code><code class="n">user_id</code><code class="p">]</code>&#13;
                        <code class="k">if</code> <code class="n">friend_id</code> <code class="ow">not</code> <code class="ow">in</code> <code class="n">shortest_paths_to</code><code class="p">)</code>&#13;
&#13;
    <code class="k">return</code> <code class="n">shortest_paths_to</code></pre>&#13;
&#13;
<p>Now let’s compute all the shortest paths:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="c1"># For each from_user, for each to_user, a list of shortest paths.</code>&#13;
<code class="n">shortest_paths</code> <code class="o">=</code> <code class="p">{</code><code class="n">user</code><code class="o">.</code><code class="n">id</code><code class="p">:</code> <code class="n">shortest_paths_from</code><code class="p">(</code><code class="n">user</code><code class="o">.</code><code class="n">id</code><code class="p">,</code> <code class="n">friendships</code><code class="p">)</code>&#13;
                  <code class="k">for</code> <code class="n">user</code> <code class="ow">in</code> <code class="n">users</code><code class="p">}</code></pre>&#13;
&#13;
<p>And we’re finally ready to compute betweenness centrality.  For every pair of nodes <em>i</em> and <em>j</em>, we know the <em>n</em> shortest paths from <em>i</em> to <em>j</em>.  Then, for each of those paths, we just add 1/n to the centrality of each node on that path:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">betweenness_centrality</code> <code class="o">=</code> <code class="p">{</code><code class="n">user</code><code class="o">.</code><code class="n">id</code><code class="p">:</code> <code class="mf">0.0</code> <code class="k">for</code> <code class="n">user</code> <code class="ow">in</code> <code class="n">users</code><code class="p">}</code>&#13;
&#13;
<code class="k">for</code> <code class="n">source</code> <code class="ow">in</code> <code class="n">users</code><code class="p">:</code>&#13;
    <code class="k">for</code> <code class="n">target_id</code><code class="p">,</code> <code class="n">paths</code> <code class="ow">in</code> <code class="n">shortest_paths</code><code class="p">[</code><code class="n">source</code><code class="o">.</code><code class="n">id</code><code class="p">]</code><code class="o">.</code><code class="n">items</code><code class="p">():</code>&#13;
        <code class="k">if</code> <code class="n">source</code><code class="o">.</code><code class="n">id</code> <code class="o">&lt;</code> <code class="n">target_id</code><code class="p">:</code>      <code class="c1"># don't double count</code>&#13;
            <code class="n">num_paths</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">paths</code><code class="p">)</code>     <code class="c1"># how many shortest paths?</code>&#13;
            <code class="n">contrib</code> <code class="o">=</code> <code class="mi">1</code> <code class="o">/</code> <code class="n">num_paths</code>    <code class="c1"># contribution to centrality</code>&#13;
            <code class="k">for</code> <code class="n">path</code> <code class="ow">in</code> <code class="n">paths</code><code class="p">:</code>&#13;
                <code class="k">for</code> <code class="n">between_id</code> <code class="ow">in</code> <code class="n">path</code><code class="p">:</code>&#13;
                    <code class="k">if</code> <code class="n">between_id</code> <code class="ow">not</code> <code class="ow">in</code> <code class="p">[</code><code class="n">source</code><code class="o">.</code><code class="n">id</code><code class="p">,</code> <code class="n">target_id</code><code class="p">]:</code>&#13;
                        <code class="n">betweenness_centrality</code><code class="p">[</code><code class="n">between_id</code><code class="p">]</code> <code class="o">+=</code> <code class="n">contrib</code></pre>&#13;
&#13;
<p>As shown in <a data-type="xref" href="#network_sized_by_betweenness">Figure 22-2</a>, users 0 and 9 have centrality 0 (as neither is on any shortest path between other users), whereas 3, 4, and 5 all have high centralities (as all three lie on many shortest paths).</p>&#13;
&#13;
<figure><div class="figure" id="network_sized_by_betweenness">&#13;
<img alt="The DataSciencester network sized by betweenness centrality." src="assets/dsf2_2202.png"/>&#13;
<h6><span class="label">Figure 22-2. </span>The DataSciencester network sized by betweenness centrality</h6>&#13;
</div></figure>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Generally the centrality numbers aren’t that meaningful themselves. What we care about is how the numbers for each node compare to the numbers for other nodes.</p>&#13;
</div>&#13;
&#13;
<p>Another<a data-primary="closeness centrality" data-type="indexterm" id="idm45635713828216"/><a data-primary="centrality" data-secondary="closeness" data-type="indexterm" id="idm45635713827480"/> measure we can look at is <em>closeness centrality</em>.  First, for each user we compute her <em>farness</em>, which is the sum of the lengths of her shortest paths to each other user.  Since we’ve already computed the shortest paths between each pair of nodes, it’s easy to add their lengths.  (If there are multiple shortest paths, they all have the same length, so we can just look at the first one.)</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">farness</code><code class="p">(</code><code class="n">user_id</code><code class="p">:</code> <code class="nb">int</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""the sum of the lengths of the shortest paths to each other user"""</code>&#13;
    <code class="k">return</code> <code class="nb">sum</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">paths</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>&#13;
               <code class="k">for</code> <code class="n">paths</code> <code class="ow">in</code> <code class="n">shortest_paths</code><code class="p">[</code><code class="n">user_id</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code class="p">())</code></pre>&#13;
&#13;
<p>after which it’s very little work to compute closeness centrality (<a data-type="xref" href="#network_sized_by_closeness">Figure 22-3</a>):</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">closeness_centrality</code> <code class="o">=</code> <code class="p">{</code><code class="n">user</code><code class="o">.</code><code class="n">id</code><code class="p">:</code> <code class="mi">1</code> <code class="o">/</code> <code class="n">farness</code><code class="p">(</code><code class="n">user</code><code class="o">.</code><code class="n">id</code><code class="p">)</code> <code class="k">for</code> <code class="n">user</code> <code class="ow">in</code> <code class="n">users</code><code class="p">}</code></pre>&#13;
&#13;
<figure><div class="figure" id="network_sized_by_closeness">&#13;
<img alt="The DataSciencester network sized by closeness centrality." src="assets/dsf2_2203.png"/>&#13;
<h6><span class="label">Figure 22-3. </span>The DataSciencester network sized by closeness centrality</h6>&#13;
</div></figure>&#13;
&#13;
<p>There is much less variation here—even the very central nodes are still pretty far from the nodes out on the periphery.</p>&#13;
&#13;
<p>As we saw, computing shortest paths is kind of a pain.  For this reason, betweenness and closeness centrality aren’t often used on large networks.  The less intuitive (but generally easier to compute) <em>eigenvector centrality</em> is more frequently used.<a data-primary="" data-startref="NAbetween22" data-type="indexterm" id="idm45635713796312"/><a data-primary="" data-startref="betcen22" data-type="indexterm" id="idm45635713795336"/><a data-primary="" data-startref="Cbet22" data-type="indexterm" id="idm45635713794392"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Eigenvector Centrality" data-type="sect1"><div class="sect1" id="eigenvector_centrality">&#13;
<h1>Eigenvector Centrality</h1>&#13;
&#13;
<p>In<a data-primary="network analysis" data-secondary="eigenvector centrality" data-type="indexterm" id="NAeigen22"/><a data-primary="centrality" data-secondary="eigenvector" data-type="indexterm" id="Ceigen22"/> order to talk about eigenvector centrality, we have to talk about eigenvectors, and in order to talk about eigenvectors, we have to talk about matrix multiplication.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Matrix Multiplication" data-type="sect2"><div class="sect2" id="matrix_multiplication">&#13;
<h2>Matrix Multiplication</h2>&#13;
&#13;
<p>If <em>A</em> is<a data-primary="eigenvector centrality" data-secondary="matrix multiplication" data-type="indexterm" id="idm45635713781096"/><a data-primary="matrix multiplication" data-type="indexterm" id="idm45635713780088"/> an <math>&#13;
  <mrow>&#13;
    <mi>n</mi>&#13;
    <mo>×</mo>&#13;
    <mi>m</mi>&#13;
  </mrow>&#13;
</math> matrix and <em>B</em> is an <math>&#13;
  <mrow>&#13;
    <mi>m</mi>&#13;
    <mo>×</mo>&#13;
    <mi>k</mi>&#13;
  </mrow>&#13;
</math> matrix (notice that the second dimension of <em>A</em> is same as the first dimension of <em>B</em>), then their product <em>AB</em> is the <math>&#13;
  <mrow>&#13;
    <mi>n</mi>&#13;
    <mo>×</mo>&#13;
    <mi>k</mi>&#13;
  </mrow>&#13;
</math> matrix whose (<em>i</em>,<em>j</em>)th entry is:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper A Subscript i Baseline 1 Baseline upper B Subscript 1 j plus upper A Subscript i Baseline 2 Baseline upper B Subscript 2 j plus ellipsis plus upper A Subscript i m Baseline upper B Subscript m j" display="block">&#13;
  <mrow>&#13;
    <msub><mi>A</mi> <mrow><mi>i</mi><mn>1</mn></mrow> </msub>&#13;
    <msub><mi>B</mi> <mrow><mn>1</mn><mi>j</mi></mrow> </msub>&#13;
    <mo>+</mo>&#13;
    <msub><mi>A</mi> <mrow><mi>i</mi><mn>2</mn></mrow> </msub>&#13;
    <msub><mi>B</mi> <mrow><mn>2</mn><mi>j</mi></mrow> </msub>&#13;
    <mo>+</mo>&#13;
    <mo>⋯</mo>&#13;
    <mo>+</mo>&#13;
    <msub><mi>A</mi> <mrow><mi>i</mi><mi>m</mi></mrow> </msub>&#13;
    <msub><mi>B</mi> <mrow><mi>m</mi><mi>j</mi></mrow> </msub>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>which is just the dot product of the <em>i</em>th row of <em>A</em> (thought of as a vector) with the <em>j</em>th column of <em>B</em> (also thought of as a vector).</p>&#13;
&#13;
<p>We can implement this using the <code>make_matrix</code> function from <a data-type="xref" href="ch04.html#linear_algebra">Chapter 4</a>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">scratch.linear_algebra</code> <code class="kn">import</code> <code class="n">Matrix</code><code class="p">,</code> <code class="n">make_matrix</code><code class="p">,</code> <code class="n">shape</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">matrix_times_matrix</code><code class="p">(</code><code class="n">m1</code><code class="p">:</code> <code class="n">Matrix</code><code class="p">,</code> <code class="n">m2</code><code class="p">:</code> <code class="n">Matrix</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Matrix</code><code class="p">:</code>&#13;
    <code class="n">nr1</code><code class="p">,</code> <code class="n">nc1</code> <code class="o">=</code> <code class="n">shape</code><code class="p">(</code><code class="n">m1</code><code class="p">)</code>&#13;
    <code class="n">nr2</code><code class="p">,</code> <code class="n">nc2</code> <code class="o">=</code> <code class="n">shape</code><code class="p">(</code><code class="n">m2</code><code class="p">)</code>&#13;
    <code class="k">assert</code> <code class="n">nc1</code> <code class="o">==</code> <code class="n">nr2</code><code class="p">,</code> <code class="s2">"must have (# of columns in m1) == (# of rows in m2)"</code>&#13;
&#13;
    <code class="k">def</code> <code class="nf">entry_fn</code><code class="p">(</code><code class="n">i</code><code class="p">:</code> <code class="nb">int</code><code class="p">,</code> <code class="n">j</code><code class="p">:</code> <code class="nb">int</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
        <code class="sd">"""dot product of i-th row of m1 with j-th column of m2"""</code>&#13;
        <code class="k">return</code> <code class="nb">sum</code><code class="p">(</code><code class="n">m1</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">k</code><code class="p">]</code> <code class="o">*</code> <code class="n">m2</code><code class="p">[</code><code class="n">k</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="k">for</code> <code class="n">k</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">nc1</code><code class="p">))</code>&#13;
&#13;
    <code class="k">return</code> <code class="n">make_matrix</code><code class="p">(</code><code class="n">nr1</code><code class="p">,</code> <code class="n">nc2</code><code class="p">,</code> <code class="n">entry_fn</code><code class="p">)</code></pre>&#13;
&#13;
<p>If we think of an <em>m</em>-dimensional vector as an <code>(m, 1)</code> matrix,&#13;
we can multiply it by an <code>(n, m)</code> matrix to get an <code>(n, 1)</code> matrix,&#13;
which we can then think of as an <em>n</em>-dimensional vector.</p>&#13;
&#13;
<p>This means another way to think about an <code>(n, m)</code> matrix is as a&#13;
linear mapping that transforms <em>m</em>-dimensional vectors into <em>n</em>-dimensional vectors:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">scratch.linear_algebra</code> <code class="kn">import</code> <code class="n">Vector</code><code class="p">,</code> <code class="n">dot</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">matrix_times_vector</code><code class="p">(</code><code class="n">m</code><code class="p">:</code> <code class="n">Matrix</code><code class="p">,</code> <code class="n">v</code><code class="p">:</code> <code class="n">Vector</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Vector</code><code class="p">:</code>&#13;
    <code class="n">nr</code><code class="p">,</code> <code class="n">nc</code> <code class="o">=</code> <code class="n">shape</code><code class="p">(</code><code class="n">m</code><code class="p">)</code>&#13;
    <code class="n">n</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">v</code><code class="p">)</code>&#13;
    <code class="k">assert</code> <code class="n">nc</code> <code class="o">==</code> <code class="n">n</code><code class="p">,</code> <code class="s2">"must have (# of cols in m) == (# of elements in v)"</code>&#13;
&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">dot</code><code class="p">(</code><code class="n">row</code><code class="p">,</code> <code class="n">v</code><code class="p">)</code> <code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">m</code><code class="p">]</code>  <code class="c1"># output has length nr</code></pre>&#13;
&#13;
<p>When <em>A</em> is a <em>square</em> matrix, this operation maps <em>n</em>-dimensional vectors to other <em>n</em>-dimensional vectors.  It’s possible that, for some matrix <em>A</em> and vector <em>v</em>, when <em>A</em> operates on <em>v</em> we get back a scalar multiple of <em>v</em>—that is, that the result is a vector that points in the same direction as <em>v</em>.  When this happens (and when, in addition, <em>v</em> is not a vector of all zeros), we call <em>v</em> an <em>eigenvector</em> of <em>A</em>.  And we call the multiplier an <em>eigenvalue</em>.</p>&#13;
&#13;
<p>One possible way to find an eigenvector of <em>A</em> is by picking a starting vector <em>v</em>, applying <code>matrix_times_vector</code>, rescaling the result to have magnitude 1, and repeating until the process converges:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">Tuple</code>&#13;
<code class="kn">import</code> <code class="nn">random</code>&#13;
<code class="kn">from</code> <code class="nn">scratch.linear_algebra</code> <code class="kn">import</code> <code class="n">magnitude</code><code class="p">,</code> <code class="n">distance</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">find_eigenvector</code><code class="p">(</code><code class="n">m</code><code class="p">:</code> <code class="n">Matrix</code><code class="p">,</code>&#13;
                     <code class="n">tolerance</code><code class="p">:</code> <code class="nb">float</code> <code class="o">=</code> <code class="mf">0.00001</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Tuple</code><code class="p">[</code><code class="n">Vector</code><code class="p">,</code> <code class="nb">float</code><code class="p">]:</code>&#13;
    <code class="n">guess</code> <code class="o">=</code> <code class="p">[</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">()</code> <code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="n">m</code><code class="p">]</code>&#13;
&#13;
    <code class="k">while</code> <code class="bp">True</code><code class="p">:</code>&#13;
        <code class="n">result</code> <code class="o">=</code> <code class="n">matrix_times_vector</code><code class="p">(</code><code class="n">m</code><code class="p">,</code> <code class="n">guess</code><code class="p">)</code>    <code class="c1"># transform guess</code>&#13;
        <code class="n">norm</code> <code class="o">=</code> <code class="n">magnitude</code><code class="p">(</code><code class="n">result</code><code class="p">)</code>                  <code class="c1"># compute norm</code>&#13;
        <code class="n">next_guess</code> <code class="o">=</code> <code class="p">[</code><code class="n">x</code> <code class="o">/</code> <code class="n">norm</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">result</code><code class="p">]</code>   <code class="c1"># rescale</code>&#13;
&#13;
        <code class="k">if</code> <code class="n">distance</code><code class="p">(</code><code class="n">guess</code><code class="p">,</code> <code class="n">next_guess</code><code class="p">)</code> <code class="o">&lt;</code> <code class="n">tolerance</code><code class="p">:</code>&#13;
            <code class="c1"># convergence so return (eigenvector, eigenvalue)</code>&#13;
            <code class="k">return</code> <code class="n">next_guess</code><code class="p">,</code> <code class="n">norm</code>&#13;
&#13;
        <code class="n">guess</code> <code class="o">=</code> <code class="n">next_guess</code></pre>&#13;
&#13;
<p>By construction, the returned <code>guess</code> is a vector such that,&#13;
when you apply <code>matrix_times_vector</code> to it and rescale it to have length 1,&#13;
you get back a vector very close to itself—which means it’s an eigenvector.</p>&#13;
&#13;
<p>Not all matrices of real numbers have eigenvectors and eigenvalues.  For example, the matrix:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">rotate</code> <code class="o">=</code> <code class="p">[[</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code>&#13;
          <code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">]]</code></pre>&#13;
&#13;
<p>rotates vectors 90 degrees clockwise, which means that the only vector it maps to a scalar multiple of itself is a vector of zeros.  If you tried <code>find_eigenvector(rotate)</code> it would run forever.  Even matrices that have eigenvectors can sometimes get stuck in cycles.  Consider the matrix:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">flip</code> <code class="o">=</code> <code class="p">[[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code>&#13;
        <code class="p">[</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">]]</code></pre>&#13;
&#13;
<p>This matrix maps any vector <code>[x, y]</code> to <code>[y, x]</code>.  This means that, for example, <code>[1, 1]</code> is an eigenvector with eigenvalue 1.  However, if you start with a random vector with unequal coordinates, <code>find_eigenvector</code> will just repeatedly swap the coordinates forever. (Not-from-scratch libraries like NumPy use different methods that would work in this case.)  Nonetheless, when <code>find_eigenvector</code> does return a result, that result is indeed an eigenvector.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Centrality" data-type="sect2"><div class="sect2" id="idm45635713788712">&#13;
<h2>Centrality</h2>&#13;
&#13;
<p>How<a data-primary="eigenvector centrality" data-secondary="centrality" data-type="indexterm" id="idm45635713301800"/> does this help us understand the DataSciencester network? To start, we’ll need to represent the connections in our network as an <code>adjacency_matrix</code>, whose (<em>i</em>,<em>j</em>)th entry is either 1 (if user <em>i</em> and user <em>j</em> are friends) or 0 (if they’re not):</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">entry_fn</code><code class="p">(</code><code class="n">i</code><code class="p">:</code> <code class="nb">int</code><code class="p">,</code> <code class="n">j</code><code class="p">:</code> <code class="nb">int</code><code class="p">):</code>&#13;
    <code class="k">return</code> <code class="mi">1</code> <code class="k">if</code> <code class="p">(</code><code class="n">i</code><code class="p">,</code> <code class="n">j</code><code class="p">)</code> <code class="ow">in</code> <code class="n">friend_pairs</code> <code class="ow">or</code> <code class="p">(</code><code class="n">j</code><code class="p">,</code> <code class="n">i</code><code class="p">)</code> <code class="ow">in</code> <code class="n">friend_pairs</code> <code class="k">else</code> <code class="mi">0</code>&#13;
&#13;
<code class="n">n</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">users</code><code class="p">)</code>&#13;
<code class="n">adjacency_matrix</code> <code class="o">=</code> <code class="n">make_matrix</code><code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="n">n</code><code class="p">,</code> <code class="n">entry_fn</code><code class="p">)</code></pre>&#13;
&#13;
<p>The eigenvector centrality for each user is then the entry corresponding to that user in the eigenvector returned by <code>find_eigenvector</code> (<a data-type="xref" href="#network_sized_by_eigenvector">Figure 22-4</a>).</p>&#13;
&#13;
<figure><div class="figure" id="network_sized_by_eigenvector">&#13;
<img alt="The DataSciencester network sized by eigenvector centrality." src="assets/dsf2_2204.png"/>&#13;
<h6><span class="label">Figure 22-4. </span>The DataSciencester network sized by eigenvector centrality</h6>&#13;
</div></figure>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>For technical reasons that are way beyond the scope of this book, any nonzero adjacency matrix necessarily has an eigenvector, all of whose values are nonnegative. And fortunately for us, for this <code>adjacency_matrix</code> our <code>find_eigenvector</code> function finds it.</p>&#13;
</div>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">eigenvector_centralities</code><code class="p">,</code> <code class="n">_</code> <code class="o">=</code> <code class="n">find_eigenvector</code><code class="p">(</code><code class="n">adjacency_matrix</code><code class="p">)</code></pre>&#13;
&#13;
<p>Users with high eigenvector centrality should be those who have a lot of connections, and connections to people who themselves have high centrality.</p>&#13;
&#13;
<p>Here users 1 and 2 are the most central, as they both have three connections to people who are themselves highly central. As we move away from them, people’s centralities steadily drop off.</p>&#13;
&#13;
<p>On a network this small, eigenvector centrality behaves somewhat erratically.  If you try adding or subtracting links, you’ll find that small changes in the network can dramatically change the centrality numbers.  In a much larger network, this would not particularly be the case.</p>&#13;
&#13;
<p>We still haven’t motivated why an eigenvector might lead to a reasonable notion of centrality. Being an eigenvector means that if you compute:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">matrix_times_vector</code><code class="p">(</code><code class="n">adjacency_matrix</code><code class="p">,</code> <code class="n">eigenvector_centralities</code><code class="p">)</code></pre>&#13;
&#13;
<p>the result is a scalar multiple of <code>eigenvector_centralities</code>.</p>&#13;
&#13;
<p>If you look at how matrix multiplication works, <code>matrix_times_vector</code> produces a vector whose <em>i</em>th element is:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">dot</code><code class="p">(</code><code class="n">adjacency_matrix</code><code class="p">[</code><code class="n">i</code><code class="p">],</code> <code class="n">eigenvector_centralities</code><code class="p">)</code></pre>&#13;
&#13;
<p>which is precisely the sum of the eigenvector centralities of the users connected to user <em>i</em>.</p>&#13;
&#13;
<p>In other words, eigenvector centralities are numbers, one per user, such that each user’s value is a constant multiple of the sum of his neighbors’ values.  In this case centrality means being connected to people who themselves are central.  The more centrality you are directly connected to,&#13;
the more central you are.  This is of course a circular definition—eigenvectors are the way of breaking out of the circularity.</p>&#13;
&#13;
<p>Another way of understanding this is by thinking about what <code>find_eigenvector</code> is doing here.  It starts by assigning each node a random centrality.  It then repeats the following two steps until the process converges:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Give each node a new centrality score that equals the sum of its neighbors’ (old) centrality scores.</p>&#13;
</li>&#13;
<li>&#13;
<p>Rescale the vector of centralities to have magnitude 1.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>Although the mathematics behind it may seem somewhat opaque at first, the calculation itself is relatively straightforward (unlike, say, betweenness centrality) and is pretty easy to perform on even very large graphs. (At least, if you use a real linear algebra library it’s easy to perform on large graphs. If you used our matrices-as-lists implementation you’d struggle.)<a data-primary="" data-startref="NAeigen22" data-type="indexterm" id="idm45635713062472"/><a data-primary="" data-startref="Ceigen22" data-type="indexterm" id="idm45635713061496"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Directed Graphs and PageRank" data-type="sect1"><div class="sect1" id="idm45635713302872">&#13;
<h1>Directed Graphs and PageRank</h1>&#13;
&#13;
<p>DataSciencester<a data-primary="network analysis" data-secondary="directed graphs and PageRank" data-type="indexterm" id="idm45635713059224"/><a data-primary="directed graphs" data-type="indexterm" id="idm45635713058248"/><a data-primary="PageRank" data-type="indexterm" id="idm45635713057576"/> isn’t getting much traction, so the VP of Revenue considers pivoting from a friendship model to an endorsement model.  It turns out that no one particularly cares which data scientists are <em>friends</em> with one another, but tech recruiters care very much which data scientists are <em>respected</em> by other data scientists.</p>&#13;
&#13;
<p>In this new model, we’ll track endorsements <code>(source, target)</code> that no longer represent a reciprocal relationship, but rather that <code>source</code> endorses <code>target</code> as an awesome data scientist (<a data-type="xref" href="#datasciencester_network_endorsements">Figure 22-5</a>).</p>&#13;
&#13;
<figure><div class="figure" id="datasciencester_network_endorsements">&#13;
<img alt="The DataSciencester endorsement network." src="assets/dsf2_2205.png"/>&#13;
<h6><span class="label">Figure 22-5. </span>The DataSciencester network of endorsements</h6>&#13;
</div></figure>&#13;
&#13;
<p>We’ll need to account for this asymmetry:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">endorsements</code> <code class="o">=</code> <code class="p">[(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">),</code> <code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">),</code> <code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">2</code><code class="p">),</code> <code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="mi">0</code><code class="p">),</code> <code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">),</code>&#13;
                <code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="mi">1</code><code class="p">),</code> <code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">3</code><code class="p">),</code> <code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="mi">3</code><code class="p">),</code> <code class="p">(</code><code class="mi">3</code><code class="p">,</code> <code class="mi">4</code><code class="p">),</code> <code class="p">(</code><code class="mi">5</code><code class="p">,</code> <code class="mi">4</code><code class="p">),</code>&#13;
                <code class="p">(</code><code class="mi">5</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="p">(</code><code class="mi">7</code><code class="p">,</code> <code class="mi">5</code><code class="p">),</code> <code class="p">(</code><code class="mi">6</code><code class="p">,</code> <code class="mi">8</code><code class="p">),</code> <code class="p">(</code><code class="mi">8</code><code class="p">,</code> <code class="mi">7</code><code class="p">),</code> <code class="p">(</code><code class="mi">8</code><code class="p">,</code> <code class="mi">9</code><code class="p">)]</code></pre>&#13;
&#13;
<p>after which we can easily find the <code>most_endorsed</code> data scientists and sell that information to recruiters:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">Counter</code>&#13;
&#13;
<code class="n">endorsement_counts</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">target</code> <code class="k">for</code> <code class="n">source</code><code class="p">,</code> <code class="n">target</code> <code class="ow">in</code> <code class="n">endorsements</code><code class="p">)</code></pre>&#13;
&#13;
<p>However, “number of endorsements” is an easy metric to game.&#13;
All you need to do is create phony accounts and have them endorse you.  Or arrange with your friends to endorse each other.  (As users 0, 1, and 2 seem to have done.)</p>&#13;
&#13;
<p>A better metric would take into account <em>who</em> endorses you.&#13;
Endorsements from people who have a lot of endorsements should somehow count more&#13;
than endorsements from people with few endorsements.  This is the essence of the PageRank algorithm, used by Google to rank websites based on which other websites link to them, which other websites link to those, and so on.</p>&#13;
&#13;
<p>(If this sort of reminds you of the idea behind eigenvector centrality, it should.)</p>&#13;
&#13;
<p>A simplified version looks like this:</p>&#13;
<ol>&#13;
<li>&#13;
<p>There is a total of 1.0 (or 100%) PageRank in the network.</p>&#13;
</li>&#13;
<li>&#13;
<p>Initially this PageRank is equally distributed among nodes.</p>&#13;
</li>&#13;
<li>&#13;
<p>At each step, a large fraction of each node’s PageRank is distributed evenly among its outgoing links.</p>&#13;
</li>&#13;
<li>&#13;
<p>At each step, the remainder of each node’s PageRank is distributed evenly among all nodes.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">tqdm</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">page_rank</code><code class="p">(</code><code class="n">users</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="n">User</code><code class="p">],</code>&#13;
              <code class="n">endorsements</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="n">Tuple</code><code class="p">[</code><code class="nb">int</code><code class="p">,</code> <code class="nb">int</code><code class="p">]],</code>&#13;
              <code class="n">damping</code><code class="p">:</code> <code class="nb">float</code> <code class="o">=</code> <code class="mf">0.85</code><code class="p">,</code>&#13;
              <code class="n">num_iters</code><code class="p">:</code> <code class="nb">int</code> <code class="o">=</code> <code class="mi">100</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">int</code><code class="p">,</code> <code class="nb">float</code><code class="p">]:</code>&#13;
    <code class="c1"># Compute how many people each person endorses</code>&#13;
    <code class="n">outgoing_counts</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">target</code> <code class="k">for</code> <code class="n">source</code><code class="p">,</code> <code class="n">target</code> <code class="ow">in</code> <code class="n">endorsements</code><code class="p">)</code>&#13;
&#13;
    <code class="c1"># Initially distribute PageRank evenly</code>&#13;
    <code class="n">num_users</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">users</code><code class="p">)</code>&#13;
    <code class="n">pr</code> <code class="o">=</code> <code class="p">{</code><code class="n">user</code><code class="o">.</code><code class="n">id</code> <code class="p">:</code> <code class="mi">1</code> <code class="o">/</code> <code class="n">num_users</code> <code class="k">for</code> <code class="n">user</code> <code class="ow">in</code> <code class="n">users</code><code class="p">}</code>&#13;
&#13;
    <code class="c1"># Small fraction of PageRank that each node gets each iteration</code>&#13;
    <code class="n">base_pr</code> <code class="o">=</code> <code class="p">(</code><code class="mi">1</code> <code class="o">-</code> <code class="n">damping</code><code class="p">)</code> <code class="o">/</code> <code class="n">num_users</code>&#13;
&#13;
    <code class="k">for</code> <code class="nb">iter</code> <code class="ow">in</code> <code class="n">tqdm</code><code class="o">.</code><code class="n">trange</code><code class="p">(</code><code class="n">num_iters</code><code class="p">):</code>&#13;
        <code class="n">next_pr</code> <code class="o">=</code> <code class="p">{</code><code class="n">user</code><code class="o">.</code><code class="n">id</code> <code class="p">:</code> <code class="n">base_pr</code> <code class="k">for</code> <code class="n">user</code> <code class="ow">in</code> <code class="n">users</code><code class="p">}</code>  <code class="c1"># start with base_pr</code>&#13;
&#13;
        <code class="k">for</code> <code class="n">source</code><code class="p">,</code> <code class="n">target</code> <code class="ow">in</code> <code class="n">endorsements</code><code class="p">:</code>&#13;
            <code class="c1"># Add damped fraction of source pr to target</code>&#13;
            <code class="n">next_pr</code><code class="p">[</code><code class="n">target</code><code class="p">]</code> <code class="o">+=</code> <code class="n">damping</code> <code class="o">*</code> <code class="n">pr</code><code class="p">[</code><code class="n">source</code><code class="p">]</code> <code class="o">/</code> <code class="n">outgoing_counts</code><code class="p">[</code><code class="n">source</code><code class="p">]</code>&#13;
&#13;
        <code class="n">pr</code> <code class="o">=</code> <code class="n">next_pr</code>&#13;
&#13;
    <code class="k">return</code> <code class="n">pr</code></pre>&#13;
&#13;
<p>If we compute page ranks:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">pr</code> <code class="o">=</code> <code class="n">page_rank</code><code class="p">(</code><code class="n">users</code><code class="p">,</code> <code class="n">endorsements</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Thor (user_id 4) has higher page rank than anyone else</code>&#13;
<code class="k">assert</code> <code class="n">pr</code><code class="p">[</code><code class="mi">4</code><code class="p">]</code> <code class="o">&gt;</code> <code class="nb">max</code><code class="p">(</code><code class="n">page_rank</code>&#13;
                   <code class="k">for</code> <code class="n">user_id</code><code class="p">,</code> <code class="n">page_rank</code> <code class="ow">in</code> <code class="n">pr</code><code class="o">.</code><code class="n">items</code><code class="p">()</code>&#13;
                   <code class="k">if</code> <code class="n">user_id</code> <code class="o">!=</code> <code class="mi">4</code><code class="p">)</code></pre>&#13;
&#13;
<p>PageRank (<a data-type="xref" href="#network_sized_by_pagerank">Figure 22-6</a>) identifies user 4 (Thor) as the highest-ranked data scientist.</p>&#13;
&#13;
<figure><div class="figure" id="network_sized_by_pagerank">&#13;
<img alt="The DataSciencester network sized by PageRank." src="assets/dsf2_2206.png"/>&#13;
<h6><span class="label">Figure 22-6. </span>The DataSciencester network sized by PageRank</h6>&#13;
</div></figure>&#13;
&#13;
<p>Even though Thor has fewer endorsements (two) than users 0, 1, and 2, his endorsements carry with them rank from their endorsements.  Additionally, both of his endorsers endorsed only him, which means that he doesn’t have to divide their rank with anyone else.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="For Further Exploration" data-type="sect1"><div class="sect1" id="idm45635713060296">&#13;
<h1>For Further Exploration</h1>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>There<a data-primary="network analysis" data-secondary="resources for learning about" data-type="indexterm" id="idm45635712555400"/><a data-primary="centrality" data-secondary="other types of" data-type="indexterm" id="idm45635712554424"/> are <a href="http://en.wikipedia.org/wiki/Centrality">many other notions of centrality</a> besides the ones we used (although the ones we used are pretty much the most popular ones).</p>&#13;
</li>&#13;
<li>&#13;
<p><a href="http://networkx.github.io/">NetworkX</a> is a<a data-primary="network analysis" data-secondary="tools for" data-type="indexterm" id="idm45635712551176"/><a data-primary="NetworkX" data-type="indexterm" id="idm45635712550168"/> Python library for network analysis.  It has functions for computing centralities and for visualizing graphs.</p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://gephi.org/">Gephi</a> is<a data-primary="Gephi" data-type="indexterm" id="idm45635712547848"/> a love-it/hate-it GUI-based network visualization tool.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>