<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 11. Performing Sentiment Analysis on Text Data"><div class="chapter" id="ch-sentiment">
<h1><span class="label">Chapter 11. </span>Performing Sentiment Analysis <span class="keep-together">on Text Data</span></h1>

<p>In every <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="about" id="ch11_term1"/>interaction that we have in the real world, our brain subconsciously registers feedback not just in the words said but also using facial expressions, body language, and other physical cues. However, as more of our communication becomes digital, it increasingly appears in the form of text, where we do not have the possibility of evaluating physical cues. Therefore, it’s important to understand the mood or sentiment felt by a person through the text they write in order to form a complete understanding of their message.</p>

<p>For example, a lot of customer support is now automated through the use of a software ticketing system or even an automated chatbot. As a result, the only way to understand how a customer is feeling is by understanding the sentiment from their responses. Therefore, if we are dealing with a particularly irate customer, it’s important to be extra careful with our responses to not annoy them further. Similarly, if we want to understand what customers think about a particular product or brand, we can analyze the sentiment from their posts, comments, or reviews about that brand in social media channels and understand how they feel about the brand.</p>

<p>Understanding sentiment from text is challenging because there are several aspects that need to be inferred that are not directly evident. A simple example is the following customer review for a laptop purchased on Amazon:</p>

<blockquote>
	<p>This laptop is full of series problem. Its speed is exactly as per specifications which is very slow! Boot time is more.”</p>
</blockquote>


<p>If a human were to read it, they could detect the irony expressed about the speed of the laptop and the fact that it takes a long time to boot up, which leads us to conclude that this is a negative review. However, if we analyze only the text, it’s clear that <span class="keep-together">the speed</span> is exactly as specified. The fact that the boot time is high might also be <span class="keep-together">perceived</span> as a good thing unless we know that this is a parameter that needs to be small. The task of sentiment analysis is also specific to the type of text data being used. For example, a newspaper article is written in a structured manner, whereas tweets and other social media text follow a loose structure with the presence of slang and incorrect punctuation. As a result, there isn’t one blueprint that might work for every scenario. Instead, we will present a set of blueprints that can be used to produce a successful sentiment analysis.</p>

<section data-type="sect1" data-pdf-bookmark="What You’ll Learn and What We’ll Build"><div class="sect1" id="idm45634178874472">
<h1>What You’ll Learn and What We’ll Build</h1>


<p>In this chapter, we will explore multiple techniques to estimate the sentiment from a snippet of text data. We will start with simple rule-based techniques and work our way through more complex methods, finally using state-of-the-art language models such as BERT from Google. The purpose of walking through these techniques is to improve our understanding of customer sentiment and provide you with a set of blueprints that can be <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="use cases for" id="idm45634178872664"/><a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for sentiment analysis of text data" data-secondary-sortas="sentiment analysis of text data" id="idm45634178871272"/>used for various use cases. For example, combined with the Twitter API blueprint from <a data-type="xref" href="ch02.xhtml#ch-api">Chapter 2</a>, you could determine the public sentiment about a certain personality or political issue. You could also use these blueprints within your organization to analyze the sentiment in customer complaints or support emails and determine how happy your clients are.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Sentiment Analysis"><div class="sect1" id="idm45634178867880">
<h1>Sentiment Analysis</h1>

<p>A lot of information is available in the form of text, and based on the context of the communication, the information can be categorized into objective texts and subjective texts. <em>Objective texts</em> contain a simple statement of facts, like we might find in a textbook or Wikipedia article. Such texts generally present the facts and do not express an opinion or sentiment. <em>Subjective texts</em>, on the other hand, convey someone’s reaction or contain information about emotion, mood, or feelings. This might be typically found in social media channels in tweets or where customers express their opinions, such as in product reviews. We undertake a study of sentiment in order to understand the state of mind of an individual expressed through the medium of text. Therefore, sentiment analysis works best on subjective texts that contain this kind of information rather than objective texts. Before starting our analysis, we must ensure that we have the right kind of dataset that captures the sentiment information we are looking for.</p>

<p>The sentiment of a piece of text can be determined at the phrase, sentence, or document level. For example, if we take the case of a customer writing an email to a company, there will be several paragraphs, with each paragraph containing multiple sentences. Sentiment can be calculated for each sentence and also for each paragraph. While paragraph 1 may be positive, paragraphs 3 and 4 could be negative. So, if <span class="keep-together">we want</span> to determine the overall sentiment expressed by this customer, we would <span class="keep-together">have to</span> determine the best way to aggregate the sentiment for each paragraph up to <span class="keep-together">the document </span>level. In the blueprints that we present, we calculate sentiment at a <span class="keep-together">sentence</span> level.</p>

<p>The techniques for performing sentiment analysis can be <a contenteditable="false" data-type="indexterm" data-primary="supervised learning models" id="idm45634178860280"/>broken down into simple rule-based techniques and supervised machine learning approaches. Rule-based techniques are easier to apply since they do not require annotated training data. Supervised learning approaches provide better results but include the additional effort of labeling the data. There might be simple ways to work around this requirement as <span class="keep-together">we will</span> show in our use case. In this chapter, we will provide the following set of <span class="keep-together">blueprints</span>:</p>

<ul>
	<li>Sentiment analysis using lexicon-based approaches</li>
	<li>Sentiment analysis by building additional features from text data and applying a supervised machine learning algorithm</li>
	<li>Sentiment analysis using transfer learning technique <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term1" id="idm45634178855256"/>and pretrained language models like BERT</li>
</ul>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Introducing the Amazon Customer Reviews Dataset"><div class="sect1" id="idm45634178853336">
<h1>Introducing the Amazon Customer Reviews Dataset</h1>

<p>Let’s assume <a contenteditable="false" data-type="indexterm" data-primary="Amazon customer reviews dataset" id="ch11_term2"/><a contenteditable="false" data-type="indexterm" data-primary="datasets, examples of" data-secondary="Amazon customer reviews dataset" id="ch11_term3"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="datasets for" id="ch11_term4"/>you are an analyst working in the marketing department of a leading consumer electronics company and would like to know how your smartphone products compare with competitors. You can easily compare the technical specifications, but it is more interesting to understand the consumer perception of the product. You could determine this by analyzing the sentiment expressed by customers in product reviews on Amazon. Using the blueprints and aggregating the sentiment for each review for a brand, you would be able to identify how customers perceive each brand. Similarly, what if your company is looking to expand their business by introducing products in an adjacent category? You could analyze customer reviews for all products in a segment, such as media tablets, smartwatches, or action cameras, and based on the aggregated sentiment determine a segment with poor customer satisfaction and therefore higher potential success of your product.</p>

<p>For our blueprints, we will use a dataset containing a collection of Amazon customer reviews for different products across multiple product categories. This dataset of Amazon customer reviews has already been scraped and compiled by researchers at Stanford University.<sup><a data-type="noteref" id="idm45634178845144-marker" href="ch11.xhtml#idm45634178845144">1</a></sup> The <a href="https://oreil.ly/QcMIz">last updated version</a> consists of product reviews from the Amazon website between 1996 and 2018 across several categories. It includes product reviews, product ratings, and other information such as helpfulness votes and product metadata. For our blueprints, we are going to focus on product reviews and use only those that are one sentence long. This is to keep the blueprint simple and remove the step of aggregation. A review containing multiple sentences can include both positive and negative sentiment. Therefore, if we tag all sentences in a review with the same sentiment, this would be incorrect. We only use data for some of the categories so that it can fit in memory and reduce processing time. This dataset has already been prepared, but you can refer to the <code>Data_Preparation</code> notebook present in the repository to understand the steps and possibly extend it. The blueprints work on any kind of dataset, and therefore if you have access to powerful hardware or cloud infrastructure, then you can choose more categories.</p>

<p>Let’s now take a look at the dataset:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">df</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">read_json</code><code class="p">(</code><code class="s1">'reviews.json'</code><code class="p">,</code> <code class="n">lines</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<table class="dataframe">
	<thead>
		<tr>
			<th> </th>
			<th>overall</th>
			<th>verified</th>
			<th>reviewerID</th>
			<th>asin</th>
			<th>text</th>
			<th>summary</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>163807</th>
			<td>5</td>
			<td>False</td>
			<td>A2A8GHFXUG1B28</td>
			<td>B0045Z4JAI</td>
			<td>Good Decaf... it has a good flavour for a decaf :)</td>
			<td>Nice!</td>
		</tr>
		<tr>
			<th>195640</th>
			<td>5</td>
			<td>True</td>
			<td>A1VU337W6PKAR3</td>
			<td>B00K0TIC56</td>
			<td>I could not ask for a better system for my small greenhouse, easy to set up and nozzles do very well</td>
			<td>I could not ask for a better system for my small greenhouse</td>
		</tr>
		<tr>
			<th>167820</th>
			<td>4</td>
			<td>True</td>
			<td>A1Z5TT1BBSDLRM</td>
			<td>B0012ORBT6</td>
			<td>good product at a good price and saves a trip to the store</td>
			<td>Four Stars</td>
		</tr>
		<tr>
			<th>104268</th>
			<td>1</td>
			<td>False</td>
			<td>A4PRXX2G8900X</td>
			<td>B005SPI45U</td>
			<td>I like the principle of a raw chip - something I can eat with my homemade salsa and guac - but these taste absolutely revolting.</td>
			<td>No better alternatives but still tastes bad.</td>
		</tr>
		<tr>
			<th>51961</th>
			<td>1</td>
			<td>True</td>
			<td>AYETYLNYDIS2S</td>
			<td>B00D1HLUP8</td>
			<td>Fake China knockoff, you get what you pay for.</td>
			<td>Definitely not OEM</td>
		</tr>
	</tbody>
</table>

<p>Looking at a summary of the dataset, we can see that it contains the following <span class="keep-together">columns</span>:</p>

<dl>
<dt>Overall</dt>
  <dd>This is the final rating provided by the reviewer to the product. Ranges from 1 (lowest) to 5 (highest).</dd>
<dt>Verified</dt>
  <dd>This indicates whether the product purchase has been verified by Amazon.</dd>
<dt>ReviewerID</dt>
  <dd>This is the unique identifier allocated by Amazon to each reviewer.</dd>
<dt>ASIN</dt>
  <dd>This is a unique product code that Amazon uses to identify the product.</dd>
<dt>Text</dt>
  <dd>The actual text in the review provided by the user.</dd>
<dt>Summary</dt>
  <dd>This is the headline or summary of the review that the user provided.</dd>
</dl>

<p>The column <code>text</code> contains the main content of the customer review and expresses the user’s opinion. While the rest of the information can be useful, we will focus on using this <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term2" id="idm45634178766472"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term3" id="idm45634178765064"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term4" id="idm45634178763688"/>column in the blueprints.</p>
</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Performing Sentiment Analysis Using Lexicon-Based Approaches"><div class="sect1" id="idm45634178852744">
<h1>Blueprint: Performing Sentiment Analysis Using Lexicon-Based Approaches</h1>

<p>As an analyst <a contenteditable="false" data-type="indexterm" data-primary="lexicon-based approaches for sentiment analysis" id="ch11_term5"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="lexicon-based approaches for " id="ch11_term6"/>working on the Amazon customer reviews data, the first challenge that might come up is the absence of target labels. We do not automatically know whether a particular review is positive or negative. Does the text express happiness because the product worked perfectly or anger because the product has broken at the first use? We cannot determine this until we actually read the review. This is challenging because we would have to read close to 300,000 reviews and manually assign a target sentiment to each of the reviews. We overcome this problem by using a lexicon-based approach.</p>

<p>What is a lexicon? A <em>lexicon</em> is like a dictionary that contains a collection of words and has been compiled using expert knowledge. The key differentiating factor for a lexicon is that it incorporates specific knowledge and has been collected for a specific purpose. We will use sentiment lexicons that contain commonly used words and capture the sentiment associated with them. A simple example of this is the word <em>happy</em>, with a sentiment score of 1, and another is the word <em>frustrated</em>, which would have a score of -1. Several standardized lexicons are available for the English language, and the popular ones are AFINN Lexicon, SentiWordNet, Bing Liu’s lexicon, and VADER lexicon, among others. They differ from each other in the size of their vocabulary and their representation. For example, the <a href="https://oreil.ly/YZ9WB">AFINN Lexicon</a> comes in the form of a single dictionary with 3,300 words, with each word assigned <span class="keep-together">a signed</span> sentiment score ranging from -3 to +3. Negative/positive indicate the polarity, and the magnitude indicates the strength. On the other hand, if we look at <a href="https://oreil.ly/jTj_u">Bing Liu lexicon</a>, it comes in the form of two lists: one for positive words and another for negative, with a combined vocabulary of 6,800 words. Most <span class="keep-together">sentiment</span> lexicons are available for English, but there are also lexicons available for German<sup><a data-type="noteref" id="idm45634178750888-marker" href="ch11.xhtml#idm45634178750888">2</a></sup> and for 81 other languages as generated by this research paper.<sup><a data-type="noteref" id="idm45634178748968-marker" href="ch11.xhtml#idm45634178748968">3</a></sup></p>

<p>The sentiment of a sentence or phrase is determined by first identifying the sentiment score for each word from the chosen lexicon and then adding them up to arrive at the overall sentiment. By using this technique, we avoid the need to manually look at each review and assign the sentiment label. Instead, we rely on the lexicon that provides expert sentiment scores for each word. For our first blueprint, we will use the Bing Liu lexicon, but you are free to extend the blueprint to use other lexicons as well. The lexicons normally contain several variants of the word and exclude stop words, and therefore the standard preprocessing steps are not essential in this approach. Only those words that are present in the lexicon will actually be scored. This also leads to one of the disadvantages of this method, which we will discuss at the end of the blueprint.</p>

<section data-type="sect2" data-pdf-bookmark="Bing Liu Lexicon"><div class="sect2" id="idm45634178745288">
<h2>Bing Liu Lexicon</h2>

<p>The Bing <a contenteditable="false" data-type="indexterm" data-primary="Bing Liu lexicon " id="ch11_term7"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="Bing Liu lexicon for" id="ch11_term8"/>Liu lexicon has been compiled by dividing the words into those that express positive opinion and those that express negative opinion. This lexicon also contains misspelled words and is more suitable to be used on text that has been extracted from online discussion forums, social media, and other such sources and should therefore produce better results on the Amazon customer reviews data.</p>

<p>The Bing Liu lexicon is available from the authors’ website as a <a href="https://oreil.ly/A_O4Q">zip file</a> that contains a set of positive and negative words. It is also available within the NLTK library as a corpus that we can use after downloading. Once we have extracted the lexicon, we will create a dictionary that can hold the lexicon words and their corresponding sentiment score. Our next step is to generate the score for each review in our dataset. We convert the contents of text to lowercase first; then <a contenteditable="false" data-type="indexterm" data-primary="word_tokenize function" id="idm45634178738424"/>using the <code>word_tokenize</code> function from the NLTK package, we split the sentence into words and check whether this word is part of our lexicon, and if so, we add the corresponding sentiment score of the word to the total sentiment score for the review. As the final step, we normalize this score based on the number of words in the sentence. This functionality is encapsulated in the function <code>bing_liu_score</code> and is applied to every review in our dataset:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">nltk.corpus</code> <code class="kn">import</code> <code class="n">opinion_lexicon</code>
<code class="kn">from</code> <code class="nn">nltk.tokenize</code> <code class="kn">import</code> <code class="n">word_tokenize</code>
<code class="n">nltk</code><code class="o">.</code><code class="n">download</code><code class="p">(</code><code class="s1">'opinion_lexicon'</code><code class="p">)</code>

<code class="k">print</code><code class="p">(</code><code class="s1">'Total number of words in opinion lexicon'</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">opinion_lexicon</code><code class="o">.</code><code class="n">words</code><code class="p">()))</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Examples of positive words in opinion lexicon'</code><code class="p">,</code>
      <code class="n">opinion_lexicon</code><code class="o">.</code><code class="n">positive</code><code class="p">()[:</code><code class="mi">5</code><code class="p">])</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Examples of negative words in opinion lexicon'</code><code class="p">,</code>
      <code class="n">opinion_lexicon</code><code class="o">.</code><code class="n">negative</code><code class="p">()[:</code><code class="mi">5</code><code class="p">])</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Total number of words in opinion lexicon 6789
Examples of positive words in opinion lexicon ['a+', 'abound', 'abounds',
'abundance', 'abundant']
Examples of negative words in opinion lexicon ['2-faced', '2-faces',
'abnormal', 'abolish', 'abominable']
</pre>

Then:

<pre data-code-language="python" data-type="programlisting">
<code class="c1"># Let's create a dictionary which we can use for scoring our review text</code>
<code class="n">df</code><code class="o">.</code><code class="n">rename</code><code class="p">(</code><code class="n">columns</code><code class="o">=</code><code class="p">{</code><code class="s2">"reviewText"</code><code class="p">:</code> <code class="s2">"text"</code><code class="p">},</code> <code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">pos_score</code> <code class="o">=</code> <code class="mi">1</code>
<code class="n">neg_score</code> <code class="o">=</code> <code class="o">-</code><code class="mi">1</code>
<code class="n">word_dict</code> <code class="o">=</code> <code class="p">{}</code>

<code class="c1"># Adding the positive words to the dictionary</code>
<code class="k">for</code> <code class="n">word</code> <code class="ow">in</code> <code class="n">opinion_lexicon</code><code class="o">.</code><code class="n">positive</code><code class="p">():</code>
        <code class="n">word_dict</code><code class="p">[</code><code class="n">word</code><code class="p">]</code> <code class="o">=</code> <code class="n">pos_score</code>

<code class="c1"># Adding the negative words to the dictionary</code>
<code class="k">for</code> <code class="n">word</code> <code class="ow">in</code> <code class="n">opinion_lexicon</code><code class="o">.</code><code class="n">negative</code><code class="p">():</code>
        <code class="n">word_dict</code><code class="p">[</code><code class="n">word</code><code class="p">]</code> <code class="o">=</code> <code class="n">neg_score</code>

<code class="k">def</code> <code class="nf">bing_liu_score</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>
    <code class="n">sentiment_score</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="n">bag_of_words</code> <code class="o">=</code> <code class="n">word_tokenize</code><code class="p">(</code><code class="n">text</code><code class="o">.</code><code class="n">lower</code><code class="p">())</code>
    <code class="k">for</code> <code class="n">word</code> <code class="ow">in</code> <code class="n">bag_of_words</code><code class="p">:</code>
        <code class="k">if</code> <code class="n">word</code> <code class="ow">in</code> <code class="n">word_dict</code><code class="p">:</code>
            <code class="n">sentiment_score</code> <code class="o">+=</code> <code class="n">word_dict</code><code class="p">[</code><code class="n">word</code><code class="p">]</code>
    <code class="k">return</code> <code class="n">sentiment_score</code> <code class="o">/</code> <code class="nb">len</code><code class="p">(</code><code class="n">bag_of_words</code><code class="p">)</code>
</pre>

<pre data-code-language="python" data-type="programlisting">
<code class="n">df</code><code class="p">[</code><code class="s1">'Bing_Liu_Score'</code><code class="p">]</code> <code class="o">=</code> <code class="n">df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">bing_liu_score</code><code class="p">)</code>
<code class="n">df</code><code class="p">[[</code><code class="s1">'asin'</code><code class="p">,</code><code class="s1">'text'</code><code class="p">,</code><code class="s1">'Bing_Liu_Score'</code><code class="p">]]</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>


<table class="dataframe">
	<thead>
		<tr>
			<th> </th>
			<th>asin</th>
			<th>text</th>
			<th>Bing_Liu_Score</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>188097</th>
			<td>B00099QWOU</td>
			<td>As expected</td>
			<td>0.00</td>
		</tr>
		<tr>
			<th>184654</th>
			<td>B000RW1XO8</td>
			<td>Works as designed...</td>
			<td>0.25</td>
		</tr>
	</tbody>
</table>

<p>Now that we have calculated the sentiment score, we would like to check whether the calculated score matches the expectation based on the rating provided by the customer. Instead of checking this for each review, we could compare the sentiment score across reviews that have different ratings. We would expect that a review that has a five-star rating would have a higher sentiment score than a review with a one-star rating. In the next step, we scale the score for each review between 1 and -1 and compute the average sentiment scores across all reviews for each type of star rating:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">df</code><code class="p">[</code><code class="s1">'Bing_Liu_Score'</code><code class="p">]</code> <code class="o">=</code> <code class="n">preprocessing</code><code class="o">.</code><code class="n">scale</code><code class="p">(</code><code class="n">df</code><code class="p">[</code><code class="s1">'Bing_Liu_Score'</code><code class="p">])</code>
<code class="n">df</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s1">'overall'</code><code class="p">)</code><code class="o">.</code><code class="n">agg</code><code class="p">({</code><code class="s1">'Bing_Liu_Score'</code><code class="p">:</code><code class="s1">'mean'</code><code class="p">})</code>
</pre>

<p><code>Out:</code></p>

<table class="dataframe">
	<thead>
		<tr>
			<th>overall</th>
			<th>Bing_Liu_Score</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>1</th>
			<td>-0.587061</td>
		</tr>
		<tr>
			<th>2</th>
			<td>-0.426529</td>
		</tr>
		<tr>
			<th>4</th>
			<td>0.344645</td>
		</tr>
		<tr>
			<th>5</th>
			<td>0.529065</td>
		</tr>
	</tbody>
</table>

<p>The previous blueprint allows us to use any kind of sentiment lexicon to quickly determine a sentiment score and can also serve as a baseline to compare other sophisticated techniques, which should improve the <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term7" id="idm45634178420504"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term8" id="idm45634178419128"/>accuracy of sentiment prediction.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Disadvantages of a Lexicon-Based Approach"><div class="sect2" id="idm45634178744632">
<h2>Disadvantages of a Lexicon-Based Approach</h2>

<p>While the lexicon-based approach is simple, it has some obvious disadvantages that we observed:</p>

<ul>
	<li>First, we are bound by the size of the lexicon; if a word does not exist in the chosen lexicon, then we are unable to use this information while determining the sentiment score for this review. In the ideal scenario, we would like to use a lexicon that captures all the words in the language, but this is not feasible.</li>
	<li>Second, we assume that the chosen lexicon is a gold standard and trust the sentiment score/polarity provided by the author(s). This is a problem because a <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="use cases for" id="idm45634178414584"/><a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for sentiment analysis of text data" data-secondary-sortas="sentiment analysis of text data" id="idm45634178413240"/>particular lexicon may not be the right fit for a given use case. In the previous example, the Bing Liu lexicon is relevant because it captures the online usage of language and includes common typos and slang in its lexicon. But if we were working on a dataset of tweets, then the <a contenteditable="false" data-type="indexterm" data-primary="VADER lexicon" id="idm45634178411224"/>VADER lexicon would be better suited since it includes support for popular acronyms (e.g., LOL) and emojis.</li>
	<li>Finally, one of the biggest disadvantages of lexicons is that they overlook negation. Since the lexicon only matches words and not phrases, this would result in <span class="keep-together">a negative</span> score for a sentence that contains <em>not bad</em> when it actually is more <span class="keep-together">neutral</span>.</li>
</ul>

<p>To improve <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term5" id="idm45634178381464"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term6" id="idm45634178380248"/>our sentiment detection, we must explore the use of supervised machine learning approaches.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Supervised Learning Approaches"><div class="sect1" id="idm45634178378408">
<h1>Supervised Learning Approaches</h1>

<p>The use of a <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="supervised learning approaches to" id="ch11_term11"/><a contenteditable="false" data-type="indexterm" data-primary="supervised learning models" id="ch11_term12"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="in supervised learning" data-secondary-sortas="supervised learning" id="ch11_term16"/>supervised learning approach is beneficial because it allows us to model the patterns in the data and create a prediction function that is close to reality. It also gives us the flexibility to choose from different techniques and identify the one that provides maximum accuracy. A more detailed overview of supervised machine learning is provided in <a data-type="xref" href="ch06.xhtml#ch-classification">Chapter 6</a>.</p>

<p>To use such an approach, we would need labeled data that may not be easily available. Often, it involves two or more human annotators looking at each review and determining the sentiment. If the annotators do not agree, then a third annotator might be needed to break the deadlock. It is common to have five annotators, with three of them agreeing on the opinion to confirm the label. This can be tedious and expensive but is the preferred approach when working with real business problems.</p>

<p>However, in many cases we will be able to test a supervised learning approach without going through the expensive labeling process. A simpler option is to check for any proxy indicators within the data that might help us annotate it automatically. Let’s illustrate this in the case of the Amazon reviews. If somebody has given a five-star product rating, then we can assume that they liked the product they used, and this should be reflected in their review. Similarly, if somebody has provided a one-star rating for a product, then they are dissatisfied with it and would have some negative things to say. Therefore, we could use the product rating as a proxy measure of whether a particular review would be positive or negative. The higher the rating, the more positive a particular review should be.</p>

<section data-type="sect2" data-pdf-bookmark="Preparing Data for a Supervised Learning Approach"><div class="sect2" id="idm45634178368136">
<h2>Preparing Data for a Supervised Learning Approach</h2>

<p>Therefore, as the <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="datasets for" id="idm45634178366600"/>first step in converting our dataset into a supervised machine learning problem, we will automatically annotate our reviews using the rating. We have chosen to annotate all reviews with a rating of 4 and 5 as positive and with ratings <span class="keep-together">1 and 2</span> as negative based on the reasoning provided earlier. In the data preparation process, we also filtered out reviews with a rating of 3 to provide a clearer separation between positive and negative reviews. This step can be tailored based on your <span class="keep-together">use case</span>.</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">df</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">read_json</code><code class="p">(</code><code class="s1">'reviews.json'</code><code class="p">,</code> <code class="n">lines</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>

<code class="c1"># Assigning a new [1,0] target class label based on the product rating</code>
<code class="n">df</code><code class="p">[</code><code class="s1">'sentiment'</code><code class="p">]</code> <code class="o">=</code> <code class="mi">0</code>
<code class="n">df</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">df</code><code class="p">[</code><code class="s1">'overall'</code><code class="p">]</code> <code class="o">&gt;</code> <code class="mi">3</code><code class="p">,</code> <code class="s1">'sentiment'</code><code class="p">]</code> <code class="o">=</code> <code class="mi">1</code>
<code class="n">df</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">df</code><code class="p">[</code><code class="s1">'overall'</code><code class="p">]</code> <code class="o">&lt;</code> <code class="mi">3</code><code class="p">,</code> <code class="s1">'sentiment'</code><code class="p">]</code> <code class="o">=</code> <code class="mi">0</code>

<code class="c1"># Removing unnecessary columns to keep a simple DataFrame</code>
<code class="n">df</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="n">columns</code><code class="o">=</code><code class="p">[</code>
    <code class="s1">'reviewTime'</code><code class="p">,</code> <code class="s1">'unixReviewTime'</code><code class="p">,</code> <code class="s1">'overall'</code><code class="p">,</code> <code class="s1">'reviewerID'</code><code class="p">,</code> <code class="s1">'summary'</code><code class="p">],</code>
        <code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">3</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<table class="dataframe">
	<thead>
		<tr>
			<th> </th>
			<th>verified</th>
			<th>asin</th>
			<th>text</th>
			<th>sentiment</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>176400</th>
			<td>True</td>
			<td>B000C5BN72</td>
			<td>everything was as listed and is in use all appear to be in good working order</td>
			<td>1</td>
		</tr>
		<tr>
			<th>65073</th>
			<td>True</td>
			<td>B00PK03IVI</td>
			<td>this is not the product i received.</td>
			<td>0</td>
		</tr>
		<tr>
			<th>254348</th>
			<td>True</td>
			<td>B004AIKVPC</td>
			<td>Just like the dealership part.</td>
			<td>1</td>
		</tr>
	</tbody>
</table>

<p>As you can see from the selection of reviews presented, we have created a new column named <code>sentiment</code> that contains a value of 1 or 0 depending on the rating provided by the user. We can now treat this as a supervised machine learning problem where we will use the content present in <code>text</code> to predict the sentiment: positive (1) or negative (0).</p>
</div></section>
</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Vectorizing Text Data and Applying a Supervised Machine Learning Algorithm"><div class="sect1" id="idm45634178270072">
<h1>Blueprint: Vectorizing Text Data and Applying a Supervised Machine Learning Algorithm</h1>

<p>In this blueprint, we will <a contenteditable="false" data-type="indexterm" data-primary="machine learning models" data-secondary="for sentiment analysis " data-secondary-sortas="sentiment analysis" id="ch11_term13"/><a contenteditable="false" data-type="indexterm" data-primary="vectorizers/vectorization" data-secondary="of text data for sentiment analysis" data-secondary-sortas="text data for sentiment analysis" id="ch11_term15"/>build a supervised machine learning algorithm by first cleaning the text data, then performing vectorization, and finally applying a support vector machine model for the classification.</p>

<section data-type="sect2" data-pdf-bookmark="Step 1: Data Preparation"><div class="sect2" id="idm45634178263960">
<h2>Step 1: Data Preparation</h2>

<p>To preprocess the <a contenteditable="false" data-type="indexterm" data-primary="cleaning text data" id="idm45634178262424"/><a contenteditable="false" data-type="indexterm" data-primary="data cleaning" id="idm45634178261288"/><a contenteditable="false" data-type="indexterm" data-primary="regex library (Python)" id="idm45634178260184"/>data, we will apply the regex blueprint from <a data-type="xref" href="ch04.xhtml#ch-preparation">Chapter 4</a> to remove any special characters, HTML tags, and URLs:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">df</code><code class="p">[</code><code class="s1">'text_orig'</code><code class="p">]</code> <code class="o">=</code> <code class="n">df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code>
<code class="n">df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code> <code class="o">=</code> <code class="n">df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">clean</code><code class="p">)</code>
</pre>

<p>Then, we will <a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="NLP pipeline for" id="idm45634178239800"/><a contenteditable="false" data-type="indexterm" data-primary="pipelines" id="idm45634178238584"/><a contenteditable="false" data-type="indexterm" data-primary="data preprocessing" data-secondary="pipelines for" id="idm45634178188232"/>apply the data preparation blueprint from the same chapter that uses the spaCy pipeline. This ensures that the text is standardized to lowercase, does not include numerals and punctuations, and is in a format that can be used by subsequent steps. Please note that it might take a couple of minutes to complete execution. In a few cases, it’s possible that all tokens in a review are removed during the cleaning step, and it doesn’t make sense to include such reviews anymore:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">df</code><code class="p">[</code><code class="s2">"text"</code><code class="p">]</code> <code class="o">=</code> <code class="n">df</code><code class="p">[</code><code class="s2">"text"</code><code class="p">]</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">clean_text</code><code class="p">)</code>

<code class="c1"># Remove observations that are empty after the cleaning step</code>
<code class="n">df</code> <code class="o">=</code> <code class="n">df</code><code class="p">[</code><code class="n">df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code><code class="o">.</code><code class="n">str</code><code class="o">.</code><code class="n">len</code><code class="p">()</code> <code class="o">!=</code> <code class="mi">0</code><code class="p">]</code>
</pre>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Step 2: Train-Test Split"><div class="sect2" id="idm45634178137528">
<h2>Step 2: Train-Test Split</h2>

<p>We split the <a contenteditable="false" data-type="indexterm" data-primary="train-test split" id="idm45634178118072"/>data so that the next step of vectorization is performed using <a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="data for" id="idm45634178116840"/>only the training dataset. We create an 80-20 split of the data and confirm that the positive and negative classes show a similar distribution across the two splits by specifying the target variable, sentiment, as the <code>stratify</code> argument:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">train_test_split</code>
<code class="n">X_train</code><code class="p">,</code> <code class="n">X_test</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">,</code> <code class="n">Y_test</code> <code class="o">=</code> <code class="n">train_test_split</code><code class="p">(</code><code class="n">df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">],</code>
                                                    <code class="n">df</code><code class="p">[</code><code class="s1">'sentiment'</code><code class="p">],</code>
                                                    <code class="n">test_size</code><code class="o">=</code><code class="mf">0.2</code><code class="p">,</code>
                                                    <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">,</code>
                                                    <code class="n">stratify</code><code class="o">=</code><code class="n">df</code><code class="p">[</code><code class="s1">'sentiment'</code><code class="p">])</code>

<code class="k">print</code> <code class="p">(</code><code class="s1">'Size of Training Data '</code><code class="p">,</code> <code class="n">X_train</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Size of Test Data '</code><code class="p">,</code> <code class="n">X_test</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>

<code class="k">print</code> <code class="p">(</code><code class="s1">'Distribution of classes in Training Data :'</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Positive Sentiment '</code><code class="p">,</code> <code class="nb">str</code><code class="p">(</code><code class="nb">sum</code><code class="p">(</code><code class="n">Y_train</code> <code class="o">==</code> <code class="mi">1</code><code class="p">)</code><code class="o">/</code> <code class="nb">len</code><code class="p">(</code><code class="n">Y_train</code><code class="p">)</code> <code class="o">*</code> <code class="mf">100.0</code><code class="p">))</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Negative Sentiment '</code><code class="p">,</code> <code class="nb">str</code><code class="p">(</code><code class="nb">sum</code><code class="p">(</code><code class="n">Y_train</code> <code class="o">==</code> <code class="mi">0</code><code class="p">)</code><code class="o">/</code> <code class="nb">len</code><code class="p">(</code><code class="n">Y_train</code><code class="p">)</code> <code class="o">*</code> <code class="mf">100.0</code><code class="p">))</code>

<code class="k">print</code> <code class="p">(</code><code class="s1">'Distribution of classes in Testing Data :'</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Positive Sentiment '</code><code class="p">,</code> <code class="nb">str</code><code class="p">(</code><code class="nb">sum</code><code class="p">(</code><code class="n">Y_test</code> <code class="o">==</code> <code class="mi">1</code><code class="p">)</code><code class="o">/</code> <code class="nb">len</code><code class="p">(</code><code class="n">Y_test</code><code class="p">)</code> <code class="o">*</code> <code class="mf">100.0</code><code class="p">))</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Negative Sentiment '</code><code class="p">,</code> <code class="nb">str</code><code class="p">(</code><code class="nb">sum</code><code class="p">(</code><code class="n">Y_test</code> <code class="o">==</code> <code class="mi">0</code><code class="p">)</code><code class="o">/</code> <code class="nb">len</code><code class="p">(</code><code class="n">Y_test</code><code class="p">)</code> <code class="o">*</code> <code class="mf">100.0</code><code class="p">))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Size of Training Data  234108
Size of Test Data  58527
Distribution of classes in Training Data :
Positive Sentiment  50.90770071932612
Negative Sentiment  49.09229928067388
Distribution of classes in Testing Data :
Positive Sentiment  50.9081278726058
Negative Sentiment  49.09187212739419
</pre>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Step 3: Text Vectorization"><div class="sect2" id="idm45634178111080">
<h2>Step 3: Text Vectorization</h2>

<p>The next step is where we convert the cleaned text to usable features. Machine learning models do not understand text data and are capable of working only with numeric data. We <a contenteditable="false" data-type="indexterm" data-primary="TF-IDF (Term-Frequency Inverse Document Frequency) weighting" data-secondary="vectorization with" id="idm45634177948728"/><a contenteditable="false" data-type="indexterm" data-primary="vectorizers/vectorization" data-secondary="with TF-IDF weighting" data-secondary-sortas="TF-IDF weighting" id="idm45634177947352"/>reuse the TF-IDF vectorization blueprint from <a data-type="xref" href="ch05.xhtml#ch-vectorization">Chapter 5</a> to create the vectorized representation. We select the <a contenteditable="false" data-type="indexterm" data-primary="min_df parameter" id="idm45634177944648"/>parameters of <code>min_df</code> as 10 and do not include bigrams. In addition, our previous step has already removed stop words, and therefore we do not need to take care of this during vectorization. We will use the same vectorizer to transform the test split, which will be used during evaluation:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sklearn.feature_extraction.text</code> <code class="kn">import</code> <code class="n">TfidfVectorizer</code>

<code class="n">tfidf</code> <code class="o">=</code> <code class="n">TfidfVectorizer</code><code class="p">(</code><code class="n">min_df</code> <code class="o">=</code> <code class="mi">10</code><code class="p">,</code> <code class="n">ngram_range</code><code class="o">=</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code class="mi">1</code><code class="p">))</code>
<code class="n">X_train_tf</code> <code class="o">=</code> <code class="n">tfidf</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>
<code class="n">X_test_tf</code> <code class="o">=</code> <code class="n">tfidf</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code>
</pre>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Step 4: Training the Machine Learning Model"><div class="sect2" id="idm45634177872696">
<h2>Step 4: Training the Machine Learning Model</h2>

<p>As described in <a data-type="xref" href="ch06.xhtml#ch-classification">Chapter 6</a>, support <a contenteditable="false" data-type="indexterm" data-primary="SVM (support vector machine) algorithm" id="idm45634177901544"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning models" data-secondary="training of" id="ch11_term17"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="of machine learning models" data-secondary-sortas="machine learning models" id="ch11_term18"/>vector machines are the preferred machine learning algorithms when working with text data. SVMs are known to work well with datasets with a large number of numeric features, and in particular <a contenteditable="false" data-type="indexterm" data-primary="LinearSVC model training" id="idm45634177896568"/>the LinearSVC module we use is quite fast. We can also select tree-based methods like random forest or XGBoost, but in our experience the accuracy is comparable, and thanks to quick training times, experimentation can be faster:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sklearn.svm</code> <code class="kn">import</code> <code class="n">LinearSVC</code>

<code class="n">model1</code> <code class="o">=</code> <code class="n">LinearSVC</code><code class="p">(</code><code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">,</code> <code class="n">tol</code><code class="o">=</code><code class="mf">1e-5</code><code class="p">)</code>
<code class="n">model1</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_tf</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=42, tol=1e-05,
          verbose=0)
</pre>

<p>Then:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">accuracy_score</code>
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">roc_auc_score</code>

<code class="n">Y_pred</code> <code class="o">=</code> <code class="n">model1</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test_tf</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Accuracy Score - '</code><code class="p">,</code> <code class="n">accuracy_score</code><code class="p">(</code><code class="n">Y_test</code><code class="p">,</code> <code class="n">Y_pred</code><code class="p">))</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'ROC-AUC Score - '</code><code class="p">,</code> <code class="n">roc_auc_score</code><code class="p">(</code><code class="n">Y_test</code><code class="p">,</code> <code class="n">Y_pred</code><code class="p">))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Accuracy Score -  0.8658396979172006
ROC-AUC Score -  0.8660667427476778
</pre>

<p>As we can see, this model achieves an accuracy of around 86%. Let’s look at some of the model predictions and the review text to perform a sense check of the model:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">sample_reviews</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code>
<code class="n">sample_reviews_tf</code> <code class="o">=</code> <code class="n">tfidf</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">sample_reviews</code><code class="p">[</code><code class="s1">'text'</code><code class="p">])</code>
<code class="n">sentiment_predictions</code> <code class="o">=</code> <code class="n">model1</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">sample_reviews_tf</code><code class="p">)</code>
<code class="n">sentiment_predictions</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code> <code class="o">=</code> <code class="n">sentiment_predictions</code><code class="p">,</code>
                                     <code class="n">index</code><code class="o">=</code><code class="n">sample_reviews</code><code class="o">.</code><code class="n">index</code><code class="p">,</code>
                                     <code class="n">columns</code><code class="o">=</code><code class="p">[</code><code class="s1">'sentiment_prediction'</code><code class="p">])</code>
<code class="n">sample_reviews</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">sample_reviews</code><code class="p">,</code> <code class="n">sentiment_predictions</code><code class="p">],</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Some sample reviews with their sentiment - '</code><code class="p">)</code>
<code class="n">sample_reviews</code><code class="p">[[</code><code class="s1">'text_orig'</code><code class="p">,</code><code class="s1">'sentiment_prediction'</code><code class="p">]]</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Some sample reviews with their sentiment -
</pre>

<table class="dataframe">
	<thead>
		<tr>
			<th> </th>
			<th>text_orig</th>
			<th>sentiment_prediction</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<th>29500</th>
			<td>Its a nice night light, but not much else apparently!</td>
			<td>1</td>
		</tr>
		<tr>
			<th>98387</th>
			<td>Way to small, do not know what to do with them or how to use them</td>
			<td>0</td>
		</tr>
		<tr>
			<th>113648</th>
			<td>Didn’t make the room “blue” enough - returned with no questions asked</td>
			<td>0</td>
		</tr>
		<tr>
			<th>281527</th>
			<td>Excellent</td>
			<td>1</td>
		</tr>
		<tr>
			<th>233713</th>
			<td>fit like oem and looks good</td>
			<td>1</td>
		</tr>
	</tbody>
</table>

<p>We can see that this model is able to predict the reviews reasonably well. For example, review 98387 where the user found the product to be too small and unusable is marked as negative. Consider review 233713 where the user says that the product was fitting well and looks good is marked as positive. How does the model <a contenteditable="false" data-type="indexterm" data-primary="Bing Liu lexicon " id="idm45634177605112"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="Bing Liu lexicon for" id="idm45634177604008"/>compare with a baseline that uses the Bing Liu lexicon?</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">baseline_scorer</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>
    <code class="n">score</code> <code class="o">=</code> <code class="n">bing_liu_score</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
    <code class="k">if</code> <code class="n">score</code> <code class="o">&gt;</code> <code class="mi">0</code><code class="p">:</code>
        <code class="k">return</code> <code class="mi">1</code>
    <code class="k">else</code><code class="p">:</code>
        <code class="k">return</code> <code class="mi">0</code>

<code class="n">Y_pred_baseline</code> <code class="o">=</code> <code class="n">X_test</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">baseline_scorer</code><code class="p">)</code>
<code class="n">acc_score</code> <code class="o">=</code> <code class="n">accuracy_score</code><code class="p">(</code><code class="n">Y_pred_baseline</code><code class="p">,</code> <code class="n">Y_test</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="n">acc_score</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
0.7521998393903668
</pre>

<p>It does provide an uplift on the lexicon baseline of 75%, and while the accuracy can be improved further, this is a simple blueprint that provides quick results. For example, if you’re looking to determine the customer perception of your brand versus competitors, then using this blueprint and aggregating sentiments for each brand will give you a fair understanding. Or let’s say <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="use cases for" id="idm45634177524056"/><a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for sentiment analysis of text data" data-secondary-sortas="sentiment analysis of text data" id="idm45634177522712"/>you want to create an app that helps people decide whether to watch a movie. Using this blueprint on data collected from Twitter or YouTube comments, you could determine whether people feel more positively or negatively and use that to provide a <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term11" id="idm45634177520744"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term12" id="idm45634177519368"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term13" id="idm45634177517992"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term15" id="idm45634177516616"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term16" id="idm45634177515240"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term17" id="idm45634177513864"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term18" id="idm45634177512488"/>suggestion. In the next blueprint, we will describe a more sophisticated technique that can be used to improve the accuracy.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Pretrained Language Models Using Deep Learning"><div class="sect1" id="idm45634177903480">
<h1>Pretrained Language Models Using Deep Learning</h1>

<p>Languages have <a contenteditable="false" data-type="indexterm" data-primary="pretrained models" data-secondary="for sentiment analysis " data-secondary-sortas="sentiment analysis" id="ch11_term19"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="pretrained language models for" id="ch11_term20"/>evolved over centuries and are still continuously changing. While there are rules of grammar and guidelines to forming sentences, these are often not strictly followed and depend heavily on context. The words that a person chooses while tweeting would be quite different when writing an email to express the same thought. And in many languages (including English) the exceptions to the rules are far too many! As a result, it is difficult for a computer program to understand text-based communication. This can be overcome by giving algorithms a deeper language understanding by making use of language models.</p>

<p>Language models are a mathematical representation of natural language that allows us to understand the structure of a sentence and the words in it. There are several types of language models, but we will focus on the use of pretrained language models in this blueprint. The most important characteristic of these language models is that they make use of deep neural network architectures and are trained on a large corpus of data. The use of language models greatly improves the performance of NLP tasks such as language translation, automatic spelling correction, and text summarization.</p>

<section data-type="sect2" data-pdf-bookmark="Deep Learning and Transfer Learning"><div class="sect2" id="idm45634177504200">
<h2>Deep Learning and Transfer Learning</h2>

<p>Deep learning is <a contenteditable="false" data-type="indexterm" data-primary="deep learning" id="ch11_term21"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="deep learning and transfer learning for" id="ch11_term22"/>commonly used to describe a set of machine learning methods that leverage <a contenteditable="false" data-type="indexterm" data-primary="artificial neural networks (ANNs)" id="idm45634177499320"/><a contenteditable="false" data-type="indexterm" data-primary="neural networks" id="idm45634177498200"/>artificial neural networks (ANNs). ANNs were inspired by the human brain and try to mimic the connections and information processing activity between neurons in biological systems. Simply explained, it tries to model a function using an interconnected network of nodes spanning several layers with the weights of the network edges learned with the help of data. For a <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="further reading on" id="idm45634177496584"/>more detailed explanation, please refer to Section II of <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632" class="orm:hideurl"><em>Hands-On Machine Learning</em></a> (O’Reilly, 2019) by Aurélien Géron.</p>

<p>Transfer learning <a contenteditable="false" data-type="indexterm" data-primary="transfer learning" id="ch11_term24"/>is a technique within deep learning that allows us to benefit from pretrained, widely available language models by <em>transferring</em> a model to our specific use case. It gives us the ability to use the knowledge and information obtained in one task and apply it to another problem. As humans, we are good at doing this. For example, we initially learn to play the guitar but can then relatively easily apply that knowledge to pick up the cello or harp more quickly (than a complete beginner). When the same concepts are applied with regard to a machine learning algorithm, then it’s referred to as <em>transfer learning</em>.</p>

<p>This idea was first popularized in the computer vision industry, where a large-scale <a href="https://oreil.ly/ISv5j">image recognition challenge</a> led to several research groups competing to build complex neural networks that are several layers deep to reduce the error on the challenge. Other researchers discovered that these complex models work well not just for that challenge but also on other image recognition tasks with small tweaks. These large models had already learned basic features about images (think of edges, shapes, etc.) and could be fine-tuned for the specific application without the need to train from scratch. In the last two years, the same techniques have been successfully applied to text analytics. First, a deep neural network is trained on a large text corpus (often derived from publicly available data sources like Wikipedia). The <a contenteditable="false" data-type="indexterm" data-primary="LSTM (long short-term memory neural network)" id="idm45634177456392"/>chosen model architecture is a variant of LSTM or Transformer.<sup><a data-type="noteref" id="idm45634177455096-marker" href="ch11.xhtml#idm45634177455096">4</a></sup> When training these models, <a contenteditable="false" data-type="indexterm" data-primary="masked words" id="idm45634177452984"/>one word is removed (masked) in the sentence, and the prediction task is to determine the masked word given all the other words in the sentence. To go back to our human analogy, there might be far more YouTube videos that teach you how to play the guitar than the harp or cello. Therefore, it would be beneficial to first learn to play the guitar because of the large number of resources available and then apply this knowledge to a different task, like playing the harp or cello.</p>

<p>Such large models take a lot of time to train and can be time-consuming. Fortunately, many research groups have made such pretrained models publicly available, including <a href="https://oreil.ly/ukMdf">ULMFiT</a> from fastai, <a href="https://oreil.ly/GtSpY">BERT</a> from Google, <a href="https://oreil.ly/LVwyy">GPT-2</a> from OpenAI, and <a href="https://msturing.org">Turing</a> from Microsoft. <a data-type="xref" href="#fig-transfer-learning">Figure 11-1</a> shows the final step of applying transfer learning, where the initial layers of the pretrained models are kept fixed, and the final layers of the model are retrained to better suit the task at hand. In this way, we can apply a pretrained model to specific tasks such as text classification and sentiment analysis.</p>

<figure><div id="fig-transfer-learning" class="figure"><img src="Images/btap_1101.jpg" width="1089" height="562"/>
<h6><span class="label">Figure 11-1. </span>Transfer learning. The parameters of earlier layers in the network are learned by training the model on the large corpus, and the parameters of the final layers are unfrozen and allowed to be fine-tuned during the training on the specific dataset.</h6>
</div></figure>

<p>For our blueprint we will use the <a contenteditable="false" data-type="indexterm" data-primary="BERT (Bidirectional Encoder Representations from Transformers) model" id="ch11_term27"/>BERT pretrained model released by Google. BERT is an acronym for <em>Bidirectional Encoder Representations from Transformers</em>. It uses the <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="Transformers library for" id="ch11_term25"/><a contenteditable="false" data-type="indexterm" data-primary="Transformers library" id="ch11_term26"/>Transformers architecture and trains a model using a large corpus of text data. The model that we use in this blueprint (<code>bert-base-uncased</code>) is <a contenteditable="false" data-type="indexterm" data-primary="Masked Language Model (MLM)" id="idm45634177438424"/>trained on the combined English Wikipedia and Books corpus using a Masked Language Model (MLM). There are other versions of the BERT model that can be trained on different corpora. For example, there is a BERT model trained on German Wikipedia articles. The masked language model randomly masks (hides) some of the tokens from the input, and the objective is to predict the original vocabulary ID of the masked word based only on its context (surrounding words). Since it’s bidirectional, the model looks at each sentence in both directions and is able to understand context better. In addition, BERT also uses subwords as tokens, which provides more granularity when identifying the meaning of a word. Another advantage is that BERT generates context-aware embeddings. For example, depending on the surrounding words in a sentence where the word <em>cell</em> is used, it can have a biological reference or actually refer to a prison cell. For a much more detailed <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term21" id="idm45634177435736"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term22" id="idm45634177434360"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term24" id="idm45634177432984"/>understanding of how BERT works, please see <a data-type="xref" href="#ch11_reading">“Further Reading”</a>.</p>
</div></section>
</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Using the Transfer Learning Technique and a Pretrained Language Model"><div class="sect1" id="idm45634177430328">
<h1>Blueprint: Using the Transfer Learning Technique and a Pretrained Language Model</h1>

<p>This blueprint <a contenteditable="false" data-type="indexterm" data-primary="machine learning models" data-secondary="for sentiment analysis " data-secondary-sortas="sentiment analysis" id="ch11_term28"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="transfer learning technique for" id="ch11_term29"/>will show you how we can leverage pretrained language models to perform sentiment classification. Consider the <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="use cases for" id="idm45634177424744"/><a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for sentiment analysis of text data" data-secondary-sortas="sentiment analysis of text data" id="idm45634177423352"/>use case where you would like to take action based on the sentiment expressed. For example, if a customer is particularly unhappy, you would like to route them to your best customer service representative. It’s important that you are able to detect the sentiment accurately or else you risk losing them. Or let’s say you are a small business that relies heavily on reviews and ratings on public websites like <a href="https://yelp.com">Yelp</a>. To improve your ratings, you would like to follow up with unhappy customers by offering them coupons or special services. It’s important to be accurate so that you target the right customers. In such use cases, we may not have a lot of data to train the model, but having a high accuracy is important. We know that sentiment is influenced by the context in which a word is used, and the use of a pretrained language model can improve our sentiment predictions. This gives us the ability to go beyond the limited dataset that we have to incorporate knowledge from general usage.</p>

<p>In our blueprint we will use the Transformers library because of its easy-to-use functionality and wide support for multiple pretrained models. <a data-type="xref" data-xrefstyle="select:nopage" href="#choosing">“Choosing the Transformers Library”</a> provides more details about this topic. The Transformers library is continuously updated, with multiple researchers contributing.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="choosing">
<h5>Choosing the Transformers Library</h5>

<p>While there are several excellent deep learning models produced by multiple research groups, at this point in time they are fragmented and not compatible across different frameworks. For example, the BERT model was developed by the Google research team primarily on TensorFlow and does not work automatically on <a contenteditable="false" data-type="indexterm" data-primary="PyTorch" id="idm45634177415896"/>PyTorch. So if someone is more comfortable using PyTorch, they will need to port/rewrite all of this code. The deep learning models also do not use a standard input format and other naming conventions, which makes a standardized approach much more difficult. This is where the Transformers library by <a href="https://oreil.ly/F0Vy7">Hugging Face</a> comes in. There are two primary advantages in making use of this library:</p>

<ul>
	<li>The Transformers library allows us to easily choose between different pretrained models by just changing a parameter value. Most of the benchmark models developed in the last two years, like BERT and GPT-2, are already implemented and available.</li>
	<li>It works in PyTorch and TensorFlow. These are the two most popular deep learning frameworks as of 2020, and the Transformers library gives us the ability to choose either of them as the underlying processing framework.</li>
</ul>

<p>The Transformers library has provided a standardized approach to reuse all the models with minimum effort and code changes. Our blueprint will make use of this library to choose a BERT pretrained model, fine-tune the training on the Amazon reviews dataset, and then evaluate the result. We <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term25" id="idm45634177411192"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term26" id="idm45634177409816"/>have put together this blueprint by using the SST-2 task example provided in the <a href="https://oreil.ly/bDMQV">Transformers repository</a> and the <a href="https://oreil.ly/cBeBK">primary trainer class implementation</a>.</p>
</div></aside>

<section data-type="sect2" data-pdf-bookmark="Step 1: Loading Models and Tokenization"><div class="sect2" id="idm45634177406632">
<h2>Step 1: Loading Models and Tokenization</h2>

<p>The first step <a contenteditable="false" data-type="indexterm" data-primary="tokenization/tokens" data-secondary="with pretrained models" data-secondary-sortas="pretrained models" id="ch11_term33"/>when using the Transformers library is to import the three classes needed for the chosen model. This includes the <em>config</em> class, used to store important model parameters; the <em>tokenizer</em>, to tokenize and prepare the text for model training; and the <em>model</em> class, which defines the model architecture and weights. These classes are specific to the model architecture, and if we want to use a different architecture, then the appropriate classes need to be imported instead. We instantiate these classes from a pretrained model and choose the smallest BERT model, <code>bert-base-uncased</code>, which is 12 layers deep and contains 110 million parameters!</p>

<p>The advantage of using the Transformers library is that it already provides multiple pretrained models for many model architectures, which you can <a href="https://oreil.ly/QdC7E">check here</a>. When we instantiate a model class from a pretrained model, the model architecture and weights are downloaded from an AWS S3 bucket hosted by <a contenteditable="false" data-type="indexterm" data-primary="Hugging Face" id="idm45634177398744"/>Hugging Face. This might take a while the first time, but it is then cached on your machine, which removes the need for subsequent downloads. Note that since we are using the pretrained model to predict the sentiment (positive versus negative), we specify <code>finetuning_task='binary'</code>. We have provided additional instructions in the accompanying notebook to ensure that additional Python packages are installed before running this blueprint.</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">transformers</code> <code class="kn">import</code> <code class="n">BertConfig</code><code class="p">,</code> <code class="n">BertTokenizer</code><code class="p">,</code> <code class="n">BertForSequenceClassification</code>

<code class="n">config</code> <code class="o">=</code> <code class="n">BertConfig</code><code class="o">.</code><code class="n">from_pretrained</code><code class="p">(</code><code class="s1">'bert-base-uncased'</code><code class="p">,</code><code class="n">finetuning_task</code><code class="o">=</code><code class="s1">'binary'</code><code class="p">)</code>
<code class="n">tokenizer</code> <code class="o">=</code> <code class="n">BertTokenizer</code><code class="o">.</code><code class="n">from_pretrained</code><code class="p">(</code><code class="s1">'bert-base-uncased'</code><code class="p">)</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">BertForSequenceClassification</code><code class="o">.</code><code class="n">from_pretrained</code><code class="p">(</code><code class="s1">'bert-base-uncased'</code><code class="p">)</code>
</pre>

<p>We have to transform the input text data into a standard format required by the model architecture. We define a simple <code>get_tokens</code> method to convert the raw text of our reviews to numeric values. The pretrained model accepts each observation as a fixed length sequence. So, if an observation is shorter than the maximum sequence length, then it is padded with empty (zero) tokens, and if it’s longer, then it is truncated. Each model architecture has a maximum sequence length that it supports. The tokenizer class provides a tokenize function that splits the sentence to tokens, pads the sentence to create the fixed-length sequence, and finally represents it as a numerical value that can be used during model training. This function also adds an attention mask to differentiate those positions where we have actual words from those that contain padding characters. Here is an example of how this process works:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">get_tokens</code><code class="p">(</code><code class="n">text</code><code class="p">,</code> <code class="n">tokenizer</code><code class="p">,</code> <code class="n">max_seq_length</code><code class="p">,</code> <code class="n">add_special_tokens</code><code class="o">=</code><code class="bp">True</code><code class="p">):</code>
  <code class="n">input_ids</code> <code class="o">=</code> <code class="n">tokenizer</code><code class="o">.</code><code class="n">encode</code><code class="p">(</code><code class="n">text</code><code class="p">,</code>
                               <code class="n">add_special_tokens</code><code class="o">=</code><code class="n">add_special_tokens</code><code class="p">,</code>
                               <code class="n">max_length</code><code class="o">=</code><code class="n">max_seq_length</code><code class="p">,</code>
                               <code class="n">pad_to_max_length</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
  <code class="n">attention_mask</code> <code class="o">=</code> <code class="p">[</code><code class="nb">int</code><code class="p">(</code><code class="nb">id</code> <code class="o">&gt;</code> <code class="mi">0</code><code class="p">)</code> <code class="k">for</code> <code class="nb">id</code> <code class="ow">in</code> <code class="n">input_ids</code><code class="p">]</code>
  <code class="k">assert</code> <code class="nb">len</code><code class="p">(</code><code class="n">input_ids</code><code class="p">)</code> <code class="o">==</code> <code class="n">max_seq_length</code>
  <code class="k">assert</code> <code class="nb">len</code><code class="p">(</code><code class="n">attention_mask</code><code class="p">)</code> <code class="o">==</code> <code class="n">max_seq_length</code>
  <code class="k">return</code> <code class="p">(</code><code class="n">input_ids</code><code class="p">,</code> <code class="n">attention_mask</code><code class="p">)</code>

<code class="n">text</code> <code class="o">=</code> <code class="s2">"Here is the sentence I want embeddings for."</code>
<code class="n">input_ids</code><code class="p">,</code> <code class="n">attention_mask</code> <code class="o">=</code> <code class="n">get_tokens</code><code class="p">(</code><code class="n">text</code><code class="p">,</code>
                                       <code class="n">tokenizer</code><code class="p">,</code>
                                       <code class="n">max_seq_length</code><code class="o">=</code><code class="mi">30</code><code class="p">,</code>
                                       <code class="n">add_special_tokens</code> <code class="o">=</code> <code class="bp">True</code><code class="p">)</code>
<code class="n">input_tokens</code> <code class="o">=</code> <code class="n">tokenizer</code><code class="o">.</code><code class="n">convert_ids_to_tokens</code><code class="p">(</code><code class="n">input_ids</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="n">input_tokens</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="n">input_ids</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="n">attention_mask</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Here is the sentence I want embeddings for.
['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed',
'##ding', '##s', 'for', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',
'[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]',
'[PAD]', '[PAD]', '[PAD]', '[PAD]']
[101, 2182, 2003, 1996, 6251, 1045, 2215, 7861, 8270, 4667, 2015, 2005, 1012,
102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0]
</pre>

<p>The first token that we observe is the <code>[CLS]</code> token, which stands for classification, which is one of the pretraining tasks of the BERT model. This token is used to identify the start of a sentence and stores the aggregated representation of the entire sentence within the model. We also see the <code>[SEP]</code> token at the end of the sentence, which stands for <em>separator</em>. When BERT is used for nonclassification tasks like language translation, each observation would include a pair of texts (for example, text in English and text in French), and the <code>[SEP]</code> token is used to separate the first text from the second. However, since we are building a classification model, the separator token is followed by <code>[PAD]</code> tokens. We specified the sequence length to be 30, and since our test observation was not that long, multiple padding tokens have been added at the end. Another interesting observation is that a word like <em>embedding</em> is not one token but actually split into <code>em</code>, <code>##bed</code>, <code>##ding</code>, and <code>##s</code>. The <code>##</code> is used to identify tokens that are subwords, which is a special characteristic of the BERT model. This allows the model to have a <a contenteditable="false" data-type="indexterm" data-primary="suffixes in text analysis" id="idm45634177210232"/>better distinction between root words, prefixes, and suffixes and also try to infer the meaning of words that it may not have seen before.</p>

<p>An important point to note is that since deep learning models use a context-based approach, it is advisable to <a contenteditable="false" data-type="indexterm" data-primary="data preprocessing" data-secondary="for deep learning models" data-secondary-sortas="deep learning models" id="idm45634177208648"/>use the text in the original form without any preprocessing, thus allowing the tokenizer to produce all possible tokens from its vocabulary. As a result, we must split the data again using the original <code>text_orig</code> column rather than the cleaned <code>text</code> column. After that, let’s apply the same function to our train and test data and this time use a <code>max_seq_length</code> of 50:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">X_train</code><code class="p">,</code> <code class="n">X_test</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">,</code> <code class="n">Y_test</code> <code class="o">=</code> <code class="n">train_test_split</code><code class="p">(</code><code class="n">df</code><code class="p">[</code><code class="s1">'text_orig'</code><code class="p">],</code>
                                                    <code class="n">df</code><code class="p">[</code><code class="s1">'sentiment'</code><code class="p">],</code>
                                                    <code class="n">test_size</code><code class="o">=</code><code class="mf">0.2</code><code class="p">,</code>
                                                    <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">,</code>
                                                    <code class="n">stratify</code><code class="o">=</code><code class="n">df</code><code class="p">[</code><code class="s1">'sentiment'</code><code class="p">])</code>
<code class="n">X_train_tokens</code> <code class="o">=</code> <code class="n">X_train</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">get_tokens</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">tokenizer</code><code class="p">,</code> <code class="mi">50</code><code class="p">))</code>
<code class="n">X_test_tokens</code> <code class="o">=</code> <code class="n">X_test</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">get_tokens</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">tokenizer</code><code class="p">,</code> <code class="mi">50</code><code class="p">))</code>
</pre>

<p>Deep learning models <a contenteditable="false" data-type="indexterm" data-primary="GPUs (graphics processing units)" id="idm45634177202520"/>are trained on GPUs using <a contenteditable="false" data-type="indexterm" data-primary="PyTorch" id="idm45634177168280"/>frameworks like <a href="https://tensorflow.org">TensorFlow</a> and <a href="https://pytorch.org">PyTorch</a>. A <a contenteditable="false" data-type="indexterm" data-primary="tensor" id="idm45634177165640"/>tensor is the basic data structure used by these frameworks to represent and work with data and can store data in N dimensions. A simple way to visualize a tensor is by drawing an analogy with a chessboard. Let’s suppose that we mark an unoccupied position with 0, a position occupied by a white piece with 1, and a position occupied by a black piece with 2. We get an 8 × 8 matrix denoting the status of the chessboard at a given point in time. If we now want to track and store this over several moves, then we get multiple 8 × 8 matrices, which can be stored in what we call a <em>tensor</em>. Tensors are n-dimensional representations of data, containing an array of components that are functions of the coordinates of a space. The tensor that tracks the historical chess moves would be a rank 3 tensor, whereas the initial 8 × 8 matrix could also be considered a tensor, but with rank 2.</p>

<p>This is a simplistic explanation, but to get a more in-depth understanding, we would <a contenteditable="false" data-type="indexterm" data-primary="Kolecki, Joseph C." id="idm45634177162744"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="further reading on" id="idm45634177161640"/>recommend reading <a href="https://oreil.ly/VC_80">“An Introduction to Tensors for Students of Physics and Engineering”</a> by Joseph C. Kolecki. In our case, we create three tensors that contain the tokens (tensors containing multiple arrays of size 50), input masks (tensors containing arrays of size 50), and target labels (tensors containing scalars of size 1):</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code> <code class="nn">torch</code>
<code class="kn">from</code> <code class="nn">torch.utils.data</code> <code class="kn">import</code> <code class="n">TensorDataset</code>

<code class="n">input_ids_train</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code>
    <code class="p">[</code><code class="n">features</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="k">for</code> <code class="n">features</code> <code class="ow">in</code> <code class="n">X_train_tokens</code><code class="o">.</code><code class="n">values</code><code class="p">],</code> <code class="n">dtype</code><code class="o">=</code><code class="n">torch</code><code class="o">.</code><code class="n">long</code><code class="p">)</code>
<code class="n">input_mask_train</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code>
    <code class="p">[</code><code class="n">features</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code> <code class="k">for</code> <code class="n">features</code> <code class="ow">in</code> <code class="n">X_train_tokens</code><code class="o">.</code><code class="n">values</code><code class="p">],</code> <code class="n">dtype</code><code class="o">=</code><code class="n">torch</code><code class="o">.</code><code class="n">long</code><code class="p">)</code>
<code class="n">label_ids_train</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="n">Y_train</code><code class="o">.</code><code class="n">values</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">torch</code><code class="o">.</code><code class="n">long</code><code class="p">)</code>

<code class="k">print</code> <code class="p">(</code><code class="n">input_ids_train</code><code class="o">.</code><code class="n">shape</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="n">input_mask_train</code><code class="o">.</code><code class="n">shape</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="n">label_ids_train</code><code class="o">.</code><code class="n">shape</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
torch.Size([234104, 50])
torch.Size([234104, 50])
torch.Size([234104])
</pre>

<p>We can take a peek at what is in this tensor and see that it contains a mapping to the BERT vocabulary for each of the tokens in a sentence. The number 101 indicates the start, and 102 indicates the end of the review sentence. We combine these tensors together into a TensorDataset, which is the basic data structure used to load all observations <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term33" id="idm45634176949928"/>during model training:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">input_ids_train</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
tensor([ 101, 2009, 2134, 1005, 1056, 2147, 6314, 2055, 2009, 1037, 5808, 1997,
        2026, 2769,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
           0,    0])
</pre>

<p>Then:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">train_dataset</code> <code class="o">=</code> <code class="n">TensorDataset</code><code class="p">(</code><code class="n">input_ids_train</code><code class="p">,</code><code class="n">input_mask_train</code><code class="p">,</code><code class="n">label_ids_train</code><code class="p">)</code>
</pre>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Step 2: Model Training"><div class="sect2" id="idm45634177405848">
<h2>Step 2: Model Training</h2>

<p>Now that we have preprocessed and tokenized the data, we are <a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="of deep learning models" data-secondary-sortas="pretrained models" id="ch11_term35"/>ready to train the model. Because of the large memory usage and computation demands of deep learning models, we follow a different approach compared to the SVM model used in the <span class="keep-together">previous</span> blueprint. All training observations are <a contenteditable="false" data-type="indexterm" data-primary="batches and epochs in model training" id="idm45634176902088"/>split into batches (defined by <code>train_batch_size</code> and randomly sampled from all observations using <code>RandomSampler</code>) and passed forward through the layers of the model. When the <a contenteditable="false" data-type="indexterm" data-primary="epochs in model training" id="idm45634176899992"/>model has seen all the training observations by going through the batches, it is said to have been trained for one epoch. An epoch is therefore one pass through all the observations in the training data. The combination of <code>batch_size</code> and number of epochs determines how long the model takes to train. Choosing a larger <code>batch_size</code> reduces the number of forward passes in an epoch but might result in higher memory consumption. Choosing a larger number of epochs gives the model more time to learn the right value of the parameters but will also result in a longer training time. For this blueprint we have defined <code>batch_size</code> to be 64 and <code>num_train_epochs</code> to be 2:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">torch.utils.data</code> <code class="kn">import</code> <code class="n">DataLoader</code><code class="p">,</code> <code class="n">RandomSampler</code>

<code class="n">train_batch_size</code> <code class="o">=</code> <code class="mi">64</code>
<code class="n">num_train_epochs</code> <code class="o">=</code> <code class="mi">2</code>

<code class="n">train_sampler</code> <code class="o">=</code> <code class="n">RandomSampler</code><code class="p">(</code><code class="n">train_dataset</code><code class="p">)</code>
<code class="n">train_dataloader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">train_dataset</code><code class="p">,</code>
                              <code class="n">sampler</code><code class="o">=</code><code class="n">train_sampler</code><code class="p">,</code>
                              <code class="n">batch_size</code><code class="o">=</code><code class="n">train_batch_size</code><code class="p">)</code>
<code class="n">t_total</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">train_dataloader</code><code class="p">)</code> <code class="o">//</code> <code class="n">num_train_epochs</code>

<code class="k">print</code> <code class="p">(</code><code class="s2">"Num examples = "</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">train_dataset</code><code class="p">))</code>
<code class="k">print</code> <code class="p">(</code><code class="s2">"Num Epochs = "</code><code class="p">,</code> <code class="n">num_train_epochs</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="s2">"Total train batch size  = "</code><code class="p">,</code> <code class="n">train_batch_size</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="s2">"Total optimization steps = "</code><code class="p">,</code> <code class="n">t_total</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Num examples =  234104
Num Epochs =  2
Total train batch size  =  64
Total optimization steps =  1829
</pre>

<p>When all the observations in one batch have passed forward through the layers of the model, the <a contenteditable="false" data-type="indexterm" data-primary="backpropagation algorithm" id="idm45634176768584"/>backpropagation algorithm is applied in the backward direction. This technique allows us to automatically compute the gradients for <a contenteditable="false" data-type="indexterm" data-primary="neural networks" id="idm45634176767304"/>each parameter in the neural network, giving us a way to tweak the parameters to reduce the error. This is similar to how stochastic gradient descent works, but we do not attempt a detailed explanation. Chapter 4 of <em>Hands-On Machine Learning</em> (O’Reilly, 2019) provides a good introduction and mathematical explanation. The key thing to note is that <a contenteditable="false" data-type="indexterm" data-primary="deep learning" id="idm45634176765288"/>when training a deep learning algorithm, parameters that influence backpropagation like the learning rate and choice of optimizer determine how quickly the model is able <span class="keep-together">to learn</span> the parameters and reach higher accuracies. However, there isn’t a scientific <span class="keep-together">reason</span> for why a certain method or value is better, but a lot of researchers<sup><a data-type="noteref" id="idm45634176762520-marker" href="ch11.xhtml#idm45634176762520">5</a></sup> attempt to determine what the best options could be. We make informed choices for the blueprint based on the parameters in the BERT paper and <a contenteditable="false" data-type="indexterm" data-primary="Transformers library" id="idm45634176760376"/><a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="Transformers library for" id="idm45634176759336"/>recommendations in the Transformers library, as shown here:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">transformers</code> <code class="kn">import</code> <code class="n">AdamW</code><code class="p">,</code> <code class="n">get_linear_schedule_with_warmup</code>

<code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">1e-4</code>
<code class="n">adam_epsilon</code> <code class="o">=</code> <code class="mf">1e-8</code>
<code class="n">warmup_steps</code> <code class="o">=</code> <code class="mi">0</code>

<code class="n">optimizer</code> <code class="o">=</code> <code class="n">AdamW</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">parameters</code><code class="p">(),</code> <code class="n">lr</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">,</code> <code class="n">eps</code><code class="o">=</code><code class="n">adam_epsilon</code><code class="p">)</code>
<code class="n">scheduler</code> <code class="o">=</code> <code class="n">get_linear_schedule_with_warmup</code><code class="p">(</code><code class="n">optimizer</code><code class="p">,</code>
                                            <code class="n">num_warmup_steps</code><code class="o">=</code><code class="n">warmup_steps</code><code class="p">,</code>
                                            <code class="n">num_training_steps</code><code class="o">=</code><code class="n">t_total</code><code class="p">)</code>
</pre>

<p>Before setting up the training loop, we check whether a GPU is available (see <a data-type="xref" data-xrefstyle="select:nopage" href="#usinggpus">“Using GPUs for Free with Google Colab”</a>). If so, the model and input data are transferred to the GPU, and then we set up the forward pass by running the inputs through the model to produce outputs. Since we have specified the labels, we already know the deviation from actual (loss), and we adjust the parameters using backpropagation that calculates gradients. The optimizer and scheduler steps are used to determine the amount of parameter adjustment. Note the special condition to clip the gradients to a max value to prevent the problem of <a href="https://oreil.ly/Ry0Vi">exploding gradients</a>.</p>


<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="usinggpus">
<h5>Using GPUs for Free with Google Colab</h5>

<p>One of the primary drivers for the popularity of neural network architectures and the success of models like BERT has been the <a contenteditable="false" data-type="indexterm" data-primary="GPUs (graphics processing units)" id="idm45634176666856"/>use of graphics processing units (GPUs). The use of a GPU allows parallel operations, specifically matrix multiplication that a deep neural network relies on. This gives us the capability to train complex neural network architectures with multiple layers that a CPU can never provide. If your laptop or desktop does not come with one of the latest (NVIDIA) GPUs, this makes it harder to experiment with these pretrained models, and one has to choose cloud providers like AWS and rent a machine with GPU on a usage basis.</p>

<p>But with <a contenteditable="false" data-type="indexterm" data-primary="Google Colab" id="idm45634176664648"/>Google Colab (Colaboratory), we have a free alternative. Google Colab is a Jupyter notebook type of environment that runs on Google Cloud. One can access it via a browser, just like Jupyter notebooks, and run commands in a cell interface. The biggest advantage is that you can change the runtime environment to a GPU, and all the code will execute using a GPU for free. There are limitations to how long you can run your notebook with the free option, but it also comes with a paid monthly subscription that enhances these limits.</p>

<p>To use this, you must have a Google account and then log in at <a href="https://colab.research.google.com"><em>https://colab.research.google.com</em></a>, create a new notebook, and then choose Edit &gt; Runtime Settings. From the drop-down for Hardware Accelerator, choose GPU. Once you are finished running your code, you can also save this notebook to your Google Drive or download it as a Jupyter notebook.</p>
</div></aside>

<p>We will now wrap all these steps in nested <code>for</code> loops—one for each epoch and another for each batch in the epoch—and use <a contenteditable="false" data-type="indexterm" data-primary="tqdm library" id="idm45634176660456"/>the TQDM library introduced earlier to keep track of the training progress while printing the loss value:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">tqdm</code> <code class="kn">import</code> <code class="n">trange</code><code class="p">,</code> <code class="n">notebook</code>

<code class="n">device</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">device</code><code class="p">(</code><code class="s2">"cuda"</code> <code class="k">if</code> <code class="n">torch</code><code class="o">.</code><code class="n">cuda</code><code class="o">.</code><code class="n">is_available</code><code class="p">()</code> <code class="k">else</code> <code class="s2">"cpu"</code><code class="p">)</code>
<code class="n">train_iterator</code> <code class="o">=</code> <code class="n">trange</code><code class="p">(</code><code class="n">num_train_epochs</code><code class="p">,</code> <code class="n">desc</code><code class="o">=</code><code class="s2">"Epoch"</code><code class="p">)</code>

<code class="c1"># Put model in 'train' mode</code>
<code class="n">model</code><code class="o">.</code><code class="n">train</code><code class="p">()</code>

<code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="n">train_iterator</code><code class="p">:</code>
    <code class="n">epoch_iterator</code> <code class="o">=</code> <code class="n">notebook</code><code class="o">.</code><code class="n">tqdm</code><code class="p">(</code><code class="n">train_dataloader</code><code class="p">,</code> <code class="n">desc</code><code class="o">=</code><code class="s2">"Iteration"</code><code class="p">)</code>
    <code class="k">for</code> <code class="n">step</code><code class="p">,</code> <code class="n">batch</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">epoch_iterator</code><code class="p">):</code>

        <code class="c1"># Reset all gradients at start of every iteration</code>
        <code class="n">model</code><code class="o">.</code><code class="n">zero_grad</code><code class="p">()</code>

        <code class="c1"># Put the model and the input observations to GPU</code>
        <code class="n">model</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
        <code class="n">batch</code> <code class="o">=</code> <code class="nb">tuple</code><code class="p">(</code><code class="n">t</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">batch</code><code class="p">)</code>

        <code class="c1"># Identify the inputs to the model</code>
        <code class="n">inputs</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'input_ids'</code><code class="p">:</code>      <code class="n">batch</code><code class="p">[</code><code class="mi">0</code><code class="p">],</code>
                  <code class="s1">'attention_mask'</code><code class="p">:</code> <code class="n">batch</code><code class="p">[</code><code class="mi">1</code><code class="p">],</code>
                  <code class="s1">'labels'</code><code class="p">:</code>         <code class="n">batch</code><code class="p">[</code><code class="mi">2</code><code class="p">]}</code>

        <code class="c1"># Forward Pass through the model. Input -&gt; Model -&gt; Output</code>
        <code class="n">outputs</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="o">**</code><code class="n">inputs</code><code class="p">)</code>

        <code class="c1"># Determine the deviation (loss)</code>
        <code class="n">loss</code> <code class="o">=</code> <code class="n">outputs</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>
        <code class="k">print</code><code class="p">(</code><code class="s2">"</code><code class="se">\r</code><code class="si">%f</code><code class="s2">"</code> <code class="o">%</code> <code class="n">loss</code><code class="p">,</code> <code class="n">end</code><code class="o">=</code><code class="s1">''</code><code class="p">)</code>

        <code class="c1"># Back-propogate the loss (automatically calculates gradients)</code>
        <code class="n">loss</code><code class="o">.</code><code class="n">backward</code><code class="p">()</code>

        <code class="c1"># Prevent exploding gradients by limiting gradients to 1.0</code>
        <code class="n">torch</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">utils</code><code class="o">.</code><code class="n">clip_grad_norm_</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">parameters</code><code class="p">(),</code> <code class="mf">1.0</code><code class="p">)</code>

        <code class="c1"># Update the parameters and learning rate</code>
        <code class="n">optimizer</code><code class="o">.</code><code class="n">step</code><code class="p">()</code>
        <code class="n">scheduler</code><code class="o">.</code><code class="n">step</code><code class="p">()</code>
</pre>

<p>The steps we have performed up to now have fine-tuned the parameters of the BERT model that we downloaded to fit the sentiment analysis of the Amazon customer reviews. If the model is learning the parameter values correctly, you should observe that the loss value reduces over multiple iterations. At the end of the training step, we can save the model and tokenizer into a <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term27" id="idm45634176656168"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term35" id="idm45634176654952"/>chosen output folder:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">model</code><code class="o">.</code><code class="n">save_pretrained</code><code class="p">(</code><code class="s1">'outputs'</code><code class="p">)</code>
</pre>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Step 3: Model Evaluation"><div class="sect2" id="idm45634176850664">
<h2>Step 3: Model Evaluation</h2>

<p>Evaluating our model on the test data is similar to the training steps, with only minor differences. First, we have to evaluate the entire test dataset and therefore don’t need to make random samples; instead, we use the <code>SequentialSampler</code> class to load observations. However, we are still constrained by the number of observations we can load at a time and therefore must use <code>test_batch_size</code> to determine this. Second, we do not need a backward pass or adjustment of parameters and only perform the forward pass. The model provides us with output tensors that contain the value of loss and output probabilities. We use the <code>np.argmax</code> function to determine the output label with maximum probability and calculate the accuracy by comparing with actual labels:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>
<code class="kn">from</code> <code class="nn">torch.utils.data</code> <code class="kn">import</code> <code class="n">SequentialSampler</code>

<code class="n">test_batch_size</code> <code class="o">=</code> <code class="mi">64</code>
<code class="n">test_sampler</code> <code class="o">=</code> <code class="n">SequentialSampler</code><code class="p">(</code><code class="n">test_dataset</code><code class="p">)</code>
<code class="n">test_dataloader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">test_dataset</code><code class="p">,</code>
                             <code class="n">sampler</code><code class="o">=</code><code class="n">test_sampler</code><code class="p">,</code>
                             <code class="n">batch_size</code><code class="o">=</code><code class="n">test_batch_size</code><code class="p">)</code>

<code class="c1"># Load the pretrained model that was saved earlier</code>
<code class="c1"># model = model.from_pretrained('/outputs')</code>

<code class="c1"># Initialize the prediction and actual labels</code>
<code class="n">preds</code> <code class="o">=</code> <code class="bp">None</code>
<code class="n">out_label_ids</code> <code class="o">=</code> <code class="bp">None</code>

<code class="c1"># Put model in "eval" mode</code>
<code class="n">model</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code>

<code class="k">for</code> <code class="n">batch</code> <code class="ow">in</code> <code class="n">notebook</code><code class="o">.</code><code class="n">tqdm</code><code class="p">(</code><code class="n">test_dataloader</code><code class="p">,</code> <code class="n">desc</code><code class="o">=</code><code class="s2">"Evaluating"</code><code class="p">):</code>

    <code class="c1"># Put the model and the input observations to GPU</code>
    <code class="n">model</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
    <code class="n">batch</code> <code class="o">=</code> <code class="nb">tuple</code><code class="p">(</code><code class="n">t</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">batch</code><code class="p">)</code>

    <code class="c1"># Do not track any gradients since in 'eval' mode</code>
    <code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code>
        <code class="n">inputs</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'input_ids'</code><code class="p">:</code>      <code class="n">batch</code><code class="p">[</code><code class="mi">0</code><code class="p">],</code>
                  <code class="s1">'attention_mask'</code><code class="p">:</code> <code class="n">batch</code><code class="p">[</code><code class="mi">1</code><code class="p">],</code>
                  <code class="s1">'labels'</code><code class="p">:</code>         <code class="n">batch</code><code class="p">[</code><code class="mi">2</code><code class="p">]}</code>

        <code class="c1"># Forward pass through the model</code>
        <code class="n">outputs</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="o">**</code><code class="n">inputs</code><code class="p">)</code>

        <code class="c1"># We get loss since we provided the labels</code>
        <code class="n">tmp_eval_loss</code><code class="p">,</code> <code class="n">logits</code> <code class="o">=</code> <code class="n">outputs</code><code class="p">[:</code><code class="mi">2</code><code class="p">]</code>

        <code class="c1"># There maybe more than one batch of items in the test dataset</code>
        <code class="k">if</code> <code class="n">preds</code> <code class="ow">is</code> <code class="bp">None</code><code class="p">:</code>
            <code class="n">preds</code> <code class="o">=</code> <code class="n">logits</code><code class="o">.</code><code class="n">detach</code><code class="p">()</code><code class="o">.</code><code class="n">cpu</code><code class="p">()</code><code class="o">.</code><code class="n">numpy</code><code class="p">()</code>
            <code class="n">out_label_ids</code> <code class="o">=</code> <code class="n">inputs</code><code class="p">[</code><code class="s1">'labels'</code><code class="p">]</code><code class="o">.</code><code class="n">detach</code><code class="p">()</code><code class="o">.</code><code class="n">cpu</code><code class="p">()</code><code class="o">.</code><code class="n">numpy</code><code class="p">()</code>
        <code class="k">else</code><code class="p">:</code>
            <code class="n">preds</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">preds</code><code class="p">,</code> <code class="n">logits</code><code class="o">.</code><code class="n">detach</code><code class="p">()</code><code class="o">.</code><code class="n">cpu</code><code class="p">()</code><code class="o">.</code><code class="n">numpy</code><code class="p">(),</code> <code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>
            <code class="n">out_label_ids</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">out_label_ids</code><code class="p">,</code>
                                      <code class="n">inputs</code><code class="p">[</code><code class="s1">'labels'</code><code class="p">]</code><code class="o">.</code><code class="n">detach</code><code class="p">()</code><code class="o">.</code><code class="n">cpu</code><code class="p">()</code><code class="o">.</code><code class="n">numpy</code><code class="p">(),</code>
                                      <code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>

<code class="c1"># Get final loss, predictions and accuracy</code>
<code class="n">preds</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">argmax</code><code class="p">(</code><code class="n">preds</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="n">acc_score</code> <code class="o">=</code> <code class="n">accuracy_score</code><code class="p">(</code><code class="n">preds</code><code class="p">,</code> <code class="n">out_label_ids</code><code class="p">)</code>
<code class="k">print</code> <code class="p">(</code><code class="s1">'Accuracy Score on Test data '</code><code class="p">,</code> <code class="n">acc_score</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Accuracy Score on Test data  0.9535086370393152
</pre>

<p>The results for our test data show an increase in model accuracy to 95%—a 10 percentage point jump compared to our previous baseline with TF-IDF and SVM. These are the benefits of using a state-of-the-art language model and is most likely a <a contenteditable="false" data-type="indexterm" data-primary="BERT (Bidirectional Encoder Representations from Transformers) model" id="idm45634176442296"/>result of BERT being trained using a large corpus of data. The reviews are quite short, and the earlier model has only that data to learn a relationship. BERT, on the other hand, is context aware <a contenteditable="false" data-type="indexterm" data-primary="transfer learning" id="idm45634176440888"/>and can <em>transfer</em> the prior information it has about the words in <span class="keep-together">the review.</span> The accuracy can be improved by fine-tuning the hyperparameters like <span class="keep-together"><code>learning_rate</code></span> or by training for more epochs. Because the number of parameters for <span class="keep-together">pretrained</span> language models far exceeds the number of observations we use for fine-tuning, we must be careful to avoid overfitting during this process!</p>

<div data-type="note" epub:type="note">
<h5>Using Saved Models</h5>

<p>If you are running the evaluation separately, you can load the fine-tuned model directly without the need to train again. Note that this is the same function that we initially used to load the pretrained model from transformers, but this time we are using the fine-tuned model that we trained ourselves.</p>
</div>

<p class="pagebreak-before">As you can see, using a pretrained language model improves the accuracy of our model but also involves many additional steps and can incur costs like the use of a GPU (training a useful model on CPU can take 50–100 times longer). The pretrained models are quite large and not memory efficient. Using these models in production is often more complicated because of the time taken to load millions of parameters in memory, and they are inefficient for real-time scenarios because of longer inference times. Some <a contenteditable="false" data-type="indexterm" data-primary="ALBERT pretrained model" id="idm45634176122552"/><a contenteditable="false" data-type="indexterm" data-primary="DistilBERT pretrained model" id="idm45634176121448"/>pretrained models like <a href="https://oreil.ly/o4xEU">DistilBERT</a> and <a href="https://oreil.ly/m715P">ALBERT</a> have been specifically developed for a more favorable trade-off between accuracy and model simplicity. You can easily try this by reusing the blueprint and changing the appropriate model classes to choose the <code>distil-bert-uncased</code> or <code>albert-base-v1</code> model, which is <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="Transformers library for" id="idm45634176117672"/><a contenteditable="false" data-type="indexterm" data-primary="Transformers library" id="idm45634176116232"/>available in the Transformers library, to <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term19" id="idm45634176115000"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term20" id="idm45634176113624"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term28" id="idm45634176112248"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch11_term29" id="idm45634176110872"/>check the accuracy.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Closing Remarks"><div class="sect1" id="idm45634176123416">
<h1>Closing Remarks</h1>

<p>In this chapter, we introduced several blueprints that can be used for sentiment analysis. They range from simple lexicon-based approaches to complex state-of-the-art language models. If your <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="use cases for" id="idm45634176107960"/><a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for sentiment analysis of text data" data-secondary-sortas="sentiment analysis of text data" id="idm45634176106616"/>use case is a one-time analysis to determine the sentiment of a particular topic using Twitter data, then the first blueprint would be most suitable. If you are looking to create a ranking of products/brands using sentiment expressed in customer reviews or route customer complaints based on their sentiment, then a supervised machine learning approach as described in the second and third blueprints would be more suitable. If accuracy is of utmost importance, the best results are obtained by using a pretrained language model, but this is also a more complicated and expensive technique. Each blueprint is appropriate for a given use case, and the crucial thing is to determine which approach is suitable for your needs. In general, you must find a method that works well for your use case, and the suggestion would always be to keep it simple at the start and then increase the complexity to get <a contenteditable="false" data-type="indexterm" data-primary="sentiment analysis of text data" data-secondary="further reading on" id="idm45634176103992"/>better results.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Further Reading"><div class="sect1" id="ch11_reading">
<h1>Further Reading</h1>

<ul class="author-date-bib">
  <li>Kolecki, Joseph C. “An Introduction to Tensors for Students of Physics and Engineering.” <a href="https://www.grc.nasa.gov/WWW/k-12/Numbers/Math/documents/Tensors_TM2002211716.pdf"><em>https://www.grc.nasa.gov/WWW/k-12/Numbers/Math/documents/Tensors_TM2002211716.pdf</em></a>.</li>
  <li>McCormick, Chris, and Nick Ryan. “BERT Word Embedding Tutorial.” <a href="http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial"><em>http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial</em></a>.</li>
  <li class="pagebreak-before">Olah, Christopher. “Understanding LSTMs.” <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs"><em>https://colah.github.io/posts/2015-08-Understanding-LSTMs</em></a>.</li>
  <li>Uszkoreit, Jakob. “Transformer: A Novel Neural Network Architecture for Language Understanding.” <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html"><em>https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html</em></a>.</li>
</ul>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="idm45634178845144"><sup><a href="ch11.xhtml#idm45634178845144-marker">1</a></sup> J. McAuley and J. Leskovec. “Hidden Factors and Hidden Topics: Understanding Rating Dimensions with Review Text.” RecSys, 2013. <a href="https://snap.stanford.edu/data/web-Amazon.html"><em>https://snap.stanford.edu/data/web-Amazon.html</em></a>.</p><p data-type="footnote" id="idm45634178750888"><sup><a href="ch11.xhtml#idm45634178750888-marker">2</a></sup> “Interest Group on German Sentiment Analysis, Multi-Domain Sentiment Lexicon for German,” <a href="https://oreil.ly/WpMhF"><em>https://oreil.ly/WpMhF</em></a>.</p><p data-type="footnote" id="idm45634178748968"><sup><a href="ch11.xhtml#idm45634178748968-marker">3</a></sup> Yanqing Chen and Steven Skiena. <a href="https://oreil.ly/Inbs8"><em>Building Sentiment Lexicons for All Major Languages</em></a>. Lexicons available on <a href="https://oreil.ly/xTeH4">Kaggle</a>.</p><p data-type="footnote" id="idm45634177455096"><sup><a href="ch11.xhtml#idm45634177455096-marker">4</a></sup> Ashish Vaswani et al. “Attention Is All You Need.” 2017. <a href="https://arxiv.org/abs/1706.03762"><em>https://arxiv.org/abs/1706.03762</em></a>.</p><p data-type="footnote" id="idm45634176762520"><sup><a href="ch11.xhtml#idm45634176762520-marker">5</a></sup> Robin M. Schmidt, Frank Schneider, and Phillipp Hennig. “Descending through a Crowded Valley: Benchmarking Deep Learning Optimizers.” 2020. <a href="https://arxiv.org/pdf/2007.01547.pdf"><em>https://arxiv.org/pdf/2007.01547.pdf</em></a>.</p></div></div></section></div>



  </body></html>