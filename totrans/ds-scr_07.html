<html><head></head><body><section data-pdf-bookmark="Chapter 6. Probability" data-type="chapter" epub:type="chapter"><div class="chapter" id="probability">&#13;
<h1><span class="label">Chapter 6. </span>Probability</h1>&#13;
&#13;
<blockquote data-type="epigraph" epub:type="epigraph">&#13;
<p>The laws of probability, so true in general, so fallacious in particular.</p>&#13;
<p data-type="attribution">Edward Gibbon</p>&#13;
</blockquote>&#13;
&#13;
<p>It<a data-primary="mathematics" data-secondary="probability" data-type="indexterm" id="Mprob06"/> is hard to do data science without some sort of understanding of <em>probability</em> and its mathematics. As with our treatment of statistics in <a data-type="xref" href="ch05.html#statistics">Chapter 5</a>, we’ll wave our hands a lot and elide many of the technicalities.</p>&#13;
&#13;
<p>For<a data-primary="probability" data-secondary="definition of term" data-type="indexterm" id="idm45635756619080"/> our purposes you should think of probability as a way of quantifying the uncertainty associated with <em>events</em> chosen from some <em>universe</em> of events.  Rather than getting technical about what these terms mean, think of rolling a die.  The universe consists of all possible outcomes.  And any subset of these outcomes is an event; for example, “the die rolls a 1” or “the die rolls an even number.”</p>&#13;
&#13;
<p>Notationally, we write <em>P</em>(<em>E</em>) to mean “the probability of the event <em>E</em>.”</p>&#13;
&#13;
<p>We’ll use probability theory to build models. We’ll use probability theory to evaluate models.&#13;
We’ll use probability theory all over the place.</p>&#13;
&#13;
<p>One could, were one so inclined, get really deep into the philosophy of&#13;
what probability theory <em>means</em>. (This is best done over beers.) We won’t be doing that.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Dependence and Independence" data-type="sect1"><div class="sect1" id="idm45635756613304">&#13;
<h1>Dependence and Independence</h1>&#13;
&#13;
<p>Roughly<a data-primary="probability" data-secondary="dependence and independence" data-type="indexterm" id="idm45635756611496"/><a data-primary="dependence" data-type="indexterm" id="idm45635756610472"/><a data-primary="independence" data-type="indexterm" id="idm45635756609800"/> speaking, we say that two events <em>E</em> and <em>F</em> are <em>dependent</em> if knowing something about whether <em>E</em> happens gives us information about whether <em>F</em> happens (and vice versa).  Otherwise, they are <em>independent</em>.</p>&#13;
&#13;
<p>For instance, if we flip a fair coin twice, knowing whether the first flip is heads gives us no information about whether the second flip is heads.  These events are independent.  On the other hand, knowing whether the first flip is heads certainly gives us information about whether both flips are tails.  (If the first flip is heads, then definitely it’s not the case that both flips are tails.)  These two events are dependent.</p>&#13;
&#13;
<p>Mathematically, we say that two events <em>E</em> and <em>F</em> are independent if the probability that they both happen is the product of the probabilities that each one happens:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper E comma upper F right-parenthesis equals upper P left-parenthesis upper E right-parenthesis upper P left-parenthesis upper F right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>,</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>In the example, the probability of “first flip heads” is 1/2, and the probability of “both flips tails” is 1/4, but the probability of “first flip heads <em>and</em> both flips tails” is 0.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Conditional Probability" data-type="sect1"><div class="sect1" id="conditional_probability">&#13;
<h1>Conditional Probability</h1>&#13;
&#13;
<p>When<a data-primary="probability" data-secondary="conditional probability" data-type="indexterm" id="idm45635756591384"/><a data-primary="conditional probability" data-type="indexterm" id="idm45635756590488"/> two events <em>E</em> and <em>F</em> are independent, then by definition we have:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper E comma upper F right-parenthesis equals upper P left-parenthesis upper E right-parenthesis upper P left-parenthesis upper F right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>,</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>If they are not necessarily independent (and if the probability of <em>F</em> is not zero), then we define the probability of <em>E</em> “conditional on <em>F</em>” as:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper E vertical-bar upper F right-parenthesis equals upper P left-parenthesis upper E comma upper F right-parenthesis slash upper P left-parenthesis upper F right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>|</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>,</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>/</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>You should think of this as the probability that <em>E</em> happens, given that we know that <em>F</em> happens.</p>&#13;
&#13;
<p>We often rewrite this as:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper E comma upper F right-parenthesis equals upper P left-parenthesis upper E vertical-bar upper F right-parenthesis upper P left-parenthesis upper F right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>,</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>|</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>When <em>E</em> and <em>F</em> are independent, you can check that this gives:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper E vertical-bar upper F right-parenthesis equals upper P left-parenthesis upper E right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>|</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>which is the mathematical way of expressing that knowing <em>F</em> occurred gives us no additional information about whether <em>E</em> occurred.</p>&#13;
&#13;
<p>One common tricky example involves a family with two (unknown) children. If we assume that:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Each child is equally likely to be a boy or a girl.</p>&#13;
</li>&#13;
<li>&#13;
<p>The gender of the second child is independent of the gender of the first child.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Then the event “no girls” has probability 1/4,&#13;
the event “one girl, one boy” has probability 1/2,&#13;
and the event “two girls” has probability 1/4.</p>&#13;
&#13;
<p>Now we can ask what is the probability of the event “both children are girls” (<em>B</em>) conditional on the event “the older child is a girl” (<em>G</em>)?  Using the definition of conditional probability:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper B vertical-bar upper G right-parenthesis equals upper P left-parenthesis upper B comma upper G right-parenthesis slash upper P left-parenthesis upper G right-parenthesis equals upper P left-parenthesis upper B right-parenthesis slash upper P left-parenthesis upper G right-parenthesis equals 1 slash 2" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>B</mi>&#13;
    <mo>|</mo>&#13;
    <mi>G</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>B</mi>&#13;
    <mo>,</mo>&#13;
    <mi>G</mi>&#13;
    <mo>)</mo>&#13;
    <mo>/</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>G</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>B</mi>&#13;
    <mo>)</mo>&#13;
    <mo>/</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>G</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
    <mo>/</mo>&#13;
    <mn>2</mn>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>since the event <em>B</em> and <em>G</em> (“both children are girls <em>and</em> the older child is a girl”) is just the event <em>B</em>.  (Once you know that both children are girls, it’s necessarily true that the older child is a girl.)</p>&#13;
&#13;
<p>Most likely this result accords with your intuition.</p>&#13;
&#13;
<p>We could also ask about the probability of the event “both children are girls” conditional on the event “at least one of the children is a girl” (<em>L</em>).  Surprisingly, the answer is different from before!</p>&#13;
&#13;
<p>As before, the event <em>B</em> and <em>L</em> (“both children are girls <em>and</em> at least one of the children is a girl”) is just the event <em>B</em>.  This means we have:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper B vertical-bar upper L right-parenthesis equals upper P left-parenthesis upper B comma upper L right-parenthesis slash upper P left-parenthesis upper L right-parenthesis equals upper P left-parenthesis upper B right-parenthesis slash upper P left-parenthesis upper L right-parenthesis equals 1 slash 3" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>B</mi>&#13;
    <mo>|</mo>&#13;
    <mi>L</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>B</mi>&#13;
    <mo>,</mo>&#13;
    <mi>L</mi>&#13;
    <mo>)</mo>&#13;
    <mo>/</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>L</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>B</mi>&#13;
    <mo>)</mo>&#13;
    <mo>/</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>L</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
    <mo>/</mo>&#13;
    <mn>3</mn>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>How can this be the case?  Well, if all you know is that at least one of the children is a girl, then it is twice as likely that the family has one boy and one girl than that it has both girls.</p>&#13;
&#13;
<p>We can check this by “generating” a lot of families:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">enum</code><code class="o">,</code> <code class="nn">random</code>&#13;
&#13;
<code class="c1"># An Enum is a typed set of enumerated values. We can use them</code>&#13;
<code class="c1"># to make our code more descriptive and readable.</code>&#13;
<code class="k">class</code> <code class="nc">Kid</code><code class="p">(</code><code class="n">enum</code><code class="o">.</code><code class="n">Enum</code><code class="p">):</code>&#13;
    <code class="n">BOY</code> <code class="o">=</code> <code class="mi">0</code>&#13;
    <code class="n">GIRL</code> <code class="o">=</code> <code class="mi">1</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">random_kid</code><code class="p">()</code> <code class="o">-&gt;</code> <code class="n">Kid</code><code class="p">:</code>&#13;
    <code class="k">return</code> <code class="n">random</code><code class="o">.</code><code class="n">choice</code><code class="p">([</code><code class="n">Kid</code><code class="o">.</code><code class="n">BOY</code><code class="p">,</code> <code class="n">Kid</code><code class="o">.</code><code class="n">GIRL</code><code class="p">])</code>&#13;
&#13;
<code class="n">both_girls</code> <code class="o">=</code> <code class="mi">0</code>&#13;
<code class="n">older_girl</code> <code class="o">=</code> <code class="mi">0</code>&#13;
<code class="n">either_girl</code> <code class="o">=</code> <code class="mi">0</code>&#13;
&#13;
<code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code>&#13;
&#13;
<code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">10000</code><code class="p">):</code>&#13;
    <code class="n">younger</code> <code class="o">=</code> <code class="n">random_kid</code><code class="p">()</code>&#13;
    <code class="n">older</code> <code class="o">=</code> <code class="n">random_kid</code><code class="p">()</code>&#13;
    <code class="k">if</code> <code class="n">older</code> <code class="o">==</code> <code class="n">Kid</code><code class="o">.</code><code class="n">GIRL</code><code class="p">:</code>&#13;
        <code class="n">older_girl</code> <code class="o">+=</code> <code class="mi">1</code>&#13;
    <code class="k">if</code> <code class="n">older</code> <code class="o">==</code> <code class="n">Kid</code><code class="o">.</code><code class="n">GIRL</code> <code class="ow">and</code> <code class="n">younger</code> <code class="o">==</code> <code class="n">Kid</code><code class="o">.</code><code class="n">GIRL</code><code class="p">:</code>&#13;
        <code class="n">both_girls</code> <code class="o">+=</code> <code class="mi">1</code>&#13;
    <code class="k">if</code> <code class="n">older</code> <code class="o">==</code> <code class="n">Kid</code><code class="o">.</code><code class="n">GIRL</code> <code class="ow">or</code> <code class="n">younger</code> <code class="o">==</code> <code class="n">Kid</code><code class="o">.</code><code class="n">GIRL</code><code class="p">:</code>&#13;
        <code class="n">either_girl</code> <code class="o">+=</code> <code class="mi">1</code>&#13;
&#13;
<code class="k">print</code><code class="p">(</code><code class="s2">"P(both | older):"</code><code class="p">,</code> <code class="n">both_girls</code> <code class="o">/</code> <code class="n">older_girl</code><code class="p">)</code>     <code class="c1"># 0.514 ~ 1/2</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="s2">"P(both | either): "</code><code class="p">,</code> <code class="n">both_girls</code> <code class="o">/</code> <code class="n">either_girl</code><code class="p">)</code>  <code class="c1"># 0.342 ~ 1/3</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Bayes’s Theorem" data-type="sect1"><div class="sect1" id="bayes_theorem">&#13;
<h1>Bayes’s Theorem</h1>&#13;
&#13;
<p>One<a data-primary="Bayes’s theorem" data-type="indexterm" id="idm45635756494920"/><a data-primary="probability" data-secondary="Bayes’s theorem" data-type="indexterm" id="idm45635756494184"/> of the data scientist’s best friends is Bayes’s theorem, which is a way of “reversing” conditional probabilities.  Let’s say we need to know the probability of some event <em>E</em>&#13;
conditional on some other event <em>F</em> occurring.&#13;
But we only have information about the probability of <em>F</em> conditional on <em>E</em> occurring.&#13;
Using the definition of conditional probability twice tells us that:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper E vertical-bar upper F right-parenthesis equals upper P left-parenthesis upper E comma upper F right-parenthesis slash upper P left-parenthesis upper F right-parenthesis equals upper P left-parenthesis upper F vertical-bar upper E right-parenthesis upper P left-parenthesis upper E right-parenthesis slash upper P left-parenthesis upper F right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>|</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>,</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>/</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>|</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mo>/</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>The event <em>F</em> can be split into the two mutually exclusive events “<em>F</em> and <em>E</em>” and  “<em>F</em> and not <em>E</em>.”  If we write <math>&#13;
  <mrow>&#13;
    <mo>¬</mo>&#13;
    <mi>E</mi>&#13;
  </mrow>&#13;
</math> for “not <em>E</em>” (i.e., “<em>E</em> doesn’t happen”), then:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper F right-parenthesis equals upper P left-parenthesis upper F comma upper E right-parenthesis plus upper P left-parenthesis upper F comma normal not-sign upper E right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>,</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mo>+</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>,</mo>&#13;
    <mo>¬</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>so that:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper E vertical-bar upper F right-parenthesis equals upper P left-parenthesis upper F vertical-bar upper E right-parenthesis upper P left-parenthesis upper E right-parenthesis slash left-bracket upper P left-parenthesis upper F vertical-bar upper E right-parenthesis upper P left-parenthesis upper E right-parenthesis plus upper P left-parenthesis upper F vertical-bar normal not-sign upper E right-parenthesis upper P left-parenthesis normal not-sign upper E right-parenthesis right-bracket" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>|</mo>&#13;
    <mi>F</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>|</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mo>/</mo>&#13;
    <mo>[</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>|</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mo>+</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>F</mi>&#13;
    <mo>|</mo>&#13;
    <mo>¬</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mo>¬</mo>&#13;
    <mi>E</mi>&#13;
    <mo>)</mo>&#13;
    <mo>]</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>which is how Bayes’s theorem is often stated.</p>&#13;
&#13;
<p>This theorem often gets used to demonstrate why data scientists are smarter than doctors.  Imagine a certain disease that affects 1 in every 10,000 people.  And imagine that there is a test for this disease that gives the correct result (“diseased” if you have the disease, “nondiseased” if you don’t) 99% of the time.</p>&#13;
&#13;
<p>What does a positive test mean?  Let’s use <em>T</em> for the event “your test is positive” and <em>D</em> for the event “you have the disease.”  Then Bayes’s theorem says that the probability that you have the disease, conditional on testing positive, is:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper D vertical-bar upper T right-parenthesis equals upper P left-parenthesis upper T vertical-bar upper D right-parenthesis upper P left-parenthesis upper D right-parenthesis slash left-bracket upper P left-parenthesis upper T vertical-bar upper D right-parenthesis upper P left-parenthesis upper D right-parenthesis plus upper P left-parenthesis upper T vertical-bar normal not-sign upper D right-parenthesis upper P left-parenthesis normal not-sign upper D right-parenthesis right-bracket" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>D</mi>&#13;
    <mo>|</mo>&#13;
    <mi>T</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>T</mi>&#13;
    <mo>|</mo>&#13;
    <mi>D</mi>&#13;
    <mo>)</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>D</mi>&#13;
    <mo>)</mo>&#13;
    <mo>/</mo>&#13;
    <mo>[</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>T</mi>&#13;
    <mo>|</mo>&#13;
    <mi>D</mi>&#13;
    <mo>)</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>D</mi>&#13;
    <mo>)</mo>&#13;
    <mo>+</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>T</mi>&#13;
    <mo>|</mo>&#13;
    <mo>¬</mo>&#13;
    <mi>D</mi>&#13;
    <mo>)</mo>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mo>¬</mo>&#13;
    <mi>D</mi>&#13;
    <mo>)</mo>&#13;
    <mo>]</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>Here we know that <math>&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>T</mi>&#13;
    <mo>|</mo>&#13;
    <mi>D</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>, the probability that someone with the disease tests positive, is 0.99. <em>P</em>(<em>D</em>), the probability that any given person has the disease, is 1/10,000 = 0.0001.  <math>&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>T</mi>&#13;
    <mo>|</mo>&#13;
    <mo>¬</mo>&#13;
    <mi>D</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>, the probability that someone without the disease tests positive, is 0.01. And <math>&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mo>¬</mo>&#13;
    <mi>D</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>, the probability that any given person doesn’t have the disease, is 0.9999. If you substitute these numbers into Bayes’s theorem, you find:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper P left-parenthesis upper D vertical-bar upper T right-parenthesis equals 0.98 percent-sign" display="block">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <mi>D</mi>&#13;
    <mo>|</mo>&#13;
    <mi>T</mi>&#13;
    <mo>)</mo>&#13;
    <mo>=</mo>&#13;
    <mn>0</mn>&#13;
    <mo>.</mo>&#13;
    <mn>98</mn>&#13;
    <mo>%</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>That is, less than 1% of the people who test positive actually have the disease.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>This assumes that people take the test more or less at random.  If only people with certain symptoms take the test, we would instead have to condition on the event “positive test <em>and</em> symptoms” and the number would likely be a lot higher.</p>&#13;
</div>&#13;
&#13;
<p>A more intuitive way to see this is to imagine a population of 1 million people.  You’d expect 100 of them to have the disease, and 99 of those 100 to test positive.  On the other hand, you’d expect 999,900 of them not to have the disease, and 9,999 of those to test positive.  That means you’d expect only 99 out of (99 + 9999) positive testers to actually have the disease.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Random Variables" data-type="sect1"><div class="sect1" id="idm45635756496456">&#13;
<h1>Random Variables</h1>&#13;
&#13;
<p>A <em>random variable</em> is<a data-primary="probability" data-secondary="random variables" data-type="indexterm" id="idm45635756256552"/><a data-primary="random variables" data-type="indexterm" id="idm45635756255544"/><a data-primary="variables" data-secondary="random variables" data-type="indexterm" id="idm45635756254872"/> a variable whose possible values have an associated&#13;
probability distribution.  A very simple random variable equals 1 if a coin flip&#13;
turns up heads and 0 if the flip turns up tails.  A more complicated one might measure&#13;
the number of heads you observe when flipping a coin 10 times&#13;
or a value picked from <code>range(10)</code> where each number is equally likely.</p>&#13;
&#13;
<p>The associated distribution gives the&#13;
probabilities that the variable realizes each of its possible values.  The coin flip variable&#13;
equals 0 with probability 0.5 and 1 with probability 0.5.  The <code>range(10)</code> variable&#13;
has a distribution that assigns probability 0.1 to each of the numbers from 0 to 9.</p>&#13;
&#13;
<p>We will sometimes talk about the <em>expected value</em> of a random variable,&#13;
which is the average of its values weighted by their probabilities.&#13;
The coin flip variable has an expected value of 1/2 (= 0 * 1/2 + 1 * 1/2),&#13;
and the <code>range(10)</code> variable has an expected value of 4.5.</p>&#13;
&#13;
<p>Random variables can be <em>conditioned</em> on events just as other events can.&#13;
Going back to the two-child example from <a data-type="xref" href="#conditional_probability">“Conditional Probability”</a>, if <em>X</em>&#13;
is the random variable representing the number of girls, <em>X</em> equals 0 with probability 1/4,&#13;
1 with probability 1/2, and 2 with probability 1/4.</p>&#13;
&#13;
<p>We can define a new random variable <em>Y</em> that gives the number of girls conditional on at least one of the children being a girl.  Then <em>Y</em> equals 1 with probability 2/3 and 2 with probability 1/3.  And a variable <em>Z</em> that’s the number of girls conditional on the older child being a girl equals 1 with probability 1/2 and 2 with probability 1/2.</p>&#13;
&#13;
<p>For the most part, we will be using random variables <em>implicitly</em> in what we do without calling special attention to them.  But if you look deeply you’ll see them.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Continuous Distributions" data-type="sect1"><div class="sect1" id="idm45635756244856">&#13;
<h1>Continuous Distributions</h1>&#13;
&#13;
<p>A<a data-primary="probability" data-secondary="continuous distributions" data-type="indexterm" id="idm45635756242936"/><a data-primary="continuous distributions" data-type="indexterm" id="idm45635756241912"/><a data-primary="discrete distributions" data-type="indexterm" id="idm45635756241224"/> coin flip corresponds to a <em>discrete distribution</em>—one that associates positive probability with discrete outcomes.  Often we’ll want to model distributions across a continuum of outcomes.  (For our purposes, these outcomes will always be real numbers, although that’s not always the case in real life.) For example,<a data-primary="uniform distributions" data-type="indexterm" id="idm45635756179352"/> the <em>uniform distribution</em> puts <em>equal weight</em> on all the numbers between 0 and 1.</p>&#13;
&#13;
<p>Because there are infinitely many numbers between 0 and 1, this means that the weight it assigns to individual points must necessarily be zero.  For<a data-primary="probability density function (PDF)" data-type="indexterm" id="idm45635756177208"/> this reason, we represent a continuous distribution with a <em>probability density function</em> (PDF) such that the probability of seeing a value in a certain interval equals the integral of the density function over the interval.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>If your integral calculus is rusty, a simpler way of understanding this is that if a distribution has density function <em>f</em>, then the probability of seeing a value between <em>x</em> and <em>x + h</em> is approximately <em>h * f(x)</em> if <em>h</em> is small.</p>&#13;
</div>&#13;
&#13;
<p>The density function for the uniform distribution is just:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">uniform_pdf</code><code class="p">(</code><code class="n">x</code><code class="p">:</code> <code class="nb">float</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="k">return</code> <code class="mi">1</code> <code class="k">if</code> <code class="mi">0</code> <code class="o">&lt;=</code> <code class="n">x</code> <code class="o">&lt;</code> <code class="mi">1</code> <code class="k">else</code> <code class="mi">0</code></pre>&#13;
&#13;
<p>The probability that a random variable following that distribution is between 0.2 and 0.3 is 1/10, as you’d expect.  Python’s <code>random.random</code> is a (pseudo)random variable with a uniform density.</p>&#13;
&#13;
<p>We<a data-primary="cumulative distribution function (CDF)" data-type="indexterm" id="idm45635756146216"/> will often be more interested in the <em>cumulative distribution function</em> (CDF), which gives the probability that a random variable is less than or equal to a certain value. It’s not hard to create the CDF for the uniform distribution (<a data-type="xref" href="#uniform_cdf">Figure 6-1</a>):</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">uniform_cdf</code><code class="p">(</code><code class="n">x</code><code class="p">:</code> <code class="nb">float</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""Returns the probability that a uniform random variable is &lt;= x"""</code>&#13;
    <code class="k">if</code> <code class="n">x</code> <code class="o">&lt;</code> <code class="mi">0</code><code class="p">:</code>   <code class="k">return</code> <code class="mi">0</code>    <code class="c1"># uniform random is never less than 0</code>&#13;
    <code class="k">elif</code> <code class="n">x</code> <code class="o">&lt;</code> <code class="mi">1</code><code class="p">:</code> <code class="k">return</code> <code class="n">x</code>    <code class="c1"># e.g. P(X &lt;= 0.4) = 0.4</code>&#13;
    <code class="k">else</code><code class="p">:</code>       <code class="k">return</code> <code class="mi">1</code>    <code class="c1"># uniform random is always less than 1</code></pre>&#13;
&#13;
<figure><div class="figure" id="uniform_cdf">&#13;
<img alt="Uniform CDF." src="assets/dsf2_0601.png"/>&#13;
<h6><span class="label">Figure 6-1. </span>The uniform CDF</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Normal Distribution" data-type="sect1"><div class="sect1" id="normal_distribution">&#13;
<h1>The Normal Distribution</h1>&#13;
&#13;
<p>The<a data-primary="bell-shaped curve" data-type="indexterm" id="idm45635756084648"/><a data-primary="probability" data-secondary="normal distribution" data-type="indexterm" id="idm45635756083912"/><a data-primary="normal distribution" data-type="indexterm" id="idm45635756082968"/> normal distribution is the classic bell curve–shaped distribution   and is completely determined by two parameters: its mean <em>μ</em> (mu) and its standard deviation <em>σ</em> (sigma).  The mean indicates where the bell is centered, and the standard deviation how “wide” it is.</p>&#13;
&#13;
<p>It has the PDF:</p>&#13;
<div data-type="equation">&#13;
<math alttext="f left-parenthesis x vertical-bar mu comma sigma right-parenthesis equals StartFraction 1 Over StartRoot 2 pi EndRoot sigma EndFraction exp left-parenthesis minus StartFraction left-parenthesis x minus mu right-parenthesis squared Over 2 sigma squared EndFraction right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>f</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>x</mi>&#13;
      <mo>|</mo>&#13;
      <mi>μ</mi>&#13;
      <mo>,</mo>&#13;
      <mi>σ</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <mfrac><mn>1</mn> <mrow><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt><mi>σ</mi></mrow></mfrac>&#13;
    <mo form="prefix">exp</mo>&#13;
    <mo>(</mo>&#13;
    <mrow>&#13;
      <mo>-</mo>&#13;
      <mfrac><msup><mrow><mo>(</mo><mi>x</mi><mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn> </msup> <mrow><mn>2</mn><msup><mi>σ</mi> <mn>2</mn> </msup></mrow></mfrac>&#13;
      <mrow>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>which we can implement as:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">math</code>&#13;
<code class="n">SQRT_TWO_PI</code> <code class="o">=</code> <code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="mi">2</code> <code class="o">*</code> <code class="n">math</code><code class="o">.</code><code class="n">pi</code><code class="p">)</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">normal_pdf</code><code class="p">(</code><code class="n">x</code><code class="p">:</code> <code class="nb">float</code><code class="p">,</code> <code class="n">mu</code><code class="p">:</code> <code class="nb">float</code> <code class="o">=</code> <code class="mi">0</code><code class="p">,</code> <code class="n">sigma</code><code class="p">:</code> <code class="nb">float</code> <code class="o">=</code> <code class="mi">1</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="k">return</code> <code class="p">(</code><code class="n">math</code><code class="o">.</code><code class="n">exp</code><code class="p">(</code><code class="o">-</code><code class="p">(</code><code class="n">x</code><code class="o">-</code><code class="n">mu</code><code class="p">)</code> <code class="o">**</code> <code class="mi">2</code> <code class="o">/</code> <code class="mi">2</code> <code class="o">/</code> <code class="n">sigma</code> <code class="o">**</code> <code class="mi">2</code><code class="p">)</code> <code class="o">/</code> <code class="p">(</code><code class="n">SQRT_TWO_PI</code> <code class="o">*</code> <code class="n">sigma</code><code class="p">))</code></pre>&#13;
&#13;
<p>In <a data-type="xref" href="#various_normal_pdfs">Figure 6-2</a>, we plot some of these PDFs to see what they look like:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="kn">as</code> <code class="nn">plt</code>&#13;
<code class="n">xs</code> <code class="o">=</code> <code class="p">[</code><code class="n">x</code> <code class="o">/</code> <code class="mf">10.0</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="o">-</code><code class="mi">50</code><code class="p">,</code> <code class="mi">50</code><code class="p">)]</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">xs</code><code class="p">,[</code><code class="n">normal_pdf</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code class="n">sigma</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">],</code><code class="s1">'-'</code><code class="p">,</code><code class="n">label</code><code class="o">=</code><code class="s1">'mu=0,sigma=1'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">xs</code><code class="p">,[</code><code class="n">normal_pdf</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code class="n">sigma</code><code class="o">=</code><code class="mi">2</code><code class="p">)</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">],</code><code class="s1">'--'</code><code class="p">,</code><code class="n">label</code><code class="o">=</code><code class="s1">'mu=0,sigma=2'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">xs</code><code class="p">,[</code><code class="n">normal_pdf</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code class="n">sigma</code><code class="o">=</code><code class="mf">0.5</code><code class="p">)</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">],</code><code class="s1">':'</code><code class="p">,</code><code class="n">label</code><code class="o">=</code><code class="s1">'mu=0,sigma=0.5'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">xs</code><code class="p">,[</code><code class="n">normal_pdf</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code class="n">mu</code><code class="o">=-</code><code class="mi">1</code><code class="p">)</code>   <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">],</code><code class="s1">'-.'</code><code class="p">,</code><code class="n">label</code><code class="o">=</code><code class="s1">'mu=-1,sigma=1'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">()</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s2">"Various Normal pdfs"</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>&#13;
&#13;
<figure><div class="figure" id="various_normal_pdfs">&#13;
<img alt="Various normal pdfs." src="assets/dsf2_0602.png"/>&#13;
<h6><span class="label">Figure 6-2. </span>Various normal PDFs</h6>&#13;
</div></figure>&#13;
&#13;
<p>When <em>μ</em> = 0 and <em>σ</em> = 1, it’s called<a data-primary="standard normal distribution" data-type="indexterm" id="idm45635755801928"/> the <em>standard normal distribution</em>.  If <em>Z</em> is a standard normal random variable, then it turns out that:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper X equals sigma upper Z plus mu" display="block">&#13;
  <mrow>&#13;
    <mi>X</mi>&#13;
    <mo>=</mo>&#13;
    <mi>σ</mi>&#13;
    <mi>Z</mi>&#13;
    <mo>+</mo>&#13;
    <mi>μ</mi>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>is also normal but with mean <math alttext="mu">&#13;
  <mi>μ</mi>&#13;
</math> and standard deviation <math alttext="sigma">&#13;
  <mi>σ</mi>&#13;
</math>.  Conversely, if <em>X</em> is a normal random variable with mean <math alttext="mu">&#13;
  <mi>μ</mi>&#13;
</math> and standard deviation <math alttext="sigma">&#13;
  <mi>σ</mi>&#13;
</math>,</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper Z equals left-parenthesis upper X minus mu right-parenthesis slash sigma" display="block">&#13;
  <mrow>&#13;
    <mi>Z</mi>&#13;
    <mo>=</mo>&#13;
    <mo>(</mo>&#13;
    <mi>X</mi>&#13;
    <mo>-</mo>&#13;
    <mi>μ</mi>&#13;
    <mo>)</mo>&#13;
    <mo>/</mo>&#13;
    <mi>σ</mi>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>is a standard normal variable.</p>&#13;
&#13;
<p>The CDF for the normal distribution cannot be written in an “elementary” manner, but we can write it using Python’s <code>math.erf</code> <a href="http://en.wikipedia.org/wiki/Error_function">error function</a>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">normal_cdf</code><code class="p">(</code><code class="n">x</code><code class="p">:</code> <code class="nb">float</code><code class="p">,</code> <code class="n">mu</code><code class="p">:</code> <code class="nb">float</code> <code class="o">=</code> <code class="mi">0</code><code class="p">,</code> <code class="n">sigma</code><code class="p">:</code> <code class="nb">float</code> <code class="o">=</code> <code class="mi">1</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="k">return</code> <code class="p">(</code><code class="mi">1</code> <code class="o">+</code> <code class="n">math</code><code class="o">.</code><code class="n">erf</code><code class="p">((</code><code class="n">x</code> <code class="o">-</code> <code class="n">mu</code><code class="p">)</code> <code class="o">/</code> <code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code> <code class="o">/</code> <code class="n">sigma</code><code class="p">))</code> <code class="o">/</code> <code class="mi">2</code></pre>&#13;
&#13;
<p>Again, in <a data-type="xref" href="#various_normal_cdfs">Figure 6-3</a>, we plot a few CDFs:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">xs</code> <code class="o">=</code> <code class="p">[</code><code class="n">x</code> <code class="o">/</code> <code class="mf">10.0</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="o">-</code><code class="mi">50</code><code class="p">,</code> <code class="mi">50</code><code class="p">)]</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">xs</code><code class="p">,[</code><code class="n">normal_cdf</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code class="n">sigma</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">],</code><code class="s1">'-'</code><code class="p">,</code><code class="n">label</code><code class="o">=</code><code class="s1">'mu=0,sigma=1'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">xs</code><code class="p">,[</code><code class="n">normal_cdf</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code class="n">sigma</code><code class="o">=</code><code class="mi">2</code><code class="p">)</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">],</code><code class="s1">'--'</code><code class="p">,</code><code class="n">label</code><code class="o">=</code><code class="s1">'mu=0,sigma=2'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">xs</code><code class="p">,[</code><code class="n">normal_cdf</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code class="n">sigma</code><code class="o">=</code><code class="mf">0.5</code><code class="p">)</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">],</code><code class="s1">':'</code><code class="p">,</code><code class="n">label</code><code class="o">=</code><code class="s1">'mu=0,sigma=0.5'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">xs</code><code class="p">,[</code><code class="n">normal_cdf</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code class="n">mu</code><code class="o">=-</code><code class="mi">1</code><code class="p">)</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">],</code><code class="s1">'-.'</code><code class="p">,</code><code class="n">label</code><code class="o">=</code><code class="s1">'mu=-1,sigma=1'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="mi">4</code><code class="p">)</code> <code class="c1"># bottom right</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s2">"Various Normal cdfs"</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>&#13;
&#13;
<figure><div class="figure" id="various_normal_cdfs">&#13;
<img alt="Various normal cdfs." src="assets/dsf2_0603.png"/>&#13;
<h6><span class="label">Figure 6-3. </span>Various normal CDFs</h6>&#13;
</div></figure>&#13;
&#13;
<p>Sometimes we’ll need to invert <code>normal_cdf</code> to find the value&#13;
corresponding to a specified probability.&#13;
There’s no simple way to compute its inverse,&#13;
but <code>normal_cdf</code> is continuous and strictly increasing,&#13;
so we can use a <a href="http://en.wikipedia.org/wiki/Binary_search_algorithm"><em>binary search</em></a>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">inverse_normal_cdf</code><code class="p">(</code><code class="n">p</code><code class="p">:</code> <code class="nb">float</code><code class="p">,</code>&#13;
                       <code class="n">mu</code><code class="p">:</code> <code class="nb">float</code> <code class="o">=</code> <code class="mi">0</code><code class="p">,</code>&#13;
                       <code class="n">sigma</code><code class="p">:</code> <code class="nb">float</code> <code class="o">=</code> <code class="mi">1</code><code class="p">,</code>&#13;
                       <code class="n">tolerance</code><code class="p">:</code> <code class="nb">float</code> <code class="o">=</code> <code class="mf">0.00001</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""Find approximate inverse using binary search"""</code>&#13;
&#13;
    <code class="c1"># if not standard, compute standard and rescale</code>&#13;
    <code class="k">if</code> <code class="n">mu</code> <code class="o">!=</code> <code class="mi">0</code> <code class="ow">or</code> <code class="n">sigma</code> <code class="o">!=</code> <code class="mi">1</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="n">mu</code> <code class="o">+</code> <code class="n">sigma</code> <code class="o">*</code> <code class="n">inverse_normal_cdf</code><code class="p">(</code><code class="n">p</code><code class="p">,</code> <code class="n">tolerance</code><code class="o">=</code><code class="n">tolerance</code><code class="p">)</code>&#13;
&#13;
    <code class="n">low_z</code> <code class="o">=</code> <code class="o">-</code><code class="mf">10.0</code>                      <code class="c1"># normal_cdf(-10) is (very close to) 0</code>&#13;
    <code class="n">hi_z</code>  <code class="o">=</code>  <code class="mf">10.0</code>                      <code class="c1"># normal_cdf(10)  is (very close to) 1</code>&#13;
    <code class="k">while</code> <code class="n">hi_z</code> <code class="o">-</code> <code class="n">low_z</code> <code class="o">&gt;</code> <code class="n">tolerance</code><code class="p">:</code>&#13;
        <code class="n">mid_z</code> <code class="o">=</code> <code class="p">(</code><code class="n">low_z</code> <code class="o">+</code> <code class="n">hi_z</code><code class="p">)</code> <code class="o">/</code> <code class="mi">2</code>     <code class="c1"># Consider the midpoint</code>&#13;
        <code class="n">mid_p</code> <code class="o">=</code> <code class="n">normal_cdf</code><code class="p">(</code><code class="n">mid_z</code><code class="p">)</code>      <code class="c1"># and the CDF's value there</code>&#13;
        <code class="k">if</code> <code class="n">mid_p</code> <code class="o">&lt;</code> <code class="n">p</code><code class="p">:</code>&#13;
            <code class="n">low_z</code> <code class="o">=</code> <code class="n">mid_z</code>              <code class="c1"># Midpoint too low, search above it</code>&#13;
        <code class="k">else</code><code class="p">:</code>&#13;
            <code class="n">hi_z</code> <code class="o">=</code> <code class="n">mid_z</code>               <code class="c1"># Midpoint too high, search below it</code>&#13;
&#13;
    <code class="k">return</code> <code class="n">mid_z</code></pre>&#13;
&#13;
<p>The function repeatedly bisects intervals until it narrows in on a <em>Z</em> that’s close enough to the desired probability.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Central Limit Theorem" data-type="sect1"><div class="sect1" id="central_limit_theorem">&#13;
<h1>The Central Limit Theorem</h1>&#13;
&#13;
<p>One<a data-primary="central limit theorem" data-type="indexterm" id="idm45635755466376"/><a data-primary="probability" data-secondary="central limit theorem" data-type="indexterm" id="idm45635755293560"/> reason the normal distribution is so useful is the <em>central limit theorem</em>, which says (in essence) that a random variable defined as the average of a large number of independent and identically distributed random variables is itself approximately normally distributed.</p>&#13;
&#13;
<p>In particular, if &#13;
<math>&#13;
  <mrow>&#13;
    <msub><mi>x</mi> <mn>1</mn> </msub>&#13;
    <mo>,</mo>&#13;
    <mo>...</mo>&#13;
    <mo>,</mo>&#13;
    <msub><mi>x</mi> <mi>n</mi> </msub>&#13;
  </mrow>&#13;
</math> are random variables with mean <em>μ</em> and standard deviation <em>σ</em>, and if <em>n</em> is large, then:</p>&#13;
<div data-type="equation">&#13;
<math display="block">&#13;
  <mrow>&#13;
    <mfrac><mn>1</mn> <mi>n</mi></mfrac>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>x</mi> <mn>1</mn> </msub>&#13;
      <mo>+</mo>&#13;
      <mo>...</mo>&#13;
      <mo>+</mo>&#13;
      <msub><mi>x</mi> <mi>n</mi> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>is approximately normally distributed with mean <em>μ</em> and standard deviation <math alttext="sigma slash StartRoot n EndRoot">&#13;
  <mrow>&#13;
    <mi>σ</mi>&#13;
    <mo>/</mo>&#13;
    <msqrt>&#13;
      <mi>n</mi>&#13;
    </msqrt>&#13;
  </mrow>&#13;
</math>. Equivalently (but often more usefully),</p>&#13;
<div data-type="equation">&#13;
<math alttext="StartFraction left-parenthesis x 1 plus ellipsis plus x Subscript n Baseline right-parenthesis minus mu n Over sigma StartRoot n EndRoot EndFraction" display="block">&#13;
  <mfrac><mrow><mo>(</mo><msub><mi>x</mi> <mn>1</mn> </msub><mo>+</mo><mo>...</mo><mo>+</mo><msub><mi>x</mi> <mi>n</mi> </msub><mo>)</mo><mo>-</mo><mi>μ</mi><mi>n</mi></mrow> <mrow><mi>σ</mi><msqrt><mi>n</mi></msqrt></mrow></mfrac>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>is approximately normally distributed with mean 0 and standard deviation 1.</p>&#13;
&#13;
<p>An<a data-primary="binomial random variables" data-type="indexterm" id="idm45635755419896"/><a data-primary="variables" data-secondary="binomial random variables" data-type="indexterm" id="idm45635755418840"/> easy way to illustrate this is by looking at <em>binomial</em> random variables, which have two parameters <em>n</em> and <em>p</em>.  A Binomial(<em>n</em>,<em>p</em>) random variable is simply the sum of <em>n</em> independent Bernoulli(<em>p</em>) random variables, each of which equals 1 with probability <em>p</em> and 0 with probability 1 – <em>p</em>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">bernoulli_trial</code><code class="p">(</code><code class="n">p</code><code class="p">:</code> <code class="nb">float</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">int</code><code class="p">:</code>&#13;
    <code class="sd">"""Returns 1 with probability p and 0 with probability 1-p"""</code>&#13;
    <code class="k">return</code> <code class="mi">1</code> <code class="k">if</code> <code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">()</code> <code class="o">&lt;</code> <code class="n">p</code> <code class="k">else</code> <code class="mi">0</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">binomial</code><code class="p">(</code><code class="n">n</code><code class="p">:</code> <code class="nb">int</code><code class="p">,</code> <code class="n">p</code><code class="p">:</code> <code class="nb">float</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">int</code><code class="p">:</code>&#13;
    <code class="sd">"""Returns the sum of n bernoulli(p) trials"""</code>&#13;
    <code class="k">return</code> <code class="nb">sum</code><code class="p">(</code><code class="n">bernoulli_trial</code><code class="p">(</code><code class="n">p</code><code class="p">)</code> <code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n</code><code class="p">))</code></pre>&#13;
&#13;
<p>The mean of a Bernoulli(<em>p</em>) variable is <em>p</em>, and its standard deviation is <math alttext="StartRoot p left-parenthesis 1 minus p right-parenthesis EndRoot">&#13;
  <msqrt>&#13;
    <mrow>&#13;
      <mi>p</mi>&#13;
      <mo>(</mo>&#13;
      <mn>1</mn>&#13;
      <mo>-</mo>&#13;
      <mi>p</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </msqrt>&#13;
</math>. The central limit theorem says that as <em>n</em> gets large, a Binomial(<em>n</em>,<em>p</em>) variable is approximately a normal random variable with mean <math alttext="mu equals n p">&#13;
  <mrow>&#13;
    <mi>μ</mi>&#13;
    <mo>=</mo>&#13;
    <mi>n</mi>&#13;
    <mi>p</mi>&#13;
  </mrow>&#13;
</math> and standard deviation <math alttext="sigma equals StartRoot n p left-parenthesis 1 minus p right-parenthesis EndRoot">&#13;
  <mrow>&#13;
    <mi>σ</mi>&#13;
    <mo>=</mo>&#13;
    <msqrt>&#13;
      <mrow>&#13;
        <mi>n</mi>&#13;
        <mi>p</mi>&#13;
        <mo>(</mo>&#13;
        <mn>1</mn>&#13;
        <mo>-</mo>&#13;
        <mi>p</mi>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
    </msqrt>&#13;
  </mrow>&#13;
</math>.  If we plot both, you can easily see the resemblance:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">Counter</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">binomial_histogram</code><code class="p">(</code><code class="n">p</code><code class="p">:</code> <code class="nb">float</code><code class="p">,</code> <code class="n">n</code><code class="p">:</code> <code class="nb">int</code><code class="p">,</code> <code class="n">num_points</code><code class="p">:</code> <code class="nb">int</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="bp">None</code><code class="p">:</code>&#13;
    <code class="sd">"""Picks points from a Binomial(n, p) and plots their histogram"""</code>&#13;
    <code class="n">data</code> <code class="o">=</code> <code class="p">[</code><code class="n">binomial</code><code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="n">p</code><code class="p">)</code> <code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_points</code><code class="p">)]</code>&#13;
&#13;
    <code class="c1"># use a bar chart to show the actual binomial samples</code>&#13;
    <code class="n">histogram</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">data</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">bar</code><code class="p">([</code><code class="n">x</code> <code class="o">-</code> <code class="mf">0.4</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">histogram</code><code class="o">.</code><code class="n">keys</code><code class="p">()],</code>&#13;
            <code class="p">[</code><code class="n">v</code> <code class="o">/</code> <code class="n">num_points</code> <code class="k">for</code> <code class="n">v</code> <code class="ow">in</code> <code class="n">histogram</code><code class="o">.</code><code class="n">values</code><code class="p">()],</code>&#13;
            <code class="mf">0.8</code><code class="p">,</code>&#13;
            <code class="n">color</code><code class="o">=</code><code class="s1">'0.75'</code><code class="p">)</code>&#13;
&#13;
    <code class="n">mu</code> <code class="o">=</code> <code class="n">p</code> <code class="o">*</code> <code class="n">n</code>&#13;
    <code class="n">sigma</code> <code class="o">=</code> <code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">n</code> <code class="o">*</code> <code class="n">p</code> <code class="o">*</code> <code class="p">(</code><code class="mi">1</code> <code class="o">-</code> <code class="n">p</code><code class="p">))</code>&#13;
&#13;
    <code class="c1"># use a line chart to show the normal approximation</code>&#13;
    <code class="n">xs</code> <code class="o">=</code> <code class="nb">range</code><code class="p">(</code><code class="nb">min</code><code class="p">(</code><code class="n">data</code><code class="p">),</code> <code class="nb">max</code><code class="p">(</code><code class="n">data</code><code class="p">)</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code>&#13;
    <code class="n">ys</code> <code class="o">=</code> <code class="p">[</code><code class="n">normal_cdf</code><code class="p">(</code><code class="n">i</code> <code class="o">+</code> <code class="mf">0.5</code><code class="p">,</code> <code class="n">mu</code><code class="p">,</code> <code class="n">sigma</code><code class="p">)</code> <code class="o">-</code> <code class="n">normal_cdf</code><code class="p">(</code><code class="n">i</code> <code class="o">-</code> <code class="mf">0.5</code><code class="p">,</code> <code class="n">mu</code><code class="p">,</code> <code class="n">sigma</code><code class="p">)</code>&#13;
          <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">]</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">xs</code><code class="p">,</code><code class="n">ys</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s2">"Binomial Distribution vs. Normal Approximation"</code><code class="p">)</code>&#13;
    <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>&#13;
&#13;
<p>For example, when you call <code>make_hist(0.75, 100, 10000)</code>, you get the graph in <a data-type="xref" href="#make_hist_result">Figure 6-4</a>.</p>&#13;
&#13;
<figure><div class="figure" id="make_hist_result">&#13;
<img alt="The result of calling binomial_histogram." src="assets/dsf2_0604.png"/>&#13;
<h6><span class="label">Figure 6-4. </span>The output from binomial_histogram</h6>&#13;
</div></figure>&#13;
&#13;
<p>The moral of this approximation is that if you want to know the probability that (say) a fair coin turns up more than 60 heads in 100 flips, you can estimate it as the probability that a Normal(50,5) is greater than 60, which is easier than computing the Binomial(100,0.5) CDF. (Although in most applications you’d probably be using statistical software that would gladly compute whatever probabilities you want.)</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="For Further Exploration" data-type="sect1"><div class="sect1" id="idm45635755467704">&#13;
<h1>For Further Exploration</h1>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><a href="https://docs.scipy.org/doc/scipy/reference/stats.html">scipy.stats</a> contains PDF<a data-primary="scipy.stats" data-type="indexterm" id="idm45635754946984"/><a data-primary="probability" data-secondary="tools for" data-type="indexterm" id="idm45635754946248"/> and CDF functions for most of the popular probability distributions.</p>&#13;
</li>&#13;
<li>&#13;
<p>Remember<a data-primary="probability" data-secondary="resources for learning" data-type="indexterm" id="idm45635754944344"/> how, at the end of <a data-type="xref" href="ch05.html#statistics">Chapter 5</a>, I said that it would be a good idea&#13;
to study a statistics textbook?  It would&#13;
also be a good idea to study a probability textbook.  The best one I know that’s available online is <a href="http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/book.html"><em>Introduction to Probability</em></a>, by Charles M. Grinstead and J. Laurie Snell (American Mathematical Society).<a data-primary="" data-startref="Mprob06" data-type="indexterm" id="idm45635754941176"/></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>