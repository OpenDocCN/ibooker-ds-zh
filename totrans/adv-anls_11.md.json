["```py\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(tidymodels)\n\n# Read in the data, select only the columns we need\nmpg <- read_csv('datasets/mpg/mpg.csv') %>%\n  select(mpg, weight, horsepower, origin, cylinders)\n\n#> -- Column specification -----------------------------------------------------\n#> cols(\n#>  mpg = col_double(),\n#>  cylinders = col_double(),\n#>  displacement = col_double(),\n#>  horsepower = col_double(),\n#>  weight = col_double(),\n#>  acceleration = col_double(),\n#>  model.year = col_double(),\n#>  origin = col_character(),\n#>  car.name = col_character()\n#> )\n\nhead(mpg)\n#> # A tibble: 6 x 5\n#>     mpg weight horsepower origin cylinders\n#>   <dbl>  <dbl>      <dbl> <chr>      <dbl>\n#> 1    18   3504        130 USA            8\n#> 2    15   3693        165 USA            8\n#> 3    18   3436        150 USA            8\n#> 4    16   3433        150 USA            8\n#> 5    17   3449        140 USA            8\n#> 6    15   4341        198 USA            8\n```", "```py\ndescribe(mpg)\n#>            vars   n    mean     sd  median trimmed    mad  min\n#> mpg           1 392   23.45   7.81   22.75   22.99   8.60    9\n#> weight        2 392 2977.58 849.40 2803.50 2916.94 948.12 1613\n#> horsepower    3 392  104.47  38.49   93.50   99.82  28.91   46\n#> origin*       4 392    2.42   0.81    3.00    2.53   0.00    1\n#> cylinders     5 392    5.47   1.71    4.00    5.35   0.00    3\n#>               max  range  skew kurtosis    se\n#> mpg          46.6   37.6  0.45    -0.54  0.39\n#> weight     5140.0 3527.0  0.52    -0.83 42.90\n#> horsepower  230.0  184.0  1.08     0.65  1.94\n#> origin*       3.0    2.0 -0.91    -0.86  0.04\n#> cylinders     8.0    5.0  0.50    -1.40  0.09\n```", "```py\nmpg %>%\n  count(origin)\n#> # A tibble: 3 x 2\n#>   origin     n\n#>   <chr>  <int>\n#> 1 Asia      79\n#> 2 Europe    68\n#> 3 USA      245\n```", "```py\nmpg %>%\n  count(origin, cylinders) %>%\n  pivot_wider(values_from = n, names_from = cylinders)\n#> # A tibble: 3 x 6\n#>   origin   `3`   `4`   `6`   `5`   `8`\n#>   <chr>  <int> <int> <int> <int> <int>\n#> 1 Asia       4    69     6    NA    NA\n#> 2 Europe    NA    61     4     3    NA\n#> 3 USA       NA    69    73    NA   103\n```", "```py\nmpg %>%\n  select(mpg, origin) %>%\n  describeBy(group = 'origin')\n\n#>  Descriptive statistics by group\n#> origin: Asia\n        vars  n  mean   sd median trimmed  mad min  max range\n#> mpg        1 79 30.45 6.09   31.6   30.47 6.52  18 46.6  28.6\n#> origin*    2 79  1.00 0.00    1.0    1.00 0.00   1  1.0   0.0\n        skew kurtosis   se\n#> mpg     0.01    -0.39 0.69\n#> origin*  NaN      NaN 0.00\n\n#> origin: Europe\n        vars  n mean   sd median trimmed  mad  min  max range\n#> mpg        1 68 27.6 6.58     26    27.1 5.78 16.2 44.3  28.1\n#> origin*    2 68  1.0 0.00      1     1.0 0.00  1.0  1.0   0.0\n        skew kurtosis  se\n#> mpg     0.73     0.31 0.8\n#> origin*  NaN      NaN 0.0\n\n#> origin: USA\n        vars   n  mean   sd median trimmed  mad min max range\n#> mpg        1 245 20.03 6.44   18.5   19.37 6.67   9  39    30\n#> origin*    2 245  1.00 0.00    1.0    1.00 0.00   1   1     0\n        skew kurtosis   se\n#> mpg     0.83     0.03 0.41\n#> origin*  NaN      NaN 0.00\n```", "```py\nggplot(data = mpg, aes(x = mpg)) +\n  geom_histogram()\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```", "```py\nggplot(data = mpg, aes(x = origin, y = mpg)) +\n  geom_boxplot()\n```", "```py\n# Histogram of mpg, facted by origin\nggplot(data = mpg, aes(x = mpg)) +\n  geom_histogram() +\n  facet_grid(~ origin)\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```", "```py\nmpg_filtered <- filter(mpg, origin=='USA' | origin=='Europe')\n```", "```py\n# Dependent variable ~ (\"by\") independent variable\nt.test(mpg ~ origin, data = mpg_filtered)\n#> \tWelch Two Sample t-test\n#>\n#>     data:  mpg by origin\n#>     t = 8.4311, df = 105.32, p-value = 1.93e-13\n#>     alternative hypothesis: true difference in means is not equal to 0\n#>     95 percent confidence interval:\n#>     5.789361 9.349583\n#>     sample estimates:\n#>     mean in group Europe    mean in group USA\n#>                 27.60294             20.03347\n```", "```py\nselect(mpg, mpg:horsepower) %>%\n  cor()\n#>                   mpg     weight horsepower\n#> mpg         1.0000000 -0.8322442 -0.7784268\n#> weight     -0.8322442  1.0000000  0.8645377\n#> horsepower -0.7784268  0.8645377  1.0000000\n```", "```py\nggplot(data = mpg, aes(x = weight,y = mpg)) +\n  geom_point() + xlab('weight (pounds)') +\n  ylab('mileage (mpg)') + ggtitle('Relationship between weight and mileage')\n```", "```py\nselect(mpg, mpg:horsepower) %>%\n  pairs()\n```", "```py\nmpg_regression <- lm(mpg ~ weight, data = mpg)\nsummary(mpg_regression)\n\n#>     Call:\n#>     lm(formula = mpg ~ weight, data = mpg)\n#>\n#>     Residuals:\n#>         Min       1Q   Median       3Q      Max\n#>     -11.9736  -2.7556  -0.3358   2.1379  16.5194\n#>\n#>     Coefficients:\n#>                 Estimate Std. Error t value Pr(>|t|)\n#>     (Intercept) 46.216524   0.798673   57.87   <2e-16 ***\n#>     weight      -0.007647   0.000258  -29.64   <2e-16 ***\n#>     ---\n#>     Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n#>\n#>     Residual standard error: 4.333 on 390 degrees of freedom\n#>     Multiple R-squared:  0.6926,\tAdjusted R-squared:  0.6918\n#>     F-statistic: 878.8 on 1 and 390 DF,  p-value: < 2.2e-16\n```", "```py\nggplot(data = mpg, aes(x = weight, y = mpg)) +\n  geom_point() + xlab('weight (pounds)') +\n  ylab('mileage (mpg)') + ggtitle('Relationship between weight and mileage') +\n  geom_smooth(method = lm)\n#> `geom_smooth()` using formula 'y ~ x'\n```", "```py\nset.seed(1234)\n```", "```py\nmpg_split <- initial_split(mpg)\nmpg_train <- training(mpg_split)\nmpg_test <- testing(mpg_split)\n```", "```py\ndim(mpg_train)\n#> [1] 294   5\ndim(mpg_test)\n#> [1] 98  5\n```", "```py\n# Specify what kind of model this is\nlm_spec <- linear_reg()\n\n# Fit the model to the data\nlm_fit <- lm_spec %>%\n  fit(mpg ~ weight, data = mpg_train)\n#> Warning message:\n#> Engine set to `lm`.\n```", "```py\ntidy(lm_fit)\n#> # A tibble: 2 x 5\n#>   term        estimate std.error statistic   p.value\n#>   <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n#> 1 (Intercept) 47.3      0.894         52.9 1.37e-151\n#> 2 weight      -0.00795  0.000290     -27.5 6.84e- 83\n#>\nglance(lm_fit)\n#> # A tibble: 1 x 12\n#>   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC\n#>       <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl>\n#> 1     0.721         0.720  4.23      754\\. 6.84e-83     1  -840\\. 1687.\n#> # ... with 4 more variables: BIC <dbl>, deviance <dbl>,\n#> #   df.residual <int>, nobs <int>\n```", "```py\nmpg_results <- predict(lm_fit, new_data = mpg_test) %>%\n  bind_cols(mpg_test)\n\nmpg_results\n#> # A tibble: 98 x 6\n#>    .pred   mpg weight horsepower origin cylinders\n#>    <dbl> <dbl>  <dbl>      <dbl> <chr>      <dbl>\n#>  1  20.0    16   3433        150 USA            8\n#>  2  16.7    15   3850        190 USA            8\n#>  3  25.2    18   2774         97 USA            6\n#>  4  30.3    27   2130         88 Asia           4\n#>  5  28.0    24   2430         90 Europe         4\n#>  6  21.0    19   3302         88 USA            6\n#>  7  14.2    14   4154        153 USA            8\n#>  8  14.7    14   4096        150 USA            8\n#>  9  29.6    23   2220         86 USA            4\n#> 10  29.2    24   2278         95 Asia           4\n#> # ... with 88 more rows\n```", "```py\nrsq(data = mpg_results, truth = mpg, estimate = .pred)\n#> # A tibble: 1 x 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rsq     standard       0.606\n```", "```py\nrmse(data = mpg_results, truth = mpg, estimate = .pred)\n#> # A tibble: 1 x 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        4.65\n```"]