- en: 9 An AI-powered trivia game
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 一个 AI 驱动的益智游戏
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Connecting your app to a Large Language Model (LLM)
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将您的应用程序连接到大型语言模型 (LLM)
- en: Engineering LLM prompts to achieve your desired results
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工程化 LLM 提示以实现您期望的结果
- en: Using Structured Outputs to obtain LLM responses in a custom parsable format
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用结构化输出以自定义可解析格式获取 LLM 响应
- en: Managing state in a sequential Streamlit app
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在顺序 Streamlit 应用中管理状态
- en: Using st.data_editor to create editable tables
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 st.data_editor 创建可编辑的表格
- en: Creating software is significantly different from what it used to be just a
    few short years ago. The difference stems from major developments in the field
    of AI (Artificial Intelligence), which—unless you've been living under a rock—you've
    probably heard orf.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 创建软件与几年前相比有显著不同。这种差异源于人工智能（Artificial Intelligence）领域的重大发展，除非你一直住在山洞里，否则你可能已经听说过。
- en: I'm talking, of course, about breakthroughs in LLMs or Large Language Models,
    and the tremendously exciting possibilities they open up. By processing and generating
    natural language, LLMs can understand context, answer complex questions, and even
    write software on their own—all with astonishing fluency. Tasks that once required
    domain-specific expertise or painstaking programming can now be achieved with
    just a few well-crafted "prompts".
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我当然是在谈论 LLM 或大型语言模型的突破，以及它们带来的令人兴奋的可能性。通过处理和生成自然语言，LLM 可以理解上下文，回答复杂问题，甚至可以自己编写软件——所有这些都能以惊人的流畅度完成。曾经需要特定领域专业知识或费尽心思编程的任务，现在只需几个精心设计的“提示”就能完成。
- en: In this chapter, we'll dive into how you can harness the power of LLMs in your
    own applications, relying on AI prompts and responses to implement product features
    that would have required highly advanced techniques half a decade ago. Along the
    way, we'll also discuss how to tune your LLM interactions to get the results you
    want, and how to do so without burning a hole in your pocket.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入了解如何在您的应用程序中利用 LLM 的力量，依靠 AI 提示和响应来实现五年前需要高度先进技术的产品功能。在这个过程中，我们还将讨论如何调整您的
    LLM 交互以获得您想要的结果，以及如何在不烧穿您的口袋的情况下做到这一点。
- en: Note
  id: totrans-10
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: The GitHub repo for this book is [https://github.com/aneevdavis/streamlit-in-action](https://github.com/aneevdavis/streamlit-in-action).
    The chapter_09 folder has this chapter's code and a requirements.txt file with
    exact versions of all the required Python libraries.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本书 GitHub 仓库为 [https://github.com/aneevdavis/streamlit-in-action](https://github.com/aneevdavis/streamlit-in-action)。chapter_09
    文件夹包含本章的代码和一个 requirements.txt 文件，其中包含所有必需 Python 库的确切版本。
- en: '9.1 Fact Frenzy: An AI trivia game'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 事实狂热：一个 AI 益智游戏
- en: If you watched the game show *Jeopardy!* as a kid—or as an adult for that matter—you're
    going to love this chapter. Having grown up outside the US, I was in my thirties
    before I watched my first episode of the show, but I suffered no dearth of trivia
    shows to obsess over when I was a boy—*Mastermind*, *Bournvita Quiz Contest*,
    and *Kaun Banega Crorepati?* (an Indian take on the original British show *Who
    Wants to Be a Millionaire?*) were all staples of my youth.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你小时候看过游戏节目 *Jeopardy!* ——或者无论如何作为一个成年人——你一定会喜欢这一章。由于我在美国以外长大，我在三十多岁时才看了这个节目的第一集，但在我小时候，我并不缺少痴迷的益智游戏——*Mastermind*、*Bournvita
    Quiz Contest* 和 *Kaun Banega Crorepati?*（这是对原始英国节目 *Who Wants to Be a Millionaire?*
    的印度版本）都是我青春期的常客。
- en: Fifteen-year-old me would never forgive adult me if I didn't include at least
    one trivia app in this book. Fortunately, trivia is a great fit for our first
    AI-powered Streamlit app, which will generate questions, evaluate answers, and
    even mix it up with a variety of quizmaster styles, all using artificial intelligence.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 十五岁的我如果在这本书中不包括至少一个益智应用，成年后的我绝不会原谅自己。幸运的是，益智游戏非常适合我们的第一个 AI 驱动的 Streamlit 应用，该应用将生成问题、评估答案，甚至以各种问答主持风格进行混合，所有这些都将使用人工智能完成。
- en: 9.1.1 Stating the concept and requirements
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 陈述概念和需求
- en: Once again, the first step we'll take is to state the concept of the app we
    want to build.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要采取的第一步是陈述我们想要构建的应用程序的概念。
- en: Concept
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 概念
- en: Fact Frenzy, a trivia game that asks users a set of trivia questions and evaluates
    their answers using AI
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 事实狂热，一款询问用户一系列知识问答并使用 AI 评估其答案的益智游戏
- en: As we've done several times before by this point in the book, the requirements
    will flesh out this simple idea further.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 就像本书中我们多次做的那样，需求将进一步阐述这个简单想法。
- en: Requirements
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 需求
- en: 'Fact Frenzy will:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 事实狂热将：
- en: use an AI model to generate trivia questions
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AI 模型生成知识问答
- en: ask these questions to a player
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向玩家提出这些问题
- en: allow the user to enter a free-text response to each question
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许用户对每个问题输入自由文本响应
- en: use AI to evaluate whether the answer is correct, and to provide the correct
    answer
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用AI评估答案是否正确，并提供正确答案
- en: keep track of a player's score
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪玩家的分数
- en: allow the player to set a difficulty level for questions
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许玩家为问题设置难度级别
- en: offer a variety of quizmaster speaking styles
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供多种问答主持人说话风格
- en: While we *generally* want our requirements to be free of "implementation" language
    (as discussed in Chapter 3), in this case the entire point of our app is to demonstrate
    the use of AI—so we definitely need it to use AI models to perform its functions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然*我们通常*希望我们的需求不包含“实现”语言（如第3章所述），但在这个案例中，我们应用程序的整个目的就是展示AI的使用——因此我们肯定需要使用AI模型来执行其功能。
- en: We've also added a fun element in the form of quizmaster speaking styles—or
    in other words, mimicking the style of various people while asking questions,
    something we'd only be able to achieve using AI.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还增加了一个有趣元素，即问答主持人的说话风格——换句话说，在提问时模仿各种人的风格，这是我们只能通过AI才能实现的事情。
- en: What's out of scope
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 范围之外的内容
- en: 'What are we leaving out? While a professional trivia game could be arbitrarily
    complex, in building Fact Frenzy, we want to create a minimal app to get hands-on
    practice with topics we haven''t encountered before. So we won''t focus on any
    of the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们省略了什么？虽然一个专业的知识竞赛游戏可以非常复杂，但在构建“事实狂热”时，我们希望创建一个最小化的应用程序，以便亲身体验我们之前未曾接触过的主题。因此，我们不会关注以下任何一项：
- en: persistent storage and retrieval of questions, answers, and scores
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久存储和检索问题、答案和分数
- en: creating and managing users
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和管理用户
- en: letting users choose particular categories of questions
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许用户选择特定的问题类别
- en: Placing the above items out of scope will let us concentrate on things like
    interacting with large language models or LLMs, state management, and of course,
    new Streamlit elements.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 将上述项目排除在范围之外将使我们能够专注于诸如与大型语言模型（LLMs）交互、状态管理以及当然，新的Streamlit元素等问题。
- en: 9.1.2 Visualizing the user experience
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 可视化用户体验
- en: To give ourselves a concrete idea of what Fact Frenzy is about, take a look
    at a sketch of our proposed UI, displayed in figure 9.1.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们对“事实狂热”有一个具体的了解，请查看我们提出的UI草图，如图9.1所示。
- en: '![image](../Images/09__image001.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image001.png)'
- en: Figure 9.1 A UI sketch of Fact Frenzy
  id: totrans-40
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.1 “事实狂热”的UI草图
- en: 'The game window shown in the sketch has a two-column layout. The left column
    has a "New game" button, as well as a couple of settings: Quizmaster and Difficulty.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图表中显示的游戏窗口具有两列布局。左侧列有一个“新游戏”按钮，以及一些设置：问答主持人和难度。
- en: Referring to the last requirement identified in the previous section, the Quizmaster
    setting is supposed to use AI to mimic speaking styles of various characters.
    In figure 9.1, the selected value is "Gollum", a character from *The Lord of the
    Rings* who speaks in a distinctive, hissing manner using phrases like "my precious."
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 参考上一节中确定的最后一个需求，问答主持人设置应该使用AI来模仿各种角色的说话风格。如图9.1所示，选定的值是“Gollum”，《指环王》中的一个角色，他使用独特的嘶嘶声说话，使用诸如“我的宝贝”之类的短语。
- en: The column on the right shows an AI-generated question "spoken" in Gollum's
    voice along with the player's score and a box to enter the answer.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 右侧的列显示了用Gollum的声音“说出”的AI生成问题，以及玩家的分数和一个输入答案的框。
- en: Gimmicks aside, it's a pretty standard question-and-answer trivia game that
    lets the player enter free-form text to answer.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 除了花招之外，这是一个相当标准的问答知识竞赛游戏，允许玩家输入自由文本来回答。
- en: 9.1.3 Brainstorming the implementation
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.3 实施头脑风暴
- en: While we'll "outsource" large parts of our logic to an LLM, we'll still need
    to own the overall game flow. Figure 9.2 shows the design we'll work to implement
    in the rest of the chapter.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们将“外包”我们逻辑的大部分部分给LLM，但我们仍然需要拥有整体的游戏流程。图9.2显示了我们在本章其余部分将努力实现的设计。
- en: Unlike some of the other apps we've written where users could take a variety
    of actions at any point, Fact Frenzy is quite linear. As the diagram shows, the
    basic logic runs in a loop—using an LLM to retrieve a trivia question, posing
    it to the player, getting the LLM to evaluate the answer, stating whether the
    provided answer was right or not, and doing it all over again for the next question,
    until the game is done.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们编写的一些其他应用程序不同，用户可以在任何时刻执行各种操作，而“事实狂热”则相当线性。如图所示，基本逻辑在一个循环中运行——使用大型语言模型（LLM）检索一个知识问题，将其提出给玩家，让LLM评估答案，声明提供的答案是否正确，然后对下一个问题重复整个过程，直到游戏结束。
- en: '![image](../Images/09__image002.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/09__image002.png)'
- en: Figure 9.2 The flow of logic in our AI-based trivia game
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.2 基于AI的知识问答游戏的逻辑流程
- en: Later on, we'll add a few bells and whistles such as allowing the player to
    set the difficulty level and quizmaster, but figure 9.2 is a pretty good representation
    of the core flow.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在以后，我们将添加一些功能，如允许玩家设置难度级别和问答大师，但图9.2很好地代表了核心流程。
- en: 9.2 Using AI to generate trivia questions
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 使用AI生成知识问答问题
- en: At the heart of Fact Frenzy is an AI model that powers the trivia experience.
    This model generates questions, evaluates player responses, and even adds personality
    to the quizmaster. To achieve all this, we use a Large Language Model (LLM)—a
    powerful AI system designed to process and generate human-like text.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在“知识狂潮”的核心是一个AI模型，它为知识问答体验提供动力。该模型生成问题、评估玩家回答，甚至为问答大师增添个性。为了实现所有这些，我们使用大型语言模型（LLM）——这是一种强大的AI系统，旨在处理和生成类似人类的文本。
- en: LLMs are trained on vast amounts of textual data, making them incredibly versatile.
    They can perform a wide range of tasks from answering factual questions to generating
    poetry, coding, or—importantly for our purposes—role-playing as a quizmaster.
    Popular examples of LLMs include OpenAI's GPT series, Anthropic's Claude, and
    Google's Gemini—all of which leverage cutting-edge machine learning techniques
    to generate coherent, contextually appropriate text.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: LLM是在大量文本数据上训练的，这使得它们具有极大的灵活性。它们可以执行从回答事实问题到创作诗歌、编写代码，以及对我们来说更重要的是——扮演问答大师等多种任务。流行的LLM例子包括OpenAI的GPT系列、Anthropic的Claude和Google的Gemini——所有这些都利用了尖端的机器学习技术来生成连贯、上下文适当的文本。
- en: 9.2.1 Why use an LLM in Fact Frenzy?
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 为什么在“知识狂潮”中使用LLM？
- en: 'What makes LLMs suitable for use in our trivia game? To answer this, let''s
    take a minute to consider some possible components of such a game and how an LLM
    can support building each one:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 什么使LLM适合用于我们的知识问答游戏？为了回答这个问题，让我们花一分钟时间考虑这种游戏的一些可能组成部分以及LLM如何支持构建每一个部分：
- en: A giant list of questions
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一个巨大的问题列表
- en: Without an LLM, we would need to maintain a set of trivia questions large and
    diverse enough to keep our app engaging. Since the major LLMs of today are all
    trained on text and data pertaining to history, culture, geography, astronomy,
    and every other category of trivia you can think of, they're instead able to generate
    questions on the fly.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 没有LLM，我们需要维护一套足够大且多样化的知识问答题库，以保持我们的应用具有吸引力。由于今天的主要LLM都是基于历史、文化、地理、天文学以及你能想到的任何其他知识问答类别的大量文本和数据进行训练，因此它们能够即时生成问题。
- en: The ability to evaluate answers
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估答案的能力
- en: If we were going the traditional non-LLM route, we would realistically only
    be able to ask multiple-choice questions, as we'd need to match the answer a player
    gives to the actual one accurately. LLMs, on the other hand, can interpret and
    respond to free-text user inputs. This allows us to ask open-ended trivia questions
    and still evaluate player responses correctly.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们走传统的非LLM路线，我们实际上只能提出多项选择题，因为我们需要准确地将玩家给出的答案与实际答案匹配。另一方面，LLM可以解释和响应自由文本用户输入。这使得我们能够提出开放式知识问答问题，同时仍然正确评估玩家的回答。
- en: Entertainment value
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 娱乐价值
- en: In addition to being able to handle factual information, LLMs can also be creative,
    and provide humor for engagement. Later in the chapter, we'll ask one to mimic
    the style of various characters as quizmasters, giving the game a personality,
    so to speak.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 除了能够处理事实信息外，LLM还可以发挥创意，提供幽默来吸引参与。在章节的后面，我们将要求它们模仿各种角色的风格，作为问答大师，从而给游戏赋予个性。
- en: Thus, in Fact Frenzy, the LLM will play the triple role of question generator,
    answer evaluator, and comic relief provider. In the next section, we'll set up
    an account with a top-tier LLM provider—OpenAI—enabling us to start interacting
    with LLMs for the first time.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在“知识狂潮”中，LLM将扮演问题生成者、答案评估者和喜剧提供者的三重角色。在下一节中，我们将与顶级LLM提供商OpenAI建立账户，使我们能够首次开始与LLM互动。
- en: Note
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 备注
- en: While LLMs are undeniably powerful, they are not omniscient. They rely on patterns
    in their training data to generate responses and may occasionally make mistakes,
    especially when evaluating highly nuanced or ambiguous answers. However, for our
    trivia app, these models strike a perfect balance between intelligence, versatility,
    and entertainment.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然LLM（大型语言模型）无疑非常强大，但它们并非全知全能。它们依赖于训练数据中的模式来生成回答，并且有时可能会犯错，尤其是在评估高度细微或模糊的回答时。然而，对于我们的Trivia（知识问答）应用来说，这些模型在智能、多样性和娱乐性之间达到了完美的平衡。
- en: 9.2.2 Setting up an OpenAI API key
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 设置OpenAI API密钥
- en: For this chapter, we'll use an LLM provided by OpenAI, perhaps the best-known
    among the set of new-ish AI firms that have been dominating tech news lately.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，我们将使用OpenAI提供的LLM，可能是最近在科技新闻中占据主导地位的新兴AI公司中最知名的一个。
- en: As we've done many times in this book so far, we'll need to open an account
    with an external service, and wire our Python code to it.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本书中多次做的那样，我们需要在第三方服务中开设账户，并将我们的Python代码与之连接。
- en: If you don't already have an OpenAI account (your ChatGPT account counts), go
    to [https://platform.openai.com/](https://platform.openai.com/) and sign up for
    one.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有OpenAI账户（你的ChatGPT账户也算），请访问[https://platform.openai.com/](https://platform.openai.com/)并注册一个账户。
- en: Note
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: If you created your OpenAI account recently or just now, you *may* have some
    free credits applied to your account. However, the free tier currently comes with
    relatively severe usage limits, such as only being able to call some models three
    times per minute. While you could *technically* get away with using the free tier
    for this chapter (assuming your account has the free credits in the first place),
    if you plan to do any amount of serious AI development, I recommend upgrading
    to a paid tier. As you'll see, you can get a lot of LLM usage for fairly low prices.
    Though you'll likely need to *buy* $5 in usage credits to get to the lowest paid
    tier, you won't need to *spend* much of that in this chapter. For reference, I
    spent less than 15 cents in credits for all the testing I did while developing
    this lesson. You can learn more about cost optimization in the sidebar named "Cost
    considerations".
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你最近创建了OpenAI账户或者现在才创建，你的账户可能已经应用了一些免费信用额度。然而，免费层目前有相对严格的限制，例如每分钟只能调用某些模型三次。虽然技术上你可以使用免费层来完成本章（假设你的账户最初就有免费信用额度），如果你计划进行任何数量的严肃AI开发，我建议升级到付费层。正如你将看到的，你可以以相当低的价格获得大量的LLM使用量。虽然你可能需要购买5美元的使用信用额度才能达到最低付费层，但你在这章中不需要花费太多。为了参考，我在开发这个课程时进行的所有测试中，花费的信用额度不到15美分。你可以在名为“成本考虑”的侧边栏中了解更多关于成本优化的信息。
- en: Once you're in, go to the Settings page—at the time of writing, you can do this
    by clicking the gear icon at the top right corner of the page—and then click on
    "API keys" in the panel to the left.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 登录后，转到设置页面——在撰写本文时，你可以通过点击页面右上角的齿轮图标来完成此操作——然后点击左侧面板中的“API密钥”。
- en: Create a new secret key and note it down. You can leave all the defaults unchanged
    (see figure 9.3).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的密钥并将其记录下来。你可以保留所有默认设置不变（见图9.3）。
- en: '![image](../Images/09__image003.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image003.png)'
- en: Figure 9.3 Creating a secret key in your OpenAI account
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.3 在你的OpenAI账户中创建密钥
- en: You'll only be able to see your key once, so copy-and-paste it somewhere. This
    goes without saying, but keep it safe!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 你只能看到一次你的密钥，所以将其复制并粘贴到某个地方。不用说，但请确保安全！
- en: 9.2.3 Calling the OpenAI API in Python
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 在Python中调用OpenAI API
- en: Before we start any development on the app, let's make sure we can call the
    OpenAI API in Python without any issues.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始开发应用程序之前，让我们确保可以在Python中无任何问题地调用OpenAI API。
- en: To begin, install the OpenAI's Python library with `pip install openai`. You
    could technically call the API via HTTP calls using the `requests` module (as
    we did in Chapter 5), but this library is more convenient to use.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用`pip install openai`安装OpenAI的Python库。技术上，你可以使用`requests`模块通过HTTP调用调用API（正如我们在第5章中所做的那样），但这个库更方便使用。
- en: 'Once that''s done, open a Python shell and import the `OpenAI` class:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，打开Python shell并导入`OpenAI`类：
- en: '[PRE0]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `OpenAI` class lets you instantiate a client using an API key to make calls
    to the OpenAI API:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`OpenAI`类允许你使用API密钥实例化一个客户端，以便调用OpenAI API：'
- en: '[PRE1]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Replace `sk-proj-...` with the actual API key you copied in the previous step.
    With a `client` object created, let''s prepare an instruction to send the LLM:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 将`sk-proj-...`替换为上一步中复制的实际API密钥。创建了一个`client`对象后，让我们准备发送给LLM的指令：
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Each request you send to the LLM is called a *prompt*. A prompt—or at least
    the type we''ll use here—consists of *messages*. In the code above, we''re assembling
    these into a list. Each message takes the form of a dictionary with two keys:
    `role` and `content`.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你发送给LLM的每个请求都称为*prompt*。prompt——至少是我们在这里将使用的类型——由*消息*组成。在上面的代码中，我们将这些消息组装成一个列表。每个消息都采用字典的形式，包含两个键：`role`和`content`。
- en: '`role` can be one of `user`, `system`, and `assistant`. We''ll explore more
    examples later, but the value of `role` signifies the perspective of the speaker
    in the conversation:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`role` 可以是 `user`、`system` 或 `assistant` 之一。我们将在稍后探索更多示例，但 `role` 的值表示对话中说话者的视角：'
- en: '`system` represents instructions or context-setting for the model, such as
    rules for how it should behave.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`system` 代表对模型的指令或上下文设置，例如它应该如何行为的规则。'
- en: '`user` represents the person interacting with the model (you).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user` 代表与模型交互的人（您）。'
- en: '`assistant` represents the model''s responses—we''ll discuss this in the next
    chapter.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`assistant` 代表模型的响应——我们将在下一章讨论这一点。'
- en: 'The prompt we''re creating here tells the LLM (in the system message) that
    it should behave like a helpful programming assistant. The actual instruction
    we want the LLM to respond to is in the user message: `Explain what Streamlit
    is in 10 words or fewer`.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里创建的提示告诉 LLM（在系统消息中）它应该表现得像一个有帮助的编程助手。我们希望 LLM 响应的实际指令在用户消息中：`用10个词或更少解释
    Streamlit`。
- en: 'We can now make an actual request to the API:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以向 API 发出实际请求：
- en: '[PRE3]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The OpenAI API has several different endpoints—one for turning audio to text,
    one for creating images, and so on. The one we'll be using is the *chat completions*
    endpoint, and it's used for text generation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API 有几个不同的端点——一个用于将音频转换为文本，一个用于创建图像，等等。我们将使用的是 *chat completions* 端点，它用于文本生成。
- en: Given a list of messages in a conversation, this endpoint is supposed to return
    what comes next—hence the term *completion*. OpenAI has a plethora of models we
    could use, but here we've picked `gpt-4o-mini`, which provides a good balance
    between intelligence, speed, and cost.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个对话中的消息列表，此端点应返回接下来会发生什么——因此有 *completion* 这个术语。OpenAI 有许多我们可以使用的模型，但我们在这里选择了
    `gpt-4o-mini`，它在智能、速度和成本之间提供了良好的平衡。
- en: Note
  id: totrans-95
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: While gpt-4o-mini is currently the most suitable model OpenAI offers for our
    use case, given the speed of developments in the AI space, by the time this book
    goes to print, we may have newer models that are smarter *and* cheaper. Keep an
    eye on OpenAI's pricing page at [https://openai.com/api/pricing/](https://openai.com/api/pricing/)
    to ensure you're using the model that fits best.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 gpt-4o-mini 目前是 OpenAI 为我们用例提供的最合适的模型，鉴于人工智能领域的快速发展，到这本书印刷的时候，我们可能会有更智能且更便宜的更新模型。请密切关注
    OpenAI 的定价页面 [https://openai.com/api/pricing/](https://openai.com/api/pricing/)，以确保您使用的是最适合的模型。
- en: 'The above statement should take a few seconds to execute, and will return a
    `ChatCompletion` object. If you like, you can inspect this object by typing just
    `completion` into the shell, but you can access the actual text response we want
    like so:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 上述语句需要几秒钟才能执行，并将返回一个 `ChatCompletion` 对象。如果您愿意，可以通过在壳中仅输入 `completion` 来检查此对象，但您可以通过以下方式访问我们想要的实际文本响应：
- en: '[PRE4]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: I couldn't have said it better myself! That concludes our first programmatic
    interaction with an LLM. Next, let's build this into our trivia game's code.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我无法用更好的方式来表达！这标志着我们与 LLM 的第一次程序性交互。接下来，让我们将其构建到我们的问答游戏代码中。
- en: 9.2.4 Writing an LLM class
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.4 编写 LLM 类
- en: In Chapter 8, we created a `Database` class that encapsulated the interaction
    that our app could have with an external database. We'll follow the same model
    in this chapter with an `Llm` class that handles all communication with the external
    LLM. This allows us to separate the logistics of talking to the LLM from the rest
    of our app, making it easier to maintain, test, or even swap it out entirely,
    without touching the remaining code.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 8 章中，我们创建了一个 `Database` 类，它封装了我们的应用程序可以与外部数据库交互的交互。在这一章中，我们将采用相同的模式，使用一个
    `Llm` 类来处理与外部 LLM 的所有通信。这使我们能够将 LLM 的通信逻辑与我们的应用程序的其他部分分开，使其更容易维护、测试，甚至完全替换，而无需触及剩余的代码。
- en: We've covered the basics of calling the LLM in the prior section, so all that's
    left is to put the logic in a class.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前一节中已经介绍了调用 LLM 的基础知识，所以剩下的只是将逻辑放入一个类中。
- en: Create a new file, `llm.py` with the content shown in listing 9.1.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新文件，`llm.py`，内容如列表 9.1 所示。
- en: Listing 9.1 llm.py
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.1 llm.py
- en: '[PRE5]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: (`chapter_09/in_progress_01/llm.py` in the GitHub repo)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub 仓库中的 `chapter_09/in_progress_01/llm.py`）
- en: The `Llm` class' `__init__` simply creates a new OpenAI client object using
    an API key that's passed to it, assigning this to `self.client`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`Llm` 类的 `__init__` 方法只是使用传递给它的 API 密钥创建一个新的 OpenAI 客户端对象，并将其分配给 `self.client`。'
- en: The `ask` method is what logic outside the `Llm` class will interact with, and
    returns the LLM's response to our prompt. Its code is essentially the same as
    what we ran in the Python shell earlier, except that we take in `user_msg` and
    `sys_msg` as arguments and put the creation of the `messages` list in its own
    method, called `construct_messages`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`ask` 方法是类外部的逻辑与之交互的部分，它返回 LLM 对我们提示的响应。其代码基本上与我们之前在 Python 命令行中运行的是相同的，除了我们现在将
    `user_msg` 和 `sys_msg` 作为参数传入，并将创建 `messages` 列表的操作放在一个名为 `construct_messages`
    的独立方法中。'
- en: Since we don't *have* to pass a system role message—the LLM will try to be helpful
    anyway—we give `sys_msg` a default value of None. `construct_messages` takes this
    fact into account while generating the `messages` list. Since this is a utility
    function that doesn't depend on anything else in the object, we make it a static
    method by decorating it with `@staticmethod`.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们**不必**传递系统角色消息——LLM 无论如何都会尽力帮助——我们给 `sys_msg` 设置了一个默认值 None。`construct_messages`
    方法在生成 `messages` 列表时考虑到这一点。由于这是一个不依赖于对象中其他任何内容的实用函数，我们通过使用 `@staticmethod` 装饰器将其设为静态方法。
- en: We'll refine the `Llm` class further along in the chapter, but for now, let's
    move on to writing the code that calls it.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章的后面进一步细化 `Llm` 类，但现在是时候继续编写调用它的代码了。
- en: 9.2.5 The Game class
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.5 `Game` 类
- en: As in Chapter 8, we'll have a single class—appropriately named `Game`—that contains
    all the backend logic that our app's frontend will call directly. This is somewhat
    analogous to the `Hub` class from Chapter 8, though we'll structure `Game` differently.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 与第 8 章一样，我们将有一个单独的类——命名为 `Game` 的类——它包含所有应用程序前端将直接调用的后端逻辑。这与第 8 章中的 `Hub` 类有些类似，尽管我们将
    `Game` 的结构设计得不同。
- en: For the moment we'll keep it quite simple, as all it needs to do is to pass
    a prompt to our `Llm` class. The initial version of the `Game` class that we'll
    place in `game.py` is shown in listing 9.2.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们将保持代码相当简单，因为它的主要功能只是将一个提示传递给我们的 `Llm` 类。我们将放置在 `game.py` 中的 `Game` 类的初始版本在列表
    9.2 中展示。
- en: Listing 9.2 game.py
  id: totrans-114
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.2 game.py
- en: '[PRE6]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: (`chapter_09/in_progress_01/game.py` in the GitHub repo)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: (`chapter_09/in_progress_01/game.py` 在 GitHub 仓库中)
- en: The initialization of a `Game` instance (through `__init__`) involves creating
    an `Llm` object by passing it the API key that we'll presumably get from the calling
    code.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`Game` 实例的初始化（通过 `__init__`）涉及通过传递 API 密钥创建一个 `Llm` 对象，我们预计将从调用代码中获取这个 API
    密钥。'
- en: The `ask_llm_for_question` method passes a simple prompt asking the LLM to generate
    a trivia question. Notice that the system message now tells the LLM to behave
    like a quizmaster.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '`ask_llm_for_question` 方法传递一个简单的提示，要求 LLM 生成一个知识问答问题。注意，系统消息现在告诉 LLM 要表现得像一位问答大师。'
- en: The user message instructs the LLM to ask a question, warning it to not provide
    any choices or reveal the answer.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 用户消息指示 LLM 提出一个问题，并警告它不要提供任何选项或泄露答案。
- en: 9.2.6 Calling the Game class in our app
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.6 在我们的应用程序中调用 `Game` 类
- en: We can now write a minimal version of our frontend code to test out everything
    we've done. As usual, our API key needs to be kept secret and safe, so we'll put
    it in a `secrets.toml` file in a new `.streamlit` directory, as seen in listing
    9.3.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以编写一个前端代码的最小版本来测试我们所做的一切。像往常一样，我们的 API 密钥需要保密并安全存放，所以我们将它放在一个新创建的 `.streamlit`
    目录下的 `secrets.toml` 文件中，如列表 9.3 所示。
- en: Listing 9.3 .streamlit/secrets.toml
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.3 .streamlit/secrets.toml
- en: '[PRE7]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#A Replace sk-proj-... with your actual API key.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '#A 将 sk-proj-... 替换为你的实际 API 密钥。'
- en: We've kept `secrets.toml` quite simple this time around with a non-nested structure—notice
    the absence of a section like `[config]`. The O in TOML does stand for "obvious"
    after all.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这次将 `secrets.toml` 保持得相当简单，采用非嵌套结构——注意 `[config]` 类似的部分缺失。毕竟，TOML 中的 O 也代表“明显”。
- en: Go ahead and create `main.py` (shown in listing 9.4) now.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在就创建 `main.py`（如列表 9.4 所示）吧。
- en: Listing 9.4 main.py
  id: totrans-127
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.4 main.py
- en: '[PRE8]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: (`chapter_09/in_progress_01/main.py` in the GitHub repo)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: (`chapter_09/in_progress_01/main.py` 在 GitHub 仓库中)
- en: There's nothing fancy here yet; we simply create a `Game` instance called `game`,
    call its `ask_llm_for_question` method to generate a trivia question, and write
    it to the screen.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 目前这里还没有什么特别之处；我们只是创建了一个名为 `game` 的 `Game` 实例，调用它的 `ask_llm_for_question` 方法来生成一个知识问答问题，并将其写入屏幕。
- en: 'Notice how we''ve combined `st.container` with a border and `st.write` into
    a single statement:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们如何将 `st.container` 与边框和 `st.write` 结合成一个单独的语句：
- en: '[PRE9]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Concise and pretty, much like Streamlit itself. Run your app using `streamlit
    run main.py` (as in prior chapters, make sure you first `cd` into the directory
    that contains `main.py` so Streamlit can find the `.streamlit` directory) to see
    something like figure 9.4.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 简洁而美观，就像Streamlit本身一样。使用`streamlit run main.py`运行你的应用程序（如前几章所述，请确保首先`cd`到包含`main.py`的目录，以便Streamlit可以找到`.streamlit`目录）以查看类似图9.4的内容。
- en: '![image](../Images/09__image004.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image004.png)'
- en: Figure 9.4 The app can now successfully call the OpenAI API to obtain a trivia
    question (see chapter_09/in_progress_01 in the GitHub repo for the full code)
  id: totrans-135
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.4 应用程序现在可以成功调用OpenAI API以获取一个知识问题（有关完整代码，请参阅GitHub仓库中的chapter_09/in_progress_01）
- en: Excellent—Our AI quizmaster can now ask the player a question! Next we'll have
    it evaluate the player's answer.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了——我们的AI测验大师现在可以向玩家提问了！接下来我们将评估玩家的答案。
- en: 9.3 Using AI to evaluate answers
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 使用AI评估答案
- en: The prompt we fed GPT-4o mini is a simple one. Vitally, we didn't have to do
    anything particularly complicated with the output—just display it on the screen
    as-is. As such, we didn't really care about the *format* in which the LLM responded.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供给GPT-4o mini的提示非常简单。至关重要的是，我们不需要对输出进行任何特别复杂的处理——只需将其原样显示在屏幕上即可。因此，我们并不真正关心LLM响应的*格式*。
- en: 'However, evaluating answers presents a slightly different challenge. When a
    player enters an answer into the app, we need the LLM to tell us two things:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，评估答案提出了一个稍微不同的挑战。当玩家在应用程序中输入答案时，我们需要LLM告诉我们两件事：
- en: Whether the answer is correct
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 答案是否正确
- en: If not, what the correct answer actually is
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果不是，那么正确答案实际上是什么
- en: 'If you''ve interacted with AI assistants before, this sounds well within their
    capabilities. But let''s examine a practical challenge: how do you reliably parse
    the LLM''s response?'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你之前与AI助手互动过，这听起来完全在其能力范围内。但让我们考察一个实际挑战：如何可靠地解析LLM的响应？
- en: 'For instance, let''s say we tell the LLM "Hey, you asked this question: <question>,
    and the player said the answer was <answer>. Tell me if that''s right, or if not,
    what the correct answer is".'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们告诉LLM：“嘿，你问了这个问题：<question>，玩家说答案是<answer>。告诉我这是否正确，如果不是，告诉我正确答案是什么”。
- en: 'The LLM does its thing and responds with:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: LLM执行其操作并响应：
- en: '"Incorrect, the answer is actually <correct answer>".'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: “不正确，正确答案是<correct answer>”。
- en: What do we do with this reply? Sure, we could display it on the screen, but
    we probably also need to perform additional actions, like deciding whether or
    not to increment the player's score. Which means that we need to *parse* the response
    to understand whether the answer was right.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们该如何处理这个回复？当然，我们可以在屏幕上显示它，但我们可能还需要执行其他操作，比如决定是否增加玩家的分数。这意味着我们需要*解析*回复来理解答案是否正确。
- en: How do we do that? A naive approach would be to look for the word "incorrect"
    in the response and mark the answer as being correct or not accordingly.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们该如何做？一个简单的方法是查找响应中的“incorrect”一词，并根据情况标记答案是否正确。
- en: But what if the LLM's answer is actually "Nope, that's not right, the answer
    is <correct answer>" or even "Hah! It *would* have been correct if they'd said
    <correct answer>. But they didn't, so tough luck."
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果LLM的回答实际上是“不，那不对，正确答案是<correct answer>”或者甚至“哈哈！如果他们说的是<correct answer>，那就会是正确的。但他们没有，所以很遗憾。”
- en: The point is that there are tons of creative ways the LLM could answer, and
    while we would be able to understand them as humans, we need a simple way to determine
    their meaning in a machine-friendly way.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，LLM有无数种创造性的回答方式，虽然我们作为人类能够理解它们，但我们仍然需要一个简单的方法来确定它们在机器友好的方式下的含义。
- en: We could request the LLM in our prompt to include the words "correct" or "incorrect"
    somewhere, but it might still occasionally mess it up. Luckily, there's a better
    approach.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在提示中要求LLM包含“正确”或“不正确”等词语，但仍然可能会偶尔出错。幸运的是，有一个更好的方法。
- en: 9.3.1 Structured Outputs
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 结构化输出
- en: Being able to parse LLM outputs reliably is a natural concern for developers,
    so OpenAI has a solution for this called *Structured Outputs*.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 能够可靠地解析LLM的输出是开发者的一个自然关注点，因此OpenAI为此提供了一个名为*结构化输出*的解决方案。
- en: Structured Outputs is a feature that ensures that the model will generate a
    response that adheres to a schema that *you* provide, making it simple to parse
    programmatically.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化输出是一个确保模型将生成一个遵循你提供的模式的响应的功能，这使得程序化解析变得简单。
- en: 'For our use case, this means we can request the LLM to provide two structured
    fields in its response: a boolean field that says whether the provided answer
    is correct, and the actual correct answer.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的用例，这意味着我们可以请求 LLM 在其响应中提供两个结构化字段：一个表示提供的答案是否正确的布尔字段，以及实际的正确答案。
- en: Let's create this schema as a class named `AnswerEvaluation` (listing 9.5).
    We'll need the third-party `pydantic` module to get this working, so install that
    first with `pip install pydantic`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建这个模式作为一个名为 `AnswerEvaluation` 的类（列表 9.5）。我们需要第三方 `pydantic` 模块来使这工作，所以首先使用
    `pip install pydantic` 安装它。
- en: Listing 9.5 answer_evaluation.py
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.5 answer_evaluation.py
- en: '[PRE10]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: (`chapter_09/in_progress_02/answer_evaluation.py` in the GitHub repo)
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub 仓库中的 `chapter_09/in_progress_02/answer_evaluation.py`）
- en: '`pydantic` is a data validation library that uses type hints to ensure that
    data conforms to a specified type.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`pydantic` 是一个使用类型提示来确保数据符合指定类型的验证库。'
- en: '`BaseModel`, which we import from `pydantic`, is a class that allows you to
    define a schema and perform data validation. It works well with OpenAI''s Structured
    Outputs.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 `pydantic` 导入的 `BaseModel` 是一个允许你定义模式并执行数据验证的类。它与 OpenAI 的结构化输出配合得很好。
- en: The class we're defining, `AnswerEvaluation`, is a *subclass* of `BaseModel`.
    *Subclasses* and *superclasses* are related to the concept of *inheritance* in
    object-oriented programming. Explaining inheritance in detail is beyond the scope
    of this book, but just know that a subclass can *inherit* functionality and attributes
    from its superclass, allowing you to reuse code and build on existing functionality
    without starting from scratch.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义的类 `AnswerEvaluation` 是 `BaseModel` 的一个 *子类*。*子类* 和 *超类* 与面向对象编程中的 *继承*
    概念相关。详细解释继承超出了本书的范围，但只需知道子类可以 *继承* 其超类中的功能属性，允许你重用代码并在现有功能的基础上构建，而不需要从头开始。
- en: In this case, `AnswerEvaluation` (subclass) inherits the features of `BaseModel`
    (superclass), such as data validation, serialization, and type checking, making
    it easy to define and work with structured data.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`AnswerEvaluation`（子类）继承了 `BaseModel`（超类）的功能，如数据验证、序列化和类型检查，这使得定义和操作结构化数据变得容易。
- en: The body of `AnswerEvaluation` is identical to what you might expect if it were
    a dataclass instead. Indeed, dataclasses are similar to `pydantic`'s `BaseModel`
    except that dataclasses do not provide the complex validations and related functionality
    that `BaseModel` does.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`AnswerEvaluation` 的主体与如果你将其视为数据类时可能期望的相同。确实，数据类与 `pydantic` 的 `BaseModel`
    类似，但数据类不提供 `BaseModel` 所提供的复杂验证和相关功能。'
- en: 'Fortunately, we don''t really need to worry about the internals of how this
    works—just note that `AnswerEvaluation` has the two fields we spoke of: a boolean
    `is_correct` and a string, `correct_answer`.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们实际上并不需要担心这个工作原理的内部细节——只需注意 `AnswerEvaluation` 有我们之前提到的两个字段：一个布尔字段 `is_correct`
    和一个字符串 `correct_answer`。
- en: 'Next, let''s modify our `ask` function in the `Llm` class (`llm.py`) to support
    Structured Outputs:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们修改 `Llm` 类中的 `ask` 函数（`llm.py`）以支持结构化输出：
- en: '[PRE11]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: (`chapter_09/in_progress_02/llm.py` in the GitHub repo)
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub 仓库中的 `chapter_09/in_progress_02/llm.py`）
- en: Here we've added an argument called `schema` that's `None` by default. If a
    value is provided (`if schema`), we call a different method in our OpenAI client
    (`beta.chat.completions.parse` as opposed to `chat.completions.create` from earlier).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们添加了一个默认值为 `None` 的名为 `schema` 的参数。如果提供了值（`if schema`），我们将调用我们 OpenAI 客户端中的不同方法（与之前的
    `chat.completions.create` 相比，现在是 `beta.chat.completions.parse`）。
- en: 'The first two parameters we pass to this new method are the same as before,
    but we''ve added a third one: `response_format`, to which we provide the value
    of `schema`.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传递给这个新方法的第一个和第二个参数与之前相同，但我们增加了一个第三个参数：`response_format`，我们将 `schema` 的值传递给它。
- en: 'The final value we return is also different: `completion.choices[0].message.parsed`
    rather than `completion.choices[0].message.content`.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们返回的最终值也有所不同：`completion.choices[0].message.parsed` 而不是 `completion.choices[0].message.content`。
- en: If `schema` is not provided, we simply default to the earlier behavior, thereby
    ensuring that the `ask` method can handle both Structured Outputs and regular
    text.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有提供 `schema`，我们将默认回退到之前的行为，从而确保 `ask` 方法可以处理结构化输出和常规文本。
- en: The value we need to pass to `schema` is a *class—*not an instance of the class,
    but the class *itself*. The value *returned* will then be an *instance* of that
    class, and will therefore follow the schema. As you may already have guessed,
    for our use case, we'll pass the `AnswerEvaluation` class to `schema`.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要传递给 `schema` 的值是一个 *类*——不是类的 *实例*，而是类 *本身*。然后返回的值将是一个该类的 *实例*，因此将遵循架构。正如你可能已经猜到的，对于我们的用例，我们将传递
    `AnswerEvaluation` 类给 `schema`。
- en: We'll create this calling code in a bit, but first let's create a new LLM prompt
    asking the model to evaluate a player's answer.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在稍后创建这个调用代码，但首先让我们创建一个新的 LLM 提示，要求模型评估玩家的答案。
- en: During development, you should expect to have to tweak your prompt many times
    to get better results—in fact, there's a whole field called *prompt engineering*
    that has sprung up in recent years.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发过程中，你应该预计需要多次调整你的提示以获得更好的结果——事实上，近年来出现了一个名为 *提示工程* 的整个领域。
- en: Since our prompts are meaningfully different from our code, let's put them in
    a different file where we can edit them without touching the rest of the code.
    We'll name this `prompts.py` and give it the contents in listing 9.6.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的提示与代码有实质性不同，所以让我们将它们放在不同的文件中，这样我们就可以在不触及其余代码的情况下编辑它们。我们将命名为 `prompts.py`
    并在列表 9.6 中给出其内容。
- en: Listing 9.6 prompts.py
  id: totrans-176
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.6 prompts.py
- en: '[PRE12]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: (`chapter_09/in_progress_02/prompts.py` in the GitHub repo)
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub 仓库中的 `chapter_09/in_progress_02/prompts.py`）
- en: Each prompt is structured as a dictionary with keys `system` and `user`, corresponding
    to the system and user messages.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 每个提示都结构化为一个字典，其中 `system` 和 `user` 键对应于系统和用户消息。
- en: '`QUESTION_PROMPT` is our prompt from earlier, while `ANSWER_PROMPT` is new.
    Notice that its user message (a Python *multi-line string* bounded by `''''''`s
    if you''re wondering about the syntax) contains these lines:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`QUESTION_PROMPT` 是我们之前的提示，而 `ANSWER_PROMPT` 是新的。请注意，其用户消息（如果你想知道语法，它是一个由 `''''''`
    包围的 Python *多行字符串*）包含以下这些行：'
- en: '[PRE13]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We're treating `{question}` and `{answer}` here as variables that we can replace
    with real values when we send the prompt to the LLM later.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里将 `{question}` 和 `{answer}` 视为变量，当我们稍后向 LLM 发送提示时，可以用真实值替换它们。
- en: Also note the last two lines in this message where we're telling the LLM to
    evaluate the answer for correctness and *also* to provide the correct answer.
    The model is smart enough to interpret this instruction and provide the results
    in our `AnswerEvaluation` schema.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意这条消息的最后两行，我们在这里告诉 LLM 评估答案的正确性，并且 *还要* 提供正确答案。这个模型足够智能，可以解释这个指令，并以我们的 `AnswerEvaluation`
    架构提供结果。
- en: 'Speaking of which, let''s actually write the code that passes this schema along
    with the prompt to fulfill our answer evaluation use case. We''ll do this by modifying
    `game.py`:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 说到这个，让我们实际编写代码，将这个架构连同提示一起传递，以满足我们的答案评估用例。我们将通过修改 `game.py` 来做这件事：
- en: '[PRE14]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: (`chapter_09/in_progress_02/game.py` in the GitHub repo)
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub 仓库中的 `chapter_09/in_progress_02/game.py`）
- en: We've refactored the `ask_llms_for_question` method to use our new `prompts.py`
    module.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经重构了 `ask_llms_for_question` 方法，以使用我们新的 `prompts.py` 模块。
- en: But the main change here is the new function, `ask_llm_to_evaluate_answer`,
    which takes in the originally asked `question`, and the `answer` provided by the
    user, plugging these values into the `{question}` and `{answer}` slots in the
    user message we discussed a minute ago.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里的主要变化是新的函数，`ask_llm_to_evaluate_answer`，它接受最初提出的 `question` 和用户提供的 `answer`，将这些值插入我们之前讨论的用户消息中的
    `{question}` 和 `{answer}` 插槽。
- en: This time, we pass in `AnswerEvaluation` (imported from `answer_evaluation.py`)
    as a third argument to `self.llm`'s ask method—`schema`, as I hope you recall.
    One interesting aspect to this is that we're passing in `AnswerEvaluation` *itself*
    here—not an *instance* of `AnswerEvaluation`, but the class. In Python, most of
    the constructs in your code are *objects* that you can pass around like this,
    including classes—something that enables powerful and flexible programing patterns.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们将 `AnswerEvaluation`（从 `answer_evaluation.py` 导入）作为第三个参数传递给 `self.llm`
    的 ask 方法——`schema`，如你希望回忆的那样。这个有趣的一个方面是我们在这里传递的是 `AnswerEvaluation` *本身*，而不是 `AnswerEvaluation`
    的 *实例*，而是类。在 Python 中，你代码中的大多数结构都是 *对象*，你可以像这样传递它们，包括类——这是使强大的灵活编程模式成为可能的东西。
- en: 'But I digress. Let''s get back to enabling our game to accept and evaluate
    answers from a player. The last step is to make the requisite changes to the frontend
    in `main.py`:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 但我跑题了。让我们回到使我们的游戏能够接受和评估玩家答案的步骤。最后一步是对 `main.py` 中的前端进行必要的更改：
- en: '[PRE15]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: (`chapter_09/in_progress_02/main.py` in the GitHub repo)
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub 仓库中的 `chapter_09/in_progress_02/game.py`）
- en: You should be able to understand what we're doing here pretty easily. Once we've
    posed the trivia question to the player, we display a text input for their answer,
    as well as a "Submit" button that when clicked, triggers the `ask_llm_to_evaluate_answer`
    method in `game.py`.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够很容易地理解我们在这里所做的事情。一旦我们向玩家提出了这个趣味问题，我们就会显示一个文本输入框供他们输入答案，以及一个“提交”按钮，当点击这个按钮时，会触发`game.py`中的`ask_llm_to_evaluate_answer`方法。
- en: The resulting value—stored in `evaluation`—is an instance of the `AnswerEvaluation`
    class. We use its `is_correct` attribute to display the appropriate correct/incorrect
    message, and `evaluation.correct_answer` for the real answer.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 结果值——存储在`evaluation`中——是`AnswerEvaluation`类的一个实例。我们使用它的`is_correct`属性来显示适当的正确/错误信息，以及`evaluation.correct_answer`来显示正确答案。
- en: Try re-running your app now and supplying an answer to the trivia question.
    Figure 9.5 shows what I got.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试重新运行你的应用程序，并为趣味问题提供一个答案。图9.5显示了我是如何做到的。
- en: '![image](../Images/09__image005.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image005.png)'
- en: Figure 9.5 An issue with session state causes our answer to be matched with
    the wrong question (see chapter_09/in_progress_02 in the GitHub repo for the full
    code)
  id: totrans-197
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.5 由于会话状态的问题，我们的答案与错误的问题匹配（有关完整代码，请参阅GitHub仓库中的chapter_09/in_progress_02）
- en: Oops! There are shenanigans afoot! The question I answered "Ottawa" to in the
    left part of figure 9.5 was "What is the capital of Canada?". But when I press
    the "Submit" button, the app displays a different question—"What is the largest
    planet in our solar system?"—and then has the nerve to tell me that "Ottawa" is,
    in fact, *not* the right answer to that.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀！这里有些鬼鬼祟祟的事情！我在图9.5的左侧部分回答“Ottawa”的问题时，答案是“加拿大的首都是什么？”。但是当我按下“提交”按钮时，应用程序显示了一个不同的问题——“我们太阳系中最大的行星是什么？”——然后竟然厚颜无耻地告诉我，“Ottawa”实际上**不是**那个问题的正确答案。
- en: You'll notice a similar bait-and-switch in your testing. What's going on? Are
    our AI overlords toying with us?
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 你会在测试中注意到类似的诱饵和替换。发生了什么事？我们的AI统治者是在玩弄我们吗？
- en: As it turns out, the LLM is entirely innocent of this alleged mischief. The
    issue—as we've seen several times before in this book—is related to session state
    and Streamlit app re-runs. In this particular instance, a click on the "Submit"
    button triggers a re-run from the *top*, meaning that before the code under `if
    st.button("Submit"):` can run, `game.ask_llm_for_question()` is called once again,
    resulting in a *new* question, which is what is passed as the first argument to
    `ask_llm_to_evaluate_answer`, along with "Ottawa" as the second argument pulled
    from the text input.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，LLM对这种所谓的恶作剧完全无辜。问题——正如我们在本书中多次看到的那样——与会话状态和Streamlit应用程序的重运行有关。在这个特定的情况下，点击“提交”按钮会从“顶部”触发重运行，这意味着在`if
    st.button("Submit"):`下的代码运行之前，`game.ask_llm_for_question()`会被再次调用，从而产生一个新的问题，这个新问题作为`ask_llm_to_evaluate_answer`的第一个参数传递，同时从文本输入中提取“Ottawa”作为第二个参数。
- en: Well, at the very least, the Structured Outputs part of our code seems to be
    working, since Jupiter is indeed the largest planet in the solar system, and Ottawa
    is incorrect.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，至少，我们代码中的结构化输出部分似乎是在正常工作，因为木星确实是太阳系中最大的行星，而Ottawa是不正确的。
- en: However, to get Fact Frenzy to exhibit the behavior we expect, we'll need to
    think through state management quite thoroughly in the next section.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了使Fact Frenzy表现出我们预期的行为，我们将在下一节中仔细思考状态管理。
- en: 9.4 Moving through game states
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 游戏状态之间的移动
- en: In chapters prior, Streamlit's rerun-the-whole-app-each-time model meant that
    we had to make extensive use of `st.session_state` to get the app to remember
    values. That holds true here as well.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，Streamlit的重运行整个应用程序的模型意味着我们必须广泛使用`st.session_state`来让应用程序记住值。这一点在这里同样适用。
- en: Fact Frenzy, however, is *sequential* in a way that our previous apps weren't.
    You can think of the desired behavior of our game as moving between various *states*,
    taking a different set of actions and displaying different widgets in each. Figure
    9.6 illustrates this.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Fact Frenzy在某种意义上是**顺序的**，而我们的先前的应用程序并不是。你可以把我们的游戏期望的行为看作是在各种**状态**之间移动，在每个状态中采取不同的动作并显示不同的小部件。图9.6说明了这一点。
- en: '![image](../Images/09__image006.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image006.png)'
- en: Figure 9.6 Our game consists of four sequential states
  id: totrans-207
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.6 我们的游戏由四个连续的状态组成
- en: 'The diagram identifies four states that the game can be in:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 该图确定了游戏可能处于的四个状态：
- en: GET_QUESTION, in which we retrieve a question from the LLM
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GET_QUESTION，其中我们从LLM检索一个问题
- en: ASK_QUESTION, where we pose said question to the player
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ASK_QUESTION，其中我们向玩家提出这个问题
- en: EVALUATE_ANSWER, which involves calling the LLM to evaluate the answer
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EVALUATE_ANSWER`，涉及调用 LLM 来评估答案'
- en: STATE_RESULT, where we tell the player whether they were right or not
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`STATE_RESULT`，在这里我们告诉玩家他们是否正确'
- en: Each of these actions should only happen while the game is in the state that
    it corresponds to. Additionally, we need to ensure that each LLM request we're
    making only happens once per question—because the alternative messes up our logic
    *and* costs money.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这些操作应该在游戏处于对应状态时才发生。此外，我们还需要确保我们对每个 LLM 请求只进行一次——因为否则会搞乱我们的逻辑，并且会花费金钱。
- en: A pattern that we'll find useful in sequential apps such as this one and others
    you may write in the future is to formally retain a state/status attribute in
    the app's central class (`Game` in our case) coupled with methods to modify it,
    and to use conditional logic based on this attribute in the frontend to display
    the right elements on the screen. Figure 9.7 should make what I'm talking about
    clearer.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在此类顺序应用程序（如本例以及你未来可能编写的其他应用程序）中，我们将发现一个有用的模式是，在应用程序的中心类（在我们的例子中是 `Game`）中正式保留一个状态/状态属性，并配合修改它的方法，并在前端使用基于此属性的逻辑条件来显示屏幕上的正确元素。图
    9.7 应该会使我所说的更清晰。
- en: '![image](../Images/09__image007.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image007.png)'
- en: Figure 9.7 Conditional branching in the frontend based on the game's state
  id: totrans-216
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.7 前端基于游戏状态的分支
- en: As you can see from our proposed logic in figure 9.7, the `Game` class will
    have a `status` attribute that indicates the state the game is in. We'll read
    this state in the frontend to branch between the various display elements—whether
    it's a text input for the answer in the `ASK_QUESTION` state, or simply a wait-during-the-LLM-request
    status element during the `GET_QUESTION` and `EVALUATE_ANSWER` states.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在图 9.7 中看到我们提出的逻辑，`Game` 类将有一个 `status` 属性，表示游戏所处的状态。我们将在前端读取这个状态，在各个显示元素之间进行分支——无论是
    `ASK_QUESTION` 状态中的答案文本输入，还是 `GET_QUESTION` 和 `EVALUATE_ANSWER` 状态期间的等待 LLM 请求的状态元素。
- en: The `Game` class also has methods that change its `status` attribute, controlling
    all of this. `obtain_question` would presumably get the question from the LLM,
    but also change the status to `ASK_QUESTION` when it's done. `accept_answer` would
    take in the answer from the player and also switch the status to `EVALUATE_ANSWER`,
    and the `evaluate_answer` method, in addition to getting the LLM to give us the
    result, would shift the status to `STATE_RESULT`.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`Game` 类也有改变其 `status` 属性的方法，控制所有这些。`obtain_question` 方法可能会从 LLM 获取问题，并在完成后将状态更改为
    `ASK_QUESTION`。`accept_answer` 方法将接受玩家的答案，并将状态切换到 `EVALUATE_ANSWER`，而 `evaluate_answer`
    方法除了让 LLM 给我们结果外，还会将状态切换到 `STATE_RESULT`。'
- en: 'Let''s put all this in action now, starting with the `Game` class:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把这些都付诸实践，从 `Game` 类开始：
- en: Listing 9.7 game.py (modified)
  id: totrans-220
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.7 game.py（已修改）
- en: '[PRE16]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: (`chapter_09/in_progress_03/game.py` in the GitHub repo)
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub 仓库中的 `chapter_09/in_progress_03/game.py`）
- en: As discussed, the first big change here is the inclusion of a `self.status`
    attribute that formally indicates the state of the game. We initialize this to
    `GET_QUESTION` as that's the first sequential state we want.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前讨论的那样，这里第一个大的变化是引入了 `self.status` 属性，它正式表示游戏的状态。我们将其初始化为 `GET_QUESTION`，因为这是我们想要的第一种顺序状态。
- en: You'll notice we also have three other attributes—`curr_question`, `curr_answer`,
    and `curr_eval`—to hold the current question, answer, and evaluation within the
    `Game` instance. This is a departure from the earlier version of `game.py` where
    we were handling `question` and `answer` as variables outside the class. Keeping
    track of these within the class is better-suited to our new *stateful* approach.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到我们还有三个其他属性——`curr_question`、`curr_answer` 和 `curr_eval`——用于在 `Game` 实例中保存当前问题、答案和评估。这与
    `game.py` 的早期版本不同，那时我们将 `question` 和 `answer` 作为类外部的变量来处理。在类内部跟踪这些内容更适合我们新的 *状态化*
    方法。
- en: You'll see this reflected in the `ask_llm_to_evaluate_answer` method, where
    we've dispensed with the `question` and `answer` parameters in favor of the `self.curr_question`
    and `self.curr_answer` attributes.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 你会在 `ask_llm_to_evaluate_answer` 方法中看到这一点，在那里我们放弃了 `question` 和 `answer` 参数，转而使用
    `self.curr_question` 和 `self.curr_answer` 属性。
- en: Additionally, we've introduced three new methods (also discussed earlier)—`obtain_question`,
    `accept_answer`, and `evaluate_answer`. `obtain_question` and `evaluate_answer`
    are wrappers around `ask_llm_for_question` and `ask_llm_to_evaluate_answer` respectively,
    each merely assigning the result to its associated attribute—`self.curr_question`
    or `self.curr_answer`—before adding a line to move `self.status` to its next value.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们引入了三种新的方法（之前也讨论过）——`obtain_question`、`accept_answer`和`evaluate_answer`。`obtain_question`和`evaluate_answer`分别是`ask_llm_for_question`和`ask_llm_to_evaluate_answer`的包装器，每个只是将结果分配给其关联的属性——`self.curr_question`或`self.curr_answer`——然后在代码中添加一行以将`self.status`移动到其下一个值。
- en: '`accept_answer` is even simpler; it just sets `self.answer` to an answer presumably
    provided by the player.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`accept_answer`甚至更简单；它只是将`self.answer`设置为玩家可能提供的答案。'
- en: 'The second half of the set of changes we need to implement the state management
    approach we''ve envisioned lies in `main.py`:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要实现的用于实现我们设想的状态管理方法的更改集的第二部分在于`main.py`：
- en: '[PRE17]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: (`chapter_09/in_progress_03/main.py` in the GitHub repo)
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_03/main.py`）
- en: 'We start by placing our `Game` instance in `st.session_state`, ensuring that
    we''ll be dealing with the same instance across re-runs:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将我们的`Game`实例放置在`st.session_state`中，确保我们在重试时将处理相同的实例：
- en: '[PRE18]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The last line here is for convenience, enabling us to refer to our `Game` instance
    simply as `game`, instead of spelling out `st.session_state.game` each time.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的最后一行是为了方便，使我们能够简单地用`game`来引用我们的`Game`实例，而不是每次都写出`st.session_state.game`。
- en: 'The remaining code builds out conditional branching based on `game`''s `status`
    attribute. Let''s briefly consider each such condition:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的代码基于`game`的`status`属性构建条件分支。让我们简要考虑每个这样的条件：
- en: '[PRE19]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The first branch deals with the `GET_QUESTION` state. The app handles this state
    without any interaction from the user, as it merely obtains the question from
    the LLM. This can take a perceptible amount of time, however, so we display what's
    known as a *status element*.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个分支处理`GET_QUESTION`状态。应用无需用户交互即可处理此状态，因为它只是从LLM获取问题。然而，这可能需要一定的时间，因此我们显示所谓的*状态元素*。
- en: A status element is simply a widget that gives some indication of what's going
    on to the user while a long-running operation happens in the background. Streamlit
    has several different status elements—`st.spinner`, `st.status`, `st.toast`, `st.progress`—each
    of which has slightly different characteristics.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 状态元素只是一个小部件，它在后台进行长时间运行的操作时向用户提供一些指示。Streamlit有几种不同的状态元素——`st.spinner`、`st.status`、`st.toast`、`st.progress`——每个都有略微不同的特性。
- en: '`st.spinner`, which we''ve used here, simply displays a spinning circle animation
    (the same one we saw in Chapter 6 when we applied the `show_spinner` parameter
    to `@st.cache_data`) until the background operation has been completed.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的`st.spinner`简单地显示一个旋转的圆形动画（我们在第6章中看到过，当时我们将`show_spinner`参数应用于`@st.cache_data`），直到后台操作完成。
- en: Notice the `st.rerun()` after we've called `game.obtain_question()`. This exists
    because once `obtain_question` (from `game.py`) has changed the status to `ASK_QUESTION`,
    we need the code to run again, so as to enter the *next* conditional branch given
    by `elif game.status == 'ASK_QUESTION':`.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们在调用`game.obtain_question()`之后调用的`st.rerun()`。这是因为一旦`obtain_question`（来自`game.py`）将状态更改为`ASK_QUESTION`，我们需要代码再次运行，以便进入由`elif
    game.status == 'ASK_QUESTION':`给出的*下一个*条件分支。
- en: The remaining branches are quite similar. In each case, there is some kind of
    trigger causing the app to move to the next state, followed by a rerun. In the
    `ASK_QUESTION` state, a click on "Submit" calls `game.accept_answer(answer)`,
    which sets `game`'s `curr_answer` attribute and changes the state to `EVALUATE_ANSWER`.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的分支相当相似。在每种情况下，都存在某种触发器导致应用移动到下一个状态，随后进行重试。在`ASK_QUESTION`状态中，点击“提交”会调用`game.accept_answer(answer)`，这将设置`game`的`curr_answer`属性并将状态更改为`EVALUATE_ANSWER`。
- en: In `EVALUATE_ANSWER`, we call `game.evaluate_answer()` and display another `st.spinner`
    while we wait for it to return, eventually changing the status to `STATE_RESULT`.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在`EVALUATE_ANSWER`中，我们调用`game.evaluate_answer()`并在等待它返回时显示另一个`st.spinner`，最终将状态更改为`STATE_RESULT`。
- en: After the rerun, we simply display the appropriate messages based on `game.curr_eval`,
    our `AnswerEvaluation` object.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 重试后，我们只需根据`game.curr_eval`，我们的`AnswerEvaluation`对象，显示适当的消息。
- en: Check out the results now by rerunning the app (figure 9.8)
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在通过重试应用查看结果（图9.8）
- en: '![image](../Images/09__image008.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image008.png)'
- en: Figure 9.8 The question-answer mismatch issue has been resolved (see chapter_09/in_progress_03
    in the GitHub repo for the full code)
  id: totrans-245
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.8 问题-答案不匹配的问题已解决（完整代码请见GitHub仓库中的chapter_09/in_progress_03）
- en: This time you'll see that the app matches the question and answer correctly,
    fixing the issue we saw earlier.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这次你会看到应用程序正确匹配问题和答案，解决了我们之前看到的问题。
- en: '9.5 Game mechanics: Keeping score, a New Game button, and Game Over'
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.5 游戏机制：计分、新游戏按钮和游戏结束
- en: 'Fact Frenzy currently does the bare minimum we need it to do: it asks a player
    a question, and evaluates the answer, all using AI. It isn''t much of a *game*
    though; there''s no score, and no concept of when the game starts and ends. Let''s
    tackle each of these problems in turn.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Fact Frenzy只做了我们需要的最基本的事情：向玩家提问，评估答案，全部使用AI。但这并不是一个真正的*游戏*；没有得分，也没有游戏开始和结束的概念。让我们逐一解决这些问题。
- en: Keeping score
  id: totrans-249
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计分
- en: We want Fact Frenzy to be easy to pick up, so we'll keep our scoring mechanism
    basic; each correct answer fetches one point.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望Fact Frenzy易于上手，所以我们将保持我们的计分机制简单；每个正确答案加一分。
- en: 'This should be fairly trivial to incorporate into the `Game` class:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该相当简单就可以集成到`Game`类中：
- en: '[PRE20]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: (`chapter_09/in_progress_04/game.py` in the GitHub repo)
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_04/game.py`）
- en: We simply add a new `score` attribute to the `Game` instance in `__init__`,
    setting it to 0 to start with.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需在`__init__`中将`Game`实例的`score`属性添加为新的属性，并将其设置为0以开始。
- en: Later, in the `evaluate_answer` method, we increment this score by 1 if the
    LLM determines that the answer is correct.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在`evaluate_answer`方法中，如果LLM确定答案正确，我们将这个分数加1。
- en: Game Over
  id: totrans-256
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 游戏结束
- en: 'Our app doesn''t yet have any concept of when the game is over, so let''s define
    this. Again, we''ll keep the logic simple: we''ll ask a predefined number of questions,
    and the game is done when all of them have been asked and answered.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的应用程序还没有结束游戏的任何概念，所以让我们定义这个。同样，我们将保持逻辑简单：我们将询问一个预定义的问题数量，当所有这些问题都被问过并回答后，游戏结束。
- en: 'This involves modifying the `Game` class again:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及到再次修改`Game`类：
- en: '[PRE21]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: (`chapter_09/in_progress_04/game.py` in the GitHub repo)
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_04/game.py`）
- en: 'Again, this should be pretty easy to follow. We add two more attributes to
    the instance in `__init__`: `num_question_completed` and `max_questions` (set
    to 1 for now since we don''t actually support multiple questions yet—that''s coming
    up in the next section).'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这应该很容易理解。我们在`__init__`中向实例添加了两个额外的属性：`num_question_completed`和`max_questions`（目前设置为1，因为我们实际上还不支持多个问题——这将在下一节中介绍）。
- en: We increment `num_questions_completed` by 1 in `evaluate_answer`, and add a
    new method called `is_over` that returns `True` if the number of questions completed
    matches or exceeds `self.max_questions`.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在`evaluate_answer`中，我们将`num_questions_completed`加1，并添加一个名为`is_over`的新方法，如果完成的问题数量与`self.max_questions`匹配或超过，则返回`True`。
- en: A New Game button
  id: totrans-263
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 新游戏按钮
- en: At the moment, Fact Frenzy jumps straight into asking the LLM for a question
    as soon as the page loads. A "New Game" button would let users trigger the start
    of a game or take any other action we may want to add later before we engage the
    LLM.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Fact Frenzy在页面加载后立即直接向LLM请求问题。一个“新游戏”按钮将允许用户在参与LLM之前触发游戏的开始或执行我们可能希望添加的任何其他操作。
- en: 'This will primarily affect our frontend code, so let''s update `main.py` thus:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这将主要影响我们的前端代码，所以让我们更新`main.py`：
- en: '[PRE22]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: (`chapter_09/in_progress_04/main.py` in the GitHub repo)
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_04/main.py`）
- en: 'There are several changes to highlight here. Firstly, there are two new functions:
    `start_new_game` and `new_game_button`, which we''ll look into in a second.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个变化需要强调。首先，有两个新的函数：`start_new_game`和`new_game_button`，我们将在下一部分中探讨。
- en: 'Since it''s now possible for a game to not have started yet—before the "New
    Game" button is clicked, we allow for game to be `None` if it hasn''t been added
    to `st.session_state` yet:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 由于现在游戏可能还没有开始——在点击“新游戏”按钮之前，如果它还没有被添加到`st.session_state`中，我们允许游戏为`None`：
- en: '[PRE23]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We''ve also changed the layout of the app to have two columns: a side column
    (`side_col`) and a main one (`main_col`):'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还改变了应用程序的布局，使其有两列：一个侧边栏（`side_col`）和一个主要列（`main_col`）：
- en: '[PRE24]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This side column could have simply been an `st.sidebar`, but in a later section,
    it'll turn out we need this column to have a higher width than `st.sidebar` offers
    by default.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这个侧边栏本可以简单地是一个`st.sidebar`，但在后面的章节中，我们会发现我们需要这个列比默认的`st.sidebar`提供更高的宽度。
- en: 'Anyway, `side_col` contains a header introducing Fact Frenzy, and a call to
    `new_game_button`:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，`side_col` 包含一个介绍疯狂事实的标题，以及一个对 `new_game_button` 的调用：
- en: '[PRE25]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In Chapter 8, we used the Material library to display icons. Here, we''ve given
    Fact Frenzy a lightning-bolt icon using a different approach: by pasting an emoji
    into our code. We''re able to do this because emoji are part of the *Unicode*
    standard, which defines a consistent way to represent text and symbols across
    different systems and platforms. Whenever you want to add an emoji, you can search
    for it on a website like `emojipedia.org` and copy it.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 8 章，我们使用了 Material 库来显示图标。在这里，我们使用不同的方法为疯狂事实添加了一个闪电图标：通过将表情符号粘贴到我们的代码中。我们能够这样做是因为表情符号是
    *Unicode* 标准的一部分，该标准定义了在不同系统和平台间表示文本和符号的一致方式。每次你想添加表情符号时，你都可以在像 `emojipedia.org`
    这样的网站上搜索它并复制它。
- en: 'The `new_game_button` function is defined thus:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '`new_game_button` 函数定义如下：'
- en: '[PRE26]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In essence, we're checking if the game is already in progress—`if game and not
    game.is_over()` determines that `game` doesn't have the value `None` and that
    its `is_over` method returns `False`—and displaying a different button according
    to the result.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，我们正在检查游戏是否已经在进行中——`if game and not game.is_over()` 确定变量 `game` 不为 `None`，并且其
    `is_over` 方法返回 `False`——并根据结果显示不同的按钮。
- en: We vary two characteristics of the button—its text and its type. The text says
    "Restart game" if the game is in progress, and "Start new game" if it's not.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们改变了按钮的两个特性——其文本和其类型。如果游戏正在进行中，文本显示为“重新开始游戏”，如果没有进行，则显示为“开始新游戏”。
- en: How about the button's `type` parameter? We may have given it a value in previous
    chapters, but let's examine it more thoroughly now. The three values `type` can
    take are `primary`, `secondary`, and `tertiary`—each indicating how prominent
    the button should be. A button with type `primary` has a solid color (usually
    orange) with white text, a `secondary` button—the default if you don't specify
    a type—is white with solid-colored text, while a `tertiary` button is more subtle
    and appears as regular text without a border.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 那按钮的 `type` 参数呢？我们可能在之前的章节中给它赋过值，但现在让我们更彻底地检查它。`type` 可以取的三个值是 `primary`、`secondary`
    和 `tertiary`——每个值都表示按钮应该有多突出。类型为 `primary` 的按钮具有实色（通常是橙色）和白色文本，`secondary` 按钮如果没有指定类型则是白色和实色文本，而
    `tertiary` 按钮则更为微妙，看起来像普通文本而没有边框。
- en: In UI design, it's a good practice to guide the user towards the "correct" or
    most likely action they might want to take at any given point—it makes for a more
    intuitive design. If the game hasn't started yet, the choice that makes the most
    sense is to click the "Start new game" button, so we give it a type of `primary`.
    If the game is in progress, the default action should be to answer the question,
    not to restart the game. Therefore, while we make that possibility available,
    we don't overly emphasize it.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在 UI 设计中，引导用户在任意时刻采取“正确”或最可能想要采取的操作是一个好的实践——这会使设计更加直观。如果游戏尚未开始，最合理的选项是点击“开始新游戏”按钮，因此我们将其类型设置为
    `primary`。如果游戏正在进行，默认操作应该是回答问题，而不是重新开始游戏。因此，虽然我们提供了这种可能性，但我们并没有过分强调它。
- en: 'These differences in the button are mostly cosmetic, however. In either case,
    a click issues a call to `start_new_game`, which has the following code:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，按钮中的这些差异主要是外观上的。在两种情况下，点击都会发出对 `start_new_game` 的调用，该调用具有以下代码：
- en: '[PRE27]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: As before, we create a `Game` instance and assign it to `st.session_state.game`.
    Since the presence of `game` in `st.session_state` changes what should be displayed
    on the screen, we also issue an `st.rerun()`.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们创建了一个 `Game` 实例并将其分配给 `st.session_state.game`。由于 `game` 在 `st.session_state`
    中的存在会改变屏幕上应该显示的内容，我们也发出了一个 `st.rerun()`。
- en: By wrapping this logic in a function, we're preventing it from executing by
    default, instead requiring the New Game button to actually be clicked.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将此逻辑封装在函数中，我们防止它默认执行，而是要求实际点击新游戏按钮。
- en: The main column of the game—`main_col`—is, of course, where the content is meant
    to be displayed. In this iteration of `main.py`, we've simply moved the widgets
    we had before into `main_col`. There are a few additions worth highlighting though.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏的主要列——`main_col`——当然是内容应该显示的地方。在本轮 `main.py` 的迭代中，我们只是将之前拥有的小部件移动到了 `main_col`。尽管如此，还有一些值得强调的添加。
- en: 'If `game` is `None`—which means no game has started yet—we want the main column
    to be completely blank so the player''s attention is focused on `side_col`. This
    explains why the code under with `main_col` starts with `if game`:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`game`是`None`——这意味着还没有开始游戏——我们希望主列完全为空，以便玩家的注意力集中在`side_col`上。这也解释了为什么在`main_col`下的代码以`if
    game`开始的原因：
- en: '[PRE28]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We've also added a header that just says "Question." We'll update this later
    to show the question number.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还添加了一个标题，上面只写着“问题。”稍后我们会更新它以显示问题编号。
- en: 'Finally, we''ve added some logic to handle the case of the game being over
    under the `STATE_RESULT` state:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在`STATE_RESULT`状态下添加了一些逻辑来处理游戏结束的情况：
- en: '[PRE29]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This should be quite clear. We use the `is_over` method we defined earlier to
    check if the game is done, and show an appropriate message and the final score
    (`game.score`) if so.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该相当清晰。我们使用之前定义的`is_over`方法来检查游戏是否结束，如果游戏结束，则显示相应的消息和最终得分（`game.score`）。
- en: That concludes another iteration of our code. Go ahead and re-run your app to
    get figure 9.9.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们代码的另一个迭代。请重新运行您的应用程序以获取图9.9。
- en: '![image](../Images/09__image009.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/09__image009.png)'
- en: Figure 9.9 Keeping score, a New Game button, and Game Over (see chapter_09/in_progress_04
    in the GitHub repo for the full code)
  id: totrans-296
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.9 记分、新游戏按钮和游戏结束（完整代码请见GitHub仓库中的chapter_09/in_progress_04）
- en: Sweet! Fact Frenzy is starting to look pretty slick. Adding support for multiple
    questions is next!
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！Fact Frenzy开始看起来相当漂亮。下一个任务是添加对多个问题的支持！
- en: 9.6 Including multiple questions
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.6 包含多个问题
- en: In the previous section, we introduced key game mechanics to our app—adding
    a score system and defining the game's start and end—to make it feel more like
    a real game.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们向我们的应用程序引入了关键的游戏机制——添加得分系统和定义游戏的开始和结束，使其更像一个真正的游戏。
- en: Fact Frenzy still only asks one question though, so it's not much of one yet.
    It's time to change that. But before we do, let's explore an LLM-related challenge
    we'll face.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，Fact Frenzy仍然只问一个问题，所以它现在还不是很多。是时候改变这一点了。但在我们这样做之前，让我们探索我们将面临的一个与LLM相关的挑战。
- en: 9.6.1 Response variability, or lack thereof
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.6.1 响应变异性，或缺乏变异性
- en: In many ways, an LLM is like a black box. Unlike a piece of "regular" code that
    tends to be deterministic—meaning that the same input always produces the same
    output—LLMs are *probabilistic*, which means you may get different responses for
    the same input (or similar inputs), based on a set of probabilities.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多方面，一个大型语言模型（LLM）就像一个黑盒。与倾向于确定性（即相同的输入总是产生相同的输出）的“常规”代码不同，LLMs是**概率性的**，这意味着根据一组概率，你可能对相同的输入（或类似的输入）得到不同的响应。
- en: Depending on what you're trying to achieve, this variability can be a good or
    a bad thing. For example, if you're trying to get an LLM to generate poetry, you
    may want a fairly high amount of creativity or variability in the response, whereas
    if you're evaluating a mathematical equation, you want less.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你试图实现的目标，这种变异性可能是一件好事或坏事。例如，如果你试图让LLM生成诗歌，你可能希望响应中有相当高的创造性和变异性，而如果你在评估一个数学方程式，你希望更少。
- en: Vendors like OpenAI generally expose a few controls for this variability, making
    it easier to manage, but often we need to engineer the prompt to extract the behavior
    we want from the model.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于OpenAI这样的供应商通常只公开一些用于这种变异性的控制，这使得管理起来更容易，但通常我们需要设计提示来从模型中提取我们想要的行为。
- en: For our use case of generating questions, we want relatively high variability.
    If you've played around with our current app for a while, you may have noticed
    that the questions we get from the LLM are often repeated. In my testing, for
    instance, the model had a particular fondness for asking about the only planet
    in the solar system that rotates on its side.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们生成问题的用例，我们希望有相对较高的变异性。如果你已经玩了一段时间我们的当前应用程序，你可能已经注意到我们从LLM得到的问题经常重复。例如，在我的测试中，该模型特别偏爱询问太阳系中唯一一个侧向旋转的行星。
- en: This won't work for us. For one thing, if a single game includes multiple questions,
    all of them *must* be unique. Secondly, even if a particular question isn't asked
    twice in the same game, we don't want it to repeat too often across *different*
    games either.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这对我们来说不起作用。首先，如果一个游戏包含多个问题，所有这些问题*必须*是唯一的。其次，即使同一个问题在同一个游戏中没有重复，我们也不想它在不同的游戏中重复得太频繁。
- en: Let's take a look at a few ways in which we can control variability in the LLM's
    answer.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们可以控制LLM答案变异性的一些方法。
- en: Note
  id: totrans-308
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: One consequence of the fact that LLMs generate text based on probabilistic patterns
    (rather than an understanding of facts) is what we call "hallucinations"—instances
    where the model produces outputs that are plausible-sounding but factually incorrect
    or entirely fabricated. These hallucinations arise because LLMs rely on the statistical
    relationships in their training data, which can sometimes lead to confident but
    misleading responses. Strategies exist to reduce the likelihood of hallucinations,
    such as enabling LLMs to connect to external sources of information, but there's
    no way to guarantee that they won't occur at all. Dealing with hallucinations
    is outside the scope of this chapter-~-we'll tackle supplementing an LLM's knowledge
    base with our own sources in the next one. Just be aware that our app may occasionally
    produce a question or answer that isn't factual. Fortunately, based on my testing,
    these occurrences tend to be infrequent.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs基于概率模式（而不是事实理解）生成文本的事实的一个后果是我们所说的“幻觉”——即模型产生看似合理但实际上错误或完全虚构的输出。这些幻觉的产生是因为LLMs依赖于其训练数据中的统计关系，这有时会导致自信但误导性的回应。存在一些策略可以减少幻觉的可能性，例如使LLMs能够连接到外部信息源，但无法保证它们绝对不会发生。处理幻觉超出了本章的范围——我们将在下一章中解决使用我们自己的来源补充LLM知识库的问题。只需注意，我们的应用程序可能会偶尔产生一个非事实性的问题或答案。幸运的是，根据我的测试，这些情况通常很少发生。
- en: Varying temperature and top_p
  id: totrans-310
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 变化温度和top_p
- en: The prompts we send to a large language model and the response we get back from
    it both consist of *tokens*. A token may be a single word or it may be part of
    a word.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发送给大型语言模型的提示和从它那里得到的响应都由*标记*组成。一个标记可能是一个单词，也可能是一个单词的一部分。
- en: At its heart, an LLM constructs the response to a prompt step-by-step, or rather,
    token-by-token. In each step, it considers a wide range of possibilities for the
    next token to include in its response, assigning a *probability* of being picked
    (from high school math, a number between 0 and 1) to each token option.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在本质上，LLM按步骤或更确切地说按标记逐步构建对提示的响应。在每一步中，它考虑将包括在其响应中的下一个标记的广泛可能性，并为每个标记选项分配一个*概率*（从高中数学，一个介于0和1之间的数字）。
- en: These tokens form what's known as a *probability distribution*—think of it as
    a curve that represents the likelihood of each token being the next one, with
    the more likely tokens plotted at a higher place on the curve than the less likely
    ones.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 这些标记形成了一个所谓的*概率分布*——将其想象为一个曲线，表示每个标记成为下一个标记的可能性，其中更可能的标记在曲线上的位置高于不太可能的标记。
- en: OpenAI offers two parameters—`temperature` and `top_p`—that can adjust the composition
    of this curve. Figure 9.10 illustrates the effect of varying these parameters
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI提供了两个参数——`temperature`和`top_p`——可以调整此曲线的组成。图9.10说明了这些参数变化的影响
- en: '![image](../Images/09__image010.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image010.png)'
- en: Figure 9.10 How temperature and top_p affect the creativity and predictability
    of an LLM's output
  id: totrans-316
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.10 温度和top_p如何影响LLM输出的创造性和可预测性
- en: '`temperature` can take values from 0 to 2, with a higher value serving to make
    the curve flatter, and a lower value making it more pronounced. A higher temperature
    thus tends to "even" out the curve, increasing the probability that some of the
    less likely token options may be picked, which makes the LLM take more "risks"
    and increases the overall creativity of its response.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '`temperature`可以取0到2之间的值，较高的值会使曲线更平坦，而较低的值会使曲线更明显。因此，较高的温度倾向于“平衡”曲线，增加选择不太可能的标记选项的概率，这使得LLM承担更多的“风险”，并增加了其响应的整体创造性。'
- en: '`top_p` can go from 0 to 1\. It represents a cutoff for the cumulative probability
    of the tokens that the model will choose from. To take an example, the LLM may
    determine that the five most likely next tokens in its response and their respective
    probabilities are: "but": 0.6, "then": 0.2, "a": 0.1, "this": 0.06, and "that":
    0.02—with all other tokens having much lower probabilities.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '`top_p`可以从0到1。它代表了模型将选择的标记的累积概率的截止值。以一个例子来说明，LLM可能确定其响应中五个最有可能的下一个标记及其相应的概率是：“但是”：0.6，“然后”：0.2，“一个”：0.1，“这个”：0.06，和“那个”：0.02——所有其他标记的概率都低得多。'
- en: A `top_p` of 0.8 would mean that the model should only choose between the most
    likely tokens with a combined probability of at least 0.8\. In this case, since
    "but" and "then" together cover a probability of 0.6 + 0.2 >= 0.8, the model discards
    everything else.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '`top_p`为0.8意味着模型应该只选择具有至少0.8组合概率的最可能标记。在这种情况下，由于“but”和“then”一起覆盖了0.6 + 0.2
    >= 0.8的概率，模型将丢弃其他所有内容。'
- en: A `top_p` of 0.95, on the other hand, would require the model to also consider
    "a" and "this" to cover the required cumulative probability (0.6 + 0.2 + 0.1 +
    0.06 >= 0.95).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`top_p`为0.95将要求模型也考虑“a”和“this”以覆盖所需的累积概率（0.6 + 0.2 + 0.1 + 0.06 >= 0.95）。
- en: A higher `top_p`, therefore, means that the LLM will consider more token options,
    potentially reducing the predictability and coherence of the response, but increasing
    its diversity.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，更高的`top_p`意味着LLM将考虑更多的标记选项，这可能会降低响应的可预测性和连贯性，但会增加其多样性。
- en: Getting back to our original goal of generating a variety of questions, we probably
    want a moderately high `temperature`—say 0.7 to 0.8—and a relatively high `top_p`
    of, say, 0.9.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们最初的目标，即生成各种问题，我们可能需要一个适度的`temperature`——比如说0.7到0.8，以及相对较高的`top_p`，比如说0.9。
- en: Including previous questions in the prompt
  id: totrans-323
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在提示词中包含先前的问题
- en: As discussed, while it would be ideal for questions to not repeat across *different*
    games, we must practically *guarantee* that the same question isn't asked twice
    in a *single* game.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前讨论的，虽然理想情况下问题不应在不同游戏中重复，但我们实际上必须**保证**在单个游戏中不会重复提出相同的问题。
- en: Fortunately, this is easily achieved—by explicitly telling the LLM which questions
    have been asked so far in the game so it knows to steer clear of those.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这很容易实现——通过明确告诉LLM游戏中已经提出的问题，这样它就知道要避开这些问题。
- en: For reinforcement, we could even tell the LLM to make sure to never ask the
    same question twice.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加强这一点，我们甚至可以告诉LLM确保永远不要提出相同的问题两次。
- en: Injecting randomness
  id: totrans-327
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注入随机性
- en: Another way to get a wider variety of questions back is to inject some structured
    randomness into the prompt. You may have heard of the word game "Mad Libs" where
    players are provided a story with various parts of speech replaced with blanks.
    Each player then fills in a blank with a word of their choice, with the completed
    story often being hilarious.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 获取更广泛的问题种类的一种方法是在提示词中注入一些结构化的随机性。你可能听说过一个叫做“Mad Libs”的单词游戏，玩家被提供了一个故事，其中各种词性被空白代替。然后每个玩家用他们选择的单词填充一个空白，完成的故事常常非常有趣。
- en: We could do something similar here. We could change our prompt to something
    like "Generate a unique trivia question in the category ______ and a topic ______
    within that category. The question should reference a person or thing whose name
    starts with the letter ______".
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里也可以做类似的事情。我们可以将提示词改为类似于“在类别 ______ 和该类别内的主题 ______ 中生成一个独特的趣味问题。问题应参考一个名字以字母
    ______ 开头的人或事物”。
- en: Within our code, we could then maintain lists of categories, topics, and letters,
    randomly picking one from each list to fill in the blanks before sending the prompt
    to the LLM. If we have say, 10 categories, 10 topics within each category, we
    would have 26 (letters in the alphabet) x 10 x 10 = 2600 unique combinations,
    in addition to the variability that the LLM itself provides.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码中，我们可以维护类别、主题和字母的列表，随机从每个列表中选取一个来填充空白，在将提示发送给LLM之前。如果我们有10个类别，每个类别中有10个主题，那么我们就会有26（字母表中的字母）x
    10 x 10 = 2600种独特的组合，再加上LLM本身提供的可变性。
- en: Or to save us the trouble of maintaining these lists, why not ask the LLM to
    pick a category and topic first? Interestingly, doing this appears to increase
    the diversity of the responses generated.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 或者为了省去维护这些列表的麻烦，为什么不先让LLM选择一个类别和主题呢？有趣的是，这样做似乎增加了生成的响应的多样性。
- en: Yet another way to inject randomness that seems to help is to explicitly provide
    a random *seed* in your prompt. In programming, a random seed is a value (generally
    an integer) that initializes a random number generator. While it's not very clear
    that adding one to the text of your prompt actually causes the LLM to generate
    a random number, in my testing, doing so did increase the variability of responses.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种注入随机性的方法是在提示词中明确提供一个随机**种子**。在编程中，随机种子是一个值（通常是一个整数），用于初始化随机数生成器。虽然不清楚将一个添加到提示词的文本中实际上是否会导致LLM生成随机数，但在我的测试中，这样做确实增加了响应的变异性。
- en: Note
  id: totrans-333
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: It's important to note here that modifying your prompt to get the results you
    want is not pure science; often you'll need to experiment with various techniques
    and prompts to identify the approach that works best. You may also see surprising
    results—for instance, AI researchers have found asking an LLM to think through
    its approach to solving a problem step-by-step often improves how well it performs
    the task.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的是，修改你的提示以获得你想要的结果并不是纯粹的科学；通常你需要尝试各种技术和提示来识别最佳的方法。你也可能会看到令人惊讶的结果——例如，AI研究人员发现，让LLM逐步思考解决问题的方法往往可以提高其完成任务的表现。
- en: 9.6.2 Implementing multiple questions
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.6.2 实现多个问题
- en: Now that we've reviewed how variability works in LLMs and possible approaches
    to ensure we get different questions each time, let's modify Fact Frenzy so it
    asks the user multiple questions in a game.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经回顾了在LLMs中变异性是如何工作的以及确保每次都能得到不同问题的可能方法，让我们修改“事实狂热”游戏，使其在游戏中向用户提出多个问题。
- en: Modifying the LLM prompt
  id: totrans-337
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 修改LLM提示
- en: Let's first make the requisite changes to our prompts to put into practice what
    we've learned.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先对我们的提示进行必要的更改，以便将我们所学的内容付诸实践。
- en: 'Before we do that—our `Llm` class doesn''t currently offer a way to change
    the `temperature` and `top_p`, so we should modify its code (in `llm.py`) thus:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们这样做之前——我们的`Llm`类目前还没有提供更改`temperature`和`top_p`的方法，因此我们应该修改其代码（在`llm.py`中）如下：
- en: '[PRE30]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: (`chapter_09/in_progress_05/llm.py` in the GitHub repo)
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_05/llm.py`）
- en: As you can see above, we've refactored the `ask` method in the `Llm` class a
    fair bit. First, it accepts `temperature` and `top_p` as new arguments, both defaulting
    to `None`.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，我们对`Llm`类中的`ask`方法进行了相当大的重构。首先，它接受`temperature`和`top_p`作为新的参数，两者默认为`None`。
- en: Instead of repeating the `model`, `messages`, `temperature`, and `top_p` arguments
    to the OpenAI client's `beta.chat.completions.parse` or `chat.completions.create`,
    we construct an `llm_args` dictionary that holds the right arguments and their
    values depending on whether each is provided.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是重复将`model`、`messages`、`temperature`和`top_p`参数传递给OpenAI客户端的`beta.chat.completions.parse`或`chat.completions.create`，我们构建一个`llm_args`字典，根据每个参数是否提供来保存正确的参数及其值。
- en: 'We then use the `**` dictionary unpacking operator (that we encountered in
    Chapter 7) to pass the arguments to the OpenAI methods. Note that we can combine
    this with the normal way of passing arguments:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`**`字典解包操作符（我们在第7章中遇到过的）将参数传递给OpenAI方法。请注意，我们可以将此与传递参数的正常方式结合起来：
- en: '[PRE31]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here we pass `reponse_format` in the regular way, but unpack `llm_args` for
    the remaining arguments.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们以常规方式传递`reponse_format`，但对于剩余的参数，我们解包`llm_args`。
- en: 'Next, in `prompts.py`, edit our question-generation prompt so it now reads:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在`prompts.py`中，编辑我们的问题生成提示，使其现在读取：
- en: '[PRE32]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: (`chapter_09/in_progress_05/prompts.py` in the GitHub repo)
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_05/prompts.py`）
- en: 'You''ll see that we''ve incorporated several of the techniques discussed in
    the last section:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到我们已经结合了上一节中讨论的几种技术：
- en: The system prompt requests the LLM to behave like a quizmaster who never asks
    the same question twice.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统提示要求LLM表现得像一个从未重复提问的问答大师。
- en: We ask the LLM to think of a unique category and a topic within it.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们要求LLM想一个独特的类别及其内的一个主题。
- en: We add a "seed" variable and ask the LLM to generate the question using that
    seed.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们添加了一个“种子”变量，并要求LLM使用该种子生成问题。
- en: At the end of the prompt, for references, we provide the questions that have
    already been asked, so the LLM can avoid those.
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在提示的最后，为了参考，我们提供了已经提出的问题，这样LLM就可以避免这些问题。
- en: We need to accompany these changes with additional ones in the `Game` class.
    Besides the LLM stuff, to enable asking multiple questions in a game, we need
    to be able to repeat the movement from the first game state to the last many times.
    In effect, our state diagram now becomes a *cycle* as opposed to a line, as shown
    in figure 9.11.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在`Game`类中伴随这些更改进行额外的更改。除了LLM相关的内容外，为了在游戏中提出多个问题，我们需要能够多次重复从第一个游戏状态到最后一个状态的运动。实际上，我们的状态图现在变成了一个*循环*，而不是一条线，如图9.11所示。
- en: '![image](../Images/09__image011.png)'
  id: totrans-356
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image011.png)'
- en: Figure 9.11 To implement multiple questions, we now cycle through the game states
    in a loop
  id: totrans-357
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.11 为了实现多个问题，我们现在循环遍历游戏状态
- en: 'This means we also need another method to move from the `STATE_RESULT` state
    back to `GET_QUESTION`. Let’s add this method along with the rest of the changes
    to `game.py` now:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们还需要另一个方法来从`STATE_RESULT`状态回到`GET_QUESTION`状态。现在让我们添加这个方法以及`game.py`中的其他更改：
- en: '[PRE33]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: (`chapter_09/in_progress_05/game.py` in the GitHub repo)
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_05/game.py`）
- en: 'You''ll see that we''ve added a new attribute, `self.questions`, within `__init__`,
    initializing it to an empty list. As you''ve likely guessed, this will hold all
    the questions we get from the LLM. We accomplish this through this addition in
    the `obtain_questions` method:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到我们在`__init__`中添加了一个新的属性`self.questions`，并将其初始化为空列表。正如你可能猜到的，这将保存我们从LLM获取的所有问题。我们通过在`obtain_questions`方法中的这个添加来实现：
- en: '[PRE34]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Additionally, since we'll finally have more than one question to ask, we've
    changed the value of `self.max_questions` to 5\. Feel free to change this to whatever
    number you like.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于我们最终将有多于一个问题要问，我们将`self.max_questions`的值更改为5。你可以随意将其更改为你喜欢的任何数字。
- en: We've revamped the `ask_llm_for_question` method entirely, since our user message
    now has a couple of variables we need to provide values for. `{already_asked}`
    can simply be replaced by `self.questions` (with the individual list items separated
    by newlines).
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们完全重写了`ask_llm_for_question`方法，因为我们的用户消息现在有几个变量我们需要提供值。`{already_asked}`可以简单地替换为`self.questions`（列表项之间用换行符分隔）。
- en: 'For the random seed, we simply use the current timestamp converted to an integer:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 对于随机种子，我们简单地使用当前时间戳转换为整数：
- en: '[PRE35]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Since timestamps always go up by definition, the current timestamp is guaranteed
    to be something the LLM has never gotten before from us.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 由于时间戳总是按定义增加，所以当前时间戳保证是LLM之前从未从我们这里得到过的。
- en: We also now pass `temperature` and `top_p` values to `self.llm.ask` in line
    with our exploration of these parameters.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在还向`self.llm.ask`传递`temperature`和`top_p`值，以符合我们对这些参数的探索。
- en: To enable multiple questions, a newly added `proceed_to_next_question` sets
    the game's status back to `GET_QUESTION`, completing the state cycle in figure
    9.11.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启用多个问题，新添加的`proceed_to_next_question`将游戏状态重置为`GET_QUESTION`，完成图9.11中的状态循环。
- en: 'The changes required to the frontend are relatively simple. Edit `main.py`
    thus:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 对前端所需的更改相对简单。编辑`main.py`如下：
- en: '[PRE36]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: (`chapter_09/in_progress_05/main.py` in the GitHub repo)
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_05/main.py`）
- en: 'Firstly, we''ve modified the header of the main column to provide the question
    number (`len(game.questions)`) and the total number of questions (`game.max_questions`):'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们修改了主列的标题，以提供问题编号（`len(game.questions)`）和总问题数（`game.max_questions`）：
- en: '[PRE37]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We''ve also added a subheader to display the score:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还添加了一个子标题来显示分数：
- en: '[PRE38]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: To facilitate the state change from `STATE_RESULT` to `GET_QUESTION`, we've
    added an `else` clause that will—if the game isn't over—display a "Next question"
    button that triggers the `game` object's `proceed_to_next_question()` when clicked.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于从`STATE_RESULT`状态切换到`GET_QUESTION`状态，我们添加了一个`else`子句，如果游戏没有结束，则会显示一个“下一个问题”按钮，点击该按钮会触发`game`对象的`proceed_to_next_question()`方法。
- en: 'Notice the unfamiliar way in which we''ve written the `st.button` widget:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们编写`st.button`小部件的不寻常方式：
- en: '[PRE39]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '`st.button`''s `on_click` parameter lets you specify a function to execute
    when the button is clicked. We *could* also have written this in the way we''ve
    done so far in this book, i.e. as:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '`st.button`的`on_click`参数允许你指定在按钮被点击时执行的功能。我们**也可以**像我们在本书中迄今为止所做的那样编写这个，即：'
- en: '[PRE40]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The difference lies in when the triggered function is actually executed. Specifically:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 差异在于触发函数实际执行的时间。具体来说：
- en: When we use the `if st.button` notation, the button click first triggers a re-run
    of the page, causing everything above the button to be re-rendered again before
    the code under the `if` executes—triggered by the fact that `st.button` evaluates
    to `True` in the re-run. After this code executes, we may need to manually trigger
    *another* re-run as shown above—and as we've been doing throughout this book,
    really—to see any changes in the page caused by it.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们使用`if st.button`表示法时，按钮点击首先会触发页面的重新运行，导致按钮上方的内容再次重新渲染，然后在`if`代码执行之前——由`st.button`在重新运行中评估为`True`的事实触发。在这段代码执行后，我们可能需要手动再次触发上述的重新运行——就像我们在整本书中一直做的那样——以查看它引起的页面上的任何变化。
- en: With the `on_click` notation, the button click causes the function listed under
    `on_click` (called a *callback* by the way) to execute *before* the page is re-run
    and everything above the button is re-rendered. We don't need a manual `st.rerun()`
    in this case, because the re-run triggered by the button-click already takes into
    account the changes made by the callback since it has already executed.
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `on_click` 注记，按钮点击会导致在 `on_click` 下列出的函数（顺便提一下，被称为回调函数）在页面重新运行和按钮上方的内容重新渲染之前执行。在这种情况下，我们不需要手动调用
    `st.rerun()`，因为由按钮点击触发的重新运行已经考虑了回调函数执行后所做的更改。
- en: So why haven't we been using this method all along? Well, the `if st.button`
    structure tends to be a little easier to grasp for simple apps. Besides, callbacks
    have some restrictions—you can't trigger an app rerun within a callback, for instance.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 那么为什么我们一直没在使用这种方法呢？嗯，对于简单的应用来说，`if st.button` 结构通常更容易理解。此外，回调函数还有一些限制——例如，你无法在回调函数中触发应用的重新运行。
- en: In any case, you should be able to re-run your app at this point to try out
    a working multi-question game (figure 9.12).
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，你现在应该能够重新运行你的应用来尝试一个工作中的多问题游戏（图9.12）。
- en: '![image](../Images/09__image012.png)'
  id: totrans-387
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/09__image012.png)'
- en: Figure 9.12 A working multi-question trivia game (see chapter_09/in_progress_05
    in the GitHub repo for the full code)
  id: totrans-388
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.12 一个工作中的多问题知识竞赛游戏（完整代码请见GitHub仓库中的chapter_09/in_progress_05）
- en: Our trivia game is technically complete now, but let's see if we can make it
    more engaging in the next section.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的知识竞赛游戏在技术上现在已经完成了，但让我们看看在下一节中我们能否让它更加吸引人。
- en: Cost considerations
  id: totrans-390
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 成本考虑
- en: LLMs are an incredible general-purpose tool, but it is important to realize
    that using them in your app—especially in production where it may be accessed
    by hundreds of users—is not free. The last thing you want is to accidentally run
    up a huge bill.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 是一个令人难以置信的通用工具，但重要的是要意识到，在你的应用中使用它们——尤其是在可能被数百名用户访问的生产环境中——并不是免费的。你最不希望的就是意外地产生一大笔费用。
- en: '**How cost is calculated**'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '**成本计算方式**'
- en: When using an LLM, costs are typically calculated based on the number of *tokens*
    processed. As discussed in section 9.5.1, a "token" represents a chunk of text—a
    word or a part of a word—that the model reads (input) or generates (output).
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用LLM时，成本通常基于处理的标记数量计算。如第9.5.1节所述，“标记”代表模型读取（输入）或生成（输出）的文本块——一个单词或单词的一部分。
- en: OpenAI charges people based on the sum of the input and output tokens processed.
    This means that the size of the input prompt and the size of the output text *both*
    contribute to the cost. The pricing also differs by model. At the time of writing,
    the model we've been using in this chapter—gpt-4o-mini—costs 15 cents for every
    1 million tokens processed.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 根据处理过的输入和输出标记的总和来收费。这意味着输入提示的大小和输出文本的大小都会影响成本。定价也因模型而异。在撰写本文时，我们在这章中使用的模型——gpt-4o-mini——处理每100万个标记的费用为15美分。
- en: You can use tools like [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)
    to count the tokens in a piece of text and determine costs.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用像 [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)
    这样的工具来计算文本中的标记数量并确定成本。
- en: '**Cost optimization strategies**'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '**成本优化策略**'
- en: 'There are several ways in which you could optimize cost while working with
    LLMs. Here are a few ideas:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 在与LLM一起工作时，有几种方法可以优化成本。以下是一些想法：
- en: Keep your input prompts short and to-the-point to reduce costs associated with
    input tokens.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持你的输入提示简短而直接，以减少与输入标记相关的成本。
- en: Reduce the size of the output text, either by instructing the LLM to keep its
    response short, or by explicitly restricting the number of tokens processed to
    a maximum value (e.g. by passing a value to the `max_tokens` argument while calling
    the OpenAI endpoint).
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过指示LLM保持其响应简短，或通过显式地将处理的标记数量限制在最大值（例如，通过在调用OpenAI端点时传递 `max_tokens` 参数的值）来减小输出文本的大小。
- en: Batch together multiple requests to reduce the total number of prompts sent
    to the LLM. For example, instead of providing a list of previously asked questions
    each time we need a new question—as we're doing here—we could simply ask the LLM
    to generate the total number of questions we want in one go.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将多个请求批量处理，以减少发送给LLM的总提示数。例如，在我们需要新的问题时，不是每次都提供一个之前提出的问题列表——就像我们在这里做的那样——我们只需简单地让LLM一次性生成我们想要的全部问题数量。
- en: Use less capable but cheaper models for some of your prompts. In our case, we're
    using gpt-4o-mini, which strikes a pretty good balance of cost and intelligence,
    but depending on your application, it may be possible to use even cheaper models
    for less complex tasks. Familiarize yourself with OpenAI's pricing page.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一些提示，使用能力较低但更便宜的模式。在我们的案例中，我们使用gpt-4o-mini，它在成本和智能之间取得了相当好的平衡，但根据您的应用程序，对于更简单的任务，可能可以使用甚至更便宜的模型。熟悉OpenAI的定价页面。
- en: Avoid LLM costs altogether by asking the user to provide their *own* LLM API
    key. For our game, this involves a major hit to user experience as it requires
    players to create an OpenAI account before they can play, but you're guaranteed
    to not have to pay a dime in LLM-related costs.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过让用户提供他们自己的LLM API密钥，完全避免LLM成本。对于我们的游戏来说，这会严重影响用户体验，因为它要求玩家在玩游戏之前创建一个OpenAI账户，但你保证在LLM相关的成本上不会花一分钱。
- en: 9.7 Adding AI personalities
  id: totrans-403
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.7 添加AI个性
- en: As an informative trivia game, Fact Frenzy works perfectly fine now. The end-to-end
    flow—from starting a new game to cycling through the questions and keeping score
    until the game ends—has been established.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一款信息类知识问答游戏，事实狂热现在运行得非常顺畅。从开始新游戏到循环提问并计分，直到游戏结束的端到端流程已经建立。
- en: However, it still lacks a certain *je ne sais quoi*—it's rather dry and mechanical.
    Wouldn't it be cool if we could give our game a personality? Fortunately, this
    is exactly the kind of thing that LLMs are great at. We could, for instance, ask
    GPT-4o to mimic the style of various characters while asking questions.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它仍然缺少某种“我不知道是什么”的东西——它相当枯燥且机械。如果我们能给我们的游戏赋予个性会怎么样？幸运的是，这正是LLMs擅长的。例如，我们可以要求GPT-4o在提问时模仿各种角色的风格。
- en: In fact, we could let players choose what character they want their quizmaster
    to take. Sound fun? Let's get to it!
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们可以让玩家选择他们希望他们的问答大师扮演的角色。听起来很有趣？让我们开始吧！
- en: 9.7.1 Adding game settings
  id: totrans-407
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.7.1 添加游戏设置
- en: We don't currently have a page or place in the app where players can view or
    change any settings, so we'll tackle that first.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们还没有一个页面或位置在应用程序中让玩家查看或更改任何设置，所以我们将首先解决这个问题。
- en: What options do we want the user to be able to set? We've already talked about
    the quizmaster speaking style, so that can be the first. We could also let the
    player pick a difficulty level that suits them.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望用户能够设置哪些选项？我们已经讨论了问答大师的说话风格，所以这可以成为第一个。我们还可以让玩家选择一个适合他们的难度级别。
- en: 'There are several different designs we could use for a "settings editor", but
    I want to use this opportunity to introduce a handy Streamlit widget we haven''t
    encountered before: `st.data_editor`.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 对于“设置编辑器”，我们可以使用几种不同的设计，但我想要利用这个机会介绍一个我们之前没有遇到过的实用Streamlit小部件：`st.data_editor`。
- en: st.data_editor
  id: totrans-411
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: st.data_editor
- en: In Chapters 6 and 7, we learned about Pandas dataframes, which make working
    with tabular data in Python easy. We discovered `st.dataframe`, used to render
    dataframes as a table in a Streamlit app for viewing.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 在第6章和第7章中，我们学习了Pandas数据框，它使Python中的表格数据处理变得容易。我们发现了`st.dataframe`，它用于在Streamlit应用程序中将数据框渲染为表格以供查看。
- en: '`st.data_editor` displays dataframes too, but also makes them *editable*, providing
    users with an experience that you might expect in a spreadsheet.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '`st.data_editor` 也可以显示数据框，但它还使它们可编辑，为用户提供可能在电子表格中期望的体验。'
- en: What does this have to do with adding settings to our app? Well, we could place
    the settings we want in a dataframe, and enable people to edit the dataframe to
    modify a setting.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 这与向我们的应用程序添加设置有什么关系呢？嗯，我们可以将我们想要的设置放在一个数据框中，并允许人们编辑数据框来修改设置。
- en: 'With the two settings we discussed a few paragraphs above, the settings dataframe
    might look like the following:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面几段讨论的两个设置中，设置数据框可能看起来如下所示：
- en: '[PRE41]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'If this dataframe is stored in `default_settings`, we might write our `st.data_editor`
    widget like so:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个数据框存储在`default_settings`中，我们可能编写我们的`st.data_editor`小部件如下所示：
- en: '[PRE42]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This would display the widget shown in figure 9.13.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示图9.13中所示的控件。
- en: '![image](../Images/09__image013.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image013.png)'
- en: Figure 9.13 A simple output of st.data_editor
  id: totrans-421
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.13 st.data_editor的简单输出
- en: The first argument here is the initial state of the data we want to edit—in
    this case, the default settings.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的第一个参数是我们想要编辑的数据的初始状态——在这种情况下，默认设置。
- en: The `num_rows='fixed'` means that the data editor widget shouldn't allow users
    to add any new rows. This makes sense because we don't want to have multiple rows
    in the dataframe shown above—a single setting can only have one value.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '`num_rows=''fixed''`意味着数据编辑器小部件不应允许用户添加任何新行。这很有意义，因为我们不希望在上述数据框中有多行——单个设置只能有一个值。'
- en: In any run of the app that happens before the user interacts with the data editor,
    `settings` will hold the same value as `default_settings`. Once the user changes
    a setting—for example, they might change Difficulty to `Easy`—`settings` will
    hold the edited dataframe across future re-runs until the user edits it again.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户与数据编辑器交互之前的任何一次应用程序运行中，`settings`将保持与`default_settings`相同的值。一旦用户更改了设置——例如，他们可能会将难度更改为`Easy`——`settings`将在未来的重新运行中保持编辑过的数据框，直到用户再次编辑它。
- en: Note
  id: totrans-425
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: The `key='settings_editor'` parameter adds a widget key to the session state
    for the data editor. While this isn't strictly required for the app to function
    correctly, it protects us from a certain quirk of Streamlit where it forgets the
    values of a widget without an explicit key between re-runs if that widget isn't
    rendered for some reason in a particular run. Adding a widget key doesn't cost
    us anything, so it's safer to provide one to avoid unforeseen bugs.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '`key=''settings_editor''`参数为数据编辑器会话状态添加了一个小部件键。虽然这对应用程序正确运行不是严格必需的，但它保护我们免受Streamlit的一个特定怪癖的影响，即在没有显式键的情况下，如果在特定运行中由于某种原因没有渲染该小部件，它会忘记小部件的值。添加小部件键不会给我们带来任何成本，因此提供一个小部件键更安全，可以避免未预见的错误。'
- en: 'Getting back to our example, we don''t necessarily want users to have to type
    in the name of the quizmaster or a difficulty level; we''d rather have them select
    from a list of options. `st.data_editor` supports this in the form of *column
    configurations*:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的示例，我们不一定希望用户必须输入测验主持人的名字或难度级别；我们更希望他们从选项列表中选择。`st.data_editor`通过*列配置*支持这一点：
- en: '[PRE43]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Here we exert more granular control over the editable data, configuring each
    column in the data through `st.column_config`.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们对可编辑的数据进行了更细粒度的控制，通过`st.column_config`配置数据中的每一列。
- en: For each of our columns, we use a `SelectBoxColumn` which lets us specify a
    list of options to choose from, and whether a value must be specified (the `required`
    parameter, set to `True` above).
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们每个列，我们使用一个`SelectBoxColumn`，它允许我们指定一个可供选择的选项列表，以及是否必须指定一个值（`required`参数，如上设置为`True`）。
- en: The results are shown in figure 9.14.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如图9.14所示。
- en: '![image](../Images/09__image014.png)'
  id: totrans-432
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image014.png)'
- en: Figure 9.14 st.data_editor with one of the columns showing a SelectBoxColumn
  id: totrans-433
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.14 st.data_editor显示了一个具有SelectBoxColumn的列
- en: '`st.column_config` supports many different column types besides `SelectBoxColumn`,
    such as a `CheckboxColumn` for boolean values, a `DatetimeColumn` that displays
    a date/time picker, and a `LinkColumn` for clickable URLs.'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '`st.column_config`除了`SelectBoxColumn`之外，还支持许多不同的列类型，例如用于布尔值的`CheckboxColumn`、显示日期/时间选择器的`DatetimeColumn`，以及用于可点击URL的`LinkColumn`。'
- en: It also supports non-editable types that can be used with `st.dataframe`, including
    `AreaChartColumn`, `BarChartColumn`, a `ListColumn` for lists, and even a `ProgressColumn`
    for numbers (displayed in a progress bar versus a target).
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 它还支持非可编辑类型，可以与`st.dataframe`一起使用，包括`AreaChartColumn`、`BarChartColumn`、用于列表的`ListColumn`，甚至用于数字的`ProgressColumn`（以进度条的形式显示，而不是目标）。
- en: Creating the settings editor
  id: totrans-436
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建设置编辑器
- en: Now that we know how `st.data_editor` works, let's go ahead and create a settings
    editor UI. We'll put this in a new file called `settings.py` (shown in listing
    9.8).
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了`st.data_editor`的工作原理，让我们继续创建一个设置编辑器UI。我们将把这个放在一个名为`settings.py`的新文件中（如列表9.8所示）。
- en: Listing 9.8 settings.py
  id: totrans-438
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.8 settings.py
- en: '[PRE44]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: (`chapter_09/in_progress_06/settings.py` in the GitHub repo)
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_06/settings.py`）
- en: We place the options for the Quizmaster and Difficulty settings right at the
    top for easy access, listing them under `QM_OPTIONS` and `DIFFICULTY_OPTIONS`.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将测验主持人和难度设置的选项直接放置在顶部，以便于访问，并在`QM_OPTIONS`和`DIFFICULTY_OPTIONS`下列出它们。
- en: The Quizmaster options range from an actual quizmaster, the late Alex Trebek
    of *Jeopardy!* fame, to a range of fictional characters like Gollum from *The
    Lord Of The Rings*, and Gruk the Caveman, an entirely made-up figure to let the
    LLM go wild.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 测验主持人选项从实际的测验主持人、已故的*Jeopardy!*名人亚历克斯·特雷贝克，到一系列虚构角色，如《指环王》中的咕噜，以及穴居人Gruk，一个完全虚构的人物，让LLM尽情发挥。
- en: 'We''ve initialized `default_settings` thus:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这样初始化了`default_settings`：
- en: '[PRE45]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Note how this *isn't* a dataframe as we suggested initially—it's a dictionary
    instead, with the name of each setting as a key, and a one-element list containing
    the default option for that setting as the corresponding value.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这**不是**我们最初建议的数据框——它是一个字典，每个设置的名称作为键，包含该设置默认选项的单元素列表作为相应的值。
- en: Interestingly, `st.data_editor` can display things that are not Pandas dataframes.
    This includes native Python types such as dictionaries, lists, and sets. The quality
    of being able to display these types even applies to `st.dataframe`, despite the
    name. In this case, it means we don't actually have to maintain the settings as
    a dataframe; we can use the more readable dictionary form above.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，`st.data_editor`可以显示不是Pandas数据框的东西。这包括原生Python类型，如字典、列表和集合。能够显示这些类型的能力甚至适用于`st.dataframe`，尽管其名称。在这种情况下，这意味着我们实际上不必将设置作为数据框来维护；我们可以使用上面更易读的字典形式。
- en: 'The `settings_editor` function renders the actual settings editor UI. We place
    everything within yet another new Streamlit widget called `st.popover`:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '`settings_editor`函数渲染实际的设置编辑器用户界面。我们将一切放置在另一个新的Streamlit小部件`st.popover`中：'
- en: '[PRE46]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '`st.popover` displays a popover widget, which is a small pop-up screen that
    you can trigger by clicking an associated button—in a similar manner to `st.expander`.
    The first argument is the label for the button that triggers the `st.popover`.'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '`st.popover`显示一个弹出小部件，这是一个可以通过点击相关按钮触发的弹出屏幕——类似于`st.expander`。第一个参数是触发`st.popover`的按钮的标签。'
- en: 'The contents of the popover are written within the `with st.popover(...)` context
    manager. In this case, we''re displaying the `st.data_editor` widget and returning
    its value, i.e. the edited `settings` dictionary:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 弹出窗口的内容是在`with st.popover(...)`上下文管理器中编写的。在这种情况下，我们显示`st.data_editor`小部件并返回其值，即编辑后的`settings`字典：
- en: '[PRE47]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This is pretty much the same code that we wrote in the previous section while
    we were discussing `st.data_editor`, though with the addition of a `use_container_width=True`
    argument, which adjusts the width of the popover.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上是我们之前在讨论`st.data_editor`时编写的相同代码，尽管增加了一个`use_container_width=True`参数，该参数调整了弹出窗口的宽度。
- en: Applying the settings
  id: totrans-453
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 应用设置
- en: 'How do we use these settings in Fact Frenzy? Both the Quizmaster and Difficulty
    settings relate to the question text generated by the LLM, so let''s incorporate
    them in the question prompt in `prompts.py`, which becomes:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何在Fact Frenzy中使用这些设置？问答大师和难度设置都与LLM生成的文本问题相关，所以让我们在`prompts.py`中的问题提示中包含它们，变成：
- en: '[PRE48]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: (`chapter_09/in_progress_06/prompts.py` in the GitHub repo)
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_06/prompts.py`）
- en: Obviously, there are plenty of ways to work our two new variables into the prompt—the
    above is just one.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，有很多方法可以将我们这两个新变量融入到提示中——上面只是其中一种。
- en: 'We''ll modify `game.py` next:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来将修改`game.py`：
- en: '[PRE49]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: (`chapter_09/in_progress_06/game.py` in the GitHub repo)
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_06/game.py`）
- en: '`Game`''s `__init__` now accepts a `settings` parameter, which—as you''d expect—is
    in the dictionary format we used in `settings.py`. This is assigned to `self.settings`
    so other methods can access it.'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: '`Game`的`__init__`现在接受一个`settings`参数，正如你所期望的，它是我们在`settings.py`中使用的字典格式。这被分配给`self.settings`，以便其他方法可以访问它。'
- en: 'We''ve added two associated methods: `get_setting` and `modify_settings`. `get_setting`
    deals with getting the value of a given setting, which is slightly tricky because
    each dictionary value is a single-element list (designed that way so it works
    with `st.data_editor`). `get_setting` abstracts away this somewhat unsightly logic
    so we restrict it to one place in the code.'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了两个相关方法：`get_setting`和`modify_settings`。`get_setting`处理获取给定设置的值，这有点棘手，因为每个字典值都是一个单元素列表（这样设计是为了与`st.data_editor`兼容）。`get_setting`抽象出这种有些不美观的逻辑，所以我们将其限制在代码的一个地方。
- en: '`modify_settings` replaces `self.settings` with a given `new_settings` dictionary.
    This will come into play when the user changes a setting.'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: '`modify_settings`用给定的`new_settings`字典替换`self.settings`。当用户更改设置时，这将会发挥作用。'
- en: Turning to the `ask_llm_for_question` method, we replace the `{quizmaster}`
    and `{difficulty}` variables we added to the prompt with their corresponding values
    from the settings, obtained through `get_setting`.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 转到`ask_llm_for_question`方法，我们将添加到提示中的`{quizmaster}`和`{difficulty}`变量替换为通过`get_setting`获取的设置中的相应值。
- en: 'The changes to `main.py` are all that remain now, so let''s make those:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 现在只剩下对`main.py`的修改，让我们进行这些修改：
- en: '[PRE50]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: (`chapter_09/in_progress_06/main.py` in the GitHub repo)
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: （GitHub仓库中的`chapter_09/in_progress_06/main.py`）
- en: In `start_new_game`, to obtain the initial `Game` instance, we now pass in `default_settings`,
    directly imported from `settings.py`.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 在`start_new_game`中，为了获取初始的`Game`实例，我们现在直接从`settings.py`导入`default_settings`。
- en: The actual settings editor is displayed within the side column (`side_col`),
    right above the New Game button. The return value—recall that this would be the
    `default_settings` dictionary before the user changes the value of any settings,
    and the modified dictionary afterward—is stored in the `settings` variable.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 实际设置编辑器显示在侧列（`side_col`）中，位于新游戏按钮上方。返回值——回想一下，在用户更改任何设置的值之前，这将是一个`default_settings`字典，之后是修改后的字典——存储在`settings`变量中。
- en: And, finally, in every re-run—provided that we're in a game—we run `game.modify_settings(settings)`
    to pick up any changes the user has made to the settings.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在每次重新运行时——前提是我们处于游戏状态——我们运行`game.modify_settings(settings)`来获取用户对设置所做的任何更改。
- en: That should do it. Run your app again to see figure 9.15\. Play around with
    the AI quizmaster options and difficulties; it's now more fun to read the questions!
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就完成了。再次运行你的应用以查看图9.15。尝试调整AI问答大师选项和难度；现在阅读问题更有趣了！
- en: '![image](../Images/09__image015.png)'
  id: totrans-472
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/09__image015.png)'
- en: Figure 9.15 A final version of Fact Frenzy with editable settings (see chapter_09/in_progress_06
    in the GitHub repo for the full code)
  id: totrans-473
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.15 Fact Frenzy的最终版本，带有可编辑的设置（完整代码请参阅GitHub仓库中的chapter_09/in_progress_06）
- en: 'That concludes our development of Fact Frenzy, the first—and only—game we''ll
    build in this book. In Chapter 10, we''ll continue our exploration of AI apps
    with a more practical application: a customer support chatbot.'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对Fact Frenzy的开发，这是我们将在本书中构建的第一个——也是唯一一个——游戏。在第10章中，我们将继续探索AI应用，使用一个更实用的应用：客户支持聊天机器人。
- en: 9.8 Summary
  id: totrans-475
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.8 摘要
- en: A Large Language Model (LLM) is an AI system designed to process and generate
    human-like text.
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）是一种设计用于处理和生成类似人类文本的AI系统。
- en: LLMs can perform both creative and analytical tasks.
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM可以执行创造性和分析性任务。
- en: OpenAI, one of the most popular LLM providers, allows developers to access its
    GPT series through an API.
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI，最受欢迎的LLM提供商之一，允许开发者通过API访问其GPT系列。
- en: The `openai` library provides a convenient way to call the OpenAI API in Python.
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai`库提供了一种方便的方法，在Python中调用OpenAI API。'
- en: You can pass a conversation to OpenAI API's chat completion endpoint with messages
    tagged as `"system"`, `"assistant"` or `"user"`, causing the model to complete
    the conversation in a logical way.
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将对话传递给OpenAI API的聊天完成端点，消息标记为`"system"`、`"assistant"`或`"user"`，这将导致模型以逻辑方式完成对话。
- en: Structured Outputs is a feature provided by OpenAI that ensures the model will
    generate a response that adheres to a given schema.
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化输出是OpenAI提供的一项功能，确保模型将生成符合给定模式的响应。
- en: A common pattern in linear Streamlit apps is to implement conditional branching
    logic based on a variable that's held in `st.session_state`.
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性Streamlit应用中的常见模式是基于存储在`st.session_state`中的变量实现基于条件的分支逻辑。
- en: You can vary parameters such as `temperature` and `top_p` to affect the creativity
    and predictability of responses generated by an LLM.
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以调整`temperature`和`top_p`等参数来影响由LLM生成的响应的创造性和可预测性。
- en: Injecting randomness into the prompt is a good way to ensure we get different
    responses to similar prompts.
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在提示中注入随机性是确保我们得到不同响应的相似提示的好方法。
- en: It's important to optimize cost in LLM-based applications. You can do this by
    having the LLM process fewer input and output tokens, reducing the number of prompts,
    using cheaper models, or even having users bear the cost by requiring them to
    supply their own API key.
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在基于LLM的应用中优化成本很重要。你可以通过让LLM处理更少的输入和输出标记、减少提示数量、使用更便宜的模型，甚至通过要求用户提供自己的API密钥来让用户承担成本来实现。
- en: '`st.data_editor` provides a way to create editable tables in Streamlit apps.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`st.data_editor`提供了一种在Streamlit应用中创建可编辑表格的方法。'
- en: '`st.column_config` lets you configure columns to be of certain editable and
    non-editable types in `st.data_editor` and `st.dataframe`.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`st.column_config`允许你在`st.data_editor`和`st.dataframe`中配置列，使其成为特定可编辑和非可编辑类型。'
- en: '`st.popover` displays a small pop-up screen triggered by a click on an associated
    button.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`st.popover`通过点击相关按钮显示一个小弹出屏幕。'
