- en: 'Chapter 9\. Capstone: R for Data Analytics'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ll apply what we’ve learned about data analysis and visualization
    in R to explore and test relationships in the familiar *mpg* dataset. You’ll learn
    a couple of new R techniques here, including how to conduct a t-test and linear
    regression. We’ll begin by calling up the necessary packages, reading in *mpg.csv*
    from the *mpg* subfolder of the book repository’s *datasets* folder, and selecting
    the columns of interest. We’ve not used `tidymodels` so far in this book, so you
    may need to install it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Exploratory Data Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Descriptive statistics are a good place to start when exploring data. We’ll
    do so with the `describe()` function from `psych`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Because *origin* is a categorical variable, we should be careful to interpret
    its descriptive statistics. (In fact, `psych` uses `*` to signal this warning.)
    We are, however, safe to analyze its one-way frequency table, which we’ll do using
    a new `dplyr` function, `count()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We learn from the resulting count column *n* that while the majority of observations
    are American cars, the observations of Asian and European cars are still likely
    to be representative samples of their subpopulations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s further break these counts down by `cylinders` to derive a two-way frequency
    table. I will combine `count()` with `pivot_wider()` to display `cylinders` along
    the columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Remember that `NA` indicates a missing value in R, in this case because no observations
    were found for some of these cross-sections.
  prefs: []
  type: TYPE_NORMAL
- en: Not many cars have three- or five-cylinder engines, and *only* American cars
    have eight cylinders. It’s common when analyzing data to have *imbalanced* datasets
    where there is a disproportionate number of observations in some levels. Special
    techniques are often needed to model such data. To learn more about working with
    imbalanced data, check out [*Practical Statistics for Data Scientists*](https://oreil.ly/jv8RS),
    2nd edition by Peter Bruce et al. (O’Reilly).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also find the descriptive statistics for each level of *origin*. First,
    we’ll use `select()` to choose the variables of interest, then we can use `psych`’s
    `describeBy()` function, setting `groupBy` to `origin`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s learn more about the potential relationship between *origin* and *mpg*.
    We’ll get started by visualizing the distribution of *mpg* with a histogram, which
    is shown in [Figure 9-1](#mpg-hist):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Histogram](assets/aina_0901.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-1\. Distribution of *mpg*
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can now hone in on visualizing the distribution of *mpg* by *origin*. Overlaying
    all three levels of *origin* on one histogram could get cluttered, so a boxplot
    like what’s shown in [Figure 9-2](#mpg-box) may be a better fit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![Boxplot](assets/aina_0902.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-2\. Distribution of *mpg* by *origin*
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If we’d rather visualize these as histograms, and not make a mess, we can do
    so in R with a *facet* plot. Use `facet_wrap()` to split the `ggplot2` plot into
    subplots, or *facets*. We’ll start with a `~`, or tilde operator, followed by
    the variable name. When you see the tilde used in R, think of it as the word “by.”
    For example, here we are faceting a histogram by `origin`, which results in the
    histograms shown in [Figure 9-3](#mpg-facet):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![Faceted histogram](assets/aina_0903.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-3\. Distribution of *mpg* by *origin*
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Hypothesis Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You could continue to explore the data using these methods, but let’s move into
    hypothesis testing. In particular, I would like to know whether there is a significant
    difference in mileage between American and European cars. Let’s create a new data
    frame containing just these observations; we’ll use it to conduct a t-test.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Independent Samples t-test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'R includes a `t.test()` function out of the box: we need to specify where our
    data comes from with the `data` argument, and we’ll also need to specify what
    *formula* to test. To do that, we’ll set the relationship between independent
    and dependent variables with the `~` operator. The dependent variable comes in
    front of the `~`, with independent variables following. Again, you interpret this
    notation as analyzing the effect of `mpg` “by” `origin`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Isn’t it great that R even explicitly states what our alternative hypothesis
    is, *and* includes the confidence interval along with the p-value? (You can tell
    this program was built for statistical analysis.) Based on the p-value, we will
    reject the null; there does appear to be evidence of a difference in means.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now turn our attention to relationships between continuous variables.
    First, we’ll use the `cor()` function from base R to print a correlation matrix.
    We’ll do this only for the continuous variables in *mpg*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use `ggplot2` to visualize, for example, the relationship between weight
    and mileage, as in [Figure 9-4](#mpg-scatter):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![Scatterplot](assets/aina_0904.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-4\. Scatterplot of *weight* by *mpg*
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Alternatively, we could use the `pairs()` function from base R to produce a
    pairplot of all combinations of variables, laid out similarly to a correlation
    matrix. [Figure 9-5](#pairplot) is a pairplot of selected variables from *mpg*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![Pairplot](assets/aina_0905.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-5\. Pairplot
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Linear Regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’re ready now for linear regression, using base R’s `lm()` function (this
    is short for *linear model*). Similar to `t.test()`, we will specify a dataset
    and a formula. Linear regression returns a fair amount more output than a t-test,
    so it’s common to assign the results to a new object in R first, then explore
    its various elements separately. In particular, the `summary()` function provides
    a helpful overview of the regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This output should look familiar. Here you’ll see the coefficients, p-values,
    and R-squared, among other figures. Again, there does appear to be a significant
    influence of weight on mileage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Last but not least, we can fit this regression line over the scatterplot by
    including `geom_smooth()` in our `ggplot()` function, setting `method` to `lm`.
    This results in [Figure 9-6](#mpg-fit-scatter):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![Fit scatterplot](assets/aina_0906.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-6\. Scatterplot with fit regression line of *weight* by *mpg*
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Train/Test Split and Validation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Chapter 5](ch05.html#data-analytics-stack) briefly reviewed how machine learning
    relates to working with data more broadly. A technique popularized by machine
    learning that you may encounter in your data analytics work is the *train/test
    split*. The idea here is to *train* the model on a subset of your data, then *test*
    it on another subset. This provides assurance that the model doesn’t just work
    on one particular sampling of observations, but can generalize to the wider population.
    Data scientists are often especially interested in how well the model does at
    making predictions on the testing data.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s split our *mpg* dataset in R, train the linear regression model on part
    of the data, and then test it on the remainder. To do so, we’ll use the `tidymodels`
    package. While not part of the `tidyverse`, this package is built along the same
    principles and thus works well with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may remember in [Chapter 2](ch02.html#foundations-of-probability) that,
    because we were using random numbers, the results you saw in your workbook were
    different than what was documented in the book. Because we’ll again be splitting
    our dataset randomly here, we could encounter that same problem. To avoid that,
    we can set the *seed* of R’s random number generator, which results in the same
    series of random numbers being generated each time. This can be done with the
    `set.seed()` function. You can set it to any number; `1234` is common:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: To begin the split, we can use the aptly named `initial_split()` function; from
    there, we’ll subset our data into training and testing datasets with the `training()`
    and `testing()` functions, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, `tidymodels` splits the data’s observations into two groups at
    random: 75% of the observations went to the training group, the remainder to the
    test. We can confirm that with the `dim()` function from base R to get the number
    of rows and columns in each dataset, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: At 294 and 98 observations, our training and testing sample sizes should be
    sufficiently large for reflective statistical inference. While it’s not often
    a consideration for the massive datasets used in machine learning, adequate sample
    size can be a limitation when splitting data.
  prefs: []
  type: TYPE_NORMAL
- en: It’s possible to split the data into other proportions than 75/25, to use special
    techniques for splitting the data, and so forth. For more information, check the
    `tidymodels` documentation; until you become more comfortable with regression
    analysis, the defaults are fine.
  prefs: []
  type: TYPE_NORMAL
- en: To build our training model, we’ll first *specify* what type of model it is
    with the `linear_reg()` function, then *fit* it. The inputs of the `fit()` function
    should look familiar to you, except this time we are using the training subset
    of *mpg* only.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: You will see from your console output that the `lm()` function from base R,
    which you’ve used before, was used as the *engine* to fit the model.
  prefs: []
  type: TYPE_NORMAL
- en: We can get the coefficients and p-values of our training model with the `tidy()`
    function, and its performance metrics (such as R-squared) with `glance()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This is great, but what we *really* want to know is how well this model performs
    when we apply it to a new dataset; this is where the test split comes in. To make
    predictions on `mpg_test`, we’ll use the `predict()` function. I will also use
    `bind_cols()` to add the column of predicted Y-values to the data frame. This
    column by default will be called `.pred`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now that we’ve applied the model to this new data, let’s evaluate its performance.
    We can, for example, find its R-squared with the `rsq()` function. From our `mpg_results`
    data frame, we’ll need to specify which column contains the actual Y values with
    the `truth` argument, and which are predictions with the `estimate` column.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: At an R-squared of 60.6%, the model derived from the training dataset explains
    a fair amount of variability in the testing data.
  prefs: []
  type: TYPE_NORMAL
- en: Another common evaluation metric is the root mean square error (RMSE). You learned
    about the concept of *residuals* in [Chapter 4](ch04.html#foundations-of-data-analytics)
    as the difference between actual and predicted values; RMSE is the standard deviation
    of the residuals and thus an estimate of how spread errors tend to be. The `rmse()`
    function returns the RMSE.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Because it’s relative to the scale of the dependent variable, there’s no one-size-fits-all
    way to evaluate RMSE, but between two competing models using the same data, a
    smaller RMSE is preferred.
  prefs: []
  type: TYPE_NORMAL
- en: '`tidymodels` makes numerous techniques available for fitting and evaluating
    models in R. We’ve looked at a regression model, which takes a continuous dependent
    variable, but it’s also possible to build *classification* models, where the dependent
    variable is categorical. This package is a relative newcomer to R, so there is
    somewhat less literature available, but expect more to come as the package grows
    in popularity.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is, of course, much more you could do to explore and test the relationships
    in this and other datasets, but the steps we’ve taken here serve as a solid opening.
    Earlier, you were able to conduct and interpret this work in Excel, and now you’ve
    leaped into doing it in R.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Take a moment to try your hand at analyzing a familiar dataset with familiar
    steps, now using R. At the end of [Chapter 4](ch04.html#foundations-of-data-analytics),
    you practiced analyzing data from the `ais` dataset in the [book repository](https://oreil.ly/egOx1).
    This data is available in the R package `DAAG`; try installing and loading it
    from there (it is available as the object `ais`). Do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Visualize the distribution of red blood cell count (*rcc*) by sex (*sex*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is there a significant difference in red blood cell count between the two groups
    of sex?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Produce a correlation matrix of the relevant variables in this dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Visualize the relationship of height (*ht*) and weight (*wt*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Regress *ht* on *wt*. Find the equation of the fit regression line. Is there
    a significant relationship? What percentage of the variance in *ht* is explained
    by *wt*?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Split your regression model into training and testing subsets. What is the R-squared
    and RMSE on your test model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
