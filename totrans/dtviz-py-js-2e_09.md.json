["```py\n{\n  \"category\": \"Physiology or Medicine\",\n  \"country\": \"Argentina\",\n  \"date_of_birth': \"8 October 1927\",\n  \"date_of_death': \"24 March 2002\",\n  \"gender\": \"male\",\n  \"link\": \"http:\\/\\/en.wikipedia.org\\/wiki\\/C%C3%A9sar_Milstein\",\n  \"name\": \"C\\u00e9sar Milstein\",\n  \"place_of_birth\": \"Bah\\u00eda Blanca ,  Argentina\",\n  \"place_of_death\": \"Cambridge , England\",\n  \"text\": \"C\\u00e9sar Milstein , Physiology or Medicine, 1984\",\n  \"year\": 1984\n}\n```", "```py\n$ conda install -c https://conda.anaconda.org/anaconda scrapy\n```", "```py\n$ pip install scrapy\n```", "```py\n$ scrapy startproject nobel_winners\nNew Scrapy project 'nobel_winners' created in:\n    /home/kyran/workspace/.../scrapy/nobel_winners\n\nYou can start your first spider with:\n    cd nobel_winners\n    scrapy genspider example example.com\n```", "```py\nnobel_winners\n├── nobel_winners\n│   ├── __init__.py\n│   ├── items.py\n│   ├── middlewares.py\n│   ├── pipelines.py\n│   ├── settings.py\n│   └── spiders\n│       └── __init__.py\n└── scrapy.cfg\n```", "```py\n//*[@id=\"mw-content-text\"]/div[1]/h3[1]\n```", "```py\n<div id=\"mw-content-text\">\n  <div>\n    <h2>\n        ...\n    </h2>\n  </div>\n    ...\n</div>\n```", "```py\n$ scrapy shell\n  https://en.wikipedia.org/wiki/List_of_Nobel_laureates_by_country\n\n2021-12-09 14:31:06 [scrapy.utils.log] INFO: Scrapy 2.5.1 started\n(bot: nobel_winners)\n...\n\n2021-12-09 14:31:07 [scrapy.core.engine] INFO: Spider opened\n2021-12-09 14:31:07 [scrapy.core.engine] DEBUG: Crawled (200)\n<GET https://en.wikip...List_of_Nobel_laureates_by_country>\n(referer: None)\n[s] Available Scrapy objects:\n\n[s]   crawler  <scrapy.crawler.Crawler object at 0x3a8f510>\n[s]   item {}\n[s]   request    <GET https://...Nobel_laureates_by_country>\n[s]   response   <200 https://...Nobel_laureates_by_country>\n[s]   settings   <scrapy.settings.Settings object at 0x34a98d0>\n[s]   spider     <DefaultSpider 'default' at 0x3f59190>\n\n[s] Useful shortcuts:\n[s]   shelp()   Shell help (print this help)\n[s]   fetch(url[, redirect=True]) Fetch URL and update local objects\n(by default, redirects are followed)\n[s]   fetch(req)                  Fetch a scrapy.Request and update\n[s]   view(response)    View response in a browser\n\nIn [1]:\n```", "```py\nIn [1]: h3s = response.xpath('//h3')\n```", "```py\nIn [2]: len(h3s)\nOut[2]: 91\n```", "```py\nIn [3] h3 = h3s[0]\nIn [4] h3.\nattrib             get                re                 remove             ...\ncss                getall             re_first           remove_namespaces  ...\nextract            namespaces         register_namespace response           ...\n```", "```py\nIn [5]: h3.extract()\nOut[6]:\nu'<h3>\n  <span class=\"mw-headline\" id=\"Argentina\">Argentina</span>\n  <span class=\"mw-editsection\">\n  <span class=\"mw-editsection-bracket\">\n  ...\n  </h3>'\n```", "```py\nIn [7]: h3_arg = h3\nIn [8]: country = h3_arg.xpath(\\\n                         'span[@class=\"mw-headline\"]/text()')\\\n.extract()\nIn [9]: country\nOut[9]: ['Argentina']\n```", "```py\nIn [10]: ol_arg = h3_arg.xpath('following-sibling::ol[1]')\nOut[10]: ol_arg\n[<Selector xpath='following-sibling::ol[1]' data=u'<ol><li>\n<a href=\"/wiki/C%C3%A9sar_Milst'>]\n```", "```py\nIn [11]: ol_arg = h2_arg.xpath('following-sibling::ol[1]')[0]\n```", "```py\nIn [12]: lis_arg = ol_arg.xpath('li')\nIn [13]: len(lis_arg)\nOut[13]: 5\n```", "```py\nIn [14]: li = lis_arg[0] # select the first list element\nIn [15]: li.extract()\nOut[15]:\n'<li><a href=\"/wiki/C%C3%A9sar_Milstein\"\n         title=\"C\\xe9sar Milstein\">C\\xe9sar Milstein</a>,\n         Physiology or Medicine, 1984</li>'\n```", "```py\nIn [16]: name = li.xpath('a//text()')[0].extract()\nIn [17]: name\nOut[17]: 'César Milstein'\n```", "```py\nIn [18]: list_text = li.xpath('descendant-or-self::text()')\\\n.extract()\nIn [19]: list_text\nOut[19]: ['César Milstein', '*, Physiology or Medicine, 1984']\n```", "```py\nIn [20]: ' '.join(list_text)\nOut[20]: 'César Milstein *, Physiology or Medicine, 1984'\n```", "```py\n<div id='toc'... >\n  ...\n   <ul ... >\n     <li ... >\n       <a href='Argentina'> ... </a>\n     </li>\n     ...\n   </ul>\n  ...\n</div>\n```", "```py\nIn [21]: toc = response.xpath('//div[@id=\"toc\"]')[0]\n```", "```py\nIn [22]: lis = toc.xpath('.//ul/li[2]/ul/li')\nIn [23]: lis = toc.xpath('ul/li[2]/ul/li')\nIn [24]: len(lis)\nOut[24]: 81 # the number of countries in the table of contents (July 2022)\n```", "```py\nIn [25]: lis = toc.xpath('//ul/li')\nIn [26]: len(lis)\nOUt[26]: 271\n```", "```py\n.\n├── nobel_winners\n│   ├── __init__.py\n│   ├── items.py\n│   ├── middlewares.py\n│   ├── pipelines.py\n│   ├── settings.py\n│   └── spiders\n│       |── __init__.py\n│       └── nwinners_list_spider.py <---\n└── scrapy.cfg\n```", "```py\n# nwinners_list_spider.py\n\nimport scrapy\nimport re\n# A. Define the data to be scraped\nclass NWinnerItem(scrapy.Item):\n    country = scrapy.Field()\n    name = scrapy.Field()\n    link_text = scrapy.Field()\n\n# B Create a named spider\nclass NWinnerSpider(scrapy.Spider):\n    \"\"\" Scrapes the country and link text of the Nobel-winners. \"\"\"\n\n    name = 'nwinners_list'\n    allowed_domains = ['en.wikipedia.org']\n    start_urls = [\n        \"http://en.wikipedia.org ... of_Nobel_laureates_by_country\"\n    ]\n    # C A parse method to deal with the HTTP response\n    def parse(self, response):\n\n         h3s = response.xpath('//h3') ![1](assets/1.png)\n\n         for h3 in h3s:\n            country = h3.xpath('span[@class=\"mw-headline\"]'\\\n            'text()').extract() ![2](assets/2.png)\n            if country:\n                winners = h2.xpath('following-sibling::ol[1]') ![3](assets/3.png)\n                for w in winners.xpath('li'):\n                    text = w.xpath('descendant-or-self::text()')\\\n                    .extract()\n                    yield NWinnerItem(\n                        country=country[0], name=text[0],\n                        link_text = ' '.join(text)\n                        )\n```", "```py\n$ scrapy list\nnwinners_list\n```", "```py\n$ scrapy crawl nwinners_list -o nobel_winners.json\n2021- ... [scrapy] INFO: Scrapy started (bot: nobel_winners)\n...\n2021- ... [nwinners_list] INFO: Closing spider (finished)\n2021- ... [nwinners_list] INFO: Dumping Scrapy stats:\n        {'downloader/request_bytes': 1147,\n         'downloader/request_count': 4,\n         'downloader/request_method_count/GET': 4,\n         'downloader/response_bytes': 66459,\n         ...\n         'item_scraped_count': 1169, ![1](assets/1.png)\n2021- ...  [scrapy.core.engine] INFO: Spider closed (finished)\n```", "```py\n$ head nobel_winners.json\n[{\"country\": \"Argentina\",\n  \"link_text\": \"C\\u00e9sar Milstein , Physiology or Medicine,\"\\\n  \" 1984\",\n  \"name\": \"C\\u00e9sar Milstein\"},\n {\"country\": \"Argentina\",\n  \"link_text\": \"Adolfo P\\u00e9rez Esquivel , Peace, 1980\",\n  \"name\": \"Adolfo P\\u00e9rez Esquivel\"},\n  ...\n```", "```py\n...\nclass NWinnerItem(scrapy.Item):\n    name = scrapy.Field()\n    link = scrapy.Field()\n    year = scrapy.Field()\n    category = scrapy.Field()\n    country = scrapy.Field()\n    gender = scrapy.Field()\n    born_in = scrapy.Field()\n    date_of_birth = scrapy.Field()\n    date_of_death = scrapy.Field()\n    place_of_birth = scrapy.Field()\n    place_of_death = scrapy.Field()\n    text = scrapy.Field()\n...\n```", "```py\n...\n\ndef parse(self, response):\n\n    h3s = response.xpath('//h3')\n\n    for h3 in h3s:\n        country = h3.xpath('span[@class=\"mw-headline\"]/text()')\\\n        .extract()\n        if country:\n            winners = h3.xpath('following-sibling::ol[1]')\n            for w in winners.xpath('li'):\n                wdata = process_winner_li(w, country[0])\n                ...\n```", "```py\n# ...\nimport re\nBASE_URL = 'http://en.wikipedia.org'\n# ...\n\ndef process_winner_li(w, country=None):\n    \"\"\"\n    Process a winner's <li> tag, adding country of birth or\n    nationality, as applicable.\n    \"\"\"\n    wdata = {}\n    # get the href link-address from the <a> tag\n    wdata['link'] = BASE_URL + w.xpath('a/@href').extract()[0] ![1](assets/1.png)\n\n    text = ' '.join(w.xpath('descendant-or-self::text()')\\\n         .extract())\n    # get comma-delineated name and strip trailing whitespace\n    wdata['name'] = text.split(',')[0].strip()\n\n    year = re.findall('\\d{4}', text) ![2](assets/2.png)\n    if year:\n        wdata['year'] = int(year[0])\n    else:\n        wdata['year'] = 0\n        print('Oops, no year in ', text)\n\n    category = re.findall(\n            'Physics|Chemistry|Physiology or Medicine|Literature|'\\\n            'Peace|Economics',\n                text) ![3](assets/3.png)\n    if category:\n        wdata['category'] = category[0]\n    else:\n        wdata['category'] = ''\n        print('Oops, no category in ', text)\n\n    if country:\n         if text.find('*') != -1: ![4](assets/4.png)\n             wdata['country'] = ''\n             wdata['born_in'] = country\n         else:\n             wdata['country'] = country\n             wdata['born_in'] = ''\n\n    # store a copy of the link's text-string for any manual corrections\n    wdata['text'] = text\n    return wdata\n```", "```py\n# -*- coding: utf-8 -*-\n\n# Scrapy settings for nobel_winners project\n#\n# This file contains only the most important settings by\n# default. All the other settings are documented here:\n#\n#     http://doc.scrapy.org/en/latest/topics/settings.xhtml\n#\n\nBOT_NAME = 'nobel_winners'\n\nSPIDER_MODULES = ['nobel_winners.spiders']\nNEWSPIDER_MODULE = 'nobel_winners.spiders'\n\n# Crawl responsibly by identifying yourself\n# (and your website) on the user-agent\n#USER_AGENT = 'nobel_winners (+http://www.yourdomain.com)'\n\nHTTPCACHE_ENABLED = True\n```", "```py\nclass NWinnerSpider(scrapy.Spider):\n    name = 'nwinners_full'\n    allowed_domains = ['en.wikipedia.org']\n    start_urls = [\n        \"https://en.wikipedia.org/wiki/List_of_Nobel_laureates\" \\\n        \"_by_country\"\n    ]\n\n    def parse(self, response):\n\n        h3s = response.xpath('//h3')\n        for h3 in h3s:\n            country = h3.xpath('span[@class=\"mw-headline\"]/text()')\n                      .extract()\n            if country:\n                winners = h2.xpath('following-sibling::ol[1]')\n                for w in winners.xpath('li'):\n                    wdata = process_winner_li(w, country[0])\n                    request = scrapy.Request( ![1](assets/1.png)\n                        wdata['link'],\n                        callback=self.parse_bio, ![2](assets/2.png)\n                        dont_filter=True)\n                    request.meta['item'] = NWinnerItem(**wdata) ![3](assets/3.png)\n                    yield request ![4](assets/4.png)\n\n    def parse_bio(self, response):\n        item = response.meta['item'] ![5](assets/5.png)\n        ...\n```", "```py\n# ...\n\n    def parse_bio(self, response):\n\n        item = response.meta['item']\n        href = response.xpath(\"//li[@id='t-wikibase']/a/@href\") ![1](assets/1.png)\n               .extract()\n        if href:\n            url = href[0] ![2](assets/2.png)\n            wiki_code = url.split('/')[-1]\n            request = scrapy.Request(href[0],\\\n                          callback=self.parse_wikidata,\\ ![3](assets/3.png)\n                          dont_filter=True)\n            request.meta['item'] = item\n            yield request\n\n    def parse_wikidata(self, response):\n\n        item = response.meta['item']\n        property_codes = [ ![4](assets/4.png)\n            {'name':'date_of_birth', 'code':'P569'},\n            {'name':'date_of_death', 'code':'P570'},\n            {'name':'place_of_birth', 'code':'P19', 'link':True},\n            {'name':'place_of_death', 'code':'P20', 'link':True},\n            {'name':'gender', 'code':'P21', 'link':True}\n          ]\n\n        for prop in property_codes:\n\n            link_html = ''\n            if prop.get('link'):\n                link_html = '/a'\n            # select the div with a property-code id\n            code_block = response.xpath('//*[@id=\"%s\"]'%(prop['code']))\n            # continue if the code_block exists\n            if code_block:\n            # We can use the css selector, which has superior class\n            # selection\n                values = code_block.css('.wikibase-snakview-value')\n            # the first value corresponds to the code property\\\n            # (e.g., '10 August 1879')\n                value = values[0]\n                prop_sel = value.xpath('.%s/text()'%link_html)\n                if prop_sel:\n                    item[prop['name']] = prop_sel[0].extract()\n\n        yield item ![5](assets/5.png)\n```", "```py\n$ scrapy crawl nwinners_full\n2021-... [scrapy] ... started (bot: nobel_winners)\n...\n2021-... [nwinners_full] DEBUG: Scraped from\n         <200 https://www.wikidata.org/wiki/Q155525>\n  {'born_in': '',\n   'category': u'Physiology or Medicine',\n   'date_of_birth': u'8 October 1927',\n   'date_of_death': u'24 March 2002',\n   'gender': u'male',\n   'link': u'http://en.wikipedia.org/wiki/C%C3%A9sar_Milstein',\n   'name': u'C\\xe9sar Milstein',\n   'country': u'Argentina',\n   'place_of_birth': u'Bah\\xeda Blanca',\n   'place_of_death': u'Cambridge',\n   'text': u'C\\xe9sar Milstein , Physiology or Medicine, 1984',\n   'year': 1984}\n2021-... [nwinners_full] DEBUG: Scraped from\n         <200 https://www.wikidata.org/wiki/Q193672>\n {'born_in': '',\n  'category': u'Peace',\n  'date_of_birth': u'1 November 1878',\n  'date_of_death': u'5 May 1959',\n  'gender': u'male',\n  'link': u'http://en.wikipedia.org/wiki/Carlos_Saavedra_Lamas',\n  ...\n```", "```py\n# nobel_winners/nobel_winners/pipelines.py\n\n# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.xhtml\n\nfrom scrapy.exceptions import DropItem\n\nclass DropNonPersons(object):\n    \"\"\" Remove non-person winners \"\"\"\n\n    def process_item(self, item, spider):\n        if not item['gender']:               ![1](assets/1.png)\n            raise DropItem(\"No gender for %s\"%item['name'])\n        return item ![2](assets/2.png)\n```", "```py\n# nobel_winners/nobel_winners/settings.py\n\nBOT_NAME = 'nobel_winners'\nSPIDER_MODULES = ['nobel_winners.spiders']\nNEWSPIDER_MODULE = 'nobel_winners.spiders'\n\nHTTPCACHE_ENABLED = True\nITEM_PIPELINES = {'nobel_winners.pipelines.DropNonPersons':300}\n```", "```py\n<div id=\"mw-content-text\">\n  <div class=\"mw-parser-output\">\n    ...\n    <table class=\"infobox biography vcard\">...</table>\n    /* target paragraphs: */\n    <p>...</p>\n    <p>...</p>\n    <p>...</p>\n    <div id=\"toc\">...</div>\n  ...\n  </div>\n</div>\n```", "```py\n  ps = response.xpath(\\\n    '//*[@id=\"mw-content-text\"]/div/table/following-sibling::p' ![1](assets/1.png)\n    '[not(preceding-sibling::div[@id=\"toc\"])]').extract() ![2](assets/2.png)\n```", "```py\n<table class=\"infobox biography vcard\">\n  ...\n        <img alt=\"Francis Crick crop.jpg\" src=\"//upload...\" />\n  ...\n</table>\n```", "```py\nimport scrapy\nimport re\n\nBASE_URL = 'http://en.wikipedia.org'\n\nclass NWinnerItemBio(scrapy.Item):\n    link = scrapy.Field()\n    name = scrapy.Field()\n    mini_bio = scrapy.Field()\n    image_urls = scrapy.Field()\n    bio_image = scrapy.Field()\n    images = scrapy.Field()\n...\n```", "```py\nclass NWinnerSpiderBio(scrapy.Spider):\n\n    name = 'nwinners_minibio'\n    allowed_domains = ['en.wikipedia.org']\n    start_urls = [\n        \"https://en.wikipedia.org/wiki/List_of_Nobel_\" \\\n        \"laureates_by_country\"\n    ]\n\n    def parse(self, response):\n\n        filename = response.url.split('/')[-1]\n        h3s = response.xpath('//h3')\n\n        for h3 in h3s:\n            country = h3.xpath('span[@class=\"mw-headline\"]'\\\n            'text()').extract()\n            if country:\n                winners = h3.xpath('following-sibling::ol[1]')\n                for w in winners.xpath('li'):\n                    wdata = {}\n                    wdata['link'] = BASE_URL + \\\n                    w.xpath('a/@href').extract()[0]\n                    # Process the winner's bio page with\n                    # the get_mini_bio method\n                    request = scrapy.Request(wdata['link'],\n                                  callback=self.get_mini_bio)\n                    request.meta['item'] = NWinnerItemBio(**wdata)\n                    yield request\n```", "```py\n...\n    def get_mini_bio(self, response):\n        \"\"\" Get the winner's bio text and photo \"\"\"\n\n        BASE_URL_ESCAPED = 'http:\\/\\/en.wikipedia.org'\n        item = response.meta['item']\n        item['image_urls'] = []\n        img_src = response.xpath(\\\n            '//table[contains(@class,\"infobox\")]//img/@src') ![1](assets/1.png)\n        if img_src:\n            item['image_urls'] = ['http:' +\\\n             img_src[0].extract()]\n\n        ps = response.xpath(\n            '//*[@id=\"mw-content-text\"]/div/table/'\n            'following-sibling::p[not(preceding-sibling::div[@id=\"toc\"])]')\\\n            .extract() ![2](assets/2.png)\n        # Concatenate the biography paragraphs for a mini_bio string\n        mini_bio = ''\n        for p in ps:\n            mini_bio += p\n        # correct for wiki-links\n        mini_bio = mini_bio.replace('href=\"/wiki', 'href=\"'\n                       + BASE_URL + '/wiki\"') ![3](assets/3.png)\n        mini_bio = mini_bio.replace('href=\"#',\\\n         'href=\"' + item['link'] + '#\"')\n        item['mini_bio'] = mini_bio\n        yield item\n```", "```py\nimport scrapy\nfrom itemadapter import ItemAdapter\nfrom scrapy.pipelines.images import ImagesPipeline\nfrom scrapy.exceptions import DropItem\n\nclass NobelImagesPipeline(ImagesPipeline):\n\n    def get_media_requests(self, item, info): ![1](assets/1.png)\n\n        for image_url in item['image_urls']:\n            yield scrapy.Request(image_url)\n\n    def item_completed(self, results, item, info): ![2](assets/2.png)\n\n        image_paths = [img['path'] for ok, img in results if ok] ![3](assets/3.png)\n\n        if not image_paths:\n            raise DropItem(\"Item contains no images\")\n        adapter = ItemAdapter(item) ![4](assets/4.png)\n        adapter['bio_image'] = image_paths[0]\n\n        return item\n```", "```py\n# nobel_winners/nobel_winners/settings.py\n\n...\nITEM_PIPELINES = {'nobel_winners.pipelines'\\\n                  '.NobelImagesPipeline':300}\nIMAGES_STORE = 'images'\n```", "```py\n$ scrapy crawl nwinners_minibio -o minibios.json\n...\n2021-12-13 17:18:05 [scrapy.core.scraper] DEBUG: Scraped from\n    <200 https://en.wikipedia.org/wiki/C%C3%A9sar_Milstein>\n\n{'bio_image': 'full/65ac9541c305ab4728ed889385d422a2321a117d.jpg',\n 'image_urls': ['http://upload.wikimedia...\n 150px-Milstein_lnp_restauraci%C3%B3n.jpg'],\n 'link': 'http://en.wikipedia.org/wiki/C%C3%A9sar_Milstein',\n 'mini_bio': '<p><b>César Milstein</b>, <a ...'\n             'href=\"http://en.wikipedia.org/wiki/Order_of_the_...'\n             'title=\"Order of the Companions of Honour\">CH</a>'\n             'href=\"http://en.wikipedia.org/wiki/Royal_Society'\n             'Society\">FRS</a><sup id=\"cite_ref-frs_2-1\" class'...>\n             'href=\"http://en.wikipedia.org/wiki/C%C3%A9sar_Mi'\n             '(8 October 1927 – 24 March 2002) was an <a ...>'\n             'href=\"http://en.wikipedia.org/wiki/Argentine\" '\n\n...\n```", "```py\n$ (nobel_winners) tree images\nimages\n└── full\n    ├── 0512ae11141584da1262661992a1b05dfb20dd52.jpg\n    ├── 092a92689118c16b15b1613751af422439df2850.jpg\n    ├── 0b6a8ca56e6ff115b7d30087df9c21da09684db1.jpg\n    ├── 1197aa95299a1fec983b3dbdeaeb97a1f7e545c9.jpg\n    ├── 1f6fb8e9e2241733da47328291b25bd1a78fa588.jpg\n    ├── 272cf1b089c7a28ea0109ad8655bc3ef1c03fb52.jpg\n    ├── 28dcc7978d9d5710f0c29d6dfcf09caa7e13a1d0.jpg\n    ...\n```", "```py\nclass NWinnerSpiderBio(scrapy.Spider):\n    name = 'nwinners_minibio'\n    allowed_domains = ['en.wikipedia.org']\n    start_urls = [\n      \"http://en.wikipedia.org/wiki\"\\\n      \"List_of_Nobel_laureates_by_country\"\n    ]\n\n    custom_settings = {\n        'ITEM_PIPELINES':\\\n        {'nobel_winners.pipelines.NobelImagesPipeline':1}\n    }\n\n    # ...\n```"]