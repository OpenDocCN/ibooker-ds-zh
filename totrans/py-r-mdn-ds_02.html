<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 1. In the Beginning"><div class="chapter" id="ch01">
<h1><span class="label">Chapter 1. </span>In the Beginning</h1>


<p class="byline">Rick J. Scavetta</p>

<p class="byline">Boyan Angelov</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45127463273912">
<h5>A note for Early Release readers</h5>
<p>With Early Release ebooks, you get books in their earliest form—the author’s raw and unedited content as they write—so you can take advantage of these technologies long before the official release of these titles.</p>
</div></aside>

<p>We would like to begin with a great first sentence, like “It was the best of times, it was the worst of times…” but honestly, it’s just the best of times — Data Science is flourishing! As it continues to mature, it has begun to splinter into niche topics, as many disciplines do over time. This maturity is the result of a long journey that began in the early days of scientific computing. It’s our belief that knowing some of Python &amp; R’s origin stories will help you to appreciate how they differ in today’s environment, and thus, how to get the most out of them.</p>

<p>We’re not going to pretend to be science historians, that niche group of academics who trace the circumstances of great discoveries and personalities. What we can do is offer a highlight reel of where Python and R come from and how that lead us to our current situation.</p>






<section data-type="sect1" data-pdf-bookmark="The origins of R"><div class="sect1" id="idm45127463270360">
<h1>The origins of R</h1>

<p>Whenever I think about R, I’m reminded of FUBU, a street wear company founded back in the 90s. The name is an acronym that I immediately fell in love with: <em>For Us, By Us</em>. FUBU meant community, it meant understanding the needs and desires of your people and making sure you served them well. <em>R is FUBU</em>.<sup><a data-type="noteref" id="idm45127463267640-marker" href="ch01.xhtml#idm45127463267640">1</a></sup> By the end of this chapter, I’m sure you’ll feel the same way. Once we acknowledge that R is FUBU, it starts to make a lot more sense.</p>

<p>We can trace the origins of R right back to the now legendary Bell Laboratories in New Jersey. In 1976, development of the statistical programming language S was being spearheaded by John Chambers. A year later Chambers published <em>Computational methods for data analysis</em> and his colleague John Tukey, also at Bell Laboratories, published <em>Exploratory Data Analysis</em>. In 1983, Chambers published <em>Graphical methods for data analysis</em>. These books provided the framework to develop a computational system that would not only allow a statistician to explore, understand and analyze their data, but also to communicate their results. We’re talking about an all-star FUBU line-up here! Coauthors of Chambers included both Tukey’s cousin Paul A. Tukey and William Cleveland. Cleveland’s empirical experiments on perception, summarized in two insightful books, continue to inform the broader field of data visualization to this day. Among their many contributions to scientific computing and statistics, Tukey developed novel visualizations, like the oft mis-understood box &amp; whiskers plot and Cleveland developed the LOESS method for non-parametric smoothing.</p>

<p>We begin with S since it laid the foundations for what would eventually become R. The nuggets of information in the previous paragraph tell us quite a bit about S’s — and R’s — foundations. First, statisticians are very literal people (<em>S</em>, get it?). This is pretty a helpful trait. Second, statisticians wanted a FUBU programming language specializing in data analysis. They weren’t interested in making a generalist programming language or an operating system. Third, these early books on computational statistics and visualization are, simply put, stunning examples of pedagogical beauty and precise exposition<sup><a data-type="noteref" id="idm45127463262088-marker" href="ch01.xhtml#idm45127463262088">2</a></sup>. They have aged surprisingly well, despite the obviously dated technology. I’d argue that these books planted the seed for how statisticians, and the R community in particular, approached technical communication in an open, clear and inclusive manner. This, I believe, is an outstanding and distinctive hallmark of the R community that has deep roots. Fourth, the early emphasis on <em>graphical methods</em> tells us that S was already concerned with flexible and efficient <em>data visualizations</em>, necessary for both understanding data and communicating results. So S was about getting the most important things done as easily as possible, and in a true FUBU way.</p>

<p>The original distribution of S ran on Unix and was available for free. Eventually, S became licensed under an implementation titled S-PLUS. This prompted another open-source and free implementation of S by Ross Ihaka and Robert Gentleman at the University of Auckland in 1991. They called this implementation R, for the initials of their first names, as a play on the name S, and in keeping with the tradition of naming programming languages using a single letter. The first official stable beta release of R <code>v1.0.0</code> was available on 29 February 2000. In the intervening years two important developments occurred. First, <a href="https://cran.r-project.org/">CRAN</a>, the Comprehensive R Archive Network, was established to host and archive R packages on mirrored servers. Second, the R Core Team was also established. This group of volunteers (which currently consists of <a href="https://www.r-project.org/contributors.html">20 members</a>) implement base R, including documentation, builds, tests and releases, plus the infrastructure that makes it all possible. Notably, some of the original members are still involved, including John Chambers, Ross Ihaka and Robert Gentleman.</p>

<p>A lot has happened since R <code>v1.0.0</code> in 2000, but the story so far should already give you an idea of R’s unique background as a FUBU statistical computing tool. Before we continue with R’s story, let’s take a look at Python.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="The origins of Python"><div class="sect1" id="idm45127463254808">
<h1>The origins of Python</h1>

<p>In 1991, as Ross Ihaka and Robert Gentleman began working on what would become R, Guido van Rossum, a Dutch programmer, released Python. Python’s core vision is really that of one person who set out to address common computing problems at the time. Indeed, van Rossum was lovingly referred to as the benevolent dictator for life (BDFL) for years, a title he gave up when he stepped down from Python’s Steering Council in 2018.</p>

<p>We saw how S arose out of the need for statisticians to perform data analysis, and how R arose from the need for an open-source implementation, so what problem was addressed by Python? Well, it wasn’t data analysis — that came much later. When Python came on the scene, C and C++, two low-level programming languages, were popular. Python slowly emerged as an interpreted, high-level alternative, in particular after Python <code>v2</code> was released in 2000 (the same year R <code>v1.0.0</code> was released). Python was written with the explicit purpose to be first-and-foremost an easy-to-use and learn, widely-adopted programming language with simple syntax. And it has succeeded in this role very well!</p>

<p>This is why you’ll notice that, in contrast to R, Python is everywhere and is incredibly versatile. You’ll see it in web development, gaming, system administration, desktop applications, data science, and so on. To be sure, R is capable of much more than data analysis, but remember, R is FUBU. If R is FUBU, Python is a Swiss army knife. It’s everywhere and everyone has one, but even though it has many tools, most people just use a single tool on a regular basis. Although data scientists using Python work in a large and varied landscape, they tend to find their niche and specialize in the packages and workflows required for their work instead of exploiting all facets of this generalist language.</p>

<p>Python’s wide-spread popularity within Data Science is not entirely due to its data science capabilities. I would posit that Python entered data science by partly riding on the back of existing uses as a general purpose language. After all, getting your foot in the door is half-way inside. Analysts and data scientists would have had an easier time sharing and implementing scripts with colleagues involved in system administration and web development because they already knew how to work with Python scripts. This played an important role in Python’s wide-spread adoption. Python was well-suited to take advantage of high-performance computing and efficiently implement deep learning algorithms. R was, and perhaps still is, a niche and somewhat foreign language that the wider computing world didn’t really get.</p>

<p>Although Python <code>v2</code> was released in 2000, a widely-adopted package for handling array data didn’t take root until 2005, with the release of <code>NumPy</code>. At this time, <code>SciPy</code>, a package that, since 2001, provided fundamental algorithms for data science (think optimization, integration, differential equations, etc.), began relying on <code>NumPy</code> data structures. <code>SciPy</code> also provides specialized data structures such as <em>k</em>-dimensional trees.</p>

<p>Once the issue of a standard package for core data structures and algorithms was settled, Python began it’s ascent into wide-spread use in scientific computing. The low-level <code>NumPy</code> and <code>SciPy</code> packages laid the foundation for high-level packages like <code>pandas</code> in 2009, providing tools for data manipulation and data structures like <code>DataFrames</code>. This is sometimes termed the pyData stack and it’s when the ball really got rolling.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="The language war begins"><div class="sect1" id="idm45127463242408">
<h1>The language war begins</h1>

<p>The early 2000s set the stage for what some would later refer to as the <em>language wars</em>. As the pyData stack started to take shape, milestones in both Python and R began to heat things up. Four stand out in particular.</p>

<p>First, in 2002, <a href="https://www.bioconductor.org/"><code>BioConductor</code></a> was established as a new R package repository and framework for handling the burgeoning (read absolute explosion of) biological data in its myriad forms. Until this point, Bioinformaticians relied on tools like MatLab and Perl (along with classic command line tools and some manual web-interface tools). MatLab is still favoured in specific disciplines, like Neuroscience. However, Perl has been mostly be superseded by <code>BioConductor</code>. <code>BioConductor</code>’s impact on bioinformatics is hard to overstate. Not only did it provide a repository of packages for dealing with remote genetic sequence databases, expression data, microarrays, and so on, but it also provided new data structures to handle genetic sequences. <code>BioConductor</code> continues to expand and is deeply embedded within the bioinformatics community.</p>

<p>Second, in 2006 the <code>IPython</code> package was released. This was a ground-breaking way to work on Python in an interactive notebook environment. Following various grants beginning in 2012, <code>IPython</code> eventually matured into the <a href="https://jupyter.org/"><em>Jupyter Project</em></a> in 2014, which now encompasses the JupyterLab IDE. Users often forget that Jupyter is short for “Julia, Python and R” because it’s very Python-centric. Notebooks have become a dominant way of doing data science in Python and in 2018 Google released <a href="https://colab.research.google.com/">Google Colab</a>, a free online notebook tool. We’ll dig into this in <a data-type="xref" href="ch03.xhtml#ch04">Chapter 3</a>.</p>

<p>Third, in 2007, Hadley Wickham published his PhD thesis, which consisted of two R packages which would fundamentally change the R landscape. The first, <code>reshape</code>, laid the foundations for what would later become formalized as the <a href="https://www.tidyverse.org/"><em>Tidyverse</em></a> (more on this later). Although <code>reshape</code> has long since been retired, it was the first glimpse into understanding how data structure influences how we think about and work with our data. The second, <code>ggplot2</code>, is an implementation of the seminal book by Leland Wilkinson, “The Grammar of Graphics”, and provided intuitive, high-level plotting, that greatly simplified previously existing tools in R (more on this in <a data-type="xref" href="ch05.xhtml#ch06">Chapter 5</a>).</p>

<p>Finally, Python v3 was released in 2008. For years the question persisted as to which version of Python to use, <code>v2</code> or <code>v3</code>. That’s because Python <code>v3</code> is backward-incompatible. Luckily, this has been resolved for you since Python <code>v2</code> was retired in 2020. Surprisingly, you can still buy a new Mac Book Pro after that date with Python 2 pre-installed, since legacy scripts still rely on it. So Python 2 lives on still.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="The battle for data science dominance"><div class="sect1" id="idm45127463226200">
<h1>The battle for data science dominance</h1>

<p>By this point both Python and R had capable tools for a wide variety of data science applications. As the so-called “language wars” continued, other key developments saw each language find its niche.</p>

<p>Both Python and R were wrapped up in specific <em>builds</em>. For Python this was the Anaconda distribution which is still in popular use (see <a data-type="xref" href="ch03.xhtml#ch04">Chapter 3</a>). For R, Revolution Analytics, a data science software developer, produced <em>Revolution R Open</em>. Although their R build was never widely adopted by the community, the company was acquired by Microsoft, signalling strong corporate support of the R language.</p>

<p>In 2011, the Python community foresaw the boom in machine learning with the release of the <code>scikit-learn</code> package. In 2016, this was followed by the release of both <code>tensorflow</code> and <code>keras</code> for deep learning, also with a healthy dose of corporate support. This also highlights Python’s strength as a high-level interpreter sitting on top of high-performance platforms. For example, you’ll find AWS lambda for massive highly-concurrent programming, <code>Numba</code> for high-performance computing, and the aforementioned <a href="https://www.tensorflow.org/">TensorFlow</a> for highly optimized C++. With its wide-spread adoption outside of data science, it’s no surprise that Python gained a reputation for deploying models in a way that R could not.</p>

<p>2011 also saw the release of <a href="https://rstudio.com/">RStudio</a> IDE by the eponymous company and over the next few years the R community began to converge on this tool. At this point, to use R is, in many regards, to use RStudio. The influence RStudio has on promoting R as a programming language suitable for a wide variety of data-centric uses is also important to note.</p>

<p>While all of this was happening, a growing segment of the R community began to move towards a suite of packages, many of which were authored or spearheaded by Hadley Wickham, that begin to reframe and simplify typical data workflows. Much of what these packages did was to standardize R function syntax, as well as input and output data storage structures. Eventually the suite of packages began to be referred to colloquially as the “Hadleyverse”. In a keynote speech at the UseR! 2016 conference at Stanford University, Wickham did away with this, igniting digital flames to burn up his name and coining the term “Tidyverse”. Since joining RStudio the company has been actively developing and promoting the Tidyverse ecosystem which has arguable become the dominant dialect in R. We’ll explore this in more depth in <a data-type="xref" href="ch02.xhtml#ch03">Chapter 2</a>.</p>

<p>We can imagine that R contains at least 2 “paradigms”, or “dialects”. They can be mixed, but each has its own distinct flavor. Base R<sup><a data-type="noteref" id="idm45127463214056-marker" href="ch01.xhtml#idm45127463214056">3</a></sup> is what most R has been and, probably, still is. <code>Tidyverse</code> re-imagines base R in a broad all-encompassing universe of packages and functions that play well together, often relying on <em>piping</em> and has a preference for data frames. I would argue that <code>BioConductor</code> provides yet another dialect, which is focused on a specific discipline, bioinformatics. You’ll no doubt find that some large packages may contain enough idiosyncrasies that you may consider them a dialect in their own right, but let’s not go down that rabbit hole. R is now at the threshold where some users know (or are taught) only the <code>Tidyverse</code> way of doing things. The distinction between base and Tidyverse R may seem trivial, but I have seen many new R learners struggle to make sense of why the Tidyverse exists. This is partly because years of base R code is still in active use and can’t be ignored. Although Tidyverse advocates argue that these packages make life much easier for the beginner, competing dialects can cause unnecessary confusion.</p>

<p>We can also imagine that Python contains distinct dialects. The <em>vanilla</em> installation of Python is the bare-bones installation, and operates differently to an environment that has imported the pyData stack. For the most part data scientists operate within the pyData stack, so there’s less confusion between dialects.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="A convergence on cooperation and community-building"><div class="sect1" id="idm45127463209176">
<h1>A convergence on cooperation and community-building</h1>

<p>For a time, it seemed that the prevailing attitude in the language wars was an <em>Us versus Them</em> mentality. A look of disdain glancing at a person’s computer screen. It seemed like either Python or R would eventually disappear from the data science landscape. Hello monoculture! Some data scientists are still rooting for this, but we’re guessing you’re not one of them. And there was also a time when it seemed like Python and R were trying to mimic each other, just porting workflows so that language didn’t matter. Luckily those endeavors have not come to fruition. Both Python and R have unique strengths; trying to imitate each other seems to miss that point.</p>

<p>Today many data scientists in the Python and R communities recognize that both languages are outstanding, useful and complementary. To return to a key point in the preface, the data science community has converged onto a point of cooperation and community-building — to the benefit of everyone involved.</p>

<p>We’re ready for a new community of bilingual data scientists. The challenge is that many users of one language don’t quite know <em>how</em> they are complementary or <em>when</em> to use which language. There have been a few solutions over the years, but we’ll get into that in <a data-type="xref" href="part04.xhtml#p04">Part IV</a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Final thoughts"><div class="sect1" id="idm45127463203384">
<h1>Final thoughts</h1>

<p>At this point you should have a good idea of where we are in 2021 and how we got here. In the next part we’ll introduce each group of users to a new language.</p>

<p>One last note: Python users refer to themselves as Pythonistias, which is a really cool name! There’s no real equivalent in R, and they also don’t get a really cool animal, but that’s life when you’re a single letter language. R users are typically called… wait for it … useRs! (exclamation optional) Indeed, the official, annual conference is called useR! (exclamation obligatory) and the publisher Springer has an ongoing and very excellent series of books of the same name. We’ll use these names for now own.</p>

<p><a data-type="xref" href="#PyRTimeline">Figure 1-1</a> provides a summary of some of the major events that we’ve highlighted in this chapter, plus some other milestones of interest.</p>

<figure><div id="PyRTimeline" class="figure">
<img src="Images/prds_0101.png" alt="" width="837" height="1076"/>
<h6><span class="label">Figure 1-1. </span>A timeline of Python and R data science milestones.</h6>
</div></figure>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm45127463267640"><sup><a href="ch01.xhtml#idm45127463267640-marker">1</a></sup> Well, OK, more like <em>For Statisticians, By Statisticians</em>, but FSBS doesn’t have the same ring to it.</p><p data-type="footnote" id="idm45127463262088"><sup><a href="ch01.xhtml#idm45127463262088-marker">2</a></sup> With the possible exception of <em>Computational methods for data analysis</em> which I admit to having not read.</p><p data-type="footnote" id="idm45127463214056"><sup><a href="ch01.xhtml#idm45127463214056-marker">3</a></sup> Python users might not be familiar with the term “base”. This means only the built-in functionality of the language without any additional package installations. Base R itself is well-equipped for data analysis. In Python, a data scientist would import the PyData stack by default.</p></div></div></section></div></body></html>