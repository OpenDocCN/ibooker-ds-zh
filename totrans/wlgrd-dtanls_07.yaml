- en: '8 Time series data: Data preparation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 时间序列数据：数据准备
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Preparing time series data for analysis
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备时间序列数据进行分析
- en: Determining what subset of time series data to use
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定使用哪些时间序列数据子集
- en: Cleaning time series data by handling gaps and missing values
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过处理缺失值和间隙来清理时间序列数据
- en: Analyzing patterns in time series data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析时间序列数据中的模式
- en: Most datasets you will come across have a time component. If the process to
    generate the data involves taking the same measurement at recurring intervals,
    the data is called *time series data*. An example is measuring the yearly GDP
    of a country or the output of machinery in a production line. However, even something
    seemingly static, such as a customer database, has a time component if we look
    at the date customer records were created. We might not explicitly think of the
    data as a time series, but using this time component allows us to unlock additional
    insights in our data. For example, you could analyze the rate at which new customer
    records are being created or what times of the day your operations team are inputting
    data into the database.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你会遇到的大多数数据集都有一个时间组件。如果生成数据的过程涉及到在重复的时间间隔内进行相同的测量，那么这些数据被称为*时间序列数据*。例如，测量一个国家的年度GDP或生产线上的机器输出。然而，即使是看似静态的东西，如客户数据库，如果我们查看客户记录创建的日期，它也有一个时间组件。我们可能不会明确地将数据视为时间序列，但使用这个时间组件可以让我们在数据中获得额外的洞察。例如，你可以分析新客户记录创建的速度或你的运营团队在一天中的哪些时间将数据输入到数据库中。
- en: 'Real business case: Forecasting'
  id: totrans-7
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 真实业务案例：预测
- en: The project covered by chapters 8 and 9 was inspired by multiple forecasting
    projects I have worked on and the fact that most data analysis curricula spend
    proportionally little time on the topic of working with temporal data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 第8章和第9章涵盖的项目灵感来源于我参与过的多个预测项目，以及大多数数据分析课程在处理时间数据主题上投入的时间相对较少的事实。
- en: In late 2020, I had to provide forecasts for where the used car market was heading
    after the initial COVID lockdown restrictions were lifted in the United Kingdom.
    Accurately forecasting an entire market is hard enough, but the added complexity
    of having patchy data for the lockdown period and having to forecast in a scenario
    no one had encountered before made this project particularly difficult.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在2020年底，我不得不在最初的COVID封锁限制在英国解除后，提供对二手车市场走向的预测。准确预测整个市场已经足够困难，但封锁期间数据不完整以及必须预测一个没有人遇到过的情况，使得这个项目尤其困难。
- en: In the end, we arrived at a prediction using a combination of fundamental forecasting
    principles, some concrete assumptions about the pandemic, and domain knowledge
    from our experts. It was a good example of a project where technical skills weren’t
    enough to solve the business problem.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过结合基本预测原则、对大流行的具体假设以及专家的领域知识，得出了预测。这是一个技术技能不足以解决业务问题的项目的良好例子。
- en: Working with time series data is more than knowing how to work with date formats.
    It involves extracting time-related components from data, handling time data at
    different resolutions, handling gaps, forecasting into the future, and working
    out whether the data can be forecasted at all.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与时间序列数据工作不仅仅是知道如何处理日期格式。它涉及到从数据中提取时间相关的组件，处理不同分辨率的时间数据，处理数据缺失，预测未来，以及确定数据是否可以进行预测。
- en: Knowing how to extract temporal patterns from your data is a vital skill in
    the real world and one that we will practice in this chapter through the project.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，知道如何从你的数据中提取时间模式是一项至关重要的技能，我们将在本章的项目中通过实践来掌握这项技能。
- en: 8.1 Working with time series data
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 与时间序列数据工作
- en: 'A time series is a repeated measurement taken at different, ideally uniform,
    time intervals. A typical tabular dataset, such as a customer dataset, will contain
    one row per customer, and each column will represent a different property of a
    customer, such as age, employment status, address, and so forth. A time series,
    however, typically contains fewer columns: one to represent the date of a measurement
    and one or more columns to represent the individual measurement value at that
    time. Each row, therefore, represents the same measurement, and it is the measurement
    time that makes each row unique.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列是在不同、理想情况下均匀的时间间隔内进行的重复测量。典型的表格数据集，如客户数据集，将包含每名客户一行，每列将代表客户的不同属性，例如年龄、就业状态、地址等。然而，时间序列通常包含较少的列：一列代表测量的日期，一列或多列代表该时间点的单个测量值。因此，每一行代表相同的测量，而测量时间是使每一行独特的原因。
- en: 8.1.1 The hidden depth of time series data
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.1 时间序列数据的潜在深度
- en: Let’s take a simple example—customer satisfaction over time. Imagine one of
    those smiley-face-based satisfaction surveys you can find at airports, supermarket
    checkouts, or any other public place. As a customer walks by, they can press a
    smiley face to indicate their level of satisfaction. They see smiley faces, and
    the database records a simple value from 1 to 5 on a Likert scale to measure the
    value from most dissatisfied to most satisfied. Table 8.1 shows an example of
    what this dataset might look like.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个简单的例子来解释——随时间推移的客户满意度。想象一下在机场、超市结账处或其他公共场所可以找到的那种基于笑脸的调查。当客户经过时，他们可以按下一个笑脸来表示他们的满意度水平。他们看到笑脸，数据库记录了一个从1到5的Likert量表上的简单值，以衡量从最不满意到最满意的值。表8.1显示了此数据集可能的样子。
- en: Table 8.1 An example of a time series dataset
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表8.1 时间序列数据集的一个示例
- en: '| Date | Satisfaction score |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 日期 | 满意度得分 |'
- en: '| --- | --- |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 2023-11-01 11:03:55  | 4  |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 2023-11-01 11:03:55  | 4  |'
- en: '| 2023-11-01 11:17:02  | 5  |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 2023-11-01 11:17:02  | 5  |'
- en: '| 2023-11-01 13:41:11  | 3  |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 2023-11-01 13:41:11  | 3  |'
- en: '| 2023-11-01 14:06:43  | 4  |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 2023-11-01 14:06:43  | 4  |'
- en: To capture satisfaction over time, you just need a timestamp and the satisfaction
    value. If you had such a system set up across multiple locations, you might also
    find a location ID column, but the data wouldn’t be more complex than that.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要捕捉随时间推移的满意度，你只需要一个时间戳和满意度值。如果你在多个地点设置了这样的系统，你也可能找到一个位置ID列，但数据不会比这更复杂。
- en: What kind of analysis could we do with what is, at first glance, a very simple
    dataset? We could
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于乍一看非常简单的数据集，我们可以进行什么样的分析？我们可以
- en: Use clusters of rows as a proxy to identify busier periods
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用行簇作为代理来识别繁忙时期
- en: Calculate average satisfaction over time at various levels of granularity (daily,
    weekly, monthly, etc.)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算不同粒度（每日、每周、每月等）上的平均满意度
- en: Investigate trends and seasonal patterns in the data (if customers are more
    satisfied at different points of the day or different days of the week)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查数据中的趋势和季节性模式（如果客户在不同时间点或不同星期的不同日子满意度更高）
- en: Find anomalies where satisfaction rose or dropped to unexpected levels
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找出满意度意外上升或下降的异常值
- en: Cross-reference this with other data to identify how satisfaction relates to
    external factors, such as special events
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将此与其他数据交叉引用以确定满意度与外部因素（如特殊事件）的关系
- en: Compare satisfaction scores across different locations where that data is available
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较不同地点的满意度得分
- en: The fact that most of these questions can be answered with just two to three
    columns of data shows the hidden depth that time series data can have.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，大多数这些问题只需要两到三列数据就可以回答，这显示了时间序列数据所具有的潜在深度。
- en: 8.1.2 How to work with time series data
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.2 如何处理时间序列数据
- en: 'What does it mean to work with time series? When exploring time data, we care
    about a lot of the same things as when exploring tabular data. We want to understand
    each column, ensure data types are consistent, and check for missing values. However,
    there are also specific considerations for time data:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 与时间序列一起工作意味着什么？在探索时间数据时，我们关心的事情与探索表格数据时关心的事情有很多相同之处。我们想要理解每一列，确保数据类型一致，并检查缺失值。然而，对于时间数据也有一些特定的考虑：
- en: What is the granularity of the time series? Is it consistent?
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列的粒度是多少？它是一致的吗？
- en: Are there any gaps in the time series? Are these gaps there by design?
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列中是否存在任何间隔？这些间隔是故意设置的吗？
- en: Is there a trend in the data?
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中是否存在趋势？
- en: Are there seasonal patterns?
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在季节性模式吗？
- en: Are there any outliers worth investigating?
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有任何值得调查的异常值？
- en: 'Once you have explored your time series dataset and want to proceed to forecasting,
    there are additional considerations:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您已经探索了您的时间序列数据集并想要进行预测，还有其他一些考虑因素：
- en: What is the right granularity for forecasting? This will depend partly on how
    much noise there is in the data. Hourly data might be too noisy, and although
    daily averages might be smoother and easier to forecast, there might not be enough
    data at a daily level.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测的正确粒度是什么？这将在一定程度上取决于数据中的噪声程度。小时数据可能太嘈杂，尽管日平均数据可能更平滑且更容易预测，但在日级别可能没有足够的数据。
- en: 'Does the time series contain autocorrelation: do past values inform future
    values? There are statistical tests for this, and time series models will take
    advantage of this property.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列是否包含自相关：过去的值是否影响未来的值？对此有统计测试，时间序列模型将利用这一特性。
- en: Is the time series stationary? Some time series models require the data to be
    stationary, which means having a roughly constant mean and variance over time.
    In reality, a lot of time series have some trend and seasonality, so we either
    need to handle those directly or use forecasting models that take care of them
    for us.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列是否平稳？一些时间序列模型要求数据平稳，这意味着在时间上大致保持恒定的均值和方差。在现实中，许多时间序列都有一些趋势和季节性，因此我们可能需要直接处理这些数据，或者使用为我们处理这些数据的预测模型。
- en: Can any outliers be explained by external factors? For example, are certain
    spikes in your sales data due to one-off special sale days, like Black Friday?
    These external factors, technically “exogenous variables,” can be used in many
    forecasting models to improve predictions.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有任何异常值可以由外部因素解释？例如，您的销售数据中的某些峰值是否是由于一次性特别促销日，如黑色星期五？这些外部因素，技术上称为“外生变量”，可以用于许多预测模型以改善预测。
- en: 'A final note on forecasting: the most important question you should ask is,
    “How will the forecast be used?” This requires answering these questions:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 关于预测的最后一句话：你应该问的最重要的问题是，“预测将如何被使用？”这需要回答这些问题：
- en: How often are forecasts required?
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测需要多频繁？
- en: What is the required granularity of the forecasts?
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测所需的粒度是多少？
- en: How far into the future should the forecasts go?
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测应该延伸多远？
- en: What does an acceptable level of accuracy look like?
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可接受的准确度水平看起来是什么样子？
- en: What is the value of an accurate forecast in business terms? What is, therefore,
    the return on investment of additional work to improve existing forecasts?
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确预测在商业意义上的价值是什么？因此，额外工作以改善现有预测的投资回报率是多少？
- en: Will the data required by the forecasting model be available in time?
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测模型所需的数据能否及时可用？
- en: Answers to these questions will inform your analytical decisions at least as
    much as the technical considerations. When completing this project, and as with
    any project, you should always focus on the business outcomes you are trying to
    improve.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题的答案至少与技术考虑一样，将指导您的分析决策。在完成这个项目时，就像任何项目一样，您应该始终关注您试图改善的商业结果。
- en: '8.2 Project 6: Analyzing time series to improve cycling infrastructure'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 项目6：分析时间序列以改善自行车基础设施
- en: Let’s look at the project in which we will analyze road traffic data to understand
    where cycling infrastructure should be improved. In this chapter, we will explore
    the available data and prepare it for analysis, which will happen in chapter 9.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们将分析道路交通数据以了解自行车基础设施应如何改进的项目。在本章中，我们将探索可用数据并为其分析做准备，分析将在第9章进行。
- en: The data is available for you to attempt the project yourself at [https://davidasboth.com/book-code](https://davidasboth.com/book-code).
    You will find the data you can use for the project, as well as the example solution
    in the form of a Jupyter notebook.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 数据已提供，您可以在[https://davidasboth.com/book-code](https://davidasboth.com/book-code)自行尝试项目。您将找到可用于项目的数据，以及以Jupyter笔记本形式的示例解决方案。
- en: This project is all about using time series data to find answers to our business
    questions. As usual, we will start by looking at the problem statement, the data
    dictionary, the outputs we are aiming for, and what tools we need to tackle the
    problem. We will then formulate our action plan using the results-oriented framework
    before diving into the example solution.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目完全是关于使用时间序列数据来寻找我们商业问题的答案。像往常一样，我们将从查看问题陈述、数据字典、我们希望达到的输出以及我们需要解决这个问题的工具开始。然后，我们将使用以结果为导向的框架制定我们的行动计划，然后再深入研究示例解决方案。
- en: 8.2.1 Problem statement
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 问题陈述
- en: You have been hired to work on a new government initiative, Bikes4Britain, which
    aims to improve cycling infrastructure in the United Kingdom. The aim of the first
    phase of the project is to identify the most suitable places around the country
    to improve infrastructure for cyclists. Specifically, your stakeholders are looking
    for recommendations of places with either substantial existing or increasing cycling
    traffic.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您被聘请参与一项新的政府倡议“Bikes4Britain”，该倡议旨在改善英国自行车基础设施。项目的第一阶段目标是确定全国最适合改善自行车基础设施的地方。具体来说，您的利益相关者正在寻找具有大量现有或增加自行车交通的地方的建议。
- en: They want to start with open data sources and have identified the Department
    for Transport’s road traffic statistics ([https://roadtraffic.dft.gov.uk](https://roadtraffic.dft.gov.uk))
    as a way to measure cycling traffic across the country. This is the dataset we
    will use in this project to look for patterns and make recommendations.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 他们希望从公开数据源开始，并已将交通部道路交通统计数据（[https://roadtraffic.dft.gov.uk](https://roadtraffic.dft.gov.uk)）作为衡量全国自行车交通的一种方式。这是我们将在本项目中寻找模式和提出建议所使用的数据集。
- en: NOTE  Data originally taken from [https://roadtraffic.dft.gov.uk/downloads](https://roadtraffic.dft.gov.uk/downloads).
    Thank you to the Department for Transport for making this data available under
    the Open Government Licence.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 备注  数据最初来自 [https://roadtraffic.dft.gov.uk/downloads](https://roadtraffic.dft.gov.uk/downloads)。感谢交通部在开放政府许可下提供这些数据。
- en: The data we will use from the Department’s statistics is the raw count data.
    This is a record of raw counts of vehicles that passed a particular counting location
    at various times. Some of the datasets are too high-level, such as area-level
    annual summaries, and some of them are estimates, such as the estimated annual
    average daily flows data (AADFs). The raw count dataset contains data at the most
    granular level, and we can always aggregate it to higher levels (e.g., annual
    values) if needed.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从部门的统计数据中使用的原始数据是原始计数数据。这是记录在特定计数位置在不同时间通过的车辆原始计数的记录。一些数据集过于高级，例如区域层面的年度汇总，而另一些则是估计值，例如估计的年度平均日流量数据（AADFs）。原始计数数据集包含最细粒度的数据，如果需要，我们总是可以将其汇总到更高的级别（例如，年度值）。
- en: 8.2.2 Data dictionary
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 数据字典
- en: Before we think further about the project, we should take a look at what data
    we have available. The data dictionary document ([https://mng.bz/4ajw](https://mng.bz/4ajw))
    is included in the project files, and table 8.2 shows the columns in detail. The
    data dictionary is shown as is, without modification from the original.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进一步思考项目之前，我们应该看看我们有哪些可用数据。数据字典文档（[https://mng.bz/4ajw](https://mng.bz/4ajw)）包含在项目文件中，表8.2详细显示了列。数据字典按原样显示，未对原始内容进行修改。
- en: Table 8.2 The data dictionary, showing all column definitions
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表8.2 数据字典，显示所有列定义
- en: '| Column name | Definition |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 列名称 | 定义 |'
- en: '| --- | --- |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `Count_point_id`  | A unique reference for the road link that links the AADFs
    to the road network  |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| `Count_point_id`  | 将AADFs与道路网络连接的道路连接的唯一参考  |'
- en: '| `Direction_of_travel`  | Direction of travel  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| `Direction_of_travel`  | 行驶方向  |'
- en: '| `Year`  | Counts are shown for each year from 2000 onwards  |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| `Year`  | 从2000年开始显示每年的计数  |'
- en: '| `Count_date`  | The date when the actual count took place  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| `Count_date`  | 实际计数发生的日期  |'
- en: '| `Hour`  | The time when the counts in question took place, where 7 represents
    between 7 a.m. and 8 a.m., and 17 represents between 5 p.m. and 6 p.m.  |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| `Hour`  | 计数发生的时间，其中7代表早上7点到8点，17代表下午5点到6点  |'
- en: '| `Region_id`  | Website region identifier  |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| `Region_id`  | 网站区域标识符  |'
- en: '| `Region_name`  | The name of the region that the count point (CP) sits within  |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| `Region_name`  | 计数点（CP）所在的区域名称  |'
- en: '| `Region_ons_code`  | The Office for National Statistics code identifier for
    the region  |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| `Region_ons_code`  | 该区域的英国国家统计办公室代码标识符  |'
- en: '| `Local_authority_id`  | Website local authority identifier  |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| `Local_authority_id`  | 网站当地政府标识符  |'
- en: '| `Local_authority_name`  | The local authority that the CP sits within  |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| `Local_authority_name`  | CP所在的当地政府机构  |'
- en: '| `Local_authority_code`  | The Office for National Statistics code identifier
    for the local authority  |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| `Local_authority_code`  | 英国国家统计办公室为当地政府机构提供的代码标识符  |'
- en: '| `Road_name`  | The road name (for instance, M25 or A3)  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| `Road_name`  | 道路名称（例如，M25或A3）  |'
- en: '| `Road_category`  | The classification of the road type (see data definitions
    for the full list)  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| `Road_category`  | 道路类型的分类（请参阅数据定义以获取完整列表）  |'
- en: '| `Road_type`  | Whether the road is a major or minor road  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| `Road_type`  | 道路是主要道路还是次要道路 |'
- en: '| `Start_junction_road_name`  | The road name of the start junction of the
    link  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| `Start_junction_road_name`  | 链接起始交叉路口的道路名称 |'
- en: '| `End_junction_road_name`  | The road name of the end junction of the link  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| `End_junction_road_name`  | 链接末端交叉路口的道路名称 |'
- en: '| `Easting`  | Easting coordinates of the CP location  |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `Easting`  | CP位置的东经坐标 |'
- en: '| `Northing`  | Northing coordinates of the CP location  |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `Northing`  | CP位置的北纬坐标 |'
- en: '| `Latitude`  | Latitude of the CP location  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| `Latitude`  | CP位置的纬度 |'
- en: '| `Longitude`  | Longitude of the CP location  |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| `Longitude`  | CP位置的经度 |'
- en: '| `Link_length_km`  | Total length of the network road link for that CP (in
    kilometers)  |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| `Link_length_km`  | 该CP网络道路链接的总长度（千米） |'
- en: '| `Link_length_miles`  | Total length of the network road link for that CP
    (in miles)  |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `Link_length_miles`  | 该CP网络道路链接的总长度（英里） |'
- en: '| `Pedal_cycles`  | Counts for pedal cycles  |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `Pedal_cycles`  | 自行车计数 |'
- en: '| `Two_wheeled_motor_vehicles`  | Counts for two-wheeled motor vehicles  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| `Two_wheeled_motor_vehicles`  | 两轮机动车计数 |'
- en: '| `Cars_and_taxis`  | Counts for cars and taxis  |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `Cars_and_taxis`  | 汽车和出租车计数 |'
- en: '| `Buses_and_coaches`  | Counts for buses and coaches  |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `Buses_and_coaches`  | 公共汽车和长途汽车计数 |'
- en: '| `LGVs`  | Counts for LGVs  |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `LGVs`  | 大型货车计数 |'
- en: '| `HGVs_2_rigid_axle`  | Counts for two-rigid axle HGVs  |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| `HGVs_2_rigid_axle`  | 两轴刚性轴大型货车计数 |'
- en: '| `HGVs_3_rigid_axle`  | Counts for three-rigid axle HGVs  |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| `HGVs_3_rigid_axle`  | 三轴刚性轴大型货车计数 |'
- en: '| `HGVs_4_or_more_rigid_axle`  | Counts for four or more rigid axle HGVs  |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| `HGVs_4_or_more_rigid_axle`  | 四轴或更多刚性轴大型货车计数 |'
- en: '| `HGVs_3_or_4_articulated_axle`  | Counts for three- or four-articulated axle
    HGVs  |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| `HGVs_3_or_4_articulated_axle`  | 三或四轴铰接轴大型货车计数 |'
- en: '| `HGVs_5_articulated_axle`  | Counts for five-articulated axle HGVs  |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `HGVs_5_articulated_axle`  | 五轴铰接轴大型货车计数 |'
- en: '| `HGVs_6_articulated_axle`  | Counts for six-articulated axle HGVs  |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `HGVs_6_articulated_axle`  | 六轴铰接轴大型货车计数 |'
- en: '| `All_HGVs`  | Counts for all HGVs  |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| `All_HGVs`  | 所有大型货车计数 |'
- en: '| `All_motor_vehicles`  | Counts for all motor vehicles  |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| `All_motor_vehicles`  | 所有机动车计数 |'
- en: The data dictionary shows that we have data about the day and time that vehicle
    counts were recorded. There is a column specifically recording the count of bicycles,
    as well as plenty of information about the stretch of road where the counting
    took place. We can already see that we will be able to look at vehicle counts
    at different locations as separate time series since we satisfy the definition
    of a time series by having both date and time information, as well as the same
    measurement taken at different time intervals.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 数据字典显示，我们有关于车辆计数记录的日期和时间的记录。有一列专门记录自行车的计数，以及关于计数发生的道路段落的丰富信息。我们可以看到，由于我们满足时间序列的定义，即具有日期和时间信息以及在不同时间间隔进行的相同测量，因此我们将能够将不同位置的车辆计数视为单独的时间序列。
- en: 8.2.3 Desired outcomes
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.3 预期成果
- en: The output of the project is a recommendation of which area, or areas, to concentrate
    on for further analysis. These might be areas that already have a lot of high
    bicycle traffic, or they might be areas where cycling is on the rise or forecasted
    to have high cycling demand in the future. Our recommendation will likely contain
    suggested additional datasets we could incorporate to continue the analysis. There
    is likely more that we would like to know about these areas before any infrastructure
    work is undertaken, and we should outline this additional work to our stakeholders.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 项目输出是对进一步分析应集中关注哪个区域或哪些区域的推荐。这些可能已经是自行车交通量很大的区域，或者可能是自行车正在兴起或预计未来将有高自行车需求的区域。我们的推荐可能包含我们建议可以纳入以继续分析的其他数据集。在开始任何基础设施工作之前，我们可能还希望了解这些区域的一些更多信息，并且我们应该向我们的利益相关者概述这项额外的工作。
- en: As this project spans multiple chapters, the desired outcome of this chapter,
    which is the data preparation part, is a filtered and cleaned version of the raw
    data, ready to be analyzed. The outcome of chapter 9 will then be the results
    of the analysis and final recommendations.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本项目跨越多个章节，本章（数据准备部分）的预期成果是对原始数据进行筛选和清洗后的版本，以便进行分析。第9章的成果将是分析结果和最终建议。
- en: 8.2.4 Required tools
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.4 需要的工具
- en: As with most projects, your data analysis toolkit needs to read, explore, and
    visualize data to be suitable for the project. In the example solution, I use
    Python and the `pandas` and `matplotlib` libraries for data exploration and visualization,
    respectively. In the following chapter, I also introduce some time series functions
    from the `statsmodels` library when investigating time-specific aspects of the
    data and the `pmdarima` module for automatically choosing the best forecasting
    model. For this project, your tool should be able to
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数项目一样，你的数据分析工具需要能够读取、探索和可视化数据，以便适合项目。在示例解决方案中，我使用Python以及`pandas`和`matplotlib`库分别进行数据探索和可视化。在下一章中，我还介绍了`statsmodels`库的一些时间序列函数，用于调查数据的时间特定方面，以及`pmdarima`模块用于自动选择最佳的预测模型。对于这个项目，你的工具应该能够
- en: Load a large dataset from a CSV or Excel file containing millions of rows
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从包含数百万行的CSV或Excel文件中加载数据集
- en: Perform basic data manipulation tasks, such as filtering, sorting, grouping,
    and reshaping data
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行基本的数据操作任务，例如过滤、排序、分组和重塑数据
- en: Create data visualizations
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建数据可视化
- en: Produce statistical analysis, specifically of time series data
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行统计分析，特别是时间序列数据的分析
- en: Optionally create forecasts based on time series data
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选地基于时间序列数据进行预测
- en: 8.3 Applying the results-driven method to analyzing road traffic data
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 将结果驱动方法应用于分析道路交通数据
- en: Let’s now see how we will address this problem in a results-driven way and formulate
    our action plan. We will follow the steps of the results-driven process to explore
    the data with our stakeholders’ requests and areas of interest in mind.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看我们将如何以结果驱动的方式解决这个问题并制定我们的行动计划。我们将遵循结果驱动过程的步骤，考虑到利益相关者的请求和感兴趣的区域来探索数据。
- en: '![figure](../Images/8-unnumb-1.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-unnumb-1.png)'
- en: Do we fully understand the problem statement? Our stakeholders are interested
    in seeing how the number of cyclists has changed over time and across different
    areas. We know that’s the part of the data we will focus on. However, their request
    is not as specific as we might like.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否完全理解了问题陈述？我们的利益相关者对看到自行车数量随时间和不同区域的变化感兴趣。我们知道这是我们将会关注的数据部分。然而，他们的请求并不像我们可能希望的那样具体。
- en: We need to define key terms, such as what it means for a place to be suitable
    for upgrading the cycling infrastructure. Is it somewhere where there are already
    a lot of cyclists? Or do we want to find places with potentially lower cycling
    traffic but where cycling is increasing the most over time? In that case, what
    are our criteria for “increasing”? If we can forecast our time series, we might
    even be able to make recommendations based on predicted future traffic.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要定义关键术语，例如，一个地方适合升级自行车基础设施意味着什么。是已经有大量自行车手的地方吗？或者我们想要找到潜在的自行车交通量较低但随时间自行车增长最快的地方？在这种情况下，“增长”的标准是什么？如果我们能预测时间序列，我们甚至可能基于预测的未来交通量提出建议。
- en: '![figure](../Images/8-unnumb-2.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-unnumb-2.png)'
- en: Let’s now think about the end result. We must focus on patterns in cycling traffic,
    so there will be parts of the data we can largely ignore for our analysis. Knowing
    that we are interested in a particular aspect of the data will help us at the
    start when we are figuring out where to go next after the standard exploratory
    steps.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来思考最终结果。我们必须关注自行车交通的模式，因此对于我们的分析，数据中的一些部分我们可以很大程度上忽略。知道我们对数据的特定方面感兴趣，将有助于我们在开始时确定在标准探索步骤之后下一步该去哪里。
- en: '![figure](../Images/8-unnumb-3.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-unnumb-3.png)'
- en: This is the step in which we decided to use the raw count data over the other
    available datasets. Again, this was driven directly by the problem statement.
    Area-level annual summaries are too high level to tease out cycling traffic, and
    using estimated measurements reduces the usefulness of our findings, leaving us
    with the raw count data to analyze. In this case, we do not have to make further
    decisions about which dataset to download, as the entire raw dataset comes as
    one file.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这是决定使用原始计数数据而不是其他可用数据集的步骤。这直接由问题陈述驱动。区域层面的年度总结过于笼统，无法揭示自行车交通情况，而使用估计的测量值会降低我们发现的有用性，使我们只剩下原始计数数据来分析。在这种情况下，我们不需要就下载哪个数据集做出进一步的决定，因为整个原始数据集作为一个文件提供。
- en: '![figure](../Images/8-unnumb-4.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-unnumb-4.png)'
- en: As with most of the projects, the data has already been downloaded, but no other
    changes have been made to it to best simulate the experience of exploring it for
    the first time. In the real world, obtaining the data might be a surprising obstacle,
    especially if you need permission, and there are privacy and governance concerns.
    This is not the case here, as we are working with open government data.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 就像大多数项目一样，数据已经被下载了，但我们没有对其进行任何其他更改，以最好地模拟首次探索它的体验。在现实世界中，获取数据可能是一个令人惊讶的障碍，尤其是如果你需要许可，并且存在隐私和治理问题。这里的情况并非如此，因为我们正在处理开放政府数据。
- en: '![figure](../Images/8-unnumb-5.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-unnumb-5.png)'
- en: Let’s now think about the steps we will take in our analysis. Before we turn
    our attention to the recommendation portion, we need to explore the dataset thoroughly.
    Specifically, we want to
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在考虑我们分析中将要采取的步骤。在我们转向建议部分之前，我们需要彻底探索数据集。具体来说，我们想要
- en: '*Investigate the granularity of our data* —What does one row represent? Is
    it one row per location per day or something else? The granularity of data is
    one of the first things to investigate because it informs all other data transformations,
    like aggregations.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*调查我们数据粒度* — 一行数据代表什么？是一天一个地点的数据，还是其他什么？数据的粒度是首先要调查的事情之一，因为它会影响到所有其他的数据转换，比如聚合。'
- en: '*Understand the coverage of the data both geographically and in time* —For
    example, because the dataset is not a single time series but many, we need to
    know if every available location has the same amount of data.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*了解数据的地理和时间覆盖范围* — 例如，因为数据集不是一个单一的时间序列，而是多个，我们需要知道每个可用的地点是否有相同数量的数据。'
- en: '*Identify gaps in the time series* —Does every location have measurements at
    constant intervals? This is important to ensure we have enough of a sample at
    each location and is also a critical requirement for forecasting. Most forecasting
    algorithms do not work with gaps in the data or inconsistent intervals.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*识别时间序列中的差距* — 每个地点都有恒定间隔的测量值吗？这很重要，以确保我们在每个地点都有足够的样本，并且对于预测也是一项关键要求。大多数预测算法都不适用于数据中的差距或不一致的间隔。'
- en: '*Investigate the distribution of bicycle counts* —What is a typical cycling
    volume for one row of data? Knowing this will immediately help identify the places
    with the highest cycling traffic.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*调查自行车计数分布* — 一行数据中典型的自行车流量是多少？了解这一点将立即帮助我们识别出自行车交通流量最高的地方。'
- en: '*Look at temporal patterns* —This includes looking at how cycling traffic fluctuates
    at different times of day, different days of the week, and across multiple years.
    Are there seasonal patterns we can identify? Which locations are showing a growing
    trend in cycling traffic?'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*观察时间模式* — 这包括观察自行车交通在不同时间、不同星期日和多年间的波动情况。我们能识别出季节性模式吗？哪些地点显示出自行车交通增长的趋势？'
- en: '*Reduce the search space* —By this I mean we may not be able to analyze every
    location in equal detail because of gaps. We may have to filter the data down
    to locations that have more complete records across a longer time horizon, especially
    if we are interested in looking for temporal patterns and forecasting.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*缩小搜索范围* — 这意味着由于存在差距，我们可能无法以相同程度详细分析每个地点。我们可能必须将数据过滤到在更长时间范围内有更完整记录的地点，特别是如果我们对寻找时间模式和预测感兴趣的话。'
- en: '*![figure](../Images/8-unnumb-6.png)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*![figure](../Images/8-unnumb-6.png)'
- en: The output of this project is likely to be a combination of line charts and
    conversations. Line charts are the de facto time series visualization tool because
    they best represent the temporal component of an analytical result. We will likely
    end up creating other visualizations, too, but this is a project where the first
    iteration will spark a lot of conversation with our stakeholders. As we identify
    the limitations of the available data, we will be able to make recommendations
    about other datasets, and deciding on which ones to focus on will be done in collaboration
    with our domain experts.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目的输出很可能是线形图和对话的结合。线形图是事实上的时间序列可视化工具，因为它们最能代表分析结果的时间成分。我们可能还会创建其他可视化，但这是一个第一个迭代就会与我们的利益相关者引发很多讨论的项目。当我们确定可用数据的局限性时，我们将能够就其他数据集提出建议，并且决定关注哪些数据集将与我们的领域专家合作完成。
- en: '![figure](../Images/8-unnumb-7.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-unnumb-7.png)'
- en: Since the dataset focuses narrowly on traffic volume, there will be multiple
    angles to explore after our initial recommendations. In the example solution,
    we’ll explore some of these possible directions in which we could take a future
    iteration.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集专注于交通量，我们将在我们的初步建议之后探索多个角度。在示例解决方案中，我们将探索一些可能的未来迭代方向。
- en: '8.4 An example solution: Where should cycling infrastructure improvements be
    focused?'
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 一个示例解决方案：应该在哪里集中改善骑行基础设施？
- en: Now, it’s time to look at an example walkthrough of analyzing this data. As
    always, I strongly recommend attempting the project yourself first. The example
    solution will be more relevant if you have your own analysis to compare it to.
    It bears repeating that the solution is not *the* solution, just one series of
    decisions you could make and conclusions you could reach along the way. Use it
    to generate more ideas and gain a different perspective on how you could have
    approached the same project brief.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候查看分析这些数据的一个示例流程了。像往常一样，我强烈建议您首先尝试自己完成这个项目。如果您有自己的分析来与之比较，示例解决方案将更有意义。重复一遍，这个解决方案不是*唯一的*解决方案，只是您在过程中可能做出的决策和可能得出的结论的一系列。使用它来产生更多想法，并从不同的角度看待您如何处理同一个项目概述。
- en: Knowing what our end goal is and having thought about the various steps we want
    to take, our action plan will start with investigating the data. Only then will
    we understand what specific questions we can answer with what’s available. Then,
    we can focus on looking for patterns and trends in cycling behavior and perhaps
    even attempt to forecast cycling trends into the future.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 明确我们的最终目标，并思考我们想要采取的各种步骤后，我们的行动计划将从调查数据开始。只有在这种情况下，我们才能理解我们可以用现有资源回答哪些具体问题。然后，我们可以专注于寻找骑行行为中的模式和趋势，甚至尝试预测未来的骑行趋势。
- en: 8.4.1 Investigating available data and extracting time series
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.1 调查可用数据并提取时间序列
- en: 'As with any data problem, our first step is to look at the data itself. We
    know what columns to expect, but seeing a few sample rows will help us understand.
    We’ll import the necessary libraries and examine a few rows of data. The output
    is shown in figure 8.1:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何数据问题一样，我们的第一步是查看数据本身。我们知道预期哪些列，但查看一些样本行将帮助我们理解。我们将导入必要的库并检查一些数据行。输出显示在图8.1中：
- en: '[PRE0]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![figure](../Images/8-1.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-1.png)'
- en: Figure 8.1 A glimpse of the first few rows of traffic count data
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.1 交通计数数据的前几行的一瞥
- en: The shape of the data is `(4815504, 35)`, meaning we have 35 columns and close
    to 5 million observations. From the columns, we can tell that this isn’t a single
    time series. It is, in fact, lots of time series at various “count points,” that
    is, measurement locations. Measurements at each count point can be treated as
    a separate time series, but we also have the option to aggregate by region, local
    authority, or even different time periods. From our data dictionary, we can also
    tell that we will be interested in the `Pedal_cycles` column, which measures the
    number of bicycles observed in a measurement period.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的形状是 `(4815504, 35)`，这意味着我们有35列和接近500万的观测值。从列中，我们可以看出这不是一个单一的时间序列。实际上，它是由多个时间序列组成的，这些时间序列位于不同的“计数点”，即测量位置。每个计数点的测量可以被视为一个单独的时间序列，但我们也有按地区、地方当局或甚至不同时间段进行聚合的选项。从我们的数据字典中，我们还可以了解到我们将对`Pedal_cycles`列感兴趣，该列测量在测量期间观察到的自行车数量。
- en: Investigating time series completeness
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 调查时间序列的完整性
- en: 'Let’s examine the data to see how complete it is. First, we will look at missing
    data. The following code produces the output in figure 8.2:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查数据以了解其完整性。首先，我们将查看缺失数据。以下代码生成了图8.2中的输出：
- en: '[PRE1]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![figure](../Images/8-2.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-2.png)'
- en: Figure 8.2 Missing values per column in the traffic data
  id: totrans-149
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.2 交通数据中每列的缺失值
- en: 'It looks like the records are mostly complete, with only road names and lengths
    missing a significant amount. This might have something to do with the different
    road types since not all roads in the country, and therefore, in the dataset,
    necessarily have a name. We will leave them missing since we have no reason to
    believe those rows are erroneous. There is a small number of measurements missing,
    which we will assume can be filled with zeros with the following code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来记录大多是完整的，只是缺少了大量的道路名称和长度。这可能和不同的道路类型有关，因为并非该国所有的道路，以及因此数据集中的道路，都必须有名称。我们将保留这些缺失，因为我们没有理由相信这些行是错误的。有一些测量数据缺失，我们将假设可以用以下代码中的零来填充：
- en: '[PRE2]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For completeness, we can also investigate what regions are covered by the data
    by inspecting the `Region_name` column. The following code produces the output
    in figure 8.3:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，我们还可以通过检查 `Region_name` 列来调查数据覆盖的区域。以下代码生成了图8.3中的输出：
- en: '[PRE3]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![figure](../Images/8-3.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-3.png)'
- en: Figure 8.3 Distribution of regions in the traffic data
  id: totrans-155
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.3 交通数据中区域的分布
- en: It looks like the data covers England, Scotland, and Wales, as well as various
    regions in England. Before moving on with our investigation, let’s start building
    the diagram to document the analysis. Figure 8.4 shows the first step, in which
    we had to make a decision about missing values.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来数据覆盖了英格兰、苏格兰和威尔士，以及英格兰的各种地区。在我们继续调查之前，让我们开始构建图表来记录分析。图8.4显示了第一步，其中我们必须对缺失值做出决定。
- en: '![figure](../Images/8-4.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-4.png)'
- en: Figure 8.4 The first step in the analysis
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.4 分析的第一步
- en: 'Our next question is concerning granularity: What precisely does one row of
    data represent?'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来的问题是关于粒度：一行数据究竟代表什么？
- en: Investigating time series granularity
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 调查时间序列粒度
- en: It is important to establish what one row of our data represents. It is a measurement
    at a particular time and location, but what specific combination of columns makes
    a row unique? We can test this by counting the number of rows for the combination
    of columns we believe to be unique and verifying if that matches the number of
    rows in the entire dataset.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 建立我们数据中的一行代表什么非常重要。它是在特定时间和地点的测量，但是什么具体的列组合使一行独特？我们可以通过计算我们认为独特的列组合的行数来测试这一点，并验证它是否与整个数据集的行数相匹配。
- en: A note on composite primary keys
  id: totrans-162
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 关于复合主键的注意事项
- en: When multiple columns make a record unique, this is called a *composite primary
    key*. It is when uniqueness does not come from a single ID column but a combination
    of more than one column. For example, customer IDs might not be unique if multiple
    customer databases are combined. In that case, the customer ID and the source
    database name might be what makes a record unique.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 当多个列使记录独特时，这被称为 *复合主键*。这是唯一性不是来自单个ID列，而是来自多个列的组合。例如，如果多个客户数据库合并，客户ID可能不是唯一的。在这种情况下，客户ID和源数据库名称可能就是使记录独特的东西。
- en: This is another way in which foundational training can differ from the real
    world. In reality, databases often have complex structures, including composite
    primary keys.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这又是基础训练与现实世界不同的另一种方式。在现实中，数据库通常具有复杂的结构，包括复合主键。
- en: 'The unique key, in this case, must at least contain `Count_point_id`, the `Count_date`,
    and therefore also the `Year`. There is also an `hour` column, suggesting the
    data is at an hourly granularity. If we assume these columns are the composite
    key, we can count the unique combinations and verify that they match the row count:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，唯一键至少必须包含 `Count_point_id`、`Count_date` 以及因此也包含的 `Year`。还有一个 `hour` 列，表明数据是按小时粒度。如果我们假设这些列是复合键，我们可以计算唯一的组合并验证它们是否与行数相匹配：
- en: '[PRE4]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This gives us `2435120`, which is too few rows and suggests there is another
    column we haven’t taken into account. The fact that this number is roughly half
    of the data suggests the column we are looking for typically has two values, so
    for every hour at every location, there is also another kind of measurement. Looking
    at the columns, this could be the `Direction_of_travel`, meaning traffic is counted
    separately in both directions at each location. Let’s add that column to the key
    to see if it matches the number of rows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们带来了 `2435120`，行数太少，这表明我们还没有考虑到另一列。这个数字大约是数据的一半，这表明我们正在寻找的列通常有两个值，因此在每个地点每小时，也有另一种测量方式。查看列，这可能就是
    `Direction_of_travel`，意味着在每个地点的交通流量分别按两个方向计数。让我们将那一列添加到键中，看看它是否与行数匹配：
- en: '[PRE5]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This returns `4815480`, which is much closer to the number of rows, suggesting
    we have found the right combination of columns, but the data contains duplicates.
    Let’s investigate these. The following code finds duplicate keys and produces
    the output in figure 8.5:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回 `4815480`，这个数字与行数非常接近，这表明我们已经找到了正确的列组合，但数据中包含重复项。让我们调查这些重复项。以下代码找到重复键并生成图8.5中的输出：
- en: '[PRE6]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![figure](../Images/8-5.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-5.png)'
- en: Figure 8.5 Duplicate records with the same composite primary key
  id: totrans-172
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.5 具有相同复合主键的重复记录
- en: 'It looks like there are two locations with duplicate measurements on two dates.
    We want to ascertain whether the measurements are also duplicated or whether the
    rows are perfect duplicates. We do this by taking one of the keys as an example
    and looking at which values the duplicate rows differ in. The following code does
    this and produces the output in figure 8.6:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来有两个地点在两个日期上有重复的测量值。我们想知道这些测量值是否也重复，或者行是否是完全重复的。我们通过以一个键为例，查看重复行在哪些值上有所不同来完成这项工作。以下代码执行此操作，并在图8.6中产生输出：
- en: '[PRE7]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Finds a specific example of a duplicate'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 找到重复的一个特定例子'
- en: '#2 Uses the shift method to check whether values are equal in both rows'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用位移法检查两行中的值是否相等'
- en: '![figure](../Images/8-6.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-6.png)'
- en: Figure 8.6 Columns where values don’t match in the example duplicate rows
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.6 示例重复行中值不匹配的列
- en: 'This tells us that for that location and date, the columns that differ are
    the ones measuring how many vehicles passed by. Let’s look at the specific measurements
    to determine how different they are. The following code extracts these columns.
    The returned data contains many columns, and by default, they are not all shown.
    Even if we could show them all, which is possible to do, they wouldn’t fit horizontally
    on the screen without the need to scroll. One trick is to take a row or two of
    data and *transpose* it to show it as only one or two columns instead. We’ll do
    this here, and the output is shown in figure 8.7:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，对于那个地点和日期，不同的列是测量通过车辆数量的列。让我们查看具体的测量值，以确定它们有多大的不同。以下代码提取了这些列。返回的数据包含许多列，默认情况下它们并没有全部显示。即使我们能够显示所有列，这也是可能的，但它们在屏幕上无法水平显示，需要滚动。一个技巧是取一行或两行数据，并将其*转置*以显示为只有一或两列。我们在这里这样做，输出显示在图8.7中：
- en: '[PRE8]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![figure](../Images/8-7.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-7.png)'
- en: Figure 8.7 Side-by-side comparison of duplicate records
  id: totrans-182
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.7 相同记录的并列比较
- en: The values are quite different for the same combination of location and measurement
    date and time, so we are now confronted with a decision to make. What are our
    options when handling these duplicates?
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于相同的位置和测量日期时间的组合，值相当不同，因此我们现在面临一个决策。处理这些重复项时我们有哪些选择？
- en: Should we combine the values somehow? This would make sense if these were partial
    measurements, but we have no evidence of this, and the numbers are too similar.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否应该以某种方式合并值？如果这些是部分测量值，这将是合理的，但我们没有这方面的证据，而且数字太相似了。
- en: Is one of them newer data, making the other row obsolete, in which case we should
    drop the first row? This is possible, but if it’s the case, we have no way of
    knowing which would be the newer measurement apart from assuming the one that
    appears later is more recent. This feels like a strong assumption to make with
    no evidence.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其中一个是新数据，使得另一行变得过时，在这种情况下我们应该删除第一行吗？这是可能的，但如果是这样，我们除了假设出现较晚的那个更近之外，没有其他方法知道哪个是新的测量值。这感觉像是一个没有证据的强烈假设。
- en: We could drop these rows entirely, but this would introduce a gap into some
    of our time series, which is problematic for time series analysis.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以完全删除这些行，但这会在我们的时间序列中引入一个缺口，这对于时间序列分析是问题。
- en: We could average the counts across the two records. This preserves the time
    series and keeps our numbers in the right ballpark, but we are essentially making
    up data this way.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以在两个记录之间平均计数。这保留了时间序列，并使我们的数字保持在正确的范围内，但本质上我们是以这种方式制造数据。
- en: There is no correct answer here. Each choice has its own assumptions and consequences.
    We will err on the side of preserving the time series and go with the averaging
    approach. While this does make up measurements that were not actually recorded,
    these duplicates are a small enough percentage of the overall data not to make
    this a big problem.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有正确答案。每个选择都有自己的假设和后果。我们将倾向于保留时间序列，采用平均方法。虽然这确实补全了未实际记录的测量值，但这些重复值占整体数据的比例很小，不会造成大问题。
- en: To combine these duplicates, we can group our data by the composite key, creating
    one group per unique identifier and averaging the measurement rows. In most cases,
    since the keys are unique, we will be averaging a single row, leaving it unaffected.
    The only additional trick is to handle missing columns. Our road name and link
    length columns, which form part of the composite key, contain missing values.
    The `pandas` library in particular will not group the records correctly when some
    grouping columns are missing.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 为了合并这些重复项，我们可以通过复合键对数据进行分组，为每个唯一标识符创建一个组，并平均测量行。在大多数情况下，由于键是唯一的，我们将平均一行，使其不受影响。唯一的额外技巧是处理缺失列。我们的道路名称和链接长度列，作为复合键的一部分，包含缺失值。特别是`pandas`库在分组列缺失时无法正确分组记录。
- en: 'To avoid this, we will temporarily fill missing values with a placeholder,
    do the deduplication, and remove the placeholder values afterward. For the `Road_name`
    column, we can use the text “PLACEHOLDER,” but for the numeric columns, we need
    to find a value that doesn’t already appear in the data. Negative numbers work
    well here, but we should double-check that there aren’t already negative values
    for link length for whatever reason:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，我们将暂时用占位符填充缺失值，进行去重，然后删除占位符值。对于 `Road_name` 列，我们可以使用文本“占位符”，但对于数值列，我们需要找到一个在数据中尚未出现过的值。负数在这里效果很好，但我们应该检查是否有任何原因导致链接长度的负值：
- en: '[PRE9]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is 0.1 and 0.06, respectively, telling us that there are no negative
    values, and we can use one as a placeholder. The process for deduplication is
    therefore the following:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 输出分别是0.1和0.06，这告诉我们没有负值，我们可以使用其中一个作为占位符。因此，去重的流程如下：
- en: Replace missing values with placeholders.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用占位符替换缺失值。
- en: Group by all columns except the measurements.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按除测量值外的所有列进行分组。
- en: Within each group, which is mostly one row each, average the measurement values.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个组内，大多数情况下每行只有一个，计算测量值的平均值。
- en: In the grouped and aggregated dataset, replace placeholders with missing data
    again.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分组和汇总的数据集中，再次用缺失数据替换占位符。
- en: 'The following code does this and verifies that we have reduced the number of
    rows to the number of unique groups:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码执行此操作并验证我们已经将行数减少到唯一组的数量：
- en: '[PRE10]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The output is `(4815504, 35) (4815480, 35)`, where the second pair of values
    shows us that we have reduced the data down to one row per unique combination
    of columns in the composite primary key. This feels like a lot of work to remove
    a few duplicates, but the presence of duplicates can cause multiple problems with
    analysis, so it is best to address them.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是 `(4815504, 35) (4815480, 35)`，其中第二对值显示我们已经将数据减少到每个复合主键唯一组合的一行。这感觉像是为了去除几个重复项而做了很多工作，但重复项的存在可能会在分析中引起多个问题，因此最好解决它们。
- en: Figure 8.8 shows the latest version of our process, including the steps we have
    just taken to merge duplicate records.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8显示了我们的最新流程版本，包括我们刚刚采取的合并重复记录的步骤。
- en: '![figure](../Images/8-8.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-8.png)'
- en: Figure 8.8 The diagram of our analysis two steps in
  id: totrans-202
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.8 我们分析两步的示意图
- en: So far, we’ve investigated and handled missing data and ensured we understand
    its granularity. Now, it’s time to look at the coverage.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经调查并处理了缺失数据，并确保我们理解了其粒度。现在，是时候查看覆盖范围了。
- en: Investigating time series coverage
  id: totrans-204
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 调查时间序列覆盖范围
- en: 'When I say we will look at the coverage, in this instance, I mean the date
    range of values in the data. We’ve looked briefly at geographic coverage, and
    now we want to investigate the following:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说我们要查看覆盖范围时，在这个例子中，我的意思是数据中值的日期范围。我们简要地查看过地理覆盖范围，现在我们想要调查以下内容：
- en: What is the date range of the data in general?
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的日期范围一般是怎样的？
- en: Does the date range vary across smaller time series (e.g., per location)?
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期范围在较小的时序（例如，每个位置）中是否会有所变化？
- en: Are there consistent measurement intervals in the data?
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中是否存在一致的测量间隔？
- en: Are there gaps in any of the time series?
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何时间序列中是否存在缺失？
- en: 'Answers to these questions will determine not only the quality of our final
    analysis but also whether we need to focus on certain parts of the country purely
    because of a lack of consistent data coverage everywhere. First, let’s understand
    the date range of the data after we convert the `Count_date` column to be the
    right type. The output is shown in figure 8.9:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题的答案将不仅决定我们最终分析的质量，还决定我们是否需要仅仅因为全国数据覆盖不统一而专注于国家的某些部分。首先，让我们在将`Count_date`列转换为正确类型后，了解数据的日期范围。输出如图8.9所示：
- en: '[PRE11]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![figure](../Images/8-9.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-9.png)'
- en: Figure 8.9 The date range of the entire dataset
  id: totrans-213
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.9 整个数据集的日期范围
- en: The output of this code is that the first date encountered in the dataset is
    March 2000, and the latest is November 2022\. We have 20-year coverage, though
    it remains to be seen whether this is consistent across measuring locations. We
    want to know
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的输出显示，数据集中遇到的第一天是2000年3月，最后一天是2022年11月。我们有20年的覆盖范围，尽管还需要看这是否在测量地点上是一致的。我们想知道
- en: Does every location have 20 years of data?
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个位置都有20年的数据吗？
- en: Are there gaps in any of the time series of the different locations?
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同位置的时间序列中是否存在任何空缺？
- en: 'One way to investigate this is to calculate the first and last date per location,
    calculate the difference, and investigate the distribution of this difference
    number. This will tell us how long each location-specific time series is at a
    glance. The following code achieves this, and the output is shown in figure 8.10:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 调查这个问题的一种方法是为每个位置计算第一个和最后一个日期，计算它们之间的差异，并研究这个差异数字的分布。这将让我们一眼就能知道每个位置特定时间序列的长度。以下代码实现了这一点，输出如图8.10所示：
- en: '[PRE12]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![figure](../Images/8-10.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-10.png)'
- en: Figure 8.10 Coverage (in years) by location
  id: totrans-220
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.10 各位置覆盖范围（按年）
- en: 'This table tells us a few important things:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表格告诉我们一些重要的事情：
- en: '*Coverage varies a lot across locations.* There are locations with a single
    day’s worth of measurements and some that have data for the entire 22-year period.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*覆盖范围在位置之间差异很大。* 有些位置只有一天的测量数据，而有些位置则在整个22年期间都有数据。'
- en: '*Measurement dates vary.* This wasn’t obvious looking at the data initially,
    but it turns out there is no consistent start or end point for any of the measurement
    time series.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*测量日期各不相同。* 初始查看数据时，这并不明显，但结果发现，任何测量时间序列都没有一致的开始或结束点。'
- en: 'To get a better sense of the distribution of these values, let’s create a histogram.
    The following code produces the histogram in figure 8.11:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解这些值的分布，让我们创建一个直方图。以下代码生成了图8.11中的直方图：
- en: '[PRE13]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![figure](../Images/8-11.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-11.png)'
- en: Figure 8.11 Histogram showing coverage in years across different locations
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.11 显示不同位置覆盖范围的直方图
- en: 'It looks like locations overwhelmingly have a coverage of near zero. That is,
    most locations only have one day of measurement to their name. This presents a
    problem because the data in those locations does not constitute much of a time
    series, except for hourly measurements on a single day. That’s not enough data
    to draw much insight from. Again, we are facing the following choice:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来，位置绝大多数的覆盖范围接近于零。也就是说，大多数位置只有一天的测量数据。这带来一个问题，因为那些位置的数据并不构成一个真正的时间序列，除了单日的小时测量数据。这些数据不足以得出很多见解。再次，我们面临以下选择：
- en: Do we include locations with only one day of measurements? Doing so means we
    don’t lose a lot of coverage, but we also can’t answer questions about increasing
    trends in those areas.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否包括只有一天测量数据的位置？这样做意味着我们不会失去很多覆盖范围，但我们也无法回答那些地区增长趋势的问题。
- en: Do we focus only on locations with enough data? This will mean we have more
    robust results but for far fewer locations and areas.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否只关注数据量充足的位置？这意味着我们将有更稳健的结果，但位置和区域将大大减少。
- en: This is a good decision point to remind ourselves of our framework. We want
    to be results driven and have the research question at the forefront of our minds.
    We will likely need to follow up our recommendations with further work and certainly
    wouldn’t want to base any infrastructure decisions on sparse data. On that basis,
    we will seek to trim down the data to keep only the time series that have the
    most data, the highest coverage, and no gaps.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个提醒我们框架的好决策点。我们希望以结果为导向，并将研究问题置于我们思维的优先位置。我们可能需要进一步的工作来跟进我们的建议，并且绝对不希望基于稀疏的数据做出任何基础设施决策。基于这一点，我们将努力减少数据量，只保留数据量最大、覆盖范围最高且没有空缺的时间序列。
- en: Note  This is one of those decisions that will drastically affect how different
    our solutions will be. If your results don’t match mine, do not assume it is because
    you have made a mistake. We might have just made different decisions, leading
    to different results. As long as those decisions and their key assumptions are
    documented, different results may be equally valuable and useful.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这是那些将极大地影响我们解决方案差异性的决策之一。如果你的结果与我的不符，不要假设是你犯了错误。我们可能只是做出了不同的决策，导致了不同的结果。只要这些决策及其关键假设得到记录，不同的结果可能同样有价值且有用。
- en: Whenever we investigate missing data, we want to know whether there are any
    patterns in the gaps. Is any specific factor causing a part of our data to be
    missing? In this instance, we are working with low coverage instead of missing
    data, but the idea holds. Let’s investigate whether there are certain areas of
    the country that have less coverage. Why could this be?
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们调查缺失数据时，我们想知道是否存在任何模式在缺口中。是否有任何特定因素导致我们的一部分数据缺失？在这种情况下，我们处理的是低覆盖率而不是缺失数据，但这个想法是适用的。让我们调查是否有某些地区的覆盖率较低。这可能是为什么？
- en: Some locations may have been added to the “traffic measurement program” later
    than others.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些地点可能比其他地点晚些时候被添加到“交通测量计划”中。
- en: There might be logistic difficulties with measuring in certain locations.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在某些地点进行测量可能存在物流困难。
- en: New roads have been built around newly built housing estates, and measurements
    could not have started at an earlier date.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新建住宅区周围已建成新道路，测量可能无法在更早的日期开始。
- en: 'Whatever the reason, we want to know whether low coverage is randomly distributed
    across the country or whether there is a pattern we should be aware of. Let’s
    use the table from figure 8.10 to focus on location points with only one day of
    data. We will drop duplicate rows for the same location ID because we want to
    look at how they are distributed and not at their granular measurements. Figure
    8.12 shows the number of locations with only one day of coverage, split by region,
    as obtained by the following code:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 无论原因如何，我们想知道低覆盖率是否在全国范围内随机分布，或者是否存在我们应该注意的模式。让我们使用图8.10中的表格来关注只有一天数据的地点点。我们将删除相同位置ID的重复行，因为我们想了解它们的分布情况，而不是它们的细粒度测量。以下代码显示了按地区划分的只有一天覆盖率的地点数量，如图8.12所示：
- en: '[PRE14]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#1 Locations with only one day of measurements are referred to as "zero" because
    the difference between the first and last measurement dates is zero.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 仅有一日测量数据的地点被称为“零”，因为首次和最后测量日期之间的差异为零。'
- en: '![figure](../Images/8-12.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-12.png)'
- en: Figure 8.12 Number of locations with one day of data across regions
  id: totrans-241
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.12 按地区划分的只有一天数据的地点数量
- en: There is variation here, but we must not fall into the trap of using absolute
    numbers to make a judgment. It might simply be that the South East has more single-day
    locations than Wales because there are more location points. Let’s calculate these
    as a percentage of the total number of locations in each region to get a fair
    comparison.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这里存在差异，但我们不能陷入使用绝对数字做出判断的陷阱。可能只是因为东南部比威尔士有更多的单日地点，因为地点点更多。让我们将这些计算为每个地区总地点数的百分比，以获得公平的比较。
- en: 'First, we calculate the number of location points by region and then use that
    number to calculate the numbers in figure 8.12 as a percentage. The following
    code calculates the locations by region, as shown in figure 8.13:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们按地区计算位置点的数量，然后使用这个数量来计算图8.12中的数字作为百分比。以下代码按地区计算位置，如图8.13所示：
- en: '[PRE15]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![figure](../Images/8-13.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-13.png)'
- en: Figure 8.13 Number of count points by region
  id: totrans-246
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.13 按地区划分的计数点数量
- en: 'The following code joins the two tables together and produces the output table
    shown in figure 8.14:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将两个表合并在一起，并生成如图8.14所示的输出表：
- en: '[PRE16]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![figure](../Images/8-14.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-14.png)'
- en: Figure 8.14 Number of total locations and single-day locations per region
  id: totrans-250
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.14 每个地区的总地点数和单日地点数
- en: If there was a real problem with single-day locations being limited to only
    certain regions, we would find considerable variation in this table. As it stands,
    the percentage of locations that only have data on a single date is consistent
    across the regions, with only Wales and London being noticeably lower. We could
    investigate this much deeper, but in the spirit of getting to our result, we will
    assume we are satisfied that the existence of single-day locations is just something
    that happens everywhere and is not something to address directly.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 如果单日地点真的存在仅限于某些地区的问题，我们会在表中发现相当大的变化。目前，只有威尔士和伦敦的单一日期数据的地点比例明显较低。我们可以对此进行更深入的调查，但本着尽快得到结果的精神，我们将假设我们对单日地点的存在感到满意，这是普遍发生的事情，而不是直接要解决的问题。
- en: Now that we have looked at missing data, granularity, and coverage, let’s turn
    our attention to gaps. Gaps are a problem when it comes to time series, so we
    want to reduce our data to locations where we can get a longer and complete time
    series.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经查看了缺失数据、粒度和覆盖范围，让我们将注意力转向缺口。在时间序列中，缺口是一个问题，因此我们希望将我们的数据减少到我们可以获得更长和完整时间序列的地点。
- en: Investigating gaps in time series
  id: totrans-253
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 调查时间序列中的缺口
- en: We’ve established that different locations have tracked data since a different
    starting point and for varying lengths of time. To identify gaps, we can’t just
    count the number of unique dates seen at a location; we need to calculate the
    difference between each encountered date and the previously encountered date and
    flag any cases with more than a one-day gap.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经确定，不同的地点从不同的起点开始跟踪数据，并且持续时间不同。为了识别缺口，我们不能仅仅计算一个地点看到的唯一日期的数量；我们需要计算每个遇到的日期与之前遇到的日期之间的差异，并标记任何超过一天缺口的案例。
- en: 'Let’s first look at the number of data points per location per date to get
    an idea whether there might be continuity problems. The following code calculates
    this and produces the table in figure 8.15:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看每个地点每个日期的数据点数量，以了解是否可能存在连续性问题。以下代码计算了这一点，并在图8.15中产生了表格：
- en: '[PRE17]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![figure](../Images/8-15.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-15.png)'
- en: Figure 8.15 Number of data points per location ID and per date
  id: totrans-258
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.15 每个地点ID和日期的数据点数量
- en: This table shows us something important. We made an incorrect assumption that
    measurements are taken daily across a year. The data is daily in its granularity,
    but there is only one day of measurement data for each year. We hadn’t sliced
    the data in the right way before to find this earlier, but this gives us a clearer
    picture of what we have.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表格向我们展示了重要的一点。我们错误地假设了一年中每天都会进行测量。数据在粒度上是每天的，但每年只有一天的数据。我们之前没有正确地切割数据以找到这一点，但这一点为我们提供了一个更清晰的了解我们所拥有的。
- en: 'To understand whether there might be gaps, first, we can check how many unique
    values there are for the `Year` column in each location. Those that have 23 are
    the ones that have measurements in every year between 2000 and 2022, inclusive.
    We will focus only on locations that have at least 10 years of data, but that’s
    somewhat arbitrary. We could also restrict time series that are complete for the
    most recent 5 to 10 years. Here, we’ll choose completeness over recency, and the
    following code calculates this and outputs the result in figure 8.16:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解是否存在缺口，首先，我们可以检查每个地点的`Year`列中有多少唯一值。那些有23个的是在2000年至2022年（包括2022年）之间每年都有测量的地点。我们将只关注至少有10年数据的地点，但这有些随意。我们也可以限制最近5到10年内数据完整的时序。在这里，我们将选择完整性而不是最近性，以下代码计算了这一点，并在图8.16中输出了结果：
- en: '[PRE18]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![figure](../Images/8-16.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-16.png)'
- en: Figure 8.16 Distribution of the number of unique calendar years per location
  id: totrans-263
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.16 每个地点的独特日历年分布
- en: 'Let’s also look at the time series for the first of those locations to get
    a sense of what a complete time series looks like in our data. The following code
    produces the plot in figure 8.17:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也看看这些地点中的第一个地点的时间序列，以了解我们的数据中完整时间序列是什么样的。以下代码生成了图8.17中的图表：
- en: '[PRE19]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![figure](../Images/8-17.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-17.png)'
- en: Figure 8.17 An example time series for location 26010
  id: totrans-267
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.17 位置26010的一个示例时间序列
- en: This is the total number of vehicles seen at a particular location on the day
    counting took place each year. There are already some interesting aspects, such
    as the dip in 2020 due to the COVID-19 lockdowns.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这是每年计数当天在特定地点看到的车辆总数。已经有一些有趣的特点，例如由于COVID-19封锁导致的2020年的下降。
- en: 'The next step is to filter our location list to only the time series that have
    no gaps. To do this, we will ensure our data is sorted and create a temporary
    column to capture the year of the previous row so that we can find instances where
    the gap between a row and the previous one is more than a year. The following
    code adds these additional columns, and a snapshot of the new `gaps` DataFrame
    is shown in figure 8.18:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是过滤我们的位置列表，只保留没有差距的时间序列。为此，我们将确保我们的数据已排序，并创建一个临时列来捕获前一年的年份，这样我们就可以找到行与前一行的差距超过一年的实例。以下代码添加了这些额外的列，新的`gaps`
    DataFrame的快照显示在图8.18中：
- en: '[PRE20]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![figure](../Images/8-18.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-18.png)'
- en: Figure 8.18 A snapshot of the new `gaps` DataFrame, with important rows highlighted
  id: totrans-272
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.18 显示了新的`gaps` DataFrame的快照，其中突出显示了一些重要的行
- en: These new columns help us identify places where the previously encountered measurements
    were from more than one year ago. In the highlighted section of figure 8.18, we
    can notice that there was no measurement at location ID 501 in the year 2018,
    so the gap between rows is two years. When the next location ID is encountered,
    the gap can become negative when the last year of the previous location ID is
    later than the first year of the next location ID.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这些新列帮助我们识别之前遇到的测量数据来自一年以上的地方。在图8.18的高亮部分，我们可以注意到2018年位置ID 501没有测量数据，因此行之间的差距是两年。当遇到下一个位置ID时，如果前一个位置ID的最后一年晚于下一个位置ID的第一年，差距可能会变成负数。
- en: To identify gaps, we could simply filter this dataset down to where the `diff`
    column is greater than 1\. However, we might encounter edge cases where the next
    location ID happens to start two years after the previous one, and we would erroneously
    mark it as having a gap.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别差距，我们可以简单地过滤这个数据集，使得`diff`列大于1。然而，我们可能会遇到边缘情况，即下一个位置ID恰好在前一个ID之后两年开始，我们会错误地将其标记为存在差距。
- en: 'To make sure we filter gaps properly, we also need to track the location ID
    of the previous column so that when we encounter a gap greater than one year,
    we also check whether the location ID is still the same. The following code does
    this, and some of the rows with problematic gaps are shown in figure 8.19:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们正确地过滤差距，我们还需要跟踪前一个列的位置ID，这样当我们遇到超过一年的差距时，我们也可以检查位置ID是否仍然相同。以下代码执行此操作，并显示了图8.19中一些有问题的差距行：
- en: '[PRE21]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![figure](../Images/8-19.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-19.png)'
- en: Figure 8.19 Some of the rows representing problematic gaps in the time series
  id: totrans-278
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.19 显示了时间序列中一些表示问题差距的行
- en: 'We can now use this `gaps` DataFrame to find all the unique location IDs that
    we want to exclude from our final time series data. This is done with the following
    code. A part of the resulting DataFrame is shown in figure 8.20:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用这个`gaps` DataFrame来找到我们想要从最终时间序列数据中排除的所有独特位置ID。这是通过以下代码完成的。结果DataFrame的一部分显示在图8.20中：
- en: '[PRE22]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![figure](../Images/8-20.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-20.png)'
- en: Figure 8.20 A snapshot of rows from the filtered traffic data
  id: totrans-282
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.20 显示了过滤后的交通数据行的快照
- en: 'Figure 8.20 now shows filtered rows from the original, raw `traffic` DataFrame.
    It contains only location IDs that have at least 10 years of continuous, gap-free
    data. Let’s now aggregate this to actually be a time series summarized at a location
    level so that we better understand how much data we are left with. The following
    code performs this aggregation, and figure 8.21 shows the first few rows of our
    newly aggregated data:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.20 现在显示了从原始的原始`traffic` DataFrame中过滤出的行。它只包含至少有10年连续无差距数据的位置ID。现在让我们将此聚合为在位置级别汇总的时间序列，以便我们更好地了解我们剩下多少数据。以下代码执行此聚合，图8.21显示了新聚合数据的前几行：
- en: '[PRE23]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![figure](../Images/8-21.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-21.png)'
- en: Figure 8.21 A snapshot of filtered traffic data now aggregated as an annual
    time series
  id: totrans-286
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.21 显示了现在按年度时间序列聚合的过滤交通数据的快照
- en: This is now one row per location ID and measurement date. As the top of figure
    8.21 shows, we still have data for just over 1,400 unique location IDs. These
    are now all-time series where there are measurements every year, so it is a time
    series with no gaps.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 现在每一行对应一个位置ID和测量日期。如图8.21顶部所示，我们仍然有超过1,400个独特位置ID的数据。这些现在都是每年都有测量的时间序列，因此这是一个没有差距的时间序列。
- en: 'To be precise, we have a time series showing the total number of vehicles that
    passed a count point in a single day in a particular year. There is only one day
    where measurements take place each year. This is an important detail because it
    leads to some caveats:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 要精确地说，我们有一个时序数据，显示了在特定年份某一天通过计数点的车辆总数。每年只有一天进行测量。这是一个重要的细节，因为它导致了一些注意事项：
- en: Figure 8.21 shows that measurements are not taken on the same day each year.
    If we want to investigate traffic patterns over time, the measurements should
    at least be taken around the same time of year because, otherwise, we might be
    comparing summer traffic to winter traffic, for example. One option is to keep
    only time series where the measurements are consistently taken around the same
    time of year.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图8.21显示，每年的测量不是在同一天进行的。如果我们想调查交通模式随时间的变化，测量至少应该在每年的同一时间进行，否则我们可能会比较夏季交通与冬季交通，例如。一个选择是只保留每年在相同时间进行一致测量的时序数据。
- en: Following this, whichever part of the year our measurements are taken from will
    introduce bias. Cycling patterns for locations where only winter measurements
    exist might not be helpful when cycling is likely reduced everywhere around that
    time of year.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此后，无论我们从哪一年的哪个部分进行测量，都会引入偏差。对于只有冬季测量数据的地点，在当年那个时间骑车可能减少，因此骑车模式可能没有帮助。
- en: If the date *is* the same each year, that might actually be a problem because
    we might be comparing different days of the week, even weekdays to weekends.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果每年的日期都相同，这实际上可能是一个问题，因为我们可能会比较不同星期几的日期，甚至工作日与周末。
- en: 'Let’s check that last point. What days of the week is the data spread across?
    The following code investigates this, and the output is shown in figure 8.22:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查最后一个观点。数据分布在星期几？以下代码调查了这一点，输出结果如图8.22所示：
- en: '[PRE24]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![figure](../Images/8-22.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/8-22.png)'
- en: Figure 8.22 The percentage of rows across different days of the week
  id: totrans-295
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.22 不同星期几的行百分比
- en: This tells us that roughly 20% of rows are spread across Tuesday to Friday,
    with slightly less on Mondays. Because we are counting days of the week starting
    with Monday as zero, we now also know there are no weekends in our remaining data,
    so that’s one concern we’ve alleviated.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，大约20%的行分布在星期二到星期五，而星期一略少。因为我们是从星期一开始计算一周的天数，所以我们也知道剩余数据中没有周末，这样就缓解了一个担忧。
- en: We can still use this data as a proxy for traffic over time to help us hone
    in on locations that have interesting cycling traffic patterns, but we must be
    fully aware of the limitations, especially when presenting results to our stakeholders.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然可以使用这些数据作为交通随时间变化的代理，帮助我们聚焦于具有有趣骑车交通模式的地点，但我们必须充分了解局限性，尤其是在向利益相关者展示结果时。
- en: Before moving on to the analysis of these time series, our final step is to
    see what would happen if we were to keep only time series where every measurement
    was made in the same month each year.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续分析这些时序数据之前，我们的最后一步是看看如果我们只保留每年每月都进行测量的时序数据会发生什么。
- en: Finding time series recorded at the same time each year
  id: totrans-299
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 找到每年在同一时间记录的时序数据
- en: 'The following code identifies the location points where measurements were only
    ever made in the same month every year. Figure 8.23 shows the output:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码识别了每年仅在相同月份进行测量的位置点。图8.23显示了输出结果：
- en: '[PRE25]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![figure](../Images/8-23.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/8-23.png)'
- en: Figure 8.23 Location IDs where only the same month was encountered
  id: totrans-303
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.23 仅遇到相同月份的位置ID
- en: Keeping this filter would halve our data but still leave us just under 700 time
    series. We should verify that the time series associated with these location IDs
    do indeed only contain the same month. We’ll take the first location ID as an
    example, but in reality, we’d want to spot-check a few cases. The following code
    examines the time series for the count point with ID 900056, and the output is
    shown in figure 8.24.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 保留这个过滤器将使我们的数据减半，但仍然留下不到700个时间序列。我们应该验证与这些位置ID相关的时间序列确实只包含相同的月份。我们将以第一个位置ID为例，但在现实中，我们可能想要抽查几个案例。以下代码检查了ID为900056的计数点的时序数据，输出结果如图8.24所示。
- en: '[PRE26]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![figure](../Images/8-24.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/8-24.png)'
- en: Figure 8.24 Time series data for location ID 900056
  id: totrans-307
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.24 位置ID 900056的时序数据
- en: Figure 8.24 shows that for all 13 years that traffic was counted at location
    900056, it was always done in May. This makes the measurements more comparable
    year on year. Let’s now export this data to an intermediate file to separate the
    cleaning process from the analysis.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.24显示，在900056位置对交通进行了13年的计数，总是在5月份进行。这使得测量结果年复一年更具可比性。现在，让我们将此数据导出到一个中间文件中，以将清理过程与分析过程分开。
- en: Exporting only complete time series data
  id: totrans-309
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 仅导出完整的时间序列数据
- en: Exporting an intermediate version of your data is a good habit to get into,
    especially if you have a lot of raw data, and cleaning and transforming it takes
    a bit of time.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 导出数据的中间版本是一个好习惯，特别是如果你有大量的原始数据，并且清理和转换它需要一些时间。
- en: 'We want to keep the raw version of the data filtered down to just the location
    IDs we have identified. We’ll use the Parquet format as it is compact and preserves
    data types. This file will be the starting point for the analysis in chapter 9\.
    The following code creates this exported file:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望将原始数据过滤到仅包含我们已识别的位置ID。我们将使用Parquet格式，因为它紧凑且保留数据类型。此文件将是第9章分析的起点。以下代码创建了这个导出文件：
- en: '[PRE27]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 8.4.2 Project progress so far
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.2 到目前为止的项目进度
- en: 'Before we move on to the analysis portion of the project in chapter 9, let’s
    recap what we have achieved in this chapter, which was the data preparation part
    of the project. Here’s what we know about our data:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入第9章项目分析部分之前，让我们回顾一下本章我们所取得的成果，这是项目的数据准备部分。以下是关于我们数据的了解：
- en: One row represents measurements taken at a single location, in a single hour
    on a particular date in a particular direction. A combination of these columns
    makes a record unique.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一行代表在特定日期特定方向的单个位置上进行的测量。这些列的组合使记录独特。
- en: For every location, we have a maximum of one unique day of measurements for
    a given calendar year.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个位置，我们都有一个给定日历年度内最多一天的唯一测量日。
- en: The number of years where measurements were taken varies significantly across
    location IDs. This means there is both inconsistent coverage and gaps in many
    of our time series.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同的位置ID之间，测量年份的数量差异很大。这意味着我们的时间序列数据存在不一致的覆盖范围和许多缺口。
- en: Apart from missing roughly half of the road name and length data, there are
    no significant missing values.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了大约一半的道路名称和长度数据缺失外，没有显著的缺失值。
- en: To mitigate some of the problems, we have extracted only locations with the
    longest and most complete time series to focus on in part 2 of our analysis. Figure
    8.25 shows the analysis steps we have taken and the decisions we have made so
    far.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻一些问题，我们只提取了最长和最完整的时间序列位置，以便在分析的第二部分中集中关注。图8.25显示了我们所采取的分析步骤和到目前为止所做的决定。
- en: '![figure](../Images/8-25.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-25.png)'
- en: Figure 8.25 The latest diagram of our steps, including investigating coverage
    and handling gaps
  id: totrans-321
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.25 我们步骤的最新图示，包括调查覆盖范围和处理缺口
- en: This diagram documents our process so far, and we will use the output of this
    chapter, a filtered version of the raw traffic data, as the starting point for
    the analysis in chapter 9.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 此图展示了我们到目前为止的过程，我们将使用本章的输出，即原始交通数据的过滤版本，作为第9章分析的起点。
- en: Summary
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Time series data can seem simple yet contain complexity and hidden value.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列数据可能看似简单，但其中包含复杂性和隐藏的价值。
- en: Understanding how to manipulate time data broadens your data analysis toolkit.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解如何操作时间数据可以扩展你的数据分析工具集。
- en: The granularity of the available time series determines the analysis we can
    perform. For example, daily patterns cannot be determined from monthly data.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用时间序列的粒度决定了我们可以执行的分析。例如，无法从月度数据中确定每日模式。
- en: Time series analysis works best if there are no gaps in the data.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果数据中没有缺口，时间序列分析效果最佳。
- en: If there are gaps, they need to be handled either by smoothing over them or
    estimating what the values in the gaps should be.*
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果存在差距，需要通过平滑处理或估计这些差距中的值来处理*。
