- en: Part II. Getting Your Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part of the book, we start our journey along the dataviz toolchain (see
    [Figure II-1](#toolchain_scrape)), beginning with a couple of chapters on how
    to get your data if it hasn’t been provided for you.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 5](ch05.xhtml#chapter_getting_data) we see how to get data off the
    web, using Python’s Requests library to grab web-based files and consume RESTful
    APIs. We also see how to use a couple of Python libraries that wrap more complex
    web APIs, namely Twitter (with Python’s Tweepy) and Google Docs. The chapter ends
    with an example of lightweight [web scraping](https://oreil.ly/fjBEA) with the
    Beautiful Soup library.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 6](ch06.xhtml#chapter_heavy_scraping) we use Scrapy, Python’s industrial-strength
    web scraper, to get the Nobel Prize dataset we’ll be using for our web visualization.
    With this *dirty* dataset to hand, we’re ready for the next part of the book,
    [Part III](part03.xhtml#part_clean_explore).
  prefs: []
  type: TYPE_NORMAL
- en: '![dpj2 p223](assets/dpj2_p223.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure II-1\. Our dataviz toolchain: getting the data'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can find the code for this part of the book at the [book’s GitHub repo](https://github.com/Kyrand/dataviz-with-python-and-js-ed-2).
  prefs: []
  type: TYPE_NORMAL
