- en: Chapter 6\. Handling Missing Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。处理缺失数据
- en: 'Missing data is a common occurrence in data analysis. In the age of big data,
    many authors and even more practitioners treat it as a minor annoyance that is
    given scant thought: just filter out the rows with missing data—if you go from
    12 million rows to 11 million, what’s the big deal? That still leaves you with
    plenty of data to run your analyses.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据分析中，缺失数据是常见的。在大数据时代，许多作者甚至更多的从业者将其视为一个次要的困扰，几乎没有太多思考：只需过滤掉缺失数据的行——如果你从1200万行减少到1100万行，那有什么大不了的呢？这仍然为您提供了足够的数据来运行您的分析。
- en: Unfortunately, filtering out the rows with missing data can introduce significant
    biases in your analysis. Let’s say that older customers are more likely to have
    missing data, for example because they are less likely to set up automated payments;
    by filtering these customers out you would bias your analysis toward younger customers,
    who would be overrepresented in your filtered data. Other common methods to handle
    missing data, such as replacing them by the average value for that variable, also
    introduce biases of their own.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，过滤掉含有缺失数据的行可能会在你的分析中引入显著的偏差。比如说，老年客户更有可能存在缺失数据，因为他们较少设置自动付款；如果过滤这些客户，你的分析就会偏向于年轻客户，在过滤数据中会过度代表他们。其他处理缺失数据的常见方法，比如用该变量的平均值替换，也会引入它们自己的偏差。
- en: Statisticians and methodologists have developed methods that have much smaller
    or even no bias. These methods have not been adopted broadly by practitioners
    yet, but hopefully this chapter will help you get ahead of the curve!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学家和方法学家已经开发出了方法，这些方法的偏差要小得多，甚至没有偏差。然而，这些方法尚未被广泛采纳，但希望本章可以帮助您走在前列！
- en: 'The theory of missing values is rooted in statistics and can easily get very
    mathematical. To make our journey in this chapter more concrete, we’ll work through
    a simulated data set for AirCnC. The business context is that the marketing department,
    in an effort to better understand customer characteristics and motivations, has
    sent out by email a survey to a sample of 2,000 customers in three states and
    collected the following information:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值理论根植于统计学，可能会变得非常数学化。为了使本章节的学习更具体化，我们将通过一个模拟数据集来探讨AirCnC。在业务背景下，市场部门为了更好地了解客户特征和动机，向三个州的2,000名客户发送了一封调查问卷，并收集了以下信息：
- en: Demographic characteristics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口统计特征
- en: Age
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄
- en: Gender
  id: totrans-7
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性别
- en: State (selecting customers from only three states, which for convenience we’ll
    call A, B, and C)
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 州（只选择三个州的客户，为了方便起见我们将它们称为A、B和C）
- en: Personality traits
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个性特质
- en: Openness
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开放性
- en: Extraversion
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外向性
- en: Neuroticism
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经质
- en: Booking amount
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预订金额
- en: To keep things simpler, we’ll assume that the demographic variables are all
    causes of booking amount and unrelated to each other ([Figure 6-1](#the_demographic_variables_cause_booking)).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化问题，我们假设人口统计变量都是预订金额的原因，并且彼此无关（见[图 6-1](#the_demographic_variables_cause_booking)）。
- en: '![The demographic variables cause booking amount](Images/BEDA_0601.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![人口统计变量导致预订金额](Images/BEDA_0601.png)'
- en: Figure 6-1\. The demographic variables cause booking amount
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-1。人口统计变量导致预订金额
- en: Note
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'As we discussed in [Chapter 2](ch02.xhtml#understanding_behavioral_data), when
    I say that demographic variables such as *Gender* and *Extraversion* are causes
    of *BookingAmount*, I mean two things: first that they are exogenous variables
    (i.e., variables that are primary causes for our purposes), and second that they
    are predictors of *BookingAmount* because of causal effects that are heavily mediated
    as well as moderated by social phenomena.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第2章](ch02.xhtml#understanding_behavioral_data)中讨论的，当我说人口统计变量如*性别*和*外向性*是*预订金额*的原因时，我指的是两件事情：首先，它们是外生变量（即在我们研究中是主要原因），其次，它们由于社会现象的因果效应而成为*预订金额*的预测因素。
- en: For instance, the effect of *Gender* is probably mediated by the person’s income,
    occupation, and family status, among many others. In that sense, it would be more
    accurate to say that *Gender* is a cause of causes of *BookingAmount*. However,
    it is important to note that this effect is *not* confounded, and as such it is
    truly causal.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，*性别*的影响可能通过个人的收入、职业和家庭状况等多种因素进行中介。从这个意义上讲，更准确地说*性别*是*预订金额*的原因的原因。然而，重要的是要注意，这种效应并没有混淆，因此它是真正的因果关系。
- en: 'The flow of this chapter will follow the steps you would take when facing a
    new data set: first, we’ll visualize our missing data, to get a rough sense of
    what’s going on. Then, we’ll learn how to diagnose missing data and see the classification
    developed by the statistician Donald Rubin, which is the reference in the matter.
    The last three sections will show how to handle each one of the categories in
    that classification.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的流程将遵循您在面对新数据集时所采取的步骤：首先，我们将可视化缺失数据，以了解大致情况。然后，我们将学习如何诊断缺失数据，并看到由统计学家唐纳德·鲁宾开发的分类，这是参考资料。最后三节将展示如何处理该分类中的每一类。
- en: Unfortunately for Python users, the excellent R packages that we’ll be using
    don’t have direct Python counterparts. I’ll do my best to show you alternatives
    and workarounds in Python, but the code will be significantly longer and less
    elegant. Sorry!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Python用户来说，不幸的是，我们将要使用的出色R包没有直接的Python对应包。我将尽力向您展示Python中的替代方法和解决方法，但代码将会显著更长，不那么优雅。抱歉！
- en: Data and Packages
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据和包
- en: 'One of the luxuries of using simulated data is that we know the true values
    for the missing data. The [GitHub folder for this chapter](https://oreil.ly/BehavioralDataAnalysisCh6)
    contains three data sets ([Table 6-1](#variables_in_our_dat)):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模拟数据的一个好处是我们知道缺失数据的真实值。[本章的GitHub文件夹](https://oreil.ly/BehavioralDataAnalysisCh6)
    包含三个数据集（[表 6-1](#variables_in_our_dat)）：
- en: The complete data for our four variables
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们四个变量的完整数据
- en: The “available” data where some values are missing for some of the variables
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “可用”数据中某些变量的一些值缺失
- en: A secondary data set of auxiliary variables that we’ll use to complement our
    analysis
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 辅助变量的辅助数据集，我们将使用它来补充我们的分析
- en: Table 6-1\. Variables in our data
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 表6-1\. 我们数据中的变量
- en: '|  | Variable description | chap6-complete_data.csv | chap6-available_data.csv
    | chap6-available_data_supp.csv |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  | 变量描述 | chap6-complete_data.csv | chap6-available_data.csv | chap6-available_data_supp.csv
    |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| *Age* | Age of customer | Complete | Complete |  |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| *年龄* | 顾客年龄 | 完整 | 完整 |  |'
- en: '| *Open* | Openness psychological trait, 0-10 | Complete | Complete |  |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| *开放度* | 开放度心理特征，0-10 | 完整 | 完整 |  |'
- en: '| *Extra* | Extraversion psychological trait, 0-10 | Complete | Partial |  |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| *额外* | 外向性心理特征，0-10 | 完整 | 部分 |  |'
- en: '| *Neuro* | Neuroticism psychological trait, 0-10 | Complete | Partial |  |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| *神经* | 神经质心理特征，0-10 | 完整 | 部分 |  |'
- en: '| *Gender* | Categorical variable for customer gender, F/M | Complete | Complete
    |  |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| *性别* | 顾客性别的分类变量，F/M | 完整 | 完整 |  |'
- en: '| *State* | Categorical variable for customer state of residence, A/B/C | Complete
    | Partial |  |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| *州* | 顾客居住州的分类变量，A/B/C | 完整 | 部分 |  |'
- en: '| *Bkg_amt* | Amount booked by customer | Complete | Partial |  |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| *预订金额* | 顾客预订金额 | 完整 | 部分 |  |'
- en: '| *Insurance* | Amount of travel insurance purchased by customer |  |  | Complete
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| *保险* | 顾客购买的旅行保险金额 |  |  | 完整 |'
- en: '| *Active* | Numeric measure of how active the customer bookings are |  |  |
    Complete |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| *活跃度* | 顾客预订活跃程度的数值测量 |  |  | 完整 |'
- en: 'In this chapter, we’ll use the following packages in addition to the common
    ones:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，除了常用的包外，我们还将使用以下包：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Visualizing Missing Data
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化缺失数据
- en: By definition, missing data is hard to visualize. Univariate methods (i.e.,
    one variable at a time) will only get us so far, so we’ll mostly rely on bivariate
    methods, plotting two variables against each other to tease out some insights.
    Used in conjunction with causal diagrams, bivariate graphs will allow us to visualize
    relationships that would otherwise be very complex to grasp.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 根据定义，缺失数据很难可视化。单变量方法（即一次处理一个变量）只能带我们走那么远，所以我们大多数时候会依赖双变量方法，将两个变量相互绘制以挖掘一些见解。与因果图结合使用，双变量图将使我们能够可视化关系，否则这些关系将非常复杂。
- en: 'Our first step is to get a sense of “how” our data is missing. The mice package
    in R has a very convenient function `md.pattern()` to visualize missing data:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是了解“数据缺失”的情况。R中的mice包有一个非常方便的函数`md.pattern()`来可视化缺失数据：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `md.pattern()` function returns a table where each row represents a pattern
    of data availability. The first row has a “1” for each variable, so it represents
    complete records. The number on the left of the table indicates the number of
    rows with that pattern, and the number on the right indicates the number of fields
    that are missing in that pattern. We have 368 complete rows in our data. The second
    row has a “0” for *Neuroticism* only, so it represents records where only *Neuroticism*
    is missing; we have 358 such rows. The numbers at the bottom of the table indicate
    the number of missing values for the corresponding variables, and the variables
    are ordered by increasing number of missing values. *Neuroticism* is the last
    variable to the right, which means it has the highest number of missing values,
    1,000\. This function also conveniently returns a visual representation of the
    table ([Figure 6-2](#patterns_of_missing_data)).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`md.pattern()` 函数返回一张表，其中每一行代表数据可用性的模式。第一行每个变量都有“1”，因此表示完整的记录。表的左侧数字表示具有该模式的行数，右侧数字表示该模式中缺失的字段数。我们的数据中有368行完整记录。第二行只有*神经质*变量为“0”，因此表示只有*神经质*缺失的记录；我们的数据中有358行这样的记录。表的底部数字表示对应变量的缺失值数量，并且变量按缺失值数量递增排序。*神经质*变量位于表的最右侧，这意味着它有最高数量的缺失值，为1,000。此函数还方便地返回表的可视化表示（[图 6-2](#patterns_of_missing_data)）。'
- en: '![Patterns of missing data](Images/BEDA_0602.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![缺失数据的模式](Images/BEDA_0602.png)'
- en: Figure 6-2\. Patterns of missing data
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-2\. 缺失数据的模式
- en: 'As we can see in [Figure 6-2](#patterns_of_missing_data), the variables *Age*,
    *Openness,* and *Gender* don’t have any missing data, but all the other variables
    do. We can obtain the same results in Python with an ad hoc function I wrote,
    although in a less readable format:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[图 6-2](#patterns_of_missing_data)中看到的，变量*年龄*、*开放性*和*性别*没有任何缺失数据，但其他所有变量都有。我们可以用我写的一个特定函数在Python中获得相同的结果，尽管格式不够易读：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is composed of two tables:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 输出由两张表组成：
- en: The first table indicates the total number of missing values for each variable
    in our data, as seen at the bottom of [Figure 6-2](#patterns_of_missing_data).
    *Extraversion* has 793 missing values, and so on.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一张表显示了我们数据中每个变量的缺失值总数，如[图 6-2](#patterns_of_missing_data)的底部所示。*外向性*有793个缺失值，依此类推。
- en: The second table represents the details of each missing data pattern. The variables
    above the logical values on the left (i.e., *Extraversion, Neuroticism, State,
    BookingAmount)* are the ones with some missing values in the data. Each line of
    the table indicates the number of rows with a certain pattern of missing data.
    The first line is made of four `False`, i.e., the pattern where none of the variables
    has missing data, and there are 368 such rows in our data, as you’ve seen previously
    in the first line of [Figure 6-2](#patterns_of_missing_data). The second line
    only changes the last `False` to `True`, with the first three `False` omitted
    for readability (i.e., any blank logical value should be read up). This pattern
    `False``/``False``/``False``/``True` happens when only *BookingAmount* has a missing
    value, which happens in 33 rows of our data, and so on.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二张表显示每种缺失数据模式的详细信息。左侧的逻辑值上方的变量（即*外向性、神经质、状态、预订金额*）是数据中有一些缺失值的变量。表的每一行指示具有特定缺失数据模式的行数。第一行由四个`False`组成，即没有任何变量缺失数据的模式，我们的数据中有368行，正如您在[图 6-2](#patterns_of_missing_data)的第一行中看到的那样。第二行只将最后一个`False`改为`True`，为了易读性省略了前三个`False`（即任何空白逻辑值应往上读取）。这种模式
    `False``/``False``/``False``/``True` 出现在仅*预订金额*有缺失值的情况下，发生在我们的数据中的33行，依此类推。
- en: 'Even with such a small data set, this visualization is very rich and it can
    be hard to know what to look for. We will explore two aspects:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是这样一个小数据集，这种可视化也非常丰富，很难知道要寻找什么。我们将探讨两个方面：
- en: Amount of missing data
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据量
- en: How much of our data is missing? For which variables do we have the highest
    percentage of missing data? Can we just discard rows with missing data?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据有多少是缺失的？哪些变量有最高百分比的缺失数据？我们可以简单地丢弃有缺失数据的行吗？
- en: Correlation of missingness
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失相关性
- en: Is data missing at the individual or variable level?
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据是在个体级别还是变量级别？
- en: Amount of Missing Data
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失数据量
- en: The first order of business is to determine how much of our data is missing
    and which variables have the highest percentage of missing data. We can find the
    necessary values at the bottom of [Figure 6-2](#patterns_of_missing_data), with
    the number of missing values per variable, in increasing order of missingness,
    or at the bottom of the Python output. If the amount of missing data is very limited,
    e.g., you have a 10-million-row data set where no variable has more than 10 missing
    values, then handling them properly through multiple imputation would be overkill
    as we’ll see later. Just drop all the rows with missing data and be done with
    it. The rationale here is that even if the missing values are extremely biased,
    there are too few of them to materially influence the outcomes of your analysis
    in any way.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 首要任务是确定我们数据的缺失情况以及哪些变量的缺失比例最高。我们可以在[图 6-2](#patterns_of_missing_data)的底部找到所需的值，其中包括每个变量的缺失值数量，按照缺失程度递增排序，或在Python输出的底部找到。如果缺失数据量非常有限，例如您有一个1000万行数据集，其中没有变量有超过10个缺失值，那么通过多重插补来妥善处理它们将是过度的，我们稍后将看到。只需删除所有具有缺失数据的行，问题就解决了。这里的理由是，即使缺失值极其偏倚，它们的数量太少，不会以任何方式实质性地影响您分析的结果。
- en: 'In our example, the variable with the highest number of missing values is *Neuroticism*,
    with 1,000 missing values. Is that a lot? Where is the limit? Is it 10, 100, 1,000
    rows or more? It depends on the context. A quick-and-dirty strategy that you can
    use is as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，缺失值最多的变量是*神经质*，有1,000个缺失值。这多吗？限制在哪里？是10、100、1,000行还是更多？这取决于上下文。您可以使用一个快速且简单的策略：
- en: 'Take the variable with the highest number of missing values and create two
    new data sets: one where all the missing values are replaced by the minimum of
    that variable and one where they are replaced by the maximum of that variable.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择缺失值最多的变量，并创建两个新数据集：一个将该变量的所有缺失值替换为该变量的最小值，另一个将其替换为该变量的最大值。
- en: Run a regression for that variable’s most important relationship with each of
    the three data sets you now have. For example, if that variable is a predictor
    of your effect of interest, then run that regression.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对您现在拥有的三个数据集中的每一个，运行关于该变量与您感兴趣效果的最重要关系的回归。例如，如果该变量是您感兴趣效果的预测变量，则运行该回归。
- en: 'If the regression coefficient is not materially different across the three
    regressions, i.e., you would draw the same business implications or take the same
    actions based on the different values, then you’re below the limit and you can
    drop the missing data. In simpler words: would these numbers mean the same thing
    to your business partners? If so, you can drop the missing data.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果在三次回归中，回归系数没有实质性差异，即基于不同数值得出相同的业务影响或采取相同行动，那么您的数据缺失率在可接受范围内，可以放弃缺失数据。简而言之：这些数字对您的业务伙伴来说意味着相同的事情吗？如果是这样，您可以放弃缺失数据。
- en: Note
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This rule of thumb is easily applied to numeric variables, but what about binary
    or categorical variables?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这一经验法则很容易适用于数值变量，但是对于二元或分类变量呢？
- en: For binary variables, the minimum will be 0 and the maximum will be 1, and that’s
    OK. The two data sets you create translate into a best-case scenario and a worst-case
    scenario.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二元变量，最小值将为0，最大值将为1，这是可以接受的。您创建的两个数据集将转化为最佳情况和最坏情况。
- en: 'For categorical variables, the minimum and maximum rule must be slightly adjusted:
    replace all the missing values with either the least frequent or the most frequent
    category.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类变量，最小和最大规则必须稍作调整：将所有缺失值替换为最少出现或最常出现的类别。
- en: 'Let’s do that here, for example for *Neuroticism*. *Neuroticism* is a predictor
    of our effect of interest, *BookingAmount*, so we’ll use that relationship as
    indicated earlier:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以*神经质*为例，做到这一点。*神经质*是我们感兴趣效果*预订金额*的一个预测变量，所以我们将使用前面指出的关系：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The results are as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: The coefficient based on the available data is −5.9.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于可用数据的系数为−5.9。
- en: The coefficient based on replacing the missing values with the minimum of *Neuroticism*
    is −8.0.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于用*神经质*的最小值替换缺失值的系数为−8.0。
- en: The coefficient based on replacing the missing values with the maximum of *Neuroticism*
    is 2.7.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于用*神经质*的最大值替换缺失值的系数为2.7。
- en: These values are very different from each other, to the point of having different
    signs, therefore we’re definitely above the threshold for material significance.
    We can’t simply drop the rows that have missing data for *Neuroticism*. Applying
    the same approach to the other variables would also show that we can’t disregard
    their missing values and need to handle them adequately.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值彼此非常不同，甚至具有不同的符号，因此我们绝对超过了材料显著性的阈值。我们不能简单地删除那些对*神经质*有缺失数据的行。对其他变量采用同样的方法也会显示出我们不能忽视它们的缺失值，需要适当处理。
- en: Correlation of Missingness
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失的相关性
- en: Once we have determined which variables we need to deal with, we’ll want to
    know how much their missingness is correlated. If you have variables whose missingness
    is highly correlated, this suggests that the missingness of one causes the missingness
    of others (e.g., if someone stops answering a survey halfway through, then all
    answers after a certain point will be missing). Alternatively, their missingness
    may have a common cause (e.g., if some subjects are more reluctant to reveal information
    about themselves). In both of these cases, identifying correlation in missingness
    will help you build a more accurate CD, which will save you time and make your
    analyses more effective.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了需要处理的变量，我们就想知道它们的缺失程度有多相关。如果有变量的缺失高度相关，这表明一个变量的缺失导致了其他变量的缺失（例如，如果某人在调查中途停止回答问题，则之后的所有答案都将缺失）。或者，它们的缺失可能有共同的原因（例如，某些受试者更不愿意透露有关自己的信息）。在这两种情况下，识别缺失的相关性将帮助您建立更精确的CD，节省时间并使分析更有效。
- en: 'Let’s look at it through a simple illustration: imagine that we have interview
    data for two offices: Tampa and Tacoma. In both offices, candidates must go through
    the same mandatory three interview sections, but in Tampa the first interviewer
    is responsible for recording all the scores of a candidate whereas in Tacoma each
    interviewer records the score for their section. Interviewers are human beings
    and they sometimes forget to turn in the data to HR. In Tampa, when an interviewer
    forgets to turn in the data, we have no data whatsoever for the candidate, apart
    from their ID in the system ([Figure 6-3](#highly_correlated_missingness_in_tampa)
    shows the data for Tampa only).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个简单的例子来看一下：想象一下我们有两个办公室的面试数据：Tampa和Tacoma。在两个办公室中，候选人必须通过相同的三个强制性面试部分，但在Tampa，第一位面试官负责记录候选人的所有分数，而在Tacoma，每位面试官都要记录其部分的分数。面试官是人类，有时会忘记将数据交给HR。在Tampa，如果面试官忘记提交数据，我们对于候选人除了系统中的ID外就没有任何数据（[Figure 6-3](#highly_correlated_missingness_in_tampa)只显示了Tampa的数据）。
- en: '![Highly correlated missingness in Tampa data](Images/BEDA_0603.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![Tampa数据中高度相关的缺失](Images/BEDA_0603.png)'
- en: Figure 6-3\. Highly correlated missingness in Tampa data
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-3。Tampa数据中高度相关的缺失。
- en: The telltale sign for high missingness correlation is a line with a large number
    of light-shaded squares (here 3) that represent a high number of cases (here 400
    out of 2,000 total rows). In addition, the figure has no line with only one or
    two light squares.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 高缺失相关性的标志是一行具有大量浅色方块（这里是3），代表了高数量的案例（这里是总行数2,000中的400）。此外，图中没有只有一个或两个浅色方块的行。
- en: In such a situation, it wouldn’t make sense to analyze our missing data one
    variable at a time. If we find that data for the first section is highly likely
    to be missing when Murphy is the first interviewer, then it will also be true
    for the other sections. (You had one job, Murphy!)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，逐个变量分析我们的缺失数据是毫无意义的。如果我们发现当Murphy是第一位面试官时，第一部分的数据非常可能丢失，那么对于其他部分也是如此。（Murphy，你只有一个任务！）
- en: In Tacoma, on the other hand, the missingness of the different sections is entirely
    uncorrelated ([Figure 6-4](#uncorrelated_missingness_in_tacomaapost)).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，在Tacoma，不同部分的缺失完全不相关（[Figure 6-4](#uncorrelated_missingness_in_tacomaapost)）。
- en: 'The pattern is the opposite of Tampa’s:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式与Tampa相反：
- en: We have a high number of lines with few missing variables (see all the 1s and
    2s on the right of the figure).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有大量只有少数缺失变量的行（请看图右边的所有1和2）。
- en: These lines represent the bulk of our data (we can see on the left that only
    17 rows have 3 missing variables).
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些行代表了我们数据的大部分（左边的数据表明只有17行有3个缺失变量）。
- en: Lines with a high number of light squares at the bottom of the figure represent
    very few cases (the same 17 individuals) because they are the result of independent
    randomness.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图中底部有大量浅色方块的线代表非常少的案例（相同的17个个体），因为它们是独立随机性的结果。
- en: '![Uncorrelated missingness in Tacoma’s data](Images/BEDA_0604.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![Tacoma数据中的不相关缺失](Images/BEDA_0604.png)'
- en: Figure 6-4\. Uncorrelated missingness in Tacoma’s data
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-4\. Tacoma数据中的不相关缺失
- en: 'The argument for the last bullet point can be extended by looking more broadly
    at what we could call “Russian dolls” sequences of increasing missingness where
    each pattern adds a missing variable on the previous pattern, for example (I3)
    → (I3, I2) → (I3, I2, I1). The corresponding numbers of cases are 262 → 55 → 17\.
    These numbers form a decreasing sequence, which is logical because if the missingness
    of the variables is completely uncorrelated, we have:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个要点的论证可以通过更广泛地观察我们可以称之为“俄罗斯套娃”序列来扩展，这些序列呈递增的缺失，其中每个模式都在上一个模式上添加一个缺失变量，例如（I3）→（I3，I2）→（I3，I2，I1）。相应的案例数量是262
    → 55 → 17\. 这些数字形成了一个递减序列，这是合乎逻辑的，因为如果变量的缺失完全不相关，我们有：
- en: '*Prob*(*I*3 *missing & I*2 *missing*) = *Prob*(*I*3 *missing*) * *Prob*(*I*2
    *missing*)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*Prob*（*I*3 *缺失 & I*2 *缺失*）= *Prob*（*I*3 *缺失*）* *Prob*（*I*2 *缺失*）'
- en: '*Prob*(*I*3 *missing & I*2 *missing & I*1 *missing*) = *Prob*(*I*3 *missing*)
    * *Prob*(*I*2 *missing*) ** Prob*(*I*1 *missing*)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*Prob*（*I*3 *缺失 & I*2 *缺失 & I*1 *缺失*）= *Prob*（*I*3 *缺失*）* *Prob*（*I*2 *缺失*）**
    Prob*（*I*1 *缺失*）'
- en: 'With a small sample and/or very high levels of missingness, these equations
    may not hold exactly true in our data, but if less than 50% of any variable is
    missing we should generally have:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在样本较小和/或缺失程度非常高的情况下，这些方程可能在我们的数据中并不完全成立，但是如果任何变量的缺失量不到50％，我们通常应该有：
- en: '*Prob*(*I*3 *missing* & *I*2 *missing* & *I*1 *missing*) < *Prob*(*I*3 *missing*
    & *I*2 *missing*) < *Prob*(*I*3 *missing*)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*Prob*（*I*3 *缺失* & *I*2 *缺失* & *I*1 *缺失*）< *Prob*（*I*3 *缺失* & *I*2 *缺失*）< *Prob*（*I*3
    *缺失*）'
- en: In real-life situations, it would be rather cumbersome to test all these inequalities
    by yourself, although you could write a function to do so at scale. Instead, I
    would recommend looking at the visualization for any significant outlier (i.e.,
    a value for several variables much larger than the values for some of the same
    variables).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际情况下，自己测试所有这些不等式可能会相当麻烦，尽管您可以编写一个函数以进行大规模测试。相反，我建议查看任何重要的异常值的可视化（即，一些相同变量的值远大于相同变量的某些值）。
- en: 'More broadly, this visualization is easy to use with only a few variables.
    As soon as you have a large number of variables, you’ll have to build and visualize
    the correlation matrix for missingness:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 更广泛地说，这种可视化在只有几个变量时很容易使用。一旦您有大量变量，您将不得不构建和可视化缺失的相关矩阵：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[Figure 6-5](#correlation_matrices_for_completely_cor) shows the resulting
    correlation matrices. In the one on the left, for Tampa, all the values are equal
    to 1: if one variable is missing, then the other two are as well. In the correlation
    matrix on the right, for Tacoma, the values are equal to 1 on the main diagonal
    but 0 everywhere else: knowing that one variable is missing tells you nothing
    about the missingness of the others.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[Figure 6-5](#correlation_matrices_for_completely_cor)显示了生成的相关矩阵。在左侧的矩阵中，对于Tampa，所有值都等于1：如果一个变量缺失，那么其他两个变量也是如此。在右侧的相关矩阵中，对于Tacoma，主对角线上的值等于1，但在其他地方都等于0：知道一个变量缺失并不能告诉您其他变量的缺失情况。'
- en: '![Correlation matrices for completely correlated missingness (left) and completely
    uncorrelated missingness (right)](Images/BEDA_0605.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![完全相关缺失的相关矩阵（左）和完全不相关缺失的相关矩阵（右）](Images/BEDA_0605.png)'
- en: Figure 6-5\. Correlation matrices for completely correlated missingness (left)
    and completely uncorrelated missingness (right)
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-5\. 完全相关缺失（左）和完全不相关缺失（右）的相关矩阵
- en: Let’s get back to our AirCnC data set and see where it falls between the two
    extremes outlined in our theoretical interview example. [Figure 6-6](#patterns_of_missing_data_left_parenthes)
    repeats [Figure 6-2](#patterns_of_missing_data) for ease of access.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们的AirCnC数据集，并看看它在我们的理论访谈示例中概述的两个极端之间的位置。[Figure 6-6](#patterns_of_missing_data_left_parenthes)重复了[Figure 6-2](#patterns_of_missing_data)以便更易于访问。
- en: '[Figure 6-6](#patterns_of_missing_data_left_parenthes) falls somewhere in the
    middle: all possible patterns of missingness are fairly represented, which suggests
    that we don’t have strongly clustered sources of missingness.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 6-6](#patterns_of_missing_data_left_parenthes) 位于中间位置：所有可能的缺失模式都相当代表，这表明我们没有强烈聚集的缺失源。'
- en: '![Patterns of missing data (repeats)](Images/BEDA_0606.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![缺失数据的模式（重复）](Images/BEDA_0606.png)'
- en: Figure 6-6\. Patterns of missing data (repeats [Figure 6-2](#patterns_of_missing_data))
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-6\. 缺失数据的模式（重复 [图 6-2](#patterns_of_missing_data)）
- en: '[Figure 6-7](#correlation_matrix_of_missingness_in_ou) shows the correlation
    matrix of missingness for our AirCnC data. As you can see, the missingness of
    our variables is almost entirely uncorrelated, well within the range of random
    fluctuations. If you want to familiarize yourself more with correlation patterns
    in missingness, one of the [exercises for this chapter on GitHub](https://oreil.ly/BehavioralDataAnalysisCh6)
    asks you to identify a few of them. As a reminder, looking at correlation patterns
    is never necessary in itself, but it can often be illuminating and save you time.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 6-7](#correlation_matrix_of_missingness_in_ou) 显示了我们的 AirCnC 数据缺失的相关性矩阵。正如你所看到的，我们变量的缺失几乎完全不相关，完全在随机波动范围内。如果你想更加熟悉缺失中的相关性模式，本章的一个[GitHub上的练习](https://oreil.ly/BehavioralDataAnalysisCh6)要求你识别其中一些。作为提醒，查看相关性模式本身并不是必要的，但通常可以启发思考并节省时间。'
- en: '![Correlation matrix of missingness in our AirCnC data](Images/BEDA_0607.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![我们 AirCnC 数据中缺失的相关性矩阵](Images/BEDA_0607.png)'
- en: Figure 6-7\. Correlation matrix of missingness in our AirCnC data
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-7\. 我们 AirCnC 数据中缺失的相关性矩阵
- en: Diagnosing Missing Data
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 诊断缺失数据
- en: Now that we have visualized our missing data, it’s time to understand what causes
    it. This is where causal diagrams come in, as we’ll use them to represent the
    causal mechanisms of missing data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经可视化了我们的缺失数据，是时候了解是什么导致了它。这就是因果图的作用所在，因为我们将使用它们来表示缺失数据的因果机制。
- en: Let’s start with a very simple example from [Chapter 1](ch01.xhtml#the_causal_behavioral_framework_for_da).
    When introducing causal diagrams, I mentioned that unobserved variables, such
    as a customer’s taste for vanilla ice cream, are represented in a darker shaded
    rectangle ([Figure 6-8](#unobserved_variables_are_represented_in)).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从[第 1 章](ch01.xhtml#the_causal_behavioral_framework_for_da)中的一个非常简单的例子开始。在介绍因果图时，我提到未观察到的变量，比如顾客对香草冰淇淋的喜好，用一个较深的阴影矩形来表示（[图 6-8](#unobserved_variables_are_represented_in)）。
- en: '![Unobserved variables are represented in an oval](Images/BEDA_0608.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![未观察到的变量以椭圆形表示](Images/BEDA_0608.png)'
- en: Figure 6-8\. Unobserved variables are represented in a darker-shaded rectangle
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-8\. 未观察到的变量以较深的阴影矩形表示
- en: Unobserved variables, which are sometimes called “latent” variables in certain
    disciplines, refer to information that we don’t have in practice, even though
    it may or may not in theory be accessible. In the present case, let’s say that
    we force our customers to disclose their taste for vanilla before making a purchase.
    This would create the corresponding data in our systems, which we would then use
    for our data analyses ([Figure 6-9](#collecting_previously_unobserved_inform)).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 未观察到的变量，在某些学科中有时被称为“潜变量”，指的是我们实际上没有的信息，尽管理论上可能是可以访问的或不可访问的。在目前的情况下，假设我们强迫客户在购买前透露他们对香草的口味。这将在我们的系统中创建相应的数据，然后我们将用它们进行数据分析（[图 6-9](#collecting_previously_unobserved_inform)）。
- en: '![Collecting previously unobserved information](Images/BEDA_0609.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![收集先前未观察到的信息](Images/BEDA_0609.png)'
- en: Figure 6-9\. Collecting previously unobserved information
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-9\. 收集先前未观察到的信息
- en: However, it is generally poor business practice to try and force customers to
    disclose information they don’t want to, and it’s often left optional. More generally,
    a large amount of data is collected on some customers but not others. We’ll represent
    that situation by drawing the corresponding box in the CD with dashes ([Figure 6-10](#representing_partially_observed_variabl)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，试图强迫客户透露他们不想透露的信息通常是不良的商业行为，并且通常是可选的。更一般地说，对一些客户收集了大量数据，而对其他客户则没有。我们将通过在
    CD 中用虚线绘制相应的框来表示该情况（[图 6-10](#representing_partially_observed_variabl)）。
- en: '![Representing partially observed variables with a dashed box](Images/BEDA_0610.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![用虚线框表示部分观察到的变量](Images/BEDA_0610.png)'
- en: Figure 6-10\. Representing partially observed variables with a dashed box
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-10\. 用虚线框表示部分观察到的变量
- en: For example, with three customers, we could have the following data, with one
    customer refusing to disclose their taste for vanilla ice cream ([Table 6-2](#the_data_underlying_our_cd)).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于三名顾客，我们可能有以下数据，其中一名顾客拒绝透露他们对香草冰淇淋的口味（[表 6-2](#the_data_underlying_our_cd)）。
- en: Table 6-2\. The data underlying our CD
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-2\. 我们CD的基础数据
- en: '| Customer name | Taste for vanilla | Stated taste | Purchased IC at stand
    (Y/N) |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 顾客姓名 | 对香草的喜好 | 声明的口味 | 在摊位购买冰淇淋（Y/N） |'
- en: '| --- | --- | --- | --- |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Ann | Low | Low | N |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 安 | 低 | 低 | N |'
- en: '| Bob | High | High | Y |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 鲍勃 | 高 | 高 | Y |'
- en: '| Carolyn | High | N/A | Y |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 卡罗琳 | 高 | N/A | Y |'
- en: In this chapter, we’re interested in understanding what causes missingness of
    a variable, and not just what causes the values of a variable. Therefore, we’ll
    create a variable to track when the stated taste variable is missing ([Table 6-3](#adding_a_missingness_variable)).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们感兴趣的是理解一个变量的缺失原因，而不仅仅是理解一个变量的值的原因。因此，我们将创建一个变量来跟踪声明口味变量何时缺失 ([表 6-3](#adding_a_missingness_variable))。
- en: Table 6-3\. Adding a missingness variable
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-3\. 添加一个缺失变量
- en: '| Customer name | Taste for vanilla | Stated taste for vanilla | Stated taste
    missing (Y/N) | Purchased IC at stand |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 顾客姓名 | 对香草的喜好 | 声明的香草口味 | 声明的口味缺失（Y/N） | 在摊位购买冰淇淋 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Ann | Low | Low | N | N |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 安 | 低 | 低 | N | N |'
- en: '| Bob | High | High | N | Y |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 鲍勃 | 高 | 高 | N | Y |'
- en: '| Carolyn | High | N/A | Y | Y |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 卡罗琳 | 高 | N/A | Y | Y |'
- en: Let’s add that variable to our CD ([Figure 6-11](#adding_missingness_to_our_causal_diagra)).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在我们的CD中添加该变量 ([图 6-11](#adding_missingness_to_our_causal_diagra))。
- en: '![Adding missingness to our causal diagram](Images/BEDA_0611.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![在我们的因果图中添加缺失](Images/BEDA_0611.png)'
- en: Figure 6-11\. Adding missingness to our causal diagram
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-11\. 在我们的因果图中添加缺失
- en: We conventionally make missingness a cause of the corresponding partially observed
    variable. The intuition is that the information exists fully in the unobserved
    variable, and the partially observed variable is equal to the unobserved variable,
    unless information is “hidden” by the missingness variable. This convention will
    make our lives much easier, because it will allow us to express and discuss causes
    of missingness in the CD that represent our relationships of interest, instead
    of having to consider missingness separately.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常将缺失作为相应部分观察变量的原因。直觉是信息完全存在于未观察变量中，并且部分观察变量等于未观察变量，除非信息被缺失变量“隐藏”。这种约定将使我们的生活更加轻松，因为它允许我们在CD中表达和讨论缺失的原因，这些原因代表了我们感兴趣的关系，而不必单独考虑缺失。
- en: Now that missingness is part of our CD, the natural next step is to ask ourselves,
    “What causes it?”
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在缺失已成为我们CD的一部分，下一个自然的步骤是问自己：“是什么原因导致了它？”
- en: 'Causes of Missingness: Rubin’s Classification'
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失的原因：鲁宾的分类
- en: There are three basic and mutually exclusive possibilities for what causes missingness
    of a variable, which have been categorized by statistician Donald Rubin.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于引起变量缺失的基本且互斥的三种可能性，统计学家唐纳德·鲁宾已进行了分类。
- en: First, if the missingness of a variable depends only on variables outside of
    our data, such as purely random factors, that variable is said to be *m**issing
    completely at random* (MCAR) ([Figure 6-12](#stated_taste_is_missing_completely_at_r)).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果一个变量的缺失仅取决于我们数据之外的变量，例如纯随机因素，那么该变量被称为*完全随机缺失*（MCAR） ([图 6-12](#stated_taste_is_missing_completely_at_r))。
- en: '![Stated taste is missing completely at random](Images/BEDA_0612.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![声明的口味是完全随机缺失的](Images/BEDA_0612.png)'
- en: Figure 6-12\. Stated taste is missing completely at random
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-12\. 声明的口味是完全随机缺失的
- en: Then, a variable goes from MCAR to *missing at random* (MAR) if even one variable
    in our data affects its missingness. Variables outside of our data and random
    factors may also play a role, but the value of the variable in question may not
    affect its own missingness. This would be the case for instance if *Purchased*
    caused the missingness of *StatedVanillaTaste*, e.g., because we only interview
    customers who purchased instead of passersby ([Figure 6-13](#stated_taste_is_missing_at_random)).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，如果我们的数据中的任何一个变量影响其缺失状态，那么一个变量从MCAR（完全随机缺失）变为*随机缺失*（MAR）。数据之外的变量和随机因素也可能起作用，但变量的值可能不会影响其自身的缺失状态。例如，如果*购买*导致了*声明的香草口味*的缺失，例如因为我们只采访购买的顾客而不是路人
    ([图 6-13](#stated_taste_is_missing_at_random))。
- en: '![Stated taste is missing at random](Images/BEDA_0613.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![声明的口味是随机缺失的](Images/BEDA_0613.png)'
- en: Figure 6-13\. Stated taste is missing at random
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-13\. 所述口味是随机缺失
- en: Finally, any variable whose value influences its own missingness is *m**issing
    not at random* (MNAR), even if other variables inside or outside of the data also
    affect the missingness. Other variables inside or outside of our data may also
    play a role, but a variable goes from MCAR or MAR to MNAR as soon as the variable
    influences its own missingness. In our example, this would mean that *VanillaTaste*
    causes the missingness of *StatedVanillaTaste* ([Figure 6-14](#stated_taste_is_missing_not_at_randomdo)).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，任何值影响其自身缺失的变量都被认为是 *缺失不是随机的*（MNAR），即使数据内外的其他变量也会影响缺失。我们的数据内外可能还有其他变量起作用，但变量一旦影响其自身缺失，就从MCAR或MAR变为MNAR。在我们的例子中，这意味着
    *香草口味* 导致 *陈述香草口味* 的缺失（[图 6-14](#stated_taste_is_missing_not_at_randomdo)）。
- en: '![Stated taste is missing not at random](Images/BEDA_0614.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![所述口味缺失不是随机](Images/BEDA_0614.png)'
- en: Figure 6-14\. Stated taste is missing not at random
  id: totrans-150
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-14\. 所述口味缺失不是随机发生的
- en: Note
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We represent the idea that the values of a variable influence its missingness
    by drawing an arrow from the unobserved variable, and not the partially observed
    variable. This way, we can make meaningful statements such as “all values that
    are in reality below a certain threshold are missing in our data.” If the arrow
    came from the partially observable variable, we would be stuck with uninformative
    statements such as “values that are missing cause themselves to be missing.”
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过从未观察到的变量而不是部分观察到的变量引入箭头来表示变量的值影响其缺失的想法。这样，我们可以做出有意义的陈述，如“实际上低于某个阈值的所有值在我们的数据中都是缺失的”。如果箭头来自部分可观察到的变量，我们将被困在无信息的陈述中，例如“缺失的值导致它们自己缺失”。
- en: In an ideal world, the rest of the section would consist of recipes to identify
    each category of missingness. Unfortunately, missing data analysis is still an
    open area of research that has not yet been fully explored. In particular, how
    missingness and causality interact is not well understood. Therefore, dealing
    with missing data remains more art than science. Trying to create systematic recipes
    would require dealing with an intractable number of exceptions, as well as introducing
    circular arguments such as “pattern X indicates that variable 1 is MAR unless
    variable 2 is MNAR; pattern Y indicates that variable 2 is MNAR unless variable
    1 is MAR.” I have done my best to cover as many cases as possible within a limited
    data set, but in the real world you might encounter situations that are “a little
    bit of this and a little bit of that” and you’ll have to make judgment calls as
    to how to proceed.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想的世界里，本节其余部分将包括识别每个缺失类别的方法。不幸的是，缺失数据分析仍然是一个尚未完全探索的开放领域。特别是，缺失和因果关系如何相互作用尚不清楚。因此，处理缺失数据仍然更像是一门艺术而不是科学。试图创建系统化的方法将需要处理大量的异常情况，以及引入循环论证，如“模式X表明变量1是MAR，除非变量2是MNAR；模式Y表明变量2是MNAR，除非变量1是MAR”。我已尽力在有限的数据集中涵盖尽可能多的情况，但在现实世界中，您可能会遇到“有点这个，有点那个”的情况，您需要判断如何继续。
- en: Some good news, however, is that with a few exceptions that I’ll call out, being
    cautious takes more time but doesn’t introduce bias. When you’re uncertain whether
    a variable is MCAR, MAR, or MNAR, just assume the worst of the possible scenarios
    and your analyses will be as unbiased as they can be.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有些好消息是，除了我会指出的几个例外外，谨慎行事会花费更多时间但不会引入偏见。当您不确定一个变量是MCAR、MAR还是MNAR时，只需假设可能的最糟情形，您的分析将尽可能是无偏的。
- en: 'With that caveat in mind, let’s get back to our AirCnC data and see how we
    can diagnose missingness in a realistic data set. As a quick refresher, our data
    set contains the following variables:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，请回顾我们的AirCnC数据，看看如何在一个实际数据集中诊断缺失情况。作为一个快速的提醒，我们的数据集包含以下变量：
- en: Demographic characteristics
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口统计特征
- en: Age
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄
- en: Gender
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性别
- en: State (A, B, and C)
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 状态（A、B和C）
- en: Personality traits
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个性特征
- en: Openness
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开放性
- en: Extraversion
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外向性
- en: Neuroticism
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经质
- en: Booking amount
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预订金额
- en: Diagnosing MCAR Variables
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 诊断MCAR变量
- en: 'MCAR variables are the simplest case. A sensor went faulty, a bug prevented
    data transmission from a customer’s mobile app, or a customer just missed the
    field to enter their taste for vanilla ice cream. Regardless, missingness happens
    in a way that is intuitively “random.” We diagnose MCAR variables by default:
    if a variable doesn’t appear to be MAR, we’ll treat it as MCAR. In other words,
    you can think of MCAR as our null hypothesis in the absence of evidence to the
    contrary.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: MCAR 变量是最简单的情况。传感器故障了，一个 bug 阻止了数据从客户的移动应用程序传输，或者客户只是错过了输入他们对香草冰淇淋口味的字段。总之，缺失以直觉上的“随机”方式发生。我们默认诊断
    MCAR 变量：如果变量似乎不是 MAR，则将其视为 MCAR。换句话说，在缺乏证据的情况下，你可以将 MCAR 视为我们的零假设。
- en: 'The main tool that we’ll use to diagnose missingness is a logistic regression
    of whether a variable is missing on all the other variables in our data set. Let’s
    look, for example, at the *Extraversion* variable:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用来诊断缺失性的主要工具是逻辑回归，即一个变量是否缺失，取决于我们数据集中的所有其他变量。让我们以 *外向性* 变量为例：
- en: '[PRE8]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: None of the variables has a large and strongly statistically significant coefficient.
    In the absence of any other evidence, this suggests that the source of missingness
    for *Extraversion* is purely random and we’ll treat our *Extraversion* variable
    as MCAR.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何变量具有大且强烈统计显著的系数。在没有任何其他证据的情况下，这表明 *外向性* 的缺失性纯粹是随机的，我们将把我们的 *外向性* 变量视为 MCAR。
- en: You can think of MCAR data as rolling dice or flipping a coin. Both of these
    actions are “random” from our perspective, but they still obey the laws of physics.
    Theoretically, if we had enough information and computing power, the outcome would
    be entirely predictable. The same could happen here. By saying that *Extraversion*
    is MCAR, we’re not saying “the missingness of *Extraversion* is fundamentally
    random and unpredictable,” we’re just saying “none of the variables *currently
    included* in our analysis is correlated with the missingness of *Extraversion.*”
    But maybe—and even probably—other variables (conscientiousness? trust? familiarity
    with technology?) would be correlated. Our goal is not to make a philosophical
    statement about *Extraversion*, but to determine if its missingness may bias our
    analyses, given the data currently available.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将 MCAR 数据视为掷骰子或抛硬币。从我们的角度来看，这两种行为都是“随机”的，但它们仍然遵守物理法则。理论上，如果我们有足够的信息和计算能力，结果将是完全可预测的。这里也可能发生同样的情况。当我们说
    *外向性* 是 MCAR 时，我们并不是在说“*外向性* 的缺失性基本上是随机且不可预测的”，我们只是说“我们目前分析中包含的变量没有一个与 *外向性* 的缺失性相关联。”但可能——甚至很可能——其他变量（责任感？信任？对技术的熟悉度？）会相关联。我们的目标不是对
    *外向性* 发表哲学性声明，而是确定其缺失是否可能会使我们的分析产生偏见，考虑到当前可用的数据。
- en: Diagnosing MAR Variables
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 诊断 MAR 变量
- en: 'MAR variables are variables whose missingness depends on the values of other
    variables in our data. If other variables in our data set are predictive of a
    variable’s missingness, then MAR becomes our default hypothesis for that variable,
    unless we have strong enough evidence that it’s MNAR. Let’s see what this looks
    like with the *State* variable:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: MAR 变量是指其缺失性取决于数据集中其他变量的值。如果数据集中的其他变量能够预测某个变量的缺失性，则 MAR 将成为我们该变量的默认假设，除非我们有足够强的证据表明其为
    MNAR。让我们看看 *状态* 变量的情况：
- en: '[PRE10]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Age* is mildly significant, with a positive coefficient. In other words, older
    customers appear less likely to provide their state. The corresponding causal
    diagram is represented in [Figure 6-15](#gender_missing_at_random).'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '*年龄* 略有显著性，具有正系数。换句话说，年长客户似乎更不可能提供他们的州。相应的因果图表示在 [图 6-15](#gender_missing_at_random)
    中。'
- en: '![Gender missing at random](Images/BEDA_0615.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![性别随机缺失](Images/BEDA_0615.png)'
- en: Figure 6-15\. Gender missing at random
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-15\. 性别随机缺失
- en: We can confirm that correlation by plotting the density of *State* missingness
    by recorded *Age* ([Figure 6-16](#density_of_missing_and_observed_state)). *State*
    has more observed values for younger customers than for older customers, or conversely,
    more missing values for older customers than for younger customers.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过绘制观察到的 *年龄* 按 *状态* 缺失情况的密度图（[图 6-16](#density_of_missing_and_observed_state)）来确认这种相关性。相对于年轻客户，*状态*
    在年长客户中的观察值更多，或者反过来，对于年长客户，*状态* 的缺失值更多。
- en: '![Density of missing and observed State data, by observed Age](Images/BEDA_0616.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![缺失和观察到的年龄密度状态数据](Images/BEDA_0616.png)'
- en: Figure 6-16\. Density of missing and observed State data, by observed Age
  id: totrans-181
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-16\. 缺失和观察到的状态数据密度，按观察到的年龄分
- en: One limitation of this density plot is that it doesn’t show the rows where the
    X variable (here *Age*) is also missing. This could be problematic or misleading
    when that variable also has missing values. A possible trick is to replace the
    missing values for the X variable by a nonsensical value, such as −10\. *Age*
    doesn’t have any missing value, so instead we’ll use as our X variable *Extraversion*,
    which has missing values. Let’s plot the density of observed and missing *State*
    data, by values of *Extraversion* ([Figure 6-17](#density_of_missing_and_observed_state_d)).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这个密度图的一个局限性是它并不显示X变量（这里是*Age*）也缺失的行。当该变量也有缺失值时，这可能会产生问题或误导。一个可能的技巧是将X变量的缺失值替换为一个不合理的值，比如−10。*Age*没有任何缺失值，所以我们将使用*Xtraversion*作为我们的X变量，该变量有缺失值。让我们按*Extraversion*的值绘制观察到的和缺失的*State*数据的密度（[图6-17](#density_of_missing_and_observed_state_d)）。
- en: '![Density of missing and observed State data by level of Extraversion, including
    missing Extraversion](Images/BEDA_0617.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![按Extraversion水平绘制的缺失和观察到的State数据密度，包括缺失的Extraversion](Images/BEDA_0617.png)'
- en: Figure 6-17\. Density of missing and observed State data by level of Extraversion,
    including missing Extraversion
  id: totrans-184
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-17\. 按Extraversion水平绘制的缺失和观察到的State数据密度，包括缺失的Extraversion
- en: '[Figure 6-17](#density_of_missing_and_observed_state_d) shows that among individuals
    with no data for *Extraversion*, there are disproportionately more individuals
    for which we observe *State* than individuals for which *State* is missing. Overall,
    we’re seeing strong evidence that *State* is not MCAR but indeed MAR, because
    its missingness appears correlated with other variables available in our data
    set.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-17](#density_of_missing_and_observed_state_d)显示，在没有*Extraversion*数据的个体中，我们观察到的*State*要比*State*缺失的个体更多。总体上，我们看到了强有力的证据表明*State*不是MCAR，而是MAR，因为其缺失似乎与我们数据集中其他可用变量相关。'
- en: Note
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You may have noticed that I used the word “correlation” earlier when talking
    about the relationship between *Age* (or *Extraversion*) and the missingness of
    *State*. Indeed, we’ve only shown correlation so far, and it is entirely possible
    that *Age* doesn’t cause missingness of *State* but that they are both caused
    by a third unobserved variable. Fortunately, when talking about missingness, the
    causal nature of a correlation (or lack thereof) doesn’t affect our analyses.
    Loosely equating the two will not introduce bias because we’ll never actually
    deal with the coefficient for that relationship.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到我在早些时候谈论*Age*（或*Extraversion*）与*State*缺失之间关系时使用了“相关性”这个词。事实上，到目前为止，我们只展示了相关性，完全有可能*Age*并不导致*State*的缺失，而是它们两者都由第三个未观察到的变量导致。幸运的是，在谈论缺失时，相关性的因果性质（或其缺乏）不会影响我们的分析。松散地将两者等同起来不会引入偏差，因为我们实际上永远不会处理那种关系的系数。
- en: Diagnosing MNAR Variables
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 诊断MNAR变量
- en: 'MNAR variables are variables whose missingness depends on their own values:
    higher values are more likely to be missing than lower values, or vice versa.
    This situation is both the most problematic for data analysis and the trickiest
    to diagnose. It is trickiest to diagnose because, by definition, we don’t know
    the values that are missing. Therefore, we’ll need to do a bit more sleuthing.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: MNAR变量是其缺失性取决于其自身值的变量：较高的值缺失的可能性比较低的值更高，反之亦然。这种情况对数据分析是最具问题的，并且诊断起来最为棘手。它很难诊断，因为根据定义，我们不知道缺失的值。因此，我们需要做更多的调查工作。
- en: 'Let’s look at the *Neuroticism* variable, and as before, start by running a
    regression of its missingness on the other variables in the data:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下*Neuroticism*变量，并且像之前一样，首先对数据中其缺失情况进行回归分析：
- en: '[PRE12]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can see that *BookingAmount* has a strongly significant coefficient. On the
    face of it, this would suggest that *Neuroticism* is MAR on *BookingAmount*. However,
    and this is a key clue, *BookingAmount* is a child of *Neuroticism* in our CD.
    From a behavioral perspective, it also seems more likely that *Neuroticism* is
    MNAR rather than MAR on *BookingAmount* (i.e., the missingness is driven by a
    personality trait rather than by the amount a customer spent).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到*BookingAmount*具有显著的系数。表面上看，这表明*神经质*对*BookingAmount*的MAR。然而，这是一个关键线索，*BookingAmount*在我们的CD中是*神经质*的子节点。从行为角度来看，*神经质*对*BookingAmount*的MNAR更为可能（即，缺失是由个性特征而非客户消费金额驱动的）。
- en: A way to confirm our suspicion is to identify another child of the variable
    with missing data, ideally as correlated with it as possible and as little correlated
    as possible with the first child. In our secondary data set, we have data about
    the total amount of travel insurance that customers purchased over their lifetime
    with the company. The fee per trip depends on trip characteristics that are only
    very loosely correlated with the booking amount, so we’re good on that front.
    Adding *Insurance* to our data set, we find that it’s strongly predictive of the
    missingness of *Neuroticism*, and that the distributions of *Insurance* amount
    with observed and missing *Neuroticism* are vastly different from each other ([Figure 6-18](#density_of_missing_and_observed_neuroti)).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 确认我们怀疑的一种方法是识别另一个具有缺失数据的变量的子类，理想情况下与其尽可能相关，与第一个子类的相关性尽可能小。在我们的次要数据集中，我们有关于客户终生在公司购买的旅行保险总金额的数据。每次旅行的费用取决于只与预订金额略微相关的行程特征，因此在这方面我们做得很好。在我们的数据集中添加*保险*后，我们发现它强烈预测了*神经质*的缺失，并且观察到和缺失的*神经质*之间的*保险*金额分布彼此截然不同（[图 6-18](#density_of_missing_and_observed_neuroti)）。
- en: '![Density of missing and observed Neuroticism data, by observed Insurance amount](Images/BEDA_0618.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![观察到的保险金额下缺失和观察到的神经质数据密度](Images/BEDA_0618.png)'
- en: Figure 6-18\. Density of missing and observed Neuroticism data, by observed
    Insurance amount
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-18\. 观察到的保险金额下缺失和观察到的神经质数据密度
- en: The more children variables we find correlated with the missingness of *Neuroticism*,
    the stronger our case becomes that the variable is MNAR. As we’ll see later, the
    way to handle a MNAR variable is to add auxiliary variables to our imputation
    model, and our children variables are perfect candidates for that, so finding
    several of them is not a waste of time but a head start for the next step.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们找到与*神经质*的缺失相关的更多子变量，我们的案例就越强烈，表明这个变量是MNAR。正如我们稍后将看到的，处理MNAR变量的方法是在我们的填充模型中添加辅助变量，我们的子变量是理想的候选人，因此找到它们不是浪费时间而是下一步的先机。
- en: 'Technically, we can never fully prove that a variable is MNAR and not just
    MAR on several of its children, but that is not an issue: auxiliary variables
    do not bias the imputation if the original variable is indeed MAR and not MNAR.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，我们永远无法完全证明一个变量是MNAR而不仅仅是MAR其子类中的一个，但这不是问题：辅助变量不会使缺失数据修补产生偏差，如果原始变量确实是MAR而不是MNAR。
- en: Missingness as a Spectrum
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失作为一个谱系
- en: 'Rubin’s classification relies on binary tests. For example, as soon as a variable
    is more likely to be missing for higher values than for lower values (or vice
    versa), it is MNAR, regardless of any other consideration. However, the shape
    of that relationship between values and missingness matters for practical purposes:
    if *all* values of a variable are missing above or below a certain threshold,
    we’ll need to handle this variable differently from our default approach. This
    situation can also occur with MAR variables so it’s worth taking a step back and
    thinking more broadly about shapes of missingness.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 鲁宾的分类依赖于二元测试。例如，只要一个变量更可能对较高值缺失而不是对较低值缺失（反之亦然），它就是MNAR，不考虑任何其他因素。然而，该关系在值和缺失之间的形状对实际目的很重要：如果一个变量的*所有*值在某个阈值以上或以下都缺失，我们将需要与默认方法不同的方式处理这个变量。这种情况也可能发生在MAR变量中，因此值得退后一步，更广泛地考虑缺失形状。
- en: 'We can think of the missingness of a variable as falling on a spectrum from
    fully probabilistic to fully deterministic. At the “probabilistic” end of the
    spectrum, the variable is MCAR and all values are as likely to be missing. At
    the “deterministic” end of the spectrum, there is a threshold: the values are
    missing for all individuals on one side of the threshold and available for all
    individuals on the other side of the threshold. This often results from the application
    of a business rule. For example, in a hiring context, if only candidates with
    a GPA above 3.0 get interviewed, you wouldn’t have any interview score for candidates
    below that threshold. This would make *InterviewScore* MAR on *GPA* ([Figure 6-19](#interview_score_being_mar_on_gpa)).'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将变量的缺失看作是在完全概率性和完全确定性之间的一个谱系。在谱系的“概率性”端，变量是MCAR，所有值都可能缺失。在谱系的“确定性”端，存在一个阈值：所有在阈值一侧的个体的值都是缺失的，而在阈值另一侧的个体的值是可用的。这通常是由于业务规则的应用。例如，在招聘背景下，如果只有GPA超过3.0的候选人才能接受面试，那么对于低于该阈值的候选人将没有任何面试分数。这会使*面试分数*在*GPA*上成为MAR（[Figure
    6-19](#interview_score_being_mar_on_gpa)）。
- en: '![Interview score being MAR on GPA](Images/BEDA_0619.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![Interview score being MAR on GPA](Images/BEDA_0619.png)'
- en: Figure 6-19\. Interview score being MAR on GPA
  id: totrans-203
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-19. *面试分数*在*GPA*上成为MAR
- en: Note
  id: totrans-204
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Rubin’s classification of MCAR/MAR/MNAR is based solely on what the cause of
    missingness is. It doesn’t take into account whether that causal relationship
    shows randomness or not. Here, counterintuitively, the fact that the missingness
    of *InterviewScore* is based deterministically on *GPA* makes *InterviewScore
    MAR* on *GPA* even though there’s no randomness involved.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 精研的MCAR/MAR/MNAR分类仅基于缺失原因，而不考虑该因果关系是否显示出随机性。在这里，令人感到反直觉的是，*InterviewScore*的缺失基于*GPA*的确定性关系，使得*InterviewScore*在*GPA*上成为MAR，尽管其中并没有涉及随机性。
- en: This can also happen for variables that are MNAR, where only values above or
    below a certain threshold get recorded. For instance, only values outside of a
    normal range may be saved in a file, or only people under or above a certain threshold
    will register themselves (e.g., for tax purposes).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这也可能发生在MNAR类型的变量上，仅记录超过或低于某一阈值的值。例如，只有在文件中保存了正常范围之外的值，或者只有超过或低于某一阈值的人才会注册（例如，出于税务目的）。
- en: In between these two extremes of complete randomness and complete determinism
    (either of the MAR or MNAR type), there are situations where the probability of
    missingness increases or decreases continuously based on the values of the cause
    of missingness.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在完全随机和完全确定之间的这两个极端情况（无论是MAR还是MNAR类型），存在着根据缺失原因的值连续增加或减少缺失概率的情况。
- en: '[Figure 6-20](#missingness_spectrumcomma_from_mcar_lef) shows what this looks
    like in the simplest case of two variables, X and Y, where X has missing values.
    For the sake of readability, available values are shown as full squares, whereas
    “missing” values are shown as crosses. The first row of [Figure 6-20](#missingness_spectrumcomma_from_mcar_lef)
    shows scatterplots of Y against X and the second row shows for each one of these
    a line plot of the relationship between X and the probability of missingness:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[Figure 6-20](#missingness_spectrumcomma_from_mcar_lef)显示了两个变量X和Y的最简单情况下的情况，其中X具有缺失值。为了便于阅读，可用值显示为实心方块，而“缺失”值显示为叉号。[Figure
    6-20](#missingness_spectrumcomma_from_mcar_lef)的第一行显示了Y相对于X的散点图，第二行显示了X和缺失概率之间关系的线图：'
- en: The leftmost column shows X being MCAR. The probability of missingness is constant
    at 0.5 and independent of X. Squares and crosses are spread similarly across the
    plot.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最左列显示X是MCAR。缺失的概率在0.5处恒定且与X无关。方块和叉号在图中分布类似。
- en: The central columns show X being probabilistically MNAR with increasing strength.
    Squares are more common on the left of the plot and crosses more common on the
    right, but there are still crosses on the left and squares on the right.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中间列显示X是具有逐渐增强概率MNAR的概率性MNAR。方块在图的左侧更为普遍，而叉号在右侧更为普遍，但左侧仍然存在叉号，右侧仍然存在方块。
- en: The rightmost column shows X being deterministically MNAR. All values of X below
    5 are available (squares) and all the values above 5 are “missing” (crosses).
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最右侧的列显示X是确定性MNAR。所有低于5的X值是可用的（方块），而所有高于5的值都是“缺失”的（叉号）。
- en: '![Missingness spectrum, from MCAR (leftmost) to deterministic MNAR (rightmost)
    through probabilistic MNAR (center)](Images/BEDA_0620.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![从 MCAR（最左侧）到确定性 MNAR（最右侧），穿过概率性 MNAR（中心）的缺失程度谱](Images/BEDA_0620.png)'
- en: Figure 6-20\. Missingness spectrum, from MCAR (leftmost) to deterministic MNAR
    (rightmost) through probabilistic MNAR (center)
  id: totrans-213
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-20\. 缺失程度谱，从 MCAR（最左侧）到确定性 MNAR（最右侧），穿过概率性 MNAR（中心）
- en: This spectrum of missingness is rarely discussed in statistical treatments of
    missing data, because it is difficult to confirm through purely mathematical methods.
    But this is a book about behavioral analytics, so we can and should use common
    sense and business knowledge. In the GPA example, the threshold in data results
    from the application of a business rule that you should be aware of. In most situations,
    you expect a variable to be in a certain range of values, and you should have
    a sense of how likely it is for a possible value to not be represented in your
    data.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这种缺失程度的谱很少在缺失数据的统计处理中讨论，因为仅凭数学方法很难确认。但这是一本关于行为分析的书籍，因此我们可以和应该使用常识和业务知识。在 GPA
    的例子中，数据的阈值是由你应该了解的业务规则应用而来的。在大多数情况下，您期望一个变量落在某些值的特定范围内，并且您应该知道可能出现某个可能值不在您的数据中的概率有多高。
- en: 'In our AirCnC survey data, we have three personality traits: *Openness*, *Extraversion*,
    and *Neuroticism*. In real life, these variables would result from the aggregation
    of the answers to several questions and would have a bell-shaped distribution
    over a known interval (see Funder (2016) for a good introduction to personality
    psychology). Let’s assume that the relevant interval is 0 to 10 in our data and
    let’s look at the distribution of our variables ([Figure 6-21](#histograms_of_personality_traits_in_our)).'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 AirCnC 调查数据中，我们有三个人格特质：*开放性*、*外倾性*和*神经质*。在现实生活中，这些变量将是对几个问题回答的汇总，并且在已知区间内有钟形分布（参见
    Funder (2016) 了解人格心理学的良好介绍）。让我们假设在我们的数据中，相关区间是从 0 到 10，并且让我们来看看我们变量的分布（[图 6-21](#histograms_of_personality_traits_in_our)）。
- en: '![Histograms of personality traits in our data](Images/BEDA_0621.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![我们数据中的人格特征直方图](Images/BEDA_0621.png)'
- en: Figure 6-21\. Histograms of personality traits in our data
  id: totrans-217
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-21\. 我们数据中的人格特征直方图
- en: Clearly, something is going on with *Neuroticism*. Based on how the personality
    traits are constructed, we would expect the same type of curve for all three variables,
    and we would certainly not expect to have a large number of customers with a value
    of 5, and none with a value of 4\. This overwhelmingly suggests a deterministically
    MNAR variable, which we’ll have to handle accordingly.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，*神经质*有些问题。基于人格特征的构建方式，我们预期三个变量的曲线类型相同，而不会出现大量数值为5的客户，也不会一个数值为4的客户都没有。这极大地暗示了一个确定性的缺失非随机变量，我们必须相应地处理。
- en: You should now be able to form a reasonable opinion of the pattern of missingness
    in a data set. How many missing values are there? Does their missingness appear
    related to the values of the variable itself (MNAR), another variable (MAR), or
    neither (MCAR)? Are these missingness relationships probabilistic or deterministic?
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您应该能够合理判断数据集中缺失情况的模式。有多少缺失值？它们的缺失是否与变量本身的值（MNAR）、另一个变量（MAR）或者都不相关（MCAR）有关？这些缺失关系是概率性的还是确定性的？
- en: '[Figure 6-22](#decision_tree_to_diagnose_missing_data) presents a decision
    tree recapping our logic to diagnose missing data.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 6-22](#decision_tree_to_diagnose_missing_data) 展示了一个决策树，总结了我们诊断缺失数据的逻辑。'
- en: '![Decision tree to diagnose missing data](Images/BEDA_0622.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![诊断缺失数据的决策树](Images/BEDA_0622.png)'
- en: Figure 6-22\. Decision tree to diagnose missing data
  id: totrans-222
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-22\. 诊断缺失数据的决策树
- en: In the next section, we’ll see how to deal with missing data in each of these
    cases.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将看到如何在每种情况下处理缺失数据。
- en: Handling Missing Data
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理缺失数据
- en: 'The first thing to keep in mind as we get into the how-to section of the chapter
    is that we’re not trying to deal with missing data for the sake of it: our goal
    is to obtain unbiased and accurate estimates of causal relationships in our data.
    Missing data is problematic only to the extent that it interferes with that goal.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进入本章的操作部分时，首先要记住的是我们并不是为了处理缺失数据而处理缺失数据：我们的目标是在我们的数据中获得无偏差和准确的因果关系估计。只有当缺失数据干扰了这一目标时，缺失数据才会成为问题。
- en: This bears emphasizing, because your first instinct might be that the outcome
    of successfully addressing missing data is a data set with no missing data, and
    that’s just not the case. The method we’ll be using, multiple imputation (MI),
    creates multiple copies of your data, each one with its own imputed values. In
    layman’s terms, we will never be saying “the correct replacement for Bob’s missing
    age is 42” but rather “Bob might be 42, 38, 44, 42, or 38 years old.” There is
    no single best guess, but instead a distribution of possibilities. Another best-practice
    approach, maximum likelihood estimation, doesn’t even make any guess for individual
    values and only deals with higher-order coefficients such as means and covariances.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点需要强调，因为你的第一反应可能是，成功处理缺失数据的结果是一个没有缺失数据的数据集，但事实并非如此。我们将使用的方法，多重插补（MI），会为您的数据创建多个副本，每个副本都有其自己的插补值。通俗地说，我们永远不会说“Bob
    缺失的年龄的正确替代值是 42 岁”，而是“Bob 可能是 42 岁、38 岁、44 岁、42 岁或者 38 岁”。没有单一的最佳猜测，而是一系列可能性。另一个最佳实践方法，最大似然估计，甚至不会对个别值进行任何猜测，只处理高阶系数，例如均值和协方差。
- en: 'In the next subsection, I will give you a high-level overview of the MI approach.
    After that, we’ll dive into more detailed algorithm specifications for the model:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我将为您提供 MI 方法的高级概述。之后，我们将深入研究模型的更详细算法规格：
- en: First, the predictive mean matching algorithm
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，预测均值匹配算法
- en: Then, the normal algorithm
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，正常算法
- en: Finally, how to add auxiliary variables to an algorithm
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，如何将辅助变量添加到算法中
- en: Unfortunately, there isn’t a one-to-one relationship between the type of missingness
    in Rubin’s classifications and the appropriate algorithm specification, as the
    amount of information available also matters ([Table 6-4](#optimal_mi_parameters_based_on_type_of)).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，鲁宾分类中缺失类型与适当的算法规格之间并不存在一对一的关系，因为可用的信息量也很重要（参见 [表 6-4](#optimal_mi_parameters_based_on_type_of)）。
- en: Table 6-4\. Optimal MI parameters based on type of missingness and information
    available
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-4. 根据缺失类型和可用信息的最佳 MI 参数
- en: '| Missingness type | No info | Distribution of variable is normal | Distribution
    of missingness is deterministic |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 缺失类型 | 无信息 | 变量分布为正态 | 缺失分布为确定性 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **MCAR** | Mean matching | Normal | (not possible) |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| **MCAR** | 均值匹配 | 正态分布 | （不可能） |'
- en: '| **MAR** | Mean matching | Normal | Normal + auxiliary variables |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| **MAR** | 均值匹配 | 正态分布 | 正态分布 + 辅助变量 |'
- en: '| **MNAR** | Mean matching + auxiliary variables | Normal + auxiliary variables
    | Normal + auxiliary variables |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| **MNAR** | 均值匹配 + 辅助变量 | 正态分布 + 辅助变量 | 正态分布 + 辅助变量 |'
- en: Introduction to Multiple Imputation (MI)
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多重插补（MI）介绍
- en: To understand how multiple imputation works, it helps to contrast it with the
    traditional approaches to missing data. Apart from simply dropping all rows with
    missing values, traditional approaches all rely on replacing missing values with
    a specific value. The replacement value may be the overall mean of the variable,
    or the predicted values based on the other variables available for that customer.
    Regardless of the rule used for the replacement value, these approaches are fundamentally
    flawed because they ignore the additional uncertainty introduced by the presence
    of missing data, and they may introduce bias in our analyses.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解多重插补的工作原理，有助于将其与传统的处理缺失数据的方法进行对比。除了简单地删除所有具有缺失值的行之外，传统方法都依赖于用特定值替换缺失值。替换值可以是变量的整体平均值，或者基于其他可用于该客户的变量预测的值。无论用于替换值的规则如何，这些方法都存在根本性缺陷，因为它们忽略了由缺失数据引入的额外不确定性，并且可能会在分析中引入偏差。
- en: The MI solution to this problem is, as its name indicates, to build multiple
    data sets where missing values are replaced by different values, then run our
    analysis of interest with each one of them, and finally aggregate the resulting
    coefficients.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的 MI 解决方案，正如其名称所示，是构建多个数据集，其中缺失值被不同的值替换，然后用每个数据集运行我们感兴趣的分析，并最终聚合生成的系数。
- en: In both R and Python, this whole process is managed behind the scenes, and if
    you want to keep it simple, you can just specify the data and analyses you want
    to run.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 和 Python 中，整个过程都是在后台管理的，如果您想保持简单，只需指定要运行的数据和分析即可。
- en: 'Let’s look first at the R code:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们看看 R 代码：
- en: '[PRE14]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `mice` package (Multiple Imputation by Chained Equations) has the `mice()`
    function, which generates the multiple data sets. We then apply our regression
    of interest to each one of them by using the keyword `with()`. Finally, the `pool()`
    function from `mice` aggregates the results in a format that we can read with
    the traditional `summary()` function.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`mice`包（多重插补通过链式方程）具有`mice()`函数，用于生成多个数据集。然后，我们使用`with()`关键字将感兴趣的回归应用于每一个数据集。最后，从`mice`中使用`pool()`函数以我们可以用传统的`summary()`函数读取的格式汇总结果。'
- en: 'The Python code is almost identical, because it implements the same approach:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: Python代码几乎相同，因为它实现了相同的方法：
- en: '[PRE15]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Here, the `mice` algorithm is imported from the `statsmodels.imputation` package.
    The `MICEData()` function generates the multiple data sets. We then indicate through
    the `MICE()` function the model formula, regression type (here, `statsmodels.OLS`),
    and data we want to use. We fit our model with the `.fit()` and `.summary()` methods
    before printing the outcome.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`mice`算法从`statsmodels.imputation`包中导入。`MICEData()`函数生成多个数据集。然后，通过`MICE()`函数指定模型公式、回归类型（这里是`statsmodels.OLS`）和要使用的数据。我们使用`.fit()`和`.summary()`方法拟合我们的模型，然后打印结果。
- en: Note
  id: totrans-248
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'One complication with the Python implementation of `mice` is that it doesn’t
    accommodate categorical variables as predictors. If you really want to use Python
    nonetheless, you’ll have to one-hot encode categorical variables first. The following
    code shows how to do it for the *Gender* variable:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: Python实现的`mice`方法的一个复杂之处在于它不支持分类变量作为预测因子。如果您确实想使用Python，您首先需要对分类变量进行独热编码。以下代码展示了如何处理*性别*变量：
- en: '[PRE16]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: First, we use the `get_dummies()` function from pandas to create variables `gender_F`
    and `gender_M`. After adding these columns to our dataframe, we indicate where
    the missing values are (by default, the one-hot encoding function sets all binary
    variables to 0 when the value for the categorical variable is missing). Finally,
    we drop our original categorical variable from our data and fit our model with
    the new variables included.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用pandas的`get_dummies()`函数创建变量`gender_F`和`gender_M`。在将这些列添加到我们的数据帧之后，我们指示缺失值的位置（默认情况下，独热编码函数在分类变量值缺失时将所有二进制变量设置为0）。最后，我们从数据中删除原始分类变量，并使用包含新变量的模型进行拟合。
- en: However, one-hot encoding breaks some of the internal structure of the data
    by removing the logical connections between variables, so your mileage may vary
    (e.g., you can see that the coefficients for the categorical variables are different
    between R and Python because of the different structures) and I would encourage
    you to use R instead if categorical variables play an important role in your data.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，独热编码通过删除变量之间的逻辑连接来破坏数据的内部结构，因此效果可能因人而异（例如，您可以看到因为结构不同，R和Python中的分类变量系数不同），如果分类变量在您的数据中起重要作用，我建议您使用R而不是Python。
- en: Voilà! If you were to stop reading this chapter right now, you would have a
    solution to handle missing data that would be significantly better than the traditional
    approaches. However, we can do even better by taking the time to lift the hood
    and better understand the imputation algorithms.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！如果您现在停止阅读本章，您将得到一个处理缺失数据的解决方案，这比传统方法要好得多。然而，通过花时间揭示内部机制并更好地理解插补算法，我们可以做得更好。
- en: 'Default Imputation Method: Predictive Mean Matching'
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 默认插补方法：预测均值匹配
- en: 'In the previous subsection, we left the imputation method unspecified and relied
    on `mice`’s defaults. In Python, the only imputation method available is predictive
    mean matching, so there’s nothing to do there. Let’s check what the default imputation
    methods are in R by asking for a summary of the imputation process:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一小节中，我们未指定插补方法，依赖于`mice`的默认设置。在Python中，唯一可用的插补方法是预测均值匹配，因此在这里没有其他操作。让我们来看看R中默认的插补方法，通过请求插补过程的摘要：
- en: '[PRE17]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'That’s a lot of information. For now, let’s look only at the `Imputation methods`
    line. Variables that don’t have missing data have an empty field `""`, which makes
    sense because they don’t get imputed. Categorical variables have the method `logreg`,
    i.e., logistic regression. Finally, numeric variables have the method `pmm`, which
    stands for predictive mean matching (PMM). The `pmm` method works by selecting
    the closest neighbors of the individual with the missing value and replacing the
    missing value with the value of one of the neighbors. Imagine, for example, a
    data set with only two variables: *Age* and *ZipCode*. If you have a customer
    from zip code 60612 with a missing age, the algorithm will pick at random the
    age of another customer in the same zip code, or as close as possible.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这是很多信息。现在，让我们只看看`Imputation methods`一行。没有缺失数据的变量有一个空字段`""`，这是有道理的，因为它们不会被填充。分类变量具有方法`logreg`，即逻辑回归。最后，数值变量具有方法`pmm`，即预测均值匹配（PMM）。`pmm`方法的工作原理是选择具有缺失值的个体的最近邻居，并用一个邻居的值替换缺失值。例如，假设数据集只有两个变量：*Age*
    和 *ZipCode*。如果您有一个来自邮编60612且年龄缺失的客户，算法将随机选择同一邮编中另一个客户的年龄，或者尽可能接近的客户的年龄。
- en: 'Because of some randomness baked in the process, each of the imputed data sets
    will end up with slightly different values, as we can visualize through the convenient
    `densityplot``()` function from the `mice` package in R:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 由于过程中存在一些随机性，每个填充的数据集最终会得到略有不同的值，我们可以通过`mice`包中方便的`densityplot()`函数可视化来查看：
- en: '[PRE18]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[Figure 6-23](#distributions_of_imputed_values_for_num) shows the distributions
    of the numeric variables in the original available data (thick line) and in the
    imputed data sets (thin dashed lines). As you can see, the distributions stick
    pretty close to the original data; the exception is *BookingAmount*, which is
    overall more concentrated around the mean (i.e., “higher peaks”) in the imputed
    data set than in the original data.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 6-23](#distributions_of_imputed_values_for_num)显示了原始可用数据（粗线）和填充数据集（细虚线）中数值变量的分布。如您所见，分布与原始数据非常接近；唯一的例外是*BookingAmount*，在填充数据集中，它的分布总体上更集中在均值周围（即“更高的峰值”）。'
- en: '![Distributions of imputed values for numeric variables in our data](Images/BEDA_0623.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![我们数据中数值变量的填充值分布](Images/BEDA_0623.png)'
- en: Figure 6-23\. Distributions of imputed values for numeric variables in our data
  id: totrans-262
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-23\. 我们数据中数值变量的填充值分布
- en: PMM has some important properties that may or may not be desirable, depending
    on the context. The most important property is that it’s basically an interpolation
    method. Therefore, you can picture PMM as creating values that are between existing
    values. By doing so, it minimizes the risk of creating nonsensical situations
    such as pregnant fathers or negative amounts. This approach will also work well
    when a variable has a weird distribution, such as *Age* in our data, which has
    two peaks, because it makes no assumptions about the shape of the overall distribution;
    it just grabs a neighbor.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: PMM 具有一些重要的特性，这些特性可能是需要的，也可能不需要，这取决于上下文。最重要的特性是它基本上是一种插值方法。因此，您可以将 PMM 想象为创建介于现有值之间的值。通过这样做，它最小化了创建荒谬情况的风险，比如怀孕的父亲或负数金额。这种方法在变量具有奇怪分布时也能很好地工作，比如我们数据中的*Age*，它有两个峰值，因为它对整体分布的形状没有假设；它只是选择一个邻居。
- en: 'There are several downsides to PMM, however: it’s slow and doesn’t scale well
    to large data sets, because it must constantly recalculate distances between individuals.
    In addition, when you have many variables or a lot of missing values, the closest
    neighbors may be “far away,” and the quality of the imputation will deteriorate.
    This is why PMM will not be our preferred option when we have distributional information,
    as we’ll see in the next subsection.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，PMM 有几个缺点：它速度较慢，并且在大数据集上不易扩展，因为它必须不断重新计算个体之间的距离。此外，当您有许多变量或许多缺失值时，最近的邻居可能“很远”，填充的质量会降低。这就是为什么当我们拥有分布信息时，PMM
    不会是我们首选的选项，正如我们将在下一小节中看到的那样。
- en: From PMM to Normal Imputation (R Only)
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 PMM 到正态填充（仅限 R）
- en: 'While PMM is a decent starting point, we often have information about the distribution
    of numeric variables that we can leverage to speed up and improve our imputation
    models in R. In particular, behavioral and natural sciences often assume that
    numeric variables follow a normal distribution, because it is very common. When
    that’s the case, we can fit a normal distribution to a variable and then draw
    imputation values from that distribution instead of using PMM. This is done by
    creating a vector of imputation methods, with the value `"norm.nob"` for the variables
    for which we’ll assume normality, and then passing that vector to the `parameter`
    method of the `mice()` function:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然PMM是一个不错的起点，但我们经常有关于数值变量分布的信息，我们可以利用这些信息来加快和改进R中的插补模型。特别是，行为和自然科学通常假设数值变量服从正态分布，因为这是非常常见的。在这种情况下，我们可以对变量拟合正态分布，然后从该分布中提取插补值，而不是使用PMM。这通过创建一个插补方法的向量来完成，对于我们将假设正态性的变量，向量中的值设为`"norm.nob"`，然后将该向量传递给`mice()`函数的`parameter`方法。
- en: '[PRE19]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As you can see, the syntax is very simple. The only question is to determine
    for which of the numeric variables we want to use a normal imputation. Let’s look
    at the numeric variables in our available data ([Figure 6-24](#distribution_of_numeric_variables_in_ou)).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，语法非常简单。唯一的问题是确定我们要为哪些数值变量使用正常插补。让我们来看看我们可用数据中的数值变量（[图 6-24](#distribution_of_numeric_variables_in_ou)）。
- en: '![Distribution of numeric variables in our data](Images/BEDA_0624.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![我们数据中的数值变量分布](Images/BEDA_0624.png)'
- en: Figure 6-24\. Distribution of numeric variables in our data
  id: totrans-270
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-24\. 我们数据中的数值变量分布
- en: '*Age* is obviously not normal with its two peaks, but all the other variables
    have only one peak. *Openness*, *Extraversion,* and *BookingAmount* also appear
    reasonably symmetrical (in technical terms, they’re not skewed). Statistical simulations
    show that as long as a variable is one-peaked and doesn’t have a “fat tail” in
    only one direction, assuming normality does not introduce bias. Therefore, we
    can assume normality for *Openness*, *Extraversion,* and *BookingAmount*.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '*年龄*显然不是正态的，因为它有两个峰，但所有其他变量只有一个峰。*开放性*、*外向性*和*预订金额*看起来也相对对称（在技术上来说，它们不倾斜）。统计模拟表明，只要一个变量是单峰的，并且在一个方向上没有“粗尾”，假设正态性不会引入偏差。因此，我们可以假设*开放性*、*外向性*和*预订金额*是正态分布的。'
- en: 'As we saw in the previous section, *Neuroticism* presents an unusual asymmetrical
    pattern: values are restricted to [5,10] even though the psychological scale we’re
    using goes from 0 to 10, which suggests that *Neuroticism* might be “deterministically”
    MNAR, i.e., all values of *Neuroticism* below a certain threshold are missing.
    Using PMM for imputation is problematic in such a situation: there are only a
    few or no neighbors for imputation on a significant range of values. At the extreme,
    all the missing values of X would be imputed as 5, the value of the threshold.
    This is a situation where the normal method will be better able to recover the
    true missing values. We can see that by comparing the values imputed by the two
    methods. [Figure 6-25](#pmm_imputation_left_parenthesistopright) shows the available
    values of *Neuroticism* (squares) and the values imputed with the PMM method (crosses,
    top panel) and with the normal method (crosses, bottom panel).'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中看到的，*神经质*呈现出不寻常的非对称模式：尽管我们使用的心理学尺度从0到10，但其值被限制在[5,10]之间，这表明*神经质*可能是“确定性地”MNAR，即*神经质*的所有值低于某个阈值都会缺失。在这种情况下使用PMM进行插补是有问题的：在大部分值范围内插补时几乎没有或根本没有邻居可用。极端情况下，X的所有缺失值将被插补为5，即阈值的值。这是一种普通方法更能恢复真实缺失值的情况。我们可以通过比较两种方法插补的值来看出这一点。[图 6-25](#pmm_imputation_left_parenthesistopright)显示了*神经质*的可用值（方块）以及用PMM方法插补的值（十字，顶部面板）和用普通方法插补的值（十字，底部面板）。
- en: '![PMM imputation (top) and normal imputation (bottom) with a deterministically
    MNAR variable](Images/BEDA_0625.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![PMM插补（顶部）和普通插补（底部）对确定性MNAR变量的影响](Images/BEDA_0625.png)'
- en: Figure 6-25\. PMM imputation (top) and normal imputation (bottom) with a deterministically
    MNAR variable
  id: totrans-274
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-25\. PMM插补（顶部）和普通插补（底部）对确定性MNAR变量的影响
- en: As you can see, the PMM method doesn’t impute any value for *Neuroticism* below
    5, whereas the normal method does. In addition, the PMM method imputes too many
    values close to 10, whereas the normal method more adequately captures the overall
    shape of the distribution. Still, the normal method is far from recovering the
    true distribution (which goes all the way to zero). This is a common problem for
    variables that are deterministically MAR or MNAR. We can further improve on the
    normal imputation by using auxiliary variables, as we’ll see in the next subsection.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，PMM 方法不对*神经质*低于 5 的任何值进行插补，而普通方法则会这样做。此外，PMM 方法对接近 10 的值进行了过多的插补，而普通方法更好地捕捉了分布的整体形状。然而，普通方法远未恢复真实分布（该分布一直延伸到零）。这是确定性地为
    MAR 或 MNAR 变量的常见问题。我们可以通过使用辅助变量进一步改进普通插补，正如我们将在下一小节中看到的那样。
- en: Adding Auxiliary Variables
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加辅助变量
- en: Quite often, we’ll have variables that are correlated with one of our variables
    with missing data (e.g., causes or effects of that variable) but don’t belong
    in our regression model. This is a situation where the `mice` algorithm especially
    shines, because we can add these variables to our imputation model to increase
    its accuracy. They are then referred to as the “auxiliary variables” of our imputation
    model.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 很多时候，我们会有与我们的某个具有缺失数据的变量相关的变量（例如，该变量的原因或影响），但不属于我们的回归模型。这是 `mice` 算法特别出色的情况，因为我们可以将这些变量添加到我们的插补模型中，以提高其准确性。然后它们被称为我们插补模型的“辅助变量”。
- en: For our AirCnC example, the supplementary available data set contains two variables,
    *Insurance* and *Active*. The former indicates the amount of travel insurance
    bought by the customer and is strongly correlated with *Neuroticism*, while the
    latter measures the degree to which the customer has picked active vacations (e.g.,
    rock climbing) and is strongly correlated with *Extraversion*. We’ll use them
    to help impute the two personality variables.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的 AirCnC 示例，可用的补充数据集包含两个变量，*保险*和*活跃*。前者指示客户购买的旅行保险金额，与*神经质*强相关；而后者则测量客户选择活跃度假（例如攀岩）的程度，并与*外向性*强相关。我们将使用它们来帮助插补这两个人格变量。
- en: 'Adding auxiliary variables to the imputation model is extremely simple: we
    simply need to add them to our data set before the imputation phase:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 向插补模型添加辅助变量非常简单：我们只需在插补阶段之前将它们添加到我们的数据集中即可。
- en: '[PRE20]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We can then run all our analyses as before. When adding auxiliary variables,
    it generally makes sense to use the normal method for the variables correlated
    with our auxiliary variables (here *Neuroticism* and *Extraversion*), especially
    when these variables are truncated or MNAR.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像以前一样运行所有分析。在添加辅助变量时，通常有意义使用普通方法来处理与我们的辅助变量相关的变量（这里是*神经质*和*外向性*），特别是当这些变量被截断或
    MNAR 时。
- en: Apart from computation constraints, there are no limits to the number of auxiliary
    variables we can include. However, a potential risk is that some of our auxiliary
    variables may misleadingly appear correlated with a variable in our original data
    set just out of sheer randomness, e.g., *Insurance* appearing correlated with
    *Extraversion* even though it isn’t truly. Such a “false positive” correlation
    would then be unduly reinforced by the imputation model.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 除了计算约束外，我们可以包含的辅助变量数量没有限制。然而，潜在风险是我们的一些辅助变量可能仅仅因为纯粹的随机性而似乎与原始数据集中的某个变量相关，例如，*保险*看似与*外向性*相关，尽管实际上并非如此。这样的“假阳性”相关性将会被插补模型错误地加强。
- en: 'The solution to that potential problem is to restrict auxiliary variables to
    be used only for the imputation of certain variables. Unfortunately, this solution
    is available only in R. This is where the predictor matrix of the `mice()` function
    comes in. This matrix appears when printing the summary of the imputation phase,
    and can also be extracted directly from our `MIDS` object:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个潜在问题的方法是仅限制辅助变量用于某些变量的插补。不幸的是，这种解决方案只在 R 中可用。这就是 `mice()` 函数的预测矩阵发挥作用的地方。该矩阵出现在打印插补阶段摘要时，并且还可以直接从我们的
    `MIDS` 对象中提取：
- en: '[PRE22]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This matrix indicates which variable is used to impute which. By default, all
    variables are used to impute all variables except themselves. A “1” in the matrix
    indicates that the “column” variable is used to impute the “row” variable. We’ll
    therefore want to modify the last two columns, for *Insurance* and *Active*, so
    that they’ll be used only to impute *Neuroticism* and *Extraversion* respectively:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 该矩阵指示用于填充哪些变量。默认情况下，除了自身外，所有变量都用于填充所有变量。矩阵中的“1”表示“列”变量用于填充“行”变量。因此，我们需要修改最后两列，用于仅填充*保险*和*活跃度*到*神经质*和*外向性*：
- en: '[PRE23]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: With that modification, we’ll reduce the risk of inadvertently baking in fluke
    correlations into our imputation model.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种修改，我们将减少意外地将偶然相关性纳入我们的填充模型的风险。
- en: Scaling Up the Number of Imputed Data Sets
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展缺失数据集数量
- en: The default number of imputed data sets created by the `mice` algorithm is 5
    in R and 10 in Python. These are fine defaults for exploratory analyses.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '`mice`算法在R中的默认生成的填充数据集数量为5，在Python中为10。这些对于探索性分析来说是很好的默认值。'
- en: For your final run, you should use 20 (by passing `m=20` as a parameter setting
    to the `mice()` function) if you’re interested only in the estimated values of
    the regression coefficients. If you want more precise information such as confidence
    intervals or interactions between variables, you might want to aim for 50 to 100\.
    The main constraints then become the computer’s speed and memory—if your data
    set is 100 Mb or even 1 Gb do you have the RAM to create a hundred copies of it?—as
    well as your patience.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在最终运行时，如果你只关心回归系数的估计值，应使用20（通过将`m=20`作为`mice()`函数的参数设置传递）。如果你需要更精确的信息，例如置信区间或变量之间的交互作用，可能需要目标设定为50到100。主要的限制因素是计算机的速度和内存——如果你的数据集大小为100
    Mb甚至1 Gb，你是否有足够的RAM来创建100份拷贝？——以及你的耐心。
- en: 'The syntax to change the number of imputed data sets is straightforward. In
    R it is passed as a parameter to the `mice()` function, while in Python it is
    passed as a parameter for the `.fit()` method of the `MICE` object:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 更改填充数据集数量的语法很简单。在R中，它作为参数传递给`mice()`函数，而在Python中，它作为`MICE`对象的`.fit()`方法的参数传递：
- en: '[PRE24]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Conclusion
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Missing data can present a real problem in behavioral data analysis, but it
    doesn’t have to. At a minimum, using the `mice` package in R or Python with its
    default parameters will outperform deleting all rows with missing values. By properly
    diagnosing missingness based on Rubin’s classification, and leveraging all available
    information, you can generally do better than that. To recap the decision rules
    in one place, [Figure 6-26](#decision_tree_to_diagnose_missing_datad) shows the
    decision tree to diagnose missing data and [Table 6-5](#optimal_imputation_method_based_on_type)
    the optimal MI parameters based on type of missingness and information available.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据在行为数据分析中可能会带来真正的问题，但这并非必然。至少，使用R或Python中的`mice`包及其默认参数将优于删除所有具有缺失值的行。通过基于Rubin的分类正确诊断缺失性，并利用所有可用信息，通常可以取得更好的效果。总结决策规则，[图6-26](#decision_tree_to_diagnose_missing_datad)展示了用于诊断缺失数据的决策树，[表6-5](#optimal_imputation_method_based_on_type)展示了基于缺失类型和可用信息的最佳MI参数。
- en: '![Decision tree to diagnose missing data](Images/BEDA_0626.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![诊断缺失数据的决策树](Images/BEDA_0626.png)'
- en: Figure 6-26\. Decision tree to diagnose missing data
  id: totrans-298
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-26\. 诊断缺失数据的决策树
- en: Table 6-5\. Optimal MI parameters based on type of missingness and information
    available
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 表6-5\. 根据缺失类型和可用信息的最佳MI参数
- en: '| Type of missingness | No info | Variable distribution is normal | Missingness
    distribution is deterministic |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| 缺失类型 | 无信息 | 变量分布正常 | 缺失分布确定性 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **MCAR** | PMM | `norm.nob` |   |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| **MCAR** | PMM | `norm.nob` |   |'
- en: '| **MAR** | PMM | `norm.nob` | `norm.nob` + aux. var. |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| **MAR** | PMM | `norm.nob` | `norm.nob` + aux. var. |'
- en: '| **MNAR** | PMM + aux. var. | `norm.nob` + aux. var. | `norm.nob` + aux. var.
    |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| **MNAR** | PMM + aux. var. | `norm.nob` + aux. var. | `norm.nob` + aux. var.
    |'
