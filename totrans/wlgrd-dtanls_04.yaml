- en: 5 Unusual data sources
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 种不寻常的数据源
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Thinking of data beyond what is available in structured formats
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑数据不仅仅是结构化格式中可用的数据
- en: Using all the data sources available to you creatively, regardless of their
    format
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创造性地使用你所能获得的所有数据源，无论其格式如何
- en: Navigating the tradeoff between time spent and value added when working with
    additional data sources
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用额外数据源时，在花费的时间和增加的价值之间进行权衡
- en: Most datasets you will encounter in your career are not as clean and structured
    as those provided in a learning environment. The reality is that it’s often the
    analyst who must search for the right data, which may be hidden in complicated
    spreadsheets or hidden even further in unstructured, nontraditional data sources.
    This chapter is about practicing the creativity of identifying and using novel
    and unstructured data sources to answer interesting analytical questions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你在职业生涯中遇到的大多数数据集都不像学习环境中提供的那样干净和结构化。现实情况是，通常分析师必须寻找正确的数据，这些数据可能隐藏在复杂的电子表格中，甚至更隐藏在非结构化、非传统数据源中。本章是关于练习识别和使用新颖的非结构化数据源来回答有趣的统计分析问题的创造力。
- en: Structured vs. unstructured data
  id: totrans-6
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 结构化数据与非结构化数据
- en: For the sake of clarity, when I use the words “structured” and “unstructured”
    to describe a dataset, I mean tabular, two-dimensional data versus everything
    else. Analysts typically work with structured data—something with rows and columns
    that can be opened in Excel or something that sits in a database and could conceivably
    be opened in Excel. Unstructured data is anything that isn’t in a rows and columns
    format, ranging from documents or raw audio to free text or a binary data format.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，当我使用“结构化”和“非结构化”这些词来描述数据集时，我的意思是表格数据，二维数据与所有其他数据的对比。分析师通常处理结构化数据——可以在Excel中打开的具有行和列的数据，或者位于数据库中，理论上可以在Excel中打开的数据。非结构化数据是任何不是行和列格式的数据，范围从文档或原始音频到自由文本或二进制数据格式。
- en: In this project, you will be working with unstructured PDF files containing
    structured data tables. The semantics of whether we call this data unstructured,
    structured, semi-structured, or something else does not change the fact that working
    with PDFs is not the same as working with tabular data. That is the structured
    versus unstructured difference with which we are dealing in this chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，你将处理包含结构化数据表的未结构化PDF文件。我们称这些数据为未结构化、结构化、半结构化或其他，其语义不会改变这样一个事实：处理PDF与处理表格数据并不相同。这是我们本章中处理的结构化与非结构化差异。
- en: 5.1 Identifying novel data sources
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 识别新型数据源
- en: I always advocate starting with a problem to solve. This is no different when
    thinking about additional data sources to use for your analysis. Once you have
    a clear problem statement, it is easier to understand what data sources you still
    need. This is why identifying and obtaining data are steps 3 and 4, and not steps
    1 and 2, of the results-driven approach.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我总是主张从要解决的问题开始。在考虑用于分析的其他数据源时，这也没有什么不同。一旦你有一个明确的问题陈述，就更容易理解你还需要哪些数据源。这就是为什么识别和获取数据是结果驱动方法中的第3步和第4步，而不是第1步和第2步。
- en: What data is available to you will vary between workplaces, but generally, the
    kinds of data that may be helpful to consider are
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你能获得的数据将在不同工作场所之间有所不同，但通常，可能有助于考虑的数据类型包括
- en: Data generated by typical business processes, such as emails.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由典型业务流程生成数据，例如电子邮件。
- en: Data in operational systems, if this is not already available.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运营系统中的数据，如果尚未可用。
- en: Self-hosted data, meaning data people create for themselves, such as spreadsheets
    on people’s computer desktops. These are important only if people rely on them
    for decision making. Otherwise, they may just be less accurate versions of existing
    operational data. One example is salespeople tracking their own client pipeline
    outside of the company CRM.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自托管数据，意味着人们为自己创建的数据，例如人们电脑桌面上的电子表格。这些数据只有在人们依赖它们进行决策时才重要。否则，它们可能只是现有运营数据的更不准确版本。一个例子是销售人员在公司CRM之外跟踪自己的客户管道。
- en: Industry data, such as market statistics published by a central body.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行业数据，例如由中央机构发布的市场统计数据。
- en: Government statistics, published as open data.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 政府统计数据，作为公开数据发布。
- en: White papers, public documents that summarize research on a given topic in an
    accessible way, created either internally or by a competitor.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 白皮书，公开文件，以易于理解的方式总结特定主题的研究，这些文件可能由内部创建或由竞争对手创建。
- en: 'Real business case: Extracting published industry data from PDFs'
  id: totrans-18
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 真实业务案例：从PDF中提取已发布的行业数据
- en: In many sectors, leading industry bodies publish market statistics, which are
    often the best indicators of the state of the market over time. Many of these
    statistics are published as tabular data, usually Excel files. However, in the
    past, I have had to resort to finding less structured forms of important statistics
    and writing my own PDF data extraction code. This is an experience every aspiring
    analyst should go through, hence the inclusion of this project.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多行业中，领先的行业机构发布市场统计数据，这些数据通常是衡量市场状况随时间变化的最佳指标。许多这些统计数据以表格数据的形式发布，通常是Excel文件。然而，在过去，我不得不求助于寻找不那么结构化的重要统计数据，并编写自己的PDF数据提取代码。这是每位有抱负的分析师都应该经历的经历，因此包含了这个项目。
- en: 5.1.1 Considerations for using new datasets
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 使用新数据集的考虑因素
- en: 'There are some general considerations when deciding to use an additional data
    source to augment your analysis:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定使用额外的数据源来增强分析时，有一些一般性的考虑因素：
- en: Does this data source integrate with existing data? Can we join or merge this
    dataset with the one we are already using or is that not required? There will
    be instances where salespeople record their sales in their own spreadsheets, either
    outside the “official” CRM or alongside it. Would it be possible to join the data
    in their own custom spreadsheet to the data in the CRM system? Is there a common
    client identifier, like an ID, present in both datasets? If not, can we still
    link clients across those datasets somehow, such as by name? Refer to chapter
    3 for a specific example of just such a problem.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个数据源是否与现有数据集成？我们能否将这个数据集与我们已经使用的那个合并，或者这并不是必需的？有些情况下，销售人员会在自己的电子表格中记录销售情况，无论是在“官方”CRM系统之外还是在旁边。是否有可能将他们自己的自定义电子表格中的数据与CRM系统中的数据合并？这两个数据集中是否存在一个共同的客户标识符，比如ID？如果没有，我们是否还能通过某种方式将客户在这两个数据集中联系起来，比如通过姓名？请参考第3章，以了解这样一个具体问题的例子。
- en: 'How much effort is it to extract structured data from this data source? This
    might involve manipulating an unstructured format and creating a tabular representation
    or taking a structured dataset that has a different format from our existing data
    and therefore requires work to change and rename columns to match the format we
    need. Either way, it is important to estimate the effort involved in this work
    before deciding to use a new data source:'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从这个数据源中提取结构化数据需要多少努力？这可能涉及操作非结构化格式并创建表格表示，或者取一个格式与我们的现有数据不同的结构化数据集，因此需要工作来更改和重命名列以匹配我们需要的格式。无论如何，在决定使用新的数据源之前，估算这项工作的努力程度是很重要的：
- en: A subset of this question is, do you currently have the expertise to manipulate
    this data? Not having worked with a particular data format is not a dealbreaker,
    but learning the necessary skills factors into estimating the effort involved.
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个问题的子集之一是，你目前是否具备操作这些数据的专业知识？没有与特定数据格式合作的经验并不是一个不可逾越的障碍，但学习必要的技能是估算所涉及努力的一个因素。
- en: A related consideration is, does your tool support this data format? If you
    are used to working solely in Excel, for example, it may be harder to manipulate
    unusual data formats, but a programming language such as Python or R may have
    a relevant library that is easy to install and use.
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关的考虑因素之一是，你的工具是否支持这种数据格式？例如，如果你习惯于仅使用Excel进行工作，那么处理不寻常的数据格式可能会更困难，但像Python或R这样的编程语言可能有一个易于安装和使用的相关库。
- en: What is the value of this additional data? What questions can you answer with
    it that you couldn’t answer before? Knowing this will help determine whether the
    effort will be worth it.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这额外数据的价值是什么？它能回答哪些你之前无法回答的问题？了解这一点将有助于确定这些努力是否值得。
- en: Does this data create additional dependencies? Will this additional data be
    used as a one-off, or is it something that will require engineering resources
    to continuously ingest and store?
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这数据是否创建了额外的依赖？这些额外数据是一次性使用，还是需要工程资源来持续摄取和存储的东西？
- en: '5.2 Project 4: Analyzing film industry trends using PDF data'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 项目4：使用PDF数据分析电影行业趋势
- en: Let’s take a look at the project in which we will extract structured data from
    PDF files to understand the effects of the COVID-19 pandemic on the film industry.
    We will look at the problems our stakeholders want to solve and the data sources
    they have provided. Section 5.3 will dive into how to approach this problem using
    the results-driven approach as well as some technical considerations when handling
    PDF files. As with every project, there is a section dedicated to a step-by-step
    example solution, which can be found in section 5.4\. As usual, our solutions
    will likely diverge, especially if you are not using Python, since I explore some
    Python-specific ways to read data tables from PDFs.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个项目，我们将从PDF文件中提取结构化数据，以了解COVID-19大流行对电影行业的影响。我们将研究我们的利益相关者想要解决的问题以及他们提供的数据来源。第5.3节将深入探讨如何使用结果驱动的方法来解决这个问题，以及处理PDF文件时的一些技术考虑。与每个项目一样，有一个专门用于逐步示例解决方案的部分，可在第5.4节找到。像往常一样，我们的解决方案可能会不同，尤其是如果您不使用Python，因为我探索了一些从PDF中读取数据表的Python特定方法。
- en: The data is available at [https://davidasboth.com/book-code](https://davidasboth.com/book-code).
    You will find the files with which you can attempt the project, as well as the
    example solution in the form of a Jupyter notebook.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可在[https://davidasboth.com/book-code](https://davidasboth.com/book-code)找到。您将找到可用于尝试项目的文件，以及以Jupyter笔记本形式的示例解决方案。
- en: 5.2.1 Problem statement
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 问题陈述
- en: In this scenario, you are working for EchoTale Analytics, a research firm in
    the entertainment industry. Their primary mission is to publish analytical pieces
    about the evolution of the entertainment industry, and you have been placed in
    charge of a project in their film division. Specifically, the firm wants to publish
    a white paper about how the COVID-19 pandemic has affected the film industry.
    They don’t currently have a more focused topic, so your task is to complete and
    present the preliminary research. Since the target is a white paper, the priority
    is to be able to tell a story that would be interesting to a film-loving audience.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个场景中，您为EchoTale Analytics工作，这是一家娱乐行业的研究公司。他们的主要任务是发布关于娱乐行业演变的分析文章，您被分配到他们的电影部门负责一个项目。具体来说，公司希望发布一份关于COVID-19大流行如何影响电影行业的白皮书。他们目前还没有一个更具体的主题，因此您的任务是完成并展示初步研究。由于目标是白皮书，优先考虑的是能够讲述一个对电影爱好者有吸引力的故事。
- en: The firm works exclusively with external data sources, and for this project,
    they have given you PDF reports from the British Film Industry’s (BFI) Research
    and Statistics Unit (RSU), called Statistical Yearbooks. These Yearbooks contain
    annual summaries of statistics about the film industry, including embedded data
    tables. Most of the data relates to the film industry in the United Kingdom, but
    some global statistics are included as well. The data goes back almost 20 years,
    and naturally, the format of the PDF report is not consistent.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 该公司仅与外部数据源合作，对于这个项目，他们给了您来自英国电影行业（BFI）研究统计单位（RSU）的PDF报告，称为统计年鉴。这些年鉴包含了关于电影行业的年度统计数据摘要，包括嵌入的数据表。大部分数据与英国的电影行业相关，但也包括一些全球统计数据。数据可以追溯到近20年前，自然地，PDF报告的格式并不一致。
- en: NOTE  Thanks to the BFI RSU and specifically John Sandow, senior research and
    data analyst, for permission to use the PDF reports.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：感谢BFI RSU以及具体的高级研究与分析员John Sandow允许使用PDF报告。
- en: To complete this project, you will need to
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成这个项目，您需要
- en: Identify the dimensions along which the film industry is analyzed in the Yearbooks
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定在年鉴中分析电影行业的维度
- en: Decide how far back to extract data, as well as what constitutes pre-COVID and
    post-lockdown periods
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定提取数据的范围，以及构成COVID-19前和封锁后时期的内容
- en: Extract the necessary underlying data
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取必要的底层数据
- en: Analyze the film statistics to arrive at a narrative that could be useful to
    your stakeholders in preparing their white paper
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析电影统计数据，得出一个对您的利益相关者准备白皮书有用的叙事
- en: Your stakeholders’ priority is that the findings are interesting and unexpected.
    They already assume cinema admissions dropped during the pandemic period and went
    down to zero during lockdowns, and they do not want to publish a white paper with
    such obvious statistics. They would prefer you explore things such as
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您的利益相关者的优先事项是研究结果既有趣又出乎意料。他们已经假设在疫情期间电影院入场人数下降，在封锁期间降至零，他们不希望发布一份包含如此明显统计数据的白皮书。他们更希望您探索以下内容：
- en: Have admissions recovered post-lockdown differently in different countries?
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的国家在封锁后恢复情况是否不同？
- en: What genres of films were popular before and after the pandemic period? Has
    this changed since lockdown restrictions were lifted?
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大流行前后，哪些电影类型流行？自封锁限制解除以来，这种变化了吗？
- en: Which distributors have experienced the biggest change post-pandemic?
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些发行商在大流行后经历了最大的变化？
- en: Has there been a change in people’s attitudes toward independent films?
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人们对待独立电影的态度是否有所改变？
- en: You will spend most of the time in the analysis portion of this project exploring
    trends pre- and post-lockdowns and comparing them to identify the most marked
    changes, which are the ones most likely to be interesting to your stakeholders.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在分析部分的大部分时间探索封锁前后的趋势，并将它们进行比较，以识别最显著的变化，这些变化最有可能引起你的利益相关者的兴趣。
- en: 5.2.2 Data dictionary
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 数据字典
- en: This project does not have an explicit data dictionary, which is a common problem
    in the real world. Even if you do not create a data dictionary, you will need
    to note down the types of data present in each Yearbook before deciding on what
    data to focus on. Some aspects of the data may only be present in older or newer
    Yearbooks, but you will need your data to be consistently available in all the
    documents you end up using.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目没有明确的数据字典，这在现实世界中是一个常见问题。即使你没有创建数据字典，你也需要在决定关注哪些数据之前，记下每本年鉴中存在的数据类型。数据的一些方面可能只存在于较老或较新的年鉴中，但你需要确保你的数据在所有你最终使用的文档中都能一致地可用。
- en: One aspect of the documents that will make your work a bit easier is that the
    data is in tables that can be extracted with the right tools. An example of such
    a table is shown in figure 5.1.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 文档的一个方面将使你的工作变得容易一些，那就是数据在表格中，可以使用适当的工具提取。图 5.1 展示了这样一个表格的例子。
- en: '![figure](../Images/5-1.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-1.png)'
- en: Figure 5.1 An example data table from a Statistical Yearbook PDF file
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.1 来自统计年鉴 PDF 文件的一个示例数据表
- en: 'Activity: Creating a data dictionary'
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 活动：创建数据字典
- en: Try writing a data dictionary for the data you end up using. Often, analysts
    write dictionaries for data they end up using because they’re the first to use
    it for analysis. It’s good practice to create this document for future users of
    the data, which includes a future version of you!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试为最终使用的数据编写数据字典。通常，分析师为最终用于分析的数据编写字典，因为他们是第一个使用它的人。为未来的数据使用者创建此文档是一个好习惯，包括未来的你！
- en: 5.2.3 Desired outcomes
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 预期成果
- en: The output of your analysis should be recommendations about potential topics
    for the white paper. The recommendations should be specific, so if you think there
    is a story about how people prefer different film genres since lockdown restrictions
    were lifted, your analysis should contain specific conclusions about which genres
    were popular before and after. Your recommendations should also be supported by
    visualizations, which may be included in the final white paper. As an additional
    consideration, you could also think about how your data extraction method, whether
    that is code or a specific tool, could be reused for future versions of this project.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你的分析输出应该是关于白皮书潜在主题的建议。建议应该是具体的，所以如果你认为自封锁限制解除以来，人们更喜欢不同电影类型的故事，你的分析应该包含关于哪些类型在大流行前后流行的具体结论。你的建议还应得到可视化支持，这些可视化可能包含在最终的白皮书中。作为一个额外的考虑，你也可以考虑你的数据提取方法，无论是代码还是特定的工具，是否可以用于该项目的未来版本。
- en: 5.2.4 Required tools
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.4 必需的工具
- en: For the example solution in this chapter, I used the Python libraries `pandas`
    and `matplotlib` to explore and visualize the data. To extract the data from the
    PDFs in the first place, I ended up using the Python library `pdfplumber`, but
    I will discuss other options. Your chosen tools may be different, and as with
    every project, the tool is less important than the process, but the tool you select
    must be able to
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章的示例解决方案，我使用了 Python 库 `pandas` 和 `matplotlib` 来探索和可视化数据。最初从 PDF 文件中提取数据时，我最终使用了
    Python 库 `pdfplumber`，但我将讨论其他选项。你选择的工具可能不同，并且与每个项目一样，工具的重要性不如过程，但你选择的工具必须能够
- en: Read a PDF file and extract tabular data from it into a more typical format,
    such as a CSV file
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取 PDF 文件并从中提取表格数据到更典型的格式，例如 CSV 文件
- en: Load multiple datasets from CSV or Excel files
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 CSV 或 Excel 文件中加载多个数据集
- en: Combine two or more datasets
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合并两个或多个数据集
- en: Perform basic data manipulation tasks, such as sorting, grouping, and reshaping
    data
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行基本的数据操作任务，如排序、分组和重塑数据
- en: Create data visualizations
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建数据可视化
- en: I have opted to stay within my Python toolkit for this chapter as well, but
    I will discuss some other options at your disposal. You may choose to extract
    the data from the PDFs with a tool outside of your regular toolkit, in which case
    your usual tools only need to satisfy the latter bullet points and not necessarily
    the first one.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择在这个章节中也保持在我的Python工具包内，但我将讨论一些你可供选择的其它选项。你可能会选择使用常规工具包之外的工具从PDF中提取数据，在这种情况下，你的常规工具只需要满足后面的要点，而不一定是第一个要点。
- en: 5.3 Applying the results-driven method to extracting data from PDFs
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 将结果驱动方法应用于从PDF中提取数据
- en: There is a lot of uncertainty in this project, partly due to the unknown and
    inconsistent structure of the PDF files and partly due to the vagueness of our
    stakeholders’ requests. Using the results-driven approach, we can formulate an
    action plan.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目有很多不确定性，部分原因是PDF文件的结构未知且不一致，部分原因是利益相关者请求的模糊性。使用结果驱动方法，我们可以制定一个行动计划。
- en: '![figure](../Images/5-unnumb-1.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-unnumb-1.png)'
- en: Our stakeholders haven’t given us much direction, so our understanding of the
    problem is incomplete at this stage. Our first iteration needs to focus on identifying
    common data tables across multiple years of the Yearbooks and analyzing what we
    have at our disposal. Once we start looking at pre-COVID and post-lockdown trends,
    we will have more information about what the main topic of our analysis will be.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的利益相关者并没有给我们太多指导，因此在这个阶段我们对问题的理解还不完整。我们的第一次迭代需要专注于识别年鉴中多年间的共同数据表，并分析我们手头上的资源。一旦我们开始观察疫情前和封锁后的趋势，我们将对分析的主要主题有更多了解。
- en: '![figure](../Images/5-unnumb-2.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-unnumb-2.png)'
- en: Even though we don’t know precisely what the white paper topic will be, we do
    know that we need to focus on comparing the same data in different time periods.
    Our minimum viable answer will focus on this comparison. Even this information
    gives us an idea of the final output of our work, which we can work toward.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们不知道白皮书的具体主题是什么，但我们知道我们需要专注于比较不同时间段的相同数据。我们的最小可行答案将专注于这一比较。即使这些信息也让我们对我们的工作最终输出有了概念，我们可以朝着这个方向努力。
- en: '![figure](../Images/5-unnumb-3.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-unnumb-3.png)'
- en: In this project, the identification stage will be crucial. This is where we
    explore the PDFs and note down common data themes we could explore. Once we have
    done that, we can move on to extracting only the specific data we need. This will
    save us time in the long run because extracting all the data tables and only then
    exploring them would take longer.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，识别阶段将是关键。这是我们在探索PDF并记录下我们可以探索的共同数据主题的地方。一旦我们完成了这些，我们就可以继续提取我们需要的特定数据。这将从长远来看节省我们的时间，因为提取所有数据表然后再探索它们会花费更长的时间。
- en: '![figure](../Images/5-unnumb-4.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-unnumb-4.png)'
- en: You could argue the data was obtained when our stakeholder provided the PDF
    files, but as we have seen, there is plenty of work to do before we have a structured
    dataset to explore. Not all projects following the results-driven approach will
    result in the same time spent on each section. In this project, I envisage this
    step taking up a large portion of our time.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为数据是在我们的利益相关者提供PDF文件时获得的，但正如我们所看到的，在我们拥有一个结构化的数据集来探索之前，还有很多工作要做。并非所有遵循结果驱动方法的项目都会在每个部分花费相同的时间。在这个项目中，我预计这一步骤将占据我们大部分的时间。
- en: '*![figure](../Images/5-unnumb-5.png)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*![figure](../Images/5-unnumb-5.png)'
- en: 'Let’s sketch out the steps we will take, building on the steps discussed in
    section 5.2.1:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们勾勒出我们将采取的步骤，基于第5.2.1节中讨论的步骤：
- en: First, we will open the PDF Yearbooks in descending year order and note the
    data tables available to us. There is no substitute for actually looking at our
    data before opening our analysis tools to get a sense of what we’re working with.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们将按年份降序打开PDF年鉴，并记录我们可用的数据表。在打开分析工具之前，实际查看我们的数据是必不可少的，这样我们才能对正在处理的内容有一个大致的了解。
- en: Next, we will decide how far back we are aiming to go in time. We do not have
    a lot of data to establish post-lockdown trends, and we don’t want to spend too
    long looking at data that’s too far in the past.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们将决定我们要追溯到多远的时间。我们没有很多数据来建立封锁后的趋势，我们也不想花太多时间查看太远过去的数据。
- en: We can then decide on which aspects of the data we will be able to extract for
    analysis. This will depend on what is available consistently over the period we’ve
    settled on.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们可以决定我们将能够从数据中提取哪些方面进行分析。这将取决于我们在确定的时间段内可用的内容。
- en: The next step will be to find and extract the specific data tables we need and
    save them in a structured format, such as CSVs.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下一步将是找到并提取我们需要的特定数据表，并将它们保存为结构化格式，例如CSV文件。
- en: 'Activity: Reusable methods'
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 活动：可重复使用的方法
- en: When you get to this point, think about how reusable your chosen extraction
    method is. Whether you manually extract the data or write a script to do it, it
    is possible that you will need to do it again in a future iteration. Thinking
    about reusability up front is a good practice to save yourself time in the long
    run.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当你到达这个阶段时，考虑一下你选择的提取方法的可重复使用性。无论你是手动提取数据还是编写脚本来做这件事，都有可能在未来的迭代中再次需要这样做。提前考虑可重复使用性是一个好的做法，可以节省你长远的时间。
- en: At this point, we can analyze the data by examining pre- and post-lockdown trends
    along the dimensions we have identified, whether that is changes in genre, admissions
    for independent films, or something else.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以通过检查我们已确定的维度上的疫情前和疫情后的趋势来分析数据，无论是类型的变化、独立电影的招生情况，还是其他方面。
- en: Finally, we will settle on a story to present to our stakeholders for inclusion
    in the white paper.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们将确定一个故事，向我们的利益相关者展示，并将其包含在白皮书中。
- en: '*![figure](../Images/5-unnumb-6.png)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*![figure](../Images/5-unnumb-6.png)'
- en: We cannot simulate the actual interaction you would have with a stakeholder
    upon presenting your findings. We can, however, practice preparing for such an
    interaction by considering the follow-up questions you might hear, given the work
    you present, and prepare your answers to them. Being ready with suggestions for
    future iterations leads to more productive stakeholder conversations.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法模拟你展示研究结果时与利益相关者的实际互动。然而，我们可以通过考虑你可能会听到的后续问题来练习准备这样的互动，并准备你的答案。准备好对未来迭代提出建议，可以导致更有效的利益相关者对话。
- en: '![figure](../Images/5-unnumb-7.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-unnumb-7.png)'
- en: In this instance, we would want to present to our stakeholders as soon as we
    have solid evidence for one or more of our findings. What constitutes “solid”
    is not necessarily a question of statistical significance but more an intuition
    about what kind of story our stakeholders would be interested in hearing and publishing.
    This analysis, like others, is not a one-off piece of work you deliver; it is
    a conversation. The idea behind what to present is part of an analyst skill set
    that can only be developed by immersing yourself in real-world scenarios.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们希望在有一个或多个我们的发现的确凿证据后，尽快向我们的利益相关者展示。构成“确凿”的并不一定是统计意义的问题，而更多的是关于我们的利益相关者会对哪种故事感兴趣并愿意发布的直觉。这项分析，就像其他分析一样，不是你交付的一次性工作；它是一个对话。关于展示什么的想法是分析师技能集的一部分，只能通过沉浸在实际场景中才能发展。
- en: '5.4 An example solution: Effects of the COVID-19 lockdown periods on the film
    industry'
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 一个示例解决方案：COVID-19封锁期间对电影产业的影响
- en: Let’s tackle an example solution for this problem. Reading my solution is more
    valuable once you have attempted the project yourself. Remember, our solutions
    may differ. You may end up doing things in a different order as well.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来解决这个问题的示例解决方案。在你自己尝试过这个项目之后，阅读我的解决方案将更有价值。记住，我们的解决方案可能会有所不同。你可能会以不同的顺序完成事情。
- en: We will begin by inspecting our PDFs to see what kind of data is consistently
    available across multiple years. Once we have made a decision on which datasets
    to focus on, we will find a PDF extraction method and make sure it can reliably
    extract tables of data from our PDFs. In the second part, we will analyze our
    newly created structured data to answer some of our stakeholders’ questions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先检查我们的PDF文件，看看在多年的时间里哪种数据是一直可用的。一旦我们决定要关注哪些数据集，我们将找到一个PDF提取方法，并确保它可以从我们的PDF文件中可靠地提取数据表。在第二部分，我们将分析我们新创建的结构化数据，以回答我们利益相关者的一些问题。
- en: 5.4.1 Inspecting the available data
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.1 检查可用数据
- en: The very first step is to decide which years of data to look at. If we look
    at the available files, a snapshot of which is shown in figure 5.2, we notice
    that the Yearbook used to be a single file per year until 2018, after which the
    files are broken down by category. However, files from 2018 onward also seem to
    have a “master” document, for example, the one titled “2018—BFI Statistical Yearbook.”
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是决定要查看哪些年份的数据。如果我们查看可用的文件，如图5.2所示的一个快照，我们会注意到年鉴在2018年之前每年只有一个文件，之后文件按类别划分。然而，从2018年开始的文件似乎也有一个“主”文档，例如，标题为“2018—BFI统计年鉴”的那个。
- en: '![figure](../Images/5-2.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-2.png)'
- en: Figure 5.2 A snapshot of the available PDF files
  id: totrans-93
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.2 可用PDF文件的快照
- en: We also appear to be missing the file for 2015 entirely, which would contain
    data for 2014\. That’s a problem we need a solution for if we want to go back
    further in time.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们似乎还缺少2015年的文件，该文件将包含2014年的数据。这是一个我们需要解决的问题，如果我们想追溯到更早的时间。
- en: NOTE  The years indicated in the files are actually for the previous year, meaning
    the file called “2018 Statistical Yearbook” contains data for 2017.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：文件中指出的年份实际上是前一年的，这意味着名为“2018统计年鉴”的文件包含2017年的数据。
- en: 'We can choose to extend our time period later, but for now, we will aim for
    the minimum amount of data that will get us pre- and post-lockdown trends. The
    first COVID lockdowns were in early 2020, so we definitely want 2019 at a minimum.
    Since we’re interested in patterns, more data would be better, so we’ll include
    two years pre-COVID: 2018 and 2019\. This also means we only include years where
    the format of the documents is consistent.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择稍后扩展我们的时间范围，但就目前而言，我们将目标设定为获取我们所需的最小数据量，以了解封锁前后的趋势。第一次COVID封锁是在2020年初，所以我们至少需要2019年的数据。由于我们感兴趣的是模式，更多的数据会更好，所以我们将包括COVID之前的两年：2018年和2019年。这也意味着我们只包括文档格式一致的年份。
- en: A longer-term review would give us more information, but we want to balance
    time and complexity, so two years will suffice for our first iteration. If we
    were to go further back in time, which would be pre-2017, we would want to make
    sure that the categories in the single documents match those that are broken out
    into separate files from 2018 onward. That is, is there data for audiences, distribution,
    public investment, and so forth available?
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 长期回顾会给我们更多信息，但我们想平衡时间和复杂性，所以两年将足够我们第一次迭代。如果我们追溯到2017年之前，我们想要确保单个文档中的类别与从2018年开始分开的文件中的类别相匹配。也就是说，是否有关于观众、发行、公共投资等方面的数据？
- en: Most of the lockdown restrictions were eased in 2021, so everything beyond that
    will be the “post-lockdowns” period, and we will need to decide how to categorize
    data in 2021.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 2021年大多数封锁限制都放宽了，所以那之后的 everything 都将是“后封锁”时期，我们需要决定如何对2021年的数据进行分类。
- en: Since we want our data to start in 2018, we will start with the 2019 Yearbook.
    Let’s see what tables of data are available. Looking at the table of contents,
    partially shown in figure 5.3, we see that the subheadings match the individual
    files for 2019, which suggests all the necessary data might be contained in this
    single file.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们希望我们的数据从2018年开始，我们将从2019年年鉴开始。让我们看看有哪些数据表可用。查看目录，部分内容如图5.3所示，我们看到子标题与2019年的单个文件相匹配，这表明所有必要的数据可能都包含在这个单一文件中。
- en: '![figure](../Images/5-3.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-3.png)'
- en: Figure 5.3 A partial view of the table of contents from the 2019 Yearbook
  id: totrans-101
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.3 2019年鉴目录的部分视图
- en: The file contains a mixture of text, charts, infographics, and data tables.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件包含文本、图表、信息图表和数据表的混合。
- en: Identifying what data to extract
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 确定要提取的数据
- en: 'Looking at the data tables, just for admissions alone, we have statistics for
    the following:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 查看数据表，仅就入场人数而言，我们有以下统计数据：
- en: Total admissions by country
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按国家划分的总入场人数
- en: Monthly admissions in the United Kingdom
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英国每月入场人数
- en: Admissions by UK region
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英国地区入场人数
- en: Annual admission figures all the way back to 1935
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回到1935年的年度入学人数
- en: Beyond this, we also have data for broad categories such as
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还有关于以下广泛类别的数据
- en: Gross box office revenue
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总票房收入
- en: Top films of the year
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年度热门电影
- en: Countries of origin
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原产国
- en: Genre
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类型
- en: Directors
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导演
- en: Independent films
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立电影
- en: Distributors
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发行商
- en: Even just looking at these data tables inspires many directions for our analysis.
    Since the data is for a white paper, we should choose categories that are likely
    to contain interesting stories. Of course, we don’t know up front, but intuition
    and domain expertise can help us choose a path that is more likely to yield results.
    Intuition like that is built only with lots of practice. We will focus on
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 即使只是查看这些数据表也激发了许多分析方向。由于这些数据是为白皮书准备的，我们应该选择可能包含有趣故事的类别。当然，我们事先不知道，但直觉和领域专业知识可以帮助我们选择更有可能产生结果的路径。这种直觉只有通过大量的实践才能建立。我们将关注
- en: Admission patterns
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 招生模式
- en: Distribution of genres
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类型分布
- en: Market share across distributors
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发行商之间的市场份额
- en: Choosing these categories means we can ask whether seasonal patterns have changed
    over time, whether people now prefer different genres, and which if any, distributor
    has come out of the pandemic as the winner in terms of market share.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 选择这些类别意味着我们可以询问季节性模式是否随时间而改变，现在人们是否更喜欢不同的类型，以及是否有任何发行商在市场份额方面成为疫情后的赢家。
- en: Let’s summarize our work so far since we have just reached the first key decision
    point. Figure 5.4 shows the current step and the alternative options.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下到目前为止我们所做的工作，因为我们刚刚达到了第一个关键决策点。图5.4显示了当前步骤和替代选项。
- en: '![figure](../Images/5-4.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-4.png)'
- en: Figure 5.4 The first step and decision point in the analysis
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.4 分析的第一步和决策点
- en: Now, we can identify exactly which tables to look for in all our files to make
    sure we have the right data each year. For simplicity, let’s limit ourselves to
    one data table per category. Figures 5.5–5.7 show the data tables in the 2019
    document that we will search for in post-2019 files.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以准确地识别出在所有文件中应该查找哪些表格，以确保我们每年都有正确的数据。为了简单起见，让我们限制每个类别只有一个数据表。图5.5–5.7显示了2019年文档中我们将要搜索的2019年之后的文件中的数据表。
- en: Based on our decision to focus on admissions, genres, and distributors, we can
    see the necessary data exists in just three tables. We can verify that these data
    tables exist for years beyond 2018 in their respective Yearbooks. If we had encountered
    a difference in structure, we would have had to investigate whether the same information
    was present in each table and ensure their structures matched so that we could
    combine them across multiple years into single files.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们决定专注于招生、类型和发行商的决定，我们可以看到必要的数据仅存在于三个表中。我们可以验证这些数据表在2018年之后的年份在其各自的年鉴中存在。如果我们遇到了结构上的差异，我们就必须调查相同的信息是否在每个表中都存在，并确保它们的结构匹配，以便我们可以将它们跨多年合并成单个文件。
- en: '![figure](../Images/5-5.png)![figure](../Images/5-5.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-5.png)![figure](../Images/5-5.png)'
- en: Figure 5.5 Monthly UK admissions from the 2019 Yearbook
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.5 2019年鉴的月度英国招生情况
- en: '![figure](../Images/5-6.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-6.png)'
- en: Figure 5.6 Releases and revenue by genre from the 2019 Yearbook
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.6 2019年鉴按类型划分的发行和收入
- en: '![figure](../Images/5-7.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-7.png)'
- en: Figure 5.7 Market share by distributor from the 2019 Yearbook
  id: totrans-132
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.7 2019年鉴按发行商的市场份额
- en: 5.4.2 Extracting data from PDFs
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.2 从PDF中提取数据
- en: Now that we know what data tables we need, we have multiple options to extract
    them. We could
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了我们需要哪些数据表，我们有多种方法来提取它们。我们可以
- en: Manually copy a limited amount of our data from the PDFs
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动从PDF中复制有限的数据
- en: Use a dedicated PDF extraction tool
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用专门的PDF提取工具
- en: Find PDF extraction capabilities for our preferred tool (e.g., Python)
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为我们首选的工具（例如，Python）查找PDF提取功能
- en: Table 5.1 shows the tradeoffs of these different approaches.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1显示了这些不同方法之间的权衡。
- en: Table 5.1 Comparing PDF extraction techniques
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.1 比较PDF提取技术
- en: '| Option | Pros | Cons |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 选项 | 优点 | 缺点 |'
- en: '| --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Manually copying data from PDFs into Excel  | • Quick for a small amount
    of data  | • Cannot be automated • Does not scale to more data'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '| 将数据从PDF手动复制到Excel | • 对于少量数据来说很快  | • 无法自动化 • 无法扩展到更多数据 |'
- en: '|'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Dedicated PDF extraction tool, either web or desktop based  | • Likely to
    be accurate • Web-based tool requires no installation'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '| 专用PDF提取工具，无论是基于Web还是桌面 | • 很可能准确 • 基于Web的工具无需安装 |'
- en: '| • May not be free • Privacy concerns if uploading files to the web'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '| • 可能不是免费的 • 上传文件到网络时的隐私问题 |'
- en: • Hard to automate
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: • 难以自动化
- en: • May not scale to multiple files
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: • 可能无法扩展到多个文件
- en: '|'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Finding PDF capabilities in our current tool  | • Allows automation and scales
    to many files • No need to leave/change our preferred tools'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '| 在我们当前的工具中查找PDF功能 | • 允许自动化并扩展到多个文件 • 无需离开/更改我们首选的工具 |'
- en: '| • Current toolkit may not have such capabilities • If there are few files
    and a one-off task, it might be quicker to extract data manually.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '| • 当前工具包可能没有这样的功能 • 如果文件很少且是一次性任务，手动提取数据可能更快。'
- en: '|'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Whatever option we settle on, we still need to go through the process of choosing
    a tool, implementing it/setting it up, and using it to extract the data from the
    PDFs. Let’s look at each step in detail, starting with choosing the right tool
    with the help of AI.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们决定哪种选项，我们仍然需要经历选择工具、实施/设置它以及使用它从PDF中提取数据的过程。让我们详细看看每个步骤，从在AI的帮助下选择正确的工具开始。
- en: Choosing a PDF extraction method
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 选择PDF提取方法
- en: 'There is a lot of uncertainty in these options. Working with a specific task
    that we only have to perform rarely is a perfect use case for AI tools. Figure
    5.8 shows the OpenAI GPT-3.5 model’s partial answer to the following prompt:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些选项中存在很多不确定性。处理我们只需要偶尔执行的具体任务是AI工具的完美用例。图5.8显示了OpenAI GPT-3.5模型对以下提示的部分回答：
- en: '*What are my options for easily extracting data tables from PDFs into a machine-readable
    format? The suggested options must be free, open source, and can include Python
    libraries.*'
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*从PDF中轻松提取数据表到机器可读格式的选项有哪些？建议的选项必须是免费、开源的，并且可以包括Python库。*'
- en: '![figure](../Images/5-8.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-8.png)'
- en: Figure 5.8 A list of options for PDF data extraction suggested by ChatGPT
  id: totrans-157
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.8 ChatGPT建议的PDF数据提取选项列表
- en: First, it is important to remember that because these tools are evolving rapidly,
    the same prompt will give us different results depending on which AI tool we use
    and when we use it. We can see that ChatGPT recommends a mix of Python libraries
    and non-Python options as requested, which gives us plenty to explore. However,
    when investigating one of the non-Python options, it turns out the GitHub link
    for TabbyPDF is incorrect. In this case, we can find it ourselves, but it is a
    reminder that AI tools sometimes hallucinate in their suggestions, and they could
    even recommend tools that don’t exist.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，重要的是要记住，由于这些工具正在快速发展，相同的提示将根据我们使用哪个AI工具以及何时使用它而给出不同的结果。我们可以看到，ChatGPT根据要求推荐了Python库和非Python选项的混合，这为我们提供了大量的探索空间。然而，在调查其中一个非Python选项时，我们发现TabbyPDF的GitHub链接是错误的。在这种情况下，我们可以自己找到它，但这提醒我们AI工具有时会在建议中产生幻觉，甚至可能推荐不存在的工具。
- en: Let’s also use the AI tool to help us to start with one of the libraries. When
    asked, “Of the Python options, which one is the easiest to set up with the fewest
    dependencies?” its suggestion is to start with `tabula-py`, as it has the fewest
    dependencies. However, its dependency is to install a Java Runtime Environment,
    which is something we may prefer not to do. Its next suggestion, the `pdfplumber`
    library, has no such external dependencies, but its documentation suggests that
    table extraction features are a “plus.” Another suggestion, `camelot`, specializes
    in data table extraction, but according to ChatGPT, it is harder to set up due
    to its own external dependencies. So, we shouldn’t take the AI’s answer as perfect;
    it should be the start and not the end of the process.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也使用AI工具帮助我们开始使用其中一个库。当被问及“在Python选项中，哪一个最容易设置且依赖项最少？”时，它的建议是从`tabula-py`开始，因为它有最少的依赖项。然而，它的依赖项是安装Java运行时环境，这是我们可能不愿意做的事情。它的下一个建议，`pdfplumber`库，没有这样的外部依赖项，但它的文档表明表格提取功能是一个“加分项”。另一个建议，`camelot`，专注于数据表提取，但根据ChatGPT的说法，由于它自己的外部依赖项，设置起来可能更困难。因此，我们不应将AI的回答视为完美；它应该是过程的开始，而不是结束。
- en: Weighing up our options, let’s settle on trying `pdfplumber` first because other
    Python libraries that are easier to install are its only dependencies. If its
    table-reading capabilities do not give us the results we require, we can always
    try another library, but we will favor simplicity in our first attempt.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在权衡我们的选择后，让我们先尝试使用`pdfplumber`，因为其他易于安装的Python库只是它的依赖项。如果它的表格读取功能不能给我们所需的结果，我们总是可以尝试另一个库，但我们将首先尝试保持简单。
- en: Installing `pdfplumber` can be done using any package manager you use, whether
    that is `pip`, `conda`, or `poetry`. As these tools install dependent libraries
    automatically, there is little for us to do in this step. However, if you choose
    to use a different tool for PDF extraction, this step may be more involved.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pdfplumber`可以通过您使用的任何包管理器来完成，无论是`pip`、`conda`还是`poetry`。由于这些工具会自动安装依赖库，在这个步骤中我们几乎不需要做什么。然而，如果您选择使用不同的工具进行PDF提取，这个步骤可能更加复杂。
- en: Now that we’ve decided on a method, let’s summarize our process until this point
    before moving on to the actual extraction step. Figure 5.9 shows the process so
    far.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经决定了一个方法，让我们在继续到实际提取步骤之前，总结一下到目前为止的过程。图5.9显示了到目前为止的过程。
- en: '![figure](../Images/5-9.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-9.png)'
- en: Figure 5.9 Steps up until settling on a PDF extraction method
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.9 选择PDF提取方法的步骤
- en: Let’s now use our chosen tool to extract the structured data from our PDFs.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用我们选择的工具从我们的PDF中提取结构化数据。
- en: Using our chosen tool to extract data from PDFs
  id: totrans-166
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用我们选择的工具从PDF中提取数据
- en: 'After installing `pdfplumber`, let’s start by importing our libraries:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装了 `pdfplumber` 之后，我们首先导入我们的库：
- en: '[PRE0]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This might be the first time we use the `pdfplumber` library, so to get started,
    we would read its documentation to understand how to open a PDF and extract tables
    from it. Because we will extract multiple tables from multiple pages across multiple
    documents, we should write a reusable function that performs the extraction of
    one or more tables from one or more pages of a single PDF. This function needs
    to open a PDF file, extract all the tables in the pages we specify, and return
    them as `pandas` DataFrames ready for analysis.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是我们第一次使用 `pdfplumber` 库，因此为了开始，我们会阅读其文档以了解如何打开PDF并从中提取表格。由于我们将从多个文档的多个页面中提取多个表格，我们应该编写一个可重用的函数，该函数可以从单个PDF的多个页面中提取一个或多个表格。这个函数需要打开一个PDF文件，提取我们指定的页面中的所有表格，并将它们作为
    `pandas` DataFrame返回，以便进行分析。
- en: 'Let’s start with the extraction code. Given a specified path and a page number,
    the following code will open the PDF, enumerate through the pages, and extract
    all the tables it identifies:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从提取代码开始。给定一个指定的路径和页码，以下代码将打开PDF，遍历页面，并提取它所识别的所有表格：
- en: '[PRE1]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#1 page_tables is a list of lists of lists(!) extracted from special Table
    objects.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 `page_tables` 是从特殊的表格对象中提取出来的列表的列表（列表的列表！）。'
- en: At this point, the `page_tables` variable is a list that contains lists of lists.
    The output is shown in figure 5.10.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，`page_tables` 变量是一个包含列表的列表的列表。输出如图5.10所示。
- en: '![figure](../Images/5-10.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-10.png)'
- en: Figure 5.10 A table extracted by `pdfplumber` from a single PDF page
  id: totrans-175
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.10 `pdfplumber` 从单个PDF页面提取的表格
- en: 'Each row of the table is a list of strings, starting with the column headers.
    These rows are themselves in a list, representing a single table. Using the `page.find_tables()`
    function means we end up with a list of these tables. Hence, our data structure
    is a list of lists of lists. Luckily, `pandas` makes it easy for us to convert
    this to a list of DataFrames, as shown in the following code snippet:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 表格的每一行都是一个字符串列表，以列标题开头。这些行本身也是一个列表，代表一个单独的表格。使用 `page.find_tables()` 函数意味着我们最终得到一个这些表格的列表。因此，我们的数据结构是一个列表的列表的列表。幸运的是，`pandas`
    让我们很容易将其转换为DataFrame的列表，如下面的代码片段所示：
- en: '[PRE2]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'These code snippets can then be extended to work across multiple pages, and
    with a few additional print statements and logical checks, the entire function
    is shown in the following code snippet, a portion of the output of which is shown
    in figure 5.11:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这些代码片段可以扩展到跨多页工作，并且通过一些额外的打印语句和逻辑检查，整个函数在下面的代码片段中展示，其中一部分输出如图5.11所示：
- en: '[PRE3]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#1 In each case, the variable table is now a list of lists and the first list
    contains the column headers.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 在每种情况下，变量 `table` 现在是一个列表的列表，第一个列表包含列标题。'
- en: '![figure](../Images/5-11.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-11.png)'
- en: Figure 5.11 A part of the output of our `extract_tables` function
  id: totrans-182
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.11 我们 `extract_tables` 函数的部分输出
- en: The variable `tables` that stores the output of our function is now a list of
    DataFrames, each representing one table extracted from a PDF. It’s time to apply
    this function to our PDFs and extract the data we need. We will walk through this
    for 2018 data, but for completeness, all the data extraction code is included
    in the supplementary code listings.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 存储我们函数输出的变量 `tables` 现在是一个DataFrame的列表，每个DataFrame代表从PDF中提取的一个表格。现在是时候将这个函数应用到我们的PDF上，提取我们需要的数据了。我们将通过2018年的数据来演示这个过程，但为了完整性，所有数据提取的代码都包含在补充代码列表中。
- en: 'First, we identify the page numbers of interest and use our function to extract
    the admissions, genre, and distributor data:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们确定感兴趣的页码，并使用我们的函数提取招生、类型和发行商数据：
- en: '[PRE4]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The full admissions data is shown in figure 5.12.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的招生数据如图5.12所示。
- en: '![figure](../Images/5-12.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-12.png)'
- en: Figure 5.12 2018 admissions data as extracted from our PDF
  id: totrans-188
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.12 从我们的PDF中提取的2018年招生数据
- en: 'One important aspect of this data that we notice is that the columns themselves
    do not tell us the year this data belongs to. This will be important when we combine
    admissions data over multiple years, so we will add a Year column. We also do
    not need 2017 data or the percentage change, so we can drop those columns. A sample
    of the modified admissions data is shown in figure 5.13:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到这个数据的一个重要方面是，列本身并没有告诉我们这些数据属于哪一年。当我们需要将多年的招生数据合并时，这一点将非常重要，因此我们将添加一个年份列。我们也不需要
    2017 年的数据或百分比变化，因此我们可以删除这些列。修改后的招生数据样本如图 5.13 所示：
- en: '[PRE5]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![figure](../Images/5-13.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-13.png)'
- en: Figure 5.13 A snapshot of the modified admissions data
  id: totrans-192
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.13 修改后的招生数据快照
- en: Moving onto genres, the second table in our extracted list of DataFrames contains
    the data we need, as shown in figure 5.14.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是类型，我们提取的 DataFrame 列表中的第二个表格包含我们需要的数据，如图 5.14 所示。
- en: '![figure](../Images/5-14.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-14.png)'
- en: Figure 5.14 Genre breakdown for 2018 as extracted from the PDF
  id: totrans-195
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.14 从 PDF 中提取的 2018 年类型分解
- en: 'As opposed to the admissions data, this breakdown is by genre and relates to
    the entire year of 2018\. We still need to add a Year column to differentiate
    genres across years, but we need to remember that this dataset has a different
    level of granularity. Again, we do not need all the columns, and we will need
    to clean up the column names to remove the `\n` newline characters. The following
    code snippet produces the modified genre data, a snapshot of which is shown in
    figure 5.15:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 与招生数据不同，这种分解是按类型进行的，并涉及 2018 年整年的数据。我们仍然需要添加一个年份列来区分不同年份的类型，但我们需要记住这个数据集具有不同的粒度级别。同样，我们不需要所有列，并且我们需要清理列名以删除
    `\n` 换行符。以下代码片段生成了修改后的类型数据，其快照如图 5.15 所示：
- en: '[PRE6]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![figure](../Images/5-15.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-15.png)'
- en: Figure 5.15 The modified genre data from 2018
  id: totrans-199
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.15 2018 年修改后的类型数据
- en: Finally, moving on to distributors, the data directly extracted from the PDF
    is shown in figure 5.16.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，转向发行商，从 PDF 中直接提取的数据如图 5.16 所示。
- en: '![figure](../Images/5-16.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-16.png)'
- en: Figure 5.16 The raw distributors data, as extracted from the PDF
  id: totrans-202
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.16 从 PDF 中提取的原始发行商数据
- en: 'In this case, all our columns will be useful, and we need to add the Year column
    again. We should also remove row 10, as it is a total of the rows above it, which
    would skew our calculations if we left it in. The following code modifies the
    data to suit our needs, and a snapshot of the modified data is shown in figure
    5.17:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们所有的列都将是有用的，我们需要再次添加年份列。我们还应该删除第 10 行，因为它上面所有行的总和，如果我们保留它，将会歪曲我们的计算。以下代码修改了数据以适应我们的需求，修改后的数据快照如图
    5.17 所示：
- en: '[PRE7]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Drops the “top 10 total” row'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 删除“前 10 名总计”行'
- en: '![figure](../Images/5-17.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-17.png)'
- en: Figure 5.17 The modified distributor data for 2018
  id: totrans-207
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.17 2018 年修改后的发行商数据
- en: Note  Repeating this process for subsequent years shows some differences. In
    2019, there are two admissions tables on the same page, so we need to explicitly
    choose the right one. Also, in the 2022 Yearbooks, the tables are spread across
    multiple PDFs. Extracting these tables is the same process for all the years,
    but these minor differences are what make PDF data extraction complicated.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：对后续年份重复此过程会显示一些差异。在 2019 年，同一页上有两个招生表格，因此我们需要明确选择正确的表格。此外，在 2022 年年鉴中，表格分布在多个
    PDF 中。所有年份的表格提取过程都是相同的，但这些细微差异使得 PDF 数据提取变得复杂。
- en: 'Every dataset of the same type across the years is structured identically,
    so we do not need to do any additional cleaning before being able to combine them.
    The following code shows how we combine the annual admissions datasets into a
    single one:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 多年间的同类型数据集结构相同，因此我们不需要在合并之前进行任何额外的清理。以下代码展示了如何将年度招生数据集合并成一个单一的数据集：
- en: '[PRE8]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To ensure we have the right amount of data, we perform a quick sanity check
    to see how many rows of monthly data we have per year. We are expecting exactly
    12 rows per year, which is verified in the output shown in figure 5.18:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们有正确数量的数据，我们进行快速合理性检查，查看每年每月数据的行数。我们预计每年正好有 12 行，如图 5.18 所示的输出中已验证：
- en: '[PRE9]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![figure](../Images/5-18.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-18.png)'
- en: Figure 5.18 Verifying that we have 12 rows of admissions data for each year
  id: totrans-214
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.18 验证我们每年都有 12 行招生数据
- en: 'Finally, we write the combined admissions data into its own file:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将合并后的招生数据写入其自己的文件：
- en: '[PRE10]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The process for combining and exporting genre and distributor data is identical,
    and we end up with three files that we are ready to analyze.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 组合和导出类型和发行商数据的流程是相同的，我们最终得到三个我们准备分析文件。
- en: 5.4.3 Analyzing the data extracted from PDFs
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.3 分析从 PDF 中提取的数据
- en: Now that we have our data extracted from our PDFs and combined, we can start
    exploring it to find stories to use in our white paper. We will take each dataset
    at a time, starting with admissions. We could continue the code, meaning we would
    already have our admissions data as a variable, but I have chosen to explicitly
    separate the extraction and analysis processes. In the accompanying resources,
    you will find the process split into two Jupyter notebooks. For the analysis portion,
    we will start a new Jupyter notebook using the data created in the first one.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经从我们的 PDF 中提取并合并了数据，我们可以开始探索它，以找到可用于我们白皮书的故事。我们将一次处理一个数据集，从招生数据开始。我们可以继续编写代码，这意味着我们已经有招生数据作为变量，但我选择明确地分离提取和分析过程。在配套资源中，您将找到将过程分为两个
    Jupyter 笔记本。对于分析部分，我们将使用第一个笔记本中创建的数据启动一个新的 Jupyter 笔记本。
- en: 'There are multiple benefits to separating extraction from analysis:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 将提取与分析分离有多重好处：
- en: Extraction and analysis can be worked on separately as long as the extraction
    step produces the output the analysis step expects.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只要提取步骤产生分析步骤期望的输出，提取和分析就可以分别工作。
- en: You save time by not having to rerun the extraction steps every time the analysis
    changes.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过不必每次分析更改时重新运行提取步骤，您可以节省时间。
- en: Steps can be more easily maintained because they are logically decoupled from
    each other.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步骤可以更容易地维护，因为它们彼此之间逻辑上是解耦的。
- en: In general, when you see an opportunity to create a cleaner solution by separating
    logical steps from each other, you should take it. Anyone looking at your work
    in the future, including yourself, will be grateful for the extra effort you put
    in early on.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当您看到有机会通过将逻辑步骤彼此分离来创建更干净的解决方案时，您应该抓住这个机会。任何将来查看您的工作的人，包括您自己，都会为你在早期付出的额外努力感到感激。
- en: Enhancing extracted data with custom logic
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用自定义逻辑增强提取数据
- en: 'We start by reading in the admissions data and taking a look at it. The following
    code produces the output in figure 5.19:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先读取招生数据并查看它。以下代码生成图 5.19 中的输出：
- en: '[PRE11]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![figure](../Images/5-19.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-19.png)'
- en: Figure 5.19 A snapshot of the admissions data
  id: totrans-229
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.19 招生数据的快照
- en: 'The dataset is small because it is a single monthly value across only a few
    years. However, it is sufficient to divide into three periods: pre-COVID lockdowns,
    during COVID lockdowns, and post-COVID lockdowns. We do this by creating a date
    column with the right data type. The output of the following code is shown in
    figure 5.20:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它只是跨越几年的单一月度值，数据集很小。然而，它足以分为三个时期：COVID 前封锁期、COVID 封锁期和 COVID 解锁后。我们通过创建一个具有正确数据类型的日期列来实现这一点。以下代码的输出显示在图
    5.20 中：
- en: '[PRE12]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#1 We define variables to mark cutoff points for COVID periods.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 我们定义变量来标记 COVID 时期的截止点。'
- en: '#2 Our data has no days, so we arbitrarily set dates to the first of the month.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 我们的数据没有日期，所以我们随意将日期设置为每月的第一天。'
- en: '![figure](../Images/5-20.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-20.png)'
- en: Figure 5.20 Verifying that our newly added Date column is as expected
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.20 验证我们新添加的日期列是否符合预期
- en: 'Next, we define cutoff points for the three periods and apply them to the data.
    We also use the `Categorical` data type in `pandas` to ensure the correct order
    is observed when sorting; otherwise, these periods would be sorted alphabetically.
    Then, we verify that this new column is distributed as we’d expect and that we
    haven’t left any missing data. The output of the following code is shown in figure
    5.21:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义三个时期的截止点并将它们应用于数据。我们还使用 `pandas` 中的 `Categorical` 数据类型来确保在排序时观察到正确的顺序；否则，这些时期将按字母顺序排序。然后，我们验证这个新列的分布是否符合我们的预期，并且我们没有遗漏任何数据。以下代码的输出显示在图
    5.21 中：
- en: '[PRE13]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![figure](../Images/5-21.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-21.png)'
- en: Figure 5.21 Number of rows per different COVID period
  id: totrans-239
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.21 不同 COVID 时期的行数
- en: 'We can now plot monthly admissions and mark each COVID period with a different
    color and line style using the following code, which produces the plot in figure
    5.22:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用以下代码绘制月度招生数据，并用不同颜色和线条样式标记每个 COVID 时期，如图 5.22 所示：
- en: '[PRE14]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![figure](../Images/5-22.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-22.png)'
- en: Figure 5.22 Admissions across multiple COVID periods
  id: totrans-243
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.22 多个 COVID 时期的招生情况
- en: At first glance, there are missing months due to the lockdown periods, and after
    the last lockdown was lifted, it appears that admissions have started to return
    to pre-pandemic levels. If we had more post-lockdown data, we could also examine
    whether seasonal patterns are similar to what they were before the pandemic.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 初看之下，由于封锁期间缺失了几个月份，在最后一次封锁解除后，似乎入院人数已经开始恢复到疫情前的水平。如果我们有更多的后封锁数据，我们还可以检查季节性模式是否与疫情前相似。
- en: 'If we were to look at the average monthly admissions in the three periods,
    we could examine this further. The following code does this and produces the output
    shown in figure 5.23:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要查看三个时期的平均每月入院人数，我们可以进一步调查这一点。以下代码执行此操作，并产生图5.23所示的输出：
- en: '[PRE15]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#1 Different hatch patterns for different metrics'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 不同指标使用不同阴影模式'
- en: '#2 Different colors for different metrics'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 不同指标使用不同颜色'
- en: '![figure](../Images/5-23.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-23.png)'
- en: Figure 5.23 Average admissions by COVID period
  id: totrans-250
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.23 按COVID时期划分的平均入院人数
- en: 'The reason for looking at both the mean and the median is to investigate whether
    the data is skewed in either direction. That is, do pre-COVID or post-lockdown
    months tend to have outliers in either direction? Looking at histograms of monthly
    admissions by period investigates this further. The following code produces the
    histograms shown in figure 5.24:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 观察均值和中位数的原因是为了调查数据是否在任一方向上存在偏斜。也就是说，COVID前或后封锁的月份是否倾向于在任一方向上有异常值？通过查看按时期划分的每月入院人数的直方图可以进一步调查这一点。以下代码生成了图5.24所示的直方图：
- en: '[PRE16]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![figure](../Images/5-24.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-24.png)'
- en: Figure 5.24 Histograms of admissions pre-COVID and post-lockdowns
  id: totrans-254
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.24 COVID前和后封锁的入院人数直方图
- en: There is not a lot of post-lockdown data, but we can observe that there are
    more months with fewer admissions, which is what we’d expect given the slow recovery.
    Pre-COVID, we expected approximately 15–17 million admissions per month, with
    a few outliers in both positive and negative directions. As it stands, there is
    not much of a story to tell about post-lockdown admissions habits, except for
    noting that admissions look to be trending toward pre-COVID levels again by the
    end of 2021.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 后封锁的数据并不多，但我们可以观察到有更多月份的入院人数较少，这是根据缓慢的恢复所预期的。COVID前，我们预计每月大约有1500万至1700万的入院人数，正负方向上都有一些异常值。目前，关于后封锁的入院习惯没有太多可以讲述的故事，除了注意到到2021年底，入院人数似乎又开始趋向于COVID前的水平。
- en: Investigating changes in trends over time using data from multiple sources
  id: totrans-256
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用来自多个来源的数据研究趋势随时间的变化
- en: 'Now, let’s see what genres were popular on either side of the pandemic period.
    First, let’s read in and examine our data. Figure 5.25 shows a snapshot of rows
    produced by the following code:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看在疫情前后流行的品类。首先，让我们读取并检查我们的数据。图5.25显示了以下代码产生的行快照：
- en: '[PRE17]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![figure](../Images/5-25.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-25.png)'
- en: Figure 5.25 A snapshot of rows from the genre dataset
  id: totrans-260
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.25 品类数据集的行快照
- en: 'There are two things to note. First, this dataset is small since it is a handful
    of genres recorded over just a few years. Second, this dataset is at an annual
    level, not a monthly one, which changes our definitions of COVID periods. Specifically,
    we must accept that the first couple of months of 2020 data will be allocated
    as “during COVID” even though they occurred before the first lockdown, and we
    need to decide what to do with 2021 data. 2021 still had lockdowns, but the second
    half of the year is useful data about post-lockdown trends, which we wouldn’t
    want to throw away. We will err on the side of keeping 2021 as “post-lockdowns”
    and categorizing 2020 as the only “during COVID” year. The following code does
    this and produces the output in figure 5.26:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 有两点需要注意。首先，由于只是记录了几年内的少量品类，因此这个数据集很小。其次，这个数据集是按年度级别，而不是按月度级别，这改变了我们对COVID时期的定义。具体来说，我们必须接受2020年最初几个月的数据将被分配为“在COVID期间”，即使它们发生在第一次封锁之前，并且我们需要决定如何处理2021年的数据。2021年仍然有封锁，但下半年的数据是关于后封锁趋势的有用数据，我们不想将其丢弃。我们将倾向于将2021年视为“后封锁”，并将2020年视为唯一的“在COVID期间”的年份。以下代码执行此操作，并产生图5.26所示的输出：
- en: '[PRE18]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![figure](../Images/5-26.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-26.png)'
- en: Figure 5.26 Distribution of rows per COVID period in the genres dataset
  id: totrans-264
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.26 品类数据集中按COVID时期分布的行
- en: 'Glancing at the data, we might notice that the gross box office column has
    non-numeric values, namely <0.1, to indicate genres that totaled less than £100,000\.
    To calculate revenue by genre, for example, we need this column to be numeric.
    We could convert that value to zero, but that would be misleading, and it is not
    the same value as 0.1, which is a value also present in our data. To indicate
    low revenue, we can add a placeholder value of, say, 0.05:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 看数据时，我们可能会注意到票房总收入列有非数值值，即<0.1，表示总收入低于10万英镑的类型。例如，为了按类型计算收入，我们需要这一列是数值的。我们可以将这个值转换为零，但这将是误导性的，并且这个值与数据中存在的0.1不同。为了表示低收入，我们可以添加一个占位符值，比如0.05：
- en: '[PRE19]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![figure](../Images/5-27.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-27.png)'
- en: Figure 5.27 Total revenue by genre
  id: totrans-268
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.27按类型划分的总收入
- en: 'Now, we can look at total revenue by genre in our dataset. The output of the
    following code is shown in figure 5.27:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以查看数据集中按类型划分的总收入。以下代码的输出显示在图5.27中：
- en: '[PRE20]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'It seems that people like action and animation films the most. What we really
    want to see is this same distribution by year. We could also look at it by COVID
    period, but let’s look at the more granular picture. The following code achieves
    this and produces the output in figure 5.28:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来人们最喜欢动作和动画电影。我们真正想看到的是这种按年份相同的分布。我们也可以按COVID时期来看，但让我们先看看更细致的图景。以下代码实现了这一点，并在图5.28中产生了输出：
- en: '[PRE21]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![figure](../Images/5-28.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-28.png)'
- en: Figure 5.28 Breakdown of revenue by genre across multiple years
  id: totrans-274
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.28 多年按类型划分的收入分解
- en: 'That gives quite a clear picture. Action films are the most popular, regardless
    of year. Comedy films historically haven’t done as well pre-COVID, but there has
    been a rise in their popularity in 2021\. Here are some theories about this result:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了一个非常清晰的图景。动作电影无论在哪个年份都是最受欢迎的。喜剧电影在COVID之前的表现一直不太好，但在2021年其受欢迎程度有所上升。以下是关于这一结果的几种理论：
- en: Animated films take years of effort, and if animators weren’t working at any
    point during COVID, that would have delayed the release of animated films in 2021\.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动画电影需要多年的努力，如果动画师在COVID期间没有在任何时候工作，那么这就会推迟2021年动画电影的上映。
- en: Comparatively, comedies are probably cheaper to make, though that’s a question
    for the domain experts.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比之下，喜剧电影可能制作成本更低，但这是一个需要领域专家回答的问题。
- en: People possibly prefer light-hearted relief in post-lockdown times.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在解封后，人们可能更喜欢轻松愉快的慰藉。
- en: 'Let’s test that first assumption. If our theory holds, we should see fewer
    releases in the animation genre in 2021\. Figure 5.29 shows the output of this
    investigation:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先测试这个第一个假设。如果我们的理论成立，我们应该看到2021年动画类型的上映数量更少。图5.29显示了这项调查的输出：
- en: '[PRE22]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![figure](../Images/5-29.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-29.png)'
- en: Figure 5.29 Number of animation releases over time
  id: totrans-282
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.29随时间动画电影发布数量
- en: 'There were almost as many films released in the animation genre in 2021 as
    in 2019, so our theory doesn’t explain why the revenue of that genre dropped.
    Another interesting point from figure 5.28 is the popularity of war films in 2020:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 2021年上映的动画电影数量几乎与2019年一样多，因此我们的理论无法解释为什么该类型的收入下降了。从图5.28中还可以看到2020年战争电影的流行：
- en: '[PRE23]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Looking into it, we find that the top-performing title in this category was
    the film *1917*, which was released in January 2020\. Although the revenue from
    this film accounts for its high place in the rankings in 2020, it was released
    before the first lockdowns, so it doesn’t tell us anything beyond that the filmmakers
    were lucky to bring in the revenue before the lockdown happened. It certainly
    isn’t evidence that people liked films about war during the pandemic.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 深入研究后，我们发现这个类别中表现最好的电影是电影*1917*，该电影于2020年1月上映。尽管这部电影的收入使其在2020年的排名中占据高位，但它是在第一次封锁之前上映的，因此这并不能告诉我们任何关于人们在大流行期间喜欢战争电影的信息。这当然不能作为证据表明人们在大流行期间喜欢战争电影。
- en: In summary, it appears that although action films are by far the most popular
    genre, comedies experienced a growth in revenue post-lockdowns. This is certainly
    a finding worth bringing to a domain expert to find out more.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，尽管动作电影无疑是最受欢迎的类型，但喜剧电影在解封后收入有所增长。这无疑是一个值得将领域专家引入以了解更多信息的发现。
- en: Resolving different entity names across data sources
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 解决跨数据源的不同实体名称
- en: 'Our final question relates to distributors. Which companies came out of the
    lockdown period grossing the most revenue for their films? Let’s look at our available
    data in figure 5.30:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后一个问题与发行商有关。哪些公司在封锁期间为他们的电影赚取了最多的收入？让我们看看我们可用的数据在图5.30中：
- en: '[PRE24]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![figure](../Images/5-30.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-30.png)'
- en: Figure 5.30 A snapshot of the distributors dataset
  id: totrans-291
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.30 发行商数据集快照
- en: 'For each distributor, we have their revenue market share, number of films released,
    and total gross box office revenue per year. Let’s assign our COVID periods again.
    Figure 5.31 shows the number of rows of data we have per COVID period:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个发行商，我们都有他们的收入市场份额、每年发布的电影数量和总票房收入。让我们再次分配我们的COVID时期。图5.31显示了每个COVID时期的数据行数：
- en: '[PRE25]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![figure](../Images/5-31.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-31.png)'
- en: Figure 5.31 Number of rows per COVID period in the distributors data
  id: totrans-295
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.31 分销商数据中每个COVID时期的行数
- en: 'We should also verify that the market share column adds up to 100% each year.
    Figure 5.32 shows whether this is the case:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该验证市场份额列每年是否加起来是100%。图5.32显示了这是否是情况：
- en: '[PRE26]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![figure](../Images/5-32.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-32.png)'
- en: Figure 5.32 Total market share per year
  id: totrans-299
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.32 每年的总市场份额
- en: 'The Statistical Yearbooks explicitly mention rounding errors, which are probably
    responsible for the numbers in figure 5.32\. Let us now look at market share by
    distributor for each year of our data. The easiest way to do this with `pandas`
    is to create a pivot table where each column is a different distributor, and each
    row is a different year. This way, when we call the `plot` function, we see one
    line per distributor over time. Let’s see what this reshaping of our data does.
    The following code produces the pivot table shown in figure 5.33:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 统计年鉴明确提到了舍入误差，这可能是图5.32中数字的原因。现在让我们看看我们数据的每年按发行商的市场份额。使用`pandas`的最简单方法是为每个不同的发行商创建一个交叉表，其中每列代表一个不同的发行商，每行代表一个不同的年份。这样，当我们调用`plot`函数时，我们可以看到每个发行商随时间的变化。让我们看看这种数据重塑会做什么。以下代码生成了图5.33所示的交叉表：
- en: '[PRE27]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![figure](../Images/5-33.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-33.png)'
- en: Figure 5.33 A snapshot of the pivot table aggregating across distributors and
    years
  id: totrans-303
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.33 按发行商和年份汇总的交叉表快照
- en: 'There are a number of data problems that become obvious. We need to merge the
    two separate values for 20th Century Fox, merge the “Other” categories into a
    single name so they get a single line over time, and investigate the various distributors
    with “Entertainment” in the name. Upon investigation, it appears Entertainment
    One and eOne Films, which both appear in our data, are the same entity ([https://www.entertainmentone.com/about-eone/](https://www.entertainmentone.com/about-eone/)).
    Entertainment Film Distributors is a legitimately separate entity from Entertainment
    One, but we don’t have evidence of whether the distributor marked simply “Entertainment”
    should be merged into any other category. We will leave it on its own. After these
    corrections, we can look at how many years each distributor is represented in
    our data. The result of this is shown in figure 5.34:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多数据问题变得明显。我们需要合并20世纪福克斯的两个单独值，将“其他”类别合并成一个单一名称，以便它们随着时间的推移获得单行，并调查名称中包含“娱乐”的各个发行商。经过调查，发现娱乐一公司和eOne
    Films，这两者都出现在我们的数据中，实际上是同一实体（[https://www.entertainmentone.com/about-eone/](https://www.entertainmentone.com/about-eone/))).
    娱乐电影发行商是 Entertainment One 的一个合法独立实体，但我们没有证据表明仅标记为“娱乐”的发行商是否应该合并到其他任何类别中。我们将将其保留独立。在这些更正之后，我们可以查看每个发行商在我们的数据中代表了多少年。这一结果在图5.34中显示：
- en: '[PRE28]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![figure](../Images/5-34.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-34.png)'
- en: Figure 5.34 Number of years each distributor is present in our data
  id: totrans-307
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.34 每个发行商在我们的数据中出现的年数
- en: 'We can also use this result to decide whether to plot all distributors. We
    are particularly interested in change over time, so we should keep only distributors
    that appear in all years of our data. This will potentially omit distributors
    who went out of business during or because of the pandemic. These could be analyzed
    further separately:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用这个结果来决定是否绘制所有发行商。我们特别关注随时间的变化，因此我们应该只保留出现在我们数据所有年份中的发行商。这可能会省略在疫情期间或因疫情而倒闭的发行商。这些可以进一步单独分析：
- en: '[PRE29]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can use these distributors to recreate our pivot table and see how market
    share compares across years:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这些发行商来重新创建我们的交叉表，并查看市场份额在年份间的比较：
- en: '[PRE30]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '#1 Converts each year to the first of January to make it a date type'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将每年转换为1月1日以使其成为日期类型'
- en: '#2 One row per year, one column per distributor'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 每年一行，每家发行商一列'
- en: 'Visually, it’s easier to read the pivot table if years go across columns, so
    let’s transpose the data and examine the output shown in figure 5.35:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 从视觉上看，如果年份跨越列，交叉表更容易阅读，所以让我们转置数据，并检查图5.35中显示的输出：
- en: '[PRE31]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![figure](../Images/5-35.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-35.png)'
- en: Figure 5.35 Distributor market share (%) over time
  id: totrans-317
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.35 发行商市场份额（%）随时间变化
- en: 'From this pivot table, we can conclude the following:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个交叉表中，我们可以得出以下结论：
- en: Walt Disney completed their purchase of 20th Century Fox in 2019, yet this did
    not translate to a large increase in market share even in 2021\.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 华特迪士尼在2019年完成了对20世纪福克斯的收购，但这并没有导致市场份额在2021年有大幅增长。
- en: Sony achieved the biggest increase in market share post-lockdown, doubling their
    market share from 2018, but Universal also increased their market share from pre-COVID
    levels.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索尼在解封后实现了市场份额的最大增长，将市场份额从2018年翻倍，但环球也从COVID之前的水平增加了市场份额。
- en: Apart from Sony and Universal, the distributors with bigger market share roughly
    returned to pre-COVID levels of market share in 2021\. Some smaller ones, like
    StudioCanal, failed to reach pre-COVID levels.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了索尼和环球之外，市场份额较大的发行商在2021年大致回到了COVID之前的市场份额水平。一些较小的发行商，如StudioCanal，未能达到COVID之前的水平。
- en: Initial speculation about these results might be that the bigger distributors
    are the ones that have the resources to bounce back from even a global pandemic,
    whereas smaller distributors will likely struggle more with this.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 对这些结果的初步推测可能是，较大的发行商是那些拥有资源从全球大流行中恢复过来的，而较小的发行商可能会遇到更大的困难。
- en: Before summarizing our findings, let’s review the whole process, including places
    where our latest step could have diverged. Figure 5.36 shows the whole process.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在总结我们的发现之前，让我们回顾整个过程，包括我们的最新步骤可能发生分歧的地方。图5.36显示了整个过程。
- en: '![figure](../Images/5-36.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-36.png)'
- en: Figure 5.36 The final steps taken in the example solution
  id: totrans-325
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.36 示例解决方案中采取的最终步骤
- en: Let’s now review our findings and summarize our recommendations to our stakeholders.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来回顾我们的发现，并总结我们对利益相关者的建议。
- en: 5.4.4 Project conclusions and recommendations
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.4 项目结论和建议
- en: What do our results mean for the white paper?
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果对白皮书意味着什么？
- en: UK-level admissions data does not tell a very interesting story beyond admissions
    looking like they are reaching pre-COVID levels. An additional year of data would
    help clarify post-lockdown trends, as would looking at admissions at a more granular
    level, such as by region or film type.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英国层面的招生数据并没有讲述一个非常有趣的故事，除了招生看起来像是达到了COVID之前的水平。额外一年的数据将有助于阐明解封后的趋势，同样，从更细致的层面，如地区或电影类型来看招生情况，也会有所帮助。
- en: There is a difference in the breakdown of genres post-lockdowns, certainly enough
    of a difference to investigate this angle further.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解封后，类型分布有所不同，确实有足够的不同来进一步调查这个角度。
- en: Distributors follow general market trends where larger entities bounce back
    from COVID more easily than smaller ones.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发行商遵循一般市场趋势，大型实体比小型实体更容易从COVID中恢复过来。
- en: The limitations of our analysis extend mostly to a lack of data. We do not have
    a lot of post-lockdown data to compare with past trends, so our conclusions can
    only be tentative. Our data is focused on the United Kingdom, so it does not give
    a global picture. However, we can assume the research firm we work for would have
    more granular data for us to investigate our findings further. There is enough
    in our conclusions to have a conversation with our domain experts, but the first
    round of analysis does not suggest we have enough to support a white paper.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分析的限制主要在于数据不足。我们没有很多解封后的数据可以与过去趋势进行比较，因此我们的结论只能是试探性的。我们的数据集中在英国，因此它不能提供一个全球的视角。然而，我们可以假设我们工作的研究公司会有更细致的数据，以便我们进一步调查我们的发现。我们的结论中有足够的论据可以与我们的领域专家进行对话，但第一轮分析并不表明我们有足够的论据来支持一份白皮书。
- en: One benefit of this analysis, whether or not it leads to a published paper,
    is that we have written a data pipeline to extract data from the BFI’s published
    statistics. Having this data in a format that is ready to be analyzed will yield
    value for future projects. Sometimes, cleaning data in this way can be a valuable
    contribution in itself.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分析的一个好处，无论它是否导致发表论文，就是我们编写了一个数据管道，用于从BFI发布的统计数据中提取数据。以这种格式拥有这些数据将为未来的项目带来价值。有时，以这种方式清理数据本身就是一项有价值的贡献。
- en: 'Activity: Further project ideas with this data'
  id: totrans-334
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 活动：使用这些数据进一步的项目想法
- en: 'The PDF files included in this chapter are a treasure trove of information
    about the film industry. This project focused on the effects of the pandemic,
    but there are many other angles to explore and many research questions that could
    be answered. Here are some ideas to get you started:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中包含的PDF文件是关于电影行业信息的宝库。这个项目专注于大流行的影响，但还有许多其他角度可以探索，以及许多可以回答的研究问题。以下是一些帮助你开始的想法：
- en: How have people’s preferences of genre evolved over time?
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人们的类型偏好是如何随时间演变的？
- en: Is there a pattern in what kind of independent films is successful?
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功的独立电影有什么样的模式吗？
- en: How have attendance figures changed over time in different countries? Are movie-goers
    changing the same way everywhere?
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同国家的观众人数是如何随时间变化的？电影观众是否在各地以相同的方式改变？
- en: 5.5 Closing thoughts on exploring novel data sources
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 关于探索新颖数据源的总结性思考
- en: There are two takeaways from this chapter. One is that you will encounter situations
    where you need to learn a specific, narrow skill to extract data from an unusual
    format. This is a good opportunity to learn about more esoteric parts of your
    existing toolkit, such as its PDF-extracting capabilities. AI tools can accelerate
    this learning process, and this chapter’s project is an example of where depth
    is not required. To successfully complete the project in this chapter, you did
    not need to become an expert in PDF extraction or optical character recognition,
    the process of converting an image to a machine-readable text form. You only needed
    to find the relevant library and code snippets to extract tabular data from a
    PDF. It is an example of learning enough to stay focused on the end result and
    no more.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 从本章中我们可以得到两个启示。一个是你会遇到需要学习特定、狭窄的技能来从异常格式中提取数据的情况。这是一个了解你现有工具中更神秘部分的好机会，例如其PDF提取功能。AI工具可以加速这一学习过程，本章的项目就是一个深度不是必需的例子。要成功完成本章的项目，你不需要成为PDF提取或光学字符识别的专家，即图像转换为机器可读文本形式的过程。你只需要找到相关的库和代码片段，从PDF中提取表格数据。这是一个学习足够以保持对最终结果专注而无需更多的例子。
- en: Second, the broader takeaway is that data is available in many forms. Knowing
    that our tools make it possible to extract data from unusual, unstructured sources
    will expand the potential data available to us for our analyses. It allows us
    to generate more creative solutions to problems, which will help us add more value
    with our work.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，更广泛的启示是数据以许多形式存在。知道我们的工具使我们能够从异常、无结构的数据源中提取数据，这将扩大我们用于分析的可用数据潜力。它使我们能够为问题生成更多创造性的解决方案，这将帮助我们通过我们的工作增加更多价值。
- en: 5.5.1 Skills for exploring unusual data sources for any project
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.1 探索任何项目的不寻常数据源所需的技能
- en: In this chapter, we explored a new source of data, namely, PDF files. The specific
    skills required for unusual data sources, and more broadly for exploring new data
    sources, which can be used for any problem, include
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探索了一种新的数据来源，即PDF文件。对于不寻常的数据源，以及更广泛地探索新的数据源，这些技能可以用于任何问题，包括
- en: Finding the relevant data in unstructured files, such as PDFs
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在非结构化文件中找到相关数据，例如PDF
- en: Identifying existing tools to extract data from a novel source
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别现有工具从新颖的数据源中提取数据
- en: Using AI tools such as ChatGPT to learn about specific tools for specific data
    formats
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用AI工具（如ChatGPT）了解特定数据格式的特定工具
- en: Using new tools to extract data from unstructured sources into structured formats
    (e.g., data from PDFs into CSV files)
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用新工具从非结构化源提取数据到结构化格式（例如，从PDF到CSV文件的数据）
- en: Enhancing extracted data with custom logic (e.g., pre- and post-COVID lockdown
    periods)
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自定义逻辑（例如，COVID封锁前后的时期）增强提取的数据
- en: Investigating trends by extracting similar data from multiple sources over time
    (e.g., the same annual report across multiple years)
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过从多个来源随时间提取相似数据来调查趋势（例如，跨多年的相同年度报告）
- en: Resolving differences across multiple similar data sources (e.g., names of production
    companies changing over time but relating to the same entity)
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决多个类似数据源之间的差异（例如，随着时间的推移，制作公司的名称发生变化，但与同一实体相关）
- en: Summary
  id: totrans-351
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Identifying novel and unstructured data sources is a core skill of a good analyst.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别新颖和无结构的数据源是优秀分析师的核心技能。
- en: 'Considering new data sources in your analysis may introduce nontabular or unstructured
    data requiring effort to clean up: time you should consider when including them.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分析中考虑新的数据源可能会引入非表格或无结构数据，需要付出努力来清理：在包括它们时应考虑的时间。
- en: Telling the story that’s in the data, rather than the one our stakeholders asked
    for in their problem statement, is critical to avoid misleading ourselves.
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据中蕴含的故事讲述出来，而不是我们利益相关者在问题陈述中要求的那一个，这对于避免误导自己至关重要。
- en: Focusing on the problem to solve rather than the data increases the chances
    that any additional data you consider will be relevant.**
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于要解决的问题而不是数据，会增加你考虑的任何额外数据相关的可能性。**
