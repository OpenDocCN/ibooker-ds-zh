<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 10. Using Python to Measure Climate Data" data-type="chapter" epub:type="chapter"><div class="chapter" id="using_python_to_measure_climate_data">
<h1><span class="label">Chapter 10. </span>Using Python to Measure Climate Data</h1>
<p>Developing technical skills and pathways for learning Python and geospatial analysis is important, but unless you provide context or create a narrative to share, it’s all simply data on a shelf.<a contenteditable="false" data-primary="climate data, using Python to measure" data-type="indexterm" id="ix_clmtda"/></p>
<p>In this final chapter, you will explore three approaches to exploring time-series data by accessing satellite image layers from <a href="https://oreil.ly/9bHFj">Landsat</a>, <a href="https://oreil.ly/PM7Lt">China–Brazil Earth Resources Satellite (CBERS)</a>, and <a href="https://oreil.ly/1Kym6">Sentinel</a>. <a contenteditable="false" data-primary="time-series data" data-secondary="approaches to exploring by accessing satellite image layers" data-type="indexterm" id="idm45433739040304"/>You will use your geospatial analysis skills to examine questions about climate change and deforestation.</p>
<p>Spatial modeling is a crucial tool for forecasting, predicting, and monitoring the real-time status of global temperature increases and deforestation, which in turn helps us anticipate the consequences of these phenomena and potentially intervene or prepare for them.</p>
<p>Three examples are presented to highlight some powerful Python packages: Xarray, Web Time Series Service (WTSS), and Forest at Risk (FAR). <a contenteditable="false" data-primary="Xarray package (Python)" data-type="indexterm" id="idm45433739037136"/><a contenteditable="false" data-primary="Forest at Risk (FAR)" data-type="indexterm" id="idm45433739261888"/><a contenteditable="false" data-primary="Web Time Series Service (WTSS)" data-type="indexterm" id="idm45433739088816"/>Although these may appear to be new tools, you have been introduced to many of their dependencies in earlier chapters. The last example is a deeper dive into the statistical power of packages designed for predictive modeling, which you’ll use in analyzing deforestation. You can run code in <a href="https://oreil.ly/9ADWy">the accompanying notebook</a>, since complete explanations of everything in it is beyond the scope of this book.</p>
<section class="pagebreak-before" data-pdf-bookmark="Example 1: Examining Climate Prediction with Precipitation Data" data-type="sect1"><div class="sect1" id="example_one_examining_climate_predictio">
<h1 class="less_space">Example 1: Examining Climate Prediction with Precipitation Data</h1>
<p>Spatial analysis often relies on multidimensional data analysis. Think of a gridded dataset as resembling a cube.<a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-type="indexterm" id="ix_clmtdaex1"/><a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-type="indexterm" id="ix_precip"/> In Python (and in computer programming in general), arrays store lists of data. The objects in the list can be referenced individually or collectively. This is important when calling a Python array because you can access each item by its index number.</p>
<p>Multidimensional and N-dimensional arrays, or <em>tensors</em>, are displayed in NumPy ndarrays. <a contenteditable="false" data-primary="NumPy" data-secondary="ndarrays, tensors displayed in" data-type="indexterm" id="idm45433739079616"/><a contenteditable="false" data-primary="tensors" data-type="indexterm" id="idm45433740980640"/><a contenteditable="false" data-primary="multidimensional and N-dimensional arrays (or tensors)" data-type="indexterm" id="idm45433739025952"/>Think of a tensor as a container of data or information. In Python, <a href="http://www.numpy.org">NumPy</a> provides the fundamental data structure and API for working with raw ndarrays.</p>
<p>You will be working with real-world datasets that encode information about how the array’s values map to locations. The data you are working with is labeled with encoded information such as timestamps, coordinates, elevation, land cover, and precipitation.</p>
<section data-pdf-bookmark="Goals" data-type="sect2"><div class="sect2" id="goals">
<h2>Goals</h2>
<p>The mission of the US government’s <a href="https://oreil.ly/NKI29">National Oceanic and Atmospheric Administration (NOAA)</a> is to “predict changes in climate, weather, oceans, and coasts” and to inform and address urgent societal and environmental impacts from extreme weather events. <a contenteditable="false" data-primary="NOAA (National Oceanic and Atmospheric Administration)" data-type="indexterm" id="idm45433739287792"/><a contenteditable="false" data-primary="National Oceanic and Atmospheric Administration (NOAA)" data-type="indexterm" id="idm45433739067776"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-tertiary="goals" data-type="indexterm" id="idm45433739027248"/><a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-secondary="goals" data-type="indexterm" id="idm45433739021360"/>In this exercise, you will work with a publicly available dataset to analyze daily precipitation. Comparing data from the continental US from 2015 and 2021, you will observe patterns in the data to determine if there are distinct observable differences.</p>
<p>First, I will introduce you to Xarray, an open source project that interoperates with NumPy, SciPy, and matplotlib, extending beyond NumPy ndarrays and pandas dataframes.</p>
<p>As with the preceding chapters, after you complete an introduction to a package and its supporting documentation, I strongly encourage you to experiment with different datasets and applications of Python packages and libraries.</p>
</div></section>
<section data-pdf-bookmark="Downloading Your Data" data-type="sect2"><div class="sect2" id="downloading_your_data">
<h2>Downloading Your Data</h2>
<p>First, navigate to <a href="https://oreil.ly/NhTn2">Gridded Climate Datasets: Precipitation</a> and choose the Climate Prediction Center (CPC) <a href="https://oreil.ly/M8ynH">Global Precipitation dataset</a>. <a contenteditable="false" data-primary="Gridded Climate Datasets: Precipitation" data-type="indexterm" id="idm45433739014496"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-tertiary="downloading your data" data-type="indexterm" id="idm45433739013520"/><a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-secondary="downloading your data" data-type="indexterm" id="idm45433739012064"/>Weather data for a given latitude/longitude is returned for the grid cell aligned with the requested lat/long.</p>
<p>Download <a contenteditable="false" data-primary="Colab" data-secondary="precipitation data files in" data-type="indexterm" id="idm45433739009168"/>the years of interest, 2015 and 2021, and upload the files to either your Google drive or directly to your computer. <a data-type="xref" href="#files_in_google_colab">Figure 10-1</a> shows the folder and file hierarchy.</p>
<figure><div class="figure" id="files_in_google_colab"><img alt="Files in Google Colab" height="808" src="assets/pgda_1001.png" width="940"/>
<h6><span class="label">Figure 10-1. </span>Files in Google Colab</h6>
</div></figure>
</div></section>
<section data-pdf-bookmark="Working in Xarray" data-type="sect2"><div class="sect2" id="working_in_xarray">
<h2>Working in Xarray</h2>
<p>Xarray is a Python library that hosts many dependencies that should by now be familiar to you, such as NumPy and pandas, as well as a few optional dependencies that you’ll need to work with the CPC Global Precipitation dataset.<a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-tertiary="working in Xarray" data-type="indexterm" id="ix_clmtdaex1Xarry"/><a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-secondary="working in Xarray" data-type="indexterm" id="ix_precipXarry"/><a contenteditable="false" data-primary="Xarray package (Python)" data-secondary="working in" data-type="indexterm" id="ix_Xarry"/> Originally developed by the Climate Corporation, <a href="https://oreil.ly/NjJmL">Xarray</a> has become a useful open source resource for analyzing climate change data files for plotting and analysis. It’s useful for exploring weather, water, and climate extremes and their impact.</p>
<p>The NOAA Physical Sciences Laboratory relies on the Network Common Data Form (netCDF) format of Xarray, which is an interface for array-oriented data containing dimensions, variables, and attributes on top of NumPy arrays. <a contenteditable="false" data-primary="Network Common Data Form (netCDF) format of Xarray" data-type="indexterm" id="idm45433739270496"/>The dimensions are often time and latitude or longitude, so this format is directly applicable to spatial observation and analysis.</p>
<p class="pagebreak-before less_space">You will download daily precipitation data and apply functions to it, including <code>groupby</code> (for grouping), <code>concat</code> (to combine files, also called <em>concatenation</em>), and <code>sel &amp; isel</code> (to select data for specific dates or particular locations). Additionally, you will learn how to handle leap years. You’ll save the desired outputs as netCDF files.</p>
<p><em>Gridded data</em> combines<a contenteditable="false" data-primary="gridded data" data-type="indexterm" id="idm45433739028928"/> point data (such as data from an individual weather station) and other data sources and maintains a spatially and temporally consistent method to account for factors like temperature changes and precipitation caused by location or elevation. The weather data is provided from a data distribution containing more than 2,500 monthly gridded data points, representing the entire globe.</p>
<p>Xarray’s data structures are <em>N-dimensional</em>, meaning that they have a variable number of dimensions. <a contenteditable="false" data-primary="N-dimensional data structures in Xarray" data-type="indexterm" id="idm45433738993520"/>This makes Xarray suitable for dealing with multidimensional scientific data. Because it uses dimension names instead of axis labels (dim=‘time’ instead of axis=0), these arrays are more manageable than arrays in NumPy ndarrays. With Xarray, you don’t need to keep track of the order of dimensions or insert placeholder dimensions of size 1 to align arrays.</p>
<p>You will work with a few of the available functions to analyze geospatial data. Running <code>open_mfdataset</code> opens multiple files at one time. <a contenteditable="false" data-primary="open_mfdataset" data-type="indexterm" id="idm45433739946544"/>You will use this to compare different timepoints.<a contenteditable="false" data-primary="Google Drive, connecting to Colab" data-type="indexterm" id="idm45433739941808"/> You are going to run these examples in <a href="https://oreil.ly/J8wam">Google Colab</a>. I always connect to my Google Drive, as I keep most of the datasets on the cloud and not on my local computer.<a contenteditable="false" data-primary="Colab" data-secondary="connecting Google Drive to" data-type="indexterm" id="idm45433738983104"/> It is simple to connect your drive to Colab and select the directory where you are hosting the dataset:</p>
<pre data-type="programlisting">
<strong>from</strong> google.colab <strong>import</strong> drive
drive.mount(<span>'/content/drive'</span>)</pre>
<div data-type="tip"><h6>Tip</h6>
<p>Not everyone has a Google Drive. You can also access your data by simply uploading it to Google Colab. I actually upgraded to Google Colab Pro to improve runtime performance. Connecting to your Google Drive is usually the best option, but your mileage may vary.</p>
</div>
<p>You will need to establish the connection by selecting and approving it. Mounting the drive will take a little time, but then the files will show up in your available files.</p>
<p>Google Colab has a preinstalled version of Xarray, but I suggest a <code>pip install</code> to make certain the dependencies are all included:</p>
<pre data-type="programlisting">
!pip install xarray[complete]</pre>
<p>I make it a habit to run installs separately but bundle the import functions; this allows me to isolate and address any errors.</p>
<p>Let’s take a look at the less familiar modules you will be importing.<a contenteditable="false" data-primary="glob module" data-type="indexterm" id="idm45433739003616"/> The <code>glob</code> module (short for “global”) returns the files or folders that you specify. This also applies to paths inside directories/files and subdirectories/subfiles. <a contenteditable="false" data-primary="matplotlib" data-secondary="plotting library for Xarray" data-type="indexterm" id="idm45433739003264"/>You should recognize matplotlib as our plotting library, built on NumPy, and <code>urllib.request</code> as a module for retrieving URLs.<a contenteditable="false" data-primary="urllib.request module" data-type="indexterm" id="idm45433738972080"/> You can download data to upload to Colab or, if your data is available as a URL, add the import to your code:</p>
<pre data-type="programlisting">
<strong>import</strong> glob
<strong>import</strong> matplotlib.pyplot <strong>as</strong> plt
<span><strong>import</strong> urllib.request</span>
<strong>import</strong> xarray <strong>as</strong> xr</pre>
</div></section>
<section data-pdf-bookmark="Combining Your 2015 and 2021 Datasets" data-type="sect2"><div class="sect2" id="combining_your_twozeroonefive_and_twoze">
<h2>Combining Your 2015 and 2021 Datasets</h2>
<p>The Xarray dataset is a container of labeled arrays.<a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-startref="ix_clmtdaex1Xarry" data-tertiary="working in Xarray" data-type="indexterm" id="idm45433738965200"/><a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-secondary="working in Xarray" data-startref="ix_precipXarry" data-type="indexterm" id="idm45433738962496"/><a contenteditable="false" data-primary="Xarray package (Python)" data-secondary="working in" data-startref="ix_Xarry" data-type="indexterm" id="idm45433738960880"/><a contenteditable="false" data-primary="Xarray package (Python)" data-secondary="combining precipitation datasets for 2015 and 2021" data-type="indexterm" id="ix_Xarrycmbds"/><a contenteditable="false" data-primary="datasets" data-secondary="Xarray" data-type="indexterm" id="idm45433738957616"/><a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-secondary="combining 2015 and 2021 datasets" data-type="indexterm" id="ix_precipcmbds"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-tertiary="combining 2015 and 2021 datasets" data-type="indexterm" id="ix_clmtdacmbds"/> It is similar to a dataframe, except it is multidimensional and aligns <a contenteditable="false" data-primary="Network Common Data Form (netCDF) format of Xarray" data-secondary="NetCDF data array" data-type="indexterm" id="idm45433738951680"/>with the netCDF dataset representation, shown in <a data-type="xref" href="#netcdf_data_array">Figure 10-2</a>.</p>
<figure><div class="figure" id="netcdf_data_array"><img alt="NetCDF data array" height="715" src="assets/pgda_1002.png" width="1498"/>
<h6><span class="label">Figure 10-2. </span>NetCDF data array</h6>
</div></figure>
<p>Enter the code to create your two variables, <code>ds2015</code> for 2015 and <code>ds2021</code> for 2021:</p>
<pre data-type="programlisting">
<span>ds2015 = xr.open_dataset(</span>'/content/precip.V1.0.2015.nc'<span>)</span>


<span>ds2021 = xr.open_dataset(</span>'/content/precip.V1.0.2021.nc'<span>)</span></pre>
<p><a data-type="xref" href="#dataset_properties_in_xarray">Figure 10-3</a> shows the key properties<a contenteditable="false" data-primary="datasets" data-secondary="Xarray" data-tertiary="properties of" data-type="indexterm" id="idm45433738942848"/> of the Xarray dataset, including dimensions, coordinates, data variables, and attributes.</p>
<figure><div class="figure" id="dataset_properties_in_xarray"><img alt="Dataset properties in Xarray" height="728" src="assets/pgda_1003.png" width="1400"/>
<h6><span class="label">Figure 10-3. </span>Dataset properties in Xarray</h6>
</div></figure>
<p>Click the database icon (it looks like stacked discs) to see more details. You will see the cell expand, as shown in <a data-type="xref" href="#expanded_dataset_details">Figure 10-4</a>. The expanded metadata reveals the array and additional information.</p>
<p>Next, you are going to <a href="https://oreil.ly/E60L2">concatenate</a> (join) Xarray objects along the <code>time</code> dimension:</p>
<pre data-type="programlisting">
ds2015_2021 = xr.concat([ds2015,ds2021], dim=<span>'time'</span>)
ds2015_2021</pre>
<figure><div class="figure" id="expanded_dataset_details"><img alt="Expanded dataset details" height="1012" src="assets/pgda_1004.png" width="724"/>
<h6><span class="label">Figure 10-4. </span>Expanded dataset details</h6>
</div></figure>
<p>The output (<a data-type="xref" href="#time_coordinates_concatenated">Figure 10-5</a>) will confirm that the datasets have been combined. <a contenteditable="false" data-primary="time coordinates concatenated" data-type="indexterm" id="idm45433738931040"/>The time coordinate now lists both years that you selected.</p>
<figure><div class="figure" id="time_coordinates_concatenated"><img alt="Time coordinates concatenated" height="851" src="assets/pgda_1005.png" width="1441"/>
<h6><span class="label">Figure 10-5. </span>Time coordinates concatenated</h6>
</div></figure>
<p>The function <code>dataarray.groupby</code> returns an object for group operations. You will be grouping operations by month (<code>time.month</code> in the code). There is a <code>dataarray</code> object for a daily dataset that spans a few years. This object has one variable and three dimensions: latitude, longitude, and time (daily). You can generate a graphic for both 2015 and 2021 (<a data-type="xref" href="#monthly_precipitation_in_the_continenta">Figure 10-6</a>).</p>
<figure><div class="figure" id="monthly_precipitation_in_the_continenta"><img alt="Monthly precipitation in the continental US in 2015 (left) and 2021 (right)" height="513" src="assets/pgda_1006.png" width="1432"/>
<h6><span class="label">Figure 10-6. </span>Monthly precipitation in the continental US in 2015 (left) and 2021 (right)</h6>
</div></figure>
</div></section>
<section data-pdf-bookmark="Generating the Images" data-type="sect2"><div class="sect2" id="generating_the_images">
<h2>Generating the Images</h2>
<p>To generate the plot for your<a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-startref="ix_clmtdacmbds" data-tertiary="combining 2015 and 2021 datasets" data-type="indexterm" id="idm45433738920928"/><a contenteditable="false" data-primary="Xarray package (Python)" data-secondary="combining precipitation datasets for 2015 and 2021" data-startref="ix_Xarrycmbds" data-type="indexterm" id="idm45433738918496"/><a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-secondary="combining 2015 and 2021 datasets" data-startref="ix_precipcmbds" data-type="indexterm" id="idm45433738916880"/> 2015 image, state the lower bound by the first item (<code>0</code>), the default for the upper bound, and the step size default.<a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-secondary="generating images for precipitation in 2015 and 2021" data-type="indexterm" id="ix_precipgenimg"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-tertiary="generating the images" data-type="indexterm" id="ix_clmtdagenimg"/> Monthly precipitation is an object to be sliced, as indicated by <code>mon.precip</code>. We are operating across the three dimensions:</p>
<pre data-type="programlisting">
ds2015_mon = ds2015.groupby(<span>'time.month'</span>).sum()
ds2015_mon.precip[<span>0</span>,:,:].plot(cmap=<span>'jet'</span>, vmax=<span>300</span>)</pre>
<p>You can use the same method to generate a map for 2021. The output for both is in <a data-type="xref" href="#monthly_precipitation_in_the_continenta">Figure 10-6</a>, and the different patterns of precipitation are visible.</p>
<p>Let’s expand beyond a single month to compare different years. Python has a calendar module that will display an entire year for comparison. Follow this code to iterate over each month in a calendar year, using matplotlib and the <code>calendar</code> module:</p>
<pre data-type="programlisting">
<strong>import</strong> calendar</pre>
<p>Now, you will apply the sum along the <code>time</code> dimension. <a contenteditable="false" data-primary="landmask" data-type="indexterm" id="idm45433739061552"/>The landmask you are creating will “mask out” certain observations instead of returning NaN values:</p>
<pre data-type="programlisting">
landmask = ds2015.precip.sum(dim=<span>'time'</span>)&gt;<span>0</span></pre>
<p>Matplotlib allows you to format and plot a series of maps.<a contenteditable="false" data-primary="matplotlib" data-secondary="formatting and plotting precipitation maps for 2015 and 2021" data-type="indexterm" id="idm45433738898736"/> There are defaults for these parameters, but when you want to customize them, you can provide a width and height in inches for the image (<code>figsize</code>) and a background color (<code>facecolor</code>). The parameter <code>subplots_adjust</code> allows you to adjust the position of the subplot or axes. Let’s do 2015 first:</p>
<pre data-type="programlisting">
fig = plt.figure(figsize=[<span>12</span>,<span>8</span>], facecolor=<span>'w'</span>)
plt.subplots_adjust(bottom=<span>0.15</span>, top=<span>0.96</span>, left=<span>0.04</span>, right=<span>0.99</span>,
                   wspace=<span>0.2</span>, hspace=<span>0.27</span>)
nrows = <span>3</span>
ncols = <span>4</span>
<strong>for</strong> i <strong>in</strong> range(<span>1</span>, <span>13</span>):
#the python data index starts at 0, but the subplot starts at 1.  
plt.subplot(nrows, ncols, i)
   dataplot = ds2015_mon.precip[i<span>-1</span>, :].where(landmask)
   p = plt.pcolormesh(ds2015_mon.lon, ds2015_mon.lat, dataplot,
                  vmax = <span>400</span>, vmin = <span>0</span>, cmap = <span>'nipy_spectral_r'</span>,
                  )
   plt.xlim([<span>233</span>,<span>295</span>])
   plt.ylim([<span>25</span>,<span>50</span>])
   plt.title(calendar.month_name[dataplot.month.values], fontsize = <span>13</span>,
             fontweight = <span>'bold'</span>, color = <span>'b'</span>)
   plt.xticks(fontsize = <span>11</span>)
   plt.yticks(fontsize = <span>11</span>)
   <strong>if</strong> i % ncols == <span>1</span>: <span># Add ylabel for the very left subplots</span>
       plt.ylabel(<span>'Latitude'</span>, fontsize = <span>11</span>, fontweight = <span>'bold'</span>)
   <strong>if</strong> i &gt; ncols*(nrows<span>-1</span>): <span># Add xlabel for the bottom row subplots</span>
       plt.xlabel(<span>'Longitude'</span>, fontsize = <span>11</span>, fontweight = <span>'bold'</span>)

<span># Add a colorbar at the bottom:</span>
cax = fig.add_axes([<span>0.25</span>, <span>0.06</span>, <span>0.5</span>, <span>0.018</span>])
cb = plt.colorbar(cax=cax, orientation=<span>'horizontal'</span>, extend = <span>'max'</span>,)
cb.ax.tick_params(labelsize=<span>11</span>)
cb.set_label(label=<span>'Precipitation (mm)'</span>, color = <span>'k'</span>, size=<span>14</span>)

<span># Now we can save a high resolution (300dpi) version of the figure:</span>
plt.savefig(<span>'Fig_prec_cpc_mon_2015.png'</span>, format = <span>'png'</span>, dpi = <span>300</span>)</pre>
<p>Experiment with different values to see how the image changes. The edges of the subplots are nudged along with the amount of width space (<code>wspace</code>) or height space (<code>hspace</code>).</p>
<p>You can explore different plot types in the <a href="https://oreil.ly/7Nrc9">matplotlib</a> usage guide. <a contenteditable="false" data-primary="Xarray package (Python)" data-secondary="yearly precipitation in continental US by month" data-type="indexterm" id="idm45433738869072"/>The output is shown in <a data-type="xref" href="#yearly_precipitation_in_the_continental">Figure 10-7</a>.</p>
<figure><div class="figure" id="yearly_precipitation_in_the_continental"><img alt="Yearly precipitation in the continental US by month, 2015, in Xarray" height="570" src="assets/pgda_1007.png" width="857"/>
<h6><span class="label">Figure 10-7. </span>Yearly precipitation in the continental US by month, 2015, in Xarray</h6>
</div></figure>
<p>Next, update the code cell to run the 2021 data (<a data-type="xref" href="#yearly_precipitationcomma_twozerotwoone">Figure 10-8</a>) and visually compare the difference in precipitation between the two years.</p>
<figure><div class="figure" id="yearly_precipitationcomma_twozerotwoone"><img alt="Yearly precipitation, 2021" height="596" src="assets/pgda_1008.png" width="863"/>
<h6><span class="label">Figure 10-8. </span>Yearly precipitation, 2021</h6>
</div></figure>
</div></section>
<section data-pdf-bookmark="More Exploration" data-type="sect2"><div class="sect2" id="more_exploration">
<h2>More Exploration</h2>
<p>There are <a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-secondary="generating images for precipitation in 2015 and 2021" data-startref="ix_precipgenimg" data-type="indexterm" id="idm45433738858912"/>additional <a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-startref="ix_clmtdagenimg" data-tertiary="generating the images" data-type="indexterm" id="idm45433738856816"/>queries you can try if you want to see the data underlying the imagery. <a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-tertiary="more exploration" data-type="indexterm" id="idm45433738853568"/><a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-secondary="more exploration" data-type="indexterm" id="idm45433738851952"/>For instance, <code>ds2021.precip.dims</code> will list the dimensions in the data, <code>ds2021.precip.attrs</code> will list attributes, and <code>ds2021.precip.data</code> will show the daily precipitation.</p>
<p>Precipitation data<a contenteditable="false" data-primary="seasonal grouping of precipitation data" data-type="indexterm" id="idm45433738849520"/> might be more meaningful if grouped seasonally, so let’s try that:</p>
<pre data-type="programlisting">
<span>ds2021.groupby(<span>"time.season"</span>)</span>
DatasetGroupBy, grouped over 'season'
4 groups with labels 'DJF', 'JJA', 'MAM', 'SON'.</pre>
<p>The seasons are named by the months they contain: <code>DJF</code> for winter, <code>JJA</code> for summer, <code>MAM</code> for spring, and <code>SON</code> for fall. Let’s order them in an intuitive manner:</p>
<pre data-type="programlisting">
seasonal_mean = seasonal_mean.reindex(season=[<span>"DJF"</span>, <span>"MAM"</span>, <span>"JJA"</span>, <span>"SON"</span>])
seasonal_mean</pre>
<p>The seasons are now displayed chronologically, as they occur in a single year. Visualizing precipitation levels allows you to observe how precipitation varies by season and location (<a data-type="xref" href="#mean_precipitation_arranged_by_season">Figure 10-9</a>).</p>
<figure><div class="figure" id="mean_precipitation_arranged_by_season"><img alt="Mean precipitation arranged by season" height="267" src="assets/pgda_1009.png" width="971"/>
<h6><span class="label">Figure 10-9. </span>Mean precipitation arranged by season</h6>
</div></figure>
<p>Observations of precipitation levels demonstrate patterns in the data. You may have noticed that temperature datasets are also available in gridded format. Now that you have been introduced to Xarray and how to work with multidimensional arrays, try exploring maximum temperature, minimum temperature, and average temperature to expand your insights. What can you learn by plotting this data as well?<a contenteditable="false" data-primary="precipitation data, examining climate prediction with (example)" data-startref="ix_precip" data-type="indexterm" id="idm45433738837648"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="examining climate prediction with precipitation data (example 1)" data-startref="ix_clmtdaex1" data-type="indexterm" id="idm45433739443120"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Example 2: Deforestation and Carbon Emissions in the Amazon Rain Forest Using WTSS Series" data-type="sect1"><div class="sect1" id="example_two_deforestation_and_carbon_em">
<h1>Example 2: Deforestation and Carbon Emissions in the Amazon Rain Forest Using WTSS Series</h1>
<p>The Amazon rain forest is shrinking. <a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example 2)" data-type="indexterm" id="ix_clmtdaex2"/><a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-type="indexterm" id="ix_deforest"/>Roadway construction in the forest, contact between humans and animals, and contact between visitors and the Indigenous peoples who live in the rain forest all contribute to ongoing deforestation and forest degradation.<a contenteditable="false" data-primary="degradation" data-type="indexterm" id="idm45433739926720"/> <em>Degradation</em> refers to a decline in forest density that does not quite meet the level of deforestation—typically, when tree cover is diminished between 10% and 30% and the land is being converted to alternative uses, such as timber harvesting or agriculture. When the forest cover is disturbed, <em>biodiversity—</em>the Amazon’s mixture of living things and ecosystems that exists nowhere else on earth—is threatened. Deforestation also has an impact on carbon emissions.<a contenteditable="false" data-primary="Web Time Series Service (WTSS)" data-type="indexterm" id="idm45433740845792"/></p>
<p>Web Time Series Service (WTSS) is a web service that processes time-series data gathered by remote sensing imagery.<sup><a data-type="noteref" href="ch10.xhtml#ch01fn14" id="ch01fn14-marker">1</a></sup> Again, you’ll be working with a 3D array with spatial (latitude and longitude) and temporal references. WTSS is a Python client library, so you can obtain a list of actual values recorded at a specific location over time.<a contenteditable="false" data-primary="WTSS" data-see="Web Time Series Service" data-type="indexterm" id="idm45433738972544"/></p>
<section data-pdf-bookmark="Setup" data-type="sect2"><div class="sect2" id="setup-id00009">
<h2>Setup</h2>
<p>In this exercise, you will explore data from a research project of Brazil’s National Institute for Space Research (INPE), <a href="https://oreil.ly/wZ1DD">Brazil Data Cube (BDC)</a>. <a contenteditable="false" data-primary="Brazil Data Cube (BDC)" data-type="indexterm" id="idm45433738975856"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example 2)" data-tertiary="setup" data-type="indexterm" id="idm45433738822976"/><a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-secondary="setup" data-type="indexterm" id="idm45433738821296"/>This data cube is a temporal composite from CBERS-4 and surface reflectance data from Advanced Wide Field Imager (AWFI), an instrument that captures high-resolution land and vegetation imagery.<a contenteditable="false" data-primary="BDC" data-see="Brazil Data Cube" data-type="indexterm" id="idm45433738819856"/></p>
<section data-pdf-bookmark="Obtaining the data" data-type="sect3"><div class="sect3" id="obtaining_the_data">
<h3>Obtaining the data</h3>
<p>Begin by registering at the website. <a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-secondary="setup" data-tertiary="obtaining the data" data-type="indexterm" id="idm45433738815920"/>You will need to create a profile, then generate and save an access token using the menu pictured in <a data-type="xref" href="#bdc_access_token">Figure 10-10</a>.</p>
<figure><div class="figure" id="bdc_access_token"><img alt="BDC access token" height="562" src="assets/pgda_1010.png" width="592"/>
<h6><span class="label">Figure 10-10. </span>BDC access token</h6>
</div></figure>
<p>The BDC project collects continuous data on land cover (an example is shown in <a data-type="xref" href="#brazil_data_cube">Figure 10-11</a>).<sup><a data-type="noteref" href="ch10.xhtml#ch01fn15" id="ch01fn15-marker">2</a></sup> To identify an area of interest, select the cube stack CBERS-4-AWFI within the CBB4_64_16D_STK-1 collection. The information icon (“i”) will provide background information.</p>
<figure><div class="figure" id="brazil_data_cube"><img alt="Brazil Data Cube" height="976" src="assets/pgda_1011.png" width="1209"/>
<h6><span class="label">Figure 10-11. </span>Brazil Data Cube</h6>
</div></figure>
<p>You’ll investigate if the vegetation density of the Amazon has changed over time by computing the NDVI, which you learned about in <a data-type="xref" href="ch06.xhtml#the_arcgis_python_api">Chapter 6</a>. <a contenteditable="false" data-primary="NDVI (Normalized Difference Vegetation Index)" data-secondary="investigating vegetation density of Amazon rain forest" data-type="indexterm" id="idm45433738824688"/>Recall that the NDVI calculates the difference between near-infrared (which is reflected by vegetation) and red light (absorbed by vegetation). These bands highlight vegetated areas and allow you to observe the density of vegetative growth. You will select a location in the Amazon rain forest within a region of dense vegetation. Enter the coordinates: latitude = –16.350000 and longitude = –56.666668.</p>
<div data-type="tip"><h6>Tip</h6>
<p>As you explore BDC on your own after finishing this exercise, try entering latitude and longitude coordinates of your own choosing. As an alternative, you can also use the bounding box (bbox) information to locate areas of interest.</p>
</div>
</div></section>
<section data-pdf-bookmark="Creating your environment" data-type="sect3"><div class="sect3" id="creating_your_environment-id00005">
<h3>Creating your environment</h3>
<p>Open a Jupyter Notebook<a contenteditable="false" data-primary="Jupyter Notebooks" data-secondary="installing libraries for deforestation and carbon emissions in Amazon rain forest study" data-type="indexterm" id="idm45433738904896"/> and <a contenteditable="false" data-primary="pip install" data-type="indexterm" id="idm45433738796240"/>install the <a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-secondary="setup" data-tertiary="creating your environment" data-type="indexterm" id="idm45433738795136"/>libraries using <code>pip install</code>. (I know, I know—I typically advocate for Conda installs, but the WTSS is only stable in pip. <a contenteditable="false" data-primary="Web Time Series Service (WTSS)" data-secondary="installing and setting up" data-type="indexterm" id="idm45433738791264"/>Often, we must adapt!)</p>
<pre data-type="programlisting">
!pip install wtss
<strong>from</strong> wtss <strong>import</strong> WTSS</pre>
<p>To access WTSS, use the link in the following code and the BDC access token you generated when creating <a contenteditable="false" data-primary="Brazil Data Cube (BDC)" data-secondary="access token, using to access WTSS" data-type="indexterm" id="idm45433738788384"/>your account:</p>
<pre data-type="programlisting">
<span>service = WTSS(</span>'https://brazildatacube.dpi.inpe.br/'<span>, 
    access_token=</span>'Your access token'<span>)</span></pre>
<p>Next, run:</p>
<pre data-type="programlisting">
service.coverages</pre>
<p>This outputs a list of services available at the link:</p>
<pre data-type="programlisting">
['LANDSAT-MOZ_30_1M_STK-1',
 'MOD13Q1-6',
 'LC8_30_6M_MEDSTK-1',
 'MYD13Q1-6',
 'S2-SEN2COR_10_16D_STK-1',
 'CB4_64_16D_STK-1',
 'LC8_30_16D_STK-1',
 'CB4MUX_20_1M_STK-1']</pre>
</div></section>
</div></section>
<section data-pdf-bookmark="Creating Your Map" data-type="sect2"><div class="sect2" id="creating_your_map">
<h2>Creating Your Map</h2>
<p>Select the CBERS coverage <a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example 2)" data-tertiary="creating your map" data-type="indexterm" id="ix_clmtdaex2crmap"/>for the<a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-secondary="creating your map" data-type="indexterm" id="ix_deforestcrmap"/> code cell:</p>
<pre data-type="programlisting">
cbers4_coverage = service[<span>'CB4_64_16D_STK-1'</span>]
cbers4_coverage</pre>
<p>The output (<a data-type="xref" href="#cbfour_sixfour_datacube_with_descriptio">Figure 10-12</a>) provides the attributes of the CB4_64 cube.</p>
<figure><div class="figure" id="cbfour_sixfour_datacube_with_descriptio"><img alt="CB4_64 datacube with description" height="379" src="assets/pgda_1012.png" width="983"/>
<h6><span class="label">Figure 10-12. </span>CB4_64 datacube with description</h6>
</div></figure>
<p>Notice how, when you assign variables, you use the name <em>exactly</em> as it appears in the table. We are interested in the near-infrared and red bands, so let’s assign variables for those:</p>
<pre data-type="programlisting">
red_band = <span>'BAND15'</span>
nir_band = <span>'BAND16'</span></pre>
<p>The time-series data for <a contenteditable="false" data-primary="time-series data" data-secondary="plotting for deforestation and carbon emissions for Amazon rain forest" data-type="indexterm" id="idm45433738769552"/>the location and dates listed is retrieved by the <code>ts</code> method:</p>
<pre data-type="programlisting">
time_series = cbers4_coverage.ts(attributes=(red_band, nir_band),
                                 latitude=<span>-16.350000</span>,
                                 longitude= <span>-56.666668</span> ,
                                 start_date=<span>"2016-01-01"</span>,
                                 end_date=<span>"2022-03-21"</span>)</pre>
<p>Plot the static visualization of the time series with the <code>plot</code> method:</p>
<pre data-type="programlisting">
time_series.plot()</pre>
<p>The output is pictured in <a data-type="xref" href="#static_visualization_of_cbfour_sixfour">Figure 10-13</a>.</p>
<figure><div class="figure" id="static_visualization_of_cbfour_sixfour"><img alt="Static visualization of CB4_64_16D_STK-1 data cube time series" height="690" src="assets/pgda_1013.png" width="875"/>
<h6><span class="label">Figure 10-13. </span>Static visualization of CB4_64_16D_STK-1 data cube time series</h6>
</div></figure>
</div></section>
<section data-pdf-bookmark="Analysis" data-type="sect2"><div class="sect2" id="analysis-id00003">
<h2>Analysis</h2>
<p>As you can see in <a data-type="xref" href="#static_visualization_of_cbfour_sixfour">Figure 10-13</a>, the NDVI in this area of the Amazonian rain forest trends upward between 2016 and 2022.<a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example 2)" data-startref="ix_clmtdaex2crmap" data-tertiary="creating your map" data-type="indexterm" id="idm45433738755456"/><a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-secondary="creating your map" data-startref="ix_deforestcrmap" data-type="indexterm" id="idm45433738754016"/><a contenteditable="false" data-primary="NDVI (Normalized Difference Vegetation Index)" data-secondary="trend for Amazon rain forest between 2016 and 2022" data-type="indexterm" id="idm45433738752864"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example 2)" data-tertiary="analysis" data-type="indexterm" id="idm45433738752000"/><a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-secondary="analysis" data-type="indexterm" id="idm45433738750432"/> This could suggest an increase in atmospheric carbon dioxide (CO<sub>2</sub>) levels, although precipitation and temperature are more important for explaining interannual NDVI variability. Indeed, ecosystem models suggest that most of the observed increase in the seasonal amplitude of atmospheric CO<sub>2</sub>, indicated by increasing plant growth over recent decades, is mostly due to CO<sub>2</sub> fertilization, with climate and land-use changes playing secondary roles. We can’t claim anything definitively based on this data, but the ability to capture surface reflectance and observe NDVI can help in generating hypotheses.<sup><a data-type="noteref" href="ch10.xhtml#ch01fn16" id="ch01fn16-marker">3</a></sup></p>
</div></section>
<section data-pdf-bookmark="Refinements" data-type="sect2"><div class="sect2" id="refinements">
<h2>Refinements</h2>
<p>Let’s look at a few more ways <a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example 2)" data-tertiary="refinements" data-type="indexterm" id="ix_clmtdaex2refine"/>to improve <a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-secondary="refinements" data-type="indexterm" id="ix_deforestrefine"/>this map.</p>
<section data-pdf-bookmark="Making your map interactive" data-type="sect3"><div class="sect3" id="making_your_map_interactive">
<h3>Making your map interactive</h3>
<p>Next, try creating an <a contenteditable="false" data-primary="pandas" data-secondary="using dataframe to create interactive map of findings in deforestation and carbon emissions study" data-type="indexterm" id="idm45433738734800"/>interactive display of your findings, using<a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-secondary="refinements" data-tertiary="making your map interactive" data-type="indexterm" id="idm45433738732688"/><a contenteditable="false" data-primary="interactive maps" data-type="indexterm" id="idm45433738731072"/> the<a contenteditable="false" data-primary="dataframes" data-secondary="using to create interactive display in deforestation study" data-type="indexterm" id="idm45433738979296"/> pandas dataframe:</p>
<pre data-type="programlisting">
cbers_df = pd.DataFrame({ <span>'BAND15'</span>: time_series.BAND15, 
<span>'BAND16'</span>: time_series.BAND16 }, 
                        index = pd.to_datetime(time_series.timeline))
cbers_df</pre>
<p>You can hover in the notebook to watch the information display (<a data-type="xref" href="#interactive_graphic_cbers_four">Figure 10-14</a>). Select different bands in different years for additional information.</p>
<figure><div class="figure" id="interactive_graphic_cbers_four"><img alt="Interactive graphic CBERS-4" height="404" src="assets/pgda_1014.png" width="812"/>
<h6><span class="label">Figure 10-14. </span>Interactive graphic CBERS-4</h6>
</div></figure>
<p><code>px.line()</code> is calling a plotly function. The <code>dataframe</code> parameter allows you to plot data. The <code>x</code> parameter specifies the variable on the <em>x</em>-axis, and the <code>y</code> parameter does the same for the <em>y</em>-axis. The title is described as well:</p>
<pre data-type="programlisting">
fig = px.line(cbers_df, x=cbers_df.index, y=[<span>'BAND15'</span>, <span>'BAND16'</span>], 
title=<span>'CBERS-4/AWFI (BAND 15 and 16)'</span>, labels={
    <span>'index'</span>: <span>'Date'</span>,
    <span>'value'</span>: <span>'Spectral Reflectance (scaled)'</span>
})

fig.update_xaxes(rangeslider_visible=<strong>True</strong>)
fig.show()</pre>
</div></section>
<section data-pdf-bookmark="Reducing cloud coverage with masking" data-type="sect3"><div class="sect3" id="reducing_cloud_coverage_with_masking">
<h3>Reducing cloud coverage with masking</h3>
<p>Satellite images <a contenteditable="false" data-primary="cloud coverage, reducing with masking" data-type="indexterm" id="idm45433738713296"/>observed in <a contenteditable="false" data-primary="masking" data-secondary="reducing cloud coverage with" data-type="indexterm" id="idm45433738712112"/>time series often <a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-secondary="refinements" data-tertiary="reducing cloud coverage with masking" data-type="indexterm" id="idm45433738710528"/>display noise or distortion from clouds, which can change the spectral behavior of the regions being analyzed. Clouds and their shadows can decrease reflectance.</p>
<p><em>Interpolation</em> is one way of replacing pixel values or points that have been distorted by cloud cover.<a contenteditable="false" data-primary="pixels" data-secondary="replacing pixel values distorted by cloud cover" data-type="indexterm" id="idm45433738705632"/><a contenteditable="false" data-primary="interpolation" data-type="indexterm" id="idm45433738704864"/><a contenteditable="false" data-primary="points distorted by cloud cover, replacing" data-type="indexterm" id="idm45433738704128"/> The process of interpolation constructs new data points within the range of discrete values of known data points. Data cubes contain <em>masks</em> that capture the influence of cloud cover, pixel by pixel.</p>
<div data-type="tip"><h6>Tip</h6>
<p>The Jupyter Notebook contains additional exercises working with masking and interpolation using BDC.</p>
</div>
<p>Remote sensing technology relies on cloud masking to process data imagery and improve its quality. Cloud masks let users identify cloudy and cloud-free pixels by analyzing the percentage of cloud in the mask.</p>
<p>The code in this section will walk you through first detecting clouds, then obtaining a mask to “hide” any low-quality data and prevent it from skewing the results.</p>
<p>When you run the code, it will output metadata with one of three values:</p>
<ul>
<li>
<p>A value of <code>0</code> means the pixel contains no data.</p>
</li>
<li>
<p>A value of <code>127</code> means the pixel is clear, with no clouds.</p>
</li>
<li>
<p>A value of <code>255</code> means the pixel is obscured by clouds.</p>
</li>
</ul>
<p class="pagebreak-before less_space">Let’s look at a slightly different location:</p>
<pre data-type="programlisting">
cb4_timeseries_cmask = cbers4_coverage.ts(

    attributes = (<span>'CMASK'</span>),

    latitude = <span>-12.0</span>,
    longitude = <span>-53.989</span>,

    start_date = <span>"2017-01-01"</span>,
    end_date = <span>"2021-12-31"</span>
)

cb4_timeseries_cmask</pre>
<p>This gives the output:</p>
<pre data-type="programlisting">
<strong>CMASK:</strong> [127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 
127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 
127.0, 127.0, 255.0, 127.0, 127.0, 127.0, 255.0, 127.0, 127.0, 127.0, 127.0, 
127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 
127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 
127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 
127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 255.0, 127.0, 127.0, 127.0, 
127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 
127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 255.0]</pre>
<p>You can see that most of the pixels are clear, but a few cloud observations record a value of <code>255.0</code>. The <code>set</code> function displays the values as well:</p>
<pre data-type="programlisting">
set(cb4_timeseries_cmask.values(<span>'CMASK'</span>))</pre>
<p>The output is <code>{127.0, 255.0}</code>.</p>
<p>The following code will display cloud observations over the time selected in the range:</p>
<pre data-type="programlisting">
cb4_timeseries = cbers4_coverage.ts(

    attributes = (<span>'NDVI'</span>, <span>'CMASK'</span>),

    latitude = <span>-12.0</span>,
    longitude = <span>-53.989</span>,

    start_date = <span>"2017-01-01"</span>,
    end_date = <span>"2019-12-31"</span>

)</pre>
<p>The timeline data is stored as a list of dates, but you <a contenteditable="false" data-primary="datetime object (Python)" data-secondary="transforming timeline data stores as list of dates to" data-type="indexterm" id="idm45433738680256"/>will need to transform it to a <code>datetime</code> object. <a contenteditable="false" data-primary="NDVI (Normalized Difference Vegetation Index)" data-secondary="timeline data stored as dates, transforming to datetime" data-type="indexterm" id="idm45433738681056"/>To do that, run the following code:</p>
<pre data-type="programlisting">
ndvi_timeline = pd.to_datetime(cb4_timeseries.timeline)
ndvi_timeline</pre>
<p>Now, you’ll <a contenteditable="false" data-primary="cmask_data variable" data-type="indexterm" id="idm45433738677200"/>store the transformed data in the variables <code>ndvi_data</code> and <code>cmask_data</code>:</p>
<pre data-type="programlisting">
<strong>import</strong> numpy <strong>as</strong> np

ndvi_data = np.array(cb4_timeseries.NDVI)
ndvi_data

cmask_data = np.array(cb4_timeseries.CMASK)
cmask_data</pre>
<p>The next step is to remove the clouds.  <a contenteditable="false" data-primary="NumPy" data-secondary="cmask_data for cloud coverage" data-type="indexterm" id="idm45433738672928"/>The NumPy array (<code>np</code>) will convert all <code>127</code> values (no clouds) to <code>1</code>, and the <code>255</code> (cloudy) values will now show as NaN (not a number):</p>
<pre data-type="programlisting">
cmask_data = np.where(cmask_data == <span>255</span>, np.nan, <span>1</span>)
cmask_data</pre>
<p>Now multiply the NaN values by the NDVI array<a contenteditable="false" data-primary="interpolation" data-secondary="using for time-series data" data-type="indexterm" id="idm45433738666800"/> to interpolate the time-series data:</p>
<pre data-type="programlisting">
ndvi_data * cmask_data</pre>
<p>This creates a new dataframe for the NaN values:</p>
<pre data-type="programlisting">
ndvi_masked_data = pd.DataFrame({ <span>'data'</span>: ndvi_data * cmask_data }, 
index = pd.to_datetime(ndvi_timeline))
ndvi_masked_data[ndvi_masked_data[<span>'data'</span>].isna()]</pre>
<p>And sure enough, when you run the code, there they are in the output (<a data-type="xref" href="#nan_values_in_interpolated_cloud_mask_d">Table 10-1</a>).</p>
<table class="border" id="nan_values_in_interpolated_cloud_mask_d">
<caption><span class="label">Table 10-1. </span>NaN values in interpolated cloud mask data</caption>
<tbody>
<tr>
<td>2018-01-01</td>
<td>NaN</td>
</tr>
<tr>
<td>2018-03-06</td>
<td>NaN</td>
</tr>
<tr>
<td>2020-02-18</td>
<td>NaN</td>
</tr>
<tr>
<td>2021-03-06</td>
<td>NaN</td>
</tr>
</tbody>
</table>
<p>Now we can pull out all of the NaN data and view the interpolated data:</p>
<pre data-type="programlisting">
ndvi_masked_data_interpolated = ndvi_masked_data.interpolate()
ndvi_masked_data_interpolated[ndvi_masked_data_interpolated[<span>'data'</span>].isna()]</pre>
<p>Let’s visualize the interpolated data! Run this code:</p>
<pre data-type="programlisting">
plt.figure(dpi = <span>120</span>)

plt.plot(ndvi_data, color=<span>'gray'</span>, linestyle=<span>'dashed'</span>, label = <span>'Original'</span>)
plt.plot(ndvi_masked_data_interpolated[<span>'data'</span>].values, color=<span>'blue'</span>, 
label = <span>'Interpolated'</span>)

plt.title(<span>'Comparison of Time Series with and without interpolation'</span>)
plt.legend()
plt.grid(<strong>True</strong>)
plt.show()</pre>
<p>Your output should look like <a data-type="xref" href="#comparison_of_the_time_series_data_afte">Figure 10-15</a>. Removing the cloud observations yields unobstructed values of the pixels and the surface reflectance to more accurately depict the vegetation density.</p>
<figure><div class="figure" id="comparison_of_the_time_series_data_afte"><img alt="Comparison of the time-series data after interpolating" height="639" src="assets/pgda_1015.png" width="843"/>
<h6><span class="label">Figure 10-15. </span>Comparison of the time-series data after interpolating</h6>
</div></figure>
<p>This<a contenteditable="false" data-primary="time-series data" data-secondary="comparison after interpolating" data-type="indexterm" id="idm45433738642736"/> exercise showed you how to use WTSS to access and analyze remote sensing data with Python and APIs and introduced you to the BDC resource. You also saw that data analysis isn’t just for backing up your arguments; in fact, exploring data with these tools can be an important part of the process of <em>generating</em> a hypothesis and can lead your inquiries to new and unexpected places.<a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-secondary="refinements" data-startref="ix_deforestrefine" data-type="indexterm" id="idm45433739045456"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example 2)" data-startref="ix_clmtdaex2refine" data-tertiary="refinements" data-type="indexterm" id="idm45433738638432"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example 2)" data-startref="ix_clmtdaex2" data-type="indexterm" id="idm45433738636480"/><a contenteditable="false" data-primary="deforestation and carbon emissions in Amazon rain forest using WTSS series (example)" data-startref="ix_deforest" data-type="indexterm" id="idm45433738634800"/></p>
</div></section>
</div></section>
</div></section>
<section data-pdf-bookmark="Example 3: Modeling and Forecasting Deforestation in Guadeloupe with Forest at Risk" data-type="sect1"><div class="sect1" id="example_three_modeling_and_forecasting">
<h1>Example 3: Modeling and Forecasting Deforestation in Guadeloupe with Forest at Risk</h1>
<p>Beyond the benefit of modeling the spatial probability of deforestation, this final section is a great example of modeling large georeferenced raster files.<a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-type="indexterm" id="ix_clmtdaex3"/><a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-type="indexterm" id="ix_FAR"/><a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-type="indexterm" id="ix_deforestGuad"/> We will be working with a Python package that analyzes deforestation: <a href="https://oreil.ly/2MLdk">Forest at Risk (FAR)</a>. The functions in this package process blocks of data modeled over large geographic scales at a high resolution.</p>
<p class="pagebreak-before less_space">The area of interest is Guadeloupe, an archipelago and overseas department of France located in the eastern Caribbean Sea. According to Global Forest Watch, more than 240 acres of Guadeloupe’s humid primary forest have been lost in 2021 alone. Tree-cover loss was responsible for about 1.07 metric tons (2,358.95 pounds) of CO<sub>2</sub> emissions.</p>
<p>The goal of working with FAR is to model Guadeloupe’s deforestation spatially, predict the risk of deforestation based on a set of variables, and forecast future forest density. The spatial variables you’ll be working with include topography (altitude, slope, and aspect), accessibility (distance to roads, towns, and the forest edge), and distance to previous areas of deforestation or protected areas.</p>
<p>Any statistical model class with a <code>.predict()</code> method can potentially be used with the function <code>forestatrisk.predict_raster()</code> to predict the spatial risk of deforestation. <a contenteditable="false" data-primary="forestatrisk.predict_raster function" data-type="indexterm" id="idm45433739036176"/>Performing computations on arrays using NumPy and GDAL increases efficiency without the need for high computational power. You’ll use this data to define the geographic area and to measure deforestation, forest degradation, and forest regrowth. Let’s see if we can visualize the change in surface reflectance and underlying tree cover by relying on geospatial tools.</p>
<p>We’ll be using <a contenteditable="false" data-primary="Forest Resources and Carbon Emissions (IFORCE) data" data-type="indexterm" id="idm45433740703024"/>data from International <a contenteditable="false" data-primary="IFORCE (International Forest Resources and Carbon Emissions) data" data-type="indexterm" id="idm45433738800592"/>Forest Resources and Carbon Emissions (IFORCE), part of the European Commission’s Joint Research Center, which is responsible for independent scientific and technical support. This data measures Landsat time-series forest-cover change in tropical moist forests (TMFs). It was gathered from seasonal rain forests at increasing distance from the equator over 30 years, from 1990 to 2020.</p>
<section data-pdf-bookmark="Setup" data-type="sect2"><div class="sect2" id="setup-id00010">
<h2>Setup</h2>
<p>Although I am working with Google Colab in this example, there<a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-tertiary="setup" data-type="indexterm" id="ix_clmtdaex3setup"/> were <a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="setup" data-type="indexterm" id="ix_deforestGUADset"/>challenges with reproducibility, and I found creating a Conda environment to be a more stable option. The dashboard in <a data-type="xref" href="#opening_the_far_dataset_in_google_colab">Figure 10-16</a> shows the output files that will not show up in your notebook automatically. Select them from the file hierarchy in Colab <a contenteditable="false" data-primary="Colab" data-secondary="opening FAR dataset in Colab Pro" data-type="indexterm" id="idm45433738594960"/>or from your Jupyter Notebook file structure.</p>
<figure><div class="figure" id="opening_the_far_dataset_in_google_colab"><img alt="Opening the FAR dataset in Google Colab Pro" height="958" src="assets/pgda_1016.png" width="1920"/>
<h6><span class="label">Figure 10-16. </span>Opening the FAR dataset in Google Colab Pro</h6>
</div></figure>
<p>Depending on your individual setup, Google Colab usually runs quite well. I default to Colab when instructing because it is straightforward in highlighting the folder structure within your Google Drive (or the import paths, if you choose to upload files). There are occasions when you might not be able to get this to work. In those instances, I have found creating an environment in the terminal to be the solution.</p>
<section data-pdf-bookmark="Creating your environment" data-type="sect3"><div class="sect3" id="creating_your_environment-id00006">
<h3>Creating your environment</h3>
<p>I am using Python 3.10, which as of<a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="setup" data-tertiary="creating your environment" data-type="indexterm" id="idm45433738591056"/> this writing is the current version, but you’ll enter your own version when you run the following code. <a contenteditable="false" data-primary="Conda environment, creating" data-secondary="for deforestation in Guadeloupe study" data-secondary-sortas="deforestation" data-type="indexterm" id="idm45433738585808"/>Everything should work, but note that when you build environments and adjust versioning, the details might need a little fine-tuning. (You are far enough along in your Python journey to be familiar with a few of these options, but return to the preface if you need a reminder.)</p>
<p>Now you can create your environment using Conda:</p>
<pre data-type="programlisting">
<span>conda create --name conda-far -c conda-forge python<span>=</span><span>3</span>.7 gdal numpy matplotlib 
pandas patsy pip statsmodels earthengine-api --yes
conda activate conda-far</span>
pip install pywdpa sklearn # Packages not available with conda
pip install forestatrisk # For PyPI version
<span>conda install -c conda-forge python-dotenv rclone</span></pre>
<div data-type="tip"><h6>Tip</h6>
<p>If you get an error message that forestatrisk is not recognized, you can create a kernel <a contenteditable="false" data-primary="kernel" data-secondary="creating inside FAR environment in the terminal" data-type="indexterm" id="idm45433738579184"/>inside your FAR environment in the terminal:</p>
<pre data-type="programlisting">
conda install ipykernel</pre>
<pre data-type="programlisting">
python -m ipykernel install --user --name myenv 
--display-name "FAR"</pre>
<p>Enter <code><strong>jupyter notebook</strong></code> and select the FAR kernel. Your package should now run.</p>
</div>
</div></section>
<section data-pdf-bookmark="Downloading and importing packages" data-type="sect3"><div class="sect3" id="downloading_and_importing_packages">
<h3>Downloading and importing packages</h3>
<p>Importing the necessary files and packages is the first step. <a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="setup" data-tertiary="downloading and importing packages" data-type="indexterm" id="idm45433738574656"/>The <code>os</code> module allows you to interact with folders on your operating system. <a contenteditable="false" data-primary="os module" data-type="indexterm" id="idm45433738570864"/>The shutil <a contenteditable="false" data-primary="shutil package" data-type="indexterm" id="idm45433738571392"/>and copy2 packages preserve <a contenteditable="false" data-primary="metadata" data-secondary="preserving in imported files" data-type="indexterm" id="idm45433738569200"/>the metadata of the files you are importing, including permissions. (There are limits to this when working on MacOS, so consult the <a href="https://oreil.ly/cJTAA">Python documentation</a>.) The urllib package collects several modules for opening and reading URLs. <a contenteditable="false" data-primary="urllib package" data-type="indexterm" id="idm45433738565856"/>You’ll also be working with ZIP files, and the <code>ZipFile</code> module provides the necessary tools.<a contenteditable="false" data-primary="ZipFile module" data-type="indexterm" id="idm45433738564752"/></p>
<p>Go ahead and import your packages:</p>
<pre data-type="programlisting">
# Imports
import<span> os</span>
<strong><span>from</span></strong> shutil <strong><span>import</span></strong> copy2
<strong><span>import</span></strong> urllib.request
<strong><span>from</span></strong> zipfile <strong><span>import</span></strong> ZipFile

<strong><span>import</span></strong> forestatrisk <strong><span>as</span></strong> far

<strong>import</strong> numpy <strong>as</strong> np
<strong>import</strong> matplotlib.pyplot <strong>as</strong> plt
<strong>import</strong> pandas <strong>as</strong> pd
<strong>from</strong> patsy <strong>import</strong> dmatrices
<strong>import</strong> pickle
<strong>from</strong> sklearn.linear_model <strong>import</strong> LogisticRegression
<strong>from</strong> sklearn.ensemble <strong>import</strong> RandomForestClassifier
<strong>from</strong> sklearn.metrics <strong>import</strong> log_loss</pre>
</div></section>
<section data-pdf-bookmark="Downloading and importing the data" data-type="sect3"><div class="sect3" id="downloading_and_importing_the_data">
<h3>Downloading and importing the data</h3>
<p>Next you’ll create an output directory, which is especially convenient when working in a notebook environment. <a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="setup" data-tertiary="downloading and importing the data" data-type="indexterm" id="idm45433738548832"/>When you run your scripts, the output files will be in this designated location, including the figures you are generating:</p>
<pre data-type="programlisting">
# Make output directory
far<span>.</span>make_dir<strong>(</strong><span>"output"</span><strong>)</strong></pre>
<p class="pagebreak-before less_space">The ZIP file <em>data_GLP.zip</em> is located at the link in the following code block, and <code>z.extractall</code> will unzip the file into your Colab or Jupyter Notebook directory, as shown in <a data-type="xref" href="#static_visualization_of_cbfour_sixfour">Figure 10-13</a>:</p>
<pre data-type="programlisting">
# Source of the data
<span>url</span> <span>=</span> "https://github.com/ghislainv/forestatrisk/raw/master/docsrc/notebooks/
data_GLP.zip"

<strong><span>if</span></strong> os<span>.</span>path<span>.</span>exists<strong>(</strong><span>"data_GLP.zip"</span><strong>) <span>is</span> <span>False</span>:</strong>
    urllib<span>.</span>request<span>.</span>urlretrieve<strong>(</strong>url<strong>,</strong> <span>"data_GLP.zip"</span><strong>)</strong>

<strong><span>with</span></strong><span> ZipFile<strong>(</strong></span>"data_GLP.zip"<strong><span>,</span></strong> "r"<strong><span>)</span></strong> <strong><span>as</span></strong><span> z<strong>:</strong></span>
    z<span>.</span>extractall<strong>(</strong><span>"data"</span><strong>)</strong></pre>
<p>The <em>.zip</em> file contains a selection of environmental variables and maps from across a timespan: all of the data you will need for this brief walk through the FAR tutorial, in which you will model the spatial probability of deforestation in a specific geography.</p>
<p>As you <a href="https://oreil.ly/lkzTB">download the data</a>, take a few moments to explore the details regarding symbology, values, and labels on the <a href="https://oreil.ly/wtHAi">IFORCE</a> site.<a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="setup" data-startref="ix_deforestGUADset" data-type="indexterm" id="idm45433738529472"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-startref="ix_clmtdaex3setup" data-tertiary="setup" data-type="indexterm" id="idm45433738525536"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Plotting the Data" data-type="sect2"><div class="sect2" id="plotting_the_data">
<h2>Plotting the Data</h2>
<p>Run the following <a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-tertiary="plotting the data" data-type="indexterm" id="idm45433738521840"/>code to <a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="plotting the data" data-type="indexterm" id="idm45433738520032"/>plot <a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-tertiary="plotting the data" data-type="indexterm" id="idm45433738518432"/>the data:</p>
<pre data-type="programlisting">
<span># Plot forest</span>
fig_fcc23 = far.plot.fcc(
    input_fcc_raster=<span>"data/fcc23.tif"</span>,
    maxpixels=<span>1e8</span>,
    output_file=<span>"output/fcc23.png"</span>,
    borders=<span>"data/ctry_PROJ.shp"</span>,
    linewidth=<span>0.3</span>, dpi=<span>500</span>)</pre>
<p>When you run the code cell, this code will generate a map as output, but it will not populate in the notebook automatically. To find the output files in Google Colab, use the dashboard to navigate through the folder hierarchy to your output folder. In a Jupyter Notebook, review the files listed in the tab at the top left corner (<a data-type="xref" href="#locating_your_output_in_the_jupyter_not">Figure 10-17</a>). The data files you downloaded will also be visible.</p>
<figure class="width-80"><div class="figure" id="locating_your_output_in_the_jupyter_not"><img height="745" src="assets/pgda_1017.png" width="1434"/>
<h6><span class="label">Figure 10-17. </span>Locating your output in the Jupyter Notebook file structure</h6>
</div></figure>
<p>When you plot the data (<a data-type="xref" href="#plotting_far_data_on_forest_cover_chang">Figure 10-18</a>), the forest appears as green and the deforested areas as red. <a contenteditable="false" data-primary="raster data" data-secondary="FAR data as GeoTiff raster file" data-type="indexterm" id="idm45433738505872"/>Can you see the perimeter where deforestation is more likely?</p>
<figure class="width-80"><div class="figure" id="plotting_far_data_on_forest_cover_chang"><img height="4084" src="assets/pgda_1018.png" width="4599"/>
<h6><span class="label">Figure 10-18. </span>Plotting FAR data on forest cover change in Guadeloupe as a GeoTiff raster file</h6>
</div></figure>
</div></section>
<section data-pdf-bookmark="Sampling the Data" data-type="sect2"><div class="sect2" id="sampling_the_data">
<h2>Sampling the Data</h2>
<p>Next, it’s time to sample your data.<a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="sampling the data" data-type="indexterm" id="ix_deforestGuadsmplda"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-tertiary="sampling the data" data-type="indexterm" id="ix_clmtdaex3smplda"/><a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-tertiary="sampling the data" data-type="indexterm" id="ix_FARsmplda"/><a contenteditable="false" data-primary="far.sample function" data-type="indexterm" id="idm45433738495728"/> You’ll use the function <code>far.sample</code>. The help documentation, which you can access by running <code>help(far.sample)</code>, tells us that this function “randomly draws spatial points in deforested and forested areas and…extract[s] environmental variable values for each spatial point.” In other words, it samples 10,000 randomly selected pixel centers (points) in the areas identified as either deforested or as remaining forest.</p>
<p>Let’s take a moment to look at the arguments this function takes. First, <code>seed</code> tells the function to reproduce the random sampling data from the previous step. Next, the spatial cells for each sample are grouped by the <code>csize</code> argument. Each spatial cell is attributed to a parameter, so they need to be of a sufficient size to ease the burden of memory and large datasets. These grouped observations are estimates of spatial autocorrelation in deforestation.<a contenteditable="false" data-primary="Tobler’s First Law of Geography" data-type="indexterm" id="idm45433738493648"/></p>
<p>Remember Tobler’s First Law, introduced in <a data-type="xref" href="ch01.xhtml#introduction_to_geospatial_analytics">Chapter 1</a>: “Everything is related to everything else, but near things are more related than distant things.” <em>Spatial autocorrelation</em> is a measure of <a contenteditable="false" data-primary="spatial autocorrelation" data-type="indexterm" id="idm45433738482048"/>spatial variation within adjacent observations where it is possible for near things to not be similar! Adjacent observations can have similar values (positive spatial autocorrelation) or have contrasting values (negative autocorrelation). The presence or absence of a pixel value between measurements has important implications for spatial statistics. There are many reasons why this might be the case, but one could be that a small sample from a much larger dataset simply isn’t representative of the larger sample.</p>
<p>In the following code cell, you’ll also see the argument <code>var_dir</code>. This points to the directory where all of the GeoTIFF files are located and to <em>fcc23.tif</em> as a forest-cover-change raster file. Once more, pay attention to the output file and notice it appearing in your directory:</p>
<pre data-type="programlisting">
# Sample points
dataset <span>=</span> far<span>.</span>sample<strong>(</strong>nsamp<span>=</span><span>10000</span><strong>,</strong> adapt<span>=</span><strong><span>True</span>,</strong> seed<span>=</span><span>1234</span><strong>,</strong> csize<span>=</span><span>10</span><strong>,</strong>
                     var_dir<span>=</span><span>"data"</span><strong>,</strong>
                     input_forest_raster<span>=</span><span>"fcc23.tif"</span><strong>,</strong>
                     output_file<span>=</span><span>"output/sample.txt"</span><strong>,</strong>
                     blk_rows<span>=</span><span>0</span><strong>)</strong></pre>
<p>I’m showing you the output here to demonstrate how the calculations are conducted:</p>
<pre data-type="programlisting">
Sample 2x 10000 pixels (deforested vs. forest)
Divide region in 168 blocks
Compute number of deforested and forest pixels per block
100%
Draw blocks at random
Draw pixels at random in blocks
100%
Compute center of pixel coordinates
Compute number of 10 x 10 km spatial cells
... 99 cells (9 x 11)
Identify cell number from XY coordinates
Make virtual raster with variables as raster bands
Extract raster values for selected pixels
100%
Export results to file output/sample.txt</pre>
<p>The following code removes “not available” (NA) values from the dataset, then computes the number of neighbors of each spatial cell. It outputs a pandas dataframe:</p>
<pre data-type="programlisting">
<span># Remove NA from dataset </span>
dataset <span><span>=</span> dataset<span>.</span>dropna<strong>(</strong>axis<span>=</span><span>0</span><strong>)</strong>
# Set number of trials to one for far.model_binomial_iCAR()
dataset<strong>[</strong><span>"trial"</span><strong>]</strong> <span>=</span> <span>1</span>
# Print the first five rows
<span>print</span><strong>(</strong>dataset<span>.</span>head<strong>(</strong><span>5</span><strong>))</strong></span></pre>
<p>If you do not remove the NAs, you won’t be able to model the data in the next steps—recall that the logistic regression model is reporting on the presence or absence of a pixel value between measurements.</p>
<p>The output shown here is a sample of the first five rows. The variables represent the spatial explanatory variables used to model the impact of deforestation and include topography represented by altitude and slope; accessibility, measured as distance to nearest road, town, river, and forest edge; deforestation history, calculated as distance to past deforestation; and land conservation status as a protected area (<code>pa</code>):</p>
<pre data-type="programlisting">
altitude  dist_defor  dist_edge  dist_river  dist_road  dist_town  fcc23  \
0      30.0       642.0       30.0      8448.0     1485.0     6364.0    0.0   
1      37.0       765.0       30.0      8583.0     1697.0     6576.0    0.0   
2      78.0       216.0       30.0      7722.0      949.0     5743.0    0.0   
3      80.0       277.0       30.0      8168.0     1172.0     6047.0    0.0   
4      46.0        30.0       30.0      6179.0      541.0     6690.0    0.0   

    pa  slope          X          Y               cell  trial  
0  0.0    8.0 -6842295.0  1851975.0   4.0      1  
1  0.0    7.0 -6842235.0  1852095.0   4.0      1  
2  0.0    5.0 -6842535.0  1851195.0   4.0      1  
3  0.0    2.0 -6842445.0  1851615.0   4.0      1  
4  0.0    1.0 -6840465.0  1849755.0   4.0      1 </pre>
<p>Sample-size calculations for forest cover change the map—the pixel value is set to <code>1</code> when there is forest and to <code>0</code> when there is no forest:</p>
<pre data-type="programlisting">
<span># Sample size</span>
ndefor = sum(dataset.fcc23 == <span>0</span>)
nfor = sum(dataset.fcc23 == <span>1</span>)
<strong>with</strong> open(<span>"output/sample_size.csv"</span>, <span>"w"</span>) <strong>as</strong> f:
    f.write(<span>"var, n\n"</span>)
    f.write(<span>"ndefor, "</span> + str(ndefor) + <span>"\n"</span>)
    f.write(<span>"nfor, "</span> + str(nfor) + <span>"\n"</span>)
print(<span>"ndefor = {}, nfor = {}"</span>.format(ndefor, nfor))</pre>
</div></section>
<section data-pdf-bookmark="Correlation Plots" data-type="sect2"><div class="sect2" id="correlation_plots">
<h2>Correlation Plots</h2>
<p>The next step is to correlate all this data.<a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="sampling the data" data-startref="ix_deforestGuadsmplda" data-type="indexterm" id="idm45433738447568"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-startref="ix_clmtdaex3smplda" data-tertiary="sampling the data" data-type="indexterm" id="idm45433738445632"/><a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-startref="ix_FARsmplda" data-tertiary="sampling the data" data-type="indexterm" id="idm45433738443648"/> This means actually comparing the locations of forested areas with the other variables, such as roads, rivers, towns, and other deforested areas, to plot how likely it is that the point in question will be deforested.<a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="correlation plots" data-type="indexterm" id="ix_deforestGuadcorr"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-tertiary="correlation plots" data-type="indexterm" id="ix_clmtdaex3corr"/><a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-tertiary="correlation plots" data-type="indexterm" id="ix_FARcorrplt"/><a contenteditable="false" data-primary="correlation plots" data-type="indexterm" id="ix_corrplt"/></p>
<p>Run the code to correlate and then plot the result:</p>
<pre data-type="programlisting">
<span># Correlation formula</span><span>
formula_corr =</span> "fcc23 ~ dist_road + dist_town + dist_river + \
dist_defor + dist_edge + altitude + slope - 1"<span>
</span>
<span># Output file</span><span>
of =</span> "output/correlation.pdf"
<span># Data</span><span>
y, data = dmatrices(formula_corr, data=dataset,
                    return_type=</span>"dataframe"<span>)</span>
<span># Plots</span><span>
figs = far.plot.correlation(
    y=y, data=data,
    plots_per_page=</span>3<span>,
    figsize=(</span>7<span>,</span> 8<span>),
    dpi=</span>80<span>,
    output_file=of)</span></pre>
<p>This outputs the <em>correlation plots</em> shown in <a data-type="xref" href="#correlation_plots_of_selected_variables">Figure 10-19</a>.</p>
<p>You can read the probability of deforestation by looking first at the distribution of the data. Notice the shape of the probability curve. Look at how far the distance a pixel is from a deforested state. In <a data-type="xref" href="#opening_the_far_dataset_in_google_colab">Figure 10-16</a>, you can see that the bulk of pixels in the sample are relatively close to a deforested area already—and, as you know, as the distance increases, the probability of deforestation declines.</p>
<p>Looking at the parameter estimates in <a data-type="xref" href="#correlation_plots_of_selected_variables">Figure 10-19</a>, you can see that the probability of deforestation decreases with altitude, slope, distance to past deforestation, and forest edge. The distances to road, town, and river all “cross zero,” meaning that the values are not significantly different from zero. The confidence interval range includes zero.<a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="correlation plots" data-startref="ix_deforestGuadcorr" data-type="indexterm" id="idm45433738818160"/><a contenteditable="false" data-primary="correlation plots" data-startref="ix_corrplt" data-type="indexterm" id="idm45433738640848"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-startref="ix_clmtdaex3corr" data-tertiary="correlation plots" data-type="indexterm" id="idm45433738639472"/><a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-startref="ix_FARcorrplt" data-tertiary="correlation plots" data-type="indexterm" id="idm45433738421040"/></p>
<figure><div class="figure" id="correlation_plots_of_selected_variables"><img alt="Correlation plots of selected variables" height="1257" src="assets/pgda_1019.png" width="446"/>
<h6><span class="label">Figure 10-19. </span>Correlation plots of selected variables</h6>
</div></figure>
</div></section>
<section data-pdf-bookmark="Modeling the Probability of Deforestation with the iCAR Model" data-type="sect2"><div class="sect2" id="modeling_the_probability_of_deforestati">
<h2>Modeling the Probability of Deforestation with the iCAR Model</h2>
<p>You won’t need to understand the underlying statistics to be able to render the output. <a contenteditable="false" data-primary="iCAR (Intrinsic Conditional Auto-Regressive) model, modeling probability of deforestation with" data-type="indexterm" id="idm45433738413568"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-tertiary="modeling deforestation probability with iCAR model" data-type="indexterm" id="idm45433738412672"/><a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="modeling probability of deforestation with iCAR model" data-type="indexterm" id="idm45433738411584"/>The statistical model <code>model_binomial_iCAR</code> estimates the probability of deforestation by examining each pixel and evaluating a set of environmental variables like altitude, distance to edge of forest, distance to road, and distance to the nearest towns.<a contenteditable="false" data-primary="model_binomial_iCAR statistical model" data-type="indexterm" id="idm45433738410240"/> These variables tell us how accessible the forest is to humans. In simple terms, we need this data because fixed environmental variables don’t completely explain the process of deforestation, at least not at large scales like a country or geographic region.</p>
<p>The probability of deforestation at any given point depends on the probability of deforestation in its neighboring cells. Nearest-neighbor methods look for training samples near a given point to indicate the number of adjacent entities. In short, it is observing patterns in the data and using them to predict new observations.</p>
<p>The statistics behind many of the methods used in this example, such as Markov Chain Monte Carlo (MCMC) methods, involve advanced concepts beyond the focus of this book, but if you’re interested in learning more, see the <a data-type="xref" href="app01.xhtml#appendix">Appendix</a>.</p>
<p>For those who know some <a contenteditable="false" data-primary="Intrinsic Conditional Auto-Regressive (iCAR) model, modeling probability of deforestation with" data-type="indexterm" id="idm45433742769264"/>statistics, briefly, the Intrinsic Conditional Auto-Regressive (iCAR) model allows estimations of varying probability of deforestation regardless of the nature of immeasurability. For example, it is impossible to measure each individual tree and its impact on the tree cover. We use a logistic regression model of a binary outcome: 1 if a forest pixel is deforested (fewer pixels) and 0 if it is not.</p>
<p>Run the code in the notebook if you are interested in the model preparation or variable selection models. The deep statistical tangent is out of the scope of this book, but understanding the process is quite interesting.<sup><a data-type="noteref" href="ch10.xhtml#ch01fn17" id="ch01fn17-marker">4</a></sup></p>
<p>Let’s look at the model summary:</p>
<pre data-type="programlisting">
Binomial logistic regression with iCAR process
  Model: I(1 - fcc23) + trial ~ 1 + scale(altitude) + scale(slope) 
  + scale(dist_defor) + scale(dist_edge) + scale(dist_road) + scale(dist_town) 
  + scale(dist_river) + cell
  Posteriors:
                        Mean        Std     CI_low    CI_high
        Intercept      -3.84      0.224      -4.23      -3.27
  scale(altitude)       -0.5      0.105     -0.679     -0.293
     scale(slope)    -0.0159     0.0545     -0.117     0.0906
scale(dist_defor)      -2.06      0.274      -2.51      -1.51
 scale(dist_edge)      -6.89       0.44      -7.78       -6.2
 scale(dist_road)    -0.0408     0.0573     -0.159     0.0702
 scale(dist_town)    -0.0916     0.0444     -0.175     0.0032
scale(dist_river)    -0.0122     0.0347    -0.0838     0.0607
             Vrho       3.12      0.852       1.83       5.07
         Deviance   1.52e+04         48   1.52e+04   1.54e+04</pre>
<p>What you are observing is that when the coefficient is negative, the variable has a negative effect on what you are measuring. For example, the likelihood of deforestation is higher when the distance from the road is smaller.</p>
</div></section>
<section data-pdf-bookmark="The MCMC Distance Matrix" data-type="sect2"><div class="sect2" id="the_mcmc_distance_matrix">
<h2>The MCMC Distance Matrix</h2>
<p>First, we sample the data, then we prepare, run, and test the model. <a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-tertiary="MCMC Distance Matrix" data-type="indexterm" id="idm45433738397728"/><a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="MCMC Distance Matrix" data-type="indexterm" id="idm45433738396176"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-tertiary="MCMC Distance Matrix" data-type="indexterm" id="idm45433738394832"/><a contenteditable="false" data-primary="MCMC Distance Matrix" data-type="indexterm" id="idm45433738393248"/>The model is summarized in <a data-type="xref" href="#mcmc_traces">Figure 10-20</a>. The statistics behind many of the methods are advanced concepts beyond the focus of this book but are highlighted in the article “Spatial Scenario
of Tropical Deforestation and Carbon Emissions for the 21st Century” by Ghislain Vieilledent et al. Briefly, MCMC methods are used in Bayesian inference and are based on techniques used to generate random sampling sequences to approximate a probability distribution.</p>
<p>MCMC tools, in brief, verify if an algorithm-generated sample is sufficient to serve as an approximation of the at-large distribution. Is your sample size large enough? To simplify a discussion on traces and posteriors, MCMC draws samples from posterior distributions, summaries of uncertainty that you can update based on new information. In a nutshell, once you see the data, you are likely to update your knowledge.</p>
<p>The main purpose is to make sure that the effective size of your sample is not too small and that the samples are similar to the target population. Compare the trace to the shape of the sample histograms to the normal distributions in <a data-type="xref" href="#mcmc_traces">Figure 10-20</a>. Do you notice any potential skew?</p>
</div></section>
<figure><div class="figure" id="mcmc_traces"><img alt="MCMC traces" height="1234" src="assets/pgda_1020.png" width="1188"/>
<h6><span class="label">Figure 10-20. </span>MCMC traces</h6>
</div></figure>
<section data-pdf-bookmark="Modeling Deforestation Probability with predict_raster_binomial_iCAR" data-type="sect2"><div class="sect2" id="modeling_deforestation_probability_with">
<h2>Modeling Deforestation Probability with predict_raster_binomial_iCAR</h2>
<p>Using <code>predict_raster_binomial_iCAR</code>, you can predict the spatial probability of deforestation from the <code>model_binomial_iCAR</code> model by computing block by block over large geographical areas. <a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-tertiary="modeling deforestation probability with predict_raster_binomial_iCAR" data-type="indexterm" id="idm45433738376176"/><a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-tertiary="modeling deforestation probability with predict_raster_binomial_iCAR" data-type="indexterm" id="idm45433738374528"/><a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="modeling deforestation probability with predict_raster_binomial_iCAR" data-type="indexterm" id="idm45433738372944"/><a contenteditable="false" data-primary="predict_raster_binomial_iCAR" data-type="indexterm" id="idm45433738371632"/>Selecting just 10 rows should help limit memory drain.</p>
<p>Run the code in the notebooks, and let’s look at the generated graphics here.</p>
<p>The output shown in <a data-type="xref" href="#probability_tiff">Figure 10-21</a> shows deforested areas as white and forested areas as black.</p>
<figure><div class="figure" id="probability_tiff"><img alt="Probability TIFF" height="1780" src="assets/pgda_1021.png" width="2020"/>
<h6><span class="label">Figure 10-21. </span>Probability TIFF</h6>
</div></figure>
<p>This model predicts that annual deforestation between 2010 and 2020 was 498.375 hectares per year. For comparison, that is the equivalent of more than 11,000 NBA basketball courts or 930 football fields (including the endzones). The notebook includes code to analyze predictions for future forest-cover change. <a data-type="xref" href="#forest_cover_changecomma_twozerozerozer">Figure 10-22</a> shows historical forest-cover change for the period between 2000 and 2020.</p>
<p>Modeling data and generating probabilities and projections are powerful tools for open source communities tasked with monitoring the threat to our rain forests and the deleterious downstream impact on our ecosystems and climate. Run the code to try modeling the data forward to 2050 and 2100:</p>
<pre data-type="programlisting">
# Projected forest cover change (2020-2050)
fcc_2050 <span>=</span> far<span>.</span>plot<span>.</span>fcc<strong>(</strong><span>"output/fcc_2050.tif"</span><strong>,</strong>
                        maxpixels<span>=</span><span>1e8</span><strong>,</strong>
                        borders<span>=</span><span>"data/ctry_PROJ.shp"</span><strong>,</strong>
                        linewidth<span>=</span><span>0.2</span><strong>,</strong>
                        output_file<span>=</span><span>"output/fcc_2050.png"</span><strong>,</strong>
                        figsize<span>=</span><strong>(</strong><span>5</span><strong>,</strong> <span>4</span><strong>),</strong> dpi<span>=</span><span>800</span><strong>)</strong></pre>
<figure><div class="figure" id="forest_cover_changecomma_twozerozerozer"><img alt="Forest-cover change, 2000, 2010, and 2020" height="1616" src="assets/pgda_1022.png" width="1852"/>
<h6><span class="label">Figure 10-22. </span>Forest-cover change, 2000, 2010, and 2020</h6>
</div></figure>
<p>The output is shown in <a data-type="xref" href="#future_forest_covercomma_twozerofivezer">Figure 10-23</a>:</p>
<pre data-type="programlisting">
// Palette for fcc_2050 and fcc_2100
var pal_fcc_proj = [
rgb(227, 26, 28), // 0. Deforestation, red
rgb(34, 139, 34), // 1. Remaining forest, green
];</pre>
<figure><div class="figure" id="future_forest_covercomma_twozerofivezer"><img alt="Future forest cover, 2050" height="1616" src="assets/pgda_1023.png" width="1852"/>
<h6><span class="label">Figure 10-23. </span>Future forest cover, 2050</h6>
</div></figure>
<p>The persistent impact of ongoing deforestation can be monitored by tracking carbon emissions as well.</p>
</div></section>
<section data-pdf-bookmark="Carbon Emissions" data-type="sect2"><div class="sect2" id="carbon_emissions">
<h2>Carbon Emissions</h2>
<p>The carbon<a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="carbon emissions" data-type="indexterm" id="idm45433738345392"/> emissions of <a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-tertiary="carbon emissions" data-type="indexterm" id="idm45433738343952"/>current and <a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-tertiary="carbon emissions, calculating" data-type="indexterm" id="idm45433738342224"/>future deforestation <a contenteditable="false" data-primary="carbon emissions of current and future deforestation" data-type="indexterm" id="idm45433738340512"/>can be calculated from the aboveground biomass (<em>AGB.tif</em>) file and the function <code>.emissions()</code>:</p>
<pre data-type="programlisting">
# Create dataframe
dpast <strong>=</strong> ["2020"]
dpast<strong>.</strong>extend(dates_fut)
C_df <strong>=</strong> pd<strong>.</strong>DataFrame({"date": dpast, "C": np<strong>.</strong>repeat(<strong>-</strong>99, ndates_fut <strong>+</strong> 1)},
                    columns<strong>=</strong>["date","C"])
# Loop on date
<strong>for</strong> i <strong>in</strong> range(ndates_fut):
    carbon <strong>=</strong> far<strong>.</strong>emissions(input_stocks<strong>=</strong>"data/emissions/AGB.tif",
                           input_forest<strong>=</strong>"output/fcc_" <strong>+</strong> dates_fut[i] <strong>+</strong> ".tif")
    C_df<strong>.</strong>loc[C_df["date"]<strong>==</strong>dates_fut[i], ["C"]] <strong>=</strong> carbon
# Past emissions
carbon <strong>=</strong> far<strong>.</strong>emissions(input_stocks<strong>=</strong>"data/emissions/AGB.tif",
                       input_forest<strong>=</strong>"data/fcc23.tif")
C_df<strong>.</strong>loc[C_df["date"]<strong>==</strong>dpast[0], ["C"]] <strong>=</strong> carbon
# Save dataframe
C_df<strong>.</strong>to_csv("output/C_emissions.csv", header<strong>=True</strong>, index<strong>=False</strong>)</pre>
<p>To view the dataframe of deforestation rate estimates:</p>
<pre data-type="programlisting">
print(C_df)</pre>
<p>Estimating the persistent rate of change in deforestation rates, annual carbon emissions will continue to increase, as depicted in the output of the code cell:</p>
<pre data-type="programlisting">
    date  C
0   2020   85954
1   2030   99463
2   2035  152047
3   2040  202883
4   2050  290920
5   2055  335097
6   2060  382887
7   2070  481913
8   2080  587963
9   2085  645071
10  2090  705914
11  2100  844066</pre>
<p>The model predicts that, in the absence of robust preservation or conservation in the area, carbon emissions will continue to increase rapidly.</p>
</div></section>
<section data-pdf-bookmark="Analysis" data-type="sect2"><div class="sect2" id="analysis-id00004">
<h2>Analysis</h2>
<p>This section<a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-secondary="analysis" data-type="indexterm" id="idm45433738318544"/> showed you<a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-tertiary="analysis" data-type="indexterm" id="idm45433738316848"/> an approach for using<a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-tertiary="analysis" data-type="indexterm" id="idm45433738315008"/> your Python and geospatial analytics skills to model and forecast tropical deforestation at the country level. This approach allows us to estimate the individual effect of each of several different environmental factors on the probability of deforestation.</p>
<p>The findings are easy to interpret: deforestation becomes more likely as forested land becomes more accessible. Deforestation is less likely inside protected areas. We also showed that there is a great deal of spatial variability in the deforestation process, and we need to account for that to be able to forecast deforestation in a realistic way at the national scale.<a contenteditable="false" data-primary="climate data, using Python to measure" data-secondary="modeling and forecasting deforestation in Guadeloupe with Forest at Risk (example 3)" data-startref="ix_clmtdaex3" data-type="indexterm" id="idm45433738799056"/><a contenteditable="false" data-primary="deforestation in Guadeloupe, modeling and forecasting with Forest at Risk" data-startref="ix_deforestGuad" data-type="indexterm" id="idm45433738611232"/><a contenteditable="false" data-primary="Forest at Risk (FAR)" data-secondary="modeling and forecasting deforestation in Guadeloupe with" data-startref="ix_FAR" data-type="indexterm" id="idm45433738613712"/></p>
</div></section>
</div></section>
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="summary-id00028">
<h1>Summary</h1>
<p>This chapter provided a glimpse into the available packages you can use to explore and analyze climate change and its potential risks using location intelligence and geospatial tools.</p>
<p>In this book, you have been introduced to geospatial analysis and important Python libraries, packages, and tools. In the beginning, introductory packages like pandas and GeoPandas introduced you to working with dataframes and GeoDataFrames. Tools like NumPy, matplotlib, and Plotly began to appear as important dependencies for more complex packages.<a contenteditable="false" data-primary="climate data, using Python to measure" data-startref="ix_clmtda" data-type="indexterm" id="idm45433738305312"/></p>
<p>I hope the long journey has been worth your time, and that you’ll continue to explore these functions, tools, packages, and more. Any work in data science is iterative. You gain confidence from practice—and, dare I say, from navigating the hiccups along <span class="keep-together">the way</span>.</p>
<p>Kudos on your journey.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="ch01fn14"><sup><a href="ch10.xhtml#ch01fn14-marker">1</a></sup> To learn more, I recommend this paper, which introduces WTSS to create a time series from remote sensing data in the Brazilian rainforest: Vinhas, L., Queiroz, G. R., Ferreira, K. R., and Camara, G. 2017. “Web Services for Big Earth Observation Data.” <em>Revista Brasileira de Cartografia</em> 69: 5. <a href="https://oreil.ly/rbckx">English translation</a>.</p><p data-type="footnote" id="ch01fn15"><sup><a href="ch10.xhtml#ch01fn15-marker">2</a></sup> Earth Observation Data Cubes for Brazil: Requirements, Methodology and Products, Earth Observation and Geoinformatics Division, National Institute for Space Research (INPE), Avenida dos Astronautas, 1758, Jardim da Granja, Sao Jose dos Campos, SP 12227-010, Brazil.</p><p data-type="footnote" id="ch01fn16"><sup><a href="ch10.xhtml#ch01fn16-marker">3</a></sup> Ito, Akihiko. 2019. “Disequilibrium of Terrestrial Ecosystem CO<sub>2</sub> Budget Caused by Disturbance-Induced Emissions and Non-CO<sub>2</sub> Carbon Export Flows: A Global Model Assessment.” <em>Earth System Dynamics</em> 10: 685–709. <a href="https://doi.org/10.5194/esd-10-685-2019"><em>https://doi.org/10.5194/esd-10-685-2019</em></a>.</p><p data-type="footnote" id="ch01fn17"><sup><a href="ch10.xhtml#ch01fn17-marker">4</a></sup> For a deeper dive into the statistical methods at work here, please see: Vieilledent, Ghislain, Vancutsem, Christelle, Bourgoin, Clément, Ploton, Pierre, Verley, Philippe, and Achard, Frédéric. 2022. “Spatial Scenario of Tropical Deforestation and Carbon Emissions for the 21st Century.” BioRxiv preprint. <a href="https://www.biorxiv.org/content/biorxiv/early/2022/07/23/2022.03.22.485306.full.pdf"><em>https://www.biorxiv.org/content/biorxiv/early/2022/07/23/2022.03.22.485306.full.pdf</em></a></p></div></div></section></div></body></html>