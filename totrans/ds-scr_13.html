<html><head></head><body><section data-pdf-bookmark="Chapter 12. k-Nearest Neighbors" data-type="chapter" epub:type="chapter"><div class="chapter" id="nearest_neighbors">&#13;
<h1><span class="label">Chapter 12. </span>k-Nearest Neighbors</h1>&#13;
&#13;
<blockquote data-type="epigraph" epub:type="epigraph">&#13;
    <p>If you want to annoy your neighbors, tell the truth about them.</p>&#13;
    <p data-type="attribution">Pietro Aretino</p>&#13;
</blockquote>&#13;
&#13;
<p>Imagine<a data-primary="predictive models" data-secondary="k-nearest neighbors" data-type="indexterm" id="PMnearest12"/><a data-primary="k-nearest neighbors" data-secondary="uses for" data-type="indexterm" id="idm45635742677944"/> that you’re trying to predict how I’m going to vote in the next presidential election. If you know nothing else about me (and if you have the data), one sensible approach is to look at how my <em>neighbors</em> are planning to vote. Living in Seattle, as I do, my neighbors are invariably planning to vote for the Democratic candidate, which suggests that “Democratic candidate” is a good guess for me as well.</p>&#13;
&#13;
<p>Now imagine you know more about me than just geography—perhaps you know my age, my income, how many kids I have, and so on.  To the extent my behavior is influenced (or characterized) by those things, looking just at my neighbors who are close to me among all those dimensions seems likely to be an even better predictor than looking at all my neighbors.  This is the idea behind<a data-primary="nearest neighbors classification" data-type="indexterm" id="idm45635742675240"/> <em>nearest neighbors classification</em>.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Model" data-type="sect1"><div class="sect1" id="idm45635742673848">&#13;
<h1>The Model</h1>&#13;
&#13;
<p>Nearest neighbors<a data-primary="k-nearest neighbors" data-secondary="model for" data-type="indexterm" id="idm45635742672184"/> is one of the simplest predictive models there is.&#13;
It makes no mathematical assumptions, and it doesn’t require any sort of heavy machinery.&#13;
The only things it requires are:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Some notion of distance</p>&#13;
</li>&#13;
<li>&#13;
<p>An assumption that points that are close to one another are similar</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Most of the techniques we’ll see in this book&#13;
look at the dataset as a whole in order to learn&#13;
patterns in the data.  Nearest neighbors, on the other hand,&#13;
quite consciously neglects a lot of information,&#13;
since the prediction for each new point depends only&#13;
on the handful of points closest to it.</p>&#13;
&#13;
<p>What’s more,&#13;
nearest neighbors is probably not going to help you understand&#13;
the drivers of whatever phenomenon you’re looking at.&#13;
Predicting my votes based on my neighbors’ votes&#13;
doesn’t tell you much about what causes me to vote the way I do,&#13;
whereas some alternative model that predicted my vote based on (say)&#13;
my income and marital status very well might.</p>&#13;
&#13;
<p>In the general situation, we have some data points and we have a corresponding set of labels.  The labels could be <code>True</code> and <code>False</code>, indicating whether each input satisfies some condition like “is spam?” or “is poisonous?” or “would be enjoyable to watch?”  Or they could be categories, like movie ratings (G, PG, PG-13, R, NC-17).  Or they could be the names of presidential candidates.  Or they could be favorite programming languages.</p>&#13;
&#13;
<p>In our case, the data points will be vectors, which means that we can use the <code>distance</code> function from <a data-type="xref" href="ch04.html#linear_algebra">Chapter 4</a>.</p>&#13;
&#13;
<p>Let’s say we’ve picked a number <em>k</em> like 3 or 5.  Then, when we want to classify some new data point, we find the <em>k</em> nearest labeled points and let them vote on the new output.</p>&#13;
&#13;
<p>To do this, we’ll need a function that counts votes.  One possibility is:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">List</code>&#13;
<code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">Counter</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">raw_majority_vote</code><code class="p">(</code><code class="n">labels</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">str</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">str</code><code class="p">:</code>&#13;
    <code class="n">votes</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">labels</code><code class="p">)</code>&#13;
    <code class="n">winner</code><code class="p">,</code> <code class="n">_</code> <code class="o">=</code> <code class="n">votes</code><code class="o">.</code><code class="n">most_common</code><code class="p">(</code><code class="mi">1</code><code class="p">)[</code><code class="mi">0</code><code class="p">]</code>&#13;
    <code class="k">return</code> <code class="n">winner</code>&#13;
&#13;
<code class="k">assert</code> <code class="n">raw_majority_vote</code><code class="p">([</code><code class="s1">'a'</code><code class="p">,</code> <code class="s1">'b'</code><code class="p">,</code> <code class="s1">'c'</code><code class="p">,</code> <code class="s1">'b'</code><code class="p">])</code> <code class="o">==</code> <code class="s1">'b'</code></pre>&#13;
&#13;
<p>But this doesn’t do anything intelligent with ties.&#13;
For example, imagine we’re rating movies&#13;
and the five nearest movies are rated G, G, PG, PG, and R.&#13;
Then G has two votes and PG also has two votes.&#13;
In that case, we have several options:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Pick one of the winners at random.</p>&#13;
</li>&#13;
<li>&#13;
<p>Weight the votes by distance and pick the weighted winner.</p>&#13;
</li>&#13;
<li>&#13;
<p>Reduce <em>k</em> until we find a unique winner.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>We’ll implement the third:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">majority_vote</code><code class="p">(</code><code class="n">labels</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">str</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">str</code><code class="p">:</code>&#13;
    <code class="sd">"""Assumes that labels are ordered from nearest to farthest."""</code>&#13;
    <code class="n">vote_counts</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">labels</code><code class="p">)</code>&#13;
    <code class="n">winner</code><code class="p">,</code> <code class="n">winner_count</code> <code class="o">=</code> <code class="n">vote_counts</code><code class="o">.</code><code class="n">most_common</code><code class="p">(</code><code class="mi">1</code><code class="p">)[</code><code class="mi">0</code><code class="p">]</code>&#13;
    <code class="n">num_winners</code> <code class="o">=</code> <code class="nb">len</code><code class="p">([</code><code class="n">count</code>&#13;
                       <code class="k">for</code> <code class="n">count</code> <code class="ow">in</code> <code class="n">vote_counts</code><code class="o">.</code><code class="n">values</code><code class="p">()</code>&#13;
                       <code class="k">if</code> <code class="n">count</code> <code class="o">==</code> <code class="n">winner_count</code><code class="p">])</code>&#13;
&#13;
    <code class="k">if</code> <code class="n">num_winners</code> <code class="o">==</code> <code class="mi">1</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="n">winner</code>                     <code class="c1"># unique winner, so return it</code>&#13;
    <code class="k">else</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="n">majority_vote</code><code class="p">(</code><code class="n">labels</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">])</code> <code class="c1"># try again without the farthest</code>&#13;
&#13;
<code class="c1"># Tie, so look at first 4, then 'b'</code>&#13;
<code class="k">assert</code> <code class="n">majority_vote</code><code class="p">([</code><code class="s1">'a'</code><code class="p">,</code> <code class="s1">'b'</code><code class="p">,</code> <code class="s1">'c'</code><code class="p">,</code> <code class="s1">'b'</code><code class="p">,</code> <code class="s1">'a'</code><code class="p">])</code> <code class="o">==</code> <code class="s1">'b'</code></pre>&#13;
&#13;
<p>This approach is sure to work eventually, since&#13;
in the worst case we go all the way down to just&#13;
one label, at which point that one label wins.</p>&#13;
&#13;
<p>With this function it’s easy to create a classifier:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">NamedTuple</code>&#13;
<code class="kn">from</code> <code class="nn">scratch.linear_algebra</code> <code class="kn">import</code> <code class="n">Vector</code><code class="p">,</code> <code class="n">distance</code>&#13;
&#13;
<code class="k">class</code> <code class="nc">LabeledPoint</code><code class="p">(</code><code class="n">NamedTuple</code><code class="p">):</code>&#13;
    <code class="n">point</code><code class="p">:</code> <code class="n">Vector</code>&#13;
    <code class="n">label</code><code class="p">:</code> <code class="nb">str</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">knn_classify</code><code class="p">(</code><code class="n">k</code><code class="p">:</code> <code class="nb">int</code><code class="p">,</code>&#13;
                 <code class="n">labeled_points</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="n">LabeledPoint</code><code class="p">],</code>&#13;
                 <code class="n">new_point</code><code class="p">:</code> <code class="n">Vector</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">str</code><code class="p">:</code>&#13;
&#13;
    <code class="c1"># Order the labeled points from nearest to farthest.</code>&#13;
    <code class="n">by_distance</code> <code class="o">=</code> <code class="nb">sorted</code><code class="p">(</code><code class="n">labeled_points</code><code class="p">,</code>&#13;
                         <code class="n">key</code><code class="o">=</code><code class="k">lambda</code> <code class="n">lp</code><code class="p">:</code> <code class="n">distance</code><code class="p">(</code><code class="n">lp</code><code class="o">.</code><code class="n">point</code><code class="p">,</code> <code class="n">new_point</code><code class="p">))</code>&#13;
&#13;
    <code class="c1"># Find the labels for the k closest</code>&#13;
    <code class="n">k_nearest_labels</code> <code class="o">=</code> <code class="p">[</code><code class="n">lp</code><code class="o">.</code><code class="n">label</code> <code class="k">for</code> <code class="n">lp</code> <code class="ow">in</code> <code class="n">by_distance</code><code class="p">[:</code><code class="n">k</code><code class="p">]]</code>&#13;
&#13;
    <code class="c1"># and let them vote.</code>&#13;
    <code class="k">return</code> <code class="n">majority_vote</code><code class="p">(</code><code class="n">k_nearest_labels</code><code class="p">)</code></pre>&#13;
&#13;
<p>Let’s take a look at how this works.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Example: The Iris Dataset" data-type="sect1"><div class="sect1" id="idm45635742673224">&#13;
<h1>Example: The Iris Dataset</h1>&#13;
&#13;
<p>The <em>Iris</em> dataset<a data-primary="k-nearest neighbors" data-secondary="Iris dataset example" data-type="indexterm" id="idm45635742336072"/><a data-primary="Iris dataset example" data-type="indexterm" id="idm45635742335064"/> is a staple of machine learning.&#13;
It contains a bunch of measurements for 150 flowers&#13;
representing three species of iris.&#13;
For each flower we have its petal length, petal width,&#13;
sepal length, and sepal width, as well as its species. You can download it from <a href="https://archive.ics.uci.edu/ml/datasets/iris"><em class="hyperlink">https://archive.ics.uci.edu/ml/datasets/iris</em></a>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">requests</code>&#13;
&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">get</code><code class="p">(</code>&#13;
  <code class="s2">"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"</code>&#13;
<code class="p">)</code>&#13;
&#13;
<code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'iris.dat'</code><code class="p">,</code> <code class="s1">'w'</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>&#13;
    <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">data</code><code class="o">.</code><code class="n">text</code><code class="p">)</code></pre>&#13;
&#13;
<p>The data is comma-separated, with fields:</p>&#13;
&#13;
<pre data-type="programlisting">sepal_length, sepal_width, petal_length, petal_width, class</pre>&#13;
&#13;
<p>For example, the first row looks like:</p>&#13;
&#13;
<pre data-type="programlisting">5.1,3.5,1.4,0.2,Iris-setosa</pre>&#13;
&#13;
<p>In this section we’ll try to build a model that can predict&#13;
the class (that is, the species) from the first four measurements.</p>&#13;
&#13;
<p>To start with, let’s load and explore the data. Our nearest neighbors&#13;
function expects a <code>LabeledPoint</code>, so let’s represent our data that way:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">Dict</code>&#13;
<code class="kn">import</code> <code class="nn">csv</code>&#13;
<code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">defaultdict</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">parse_iris_row</code><code class="p">(</code><code class="n">row</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">str</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="n">LabeledPoint</code><code class="p">:</code>&#13;
    <code class="sd">"""</code>&#13;
<code class="sd">    sepal_length, sepal_width, petal_length, petal_width, class</code>&#13;
<code class="sd">    """</code>&#13;
    <code class="n">measurements</code> <code class="o">=</code> <code class="p">[</code><code class="nb">float</code><code class="p">(</code><code class="n">value</code><code class="p">)</code> <code class="k">for</code> <code class="n">value</code> <code class="ow">in</code> <code class="n">row</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">]]</code>&#13;
    <code class="c1"># class is e.g. "Iris-virginica"; we just want "virginica"</code>&#13;
    <code class="n">label</code> <code class="o">=</code> <code class="n">row</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s2">"-"</code><code class="p">)[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>&#13;
&#13;
    <code class="k">return</code> <code class="n">LabeledPoint</code><code class="p">(</code><code class="n">measurements</code><code class="p">,</code> <code class="n">label</code><code class="p">)</code>&#13;
&#13;
<code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'iris.data'</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>&#13;
    <code class="n">reader</code> <code class="o">=</code> <code class="n">csv</code><code class="o">.</code><code class="n">reader</code><code class="p">(</code><code class="n">f</code><code class="p">)</code>&#13;
    <code class="n">iris_data</code> <code class="o">=</code> <code class="p">[</code><code class="n">parse_iris_row</code><code class="p">(</code><code class="n">row</code><code class="p">)</code> <code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">reader</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># We'll also group just the points by species/label so we can plot them</code>&#13;
<code class="n">points_by_species</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">List</code><code class="p">[</code><code class="n">Vector</code><code class="p">]]</code> <code class="o">=</code> <code class="n">defaultdict</code><code class="p">(</code><code class="nb">list</code><code class="p">)</code>&#13;
<code class="k">for</code> <code class="n">iris</code> <code class="ow">in</code> <code class="n">iris_data</code><code class="p">:</code>&#13;
    <code class="n">points_by_species</code><code class="p">[</code><code class="n">iris</code><code class="o">.</code><code class="n">label</code><code class="p">]</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">iris</code><code class="o">.</code><code class="n">point</code><code class="p">)</code></pre>&#13;
&#13;
<p>We’d like to plot the measurements so we can see how they vary by species.&#13;
Unfortunately, they are four-dimensional, which makes them tricky to plot.&#13;
One thing we can do is look at the scatterplots for each of the six pairs&#13;
of measurements (<a data-type="xref" href="#iris_scatterplots">Figure 12-1</a>). I won’t explain all the details, but it’s a nice illustration of more complicated things you can do with matplotlib, so it’s worth studying:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">matplotlib</code> <code class="kn">import</code> <code class="n">pyplot</code> <code class="k">as</code> <code class="n">plt</code>&#13;
<code class="n">metrics</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'sepal length'</code><code class="p">,</code> <code class="s1">'sepal width'</code><code class="p">,</code> <code class="s1">'petal length'</code><code class="p">,</code> <code class="s1">'petal width'</code><code class="p">]</code>&#13;
<code class="n">pairs</code> <code class="o">=</code> <code class="p">[(</code><code class="n">i</code><code class="p">,</code> <code class="n">j</code><code class="p">)</code> <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">4</code><code class="p">)</code> <code class="k">for</code> <code class="n">j</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">4</code><code class="p">)</code> <code class="k">if</code> <code class="n">i</code> <code class="o">&lt;</code> <code class="n">j</code><code class="p">]</code>&#13;
<code class="n">marks</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'+'</code><code class="p">,</code> <code class="s1">'.'</code><code class="p">,</code> <code class="s1">'x'</code><code class="p">]</code>  <code class="c1"># we have 3 classes, so 3 markers</code>&#13;
&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="mi">3</code><code class="p">)</code>&#13;
&#13;
<code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">2</code><code class="p">):</code>&#13;
    <code class="k">for</code> <code class="n">col</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">3</code><code class="p">):</code>&#13;
        <code class="n">i</code><code class="p">,</code> <code class="n">j</code> <code class="o">=</code> <code class="n">pairs</code><code class="p">[</code><code class="mi">3</code> <code class="o">*</code> <code class="n">row</code> <code class="o">+</code> <code class="n">col</code><code class="p">]</code>&#13;
        <code class="n">ax</code><code class="p">[</code><code class="n">row</code><code class="p">][</code><code class="n">col</code><code class="p">]</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="n">f</code><code class="s2">"{metrics[i]} vs {metrics[j]}"</code><code class="p">,</code> <code class="n">fontsize</code><code class="o">=</code><code class="mi">8</code><code class="p">)</code>&#13;
        <code class="n">ax</code><code class="p">[</code><code class="n">row</code><code class="p">][</code><code class="n">col</code><code class="p">]</code><code class="o">.</code><code class="n">set_xticks</code><code class="p">([])</code>&#13;
        <code class="n">ax</code><code class="p">[</code><code class="n">row</code><code class="p">][</code><code class="n">col</code><code class="p">]</code><code class="o">.</code><code class="n">set_yticks</code><code class="p">([])</code>&#13;
&#13;
        <code class="k">for</code> <code class="n">mark</code><code class="p">,</code> <code class="p">(</code><code class="n">species</code><code class="p">,</code> <code class="n">points</code><code class="p">)</code> <code class="ow">in</code> <code class="nb">zip</code><code class="p">(</code><code class="n">marks</code><code class="p">,</code> <code class="n">points_by_species</code><code class="o">.</code><code class="n">items</code><code class="p">()):</code>&#13;
            <code class="n">xs</code> <code class="o">=</code> <code class="p">[</code><code class="n">point</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="k">for</code> <code class="n">point</code> <code class="ow">in</code> <code class="n">points</code><code class="p">]</code>&#13;
            <code class="n">ys</code> <code class="o">=</code> <code class="p">[</code><code class="n">point</code><code class="p">[</code><code class="n">j</code><code class="p">]</code> <code class="k">for</code> <code class="n">point</code> <code class="ow">in</code> <code class="n">points</code><code class="p">]</code>&#13;
            <code class="n">ax</code><code class="p">[</code><code class="n">row</code><code class="p">][</code><code class="n">col</code><code class="p">]</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code class="n">xs</code><code class="p">,</code> <code class="n">ys</code><code class="p">,</code> <code class="n">marker</code><code class="o">=</code><code class="n">mark</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="n">species</code><code class="p">)</code>&#13;
&#13;
<code class="n">ax</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">][</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'lower right'</code><code class="p">,</code> <code class="n">prop</code><code class="o">=</code><code class="p">{</code><code class="s1">'size'</code><code class="p">:</code> <code class="mi">6</code><code class="p">})</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>&#13;
&#13;
<figure><div class="figure" id="iris_scatterplots">&#13;
<img alt="Iris scatterplots" src="assets/dsf2_1201.png"/>&#13;
<h6><span class="label">Figure 12-1. </span>Iris scatterplots</h6>&#13;
</div></figure>&#13;
&#13;
<p>If you look at those plots, it seems like the measurements really do cluster by species.&#13;
For example, looking at sepal length and sepal width alone, you probably couldn’t distinguish&#13;
between <em>versicolor</em> and <em>virginica</em>. But once you add petal length and width into the mix, it seems like you should be able to predict the species based on the nearest neighbors.</p>&#13;
&#13;
<p>To start with, let’s split the data into a test set and a training set:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">random</code>&#13;
<code class="kn">from</code> <code class="nn">scratch.machine_learning</code> <code class="kn">import</code> <code class="n">split_data</code>&#13;
&#13;
<code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="mi">12</code><code class="p">)</code>&#13;
<code class="n">iris_train</code><code class="p">,</code> <code class="n">iris_test</code> <code class="o">=</code> <code class="n">split_data</code><code class="p">(</code><code class="n">iris_data</code><code class="p">,</code> <code class="mf">0.70</code><code class="p">)</code>&#13;
<code class="k">assert</code> <code class="nb">len</code><code class="p">(</code><code class="n">iris_train</code><code class="p">)</code> <code class="o">==</code> <code class="mf">0.7</code> <code class="o">*</code> <code class="mi">150</code>&#13;
<code class="k">assert</code> <code class="nb">len</code><code class="p">(</code><code class="n">iris_test</code><code class="p">)</code> <code class="o">==</code> <code class="mf">0.3</code> <code class="o">*</code> <code class="mi">150</code></pre>&#13;
&#13;
<p>The training set will be the “neighbors” that we’ll use to classify&#13;
the points in the test set. We just need to choose a value for <em>k</em>,&#13;
the number of neighbors who get to vote. Too small (think <em>k</em> = 1),&#13;
and we let outliers have too much influence; too large (think <em>k</em> = 105), and we just predict the most common class in the dataset.</p>&#13;
&#13;
<p>In a real application (and with more data), we might create a separate&#13;
validation set and use it to choose <em>k</em>. Here we’ll just use <em>k</em> = 5:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">Tuple</code>&#13;
&#13;
<code class="c1"># track how many times we see (predicted, actual)</code>&#13;
<code class="n">confusion_matrix</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="n">Tuple</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="nb">str</code><code class="p">],</code> <code class="nb">int</code><code class="p">]</code> <code class="o">=</code> <code class="n">defaultdict</code><code class="p">(</code><code class="nb">int</code><code class="p">)</code>&#13;
<code class="n">num_correct</code> <code class="o">=</code> <code class="mi">0</code>&#13;
&#13;
<code class="k">for</code> <code class="n">iris</code> <code class="ow">in</code> <code class="n">iris_test</code><code class="p">:</code>&#13;
    <code class="n">predicted</code> <code class="o">=</code> <code class="n">knn_classify</code><code class="p">(</code><code class="mi">5</code><code class="p">,</code> <code class="n">iris_train</code><code class="p">,</code> <code class="n">iris</code><code class="o">.</code><code class="n">point</code><code class="p">)</code>&#13;
    <code class="n">actual</code> <code class="o">=</code> <code class="n">iris</code><code class="o">.</code><code class="n">label</code>&#13;
&#13;
    <code class="k">if</code> <code class="n">predicted</code> <code class="o">==</code> <code class="n">actual</code><code class="p">:</code>&#13;
        <code class="n">num_correct</code> <code class="o">+=</code> <code class="mi">1</code>&#13;
&#13;
    <code class="n">confusion_matrix</code><code class="p">[(</code><code class="n">predicted</code><code class="p">,</code> <code class="n">actual</code><code class="p">)]</code> <code class="o">+=</code> <code class="mi">1</code>&#13;
&#13;
<code class="n">pct_correct</code> <code class="o">=</code> <code class="n">num_correct</code> <code class="o">/</code> <code class="nb">len</code><code class="p">(</code><code class="n">iris_test</code><code class="p">)</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">pct_correct</code><code class="p">,</code> <code class="n">confusion_matrix</code><code class="p">)</code></pre>&#13;
&#13;
<p>On this simple dataset, the model predicts almost perfectly. There’s one <em>versicolor</em>&#13;
for which it predicts <em>virginica</em>, but otherwise it gets things exactly right.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Curse of Dimensionality" data-type="sect1"><div class="sect1" id="the_curse_of_dimensionality">&#13;
<h1>The Curse of Dimensionality</h1>&#13;
&#13;
<p>The <em>k</em>-nearest neighbors<a data-primary="k-nearest neighbors" data-secondary="curse of dimensionality" data-type="indexterm" id="idm45635741586520"/><a data-primary="curse of dimensionality" data-type="indexterm" id="idm45635741585512"/> algorithm runs into trouble in higher dimensions thanks to the “curse of dimensionality,” which boils down to the fact that high-dimensional spaces are <em>vast</em>.  Points in high-dimensional spaces tend not to be close to one another at all.  One way to see this is by randomly generating pairs of points in the <em>d</em>-dimensional “unit cube” in a variety of dimensions, and calculating the distances between them.</p>&#13;
&#13;
<p>Generating random points should be second nature by now:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">random_point</code><code class="p">(</code><code class="n">dim</code><code class="p">:</code> <code class="nb">int</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Vector</code><code class="p">:</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">()</code> <code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">dim</code><code class="p">)]</code></pre>&#13;
&#13;
<p>as is writing a function to generate the distances:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">random_distances</code><code class="p">(</code><code class="n">dim</code><code class="p">:</code> <code class="nb">int</code><code class="p">,</code> <code class="n">num_pairs</code><code class="p">:</code> <code class="nb">int</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">]:</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">distance</code><code class="p">(</code><code class="n">random_point</code><code class="p">(</code><code class="n">dim</code><code class="p">),</code> <code class="n">random_point</code><code class="p">(</code><code class="n">dim</code><code class="p">))</code>&#13;
            <code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_pairs</code><code class="p">)]</code></pre>&#13;
&#13;
<p>For every dimension from 1 to 100, we’ll compute 10,000 distances and use those to compute the average distance between points and the minimum distance between points in each dimension (<a data-type="xref" href="#curse_of_dimensionality_graph">Figure 12-2</a>):</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">tqdm</code>&#13;
<code class="n">dimensions</code> <code class="o">=</code> <code class="nb">range</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">101</code><code class="p">)</code>&#13;
&#13;
<code class="n">avg_distances</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">min_distances</code> <code class="o">=</code> <code class="p">[]</code>&#13;
&#13;
<code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code>&#13;
<code class="k">for</code> <code class="n">dim</code> <code class="ow">in</code> <code class="n">tqdm</code><code class="o">.</code><code class="n">tqdm</code><code class="p">(</code><code class="n">dimensions</code><code class="p">,</code> <code class="n">desc</code><code class="o">=</code><code class="s2">"Curse of Dimensionality"</code><code class="p">):</code>&#13;
    <code class="n">distances</code> <code class="o">=</code> <code class="n">random_distances</code><code class="p">(</code><code class="n">dim</code><code class="p">,</code> <code class="mi">10000</code><code class="p">)</code>      <code class="c1"># 10,000 random pairs</code>&#13;
    <code class="n">avg_distances</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="nb">sum</code><code class="p">(</code><code class="n">distances</code><code class="p">)</code> <code class="o">/</code> <code class="mi">10000</code><code class="p">)</code>  <code class="c1"># track the average</code>&#13;
    <code class="n">min_distances</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="nb">min</code><code class="p">(</code><code class="n">distances</code><code class="p">))</code>          <code class="c1"># track the minimum</code></pre>&#13;
&#13;
<figure><div class="figure" id="curse_of_dimensionality_graph">&#13;
<img alt="The Curse of Dimensionality." src="assets/dsf2_1202.png"/>&#13;
<h6><span class="label">Figure 12-2. </span>The curse of dimensionality</h6>&#13;
</div></figure>&#13;
&#13;
<p>As the number of dimensions increases, the average distance between points increases.  But what’s more problematic is the ratio between the closest distance and the average distance (<a data-type="xref" href="#curse_of_dimensionality_graph2">Figure 12-3</a>):</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">min_avg_ratio</code> <code class="o">=</code> <code class="p">[</code><code class="n">min_dist</code> <code class="o">/</code> <code class="n">avg_dist</code>&#13;
                 <code class="k">for</code> <code class="n">min_dist</code><code class="p">,</code> <code class="n">avg_dist</code> <code class="ow">in</code> <code class="nb">zip</code><code class="p">(</code><code class="n">min_distances</code><code class="p">,</code> <code class="n">avg_distances</code><code class="p">)]</code></pre>&#13;
&#13;
<figure><div class="figure" id="curse_of_dimensionality_graph2">&#13;
<img alt="The Curse of Dimensionality Again." src="assets/dsf2_1203.png"/>&#13;
<h6><span class="label">Figure 12-3. </span>The curse of dimensionality again</h6>&#13;
</div></figure>&#13;
&#13;
<p>In low-dimensional datasets, the closest points tend to be much closer than average. But two points are close only if they’re close in every dimension, and every extra dimension—even if just noise—is another opportunity for each point to be farther away from every other point.  When you have a lot of dimensions, it’s likely that the closest points aren’t much closer than average, so two points being close doesn’t mean very much (unless there’s a lot of structure in your data that makes it behave as if it were much lower-dimensional).</p>&#13;
&#13;
<p>A different way of thinking about the problem involves the sparsity of higher-dimensional spaces.</p>&#13;
&#13;
<p>If you pick 50 random numbers between 0 and 1, you’ll probably get a pretty good sample of the unit interval (<a data-type="xref" href="#fifty_points_1d">Figure 12-4</a>).</p>&#13;
&#13;
<figure><div class="figure" id="fifty_points_1d">&#13;
<img alt="50 Random Points in One Dimension." src="assets/dsf2_1204.png"/>&#13;
<h6><span class="label">Figure 12-4. </span>Fifty random points in one dimension</h6>&#13;
</div></figure>&#13;
&#13;
<p>If you pick 50 random points in the unit square, you’ll get less coverage (<a data-type="xref" href="#fifty_points_2d">Figure 12-5</a>).</p>&#13;
&#13;
<figure><div class="figure" id="fifty_points_2d">&#13;
<img alt="50 Random Points in Two Dimensions." src="assets/dsf2_1205.png"/>&#13;
<h6><span class="label">Figure 12-5. </span>Fifty random points in two dimensions</h6>&#13;
</div></figure>&#13;
&#13;
<p>And in three dimensions, less still (<a data-type="xref" href="#fifty_points_3d">Figure 12-6</a>).</p>&#13;
&#13;
<p>matplotlib doesn’t graph four dimensions well, so that’s as far as we’ll go, but you can see already that there are starting to be large empty spaces with no points near them.  In more dimensions—unless you get exponentially more data—those large empty spaces represent regions far from all the points you want to use in your predictions.</p>&#13;
&#13;
<p>So if you’re trying to use nearest neighbors in higher dimensions, it’s probably a good idea to do some kind of dimensionality reduction first.</p>&#13;
&#13;
<figure><div class="figure" id="fifty_points_3d">&#13;
<img alt="50 Random Points in Three Dimensions." src="assets/dsf2_1206.png"/>&#13;
<h6><span class="label">Figure 12-6. </span>Fifty random points in three dimensions</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="For Further Exploration" data-type="sect1"><div class="sect1" id="idm45635741587784">&#13;
<h1>For Further Exploration</h1>&#13;
&#13;
<p>scikit-learn has many <a href="https://scikit-learn.org/stable/modules/neighbors.html">nearest neighbor</a> models.<a data-primary="" data-startref="PMnearest12" data-type="indexterm" id="idm45635741341864"/><a data-primary="scikit-learn" data-type="indexterm" id="idm45635741340856"/><a data-primary="k-nearest neighbors" data-secondary="tools for" data-type="indexterm" id="idm45635741340184"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>