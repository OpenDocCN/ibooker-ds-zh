- en: Chapter 3\. Foundations of Inferential Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 1](ch01.html#foundations-of-eda) provided a framework for exploring
    a dataset by classifying, summarizing, and visualizing variables. Though this
    is an essential start to analytics, we usually don’t want it to end there: we
    would like to know whether what we see in our sample data can *generalize* to
    a larger population.'
  prefs: []
  type: TYPE_NORMAL
- en: The thing is, we don’t actually know what we’ll find in the population, because
    we don’t have the data for all of it. However, using the principles of probability
    introduced in [Chapter 2](ch02.html#foundations-of-probability), we can quantify
    our uncertainty that what we see in our sample will also be found in the population.
  prefs: []
  type: TYPE_NORMAL
- en: Estimating the values of a population given a sample is known as *inferential
    statistics* and is carried out by *hypothesis testing*. That framework is the
    basis of this chapter. You may have studied inferential statistics in school,
    which could have easily turned you off the subject, seeming incomprehensible and
    without application. That’s why I’ll make this chapter as applied as possible,
    exploring a real-world dataset using Excel.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the chapter, you will have a handle on this basic framework that
    powers much of analytics. We’ll continue to build on its application in [Chapter 4](ch04.html#foundations-of-data-analytics).
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 1](ch01.html#foundations-of-eda) concluded with an exercise on the
    *housing* dataset, which will be the focus of this chapter. You can find the dataset
    in the *datasets* folder of the book repository, under the *housing* subfolder.
    Make a copy of it, add an index column, and convert this dataset into a table
    named *housing*.'
  prefs: []
  type: TYPE_NORMAL
- en: The Framework of Statistical Inference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The ability to infer characteristics of a population based on a sample seems
    magical, doesn’t it? Just like with any magic trick, inferential statistics may
    look easy to outsiders. But to those within, it’s the culmination of a series
    of finely tuned steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Collect a representative sample.* This technically comes *before* the hypothesis
    test, but is essential for its success. We must be sure that the sample collected
    is a fair reflection of the population.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*State the hypotheses.* First, we will state a *research hypothesis*, or some
    statement that motivates our analysis and that we think explains something about
    our population. We will then state a *statistical hypothesis* to test whether
    the data supports this explanation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Formulate an analysis plan.* We will then outline what methods we’ll use to
    conduct this test, and what criteria we’ll use to evaluate it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Analyze the data.* Here is where we actually crunch the numbers, and develop
    the evidence that we’ll use to evaluate our test against.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Make a decision.* It’s the moment of truth: we will compare the evaluation
    criteria from step 2 with the actual results from step 3, and conclude whether
    the evidence supports our statistical hypothesis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each of these steps, I’ll provide a brief conceptual overview. We’ll then
    immediately apply these concepts to the *housing* dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Collect a Representative Sample
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [Chapter 2](ch02.html#foundations-of-probability) you learned that, thanks
    to the law of large numbers, the average of sample means should get closer to
    the expected value as the sample size increases. This forms a rule of thumb for
    what makes an adequate sample size to conduct inferential statistics. We are assuming,
    however, that we are working with a *representative* sample or a set of observations
    that fairly reflect the population. If the sample isn’t representative, we’d have
    no standing to assume its sample mean would approach the population mean with
    more observations.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring a representative sample is best handled during the conceptualization
    and collection phases of research; by the time the data is collected, it’s hard
    to walk back any issues related to sampling. There are many approaches to collecting
    data, but while it’s an important part of the analytics workflow, it is outside
    the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The best time to ensure a representative sample is during the collection of
    the data itself. If you’re working with a preassembled dataset, consider what
    steps were taken to meet this objective.
  prefs: []
  type: TYPE_NORMAL
- en: 'Getting a representative sample of the population prompts the question: what
    is the target population? This population can be as general or specific as we
    want. For example, let’s say we’re interested in exploring the heights and weights
    of dogs. Our population could be all dogs, or it could be a specific breed. It
    could be a certain age group or sex of dogs as well. Some target populations may
    be of more theoretical importance, or logistically easier to sample. Your target
    population can be anything, but your sample of that population needs to be representative.'
  prefs: []
  type: TYPE_NORMAL
- en: At 546 observations, *housing* is likely a large-enough sample for conducting
    valid inferential statistics. Is it representative, though? Without some understanding
    of the collection methods or the target population, it’s hard to be sure. This
    data comes from the peer-reviewed *Journal of Applied Econometrics*, so it is
    trustworthy. Data that you receive at work may not come to you as polished, so
    it’s worth thinking through or inquiring about the collection and sampling procedures.
  prefs: []
  type: TYPE_NORMAL
- en: As for the data’s target population, the data’s *readme* file, available in
    the book repository under *datasets* → *housing*, indicates it comes from home
    sales in Windsor, Ontario, Canada. That means that housing prices in Windsor may
    be the best target population; the findings may or may not, for example, transfer
    to housing prices across Canada or even Ontario. This is also an older dataset,
    taken from a paper written in the 1990s, so it’s not guaranteed that the findings
    from it would apply to today’s housing market, even in Windsor.
  prefs: []
  type: TYPE_NORMAL
- en: State the Hypotheses
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With some comfort that our sample data is representative of the population,
    we can start to think about what exactly we’d like to infer by stating hypotheses.
    Maybe you’ve heard rumors about some trend or unusual phenomenon in your data.
    Maybe something struck you about the data as you began checking it out during
    EDA. This is your time to speculate on what you *think* you’ll find as the result
    of your analysis. Going to our *housing* example, I think few would disagree that
    air conditioning is desirable to have in a home. It stands to reason, then, that
    homes with air conditioning sell for higher prices than those without. This informal
    statement about the relationship you’ll find in the data is called a *research
    hypothesis*. Another way to state this relationship is that there is an *effect*
    of air conditioning on sale price. Homes in Windsor are our *population*, and
    those homes with and without air conditioning are two of its groups or *subpopulations*.
  prefs: []
  type: TYPE_NORMAL
- en: Now, it’s great that you have your hypothesis about how air conditioning affects
    sale prices. It’s crucial as an analyst to have a strong intuition and opinion
    about your work. But as American engineer W. Edwards Deming famously said, “In
    God we trust. All others must bring data.” What we *really* want to know is whether
    your speculated relationship is actually present in the population. And for this,
    we’ll need to use inferential statistics.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you’ve already seen, statistical language is usually different than everyday
    language. It can feel pedantic at first, but the nuances reveal a lot about how
    data analysis works. *Statistical hypotheses* are one such example. To test whether
    the data supports our proposed relationship, we’ll provide two statistical hypotheses
    like the following. Take a look at them now; they’ll be explained later:'
  prefs: []
  type: TYPE_NORMAL
- en: H0
  prefs: []
  type: TYPE_NORMAL
- en: There is no difference in the average sale price of homes with or without air
    conditioning.
  prefs: []
  type: TYPE_NORMAL
- en: Ha
  prefs: []
  type: TYPE_NORMAL
- en: There is a difference in the average sale price of homes with or without air
    conditioning.
  prefs: []
  type: TYPE_NORMAL
- en: By design, these hypotheses are mutually exclusive, so that if one is true,
    the other must be false. They are also testable and falsifiable, meaning that
    we can use real-world evidence to measure and contradict them. These are big-idea
    topics on the philosophy of science that we can’t do full credit to here; the
    main takeaway is that you want to make sure that your hypotheses can actually
    be tested with your data.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we need to leave all preconceived notions about the data behind,
    such as what was speculated in the research hypothesis. We’re now assuming *no*
    effect. After all, why would we? We only have a *sample* of the population’s data,
    so we’ll never truly know the population’s true value, or parameter. That’s why
    the first hypothesis, or H0, called the *null hypothesis*, is stated so peculiarly.
  prefs: []
  type: TYPE_NORMAL
- en: On the flip side is the *alternative hypothesis*, or Ha. If there’s no evidence
    in the data for the null hypothesis, then the evidence has to be for the alternative,
    given the way they are stated. That said, we can never say we’ve *proven* either
    to be true, because we don’t actually know the population’s parameter. It could
    be that the effect we found in the sample is just a fluke, and we wouldn’t have
    actually found it in the population. In fact, measuring the probability of this
    happening will be a major element of what we do in hypothesis testing.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The results of hypothesis testing don’t “prove” either hypothesis to be correct,
    because the “true” parameter of the population isn’t known in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: Formulate an Analysis Plan
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have our statistical hypotheses teed up, it’s time to specify the
    methods used to test the data. The proper statistical test for a given hypothesis
    depends on a variety of factors, including the type of variables used in the analysis:
    continuous, categorical, and so on. This is another reason it’s a good idea to
    classify variables during EDA. Specifically, the test we decide to use depends
    on the types of our independent and dependent variables.'
  prefs: []
  type: TYPE_NORMAL
- en: The study of cause and effect drives much of what we do in analytics; we use
    *independent* and *dependent* variables to model and analyze these relationships.
    (Remember, though, that because we are dealing with samples, causation is impossible
    to claim with certainty.) We talked about the idea of experiments in [Chapter 2](ch02.html#foundations-of-probability)
    as repeatable events generating a defined set of random outcomes. We used the
    example of a die throw as an experiment; most experiments in real life are more
    complicated. Let’s look at an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say we are researchers interested in what contributes to plant growth. A colleague
    has speculated that watering the plants could have a positive impact. We decide
    to try it by running experiments. We provide various amounts of water among observations,
    making sure to record the data. Then we wait a few days and measure the resulting
    plant growth. We’ve got two variables in this experiment: watering amount and
    plant growth. Can you guess which is our independent and which is our dependent
    variable?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Watering is the *independent variable* because it’s what we as researchers
    control as part of the experiment. Plant growth is the *dependent* because it’s
    what we’ve hypothesized will change given a change in the independent variable.
    The independent variable is often recorded first: for example, plants are watered
    *first*, and *then* they grow.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Independent variables are generally recorded before dependent variables because
    cause must come before effect.
  prefs: []
  type: TYPE_NORMAL
- en: Given this example, what’s the more sensible way to model the relationship between
    air conditioning and sale price? It stands to reason that air conditioning is
    installed first, *then* the house is sold. That makes *airco* and *price* our
    independent and dependent variables, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Because we are looking to test the effect of a binary independent variable on
    a continuous dependent variable, we’ll use something called the *independent samples
    t-test*. Don’t worry about memorizing the best test to use for any given occasion.
    Instead, the objective here is picking up the common framework of making inferences
    about a population given a sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most statistical tests make some assumptions about their data. If these assumptions
    aren’t met, then test results may be inaccurate. For example, the independent
    samples t-test assumes that no observation influences another and that each observation
    is found in one and only one group (that is, they are *independent*). To adequately
    estimate the population mean, the test generally assumes normally distributed
    samples; that said, it’s possible to circumvent that constraint for larger datasets
    given the magic of the central limit theorem. Excel will help us bypass another
    assumption: that the variance of each population is equal.'
  prefs: []
  type: TYPE_NORMAL
- en: We know what test we’ll use, but we still need to set some rules for implementing
    it. For one, we need to decide the *statistical significance* of the test. Let’s
    go back to the scenario mentioned previously, where the effect inferred in the
    sample is just a fluke and wouldn’t have been found in the population. This scenario
    will happen eventually, because we’ll never actually know the population mean.
    In other words, we are *uncertain* about this outcome…and, as you learned in [Chapter 2](ch02.html#foundations-of-probability),
    it’s possible to *quantify* uncertainty as a number between 0 and 1\. This number
    is called *alpha* and represents the statistical significance of the test.
  prefs: []
  type: TYPE_NORMAL
- en: The alpha shows how comfortable we are with the possibility that there’s really
    no effect in the populations, but that we found one in the samples due to chance.
    A common threshold for alpha that we’ll use throughout the book is 5%. In other
    words, we are comfortable with claiming a relationship in the data when there
    really is none 5% or less of the time.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This book follows the standard convention of conducting two-tailed hypothesis
    tests at the 5% statistical significance level.
  prefs: []
  type: TYPE_NORMAL
- en: Other common significance levels include 10% or 1%. There is no one “right”
    level of alpha; setting it depends on a variety of factors such as the research
    objective, ease of interpretability, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering why we would be comfortable *at all* with the possibility
    of claiming an effect when there is none. In other words, why not an alpha of
    0? In this case, we’re unable to claim *anything* about our population given the
    sample. Effectively, with an alpha of 0 we’d be saying that, because we don’t
    ever want to be wrong about the population’s true value, it could be anything.
    To make any inference at all, being wrong is a risk we must take.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to state which *direction* in effect we’re interested in. For
    example, we’re assuming a *positive* effect of air conditioning on sale price:
    that is, the average sale price of homes with air conditioning is greater than
    those without. However, it could turn out that there’s a negative effect: it might
    be you’re dealing with a population that would prefer not to have air conditioning.
    Or, maybe it’s a climate where using air conditioning is rarely justified, and
    having the unit is a needless expense. These scenarios are theoretically possible;
    if there’s any doubt, then the statistical test should examine for both positive
    *and* negative effects. This is known as a *two-tailed* (or two-tail, as Excel
    refers to it) test, and we’ll be using it in this book. One-tailed tests are possible,
    but relatively rare and outside our scope.'
  prefs: []
  type: TYPE_NORMAL
- en: This may seem like a lot of windup when we haven’t even touched the data yet.
    But these steps exist to ensure that we as analysts come to the data fairly when
    we finally make the calculations. The results of our hypothesis test depend on
    the level of statistical significance and the number of tails tested. As you’ll
    see later, it’s very possible that slightly different inputs to the test, such
    as a different statistical significance level, result in different findings. This
    offers a real temptation to run the numbers, *then* decide on a specific test
    for a favorable outcome. However, we want to avoid the urge to engineer the results
    to fit our agenda.
  prefs: []
  type: TYPE_NORMAL
- en: Analyze the Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'And now, the moment you’ve likely been waiting for: time to crunch the data.
    This part of the work often gets the most attention and is what we’ll focus on
    here, but it’s worth keeping in mind that it’s just one of the many steps of hypothesis
    testing. Remember, data analysis is an iterative process. It’s unlikely (and unwise)
    that you’ve performed *no* analysis of this data before conducting a hypothesis
    test. In fact, exploratory data analysis is designed as a precursor to hypothesis
    testing, or *confirmatory* data analysis. You should *always* be comfortable with
    the dataset’s descriptive statistics before looking to make inferences about it.
    In that spirit, let’s do that here with our *housing* dataset, then move to the
    analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3-1](#price-by-ac) calculates the descriptive statistics for and visualizes
    the distributions of *price* for both levels of *airco*. If you need a refresher
    on how to do this, check out [Chapter 1](ch01.html#foundations-of-eda). I relabeled
    the ToolPak output to help indicate what is being measured in each group.'
  prefs: []
  type: TYPE_NORMAL
- en: '![_housing_ descriptive statistics](assets/aina_0301.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-1\. EDA of the housing dataset
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The histogram in this output shows us that both groups of data are approximately
    normally distributed, and the descriptive statistics tell us that we have relatively
    large sample sizes. While far more homes do not have air conditioning (373 without
    versus 173 with), this is not necessarily a problem for the t-test.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The independent samples t-test is not sensitive to differences in sample sizes
    between the two groups, so long as each group is sufficiently large. Other statistical
    tests may be affected by this difference.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3-1](#price-by-ac) also gives us the sample means of our groups: approximately
    $86,000 for homes with air conditioning, and $60,000 for those without. That’s
    good to know, but we’d *really* like to find out whether we could expect such
    an effect in the population at large. That’s where the t-test comes in, and we’ll
    lean yet again on PivotTables and the Data Analysis ToolPak to conduct it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Insert a PivotTable into a new worksheet, placing *id* in the Rows area, *airco*
    in the Columns area, and “Sum of price” in the Values area. Clear out all grand
    totals from the report. This data arrangement will be easy to input into the t-test
    menu, which can be accessed from the ribbon via Data → Data Analysis → t-Test:
    Two-Sample Assuming Unequal Variances. The “variances” referred to here are our
    subpopulation variances. We really don’t know whether these are equal, so it’s
    better to choose this option, assuming equal variances for more conservative results.'
  prefs: []
  type: TYPE_NORMAL
- en: A dialog box will appear; fill it out as in [Figure 3-2](#t-test-setup). Make
    sure that the box next to Labels is checked. Immediately above this selection
    is an option titled Hypothesized Mean Difference. By default, this is left blank,
    which means we are testing for a difference of zero. This is precisely our null
    hypothesis, so we don’t have to change anything. Immediately below that line is
    an option titled Alpha. This is our stated level of statistical significance;
    Excel defaults to 5%, which is what we want.
  prefs: []
  type: TYPE_NORMAL
- en: '![T-test setup](assets/aina_0302.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-2\. t-test setup menu in the ToolPak
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The results are shown in [Figure 3-3](#t-test-output). I’ve again relabeled
    each group as *ac-no* and *ac-yes* to clarify what groups are represented. We’ll
    step through selected parts of the output next.
  prefs: []
  type: TYPE_NORMAL
- en: '![T-test setup](assets/aina_0303.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-3\. t-test output
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'First, we’re given some information about our two samples in `F5:G7`: their
    means, variances, and sample sizes. Our hypothesized mean difference of zero is
    also included.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll skip a few statistics here and focus next on cell `F13`, *P(T < = t) two-tail*.
    This probably doesn’t make much sense to you, but *two-tail* should sound familiar,
    as it’s the type of test we decided to focus on earlier instead of a one-tail
    test. This figure is called the *p-value*, and we’ll use it to make a decision
    about the hypothesis test.
  prefs: []
  type: TYPE_NORMAL
- en: Make a Decision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Earlier you learned that alpha is our level of statistical significance, or
    the level with which we are comfortable assuming there’s a real effect in the
    population when there is not, because the effect we found in the sample is due
    to random chance. The p-value quantifies the probability that we will find this
    scenario in the data, and we compare it to alpha to make a decision:'
  prefs: []
  type: TYPE_NORMAL
- en: If the p-value is less than or equal to our alpha, then we reject the null.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the p-value is greater than our alpha, then we fail to reject the null.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s cut through this statistical jargon with the data at hand. As a probability,
    the p-value is always between 0 and 1\. Our p-value in `F13` is very small, so
    small that Excel has labeled it in scientific notation. The way to read this output
    is as 1.93 times 10 to the negative 22nd power—a *very* small number. We are saying,
    then, that if there were really no effect in the population, we’d expect to find
    the effect that we did in the samples well under less than 1% of the time. This
    is well below our alpha of 5%, so we can reject the null. When a p-value is so
    small that scientific notation is required to report it, you’ll often see the
    results simply summarized as “p < 0.05.”
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, let’s say our p-value was 0.08 or 0.24\. In these cases,
    we would *fail* to reject the null. Why this odd language? Why don’t we just say
    that we “proved” either the null or the alternative? It all goes back to the inherent
    uncertainty of inferential statistics. We don’t ever know the true subpopulation
    values, so it’s safer to start on the premise that they are both equal. The results
    of our test can confirm or deny evidence for either, but they can never definitively
    *prove* it.
  prefs: []
  type: TYPE_NORMAL
- en: While p-values are used to make a decision about a hypothesis test, it’s also
    important to know what they *cannot* tell us. For example, a frequent misinterpretation
    is that the p-value is the probability of making a mistake. In fact, a p-value
    *assumes* that our null hypothesis is true, regardless of what is found in the
    sample; the idea of there being a “mistake” in the sample doesn’t change this
    assumption at all. The p-value *only* tells us what percentage of the time we’d
    find the effect that we did in our sample, given no effect in the population.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The p-value is *not* the probability of making a mistake; rather, it is the
    probability of finding the effect in the sample that we did, given no effect in
    the population.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another common misinterpretation is that the smaller the p-value, the larger
    the effect. The p-value, however, is only a measure of *statistical* significance:
    it tells us how *likely* an effect in the population is. The p-value does not
    indicate the *substantive* significance, or how large that effect size is likely
    to be. It’s common for statistical software to report only statistical and not
    substantive significance. Our Excel output is one such case: while it returns
    the p-value, it does not return the *confidence interval*, or the range within
    which we’d expect to find our population.'
  prefs: []
  type: TYPE_NORMAL
- en: We can use the so-called critical value of our test, displayed in cell `F14`
    of [Figure 3-3](#t-test-output), to derive the confidence interval. The number
    (1.97) may seem arbitrary, but you can actually make sense of it given what you
    learned in [Chapter 2](ch02.html#foundations-of-probability). With this t-test,
    we have taken a sample difference in average home prices. Were we to continue
    taking random samples and plotting the distribution of the mean differences, this
    distribution would be…that’s right, *normal*, due to the central limit theorem.
  prefs: []
  type: TYPE_NORMAL
- en: With a normal distribution, we can expect about 95% of observations to fall
    within two standard deviations of the mean thanks to the empirical rule. In the
    special case of a normally distributed variable with a mean of 0 and standard
    deviation of 1 (called a *standard* normal distribution), we could say that about
    95% of all observations would fall between –2 and 2\. To be a little more specific,
    they would be between –1.96 and 1.96, and that is how the two-tailed critical
    value is derived. [Figure 3-4](#confidence-95) illustrates the area within which
    we’d expect to find the population’s parameter with 95% confidence.
  prefs: []
  type: TYPE_NORMAL
- en: '![Confidence interval example](assets/aina_0304.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-4\. The 95% confidence interval and critical value visualized on a
    histogram
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Equation 3-1](#confidence-interval-formula) displays the formula for finding
    the confidence interval of a two-tailed independent samples t-test. We’ll calculate
    the labeled elements in Excel.'
  prefs: []
  type: TYPE_NORMAL
- en: Equation 3-1\. Formula for finding the confidence interval
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: <math alttext="c period i period equals left-parenthesis upper X overbar Subscript
    1 Baseline minus upper X overbar Subscript 2 Baseline right-parenthesis plus-or-minus
    t a Subscript slash 2 Baseline times StartRoot StartFraction s 1 squared Over
    n 1 EndFraction plus StartFraction s 2 squared Over n 2 EndFraction EndRoot" display="block"><mrow><mtext>c.</mtext>
    <mi>i</mi> <mo>.</mo> <mo>=</mo> <mfenced close=")" open="(" separators=""><msub><mover
    accent="true"><mi>X</mi> <mo>¯</mo></mover> <mn>1</mn></msub> <mo>-</mo> <msub><mover
    accent="true"><mi>X</mi> <mo>¯</mo></mover> <mn>2</mn></msub></mfenced> <mo>±</mo>
    <mi>t</mi> <msub><mi>a</mi> <mrow><mo>/</mo><mn>2</mn></mrow></msub> <mo>×</mo>
    <msqrt><mrow><mfrac><msubsup><mi>s</mi> <mrow><mn>1</mn></mrow> <mn>2</mn></msubsup>
    <msub><mi>n</mi> <mn>1</mn></msub></mfrac> <mo>+</mo> <mfrac><msubsup><mi>s</mi>
    <mrow><mn>2</mn></mrow> <mn>2</mn></msubsup> <msub><mi>n</mi> <mn>2</mn></msub></mfrac></mrow></msqrt></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: To break this formula down, <math alttext="left-parenthesis upper X overbar
    Subscript 1 Baseline minus upper X overbar Subscript 2 Baseline right-parenthesis"><mfenced
    close=")" open="(" separators=""><msub><mover accent="true"><mi>X</mi> <mo>¯</mo></mover>
    <mn>1</mn></msub> <mo>-</mo> <msub><mover accent="true"><mi>X</mi> <mo>¯</mo></mover>
    <mn>2</mn></msub></mfenced></math> is the point estimate, <math alttext="t a Subscript
    slash 2"><mrow><mi>t</mi> <msub><mi>a</mi> <mrow><mo>/</mo><mn>2</mn></mrow></msub></mrow></math>
    is the critical value, and <math alttext="StartRoot StartFraction s 1 squared
    Over n 1 EndFraction plus StartFraction s 2 squared Over n 2 EndFraction EndRoot"><msqrt><mrow><mfrac><msubsup><mi>s</mi>
    <mrow><mn>1</mn></mrow> <mn>2</mn></msubsup> <msub><mi>n</mi> <mn>1</mn></msub></mfrac>
    <mo>+</mo> <mfrac><msubsup><mi>s</mi> <mrow><mn>2</mn></mrow> <mn>2</mn></msubsup>
    <msub><mi>n</mi> <mn>2</mn></msub></mfrac></mrow></msqrt></math> is the standard
    error. The product of the critical value and the standard error is the margin
    of error.
  prefs: []
  type: TYPE_NORMAL
- en: This equation can be pretty intimidating, so to make it more concrete I’ve already
    calculated the confidence interval and its various elements for our example in
    [Figure 3-5](#confidence-interval-excel). Rather than get hung up over the formal
    equation, our focus will be on computing the results and understanding what they
    tell us.
  prefs: []
  type: TYPE_NORMAL
- en: '![Confidence interval calculations in Excel](assets/aina_0305.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-5\. Calculating the confidence interval in Excel
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: First, the *point estimate* in cell `F16`, or the effect in the population we
    are most likely to find. This is the difference in our sample means. After all,
    if our sample is representative of the population, the difference in sample and
    population means should be negligible. But it probably won’t be exactly the same;
    we will derive a range of values within which we are 95% confident we’ll find
    that true difference.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the critical value in cell `F17`. Excel provided this number for us, but
    I’ve included it here for ease of analysis. As described previously, we can use
    this value to help us find the 95% of values that fall within approximately two
    standard deviations of the mean.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have the standard error in cell `F18`. You’ve actually seen this term
    before, in the ToolPak’s descriptive statistics output; see [Figure 3-1](#price-by-ac)
    as an example. To understand how the standard error works, imagine if you were
    to go out and resample housing prices from the population over and over. Each
    time, you’d get slightly different sample means. That variability is known as
    the *standard error*. A larger standard error means that a sample is less accurate
    in representing a population.
  prefs: []
  type: TYPE_NORMAL
- en: 'The standard error for one sample can be found by dividing its standard deviation
    by its sample size. Because we are finding the standard error for a *difference*
    in means, the formula is a bit more complicated, but the same pattern holds: the
    variability of the samples goes in the numerator, and the number of observations
    goes in the denominator. This makes sense: we’d expect more variability in a sample
    difference when each sample mean itself contains more variability; as we collect
    larger sample sizes, we’d expect them to exhibit less variability from the population.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now take the product of the critical value and the standard error to
    get the *margin of error* in cell `F19`. This may be a term you’ve heard of: polls
    are often reported with this figure included. The margin of error provides an
    estimate of just how much variability there is around our point estimate. In the
    case of [Figure 3-5](#confidence-interval-excel), we’re saying that while we think
    the population difference is $25,996, we could be off by as much as $4,784.'
  prefs: []
  type: TYPE_NORMAL
- en: Because this is a two-tailed test, this difference could be found in *either
    direction*. So we’ll need to both subtract and add the margin of error to derive
    the lower and upper bounds of our confidence interval, respectively. Those figures
    are found in `F20` and `F21`, respectively. The bottom line? With 95% confidence,
    we believe that the average price of a home with air conditioning has a sale price
    of between $21,211 and $30,780 higher than one without air conditioning.
  prefs: []
  type: TYPE_NORMAL
- en: Why go through all the trouble to derive a confidence interval? As a measure
    of substantive rather than statistical significance, it often plays better with
    general audiences because it translates the results of the statistical hypothesis
    test back into the language of the research hypothesis. For example, imagine you
    were a research analyst at a bank reporting the results of this study on home
    prices to management. These managers wouldn’t know where to start conducting a
    t-test if their careers depended on it—but their careers *do* depend on making
    smart decisions from that analysis, so you want to make it as intelligible as
    possible. Which statement do you think will be more helpful?
  prefs: []
  type: TYPE_NORMAL
- en: “We rejected the null that there is no difference in the average sale price
    of homes with or without air conditioning at p < 0.05.”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “With 95% confidence, the average sale price of homes with air conditioning
    is approximately between $21,200 and $30,800 higher than those without.”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nearly anyone can make sense of the second statement, whereas the first requires
    a fair amount of statistical know-how. But confidence intervals aren’t just for
    laypeople: there’s also been a push in research and data circles to report them
    along with p-values. After all, the p-value *only* measures statistical effect,
    *not* substantive.'
  prefs: []
  type: TYPE_NORMAL
- en: But while p-values and confidence intervals show the results from different
    angles, they are fundamentally *always in agreement*. Let’s illustrate this concept
    by conducting another hypothesis test on the *housing* dataset. This time, we
    would like to know if there is a significant difference in the average lot size
    (*lotsize*) of homes with and without a full, finished basement (*fullbase*).
    This relationship can also be tested with a t-test; I will follow the same steps
    as before in a new worksheet, which results in [Figure 3-6](#fullbase-lotsize).
    (Don’t forget to explore the descriptive statistics of these new variables first.)
  prefs: []
  type: TYPE_NORMAL
- en: '![t-test output](assets/aina_0306.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-6\. The effect on lot size of having a full finished basement
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The results of this test are *not* statistically significant: based on the
    p-value of 0.27, we’d expect to find the effect we did in over one-quarter of
    our samples, assuming no effect in the population. As for the substantive significance,
    we are 95% confident that the difference in average lot size is between approximately
    167 square feet less and 599 square feet more. In other words, the true difference
    could be positive *or* negative, we can’t say for sure. Based on either of these
    results, we fail to reject the null: there does not appear to be a significant
    difference in average lot size. These results will always agree because they are
    both based in part on the level of statistical significance: alpha determines
    how we evaluate the p-value and sets the critical value used to derive the confidence
    interval.'
  prefs: []
  type: TYPE_NORMAL
- en: If you’ve ever built a financial model, you might be familiar with doing a what-if
    analysis on your work to see how its output might change given your inputs or
    assumptions. In that same spirit, let’s examine how the results of our basement/lot
    size t-test might have been different. Because we’ll be manipulating the results
    of our ToolPak output, it’s wise to copy and paste the data in cells `E2:G21`
    into a new range so the original is preserved. I’ll place mine in cells `J2:L22`
    of the current worksheet. I will also relabel my output and highlight the cells
    `K6:L6` and `K14` so that it’s clear they’ve been tampered with.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s manipulate the sample sizes and critical value here. Without looking at
    the resulting confidence interval, try to guess what will happen based on what
    you know about how these figures relate. First, I will set the sample size to
    550 observations for each group. This is a dangerous game to play; we didn’t *actually*
    collect 550 observations, but to understand statistics you sometimes have to get
    your hands dirty. Next, we’ll change our statistical significance from 95% to
    90%. The resulting critical value is 1.64\. This is also dicey; statistical significance
    should be locked in prior to analysis for the reason that you are about to see
    right now.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3-7](#what-if-analysis) displays the result of this what-if analysis.
    Our confidence interval of between $1 and $430 indicates statistical significance,
    although just barely—it’s awfully close to zero.'
  prefs: []
  type: TYPE_NORMAL
- en: '![t-test output](assets/aina_0307.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-7\. A what-if analysis of the confidence interval
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: There are ways to calculate the corresponding p-value, but because you know
    it is always fundamentally in agreement with the confidence interval, we’ll skip
    that exercise. Our test is now significant, and that can make all the difference
    for funding, fame, and glory.
  prefs: []
  type: TYPE_NORMAL
- en: The moral of the story is that the results of hypothesis testing can be easily
    gamed. Sometimes, all it takes is a different level of statistical significance
    to tip the balance to rejecting the null. Resampling or, in our example, falsely
    bulking up the number of observations could also do it. Even absent foul play,
    there will always be a gray area in claiming to find the parameter of a population
    you don’t actually know.
  prefs: []
  type: TYPE_NORMAL
- en: It’s Your World…the Data’s Only Living in It
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s tempting to go into autopilot when conducting inferential statistics, just
    plugging and chugging p-values without regard for broader considerations about
    data collection or substantive significance. You’ve already seen how sensitive
    the results can be to changes in statistical significance or sample size. To show
    another possibility, let’s take one more example from the *housing* dataset.
  prefs: []
  type: TYPE_NORMAL
- en: On your own, test for a significant difference in the sale price of homes with
    and without gas for water heating. The relevant variables are *price* and *gashw*.
    The results are shown in [Figure 3-8](#gas-t-test).
  prefs: []
  type: TYPE_NORMAL
- en: '![t-test output](assets/aina_0308.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-8\. t-test results of the effect on sale price of using gas
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Going by the p-value alone, we should fail to reject the null: after all, it’s
    greater than 0.05. But 0.067 is not *that* different, so it’s worth paying closer
    attention here. For one thing, consider the sample sizes: at just 25 observations
    of homes with gas, it may be worth collecting more data before definitively rejecting
    the null. Granted, you probably would have observed this sample size prior to
    running the test, during descriptive statistics.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By the same token, the confidence interval posits that the true difference
    is anywhere between approximately $900 less and $24,500 more. With that kind of
    money on the table, it’s worth digging further into the problem. If you were just
    to blindly reject the null due to the p-value, you may miss out on a potentially
    important relationship. Be aware of these potential “edge cases”: if one already
    came up here in this dataset, you can bet you’ll find more in your data work.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Statistics and analytics are powerful tools for making sense of the world,
    but they’re just that: tools. Without a skilled craftsperson in control, they
    can be useless at best and harmful at worst. Don’t be content to take the p-value
    on its face; consider the broader context of how statistics works and the objective
    you’re aiming to meet (without gaming the results, as you’ve seen is possible).
    Remember: it’s your world, the data’s only living in it.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You may have been wondering earlier why, in a book on analytics, we spent a
    chapter on the seemingly obscure topic of probability. I hope the connection is
    now clear: because we don’t know parameters of the population, we must quantify
    this uncertainty as a probability. In this chapter, we’ve used the framework of
    inferential statistics and hypothesis testing to explore the difference in means
    between two groups. In the next, we’ll use it to examine the influence of one
    continuous variable on another, in a method you may have heard of: linear regression.
    Although a different test, the statistical framework behind it remains the same.'
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now it’s your turn to make probabilistic inferences about a dataset. Find the
    *tips.xlsx* dataset in the *datasets* folder and *tips* subfolder of the book’s
    [companion repository](https://oreil.ly/1hlYj), and try the following exercises:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Test the relationship between the time of day (lunch or dinner) and the total
    bill:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are your statistical hypotheses?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Are your results statistically significant? What evidence does this lend to
    your hypotheses?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the estimated effect size?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer the same questions, but for the relationship between the time of day
    and the tip.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
