<html><head></head><body><section data-pdf-bookmark="Chapter 11. Beyond Python" data-type="chapter" epub:type="chapter"><div class="chapter" id="chapter11">&#13;
<h1><span class="label">Chapter 11. </span>Beyond Python</h1>&#13;
&#13;
&#13;
<p>Python is an exceptionally powerful and versatile tool for working with data, and if you’ve followed along with the exercises in this book, you are hopefully starting to feel confident about using it to move your own data wrangling projects forward. Thanks to the vibrant Python community and the constantly evolving suite of helpful libraries that its members create and maintain, the work you’ve put into learning the fundamentals in this book will still be valuable whether your next data wrangling project comes along tomorrow or next year. Also, while Python as a programming language is unique in many ways, the programming skills and vocabulary that you’ve acquired here will give you a head start with other programming languages, especially ones relatively object-oriented ones like JavaScript.</p>&#13;
&#13;
<p>Still, one thing I’ve tried to clarify throughout this book is that there are times when the “programmatic” solution to a problem is not <em>really</em> the most efficient one. Our work with Excel and XML files in <a data-type="xref" href="ch04.html#chapter4">Chapter 4</a>, for example, highlighted that sometimes trying to do things programmatically just doesn’t make sense. For example, while in <a data-type="xref" href="ch04.html#xml_parsing">Example 4-12</a> we <em>could</em> have written a Python script to traverse our entire XML document in order to discover its structure, it was undoubtedly faster and easier to simply <em>look</em> at our data, identify the elements that interested us, and write our Python program to target them directly. Likewise, there are times when writing a Python program <em>at all</em> can be more effort than a particular data wrangling project really requires, especially if it is smaller or more exploratory. Though <em>pandas</em> is an incredibly useful library, you can still end up writing a fair amount of code just to get a basic sense of what a new dataset contains. In other words, while I fully believe that the power and versatility of Python makes it an indispensable data wrangling tool, I also want to highlight a few other free and/or open source tools that I think you’ll find useful<sup><a data-type="noteref" href="ch11.html#idm45143393541072" id="idm45143393541072-marker">1</a></sup> as a complement to Python in your data wrangling projects.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Additional Tools for Data Review" data-type="sect1"><div class="sect1" id="idm45143393540384">&#13;
<h1>Additional Tools for Data Review</h1>&#13;
&#13;
<p>Python offers great speed and flexibility when it comes to actually accessing and wrangling data, but it’s not particularly well suited to letting you actually <em>look</em> at your data. So throughout this book we’ve relied on basic text editors (and occasionally web browsers) when we want to browse our dataset visually. While text editors are a great first step for this, you’ll also want to get comfortable with at least one of each of the following program types to help you get a quick initial overview of your data—especially if the files you’re working with are not too large.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Spreadsheet Programs" data-type="sect2"><div class="sect2" id="idm45143393537936">&#13;
<h2>Spreadsheet Programs</h2>&#13;
&#13;
<p>It’s <a data-primary="data review" data-secondary="spreadsheet programs for" data-type="indexterm" id="data-review-spreadsheet"/><a data-primary="spreadsheets" data-secondary="for data review" data-secondary-sortas="data review" data-type="indexterm" id="spreadsheet-data-review"/><a data-primary="reviewing data" data-see="data review" data-type="indexterm" id="idm45143393533408"/>possible that before you began reading this book you were already familiar with spreadsheet programs—whether online versions like Google Sheets, paid local software options like Microsoft Excel, or contribution-supported, open source alternatives like Libre Office Calc. Spreadsheet programs typically come bundled with “office”-style software suites and offer basic calculation, analysis, and charting functionality. In general, there is not a huge variation in what these programs can do, though some are more flexible than others. I<a data-primary="LibreOffice" data-type="indexterm" id="idm45143393531776"/> prefer <a href="https://libreoffice.org">LibreOffice</a>, for example, because it is free, open source, and works across platforms (including less common ones, like Linux). It even has a certified app for Chromebooks and Android devices<a data-primary="Collabora" data-type="indexterm" id="idm45143393530096"/> called <a href="https://collaboraoffice.com/press-releases/collabora-office-ships-for-chromebooks">Collabora</a>. That said, if you already have or are familiar with a particular spreadsheet program, there is no important reason to switch to any other, as long as you are not going broke paying for it. Whatever you do, do <em>not</em> use pirated software; in a world where ransomware is running rampant—i.e., this one—it’s simply not worth the risk to your devices and data!</p>&#13;
&#13;
<p>While many spreadsheet programs have advanced functions that approximate what Python does (on a much smaller scale), I usually find myself turning to them for very specific data wrangling and assessment tasks. In particular, I will often use a spreadsheet program to quickly do the following:</p>&#13;
<dl>&#13;
<dt>Change file formats</dt>&#13;
<dd>&#13;
<p>For example, if my data is provided as an multisheet XLSX file, I might open it in a spreadsheet program and save only the sheet I am interested in as a <em>.csv</em>.</p>&#13;
</dd>&#13;
<dt>Rename columns</dt>&#13;
<dd>&#13;
<p>If there are not many columns, I may change those with awkward or nondescript headers to be something more readable and/or intuitive for my purposes.</p>&#13;
</dd>&#13;
<dt>Get a “feel” for data values</dt>&#13;
<dd>&#13;
<p>Are the values provided in a “date” column actually dates? Or are they simply years? Are there a lot of obviously missing data values? If my dataset is relatively small, just visually scanning through the data in a spreadsheet program can sometimes be enough to determine whether I have the data I need—or if I need to move on.</p>&#13;
</dd>&#13;
<dt>Generate basic summary statistics</dt>&#13;
<dd>&#13;
<p>Of course I can do this in Python, and most of the time I do. But if I have only a few hundred rows of data, typing <code>=MEDIAN()</code> and then selecting the cells of interest is sometimes faster, especially if my original data file has metadata in it that would otherwise need to be stripped out (as we saw in <a data-type="xref" href="ch04.html#chapter4">Chapter 4</a> and again in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch07.html#chapter7">7</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch08.html#chapter8">8</a>).</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Of course, every tool comes with its trade-offs, and previewing data in a spreadsheet program can create some unexpected results. As you might guess from our extended adventures in dealing with XLS-style “dates,” previewing a file that contains date-like values can cause them to display very differently according to particular spreadsheet program and its default handling and rendering of dates. As a result, you should <em>always</em> inspect date-like values using a text editor if the original data format is text based (e.g., <em>.csv</em>, <em>.tsv</em>, or <em>.txt</em>). Likewise, be sure to confirm the formatting (whether default or applied) on any number-containing cells, as truncating or rounding of values can obscure important variations in your <a data-primary="data review" data-secondary="spreadsheet programs for" data-startref="data-review-spreadsheet" data-type="indexterm" id="idm45143393387136"/><a data-primary="spreadsheets" data-secondary="for data review" data-secondary-sortas="data review" data-startref="spreadsheet-data-review" data-type="indexterm" id="idm45143393385872"/>data.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="OpenRefine" data-type="sect2"><div class="sect2" id="idm45143393384256">&#13;
<h2>OpenRefine</h2>&#13;
&#13;
<p>One of<a data-primary="data review" data-secondary="OpenRefine for" data-type="indexterm" id="data-review-openrefine"/><a data-primary="OpenRefine" data-type="indexterm" id="openrefine"/> the tools I turn to most for my initial exploration of larger, structured datasets is <a href="https://openrefine.org">OpenRefine</a>. In my experience, OpenRefine has proved to be a unique software tool that helps bridge the gap between traditional spreadsheet programs and full-on programming languages like Python. Like spreadsheet programs, OpenRefine operates through a graphical user interface (GUI), so most of your work with it will involve pointing and clicking with a mouse. <em>Unlike</em> spreadsheet programs, however, you don’t scroll through rows of data to get a sense of what they contain; instead, you can use menu options to create <em>facets</em> that provide summary information similar to that provided by the <a href="https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html">pandas <code>value_counts()</code> method</a>—but without needing to write any code. OpenRefine also supports batch editing, implements several algorithms for string matching (including the fingerprinting method we used in <a data-type="xref" href="ch06.html#ppp_lender_names">Example 6-11</a>), and can import large files in segments (e.g., 100,000 rows at a time). In truth, OpenRefine is often my first stop when wrangling a new dataset, because it easily opens a variety of data formats and even offers a handy live preview of how the data will be parsed based on your selection of delimiters, for example. Once your dataset is loaded, OpenRefine can also provide almost one-click answers to questions like “What is the most common value in column <em>x</em>?” Finally, any time you make an actual change to a data file in OpenRefine (as opposed to just clustering or faceting it), it automatically records your actions in an exportable <em>.json</em> file that you can then apply to a <em>different</em> OpenRefine file in order to have those actions automatically repeated (usually in seconds). This is incredibly useful if you need to rename or rearrange data columns for a dataset that is regularly updated by the data provider. It’s even <em>more</em> useful, however, if you need <em>someone else</em> to be able to do it and they don’t have or cannot use Python.</p>&#13;
&#13;
<p>For the most part, I use OpenRefine to easily do the following:</p>&#13;
<dl>&#13;
<dt>Preview small pieces of large datasets</dt>&#13;
<dd>&#13;
<p>OpenRefine allows you to load (and skip) as many<a data-primary="partial datasets, loading in OpenRefine" data-type="indexterm" id="idm45143393371152"/><a data-primary="loading partial datasets in OpenRefine" data-type="indexterm" id="idm45143393370384"/> rows in your dataset as you like. This is especially handy for large datasets when I want to get a reasonable sense of what they contain, but I know truly nothing about them. I can start by loading 50,000 or 100,000 rows and use facets and other functions to get an overview of, say, what the data types are and how the overall dataset is organized.</p>&#13;
</dd>&#13;
<dt>Get quick top-line information about a dataset</dt>&#13;
<dd>&#13;
<p>What’s <a class="orm:hideurl" href="https://data.cityofnewyork.us/City-Government/Film-Permits/tg4x-b46p">the most common type of film permit requested in New York City</a>? And what is the most popular borough? As shown in <a data-type="xref" href="#openrefine_film_facets">Figure 11-1</a>, OpenRefine can give you these counts in one or two clicks and allows you to create cross-tabulations just as quickly.</p>&#13;
</dd>&#13;
<dt>Do basic transformations that spreadsheet programs don’t support</dt>&#13;
<dd>&#13;
<p>Some spreadsheet programs lack functionality, like the ability to split a string on a particular character, or may have limited regular expression support. One of my favorite features of OpenRefine is batch editing, <a data-primary="batch editing in OpenRefine" data-type="indexterm" id="idm45143393364576"/>which you can do quickly and easily through the lefthand facet window.</p>&#13;
</dd>&#13;
<dt>Autogenerate macros</dt>&#13;
<dd>&#13;
<p>Many spreadsheet<a data-primary="macros" data-type="indexterm" id="idm45143393362448"/> programs will let you record <em>macros</em> that automate certain actions, but OpenRefine records these for you by default—making it a more powerful tool with a lower learning curve for this type of task.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Of course, there are some aspects of working with OpenRefine that can take some getting used to. First, while installation is getting more user friendly, it relies on having another programming language, called Java, installed on your computer, so getting it up and running can be a multistep process. Launching the program once it’s installed is also a little unusual: You need to both click (or double-click) on the program icon to launch and, in some cases, open a browser window pointed to your “localhost” address (typically <code>http://127.0.0.1:3333/</code> or <code>http://localhost:3333</code>). Like Jupyter Notebook, OpenRefine actually runs through a tiny web server on your computer, and the interface is just a web page that behaves sort of like a supercharged spreadsheet program. Despite these quirks, OpenRefine is <em>incredibly</em> useful and often a great place to start when you want to do some initial<a data-primary="data review" data-secondary="OpenRefine for" data-startref="data-review-openrefine" data-type="indexterm" id="idm45143393358400"/><a data-primary="OpenRefine" data-startref="openrefine" data-type="indexterm" id="idm45143393357152"/> exploration of a (potentially messy) dataset.</p>&#13;
&#13;
<figure><div class="figure" id="openrefine_film_facets">&#13;
<img alt="OpenRefine NYC Film Permit Facets." src="assets/ppdw_1101.png"/>&#13;
<h6><span class="label">Figure 11-1. </span>OpenRefine NYC film permit facets</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Additional Tools for Sharing and Presenting Data" data-type="sect1"><div class="sect1" id="idm45143393353872">&#13;
<h1>Additional Tools for Sharing and Presenting Data</h1>&#13;
&#13;
<p>In <a data-type="xref" href="ch10.html#chapter10">Chapter 10</a>, we <a data-primary="data presentations" data-see="visualizations" data-type="indexterm" id="idm45143393351248"/><a data-primary="presenting data" data-see="visualizations" data-type="indexterm" id="idm45143393350272"/><a data-primary="sharing data" data-see="visualizations" data-type="indexterm" id="idm45143393349328"/>focused on how to select and refine visualizations using Python and key libraries like <code>seaborn</code> and <code>matplotlib</code>. While the degree of customization that you can achieve using these tools is impressive, there are times when you may need to make a small tweak to a visualization and you may not want—or be able—to regenerate it from the original data source with Python.</p>&#13;
&#13;
<p>If you need to quickly add or change something minor on a visualization, having access to image editing software is valuable. And while you’re probably familiar with the very powerful—and very expensive—commercial software applications for editing images, you may not realize that there are similarly powerful tools that are free and open source.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Image Editing for JPGs, PNGs, and GIFs" data-type="sect2"><div class="sect2" id="idm45143393346368">&#13;
<h2>Image Editing for JPGs, PNGs, and GIFs</h2>&#13;
&#13;
<p>For<a data-primary="visualizations" data-secondary="image-editing software" data-type="indexterm" id="idm45143393345072"/><a data-primary="image-editing software" data-type="indexterm" id="idm45143393344064"/><a data-primary="GIMP (GNU Image Manipulation Program)" data-type="indexterm" id="idm45143393343392"/><a data-primary="pixel-based images, editing software for" data-type="indexterm" id="idm45143393342656"/> editing pixel-based images, the GNU Image Manipulation Program (GIMP) is an especially good option if you’re looking for something powerful but you can’t (or don’t want to) pay a lot for it. <a href="https://gimp.org">GIMP</a> is free and open source, and it works across platforms. While the style of its user interface is decidedly outdated (the interface is being overhauled at the time of this writing), the reality is that the program itself can probably do whatever basic (and not-so-basic) high-quality image editing you may need, especially if you’re just looking to add (or remove) some text or annotations from an image, update the axis labels, etc.</p>&#13;
&#13;
<p>It’s true that GIMP can have a somewhat steep learning curve. The keyboard shortcuts may not be what you expect, and the placement of some menus and the look of their icons do not match what you’ll see in commercial software. That said, unless you are an expert in another image editing program and you are willing to pay (and continue to pay) for access to it, whatever time you invest in learning GIMP will be well worth it. Especially if what you need is occasional access to image editing software, GIMP is a powerful and flexible choice.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Software for Editing SVGs and Other Vector Formats" data-type="sect2"><div class="sect2" id="idm45143393339344">&#13;
<h2>Software for Editing SVGs and Other Vector Formats</h2>&#13;
&#13;
<p>If you<a data-primary="vector-based images, editing software for" data-type="indexterm" id="idm45143393338048"/> plan to use your visualizations for print or other high-resolution (or flexible-resolution) contexts, you may well choose to save it in a vector format. Although the file sizes are larger, vector graphics are much more flexible than their pixel-driven counterparts; they can be scaled up and down without losing quality by becoming pixelated or blurry. They can’t, however, be edited effectively with bitmap software like GIMP.</p>&#13;
&#13;
<p>Once again, if you have the budget for commercial software, you should go ahead<a data-primary="Inkscape" data-type="indexterm" id="idm45143393336384"/> and use it—but here, too, you have a free and open source option. Like GIMP, <a href="https://inkscape.org">Inkscape</a> is free, open source, and cross platform. And, like GIMP, it has almost all the same features as expensive commercial vector editing software. Even better, if you take the time to get comfortable with vector editing software, it won’t just let you tweak your digital-to-print data graphics—vector editing software is also essential to T-shirt printing, laser cutting, and lots of other digital-to-physical work. If you’re just starting out, Inkscape is also definitely the right price: free!</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="about_foss_sidebar">&#13;
<h5>About FOSS</h5>&#13;
<p><em>FOSS</em> is<a data-primary="FOSS (Free and Open Source Software)" data-type="indexterm" id="FOSS"/> an acronym for Free and Open Source Software, and many FOSS programs—like GIMP and Inkscape—have been around for decades. Despite the fact that most of us are much more familiar with brand-name software made by companies like Apple, Microsoft, Google, and others, the fact is that a large portion of the software that runs both computers and the internet today is based on programs, packages, and libraries that—like the Python packages and libraries we’ve used throughout this book—are free for anyone to access and use. In many cases, it’s even legal to create and sell products that have FOSS software at their core—and this is something that lots of companies do.</p>&#13;
&#13;
<p>While free and open source software helps ensure that the tools for innovation aren’t locked away as the intellectual property of big companies, the reality is that building, maintaining, and enhancing these tools isn’t <em>actually</em> free. It’s made possible by the work of volunteers—some of whom are allowed to use work hours paid for by their company to do it—but many of whom do it unpaid.</p>&#13;
&#13;
<p>The fact that FOSS tools are free for everyone helps keep data wrangling work accessible, and I (obviously) recommend working with them if you can. At the same time, if you find yourself using them regularly and are able, I also recommend a small donation to the projects you use in order to help keep<a data-primary="FOSS (Free and Open Source Software)" data-startref="FOSS" data-type="indexterm" id="idm45143393328384"/> them going.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Reflecting on Ethics" data-type="sect1"><div class="sect1" id="idm45143393327008">&#13;
<h1>Reflecting on Ethics</h1>&#13;
&#13;
<p>The <a data-primary="data wrangling" data-secondary="ethical standards checklist" data-type="indexterm" id="data-wrangling-ethics"/><a data-primary="data quality" data-secondary="ethical standards checklist" data-type="indexterm" id="data-quality-ethics"/><a data-primary="ethics" data-secondary="standards checklist" data-type="indexterm" id="ethics-checklist"/>main focus of this book has been on building data wrangling skills—in large part to support our interest in assessing and improving data quality. Along the way, we’ve touched on the broader implications of data quality, both abstractly and concretely. Poor data quality can lead to analyses that produce a misleading, distorted, or discriminatory view of the world; couple this with <a class="orm:hideurl" href="https://penguinrandomhouse.com/books/241363/weapons-of-math-destruction-by-cathy-oneil">the scale and ubiquity of data-driven systems</a> today, and the resulting harms can be substantial and far-reaching. While you can use the methods in this book to test and improve the quality of your data, there is unfortunately still plenty of room for “good-quality” data to be obtained unethically. And just as with every other part of the data wrangling process, it’s up to you to decide what kind of data you’re comfortable working with and for what purposes.</p>&#13;
&#13;
<p>One strategy for ensuring that your data wrangling work doesn’t unintentionally violate your own ethical standards is to develop a checklist. By developing a list of questions you ask yourself about your data sources and how the output of your analysis will be used, you can determine early on if a given data wrangling project is one you’re willing to pursue. The following checklist is adapted from one shared by data experts <a href="https://oreilly.com/radar/of-oaths-and-checklists">DJ Patil, Hilary Mason, and Mike Loukides</a>. Like the list of data characteristics in <a data-type="xref" href="ch03.html#chapter3">Chapter 3</a>, the purpose here is not to reject a data project unless the answer to every question is “yes”; the goal is to think critically about <em>all</em> aspects of data quality—including those that may be outside our control. True, we may only be able to decline (rather than change) a project that doesn’t meet our ethical standards, but if you voice your concerns, you may help make room for others to do the same. At worse, the project is taken on by someone else and your conscience is (somewhat) clear. At best, you may inspire others to consider the ethical implications of their work before they take on their next project as well. Here are some questions that you might want to include:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Does the design of the data collection reflect the values of the community it is about?</p>&#13;
</li>&#13;
<li>&#13;
<p>Do the members of that community know that it was collected, and did they have a meaningful way to decline?</p>&#13;
</li>&#13;
<li>&#13;
<p>Has the data been evaluated for representativeness?</p>&#13;
</li>&#13;
<li>&#13;
<p>Is there a way to test the data for bias?</p>&#13;
</li>&#13;
<li>&#13;
<p>Are our data features accurate proxies for the phenomena we want to describe?</p>&#13;
</li>&#13;
<li>&#13;
<p>Will our analysis be replaced if and when the data becomes out of date?</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>Ultimately, you may decide that your own concerns about data have a different focus. Whatever you choose to include in your own checklist, however, you’ll find your data principles much easier to stick to if you lay them out<a data-primary="data wrangling" data-secondary="ethical standards checklist" data-startref="data-wrangling-ethics" data-type="indexterm" id="idm45143393310128"/><a data-primary="data quality" data-secondary="ethical standards checklist" data-startref="data-quality-ethics" data-type="indexterm" id="idm45143393308864"/><a data-primary="ethics" data-secondary="standards checklist" data-startref="ethics-checklist" data-type="indexterm" id="idm45143393307632"/> in advance.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm45143393306160">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>Over the course of this book, we have covered everything from the basics of Python programming and data quality assessment to wrangling data from half-a-dozen file formats and APIs. We’ve applied our skills to some typically messy and problematic real-world data and refined our code to make future projects easier. We’ve even explored how to do basic data analysis and visually present our data in support of our insights.</p>&#13;
&#13;
<p>If you’ve made it this far, then I imagine by this point you’ve caught some sort of “bug”: for programming, for data, for analysis and visualization—or maybe all of the above. Whatever brought you to this book, I hope you’ve found at least some of what you were looking for, including, perhaps, the confidence to take the next step. Because whatever else may change about the world of data wrangling in the coming years, one thing is sure to be true: we need as many people as possible doing this work critically and thoughtfully. Why shouldn’t one of them be you?</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45143393541072"><sup><a href="ch11.html#idm45143393541072-marker">1</a></sup> I certainly do!</p></div></div></section></body></html>