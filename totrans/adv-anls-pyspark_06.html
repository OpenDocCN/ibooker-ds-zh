<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 6. Understanding Wikipedia &#10;with LDA and Spark NLP" data-type="chapter" epub:type="chapter"><div class="chapter" id="understanding_wikipedia_with_lda_and_spark_nlp">
<h1><span class="label">Chapter 6. </span>Understanding Wikipedia 
<span class="keep-together">with LDA and Spark NLP</span></h1>
<p>With the growing amount of unstructured text data in recent years,<a data-primary="natural language processing (NLP)" data-secondary="about" data-type="indexterm" id="idm46507975153040"/><a data-primary="natural language processing (NLP)" data-secondary="latent Dirichlet allocation" data-type="indexterm" id="idm46507975152096"/><a data-primary="Wikipedia document processing" data-secondary="latent Dirichlet allocation" data-type="indexterm" id="idm46507975151120"/><a data-primary="Spark NLP" data-secondary="latent Dirichlet allocation" data-type="indexterm" id="idm46507975150144"/><a data-primary="Wikipedia document processing" data-secondary="about natural language processing" data-type="indexterm" id="idm46507975149184"/><a data-primary="Spark NLP" data-secondary="about natural language processing" data-type="indexterm" id="idm46507975148208"/><a data-primary="NLP" data-see="natural language processing" data-type="indexterm" id="idm46507974782752"/> it has become difficult to obtain the relevant and desired information. Language technology provides powerful methods that can be used to mine through text data and fetch the information that we are looking for. In this chapter, we will use PySpark and the Spark NLP (natural language processing) library to use one such technique—topic modeling. Specifically, we will use the latent Dirichlet algorithm (LDA) to understand a dataset of Wikipedia documents.</p>
<p><em>Topic modeling</em>, one of the most common tasks<a data-primary="natural language processing (NLP)" data-secondary="topic modeling" data-type="indexterm" id="idm46507974781136"/><a data-primary="Wikipedia document processing" data-secondary="topic modeling" data-type="indexterm" id="idm46507974780288"/><a data-primary="topic modeling" data-type="indexterm" id="idm46507974779440"/> in natural language processing, is a statistical approach for data modeling that helps in discovering underlying topics that are present in a collection of documents. Extracting topic distribution from millions of documents can be useful in many ways—for example, identifying the reasons for complaints about a particular product or all products, or identifying topics in news articles. <a data-primary="latent Dirichlet allocation (LDA)" data-type="indexterm" id="idm46507974778704"/>The most popular algorithm for topic modeling is LDA. It is a generative model that assumes that documents are represented by a distribution of topics. Topics, in turn, are represented by a distribution of words. <a data-primary="MLlib component of Spark" data-secondary="LDA (latent Dirichlet algorithm)" data-type="indexterm" id="idm46507974777968"/>PySpark MLlib offers an optimized version of LDA that is specifically designed to work in a distributed environment. We will build a simple topic modeling pipeline using Spark NLP for preprocessing the data and Spark MLlib’s LDA to extract topics from the data.</p>
<p>In this chapter, we’ll embark upon the modest task of distilling the human knowledge based on latent (hidden) topics and relationships. We’ll apply LDA to a corpus consisting of the articles contained in Wikipedia. We will start by understanding the basics of LDA and go over its implementation in PySpark. Then we’ll download the dataset and set up our programming environment by installing Spark NLP. This will be followed by data preprocessing. You will witness the power of Spark NLP library’s out-of-the-box methods, which make NLP tasks significantly easier.</p>
<p>Then we will score the terms in our documents using the TF-IDF (term frequency-inverse document frequency) technique and feed the resulting output into our LDA model. To finish up, we’ll go through the topics assigned by our model to the input documents. We should be able to understand which bucket an entry belongs in without the need to read it. Let’s begin by going over the fundamentals of LDA.</p>
<section data-pdf-bookmark="Latent Dirichlet Allocation" data-type="sect1"><div class="sect1" id="idm46507974775824">
<h1>Latent Dirichlet Allocation</h1>
<p>The idea behind latent Dirichlet allocation<a data-primary="latent Dirichlet allocation (LDA)" data-type="indexterm" id="idm46507974774448"/><a data-primary="natural language processing (NLP)" data-secondary="latent Dirichlet allocation" data-type="indexterm" id="idm46507974773840"/><a data-primary="Wikipedia document processing" data-secondary="latent Dirichlet allocation" data-type="indexterm" id="idm46507974772992"/><a data-primary="Spark NLP" data-secondary="latent Dirichlet allocation" data-type="indexterm" id="idm46507974772144"/> is that documents are generated based on a set of topics. In this process, we assume that each document is distributed over the topics, and each topic is distributed over a set of terms. Each document and each word are generated from sampling these distributions. The LDA learner works backward and tries to identify the distributions where the observed is most probable.</p>
<p>It attempts to distill the corpus into<a data-primary="latent Dirichlet allocation (LDA)" data-secondary="topics" data-type="indexterm" id="idm46507974770560"/><a data-primary="topic modeling" data-secondary="topics in LDA" data-type="indexterm" id="idm46507974769712"/><a data-primary="LDA" data-see="latent Dirichlet allocation" data-type="indexterm" id="idm46507974768864"/><a data-primary="natural language processing (NLP)" data-secondary="topic modeling" data-tertiary="topics in LDA" data-type="indexterm" id="idm46507974768016"/><a data-primary="Wikipedia document processing" data-secondary="topic modeling" data-tertiary="topics in LDA" data-type="indexterm" id="idm46507974766928"/> a set of relevant <em>topics</em>.  Each topic captures a thread of variation in the data and often corresponds to one of the ideas that the corpus discusses. A document can be a part of multiple topics. You can think of LDA as providing a way to <em>soft cluster</em> the documents, too. Without delving into the mathematics, an LDA topic model describes two primary attributes: a chance of selecting a topic when sampling a particular document, and a chance of selecting a particular term when selecting a topic.
For example, LDA might discover a topic with strong association with the terms “Asimov” and “robot,” and with the documents “foundation series” and “science fiction.”  By selecting only the most important concepts, LDA can throw away some irrelevant noise and merge co-occurring strands to come up with a simpler representation of the data.</p>
<p>We can employ this technique in a variety of tasks. For example, it can help us recommend similar Wikipedia entries when provided with an input entry. By encapsulating the patterns of variance in the corpus, it can base scores on a deeper understanding than simply on counting occurrences and co-occurrences of words. Up next, let’s have a look at PySpark’s LDA implementation.</p>
<section data-pdf-bookmark="LDA in PySpark" data-type="sect2"><div class="sect2" id="idm46507974764560">
<h2>LDA in PySpark</h2>
<p>PySpark MLlib offers an LDA implementation<a data-primary="Wikipedia document processing" data-secondary="latent Dirichlet allocation" data-tertiary="PySpark implementation" data-type="indexterm" id="idm46507974763184"/><a data-primary="Spark NLP" data-secondary="latent Dirichlet allocation" data-tertiary="PySpark implementation" data-type="indexterm" id="idm46507974762096"/><a data-primary="natural language processing (NLP)" data-secondary="latent Dirichlet allocation" data-tertiary="PySpark implementation" data-type="indexterm" id="idm46507974761008"/><a data-primary="latent Dirichlet allocation (LDA)" data-secondary="PySpark implementation" data-type="indexterm" id="idm46507974759920"/> as one of its clustering algorithms. Here’s some example code:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code><code> </code><code class="nn">pyspark</code><code class="nn">.</code><code class="nn">ml</code><code class="nn">.</code><code class="nn">linalg</code><code> </code><code class="kn">import</code><code> </code><code class="n">Vectors</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">pyspark</code><code class="nn">.</code><code class="nn">ml</code><code class="nn">.</code><code class="nn">clustering</code><code> </code><code class="kn">import</code><code> </code><code class="n">LDA</code><code>
</code><code>
</code><code class="n">df</code><code> </code><code class="o">=</code><code> </code><code class="n">spark</code><code class="o">.</code><code class="n">createDataFrame</code><code class="p">(</code><code class="p">[</code><code class="p">[</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">Vectors</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="p">[</code><code class="mf">0.0</code><code class="p">,</code><code> </code><code class="mf">1.0</code><code class="p">]</code><code class="p">)</code><code class="p">]</code><code class="p">,</code><code>
</code><code>      </code><code class="p">[</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">Vectors</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="p">[</code><code class="mf">2.0</code><code class="p">,</code><code> </code><code class="mf">3.0</code><code class="p">]</code><code class="p">)</code><code class="p">]</code><code class="p">,</code><code class="p">]</code><code class="p">,</code><code>
</code><code>      </code><code class="p">[</code><code class="s2">"</code><code class="s2">id</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="s2">"</code><code class="s2">features</code><code class="s2">"</code><code class="p">]</code><code class="p">)</code><code>
</code><code>
</code><code class="n">lda</code><code> </code><code class="o">=</code><code> </code><code class="n">LDA</code><code class="p">(</code><code class="n">k</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">seed</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code> </code><a class="co" href="#callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO1-1" id="co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO1-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code class="n">lda</code><code class="o">.</code><code class="n">setMaxIter</code><code class="p">(</code><code class="mi">10</code><code class="p">)</code><code>
</code><code>
</code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">lda</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">df</code><code class="p">)</code><code>
</code><code>
</code><code class="n">model</code><code class="o">.</code><code class="n">vocabSize</code><code class="p">(</code><code class="p">)</code><code>
</code><code class="mi">2</code><code>
</code><code>
</code><code class="n">model</code><code class="o">.</code><code class="n">describeTopics</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO1-2" id="co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO1-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a><code>
</code><code class="o">+</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">+</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">+</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">+</code><code>
</code><code class="o">|</code><code class="n">topic</code><code class="o">|</code><code class="n">termIndices</code><code class="o">|</code><code>         </code><code class="n">termWeights</code><code class="o">|</code><code>
</code><code class="o">+</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">+</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">+</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">+</code><code>
</code><code class="o">|</code><code>    </code><code class="mi">0</code><code class="o">|</code><code>     </code><code class="p">[</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">]</code><code class="o">|</code><code class="p">[</code><code class="mf">0.53331100994293</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="o">|</code><code>
</code><code class="o">|</code><code>    </code><code class="mi">1</code><code class="o">|</code><code>     </code><code class="p">[</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="o">|</code><code class="p">[</code><code class="mf">0.50230220117597</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="o">|</code><code>
</code><code class="o">+</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">+</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">+</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">+</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO1-1" id="callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO1-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>We apply LDA to our dataframe with the number of topics (<em>k</em>) set to 2.</p></dd>
<dt><a class="co" href="#co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO1-2" id="callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO1-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></dt>
<dd><p>Dataframe describing the probability weight associated with each term in our topics.</p></dd>
</dl>
<p>We will explore PySpark’s LDA implementation and associated parameters when applying it to the Wikipedia dataset. First, though, we need to download the relevant dataset. That’s what we will do next.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Getting the Data" data-type="sect1"><div class="sect1" id="idm46507974456144">
<h1>Getting the Data</h1>
<p>Wikipedia makes dumps of all its articles available.<a data-primary="natural language processing (NLP)" data-secondary="Wikipedia data" data-tertiary="getting the data" data-type="indexterm" id="idm46507974454384"/><a data-primary="latent Dirichlet allocation (LDA)" data-secondary="Wikipedia data" data-tertiary="getting the data" data-type="indexterm" id="idm46507974453168"/><a data-primary="Wikipedia document processing" data-secondary="data" data-tertiary="getting the data" data-type="indexterm" id="idm46507974451984"/><a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="getting the data" data-type="indexterm" id="idm46507974450800"/><a data-primary="online resources" data-secondary="Wikipedia article download" data-type="indexterm" id="idm46507974449584"/><a data-primary="datasets" data-secondary="Wikipedia documents" data-type="indexterm" id="idm46507974448672"/>  The full dump comes in a single, large XML file. These can be <a href="https://oreil.ly/DhGlJ">downloaded</a> and then placed on a cloud storage solution (such as AWS S3 or GCS, Google Cloud Storage) or HDFS. For example:</p>
<pre data-code-language="shell" data-type="programlisting">$ curl -s -L https://dumps.wikimedia.org/enwiki/latest/<code class="se">\</code>
$ enwiki-latest-pages-articles-multistream.xml.bz2 <code class="se">\</code>
$   <code class="p">|</code> bzip2 -cd <code class="se">\</code>
$   <code class="p">|</code> hadoop fs -put - wikidump.xml</pre>
<p>This can take a little while.</p>
<p>Chugging through this volume of data makes the most sense with a cluster of a few nodes to work with.  To run this chapter’s code on a local machine, a better option is to generate a smaller dump using <a href="https://oreil.ly/Rrpmr">Wikipedia’s export pages</a>.  Try getting all the pages from multiple categories that have many pages and few subcategories, such as biology, health, and geometry.  For the following code to work, download the dump into the <em>ch06-LDA/</em> directory and rename it to <em>wikidump.xml</em>.</p>
<p>We need to convert the Wikipedia XML dump into a format that we can easily work with in PySpark. <a data-primary="natural language processing (NLP)" data-secondary="Wikipedia data" data-tertiary="WikiExtractor tool" data-type="indexterm" id="idm46507974398944"/><a data-primary="latent Dirichlet allocation (LDA)" data-secondary="Wikipedia data" data-tertiary="WikiExtractor tool" data-type="indexterm" id="idm46507974397728"/><a data-primary="Wikipedia document processing" data-secondary="data" data-tertiary="WikiExtractor tool" data-type="indexterm" id="idm46507974396544"/><a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="WikiExtractor tool" data-type="indexterm" id="idm46507974395360"/><a data-primary="online resources" data-secondary="Wikipedia article download" data-tertiary="WikiExtractor tool" data-type="indexterm" id="idm46507974394144"/>When working on our local machine, we can use the convenient <a href="https://oreil.ly/pfwrE">WikiExtractor tool</a> for this. It extracts and cleans text from Wikipedia database dumps such as what we have.</p>
<p>Install it using pip:</p>
<pre data-code-language="shell" data-type="programlisting">$ pip3 install wikiextractor</pre>
<p>Then it’s as simple as running the following command in the directory containing the downloaded file:</p>
<pre data-code-language="shell" data-type="programlisting">$ wikiextractor wikidump.xml</pre>
<p>The output is stored in a single or several files of similar size in a given directory named <code>text</code>. Each file will contains several documents in the following format:</p>
<pre data-code-language="shell" data-type="programlisting"><code>$</code><code> </code><code>mv</code><code> </code><code>text</code><code> </code><code>wikidump</code><code> </code><a class="co" href="#callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO2-1" id="co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO2-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code>$</code><code> </code><code>tree</code><code> </code><code>wikidump</code><code>
</code><code>...</code><code>
</code><code>wikidump</code><code>
</code><code>└──</code><code> </code><code>AA</code><code>
    </code><code>└──</code><code> </code><code>wiki_00</code><code>

</code><code>...</code><code>
</code><code>$</code><code> </code><code>head</code><code> </code><code>-n</code><code> </code><code class="m">5</code><code> </code><code>wikidump/AA/wiki_00</code><code>
</code><code>...</code><code>

</code><code>&lt;</code><code>doc</code><code> </code><code class="nv">id</code><code class="o">=</code><code class="s2">"18831"</code><code> </code><code class="nv">url</code><code class="o">=</code><code class="s2">"?curid=18831"</code><code> </code><code class="nv">title</code><code class="o">=</code><code class="s2">"Mathematics"</code><code>&gt;</code><code>
</code><code>Mathematics</code><code>

</code><code>Mathematics</code><code> </code><code class="o">(</code><code>from</code><code> </code><code>Greek:</code><code> </code><code class="o">)</code><code> </code><code>includes</code><code> </code><code>the</code><code> </code><code>study</code><code> </code><code>of</code><code> </code><code>such</code><code> </code><code>topics</code><code> </code><code>as</code><code> </code><code>numbers</code><code> </code><code>...</code><code>
</code><code>...</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO2-1" id="callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO2-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>Rename text directory to wikidump</p></dd>
</dl>
<p>Next, let’s get familiar with the Spark NLP library before we start working on the data.</p>
</div></section>
<section data-pdf-bookmark="Spark NLP" data-type="sect1"><div class="sect1" id="idm46507974455488">
<h1>Spark NLP</h1>
<p>The Spark NLP library was originally<a data-primary="John Snow Labs" data-type="indexterm" id="idm46507974279568"/><a data-primary="natural language processing (NLP)" data-secondary="Spark NLP" data-tertiary="about" data-type="indexterm" id="idm46507974278960"/><a data-primary="latent Dirichlet allocation (LDA)" data-secondary="Spark NLP" data-see="Spark NLP" data-type="indexterm" id="idm46507974277872"/><a data-primary="Wikipedia document processing" data-secondary="Spark NLP" data-tertiary="about" data-type="indexterm" id="idm46507974276784"/><a data-primary="Spark NLP" data-secondary="about" data-type="indexterm" id="idm46507974275696"/> designed by <a href="https://oreil.ly/E9KVt">John Snow Labs</a> in early 2017 as an annotation library native to Spark to take full advantage of Spark SQL and MLlib modules. The inspiration came from trying to use Spark to distribute other NLP libraries, which were generally not implemented with concurrency or distributed computing in mind.</p>
<p>Spark NLP has the same concepts as any<a data-primary="annotation libraries" data-secondary="Spark NLP as" data-seealso="Spark NLP" data-type="indexterm" id="idm46507974244368"/> other annotation library but differs in how it stores annotations. Most annotation libraries store the annotations in the document object, but Spark NLP creates columns for the different types of annotations. The annotators are implemented as transformers, estimators, and models. We will look at these in the next section when applying them to our dataset for preprocessing. Before that, let’s download and set up Spark NLP on our system.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46507974243136">
<h5>Functionality and Annotation NLP Libraries</h5>
<p>NLP libraries can be broadly divided into two types:<a data-primary="annotation libraries" data-secondary="functionality libraries versus" data-type="indexterm" id="idm46507974241536"/><a data-primary="functionality versus annotation libraries" data-type="indexterm" id="idm46507974240688"/><a data-primary="natural language processing (NLP)" data-secondary="Spark NLP" data-tertiary="functionality versus annotation libraries" data-type="indexterm" id="idm46507974240080"/><a data-primary="Wikipedia document processing" data-secondary="Spark NLP" data-tertiary="functionality versus annotation libraries" data-type="indexterm" id="idm46507974238992"/><a data-primary="Spark NLP" data-secondary="about annotation libraries" data-tertiary="functionality libraries versus" data-type="indexterm" id="idm46507974237904"/> <em>functionality libraries</em> and <em>annotation libraries</em>.</p>
<p>Functionality libraries are built for specific NLP tasks and techniques. The methods provided by these libraries are often self-contained. That means, it is assumed that basic tasks like tokenization will have to be performed even when methods for entity recognition or part-of-speech tagging are invoked. This makes them easier to work with at the cost of performance since there is a lack of coherent design.</p>
<p>Annotation libraries are libraries<a data-primary="annotation libraries" data-type="indexterm" id="idm46507974235056"/><a data-primary="Spark NLP" data-secondary="about annotation libraries" data-type="indexterm" id="idm46507974234448"/><a data-primary="annotation libraries" data-secondary="document, annotation, annotator" data-type="indexterm" id="idm46507974233600"/><a data-primary="documents (document-annotation model)" data-type="indexterm" id="idm46507974232752"/><a data-primary="annotations (document-annotation model)" data-type="indexterm" id="idm46507974232144"/><a data-primary="annotators (document-annotation model)" data-type="indexterm" id="idm46507974231536"/> in which all the functionality is built around a document-annotation model. There are three main concepts that they are designed around: <em>document</em>, <em>annotation</em>, and <em>annotator</em>:</p>
<dl>
<dt>Document</dt>
<dd>
<p>A representation of the text we want to analyze or work with.</p>
</dd>
<dt>Annotation</dt>
<dd>
<p>A representation of the output of our NLP functions.</p>
</dd>
<dt>Annotator</dt>
<dd>
<p>The object that contains the logic for using the NLP functions.</p>
</dd>
</dl>
<p>As we use Spark NLP in upcoming sections, these concepts will become clearer.</p>
</div></aside>
<section data-pdf-bookmark="Setting Up Your Environment" data-type="sect2"><div class="sect2" id="idm46507974225168">
<h2>Setting Up Your Environment</h2>
<p>Install Spark NLP via pip:<a data-primary="Spark NLP" data-secondary="installing" data-type="indexterm" id="idm46507974223728"/><a data-primary="natural language processing (NLP)" data-secondary="Spark NLP" data-tertiary="installing" data-type="indexterm" id="idm46507974222880"/><a data-primary="Wikipedia document processing" data-secondary="Spark NLP" data-tertiary="installing" data-type="indexterm" id="idm46507974221792"/><a data-primary="installing Spark NLP" data-type="indexterm" id="idm46507974220704"/><a data-primary="online resources" data-secondary="Spark NLP installer" data-type="indexterm" id="idm46507974220096"/></p>
<pre data-code-language="python" data-type="programlisting"><code class="n">pip3</code> <code class="n">install</code> <code class="n">spark</code><code class="o">-</code><code class="n">nlp</code><code class="o">==</code><code class="mf">3.2.3</code></pre>
<p>Start the PySpark shell:</p>
<pre data-code-language="shell" data-type="programlisting">pyspark --packages com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.4</pre>
<p>Let’s import Spark NLP in our PySpark shell:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">sparknlp</code>

<code class="n">spark</code> <code class="o">=</code> <code class="n">sparknlp</code><code class="o">.</code><code class="n">start</code><code class="p">()</code></pre>
<p>Now, you can import the relevant Spark NLP modules that we’ll use:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">sparknlp.base</code> <code class="kn">import</code> <code class="n">DocumentAssembler</code><code class="p">,</code> <code class="n">Finisher</code>
<code class="kn">from</code> <code class="nn">sparknlp.annotator</code> <code class="kn">import</code> <code class="p">(</code><code class="n">Lemmatizer</code><code class="p">,</code> <code class="n">Stemmer</code><code class="p">,</code>
                                <code class="n">Tokenizer</code><code class="p">,</code> <code class="n">Normalizer</code><code class="p">,</code>
                                <code class="n">StopWordsCleaner</code><code class="p">)</code>
<code class="kn">from</code> <code class="nn">sparknlp.pretrained</code> <code class="kn">import</code> <code class="n">PretrainedPipeline</code></pre>
<p>Now that we have set up our programming environment, let’s start working on our dataset. We’ll start by parsing the data as a PySpark DataFrame.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Parsing the Data" data-type="sect1"><div class="sect1" id="idm46507974224704">
<h1>Parsing the Data</h1>
<p>The output from WikiExtractor can create<a data-primary="natural language processing (NLP)" data-secondary="Wikipedia data" data-tertiary="parsing the data" data-type="indexterm" id="idm46507974106480"/><a data-primary="latent Dirichlet allocation (LDA)" data-secondary="Wikipedia data" data-tertiary="parsing the data" data-type="indexterm" id="idm46507974105264"/><a data-primary="Wikipedia document processing" data-secondary="data" data-tertiary="parsing the data" data-type="indexterm" id="idm46507974104080"/><a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="parsing the data" data-type="indexterm" id="idm46507974102896"/><a data-primary="dataframes" data-secondary="WikiExtractor output as DataFrame" data-type="indexterm" id="idm46507974101680"/> multiple directories depending on the size of the input dump. We want to import all the data as a single DataFrame. Let’s start by specifying the input directory:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">data_source</code> <code class="o">=</code> <code class="s1">'wikidump/*/*'</code></pre>
<p>We import the data using the <code>wholeTextFiles</code> method<a data-primary="RDDs (resilient distributed datasets)" data-secondary="WikiExtractor output as DataFrame" data-type="indexterm" id="idm46507974079504"/><a data-primary="wholeTextFiles method" data-type="indexterm" id="idm46507974078656"/><a data-primary="sparkContext" data-type="indexterm" id="idm46507974078048"/> accessible through <code>sparkContext</code>. This method reads the data in as an RDD. We convert it into a DataFrame since that’s what we want:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">raw_data</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">sparkContext</code><code class="o">.</code><code class="n">wholeTextFiles</code><code class="p">(</code><code class="n">data_source</code><code class="p">)</code><code class="o">.</code><code class="n">toDF</code><code class="p">()</code>
<code class="n">raw_data</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="n">vertical</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="o">...</code>

<code class="o">-</code><code class="n">RECORD</code> <code class="mi">0</code><code class="o">-------------------</code>
 <code class="n">_1</code>  <code class="o">|</code> <code class="n">file</code><code class="p">:</code><code class="o">/</code><code class="n">home</code><code class="o">/</code><code class="n">analyt</code><code class="o">...</code>
 <code class="n">_2</code>  <code class="o">|</code> <code class="o">&lt;</code><code class="n">doc</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"18831"</code> <code class="n">u</code><code class="o">...</code></pre>
<p>The resulting DataFrame will consist of two columns. The number of records will correspond to the number of files that were read. The first column consists of the filepath and the second contains the corresponding text content. The text contains multiple entries, but we want each row to correspond to a single entry. <a data-primary="dataframes" data-secondary="split method" data-type="indexterm" id="idm46507974032928"/><a data-primary="split method on dataframes" data-type="indexterm" id="idm46507974014928"/><a data-primary="dataframes" data-secondary="explode method" data-type="indexterm" id="idm46507974014320"/><a data-primary="explode method on dataframes" data-type="indexterm" id="idm46507974013408"/>Based on the entry structure that we had seen earlier, we can separate entries using a couple of PySpark utilities: <code>split</code> and <code>explode</code>.</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.sql</code> <code class="kn">import</code> <code class="n">functions</code> <code class="k">as</code> <code class="n">fun</code>
<code class="n">df</code> <code class="o">=</code> <code class="n">raw_data</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s1">'content'</code><code class="p">,</code> <code class="n">fun</code><code class="o">.</code><code class="n">explode</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s2">"_2"</code><code class="p">),</code>
  <code class="s2">"&lt;/doc&gt;"</code><code class="p">)))</code>
<code class="n">df</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'_2'</code><code class="p">))</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'_1'</code><code class="p">))</code>

<code class="n">df</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">4</code><code class="p">,</code> <code class="n">vertical</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="o">...</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">0</code><code class="o">-----------------------</code>
 <code class="n">content</code> <code class="o">|</code> <code class="o">&lt;</code><code class="n">doc</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"18831"</code> <code class="n">u</code><code class="o">...</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">1</code><code class="o">-----------------------</code>
 <code class="n">content</code> <code class="o">|</code>
<code class="o">&lt;</code><code class="n">doc</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"5627588...</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">2</code><code class="o">-----------------------</code>
 <code class="n">content</code> <code class="o">|</code>
<code class="o">&lt;</code><code class="n">doc</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"3354393...</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">3</code><code class="o">-----------------------</code>
 <code class="n">content</code> <code class="o">|</code>
<code class="o">&lt;</code><code class="n">doc</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"5999808...</code>
<code class="n">only</code> <code class="n">showing</code> <code class="n">top</code> <code class="mi">4</code> <code class="n">rows</code></pre>
<p>The <code>split</code> function is used to split the DataFrame string <code>Column</code> into an array based on matches of a provided pattern. In the previous code, we split the combined document XML string into an array based on the <em>&lt;/doc&gt;</em> string. This effectively gives us an array of multiple documents. Then, we use <code>explode</code> to create new rows for each element in the array returned by the <code>split</code> function. This results in rows being created corresponding to each document.</p>
<p>Go through the structure obtained in the <code>content</code> column by our previous operation:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">df</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="n">truncate</code><code class="o">=</code><code class="kc">False</code><code class="p">,</code> <code class="n">vertical</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="o">...</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">0</code>

<code class="o">-------------------------------------------------------------------</code>
 <code class="n">content</code> <code class="o">|</code> <code class="o">&lt;</code><code class="n">doc</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"18831"</code> <code class="n">url</code><code class="o">=</code><code class="s2">"?curid=18831"</code> <code class="n">title</code><code class="o">=</code><code class="s2">"Mathematics"</code><code class="o">&gt;</code>
<code class="n">Mathematics</code>

<code class="n">Mathematics</code> <code class="p">(</code><code class="kn">from</code> <code class="nn">Greek</code><code class="p">:</code> <code class="p">)</code> <code class="n">includes</code> <code class="n">the</code> <code class="n">study</code> <code class="n">of</code> <code class="n">such</code> <code class="n">topics</code> <code class="k">as</code> <code class="n">numbers</code><code class="o">...</code></pre>
<p>We can further split our <code>content</code> column by extracting the entries’ titles:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">df</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s1">'title'</code><code class="p">,</code> <code class="n">fun</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'content'</code><code class="p">),</code> <code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code class="n">getItem</code><code class="p">(</code><code class="mi">2</code><code class="p">))</code> \
        <code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s1">'content'</code><code class="p">,</code> <code class="n">fun</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'content'</code><code class="p">),</code> <code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code class="n">getItem</code><code class="p">(</code><code class="mi">4</code><code class="p">))</code>
<code class="n">df</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">4</code><code class="p">,</code> <code class="n">vertical</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="o">...</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">0</code><code class="o">-----------------------</code>
 <code class="n">content</code> <code class="o">|</code> <code class="n">In</code> <code class="n">mathematics</code><code class="p">,</code> <code class="n">a</code><code class="o">...</code>
 <code class="n">title</code>   <code class="o">|</code> <code class="n">Tertiary</code> <code class="n">ideal</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">1</code><code class="o">-----------------------</code>
 <code class="n">content</code> <code class="o">|</code> <code class="n">In</code> <code class="n">algebra</code><code class="p">,</code> <code class="n">a</code> <code class="nb">bin</code><code class="o">...</code>
 <code class="n">title</code>   <code class="o">|</code> <code class="n">Binomial</code> <code class="p">(</code><code class="n">polynom</code><code class="o">...</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">2</code><code class="o">-----------------------</code>
 <code class="n">content</code> <code class="o">|</code> <code class="n">Algebra</code> <code class="p">(</code><code class="kn">from</code> <code class="p">)</code> <code class="n">i</code><code class="o">...</code>
 <code class="n">title</code>   <code class="o">|</code> <code class="n">Algebra</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">3</code><code class="o">-----------------------</code>
 <code class="n">content</code> <code class="o">|</code> <code class="n">In</code> <code class="nb">set</code> <code class="n">theory</code><code class="p">,</code> <code class="n">th</code><code class="o">...</code>
 <code class="n">title</code>   <code class="o">|</code> <code class="n">Kernel</code> <code class="p">(</code><code class="nb">set</code> <code class="n">theory</code><code class="p">)</code>
<code class="n">only</code> <code class="n">showing</code> <code class="n">top</code> <code class="mi">4</code> <code class="n">rows</code>
<code class="o">...</code></pre>
<p>Now that we have our parsed dataset, let’s move on to preprocessing using Spark NLP.</p>
</div></section>
<section data-pdf-bookmark="Preparing the Data Using Spark NLP" data-type="sect1"><div class="sect1" id="idm46507974107360">
<h1>Preparing the Data Using Spark NLP</h1>
<p>We had earlier mentioned that a library based<a data-primary="natural language processing (NLP)" data-secondary="Wikipedia data" data-tertiary="preparing data with Spark NLP" data-type="indexterm" id="ch06-doc"/><a data-primary="latent Dirichlet allocation (LDA)" data-secondary="Wikipedia data" data-tertiary="preparing data with Spark NLP" data-type="indexterm" id="ch06-doc2"/><a data-primary="Wikipedia document processing" data-secondary="data" data-tertiary="preparing data with Spark NLP" data-type="indexterm" id="ch06-doc3"/><a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="preparing data with Spark NLP" data-type="indexterm" id="ch06-doc4"/><a data-primary="natural language processing (NLP)" data-secondary="Spark NLP" data-tertiary="preparing data with" data-type="indexterm" id="ch06-doc5"/><a data-primary="Wikipedia document processing" data-secondary="Spark NLP" data-tertiary="preparing data with" data-type="indexterm" id="ch06-doc6"/><a data-primary="documents (document-annotation model)" data-secondary="Spark NLP interoperability" data-type="indexterm" id="ch06-doc7"/><a data-primary="dataframes" data-secondary="document-annotator model interoperability" data-type="indexterm" id="ch06-doc8"/> on the document-annotator model such as Spark NLP has the concept of “documents.” There does not exist such a concept natively in PySpark. Hence, one of Spark NLP’s core design tenets is strong interoperability with MLlib. This is done by providing DataFrame-compatible transformers that convert text columns into documents and convert annotations into PySpark data types.</p>
<p>We start by creating our <code>document</code> column using <code>DocumentAssembler</code>:<a data-primary="DocumentAssembler method" data-type="indexterm" id="idm46507973509456"/></p>
<pre data-code-language="python" data-type="programlisting"><code class="n">document_assembler</code> <code class="o">=</code> <code class="n">DocumentAssembler</code><code class="p">()</code> \
    <code class="o">.</code><code class="n">setInputCol</code><code class="p">(</code><code class="s2">"content"</code><code class="p">)</code> \
    <code class="o">.</code><code class="n">setOutputCol</code><code class="p">(</code><code class="s2">"document"</code><code class="p">)</code> \
    <code class="o">.</code><code class="n">setCleanupMode</code><code class="p">(</code><code class="s2">"shrink"</code><code class="p">)</code>

<code class="n">document_assembler</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">df</code><code class="p">)</code><code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s1">'document'</code><code class="p">)</code><code class="o">.</code><code class="n">limit</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code><code class="o">.</code><code class="n">collect</code><code class="p">()</code>
<code class="o">...</code>

<code class="n">Row</code><code class="p">(</code><code class="n">document</code><code class="o">=</code><code class="p">[</code><code class="n">Row</code><code class="p">(</code><code class="n">annotatorType</code><code class="o">=</code><code class="s1">'document'</code><code class="p">,</code> <code class="n">begin</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">end</code><code class="o">=</code><code class="mi">289</code><code class="p">,</code> <code class="n">result</code><code class="o">=</code><code class="s1">'...'</code><code class="p">,</code>
    <code class="n">metadata</code><code class="o">=</code><code class="p">{</code><code class="s1">'sentence'</code><code class="p">:</code> <code class="s1">'0'</code><code class="p">},</code> <code class="n">embeddings</code><code class="o">=</code><code class="p">[])])</code></pre>
<div data-type="note" epub:type="note">
<p>We could have utilized<a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="DocumentNormalizer annotator" data-type="indexterm" id="idm46507973417760"/><a data-primary="natural language processing (NLP)" data-secondary="Spark NLP" data-tertiary="DocumentNormalizer annotator" data-type="indexterm" id="idm46507973432240"/><a data-primary="Wikipedia document processing" data-secondary="Spark NLP" data-tertiary="DocumentNormalizer annotator" data-type="indexterm" id="idm46507973431088"/><a data-primary="documents (document-annotation model)" data-secondary="Spark NLP interoperability" data-tertiary="DocumentNormalizer annotator" data-type="indexterm" id="idm46507973429936"/><a data-primary="online resources" data-secondary="Spark NLP installer" data-tertiary="DocumentNormalizer annotator" data-type="indexterm" id="idm46507973428720"/> Spark NLP’s <a href="https://oreil.ly/UL1vp"><code>DocumentNormalizer</code></a> annotator in the parsing section.</p>
</div>
<p>We can transform the input dataframe directly as we have done in the previous code. However, we will instead use <code>DocumentAssembler</code> and other required annotators as part of an ML pipeline.</p>
<p>We will use the following annotators as part of our preprocessing pipeline: <code>Tokenizer</code>, <code>Normalizer</code>, <code>StopWordsCleaner</code>, and <code>Stemmer</code>.</p>
<p>Let’s start with the <code>Tokenizer</code>:</p>
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Split sentence to tokens(array)</code>
<code class="n">tokenizer</code> <code class="o">=</code> <code class="n">Tokenizer</code><code class="p">()</code> \
  <code class="o">.</code><code class="n">setInputCols</code><code class="p">([</code><code class="s2">"document"</code><code class="p">])</code> \
  <code class="o">.</code><code class="n">setOutputCol</code><code class="p">(</code><code class="s2">"token"</code><code class="p">)</code></pre>
<p>The <code>Tokenizer</code> is a fundamental annotator.<a data-primary="natural language processing (NLP)" data-secondary="Spark NLP" data-tertiary="Tokenizer" data-type="indexterm" id="idm46507973381488"/><a data-primary="Wikipedia document processing" data-secondary="Spark NLP" data-tertiary="Tokenizer" data-type="indexterm" id="idm46507973344656"/><a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="Tokenizer" data-type="indexterm" id="idm46507973343472"/> Almost all text-based data processing begins with some form of tokenization, which is the process of breaking raw text into small chunks. Tokens can be words, characters, or subwords (n-grams).
Most classical NLP algorithms expect tokens as the basic input. Many deep learning algorithms are being developed that take characters as basic input. Most NLP applications still use tokenization.</p>
<p>Next up is the <code>Normalizer</code>:<a data-primary="natural language processing (NLP)" data-secondary="Spark NLP" data-tertiary="Normalizer" data-type="indexterm" id="idm46507973340896"/><a data-primary="Wikipedia document processing" data-secondary="Spark NLP" data-tertiary="Normalizer" data-type="indexterm" id="idm46507973366304"/><a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="Normalizer" data-type="indexterm" id="idm46507973365120"/></p>
<pre data-code-language="python" data-type="programlisting"><code class="c1"># clean unwanted characters and garbage</code>
<code class="n">normalizer</code> <code class="o">=</code> <code class="n">Normalizer</code><code class="p">()</code> \
    <code class="o">.</code><code class="n">setInputCols</code><code class="p">([</code><code class="s2">"token"</code><code class="p">])</code> \
    <code class="o">.</code><code class="n">setOutputCol</code><code class="p">(</code><code class="s2">"normalized"</code><code class="p">)</code> \
    <code class="o">.</code><code class="n">setLowercase</code><code class="p">(</code><code class="kc">True</code><code class="p">)</code></pre>
<p>The <code>Normalizer</code> cleans out tokens from the previous step and removes all unwanted characters from the text.</p>
<p>Next up is the <code>StopWordsCleaner</code>:</p>
<pre data-code-language="python" data-type="programlisting"><code class="c1"># remove stopwords</code>
<code class="n">stopwords_cleaner</code> <code class="o">=</code> <code class="n">StopWordsCleaner</code><code class="p">()</code>\
      <code class="o">.</code><code class="n">setInputCols</code><code class="p">(</code><code class="s2">"normalized"</code><code class="p">)</code>\
      <code class="o">.</code><code class="n">setOutputCol</code><code class="p">(</code><code class="s2">"cleanTokens"</code><code class="p">)</code>\
      <code class="o">.</code><code class="n">setCaseSensitive</code><code class="p">(</code><code class="kc">False</code><code class="p">)</code></pre>
<p>This annotator removes <em>stop words</em> from text. Stop words such as “the,” “is,” and “at,” which are so common that they can be removed without significantly altering the meaning of a text. Removing stop words is useful when one wants to deal with only the most semantically important words in a text and ignore words that are rarely semantically relevant, such as articles and prepositions.</p>
<p>Last up is the <code>Stemmer</code>:<a data-primary="natural language processing (NLP)" data-secondary="Spark NLP" data-tertiary="Stemmer" data-type="indexterm" id="idm46507973255184"/><a data-primary="Wikipedia document processing" data-secondary="Spark NLP" data-tertiary="Stemmer" data-type="indexterm" id="idm46507973253936"/><a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="Stemmer" data-type="indexterm" id="idm46507973269360"/></p>
<pre data-code-language="python" data-type="programlisting"><code class="c1"># stem the words to bring them to the root form.</code>
<code class="n">stemmer</code> <code class="o">=</code> <code class="n">Stemmer</code><code class="p">()</code> \
    <code class="o">.</code><code class="n">setInputCols</code><code class="p">([</code><code class="s2">"cleanTokens"</code><code class="p">])</code> \
    <code class="o">.</code><code class="n">setOutputCol</code><code class="p">(</code><code class="s2">"stem"</code><code class="p">)</code></pre>
<p><code>Stemmer</code> returns hard stems out of words with the objective of retrieving the meaningful part of the word. <em>Stemming</em> is the process of reducing a word to its root word stem with the objective of retrieving the meaningful part. For example, “picking,” “picked,” and “picks” all have “pick” as the root.</p>
<p>We are almost done. Before we can complete<a data-primary="natural language processing (NLP)" data-secondary="Spark NLP" data-tertiary="Finisher" data-type="indexterm" id="idm46507973225632"/><a data-primary="Wikipedia document processing" data-secondary="Spark NLP" data-tertiary="Finisher" data-type="indexterm" id="idm46507973202784"/><a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="Finisher" data-type="indexterm" id="idm46507973201600"/> our NLP pipeline, we need to add the <code>Finisher</code>. Spark NLP adds its own structure when we convert each row in the dataframe to a document. <code>Finisher</code> is critical because it helps us to bring back the expected structure, an array of tokens:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">finisher</code> <code class="o">=</code> <code class="n">Finisher</code><code class="p">()</code> \
    <code class="o">.</code><code class="n">setInputCols</code><code class="p">([</code><code class="s2">"stem"</code><code class="p">])</code> \
    <code class="o">.</code><code class="n">setOutputCols</code><code class="p">([</code><code class="s2">"tokens"</code><code class="p">])</code> \
    <code class="o">.</code><code class="n">setOutputAsArray</code><code class="p">(</code><code class="kc">True</code><code class="p">)</code> \
    <code class="o">.</code><code class="n">setCleanAnnotations</code><code class="p">(</code><code class="kc">False</code><code class="p">)</code></pre>
<p>Now we have all the required pieces in place. Let’s build our pipeline so that each phase can be executed in sequence:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.ml</code> <code class="kn">import</code> <code class="n">Pipeline</code>
<code class="n">nlp_pipeline</code> <code class="o">=</code> <code class="n">Pipeline</code><code class="p">(</code>
    <code class="n">stages</code><code class="o">=</code><code class="p">[</code><code class="n">document_assembler</code><code class="p">,</code>
            <code class="n">tokenizer</code><code class="p">,</code>
            <code class="n">normalizer</code><code class="p">,</code>
            <code class="n">stopwords_cleaner</code><code class="p">,</code>
            <code class="n">stemmer</code><code class="p">,</code>
            <code class="n">finisher</code><code class="p">])</code></pre>
<p class="pagebreak-before">Execute the pipeline and transform the dataframe:<a data-primary="schemas of dataframes" data-secondary="Wikipedia documents" data-type="indexterm" id="idm46507973130992"/><a data-primary="dataframes" data-secondary="schemas" data-tertiary="Wikipedia documents" data-type="indexterm" id="idm46507973130144"/></p>
<pre data-code-language="python" data-type="programlisting"><code class="n">nlp_model</code><code> </code><code class="o">=</code><code> </code><code class="n">nlp_pipeline</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">df</code><code class="p">)</code><code> </code><a class="co" href="#callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO3-1" id="co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO3-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code>
</code><code class="n">processed_df</code><code>  </code><code class="o">=</code><code> </code><code class="n">nlp_model</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">df</code><code class="p">)</code><code> </code><a class="co" href="#callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO3-2" id="co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO3-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a><code>
</code><code>
</code><code class="n">processed_df</code><code class="o">.</code><code class="n">printSchema</code><code class="p">(</code><code class="p">)</code><code>
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code>
</code><code>
</code><code class="n">root</code><code>
</code><code> </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">content</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">title</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">document</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="n">struct</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">annotatorType</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">begin</code><code class="p">:</code><code> </code><code class="n">integer</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">end</code><code class="p">:</code><code> </code><code class="n">integer</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">result</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">metadata</code><code class="p">:</code><code> </code><code class="nb">map</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">key</code><code class="p">:</code><code> </code><code class="n">string</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">value</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">valueContainsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">embeddings</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="nb">float</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">token</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="n">struct</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">annotatorType</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">begin</code><code class="p">:</code><code> </code><code class="n">integer</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">end</code><code class="p">:</code><code> </code><code class="n">integer</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">result</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">metadata</code><code class="p">:</code><code> </code><code class="nb">map</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">key</code><code class="p">:</code><code> </code><code class="n">string</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">value</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">valueContainsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">embeddings</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="nb">float</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">normalized</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="n">struct</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">annotatorType</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">begin</code><code class="p">:</code><code> </code><code class="n">integer</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">end</code><code class="p">:</code><code> </code><code class="n">integer</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">result</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">metadata</code><code class="p">:</code><code> </code><code class="nb">map</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">key</code><code class="p">:</code><code> </code><code class="n">string</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">value</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">valueContainsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">embeddings</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="nb">float</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">cleanTokens</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="n">struct</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">annotatorType</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">begin</code><code class="p">:</code><code> </code><code class="n">integer</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">end</code><code class="p">:</code><code> </code><code class="n">integer</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">result</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">metadata</code><code class="p">:</code><code> </code><code class="nb">map</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">key</code><code class="p">:</code><code> </code><code class="n">string</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">value</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">valueContainsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">embeddings</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="nb">float</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">stem</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="n">struct</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">annotatorType</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">begin</code><code class="p">:</code><code> </code><code class="n">integer</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">end</code><code class="p">:</code><code> </code><code class="n">integer</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">result</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">metadata</code><code class="p">:</code><code> </code><code class="nb">map</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">key</code><code class="p">:</code><code> </code><code class="n">string</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">value</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">valueContainsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">embeddings</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="nb">float</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">false</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">tokens</code><code class="p">:</code><code> </code><code class="n">array</code><code> </code><code class="p">(</code><code class="n">nullable</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code><code>
</code><code> </code><code class="o">|</code><code>    </code><code class="o">|</code><code class="o">-</code><code class="o">-</code><code> </code><code class="n">element</code><code class="p">:</code><code> </code><code class="n">string</code><code> </code><code class="p">(</code><code class="n">containsNull</code><code> </code><code class="o">=</code><code> </code><code class="n">true</code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO3-1" id="callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO3-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>Train the pipeline.</p></dd>
<dt><a class="co" href="#co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO3-2" id="callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO3-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></dt>
<dd><p>Apply the pipeline to transform the dataframe.</p></dd>
</dl>
<p>The NLP pipeline created intermediary columns that we do not need. Let’s remove the redundant columns:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">tokens_df</code> <code class="o">=</code> <code class="n">processed_df</code><code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s1">'title'</code><code class="p">,</code><code class="s1">'tokens'</code><code class="p">)</code>
<code class="n">tokens_df</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="n">vertical</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="o">...</code>

<code class="o">-</code><code class="n">RECORD</code> <code class="mi">0</code><code class="o">----------------------</code>
 <code class="n">title</code>  <code class="o">|</code> <code class="n">Tertiary</code> <code class="n">ideal</code>
 <code class="n">tokens</code> <code class="o">|</code> <code class="p">[</code><code class="n">mathemat</code><code class="p">,</code> <code class="n">tertia</code><code class="o">...</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">1</code><code class="o">----------------------</code>
 <code class="n">title</code>  <code class="o">|</code> <code class="n">Binomial</code> <code class="p">(</code><code class="n">polynom</code><code class="o">...</code>
 <code class="n">tokens</code> <code class="o">|</code> <code class="p">[</code><code class="n">algebra</code><code class="p">,</code> <code class="n">binomi</code><code class="p">,</code><code class="o">...</code>
<code class="n">only</code> <code class="n">showing</code> <code class="n">top</code> <code class="mi">2</code> <code class="n">rows</code></pre>
<p>Next, we will understand the basics of TF-IDF and implement it on the preprocessed dataset, <code>token_df</code>, that we have obtained before building an LDA model.<a data-startref="ch06-doc" data-type="indexterm" id="idm46507964883040"/><a data-startref="ch06-doc2" data-type="indexterm" id="idm46507964954848"/><a data-startref="ch06-doc3" data-type="indexterm" id="idm46507964954208"/><a data-startref="ch06-doc4" data-type="indexterm" id="idm46507964953536"/><a data-startref="ch06-doc5" data-type="indexterm" id="idm46507964952864"/><a data-startref="ch06-doc6" data-type="indexterm" id="idm46507964952192"/><a data-startref="ch06-doc7" data-type="indexterm" id="idm46507964951520"/><a data-startref="ch06-doc8" data-type="indexterm" id="idm46507964950848"/></p>
</div></section>
<section data-pdf-bookmark="TF-IDF" data-type="sect1"><div class="sect1" id="idm46507973516544">
<h1>TF-IDF</h1>
<p>Before applying LDA, we need to convert<a data-primary="term frequency-inverse document frequency method" data-see="TF-IDF" data-type="indexterm" id="idm46507964949120"/><a data-primary="TF-IDF (term frequency-inverse document frequency method)" data-type="indexterm" id="idm46507964948112"/><a data-primary="natural language processing (NLP)" data-secondary="Wikipedia data" data-tertiary="TF-IDF" data-type="indexterm" id="idm46507964947472"/><a data-primary="latent Dirichlet allocation (LDA)" data-secondary="Wikipedia data" data-tertiary="TF-IDF" data-type="indexterm" id="idm46507964946288"/><a data-primary="Wikipedia document processing" data-secondary="data" data-tertiary="TF-IDF" data-type="indexterm" id="idm46507964945104"/><a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="TF-IDF" data-type="indexterm" id="idm46507964943920"/> our data into a numeric representation. We will obtain such a representation using the term frequency-inverse document frequency method. Loosely, TF-IDF is used to determine the importance of terms corresponding to given documents. Here’s a representation in Python code of the formula. We won’t actually end up using this code because PySpark provides its own implementation.</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">math</code>

<code class="k">def</code> <code class="nf">term_doc_weight</code><code class="p">(</code><code class="n">term_frequency_in_doc</code><code class="p">,</code> <code class="n">total_terms_in_doc</code><code class="p">,</code>
                    <code class="n">term_freq_in_corpus</code><code class="p">,</code> <code class="n">total_docs</code><code class="p">):</code>
  <code class="n">tf</code> <code class="o">=</code> <code class="n">term_frequency_in_doc</code> <code class="o">/</code> <code class="n">total_terms_in_doc</code>
  <code class="n">doc_freq</code> <code class="o">=</code> <code class="n">total_docs</code> <code class="o">/</code> <code class="n">term_freq_in_corpus</code>
  <code class="n">idf</code> <code class="o">=</code> <code class="n">math</code><code class="o">.</code><code class="n">log</code><code class="p">(</code><code class="n">doc_freq</code><code class="p">)</code>
  <code class="n">tf</code> <code class="o">*</code> <code class="n">idf</code>
<code class="p">}</code></pre>
<p>TF-IDF captures two intuitions about the relevance of a term to a document.  First, we would expect that the more often a term occurs in a document, the more important it is to that document.  Second, not all terms are equal in a global sense.  It is more meaningful to encounter a word that occurs rarely in the entire corpus than a word that appears in most of the documents; thus, the metric uses the <em>inverse</em> of the word’s appearance in documents in the full corpus.</p>
<p>The frequency of words in a corpus tends to be distributed exponentially.  A common word might appear ten times as often as a mildly common word, which in turn might appear ten or a hundred times as often as a rare word.  Basing a metric on the raw inverse document frequency would give rare words enormous weight and practically ignore the impact of all other words.  To capture this distribution, the scheme uses the <em>log</em> of the inverse document frequency.  This mellows the differences in document frequencies by transforming the multiplicative gaps between them into additive gaps.</p>
<p>The model relies on a few assumptions.  It treats each document as a “bag of words,” meaning that it pays no attention to the ordering of words, sentence structure, or negations.  By representing each term once, <a data-primary="TF-IDF (term frequency-inverse document frequency method)" data-secondary="same word with multiple meanings" data-type="indexterm" id="idm46507973015328"/>the model has difficulty dealing with <span class="keep-together"><em>polysemy</em>,</span> the use of the same word for multiple meanings.  For example, the model can’t distinguish between the use of “band” in “Radiohead is the best band ever” and “I broke a rubber band.” If both sentences appear often in the corpus, it may come to associate “Radiohead” with “rubber.”</p>
<p>Let’s proceed now to the implementation of TF-IDF using PySpark.</p>
</div></section>
<section data-pdf-bookmark="Computing the TF-IDFs" data-type="sect1"><div class="sect1" id="idm46507973012704">
<h1>Computing the TF-IDFs</h1>
<p>First, we’ll calculate TF<a data-primary="TF-IDF (term frequency-inverse document frequency method)" data-secondary="computing" data-type="indexterm" id="idm46507973011136"/><a data-primary="natural language processing (NLP)" data-secondary="Wikipedia data" data-tertiary="TF-IDF computed" data-type="indexterm" id="idm46507973010192"/><a data-primary="latent Dirichlet allocation (LDA)" data-secondary="Wikipedia data" data-tertiary="TF-IDF computed" data-type="indexterm" id="idm46507973009008"/><a data-primary="Wikipedia document processing" data-secondary="data" data-tertiary="TF-IDF computed" data-type="indexterm" id="idm46507973007824"/><a data-primary="Spark NLP" data-secondary="Wikipedia data" data-tertiary="TF-IDF computed" data-type="indexterm" id="idm46507971785392"/><a data-primary="CountVectorizer" data-type="indexterm" id="idm46507971784176"/> (term frequency; that is, the frequency of each term in a document) with <code>CountVectorizer</code>, which keeps track of the vocabulary that’s being created so we can map our topics back to their corresponding words. TF creates a matrix that counts how many times each word in the vocabulary appears in each body of text. This then gives each word a weight based on its frequency. We derive the vocabulary of our data while fitting and get the counts at the transform step:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.ml.feature</code> <code class="kn">import</code> <code class="n">CountVectorizer</code>
<code class="n">cv</code> <code class="o">=</code> <code class="n">CountVectorizer</code><code class="p">(</code><code class="n">inputCol</code><code class="o">=</code><code class="s2">"tokens"</code><code class="p">,</code> <code class="n">outputCol</code><code class="o">=</code><code class="s2">"raw_features"</code><code class="p">)</code>

<code class="c1"># train the model</code>
<code class="n">cv_model</code> <code class="o">=</code> <code class="n">cv</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">tokens_df</code><code class="p">)</code>

<code class="c1"># transform the data. Output column name will be raw_features.</code>
<code class="n">vectorized_tokens</code> <code class="o">=</code> <code class="n">cv_model</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">tokens_df</code><code class="p">)</code></pre>
<p>Then, we proceed with IDF (the inverse frequency of documents where a term occurred), which reduces the weights of commonly appearing terms:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.ml.feature</code> <code class="kn">import</code> <code class="n">IDF</code>
<code class="n">idf</code> <code class="o">=</code> <code class="n">IDF</code><code class="p">(</code><code class="n">inputCol</code><code class="o">=</code><code class="s2">"raw_features"</code><code class="p">,</code> <code class="n">outputCol</code><code class="o">=</code><code class="s2">"features"</code><code class="p">)</code>

<code class="n">idf_model</code> <code class="o">=</code> <code class="n">idf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">vectorized_tokens</code><code class="p">)</code>

<code class="n">vectorized_df</code> <code class="o">=</code> <code class="n">idf_model</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">vectorized_tokens</code><code class="p">)</code></pre>
<p>This is what the result will look like:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">vectorized_df</code> <code class="o">=</code> <code class="n">vectorized_df</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'raw_features'</code><code class="p">))</code>

<code class="n">vectorized_df</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">6</code><code class="p">)</code>
<code class="o">...</code>

<code class="o">+--------------------+--------------------+--------------------+</code>
<code class="o">|</code>               <code class="n">title</code><code class="o">|</code>              <code class="n">tokens</code><code class="o">|</code>            <code class="n">features</code><code class="o">|</code>
<code class="o">+--------------------+--------------------+--------------------+</code>
<code class="o">|</code>      <code class="n">Tertiary</code> <code class="n">ideal</code><code class="o">|</code><code class="p">[</code><code class="n">mathemat</code><code class="p">,</code> <code class="n">tertia</code><code class="o">...|</code><code class="p">(</code><code class="mi">2451</code><code class="p">,[</code><code class="mi">1</code><code class="p">,</code><code class="mi">6</code><code class="p">,</code><code class="mi">43</code><code class="p">,</code><code class="mi">56</code><code class="p">,</code><code class="o">...|</code>
<code class="o">|</code><code class="n">Binomial</code> <code class="p">(</code><code class="n">polynom</code><code class="o">...|</code><code class="p">[</code><code class="n">algebra</code><code class="p">,</code> <code class="n">binomi</code><code class="p">,</code><code class="o">...|</code><code class="p">(</code><code class="mi">2451</code><code class="p">,[</code><code class="mi">0</code><code class="p">,</code><code class="mi">10</code><code class="p">,</code><code class="mi">14</code><code class="p">,</code><code class="mf">34.</code><code class="o">..|</code>
<code class="o">|</code>             <code class="n">Algebra</code><code class="o">|</code><code class="p">[</code><code class="n">algebra</code><code class="p">,</code> <code class="n">on</code><code class="p">,</code> <code class="n">bro</code><code class="o">...|</code><code class="p">(</code><code class="mi">2451</code><code class="p">,[</code><code class="mi">0</code><code class="p">,</code><code class="mi">1</code><code class="p">,</code><code class="mi">5</code><code class="p">,</code><code class="mi">6</code><code class="p">,</code><code class="mf">15.</code><code class="o">..|</code>
<code class="o">|</code> <code class="n">Kernel</code> <code class="p">(</code><code class="nb">set</code> <code class="n">theory</code><code class="p">)</code><code class="o">|</code><code class="p">[</code><code class="nb">set</code><code class="p">,</code> <code class="n">theori</code><code class="p">,</code> <code class="n">ker</code><code class="o">...|</code><code class="p">(</code><code class="mi">2451</code><code class="p">,[</code><code class="mi">2</code><code class="p">,</code><code class="mi">3</code><code class="p">,</code><code class="mi">13</code><code class="p">,</code><code class="mi">19</code><code class="p">,</code><code class="o">...|</code>
<code class="o">|</code><code class="n">Generalized</code> <code class="n">arith</code><code class="o">...|</code><code class="p">[</code><code class="n">mathemat</code><code class="p">,</code> <code class="n">gener</code><code class="p">,</code><code class="o">...|</code><code class="p">(</code><code class="mi">2451</code><code class="p">,[</code><code class="mi">1</code><code class="p">,</code><code class="mi">2</code><code class="p">,</code><code class="mi">6</code><code class="p">,</code><code class="mi">45</code><code class="p">,</code><code class="mf">4.</code><code class="o">..|</code>
<code class="o">+--------------------+--------------------+--------------------+</code></pre>
<p>With all the preprocessing and feature engineering done, we can now create our LDA model. That’s what we’ll do in the next section.</p>
</div></section>
<section data-pdf-bookmark="Creating Our LDA Model" data-type="sect1"><div class="sect1" id="idm46507971658320">
<h1>Creating Our LDA Model</h1>
<p>We had mentioned previously that<a data-primary="natural language processing (NLP)" data-secondary="latent Dirichlet allocation" data-tertiary="creating LDA model" data-type="indexterm" id="ch06-LDA"/><a data-primary="Wikipedia document processing" data-secondary="latent Dirichlet allocation" data-tertiary="creating LDA model" data-type="indexterm" id="ch06-LDA2"/><a data-primary="Spark NLP" data-secondary="latent Dirichlet allocation" data-tertiary="creating LDA model" data-type="indexterm" id="ch06-LDA3"/><a data-primary="latent Dirichlet allocation (LDA)" data-secondary="creating LDA model" data-type="indexterm" id="ch06-LDA4"/><a data-primary="topic modeling" data-secondary="creating LDA model" data-type="indexterm" id="ch06-LDA5"/><a data-primary="natural language processing (NLP)" data-secondary="topic modeling" data-tertiary="creating LDA model" data-type="indexterm" id="ch06-LDA6"/><a data-primary="Wikipedia document processing" data-secondary="topic modeling" data-tertiary="creating LDA model" data-type="indexterm" id="ch06-LDA7"/> LDA distills a corpus into a set of relevant topics. We will get to have a look at examples of such topics further ahead in this section. <a data-primary="latent Dirichlet allocation (LDA)" data-secondary="creating LDA model" data-tertiary="hyperparameters" data-type="indexterm" id="idm46507971902448"/><a data-primary="hyperparameters" data-secondary="LDA (latent Dirichlet allocation) model" data-type="indexterm" id="idm46507971901264"/>Before that, we need to decide on two hyperparameters that our LDA model requires. They are number of topics (referred to as <em>k</em>) and number of iterations.</p>
<p>There are multiple ways that you can go about choosing <em>k</em>. Two popular metrics used for doing this<a data-primary="perplexity metric for NLP" data-type="indexterm" id="idm46507971898912"/><a data-primary="topic coherence metric for NLP" data-type="indexterm" id="idm46507971898240"/> are perplexity and topic coherence. The former is made available by PySpark’s implementation. The basic idea is to try to figure out the <em>k</em> where the improvements to these metrics start to become insignificant. If you are familiar with the <em>elbow method</em> for finding the number of clusters for K-means, this is similar. Depending on the size of your corpus, it can be a resource-intensive and time-consuming process since you will need to build the model for multiple values of <em>k</em>. An alternative could be to try to create a representative sample of the dataset in hand and use it to determine <em>k</em>. It is left as an exercise for you to read up on this and try it.</p>
<p>Since you may be working locally right now, we will go ahead and assign reasonable values (<em>k</em> as 5 and <code>max_iter</code> as 50) for now.</p>
<p>Let’s create our LDA model:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.ml.clustering</code> <code class="kn">import</code> <code class="n">LDA</code>

<code class="n">num_topics</code> <code class="o">=</code> <code class="mi">5</code>
<code class="n">max_iter</code> <code class="o">=</code> <code class="mi">50</code>

<code class="n">lda</code> <code class="o">=</code> <code class="n">LDA</code><code class="p">(</code><code class="n">k</code><code class="o">=</code><code class="n">num_topics</code><code class="p">,</code> <code class="n">maxIter</code><code class="o">=</code><code class="n">max_iter</code><code class="p">)</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">lda</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">vectorized_df</code><code class="p">)</code>

<code class="n">lp</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">logPerplexity</code><code class="p">(</code><code class="n">vectorized_df</code><code class="p">)</code>

<code class="nb">print</code><code class="p">(</code><code class="s2">"The upper bound on perplexity: "</code> <code class="o">+</code> <code class="nb">str</code><code class="p">(</code><code class="n">lp</code><code class="p">))</code>
<code class="o">...</code>

<code class="n">The</code> <code class="n">upper</code> <code class="n">bound</code> <code class="n">on</code> <code class="n">perplexity</code><code class="p">:</code> <code class="mf">6.768323190833805</code></pre>
<p>Perplexity is a measurement of how well a model predicts a sample. A low perplexity indicates the probability distribution is good at predicting the sample. When comparing different models, go for the one with the lower value of perplexity.</p>
<p>Now that we have created our model, we want to output the topics as human-readable. We will get the vocabulary generated from our preprocessing steps, get the topics from the LDA model, and map both of them.</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">vocab</code><code> </code><code class="o">=</code><code> </code><code class="n">cv_model</code><code class="o">.</code><code class="n">vocabulary</code><code> </code><a class="co" href="#callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-1" id="co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code>
</code><code class="n">raw_topics</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">describeTopics</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code class="n">collect</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-2" id="co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a><code>
</code><code>
</code><code class="n">topic_inds</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">ind</code><code class="o">.</code><code class="n">termIndices</code><code> </code><code class="k">for</code><code> </code><code class="n">ind</code><code> </code><code class="ow">in</code><code> </code><code class="n">raw_topics</code><code class="p">]</code><code> </code><a class="co" href="#callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-3" id="co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-3"><img alt="3" height="12" src="assets/3.png" width="12"/></a><code>
</code><code>
</code><code class="n">topics</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>
</code><code class="k">for</code><code> </code><code class="n">topic</code><code> </code><code class="ow">in</code><code> </code><code class="n">topic_inds</code><code class="p">:</code><code>
</code><code>    </code><code class="n">_topic</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>
</code><code>    </code><code class="k">for</code><code> </code><code class="n">ind</code><code> </code><code class="ow">in</code><code> </code><code class="n">topic</code><code class="p">:</code><code>
</code><code>        </code><code class="n">_topic</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">vocab</code><code class="p">[</code><code class="n">ind</code><code class="p">]</code><code class="p">)</code><code>
</code><code>    </code><code class="n">topics</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">_topic</code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-1" id="callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>Create a reference to our vocabulary.</p></dd>
<dt><a class="co" href="#co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-2" id="callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></dt>
<dd><p>Get topics generated by the LDA model using <code>describeTopics</code> and load them into a Python list.</p></dd>
<dt><a class="co" href="#co_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-3" id="callout_understanding_wikipedia___span_class__keep_together__with_lda_and_spark_nlp__span__CO4-3"><img alt="3" height="12" src="assets/3.png" width="12"/></a></dt>
<dd><p>Get indices of the vocabulary terms from our topics.</p></dd>
</dl>
<p>Let us now generate the mappings from our topic indices to our vocabulary:</p>
<pre data-code-language="python" data-type="programlisting"><code class="k">for</code> <code class="n">i</code><code class="p">,</code> <code class="n">topic</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">topics</code><code class="p">,</code> <code class="n">start</code><code class="o">=</code><code class="mi">1</code><code class="p">):</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"topic </code><code class="si">{</code><code class="n">i</code><code class="si">}</code><code class="s2">: </code><code class="si">{</code><code class="n">topic</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
<code class="o">...</code>

<code class="n">topic</code> <code class="mi">1</code><code class="p">:</code> <code class="p">[</code><code class="s1">'islam'</code><code class="p">,</code> <code class="s1">'health'</code><code class="p">,</code> <code class="s1">'drug'</code><code class="p">,</code> <code class="s1">'empir'</code><code class="p">,</code> <code class="s1">'medicin'</code><code class="p">,</code> <code class="s1">'polici'</code><code class="p">,</code><code class="o">...</code>
<code class="n">topic</code> <code class="mi">2</code><code class="p">:</code> <code class="p">[</code><code class="s1">'formula'</code><code class="p">,</code> <code class="s1">'group'</code><code class="p">,</code> <code class="s1">'algebra'</code><code class="p">,</code> <code class="s1">'gener'</code><code class="p">,</code> <code class="s1">'transform'</code><code class="p">,</code>    <code class="o">...</code>
<code class="n">topic</code> <code class="mi">3</code><code class="p">:</code> <code class="p">[</code><code class="s1">'triangl'</code><code class="p">,</code> <code class="s1">'plane'</code><code class="p">,</code> <code class="s1">'line'</code><code class="p">,</code> <code class="s1">'point'</code><code class="p">,</code> <code class="s1">'two'</code><code class="p">,</code> <code class="s1">'tangent'</code><code class="p">,</code>  <code class="o">...</code>
<code class="n">topic</code> <code class="mi">4</code><code class="p">:</code> <code class="p">[</code><code class="s1">'face'</code><code class="p">,</code> <code class="s1">'therapeut'</code><code class="p">,</code> <code class="s1">'framework'</code><code class="p">,</code> <code class="s1">'particl'</code><code class="p">,</code> <code class="s1">'interf'</code><code class="p">,</code>  <code class="o">...</code>
<code class="n">topic</code> <code class="mi">5</code><code class="p">:</code> <code class="p">[</code><code class="s1">'comput'</code><code class="p">,</code> <code class="s1">'polynomi'</code><code class="p">,</code> <code class="s1">'pattern'</code><code class="p">,</code> <code class="s1">'internet'</code><code class="p">,</code> <code class="s1">'network'</code><code class="p">,</code> <code class="o">...</code></pre>
<p>The previous result is not perfect, but there are some patterns that can be noticed in the topics. Topic 1 is primarily related to health. It also contains references to Islam and empire. Could it be because of them being referenced in medicinal history and vice versa or something else? Topics 2 and 3 are related to mathematics with the latter inclined toward geometry. Topic 5 is a mix of computing and mathematics. Even if you hadn’t read any of the documents, you can already guess with a reasonable accuracy about their categories. This is exciting!</p>
<p>We can now also check which topics our input documents are most closely related to. A single document can have multiple topic associations that are significant. For now, we’ll only look at the most strongly associated topics.</p>
<p>Let’s run the LDA model’s transform operation on our input dataframe:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">lda_df</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">vectorized_df</code><code class="p">)</code>
<code class="n">lda_df</code><code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'title'</code><code class="p">),</code> <code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'topicDistribution'</code><code class="p">))</code><code class="o">.</code>\
                <code class="n">show</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="n">vertical</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <code class="n">truncate</code><code class="o">=</code><code class="kc">False</code><code class="p">)</code>
<code class="o">...</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">0</code><code class="o">-------------------------------------</code>
 <code class="n">title</code>             <code class="o">|</code> <code class="n">Tertiary</code> <code class="n">ideal</code>
 <code class="n">topicDistribution</code> <code class="o">|</code> <code class="p">[</code><code class="mf">5.673953573608612E-4</code><code class="p">,</code><code class="o">...</code>
<code class="o">-</code><code class="n">RECORD</code> <code class="mi">1</code><code class="o">----------------------------------...</code>
 <code class="n">title</code>             <code class="o">|</code> <code class="n">Binomial</code> <code class="p">(</code><code class="n">polynomial</code><code class="p">)</code> <code class="o">...</code>
 <code class="n">topicDistribution</code> <code class="o">|</code> <code class="p">[</code><code class="mf">0.0019374384060205127</code><code class="o">...</code>
<code class="n">only</code> <code class="n">showing</code> <code class="n">top</code> <code class="mi">2</code> <code class="n">rows</code></pre>
<p>As you can see, each document has a topic probability distribution associated with it. To get the associated topic for each document, we want to find out the topic index with the highest probability score. We can then map it to the topics that we obtained previously.</p>
<p>We will write a PySpark UDF to find the highest topic probability score for each record:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.sql.types</code> <code class="kn">import</code> <code class="n">IntegerType</code>
<code class="n">max_index</code> <code class="o">=</code> <code class="n">fun</code><code class="o">.</code><code class="n">udf</code><code class="p">(</code><code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">x</code><code class="o">.</code><code class="n">tolist</code><code class="p">()</code><code class="o">.</code><code class="n">index</code><code class="p">(</code><code class="nb">max</code><code class="p">(</code><code class="n">x</code><code class="p">))</code> <code class="o">+</code> <code class="mi">1</code><code class="p">,</code> <code class="n">IntegerType</code><code class="p">())</code>
<code class="n">lda_df</code> <code class="o">=</code> <code class="n">lda_df</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s1">'topic_index'</code><code class="p">,</code>
                        <code class="n">max_index</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'topicDistribution'</code><code class="p">)))</code></pre>
<pre data-code-language="python" data-type="programlisting"><code class="n">lda_df</code><code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s1">'title'</code><code class="p">,</code> <code class="s1">'topic_index'</code><code class="p">)</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="n">truncate</code><code class="o">=</code><code class="kc">False</code><code class="p">)</code>
<code class="o">...</code>

<code class="o">+----------------------------------+-----------+</code>
<code class="o">|</code><code class="n">title</code>                             <code class="o">|</code><code class="n">topic_index</code><code class="o">|</code>
<code class="o">+----------------------------------+-----------+</code>
<code class="o">|</code><code class="n">Tertiary</code> <code class="n">ideal</code>                    <code class="o">|</code><code class="mi">2</code>          <code class="o">|</code>
<code class="o">|</code><code class="n">Binomial</code> <code class="p">(</code><code class="n">polynomial</code><code class="p">)</code>             <code class="o">|</code><code class="mi">2</code>          <code class="o">|</code>
<code class="o">|</code><code class="n">Algebra</code>                           <code class="o">|</code><code class="mi">2</code>          <code class="o">|</code>
<code class="o">|</code><code class="n">Kernel</code> <code class="p">(</code><code class="nb">set</code> <code class="n">theory</code><code class="p">)</code>               <code class="o">|</code><code class="mi">2</code>          <code class="o">|</code>
<code class="o">|</code><code class="n">Generalized</code> <code class="n">arithmetic</code> <code class="n">progression</code><code class="o">|</code><code class="mi">2</code>          <code class="o">|</code>
<code class="o">|</code><code class="n">Schur</code> <code class="n">algebra</code>                     <code class="o">|</code><code class="mi">2</code>          <code class="o">|</code>
<code class="o">|</code><code class="n">Outline</code> <code class="n">of</code> <code class="n">algebra</code>                <code class="o">|</code><code class="mi">2</code>          <code class="o">|</code>
<code class="o">|</code><code class="n">Recurrence</code> <code class="n">relation</code>               <code class="o">|</code><code class="mi">5</code>          <code class="o">|</code>
<code class="o">|</code><code class="n">Rational</code> <code class="n">difference</code> <code class="n">equation</code>      <code class="o">|</code><code class="mi">5</code>          <code class="o">|</code>
<code class="o">|</code><code class="n">Polynomial</code> <code class="n">arithmetic</code>             <code class="o">|</code><code class="mi">2</code>          <code class="o">|</code>
<code class="o">+----------------------------------+-----------+</code>
<code class="n">only</code> <code class="n">showing</code> <code class="n">top</code> <code class="mi">11</code> <code class="n">rows</code></pre>
<p>Topic 2, if you remember, was associated with mathematics. The output is in line with our expectations. You can scan more of the dataset to see how it performed. You can select particular topics using the <code>where</code> or <code>filter</code> commands and compare them against the topic list generated earlier to get a better sense of the clusters that have been created.
As promised at the beginning of the chapter, we’re able to cluster articles into different topics without reading them!<a data-startref="ch06-LDA" data-type="indexterm" id="idm46507970952912"/><a data-startref="ch06-LDA2" data-type="indexterm" id="idm46507970952272"/><a data-startref="ch06-LDA3" data-type="indexterm" id="idm46507970951600"/><a data-startref="ch06-LDA4" data-type="indexterm" id="idm46507970950928"/><a data-startref="ch06-LDA5" data-type="indexterm" id="idm46507970950256"/><a data-startref="ch06-LDA6" data-type="indexterm" id="idm46507970949584"/><a data-startref="ch06-LDA7" data-type="indexterm" id="idm46507970948912"/></p>
</div></section>
<section data-pdf-bookmark="Where to Go from Here" data-type="sect1"><div class="sect1" id="idm46507971657408">
<h1>Where to Go from Here</h1>
<p>In this chapter, we performed LDA on the Wikipedia corpus. In the process, we also learned about text preprocessing using the amazing Spark NLP library and the TF-IDF technique. You can further build on this by improving the model by better preprocessing and hyperparameter tuning. In addition, you can even try to recommend similar entries based on document similarity when provided with user input. Such a similarity measure may be obtained by using the probability distribution vector obtained from LDA.</p>
<p>In addition, a variety of other methods exist for understanding large corpora of text. For example, a technique known as latent semantic analysis (LSA) is useful in similar applications and was used in the previous edition of this book on the same dataset. Deep learning, which is explored in <a data-type="xref" href="ch10.xhtml#image_similarity_detection_with_deep_learning_and_pyspark_lsh">Chapter 10</a>, also offers avenues to perform topic modeling. You can explore them on your own.</p>
</div></section>
</div></section></div></body></html>