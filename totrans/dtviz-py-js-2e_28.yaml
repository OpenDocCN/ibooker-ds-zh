- en: Chapter 22\. Conclusion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第22章 结论
- en: Although this book had a guiding narrative—the transformation of some basic
    Wikipedia HTML pages into a modern, interactive JavaScript web visualization—it
    is meant to be dipped into as and when required. The different parts are self-contained,
    allowing for the existence of the dataset in its various stages, and can be used
    independently. Let’s have a short recap of what was covered before moving on to
    a few ideas for future visualization work.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本书有一个引导性的叙述——将一些基本的维基百科HTML页面转化为现代、交互式的JavaScript Web可视化——它旨在根据需要随时查阅。不同的部分是独立的，允许数据集以其各个阶段的存在，并可以独立使用。在继续前进之前，让我们简要回顾一下之前涵盖的内容，并提出一些未来可视化工作的想法。
- en: Recap
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾
- en: 'This book was divided into five parts. The first part introduced a basic Python
    and JavaScript dataviz toolkit, while the next four showed how to retrieve raw
    data, clean it, explore it, and finally transform it into a modern web visualization.
    This process of refinement and transformation used as its backbone a dataviz challenge:
    to take a fairly basic Wikipedia Nobel Prize list and transform the dataset contained
    into something more engaging and informative. Let’s summarize the key lessons
    of each part now.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书分为五个部分。第一部分介绍了基本的Python和JavaScript数据可视化工具包，而接下来的四部分则展示了如何获取原始数据、清理数据、探索数据，最后将其转化为现代Web可视化。这个精炼和转化的过程以数据可视化挑战为基础：将基本的维基百科诺贝尔奖列表转化为更具吸引力和信息性的数据集。现在让我们总结每个部分的关键教训。
- en: 'Part I: Basic Toolkit'
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第I部分：基本工具包
- en: 'Our basic toolkit consisted of:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的基本工具包包括：
- en: A language-learning bridge between Python and JavaScript. This was designed
    to smooth the transition between the two languages, highlighting their many similarities
    and setting the scene for the bilingual process of modern dataviz. Python and
    JavaScript share even more in common, making switching between them that much
    less stressful.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种连接Python和JavaScript的语言学习桥梁。设计它的初衷是平滑过渡这两种语言，突出它们的许多相似之处，并为现代数据可视化的双语过程设定场景。Python和JavaScript有更多共同点，这使得在它们之间切换变得更加轻松。
- en: Being able to read from and write to the key data formats (e.g., JSON and CSV)
    and databases (both SQL and NoSQL) with ease is one of Python’s great strengths.
    We saw how easy it is to pass data around in Python, translating formats and changing
    databases as we go. This fluid movement of data is the main lubricant of any dataviz
    toolchain.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够轻松读写主要数据格式（例如JSON和CSV）和数据库（包括SQL和NoSQL）是Python的一大优势。我们看到，在Python中传递数据如此简单，可以在此过程中转换格式并更改数据库。数据的流动是任何数据可视化工具链的主要润滑剂。
- en: We covered the basic web development (webdev) skills needed to start producing
    modern, interactive, browser-based dataviz. By focusing on the concept of the
    [single-page application](https://oreil.ly/v0vDP) rather than building whole websites,
    we minimize conventional webdev and place the emphasis on programming your visual
    creations in JavaScript. An introduction to Scalable Vector Graphics (SVG), the
    chief building block of D3 visualizations, set the scene for the creation of our
    Nobel Prize visualization in [Part V](part05.xhtml#part_viz).
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们讨论了开始制作现代、交互式、基于浏览器的数据可视化所需的基本Web开发（webdev）技能。通过专注于单页面应用程序的概念，而不是构建整个网站，我们最大程度地减少了传统的Web开发，并将重点放在用JavaScript编程您的视觉创作上。可伸缩矢量图形（SVG）的介绍，作为D3可视化的主要构建块，为我们在第五部分创建诺贝尔奖可视化奠定了基础（part05.xhtml#part_viz）。
- en: 'Part II: Getting Your Data'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第II部分：获取您的数据
- en: 'In this part of the book, we looked at how to get data from the web using Python,
    assuming a nice, clean data file hasn’t been provided to the data visualizer:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的这一部分中，我们看到如何使用Python从Web获取数据，假设数据可视化者没有提供一个干净、整洁的数据文件：
- en: If you’re lucky, a clean file in an easily usable data format (i.e., JSON or
    CSV) is at an open URL, a simple HTTP request away. Alternatively, there may be
    a dedicated web API for your dataset, with any luck a RESTful one. As an example,
    we looked at using the Twitter API (via Python’s Tweepy library). We also saw
    how to use Google spreadsheets, a widely used data-sharing resource in dataviz.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你幸运的话，在一个易于使用的数据格式（即JSON或CSV）的开放URL上，可能有一个干净的文件，只需进行简单的HTTP请求即可获取。或者，可能有一个专门的Web
    API用于您的数据集，如果幸运的话，它可能是一个RESTful API。作为示例，我们看了如何使用Twitter API（通过Python的Tweepy库）。我们还看到了如何使用Google电子表格，这是数据可视化中广泛使用的数据共享资源。
- en: Things get more involved when the data of interest is present on the web in
    human-readable form, often in HTML tables, lists, or hierarchical content blocks.
    In this case, you have to resort to *scraping*, getting the raw HTML content and
    then using a parser to make its embedded content available. We saw how to use
    Python’s lightweight Beautiful Soup scraping library and the much more featureful
    and heavyweight Scrapy, the biggest star in the Python scraping firmament.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当感兴趣的数据以人类可读形式出现在网络上，通常是在HTML表格、列表或分层内容块中时，情况会更加复杂。在这种情况下，你必须求助于*抓取*，获取原始HTML内容，然后使用解析器使其嵌入内容可用。我们看到了如何使用Python的轻量级Beautiful
    Soup抓取库以及更多功能强大和重量级的Scrapy，后者是Python抓取领域的明星。
- en: 'Part III: Cleaning and Exploring Data with pandas'
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三部分：使用pandas清理和探索数据
- en: 'In this part, we turned the big guns of pandas, Python’s powerful programmatic
    spreadsheet, on the problem of cleaning and then exploring datasets. We first
    saw how pandas is part of Python’s NumPy ecosystem, leveraging the power of very
    fast, powerful low-level array processing libraries but making them accessible.
    The focus was on using pandas to clean and then explore our Nobel Prize dataset:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这部分中，我们把pandas这一强大的Python编程电子表格工具应用于清理和探索数据集的问题上。我们首先看到pandas是Python NumPy生态系统的一部分，利用了非常快速、强大的低级别数组处理库的力量，但使其易于使用。重点是使用pandas清理和探索我们的诺贝尔奖数据集：
- en: Most data, even that which comes from official web APIs, is dirty. And making
    it clean and usable will occupy far more of your time as a data visualizer than
    you probably anticipated. Taking the Nobel dataset as an example, we progressively
    cleaned it, searching for dodgy dates, anomalous datatypes, missing fields, and
    all the common grime that needs cleaning before you can start to explore and then
    transform your data into a visualization.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数数据，即使来自官方网络API，也是脏乱的。使其变得清洁和可用将占据你作为数据可视化者更多的时间，这可能超出了你的预期。以诺贝尔奖数据集为例，我们逐步清理它，搜索不可靠的日期，异常的数据类型，缺失字段以及所有需要在开始探索并将数据转换为可视化之前清理的常见问题。
- en: With our clean (as we could make it) Nobel Prize dataset in hand, we saw how
    easy it is to use pandas and Matplotlib to interactively explore data, easily
    creating inline charts, slicing the data every which way, and generally getting
    a feel for it, while looking for those interesting nuggets you want to deliver
    with visualization.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手头有我们尽可能清洁的诺贝尔奖数据集后，我们看到了使用pandas和Matplotlib进行交互式数据探索是多么容易，可以轻松创建内联图表，灵活地切片数据，并且总体上对数据有了更深的了解，同时寻找那些你想要通过可视化呈现的有趣信息。
- en: 'Part IV: Delivering the Data'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四部分：数据交付
- en: In this part, we saw how easy it is to create a minimal data API using Flask,
    to deliver data both statically and dynamically to the web browser.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这部分中，我们看到了使用Flask创建最小数据API是多么容易，可以将数据静态和动态地提供给Web浏览器。
- en: First, we saw how to use Flask to serve static files and then how to roll your
    own basic data API, serving data from a local database. Flask’s minimalism allows
    you to create a very thin data-serving layer between the fruits of your Python
    data processing and their eventual visualization on the browser. The glory of
    open source software is that you can often find robust, easy-to-use libraries
    that solve your problem better than you could. In the second chapter of this part,
    we saw how easy it is to use best-of-breed Python (Flask) libraries to craft a
    robust, flexible RESTful API, ready to server your data online. We also covered
    the easy online deployment of this data server using Heroku, a favorite of Pythonistas.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们看到如何使用Flask来提供静态文件，然后如何自行构建基本的数据API，从本地数据库提供数据。Flask的极简主义允许你在Python数据处理成果与最终在浏览器上可视化之间创建非常薄的数据服务层。开源软件的优势在于，你通常可以找到比你更好地解决问题的稳健易用的库。在本部分的第二章，我们看到了如何使用Python的最佳库（Flask）轻松创建健壮灵活的RESTful
    API，准备好在线提供你的数据。我们还介绍了如何使用Heroku进行轻松的在线部署，这是Python爱好者喜爱的平台。
- en: 'Part V: Visualizing Your Data with D3 and Plotly'
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第五部分：使用D3和Plotly可视化你的数据
- en: In the first chapter of this part, we saw how to take the fruits of your pandas-driven
    exploration, in the form of charts or maps, and put them on the web, where they
    belong. Matplotlib can produce publication-standard static charts, while Plotly
    brings user controls and dynamic charts to the table. We saw how to take a Plotly
    chart directly from a Jupyter notebook and put it in a web page.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分的第一章中，我们看到了如何通过 pandas 驱动的探索结果（如图表或地图）并将它们放在它们应该展示的地方——网页上。Matplotlib 可以生成出版标准的静态图表，而
    Plotly 则为用户提供控件和动态图表。我们还看到了如何将 Plotly 图表直接从 Jupyter 笔记本放入网页中。
- en: I think it’s fair to say that taking on D3 was the most ambitious part of this
    book, but I was determined to demonstrate the construction of a multielement visualization,
    such as the kind you may well end up being employed to make. One of the joys of
    D3 is the [huge number of examples](https://oreil.ly/nYKx8) that can easily be
    found online, but most of them demonstrate a single technique and there are few
    showing how to orchestrate multiple visual elements. In these D3 chapters, we
    saw how to synchronize the update of a timeline (featuring all the Nobel Prizes),
    a map, a bar chart, and a list as the user filtered the Nobel Prize dataset or
    changed the prize-winning metric (absolute or per capita).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为可以说，学习 D3 是本书中最雄心勃勃的部分，但我决心展示如何构建多元素可视化，例如您可能最终被雇用去制作的可视化。D3 的一大乐趣在于可以轻松找到大量的[示例](https://oreil.ly/nYKx8)在线，但大多数示例仅演示单一技术，并且几乎没有展示如何编排多个视觉元素的示例。在这些
    D3 章节中，我们看到了如何同步更新一个时间线（包含所有的诺贝尔奖），一个地图，一个条形图和一个列表，当用户过滤诺贝尔奖数据集或更改获奖指标（绝对或人均）时。
- en: Mastery of the core themes demonstrated in these chapters should allow you to
    let loose your imagination and learn by doing. I’d recommend choosing some data
    close to your heart and designing a D3 creation around it.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握这些章节中展示的核心主题应该使您能够释放您的想象力并通过实践学习。我建议选择一些您关心的数据，并围绕它设计一个 D3 创作。
- en: Future Progress
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来的进展
- en: As mentioned, the Python and JavaScript data-processing and visualization ecosystems
    are incredibly active right now and are building from a very solid base.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 正如提到的，Python 和 JavaScript 的数据处理和可视化生态系统目前非常活跃，并且是建立在非常坚实的基础之上。
- en: While the business of acquiring and cleaning datasets learned in [Part II](part02.xhtml#part_getting_data)
    and [Chapter 9](ch09.xhtml#chapter_cleaning) improves incrementally, getting a
    lot easier as your craft skills (e.g., your pandas fu) improve, Python is throwing
    out new and powerful data-processing tools with abandon. There’s a [fairly comprehensive
    list](https://oreil.ly/ODNE1) at the Python wiki. Here are a few ideas you might
    want to use to create some visualizations.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然获取和清理数据集在[第二部分](part02.xhtml#part_getting_data)和[第九章](ch09.xhtml#chapter_cleaning)中逐步改进，随着您的技艺（例如，您的
    pandas 技能）的提高，变得更加容易，Python 却大量推出了新的强大的数据处理工具。Python 的维基上有一份[相当全面的列表](https://oreil.ly/ODNE1)。以下是您可能想要用来创建一些可视化的一些想法。
- en: Visualizing Social Media Networks
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化社交媒体网络
- en: The advent of social media has provided a huge amount of interesting data, often
    available from a web API or eminently scrapeable. There are also curated collections
    of social media data such as [Stanford’s Large Network Dataset Collection](https://oreil.ly/2E02E)
    or the [UCIrvine collection](https://oreil.ly/x09oi). These datasets can provide
    an easy testing ground for adventures in network visualization, an increasingly
    popular area.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 社交媒体的出现提供了大量有趣的数据，通常可以从 Web API 中获取或者很容易被抓取。还有一些经过策划的社交媒体数据集，如[斯坦福大学的大型网络数据集合](https://oreil.ly/2E02E)或[加州大学尔湾分校的收藏](https://oreil.ly/x09oi)。这些数据集可以为网络可视化的探索提供一个简单的测试场所，这是一个日益流行的领域。
- en: The two most popular Python libraries for network analysis are [graph-tool](https://graph-tool.skewed.de)
    and [NetworkX](https://networkx.org). While graph-tool is more heavily optimized,
    NetworkX is arguably more user-friendly. Both libraries produce graphs in the
    common [GraphML](http://graphml.graphdrawing.org) and [GML](https://oreil.ly/18AUU)
    formats. D3 cannot read GML files directly, but it’s easy enough to convert them
    to a JSON format it can read. You’ll find a nice example of that in this [blog
    post](https://oreil.ly/thuBE), with accompanying code on [GitHub](https://oreil.ly/3IHVR).
    Note that in D3 version 4, the forceSimulation API changed. You can find a gentle
    introduction to the new API, which uses a `forceSimulation` object to keep track
    of things, on [Pluralsight](https://oreil.ly/DZxAz).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Python网络分析的两个最流行的库是[graph-tool](https://graph-tool.skewed.de)和[NetworkX](https://networkx.org)。虽然graph-tool更加优化，但NetworkX可以说更加用户友好。这两个库都可以生成通用的[GraphML](http://graphml.graphdrawing.org)和[GML](https://oreil.ly/18AUU)格式的图形。D3无法直接读取GML文件，但很容易将它们转换为JSON格式以供读取。您可以在这篇[博客文章](https://oreil.ly/thuBE)中找到一个很好的例子，其中附带了在[GitHub](https://oreil.ly/3IHVR)上的代码。请注意，在D3版本4中，forceSimulation
    API发生了变化。您可以在[Pluralsight](https://oreil.ly/DZxAz)找到对新API的简要介绍，该API使用forceSimulation对象来跟踪事物。
- en: Machine-Learning Visualizations
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习可视化
- en: Machine learning is more than a little in vogue at the moment, and Python offers
    a fantastic set of tools to allow you to start analyzing and mining your data
    with a huge range of algorithms, from the supervised to unsupervised, from basic
    regression algorithms (such as linear or logistic regression) to more esoteric,
    cutting-edge stuff like the family of ensemble algorithms such as random forest.
    See this [nice tour](https://oreil.ly/IR8LZ) of the different flavors of algorithm.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当前机器学习颇受青睐，Python提供了一套出色的工具，让您可以开始分析和挖掘数据，使用从监督到无监督、从基本回归算法（如线性或逻辑回归）到更加奇特前沿的算法族（如随机森林）的广泛算法。参见这个[不错的导览](https://oreil.ly/IR8LZ)以了解不同风格的算法。
- en: Premier among Python’s machine-learning stable is [scikit-learn](https://oreil.ly/gjAKs),
    which is part of the NumPy ecosystem, also building on SciPy and Matplotlib. scikit-learn
    provides an amazing resource for efficient data mining and data analysis. Algorithms
    that only a few years back would have taken days or weeks to craft are available
    with a single import, well designed, easy to use, and able to get useful results
    in a few lines of code.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python的机器学习工具中，首屈一指的是[scikit-learn](https://oreil.ly/gjAKs)，它是NumPy生态系统的一部分，同时也依赖于SciPy和Matplotlib。scikit-learn为高效的数据挖掘和数据分析提供了一个令人惊叹的资源。几年前还需要花费几天甚至几周来开发的算法，现在只需一行导入就能获得，设计良好，易于使用，并且能够在几行代码中获得有用的结果。
- en: Tools like scikit-learn enable you to discover deep correlations in your data,
    if they exist. There’s a [nice demonstration](https://oreil.ly/Q0GVd) at R2D3
    that both introduces some machine-learning techniques and uses D3 to visualize
    the process and results. It’s a great example of the creative freedom that mastery
    of D3 provides and the way in which good web dataviz is pushing the boundaries,
    making novel visualizations that engage in a way that hasn’t been possible before—and,
    of course, are available to everybody.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 像scikit-learn这样的工具使您能够发现数据中存在的深层次相关性。在R2D3上有一个[不错的演示](https://oreil.ly/Q0GVd)，介绍了一些机器学习技术，并使用D3来可视化过程和结果。这是D3掌握带来的创造自由的一个很好的例子，以及优秀的网络数据可视化正在推动界限，创造出以前不可能的新颖可视化效果，并且当然这些都是对每个人都可用的。
- en: There’s a [great collection](https://oreil.ly/wZ1bJ) of IPython (Jupyter) notebooks
    for statistics, machine learning, and data science at the IPython GitHub repo.
    Many of these demonstrate visualization techniques that can be adapted and extended
    in your own works.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在IPython（Jupyter）的GitHub仓库中有一个[很棒的集合](https://oreil.ly/wZ1bJ)，涵盖了统计、机器学习和数据科学的IPython笔记本。其中许多演示了可在您自己的工作中进行适应和扩展的可视化技术。
- en: Final Thoughts
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结思考
- en: The suggestions in the previous section just scratch the surface of where you
    might take your new Python and JavaScript dataviz skills. Hopefully this book
    has provided a solid bedrock on which to build your web dataviz efforts for the
    many jobs now opening up in the field or just to scratch a personal itch. The
    ability to harness Python’s immensely powerful data wrangling and general-purpose
    abilities to JavaScript’s (D3 being prominent here) increasingly powerful and
    mature visualization libraries represents the richest dataviz stack I know. Skills
    in this area are already very bankable, but the pace of change and scale of interest
    is increasing at a rapid rate. I hope you find this exciting and emergent field
    as fulfilling as I do.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中提出的建议只是揭示了你可能利用新学到的Python和JavaScript数据可视化技能的表面。希望本书为你在这个领域建立网页数据可视化工作提供了坚实的基础，或者只是为了满足个人的兴趣。能够利用Python强大的数据处理和通用能力与JavaScript（尤其是D3）日益强大和成熟的可视化库，代表了我所知道的最丰富的数据可视化技术栈。这一领域的技能已经非常值钱，但变化的速度和兴趣的规模正在迅速增加。希望你发现这个充满活力和新兴的领域像我一样充满成就感。
