<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 3. Introduction to Causal Diagrams"><div class="chapter" id="introduction_to_causal_diagrams">
<h1><span class="label">Chapter 3. </span>Introduction to Causal Diagrams</h1>

<blockquote data-type="epigraph" epub:type="epigraph">
<p>In fact, with few exceptions, correlation does imply causation.<a contenteditable="false" data-primary="correlation" data-secondary="causation implied" data-type="indexterm" id="idm45968167713096"/><a contenteditable="false" data-primary="causes" data-secondary="correlation implying causation" data-type="indexterm" id="idm45968167711640"/> If we observe a systematic relationship between two variables, and we have ruled out the likelihood that this is simply due to a random coincidence, then something must be causing this relationship. When the audience at a Malay shadow theatre sees a solid round shadow on the screen they know that some three-dimensional object has cast it, though they may not know if the object is a ball or a rice bowl in profile. A more accurate sound bite for introductory statistics would be that a simple correlation implies an unresolved causal structure.</p>

<p data-type="attribution">Bill Shipley, <em>Cause and Correlation in Biology</em> (2016)<a contenteditable="false" data-primary="Shipley, Bill" data-type="indexterm" id="idm45968167708376"/></p>
</blockquote>

<p>Causal diagrams (CDs) may well be one of the most powerful tools for analysis most people have never heard of. As such they are one of the three extremities (vertices) of the causal-behavioral framework<a contenteditable="false" data-primary="CDs" data-see="causal diagrams" data-type="indexterm" id="idm45968167706504"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="about causal-behavioral framework" data-type="indexterm" id="idm45968167705128"/> (<a data-type="xref" href="#the_causal_behavioral_framework_for_d">Figure 3-1</a>). <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="about" data-type="indexterm" id="idm45968167702552"/>They provide a language to express and analyze cause-to-effect relationships, which works especially well when dealing with behavioral data analyses.</p>

<figure><div id="the_causal_behavioral_framework_for_d" class="figure"><img alt="" src="Images/BEDA_0301.png" width="596" height="371"/>
<h6><span class="label">Figure 3-1. </span>The causal-behavioral framework for data analysis</h6>
</div></figure>

<p>In the first section of this chapter, I’ll show how CDs fit into the framework from a conceptual perspective, that is, how they are connected to behaviors and data. In the second section, I’ll describe the three fundamental structures in CDs: chains, forks, and colliders. Finally, in the third section, we’ll see some common transformations that can be applied to CDs.</p>

<section data-type="sect1" data-pdf-bookmark="Causal Diagrams and the Causal-Behavioral Framework"><div class="sect1" id="causal_diagrams_and_the_causal_behavior">
<h1>Causal Diagrams and the Causal-Behavioral Framework</h1>

<p>First, let’s define what a CD is. <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="definition" data-type="indexterm" id="idm45968167696104"/>A CD is a visual representation of variables, shown as boxes, and their relationships to each other shown as arrows going from one box to another.</p>

<p>In our C-Mart example in <a data-type="xref" href="ch01.xhtml#the_causal_behavioral_framework_for_da">Chapter 1</a>, the variable <em>IcedCoffeeSales</em> <a contenteditable="false" data-primary="C-Mart fictional supermarket chain" data-secondary="causal diagrams" data-type="indexterm" id="idm45968167692360"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="first CD C-Mart iced coffee sales" data-type="indexterm" id="idm45968167690888"/>was affected by a single cause, <em>Temperature</em>. <a data-type="xref" href="#our_very_first_causal_diagram">Figure 3-2</a> shows the corresponding causal diagram.</p>

<figure><div id="our_very_first_causal_diagram" class="figure"><img alt="Our very first causal diagram" src="Images/BEDA_0302.png" width="671" height="139"/>
<h6><span class="label">Figure 3-2. </span>Our very first causal diagram</h6>
</div></figure>

<p>Each rectangle represents a variable we can observe (one we have in our data set),<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="clear rectangles as observed variables" data-type="indexterm" id="idm45968167685736"/><a contenteditable="false" data-primary="variables" data-secondary="causal diagrams" data-type="indexterm" id="idm45968167684008"/> and the arrow between them represents the existence and direction of a causal relationship. Here, the arrow between <em>Temperature</em> and <em>IcedCoffeeSales</em> indicates that the former is a cause of the latter.</p>

<p>Sometimes, however, there will be an additional variable that we aren’t able to observe.<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="shaded rectangles or ovals as unobserved variables" data-type="indexterm" id="idm45968167680920"/><a contenteditable="false" data-primary="variables" data-secondary="unobserved variables" data-tertiary="shaded rectangles or ovals in causal diagrams" data-type="indexterm" id="idm45968167679160"/><a contenteditable="false" data-primary="unobserved variables" data-secondary="shaded rectangles or ovals in causal diagrams" data-type="indexterm" id="idm45968167677480"/> If we still want to show it in a causal diagram, we can represent it with a shaded rectangle<sup><a data-type="noteref" id="idm45968167675832-marker" href="ch03.xhtml#idm45968167675832">1</a></sup> (<a data-type="xref" href="#a_causal_diagram_with_an_unobserved_var">Figure 3-3</a>).</p>

<figure><div id="a_causal_diagram_with_an_unobserved_var" class="figure"><img alt="A causal diagram with an unobserved variable" src="Images/BEDA_0303.png" width="671" height="371"/>
<h6><span class="label">Figure 3-3. </span>A causal diagram with an unobserved variable</h6>
</div></figure>

<p>In <a data-type="xref" href="#a_causal_diagram_with_an_unobserved_var">Figure 3-3</a>, <em>CustomerSweetTooth</em> is a cause of <em>IcedCoffeeSales</em>, meaning that customers with a stronger sweet tooth buy more iced coffee. However, we can’t observe the degree of a customer’s sweet tooth. We’ll discuss later the importance of unobserved confounders and more generally unobserved variables in causal analysis. For the time being, let’s just note that even if we have no way of observing a particular variable, it can still be included in a causal diagram by representing it as an oval.</p>

<section data-type="sect2" data-pdf-bookmark="Causal Diagrams Represent Behaviors"><div class="sect2" id="causal_diagrams_represent_behaviors">
<h2>Causal Diagrams Represent Behaviors</h2>

<p>The first way of looking at causal diagrams is to treat them as<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="behaviors represented" data-type="indexterm" id="idm45968167667336"/> representations of causal relationships between behaviors, as well as other phenomena in the real world that impact behaviors (<a data-type="xref" href="#cds_are_connected_to_behaviors_in_our_f">Figure 3-4</a>). From this perspective, the elements of CDs represent real “things” that exist and have effects on each other. An analogy from physical sciences would be a magnet, a bar of iron, and the magnetic field around the magnet. You can’t see the magnetic field but it exists nonetheless, and it affects the iron bar. You may not have any data on the magnetic field and maybe you’ve never seen the equations describing it, but you can sense it as you move the bar, and you can develop intuitions as to what it does.</p>

<figure><div id="cds_are_connected_to_behaviors_in_our_f" class="figure"><img alt="CDs are connected to behaviors in our framework" src="Images/BEDA_0304.png" width="596" height="371"/>
<h6><span class="label">Figure 3-4. </span>CDs are connected to behaviors in our framework</h6>
</div></figure>

<p>The same perspective applies when we want to understand what drives behaviors. We intuitively understand that human beings have habits, preferences, and emotions, and we treat these as causes even though we often don’t have any numeric data about them. When we say, “Joe bought peanuts because he was hungry,” we are relying on our knowledge, experience, and beliefs about humans in general and Joe in particular. We treat hunger as a real thing, even if we’re not measuring Joe’s blood sugar or brain activation.</p>

<p>Here, we’re making a causal statement about reality: we’re saying that had Joe not been hungry, he wouldn’t have bought peanuts. <a contenteditable="false" data-primary="causes" data-secondary="intuitive understanding of causality" data-type="indexterm" id="idm45968167660632"/><a contenteditable="false" data-primary="intuition" data-secondary="about what drives behaviors" data-type="indexterm" id="idm45968167659240"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="intuitive understanding of causality" data-type="indexterm" id="idm45968167657848"/>Causality is so fundamental to our intuitive understanding of reality that even young children are able to make correct causal inferences (evidenced by their use of the word “because”) long before they have had any exposure to the scientific method or data analysis. <a contenteditable="false" data-primary="biases in data and analyses" data-secondary="intuition subject to biases" data-type="indexterm" id="idm45968167656040"/>Of course, intuition is subject to a variety of biases well known by behavioral scientists, even when it takes the more educated form of common sense or expertise. But more often than not, intuition guides us well in our daily lives even in the absence of quantitative data.</p>

<p>You might worry that using CDs to represent intuitions and beliefs <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="subjectivity introduced by" data-type="indexterm" id="idm45968167653800"/><a contenteditable="false" data-primary="subjectivity in causal diagrams" data-type="indexterm" id="idm45968167652328"/>about the world introduces subjectivity, and that’s certainly true. But because CDs are tools for <span class="keep-together">thinking</span> and analysis, they don’t have to be “true.” You and I might have different ideas as to why Joe bought peanuts, which means we would draw different CDs. Even if we fully agreed on what causes what, we couldn’t represent everything and their relationships in one diagram; there is judgment involved in determining what variables and relationships to include or exclude. In some cases, when data is available, it will help: we’ll be able to reject a CD because it is incompatible with the data at hand. But in other cases, very different CDs will be equally compatible with the data and we won’t be able to choose between them, especially if we don’t have experimental data.</p>

<p>This subjectivity might look like a (possibly fatal) flaw of CDs, but it’s actually a feature, not a bug. CDs don’t create uncertainty; they simply reflect the uncertainty that is already in our world. If there are several possible interpretations of the situation at hand that appear equally valid, you should explicitly say so. The alternative would be to allow people who have different mental models in their heads to each believe that they know the truth and others agree with them, when in reality that’s not the case. At least putting the uncertainty in the open will allow a principled discussion and guide your analysis.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Causal Diagrams Represent Data"><div class="sect2" id="causal_diagrams_represent_data">
<h2>Causal Diagrams Represent Data</h2>

<p>While there is an art to building and interpreting CDs, <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="data represented" data-type="indexterm" id="ch03-cada"/><a contenteditable="false" data-primary="data" data-secondary="causal diagrams" data-type="indexterm" id="ch03-cada2"/><a contenteditable="false" data-primary="variables" data-secondary="causal diagrams" data-type="indexterm" id="idm45968167643064"/>there’s also a science to it, and we can use CDs to represent relationships between variables in our data (<a data-type="xref" href="#cds_are_also_connected_to_data">Figure 3-5</a>). <a contenteditable="false" data-primary="linear algebra in causal diagrams" data-type="indexterm" id="idm45968167640408"/>When these relationships are entirely linear, or approximately so, CDs have clear equivalents in linear algebra. This means we can use the rules and tools of linear algebra to validate the “legality” of how we manipulate and transform CDs, thus ensuring that we draw correct conclusions.</p>

<figure><div id="cds_are_also_connected_to_data" class="figure"><img alt="CDs are also connected to data" src="Images/BEDA_0305.png" width="596" height="371"/>
<h6><span class="label">Figure 3-5. </span>CDs are also connected to data</h6>
</div></figure>

<p>The linearity requirement may seem very restrictive. <a contenteditable="false" data-primary="generalized linear models (GLM)" data-type="indexterm" id="idm45968167636552"/><a contenteditable="false" data-primary="logistic regressions" data-secondary="generalized linear model" data-type="indexterm" id="idm45968167635384"/>However, some of the rules and tools of linear algebra continue to apply when some of these relationships are not linear but still belong to the broad category of models called generalized linear models (GLM). A logistic regression model for example is a GLM. This means that we can represent and handle a causal relationship where the effect variable is binary with CDs. As the sidebar shows, the math gets more convoluted in that case, but most of our intuitions about CDs remain true.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="technical_deeper_dive_cds_and_logistic">
<h5>Technical Deeper Dive: CDs and Logistic Regression</h5>

<p>All the relationships we’ve seen so far between variables are linear.<a contenteditable="false" data-primary="binary variables" data-secondary="binary dependent variable regression" data-type="indexterm" id="idm45968167631256"/><a contenteditable="false" data-primary="logistic regressions" data-secondary="causal diagrams" data-type="indexterm" id="idm45968167629784"/><a contenteditable="false" data-primary="regression" data-secondary="binary dependent variable" data-type="indexterm" id="idm45968167628408"/><a contenteditable="false" data-primary="dependent variable" data-secondary="binary and logistic regression" data-type="indexterm" id="idm45968167627016"/><a contenteditable="false" data-primary="logistic regressions" data-secondary="generalized linear model" data-type="indexterm" id="idm45968167625624"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="logistic regressions" data-type="indexterm" id="idm45968167624232"/> When the dependent variable is binary (i.e., it can take only two values, usually “Yes” and “No”), we use a logistic regression rather than a linear one. Logistic regression is an example of a GLM and as such it’s not linear, but it has some linear characteristics. This implies that the logic of causal diagrams still works, with some hand waving. If you’re interested, let’s take a look under the hood to make sure you understand what’s going on.</p>

<p>Let’s look at one of our previous examples, in which taste for vanilla and taste for chocolate cause the purchase of ice cream. This time we’ll represent purchases of ice cream as a binary variable: 1 if the customer purchased at least one ice cream that day, 0 if they did not (<a data-type="xref" href="#representing_purchases_of_ice_cream_as">Figure 3-6</a>).</p>

<figure><div id="representing_purchases_of_ice_cream_as" class="figure"><img alt="Representing purchases of ice cream as a binary variable in a CD" src="Images/BEDA_0306.png" width="671" height="303"/>
<h6><span class="label">Figure 3-6. </span>Representing purchases of ice cream as a binary variable in a CD</h6>
</div></figure>

<p>Instead of the linear regression we had previously, the arrows in this CD now represent a logistic regression, meaning that the probability that our target variable equals 1 is a transformation of the linear combination of the explanatory variables:</p>

<div data-type="equation">
<p><em>P</em>(<em>IceCreamPurchase</em> = 1) = (1 + e<sup>-(<em>β</em><sub>0</sub> + <em>β</em><sub>V</sub><em>.TasteForVanilla + β</em><sub>C</sub><em>.TasteForChocolate</em>)</sup>)<sup>-1</sup></p>
</div>

<p><em>F(x)</em> = 1/(1 + <em>e<sup>-x</sup></em>) is called the logistic function, and it results in an S-curve with values between zero and one. The previous equation can therefore be rewritten by inserting the <em>f</em> function into it:</p>

<div data-type="equation">
<p><em>P</em>(<em>IceCreamPurchase</em> = 1) = <em>f</em>(<em>β</em><sub>0</sub> + <em>β</em><sub>V</sub><em>.TasteForVanilla</em> + <em>β</em><sub>C</sub><em>.TasteForChocolate</em>)</p>
</div>

<p>This means that we can’t directly translate an increase of 1 “unit” of taste for vanilla ice cream into a fixed increase in the probability of purchasing ice cream. Coefficients of a logistic regression are notoriously hard to interpret for this reason. <a contenteditable="false" data-primary="linear algebra in causal diagrams" data-type="indexterm" id="idm45968167604712"/>However, the relationships between the coefficients and the variables within the logistic function remain linear, which means that the algebraic transformations we’ll see in the next section will still be correct.</p> 

<p>For example, we could conceptually split <em>TasteForChocolate</em> into variables representing the taste for various chocolate flavors. The preceding equation would then become:</p>

<div data-type="equation">
<p><em>P</em>(<em>IceCreamPurchase</em> = 1) = <em>F</em>(<em>β</em><sub>0</sub> + <em>β</em><sub>V</sub><em>.TasteForVanilla</em> + <em>β</em><sub>DC</sub><em>.TasteForDarkChocolate</em> + <em>β</em><sub>FC</sub><em>.TasteForFudgeChocolate</em>)</p>
</div>

<p>Within the logistic function, the explanatory variables are still linear and the linear transformations can still be applied. <a contenteditable="false" data-primary="linear regression" data-secondary="causal diagrams" data-type="indexterm" id="idm45968167595608"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="linear regressions" data-type="indexterm" id="idm45968167594200"/>All of that is to say that I’ll mostly be referring to linear regression because it’s more common, but you can rest assured that everything I’m saying will also apply to logistic regression, plus or minus some minor math <span class="keep-together">transformation.</span></p>
</div></aside>

<p>From this perspective, the causal diagram from <a data-type="xref" href="#a_causal_diagram_with_an_unobserved_var">Figure 3-3</a> connecting <em>Temperature</em> to <em>IcedCoffeeSales</em> would mean that:</p>

<div data-type="equation">
<p><em>IcedCoffeeSales = β * Temperature + <em>ε</em></em></p>
</div>

<p>This linear regression means that if temperature were to increase by one degree, keeping everything else equal, then sales of iced coffee would increase by <em>β</em> dollars. Each box in the causal diagram represents a column of data, as with the simulated data in <a data-type="xref" href="#simulated_data_illustrating_the_relatio">Table 3-1</a>.</p>

<table class="border" id="simulated_data_illustrating_the_relatio">
	<caption><span class="label">Table 3-1. </span>Simulated data illustrating the relationship in our causal diagram</caption>
	<thead>
		<tr>
			<th>Date</th>
			<th><em>Temperature</em></th>
			<th><em>IcedCoffeeSales</em></th>
			<th><em>β</em> * <em>Temperature</em></th>
			<th><em>ε</em> = <em>IcedCoffeeSales</em> – <em>β</em> * <em>Temperature</em></th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>6/1/2019</td>
			<td>71</td>
			<td>$70,945</td>
			<td>$71,000</td>
			<td>$55</td>
		</tr>
		<tr>
			<td>6/2/2019</td>
			<td>57</td>
			<td>$56,969</td>
			<td>$57,000</td>
			<td>$31</td>
		</tr>
		<tr>
			<td>6/3/2019</td>
			<td>79</td>
			<td>$78,651</td>
			<td>$79,000</td>
			<td>-$349</td>
		</tr>
	</tbody>
</table>

<p>For people who are familiar with linear algebra notation, we can rewrite the previous equation as:</p>

<div data-type="equation">
<p><math><mrow><mrow><mrow><mo>(</mo><mtable><mtr/><mtr/><mtr/></mtable><mtable><mtr><mtd><mn>70</mn><mo>,</mo><mn>945</mn></mtd></mtr><mtr><mtd><mn>56</mn><mo>,</mo><mn>969</mn></mtd></mtr><mtr><mtd><mn>78</mn><mo>,</mo><mn>651</mn></mtd></mtr></mtable><mo>)</mo></mrow><mo>=</mo><mn>1000</mn><mo>*</mo><mrow><mo>(</mo><mtable><mtr><mtd><mn>71</mn></mtd></mtr><mtr><mtd><mn>57</mn></mtd></mtr><mtr><mtd><mn>79</mn></mtd></mtr></mtable><mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><mtable><mtr><mtd><mphantom><mrow/></mphantom><mn>55</mn></mtd></mtr><mtr><mtd><mphantom><mrow/></mphantom><mn>31</mn></mtd></mtr><mtr><mtd><mo>−</mo><mn>349</mn></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow></math></p>
</div>

<aside data-type="sidebar" epub:type="sidebar" class="pagebreak-before less_space"><div class="sidebar" id="causal_diagrams_and_error_terms">
<h5>Causal Diagrams and Error Terms</h5>

<p>The last column in <a data-type="xref" href="#simulated_data_illustrating_the_relatio">Table 3-1</a>, which shows the<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="data represented" data-tertiary="error terms" data-type="indexterm" id="idm45968167553176"/><a contenteditable="false" data-primary="data" data-secondary="causal diagrams" data-tertiary="error terms" data-type="indexterm" id="idm45968167551528"/> residual or error term in our regression, doesn’t have any counterpart in the CD from <a data-type="xref" href="#our_very_first_causal_diagram">Figure 3-2</a>. For the sake of completeness, error terms are sometimes represented in CDs as empty circles (<a data-type="xref" href="#adding_an_error_term_to_a_cd">Figure 3-7</a>). Feel free to do so if you find it helpful; I won’t in the rest of the book because I think it makes CDs less readable. I’ll just assume that any relationship in a CD that we would want to estimate comes with an implicit error term.</p>
<figure><div id="adding_an_error_term_to_a_cd" class="figure"><img alt="Adding an error term to a CD" src="Images/BEDA_0307.png" width="671" height="343"/>
<h6><span class="label">Figure 3-7. </span>Adding an error term to a CD</h6>
</div></figure>
</div></aside>

<p>From that perspective, CDs are all about data—variables and relationships between them. This generalizes immediately to multiple causes. Let’s draw a causal diagram showing that <em>Temperature</em> and <em>SummerMonth</em> both cause <em>IceCreamSales</em> (<a data-type="xref" href="#a_causal_diagram_with_more_than_one_cau">Figure 3-8</a>).</p>

<figure><div id="a_causal_diagram_with_more_than_one_cau" class="figure"><img alt="A causal diagram with more than one cause" src="Images/BEDA_0308.png" width="671" height="368"/>
<h6><span class="label">Figure 3-8. </span>A causal diagram with more than one cause</h6>
</div></figure>

<p>Translating this CD in mathematical terms would yield the following equation:</p>

<div data-type="equation">
<p><em>IceCreamSales = β<sub><em>T</em></sub>.Temperature + β<sub><em>S</em></sub>.SummerMonth + ε</em></p>
</div>

<p>Obviously, this equation is a standard multiple linear regression,<a contenteditable="false" data-primary="linear regression" data-secondary="causal diagrams" data-type="indexterm" id="idm45968167537016"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="linear regressions" data-type="indexterm" id="idm45968167535560"/> but the fact that it is based on a CD changes its interpretation. Outside of a causal framework, the only conclusion we would be able to draw from it is “an increase of one degree of temperature is associated with an increase of <em>β</em><sub><em>T</em></sub> dollars in ice cream sales.” Because correlation is not causation, it would be illegitimate to infer anything further. However, when a regression is backed by a CD, as is the case here, we can make a significantly stronger statement—namely, “unless this CD is wrong, an increase of one degree of temperature will cause an increase of <em>β</em><sub><em>T</em></sub> dollars in ice cream sales,” which is what the business cares about.</p>

<p>If you have a quantitative background such as data science, you may be tempted to focus on the connection between CDs and data at the expense of the connection with behaviors. <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="data represented" data-tertiary="probabilistic graphical models" data-type="indexterm" id="idm45968167531096"/><a contenteditable="false" data-primary="data" data-secondary="causal diagrams" data-tertiary="probabilistic graphical models" data-type="indexterm" id="idm45968167529432"/><a contenteditable="false" data-primary="probabilistic graphical models" data-type="indexterm" id="idm45968167527768"/>It is certainly a viable path, and it has given birth to an entire category of statistical models called probabilistic graphical models. For instance, algorithms have been and are still developed to identify causal relationships in data without relying on human expertise or judgment. However, this field is still in its infancy, and when applied to real-life data, these algorithms are often unable to select between several possible CDs that lead to vastly different business implications. Business and common sense can frequently do a better job of selecting the most reasonable one. Therefore I strongly believe that you are better off using the mixed approach shown in this book’s framework and accepting the idea that you’ll need to use your judgment. <a contenteditable="false" data-primary="intuition" data-secondary="from causal diagrams" data-type="indexterm" id="idm45968167525736"/><a contenteditable="false" data-primary="intuition" data-secondary="about data" data-type="indexterm" id="idm45968167524360"/>The back and forth that CDs enable between your intuitions and your data is—literally, in many cases—where the money is.<a contenteditable="false" data-primary="" data-startref="ch03-cada" data-type="indexterm" id="idm45968167522712"/><a contenteditable="false" data-primary="" data-startref="ch03-cada2" data-type="indexterm" id="idm45968167521336"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Fundamental Structures of Causal Diagrams"><div class="sect1" id="fundamental_structures_of_causal_diagra">
<h1>Fundamental Structures of Causal Diagrams</h1>

<p>Causal diagrams can take a bewildering variety of shapes.<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="about" data-type="indexterm" id="idm45968167199576"/><a contenteditable="false" data-primary="chains in causal diagrams" data-secondary="about" data-type="indexterm" id="idm45968167197912"/> Fortunately, researchers have been working on causality for a while now, and they have brought some order to it:</p>

<ul>
	<li>
	<p>There exist only three fundamental structures—chains, forks, and colliders—and all causal diagrams can be represented as combinations of them.</p>
	</li>
	<li>
	<p>By looking at CDs as if they were family trees, we can easily<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="parent/child relationships" data-type="indexterm" id="idm45968167194184"/> describe relationships between variables that are far away from each other in the diagram, for example by saying that one is the “descendant” or the “child” of another.</p>
	</li>
</ul>

<p>And really, that’s all there is to it! We’ll now see these fundamental structures in more detail, and once you have familiarized yourself with them and how to name relationships between variables, you’ll be able to fully describe any CD you work with.</p>

<section data-type="sect2" data-pdf-bookmark="Chains"><div class="sect2" id="chains">
<h2>Chains</h2>

<p>A chain is a causal diagram with three boxes, representing three<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="chains" data-type="indexterm" id="ch03-cha"/><a contenteditable="false" data-primary="chains in causal diagrams" data-type="indexterm" id="ch03-cha2"/><a contenteditable="false" data-primary="C-Mart fictional supermarket chain" data-secondary="causal diagrams" data-tertiary="chains" data-type="indexterm" id="idm45968167185736"/> variables, and two arrows connecting these boxes in a straight line. To show you one, I’ll have to introduce a new treat in our C-Mart example—namely, the mighty donut. For the sake of simplicity, let’s assume that only one of the variables we have already seen affects the sales of donuts: <em>IcedCoffeeSales</em>. Then <em>Temperature</em>, <em>IcedCoffeeSales</em>, and <em>DonutSales</em> are causally connected (<a data-type="xref" href="#causal_diagram_of_a_chain">Figure 3-9</a>).</p>

<figure><div id="causal_diagram_of_a_chain" class="figure"><img alt="Causal diagram of a chain" src="Images/BEDA_0309.png" width="1052" height="139"/>
<h6><span class="label">Figure 3-9. </span>Causal diagram of a chain</h6>
</div></figure>

<p>What makes this CD a chain is that the two arrows are going “in the same direction,” i.e., the first arrow goes from one box to another, and the second arrow goes from that second box to the last one. This CD is an expansion of the one in <a data-type="xref" href="#a_causal_diagram_with_an_unobserved_var">Figure 3-3</a>. It represents the fact that temperature causes sales of iced coffee, which in turn causes sales of donuts.</p>

<p>Let’s define a few terms that will allow us to characterize the relationships between variables.<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="family tree structure" data-type="indexterm" id="idm45968167176472"/><a contenteditable="false" data-primary="parent in causal diagrams" data-type="indexterm" id="idm45968167175096"/><a contenteditable="false" data-primary="child in causal diagrams" data-type="indexterm" id="idm45968167173928"/><a contenteditable="false" data-primary="variables" data-secondary="causal diagrams" data-tertiary="parent/child relationships" data-type="indexterm" id="idm45968167172808"/> In this diagram, <em>Temperature</em> is called the <em>parent</em> of <em>IcedCoffeeSales</em>, and <em>IcedCoffeeSales</em> is a <em>child</em> of <em>Temperature</em>. But <em>IcedCoffeeSales</em> is also a parent of <em>DonutSales</em>, which is its child. <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="direct relationships" data-type="indexterm" id="idm45968167167432"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="indirect relationships" data-type="indexterm" id="idm45968167166024"/>When a variable has a parent/child relationship with another variable we call that a <em>direct relationship</em>. When there are intermediary variables between them, we call that an <em>indirect relationship</em>. The actual count of variables that makes a relationship indirect is not generally important, so you don’t have to count the number of boxes to describe the fundamental structure of the relationship between them.</p>

<p>In addition, we say that a variable is <a contenteditable="false" data-primary="ancestor in causal diagrams" data-type="indexterm" id="idm45968167163384"/>the <em>ancestor</em> of another variable if the first variable is the parent of another, which may be the parent of another, and so on, ending up with our second variable as a child. In our example, <em>Temperature</em> is an ancestor of <em>DonutSales</em> because it’s a parent of <em>IcedCoffeeSales</em>, which is itself a parent of <em>DonutSales</em>. Very logically, this makes <em>DonutSales</em> a <em>descendant</em> of <em>Temperature</em> (<a data-type="xref" href="#relationships_between_variables_along_a">Figure 3-10</a>).</p>

<figure><div id="relationships_between_variables_along_a" class="figure"><img alt="Relationships between variables along a chain" src="Images/BEDA_0310.png" width="714" height="606"/>
<h6><span class="label">Figure 3-10. </span>Relationships between variables along a chain</h6>
</div></figure>

<p>In this situation, <em>IcedCoffeeSales</em> is also <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="mediators" data-type="indexterm" id="idm45968167154200"/><a contenteditable="false" data-primary="mediation" data-secondary="mediators in causal diagrams" data-type="indexterm" id="idm45968167152792"/>the <em>mediator</em> of the relationship between <em>Temperature</em> and <em>DonutSales</em>. We’ll explore mediation in more depth in <a data-type="xref" href="ch12.xhtml#mediation_and_instrumental_variables">Chapter 12</a>. <a contenteditable="false" data-primary="C-Mart fictional supermarket chain" data-secondary="causal diagrams" data-tertiary="mediator values" data-type="indexterm" id="idm45968167148920"/>For now, let’s just note that if a mediator value does not change, then the variables earlier in a chain won’t influence the variables further along the chain unless they are otherwise connected. In our example, if C-Mart were to experience a shortage of iced coffee, we would expect that for the duration of that shortage, changes in temperature would not have any effect on the sales of donuts.</p>

<section data-type="sect3" data-pdf-bookmark="Collapsing chains"><div class="sect3" id="collapsing_chains">
<h3>Collapsing chains</h3>

<p>The preceding causal diagram translates into the following regression equations:<a contenteditable="false" data-primary="chains in causal diagrams" data-secondary="collapsing chains" data-type="indexterm" id="idm45968167144664"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="collapsing chains" data-type="indexterm" id="idm45968167143320"/><a contenteditable="false" data-primary="C-Mart fictional supermarket chain" data-secondary="causal diagrams" data-tertiary="collapsing chains" data-type="indexterm" id="idm45968167141656"/></p>

<div data-type="equation">
<p><em>IcedCoffeeSales</em> = <em>β<sub>T</sub>.Temperature</em></p>
</div>

<div data-type="equation">
<p><em>DonutSales</em> = <em>β<sub>I</sub>.IcedCoffeeSales</em></p>
</div>

<p>We can replace <em>IcedCoffeeSales</em> by its expression in the second equation:</p>

<div data-type="equation">
<p><em>DonutSales</em> = <em>β</em><sub>I</sub>.(<em>β<sub>T</sub>Temperature</em>) = (<em>β<sub>I</sub>β<sub>T</sub></em>)<em>Temperature</em></p>
</div>

<p>But <em>β</em><sub>I</sub><em>β</em><sub>T</sub> is just the product of two constant coefficients, so we can treat it as a new coefficient in itself: <math><mrow><mrow><mi>D</mi><mi>o</mi><mi>n</mi><mi>u</mi><mi>t</mi><mi>S</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>s</mi><mo>=</mo><msub><mrow><mover><mrow><mi>β</mi></mrow><mrow><mo>˜</mo></mrow></mover></mrow><mrow><mi>T</mi></mrow></msub><mn>.</mn><mtext> </mtext><mi>T</mi><mi>e</mi><mi>m</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi></mrow></mrow></math>. We have managed to express <em>DonutSales</em> as a linear function of <em>Temperature</em>, which can in turn be translated into a causal diagram (<a data-type="xref" href="#collapsing_a_cd_into_another_cd">Figure 3-11</a>).</p>

<figure><div id="collapsing_a_cd_into_another_cd" class="figure"><img alt="Collapsing a CD into another CD" src="Images/BEDA_0311.png" width="671" height="139"/>
<h6><span class="label">Figure 3-11. </span>Collapsing a CD into another CD</h6>
</div></figure>

<p>Here, we have <em>collapsed a chain</em>, that is, we have removed the variable in the middle and replaced it with an arrow going from the first variable to the last. By doing so, we have effectively simplified our original causal diagram to focus on the relationship that we’re interested in. This can be useful when the last variable in a chain is a business metric we’re interested in and the first one is actionable. In some circumstances, for example, we might be interested in the intermediary relations between <em>Temperature</em> and <em>IcedCoffeeSales</em> and between <em>IcedCoffeeSales</em> and <em>DonutSales</em> to manage pricing or promotions. In other circumstances, we might be interested only in the relation between <em>Temperature</em> and <em>DonutSales</em>—for example, to plan for inventory.</p>

<p>The transitivity property of linear algebra also applies here:<a contenteditable="false" data-primary="linear algebra in causal diagrams" data-secondary="transitivity property in collapsing chains" data-type="indexterm" id="idm45968167110680"/><a contenteditable="false" data-primary="chains in causal diagrams" data-secondary="collapsing chains" data-tertiary="transitivity property" data-type="indexterm" id="idm45968167109112"/><a contenteditable="false" data-primary="transitivity property in collapsing chains" data-type="indexterm" id="idm45968167107448"/> if <em>DonutSales</em> caused another variable, then that chain could also be collapsed around <em>DonutSales</em>, and so on.</p>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Expanding chains"><div class="sect3" id="expanding_chains">
<h3>Expanding chains</h3>

<p>The collapsing operation can obviously be reversed: <a contenteditable="false" data-primary="chains in causal diagrams" data-secondary="expanding chains" data-type="indexterm" id="idm45968167103544"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="expanding chains" data-type="indexterm" id="idm45968167101816"/><a contenteditable="false" data-primary="C-Mart fictional supermarket chain" data-secondary="causal diagrams" data-tertiary="expanding chains" data-type="indexterm" id="idm45968167100200"/>we can go from our last CD to the previous one by adding the <em>IcedCoffeeSales</em> variable in the middle. More generally, we say that we are <em>expanding a chain</em> whenever we inject an intermediary variable between two variables currently connected by an arrow. For example, let’s say that we start with the relationship between <em>Temperature</em> and <em>DonutSales</em> (<a data-type="xref" href="#collapsing_a_cd_into_another_cd">Figure 3-11</a>). This causal relationship translates into the equation <em>DonutSales</em> = <em>β<sub>T</sub>Temperature</em>. Let’s assume that <em>Temperature</em> affects <em>DonutSales</em> only through <em>IcedCoffeeSales</em>. We can add this variable in our CD, which brings us back to our original CD from <a data-type="xref" href="#a_causal_diagram_with_more_than_one_cau">Figure 3-8</a> (<a data-type="xref" href="#expanding_a_cd_into_another_cd">Figure 3-12</a>).</p>

<figure><div id="expanding_a_cd_into_another_cd" class="figure"><img alt="Expanding a CD into another CD" src="Images/BEDA_0312.png" width="1052" height="139"/>
<h6><span class="label">Figure 3-12. </span>Expanding a CD into another CD</h6>
</div></figure>

<p>Expanding chains can be useful to better understand what’s happening in a given situation. For example, let’s say that temperature increased but sales of donuts did not. There could be two potential reasons for that:</p>

<ul>
	<li>
	<p>First, the increase in temperature did not increase the sales of iced coffee, perhaps because the store manager has been more aggressive with the AC. In other words, the first arrow in <a data-type="xref" href="#collapsing_a_cd_into_another_cd">Figure 3-11</a> disappeared or weakened.</p>
	</li>
	<li>
	<p>Alternatively, the increase in temperature <em>did</em> increase the sales of iced coffee, but the increase in the sales of iced coffee did not increase the sales of donuts, e.g., because people are buying the newly offered cookies instead. In other words, in <a data-type="xref" href="#collapsing_a_cd_into_another_cd">Figure 3-11</a>, the first arrow is unchanged but the second one disappeared or weakened.</p>
	</li>
</ul>

<p>Depending on which one is true, you might take very different corrective actions—either turning off the AC or changing the price of cookies. In many cases, looking at the variable in the middle of a chain, namely the mediator, will allow you to make better decisions.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Because chains can be collapsed or expanded at will, in general we <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="collapsing and expanding not indicated" data-type="indexterm" id="idm45968167081528"/><a contenteditable="false" data-primary="chains in causal diagrams" data-secondary="collapsing and expanding not indicated" data-type="indexterm" id="idm45968167079720"/>do not explicitly indicate when it has been done. It’s always assumed that any arrow could potentially be expanded to highlight an intermediary variable along the way.</p>

<p>This also implies that the definition of “direct” and “indirect” relationships<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="direct relationships" data-type="indexterm" id="idm45968167077576"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="indirect relationships" data-type="indexterm" id="idm45968167076200"/> mentioned earlier relates to a specific representation of a CD: when you collapse a chain, two variables that had an indirect relationship now have a direct relationship.<a contenteditable="false" data-primary="" data-startref="ch03-cha" data-type="indexterm" id="idm45968167074504"/><a contenteditable="false" data-primary="" data-startref="ch03-cha2" data-type="indexterm" id="idm45968167073128"/></p>
</div>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Forks"><div class="sect2" id="forks">
<h2>Forks</h2>

<p>When a variable causes two or more effects, the relationship<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="forks" data-type="indexterm" id="ch03-fork"/><a contenteditable="false" data-primary="forks in causal diagrams" data-type="indexterm" id="ch03-fork2"/><a contenteditable="false" data-primary="variables" data-secondary="causal diagrams" data-tertiary="forks" data-type="indexterm" id="ch03-fork3"/><a contenteditable="false" data-primary="C-Mart fictional supermarket chain" data-secondary="causal diagrams" data-tertiary="forks" data-type="indexterm" id="ch03-fork4"/> creates a <em>fork</em>. <em>Temperature</em> causes both <em>IcedCoffeeSales</em> and <em>IceCreamSales</em>, so a representation of this fork is shown in <a data-type="xref" href="#a_fork_between_three_variables">Figure 3-13</a>.</p>

<figure><div id="a_fork_between_three_variables" class="figure"><img alt="A fork between three variables" src="Images/BEDA_0313.png" width="671" height="294"/>
<h6><span class="label">Figure 3-13. </span>A fork between three variables</h6>
</div></figure>

<p>This CD shows that <em>Temperature</em> influences both <em>IceCreamSales</em> and <em>IcedCoffeeSales</em>, but that they do not have a causal relationship with each other. If it is hot out, demand for both ice cream and iced coffee increases, but buying one does not make you want to buy the other, nor does it make you less likely to buy the other.</p>

<p>This situation where two variables have a common cause is very frequent but also potentially problematic, because it creates a correlation among these two variables. It makes sense that when it is hot out, we will see an increase in sales of both, and when it is cold fewer people will want both. A linear regression predicting <em>IceCreamSales</em> from <em>IcedCoffeeSales</em> would be fairly predictive, but here correlation does not equal causation, and since we know that the causal impact is 0, the coefficient provided by the model would not be accurate.</p>

<p>Another way to look at this relationship is that if C-Mart experienced a shortage of iced coffee, we would not expect to see a change in the sales of ice cream. More generally, it would be only a slight exaggeration to say that forks are one of the main roots of evil in the world of data analysis. <a contenteditable="false" data-primary="correlation" data-secondary="forks creating appearance of" data-type="indexterm" id="idm45968167053128"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="data represented" data-tertiary="correlation without direct causality" data-type="indexterm" id="idm45968167051688"/>Whenever we observe a correlation between two variables that doesn’t reflect direct causality between them (i.e., neither is the cause of the other), more often than not it will be because they share a common cause. From that perspective, one of the main benefits of using CDs is that they can show very clearly and intuitively what’s going on in those cases and how to correct for it.</p>

<p>Forks are also typical of situations where we look at demographic variables:<a contenteditable="false" data-primary="demographic variables" data-secondary="forks" data-type="indexterm" id="idm45968167049080"/> age, gender, and place of residence all cause a variety of other variables that may or may not cause each other. You can picture a demographic variable such as age as being at the root of a fork with many teeth.</p>

<p>A question that sometimes comes up when you have a fork in the middle of a CD is whether you can still <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="collapsing chains around forks" data-type="indexterm" id="idm45968167046600"/><a contenteditable="false" data-primary="confounders" data-secondary="collapsing chains around forks" data-type="indexterm" id="idm45968167044968"/><a contenteditable="false" data-primary="chains in causal diagrams" data-secondary="collapsing chains" data-tertiary="around forks" data-type="indexterm" id="idm45968167043576"/>collapse the chain around it. For example, let’s say that we’re interested in analyzing the relationship between <em>SummerMonth</em> and <em>IcedCoffeeSales</em> using the CD in <a data-type="xref" href="#a_cd_with_a_fork_and_a_chain">Figure 3-14</a>.</p>

<figure><div id="a_cd_with_a_fork_and_a_chain" class="figure"><img alt="A CD with a fork and a chain" src="Images/BEDA_0314.png" width="1052" height="372"/>
<h6><span class="label">Figure 3-14. </span>A CD with a fork and a chain</h6>
</div></figure>

<p>In this CD, there’s a fork between <em>SummerMonth</em> on one side and <em>IceCreamSales</em> and <em>Temperature</em> on the other, but there’s also a chain <em>SummerMonth</em> → <em>Temperature</em> → <em>IcedCoffeeSales</em>. Can we collapse the chain?</p>

<p>In this case, yes. We’ll see in <a data-type="xref" href="ch05.xhtml#using_causal_diagrams_to_deconfound_da">Chapter 5</a> how to determine when a variable is a confounder of a relationship; here it will suffice to say that <em>IceCreamSales</em> is not a confounder of the relationship between <em>SummerMonth</em> and <em>IcedCoffeeSales</em>, which is the one we’re interested in. Therefore we can simplify our CD (<a data-type="xref" href="#a_collapsed_version_of_the_previous_cd">Figure 3-15</a>).</p>

<figure><div id="a_collapsed_version_of_the_previous_cd" class="figure"><img alt="A collapsed version of the previous CD" src="Images/BEDA_0315.png" width="671" height="139"/>
<h6><span class="label">Figure 3-15. </span>A collapsed version of the previous CD</h6>
</div></figure>

<p>Similarly, if we were interested in the relationship between <em>SummerMonth</em> and <em>IceCreamSales</em> in <a data-type="xref" href="#a_cd_with_a_fork_and_a_chain">Figure 3-14</a>, we could neglect <em>IcedCoffeeSales</em> but not <em>Temperature.</em></p>

<p>Because forks are so important to causal analysis, we’ll sometimes want to represent them even when we don’t know the joint cause. <a contenteditable="false" data-primary="forks in causal diagrams" data-secondary="unknown forks with two-headed arrows" data-type="indexterm" id="idm45968167025240"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="unknown forks" data-type="indexterm" id="idm45968167023784"/><a contenteditable="false" data-primary="information unknown" data-secondary="unknown forks" data-type="indexterm" id="idm45968167022120"/>When that’s the case, we’ll represent the unknown fork with a two-headed arrow (<a data-type="xref" href="#a_fork_with_an_unknown_joint_cause">Figure 3-16</a>).</p>

<figure><div id="a_fork_with_an_unknown_joint_cause" class="figure"><img alt="A fork with an unknown joint cause" src="Images/BEDA_0316.png" width="350" height="372"/>
<h6><span class="label">Figure 3-16. </span>A fork with an unknown joint cause</h6>
</div></figure>

<p>The two-headed arrow also looks like the two variables are causing each other. This is by design, and we’ll also use a two-headed arrow when we observe a correlation between two variables but we don’t know which is causing which. Thus, a two-headed arrow encompasses the three possible reasons why two variables A and B would appear correlated: A causes B, B causes A, and/or A and B share a cause. Sometimes we’ll use a two-headed arrow as a placeholder until we clarify the true reason; if we don’t care about the reason, we may simply retain the two-headed arrow in our final CD.<a contenteditable="false" data-primary="" data-startref="ch03-fork" data-type="indexterm" id="idm45968167016632"/><a contenteditable="false" data-primary="" data-startref="ch03-fork2" data-type="indexterm" id="idm45968167015256"/><a contenteditable="false" data-primary="" data-startref="ch03-fork3" data-type="indexterm" id="idm45968167013880"/><a contenteditable="false" data-primary="" data-startref="ch03-fork4" data-type="indexterm" id="idm45968167012504"/></p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Colliders"><div class="sect2" id="colliders">
<h2>Colliders</h2>

<p>Very few things in the world have only one cause. <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="colliders" data-type="indexterm" id="idm45968167009160"/><a contenteditable="false" data-primary="colliders in causal diagrams" data-type="indexterm" id="idm45968167007496"/>When two or more variables cause the same outcome, the relationship creates a <em>collider</em>. Since C-Mart’s concession stand sells only two flavors of ice cream, chocolate and vanilla, a causal diagram representing taste and ice cream purchasing behavior would show that appetite for either flavor would cause past purchases of ice cream at the stand (<a data-type="xref" href="#cd_of_a_collider">Figure 3-17</a>).</p>

<figure><div id="cd_of_a_collider" class="figure"><img alt="CD of a collider" src="Images/BEDA_0317.png" width="671" height="303"/>
<h6><span class="label">Figure 3-17. </span>CD of a collider</h6>
</div></figure>

<p>Colliders are a common occurrence, and they can also be an issue in data analysis. A collider is in a sense the opposite of a fork, and the problems with them are also symmetric: a fork is problematic if we <em>don’t control</em> for the joint cause whereas a collider is a problem if we <em>do control</em> for the joint effect. We’ll explore these issues further in <a data-type="xref" href="ch05.xhtml#using_causal_diagrams_to_deconfound_da">Chapter 5</a>.</p>

<p>To recap this section, chains, forks, and colliders represent the only<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="about" data-type="indexterm" id="idm45968166999608"/><a contenteditable="false" data-primary="chains in causal diagrams" data-secondary="about" data-type="indexterm" id="idm45968166997816"/> three possible ways for three variables to be related to each other in a CD. They are not exclusive of each other, however, and it’s actually reasonably common to have three variables that exhibit all three structures at the same time, as was the case in our very first example (<a data-type="xref" href="#a_three_variable_cd_containing_a_chainc">Figure 3-18</a>).</p>

<figure><div id="a_three_variable_cd_containing_a_chainc" class="figure"><img alt="A three-variable CD containing a chain, a fork, and a collider at the same time" src="Images/BEDA_0318.png" width="671" height="372"/>
<h6><span class="label">Figure 3-18. </span>A three-variable CD containing a chain, a fork, and a collider at the same time</h6>
</div></figure>

<p>Here, <em>SummerMonth</em> influences <em>IceCreamSales</em> as well as <em>Temperature</em>, which itself influences <em>IceCreamSales</em>. The causal relationships at play are reasonably simple and easy to grasp, but this graph also contains all three types of basic relationships:</p>

<ul>
	<li>
	<p>A chain: <em>SummerMonth</em> → <em>Temperature</em> → <em>IceCreamSales</em></p>
	</li>
	<li>
	<p>A fork, with SummerMonth causing both <em>Temperature</em> and <em>IceCreamSales</em></p>
	</li>
	<li>
	<p>A collider, with <em>IceCreamSales</em> being caused by both <em>Temperature</em> and <span class="keep-together"><em>SummerMonth</em></span></p>
	</li>
</ul>

<p>Another thing to note in a situation like this one is that variables have more than one relationship with each other. For example, <em>SummerMonth</em> is the parent of <em>IceCreamSales</em> because there is an arrow going directly from the former to the latter (a direct relationship); but at the same time, <em>SummerMonth</em> is also indirectly an ancestor of <em>IceCreamSales</em> through the chain <em>SummerMonth → Temperature → IceCreamSales</em> (an indirect relationship). So you can see these are not exclusive!</p>

<p>While a CD is always made of these three structures, it is not static. A CD can be transformed by modifying the variables themselves as well as their relationships, as we’ll now see.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Common Transformations of Causal Diagrams"><div class="sect1" id="common_transformations_of_causal_diagra">
<h1>Common Transformations of Causal Diagrams</h1>

<p>Chains, forks, and colliders take the variables in a CD as given.<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="transformations of" data-type="indexterm" id="idm45968166978264"/><a contenteditable="false" data-primary="variables" data-secondary="causal diagrams" data-tertiary="transformations of" data-type="indexterm" id="ch03-cauxf"/><a contenteditable="false" data-primary="transformations of causal diagrams" data-secondary="about" data-type="indexterm" id="idm45968166974888"/> But in the same way that a chain can be collapsed or expanded, variables can themselves be sliced or aggregated to “zoom” in and out of specific behaviors and categories. We may also decide to modify the arrows—for example, when we’re faced with otherwise intractable cycles.</p>

<section data-type="sect2" data-pdf-bookmark="Slicing/Disaggregating Variables"><div class="sect2" id="slicingsolidusdisaggregating_variables">
<h2>Slicing/Disaggregating Variables</h2>

<p>Forks and colliders are often created when you slice or<a contenteditable="false" data-primary="transformations of causal diagrams" data-secondary="slicing or disaggregating variables" data-type="indexterm" id="idm45968166970776"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="transformations of" data-tertiary="slicing or disaggregating variables" data-type="indexterm" id="idm45968166969368"/><a contenteditable="false" data-primary="forks in causal diagrams" data-secondary="slicing or disaggregating variables" data-type="indexterm" id="idm45968166967704"/><a contenteditable="false" data-primary="colliders in causal diagrams" data-secondary="slicing or disaggregating variables" data-type="indexterm" id="idm45968166966296"/><a contenteditable="false" data-primary="aggregate metrics" data-secondary="transformations of causal diagrams" data-tertiary="slicing or disaggregating variables" data-type="indexterm" id="idm45968166964888"/><a contenteditable="false" data-primary="chains in causal diagrams" data-secondary="slicing or disaggregating variables" data-type="indexterm" id="idm45968166963208"/><a contenteditable="false" data-primary="mediation" data-secondary="mediators in causal diagrams" data-tertiary="slicing or disaggregating variables" data-type="indexterm" id="idm45968166961800"/> disaggregate a variable to reveal its components. In a previous example, we looked at the relationship between <em>Temperature</em> and <em>DonutSales</em>, where <em>IcedCoffeeSales</em> was the mediator (<a data-type="xref" href="#the_chain_that_we_will_slice">Figure 3-19</a>).</p>

<figure><div id="the_chain_that_we_will_slice" class="figure"><img alt="The chain that we will slice" src="Images/BEDA_0319.png" width="1052" height="139"/>
<h6><span class="label">Figure 3-19. </span>The chain that we will slice</h6>
</div></figure>

<p>But maybe we want to split <em>IcedCoffeeSales</em> by type to better understand demand dynamics. This is what I mean by “slicing” a variable. This is allowed per the rules of linear algebra, because we can express the total iced coffee sales as the sum of sales by type, say Americano and latte:</p>

<div data-type="equation">
<p><em>IcedCoffeeSales</em> = <em>IcedAmericanoSales</em> + <em>IcedLatteSales</em></p>
</div>

<p>Our CD would now become <a data-type="xref" href="#a_chain_where_the_mediator_has_been_sli">Figure 3-20</a>, with a fork on the left and a collider on the right.</p>

<figure><div id="a_chain_where_the_mediator_has_been_sli" class="figure"><img alt="A chain where the mediator has been sliced" src="Images/BEDA_0320.png" width="1052" height="311"/>
<h6><span class="label">Figure 3-20. </span>A chain where the mediator has been sliced</h6>
</div></figure>

<p>Each slice of the variable would now have its own equation:</p>

<div data-type="equation">
<p><em>IcedAmericanoSales</em> = <em>β<sub><em>TA</em></sub>.Temperature</em></p>
</div>

<div data-type="equation">
<p><em>IcedLatteSales</em> = <em>β<sub>TL</sub>.Temperature</em></p>
</div>

<p>Since the effect of <em>Temperature</em> is completely mediated by our <em>IcedCoffeeSales</em> slices, we can create a unified multiple regression for <em>DonutSales</em> as follows:</p>

<div data-type="equation">
<p><em>DonutSales</em> = <em>β<sub>IA</sub>.IcedAmericanoSales + β<sub>IL</sub>.IcedLatteSales</em></p>
</div>

<p>This would allow you to understand more finely what’s happening—should you plan for the same increase in sales in both types when temperature increases? Do they both have the same effect on <em>DonutSales</em> or should you try to favor one of them?</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Aggregating Variables"><div class="sect2" id="aggregating_variables">
<h2>Aggregating Variables</h2>

<p>As you may have guessed, slicing variables can be reversed,<a contenteditable="false" data-primary="transformations of causal diagrams" data-secondary="aggregating variables" data-type="indexterm" id="idm45968166936360"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="transformations of" data-tertiary="aggregating variables" data-type="indexterm" id="idm45968166934936"/><a contenteditable="false" data-primary="aggregate metrics" data-secondary="transformations of causal diagrams" data-tertiary="aggregating variables" data-type="indexterm" id="idm45968166933288"/> and more generally we can aggregate variables that have the same causes and effects. This can be used to aggregate and disaggregate data analysis by product, region, line of business, and so on. But it can also be used more loosely to represent important causal factors that are not precisely defined. For example, let’s say that <em>Age</em> and <em>Gender</em> both impact <em>TasteForVanilla</em> as well as the propensity to buy ice cream at C-Mart concession stands, <em>PurchasedIceCream</em> (<a data-type="xref" href="#age_and_gender_are_shown_separately">Figure 3-21</a>).</p>

<figure><div id="age_and_gender_are_shown_separately" class="figure"><img alt="Age and Gender are shown separately" src="Images/BEDA_0321.png" width="671" height="429"/>
<h6><span class="label">Figure 3-21. </span>Age and Gender are shown separately</h6>
</div></figure>

<p>Because <em>Age</em> and <em>Gender</em> have the same causal relationships, they can be aggregated into a <em>DemographicCharacteristics</em> variable (<a data-type="xref" href="#cd_where_age_and_gender_are_aggregated">Figure 3-22</a>).</p>

<figure><div id="cd_where_age_and_gender_are_aggregated" class="figure"><img alt="CD where Age and Gender are aggregated into a single variable" src="Images/BEDA_0322.png" width="671" height="429"/>
<h6><span class="label">Figure 3-22. </span>CD where Age and Gender are aggregated into a single variable</h6>
</div></figure>

<p>In this case, we obviously don’t have a single column in our data called “Demographic Characteristics” or “Demographics”; we’re simply using that variable in our CD as a shortcut for a variety of variables that we may or may not want to explore in further detail later on. Let’s say that we want to run an A/B test and understand the causal relationships at hand. As we’ll see later, randomization can allow us to control for demographic factors so that we won’t have to include them in our analysis, but we might want to include them in our CD of the situation without randomization. If need be, we can always expand our diagram to accurately represent the demographic variables involved. Remember, however, that <em>any variable can be split, but only variables that have the same direct and indirect relationships can be aggregated.</em></p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="technical_deeper_dive_aggregating_varia">
<h5>Technical Deeper Dive: Aggregating Variables and Linear Algebra</h5>

<p>Using a summary <em>Demographics</em> variable may look<a contenteditable="false" data-primary="aggregate metrics" data-secondary="linear algebra and aggregating variables" data-type="indexterm" id="idm45968166917624"/><a contenteditable="false" data-primary="linear algebra in causal diagrams" data-secondary="aggregating variables and" data-type="indexterm" id="idm45968166916248"/><a contenteditable="false" data-primary="demographic variables" data-secondary="summary variable linear algebra proof" data-type="indexterm" id="idm45968166914840"/> like a dubious sleight of hand, but it is actually completely sound from the perspective of linear algebra. If you’ll take my word for it or your linear algebra is too rusty, you can just skip this box and not worry about it. But if you want to check the math, here it is.</p>

<p>We can treat our variables as vectors:</p>

<div data-type="equation">
<p><math><mrow><mrow><mtext mathvariant="italic">TasteForVanilla</mtext><mo>=</mo><mrow><mo>(</mo><mtable><mtr><mtd><mn>3</mn></mtd></mtr><mtr><mtd><mn>15</mn></mtd></mtr><mtr><mtd><mn>8</mn></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mn>17</mn></mtd></mtr></mtable><mo>)</mo></mrow><mo>,</mo><mtext mathvariant="italic">Age</mtext><mo>=</mo><mrow><mo>(</mo><mtable><mtr><mtd><mn>23</mn></mtd></mtr><mtr><mtd><mn>78</mn></mtd></mtr><mtr><mtd><mn>52</mn></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mn>41</mn></mtd></mtr></mtable><mo>)</mo></mrow><mrow><mn/></mrow><mspace width=".25em"/><mtext mathvariant="italic">and Gender</mtext><mo>=</mo><mrow><mo>(</mo><mtable><mtr><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mn>0</mn></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow></math></p>
</div>

<p>We now have the corresponding equation:</p>

<div data-type="equation">
<p><em>TasteForVanilla</em> = <em>β<sub>A</sub>.Age</em> + <em>β<sub>G</sub>.Gender</em></p>
</div>

<p>But we can also attach our vectors together in a matrix (which is technically how linear regression models are traditionally solved):</p>

<div data-type="equation">
<p><math><mrow><mi>D</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>p</mi><mi>h</mi><mi>i</mi><mi>c</mi><mi>s</mi><mo>=</mo><mrow><mrow><mo>(</mo><mi>A</mi><mi>g</mi><mi>e</mi><mphantom><mrow><mn>00</mn></mrow></mphantom><mi>G</mi><mi>e</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo>)</mo></mrow><mo>=</mo><mrow><mo>(</mo><mtable><mtr><mtd><mn>23</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>78</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>52</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mn>41</mn></mtd><mtd><mn>0</mn></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow></math></p>
</div>

<p>This allows us to rewrite the previous equation as:</p>

<div data-type="equation">
<p><math><mrow><mrow><mi>T</mi><mi>a</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>F</mi><mi>o</mi><mi>r</mi><mi>V</mi><mi>a</mi><mi>n</mi><mi>i</mi><mi>l</mi><mi>l</mi><mi>a</mi><mo>=</mo><mrow><mrow><mo>(</mo><mi>A</mi><mi>g</mi><mi>e</mi><mphantom><mrow><mn>00</mn></mrow></mphantom><mi>G</mi><mi>e</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo>)</mo></mrow><mo>*</mo><mrow><mrow><mo>(</mo><mtable><mtr><mtd><msub><mrow><mi>β</mi></mrow><mrow><mi>a</mi></mrow></msub></mtd></mtr><mtr><mtd><msub><mrow><mi>β</mi></mrow><mrow><mi>g</mi></mrow></msub></mtd></mtr></mtable><mo>)</mo></mrow><mo>=</mo><mi>D</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>p</mi><mi>h</mi><mi>i</mi><mi>c</mi><mi>s</mi><mo>*</mo><mover><mrow><mi>β</mi></mrow><mrow><mo>→</mo></mrow></mover><mphantom><mrow><mn>0</mn></mrow></mphantom><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi></mrow></mrow><mphantom><mrow><mn>0</mn></mrow></mphantom><mover><mrow><mi>β</mi></mrow><mrow><mo>→</mo></mrow></mover><mo>=</mo><mrow><mo>(</mo><mtable><mtr><mtd><msub><mrow><mi>β</mi></mrow><mrow><mi>a</mi></mrow></msub></mtd></mtr><mtr><mtd><msub><mrow><mi>β</mi></mrow><mrow><mi>g</mi></mrow></msub></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow></math></p>
</div>

<p>We have now expressed <em>TasteForVanilla</em> as a linear function of <em>Demographics</em> in vector notation. In other words, as long as we’re only aggregating variables that have exactly the same relationships with other variables, we’re on solid mathematical grounds.</p>
</div></aside>
</div></section>

<section data-type="sect2" data-pdf-bookmark="What About Cycles?"><div class="sect2" id="what_about_cyclesquestion_mark">
<h2>What About Cycles?</h2>

<p>In the three fundamental structures that we’ve seen, there has<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="transformations of" data-tertiary="cycles" data-type="indexterm" id="idm45968166847512"/><a contenteditable="false" data-primary="transformations of causal diagrams" data-secondary="cycles" data-type="indexterm" id="idm45968166845864"/><a contenteditable="false" data-primary="cycles in causal diagrams" data-type="indexterm" id="idm45968166844520"/> been only one arrow between two given boxes. More generally, it was not possible to reach the same variable twice by following the direction of arrows (e.g., A → B → C → A). A variable could be the effect of one variable and the cause of another, but it could not be at the same time the cause and the effect of one variable.</p>

<p>In real life, however, we often see variables that influence each other causally. This type of CD is called a <em>cycle</em>. <a contenteditable="false" data-primary="substitution effects" data-secondary="cycles in causal diagrams" data-type="indexterm" id="idm45968166842008"/>Cycles can arise for a variety of reasons; two of the most common in behavioral data analysis are substitution effects and feedback loops. Fortunately, there are some workarounds that will allow you to deal with cycles when you encounter them.</p>

<section data-type="sect3" data-pdf-bookmark="Understanding cycles: Substitution effects and feedback loops"><div class="sect3" id="understanding_cycles_substitution_effec">
<h3>Understanding cycles: Substitution effects and feedback loops</h3>

<p>Substitution effects are a cornerstone of economics theory:<a contenteditable="false" data-primary="substitution effects" data-type="indexterm" id="idm45968166838168"/> customers might <em>substitute</em> a product for another, depending on the products’ availability and price and the customers’ desire for variety. <a contenteditable="false" data-primary="C-Mart fictional supermarket chain" data-secondary="causal diagrams" data-tertiary="substitution effects" data-type="indexterm" id="idm45968166836280"/>For example, customers coming to the C-Mart concession store might choose between iced coffee and hot coffee based not only on temperature but also on special promotions and how often they had coffee this week. Therefore, there is a causal relationship from purchases of iced coffee to purchases of hot coffee, and another causal relationship in the opposite direction (<a data-type="xref" href="#a_cd_with_a_substitution_effect_generat">Figure 3-23</a>).</p>

<figure><div id="a_cd_with_a_substitution_effect_generat" class="figure"><img alt="A CD with a substitution effect generating a cycle" src="Images/BEDA_0323.png" width="745" height="139"/>
<h6><span class="label">Figure 3-23. </span>A CD with a substitution effect generating a cycle</h6>
</div></figure>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>One thing to note is that the direction of the arrows shows <a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="fundamental structures of" data-tertiary="direction of arrow as causality" data-type="indexterm" id="idm45968166830248"/>the direction of causality (what is the cause and what is the effect), not the sign of the effect. In all of the CDs we looked at previously, the variables had a positive relationship where an increase in one caused an increase in the other. In this case, the relationships are negative, where an increase in one variable will cause a decrease in the other. The sign of the effect does not matter for causal diagrams, and a regression will be able to sort out the sign for the coefficient correctly as long as you correctly identify the relevant causal relationships.</p>
</div>

<p>Another common cycle is a feedback loop, where a person<a contenteditable="false" data-primary="feedback loops" data-type="indexterm" id="idm45968166827176"/><a contenteditable="false" data-primary="environment and behavior" data-secondary="feedback loop" data-type="indexterm" id="idm45968166826072"/><a contenteditable="false" data-primary="C-Mart fictional supermarket chain" data-secondary="causal diagrams" data-tertiary="feedback loops" data-type="indexterm" id="idm45968166824680"/> modifies their behavior in reaction to changes in the environment. For example, a store manager at C-Mart might keep an eye on the length of waiting lines and open new lines if the existing ones get too long, so that customers don’t give up and just leave (<a data-type="xref" href="#example_of_a_feedback_loop_generating_a">Figure 3-24</a>).</p>

<figure><div id="example_of_a_feedback_loop_generating_a" class="figure"><img alt="Example of a feedback loop generating a cycle" src="Images/BEDA_0324.png" width="1200" height="139"/>
<h6><span class="label">Figure 3-24. </span>Example of a feedback loop generating a cycle</h6>
</div></figure>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Managing cycles"><div class="sect3" id="managing_cycles">
<h3>Managing cycles</h3>

<p>Cycles reflect situations that are often complex to study and<a contenteditable="false" data-primary="cycles in causal diagrams" data-secondary="managing cycles" data-type="indexterm" id="idm45968166817144"/><a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="transformations of" data-tertiary="managing cycles" data-type="indexterm" id="idm45968166815832"/><a contenteditable="false" data-primary="transformations of causal diagrams" data-secondary="cycles" data-tertiary="managing" data-type="indexterm" id="idm45968166814184"/><a contenteditable="false" data-primary="systems thinking" data-type="indexterm" id="idm45968166812520"/> manage, which is why a whole field of research, called <em>systems thinking</em>, has sprouted for that purpose.<sup><a data-type="noteref" id="ch01fn7-marker" href="ch03.xhtml#ch01fn7">2</a></sup> Complex mathematical methods, such as structural equation modeling, have been developed to deal accurately with cycles, but their analysis would take us beyond the scope of this book. I would be remiss, however, if I didn’t give you any solution, so I’ll mention two rules of thumb that should keep you from getting stuck with cycles.</p>

<p>The first one is to pay close attention to timing. In almost all<a contenteditable="false" data-primary="timing" data-secondary="managing cycles" data-type="indexterm" id="idm45968166808056"/> cases, it takes some time for one variable to influence another, which means you can “break the cycle” and turn it into an “acyclical” CD, i.e., a CD without cycles (which you can then analyze with the tools presented in this book), by looking at your data at a more granular level of time. For example, let’s say that it takes 15 minutes for a store manager to react to an increasing waiting time by getting new lines open, and it similarly takes 15 minutes for customers to adjust their perception of waiting time. In that case, by clarifying the temporal order of things, we can split the waiting time variable in our CD (<a data-type="xref" href="#breaking_a_feedback_loop_into_time_incr">Figure 3-25</a>).</p>

<figure><div id="breaking_a_feedback_loop_into_time_incr" class="figure"><img alt="Breaking a feedback loop into time increments" src="Images/BEDA_0325.png" width="1200" height="350"/>
<h6><span class="label">Figure 3-25. </span>Breaking a feedback loop into time increments</h6>
</div></figure>

<p>I’ll explain this CD one piece at a time. On the left, we have an arrow from average waiting time to number of customers waiting:</p>

<div data-type="equation">
<p><em>NbCustomersWaiting(t</em> + 15mn) = <em>β<sub>1</sub>.AvgWaitingTime(t)</em></p>
</div>

<p>This means that the number of customers waiting at, say, 9:15 a.m. would be expressed as a function of the average waiting time at 9:00 a.m. Then the number of customers waiting at 9:30 a.m. would have the same relation to the average waiting time at 9:15 a.m. and so on.</p>

<p>Similarly, on the right, we have an arrow from average waiting time to number of lines open:</p>

<div data-type="equation">
<p><em>NbLinesOpen(t</em> + 15mn) = <em>β<sub>2</sub>.AvgWaitingTime(t)</em></p>
</div>

<p>This means that the number of lines open at 9:15 a.m. would be expressed as a function of the average waiting time at 9:00 a.m. Then the number of lines open at 9:30 a.m. would have the same relation to the average waiting time at 9:15 a.m. and so on.</p>

<p>Then in the middle, we have causal arrows from the number of customers waiting and from the number of lines open to the average waiting time. Assuming linear relationships here for the sake of simplicity, this would translate into the following <span class="keep-together">equation:</span></p>

<div data-type="equation">
<p><em>AvgWaitingTime(t)</em> = <em>β</em><sub>3</sub>.<em>NbCustomersWaiting(t)</em> + <em>β</em><sub>4</sub>.<em>NbLinesOpen(t)</em></p>
</div>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In reality, the assumption of linear relationships is <em>very</em> unlikely to be true in this case. Specific models have been developed for queues, or for time-to-event variables (e.g., survival analysis). These models are part of the broader category of GLMs, and as such, a good rule of thumb is that for our purposes they’ll behave like logistic regressions.</p>
</div>

<p>This means that the average waiting time for customers reaching the checkout lines at 9:15 a.m. depends on the number of customers already present and the number of checkout lines open at 9:15 a.m. Then the average waiting time for customers reaching the checkout lines at 9:30 a.m. depends on the number of customers already present and the number of checkout lines open at 9:30 a.m. and so on.</p>

<p>By breaking down variables into time increments, we have been able to create a CD where there is no cycle in the strict sense. We can estimate the three preceding linear regression equations without introducing any circular logic.</p>

<p>The second rule of thumb for dealing with cycles is to simplify your CD and to keep only the arrows along the causal path you are most interested in. Feedback effects (where a variable influences the variable that just influenced it) are generally smaller, and often much smaller, than the first effect and can be ignored as a first <span class="keep-together">approximation.</span></p>

<p>In our example of iced and hot coffee, you might be worried that the increase in sales of iced coffee when it is hot will decrease the sale of hot coffee; this is a reasonable concern that you should investigate. However, it’s unlikely that the decrease in sales of hot coffee would in turn trigger a further increase in sales of iced coffee, and you can ignore that feedback effect in your CD (<a data-type="xref" href="#simplifying_a_cd_by_neglecting_certain">Figure 3-26</a>).</p>

<figure><div id="simplifying_a_cd_by_neglecting_certain" class="figure"><img alt="Simplifying a CD by neglecting certain relationships" src="Images/BEDA_0326.png" width="737" height="433"/>
<h6><span class="label">Figure 3-26. </span>Simplifying a CD by neglecting certain relationships</h6>
</div></figure>

<p>In <a data-type="xref" href="#simplifying_a_cd_by_neglecting_certain">Figure 3-26</a>, we delete the arrow from purchases of hot coffee to purchases of iced coffee and ignore that relationship as a reasonable approximation.</p>

<p>Once again, this is just a rule of thumb, and certainly not a blanket invitation to disregard cycles and feedback effects. These should be represented fully in your complete CD to guide future analyses.</p>
</div></section>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Paths"><div class="sect2" id="paths">
<h2>Paths</h2>

<p>Having seen the various ways variables can interact, we can now<a contenteditable="false" data-primary="causal diagrams (CDs)" data-secondary="transformations of" data-tertiary="paths" data-type="indexterm" id="idm45968166778456"/><a contenteditable="false" data-primary="transformations of causal diagrams" data-secondary="paths" data-type="indexterm" id="idm45968166776728"/><a contenteditable="false" data-primary="paths in causal diagrams" data-type="indexterm" id="idm45968166775384"/> introduce one last concept that encompasses all of them: <em>paths</em>. We say that there is a path between two variables <em>if there are arrows between them, regardless of the direction of the arrows, and if no variable appears twice along the way.</em> Let’s see what that looks like in a CD we have seen before (<a data-type="xref" href="#paths_in_a_causal_diagram">Figure 3-27</a>).</p>

<figure><div id="paths_in_a_causal_diagram" class="figure"><img alt="Paths in a causal diagram" src="Images/BEDA_0327.png" width="1052" height="372"/>
<h6><span class="label">Figure 3-27. </span>Paths in a causal diagram</h6>
</div></figure>

<p>In the previous CD, there are two paths from<a contenteditable="false" data-primary="C-Mart fictional supermarket chain" data-secondary="causal diagrams" data-tertiary="paths" data-type="indexterm" id="idm45968166769800"/> <em>SummerMonth</em> to <em>IcedCoffeeSales</em>:</p>

<ul>
	<li>
	<p>One path along the chain <em>SummerMonth</em> → <em>Temperature</em> → <em>IcedCoffeeSales</em></p>
	</li>
	<li>
	<p>A second path through <em>IceCreamSales</em>, <em>SummerMonth</em> → <em>IceCreamSales</em> ← <em>Temperature</em> → <em>IcedCoffeeSales</em></p>
	</li>
</ul>

<p>This means that a chain is a path, but so are a fork or a collider!<a contenteditable="false" data-primary="chains in causal diagrams" data-secondary="paths" data-type="indexterm" id="idm45968166761144"/><a contenteditable="false" data-primary="forks in causal diagrams" data-secondary="paths" data-type="indexterm" id="idm45968166759624"/><a contenteditable="false" data-primary="colliders in causal diagrams" data-secondary="paths" data-type="indexterm" id="idm45968166758232"/> Also note that two different paths between two variables can also share some arrows, as long as there is at least one difference between them, as is the case here: the arrow from <em>Temperature</em> to <em>IcedCoffeeSales</em> appears in both paths.</p>

<p>However, the following is not a valid path between <em>Temperature</em> and <em>IcedCoffeeSales</em> because <em>Temperature</em> appears twice:</p>

<ul>
	<li>
	<p><em>Temperature</em> ← <em>SummerMonth</em> → <em>IceCreamSales</em> ← <em>Temperature</em> → <em>IcedCoffeeSales</em></p>
	</li>
</ul>

<p>One consequence of these definitions is that if you pick two different variables in a CD, there is always at least one path between them. The definition of paths may seem so broad that it is useless, but as we’ll see in <a data-type="xref" href="ch05.xhtml#using_causal_diagrams_to_deconfound_da">Chapter 5</a>, paths will actually play a crucial role in identifying confounders in a CD.<a contenteditable="false" data-primary="" data-startref="ch03-cauxf" data-type="indexterm" id="idm45968166748904"/></p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="conclusion-id00008">
<h1>Conclusion</h1>

<p>Correlation is not causation because confounders can introduce bias in our analyses. Unfortunately, as we’ve seen through examples, simply throwing all available variables and the kitchen sink into a regression is not sufficient to resolve confounding. Worse, controlling on the wrong variables can introduce spurious correlations and create new biases.</p>

<p>As a first step toward unbiased regression, I introduced a tool known as causal diagrams. CDs may be the best analytical tool you’ve never heard of. They can be used to represent our intuitions about causal relationships in the real world, as well as causal relationships between variables in our data; but they are most powerful as a bridge between the two, allowing us to connect our intuition and expert knowledge to observed data, and vice versa.</p>

<p>CDs can get convoluted and complex, but they are based on three simple building blocks: chains, forks, and colliders. They can also be collapsed or expanded, sliced, or aggregated, according to simple rules that are consistent with linear algebra. If you want to know more about CDs, Pearl and Mackenzie (2018) is a very readable and enjoyable book-length introduction.</p>

<p>The full power of CDs will become apparent in <a data-type="xref" href="ch05.xhtml#using_causal_diagrams_to_deconfound_da">Chapter 5</a>, where we’ll see that they allow us to optimally handle confounders in regression, even with nonexperimental data. But CDs are also helpful more broadly, to help us think better about data. In the next chapter, as we get into cleaning and prepping data for analysis, they will allow us to mitigate biases in our data prior to any analysis. This will give you the opportunity to get more familiar with CDs in a simple setting.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="idm45968167675832"><sup><a href="ch03.xhtml#idm45968167675832-marker">1</a></sup> The most common way to represent unobserved variables in CDs is with ovals instead of rectangles.</p><p data-type="footnote" id="ch01fn7"><sup><a href="ch03.xhtml#ch01fn7-marker">2</a></sup> Interested readers are referred to <em>Thinking in Systems: A Primer</em> by Meadows and Wright (2008), as well as <em>The Fifth Discipline: The Art &amp; Practice of the Learning Organization</em> by Senge (2010).</p></div></div></section></div></body></html>