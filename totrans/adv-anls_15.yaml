- en: Chapter 12\. Data Manipulation and Visualization in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章。Python中的数据操作和可视化
- en: In [Chapter 8](ch08.html#r-data-manipulation-visualization) you learned how
    to manipulate and visualize data, with heavy help from the `tidyverse` suite of
    packages. Here we’ll demonstrate similar techniques on the same *star* dataset,
    this time in Python. In particular, we’ll use `pandas` and `seaborn` to manipulate
    and visualize data, respectively. This isn’t a comprehensive guide to what these
    modules, or Python, can do with data analysis. Instead, it’s enough to get you
    exploring on your own.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第8章](ch08.html#r-data-manipulation-visualization)中，你学习如何在数据操作和可视化方面使用`tidyverse`套件。在这里，我们将在Python中演示类似的技术，应用于相同的*star*数据集。特别是，我们将使用`pandas`和`seaborn`分别进行数据操作和可视化。这不是关于这些模块或Python在数据分析中的全部功能的详尽指南。相反，这足以让你自己探索。
- en: As much as possible, I’ll mirror the steps and perform the same operations that
    we did in [Chapter 8](ch08.html#r-data-manipulation-visualization). Because of
    this familiarity, I’ll focus less on the whys of manipulating and visualizing
    data than I will on hows of doing it in Python. Let’s load the necessary modules
    and get started with *star*. The third module, `matplotlib`, is new for you and
    will be used to complement our work in `seaborn`. It comes installed with Anaconda.
    Specifically, we’ll be using the `pyplot` submodule, aliasing it as `plt`.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽可能地，我会模仿我们在[第8章](ch08.html#r-data-manipulation-visualization)中所做的步骤，并执行相同的操作。因为熟悉这些操作，我会更专注于如何在Python中执行数据操作和可视化，而不是为什么这样做。让我们加载必要的模块，并开始使用*star*。第三个模块`matplotlib`对你来说是新的，将用于辅助我们在`seaborn`中的工作。它已经随Anaconda安装。具体来说，我们将使用`pyplot`子模块，并将其别名为`plt`。
- en: '[PRE0]'
  id: totrans-3
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Column-Wise Operations
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列操作
- en: 'In [Chapter 11](ch11.html#data-structures-in-python) you learned that `pandas`
    will attempt to convert one-dimensional data structures into Series. This seemingly
    trivial point will be quite important when selecting columns. Let’s take a look
    at an example: say we *just* wanted to keep the *tmathssk* column from our DataFrame.
    We could do so using the familiar single-bracket notation, but this technically
    results in a Series, not a DataFrame:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第11章](ch11.html#data-structures-in-python)中，你学习到`pandas`将尝试将一维数据结构转换为Series。当选择列时，这个看似微不足道的点将变得非常重要。让我们看一个例子：假设我们只想保留DataFrame中的*tmathssk*列。我们可以使用熟悉的单括号表示法来做到这一点，但从技术上讲，这会导致一个Series，而不是DataFrame：
- en: '[PRE1]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'It’s probably better to keep this as a DataFrame if we aren’t positive that
    we want *math_scores* to stay as a one-dimensional structure. To do so, we can
    use two sets of brackets instead of one:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不能确定是否希望*math_scores*保持为一维结构，最好将其保留为DataFrame。为此，我们可以使用两组方括号而不是一组：
- en: '[PRE2]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Following this pattern, we can keep only the desired columns in *star*. I’ll
    use the `columns` attribute to confirm.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这个模式，我们可以在*star*中仅保留所需的列。我将使用`columns`属性来确认。
- en: '[PRE3]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To drop specific columns, use the `drop()` method. `drop()` can be used to drop
    columns *or* rows, so we’ll need to specify which by using the `axis` argument.
    In `pandas`, rows are axis `0` and columns axis `1`, as [Figure 12-1](#pandas-axes)
    demonstrates.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除特定的列，请使用`drop()`方法。`drop()`可以用于删除列或行，所以我们需要通过使用`axis`参数来指定。在`pandas`中，行是轴`0`，列是轴`1`，正如[图12-1](#pandas-axes)所示。
- en: '![Axes of star dataset](assets/aina_1201.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![star数据集的轴](assets/aina_1201.png)'
- en: Figure 12-1\. Axes of a `pandas` DataFrame
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图12-1。一个`pandas` DataFrame的轴
- en: 'Here’s how to drop the *schidkn* column:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是如何删除*schidkn*列的方法：
- en: '[PRE4]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s now look at deriving new columns of a DataFrame. We can do that using
    bracket notation—this time, I *do* want the result to be a Series, as each column
    of a DataFrame is actually a Series (just as each column of an R data frame is
    actually a vector). Here I’ll calculate combined math and reading scores:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看如何从DataFrame中派生新的列。我们可以使用方括号表示法来做到这一点——这一次，我确实希望结果是一个Series，因为DataFrame的每一列实际上都是一个Series（就像R数据框的每一列实际上都是一个向量一样）。在这里，我将计算数学和阅读成绩的综合：
- en: '[PRE5]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Again, *new_column* isn’t a terribly descriptive variable name. Let’s fix that
    with the `rename()` function. We’ll use the `columns` argument and pass data to
    it in a format you’re likely unfamiliar with:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，*new_column*不是一个非常描述性的变量名。让我们使用`rename()`函数来修复它。我们将使用`columns`参数，并以你可能不熟悉的格式传递数据：
- en: '[PRE6]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The curly bracket notation used in the last example is a Python *dictionary*.
    Dictionaries are collections of *key-value* pairs, with the key and value of each
    element separated by a colon. This is a core Python data structure and one to
    check out as you continue learning the language.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个示例中使用的花括号表示法是 Python 的 *字典*。字典是 *键-值* 对的集合，每个元素的键和值由冒号分隔。这是 Python 的核心数据结构之一，是你继续学习该语言时要了解的内容。
- en: Row-Wise Operations
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按行进行操作
- en: 'Now let’s move to common operations by row. We’ll start with sorting, which
    can be done in `pandas` with the `sort_values()` method. We’ll pass a list of
    columns we want to sort by in their respective order to the `by` argument:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们转向按行常见的操作。我们将从排序开始，在 `pandas` 中可以使用 `sort_values()` 方法完成。我们将按照各列的指定顺序传递给
    `by` 参数来排序：
- en: '[PRE7]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: By default, all columns are sorted ascendingly. To modify that, we can include
    another argument, `ascending`, which will contain a list of `True`/`False` flags.
    Let’s sort *star* by class size (*classk*) ascending and math score (*treadssk*)
    descending. Because we’re not assigning this output back to *star*, this sorting
    is not permanent to the dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，所有列都按升序排序。要修改这一点，我们可以包含另一个参数 `ascending`，其中包含 `True`/`False` 标志的列表。让我们按照班级大小（*classk*）升序和数学分数（*treadssk*）降序来排序
    *star*。因为我们没有将此输出重新分配给 *star*，所以这种排序不会永久影响数据集。
- en: '[PRE8]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To filter a DataFrame, we’ll first use conditional logic to create a Series
    of `True`/`False` flags indicating whether each row meets some criteria. We’ll
    then keep only the rows in the DataFrame where records in the Series are flagged
    as `True`. For example, let’s keep only the records where `classk` is equal to
    `small.class`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要筛选 DataFrame，我们首先使用条件逻辑创建一个 Series，其中包含每行是否符合某些条件的 `True`/`False` 标志。然后，我们仅保留
    DataFrame 中 Series 中标记为 `True` 的记录。例如，让我们仅保留 `classk` 等于 `small.class` 的记录。
- en: '[PRE9]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can now filter by this resulting Series by using brackets. We can confirm
    the number of rows and columns in our new DataFrame with the `shape` attribute:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用括号过滤此结果的 Series。我们可以使用 `shape` 属性确认新 DataFrame 的行数和列数：
- en: '[PRE10]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`star_filtered` will contain fewer rows than *star*, but the same number of
    columns:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`star_filtered` 将包含比 *star* 更少的行，但列数相同：'
- en: '[PRE11]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let’s try one more: we’ll find the records where `treadssk` is at least `500`:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再试一次：找到 `treadssk` 至少为 `500` 的记录：
- en: '[PRE12]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'It’s also possible to filter by multiple conditions using and/or statements.
    Just like in R, `&` and `|` indicate “and” and “or” in Python, respectively. Let’s
    pass both of the previous criteria into one statement by placing each in parentheses,
    connecting them with `&`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用 and/or 语句根据多个条件进行过滤。就像在 R 中一样，`&` 和 `|` 分别表示 "和" 和 "或"。让我们将前面的两个条件放入括号中，并使用
    `&` 将它们连接到一个语句中：
- en: '[PRE13]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Aggregating and Joining Data
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚合和连接数据
- en: 'To group observations in a DataFrame, we’ll use the `groupby()` method. If
    we print `star_grouped`, you’ll see it’s a `DataFrameGroupBy` object:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 DataFrame 中对观察结果进行分组，我们将使用 `groupby()` 方法。如果打印 `star_grouped`，你会看到它是一个 `DataFrameGroupBy`
    对象：
- en: '[PRE14]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We can now choose other fields to aggregate this grouped DataFrame by. [Table 12-1](#pandas-agg-types)
    lists some common aggregation methods.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以选择其他字段来对这个分组的 DataFrame 进行聚合。[Table 12-1](#pandas-agg-types) 列出了一些常见的聚合方法。
- en: Table 12-1\. Helpful aggregation functions in `pandas`
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-1\. `pandas` 中有用的聚合函数
- en: '| Method | Aggregation type |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 聚合类型 |'
- en: '| --- | --- |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `sum()` | Sum |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `sum()` | 总和 |'
- en: '| `count()` | Count values |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `count()` | 计数值 |'
- en: '| `mean()` | Average |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `mean()` | 平均值 |'
- en: '| `max()` | Highest value |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `max()` | 最高值 |'
- en: '| `min()` | Lowest value |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| `min()` | 最小值 |'
- en: '| `std()` | Standard deviation |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| `std()` | 标准差 |'
- en: 'The following gives us the average math score for each class size:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下给出了每个班级大小的平均数学分数：
- en: '[PRE15]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now we’ll find the highest total score for each year of teacher experience.
    Because this would return quite a few rows, I will include the `head()` method
    to get just a few. This practice of adding multiple methods to the same command
    is called method *chaining*:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将找到每年教师经验的最高总分。因为这将返回相当多的行，我将包含 `head()` 方法以仅获取一些行。将多个方法添加到同一命令的这种做法称为方法
    *链式调用*：
- en: '[PRE16]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[Chapter 8](ch08.html#r-data-manipulation-visualization) reviewed the similarities
    and differences between Excel’s `VLOOKUP()` and a left outer join. I’ll read in
    a fresh copy of *star* as well as *districts*; let’s use `pandas` to join these
    datasets. We’ll use the `merge()` method to “look up” data from *school-districts*
    into *star*. By setting the `how` argument to `left`, we’ll specify a left outer
    join, which again is the join type most similar to `VLOOKUP()`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[第8章](ch08.html#r-data-manipulation-visualization)回顾了Excel的`VLOOKUP()`和左外连接之间的相似性和差异。我将重新读入*star*和*districts*的最新副本；让我们使用`pandas`来合并这些数据集。我们将使用`merge()`方法将*school-districts*中的数据“查找”到*star*中。通过将`how`参数设置为`left`，我们将指定左外连接，这是最接近`VLOOKUP()`的连接类型：'
- en: '[PRE17]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Python, like R, is quite intuitive about joining data: it knew by default to
    merge on *schidkn* and brought in both *school_name* and *county*.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Python像R一样对数据连接非常直观：它默认使用*schidkn*进行合并，并同时引入*school_name*和*county*。
- en: Reshaping Data
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据重塑
- en: 'Let’s take a look at widening and lengthening a dataset in Python, again using
    `pandas`. To start, we can use the `melt()` function to combine *tmathssk* and
    *treadssk* into one column. To do this, I’ll specify the DataFrame to manipulate
    with the `frame` argument, which variable to use as a unique identifier with `id_vars`,
    and which variables to melt into a single column with `value_vars`. I’ll also
    specify what to name the resulting value and label variables with `value_name`
    and `var_name`, respectively:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看如何在Python中扩展和延长数据集，再次使用`pandas`。首先，我们可以使用`melt()`函数将*tmathssk*和*treadssk*合并到一列中。为此，我将指定要使用`frame`参数操作的DataFrame，使用`id_vars`作为唯一标识符的变量，并使用`value_vars`将变量融合为单列。我还将指定如何命名生成的值和标签变量，分别为`value_name`和`var_name`：
- en: '[PRE18]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'How about renaming *tmathssk* and *treadssk* as *math* and *reading*, respectively?
    To do this, I’ll use a Python dictionary to set up an object called `mapping`,
    which serves as something like a “lookup table” to recode the values. I’ll pass
    this into the `map()` method which will recode *test_type*. I’ll also use the
    `unique()` method to confirm that only *math* and *reading* are now found in *test_type*:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如何将*tmathssk*和*treadssk*重命名为*math*和*reading*？为此，我将使用一个Python字典来设置一个名为`mapping`的对象，它类似于一个“查找表”以重新编码这些值。我将把它传递给`map()`方法来重新编码*test_type*。我还将使用`unique()`方法确认*test_type*现在仅包含*math*和*reading*：
- en: '[PRE19]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: To widen *star_pivot* back into separate *math* and *reading* columns, I’ll
    use the `pivot_table()` method. First I’ll specify what variable to index by with
    the `index` argument, then which variables contain the labels and values to pivot
    from with the `columns` and `values` arguments, respectively.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要将*star_pivot*扩展回单独的*math*和*reading*列，我将使用`pivot_table()`方法。首先，我将指定要使用`index`参数索引的变量，然后使用`columns`和`values`参数指定标签和值来自哪些变量：
- en: It’s possible in `pandas` to set unique index columns; by default, `pivot_table()`
    will set whatever variables you’ve included in the `index` argument there. To
    override this, I’ll use the `reset_index()` method. To learn more about custom
    indexing in `pandas`, along with countless other data manipulation and analysis
    techniques we couldn’t cover here, check out [*Python for Data Analysis*](https://oreil.ly/CrP7B),
    2nd edition by Wes McKinney (O’Reilly).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在`pandas`中，可以设置唯一的索引列；默认情况下，`pivot_table()`将设置`index`参数中包含的任何变量。为了覆盖这一点，我将使用`reset_index()`方法。要了解更多关于`pandas`中自定义索引以及其他无数的数据操作和分析技术，请参阅《*Python
    for Data Analysis*》（O'Reilly出版社第2版）作者Wes McKinney的书籍[链接](https://oreil.ly/CrP7B)。
- en: '[PRE20]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Data Visualization
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据可视化
- en: Let’s now briefly touch on data visualization in Python, specifically using
    the `seaborn` package. `seaborn` works especially well for statistical analysis
    and with `pandas` DataFrames, so it’s a great choice here. Similarly to how `pandas`
    is built on top of `numpy`, `seaborn` leverages features of another popular Python
    plotting package, `matplotlib`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们简要介绍一下Python中的数据可视化，特别是使用`seaborn`包。`seaborn`在统计分析和`pandas`数据框架中表现特别出色，因此在这里是一个很好的选择。类似于`pandas`是建立在`numpy`之上，`seaborn`利用了另一个流行的Python绘图包`matplotlib`的功能。
- en: '`seaborn` includes many functions to build different plot types. We’ll modify
    the arguments within these functions to specify which dataset to plot, which variables
    go along the x- and y-axes, which colors to use, and so on. Let’s get started
    by visualizing the count of observations for each level of *classk*, which we
    can do with the `countplot()` function.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`seaborn`包括许多函数来构建不同类型的图表。我们将修改这些函数中的参数，以指定要绘制的数据集、沿x轴和y轴的变量、要使用的颜色等。我们首先通过使用`countplot()`函数来可视化每个*classk*水平的观察计数。'
- en: 'Our dataset is *star*, which we’ll specify with the `data` argument. To place
    our levels of *classk* along the x-axis we’ll use the `x` argument. This results
    in the countplot shown in [Figure 12-2](#seaborn-countplot):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集是*star*，我们将使用`data`参数指定。要将*classk*的水平放置在x轴上，我们将使用`x`参数。这导致了图 12-2 中所示的计数图：
- en: '[PRE21]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![Countplot](assets/aina_1202.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![Countplot](assets/aina_1202.png)'
- en: Figure 12-2\. Countplot
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-2\. 计数图
- en: 'Now for a histogram of *treadssk*, we’ll use the `displot()` function. Again,
    we’ll specify `x` and `data`. [Figure 12-3](#seaborn-histogram) shows the result:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在对于*treadssk*的直方图，我们将使用`displot()`函数。同样，我们将指定`x`和`data`。[图 12-3](#seaborn-histogram)展示了结果：
- en: '[PRE22]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![Histogram](assets/aina_1203.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![直方图](assets/aina_1203.png)'
- en: Figure 12-3\. Histogram
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-3\. 直方图
- en: '`seaborn` functions include many optional arguments to customize a plot’s appearance.
    For example, let’s change the number of bins to 25 and the plot color to pink.
    This results in [Figure 12-4](#seaborn-custom-histogram):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`seaborn`函数包括许多可选参数，用于自定义图表的外观。例如，让我们将箱数更改为25并将绘图颜色更改为粉红色。这将产生[图 12-4](#seaborn-custom-histogram)：'
- en: '[PRE23]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![Custom histogram](assets/aina_1204.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![自定义直方图](assets/aina_1204.png)'
- en: Figure 12-4\. Custom histogram
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-4\. 自定义直方图
- en: 'To make a boxplot, use the `boxplot()` function as in [Figure 12-5](#seaborn-boxplot):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要制作箱线图，使用`boxplot()`函数，如[图 12-5](#seaborn-boxplot)所示：
- en: '[PRE24]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In any of these cases so far, we could’ve “flipped” the plot by instead including
    the variable of interest in the `y` argument. Let’s try it with our boxplot, and
    we’ll get what’s shown in [Figure 12-6](#seaborn-flipped-boxplot) as output:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在所有这些情况下，我们都可以通过将感兴趣的变量包含在`y`参数中来“翻转”图表。让我们尝试使用我们的箱线图进行演示，我们将得到图 12-6
    中显示的输出：
- en: '[PRE25]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![Boxplot](assets/aina_1205.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![箱线图](assets/aina_1205.png)'
- en: Figure 12-5\. Boxplot
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-5\. 箱线图
- en: '![Boxplot](assets/aina_1206.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![箱线图](assets/aina_1206.png)'
- en: Figure 12-6\. “Flipped” boxplot
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-6\. “翻转”的箱线图
- en: 'To make a boxplot for each level of class size, we’ll include an additional
    argument to plot *classk* along the x-axis, giving us the boxplot by group depicted
    in [Figure 12-7](#seaborn-grouped-boxplot):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要为每个班级大小水平制作箱线图，我们将在`classk`的x轴上包含一个额外的参数，这样就得到了图 12-7 中所示的按组的箱线图：
- en: '[PRE26]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![Grouped boxplot](assets/aina_1207.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![分组箱线图](assets/aina_1207.png)'
- en: Figure 12-7\. Boxplot by group
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-7\. 按组的箱线图
- en: 'Now let’s use the `scatterplot()` function to plot the relationship of *tmathssk*
    on the x-axis and *treadssk* on the y. [Figure 12-8](#seaborn-scatterplot) is
    the result:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用`scatterplot()`函数在x轴上绘制*tmathssk*与y轴上的*treadssk*之间的关系。[图 12-8](#seaborn-scatterplot)是结果：
- en: '[PRE27]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![Scatterplot](assets/aina_1208.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![散点图](assets/aina_1208.png)'
- en: Figure 12-8\. Scatterplot
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-8\. 散点图
- en: 'Let’s say we wanted to share this plot with an outside audience, who may not
    be familiar with what *treadssk* and *tmathssk* are. We can add more helpful labels
    to this chart by borrowing features from `matplotlib.pyplot`. We’ll run the same
    `scatterplot()` function as before, but this time we’ll also call in functions
    from `pyplot` to add custom x- and y-axis labels, as well as a chart title. This
    results in [Figure 12-9](#seaborn-labeled-scatterplot):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要与外部观众分享这个图表，他们可能不熟悉*treadssk*和*tmathssk*是什么。我们可以通过从`matplotlib.pyplot`中借用功能向该图表添加更多有用的标签。我们将与之前相同地运行`scatterplot()`函数，但这次我们还将调用`pyplot`中的函数来添加自定义的x和y轴标签，以及图表标题。这导致了图
    12-9 中显示的带有标签的散点图：
- en: '[PRE28]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![Scatterplot with custom labels and title](assets/aina_1209.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![带有自定义标签和标题的散点图](assets/aina_1209.png)'
- en: Figure 12-9\. Scatterplot with custom axis labels and title
  id: totrans-98
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-9\. 带有自定义轴标签和标题的散点图
- en: '`seaborn` includes many more features for building visually appealing data
    visualizations. To learn more, check out [the official documentation](https://oreil.ly/2joMU).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`seaborn`包括许多功能，用于构建视觉上吸引人的数据可视化。要了解更多，请查看[官方文档](https://oreil.ly/2joMU)。'
- en: Conclusion
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'There’s so much more that `pandas` and `seaborn` can do, but this is enough
    to get you started with the true task at hand: to explore and test relationships
    in data. That will be the focus of [Chapter 13](ch13.html#python-for-data-analysis-capstone).'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`和`seaborn`能做的远不止这些，但这已足以让你开始真正的任务：探索和测试数据中的关系。这将是[第13章](ch13.html#python-for-data-analysis-capstone)的重点。'
- en: Exercises
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'The [book repository](https://oreil.ly/hFEOG) has two files in the *census*
    subfolder of *datasets*, *census.csv* and *census-divisions.csv*. Read these into
    Python and do the following:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[书籍存储库](https://oreil.ly/hFEOG)的*datasets*子文件夹*census*中有两个文件，*census.csv*和*census-divisions.csv*。将这些文件读入Python并执行以下操作：'
- en: Sort the data by region ascending, division ascending and population descending.
    (You will need to combine datasets to do this.) Write the results to an Excel
    worksheet.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按地区升序、分区升序和人口降序对数据进行排序（你需要合并数据集才能做到这一点）。将结果写入Excel工作表。
- en: Drop the postal code field from your merged dataset.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从合并的数据集中删除邮政编码字段。
- en: Create a new column, *density*, that is a calculation of population divided
    by land area.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为*density*的新列，该列是人口除以陆地面积的计算结果。
- en: Visualize the relationship between land area and population for all observations
    in 2015.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化2015年所有观察中陆地面积和人口之间的关系。
- en: Find the total population for each region in 2015.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出每个地区在2015年的总人口。
- en: Create a table containing state names and populations, with the population for
    each year 2010–2015 kept in an individual column.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含州名和人口的表，每年2010年至2015年的人口分别保留在一个单独的列中。
