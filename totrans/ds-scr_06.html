<html><head></head><body><section data-pdf-bookmark="Chapter 5. Statistics" data-type="chapter" epub:type="chapter"><div class="chapter" id="statistics">&#13;
<h1><span class="label">Chapter 5. </span>Statistics</h1>&#13;
&#13;
<blockquote data-type="epigraph" epub:type="epigraph">&#13;
<p>Facts are stubborn, but statistics are more pliable.</p>&#13;
<p data-type="attribution">Mark Twain</p>&#13;
</blockquote>&#13;
&#13;
<p><em>Statistics</em> refers<a data-primary="mathematics" data-secondary="statistics" data-type="indexterm" id="Mstat05"/> to the mathematics and techniques with which we understand data.  It is a rich, enormous field, more suited to a shelf (or room) in a library than a chapter in a book, and so our discussion will necessarily not be a deep one.  Instead, I’ll try to teach you just enough to be dangerous, and pique your interest just enough that you’ll go off and learn more.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Describing a Single Set of Data" data-type="sect1"><div class="sect1" id="idm45635758409576">&#13;
<h1>Describing a Single Set of Data</h1>&#13;
&#13;
<p>Through<a data-primary="statistics" data-secondary="describing single sets of data" data-type="indexterm" id="Ssingle05"/> a combination of word of mouth and luck, DataSciencester has grown to dozens of members, and the VP of Fundraising asks you for some sort of description of how many friends your members have that he can include in his elevator pitches.</p>&#13;
&#13;
<p>Using techniques from <a data-type="xref" href="ch01.html#introduction">Chapter 1</a>, you are easily able to produce this data.  But now you are faced with the problem of how to <em>describe</em> it.</p>&#13;
&#13;
<p>One obvious description of any dataset is simply the data itself:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">num_friends</code> <code class="o">=</code> <code class="p">[</code><code class="mi">100</code><code class="p">,</code> <code class="mi">49</code><code class="p">,</code> <code class="mi">41</code><code class="p">,</code> <code class="mi">40</code><code class="p">,</code> <code class="mi">25</code><code class="p">,</code>&#13;
               <code class="c1"># ... and lots more</code>&#13;
              <code class="p">]</code></pre>&#13;
&#13;
<p>For a small enough dataset, this might even be the best description.  But for a larger dataset, this is unwieldy and probably opaque. (Imagine staring at a list of 1 million numbers.) For that reason, we use statistics to distill and communicate relevant features of our data.</p>&#13;
&#13;
<p>As<a data-primary="data" data-secondary="describing single sets of" data-tertiary="histograms" data-type="indexterm" id="idm45635758372680"/> a first approach, you put the friend counts into a histogram using <code>Counter</code> and <code>plt.bar</code> (<a data-type="xref" href="#histogram_friend_counts">Figure 5-1</a>):</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">Counter</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="kn">as</code> <code class="nn">plt</code>&#13;
&#13;
<code class="n">friend_counts</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code>&#13;
<code class="n">xs</code> <code class="o">=</code> <code class="nb">range</code><code class="p">(</code><code class="mi">101</code><code class="p">)</code>                         <code class="c1"># largest value is 100</code>&#13;
<code class="n">ys</code> <code class="o">=</code> <code class="p">[</code><code class="n">friend_counts</code><code class="p">[</code><code class="n">x</code><code class="p">]</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">]</code>     <code class="c1"># height is just # of friends</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">bar</code><code class="p">(</code><code class="n">xs</code><code class="p">,</code> <code class="n">ys</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">axis</code><code class="p">([</code><code class="mi">0</code><code class="p">,</code> <code class="mi">101</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">25</code><code class="p">])</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s2">"Histogram of Friend Counts"</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s2">"# of friends"</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s2">"# of people"</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>&#13;
&#13;
<figure><div class="figure" id="histogram_friend_counts">&#13;
<img alt="Number of friends." src="assets/dsf2_0501.png"/>&#13;
<h6><span class="label">Figure 5-1. </span>A histogram of friend counts</h6>&#13;
</div></figure>&#13;
&#13;
<p>Unfortunately, this<a data-primary="data" data-secondary="describing single sets of" data-tertiary="number of data points" data-type="indexterm" id="idm45635758205112"/> chart is still too difficult to slip into conversations.  So you start generating some statistics.  Probably the simplest statistic is the number of data points:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">num_points</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code>               <code class="c1"># 204</code></pre>&#13;
&#13;
<p>You’re<a data-primary="data" data-secondary="describing single sets of" data-tertiary="largest and smallest values" data-type="indexterm" id="idm45635758200216"/> probably also interested in the largest and smallest values:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">largest_value</code> <code class="o">=</code> <code class="nb">max</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code>            <code class="c1"># 100</code>&#13;
<code class="n">smallest_value</code> <code class="o">=</code> <code class="nb">min</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code>           <code class="c1"># 1</code></pre>&#13;
&#13;
<p>which<a data-primary="data" data-secondary="describing single sets of" data-tertiary="specific positions of values" data-type="indexterm" id="idm45635758106840"/> are just special cases of wanting to know the values in specific positions:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">sorted_values</code> <code class="o">=</code> <code class="nb">sorted</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code>&#13;
<code class="n">smallest_value</code> <code class="o">=</code> <code class="n">sorted_values</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>           <code class="c1"># 1</code>&#13;
<code class="n">second_smallest_value</code> <code class="o">=</code> <code class="n">sorted_values</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code>    <code class="c1"># 1</code>&#13;
<code class="n">second_largest_value</code> <code class="o">=</code> <code class="n">sorted_values</code><code class="p">[</code><code class="o">-</code><code class="mi">2</code><code class="p">]</code>    <code class="c1"># 49</code></pre>&#13;
&#13;
<p>But we’re only getting started.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Central Tendencies" data-type="sect2"><div class="sect2" id="idm45635758187160">&#13;
<h2>Central Tendencies</h2>&#13;
&#13;
<p>Usually, we’ll<a data-primary="mean (average)" data-type="indexterm" id="idm45635758088392"/><a data-primary="average (mean)" data-type="indexterm" id="idm45635758087656"/><a data-primary="central tendencies" data-type="indexterm" id="idm45635758086984"/><a data-primary="data" data-secondary="describing single sets of" data-tertiary="mean (average)" data-type="indexterm" id="idm45635758086312"/> want some notion of where our data is centered.  Most commonly we’ll use the <em>mean</em> (or average), which is just the sum of the data divided by its count:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">mean</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="k">return</code> <code class="nb">sum</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code> <code class="o">/</code> <code class="nb">len</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code>&#13;
&#13;
<code class="n">mean</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code>   <code class="c1"># 7.333333</code></pre>&#13;
&#13;
<p>If you have two data points, the mean is simply the point halfway between them. As you add more points, the mean shifts around, but it always depends on the value of every point. For example, if you have 10 data points, and you increase the value of any of them by 1, you increase the mean by 0.1.</p>&#13;
&#13;
<p>We’ll also sometimes be interested<a data-primary="median" data-type="indexterm" id="idm45635758065016"/><a data-primary="data" data-secondary="describing single sets of" data-tertiary="median" data-type="indexterm" id="idm45635758028200"/> in the <em>median</em>, which is the middle-most value (if the number of data points is odd) or the average of the two middle-most values (if the number of data points is even).</p>&#13;
&#13;
<p>For instance, if we have five data points in a sorted vector <code>x</code>, the median is <code>x[5 // 2]</code> or <code>x[2]</code>.  If we have six data points, we want the average of <code>x[2]</code> (the third point) and <code>x[3]</code> (the fourth point).</p>&#13;
&#13;
<p>Notice that—unlike the mean—the median doesn’t fully depend on every value in your data.  For example, if you make the largest point larger (or the smallest point smaller), the middle points remain unchanged, which means so does the median.</p>&#13;
&#13;
<p>We’ll write different functions for the even and odd cases and combine them:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="c1"># The underscores indicate that these are "private" functions, as they're</code>&#13;
<code class="c1"># intended to be called by our median function but not by other people</code>&#13;
<code class="c1"># using our statistics library.</code>&#13;
<code class="k">def</code> <code class="nf">_median_odd</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""If len(xs) is odd, the median is the middle element"""</code>&#13;
    <code class="k">return</code> <code class="nb">sorted</code><code class="p">(</code><code class="n">xs</code><code class="p">)[</code><code class="nb">len</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code> <code class="o">//</code> <code class="mi">2</code><code class="p">]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">_median_even</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""If len(xs) is even, it's the average of the middle two elements"""</code>&#13;
    <code class="n">sorted_xs</code> <code class="o">=</code> <code class="nb">sorted</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code>&#13;
    <code class="n">hi_midpoint</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code> <code class="o">//</code> <code class="mi">2</code>  <code class="c1"># e.g. length 4 =&gt; hi_midpoint 2</code>&#13;
    <code class="k">return</code> <code class="p">(</code><code class="n">sorted_xs</code><code class="p">[</code><code class="n">hi_midpoint</code> <code class="o">-</code> <code class="mi">1</code><code class="p">]</code> <code class="o">+</code> <code class="n">sorted_xs</code><code class="p">[</code><code class="n">hi_midpoint</code><code class="p">])</code> <code class="o">/</code> <code class="mi">2</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">median</code><code class="p">(</code><code class="n">v</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""Finds the 'middle-most' value of v"""</code>&#13;
    <code class="k">return</code> <code class="n">_median_even</code><code class="p">(</code><code class="n">v</code><code class="p">)</code> <code class="k">if</code> <code class="nb">len</code><code class="p">(</code><code class="n">v</code><code class="p">)</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">0</code> <code class="k">else</code> <code class="n">_median_odd</code><code class="p">(</code><code class="n">v</code><code class="p">)</code>&#13;
&#13;
<code class="k">assert</code> <code class="n">median</code><code class="p">([</code><code class="mi">1</code><code class="p">,</code> <code class="mi">10</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="mi">9</code><code class="p">,</code> <code class="mi">5</code><code class="p">])</code> <code class="o">==</code> <code class="mi">5</code>&#13;
<code class="k">assert</code> <code class="n">median</code><code class="p">([</code><code class="mi">1</code><code class="p">,</code> <code class="mi">9</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="mi">10</code><code class="p">])</code> <code class="o">==</code> <code class="p">(</code><code class="mi">2</code> <code class="o">+</code> <code class="mi">9</code><code class="p">)</code> <code class="o">/</code> <code class="mi">2</code></pre>&#13;
&#13;
<p>And now we can compute the median number of friends:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">print</code><code class="p">(</code><code class="n">median</code><code class="p">(</code><code class="n">num_friends</code><code class="p">))</code>  <code class="c1"># 6</code></pre>&#13;
&#13;
<p>Clearly, the mean is simpler to compute, and it varies smoothly as our data changes.  If we have <em>n</em> data points and one of them increases by some small amount <em>e</em>, then necessarily the mean will increase by <em>e</em> / <em>n</em>.  (This makes the mean amenable to all sorts of calculus tricks.)  In order to find the median, however, we have to sort our data. And changing one of our data points by a small amount <em>e</em> might increase the median by <em>e</em>, by some number less than <em>e</em>, or not at all (depending on the rest of the data).</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>There are, in fact, nonobvious tricks to efficiently <a href="http://en.wikipedia.org/wiki/Quickselect">compute medians</a> without sorting the data. However, they are beyond the scope of this book, so <em>we</em> have to sort the data.</p>&#13;
</div>&#13;
&#13;
<p>At the same time, the mean is very sensitive to outliers in our data.  If our friendliest user had 200 friends (instead of 100), then the mean would rise to 7.82, while the median would stay the same.&#13;
If outliers are likely to be bad data (or otherwise unrepresentative of whatever phenomenon we’re trying to understand), then the mean can sometimes give us a misleading picture. For example, the story is often told that in the mid-1980s, the major at the University of North Carolina with the highest average starting salary was geography, mostly because of NBA star (and outlier) Michael Jordan.</p>&#13;
&#13;
<p>A<a data-primary="quantile" data-type="indexterm" id="idm45635757845336"/><a data-primary="data" data-secondary="describing single sets of" data-tertiary="quantile" data-type="indexterm" id="idm45635757844600"/> generalization of the median is the <em>quantile</em>, which represents the value under which a certain percentile of the data lies (the median represents the value under which 50% of the data lies):</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">quantile</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">],</code> <code class="n">p</code><code class="p">:</code> <code class="nb">float</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""Returns the pth-percentile value in x"""</code>&#13;
    <code class="n">p_index</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">p</code> <code class="o">*</code> <code class="nb">len</code><code class="p">(</code><code class="n">xs</code><code class="p">))</code>&#13;
    <code class="k">return</code> <code class="nb">sorted</code><code class="p">(</code><code class="n">xs</code><code class="p">)[</code><code class="n">p_index</code><code class="p">]</code>&#13;
&#13;
<code class="k">assert</code> <code class="n">quantile</code><code class="p">(</code><code class="n">num_friends</code><code class="p">,</code> <code class="mf">0.10</code><code class="p">)</code> <code class="o">==</code> <code class="mi">1</code>&#13;
<code class="k">assert</code> <code class="n">quantile</code><code class="p">(</code><code class="n">num_friends</code><code class="p">,</code> <code class="mf">0.25</code><code class="p">)</code> <code class="o">==</code> <code class="mi">3</code>&#13;
<code class="k">assert</code> <code class="n">quantile</code><code class="p">(</code><code class="n">num_friends</code><code class="p">,</code> <code class="mf">0.75</code><code class="p">)</code> <code class="o">==</code> <code class="mi">9</code>&#13;
<code class="k">assert</code> <code class="n">quantile</code><code class="p">(</code><code class="n">num_friends</code><code class="p">,</code> <code class="mf">0.90</code><code class="p">)</code> <code class="o">==</code> <code class="mi">13</code></pre>&#13;
&#13;
<p>Less<a data-primary="mode" data-type="indexterm" id="idm45635757804968"/><a data-primary="data" data-secondary="describing single sets of" data-tertiary="mode" data-type="indexterm" id="idm45635757804360"/> commonly you might want to look at the <em>mode</em>, or most common value(s):</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">mode</code><code class="p">(</code><code class="n">x</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">]:</code>&#13;
    <code class="sd">"""Returns a list, since there might be more than one mode"""</code>&#13;
    <code class="n">counts</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">x</code><code class="p">)</code>&#13;
    <code class="n">max_count</code> <code class="o">=</code> <code class="nb">max</code><code class="p">(</code><code class="n">counts</code><code class="o">.</code><code class="n">values</code><code class="p">())</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">x_i</code> <code class="k">for</code> <code class="n">x_i</code><code class="p">,</code> <code class="n">count</code> <code class="ow">in</code> <code class="n">counts</code><code class="o">.</code><code class="n">items</code><code class="p">()</code>&#13;
            <code class="k">if</code> <code class="n">count</code> <code class="o">==</code> <code class="n">max_count</code><code class="p">]</code>&#13;
&#13;
<code class="k">assert</code> <code class="nb">set</code><code class="p">(</code><code class="n">mode</code><code class="p">(</code><code class="n">num_friends</code><code class="p">))</code> <code class="o">==</code> <code class="p">{</code><code class="mi">1</code><code class="p">,</code> <code class="mi">6</code><code class="p">}</code></pre>&#13;
&#13;
<p>But most frequently we’ll just use the mean.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Dispersion" data-type="sect2"><div class="sect2" id="idm45635758089240">&#13;
<h2>Dispersion</h2>&#13;
&#13;
<p><em>Dispersion</em> refers<a data-primary="dispersion" data-type="indexterm" id="idm45635757609320"/><a data-primary="data" data-secondary="describing single sets of" data-tertiary="dispersion" data-type="indexterm" id="idm45635757608584"/> to measures of how spread out our data is.  Typically they’re statistics for which values near zero signify <em>not spread out at all</em> and for which large values (whatever that means) signify <em>very spread out</em>. For instance, a very simple measure is the <em>range</em>, which is just the difference between the largest and smallest elements:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="c1"># "range" already means something in Python, so we'll use a different name</code>&#13;
<code class="k">def</code> <code class="nf">data_range</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="k">return</code> <code class="nb">max</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code> <code class="o">-</code> <code class="nb">min</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code>&#13;
&#13;
<code class="k">assert</code> <code class="n">data_range</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code> <code class="o">==</code> <code class="mi">99</code></pre>&#13;
&#13;
<p>The range is zero precisely when the <code>max</code> and <code>min</code> are equal, which can only happen if the elements of <code>x</code> are all the same, which means the data is as undispersed as possible.  Conversely, if the range is large, then the <code>max</code> is much larger than the <code>min</code> and the data is more spread out.</p>&#13;
&#13;
<p>Like the median, the range doesn’t really depend on the whole dataset. A dataset whose points are all either 0 or 100 has the same range as a dataset whose values are 0, 100, and lots of 50s.  But it seems like the first dataset “should” be more spread out.</p>&#13;
&#13;
<p>A more complex measure of dispersion<a data-primary="data" data-secondary="describing single sets of" data-tertiary="variance" data-type="indexterm" id="idm45635757491592"/><a data-primary="variance" data-type="indexterm" id="idm45635757490376"/> is the <em>variance</em>, which is computed as:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">scratch.linear_algebra</code> <code class="kn">import</code> <code class="n">sum_of_squares</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">de_mean</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">]:</code>&#13;
    <code class="sd">"""Translate xs by subtracting its mean (so the result has mean 0)"""</code>&#13;
    <code class="n">x_bar</code> <code class="o">=</code> <code class="n">mean</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">x</code> <code class="o">-</code> <code class="n">x_bar</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">xs</code><code class="p">]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">variance</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""Almost the average squared deviation from the mean"""</code>&#13;
    <code class="k">assert</code> <code class="nb">len</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code> <code class="o">&gt;=</code> <code class="mi">2</code><code class="p">,</code> <code class="s2">"variance requires at least two elements"</code>&#13;
&#13;
    <code class="n">n</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code>&#13;
    <code class="n">deviations</code> <code class="o">=</code> <code class="n">de_mean</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code>&#13;
    <code class="k">return</code> <code class="n">sum_of_squares</code><code class="p">(</code><code class="n">deviations</code><code class="p">)</code> <code class="o">/</code> <code class="p">(</code><code class="n">n</code> <code class="o">-</code> <code class="mi">1</code><code class="p">)</code>&#13;
&#13;
<code class="k">assert</code> <code class="mf">81.54</code> <code class="o">&lt;</code> <code class="n">variance</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mf">81.55</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>This looks like it is almost the average squared deviation from the mean, except that we’re dividing by <code>n - 1</code> instead of <code>n</code>.&#13;
In fact, when we’re dealing with a sample from a larger population,&#13;
<code>x_bar</code> is only an <em>estimate</em> of the actual mean,&#13;
which means that on average <code>(x_i - x_bar) ** 2</code> is an underestimate of&#13;
<code>x_i</code>’s squared deviation from the mean, which is why we divide by <code>n - 1</code> instead of <code>n</code>. See <a href="https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation">Wikipedia</a>.</p>&#13;
</div>&#13;
&#13;
<p>Now, whatever units our data is in (e.g., “friends”), all of our measures of central tendency are in that same unit.  The range will similarly be in that same unit.  The variance, on the other hand, has units that are the <em>square</em> of the original units (e.g., “friends squared”).  As it can be hard to make sense of these, we often look<a data-primary="data" data-secondary="describing single sets of" data-tertiary="standard deviation" data-type="indexterm" id="idm45635757354248"/><a data-primary="standard deviation" data-type="indexterm" id="idm45635757353032"/> instead at the <em>standard deviation</em>:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">import</code> <code class="nn">math</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">standard_deviation</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""The standard deviation is the square root of the variance"""</code>&#13;
    <code class="k">return</code> <code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">variance</code><code class="p">(</code><code class="n">xs</code><code class="p">))</code>&#13;
&#13;
<code class="k">assert</code> <code class="mf">9.02</code> <code class="o">&lt;</code> <code class="n">standard_deviation</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mf">9.04</code></pre>&#13;
&#13;
<p>Both the range and the standard deviation have the same outlier problem that we saw earlier for the mean.  Using the same example, if our friendliest user had instead 200 friends, the standard deviation would be 14.89—more than 60% higher!</p>&#13;
&#13;
<p>A more robust alternative computes the difference between the 75th percentile value and the 25th percentile value:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">interquartile_range</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""Returns the difference between the 75%-ile and the 25%-ile"""</code>&#13;
    <code class="k">return</code> <code class="n">quantile</code><code class="p">(</code><code class="n">xs</code><code class="p">,</code> <code class="mf">0.75</code><code class="p">)</code> <code class="o">-</code> <code class="n">quantile</code><code class="p">(</code><code class="n">xs</code><code class="p">,</code> <code class="mf">0.25</code><code class="p">)</code>&#13;
&#13;
<code class="k">assert</code> <code class="n">interquartile_range</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code> <code class="o">==</code> <code class="mi">6</code></pre>&#13;
&#13;
<p>which is quite plainly unaffected by a small number of outliers.<a data-primary="" data-startref="Ssingle05" data-type="indexterm" id="idm45635757245784"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Correlation" data-type="sect1"><div class="sect1" id="correlation">&#13;
<h1>Correlation</h1>&#13;
&#13;
<p>DataSciencester’s VP of Growth<a data-primary="statistics" data-secondary="correlation" data-type="indexterm" id="Scor05"/><a data-primary="correlation" data-type="indexterm" id="cor05"/> has a theory that the amount of time people spend on the site is related to the number of friends they have on the site (she’s not a VP for nothing), and she’s asked you to verify this.</p>&#13;
&#13;
<p>After digging through traffic logs, you’ve come up with a list called <code>daily_minutes</code> that shows how many minutes per day each user spends on DataSciencester, and you’ve ordered it so that its elements correspond to the elements of our previous <code>num_friends</code> list.  We’d like to investigate the relationship between these two metrics.</p>&#13;
&#13;
<p>We’ll<a data-primary="covariance" data-type="indexterm" id="idm45635757218776"/> first look at <em>covariance</em>, the paired analogue of variance.  Whereas variance measures how a single variable deviates from its mean, covariance measures how two variables vary in tandem from their means:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="kn">from</code> <code class="nn">scratch.linear_algebra</code> <code class="kn">import</code> <code class="n">dot</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">covariance</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">],</code> <code class="n">ys</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="k">assert</code> <code class="nb">len</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code> <code class="o">==</code> <code class="nb">len</code><code class="p">(</code><code class="n">ys</code><code class="p">),</code> <code class="s2">"xs and ys must have same number of elements"</code>&#13;
&#13;
    <code class="k">return</code> <code class="n">dot</code><code class="p">(</code><code class="n">de_mean</code><code class="p">(</code><code class="n">xs</code><code class="p">),</code> <code class="n">de_mean</code><code class="p">(</code><code class="n">ys</code><code class="p">))</code> <code class="o">/</code> <code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code> <code class="o">-</code> <code class="mi">1</code><code class="p">)</code>&#13;
&#13;
<code class="k">assert</code> <code class="mf">22.42</code> <code class="o">&lt;</code> <code class="n">covariance</code><code class="p">(</code><code class="n">num_friends</code><code class="p">,</code> <code class="n">daily_minutes</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mf">22.43</code>&#13;
<code class="k">assert</code> <code class="mf">22.42</code> <code class="o">/</code> <code class="mi">60</code> <code class="o">&lt;</code> <code class="n">covariance</code><code class="p">(</code><code class="n">num_friends</code><code class="p">,</code> <code class="n">daily_hours</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mf">22.43</code> <code class="o">/</code> <code class="mi">60</code></pre>&#13;
&#13;
<p>Recall that <code>dot</code> sums up the products of corresponding pairs of elements.  When corresponding elements of <code>x</code> and <code>y</code> are either both above their means or both below their means, a positive number enters the sum.  When one is above its mean and the other below, a negative number enters the sum.  Accordingly, a “large” positive covariance means that <code>x</code> tends to be large when <code>y</code> is large and small when <code>y</code> is small.  A “large” negative covariance means the opposite—that <code>x</code> tends to be small when <code>y</code> is large and vice versa.  A covariance close to zero means that no such relationship exists.</p>&#13;
&#13;
<p>Nonetheless, this number can be hard to interpret, for a couple of reasons:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Its units are the product of the inputs’ units (e.g., friend-minutes-per-day), which can be hard to make sense of.  (What’s a “friend-minute-per-day”?)</p>&#13;
</li>&#13;
<li>&#13;
<p>If each user had twice as many friends (but the same number of minutes), the covariance would be twice as large.  But in a sense, the variables would be just as interrelated.  Said differently, it’s hard to say what counts as a “large” covariance.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>For this reason, it’s more common to look at the <em>correlation</em>, which divides out the standard deviations of both variables:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="k">def</code> <code class="nf">correlation</code><code class="p">(</code><code class="n">xs</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">],</code> <code class="n">ys</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">float</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="nb">float</code><code class="p">:</code>&#13;
    <code class="sd">"""Measures how much xs and ys vary in tandem about their means"""</code>&#13;
    <code class="n">stdev_x</code> <code class="o">=</code> <code class="n">standard_deviation</code><code class="p">(</code><code class="n">xs</code><code class="p">)</code>&#13;
    <code class="n">stdev_y</code> <code class="o">=</code> <code class="n">standard_deviation</code><code class="p">(</code><code class="n">ys</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="n">stdev_x</code> <code class="o">&gt;</code> <code class="mi">0</code> <code class="ow">and</code> <code class="n">stdev_y</code> <code class="o">&gt;</code> <code class="mi">0</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="n">covariance</code><code class="p">(</code><code class="n">xs</code><code class="p">,</code> <code class="n">ys</code><code class="p">)</code> <code class="o">/</code> <code class="n">stdev_x</code> <code class="o">/</code> <code class="n">stdev_y</code>&#13;
    <code class="k">else</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="mi">0</code>    <code class="c1"># if no variation, correlation is zero</code>&#13;
&#13;
<code class="k">assert</code> <code class="mf">0.24</code> <code class="o">&lt;</code> <code class="n">correlation</code><code class="p">(</code><code class="n">num_friends</code><code class="p">,</code> <code class="n">daily_minutes</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mf">0.25</code>&#13;
<code class="k">assert</code> <code class="mf">0.24</code> <code class="o">&lt;</code> <code class="n">correlation</code><code class="p">(</code><code class="n">num_friends</code><code class="p">,</code> <code class="n">daily_hours</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mf">0.25</code></pre>&#13;
&#13;
<p>The <code>correlation</code> is unitless and always lies between –1 (perfect anticorrelation) and 1 (perfect correlation).  A number like 0.25 represents a relatively weak positive correlation.</p>&#13;
&#13;
<p>However, one thing we neglected to do was examine our data. Check out <a data-type="xref" href="#correlation_outlier">Figure 5-2</a>.</p>&#13;
&#13;
<figure><div class="figure" id="correlation_outlier">&#13;
<img alt="Correlation outlier." src="assets/dsf2_0502.png"/>&#13;
<h6><span class="label">Figure 5-2. </span>Correlation with an outlier</h6>&#13;
</div></figure>&#13;
&#13;
<p>The person with 100 friends (who spends only 1 minute per day on the site) is a huge outlier, and correlation can be very sensitive to outliers.  What happens if we ignore him?</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">outlier</code> <code class="o">=</code> <code class="n">num_friends</code><code class="o">.</code><code class="n">index</code><code class="p">(</code><code class="mi">100</code><code class="p">)</code>    <code class="c1"># index of outlier</code>&#13;
&#13;
<code class="n">num_friends_good</code> <code class="o">=</code> <code class="p">[</code><code class="n">x</code>&#13;
                    <code class="k">for</code> <code class="n">i</code><code class="p">,</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">num_friends</code><code class="p">)</code>&#13;
                    <code class="k">if</code> <code class="n">i</code> <code class="o">!=</code> <code class="n">outlier</code><code class="p">]</code>&#13;
&#13;
<code class="n">daily_minutes_good</code> <code class="o">=</code> <code class="p">[</code><code class="n">x</code>&#13;
                      <code class="k">for</code> <code class="n">i</code><code class="p">,</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">daily_minutes</code><code class="p">)</code>&#13;
                      <code class="k">if</code> <code class="n">i</code> <code class="o">!=</code> <code class="n">outlier</code><code class="p">]</code>&#13;
&#13;
<code class="n">daily_hours_good</code> <code class="o">=</code> <code class="p">[</code><code class="n">dm</code> <code class="o">/</code> <code class="mi">60</code> <code class="k">for</code> <code class="n">dm</code> <code class="ow">in</code> <code class="n">daily_minutes_good</code><code class="p">]</code>&#13;
&#13;
<code class="k">assert</code> <code class="mf">0.57</code> <code class="o">&lt;</code> <code class="n">correlation</code><code class="p">(</code><code class="n">num_friends_good</code><code class="p">,</code> <code class="n">daily_minutes_good</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mf">0.58</code>&#13;
<code class="k">assert</code> <code class="mf">0.57</code> <code class="o">&lt;</code> <code class="n">correlation</code><code class="p">(</code><code class="n">num_friends_good</code><code class="p">,</code> <code class="n">daily_hours_good</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mf">0.58</code></pre>&#13;
&#13;
<p>Without the outlier, there is a much stronger correlation (<a data-type="xref" href="#correlation_no_outliers">Figure 5-3</a>).</p>&#13;
&#13;
<figure><div class="figure" id="correlation_no_outliers">&#13;
<img alt="Correlation no outlier." src="assets/dsf2_0503.png"/>&#13;
<h6><span class="label">Figure 5-3. </span>Correlation after removing the outlier</h6>&#13;
</div></figure>&#13;
&#13;
<p>You investigate further and discover that the outlier was actually an internal <em>test</em> account&#13;
that no one ever bothered to remove.  So you feel justified in excluding it.<a data-primary="" data-startref="Scor05" data-type="indexterm" id="idm45635756843240"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Simpson’s Paradox" data-type="sect1"><div class="sect1" id="idm45635757224344">&#13;
<h1>Simpson’s Paradox</h1>&#13;
&#13;
<p>One<a data-primary="statistics" data-secondary="correlation" data-tertiary="Simpson's paradox" data-type="indexterm" id="idm45635756840472"/><a data-primary="Simpson's paradox" data-type="indexterm" id="idm45635756839192"/> not uncommon surprise when analyzing data is <em>Simpson’s paradox</em>, in which correlations can<a data-primary="variables" data-secondary="confounding variables" data-type="indexterm" id="idm45635756838008"/><a data-primary="confounding variables" data-type="indexterm" id="idm45635756837032"/> be misleading when <em>confounding</em> variables are ignored.</p>&#13;
&#13;
<p>For example, imagine that you can identify all of your members as either East Coast data scientists or West Coast data scientists.  You decide to examine which coast’s data scientists are friendlier:</p>&#13;
<table>&#13;
&#13;
<thead>&#13;
<tr>&#13;
<th>Coast</th>&#13;
<th># of members</th>&#13;
<th>Avg. # of friends</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>West Coast</p></td>&#13;
<td><p>101</p></td>&#13;
<td><p>8.2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>East Coast</p></td>&#13;
<td><p>103</p></td>&#13;
<td><p>6.5</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>It certainly looks like the West Coast data scientists are friendlier than the East Coast data scientists. Your coworkers advance all sorts of theories as to why this might be: maybe it’s the sun, or the coffee, or the organic produce, or the laid-back Pacific vibe?</p>&#13;
&#13;
<p>But when playing with the data, you discover something very strange.  If you look only at people with PhDs, the East Coast data scientists have more friends on average.  And if you look only at people without PhDs, the East Coast data scientists also have more friends on average!</p>&#13;
<table>&#13;
&#13;
<thead>&#13;
<tr>&#13;
<th>Coast</th>&#13;
<th>Degree</th>&#13;
<th># of members</th>&#13;
<th>Avg. # of friends</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>West Coast</p></td>&#13;
<td><p>PhD</p></td>&#13;
<td><p>35</p></td>&#13;
<td><p>3.1</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>East Coast</p></td>&#13;
<td><p>PhD</p></td>&#13;
<td><p>70</p></td>&#13;
<td><p>3.2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>West Coast</p></td>&#13;
<td><p>No PhD</p></td>&#13;
<td><p>66</p></td>&#13;
<td><p>10.9</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>East Coast</p></td>&#13;
<td><p>No PhD</p></td>&#13;
<td><p>33</p></td>&#13;
<td><p>13.4</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Once you account for the users’ degrees, the correlation goes in the opposite direction!  Bucketing the data as East Coast/West Coast disguised the fact that the East Coast data scientists skew much more heavily toward PhD types.</p>&#13;
&#13;
<p>This phenomenon crops up in the real world with some regularity.  The key issue is that correlation is measuring the relationship between your two variables <em>all else being equal</em>.  If your dataclasses are assigned at random, as they might be in a well-designed experiment, “all else being equal” might not be a terrible assumption.  But when there is a deeper pattern to class assignments, “all else being equal” can be an awful assumption.</p>&#13;
&#13;
<p>The only real way to avoid this is by <em>knowing your data</em> and by doing what you can to make sure you’ve checked for possible confounding factors.  Obviously, this is not always possible.  If you didn’t have data on the educational attainment of these 200 data scientists, you might simply conclude that there was something inherently more sociable about the West Coast.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Some Other Correlational Caveats" data-type="sect1"><div class="sect1" id="idm45635756841672">&#13;
<h1>Some Other Correlational Caveats</h1>&#13;
&#13;
<p>A<a data-primary="statistics" data-secondary="correlation" data-tertiary="correlational caveats" data-type="indexterm" id="idm45635756807048"/> correlation of zero indicates that there is no linear relationship between the two variables.  However, there may be other sorts of relationships.  For example, if:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">x</code> <code class="o">=</code> <code class="p">[</code><code class="o">-</code><code class="mi">2</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">]</code>&#13;
<code class="n">y</code> <code class="o">=</code> <code class="p">[</code> <code class="mi">2</code><code class="p">,</code>  <code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">]</code></pre>&#13;
&#13;
<p>then <code>x</code> and <code>y</code> have zero correlation.  But they certainly have a relationship—each element of <code>y</code> equals the absolute value of the corresponding element of <code>x</code>.  What they don’t have is a relationship in which knowing how <code>x_i</code> compares to <code>mean(x)</code> gives us information about how <code>y_i</code> compares to <code>mean(y)</code>.  That is the sort of relationship that correlation looks for.</p>&#13;
&#13;
<p>In addition, correlation tells you nothing about how large the relationship is.  The variables:</p>&#13;
&#13;
<pre data-code-language="py" data-type="programlisting"><code class="n">x</code> <code class="o">=</code> <code class="p">[</code><code class="o">-</code><code class="mi">2</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">]</code>&#13;
<code class="n">y</code> <code class="o">=</code> <code class="p">[</code><code class="mf">99.98</code><code class="p">,</code> <code class="mf">99.99</code><code class="p">,</code> <code class="mi">100</code><code class="p">,</code> <code class="mf">100.01</code><code class="p">,</code> <code class="mf">100.02</code><code class="p">]</code></pre>&#13;
&#13;
<p>are perfectly correlated, but (depending on what you’re measuring)&#13;
it’s quite possible that this relationship isn’t all that interesting.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Correlation and Causation" data-type="sect1"><div class="sect1" id="idm45635756688408">&#13;
<h1>Correlation and Causation</h1>&#13;
&#13;
<p>You<a data-primary="statistics" data-secondary="correlation" data-tertiary="causation and" data-type="indexterm" id="idm45635756686936"/><a data-primary="causation" data-type="indexterm" id="idm45635756685656"/> have probably heard at some point that “correlation is not causation,”&#13;
most likely from someone looking at data that posed a challenge to parts of his worldview&#13;
that he was reluctant to question.&#13;
Nonetheless, this is an important point—if <code>x</code> and <code>y</code> are strongly correlated,&#13;
that might mean that <code>x</code> causes <code>y</code>,&#13;
that <code>y</code> causes <code>x</code>,&#13;
that each causes the other,&#13;
that some third factor causes both,&#13;
or nothing at all.</p>&#13;
&#13;
<p>Consider the relationship between <code>num_friends</code> and <code>daily_minutes</code>. It’s possible that having more friends on the site&#13;
<em>causes</em> DataSciencester users to spend more time on the site.&#13;
This might be the case if each friend posts a certain amount of content each day,&#13;
which means that the more friends you have,&#13;
the more time it takes to stay current with their updates.</p>&#13;
&#13;
<p>However, it’s also possible that&#13;
the more time users spend arguing in the DataSciencester forums,&#13;
the more they encounter and befriend like-minded people.  That is,&#13;
spending more time on the site <em>causes</em> users to have more friends.</p>&#13;
&#13;
<p>A third possibility is that the users who are most passionate about data science&#13;
spend more time on the site (because they find it more interesting)&#13;
and more actively collect data science friends&#13;
(because they don’t want to associate with anyone else).</p>&#13;
&#13;
<p>One way to feel more confident about causality is by conducting randomized trials.  If you can randomly split your users into two groups with similar demographics and give one of the groups a slightly different experience, then you can often feel pretty good that the different experiences are causing the different outcomes.</p>&#13;
&#13;
<p>For instance, if you don’t mind being angrily accused of <a href="https://www.nytimes.com/2014/06/30/technology/facebook-tinkers-with-users-emotions-in-news-feed-experiment-stirring-outcry.html?"><em class="hyperlink">https://www.nytimes.com/2014/06/30/technology/facebook-tinkers-with-users-emotions-in-news-feed-experiment-stirring-outcry.html?</em></a><em>r=0[experimenting on your users], you could randomly choose a subset of your users and show them content from only a fraction of their friends.  If this subset subsequently spent less time on the site, this would give you some confidence that having more friends _causes</em> more time to be spent on the site.<a data-primary="" data-startref="cor05" data-type="indexterm" id="idm45635756675256"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="For Further Exploration" data-type="sect1"><div class="sect1" id="idm45635756674184">&#13;
<h1>For Further Exploration</h1>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><a href="https://www.scipy.org/">SciPy</a>, <a href="http://pandas.pydata.org">pandas</a>, and <a href="http://www.statsmodels.org/">StatsModels</a> all<a data-primary="SciPy" data-type="indexterm" id="idm45635756670088"/><a data-primary="pandas" data-type="indexterm" id="idm45635756669352"/><a data-primary="StatsModels" data-type="indexterm" id="idm45635756668680"/><a data-primary="statistics" data-secondary="tools for" data-type="indexterm" id="idm45635756668008"/> come with a wide variety of statistical functions.</p>&#13;
</li>&#13;
<li>&#13;
<p>Statistics<a data-primary="statistics" data-secondary="resources for learning" data-type="indexterm" id="idm45635756666168"/> is <em>important</em>.  (Or maybe statistics <em>are</em> important?) If you want to be a better data scientist,&#13;
it would be a good idea to read a statistics textbook. Many are freely available online, including:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><a href="https://open.umn.edu/opentextbooks/textbooks/introductory-statistics"><em>Introductory Statistics</em></a>, by Douglas Shafer and Zhiyi Zhang (Saylor Foundation)</p>&#13;
</li>&#13;
<li>&#13;
<p><a href="http://onlinestatbook.com/"><em>OnlineStatBook</em></a>, by David Lane (Rice University)</p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://openstax.org/details/introductory-statistics"><em>Introductory Statistics</em></a>, by OpenStax (OpenStax College)<a data-primary="" data-startref="Mstat05" data-type="indexterm" id="idm45635756627496"/></p>&#13;
</li>&#13;
</ul>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>