<html><head></head><body><section data-pdf-bookmark="Chapter 2. Questions and Data Scope" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch-data-scope">&#13;
<h1><span class="label">Chapter 2. </span>Questions and Data Scope</h1>&#13;
&#13;
<p>As data scientists, we use data to answer questions<a contenteditable="false" data-primary="lifecycle, data science" data-secondary="questions and data scope" data-type="indexterm" id="ix_lifecycle_data_sci_q_s"/><a contenteditable="false" data-primary="question, purpose in data science lifecycle" data-type="indexterm" id="id635"/>, and the quality of the data collection process can significantly impact the validity and accuracy of the data, the strength of the conclusions we draw from an analysis, and the decisions we make. In this chapter, we describe a general approach for understanding data collection and evaluating the usefulness of the data in addressing the question of interest. Ideally, we aim for data to be representative of the phenomenon that we are studying, whether that phenomenon is a population characteristic, a physical model, or some type of social behavior. Typically, our data do not contain complete information (the scope is restricted in some way), yet we want to use the data to accurately describe a population, estimate a scientific quantity, infer the form of a relationship between features, or predict future outcomes. In all of these situations, if our data are not representative of the object of our study, then our conclusions can be limited, possibly misleading, or even wrong.</p>&#13;
&#13;
<p>To motivate the need to think about these issues, we begin with an example of the power of big data and what can go wrong. We then provide a framework that can help you connect the goal of your study (your question) with the data collection process. We refer<a contenteditable="false" data-primary="data scope" data-type="indexterm" id="ix_data_scope_ch2"/> to this as the <em>data scope</em>,<sup><a data-type="noteref" href="ch02.html#id636" id="id636-marker">1</a></sup> and we provide terminology to help describe data scope, along with examples from surveys, government data, scientific instruments, and online resources. Later in this chapter, we consider what it means for data to be accurate. There, we introduce different forms of bias and variation, and describe situations where they can arise. Throughout, the examples cover the spectrum of the sorts of data that you may be using as a data scientist; these examples are from science, politics, public health, and online communities.</p>&#13;
&#13;
<section data-pdf-bookmark="Big Data and New Opportunities" data-type="sect1"><div class="sect1" id="sec-scope-bigdata">&#13;
<h1>Big Data and New Opportunities</h1>&#13;
&#13;
<p>The tremendous<a contenteditable="false" data-primary="big data considerations" data-secondary="question and scope example" data-type="indexterm" id="ix_big_data_ch2"/> increase in openly available data has created new roles and opportunities in data science. For example, data journalists look for interesting stories in data much like how traditional beat reporters hunt for news stories. The lifecycle for the data journalist begins with the search for existing data that might have an interesting story, rather than beginning with a research question and figuring out how to collect new or use existing data to address the question.</p>&#13;
&#13;
<p>Citizen science projects are another example. They engage many people (and instruments) in data collection. Collectively, these data are made available to researchers who organize the project, and often they are made available in repositories for the general public to further investigate.</p>&#13;
&#13;
<p>The availability of administrative and organizational data creates other opportunities. Researchers can link data collected from scientific studies with, say, medical data that have been collected for health-care purposes; these administrative data have been collected for reasons that don’t directly stem from the question of interest, but they can be useful in other settings. Such linkages can help data scientists expand the possibilities of their analyses and cross-check the quality of their data. In addition, found data can include digital traces, such as your web-browsing activity, your posts on social media, and your online network of friends and acquaintances, and they can be quite complex.</p>&#13;
&#13;
<p>When we have large amounts of administrative data or expansive digital traces, it can be tempting to treat them as more definitive than data collected from traditional, smaller research studies. We might even consider these large datasets to be a replacement for scientific studies and essentially a census. This overreach is referred to as <a class="reference external" href="https://doi.org/10.1126/science.1248506">“big data hubris”</a>. Data with a large scope does not mean that we can ignore foundational issues of how representative the data are, nor can we ignore issues with measurement, dependency, and reliability. (And it can be easy to discover meaningless or nonsensical relationships just by coincidence.) One well-known example is the Google Flu Trends tracking system.</p>&#13;
&#13;
<section data-pdf-bookmark="Example: Google Flu Trends" data-type="sect2"><div class="sect2" id="example-google-flu-trends">&#13;
<h2>Example: Google Flu Trends</h2>&#13;
&#13;
<p><a class="reference external" href="https://oreil.ly/i2PVM">Digital epidemiology</a>, a new subfield of epidemiology, leverages data generated outside the public health system to study patterns of disease and health dynamics in populations. The Google<a contenteditable="false" data-primary="lifecycle, data science" data-secondary="Google Flu Trends example" data-type="indexterm" id="ix_google_flu"/><a contenteditable="false" data-primary="GFT (Google Flu Trends) big data example" data-type="indexterm" id="id637"/><a contenteditable="false" data-primary="Google Flu Trends (GFT) big data example" data-type="indexterm" id="id638"/> Flu Trends (GFT) tracking system was one of the earliest examples of digital epidemiology. In 2007, researchers found that counting the searches people made for flu-related terms could accurately estimate the number of flu cases. This apparent success made headlines, and many researchers became excited about the possibilities of big data. However, GFT did not live up to expectations and was abandoned in 2015.</p>&#13;
&#13;
<p>What went wrong? After all, GFT used millions of <a contenteditable="false" data-primary="question, purpose in data science lifecycle" data-type="indexterm" id="id639"/>digital traces from online queries for terms related to influenza to predict flu activity. Despite initial success, in the 2011–2012 flu season, Google’s data scientists found that GFT was not a substitute for the more traditional surveillance reports of three-week-old counts collected by the US Centers for Disease Control and Prevention (CDC) from laboratories across the country. In comparison, GFT overestimated the CDC numbers for 100 out of 108 weeks. Week after week, GFT came in too high for the cases of influenza, even though it was based on big data:</p>&#13;
&#13;
<figure class="informal"><div class="figure"><img src="assets/leds_02in01.png"/></div></figure>&#13;
&#13;
<p>From weeks 412 to 519 in this plot, GFT (solid line) overestimated the actual CDC reports (dashed line) 100 times. Also plotted here are predictions from a model based on three-week-old CDC data and seasonal trends (dotted line), which follows the actuals more closely than GFT.</p>&#13;
&#13;
<p>Data scientists found that a simple model built from past CDC reports that used three-week-old CDC data and seasonal trends did a better job of predicting flu prevalence than GFT. GFT overlooked considerable information that can be extracted by basic statistical methods. This does not mean that big data captured from online activity is useless. In fact, <a class="reference external" href="https://oreil.ly/Qlw6u">researchers have shown</a> that the combination of GFT data with CDC data can substantially improve both GFT predictions and the CDC-based model. It is often the case that combining different approaches leads to improvements over individual methods.</p>&#13;
&#13;
<p>The GFT example shows us that even when we have tremendous amounts of information, the connections between the data and the question being asked are paramount. Understanding this framework can help us avoid answering the wrong question, applying inappropriate methods to the data, and overstating our findings.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>In the age of big data, we are tempted to collect more and more data to answer a question precisely. After all, a census gives us perfect information, so shouldn’t big data be nearly perfect? Unfortunately, this is often not the case, especially with administrative data and digital traces. The inaccessibility of a small fraction of the people you want to study (see the 2016 election upset in <a class="reference internal" data-type="xref" href="ch03.html#ch-theory-datadesign">Chapter 3</a>) or the measurement process itself (as in this GFT example) can lead to poor predictions. It is important to consider the scope of the data as it relates to the question under investigation.</p>&#13;
</div>&#13;
&#13;
<p>A key factor to keep in mind is the scope of the data. Scope includes considering the population we want to study, how to access information about that population, and what we are actually measuring. Thinking through these points can help us see potential gaps in our approach. We investigate this in the next section.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Target Population, Access Frame, and Sample" data-type="sect1"><div class="sect1" id="sec-scope-construct">&#13;
<h1>Target Population, Access Frame, and Sample</h1>&#13;
&#13;
<p>An <a contenteditable="false" data-primary="populations" data-type="indexterm" id="id640"/><a contenteditable="false" data-primary="samples and sampling" data-type="indexterm" id="id641"/><a contenteditable="false" data-primary="target population" data-seealso="populations" data-type="indexterm" id="id642"/><a contenteditable="false" data-primary="access frame" data-type="indexterm" id="ix_access_frame_ch2"/><a contenteditable="false" data-primary="lifecycle, data science" data-secondary="target population, access frame, sample" data-type="indexterm" id="ix_lifecycle_data_sci_pop"/>important<a contenteditable="false" data-primary="target, access, sample framework" data-type="indexterm" id="ix_targ_acc_sam_fw"/> initial step in the data lifecycle is to express the question of interest in the context of the subject area and consider the connection between the question and the data collected to answer that question. It’s a good practice to do this before even thinking about the analysis or modeling steps because it may uncover a disconnect where the question of interest cannot be directly addressed by the data. As part of making the connection between the data collection process and the topic of investigation, we identify the population, the means to access the population, instruments of measurement, and additional protocols used in the collection process. These concepts⁠—​the target population, the access frame, and the sample—help us understand the scope of the data, whether we aim to gain knowledge about a population, scientific quantity, physical model, social behavior, or something else:</p>&#13;
&#13;
<dl class="simple myst">&#13;
	<dt>Target population</dt>&#13;
	<dd>&#13;
	<p>The <em>target population</em> consists of the collection of elements comprising the population that you ultimately intend to describe and draw conclusions about. The element may be a person in a group of people, a voter in an election, a tweet from a collection of tweets, or a county in a state. We sometimes call an element a <em>unit</em> or an <em>atom</em>.</p>&#13;
	</dd>&#13;
	<dt>Access frame</dt>&#13;
	<dd>&#13;
	<p>The <em>access frame</em> is the collection of elements that are accessible to you for measurement and observation. These are the units through which you can study the target population. Ideally, the access frame and population are perfectly aligned, meaning they consist of the exact same elements. However, the units in an access frame may be only a subset of the target population; additionally, the frame may include units that don’t belong to the population. For example, to find out how a voter intends to vote in an election, you might call people by phone. Someone you call may not be a voter, so they are in your frame but not in the population. On the other hand, a voter who never answers a call from an unknown number can’t be reached, so they are in the population but not in your frame.</p>&#13;
	</dd>&#13;
	<dt>Sample</dt>&#13;
	<dd>&#13;
	<p>The <em>sample</em> is the subset of units taken from the access frame to observe and measure. The sample gives you the data to analyze in order to make predictions or generalizations about the population of interest. When resources have been put into following up with nonrespondents and tracking down hard-to-find units, a small sample can be more effective than a large sample or an attempt at a census where subsets of the population have been overlooked.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>The contents of the access frame, in comparison to the target population, and the method used to select units from the frame to be in the sample are important factors in determining whether or not the data can be considered representative of the target population. If the access frame is not representative of the target population, then the data from the sample is most likely not representative either. And if the units are sampled in a biased manner, problems with representativeness also arise.</p>&#13;
&#13;
<p>You will also want to consider time and place in the data scope<a contenteditable="false" data-primary="data scope" data-secondary="role in data analysis" data-type="indexterm" id="id643"/>. For example, the effectiveness of a drug trial tested in one part of the world where a disease is raging might not compare favorably with a trial in a different part of the world where background infection rates are lower (see <a class="reference internal" data-type="xref" href="ch03.html#ch-theory-datadesign">Chapter 3</a>). Additionally, data collected for the purpose of studying changes over time, like with the monthly measurements of carbon dioxide (CO<sub>2</sub>) in the atmosphere (see <a class="reference internal" data-type="xref" href="ch09.html#ch-wrangling">Chapter 9</a>) and the weekly reporting of Google<a contenteditable="false" data-primary="spatial data patterns" data-type="indexterm" id="id644"/><a contenteditable="false" data-primary="temporal structure of data" data-type="indexterm" id="id645"/> searches for predicting flu trends, have a <em>temporal</em> structure that we need to be mindful of as we examine the data. At other times, there might be <em>spatial</em> patterns in the data. For example, the environmental health data, described later in this section, are reported for each census tract in the State of California, and we might make maps to look for spatial correlations.</p>&#13;
&#13;
<p>And if you didn’t collect the data, you will want to consider who did and for what purpose. This is especially relevant now since more data is passively collected instead of collected with a specific goal in mind. Taking a hard look at found data and asking yourself whether and how these data might be used to address your question can save you from making a fruitless analysis or drawing inappropriate conclusions.</p>&#13;
&#13;
<p>For the examples in the following subsections, we begin with a general question, narrow it to one that can be answered with data, and in doing so, identify the target population, access frame, and sample. These concepts are represented by circles and rectangles in diagrams, and the configuration of the overlap of these shapes helps reveal key aspects of the scope. Also in each example, we describe relevant temporal and spatial features of the data scope.</p>&#13;
&#13;
<section data-pdf-bookmark="Example: What Makes Members of an Online Community Active?" data-type="sect2"><div class="sect2" id="id10">&#13;
	<h2>Example: What Makes Members of an Online Community Active?</h2>&#13;
&#13;
<p>Content on Wikipedia<a contenteditable="false" data-primary="online community active levels" data-type="indexterm" id="id646"/> is written and edited by volunteers who belong to the Wikipedia community. This online community is crucial to the success and vitality of Wikipedia. In trying to understand how to incentivize members of online communities, <a class="reference external" href="https://oreil.ly/j74rl">researchers</a> carried out an experiment with Wikipedia contributors as subjects. A narrowed version of the general question asks: do awards increase the activity of Wikipedia contributors? For this experiment, the target population<a contenteditable="false" data-primary="populations" data-type="indexterm" id="id647"/> is the collection of top, active contributors—the 1% most active contributors to Wikipedia in the month before the start of the study. The access frame eliminated anyone in the population who had received an incentive (award) that month. The access frame purposely excluded some of the contributors in the population because the researchers wanted to measure the impact of an incentive, and those who had already received one incentive might behave differently (see <a class="reference internal" data-type="xref" href="#fig-wikipediaexptconstruct">Figure 2-1</a>).</p>&#13;
&#13;
<figure><div class="figure" id="fig-wikipediaexptconstruct"><img src="assets/leds_0201.png"/>&#13;
<h6><span class="label">Figure 2-1. </span>Representation of scope in the Wikipedia experiment</h6>&#13;
</div></figure>&#13;
&#13;
<p>The sample is a randomly selected set of 200 contributors from the frame. The contributors were observed for 90 days, and digital traces of their activities on Wikipedia were collected. Notice that the contributor population is not static; there is regular turnover. In the month prior to the start of the study, more than 144,000 volunteers produced content for Wikipedia. Selecting top contributors from among this group limits the generalizability of the findings, but given the size of the group of top contributors, if they can be influenced by an informal reward to maintain or increase their contributions, this is still a valuable finding.</p>&#13;
&#13;
<p>In many experiments and studies, we don’t have the ability to include all population units in the frame. It is often the case that the access frame consists of volunteers who are willing to join the study/experiment.</p>&#13;
&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Example: Who Will Win the Election?" data-type="sect2"><div class="sect2" id="id11">&#13;
	<h2>Example: Who Will Win the Election?</h2>&#13;
&#13;
<p>The outcome of the US presidential election<a contenteditable="false" data-primary="predictions and predicting" data-secondary="election outcomes" data-type="indexterm" id="id648"/><a contenteditable="false" data-primary="election outcome prediction" data-type="indexterm" id="id649"/> in 2016 took many people and many pollsters by surprise. Most preelection polls predicted Hillary Clinton would beat Donald Trump. Political polling is a type of public opinion survey held prior to an election that attempts to gauge whom people will vote for. Since opinions change over time, the focus is reduced to a “horse race” question, where respondents are asked whom they would vote for in a head-to-head race if the election were tomorrow: candidate A or candidate B.</p>&#13;
&#13;
<p>Polls<a contenteditable="false" data-primary="poll data for elections" data-type="indexterm" id="id650"/> are conducted regularly throughout the presidential campaign, and as election day approaches, we expect the polls to get better at predicting the outcome as preferences stabilize. Polls are also typically conducted statewide and later combined to make predictions for the overall winner. For these reasons, the timing and location of a poll matters. The <a class="reference external" href="https://oreil.ly/iHApH">pollster matters too</a>; some have consistently been closer to the mark than others.</p>&#13;
&#13;
<p>In these preelection surveys, the target population consists of those who will vote in the election, which in this example was the 2016 US presidential election. However, pollsters can only guess at whether someone will vote in the election, so the access frame consists of those deemed to be likely voters (this is usually based on past voting records, but other factors may also be used). And since people are contacted by phone, the access frame is limited to those who have a landline or mobile phone. The sample consists of those people in the frame who are chosen according to a random dialing scheme (see <a class="reference internal" data-type="xref" href="#fig-electionpollconstruct">Figure 2-2</a>).</p>&#13;
&#13;
<figure><div class="figure" id="fig-electionpollconstruct"><img src="assets/leds_0202.png"/>&#13;
<h6><span class="label">Figure 2-2. </span>Representation of scope in the 2016 presidential election survey</h6>&#13;
</div></figure>&#13;
&#13;
<p>In <a class="reference internal" data-type="xref" href="ch03.html#ch-theory-datadesign">Chapter 3</a>, we discuss the impact on the election predictions of people’s unwillingness to answer their phone or participate in the poll.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Example: How Do Environmental Hazards Relate to an Individual’s Health?" data-type="sect2"><div class="sect2" id="id12">&#13;
	<h2>Example: How Do Environmental Hazards Relate <span class="keep-together">to an Individual’s Health?</span></h2>&#13;
&#13;
<p>To address<a contenteditable="false" data-primary="environmental hazards and individual health" data-type="indexterm" id="id651"/><a contenteditable="false" data-primary="health and environmental hazards" data-type="indexterm" id="id652"/> this question, the California Environmental Protection Agency (CalEPA), the California Office of Environmental Health Hazard Assessment (OEHHA), and the public developed the <a class="reference external" href="https://oreil.ly/qeVD0">CalEnviroScreen</a> project. The project studies connections between population health and environmental pollution in California communities using data collected from several sources that include demographic summaries from the US census, health statistics from the California Department of Health Care Access and Information, and pollution measurements from air monitoring stations around the state maintained by the California Air Resources Board.</p>&#13;
&#13;
<p>Ideally, we want to study the people of California and assess the impact of these environmental hazards on an individual’s health. However, in this situation, the data can only be obtained at the level of a census tract. The access frame consists of groups of residents living in the same census tract. So the units in the frame are census tracts and the sample is a census—all of the tracts—since data are provided for all of the tracts in the state (see <a class="reference internal" data-type="xref" href="#fig-calenviroconstruct">Figure 2-3</a>).</p>&#13;
&#13;
<figure><div class="figure" id="fig-calenviroconstruct"><img src="assets/leds_0203.png"/>&#13;
<h6><span class="label">Figure 2-3. </span>Scope of the CalEnviroScreen project; the grid in the access frame represents the census tracts</h6>&#13;
</div></figure>&#13;
&#13;
<p>Unfortunately, we cannot disaggregate the information in a tract to examine an individual person. This aggregation impacts the questions we can address and the conclusions that we can draw. For example, we can ask questions about the relation between rates of hospitalizations due to asthma and air quality in California communities. But we can’t answer the original question posed about an individual’s health.</p>&#13;
&#13;
<p>These examples<a contenteditable="false" data-primary="process of data collection, and data quality" data-type="indexterm" id="id653"/> have demonstrated possible configurations for a target, access frame, and sample. When a frame doesn’t reach everyone, we should consider how this missing information might impact our findings. Similarly, we ask what might happen when a frame includes those not in the population. Additionally, the techniques for drawing the sample can affect how representative the sample is of the population. When you think about generalizing your data findings, you also want to consider the quality of the instruments and procedures used to collect the data. If your sample is a census that matches your target, but the information is poorly collected, then your findings will be of little value. This is the topic of the next section.<a contenteditable="false" data-startref="ix_access_frame_ch2" data-type="indexterm" id="id654"/><a contenteditable="false" data-primary="" data-startref="ix_lifecycle_data_sci_pop" data-type="indexterm" id="id655"/><a contenteditable="false" data-primary="" data-startref="ix_targ_acc_sam_fw" data-type="indexterm" id="id656"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Instruments and Protocols" data-type="sect1"><div class="sect1" id="sec-scope-protocols">&#13;
<h1>Instruments and Protocols</h1>&#13;
&#13;
<p>When we consider<a contenteditable="false" data-primary="protocol, data collection" data-type="indexterm" id="id657"/><a contenteditable="false" data-primary="instruments for taking measurements, accuracy of" data-type="indexterm" id="id658"/><a contenteditable="false" data-primary="lifecycle, data science" data-secondary="instruments and protocols" data-type="indexterm" id="id659"/> the scope of the data, we also consider the instrument being used to take the measurements and the procedure for taking measurements, which we call the <em>protocol</em>. For a survey, the instrument is typically a questionnaire that an individual in the sample answers. The protocol for a survey includes how the sample is chosen, how nonrespondents are followed up on, interviewer training, protections for confidentiality, and so on.</p>&#13;
&#13;
<p>Good instruments and protocols are important to all kinds of data collection. If we want to measure a natural phenomenon, such as carbon dioxide in the atmosphere, we need to quantify the accuracy of the instrument. The protocol for calibrating the instrument and taking measurements is vital to obtaining accurate measurements. Instruments can go out of alignment and measurements can drift over time, leading to poor, highly inaccurate measurements.</p>&#13;
&#13;
<p>Protocols are also critical in experiments. Ideally, any factor that can influence the outcome of the experiment is controlled. For example, temperature, time of day, confidentiality of a medical record, and even the order in which measurements are taken need to be consistent to rule out potential effects from these factors getting in the way.</p>&#13;
&#13;
<p>With digital traces<a contenteditable="false" data-primary="online community active levels" data-type="indexterm" id="id660"/><a contenteditable="false" data-primary="GFT (Google Flu Trends) big data example" data-type="indexterm" id="id661"/><a contenteditable="false" data-primary="Google Flu Trends (GFT) big data example" data-type="indexterm" id="id662"/>, the algorithms used to support online activity are dynamic and continually reengineered. For example, Google’s search algorithms are continually tweaked to improve user service and advertising revenue. Changes to the search algorithms can impact the data generated from the searches, which in turn impact systems built from these data, such as the Google Flu Trends tracking system. This changing environment can make it untenable to maintain data collection protocols and difficult to replicate findings.</p>&#13;
&#13;
<p>Many data science projects involve linking data together from multiple sources. Each source should be examined through this data-scope construct, and any difference across sources should be considered. Additionally, matching algorithms used to combine data from multiple sources need to be clearly understood so that populations and frames from the sources can be compared.</p>&#13;
&#13;
<p>Measurements from an instrument taken to study a natural phenomenon can be cast in the scope diagram of a target, access frame, and sample. This approach is helpful in understanding the instrument’s accuracy.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Measuring Natural Phenomena" data-type="sect1"><div class="sect1" id="sec-scope-naturalphenomenon">&#13;
<h1>Measuring Natural Phenomena</h1>&#13;
&#13;
<p>The scope diagram<a contenteditable="false" data-primary="parameters" data-type="indexterm" id="ix_params_ch2"/><a contenteditable="false" data-primary="measurement error" data-type="indexterm" id="ix_meas_error"/><a contenteditable="false" data-primary="errors" data-secondary="measurement" data-type="indexterm" id="ix_error_meas"/><a contenteditable="false" data-primary="lifecycle, data science" data-secondary="measuring natural phenomena" data-type="indexterm" id="ix_lifecycle_data_sci_phenom"/> introduced for observing a target population can be extended to the situation where we want to measure a quantity, such as a particle count in the air, the age of a fossil, or the speed of light. In these cases, we consider the quantity we want to measure as an unknown exact value. (This unknown value is often referred to as a <em>parameter</em>.) We can adapt our scope diagram to this setting: we shrink the target to a point that represents the unknown; the instrument’s accuracy acts as the access frame; and the sample consists of the measurements taken by the instrument. You might think of the frame as a dartboard, where the instrument is the person throwing the darts, and the darts land within the circle, scattered around the bullseye. The <span class="keep-together">scatter</span> of darts corresponds to the measurements taken by the instrument. The target point is not seen by the dart thrower, but ideally it coincides with the bullseye.</p>&#13;
&#13;
<p>To illustrate the concept of measurement error and its connection to sampling error, we examine the problem of measuring CO<sub>2</sub> levels in the air.</p>&#13;
&#13;
<section data-pdf-bookmark="Example: What Is the Level of CO2 in the Air?" data-type="sect2"><div class="sect2" id="id15">&#13;
	<h2>Example: What Is the Level of CO<sub>2</sub> in the Air?</h2>&#13;
&#13;
<p>CO<sub>2</sub> is an important signal<a contenteditable="false" data-primary="CO₂ measurements, Mauna Loa Observatory" data-type="indexterm" id="ix_co2_mauna"/> of global warming because it traps heat in the Earth’s atmosphere. Without CO<sub>2</sub>, the Earth would be impossibly cold, but it’s a delicate balance. An increase in CO<sub>2</sub> drives global warming and threatens our planet’s climate. To address this question, CO<sub>2</sub> concentrations have been monitored at <a class="reference external" href="https://oreil.ly/HpqFr">Mauna Loa Observatory</a> since 1958. These data offer a crucial benchmark for understanding the threat of global warming.</p>&#13;
&#13;
<p>When thinking about the scope of the data, we consider the location and time of data collection. Scientists chose to measure CO<sub>2</sub> on the Mauna Loa volcano because they wanted a place where they could measure the background level of CO<sub>2</sub> in the air. Mauna Loa is in the Pacific Ocean, far away from pollution sources, and the observatory is high up on a mountain surrounded by bare lava, away from plants that remove CO<sub>2</sub> from the air.</p>&#13;
&#13;
<p>It’s important that the instrument measuring CO<sub>2</sub> is as accurate as possible. <a class="reference external" href="https://oreil.ly/r_Da9">Rigorous protocols</a> are in place to keep the instrument in top condition. For example, samples of air are routinely measured at Mauna Loa by different types of equipment, and other samples are sent off-site to a laboratory for more accurate measurement. These measurements help determine the accuracy of the instrument. In addition, a reference gas is measured for 5 minutes every hour, and two other reference gases are measured for 15 minutes every day. These reference gases have known CO<sub>2</sub> levels. A comparison of the measured concentrations against the known values helps identify bias in the instrument.</p>&#13;
&#13;
<p>While the CO<sub>2</sub> in background air is relatively steady at Mauna Loa, the five-minute average concentrations that are measured in any hour deviate from the hourly average. These deviations reflect the accuracy of the instrument and variation in airflow.</p>&#13;
&#13;
<p>The scope for data collection can be summarized as follows: at this particular location (high up on Mauna Loa) during a particular one-hour period, there is a true background concentration of CO<sub>2</sub>; this is our target (see <a class="reference internal" data-type="xref" href="#fig-maunaloaconstruct">Figure 2-4</a>). The instrument takes measurements and reports five-minute averages. These readings form a sample contained in the access frame, the dartboard. If the instrument is working properly, the bullseye coincides with the target (the one-hour average concentration of CO<sub>2</sub>) and the measurements are centered on the bullseye, with deviations of about 0.30 parts per million (ppm). The measurement of CO<sub>2</sub> is the number of CO<sub>2</sub> molecules per 1 million molecules of dry air, so the unit of measurement is ppm.</p>&#13;
&#13;
<figure><div class="figure" id="fig-maunaloaconstruct"><img src="assets/leds_0204.png"/>&#13;
<h6><span class="label">Figure 2-4. </span>The access frame represents the accuracy of the instrument; the star represents the true value of interest</h6>&#13;
</div></figure>&#13;
&#13;
<p>We continue the dartboard analogy in the next section to introduce the concepts of bias and variation, describe common ways in which a sample might not be representative of the population, and draw connections between accuracy and protocol.<a contenteditable="false" data-primary="" data-startref="ix_data_scope_ch2" data-type="indexterm" id="id663"/><a contenteditable="false" data-primary="" data-startref="ix_big_data_ch2" data-type="indexterm" id="id664"/><a contenteditable="false" data-primary="" data-startref="ix_google_flu" data-type="indexterm" id="id665"/><a contenteditable="false" data-primary="" data-startref="ix_lifecycle_data_sci_phenom" data-type="indexterm" id="id666"/><a contenteditable="false" data-primary="" data-startref="ix_meas_error" data-type="indexterm" id="id667"/><a contenteditable="false" data-primary="" data-startref="ix_params_ch2" data-type="indexterm" id="id668"/><a contenteditable="false" data-primary="" data-startref="ix_co2_mauna" data-type="indexterm" id="id669"/><a contenteditable="false" data-primary="" data-startref="ix_error_meas" data-type="indexterm" id="id670"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Accuracy" data-type="sect1"><div class="sect1" id="sec-scope-accuracy">&#13;
<h1>Accuracy</h1>&#13;
&#13;
<p>In a census, the access<a contenteditable="false" data-primary="lifecycle, data science" data-secondary="accuracy" data-type="indexterm" id="ix_accur_lifecycle"/><a contenteditable="false" data-primary="accuracy" data-type="indexterm" id="ix_accur_ch2"/> frame matches the population, and the sample captures the entire population. In this situation, if we administer a well-designed questionnaire, then we have complete and accurate information on the population, and the scope is perfect. Similarly, in measuring CO<sub>2</sub> concentrations in the atmosphere, if our instrument has perfect accuracy and is properly used, then we can measure the exact value of the CO<sub>2</sub> concentration (ignoring air fluctuations). These situations are rare, if not impossible. In most settings, we need to quantify the accuracy of our measurements in order to generalize our findings to the unobserved. For example, we often use the sample to estimate an average value for a population, infer the value of a scientific unknown from measurements, or predict the behavior of a new individual. In each of these settings, we also want a quantifiable degree of accuracy. We want to know how close our estimates, inferences, and predictions are to the truth.</p>&#13;
&#13;
<p>The analogy<a contenteditable="false" data-primary="variation" data-type="indexterm" id="id671"/><a contenteditable="false" data-primary="precision metric" data-seealso="variation" data-type="indexterm" id="id672"/> of darts thrown at a dartboard that was introduced earlier can be useful in understanding accuracy. We divide <em>accuracy</em> into two basic parts: <em>bias</em> and <em>precision</em> (also known as <em>variation</em>). Our goal is for the darts to hit the bullseye on the dartboard and for the bullseye to line up with the unseen target. The spray of the darts on the board represents the precision in our measurements, and the gap from the bullseye to the unknown value that we are targeting represents the bias.</p>&#13;
&#13;
<p><a class="reference internal" data-type="xref" href="#fig-scattershot">Figure 2-5</a> shows combinations of low and high bias and precision. In each of these diagrams, the dots represent the measurements taken, and the star represents the true, unknown parameter value. The dots form a scattershot within the access frame, represented by the dartboard. When the bullseye of the access frame is roughly centered on the star (top row), the measurements are scattered around the value of interest and bias is low. The larger dartboards (on the right) indicate a wider spread (lower precision) in the measurements.</p>&#13;
&#13;
<figure><div class="figure" id="fig-scattershot"><img src="assets/leds_0205.png"/>&#13;
<h6><span class="label">Figure 2-5. </span>Combinations of low and high measurement bias and precision</h6>&#13;
</div></figure>&#13;
&#13;
<p>Representative data puts us in the top row of the diagram, where there is low bias, meaning that the unknown target aligns with the bullseye. Ideally, our instruments and protocols put us in the upper-left part of the diagram, where the variation is also low. The pattern of points in the bottom row systematically misses the targeted value. Taking larger samples will not correct this bias.</p>&#13;
&#13;
<section data-pdf-bookmark="Types of Bias" data-type="sect2"><div class="sect2" id="sec-biastypes">&#13;
<h2>Types of Bias</h2>&#13;
&#13;
<p>Bias<a contenteditable="false" data-primary="bias" data-secondary="types of" data-type="indexterm" id="ix_bias_types"/><a contenteditable="false" data-primary="target, access, sample framework" data-type="indexterm" id="ix_targ_acc_sam_fw2"/> comes in many forms. We describe some classic types here and connect them to our target-access-sample framework:</p>&#13;
&#13;
<dl class="simple myst">&#13;
	<dt>Coverage bias</dt>&#13;
	<dd>&#13;
	<p>Occurs when the access<a contenteditable="false" data-primary="coverage bias" data-type="indexterm" id="id673"/><a contenteditable="false" data-primary="access frame" data-type="indexterm" id="id674"/> frame does not include everyone in the target population. For example, a survey based on phone calls cannot reach those without a phone. In this situation, those who cannot be reached may differ in important ways from those in the access frame.</p>&#13;
	</dd>&#13;
	<dt>Selection bias</dt>&#13;
	<dd>&#13;
	<p>Arises when the mechanism<a contenteditable="false" data-primary="self-selection bias" data-type="indexterm" id="id675"/><a contenteditable="false" data-primary="selection bias" data-type="indexterm" id="id676"/> used to choose units for the sample tends to select certain units more often than they should be selected. As an example, a convenience sample chooses the units that are most easily available. Problems can arise when those who are easy to reach differ in important ways from those who are harder to reach. As another example, observational studies and experiments often rely on volunteers (people who choose to participate), and this self-selection has the potential for bias if the volunteers differ from the target population in important ways.</p>&#13;
	</dd>&#13;
	<dt>Nonresponse bias</dt>&#13;
	<dd>&#13;
	<p>Comes in two forms<a contenteditable="false" data-primary="nonresponse bias" data-type="indexterm" id="id677"/><a contenteditable="false" data-primary="item nonresponse bias" data-type="indexterm" id="id678"/><a contenteditable="false" data-primary="unit nonresponse bias" data-type="indexterm" id="id679"/>: unit and item. Unit nonresponse happens when someone selected for a sample is unwilling to participate (they may never answer a phone call from an unknown caller). Item nonresponse occurs when, say, someone answers the phone but refuses to respond to a particular survey question. Nonresponse can lead to bias if those who choose not to respond are systematically different from those who choose to respond.</p>&#13;
	</dd>&#13;
	<dt>Measurement bias</dt>&#13;
	<dd>&#13;
	<p>Happens<a contenteditable="false" data-primary="measurement bias" data-type="indexterm" id="id680"/> when an instrument systematically misses the target in one direction. For example, low humidity can systematically give us incorrectly high measurements of air pollution. In addition, measurement devices can become unstable and drift over time and so produce systematic errors. In surveys, measurement bias can arise when questions are confusingly worded or leading, or when respondents may not be comfortable answering honestly.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>Each of these types<a contenteditable="false" data-primary="protocol, data collection" data-type="indexterm" id="id681"/><a contenteditable="false" data-primary="chance mechanism" data-seealso="probability" data-type="indexterm" id="id682"/><a contenteditable="false" data-primary="chance mechanism" data-secondary="to avoid bias" data-secondary-sortas="avoid bias" data-type="indexterm" id="id683"/> of bias can lead to situations where the data are not centered on the unknown targeted value. Often, we cannot assess the potential magnitude of the bias, since little to no information is available on those who are outside the access frame, less likely to be selected for the sample, or disinclined to respond. Protocols are key to reducing these sources of bias. Chance mechanisms to select a sample from the frame or to assign units to experimental conditions can eliminate selection bias. A nonresponse follow-up protocol to encourage participation can reduce nonresponse bias. A pilot survey can improve question wording and so reduce measurement bias. Procedures to calibrate instruments and protocols to take measurements in, say, random order can reduce measurement bias.</p>&#13;
&#13;
<p>In the 2016 US presidential election<a contenteditable="false" data-primary="predictions and predicting" data-secondary="election outcomes" data-type="indexterm" id="id684"/><a contenteditable="false" data-primary="election outcome prediction" data-type="indexterm" id="id685"/>, nonresponse bias and measurement bias were key factors in the inaccurate predictions of the winner. Nearly all voter polls leading up to the election predicted Clinton a winner over Trump. Trump’s upset victory came as a surprise. After the election, many polling experts attempted to diagnose where things went wrong in the polls. The <a class="reference external" href="https://oreil.ly/uPDlR">American Association for Public Opinion Research</a> found that the predictions were flawed for two key reasons:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>College-educated voters were overrepresented. <a class="reference external" href="https://oreil.ly/K4BvY">College-educated voters are more likely to participate in surveys than those with less education</a>, and in 2016 they were more likely to support Clinton. Higher response rates from more highly educated voters biased the sample and overestimated support for Clinton.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Voters were undecided or changed their preferences a few days before the election. Since a poll is static and can only directly measure current beliefs, it cannot reflect a shift in attitudes.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>It’s difficult to figure out whether people held back their preference or changed their preference and how large a bias this created. However, exit polls have helped polling experts understand what happened after the fact. They indicate that in battleground states, such as Michigan, many voters made their choice in the final week of the campaign, and that group went for Trump by a wide margin.</p>&#13;
&#13;
<p>Bias<a contenteditable="false" data-primary="variance" data-secondary="and bias" data-secondary-sortas="bias" data-type="indexterm" id="id686"/> does not need to be avoided under all circumstances. If an instrument is highly precise (low variance) and has a small bias, then that instrument might be preferable to another with higher variance and no bias. As an example, biased studies are potentially useful to pilot a survey instrument or to capture useful information for the design of a larger study. Many times we can at best recruit volunteers for a study. Given this limitation, it can still be useful to enroll these volunteers in the study and use random assignment to split them into treatment groups. That’s the idea behind randomized controlled experiments.</p>&#13;
&#13;
<p>Whether or not bias is present, data typically also exhibit variation. Variation can be introduced purposely by using a chance mechanism to select a sample, and it can occur naturally through an instrument’s precision. In the next section, we identify three common sources of variation.<a contenteditable="false" data-primary="" data-startref="ix_bias_types" data-type="indexterm" id="id687"/><a contenteditable="false" data-primary="" data-startref="ix_targ_acc_sam_fw2" data-type="indexterm" id="id688"/></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Types of Variation" data-type="sect2"><div class="sect2" id="sec-variationtypes">&#13;
<h2>Types of Variation</h2>&#13;
&#13;
<p>The following types of variation results from a chance<a contenteditable="false" data-primary="variation" data-secondary="types of" data-type="indexterm" id="ix_var_types"/><a contenteditable="false" data-primary="chance mechanism" data-secondary="to balance variation" data-secondary-sortas="balance variation" data-type="indexterm" id="ix_chance_bal_var"/> mechanism and have the advantage of being quantifiable:</p>&#13;
&#13;
<dl class="simple myst">&#13;
	<dt>Sampling variation</dt>&#13;
	<dd>&#13;
	<p>Results<a contenteditable="false" data-primary="samples and sampling" data-secondary="sampling variation" data-type="indexterm" id="id689"/> from using chance to select a sample. In this case, we can, in principle, compute the chance that a particular collection of elements is selected for the sample.</p>&#13;
	</dd>&#13;
	<dt>Assignment variation</dt>&#13;
	<dd>&#13;
	<p>Occurs in a controlled<a contenteditable="false" data-primary="assignment variation" data-type="indexterm" id="id690"/> experiment when we assign units at random to treatment groups. In this situation, if we split the units up differently, then we can get <span class="keep-together">different</span> results from the experiment. This assignment process allows us to compute the chance of a particular group assignment.</p>&#13;
	</dd>&#13;
	<dt>Measurement error</dt>&#13;
	<dd>&#13;
	<p>Results from the measurement<a contenteditable="false" data-primary="measurement error" data-type="indexterm" id="id691"/><a contenteditable="false" data-primary="errors" data-secondary="measurement" data-type="indexterm" id="id692"/> process. If the instrument used for measurement has no drift or bias and a reliable distribution of errors, then when we take multiple measurements on the same object, we get random variations in measurements that are centered on the truth.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>The <em>urn model</em> is a simple abstraction<a contenteditable="false" data-primary="urn model" data-type="indexterm" id="id693"/> that can be helpful for understanding variation. This model sets up a container (an urn, which is like a vase or a bucket) full of identical marbles that have been labeled, and we use the simple action of drawing marbles from the urn to reason about sampling schemes, randomized controlled experiments, and measurement error. For each of these types of variation, the urn model helps us estimate the size of the variation using either probability or simulation (see <a class="reference internal" data-type="xref" href="ch03.html#ch-theory-datadesign">Chapter 3</a>). The example of selecting Wikipedia<a contenteditable="false" data-primary="Wikipedia contributors, selecting awards" data-type="indexterm" id="id694"/> contributors to receive an informal award provides two examples of the urn model.</p>&#13;
&#13;
<p>Recall the Wikipedia experiment, where 200 contributors were selected at random from 1,440 top contributors. These 200 contributors were then split, again at random, into two groups of 100 each. One group received an informal award and the other didn’t. Here’s how we use the urn model to characterize this process of selection and splitting:</p>&#13;
&#13;
<ol>&#13;
	<li>&#13;
	<p>Imagine an urn filled with 1,440 marbles that are identical in shape and size, and written on each marble is one of the 1,440 Wikipedia usernames. (This is the access frame.)</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Mix the marbles in the urn really well, select one marble, and set it aside.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Repeat the mixing and selecting of the marbles to obtain 200 marbles.</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>The marbles drawn form the sample. Next, to determine which of the 200 contributors receive awards, we work with another urn:</p>&#13;
&#13;
<ol>&#13;
	<li>&#13;
	<p>In a second urn, put in the 200 marbles from the preceding sample.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Mix these marbles well, select one marble, and set it aside.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Repeat, choosing 100 marbles. That is, choose marbles one at a time, mixing in between, and setting the chosen marble aside.</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>The 100 drawn marbles are assigned to the treatment group and correspond to the contributors who receive an award. The 100 left in the urn form the control group and receive no award.</p>&#13;
&#13;
<p>Both the selection<a contenteditable="false" data-primary="assignment variation" data-type="indexterm" id="id695"/> of the sample and the choice of award recipients use a chance mechanism. If we were to repeat the first sampling activity again, returning all 1,440 marbles to the original urn, then we would most likely get a different sample. This variation is the source of <em>sampling variation</em>. Likewise, if we were to repeat the random assignment process again (keeping the sample of 200 unchanged), then we would get a different treatment group. <em>Assignment variation</em> arises from this second chance process.</p>&#13;
&#13;
<p>The Wikipedia experiment provided an example of both sampling and assignment variation. In both cases, the researcher imposed a chance mechanism on the data collection process. Measurement error can at times also be considered a chance process that follows an urn model. For example, we can characterize the measurement error of the CO<sub>2</sub> monitor at Mauna Loa in this way.</p>&#13;
&#13;
<p>If we can draw an accurate analogy between variation in the data and the urn model, the urn model provides us the tools to estimate the size of the variation (see <a class="reference internal" data-type="xref" href="ch03.html#ch-theory-datadesign">Chapter 3</a>). This is highly desirable because we can give concrete values for the variation in our data. However, it’s vital to confirm that the urn model is a reasonable depiction of the source of variation. Otherwise, our claims of accuracy can be seriously flawed. We need to know as much as possible about data scope, including instruments and protocols and chance mechanisms used in data collection, to apply these urn models.<a contenteditable="false" data-primary="" data-startref="ix_accur_lifecycle" data-type="indexterm" id="id696"/><a contenteditable="false" data-primary="" data-startref="ix_chance_bal_var" data-type="indexterm" id="id697"/><a contenteditable="false" data-primary="" data-startref="ix_var_types" data-type="indexterm" id="id698"/><a contenteditable="false" data-primary="" data-startref="ix_accur_ch2" data-type="indexterm" id="id699"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="sec-data-scope-summary">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>No matter the kind of data you are working with, before diving into cleaning, exploration, and analysis, take a moment to look into the data’s source. If you didn’t collect the data, ask yourself:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Who collected the data?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Why were the data collected?</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Answers to these questions can help determine whether these found data can be used to address the question of interest to you.</p>&#13;
&#13;
<p>Consider the scope of the data. Questions about the temporal and spatial aspects of data collection can provide valuable insights:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>When were the data collected?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Where were the data collected?</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Answers to these questions help you determine whether your findings are relevant to the situation that interests you, or whether your situation may not be comparable to this other place and time.</p>&#13;
&#13;
<p class="pagebreak-before less_space">Core to the notion of scope are answers to the following questions:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>What is the target population (or unknown parameter value)?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>How was the target accessed?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>What methods were used to select samples/take measurements?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>What instruments were used and how were they calibrated?</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Answering as many of these questions as possible can give you valuable insights as to how much trust you can place in your findings and whether you can generalize from them.<a contenteditable="false" data-primary="" data-startref="ix_lifecycle_data_sci_q_s" data-type="indexterm" id="id700"/></p>&#13;
&#13;
<p>This chapter provided you with terminology and a framework for thinking about and answering these questions. The chapter also outlined ways to identify possible sources of bias and variance that can impact the accuracy of your findings. To help you reason about bias and variance, we introduced the following diagrams and notions:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Scope diagram to indicate the overlap between target population, access frame, and sample</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Dartboard to describe an instrument’s bias and variance</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Urn model for situations when a chance mechanism has been used to select a sample from an access frame, divide a group into experimental treatment groups, or take measurements from a well-calibrated instrument</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>These diagrams and models attempt to boil down key concepts that are required to understand how to identify limitations and judge the usefulness of your data in answering your question. <a class="reference internal" data-type="xref" href="ch03.html#ch-theory-datadesign">Chapter 3</a> continues the development of the urn model to more formally quantify accuracy and design simulation studies.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id636"><sup><a href="ch02.html#id636-marker">1</a></sup> The notion of “scope” has been adapted from Joseph Hellerstein’s <a href="https://oreil.ly/VrByF">course notes</a> on scope, temporality, and faithfulness.</p></div></div></section></body></html>