- en: Chapter 2\. Foundations of Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Have you ever stopped to consider what your meteorologist really means by a
    30% chance of rain? Barring a crystal ball, they can’t say for sure that it will
    rain. That is, they are *uncertain* about an *outcome*. What they *can* do is
    *quantify* that uncertainty as a value between 0% (certain it will not rain) and
    100% (certain it will rain).
  prefs: []
  type: TYPE_NORMAL
- en: Data analysts, like meteorologists, do not possess crystal balls. Often, we
    want to make claims about an entire population while only possessing the data
    for a sample. So we too will need to quantify uncertainty as a probability.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start this chapter by digging deeper into how probability works and how
    probabilities are derived. We’ll also use Excel to simulate some of the most important
    theorems in statistics, which are largely based on probability. This will put
    you on excellent footing for [Chapter 3](ch03.html#foundations-of-inference) and
    [Chapter 4](ch04.html#foundations-of-data-analytics), where we’ll perform inferential
    statistics in Excel.
  prefs: []
  type: TYPE_NORMAL
- en: Probability and Randomness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Colloquially, we say that something is “random” when it seems out of context
    or haphazard. In probability, something is *random* when we know an event will
    *have* an outcome, but we’re not sure what that outcome will be.
  prefs: []
  type: TYPE_NORMAL
- en: Take a six-sided die, for example. When we toss the die, we know it will land
    on one side—it won’t disappear or land on multiple sides. Knowing that we’ll get
    *an* outcome, but not *which* outcome, is what’s meant by randomness in statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Probability and Sample Space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We know that when the die lands, it will display a number between one and six.
    This set of all outcomes is called a *sample space*. Each of these outcomes is
    assigned a probability greater than zero, because it’s possible that the die may
    land on any of its sides. Summed together, these probabilities come to 1, because
    we are certain the outcome will be one of these possibilities in the sample space.
  prefs: []
  type: TYPE_NORMAL
- en: Probability and Experiments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve determined that rolling a die is random, and we’ve outlined its *sample
    space*. We can now begin to build experiments for this random event. In probability,
    experiments are procedures that can be infinitely replicated with a consistent
    sample space of possible outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some experiments take many years of planning, but ours is fortunately simple:
    roll a die. Each time we do, we get another value between one and six. The result
    is our outcome. Each die roll is known as a *trial* of the experiment.'
  prefs: []
  type: TYPE_NORMAL
- en: Unconditional and Conditional Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Given what we know about probability so far, a typical probabilistic question
    about die rolls might be: “What is the probability of rolling a four?” This is
    called the *marginal* or *unconditional* probability, as we are only looking at
    one event in isolation.'
  prefs: []
  type: TYPE_NORMAL
- en: But what about a question like “What is the probability of rolling a two, given
    that we rolled a one in the last trial?” To answer this, we would be discussing
    *joint* probability. Sometimes when we are studying the probability of two events,
    we know the outcome of one but not the other. This is known as *conditional* probability,
    and one way to calculate it is with Bayes’ rule.
  prefs: []
  type: TYPE_NORMAL
- en: We will not cover Bayes’ rule, and the many areas of probability and statistics
    that apply it, in this book, but it’s well worth your future study. Check out
    Will Kurt’s *Bayesian Statistics the Fun Way* (No Starch Press) for a fantastic
    introduction. You will see that Bayesianism offers a unique approach to working
    with data with some impressive applications for analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The schools of thought developed around Bayes’ rule diverge from the so-called
    frequentist approaches used in this book and much of classical statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Probability Distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we’ve learned what makes our die toss a random experiment, and we’ve
    enumerated the sample space of what possible values a trial might take. We know
    that the sum of the probabilities of each outcome must equal 1, but what is the
    relative probability for each outcome? For this we can refer to *probability distributions*.
    A probability distribution is a listing of what possible outcomes an event can
    take, and how common each outcome is. While a probability distribution could be
    written as a formal mathematical function, we will instead focus on its quantitative
    output.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 1](ch01.html#foundations-of-eda), you learned about the difference
    between discrete and continuous variables. There are also related discrete and
    continuous probability *distributions*. Let’s learn more, starting with the former.
  prefs: []
  type: TYPE_NORMAL
- en: Discrete Probability Distributions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll continue with our example of a die toss. This is considered a *discrete*
    probability distribution because there are a countable number of outcomes: for
    example, while a die toss can result in a 2 or a 3, it can never result in a 2.25.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, a die toss is a *discrete uniform* probability distribution
    because each outcome is equally likely for any trial: that is, we are just as
    likely to roll a 4 as we are a 2, and so forth. To be more specific, we have a
    one-in-six probability for each outcome.'
  prefs: []
  type: TYPE_NORMAL
- en: To follow along with this and the other Excel demos in this chapter, head to
    the *ch-2.xlsx* file in this book’s [repository](https://oreil.ly/1hlYj). For
    most of these exercises, I completed some staging of the worksheet already and
    will work through the remainder with you here. Start with the *uniform-distribution*
    worksheet. Each possible outcome *X* is listed in the range `A2:A7`. We know that
    it’s equally likely to get any outcome, so our formula in `B2:B7` should be `=1/6`.
    *P(X=x)* indicates the probability that a given event will result in the listed
    outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Now, select the range `A1:B7` and from the ribbon, go to Insert > Clustered
    Column. Your probability distribution and visualization should look like [Figure 2-1](#die-toss-distribution).
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to your first, if unexciting, probability distribution. Notice the gaps
    between values in our visualization? This is a wise choice to indicate that these
    are *discrete* and not continuous outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes we may want to know the *cumulative* probability of an outcome. In
    this case, we take a running total of all probabilities until we reach 100% (because
    the sample space must sum to 1). We’ll find the probability of an event being
    *less than or equal to* a given outcome in column `C`. We can set up a running
    total in the range `C2:C7` with the formula `=SUM($B$2:B2)`.
  prefs: []
  type: TYPE_NORMAL
- en: '![The probability distribution of a six-sided die toss](assets/aina_0201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. The probability distribution of a six-sided die toss
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now, select the range `A1:A7`, hold down the Ctrl key for Windows or Cmd for
    Mac, and highlight `C1:C7`. With this noncontiguous range selected, create a second
    clustered column chart. Do you see the difference between a probability distribution
    and a *cumulative* probability distribution in [Figure 2-2](#cumulative-probability)?
  prefs: []
  type: TYPE_NORMAL
- en: '![Probability versus cumulative distribution](assets/aina_0202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-2\. The probability versus cumulative probability distribution of a
    six-sided die toss
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Based on logic and mathematical reasoning, we’ve been assuming a one-in-six
    probability of landing on any side of the die. This is called our *theoretical
    probability*. We could also find the probability distribution empirically by rolling
    a die many times and recording the results. This is called an *experimental probability*.
    After all, we could find through experiments that the probability for each side
    of the die is really *not* one in six as theoretically reasoned, and that the
    die is biased toward a given side.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a couple of options for deriving experimental probabilities: first,
    we could indeed conduct a real experiment. Of course, rolling a die dozens of
    times and recording the results might get quite tedious. Our alternative is to
    get the computer to do the heavy lifting, and *simulate* the experiment. Simulation
    often provides a decent approximation of reality, and is frequently used when
    running experiments in real life is too difficult or time-consuming. The downside
    of simulation is that it can fail to reflect any anomalies or idiosyncrasies from
    the real-life experiment that it intends to represent.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Simulation is frequently used in analytics to glean what might happen in real
    life when finding out through actual experiments is too difficult or even impossible.
  prefs: []
  type: TYPE_NORMAL
- en: To simulate the experiment of rolling a die, we need a way to consistently choose
    a number between one and six at random. We can do this using Excel’s random number
    generator, `RANDBETWEEN()`. The results you see in the book will be different
    than what you get when you try it yourself…but they will *all* be random numbers
    between one and six.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Your individual results using Excel’s random number generator will look different
    from what’s been recorded in the book.
  prefs: []
  type: TYPE_NORMAL
- en: Now, go to the *experimental-probability* worksheet. In column `A`, we have
    labeled 100 die toss trials for which we’d like to record the outcome. At this
    point, you could start rolling a real die and recording the results in column
    `B`. Your more efficient, if less realistic, alternative is to simulate the results
    with `RANDBETWEEN()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This function takes two arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We are using a six-sided die, which makes our range go between one and six:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`RANDBETWEEN()` only returns whole numbers, which is what we want in this case:
    again, this is a *discrete* distribution. Using the fill handle, you can generate
    an outcome for all 100 trials. Don’t get too attached to your current outcomes:
    press F9 in Windows, fn-F9 for Mac, or from the ribbon select Formulas → Calculate
    Now. This will recalculate your workbook, and regenerate your random numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s compare our theoretical versus experimental probabilities of a die toss
    in columns `D-F`. Column `D` will be used to enumerate our sample space: the numbers
    one through six. In column `E`, take the theoretical distribution: `1/6`, or `16.67%`.
    In column `F`, calculate the experimental distribution from columns `A` and `B`.
    This is the percentage of times we find each outcome across all trials. You can
    find this using the formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Select your range `D1:F7` and from the ribbon go to Insert → Clustered Column.
    Your worksheet should now look like [Figure 2-3](#theoretical-experimental-probabilities).
    Try recalculating it a couple of times.
  prefs: []
  type: TYPE_NORMAL
- en: '![Theoretical versus experimental probabilities](assets/aina_0203.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-3\. Theoretical versus experimental probabilities of a six-sided die
    toss
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'It looks like, based on our experimental distribution, we were right to predict
    an equal likelihood of rolling any number. Of course, our experimental distribution
    isn’t *perfectly* like the theoretical: there will always be some error due to
    random chance.'
  prefs: []
  type: TYPE_NORMAL
- en: It could be the case, however, that were we to conduct the experiment in real
    life, the results would differ from what we derived from simulation. Perhaps the
    real-life die of interest is *not* fair, and we’ve overlooked that by relying
    on our own reasoning and Excel’s algorithm. It seems like a trivial point, but
    often probabilities in real life don’t behave as we (or our computers) expect
    them to.
  prefs: []
  type: TYPE_NORMAL
- en: The discrete uniform is one of many discrete probability distributions; others
    commonly used in analytics include the binomial and Poisson distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Probability Distributions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A distribution is considered continuous when an outcome can take any possible
    value between two other values. We will focus here on the normal distribution,
    or the *bell curve*, as depicted with a histogram. You may be familiar with this
    famous shape, seen in [Figure 2-4](#normal-distribution).
  prefs: []
  type: TYPE_NORMAL
- en: You’ll see in this chart a perfectly symmetrical distribution centered around
    the variable’s mean (μ). Let’s dig in on what the normal distribution is and what
    it tells us, using Excel to illustrate the fundamental statistical concepts that
    are based on it.
  prefs: []
  type: TYPE_NORMAL
- en: '![Normal distribution](assets/aina_0204.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-4\. The normal distribution depicted with a histogram
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The normal distribution is worth reviewing in part because it is so common in
    the natural world. For example, [Figure 2-5](#real-normal-distributions) shows
    histograms of the distribution of student heights and wine pH levels, respectively.
    These datasets are available in the book’s [repository](https://oreil.ly/1hlYj)
    for you to explore in the *datasets* folder under *heights* and *wine*, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![Normal variables](assets/aina_0205.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2-5\. Two normally distributed variables from real life: student heights
    and wine pH levels'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You may be wondering how we know when a variable is normally distributed. Good
    question. Think back to our die toss example: we enumerated all possible outcomes,
    derived a theoretical distribution, then derived an experimental distribution
    (via simulation) to compare the two. Consider the histograms in [Figure 2-5](#real-normal-distributions)
    as *experimental distributions* of their own: in this case, the data was collected
    manually rather than relying on a simulation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several ways to determine whether a real-life dataset with its experimental
    distribution is close enough to a theoretical normal distribution. For now, we’ll
    look out for the telltale bell curve histogram: a symmetrical shape, with the
    majority of values found near the center. Other ways include evaluating skewness
    and kurtosis, which are two additional summary statistics measuring the distribution’s
    symmetry and peakedness, respectively. It’s also possible to test for normality
    using methods of statistical inference. You’ll learn the basics of statistical
    inference in [Chapter 3](ch03.html#foundations-of-inference). But for now, we’ll
    go by the rule: “You know it when you see it.”'
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When you are dealing with real-life data, you are dealing with *experimental*
    distributions. They will never perfectly match theoretical distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The normal distribution offers some easy-to-remember guidelines for what percentage
    of observations we expect to find within a given number of standard deviations
    of the mean. Specifically, for a normally distributed variable we expect:'
  prefs: []
  type: TYPE_NORMAL
- en: 68% of observations to fall within one standard deviation of the mean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 95% of observations to fall within two standard deviations of the mean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 99.7% of observations to fall within three standard deviations of the mean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is known as the *empirical rule*, or the *68–95–99.7 rule*. Let’s see it
    in action using Excel. Next, go to the *empirical-rule* worksheet, as shown in
    [Figure 2-6](#empirical-rule-start).
  prefs: []
  type: TYPE_NORMAL
- en: '![The empirical rule demonstrated in Excel](assets/aina_0206.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-6\. The start of the *empirical-rule* worksheet
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In cells `A10:A109` we have the values 1–100\. Our objective in cells `B10:B109`
    is to find what percentage of observations will take on these values for a normally
    distributed variable with a mean of 50 and a standard deviation of 10 (cells `B1`
    and `B2`, respectively). We will then find what percentage of observations fall
    within one, two, and three standard deviations of the mean in `C10:E109`. Once
    we do so, the charts to the right will be populated. Cells `C4:E4` will also find
    the total percentages for each column.
  prefs: []
  type: TYPE_NORMAL
- en: The normal distribution is continuous, which means that observations can theoretically
    take on any value between two other values. This makes for a *lot* of outcomes
    to assign a probability to. For simplicity, it’s common to bin these observations
    into discrete ranges. The probability mass function (PMF) will return the probabilities
    found for each discrete bin in the range of observations. We’ll use Excel’s `NORM.DIST()`
    function to calculate a PMF for our variable in the range 1–100\. This function
    is more involved than others used so far, so I’ve described each argument in [Table 2-1](#norm-dist).
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-1\. The arguments needed for `NORM.DIST()`
  prefs: []
  type: TYPE_NORMAL
- en: '| **Argument** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `X` | The outcome for which you want to find the probability |'
  prefs: []
  type: TYPE_TB
- en: '| `Mean` | The mean of the distribution |'
  prefs: []
  type: TYPE_TB
- en: '| `Standard_dev` | The standard deviation of the distribution |'
  prefs: []
  type: TYPE_TB
- en: '| `Cumulative` | If `TRUE`, a cumulative function is returned; if `FALSE`,
    the mass function is returned |'
  prefs: []
  type: TYPE_TB
- en: 'Column `A` of our worksheet contains our outcomes, `B1` and `B2` contain our
    mean and standard deviation, respectively, and we want a mass instead of a cumulative
    distribution. Cumulative would return a running sum of the probability, which
    we don’t want here. That makes our formula for `B10`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using the fill handle, you’ll get the percentage likelihood of an observation
    taking on each value from 0 to 100\. For example, you’ll see in cell `B43` that
    there is approximately a 1.1% chance of an observation being equal to 34.
  prefs: []
  type: TYPE_NORMAL
- en: We can see in cell `B4` that an outcome is likely to be between 1 and 100 over
    99.99% of the time. Importantly, this number is not equal to 100%, because an
    observation in a continuous distribution can take on *any* possible value—not
    just those from 1 to 100\. In cells `C7:E8` I’ve written formulas to find the
    range of values within one, two and three standard deviations of our mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use these thresholds along with conditional logic to find what parts
    of our probability mass function in column `B` can be found within these respective
    regions. In cell `C10` enter the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This function will carry the probability over from column `B` if the value of
    column `A` falls within the standard deviation range. If it falls outside the
    range, the cell is left blank. Using the fill handle, you can apply this formula
    to the entire range `C10:E109`. Your worksheet should now look like [Figure 2-7](#empirical-rule-excel).
  prefs: []
  type: TYPE_NORMAL
- en: '![The empirical rule demonstrated in Excel](assets/aina_0207.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-7\. The empirical rule demonstrated in Excel
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Cells `C4:E4` indicate that we find approximately 65.8%, 94.9%, and 99.7% of
    values within one, two, and three standard deviations of the mean, respectively.
    These numbers are very close to matching the 68–95–99.7 rule.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, take a look at the resulting visualizations: we see that a sizable majority
    of observations can be found within one standard deviation, and more still within
    two. By three standard deviations, it’s hard to see the part of the chart in [Figure 2-8](#empirical-rule-visualized)
    that is *not* covered, but it’s still there. (Remember, this is only 0.3% of all
    observations.)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Empirical rule charts](assets/aina_0208.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-8\. The empirical rule visualized in Excel
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'What happens when you change the standard deviation of our example to eight?
    To 12? The bell curve shape remains symmetrically centered around the mean of
    50 but contracts and expands: a lower standard deviation leads to a “tighter”
    curve and vice versa. In any case, the empirical rule roughly applies to the data.
    If you shift the mean to 49 or 51, you see the “center” of the curve move along
    the x-axis. A variable can have any mean and standard deviation and still be normally
    distributed; its resulting probability mass function will be different.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 2-9](#different-normal-distributions) shows two normal distributions
    with different means and standard deviations. Despite their very different shapes,
    they both still follow the empirical rule.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Different normal distributions](assets/aina_0209.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-9\. Different normal distributions
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A normal distribution can have any possible combination of mean and standard
    deviation. The resulting probability density function will change, but will roughly
    follow the empirical rule.
  prefs: []
  type: TYPE_NORMAL
- en: The normal distribution is also important because of its place in the central
    limit theorem. I call this theorem the “missing link of statistics” for reasons
    you’ll see in this and following chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'For an example of the central limit theorem, we will use another common game
    of chance: roulette. A European roulette wheel is equally likely to return any
    number between 0 and 36 (compared to the American wheel, which has slots labeled
    both 0 and 00). Based on what you’ve learned about die tosses, what kind of probability
    distribution is this? It’s a discrete uniform. Does it seem odd that we’re analyzing
    this distribution in a demo I said was about the normal distribution? Well, we
    have the central limit theorem to thank here. To see this theorem in action for
    yourself, go to the *roulette-dist* worksheet and simulate 100 spins of a roulette
    wheel in `B2:B101` using `RANDBETWEEN()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Visualize the result using a histogram. Your worksheet should look like [Figure 2-10](#distribution-roulette-spins).
    Try recalculating a few times. You will see that each time you get a rather flat-looking
    histogram. This is indeed a discrete uniform distribution, where it’s equally
    likely to land on any number between 0 and 36.
  prefs: []
  type: TYPE_NORMAL
- en: '![Histogram of roulette spins](assets/aina_0210.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-10\. The distribution of simulated roulette spins
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now go to the *roulette-sample-mean-dist* worksheet. Here we will be doing
    something a little different: we’ll simulate 100 spins, then take the average
    of those spins. We’ll do this 100 times and plot the distribution of these trial
    averages, again as a histogram. This “average of averages” is known as a *sample
    mean*. Once you’ve done that using the `RANDBETWEEN()` and `AVERAGE()` functions,
    you should see something like [Figure 2-11](#distribution-sample-means).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Histogram of sample means roulette spins](assets/aina_0211.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-11\. The distribution of sample means of simulated roulette spins
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This distribution no longer looks like a rectangle: in fact, it looks like
    a bell curve. It’s symmetrical, and most observations are clustered around the
    center: we now have a normal distribution. How could our distribution of sample
    means be normally distributed, when the roulette spins themselves are not? Welcome
    to the very special kind of magic known as the *central limit theorem* (CLT).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Put formally, the CLT tells us that:'
  prefs: []
  type: TYPE_NORMAL
- en: The distribution of sample means will be normal or nearly normal if the sample
    size is large enough.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This phenomenon is a game changer, because it allows us to use the unique traits
    of the normal distribution (such as the empirical rule) to make claims about the
    sample means of a variable, even when that variable itself isn’t normally distributed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Did you catch the fine print? The CLT only applies *when the sample size is
    large enough*. It’s an important disclaimer, but also an ambiguous one: how large
    is large enough? Let’s gather some ideas with another Excel demo. Head to the
    *law-of-large-numbers* worksheet to follow along. In column `B`, we can simulate
    the outcomes of 300 trials of a roulette spin using `RANDBETWEEN(0, 36)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In column `C`, we want to take a running average of the outcome. We can do
    so using mixed references; in column `C` enter the following and drag it alongside
    your 300 trials:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in finding the running average of column `B`. Select your
    resulting data in column `C` and then head to the ribbon and click Insert → Line.
    Take a look at your line chart and recalculate the workbook a few times. Each
    resulting simulation will be different than what’s shown in [Figure 2-12](#lln-excel),
    but as a pattern the average tends to converge to 18 with more spins, which makes
    sense: it’s the average between 0 and 36\. This anticipated figure is known as
    the *expected value*.'
  prefs: []
  type: TYPE_NORMAL
- en: '![The law of large numbers](assets/aina_0212.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-12\. The law of large numbers, visualized in Excel
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This phenomenon is known as the *law of large numbers* (LLN). Stated formally,
    the LLN tells us:'
  prefs: []
  type: TYPE_NORMAL
- en: The average of results obtained from trials become closer to the expected value
    as more trials are performed.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This definition, though, begs the question we first asked: how large does a
    sample size need to be for the CLT to apply? You’ll often hear 30 given as a threshold.
    More conservative guidelines may call for a sample size of 60 or 100\. Given these
    sample size guidelines, look back to [Figure 2-12](#lln-excel). See how it indeed
    settles more closely to the expected value at around these thresholds?'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The law of large numbers provides a loose rule of thumb for an adequate sample
    size that meets the CLT.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample sizes of 30, 60, and 100 are purely rules of thumb; there are more rigorous
    ways to determine what sample sizes are needed for the CLT to apply. For now,
    remember this: given that our sample size meets these thresholds, our sample mean
    should be close to the expected value (thanks to the LLN), and should also be
    normally distributed (thanks to the CLT).'
  prefs: []
  type: TYPE_NORMAL
- en: Several continuous probability distributions exist, such as the exponential
    and triangular. We focused on the normal distribution both because of its ubiquity
    in the real world and because of its special statistical properties.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned at the beginning of this chapter, data analysts live in a world
    of uncertainty. Specifically, we often want to make claims about an entire population,
    while only possessing a sample’s worth of data. Using the framework of probability
    covered in this chapter, we will be able to do this while also quantifying its
    inherent uncertainty. In [Chapter 3](ch03.html#foundations-of-inference), we’ll
    dig into the elements of hypothesis testing, a core method of data analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using Excel and your knowledge of probability, consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the expected value of a six-sided die toss?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Consider a variable that is normally distributed with a mean of 100 and standard
    deviation of 10.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the probability that an observation from this variable would take the
    value 87?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: What percentage of observations would you expect to find between 80 and 120?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If the expected value of a European roulette spin is 18, does that mean you
    are better off betting on 18 than other numbers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
