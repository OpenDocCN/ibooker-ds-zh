- en: Chapter 7\. Hypothesis and Inference
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 7 章。假设与推断
- en: It is the mark of a truly intelligent person to be moved by statistics.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 被统计数据感动是真正聪明的人的标志。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: George Bernard Shaw
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 乔治·伯纳德·肖
- en: What will we do with all this statistics and probability theory? The *science*
    part of data science frequently involves forming and testing *hypotheses* about
    our data and the processes that generate it.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会用所有这些统计数据和概率理论做什么呢？数据科学的*科学*部分经常涉及形成和测试关于数据及其生成过程的*假设*。
- en: Statistical Hypothesis Testing
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计假设检验
- en: Often, as data scientists, we’ll want to test whether a certain hypothesis is
    likely to be true. For our purposes, hypotheses are assertions like “this coin
    is fair” or “data scientists prefer Python to R” or “people are more likely to
    navigate away from the page without ever reading the content if we pop up an irritating
    interstitial advertisement with a tiny, hard-to-find close button” that can be
    translated into statistics about data. Under various assumptions, those statistics
    can be thought of as observations of random variables from known distributions,
    which allows us to make statements about how likely those assumptions are to hold.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，我们经常想测试某个假设是否可能成立。对于我们来说，假设是一些断言，比如“这枚硬币是公平的”或“数据科学家更喜欢 Python 而不是 R”或“人们更有可能在看不见关闭按钮的烦人插页广告出现后，不阅读内容直接离开页面”。这些可以转化为关于数据的统计信息。在各种假设下，这些统计信息可以被视为来自已知分布的随机变量的观察结果，这使我们能够对这些假设的可能性进行陈述。
- en: In the classical setup, we have a *null hypothesis*, <math><msub><mi>H</mi>
    <mn>0</mn></msub></math> , that represents some default position, and some alternative
    hypothesis, <math><msub><mi>H</mi> <mn>1</mn></msub></math> , that we’d like to
    compare it with. We use statistics to decide whether we can reject <math><msub><mi>H</mi>
    <mn>0</mn></msub></math> as false or not. This will probably make more sense with
    an example.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在经典设置中，我们有一个*零假设*，<math><msub><mi>H</mi> <mn>0</mn></msub></math> ，代表某些默认位置，以及我们想要与之比较的一些备选假设，<math><msub><mi>H</mi>
    <mn>1</mn></msub></math> 。我们使用统计数据来决定我们是否可以拒绝<math><msub><mi>H</mi> <mn>0</mn></msub></math>
    作为虚假的。这可能通过一个例子更容易理解。
- en: 'Example: Flipping a Coin'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例：抛硬币
- en: Imagine we have a coin and we want to test whether it’s fair. We’ll make the
    assumption that the coin has some probability *p* of landing heads, and so our
    null hypothesis is that the coin is fair—that is, that *p* = 0.5\. We’ll test
    this against the alternative hypothesis *p* ≠ 0.5.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 想象我们有一枚硬币，我们想测试它是否公平。我们假设硬币有一定概率 *p* 出现正面，因此我们的零假设是硬币是公平的——也就是说，*p* = 0.5。我们将这个假设与备选假设
    *p* ≠ 0.5 进行测试。
- en: 'In particular, our test will involve flipping the coin some number, *n*, times
    and counting the number of heads, *X*. Each coin flip is a Bernoulli trial, which
    means that *X* is a Binomial(*n*,*p*) random variable, which (as we saw in [Chapter 6](ch06.html#probability))
    we can approximate using the normal distribution:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们的测试将涉及抛硬币 *n* 次，并计算正面出现的次数 *X*。每次抛硬币都是伯努利试验，这意味着 *X* 是一个二项分布变量，我们可以用正态分布（如我们在
    [第 6 章](ch06.html#probability) 中看到的）来近似它：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Whenever a random variable follows a normal distribution, we can use `normal_cdf`
    to figure out the probability that its realized value lies within or outside a
    particular interval:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每当一个随机变量遊服从正态分布时，我们可以使用 `normal_cdf` 来确定其实现值在特定区间内或外的概率：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can also do the reverse—find either the nontail region or the (symmetric)
    interval around the mean that accounts for a certain level of likelihood. For
    example, if we want to find an interval centered at the mean and containing 60%
    probability, then we find the cutoffs where the upper and lower tails each contain
    20% of the probability (leaving 60%):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以反过来——找到非尾部区域或（对称的）包含一定概率水平的平均值的区间。例如，如果我们想找到一个以均值为中心且包含 60% 概率的区间，那么我们找到上下尾部各包含
    20% 概率的截止点（留下 60%）：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In particular, let’s say that we choose to flip the coin *n* = 1,000 times.
    If our hypothesis of fairness is true, *X* should be distributed approximately
    normally with mean 500 and standard deviation 15.8:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，假设我们选择抛硬币 *n* = 1,000 次。如果我们的公平假设成立，*X* 应该近似正态分布，均值为 500，标准差为 15.8：
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We need to make a decision about *significance*—how willing we are to make a
    *type 1 error* (“false positive”), in which we reject <math><msub><mi>H</mi> <mn>0</mn></msub></math>
    even though it’s true. For reasons lost to the annals of history, this willingness
    is often set at 5% or 1%. Let’s choose 5%.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要就*显著性*做出决策——我们愿意做*第一类错误*的程度，即拒绝<math><msub><mi>H</mi> <mn>0</mn></msub></math>即使它是真的。由于历史记载已经遗失，这种愿意通常设定为5%或1%。让我们选择5%。
- en: 'Consider the test that rejects <math><msub><mi>H</mi> <mn>0</mn></msub></math>
    if *X* falls outside the bounds given by:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到如果*X*落在以下界限之外则拒绝<math><msub><mi>H</mi> <mn>0</mn></msub></math>的测试：
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Assuming *p* really equals 0.5 (i.e., <math><msub><mi>H</mi> <mn>0</mn></msub></math>
    is true), there is just a 5% chance we observe an *X* that lies outside this interval,
    which is the exact significance we wanted. Said differently, if <math><msub><mi>H</mi>
    <mn>0</mn></msub></math> is true, then, approximately 19 times out of 20, this
    test will give the correct result.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 假设*p*真的等于0.5（即<math><msub><mi>H</mi> <mn>0</mn></msub></math>为真），我们只有5%的机会观察到一个落在这个区间之外的*X*，这正是我们想要的显著性水平。换句话说，如果<math><msub><mi>H</mi>
    <mn>0</mn></msub></math>为真，那么大约有20次中有19次这个测试会给出正确的结果。
- en: We are also often interested in the *power* of a test, which is the probability
    of not making a *type 2 error* (“false negative”), in which we fail to reject
    <math><msub><mi>H</mi> <mn>0</mn></msub></math> even though it’s false. In order
    to measure this, we have to specify what exactly <math><msub><mi>H</mi> <mn>0</mn></msub></math>
    being false *means*. (Knowing merely that *p* is *not* 0.5 doesn’t give us a ton
    of information about the distribution of *X*.) In particular, let’s check what
    happens if *p* is really 0.55, so that the coin is slightly biased toward heads.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还经常关注测试的*功效*，即不犯*第二类错误*（“假阴性”）的概率，即我们未能拒绝<math><msub><mi>H</mi> <mn>0</mn></msub></math>，尽管它是错误的。为了衡量这一点，我们必须明确<math><msub><mi>H</mi>
    <mn>0</mn></msub></math>假设为假*的含义*。 （仅知道*p*不等于0.5并不能给我们关于*X*分布的大量信息。）特别是，让我们检查*p*真的是0.55的情况，这样硬币稍微偏向正面。
- en: 'In that case, we can calculate the power of the test with:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以计算测试的功效：
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Imagine instead that our null hypothesis was that the coin is not biased toward
    heads, or that <math><mrow><mi>p</mi> <mo>≤</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn></mrow></math>
    . In that case we want a *one-sided test* that rejects the null hypothesis when
    *X* is much larger than 500 but not when *X* is smaller than 500\. So, a 5% significance
    test involves using `normal_probability_below` to find the cutoff below which
    95% of the probability lies:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 假设相反，我们的零假设是硬币不偏向正面，或者<math><mrow><mi>p</mi> <mo>≤</mo> <mn>0</mn> <mo>.</mo>
    <mn>5</mn></mrow></math>。在这种情况下，我们需要一个*单边测试*，当*X*远大于500时拒绝零假设，但当*X*小于500时不拒绝。因此，一个5%显著性测试涉及使用`normal_probability_below`找到概率分布中95%以下的截止值：
- en: '[PRE6]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is a more powerful test, since it no longer rejects <math><msub><mi>H</mi>
    <mn>0</mn></msub></math> when *X* is below 469 (which is very unlikely to happen
    if <math><msub><mi>H</mi> <mn>1</mn></msub></math> is true) and instead rejects
    <math><msub><mi>H</mi> <mn>0</mn></msub></math> when *X* is between 526 and 531
    (which is somewhat likely to happen if <math><msub><mi>H</mi> <mn>1</mn></msub></math>
    is true).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个更强大的测试，因为当*X*低于469（如果<math><msub><mi>H</mi> <mn>1</mn></msub></math>为真的话，这几乎不太可能发生）时，它不再拒绝<math><msub><mi>H</mi>
    <mn>0</mn></msub></math>，而是在*X*在526到531之间时拒绝<math><msub><mi>H</mi> <mn>0</mn></msub></math>（如果<math><msub><mi>H</mi>
    <mn>1</mn></msub></math>为真的话，这有一定可能发生）。
- en: p-Values
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: p-值
- en: An alternative way of thinking about the preceding test involves *p-values*.
    Instead of choosing bounds based on some probability cutoff, we compute the probability—assuming
    <math><msub><mi>H</mi> <mn>0</mn></msub></math> is true—that we would see a value
    at least as extreme as the one we actually observed.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对前述测试的另一种思考方式涉及*p值*。我们不再基于某个概率截断选择边界，而是计算概率——假设<math><msub><mi>H</mi> <mn>0</mn></msub></math>为真——我们会看到一个至少与我们实际观察到的值一样极端的值的概率。
- en: 'For our two-sided test of whether the coin is fair, we compute:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的双边测试，检验硬币是否公平，我们计算：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If we were to see 530 heads, we would compute:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看到530次正面朝上，我们会计算：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Why did we use a value of `529.5` rather than using `530`? This is what’s called
    a [*continuity correction*](http://en.wikipedia.org/wiki/Continuity_correction).
    It reflects the fact that `normal_probability_between(529.5, 530.5, mu_0, sigma_0)`
    is a better estimate of the probability of seeing 530 heads than `normal_probability_between(530,
    531, mu_0, sigma_0)` is.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们使用`529.5`而不是`530`？这就是所谓的[*连续性校正*](http://en.wikipedia.org/wiki/Continuity_correction)。这反映了`normal_probability_between(529.5,
    530.5, mu_0, sigma_0)`比`normal_probability_between(530, 531, mu_0, sigma_0)`更好地估计看到530枚硬币正面的概率。
- en: Correspondingly, `normal_probability_above(529.5, mu_0, sigma_0)` is a better
    estimate of the probability of seeing at least 530 heads. You may have noticed
    that we also used this in the code that produced [Figure 6-4](ch06.html#make_hist_result).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 相应地，`normal_probability_above(529.5, mu_0, sigma_0)`更好地估计了至少看到530枚硬币正面的概率。你可能已经注意到，我们在生成[图 6-4](ch06.html#make_hist_result)的代码中也使用了这个。
- en: 'One way to convince yourself that this is a sensible estimate is with a simulation:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 说服自己这是一个明智的估计的一种方法是通过模拟：
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Since the *p*-value is greater than our 5% significance, we don’t reject the
    null. If we instead saw 532 heads, the *p*-value would be:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于*p*-值大于我们的5%显著性水平，我们不拒绝零假设。如果我们看到532枚硬币正面，*p*-值将是：
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: which is smaller than the 5% significance, which means we would reject the null.
    It’s the exact same test as before. It’s just a different way of approaching the
    statistics.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这比5%的显著性水平还要小，这意味着我们将拒绝零假设。这和之前完全一样的检验，只是统计学上的不同方法而已。
- en: 'Similarly, we would have:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们会得到：
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'For our one-sided test, if we saw 525 heads we would compute:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的单边检验，如果我们看到525枚硬币正面，我们会计算：
- en: '[PRE12]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'which means we wouldn’t reject the null. If we saw 527 heads, the computation
    would be:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们不会拒绝零假设。如果我们看到527枚硬币正面，计算将是：
- en: '[PRE13]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: and we would reject the null.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将拒绝零假设。
- en: Warning
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Make sure your data is roughly normally distributed before using `normal_probability_above`
    to compute *p*-values. The annals of bad data science are filled with examples
    of people opining that the chance of some observed event occurring at random is
    one in a million, when what they really mean is “the chance, assuming the data
    is distributed normally,” which is fairly meaningless if the data isn’t.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`normal_probability_above`计算*p*-值之前，请确保你的数据大致服从正态分布。糟糕的数据科学充满了人们声称某些观察到的事件在随机发生的机会是百万分之一的例子，当他们真正的意思是“机会，假设数据是正态分布的”，如果数据不是的话，这是相当毫无意义的。
- en: There are various statistical tests for normality, but even plotting the data
    is a good start.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种检验正态性的统计方法，但即使是绘制数据也是一个很好的开始。
- en: Confidence Intervals
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 置信区间
- en: We’ve been testing hypotheses about the value of the heads probability *p*,
    which is a *parameter* of the unknown “heads” distribution. When this is the case,
    a third approach is to construct a *confidence interval* around the observed value
    of the parameter.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在测试关于硬币正面概率*p*值的假设，这是未知“正面”分布的一个*参数*。在这种情况下，第三种方法是围绕参数的观察值构建一个*置信区间*。
- en: For example, we can estimate the probability of the unfair coin by looking at
    the average value of the Bernoulli variables corresponding to each flip—1 if heads,
    0 if tails. If we observe 525 heads out of 1,000 flips, then we estimate *p* equals
    0.525.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以通过观察与每次翻转相对应的伯努利变量的平均值来估计不公平硬币的概率—如果是正面则为1，如果是反面则为0。如果我们在1,000次翻转中观察到525枚硬币正面，则我们估计*p*等于0.525。
- en: 'How *confident* can we be about this estimate? Well, if we knew the exact value
    of *p*, the central limit theorem (recall [“The Central Limit Theorem”](ch06.html#central_limit_theorem))
    tells us that the average of those Bernoulli variables should be approximately
    normal, with mean *p* and standard deviation:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对这个估计有多么*有信心*？嗯，如果我们知道*p*的确切值，那么中心极限定理（回顾[“中心极限定理”](ch06.html#central_limit_theorem)）告诉我们，这些伯努利变量的平均值应该近似正态分布，均值为*p*，标准差为：
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here we don’t know *p*, so instead we use our estimate:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们不知道*p*的值，所以我们使用我们的估计值：
- en: '[PRE15]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This is not entirely justified, but people seem to do it anyway. Using the
    normal approximation, we conclude that we are “95% confident” that the following
    interval contains the true parameter *p*:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不完全合理，但人们似乎仍然这样做。使用正态近似，我们得出“95%的置信度”下以下区间包含真实参数*p*的结论：
- en: '[PRE16]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This is a statement about the *interval*, not about *p*. You should understand
    it as the assertion that if you were to repeat the experiment many times, 95%
    of the time the “true” parameter (which is the same every time) would lie within
    the observed confidence interval (which might be different every time).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于*区间*而不是关于*p*的说法。你应该理解它是这样的断言：如果你重复进行实验很多次，那么95%的时间，“真实”的参数（每次都相同）会落在观察到的置信区间内（每次可能不同）。
- en: In particular, we do not conclude that the coin is unfair, since 0.5 falls within
    our confidence interval.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们不会得出硬币不公平的结论，因为0.5位于我们的置信区间内。
- en: 'If instead we’d seen 540 heads, then we’d have:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看到了540次正面，那么我们将会：
- en: '[PRE17]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Here, “fair coin” doesn’t lie in the confidence interval. (The “fair coin” hypothesis
    doesn’t pass a test that you’d expect it to pass 95% of the time if it were true.)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，“公平硬币”的置信区间中不存在。（如果真的是公平硬币假设，它不会通过一个测试。）
- en: p-Hacking
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: p-操纵
- en: 'A procedure that erroneously rejects the null hypothesis only 5% of the time
    will—by definition—5% of the time erroneously reject the null hypothesis:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一个过程，只有5%的时间错误地拒绝原假设，按定义来说：
- en: '[PRE18]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: What this means is that if you’re setting out to find “significant” results,
    you usually can. Test enough hypotheses against your dataset, and one of them
    will almost certainly appear significant. Remove the right outliers, and you can
    probably get your *p*-value below 0.05\. (We did something vaguely similar in
    [“Correlation”](ch05.html#correlation); did you notice?)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，如果你试图找到“显著”结果，通常你可以找到。对数据集测试足够多的假设，几乎肯定会出现一个显著结果。移除正确的异常值，你可能会将*p*-值降低到0.05以下。（我们在[“相关性”](ch05.html#correlation)中做了类似的事情；你注意到了吗？）
- en: This is sometimes called [*p-hacking*](https://www.nature.com/news/scientific-method-statistical-errors-1.14700)
    and is in some ways a consequence of the “inference from *p*-values framework.”
    A good article criticizing this approach is [“The Earth Is Round”](http://www.iro.umontreal.ca/~dift3913/cours/papers/cohen1994_The_earth_is_round.pdf),
    by Jacob Cohen.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这有时被称为[*p-操纵*](https://www.nature.com/news/scientific-method-statistical-errors-1.14700)，在某种程度上是“从*p*-值框架推断”的结果。一篇批评这种方法的好文章是[“地球是圆的”](http://www.iro.umontreal.ca/~dift3913/cours/papers/cohen1994_The_earth_is_round.pdf)，作者是雅各布·科恩。
- en: If you want to do good *science*, you should determine your hypotheses before
    looking at the data, you should clean your data without the hypotheses in mind,
    and you should keep in mind that *p*-values are not substitutes for common sense.
    (An alternative approach is discussed in [“Bayesian Inference”](#bayesian_inference).)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想进行良好的*科学*研究，你应该在查看数据之前确定你的假设，清理数据时不要考虑假设，并且要记住*p*-值并不能替代常识。（另一种方法在[“贝叶斯推断”](#bayesian_inference)中讨论。）
- en: 'Example: Running an A/B Test'
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 例如：运行A/B测试
- en: One of your primary responsibilities at DataSciencester is experience optimization,
    which is a euphemism for trying to get people to click on advertisements. One
    of your advertisers has developed a new energy drink targeted at data scientists,
    and the VP of Advertisements wants your help choosing between advertisement A
    (“tastes great!”) and advertisement B (“less bias!”).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你在DataSciencester的主要职责之一是体验优化，这是一个试图让人们点击广告的委婉说法。你的一个广告客户开发了一种新的面向数据科学家的能量饮料，广告部副总裁希望你帮助选择广告A（“味道棒！”）和广告B（“更少偏见！”）之间的区别。
- en: Being a *scientist*, you decide to run an *experiment* by randomly showing site
    visitors one of the two advertisements and tracking how many people click on each
    one.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 作为*科学家*，你决定通过随机向站点访问者展示两个广告，并跟踪点击每个广告的人数来运行*实验*。
- en: If 990 out of 1,000 A-viewers click their ad, while only 10 out of 1,000 B-viewers
    click their ad, you can be pretty confident that A is the better ad. But what
    if the differences are not so stark? Here’s where you’d use statistical inference.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在1,000个A观众中有990个点击他们的广告，而在1,000个B观众中只有10个点击他们的广告，你可以相当有信心认为A是更好的广告。但如果差异不那么明显呢？这就是你会使用统计推断的地方。
- en: Let’s say that <math><msub><mi>N</mi> <mn>A</mn></msub></math> people see ad
    A, and that <math><msub><mi>n</mi> <mn>A</mn></msub></math> of them click it.
    We can think of each ad view as a Bernoulli trial where <math><msub><mi>p</mi>
    <mn>A</mn></msub></math> is the probability that someone clicks ad A. Then (if
    <math><msub><mi>N</mi> <mn>A</mn></msub></math> is large, which it is here) we
    know that <math><mrow><msub><mi>n</mi> <mi>A</mi></msub> <mo>/</mo> <msub><mi>N</mi>
    <mi>A</mi></msub></mrow></math> is approximately a normal random variable with
    mean <math><msub><mi>p</mi> <mi>A</mi></msub></math> and standard deviation <math><mrow><msub><mi>σ</mi>
    <mi>A</mi></msub> <mo>=</mo> <msqrt><mrow><msub><mi>p</mi> <mi>A</mi></msub> <mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <msub><mi>p</mi> <mi>A</mi></msub> <mo>)</mo></mrow> <mo>/</mo>
    <msub><mi>N</mi> <mi>A</mi></msub></mrow></msqrt></mrow></math> .
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 假设<math><msub><mi>N</mi> <mn>A</mn></msub></math>人看到广告A，并且其中<math><msub><mi>n</mi>
    <mn>A</mn></msub></math>人点击了它。我们可以将每次广告浏览视为伯努利试验，其中<math><msub><mi>p</mi> <mn>A</mn></msub></math>是某人点击广告A的概率。那么（如果<math><msub><mi>N</mi>
    <mn>A</mn></msub></math>很大，这里是这样），我们知道<math><mrow><msub><mi>n</mi> <mi>A</mi></msub>
    <mo>/</mo> <msub><mi>N</mi> <mi>A</mi></msub></mrow></math>大致上是一个均值为<math><msub><mi>p</mi>
    <mi>A</mi></msub></math>，标准差为<math><mrow><msub><mi>σ</mi> <mi>A</mi></msub> <mo>=</mo>
    <msqrt><mrow><msub><mi>p</mi> <mi>A</mi></msub> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo>
    <msub><mi>p</mi> <mi>A</mi></msub> <mo>)</mo></mrow> <mo>/</mo> <msub><mi>N</mi>
    <mi>A</mi></msub></mrow></msqrt></mrow></math>的正态随机变量。
- en: 'Similarly, <math><mrow><msub><mi>n</mi> <mi>B</mi></msub> <mo>/</mo> <msub><mi>N</mi>
    <mi>B</mi></msub></mrow></math> is approximately a normal random variable with
    mean <math><msub><mi>p</mi> <mi>B</mi></msub></math> and standard deviation <math><mrow><msub><mi>σ</mi>
    <mi>B</mi></msub> <mo>=</mo> <msqrt><mrow><msub><mi>p</mi> <mi>B</mi></msub> <mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <msub><mi>p</mi> <mi>B</mi></msub> <mo>)</mo></mrow> <mo>/</mo>
    <msub><mi>N</mi> <mi>B</mi></msub></mrow></msqrt></mrow></math> . We can express
    this in code as:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，<math><mrow><msub><mi>n</mi> <mi>B</mi></msub> <mo>/</mo> <msub><mi>N</mi>
    <mi>B</mi></msub></mrow></math>大致上是一个均值为<math><msub><mi>p</mi> <mi>B</mi></msub></math>，标准差为<math><mrow><msub><mi>σ</mi>
    <mi>B</mi></msub> <mo>=</mo> <msqrt><mrow><msub><mi>p</mi> <mi>B</mi></msub> <mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <msub><mi>p</mi> <mi>B</mi></msub> <mo>)</mo></mrow> <mo>/</mo>
    <msub><mi>N</mi> <mi>B</mi></msub></mrow></msqrt></mrow></math>。我们可以用代码表示这个过程：
- en: '[PRE19]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: If we assume those two normals are independent (which seems reasonable, since
    the individual Bernoulli trials ought to be), then their difference should also
    be normal with mean <math><mrow><msub><mi>p</mi> <mi>B</mi></msub> <mo>-</mo>
    <msub><mi>p</mi> <mi>A</mi></msub></mrow></math> and standard deviation <math><msqrt><mrow><msubsup><mi>σ</mi>
    <mi>A</mi> <mn>2</mn></msubsup> <mo>+</mo> <msubsup><mi>σ</mi> <mi>B</mi> <mn>2</mn></msubsup></mrow></msqrt></math>
    .
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们假设这两个正态分布是独立的（这似乎是合理的，因为单个伯努利试验应该是独立的），那么它们的差异也应该是均值为<math><mrow><msub><mi>p</mi>
    <mi>B</mi></msub> <mo>-</mo> <msub><mi>p</mi> <mi>A</mi></msub></mrow></math>，标准差为<math><msqrt><mrow><msubsup><mi>σ</mi>
    <mi>A</mi> <mn>2</mn></msubsup> <mo>+</mo> <msubsup><mi>σ</mi> <mi>B</mi> <mn>2</mn></msubsup></mrow></msqrt></math>。
- en: Note
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This is sort of cheating. The math only works out exactly like this if you *know*
    the standard deviations. Here we’re estimating them from the data, which means
    that we really should be using a *t*-distribution. But for large enough datasets,
    it’s close enough that it doesn’t make much of a difference.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这有点作弊。只有当您*知道*标准偏差时，数学才能完全工作。在这里，我们是从数据中估计它们，这意味着我们确实应该使用*t*分布。但是对于足够大的数据集，它接近标准正态分布，所以差别不大。
- en: 'This means we can test the *null hypothesis* that <math><msub><mi>p</mi> <mi>A</mi></msub></math>
    and <math><msub><mi>p</mi> <mi>B</mi></msub></math> are the same (that is, that
    <math><mrow><msub><mi>p</mi> <mi>A</mi></msub> <mo>-</mo> <msub><mi>p</mi> <mi>B</mi></msub></mrow></math>
    is 0) by using the statistic:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以测试*零假设*，即<math><msub><mi>p</mi> <mi>A</mi></msub></math>和<math><msub><mi>p</mi>
    <mi>B</mi></msub></math>相同（即<math><mrow><msub><mi>p</mi> <mi>A</mi></msub> <mo>-</mo>
    <msub><mi>p</mi> <mi>B</mi></msub></mrow></math>为0），使用的统计量是：
- en: '[PRE20]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: which should approximately be a standard normal.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 应该大约是一个标准正态分布。
- en: 'For example, if “tastes great” gets 200 clicks out of 1,000 views and “less
    bias” gets 180 clicks out of 1,000 views, the statistic equals:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果“味道好”的广告在1,000次浏览中获得了200次点击，“更少偏见”的广告在1,000次浏览中获得了180次点击，则统计量等于：
- en: '[PRE21]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The probability of seeing such a large difference if the means were actually
    equal would be:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果实际上平均值相等，观察到这么大差异的概率将是：
- en: '[PRE22]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'which is large enough that we can’t conclude there’s much of a difference.
    On the other hand, if “less bias” only got 150 clicks, we’d have:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概率足够大，我们无法得出有太大差异的结论。另一方面，如果“更少偏见”的点击仅为150次，则有：
- en: '[PRE23]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: which means there’s only a 0.003 probability we’d see such a large difference
    if the ads were equally effective.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着如果广告效果相同，我们看到这么大的差异的概率只有0.003。
- en: Bayesian Inference
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯推断
- en: 'The procedures we’ve looked at have involved making probability statements
    about our *tests*: e.g., “There’s only a 3% chance you’d observe such an extreme
    statistic if our null hypothesis were true.”'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所看到的程序涉及对我们的*测试*做出概率陈述：例如，“如果我们的零假设成立，你观察到如此极端的统计量的概率只有3%”。
- en: An alternative approach to inference involves treating the unknown parameters
    themselves as random variables. The analyst (that’s you) starts with a *prior
    distribution* for the parameters and then uses the observed data and Bayes’s theorem
    to get an updated *posterior distribution* for the parameters. Rather than making
    probability judgments about the tests, you make probability judgments about the
    parameters.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 推理的另一种方法涉及将未知参数本身视为随机变量。分析员（也就是你）从参数的*先验分布*开始，然后使用观察到的数据和贝叶斯定理来获得参数的更新*后验分布*。与对测试进行概率判断不同，你对参数进行概率判断。
- en: 'For example, when the unknown parameter is a probability (as in our coin-flipping
    example), we often use a prior from the *Beta distribution*, which puts all its
    probability between 0 and 1:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当未知参数是概率时（如我们抛硬币的示例），我们通常使用*Beta分布*中的先验，该分布将其所有概率都放在0和1之间：
- en: '[PRE24]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Generally speaking, this distribution centers its weight at:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，这个分布将其权重集中在：
- en: '[PRE25]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: and the larger `alpha` and `beta` are, the “tighter” the distribution is.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 而且`alpha`和`beta`越大，分布就越“紧密”。
- en: For example, if `alpha` and `beta` are both 1, it’s just the uniform distribution
    (centered at 0.5, very dispersed). If `alpha` is much larger than `beta`, most
    of the weight is near 1\. And if `alpha` is much smaller than `beta`, most of
    the weight is near 0\. [Figure 7-1](#beta_priors) shows several different Beta
    distributions.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果`alpha`和`beta`都为1，那就是均匀分布（以0.5为中心，非常分散）。如果`alpha`远大于`beta`，大部分权重都集中在1附近。如果`alpha`远小于`beta`，大部分权重都集中在0附近。[图7-1](#beta_priors)展示了几种不同的Beta分布。
- en: '![Example Beta distributions.](assets/dsf2_0701.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![示例Beta分布。](assets/dsf2_0701.png)'
- en: Figure 7-1\. Example Beta distributions
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1。示例Beta分布
- en: Say we assume a prior distribution on *p*. Maybe we don’t want to take a stand
    on whether the coin is fair, and we choose `alpha` and `beta` to both equal 1\.
    Or maybe we have a strong belief that the coin lands heads 55% of the time, and
    we choose `alpha` equals 55, `beta` equals 45.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们对*p*有一个先验分布。也许我们不想对硬币是否公平发表立场，我们选择`alpha`和`beta`都等于1。或者我们非常相信硬币55%的时间会正面朝上，我们选择`alpha`等于55，`beta`等于45。
- en: Then we flip our coin a bunch of times and see *h* heads and *t* tails. Bayes’s
    theorem (and some mathematics too tedious for us to go through here) tells us
    that the posterior distribution for *p* is again a Beta distribution, but with
    parameters `alpha + h` and `beta + t`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们多次抛硬币，看到*h*次正面和*t*次反面。贝叶斯定理（以及一些在这里过于繁琐的数学）告诉我们*p*的后验分布再次是Beta分布，但参数为`alpha
    + h`和`beta + t`。
- en: Note
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: It is no coincidence that the posterior distribution was again a Beta distribution.
    The number of heads is given by a Binomial distribution, and the Beta is the [*conjugate
    prior*](http://www.johndcook.com/blog/conjugate_prior_diagram/) to the Binomial
    distribution. This means that whenever you update a Beta prior using observations
    from the corresponding binomial, you will get back a Beta posterior.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 后验分布再次是Beta分布并非巧合。头数由二项式分布给出，而Beta是与二项式分布[*共轭先验*](http://www.johndcook.com/blog/conjugate_prior_diagram/)。这意味着每当您使用相应的二项式观察更新Beta先验时，您将得到一个Beta后验。
- en: Let’s say you flip the coin 10 times and see only 3 heads. If you started with
    the uniform prior (in some sense refusing to take a stand about the coin’s fairness),
    your posterior distribution would be a Beta(4, 8), centered around 0.33\. Since
    you considered all probabilities equally likely, your best guess is close to the
    observed probability.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你抛了10次硬币，只看到3次正面。如果你从均匀先验开始（在某种意义上拒绝对硬币的公平性发表立场），你的后验分布将是一个Beta(4, 8)，中心在0.33左右。由于你认为所有概率都是同等可能的，你的最佳猜测接近观察到的概率。
- en: If you started with a Beta(20, 20) (expressing a belief that the coin was roughly
    fair), your posterior distribution would be a Beta(23, 27), centered around 0.46,
    indicating a revised belief that maybe the coin is slightly biased toward tails.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你最初使用一个Beta(20, 20)（表达了一种认为硬币大致公平的信念），你的后验分布将是一个Beta(23, 27)，中心在0.46左右，表明修正后的信念可能硬币稍微偏向反面。
- en: And if you started with a Beta(30, 10) (expressing a belief that the coin was
    biased to flip 75% heads), your posterior distribution would be a Beta(33, 17),
    centered around 0.66\. In that case you’d still believe in a heads bias, but less
    strongly than you did initially. These three different posteriors are plotted
    in [Figure 7-2](#beta_posteriors).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你最初假设一个Beta(30, 10)（表达了一种认为硬币有75%概率翻转为正面的信念），你的后验分布将是一个Beta(33, 17)，中心在0.66左右。在这种情况下，你仍然相信硬币有正面的倾向，但不像最初那样强烈。这三种不同的后验分布在[图 7-2](#beta_posteriors)中绘制出来。
- en: '![Posteriors arising from different priors.](assets/dsf2_0702.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![来自不同先验的后验分布。](assets/dsf2_0702.png)'
- en: Figure 7-2\. Posteriors arising from different priors
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-2。来自不同先验的后验分布
- en: If you flipped the coin more and more times, the prior would matter less and
    less until eventually you’d have (nearly) the same posterior distribution no matter
    which prior you started with.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不断地翻转硬币，先验的影响将越来越小，最终你将拥有（几乎）相同的后验分布，无论你最初选择了哪个先验。
- en: For example, no matter how biased you initially thought the coin was, it would
    be hard to maintain that belief after seeing 1,000 heads out of 2,000 flips (unless
    you are a lunatic who picks something like a Beta(1000000,1) prior).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，无论你最初认为硬币有多么偏向正面，看到2000次翻转中有1000次正面后，很难维持那种信念（除非你选择像Beta(1000000,1)这样的先验，这是疯子的行为）。
- en: 'What’s interesting is that this allows us to make probability statements about
    hypotheses: “Based on the prior and the observed data, there is only a 5% likelihood
    the coin’s heads probability is between 49% and 51%.” This is philosophically
    very different from a statement like “If the coin were fair, we would expect to
    observe data so extreme only 5% of the time.”'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，这使我们能够对假设进行概率性陈述：“基于先验和观察数据，硬币的正面概率在49%到51%之间的可能性仅为5%。”这在哲学上与“如果硬币是公平的，我们预期观察到极端数据的概率也仅为5%”这样的陈述有很大的不同。
- en: Using Bayesian inference to test hypotheses is considered somewhat controversial—in
    part because the mathematics can get somewhat complicated, and in part because
    of the subjective nature of choosing a prior. We won’t use it any further in this
    book, but it’s good to know about.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 使用贝叶斯推断来测试假设在某种程度上被认为是有争议的——部分原因是因为数学可以变得相当复杂，部分原因是因为选择先验的主观性质。我们在本书中不会进一步使用它，但了解这一点是很好的。
- en: For Further Exploration
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步探索
- en: We’ve barely scratched the surface of what you should know about statistical
    inference. The books recommended at the end of [Chapter 5](ch05.html#statistics)
    go into a lot more detail.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们只是浅尝辄止地探讨了统计推断中你应该了解的内容。第五章末推荐的书籍详细讨论了这些内容。
- en: Coursera offers a [Data Analysis and Statistical Inference](https://www.coursera.org/course/statistics)
    course that covers many of these topics.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Coursera提供了一门[数据分析与统计推断](https://www.coursera.org/course/statistics)课程，涵盖了许多这些主题。
