- en: '7 The CEO Strikes Back: Supercharging our dashboard'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Critically evaluating an app and resolving user feedback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding flexibility to Streamlit visualizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving usability by making commonly-used features easy to access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating modal dialogs in Streamlit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using query parameters to enable deeplinks in a Streamlit app
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When Python was first released, it lacked many of the features we rely on today.
    The Python we know and love has been carefully refined over the years—and that
    process is still ongoing. A big part of this evolution comes from the feedback
    of developers who actively build with the language.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, no software is perfect at launch. Instead, it is refined over time,
    with a bugfix here and a new feature added there. The projects we build in this
    book are no exception.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we created a metrics dashboard for a company called
    Note n' Nib. In this one, we'll skip forward and see how users responded. We'll
    use their opinions and comments to revisit our app in a critical light and improve
    it. As we go through this process, we'll learn more about Streamlit visualizations,
    introduce modal dialogs and query parameters, and understand how to program an
    advanced, flexible dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: If Chapter 6 was about *launching* a dashboard based on user requirements, Chapter
    7 is about *landing* it, addressing our users' concerns and iterating on the app
    to ensure quality and satisfaction.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Feedback on the dashboard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dashboard you built in the last chapter has made waves at Note n' Nib. For
    the first time, the company's executives can look up updated sales numbers, compare
    performance between products, and analyze trends on their own, without having
    to enlist help from Engineering.
  prefs: []
  type: TYPE_NORMAL
- en: The CEO has requested that all staff meetings start with a review of the key
    sales metrics, which means that the top brass is now intimately familiar with
    your dashboard. Of course, with that kind of attention comes increased scrutiny,
    and you're not entirely surprised when, one Monday afternoon a few weeks after
    launch, you find an email from the CEO in your inbox.
  prefs: []
  type: TYPE_NORMAL
- en: The email contains collated feedback about your dashboard from the higher-ups—essentially
    a wishlist of additional features for you to implement.
  prefs: []
  type: TYPE_NORMAL
- en: Well, there goes the rest of your week. You're excited about the work, though,
    since you get to play with Streamlit some more! Over the course of this chapter,
    we'll inspect and resolve each item of feedback.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Granularity in the time series chart
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first bullet point in the email reads: "The time chart is useful in reviewing
    a few days of data, but it''s hard to make sense of for longer periods".'
  prefs: []
  type: TYPE_NORMAL
- en: Recall that our dashboard has a line chart showing a selected metric's evolution
    over time. For smaller date ranges (about a month or so), it works reasonably
    well (see the left side of figure 7.1), but for longer ones (say a year or more),
    it looks like the right side.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image001.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 The day granularity in the existing time chart works for small time
    frames like a month (left) but not for longer time frames (right)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: All the data is there, but there's so much of it that it's overwhelming. When
    considering *years* of data, we don't need to plot a single point for every date
    in the range.
  prefs: []
  type: TYPE_NORMAL
- en: You can see how doing so increases the number of individual markers in the chart;
    if we're observing a date range of two years, that's 365 x 2 = 730 points—far
    too many to interpret.
  prefs: []
  type: TYPE_NORMAL
- en: So, how do we address this? A granularity of a single day is too much over a
    longer time horizon, but if we have a shorter date range, like a week or a month,
    it's reasonable. For longer ranges, we would probably want one marker for a week,
    a month, or perhaps even a year.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest solution would be to allow the user to pick the granularity they
    want. Let's tackle this now.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.1 Enabling different time grains
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To enable weekly, monthly, and yearly granularities, we first have to ensure
    our data *has* those fields, which it doesn't currently. Once we do, we'll be
    able to aggregate each metric to the right grain.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that the flow of data in our app starts with the `load_data` function
    in `data_loader.py`, which obtains the data from an external source, currently
    a CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by `prep_data` in `data_wrangling.py` where we rename the columns
    and add the `Day` field. This is also where we need to make changes to incorporate
    the other grains we want.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go ahead and edit `prep_data` so it now looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re adding three new columns to the Pandas dataframe: `Week`, `Month` and
    `Year`. To obtain each field, we start with the `Day` column (`df[''Day'']`),
    convert it to a period, and then convert the result to a timestamp. Consider one
    such statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`.dt` here is used to access the date/time-related properties of the column
    in an element-wise manner. `to_period(''M'')` converts the `Day` column into a
    monthly "period" type internal to Pandas, representing a whole month rather than
    a specific point in time.'
  prefs: []
  type: TYPE_NORMAL
- en: We then use a second `.dt` accessor to get the date/time properties of the transformed
    column, and finally `.to_timestamp()` to convert each monthly period into a date
    representing the start of the month.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if one of the elements we're operating on in `df['Day']` is the
    date `2024-07-12`, we end up with the date `2024-07-01`, the start of the corresponding
    month.
  prefs: []
  type: TYPE_NORMAL
- en: The other two statements that create the `Week` and `Year` columns are analogous,
    adding dates representing the start of the week and the year respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Elsewhere in the code—specifically within (other) functions in `data_wrangling.py`
    and `time_series_chart.py`—we've been treating `Day` as a hardcoded column name.
    Once we have these other columns, all we need to do in the backend is to introduce
    a variable to represent the grain instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the function `get_metric_time_series` from `data_wrangling.py` would now
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'And `get_time_series_chart` (in `time_series_chart.py`) becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In both cases, we''re making the same changes: adding `grain` as a new parameter
    in the function, and replacing `''Day''` wherever it occurs to `grain`.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.2 Creating a time grain selector
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we've wired up the functions that ultimately generate the time series
    chart to handle `grain` as a variable, we need to provide the user with a way
    to select what grain they want.
  prefs: []
  type: TYPE_NORMAL
- en: st.select_slider
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let''s use a new Streamlit widget for this: `st.select_slider`, another selection
    element. `st.select_slider` is a cross between `st.selectbox`, which lets you
    pick a single value from a dropdown, and `st.slider`, which lets you choose a
    numeric value.'
  prefs: []
  type: TYPE_NORMAL
- en: You use it when you have a list of text options for users to pick from, but
    also want to impose some ordering on them. For instance, when you're creating
    options for a survey, "Strongly agree", "Agree", "Neutral", "Disagree", and "Strongly
    disagree" are strings, but they have a specific order to them—from the most to
    the least agreement.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, the time grain options we want the user to see—"Day," "Week," "Month,"
    and "Year"—also have an order, from the smallest unit of time to the largest.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our purposes, we can use `st.select_slider` like this within the `time_series_chart`
    function in `time_series_chart.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`grain_options` here holds the ordered list of options, and is fed to the second
    parameter of `st.select_slider`, the first being the label to display. You''ll
    find these parameters very similar to those of `st.selectbox` and `st.radio`.
    `st.select_slider` returns the option selected by the user, which we store in
    `grain`, and pass as the new parameter we recently added to `get_time_series_chart`.'
  prefs: []
  type: TYPE_NORMAL
- en: Save and run your app with `streamlit run <path to dashboard.py>` to get figure
    7.2
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image002.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 The line chart now has a time grain selector (see chapter_7/in_progress_01
    in the GitHub repo for the full code at this point)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Play around with the grain selector. Using the month grain makes the chart much
    more palatable when viewing a long date range spanning multiple years.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3 Interdependent filters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '"If I''ve already selected the ''Writing tools'' category, why does it still
    ask me if I want to see staples and calendars?" asks a verbatim comment in the
    email, reportedly from the CFO, one of the dashboard''s more passionate users.'
  prefs: []
  type: TYPE_NORMAL
- en: You admit it's a valid question. She's referring to the filter bar in figure
    7.3, which doesn't take the existing selections into account while displaying
    options in the filter dropdowns, leading to nonsensical combinations such as "Writing
    tools" paired with "Paper clips."
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image003.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 The filter bar options can have mismatching combinations
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The filter bar isn't "intelligent". Filtering on a product category doesn't
    update the options available to the user in the segment and product name filters,
    even if those segments and products don't belong to the selected category.
  prefs: []
  type: TYPE_NORMAL
- en: If a user filters the data for "Writing tools", it's a bit annoying to still
    see all the other product lines (like "Paper clips") in the segment dropdown.
    The example data we've been using only has ten products overall, so it isn't a
    dealbreaker per se, but consider the situation where there are hundreds. At that
    point, using the higher levels in the product hierarchy (like "category") to filter
    out irrelevant products from the other dropdowns becomes a necessary feature,
    not a nice-to-have.
  prefs: []
  type: TYPE_NORMAL
- en: Let's consider how to fix this.
  prefs: []
  type: TYPE_NORMAL
- en: One possibility is to record the interdependencies between the dimensions, and
    then look up and resolve those dependencies while obtaining the unique values
    for each field. For example, since `Product name` should depend on the selections
    for `Category` and `Segment`, we might record that dependency somewhere.
  prefs: []
  type: TYPE_NORMAL
- en: This requires us to maintain a new configuration and the logic could get fairly
    involved.
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s an easier alternative: rather than obtaining all the unique filter
    values first and *then* filtering the dataframe (figure 7.4), we could get the
    unique values for the first filter, apply the filter to get a new dataframe, get
    the unique values for the second filter, apply that one too, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image004.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4 Old filtering approach: Get unique values for all filters first,
    then filter based on selections'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In the new approach (figure 7.5), since we filter the data frame before getting
    the unique values for the next filter, we're guaranteed to show only the available
    values.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image005.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.5 New filtering approach: Get unique values for each filter, apply
    filter based on selection, then repeat for other filters'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: So when a user selects the category `"Writing tools"` the dataframe is filtered
    to only include those rows, and the unique values for the segment filter are drawn
    from this new set, which won't include staplers and the like.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement this, modify `filter_panel`.py:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The changes aren't too complicated. In each iteration through the filter fields,
    rather than passing `df` directly to `get_unique_values` to get the set of dropdown
    options to display, we introduce a variable called `effective_df` and pass that.
  prefs: []
  type: TYPE_NORMAL
- en: In line with our explanation of the approach, `effective_df` is recomputed in
    each loop iteration by applying the filters we have so far (we import `apply_filters`
    at the top for this purpose).
  prefs: []
  type: TYPE_NORMAL
- en: Go ahead and re-run your app! Figure 7.6 shows what happens when you select
    `"Writing tools"` as the only category you're interested in.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image006.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 The filter bar only shows valid option combinations (see chapter_7/in_progress_02
    in the GitHub repo for the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As expected, the `Segment` filter now only shows writing instruments.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The *order* of the filters is now meaningful. If the Category filter were to
    be placed *after* Segment, choosing a category would have no effect on Segment
    because the unique values for Segment would already have been computed by the
    time the selected Category values are evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: 7.4 Date range comparisons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another piece of feedback comes from one of the product line chiefs, who posted
    a screenshot (figure 7.7) to illustrate her point: "I can see that sales for RoyalQuill
    were $1.32M for July. But is that good or bad? How did we do last year?"'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image007.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 Sales for RoyalQuill were $1.32M but there's no indication of whether
    that's good, or what the sales were in a previous comparable period
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Often, the hard part about analyzing data is not obtaining or transforming it
    but *contextualizing* it. A metric by itself doesn't mean much. To make it useful,
    you have to be able to *compare* it to something. If we know sales for a product
    are $1m in a year, the decisions we would make if we knew that last year's sales
    were $10m are very different from those we'd make if last year's sales were only
    $100k.
  prefs: []
  type: TYPE_NORMAL
- en: Our dashboard doesn't currently offer an easy way to make this comparison.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, when we see a metric for a certain time period, we should also be able
    to tell how it's *changed* as compared to the past. In this section, we'll explore
    this requirement more deeply and incorporate it into our dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.1 Adding another date range selector
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: What exactly does it mean to compare a metric to its past value? What start
    date and end date do we use for "the past"? Let's consider some frequently-accessed
    comparisons that users may be interested in.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if the user is viewing the total sales for August 1 to August
    15, 2024, there's a good chance that they might want to see how that compares
    to the same dates in the previous month, i.e. July 1 to July 15, 2024\. This is
    called a "month-over-month" comparison, often abbreviated to "MoM".
  prefs: []
  type: TYPE_NORMAL
- en: 'Other similar comparisons the user might want to make are QoQ ("quarter-over-quarter")
    and YoY ("year-over-year"), which are both similar to MoM. QoQ means comparing
    to analogous dates in the previous quarter. For example, August 1 to August 15
    represents the first 15 days of the second month of Q3, so QoQ would compare this
    to the first 15 days of the second month of *Q2*, or exactly three months earlier:
    May 1 to May 15.'
  prefs: []
  type: TYPE_NORMAL
- en: YoY should be obvious—it's the date range that's exactly a year in the past,
    so August 1 to August 15, *2023* for our example.
  prefs: []
  type: TYPE_NORMAL
- en: Another type of comparison an executive might want to make is against the immediately
    prior X days, where X is the number of days in the currently selected main date
    range.
  prefs: []
  type: TYPE_NORMAL
- en: So, if the main range is August 1 to August 15, the "previous period" would
    be the 15 days immediately preceding August 1, i.e. July 17 to July 31.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now implement these commonly-accessed comparisons. We start by updating
    our `date_range_panel` function in `date_range_panel.py` to incorporate a comparison
    selector and return two more dates to the caller (`dashboard.py`, which we''ll
    edit later):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Since the comparison options are discrete values, we use an `st.selectbox` to
    offer users a choice between them, and call a yet-to-be-defined function, `get_compare_range`,
    to get the actual start and end dates of the comparison range.
  prefs: []
  type: TYPE_NORMAL
- en: We also expose these comparison dates to the user in an `st.info` box so the
    user doesn't have to do any calendar math themselves to get that information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s also define the `get_compare_range` function we referenced above (in
    the same file, `date_range_panel.py`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This function accepts three parameters: the start and end dates of the main
    date range, and `comparison`, a string that holds the type of comparison we want
    to perform—as discussed above, this could be `MoM`, `QoQ`, `YoY`, or `Previous
    period`.'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the comparison date range comes down to subtracting the right *offset*
    from both the start and end dates. For example, for an MoM comparison, we need
    to subtract one month from both dates. For QoQ, we subtract 3 months, and for
    YoY, we subtract a year.
  prefs: []
  type: TYPE_NORMAL
- en: For the `Previous period` comparison, we first find the number of days within
    the main date range using `(end - start).days + 1`, and use that as the offset.
  prefs: []
  type: TYPE_NORMAL
- en: 'We store these offsets in a dictionary (called `offsets` in the code above)
    with the comparison name as the key and a Pandas `DateOffset` object as the value.
    We can then obtain the new start and end dates by subtracting the offset from
    each:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Why are the `.date()`s necessary here? Well, if you've been paying particularly
    close attention, you might have realized that `start` and `end` are `datetime.date`
    objects, not Pandas timestamp objects. Pandas makes sure that `pd.DateOffset`
    is compatible with `datetime.date` and that the former can be subtracted from
    the latter, but the result is a Pandas timestamp object. Since we've been trying
    to keep our date ranges `datetime.date` objects elsewhere, we use the `.date()`
    method of the Pandas timestamp class to convert `start - offset` and `end - offset`
    to `datetime.dates`—thus ensuring consistency.
  prefs: []
  type: TYPE_NORMAL
- en: Since the function `date_range_panel` now returns four values (`start`, `end`,
    `compare_start`, and `compare_end`) instead of just two, we need to update the
    code that calls it to reflect this.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code happens to be in `dashboard.py`, within the sidebar. Change it from:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Your app's sidebar should now look like figure 7.8.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image008.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 Sidebar showing a start/end date selector for the main date range
    as well as a "Compare to" input (see chapter_7/in_progress_03 in the GitHub repo
    for the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Though we're not actually doing anything with the comparison date range, you
    can see the new selectors.
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.2 Showing the comparison in the metric bar
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we've collected the date range to compare to the main date range, how
    do we use it to resolve the feedback we received?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider this with an example. Say we have two date ranges: August 1
    to August 31, 2024 (the "main" date range) and July 1 to July 31, 2024 (the comparison
    date range). If we''re comparing the total sales between those ranges, we''ll
    need to calculate them separately for both date ranges and then display the *delta*
    (difference) between them.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the August sales are $5m and those in July are $4m, we would display a delta
    of $1m. Generally speaking, expressing the difference as a percentage of the past
    number is more useful, so the delta is 20% ($4m / $5m x 100). We would show this
    number alongside the August sales to provide a complete picture: Sales in August
    were $5m, up 20% from the previous period.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach requires us to do two things:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate the metric separately for the comparison date frame, keeping everything
    else (mainly the filter values) constant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute the percentage delta and display it with the main metric.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the first part, let''s modify `dashboard.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here, we're obtaining a new Pandas dataframe, `compare_df`, in much the same
    way that we get `main_df`—by passing the raw prepped data to `get_filtered_data_within_date_range`
    with the appropriate start and end dates and filters.
  prefs: []
  type: TYPE_NORMAL
- en: The filters are the same as those used to create `main_df`. This is important
    because if a user has filtered for, say, a particular category and/or gender,
    the comparison they want to see is with the same category and/or gender, just
    for a different date range.
  prefs: []
  type: TYPE_NORMAL
- en: We also pass `compare_df` as a second argument to `metric_bar`, which it doesn't
    support yet, but will when we're done.
  prefs: []
  type: TYPE_NORMAL
- en: To compute and display the percentage delta, the changes we need to make are
    in `metric_bar.py`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by modifying `metric_bar` to accept the extra argument we passed
    in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Earlier, for each metric we needed to display, we would get the formatted value
    using `format_metric` and pass that, along with a title, to `st.metric` for display
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: However, `st.metric` supports showing a delta as well, through its third and
    fourth argument (internally named `delta` and `delta_color`).
  prefs: []
  type: TYPE_NORMAL
- en: The third argument is the formatted number to show as the change (in this case,
    the percentage difference), while the fourth argument, `delta_color`, indicates
    the color scheme to display the delta in.
  prefs: []
  type: TYPE_NORMAL
- en: '`delta_color` can take the values `"normal,"` `"inverse,"` or `"off."` If it''s
    set to `"normal,"` positive deltas are displayed in green, and negative changes
    will be in red. If it''s `"inverse,"` the reverse is true: increases are in red,
    and decreases are green (this is appropriate for metrics where a lower value is
    better, like cost). If it''s `"off,"` Streamlit just shows everything in gray.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we''re calling `st.metric` like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '`"normal"` is appropriate for all of our metrics since a higher value is better
    for all of them (you''d want higher sales, a higher gross margin, a higher margin
    percentage, and a higher average transaction value). For the third argument, we
    pass in `formatted_delta`, which we''re obtaining above by calling a function
    we haven''t defined yet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s go ahead and create `get_formatted_delta`, and any associated functions
    now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve defined two functions: `get_delta` calculates the actual delta, while
    `get_formatted_delta` calls it and formats the result.'
  prefs: []
  type: TYPE_NORMAL
- en: '`get_delta` accepts the value of the main metric, `compare_df`—the comparison
    dataframe we computed in `dashboard.py`—and `metric`, which is the `Metric` object
    that represents the measure we''re trying to show the change in.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The body of `get_delta` isn''t complicated. We use the `get_metric` function
    on `compare_df` to calculate the metric for the comparison date range, and obtain
    the percentage delta as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: At any point, if we realize that a delta can't be displayed (either because
    `compare_df` contains no data or because trying to calculate it would cause a
    divide-by-zero error since the comparison value is zero), we return `None` instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `get_formatted_delta`, we take this returned value and get a formatted version
    of it by calling `format_metric`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Recall from Chapter 6 that `format_metric` (defined in the file `formatting.py`)
    converts a numeric value into a user-friendly string depending on its type. In
    this case, the metric type is a "percent," so format_metric will add a "%" sign
    at the end.
  prefs: []
  type: TYPE_NORMAL
- en: If there's no delta to format (which happens when `get_delta` returns `None`),
    `get_formatted_delta` returns `None` as well.
  prefs: []
  type: TYPE_NORMAL
- en: When this is eventually passed to `st.metric`, Streamlit handles the `None`
    value correctly by not displaying anything at all.
  prefs: []
  type: TYPE_NORMAL
- en: You can now re-run the dashboard to view your updated metric bar (remember to
    choose a comparison date range that we have data for), as shown in figure 7.9.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image009.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 Metric bar showing how each metric has changed from the comparison
    date range (see chapter_7/in_progress_04 in the GitHub repo for the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As you can see, the metric bar now shows how each metric has changed as compared
    to its value in the comparison date range.
  prefs: []
  type: TYPE_NORMAL
- en: Boom! We've addressed another key piece of feedback and are well on our way
    to version 2.0 of our dashboard! Let's see what else the email has to say.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5 A drilldown view
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Note n' Nib's CEO prides himself on being a "details guy," so when he sees a
    number on the dashboard, he wants to investigate *why*. For instance, if he finds
    that the average transaction value on ball pens is lower than that on fountain
    pens, he wants to dig deeper into the data to understand if there's a certain
    demographic driving the ATV down.
  prefs: []
  type: TYPE_NORMAL
- en: Our dashboard doesn't expose data beyond what's in the metrics bar, line and
    pie charts, but there's clearly a desire for a more flexible and detailed view,
    perhaps even showing the individual rows in the source data.
  prefs: []
  type: TYPE_NORMAL
- en: So far in our dashboard design, we've tried to shield users from complexity
    where possible. We've relied on visualizations to make data easy to grasp and
    used a clear, friendly metric bar to display key aggregate numbers. The quality
    of abstracting away complexity is a laudable one most of the time and for most
    users. Now and then, however, you'll come across a power user who wants to go
    deeper and interact with your software in more advanced ways.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, Note n' Nib's CEO fits this description—he's comfortable with data
    and has expressed frustration at not being able to drill down for more detailed
    insights. Addressing this feedback will likely be the most complex task of this
    chapter, as we'll need to create a whole new view rather than just improve upon
    the existing features.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.1 Inserting a modal dialog
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before considering what a drilldown view might contain, let's ponder where to
    place this functionality. Since we're classifying it as an "advanced" feature,
    we probably shouldn't place it in the main window of the dashboard. Casual users
    should be able to ignore the new, more detailed view, while advanced users should
    be able to find it with no trouble.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use this opportunity to discuss a new UI construct: a modal dialog.
    A modal dialog is essentially an overlay displayed on top of the main content,
    temporarily blocking interaction with the underlying interface until it has been
    dismissed. This overlay would remain focused on a particular task, which makes
    it ideal for presenting advanced functionality like drilldowns.'
  prefs: []
  type: TYPE_NORMAL
- en: st.dialog
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Streamlit offers modal dialogs out of the box with `st.dialog`. Let's see this
    in action now.
  prefs: []
  type: TYPE_NORMAL
- en: For our first iteration on the drilldown view, to keep things simple, when a
    user wants to drill down into the data, we'll just show them the entire Pandas
    dataframe. Of course, since users are likely to want to also dive into the comparison
    date range we recently added, we'll need to show both the main and the comparison
    dataframes.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.1 shows a new file, `drilldown.py`, set up to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.1 drilldown.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: It may surprise you to learn that `st.dialog` is *not* structured the same way
    as `st.columns`, `st.tabs`, or `st.container`, i.e., as a widget that holds other
    widgets within.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, it's similar to `st.cache_data` from chapter 6 in that it's a *decorator*.
    A function decorated with `st.dialog` runs and has its content rendered inside
    a popup dialog.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The width parameter simply sets the size of the dialog, which may be `"small"`
    (500 pixels wide) or `"large"` (750 pixels wide).
  prefs: []
  type: TYPE_NORMAL
- en: The function being decorated is called `drilldown`, and it accepts `main_df`
    and `compare_df` from `dashboard.py` as arguments. The function renders two tabs
    titled "Main" and "Compare", and uses a new widget, `st.dataframe`, to display
    the passed Pandas dataframes in their respective tabs.
  prefs: []
  type: TYPE_NORMAL
- en: Using `st.dataframe` like this simply shows the dataframe on the screen, just
    as `st.write` did in Chapter 6\. We'll encounter it later too.
  prefs: []
  type: TYPE_NORMAL
- en: To see the dialog, we need to *trigger* it, so let's focus on that next.
  prefs: []
  type: TYPE_NORMAL
- en: Using st.container to display UI elements out of order
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As alluded to earlier, the drilldown view should be unobtrusive to the casual
    user, but fairly obvious for a power user to access. One way to achieve this would
    be to add a button labeled "Drilldown" to the sidebar, and have it trigger the
    dialog when clicked.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s examine the existing code in `dashboard.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The sidebar already has the date range panel in it, with four widgets (two date
    inputs for the main range, a comparison selectbox, and an info box showing the
    comparison range), all lined up vertically. Since we want the drilldown trigger
    to be easily visible, we probably don't want it to be *below* the date range panel.
    Cool, so we put it above the panel instead, right?
  prefs: []
  type: TYPE_NORMAL
- en: Except, there's a bit of an ordering issue here. To trigger the drilldown view,
    we need to call the `drilldown` function we just decorated with `st.dialog`. The
    parameters to this function are `main_df` and `compare_df`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you inspect the `dashboard.py` code again, you''ll realize that obtaining
    `main_df` and `compare_df` requires that we already *have* the `start`, `end`,
    `compare_start` and `compare_end` values so we can pass them in like this (for
    `main_df`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: But where do we get these values? Why, in the sidebar!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Do you see our dilemma? To place the drilldown button above the date range panel,
    we'd need to write its code *before* this line, but that code requires values
    that are only available *after* this line!
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the perfect place to elaborate on something I mentioned in passing
    in Chapter 6: the ability to display elements out of order. We need a way to separate
    the order in which Streamlit renders widgets on the screen from the order in which
    those widgets are computed.'
  prefs: []
  type: TYPE_NORMAL
- en: We'll use `st.container` for this. In chapter 6, we used it to display a border
    around the metric bar and visualizations. This time, we'll capitalize on a different
    property—`st.container` can put a *placeholder* widget on the screen that we can
    populate with other widgets when we can.
  prefs: []
  type: TYPE_NORMAL
- en: For our use case, the placeholder will be above the date range panel—within
    the sidebar—and we'll only populate it with the actual drilldown button once we
    have `main_df` and `compare_df` later in the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s lay this out in `dashboard.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '#A This is the placeholder defined within st.sidebar'
  prefs: []
  type: TYPE_NORMAL
- en: As promised, we use `st.container` above the date range panel to put a placeholder
    and refer to it by the name `dd_button_container`.
  prefs: []
  type: TYPE_NORMAL
- en: Then, once we have `main_df` and `compare_df`, we create the button that calls
    the drilldown function when clicked. Notice that we're using the syntax `dd_button_container.button`
    instead of the `with`/`st.button` structure, just as we could with columns or
    tabs.
  prefs: []
  type: TYPE_NORMAL
- en: It's finally time to see our dialog come to life! Re-run `dashboard.py` and
    click the drilldown button to get figure 7.10.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image010.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 A basic raw dataframe view rendered in a dialog using st.dialog
    (see chapter_7/in_progress_05 in the GitHub repo for the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You may have noticed that the drilldown button took a second to appear before
    you clicked it. As you probably guessed, that's because we delayed its rendering
    until a bunch of other stuff was processed.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.2 Designing the content of the drilldown
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Turn your attention to the dialog in figure 7.10 for a minute. We're currently
    just displaying `main_df` and `compare_df` as-is. It's rather ugly, with the horizontal
    *and* vertical scrollbars indicating that we only see a tiny portion of the data.
    More to the point, we can't easily use this view to look for specific data points
    or view a specific subset of the data. The boss would not be pleased if he had
    to use this.
  prefs: []
  type: TYPE_NORMAL
- en: No, we need to think carefully to get the experience right.
  prefs: []
  type: TYPE_NORMAL
- en: What do users need from a drilldown view?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It's clear that the content of the drilldown page needs to change, but how?
    What do our users need from this view? Well, what better way to understand than
    to talk to a user?
  prefs: []
  type: TYPE_NORMAL
- en: So, you book a slot on the CEO's calendar—it's a sign of his enthusiasm for
    the dashboard that he readily accepts. In your interview with him, he lays out
    the original motivation for the feedback he provided about the drilldown view.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note n'' Nib has two separate products in its best-selling line of fountain
    pens: Inkstream and RoyalQuill. InkStream is supposed to be a chic modern take
    on the fountain pen, while RoyalQuill, reminiscent of the classic elegance of
    vintage pens, is targeted at older customers.'
  prefs: []
  type: TYPE_NORMAL
- en: Recently, the company ran an advertising campaign for RoyalQuill, specifically
    targeting women in the 46-55 and 56+ age groups. The CEO wanted some data on the
    assumptions and results of this campaign. Specifically, he wanted to know how
    sales broke down for InkStream and RoyalQuill by age *and* gender.
  prefs: []
  type: TYPE_NORMAL
- en: Our current dashboard shows users a breakdown of a metric by age *or* gender
    but not by both, so he can't easily access this information.
  prefs: []
  type: TYPE_NORMAL
- en: You may see how this feedback can be generalized to *any* combination of dimensions
    in the data, not just age group/gender. Also, it would be tricky to present this
    kind of detail in a coherent repeatable visualization.
  prefs: []
  type: TYPE_NORMAL
- en: 'What we need, then, is a highly flexible tabular form to show the data, similar
    to pivot tables that you may be familiar with from spreadsheet programs like Microsoft
    Excel. This table should:'
  prefs: []
  type: TYPE_NORMAL
- en: enable us to view numbers for any combination of dimensions we choose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: allow us to focus on just the fields we care about, hiding irrelevant rows and/or
    columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: show aggregate numbers so we can see a full breakdown
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A mock UI created with these requirements in mind is shown in figure 7.11.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image011.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 A mock UI for the drilldown view
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The mock shows us a fairly flexible table, that's quite similar to a pivot table.
    The "Drilldown fields" box is a multi-select that lets us choose the dimensions
    we care about. Below that is a table that only shows the dimensions we've selected.
    It *aggregates* the data over those dimensions, showing the metrics for every
    combination of the selected dimensions. There's also a total row that adds up
    everything.
  prefs: []
  type: TYPE_NORMAL
- en: We've also retained the main/comparison tabs so that users can switch between
    them to see a past/present view of the metrics. This format is quite flexible,
    and meets our requirements, so it's time to build it out!
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.3 Implementing the drilldown view
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The drilldown view in figure 7.11 is fairly complex, so we'll assemble it piece
    by piece, starting with the drilldown field selector, and ending with some formatting
    and styling.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregating by a few chosen dimensions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Building the dimension selector (the top widget in figure 7.11) is just a matter
    of passing the possible dimension options in an `st.multiselect`. Add a new function
    to `drilldown.py` that does this and returns the list of the user''s selections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: As our mock in figure 7.11 shows, we want to display all key metrics simultaneously.
    Let's put another function (also in `drilldown.py`) that takes in a dataframe
    (or a slice thereof), calculates all the metrics by aggregating it, and returns
    the results. Remember to import all the modules we need!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The expression `{met: metric.func(df) for met, metric in metrics.items()}`
    is a *dictionary comprehension*, which is shorthand to create a dictionary by
    iterating through something. Here it''s saying "iterate through the metrics dictionary
    (from `metric_config.py`) and return a new dictionary where each key is the name
    of the metric, and the corresponding value is the result of applying the metric
    function `metric.func` on `df`, i.e. the value of that metric".'
  prefs: []
  type: TYPE_NORMAL
- en: We use a Pandas series here because, as you'll see shortly, it's a versatile
    data type that integrates seamlessly with various dataframe operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prepare the aggregated table given a dataframe and a list of dimensions,
    we introduce a new function called `get_aggregate_metrics` in the same file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: If `dimensions` is not an empty list, i.e. if the user has indeed selected some
    drilldown dimensions, `get_aggregate_metrics` groups `df` by those fields, and
    applies `get_metric_cols` to each of the groups (using `grouped.apply`, which
    you should be familiar with from Chapter 6), thus obtaining metric values for
    each group.
  prefs: []
  type: TYPE_NORMAL
- en: 'If no dimensions are selected, then we call `get_metric_cols` directly on `df`
    to get a Pandas series object with the aggregated metrics for the entire dataframe.
    Finally, we convert this series into a dataframe and return its *transpose*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The transpose (referenced using a Pandas dataframe's `.T` property) of a dataframe
    is another dataframe whose rows and columns are interchanged. In this case, `metric_cols`
    is a `pd.Series` object, and calling `pd.Dataframe` on it would return a one-column
    dataframe where each of the metrics is a row.
  prefs: []
  type: TYPE_NORMAL
- en: The `.T` is required to turn this into a one-*row* dataframe where each metric
    is a column, a format that's more handy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we write a function that returns our full drilldown table. For now it''s
    pretty thin since we''re only doing some aggregations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We'll add more logic to `get_drilldown_table` later.
  prefs: []
  type: TYPE_NORMAL
- en: 'To wrap up, we also need a function that displays the drilldown table (which
    is currently a Pandas dataframe):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This should be simple; we display a warning if there's no data, or use `st.dataframe`
    to display the aggregated table otherwise. Note the use of `hide_index=True`.
    By default, Streamlit displays the index field (which, as you may recall from
    Chapter 6, is a unique identifier for the row, defaulting to a simple serial number)
    alongside each row. You can see this in figure 7.10 (they're the numbers to the
    extreme left in the dataframe). We don't want the index displayed to the user,
    so we hide it.
  prefs: []
  type: TYPE_NORMAL
- en: 'With these changes made, we can update the `drilldown` function too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The order of operations is logical: First we get the drilldown dimensions from
    the user (`dimensions = drilldown_dimensions()`), then we compute the aggregated
    dataframes (for both `main_df` and `compare_df`) using `get_drilldown_table`,
    and eventually display them in separate tabs using `display_drilldown_table`.'
  prefs: []
  type: TYPE_NORMAL
- en: If you re-run the dashboard now, you should see a much more palatable version
    of the drilldown view, as shown in figure 7.12.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image012.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.12 Drilldown view with a dimension selector and aggregated for selected
    dimensions (see chapter_7/in_progress_06 in the GitHub repo for the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The user can now pick whichever dimensions they want, and see the metrics for
    every combination of those dimensions. This effectively lets the user drill into
    the required level of detail in the data, but perhaps a summary "total" row would
    be warranted to understand the whole that's being broken down here.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a "Total" row
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Adding a summary row to the drilldown table is relatively complicated for a
    couple of reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Pandas dataframes do not natively have a way of designating a row as a summary
    of all the other rows. When we want totals, we have to wrangle them together using
    various operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dimension values are meaningless in a total row and should be blank.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To take an example, let''s say we have the following drilldown dataframe (after
    the filtering and aggregation):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'With the total row added to the top, we would have a dataframe that looks like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s implement this with a new function, `add_total_row`, in `drilldown.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '`add_total_rows` takes three arguments: `df`, `all_df`, and `dimensions` (the
    same list of dimension names we''ve been passing around). `df` is the drilldown
    dataframe we have so far (e.g. the first table above), while `all_df` is the dataframe
    with the original granular columns *before* aggregation.'
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need both `df` *and* `all_df` here? Recall that we have a `get_metric_cols`
    function that can calculate all the metrics we need for a given dataframe—in other
    words, the numeric values for the "total" row we're trying to build. `get_metric_cols`
    expects a raw non-aggregated dataframe, not the aggregated version. This means
    we need to pass it `all_df`, not `df`.
  prefs: []
  type: TYPE_NORMAL
- en: That is indeed what the first statement in the function does, storing the results
    in `total_metrics`.
  prefs: []
  type: TYPE_NORMAL
- en: The next part builds the total row if the dimensions list is non-empty (`if
    dimensions:`), i.e. if the user has selected some drilldown dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following two lines are associated with populating the dimension values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The first line is another dictionary comprehension that has a blank value for
    every dimension key from dimensions. We then set the value for the first dimension
    to `"Total"`. This effectively creates the text display values for our total row
    as we saw in our example above—`"Total"` in the first field and blanks for everything
    else.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the dimension values for the total row in `dim_vals` (a dictionary)
    and the metric values in `total_metrics` (a `pd.Series`). All we need to do is
    to put them together! That''s what the next line does:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: There's some interesting syntax here, so let's break it down.
  prefs: []
  type: TYPE_NORMAL
- en: The character sequence `**` here is called a *dictionary unpacking operator*.
    It unpacks the items from a dictionary so they can be combined with other items
    to form a new dictionary, or even passed as function arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The former is what''s happening here. For instance, if `dim_vals` is something
    like `{''Gender'': ''Total'', ''Segment'': '''', ...}` and total_metrics is `{''Total
    sales'': 300000, …}`, `{**dim_vals, **total_metrics}` gives you a *combined* dictionary
    `{''Gender'': ''Total'', ''Segment'': '''', ..., ''Total sales'': 300000, ...}`.
    The `index=[0]` sets the index of the only row in this single-row dataframe to
    0.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You might notice one issue with this though: Didn''t we just say that `total_metrics`
    is a `pd.Series` and *not* a dictionary? Well, though that''s true, a Pandas series
    actually has many of the properties of a regular Python dictionary—among them
    support for the `**` operator.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next line concatenates this total row to the rest of the drilldown dataframe
    and returns it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if the user has *not* selected any dimensions and `dimensions` is empty,
    getting the dataframe with a total row becomes easier; we just need to add a blank
    column that says `''Total''` to `total_metrics`, and there''s nothing to concatenate
    the row to—the dataframe consists of only the total row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now add the act of obtaining the total row to the transformations in
    `get_drilldown_table` like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Re-run the dashboard to see what your total row looks like (see figure 7.13):'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image013.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.13 Drilldown dataframe view with a total row (see chapter_7/in_progress_07
    in the GitHub repo for the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This is *almost* perfect, but wouldn't it be nice if the total row were highlighted
    or shaded to set it apart from the other rows?
  prefs: []
  type: TYPE_NORMAL
- en: Formatting and styling the drilldown table
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'While we have the content of our drilldown table ready to go, the presentation
    leaves a couple of things to be desired:'
  prefs: []
  type: TYPE_NORMAL
- en: As figure 7.17 shows, the numbers in the table are user-unfriendly raw ones,
    with hardly any formatting. Ideally, we'd want these to be shown in the same way
    as in the metric bar (e.g. "$1.2m" instead of "1200000").
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No shading distinguishes the total row from the rest of the table.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's tackle the former first. Formatting the numbers in the table should be
    quite straightforward because we've already defined the actual formatting rules
    in the `formatting.py` file from Chapter 6.
  prefs: []
  type: TYPE_NORMAL
- en: All we need is a function to apply the formatting to an entire Pandas dataframe
    rather than the individual numbers displayed in the metric bar.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spin up a new function for this in `formatting.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The `format_dataframe` function should be simple to wrap your head around. After
    accepting two parameters (`df`, the dataframe to format, and the `metrics` dictionary
    from `metrics.py`), we simply iterate through the columns in `df`, and apply `format_metric`
    (a function we wrote in chapter 6) element-wise to each column.
  prefs: []
  type: TYPE_NORMAL
- en: Notice how we're passing `metric_type` to `format_metric` as *another* parameter
    to `.apply()`!
  prefs: []
  type: TYPE_NORMAL
- en: 'Essentially the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'is saying: "issue the function call `format_metric(element, metric_type=metrics[col].type)`"
    for every element in `df[col]`, and save the result, which should be our formatted
    dataframe.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s turn to the shading problem next: let''s say we want to give the total
    row a gray background so it stands out from the rest of the table.'
  prefs: []
  type: TYPE_NORMAL
- en: The key to this lies in the `style` property of a Pandas dataframe, which enables
    us to apply *conditional formatting* (i.e. formatting based on certain rules)
    to the dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, we would use the `.apply` method of the `style` property, along
    with a custom function that defines the conditional style to apply.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a new function in `drilldown.py` to implement this logic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The `style_total_row` function accepts the drilldown dataframe `df`, and applies
    the shading we need. To achieve this, it does something interesting: it defines
    *another* function called `get_style` within its body!'
  prefs: []
  type: TYPE_NORMAL
- en: In Python, a function defined within another is called a *nested function* or
    an *inner function*. Python considers a nested function to be local to the enclosing
    function's scope. In other words, any code outside of `style_total_row` cannot
    call `get_style`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting to the logic of the `get_style` function, it operates on an individual
    row of a Pandas dataframe, and so takes in row as a parameter.
  prefs: []
  type: TYPE_NORMAL
- en: It then identifies the name of the first column of the dataframe using `first_col
    = row.index[0]`. The `index` property of a dataframe row is a list-like object
    containing the names of its columns, so `index[0]` gives the name of the first
    column.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next line defines (and returns) the actual conditional style we want to
    apply:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The expression we're returning is a *list comprehension* which builds a new
    list by iterating through something (similar to how the dictionary comprehensions
    we've seen build new dictionaries).
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we're iterating through the fields in the dataframe row, using
    `for _ in row`. We don't actually need to refer to the fields themselves, which
    is why we use `_`—a perfectly valid Python identifier, by the way—as the loop
    index here.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each field, if the passed row is the total row (which we verify by checking
    if the value of the first column is `"Total"),` we add a peculiar string, `''background-color:
    lightgray''`, to the list we''re constructing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This notation comes from CSS, the language used to style web pages. I know
    I promised you don''t need to learn CSS to read this book, but this particular
    piece of it should be obvious enough: we''re telling Pandas to give a light gray
    background to every field in a total row.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve now defined the conditional style we want to apply, but we still need
    to do the applying. The last line in `style_total_row` does this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '`.apply` here expects a function that accepts a dataframe row, so it can call
    it on every row ( as we''ve seen before).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To complete our drilldown view, the final thing we need is to add the formatting
    and styling to `get_drilldown_table`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: And that's it! Our drilldown view is fully formed now. Check it out in figure
    7.14.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image014.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.14 Completed drilldown view with shaded total row and formatted values
    (see chapter_7/in_progress_08 in the GitHub repo for the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Whew! That was a lot of work! However, we have more feature requests to address
    before we're done.
  prefs: []
  type: TYPE_NORMAL
- en: The fragment-like behavior of st.dialog
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: If you paid especially close attention in Chapter 4 where we learned about Streamlit's
    execution model, there's one aspect of how we implemented the drilldown view that
    may be puzzling you.
  prefs: []
  type: TYPE_NORMAL
- en: 'To show the dialog, we nested it under a button like this (in `dashboard.py`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: with `drilldown` being a function decorated with `st.dialog`. Within the drilldown,
    we can perform many interactions, such as selecting a dimension, or setting a
    filter.
  prefs: []
  type: TYPE_NORMAL
- en: But in previous projects, we've seen that the "clicked" state of `st.button`
    only holds for a single re-run, and that whenever we interact with something nested
    under a button, the app gets re-run again, and the button click gets cleared.
    In fact, we had to jump through a bunch of hoops in chapter 4 using `st.session_state`
    to get the behavior we wanted.
  prefs: []
  type: TYPE_NORMAL
- en: But we didn't need to do any of that in this case. Shouldn't interacting with
    the drilldown have caused a re-run with the button-click getting reset and the
    drilldown disappearing?
  prefs: []
  type: TYPE_NORMAL
- en: This doesn't happen because of some special behavior that `st.dialog` exhibits.
    When a user interacts with a widget within an `st.dialog`-decorated function,
    only the decorated function gets re-run, *not* the entire app!
  prefs: []
  type: TYPE_NORMAL
- en: In the above case, when someone selects a drilldown dimension, only the drilldown
    function gets re-run, and the button remains in the "clicked" state. `st.dialog`
    gets this behavior from a more general decorator called `st.fragment`.
  prefs: []
  type: TYPE_NORMAL
- en: 7.6 Enabling deeplinks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next up on the feedback list is a complaint about not being able to share views
    on the dashboard with other people. Naturally, the CEO frequently emails his reports
    about data she sees on the dashboard after applying a variety of filters and selections.
  prefs: []
  type: TYPE_NORMAL
- en: When receiving one of these, the subordinate spends a good few minutes trying
    to recreate what his boss saw on the dashboard, sometimes using trial-and-error
    to get the filters and date ranges right. "This," the CEO writes, "amounts to
    a collaboration tax."
  prefs: []
  type: TYPE_NORMAL
- en: Decision-making through data is not an isolated activity, or shouldn't be, at
    any enterprise. You generally want at least a few other pairs of eyes to validate
    the decisions you intend to make. This presents a real problem for users of our
    dashboard currently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the dashboard, they may identify a trend or data point that is key to
    a decision the company is evaluating. However, if they are to share it with someone
    else, they have two options: either screenshot the app or give the sharee instructions
    on how to recreate the view.'
  prefs: []
  type: TYPE_NORMAL
- en: Neither of these is ideal. A screenshot prevents the other person from interacting
    with the app further, and the other way is decidedly low-tech (imagine a user
    telling someone, "You're doing it wrong. You need to apply a date range of last
    year, filter for the 18-25 age group, and choose a monthly granularity!").
  prefs: []
  type: TYPE_NORMAL
- en: Wouldn't it be nice if the user could just copy-paste the URL they're looking
    at over chat, and the recipient could go to the URL to see exactly what the first
    user was seeing? After all, this works for many other websites. For instance,
    when you use a search engine like Google or DuckDuckGo, you can send someone directly
    to the search results page by sending them your search URL.
  prefs: []
  type: TYPE_NORMAL
- en: This functionality is called *deeplinking*, in the sense of linking someone
    "deep" into your website.
  prefs: []
  type: TYPE_NORMAL
- en: 'How do deeplinks work? Let''s take an example from the search engine DuckDuckGo.
    If you search for `"streamlit"` on duckduckgo.com, the URL of the search results
    page will be something like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Copy-and-paste this URL in your browser and it'll take you directly to the search
    results page for the query "streamlit". The part of the URL where it says `q=streamlit`
    is what makes this possible. The URL has embedded information about the inputs
    entered by the first user, and DuckDuckGo uses this information to direct the
    second user to the right page.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we apply this logic to our app, we need two things to implement deeplinks:'
  prefs: []
  type: TYPE_NORMAL
- en: A way to embed the inputs entered by a user in the app's URL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given such a URL, a way to repopulate these inputs in the app automatically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7.6.1 Using st.query_params
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The part of the URL that contains the "extra" information after the actual address
    is called a *query string*. It is separated from the rest of the URL by a question
    mark (`?`) character. The query string is made up of several key-value pairs called
    *query parameters*, separated in turn by the ampersand (`&`) character.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, in the URL we discussed above, i.e. `https://duckduckgo.com/?t=h_&q=streamlit&ia=web`:'
  prefs: []
  type: TYPE_NORMAL
- en: The query string is `t=h_&q=streamlit&ia=web`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The query parameters are: `t=h_` (key `t` and value `h_`), `q=streamlit` (key
    `q` and value `streamlit`), and `ia=web` (key `ia` and value `web`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If our app were to have query parameters, what would they look like? Well,
    since the query string needs to capture the inputs entered by the user, it might
    be something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Essentially, the user's selections need to be part of the query string (and,
    therefore, the URL).
  prefs: []
  type: TYPE_NORMAL
- en: Streamlit allows you to manage query parameters through `st.query_params`, which
    is another dictionary-like object similar to `st.session_state`.
  prefs: []
  type: TYPE_NORMAL
- en: At any point, `st.query_params` contains whatever key-value pairs are in your
    app's URL query string. You can also modify the query string in your browser's
    address bar by modifying `st.query_params`.
  prefs: []
  type: TYPE_NORMAL
- en: The syntax for getting and setting parameters in `st.query_params` is identical
    to using a dictionary. For example, the code `st.query_params["pie_chart_dimension"]
    = "Gender"` would set the `pie_chart_dimension` parameter, updating the URL to
    include `pie_chart_dimension=Gender` somewhere.
  prefs: []
  type: TYPE_NORMAL
- en: 'You could also read in the value of the parameter like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Our solution, then, would involve something like figure 7.15.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image015.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.15 Approach for implementing deeplinking
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When someone first navigates to our app, we should extract the query parameters
    from the URL if there are any.
  prefs: []
  type: TYPE_NORMAL
- en: We then set the values of the widgets based on those parameters. For instance,
    if we have `start_date=2024-08-01` as one of the query parameters, we would set
    the start date in the date range selector widget to 2024-08-01\. If there are
    no query parameters, or no value specified for a particular widget, we don't set
    the value of the widget; instead we let the default behavior take over.
  prefs: []
  type: TYPE_NORMAL
- en: Then, when someone changes a selection in a widget, we *update* the query parameters
    to reflect that change, thus also changing the URL in the address bar. This way,
    if a user copies the URL, it always has the latest selections they've made in
    the app!
  prefs: []
  type: TYPE_NORMAL
- en: 7.6.2 Setting widget defaults through st.session_state
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There's one part of our scheme that hasn't been covered in any previous chapters.
    How do we programmatically set the value of an input widget?
  prefs: []
  type: TYPE_NORMAL
- en: Recall from chapter 4 that every Streamlit widget (or UI element) has a unique
    identifier called a widget key. The key is usually created automatically by Streamlit,
    but if you have two identical widgets, you have to give each one a key manually
    so Streamlit can tell them apart. One neat thing I didn't mention earlier is that
    every time you provide a widget a key, its value becomes accessible in `st.session_state`.
  prefs: []
  type: TYPE_NORMAL
- en: 'So if you have a dropdown input coded like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: You can access its value using `st.session_state["select_dim"]`
  prefs: []
  type: TYPE_NORMAL
- en: 'Importantly for us, we can also *set* its value, simulating a user selection,
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: One caveat is that we can only do this *before* the widget code is run. In other
    words, we can set the value of the widget key in `st.session_state` *first* and
    have the widget take on that value when it renders later, but you can't render
    the widget with a key *first* and *then* overwrite its value by setting the value
    of the key in `st.session_state`.
  prefs: []
  type: TYPE_NORMAL
- en: 7.6.3 Implementing deeplinks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We now have all the information needed to build the deeplink functionality.
    Create a new file called `query_params.py` with the content shown in listing 7.2.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.2 query_params.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: The `get_param` function gets the value of a particular query parameter given
    its name. It does so by using the `.get()` method of `st.query_params`, which—identically
    to that of a regular dictionary—returns a default value of `None` if the key does
    not exist.
  prefs: []
  type: TYPE_NORMAL
- en: '`set_widget_defaults` populates the values of various widgets in the app from
    the query parameters by iterating through them and setting the value of each widget
    key in `st.session_state`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Why do we have the following condition?:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: We don't necessarily want *every* key stored in `st.session_state` to appear
    in the URL, just those representing widgets. To ensure this, later on we'll prefix
    the string `'w:'` to every widget key we want in the query parameters. This gives
    us the flexibility of using `st.session_state` for other purposes should we need
    to while still being able to autopopulate widget values with it.
  prefs: []
  type: TYPE_NORMAL
- en: We also don't want Streamlit to try to set the widget value from `st.query_params`
    in every re-run of the app because then *users* wouldn't be able to change the
    value. Instead, we only want to set each widget value once, when the app is being
    loaded for the first time from the parameter-embedded URL. That's why we have
    the sub-condition `key not in st.session_state`.
  prefs: []
  type: TYPE_NORMAL
- en: '`set_widget_defaults` fulfills the first part of what we need for deep links—the
    ability to populate widget inputs from the URL. However, we still need to change
    the query parameters whenever a user makes a selection.'
  prefs: []
  type: TYPE_NORMAL
- en: That's what the `set_params` function does. It loops through `st.session_state`,
    gets the value of every widget key and stores them in a dictionary, `query_params_dict`.
    It then populates all of `st.query_params` directly from this dictionary using
    the `from_dict` method. As I illustrated earlier, we could also have set each
    value in `st.query_params`, but I wanted to show you this way too.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, for this to work, all of the widgets we want in the query parameters
    must have keys defined, starting with `'w:'`. Therefore, we'll need to go through
    all of our code and add widget keys to each widget. Not a lot of fun, I'm afraid,
    but it has to be done.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the changes we''ll need to make, if you''re following along:'
  prefs: []
  type: TYPE_NORMAL
- en: Changes to date_range_panel.py
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In `date_range_panel.py`, there are three date selection widgets we show the
    user. We need to add keys to each of them. These would become:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The exact names for the keys don't matter as long as they start with `w:`. There
    is an additional wrinkle here though.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we currently assign default values `THIRTY_DAYS_AGO` and `TODAY`
    to the start and end date selectors respectively, through the `value` parameter
    in `st.date_input`.
  prefs: []
  type: TYPE_NORMAL
- en: When we use `st.session_state` to set widget values—as we're doing in the `set_widget_defaults`
    function we created earlier—Streamlit will throw an error if we *also* try to
    set the value using the `value` parameter. We can't use both methods, we have
    to choose one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Here, we've removed the `value` parameter from both widgets and added some logic
    at the beginning to set the same values using `st.session_state`. These lines
    must come before the widgets are defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'For reference, the overall `date_range_panel` function is now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Changes to filter_panel.py
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`filter_panel.py` has multiselects we need to add a key to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: In this case, since multiple widgets are populated through a loop, we use the
    f-string `f'w:filter|{dim}'` as the key, using the dimension name `dim` to differentiate
    between the keys.
  prefs: []
  type: TYPE_NORMAL
- en: Changes to pie_chart.py and time_series_chart.py
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In `pie_chart.py`, add a key to the `st.selectbox` assigned to `split_dimension`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, in `time_series_chart.py`, add keys to `grain` and `split_dimension`
    in the `time_series_chart` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'With the widget keys in place, we can now call the relevant functionality we
    defined earlier in query_params.py from `dashboard.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Pay attention to exactly where we've placed the calls to `set_widget_defaults`
    and `set_params`. As mentioned earlier, we can only use `st.session_state` to
    set widget key values *before* any of the widgets are created, so the call to
    `set_widget_defaults()` needs to go right at the top (just after `st.set_page_config(layout='wide')`
    which needs to be the first command).
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the query parameters need to capture changes to *any* widget
    that the user has changed, so the call to `set_params` has to go at the very *end*
    of `dashboard.py`, after all the widgets have been created.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s test out our deeplinks! Save everything and re-run the app. Then try
    making the following selections in the app:'
  prefs: []
  type: TYPE_NORMAL
- en: Set "Start date" to 2024/07/01, and "Compare to" to YoY.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set the "Time grain" slider in the line chart to Week.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you now check the URL in your browser''s address bar, it should look something
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: When a web URL contains certain special characters, such as a colon (`:`) or
    a space, it is converted into *percent-encoded* characters to ensure that browsers
    and web servers interpret them correctly. Each special character is usually replaced
    by a `%` sign followed by a two-digit hexadecimal code representing the original
    character in the ASCII standard. One exception is the space character, which,
    when it appears in the query parameters part of the URL, is encoded as a `+` sign.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, the following substitutions have occurred:'
  prefs: []
  type: TYPE_NORMAL
- en: The colon character has become `%3A`, so `w:ts_grain` becomes `w%3Ats_grain`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The space character has become `+`, so `Age group` becomes `Age+group`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reverse those substitutions and the URL becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: This is pretty much what we expected—the selections we made are reflected in
    the URL (along with the value of the pie chart dimension selectbox, which gets
    a non-blank value—`Age group`—by default, which is automatically captured in the
    URL).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The URL starts with http://localhost: since we''re currently developing locally.
    When we deploy our app, the localhost part will be replaced by whatever the address
    of the app is. For instance, if we deploy to Streamlit Community Cloud under [https://ceo-dashboard.streamlit.app](https://ceo-dashboard.streamlit.app),
    our URL with query parameters would look something like https://ceo-dashboard.streamlit.app?query_param1=value1&query_param2=...'
  prefs: []
  type: TYPE_NORMAL
- en: Next, paste the original URL you copied into another browser tab and navigate
    to it. Unfortunately, the app throws an error (see figure 7.16).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image016.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.16 We get an error when we inadvertently pass a string to an st.date_input
    (see chapter_7/in_progress_09 in the GitHub repo for the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The error claims that we tried to pass the wrong kind of value to a "DateInput",
    presumably the "Start date" and/or "End date" widgets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The issue here is that in the (parsed) URL above, the value given to the start
    date widget (with the key `w:start`) is the string `"2024-07-01"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: When Streamlit tries to assign this value to the date input widget when it's
    eventually defined, it results in an error because `st.date_input` expects a date
    object, not a string.
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s a similar problem with our filter inputs: these widgets expect lists
    (as you can select multiple values), but we''re passing strings.'
  prefs: []
  type: TYPE_NORMAL
- en: We need some special handling logic for when the value to be set is not a string
    but a date or a list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, when setting the value of such a widget in `st.query_params`, let''s
    add a prefix to denote that the value we''re placing is a list or a date—say `L#`
    for a list and `D#` for a date. Here''s the `set_params` function in `query_params.py`
    with this modification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Here, before adding a value to `query_params_dict`, we check its type using
    `isinstance`. If it's a list, we convert it to a string in a specific format (e.g.
    `['M', 'F']` becomes `L#M,F`). If it's a date, we convert it into a different
    format (e.g. `2024-08-01` becomes `D#2024-08-01`).
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need the reverse logic to decode these string formats and convert them
    into the original values. This part goes in the `get_param` function, which we''ll
    rewrite entirely:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, for a particular key, if the value is a string that starts with
    one of our special prefixes—either `L#` or `D#`—we do the reverse transformation,
    converting the string to the original list or date respectively.
  prefs: []
  type: TYPE_NORMAL
- en: When we use this returned value in `set_widget_defaults`, it will thus be in
    the expected type, identical to the value that the user originally set, removing
    the error.
  prefs: []
  type: TYPE_NORMAL
- en: You can see for yourself by retrying the earlier steps. You should see figure
    7.17 now, demonstrating that you can now copy and paste the current URL of your
    dashboard to show others exactly what you're seeing.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image017.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.17 The widgets in the dashboard are populated based on the URL values
    (see chapter_7/in_progress_10 in the GitHub repo for the full code)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Explore the deeplinks some more. Note n' Nib's execs can now spend less time
    fiddling with the dashboard and more time making decisions that benefit the company!
  prefs: []
  type: TYPE_NORMAL
- en: 7.7 Sourcing data from a data warehouse
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ve addressed all of the user feedback on the dashboard, but there''s one
    glaring practical problem with it we have yet to talk about: the data we display
    in the dashboard is sourced from a static CSV file.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I chose this approach as I wanted us to focus primarily on what we do with
    the data once we have it. Reading a static CSV file is probably the easiest way
    to ingest data in our app. However, there are multiple issues with this:'
  prefs: []
  type: TYPE_NORMAL
- en: While a CSV is manageable when dealing with a small amount of data, it quickly
    becomes inefficient when handling large datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can't query the data flexibly at the source, and instead have to load it
    in memory to perform operations like filtering, aggregations, and joins.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the real world, we would generally store this data in a *data warehouse,*
    which is a specialized system designed to manage large volumes of structured data.
    In this section, we'll swap out our CSV for a table in a data warehouse—specifically
    Google BigQuery.
  prefs: []
  type: TYPE_NORMAL
- en: 7.7.1 Getting our data into BigQuery
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Google BigQuery is a cloud-based data warehouse service that's part of the Google
    Cloud Platform (GCP). It allows you to efficiently store and analyze massive datasets
    using a language called *Structured Query Language* (SQL), without needing to
    manage infrastructure or worry about scaling.
  prefs: []
  type: TYPE_NORMAL
- en: To begin, you'll need to set up a GCP account, which you can do at cloud.google.com.
    You'll probably need to enter details of a payment method such as a credit card,
    but you won't get charged since we're only going to be using free resources for
    this exercise.
  prefs: []
  type: TYPE_NORMAL
- en: When you create a new account, Google will also create a *GCP project* for you.
    In GCP parlance, a project is a container for organizing and managing your Google
    Cloud resources. You need one to use BigQuery; feel free to use the default one
    created for you or to create a new one. A project has a unique ID; you can choose
    what this is when you create a project, but the default one is a randomly generated
    string. For instance, my default project ID was `dauntless-brace-436702-q0`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's go to BigQuery itself. Google Cloud is so vast and offers so many
    products and services that its UI may be intimidating to a beginner. The most
    reliable way to find BigQuery is probably to enter the search string "bigquery"
    in the search box at the top (see figure 7.18)
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image018.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.18 The most reliable way to find something on GCP is to use the search
    bar.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Once on the BigQuery page, you should be able to see your BigQuery resources
    categorized under your GCP projects in an Explorer side panel to the left (see
    figure 7.19). "Resources" here means things like "queries", "notebooks", "workflows"
    etc., all of which you may ignore.
  prefs: []
  type: TYPE_NORMAL
- en: What we're trying to do is to create a BigQuery table by uploading our CSV file.
    Before we can do this, we need to create a dataset. A BigQuery dataset is just
    a way to organize your tables within a project.
  prefs: []
  type: TYPE_NORMAL
- en: Make your first dataset by clicking the three dots next to your project ID in
    the Explorer panel and then "Create dataset" (figure 7.19).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image019.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.19 The Explorer pane in BigQuery
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This will open a screen where you can configure the dataset. All you need to
    enter is a name (I chose `sia_ceo_dashboard`); you can use the defaults for the
    remaining options.
  prefs: []
  type: TYPE_NORMAL
- en: Once created, your dataset should appear in the Explorer panel. Click the three
    dots next to it and "Create table" to get to the table creation screen where we
    can upload our file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Select "Upload" under the "Create table from" options, and "CSV" as the file
    format. You can then select the `sales_data.csv` file from your local disk. You''ll
    need to pick a name for the table (`sales_data` works). The remaining options
    should be straightforward and will likely be auto-populated: your project ID,
    and the name of the dataset you just created. Figure 7.20 shows what the screen
    looks like.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../Images/ch07__image020.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.20 The table creation screen in BigQuery
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Check the "Auto detect" box under "Schema" so you don't have to enter it manually.
    Then click the button at the bottom to actually create your table.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, your data is in BigQuery, and the table should appear under your
    dataset in Explorer. If you like, you can click into it and go to the "Preview"
    tab to see the data.
  prefs: []
  type: TYPE_NORMAL
- en: 7.7.2 Setting up the Python-BigQuery connection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can now access our data in the BigQuery interface, but we also need to be
    able to connect to it from our Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling the BigQuery and BigQuery Storage APIs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'First, we need to enable a couple of BigQuery-related APIs in our GCP project:
    the BigQuery and BigQuery Storage APIs. The BigQuery API is what enables us to
    connect to BigQuery in the first place, while the Storage API makes it faster
    to ingest data into a Pandas dataframe.'
  prefs: []
  type: TYPE_NORMAL
- en: In each case, the corresponding result should lead you to a page when you can
    enable the API.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a service account
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Since our app will connect to BigQuery programmatically, we need a *GCP service
    account* to handle authentication. A service account is a special type of account
    that belongs to your application instead of to an individual user. It enables
    your app to authenticate and interact with Google Cloud services, including BigQuery.
  prefs: []
  type: TYPE_NORMAL
- en: To create a service account, first find "IAM & Admin" and then "Service accounts"
    in the Google Cloud navigation menu (or better still, search for "service accounts"
    and click the first result.
  prefs: []
  type: TYPE_NORMAL
- en: In the "Service Accounts" page, click the option to create one. This screen
    will ask you for a service account name (I used `sia_service_account`) and description.
    Once you've created the account, you'll also need to grant it access to your project
    on the same screen. Choose the role "Viewer" when you do this.
  prefs: []
  type: TYPE_NORMAL
- en: Your service account should now appear in the Service Accounts page.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a service account key
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We have a service account that can access our BigQuery resources, but we still
    need to obtain the credentials that will let our Streamlit app act *as* the service
    account. For this, we require a service account key.
  prefs: []
  type: TYPE_NORMAL
- en: Find the account you just created on the Service Accounts page, click the three
    dots under "Actions" next to it, and then click "Manage keys."
  prefs: []
  type: TYPE_NORMAL
- en: Click "ADD KEY" > "Create new key" and select "JSON" as the key type. When you
    click "Create", your computer should automatically download a JSON file. Inspect
    this file in a text editor. It should contain the credentials you need to access
    BigQuery from your app, as well as additional details such as your project ID.
  prefs: []
  type: TYPE_NORMAL
- en: Generating secrets.toml
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The credentials we just obtained must be kept secret as they allow anyone who
    has them to read your BigQuery data. Recall from Chapter 5 that the optimal way
    to maintain confidential info in Streamlit is to use a `secrets.toml` file in
    conjunction with `st.secrets`.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the credential file we have is in JSON, so we need to convert
    it to TOML. You can do this manually, but let's use Python instead.
  prefs: []
  type: TYPE_NORMAL
- en: First create a `.streamlit` folder to hold your `secrets.toml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rename your JSON file to `sia-service-account.json`, then open a Python shell
    from the same folder and type in the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You may first need to run "pip install toml" to get this to work.
  prefs: []
  type: TYPE_NORMAL
- en: All we're doing here is opening the JSON file we got from GCP, reading it into
    a Python dictionary, and writing it back to `secrets.toml` under the key "bigquery".
    If you now open `secrets.toml`, you should be able to see the credentials in TOML
    format.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 7.7.3 Updating the dashboard to load data from BigQuery
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It''s time to update our code to source data from BigQuery instead of a static
    CSV file. We need to install three new Python modules to enable this, so go ahead
    and enter the following commands into a terminal window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The first two are needed to access the BigQuery and BigQuery Storage APIs. `db-dtypes`
    is required to enable converting the data returned by BigQuery to a Pandas dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: Since we wrote our code in a modular way, the only thing we need to change is
    the implementation of the `load_data` function in `data_loader.py`, and the rest
    of our app should work as before. This is an advantage of the "separation of concerns"
    principle we discussed in chapter 3.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.3 shows the new `data_loader.py` with `load_data` re-implemented to
    use BigQuery.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.3 data_loader.py reimplemented to use BigQuery
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: We keep a couple of constants at the top (`DATASET` and `TABLE`) to hold the
    names of the dataset and table we created in BigQuery.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within `load_data`, we first save the credentials from the `bigquery` key in
    `st.secrets` to `service_account_info`. We then pass in these credentials to create
    a BigQuery client (essentially an object that contains the methods and abstractions
    needed to interact with BigQuery):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'We want to use the same credentials in the BigQuery Storage API client too,
    so we extract the credentials from the BigQuery client and use them to initialize
    `storage_client`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Our connection is now established.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tables in BigQuery are referred to using a dot-separated combination of the
    project ID, dataset name, and table name. For instance, the table I created would
    be referenced as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: We obtain the project ID from the credentials (`project_id = service_account_info["project_id"]`)
    and the dataset and table names from the constants we created above.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the table reference to construct a SQL query like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: We'll encounter more SQL in chapter 8, but for the moment, all you need to understand
    is that "`SELECT * from <table>`" means "get me all the columns from `<table>`".
    Essentially, we're telling BigQuery to return all the data in the table.
  prefs: []
  type: TYPE_NORMAL
- en: Though we're not doing it here, we could have used a different SQL query to
    obtain some *subset* of the data; we couldn't have done this if we were still
    using a CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next two lines execute the query itself, wait for it to finish, and save
    the results to result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, we convert the result to a Pandas dataframe, utilizing the BigQuery
    Storage client for optimized performance, and return the dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: If you execute `streamlit run dashboard.py` again (you can't just re-run the
    app in the browser since we're using `st.cache_data` and simply re-running would
    return a previously cached version), the app will now pull data from BigQuery!
  prefs: []
  type: TYPE_NORMAL
- en: 7.7.4 Notes on deployment to Streamlit Community Cloud
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In chapter 5, we explored how to deploy our apps to Streamlit Community Cloud.
    The process to do so remains the same for our metrics dashboard, but I want to
    call out a couple of things.
  prefs: []
  type: TYPE_NORMAL
- en: The first is related to where we store the data. When deploying, if you're using
    the static CSV approach to source the data, you need to commit the CSV file in
    git, essentially storing it in your GitHub repo.
  prefs: []
  type: TYPE_NORMAL
- en: If you're using BigQuery instead, the CSV is obviously not required, and you
    don't have to check it into your repository. However, you do need to configure
    your GCP credentials in Streamlit Community Cloud using the same process we used
    in Chapter 5.
  prefs: []
  type: TYPE_NORMAL
- en: You'll also need to create a `requirements.txt` with all the modules we're using
    and need Community Cloud to install. As discussed in chapter 5, you can use the
    `pip freeze` command to identify the specific versions of the libraries we're
    using.
  prefs: []
  type: TYPE_NORMAL
- en: An example `requirements.txt` for the dashboard is provided in listing 7.4.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.4 requirements.txt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: We're finally all set to release version 2.0 of our dashboard! Without a doubt,
    there will be more feedback later, and each iteration will refine our dashboard
    further.
  prefs: []
  type: TYPE_NORMAL
- en: For now, however, it's time to bid farewell to Note n' Nib and its data needs.
    In the next chapter, we're shifting gears from data insights to interactive tools,
    as we dive into a web app for creating, storing, and sharing haikus.
  prefs: []
  type: TYPE_NORMAL
- en: 7.8 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Launching* an app is only the first part of making it successful. You also
    have to *land* it, making sure that it serves your users'' needs. For this, it
    is critical to hear from users directly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`st.select_slider` is a cross between `st.selectbox` and `st.slider`, used
    when you want to impose a logical order between options.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`st.metric` can show the delta associated with a metric, i.e. how a value has
    changed over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`st.dialog` is a decorator that lets you create a modal dialog, an overlay
    that blocks interaction with the rest of the app.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use `st.container` to create placeholders in your app, only rendering
    the content you want to show when it's available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas dataframes have a style property that can be used to set conditional
    rules that modify how they are displayed on the screen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`st.query_params` is a dictionary-like object that lets you read and update
    URL query parameters—this can be used to enable deeplinks in an app.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A data warehouse is a specialized system designed to store and retrieve large
    amounts of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google BigQuery—part of GCP—is an example of a data warehouse. To enable an
    app to connect to it, you need to create a service account with a key, and record
    the credentials in `st.secrets`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
