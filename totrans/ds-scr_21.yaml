- en: Chapter 20\. Clustering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第20章 聚类
- en: Where we such clusters had
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当我们有这样的聚类时
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As made us nobly wild, not mad
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使我们变得高尚而不是疯狂
- en: ''
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Robert Herrick
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 罗伯特·赫里克
- en: Most of the algorithms in this book are what’s known as *supervised learning*
    algorithms, in that they start with a set of labeled data and use that as the
    basis for making predictions about new, unlabeled data. Clustering, however, is
    an example of *unsupervised learning*, in which we work with completely unlabeled
    data (or in which our data has labels but we ignore them).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的大多数算法都属于*监督学习*算法，即它们从一组带标签的数据开始，并将其用作对新的未标记数据进行预测的基础。然而，聚类是*无监督学习*的一个例子，我们在其中使用完全未标记的数据（或者我们的数据具有标签但我们忽略它们）。
- en: The Idea
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思路
- en: Whenever you look at some source of data, it’s likely that the data will somehow
    form *clusters*. A dataset showing where millionaires live probably has clusters
    in places like Beverly Hills and Manhattan. A dataset showing how many hours people
    work each week probably has a cluster around 40 (and if it’s taken from a state
    with laws mandating special benefits for people who work at least 20 hours a week,
    it probably has another cluster right around 19). A dataset of demographics of
    registered voters likely forms a variety of clusters (e.g., “soccer moms,” “bored
    retirees,” “unemployed millennials”) that pollsters and political consultants
    consider relevant.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 每当您查看某些数据源时，很可能数据会以某种方式形成*聚类*。显示百万富翁住在哪里的数据集可能在比佛利山庄和曼哈顿等地形成聚类。显示人们每周工作多少小时的数据集可能在周围形成一个大约为40的聚类（如果它来自于一项法律规定每周至少工作20小时的州，那么它可能还有另一个大约在19左右的聚类）。登记选民的人口统计数据集可能形成各种各样的聚类（例如，“足球妈妈”，“无聊的退休者”，“失业的千禧一代”），这些聚类被民意调查员和政治顾问认为是相关的。
- en: Unlike some of the problems we’ve looked at, there is generally no “correct”
    clustering. An alternative clustering scheme might group some of the “unemployed
    millennials” with “grad students,” and others with “parents’ basement dwellers.”
    Neither scheme is necessarily more correct—instead, each is likely more optimal
    with respect to its own “how good are the clusters?” metric.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们已经研究过的一些问题不同，通常没有“正确”的聚类。另一种聚类方案可能会将一些“失业的千禧一代”与“研究生”分组，而将其他一些与“父母的地下室居民”分组。这两种方案都不一定更正确——而是每一种都可能更优，关于自身的“聚类有多好？”度量标准而言。
- en: Furthermore, the clusters won’t label themselves. You’ll have to do that by
    looking at the data underlying each one.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些簇不会自行标记。您需要通过查看每个簇下面的数据来完成。
- en: The Model
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型
- en: For us, each `input` will be a vector in *d*-dimensional space, which, as usual,
    we will represent as a list of numbers. Our goal will be to identify clusters
    of similar inputs and (sometimes) to find a representative value for each cluster.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说，每个`input`将是*d*维空间中的一个向量，通常我们将其表示为数字列表。我们的目标将是识别相似输入的簇，并（有时）为每个簇找到一个代表值。
- en: For example, each input could be a numeric vector that represents the title
    of a blog post, in which case the goal might be to find clusters of similar posts,
    perhaps in order to understand what our users are blogging about. Or imagine that
    we have a picture containing thousands of `(red, green, blue)` colors and that
    we need to screen-print a 10-color version of it. Clustering can help us choose
    10 colors that will minimize the total “color error.”
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，每个输入可以是表示博客文章标题的数值向量，此时目标可能是找到相似帖子的簇，也许是为了理解我们的用户正在博客的内容。或者想象一下，我们有一张包含数千个`(红色，绿色，蓝色)`颜色的图片，并且我们需要丝网印刷它的10种颜色版本。聚类可以帮助我们选择最小化总“颜色误差”的10种颜色。
- en: One of the simplest clustering methods is *k*-means, in which the number of
    clusters *k* is chosen in advance, after which the goal is to partition the inputs
    into sets <math><mrow><msub><mi>S</mi> <mn>1</mn></msub> <mo>,</mo> <mo>...</mo>
    <mo>,</mo> <msub><mi>S</mi> <mi>k</mi></msub></mrow></math> in a way that minimizes
    the total sum of squared distances from each point to the mean of its assigned
    cluster.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的聚类方法之一是*k*-means，在其中聚类数*k*是预先选择的，然后目标是以最小化每个点到其分配的簇的平均值的距离的总平方和的方式将输入分区到集合<math><mrow><msub><mi>S</mi>
    <mn>1</mn></msub> <mo>,</mo> <mo>...</mo> <mo>,</mo> <msub><mi>S</mi> <mi>k</mi></msub></mrow></math>。
- en: 'There are a lot of ways to assign *n* points to *k* clusters, which means that
    finding an optimal clustering is a very hard problem. We’ll settle for an iterative
    algorithm that usually finds a good clustering:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多方法可以将*n*个点分配到*k*个簇中，这意味着找到最佳聚类是一个非常困难的问题。我们将采用一个通常能找到良好聚类的迭代算法：
- en: Start with a set of *k*-means, which are points in *d*-dimensional space.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign each point to the mean to which it is closest.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If no point’s assignment has changed, stop and keep the clusters.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If some point’s assignment has changed, recompute the means and return to step
    2.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the `vector_mean` function from [Chapter 4](ch04.html#linear_algebra),
    it’s pretty simple to create a class that does this.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with, we’ll create a helper function that measures how many coordinates
    two vectors differ in. We’ll use this to track our training progress:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We also need a function that, given some vectors and their assignments to clusters,
    computes the means of the clusters. It may be the case that some cluster has no
    points assigned to it. We can’t take the mean of an empty collection, so in that
    case we’ll just randomly pick one of the points to serve as the “mean” of that
    cluster:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And now we’re ready to code up our clusterer. As usual, we’ll use `tqdm` to
    track our progress, but here we don’t know how many iterations it will take, so
    we then use `itertools.count`, which creates an infinite iterable, and we’ll `return`
    out of it when we’re done:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let’s take a look at how this works.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Meetups'
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To celebrate DataSciencester’s growth, your VP of User Rewards wants to organize
    several in-person meetups for your hometown users, complete with beer, pizza,
    and DataSciencester t-shirts. You know the locations of all your local users ([Figure 20-1](#user_locations)),
    and she’d like you to choose meetup locations that make it convenient for everyone
    to attend.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![User locations.](assets/dsf2_2001.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: Figure 20-1\. The locations of your hometown users
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Depending on how you look at it, you probably see two or three clusters. (It’s
    easy to do visually because the data is only two-dimensional. With more dimensions,
    it would be a lot harder to eyeball.)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine first that she has enough budget for three meetups. You go to your
    computer and try this:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You find three clusters centered at [–44, 5], [–16, –10], and [18, 20], and
    you look for meetup venues near those locations ([Figure 20-2](#user_locations_3_means)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![User locations with 3 means.](assets/dsf2_2002.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: Figure 20-2\. User locations grouped into three clusters
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You show your results to the VP, who informs you that now she only has enough
    budgeted for *two* meetups.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '“No problem,” you say:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As shown in [Figure 20-3](#user_locations_2_means), one meetup should still
    be near [18, 20], but now the other should be near [–26, –5].
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![User locations with 2 means.](assets/dsf2_2003.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: Figure 20-3\. User locations grouped into two clusters
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Choosing k
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous example, the choice of *k* was driven by factors outside of
    our control. In general, this won’t be the case. There are various ways to choose
    a *k*. One that’s reasonably easy to understand involves plotting the sum of squared
    errors (between each point and the mean of its cluster) as a function of *k* and
    looking at where the graph “bends”:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'which we can apply to our previous example:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Looking at [Figure 20-4](#choosing_a_k), this method agrees with our original
    eyeballing that three is the “right” number of clusters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![Choosing a k.](assets/dsf2_2004.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: Figure 20-4\. Choosing a *k*
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Example: Clustering Colors'
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The VP of Swag has designed attractive DataSciencester stickers that he’d like
    you to hand out at meetups. Unfortunately, your sticker printer can print at most
    five colors per sticker. And since the VP of Art is on sabbatical, the VP of Swag
    asks if there’s some way you can take his design and modify it so that it contains
    only five colors.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Computer images can be represented as two-dimensional arrays of pixels, where
    each pixel is itself a three-dimensional vector `(red, green, blue)` indicating
    its color.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a five-color version of the image, then, entails:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Choosing five colors.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assigning one of those colors to each pixel.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It turns out this is a great task for *k*-means clustering, which can partition
    the pixels into five clusters in red-green-blue space. If we then recolor the
    pixels in each cluster to the mean color, we’re done.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with, we’ll need a way to load an image into Python. We can do this
    with matplotlib, if we first install the pillow library:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then we can just use `matplotlib.image.imread`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Behind the scenes `img` is a NumPy array, but for our purposes, we can treat
    it as a list of lists of lists.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '`img[i][j]` is the pixel in the *i*th row and *j*th column, and each pixel
    is a list `[red, green, blue]` of numbers between 0 and 1 indicating the [color
    of that pixel](http://en.wikipedia.org/wiki/RGB_color_model):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In particular, we can get a flattened list of all the pixels as:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'and then feed them to our clusterer:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Once it finishes, we just construct a new image with the same format:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'and display it, using `plt.imshow`:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: It is difficult to show color results in a black-and-white book, but [Figure 20-5](#mt_both)
    shows grayscale versions of a full-color picture and the output of using this
    process to reduce it to five colors.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '![Original picture and its 5-means decoloring.](assets/dsf2_2005.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
- en: Figure 20-5\. Original picture and its 5-means decoloring
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Bottom-Up Hierarchical Clustering
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An alternative approach to clustering is to “grow” clusters from the bottom
    up. We can do this in the following way:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Make each input its own cluster of one.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As long as there are multiple clusters remaining, find the two closest clusters
    and merge them.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At the end, we’ll have one giant cluster containing all the inputs. If we keep
    track of the merge order, we can re-create any number of clusters by unmerging.
    For example, if we want three clusters, we can just undo the last two merges.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use a really simple representation of clusters. Our values will live
    in *leaf* clusters, which we will represent as `NamedTuple`s:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We’ll use these to grow *merged* clusters, which we will also represent as
    `NamedTuple`s:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This is another case where Python’s type annotations have let us down. You’d
    like to type hint `Merged.children` as `Tuple[Cluster, Cluster]` but `mypy` doesn’t
    allow recursive types like that.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一种情况，Python的类型注解让我们感到失望。你想用`Tuple[Cluster, Cluster]`作为`Merged.children`的类型提示，但`mypy`不允许这样的递归类型。
- en: 'We’ll talk about merge order in a bit, but first let’s create a helper function
    that recursively returns all the values contained in a (possibly merged) cluster:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后会讨论合并顺序，但首先让我们创建一个递归返回所有值的帮助函数，这些值包含在（可能已合并的）簇中：
- en: '[PRE16]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In order to merge the closest clusters, we need some notion of the distance
    between clusters. We’ll use the *minimum* distance between elements of the two
    clusters, which merges the two clusters that are closest to touching (but will
    sometimes produce large chain-like clusters that aren’t very tight). If we wanted
    tight spherical clusters, we might use the *maximum* distance instead, as it merges
    the two clusters that fit in the smallest ball. Both are common choices, as is
    the *average* distance:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了合并最接近的簇，我们需要一些关于簇之间距离的概念。我们将使用两个簇中元素之间的*最小*距离，这将合并最接近接触的两个簇（但有时会产生不太紧密的链式簇）。如果我们想要紧凑的球状簇，我们可能会改用*最大*距离，因为它会合并适合最小球中的两个簇。这两种选择都很常见，同样常见的是*平均*距离：
- en: '[PRE17]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We’ll use the merge order slot to track the order in which we did the merging.
    Smaller numbers will represent *later* merges. This means when we want to unmerge
    clusters, we do so from lowest merge order to highest. Since `Leaf` clusters were
    never merged, we’ll assign them infinity, the highest possible value. And since
    they don’t have an `.order` property, we’ll create a helper function:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用合并顺序插槽来跟踪我们执行合并的顺序。较小的数字将表示*较晚*的合并。这意味着当我们想要拆分簇时，我们会从最低的合并顺序到最高的顺序进行。由于`Leaf`簇从未合并过，我们将给它们分配无穷大，即最大可能的值。由于它们没有`.order`属性，因此我们将创建一个辅助函数：
- en: '[PRE18]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Similarly, since `Leaf` clusters don’t have children, we’ll create and add
    a helper function for that:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，由于`Leaf`簇没有子节点，因此我们将为此创建并添加一个辅助函数：
- en: '[PRE19]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now we’re ready to create the clustering algorithm:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备创建聚类算法：
- en: '[PRE20]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Its use is very simple:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 它的使用非常简单：
- en: '[PRE21]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This produces a clustering that looks as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个如下所示的聚类：
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The numbers at the top indicate “merge order.” Since we had 20 inputs, it took
    19 merges to get to this one cluster. The first merge created cluster 18 by combining
    the leaves [19, 28] and [21, 27]. And the last merge created cluster 0.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 顶部的数字表示“合并顺序”。因为我们有20个输入，所以需要19次合并才能得到这一个簇。第一次合并通过组合叶子[19, 28]和[21, 27]创建了簇18。最后一次合并创建了簇0。
- en: If you wanted only two clusters, you’d split at the first fork (“0”), creating
    one cluster with six points and a second with the rest. For three clusters, you’d
    continue to the second fork (“1”), which indicates to split that first cluster
    into the cluster with ([19, 28], [21, 27], [20, 23], [26, 13]) and the cluster
    with ([11, 15], [13, 13]). And so on.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只想要两个簇，你可以在第一个分叉点“0”处分割，创建一个包含六个点的簇和另一个包含剩余点的簇。对于三个簇，你将继续到第二个分叉点“1”，它指示要将第一个簇拆分为包含([19,
    28], [21, 27], [20, 23], [26, 13])的簇和包含([11, 15], [13, 13])的簇。依此类推。
- en: 'Generally, though, we don’t want to be squinting at nasty text representations
    like this. Instead, let’s write a function that generates any number of clusters
    by performing the appropriate number of unmerges:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们通常不想看到像这样的难看文本表示。相反，让我们编写一个函数，通过执行适当数量的拆分来生成任意数量的簇：
- en: '[PRE23]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'So, for example, if we want to generate three clusters, we can just do:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想生成三个簇，我们只需执行以下操作：
- en: '[PRE24]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'which we can easily plot:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 可以轻松绘制的部分：
- en: '[PRE25]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This gives very different results than *k*-means did, as shown in [Figure 20-6](#hierarchical_clustering_image).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这与*k*-means产生了非常不同的结果，如[图20-6](#hierarchical_clustering_image)所示。
- en: '![Three Bottom-Up Clusters Using Min Distance.](assets/dsf2_2006.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![使用最小距离生成的三个自下而上的簇。](assets/dsf2_2006.png)'
- en: Figure 20-6\. Three bottom-up clusters using min distance
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图20-6\. 使用最小距离生成的三个自下而上的簇
- en: As mentioned previously, this is because using `min` in `cluster_distance` tends
    to give chain-like clusters. If we instead use `max` (which gives tight clusters),
    it looks the same as the 3-means result ([Figure 20-7](#hierarchical_clustering_image_max)).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这是因为在`cluster_distance`中使用`min`倾向于生成链式簇。如果我们改用`max`（生成紧密簇），它将与3-means结果相同（见[图20-7](#hierarchical_clustering_image_max)）。
- en: Note
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The previous `bottom_up_clustering` implementation is relatively simple, but
    also shockingly inefficient. In particular, it recomputes the distance between
    each pair of inputs at every step. A more efficient implementation might instead
    precompute the distances between each pair of inputs and then perform a lookup
    inside `cluster_distance`. A *really* efficient implementation would likely also
    remember the `cluster_distance`s from the previous step.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的`bottom_up_clustering`实现相对简单，但效率惊人地低下。特别是，它在每一步重新计算每对输入之间的距离。更高效的实现可能会预先计算每对输入之间的距离，然后在`cluster_distance`内执行查找。*真正*高效的实现可能还会记住前一步骤的`cluster_distance`。
- en: '![Three Bottom-Up Clusters Using Max Distance.](assets/dsf2_2007.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![使用最大距离的三个自底向上聚类。](assets/dsf2_2007.png)'
- en: Figure 20-7\. Three bottom-up clusters using max distance
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-7\. 使用最大距离的三个自底向上聚类
- en: For Further Exploration
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步探索
- en: scikit-learn has an entire module, [`sklearn.cluster`](http://scikit-learn.org/stable/modules/clustering.html),
    that contains several clustering algorithms including `KMeans` and the `Ward`
    hierarchical clustering algorithm (which uses a different criterion for merging
    clusters than ours did).
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn有一个完整的模块，[`sklearn.cluster`](http://scikit-learn.org/stable/modules/clustering.html)，其中包含几种聚类算法，包括`KMeans`和`Ward`层次聚类算法（其合并集群的标准与我们的不同）。
- en: '[SciPy](http://www.scipy.org/) has two clustering models: `scipy.cluster.vq`,
    which does *k*-means, and `scipy.cluster.hierarchy`, which has a variety of hierarchical
    clustering algorithms.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SciPy](http://www.scipy.org/) 提供了两种聚类模型：`scipy.cluster.vq`，实现*k*-均值；以及`scipy.cluster.hierarchy`，提供多种层次聚类算法。'
