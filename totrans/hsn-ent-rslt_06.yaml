- en: Chapter 6\. Company Matching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 5](ch05.html#chapter_5), we examined the challenge of resolving
    a larger set of individual entities, matching on name and date of birth. In this
    chapter, we consider another typical scenario, resolving organization entities
    so that we can get a more complete picture of their business.
  prefs: []
  type: TYPE_NORMAL
- en: We could perhaps use the date of incorporation of the organization as a discriminator,
    similar to the way we used date of birth to help identify unique individuals.
    However, this incorporation date information is not typically included in organization
    datasets; it is much more common for a company to be identified by its registered
    address.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, in this chapter, we will use company address information, along with
    company names, to identify likely matches. We will then consider how to evaluate
    a new record for matches against the original data sources without having to undertake
    a time-consuming retrain of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Sample Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will resolve a list of company names that is published by
    the UK Maritime and Coastguard Agency (MCA) against basic organization details
    published in the Companies House register. This problem illustrates some of the
    challenges of identifying unique references to the same company, simply based
    on name and address data.
  prefs: []
  type: TYPE_NORMAL
- en: UK Companies House provides a free downloadable data snapshot containing basic
    company data of live companies on the register. This data complements the “person
    with significant control” data we used in [Chapter 5](ch05.html#chapter_5).
  prefs: []
  type: TYPE_NORMAL
- en: The MCA publishes a list of recruitment and placement agencies approved under
    Regulation 1.4 of the Maritime Labour Convention (MLC) 2006.^([1](ch06.html#id470))
  prefs: []
  type: TYPE_NORMAL
- en: Data Acquisition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To acquire the datasets, we use the same approach we used in [Chapter 5](ch05.html#chapter_5).
    The MCA data, published as a single comma-separated values (CSV) file, is downloaded
    and ingested into a DataFrame. The Companies House snapshot data is downloaded
    as ZIP files, and the extracted JSON structure is then parsed into a DataFrame.
    Unwanted columns are then removed and the snapshot DataFrames are concatenated
    into a single composite DataFrame. Both raw datasets are then stored locally as
    CSV files for ease of reloading.
  prefs: []
  type: TYPE_NORMAL
- en: The code is available as *Chapter6.ipynb* in the [GitHub repository](https://github.com/mshearer0/HandsOnEntityResolution).
  prefs: []
  type: TYPE_NORMAL
- en: Data Standardization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To match the MCA company list to the Companies House organization dataset, we
    need to standardize the name and address data into the same format. We have seen
    how to cleanse names. Addresses, however, pose more of a challenge.  Even within
    reasonably consistent data from same source, we often see considerable variation
    in address format and content.
  prefs: []
  type: TYPE_NORMAL
- en: For example, consider the first three records in the MCA list, as shown in [Table 6-1](#table-6-1).
  prefs: []
  type: TYPE_NORMAL
- en: Table 6-1\. MCA sample addresses
  prefs: []
  type: TYPE_NORMAL
- en: '| Address attribute |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| 48 Charlotte Street, London, W1T 2NS |'
  prefs: []
  type: TYPE_TB
- en: '| 4th Floor, 105 George Street, Glasgow, G2 1PB |'
  prefs: []
  type: TYPE_TB
- en: '| Unit 16, Beaverbank Business Park EH7 4HG |'
  prefs: []
  type: TYPE_TB
- en: We can see the first address is made up of three comma-separated elements, the
    second record by four elements, and the third again by only two. In each case,
    the postcode is contained in the final element, but in the third record, it is
    grouped with part of the address itself. The building number is present in either
    the first element or the second element.
  prefs: []
  type: TYPE_NORMAL
- en: 'To view a histogram distribution of the number of address elements in the MCA
    list we can use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This gives us the distribution chart presented in [Figure 6-1](#fig-6-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0601.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-1\. MCA address element count
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This lack of consistency makes parsing addresses consistently into the same
    discrete elements for matching quite difficult. Therefore, for this example, we
    will use just exact postcode matches to compare addresses. More advanced parsing
    and matching techniques, such as natural language processing and geocoding, are
    discussed in [Chapter 11](ch11.html#chapter_11).
  prefs: []
  type: TYPE_NORMAL
- en: Companies House Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many jurisdictions companies are required to declare the nature of their
    incorporation at the end of their name, for example, adding “Limited” or “Ltd”
    if they are constituted as a limited liability company. These variable suffixes
    may not always be present, so standardization is challenging.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure a mismatch doesn’t unduly negatively interfere with the matching process,
    it is advisable to separate these lower-value terms from the name record as part
    of the standardization process. This will remove the chance of missing a potential
    match due to inconsistencies in suffix format, at the risk of declaring a false
    positive match between, say, a public limited company and a limited company with
    similar names.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to removing incorporation suffixes, it can also be helpful to remove
    common terms that don’t differentiate between companies and whose inclusion would
    otherwise exaggerate the similarity of our name matches.
  prefs: []
  type: TYPE_NORMAL
- en: Although we choose to remove these terms, or *stopwords*, from the company name
    attribute, they do still contain some value that may be useful when the decision
    to declare a match is in the balance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following helper function strips these stopwords, returning the cleansed
    company name and the removed terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can apply this function to the Company House data using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `*` operator unzips the series of tuples (containing `CompanyName` and `Stopwords`)
    returned by the helper function. We assemble these value lists into a two-row
    DataFrame that we then transpose to columns so that we can add as new attributes.
    This approach is efficient as we only have to create a new DataFrame once as opposed
    to per row.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we already have a discrete column containing a discrete postcode, all
    that remains is to standardize the column name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Maritime and Coastguard Agency Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To standardize the MCA company name, we first convert the name to uppercase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We also remove the stopwords and then we need to extract the postcode from the
    address field. A convenient way to do this is to use a *regular expression*.
  prefs: []
  type: TYPE_NORMAL
- en: Regular Expression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A regular expression is a sequence of characters that specifies a match pattern
    in text. Usually such patterns are used by string-searching algorithms for “find”
    or “find and replace” operations on strings, or for input validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'A UK postcode is made up of two parts. The first part compromises one or two
    capital letters followed by a single digit and then either a single digit or a
    single capital letter. After a space, the second part begins with a single digit
    followed by two capital letters (excluding CIKMOV). This can be encoded as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We can construct a helper function to find, extract, and return a matching
    pattern of characters or return a null value if not found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As before, we can apply this function to every row:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Record Blocking and Attribute Comparison
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As in the previous chapter, we will use the Splink tool to perform the matching
    process. Let’s consider the settings that will allow us to do this.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we can expect organizations with matching postcodes to be reasonable
    match candidates and similarly those with exactly equivalent names. We can use
    these conditions as our blocking rules, only calculating predictions when either
    condition is fulfilled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Splink provides a handy visualization for us to see the volume of record pairs
    that will pass the blocking rules. As expected, there are a significant number
    of postcode matches and very few exact name matches, as shown in [Figure 6-2](#fig-6-2).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/hoer_0602.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-2\. Blocking rule comparisons
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Within that subset of potential combinations, we evaluate the similarity of
    the selected pair of `CompanyName` entries in four segments:'
  prefs: []
  type: TYPE_NORMAL
- en: Exact match
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jaro-Winkler score of >0.9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jaro-Winkler score between 0.8 and 0.9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jaro-Winkler score of <0.8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also evaluate the stopwords in a similar manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'The corresponding Splink settings are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Of course, those pairs that pass the blocking rule as exact name equivalents
    will be evaluated as exact matches, whereas those with only a postcode match will
    be evaluated as candidates for both exact and approximate name matching.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can apply the blocking rules and calculate our match probabilities,
    we need to train our model. The Cartesian product of the two DataFrames is >500
    million pairwise combinations, so we train the *u* value using random sampling
    over 50 million target rows to have a reasonable sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'As in [Chapter 5](ch05.html#chapter_5), we use the expectation-maximization
    algorithm to estimate the *m* values. Here we block on only matching postcodes
    because the tiny relative proportion of name matches has no beneficial effect
    on the parameter estimation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can display the proportion of records in each segment that the trained model
    observes using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The record comparison chart, seen in [Figure 6-3](#fig-6-3), shows a strong
    differentiation on `CompanyName` similarity between matching and nonmatching records.
    For the stopwords, there is only a marked differentiation between the approximately
    matching records at similarity threshold equal to or greater than 0.9, but not
    exact.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0603.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-3\. Proportion of record comparisons by match status
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As expected, the parameters chart (as shown in [Figure 6-4](#fig-6-4)) shows
    that exact and approximate `CompanyName` matches have strong match weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/hoer_0604.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-4\. Model parameters
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Match Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, we expect to find a match for each of the MCA organizations
    in the Companies House dataset, so we set a low match threshold of 0.05 to make
    sure we surface as many potential matches as possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'To identify the MCA entities where we failed to find at least one match, we
    can merge our predictions with the MCA dataset by `unique_id` and then select
    those results with a null match weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As shown in [Figure 6-5](#fig-6-5), this produces 11 records for which we didn’t
    find any match.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0605.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-5\. Unmatched records
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: At the time of writing, a manual search of Companies House reveals that 7 of
    these 11 entities have candidate matches, but these candidates do not have exact
    matching postcodes or names and so were filtered out by our blocking rules. Two
    of these entities have candidates with exact match postcodes but significantly
    different names and so fall below our approximate similarity threshold. Finally,
    the two remaining candidates  have been dissolved and so are not included in our
    live companies snapshot.
  prefs: []
  type: TYPE_NORMAL
- en: 'A convenient way to examine the predicted matches and the contribution that
    an attribute makes to the overall match score is to draw a match weight waterfall
    chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In the example given in [Figure 6-6](#fig-6-6), we can see that the prior match
    weight, a measure of the likelihood that two records chosen at random refer to
    the same entity, is –13.29\. From this starting point, we add a match weight of
    20.92 when we find an exact match of the `CompanyName` “Bespoke Crew.” This represents
    the degree to which it’s more likely to find exact equivalence on `CompanyName`
    within the `match` population than within the `notmatch` population.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0606.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-6\. Match weights waterfall chart
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: However, we also need to subtract 0.45 due to the exact match on “Limited,”
    as an exact equivalent on stopwords is more likely to occur on `notmatch`es as
    opposed to `match`es. This gives us a final match weight of 7.19, which translates
    into a probability of almost 1.0.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After standardizing, the MCA data has 96 organizations.
  prefs: []
  type: TYPE_NORMAL
- en: At a 0.05 match threshold, our results are shown in [Table 6-2](#table-6-2).
  prefs: []
  type: TYPE_NORMAL
- en: Table 6-2\. MCA match results—low threshold
  prefs: []
  type: TYPE_NORMAL
- en: '| **Match threshold = 0.05** | **Number of matches** | **Unique entities matched**
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Name and postcode match | 47 | 45 |'
  prefs: []
  type: TYPE_TB
- en: '| Name match only | 37 | 31 |'
  prefs: []
  type: TYPE_TB
- en: '| Postcode match only | 116 | 27 |'
  prefs: []
  type: TYPE_TB
- en: '| **Total matches** | **200** | **85 (deduped)** |'
  prefs: []
  type: TYPE_TB
- en: '| Unmatched |   | 11 (of which 2 dissolved) |'
  prefs: []
  type: TYPE_TB
- en: '| **Total organizations** |   | **96** |'
  prefs: []
  type: TYPE_TB
- en: 'If we assume the deduped unique matches are true positive matches, 9 of the
    11 unmatched entities are false negatives, and the 2 dissolved entities are true
    negatives, then we can evaluate our performance as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper T r u e p o s i t i v e m a t c h e s left-parenthesis
    upper T upper P right-parenthesis equals 85"><mrow><mi>T</mi> <mi>r</mi> <mi>u</mi>
    <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi> <mi>v</mi>
    <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi>
    <mo>(</mo> <mi>T</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo> <mn>85</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper F a l s e p o s i t i v e m a t c h e s left-parenthesis
    upper F upper P right-parenthesis equals 200 minus 85 equals 115"><mrow><mi>F</mi>
    <mi>a</mi> <mi>l</mi> <mi>s</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi>
    <mi>t</mi> <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi>
    <mi>h</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo>
    <mn>200</mn> <mo>-</mo> <mn>85</mn> <mo>=</mo> <mn>115</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper F a l s e n e g a t i v e m a t c h e s left-parenthesis
    upper F upper N right-parenthesis equals 11 minus 2 equals 9"><mrow><mi>F</mi>
    <mi>a</mi> <mi>l</mi> <mi>s</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mi>g</mi> <mi>a</mi>
    <mi>t</mi> <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi>
    <mi>h</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>N</mi> <mo>)</mo> <mo>=</mo>
    <mn>11</mn> <mo>-</mo> <mn>2</mn> <mo>=</mo> <mn>9</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper T r u e n e g a t i v e s equals 2"><mrow><mi>T</mi> <mi>r</mi>
    <mi>u</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mi>g</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>s</mi> <mo>=</mo> <mn>2</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P r e c i s i o n equals StartFraction upper T upper P
    Over left-parenthesis upper T upper P plus upper F upper P right-parenthesis EndFraction
    equals StartFraction 85 Over left-parenthesis 85 plus 115 right-parenthesis EndFraction
    almost-equals 42 percent-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>e</mi> <mi>c</mi>
    <mi>i</mi> <mi>s</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>85</mn> <mrow><mo>(</mo><mn>85</mn><mo>+</mo><mn>115</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>42</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper R e c a l l equals StartFraction upper T upper P Over left-parenthesis
    upper T upper P plus upper F upper N right-parenthesis EndFraction equals StartFraction
    85 Over left-parenthesis 85 plus 9 right-parenthesis EndFraction almost-equals
    90 percent-sign"><mrow><mi>R</mi> <mi>e</mi> <mi>c</mi> <mi>a</mi> <mi>l</mi>
    <mi>l</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow> <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>85</mn> <mrow><mo>(</mo><mn>85</mn><mo>+</mo><mn>9</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>90</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper A c c u r a c y equals StartFraction left-parenthesis upper
    T upper P plus upper T upper N right-parenthesis Over left-parenthesis upper T
    upper P plus upper T upper N plus upper F upper P plus upper F upper N right-parenthesis
    EndFraction equals StartFraction left-parenthesis 85 plus 2 right-parenthesis
    Over left-parenthesis 85 plus 2 plus 115 plus 9 right-parenthesis EndFraction
    almost-equals 41 percent-sign"><mrow><mi>A</mi> <mi>c</mi> <mi>c</mi> <mi>u</mi>
    <mi>r</mi> <mi>a</mi> <mi>c</mi> <mi>y</mi> <mo>=</mo> <mfrac><mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>)</mo></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mo>(</mo><mn>85</mn><mo>+</mo><mn>2</mn><mo>)</mo></mrow>
    <mrow><mo>(</mo><mn>85</mn><mo>+</mo><mn>2</mn><mo>+</mo><mn>115</mn><mo>+</mo><mn>9</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>41</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Recalculating our predictions at a threshold of 0.9 removes postcode-only matches,
    giving us the results shown in [Table 6-3](#table-6-3).
  prefs: []
  type: TYPE_NORMAL
- en: Table 6-3\. MCA match result—high threshold
  prefs: []
  type: TYPE_NORMAL
- en: '| **Match threshold = 0.9** | **Number of matches** | **Unique entities matched**
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Name and postcode match | 47 | 45 |'
  prefs: []
  type: TYPE_TB
- en: '| Name match only | 37 | 31 |'
  prefs: []
  type: TYPE_TB
- en: '| Postcode match only | 3 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| **Total matches** | **87** | **73 (deduped)** |'
  prefs: []
  type: TYPE_TB
- en: '| Unmatched |   | 23 (of which 2 dissolved) |'
  prefs: []
  type: TYPE_TB
- en: '| **Total organizations** |   | **96** |'
  prefs: []
  type: TYPE_TB
- en: <math alttext="upper T r u e p o s i t i v e m a t c h e s left-parenthesis
    upper T upper P right-parenthesis equals 73"><mrow><mi>T</mi> <mi>r</mi> <mi>u</mi>
    <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi> <mi>v</mi>
    <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi>
    <mo>(</mo> <mi>T</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo> <mn>73</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper F a l s e p o s i t i v e m a t c h e s left-parenthesis
    upper F upper P right-parenthesis equals 87 minus 73 equals 14"><mrow><mi>F</mi>
    <mi>a</mi> <mi>l</mi> <mi>s</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi>
    <mi>t</mi> <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi>
    <mi>h</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo>
    <mn>87</mn> <mo>-</mo> <mn>73</mn> <mo>=</mo> <mn>14</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper F a l s e n e g a t i v e m a t c h e s left-parenthesis
    upper F upper N right-parenthesis equals 23 minus 2 equals 21"><mrow><mi>F</mi>
    <mi>a</mi> <mi>l</mi> <mi>s</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mi>g</mi> <mi>a</mi>
    <mi>t</mi> <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi>
    <mi>h</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>N</mi> <mo>)</mo> <mo>=</mo>
    <mn>23</mn> <mo>-</mo> <mn>2</mn> <mo>=</mo> <mn>21</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper T r u e n e g a t i v e s equals 2"><mrow><mi>T</mi> <mi>r</mi>
    <mi>u</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mi>g</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>s</mi> <mo>=</mo> <mn>2</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P r e c i s i o n equals StartFraction upper T upper P
    Over left-parenthesis upper T upper P plus upper F upper P right-parenthesis EndFraction
    equals StartFraction 73 Over left-parenthesis 73 plus 14 right-parenthesis EndFraction
    almost-equals 84 percent-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>e</mi> <mi>c</mi>
    <mi>i</mi> <mi>s</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>73</mn> <mrow><mo>(</mo><mn>73</mn><mo>+</mo><mn>14</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>84</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper R e c a l l equals StartFraction upper T upper P Over left-parenthesis
    upper T upper P plus upper F upper N right-parenthesis EndFraction equals StartFraction
    73 Over left-parenthesis 73 plus 21 right-parenthesis EndFraction almost-equals
    78 percent-sign"><mrow><mi>R</mi> <mi>e</mi> <mi>c</mi> <mi>a</mi> <mi>l</mi>
    <mi>l</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow> <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>73</mn> <mrow><mo>(</mo><mn>73</mn><mo>+</mo><mn>21</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>78</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper A c c u r a c y equals StartFraction left-parenthesis upper
    T upper P plus upper T upper N right-parenthesis Over left-parenthesis upper T
    upper P plus upper T upper N plus upper F upper P plus upper F upper N right-parenthesis
    EndFraction equals StartFraction left-parenthesis 73 plus 2 right-parenthesis
    Over left-parenthesis 73 plus 2 plus 14 plus 21 right-parenthesis EndFraction
    almost-equals 69 percent-sign"><mrow><mi>A</mi> <mi>c</mi> <mi>c</mi> <mi>u</mi>
    <mi>r</mi> <mi>a</mi> <mi>c</mi> <mi>y</mi> <mo>=</mo> <mfrac><mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>)</mo></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mo>(</mo><mn>73</mn><mo>+</mo><mn>2</mn><mo>)</mo></mrow>
    <mrow><mo>(</mo><mn>73</mn><mo>+</mo><mn>2</mn><mo>+</mo><mn>14</mn><mo>+</mo><mn>21</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>69</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, as expected, we see that a higher match threshold increases our precision
    from 42% to 86%, but at the cost of missing nearly twice as many potential matches
    (up from 9 to 21 false negatives).
  prefs: []
  type: TYPE_NORMAL
- en: Tuning an entity resolution solution requires a degree of trial and error, adjusting
    blocking rules, similarity thresholds, and overall match thresholds to find the
    optimum balance. This will depend heavily on the characteristics of your data
    and your risk appetite for failing to identify potential matches.
  prefs: []
  type: TYPE_NORMAL
- en: Matching New Entities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we have seen, model training is not a quick process. What if we have a new
    entity, say a new entry onto the MCA list, that we’d like to resolve against the
    Companies House data? Splink provides the option to match new records against
    previously matched datasets without retraining. We can also use this feature to
    find all potential matches, without the constraint of blocking rules or match
    thresholds, to help us understand why those candidates weren’t identified. For
    example, if we take the last entity in our unmatched population:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This results in a full list of candidate matches, the first four of which, with
    the highest match probabilities, are listed in [Figure 6-7](#fig-6-7).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/hoer_0607.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-7\. New potential matches
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The first entry in the table is the original record in the MCA dataset. The
    next three records, as candidates matches from the Companies House data, don’t
    have exact postcodes or name matches and so would have been excluded by our blocking
    rules. However, the second record does have a somewhat similar name and a close
    match on postcode and so looks like a good potential candidate.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we used a combination of name and address matching to resolve
    company entities across two datasets. We separated stopwords from our organization
    names and employed a regular expression to extract postcodes for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: We used exact equivalence blocking rules and then calculated our match probabilities
    based on name similarity above a threshold. We evaluated our results by examining
    the trade-off between setting a low match threshold that produced a relatively
    large number of false positives and using a high threshold with the consequence
    that we missed some potentially promising match candidates.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter has also illustrated that, even employing blocking techniques,
    entity resolution at scale can become a time-consuming and compute-intensive task.
    In subsequent chapters we will examine how to leverage cloud computing infrastructure
    to distribute our matching workload across a number of machines in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch06.html#id470-marker)) MLC 2006 regulates the operation of seafarer
    recruitment and placement services to inform seafarers seeking employment on ships
    flying flags other than those of their own countries.
  prefs: []
  type: TYPE_NORMAL
