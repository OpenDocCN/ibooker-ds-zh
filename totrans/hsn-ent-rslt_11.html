<html><head></head><body><section data-pdf-bookmark="Chapter 11. Further Considerations" data-type="chapter" epub:type="chapter"><div class="chapter" id="chapter_11">&#13;
<h1><span class="label">Chapter 11. </span>Further Considerations</h1>&#13;
&#13;
<p>Hopefully the previous chapters have given you a solid practical understanding of how to resolve entities within your datasets and have equipped you to overcome some of the challenges you are likely to meet along the way.</p>&#13;
&#13;
<p>Real-world data<a contenteditable="false" data-primary="cloud entity resolution services" data-see="also Google Cloud Platform" data-type="indexterm" id="id640"/><a contenteditable="false" data-primary="standardization" data-see="data standardization" data-type="indexterm" id="id641"/><a contenteditable="false" data-primary="MCA data" data-see="Maritime and Coastguard Agency data" data-type="indexterm" id="id642"/><a contenteditable="false" data-primary="Companies House data" data-see="UK Companies House data" data-type="indexterm" id="id643"/><a contenteditable="false" data-primary="pairwise comparisons" data-see="also clustering" data-type="indexterm" id="id644"/><a contenteditable="false" data-primary="scaling" data-see="Google Cloud Platform" data-type="indexterm" id="id645"/><a contenteditable="false" data-primary="GCP" data-see="Google Cloud Platform" data-type="indexterm" id="id646"/><a contenteditable="false" data-primary="entity resolution" data-see="also cloud entity resolution services" data-type="indexterm" id="id647"/><a contenteditable="false" data-primary="Google Cloud Platform (GCP)" data-see="also cloud entity resolution services" data-type="indexterm" id="id648"/><a contenteditable="false" data-primary="Enterprise KG" data-see="Google Enterprise Knowledge Graph API" data-type="indexterm" id="id649"/><a contenteditable="false" data-primary="matching" data-see="also company matching; entity resolution; probabilistic matching; text matching" data-type="indexterm" id="id650"/><a contenteditable="false" data-primary="DataFrames" data-see="pandas DataFrames" data-type="indexterm" id="id651"/> is messy and full of surprises, so joining it up is rarely straightforward. But it’s well worth spending the time to make the connections because the story becomes so much richer when we can bring together all the pieces of the jigsaw.</p>&#13;
&#13;
<p>In this short closing chapter, I’ll talk about a few aspects of entity resolution that are worth considering when building a resilient production solution. I’ll also share some closing thoughts on the future of the art and science of entity resolution.</p>&#13;
&#13;
<section data-pdf-bookmark="Data Considerations" data-type="sect1"><div class="sect1" id="id264">&#13;
<h1>Data Considerations</h1>&#13;
&#13;
<p>As with any analytic process, the importance of understanding the context and quality of your input data cannot be overstated. Quirks or misunderstandings in data that a traditional application could tolerate may fundamentally derail a matching process. Poor data can result in over- and underlinking, sometimes matching entities that do not represent the same person, with potentially serious consequences.</p>&#13;
&#13;
<p>In this section, I’ll discuss the most important data-related issues to consider when performing entity resolution.</p>&#13;
&#13;
<section data-pdf-bookmark="Unstructured Data" data-type="sect2"><div class="sect2" id="id87">&#13;
<h2>Unstructured Data</h2>&#13;
&#13;
<p>Throughout<a contenteditable="false" data-primary="data standardization" data-secondary="unstructured data" data-type="indexterm" id="id652"/><a contenteditable="false" data-primary="unstructured data" data-type="indexterm" id="id653"/> this book we have primarily used structured data to perform the matching process. When we encountered<a contenteditable="false" data-primary="semi-unstructured data" data-type="indexterm" id="id654"/> semi-unstructured data we used very simple rules of thumb to extract the attributes we needed. For example, in <a data-type="xref" href="ch02.html#chapter_2">Chapter 2</a>, we somewhat arbitrarily split full name strings into <code>Firstname</code> and <code>Lastname</code>, and in <a data-type="xref" href="ch06.html#chapter_6">Chapter 6</a>, we extracted only the postcode from the full address text. In the name of simplicity, we neglected potentially valuable data that could have enriched our matching process.</p>&#13;
&#13;
<p>Fortunately, the state of the art in extracting meaning from unstructured text has developed considerably in the last few years. Advances in<a contenteditable="false" data-primary="named entity recognition (NER)" data-type="indexterm" id="id655"/> named entity recognition (NER) techniques for understanding sentence construction, and extracting entities in context, mean we can more easily link to unstructured content.</p>&#13;
&#13;
<p>For example, there are several Python libraries<a contenteditable="false" data-primary="Python" data-secondary="address parsing libraries" data-type="indexterm" id="id656"/> available (such as<a contenteditable="false" data-primary="usaddress library" data-type="indexterm" id="id657"/><a contenteditable="false" data-primary="deepparse library" data-type="indexterm" id="id658"/><a contenteditable="false" data-primary="libpostal library" data-type="indexterm" id="id659"/> usaddress, deepparse, and libpostal) that can<a contenteditable="false" data-primary="addresses, parsing" data-type="indexterm" id="id660"/> parse addresses, extracting individual house number, street, and town attributes. The performance of these models depends on the availability of high-quality training data and so varies by country.</p>&#13;
&#13;
<p>However, even the most sophisticated NER cannot make up for the absence of key attributes if they are not present in the source text. News articles, for example, will rarely provide a date of birth for their subjects, and financial transactions will not typically include a social security number.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Data Quality" data-type="sect2"><div class="sect2" id="id88">&#13;
<h2>Data Quality</h2>&#13;
&#13;
<p>In<a contenteditable="false" data-primary="data standardization" data-secondary="data quality" data-type="indexterm" id="id661"/><a contenteditable="false" data-primary="input data, quality of" data-type="indexterm" id="id662"/> our illustrative examples, we have accepted much of our input data at face value and taken expedient shortcuts to prepare our data for matching. For example, as a shortcut, we simply dropped records that contained an attribute with a missing  value. Our process should be able to ignore (i.e., assign a zero match weight to that attribute) as opposed to discarding the whole record. For a production solution, a more rigorous approach to measuring and continuously improving data quality is vital. The better the data quality, the easier the matching task will be.</p>&#13;
&#13;
<p>Additional data checks for completeness and<a contenteditable="false" data-primary="characters, identifying hidden and unexpected" data-type="indexterm" id="id663"/> validity (including identifying hidden and unexpected characters) will alert you to problems that may frustrate your matching process in unexpected ways and are challenging to diagnose further down the line.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Temporal Equivalence" data-type="sect2"><div class="sect2" id="id89">&#13;
<h2>Temporal Equivalence</h2>&#13;
&#13;
<p>The<a contenteditable="false" data-primary="entity resolution" data-secondary="temporal equivalence and" data-type="indexterm" id="id664"/><a contenteditable="false" data-primary="temporal equivalence and" data-type="indexterm" id="id665"/><a contenteditable="false" data-primary="data standardization" data-secondary="temporal equivalence" data-type="indexterm" id="id666"/> entity resolution process relies on matching attributes to determine whether records refer to the same real-world entity. However, the attributes associated with an entity may change over time. Last names may change with marital status; phone numbers and email addresses may change as individuals swap service providers; passports, driving licenses, and other forms of identification are reissued with new identifiers.</p>&#13;
&#13;
<p>It sounds obvious, but this temporal aspect of entity resolution is often overlooked, so my advice is to be careful with datasets that contain data drawn from different time periods and ensure the model doesn’t place too much weight on attributes that are subject to change. Of course, where the entity is trying not to be identified, frequent attribute changes can be sign of a deliberate attempt to frustrate the entity resolution process.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Attribute Comparison" data-type="sect1"><div class="sect1" id="id139">&#13;
<h1>Attribute Comparison</h1>&#13;
&#13;
<p>In <a data-type="xref" href="ch03.html#chapter_3">Chapter 3</a>, we<a contenteditable="false" data-primary="data standardization" data-secondary="attribute comparison" data-type="indexterm" id="DSatcomp11"/><a contenteditable="false" data-primary="attribute comparison" data-secondary="data standardization" data-type="indexterm" id="id667"/> explored some of the most commonly used techniques for approximate string matching. We considered edit distance and phonetic equivalence to determine a match between discrete name attributes. These approaches work well when we have a single token, such as a discrete element of a name, to compare. When we are faced with assessing the similarity between two strings with multiple words or tokens, such as addresses or the names of organizations, then there are other techniques we can consider.</p>&#13;
&#13;
<section data-pdf-bookmark="Set Matching" data-type="sect2"><div class="sect2" id="id90">&#13;
<h2>Set Matching</h2>&#13;
&#13;
<p>When<a contenteditable="false" data-primary="attribute comparison" data-secondary="set matching" data-type="indexterm" id="id668"/><a contenteditable="false" data-primary="set matching" data-type="indexterm" id="id669"/><a contenteditable="false" data-primary="matching" data-secondary="set matching" data-type="indexterm" id="id670"/> an entity is identified by a collection of terms, we can use set-based methods (such as<a contenteditable="false" data-primary=" Jaccard index" data-type="indexterm" id="id671"/> Jaccard index<sup><a data-type="noteref" href="ch11.html#id672" id="id672-marker">1</a></sup>) to measure the degree of overlap between the tokens present in each set. More sophisticated methods, such as Monge-Elkan similarity, combine both set-based and edit distance techniques to perform the comparison.</p>&#13;
&#13;
<p>Recent advances in<a contenteditable="false" data-primary="sentence embedding" data-type="indexterm" id="id673"/> sentence embedding<sup><a data-type="noteref" href="ch11.html#id674" id="id674-marker">2</a></sup> now allow us to translate the<a contenteditable="false" data-primary="semantic meaning, translating" data-type="indexterm" id="id675"/> semantic meaning of a string of text into a vector (an array of quantities in number of dimensions). These vectorizing models, trained on vast repositories of open source data, are accessible through public interfaces, such as OpenAI’s embedding API. The semantic similarity of these text strings can then be assessed by techniques such as cosine similarity, which measures the angle between the vectors.</p>&#13;
&#13;
<p>Vector-based approaches can also be applied to measure the similarity between individual words (represented as strings of single characters or multiple character n-grams) but they typically do not consider the sequence of these letters, which can be extremely important in matching, e.g., NAB (an Australian bank) versus NBA (a US basketball organization).</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Geocoding Location Matching" data-type="sect2"><div class="sect2" id="id91">&#13;
<h2>Geocoding Location Matching</h2>&#13;
&#13;
<p>An<a contenteditable="false" data-primary="attribute comparison" data-secondary="geocoding location matching" data-type="indexterm" id="id676"/><a contenteditable="false" data-primary="geocoding location matching" data-type="indexterm" id="id677"/><a contenteditable="false" data-primary="location matching" data-type="indexterm" id="id678"/><a contenteditable="false" data-primary="matching" data-secondary="location matching" data-type="indexterm" id="id679"/> alternative to matching the individual words, or tokens, that comprise an address is to convert the address into a set of geographic coordinates (latitude and longitude). We can then compare these values within a set straight line distance tolerance to determine if they refer to the same place. Clearly, for multioccupancy locations in close proximity (within a shared building or industrial estate, for example), this approach can produce a number of false positives.</p>&#13;
&#13;
<p>At the time of writing Google, Microsoft, and OpenStreetMap (via Nominatim) offer geocoding APIs that will perform the conversion, subject to pricing and usage policies. As an on-demand software as a service (SaaSso) offering, this approach may not be suitable for bulk address comparison or where the data is sensitive and cannot be shared with third parties.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Aggregating Comparisons" data-type="sect2"><div class="sect2" id="id92">&#13;
<h2>Aggregating Comparisons</h2>&#13;
&#13;
<p>As<a contenteditable="false" data-primary="attribute comparison" data-secondary="aggregating comparisons" data-type="indexterm" id="id680"/> we have seen, there are often several different techniques we can use to compare attributes, each with their strengths and weaknesses. In certain use cases it may be beneficial to evaluate a potential match using multiple approaches, for example, using both a<a contenteditable="false" data-primary="Soundex comparisons" data-type="indexterm" id="id681"/> Soundex comparison and an<a contenteditable="false" data-primary="edit distance" data-type="indexterm" id="id682"/><a contenteditable="false" data-primary="text matching" data-secondary="edit distance matching" data-type="indexterm" id="id683"/> edit distance measurement to determine the most appropriate result.</p>&#13;
&#13;
<p>It should be noted that if parallel techniques are used on the same attributes, then the results will not respect the<a contenteditable="false" data-primary="conditional  independence assumption " data-type="indexterm" id="id684"/> conditional<a contenteditable="false" data-primary="independence assumption" data-type="indexterm" id="id685"/> independence assumption of the<a contenteditable="false" data-primary="Fellegi-Sunter (FS) model" data-type="indexterm" id="id686"/> Fellegi-Sunter model and therefore may not perform well when using probabilistic tools such as Splink. In particular, the different measurements should be included at different comparison levels within a single comparison to avoid double counting. Alternatively, these different measurements could be preaggregated into a single score using a custom similarity function.<a contenteditable="false" data-primary="" data-startref="DSatcomp11" data-type="indexterm" id="id687"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Post Processing" data-type="sect1"><div class="sect1" id="id93">&#13;
<h1>Post Processing</h1>&#13;
&#13;
<p>In <a data-type="xref" href="ch10.html#chapter_10">Chapter 10</a>, we<a contenteditable="false" data-primary="post processing" data-type="indexterm" id="postpro11"/><a contenteditable="false" data-primary="entity resolution" data-secondary="post processing" data-type="indexterm" id="ERpostpro11"/> saw how we can group paired records into a single distinct cluster. We also introduced the challenge of determining which attribute values to use to describe our unified entity. The selection logic to choose which attribute value to promote is likely to be bespoke to your use case and may depend upon the relative trustworthiness and seniority of your datasets.</p>&#13;
&#13;
<p>Once a canonical entity view has been established, there is the opportunity to repeat the pairwise matching exercise, treating the newly consolidated entity as a new record. Additional records, previously too dissimilar to match, may now reach the equivalence threshold due to the concentration of attributes in the new composite entity.</p>&#13;
&#13;
<p>For example, consider the input records shown in <a data-type="xref" href="#table-11-1">Table 11-1</a>. Records 1 and 2 may be assessed as referring to the same individual (based on equivalent first name and date of birth) but Record 3 does not have sufficient commonality with either to join that small cluster.</p>&#13;
&#13;
<table id="table-11-1">&#13;
	<caption><span class="label">Table 11-1. </span>Entity resolution—input</caption>&#13;
	<thead>&#13;
		<tr>&#13;
			<th><strong>Attribute</strong></th>&#13;
			<th><strong>Record 1</strong></th>&#13;
			<th><strong> Record 2</strong></th>&#13;
			<th><strong>Record 3</strong></th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<th>First name</th>&#13;
			<td>Michael </td>&#13;
			<td>Michael</td>&#13;
			<td>M</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Last name</th>&#13;
			<td>Shearer</td>&#13;
			<td>Shear</td>&#13;
			<td>Shearer</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Date of birth</th>&#13;
			<td>4/1/1970</td>&#13;
			<td>4/1/1970</td>&#13;
			<td> </td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Place of birth</th>&#13;
			<td>                        </td>&#13;
			<td>Stow on the Wold</td>&#13;
			<td>Stow on the Wold</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Mobile number</th>&#13;
			<td> </td>&#13;
			<td> </td>&#13;
			<td>07700 900999</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>Having resolved Records 1 and 2 into a single entity, suppose we choose the value “Shearer” over “Shear” to represent the last name. Perhaps Record 1 was part of a dataset that was deemed of higher quality than that containing Record 2. Or perhaps we implemented a rule to select the more complete value. As shown in <a data-type="xref" href="#table-11-2">Table 11-2</a>, we would then have a richer set of attributes to match against Record 3.</p>&#13;
&#13;
<table id="table-11-2">&#13;
	<caption><span class="label">Table 11-2. </span>Entity resolution—pairwise clustering</caption>&#13;
	<thead>&#13;
		<tr>&#13;
			<th><strong>Attribute</strong></th>&#13;
			<th><strong>Cluster 1<br/>&#13;
			Record 1 and 2</strong></th>&#13;
			<th><strong>Record 3</strong></th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<th>First name</th>&#13;
			<td>Michael </td>&#13;
			<td>M </td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Last name</th>&#13;
			<td>Shearer</td>&#13;
			<td>Shearer</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Date of birth</th>&#13;
			<td>4/1/1970</td>&#13;
			<td> </td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Place of birth</th>&#13;
			<td>Stow on the Wold       </td>&#13;
			<td>Stow on the Wold</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Mobile number</th>&#13;
			<td> </td>&#13;
			<td>07700 900999</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>If an exact last name match and equivalent place of birth were deemed sufficient evidence, then we could conclude that Record 3 should now join the cluster of Records 1 and 2.</p>&#13;
&#13;
<p>As shown in <a data-type="xref" href="#table-11-3">Table 11-3</a>, we have now resolved all three records into a single entity and, thanks to our additional step, added a phone number that we would otherwise not have linked to our entity.</p>&#13;
&#13;
<table id="table-11-3">&#13;
	<caption><span class="label">Table 11-3. </span>Entity resolution—entity record resolution</caption>&#13;
	<thead>&#13;
		<tr>&#13;
			<th><strong>Attribute</strong></th>&#13;
			<th><strong>Cluster 1<br/>&#13;
			Record 1, 2, and 3</strong></th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<th>First name</th>&#13;
			<td>Michael </td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Last name</th>&#13;
			<td>Shearer</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Date of birth</th>&#13;
			<td>4/1/1970</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Place of birth</th>&#13;
			<td>Stow on the Wold       </td>&#13;
		</tr>&#13;
		<tr>&#13;
			<th>Mobile number</th>&#13;
			<td><strong>07700 900999</strong></td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>This shows how we can progressively build the confidence to join these records into a single clustered entity. This is an example of “bottom up,” or<a contenteditable="false" data-primary="agglomerative hierarchical clustering" data-type="indexterm" id="id688"/><a contenteditable="false" data-primary="hierarchical agglomerative clustering" data-type="indexterm" id="id689"/><a contenteditable="false" data-primary="clustering" data-secondary="hierarchical agglomerative clustering" data-type="indexterm" id="id690"/> agglomerative hierarchical clustering. In this simple example, we exhaustively linked all three records, but in larger datasets there would have been many more candidates to compare and potentially cluster together in subsequent iterations.</p>&#13;
&#13;
<p>In <a data-type="xref" href="ch08.html#chapter_8">Chapter 8</a>, we saw how the<a contenteditable="false" data-primary="Google Cloud Entity Reconciliation service" data-type="indexterm" id="id691"/> Google Cloud Entity Reconciliation service uses this technique. The Google service specifies a number of iterations after which it terminates the clustering process. Clearly, this approach can be computationally intensive on large datasets and is not guaranteed to find the optimum solution.<a contenteditable="false" data-primary="" data-startref="postpro11" data-type="indexterm" id="id692"/><a contenteditable="false" data-primary="" data-startref="ERpostpro11" data-type="indexterm" id="id693"/></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Graphical Representation" data-type="sect1"><div class="sect1" id="id94">&#13;
<h1>Graphical Representation</h1>&#13;
&#13;
<p>After <a contenteditable="false" data-primary="cloud entity resolution services" data-secondary="Google Enterprise Knowledge Graph API" data-type="indexterm" id="id694"/><a contenteditable="false" data-primary="graph visualizations" data-type="indexterm" id="id695"/>attribute comparison and pairwise match classification, the final steps in the entity resolution process overlap quite significantly with the field of graph analytics.</p>&#13;
&#13;
<p>As we saw in <a data-type="xref" href="ch10.html#chapter_10">Chapter 10</a>, the output of the clustering process can be presented as an<a contenteditable="false" data-primary="nodes" data-type="indexterm" id="id696"/><a contenteditable="false" data-primary="edges" data-type="indexterm" id="id697"/> entity graph of source records (nodes) and a set of matching attribute pairs (edges).  This representation may form part of a wider network graph showing how distinct entities are connected via shared relationships or common attributes. This representation is useful to allow inspection (and potential discounting) of the matches informed by the context of their wider network.</p>&#13;
&#13;
<p>Alternatively, if matching confidence is high, or a simpler representation is required, the entity graph can resolve (or collapse) to a single node. That node can either list a canonical set of attributes or persist the alternative attribute values for closer examination. This curated network, or knowledge graph, provides a combined view of all the information about a given entity drawn from different sources.</p>&#13;
&#13;
<p>You may have noticed that this is partly how Google search works today. Search results now present factual information from <a href="https://oreil.ly/H59UU">Google’s Knowledge Graph</a>, which contains over 500 million objects with over 3.5 billion facts about, and relationships between, these different objects. As we saw in <a data-type="xref" href="ch08.html#chapter_8">Chapter 8</a>, you can now resolve your entities against Google’s objects using their reconciliation API.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Real-Time Considerations" data-type="sect1"><div class="sect1" id="id95">&#13;
<h1>Real-Time Considerations</h1>&#13;
&#13;
<p>In<a contenteditable="false" data-primary="static versus real-time data" data-type="indexterm" id="id698"/><a contenteditable="false" data-primary="real-time versus static data" data-type="indexterm" id="id699"/><a contenteditable="false" data-primary="entity resolution" data-secondary="static versus real-time data" data-type="indexterm" id="id700"/> this book, we have considered batch-based entity resolution of static datasets. This point-in-time approach allows us to compare, match, and cluster all relevant records to produce a set of resolved entities. This reference point can then be used for a period of time before becoming stale and the exercise repeated. In <a data-type="xref" href="ch06.html#chapter_6">Chapter 6</a>, we saw how to pairwise match a new record against an existing dataset using a pretrained probabilistic model.</p>&#13;
&#13;
<p>If an up-to-the-minute set of all resolved entities is required, then incrementally processing new records as they arrive brings with it some additional considerations. Depending upon the processing time window available, it may be challenging to recluster and generate new canonical entities based on the contents of a newly available record, or to reshape existing entities into a new configuration.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Performance Evaluation" data-type="sect1"><div class="sect1" id="id96">&#13;
<h1>Performance Evaluation</h1>&#13;
&#13;
<p>The<a contenteditable="false" data-primary="performance, measuring" data-secondary="functional performance" data-type="indexterm" id="id701"/><a contenteditable="false" data-primary="functional performance" data-type="indexterm" id="id702"/> functional performance of an entity resolution solution may be evaluated by the extent to which records are matched when then they are truly distinct (overlinking) or remain unconnected when they refer to the same real-world entity (underlinking). The nature of the decisions and actions you propose to take based on the resolved dataset will determine the relative priority of these metrics. For example, in a high-risk situation, where the consequence of missing a link could be significant, you may wish to err toward overlinking. In a more speculative process, you may wish to lean toward underlinking to minimize unnecessary customer friction.</p>&#13;
&#13;
<p>Systematic evaluation<a contenteditable="false" data-primary="performance, measuring" data-secondary="systematic evaluation" data-type="indexterm" id="id703"/><a contenteditable="false" data-primary="systematic evaluation" data-type="indexterm" id="id704"/> of the degree to which your solution is over- or underlinking is challenging. In the earlier chapters of this book, we had the benefit of a known population against which we could evaluate the precision, recall, and accuracy of our process. But in practice that is rarely the case. The need to resolve entities usually arises as a result of the lack of a common key or known population between datasets, thereby depriving the evaluator of ground truth against which to measure performance.</p>&#13;
&#13;
<p>Smaller benchmark datasets, which can be affordably manually linked, are often used to<a contenteditable="false" data-primary="performance, predicting" data-type="indexterm" id="id705"/> predict performance at scale. However, these limited datasets can give a distorted view of the likely real-world outcomes. Larger datasets are more likely to contain distinct entities that have similar attributes (e.g., same name), increasing the rate of false positives. Care must also be taken to make sure the distribution of benchmark dataset is accounted for in the evaluation process. The ratio of matching to nonmatching records is often significantly higher in benchmark datasets that are constructed to check that the matching process finds the right matches (i.e., maximizes recall) but gives an overly optimistic view of the frequency of errors (i.e., overestimates precision). There is also a risk, particularly for the more sophisticated embedding-based approaches, of overfitting the entity resolution model because the benchmark data was represented in the training data, resulting in poor generalized performance.</p>&#13;
&#13;
<p>Evaluating the performance of an entity resolution solution is a critical part of model development and improvement. It requires labeling data that can then be used to train more sophisticated models or to estimate performance metrics such as precision and recall.</p>&#13;
&#13;
<p>There are two main approach types to data labeling and performance evaluation in entity resolution applications:</p>&#13;
&#13;
<dl>&#13;
	<dt>Pairwise approach</dt>&#13;
	<dd>&#13;
	<p>Labeling a set of record pairs as a match and not a match</p>&#13;
	</dd>&#13;
	<dt>Cluster-based approach</dt>&#13;
	<dd>&#13;
	<p>Identifying or using a set of known, fully resolved entities (clusters)</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<section data-pdf-bookmark="Pairwise Approach" data-type="sect2"><div class="sect2" id="id97">&#13;
<h2>Pairwise Approach</h2>&#13;
&#13;
<p>Using<a contenteditable="false" data-primary="performance, measuring" data-secondary="pairwise approach" data-type="indexterm" id="id706"/><a contenteditable="false" data-primary="pairwise evaluation" data-type="indexterm" id="id707"/> a pairwise approach we can estimate precision, i.e., how often we are correct when we declare a match, by simply sampling pairs of matched records and manually reviewing them. Once classified as true or false positives, we can calculate precision as:</p>&#13;
&#13;
<div data-type="equation">&#13;
<p><math alttext="upper P r e c i s i o n equals StartFraction upper T r u e p o s i t i v e s Over left-parenthesis upper T r u e p o s i t i v e s plus upper F a l s e p o s i t i v e s right-parenthesis EndFraction">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mi>r</mi>&#13;
    <mi>e</mi>&#13;
    <mi>c</mi>&#13;
    <mi>i</mi>&#13;
    <mi>s</mi>&#13;
    <mi>i</mi>&#13;
    <mi>o</mi>&#13;
    <mi>n</mi>&#13;
    <mo>=</mo>&#13;
    <mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mspace width="4pt"/><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow> <mrow><mo>(</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mspace width="4pt"/><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mspace width="4pt"/><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>)</mo></mrow></mfrac>&#13;
  </mrow>&#13;
</math></p>&#13;
</div>&#13;
&#13;
<p>To estimate recall is more challenging, as we essentially have to repeat the resolution exercise to identify records that should have been declared a match but were not. This can be more efficiently estimated by selecting a block of loosely matching records and then exhaustively reviewing all the potential pairs of records within this block. Of course, as with any blocking approach, we risk overlooking wildcard matches that didn’t make it into our loosely selected block.</p>&#13;
&#13;
<p>As a reminder, recall is calculated as:</p>&#13;
&#13;
<div data-type="equation">&#13;
<p><math alttext="upper R e c a l l equals StartFraction upper T r u e p o s i t i v e s Over left-parenthesis upper T r u e p o s i t i v e s plus upper F a l s e n e g a t i v e s right-parenthesis EndFraction">&#13;
  <mrow>&#13;
    <mi>R</mi>&#13;
    <mi>e</mi>&#13;
    <mi>c</mi>&#13;
    <mi>a</mi>&#13;
    <mi>l</mi>&#13;
    <mi>l</mi>&#13;
    <mo>=</mo>&#13;
    <mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mspace width="4pt"/><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow> <mrow><mo>(</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mspace width="4pt"/><mi>p</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mspace width="4pt"/><mi>n</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>)</mo></mrow></mfrac>&#13;
  </mrow>&#13;
</math></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Cluster-Based Approach" data-type="sect2"><div class="sect2" id="id98">&#13;
<h2>Cluster-Based Approach</h2>&#13;
&#13;
<p>An<a contenteditable="false" data-primary="performance, measuring" data-secondary="cluster-based approach" data-type="indexterm" id="id708"/><a contenteditable="false" data-primary="cluster-based evaluation" data-type="indexterm" id="id709"/> alternative to the pairwise approach is to manually determine, for example, through the use of search tools, a true cluster view of those records that described the same real-world entity. We can then compare our pairwise predictions against this gold standard to assess our performance and improve our model. For example, consider the simple example shown in <a data-type="xref" href="#fig-11-1">Figure 11-1</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig-11-1"><img alt="" class="iimagesch11ch11clusterspng" src="assets/hoer_1101.png"/>&#13;
<h6><span class="label">Figure 11-1. </span>Cluster-based evaluation example</h6>&#13;
</div></figure>&#13;
&#13;
<p>Within a population of four records, A to D, our model has paired records A + B and C + D. A true cluster view shows that A, B, and C all refer to the same entity but D is distinct. From this, we can assess the following and calculate our performance metrics.</p>&#13;
&#13;
<table id="table-11-4">&#13;
	<thead>&#13;
		<tr>&#13;
			<th scope="col">Record pair</th>&#13;
			<th scope="col">Predicted</th>&#13;
			<th scope="col">Actual</th>&#13;
			<th scope="col">Result</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>A - B</td>&#13;
			<td>Match</td>&#13;
			<td>Match</td>&#13;
			<td>True positive</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>A - C</td>&#13;
			<td>Not match</td>&#13;
			<td>Match</td>&#13;
			<td>False negative</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>A - D</td>&#13;
			<td>Not match</td>&#13;
			<td>Not match</td>&#13;
			<td>True negative</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>B - C</td>&#13;
			<td>Not match</td>&#13;
			<td>Match</td>&#13;
			<td>False negative</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>B - D</td>&#13;
			<td>Not match</td>&#13;
			<td>Not match</td>&#13;
			<td>True negative</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>C - D</td>&#13;
			<td>Match</td>&#13;
			<td>Not match</td>&#13;
			<td>False positive</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>The evaluation of entity resolution is an area of active research with toolsets emerging to assist with the process and produce actionable feedback to improve <span class="keep-together">performance</span>.<sup><a data-type="noteref" href="ch11.html#id710" id="id710-marker">3</a></sup></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Future of Entity Resolution" data-type="sect1"><div class="sect1" id="id99">&#13;
<h1>Future of Entity Resolution</h1>&#13;
&#13;
<p>Entity resolution<a contenteditable="false" data-primary="entity resolution" data-secondary="future of" data-type="indexterm" id="id711"/> is by definition a means to an end. By resolving entities, we seek to assemble all the relevant information from multiple sources to enable us to derive valuable insights and ultimately make better decisions.</p>&#13;
&#13;
<p>In an increasingly digital world, we have a shared responsibility to ensure that our data records accurately and comprehensively reflect society. If we have incorrect information, or only part of the picture, we risk drawing the wrong conclusions and taking the wrong actions. There is also a duty to respect individual privacy and to manage sensitive data accordingly.</p>&#13;
&#13;
<p>The art and science of entity resolution is evolving to balance these concerns. Entity resolution can enhance your ability to connect the dots in your data and show the bigger picture. Increasingly it can be done without unnecessarily sharing personal information. New machine learning algorithms, and techniques to more rigorously evaluate and optimize their performance, are now freely available.</p>&#13;
&#13;
<p>Recent advancements in the scale and availability of<a contenteditable="false" data-primary="large language models (LLMs)" data-type="indexterm" id="id712"/> large language models (LLMs) open up a breadth of information about how real-world entities are described and interrelated. The embedding technology that underpins these models provides a rich context to inform the matching processes. The increasing availability of managed entity resolution services and the ability to relate your entities to public knowledge repositories promises to make the matching process easier and the results richer.</p>&#13;
&#13;
<p>I hope you have enjoyed our shared journey through the challenges of entity resolution and that you feel ready to join the dots in your data. Who knows what you will find...</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id672"><sup><a href="ch11.html#id672-marker">1</a></sup> For more details on the Jaccard index, visit the <a href="https://oreil.ly/vJyir">Wikipedia page</a>.</p><p data-type="footnote" id="id674"><sup><a href="ch11.html#id674-marker">2</a></sup> Further details on how to use the sent2vec library are available in the <a href="https://oreil.ly/SUHrG">PyPI documentation</a>.</p><p data-type="footnote" id="id710"><sup><a href="ch11.html#id710-marker">3</a></sup> For example, an open source Python package for the evaluation of entity resolution (ER) systems is available on <a href="https://github.com/Valires/er-evaluation">GitHub</a>.</p></div></div></section></body></html>