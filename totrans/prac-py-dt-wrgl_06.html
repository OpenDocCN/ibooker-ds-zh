<html><head></head><body><section data-pdf-bookmark="Chapter 6. Assessing Data Quality" data-type="chapter" epub:type="chapter"><div class="chapter" id="chapter6">&#13;
<h1><span class="label">Chapter 6. </span>Assessing Data Quality</h1>&#13;
&#13;
&#13;
<p>Over<a data-primary="data quality" data-secondary="difficulty of achieving" data-type="indexterm" id="data-quality-difficult"/> the past two chapters, we’ve focused our efforts on identifying and accessing different formats of data in different locations—from spreadsheets to websites. But getting our hands on (potentially) interesting data is really only the beginning. The next step is conducting a thorough quality assessment to understand if what we have is useful, salvageable, or just straight up garbage.</p>&#13;
&#13;
<p>As you may have gleaned from reading <a data-type="xref" href="ch03.html#chapter3">Chapter 3</a>, crafting quality data is a complex and time-consuming business. The process is roughly equal parts research, experimentation, and dogged perseverance. Most importantly, committing to data quality means that you have to be willing to invest significant amounts of time and energy—and <em>still be willing to throw it all out and start over</em> if, despite your best efforts, the data you have just can’t be brought up to par.</p>&#13;
&#13;
<p>When it comes down to it, in fact, that last criterion is probably what makes doing really high-quality, meaningful work with data truly difficult. The technical skills, as I hope you are already discovering, take some effort to master but are still highly achievable with sufficient practice. Research skills are a bit harder to document and convey, but working through the examples in this book will help you develop many of them, especially those related to the information discovery and collation needed for assessing and improving data quality.</p>&#13;
&#13;
<p>When it comes to reconciling yourself to the fact that, after dozens of hours of work, you may need to “give up” on a dataset because its flaws are too deep or widespread, the only advice I can offer is that you try to remember that <em>learning meaningful things about the world is a “long game.”</em> That’s why I always suggest that folks interested in learning about how to do data wrangling and analysis start by identifying a question about the world that is truly interesting and/or important to them. To do this work well, you have to care <em>more</em> about getting it right than about getting it “done.” But it also helps if you truly value what you learn in the <em>process</em> of data wrangling—whether because you learn a new Python or data wrangling strategy or because you make contact with a new expert or discover a new information resource. In truth, the effort of doing good data work is never wasted if you really care about the topic you’re exploring. It’s just that it can lead you in a different direction than you expected.</p>&#13;
&#13;
<p>Often, you will find that while a dataset cannot answer your original question, it can still shed light on some key aspect of it. Other times, you may find that there’s <em>no</em> data on the subject you’re exploring, and you may be able to leverage that fact to get help—discovering what data <em>doesn’t</em> exist may prompt you—and others—to change focus entirely. And since there will <em>never</em> be a “perfect” dataset, there are times when you may choose to <em>very carefully</em> share data that you know has flaws, because even the partial insight it offers has important public interest benefits. What matters in every case is that you are willing to personally take responsibility for the choices you make—because no matter what the “original” data was or where it came from, the cleaned, augmented, transformed, and/or analyzed dataset is still <em>yours</em>.</p>&#13;
&#13;
<p>If this feels a little overwhelming—well, that’s not entirely an accident. We are living in a moment when it is too easy to wield powerful digital tools without considering their real-world consequences, and where the people building “advanced” technologies are writing the algorithmic rules largely in their own favor.<sup><a data-type="noteref" href="ch06.html#idm45143406437120" id="idm45143406437120-marker">1</a></sup> In the end, data can be a mechanism for informing <em>and</em> manipulating, for explaining <em>and</em> exploiting. Ensuring which side of those lines your work falls on is ultimately<a data-primary="data quality" data-secondary="difficulty of achieving" data-startref="data-quality-difficult" data-type="indexterm" id="idm45143406435536"/> up to you.</p>&#13;
&#13;
<p>But what does achieving data quality really mean in practice? To get a sense of this, we’ll spend the remainder of this chapter evaluating real-world data in terms of the aspects of data <em>integrity</em> and data <em>fit</em> introduced in <a data-type="xref" href="ch03.html#chapter3">Chapter 3</a>. The dataset we’ll use for this is a single instance of loan data from the US Paycheck Protection Program (PPP), which contains information about millions of loans to small businesses during the COVID-19 pandemic. As we’ll encounter firsthand throughout the remainder of this chapter, the PPP data exemplifies many of the challenges common in “found” data, whether it is compiled by government agencies or private companies: unclear terms and unexplained changes from one version of the data to the next leave room for data <em>fit</em> issues that will require additional research to address. More straightforward (though not necessarily faster to resolve) are the data <em>integrity</em> issues—like confirming whether a given bank is spelled the same way throughout the dataset or that our data file(s) contain the values and time ranges they ought to. While we will find our way through most of these challenges, in the end our insights will be high confidence, <em>not</em> incontrovertible. As with all data work, they will be the cumulative result of informed decisions, logical reasoning, and a whole <em>lot</em> of data wrangling. To get that wrangling done, the Python library we’ll rely on most is <em>pandas</em>, which offers a popular and powerful set of tools for working with table-type data. Let’s get started!</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Pandemic and the PPP" data-type="sect1"><div class="sect1" id="pandemic_and_ppp">&#13;
<h1>The Pandemic and the PPP</h1>&#13;
&#13;
<p>In the <a data-primary="PPP (Paycheck Protection Program) example" data-type="indexterm" id="idm45143406494592"/><a data-primary="Paycheck Protection Program example" data-see="PPP example" data-type="indexterm" id="idm45143406493888"/>spring of 2020, the US government announced a loan program designed to help stabilize the American economy in the face of job losses related to the COVID-19 pandemic. With designated funding of nearly $1 trillion,<sup><a data-type="noteref" href="ch06.html#idm45143406492528" id="idm45143406492528-marker">2</a></sup> the objective of the PPP was ostensibly to help small businesses pay rent and keep paying employees despite sometimes mandatory closures and other restrictions. Although a drop in unemployment appeared to follow the first roll-out of funds, some parts of the federal government seemed determined to resist calls for transparency about where the money had gone.<sup><a data-type="noteref" href="ch06.html#idm45143406490368" id="idm45143406490368-marker">3</a></sup></p>&#13;
&#13;
<p>So did the PPP loans help save American small businesses? Now that some time has passed, one might imagine that would be a straightforward enough question to answer—but we’re here to find out for ourselves. To do that we’ll look at the data, of course, starting with a systematic assessment of its overall quality, in which we review our PPP loan data for each of the characteristics of data <em>integrity</em> and data <em>fit</em>, in turn. Just as importantly, we’re going to <em>carefully document</em> each<a data-primary="documentation" data-secondary="in data quality assessments" data-secondary-sortas="data quality assessments" data-type="indexterm" id="idm45143406486304"/><a data-primary="data quality" data-secondary="documentation of" data-type="indexterm" id="idm45143406484992"/> part of this process so that we have a record of what we did, the choices we made, and the reasoning behind them. This data diary will be a crucial resource for us in the future, especially should we need to explain or reproduce any of our work. While you can use whatever form and format you prefer, I like to keep my formatting simple and have my data diary live near my code, so I’m going to document my work in a markdown file that I can easily back up to and read on GitHub.<sup><a data-type="noteref" href="ch06.html#idm45143406483424" id="idm45143406483424-marker">4</a></sup> Since this file is really a running tally of everything I’m doing, I’m going to call it <em>ppp_process_log.md</em>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Assessing Data Integrity" data-type="sect1"><div class="sect1" id="idm45143406481056">&#13;
<h1>Assessing Data Integrity</h1>&#13;
&#13;
<p>Should<a data-primary="data quality" data-secondary="data integrity assessments" data-type="indexterm" id="data-quality-integrity-assess2"/><a data-primary="data integrity" data-secondary="assessing" data-type="indexterm" id="data-integrity-assess2"/><a data-primary="assessing" data-secondary="data integrity" data-type="indexterm" id="assessing-data-integrity2"/> you begin your data wrangling process by assessing data integrity or data fit? Unsurprisingly: a little of both. As discussed in <a data-type="xref" href="ch01.html#describing_data_wrangling">“What Is “Data Wrangling”?”</a>, you should never really start a data wrangling process unless you have some sort of question you’re looking to answer and some sense that a particular dataset can help you answer it—in other words, until you have some idea where your data wrangling process is going and that your data is “fit” for it. At the same time, fully assessing a dataset’s fit is often difficult until its integrity has been explored. For example, if there are gaps in the data, can they be filled in somehow? Can missing metadata be located? If so, then we may be able to resolve these integrity issues and return to the assessment of fit with more complete information. If we then find that we can improve the data’s fit by augmenting it (which we’ll explore in detail in <a data-type="xref" href="ch07.html#chapter7">Chapter 7</a>), of course, this will initiate <em>another</em> round of data integrity assessments. And then the cycle begins again.</p>&#13;
&#13;
<p>If you suspect that this will lead to an infinite loop of data wrangling, you’re not <em>entirely</em> wrong; all good questions will generate others, so there’s always more to learn. That said, the time, energy, and other resources we can dedicate to data wrangling are <em>not</em> infinite, which is why we have to make informed decisions and document them. Thoroughly assessing our data’s quality will help us make those decisions well. By methodically examining your data for integrity and fit, you ensure that you not only end up with high-quality data but also that you make and document decisions that you can use to describe (and even defend, if necessary) any insights you generate. This doesn’t mean that everyone will agree with your conclusions. It does, however, help ensure you can have a meaningful discussion about them—and that’s what really advances knowledge.</p>&#13;
&#13;
<p>So without further ado, let’s dive into our data integrity evaluation!</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Much of the data used in this chapter has since been removed from the internet and/or replaced with other files—this is not unusual. I have intentionally left the content of this chapter largely intact despite these changes, because they reflect the very real and typical challenges of trying to do data wrangling work in anything close to real time.</p>&#13;
&#13;
<p>It also illustrates how quickly—and almost untraceably—data can evolve and change in the digital world. Something to keep in mind.&#13;
In the meantime, you can find all of the datasets referenced in this chapter on this <a href="https://drive.google.com/file/d/1EtUB0nK9aQeWWWGUOiayO9Oe-avsKvXH/view?usp=sharing">Google Drive folder</a>.</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Is It of Known Pedigree?" data-type="sect2"><div class="sect2" id="idm45143406467072">&#13;
<h2>Is It of Known Pedigree?</h2>&#13;
&#13;
<p>At<a data-primary="data quality" data-secondary="data integrity assessments" data-tertiary="of known provenance" data-tertiary-sortas="known provenance" data-type="indexterm" id="data-quality-integrity-assess2-known"/><a data-primary="data integrity" data-secondary="assessing" data-tertiary="of known provenance" data-tertiary-sortas="known provenance" data-type="indexterm" id="data-integrity-assess2-known"/><a data-primary="assessing" data-secondary="data integrity" data-tertiary="of known provenance" data-tertiary-sortas="known provenance" data-type="indexterm" id="assessing-data-integrity2-known"/><a data-primary="known provenance, in data integrity" data-type="indexterm" id="known-provenance2"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-tertiary="of known provenance" data-tertiary-sortas="known provenance" data-type="indexterm" id="ppp-integrity-known"/> the time of this writing, the first search result for the phrase “most recent PPP loan data” is a page on the US Department of the Treasury website that links to data from August 2020.<sup><a data-type="noteref" href="ch06.html#idm45143406687968" id="idm45143406687968-marker">5</a></sup> The second result links to more recent data, from the Small Business Administration (SBA)—the government department charged with actually administering the funds.<sup><a data-type="noteref" href="ch06.html#idm45143406684480" id="idm45143406684480-marker">6</a></sup></p>&#13;
&#13;
<p>While both of these are legitimate sites for government agencies whose work is relevant to the PPP, it makes more sense for us to work principally with data published by the SBA. Still, it was <em>not</em> the first thing I found when I first went to look for this data.</p>&#13;
&#13;
<p>I really want to highlight this because the Treasury Department is obviously both a reasonable and reputable source for the data we were seeking, but it was still not the <em>best</em> one available. That’s why it matters to evaluate not just <em>where</em> your data came from but <em>how</em> you came to find <a data-primary="data quality" data-secondary="data integrity assessments" data-startref="data-quality-integrity-assess2-known" data-tertiary="of known provenance" data-tertiary-sortas="known provenance" data-type="indexterm" id="idm45143406679568"/><a data-primary="data integrity" data-secondary="assessing" data-startref="data-integrity-assess2-known" data-tertiary="of known provenance" data-tertiary-sortas="known provenance" data-type="indexterm" id="idm45143406677664"/><a data-primary="assessing" data-secondary="data integrity" data-startref="assessing-data-integrity2-known" data-tertiary="of known provenance" data-tertiary-sortas="known provenance" data-type="indexterm" id="idm45143406675888"/><a data-primary="known provenance, in data integrity" data-startref="known-provenance2" data-type="indexterm" id="idm45143406674112"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-startref="ppp-integrity-known" data-tertiary="of known provenance" data-tertiary-sortas="known provenance" data-type="indexterm" id="idm45143406673152"/>it.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Is It Timely?" data-type="sect2"><div class="sect2" id="idm45143406671152">&#13;
<h2>Is It Timely?</h2>&#13;
&#13;
<p>If<a data-primary="data quality" data-secondary="data integrity assessments" data-tertiary="timely" data-type="indexterm" id="idm45143406669600"/><a data-primary="data integrity" data-secondary="assessing" data-tertiary="timely" data-type="indexterm" id="idm45143406668352"/><a data-primary="assessing" data-secondary="data integrity" data-tertiary="timely" data-type="indexterm" id="idm45143406667136"/><a data-primary="timely, in data integrity" data-type="indexterm" id="idm45143406665920"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-tertiary="timely" data-type="indexterm" id="idm45143406665280"/> we want to use data to learn something about the state of the world as it is <em>now</em>, the first thing we need to establish is <em>when</em> our data dates from—and confirm that it’s the most recent available.</p>&#13;
&#13;
<p>If this seems like it should be straightforward, think again—many websites don’t automatically date every post, so even determining when something went online is often a challenge. Alternatively, a website that <em>does</em> date its content may change it any time a change (even an insubstantial one) is made; some sites may regularly update the “published” date in an attempt to game search engine algorithms that favor more recent content.</p>&#13;
&#13;
<p>In other words, determining what is <em>actually</em> the most recent, relevant data for your particular data wrangling problem may well require some digging. The only way to know for sure will be to try a few different search terms, click through several sets of results, and maybe reach out to an expert for advice. In the process, you’ll most likely find enough references to reassure you what the most recently available data is.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Is It Complete?" data-type="sect2"><div class="sect2" id="idm45143406660496">&#13;
<h2>Is It Complete?</h2>&#13;
&#13;
<p>So far, <a data-primary="data quality" data-secondary="data integrity assessments" data-tertiary="complete" data-type="indexterm" id="data-quality-integrity-assess2-complete"/><a data-primary="data integrity" data-secondary="assessing" data-tertiary="complete" data-type="indexterm" id="data-integrity-assess2-complete"/><a data-primary="assessing" data-secondary="data integrity" data-tertiary="complete" data-type="indexterm" id="assessing-data-integrity2-complete"/><a data-primary="complete, in data integrity" data-type="indexterm" id="complete2"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-tertiary="complete" data-type="indexterm" id="ppp-integrity-complete"/>we know that there have been multiple data releases for the PPP. While we can be pretty confident that we’ve successfully located the most <em>recent</em> data, the next question is: is this <em>all</em> the data?</p>&#13;
&#13;
<p>Since we’re primarily interested in businesses that received larger loans, we only have to worry about examining one file: <em>public_150k_plus.csv</em>.<sup><a data-type="noteref" href="ch06.html#idm45143406648768" id="idm45143406648768-marker">7</a></sup> But how can we know if this includes all phases of the program to date, or just the loans made since the <em>first</em> data release in August 2020? Since we have access to both sets of data,<sup><a data-type="noteref" href="ch06.html#idm45143406646448" id="idm45143406646448-marker">8</a></sup> we have a few strategies we can use:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Find the earliest date(s) in our “recent” data file and confirm that they are <em>before</em> August 8, 2020.</p>&#13;
</li>&#13;
<li>&#13;
<p>Compare the file sizes and/or row counts of the two datasets to confirm that the more recent file is larger than the older file.</p>&#13;
</li>&#13;
<li>&#13;
<p>Compare the data they contain to confirm that all the records in the earlier file already exist in the later file.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>At this point you might be thinking, “Hang on, isn’t confirming the earliest date enough? Why would we do the other two? Both of those seem much more difficult.” Well, sure—in <em>theory</em>, just confirming that we have data from the earlier phases should be enough. But in truth, that’s a pretty cursory check. Obviously, we cannot confirm that the data the federal government has released is complete by trying to go out and collect more comprehensive data ourselves. On the other hand (and as we’ll see shortly), the data collection processes of governments and large organizations (including—and perhaps especially—banks) are far from perfect.<sup><a data-type="noteref" href="ch06.html#idm45143406638368" id="idm45143406638368-marker">9</a></sup> Since we’ll be taking ownership of this data if we use it to draw conclusions, I think it’s worth being thorough.</p>&#13;
&#13;
<p>Happily, conducting our first “completeness” check is quite simple: just by opening the data in a text editor, we can see that the first entry contains a “DateApproved” value of <em>05/01/2020</em>, suggesting that the recent dataset <em>does</em> in fact include data from the first round of PPP loans, which were disbursed in the spring of 2020, as shown in <a data-type="xref" href="#ppp_loan_data_recent">Figure 6-1</a>.</p>&#13;
&#13;
<figure><div class="figure" id="ppp_loan_data_recent">&#13;
<img alt="Quick text editor view of recent PPP loan data." src="assets/ppdw_0601.png"/>&#13;
<h6><span class="label">Figure 6-1. </span>Quick text editor view of recent PPP loan data</h6>&#13;
</div></figure>&#13;
&#13;
<p>That was easy! If we want to go a little bit further, we can always write a quick script to find the oldest and most recent <code>LoanStatus</code> dates in the recent data. To avoid confusion, I’ve renamed the more recent file <em>public_150k_plus_recent.csv</em>. Currently,<sup><a data-type="noteref" href="ch06.html#idm45143406630688" id="idm45143406630688-marker">10</a></sup> following the data linked from <a href="https://home.treasury.gov/policy-issues/cares-act/assistance-for-small-businesses/sba-paycheck-protection-program-loan-level-data"><em class="hyperlink">https://home.treasury.gov/policy-issues/cares-act/assistance-for-small-businesses/sba-paycheck-protection-program-loan-level-data</em></a> leads to a <em>different</em> folder on the SBA Box account, which shows an upload date of <a href="https://sba.app.box.com/s/ox4mwmvli4ndbp14401xr411m8sefx3i">August 14, 2020</a>. We have to download the entire folder, <em>150k plus 0808.zip</em>, but we can pull out the CSV and rename it <em>public_150k_plus_080820.csv</em>.</p>&#13;
&#13;
<p>To help us with this process, we will, as usual, be looking for a library to smooth<a data-primary="Pandas" data-type="indexterm" id="pandas"/> the way—this time in the form of Pandas, a well-known Python library for manipulating table-type data. While we won’t examine the <em>pandas</em> library in detail here (there is already an excellent O’Reilly book, <em>Python for Data Analysis</em>, written by the creator of Pandas, Wes McKinney!), we will definitely make use of its many helpful features in carrying out our data quality checks going forward.</p>&#13;
&#13;
<p>To start with, we’ll need to install the library by running the following from the command line:</p>&#13;
<pre>pip install pandas</pre>&#13;
&#13;
<p>Now, let’s use it to pull in the recent PPP loan data and see what the earliest and latest dates are in that file, as shown in <a data-type="xref" href="#ppp_date_range">Example 6-1</a>.</p>&#13;
<div data-type="example" id="ppp_date_range">&#13;
<h5><span class="label">Example 6-1. </span>ppp_date_range.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for finding the earliest and latest loan dates in the PPP loan</code><code>&#13;
</code><code class="c1"># data</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># importing the `pandas` library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code> </code><a class="co" href="#callout_assessing_data_quality_CO1-1" id="co_assessing_data_quality_CO1-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># read the recent data into a pandas DataFrame using its `read_csv()` method</code><code>&#13;
</code><code class="n">ppp_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">public_150k_plus_recent.csv</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># convert the values in the `DateApproved` column to *actual* dates</code><code>&#13;
</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">DateApproved</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">to_datetime</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">DateApproved</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>&#13;
</code><code>                                          </code><code class="n">format</code><code class="o">=</code><code class="s1">'</code><code class="si">%m</code><code class="s1">/</code><code class="si">%d</code><code class="s1">/</code><code class="si">%Y</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" href="#callout_assessing_data_quality_CO1-2" id="co_assessing_data_quality_CO1-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># print out the `min()` and `max()` values in the `DateApproved` column</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">DateApproved</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">min</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">DateApproved</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">max</code><code class="p">(</code><code class="p">)</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_assessing_data_quality_CO1-1" id="callout_assessing_data_quality_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Using the <code>as</code> keyword here lets us create a nickname for the library so that we can refer to it in fewer characters later in our code.</p></dd>&#13;
<dt><a class="co" href="#co_assessing_data_quality_CO1-2" id="callout_assessing_data_quality_CO1-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>In order to find the oldest and most recent dates, we need to first convert the (string) values in our dataset to <em>actual</em> <code>Date</code> data types. Here, we’ll use the Pandas <code>to_datetime()</code> function and provide it with (1) <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html">the column we want converted</a>, and (2) <a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior">the format of the dates</a> as they <em>currently</em> appear in our dataset.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>As we can see from the following output, the earliest loan in this dataset was made on April 3, 2020, and the most recent was made on January 31, 2021:</p>&#13;
<pre>2020-04-03 00:00:00&#13;
2021-01-31 00:00:00</pre>&#13;
&#13;
<p>Note that while we don’t <em>absolutely</em> have to pass the <code>format</code> ingredient to the Pandas <code>to_datetime()</code> function, it’s always a good idea to do so; if we don’t provide this information, then Pandas has to try to “guess” what date format it’s looking at, which can make the actual processing take a long time. Here it only saves us about a second of processing time—but with larger datasets (or more than one), that can quickly<a data-primary="Pandas" data-startref="pandas" data-type="indexterm" id="idm45143406202624"/><a data-primary="to_datetime() function" data-type="indexterm" id="idm45143406201776"/> &#13;
<span class="keep-together">add up!</span></p>&#13;
&#13;
<p>Now let’s <a data-primary="files" data-secondary="comparing" data-type="indexterm" id="file-compare"/><a data-primary="comparing files" data-type="indexterm" id="compare-files"/><a data-primary="Python" data-secondary="comparing files" data-type="indexterm" id="python-compare-files"/>compare the file size of the recent data with the one that was released in August 2020. Just looking at the <em>public_150k_plus_recent.csv</em> and the <em>public_150k_plus_080820.csv</em> files in a finder window, we can see that the file size of the more recent data is <em>much</em> larger than the earlier one: the August data is ~124 MB, while the recent data is several hundred megabytes. So far so good.</p>&#13;
&#13;
<p>Drawing on the techniques we used in <a data-type="xref" href="ch04.html#fixed_width_parsing">Example 4-7</a> and <a data-type="xref" href="ch05.html#downloading_the_data">Example 5-10</a>, let’s write a quick script to determine how many rows of data are in each file, as shown in <a data-type="xref" href="#ppp_numrows">Example 6-2</a>.</p>&#13;
<div data-type="example" id="ppp_numrows">&#13;
<h5><span class="label">Example 6-2. </span>ppp_numrows.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script to print out the number of rows in each of our PPP loan data files</code><code>&#13;
</code><code class="c1"># this is a pretty basic task, so no need to import extra libraries!</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># open the August PPP data in "read" mode</code><code>&#13;
</code><code class="n">august_data</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s2">"</code><code class="s2">public_150k_plus_080820.csv</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">r</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># use `readlines()` to convert the lines in the data file into a list</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="s2">"</code><code class="s2">August file has </code><code class="s2">"</code><code class="o">+</code><code class="nb">str</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">august_data</code><code class="o">.</code><code class="n">readlines</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code class="o">+</code><code class="s2">"</code><code class="s2"> rows.</code><code class="s2">"</code><code class="p">)</code><code> </code><a class="co" href="#callout_assessing_data_quality_CO2-1" id="co_assessing_data_quality_CO2-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># ditto for the recent PPP data</code><code>&#13;
</code><code class="n">recent_data</code><code> </code><code class="o">=</code><code> </code><code class="nb">open</code><code class="p">(</code><code class="s2">"</code><code class="s2">public_150k_plus_recent.csv</code><code class="s2">"</code><code class="p">,</code><code class="s2">"</code><code class="s2">r</code><code class="s2">"</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># once again, print the number of lines</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="s2">"</code><code class="s2">Recent file has </code><code class="s2">"</code><code class="o">+</code><code class="nb">str</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">recent_data</code><code class="o">.</code><code class="n">readlines</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code class="o">+</code><code class="s2">"</code><code class="s2"> rows.</code><code class="s2">"</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_assessing_data_quality_CO2-1" id="callout_assessing_data_quality_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Once the <code>readlines()</code> method has put the lines of our data file into a list, we can use the built-in <code>len()</code> method to determine how many there are. To print the result, we have to cast that number as a string with the built-in <code>str()</code> function first, or Python will yell at us.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>Running this script confirms that while the file from August 2020 contains 662,516 rows, the more recent version (from February 1, 2021) contains 766,500 rows.</p>&#13;
&#13;
<p>Finally, let’s look at comparing the contents of the two files to confirm that everything in the earlier file appears in the newer file. This will undoubtedly be a multistep process, but let’s start by opening up the August data file in a text editor, as shown in <a data-type="xref" href="#ppp_loan_data_august">Figure 6-2</a>.</p>&#13;
&#13;
<figure><div class="figure" id="ppp_loan_data_august">&#13;
<img alt="Quick text editor view of August, 2020 PPP loan data." src="assets/ppdw_0602.png"/>&#13;
<h6><span class="label">Figure 6-2. </span>Quick text editor view of August 2020 PPP loan data</h6>&#13;
</div></figure>&#13;
&#13;
<p>Right away it’s clear there are some…differences, which will make this particular check even more complicated than we might have anticipated. First, it’s clear that there are <em>many</em> more columns of data in the more recent file, which means that we’ll need to devise a strategy for matching up the records from the earlier dataset to the most recent one.</p>&#13;
&#13;
<p>First, we need to get a handle on which data columns seem to overlap between the two files. We’ll do that by creating and comparing two small <em>sample</em> CSV files, each containing the first several rows of data from each dataset.</p>&#13;
&#13;
<p>Next, we’ll write a quick script that converts each of our source files into a <code>DataFrame</code>—a special Pandas data type for table-type data—and then writes the first few rows to a separate CSV, as shown in <a data-type="xref" href="#ppp_data_samples">Example 6-3</a>.</p>&#13;
<div data-type="example" id="ppp_data_samples">&#13;
<h5><span class="label">Example 6-3. </span>ppp_data_samples.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for creating new CSVs that each contain the first few rows of</code><code>&#13;
</code><code class="c1"># our larger data files</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># importing the `pandas` library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># read the august data into a pandas DataFrame using its `read_csv()` method</code><code>&#13;
</code><code class="n">august_ppp_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">public_150k_plus_080820.csv</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># the `head()` method returns the DataFrame's column headers</code><code>&#13;
</code><code class="c1"># along with the first 5 rows of data</code><code>&#13;
</code><code class="n">august_sample</code><code> </code><code class="o">=</code><code> </code><code class="n">august_ppp_data</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># write those first few rows to a CSV called `august_sample.csv`</code><code>&#13;
</code><code class="c1"># using the pandas `to_csv()` method</code><code>&#13;
</code><code class="n">august_sample</code><code class="o">.</code><code class="n">to_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">august_sample.csv</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">index</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code> </code><a class="co" href="#callout_assessing_data_quality_CO3-1" id="co_assessing_data_quality_CO3-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># read the recent data into a pandas DataFrame using its `read_csv()` method</code><code>&#13;
</code><code class="n">recent_ppp_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">public_150k_plus_recent.csv</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># the `head()` method returns the DataFrame's column headers</code><code>&#13;
</code><code class="c1"># along with the first 5 rows of data</code><code>&#13;
</code><code class="n">recent_sample</code><code> </code><code class="o">=</code><code> </code><code class="n">recent_ppp_data</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># write those first few rows to a CSV called `recent_sample.csv`</code><code>&#13;
</code><code class="n">recent_sample</code><code class="o">.</code><code class="n">to_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">recent_sample.csv</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">index</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_assessing_data_quality_CO3-1" id="callout_assessing_data_quality_CO3-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The <em>pandas</em> <code>to_csv()</code> method encapsulates several steps we’ve previously done in plain-old Python: opening a new writable file and saving data to it. Because Pandas adds an index column (which essentially includes row numbers) to every DataFrame it creates, however, we need to include the second “ingredient” of <code>index=False</code> because we <em>don’t</em> want those row numbers to appear in our output CSV.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>Now that we have our two smaller file samples, let’s open them up and just look through them to visually compare both the column headers and their contents. You can see screenshots of the August data in <a data-type="xref" href="#august_data_sample">Figure 6-3</a>, while the more recent data is shown in <a data-type="xref" href="#recent_data_sample">Figure 6-4</a>.</p>&#13;
&#13;
<figure><div class="figure" id="august_data_sample">&#13;
<img alt="First few lines of August PPP loan data file." src="assets/ppdw_0603.png"/>&#13;
<h6><span class="label">Figure 6-3. </span>First few lines of August PPP loan data file</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="recent_data_sample">&#13;
<img alt="First few lines of recent PPP loan data file." src="assets/ppdw_0604.png"/>&#13;
<h6><span class="label">Figure 6-4. </span>First few lines of recent PPP loan data file</h6>&#13;
</div></figure>&#13;
&#13;
<p>Luckily, it looks like the first few rows of both files contain at least <em>some</em> of the same entries. This will make it easier for us to compare their contents and (hopefully) identify which columns we can use to match up the rows.</p>&#13;
&#13;
<p>Let’s start by choosing a single entry to work with, ideally one with as many completed fields as possible. For example, something called <code>SUMTER COATINGS, INC.</code> appears on line 6 of the August data sample (as labeled in the spreadsheet interface) under the column heading <code>BusinessName</code>. On line 2 of the recent data sample, the same value appears under the column heading <code>BorrowerName</code>. In the August sample file, the term <code>Synovus Bank</code> appears in a column called <code>Lender</code>, while that term appears &#13;
<span class="keep-together">in the</span> recent sample file in a column called <code>ServicingLenderName</code>. So far so good—or &#13;
<span class="keep-together">is it?</span></p>&#13;
&#13;
<p>Although many details between these rows seem to match across the two data files, some seemingly important ones <em>don’t</em>. For example, in the August data sample, the value in the <code>DateApproved</code> column is <code>05/03/2020</code>; in the recent data sample, it is <code>05/01/2020</code>. If we look at another seemingly shared entry, we see that for the business/borrower called <code>PLEASANT PLACES, INC.</code> (row 5 in the August data and row 3 in the recent data), the column titled <code>CD</code> in both files (spreadsheet column AF in the recent file, column P in the August file) has different values, showing <code>SC-01</code> in the August data and <code>SC-06</code> in the recent data. What’s going on?</p>&#13;
&#13;
<p>At this point, we have to make some judgment calls about <em>which</em> column values need to match in order for us to treat a particular loan row as the same between the two. Requiring that the business name and the lender name match seems like a good starting point. Since we know that multiple rounds of loans have been made by now, we probably want to require that the values in the <code>DateApproved</code> column match as well (even though it seems unlikely that Synovus Bank made two loans to Sumter Coatings, Inc. two days apart). What about the mismatched congressional district? If we look at a map of South Carolina’s congressional districts, it’s clear that their boundaries haven’t been changed since 2013,<sup><a data-type="noteref" href="ch06.html#idm45143405919056" id="idm45143405919056-marker">11</a></sup> though it does seem like the 1st and the 6th district share a boundary. Given that, we might conclude that the discrepancy here is just a mistake.</p>&#13;
&#13;
<p>As you<a data-primary="joins, outer" data-type="indexterm" id="join-outer"/><a data-primary="outer joins" data-type="indexterm" id="outer-joins"/><a data-primary="Python" data-secondary="outer joins" data-type="indexterm" id="python-outer-join"/> can see, we’re already finding some significant data quality issues—and we’ve only looked at five rows of data! Since we obviously can’t resolve all of these differences at once, we need to start by putting together the rows that (we hope) really match, while making sure to keep track of any that don’t. To do this, we’ll need to <em>join</em> or <em>merge</em> the two datasets. Because we already know there will be discrepancies, however, we need a way to keep track of those as well. In other words, we want the file created by our join process to include <em>every</em> row from <em>both</em> datasets, whether they match or not. To do this, we need what’s called <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#brief-primer-on-merge-methods-relational-algebra">an <em>outer</em> join</a>. We’ll make use of this in <a data-type="xref" href="#ppp_data_join">Example 6-4</a>.</p>&#13;
&#13;
<p>Note that because an outer join preserves <em>all</em> data rows, it’s possible that our resulting dataset could have as many rows as the individual datasets combined—in this case about <em>1.4 million rows</em>. Don’t worry, though! Python can handle it. But can your device?</p>&#13;
&#13;
<p>If you have a Macintosh or Windows machine, chances are that working with the &#13;
<span class="keep-together">~500 MB</span> of data that we need to in these examples will be no problem. If, like me, you’re working on a Chromebook or something similar, now’s the moment to move to the cloud.</p>&#13;
<div data-type="example" id="ppp_data_join">&#13;
<h5><span class="label">Example 6-4. </span>ppp_data_join.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for creating new CSVs that each contain the first few rows of</code><code>&#13;
</code><code class="c1"># our larger data files</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># importing the `pandas` library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># read the august data into a pandas DataFrame using its `read_csv()` method</code><code>&#13;
</code><code class="n">august_ppp_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">public_150k_plus_080820.csv</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># read the recent data into a pandas DataFrame using its `read_csv()` method</code><code>&#13;
</code><code class="n">recent_ppp_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">public_150k_plus_recent.csv</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># now that we have both files in memory, let's merge them!</code><code>&#13;
</code><code class="n">merged_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">merge</code><code class="p">(</code><code class="n">august_ppp_data</code><code class="p">,</code><code class="n">recent_ppp_data</code><code class="p">,</code><code class="n">how</code><code class="o">=</code><code class="s1">'</code><code class="s1">outer</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>    </code><code class="n">left_on</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">BusinessName</code><code class="s1">'</code><code class="p">,</code><code class="s1">'</code><code class="s1">Lender</code><code class="s1">'</code><code class="p">,</code><code class="s1">'</code><code class="s1">DateApproved</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code class="n">right_on</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">BorrowerName</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>    </code><code class="s1">'</code><code class="s1">ServicingLenderName</code><code class="s1">'</code><code class="p">,</code><code class="s1">'</code><code class="s1">DateApproved</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code class="n">indicator</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code> </code><a class="co" href="#callout_assessing_data_quality_CO4-1" id="co_assessing_data_quality_CO4-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># `print()` the values in the "indicator" column,</code><code>&#13;
</code><code class="c1"># which has a default label of `_merge`</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">merged_data</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="s1">'</code><code class="s1">_merge</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_assessing_data_quality_CO4-2" id="co_assessing_data_quality_CO4-2"><img alt="2" src="assets/2.png"/></a></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_assessing_data_quality_CO4-1" id="callout_assessing_data_quality_CO4-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>We’re passing the <code>indicator=True</code> parameter here because it will create a new column that lets us know which rows appeared in one or both files.</p></dd>&#13;
<dt><a class="co" href="#co_assessing_data_quality_CO4-2" id="callout_assessing_data_quality_CO4-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Using <code>indicator=True</code> produces a column called <code>merge</code>, whose value for each row shows which dataset that particular row matched on. As we’ll see from the output, that value will be&#13;
<code>both</code>, <code>left_only</code>, or <code>right_only</code>.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>If everything went well, you get an output like this:</p>&#13;
<pre>_merge&#13;
both          595866&#13;
right_only    171334&#13;
left_only      67333&#13;
dtype: int64</pre>&#13;
&#13;
<p>So what does this mean? It looks like our effort to match the August data with the recent data on business name, servicing lender name, and the date of the loan successfully matched 595,866 loans. The <code>right_only</code> loans are the <em>recent</em> loans that weren’t matched (<code>recent_ppp_data</code> was the second argument to our <code>pd.merge()</code> function, so it is considered to be in the “right”); we found 171,334 of these. This seems perfectly plausible, since we can imagine that many new loans may have been issued since August.</p>&#13;
&#13;
<p>The troubling number here is <code>left_only</code>: 67,333 loans that appear in the August data that were <em>not</em> matched to any loan row contained our recent dataset. That suggests that either our recent data is incomplete or we have some serious quality issues lurking.</p>&#13;
&#13;
<p>From our very cursory examination of the sample data earlier, we already know that the <code>DateApproved</code> columns may have some problems, so let’s see what happens if we eliminate the need to match on date. To do this, we’ll just add the snippet in <a data-type="xref" href="#ppp_data_join_cont">Example 6-5</a> to <a data-type="xref" href="#ppp_data_join">Example 6-4</a> but without specifying that the dates need to match. Let’s see what happens.</p>&#13;
<div data-type="example" id="ppp_data_join_cont">&#13;
<h5><span class="label">Example 6-5. </span>ppp_data_join.py (continued)</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># merge the data again, removing the match on `DateApproved`</code>&#13;
<code class="n">merged_data_no_date</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">merge</code><code class="p">(</code><code class="n">august_ppp_data</code><code class="p">,</code><code class="n">recent_ppp_data</code><code class="p">,</code><code class="n">how</code><code class="o">=</code><code class="s1">'outer'</code><code class="p">,</code>&#13;
    <code class="n">left_on</code><code class="o">=</code><code class="p">[</code><code class="s1">'BusinessName'</code><code class="p">,</code><code class="s1">'Lender'</code><code class="p">],</code><code class="n">right_on</code><code class="o">=</code><code class="p">[</code><code class="s1">'BorrowerName'</code><code class="p">,</code>&#13;
    <code class="s1">'ServicingLenderName'</code><code class="p">],</code><code class="n">indicator</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># `print()` the values in the "indicator" column,</code>&#13;
<code class="c1"># which has a default label of `_merge`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">merged_data_no_date</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="s1">'_merge'</code><code class="p">))</code></pre></div>&#13;
&#13;
<p>Now we get an output something like this:</p>&#13;
<pre>_merge&#13;
both          671942&#13;
right_only     96656&#13;
left_only      22634&#13;
dtype: int64</pre>&#13;
&#13;
<p>In other words, if we only require that the business name and lender match, then we “find” another ~45,000 loans from the August data in the recent data. Of course, what we <em>don’t</em> know is how many of those new “matches” are the result of data entry errors (along the lines of our <code>05/03/2020</code> versus <code>05/01/2020</code> problem) and how many of them represent multiple loans.<sup><a data-type="noteref" href="ch06.html#idm45143405666608" id="idm45143405666608-marker">12</a></sup> All we know is that we’re down to 22,634 loans from the August data that we can’t locate in the recent data.</p>&#13;
&#13;
<p>So what if we simply check whether a given business shows up in both datasets? This seems like the most basic form of comparison: in theory, the bank or lender servicing the PPP loan could change over the course of many months, or there could be additional mismatches because of (possibly) minor data-entry differences. Remember: our goal right now is simply to evaluate how far we can trust that the <em>recent</em> data includes all of the August data.</p>&#13;
&#13;
<p>So let’s add on a final, <em>very</em> relaxed merge to see what happens. Adding the snippet in <a data-type="xref" href="#ppp_data_join_cont2">Example 6-6</a>, we’ll match <em>only</em> on business name and see what we get.</p>&#13;
<div data-type="example" id="ppp_data_join_cont2">&#13;
<h5><span class="label">Example 6-6. </span>ppp_data_join.py (continued)</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># merge the data again, matching only on `BusinessName`/`BorrowerName`</code>&#13;
<code class="n">merged_data_biz_only</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">merge</code><code class="p">(</code><code class="n">august_ppp_data</code><code class="p">,</code><code class="n">recent_ppp_data</code><code class="p">,</code><code class="n">how</code><code class="o">=</code><code class="s1">'outer'</code><code class="p">,</code>&#13;
    <code class="n">left_on</code><code class="o">=</code><code class="p">[</code><code class="s1">'BusinessName'</code><code class="p">],</code><code class="n">right_on</code><code class="o">=</code><code class="p">[</code><code class="s1">'BorrowerName'</code><code class="p">],</code><code class="n">indicator</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># `print()` the values in the "indicator" column,</code>&#13;
<code class="c1"># which has a default label of `_merge`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">merged_data_biz_only</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="s1">'_merge'</code><code class="p">))</code></pre></div>&#13;
&#13;
<p>And now our output is the following:</p>&#13;
<pre>_merge&#13;
both          706349&#13;
right_only     77064&#13;
left_only       7207&#13;
dtype: int64</pre>&#13;
&#13;
<p>Things are looking a little bit better: out of a total of 790,620 (706,349 + 77,064 + 7,207) possible loans, we’ve “found” all but 7,207—a little less than 0.1%. That’s <em>pretty</em> good; we might be tempted to call that quantity of missing data a “rounding error” and move on. But before we get complacent about having accounted for 99.9% of all the PPP loans, let’s stop for a moment and consider what that “small” amount of missing data really represents. Even if we assume that every one of those “missing” loans was for the minimum possible amount (recall that we’re only looking at loans of $150,000 or more), that still means that our recent dataset has <em>at least</em> $1,081,050,000—over $1 billion!—in possible loans that are unaccounted for. Given how hard I work to figure (and pay) my taxes every year, I certainly hope the federal government isn’t simply going to “lose” $1 billion in taxpayer money and not worry about it. But what can <em>we</em> do to account for it? This is where we get to the<a data-primary="files" data-secondary="comparing" data-startref="file-compare" data-type="indexterm" id="idm45143405589744"/><a data-primary="comparing files" data-startref="compare-files" data-type="indexterm" id="idm45143405588656"/><a data-primary="Python" data-secondary="comparing files" data-startref="python-compare-files" data-type="indexterm" id="idm45143405587744"/><a data-primary="joins, outer" data-startref="join-outer" data-type="indexterm" id="idm45143405586528"/><a data-primary="outer joins" data-startref="outer-joins" data-type="indexterm" id="idm45143405585584"/><a data-primary="Python" data-secondary="outer joins" data-startref="python-outer-join" data-type="indexterm" id="idm45143405584640"/> part of data work that can be both daunting and energizing: it’s time to talk to people!</p>&#13;
&#13;
<p>While reaching out to subject matter experts is always a great place to start your data quality investigations, in this instance we have something even better: information about the lenders and loan recipients themselves. Between the business names and locations contained in the file, we can probably track down contact information for at least a handful of our “lost” 7,207 loans from the August dataset and try to find out what happened.</p>&#13;
&#13;
<p>Before you pick up the phone and start calling people (and yes, most of the time you should be <em>calling</em>), however, figure out what you’re going to ask. While it may be tempting to imagine that something nefarious is going on (are the lenders hiding money? Are the businesses misrepresenting themselves?), there is an old (and very malleable) quote that goes something like “Never attribute to malice that which can be explained by incompetence/stupidity/neglect.”<sup><a data-type="noteref" href="ch06.html#idm45143405581136" id="idm45143405581136-marker">13</a></sup> In other words, it’s likely that these loans don’t appear in the more recent data because of some data-entry error, or even because <em>the loans simply never came through</em>.</p>&#13;
&#13;
<p>And in fact, after calling a few autobody repair and barber shops around the country, that was the story I heard most often. Multiple people I spoke with described a similar pattern: they applied for a loan, had been told it was approved, and then—the money simply never came through. While it would be impractical to try to confirm that this was the case for every single “missing” loan, hearing basically the same story from multiple businesses that are thousands of miles apart makes me <em>reasonably</em> confident that these loans don’t appear in the final dataset because the money was never actually sent.<sup><a data-type="noteref" href="ch06.html#idm45143405576560" id="idm45143405576560-marker">14</a></sup></p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45143405575424">&#13;
<h5>Talk to Me!</h5>&#13;
<p>If the<a data-primary="cold calling, tips for" data-type="indexterm" id="idm45143405573952"/><a data-primary="calling people, tips for" data-type="indexterm" id="idm45143405573216"/> idea of “cold calling” an individual or business and asking for information makes you nervous, you’re not alone. What helps the most is practice—but giving yourself a brief script to follow can go a long way for those first few calls. Below is a simple outline of how to approach calling a business (which mostly applies to individuals as well) to ask for information. Set your assumptions aside, and remember that you’re asking busy people for their time. If you are polite and considerate, you’ll get much further!</p>&#13;
<ol>&#13;
<li>&#13;
<p>Identify yourself. Give your name and where you’re calling from, and (briefly) what you want to speak to them about.</p>&#13;
</li>&#13;
<li>&#13;
<p>Ask if they have a moment—don’t launch into the reason for your call without finding out if they’re busy first.</p>&#13;
</li>&#13;
<li>&#13;
<p>If you’re not sure who to ask for, ask if the owner or a manager is available. If they’re not, ask when is a good time to call back.</p>&#13;
</li>&#13;
<li>&#13;
<p>Ask politely who you’re speaking to, and confirm their name. Thank them for their time and hang up.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>Always make sure you take notes! If/when you call back, ask for the owner/manager by name (if you have it). Mention who you spoke to the first time you called and that they mentioned this might be a good time. Offer again to call back later, or try to make an appointment if possible.</p>&#13;
&#13;
<p>Be clear and honest about why you’re getting in touch, and articulate what you’ll do with the information you’re asking for as you’re asking for it.&#13;
<em>Never</em> identify anyone in published work without clearly obtaining their permission first.</p>&#13;
</div></aside>&#13;
&#13;
<p>At this point, it seems fairly clear that our recent PPP loan data is, in fact, “complete” for our purposes. While this may have felt like a lot of work to test our dataset for just one of almost a dozen data integrity measures, keep in mind that in the process, we’ve learned valuable information that will make many of our later “tests” much faster—or even trivial—to complete. So with that, let’s turn to our next <a data-primary="data quality" data-secondary="data integrity assessments" data-startref="data-quality-integrity-assess2-complete" data-tertiary="complete" data-type="indexterm" id="idm45143405564848"/><a data-primary="data integrity" data-secondary="assessing" data-startref="data-integrity-assess2-complete" data-tertiary="complete" data-type="indexterm" id="idm45143405563312"/><a data-primary="assessing" data-secondary="data integrity" data-startref="assessing-data-integrity2-complete" data-tertiary="complete" data-type="indexterm" id="idm45143405561808"/><a data-primary="complete, in data integrity" data-startref="complete2" data-type="indexterm" id="idm45143405560304"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-startref="ppp-integrity-complete" data-tertiary="complete" data-type="indexterm" id="idm45143405559344"/>criterion.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Is It Well-Annotated?" data-type="sect2"><div class="sect2" id="idm45143406658912">&#13;
<h2>Is It Well-Annotated?</h2>&#13;
&#13;
<p>Having<a data-primary="data quality" data-secondary="data integrity assessments" data-tertiary="well-annotated" data-type="indexterm" id="data-quality-integrity-assess2-annotate"/><a data-primary="data integrity" data-secondary="assessing" data-tertiary="well-annotated" data-type="indexterm" id="data-integrity-assess2-annotate"/><a data-primary="assessing" data-secondary="data integrity" data-tertiary="well-annotated" data-type="indexterm" id="assessing-data-integrity2-annotate"/><a data-primary="well-annotated, in data integrity" data-type="indexterm" id="annotate2"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-tertiary="well-annotated" data-type="indexterm" id="ppp-integrity-annotate"/> satisfied ourselves that our data is appropriately <em>timely</em> and <em>complete</em>, we need to turn to understanding in detail what information the data columns in our recent PPP loan data actually contain.<sup><a data-type="noteref" href="ch06.html#idm45143405548048" id="idm45143405548048-marker">15</a></sup> As with our completeness assessment, one place we can start is with the data itself. By looking at the column names and some of the values they contain, we can start to get a sense of what we need more information about. If the column name seems descriptive and the data values we find in that column align with our interpretation of the column name, that’s a pretty good starting point.</p>&#13;
&#13;
<p>While we have a couple of options for reviewing our column names and their corresponding values, let’s go ahead and take advantage of the sample files we created earlier. Because our screen width will generally prevent us from easily printing lots of columns of data (whereas we can easily scroll down to see more rows), we’re going to<a data-primary="transposing data" data-type="indexterm" id="transpose"/><a data-primary="Python" data-secondary="transposing data" data-type="indexterm" id="python-transpose"/> start by <em>transposing</em> our sample data (that is, converting the columns to row and rows to columns) to make seeing the column titles easier.<sup><a data-type="noteref" href="ch06.html#idm45143405541024" id="idm45143405541024-marker">16</a></sup> We’re also going to apply some additional data type filtering to make it easier for us to see what data is missing. Our first pass at this can be seen in <a data-type="xref" href="#ppp_columns_review">Example 6-7</a>.</p>&#13;
<div data-type="example" id="ppp_columns_review">&#13;
<h5><span class="label">Example 6-7. </span>ppp_columns_review.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for reviewing all the column names in the PPP data</code><code>&#13;
</code><code class="c1"># to see what we can infer about them from the data itself</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># importing the `pandas` library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># read the recent data into a pandas DataFrame using its `read_csv()` method</code><code>&#13;
</code><code class="n">ppp_data_sample</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">recent_sample.csv</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># convert all missing data entries to '&lt;NA&gt;' using the `convertdtypes()` method</code><code>&#13;
</code><code class="n">converted_data_sample</code><code> </code><code class="o">=</code><code> </code><code class="n">ppp_data_sample</code><code class="o">.</code><code class="n">convert_dtypes</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_assessing_data_quality_CO5-1" id="co_assessing_data_quality_CO5-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># transpose the whole sample</code><code>&#13;
</code><code class="n">transposed_ppp_data_sample</code><code> </code><code class="o">=</code><code> </code><code class="n">converted_data_sample</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># print out the results!</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">transposed_ppp_data_sample</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_assessing_data_quality_CO5-1" id="callout_assessing_data_quality_CO5-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>For the sake of speed, the Pandas <code>read_csv()</code> method converts all missing entries to <code>NaN</code> (Not a Number), as described at <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html"><em class="hyperlink">https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html</em></a>. To get these values converted to the more general (and intuitive) <em>&lt;NA&gt;</em> label, we apply the <code>convertdtypes()</code> method to the entire DataFrame, as described at <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data-na-conversion"><em class="hyperlink">https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data-na-conversion</em></a>.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>As you can see in <a data-type="xref" href="#transposed_sample_recent">Figure 6-5</a>, this lets us see all of the original column names as rows, along with a couple of the original rows as columns of data. By looking through these, we can start to get a sense of what we know—and what we don’t.</p>&#13;
&#13;
<p>Thanks to their relatively descriptive names, we can start to guess at what we are &#13;
<span class="keep-together">likely to</span> find in many of these columns. For example, columns like <code>DateApproved</code>, &#13;
<span class="keep-together"><code>ProcessingMethod</code></span>, <code>BorrowerName</code>, <code>BorrowerAddress</code>, <code>BorrowerCity</code>, <code>BorrowerCity</code>, &#13;
<span class="keep-together"><code>BorrowerState</code></span>, and <code>BorrowerZip</code> are fairly straightforward. In some cases, the name is descriptive but doesn’t give us all the information we need. For example, while <code>SBAGuarantyPercentage</code> gives us information about both the column’s content and its units (presumably the amount of the loan guaranteed by the SBA, as a percentage), the <code>Term</code> column doesn’t tell us if the value should be interpreted as 24 days, weeks, months, or years. Likewise, while the values in <code>BusinessAgeDescription</code> are themselves descriptive (e.g., <code>Existing or more than 2 years old</code>), a <code>LoanStatus</code> value of <code>Exemption 4</code> doesn’t really help us understand what happened to the loan. Finally, there are column names like <code>LMIIndicator</code> that might be easy for an expert to interpret but difficult for those of us not well-versed in loan jargon to<a data-primary="transposing data" data-startref="transpose" data-type="indexterm" id="idm45143405441056"/><a data-primary="Python" data-secondary="transposing data" data-startref="python-transpose" data-type="indexterm" id="idm45143405440080"/> identify.</p>&#13;
&#13;
<p>What we really need at this point<a data-primary="data dictionaries" data-type="indexterm" id="data-dictionary"/> is a “data dictionary”—the term sometimes used to refer to the document that describes the contents of (especially) table-type data. Data dictionaries are important because while table-type data is very handy for conducting analyses, it doesn’t inherently offer a way to include the type <a data-primary="metadata" data-type="indexterm" id="idm45143405437184"/>of <em>metadata</em>—that is, data <em>about</em> the data—that we need to answer questions like “What units should be used?” or “What do coded categories mean?” which are exactly the kinds of questions that come up frequently with complex datasets.</p>&#13;
&#13;
<p>The most likely place to find a data dictionary should be the same location where we originally obtained the data (remember that in <a data-type="xref" href="ch04.html#chapter4">Chapter 4</a>, we found the description of the <em>ghcnd-stations.txt</em> file linked from the <em>readme.txt</em> file in the same folder where the data was located). In this instance, that means going back to <a href="https://sba.gov/funding-programs/loans/coronavirus-relief-options/paycheck-protection-program/ppp-data">the SBA website</a> and seeing what we can find.</p>&#13;
&#13;
<figure><div class="figure" id="transposed_sample_recent">&#13;
<img alt="ppdw 0605" src="assets/ppdw_0605.png"/>&#13;
<h6><span class="label">Figure 6-5. </span>Recent sample data transposed</h6>&#13;
</div></figure>&#13;
&#13;
<p>At first, things look fairly promising. Under the “All Data” section on that page, we see a link promising a summary of “key data aspects,” as shown in <a data-type="xref" href="#ppp_data_landing_page">Figure 6-6</a>.<sup><a data-type="noteref" href="ch06.html#idm45143405428640" id="idm45143405428640-marker">17</a></sup></p>&#13;
&#13;
<figure><div class="figure" id="ppp_data_landing_page">&#13;
<img alt="Landing page for PPP loan data on the SBA's website" src="assets/ppdw_0606.png"/>&#13;
<h6><span class="label">Figure 6-6. </span>Landing page for PPP loan data on the SBA’s website</h6>&#13;
</div></figure>&#13;
&#13;
<p><a href="https://sba.gov/document/report-paycheck-protection-program-ppp-loan-data-key-aspects">Following the link</a> brings us to a page that (as of this writing) lists two PDF documents from the summer of 2020. Unfortunately, neither of them seems to contain what we need—they are mostly filled with disclaimer-type text about how PPP loans are processed, though they do confirm our discovery that “canceled” loans will not appear in the database, as shown in <a data-type="xref" href="#ppp_data_aspects">Figure 6-7</a>.</p>&#13;
&#13;
<figure><div class="figure" id="ppp_data_aspects">&#13;
<img alt="Excerpt of 'Information to keep in mind when reviewing Paycheck Protection Program (PPP) data'" src="assets/ppdw_0607.png"/>&#13;
<h6><span class="label">Figure 6-7. </span>Excerpt of <em>information to keep in mind when reviewing PPP data</em></h6>&#13;
</div></figure>&#13;
&#13;
<p>Now what? We have a few options. We can turn to a more general research strategy in order to learn more about the PPP and hopefully fill in some of the blanks for ourselves. For example, reading enough articles on websites targeting potential PPP applicants will make clear that the appropriate units for the <code>Term</code> column is almost certainly weeks. Likewise, if we do enough web searches for the term <code>LMIIndicator</code>, <code>LMI Indicator</code>, and <code>LMI Indicator loans</code>, we’ll eventually come across a Wikipedia page that suggests this term <em>may</em> be shorthand for “Loan Mortgage Insurance Indicator”—but we hardly know for sure.</p>&#13;
&#13;
<p>In other words, it’s once again time to look for some human help. But who can we reach out to? Scholars who have looked at the PPP data already are one place to start, but they might be hard to find if the data release is relatively recent. So, just as we did when trying to confirm what happened to all those missing loans from the August dataset, we’re going to go straight to the source: the SBA. And fortunately, if we go back to the site where we downloaded our actual data files, as shown in <a data-type="xref" href="#ppp_box_site">Figure 6-8</a>, it turns out there is a name attached to those uploads: Stephen Morris.<sup><a data-type="noteref" href="ch06.html#idm45143405416416" id="idm45143405416416-marker">18</a></sup></p>&#13;
&#13;
<figure><div class="figure" id="ppp_box_site">&#13;
<img alt="PPP data download portal" src="assets/ppdw_0608.png"/>&#13;
<h6><span class="label">Figure 6-8. </span>PPP data download portal</h6>&#13;
</div></figure>&#13;
&#13;
<p>After placing a call and sending an email, I learned that, at the time of my inquiry, the SBA hadn’t yet created a data dictionary for the PPP loan data, though Morris did refer me to both the original PDF and a data dictionary for the SBA’s 7a loan program, on which the PPP loan structure was based. While the latter file (located at <a href="https://data.sba.gov/dataset/7-a-504-foia"><em class="hyperlink">https://data.sba.gov/dataset/7-a-504-foia</em></a>) still differed significantly from the PPP loan data columns, it did provide insight into some key elements. For example, that file included a description of a column also called <code>LoanStatus</code>, whose possible values seem to parallel at least some of what we’ve found in the PPP loan data so far:</p>&#13;
<pre>LoanStatus        Current status of loan:&#13;
               • NOT FUNDED = Undisbursed&#13;
               • PIF = Paid In Full&#13;
               • CHGOFF = Charged Off&#13;
               • CANCLD = Canceled&#13;
               • EXEMPT = The status of loans that have been disbursed but&#13;
                   have not been canceled, paid in full, or charged off are&#13;
                   exempt from disclosure under FOIA Exemption 4</pre>&#13;
&#13;
<p>So is this data “well-annotated”? Somewhat. It’s not as well annotated as, say, the NOAA data we worked with in <a data-type="xref" href="ch04.html#fixed_width">“Finally, Fixed-Width”</a>, but with some effort we’ll probably be able to build up our own data dictionary for the PPP loan data that we can be pretty <a data-primary="data dictionaries" data-startref="data-dictionary" data-type="indexterm" id="idm45143405408208"/><a data-primary="data quality" data-secondary="data integrity assessments" data-startref="data-quality-integrity-assess2-annotate" data-tertiary="well-annotated" data-type="indexterm" id="idm45143405407264"/><a data-primary="data integrity" data-secondary="assessing" data-startref="data-integrity-assess2-annotate" data-tertiary="well-annotated" data-type="indexterm" id="idm45143405405696"/><a data-primary="assessing" data-secondary="data integrity" data-startref="assessing-data-integrity2-annotate" data-tertiary="well-annotated" data-type="indexterm" id="idm45143405404192"/><a data-primary="well-annotated, in data integrity" data-startref="annotate2" data-type="indexterm" id="idm45143405402688"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-startref="ppp-integrity-annotate" data-tertiary="well-annotated" data-type="indexterm" id="idm45143405401728"/>confident in.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Is It High Volume?" data-type="sect2"><div class="sect2" id="idm45143406658288">&#13;
<h2>Is It High Volume?</h2>&#13;
&#13;
<p>Since<a data-primary="data quality" data-secondary="data integrity assessments" data-tertiary="high volume" data-type="indexterm" id="data-quality-integrity-assess2-volume"/><a data-primary="data integrity" data-secondary="assessing" data-tertiary="high volume" data-type="indexterm" id="data-integrity-assess2-volume"/><a data-primary="assessing" data-secondary="data integrity" data-tertiary="high volume" data-type="indexterm" id="assessing-data-integrity2-volume"/><a data-primary="high volume, in data integrity" data-type="indexterm" id="high-volume2"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-tertiary="high volume" data-type="indexterm" id="ppp-integrity-volume"/> we have already finished our “completeness” review, we have largely already answered the question of whether the data we’re using is <em>generally</em> high volume. There are few instances in which having more than 750,000 rows of data won’t be sufficient for conducting at least <em>some</em> useful form of analysis.</p>&#13;
&#13;
<p>At the same time, we also can’t say yet exactly what types of analyses we’ll be able to conduct, because the number of data rows we have doesn’t matter if most of them are empty. So how can we check this? For columns where we only expect to find a few possible values, like <code>LoanStatus</code>, we can use the Pandas <code>value_counts()</code> method to summarize the contents. For columns that have very diverse values (such as <code>BorrowerName</code> or <code>BorrowerAddress</code>), we’ll need to instead check specifically for <em>missing</em> values and then compare that to the total row count to get a sense of how much data might be missing. To start off with, we’ll summarize the columns we expect will only contain a handful of distinct values, as shown in <a data-type="xref" href="#ppp_columns_summary">Example 6-8</a>. We’ll also count the <code>NA</code> entries in a more varied column—in this case, <code>BorrowerAddress</code>.</p>&#13;
<div data-type="example" id="ppp_columns_summary">&#13;
<h5><span class="label">Example 6-8. </span>ppp_columns_summary.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for reviewing all the column names in the PPP data</code>&#13;
<code class="c1"># to see what we can infer about them from the data itself</code>&#13;
&#13;
<code class="c1"># importing the `pandas` library</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="kn">as</code> <code class="nn">pd</code>&#13;
&#13;
<code class="c1"># read the recent data sample into a pandas DataFrame</code>&#13;
<code class="n">ppp_data</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'public_150k_plus_recent.csv'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># print the summary of values that appear in the `LoanStatus` column</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="s1">'LoanStatus'</code><code class="p">))</code>&#13;
&#13;
<code class="c1"># print the total number of entries in the `LoanStatus` column</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="nb">sum</code><code class="p">(</code><code class="n">ppp_data</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="s1">'LoanStatus'</code><code class="p">)))</code>&#13;
&#13;
<code class="c1"># print the summary of values that appear in the `Gender` column</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="s1">'Gender'</code><code class="p">))</code>&#13;
&#13;
<code class="c1"># print the total number of entries in the `Gender` column</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="nb">sum</code><code class="p">(</code><code class="n">ppp_data</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="s1">'Gender'</code><code class="p">)))</code>&#13;
&#13;
<code class="c1"># print how many rows do not list a value for `BorrowerAddress`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'BorrowerAddress'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">()</code><code class="o">.</code><code class="n">sum</code><code class="p">())</code></pre></div>&#13;
&#13;
<p>The output from <a data-type="xref" href="#ppp_columns_summary">Example 6-8</a>, shown in <a data-type="xref" href="#recent_col_summaries">Example 6-9</a>, starts to paint a picture of what kind of data is actually contained in our dataset’s ~750,000 rows. For example, the status of most loans is “Exemption 4,” which we know from our annotation investigation means it is “exempt from disclosure under FOIA Exemption 4.”<sup><a data-type="noteref" href="ch06.html#idm45143405275328" id="idm45143405275328-marker">19</a></sup> Similarly, we can see that more than two-thirds of loan applicants did not indicate their gender when applying, and 17 loans don’t even list the borrower’s address!</p>&#13;
<div data-type="example" id="recent_col_summaries">&#13;
<h5><span class="label">Example 6-9. </span>Recent data column summaries</h5>&#13;
&#13;
<pre data-type="programlisting">LoanStatus&#13;
Exemption 4            549011&#13;
Paid in Full           110120&#13;
Active Un-Disbursed    107368&#13;
dtype: int64&#13;
766499&#13;
&#13;
Gender&#13;
Unanswered      563074&#13;
Male Owned      168969&#13;
Female Owned     34456&#13;
dtype: int64&#13;
766499&#13;
&#13;
17</pre></div>&#13;
&#13;
<p>So is this data “high volume”? Yes—while we’re missing quite a lot of data overall, there seems to be useful information in a relatively high proportion of the rows and columns that we have. Keep in mind that in some cases, it’s possible to generate useful insights about something with as little as a <em>few dozen</em> rows of data—as long as they contain truly meaningful information. That’s why it’s not sufficient to simply look at the size of a data file or even the number of rows it contains to confirm that it’s truly “high volume”—we actually have to really examine the data in some detail in order to <a data-primary="data quality" data-secondary="data integrity assessments" data-startref="data-quality-integrity-assess2-volume" data-tertiary="high volume" data-type="indexterm" id="idm45143405269152"/><a data-primary="data integrity" data-secondary="assessing" data-startref="data-integrity-assess2-volume" data-tertiary="high volume" data-type="indexterm" id="idm45143405267552"/><a data-primary="assessing" data-secondary="data integrity" data-startref="assessing-data-integrity2-volume" data-tertiary="high volume" data-type="indexterm" id="idm45143405266048"/><a data-primary="high volume, in data integrity" data-startref="high-volume2" data-type="indexterm" id="idm45143405264544"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-startref="ppp-integrity-volume" data-tertiary="high volume" data-type="indexterm" id="idm45143405263584"/>be sure.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Is It Consistent?" data-type="sect2"><div class="sect2" id="idm45143405261728">&#13;
<h2>Is It Consistent?</h2>&#13;
&#13;
<p>Another<a data-primary="data quality" data-secondary="data integrity assessments" data-tertiary="consistent" data-type="indexterm" id="data-quality-integrity-assess2-consistent"/><a data-primary="data integrity" data-secondary="assessing" data-tertiary="consistent" data-type="indexterm" id="data-integrity-assess2-consistent"/><a data-primary="assessing" data-secondary="data integrity" data-tertiary="consistent" data-type="indexterm" id="assessing-data-integrity2-consistent"/><a data-primary="consistent, in data integrity" data-type="indexterm" id="consistent2"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-tertiary="consistent" data-type="indexterm" id="ppp-integrity-consistent"/> thing we know from our earlier completeness check is that the format of the PPP loan data absolutely was <em>not</em> consistent between August and later releases: the data published beginning in December 2020 was <a href="https://washingtonpost.com/business/2020/06/11/trump-administration-wont-say-who-got-511-billion-taxpayer-backed-coronavirus-loans">much more detailed than what had been released previously</a>, and even most of the column names differed between the two files.</p>&#13;
&#13;
<p>Since we’re now relying only on the more recent data files, there is a different kind of consistency we need to think about: how consistent are the values within the dataset itself? We might hope, for example, that the same units will have been used in the dollar amount columns like <code>InitialApprovalAmount</code> and <code>CurrentApprovalAmount</code>. Still, it’s better to check for errors just in case. In <a data-type="xref" href="#ppp_min_max_loan">Example 6-10</a>, we’ll do another quick min/max confirmation to ensure that the figures for these fall within the range we expect.</p>&#13;
<div data-type="example" id="ppp_min_max_loan">&#13;
<h5><span class="label">Example 6-10. </span>ppp_min_max_loan.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for finding the minimum and maximum loans currently approved</code>&#13;
<code class="c1"># in our PPP loan dataset</code>&#13;
&#13;
<code class="c1"># importing the `pandas` library</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="kn">as</code> <code class="nn">pd</code>&#13;
&#13;
<code class="c1"># read the recent data into a pandas DataFrame</code>&#13;
<code class="n">ppp_data</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'public_150k_plus_recent.csv'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># use the pandas `min()` and `max()` methods to retrieve the</code>&#13;
<code class="c1"># largest and smallest values, respectively</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'CurrentApprovalAmount'</code><code class="p">]</code><code class="o">.</code><code class="n">min</code><code class="p">())</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'CurrentApprovalAmount'</code><code class="p">]</code><code class="o">.</code><code class="n">max</code><code class="p">())</code></pre></div>&#13;
&#13;
<p>Based on the title of our data file—<em>150k_plus</em>—we would expect that the <em>minimum</em> loan amount we’ll find approved is $150,000. A quick web search for “maximum loan under ppp” leads to a document on the SBA website that indicates that for most types of businesses,<sup><a data-type="noteref" href="ch06.html#idm45143405217296" id="idm45143405217296-marker">20</a></sup> the maximum loan amount is $10 million. Indeed, running our script seems to confirm that this minimum and maximum are reflected in our data:</p>&#13;
<pre>150000.0&#13;
10000000.0</pre>&#13;
&#13;
<p>At this point, we also want to check for one of the most common (and insidious) forms of inconsistency: spelling differences. <em>Anytime</em> you’re dealing with data that has been entered by humans, there are going to be spelling issues: extra spaces, typos, and differences in punctuation, at minimum. This is a problem because if we want to be able to answer a seemingly simple question like “How many loans originated with lender X?” we need the spelling of that bank’s name to be consistent throughout the data. And it’s almost guaranteed that it won’t be—at least at first.</p>&#13;
&#13;
<p>Fortunately, because this is such a common data problem, there are a number of well-developed approaches for dealing with it. Here we’re going to use an approach <a data-primary="fingerprinting" data-type="indexterm" id="fingerprinting"/>called <em>fingerprinting</em> to begin checking the consistency of bank name spellings in our dataset. While there are many ways that we could cluster these company names (phonetically, for example) when looking for differently spelled duplicates, we’re choosing fingerprinting because it follows a simple, strict-but-effective <em>algorithm</em> (really, just a set of sets) that minimizes the risk that we’ll end up matching up two names that really <em>shouldn’t</em> be the same.</p>&#13;
&#13;
<p>Specifically, the fingerprinting algorithm we’ll be using does the following things:<sup><a data-type="noteref" href="ch06.html#idm45143405172768" id="idm45143405172768-marker">21</a></sup></p>&#13;
<ol>&#13;
<li>&#13;
<p>Removes leading and trailing whitespace</p>&#13;
</li>&#13;
<li>&#13;
<p>Changes all characters to their lowercase representation</p>&#13;
</li>&#13;
<li>&#13;
<p>Removes all punctuation and control characters</p>&#13;
</li>&#13;
<li>&#13;
<p>Normalizes extended Western characters to their ASCII representation (for example “gödel” → “godel”)</p>&#13;
</li>&#13;
<li>&#13;
<p>Splits the string into whitespace-separated <em>tokens</em></p>&#13;
</li>&#13;
<li>&#13;
<p>Sorts the tokens and removes duplicates</p>&#13;
</li>&#13;
<li>&#13;
<p>Joins the tokens back together</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>As usual, <a data-primary="fingerprints library" data-type="indexterm" id="fingerprints-lib"/><a data-primary="Python" data-secondary="fingerprints library" data-type="indexterm" id="python-fingerprint"/>while we could write the code for this ourselves, we’re lucky that someone in the Python community has already done this and has created the library <em>fingerprints</em>, which we can install using pip:</p>&#13;
<pre>pip install fingerprints</pre>&#13;
&#13;
<p>For the moment, our main concern is confirming whether we have any spelling discrepancies to speak of; actually transforming our data to address these differences is something we’ll look at in <a data-type="xref" href="ch07.html#chapter7">Chapter 7</a>. So for now, we’re just going to count all the unique bank names in our dataset and then see how many unique fingerprints there are in that list. If all the bank names in the file are truly distinct, then in <em>theory</em> the two lists should be the same length. If, on the other hand, some of the bank names in our dataset are “unique” only because of minor punctuation and whitespace differences, for example, then our list of fingerprints will be <em>shorter</em> than our list of “unique” bank names. This would suggest that we’ll need to do some data transformations in order to reconcile multiple spellings of the same bank name to ensure that, for example, we’re really able to pull up <em>all</em> of the loans associated with a single bank if we want to (<a data-type="xref" href="#ppp_lender_names">Example 6-11</a>).</p>&#13;
<div data-type="example" id="ppp_lender_names">&#13;
<h5><span class="label">Example 6-11. </span>ppp_lender_names.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for determining whether there are typos &amp;c. in any of the PPP</code>&#13;
<code class="c1"># loan data's bank names</code>&#13;
&#13;
<code class="c1"># importing the `pandas` library</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="kn">as</code> <code class="nn">pd</code>&#13;
&#13;
<code class="c1"># importing the `fingerprints` library, which will help us generate normalized</code>&#13;
<code class="c1"># labels for each of the bank names in our dataset</code>&#13;
<code class="kn">import</code> <code class="nn">fingerprints</code>&#13;
&#13;
<code class="c1"># read the recent data into a pandas DataFrame</code>&#13;
<code class="n">ppp_data</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'public_150k_plus_recent.csv'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># use the pandas DataFrame `unique()` method to create a list of unique</code>&#13;
<code class="c1"># bank names in our data's `OriginatingLender` column</code>&#13;
<code class="n">unique_names</code> <code class="o">=</code> <code class="n">ppp_data</code><code class="p">[</code><code class="s1">'OriginatingLender'</code><code class="p">]</code><code class="o">.</code><code class="n">unique</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># confirm how many unique names there are</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">unique_names</code><code class="p">))</code>&#13;
&#13;
<code class="c1"># create an empty list to hold the fingerprint of each of the unique names</code>&#13;
<code class="n">fingerprint_list</code> <code class="o">=</code> <code class="p">[]</code>&#13;
&#13;
<code class="c1"># iterate through each name in the list of unique names</code>&#13;
<code class="k">for</code> <code class="n">name</code> <code class="ow">in</code> <code class="n">unique_names</code><code class="p">:</code>&#13;
&#13;
    <code class="c1"># for each name, generate its fingerprint</code>&#13;
    <code class="c1"># and append it to the end of the list</code>&#13;
    <code class="n">fingerprint_list</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">fingerprints</code><code class="o">.</code><code class="n">generate</code><code class="p">(</code><code class="n">name</code><code class="p">))</code>&#13;
&#13;
&#13;
<code class="c1"># use the `set()` function to remove duplicates and sort `fingerprint_list`</code>&#13;
<code class="n">fingerprint_set</code> <code class="o">=</code> <code class="nb">set</code><code class="p">(</code><code class="n">fingerprint_list</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># check the length of `fingerprint_set`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">fingerprint_set</code><code class="p">))</code></pre></div>&#13;
&#13;
<p>Running this script yields the output:<sup><a data-type="noteref" href="ch06.html#idm45143405153824" id="idm45143405153824-marker">22</a></sup></p>&#13;
&#13;
<pre data-type="programlisting">4337&#13;
4242</pre>&#13;
&#13;
<p>The length difference between the two lists certainly suggests that there are some spelling discrepancies in our dataset: the number of “unique” names in the raw data is 4,337, but the number of distinct fingerprints for those names is only 4,242. While the difference here is “only” ~100 items, these discrepancies may well affect thousands of rows of data, since on average each bank has issued hundreds of loans (750,000/4337 = ~173). As a result, we cannot say how many rows of our original dataset contain a given “misspelled” name (nor can we be sure that this is exhaustive). In <a data-type="xref" href="ch07.html#correcting_inconsistencies">“Correcting for Spelling Inconsistencies”</a>, we’ll go through the process of transforming our data using these fingerprints to better identify specific lenders <a data-primary="data quality" data-secondary="data integrity assessments" data-startref="data-quality-integrity-assess2-consistent" data-tertiary="consistent" data-type="indexterm" id="idm45143405030896"/><a data-primary="data integrity" data-secondary="assessing" data-startref="data-integrity-assess2-consistent" data-tertiary="consistent" data-type="indexterm" id="idm45143405029296"/><a data-primary="assessing" data-secondary="data integrity" data-startref="assessing-data-integrity2-consistent" data-tertiary="consistent" data-type="indexterm" id="idm45143405027792"/><a data-primary="consistent, in data integrity" data-startref="consistent2" data-type="indexterm" id="idm45143405026288"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-startref="ppp-integrity-consistent" data-tertiary="consistent" data-type="indexterm" id="idm45143405025328"/><a data-primary="fingerprinting" data-startref="fingerprinting" data-type="indexterm" id="idm45143405023776"/><a data-primary="fingerprints library" data-startref="fingerprints-lib" data-type="indexterm" id="idm45143405022832"/><a data-primary="Python" data-secondary="fingerprints library" data-startref="python-fingerprint" data-type="indexterm" id="idm45143405021888"/>and borrowers.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Is It Multivariate?" data-type="sect2"><div class="sect2" id="idm45143405261136">&#13;
<h2>Is It Multivariate?</h2>&#13;
&#13;
<p>In much <a data-primary="data quality" data-secondary="data integrity assessments" data-tertiary="multivariate" data-type="indexterm" id="data-quality-integrity-assess2-multivariate"/><a data-primary="data integrity" data-secondary="assessing" data-tertiary="multivariate" data-type="indexterm" id="data-integrity-assess2-multivariate"/><a data-primary="assessing" data-secondary="data integrity" data-tertiary="multivariate" data-type="indexterm" id="assessing-data-integrity2-multivariate"/><a data-primary="multivariate data (data integrity)" data-type="indexterm" id="multivariate2"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-tertiary="multivariate" data-type="indexterm" id="ppp-integrity-multivariate"/>the same way that a dataset is more likely to be high volume if it contains many rows, it is more likely to be multivariate if it has many columns. Just like our quality check for volume, however, determining whether the columns we have make our data truly multivariate means doing a quality check on the data they contain as well.</p>&#13;
&#13;
<p>For example, while our PPP loan data contains 50 data columns, about a dozen of these are essentially expanded addresses, since the location of the borrower, originating lender, and servicing lender are each broken out into a separate column for street address, city, state, and zip code. While many of the remaining columns may contain unique data, we need to get a sense of what they contain to understand how many data characteristics or <em>features</em> we actually have to work with.</p>&#13;
&#13;
<p>For example, how many of the loans in our dataset have reported requesting money for something other than payroll costs? While the data structure (and the loan program) allows borrowers to use the loans for other things (such as <a href="https://sba.gov/funding-programs/loans/covid-19-relief-options/paycheck-protection-program/first-draw-ppp-loan">healthcare costs and rent</a>), to what extent does that show up in the data?</p>&#13;
&#13;
<p>Just as we did when assessing how high volume our data really was, we’ll look at the contents of a few more columns to determine whether the detail that they appear to offer is really borne out in the amount of data they contain. In this instance (<a data-type="xref" href="#ppp_loan_uses">Example 6-12</a>), we’ll look at how many rows for each of the <code>PROCEED</code> columns do <em>not</em> contain a value.</p>&#13;
<div data-type="example" id="ppp_loan_uses">&#13;
<h5><span class="label">Example 6-12. </span>ppp_loan_uses.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for determining what borrowers did (or really, did not) state</code>&#13;
<code class="c1"># they would use PPP loan funds for</code>&#13;
&#13;
<code class="c1"># importing the `pandas` library</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="kn">as</code> <code class="nn">pd</code>&#13;
&#13;
<code class="c1"># read the recent data sample into a pandas DataFrame</code>&#13;
<code class="n">ppp_data</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'public_150k_plus_recent.csv'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># print how many rows do not list a value for `UTILITIES_PROCEED`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'UTILITIES_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">()</code><code class="o">.</code><code class="n">sum</code><code class="p">())</code>&#13;
&#13;
<code class="c1"># print how many rows do not list a value for `PAYROLL_PROCEED`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'PAYROLL_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">()</code><code class="o">.</code><code class="n">sum</code><code class="p">())</code>&#13;
&#13;
<code class="c1"># print how many rows do not list a value for `MORTGAGE_INTEREST_PROCEED`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'MORTGAGE_INTEREST_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">()</code><code class="o">.</code><code class="n">sum</code><code class="p">())</code>&#13;
&#13;
<code class="c1"># print how many rows do not list a value for `RENT_PROCEED`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'RENT_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">()</code><code class="o">.</code><code class="n">sum</code><code class="p">())</code>&#13;
&#13;
<code class="c1"># print how many rows do not list a value for `REFINANCE_EIDL_PROCEED`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'REFINANCE_EIDL_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">()</code><code class="o">.</code><code class="n">sum</code><code class="p">())</code>&#13;
&#13;
<code class="c1"># print how many rows do not list a value for `HEALTH_CARE_PROCEED`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'HEALTH_CARE_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">()</code><code class="o">.</code><code class="n">sum</code><code class="p">())</code>&#13;
&#13;
<code class="c1"># print how many rows do not list a value for `DEBT_INTEREST_PROCEED`</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'DEBT_INTEREST_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">()</code><code class="o">.</code><code class="n">sum</code><code class="p">())</code>&#13;
&#13;
<code class="c1"># create a new DataFrame that contains all rows reporting *only* payroll costs</code>&#13;
<code class="c1"># that is, where all _other_ costs are listed as "NA"</code>&#13;
<code class="n">payroll_only</code> <code class="o">=</code> <code class="n">ppp_data</code><code class="p">[(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'UTILITIES_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">())</code> <code class="o">&amp;</code> <code class="p">(</code><code class="n">ppp_data</code>&#13;
    <code class="p">[</code><code class="s1">'MORTGAGE_INTEREST_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">())</code> <code class="o">&amp;</code> <code class="p">(</code><code class="n">ppp_data</code>&#13;
    <code class="p">[</code><code class="s1">'MORTGAGE_INTEREST_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">())</code> <code class="o">&amp;</code> <code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'RENT_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">())</code> <code class="o">&amp;</code>&#13;
    <code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'REFINANCE_EIDL_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">())</code> <code class="o">&amp;</code>  <code class="p">(</code><code class="n">ppp_data</code>&#13;
    <code class="p">[</code><code class="s1">'HEALTH_CARE_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">())</code> <code class="o">&amp;</code> <code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'DEBT_INTEREST_PROCEED'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">())</code>&#13;
    <code class="p">]</code>&#13;
&#13;
<code class="c1"># print the length of our "payroll costs only" DataFrame</code>&#13;
<code class="k">print</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">payroll_only</code><code class="o">.</code><code class="n">index</code><code class="p">))</code></pre></div>&#13;
&#13;
<p>As we can see from the output shown in <a data-type="xref" href="#reported_use_of_funds">Example 6-13</a>, the vast majority of businesses (all but 1,828) said that they intended to use money for payroll expenses when they applied, with less than one-third reporting that they would (probably also) use the money to pay utilities. Another portion provided information about using the money for rent. Our last test, meanwhile, shows that well over two-thirds of all businesses listed <em>only</em> payroll expenses as the intended use of their PPP funds.</p>&#13;
<div data-type="example" id="reported_use_of_funds">&#13;
<h5><span class="label">Example 6-13. </span>Reported uses of PPP loan funds</h5>&#13;
&#13;
<pre data-type="programlisting">570995&#13;
1828&#13;
719946&#13;
666788&#13;
743125&#13;
708892&#13;
734456&#13;
538905</pre></div>&#13;
&#13;
<p>What does this mean about how “multivariate” our data is? Even if we decide to discount the additional columns dedicated to address details, or the seemingly underutilized <code>PROCEED</code> columns, there’s still quite a lot of information in this dataset to explore. It seems likely that we’ll be able to use it to at least begin to draw conclusions about who has received PPP loans and how they used the money. As always, however, we cannot take for granted that the columns or rows of our dataset have data content until we’ve checked and confirmed for<a data-primary="data quality" data-secondary="data integrity assessments" data-startref="data-quality-integrity-assess2-multivariate" data-tertiary="multivariate" data-type="indexterm" id="idm45143404750304"/><a data-primary="data integrity" data-secondary="assessing" data-startref="data-integrity-assess2-multivariate" data-tertiary="multivariate" data-type="indexterm" id="idm45143404748624"/><a data-primary="assessing" data-secondary="data integrity" data-startref="assessing-data-integrity2-multivariate" data-tertiary="multivariate" data-type="indexterm" id="idm45143404747120"/><a data-primary="multivariate data (data integrity)" data-startref="multivariate2" data-type="indexterm" id="idm45143404745616"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-startref="ppp-integrity-multivariate" data-tertiary="multivariate" data-type="indexterm" id="idm45143404744656"/> ourselves.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Is It Atomic?" data-type="sect2"><div class="sect2" id="idm45143404742848">&#13;
<h2>Is It Atomic?</h2>&#13;
&#13;
<p>This is <a data-primary="data quality" data-secondary="data integrity assessments" data-tertiary="atomic" data-type="indexterm" id="idm45143404741520"/><a data-primary="data integrity" data-secondary="assessing" data-tertiary="atomic" data-type="indexterm" id="idm45143404740272"/><a data-primary="assessing" data-secondary="data integrity" data-tertiary="atomic" data-type="indexterm" id="idm45143404739056"/><a data-primary="atomic data (data integrity)" data-type="indexterm" id="idm45143404737840"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-tertiary="atomic" data-type="indexterm" id="idm45143404737152"/>another instance where our previous work on the data lets us say “Yes!” fairly quickly on this measure of data integrity. While the August version of our data contained only loan amount ranges, we know that this dataset contains one loan per row, including their exact dollar amounts. Since we have specific numbers rather than summary or aggregate values, we can feel pretty confident that our data is sufficiently granular or “atomic” to support a wide range of possible data analyses later on.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Is It Clear?" data-type="sect2"><div class="sect2" id="idm45143404734976">&#13;
<h2>Is It Clear?</h2>&#13;
&#13;
<p>Although<a data-primary="data quality" data-secondary="data integrity assessments" data-tertiary="clear" data-type="indexterm" id="data-quality-integrity-assess2-clear"/><a data-primary="data integrity" data-secondary="assessing" data-tertiary="clear" data-type="indexterm" id="data-integrity-assess2-clear"/><a data-primary="assessing" data-secondary="data integrity" data-tertiary="clear" data-type="indexterm" id="assessing-data-integrity2-clear"/><a data-primary="clear, in data integrity" data-type="indexterm" id="clear2"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-tertiary="clear" data-type="indexterm" id="ppp-integrity-clear"/> this dataset did <em>not</em> turn out to be especially well annotated, we’ve been able to make our way through many of our data integrity checks nonetheless because, for the most part, its column labels and their meanings <em>are</em> fairly clear. For example, if we weren’t sure what <code>CD</code> stood for, a peek at some of the values (such as <code>SC-05</code>) makes inferring that this stands for “congressional district” fairly straightforward. As we gain more experience working with public and government datasets (or working in a particular subject area), more of the codes and jargon will make sense more quickly.</p>&#13;
&#13;
<p>For the columns whose labels weren’t so clear, exchanging a few emails with Stephen Morris at the SBA was enlightening. For example, he confirmed that the appropriate units for the <code>Term</code> column was months (not weeks, as first seemed likely) and that the <code>PROCEED</code> columns describe what the loan funds would be used for, according to “what the lender submitted to SBA (as stated by the borrower to them on the borrower application).”</p>&#13;
&#13;
<p>My correspondence with Morris also illustrated why going to a primary source expert, if at all possible, is an essential step in conducting data integrity checks. If you recall, one of the column headers whose meaning was <em>not</em> clear at the start was <code>LMIIndicator</code>. Since my sample data rows did not contain values for this column, I started doing some web searches and ended up with results that included “lenders’ mortgage insurance” (as shown in <a data-type="xref" href="#lmi_indicator_search_results">Figure 6-9</a>); at the time, this <em>seemed</em> like a reasonable interpretation of the column heading.</p>&#13;
&#13;
<figure><div class="figure" id="lmi_indicator_search_results">&#13;
<img alt="Search results for LMI Indicator loans" src="assets/ppdw_0609.png"/>&#13;
<h6><span class="label">Figure 6-9. </span>Search results for LMI indicator loans</h6>&#13;
</div></figure>&#13;
&#13;
<p>The only problem? It’s wrong. As Morris clarified via email, “The LMI Indicator tells whether a borrower is geographically located in a Low-Moderate Income zone.”</p>&#13;
&#13;
<p>The lesson here is that if you don’t have an official data dictionary, you always want to be a bit cautious about how much you try to infer from column headers; even those that <em>seem</em> clear may not mean what you think. If there’s any doubt, be sure to reach out to some experts (ideally the folks who compiled the data) to confirm your <a data-primary="data quality" data-secondary="data integrity assessments" data-startref="data-quality-integrity-assess2-clear" data-tertiary="clear" data-type="indexterm" id="idm45143404715616"/><a data-primary="data integrity" data-secondary="assessing" data-startref="data-integrity-assess2-clear" data-tertiary="clear" data-type="indexterm" id="idm45143404714016"/><a data-primary="assessing" data-secondary="data integrity" data-startref="assessing-data-integrity2-clear" data-tertiary="clear" data-type="indexterm" id="idm45143404712512"/><a data-primary="clear, in data integrity" data-startref="clear2" data-type="indexterm" id="idm45143404711008"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-startref="ppp-integrity-clear" data-tertiary="clear" data-type="indexterm" id="idm45143404710048"/>inferences.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Is It Dimensionally Structured?" data-type="sect2"><div class="sect2" id="idm45143404708192">&#13;
<h2>Is It Dimensionally Structured?</h2>&#13;
&#13;
<p>If <a data-primary="data quality" data-secondary="data integrity assessments" data-tertiary="dimensionally structured" data-type="indexterm" id="idm45143404706496"/><a data-primary="data integrity" data-secondary="assessing" data-tertiary="dimensionally structured" data-type="indexterm" id="idm45143404705216"/><a data-primary="assessing" data-secondary="data integrity" data-tertiary="dimensionally structured" data-type="indexterm" id="idm45143404704000"/><a data-primary="dimensionally structured, in data integrity" data-type="indexterm" id="idm45143404702768"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data integrity assessments" data-tertiary="dimensionally structured" data-type="indexterm" id="idm45143404702064"/>the idea of <em>dimensionally structured</em> data seemed a bit abstract when we discussed it in <a data-type="xref" href="ch03.html#chapter3">Chapter 3</a>, hopefully it makes a bit more sense now that we have a real dataset in front of us. Dimensionally structured data includes information about useful categories or classes that we can use to group our data, alongside the more atomic features that help us conduct more granular analyses.</p>&#13;
&#13;
<p>In the case of our PPP loan data, I would say that some of those usefully “dimensional” data columns include ones like <code>RuralUrbanIndicator</code>, <code>HubzoneIndicator</code>, the newly clarified <code>LMIIndicator</code>, <code>NAICSCode</code>, and to some extent even <code>SBAOfficeCode</code>. Columns like <code>RaceEthnicity</code>, <code>Gender</code>, and <code>Veteran</code> could also be dimensionally useful, but as we know that many of them are “Unanswered,” this limits what we can infer from them. The others, meanwhile, can help us answer useful questions about the location and types of businesses that have so far benefited from the PPP.</p>&#13;
&#13;
<p>Even more than that, columns like <code>NAICSCode</code> offer the possibility of usefully <em>augmenting</em> our dataset by allowing us to understand what industries benefiting businesses belong to, which we can potentially compare to things like Bureau of Labor Statistics and other datasets about employment sectors in the United States. We’ll dive into this process more deeply in <a data-type="xref" href="ch07.html#augmenting_data">“Augmenting Your Data”</a>.</p>&#13;
&#13;
<p>So far, we’ve been able to answer some of our data integrity questions with a resounding “Yes!”, while others have been more qualified, suggesting the need for additional transformations and evaluations before we move on to the data analysis phase. Before we do that, however, we need to turn to the crucial question(s) of data <em>fit</em>: whether our data demonstrates the <em>validity</em>, <em>reliability</em>, and <em>representativeness</em> we need in order to draw meaningful conclusions about (in this case) how the PPP is affecting small businesses in the<a data-primary="data quality" data-secondary="data integrity assessments" data-startref="data-quality-integrity-assess2" data-type="indexterm" id="idm45143404689600"/><a data-primary="data integrity" data-secondary="assessing" data-startref="data-integrity-assess2" data-type="indexterm" id="idm45143404688272"/><a data-primary="assessing" data-secondary="data integrity" data-startref="assessing-data-integrity2" data-type="indexterm" id="idm45143404687056"/> United States.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Assessing Data Fit" data-type="sect1"><div class="sect1" id="idm45143406480432">&#13;
<h1>Assessing Data Fit</h1>&#13;
&#13;
<p>Now <a data-primary="data quality" data-secondary="data fit assessments" data-type="indexterm" id="data-quality-fit-assess2"/><a data-primary="data fit" data-secondary="assessing" data-type="indexterm" id="data-fit-assess2"/><a data-primary="assessing" data-secondary="data fit" data-type="indexterm" id="assessing-data-fit2"/>that we’ve evaluated our dataset’s integrity with respect to nearly a dozen different measures, it’s time to assess the extent to which it is <em>fit</em> for our purposes; that is, whether this data can really give us answers to the question(s) that we’re asking. To do that, we’ll turn to our three main criteria for data <em>fitness</em>: validity, reliability, and representativeness. Now is the time that we need to examine our dataset with our original question in mind: did the PPP help save American small businesses?</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Validity" data-type="sect2"><div class="sect2" id="idm45143404679088">&#13;
<h2>Validity</h2>&#13;
&#13;
<p>Remember <a data-primary="data quality" data-secondary="data fit assessments" data-tertiary="validity" data-type="indexterm" id="data-quality-fit-assess2-validity"/><a data-primary="data fit" data-secondary="assessing" data-tertiary="validity" data-type="indexterm" id="data-fit-assess2-validity"/><a data-primary="assessing" data-secondary="data fit" data-tertiary="validity" data-type="indexterm" id="assessing-data-fit2-validity"/><a data-primary="validity, in data fit" data-type="indexterm" id="validity-data-fit2"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data fit assessments" data-tertiary="validity" data-type="indexterm" id="ppp-fit-validity"/>that our working definition of validity is “the extent that something measures what it’s supposed to.” Even if our PPP loan data was perfect, we’d need to somehow determine whether it can answer that question in some way. At this point, we know that our dataset provides one essential piece of that answer, because we are pretty confident now that it accurately details which businesses currently have <em>approved</em> PPP loans. Through our investigations into its integrity (especially around completeness and in our search for annotating information, or <em>metadata</em>), we are also pretty confident that already <em>canceled</em> loans are not showing up in the dataset—we confirmed this both through the SBA’s published information about the PPP program and by reaching out directly to businesses.</p>&#13;
&#13;
<p>We can also use elements of the dataset (specifically <code>LoanStatus</code> and <code>LoanStatusDate</code>) to get a sense of which businesses—among the more than 750,000 that have been approved for a loan—have actually received the money. We can check this by first summarizing the <code>LoanStatus</code> column using the <code>value_counts()</code> method as we have before, as shown in <a data-type="xref" href="#ppp_loan_status">Example 6-14</a>.</p>&#13;
<div data-type="example" id="ppp_loan_status">&#13;
<h5><span class="label">Example 6-14. </span>ppp_loan_status.py</h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for determining how many loans have been disbursed</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># importing the `pandas` library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># read the recent data sample into a pandas DataFrame</code><code>&#13;
</code><code class="n">ppp_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">public_150k_plus_recent.csv</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># print a summary of values in the `LoanStatus` column</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">LoanStatus</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="nb">sum</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">LoanStatus</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_assessing_data_quality_CO6-1" id="co_assessing_data_quality_CO6-1"><img alt="1" src="assets/1.png"/></a></pre></div>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_assessing_data_quality_CO6-1" id="callout_assessing_data_quality_CO6-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Note that because the <code>value_counts()</code> method will <em>not</em> include <code>NA</code> values, I am also summing the entries to make sure every row has been accounted for.</p></dd>&#13;
</dl>&#13;
&#13;
<p>The output from this script, shown in <a data-type="xref" href="#loanstatus_summary">Example 6-15</a>, confirms that of the 766,499 loans currently in our dataset, the funds for over 100,000 of them have not actually been sent to businesses yet, while more than another 100,000 businesses appear to have repaid their loans already.</p>&#13;
<div class="pagebreak-before less_space" data-type="example" id="loanstatus_summary">&#13;
<h5><span class="label">Example 6-15. </span><code>LoanStatus</code> summary</h5>&#13;
&#13;
<pre data-type="programlisting">Exemption 4            549011&#13;
Paid in Full           110120&#13;
Active Un-Disbursed    107368&#13;
Name: LoanStatus, dtype: int64&#13;
766499</pre></div>&#13;
&#13;
<p>If we’re hoping to evaluate the fate of small businesses that received PPP loans, then, we need to start by making sure that we look only at those that have actually <em>received</em> the funds—meaning that we should restrict our inquiry to those whose <code>LoanStatus</code> value is either “Exemption 4” or “Paid in Full.”</p>&#13;
&#13;
<p>In theory, when businesses applied for PPP loans, they asked for enough money to keep their businesses afloat, so we might be tempted to assume that if a business has gotten the PPP money, it should be doing all right. But just as potentially too-loose criteria may have allowed many businesses to <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3906395">fraudulently get PPP loans</a>, the fact that a business <em>received</em> PPP money is no guarantee that it’s still doing OK. This reality is exemplified by this <em>Wall Street Journal</em> article, <a href="https://wsj.com/articles/hundreds-of-companies-that-got-stimulus-aid-have-failed-11605609180">which tells the story of one company that filed for bankruptcy despite receiving a PPP loan</a>. Since we already know that this business filed for bankruptcy, finding its record within our dataset can help give us a sense of what these records potentially look like, as shown in <a data-type="xref" href="#ppp_find_waterford">Example 6-16</a>.</p>&#13;
<div data-type="example" id="ppp_find_waterford">&#13;
<h5><span class="label">Example 6-16. </span><em>ppp_find_waterford.py</em></h5>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="c1"># quick script for finding a business within our dataset by (partial) name</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># importing the `pandas` library</code><code>&#13;
</code><code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># read the recent data sample into a pandas DataFrame</code><code>&#13;
</code><code class="n">ppp_data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">public_150k_plus_recent.csv</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="c1"># create a DataFrame without any missing `BorrowerName` values</code><code>&#13;
</code><code class="n">ppp_data_named_borrowers</code><code> </code><code class="o">=</code><code> </code><code class="n">ppp_data</code><code class="p">[</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">BorrowerName</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">notna</code><code class="p">(</code><code class="p">)</code><code class="p">]</code><code> </code><a class="co" href="#callout_assessing_data_quality_CO7-1" id="co_assessing_data_quality_CO7-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># because precise matching can be tricky,</code><code>&#13;
</code><code class="c1"># we'll use the pandas `str.contains()` method</code><code>&#13;
</code><code class="n">bankruptcy_example</code><code> </code><code class="o">=</code><code> </code><code class="n">ppp_data_named_borrowers</code><code class="p">[</code><code> </code><code>\&#13;
</code><code>                                </code><code class="n">ppp_data_named_borrowers</code><code class="p">[</code><code class="s1">'</code><code class="s1">BorrowerName</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>                                </code><code class="o">.</code><code class="n">str</code><code class="o">.</code><code class="n">contains</code><code class="p">(</code><code class="s1">'</code><code class="s1">WATERFORD RECEPTIONS</code><code class="s1">'</code><code class="p">)</code><code class="p">]</code><code> </code><a class="co" href="#callout_assessing_data_quality_CO7-2" id="co_assessing_data_quality_CO7-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="c1"># transposing the result so it's easier to read</code><code>&#13;
</code><code class="k">print</code><code class="p">(</code><code class="n">bankruptcy_example</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="p">)</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_assessing_data_quality_CO7-1" id="callout_assessing_data_quality_CO7-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Pandas cannot search for a string within any column that has <code>NA</code> values, so we need to create a DataFrame that doesn’t have any of those in our target column, just for review purposes (obviously we might want to investigate loans with no named borrower).</p></dd>&#13;
<dt><a class="co" href="#co_assessing_data_quality_CO7-2" id="callout_assessing_data_quality_CO7-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>While <code>str.contains()</code> will match successfully on only part of a string, it <em>is</em> case-sensitive. This means that the fact that borrower names are in ALL CAPS matters!</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>The following output from this script is telling: the loan shows up with a status of “Exemption 4,” and perhaps even more interestingly, with a <code>LoanStatusDate</code> of <code>NA</code>. But otherwise, there’s no indicator that this business is, well, no longer in business.</p>&#13;
&#13;
<pre data-type="programlisting">LoanNumber                                        7560217107&#13;
DateApproved                                      04/14/2020&#13;
SBAOfficeCode                                            353&#13;
ProcessingMethod                                         PPP&#13;
BorrowerName                       WATERFORD RECEPTIONS, LLC&#13;
BorrowerAddress                         6715 COMMERCE STREET&#13;
BorrowerCity                                     SPRINGFIELD&#13;
BorrowerState                                             VA&#13;
BorrowerZip                                            22150&#13;
LoanStatusDate                                           NaN&#13;
LoanStatus                                       Exemption 4&#13;
Term                                                      24&#13;
SBAGuarantyPercentage                                    100&#13;
InitialApprovalAmount                               413345.0&#13;
CurrentApprovalAmount                               413345.0&#13;
UndisbursedAmount                                        0.0&#13;
FranchiseName                                            NaN&#13;
ServicingLenderLocationID                             122873&#13;
ServicingLenderName                                EagleBank&#13;
ServicingLenderAddress                     7815 Woodmont Ave&#13;
ServicingLenderCity                                 BETHESDA&#13;
ServicingLenderState                                      MD&#13;
ServicingLenderZip                                     20814&#13;
RuralUrbanIndicator                                        U&#13;
HubzoneIndicator                                           N&#13;
LMIIndicator                                             NaN&#13;
BusinessAgeDescription       New Business or 2 years or less&#13;
ProjectCity                                      SPRINGFIELD&#13;
ProjectCountyName                                    FAIRFAX&#13;
ProjectState                                              VA&#13;
ProjectZip                                        22150-0001&#13;
CD                                                     VA-08&#13;
JobsReported                                            45.0&#13;
NAICSCode                                           722320.0&#13;
RaceEthnicity                                     Unanswered&#13;
UTILITIES_PROCEED                                        NaN&#13;
PAYROLL_PROCEED                                     413345.0&#13;
MORTGAGE_INTEREST_PROCEED                                NaN&#13;
RENT_PROCEED                                             NaN&#13;
REFINANCE_EIDL_PROCEED                                   NaN&#13;
HEALTH_CARE_PROCEED                                      NaN&#13;
DEBT_INTEREST_PROCEED                                    NaN&#13;
BusinessType                 Limited  Liability Company(LLC)&#13;
OriginatingLenderLocationID                           122873&#13;
OriginatingLender                                  EagleBank&#13;
OriginatingLenderCity                               BETHESDA&#13;
OriginatingLenderState                                    MD&#13;
Gender                                            Male Owned&#13;
Veteran                                          Non-Veteran&#13;
NonProfit                                                NaN</pre>&#13;
&#13;
<p>In fact, if we quickly check how many loans appear with a <code>LoanStatusDate</code> of <code>NA</code> by adding the following line to the end of our script, we see that it is a perfect match for those with a <code>LoanStatus</code> of <code>Exemption 4</code>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="k">print</code><code class="p">(</code><code class="nb">sum</code><code class="p">(</code><code class="n">ppp_data</code><code class="p">[</code><code class="s1">'LoanStatusDate'</code><code class="p">]</code><code class="o">.</code><code class="n">isna</code><code class="p">()))</code></pre>&#13;
&#13;
<p>So does this PPP loan data <em>measure what it is supposed to measure</em>? I would say yes, but that’s not the whole story. As we saw from our summary of the <code>LoanStatus</code> information, not all of the businesses that appear in this dataset <em>have actually gotten a loan</em>; they have been approved and still <em>could</em> receive the money (we know their loans have not been canceled)—but 107,368 of them have not yet taken the money, and we can’t know for sure if they ever will.</p>&#13;
&#13;
<p>We also can’t say from this dataset alone what has happened to the businesses that have received the money. Some may still be in operation; others have gone bankrupt. Still others could have liquidated without filing for bankruptcy. In other words, while the PPP data has strong validity when it comes to answering certain parts of our question, answering the whole question will require much more than just this one<a data-primary="data quality" data-secondary="data fit assessments" data-startref="data-quality-fit-assess2-validity" data-tertiary="validity" data-type="indexterm" id="idm45143404431328"/><a data-primary="data fit" data-secondary="assessing" data-startref="data-fit-assess2-validity" data-tertiary="validity" data-type="indexterm" id="idm45143404429808"/><a data-primary="assessing" data-secondary="data fit" data-startref="assessing-data-fit2-validity" data-tertiary="validity" data-type="indexterm" id="idm45143404428304"/><a data-primary="validity, in data fit" data-startref="validity-data-fit2" data-type="indexterm" id="idm45143404426800"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data fit assessments" data-startref="ppp-fit-validity" data-tertiary="validity" data-type="indexterm" id="idm45143404425856"/> dataset.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Reliability" data-type="sect2"><div class="sect2" id="idm45143404678464">&#13;
<h2>Reliability</h2>&#13;
&#13;
<p>When it <a data-primary="data quality" data-secondary="data fit assessments" data-tertiary="reliability" data-type="indexterm" id="idm45143404422752"/><a data-primary="data fit" data-secondary="assessing" data-tertiary="reliability" data-type="indexterm" id="idm45143404421472"/><a data-primary="assessing" data-secondary="data fit" data-tertiary="reliability" data-type="indexterm" id="idm45143404420256"/><a data-primary="reliability, in data fit" data-type="indexterm" id="idm45143404393120"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data fit assessments" data-tertiary="reliability" data-type="indexterm" id="idm45143404392512"/>comes to <em>reliability</em>, the primary criteria we are interested in are <em>accuracy</em> and <em>stability</em>. In other words, how well does the PPP data reflect who has gotten PPP loans, and how likely is it that the picture of who has gotten those loans will change over time?</p>&#13;
&#13;
<p>Thanks to our previous investigations, we know by now that the <em>stability</em> of this dataset is far from perfect. Several thousand businesses that were approved for loans and appeared in the August dataset do <em>not</em> appear in the current one (we’ll address the implications this has for <em>representativeness</em> in the next section), which comports with documentation from the SBA<sup><a data-type="noteref" href="ch06.html#idm45143404387856" id="idm45143404387856-marker">23</a></sup> that canceled loans are not included.<sup><a data-type="noteref" href="ch06.html#idm45143404385984" id="idm45143404385984-marker">24</a></sup> It’s also not clear whether, as updates are made, previous versions of the data will still be available, making it difficult to determine what has changed unless we begin downloading and archiving each release ourselves.</p>&#13;
&#13;
<p>Even the figures within the dataset itself may not be especially stable over time. For example, we know that 538,905 businesses reported that they would only be using their PPP loan for payroll costs. But as SBA representative Stephen Morris explained via email, “This data is speculative to some extent because it’s not required that the borrower use the funds for the purpose they selected on their application.” In other words, unless some part of the loan forgiveness or repayment process <em>requires</em> that PPP loan recipients detail how the money was spent (and that information is subsequently updated in this dataset), we can’t know for sure whether the figures we see in the various <code>PROCEED</code> columns are either accurate or stable.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Representativeness" data-type="sect2"><div class="sect2" id="idm45143404382864">&#13;
<h2>Representativeness</h2>&#13;
&#13;
<p>Is the<a data-primary="data quality" data-secondary="data fit assessments" data-tertiary="representativeness" data-type="indexterm" id="data-quality-fit-assess2-representativeness"/><a data-primary="data fit" data-secondary="assessing" data-tertiary="representativeness" data-type="indexterm" id="data-fit-assess2-representativeness"/><a data-primary="assessing" data-secondary="data fit" data-tertiary="representativeness" data-type="indexterm" id="assessing-data-fit2-representativeness"/><a data-primary="representativeness, in data fit" data-type="indexterm" id="representativeness-data-fit2"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data fit assessments" data-tertiary="representativeness" data-type="indexterm" id="ppp-fit-representativeness"/> PPP loan data representative of everyone who actually received a PPP loan? Most likely. After a public outcry <a href="https://nbcnews.com/business/business-news/which-companies-are-returning-their-ppp-loan-here-s-list-n1194566">led many large and/or publicly traded companies to return early PPP loans</a>, the SBA indicated that they would be closely scrutinizing loans over $2 million, and <a href="https://cnbc.com/2020/07/06/companies-returned-30-billion-in-small-business-loans-from-ppp.html">almost $30 billion in loans had been returned or canceled by early July</a>. After our relatively exhaustive comparisons between the August and February datasets, we can feel pretty confident that the dataset we have is at least representative of who has received PPP loans to date.</p>&#13;
&#13;
<p>At the same time, this doesn’t really tell us as much as we might think. We already know that the vast majority of PPP loan recipients that appear in this data did not disclose their gender, race, ethnicity, or veteran status, meaning that we have no real way of knowing how well (if at all) the demographics of PPP loan recipients reflect the population of small business owners in the United States. In fact, as we’ll see in <a data-type="xref" href="ch09.html#chapter9">Chapter 9</a> it’s very unlikely that we can draw conclusions about the demographics of PPP loan recipients at all, because the number of applicants who included this information is so small.</p>&#13;
&#13;
<p class="pagebreak-before less_space">But the question of representativeness actually goes deeper than that, back to (and beyond) those 7,207 loans that disappeared between the August data release and the more recent one(s). Those missing loans reflect businesses that applied for loans and were approved, but in the words of one employee: “The money just never arrived.” That means that while we know how many businesses <em>got</em> a PPP loan, we have no way of knowing <em>how many applied</em>. Because those canceled loans have been removed from the data, we are now left with an instance of what I like to call the “denominator” problem.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The denominator problem" data-type="sect3"><div class="sect3" id="idm45143404368080">&#13;
<h3>The denominator problem</h3>&#13;
&#13;
<p>The<a data-primary="denominator problem" data-type="indexterm" id="idm45143404366528"/><a data-primary="benchmarking problem" data-type="indexterm" id="idm45143404365824"/><a data-primary="baseline problem" data-type="indexterm" id="idm45143404365120"/> denominator problem is recognized—albeit under different names—across almost every field of data-driven inquiry. Sometimes called the <em>benchmarking</em> or <em>baseline</em> problem,<sup><a data-type="noteref" href="ch06.html#idm45143404363328" id="idm45143404363328-marker">25</a></sup> the denominator problem encapsulates the difficulty of trying to draw meaning from data when you lack sufficient comparative information to put it into context. In most cases, this is because the comparison data you really need was never collected.</p>&#13;
&#13;
<p>In our exploration of the PPP data, we’ve already encountered one version of this problem: we know which businesses have received loans, but we don’t know who applied and was rejected or why (in at least some cases, it seems, the recipients don’t know, either). This is a problem for assessing the PPP loan process, because we don’t know if legitimate applicants have been rejected even as some businesses are granted multiple rounds of loans. If we want to know whether the distribution of loans was fair—or even effective—knowing who <em>hasn’t</em> been included is as important as finding out who <em>has</em>.</p>&#13;
&#13;
<p>Some of the denominator problems we’ve encountered so far may be answerable using complementary data of some kind—that’s what <em>The Wall Street Journal</em> did in comparing PPP loan data to bankruptcy filings. In others, the solution will be for us to build our own archive if—as seems to be the case here—the earlier datasets are not being offered by the data provider along with the updated <a data-primary="data quality" data-secondary="data fit assessments" data-startref="data-quality-fit-assess2" data-type="indexterm" id="idm45143404358496"/><a data-primary="data fit" data-secondary="assessing" data-startref="data-fit-assess2" data-type="indexterm" id="idm45143404357344"/><a data-primary="assessing" data-secondary="data fit" data-startref="assessing-data-fit2" data-type="indexterm" id="idm45143404356256"/><a data-primary="data quality" data-secondary="data fit assessments" data-startref="data-quality-fit-assess2-representativeness" data-tertiary="representativeness" data-type="indexterm" id="idm45143404355136"/><a data-primary="data fit" data-secondary="assessing" data-startref="data-fit-assess2-representativeness" data-tertiary="representativeness" data-type="indexterm" id="idm45143404353552"/><a data-primary="assessing" data-secondary="data fit" data-startref="assessing-data-fit2-representativeness" data-tertiary="representativeness" data-type="indexterm" id="idm45143404352048"/><a data-primary="representativeness, in data fit" data-startref="representativeness-data-fit2" data-type="indexterm" id="idm45143404350544"/><a data-primary="PPP (Paycheck Protection Program) example" data-secondary="data fit assessments" data-startref="ppp-fit-representativeness" data-tertiary="representativeness" data-type="indexterm" id="idm45143404349568"/>versions.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm45143404347776">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>So, did the Paycheck Protection Program help save small businesses? <em>Maybe</em>. On the one hand, it’s hard to imagine that so much money could be spent without <em>some</em> positive benefit. On the other hand, both the real world—and the data we have about it—is a complicated, interdependent mess. If a PPP loan recipient pivoted its business model and found new revenue streams, would we put it in the “saved by the PPP” category or not? Similarly, if a business that didn’t receive a loan fails, is that <em>because</em> it didn’t receive a loan, or would it have failed anyway? The more of these “what ifs” we propose, the more likely it is that a couple of things will happen:</p>&#13;
<ol>&#13;
<li>&#13;
<p>We’ll develop a violent headache, decide it isn’t possible to <em>really</em> know anything, and look for a reassuring way to procrastinate.</p>&#13;
</li>&#13;
<li>&#13;
<p>After enough time playing games/reading the internet/complaining to confused friends and relations about how we spent all this time wrangling a dataset that we’re not sure is worth anything and we can hardly remember why we started this whole thing in the first place, we’ll come across something that gives us an idea for a <em>slightly</em> different, possibly <em>much</em> narrower question to explore, and excitedly return to our dataset, eager to see if we can somehow answer this new question any better than the last one.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>Is this process arduous and circuitous? Yes. It is also reminiscent of our discussion about construct validity in <a data-type="xref" href="ch03.html#how_for_whom">“How? And for Whom?”</a>. In the end, it is also <em>actually how new knowledge is formed.</em> The uncertain, frustrating, and slippery work of considering new options, thinking them through, testing them out, and then (potentially) starting the whole process over again with a bit more information and understanding the next time is how genuinely <em>original</em> insights are made. It’s the thing that every algorithmic system in the world is desperately trying to approximate, or imitate. But if you’re willing to put the effort in, <em>you can</em> actually succeed.</p>&#13;
&#13;
<p>At this point, I feel like I’ve learned quite a bit about this dataset—enough that I know I probably <em>cannot</em> answer my original question with it but can still imagine some interesting insights it could yield. For example, I feel confident that the most recent data accurately reflects the state of currently approved loans, because I confirmed that loans missing from more recent files were (for some reason or other) probably never actually made. At the same time, while the SBA announced that as of early January 2021, over <a href="https://sba.gov/article/2021/jan/12/11-million-paycheck-protection-program-loans-forgiven-so-far-totaling-over-100-billion">$100 billion in PPP loans had been forgiven</a>, there didn’t seem to be a distinct value in the <code>LoanStatus</code> column to indicate forgiven loans, even more than six weeks later. While the SBA’s Stephen Morris stopped responding to my emails in early March, as of early May 2021, a data dictionary does seem to be available,<sup><a data-type="noteref" href="ch06.html#idm45143404333728" id="idm45143404333728-marker">26</a></sup> even if neither it—nor the updated data—contains this information, either.</p>&#13;
&#13;
<p>Of course, there’s still plenty more to learn here: about who has received loans and where they’re located, how much they were approved for, and who is making those loans. And while the data is far from perfect, I can keep copies of past datasets on hand to reassure myself that if anything in the future changes significantly, I will at least have the resources on hand to spot it. Given that, it’s time to move on from the assessment phase of our work and apply ourselves to the task of actually cleaning and transforming our data, which we’ll tackle in <a data-type="xref" href="ch07.html#chapter7">Chapter 7</a>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45143406437120"><sup><a href="ch06.html#idm45143406437120-marker">1</a></sup> Even if they don’t always realize it.</p><p data-type="footnote" id="idm45143406492528"><sup><a href="ch06.html#idm45143406492528-marker">2</a></sup> See <a href="https://en.wikipedia.org/wiki/Paycheck_Protection_Program"><em class="hyperlink">https://en.wikipedia.org/wiki/Paycheck_Protection_Program</em></a> for details on the PPP.</p><p data-type="footnote" id="idm45143406490368"><sup><a href="ch06.html#idm45143406490368-marker">3</a></sup> “Who Got Half a Trillion in COVID Loans? The Trump Administration Won’t Say,” <a href="https://marketplace.org/shows/make-me-smart-with-kai-and-molly/who-got-half-a-billion-in-covid-loans-the-trump-administration-wont-say"><em class="hyperlink">https://marketplace.org/shows/make-me-smart-with-kai-and-molly/who-got-half-a-billion-in-covid-loans-the-trump-administration-wont-say</em></a>.</p><p data-type="footnote" id="idm45143406483424"><sup><a href="ch06.html#idm45143406483424-marker">4</a></sup> You can find a good markdown cheatsheet at <a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Here-Cheatsheet"><em class="hyperlink">https://github.com/adam-p/markdown-here/wiki/Markdown-Here-Cheatsheet</em></a>.</p><p data-type="footnote" id="idm45143406687968"><sup><a href="ch06.html#idm45143406687968-marker">5</a></sup> The original link for this content was <a href="https://home.treasury.gov/policy-issues/cares-act/assistance-for-small-businesses/sba-paycheck-protection-program-loan-level-data"><em class="hyperlink">https://home.treasury.gov/policy-issues/cares-act/assistance-for-small-businesses/sba-paycheck-protection-program-loan-level-data</em></a>, however it is now found at <a href="https://home.treasury.gov/policy-issues/coronavirus/assistance-for-small-businesses/paycheck-protection-program"><em class="hyperlink">https://home.treasury.gov/policy-issues/coronavirus/assistance-for-small-businesses/paycheck-protection-program</em></a>.</p><p data-type="footnote" id="idm45143406684480"><sup><a href="ch06.html#idm45143406684480-marker">6</a></sup> And this second link is <a href="https://sba.gov/funding-programs/loans/coronavirus-relief-options/paycheck-protection-program/ppp-data"><em class="hyperlink">https://sba.gov/funding-programs/loans/coronavirus-relief-options/paycheck-protection-program/ppp-data</em></a>.</p><p data-type="footnote" id="idm45143406648768"><sup><a href="ch06.html#idm45143406648768-marker">7</a></sup> You can download this file at <a href="https://drive.google.com/file/d/1EtUB0nK9aQeWWWGUOiayO9Oe-avsKvXH/view?usp=sharing"><em class="hyperlink">https://drive.google.com/file/d/1EtUB0nK9aQeWWWGUOiayO9Oe-avsKvXH/view?usp=sharing</em></a>.</p><p data-type="footnote" id="idm45143406646448"><sup><a href="ch06.html#idm45143406646448-marker">8</a></sup> Data for August 2020 can be found at <a href="https://drive.google.com/file/d/11wTOapbAzcfeCQVVB-YJFIpsQVaZxJAm/view?usp=sharing"><em class="hyperlink">https://drive.google.com/file/d/11wTOapbAzcfeCQVVB-YJFIpsQVaZxJAm/view?usp=sharing</em></a>; data for February 2021 can be found at <a href="https://drive.google.com/file/d/1EtUB0nK9aQeWWWGUOiayO9Oe-avsKvXH/view?usp=sharing"><em class="hyperlink">https://drive.google.com/file/d/1EtUB0nK9aQeWWWGUOiayO9Oe-avsKvXH/view?usp=sharing</em></a>.</p><p data-type="footnote" id="idm45143406638368"><sup><a href="ch06.html#idm45143406638368-marker">9</a></sup> Following the 2008 financial crisis, for example, it became clear that many banks had not kept proper records as they repackaged and sold—or “securitized”—home mortgages, leading some courts to <a href="https://nytimes.com/2009/10/25/business/economy/25gret.html">reject their attempts to foreclose on homeowners</a>.</p><p data-type="footnote" id="idm45143406630688"><sup><a href="ch06.html#idm45143406630688-marker">10</a></sup> The following links are included for posterity, as they represent the original locations from which the datasets provided with this chapter are drawn.</p><p data-type="footnote" id="idm45143405919056"><sup><a href="ch06.html#idm45143405919056-marker">11</a></sup> For South Carolina congressional districts, see Wikipedia’s page at <a href="https://en.wikipedia.org/wiki/South_Carolina%27s_congressional_districts#Historical_and_present_district_boundaries"><em class="hyperlink">https://en.wikipedia.org/wiki/South_Carolina%27s_congressional_districts#Historical_and_present_district_boundaries</em></a>.</p><p data-type="footnote" id="idm45143405666608"><sup><a href="ch06.html#idm45143405666608-marker">12</a></sup> The SBA began accepting applications for so-called “second-round” PPP loans on <a href="https://uschamber.com/co/run/business-financing/second-draw-ppp-loans">January 31, 2021</a>.</p><p data-type="footnote" id="idm45143405581136"><sup><a href="ch06.html#idm45143405581136-marker">13</a></sup> Attempting to attribute axioms is always problematic, but while I prefer the phrasing of <em>incompetence</em> or <em>neglect</em>, I like the attribution of this expression as “Hanlon’s Razor” found in <a href="https://jargon-file.org/archive/jargon-4.4.7.dos.txt">“The Jargon File”</a>, mostly because that document explains the origin of a lot of computer/programming slang.</p><p data-type="footnote" id="idm45143405576560"><sup><a href="ch06.html#idm45143405576560-marker">14</a></sup> Of course, <em>why</em> it was never sent is an interesting question unto itself.</p><p data-type="footnote" id="idm45143405548048"><sup><a href="ch06.html#idm45143405548048-marker">15</a></sup> You may have noticed that in this chapter, I haven’t addressed our data integrity criteria in precisely the order I listed them in <a data-type="xref" href="ch03.html#chapter3">Chapter 3</a>. Because the PPP was <a href="https://journalofaccountancy.com/news/2020/apr/paycheck-protection-program-ppp-loans-sba-details-coronavirus.html">modeled on the existing 7(a) loan program</a>, I made the (questionable) assumption that this data would be well-annotated. Of course, these were also the <em>only</em> datasets available about the PPP, so my options were limited (as they so often are when working with real-world data).</p><p data-type="footnote" id="idm45143405541024"><sup><a href="ch06.html#idm45143405541024-marker">16</a></sup> I sometimes find it easier to think of transposing data as “turning it on its side.”</p><p data-type="footnote" id="idm45143405428640"><sup><a href="ch06.html#idm45143405428640-marker">17</a></sup> This page has changed considerably since this chapter was originally written. Notably, the main data location now includes a “data dictionary”—but this was released only several months after the data was first posted.</p><p data-type="footnote" id="idm45143405416416"><sup><a href="ch06.html#idm45143405416416-marker">18</a></sup> It seems slightly noteworthy that this attribution was changed to <code>SM</code> shortly after I reached out to him.</p><p data-type="footnote" id="idm45143405275328"><sup><a href="ch06.html#idm45143405275328-marker">19</a></sup> For more information on FOIA requests and exemptions, see <a data-type="xref" href="app03.html#foia_requests">“FOIA/L Requests”</a> and the full text of the exemption on the <a href="https://justice.gov/oip/exemption-4-after-supreme-courts-ruling-food-marketing-institute-v-argus-leader-media">Department of Justice’s website</a>.</p><p data-type="footnote" id="idm45143405217296"><sup><a href="ch06.html#idm45143405217296-marker">20</a></sup> Specifically, “Paycheck Protection Program: How to Calculate Maximum Loan Amounts for First Draw PPP Loans and What Documentation to Provide by Business Type,” which can be found at <a href="https://sba.gov/sites/default/files/2021-01/PPP%20--%20How%20to%20Calculate%20Maximum%20Loan%20Amounts%20for%20First%20Draw%20PPP%20Loans%20%281.17.2021%29-508.pdf"><em class="hyperlink">https://sba.gov/sites/default/files/2021-01/PPP%20--%20How%20to%20Calculate%20Maximum%20Loan%20Amounts%20for%20First%20Draw%20PPP%20Loans%20%281.17.2021%29-508.pdf</em></a>.</p><p data-type="footnote" id="idm45143405172768"><sup><a href="ch06.html#idm45143405172768-marker">21</a></sup> See <a href="https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth"><em class="hyperlink">https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth</em></a> for more information on clustering.</p><p data-type="footnote" id="idm45143405153824"><sup><a href="ch06.html#idm45143405153824-marker">22</a></sup> When you run this script, you may see a warning about installing pyICU. Installing this library is a little bit complicated, however, and won’t change our results for this exercise. If you plan to use this fingerprinting process extensively, though, you may want to invest the additional time to setup pyICU. You can find more information about this process here: <a href="https://pypi.org/project/PyICU"><em class="hyperlink">https://pypi.org/project/PyICU</em></a>.</p><p data-type="footnote" id="idm45143404387856"><sup><a href="ch06.html#idm45143404387856-marker">23</a></sup> Which can be downloaded from <a href="https://sba.gov/document/report-paycheck-protection-program-ppp-loan-data-key-aspects"><em class="hyperlink">https://sba.gov/document/report-paycheck-protection-program-ppp-loan-data-key-aspects</em></a>.</p><p data-type="footnote" id="idm45143404385984"><sup><a href="ch06.html#idm45143404385984-marker">24</a></sup> Again, understanding why and how these loans were canceled might be instructive, but we won’t find that information here—only some bread crumbs about where to start looking.</p><p data-type="footnote" id="idm45143404363328"><sup><a href="ch06.html#idm45143404363328-marker">25</a></sup> The term <em>denominator problem</em> appears to have a very specific meaning when it comes to US property law, but needless to say, that is not precisely how I am using it here.</p><p data-type="footnote" id="idm45143404333728"><sup><a href="ch06.html#idm45143404333728-marker">26</a></sup> And can be found at <a href="https://data.sba.gov/dataset/ppp-foia/resource/aab8e9f9-36d1-42e1-b3ba-e59c79f1d7f0"><em class="hyperlink">https://data.sba.gov/dataset/ppp-foia/resource/aab8e9f9-36d1-42e1-b3ba-e59c79f1d7f0</em></a>.</p></div></div></section></body></html>