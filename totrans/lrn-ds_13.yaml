- en: Chapter 10\. Exploratory Data Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'More than 50 years ago, John Tukey avidly promoted an alternative type of data
    analysis that broke from the formal world of confidence intervals, hypothesis
    tests, and modeling. Today Tukey’s [*exploratory data analysis*](https://oreil.ly/Himzi)
    (EDA) is widely practiced. Tukey [describes EDA](https://oreil.ly/UO9F8) as a
    philosophical approach to working with data:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory data analysis is actively incisive, rather than passively descriptive,
    with real emphasis on the discovery of the unexpected.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As a data scientist, you will want to use EDA in every stage of the data lifecycle,
    from checking the quality of your data to preparing for formal modeling to confirming
    that your model is reasonable. Indeed, the work described in [Chapter 9](ch09.html#ch-wrangling)
    to clean and transform the data relied heavily on EDA to guide our quality checks
    and transformations.
  prefs: []
  type: TYPE_NORMAL
- en: In EDA, we enter a process of discovery, continually asking questions and diving
    into uncharted territory to explore ideas. We use plots to uncover features of
    the data, examine distributions of values, and reveal relationships that cannot
    be detected from simple numerical summaries. This exploration involves transforming,
    visualizing, and summarizing data to build and confirm our understanding, identify
    and address potential issues with the data, and inform subsequent analysis.
  prefs: []
  type: TYPE_NORMAL
- en: EDA is fun! But it takes practice. One of the best ways to learn how to carry
    out EDA is to learn from others as they describe their thought process while they
    explore data, and we attempt to reveal EDA thinking in our examples and case studies
    in this book.
  prefs: []
  type: TYPE_NORMAL
- en: EDA can provide valuable insights, but you need to be cautious about the conclusions
    that you draw. It is important to recognize that EDA can bias your analysis. EDA
    is a winnowing process and a decision-making process that can impact the replicability
    of your later, model-based findings. With enough data and if you look hard, you
    often can dredge up something interesting that is entirely spurious.
  prefs: []
  type: TYPE_NORMAL
- en: 'The role of EDA in the scientific reproducibility crisis has been noted, and
    data scientists have cautioned against overdoing it. For example, [Gelman and
    Loken](https://doi.org/10.1511/2014.111.460) note:'
  prefs: []
  type: TYPE_NORMAL
- en: Even in settings where a single analysis has been carried out on the given data,
    the issue of multiple comparisons [data dredging] emerges because different choices
    about combining variables, inclusion and exclusion of cases, transformations of
    variables, tests for interactions in the absence of main effects, and many other
    steps in the analysis could well have occurred with different data.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It’s a good practice to report and provide the code from your EDA so that others
    are aware of the choices you made and the paths you took in learning about your
    data.
  prefs: []
  type: TYPE_NORMAL
- en: The topic of visualization is split across three chapters. In [Chapter 9](ch09.html#ch-wrangling),
    we used plots to inform us in our data wrangling. The plots there were basic and
    the findings straightforward. We didn’t dwell on interpretations and choices of
    plots. In this chapter, we spend more time learning how to choose the right plot
    and interpret it. We usually take the default parameter settings of the plotting
    functions since our goal is to make plots quickly as we carry out EDA. In [Chapter 11](ch11.html#ch-viz),
    we’ll provide guidelines for making effective and informative plots and give advice
    on how to make our visual argument clear and compelling.
  prefs: []
  type: TYPE_NORMAL
- en: 'According to [Tukey](https://oreil.ly/AIWW5), visualization is central to EDA:'
  prefs: []
  type: TYPE_NORMAL
- en: The greatest gains from data come from surprises… The unexpected is best brought
    to our attention by pictures.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To make these pictures, we need to choose an appropriate type of plot, and our
    choice depends on the kinds of data that have been collected. This mapping between
    feature type and plot choice is the topic of the next section. From there, we
    go on to describe how to “read” a plot, what to look for, and how to interpret
    what you see. We first discuss what to look for in a one-feature plot, then focus
    on reading relationships between two features, and finally describe plots for
    three or more features. After we have introduced the visualization tools for EDA,
    we provide guidelines for carrying out an EDA and then walk through an example
    as we follow these guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: Feature Types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before making an exploratory plot, or any plot for that matter, it’s a good
    idea to examine the feature (or features) and decide on its *feature type*. (Sometimes
    we refer to a feature as a *variable* and its type as *variable type*.) Although
    there are multiple ways of categorizing feature types, in this book we consider
    three basic ones. Ordinal and nominal data are subtypes of *categorical* data.
    Another name for categorical data is *qualitative*. In contrast, we also have
    *quantitative* features:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Nominal*'
  prefs: []
  type: TYPE_NORMAL
- en: A feature that represents “named” categories, where the categories do not have
    a natural ordering, is called nominal. Examples include political party affiliation
    (Democrat, Republican, Green, other); dog type (herding, hound, non-sporting,
    sporting, terrier, toy, working); and computer operating system (Windows, macOS,
    Linux).
  prefs: []
  type: TYPE_NORMAL
- en: '*Ordinal*'
  prefs: []
  type: TYPE_NORMAL
- en: Measurements that represent ordered categories are called ordinal. Examples
    of ordinal features are T-shirt size (small, medium, large), Likert-scale response
    (disagree, neutral, agree), and level of education (high school, college, graduate
    school). It is important to note that with an ordinal feature, the difference
    between, say, small and medium need not be the same as the difference between
    medium and large. Also, the differences between consecutive categories may not
    even be quantifiable. Think of the number of stars in a restaurant review and
    what one star means in comparison to two stars.
  prefs: []
  type: TYPE_NORMAL
- en: '*Quantitative*'
  prefs: []
  type: TYPE_NORMAL
- en: Data that represent numeric measurements or quantities are called quantitative.
    Examples include height measured to the nearest cm, price reported in USD, and
    distance measured to the nearest km. Quantitative features can be further divided
    into *discrete*, meaning that only a few values of the feature are possible, and
    *continuous*, meaning that the quantity could in principle be measured to arbitrary
    precision. The number of siblings in a family takes on a discrete set of values
    (such as 0, 1, 2, …, 8). In contrast, height can theoretically be reported to
    any number of decimal places, so we consider it continuous. There is no hard and
    fast rule to determine whether a quantity is discrete or continuous. In some cases,
    it can be a judgment call, and in others, we may want to purposefully consider
    a continuous feature to be discrete.
  prefs: []
  type: TYPE_NORMAL
- en: A feature type is not the same thing as a data storage type. Each column in
    a `pandas` `DataFrame` has its own *storage type*. These types can be integer,
    floating point, boolean, date-time format, category, and object (strings of varying
    length are stored as objects in Python with pointers to the strings). We use the
    term *feature type* to refer to a conceptual notion of the information and the
    term *storage type* to refer to the representation of the information in the computer.
  prefs: []
  type: TYPE_NORMAL
- en: A feature stored as an integer can represent nominal data, strings can be quantitative
    (like `"\$100.00"`), and, in practice, boolean values often represent nominal
    features that have only two possible values.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '`pandas` calls the storage type `dtype`, which is short for data type. We refrain
    from using the term *data type* here because it can be confused with both storage
    type and feature type.'
  prefs: []
  type: TYPE_NORMAL
- en: In order to determine a feature type, we often need to consult a dataset’s *data
    dictionary* or *codebook*. A data dictionary is a document included with the data
    that describes what each column in the data table represents. In the following
    example, we take a look at the storage and feature types of the columns in a dataframe
    about various dog breeds, and we find that the storage type is often not a good
    indicator of the kind of information contained in a field.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Dog Breeds'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We use the [American Kennel Club (AKC)](https://www.akc.org) data on registered
    dog breeds to introduce the various concepts related to EDA. The AKC, a nonprofit
    that was founded in 1884, has the stated mission to “advance the study, breeding,
    exhibiting, running and maintenance of purebred dogs.” The AKC organizes events
    like the National Championship, Agility Invitational, and Obedience Classic, and
    mixed-breed dogs are welcome to participate in most events. The [Information Is
    Beautiful](https://informationisbeautiful.net) website provides a dataset with
    information from the AKC on 172 breeds. Its visualization, [Best in Show](https://oreil.ly/amksD),
    incorporates many features of the breeds and is fun to look at.
  prefs: []
  type: TYPE_NORMAL
- en: 'The AKC dataset contains several different kinds of features, and we have extracted
    a handful of them that show a variety of types of information. These features
    include the name of the breed; its longevity, weight, and height; and other information
    such as its suitability for children and the number of repetitions needed to learn
    a new trick. Each record in the dataset is a breed of dog, and the information
    provided is meant to be typical of that breed. Let’s read the data into a dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '|   | breed | group | score | longevity | ... | size | weight | height | repetition
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | Border Collie | herding | 3.64 | 12.52 | ... | medium | NaN | 51.0
    | <5 |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | Border Terrier | terrier | 3.61 | 14.00 | ... | small | 6.0 | NaN
    | 15-25 |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | Brittany | sporting | 3.54 | 12.92 | ... | medium | 16.0 | 48.0 |
    5-15 |'
  prefs: []
  type: TYPE_TB
- en: '| **...** | ... | ... | ... | ... | ... | ... | ... | ... | ... |'
  prefs: []
  type: TYPE_TB
- en: '| **169** | Wire Fox Terrier | terrier | NaN | 13.17 | ... | small | 8.0 |
    38.0 | 25-40 |'
  prefs: []
  type: TYPE_TB
- en: '| **170** | Wirehaired Pointing Griffon | sporting | NaN | 8.80 | ... | medium
    | NaN | 56.0 | 25-40 |'
  prefs: []
  type: TYPE_TB
- en: '| **171** | Xoloitzcuintli | non-sporting | NaN | NaN | ... | medium | NaN
    | 42.0 | NaN |'
  prefs: []
  type: TYPE_TB
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'A cursory glance at the table shows us that breed, group, and size appear to
    be strings, and the other columns are numbers. The summary of the dataframe, shown
    here, provides the index, name, count of non-null values, and `dtype` for each
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Several columns of this dataframe have a numeric computational type, as signified
    by `float64`, which means that the column can contain numbers other than integers.
    We also confirm that `pandas` encodes the string columns as the `object` `dtype`,
    rather than a `string` `dtype`. Notice that we guessed incorrectly that `repetition`
    is quantitative. Looking a bit more carefully at the data table, we see that `repetition`
    contains string values for ranges, such as `"<5"`, `"15-25"`, and `"25-40"`, so
    this feature is ordinal.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In computer architecture, a floating-point number, or “float” for short, refers
    to a number that can have a decimal component. We won’t go in depth into computer
    architecture in this book, but we will point it out when it affects terminology,
    as in this case. The `dtype` `float64` says that the column contains decimal numbers
    that each take up 64 bits of space when stored in computer memory.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, `pandas` uses optimized storage types for numeric data, like `float64`
    or `int64`. However, it doesn’t have optimizations for Python objects like strings,
    dictionaries, or sets, so these are all stored as the `object` `dtype`. This means
    that the storage type is ambiguous, but in most settings we know whether `object`
    columns contain strings or some other Python type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at the column storage types, we might guess `ailments` and `children`
    are quantitative features because they are stored as `float64` `dtype`s. But let’s
    tally their unique values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Both `ailments` and `children` only take on a few integer values. What does
    a value of `3.0` for `children` or `9.0` for `ailments` mean? We need more information
    to figure this out. The name of the column and how the information is stored in
    the dataframe is not enough. Instead, we consult  the data dictionary shown in
    [Table 10-1](#akc-codebook).
  prefs: []
  type: TYPE_NORMAL
- en: Table 10-1\. AKC dog breed codebook
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `breed` | Dog breed, e.g., Border Collie, Dalmatian, Vizsla |'
  prefs: []
  type: TYPE_TB
- en: '| `group` | American Kennel Club grouping (herding, hound, non-sporting, sporting,
    terrier, toy, working) |'
  prefs: []
  type: TYPE_TB
- en: '| `score` | AKC score |'
  prefs: []
  type: TYPE_TB
- en: '| `longevity` | Typical lifetime (years) |'
  prefs: []
  type: TYPE_TB
- en: '| `ailments` | Number of serious genetic ailments |'
  prefs: []
  type: TYPE_TB
- en: '| `purchase_price` | Average purchase price from [puppyfind.com](http://puppyfind.com)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `grooming` | Grooming required once every: 1 = day, 2 = week, 3 = few weeks
    |'
  prefs: []
  type: TYPE_TB
- en: '| `children` | Suitability for children: 1 = high, 2 = medium, 3 = low |'
  prefs: []
  type: TYPE_TB
- en: '| `size` | Size: small, medium, large |'
  prefs: []
  type: TYPE_TB
- en: '| `weight` | Typical weight (kg) |'
  prefs: []
  type: TYPE_TB
- en: '| `height` | Typical height from the shoulder (cm) |'
  prefs: []
  type: TYPE_TB
- en: '| `repetition` | Number of repetitions to understand a new command: <5, 5–15,
    15–25, 25–40, 40–80, >80 |'
  prefs: []
  type: TYPE_TB
- en: Although the data dictionary does not explicitly specify the feature types,
    the description is enough for us to figure out that the feature `children` represents
    the suitability of the breed for children, and a value of `1.0` corresponds to
    “high” suitability. We also find that the feature `ailments` is a count of the
    number of serious genetic ailments that dogs of this breed tend to have. Based
    on the codebook, we treat `children` as a categorical feature, even though it
    is stored as a floating-point number, and since low < medium < high, the feature
    is ordinal. Since `ailments` is a count, we treat it as a quantitative (numeric)
    type, and for some analyses we further define it as discrete because there are
    only a few possible values that `ailments` can take on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The codebook also confirms that the features `score`, `longevity`, `purchase_price`,
    `weight`, and `height` are quantitative. The idea here is that numeric features
    have values that can be compared through differences. It makes sense to say that
    chihuahuas typically live about four years longer than dachshunds (16.5 versus
    12.6 years). Another check is whether it makes sense to compare ratios of values:
    a dachshund is usually about five times heavier than a chihuahua (11 kg versus
    2 kg). All of these quantitative features are continuous; only `ailments` is discrete.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The data dictionary descriptions for `breed`, `group`, `size`, and `repetition`
    suggest that these features are qualitative. Each variable has different, and
    yet commonly found, characteristics that are worth exploring a bit more. We do
    this by examining the counts of each unique value for the various features. We
    begin with `breed`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `breed` feature has 172 unique values—that’s the same as the number of records
    in the dataframe—so we can think of `breed` as the *primary key* for the data
    table. By design, each dog breed has one record, and this `breed` feature determines
    the dataset’s granularity. Although `breed` is also considered a nominal feature,
    it doesn’t really make sense to analyze it. We do want to confirm that all values
    are unique and clean, but otherwise we would only use it to, say, label unusual
    values in a plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we examine the feature `group`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This feature has seven unique values. Since a dog breed labeled as “sporting”
    and another considered to be “toy” differ from each other in several ways, the
    categories cannot be easily reduced to an ordering. So we consider `group` a nominal
    feature. Nominal features do not provide meaning in even the direction of the
    differences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we examine the unique values and their counts for `size`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The `size` feature has a natural ordering: small < medium < large, so it is
    ordinal. We don’t know how the category “small” is determined, but we do know
    that a small breed is in some sense smaller than a medium-sized breed, which is
    smaller than a large one. We have an ordering, but differences and ratios don’t
    make sense conceptually for this feature.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `repetition` feature is an example of a quantitative variable that has
    been collapsed into categories to become ordinal. The codebook tells us that `repetition`
    is the number of times a new command needs to be repeated before the dog understands
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The numeric values have been lumped together as `<5`, `5-15`, `15-25`, `25-40`,
    `40-80`, `80-100`, and notice that these categories have different widths. The
    first has 5 repetitions, while others are 10, 15, and 40 repetitions wide. The
    ordering is clear, but the gaps from one category to the next are not of the same
    magnitude.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have double-checked the values in the variables against the descriptions
    in the codebook, we can augment the data dictionary to include this additional
    information about the feature types. Our revised dictionary appears in [Table 10-2](#revised-akc-codebook).
  prefs: []
  type: TYPE_NORMAL
- en: Table 10-2\. Revised AKC dog breed codebook
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature | Description | Feature type | Storage type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `breed` | Dog breed, e.g., Border Collie, Dalmatian, Vizsla | primary key
    | string |'
  prefs: []
  type: TYPE_TB
- en: '| `group` | AKC group (herding, hound, non-sporting, sporting, terrier, toy,
    working) | qualitative - nominal | string |'
  prefs: []
  type: TYPE_TB
- en: '| score | AKC `score` | quantitative | floating point |'
  prefs: []
  type: TYPE_TB
- en: '| `longevity` | Typical lifetime (years) | quantitative | floating point |'
  prefs: []
  type: TYPE_TB
- en: '| `ailments` | Number of serious genetic ailments (0, 1, …, 9) | quantitative
    - discrete | floating point |'
  prefs: []
  type: TYPE_TB
- en: '| `purchase_price` | Average purchase price from [puppyfind.com](http://puppyfind.com)
    | quantitative | floating point |'
  prefs: []
  type: TYPE_TB
- en: '| `grooming` | Groom once every: 1 = day, 2 = week, 3 = few weeks | qualitative
    - ordinal | floating point |'
  prefs: []
  type: TYPE_TB
- en: '| `children` | Suitability for children: 1 = high, 2 = medium, 3 = low | qualitative
    - ordinal | floating point |'
  prefs: []
  type: TYPE_TB
- en: '| `size` | Size: small, medium, large | qualitative - ordinal | string |'
  prefs: []
  type: TYPE_TB
- en: '| `weight` | Typical weight (kg) | quantitative | floating point |'
  prefs: []
  type: TYPE_TB
- en: '| `height` | Typical height from the shoulder (cm) | quantitative | floating
    point |'
  prefs: []
  type: TYPE_TB
- en: '| `repetition` | Number of repetitions to understand a new command: <5, 5–15,
    15–25, 25–40, 40–80, 80–100 | qualitative - ordinal | string |'
  prefs: []
  type: TYPE_TB
- en: This sharper understanding of the feature types of the AKC data helps us make
    quality checks and transformations. We discussed transformations in [Chapter 9](ch09.html#ch-wrangling),
    but there are a few additional transformations that were not covered. These pertain
    to categories of qualitative features, and we describe them next.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming Qualitative Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Whether a feature is nominal or ordinal, we may find it useful to relabel categories
    so that they are more informative, collapse categories to simplify a visualization,
    and even convert a numeric feature to ordinal to focus on particular transition
    points. We explain when we may want to make each of these transformations and
    give examples.
  prefs: []
  type: TYPE_NORMAL
- en: Relabel categories
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Summary statistics, like the mean and the median, make sense for quantitative
    data, but typically not for qualitative data. For example, the average price for
    toy breeds makes sense to calculate ($687), but the “average” breed suitability
    for children doesn’t. However, `pandas` will happily compute the mean of the values
    in the `children` column if we ask it to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Instead, we want to consider the distribution of 1s, 2s, and 3s of `children`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The key difference between storage types and feature types is that storage types
    say what operations we can write code to *compute*, while feature types say what
    operations *make sense for the data*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can transform `children` by replacing the numbers with their string descriptions.
    Changing 1, 2, and 3 into high, medium, and low makes it easier to recognize that
    `children` is categorical. With strings, we would not be tempted to compute a
    mean, the categories would be connected to their meaning, and labels for plots
    would have reasonable values by default. For example, let’s focus on just the
    toy breeds and make a bar plot of suitability for children. First, we create a
    new column with the categories of suitability as strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '|   | breed | group | score | longevity | ... | weight | height | repetition
    | kids |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | Border Collie | herding | 3.64 | 12.52 | ... | NaN | 51.0 | <5 |
    low |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | Border Terrier | terrier | 3.61 | 14.00 | ... | 6.0 | NaN | 15-25
    | high |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | Brittany | sporting | 3.54 | 12.92 | ... | 16.0 | 48.0 | 5-15 | medium
    |'
  prefs: []
  type: TYPE_TB
- en: '| **...** | ... | ... | ... | ... | ... | ... | ... | ... | ... |'
  prefs: []
  type: TYPE_TB
- en: '| **169** | Wire Fox Terrier | terrier | NaN | 13.17 | ... | 8.0 | 38.0 | 25-40
    | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| **170** | Wirehaired Pointing Griffon | sporting | NaN | 8.80 | ... | NaN
    | 56.0 | 25-40 | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| **171** | Xoloitzcuintli | non-sporting | NaN | NaN | ... | NaN | 42.0 |
    NaN | NaN |'
  prefs: []
  type: TYPE_TB
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can make the bar plot of counts of each category of suitability among
    the toy breeds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in01.png)'
  prefs: []
  type: TYPE_IMG
- en: We do not always want to have categorical data represented by strings. Strings
    generally take up more space to store, which can greatly increase the size of
    a dataset if it contains many categorical features.
  prefs: []
  type: TYPE_NORMAL
- en: At times, a qualitative feature has many categories and we prefer a higher-level
    view of the data, so we collapse categories.
  prefs: []
  type: TYPE_NORMAL
- en: Collapse categories
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s create a new column, called `play`, to represent the groups of dogs whose
    “purpose” is to play (or not). (This is a fictitious distinction used for demonstration
    purposes.) This category consists of the toy and non-sporting breeds. The new
    feature, `play`, is a transformation of the feature `group` that collapses categories:
    toy and non-sporting are combined into one category, and the remaining categories
    are placed in a second, non-play category. The boolean (`bool`) storage type is
    useful to indicate the presence or absence of this characteristic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Representing a two-category qualitative feature as a boolean has a few advantages.
    For example, the mean of `play` makes sense because it returns the fraction of
    `True` values. When booleans are used for numeric calculations, `True` becomes
    1 and `False` becomes 0:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This storage type gives us a shortcut to compute counts and averages of boolean
    values. In [Chapter 15](ch15.html#ch-linear), we’ll see that it’s also a handy
    encoding for modeling.
  prefs: []
  type: TYPE_NORMAL
- en: There are also times, like when a discrete quantitative feature has a long tail,
    that we want to truncate the higher values, which turns the quantitative feature
    into an ordinal. We describe this next.
  prefs: []
  type: TYPE_NORMAL
- en: Convert quantitative to ordinal
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, another transformation that we sometimes find useful is to convert
    numeric values into categories. For example, we might collapse the values in `ailments`
    into categories: 0, 1, 2, 3, 4+. In other words, we turn `ailments` from a quantitative
    feature into an ordinal feature with the mapping 0→0, 1→1, 2→2, 3→3, and any value
    4 or larger→4+. We might want to make this transformation because few breeds have
    more than three genetic ailments. This simplification can be clearer and adequate
    for an investigation.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As of this writing (late 2022), `pandas` also implements a `category` `dtype`
    that is designed to work with qualitative data. However, this storage type is
    not yet widely adopted by the visualization and modeling libraries, which limits
    its usefulness. For that reason, we do not transform our qualitative variables
    into the `category` `dtype`. We expect that future readers may want to use the
    `category` `dtype` as more libraries support it.
  prefs: []
  type: TYPE_NORMAL
- en: When we convert a quantitative feature to ordinal, we lose information. We can’t
    go back. That is, if we know the number of ailments for a breed is four or more,
    we can’t re-create the actual numeric value. The same thing happens when we collapse
    categories. For this reason, it’s a good practice to keep the original feature.
    If we need to check our work or change categories, we can document and re-create
    our steps.
  prefs: []
  type: TYPE_NORMAL
- en: In general, the feature type helps us figure out what kind of plot is most appropriate.
    We discuss the mapping between feature type and plots next.
  prefs: []
  type: TYPE_NORMAL
- en: The Importance of Feature Types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Feature types guide us in our data analysis. They help specify the operations,
    visualizations, and models we can meaningfully apply to the data. [Table 10-3](#feature-plot)
    matches the feature type(s) to the various kinds of plots that are typically good
    options. Whether the variable(s) are quantitative or qualitative generally determines
    the set of viable plots to make, although there are exceptions. Other factors
    that enter into the decision are the number of observations and whether the feature
    takes on only a few distinct values. For example, we might make a bar chart, rather
    than a histogram, for a discrete quantitative variable.
  prefs: []
  type: TYPE_NORMAL
- en: Table 10-3\. Mapping feature types to plots
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature type | Dimension | Plot |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Quantitative | One feature | Rug plot, histogram, density curve, box plot,
    violin plot |'
  prefs: []
  type: TYPE_TB
- en: '| Qualitative | One feature | Bar plot, dot plot, line plot, pie chart |'
  prefs: []
  type: TYPE_TB
- en: '| Quantitative | Two features | Scatterplot, smooth curve, contour plot, heat
    map, quantile-quantile plot |'
  prefs: []
  type: TYPE_TB
- en: '| Qualitative | Two features | Side-by-side bar plots, mosaic plot, overlaid
    lines |'
  prefs: []
  type: TYPE_TB
- en: '| Mixed | Two features | Overlaid density curves, side-by-side box plots, overlaid
    smooth curves, quantile-quantile plot |'
  prefs: []
  type: TYPE_TB
- en: The feature type also helps us decide the kind of summary statistics to calculate.
    With qualitative data, we usually don’t compute means or standard deviations,
    and instead compute the count, fraction, or percentage of records in each category.
    With a quantitative feature, we compute the mean or median as a measure of center,
    and, respectively, the standard deviation or inner quartile range (75th percentile
    to 25th percentile) as a measure of spread. In addition to the quartiles, we may
    find other percentiles informative.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The *n*th percentile is that value *q* such that *n% of the data values fall
    at or below it.* The value *q* might not be unique, and there are several approaches
    to select a unique value from the possibilities. With enough data, there should
    be little difference between these definitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'To compute percentiles in Python, we prefer using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: When exploring data, we need to know how to interpret the shapes that our plots
    reveal. The next three sections give guidance with this interpretation. We also
    introduce many of the types of plots listed in [Table 10-3](#feature-plot) through
    the examples. Others are introduced in [Chapter 11](ch11.html#ch-viz).
  prefs: []
  type: TYPE_NORMAL
- en: What to Look For in a Distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Visual displays of a feature can help us see patterns in observations; they
    are often much better than direct examination of the numbers or strings themselves.
    The simple rug plot locates each observation as a “yarn” in a “rug” along an axis.
    The rug plot can be useful when we have a handful of observations, but it soon
    gets difficult to distinguish high-density (most-populated) regions with, say,
    even 100 values. The following figure shows a rug plot with about 150 longevity
    values for dog breeds along the top of a histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Although we can see an unusually large value that’s greater than 16 in the
    rug plot, it’s hard to compare the density of yarns in the other regions. Instead,
    the histogram gives a much better sense of the density of observations for various
    longevity values. Similarly, the *density curve* shown in the following figure
    gives a picture of the regions of high and low density:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_10in03.png)'
  prefs: []
  type: TYPE_IMG
- en: In both the histogram and density curve, we can see that the distribution of
    longevity is asymmetric. There is one main mode around 12 years and a shoulder
    in the 9-to-11-year range, meaning that while 12 is the most common longevity,
    many breeds have a longevity one to three years shorter than 12\. We also see
    a small secondary mode around 7, and a few breeds with longevity as long as 14
    to 16 years.
  prefs: []
  type: TYPE_NORMAL
- en: When interpreting a histogram or density curve, we examine the symmetry and
    skewness of the distribution; the number, location, and size of high-frequency
    regions (modes); the length of tails (often in comparison to a bell-shaped curve);
    gaps where no values are observed; and unusually large or anomalous values. [Figure 10-1](#example-density-plot)
    provides a characterization of a distribution with several of these features.
    When we read a distribution, we connect the features that we see in the plot to
    the quantity measured.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_1001.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-1\. Example density plot identifying qualities of a distribution based
    on its shape
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As another example, the distribution of the number of ailments in dog breeds
    appears in the following histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in04.png)'
  prefs: []
  type: TYPE_IMG
- en: A value of 0 means this breed has no genetic ailments, 1 corresponds to one
    genetic ailment, and so on. From the histogram, we see that the distribution of
    ailments is unimodal with a peak at 0\. We also see that the distribution is heavily
    skewed to the right, with a long right tail indicating that few breeds have between
    four and nine genetic ailments. Although quantitative, ailments is discrete because
    only a few integer values are possible. For this reason, we centered the bins
    on the integers so that the bin from 1.5 to 2.5 contains only those breeds with
    two ailments. We also made the rightmost bin wider. We lumped into one bin all
    of the breeds with four to nine ailments. When bin counts are small, we use wider
    bins to further smooth the distribution because we do not want to read too much
    into the fluctuations of small numbers. In this case, none of the breeds have
    six or seven ailments, but some have four, five, eight, or nine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we point out three key aspects of histograms and density curves: the
    y-axis should be on a density scale, smoothing hides unimportant details, and
    histograms are fundamentally different from bar plots. We describe each in turn:'
  prefs: []
  type: TYPE_NORMAL
- en: Density in the y-axis
  prefs: []
  type: TYPE_NORMAL
- en: 'The y-axes in the histograms of longevity and ailments are both labeled “density.”
    This label implies that the total area of the bars in the histogram equals 1\.
    To explain, we can think of the histogram as a skyline with tall buildings having
    denser populations, and we find the fraction of observations in any bin from the
    area of the rectangle. For example, the rectangle that runs from 3.5 to 9.5 in
    the ailments histogram contains about 10% of the breeds: 6 (width) × 0.017 (height)
    is roughly 0.10\. If all of the bins are the same width, then the “skyline” will
    look the same whether the y-axis represents counts or density. But changing the
    y-axis to counts in this histogram would give a misleading picture of a very large
    rectangle in the right tail.'
  prefs: []
  type: TYPE_NORMAL
- en: Smoothing
  prefs: []
  type: TYPE_NORMAL
- en: With a histogram we hide the details of individual yarns in a rug plot in order
    to view the general features of the distribution. Smoothing refers to this process
    of replacing sets of points with rectangles; we choose not to show every single
    point in the dataset in order to reveal broader trends. We might want to smooth
    out these points because this is a sample and we believe that other values near
    the ones we observed are reasonable, and/or we want to focus on general structure
    rather than individual observations. Without the rug, we can’t tell where the
    points are in a bin. Smooth density curves, like the one we showed earlier for
    longevity, also have the property that the total area under the curve sums to
    1\. The density curve uses a smooth *kernel* function to spread out the individual
    yarns and is sometimes referred to as a *kernel density estimate* (KDE).
  prefs: []
  type: TYPE_NORMAL
- en: Bar plot ≠ histogram
  prefs: []
  type: TYPE_NORMAL
- en: 'With qualitative data, the bar plot serves a similar role to the histogram.
    The bar plot gives a visual presentation of the “popularity” or frequency of different
    groups. However, we cannot interpret the shape of the bar plot in the same way
    as a histogram. Tails and symmetry do not make sense in this setting. Also, the
    frequency of a category is represented by the height of the bar, and the width
    carries no information. The two bar charts that follow display identical information
    about the number of breeds in a category; the only difference is in the width
    of the bars. In the extreme, the rightmost plot eliminates the bars entirely and
    represents each count by a single dot. (Without the connecting lines, this figure
    is called a *dot plot*.) Reading this line plot, we see that only a few breeds
    are unsuitable for children:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in05.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we have covered how to examine distributions of single features, we
    turn to the situation when we want to look at two features and how they relate.
  prefs: []
  type: TYPE_NORMAL
- en: What to Look For in a Relationship
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we investigate  multiple variables, we examine the relationships between
    them, in addition to their distributions. In this section, we consider pairs of
    features and describe what to look for. [Table 10-3](#feature-plot) provides guidelines
    for the type of plot to make based on the feature types. For two features, the
    combination of types (both quantitative, both qualitative, or a mix) matters.
    We consider each combination in turn.
  prefs: []
  type: TYPE_NORMAL
- en: Two Quantitative Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If both features are quantitative, then we often examine their relationship
    with a scatterplot. Each point in a scatterplot marks the position of a pair of
    values for an observation. So we can think of a scatterplot as a two-dimensional
    rug plot.
  prefs: []
  type: TYPE_NORMAL
- en: With scatter plots, we look for linear and simple nonlinear relationships, and
    we examine the strength of the relationships. We also look to see if a transformation
    of one or the other or both features leads to a linear relationship.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following scatterplot displays the weight and height of dog breeds (both
    are quantitative):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We observe that dogs that are above average in height tend to be above average
    in weight. This relationship appears nonlinear: the change in weight for taller
    dogs grows faster than for shorter dogs. Indeed, that makes sense if we think
    of a dog as basically shaped like a box: for similarly proportioned boxes, the
    weight of the contents of the box has a cubic relationship to its length.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that two univariate plots are missing information found
    in a bivariate plot—information about how the two features vary together. Practically,
    histograms for two quantitative features do not contain enough information to
    create a scatterplot of the features. We must exercise caution and not read too
    much into a pair of univariate plots. Instead, we need to use one of the plots
    listed in the appropriate row of [Table 10-3](#feature-plot) (scatterplot, smooth
    curve, contour plot, heat map, quantile–quantile plot) to get a sense of the relationship
    between two quantitative features.
  prefs: []
  type: TYPE_NORMAL
- en: When one feature is numeric and the other qualitative, [Table 10-3](#feature-plot)
    makes different recommendations. We describe them next.
  prefs: []
  type: TYPE_NORMAL
- en: One Qualitative and One Quantitative Variable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To examine the relationship between a quantitative and a qualitative feature,
    we often use the qualitative feature to divide the data into groups and compare
    the distribution of the quantitative feature across these groups. For example,
    we can compare the distribution of height for small, medium, and large dog breeds
    with three overlaid density curves:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_10in07.png)'
  prefs: []
  type: TYPE_IMG
- en: We see that the distribution of height for the small and medium breeds both
    appear bimodal, with the left mode the larger in each group. Also, the small and
    medium groups have a larger spread in height than the large group of breeds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Side-by-side box plots offer a similar comparison of distributions across groups.
    The box plot offers a simpler approach that can give a crude understanding of
    a distribution. Likewise, violin plots sketch density curves along an axis for
    each group. The curve is flipped to create a symmetric “violin” shape. The violin
    plot aims to bridge the gap between the density curve and box plot. We create
    box plots (left) and violin plots (right) for the height of breeds given the size
    labeling:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_10in08.png)'
  prefs: []
  type: TYPE_IMG
- en: The three box plots of height, one for each size of dog, make it clear that
    the size categorization is based on height because there is almost no overlap
    in height ranges for the groups. (This was not evident in the density curves due
    to the smoothing.) What we don’t see in these box plots is the bimodality in the
    small and medium groups, but we can still see that the large dogs have a narrower
    spread compared to the other two groups.
  prefs: []
  type: TYPE_NORMAL
- en: Box plots (also known as box-and-whisker plots) give a visual summary of a few
    important statistics of a distribution. The box denotes the 25th percentile, median,
    and 75th percentile, the whiskers show the tails, and unusually large or small
    values are also plotted. Box plots cannot reveal as much shape as a histogram
    or density curve. They primarily show symmetry and skew, long/short tails, and
    unusually large/small values (also known as *outliers*).
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 10-2](#box-plot) is a visual explanation of the parts of a box plot.
    Asymmetry is evident from the median not being in the middle of the box, the sizes
    of the tails are shown by the length of the whiskers, and outliers are shown by
    the points that appear beyond the whiskers. The maximum is considered an outlier
    because it appears beyond the whisker on the right.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_1002.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-2\. Diagram of a box plot with the summary statistics labeled
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When we examine the relationship between two qualitative features, our focus
    is on proportions, as we explain next.
  prefs: []
  type: TYPE_NORMAL
- en: Two Qualitative Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With two qualitative features, we often compare the distribution of one feature
    across subgroups defined by the other feature. In effect, we hold one feature
    constant and plot the distribution of the other one. To do this, we can use some
    of the same plots we used to display the distribution of one qualitative feature,
    such as a line plot or bar plot. As an example, let’s examine the relationship
    between the suitability of a breed for children and the size of the breed.
  prefs: []
  type: TYPE_NORMAL
- en: 'To examine the relationship between these two qualitative features, we calculate
    three sets of proportions (one each for low, medium, and high suitability). Within
    each suitability category, we find the proportion of small, medium, and large
    dogs. These proportions are displayed in the following table. Notice that each
    column sums to 1 (equivalent to 100%):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '| kids | high | medium | low |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| size |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **large** | 0.37 | 0.29 | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| **medium** | 0.36 | 0.34 | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| **small** | 0.27 | 0.37 | 0.7 |'
  prefs: []
  type: TYPE_TB
- en: 'The line plot that follows provides a visualization of these proportions. There
    is one “line” (set of connected dots) for each suitability level. The connected
    dots give the breakdown of size within a suitability category. We see that breeds
    with low suitability for kids are primarily small:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also present these proportions as a collection of side-by-side bar plots,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in10.png)'
  prefs: []
  type: TYPE_IMG
- en: So far, we’ve covered visualizations that incorporate one or two features. In
    the next section, we discuss visualizations that incorporate more than two features.
  prefs: []
  type: TYPE_NORMAL
- en: Comparisons in Multivariate Settings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we examine a distribution or relationship, we often want to compare it
    across subgroups of the data. This process of conditioning on additional factors
    often leads to visualizations that involve three or more variables. In this section,
    we explain how to read plots that are commonly used to visualize multiple variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let’s compare the relationship between height and longevity
    across repetition categories. First, we collapse repetition (the typical number
    of times it takes for a dog to learn a new command) from six categories into four:
    <15, 15–25, 25–40, and 40+:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now each group has about 30 breeds in it, and having fewer categories makes
    it easier to decipher relationships. These categories are conveyed by differently
    shaped symbols in a scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in11.png)'
  prefs: []
  type: TYPE_IMG
- en: This plot would be challenging to interpret if there were more levels within
    the `repetition` feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Facet plots offer an alternative approach to display these three features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in12.png)'
  prefs: []
  type: TYPE_IMG
- en: Each of the four scatterplots shows the relationship between longevity and height
    for a different range of repetitions. By separating the scatterplots, we can better
    assess how the relationship between two quantitative features changes across the
    subgroups. And we can more easily see the range of height and longevity for each
    repetition range. We can see that the larger breeds tend to have shorter lifespans.
    Another interesting feature is that the lines are similar in slope, but the line
    for the 40+ repetitions sits about 1.5 years below the others. Those breeds tend
    to live about 1.5 years less on average than the other repetition categories,
    no matter the height.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we summarize the various plotting techniques for making comparisons when
    we have three (or more) features:'
  prefs: []
  type: TYPE_NORMAL
- en: Two quantitative and one qualitative
  prefs: []
  type: TYPE_NORMAL
- en: We demonstrated this case already with a scatterplot that varies the markers
    according to the qualitative feature’s categories, or by the panels of scatterplots,
    with one for each category.
  prefs: []
  type: TYPE_NORMAL
- en: Two qualitative and one quantitative feature
  prefs: []
  type: TYPE_NORMAL
- en: We have seen in the collections of box plots of height according to breed size
    that we can compare the basic shape of a distribution across subgroups with side-by-side
    box plots. When we have two or more qualitative features, we can organize the
    box plots into groups according to one of the qualitative features.
  prefs: []
  type: TYPE_NORMAL
- en: Three quantitative features
  prefs: []
  type: TYPE_NORMAL
- en: We can use a similar technique when we plot two quantitative features and one
    qualitative. This time, we convert one of the quantitative features into an ordinal
    feature, where each category typically has roughly the same number of records.
    Then we make faceted scatterplots of the other two features. We again look for
    similarities in relationships across the facets.
  prefs: []
  type: TYPE_NORMAL
- en: Three qualitative features
  prefs: []
  type: TYPE_NORMAL
- en: When we examine relationships between qualitative features, we examine proportions
    of one feature within subgroups defined by another. In the previous section, the
    three line plots in one figure and the side-by-side bar plots both display such
    comparisons. With three (or more) qualitative features, we can continue to subdivide
    the data according to the combinations of levels of the features and compare these
    proportions using line plots, dot plots, side-by-side bar charts, and so forth.
    But these plots tend to get increasingly difficult to understand with further
    subdivisions.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It’s a good practice to break down a visualization to see whether a relationship
    changes for subgroups of the data determined by a qualitative feature. This technique
    is called *controlling for* a feature. You might get a surprise when, for example,
    a linear relationship in a scatterplot that has an upward trend reverses to downward
    trends in some or all facets of the scatterplot. This phenomenon is known as *Simpson’s
    paradox*. The paradox can happen with qualitative features as well. A [famous
    case](https://oreil.ly/h9tMw) occurred at Berkeley when the admissions to graduate
    school for men were higher than for women, but when examined within each program
    the rates favored women. The issue was that women were applying in greater numbers
    to programs that had lower admission rates.
  prefs: []
  type: TYPE_NORMAL
- en: Comparisons that involve more than one categorical variable can quickly become
    cumbersome as the number of possible combinations of categories grows. For example,
    there are 3 × 4 = 12 size-repetition combinations (if we had kept the original
    categories for repetitions, we would have 18 combinations). Examining a distribution
    across 12 subgroups can be difficult. Further, we come up against the problem
    of having too few observations in subgroups. Although there are nearly 200 rows
    in the dogs dataframe, half of the size-repetition combinations have 10 or fewer
    observations. (This is compounded by losing an observation when one feature has
    a missing value.) This *curse of dimensionality* also arises when we compare relationships
    with quantitative data. With just three quantitative variables, some of the scatterplots
    in a facet plot can easily have too few observations to confirm the shape of the
    relationship between two variables for the subgroups.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve seen practical examples of visualizations that are commonly used
    in exploratory data analysis, we proceed to discuss some high-level guidelines
    for EDA.
  prefs: []
  type: TYPE_NORMAL
- en: Guidelines for Exploration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this chapter, we have introduced the notion of feature types, seen
    how the feature type can help to figure out what plot to make, and described how
    to read distributions and relationships in a visualization. EDA relies on building
    these skills and flexibly developing your understanding of the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'You saw EDA in action in [Chapter 9](ch09.html#ch-wrangling) when we developed
    checks for data quality and feature transformations to improve their usefulness
    in data analysis. Following are questions to guide you when making plots to explore
    the data:'
  prefs: []
  type: TYPE_NORMAL
- en: How are the values of Feature X distributed?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do Feature X and Feature Y relate to each other?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the distribution of Feature X the same across subgroups defined by Feature
    Z?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there any unusual observations in X? In the combination of (X,Y)? In X for
    a subgroup of Z?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As you answer each of these questions, it is important to tie your answer back
    to the features measured and the context. It is also important to adopt an active,
    inquisitive approach to the investigation. To guide your explorations, ask yourself
    “what next” and “so what” questions, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Do you have reason to expect that one group/observation might be different?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why might your finding about shape matter?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What additional comparison might bring added value to the investigation?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there any potentially important features to create comparisons with/against?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this process, it’s important to step away from the computer at times to mull
    over your work. You may want to read additional literature on the subject or go
    to an expert in the field to discuss your findings. For example, there could be
    good reasons for an unusual observation, and someone in the field can help clear
    up and provide more background.
  prefs: []
  type: TYPE_NORMAL
- en: We put these guidelines into practice with a concrete example of EDA next.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Sale Prices for Houses'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final section, we carry out an exploratory analysis using the questions
    in the previous section to direct our investigations. Although EDA typically begins
    in the data wrangling stage, for demonstration purposes the data we work with
    here have already been partially cleaned so that we can focus on exploring the
    features of interest. Note also that we do not discuss refining the visualizations
    in much detail; that topic is covered in [Chapter 11](ch11.html#ch-viz).
  prefs: []
  type: TYPE_NORMAL
- en: Our data were scraped from the [*San Francisco Chronicle*](https://oreil.ly/tP9Xp)
    (SFChron) website. The data comprise a complete list of homes sold in the area
    from April 2003 to December 2008\. Since we have no plans to generalize our findings
    beyond the time period and the location and we are working with a census, the
    population matches the access frame and the sample consists of the entire population.
  prefs: []
  type: TYPE_NORMAL
- en: As for granularity, each record represents a sale of a home in the SF Bay Area
    during the specified time period. This means that if a home was sold twice during
    this time, then there are two records in the table. And if a home in the Bay Area
    was not up for sale during this time, then it does not appear in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data are in the dataframe `sfh_df`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '|   | city | zip | street | price | br | lsqft | bsqft | timestamp |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | Alameda | 94501.0 | 1001 Post Street | 689000.0 | 4.0 | 4484.0 |
    1982.0 | 2004-08-29 |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | Alameda | 94501.0 | 1001 Santa Clara Avenue | 880000.0 | 7.0 | 5914.0
    | 3866.0 | 2005-11-06 |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | Alameda | 94501.0 | 1001 Shoreline Drive \#102 | 393000.0 | 2.0 |
    39353.0 | 1360.0 | 2003-09-21 |'
  prefs: []
  type: TYPE_TB
- en: '| **...** | ... | ... | ... | ... | ... | ... | ... | ... |'
  prefs: []
  type: TYPE_TB
- en: '| **521488** | Windsor | 95492.0 | 9998 Blasi Drive | 392500.0 | NaN | 3111.0
    | NaN | 2008-02-17 |'
  prefs: []
  type: TYPE_TB
- en: '| **521489** | Windsor | 95492.0 | 9999 Blasi Drive | 414000.0 | NaN | 2915.0
    | NaN | 2008-02-17 |'
  prefs: []
  type: TYPE_TB
- en: '| **521490** | Windsor | 95492.0 | 999 Gemini Drive | 325000.0 | 3.0 | 7841.0
    | 1092.0 | 2003-09-21 |'
  prefs: []
  type: TYPE_TB
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The dataset does not have an accompanying codebook, but we can determine the
    features and their storage types by inspection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Based on the names of the fields, we expect the primary key to consist of some
    combination of city, zip code, street address, and date.
  prefs: []
  type: TYPE_NORMAL
- en: Sale price is our focus, so let’s begin by exploring its distribution. To develop
    your intuition about distributions, make a guess about the shape of the distribution
    before you start reading the next section. Don’t worry about the range of prices,
    just sketch the general shape.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Price
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It seems that a good guess for the shape of the distribution of sale price
    might be highly skewed to the right with a few very expensive houses. The following
    summary statistics confirm this skewness:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '|   | price |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | 22000.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **25** | 410000.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **50** | 555000.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **75** | 744000.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **100** | 20000000.00 |'
  prefs: []
  type: TYPE_TB
- en: 'The median is closer to the lower quartile than the upper quartile. Also, the
    maximum is 40 times the median! We might wonder whether that $20M sale price is
    simply an anomalous value or whether there are many houses that sold at such a
    high price. To find out, we can zoom in on the right tail of the distribution
    and compute a few high percentiles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '|   | price |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **95.00** | 1295000.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **97.00** | 1508000.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **98.00** | 1707000.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **99.00** | 2110000.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **99.50** | 2600000.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **99.90** | 3950000.00 |'
  prefs: []
  type: TYPE_TB
- en: 'We see that 99.9% of the houses sold for under $4M, so the $20M sale is indeed
    a rarity. Let’s examine the histogram of sale prices below $4M:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Even without the top 0.1%, the distribution remains highly skewed to the right,
    with a single mode around $500,000\. Let’s plot the histogram of the log-transformed
    sale price. The logarithm transformation often does a good job at converting a
    right-skewed distribution into one that is more symmetric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in14.png)'
  prefs: []
  type: TYPE_IMG
- en: We see that the distribution of log-transformed sale price is roughly symmetric.
    Now that we have an understanding of the distribution of sale price, let’s consider
    the so-what questions posed in the previous section on EDA guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: What Next?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have a description of the shape of the sale price, but we need to consider
    why the shape matters and look for comparison groups where distributions might
    differ.
  prefs: []
  type: TYPE_NORMAL
- en: Shape matters because models and statistics based on symmetric distributions
    tend to have more robust and stable properties than highly skewed distributions.
    (We address this issue more when we cover linear models in [Chapter 15](ch15.html#ch-linear).)
    For this reason, we primarily work with the log-transformed sale price. And we
    might also choose to limit our analysis to sale prices under $4M since the super-expensive
    houses may behave quite differently.
  prefs: []
  type: TYPE_NORMAL
- en: As for possible comparisons to make, we look to the context. The housing market
    rose rapidly during this time and then the bottom fell out of the market. So the
    distribution of sale price in, say, 2004 might be quite different than in 2008,
    right before the crash. To explore this notion further, we can examine the behavior
    of prices over time. Alternatively, we can fix time, and examine the relationships
    between price and the other features of interest. Both approaches are potentially
    worthwhile.
  prefs: []
  type: TYPE_NORMAL
- en: 'We narrow our focus to one year (in [Chapter 11](ch11.html#ch-viz) we look
    at the time dimension). We reduce the data to sales made in 2004, so rising prices
    should have a limited impact on the distributions and relationships that we examine.
    To limit the influence of the very expensive and large houses, we also restrict
    the dataset to sales below $4M and houses smaller than 12,000 ft². This subset
    still contains large and expensive houses, but not outrageously so. Later, we
    further narrow our exploration to a few cities of interest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '|   | city | zip | street | price | br | lsqft | bsqft | timestamp |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | Alameda | 94501.00 | 1001 Post Street | 689000.00 | 4.00 | 4484.00
    | 1982.00 | 2004-08-29 |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | Alameda | 94501.00 | 1001 Shoreline Drive \#108 | 485000.00 | 2.00
    | 39353.00 | 1360.00 | 2004-09-05 |'
  prefs: []
  type: TYPE_TB
- en: '| **10** | Alameda | 94501.00 | 1001 Shoreline Drive \#306 | 390000.00 | 2.00
    | 39353.00 | 1360.00 | 2004-01-25 |'
  prefs: []
  type: TYPE_TB
- en: '| **...** | ... | ... | ... | ... | ... | ... | ... | ... |'
  prefs: []
  type: TYPE_TB
- en: '| **521467** | Windsor | 95492.00 | 9960 Herb Road | 439000.00 | 3.00 | 9583.00
    | 1626.00 | 2004-04-04 |'
  prefs: []
  type: TYPE_TB
- en: '| **521471** | Windsor | 95492.00 | 9964 Troon Court | 1200000.00 | 3.00 |
    20038.00 | 4281.00 | 2004-10-31 |'
  prefs: []
  type: TYPE_TB
- en: '| **521478** | Windsor | 95492.00 | 9980 Brooks Road | 650000.00 | 3.00 | 45738.00
    | 1200.00 | 2004-10-24 |'
  prefs: []
  type: TYPE_TB
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: For these data, the shape of the distribution of sale price remains the same—price
    is still highly skewed to the right. We continue to work with this subset to address
    the question of whether there are any potentially important features to study
    along with price.
  prefs: []
  type: TYPE_NORMAL
- en: Examining Other Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to the sale price, which is our main focus, a few other features
    that might be important to our investigation are the size of the house, lot (or
    property) size, and number of bedrooms. We explore the distributions of these
    features and their relationship to sale price and to each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the size of the house and the property are likely related to its price,
    it seems reasonable to guess that these features are also skewed to the right,
    so we apply a log transformation to the building size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We compare the distribution of building size on the regular and logged scales:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The distribution is unimodal with a peak at about 1,500 ft², and many houses
    are over 2,500 ft² in size. We have confirmed our intuition: the log-transformed
    building size is nearly symmetric, although it maintains a slight skew. The same
    is the case for the distribution of lot size.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that both house and lot size have skewed distributions, a scatterplot
    of the two should most likely be on log scale too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We compare the plot with and without the log transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_10in16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The scatterplot on the left is in the original units, which makes it difficult
    to discern the relationship because most of the points are crowded into the bottom
    of the plotting region. In contrast, the scatterplot on the right reveals a few
    interesting features: there is a horizontal line along the bottom of the scatterplot,
    where it appears that many houses have the same lot size, no matter the building
    size; and there appears to be a slight positive log–log linear association between
    lot and building size.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at some lower quantiles of lot size to try to figure out this unusual
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '|   | lot_size |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0.50** | 436.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **1.00** | 436.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **1.50** | 436.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **2.00** | 436.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **2.50** | 436.00 |'
  prefs: []
  type: TYPE_TB
- en: '| **3.00** | 782.00 |'
  prefs: []
  type: TYPE_TB
- en: 'We found something interesting: about 2.5% of the houses have a lot size of
    436 ft². This is tiny and makes little sense, so we make a note of the anomaly
    for further investigation.'
  prefs: []
  type: TYPE_NORMAL
- en: Another measure of house size is the number of bedrooms. Since this is a discrete
    quantitative variable, we can treat it as a qualitative feature and make a bar
    plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Houses in the Bay Area tend to be on the smaller side, so we venture to guess
    that the distribution will have a peak at three and skew to the right, with a
    few houses having five or six bedrooms. Let’s check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in17.png)'
  prefs: []
  type: TYPE_IMG
- en: The bar plot confirms that we generally had the right idea. However, we find
    that there are some houses with over 30 bedrooms! That’s a bit hard to believe
    and points to another possible data quality problem. Since the records include
    the addresses of the houses, we can double-check theses values on a real estate
    app.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the meantime, let’s just transform the number of bedrooms into an ordinal
    feature by reassigning all values larger than 8 to 8+, and re-create the bar plot
    with the transformed data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in18.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that even if we lump all of the houses with 8+ bedrooms together,
    they do not amount to many. The distribution is nearly symmetric with a peak at
    3, nearly the same proportion of houses have two or four bedrooms, and nearly
    the same have one or five. There is asymmetry present, with a few houses having
    six or more bedrooms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we examine the relationship between the number of bedrooms and sale price.
    Before we proceed, we save the transformations done thus far:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Now we’re ready to consider relationships between the number of bedrooms and
    other variables.
  prefs: []
  type: TYPE_NORMAL
- en: Delving Deeper into Relationships
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s begin by examining how the distribution of price changes for houses with
    different numbers of bedrooms. We can do this with box plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in19.png)'
  prefs: []
  type: TYPE_IMG
- en: The median sale price increases with the number of bedrooms from one to five,
    but for the largest houses (those with more than six bedrooms), the distribution
    of log-transformed sale price appears nearly the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'We would expect houses with one bedroom to be smaller than houses with, say,
    four bedrooms. We might also guess that houses with six or more bedrooms are similar
    in size and price. To dive deeper, we consider a kind of transformation that divides
    price by building size to give us the price per square foot. We want to check
    if this feature is constant for all houses; in other words, if price is primarily
    determined by size. To do this we look at the relationship between the two pairs
    of size and price, and price per square foot and size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'We create two scatterplots. The one on the left shows price against building
    size (both log-transformed), and the plot on the right shows price per square
    foot (log-transformed) against building size. In addition, each plot has an added
    smooth curve that reflects the local average price or price per square foot for
    buildings of roughly the same size:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_10in20.png)'
  prefs: []
  type: TYPE_IMG
- en: The lefthand plot shows what we expect—larger houses cost more. We also see
    that there is roughly a log–log association between these features.
  prefs: []
  type: TYPE_NORMAL
- en: 'The righthand plot in this figure is interestingly nonlinear. We see that smaller
    houses cost more per square foot than larger ones, and the price per square foot
    for larger houses is relatively flat. This feature appears to be quite interesting,
    so we save the price per square foot transforms into `sfh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: So far we haven’t considered the relationship between prices and location. There
    are house sales from over 150 different cities in this dataset. Some cities have
    a handful of sales and others have thousands. We continue our narrowing down of
    the data and examine relationships for a few cities next.
  prefs: []
  type: TYPE_NORMAL
- en: Fixing Location
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You may have heard the expression: there are three things that matter in real
    estate—*location, location, location.* Comparing prices across cities might bring
    additional insights to our investigation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We examine data for some cities in the San Francisco East Bay: Richmond, El
    Cerrito, Albany, Berkeley, Walnut Creek, Lamorinda (which is a combination of
    Lafayette, Moraga, and Orinda, three neighboring bedroom communities), and Piedmont.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin by comparing the distribution of sale price for these cities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in21.png)'
  prefs: []
  type: TYPE_IMG
- en: The box plots show that Lamorinda and Piedmont tend to have more expensive homes
    and Richmond has the least expensive, but there is overlap in sale price for many
    cities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we examine the relationship between price per square foot and house size
    more closely with faceted scatterplots, one for each of four cities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_10in22.png)'
  prefs: []
  type: TYPE_IMG
- en: The relationship between price per square foot and building size is roughly
    log-linear, with a negative association for each of the four locations. While
    not parallel, it does appear that there is a location boost for houses, regardless
    of size, where, say, a house in Berkeley costs about $250 more per square foot
    than a house in Richmond. We also see that Piedmont and Lamorinda are more expensive
    cities, and in both cities there is not the same reduction in price per square
    foot for larger houses in comparison to smaller ones. These plots support the
    “location, location, location” adage.
  prefs: []
  type: TYPE_NORMAL
- en: In EDA, we often revisit earlier plots to check whether new findings add insights
    to previous visualizations. It is important to continually take stock of our findings
    and use them to guide us in further explorations. Let’s summarize our findings
    so far.
  prefs: []
  type: TYPE_NORMAL
- en: EDA Discoveries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our EDA has uncovered several interesting phenomena. Briefly, some of the most
    notable are:'
  prefs: []
  type: TYPE_NORMAL
- en: Sale price and building size are highly skewed to the right with one mode.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Price per square foot decreases nonlinearly with building size, with smaller
    houses costing more per square foot than larger houses and price per square foot
    being roughly constant for large houses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More desirable locations add a bump in sale price that is roughly the same amount
    for houses of different sizes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many additional explorations we can (and should) perform, and there
    are several checks that we should make. These include investigating the 436 value
    for lot size and cross-checking unusual houses, like the 30-bedroom house and
    the $20M house, with online real estate apps.
  prefs: []
  type: TYPE_NORMAL
- en: We narrowed our investigation down to one year and later to a few cities. This
    narrowing helped us control for features that might interfere with finding simple
    relationships. For example, since the data were collected over several years,
    the date of sale may confound the relationship between sale price and number of
    bedrooms. At other times, we want to consider the effect of time on prices. To
    examine price changes over time, we often make line plots, and we adjust for inflation.
    We revisit these data in [Chapter 11](ch11.html#ch-viz) when we consider data
    scope and look more closely at trends in time.
  prefs: []
  type: TYPE_NORMAL
- en: Despite being brief, this section conveys the basic approach of EDA in action.
    For an extended case study on a different dataset, see [Chapter 12](ch12.html#ch-pa).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced the nominal, ordinal, and numerical feature types
    and their importance for data analysis. When presented with a dataset, we demonstrated
    how to consult the data dictionary and the data itself to determine the feature
    types for each column. We also explained how the storage type is not to be confused
    with feature type. Since much of EDA is carried out with statistical graphs, we
    described how to recognize and interpret the shapes and patterns that emerge and
    how to connect these to the data being plotted. Finally, we provided guidelines
    for how you might conduct an EDA, and provided an example.
  prefs: []
  type: TYPE_NORMAL
- en: One approach that you may find helpful in developing your intuition about distributions
    and relationships of features is to make a guess about what you will see before
    you make the plot. Try to sketch or describe what you think the shape of distribution
    will be, and then make the plot. For example, variables that have a natural lower/upper
    bound on their values tend to have a long tail on the opposite of the bound. The
    distribution of income (bounded below by 0) tends to have a long right tail, and
    exam scores (bounded above by 100) tend to have a long left tail. You can make
    similar guesses for the shape of a relationship. We saw that price and house size
    had nearly a log–log linear relationship. As you gain intuition about shapes,
    it becomes easier to carry out an EDA; you can more easily identify when a plot
    shows a surprising shape.
  prefs: []
  type: TYPE_NORMAL
- en: Our focus in this chapter was on “reading” visualizations. In [Chapter 11](ch11.html#ch-viz),
    we provide style guidelines for how to create informative, effective, and beautiful
    graphs. Many of the ideas in that chapter were followed here, but we have not
    called attention to them.
  prefs: []
  type: TYPE_NORMAL
