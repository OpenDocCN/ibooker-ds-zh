["```py\nfile = \"un-general-debates-blueprint.csv\"\ndf = pd.read_csv(file)\ndf.sample(2)\n\n```", "```py\ndf['length'] = df['text'].str.len()\n\ndf.describe().T\n\n```", "```py\ndf[['country', 'speaker']].describe(include='O').T\n\n```", "```py\ndf.isna().sum()\n\n```", "```py\nsession            0\nyear               0\ncountry            0\ncountry_name       0\nspeaker           27\nposition        3005\ntext               0\nlength             0\ndtype: int64\n\n```", "```py\ndf['speaker'].fillna('unknown', inplace=True)\n\n```", "```py\ndf[df['speaker'].str.contains('Bush')]['speaker'].value_counts()\n\n```", "```py\nGeorge W. Bush        4\nMr. George W. Bush    2\nGeorge Bush           1\nMr. George W Bush     1\nBush                  1\nName: speaker, dtype: int64\n\n```", "```py\ndf['length'].plot(kind='box', vert=False)\n\n```", "```py\ndf['length'].plot(kind='hist', bins=30)\n\n```", "```py\nwhere = df['country'].isin(['USA', 'FRA', 'GBR', 'CHN', 'RUS'])\nsns.catplot(data=df[where], x=\"country\", y=\"length\", kind='box')\nsns.catplot(data=df[where], x=\"country\", y=\"length\", kind='violin')\n\n```", "```py\ndf.groupby('year').size().plot(title=\"Number of Countries\")\n\n```", "```py\ndf.groupby('year').agg({'length': 'mean'}) \\\n  .plot(title=\"Avg. Speech Length\", ylim=(0,30000))\n\n```", "```py\nimport regex as re\n\ndef tokenize(text):\n    return re.findall(r'[\\w-]*\\p{L}[\\w-]*', text)\n\n```", "```py\ntext = \"Let's defeat SARS-CoV-2 together in 2020!\"\ntokens = tokenize(text)\nprint(\"|\".join(tokens))\n\n```", "```py\nLet|s|defeat|SARS-CoV-2|together|in\n\n```", "```py\nimport nltk\n\nstopwords = set(nltk.corpus.stopwords.words('english'))\n\n```", "```py\ndef remove_stop(tokens):\n    return [t for t in tokens if t.lower() not in stopwords]\n\n```", "```py\ninclude_stopwords = {'dear', 'regards', 'must', 'would', 'also'}\nexclude_stopwords = {'against'}\n\nstopwords |= include_stopwords\nstopwords -= exclude_stopwords\n\n```", "```py\npipeline = [str.lower, tokenize, remove_stop]\n\ndef prepare(text, pipeline):\n    tokens = text\n    for transform in pipeline:\n        tokens = transform(tokens)\n    return tokens\n\n```", "```py\ndf['tokens'] = df['text'].apply(prepare, pipeline=pipeline)\n\n```", "```py\ndf['num_tokens'] = df['tokens'].map(len)\n\n```", "```py\nfrom collections import Counter\n\ntokens = tokenize(\"She likes my cats and my cats like my sofa.\")\n\ncounter = Counter(tokens)\nprint(counter)\n\n```", "```py\nCounter({'my': 3, 'cats': 2, 'She': 1, 'likes': 1, 'and': 1, 'like': 1,\n         'sofa': 1})\n\n```", "```py\nmore_tokens = tokenize(\"She likes dogs and cats.\")\ncounter.update(more_tokens)\nprint(counter)\n\n```", "```py\nCounter({'my': 3, 'cats': 3, 'She': 2, 'likes': 2, 'and': 2, 'like': 1,\n         'sofa': 1, 'dogs': 1})\n\n```", "```py\ncounter = Counter()\n\ndf['tokens'].map(counter.update)\n\n```", "```py\nprint(counter.most_common(5))\n\n```", "```py\n[('nations', 124508),\n ('united', 120763),\n ('international', 117223),\n ('world', 89421),\n ('countries', 85734)]\n\n```", "```py\ndef count_words(df, column='tokens', preprocess=None, min_freq=2):\n\n    # process tokens and update counter\n    def update(doc):\n        tokens = doc if preprocess is None else preprocess(doc)\n        counter.update(tokens)\n\n    # create counter and run through all data\n    counter = Counter()\n    df[column].map(update)\n\n    # transform counter into a DataFrame\n    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n    freq_df = freq_df.query('freq >= @min_freq')\n    freq_df.index.name = 'token'\n\n    return freq_df.sort_values('freq', ascending=False)\n\n```", "```py\nfreq_df = count_words(df)\nfreq_df.head(5)\n\n```", "```py\n    count_words(df, column='text',\n                preprocess=lambda text: re.findall(r\"\\w{10,}\", text))\n```", "```py\nax = freq_df.head(15).plot(kind='barh', width=0.95)\nax.invert_yaxis()\nax.set(xlabel='Frequency', ylabel='Token', title='Top Words')\n\n```", "```py\nfrom wordcloud import WordCloud\nfrom matplotlib import pyplot as plt\n\ntext = df.query(\"year==2015 and country=='USA'\")['text'].values[0]\n\nwc = WordCloud(max_words=100, stopwords=stopwords)\nwc.generate(text)\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\n\n```", "```py\ndef wordcloud(word_freq, title=None, max_words=200, stopwords=None):\n\n    wc = WordCloud(width=800, height=400,\n                   background_color= \"black\", colormap=\"Paired\",\n                   max_font_size=150, max_words=max_words)\n\n    # convert DataFrame into dict\n    if type(word_freq) == pd.Series:\n        counter = Counter(word_freq.fillna(0).to_dict())\n    else:\n        counter = word_freq\n\n    # filter stop words in frequency counter\n    if stopwords is not None:\n        counter = {token:freq for (token, freq) in counter.items()\n                              if token not in stopwords}\n    wc.generate_from_frequencies(counter)\n\n    plt.title(title)\n\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis(\"off\")\n\n```", "```py\nfreq_2015_df = count_words(df[df['year']==2015])\nplt.figure()\nwordcloud(freq_2015_df['freq'], max_words=100)\nwordcloud(freq_2015_df['freq'], max_words=100, stopwords=freq_df.head(50).index)\n\n```", "```py\ndef compute_idf(df, column='tokens', preprocess=None, min_df=2):\n\n    def update(doc):\n        tokens = doc if preprocess is None else preprocess(doc)\n        counter.update(set(tokens))\n\n    # count tokens\n    counter = Counter()\n    df[column].map(update)\n\n    # create DataFrame and compute idf\n    idf_df = pd.DataFrame.from_dict(counter, orient='index', columns=['df'])\n    idf_df = idf_df.query('df >= @min_df')\n    idf_df['idf'] = np.log(len(df)/idf_df['df'])+0.1\n    idf_df.index.name = 'token'\n    return idf_df\n\n```", "```py\nidf_df = compute_idf(df)\n\n```", "```py\nfreq_df['tfidf'] = freq_df['freq'] * idf_df['idf']\n\n```", "```py\nfreq_1970 = count_words(df[df['year'] == 1970])\nfreq_2015 = count_words(df[df['year'] == 2015])\n\nfreq_1970['tfidf'] = freq_1970['freq'] * idf_df['idf']\nfreq_2015['tfidf'] = freq_2015['freq'] * idf_df['idf']\n\n#wordcloud(freq_df['freq'], title='All years', subplot=(1,3,1))\nwordcloud(freq_1970['freq'], title='1970 - TF',\n          stopwords=['twenty-fifth', 'twenty-five'])\nwordcloud(freq_2015['freq'], title='2015 - TF',\n          stopwords=['seventieth'])\nwordcloud(freq_1970['tfidf'], title='1970 - TF-IDF',\n          stopwords=['twenty-fifth', 'twenty-five', 'twenty', 'fifth'])\nwordcloud(freq_2015['tfidf'], title='2015 - TF-IDF',\n          stopwords=['seventieth'])\n\n```", "```py\n5 random samples out of 73 contexts for 'sdgs':\n of our planet and its people. The   SDGs   are a tangible manifestation of th\nnd, we are expected to achieve the   SDGs   and to demonstrate dramatic develo\nead by example in implementing the   SDGs   in Bangladesh. Attaching due impor\nthe Sustainable Development Goals (  SDGs  ). We applaud all the Chairs of the\nnew Sustainable Development Goals (  SDGs  ) aspire to that same vision. The A\n\n```", "```py\nfrom textacy.text_utils import KWIC\n\ndef kwic(doc_series, keyword, window=35, print_samples=5):\n\n    def add_kwic(text):\n        kwic_list.extend(KWIC(text, keyword, ignore_case=True,\n                              window_width=window, print_only=False))\n\n    kwic_list = []\n    doc_series.map(add_kwic)\n\n    if print_samples is None or print_samples==0:\n        return kwic_list\n    else:\n        k = min(print_samples, len(kwic_list))\n        print(f\"{k} random samples out of {len(kwic_list)} \" + \\\n              f\"contexts for '{keyword}':\")\n        for sample in random.sample(list(kwic_list), k):\n            print(re.sub(r'[\\n\\t]', ' ', sample[0])+'  '+ \\\n                  sample[1]+'  '+\\\n                  re.sub(r'[\\n\\t]', ' ', sample[2]))\n\n```", "```py\nkwic(df[df['year'] == 2015]['text'], 'sdgs', print_samples=5)\n\n```", "```py\ndef ngrams(tokens, n=2, sep=' '):\n    return [sep.join(ngram) for ngram in zip(*[tokens[i:] for i in range(n)])]\n\ntext = \"the visible manifestation of the global climate change\"\ntokens = tokenize(text)\nprint(\"|\".join(ngrams(tokens, 2)))\n\n```", "```py\nthe visible|visible manifestation|manifestation of|of the|the global|\nglobal climate|climate change\n\n```", "```py\ndef ngrams(tokens, n=2, sep=' ', stopwords=set()):\n    return [sep.join(ngram) for ngram in zip(*[tokens[i:] for i in range(n)])\n            if len([t for t in ngram if t in stopwords])==0]\n\nprint(\"Bigrams:\", \"|\".join(ngrams(tokens, 2, stopwords=stopwords)))\nprint(\"Trigrams:\", \"|\".join(ngrams(tokens, 3, stopwords=stopwords)))\n\n```", "```py\nBigrams: visible manifestation|global climate|climate change\nTrigrams: global climate change\n\n```", "```py\ndf['bigrams'] = df['text'].apply(prepare, pipeline=[str.lower, tokenize]) \\\n                          .apply(ngrams, n=2, stopwords=stopwords)\n\ncount_words(df, 'bigrams').head(5)\n\n```", "```py\n# concatenate existing IDF DataFrame with bigram IDFs\nidf_df = pd.concat([idf_df, compute_idf(df, 'bigrams', min_df=10)])\n\nfreq_df = count_words(df[df['year'] == 2015], 'bigrams')\nfreq_df['tfidf'] = freq_df['freq'] * idf_df['idf']\nwordcloud(freq_df['tfidf'], title='all bigrams', max_words=50)\n\n```", "```py\nwhere = freq_df.index.str.contains('climate')\nwordcloud(freq_df[where]['freq'], title='\"climate\" bigrams', max_words=50)\n\n```", "```py\ndef count_keywords(tokens, keywords):\n    tokens = [t for t in tokens if t in keywords]\n    counter = Counter(tokens)\n    return [counter.get(k, 0) for k in keywords]\n\n```", "```py\nkeywords = ['nuclear', 'terrorism', 'climate', 'freedom']\ntokens = ['nuclear', 'climate', 'climate', 'freedom', 'climate', 'freedom']\n\nprint(count_keywords(tokens, keywords))\n\n```", "```py\n[1, 0, 3, 2]\n\n```", "```py\ndef count_keywords_by(df, by, keywords, column='tokens'):\n\n    freq_matrix = df[column].apply(count_keywords, keywords=keywords)\n    freq_df = pd.DataFrame.from_records(freq_matrix, columns=keywords)\n    freq_df[by] = df[by] # copy the grouping column(s)\n\n    return freq_df.groupby(by=by).sum().sort_values(by)\n\n```", "```py\nfreq_df = count_keywords_by(df, by='year', keywords=keywords)\n\n```", "```py\nfreq_df.plot(kind='line')\n\n```", "```py\nkeywords = ['terrorism', 'terrorist', 'nuclear', 'war', 'oil',\n            'syria', 'syrian', 'refugees', 'migration', 'peacekeeping',\n            'humanitarian', 'climate', 'change', 'sustainable', 'sdgs']\n\nfreq_df = count_keywords_by(df, by='year', keywords=keywords)\n\n# compute relative frequencies based on total number of tokens per year\nfreq_df = freq_df.div(df.groupby('year')['num_tokens'].sum(), axis=0)\n# apply square root as sublinear filter for better contrast\nfreq_df = freq_df.apply(np.sqrt)\n\nsns.heatmap(data=freq_df.T,\n            xticklabels=True, yticklabels=True, cbar=False, cmap=\"Reds\")\n\n```"]