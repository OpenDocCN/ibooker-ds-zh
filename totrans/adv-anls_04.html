<html><head></head><body><section data-pdf-bookmark="Chapter 3. Foundations of Inferential Statistics" data-type="chapter" epub:type="chapter"><div class="chapter" id="foundations-of-inference">&#13;
<h1><span class="label">Chapter 3. </span>Foundations of Inferential Statistics</h1>&#13;
&#13;
&#13;
<p><a data-type="xref" href="ch01.html#foundations-of-eda">Chapter 1</a> provided a framework for exploring a dataset by classifying,&#13;
summarizing, and visualizing variables. Though this is an essential start&#13;
to analytics, we usually don’t want it to end there: we would like to&#13;
know whether what we see in our <a data-primary="descriptive statistics" data-secondary="for sample versus population" data-secondary-sortas="sample versus population" data-type="indexterm" id="ch3_term2"/><a data-primary="population versus sample data" data-type="indexterm" id="ch3_term3"/><a data-primary="sample versus population data" data-type="indexterm" id="ch3_term4"/>sample data can <em>generalize</em> to a larger&#13;
population.</p>&#13;
&#13;
<p>The thing is, we don’t actually know what we’ll find in the population, because we&#13;
don’t have the data for all of it. However, using the principles of probability&#13;
introduced in <a data-type="xref" href="ch02.html#foundations-of-probability">Chapter 2</a>, we can <a data-primary="inferential statistics" data-secondary="uncertainty and" data-type="indexterm" id="idm46274547343256"/>quantify our uncertainty that what we see in our sample will also be found in the population.</p>&#13;
&#13;
<p>Estimating the <a data-primary="hypothesis testing" data-type="indexterm" id="idm46274547341656"/><a data-primary="inferential statistics" data-seealso="correlation and regression" data-type="indexterm" id="idm46274547340920"/><a data-primary="inferential statistics" data-secondary="about" data-type="indexterm" id="ch3_term1"/>values of a population given a sample is known as&#13;
<em>inferential statistics</em> and is carried out by <em>hypothesis testing</em>.&#13;
That framework is the basis of this chapter. You may have studied inferential statistics in school, which could have easily&#13;
turned you off the subject, seeming incomprehensible and without&#13;
application. That’s why I’ll make this chapter as applied as possible, exploring a&#13;
real-world dataset using Excel.</p>&#13;
&#13;
<p>By the end of the chapter, you will have a handle on this basic&#13;
framework that powers much of analytics. We’ll continue to build on its application in <a data-type="xref" href="ch04.html#foundations-of-data-analytics">Chapter 4</a>.</p>&#13;
&#13;
<p><a data-type="xref" href="ch01.html#foundations-of-eda">Chapter 1</a> concluded with an <a data-primary="datasets" data-secondary="housing example" data-type="indexterm" id="idm46274547334712"/><a data-primary="housing dataset example" data-type="indexterm" id="idm46274547333736"/><a data-primary="hypothesis testing" data-secondary="housing dataset for" data-type="indexterm" id="idm46274547333064"/>exercise on the <em>housing</em> dataset, which will be the focus of this chapter. You can find the dataset in the <em>datasets</em> folder of the book repository, under the <em>housing</em> subfolder. Make a copy of it, add an index column, and convert this dataset into a table named <em>housing</em>.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Framework of Statistical Inference" data-type="sect1"><div class="sect1" id="idm46274547330216">&#13;
<h1>The Framework of Statistical Inference</h1>&#13;
&#13;
<p>The ability to infer characteristics of a population based on a&#13;
sample seems magical, doesn’t it? Just like with any magic trick, inferential&#13;
statistics may look easy to outsiders. But to those within, it’s the&#13;
culmination of a series of finely tuned steps:</p>&#13;
<ol start="0">&#13;
<li>&#13;
<p><em>Collect a representative sample.</em> This <a data-primary="collecting data" data-type="indexterm" id="ch3_term6"/><a data-primary="data collection concerns" data-type="indexterm" id="ch3_term7"/><a data-primary="hypothesis testing" data-secondary="representative samples, collecting" data-type="indexterm" id="ch3_term8"/><a data-primary="representative sampling of population" data-type="indexterm" id="ch3_term9"/><a data-primary="sample size" data-secondary="effects of" data-type="indexterm" id="ch3_term10"/><a data-primary="sample size" data-secondary="as representative of population" data-secondary-sortas="representative of population" data-type="indexterm" id="ch3_term11"/>technically comes <em>before</em> the&#13;
hypothesis test, but is essential for its success. We must be sure that&#13;
the sample collected is a fair reflection of the population.</p>&#13;
</li>&#13;
<li>&#13;
<p><em>State the hypotheses.</em> First, we will <a data-primary="research hypothesis" data-type="indexterm" id="idm46274547317528"/><a data-primary="hypothesis testing" data-secondary="hypotheses, stating" data-type="indexterm" id="idm46274547316792"/>state a <em>research hypothesis</em>,&#13;
or some statement that motivates our analysis and that we think explains&#13;
something about our population. We will then <a data-primary="statistical hypotheses" data-type="indexterm" id="idm46274547315160"/>state a <em>statistical&#13;
hypothesis</em> to test whether the data supports this explanation.</p>&#13;
</li>&#13;
<li>&#13;
<p><em>Formulate an analysis plan.</em> We will then <a data-primary="hypothesis testing" data-secondary="analysis plans, formulating" data-type="indexterm" id="idm46274547312888"/>outline what methods we’ll use&#13;
to conduct this test, and what criteria we’ll use to evaluate it.</p>&#13;
</li>&#13;
<li>&#13;
<p><em>Analyze the data.</em> Here is where we actually <a data-primary="hypothesis testing" data-secondary="data, analyzing" data-type="indexterm" id="idm46274547310536"/>crunch the numbers, and&#13;
develop the evidence that we’ll use to evaluate our test against.</p>&#13;
</li>&#13;
<li>&#13;
<p><em>Make a decision.</em> It’s the <a data-primary="hypothesis testing" data-secondary="decisions, making" data-type="indexterm" id="idm46274547308200"/>moment of truth: we will <a data-primary="evaluation metrics" data-type="indexterm" id="idm46274547307016"/>compare the&#13;
evaluation criteria from step 2 with the actual results from step 3, and&#13;
conclude whether the evidence supports our statistical hypothesis.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>For each of these steps, I’ll provide a brief conceptual <a data-startref="ch3_term1" data-type="indexterm" id="idm46274547305544"/>overview. We’ll then immediately apply these concepts to the <em>housing</em> dataset.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Collect a Representative Sample" data-type="sect2"><div class="sect2" id="idm46274547304152">&#13;
<h2>Collect a Representative Sample</h2>&#13;
&#13;
<p>In <a data-type="xref" href="ch02.html#foundations-of-probability">Chapter 2</a> you learned that, thanks to the law of large numbers, the <a data-primary="average of averages (sample mean)" data-type="indexterm" id="idm46274547301432"/><a data-primary="sample mean" data-type="indexterm" id="idm46274547300664"/><a data-primary="mean" data-secondary="sample" data-type="indexterm" id="idm46274547299992"/><a data-primary="mean" data-secondary="population" data-type="indexterm" id="idm46274547299048"/><a data-primary="population mean" data-type="indexterm" id="idm46274547298104"/>average of sample means should get closer to the expected value as the sample size increases. This forms a rule of thumb for what makes an adequate sample size to conduct inferential statistics. We are assuming, however, that we are working with a <em>representative</em> sample or a set of observations that fairly reflect the population. If the sample isn’t representative, we’d have no standing to assume its sample mean would approach the population mean with more observations.</p>&#13;
&#13;
<p>Ensuring a representative sample is best handled during the conceptualization and collection phases of research; by the time the data is collected, it’s hard to walk back any issues related to sampling. There are many approaches to collecting data, but while it’s an important part of the analytics workflow, it is outside the scope of this book.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The best time to ensure a representative sample is during the collection of the data itself. If you’re working with a preassembled dataset, consider what steps were taken to meet this objective.</p>&#13;
</div>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46274547294296">&#13;
<h5>Statistical Bias</h5>&#13;
<p>Collecting an <a data-primary="bias, statistical" data-type="indexterm" id="idm46274547292968"/><a data-primary="statistical bias" data-type="indexterm" id="idm46274547292232"/>unrepresentative sample is one of the many ways to introduce <em>bias</em> into an experiment. You may think of bias in the cultural sense of an inclination or prejudice for or against some thing or person. This is indeed yet another potential source of bias in data analysis. In other words, we say something is statistically biased if it &#13;
<span class="keep-together">is calculated</span> in some way that is systematically different from the underlying parameter being estimated. Detecting and correcting for bias is one of the central tasks of &#13;
<span class="keep-together">analytics</span>.</p>&#13;
</div></aside>&#13;
&#13;
<p>Getting a <a data-primary="hypothesis testing" data-secondary="populations in" data-type="indexterm" id="idm46274547288552"/><a data-primary="populations in hypothesis testing" data-type="indexterm" id="idm46274547287544"/><a data-primary="target population" data-type="indexterm" id="idm46274547286904"/>representative sample of the population prompts the question: what is the target population? This population can be as general or specific as we want. For example, let’s say we’re interested in exploring the heights and weights of dogs. Our population could be all dogs, or it could be a specific breed. It could be a certain age group or sex of dogs as well. Some target populations may be of more theoretical importance, or logistically easier to sample. Your target population can be anything, but your sample of that population needs to be representative.</p>&#13;
&#13;
<p>At 546 <a data-primary="datasets" data-secondary="housing example" data-type="indexterm" id="idm46274547285144"/><a data-primary="housing dataset example" data-type="indexterm" id="idm46274547284136"/><a data-primary="hypothesis testing" data-secondary="housing dataset for" data-type="indexterm" id="idm46274547283464"/>observations, <em>housing</em> is likely a large-enough sample for conducting valid inferential statistics. Is it representative, though? Without some understanding of the collection methods or the target population, it’s hard to be sure. This data comes from the peer-reviewed <em>Journal of Applied Econometrics</em>, so it is trustworthy. Data that you receive at work may not come to you as polished, so it’s worth thinking through or inquiring about the collection and sampling procedures.</p>&#13;
&#13;
<p>As for the data’s target population, the data’s <em>readme</em> file, available in the book repository under <em>datasets</em> → <em>housing</em>, indicates it comes from home sales in Windsor, Ontario, Canada. That means that housing prices in Windsor may be the best target population; the findings may or may not, for example, transfer to housing prices across Canada or even Ontario. This is also an older dataset, taken from a paper written in the 1990s, so it’s not guaranteed that the findings from it would apply to <a data-startref="ch3_term6" data-type="indexterm" id="idm46274547278744"/><a data-startref="ch3_term7" data-type="indexterm" id="idm46274547278040"/><a data-startref="ch3_term8" data-type="indexterm" id="idm46274547277368"/><a data-startref="ch3_term9" data-type="indexterm" id="idm46274547276696"/><a data-startref="ch3_term10" data-type="indexterm" id="idm46274547276024"/><a data-startref="ch3_term11" data-type="indexterm" id="idm46274547275352"/>today’s housing market, even in Windsor.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="State the Hypotheses" data-type="sect2"><div class="sect2" id="idm46274547274488">&#13;
<h2>State the Hypotheses</h2>&#13;
&#13;
<p>With some comfort that our sample data is representative of the population, we can start to <a data-startref="ch3_term2" data-type="indexterm" id="idm46274547272408"/><a data-startref="ch3_term3" data-type="indexterm" id="idm46274547271704"/><a data-startref="ch3_term4" data-type="indexterm" id="idm46274547271032"/>think about what <a data-primary="hypothesis testing" data-secondary="hypotheses, stating" data-type="indexterm" id="ch3_term12"/>exactly we’d like to infer by stating hypotheses.&#13;
Maybe you’ve heard rumors about some trend or unusual phenomenon in your data. Maybe something struck you about the data as you began checking it out during EDA. This is your time to speculate on what you <em>think</em> you’ll find as the result of your analysis. Going to our <em>housing</em> example, I think few would disagree that air conditioning is desirable to have in a home. It stands to reason, then, that homes with air conditioning sell for higher prices than those without. This <a data-primary="research hypothesis" data-type="indexterm" id="idm46274547267496"/>informal statement about the relationship you’ll find in the data is called a <em>research hypothesis</em>. Another way to state this <a data-primary="hypothesis testing" data-secondary="subpopulations in" data-type="indexterm" id="idm46274547266280"/><a data-primary="subpopulations" data-type="indexterm" id="idm46274547265304"/>relationship is that there is an <em>effect</em> of air conditioning on sale price. Homes in Windsor are our <em>population</em>, and those homes with and without air conditioning are two of its groups or <em>subpopulations</em>.</p>&#13;
&#13;
<p>Now, it’s great that you have your hypothesis about how air conditioning affects sale prices. It’s crucial as an analyst to have a strong intuition and opinion about your work. But as American engineer W. Edwards Deming famously said, “In God we trust. All others must bring data.” What we <em>really</em> want to know is whether your speculated relationship is actually present in the population. And for this, we’ll need to use inferential statistics.</p>&#13;
&#13;
<p>As you’ve already seen, statistical language is usually different than everyday language. It can feel pedantic at first, but the nuances reveal a lot about how data analysis works. <em>Statistical hypotheses</em> are one such example. To test whether the data supports our proposed relationship, we’ll provide <a data-primary="alternative (Ha) hypothesis" data-type="indexterm" id="idm46274547261112"/><a data-primary="H0, null hypothesis" data-type="indexterm" id="idm46274547260344"/><a data-primary="Ha, alternative hypothesis" data-type="indexterm" id="idm46274547259672"/><a data-primary="null (H0) hypothesis" data-type="indexterm" id="idm46274547258984"/><a data-primary="statistical hypotheses" data-type="indexterm" id="idm46274547258312"/>two statistical hypotheses like the following. Take a look at them now; they’ll be explained later:</p>&#13;
<dl>&#13;
<dt>H0</dt>&#13;
<dd>&#13;
<p>There is no difference in the average sale price of homes with or without air &#13;
<span class="keep-together">conditioning</span>.</p>&#13;
</dd>&#13;
<dt>Ha</dt>&#13;
<dd>&#13;
<p>There is a difference in the average sale price of homes with or without air &#13;
<span class="keep-together">conditioning</span>.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>By design, these hypotheses are mutually exclusive, so that if one is true, the other must be false. They are also testable and falsifiable, meaning that we can use real-world evidence to measure and contradict them. These are big-idea topics on the philosophy of science that we can’t do full credit to here; the main takeaway is that you want to make sure that your hypotheses can actually be tested with your data.</p>&#13;
&#13;
<p>At this point, we need to leave all preconceived notions about the data behind, such as what was speculated in the research hypothesis. We’re now assuming <em>no</em> effect. After all, why would we? We <a data-primary="descriptive statistics" data-secondary="for sample versus population" data-secondary-sortas="sample versus population" data-type="indexterm" id="idm46274547250552"/><a data-primary="population versus sample data" data-type="indexterm" id="idm46274547249272"/><a data-primary="sample versus population data" data-type="indexterm" id="idm46274547248584"/><a data-primary="hypothesis testing" data-secondary="populations in" data-type="indexterm" id="idm46274547247896"/><a data-primary="populations in hypothesis testing" data-type="indexterm" id="idm46274547246952"/>only have a <em>sample</em> of the population’s data, so we’ll never truly know the population’s true value, or parameter. That’s why the first hypothesis, or H0, called the <em>null hypothesis</em>, is stated so peculiarly.</p>&#13;
&#13;
<p>On the flip side is the <em>alternative hypothesis</em>, or Ha. If there’s no evidence in the data for the null hypothesis, then the evidence has to be for the alternative, given the way they are stated. That said, we can <a data-primary="inferential statistics" data-secondary="uncertainty and" data-type="indexterm" id="idm46274547244232"/><a data-primary="hypothesis testing" data-secondary="caution with results of" data-type="indexterm" id="idm46274547243256"/>never say we’ve <em>proven</em> either to be true, because we don’t actually know the population’s parameter. It could be that the effect we found in the sample is just a fluke, and we wouldn’t have actually found it in the population. In fact, measuring the probability of this happening will be a major element of what we do in hypothesis testing.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The results of hypothesis testing don’t “prove” either hypothesis to be correct, because the “true” parameter of the population isn’t known in the first place.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Formulate an Analysis Plan" data-type="sect2"><div class="sect2" id="idm46274547239976">&#13;
<h2>Formulate an Analysis Plan</h2>&#13;
&#13;
<p>Now that we have our <a data-startref="ch3_term12" data-type="indexterm" id="idm46274547238184"/>statistical hypotheses teed up, it’s time to specify the <a data-primary="analysis in hypothesis testing" data-secondary="formulating plan for" data-type="indexterm" id="ch3_term16"/><a data-primary="hypothesis testing" data-secondary="analysis plans, formulating" data-type="indexterm" id="ch3_term17"/><a data-primary="methods" data-secondary="statistical" data-type="indexterm" id="ch3_term18"/><a data-primary="data analytics" data-secondary="in hypothesis testing" data-secondary-sortas="hypothesis testing" data-type="indexterm" id="ch3_term19"/>methods used to test the data. The proper statistical test for a given hypothesis depends on a variety of factors, including the type of variables used in the analysis: continuous, categorical, and so on. This is another reason it’s a good idea to <a data-primary="exploratory data analysis (EDA)" data-secondary="classifying variables for" data-type="indexterm" id="idm46274547231672"/><a data-primary="exploratory data analysis (EDA)" data-secondary="hypothesis testing and" data-type="indexterm" id="idm46274547230696"/><a data-primary="classifying variables" data-type="indexterm" id="idm46274547229736"/><a data-primary="variables" data-secondary="types of" data-type="indexterm" id="idm46274547229064"/>classify variables during EDA. Specifically, the test we decide to use depends on the types of our independent and dependent variables.</p>&#13;
&#13;
<p>The study of <a data-primary="cause and effect" data-type="indexterm" id="ch3_term13"/><a data-primary="dependent variables" data-secondary="in data analysis" data-secondary-sortas="data analysis" data-type="indexterm" id="ch3_term14"/><a data-primary="independent variables" data-secondary="in data analysis" data-secondary-sortas="data analysis" data-type="indexterm" id="ch3_term15"/>cause and effect drives much of what we do in analytics; we&#13;
use <em>independent</em> and <em>dependent</em> variables to model and analyze these&#13;
relationships. (Remember, though, that because we are dealing with samples, causation is impossible to claim with certainty.) We talked about the idea of experiments in <a data-type="xref" href="ch02.html#foundations-of-probability">Chapter 2</a> as repeatable events generating a defined set of random outcomes. We used the example of&#13;
a die throw as an experiment; most experiments in real life are more complicated. Let’s look at an example.</p>&#13;
&#13;
<p>Say we are researchers interested in what contributes to plant growth. A colleague has speculated that watering the plants could have a positive impact. We decide to try it by running experiments. We provide various amounts of water among observations, making sure to record the data. Then we wait a few days and measure the resulting plant growth. We’ve got two variables in this experiment: watering amount and plant growth. Can you guess which is our independent and which is our dependent &#13;
<span class="keep-together">variable</span>?</p>&#13;
&#13;
<p>Watering is the <em>independent variable</em> because it’s what we as&#13;
researchers control as part of the experiment. Plant growth is the&#13;
<em>dependent</em> because it’s what we’ve hypothesized will change given a&#13;
change in the independent variable. The independent variable is often recorded first: for&#13;
example, plants are watered <em>first</em>, and <em>then</em> they grow.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Independent variables are generally recorded before dependent variables because cause must come before effect.</p>&#13;
</div>&#13;
&#13;
<p>Given this example, what’s the more sensible way to model the relationship between air conditioning and sale price? It stands to reason that air conditioning is installed first, <em>then</em> the house is sold. That makes <em>airco</em> and <em>price</em> our independent and dependent variables, respectively.</p>&#13;
&#13;
<p>Because we are looking to test the <a data-primary="binary variables" data-type="indexterm" id="idm46274547213288"/><a data-primary="continuous variables" data-secondary="relationships between" data-type="indexterm" id="idm46274547212584"/>effect of a binary independent variable on a continuous dependent variable, we’ll use <a data-primary="independent samples t-tests" data-secondary="with Excel" data-secondary-sortas="Excel" data-type="indexterm" id="idm46274547211400"/><a data-primary="independent samples t-tests" data-secondary="statistical significance of" data-type="indexterm" id="ch3_term20"/>something called the <em>independent samples t-test</em>. Don’t worry about memorizing the best test to use for any given occasion. Instead, the <a data-primary="hypothesis testing" data-secondary="populations in" data-type="indexterm" id="idm46274547208216"/><a data-primary="populations in hypothesis testing" data-type="indexterm" id="idm46274547207272"/><a data-primary="descriptive statistics" data-secondary="for sample versus population" data-secondary-sortas="sample versus population" data-type="indexterm" id="idm46274547206536"/><a data-primary="population versus sample data" data-type="indexterm" id="idm46274547205288"/><a data-primary="sample versus population data" data-type="indexterm" id="idm46274547204600"/>objective here is picking up the common framework of making inferences about a population given a <a data-startref="ch3_term13" data-type="indexterm" id="idm46274547203672"/><a data-startref="ch3_term14" data-type="indexterm" id="idm46274547203000"/><a data-startref="ch3_term15" data-type="indexterm" id="idm46274547202328"/>sample.</p>&#13;
&#13;
<p>Most statistical tests make some assumptions about their data. If these assumptions aren’t met, then test results may be inaccurate. For example, the independent samples t-test assumes that no observation influences another and that each observation is found in one and only one group (that is, they are <em>independent</em>). To adequately <a data-primary="mean" data-secondary="population" data-type="indexterm" id="idm46274547200504"/><a data-primary="population mean" data-type="indexterm" id="idm46274547199496"/>estimate the population mean, the test generally assumes normally distributed samples; that said, it’s possible to circumvent that constraint for larger datasets given the magic of the <a data-primary="CLT (central limit theorem)" data-type="indexterm" id="idm46274547198488"/><a data-primary="central limit theorem (CLT)" data-type="indexterm" id="idm46274547197848"/>central limit theorem. Excel will help us bypass another assumption: that the variance of each population is equal.</p>&#13;
&#13;
<p>We know what test we’ll use, but we still need to set some rules for implementing it. For one, we need to <a data-primary="hypothesis testing" data-secondary="statistical significance in" data-type="indexterm" id="ch3_term21"/><a data-primary="statistical significance" data-type="indexterm" id="ch3_term22"/>decide the <em>statistical significance</em> of the test. Let’s go back to the scenario mentioned previously, where the effect inferred in the sample is just a fluke and wouldn’t have been found in the population. This scenario will happen eventually, because we’ll never actually know the population mean. In other words, we are <em>uncertain</em> about this outcome…and, as you learned in <a data-type="xref" href="ch02.html#foundations-of-probability">Chapter 2</a>, it’s <a data-primary="inferential statistics" data-secondary="uncertainty and" data-type="indexterm" id="idm46274547191800"/>possible to <em>quantify</em> uncertainty as a number between 0 and 1. This <a data-primary="alpha in hypothesis testing" data-type="indexterm" id="idm46274547190216"/>number is called <em>alpha</em> and represents the statistical significance of the test.</p>&#13;
&#13;
<p>The alpha shows how comfortable we are with the possibility that there’s really no effect in the populations, but that we found one in the samples due to chance.&#13;
A common threshold for alpha that we’ll use throughout the book is 5%.&#13;
In other words, we are comfortable with claiming a relationship in the data when there really is none 5% or less of the time.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>This book follows the standard convention of conducting two-tailed hypothesis tests at the 5% statistical significance level.</p>&#13;
</div>&#13;
&#13;
<p>Other common significance levels include 10% or 1%. There is no one “right” level of alpha; setting it depends on a variety of factors such as the research objective, ease of interpretability, and so forth.</p>&#13;
&#13;
<p>You may be wondering why we would be comfortable <em>at all</em> with the possibility of claiming an effect when there is none. In other words, why not an alpha of 0? In this case, we’re unable to claim <em>anything</em> about our population given the sample. Effectively, with an alpha of 0 we’d be saying that, because we don’t ever want to be wrong about the population’s true value, it could be anything. To make any inference at all, being wrong is a risk we must take.</p>&#13;
&#13;
<p>We also need to state which <em>direction</em> in effect we’re interested in. For example, <a data-primary="datasets" data-secondary="housing example" data-type="indexterm" id="idm46274547183416"/><a data-primary="housing dataset example" data-type="indexterm" id="idm46274547182440"/><a data-primary="hypothesis testing" data-secondary="housing dataset for" data-type="indexterm" id="idm46274547181768"/>we’re assuming a <em>positive</em> effect of air conditioning on sale price: that is, the average sale price of homes with air conditioning is greater than those without. However, it could turn out that there’s a negative effect: it might be&#13;
you’re dealing with a population that would prefer not to have air conditioning.&#13;
Or, maybe it’s a climate where using air conditioning is rarely justified, and having the unit is a needless expense. These scenarios are theoretically possible; if there’s any doubt, then the statistical test should examine for both positive <em>and</em> negative effects. This is <a data-primary="hypothesis testing" data-secondary="two-tailed direction for" data-type="indexterm" id="idm46274547179304"/><a data-primary="two-tailed tests" data-type="indexterm" id="idm46274547178312"/>known as a <em>two-tailed</em> (or two-tail, as Excel refers to it) test, and we’ll be using it in this book. One-tailed tests are possible, but relatively rare and outside our scope.</p>&#13;
&#13;
<p>This may seem like a lot of windup when we haven’t even touched the data yet. But these steps exist to ensure that we as analysts come to the data fairly when we finally make the calculations. The results of our hypothesis test depend on the level of statistical significance and the number of tails tested. As you’ll see later, it’s very possible that slightly different inputs to the test, such as a different statistical significance level, result in different findings. This offers a real temptation to run the numbers, <em>then</em> decide on a specific test for a favorable outcome. However, we want to avoid the urge to engineer the <a data-startref="ch3_term16" data-type="indexterm" id="idm46274547175560"/><a data-startref="ch3_term17" data-type="indexterm" id="idm46274547174856"/><a data-startref="ch3_term18" data-type="indexterm" id="idm46274547174184"/><a data-startref="ch3_term20" data-type="indexterm" id="idm46274547173512"/><a data-startref="ch3_term21" data-type="indexterm" id="idm46274547172840"/><a data-startref="ch3_term22" data-type="indexterm" id="idm46274547172168"/>results to fit our agenda.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Analyze the Data" data-type="sect2"><div class="sect2" id="idm46274547239352">&#13;
<h2>Analyze the Data</h2>&#13;
&#13;
<p>And now, the moment you’ve likely been waiting for: time to <a data-primary="analysis in hypothesis testing" data-secondary="of data" data-secondary-sortas="data" data-type="indexterm" id="ch3_term23"/>crunch the data. This part of the work often gets the most attention and is what we’ll focus on here, but it’s worth keeping in mind that it’s just one of the many steps of hypothesis testing. Remember, data analysis is an iterative process. It’s unlikely (and unwise) that you’ve performed <em>no</em> analysis of this data before conducting a hypothesis test. In fact, <a data-primary="exploratory data analysis (EDA)" data-secondary="hypothesis testing and" data-type="indexterm" id="idm46274547167128"/>exploratory data analysis is designed as a precursor to hypothesis testing, or <em>confirmatory</em> data analysis. You should <em>always</em> be comfortable with the dataset’s descriptive statistics before looking to make inferences about it. In that spirit, let’s do that here with our <em>housing</em> dataset, then move to the analysis.</p>&#13;
&#13;
<p class="pagebreak-before"><a data-type="xref" href="#price-by-ac">Figure 3-1</a> calculates the <a data-primary="descriptive statistics" data-secondary="in hypothesis testing" data-secondary-sortas="hypothesis testing" data-type="indexterm" id="ch3_term24"/><a data-primary="Excel" data-secondary="hypothesis testing with" data-type="indexterm" id="ch3_term25"/><a data-primary="hypothesis testing" data-secondary="descriptive statistics in" data-type="indexterm" id="ch3_term26"/><a data-primary="hypothesis testing" data-secondary="with Excel" data-secondary-sortas="Excel" data-type="indexterm" id="ch3_term27"/><a data-primary="hypothesis testing" data-secondary="data, analyzing" data-type="indexterm" id="ch3_term28"/><a data-primary="Excel" data-secondary="descriptive statistics in" data-type="indexterm" id="idm46274547156328"/><a data-primary="descriptive statistics" data-secondary="with Excel" data-secondary-sortas="Excel" data-type="indexterm" id="idm46274547155368"/>descriptive statistics for and visualizes the distributions of <em>price</em> for both levels of <em>airco</em>. If you need a refresher on how to do this, check out <a data-type="xref" href="ch01.html#foundations-of-eda">Chapter 1</a>. I relabeled the <a data-primary="Data Analysis ToolPak, Excel" data-secondary="t-tests with" data-type="indexterm" id="ch3_term29"/>ToolPak output to help indicate what is being measured in each group.</p>&#13;
&#13;
<figure><div class="figure" id="price-by-ac">&#13;
<img alt="_housing_ descriptive statistics" src="assets/aina_0301.png"/>&#13;
<h6><span class="label">Figure 3-1. </span>EDA of the housing dataset</h6>&#13;
</div></figure>&#13;
&#13;
<p>The histogram <a data-primary="histograms" data-secondary="of normal probability distributions" data-secondary-sortas="normal probability distributions" data-type="indexterm" id="idm46274547148680"/><a data-primary="normal distributions" data-secondary="visualizations of" data-type="indexterm" id="idm46274547147320"/><a data-primary="Excel" data-secondary="visualizations with" data-type="indexterm" id="idm46274547146376"/><a data-primary="visualization of data" data-secondary="with Excel" data-secondary-sortas="Excel" data-type="indexterm" id="idm46274547145432"/>in this output shows us that both groups of data are approximately normally distributed, and the descriptive statistics tell us that we have relatively <a data-primary="sample size" data-secondary="effects of" data-type="indexterm" id="idm46274547143912"/>large sample sizes. While far more homes do not have air conditioning (373 without versus 173 with), this is not necessarily a problem for the t-test.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The independent samples t-test is not sensitive to differences &#13;
<span class="keep-together">in sample</span> sizes between the two groups, so long as each group is &#13;
<span class="keep-together">sufficiently</span> large. Other statistical tests may be&#13;
affected by this &#13;
<span class="keep-together">difference</span>.</p>&#13;
</div>&#13;
&#13;
<p><a data-type="xref" href="#price-by-ac">Figure 3-1</a> also gives us the <a data-primary="average of averages (sample mean)" data-type="indexterm" id="idm46274547138120"/><a data-primary="sample mean" data-type="indexterm" id="idm46274547137400"/><a data-primary="mean" data-secondary="sample" data-type="indexterm" id="idm46274547136728"/>sample means of our groups: approximately $86,000 for homes with air conditioning, and $60,000 for those without. That’s good to know, but we’d <em>really</em> like to find out whether we could expect such an effect in the population at large. That’s where the <a data-primary="PivotTables, Excel" data-secondary="for t-tests" data-secondary-sortas="t-tests" data-type="indexterm" id="idm46274547134984"/>t-test comes in, and we’ll lean yet again on PivotTables and the Data Analysis ToolPak to conduct it.</p>&#13;
&#13;
<p>Insert a PivotTable into a new worksheet, placing <em>id</em> in the Rows area, <em>airco</em> in the Columns area, and “Sum of price” in the Values area. Clear out all grand totals from the report. This data arrangement will be easy to input into the <a data-primary="Excel" data-secondary="t-Test in" data-type="indexterm" id="ch3_term30"/><a data-primary="independent samples t-tests" data-secondary="with Excel" data-secondary-sortas="Excel" data-type="indexterm" id="ch3_term31"/><a data-primary="t-Test: Two-Sample Assuming Unequal Variances, Excel" data-type="indexterm" id="ch3_term32"/>t-test menu, which can be accessed from the ribbon via Data → Data Analysis → t-Test: Two-Sample Assuming Unequal Variances. The “variances” <a data-primary="variance, measuring" data-type="indexterm" id="idm46274547127848"/><a data-primary="descriptive statistics" data-secondary="for variance" data-secondary-sortas="variance" data-type="indexterm" id="idm46274547127176"/><a data-primary="hypothesis testing" data-secondary="variances in" data-type="indexterm" id="idm46274547125960"/><a data-primary="hypothesis testing" data-secondary="subpopulations in" data-type="indexterm" id="idm46274547125016"/><a data-primary="subpopulations" data-type="indexterm" id="idm46274547124072"/>referred to here are our subpopulation variances. We really don’t know whether these are equal, so it’s better to choose this option, assuming equal variances for more conservative results.</p>&#13;
&#13;
<p>A dialog box will appear; fill it out as in <a data-type="xref" href="#t-test-setup">Figure 3-2</a>. Make sure that the box next to Labels is checked. Immediately above this selection is an option titled Hypothesized Mean Difference. By default, this is left blank, which means we are <a data-primary="null (H0) hypothesis" data-type="indexterm" id="idm46274547121768"/>testing for a difference of zero. This is precisely our null hypothesis, so we don’t have to change anything. Immediately below that line is an option titled <a data-primary="alpha in hypothesis testing" data-type="indexterm" id="idm46274547120792"/>Alpha. This is our <a data-primary="hypothesis testing" data-secondary="statistical significance in" data-type="indexterm" id="idm46274547120024"/><a data-primary="statistical significance" data-type="indexterm" id="idm46274547119032"/>stated level of statistical significance; Excel defaults to 5%, which is what we want.</p>&#13;
&#13;
<figure><div class="figure" id="t-test-setup">&#13;
<img alt="T-test setup" src="assets/aina_0302.png"/>&#13;
<h6><span class="label">Figure 3-2. </span>t-test setup menu in the ToolPak</h6>&#13;
</div></figure>&#13;
&#13;
<p>The results are shown in <a data-type="xref" href="#t-test-output">Figure 3-3</a>. I’ve again relabeled each group as <em>ac-no</em> and <em>ac-yes</em> to clarify what groups are represented. We’ll step through selected parts of the output next.</p>&#13;
&#13;
<figure><div class="figure" id="t-test-output">&#13;
<img alt="T-test setup" src="assets/aina_0303.png"/>&#13;
<h6><span class="label">Figure 3-3. </span>t-test output</h6>&#13;
</div></figure>&#13;
&#13;
<p>First, we’re given some information about our two samples in <code>F5:G7</code>: their means, variances, and sample sizes. Our hypothesized mean difference of zero is also included.</p>&#13;
&#13;
<p>We’ll skip a few statistics here and focus next on <a data-primary="hypothesis testing" data-secondary="two-tailed direction for" data-type="indexterm" id="idm46274547110488"/><a data-primary="two-tailed tests" data-type="indexterm" id="idm46274547109128"/><a data-primary="p-values" data-secondary="methodology for" data-type="indexterm" id="idm46274547108456"/>cell <code>F13</code>, <em>P(T &lt; = t) two-tail</em>. This probably doesn’t make much sense to you, but <em>two-tail</em> should sound familiar, as it’s the type of test we decided to focus on earlier instead of a one-tail test. This <a data-startref="ch3_term19" data-type="indexterm" id="idm46274547105976"/>figure is called the <em>p-value</em>, and we’ll use it to make a decision about the <a data-startref="ch3_term23" data-type="indexterm" id="idm46274547104664"/><a data-startref="ch3_term24" data-type="indexterm" id="idm46274547103960"/><a data-startref="ch3_term25" data-type="indexterm" id="idm46274547103288"/><a data-startref="ch3_term26" data-type="indexterm" id="idm46274547102616"/><a data-startref="ch3_term27" data-type="indexterm" id="idm46274547101944"/><a data-startref="ch3_term28" data-type="indexterm" id="idm46274547101272"/><a data-startref="ch3_term29" data-type="indexterm" id="idm46274547100600"/><a data-startref="ch3_term30" data-type="indexterm" id="idm46274547099928"/><a data-startref="ch3_term31" data-type="indexterm" id="idm46274547099256"/><a data-startref="ch3_term32" data-type="indexterm" id="idm46274547098584"/>hypothesis test.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Make a Decision" data-type="sect2"><div class="sect2" id="idm46274547170904">&#13;
<h2>Make a Decision</h2>&#13;
&#13;
<p>Earlier you learned that <a data-primary="alpha in hypothesis testing" data-type="indexterm" id="idm46274547095800"/>alpha is our level of <a data-primary="hypothesis testing" data-secondary="statistical significance in" data-type="indexterm" id="idm46274547095000"/><a data-primary="statistical significance" data-type="indexterm" id="idm46274547094008"/><a data-primary="analysis in hypothesis testing" data-secondary="for decision-making" data-secondary-sortas="decision-making" data-type="indexterm" id="ch3_term34"/><a data-primary="hypothesis testing" data-secondary="decisions, making" data-type="indexterm" id="ch3_term35"/>statistical significance, or the level with which we are comfortable assuming there’s a real effect in the population when there is not, because the effect we found in the sample is due to random chance. The <a data-primary="p-values" data-secondary="as basis for decisions" data-secondary-sortas="basis for decisions" data-type="indexterm" id="ch3_term33"/>p-value quantifies the probability that we will find this scenario in the data, and we compare it to <a data-primary="null, rejection of" data-type="indexterm" id="idm46274547088520"/><a data-primary="null (H0) hypothesis" data-type="indexterm" id="idm46274547087848"/><a data-primary="rejection of null" data-type="indexterm" id="idm46274547087176"/><a data-primary="rejection of null, failure of" data-type="indexterm" id="idm46274547086504"/><a data-primary="null, failure to reject" data-type="indexterm" id="idm46274547085816"/>alpha to make a decision:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>If the p-value is less than or equal to our alpha, then we reject the null.</p>&#13;
</li>&#13;
<li>&#13;
<p>If the p-value is greater than our alpha, then we fail to reject the null.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Let’s cut through this statistical jargon with the data at hand. As a probability, the p-value is always between 0 and 1. Our p-value in <code>F13</code> is very small, so small that Excel has labeled it in scientific notation. The way to read this output is as 1.93 times 10 to the negative 22nd power—a <em>very</em> small number. We are saying, then, that if there were really no effect in the population, we’d expect to find the effect that we did in the samples well under less than 1% of the time. This is well below our alpha of 5%, so we can reject the null. When a p-value is so small that scientific notation is required to report it, you’ll often see the results simply summarized as “p &lt; 0.05.”</p>&#13;
&#13;
<p>On the other hand, let’s say our p-value was 0.08 or 0.24. In these cases, we would <em>fail</em> to reject the null. Why this odd language? Why don’t we just say that we “proved” either the null or the alternative? It all goes <a data-primary="inferential statistics" data-secondary="uncertainty and" data-type="indexterm" id="idm46274547079624"/>back to the inherent uncertainty of inferential statistics. We <a data-primary="hypothesis testing" data-secondary="subpopulations in" data-type="indexterm" id="idm46274547078520"/><a data-primary="subpopulations" data-type="indexterm" id="idm46274547077576"/>don’t ever know the true subpopulation values, so it’s safer to start on the premise that they are both equal. The results of our test can confirm or deny evidence for either, but they can never definitively <em>prove</em> it.</p>&#13;
&#13;
<p>While <a data-primary="p-values" data-secondary="misinterpretations and limitations of" data-type="indexterm" id="idm46274547075720"/>p-values are used to make a decision about a hypothesis test, it’s also important to know what they <em>cannot</em> tell us. For example, a frequent misinterpretation is that the p-value is the probability of making a mistake. In fact, a p-value <em>assumes</em> that our null hypothesis is true, regardless of what is found in the sample; the idea of there being a “mistake” in the sample doesn’t change this assumption at all. The p-value <em>only</em> tells us what percentage of the time we’d find the effect that we did in our sample, given no effect in the population.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The p-value is <em>not</em> the probability of making a mistake; rather, it is the probability of finding the effect in the <a data-primary="hypothesis testing" data-secondary="populations in" data-type="indexterm" id="idm46274547071080"/><a data-primary="population versus sample data" data-type="indexterm" id="idm46274547070104"/><a data-primary="sample versus population data" data-type="indexterm" id="idm46274547069416"/><a data-primary="populations in hypothesis testing" data-type="indexterm" id="idm46274547068728"/>sample that we did, given no effect in the population.</p>&#13;
</div>&#13;
&#13;
<p>Another common misinterpretation is that the smaller the p-value, the larger the effect. The p-value, however, is only a measure of <em>statistical</em> significance: it tells us how <em>likely</em> an effect in the population is. The p-value does not <a data-primary="substantive significance" data-type="indexterm" id="idm46274547066136"/><a data-primary="hypothesis testing" data-secondary="substantive significance in" data-type="indexterm" id="idm46274547065416"/>indicate the <em>substantive</em> significance, or how large that effect size is likely to be. It’s common for statistical software to report only statistical and not substantive significance. Our Excel <a data-primary="confidence intervals" data-secondary="in Excel" data-secondary-sortas="Excel" data-type="indexterm" id="ch3_term36"/>output is one such case: while it returns the p-value, it does not <a data-primary="confidence intervals" data-secondary="defined" data-type="indexterm" id="idm46274547062072"/>return the <em>confidence interval</em>, or the range within which we’d expect to find our population.</p>&#13;
&#13;
<p>We can use the so-called <a data-primary="critical values" data-type="indexterm" id="ch3_term37"/>critical value of our test, displayed in cell <code>F14</code> of <a data-type="xref" href="#t-test-output">Figure 3-3</a>, to derive the confidence interval. The number (1.97) may seem arbitrary, but you can actually make sense of it given what you learned in <a data-type="xref" href="ch02.html#foundations-of-probability">Chapter 2</a>. With this t-test, we have taken a sample difference in average home prices. Were we to continue taking random samples and plotting the distribution of the mean differences, this distribution would be…that’s right, <em>normal</em>, due to the <a data-primary="central limit theorem (CLT)" data-type="indexterm" id="idm46274547055944"/><a data-primary="CLT (central limit theorem)" data-type="indexterm" id="idm46274547055192"/>central limit theorem.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46274547054376">&#13;
<h5>The Normal Distribution and the T-distribution</h5>&#13;
<p>For smaller <a data-primary="sample size" data-secondary="t-distribution and" data-type="indexterm" id="idm46274547053016"/><a data-primary="t-distribution" data-type="indexterm" id="idm46274547052008"/><a data-primary="normal distributions" data-secondary="t-distributions and" data-type="indexterm" id="idm46274547051336"/>sample sizes, the <em>t-distribution</em> is used to derive critical values for a t-test.&#13;
But as sample sizes increase, critical values converge to those found in the normal dis‐&#13;
tribution. When I refer to specific critical values in this book, I am using those found&#13;
from the normal distribution; these may vary slightly from what you see in Excel due&#13;
to sample size. For sample sizes in the hundreds like we’ve generally been using here, the differences should be negligible</p>&#13;
</div></aside>&#13;
&#13;
<p>With a normal distribution, we can expect about 95% of observations to fall within&#13;
two standard deviations of the mean thanks to the <a data-primary="empirical (68–95–99.7) rule in probability" data-type="indexterm" id="idm46274547048488"/><a data-primary="probability" data-secondary="empirical (68–95–99.7) rule in" data-type="indexterm" id="idm46274547047688"/>empirical rule. In the special case&#13;
of a normally distributed variable with a mean of 0 and <a data-primary="descriptive statistics" data-secondary="for standard deviations" data-secondary-sortas="standard deviations" data-type="indexterm" id="idm46274547046536"/><a data-primary="standard deviations" data-type="indexterm" id="idm46274547045320"/><a data-primary="standard normal distribution" data-type="indexterm" id="idm46274547044648"/>standard deviation of 1 (called a <em>standard</em> normal distribution), we&#13;
could say that about 95% of all observations would fall between –2 and 2. To be a little&#13;
more specific, they would be between –1.96 and 1.96, and that is <a data-primary="two-tailed tests" data-type="indexterm" id="idm46274547043288"/><a data-primary="hypothesis testing" data-secondary="two-tailed direction for" data-type="indexterm" id="idm46274547042584"/>how the two-tailed critical value is derived. <a data-type="xref" href="#confidence-95">Figure 3-4</a> illustrates the area <a data-primary="histograms" data-secondary="of normal probability distributions" data-secondary-sortas="normal probability distributions" data-type="indexterm" id="idm46274547040648"/><a data-primary="normal distributions" data-secondary="visualizations of" data-type="indexterm" id="idm46274547039368"/>within which we’d expect to find&#13;
the population’s parameter with 95% confidence.</p>&#13;
&#13;
<figure><div class="figure" id="confidence-95">&#13;
<img alt="Confidence interval example" src="assets/aina_0304.png"/>&#13;
<h6><span class="label">Figure 3-4. </span>The 95% confidence interval and critical value visualized on a histogram</h6>&#13;
</div></figure>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46274547036392">&#13;
<h5>The Test Statistic and the Critical Value</h5>&#13;
<p>Cell <code>F10</code> of <a data-type="xref" href="#t-test-output">Figure 3-3</a> returns <a data-primary="test statistic" data-type="indexterm" id="idm46274547033528"/>the <em>test statistic</em>. Though we’ve been using p-values to&#13;
make a decision about our hypothesis test, we could also use the test statistic: if it falls&#13;
outside the inner range of our critical values, we reject the null. The test statistic and&#13;
the p-value will fundamentally be in agreement; if one indicates significance, so will&#13;
the other. Because the p-value is often easier to interpret, it’s more commonly&#13;
reported than the test statistic.</p>&#13;
</div></aside>&#13;
&#13;
<p><a data-type="xref" href="#confidence-interval-formula">Equation 3-1</a> displays the <a data-startref="ch3_term33" data-type="indexterm" id="idm46274547030568"/>formula for finding the <a data-primary="confidence intervals" data-secondary="formula (Excel) for" data-type="indexterm" id="idm46274547029736"/><a data-primary="independent samples t-tests" data-secondary="with Excel" data-secondary-sortas="Excel" data-type="indexterm" id="idm46274547028792"/><a data-primary="Excel" data-secondary="hypothesis testing with" data-type="indexterm" id="ch3_term39"/><a data-primary="hypothesis testing" data-secondary="with Excel" data-secondary-sortas="Excel" data-type="indexterm" id="ch3_term38"/>confidence interval of a two-tailed independent samples t-test. We’ll calculate the labeled elements in Excel.</p>&#13;
<div data-type="equation" id="confidence-interval-formula">&#13;
<h5><span class="label">Equation 3-1. </span>Formula for finding the confidence interval</h5>&#13;
<math alttext="c period i period equals left-parenthesis upper X overbar Subscript 1 Baseline minus upper X overbar Subscript 2 Baseline right-parenthesis plus-or-minus t a Subscript slash 2 Baseline times StartRoot StartFraction s 1 squared Over n 1 EndFraction plus StartFraction s 2 squared Over n 2 EndFraction EndRoot" display="block">&#13;
  <mrow>&#13;
    <mspace width="4.pt"/>&#13;
    <mtext>c.</mtext>&#13;
    <mspace width="4.pt"/>&#13;
    <mi>i</mi>&#13;
    <mo>.</mo>&#13;
    <mo>=</mo>&#13;
    <mfenced close=")" open="(" separators="">&#13;
      <msub><mover accent="true"><mi>X</mi> <mo>¯</mo></mover> <mn>1</mn> </msub>&#13;
      <mo>-</mo>&#13;
      <msub><mover accent="true"><mi>X</mi> <mo>¯</mo></mover> <mn>2</mn> </msub>&#13;
    </mfenced>&#13;
    <mo>±</mo>&#13;
    <mi>t</mi>&#13;
    <msub><mi>a</mi> <mrow><mo>/</mo><mn>2</mn></mrow> </msub>&#13;
    <mo>×</mo>&#13;
    <msqrt>&#13;
      <mrow>&#13;
        <mfrac><msubsup><mi>s</mi> <mrow><mn>1</mn></mrow> <mn>2</mn> </msubsup> <msub><mi>n</mi> <mn>1</mn> </msub></mfrac>&#13;
        <mo>+</mo>&#13;
        <mfrac><msubsup><mi>s</mi> <mrow><mn>2</mn></mrow> <mn>2</mn> </msubsup> <msub><mi>n</mi> <mn>2</mn> </msub></mfrac>&#13;
      </mrow>&#13;
    </msqrt>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>To break this formula down, <math alttext="left-parenthesis upper X overbar Subscript 1 Baseline minus upper X overbar Subscript 2 Baseline right-parenthesis">&#13;
  <mfenced close=")" open="(" separators="">&#13;
    <msub><mover accent="true"><mi>X</mi> <mo>¯</mo></mover> <mn>1</mn> </msub>&#13;
    <mo>-</mo>&#13;
    <msub><mover accent="true"><mi>X</mi> <mo>¯</mo></mover> <mn>2</mn> </msub>&#13;
  </mfenced>&#13;
</math> is the point estimate, <math alttext="t a Subscript slash 2">&#13;
  <mrow>&#13;
    <mi>t</mi>&#13;
    <msub><mi>a</mi> <mrow><mo>/</mo><mn>2</mn></mrow> </msub>&#13;
  </mrow>&#13;
</math> is the critical value, and  <math alttext="StartRoot StartFraction s 1 squared Over n 1 EndFraction plus StartFraction s 2 squared Over n 2 EndFraction EndRoot">&#13;
  <msqrt>&#13;
    <mrow>&#13;
      <mfrac><msubsup><mi>s</mi> <mrow><mn>1</mn></mrow> <mn>2</mn> </msubsup> <msub><mi>n</mi> <mn>1</mn> </msub></mfrac>&#13;
      <mo>+</mo>&#13;
      <mfrac><msubsup><mi>s</mi> <mrow><mn>2</mn></mrow> <mn>2</mn> </msubsup> <msub><mi>n</mi> <mn>2</mn> </msub></mfrac>&#13;
    </mrow>&#13;
  </msqrt>&#13;
</math> is the standard error. The product of the critical value and the <a data-primary="standard error" data-type="indexterm" id="idm46274546982504"/>standard error is the <a data-primary="margin of error" data-type="indexterm" id="idm46274546981704"/>margin of error.</p>&#13;
&#13;
<p>This equation can be pretty intimidating, so to make it more concrete I’ve already calculated the confidence interval and its various elements for our example in <a data-type="xref" href="#confidence-interval-excel">Figure 3-5</a>. Rather than get hung up over the formal equation, our focus will be on <a data-primary="t-Test: Two-Sample Assuming Unequal Variances, Excel" data-type="indexterm" id="idm46274546979560"/>computing the results and understanding what they tell us.</p>&#13;
&#13;
<figure><div class="figure" id="confidence-interval-excel">&#13;
<img alt="Confidence interval calculations in Excel" src="assets/aina_0305.png"/>&#13;
<h6><span class="label">Figure 3-5. </span>Calculating the confidence interval in Excel</h6>&#13;
</div></figure>&#13;
&#13;
<p>First, the <em>point estimate</em> in <a data-primary="point estimate" data-type="indexterm" id="idm46274546975512"/>cell <code>F16</code>, or the effect in the <a data-primary="descriptive statistics" data-secondary="for sample versus population" data-secondary-sortas="sample versus population" data-type="indexterm" id="idm46274546974232"/><a data-primary="population versus sample data" data-type="indexterm" id="idm46274546972968"/><a data-primary="sample versus population data" data-type="indexterm" id="idm46274546972280"/><a data-primary="hypothesis testing" data-secondary="populations in" data-type="indexterm" id="ch3_term40"/><a data-primary="populations in hypothesis testing" data-type="indexterm" id="ch3_term41"/>population we are most likely to find. This is the difference in our <a data-primary="average of averages (sample mean)" data-type="indexterm" id="idm46274546969288"/><a data-primary="mean" data-secondary="sample" data-type="indexterm" id="idm46274546968520"/><a data-primary="sample mean" data-type="indexterm" id="idm46274546967576"/>sample means. After all, if our sample is representative of the population, the difference in sample and <a data-primary="population mean" data-type="indexterm" id="idm46274546966648"/><a data-primary="mean" data-secondary="population" data-type="indexterm" id="idm46274546965976"/>population means should be negligible. But it probably won’t be exactly the same; we will derive a range of values within which we are 95% confident we’ll find that true difference.</p>&#13;
&#13;
<p>Next, the critical value in cell <code>F17</code>. Excel provided this number for us, but I’ve included it here for ease of analysis. As described previously, we can use this value to help us find the 95% of values that fall within approximately two standard deviations of the mean.</p>&#13;
&#13;
<p>Now we have the <a data-primary="standard error" data-type="indexterm" id="idm46274546963128"/>standard error in cell <code>F18</code>. You’ve actually seen this term before, in the <a data-primary="Data Analysis ToolPak, Excel" data-secondary="descriptive statistics from" data-type="indexterm" id="idm46274546961784"/>ToolPak’s descriptive statistics output; see <a data-type="xref" href="#price-by-ac">Figure 3-1</a> as an example. To understand how the standard error works, imagine if you were to go out and resample housing prices from the population over and over. Each time, you’d get slightly different sample means. That variability is known as the <em>standard error</em>. A larger standard error means that a sample is less accurate in representing a population.</p>&#13;
&#13;
<p>The standard error for one sample can be found by dividing its <a data-primary="standard deviations" data-type="indexterm" id="idm46274546958792"/><a data-primary="descriptive statistics" data-secondary="for standard deviations" data-secondary-sortas="standard deviations" data-type="indexterm" id="idm46274546958008"/>standard deviation by its sample size. Because we are finding the standard error for a <em>difference</em> in means, the formula is a bit more complicated, but the same pattern holds: the variability of the samples goes in the numerator, and the number of observations goes in the denominator. This makes sense: we’d expect more variability in a sample difference when each sample mean itself contains more variability; as we collect larger <a data-primary="sample size" data-secondary="effects of" data-type="indexterm" id="idm46274546955928"/>sample sizes, we’d expect them to exhibit less variability from the population.</p>&#13;
&#13;
<p>We will now take the product of the critical value <a data-startref="ch3_term37" data-type="indexterm" id="idm46274546954152"/>and the standard error to <a data-primary="margin of error" data-type="indexterm" id="idm46274546953320"/>get the <em>margin of error</em> in cell <code>F19</code>. This may be a term you’ve heard of: polls are often reported with this figure included. The margin of error provides an estimate of just how much variability there is around our point estimate. In the case of <a data-type="xref" href="#confidence-interval-excel">Figure 3-5</a>, we’re saying that while we think the population difference is $25,996, we could be off by as much as $4,784.</p>&#13;
&#13;
<p>Because this is a <a data-primary="hypothesis testing" data-secondary="two-tailed direction for" data-type="indexterm" id="idm46274546950248"/><a data-primary="two-tailed tests" data-type="indexterm" id="idm46274546949272"/>two-tailed test, this difference could be found in <em>either direction</em>. So we’ll need to both subtract and add the margin of error to derive the lower and upper bounds of our confidence interval, respectively. Those figures are found in <code>F20</code> and <code>F21</code>, respectively. The bottom line? With 95% confidence, we believe that the average price of a home with air conditioning has a sale price of between $21,211 and $30,780 higher than one without air conditioning.</p>&#13;
&#13;
<p>Why go through all the trouble to derive a <a data-startref="ch3_term36" data-type="indexterm" id="idm46274546946040"/>confidence interval? As a <a data-primary="substantive significance" data-type="indexterm" id="idm46274546945208"/><a data-primary="statistical significance" data-type="indexterm" id="idm46274546944520"/><a data-primary="hypothesis testing" data-secondary="statistical significance in" data-type="indexterm" id="idm46274546943832"/><a data-primary="hypothesis testing" data-secondary="substantive significance in" data-type="indexterm" id="idm46274546942872"/>measure of substantive rather than statistical significance, it often plays better with general audiences because it translates the results of the <a data-primary="statistical hypotheses" data-type="indexterm" id="idm46274546941624"/>statistical hypothesis test back into the <a data-primary="research hypothesis" data-type="indexterm" id="idm46274546940760"/>language of the research hypothesis. For example, imagine you were a research analyst at a bank reporting the results of this study on home prices to management. These managers wouldn’t know where to start conducting a t-test if their careers depended on &#13;
<span class="keep-together">it—but</span> their careers <em>do</em> depend on making smart decisions from that analysis, so you want to make it as intelligible as possible. Which <a data-primary="rejection of null" data-type="indexterm" id="idm46274546938456"/><a data-primary="null, rejection of" data-type="indexterm" id="idm46274546937752"/>statement do you think will be more helpful?</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>“We rejected the null that there is no difference in the average sale price of homes with or without air conditioning at p &lt; 0.05.”</p>&#13;
</li>&#13;
<li>&#13;
<p>“With 95% confidence, the average sale price of homes with air conditioning is approximately between $21,200 and $30,800 higher than those without.”</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Nearly anyone can make sense of the second statement, whereas the first requires a fair amount of statistical know-how. But confidence intervals aren’t just for laypeople: there’s also been a <a data-primary="p-values" data-secondary="misinterpretations and limitations of" data-type="indexterm" id="idm46274546933928"/>push in research and data circles to report them along with p-values. After all, the p-value <em>only</em> measures statistical effect, <em>not</em> substantive.</p>&#13;
&#13;
<p>But while p-values and confidence intervals show the results from different angles, they are fundamentally <em>always in agreement</em>. Let’s illustrate this concept by conducting another <a data-primary="datasets" data-secondary="housing example" data-type="indexterm" id="idm46274546930728"/><a data-primary="housing dataset example" data-type="indexterm" id="idm46274546929672"/>hypothesis test on the <em>housing</em> dataset. This time, we would like to know if there is a significant difference in the average lot size (<em>lotsize</em>) of homes with and without a full, finished basement (<em>fullbase</em>). This relationship can also be <a data-primary="independent samples t-tests" data-secondary="with Excel" data-secondary-sortas="Excel" data-type="indexterm" id="idm46274546927432"/><a data-primary="Excel" data-secondary="demos and worksheets for" data-type="indexterm" id="idm46274546926120"/>tested with a t-test; I will follow the same steps as before in a new worksheet, which results in <a data-type="xref" href="#fullbase-lotsize">Figure 3-6</a>. (Don’t forget to explore the descriptive statistics of these new variables first.)</p>&#13;
&#13;
<figure><div class="figure" id="fullbase-lotsize">&#13;
<img alt="t-test output" src="assets/aina_0306.png"/>&#13;
<h6><span class="label">Figure 3-6. </span>The effect on lot size of having a full finished basement</h6>&#13;
</div></figure>&#13;
&#13;
<p>The results of this <a data-primary="statistical significance" data-type="indexterm" id="idm46274546921592"/>test are <em>not</em> statistically significant: based on the p-value of 0.27, we’d expect to find the effect we did in over one-quarter of our samples, assuming no effect in the <a data-startref="ch3_term40" data-type="indexterm" id="idm46274546920168"/><a data-startref="ch3_term41" data-type="indexterm" id="idm46274546919464"/>population. As for the <a data-primary="substantive significance" data-type="indexterm" id="idm46274546918664"/><a data-primary="hypothesis testing" data-secondary="substantive significance in" data-type="indexterm" id="idm46274546917992"/>substantive significance, we are 95% confident that the difference in average lot size is between approximately 167 square feet less and 599 square feet more. In other words, the true difference could be positive <em>or</em> negative, we can’t say for sure. Based on either of these results, we fail to reject the null: there does not appear to be a significant difference in average lot size. These results will always agree because they are both based in part on the level of statistical significance: alpha determines how we evaluate the <a data-primary="p-values" data-secondary="as basis for decisions" data-secondary-sortas="basis for decisions" data-type="indexterm" id="idm46274546915960"/>p-value and <a data-primary="critical values" data-type="indexterm" id="ch3_term43"/>sets the critical value used to derive the confidence interval.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46274546913480">&#13;
<h5>Hypothesis Testing and Data Mining</h5>&#13;
<p>Whether we <a data-primary="data mining and hypothesis testing" data-type="indexterm" id="idm46274546912136"/><a data-primary="hypothesis testing" data-secondary="caution with results of" data-type="indexterm" id="ch3_term44"/>really <em>did</em> expect to find a significant relationship between lot size and a full, finished basement is questionable. After all, how these variables are related is less clear than how the presence of air conditioning might affect sale price. In fact, I chose to test this relationship only to get an intended <em>insignificant</em> relationship for the purposes of demonstration. In most other cases, it would be more tempting to mine the data and look for <em>significant</em> relationships. Cheap computing has allowed for a more freewheeling approach to data analysis, but if you can’t explain the results of your analysis based on logic, theory, or prior empirical evidence, you should treat it cautiously—no matter how strong or powerful the findings.</p>&#13;
</div></aside>&#13;
&#13;
<p>If you’ve ever built a financial model, you might be familiar with <a data-primary="what-if analyses" data-type="indexterm" id="ch3_term45"/>doing a what-if analysis on your work to see how its output might change given your inputs or assumptions. In that same spirit, let’s examine how the results of our basement/lot size t-test might have been different. Because we’ll be manipulating the results of our ToolPak output, it’s wise to copy and paste the data in cells <code>E2:G21</code> into a new range so the original is preserved. I’ll place mine in cells <code>J2:L22</code> of the current worksheet. I will also relabel my output and highlight the cells <code>K6:L6</code> and <code>K14</code> so that it’s clear they’ve been tampered with.</p>&#13;
&#13;
<p>Let’s manipulate the <a data-primary="sample size" data-secondary="effects of" data-type="indexterm" id="idm46274546903704"/>sample sizes and critical value here. Without looking at the resulting confidence interval, try to guess what will happen based on what you know about how these figures relate. First, I will set the sample size to 550 observations for each group. This is a dangerous game to play; we didn’t <em>actually</em> collect 550 observations, but to understand statistics you sometimes have to get your hands dirty. Next, we’ll change our statistical significance from 95% to 90%. The resulting critical value is 1.64. This is also dicey; statistical significance should be locked in prior to analysis for the reason that you are about to see right now.</p>&#13;
&#13;
<p><a data-type="xref" href="#what-if-analysis">Figure 3-7</a> displays the result of this what-if analysis. Our confidence interval of between $1 and $430 indicates <a data-primary="hypothesis testing" data-secondary="statistical significance in" data-type="indexterm" id="idm46274546900280"/><a data-primary="statistical significance" data-type="indexterm" id="idm46274546899320"/>statistical significance, although just barely—it’s awfully close to <a data-startref="ch3_term36" data-type="indexterm" id="idm46274546898504"/>zero.</p>&#13;
&#13;
<figure><div class="figure" id="what-if-analysis">&#13;
<img alt="t-test output" src="assets/aina_0307.png"/>&#13;
<h6><span class="label">Figure 3-7. </span>A what-if analysis of the confidence interval</h6>&#13;
</div></figure>&#13;
&#13;
<p>There are ways to calculate the corresponding p-value, but because you know it is always fundamentally in agreement with the confidence interval, we’ll skip that <a data-startref="ch3_term43" data-type="indexterm" id="idm46274546895080"/>exercise. Our test is now significant, and that can make all the difference for funding, fame, and glory.</p>&#13;
&#13;
<p>The moral of the story is that the results of hypothesis testing can be easily gamed. Sometimes, all it takes is a different level of statistical significance to tip the balance to rejecting the null. Resampling or, in our example, falsely bulking up the number of observations could also do it. Even absent foul play, there will always be a gray area in claiming to find the parameter of a population you don’t <a data-startref="ch3_term34" data-type="indexterm" id="idm46274546893304"/><a data-startref="ch3_term35" data-type="indexterm" id="idm46274546892600"/><a data-startref="ch3_term45" data-type="indexterm" id="idm46274546891928"/>actually know.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="It’s Your World…the Data’s Only Living in It" data-type="sect1"><div class="sect1" id="idm46274547097000">&#13;
<h1>It’s Your World…the Data’s Only Living in It</h1>&#13;
&#13;
<p>It’s tempting to go into autopilot when <a data-primary="inferential statistics" data-secondary="about" data-type="indexterm" id="ch3_term46"/>conducting inferential statistics, just plugging and chugging p-values without regard for broader considerations about <a data-primary="collecting data" data-type="indexterm" id="idm46274546888184"/><a data-primary="data collection concerns" data-type="indexterm" id="idm46274546887512"/>data collection or <a data-primary="substantive significance" data-type="indexterm" id="idm46274546886744"/><a data-primary="hypothesis testing" data-secondary="substantive significance in" data-type="indexterm" id="idm46274546886072"/>substantive significance. You’ve already seen how sensitive the results can be to changes in statistical significance or sample size. To show another possibility, let’s take one more <a data-primary="datasets" data-secondary="housing example" data-type="indexterm" id="idm46274546884776"/><a data-primary="housing dataset example" data-type="indexterm" id="idm46274546883832"/><a data-primary="hypothesis testing" data-secondary="housing dataset for" data-type="indexterm" id="idm46274546883160"/>example from the <em>housing</em> dataset.</p>&#13;
&#13;
<p>On your own, test for a significant difference in the sale price of homes with and without gas for water heating. The relevant variables are <em>price</em> and <em>gashw</em>. The results are shown in <a data-type="xref" href="#gas-t-test">Figure 3-8</a>.</p>&#13;
&#13;
<figure><div class="figure" id="gas-t-test">&#13;
<img alt="t-test output" src="assets/aina_0308.png"/>&#13;
<h6><span class="label">Figure 3-8. </span>t-test results of the effect on sale price of using gas</h6>&#13;
</div></figure>&#13;
&#13;
<p>Going by the p-value alone, we should fail to reject the null: after all, it’s greater than &#13;
<span class="keep-together">0.05.</span> But 0.067 is not <em>that</em> different, so it’s worth paying closer attention here. For one thing, consider the sample sizes: at just 25 observations of homes with gas, it may be worth collecting more data before definitively rejecting the null. <a data-startref="ch3_term38" data-type="indexterm" id="idm46274546875560"/><a data-startref="ch3_term39" data-type="indexterm" id="idm46274546874856"/>Granted, you probably would have observed this sample size prior to running the test, during descriptive statistics.</p>&#13;
&#13;
<p>By the same token, the <a data-primary="confidence intervals" data-secondary="in Excel" data-secondary-sortas="Excel" data-type="indexterm" id="idm46274546873544"/><a data-primary="data analytics" data-secondary="cautions with" data-type="indexterm" id="idm46274546872264"/><a data-primary="inferential statistics" data-secondary="uncertainty and" data-type="indexterm" id="idm46274546871320"/>confidence interval posits that the true difference is anywhere between approximately $900 less and $24,500 more. With that kind of money on the table, it’s worth digging further into the problem. If you were just to blindly reject the null due to the p-value, you may miss out on a potentially important relationship. Be aware of these potential “edge cases”: if one already came up here in this dataset, you can bet you’ll find more in your data work.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Statistics and analytics are powerful tools for making sense of the world, but they’re just that: tools. Without a skilled craftsperson in control, they can be useless at best and harmful at worst. Don’t be content to take the p-value on its face; consider the broader context of how statistics works and the objective you’re aiming to meet (without gaming the results, as you’ve seen is possible). Remember: it’s your world, the data’s only living in it.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm46274546868056">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>You may have been wondering earlier why, in a book on analytics, we&#13;
spent a chapter on the seemingly <a data-primary="probability" data-secondary="relevance of" data-type="indexterm" id="idm46274546866616"/>obscure topic of probability. I hope the connection is now clear: because we don’t know parameters of the population, we must quantify this uncertainty as a <a data-startref="ch3_term44" data-type="indexterm" id="idm46274546865336"/>probability. In this chapter, we’ve used the framework of inferential statistics and hypothesis testing to explore the difference in means between two <a data-startref="ch3_term46" data-type="indexterm" id="idm46274546864360"/>groups. In the next, we’ll use it to examine the influence of one continuous variable on another, in a method you may have heard of: linear regression. Although a different test, the statistical framework behind it remains the same.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Exercises" data-type="sect1"><div class="sect1" id="idm46274546863048">&#13;
<h1>Exercises</h1>&#13;
&#13;
<p>Now it’s your <a data-primary="inferential statistics" data-secondary="exercises" data-type="indexterm" id="idm46274546861240"/>turn to make probabilistic inferences about a dataset. Find the <em>tips.xlsx</em> dataset in the <em>datasets</em> folder and <em>tips</em> subfolder of the book’s <a href="https://oreil.ly/1hlYj">companion repository</a>, and try the following exercises:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Test the relationship between the time of day (lunch or dinner) and the total bill:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>What are your statistical hypotheses?</p>&#13;
</li>&#13;
<li>&#13;
<p>Are your results statistically significant? What evidence does this lend to your hypotheses?</p>&#13;
</li>&#13;
<li>&#13;
<p>What is the estimated effect size?</p>&#13;
</li>&#13;
</ul>&#13;
</li>&#13;
<li>&#13;
<p>Answer the same questions, but for the relationship between the time of day and the tip.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>