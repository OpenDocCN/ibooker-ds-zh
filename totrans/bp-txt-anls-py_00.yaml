- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The written word is a powerful thing. The ancient Sumerians invented the first
    written language, and the introduction of the Gutenberg press allowed the written
    word to spread knowledge and enlightenment across the world. Language is in fact
    so important to human thinking that anthropologists claim that our ability for
    complex reasoning evolved at the same time that we developed language. Language
    represented in the form of text captures most of human thought, deeds, and actions,
    and our life is increasingly dominated by it. We communicate with colleagues through
    emails, with friends and family via messengers, and with others who share our
    passions using social media tools. Leaders inspire huge populations through speeches
    (and tweets) that are recorded as text, leading researchers communicate their
    findings via published research papers, and companies communicate their health
    through quarterly reports. Even this book uses text to spread knowledge. Analyzing
    and understanding text gives us the ability to gain knowledge and make decisions.
    Text analytics is about writing computer programs that can analyze vast amounts
    of information available in the form of text. Before making a product purchase
    or visiting a restaurant, we read customer reviews. A company could then use the
    same reviews to improve their product or service. A publisher could analyze discussions
    on the internet to estimate the demand for a certain programming language before
    commissioning a book on it.
  prefs: []
  type: TYPE_NORMAL
- en: It is much harder for a computer to understand text compared to other types
    of data. While there are rules of grammar and guidelines to forming sentences,
    these are often not strictly followed and depend heavily on context. Even with
    the correct grammar, it is hard for a machine to interpret the text correctly.
    The words that a person chooses while tweeting would be quite different from writing
    an email to express the same thought. There have been recent advances in statistical
    techniques and machine learning algorithms that allow us to get past many of these
    obstacles to derive value from text data. New models are able to capture the semantic
    meaning of text better than previous approaches based on word frequencies alone.
    But there are also many business tasks where these simple models perform surprisingly
    well.
  prefs: []
  type: TYPE_NORMAL
- en: In one of our client projects, for example, a home appliance manufacturer was
    able to understand the key topics affecting customer purchases by analyzing product
    reviews and adjust their marketing message to focus on these aspects. In another
    case, an e-commerce retailer used a deep neural network to classify customer queries
    and route them to the correct department for faster resolution. Analyzing abstracts
    from scientific journals has allowed an R&D company to detect trends in new materials
    and adjust their research accordingly. A fashion company identified mega-topics
    in their customer group by taking a look at posts in social networks. With this
    book we have tried to transfer our experiences from these and many other projects
    into blueprints that you can easily reuse in your own projects.
  prefs: []
  type: TYPE_NORMAL
- en: Approach of the Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is intended to support data scientists and developers so they can
    quickly enter the area of text analytics and natural language processing. Thus,
    we put the focus on developing practical solutions that can serve as blueprints
    in your daily business. A blueprint, in our definition, is a best-practice solution
    for a common problem. It is a template that you can easily copy and adapt for
    reuse. For these blueprints we use production-ready Python frameworks for data
    analysis, natural language processing, and machine learning. Nevertheless, we
    also introduce the underlying models and algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: We do not expect any previous knowledge in the field of natural language processing
    but provide you with the necessary background knowledge to get started quickly.
    In each chapter, we explain and discuss different solution approaches for the
    respective tasks with their potential strengths and weaknesses. Thus, you will
    not only acquire the knowledge about how to solve a certain kind of problem but
    also get a set of ready-to-use blueprints that you can take and customize to your
    data and requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Each of the 13 chapters includes a self-contained use case for a specific aspect
    of text analytics (see [Table P-1](#preface_approach_table)). Based on an example
    dataset, we develop and explain the blueprints step by step.
  prefs: []
  type: TYPE_NORMAL
- en: Table P-1\. Overview of the chapters
  prefs: []
  type: TYPE_NORMAL
- en: '| Chapter | Dataset | Libraries |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 1, *Gaining Early Insights from Textual Data*](ch01.xhtml#ch-exploration)Getting
    started with the statistical exploration of textual data | UN General Debates
    | Pandas, Regex |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 2, *Extracting Textual Insights with APIs*](ch02.xhtml#ch-api)Using
    different Python modules to extract data from popular APIs | GitHub, Twitter,
    and Wikipedia API | Requests, Tweepy |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 3, *Scraping Websites and Extracting Data*](ch03.xhtml#ch-scraping)Using
    Python libraries to download web pages and extract content | Reuters website |
    Requests, Beautiful Soup, Readability-lxml, Scrapy |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 4, *Preparing Textual Data for Statistics and Machine Learning*](ch04.xhtml#ch-preparation)Introduction
    to data cleaning and linguistic processing | Reddit Selfposts | Regex, spaCy |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 5, *Feature Engineering and Syntactic Similarity*](ch05.xhtml#ch-vectorization)Introduction
    to features and vectorization | 1 million headlines from ABC News | scikit-learn,
    NumPy |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 6, *Text Classification Algorithms*](ch06.xhtml#ch-classification).
    Text Classification AlgorithmsUsing machine learning algorithms to classify software
    bugs | Java Development Tools bug reports | scikit-learn |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 7, *How to Explain a Text Classifier*](ch07.xhtml#ch-explain)Explaining
    models and classification results | Java Development Tools bug reports | scikit-learn,
    Lime, Anchor, ELI5 |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 8, *Unsupervised Methods: Topic Modeling and Clustering*](ch08.xhtml#ch-topicmodels)Using
    unsupervised methods to gain unbiased insights into text | UN General Debates
    | scikit-learn, Gensim |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 9, *Text Summarization*](ch09.xhtml#ch-summarization)Creating short
    summaries of news articles and forum threads using rule-based and machine learning
    approaches | Reuters News articles, Travel Forum threads | Sumy, scikit-learn
    |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 10, *Exploring Semantic Relationships with Word Embeddings*](ch10.xhtml#ch-embeddings)Using
    word embeddings to explore and visualize semantic similarities in a specific data
    set | Reddit Selfposts | Gensim |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 11, *Performing Sentiment Analysis on Text Data*](ch11.xhtml#ch-sentiment)Identifying
    customer sentiment in Amazon product reviews | Amazon product reviews | Transformers,
    scikit-learn, NLTK |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 12, *Building a Knowledge Graph*](ch12.xhtml#ch-knowledge)How to
    extract named entities and their relationships using pretrained models and custom
    rules | Reuters news on mergers and acquisitions | spaCy |'
  prefs: []
  type: TYPE_TB
- en: '| [Chapter 13, *Using Text Analytics in Production*](ch13.xhtml#ch-production)Deploy
    and scale the sentiment analysis blueprint as an API on Google Cloud Platform
    |  | FastAPI, Docker, conda, Kubernetes, gcloud |'
  prefs: []
  type: TYPE_TB
- en: The choice of topics reflects the most common types of problems in our daily
    text analytics work. Typical tasks include data acquisition, statistical data
    exploration, and the use of supervised and unsupervised machine learning. The
    business questions range from content analysis (“What are people talking about?”)
    to automatic text categorization.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book you will learn how to solve text analytics problems efficiently
    with the Python ecosystem. We will explain all concepts specific to text analytics
    and machine learning in detail but assume that you already have basic knowledge
    of Python, including fundamental libraries like Pandas. You should also be familiar
    with Jupyter notebooks so that you can experiment with the code while reading
    the book. If not, check out the tutorials on [*learnpython.org*](https://www.learnpython.org/),
    [*docs.python.org*](https://docs.python.org/3/tutorial), or [DataCamp](https://oreil.ly/oB-eH).
  prefs: []
  type: TYPE_NORMAL
- en: Even though we explain the general ideas of the algorithms used, we won’t go
    too much into the details. You should be able to follow the examples and reuse
    the code without completely understanding the mathematics behind it. College-level
    knowledge of linear algebra and statistics is helpful, though.
  prefs: []
  type: TYPE_NORMAL
- en: Some Important Libraries to Know
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every data analytics project starts with data exploration and data processing.
    The most popular Python library for those tasks is definitely [*Pandas*](https://pandas.pydata.org).
    It offers rich functionality to access, transform, analyze, and visualize data.
    If you have never worked with this framework, we recommend checking out the official
    introduction, [*10 minutes to Pandas*](https://oreil.ly/eWlId), or one of the
    other free tutorials available on the internet before reading the book.
  prefs: []
  type: TYPE_NORMAL
- en: For years, [*scikit-learn*](https://scikit-learn.org) has been the machine learning
    toolkit for Python. It implements a large variety of supervised and unsupervised
    machine learning algorithms as well as many functions for data preprocessing.
    We use scikit-learn in several of the chapters to transform text into numerical
    vectors and for text classification.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to deep neural models, however, frameworks like PyTorch or TensorFlow
    are clearly superior to scikit-learn. Instead of using those libraries directly,
    we use the [*Transformers library*](https://oreil.ly/f5Ped) from Hugging Face
    in [Chapter 11](ch11.xhtml#ch-sentiment) for sentiment analysis. Since the publication
    of BERT,^([1](preface01.xhtml#idm45634210878232)) transformer-based models outperform
    previous approaches on tasks that require an understanding of the meaning of text,
    and the Transformers library provides easy access to many pretrained models.
  prefs: []
  type: TYPE_NORMAL
- en: Our favorite library for natural language processing is *spaCy*. Since its first
    release in 2016, spaCy enjoys a constantly growing user base. Though open source,
    it is primarily developed by the company [Explosion](https://explosion.ai). Pretrained
    neural language models for part-of-speech tagging, dependency parsing, and named-entity
    recognition are available for many languages. We used spaCy version 2.3.2 for
    the development of this book, especially for data preparation ([Chapter 4](ch04.xhtml#ch-preparation))
    and knowledge extraction ([Chapter 12](ch12.xhtml#ch-knowledge)). At the time
    of publication, spaCy 3.0 will be out with completely new, transformer-based models,
    support for custom models in PyTorch and TensorFlow, and templates for defining
    end-to-end workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Another NLP library we use is [Gensim](https://oreil.ly/YJ4Pz), which is maintained
    by Radim Řehůřek. Gensim puts the focus on semantic analysis and provides all
    that is necessary to learn topic models ([Chapter 8](ch08.xhtml#ch-topicmodels))
    and word embeddings ([Chapter 10](ch10.xhtml#ch-embeddings)).
  prefs: []
  type: TYPE_NORMAL
- en: There are many other libraries for natural language processing that can be helpful
    but are not or only briefly mentioned in the book. These include NLTK (feature-rich
    grandfather of Python NLP libraries), TextBlob (easy to get started), Stanford’s
    Stanza and CoreNLP, as well as Flair (state-of-the-art models for advanced tasks).
    Our goal was not to give an overview on everything that’s out there but to choose
    and explain those libraries that worked best in our projects.
  prefs: []
  type: TYPE_NORMAL
- en: Books to Read
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we focus on practical solutions for our use cases, you might want to check
    out some additional books for further details or topics we did not cover. Below
    you will find some recommendations for books to read alongside this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Practical Natural Language Processing*](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/)
    by Sowmya Vajjala, Bodhisattwa Majumder, Anuj Gupta, and Harshit Surana (O’Reilly,
    2020), ISBN 978-1-492-05405-4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Natural Language Processing in Action*](https://www.oreilly.com/library/view/natural-language-processing/9781617294631/)
    by Hobson Lane, Cole Howard, and Hannes Hapke (Manning Publications, 2019), ISBN
    978-1-617-29463-1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Mining the Social Web*, 3rd Edition](https://www.oreilly.com/library/view/mining-the-social/9781491973547/)
    by Matthew A. Russell and Mikhail Klassen (O’Reilly, 2019), ISBN 978-1-491-98504-5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Applied Text Analysis with Python*](https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/)
    by Benjamin Bengfort, Rebecca Bilbro, and Tony Ojeda (O’Reilly 2018), ISBN 978-1-491-96304-3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Python for Data Analysis*, 2nd Edition](https://www.oreilly.com/library/view/python-for-data/9781491957653/)
    by Wes McKinney (O’Reilly, 2017), ISBN 978-1-491-95766-0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conventions Used in This Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following typographical conventions are used in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Italic*'
  prefs: []
  type: TYPE_NORMAL
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  prefs: []
  type: TYPE_NORMAL
- en: '`Constant width`'
  prefs: []
  type: TYPE_NORMAL
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  prefs: []
  type: TYPE_NORMAL
- en: '**`Constant width bold`**'
  prefs: []
  type: TYPE_NORMAL
- en: Shows commands or other text that should be typed literally by the user.
  prefs: []
  type: TYPE_NORMAL
- en: '*`Constant width italic`*'
  prefs: []
  type: TYPE_NORMAL
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element signifies a tip or suggestion.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element signifies a general note.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element indicates a warning or caution.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element indicates a blueprint.
  prefs: []
  type: TYPE_NORMAL
- en: Using Code Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The whole purpose of a blueprint is to be copied. Thus, we provide all the code
    developed in this book in our [GitHub repository](https://oreil.ly/btap-code).
  prefs: []
  type: TYPE_NORMAL
- en: For each chapter, you will find an executable Jupyter notebook with the code
    from the book and possibly some additional functions or blueprints that have been
    omitted. The repository also contains the necessary datasets and some additional
    information.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to run the notebooks is on [Google Colab](https://oreil.ly/colab),
    Google’s public cloud platform for machine learning. You don’t even have to install
    Python on your local computer; just click on the Colab link for the respective
    chapter on GitHub (Google account required). However, we also added instructions
    for setting up your own (virtual) Python environment in the GitHub repository.
    We designed the Jupyter notebooks in a way that allows you to run them both locally
    and on Google Colab.
  prefs: []
  type: TYPE_NORMAL
- en: Libraries, data, and websites are subject to continuous change. Therefore, it
    can easily happen that the verbatim code in the book will not run properly in
    the future. To overcome this, we will keep the repository up to date. If you discover
    any technical problems or have recommendations on how to improve the code, do
    not hesitate to create an issue in the repository or send us a pull request.
  prefs: []
  type: TYPE_NORMAL
- en: If you have a technical question or a problem using the code examples, please
    email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com). In the
    case of technical problems, we recommend [creating an issue in the GitHub repo](https://oreil.ly/ApUgF)
    and refer to O’Reilly’s errata page for errors in the book.
  prefs: []
  type: TYPE_NORMAL
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing examples
    from O’Reilly books does require permission. Answering a question by citing this
    book and quoting example code does not require permission. Incorporating a significant
    amount of example code from this book into your product’s documentation does require
    permission.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may use our code freely in your own projects without asking for permission.
    Especially if you publicly republish our code, we appreciate attribution. An attribution
    usually includes the title, author, publisher, and ISBN. For example: “*Blueprints
    for Text Analytics Using Python* by Jens Albrecht, Sidharth Ramachandran, and
    Christian Winkler (O’Reilly, 2021), 978-1-492-07408-3.”'
  prefs: []
  type: TYPE_NORMAL
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: O’Reilly Online Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For more than 40 years, [*O’Reilly Media*](http://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*http://oreilly.com*](http://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: How to Contact Us
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please address comments and questions concerning this book to the publisher:'
  prefs: []
  type: TYPE_NORMAL
- en: O’Reilly Media, Inc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1005 Gravenstein Highway North
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sebastopol, CA 95472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 800-998-9938 (in the United States or Canada)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-829-0515 (international or local)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-829-0104 (fax)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/text-analytics-with-python*](https://oreil.ly/text-analytics-with-python).
  prefs: []
  type: TYPE_NORMAL
- en: Email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com) to comment
    or ask technical questions about this book.
  prefs: []
  type: TYPE_NORMAL
- en: For news and information about our books and courses, visit [*http://oreilly.com*](http://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: 'Find us on Facebook: [*http://facebook.com/oreilly*](http://facebook.com/oreilly)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow us on Twitter: [*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Watch us on YouTube: [*http://youtube.com/oreillymedia*](http://youtube.com/oreillymedia)'
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Writing a book is a challenge, not only for the authors but also for their families
    and friends. All of us expected that it would take a lot of time, but still we
    were surprised by how much time we needed to develop the stories for each of the
    chapters. As we are all working full-time jobs, the time for discussing, coding,
    writing, and rewriting had to be taken from our families.
  prefs: []
  type: TYPE_NORMAL
- en: Working with O’Reilly has been a great pleasure for all of us. From the original
    proposal, during the time of writing, and in the production phase, we enjoyed
    working with professionals and immensely benefited from their hints and suggestions.
    The most intense time for us was writing the individual chapters. During that,
    we were perfectly supported by our development editor, Amelia Blevins. Without
    her help and improvements, the book would have been stuck in a less-readable state.
  prefs: []
  type: TYPE_NORMAL
- en: We would also like to express our gratitude to our reviewers, Oliver Zeigermann,
    Benjamin Bock, Alexander Schneider, and Darren Cook. They used their expertise
    and a lot of their time to make excellent suggestions and improvements and also
    to find errors in the text and the notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: As we used state-of-the-art features of libraries, we sometimes encountered
    problems or incompatibilities. With spaCy as a central component in our analytics
    pipeline, working with the super responsive team from Explosion (Ines Montani,
    Sofie Van Landeghem, and Adriane Boyd) was a great pleasure. Their comments on
    the sections covering spaCy have been extremely helpful. Thanks also to Burton
    DeWilde, the developer behind textacy, for checking parts of the code.
  prefs: []
  type: TYPE_NORMAL
- en: '^([1](preface01.xhtml#idm45634210878232-marker)) Devlin, Jacob, et al., “BERT:
    Pre-training of Deep Bidirectional Transformers for Language Understanding.” 2018\.
    [*https://arxiv.org/abs/1810.04805*](https://arxiv.org/abs/1810.04805).'
  prefs: []
  type: TYPE_NORMAL
