["```py\nimport spacy\n\n```", "```py\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n<ipython-input-1-76a01d9c502b> in <module>\n----> 1 import spacy\nModuleNotFoundError: No module named 'spacy'\n\n```", "```py\nconda create -n env_name [list_of_packages]\n```", "```py\n$ conda create -n blueprints numpy pandas scikit-learn notebook python=3.8\nCollecting package metadata (current_repodata.json): - done\nSolving environment: \\ done\n Package Plan\n  environment location: /home/user/miniconda3/envs/blueprints\n  added / updated specs:\n    - notebook\n    - numpy\n    - pandas\n    - python=3.8\n    - scikit-learn\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    blas-1.0                   |              mkl           6 KB\n    intel-openmp-2020.1        |              217         780 KB\n    joblib-0.16.0              |             py_0         210 KB\n    libgfortran-ng-7.3.0       |       hdf63c60_0        1006 KB\n    mkl-2020.1                 |              217       129.0 MB\n    mkl-service-2.3.0          |   py37he904b0f_0         218 KB\n    mkl_fft-1.1.0              |   py37h23d657b_0         143 KB\n    mkl_random-1.1.1           |   py37h0573a6f_0         322 KB\n    numpy-1.18.5               |   py37ha1c710e_0           5 KB\n    numpy-base-1.18.5          |   py37hde5b4d6_0         4.1 MB\n    pandas-1.0.5               |   py37h0573a6f_0         7.8 MB\n    pytz-2020.1                |             py_0         184 KB\n    scikit-learn-0.23.1        |   py37h423224d_0         5.0 MB\n    scipy-1.5.0                |   py37h0b6359f_0        14.4 MB\n    threadpoolctl-2.1.0        |     pyh5ca1d4c_0          17 KB\n    ------------------------------------------------------------\n                                           Total:       163.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n  attrs              pkgs/main/noarch::attrs-19.3.0-py_0\n  backcall           pkgs/main/noarch::backcall-0.2.0-py_0\n  blas               pkgs/main/linux-64::blas-1.0-mkl\n  bleach             pkgs/main/noarch::bleach-3.1.5-py_0\n  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.6.24-0\n\n(Output truncated)\n\n```", "```py\n$ conda activate blueprints\n(blueprints) $ python --version\nPython 3.8\n\n```", "```py\n(blueprints) $ conda env list\n# conda environments:\n#\nbase                     /home/user/miniconda3\nblueprints            *  /home/user/miniconda3/envs/blueprints\n\n```", "```py\n(blueprints) $ conda env export > environment.yml\n(blueprints) $ cat environment.yml\nname: blueprints\nchannels:\n  - defaults\ndependencies:\n  - _libgcc_mutex=0.1=main\n  - attrs=19.3.0=py_0\n  - backcall=0.2.0=py_0\n  - blas=1.0=mkl\n  - bleach=3.1.5=py_0\n  - ca-certificates=2020.6.24=0\n  - certifi=2020.6.20=py37_0\n  - decorator=4.4.2=py_0\n  - defusedxml=0.6.0=py_0\n  - entrypoints=0.3=py37_0\n  - importlib-metadata=1.7.0=py37_0\n  - importlib_metadata=1.7.0=0\n  - intel-openmp=2020.1=217\n  - ipykernel=5.3.0=py37h5ca1d4c_0\n(output truncated)\n\n```", "```py\n(blueprints) $ conda env export --from-history > environment.yml\n(blueprints) $ cat environment.yml\nname: blueprints\nchannels:\n  - defaults\ndependencies:\n  - scikit-learn\n  - pandas\n  - notebook\n  - python=3.8\n  - numpy\nprefix: /home/user/miniconda3/envs/blueprints\n\n```", "```py\n$ sudo docker run hello-world\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1\\. The Docker client contacted the Docker daemon.\n 2\\. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3\\. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4\\. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n\n```", "```py\n$ sudo docker search miniconda\nNAME                                        STARS\ncontinuumio/miniconda3                      218\ncontinuumio/miniconda                       77\nconda/miniconda3                            35\nconda/miniconda3-centos7                    7\nyamitzky/miniconda-neologd                  3\nconda/miniconda2                            2\natavares/miniconda-rocker-geospatial        2\n\n```", "```py\nFROM continuumio/miniconda3\n\n# Add environment.yml to the build context and create the environment\nARG conda_env=blueprints\nADD environment.yml /tmp/environment.yml\nRUN conda env create -f /tmp/environment.yml\n\n```", "```py\n# Activating the environment and starting the jupyter notebook\nRUN echo \"source activate ${conda_env}\" > ~/.bashrc\nENV PATH /opt/conda/envs/${conda_env}/bin:$PATH\n\n```", "```py\n# Start jupyter server on container\nEXPOSE 8888\nENTRYPOINT [\"jupyter\",\"notebook\",\"--ip=0.0.0.0\", \\\n      \"--port=8888\",\"--allow-root\",\"--no-browser\"]\n\n```", "```py\ndocker build -t username/docker_project -f Dockerfile [PATH]\n```", "```py\n$ sudo docker build -t textblueprints/ch13:v1 .\nSending build context to Docker daemon  5.363MB\nStep 1/8 : FROM continuumio/miniconda3\n ---> b4adc22212f1\nStep 2/8 : ARG conda_env=blueprints\n ---> 959ed0c16483\nStep 3/8 : ADD environment.yml /tmp/environment.yml\n ---> 60e039e09fa7\nStep 4/8 : RUN conda env create -f /tmp/environment.yml\n ---> Running in 85d2f149820b\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\n(output truncated)\n\nRemoving intermediate container 85d2f149820b\nStep 5/8 : RUN echo \"source activate ${conda_env}\" > ~/.bashrc\n ---> e0ed2b448211\nStep 6/8 : ENV PATH /opt/conda/envs/${conda_env}/bin:$PATH\n ---> 7068395ce2cf\nStep 7/8 : EXPOSE 8888\n ---> Running in f78ac4aa0569\nRemoving intermediate container f78ac4aa0569\n ---> 06cfff710f8e\nStep 8/8 : ENTRYPOINT [\"jupyter\",\"notebook\",\"--ip=0.0.0.0\",\n                       \"--port=8888\",\"--allow-root\",\"--no-browser\"]\n ---> Running in 87852de682f4\nRemoving intermediate container 87852de682f4\n ---> 2b45bb18c071\nSuccessfully built 2b45bb18c071\nSuccessfully tagged textblueprints/ch13:v1\n\n```", "```py\n$ sudo docker images\nREPOSITORY                          TAG                 IMAGE ID\ntextblueprints/ch13                 v1                  83a05579afe6\njupyter/minimal-notebook            latest              d94723ae86d1\ncontinuumio/miniconda3              latest              b4adc22212f1\nhello-world                         latest              bf756fb1ae65\n\n```", "```py\ndocker run -p host_port:container_port username/docker_project:tag_name\n```", "```py\nsudo docker run -p 5000:8888 -v \\\n/home/user/text-blueprints/ch13/:/work textblueprints/ch13:v1\n```", "```py\n[NotebookApp] Writing notebook server cookie secret to\n/root/.local/share/jupyter/runtime/notebook_cookie_secret\n[NotebookApp] Serving notebooks from local directory: /\n[NotebookApp] The Jupyter Notebook is running at:\n[NotebookApp] http://aaef990b90a3:8888/?token=xxxxxx\n[NotebookApp]  or http://127.0.0.1:8888/?token=xxxxxx\n[NotebookApp] Use Control-C to stop this server and shut down all kernels\n(twice to skip confirmation).\n[NotebookApp]\n\n    To access the notebook, open this file in a browser:\n        file:///root/.local/share/jupyter/runtime/nbserver-1-open.html\n    Or copy and paste one of these URLs:\n        http://aaef990b90a3:8888/?token=xxxxxx\n     or http://127.0.0.1:8888/?token=xxxxxx\n\n```", "```py\n$ sudo docker container ls\nCONTAINER ID        IMAGE                    STATUS              NAMES\n862e5b0570fe        textblueprints/ch13:v1   Up About a minute   musing_chaum\n\n```", "```py\n  .git\n  .cache\n  figures\n  **/*.html\n  **/*.ipynb\n  **/*.css\n\n```", "```py\n├── app\n│   ├── main.py\n│   ├── Dockerfile\n│   ├── environment.yml\n│   ├── models\n│   │   ├── sentiment_classification.pickle\n│   │   └── sentiment_vectorizer.pickle\n│   ├── preprocessing.py\n│   └── start_script.sh\n\n```", "```py\nfrom fastapi import FastAPI\napp = FastAPI()\n\n```", "```py\nclass Sentiment(Enum):\n    POSITIVE = 1\n    NEGATIVE = 0\n\n@app.post(\"/api/v1/sentiment\", response_model=Review)\ndef predict(review: Review, model = Depends(load_model())):\n    text_clean = preprocessing.clean(review.text)\n    text_tfidf = vectorizer.transform([text_clean])\n    sentiment = prediction_model.predict(text_tfidf)\n    review.sentiment = Sentiment(sentiment.item()).name\n    return review\n\n```", "```py\nclass Review(BaseModel):\n    text: str\n    reviewerID: Optional[str] = None\n    asin: Optional[str] = None\n    sentiment: Optional[str] = None\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"text\": \"This was a great purchase, saved me much time!\",\n                \"reviewerID\": \"A1VU337W6PKAR3\",\n                \"productID\": \"B00K0TIC56\"\n            }\n        }\n\n```", "```py\ndef load_model():\n    try:\n        print('Calling Depends Function')\n        global prediction_model, vectorizer\n        prediction_model = pickle.load(\n            open('models/sentiment_classification.pickle', 'rb'))\n        vectorizer = pickle.load(open('models/tfidf_vectorizer.pickle', 'rb'))\n        print('Models have been loaded')\n    except Exception as e:\n        raise ValueError('No model here')\n\n```", "```py\ngunicorn -w 3 -b :5000 -t 5 -k uvicorn.workers.UvicornWorker main:app\n```", "```py\nvulture app/\n\n```", "```py\napp/main.py:11: unused variable 'POSITIVE' (60% confidence)\napp/main.py:12: unused variable 'NEGATIVE' (60% confidence)\napp/main.py:16: unused variable 'reviewerID' (60% confidence)\napp/main.py:17: unused variable 'asin' (60% confidence)\napp/main.py:20: unused class 'Config' (60% confidence)\napp/main.py:21: unused variable 'schema_extra' (60% confidence)\napp/main.py:40: unused variable 'model' (100% confidence)\napp/main.py:44: unused attribute 'sentiment' (60% confidence)\napp/preprocessing.py:30: unused import 'spacy' (90% confidence)\napp/preprocessing.py:34: unused function 'display_nlp' (60% confidence)\n\n```", "```py\nname: sentiment-app\nchannels:\n  - conda-forge\ndependencies:\n  - python==3.8\n  - fastapi==0.59.0\n  - pandas==1.0.5\n  - scikit-learn==0.23.2\n  - gunicorn==20.0.4\n  - uvicorn==0.11.3\n\n```", "```py\n# Copy files required for deploying service to app folder in container\nCOPY . /app\nWORKDIR /app\n\n```", "```py\n# Start WSGI server on container\nEXPOSE 5000\nRUN [\"chmod\", \"+x\", \"start_script.sh\"]\nENTRYPOINT [ \"/bin/bash\", \"-c\" ]\nCMD [\"./start_script.sh\"]\n\n```", "```py\n#!/bin/bash\nsource activate my_env_name\nGUNICORN_CMD_ARGS=\"--access-logfile -\" gunicorn -w 3 -b :5000 -t 5 \\\n          -k uvicorn.workers.UvicornWorker main:app -\n\n```", "```py\n$ sudo docker run -p 5000:5000 textblueprints/sentiment-app:v1\n    [INFO] Starting gunicorn 20.0.4\n    [INFO] Listening at: http://0.0.0.0:5000 (11)\n    [INFO] Using worker: sync\n    [INFO] Booting worker with pid: 14\n\n```", "```py\nimport requests\nimport json\n\nurl = 'http://0.0.0.0:5000/api/v1/sentiment'\ndata = {\n    'text':\n    'I could not ask for a better system for my small greenhouse, \\\n easy to set up and nozzles do very well',\n    'reviewerID': 'A1VU337W6PKAR3',\n    'productID': 'B00K0TIC56'\n}\ninput_data = json.dumps(data)\nheaders = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\nr = requests.post(url, data=input_data, headers=headers)\nprint(r.text)\n\n```", "```py\n{\n  \"prediction\": \"POSITIVE\"\n}\n\n```", "```py\ngcloud components install kubectl\n```", "```py\ngcloud config set project sentiment-rest-api\n```", "```py\ngcloud config set compute/zone us-central1-a\n```", "```py\ngcloud container clusters create \\  sentiment-app-cluster --num-nodes 3 \\\n--machine-type n1-standard-1\n```", "```py\n$ gcloud compute instances list\nNAME                                   ZONE           MACHINE_TYPE   STATUS\ngke-sentiment-app-cluste-default-pool  us-central1-a  n1-standard-1  RUNNING\ngke-sentiment-app-cluste-default-pool  us-central1-a  n1-standard-1  RUNNING\ngke-sentiment-app-cluste-default-pool  us-central1-a  n1-standard-1  RUNNING\n\n```", "```py\nkubectl create deployment sentiment-app --image=textblueprints/sentiment-app:v0.1\n```", "```py\nkubectl scale deployment sentiment-app --replicas=3\n```", "```py\nkubectl expose deployment sentiment-app --name=sentiment-app-loadbalancer\n--type=LoadBalancer --port 5000 --target-port 5000\n```", "```py\n$ kubectl expose deployment sentiment-app --name=sentiment-app-loadbalancer \\\n--type=LoadBalancer --port 5000 --target-port 5000\nservice \"sentiment-app-loadbalancer\" exposed\n$ kubectl get service\nNAME                         TYPE           CLUSTER-IP    EXTERNAL-IP\nkubernetes                   ClusterIP      10.3.240.1    <none>\nsentiment-app-loadbalancer   LoadBalancer   10.3.248.29   34.72.142.113\n\n```", "```py\nkubectl delete service sentiment-app-loadbalancer\n```", "```py\ngcloud container clusters delete sentiment-app-cluster\n```", "```py\nname: sentiment-app-deploy\n\non:\n  push:\n    tags:\n      - '*'\n\njobs:\n  build:\n    name: build\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n\n```", "```py\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: build and push image\n      uses: docker/build-push-action@v1\n      with:\n        username: ${{ secrets.DOCKER_USERNAME }}\n        password: ${{ secrets.DOCKER_PASSWORD }}\n        repository: sidhusmart/sentiment-app\n        tag_with_ref: true\n        add_git_labels: true\n        push: ${{ startsWith(github.ref, 'refs/tags/') }}\n\n    - name: Get the Tag Name\n      id: source_details\n      run: |-\n        echo ::set-output name=TAG_NAME::${GITHUB_REF#refs/tags/}\n\n```", "```py\n    # Setup gcloud CLI\n    - uses: GoogleCloudPlatform/github-actions/setup-gcloud@master\n      with:\n        version: '290.0.1'\n        service_account_key: ${{ secrets.GCLOUD_AUTH }}\n        project_id: ${{ secrets.PROJECT_ID }}\n\n    # Get the GKE credentials so we can deploy to the cluster\n    - run: |-\n        gcloud container clusters get-credentials ${{ secrets.CLUSTER_NAME }} \\\n                                           --zone ${{ secrets.LOCATION_ZONE }}\n\n```", "```py\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        kubectl set image --record deployment.apps/sentiment-app \\\n                  sentiment-app=textblueprints/sentiment-app:\\\n                  ${{ steps.source_details.outputs.TAG_NAME }}\n\n    # Verify that deployment completed\n    - name: Verify Deployment\n      run: |-\n        kubectl rollout status deployment.apps/sentiment-app\n        kubectl get services -o wide\n\n```"]