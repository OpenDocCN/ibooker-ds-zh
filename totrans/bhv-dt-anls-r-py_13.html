<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 9. Stratified Randomization"><div class="chapter" id="stratified_randomizatio">
<h1><span class="label">Chapter 9. </span>Stratified Randomization</h1>
<p>In the previous chapter, we saw the simplest form of randomization: a customer shows up, and we toss a metaphorical coin or dice. Heads and they see version A, tails and they see version B. The probabilities may be different from 50/50, but they are constant, and independent of the customer characteristics. <a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="stratified randomization" data-tertiary="about" id="idm45968150984872"/><a contenteditable="false" data-type="indexterm" data-primary="random assignment" data-secondary="pitfalls of" data-seealso="stratified randomization" id="idm45968150983416"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="about" id="idm45968150981960"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="about" id="idm45968150980744"/>No “my control group is a bit older than my treatment group, let’s make sure the next Millennial who shows up goes into the control group.” As a consequence, your control and treatment groups are “probabilistically equivalent,” which is statistics’ way of saying that if you kept running your experiment forever, your two groups would have the exact same proportions as your general population. In practice, however, your experimental groups; can end up being quite different from each other. Adding explanatory variables to your final analysis can somewhat compensate for these imbalances, but as we’ll now see, we can do better than that if we know ahead of time who is going to be part of our experiment.</p>
<p>In this chapter, I’ll introduce you to stratified randomization, which will allow us to ensure that our experimental groups are as similar as possible. <a contenteditable="false" data-type="indexterm" data-primary="statistical power" data-secondary="stratified randomization increasing" id="idm45968150977864"/><a contenteditable="false" data-type="indexterm" data-primary="sample size" data-secondary="stratified randomization increasing statistical power" id="idm45968150976648"/>This starkly increases the explanatory power of an experiment, which is especially useful when you can’t have large sample sizes.</p>
<p>Stratified randomization can be applied to any situation where we have a predetermined list of customers/employees/etc. to build our experimental groups from. Given that A/B tests are most often discussed in relation to minor changes to an email or website, I could have taken the example of an email campaign. But I wanted to demonstrate that larger business initiatives, which are often taken by company executives based on their “strategic sense,” can also be tested and validated.</p>
<p>The business context here is that by default, <a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="stratified randomization" data-tertiary="about business problem" id="idm45968150973880"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="about business problem" id="idm45968150972424"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="about business problem" id="idm45968150971208"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="about booking profit versus CX" id="idm45968150969752"/>AirCnC gives owners at least 24 hours to clean their property between two bookings. In high-demand markets where properties are booked as soon as they’re available, this represents a significant limiting <span class="keep-together">factor.</span> Business leaders are keen to reduce it and increase monthly profit per property. As is often the case, there are two schools of thought in the company:</p>
<ul>
<li><p>The finance department advocates offering owners the opportunity to set a minimum duration of two nights per booking.</p></li>
<li><p>The customer experience department believes a minimum duration would adversely impact customer satisfaction; instead, it advocates offering owners the services of a professional cleaning company for free in exchange for a reduction of the cleaning window from 24 to 8 hours.</p></li>
</ul>
<p>Situations like this often arise in business. Both sides have somewhat compelling arguments that speak to different aspects of the problem or emphasize different metrics (here, booking profit versus customer experience), and/or provide anecdotal evidence in favor of their position (“this other company does X, so we should do it too”). A common outcome is that whoever has the most sway “wins” and their solution gets implemented, a.k.a. organizational politics rule.</p>
<p>At this point, you probably expect me to say something along the lines <a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="bypassing political problems" id="idm45968150964296"/>of “but experimentation allows you to bypass all politics and reach the best solution without any fuss.” I wish it were that easy! The truth is that experimentation can be of tremendous help in such situations, but it’s not a cure-all, for two reasons.</p>
<p>The first reason is that unless a solution turns out to be superior to the other on all fronts, there will be some genuine trade-offs that need to be made between competing objectives: how much decrease in customer satisfaction is the company willing to tolerate for an increase in profit? That question is inherently political because different stakeholders in the company have different preferences on that matter. You’ll have to present these trade-offs as clearly as possible to your leaders and get them resolved as much as possible ahead of time if you want your experiment to be successful.</p>
<p>The second reason is that your experiment will make at most one side happy (it can also make both sides unhappy if the control group has the best outcomes!). Unhappy business leaders, like any other unhappy human being, can be very good at finding rationalizations after the fact: “The San Francisco Bay area is different from other high-demand markets,” “Survey-measured customer satisfaction is down, but Net Promoter Score is up, and NPS is a better measure of ‘true’ customer satisfaction,” etc.</p>
<p>These two reasons make it <a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" data-tertiary="importance of" id="idm45968150960392"/>extra important to properly plan and run your experiment, not just from an experimental design perspective, but also from a business <span class="keep-together">perspective.</span></p>
<section data-type="sect1" data-pdf-bookmark="Planning the Experiment"><div class="sect1" id="planning_the_experiment">
<h1>Planning the Experiment</h1>
<p>As we’ve seen in the previous chapter, successfully planning an<a contenteditable="false" data-type="indexterm" data-primary="theory of change (ToC)" data-secondary="booking profit versus CX" id="ch09-plaex6"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="planning the experiment" id="ch09-plaex5"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" id="ch09-plaex"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="stratified randomization" data-tertiary="planning the experiment" id="ch09-plaex2"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="planning the experiment" id="ch09-plaex3"/><a contenteditable="false" data-type="indexterm" data-primary="customer experience (CX)" data-secondary="theory of change in booking profit versus" id="ch09-plaexx"/> experiment requires us to clearly articulate its theory of change:</p>
<ul>
<li><p>What are the business goal and the target metric?</p></li>
<li><p>What is the definition of our intervention?</p></li>
<li><p>How are these connected by our behavioral logic?</p></li>
</ul>
<p>You should hopefully by now be familiar with that process, so I will not elaborate on how to do it, and I’ll just go through the steps quickly to give you a deeper understanding of the experiment. In particular, I’ll use the opportunity to call out some peculiarities of the experiment from a behavioral perspective.</p>
<section data-type="sect2" data-pdf-bookmark="Business Goal and Target Metric"><div class="sect2" id="business_goal_and_target_metric">
<h2>Business Goal and Target Metric</h2>
<p>The business goal for this experiment, or equivalently the<a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" data-tertiary="business goal" id="ch09-bsgl"/><a contenteditable="false" data-type="indexterm" data-primary="business goals" data-secondary="booking profit versus CX" id="ch09-bsgl2"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="planning the experiment" data-tertiary="business goal" id="ch09-bsgl3"/> business problem we’re trying to solve, is to increase profitability by reducing the amount of downtime in high-demand markets. Because the cost of offering free cleaning services to owners is significant (finance has estimated it to be $10/day), we’ll need to include it in our analysis.</p>
<p>We’ll do so by modifying our target metric accordingly. <a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" data-tertiary="target metric" id="ch09-tgmt"/><a contenteditable="false" data-type="indexterm" data-primary="target metrics" data-secondary="booking profit versus CX" id="ch09-tgmt2"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="planning the experiment" data-tertiary="target metric" id="ch09-tgmt3"/>Our basic metric is average booking profit per day; we’ll use instead average booking profit per day <em>net of extra cost</em>. This simply means that we’ll have to deduce $10 from the basic metric for the free cleaning treatment.</p>
<p>However, there are also some concerns that the<a contenteditable="false" data-type="indexterm" data-primary="customer satisfaction (CSAT)" data-secondary="negative impact from intervention" id="ch09-csat"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="customer satisfaction negative impact" id="ch09-csat2"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="stratified randomization" data-tertiary="customer satisfaction negative impact" id="ch09-csat3"/> minimum-duration intervention would negatively impact customer satisfaction. How can we take that into account?</p>
<p>A solution I have seen other authors advocate is to use a<a contenteditable="false" data-type="indexterm" data-primary="target metrics" data-secondary="weighted average of metrics" id="ch09wtav"/><a contenteditable="false" data-type="indexterm" data-primary="weighted average of metrics" id="ch09wtav2"/><a contenteditable="false" data-type="indexterm" data-primary="Overall Evaluation Criterion (OEC)" id="ch09wtav3"/><a contenteditable="false" data-type="indexterm" data-primary="target metrics" data-secondary="Overall Evaluation Criterion" id="ch09wtav4"/> weighted average of metrics, (sometimes called an Overall Evaluation Criterion [OEC]). In our present example, this would mean assigning weights, e.g., 50% each, to our two variables, and then using that new metric as our target. You should certainly feel free to use that approach if you or your business partners wish to, but I would recommend instead picking a unique target metric, and if necessary have a few other “guardrail” metrics on a watch list, for several reasons.</p>
<p>The first one is that the trade-offs between business goals are ultimately strategic and political decisions. There is no objective best answer as to how many CSAT points an increase in profit is worth; it depends on the organization, its context, and its current priorities. Using a weighted average determined at one point in time gives the process the appearance of technical objectivity but it’s really only fossilized subjectivity.</p>
<p>The second is that an OEC makes these trade-offs linear. If one CSAT point is equivalent to $10 million of profit with an OEC, then five CSAT points are equivalent to $50 million of profit. But a decrease of one CSAT point might mean fewer delighted customers while a decrease of five points might mean a social media storm. A dollar is always worth another dollar, but for pretty much anything else, a series of small changes is generally preferred to a single big one. Relying blindly on an OEC can lead to riskier decisions. Proponents of the OEC approach may object at this point that obviously you shouldn’t rely on it blindly; but if you’re going to look at the various components and have an open discussion anyway, I’m not quite sure how having an OEC helps.</p>
<p>Moreover, an OEC takes business interventions as fixed. Sticking with the 1 point CSAT = $10 million equivalence, the following two options would have an equal rating of zero:</p>
<ol>
<li><p>The first intervention increases profit by $1 million and decreases CSAT by 0.1 points.</p></li>
<li><p>The second intervention increases profit by $50 million and decreases CSAT by 5 points.</p></li>
</ol>
<p>But there is a big difference from a behavioral perspective. The first option is basically a dead horse and there is little hope of beating life into it, whereas the second option is more like a mercurial purebred. By targeting it to a specific segment of customers, changing its terms or the way it’s presented, there might be a way to reap at least some of its benefits without its costs. In that sense, an intervention with both big positive and negative effects calls for exploration and design iterations rather than the binary decisions encouraged by an OEC.</p>
<p>Finally, I believe that in some cases, an OEC is used as a shortcut. Let’s say that an intervention increases short-term profit but also increases the probability of defection. This is not a genuine strategic trade-off: we should measure the impact of the probability of defection on lifetime value, and then determine the net effect on profitability. Saying that your OEC will be 90% short-term profit and 10% effect on defection rate is a way of taking a guess instead of measuring the true exchange rate. With the causal-behavioral framework of this book, we can do better than taking guesses.</p>
<p>Therefore, for the rest of the chapter, we’ll use average booking profit per day as our single target metric, and assume that CSAT is being monitored in the background for any worrying change.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>That’s all well and good, but when we’re talking about tracking customer satisfaction, which customers are we talking about? If customers want to book a location for just one night and are offered a location with a duration minimum, they might decide to book a different one (either in the control group or the free-cleaning group), or else completely give up on booking through AirCnC and book a hotel instead. Therefore, we can’t simply measure customer experience for a clearly defined group of customers.</p>
<p>Unfortunately, that problem is not rare: whenever you run an experiment where the experimental unit for random assignment is not a customer, you have to ask yourself how this will play out on the customer side. What we can do is leverage the fact that minimum duration would impact only customers who are looking for a one-night booking; we also know that customers enter their desired duration before being shown available properties. Therefore, we could track all customers in our experiment who have a one-night desired duration and check whether they end up booking several nights in the same property or one night in another property, or end up not booking at all. Whenever they make a booking, we would also track how they rate their stay. That’s certainly far from perfect because we would be tracking different metrics for different subgroups of customers, but that’s the best we can do, and is another example of why I believe much more in monitoring guardrail variables than in aggregating them in an OEC.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-csat" id="idm45968150909832"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-bsgl" id="idm45968150908616"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-bsgl2" id="idm45968150907400"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-tgmt" id="idm45968150906184"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-tgmt2" id="idm45968150904968"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-csat2" id="idm45968150903752"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09wtav" id="idm45968150902536"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09wtav2" id="idm45968150901320"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09wtav3" id="idm45968150900104"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09wtav4" id="idm45968150898760"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-csat3" id="idm45968150897384"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-bsgl3" id="idm45968150896008"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-tgmt3" id="idm45968150894632"/></p>
</div>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Definition of the Intervention"><div class="sect2" id="definition_of_the_intervention-id00028">
<h2>Definition of the Intervention</h2>
<p>After determining the criteria for success, we need to make sure<a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" data-tertiary="intervention" id="idm45968150891544"/><a contenteditable="false" data-type="indexterm" data-primary="interventions" data-secondary="booking profit versus CX" id="idm45968150889816"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="planning the experiment" data-tertiary="intervention" id="idm45968150888472"/> we have clarity on what we are testing. This is especially important when the organizational stakes are high, e.g., business leaders are butting heads on the question. Here, it is important to point out that we’re offering owners the opportunity to set a minimum duration, which is not the same thing as making a minimum duration mandatory. Similarly, owners may or may not take the free-cleaning offer. In addition, the treatments themselves could still be open to interpretation. How thorough and costly for the company is the free cleaning? What is the minimum duration we’re enforcing on customers?</p>
<p>Because both of our interventions are somewhat complex and rely on owners understanding an offer and choosing to take it, it is probably a good idea to create a few different designs and test them qualitatively through UX research. In addition, after running the experiment, it would be a good idea to consider slightly different variations of whichever treatment we decide to implement.</p>
<p>Ultimately, you’ll want to make sure that all the stakeholders are satisfied with the designs for the experiment and are willing to sign off on it. It will reduce (but not eliminate!) the risk that when the results come in, they will argue that what was tested did not adequately represent their proposed solution.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Behavioral Logic"><div class="sect2" id="behavioral_logic">
<h2>Behavioral Logic</h2>
<p>The behavioral logic is different for the two treatments: <a contenteditable="false" data-type="indexterm" data-primary="behavioral logic" data-secondary="stratified randomization" id="idm45968150882808"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="planning the experiment" data-tertiary="behavioral logic" id="idm45968150881288"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="planning the experiment" data-tertiary="behavioral logic" id="idm45968150879672"/><a contenteditable="false" data-type="indexterm" data-primary="theory of change (ToC)" data-secondary="behavioral logic" id="idm45968150878024"/>the minimum-duration approach would increase the duration and amount per booking but may reduce the overall number of bookings; on the other hand, the free-cleaning approach would increase the number of bookings but will reduce the profit per booking due to the added cost. In addition, we need to take into account that our experimental treatments/interventions are <em>offers</em>, which owners may or may not accept (<a data-type="xref" href="#the_cd_of_the_two_treatments_under_cons">Figure 9-1</a>).</p>
<figure><div id="the_cd_of_the_two_treatments_under_cons" class="figure">
<img src="Images/BEDA_0901.png" alt="The CD of the two treatments under consideration" width="1460" height="660"/>
<h6><span class="label">Figure 9-1. </span>The CD of the two treatments under consideration</h6>
</div></figure>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Data and Packages"><div class="sect2" id="data_and_libraries-id00024">
<h2>Data and Packages</h2>
<p>The <a href="https://oreil.ly/BehavioralDataAnalysisCh9">GitHub folder for this chapter</a> <a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="data and packages for examples" id="idm45968150869624"/><a contenteditable="false" data-type="indexterm" data-primary="GitHub" data-secondary="experimental design data" data-tertiary="booking profit vs CX" id="idm45968150868200"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="data and packages for example" id="idm45968150866536"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="stratified randomization" data-tertiary="data and packages for example" id="idm45968150864856"/>contains two CSV files with the variables listed in <a data-type="xref" href="#variables_in_our_data-id00081">Table 9-1</a>. The check mark (✓) indicates the variables present in that file, while the cross (☓) indicates the variables that are not present.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-plaex" id="idm45968150861896"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-plaex2" id="idm45968150860552"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-plaex3" id="idm45968150859176"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-plaex5" id="idm45968150857800"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-plaex6" id="idm45968150856424"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-plaexx" id="idm45968150855048"/></p>
<table class="border" id="variables_in_our_data-id00081">
<caption><span class="label">Table 9-1. </span>Variables in our data</caption>
<thead>
<tr>
<th/>
<th>Variable description</th>
<th>chap9-historical_data.csv</th>
<th>chap9-experimental_data.csv</th>
</tr>
</thead>
<tbody>
<tr>
<td><em>ID</em></td>
<td>Property/owner ID, 1-5000</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>sq_ft</em></td>
<td>Square footage of property, 460-1120</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>tier</em></td>
<td>Tier of property, categorical, from 1 to 3 in descending tiers</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>avg_review</em></td>
<td>Average review of property, 0-10</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>BPday</em></td>
<td>Booking profit per day, target variable, 0-126</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>Period</em></td>
<td>Month index, 1-35 in historical data, 36 implicit in experimental data</td>
<td>✓</td>
<td/>
</tr>
<tr>
<td><em>Month</em></td>
<td>Month of year, 1-12</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><em>group</em></td>
<td>Experimental assignment, “ctrl,” “treat1” (free cleaning), “treat2” (min. booking duration)</td>
<td>☓</td>
<td>✓</td>
</tr>
<tr>
<td><em>compliant</em></td>
<td>Binary variable indicating if owner was treated according to their assigned group</td>
<td>☓</td>
<td>✓</td>
</tr>
</tbody>
</table>
<p>In this chapter, we’ll use the following packages in addition to the common ones:<a contenteditable="false" data-type="indexterm" data-primary="block() function" data-secondary="package" id="idm45968150827256"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="block() function" id="idm45968150825880"/><a contenteditable="false" data-type="indexterm" data-primary="dummyVars()" data-secondary="package" id="idm45968150824504"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="rescale() function" id="idm45968150823128"/><a contenteditable="false" data-type="indexterm" data-primary="rescale() function package" id="idm45968150821752"/><a contenteditable="false" data-type="indexterm" data-primary="one-hot encoding" data-secondary="dummyVars() function" data-tertiary="package" id="idm45968150820632"/><a contenteditable="false" data-type="indexterm" data-primary="OneHotEncoder" data-secondary="package" id="idm45968150818984"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="OneHotEncoder" id="idm45968150817608"/><a contenteditable="false" data-type="indexterm" data-primary="MinMaxScaler" data-secondary="package" id="idm45968150816232"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="MinMaxScaler" id="idm45968150814856"/><a contenteditable="false" data-type="indexterm" data-primary="random package for sample() and shuffle()" id="idm45968150813480"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="random for sample() and shuffle()" id="idm45968150812280"/><a contenteditable="false" data-type="indexterm" data-primary="sample() function" data-secondary="package" id="idm45968150810888"/><a contenteditable="false" data-type="indexterm" data-primary="shuffle() function package" id="idm45968150809512"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="dummyVars() one-hot encoding" id="idm45968150808392"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="nf">library</code><code class="p">(</code><code class="n">blockTools</code><code class="p">)</code> <code class="c1"># For function block()</code>
<code class="nf">library</code><code class="p">(</code><code class="n">caret</code><code class="p">)</code> <code class="c1"># For one-hot encoding function dummyVars()</code>
<code class="nf">library</code><code class="p">(</code><code class="n">scales</code><code class="p">)</code> <code class="c1"># For function rescale()</code></pre>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python</code>
<code class="kn">import</code> <code class="nn">random</code> <code class="c1"># For functions sample() and shuffle()</code>
<code class="c1"># To rescale numeric variables</code>
<code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="kn">import</code> <code class="n">MinMaxScaler</code>
<code class="c1"># To one-hot encode cat. variables</code>
<code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="kn">import</code> <code class="n">OneHotEncoder</code></pre>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Determining Random Assignment and Sample Size/Power"><div class="sect1" id="determining_random_assignment_and_sampl">
<h1>Determining Random Assignment and Sample Size/Power</h1>
<p>For this experiment, we’ll assign experimental groups all at once,<a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="random assignment" id="ch09-rass"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="random assignment" id="ch09-rass2"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="random assignment" data-tertiary="about" id="idm45968150775496"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="stratified randomization" data-tertiary="random assignment" id="ch09-rass3"/> based on the list of our owners at a point in time. This gives us an opportunity to significantly improve over purely random allocation by ensuring from the get-go that our two groups are well balanced through a method called stratification. This will allow us to get more statistical power out of any given sample size.</p>
<p>Therefore, I’ll first explain the method for the random assignment, so that we can use it in the simulations for our power analysis. Finally, we’ll compare the results of these simulations with a traditional statistical power analysis.</p>
<section data-type="sect2" data-pdf-bookmark="Random Assignment"><div class="sect2" id="random_assignment">
<h2>Random Assignment</h2>
<p>Before getting into stratification, let’s see what standard randomization would look like.</p>
<section data-type="sect3" data-pdf-bookmark="Random assignment level"><div class="sect3" id="random_assignment_level">
<h3>Random assignment level</h3>
<p>The first consideration for our random assignment is the level<a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="random assignment" data-tertiary="without stratification" id="ch09-nostr"/> at which we’ll implement it and then measure the outcomes of the experiment. In the previous chapter, I discussed the question of whether the random assignment should happen at the level of a customer or of a booking. In the present case, the logistics of the experimental treatments, especially the free-cleaning one, precludes implementation at the booking level. Therefore, we’ll do the random assignment at the level of a property owner, which number 5,000 in AirCnC’s data at this point in time.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Standard randomization"><div class="sect3" id="standard_randomization">
<h3>Standard randomization</h3>
<p>The process is similar to the one we used in the previous experiment, but <a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="random assignment" id="idm45968150728856"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="random assignment" id="idm45968150727480"/>simpler because it can be done offline instead of in real time: first, we assign a random number between 0 and 1 to each individual in our experimental population. Then, we assign groups based on that random number: if K is the number of groups we want (including a control group), then all individuals with a random number less than 1/K are in the first group, all individuals with a random number between 1/K and 2/K are in the second group, and so on. The following code illustrates the approach with three groups and a sample size of (for illustration purposes) 5,000:<a contenteditable="false" data-type="indexterm" data-primary="sample() function" id="idm45968150725384"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">no_strat_assgnt_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">Nexp</code><code class="p">){</code>
  <code class="n">K</code> <code class="o">&lt;-</code> <code class="m">3</code>  
  <code class="n">dat</code> <code class="o">&lt;-</code> <code class="n">dat</code> <code class="o">%&gt;%</code>
    <code class="nf">distinct</code><code class="p">(</code><code class="n">ID</code><code class="p">)</code> <code class="o">%&gt;%</code>
    <code class="nf">slice_sample</code><code class="p">(</code><code class="n">n</code><code class="o">=</code><code class="n">Nexp</code><code class="p">)</code> <code class="o">%&gt;%</code>
    <code class="nf">mutate</code><code class="p">(</code><code class="n">assgnt</code> <code class="o">=</code> <code class="nf">runif</code><code class="p">(</code><code class="n">Nexp</code><code class="p">,</code><code class="m">0</code><code class="p">,</code><code class="m">1</code><code class="p">))</code> <code class="o">%&gt;%</code>
    <code class="nf">mutate</code><code class="p">(</code><code class="n">group</code> <code class="o">=</code> <code class="nf">case_when</code><code class="p">(</code>
      <code class="n">assgnt</code> <code class="o">&lt;</code> <code class="o">=</code> <code class="m">1</code><code class="o">/</code><code class="n">K</code> <code class="o">~</code> <code class="s">"ctrl"</code><code class="p">,</code>
      <code class="n">assgnt</code> <code class="o">&gt;</code> <code class="m">1</code><code class="o">/</code><code class="n">K</code> <code class="o">&amp;</code> <code class="n">assgnt</code> <code class="o">&lt;</code> <code class="o">=</code> <code class="m">2</code><code class="o">/</code><code class="n">K</code> <code class="o">~</code> <code class="s">"treat1"</code><code class="p">,</code>
      <code class="n">assgnt</code> <code class="o">&gt;</code> <code class="m">2</code><code class="o">/</code><code class="n">K</code> <code class="o">~</code> <code class="s">"treat2"</code><code class="p">))</code> <code class="o">%&gt;%</code>
    <code class="nf">mutate</code><code class="p">(</code><code class="n">group</code> <code class="o">=</code> <code class="nf">as.factor</code><code class="p">(</code><code class="n">group</code><code class="p">))</code> <code class="o">%&gt;%</code>
    <code class="nf">select</code><code class="p">(</code><code class="o">-</code><code class="n">assgnt</code><code class="p">)</code>
  <code class="nf">return</code><code class="p">(</code><code class="n">dat</code><code class="p">)</code>
<code class="p">}</code>
<code class="n">no_strat_assgnt</code> <code class="o">&lt;-</code> <code class="nf">no_strat_assgnt_fun</code><code class="p">(</code><code class="n">hist_data</code><code class="p">,</code> <code class="n">Nexp</code> <code class="o">=</code> <code class="m">5000</code><code class="p">)</code></pre>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python</code>
<code class="k">def</code> <code class="nf">no_strat_assgnt_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">,</code> <code class="n">Nexp</code><code class="p">,</code> <code class="n">K</code><code class="p">):</code>
    <code class="n">dat_df</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code><code class="s1">'ID'</code><code class="p">:</code> <code class="n">dat_df</code><code class="o">.</code><code class="n">ID</code><code class="o">.</code><code class="n">unique</code><code class="p">()})</code>
    <code class="n">dat_df</code> <code class="o">=</code> <code class="n">dat_df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">Nexp</code><code class="p">)</code>
    <code class="n">dat_df</code><code class="p">[</code><code class="s1">'assgnt'</code><code class="p">]</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">uniform</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code><code class="mi">1</code><code class="p">,</code><code class="n">Nexp</code><code class="p">)</code>
    <code class="n">dat_df</code><code class="p">[</code><code class="s1">'group'</code><code class="p">]</code> <code class="o">=</code> <code class="s1">'ctrl'</code>
    <code class="n">dat_df</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">dat_df</code><code class="p">[</code><code class="s1">'assgnt'</code><code class="p">]</code><code class="o">.</code><code class="n">between</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="o">/</code><code class="n">K</code><code class="p">,</code> <code class="n">inclusive</code><code class="o">=</code><code class="bp">True</code><code class="p">),</code> 
               <code class="s1">'group'</code><code class="p">]</code> <code class="o">=</code> <code class="s1">'treat1'</code>
    <code class="n">dat_df</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">dat_df</code><code class="p">[</code><code class="s1">'assgnt'</code><code class="p">]</code><code class="o">.</code><code class="n">between</code><code class="p">(</code><code class="mi">1</code><code class="o">/</code><code class="n">K</code><code class="p">,</code> <code class="mi">2</code><code class="o">/</code><code class="n">K</code><code class="p">,</code> <code class="n">inclusive</code><code class="o">=</code><code class="bp">False</code><code class="p">),</code> 
               <code class="s1">'group'</code><code class="p">]</code> <code class="o">=</code> <code class="s1">'treat2'</code>
    <code class="k">del</code><code class="p">(</code><code class="n">dat_df</code><code class="p">[</code><code class="s1">'assgnt'</code><code class="p">])</code>
    <code class="k">return</code> <code class="n">dat_df</code>
<code class="n">no_strat_assgnt</code> <code class="o">=</code> <code class="n">no_strat_assgnt_fun</code><code class="p">(</code><code class="n">hist_data_df</code><code class="p">,</code> <code class="n">Nexp</code> <code class="o">=</code> <code class="mi">5000</code><code class="p">,</code> <code class="n">K</code> <code class="o">=</code> <code class="mi">3</code><code class="p">)</code></pre>
<p>One nice aspect of this approach is that it can easily be generalized to an arbitrarily large number of groups, by creating a simple loop; the control group is then tagged with <code>0</code>, the first treatment group <code>1</code>, and so on:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">no_strat_assgnt_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">Nexp</code><code class="p">,</code> <code class="n">K</code><code class="p">){</code>
  <code class="n">dat</code> <code class="o">&lt;-</code> <code class="n">dat</code> <code class="o">%&gt;%</code>
    <code class="nf">distinct</code><code class="p">(</code><code class="n">ID</code><code class="p">)</code> <code class="o">%&gt;%</code>
    <code class="nf">slice_sample</code><code class="p">(</code><code class="n">n</code><code class="o">=</code><code class="n">Nexp</code><code class="p">)</code> <code class="o">%&gt;%</code>
    <code class="nf">mutate</code><code class="p">(</code><code class="n">assgnt</code> <code class="o">=</code> <code class="nf">runif</code><code class="p">(</code><code class="n">Nexp</code><code class="p">,</code><code class="m">0</code><code class="p">,</code><code class="m">1</code><code class="p">))</code> <code class="o">%&gt;%</code>
    <code class="nf">mutate</code><code class="p">(</code><code class="n">group</code> <code class="o">=</code> <code class="m">-1</code><code class="p">)</code> <code class="c1"># initializing the “group” variable</code>
  <code class="nf">for</code><code class="p">(</code><code class="n">i</code> <code class="n">in</code> <code class="nf">seq</code><code class="p">(</code><code class="m">1</code><code class="p">,</code><code class="n">K</code><code class="p">)){</code>
    <code class="n">dat</code><code class="o">$</code><code class="n">group</code> <code class="o">=</code> <code class="nf">ifelse</code><code class="p">(</code><code class="n">dat</code><code class="o">$</code><code class="n">assgnt</code> <code class="o">&gt;=</code> <code class="p">(</code><code class="n">i</code><code class="m">-1</code><code class="p">)</code><code class="o">/</code><code class="n">K</code> <code class="o">&amp;</code> <code class="n">dat</code><code class="o">$</code><code class="n">assgnt</code> <code class="o">&lt;</code> <code class="n">i</code><code class="o">/</code><code class="n">K</code><code class="p">,</code><code class="n">i</code><code class="m">-1</code><code class="p">,</code><code class="n">dat</code><code class="o">$</code><code class="n">group</code><code class="p">)}</code> 
  <code class="n">dat</code> <code class="o">&lt;-</code> <code class="n">dat</code> <code class="o">%&gt;%</code>
    <code class="nf">mutate</code><code class="p">(</code><code class="n">group</code> <code class="o">=</code> <code class="nf">as.factor</code><code class="p">(</code><code class="n">group</code><code class="p">))</code> <code class="o">%&gt;%</code>
    <code class="nf">select</code><code class="p">(</code><code class="o">-</code><code class="n">assgnt</code><code class="p">)</code>
  <code class="nf">return</code><code class="p">(</code><code class="n">dat</code><code class="p">)</code>
<code class="p">}</code>
<code class="n">no_strat_assgnt</code> <code class="o">&lt;-</code> <code class="nf">no_strat_assgnt_fun</code><code class="p">(</code><code class="n">hist_data</code><code class="p">,</code> <code class="n">Nexp</code> <code class="o">=</code> <code class="m">5000</code><code class="p">,</code> <code class="n">K</code> <code class="o">=</code> <code class="m">4</code><code class="p">)</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
<code class="k">def</code> <code class="nf">no_strat_assgnt_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">,</code> <code class="n">Nexp</code><code class="p">,</code> <code class="n">K</code><code class="p">):</code>
    <code class="n">dat_df</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code><code class="s1">'ID'</code><code class="p">:</code> <code class="n">dat_df</code><code class="o">.</code><code class="n">ID</code><code class="o">.</code><code class="n">unique</code><code class="p">()})</code>
    <code class="n">dat_df</code> <code class="o">=</code> <code class="n">dat_df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">Nexp</code><code class="p">)</code>
    <code class="n">dat_df</code><code class="p">[</code><code class="s1">'assgnt'</code><code class="p">]</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">uniform</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code><code class="mi">1</code><code class="p">,</code><code class="n">Nexp</code><code class="p">)</code>
    <code class="n">dat_df</code><code class="p">[</code><code class="s1">'group'</code><code class="p">]</code> <code class="o">=</code> <code class="o">-</code><code class="mi">1</code> <code class="c1"># initializing the “group” variable</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">K</code><code class="p">):</code>
        <code class="n">dat_df</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">dat_df</code><code class="p">[</code><code class="s1">'assgnt'</code><code class="p">]</code><code class="o">.</code><code class="n">between</code><code class="p">(</code><code class="n">i</code><code class="o">/</code><code class="n">K</code><code class="p">,</code> <code class="p">(</code><code class="n">i</code><code class="o">+</code><code class="mi">1</code><code class="p">)</code><code class="o">/</code><code class="n">K</code><code class="p">,</code> <code class="n">inclusive</code><code class="o">=</code><code class="bp">True</code><code class="p">),</code> 
               <code class="s1">'group'</code><code class="p">]</code> <code class="o">=</code> <code class="n">i</code>
    <code class="k">del</code><code class="p">(</code><code class="n">dat_df</code><code class="p">[</code><code class="s1">'assgnt'</code><code class="p">])</code>
    <code class="k">return</code> <code class="n">dat_df</code>   
<code class="n">no_strat_assgnt</code> <code class="o">=</code> <code class="n">no_strat_assgnt_fun</code><code class="p">(</code><code class="n">hist_data_df</code><code class="p">,</code> <code class="n">Nexp</code> <code class="o">=</code> <code class="mi">5000</code><code class="p">,</code> <code class="n">K</code> <code class="o">=</code> <code class="mi">4</code><code class="p">)</code></pre>
<p>However, an issue with the previous approach is that experimental groups are unlikely to be perfectly balanced across customer characteristics. In order to create balanced experimental groups, we’ll want to use a technique called stratification.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-nostr" id="idm45968150451736"/></p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Stratified randomization"><div class="sect3" id="stratified_randomizati">
<h3>Stratified randomization</h3>
<p>Why is a purely random allocation not our best choice? <a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="random assignment" data-tertiary="stratified randomization" id="ch09-strra"/>Let’s imagine that we are running an experiment on 20 customers, 10 of which are male and 10 of which are female. If we randomly assign each customer to either the control or the treatment group with probability 50%, we expect that on average, there will be 5 males and 5 females in each of the two groups. “On average” here means that if we repeated this assignment a large number of times, the average number of males in the control group across assignments would be 5. But in any given experiment, there’s only a 34.4% chance that we get exactly 5 males and 5 females in each group, and there’s a 8.9% chance that we get 7 or more men in one group, <a contenteditable="false" data-type="indexterm" data-primary="hypergeometric distribution" id="idm45968150049656"/><a contenteditable="false" data-type="indexterm" data-primary="Kaltenbrunner, Andreas" id="idm45968150048536"/>based on the hypergeometric distribution.<sup><a data-type="noteref" id="ch01fn18-marker" href="ch09.xhtml#ch01fn18">1</a></sup> Obviously, this problem gets less pronounced with larger sample sizes. <a contenteditable="false" data-type="indexterm" data-primary="demographic variables" data-secondary="stratification in stratified randomization" id="idm45968150045672"/>With 100 males and 100 females, the probability of getting 70 men or more in one group becomes negligible. But we don’t care only about gender: ideally, we would also want a good balance of age, state of residence, usage pattern, etc. This would ensure that our results are relevant for our entire customer base as much as possible, and not just to a specific subgroup of it.</p>
<p>Fortunately, when we have the luxury of assigning experimental groups to all individuals at once, for instance, we can do significantly better than just crossing our fingers and hoping for the best. <a contenteditable="false" data-type="indexterm" data-primary="variables" data-secondary="stratification in stratified randomization" id="idm45968150043080"/>We can stratify our data: we create “layers” of similar customers, called strata,<sup><a data-type="noteref" id="ch01fn19-marker" href="ch09.xhtml#ch01fn19">2</a></sup> and we split them between our experimental groups. In the case of our 10 male and 10 female customers, we would create a layer of men, 5 of which would go to the control group and 5 of which to the treatment group, and similarly for women. This implies that each individual still has a 50% chance of ending in either group but our control and treatment groups are now perfectly balanced for gender.</p>
<p>Stratification can be applied to any number of variables. With gender and state of residence, we would create a stratum of all women from Kansas and split it equally between our control and treatment group, and so on. With a large number of variables, or with continuous variables, it becomes impossible to find exact matches; in our data, we may not have two women in Kansas with the exact same age and whose properties have the exact same square footage. The solution is to create pairs of individuals that are “as similar as possible,” e.g., a 58-year-old woman with a 900-square-foot property and a 56-year-old woman with a 930-square-foot property, and then assign at random one of them to the control group and the other to the treatment group. This way, they still have the same probability individually of ending in any experimental group. When we have only two individuals per strata, this is also called “matching,” because we’re creating matching pairs of customers.</p>
<p>As often, the intuition is clear enough, but the devil is in the detail of the implementation. There are two steps here:</p>
<ol>
<li><p>Give a mathematical meaning to the phrase “as similar as possible.”</p></li>
<li><p>Efficiently go through our data to allocate each customer to a pair.</p></li>
</ol>
<p>The mathematical concept that we’ll use to express “as similar as possible” is distance. Distance can be applied easily to a single numeric variable. If one owner is 56 years old and another is 58 years old, the distance between them is 58 − 56 = 2 years. Similarly, we could say that the distance between a 900-square-foot property and a 930-square-foot property is 30 square feet.</p>
<p>The first complication comes in aggregating multiple numeric variables. We could simply add (or equivalently, take the mean of) the two numbers and say that our two owners are “distant” by 2 + 30 = 32 distance units. The problem with that approach is that square-footage numbers are much bigger than age numbers, as we can see in our example. A difference of 30 years between two owners is likely to be much more important behaviorally than a difference of 30 square feet between their properties. This can be resolved by rescaling all our numeric variables so that their minimum is reset to 0 and their maximum to 1. This means that the “distance” between the youngest and the oldest owners is 1, and the distance between the smallest and the biggest property is also 1. This is not a perfect solution, especially when you have outliers, but it’s fast and good enough for most purposes.</p>
<p>The second complication comes from categorical variables. What is the “distance” between a townhouse and an apartment? Or between having a pool or not? A common solution is to say that the distance between two properties is 0 if they are in the same category and 1 otherwise. For example, a townhouse and a house would have a distance of 1 for the property type variable. <a contenteditable="false" data-type="indexterm" data-primary="OneHotEncoder" data-secondary="one-hot encoding" id="idm45968150032568"/><a contenteditable="false" data-type="indexterm" data-primary="dummyVars()" data-secondary="one-hot encoding" id="idm45968150031192"/><a contenteditable="false" data-type="indexterm" data-primary="one-hot encoding" data-secondary="dummyVars() function" id="idm45968150029816"/><a contenteditable="false" data-type="indexterm" data-primary="one-hot encoding" data-secondary="OneHotEncoder" id="idm45968150028440"/><a contenteditable="false" data-type="indexterm" data-primary="one-hot encoding" id="idm45968150027064"/><a contenteditable="false" data-type="indexterm" data-primary="categorical variables" data-secondary="one-hot encoding" id="idm45968150025960"/><a contenteditable="false" data-type="indexterm" data-primary="variables" data-secondary="one-hot encoding categorical" id="idm45968150024584"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="random assignment" data-tertiary="one-hot encoding" id="idm45968150023144"/><a contenteditable="false" data-type="indexterm" data-primary="binary variables" data-secondary="one-hot encoding categorical variables" id="idm45968150021480"/>Mathematically, this is done by <em>one-hot encoding</em> categorical variables: that is, we create as many binary 0/1 variables as we have categories. For example, we would transform property type = (“house,” “townhouse,” “apartment”) into three variables, <em>type.house</em>, <em>type.townhouse,</em> and <em>type.apartment</em>. A property that is an apartment would have a value of 1 for the variable <em>type.apartment</em> and 0 for the other two variables. This also has the added advantage of making categorical “distances” comparable with numerical distance. In effect, we’re saying that the difference between a townhouse and an apartment is as important as the difference between the smallest and the largest properties. This is again debatable from a behavioral perspective, but that’s a good starting point, and often a good stopping point as well.</p>
<p>I have written R and Python functions that prepare our data by rescaling numeric variables and one-hot encoding categorical variables. This is just boilerplate code, so just skip that bit of code if you don’t care about the details of the implementation:<a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="stratified randomization" data-tertiary="rescaling and one-hot encoding" id="idm45968150033096"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="stratified randomization" data-tertiary="rescaling and one-hot encoding" id="idm45968150015256"/><a contenteditable="false" data-type="indexterm" data-primary="MinMaxScaler" id="idm45968150013576"/></p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python code (output not shown)</code>
<code class="k">def</code> <code class="nf">strat_prep_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">):</code>
    <code class="c1"># Extracting property-level variables</code>
    <code class="n">dat_df</code> <code class="o">=</code> <code class="n">dat_df</code><code class="o">.</code><code class="n">groupby</code><code class="p">([</code><code class="s1">'ID'</code><code class="p">])</code><code class="o">.</code><code class="n">agg</code><code class="p">(</code>
        <code class="n">tier</code> <code class="o">=</code> <code class="p">(</code><code class="s1">'tier'</code><code class="p">,</code> <code class="s1">'mean'</code><code class="p">),</code>
        <code class="n">avg_review</code> <code class="o">=</code> <code class="p">(</code><code class="s1">'avg_review'</code><code class="p">,</code> <code class="s1">'mean'</code><code class="p">),</code>
        <code class="n">sq_ft</code> <code class="o">=</code> <code class="p">(</code><code class="s1">'sq_ft'</code><code class="p">,</code> <code class="s1">'mean'</code><code class="p">),</code>
        <code class="n">BPday</code> <code class="o">=</code> <code class="p">(</code><code class="s1">'BPday'</code><code class="p">,</code> <code class="s1">'mean'</code><code class="p">))</code><code class="o">.</code><code class="n">reset_index</code><code class="p">()</code>
    <code class="n">dat_df</code><code class="p">[</code><code class="s1">'tier'</code><code class="p">]</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">Categorical</code><code class="p">(</code><code class="n">dat_df</code><code class="o">.</code><code class="n">tier</code><code class="p">,</code> <code class="n">categories</code><code class="o">=</code><code class="p">[</code><code class="mi">3</code><code class="p">,</code><code class="mi">2</code><code class="p">,</code><code class="mi">1</code><code class="p">],</code> 
                                    <code class="n">ordered</code> <code class="o">=</code> <code class="bp">True</code><code class="p">)</code>
    <code class="n">dat_df</code><code class="p">[</code><code class="s1">'ID'</code><code class="p">]</code> <code class="o">=</code> <code class="n">dat_df</code><code class="o">.</code><code class="n">ID</code><code class="o">.</code><code class="n">astype</code><code class="p">(</code><code class="nb">str</code><code class="p">)</code>
    <code class="n">num_df</code> <code class="o">=</code> <code class="n">dat_df</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">dat_df</code><code class="o">.</code><code class="n">dtypes</code><code class="o">==</code><code class="s1">'float64'</code><code class="p">]</code> <code class="c1">#Numeric vars </code>
    <code class="n">cat_df</code> <code class="o">=</code> <code class="n">dat_df</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code><code class="o">.</code><code class="n">loc</code><code class="p">[:,</code><code class="n">dat_df</code><code class="o">.</code><code class="n">dtypes</code><code class="o">==</code><code class="s1">'category'</code><code class="p">]</code> <code class="c1">#Categorical vars</code>

    <code class="c1"># Normalizing all numeric variables to [0,1]</code>
    <code class="n">scaler</code> <code class="o">=</code> <code class="n">MinMaxScaler</code><code class="p">()</code>
    <code class="n">scaler</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">num_df</code><code class="p">)</code>
    <code class="n">num_np</code> <code class="o">=</code> <code class="n">scaler</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">num_df</code><code class="p">)</code>
    
    <code class="c1"># One-hot encoding all categorical variables</code>
    <code class="n">enc</code> <code class="o">=</code> <code class="n">OneHotEncoder</code><code class="p">(</code><code class="n">handle_unknown</code><code class="o">=</code><code class="s1">'ignore'</code><code class="p">)</code>
    <code class="n">enc</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">cat_df</code><code class="p">)</code>
    <code class="n">cat_np</code> <code class="o">=</code> <code class="n">enc</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">cat_df</code><code class="p">)</code><code class="o">.</code><code class="n">toarray</code><code class="p">()</code>
    
    <code class="c1">#Binding arrays</code>
    <code class="n">data_np</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">concatenate</code><code class="p">((</code><code class="n">num_np</code><code class="p">,</code> <code class="n">cat_np</code><code class="p">),</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
    <code class="k">del</code> <code class="n">num_df</code><code class="p">,</code> <code class="n">num_np</code><code class="p">,</code> <code class="n">cat_df</code><code class="p">,</code> <code class="n">cat_np</code><code class="p">,</code> <code class="n">enc</code><code class="p">,</code> <code class="n">scaler</code>
    <code class="k">return</code> <code class="n">data_np</code>
<code class="n">prepped_data_np</code> <code class="o">=</code> <code class="n">strat_prep_fun</code><code class="p">(</code><code class="n">hist_data_df</code><code class="p">)</code></pre>
<pre data-type="programlisting" data-code-language="r">
<code class="c1">## R</code>
<code class="o">&gt;</code> <code class="n">strat_prep_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">){</code>
    <code class="c1"># Extracting property-level variables</code>
    <code class="n">dat</code> <code class="o">&lt;-</code> <code class="n">dat</code> <code class="o">%&gt;%</code>
      <code class="nf">group_by</code><code class="p">(</code><code class="n">ID</code><code class="p">,</code> <code class="n">tier</code><code class="p">)</code> <code class="o">%&gt;%</code>
      <code class="nf">summarise</code><code class="p">(</code><code class="n">sq_ft</code> <code class="o">=</code> <code class="nf">mean</code><code class="p">(</code><code class="n">sq_ft</code><code class="p">),</code>
                <code class="n">avg_review</code> <code class="o">=</code> <code class="nf">mean</code><code class="p">(</code><code class="n">avg_review</code><code class="p">),</code>
                <code class="n">BPday</code> <code class="o">=</code> <code class="nf">mean</code><code class="p">(</code><code class="n">BPday</code><code class="p">))</code> <code class="o">%&gt;%</code>
      <code class="nf">ungroup</code><code class="p">()</code>
    
    <code class="c1"># Isolating the different components of our data</code>
    <code class="n">ID</code> <code class="o">&lt;-</code> <code class="n">dat</code><code class="o">$</code><code class="n">ID</code>  <code class="c1"># Owner identifier</code>
    <code class="n">dat</code> <code class="o">&lt;-</code> <code class="n">dat</code> <code class="o">%&gt;%</code> <code class="nf">select</code><code class="p">(</code><code class="o">-</code><code class="n">ID</code><code class="p">)</code>
    <code class="n">cat_vars</code> <code class="o">&lt;-</code> <code class="n">dat</code> <code class="o">%&gt;%</code>
      <code class="c1">#Selecting categorical variables</code>
      <code class="nf">select_if</code><code class="p">(</code><code class="n">is.factor</code><code class="p">)</code> 
    <code class="n">num_vars</code> <code class="o">&lt;-</code> <code class="n">dat</code> <code class="o">%&gt;%</code>
      <code class="c1">#Selecting numeric variables</code>
      <code class="nf">select_if</code><code class="p">(</code><code class="nf">function</code><code class="p">(</code><code class="n">x</code><code class="p">)</code> <code class="nf">is.numeric</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code class="o">|</code><code class="nf">is.integer</code><code class="p">(</code><code class="n">x</code><code class="p">))</code> 
    
    <code class="c1">#One-hot encoding categorical variables</code>
    <code class="n">cat_vars_out</code> <code class="o">&lt;-</code> <code class="nf">data.frame</code><code class="p">(</code><code class="nf">predict</code><code class="p">(</code><code class="nf">dummyVars</code><code class="p">(</code><code class="s">" ~."</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">cat_vars</code><code class="p">),</code> 
                                       <code class="n">newdata</code> <code class="o">=</code> <code class="n">cat_vars</code><code class="p">))</code>
    
    <code class="c1"># Normalizing numeric variables</code>
    <code class="n">num_vars_out</code> <code class="o">&lt;-</code> <code class="n">num_vars</code> <code class="o">%&gt;%</code>
      <code class="nf">mutate_all</code><code class="p">(</code><code class="n">rescale</code><code class="p">)</code>
    
    <code class="c1"># Putting the variables back together</code>
    <code class="n">dat_out</code> <code class="o">&lt;-</code> <code class="nf">cbind</code><code class="p">(</code><code class="n">ID</code><code class="p">,</code> <code class="n">num_vars_out</code><code class="p">,</code> <code class="n">cat_vars_out</code><code class="p">)</code>  <code class="o">%&gt;%</code>
      <code class="nf">mutate</code><code class="p">(</code><code class="n">ID</code> <code class="o">=</code> <code class="nf">as.character</code><code class="p">(</code><code class="n">ID</code><code class="p">))</code> <code class="o">%&gt;%</code>
      <code class="nf">mutate_if</code><code class="p">(</code><code class="n">is.numeric</code><code class="p">,</code> <code class="nf">function</code><code class="p">(</code><code class="n">x</code><code class="p">)</code> <code class="nf">round</code><code class="p">(</code><code class="n">x</code><code class="p">,</code> <code class="m">4</code><code class="p">))</code> <code class="c1">#Rounding for readability</code>
    
    <code class="nf">return</code><code class="p">(</code><code class="n">dat_out</code><code class="p">)}</code>
<code class="o">&gt;</code> <code class="n">prepped_data</code> <code class="o">&lt;-</code> <code class="nf">strat_prep_fun</code><code class="p">(</code><code class="n">hist_data</code><code class="p">)</code>
<code class="nf">`summarise</code><code class="p">()</code><code class="n">` regrouping output by 'ID' (override with `.groups`</code> <code class="n">argument</code><code class="p">)</code>
<code class="o">&gt;</code> <code class="nf">head</code><code class="p">(</code><code class="n">prepped_data</code><code class="p">,</code> <code class="m">5</code><code class="p">)</code>
    <code class="n">ID</code>  <code class="n">sq_ft</code> <code class="n">avg_review</code>  <code class="n">BPday</code> <code class="n">tier.3</code> <code class="n">tier.2</code> <code class="n">tier.1</code>
<code class="m">1</code>    <code class="m">1</code> <code class="m">0.3321</code>     <code class="m">0.3514</code> <code class="m">0.2365</code>      <code class="m">1</code>      <code class="m">0</code>      <code class="m">0</code>
<code class="m">2</code>   <code class="m">10</code> <code class="m">0.3802</code>     <code class="m">0.7191</code> <code class="m">0.5231</code>      <code class="m">1</code>      <code class="m">0</code>      <code class="m">0</code>
<code class="m">3</code>  <code class="m">100</code> <code class="m">0.8370</code>     <code class="m">0.6105</code> <code class="m">0.6603</code>      <code class="m">0</code>      <code class="m">0</code>      <code class="m">1</code>
<code class="m">4</code> <code class="m">1000</code> <code class="m">0.4476</code>     <code class="m">0.4882</code> <code class="m">0.3843</code>      <code class="m">1</code>      <code class="m">0</code>      <code class="m">0</code>
<code class="m">5</code> <code class="m">1001</code> <code class="m">0.3323</code>     <code class="m">0.7276</code> <code class="m">0.4316</code>      <code class="m">0</code>      <code class="m">1</code>      <code class="m">0</code></pre>
<p>Once we have prepared our data, the second step is to create pairs. <a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="stratified randomization" data-tertiary="creating pairs" id="idm45968149714616"/><a contenteditable="false" data-type="indexterm" data-primary="block() function" id="idm45968149713064"/>This computationally intensive problem quickly becomes intractable with larger data (at least if you want the optimal solution). Fortunately, algorithms have been created that will handle it for you. In R, we can use the function <code>block()</code> from the <code>blockTools</code> package:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">stratified_data</code> <code class="o">&lt;-</code> <code class="nf">block</code><code class="p">(</code><code class="n">prepped_data</code><code class="p">,</code> <code class="n">id.vars</code> <code class="o">=</code> <code class="nf">c</code><code class="p">(</code><code class="s">"ID"</code><code class="p">),</code> <code class="n">n.tr</code> <code class="o">=</code> <code class="m">3</code><code class="p">,</code> 
                         <code class="n">algorithm</code> <code class="o">=</code> <code class="s">"naiveGreedy"</code><code class="p">,</code> <code class="n">distance</code> <code class="o">=</code> <code class="s">"euclidean"</code><code class="p">)</code></pre>
<p>The parameters for that function are:</p>
<dl>
<dt><code>id.vars</code></dt>
<dd><p>This is the variable(s) used to identify the individuals in the data.</p></dd>
<dt><code>n.tr</code></dt>
<dd><p>This is the number of experimental groups, including the control group.</p></dd>
<dt><code>algorithm</code></dt>
<dd><p> Indicates the name of the algorithm to use. Predictably, <code>"</code><code>optimal"</code> will yield the best pairing overall but can quickly become unfeasible with large data and limited computational power; <code>"</code><code>naiveGreedy"</code> is the least computationally demanding and a good start. <code>"optGreedy"</code> is generally a good compromise for when you’re ready to do the final assignment.</p></dd>
<dt><code>distance</code></dt>
<dd><p>Indicates how to calculate distances between individuals. <code>"</code><code>euclidean"</code> is the distance function from high school, and appropriate for the data we have prepared.</p></dd>
</dl>
<p>The <code>block()</code> function returns the stratified allocation in an unwieldy format, so I created a convenience wrapper that transforms its output into a usable format. Feel free to look at its code on <a href="https://oreil.ly/BehavioralDataAnalysisCh9">GitHub</a>: I’ll just show you its output here:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="o">&gt;</code> <code class="n">Nexp</code> <code class="o">&lt;-</code> <code class="m">4998</code> <code class="c1">#Restricting our data to a multiple of 3</code>
<code class="o">&gt;</code> <code class="n">stratified_data</code> <code class="o">&lt;-</code> <code class="nf">block_wrapper_fun</code><code class="p">(</code><code class="n">prepped_data</code><code class="p">,</code> <code class="n">Nexp</code><code class="p">)</code>
<code class="n">Warning</code> <code class="n">message</code><code class="o">:</code>
<code class="n">attributes</code> <code class="n">are</code> <code class="n">not</code> <code class="n">identical</code> <code class="n">across</code> <code class="n">measure</code> <code class="n">variables</code><code class="p">;</code>
<code class="n">they</code> <code class="n">will</code> <code class="n">be</code> <code class="n">dropped</code> 
<code class="o">&gt;</code> <code class="nf">head</code><code class="p">(</code><code class="n">stratified_data</code><code class="p">,</code><code class="m">3</code><code class="p">)</code>
    <code class="n">ID</code>  <code class="n">sq_ft</code> <code class="n">avg_review</code>  <code class="n">BPday</code> <code class="n">tier.3</code> <code class="n">tier.2</code> <code class="n">tier.1</code>  <code class="n">group</code>
<code class="m">1</code>  <code class="m">224</code> <code class="m">0.6932</code>     <code class="m">0.8167</code> <code class="m">0.4964</code>      <code class="m">1</code>      <code class="m">0</code>      <code class="m">0</code> <code class="n">treat1</code>
<code class="m">2</code> <code class="m">3627</code> <code class="m">0.4143</code>     <code class="m">0.9290</code> <code class="m">0.6084</code>      <code class="m">1</code>      <code class="m">0</code>      <code class="m">0</code> <code class="n">treat1</code>
<code class="m">3</code> <code class="m">4190</code> <code class="m">0.6686</code>     <code class="m">0.5976</code> <code class="m">0.2820</code>      <code class="m">1</code>      <code class="m">0</code>      <code class="m">0</code> <code class="n">treat1</code></pre>
<p>Note that 5,000 is not divisible by 3, so we need to drop at random two rows, the closest smaller number divisible by 3 being 4,998. Comparing the two types of random assignments would show that the experimental groups obtained by stratified randomization are much more similar than the groups obtained by standard randomization.</p>
<p>Beyond helping reduce noise in our experiments, stratification is also helpful if you intend to do subgroup or moderation analysis (which we’ll discuss later in the book). As the phrase goes, “block [with stratification] what you can and randomize what you cannot” (Gerber and Green, 2012).</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="whatapostrophes_a_python_user_to_doques">
<h5>What’s a Python User to Do?</h5>
<p>If you’re a Python user, unfortunately, there’s no equivalent of <a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="stratified randomization" data-tertiary="creating pairs" id="idm45968149199896"/>the <code>block()</code> function.<sup><a data-type="noteref" id="ch01fn20-marker" href="ch09.xhtml#ch01fn20">3</a></sup> I wrote a function, <code>stratified_assgnt_fun()</code>, which does the job for simple cases; you can find it in the <a href="https://oreil.ly/BehavioralDataAnalysis">book’s GitHub repo</a>. It takes as arguments a dataframe of information on the subject base, the number of subjects required for the experiment, and the number of experimental groups required (including control, i.e., 2 for a standard A/B test):</p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python </code>
<code class="c1">#Sampling a random monthly period</code>
<code class="n">per</code> <code class="o">=</code> <code class="n">random</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="nb">range</code><code class="p">(</code><code class="mi">35</code><code class="p">),</code> <code class="mi">1</code><code class="p">)[</code><code class="mi">0</code><code class="p">]</code> <code class="o">+</code> <code class="mi">1</code>
<code class="n">sample_df</code> <code class="o">=</code> <code class="n">hist_data_df</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">hist_data_df</code><code class="o">.</code><code class="n">period</code> <code class="o">==</code> <code class="n">per</code><code class="p">]</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">5000</code><code class="p">)</code>
<code class="n">stratified_data_df</code> <code class="o">=</code> <code class="n">stratified_assgnt_fun</code><code class="p">(</code><code class="n">sample_df</code><code class="p">,</code> <code class="n">K</code><code class="o">=</code><code class="mi">3</code><code class="p">)</code></pre>
<p>This function takes about 30 seconds to run on my laptop for 5,000 subjects. I also created a simple function to compare the results of the stratified assignment with a purely random assignment, <code>assgnt_comparison_fun()</code>, which takes as arguments the dataframe generated by the previous function and the name of a numeric variable we want to use for comparison and returns the standard deviation (s.d.):</p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python</code>
<code class="o">&gt;&gt;</code> <code class="n">assgnt_comparison_fun</code><code class="p">(</code><code class="n">sample_df</code><code class="p">,</code> <code class="s1">'sq_ft'</code><code class="p">)</code>
<code class="n">The</code> <code class="n">s</code><code class="o">.</code><code class="n">d</code><code class="o">.</code> <code class="n">between</code> <code class="n">groups</code> <code class="k">for</code> <code class="n">sq_ft</code> <code class="ow">is</code> <code class="mf">0.1</code> <code class="k">for</code> <code class="n">stratified</code> <code class="n">assignment</code>
<code class="n">The</code> <code class="n">s</code><code class="o">.</code><code class="n">d</code><code class="o">.</code> <code class="n">between</code> <code class="n">groups</code> <code class="k">for</code> <code class="n">sq_ft</code> <code class="ow">is</code> <code class="mf">4.0</code> <code class="k">for</code> <code class="n">random</code> <code class="n">assignment</code>

<code class="n">assgnt_comparison_fun</code><code class="p">(</code><code class="n">sample_df</code><code class="p">,</code> <code class="s1">'BPday'</code><code class="p">)</code>
<code class="n">The</code> <code class="n">s</code><code class="o">.</code><code class="n">d</code><code class="o">.</code> <code class="n">between</code> <code class="n">groups</code> <code class="k">for</code> <code class="n">BPday</code> <code class="ow">is</code> <code class="mf">0.0</code> <code class="k">for</code> <code class="n">stratified</code> <code class="n">assignment</code>
<code class="n">The</code> <code class="n">s</code><code class="o">.</code><code class="n">d</code><code class="o">.</code> <code class="n">between</code> <code class="n">groups</code> <code class="k">for</code> <code class="n">BPday</code> <code class="ow">is</code> <code class="mf">0.3</code> <code class="k">for</code> <code class="n">random</code> <code class="n">assignment</code></pre>
<p>As you can see, even a very simple function hacked together in a few hours can make your experimental groups much more similar than a purely random assignment.</p>
</div></aside>
<p>Stratified randomization is an effective and robust <a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="about" id="idm45968149144376"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="about" id="idm45968149019944"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="stratified randomization" data-tertiary="about" id="idm45968149018328"/>approach to experimental allocation. Its robustness comes largely from its transparency: you can always check afterward that your experimental groups are well-balanced in terms of the means of numeric variables and the proportions of categories for categorical variables.</p>
<p>In addition, because each individual in a pair has the same probability of ending up in any experimental group, even a poorly or wrongly defined distance function will leave you no worse than a purely random allocation. The main risk is to include too many irrelevant variables, which then drown out the relevant variables. That is however easily remedied by including only variables that are part of your causal diagram or the main demographic variables. Don’t add a load of other variables simply because you can.</p>
<p>Categorical variables with a large number of categories can also sometimes add noise to your stratification because of their coarseness. Taking the example of employment, a data scientist is different from a statistician, but intuitively, that difference is less than their joint difference with, say, a firefighter. Very granular variables ignore such nuances, and are better replaced with broader categories.</p>
<p>Lest these caveats discourage you: stratification is effective and robust; don’t be afraid to use it. Even stratifying based only on a few key demographic variables leads to significant improvements and should be your default approach.</p>
<p>Now that we’ve determined how we’re going to do the random allocation, let’s do our power analysis to determine the sample size.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-rass" id="idm45968149013304"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-rass2" id="idm45968149011928"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-rass3" id="idm45968149010552"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-strra" id="idm45968149009176"/></p>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Power Analysis with Bootstrap Simulations"><div class="sect2" id="power_analysis_with_bootstrap_simulatio">
<h2>Power Analysis with Bootstrap Simulations</h2>
<p>After concertation with the business partners, we determine <a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="power analysis with Bootstrap" id="ch09-btpw"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="power analysis with Bootstrap" id="ch09-btpw2"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="power analysis" data-tertiary="stratified randomization" id="ch09-btpw3"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="stratified randomization" data-tertiary="power analysis with Bootstrap" id="ch09-btpw4"/><a contenteditable="false" data-type="indexterm" data-primary="power analysis" data-secondary="Bootstrap simulations" data-tertiary="stratified randomization" id="ch09-btpw5"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="Bootstrap" data-tertiary="power analysis" id="ch09-btpw6"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="Bootstrap" data-tertiary="power analysis" id="ch09-btpw7"/>that we want to have 90% power for an increase in net booking profit (BP) per day of $2, as it is the minimal observable effect they would be interested in. This translates into an increase in “raw” BP/day of $12 for the free-cleaning intervention (treatment 1) and $2 for the minimum-duration intervention (treatment 2). This won’t impact our analyses in any material way, as we can just shift the outcome variable by deducing the $10 cost from the BP/day for properties in the free-cleaning group, but we’ll need to keep that in mind and remember to do it. For the sake of simplicity, I’ll only discuss the minimum-duration intervention in our power analyses.</p>
<p>Simulation methods really shine in situations such as this one, where there are often no available dedicated formulas to calculate power or sample sizes, or available formulas get horribly complex. The alternative would be to use standard formulas that disregard the specifics of the situation (here, the stratification of our experimental data) and cross our fingers that things go well (Murphy’s law: they probably won’t).</p>
<p class="pagebreak-before less_space">Our process will be the same as in <a data-type="xref" href="ch08.xhtml#experimental_design_the_basics">Chapter 8</a>:</p>
<ol>
<li><p>First, we’ll define our metric function and our decision function.</p></li>
<li><p>Then we’ll create a function that simulates a single experiment for a given sample size and effect size.</p></li>
<li><p>Finally, we’ll create a function that simulates a large number of experiments and count how many of them result in a true positive (i.e., our decision function adequately captures the effect); the percentage of true positives is our power for that sample size.</p></li>
</ol>
<section data-type="sect3" data-pdf-bookmark="Single simulation"><div class="sect3" id="single_simulation">
<h3>Single simulation</h3>
<p>Our metric function for the minimum-duration treatment is as follows:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">treat2_metric_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">){</code>
  <code class="n">lin_model</code> <code class="o">&lt;-</code> <code class="nf">lm</code><code class="p">(</code><code class="n">BPday</code><code class="o">~</code><code class="n">sq_ft</code><code class="o">+</code><code class="n">tier</code><code class="o">+</code><code class="n">avg_review</code><code class="o">+</code><code class="n">group</code><code class="p">,</code> <code class="n">data</code> <code class="o">=</code> <code class="n">dat</code><code class="p">)</code>
  <code class="n">summ</code> <code class="o">&lt;-</code> <code class="nf">summary</code><code class="p">(</code><code class="n">lin_model</code><code class="p">)</code>
  <code class="n">coeff</code> <code class="o">&lt;-</code> <code class="n">summ</code><code class="o">$</code><code class="n">coefficients</code><code class="p">[</code><code class="s">'grouptreat2'</code><code class="p">,</code> <code class="s">'Estimate'</code><code class="p">]</code>
  <code class="nf">return</code><code class="p">(</code><code class="n">coeff</code><code class="p">)}</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
 <code class="k">def</code> <code class="nf">treat2_metric_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">):</code>
    <code class="n">model</code> <code class="o">=</code> <code class="n">ols</code><code class="p">(</code><code class="s2">"BPday~sq_ft+tier+avg_review+group"</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">dat_df</code><code class="p">)</code>
    <code class="n">res</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">disp</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>
    <code class="n">coeff</code> <code class="o">=</code> <code class="n">res</code><code class="o">.</code><code class="n">params</code><code class="p">[</code><code class="s1">'group[T.treat2]'</code><code class="p">]</code>
    <code class="k">return</code> <code class="n">coeff</code></pre>
<p>The metric function for treatment 1 would be defined similarly.</p>
<p>We’ll reuse the <code>boot_CI_fun()</code> and <code>decision_fun()</code> functions from <a data-type="xref" href="ch08.xhtml#experimental_design_the_basics">Chapter 8</a>. In other words, our decision rule will be to implement the treatment if its 90%-CI is strictly above zero. I’m repeating their code in the following, just for reference:<a contenteditable="false" data-type="indexterm" data-primary="sample() function" id="idm45968148824408"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="o">&gt;</code> <code class="n">boot_CI_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">metric_fun</code><code class="p">,</code> <code class="n">B</code> <code class="o">=</code> <code class="m">100</code><code class="p">,</code> <code class="n">conf.level</code> <code class="o">=</code> <code class="m">0.9</code><code class="p">){</code>
    <code class="c1">#Setting the number of bootstrap samples</code>
    <code class="n">boot_metric_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">J</code><code class="p">){</code>
      <code class="n">boot_dat</code> <code class="o">&lt;-</code> <code class="n">dat</code><code class="p">[</code><code class="n">J</code><code class="p">,]</code>
      <code class="nf">return</code><code class="p">(</code><code class="nf">metric_fun</code><code class="p">(</code><code class="n">boot_dat</code><code class="p">))}</code>
    <code class="n">boot.out</code> <code class="o">&lt;-</code> <code class="nf">boot</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">dat</code><code class="p">,</code> <code class="n">statistic</code><code class="o">=</code><code class="n">boot_metric_fun</code><code class="p">,</code> <code class="n">R</code><code class="o">=</code><code class="n">B</code><code class="p">)</code>
    <code class="n">confint</code> <code class="o">&lt;-</code> <code class="nf">boot.ci</code><code class="p">(</code><code class="n">boot.out</code><code class="p">,</code> <code class="n">conf</code> <code class="o">=</code> <code class="n">conf.level</code><code class="p">,</code> <code class="n">type</code> <code class="o">=</code> <code class="nf">c</code><code class="p">(</code><code class="s">'perc'</code><code class="p">))</code>
    <code class="n">CI</code> <code class="o">&lt;-</code> <code class="n">confint</code><code class="o">$</code><code class="n">percent</code><code class="nf">[c</code><code class="p">(</code><code class="m">4</code><code class="p">,</code><code class="m">5</code><code class="p">)]</code>
    
    <code class="nf">return</code><code class="p">(</code><code class="n">CI</code><code class="p">)}</code>
<code class="o">&gt;</code> <code class="n">decision_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">metric_fun</code><code class="p">){</code>
    <code class="n">boot_CI</code> <code class="o">&lt;-</code> <code class="nf">boot_CI_fun</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">metric_fun</code><code class="p">)</code>
    <code class="n">decision</code> <code class="o">&lt;-</code> <code class="nf">ifelse</code><code class="p">(</code><code class="n">boot_CI</code><code class="p">[</code><code class="m">1</code><code class="p">]</code><code class="o">&gt;</code><code class="m">0</code><code class="p">,</code><code class="m">1</code><code class="p">,</code><code class="m">0</code><code class="p">)</code>
    <code class="nf">return</code><code class="p">(</code><code class="n">decision</code><code class="p">)}</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
<code class="k">def</code> <code class="nf">boot_CI_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">,</code> <code class="n">metric_fun</code><code class="p">,</code> <code class="n">B</code> <code class="o">=</code> <code class="mi">100</code><code class="p">,</code> <code class="n">conf_level</code> <code class="o">=</code> <code class="mf">0.9</code><code class="p">):</code>
  <code class="c1">#Setting sample size</code>
  <code class="n">N</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">dat_df</code><code class="p">)</code>
  <code class="n">coeffs</code> <code class="o">=</code> <code class="p">[]</code>
  
  <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">B</code><code class="p">):</code>
      <code class="n">sim_data_df</code> <code class="o">=</code> <code class="n">dat_df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">n</code><code class="o">=</code><code class="n">N</code><code class="p">,</code> <code class="n">replace</code> <code class="o">=</code> <code class="bp">True</code><code class="p">)</code>
      <code class="n">coeff</code> <code class="o">=</code> <code class="n">metric_fun</code><code class="p">(</code><code class="n">sim_data_df</code><code class="p">)</code>
      <code class="n">coeffs</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">coeff</code><code class="p">)</code>
  
  <code class="n">coeffs</code><code class="o">.</code><code class="n">sort</code><code class="p">()</code>
  <code class="n">start_idx</code> <code class="o">=</code> <code class="nb">round</code><code class="p">(</code><code class="n">B</code> <code class="o">*</code> <code class="p">(</code><code class="mi">1</code> <code class="o">-</code> <code class="n">conf_level</code><code class="p">)</code> <code class="o">/</code> <code class="mi">2</code><code class="p">)</code>
  <code class="n">end_idx</code> <code class="o">=</code> <code class="o">-</code> <code class="nb">round</code><code class="p">(</code><code class="n">B</code> <code class="o">*</code> <code class="p">(</code><code class="mi">1</code> <code class="o">-</code> <code class="n">conf_level</code><code class="p">)</code> <code class="o">/</code> <code class="mi">2</code><code class="p">)</code>
  <code class="n">confint</code> <code class="o">=</code> <code class="p">[</code><code class="n">coeffs</code><code class="p">[</code><code class="n">start_idx</code><code class="p">],</code> <code class="n">coeffs</code><code class="p">[</code><code class="n">end_idx</code><code class="p">]]</code>  
  <code class="k">return</code><code class="p">(</code><code class="n">confint</code><code class="p">)</code>

<code class="k">def</code> <code class="nf">decision_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">,</code> <code class="n">metric_fun</code><code class="p">,</code> <code class="n">B</code> <code class="o">=</code> <code class="mi">100</code><code class="p">,</code> <code class="n">conf_level</code> <code class="o">=</code> <code class="mf">0.9</code><code class="p">):</code>
    <code class="n">boot_CI</code> <code class="o">=</code> <code class="n">boot_CI_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">,</code> <code class="n">metric_fun</code><code class="p">,</code> <code class="n">B</code> <code class="o">=</code> <code class="n">B</code><code class="p">,</code> <code class="n">conf_level</code> <code class="o">=</code> <code class="n">conf_level</code><code class="p">)</code>
    <code class="n">decision</code> <code class="o">=</code> <code class="mi">1</code> <code class="k">if</code> <code class="n">boot_CI</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">&gt;</code> <code class="mi">0</code>  <code class="k">else</code> <code class="mi">0</code>
    <code class="k">return</code> <code class="n">decision</code></pre>
<p>We can then write the function to run a single simulation, which embeds the logic we’ve seen so far:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code><code>
</code><code class="n">single_sim_fun</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code><code> </code><code class="n">Nexp</code><code class="p">,</code><code> </code><code class="n">eff_size</code><code class="p">)</code><code class="p">{</code><code>
  
  </code><code class="c1">#Filter the data down to a random month </code><a class="co" id="comarker91c" href="#c091"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code class="c1">          </code><code>
  </code><code class="n">per</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">sample</code><code class="p">(</code><code class="m">1</code><code class="o">:</code><code class="m">35</code><code class="p">,</code><code> </code><code class="n">size</code><code class="o">=</code><code class="m">1</code><code class="p">)</code><code>
  </code><code class="n">dat</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">dat</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="nf">filter</code><code class="p">(</code><code class="n">period</code><code> </code><code class="o">==</code><code> </code><code class="n">per</code><code class="p">)</code><code>
  
  </code><code class="c1">#Prepare the stratified assignment for a random sample of desired size </code><a class="co" id="comarker92c" href="#c092"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code class="c1"> </code><code>
  </code><code class="n">stratified_assgnt</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">dat</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="nf">slice_sample</code><code class="p">(</code><code class="n">n</code><code class="o">=</code><code class="n">Nexp</code><code class="p">)</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="c1">#Stratified assignment</code><code>
    </code><code class="nf">block_wrapper_fun</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="c1">#extract the ID and group assignment</code><code>
    </code><code class="nf">select</code><code class="p">(</code><code class="n">ID</code><code class="p">,</code><code> </code><code class="n">group</code><code class="p">)</code><code>
  
  </code><code class="n">sim_data</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">dat</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="c1">#Apply assignment to full data </code><a class="co" id="comarker93c" href="#c093"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code class="c1">                           </code><code>
    </code><code class="nf">inner_join</code><code class="p">(</code><code class="n">stratified_assgnt</code><code class="p">)</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="c1">#Add target effect size</code><code>
    </code><code class="nf">mutate</code><code class="p">(</code><code class="n">BPday</code><code> </code><code class="o">=</code><code> </code><code class="nf">ifelse</code><code class="p">(</code><code class="n">group</code><code> </code><code class="o">==</code><code> </code><code class="s">'</code><code class="s">treat2'</code><code class="p">,</code><code> </code><code class="n">BPday</code><code> </code><code class="o">+</code><code> </code><code class="n">eff_size</code><code class="p">,</code><code> </code><code class="n">BPday</code><code class="p">)</code><code class="p">)</code><code>
  
  </code><code class="c1">#Calculate the decision (we want it to be 1) </code><a class="co" id="comarker94c" href="#c094"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code class="c1">    </code><code>
  </code><code class="n">decision</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">decision_fun</code><code class="p">(</code><code class="n">sim_data</code><code class="p">,</code><code> </code><code class="n">treat2_metric_fun</code><code class="p">)</code><code>
  </code><code class="nf">return</code><code class="p">(</code><code class="n">decision</code><code class="p">)</code><code class="p">}</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code><code>
</code><code class="k">def</code><code> </code><code class="nf">single_sim_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">,</code><code> </code><code class="n">metric_fun</code><code class="p">,</code><code> </code><code class="n">Nexp</code><code class="p">,</code><code> </code><code class="n">eff_size</code><code class="p">,</code><code> </code><code class="n">B</code><code> </code><code class="o">=</code><code> </code><code class="mi">100</code><code class="p">,</code><code> </code><code>
</code><code>                   </code><code class="n">conf_level</code><code> </code><code class="o">=</code><code> </code><code class="mf">0.9</code><code class="p">)</code><code class="p">:</code><code>
</code><code>    </code><code>
</code><code>    </code><code class="c1">#Filter the data down to a random month </code><a class="co" id="comarker91b" href="#c091"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code class="c1"> </code><code>
</code><code>    </code><code class="n">per</code><code> </code><code class="o">=</code><code> </code><code class="n">random</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="nb">range</code><code class="p">(</code><code class="mi">35</code><code class="p">)</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">)</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code> </code><code class="o">+</code><code> </code><code class="mi">1</code><code>
</code><code>    </code><code class="n">dat_df</code><code> </code><code class="o">=</code><code> </code><code class="n">dat_df</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">dat_df</code><code class="o">.</code><code class="n">period</code><code> </code><code class="o">==</code><code> </code><code class="n">per</code><code class="p">]</code><code>
</code><code>    </code><code class="n">dat_df</code><code> </code><code class="o">=</code><code> </code><code class="n">dat_df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">n</code><code class="o">=</code><code class="n">Nexp</code><code class="p">)</code><code>
</code><code>    </code><code>
</code><code>    </code><code class="c1">#Prepare the stratified assignment for a random sample of desired size </code><a class="co" id="comarker92b" href="#c092"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>    </code><code class="n">assgnt</code><code> </code><code class="o">=</code><code> </code><code class="n">strat_assgnt_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">,</code><code> </code><code class="n">Nexp</code><code> </code><code class="o">=</code><code> </code><code class="n">Nexp</code><code class="p">)</code><code>
</code><code>    </code><code class="n">sim_data_df</code><code> </code><code class="o">=</code><code> </code><code class="n">dat_df</code><code class="o">.</code><code class="n">merge</code><code class="p">(</code><code class="n">assgnt</code><code class="p">,</code><code> </code><code class="n">on</code><code class="o">=</code><code class="s1">'</code><code class="s1">ID</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">how</code><code class="o">=</code><code class="s1">'</code><code class="s1">inner</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>    </code><code>
</code><code>    </code><code class="c1">#Add target effect size </code><a class="co" id="comarker93b" href="#c093"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>    </code><code class="n">sim_data_df</code><code class="o">.</code><code class="n">BPday</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">sim_data_df</code><code class="o">.</code><code class="n">group</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">treat2</code><code class="s1">'</code><code class="p">,</code><code> </code><code>
</code><code>                                 </code><code class="n">sim_data_df</code><code class="o">.</code><code class="n">BPday</code><code> </code><code class="o">+</code><code> </code><code class="n">eff_size</code><code class="p">,</code><code> </code><code class="n">sim_data_df</code><code class="o">.</code><code class="n">BPday</code><code class="p">)</code><code>
</code><code>    </code><code>
</code><code>    </code><code class="c1">#Calculate the decision (we want it to be 1) </code><a class="co" id="comarker94b" href="#c094"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code class="c1">  </code><code>
</code><code>    </code><code class="n">decision</code><code> </code><code class="o">=</code><code> </code><code class="n">decision_fun</code><code class="p">(</code><code class="n">sim_data_df</code><code class="p">,</code><code> </code><code class="n">metric_fun</code><code class="p">,</code><code> </code><code class="n">B</code><code> </code><code class="o">=</code><code> </code><code class="n">B</code><code class="p">,</code><code> </code><code>
</code><code>                            </code><code class="n">conf_level</code><code> </code><code class="o">=</code><code> </code><code class="n">conf_level</code><code class="p">)</code><code>
</code><code>    </code><code class="k">return</code><code> </code><code class="n">decision</code></pre>

<dl class="calloutlist">
 <dt><a class="co" id="c091" href="#comarker91b"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
  <dd><p>Select a month at random, to mimic the way we will run our actual experiment (we don’t want to use data from 10 years apart in our power analysis).</p></dd> 
 <dt><a class="co" id="c092" href="#comarker92b"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
  <dd><p>Generate stratified random assignment for a sample of desired size.</p></dd>
 <dt><a class="co" id="c093" href="#comarker93b"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
  <dd><p>Apply the assignment to the data and apply the target effect size to treatment group 2.</p></dd> 
 <dt><a class="co" id="c094" href="#comarker94b"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
  <dd><p>Apply the decision function and return its output.</p></dd> 
</dl>

</div></section>
<section data-type="sect3" data-pdf-bookmark="Simulations at scale"><div class="sect3" id="simulations_at_scale">
<h3>Simulations at scale</h3>
<p>From there, we can apply the same overall function for power simulations as in <a data-type="xref" href="ch08.xhtml#experimental_design_the_basics">Chapter 8</a> (repeated in the following for reference):</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">power_sim_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">Nexp</code><code class="p">,</code> <code class="n">eff_size</code><code class="p">,</code> <code class="n">Nsim</code><code class="p">){</code>
  <code class="n">power_list</code> <code class="o">&lt;-</code> <code class="nf">vector</code><code class="p">(</code><code class="n">mode</code> <code class="o">=</code> <code class="s">"list"</code><code class="p">,</code> <code class="n">length</code> <code class="o">=</code> <code class="n">Nsim</code><code class="p">)</code>
  <code class="nf">for</code><code class="p">(</code><code class="n">i</code> <code class="n">in</code> <code class="m">1</code><code class="o">:</code><code class="n">Nsim</code><code class="p">){</code>
    <code class="n">power_list</code><code class="p">[[</code><code class="n">i</code><code class="p">]]</code> <code class="o">&lt;-</code> <code class="nf">single_sim_fun</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">Nexp</code><code class="p">,</code> <code class="n">eff_size</code><code class="p">)}</code>
  <code class="n">power</code> <code class="o">&lt;-</code> <code class="nf">mean</code><code class="p">(</code><code class="nf">unlist</code><code class="p">(</code><code class="n">power_list</code><code class="p">))</code>
  <code class="nf">return</code><code class="p">(</code><code class="n">power</code><code class="p">)}</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
<code class="k">def</code> <code class="nf">power_sim_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">,</code> <code class="n">metric_fun</code><code class="p">,</code> <code class="n">Nexp</code><code class="p">,</code> <code class="n">eff_size</code><code class="p">,</code> <code class="n">Nsim</code><code class="p">,</code> <code class="n">B</code> <code class="o">=</code> <code class="mi">100</code><code class="p">,</code> 
                  <code class="n">conf_level</code> <code class="o">=</code> <code class="mf">0.9</code><code class="p">):</code>
    <code class="n">power_lst</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">Nsim</code><code class="p">):</code>
        <code class="n">power_lst</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">single_sim_fun</code><code class="p">(</code><code class="n">dat_df</code><code class="p">,</code> <code class="n">metric_fun</code> <code class="o">=</code> <code class="n">metric_fun</code><code class="p">,</code> 
                                        <code class="n">Nexp</code> <code class="o">=</code> <code class="n">Nexp</code><code class="p">,</code> <code class="n">eff_size</code> <code class="o">=</code> <code class="n">eff_size</code><code class="p">,</code> 
                                        <code class="n">B</code> <code class="o">=</code> <code class="n">B</code><code class="p">,</code> <code class="n">conf_level</code> <code class="o">=</code> <code class="n">conf_level</code><code class="p">))</code>
    <code class="n">power</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">power_lst</code><code class="p">)</code>
    <code class="k">return</code><code class="p">(</code><code class="n">power</code><code class="p">)</code></pre>
<p>Our maximum sample size would be 5,000, because that’s the total number of property owners AirCnC has. That’s a manageable number for simulation purposes, so let’s first run 100 simulations with that sample size. There’s no point in working our way up to that if it turns out that we would need to use our entire population for the experiment. We find a power of 1, which is comforting: the required sample size is less than our total population. From there, we try different sample sizes, progressively increasing the number of simulations as we zero in on the sample size with a power of 0.90 (<a data-type="xref" href="#iterative_power_simulations_with_increa">Figure 9-2</a>).</p>
<figure><div id="iterative_power_simulations_with_increa" class="figure">
<img src="Images/BEDA_0902.png" alt="Iterative power simulations with increasing number of simulations, with labels indicating the order of runs" width="1879" height="1166"/>
<h6><span class="label">Figure 9-2. </span>Iterative power simulations with increasing number of simulations, with labels indicating the order of runs</h6>
</div></figure>
<p>It looks like a sample size of 1,500 will do. As in <a data-type="xref" href="ch08.xhtml#experimental_design_the_basics">Chapter 8</a>, let’s now determine the power curve for various effect sizes at that sample size (<a data-type="xref" href="#power_to_detect_various_effect_sizes_an">Figure 9-3</a>).</p>
<figure><div id="power_to_detect_various_effect_sizes_an" class="figure">
<img src="Images/BEDA_0903.png" alt="Power to detect various effect sizes and significance (sample size = 1,500)" width="1898" height="1158"/>
<h6><span class="label">Figure 9-3. </span>Power to detect various effect sizes and significance (sample size = 1,500)</h6>
</div></figure>
<p>As you can see in <a data-type="xref" href="#power_to_detect_various_effect_sizes_an">Figure 9-3</a>, our power curve drops very steeply, going from an effect size of $2 to $1, and our power is almost nil for effect sizes less than 1; that is, if we assume that the treatment increases <em>BPday</em> by $1, we’re very likely to end up with a CI that includes zero and then conclude that there’s no effect. At the leftward end of the curve, our simulated significance is equal to zero, instead of the expected 5%. Let’s discuss what causes that and whether we should worry about it.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Understanding the power/significance trade-off"><div class="sect3" id="understanding_the_powersolidussignifica">
<h3>Understanding the power/significance trade-off</h3>
<p>As I mentioned in the last chapter, if our data is<a contenteditable="false" data-type="indexterm" data-primary="power analysis" data-secondary="power/significance trade-off" data-seealso="statistical power" id="idm45968147796744"/><a contenteditable="false" data-type="indexterm" data-primary="statistical significance (p-value)" data-secondary="power/significance trade-off" id="idm45968147795128"/><a contenteditable="false" data-type="indexterm" data-primary="p-value" data-secondary="power/significance trade-off" id="idm45968147793720"/><a contenteditable="false" data-type="indexterm" data-primary="statistical power" data-secondary="power/significance trade-off" id="idm45968147792328"/><a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="power/significance trade-off" id="idm45968147790936"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="power analysis with Bootstrap" data-tertiary="power/significance trade-off" id="idm45968147789528"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="power/significance trade-off" id="idm45968147787832"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="random assignment" data-tertiary="power/significance trade-off" id="idm45968147786152"/><a contenteditable="false" data-type="indexterm" data-primary="random assignment" data-secondary="power/significance trade-off" id="idm45968147784488"/> “well-behaved” (i.e., normally distributed, allocated between experimental groups purely at random, etc.) and there is no true effect, we would expect a 90%-CI to include zero 90% of the time, be strictly above it 5% of the time, and be strictly under it 5% of the time. Here, because of the stratified randomization, our false positive rate appears lower than 5%: I observed none whatsoever in 500 simulations. By reducing the noise in our data, stratified randomization also reduces the risk of false positives.</p>
<p>That’s nice but in this case it may be too much of a good thing, because it also brings down the power curve for small positive effects up to 1, as we can see in <a data-type="xref" href="#power_to_detect_various_effect_sizes_an">Figure 9-3</a>. Let’s put it in a different way: if we had a 5% chance of assuming there is an effect when there is none, then we would have at least a 5% chance of assuming that there is an effect when there is a small one. In that sense, significance gives us some “free” power for low effect sizes.</p>
<p>Let’s compare the previous power curve with the power curves for lower confidence levels. By definition, this will give us narrower confidence intervals, meaning a higher significance and a higher power, especially for small effect sizes (<a data-type="xref" href="#comparison_of_power_curves_for_confiden">Figure 9-4</a>).</p>
<figure><div id="comparison_of_power_curves_for_confiden" class="figure">
<img src="Images/BEDA_0904.png" alt="Comparison of power curves for confidence levels 0.90 (solid line), 0.80 (long-dash line), 0.60 (dashed line), and 0.40 (dotted line)" width="1898" height="1158"/>
<h6><span class="label">Figure 9-4. </span>Comparison of power curves for confidence levels 0.90 (solid line), 0.80 (long-dash line), 0.60 (dashed line), and 0.40 (dotted line)</h6>
</div></figure>
<p>As you can see, with a 40%-CI, we only get a small increase in significance but a large increase in power, with a power of approximately 50% to detect an effect size of 0.5.</p>
<p>Does that mean that we should use a 40%-CI instead of a 90%-CI? It depends. Let’s get back to the business problem. Our business partners have asked for a power of 90% for an effect size of 2 because they’re not interested in going through the hassle of implementing either of the treatments if the benefits are lower than that. Thus, capturing a true effect size of 0.5 with a CI that doesn’t include zero, or having a CI that includes zero, is essentially the same thing from a business perspective. Either way, no treatment will be implemented. Therefore, the power curve for the 90%-CI better reflects our business goals.</p>
<p>On the other hand, with an experiment like the “1-click button” in <a data-type="xref" href="ch08.xhtml#experimental_design_the_basics">Chapter 8</a>, costs and risks of implementation are limited. The 90% power threshold is just a baseline, and virtually any strictly positive effect would warrant implementation. In such a situation, increasing power for small effect sizes is probably worth a slight increase in significance.</p>
<p>More broadly, when your data or your experimental design diverge from the standard framework, power analysis stops being a simple matter of plugging conventional numbers into a formula and requires understanding what’s going on and making judgment calls about the right decisions. Fortunately, power curves offer a great tool to visualize the possible outcomes of an experiment under different scenarios and different decision rules.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-btpw" id="idm45968147772536"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-btpw2" id="idm45968147771160"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-btpw3" id="idm45968147769784"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-btpw4" id="idm45968147768408"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-btpw5" id="idm45968147767032"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-btpw6" id="idm45968147765656"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-btpw7" id="idm45968147764280"/></p>
</div></section>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Analyzing and Interpreting Experimental Results"><div class="sect1" id="analyzing_and_interpreting_experimental">
<h1>Analyzing and Interpreting Experimental Results</h1>
<p>Once we’ve run the experiment, we can analyze its results. <a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="analyzing experimental results" id="ch09-anz"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="analyzing experimental results" id="ch09-anz2"/><a contenteditable="false" data-type="indexterm" data-primary="T-test of means" id="idm45968147757368"/><a contenteditable="false" data-type="indexterm" data-primary="linear regression" data-secondary="stratified randomization analysis" id="ch09-anz3"/><a contenteditable="false" data-type="indexterm" data-primary="AirCnC (Air Coach and Couch)" data-secondary="stratified randomization" data-tertiary="analyzing experimental results" id="ch09-anz4"/>Our target metric, average booking profit per day, is continuous and not binary; therefore, the two appropriate methods are the T-test of means and linear regression. I will refer you to Gerber and Green (2012) if you want to learn more about the T-test, and I’ll cover linear <span class="keep-together">regression.</span></p>
<p>Before getting into the quantitative analysis, remember that we could not force owners to have a two-night minimum duration or to agree to a reduction in the duration of the cleaning window in exchange for free cleaning services. <a contenteditable="false" data-type="indexterm" data-primary="encouragement design" id="idm45968147751000"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="encouragement design" id="idm45968147749896"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="analyzing experimental results" data-tertiary="encouragement design" id="idm45968147748520"/>We could only offer them the opportunity to opt in, which some took and others did not. In technical terms, this approach is called an <em>encouragement design</em>, because we’re encouraging subjects to take up our offer.</p>
<p>Encouragement designs are very common, but they introduce some additional considerations, because we now have two categories of people in a treatment group: those who opted in and those who didn’t. For practical purposes, this means we have two different questions we can try to answer:</p>
<ul>
<li><p>What would happen if we offered the possibility of opting into the treatment to our entire owner population?</p></li>
<li><p>What would happen if we enforced the treatment on our entire owner population, without giving them the option of opting out?</p></li>
</ul>
<p>The answer to the first question is called the <em>i</em><em>ntention-to-treat</em> (ITT) estimate<a contenteditable="false" data-type="indexterm" data-primary="intention-to-treat (ITT) estimate" id="idm45968147742184"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="analyzing experimental results" data-tertiary="intention-to-treat (ITT) estimate" id="idm45968147741080"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="intention-to-treat (ITT) estimate" id="idm45968147739384"/><a contenteditable="false" data-type="indexterm" data-primary="encouragement design" data-secondary="intention-to-treat (ITT) estimate" id="idm45968147737704"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="encouragement design" data-tertiary="intention-to-treat (ITT) estimate" id="idm45968147713400"/> because we intend for people to be treated but we don’t make it mandatory. The second question is more complex, and we can’t answer it fully based only on an encouragement design (or at least it requires additional assumptions), but we can get a closer approximation than the ITT estimate, with the <em>complier average causal effect</em> (CACE) <span class="keep-together">estimate.</span></p>
<p>Let’s calculate both of these estimates in turn.</p>
<section data-type="sect2" data-pdf-bookmark="Intention-to-Treat Estimate for Encouragement Intervention"><div class="sect2" id="intention_to_treat_estimate_for_encoura">
<h2>Intention-to-Treat Estimate for Encouragement Intervention</h2>
<p>Let’s first calculate the ITT estimate, which will be very easy: it’s simply the coefficient for the effect of the experimental assignment, as we’ve calculated in the previous chapter. Should we factor in the fact that the majority of the owners in the treatment groups did not opt in? No. The fact that the ITT coefficient is diluted by people who opted out is a feature, not a bug: the same dilution would happen at a larger scale.</p>
<p>Let’s subtract $10 for the owners in the cleaning group who opted in, to account for the extra cost, then run a linear regression. We could apply our metric functions separately, but I prefer running the whole regression at once to be able to see the other coefficients as well:<a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="stratified randomization" data-tertiary="intention-to-treat estimate" id="idm45968147706760"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="stratified randomization" data-tertiary="intention-to-treat estimate" id="idm45968147705080"/></p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python (output not shown)</code>
<code class="n">exp_data_reg_df</code> <code class="o">=</code> <code class="n">exp_data_df</code><code class="o">.</code><code class="n">copy</code><code class="p">()</code>
<code class="n">exp_data_reg_df</code><code class="o">.</code><code class="n">BPday</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">((</code><code class="n">exp_data_reg_df</code><code class="o">.</code><code class="n">compliant</code> <code class="o">==</code> <code class="mi">1</code><code class="p">)</code> <code class="o">&amp;</code> \
                                 <code class="p">(</code><code class="n">exp_data_reg_df</code><code class="o">.</code><code class="n">group</code> <code class="o">==</code> <code class="s1">'treat2'</code><code class="p">),</code> 
                                 <code class="n">exp_data_reg_df</code><code class="o">.</code><code class="n">BPday</code> <code class="o">-</code><code class="mi">10</code><code class="p">,</code> 
                                 <code class="n">exp_data_reg_df</code><code class="o">.</code><code class="n">BPday</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">ols</code><code class="p">(</code><code class="s2">"BPday~sq_ft+tier+avg_review+group"</code><code class="p">,</code> 
          <code class="n">data</code><code class="o">=</code><code class="n">exp_data_reg_df</code><code class="p">)</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">disp</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code class="o">.</code><code class="n">summary</code><code class="p">())</code></pre>
<pre data-type="programlisting" data-code-language="r">
<code class="c1">## R</code><code>
</code><code class="o">&gt;</code><code> </code><code class="n">exp_data_reg</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">exp_data</code><code> </code><code class="o">%&gt;%</code><code>
    </code><code class="nf">mutate</code><code class="p">(</code><code class="n">BPday</code><code> </code><code class="o">=</code><code> </code><code class="n">BPday</code><code> </code><code class="o">-</code><code> </code><code class="nf">ifelse</code><code class="p">(</code><code class="n">group</code><code class="o">==</code><code class="s">"</code><code class="s">treat2"</code><code> </code><code class="o">&amp;</code><code> </code><code class="n">compliant</code><code class="p">,</code><code> </code><code class="m">10</code><code class="p">,</code><code class="m">0</code><code class="p">)</code><code class="p">)</code><code>
</code><code class="o">&gt;</code><code> </code><code class="n">lin_model</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">lm</code><code class="p">(</code><code class="n">BPday</code><code class="o">~</code><code class="n">sq_ft</code><code class="o">+</code><code class="n">tier</code><code class="o">+</code><code class="n">avg_review</code><code class="o">+</code><code class="n">group</code><code class="p">,</code><code> </code><code class="n">data</code><code> </code><code class="o">=</code><code> </code><code class="n">exp_data_reg</code><code class="p">)</code><code>
</code><code class="o">&gt;</code><code> </code><code class="nf">summary</code><code class="p">(</code><code class="n">lin_model</code><code class="p">)</code><code>

</code><code class="kc">...</code><code>
</code><code class="n">Coefficients</code><code class="o">:</code><code>
             </code><code class="n">Estimate</code><code> </code><code class="n">Std.</code><code> </code><code class="n">Error</code><code> </code><code class="n">t</code><code> </code><code class="n">value</code><code>        </code><code class="nf">Pr</code><code class="p">(</code><code class="o">&gt;</code><code class="o">|</code><code class="n">t</code><code class="o">|</code><code class="p">)</code><code>    
</code><code class="p">(</code><code class="n">Intercept</code><code class="p">)</code><code> </code><code class="m">19.232831</code><code>   </code><code class="m">3.573522</code><code>   </code><code class="m">5.382</code><code> </code><code class="m">0.0000000854103</code><code> </code><code class="o">*</code><code class="o">*</code><code class="o">*</code><code>
</code><code class="n">sq_ft</code><code>        </code><code class="m">0.006846</code><code>   </code><code class="m">0.003726</code><code>   </code><code class="m">1.838</code><code>          </code><code class="m">0.0663</code><code> </code><code class="n">. </code><code> 
</code><code class="n">tier2</code><code>        </code><code class="m">1.059599</code><code>   </code><code class="m">0.840598</code><code>   </code><code class="m">1.261</code><code>          </code><code class="m">0.2077</code><code>    
</code><code class="n">tier1</code><code>        </code><code class="m">5.170473</code><code>   </code><code class="m">1.036066</code><code>   </code><code class="m">4.990</code><code> </code><code class="m">0.0000006728868</code><code> </code><code class="o">*</code><code class="o">*</code><code class="o">*</code><code>
</code><code class="n">avg_review</code><code>   </code><code class="m">1.692557</code><code>   </code><code class="m">0.253566</code><code>   </code><code class="m">6.675</code><code> </code><code class="m">0.0000000000347</code><code> </code><code class="o">*</code><code class="o">*</code><code class="o">*</code><code>
</code><strong><code class="n">grouptreat1</code><code>  </code><code class="m">0.966938</code><code>   </code><code class="m">0.888683</code><code>   </code><code class="m">1.088</code><code>          </code><code class="m">0.2767</code></strong><code>
</code><strong><code class="n">grouptreat2</code><code> </code><code class="m">-0.172594</code><code>   </code><code class="m">0.888391</code><code>  </code><code class="m">-0.194</code><code>          </code><code class="m">0.8460</code></strong><code>
</code><code class="kc">...</code></pre>
<p>We do a regression of our variable of interest, booked profit per day, on the square footage of the property, the city tier, the average of the customer reviews, and the experimental groups. The coefficient for <em>Grouptreat1</em> refers to the minimum-duration treatment while <em>Grouptreat2</em> refers to the free-cleaning treatment.</p>
<p>The first treatment increases <em>BPday</em> by approximately $0.97 on average, but the p-value is moderately high, at approximately 0.27. This suggests that the coefficient may not be significantly different from zero, and indeed the corresponding Bootstrap 90%-CI is approximately [0.002; 2.66].</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If you were to run a T-test comparing the first treatment group with the control group, you’d find that the absolute value of the test statistic is 0.96, close to the coefficient in the regression we just ran. Similarly, the raw difference in <em>BPday</em> averages between the control group and the first treatment group is approximately 0.85. Should that surprise us? No. Thanks to stratification, our experimental groups are very well balanced and therefore other independent variables have the same average effect across groups. This means that even metrics that don’t account for covariates are unbiased (their p-values would be off, however, because they don’t take into account the stratification).</p>
</div>
<p>The second treatment decreases <em>BPday</em> by approximately $0.17, after cost, not a great value proposition. The corresponding CI is [-2.23; 1.61].</p>
<p>Remember that our business partners are interested only in implementing an intervention if it generates $2 of additional BP/day above costs. On the face of it, this would preclude implementing the minimum-duration intervention—not just because the statistical significance is borderline, but primarily because of the lack of economic significance. Even if the lower bound of the confidence interval was squarely above zero, this would still not change our business partners’ decision.</p>
<p>If this had to be the end of the story, our business partners would not implement either of the encouragement interventions. However, it might be worth considering what would happen if we enforced the minimum-duration treatment across the board without offering people the option to opt out.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Complier Average Causal Estimate for Mandatory Intervention"><div class="sect2" id="complier_average_causal_estimate_for_ma">
<h2>Complier Average Causal Estimate for Mandatory Intervention</h2>
<p>When we have an encouragement design, can we estimate the effect of making the treatment mandatory? <a contenteditable="false" data-type="indexterm" data-primary="encouragement design" data-secondary="complier average causal effect" id="ch09-cace2"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="encouragement design" data-tertiary="complier average causal effect" id="ch09-cace3"/><a contenteditable="false" data-type="indexterm" data-primary="complier average causal effect (CACE) for encouragement design" id="ch09-cace"/><a contenteditable="false" data-type="indexterm" data-primary="stratified randomization" data-secondary="analyzing experimental results" data-tertiary="complier average causal effect for encouragement design" id="ch09-cace4"/><a contenteditable="false" data-type="indexterm" data-primary="experimental design" data-secondary="stratified randomization" data-tertiary="complier average causal effect for mandatory intervention" id="ch09-cace5"/>A tempting but incorrect way to answer it would be to compare the value of the business metric for the opt-in category (a.k.a. the “treated”) on the one hand, with the value for the opt-out category and the control group on the other hand, lumping the latter two together as “untreated.” One could assume that this comparison would reflect the expected outcome of enforcing the treatment across the board, i.e., imposing a two-night minimum in hot markets or unilaterally shortening the cleaning window while offering free cleaning, regardless of owners’ preferences. It does not, because opting in to the treatment is not randomized and is likely to be confounded. Within the treatment groups, it is plausible that the owners who opt in are in some regards different from the owners who don’t, e.g., they have financial needs or other characteristics that make them give more attention and effort to their property (<a data-type="xref" href="#the_experimental_allocation_is_randomi">Figure 9-5</a>).</p>
<figure><div id="the_experimental_allocation_is_randomi" class="figure">
<img src="Images/BEDA_0905.png" alt="The experimental allocation is randomized but accepting the free-cleaning treatment is not" width="1456" height="731"/>
<h6><span class="label">Figure 9-5. </span>The experimental allocation is randomized but accepting the free-cleaning treatment is not</h6>
</div></figure>
<p>If that CD is correct, then accepting the free-cleaning offer is correlated with behaviors that increase booked profit per day and bias upward our coefficient. In other words, we would wrongly attribute to the offer some of the effect of those behaviors if we compared people who opt in with people who don’t. The random allocation ensures that comparisons between experimental groups are unbiased, but it doesn’t guarantee anything for subgroups further down the line.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In the case of email A/B tests, this limitation on the <a contenteditable="false" data-type="indexterm" data-primary="A/B tests" data-secondary="complier average causal effect (CACE) for encouragement design" id="idm45968147488216"/>effect of randomization means that rates (e.g., opening rate, click-through rate, etc.) should all have as numerator the number of people in the experimental group and not the number of people from the previous stage. If 50% of people open your email and 50% of those who open the email click through, the click-through rate should be expressed as 25%, not 50%.</p>
</div>
<p>In an encouragement design, we intend for the people in the treatment group to opt in and get treated, but we also intend for people in the control group to <em>not</em> be treated. However, in certain situations we can’t prevent them from accessing the treatment. In our present example, the free-cleaning treatment has features that are entirely under our control: property owners may use professional cleaning services but they have to pay for it, and the window between bookings is baked in the software. Therefore no one outside of that treatment group can access that precise treatment. Things are less clear-cut however with the two-night minimum treatment: property owners outside of that treatment group may unofficially enforce a two-night minimum by rejecting single-night requested bookings (<a data-type="xref" href="#the_experimental_allocation_is_randomiz">Figure 9-6</a>).</p>
<figure><div id="the_experimental_allocation_is_randomiz" class="figure">
<img src="Images/BEDA_0906.png" alt="The experimental allocation is randomized but accepting the minimum booking treatment is not, and it can happen outside of the treatment group" width="1456" height="731"/>
<h6><span class="label">Figure 9-6. </span>The experimental allocation is randomized but accepting the minimum booking treatment is not, and it can happen outside of the treatment group</h6>
</div></figure>
<p>With the minimum booking treatment, there are four possible cases for owners that we can observe:</p>
<ol type="A">
<li><p>Being in the control group and not having a two-night minimum</p></li>
<li><p>Being in the control group and having a two-night minimum nonetheless</p></li>
<li><p>Being in the treatment group and having a two-night minimum</p></li>
<li><p>Being in the treatment group and not having a two-night minimum nonetheless</p></li>
</ol>
<p>This categorization doesn’t yet answer our question but it’s giving us some important building blocks to distinguish between the effect of the treatment per se and the effect of unobserved factors conducive to setting up a two-night minimum. Let’s imagine for a second that we could observe these factors, and rank all the owners in decreasing order of these factors. Because of randomization, we can assume that the control and the treatment groups are reasonably identical in terms of the distribution of unobserved factors (<a data-type="xref" href="#distribution_of_unobserved_factors_and">Figure 9-7</a>).</p>
<p>All owners in the control group whose value for unobserved factors is high enough will implement a two-night minimum (group B) and all other owners in the control group won’t (group A). For the treatment group, we can reasonably assume that the owners with a high factor value are still implementing a two-night minimum and that our encouragement intervention simply lowers the threshold, by getting some owners who wouldn’t otherwise to implement it (together they form the group C). Finally, owners who are too low still don’t implement it, despite our best efforts (group D).</p>
<figure><div id="distribution_of_unobserved_factors_and" class="figure">
<img src="Images/BEDA_0907.png" alt="Distribution of unobserved factors and observed behaviors in the two groups" width="1018" height="1020"/>
<h6><span class="label">Figure 9-7. </span>Distribution of unobserved factors and observed behaviors in the two groups</h6>
</div></figure>
<p>In econometrics lingo, subjects who would <a contenteditable="false" data-type="indexterm" data-primary="always-takers" id="idm45968147472568"/>always be treated regardless of their experimental assignment (group B in the control group and the corresponding part of group C in the treatment group) are called <em>always-takers</em>. <a contenteditable="false" data-type="indexterm" data-primary="never-takers" id="idm45968147470744"/>Subjects who would never be treated regardless of their experimental assignment (group D in the treatment group and the corresponding part of group A in the control group) are predictably called <em>never-takers</em>. Subjects who are treated if and only if they are in the treatment group (the overlap between group A and group C)” are called <em>compliers.</em></p>
<p>Theoretically, you could have a fourth category, namely <a contenteditable="false" data-type="indexterm" data-primary="reactance" id="idm45968147468008"/><a contenteditable="false" data-type="indexterm" data-primary="defiers" id="idm45968147466904"/>subjects who are treated if and only if they are in the control group. They are called <em>defiers</em> because they are always doing the exact opposite of what we want them to do. The technical term for this in psychology is <em>reactance</em>. While it can happen in real life (cough, teenagers, cough), it’s rarely a concern in business settings, unless you’re trying to force people to do things they don’t want to do and I won’t help you with that.</p>
<p>By definition, we can’t observe the unobserved factors in our experiment, which means that we can only identify with certainty two groups: the always-takers assigned to control (B) and the never-takers assigned to treatment (D). We can’t know if the owners in the treatment group implementing the two-night minimum (C) are always-takers or compliers, and we can’t know if the owners in the control group not implementing it (A) are compliers or never-takers. <a contenteditable="false" data-type="indexterm" data-primary="complier average causal effect (CACE) for mandatory intervention" data-secondary="formula" id="idm45968147463560"/>However, and this is where the trick is, we can net out the always-takers and never-takers across experimental groups to measure the effect of the treatment on the compliers, which is called the <em>c</em><em>omplier average causal effect</em> (CACE). The formula for the CACE is very simple:<a contenteditable="false" data-type="indexterm" data-primary="intention-to-treat (ITT) estimate" data-secondary="complier average causal effect" id="idm45968147461176"/><sup><a data-type="noteref" id="ch01fn21-marker" href="ch09.xhtml#ch01fn21">4</a></sup></p>
<div data-type="equation">
<p><math><mrow><mrow><mi>C</mi><mi>A</mi><mi>C</mi><mi>E</mi><mo>=</mo><mrow><mfrac><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>I</mi><mi>T</mi><mi>T</mi></mrow></mstyle><mstyle scriptlevel="0"><mrow><mi>P</mi><mrow><mo>(</mo><mi>t</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>d</mi><mrow><mo>|</mo><mi>T</mi><mi>G</mi></mrow><mo>)</mo><mo>−</mo><mi>P</mi><mrow><mo>(</mo><mi>t</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>d</mi><mrow><mo>|</mo><mi>C</mi><mi>G</mi></mrow><mo>)</mo></mrow></mrow></mrow></mstyle></mfrac></mrow></mrow></mrow></math></p>
</div>
<p>In other words, to determine the effect of the treatment on the compliers, we simply need to weight our previous ITT estimate by a measure of the noncompliance in our experiment: if we have full compliance in both groups, meaning that no one gets access to the treatment in the control group (P(treated|CG) = 0) and everyone is treated in the treatment group (P(treated|TG) = 1), this simplifies to the ITT estimate. Very often with encouragement designs, we can prevent people in the control group from accessing the treatment, but only a fraction of the people in the treatment group are actually treated. In that case, the CACE is a multiple of the ITT: if only 10% of the people in the treatment group are treated, then our effect is very diluted and our CACE is equal to 10 times the ITT.</p>
<p>The CACE is very useful in two regards: first, it gives us an estimate of the effect of implementing the treatment across the board, without the possibility of opting out. Second, looking at the relationship between the ITT and the CACE allows us to distinguish between two possible situations:</p>
<ul>
<li><p>The ITT is low, but <em>P</em>(<em>treated</em>|<em>TG</em>) - <em>P</em>(<em>treated</em>|<em>CG</em>) is high, meaning that the intervention has a low impact on compliers but a high level of <span class="keep-together">compliance.</span></p></li>
<li><p>Conversely, the ITT is high, but <em>P</em>(<em>treated</em>|<em>TG</em>) - <em>P</em>(<em>treated</em>|<em>CG</em>) is low, meaning that the intervention has a high impact on compliers but a low level of <span class="keep-together">compliance.</span></p></li>
</ul>
<p>In the first case, we would focus our effort on increasing the effectiveness of the intervention whereas in the second case we would focus on increasing the take-up rate, possibly by making the intervention mandatory. These insights can also help us explore alternative designs: maybe 8 hours is too short, but 12 hours would be acceptable? Maybe we don’t need to offer <em>free</em> cleaning, simply suggesting a reputable service provider to owners would be enough?</p>
<p>In our present experiment, the uptake rates are quite low in the treatment groups, at about 20% on average:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R (output not shown)</code>
<code class="o">&gt;</code> <code class="n">exp_data_reg</code> <code class="o">%&gt;%</code>
    <code class="nf">group_by</code><code class="p">(</code><code class="n">group</code><code class="p">)</code> <code class="o">%&gt;%</code>
    <code class="nf">summarise</code><code class="p">(</code><code class="n">compliance_rate</code> <code class="o">=</code> <code class="nf">mean</code><code class="p">(</code><code class="n">compliant</code><code class="p">))</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
<code class="n">exp_data_reg_df</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s1">'group'</code><code class="p">)</code><code class="o">.</code><code class="n">agg</code><code class="p">(</code><code class="n">compliance_rate</code> <code class="o">=</code> <code class="p">(</code><code class="s1">'compliant'</code><code class="p">,</code> <code class="s1">'mean'</code><code class="p">))</code>
<code class="n">Out</code><code class="p">[</code><code class="mi">15</code><code class="p">]:</code> 
        <code class="n">compliance_rate</code>
<code class="n">group</code>                  
<code class="n">ctrl</code>              <code class="mf">1.000</code>
<code class="n">treat1</code>            <code class="mf">0.238</code>
<code class="n">treat2</code>            <code class="mf">0.166</code></pre>
<p>This means that our CACE estimate for the effect of the minimum-duration treatment will be significantly higher than the ITT estimate:</p>
<div data-type="equation">
<p><em>CACE</em><sub>1</sub> = <em>ITT</em><sub>1</sub>/<em>ComplianceRate</em><sub>1</sub> = 0.97/0.24 ≈ 4.06</p>
</div>
<p>Now, that’s a much more interesting value. The low uptake rate and high CACE suggests that our intervention is fundamentally sound and does generate value when implemented. We can either try to increase the uptake rate by changing the design, or make the intervention mandatory.</p>
<p>The CACE has a very neat but narrow interpretation: because we’re (implicitly) comparing the same people, the compliers, across the control and the treatment group, our estimate of the effect of the treatment is unbiased. We’re not inadvertently capturing the influence of other factors. However, we’re measuring it only for that narrow slice of our population, so generalizability is not a given. Compliers might have characteristics that <em>interact</em> with our treatment. That is, they might have traits that influence not (or not only) whether they take up the treatment, but how much the treatment affects them. This is where we need to go from a causal to a behavioral lens: is our treatment a tide that lifts all boats, or do the people involved matter? For example, we’ll see in the next chapter the example of a talk path in call centers. In that case, complying doesn’t just mean applying the treatment, but exerting effort to do so convincingly and not just going through the motions.</p>
<p>Here our intervention is implemented through AirCnC’s website. A two-night minimum is a two-night minimum, whoever you’re renting from. This means we can be confident that our treatment would be implemented as planned if rolled out across the board, and we can give our business partners the green light to do so.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-anz" id="idm45968147341336"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-anz2" id="idm45968147339960"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-anz3" id="idm45968147338584"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-anz4" id="idm45968147337208"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-cace" id="idm45968147335832"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-cace2" id="idm45968147334456"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-cace3" id="idm45968147333080"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-cace4" id="idm45968147331704"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch09-cace5" id="idm45968147330328"/></p>
</div></section>
</div></section>
<section data-type="sect1" class="pagebreak-before" data-pdf-bookmark="Conclusion"><div class="sect1" id="conclusion-id00014">
<h1 class="less_space">Conclusion</h1>
<p>In the previous chapter, we had to randomize our experimental assignment “on the fly” as customers connected to the website. In this chapter, we were able to do the random assignment all at once, and therefore <em>stratify</em> (a.k.a. <em>block</em>) our sample by creating pairs of similar subjects, one of which is assigned to the control group and the other to the treatment group. While this added a layer of complexity, it also significantly increased the effectiveness (in statistical terms, the power) of our experiment. Once you get familiar with stratification, you’ll appreciate the ability to extract insights even from small samples.</p>
<p>We also introduced a second complication: our experimental intervention was an <em>encouragement</em> treatment. We offered possibilities to owners, but we couldn’t force them to take them up, and the uptake was not random. In situations like this, we can easily measure the effect of the encouragement intervention per se, but measuring the effect of accepting the offer (a.k.a. opting in to the treatment) is trickier. Fortunately, we have in the CACE an unbiased estimate of that effect for the compliers in our experimental population. When we can assume the absence of interaction between personal characteristics and the treatment, the CACE can be generalized to our entire experimental population. Even when we can’t generalize that far, it provides a less biased estimate than simply comparing the control and treatment group (i.e., the intention-to-treat estimate).</p>
<p>Finally, we had multiple treatments. This did not change anything fundamentally, but it also added some complexity. I would recommend starting your experimentation journey with only one treatment, but I believe in the longer run you’ll come to appreciate the organizational “fixed costs” of running an experiment: getting approval from all stakeholders (business partners, legal department, etc.) and getting the technology and data pipeline in place takes barely more time with two treatments than with one. Therefore, running experiments with multiple treatments at once is a key step in increasing the number of treatments tested in a year.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="ch01fn18"><sup><a href="ch09.xhtml#ch01fn18-marker">1</a></sup> Thanks to Andreas Kaltenbrunner for pointing out that this is a hypergeometric and not a binomial <span class="keep-together">distribution.</span></p><p data-type="footnote" id="ch01fn19"><sup><a href="ch09.xhtml#ch01fn19-marker">2</a></sup> This is the plural of the Latin word for layer, <em>stratum</em>, hence the word stratification.</p><p data-type="footnote" id="ch01fn20"><sup><a href="ch09.xhtml#ch01fn20-marker">3</a></sup> Technically, there are functions for stratified sampling, such as <code>sklearn.utils.resample()</code>, but these don’t allow distance-based matching like we’re doing here.</p><p data-type="footnote" id="ch01fn21"><sup><a href="ch09.xhtml#ch01fn21-marker">4</a></sup> If you’re curious where it comes from, the derivation is available in the <a href="https://github.com/FlorentBuissonOReilly/BehavioralDataAnalysis">book’s GitHub repo</a>.</p></div></div></section></div></body></html>