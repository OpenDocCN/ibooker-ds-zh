<html><head></head><body>
<div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 8. Estimating Financial Risk" data-type="chapter" epub:type="chapter"><div class="chapter" id="idm46507970945536">
<h1><span class="label">Chapter 8. </span>Estimating Financial Risk</h1>
<p>Is there a way to approximate how much<a data-primary="financial risk estimation" data-secondary="about" data-type="indexterm" id="idm46507967745520"/><a data-primary="value at risk (VaR)" data-secondary="about" data-type="indexterm" id="idm46507967744576"/><a data-primary="investment risk" data-secondary="about" data-type="indexterm" id="idm46507967743632"/><a data-primary="temporal data" data-secondary="value at risk" data-type="indexterm" id="idm46507967701904"/> you can expect to lose when investing in financial markets?  This is the quantity that the financial statistic <em>value at risk</em> (VaR) seeks to measure. VaR is a simple measure of investment risk that tries to provide a reasonable estimate of the maximum probable loss in value of an investment portfolio over a particular time period.  A VaR statistic depends on three parameters: a portfolio, a time period, and a probability. For example, a VaR value of $1 million with a 5% probability and two weeks indicates the belief that the portfolio stands only a 5% chance of losing more than $1 million over two weeks.</p>
<p>Since its development soon after the stock market crash of 1987, VaR has seen widespread use across financial services organizations. The statistic plays a vital role in the management of these institutions by helping to determine the risk characteristics of their strategies.</p>
<p>Many of the most sophisticated approaches to estimating this statistic rely on computationally intensive simulations of markets under random conditions. <a data-primary="Monte Carlo simulations" data-secondary="about" data-type="indexterm" id="idm46507967699264"/><a data-primary="financial risk estimation" data-secondary="Monte Carlo simulations" data-type="indexterm" id="idm46507967698288"/><a data-primary="investment risk" data-secondary="Monte Carlo simulations" data-type="indexterm" id="idm46507967697376"/>The technique behind these approaches, called the Monte Carlo simulation, involves posing thousands or millions of random market scenarios and observing how they tend to affect a portfolio. <a data-primary="Monte Carlo simulations" data-secondary="trials" data-type="indexterm" id="idm46507967696304"/><a data-primary="trials in Monte Carlo simulations" data-type="indexterm" id="idm46507967695360"/>These scenarios are referred to as <em>trials</em>. PySpark is an ideal tool for Monte Carlo simulations. PySpark can leverage thousands of cores to run random trials and aggregate their results. As a general-purpose data transformation engine, it is also adept at performing the pre- and postprocessing steps that surround the simulations. It can transform raw financial data into the model parameters needed to carry out the simulations, as well as support ad hoc analysis of the results.  <a data-primary="HPC (high-performance computing)" data-secondary="PySpark Monte Carlo simulations" data-type="indexterm" id="idm46507967694208"/>Its simple programming model can drastically reduce development time compared to more traditional approaches that use HPC environments.</p>
<p class="pagebreak-before">We’ll also discuss how to compute a related<a data-primary="conditional value at risk (CVaR)" data-type="indexterm" id="idm46507967692272"/><a data-primary="expected shortfall" data-type="indexterm" id="idm46507967691552"/><a data-primary="Basel Committee on Banking Supervision" data-type="indexterm" id="idm46507967690880"/><a data-primary="value at risk (VaR)" data-secondary="conditional value at risk better" data-type="indexterm" id="idm46507967690192"/> statistic called <em>conditional value at risk</em> (CVaR), sometimes known as <em>expected shortfall</em>, which the Basel Committee on Banking Supervision proposed as a better risk measure than VaR a few years back.  A CVaR statistic has the same three parameters as a VaR statistic but considers the expected average loss instead of providing a probable loss value.  A CVaR of $5 million with a 5% <em>q-value</em> and two weeks indicates the belief that the average loss in the worst 5% of outcomes is $5 million.</p>
<p>In the process of modeling VaR, we’ll introduce a few different concepts, approaches, and packages.  We’ll start by going over basic financial terminology that will be used throughout the chapter and then learn about the methods used to calculate VaR, including the Monte Carlo simulation technique. After that, we will download and prepare our dataset using PySpark and pandas. We’ll be using stock market data from late 2000s and early 2010s, including market indicators such as treasury bond prices along with stock values of various companies. Once done with preprocessing, we will create a linear regression model to calculate change in value for stocks over a time period. We’ll also come up with a way to generate sample market indicator values for use in trials when performing a Monte Carlo simulation. Finally, we’ll perform the simulation using PySpark and go over our results.</p>
<p>Let’s start by defining basic financial terms that we will use.</p>
<section data-pdf-bookmark="Terminology" data-type="sect1"><div class="sect1" id="idm46507967686896">
<h1>Terminology</h1>
<p>This chapter makes use of a set<a data-primary="financial risk estimation" data-secondary="terminology" data-type="indexterm" id="idm46507967685632"/><a data-primary="investment risk" data-secondary="terminology" data-type="indexterm" id="idm46507967684592"/> of terms specific to the finance domain:</p>
<dl>
<dt>Instrument</dt>
<dd>
<p>A tradable asset, <a data-primary="instruments (financial)" data-type="indexterm" id="idm46507967681664"/><a data-primary="value of financial instruments" data-type="indexterm" id="idm46507967680928"/>such as a bond, loan, option, or stock investment.  At any particular time, an instrument is considered to have a <em>value</em>, which is the price for which it could be sold.</p>
</dd>
<dt>Portfolio</dt>
<dd>
<p>A collection of instruments<a data-primary="portfolio of financial instruments" data-type="indexterm" id="idm46507967678336"/> owned by a financial institution.</p>
</dd>
<dt>Return</dt>
<dd>
<p>The change in an instrument<a data-primary="return (financial)" data-type="indexterm" id="idm46507967676112"/><a data-primary="value of financial instruments" data-secondary="return" data-type="indexterm" id="idm46507967675408"/> or portfolio’s value over a time period.</p>
</dd>
<dt>Loss</dt>
<dd>
<p>A negative return.<a data-primary="loss (financial)" data-type="indexterm" id="idm46507967672992"/><a data-primary="value of financial instruments" data-secondary="loss" data-type="indexterm" id="idm46507967672256"/><a data-primary="return (financial)" data-secondary="loss as negative return" data-type="indexterm" id="idm46507967671296"/></p>
</dd>
<dt>Index</dt>
<dd>
<p>An imaginary portfolio of instruments.<a data-primary="index (financial)" data-type="indexterm" id="idm46507967669072"/><a data-primary="portfolio of financial instruments" data-secondary="index" data-type="indexterm" id="idm46507967668368"/>  For example, the NASDAQ Composite Index includes about 3,000 stocks and similar instruments for major US and international companies.</p>
</dd>
<dt>Market factor</dt>
<dd>
<p>A value that can be used<a data-primary="market factors" data-type="indexterm" id="idm46507967665952"/><a data-primary="factors" data-type="indexterm" id="idm46507967665248"/> as an indicator of macro aspects of the financial climate at a particular time—for example, the value of an index, the gross domestic product of the United States, or the exchange rate between the dollar and the euro.  We will often refer to market factors as just <em>factors</em>.</p>
</dd>
</dl>
</div></section>
<section data-pdf-bookmark="Methods for Calculating VaR" data-type="sect1"><div class="sect1" id="idm46507967663808">
<h1>Methods for Calculating VaR</h1>
<p>So far, our definition of VaR has been<a data-primary="value at risk (VaR)" data-secondary="calculating" data-tertiary="about" data-type="indexterm" id="idm46507967662144"/><a data-primary="financial risk estimation" data-secondary="calculating VaR" data-type="indexterm" id="idm46507967660896"/><a data-primary="investment risk" data-secondary="calculating VaR" data-type="indexterm" id="idm46507967659888"/> fairly open ended.  Estimating this statistic requires proposing a model for how a portfolio functions and choosing the probability distribution its returns are likely to take.  Institutions employ a variety of approaches for calculating VaR, all of which tend to fall under a few general methods.</p>
<section data-pdf-bookmark="Variance-Covariance" data-type="sect2"><div class="sect2" id="idm46507967658688">
<h2>Variance-Covariance</h2>
<p><em>Variance-covariance</em> is by far the simplest and<a data-primary="value at risk (VaR)" data-secondary="calculating" data-tertiary="variance-covariance" data-type="indexterm" id="idm46507967657104"/><a data-primary="variance-covariance financial calculation" data-type="indexterm" id="idm46507967655856"/> least computationally intensive method. Its model assumes that the return of each instrument is normally distributed, which allows deriving an estimate analytically.</p>
</div></section>
<section data-pdf-bookmark="Historical Simulation" data-type="sect2"><div class="sect2" id="idm46507967654832">
<h2>Historical Simulation</h2>
<p><em>Historical simulation</em> extrapolates risk<a data-primary="historical financial data" data-secondary="VaR calculation" data-type="indexterm" id="idm46507967653248"/><a data-primary="value at risk (VaR)" data-secondary="calculating" data-tertiary="historical simulation" data-type="indexterm" id="idm46507967652176"/> from historical data by using its distribution directly instead of relying on summary statistics. For example, to determine a 95% VaR for a portfolio, we might look at that portfolio’s performance for the last 100 days and estimate the statistic as its value on the fifth-worst day.  A drawback of this method is that historical data can be limited and fails to include what-ifs. For example, what if the history we have for the instruments in our portfolio lacks market collapses, and we want to model what happens to our portfolio in these situations? Techniques exist for making historical simulation robust to these issues, such as introducing “shocks” into the data, but we won’t cover them here.</p>
</div></section>
<section data-pdf-bookmark="Monte Carlo Simulation" data-type="sect2"><div class="sect2" id="idm46507967650576">
<h2>Monte Carlo Simulation</h2>
<p><em>Monte Carlo simulation</em>, which the rest of this<a data-primary="value at risk (VaR)" data-secondary="calculating" data-tertiary="Monte Carlo simulation" data-type="indexterm" id="idm46507967648992"/><a data-primary="Monte Carlo simulations" data-secondary="about" data-type="indexterm" id="idm46507967647744"/><a data-primary="portfolio of financial instruments" data-secondary="Monte Carlo simulations" data-seealso="Monte Carlo simulations" data-type="indexterm" id="idm46507967646800"/><a data-primary="models" data-secondary="Monte Carlo simulations" data-seealso="Monte Carlo simulations" data-type="indexterm" id="idm46507967645520"/><a data-primary="financial risk estimation" data-secondary="Monte Carlo simulations" data-seealso="Monte Carlo simulations" data-type="indexterm" id="idm46507967644304"/><a data-primary="investment risk" data-secondary="Monte Carlo simulations" data-seealso="Monte Carlo simulations" data-type="indexterm" id="idm46507967643072"/> chapter will focus on, tries to weaken the assumptions in the previous methods by simulating the portfolio under random conditions.  When we can’t derive a closed form for a probability distribution analytically, we can often estimate its probability density function by repeatedly sampling simpler random variables that it depends on and seeing how it plays out in aggregate.  In its most general form, this method:</p>
<ul>
<li>
<p>Defines a relationship between market conditions and each instrument’s returns.<a data-primary="return (financial)" data-secondary="Monte Carlo simulations" data-seealso="Monte Carlo simulations" data-type="indexterm" id="idm46507967640704"/><a data-primary="historical financial data" data-secondary="Monte Carlo simulations" data-type="indexterm" id="idm46507967639456"/><a data-primary="temporal data" data-secondary="historical financial data" data-type="indexterm" id="idm46507967638496"/><a data-primary="Monte Carlo simulations" data-secondary="historical data" data-type="indexterm" id="idm46507967637536"/>  This relationship takes the form of a model fitted to historical data.</p>
</li>
<li>
<p>Defines distributions for the market conditions that are straightforward to sample from.  These distributions are fitted to historical data.</p>
</li>
<li>
<p>Poses trials consisting of random market conditions.<a data-primary="trials in Monte Carlo simulations" data-type="indexterm" id="idm46507967634768"/><a data-primary="Monte Carlo simulations" data-secondary="trials" data-type="indexterm" id="idm46507967634048"/></p>
</li>
<li>
<p>Calculates the total portfolio loss for each trial<a data-primary="loss (financial)" data-secondary="Monte Carlo simulations" data-seealso="Monte Carlo simulations" data-type="indexterm" id="idm46507967632208"/><a data-primary="conditional value at risk (CVaR)" data-secondary="Monte Carlo simulations" data-seealso="Monte Carlo simulations" data-type="indexterm" id="idm46507967630960"/> and uses these losses to define an empirical distribution over losses.  This means that if we run 100 trials and want to estimate the 5% VaR, we would choose it as the loss from the trial with the fifth-greatest loss.  To calculate the 5% CVaR, we would find the average loss over the five worst trials.</p>
</li>
</ul>
<p>Of course, the Monte Carlo method isn’t perfect either. It relies on models for generating trial conditions and for inferring instrument performance, and these models must make simplifying assumptions. If these assumptions don’t correspond to reality, then neither will the final probability distribution that comes out.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Our Model" data-type="sect1"><div class="sect1" id="idm46507967628576">
<h1>Our Model</h1>
<p>A Monte Carlo risk model typically phrases<a data-primary="Monte Carlo simulations" data-secondary="modeling" data-tertiary="about" data-type="indexterm" id="idm46507967626352"/> each instrument’s return in terms of a set of market factors.  Common market factors might be the value of indexes like the S&amp;P 500, the US GDP, or currency exchange rates.  We then need a model that predicts the return of each instrument based on these market conditions.  In our simulation, we’ll use a simple linear model. <a data-primary="return (financial)" data-secondary="factor return" data-type="indexterm" id="idm46507967624976"/><a data-primary="factor return" data-type="indexterm" id="idm46507967624032"/><a data-primary="value of financial instruments" data-secondary="return" data-tertiary="factor return" data-type="indexterm" id="idm46507967623360"/><a data-primary="market factors" data-secondary="factor return" data-type="indexterm" id="idm46507967622176"/>By our previous definition of return, a <em>factor return</em> is a change in the value of a market factor over a particular time. For example, if the value of the S&amp;P 500 moves from 2,000 to 2,100 over a time interval, its return would be 100.  <a data-primary="feature vectors" data-secondary="factor returns" data-type="indexterm" id="idm46507967620656"/>We’ll derive a set of features from simple transformations of the factor returns.  That is, the market factor vector <em>m<sub>t</sub></em> for a trial <em>t</em> is transformed by some function ϕ to produce a feature vector of possible different length <em>f<sub>t</sub></em>:</p>
<ul class="simplelist fifty-percent">
<li><em>f<sub>t</sub> = ϕ(m<sub>t</sub>)</em></li>
</ul>
<p>For each instrument, we’ll train a model that assigns a weight to each feature.  To calculate <em>r<sub>it</sub></em>, the return of instrument <em>i</em> in trial <em>t</em>, we use <em>c<sub>i</sub></em>, the intercept term for the instrument; <em>w<sub>ij</sub></em>, the regression weight for feature <em>j</em> on instrument <em>i</em>; and  <em>f<sub>tj</sub></em>, the randomly generated value of feature <em>j</em> in trial <em>t</em>:</p>
<div class="fifty-percent" data-type="equation">
<math alttext="r Subscript i t Baseline equals c Subscript i Baseline plus sigma-summation Underscript j equals 1 Overscript StartAbsoluteValue w Subscript i Baseline EndAbsoluteValue Endscripts w Subscript i j Baseline asterisk f Subscript t j" display="block">
<mrow>
<msub><mi>r</mi> <mrow><mi>i</mi><mi>t</mi></mrow> </msub>
<mo>=</mo>
<msub><mi>c</mi> <mi>i</mi> </msub>
<mo>+</mo>
<munderover><mo>∑</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow> <mrow><mrow><mo>|</mo></mrow><msub><mi>w</mi> <mi>i</mi> </msub><mrow><mo>|</mo></mrow></mrow> </munderover>
<msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow> </msub>
<mo>*</mo>
<msub><mi>f</mi> <mrow><mi>t</mi><mi>j</mi></mrow> </msub>
</mrow>
</math>
</div>
<p>This means that the return of each instrument is calculated as the sum of the returns of the market factor features multiplied by their weights for that instrument.  <a data-primary="linear regression" data-secondary="fitting financial linear models" data-type="indexterm" id="idm46507967594832"/><a data-primary="historical financial data" data-secondary="linear regression" data-type="indexterm" id="idm46507967593792"/>We can fit the linear model for each instrument using historical data (also known as doing linear regression).  If the horizon of the VaR calculation is two weeks, the regression treats every (overlapping) two-week interval in history as a labeled point.</p>
<p>It’s also worth mentioning that we could have chosen a more complicated model.  For example, the model need not be linear: it could be a regression tree or explicitly incorporate domain-specific knowledge.</p>
<p>Now that we have our model for calculating instrument losses from market factors, <a data-primary="market factors" data-secondary="Monte Carlo simulations" data-seealso="Monte Carlo simulations" data-type="indexterm" id="idm46507967591904"/>we need a process for simulating the behavior of market factors.  A simple assumption is that each market factor return follows a normal distribution.  <a data-primary="correlation between market factors" data-type="indexterm" id="idm46507967590528"/>To capture the fact that market factors are often correlated—when the NASDAQ is down, the Dow is likely to be suffering as well—we can use a multivariate normal distribution with a nondiagonal covariance matrix:</p>
<div class="fifty-percent" data-type="equation">
<math alttext="m Subscript t Baseline tilde script upper N left-parenthesis mu comma normal upper Sigma right-parenthesis" display="block">
<mrow>
<msub><mi>m</mi> <mi>t</mi> </msub>
<mo>∼</mo>
<mi>𝒩</mi>
<mrow>
<mo>(</mo>
<mi>μ</mi>
<mo>,</mo>
<mi>Σ</mi>
<mo>)</mo>
</mrow>
</mrow>
</math>
</div>
<p>where μ is a vector of the empirical means of the returns of the factors and Σ is the empirical covariance matrix of the returns of the factors.</p>
<p>As before, we could have chosen a more complicated method of simulating the market or assumed a different type of distribution for each market factor, perhaps using distributions with fatter tails.</p>
</div></section>
<section data-pdf-bookmark="Getting the Data" data-type="sect1"><div class="sect1" id="idm46507967627952">
<h1>Getting the Data</h1>
<p>Download the historical stock price dataset<a data-primary="Monte Carlo simulations" data-secondary="historical data" data-tertiary="getting the data" data-type="indexterm" id="idm46507967579344"/><a data-primary="historical financial data" data-secondary="Monte Carlo simulations" data-tertiary="getting the historical data" data-type="indexterm" id="idm46507967578096"/><a data-primary="datasets" data-secondary="financial historical data" data-type="indexterm" id="idm46507967576848"/><a data-primary="temporal data" data-secondary="historical financial data" data-tertiary="getting the historical data" data-type="indexterm" id="idm46507967575888"/> and place it in a <em>data/stocks/</em> directory:</p>
<pre data-code-language="shell" data-type="programlisting">$ mkdir stocks <code class="o">&amp;&amp;</code> <code class="nb">cd</code> stocks
$ <code class="nv">url</code><code class="o">=</code><code class="s2">"https://raw.githubusercontent.com/ \</code>
<code class="s2">        sryza/aas/master/ch09-risk/data/stocks.zip"</code>
$ wget <code class="nv">$url</code>
$ unzip stocks.zip</pre>
<p>It can be difficult to find large volumes of nicely formatted historical price data. The dataset used in this chapter was downloaded from Yahoo!</p>
<p>We also need historical data for risk factors.<a data-primary="risk factor data download" data-seealso="Monte Carlo simulations" data-type="indexterm" id="idm46507967566400"/> For our factors, we’ll use the values of:</p>
<ul>
<li>
<p>iShares 20 Plus Year Treasury Bond ETF (NASDAQ: TLT)</p>
</li>
<li>
<p>iShares US Credit Bond ETF (NYSEArca: CRED)</p>
</li>
<li>
<p>SPDR Gold Trust (NYSEArca: GLD)</p>
</li>
</ul>
<p>Download and place the factors data:</p>
<pre data-code-language="shell" data-type="programlisting">$ <code class="nb">cd</code> .. <code class="o">&amp;&amp;</code> mkdir factors <code class="o">&amp;&amp;</code> <code class="nb">cd</code> factors
$ <code class="nv">url2</code> <code class="o">=</code> <code class="s2">"https://raw.githubusercontent.com/ \</code>
<code class="s2">          sryza/aas/master/ch09-risk/data/factors.zip"</code>
$ wget <code class="nv">$url2</code>
$ unzip factors.zip
$ ls factors
...

NASDAQ%3ATLT.csv  NYSEARCA%3ACRED.csv  NYSEARCA%3AGLD.csv</pre>
<p>Let’s have a look at one of our factors:</p>
<pre data-code-language="shell" data-type="programlisting">$ !head -n <code class="m">5</code> data/factors/NASDAQ%3ATLT.csv
...

Date,Open,High,Low,Close,Volume
<code class="m">31</code>-Dec-13,102.29,102.55,101.17,101.86,7219195
<code class="m">30</code>-Dec-13,102.15,102.58,102.08,102.51,4491711
<code class="m">27</code>-Dec-13,102.07,102.31,101.69,101.81,4755262
<code class="m">26</code>-Dec-13,102.35,102.36,102.01,102.10,4645323
<code class="m">24</code>-Dec-13,103.23,103.35,102.80,102.83,4897009</pre>
<p>With our dataset downloaded, we will now prepare it.</p>
</div></section>
<section data-pdf-bookmark="Preparing the Data" data-type="sect1"><div class="sect1" id="idm46507967580448">
<h1>Preparing the Data</h1>
<p>The first few rows of the Yahoo!-formatted data for GOOGL look like this:<a data-primary="Monte Carlo simulations" data-secondary="historical data" data-tertiary="preparing the data" data-type="indexterm" id="ch08-prep"/><a data-primary="historical financial data" data-secondary="Monte Carlo simulations" data-tertiary="preparing the data" data-type="indexterm" id="ch08-prep2"/><a data-primary="temporal data" data-secondary="historical financial data" data-tertiary="preparing the data" data-type="indexterm" id="ch08-prep3"/></p>
<pre data-code-language="shell" data-type="programlisting">$ !head -n <code class="m">5</code> data/stocks/GOOGL.csv
...

Date,Open,High,Low,Close,Volume
<code class="m">31</code>-Dec-13,556.68,561.06,553.68,560.92,1358300
<code class="m">30</code>-Dec-13,560.73,560.81,555.06,555.28,1236709
<code class="m">27</code>-Dec-13,560.56,560.70,557.03,559.76,1570140
<code class="m">26</code>-Dec-13,557.56,560.06,554.90,559.29,1338507
<code class="m">24</code>-Dec-13,558.04,558.18,554.60,556.48,734170</pre>
<p>Let’s fire up the PySpark shell:</p>
<pre data-code-language="shell" data-type="programlisting">$ pyspark --driver-memory 4g</pre>
<p>Read in the instruments dataset as a DataFrame:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">stocks</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">read</code><code class="o">.</code><code class="n">csv</code><code class="p">(</code><code class="s2">"data/stocks/"</code><code class="p">,</code> <code class="n">header</code><code class="o">=</code><code class="s1">'true'</code><code class="p">,</code> <code class="n">inferSchema</code><code class="o">=</code><code class="s1">'true'</code><code class="p">)</code>

<code class="n">stocks</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>
<code class="o">...</code>

<code class="o">+----------+----+----+----+-----+------+</code>
<code class="o">|</code>      <code class="n">Date</code><code class="o">|</code><code class="n">Open</code><code class="o">|</code><code class="n">High</code><code class="o">|</code> <code class="n">Low</code><code class="o">|</code><code class="n">Close</code><code class="o">|</code><code class="n">Volume</code><code class="o">|</code>
<code class="o">+----------+----+----+----+-----+------+</code>
<code class="o">|</code><code class="mi">2013</code><code class="o">-</code><code class="mi">12</code><code class="o">-</code><code class="mi">31</code><code class="o">|</code><code class="mf">4.40</code><code class="o">|</code><code class="mf">4.48</code><code class="o">|</code><code class="mf">3.92</code><code class="o">|</code> <code class="mf">4.07</code><code class="o">|</code><code class="mi">561247</code><code class="o">|</code>
<code class="o">|</code><code class="mi">2013</code><code class="o">-</code><code class="mi">12</code><code class="o">-</code><code class="mi">30</code><code class="o">|</code><code class="mf">3.93</code><code class="o">|</code><code class="mf">4.42</code><code class="o">|</code><code class="mf">3.90</code><code class="o">|</code> <code class="mf">4.38</code><code class="o">|</code><code class="mi">550358</code><code class="o">|</code>
<code class="o">+----------+----+----+----+-----+------+</code></pre>
<p>The DataFrame is missing the instrument symbol. Let’s add that using the input filenames corresponding to each row:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.sql</code> <code class="kn">import</code> <code class="n">functions</code> <code class="k">as</code> <code class="n">fun</code>

<code class="n">stocks</code> <code class="o">=</code> <code class="n">stocks</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s2">"Symbol"</code><code class="p">,</code> <code class="n">fun</code><code class="o">.</code><code class="n">input_file_name</code><code class="p">())</code><code class="o">.</code>\
                <code class="n">withColumn</code><code class="p">(</code><code class="s2">"Symbol"</code><code class="p">,</code>
                  <code class="n">fun</code><code class="o">.</code><code class="n">element_at</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s2">"Symbol"</code><code class="p">,</code> <code class="s2">"/"</code><code class="p">),</code> <code class="o">-</code><code class="mi">1</code><code class="p">))</code><code class="o">.</code>\
                <code class="n">withColumn</code><code class="p">(</code><code class="s2">"Symbol"</code><code class="p">,</code>
                  <code class="n">fun</code><code class="o">.</code><code class="n">element_at</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s2">"Symbol"</code><code class="p">,</code> <code class="s2">"\."</code><code class="p">),</code> <code class="mi">1</code><code class="p">))</code>

<code class="n">stocks</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>
<code class="o">...</code>
<code class="o">+---------+-------+-------+-------+-------+------+------+</code>
<code class="o">|</code>     <code class="n">Date</code><code class="o">|</code>   <code class="n">Open</code><code class="o">|</code>   <code class="n">High</code><code class="o">|</code>    <code class="n">Low</code><code class="o">|</code>  <code class="n">Close</code><code class="o">|</code><code class="n">Volume</code><code class="o">|</code><code class="n">Symbol</code><code class="o">|</code>
<code class="o">+---------+-------+-------+-------+-------+------+------+</code>
<code class="o">|</code><code class="mi">31</code><code class="o">-</code><code class="n">Dec</code><code class="o">-</code><code class="mi">13</code><code class="o">|</code><code class="mf">1884.00</code><code class="o">|</code><code class="mf">1900.00</code><code class="o">|</code><code class="mf">1880.00</code><code class="o">|</code> <code class="mf">1900.0</code><code class="o">|</code>   <code class="mi">546</code><code class="o">|</code>  <code class="n">CLDN</code><code class="o">|</code>
<code class="o">|</code><code class="mi">30</code><code class="o">-</code><code class="n">Dec</code><code class="o">-</code><code class="mi">13</code><code class="o">|</code><code class="mf">1889.00</code><code class="o">|</code><code class="mf">1900.00</code><code class="o">|</code><code class="mf">1880.00</code><code class="o">|</code> <code class="mf">1900.0</code><code class="o">|</code>  <code class="mi">1656</code><code class="o">|</code>  <code class="n">CLDN</code><code class="o">|</code>
<code class="o">+---------+-------+-------+-------+-------+------+------+</code></pre>
<p>We will read in and process the factors dataset in a similar manner:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">factors</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">read</code><code class="o">.</code><code class="n">csv</code><code class="p">(</code><code class="s2">"data/factors"</code><code class="p">,</code> <code class="n">header</code><code class="o">=</code><code class="s1">'true'</code><code class="p">,</code> <code class="n">inferSchema</code><code class="o">=</code><code class="s1">'true'</code><code class="p">)</code>
<code class="n">factors</code> <code class="o">=</code> <code class="n">factors</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s2">"Symbol"</code><code class="p">,</code> <code class="n">fun</code><code class="o">.</code><code class="n">input_file_name</code><code class="p">())</code><code class="o">.</code>\
                  <code class="n">withColumn</code><code class="p">(</code><code class="s2">"Symbol"</code><code class="p">,</code>
                    <code class="n">fun</code><code class="o">.</code><code class="n">element_at</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s2">"Symbol"</code><code class="p">,</code> <code class="s2">"/"</code><code class="p">),</code> <code class="o">-</code><code class="mi">1</code><code class="p">))</code><code class="o">.</code>\
                  <code class="n">withColumn</code><code class="p">(</code><code class="s2">"Symbol"</code><code class="p">,</code>
                    <code class="n">fun</code><code class="o">.</code><code class="n">element_at</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s2">"Symbol"</code><code class="p">,</code> <code class="s2">"\."</code><code class="p">),</code> <code class="mi">1</code><code class="p">))</code></pre>
<p>We filter out instruments with less than five years of history:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.sql</code> <code class="kn">import</code> <code class="n">Window</code>

<code class="n">stocks</code> <code class="o">=</code> <code class="n">stocks</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s1">'count'</code><code class="p">,</code> <code class="n">fun</code><code class="o">.</code><code class="n">count</code><code class="p">(</code><code class="s1">'Symbol'</code><code class="p">)</code><code class="o">.</code>\
                <code class="n">over</code><code class="p">(</code><code class="n">Window</code><code class="o">.</code><code class="n">partitionBy</code><code class="p">(</code><code class="s1">'Symbol'</code><code class="p">)))</code><code class="o">.</code>\
                <code class="nb">filter</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'count'</code><code class="p">)</code> <code class="o">&gt;</code> <code class="mi">260</code><code class="o">*</code><code class="mi">5</code> <code class="o">+</code> <code class="mi">10</code><code class="p">)</code></pre>
<p>Different types of instruments may trade on different days,<a data-primary="missing data values" data-secondary="historical financial data" data-type="indexterm" id="idm46507965844976"/> or the data may have missing values for other reasons, so it is important to make sure that our different histories align. First, we need to trim all of our time series to the same period in time. To do that, we’ll first convert the <code>Date</code> column’s type from string to date:<a data-primary="schemas of dataframes" data-secondary="historical financial data" data-type="indexterm" id="idm46507965827136"/><a data-primary="dataframes" data-secondary="schemas" data-tertiary="historical financial data" data-type="indexterm" id="idm46507965826288"/></p>
<pre data-code-language="python" data-type="programlisting"><code class="n">stocks</code> <code class="o">=</code> <code class="n">stocks</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s1">'Date'</code><code class="p">,</code>
                  <code class="n">fun</code><code class="o">.</code><code class="n">to_date</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">to_timestamp</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'Date'</code><code class="p">),</code>
                                              <code class="s1">'dd-MM-yy'</code><code class="p">)))</code>
<code class="n">stocks</code><code class="o">.</code><code class="n">printSchema</code><code class="p">()</code>
<code class="o">...</code>
<code class="n">root</code>
 <code class="o">|--</code> <code class="n">Date</code><code class="p">:</code> <code class="n">date</code> <code class="p">(</code><code class="n">nullable</code> <code class="o">=</code> <code class="n">true</code><code class="p">)</code>
 <code class="o">|--</code> <code class="n">Open</code><code class="p">:</code> <code class="n">string</code> <code class="p">(</code><code class="n">nullable</code> <code class="o">=</code> <code class="n">true</code><code class="p">)</code>
 <code class="o">|--</code> <code class="n">High</code><code class="p">:</code> <code class="n">string</code> <code class="p">(</code><code class="n">nullable</code> <code class="o">=</code> <code class="n">true</code><code class="p">)</code>
 <code class="o">|--</code> <code class="n">Low</code><code class="p">:</code> <code class="n">string</code> <code class="p">(</code><code class="n">nullable</code> <code class="o">=</code> <code class="n">true</code><code class="p">)</code>
 <code class="o">|--</code> <code class="n">Close</code><code class="p">:</code> <code class="n">double</code> <code class="p">(</code><code class="n">nullable</code> <code class="o">=</code> <code class="n">true</code><code class="p">)</code>
 <code class="o">|--</code> <code class="n">Volume</code><code class="p">:</code> <code class="n">string</code> <code class="p">(</code><code class="n">nullable</code> <code class="o">=</code> <code class="n">true</code><code class="p">)</code>
 <code class="o">|--</code> <code class="n">Symbol</code><code class="p">:</code> <code class="n">string</code> <code class="p">(</code><code class="n">nullable</code> <code class="o">=</code> <code class="n">true</code><code class="p">)</code>
 <code class="o">|--</code> <code class="n">count</code><code class="p">:</code> <code class="n">long</code> <code class="p">(</code><code class="n">nullable</code> <code class="o">=</code> <code class="n">false</code><code class="p">)</code></pre>
<p>Let’s trim the time periods of instruments to align:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">datetime</code> <code class="kn">import</code> <code class="n">datetime</code>

<code class="n">stocks</code> <code class="o">=</code> <code class="n">stocks</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'Date'</code><code class="p">)</code> <code class="o">&gt;=</code> <code class="n">datetime</code><code class="p">(</code><code class="mi">2009</code><code class="p">,</code> <code class="mi">10</code><code class="p">,</code> <code class="mi">23</code><code class="p">))</code><code class="o">.</code>\
                <code class="nb">filter</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'Date'</code><code class="p">)</code> <code class="o">&lt;=</code> <code class="n">datetime</code><code class="p">(</code><code class="mi">2014</code><code class="p">,</code> <code class="mi">10</code><code class="p">,</code> <code class="mi">23</code><code class="p">))</code></pre>
<p>We will convert the <code>Date</code> column’s type and trim the time period in our factors DataFrame too:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">factors</code> <code class="o">=</code> <code class="n">factors</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s1">'Date'</code><code class="p">,</code>
                              <code class="n">fun</code><code class="o">.</code><code class="n">to_date</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">to_timestamp</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'Date'</code><code class="p">),</code>
                                                          <code class="s1">'dd-MMM-yy'</code><code class="p">)))</code>

<code class="n">factors</code> <code class="o">=</code> <code class="n">factors</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'Date'</code><code class="p">)</code> <code class="o">&gt;=</code> <code class="n">datetime</code><code class="p">(</code><code class="mi">2009</code><code class="p">,</code> <code class="mi">10</code><code class="p">,</code> <code class="mi">23</code><code class="p">))</code><code class="o">.</code>\
                  <code class="nb">filter</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">col</code><code class="p">(</code><code class="s1">'Date'</code><code class="p">)</code> <code class="o">&lt;=</code> <code class="n">datetime</code><code class="p">(</code><code class="mi">2014</code><code class="p">,</code> <code class="mi">10</code><code class="p">,</code> <code class="mi">23</code><code class="p">))</code></pre>
<p>The histories of a few thousand instruments and three factors are small enough to read and process locally. This remains the case even for larger simulations with hundreds of thousands of instruments and thousands of factors. Even though we have used PySpark for preprocessing our data so far, the need arises for a distributed system such as PySpark when we’re actually running the simulations, which can require massive amounts of computation on each instrument. We can convert our PySpark DataFrame into a pandas DataFrame and still continue working with it easily by performing in-memory operations.</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">stocks_pd_df</code> <code class="o">=</code> <code class="n">stocks</code><code class="o">.</code><code class="n">toPandas</code><code class="p">()</code>
<code class="n">factors_pd_df</code> <code class="o">=</code> <code class="n">factors</code><code class="o">.</code><code class="n">toPandas</code><code class="p">()</code>

<code class="n">factors_pd_df</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code>
<code class="o">...</code>
 	<code class="n">Date</code> 	<code class="n">Open</code> 	<code class="n">High</code> 	<code class="n">Low</code> 	<code class="n">Close</code> 	<code class="n">Volume</code> 	<code class="n">Symbol</code>
<code class="mi">0</code> 	<code class="mi">2013</code><code class="o">-</code><code class="mi">12</code><code class="o">-</code><code class="mi">31</code> 	<code class="mf">102.29</code> 	<code class="mf">102.55</code> 	<code class="mf">101.17</code> 	<code class="mf">101.86</code> 	<code class="mi">7219195</code>
    <code class="n">NASDAQ</code><code class="o">%</code><code class="mi">253</code><code class="n">ATLT</code>
<code class="mi">1</code> 	<code class="mi">2013</code><code class="o">-</code><code class="mi">12</code><code class="o">-</code><code class="mi">30</code> 	<code class="mf">102.15</code> 	<code class="mf">102.58</code> 	<code class="mf">102.08</code> 	<code class="mf">102.51</code> 	<code class="mi">4491711</code>
    <code class="n">NASDAQ</code><code class="o">%</code><code class="mi">253</code><code class="n">ATLT</code>
<code class="mi">2</code> 	<code class="mi">2013</code><code class="o">-</code><code class="mi">12</code><code class="o">-</code><code class="mi">27</code> 	<code class="mf">102.07</code> 	<code class="mf">102.31</code> 	<code class="mf">101.69</code> 	<code class="mf">101.81</code> 	<code class="mi">4755262</code>
    <code class="n">NASDAQ</code><code class="o">%</code><code class="mi">253</code><code class="n">ATLT</code>
<code class="mi">3</code> 	<code class="mi">2013</code><code class="o">-</code><code class="mi">12</code><code class="o">-</code><code class="mi">26</code> 	<code class="mf">102.35</code> 	<code class="mf">102.36</code> 	<code class="mf">102.01</code> 	<code class="mf">102.10</code> 	<code class="mi">4645323</code>
    <code class="n">NASDAQ</code><code class="o">%</code><code class="mi">253</code><code class="n">ATLT</code>
<code class="mi">4</code> 	<code class="mi">2013</code><code class="o">-</code><code class="mi">12</code><code class="o">-</code><code class="mi">24</code> 	<code class="mf">103.23</code> 	<code class="mf">103.35</code> 	<code class="mf">102.80</code> 	<code class="mf">102.83</code> 	<code class="mi">4897009</code>
    <code class="n">NASDAQ</code><code class="o">%</code><code class="mi">253</code><code class="n">ATLT</code></pre>
<p>We will use these pandas DataFrames in the next section as we try to fit a linear regression model to predict instrument returns based on factor returns.<a data-startref="ch08-prep" data-type="indexterm" id="idm46507970081712"/><a data-startref="ch08-prep2" data-type="indexterm" id="idm46507970081104"/><a data-startref="ch08-prep3" data-type="indexterm" id="idm46507969884416"/></p>
</div></section>
<section data-pdf-bookmark="Determining the Factor Weights" data-type="sect1"><div class="sect1" id="idm46507967525616">
<h1>Determining the Factor Weights</h1>
<p>Recall that VaR deals with<a data-primary="value at risk (VaR)" data-secondary="about" data-type="indexterm" id="idm46507969882416"/><a data-primary="temporal data" data-secondary="value at risk" data-seealso="Monte Carlo simulations; value at risk (VaR)" data-type="indexterm" id="idm46507969881440"/><a data-primary="Monte Carlo simulations" data-secondary="modeling" data-tertiary="determining factor weights" data-type="indexterm" id="ch08-fw"/> losses <em>over a particular time horizon</em>.  We are not concerned with the absolute prices of instruments, but with how those prices move over a given length of time.  In our calculation, we will set that length to two weeks. The following function makes use of the pandas <code>rolling</code> method to transform a time series of prices into an overlapping sequence of price movements over two-week intervals.  Note that we use 10 instead of 14 to define the window because financial data does not include weekends:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">n_steps</code> <code class="o">=</code> <code class="mi">10</code>
<code class="k">def</code> <code class="nf">my_fun</code><code class="p">(</code><code class="n">x</code><code class="p">):</code>
    <code class="k">return</code> <code class="p">((</code><code class="n">x</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code> <code class="o">-</code> <code class="n">x</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code> <code class="o">/</code> <code class="n">x</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>

<code class="n">stock_returns</code> <code class="o">=</code> <code class="n">stocks_pd_df</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s1">'Symbol'</code><code class="p">)</code><code class="o">.</code><code class="n">Close</code><code class="o">.</code>\
                            <code class="n">rolling</code><code class="p">(</code><code class="n">window</code><code class="o">=</code><code class="n">n_steps</code><code class="p">)</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">my_fun</code><code class="p">)</code>
<code class="n">factors_returns</code> <code class="o">=</code> <code class="n">factors_pd_df</code><code class="o">.</code><code class="n">groupby</code><code class="p">(</code><code class="s1">'Symbol'</code><code class="p">)</code><code class="o">.</code><code class="n">Close</code><code class="o">.</code>\\
                            <code class="n">rolling</code><code class="p">(</code><code class="n">window</code><code class="o">=</code><code class="n">n_steps</code><code class="p">)</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">my_fun</code><code class="p">)</code>

<code class="n">stock_returns</code> <code class="o">=</code> <code class="n">stock_returns</code><code class="o">.</code><code class="n">reset_index</code><code class="p">()</code><code class="o">.</code>\
                              <code class="n">sort_values</code><code class="p">(</code><code class="s1">'level_1'</code><code class="p">)</code><code class="o">.</code>\
                              <code class="n">reset_index</code><code class="p">()</code>
<code class="n">factors_returns</code> <code class="o">=</code> <code class="n">factors_returns</code><code class="o">.</code><code class="n">reset_index</code><code class="p">()</code><code class="o">.</code>\
                                  <code class="n">sort_values</code><code class="p">(</code><code class="s1">'level_1'</code><code class="p">)</code><code class="o">.</code>\
                                  <code class="n">reset_index</code><code class="p">()</code></pre>
<p>With these return histories in hand, we can turn to our goal of training predictive models for the instrument returns.<a data-primary="linear regression" data-secondary="fitting financial linear models" data-tertiary="Monte Carlo simulations" data-type="indexterm" id="idm46507969817744"/>  For each instrument, we want a model that predicts its two-week return based on the returns of the factors over the same time period.  For simplicity, we will use a linear regression model.</p>
<p>To model the fact that instrument returns may be nonlinear functions of the factor returns, we can include some additional features in our model that we derive from nonlinear transformations of the factor returns. As an example, we will add one additional feature for each factor return: square.  Our model is still a linear model in the sense that the response variable is a linear function of the features.  Some of the features just happen to be determined by nonlinear functions of the factor returns.  Keep in mind that this particular feature transformation is meant to demonstrate some of the options available—it shouldn’t be perceived as a state-of-the-art practice in predictive financial modeling.</p>
<pre data-code-language="python" data-type="programlisting"><code class="c1"># Create combined stocks DF</code><code>
</code><code class="n">stocks_pd_df_with_returns</code><code> </code><code class="o">=</code><code> </code><code class="n">stocks_pd_df</code><code class="o">.</code><code>\
</code><code>                              </code><code class="n">assign</code><code class="p">(</code><code class="n">stock_returns</code><code> </code><code class="o">=</code><code> </code><code>\
</code><code>                                    </code><code class="n">stock_returns</code><code class="p">[</code><code class="s1">'</code><code class="s1">Close</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>
</code><code class="c1"># Create combined factors DF</code><code>
</code><code class="n">factors_pd_df_with_returns</code><code> </code><code class="o">=</code><code> </code><code class="n">factors_pd_df</code><code class="o">.</code><code>\
</code><code>                              </code><code class="n">assign</code><code class="p">(</code><code class="n">factors_returns</code><code> </code><code class="o">=</code><code> </code><code>\
</code><code>                                    </code><code class="n">factors_returns</code><code class="p">[</code><code class="s1">'</code><code class="s1">Close</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                                    </code><code class="n">factors_returns_squared</code><code> </code><code class="o">=</code><code> </code><code>\
</code><code>                                    </code><code class="n">factors_returns</code><code class="p">[</code><code class="s1">'</code><code class="s1">Close</code><code class="s1">'</code><code class="p">]</code><code class="o">*</code><code class="o">*</code><code class="mi">2</code><code class="p">)</code><code>
</code><code>
</code><code class="n">factors_pd_df_with_returns</code><code> </code><code class="o">=</code><code> </code><code class="n">factors_pd_df_with_returns</code><code class="o">.</code><code>\
</code><code>                                </code><code class="n">pivot</code><code class="p">(</code><code class="n">index</code><code class="o">=</code><code class="s1">'</code><code class="s1">Date</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                                      </code><code class="n">columns</code><code class="o">=</code><code class="s1">'</code><code class="s1">Symbol</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                                      </code><code class="n">values</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">factors_returns</code><code class="s1">'</code><code class="p">,</code><code> </code><code>\
</code><code>                                              </code><code class="s1">'</code><code class="s1">factors_returns_squared</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code> </code><a class="co" href="#callout_estimating_financial_risk_CO1-1" id="co_estimating_financial_risk_CO1-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code>
</code><code class="n">factors_pd_df_with_returns</code><code class="o">.</code><code class="n">columns</code><code> </code><code class="o">=</code><code> </code><code class="n">factors_pd_df_with_returns</code><code class="o">.</code><code>\
</code><code>                                        </code><code class="n">columns</code><code class="o">.</code><code>\
</code><code>                                        </code><code class="n">to_series</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code>\
</code><code>                                        </code><code class="nb">str</code><code class="o">.</code><code>\
</code><code>                                        </code><code class="n">join</code><code class="p">(</code><code class="s1">'</code><code class="s1">_</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code>\
</code><code>                                        </code><code class="n">reset_index</code><code class="p">(</code><code class="p">)</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code>  </code><a class="co" href="#callout_estimating_financial_risk_CO1-2" id="co_estimating_financial_risk_CO1-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a><code>
</code><code>
</code><code class="n">factors_pd_df_with_returns</code><code> </code><code class="o">=</code><code> </code><code class="n">factors_pd_df_with_returns</code><code class="o">.</code><code>\
</code><code>                                </code><code class="n">reset_index</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="nb">print</code><code class="p">(</code><code class="n">factors_pd_df_with_returns</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code><code class="p">)</code><code>
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code>
</code><code class="mi">0</code><code>        </code><code class="n">Date</code><code>  </code><code class="n">factors_returns_NASDAQ</code><code class="o">%</code><code class="mi">253</code><code class="n">ATLT</code><code>  </code><code>\
</code><code class="mi">0</code><code>  </code><code class="mi">2009</code><code class="o">-</code><code class="mi">10</code><code class="o">-</code><code class="mi">23</code><code>                         </code><code class="mf">0.01834</code><code>
</code><code>
</code><code class="mi">0</code><code>  </code><code class="n">factors_returns_NYSEARCA</code><code class="o">%</code><code class="mi">253</code><code class="n">ACRED</code><code>
</code><code class="mi">0</code><code>                          </code><code class="o">-</code><code class="mf">0.006594</code><code>
</code><code>
</code><code class="mi">0</code><code> </code><code class="n">factors_returns_NYSEARCA</code><code class="o">%</code><code class="mi">253</code><code class="n">AGLD</code><code>  </code><code>\
</code><code class="mi">0</code><code>                       </code><code class="o">-</code><code> </code><code class="mf">0.032623</code><code>
</code><code>
</code><code class="mi">0</code><code>  </code><code class="n">factors_returns_squared_NASDAQ</code><code class="o">%</code><code class="mi">253</code><code class="n">ATLT</code><code>  </code><code>\
</code><code class="mi">0</code><code>                                </code><code class="mf">0.000336</code><code>
</code><code>
</code><code class="mi">0</code><code>  </code><code class="n">factors_returns_squared_NYSEARCA</code><code class="o">%</code><code class="mi">253</code><code class="n">ACRED</code><code>  </code><code>\
</code><code class="mi">0</code><code>                                   </code><code class="mf">0.000043</code><code>
</code><code>
</code><code class="mi">0</code><code>  </code><code class="n">factors_returns_squared_NYSEARCA</code><code class="o">%</code><code class="mi">253</code><code class="n">AGLD</code><code>
</code><code class="mi">0</code><code>                                  </code><code class="mf">0.001064</code><code>
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code>
</code><code>
</code><code class="nb">print</code><code class="p">(</code><code class="n">factors_pd_df_with_returns</code><code class="o">.</code><code class="n">columns</code><code class="p">)</code><code>
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code>
</code><code class="n">Index</code><code class="p">(</code><code class="p">[</code><code class="s1">'</code><code class="s1">Date</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">factors_returns_NASDAQ</code><code class="s1">%</code><code class="s1">253ATLT</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>       </code><code class="s1">'</code><code class="s1">factors_returns_NYSEARCA</code><code class="s1">%</code><code class="s1">253ACRED</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">factors_returns_NYSEARCA</code><code class="s1">%</code><code class="s1">253AGLD</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>       </code><code class="s1">'</code><code class="s1">factors_returns_squared_NASDAQ</code><code class="s1">%</code><code class="s1">253ATLT</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>       </code><code class="s1">'</code><code class="s1">factors_returns_squared_NYSEARCA</code><code class="s1">%</code><code class="s1">253ACRED</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>       </code><code class="s1">'</code><code class="s1">factors_returns_squared_NYSEARCA</code><code class="s1">%</code><code class="s1">253AGLD</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>
</code><code>      </code><code class="n">dtype</code><code class="o">=</code><code class="s1">'</code><code class="s1">object</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">name</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code>
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_estimating_financial_risk_CO1-1" id="callout_estimating_financial_risk_CO1-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>Convert factors dataframe from long to wide format so that all factors for a period are in one row</p></dd>
<dt><a class="co" href="#co_estimating_financial_risk_CO1-2" id="callout_estimating_financial_risk_CO1-2"><img alt="2" height="12" src="assets/2.png" width="12"/></a></dt>
<dd><p>Flatten multi-index dataframe and fix column names</p></dd>
</dl>
<p>Even though we will be carrying out many regressions—one for each instrument—the number of features and data points in each regression is small, meaning that we don’t need to make use of PySpark’s distributed linear modeling capabilities. <a data-primary="least squares regression for Monte Carlo simulations" data-type="indexterm" id="idm46507969414368"/><a data-primary="scikit-learn least squares regression" data-type="indexterm" id="idm46507969413696"/>Instead, we’ll use the ordinary least squares regression offered by the scikit-learn package:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">LinearRegression</code>

<code class="c1"># For each stock, create input DF for linear regression training</code>

<code class="n">stocks_factors_combined_df</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">merge</code><code class="p">(</code><code class="n">stocks_pd_df_with_returns</code><code class="p">,</code>
                                      <code class="n">factors_pd_df_with_returns</code><code class="p">,</code>
                                      <code class="n">how</code><code class="o">=</code><code class="s2">"left"</code><code class="p">,</code> <code class="n">on</code><code class="o">=</code><code class="s2">"Date"</code><code class="p">)</code>

<code class="n">feature_columns</code> <code class="o">=</code> <code class="nb">list</code><code class="p">(</code><code class="n">stocks_factors_combined_df</code><code class="o">.</code><code class="n">columns</code><code class="p">[</code><code class="o">-</code><code class="mi">6</code><code class="p">:])</code>

<code class="k">with</code> <code class="n">pd</code><code class="o">.</code><code class="n">option_context</code><code class="p">(</code><code class="s1">'mode.use_inf_as_na'</code><code class="p">,</code> <code class="kc">True</code><code class="p">):</code>
    <code class="n">stocks_factors_combined_df</code> <code class="o">=</code> <code class="n">stocks_factors_combined_df</code><code class="o">.</code>\
                                    <code class="n">dropna</code><code class="p">(</code><code class="n">subset</code><code class="o">=</code><code class="n">feature_columns</code> \
                                            <code class="o">+</code> <code class="p">[</code><code class="s1">'stock_returns'</code><code class="p">])</code>


<code class="k">def</code> <code class="nf">find_ols_coef</code><code class="p">(</code><code class="n">df</code><code class="p">):</code>
    <code class="n">y</code> <code class="o">=</code> <code class="n">df</code><code class="p">[[</code><code class="s1">'stock_returns'</code><code class="p">]]</code><code class="o">.</code><code class="n">values</code>
    <code class="n">X</code> <code class="o">=</code> <code class="n">df</code><code class="p">[</code><code class="n">feature_columns</code><code class="p">]</code>

    <code class="n">regr</code> <code class="o">=</code> <code class="n">LinearRegression</code><code class="p">()</code>
    <code class="n">regr_output</code> <code class="o">=</code> <code class="n">regr</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code>

    <code class="k">return</code> <code class="nb">list</code><code class="p">(</code><code class="n">df</code><code class="p">[[</code><code class="s1">'Symbol'</code><code class="p">]]</code><code class="o">.</code><code class="n">values</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code> <code class="o">+</code> \
                <code class="nb">list</code><code class="p">(</code><code class="n">regr_output</code><code class="o">.</code><code class="n">coef_</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>

<code class="n">coefs_per_stock</code> <code class="o">=</code> <code class="n">stocks_factors_combined_df</code><code class="o">.</code>\
                      <code class="n">groupby</code><code class="p">(</code><code class="s1">'Symbol'</code><code class="p">)</code><code class="o">.</code>\
                      <code class="n">apply</code><code class="p">(</code><code class="n">find_ols_coef</code><code class="p">)</code>


<code class="n">coefs_per_stock</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">coefs_per_stock</code><code class="p">)</code><code class="o">.</code><code class="n">reset_index</code><code class="p">()</code>
<code class="n">coefs_per_stock</code><code class="o">.</code><code class="n">columns</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'symbol'</code><code class="p">,</code> <code class="s1">'factor_coef_list'</code><code class="p">]</code>

<code class="n">coefs_per_stock</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">coefs_per_stock</code><code class="o">.</code>\
                                <code class="n">factor_coef_list</code><code class="o">.</code><code class="n">tolist</code><code class="p">(),</code>
                                <code class="n">index</code><code class="o">=</code><code class="n">coefs_per_stock</code><code class="o">.</code><code class="n">index</code><code class="p">,</code>
                                <code class="n">columns</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'Symbol'</code><code class="p">]</code> <code class="o">+</code> <code class="n">feature_columns</code><code class="p">)</code>

<code class="n">coefs_per_stock</code></pre>
<p>We now have a dataframe where each row is the set of model parameters (coefficients, weights, covariants, regressors, or whatever you wish to call them) for an instrument.</p>
<p>At this point in any real-world pipeline it would be useful to understand how well these models fit the data.  Because the data points are drawn from time series, and especially because the time intervals are overlapping, it is very likely that the samples are autocorrelated.  This means that common measures like <em>R</em><sup>2</sup> are likely to overestimate how well the models fit the data. <a data-primary="Breusch-Godfrey test" data-type="indexterm" id="idm46507972908592"/><a data-primary="online resources" data-secondary="Breusch-Godfrey test" data-type="indexterm" id="idm46507972907952"/>The <a href="https://oreil.ly/9cwg6">Breusch-Godfrey test</a> is a standard test for assessing these effects.  One quick way to evaluate a model is to separate a time series into two sets, leaving out enough data points in the middle so that the last points in the earlier set are not autocorrelated with the first points in the later set.  Then train the model on one set and look at its error on the other.</p>
<p>With our models that map factor returns to instrument returns in hand, we now need a procedure for simulating market conditions by generating random factor returns. That’s what we’ll do next.<a data-startref="ch08-fw" data-type="indexterm" id="idm46507972756864"/></p>
</div></section>
<section data-pdf-bookmark="Sampling" data-type="sect1"><div class="sect1" id="idm46507972755904">
<h1>Sampling</h1>
<p>To come up with a way for generating random factor<a data-primary="Monte Carlo simulations" data-secondary="modeling" data-tertiary="sampling" data-type="indexterm" id="ch08-samp"/> returns, we need to decide on a probability distribution over factor return vectors and sample from it. What distribution does the data actually take? It can often be useful to start answering this kind of question visually.</p>
<p>A nice way to visualize a probability distribution over continuous data is a density plot that plots the distribution’s domain versus its probability density function.  Because we don’t know the distribution that governs the data, we don’t have an equation that can give us its density at an arbitrary point, <a data-primary="Monte Carlo simulations" data-secondary="modeling" data-tertiary="kernel density estimation" data-type="indexterm" id="idm46507972751952"/><a data-primary="kernel density estimation (KDE)" data-type="indexterm" id="idm46507972750688"/><a data-primary="probability density via kernel density estimation" data-type="indexterm" id="idm46507972750000"/>but we can approximate it through a technique called <em>kernel density estimation</em> (KDE).  In a loose way, kernel density estimation is a way of smoothing out a histogram. It centers a probability distribution (usually a normal distribution) at each data point. So a set of two-week-return samples would result in multiple normal distributions, each with a different mean.  To estimate the probability density at a given point, it evaluates the PDFs of all the normal distributions at that point and takes their average.  <a data-primary="bandwidth of kernel density plot" data-type="indexterm" id="idm46507972748784"/>The smoothness of a kernel density plot depends on its <em>bandwidth</em>, the standard deviation of each of the normal distributions.</p>
<p>We’ll use one of pandas DataFrame’s built-in methods to calculate and draw a KDE plot. The following snippet creates a density plot for one of our factors:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">samples</code> <code class="o">=</code> <code class="n">factors_returns</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">factors_returns</code><code class="o">.</code><code class="n">Symbol</code> <code class="o">==</code> \
                              <code class="n">factors_returns</code><code class="o">.</code><code class="n">Symbol</code><code class="o">.</code><code class="n">unique</code><code class="p">()[</code><code class="mi">0</code><code class="p">]][</code><code class="s1">'Close'</code><code class="p">]</code>
<code class="n">samples</code><code class="o">.</code><code class="n">plot</code><code class="o">.</code><code class="n">kde</code><code class="p">()</code></pre>
<p><a data-type="xref" href="#figure8-1">Figure 8-1</a> shows the distribution (probability density function) of two-week returns for the 20+ Year Treasury Bond ETF in our history.</p>
<figure><div class="figure" id="figure8-1">
<img alt="Two-week 20+ Year Treasury Bond ETF distribution" height="236" src="assets/aaps_0801.png" width="370"/>
<h6><span class="label">Figure 8-1. </span>Two-week 20+ Year Treasury Bond ETF distribution</h6>
</div></figure>
<p><a data-type="xref" href="#figure8-2">Figure 8-2</a> shows the same for two-week returns of US Credit Bonds.</p>
<figure><div class="figure" id="figure8-2">
<img alt="aaps 0802" height="235" src="assets/aaps_0802.png" width="373"/>
<h6><span class="label">Figure 8-2. </span>Two-week US Credit Bond ETF returns distribution</h6>
</div></figure>
<p>We will fit a normal distribution to the returns of each factor.  Looking for a more exotic distribution, perhaps with fatter tails, that more closely fits the data is often worthwhile.  However, for the sake of simplicity, we’ll avoid tuning our simulation in this way.</p>
<p>The simplest way to sample factors’ returns would be to fit a normal distribution to each of the factors and sample from these distributions independently.  However, this ignores the fact that market factors are often correlated. If the Treasury Bond ETF is down, the Credit Bond ETF is likely to be down as well. Failing to take these correlations into account can give us a much rosier picture of our risk profile than its reality.  Are the returns of our factors correlated? The Pearson’s correlation implementation in pandas can help us find out:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">f_1</code> <code class="o">=</code> <code class="n">factors_returns</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">factors_returns</code><code class="o">.</code><code class="n">Symbol</code> <code class="o">==</code> \
                          <code class="n">factors_returns</code><code class="o">.</code><code class="n">Symbol</code><code class="o">.</code><code class="n">unique</code><code class="p">()[</code><code class="mi">0</code><code class="p">]][</code><code class="s1">'Close'</code><code class="p">]</code>
<code class="n">f_2</code> <code class="o">=</code> <code class="n">factors_returns</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">factors_returns</code><code class="o">.</code><code class="n">Symbol</code> <code class="o">==</code> \
                          <code class="n">factors_returns</code><code class="o">.</code><code class="n">Symbol</code><code class="o">.</code><code class="n">unique</code><code class="p">()[</code><code class="mi">1</code><code class="p">]][</code><code class="s1">'Close'</code><code class="p">]</code>
<code class="n">f_3</code> <code class="o">=</code> <code class="n">factors_returns</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">factors_returns</code><code class="o">.</code><code class="n">Symbol</code> <code class="o">==</code> \
                          <code class="n">factors_returns</code><code class="o">.</code><code class="n">Symbol</code><code class="o">.</code><code class="n">unique</code><code class="p">()[</code><code class="mi">2</code><code class="p">]][</code><code class="s1">'Close'</code><code class="p">]</code>

<code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code><code class="s1">'f1'</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">f_1</code><code class="p">),</code> <code class="s1">'f2'</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">f_2</code><code class="p">),</code> <code class="s1">'f3'</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">f_3</code><code class="p">)})</code><code class="o">.</code><code class="n">corr</code><code class="p">()</code>
<code class="o">...</code>

         <code class="n">f1</code> 	   <code class="n">f2</code> 	    <code class="n">f3</code>
<code class="n">f1</code> 	<code class="mf">1.000000</code> 	<code class="mf">0.530550</code> 	<code class="mf">0.074578</code>
<code class="n">f2</code> 	<code class="mf">0.530550</code> 	<code class="mf">1.000000</code> 	<code class="mf">0.206538</code>
<code class="n">f3</code> 	<code class="mf">0.074578</code> 	<code class="mf">0.206538</code> 	<code class="mf">1.000000</code></pre>
<p>Because we have nonzero elements off the diagonals, it doesn’t look like it.<a data-startref="ch08-samp" data-type="indexterm" id="idm46507972642784"/></p>
<section data-pdf-bookmark="The Multivariate Normal Distribution" data-type="sect2"><div class="sect2" id="idm46507972642048">
<h2>The Multivariate Normal Distribution</h2>
<p>The multivariate normal distribution<a data-primary="Monte Carlo simulations" data-secondary="modeling" data-tertiary="multivariate normal distribution" data-type="indexterm" id="idm46507972597488"/><a data-primary="multivariate normal distribution" data-type="indexterm" id="idm46507972596176"/><a data-primary="correlation between market factors" data-secondary="multivariate normal distribution" data-type="indexterm" id="idm46507972595488"/><a data-primary="vectors" data-secondary="multivariate normal samples" data-type="indexterm" id="idm46507972594512"/> can help here by taking the correlation information between the factors into account.  Each sample from a multivariate normal is a vector.  Given values for all of the dimensions but one, the distribution of values along that dimension is normal.  But, in their joint distribution, the variables are not independent.</p>
<p>The multivariate normal is parameterized with a mean along each dimension and a matrix describing the covariances between each pair of dimensions.  With <em>N</em> dimensions, the covariance matrix is <em>N</em> by <em>N</em> because we want to capture the covariances between each pair of dimensions.  When the covariance matrix is diagonal, the multivariate normal reduces to sampling along each dimension independently, but placing nonzero values in the off-diagonals helps capture the relationships between variables.</p>
<p>The VaR literature often describes a step in which the factor weights are transformed (decorrelated) so that sampling can proceed. This is normally accomplished with a Cholesky decomposition or eigendecomposition. <a data-primary="NumPy package MultivariateNormalDistribution" data-type="indexterm" id="idm46507972591344"/>NumPy package’s <code>M⁠u⁠l⁠t⁠i⁠v⁠a⁠r⁠i⁠a⁠t⁠e​N⁠o⁠r⁠m⁠a⁠l⁠Distribution</code> takes care of this step for us under the covers using an 
<span class="keep-together">eigendecomposition</span>.</p>
<p>To fit a multivariate normal distribution to our data, first we need to find its sample means and covariances:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">factors_returns_cov</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code><code class="s1">'f1'</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">f_1</code><code class="p">),</code>
                                    <code class="s1">'f2'</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">f_2</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">]),</code>
                                    <code class="s1">'f3'</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">f_3</code><code class="p">[:</code><code class="o">-</code><code class="mi">2</code><code class="p">])})</code>\
                                    <code class="o">.</code><code class="n">cov</code><code class="p">()</code><code class="o">.</code><code class="n">to_numpy</code><code class="p">()</code>
<code class="n">factors_returns_mean</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code><code class="s1">'f1'</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">f_1</code><code class="p">),</code>
                                     <code class="s1">'f2'</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">f_2</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">]),</code>
                                     <code class="s1">'f3'</code><code class="p">:</code> <code class="nb">list</code><code class="p">(</code><code class="n">f_3</code><code class="p">[:</code><code class="o">-</code><code class="mi">2</code><code class="p">])})</code><code class="o">.</code>\
                                     <code class="n">mean</code><code class="p">()</code></pre>
<p>Then we can simply create a distribution parameterized with them and sample a set of market conditions from it:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">numpy.random</code> <code class="kn">import</code> <code class="n">multivariate_normal</code>

<code class="n">multivariate_normal</code><code class="p">(</code><code class="n">factors_returns_mean</code><code class="p">,</code> <code class="n">factors_returns_cov</code><code class="p">)</code>
<code class="o">...</code>
<code class="n">array</code><code class="p">([</code> <code class="mf">0.02234821</code><code class="p">,</code>  <code class="mf">0.01838763</code><code class="p">,</code> <code class="o">-</code><code class="mf">0.01107748</code><code class="p">])</code></pre>
<p>With the per-instrument models and a procedure for sampling factor returns, we now have the pieces we need to run the actual trials. Let’s start working on our simulation and run the trials.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Running the Trials" data-type="sect1"><div class="sect1" id="idm46507972755312">
<h1>Running the Trials</h1>
<p>Because running the trials is computationally intensive,<a data-primary="Monte Carlo simulations" data-secondary="modeling" data-tertiary="running the trials" data-type="indexterm" id="ch08-trial"/><a data-primary="trials in Monte Carlo simulations" data-secondary="running the trials" data-type="indexterm" id="ch08-trial2"/><a data-primary="parallelizing" data-secondary="Monte Carlo trials" data-type="indexterm" id="ch08-trial3"/> we’ll turn to PySpark to help us parallelize them.  In each trial, we want to sample a set of risk factors, use them to predict the return of each instrument, and sum all those returns to find the full trial loss.  To achieve a representative distribution, we want to run thousands or millions of these trials.</p>
<p>We have a few choices for how to parallelize the simulation.  We can parallelize along trials, instruments, or both.  To parallelize along both, we would create a dataset of instruments and a dataset of trial parameters and then use the <code>crossJoin</code> transformation to generate a dataset of all the pairs.  This is the most general approach, but it has a couple of disadvantages.  First, it requires explicitly creating a DataFrame of trial parameters, which we can avoid by using some tricks with random seeds. Second, it requires a shuffle operation.</p>
<p>Partitioning along instruments would look something like this:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">random_seed</code> <code class="o">=</code> <code class="mi">1496</code>
<code class="n">instruments_dF</code> <code class="o">=</code> <code class="o">...</code>
<code class="k">def</code> <code class="nf">trialLossesForInstrument</code><code class="p">(</code><code class="n">seed</code><code class="p">,</code> <code class="n">instrument</code><code class="p">):</code>
  <code class="o">...</code>

<code class="n">instruments_DF</code><code class="o">.</code><code class="n">rdd</code><code class="o">.</code>\
  <code class="n">flatMap</code><code class="p">(</code><code class="n">trialLossesForInstrument</code><code class="p">(</code><code class="n">random_seed</code><code class="p">,</code> <code class="n">_</code><code class="p">))</code><code class="o">.</code>\
  <code class="n">reduceByKey</code><code class="p">(</code><code class="n">_</code> <code class="o">+</code> <code class="n">_</code><code class="p">)</code></pre>
<p>With this approach, the data is partitioned across a DataFrame of instruments, and for each instrument a <code>flatMap</code> transformation computes and yields the loss against every trial.  Using the same random seed across all tasks means that we will generate the same sequence of trials.  <code>reduceByKey</code> sums together all the losses corresponding to the same trials.  A disadvantage of this approach is that it still requires shuffling <em>O</em>(|instruments| * |trials|) data.</p>
<p>Our model data for our few thousand instruments is small enough to fit in memory on every executor, and some back-of-the-envelope calculations reveal that this is probably still the case even with a million or so instruments and hundreds of factors.  A million instruments times 500 factors times the 8 bytes needed for the double that stores each factor weight equals roughly 4 GB, small enough to fit in each executor on most modern-day cluster machines.  This means that a good option is to distribute the instrument data in a broadcast variable. The advantage of each executor having a full copy of the instrument data is that total loss for each trial can be computed on a single machine. No aggregation is necessary. We also broadcast some other data required for trial return calculation.</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">b_coefs_per_stock</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">sparkContext</code><code class="o">.</code><code class="n">broadcast</code><code class="p">(</code><code class="n">coefs_per_stock</code><code class="p">)</code>
<code class="n">b_feature_columns</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">sparkContext</code><code class="o">.</code><code class="n">broadcast</code><code class="p">(</code><code class="n">feature_columns</code><code class="p">)</code>
<code class="n">b_factors_returns_mean</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">sparkContext</code><code class="o">.</code><code class="n">broadcast</code><code class="p">(</code><code class="n">factors_returns_mean</code><code class="p">)</code>
<code class="n">b_factors_returns_cov</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">sparkContext</code><code class="o">.</code><code class="n">broadcast</code><code class="p">(</code><code class="n">factors_returns_cov</code><code class="p">)</code></pre>
<p>With the partition-by-trials approach (which we will use), we start out with a DataFrame of seeds.  We want a different seed in each partition so that each partition generates different trials:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">pyspark.sql.types</code> <code class="kn">import</code> <code class="n">IntegerType</code>

<code class="n">parallelism</code> <code class="o">=</code> <code class="mi">1000</code>
<code class="n">num_trials</code> <code class="o">=</code> <code class="mi">1000000</code>
<code class="n">base_seed</code> <code class="o">=</code> <code class="mi">1496</code>

<code class="n">seeds</code> <code class="o">=</code> <code class="p">[</code><code class="n">b</code> <code class="k">for</code> <code class="n">b</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">base_seed</code><code class="p">,</code>
                          <code class="n">base_seed</code> <code class="o">+</code> <code class="n">parallelism</code><code class="p">)]</code>
<code class="n">seedsDF</code> <code class="o">=</code> <code class="n">spark</code><code class="o">.</code><code class="n">createDataFrame</code><code class="p">(</code><code class="n">seeds</code><code class="p">,</code> <code class="n">IntegerType</code><code class="p">())</code>

<code class="n">seedsDF</code> <code class="o">=</code> <code class="n">seedsDF</code><code class="o">.</code><code class="n">repartition</code><code class="p">(</code><code class="n">parallelism</code><code class="p">)</code></pre>
<p>Random number generation is a time-consuming<a data-primary="random number generation" data-type="indexterm" id="idm46507972186672"/><a data-primary="models" data-secondary="random number generation" data-type="indexterm" id="idm46507972163040"/><a data-primary="Monte Carlo simulations" data-secondary="modeling" data-tertiary="random number generation" data-type="indexterm" id="idm46507972162192"/> and CPU-intensive process.  While we don’t employ this trick here, it can often be useful to generate a set of random numbers in advance and use it across multiple jobs.  The same random numbers should <em>not</em> be used within a single job, because this would violate the Monte Carlo assumption that the random values are independently distributed.</p>
<p>For each seed, we want to generate a set of trial parameters and observe the effects of these parameters on all the instruments. We will write a function that calculates the full return of instruments for multiple trials. We start by simply applying the linear model that we trained earlier for each instrument. Then we average over the returns of all the instruments. This assumes that we’re holding an equal value of each instrument in the portfolio. A weighted average would be used if we held different amounts of each stock. Lastly, we need to generate a bunch of trials in each task.<a data-primary="random number generation" data-type="indexterm" id="idm46507972160144"/><a data-primary="math library random number generator" data-type="indexterm" id="idm46507972159472"/> Because choosing random numbers is a big part of the process, it is important to use a strong random number generator. Python’s in-built <code>random</code> library includes a Mersenne Twister implementation that is good for this.  We use it to sample from a multivariate normal distribution as described previously:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">random</code>

<code class="kn">from</code> <code class="nn">pyspark.sql.types</code> <code class="kn">import</code> <code class="n">LongType</code><code class="p">,</code> <code class="n">ArrayType</code>
<code class="kn">from</code> <code class="nn">pyspark.sql.functions</code> <code class="kn">import</code> <code class="n">udf</code>

<code class="k">def</code> <code class="nf">calculate_trial_return</code><code class="p">(</code><code class="n">x</code><code class="p">):</code>
<code class="c1">#     return x</code>
    <code class="n">trial_return_list</code> <code class="o">=</code> <code class="p">[]</code>

    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_trials</code><code class="o">/</code><code class="n">parallelism</code><code class="p">):</code>
        <code class="n">random_int</code> <code class="o">=</code> <code class="n">random</code><code class="o">.</code><code class="n">randint</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="n">num_trials</code><code class="o">*</code><code class="n">num_trials</code><code class="p">)</code>

        <code class="n">seed</code><code class="p">(</code><code class="n">x</code><code class="p">)</code>

        <code class="n">random_factors</code> <code class="o">=</code> <code class="n">multivariate_normal</code><code class="p">(</code><code class="n">b_factors_returns_mean</code><code class="o">.</code><code class="n">value</code><code class="p">,</code>
          <code class="n">b_factors_returns_cov</code><code class="o">.</code><code class="n">value</code><code class="p">)</code>

        <code class="n">coefs_per_stock_df</code> <code class="o">=</code> <code class="n">b_coefs_per_stock</code><code class="o">.</code><code class="n">value</code>
        <code class="n">returns_per_stock</code> <code class="o">=</code> <code class="n">coefs_per_stock_df</code><code class="p">[</code><code class="n">b_feature_columns</code><code class="o">.</code><code class="n">value</code><code class="p">]</code> <code class="o">*</code>
          <code class="p">(</code><code class="nb">list</code><code class="p">(</code><code class="n">random_factors</code><code class="p">)</code> <code class="o">+</code> <code class="nb">list</code><code class="p">(</code><code class="n">random_factors</code><code class="o">**</code><code class="mi">2</code><code class="p">))</code>

        <code class="n">trial_return_list</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="nb">float</code><code class="p">(</code><code class="n">returns_per_stock</code><code class="o">.</code><code class="n">sum</code><code class="p">(</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="o">.</code><code class="n">sum</code><code class="p">()</code><code class="o">/</code><code class="n">b_coefs_</code>
          <code class="n">per_stock</code><code class="o">.</code><code class="n">value</code><code class="o">.</code><code class="n">size</code><code class="p">))</code>

    <code class="k">return</code> <code class="n">trial_return_list</code>

<code class="n">udf_return</code> <code class="o">=</code> <code class="n">udf</code><code class="p">(</code><code class="n">calculate_trial_return</code><code class="p">,</code> <code class="n">ArrayType</code><code class="p">(</code><code class="n">DoubleType</code><code class="p">()))</code></pre>
<p>With our scaffolding complete, we can use it to compute a DataFrame where each element is the total return from a single trial:</p>
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code><code> </code><code class="nn">pyspark</code><code class="nn">.</code><code class="nn">sql</code><code class="nn">.</code><code class="nn">functions</code><code> </code><code class="kn">import</code><code> </code><code class="n">col</code><code class="p">,</code><code> </code><code class="n">explode</code><code>
</code><code>
</code><code class="n">trials</code><code> </code><code class="o">=</code><code> </code><code class="n">seedsDF</code><code class="o">.</code><code class="n">withColumn</code><code class="p">(</code><code class="s2">"</code><code class="s2">trial_return</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="n">udf_return</code><code class="p">(</code><code class="n">col</code><code class="p">(</code><code class="s2">"</code><code class="s2">value</code><code class="s2">"</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>
</code><code class="n">trials</code><code> </code><code class="o">=</code><code> </code><code class="n">trials</code><code class="o">.</code><code class="n">select</code><code class="p">(</code><code class="s1">'</code><code class="s1">value</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">explode</code><code class="p">(</code><code class="s1">'</code><code class="s1">trial_return</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_estimating_financial_risk_CO2-1" id="co_estimating_financial_risk_CO2-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a><code>
</code><code>
</code><code class="n">trials</code><code class="o">.</code><code class="n">cache</code><code class="p">(</code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_estimating_financial_risk_CO2-1" id="callout_estimating_financial_risk_CO2-1"><img alt="1" height="12" src="assets/1.png" width="12"/></a></dt>
<dd><p>Split array of trial returns into individual DataFrame rows</p></dd>
</dl>
<p>If you recall, the whole reason we’ve been messing<a data-primary="value at risk (VaR)" data-secondary="calculating" data-tertiary="Monte Carlo simulation" data-type="indexterm" id="idm46507967122800"/><a data-primary="Monte Carlo simulations" data-secondary="modeling" data-tertiary="VaR" data-type="indexterm" id="idm46507967121552"/> around with all these numbers is to calculate VaR.  <code>trials</code> now forms an empirical distribution over portfolio returns.  To calculate 5% VaR, we need to find a return that we expect to underperform 5% of the time, and a return that we expect to outperform 5% of the time.  With our empirical distribution, this is as simple as finding the value that 5% of trials are worse than and 95% of trials are better than. <a data-primary="takeOrdered action" data-type="indexterm" id="idm46507967119824"/>We can accomplish this by pulling the worst 5% of trials into the driver.  Our VaR is the return of the best trial in this subset:</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">trials</code><code class="o">.</code><code class="n">approxQuantile</code><code class="p">(</code><code class="s1">'trial_return'</code><code class="p">,</code> <code class="p">[</code><code class="mf">0.05</code><code class="p">],</code> <code class="mf">0.0</code><code class="p">)</code>
<code class="o">...</code>
<code class="o">-</code><code class="mf">0.010831826593164014</code></pre>
<p>We can find the CVaR with a nearly identical approach.  Instead of taking the best trial return from the worst 5% of trials, we take the average return from that set of trials:<a data-startref="ch08-trial" data-type="indexterm" id="idm46507967072816"/><a data-startref="ch08-trial2" data-type="indexterm" id="idm46507967072208"/><a data-startref="ch08-trial3" data-type="indexterm" id="idm46507967071600"/></p>
<pre data-code-language="python" data-type="programlisting"><code class="n">trials</code><code class="o">.</code><code class="n">orderBy</code><code class="p">(</code><code class="n">col</code><code class="p">(</code><code class="s1">'trial_return'</code><code class="p">)</code><code class="o">.</code><code class="n">asc</code><code class="p">())</code><code class="o">.</code>\
  <code class="n">limit</code><code class="p">(</code><code class="nb">int</code><code class="p">(</code><code class="n">trials</code><code class="o">.</code><code class="n">count</code><code class="p">()</code><code class="o">/</code><code class="mi">20</code><code class="p">))</code><code class="o">.</code>\
  <code class="n">agg</code><code class="p">(</code><code class="n">fun</code><code class="o">.</code><code class="n">avg</code><code class="p">(</code><code class="n">col</code><code class="p">(</code><code class="s2">"trial_return"</code><code class="p">)))</code><code class="o">.</code><code class="n">show</code><code class="p">()</code>
<code class="o">...</code>
<code class="o">+--------------------+</code>
<code class="o">|</code>   <code class="n">avg</code><code class="p">(</code><code class="n">trial_return</code><code class="p">)</code><code class="o">|</code>
<code class="o">+--------------------+</code>
<code class="o">|-</code><code class="mf">0.09002629251426077</code><code class="o">|</code>
<code class="o">+--------------------+</code></pre>
</div></section>
<section data-pdf-bookmark="Visualizing the Distribution of Returns" data-type="sect1"><div class="sect1" id="idm46507967039248">
<h1>Visualizing the Distribution of Returns</h1>
<p>In addition to calculating VaR at a <a data-primary="Monte Carlo simulations" data-secondary="modeling" data-tertiary="visualizing distribution of returns" data-type="indexterm" id="idm46507967005792"/><a data-primary="visualizing distribution of returns" data-type="indexterm" id="idm46507967004640"/>particular confidence level, it can be useful to look at a fuller picture of the distribution of returns.  Are they normally distributed?  Do they spike at the extremities?  As we did for the individual factors, we can plot an estimate of the probability density function for the joint probability distribution using kernel density estimation (see <a data-type="xref" href="#figure9-3">Figure 8-3</a>):</p>
<pre data-code-language="python" data-type="programlisting"><code class="n">trials</code><code class="o">.</code><code class="n">plot</code><code class="o">.</code><code class="n">kde</code><code class="p">()</code></pre>
<figure><div class="figure" id="figure9-3">
<img alt="aaps 0803" height="361" src="assets/aaps_0803.png" width="579"/>
<h6><span class="label">Figure 8-3. </span>Two-week returns distribution</h6>
</div></figure>
</div></section>
<section data-pdf-bookmark="Where to Go from Here" data-type="sect1"><div class="sect1" id="idm46507966998320">
<h1>Where to Go from Here</h1>
<p>The model laid out in this exercise is a very rough first cut of what would be used in an actual financial institution.  <a data-primary="Monte Carlo simulations" data-secondary="modeling" data-tertiary="what more is needed" data-type="indexterm" id="idm46507966996944"/>In building an accurate VaR model, we glossed over a few very important steps.  Curating the set of market factors can make or break a model, and it is not uncommon for financial institutions to incorporate hundreds of factors in their simulations.  Picking these factors requires both running numerous experiments on historical data and a heavy dose of creativity. Choosing the predictive model that maps market factors to instrument returns is also important. Although we used a simple linear model, many calculations use nonlinear functions or simulate the path over time with Brownian motion.</p>
<p>Lastly, it is worth putting care into the distribution used to simulate the factor returns.  Kolmogorov-Smirnov tests and chi-squared tests are useful for testing an empirical distribution’s normality.  Q-Q plots are useful for comparing distributions visually.  <a data-primary="fat-tailed distributions" data-type="indexterm" id="idm46507966950352"/><a data-primary="“Financial Economics, Fat-tailed Distributions” (Haas and Pigorsch)" data-primary-sortas="Financial Economics" data-type="indexterm" id="idm46507966949680"/><a data-primary="Haas, Markus" data-type="indexterm" id="idm46507966948768"/><a data-primary="Pigorsch, Christian" data-type="indexterm" id="idm46507966948096"/>Usually, financial risk is better mirrored by a distribution with fatter tails than the normal distribution that we used.  Mixtures of normal distributions are one good way to achieve these fatter tails.  <a href="https://oreil.ly/XSxhB">“Financial Economics, Fat-tailed Distributions”</a>, an article by Markus Haas and Christian Pigorsch, provides a nice reference on some of the other fat-tailed distributions out there.</p>
<p>Banks use PySpark and large-scale data processing<a data-primary="“Evaluation of Value-at-Risk Models Using Historical Data” (Hendricks)" data-primary-sortas="Evaluation of Value-at-Risk" data-type="indexterm" id="idm46507966946256"/><a data-primary="value at risk (VaR)" data-secondary="“Evaluation of Value-at-Risk Models Using Historical Data” (Hendricks)" data-secondary-sortas="Evaluation of Value-at-Risk" data-type="indexterm" id="idm46507966945344"/><a data-primary="Hendricks, Darryll" data-type="indexterm" id="idm46507966944192"/> frameworks for calculating VaR with historical methods as well. <a href="https://oreil.ly/0JoXu">“Evaluation of Value-at-Risk Models Using Historical Data”</a>, by Darryll Hendricks, provides a good overview and performance comparison of historical VaR methods.</p>
<p>Monte Carlo risk simulations can be used for more than calculating a single statistic.  The results can be used to proactively reduce the risk of a portfolio by shaping investment decisions.  For example, if in the trials with the poorest returns, a particular set of instruments tends to come up losing money repeatedly, we might consider dropping those instruments from the portfolio or adding instruments that tend to move in the opposite direction from them.</p>
</div></section>
</div></section></div></body></html>