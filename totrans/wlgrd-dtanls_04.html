<html><head></head><body>
<div id="sbo-rt-content"><div class="readable-text" id="p1">
<h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">5</span></span> <span class="chapter-title-text">Unusual data sources</span></h1>
</div>
<div class="introduction-summary">
<h3 class="introduction-header sigil_not_in_toc">This chapter covers</h3>
<ul>
<li class="readable-text" id="p2">Thinking of data beyond what is available in structured formats</li>
<li class="readable-text" id="p3">Using all the data sources available to you creatively, regardless of their format</li>
<li class="readable-text" id="p4">Navigating the tradeoff between time spent and value added when working with additional data sources</li>
</ul>
</div>
<div class="readable-text" id="p5">
<p>Most datasets you will encounter in your career are not as clean and structured as those provided in a learning environment. The reality is that it’s often the analyst who must search for the right data, which may be hidden in complicated spreadsheets or hidden even further in unstructured, nontraditional data sources. This chapter is about practicing the creativity of identifying and using novel and unstructured data sources to answer interesting analytical questions.</p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p6">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Structured vs. unstructured data</h5>
</div>
<div class="readable-text" id="p7">
<p>For the sake of clarity, when I use the words “structured” and “unstructured” to describe a dataset, I mean tabular, two-dimensional data versus everything else. Analysts typically work with structured data—something with rows and columns that can be opened in Excel or something that sits in a database and could conceivably be opened in Excel. Unstructured data is anything that isn’t in a rows and columns format, ranging from documents or raw audio to free text or a binary data format.</p>
</div>
<div class="readable-text" id="p8">
<p>In this project, you will be working with unstructured PDF files containing structured data tables. The semantics of whether we call this data unstructured, structured, semi-structured, or something else does not change the fact that working with PDFs is not the same as working with tabular data. That is the structured versus unstructured difference with which we are dealing in this chapter.</p>
</div>
</div>
<div class="readable-text" id="p9">
<h2 class="readable-text-h2" id="sigil_toc_id_57"><span class="num-string">5.1</span> Identifying novel data sources</h2>
</div>
<div class="readable-text" id="p10">
<p>I always advocate starting with a problem to solve. This is no different when thinking about additional data sources to use for your analysis. Once you have a clear problem statement, it is easier to understand what data sources you still need. This is why identifying and obtaining data are steps 3 and 4, and not steps 1 and 2, of the results-driven approach.</p>
</div>
<div class="readable-text intended-text" id="p11">
<p>What data is available to you will vary between workplaces, but generally, the kinds of data that may be helpful to consider are</p>
</div>
<ul>
<li class="readable-text" id="p12"> Data generated by typical business processes, such as emails. </li>
<li class="readable-text" id="p13"> Data in operational systems, if this is not already available. </li>
<li class="readable-text" id="p14"> Self-hosted data, meaning data people create for themselves, such as spreadsheets on people’s computer desktops. These are important only if people rely on them for decision making. Otherwise, they may just be less accurate versions of existing operational data. One example is salespeople tracking their own client pipeline outside of the company CRM. </li>
<li class="readable-text" id="p15"> Industry data, such as market statistics published by a central body. </li>
<li class="readable-text" id="p16"> Government statistics, published as open data. </li>
<li class="readable-text" id="p17"> White papers, public documents that summarize research on a given topic in an accessible way, created either internally or by a competitor. </li>
</ul>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p18">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Real business case: Extracting published industry data from PDFs</h5>
</div>
<div class="readable-text" id="p19">
<p>In many sectors, leading industry bodies publish market statistics, which are often the best indicators of the state of the market over time. Many of these statistics are published as tabular data, usually Excel files. However, in the past, I have had to resort to finding less structured forms of important statistics and writing my own PDF data extraction code. This is an experience every aspiring analyst should go through, hence the inclusion of this project.</p>
</div>
</div>
<div class="readable-text" id="p20">
<h3 class="readable-text-h3" id="sigil_toc_id_58"><span class="num-string">5.1.1</span> Considerations for using new datasets</h3>
</div>
<div class="readable-text" id="p21">
<p>There are some general considerations when deciding to use an additional data source to augment your analysis:</p>
</div>
<ul>
<li class="readable-text" id="p22"> Does this data source integrate with existing data? Can we join or merge this dataset with the one we are already using or is that not required? There will be instances where salespeople record their sales in their own spreadsheets, either outside the “official” CRM or alongside it. Would it be possible to join the data in their own custom spreadsheet to the data in the CRM system? Is there a common client identifier, like an ID, present in both datasets? If not, can we still link clients across those datasets somehow, such as by name? Refer to chapter 3 for a specific example of just such a problem. </li>
<li class="readable-text buletless-item" id="p23"> How much effort is it to extract structured data from this data source? This might involve manipulating an unstructured format and creating a tabular representation or taking a structured dataset that has a different format from our existing data and therefore requires work to change and rename columns to match the format we need. Either way, it is important to estimate the effort involved in this work before deciding to use a new data source: 
    <ul>
<li> A subset of this question is, do you currently have the expertise to manipulate this data? Not having worked with a particular data format is not a dealbreaker, but learning the necessary skills factors into estimating the effort involved. </li>
<li> A related consideration is, does your tool support this data format? If you are used to working solely in Excel, for example, it may be harder to manipulate unusual data formats, but a programming language such as Python or R may have a relevant library that is easy to install and use. </li>
</ul></li>
<li class="readable-text" id="p24"> What is the value of this additional data? What questions can you answer with it that you couldn’t answer before? Knowing this will help determine whether the effort will be worth it. </li>
<li class="readable-text" id="p25"> Does this data create additional dependencies? Will this additional data be used as a one-off, or is it something that will require engineering resources to continuously ingest and store? </li>
</ul>
<div class="readable-text" id="p26">
<h2 class="readable-text-h2" id="sigil_toc_id_59"><span class="num-string">5.2</span> Project 4: Analyzing film industry trends using PDF data</h2>
</div>
<div class="readable-text" id="p27">
<p>Let’s take a look at the project in which we will extract structured data from PDF files to understand the effects of the COVID-19 pandemic on the film industry. We will look at the problems our stakeholders want to solve and the data sources they have provided. Section 5.3 will dive into how to approach this problem using the results-driven approach as well as some technical considerations when handling PDF files. As with every project, there is a section dedicated to a step-by-step example solution, which can be found in section 5.4. As usual, our solutions will likely diverge, especially if you are not using Python, since I explore some Python-specific ways to read data tables from PDFs.</p>
</div>
<div class="readable-text intended-text" id="p28">
<p>The data is available at <a href="https://davidasboth.com/book-code">https://davidasboth.com/book-code</a>. You will find the files with which you can attempt the project, as well as the example solution in the form of a Jupyter notebook.</p>
</div>
<div class="readable-text" id="p29">
<h3 class="readable-text-h3" id="sigil_toc_id_60"><span class="num-string">5.2.1</span> Problem statement</h3>
</div>
<div class="readable-text" id="p30">
<p>In this scenario, you are working for EchoTale Analytics, a research firm in the entertainment industry. Their primary mission is to publish analytical pieces about the evolution of the entertainment industry, and you have been placed in charge of a project in their film division. Specifically, the firm wants to publish a white paper about how the COVID-19 pandemic has affected the film industry. They don’t currently have a more focused topic, so your task is to complete and present the preliminary research. Since the target is a white paper, the priority is to be able to tell a story that would be interesting to a film-loving audience.</p>
</div>
<div class="readable-text intended-text" id="p31">
<p>The firm works exclusively with external data sources, and for this project, they have given you PDF reports from the British Film Industry’s (BFI) Research and Statistics Unit (RSU), called Statistical Yearbooks. These Yearbooks contain annual summaries of statistics about the film industry, including embedded data tables. Most of the data relates to the film industry in the United Kingdom, but some global statistics are included as well. The data goes back almost 20 years, and naturally, the format of the PDF report is not consistent.</p>
</div>
<div class="readable-text print-book-callout" id="p32">
<p><span class="print-book-callout-head">NOTE</span>  Thanks to the BFI RSU and specifically John Sandow, senior research and data analyst, for permission to use the PDF reports.</p>
</div>
<div class="readable-text" id="p33">
<p>To complete this project, you will need to</p>
</div>
<ul>
<li class="readable-text" id="p34"> Identify the dimensions along which the film industry is analyzed in the Yearbooks </li>
<li class="readable-text" id="p35"> Decide how far back to extract data, as well as what constitutes pre-COVID and post-lockdown periods </li>
<li class="readable-text" id="p36"> Extract the necessary underlying data </li>
<li class="readable-text" id="p37"> Analyze the film statistics to arrive at a narrative that could be useful to your stakeholders in preparing their white paper </li>
</ul>
<div class="readable-text" id="p38">
<p>Your stakeholders’ priority is that the findings are interesting and unexpected. They already assume cinema admissions dropped during the pandemic period and went down to zero during lockdowns, and they do not want to publish a white paper with such obvious statistics. They would prefer you explore things such as</p>
</div>
<ul>
<li class="readable-text" id="p39"> Have admissions recovered post-lockdown differently in different countries? </li>
<li class="readable-text" id="p40"> What genres of films were popular before and after the pandemic period? Has this changed since lockdown restrictions were lifted? </li>
<li class="readable-text" id="p41"> Which distributors have experienced the biggest change post-pandemic? </li>
<li class="readable-text" id="p42"> Has there been a change in people’s attitudes toward independent films? </li>
</ul>
<div class="readable-text" id="p43">
<p>You will spend most of the time in the analysis portion of this project exploring trends pre- and post-lockdowns and comparing them to identify the most marked changes, which are the ones most likely to be interesting to your stakeholders.</p>
</div>
<div class="readable-text" id="p44">
<h3 class="readable-text-h3" id="sigil_toc_id_61"><span class="num-string">5.2.2</span> Data dictionary</h3>
</div>
<div class="readable-text" id="p45">
<p>This project does not have an explicit data dictionary, which is a common problem in the real world. Even if you do not create a data dictionary, you will need to note down the types of data present in each Yearbook before deciding on what data to focus on. Some aspects of the data may only be present in older or newer Yearbooks, but you will need your data to be consistently available in all the documents you end up using.</p>
</div>
<div class="readable-text intended-text" id="p46">
<p>One aspect of the documents that will make your work a bit easier is that the data is in tables that can be extracted with the right tools. An example of such a table is shown in figure 5.1.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p47">
<img alt="figure" height="831" src="../Images/5-1.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.1</span> An example data table from a Statistical Yearbook PDF file</h5>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p48">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Activity: Creating a data dictionary</h5>
</div>
<div class="readable-text" id="p49">
<p>Try writing a data dictionary for the data you end up using. Often, analysts write dictionaries for data they end up using because they’re the first to use it for analysis. It’s good practice to create this document for future users of the data, which includes a future version of you!</p>
</div>
</div>
<div class="readable-text" id="p50">
<h3 class="readable-text-h3" id="sigil_toc_id_62"><span class="num-string">5.2.3</span> Desired outcomes</h3>
</div>
<div class="readable-text" id="p51">
<p>The output of your analysis should be recommendations about potential topics for the white paper. The recommendations should be specific, so if you think there is a story about how people prefer different film genres since lockdown restrictions were lifted, your analysis should contain specific conclusions about which genres were popular before and after. Your recommendations should also be supported by visualizations, which may be included in the final white paper. As an additional consideration, you could also think about how your data extraction method, whether that is code or a specific tool, could be reused for future versions of this project.</p>
</div>
<div class="readable-text" id="p52">
<h3 class="readable-text-h3" id="sigil_toc_id_63"><span class="num-string">5.2.4</span> Required tools</h3>
</div>
<div class="readable-text" id="p53">
<p>For the example solution in this chapter, I used the Python libraries <code>pandas</code> and <code>matplotlib</code> to explore and visualize the data. To extract the data from the PDFs in the first place, I ended up using the Python library <code>pdfplumber</code>, but I will discuss other options. Your chosen tools may be different, and as with every project, the tool is less important than the process, but the tool you select must be able to</p>
</div>
<ul>
<li class="readable-text" id="p54"> Read a PDF file and extract tabular data from it into a more typical format, such as a CSV file </li>
<li class="readable-text" id="p55"> Load multiple datasets from CSV or Excel files </li>
<li class="readable-text" id="p56"> Combine two or more datasets </li>
<li class="readable-text" id="p57"> Perform basic data manipulation tasks, such as sorting, grouping, and reshaping data </li>
<li class="readable-text" id="p58"> Create data visualizations </li>
</ul>
<div class="readable-text" id="p59">
<p>I have opted to stay within my Python toolkit for this chapter as well, but I will discuss some other options at your disposal. You may choose to extract the data from the PDFs with a tool outside of your regular toolkit, in which case your usual tools only need to satisfy the latter bullet points and not necessarily the first one.</p>
</div>
<div class="readable-text" id="p60">
<h2 class="readable-text-h2" id="sigil_toc_id_64"><span class="num-string">5.3</span> Applying the results-driven method to extracting data from PDFs</h2>
</div>
<div class="readable-text" id="p61">
<p>There is a lot of uncertainty in this project, partly due to the unknown and inconsistent structure of the PDF files and partly due to the vagueness of our stakeholders’ requests. Using the results-driven approach, we can formulate an action plan.</p>
</div>
<div class="browsable-container figure-container" id="p62">
<img alt="figure" height="175" src="../Images/5-unnumb-1.png" width="529"/>
</div>
<div class="readable-text" id="p63">
<p><em><span class="aframe-location"/></em>Our stakeholders haven’t given us much direction, so our understanding of the problem is incomplete at this stage. Our first iteration needs to focus on identifying common data tables across multiple years of the Yearbooks and analyzing what we have at our disposal. Once we start looking at pre-COVID and post-lockdown trends, we will have more information about what the main topic of our analysis will be.</p>
</div>
<div class="browsable-container figure-container" id="p64">
<img alt="figure" height="175" src="../Images/5-unnumb-2.png" width="529"/>
</div>
<div class="readable-text" id="p65">
<p><em><span class="aframe-location"/></em>Even though we don’t know precisely what the white paper topic will be, we do know that we need to focus on comparing the same data in different time periods. Our minimum viable answer will focus on this comparison. Even this information gives us an idea of the final output of our work, which we can work toward.</p>
</div>
<div class="browsable-container figure-container" id="p66">
<img alt="figure" height="175" src="../Images/5-unnumb-3.png" width="529"/>
</div>
<div class="readable-text" id="p67">
<p><em><span class="aframe-location"/></em>In this project, the identification stage will be crucial. This is where we explore the PDFs and note down common data themes we could explore. Once we have done that, we can move on to extracting only the specific data we need. This will save us time in the long run because extracting all the data tables and only then exploring them would take longer.</p>
</div>
<div class="browsable-container figure-container" id="p68">
<img alt="figure" height="175" src="../Images/5-unnumb-4.png" width="529"/>
</div>
<div class="readable-text" id="p69">
<p><em><span class="aframe-location"/></em>You could argue the data was obtained when our stakeholder provided the PDF files, but as we have seen, there is plenty of work to do before we have a structured dataset to explore. Not all projects following the results-driven approach will result in the same time spent on each section. In this project, I envisage this step taking up a large portion of our time. <em/></p>
</div>
<div class="browsable-container figure-container" id="p70">
<img alt="figure" height="104" src="../Images/5-unnumb-5.png" width="317"/>
</div>
<div class="readable-text" id="p71">
<p><em><span class="aframe-location"/></em>Let’s sketch out the steps we will take, building on the steps discussed in section 5.2.1:</p>
</div>
<ul>
<li class="readable-text" id="p72"> First, we will open the PDF Yearbooks in descending year order and note the data tables available to us. There is no substitute for actually looking at our data before opening our analysis tools to get a sense of what we’re working with. </li>
<li class="readable-text" id="p73"> Next, we will decide how far back we are aiming to go in time. We do not have a lot of data to establish post-lockdown trends, and we don’t want to spend too long looking at data that’s too far in the past. </li>
<li class="readable-text" id="p74"> We can then decide on which aspects of the data we will be able to extract for analysis. This will depend on what is available consistently over the period we’ve settled on. </li>
<li class="readable-text" id="p75"> The next step will be to find and extract the specific data tables we need and save them in a structured format, such as CSVs. </li>
</ul>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p76">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Activity: Reusable methods</h5>
</div>
<div class="readable-text" id="p77">
<p>When you get to this point, think about how reusable your chosen extraction method is. Whether you manually extract the data or write a script to do it, it is possible that you will need to do it again in a future iteration. Thinking about reusability up front is a good practice to save yourself time in the long run.</p>
</div>
</div>
<ul>
<li class="readable-text" id="p78"> At this point, we can analyze the data by examining pre- and post-lockdown trends along the dimensions we have identified, whether that is changes in genre, admissions for independent films, or something else. </li>
<li class="readable-text" id="p79"> Finally, we will settle on a story to present to our stakeholders for inclusion in the white paper.<em/> </li>
</ul>
<div class="browsable-container figure-container" id="p80">
<img alt="figure" height="175" src="../Images/5-unnumb-6.png" width="529"/>
</div>
<div class="readable-text" id="p81">
<p><em><span class="aframe-location"/></em>We cannot simulate the actual interaction you would have with a stakeholder upon presenting your findings. We can, however, practice preparing for such an interaction by considering the follow-up questions you might hear, given the work you present, and prepare your answers to them. Being ready with suggestions for future iterations leads to more productive stakeholder conversations.</p>
</div>
<div class="browsable-container figure-container" id="p82">
<img alt="figure" height="175" src="../Images/5-unnumb-7.png" width="529"/>
</div>
<div class="readable-text" id="p83">
<p><em><span class="aframe-location"/></em>In this instance, we would want to present to our stakeholders as soon as we have solid evidence for one or more of our findings. What constitutes “solid” is not necessarily a question of statistical significance but more an intuition about what kind of story our stakeholders would be interested in hearing and publishing. This analysis, like others, is not a one-off piece of work you deliver; it is a conversation. The idea behind what to present is part of an analyst skill set that can only be developed by immersing yourself in real-world scenarios.</p>
</div>
<div class="readable-text" id="p84">
<h2 class="readable-text-h2" id="sigil_toc_id_65"><span class="num-string">5.4</span> An example solution: Effects of the COVID-19 lockdown periods on the film industry</h2>
</div>
<div class="readable-text" id="p85">
<p>Let’s tackle an example solution for this problem. Reading my solution is more valuable once you have attempted the project yourself. Remember, our solutions may differ. You may end up doing things in a different order as well.</p>
</div>
<div class="readable-text intended-text" id="p86">
<p>We will begin by inspecting our PDFs to see what kind of data is consistently available across multiple years. Once we have made a decision on which datasets to <span class="aframe-location"/>focus on, we will find a PDF extraction method and make sure it can reliably extract tables of data from our PDFs. In the second part, we will analyze our newly created structured data to answer some of our stakeholders’ questions.</p>
</div>
<div class="readable-text" id="p87">
<h3 class="readable-text-h3" id="sigil_toc_id_66"><span class="num-string">5.4.1</span> Inspecting the available data</h3>
</div>
<div class="readable-text" id="p88">
<p>The very first step is to decide which years of data to look at. If we look at the available files, a snapshot of which is shown in figure 5.2, we notice that the Yearbook used to be a single file per year until 2018, after which the files are broken down by category. However, files from 2018 onward also seem to have a “master” document, for example, the one titled “2018—BFI Statistical Yearbook.”<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p89">
<img alt="figure" height="890" src="../Images/5-2.png" width="530"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.2</span> A snapshot of the available PDF files</h5>
</div>
<div class="readable-text" id="p90">
<p>We also appear to be missing the file for 2015 entirely, which would contain data for 2014. That’s a problem we need a solution for if we want to go back further in time.</p>
</div>
<div class="readable-text print-book-callout" id="p91">
<p><span class="print-book-callout-head">NOTE</span>  The years indicated in the files are actually for the previous year, meaning the file called “2018 Statistical Yearbook” contains data for 2017.</p>
</div>
<div class="readable-text" id="p92">
<p>We can choose to extend our time period later, but for now, we will aim for the minimum amount of data that will get us pre- and post-lockdown trends. The first COVID lockdowns were in early 2020, so we definitely want 2019 at a minimum. Since we’re interested in patterns, more data would be better, so we’ll include two years pre-COVID: 2018 and 2019. This also means we only include years where the format of the documents is consistent.</p>
</div>
<div class="readable-text intended-text" id="p93">
<p>A longer-term review would give us more information, but we want to balance time and complexity, so two years will suffice for our first iteration. If we were to go further back in time, which would be pre-2017, we would want to make sure that the categories in the single documents match those that are broken out into separate files from 2018 onward. That is, is there data for audiences, distribution, public investment, and so forth available?</p>
</div>
<div class="readable-text intended-text" id="p94">
<p>Most of the lockdown restrictions were eased in 2021, so everything beyond that will be the “post-lockdowns” period, and we will need to decide how to categorize data in 2021.</p>
</div>
<div class="readable-text intended-text" id="p95">
<p>Since we want our data to start in 2018, we will start with the 2019 Yearbook. Let’s see what tables of data are available. Looking at the table of contents, partially shown in figure 5.3, we see that the subheadings match the individual files for 2019, which suggests all the necessary data might be contained in this single file.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p96">
<img alt="figure" height="833" src="../Images/5-3.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.3</span> A partial view of the table of contents from the 2019 Yearbook</h5>
</div>
<div class="readable-text intended-text" id="p97">
<p>The file contains a mixture of text, charts, infographics, and data tables.</p>
</div>
<div class="readable-text" id="p98">
<h4 class="readable-text-h4 sigil_not_in_toc">Identifying what data to extract</h4>
</div>
<div class="readable-text" id="p99">
<p>Looking at the data tables, just for admissions alone, we have statistics for the following:</p>
</div>
<ul>
<li class="readable-text" id="p100"> Total admissions by country </li>
<li class="readable-text" id="p101"> Monthly admissions in the United Kingdom </li>
<li class="readable-text" id="p102"> Admissions by UK region </li>
<li class="readable-text" id="p103"> Annual admission figures all the way back to 1935 </li>
</ul>
<div class="readable-text" id="p104">
<p>Beyond this, we also have data for broad categories such as</p>
</div>
<ul>
<li class="readable-text" id="p105"> Gross box office revenue </li>
<li class="readable-text" id="p106"> Top films of the year </li>
<li class="readable-text" id="p107"> Countries of origin </li>
<li class="readable-text" id="p108"> Genre </li>
<li class="readable-text" id="p109"> Directors </li>
<li class="readable-text" id="p110"> Independent films </li>
<li class="readable-text" id="p111"> Distributors </li>
</ul>
<div class="readable-text" id="p112">
<p>Even just looking at these data tables inspires many directions for our analysis. Since the data is for a white paper, we should choose categories that are likely to contain interesting stories. Of course, we don’t know up front, but intuition and domain expertise can help us choose a path that is more likely to yield results. Intuition like that is built only with lots of practice. We will focus on</p>
</div>
<ul>
<li class="readable-text" id="p113"> Admission patterns </li>
<li class="readable-text" id="p114"> Distribution of genres </li>
<li class="readable-text" id="p115"> Market share across distributors </li>
</ul>
<div class="readable-text" id="p116">
<p>Choosing these categories means we can ask whether seasonal patterns have changed over time, whether people now prefer different genres, and which if any, distributor has come out of the pandemic as the winner in terms of market share.</p>
</div>
<div class="readable-text intended-text" id="p117">
<p>Let’s summarize our work so far since we have just reached the first key decision point. Figure 5.4 shows the current step and the alternative options.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p118">
<img alt="figure" height="429" src="../Images/5-4.png" width="927"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.4</span> The first step and decision point in the analysis</h5>
</div>
<div class="readable-text" id="p119">
<p>Now, we can identify exactly which tables to look for in all our files to make sure we have the right data each year. For simplicity, let’s limit ourselves to one data table per category. Figures 5.5–5.7 show the data tables in the 2019 document that we will search for in post-2019 files.</p>
</div>
<div class="readable-text intended-text" id="p120">
<p>Based on our decision to focus on admissions, genres, and distributors, we can see the necessary data exists in just three tables. We can verify that these data tables exist for years beyond 2018 in their respective Yearbooks. If we had encountered a difference in structure, we would have had to investigate whether the same information was present in each table and ensure their structures matched so that we could combine them across multiple years into single files.<span class="aframe-location"/><span class="aframe-location"/><span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p121">
<img alt="figure" height="575" src="../Images/5-5.png" width="1067"/>
</div>
<div class="browsable-container figure-container" id="p122">
<img alt="figure" height="575" src="../Images/5-5.png" width="1067"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.5</span> Monthly UK admissions from the 2019 Yearbook</h5>
</div>
<div class="browsable-container figure-container" id="p123">
<img alt="figure" height="806" src="../Images/5-6.png" width="1066"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.6</span> Releases and revenue by genre from the 2019 Yearbook</h5>
</div>
<div class="browsable-container figure-container" id="p124">
<img alt="figure" height="668" src="../Images/5-7.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.7</span> Market share by distributor from the 2019 Yearbook</h5>
</div>
<div class="readable-text" id="p125">
<h3 class="readable-text-h3" id="sigil_toc_id_67"><span class="num-string">5.4.2</span> Extracting data from PDFs</h3>
</div>
<div class="readable-text" id="p126">
<p>Now that we know what data tables we need, we have multiple options to extract them. We could</p>
</div>
<ul>
<li class="readable-text" id="p127"> Manually copy a limited amount of our data from the PDFs </li>
<li class="readable-text" id="p128"> Use a dedicated PDF extraction tool </li>
<li class="readable-text" id="p129"> Find PDF extraction capabilities for our preferred tool (e.g., Python) </li>
</ul>
<div class="readable-text" id="p130">
<p>Table 5.1 shows the tradeoffs of these different approaches.</p>
</div>
<div class="browsable-container browsable-table-container framemaker-table-container" id="p131">
<h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 5.1</span> Comparing PDF extraction techniques</h5>
<table>
<thead>
<tr>
<th>
<div>
         Option 
       </div></th>
<th>
<div>
         Pros 
       </div></th>
<th>
<div>
         Cons 
       </div></th>
</tr>
</thead>
<tbody>
<tr>
<td>  Manually copying data from PDFs into Excel <br/></td>
<td>  • Quick for a small amount of data <br/></td>
<td>  • Cannot be automated <br/>  • Does not scale to more data <br/></td>
</tr>
<tr>
<td>  Dedicated PDF extraction tool, either web or desktop based <br/></td>
<td>  • Likely to be accurate <br/>  • Web-based tool requires no installation <br/></td>
<td>  • May not be free <br/>  • Privacy concerns if uploading files to the web <br/>  • Hard to automate <br/>  • May not scale to multiple files <br/></td>
</tr>
<tr>
<td>  Finding PDF capabilities in our current tool <br/></td>
<td>  • Allows automation and scales to many files <br/>  • No need to leave/change our preferred tools <br/></td>
<td>  • Current toolkit may not have such capabilities <br/>  • If there are few files and a one-off task, it might be quicker to extract data manually. <br/></td>
</tr>
</tbody>
</table>
</div>
<div class="readable-text" id="p132">
<p>Whatever option we settle on, we still need to go through the process of choosing a tool, implementing it/setting it up, and using it to extract the data from the PDFs. Let’s look at each step in detail, starting with choosing the right tool with the help of AI.</p>
</div>
<div class="readable-text" id="p133">
<h4 class="readable-text-h4 sigil_not_in_toc">Choosing a PDF extraction method</h4>
</div>
<div class="readable-text" id="p134">
<p>There is a lot of uncertainty in these options. Working with a specific task that we only have to perform rarely is a perfect use case for AI tools. Figure 5.8 shows the OpenAI GPT-3.5 model’s partial answer to the following prompt:</p>
</div>
<div class="readable-text" id="p135">
<blockquote>
<div>
<em>What are my options for easily extracting data tables from PDFs into a machine-readable format? The suggested options must be free, open source, and can include Python libraries.<span class="aframe-location"/></em>
</div>
</blockquote>
</div>
<div class="browsable-container figure-container" id="p136">
<img alt="figure" height="1278" src="../Images/5-8.png" width="1030"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.8</span> A list of options for PDF data extraction suggested by ChatGPT</h5>
</div>
<div class="readable-text" id="p137">
<p>First, it is important to remember that because these tools are evolving rapidly, the same prompt will give us different results depending on which AI tool we use and when we use it. We can see that ChatGPT recommends a mix of Python libraries and non-Python options as requested, which gives us plenty to explore. However, when investigating one of the non-Python options, it turns out the GitHub link for TabbyPDF is incorrect. In this case, we can find it ourselves, but it is a reminder that AI tools sometimes hallucinate in their suggestions, and they could even recommend tools that don’t exist.</p>
</div>
<div class="readable-text intended-text" id="p138">
<p>Let’s also use the AI tool to help us to start with one of the libraries. When asked, “Of the Python options, which one is the easiest to set up with the fewest dependencies?” its suggestion is to start with <code>tabula-py</code>, as it has the fewest dependencies. However, its dependency is to install a Java Runtime Environment, which is something we may prefer not to do. Its next suggestion, the <code>pdfplumber</code> library, has no such external dependencies, but its documentation suggests that table extraction features are a “plus.” Another suggestion, <code>camelot</code>, specializes in data table extraction, but according to ChatGPT, it is harder to set up due to its own external dependencies. So, we shouldn’t take the AI’s answer as perfect; it should be the start and not the end of the process.</p>
</div>
<div class="readable-text intended-text" id="p139">
<p>Weighing up our options, let’s settle on trying <code>pdfplumber</code> first because other Python libraries that are easier to install are its only dependencies. If its table-reading capabilities do not give us the results we require, we can always try another library, but we will favor simplicity in our first attempt.</p>
</div>
<div class="readable-text intended-text" id="p140">
<p>Installing <code>pdfplumber</code> can be done using any package manager you use, whether that is <code>pip</code>, <code>conda</code>, or <code>poetry</code>. As these tools install dependent libraries automatically, there is little for us to do in this step. However, if you choose to use a different tool for PDF extraction, this step may be more involved.</p>
</div>
<div class="readable-text" id="p141">
<p>Now that we’ve decided on a method, let’s summarize our process until this point before moving on to the actual extraction step. Figure 5.9 shows the process so far.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p142">
<img alt="figure" height="627" src="../Images/5-9.png" width="617"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.9</span> Steps up until settling on a PDF extraction method</h5>
</div>
<div class="readable-text" id="p143">
<p>Let’s now use our chosen tool to extract the structured data from our PDFs.</p>
</div>
<div class="readable-text" id="p144">
<h4 class="readable-text-h4 sigil_not_in_toc">Using our chosen tool to extract data from PDFs</h4>
</div>
<div class="readable-text" id="p145">
<p>After installing <code>pdfplumber</code>, let’s start by importing our libraries:</p>
</div>
<div class="browsable-container listing-container" id="p146">
<div class="code-area-container">
<pre class="code-area">import numpy as np
import pandas as pd

import pdfplumber

from IPython.display import display</pre>
</div>
</div>
<div class="readable-text" id="p147">
<p>This might be the first time we use the <code>pdfplumber</code> library, so to get started, we would read its documentation to understand how to open a PDF and extract tables from it. Because we will extract multiple tables from multiple pages across multiple documents, we should write a reusable function that performs the extraction of one or more tables from one or more pages of a single PDF. This function needs to open a PDF file, extract all the tables in the pages we specify, and return them as <code>pandas</code> DataFrames ready for analysis.</p>
</div>
<div class="readable-text intended-text" id="p148">
<p>Let’s start with the extraction code. Given a specified path and a page number, the following code will open the PDF, enumerate through the pages, and extract all the tables it identifies:</p>
</div>
<div class="browsable-container listing-container" id="p149">
<div class="code-area-container">
<pre class="code-area">pdf_path = "./files/2019 - BFI yearbook 2019 - 888.pdf"
page_num = 11

page_tables = []

with pdfplumber.open(pdf_path) as pdf:
    page = pdf.pages[page_num-1]
    page_tables = [t.extract() for t in page.find_tables()]<span class="aframe-location"/> #1

page_tables</pre>
<div class="code-annotations-overlay-container">
     #1 page_tables is a list of lists of lists(!) extracted from special Table objects.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p150">
<p>At this point, the <code>page_tables</code> variable is a list that contains lists of lists. The output is shown in figure 5.10.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p151">
<img alt="figure" height="389" src="../Images/5-10.png" width="800"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.10</span> A table extracted by <code>pdfplumber</code> from a single PDF page</h5>
</div>
<div class="readable-text" id="p152">
<p>Each row of the table is a list of strings, starting with the column headers. These rows are themselves in a list, representing a single table. Using the <code>page.find_tables()</code> function means we end up with a list of these tables. Hence, our data structure is a list of lists of lists. Luckily, <code>pandas</code> makes it easy for us to convert this to a list of DataFrames, as shown in the following code snippet:</p>
</div>
<div class="browsable-container listing-container" id="p153">
<div class="code-area-container">
<pre class="code-area">table = page_tables[0]
pd.DataFrame(table[1:-1], columns=table[0])</pre>
</div>
</div>
<div class="readable-text" id="p154">
<p>These code snippets can then be extended to work across multiple pages, and with a few additional print statements and logical checks, the entire function is shown in the following code snippet, a portion of the output of which is shown in figure 5.11:</p>
</div>
<div class="browsable-container listing-container" id="p155">
<div class="code-area-container code-area-with-html">
<pre class="code-area">def extract_tables(pdf_path, pages=None, print_tables=True):
  """
  Extract all tables found in a PDF.

  `pdf_path`: file path pointing to the PDF
  `pages`: the page number(s) to read
  `print_tables`: whether to also print out
  all the tables that are found (default: True)

  returns: a list of pandas DataFrames
  """

  if not pages:
      pages = []

  print(f"Reading {pdf_path}")

  tables = []

  with pdfplumber.open(pdf_path) as pdf:
      for page_num in pages:
          page = pdf.pages[page_num-1]

          page_tables = [t.extract() for t in page.find_tables()]

          df = [pd.DataFrame(table[1:-1], columns=table[0])<span class="aframe-location"/> #1
<span class="">↪</span> for table in page_tables]

          tables.extend(df)

  print(f"{len(tables)} tables found.")

  if len(tables) &gt; 0:
    if print_tables:
        for index, df in enumerate(tables):
          print(f"\n##########################\n\tTable
<span class="">↪</span> {index}\n##########################\n")
          display(df)

  return tables

tables = extract_tables("./files/2019 - BFI yearbook 2019 - 888.pdf",
<span class="">↪</span> pages=[11,34,70])<span class="aframe-location"/></pre>
<div class="code-annotations-overlay-container">
     #1 In each case, the variable table is now a list of lists and the first list contains the column headers.
     <br/>
</div>
</div>
</div>
<div class="browsable-container figure-container" id="p156">
<img alt="figure" height="443" src="../Images/5-11.png" width="591"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.11</span> A part of the output of our <code>extract_tables</code> function</h5>
</div>
<div class="readable-text" id="p157">
<p>The variable <code>tables</code> that stores the output of our function is now a list of DataFrames, each representing one table extracted from a PDF. It’s time to apply this function to our PDFs and extract the data we need. We will walk through this for 2018 data, but for completeness, all the data extraction code is included in the supplementary code listings.</p>
</div>
<div class="readable-text intended-text" id="p158">
<p>First, we identify the page numbers of interest and use our function to extract the admissions, genre, and distributor data:</p>
</div>
<div class="browsable-container listing-container" id="p159">
<div class="code-area-container code-area-with-html">
<pre class="code-area">tables_2018 = extract_tables("./files/2019 - BFI yearbook 2019 - 888.pdf",
<span class="">↪</span> pages=[11,34,70])</pre>
</div>
</div>
<div class="readable-text" id="p160">
<p>The full admissions data is shown in figure 5.12.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p161">
<img alt="figure" height="524" src="../Images/5-12.png" width="593"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.12</span> 2018 admissions data as extracted from our PDF</h5>
</div>
<div class="readable-text" id="p162">
<p>One important aspect of this data that we notice is that the columns themselves do not tell us the year this data belongs to. This will be important when we combine admissions data over multiple years, so we will add a Year column. We also do not need 2017 data or the percentage change, so we can drop those columns. A sample of the modified admissions data is shown in figure 5.13:</p>
</div>
<div class="browsable-container listing-container" id="p163">
<div class="code-area-container">
<pre class="code-area">admissions_2018 = (
    tables_2018[0]
    .iloc[:,[0, 2]]
)

admissions_2018.columns = ["Month", "Admissions (million)"]

admissions_2018.insert(0, "Year", 2018)

admissions_2018.head()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p164">
<img alt="figure" height="243" src="../Images/5-13.png" width="406"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.13</span> A snapshot of the modified admissions data</h5>
</div>
<div class="readable-text" id="p165">
<p>Moving onto genres, the second table in our extracted list of DataFrames contains the data we need, as shown in figure 5.14.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p166">
<img alt="figure" height="583" src="../Images/5-14.png" width="834"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.14</span> Genre breakdown for 2018 as extracted from the PDF</h5>
</div>
<div class="readable-text" id="p167">
<p>As opposed to the admissions data, this breakdown is by genre and relates to the entire year of 2018. We still need to add a Year column to differentiate genres across years, but we need to remember that this dataset has a different level of granularity. Again, we do not need all the columns, and we will need to clean up the column names to remove the <code>\n</code> newline characters. The following code snippet produces the modified genre data, a snapshot of which is shown in figure 5.15:</p>
</div>
<div class="browsable-container listing-container" id="p168">
<div class="code-area-container code-area-with-html">
<pre class="code-area">genres_2018 = (
    tables_2018[1]
    .drop(columns=[tables_2018[1].columns[2], tables_2018[1].columns[4]])
)

genres_2018.insert(0, "Year", 2018)

genres_2018.columns = ["Year", "Genre", "Number of releases",
<span class="">↪</span> "Gross box office (£ million)", "Top performing title"]

genres_2018.head()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p169">
<img alt="figure" height="257" src="../Images/5-15.png" width="1011"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.15</span> The modified genre data from 2018</h5>
</div>
<div class="readable-text" id="p170">
<p>Finally, moving on to distributors, the data directly extracted from the PDF is shown in figure 5.16.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p171">
<img alt="figure" height="577" src="../Images/5-16.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.16</span> The raw distributors data, as extracted from the PDF</h5>
</div>
<div class="readable-text intended-text" id="p172">
<p>In this case, all our columns will be useful, and we need to add the Year column again. We should also remove row 10, as it is a total of the rows above it, which would skew our calculations if we left it in. The following code modifies the data to suit our needs, and a snapshot of the modified data is shown in figure 5.17:</p>
</div>
<div class="browsable-container listing-container" id="p173">
<div class="code-area-container code-area-with-html">
<pre class="code-area">distributors_2018 = (
    tables_2018[2]
    .drop(index=[10])<span class="aframe-location"/> #1
)

distributors_2018.insert(0, "Year", 2018)

distributors_2018.columns = ["Year", "Distributor", "Market share",
<span class="">↪</span> "Films on release", "Box office gross (£ million)"]

distributors_2018.head()<span class="aframe-location"/></pre>
<div class="code-annotations-overlay-container">
     #1 Drops the “top 10 total” row
     <br/>
</div>
</div>
</div>
<div class="browsable-container figure-container" id="p174">
<img alt="figure" height="265" src="../Images/5-17.png" width="892"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.17</span> The modified distributor data for 2018</h5>
</div>
<div class="readable-text print-book-callout" id="p175">
<p><span class="print-book-callout-head">Note</span>  Repeating this process for subsequent years shows some differences. In 2019, there are two admissions tables on the same page, so we need to explicitly choose the right one. Also, in the 2022 Yearbooks, the tables are spread across multiple PDFs. Extracting these tables is the same process for all the years, but these minor differences are what make PDF data extraction complicated.</p>
</div>
<div class="readable-text" id="p176">
<p>Every dataset of the same type across the years is structured identically, so we do not need to do any additional cleaning before being able to combine them. The following code shows how we combine the annual admissions datasets into a single one:</p>
</div>
<div class="browsable-container listing-container" id="p177">
<div class="code-area-container">
<pre class="code-area">admissions = pd.concat([admissions_2018, admissions_2019,
  admissions_2020, admissions_2021],
  ignore_index=True,
  axis=0)</pre>
</div>
</div>
<div class="readable-text" id="p178">
<p>To ensure we have the right amount of data, we perform a quick sanity check to see how many rows of monthly data we have per year. We are expecting exactly 12 rows per year, which is verified in the output shown in figure 5.18:</p>
</div>
<div class="browsable-container listing-container" id="p179">
<div class="code-area-container">
<pre class="code-area">admissions["Year"].value_counts()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p180">
<img alt="figure" height="130" src="../Images/5-18.png" width="291"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.18</span> Verifying that we have 12 rows of admissions data for each year</h5>
</div>
<div class="readable-text" id="p181">
<p>Finally, we write the combined admissions data into its own file:</p>
</div>
<div class="browsable-container listing-container" id="p182">
<div class="code-area-container">
<pre class="code-area">admissions.to_csv("admissions.csv", index=False)</pre>
</div>
</div>
<div class="readable-text" id="p183">
<p>The process for combining and exporting genre and distributor data is identical, and we end up with three files that we are ready to analyze.</p>
</div>
<div class="readable-text" id="p184">
<h3 class="readable-text-h3" id="sigil_toc_id_68"><span class="num-string">5.4.3</span> Analyzing the data extracted from PDFs</h3>
</div>
<div class="readable-text" id="p185">
<p>Now that we have our data extracted from our PDFs and combined, we can start exploring it to find stories to use in our white paper. We will take each dataset at a time, starting with admissions. We could continue the code, meaning we would already have our admissions data as a variable, but I have chosen to explicitly separate the extraction and analysis processes. In the accompanying resources, you will find the process split into two Jupyter notebooks. For the analysis portion, we will start a new Jupyter notebook using the data created in the first one.</p>
</div>
<div class="readable-text intended-text" id="p186">
<p>There are multiple benefits to separating extraction from analysis:</p>
</div>
<ul>
<li class="readable-text" id="p187"> Extraction and analysis can be worked on separately as long as the extraction step produces the output the analysis step expects. </li>
<li class="readable-text" id="p188"> You save time by not having to rerun the extraction steps every time the analysis changes. </li>
<li class="readable-text" id="p189"> Steps can be more easily maintained because they are logically decoupled from each other. </li>
</ul>
<div class="readable-text" id="p190">
<p>In general, when you see an opportunity to create a cleaner solution by separating logical steps from each other, you should take it. Anyone looking at your work in the future, including yourself, will be grateful for the extra effort you put in early on.</p>
</div>
<div class="readable-text" id="p191">
<h4 class="readable-text-h4 sigil_not_in_toc">Enhancing extracted data with custom logic</h4>
</div>
<div class="readable-text" id="p192">
<p>We start by reading in the admissions data and taking a look at it. The following code produces the output in figure 5.19:</p>
</div>
<div class="browsable-container listing-container" id="p193">
<div class="code-area-container">
<pre class="code-area">import pandas as pd
import matplotlib.pyplot as plt
import datetime
admissions = pd.read_csv("admissions.csv")
print(admissions.shape)
admissions.head()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p194">
<img alt="figure" height="245" src="../Images/5-19.png" width="412"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.19</span> A snapshot of the admissions data</h5>
</div>
<div class="readable-text" id="p195">
<p>The dataset is small because it is a single monthly value across only a few years. However, it is sufficient to divide into three periods: pre-COVID lockdowns, during COVID lockdowns, and post-COVID lockdowns. We do this by creating a date column with the right data type. The output of the following code is shown in figure 5.20:</p>
</div>
<div class="browsable-container listing-container" id="p196">
<div class="code-area-container">
<pre class="code-area">COVID_START_DATE = datetime.datetime(2020, 3, 1)    <span class="aframe-location"/> #1
LOCKDOWN_END_DATE = datetime.datetime(2021, 7, 1)

admissions["date"] = (
    "1 " +     <span class="aframe-location"/> #2
    admissions["Month"] +
    " " +
    admissions["Year"].astype(str)
)

admissions["date"] = pd.to_datetime(admissions["date"], format="%d %B %Y")
admissions.head()<span class="aframe-location"/></pre>
<div class="code-annotations-overlay-container">
     #1 We define variables to mark cutoff points for COVID periods.
     <br/>#2 Our data has no days, so we arbitrarily set dates to the first of the month.
     <br/>
</div>
</div>
</div>
<div class="browsable-container figure-container" id="p197">
<img alt="figure" height="209" src="../Images/5-20.png" width="452"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.20</span> Verifying that our newly added Date column is as expected</h5>
</div>
<div class="readable-text" id="p198">
<p>Next, we define cutoff points for the three periods and apply them to the data. We also use the <code>Categorical</code> data type in <code>pandas</code> to ensure the correct order is observed when sorting; otherwise, these periods would be sorted alphabetically. Then, we verify that this new column is distributed as we’d expect and that we haven’t left any missing data. The output of the following code is shown in figure 5.21:</p>
</div>
<div class="browsable-container listing-container" id="p199">
<div class="code-area-container code-area-with-html">
<pre class="code-area">admissions.loc[admissions["date"] &lt; COVID_START_DATE, "covid_period"]
<span class="">↪</span> = "pre-COVID"
admissions.loc[admissions["date"].between(COVID_START_DATE,
<span class="">↪</span> LOCKDOWN_END_DATE, "left"), "covid_period"] = "during COVID"
admissions.loc[admissions["date"] &gt;= LOCKDOWN_END_DATE, "covid_period"]
<span class="">↪</span> = "post-lockdowns"

admissions["covid_period"] = (
    pd.Categorical(
        admissions["covid_period"],
        categories=["pre-COVID", "during COVID", "post-lockdowns"],
        ordered=True
    )
)

admissions["covid_period"].value_counts(dropna=False)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p200">
<img alt="figure" height="104" src="../Images/5-21.png" width="387"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.21</span> Number of rows per different COVID period</h5>
</div>
<div class="readable-text" id="p201">
<p>We can now plot monthly admissions and mark each COVID period with a different color and line style using the following code, which produces the plot in figure 5.22:</p>
</div>
<div class="browsable-container listing-container" id="p202">
<div class="code-area-container code-area-with-html">
<pre class="code-area">fig, axis = plt.subplots(figsize=(10, 6))

linestyles = ["solid", "dotted", "dashed"]

for idx, covid_period in 
<span class="">↪</span> enumerate(admissions["covid_period"].value_counts().index):
    (
        admissions
        .query(f"covid_period=='{covid_period}'")
        .set_index("date")
        ["Admissions (million)"]
        .plot(ax=axis, label=covid_period, linestyle=linestyles[idx])
    )

axis.set(
    title="Monthly cinema admissions over time",
    ylabel="Admissions (millions)"
)

axis.legend()

plt.show()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p203">
<img alt="figure" height="705" src="../Images/5-22.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.22</span> Admissions across multiple COVID periods</h5>
</div>
<div class="readable-text" id="p204">
<p>At first glance, there are missing months due to the lockdown periods, and after the last lockdown was lifted, it appears that admissions have started to return to pre-pandemic levels. If we had more post-lockdown data, we could also examine whether seasonal patterns are similar to what they were before the pandemic.</p>
</div>
<div class="readable-text" id="p205">
<p>If we were to look at the average monthly admissions in the three periods, we could examine this further. The following code does this and produces the output shown in figure 5.23:</p>
</div>
<div class="browsable-container listing-container" id="p206">
<div class="code-area-container">
<pre class="code-area">fig, axis = plt.subplots()

admissions_by_period = (
    admissions
    .groupby("covid_period")
    ["Admissions (million)"]
    .agg(["mean", "median"])
)

for i, metric in enumerate(admissions_by_period.columns):
    hatch = "/" if i == 0 else "\\\\"                           <span class="aframe-location"/> #1
    color = "C0" if i == 0 else "C1"    <span class="aframe-location"/> #2
    admissions_by_period[metric].plot(kind="bar", ax=axis, position=i,
                                      hatch=hatch, label=metric,
                                      width=0.2, color=color)

axis.set(
    title="Average monthly cinema admissions during COVID periods",
    ylabel="Admissions (millions)",
    xlabel="Period",
    xticklabels = admissions_by_period.index
)

axis.legend()

plt.show()<span class="aframe-location"/></pre>
<div class="code-annotations-overlay-container">
     #1 Different hatch patterns for different metrics
     <br/>#2 Different colors for different metrics
     <br/>
</div>
</div>
</div>
<div class="browsable-container figure-container" id="p207">
<img alt="figure" height="654" src="../Images/5-23.png" width="677"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.23</span> Average admissions by COVID period</h5>
</div>
<div class="readable-text" id="p208">
<p>The reason for looking at both the mean and the median is to investigate whether the data is skewed in either direction. That is, do pre-COVID or post-lockdown months tend to have outliers in either direction? Looking at histograms of monthly admissions by period investigates this further. The following code produces the histograms shown in figure 5.24:</p>
</div>
<div class="browsable-container listing-container" id="p209">
<div class="code-area-container code-area-with-html">
<pre class="code-area">fig, axes = plt.subplots(1, 2, figsize=(10, 6), sharey=True)

(
    admissions
    .loc[admissions["covid_period"] == "pre-COVID", "Admissions (million)"]
    .hist(bins=10, ax=axes[0])
)

axes[0].set(
    title="Distribution of monthly admissions pre-COVID",
    xlabel="Admissions (million)",
    ylabel="Frequency"
)

(
    admissions
    .loc[admissions["covid_period"] == "post-lockdowns",
<span class="">↪</span> "Admissions (million)"]
    .hist(ax=axes[1])
)

axes[1].set(
    title="Distribution of monthly admissions post-lockdowns",
    xlabel="Admissions (million)"
)

plt.show()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p210">
<img alt="figure" height="689" src="../Images/5-24.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.24</span> Histograms of admissions pre-COVID and post-lockdowns</h5>
</div>
<div class="readable-text" id="p211">
<p>There is not a lot of post-lockdown data, but we can observe that there are more months with fewer admissions, which is what we’d expect given the slow recovery. Pre-COVID, we expected approximately 15–17 million admissions per month, with a few outliers in both positive and negative directions. As it stands, there is not much of a story to tell about post-lockdown admissions habits, except for noting that admissions look to be trending toward pre-COVID levels again by the end of 2021.</p>
</div>
<div class="readable-text" id="p212">
<h4 class="readable-text-h4 sigil_not_in_toc">Investigating changes in trends over time using data from multiple sources</h4>
</div>
<div class="readable-text" id="p213">
<p>Now, let’s see what genres were popular on either side of the pandemic period. First, let’s read in and examine our data. Figure 5.25 shows a snapshot of rows produced by the following code:</p>
</div>
<div class="browsable-container listing-container" id="p214">
<div class="code-area-container">
<pre class="code-area">genres = pd.read_csv("genres.csv")
print(genres.shape)
genres.head()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p215">
<img alt="figure" height="235" src="../Images/5-25.png" width="933"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.25</span> A snapshot of rows from the genre dataset</h5>
</div>
<div class="readable-text" id="p216">
<p>There are two things to note. First, this dataset is small since it is a handful of genres recorded over just a few years. Second, this dataset is at an annual level, not a monthly one, which changes our definitions of COVID periods. Specifically, we must accept that the first couple of months of 2020 data will be allocated as “during COVID” even though they occurred before the first lockdown, and we need to decide what to do with 2021 data. 2021 still had lockdowns, but the second half of the year is useful data about post-lockdown trends, which we wouldn’t want to throw away. We will err on the side of keeping 2021 as “post-lockdowns” and categorizing 2020 as the only “during COVID” year. The following code does this and produces the output in figure 5.26:</p>
</div>
<div class="browsable-container listing-container" id="p217">
<div class="code-area-container">
<pre class="code-area">genres.loc[genres["Year"] &lt; 2020, "covid_period"] = "pre-COVID"
genres.loc[genres["Year"] == 2020, "covid_period"] = "during COVID"
genres.loc[genres["Year"] &gt; 2020, "covid_period"] = "post-lockdowns"

genres["covid_period"].value_counts(dropna=False)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p218">
<img alt="figure" height="135" src="../Images/5-26.png" width="309"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.26</span> Distribution of rows per COVID period in the genres dataset</h5>
</div>
<div class="readable-text" id="p219">
<p>Glancing at the data, we might notice that the gross box office column has non-numeric values, namely &lt;0.1, to indicate genres that totaled less than £100,000. To calculate revenue by genre, for example, we need this column to be numeric. We could convert that value to zero, but that would be misleading, and it is not the same value as 0.1, which is a value also present in our data. To indicate low revenue, we can add a placeholder value of, say, 0.05:</p>
</div>
<div class="browsable-container listing-container" id="p220">
<div class="code-area-container code-area-with-html">
<pre class="code-area">genres.loc[genres["Gross box office (£ million)"] == "&lt;0.1",
<span class="">↪</span> "Gross box office (£ million)"] = 0.05
genres["Gross box office (£ million)"] =
<span class="">↪</span> genres["Gross box office (£ million)"].astype(float)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p221">
<img alt="figure" height="772" src="../Images/5-27.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.27</span> Total revenue by genre</h5>
</div>
<div class="readable-text" id="p222">
<p>Now, we can look at total revenue by genre in our dataset. The output of the following code is shown in figure 5.27:</p>
</div>
<div class="browsable-container listing-container" id="p223">
<div class="code-area-container">
<pre class="code-area">fig, axis = plt.subplots()

(
    genres
    .groupby("Genre")
    ["Gross box office (£ million)"]
    .sum()
    .sort_values()
    .plot
    .barh(ax=axis)
)


axis.set(
    title="Total revenue (£ millions) by genre",
    xlabel="Gross revenue (£ million)"
)

plt.show()</pre>
</div>
</div>
<div class="readable-text" id="p224">
<p>It seems that people like action and animation films the most. What we really want to see is this same distribution by year. We could also look at it by COVID period, but let’s look at the more granular picture. The following code achieves this and produces the output in figure 5.28:</p>
</div>
<div class="browsable-container listing-container" id="p225">
<div class="code-area-container code-area-with-html">
<pre class="code-area">years = genres["Year"].unique()

fig, axes = plt.subplots(1, len(years),
<span class="">↪</span> figsize=(3*len(years),8), sharex=True)

for idx, year in enumerate(years):
    (
        genres[genres["Year"] == year]
        .groupby("Genre")
        ["Gross box office (£ million)"]
        .sum()
        .sort_values()
        .plot
        .barh(ax=axes[idx])
    )

    axes[idx].set(
        title=f"Revenue by genre ({year})"
    )

plt.tight_layout()
plt.show()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p226">
<img alt="figure" height="730" src="../Images/5-28.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.28</span> Breakdown of revenue by genre across multiple years</h5>
</div>
<div class="readable-text" id="p227">
<p>That gives quite a clear picture. Action films are the most popular, regardless of year. Comedy films historically haven’t done as well pre-COVID, but there has been a rise in their popularity in 2021. Here are some theories about this result:</p>
</div>
<ul>
<li class="readable-text" id="p228"> Animated films take years of effort, and if animators weren’t working at any point during COVID, that would have delayed the release of animated films in 2021. </li>
<li class="readable-text" id="p229"> Comparatively, comedies are probably cheaper to make, though that’s a question for the domain experts. </li>
<li class="readable-text" id="p230"> People possibly prefer light-hearted relief in post-lockdown times. </li>
</ul>
<div class="readable-text" id="p231">
<p>Let’s test that first assumption. If our theory holds, we should see fewer releases in the animation genre in 2021. Figure 5.29 shows the output of this investigation:</p>
</div>
<div class="browsable-container listing-container" id="p232">
<div class="code-area-container">
<pre class="code-area">(
    genres[genres["Genre"] == "Animation"]
    .groupby("Year")
    ["Number of releases"]
    .sum()
)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p233">
<img alt="figure" height="160" src="../Images/5-29.png" width="462"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.29</span> Number of animation releases over time</h5>
</div>
<div class="readable-text" id="p234">
<p>There were almost as many films released in the animation genre in 2021 as in 2019, so our theory doesn’t explain why the revenue of that genre dropped. Another interesting point from figure 5.28 is the popularity of war films in 2020:</p>
</div>
<div class="browsable-container listing-container" id="p235">
<div class="code-area-container">
<pre class="code-area">genres[(genres["Genre"] == "War") &amp; (genres["Year"] == 2020)]</pre>
</div>
</div>
<div class="readable-text" id="p236">
<p>Looking into it, we find that the top-performing title in this category was the film <em>1917</em>, which was released in January 2020. Although the revenue from this film accounts for its high place in the rankings in 2020, it was released before the first lockdowns, so it doesn’t tell us anything beyond that the filmmakers were lucky to bring in the revenue before the lockdown happened. It certainly isn’t evidence that people liked films about war during the pandemic.</p>
</div>
<div class="readable-text intended-text" id="p237">
<p>In summary, it appears that although action films are by far the most popular genre, comedies experienced a growth in revenue post-lockdowns. This is certainly a finding worth bringing to a domain expert to find out more.</p>
</div>
<div class="readable-text" id="p238">
<h4 class="readable-text-h4 sigil_not_in_toc">Resolving different entity names across data sources</h4>
</div>
<div class="readable-text" id="p239">
<p>Our final question relates to distributors. Which companies came out of the lockdown period grossing the most revenue for their films? Let’s look at our available data in figure 5.30:</p>
</div>
<div class="browsable-container listing-container" id="p240">
<div class="code-area-container">
<pre class="code-area">distributors = pd.read_csv("distributors.csv")
print(distributors.shape)
distributors.head()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p241">
<img alt="figure" height="247" src="../Images/5-30.png" width="847"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.30</span> A snapshot of the distributors dataset</h5>
</div>
<div class="readable-text" id="p242">
<p>For each distributor, we have their revenue market share, number of films released, and total gross box office revenue per year. Let’s assign our COVID periods again. Figure 5.31 shows the number of rows of data we have per COVID period:</p>
</div>
<div class="browsable-container listing-container" id="p243">
<div class="code-area-container code-area-with-html">
<pre class="code-area">distributors.loc[distributors["Year"] &lt; 2020, "covid_period"] = "pre-COVID"
distributors.loc[distributors["Year"] == 2020, "covid_period"]
<span class="">↪</span> = "during COVID"
distributors.loc[distributors["Year"] &gt; 2020, "covid_period"]
<span class="">↪</span> = "post-lockdowns"

distributors["covid_period"].value_counts(dropna=False)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p244">
<img alt="figure" height="134" src="../Images/5-31.png" width="312"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.31</span> Number of rows per COVID period in the distributors data</h5>
</div>
<div class="readable-text" id="p245">
<p>We should also verify that the market share column adds up to 100% each year. Figure 5.32 shows whether this is the case:</p>
</div>
<div class="browsable-container listing-container" id="p246">
<div class="code-area-container">
<pre class="code-area">distributors.groupby("Year")["Market share"].sum()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p247">
<img alt="figure" height="156" src="../Images/5-32.png" width="416"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.32</span> Total market share per year</h5>
</div>
<div class="readable-text" id="p248">
<p>The Statistical Yearbooks explicitly mention rounding errors, which are probably responsible for the numbers in figure 5.32. Let us now look at market share by distributor for each year of our data. The easiest way to do this with <code>pandas</code> is to create a pivot table where each column is a different distributor, and each row is a different year. This way, when we call the <code>plot</code> function, we see one line per distributor over time. Let’s see what this reshaping of our data does. The following code produces the pivot table shown in figure 5.33:</p>
</div>
<div class="browsable-container listing-container" id="p249">
<div class="code-area-container">
<pre class="code-area">(
    distributors
    .groupby(["Year", "Distributor"])
    ["Market share"]
    .sum()
    .unstack()
)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p250">
<img alt="figure" height="232" src="../Images/5-33.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.33</span> A snapshot of the pivot table aggregating across distributors and years</h5>
</div>
<div class="readable-text" id="p251">
<p>There are a number of data problems that become obvious. We need to merge the two separate values for 20th Century Fox, merge the “Other” categories into a single name so they get a single line over time, and investigate the various distributors with “Entertainment” in the name. Upon investigation, it appears Entertainment One and eOne Films, which both appear in our data, are the same entity (<a href="https://www.entertainmentone.com/about-eone/">https://www.entertainmentone.com/about-eone/</a>). Entertainment Film Distributors is a legitimately separate entity from Entertainment One, but we don’t have evidence of whether the distributor marked simply “Entertainment” should be merged into any other category. We will leave it on its own. After these corrections, we can look at how many years each distributor is represented in our data. The result of this is shown in figure 5.34:</p>
</div>
<div class="browsable-container listing-container" id="p252">
<div class="code-area-container code-area-with-html">
<pre class="code-area">distributors["Distributor"] = (
    distributors["Distributor"].replace({
        "20th Century Fox*": "20th Century Fox",
        "eOne Films": "Entertainment One"
    })
)

distributors.loc[distributors["Distributor"].str.startswith("Other"),
<span class="">↪</span> "Distributor"] = "Other"

distributors["Distributor"].value_counts()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p253">
<img alt="figure" height="413" src="../Images/5-34.png" width="426"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.34</span> Number of years each distributor is present in our data</h5>
</div>
<div class="readable-text" id="p254">
<p>We can also use this result to decide whether to plot all distributors. We are particularly interested in change over time, so we should keep only distributors that appear in all years of our data. This will potentially omit distributors who went out of business during or because of the pandemic. These could be analyzed further separately:</p>
</div>
<div class="browsable-container listing-container" id="p255">
<div class="code-area-container">
<pre class="code-area">distributors_to_keep = (
    distributors["Distributor"]
    .value_counts()
    .loc[lambda x: x == distributors["Year"].nunique()]
    .index
)</pre>
</div>
</div>
<div class="readable-text" id="p256">
<p>We can use these distributors to recreate our pivot table and see how market share compares across years:</p>
</div>
<div class="browsable-container listing-container" id="p257">
<div class="code-area-container">
<pre class="code-area">distributors_pivot = (
  distributors
  .query("Distributor in @distributors_to_keep")
  .assign(Year=distributors["Year"]
          .apply(lambda x: datetime.datetime(x, 1, 1))    <span class="aframe-location"/> #1
         )
  .groupby(["Year", "Distributor"])
  ["Market share"]
  .sum()
  .unstack()     <span class="aframe-location"/> #2
)</pre>
<div class="code-annotations-overlay-container">
     #1 Converts each year to the first of January to make it a date type
     <br/>#2 One row per year, one column per distributor
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p258">
<p>Visually, it’s easier to read the pivot table if years go across columns, so let’s transpose the data and examine the output shown in figure 5.35:</p>
</div>
<div class="browsable-container listing-container" id="p259">
<div class="code-area-container">
<pre class="code-area">distributors_pivot.transpose()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p260">
<img alt="figure" height="472" src="../Images/5-35.png" width="703"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.35</span> Distributor market share (%) over time</h5>
</div>
<div class="readable-text" id="p261">
<p>From this pivot table, we can conclude the following:</p>
</div>
<ul>
<li class="readable-text" id="p262"> Walt Disney completed their purchase of 20th Century Fox in 2019, yet this did not translate to a large increase in market share even in 2021. </li>
<li class="readable-text" id="p263"> Sony achieved the biggest increase in market share post-lockdown, doubling their market share from 2018, but Universal also increased their market share from pre-COVID levels. </li>
<li class="readable-text" id="p264"> Apart from Sony and Universal, the distributors with bigger market share roughly returned to pre-COVID levels of market share in 2021. Some smaller ones, like StudioCanal, failed to reach pre-COVID levels. </li>
</ul>
<div class="readable-text" id="p265">
<p>Initial speculation about these results might be that the bigger distributors are the ones that have the resources to bounce back from even a global pandemic, whereas smaller distributors will likely struggle more with this.</p>
</div>
<div class="readable-text intended-text" id="p266">
<p>Before summarizing our findings, let’s review the whole process, including places where our latest step could have diverged. Figure 5.36 shows the whole process.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p267">
<img alt="figure" height="874" src="../Images/5-36.png" width="812"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.36</span> The final steps taken in the example solution</h5>
</div>
<div class="readable-text" id="p268">
<p>Let’s now review our findings and summarize our recommendations to our stakeholders.</p>
</div>
<div class="readable-text" id="p269">
<h3 class="readable-text-h3" id="sigil_toc_id_69"><span class="num-string">5.4.4</span> Project conclusions and recommendations</h3>
</div>
<div class="readable-text" id="p270">
<p>What do our results mean for the white paper?</p>
</div>
<ul>
<li class="readable-text" id="p271"> UK-level admissions data does not tell a very interesting story beyond admissions looking like they are reaching pre-COVID levels. An additional year of data would help clarify post-lockdown trends, as would looking at admissions at a more granular level, such as by region or film type. </li>
<li class="readable-text" id="p272"> There is a difference in the breakdown of genres post-lockdowns, certainly enough of a difference to investigate this angle further. </li>
<li class="readable-text" id="p273"> Distributors follow general market trends where larger entities bounce back from COVID more easily than smaller ones. </li>
</ul>
<div class="readable-text" id="p274">
<p>The limitations of our analysis extend mostly to a lack of data. We do not have a lot of post-lockdown data to compare with past trends, so our conclusions can only be tentative. Our data is focused on the United Kingdom, so it does not give a global picture. However, we can assume the research firm we work for would have more granular data for us to investigate our findings further. There is enough in our conclusions to have a conversation with our domain experts, but the first round of analysis does not suggest we have enough to support a white paper.</p>
</div>
<div class="readable-text intended-text" id="p275">
<p>One benefit of this analysis, whether or not it leads to a published paper, is that we have written a data pipeline to extract data from the BFI’s published statistics. Having this data in a format that is ready to be analyzed will yield value for future projects. Sometimes, cleaning data in this way can be a valuable contribution in itself.</p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p276">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Activity: Further project ideas with this data</h5>
</div>
<div class="readable-text" id="p277">
<p>The PDF files included in this chapter are a treasure trove of information about the film industry. This project focused on the effects of the pandemic, but there are many other angles to explore and many research questions that could be answered. Here are some ideas to get you started:</p>
</div>
<ul>
<li class="readable-text" id="p278"> How have people’s preferences of genre evolved over time? </li>
<li class="readable-text" id="p279"> Is there a pattern in what kind of independent films is successful? </li>
<li class="readable-text" id="p280"> How have attendance figures changed over time in different countries? Are movie-goers changing the same way everywhere? </li>
</ul>
</div>
<div class="readable-text" id="p281">
<h2 class="readable-text-h2" id="sigil_toc_id_70"><span class="num-string">5.5</span> Closing thoughts on exploring novel data sources</h2>
</div>
<div class="readable-text" id="p282">
<p>There are two takeaways from this chapter. One is that you will encounter situations where you need to learn a specific, narrow skill to extract data from an unusual format. This is a good opportunity to learn about more esoteric parts of your existing toolkit, such as its PDF-extracting capabilities. AI tools can accelerate this learning process, and this chapter’s project is an example of where depth is not required. To successfully complete the project in this chapter, you did not need to become an expert in PDF extraction or optical character recognition, the process of converting an image to a machine-readable text form. You only needed to find the relevant library and code snippets to extract tabular data from a PDF. It is an example of learning enough to stay focused on the end result and no more.</p>
</div>
<div class="readable-text intended-text" id="p283">
<p>Second, the broader takeaway is that data is available in many forms. Knowing that our tools make it possible to extract data from unusual, unstructured sources will expand the potential data available to us for our analyses. It allows us to generate more creative solutions to problems, which will help us add more value with our work.</p>
</div>
<div class="readable-text" id="p284">
<h3 class="readable-text-h3" id="sigil_toc_id_71"><span class="num-string">5.5.1</span> Skills for exploring unusual data sources for any project</h3>
</div>
<div class="readable-text" id="p285">
<p>In this chapter, we explored a new source of data, namely, PDF files. The specific skills required for unusual data sources, and more broadly for exploring new data sources, which can be used for any problem, include</p>
</div>
<ul>
<li class="readable-text" id="p286"> Finding the relevant data in unstructured files, such as PDFs </li>
<li class="readable-text" id="p287"> Identifying existing tools to extract data from a novel source </li>
<li class="readable-text" id="p288"> Using AI tools such as ChatGPT to learn about specific tools for specific data formats </li>
<li class="readable-text" id="p289"> Using new tools to extract data from unstructured sources into structured formats (e.g., data from PDFs into CSV files) </li>
<li class="readable-text" id="p290"> Enhancing extracted data with custom logic (e.g., pre- and post-COVID lockdown periods) </li>
<li class="readable-text" id="p291"> Investigating trends by extracting similar data from multiple sources over time (e.g., the same annual report across multiple years) </li>
<li class="readable-text" id="p292"> Resolving differences across multiple similar data sources (e.g., names of production companies changing over time but relating to the same entity) </li>
</ul>
<div class="readable-text" id="p293">
<h2 class="readable-text-h2" id="sigil_toc_id_72">Summary</h2>
</div>
<ul>
<li class="readable-text" id="p294"> Identifying novel and unstructured data sources is a core skill of a good analyst. </li>
<li class="readable-text" id="p295"> Considering new data sources in your analysis may introduce nontabular or unstructured data requiring effort to clean up: time you should consider when including them. </li>
<li class="readable-text" id="p296"> Telling the story that’s in the data, rather than the one our stakeholders asked for in their problem statement, is critical to avoid misleading ourselves. </li>
<li class="readable-text" id="p297"> Focusing on the problem to solve rather than the data increases the chances that any additional data you consider will be relevant. </li>
</ul>
</div></body></html>