["```py\n## Python\nimport statsmodels.api as sm # For QQ-plot\nimport statsmodels.stats.outliers_influence as st_inf # For Cook distance\n```", "```py\n## R (output not shown)\nlin_mod_summ <- summary(lm(times~1, data=dat))\nest <- lin_mod_summ$coefficients[1,1]\nse <- lin_mod_summ$coefficients[1,2]\nLL <- est-1.96*se\nUL <- est+1.96*se\n\n```", "```py\n## Python\nlin_mod = ols(\"times~1\", data=data_df).fit()\nest = lin_mod.params['Intercept']\nse = lin_mod.bse['Intercept']\nLL = est-1.96*se #Lower limit\nUL = est+1.96*se #Upper limit\nprint(\"LL = \", LL)\nprint(\"UL = \",UL)\n\nLL =  -23.040199740431333\nUL =  134.64019974043134\n```", "```py\n## R\nboot_dat <- slice_sample(dat, n=nrow(dat), replace = TRUE)\n\n```", "```py\n## Python\nboot_df = data_df.sample(len(data_df), replace = True)\n```", "```py\n## R\nmean_lst <- list() ![1](Images/1.png)\nB <- 2000\nN <- nrow(dat)\nfor(i in 1:B){  ![2](Images/2.png)\n  boot_dat <- slice_sample(dat, n=N, replace = TRUE)\n  M <- mean(boot_dat$times)\n  mean_lst[[i]] <- M}\nmean_summ <- tibble(means = unlist(mean_lst)) ![3](Images/3.png)\n\n```", "```py\n## Python \nres_boot_sim = [] \nB = 2000\nN = len(data_df)\nfor i in range(B): \n    boot_df = data_df.sample(N, replace = True)\n    M = np.mean(boot_df.times)\n    res_boot_sim.append(M)\n```", "```py\n## R (output not shown)\nLL_b <- as.numeric(quantile(mean_summ$means, c(0.025)))\nUL_b <- as.numeric(quantile(mean_summ$means, c(0.975)))\n\n```", "```py\n## Python \nLL_b = np.quantile(mean_lst, 0.025)  \nUL_b = np.quantile(mean_lst, 0.975)\nprint(\"LL_b = \", LL_b)\nprint(\"UL_b = \",UL_b)\n\nLL_b =  7.4975000000000005\nUL_b =  140.80249999999998\n```", "```py\n## R\npromise_lst <- list()\nN <- nrow(dat)\nB <- 2000\nfor(i in 1:B){\n  boot_dat <- slice_sample(dat, n=N, replace = TRUE)\n  above180 <- sum(boot_dat$times >= 180)/N\n  promise_lst[[i]] <- above180}\npromise_summ <- tibble(above180 = unlist(promise_lst))\nLL_b <- as.numeric(quantile(promise_summ$above180, c(0.025)))\nUL_b <- as.numeric(quantile(promise_summ$above180, c(0.975)))\n```", "```py\n## Python\npromise_lst = []\nB = 2000\nN = len(data_df)\nfor i in range(B):\n    boot_df = data_df.sample(N, replace = True)\n    above180 =  len(boot_df[boot_df.times >= 180]) / N\n    promise_lst.append(above180)\nLL_b = np.quantile(promise_lst, 0.025)  \nUL_b = np.quantile(promise_lst, 0.975)\n```", "```py\n## Python (output not shown)\nprint(ols(\"times~experience\", data=data_df).fit().summary())\n```", "```py\n## R \nmod <- lm(times~experience, data=dat)\nmod_summ <- summary(mod)\nmod_summ\n...\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  132.389     61.750   2.144   0.0644\nexperience    -9.819      6.302  -1.558   0.1578 \n...\n```", "```py\n## R (output not shown)\nreg_fun <- function(dat, B){\n  N <- nrow(dat)\n  reg_lst <- list()\n  for(i in 1:B){\n    boot_dat <- slice_sample(dat, n=N, replace = TRUE)\n    summ <- summary(lm(times~experience, data=boot_dat))\n    coeff <- summ$coefficients['experience','Estimate']\n    reg_lst[[i]] <- coeff}\n  reg_summ <- tibble(coeff = unlist(reg_lst))\n  return(reg_summ)}\nreg_summ <- reg_fun(dat, B=4000)\n```", "```py\n## Python (output not shown)\nreg_lst = []\nB = 4000\nN = len(data_df)\nfor i in range(B):\n    boot_df = data_df.sample(N, replace = True)\n    lin_mod = ols(\"times~experience\", data=boot_df).fit()\n    coeff = lin_mod.params['experience']\n    reg_lst.append(coeff)\nLL_b = np.quantile(reg_lst, 0.025)  \nUL_b = np.quantile(reg_lst, 0.975)\n```", "```py\n## Python (output not shown)\npval = 2 * sum(1 for x in reg_lst if x > 0) / B\n\n```", "```py\n## R\nreg_summ %>% summarise(pval = 2 * sum(coeff > 0)/n())\n# A tibble: 1 x 1\n    pval\n  <dbl>\n1 0.04\n```", "```py\n## Python (output not shown)\nCD = st_inf.OLSInfluence(lin_mod).summary_frame()['cooks_d']\nCD[CD > 1]\n```", "```py\n## R\n> CD <- cooks.distance(mod)\n> CD[CD > 1]\n     10 \n1.45656\n```", "```py\n## R\nres_dat <- tibble(res = resid(mod))\np1 <- ggplot(res_dat, aes(res)) + geom_density() + xlab(\"regression residuals\")\np2 <- ggplot(res_dat, aes(sample=res)) + geom_qq() + geom_qq_line() + \n  coord_flip()\nggarrange(p1, p2, ncol=2, nrow=1)\n```", "```py\n## Python \nres_df = lin_mod.resid\nsns.kdeplot(res_df)\nfig = sm.qqplot(res_df, line='s')\nplt.show()\n```", "```py\n## R\n(...)\nfor(i in 1:B){\n  boot_dat <- slice_sample(dat, n=N, replace = TRUE)\n  summ <- summary(lm(times~experience, data=boot_dat))\n(...)\n```", "```py\n## R\n> I <- c(1:10)\n> I\n [1]  1  2  3  4  5  6  7  8  9 10\n> J <- sample(I, 10, replace = TRUE)\n> J\n [1] 10  3  1  1  6  1  9  3  4  3\n> boot_dat <- dat[J,]\n```", "```py\n## R\nboot_fun <- function(dat, J){\n  Boot_dat <- dat[J,]\n  summ <- summary(lm(times~experience, data=boot_dat))\n  coeff <- summ$coefficients['experience','Estimate']\n  return(coeff)\n}\n```", "```py\n## R\n> boot.out <- boot(data = dat, statistic = boot_fun, R = 2000)\n> boot.ci(boot.out, conf = 0.95, type = c('norm', 'perc', 'bca'))\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 2000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = boot.out, conf = 0.95, type = c(\"norm\", \"perc\", \n    \"bca\"))\n\nIntervals : \nLevel      Normal             Percentile            BCa          \n95%   (-25.740,   6.567 )   (-28.784,  -0.168 )   (-38.144,  -0.383 )  \nCalculations and Intervals on Original Scale\n```", "```py\n## R \nboot_CI_fun <- function(dat, metric_fun){\n  #Setting the number of bootstrap samples\n  B <- 100\n\n  boot_metric_fun <- function(dat, J){\n    boot_dat <- dat[J,]\n    return(metric_fun(boot_dat))\n  }\n  boot.out <- boot(data=dat, statistic=boot_metric_fun, R=B)\n  confint <- boot.ci(boot.out, conf = 0.90, type = c('perc'))\n  CI <- confint$percent[c(4,5)]\n\n  return(CI)\n}\n```", "```py\n## Python\n# Creating unique numpy array for sampling\ndata_ar = data_df.to_numpy() ![1](Images/1.png)                                        \nrng = np.random.default_rng() ![2](Images/2.png)           \n\nnp_lst = []\nfor i in range(B): \n    # Extracting the relevant columns from array\n    boot_ar = rng.choice(data_ar, size=N, replace=True) ![3](Images/3.png)          \n    X = boot_ar[:,1] ![4](Images/4.png)\n    X = np.c_[X, np.ones(N)]\n    Y = boot_ar[:,0] ![5](Images/5.png)                                           \n\n    ### LSTQ implementation\n    np_lst.append(np.linalg.lstsq(X, Y, rcond=-1)[0][0]) ![6](Images/6.png)\n```"]