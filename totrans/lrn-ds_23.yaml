- en: 'Chapter 18\. Case Study: How to Weigh a Donkey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Donkeys play important roles in rural Kenya. People need them to transport crops,
    water, and people and to plow fields. When a donkey gets sick, the veterinarian
    needs to figure out how much the donkey weighs in order to prescribe the right
    amount of medicine. But many vets in rural Kenya don’t have access to a scale,
    so they need to guess the donkey’s weight. Too little medicine can allow an infection
    to reemerge; too much medicine can cause a harmful overdose. There are over 1.8
    million donkeys in Kenya, so it’s important to have a simple, accurate way to
    estimate the weight of a donkey.
  prefs: []
  type: TYPE_NORMAL
- en: In this case study, we follow the work of [Kate Milner and Jonathan Rougier](https://doi.org/10.1111/j.1740-9713.2014.00768.x)
    to create a model that veterinarians in the Kenyan countryside can use to make
    accurate estimates of a donkey’s weight. As usual, we walk through the steps of
    the data science lifecycle, but this time our work departs from the basics covered
    so far in this book. You can think of this case study as an opportunity to reflect
    on many of the core principles of working with data and to understand how they
    can be extended to address the context of the situation. We directly evaluate
    sources of measurement error, design a special loss function that reflects the
    concern about an overdose, build a model while keeping applicability top of mind,
    and evaluate model predictions using special criteria that are relative to the
    donkey’s size.
  prefs: []
  type: TYPE_NORMAL
- en: We begin with the scope of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Donkey Study Question and Scope
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our motivating question is: how can a vet accurately estimate the weight of
    a donkey when they’re out in the countryside without a scale? Let’s think about
    the information that is more readily available to them. They can carry a tape
    measure and find the size of the donkey in other dimensions, like its height.
    They can observe the animal’s sex, assess its general condition, and inquire about
    the donkey’s age. So we can refine our question to: how can a vet accurately predict
    the weight of a donkey from easy-to-get measurements?'
  prefs: []
  type: TYPE_NORMAL
- en: To address this more precise question, [The Donkey Sanctuary](https://oreil.ly/uUyZj)
    carried out a study at 17 mobile deworming sites in rural Kenya.
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of scope ([Chapter 2](ch02.html#ch-data-scope)), the target population
    is the donkey population in rural Kenya. The access frame is the set of all donkeys
    that were brought into the de-worming sites. The sample consists of all donkeys
    brought to these sites between July 23 and August 11, 2010, with a few caveats:
    if there were too many donkeys to measure at a site, the scientists selected a
    subset of donkeys to measure, and any pregnant or visibly diseased donkeys were
    excluded from the study.'
  prefs: []
  type: TYPE_NORMAL
- en: To avoid accidentally weighing a donkey twice, each donkey was marked after
    weighing. To quantify the measurement error and assess repeatability of the weighing
    process, 31 donkeys were measured twice, without the staff knowing that a donkey
    was being reweighed.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this sampling process in mind, potential sources of bias for this data
    include:'
  prefs: []
  type: TYPE_NORMAL
- en: Coverage bias
  prefs: []
  type: TYPE_NORMAL
- en: The 17 sites were located in the regions surrounding the Yatta district in eastern
    Kenya and the Naivasha district in the Rift Valley.
  prefs: []
  type: TYPE_NORMAL
- en: Selection bias
  prefs: []
  type: TYPE_NORMAL
- en: Only donkeys brought to the sanctuary were enrolled in the study, and when there
    were too many donkeys at a site, a nonrandom sample was selected.
  prefs: []
  type: TYPE_NORMAL
- en: Measurement bias
  prefs: []
  type: TYPE_NORMAL
- en: In addition to measurement error, the scale might have a bias. Ideally, the
    scale(s) would be calibrated before and after use at a site ([Chapter 12](ch12.html#ch-pa)).
  prefs: []
  type: TYPE_NORMAL
- en: Despite these potential sources of bias, the access frame seems reasonable for
    accessing donkeys from rural areas in Kenya that have owners looking after the
    health of their animals.
  prefs: []
  type: TYPE_NORMAL
- en: Our next step is to clean the data.
  prefs: []
  type: TYPE_NORMAL
- en: Wrangling and Transforming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We begin by taking a peek at the contents of our datafile. To do this, we open
    the file and examine the first few rows ([Chapter 8](ch08.html#ch-files)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the file is CSV-formatted, we can easily read it into a dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '|   | BCS | Age | Sex | Length | Girth | Height | Weight | WeightAlt |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | 3.0 | <2 | stallion | 78 | 90 | 90 | 77 | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | 2.5 | <2 | stallion | 91 | 97 | 94 | 100 | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | 1.5 | <2 | stallion | 74 | 93 | 95 | 74 | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| **...** | ... | ... | ... | ... | ... | ... | ... | ... |'
  prefs: []
  type: TYPE_TB
- en: '| **541** | 2.5 | 10-15 | stallion | 103 | 118 | 103 | 174 | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| **542** | 3.0 | 2-5 | stallion | 91 | 112 | 100 | 139 | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| **543** | 3.0 | 5-10 | stallion | 104 | 124 | 110 | 189 | NaN |'
  prefs: []
  type: TYPE_TB
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Over five hundred donkeys participated in the survey, and eight measurements
    were made on each donkey. According to the documentation, the granularity is a
    single donkey ([Chapter 9](ch09.html#ch-wrangling)). [Table 18-1](#tbl-donkey-codebook)
    provides descriptions of the eight features.
  prefs: []
  type: TYPE_NORMAL
- en: Table 18-1\. Donkey study codebook
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature | Data type | Feature type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| BCS | float64 | Ordinal | Body condition score: from 1 (emaciated) to 3 (healthy)
    to 5 (obese) in increments of 0.5. |'
  prefs: []
  type: TYPE_TB
- en: '| Age | string | Ordinal | Age in years, under 2, 2–5, 5–10, 10–15, 15–20,
    and over 20 years |'
  prefs: []
  type: TYPE_TB
- en: '| Sex | string | Nominal | Sex categories: stallion, gelding, female |'
  prefs: []
  type: TYPE_TB
- en: '| Length | int64 | Numeric | Body length (cm) from front leg elbow to back
    of pelvis |'
  prefs: []
  type: TYPE_TB
- en: '| Girth | int64 | Numeric | Body circumference (cm), measured just behind front
    legs |'
  prefs: []
  type: TYPE_TB
- en: '| Height | int64 | Numeric | Body height (cm) up to point where neck connects
    to back |'
  prefs: []
  type: TYPE_TB
- en: '| Weight | int64 | Numeric | Weight (kilogram) |'
  prefs: []
  type: TYPE_TB
- en: '| WeightAlt | float64 | Numeric | Second weight measurement taken on a subset
    of donkeys |'
  prefs: []
  type: TYPE_TB
- en: '[Figure 18-1](#fig-donkeydiagram) is a stylized representation of a donkey
    as a cylinder with neck and legs appended. Height is measured from the ground
    to the base of the neck above the shoulders; girth is around the body, just behind
    the legs; and length is from the front elbow to the back of the pelvis.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_1801.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18-1\. Diagram of a donkey’s girth, length, and height, characterized
    as measurements on a cylinder
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Our next step is to perform some quality checks on the data. In the previous
    section, we listed a few potential quality concerns based on scope. Next, we check
    the quality of the measurements and their distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by comparing the two weight measurements made on the subset of
    donkeys to check on the consistency of the scale. We make a histogram of the difference
    between these two measurements for the 31 donkeys that were weighed twice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_18in01.png)'
  prefs: []
  type: TYPE_IMG
- en: The measurements are all within 1 kg of each other, and the majority are exactly
    the same (to the nearest kilogram). This gives us confidence in the accuracy of
    the measurements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we look for unusual values in the body condition score:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'From this output, we see that there’s only one emaciated (BCS = 1) and one
    obese (BCS = 4.5) donkey. Let’s look at the complete records for these two donkeys:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '|   | BCS | Age | Sex | Length | Girth | Height | Weight | WeightAlt |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **291** | 4.5 | 10-15 | female | 107 | 130 | 106 | 227 | NaN |'
  prefs: []
  type: TYPE_TB
- en: '| **445** | 1.0 | >20 | female | 97 | 109 | 102 | 115 | NaN |'
  prefs: []
  type: TYPE_TB
- en: Since these BCS values are extreme, we want to be cautious about including these
    two donkeys in our analysis. We have only one donkey in each of these extreme
    categories, so our model might well not extend to donkeys with a BCS of 1 or 4.5\.
    We remove these two records from the dataframe and note that our analysis may
    not extend to emaciated or obese donkeys. In general, we exercise caution in dropping
    records from a dataframe. Later, we may also decide to remove the five donkeys
    with a score of 1.5 if they appear anomalous in our analysis, but for now, we
    keep them in our dataframe. In general, we need a good reason to exclude data,
    and we should document these actions since they can impact our findings. Removing
    data can lead to over fitting, if we drop any record that disagrees with the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We remove these two outliers next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we examine the distribution of values for weight to see if there are any
    issues with quality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_18in02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It appears there is one very light donkey weighing less than 30 kg. Next, we
    check the relationship between weight and height to assess the quality of the
    data for analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_18in03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The small donkey is far from the main concentration of donkeys and would overly
    influence our models. For this reason, we exclude it. Again, we keep in mind that
    we may also want to exclude the one or two heavy donkeys if they appear to overly
    influence our future model fitting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In summary, based on our cleaning and quality checks, we removed three anomalous
    observations from the dataframe. Now we’re nearly ready to begin our exploratory
    analysis. Before we proceed, we set aside some of our data as a test set.
  prefs: []
  type: TYPE_NORMAL
- en: We talked about why it’s important to separate out a test set from the train
    set in [Chapter 16](ch16.html#ch-risk). A best practice is to separate out a test
    set early in the analysis, before we explore the data in detail, because in EDA,
    we begin to make decisions about what kinds of models to fit and what variables
    to use in the model. It’s important that our test set isn’t involved in these
    decisions so that it imitates how our model would perform with entirely new data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We divide our data into an 80/20 split, where we use 80% of the data to explore
    and build a model. Then we evaluate the model with the 20% that has been set aside.
    We use a simple random sample to split the dataframe into the test and train sets.
    To begin, we randomly shuffle the indices of the dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we assign the first 80% of the dataframe to the train set and the remaining
    20% to the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now we’re ready to explore the training data and look for useful relationships
    and distributions that inform our modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s look at the features in our dataframe for shapes and relationships that
    will help us make transformations and models ([Chapter 10](ch10.html#ch-eda)).
    We start by looking at how the categorical features of age, sex, and body condition
    relate to weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_18in04.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_18in05.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that we plotted the points as well as the boxes for the body condition
    score because we saw earlier that there are only a handful of observations with
    a score of 1.5, so we don’t want to read too much into a box plot with only a
    few data points ([Chapter 11](ch11.html#ch-viz)). It appears that the median weight
    increases with the body condition score, but not in a simple linear fashion. On
    the other hand, weight distributions for the three sex categories appear roughly
    the same. As for age, once a donkey reaches five years, the distribution of weight
    doesn’t seem to change much. But donkeys under age 2 and donkeys from 2 to 5 years
    of age have lower weights in general.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s examine the quantitative variables. We plot all pairs of quantitative
    variables in the scatterplot matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_18in06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The height, length, and girth of donkeys all appear linearly associated with
    weight and with each other. This is not too surprising; given one of the donkey’s
    dimensions, we should have a good guess about the other dimensions. Girth appears
    most highly correlated with weight, and this is confirmed by the correlation coefficient
    matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '|   | Weight | Length | Girth | Height |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Weight** | 1.00 | 0.78 | 0.90 | 0.71 |'
  prefs: []
  type: TYPE_TB
- en: '| **Length** | 0.78 | 1.00 | 0.66 | 0.58 |'
  prefs: []
  type: TYPE_TB
- en: '| **Girth** | 0.90 | 0.66 | 1.00 | 0.70 |'
  prefs: []
  type: TYPE_TB
- en: '| **Height** | 0.71 | 0.58 | 0.70 | 1.00 |'
  prefs: []
  type: TYPE_TB
- en: Our explorations uncovered several aspects of the data that may be relevant
    for modeling. We found that the donkey’s girth, length, and height all have linear
    associations with weight and with each other, and girth has the strongest linear
    relationship with weight. We also observed that the body condition score has a
    positive association with weight; the sex of the donkey does not appear related
    to weight; and neither does age for those donkeys over 5 years. In the next section,
    we use these findings to build our model.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling a Donkey’s Weight
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We want to build a simple model for predicting the weight of a donkey. The model
    should be easy for a vet to implement in the field with only a hand calculator.
    The model should also be easy to interpret.
  prefs: []
  type: TYPE_NORMAL
- en: We also want the model to depend on the vet’s situation—for example, whether
    they’re prescribing an antibiotic or an anesthetic. For brevity, we only consider
    the case of prescribing an anesthetic. Our first step is to choose a loss function
    that reflects this situation.
  prefs: []
  type: TYPE_NORMAL
- en: A Loss Function for Prescribing Anesthetics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An overdose of an anesthetic can be much worse than an underdose. It’s not
    hard for a vet to see when a donkey has too little anesthetic (it’ll complain),
    and the vet can give the donkey a bit more. On the other hand, too much anesthetic
    can have serious consequences and can even be fatal. Because of this, we want
    an asymmetric loss function: it should have a bigger loss for an overestimate
    of weight compared to an underestimate. This is in contrast to the other loss
    functions that we have used so far in this book, which have all been symmetric.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve created a loss function `anes_loss(x)` with this in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The relative error is <math><mn>100</mn> <mo stretchy="false">(</mo> <mi>y</mi>
    <mo>−</mo> <mrow><mover><mi>y</mi> <mo stretchy="false">^</mo></mover></mrow>
    <mo stretchy="false">)</mo> <mrow><mo>/</mo></mrow> <mrow><mover><mi>y</mi> <mo
    stretchy="false">^</mo></mover></mrow></math> , where <math><mi>y</mi></math>
    is the true value and <math><mrow><mover><mi>y</mi> <mo stretchy="false">^</mo></mover></mrow></math>
    is the prediction. We can demonstrate the asymmetry of the loss function with
    a plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_18in07.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that a value of –10 on the x-axis reflects an overestimate of 10%.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s fit a simple linear model using this loss function.
  prefs: []
  type: TYPE_NORMAL
- en: Fitting a Simple Linear Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We saw that girth has the highest correlation with weight among the donkeys
    in our train set. So we fit a model of the form:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi>
    <mn>1</mn></msub> <mtext>Girth</mtext></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'To find the best fit <math><msub><mi>θ</mi> <mn>0</mn></msub></math> and <math><msub><mi>θ</mi>
    <mn>1</mn></msub></math> to the data, we first create a design matrix that has
    girth and an intercept term. We also create the <math><mi>y</mi></math> vector
    of observed donkey weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '|   | intr | Girth |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **230** | 1 | 116 |'
  prefs: []
  type: TYPE_TB
- en: '| **74** | 1 | 117 |'
  prefs: []
  type: TYPE_TB
- en: '| **354** | 1 | 123 |'
  prefs: []
  type: TYPE_TB
- en: '| **...** | ... | ... |'
  prefs: []
  type: TYPE_TB
- en: '| **157** | 1 | 123 |'
  prefs: []
  type: TYPE_TB
- en: '| **41** | 1 | 103 |'
  prefs: []
  type: TYPE_TB
- en: '| **381** | 1 | 106 |'
  prefs: []
  type: TYPE_TB
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we want to find the <math><msub><mi>θ</mi> <mn>0</mn></msub></math> and
    <math><msub><mi>θ</mi> <mn>1</mn></msub></math> that minimize the average anesthetic
    loss over the data. To do this, we could use calculus as we did in [Chapter 15](ch15.html#ch-linear),
    but here we’ll instead use the `minimize` method from the `scipy` package, which
    performs a numerical optimization (see [Chapter 20](ch20.html#ch-gd)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see how this simple model does. We can use the model to predict the donkey
    weights on our train set, then find the errors in the predictions. The residual
    plot that follows shows the model error as a percentage of the predicted value.
    It’s more important for the prediction errors to be small relative to the size
    of the donkey, since a 10 kg error is much worse for a 100 kg donkey than a 200
    kg one. Thus, we find the relative error of each prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s examine a scatterplot of the relative errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_18in08.png)'
  prefs: []
  type: TYPE_IMG
- en: With the simplest model, some of the predictions are off by 20% to 30%. Let’s
    see if a slightly more complicated model improves the predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Fitting a Multiple Linear Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s consider additional models that incorporate the other numeric variables.
    We have three numeric variables that measure the donkey’s girth, length, and height,
    and there are seven total ways to combine these variables in a model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'For each of these variable combinations, we can fit a model with our special
    loss function. Then we can look at how well each model does on the train set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '|   | model | mean_training_error |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | [Girth] | 94.36 |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | [Length] | 200.55 |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | [Height] | 268.88 |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | [Girth, Length] | 65.65 |'
  prefs: []
  type: TYPE_TB
- en: '| **4** | [Girth, Height] | 86.18 |'
  prefs: []
  type: TYPE_TB
- en: '| **5** | [Length, Height] | 151.15 |'
  prefs: []
  type: TYPE_TB
- en: '| **6** | [Girth, Length, Height] | 63.44 |'
  prefs: []
  type: TYPE_TB
- en: As we stated earlier, the girth of the donkey is the single best predictor for
    weight. However, the combination of girth and length has an average loss that
    is quite a bit smaller than girth alone, and this particular two-variable model
    is nearly as good as the model that includes all three. Since we want a simple
    model, we select the two-variable model over the three-variable one.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we use feature engineering to incorporate categorical variables into the
    model, which improves our model.
  prefs: []
  type: TYPE_NORMAL
- en: Bringing Qualitative Features into the Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our exploratory analysis, we found that the box plots of weight for a donkey’s
    body condition and age could contain useful information in predicting weight.
    Since these are categorical features, we can transform them into 0-1 variables
    with one-hot encoding, as explained in [Chapter 15](ch15.html#ch-linear).
  prefs: []
  type: TYPE_NORMAL
- en: 'One-hot encoding lets us adjust the intercept term in the model for each combination
    of categories. Our current model includes the numeric variables girth and length:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi>
    <mn>1</mn></msub> <mtext>Girth</mtext> <mo>+</mo> <msub><mi>θ</mi> <mn>2</mn></msub>
    <mtext>Length</mtext></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If we cleaned up the age feature to consist of three categories—`Age<2`, `Age2-5`,
    and `Age>5`—a one-hot encoding of age creates three 0-1 features, one for each
    category. Including the one-hot-encoded feature in the model gives:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><msub><mi>θ</mi> <mn>0</mn></msub></mtd>
    <mtd><mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mtext>Girth </mtext> <mo>+</mo>
    <msub><mi>θ</mi> <mn>2</mn></msub> <mtext>Length </mtext></mtd></mtr> <mtr><mtd><mo>+</mo>
    <msub><mi>θ</mi> <mn>3</mn></msub> <mtext>Age<2 </mtext> <mo>+</mo> <msub><mi>θ</mi>
    <mn>4</mn></msub> <mtext>Age2-5 </mtext></mtd></mtr></mtable></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: In this model, `Age<2` is 1 for a donkey younger than 2 and 0 otherwise. Similarly,
    `Age2-5` is 1 for a donkey between 2 and 5 years old and 0 otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can think of this model as fitting three linear models that are identical
    except for the size of the constant, since the model is equivalent to:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mo stretchy="false">(</mo> <msub><mi>θ</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>3</mn></msub> <mo stretchy="false">)</mo>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mtext>Girth</mtext> <mo>+</mo>
    <msub><mi>θ</mi> <mn>2</mn></msub> <mtext>Length</mtext></mtd> <mtd><mtext>for
    a donkey under 2</mtext></mtd></mtr> <mtr><mtd><mo stretchy="false">(</mo> <msub><mi>θ</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>4</mn></msub> <mo stretchy="false">)</mo>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mtext>Girth</mtext> <mo>+</mo>
    <msub><mi>θ</mi> <mn>2</mn></msub> <mtext>Length</mtext></mtd> <mtd><mtext>for
    a donkey between 2 and 4</mtext></mtd></mtr> <mtr><mtd><msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mtext>Girth</mtext> <mo>+</mo>
    <msub><mi>θ</mi> <mn>2</mn></msub> <mtext>Length</mtext></mtd> <mtd>          <mtext>for
    a donkey over 5</mtext></mtd></mtr></mtable></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s apply a one-hot encoding to all three of our categorical variables
    (body condition, age, and sex):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '|   | intr | Length | Girth | BCS_1.5 | ... | Age_<2 | Age_>20 | Sex_gelding
    | Sex_stallion |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **230** | 1 | 101 | 116 | 0 | ... | 0 | 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| **74** | 1 | 92 | 117 | 0 | ... | 0 | 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| **354** | 1 | 103 | 123 | 0 | ... | 0 | 1 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| **...** | ... | ... | ... | ... | ... | ... | ... | ... | ... |'
  prefs: []
  type: TYPE_TB
- en: '| **157** | 1 | 93 | 123 | 0 | ... | 0 | 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| **41** | 1 | 89 | 103 | 0 | ... | 1 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| **381** | 1 | 86 | 106 | 0 | ... | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We dropped one dummy variable for each categorical feature. Since `BCS`, `Age`,
    and `Sex` have six, six, and three categories, respectively, we have added 12
    dummy variables to the design matrix for a total of 15 columns, including the
    intercept term, girth, and length.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see which categorical variables, if any, improve on our two-variable
    model. To do this, we can fit the model that includes the dummies from all three
    categorical features, along with girth and length:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'According to average loss, this model does better than the previous model with
    only `Girth` and `Length`. But let’s try to make this model simpler while keeping
    its accuracy. To do this, we look at the coefficients for each of the dummy variables
    to see how close they are to 0 and to one another. In other words, we want to
    see how much the intercept might change if we include the coefficients in the
    model. A plot of the coefficients will make this comparison easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_18in09.png)'
  prefs: []
  type: TYPE_IMG
- en: The coefficients confirm what we saw in the box plots. The coefficients for
    the sex of the donkey are close to zero, meaning that knowing the sex doesn’t
    really change the weight prediction. We also see that combining the age categories
    for donkeys over 5 years will simplify the model without losing much. Lastly,
    since there are so few donkeys with a body condition score of 1.5 and its coefficient
    is close to that of a BCS of 2, we are inclined to combine these two categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'We update the design matrix in view of these findings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'And then we fit the simpler model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The average error is close enough to that of the more complex model for us
    to settle on this simpler one. Let’s display the coefficients and summarize the
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '|   | var | theta_hat |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | intr | -175.25 |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | Length | 1.01 |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | Girth | 1.97 |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | BCS_2.0 | -6.33 |'
  prefs: []
  type: TYPE_TB
- en: '| **4** | BCS_2.5 | -5.11 |'
  prefs: []
  type: TYPE_TB
- en: '| **5** | BCS_3.5 | 7.36 |'
  prefs: []
  type: TYPE_TB
- en: '| **6** | BCS_4.0 | 20.05 |'
  prefs: []
  type: TYPE_TB
- en: '| **7** | Age_2-5 | -3.47 |'
  prefs: []
  type: TYPE_TB
- en: '| **8** | Age_<2 | -6.49 |'
  prefs: []
  type: TYPE_TB
- en: 'Our model is roughly:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtext>Weight</mtext> <mo>≈</mo> <mo>−</mo> <mn>175</mn>
    <mo>+</mo> <mtext>Length</mtext> <mo>+</mo> <mn>2</mn> <mtext>Girth</mtext></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'After this initial approximation, we use the categorical features to make some
    adjustments:'
  prefs: []
  type: TYPE_NORMAL
- en: BCS 2 or less? Subtract 6.5 kg.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BCS 2.5? Subtract 5.1 kg.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BCS 3.5? Add 7.4 kg.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BCS 4? Add 20 kg.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Age under 2 years? Subtract 6.5 kg.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Age between 2 and 5 years? Subtract 3.5 kg.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This model seems quite simple to implement because after our initial estimate
    based on the length and girth of the donkey, we add or subtract a few numbers
    based on answers to a few yes/no questions. Let’s see how well the model does
    in predicting the weights of the donkeys in the test set.
  prefs: []
  type: TYPE_NORMAL
- en: Model Assessment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Remember that we put aside 20% of our data before exploring and modeling with
    the remaining 80%. We are now ready to apply what we have learned from the training
    set to the test set. That is, we take our fitted model and use it to predict the
    weights of the donkeys in the test set. To do this, we need to prepare the test
    set. Our model uses the girth and length of the donkey, as well as dummy variables
    for the donkey’s age and body condition score. We apply all of our transformations
    on the train set to our test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We consolidate all of our manipulations of the design matrix to create the
    final version that we settled on in our modeling with the train set. Now we are
    ready to use the <math><mi>θ</mi></math> s that we fitted with the train set to
    make weight predictions for those donkeys in the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can plot the relative prediction errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_18in10.png)'
  prefs: []
  type: TYPE_IMG
- en: Remember that positive relative error means underestimating weight, which is
    not as critical as overestimating weight. From this residual plot, we see that
    nearly all of the test set weights are within 10% of the predictions, and only
    one error that exceeds 10% errs on the side of overestimation. This makes sense
    given that our loss function penalized overestimation more.
  prefs: []
  type: TYPE_NORMAL
- en: 'An alternative scatterplot that shows the actual and predicted values along
    with lines marking 10% error gives a different view:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_18in11.png)'
  prefs: []
  type: TYPE_IMG
- en: The 10% lines lie farther from the prediction line for larger weights.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve accomplished our goal! We have a model that uses easy-to-get measurements,
    is simple enough to explain on an instruction sheet, and makes predictions within
    10% of the actual donkey weight. Next, we summarize this case study and reflect
    on our model.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this case study, we demonstrated the different purposes of modeling: description,
    inference, and prediction. For description, we sought a simple, understandable
    model. We handcrafted this model, beginning with our findings from the exploratory
    phase of the analysis. Every action we took to include a feature in the model,
    collapse categories, or transform a feature amounts to a decision we made while
    investigating the data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In modeling a natural phenomenon such as the weight of a donkey, we would ideally
    make use of physical and statistical models. In this case, the physical model
    is the representation of a donkey by a cylinder. An inquisitive reader might have
    pointed out that we could have used this representation directly to estimate the
    weight of a donkey (cylinder) from its length and girth (since girth is <math><mn>2</mn>
    <mi>π</mi> <mi>r</mi></math> ):'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mi>w</mi> <mi>e</mi> <mi>i</mi> <mi>g</mi> <mi>h</mi>
    <mi>t</mi> <mo>∝</mo> <mi>g</mi> <mi>i</mi> <mi>r</mi> <mi>t</mi> <msup><mi>h</mi>
    <mn>2</mn></msup> <mo>×</mo> <mi>l</mi> <mi>e</mi> <mi>n</mi> <mi>g</mi> <mi>t</mi>
    <mi>h</mi></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'This physical model suggests that the log-transformed weight is approximately
    linear in girth and length:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>w</mi>
    <mi>e</mi> <mi>i</mi> <mi>g</mi> <mi>h</mi> <mi>t</mi> <mo stretchy="false">)</mo>
    <mo>∝</mo> <mn>2</mn> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>g</mi>
    <mi>i</mi> <mi>r</mi> <mi>t</mi> <mi>h</mi> <mo stretchy="false">)</mo> <mo>+</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>l</mi> <mi>e</mi> <mi>n</mi>
    <mi>g</mi> <mi>t</mi> <mi>h</mi> <mo stretchy="false">)</mo></math>
  prefs: []
  type: TYPE_NORMAL
- en: Given this physical model, you might wonder why we did not use logarithmic or
    square transformations in fitting our model. We leave you to investigate such
    a model in greater detail. But generally, if the range of values measured is small,
    then the log function is roughly linear. To keep our model simple, we chose not
    to make these transformations given the strength of the statistical model seen
    by the high correlation between girth and weight.
  prefs: []
  type: TYPE_NORMAL
- en: We did a lot of *data dredging* in this modeling exercise. We examined all possible
    models built from linear combinations of the numeric features, and we examined
    coefficients of dummy variables to decide whether to collapse categories. When
    we create models using an iterative approach like this, it is extremely important
    that we set aside data to assess the model. Evaluating the model on new data reassures
    us that the model we chose works well. The data that we set aside did not enter
    into any decision making when building the model, so it gives us a good sense
    of how well the model works for making predictions.
  prefs: []
  type: TYPE_NORMAL
- en: We should keep the data scope and its potential biases described earlier in
    mind. Our model has done well on the test set, but the test and train sets come
    from the same data collection process. We expect our model to work well in practice
    as long as the scope remains the same for new data.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, this case study shows how fitting models is often a balance between
    simplicity and complexity and between physical and statistical models. A physical
    model can be a good starting point in modeling, and a statistical model can inform
    a physical model. As data scientists, we needed to make judgment calls at each
    step in the analysis. Modeling is both an art and a science.
  prefs: []
  type: TYPE_NORMAL
- en: This case study and several chapters preceding it have focused on fitting linear
    models. Next, we consider a different kind of modeling for the situation when
    the response variable we are explaining or predicting is qualitative, not quantitative.
  prefs: []
  type: TYPE_NORMAL
