<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 12. Building a Knowledge Graph"><div class="chapter" id="ch-knowledge">
<h1><span class="label">Chapter 12. </span>Building a Knowledge Graph</h1>

<p>In this book, we have been working through many blueprints for text analysis. Our goal was always to identify patterns in the data with the help of statistics and machine learning. In <a data-type="xref" href="ch10.xhtml#ch-embeddings">Chapter 10</a> we explained how embeddings can be used to answer questions like “What is to Germany like Paris is to France?” Embeddings represent some kind of implicit knowledge that was learned from the training documents based on a notion of <a contenteditable="false" data-type="indexterm" data-primary="knowledge graphs" id="ch12_term1"/>similarity. </p>

<p>A knowledge base, in contrast, consists of structured statements of the form “Berlin capital-of Germany.” In this case, “capital-of” is a precisely defined relation between the two specific entities <em>Berlin</em> and <em>Germany</em>. The network formed by many entities and their relations is a graph in the mathematical sense, a <em>knowledge graph</em>. <a data-type="xref" href="#fig-simple-kg">Figure 12-1</a> shows a simple knowledge graph illustrating the example. In this chapter, we will introduce blueprints to extract structured information from unstructured text and build a basic knowledge graph. </p>

<figure><div id="fig-simple-kg" class="figure">
<img src="Images/btap_1201.jpg" width="1446" height="464"/>
<h6><span class="label">Figure 12-1. </span>A simple knowledge graph.</h6></div></figure>

<section data-type="sect1" data-pdf-bookmark="What You’ll Learn and What We’ll Build"><div class="sect1" id="idm45634176084472">
<h1>What You’ll Learn and What We’ll Build</h1>

<p>Information extraction is one of the hardest tasks in natural language processing because of the complexity and inherent ambiguity of language. Thus, we need to apply a sequence of different steps to discover the entities and relationships. Our example use case in this section is the creation of a knowledge graph based on business news articles about companies.</p>

<p>In the course of the chapter, we will take a deep dive into the advanced language processing features of spaCy. We will use the pretrained neural models in combination with custom rules for named-entity recognition, coreference resolution, and relation extraction. We will also explain the necessary steps to perform entity linking, but we won’t go into the implementation details.</p>

<p>After reading this chapter, you will have the basic linguistic and technical knowledge to start building your own knowledge base. You will find the source code for this chapter and additional information in our <a href="https://oreil.ly/5dF4g">GitHub repository</a>.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Knowledge Graphs"><div class="sect1" id="idm45634176080424">
<h1>Knowledge Graphs</h1>

<p>A knowledge graph is a large semantic network. It consists of nodes that are entities such as persons, places, events, or companies, and edges that represent formalized relations between those nodes, as shown in <a data-type="xref" href="#fig-simple-kg">Figure 12-1</a>.</p>

<p>All the big players such as Google, Microsoft, Facebook, etc., <a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="for knowledge graphs" data-secondary-sortas="knowledge graphs" id="idm45634176076968"/>use knowledge graphs to power their search engines and query services.<sup><a data-type="noteref" id="idm45634176075192-marker" href="ch12.xhtml#idm45634176075192">1</a></sup> And nowadays more and more companies are building their own knowledge graphs to gain market insights or power chatbots. But the <a contenteditable="false" data-type="indexterm" data-primary="Linked Open Data" id="idm45634176072536"/>largest knowledge graph is distributed all over the world: <em>Linked Open Data</em> refers to all the available data on the web that can be <a contenteditable="false" data-type="indexterm" data-primary="URIs (uniform resource identifiers)" id="idm45634176070872"/>identified by a uniform resource identifier (URI). It is the result of 20 years of academic development in the area of the
<!-- <a contenteditable="false" data-type="indexterm" data-primary="Semantic Web">&nbsp;</a>Semantic Web (see <a data-type="xref" href="#semanticwebRDF" data-xrefstyle="select:nopage">#semanticwebRDF</a>).</p> -->
<a contenteditable="false" data-type="indexterm" data-primary="Semantic Web" id="idm45634176068920"/>Semantic Web (see <a data-type="xref" href="#semanticwebRDF">“Semantic Web and RDF”</a>).</p>

<p>The types of nodes and edges are precisely <a contenteditable="false" data-type="indexterm" data-primary="ontology" id="idm45634176066056"/>defined by an <em>ontology</em>, which is itself a knowledge base for the terminology used in a domain. For example, the <a contenteditable="false" data-type="indexterm" data-primary="Wikidata" id="idm45634176064264"/>public ontology Wikidata provides definitions for all types used in <a data-type="xref" href="#fig-simple-kg">Figure 12-1</a>.<sup><a data-type="noteref" id="idm45634176061992-marker" href="ch12.xhtml#idm45634176061992">2</a></sup> Each of these definitions has a unique URI (e.g., “city” is <a href="http://www.wikidata.org/wiki/Q515"><em>http://www.wikidata.org/wiki/Q515</em></a>.). In fact, Wikidata contains both, the type definitions and the actual objects in a queryable <span class="keep-together">format</span>.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="semanticwebRDF">
<h5>Semantic Web and RDF</h5>

<p>The vision of <a contenteditable="false" data-type="indexterm" data-primary="Berners-Lee, Tim" id="idm45634176056664"/>Tim Berners-Lee, who coined the term <em>Semantic Web</em> in 2001, was to make the data on the web understandable to computers.<sup><a data-type="noteref" id="idm45634176054984-marker" href="ch12.xhtml#idm45634176054984">3</a></sup> Today, a lot of knowledge is available in <a contenteditable="false" data-type="indexterm" data-primary="DBpedia" id="idm45634176053288"/><a contenteditable="false" data-type="indexterm" data-primary="Wikipedia articles" id="idm45634176052184"/>public knowledge graphs. For example, <a href="https://wikidata.org">Wikidata</a> and <a href="https://wiki.dbpedia.org">DBpedia</a> are two huge knowledge bases related to <span class="keep-together">Wikipedia</span>. </p>

<p>RDF, the <a contenteditable="false" data-type="indexterm" data-primary="RDF (Resource Description Framework)" id="idm45634176048136"/>resource description framework, is a W3C standard that defines notations for entities and their attributes and relationships. Its intention is to simplify the interlinking of knowledge between knowledge bases. The basic concepts in RDF are <em>resources</em> and <em>statements</em>. The resources are “things” like entities, types, or literal values. A <em>statement</em> is a <a contenteditable="false" data-type="indexterm" data-primary="triple stores for graph databases" id="idm45634176045368"/>subject-predicate-object <em>triple</em> of resources, like <em>Berlin(Q64) capital-of(P1376) Germany(Q183)</em>. The numbers in the example are the unique Wikidata identifiers for the mentioned entities and the relation “capital-of.” Unique identifiers and standardized definitions are the basis to interlink public and private knowledge bases.</p>

<p>Public knowledge bases like Wikidata provide the possibility to <a contenteditable="false" data-type="indexterm" data-primary="SPARQL query language" id="idm45634176042696"/>query their data with SPARQL. SPARQL is an RDF-based query language. You could, for example, visit the Wikidata <a href="https://query.wikidata.org">SPARQL</a> endpoint and request a list of relevant entities for your domain. In the notebook on <a href="https://oreil.ly/FKJ2D">GitHub for this chapter</a>, you will find an additional blueprint that queries the Wikidata SPARQL endpoint. It request the list of all US departments with their alias names and <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term1" id="idm45634176039592"/>returns the result as a Pandas dataframe.</p></div></aside>

<section data-type="sect2" data-pdf-bookmark="Information Extraction"><div class="sect2" id="idm45634176037896">
<h2>Information Extraction</h2>

<p>There are <a contenteditable="false" data-type="indexterm" data-primary="information extraction" id="ch12_term3"/>several typical steps needed to extract structured information from text, as shown in <a data-type="xref" href="#fig-ie">Figure 12-2</a>.
As a <a contenteditable="false" data-type="indexterm" data-primary="named-entity recognition (NER)" id="idm45634176033640"/>first step, <em>named-entity recognition</em>, finds <em>mentions</em> of named entities in the text and labels them with the correct type, e.g., person, organization, or location. The same entity is usually referenced multiple times in a document by different variants of the name or by pronouns. The <a contenteditable="false" data-type="indexterm" data-primary="coreference resolution" id="idm45634176031288"/>second step, <em>coreference resolution</em>, identifies and resolves those <em>coreferences</em> to prevent duplicates and information loss.</p>

<p>Closely related to coreference resolution, and usually the <a contenteditable="false" data-type="indexterm" data-primary="entity linking" id="idm45634176028632"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for entity linking" data-secondary-sortas="entity linking" id="idm45634176027448"/>next step, is the task of <em>entity linking</em>. Here, the goal is to <a contenteditable="false" data-type="indexterm" data-primary="ontology" id="idm45634176025288"/>link a mention in the text to a unique real-world entity in an ontology, for example, <em>Berlin</em> to the URI <a href="http://www.wikidata.org/entity/Q64"><em>http://www.wikidata.org/entity/Q64</em></a>. Thus, any ambiguities are removed: Q64 is the Berlin in Germany and not the one in New Hampshire (which is, by the way, Q821244 in Wikidata). This is essential to connect information from different sources and really build a knowledge base. </p>

<figure><div id="fig-ie" class="figure">
  <img src="Images/btap_1202.jpg" width="1367" height="218"/>
  <h6><span class="label">Figure 12-2. </span>The process of information extraction.</h6></div></figure>

<p>The last <a contenteditable="false" data-type="indexterm" data-primary="relation extraction" id="idm45634176020552"/>step, <em>relation extraction</em>, identifies the relations between those entities. In an application scenario, you will usually consider only a few relations of interest because it is hard to extract this kind of information correctly from arbitrary text. </p>

<p>Finally, you could <a contenteditable="false" data-type="indexterm" data-primary="graph databases" id="idm45634176018184"/>store the graph in a graph database as the backend of a knowledge-based application. Such graph databases store the data either <a contenteditable="false" data-type="indexterm" data-primary="triple stores for graph databases" id="idm45634176016776"/>as RDF triples (<em>triple stores</em>) or in the form of a property graph, where nodes and edges can have arbitrary attributes. Commonly used graph databases are, for example, GraphDB (triple store), Neo4j, and Grakn (property graphs).</p>

<p>For each of the steps, you have the <a contenteditable="false" data-type="indexterm" data-primary="rule-based heuristics for knowledge graphs" id="idm45634176014408"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning models" data-secondary="training of" id="idm45634176013208"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="of machine learning models" data-secondary-sortas="machine learning models" id="idm45634175916104"/>choice between a rule-based approach and machine learning. We will use available models of spaCy and rules in addition. We will not train our own models, though. The usage of rules for the extraction of domain-specific knowledge has the advantage that you can get started quickly without training data. As we will see, the results allow some really interesting analyses. But if you plan to build a corporate knowledge base on a large scale, you may have to train your own models for named-entity and relationship detection as well as for <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term3" id="idm45634175913736"/>entity linking. </p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Introducing the Dataset"><div class="sect1" id="idm45634175912104">
<h1>Introducing the Dataset</h1>

<p>Assume you are working in the financial business and want to track news on mergers and acquisitions. It would be great if you could automatically identify company names and the kind of deals they are involved in and make the results available in a knowledge base. In this chapter, we will explain the building blocks to extract some information about companies. For example, we will extract the relation “Company1 acquires Company2.”</p>

<p>To simulate such a scenario, we <a contenteditable="false" data-type="indexterm" data-primary="datasets, examples of" data-secondary="Reuters News Archive" id="idm45634175909736"/><a contenteditable="false" data-type="indexterm" data-primary="news archives" id="idm45634175908360"/><a contenteditable="false" data-type="indexterm" data-primary="Reuters News Archive" id="idm45634175907256"/>use a publicly available dataset, the well-known <a href="https://oreil.ly/lltWo">Reuters-21578</a> news corpus. It contains more than 20,000 news articles of 90 categories published by Reuters in 1987. This dataset was chosen because it is free and easy to get. In fact, it is available as one of the NLTK standard corpora, and you can simply download it with NLTK:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code> <code class="nn">nltk</code>
<code class="n">nltk</code><code class="o">.</code><code class="n">download</code><code class="p">(</code><code class="s1">'reuters'</code><code class="p">)</code>
</pre>

<p>We will work only with articles from the acquisitions category (acq). To prepare it for our purposes, we loaded all articles into a single <code>DataFrame</code> and did some <a contenteditable="false" data-type="indexterm" data-primary="data cleaning" id="idm45634175897112"/><a contenteditable="false" data-type="indexterm" data-primary="cleaning text data" id="idm45634175896104"/><a contenteditable="false" data-type="indexterm" data-primary="text data preparation" data-secondary="cleaning processes for" id="idm45634175895000"/>data cleaning following the blueprints in <a data-type="xref" href="ch04.xhtml#ch4-cleaning">“Cleaning Text Data”</a>. Clean data is crucial to recognize named-entities and relationships as the neural models benefit from well-structured sentences. For this dataset, we substituted HTML escapes, removed stock ticker symbols, replaced abbreviations like <em>mln</em> for <em>million</em>, and <a contenteditable="false" data-type="indexterm" data-primary="spelling discrepancies" id="idm45634175889032"/>corrected some spelling mistakes. We also dropped the headlines because they are written in capital letters only. The complete article bodies are retained, though. All cleaning steps can be found in the notebook on <a href="https://oreil.ly/21p8d">GitHub</a>. Let’s take a look at a sample of the cleaned articles in our <code>DataFrame</code>:</p>

<pre data-type="programlisting">
USAir Group Inc said a U.S. District Court in Pittsburgh issued a temporary
restraining order to prevent Trans World Airlines Inc from buying additional
USAir shares. USAir said the order was issued in response to its suit, charging
TWA chairman Carl Icahn and TWA violated federal laws and made misleading
statements. TWA last week said it owned 15 % of USAir's shares. It also offered
to buy the company for 52 dollars a share cash or 1.4 billion dollars.
</pre>

<p>So, this is the data we have in mind when we develop the blueprints for information extraction. However, most of the sentences in the following sections are simplified examples to better explain the concepts.</p>

</div></section>

<section data-type="sect1" data-pdf-bookmark="Named-Entity Recognition"><div class="sect1" id="ch12-ner">
<h1>Named-Entity Recognition</h1>

<p>After data cleaning, we can <a contenteditable="false" data-type="indexterm" data-primary="named-entity recognition (NER)" id="ch12_term6"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for named-entity recognition" data-secondary-sortas="named-entity recognition" id="ch12_term7"/>start with the first step of our information extraction process: named-entity recognition.
Named-entity recognition was briefly introduced in <a data-type="xref" href="ch04.xhtml#ch-preparation">Chapter 4</a> as part of spaCy’s standard pipeline. spaCy is our library of choice for all the blueprints in this chapter because it is fast and has an extensible API that we will utilize. But you could also use <a contenteditable="false" data-type="indexterm" data-primary="Stanza" id="idm45634175856568"/><a contenteditable="false" data-type="indexterm" data-primary="Flair" id="idm45634175855560"/>Stanza or Flair (see <a data-type="xref" href="#alts4ner">“Alternatives for NER: Stanza and Flair”</a>). </p>

<p>spaCy provides trained <a contenteditable="false" data-type="indexterm" data-primary="NER types of OntoNotes5 corpus" id="idm45634175853048"/><a contenteditable="false" data-type="indexterm" data-primary="OntoNotes5 corpus" id="idm45634175851944"/>NER models for many languages. The English models have been trained on the large <a href="https://oreil.ly/gyOiH">OntoNotes5 corpus</a> containing 18 different entity types. <a data-type="xref" href="#tab-ner-types">Table 12-1</a> lists a subset of these. The remaining types are for numeric entities.</p>

<table id="tab-ner-types"><caption><span class="label">Table 12-1. </span>Subset of NER types of the OntoNotes 5 corpus</caption><thead>
<tr>
<th>NER Type</th>
<th>Description</th>
<th>NER Type</th>
<th>Description</th></tr>
</thead>
<tbody>
<tr>
<td>PERSON</td>
<td>People, including fictional</td>
<td>PRODUCT</td>
<td>Vehicles, weapons, foods, etc. (Not services)</td></tr>
<tr>
<td>NORP</td>
<td>Nationalities or religious or political groups</td>
<td>EVENT</td>
<td>Named hurricanes, battles, wars, sports events, etc.</td></tr>
<tr>
<td>FAC</td>
<td>Facilities: buildings, airports, highways, bridges, etc.</td>
<td>WORK_OF_ART</td>
<td>Titles of books, songs, etc.</td></tr>
<tr>
<td>ORG</td>
<td>Organizations: companies, agencies, institutions, etc.</td>
<td>LAW</td>
<td>Named documents made into laws</td></tr>
<tr>
<td>GPE</td>
<td>Countries, cities, states</td>
<td>LANGUAGE</td>
<td>Any named language</td></tr>
<tr>
<td>LOCATION</td>
<td>Non-GPE locations, mountain ranges, bodies of water</td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>

<p>The NER tagger is enabled by default when you load a language model. Let’s start by initializing an <code>nlp</code> object with the standard (small) English model <code>en_core_web_sm</code> and print the components of the NLP pipeline:<sup><a data-type="noteref" id="idm45634175830936-marker" href="ch12.xhtml#idm45634175830936">4</a></sup> </p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">nlp</code> <code class="o">=</code> <code class="n">spacy</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="s1">'en_core_web_sm'</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="n">nlp</code><code class="o">.</code><code class="n">pipeline</code><code class="p">,</code> <code class="n">sep</code><code class="o">=</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
('tagger', &lt;spacy.pipeline.pipes.Tagger object at 0x7f98ac6443a0&gt;)
('parser', &lt;spacy.pipeline.pipes.DependencyParser object at 0x7f98ac7a07c0&gt;)
('ner', &lt;spacy.pipeline.pipes.EntityRecognizer object at 0x7f98ac7a0760&gt;)
</pre>

<p>Once the text is processed, we can access the named entities directly with <code>doc.ents</code>. Each entity has a text and a label describing the entity type. These attributes are used in the last line in the following code to print the list of entities recognized in this text:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="s2">"""Hughes Tool Co Chairman W.A. Kistler said its merger with</code>
<code class="s2">Baker International Corp was still under consideration.</code>
<code class="s2">We hope to come soon to a mutual agreement, Kistler said.</code>
<code class="s2">The directors of Baker filed a law suit in Texas to force Hughes</code>
<code class="s2">to complete the merger."""</code>
<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>

<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="p">[(</code><code class="n">e</code><code class="o">.</code><code class="n">text</code><code class="p">,</code> <code class="n">e</code><code class="o">.</code><code class="n">label_</code><code class="p">)</code> <code class="k">for</code> <code class="n">e</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">ents</code><code class="p">],</code> <code class="n">sep</code><code class="o">=</code><code class="s1">' '</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
(Hughes Tool Co, ORG) (W.A. Kistler, PERSON) (Baker International Corp, ORG)
(Kistler, ORG) (Baker, PERSON) (Texas, GPE) (Hughes, ORG)
</pre>

<p>With spaCy’s neat <a contenteditable="false" data-type="indexterm" data-primary="displacy (spaCy)" id="idm45634175733416"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="visualizations for" id="idm45634175732312"/><a contenteditable="false" data-type="indexterm" data-primary="visualization of data" data-secondary="with knowledge graphs" data-secondary-sortas="knowledge graphs" id="idm45634175730968"/><a contenteditable="false" data-type="indexterm" data-primary="visualization of data" data-secondary="with spaCy displacy module" data-secondary-sortas="spaCy displacy module" id="idm45634175729320"/>visualization module <code>displacy</code>, we can generate a visual representation of the sentence and its named entities. This is helpful to inspect the result:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">spacy</code> <code class="kn">import</code> <code class="n">displacy</code>
<code class="n">displacy</code><code class="o">.</code><code class="n">render</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">style</code><code class="o">=</code><code class="s1">'ent'</code><code class="p">)</code>
</pre>

<p class="pagebreak-before"><code>Out:</code></p>

<figure><div class="figure">
<img src="Images/btap_12in01.jpg" width="1259" height="180"/>
<h6/>
</div></figure>

<p>In general, spaCy’s named-entity recognizer does a good job. In our example, it was able to detect all named entities. The labels of <em>Kistler</em> and <em>Baker</em> in the second and third sentence, however, are not correct. In fact, distinguishing between persons and organizations is quite a challenge for NER models because those entity types are used very similarly. We will resolve such problems later in the blueprint for name-based coreference resolution.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="alts4ner">
<h5>Alternatives for NER: Stanza and Flair</h5>

<p>Previously known as <a contenteditable="false" data-type="indexterm" data-primary="Stanza" id="idm45634175680760"/><a contenteditable="false" data-type="indexterm" data-primary="Stanford University" id="idm45634175679624"/>StanfordNLP, <a href="https://oreil.ly/MupNu">Stanza 1.0.0</a> was released in March 2020. Similar to spaCy, it was designed to support many languages in a coherent way. It also includes a Python API for additional linguistic functions in the well-known CoreNLP Java package.</p>

<p>Stanza’s API is very similar to spaCy’s. Even better, the <a href="https://oreil.ly/2Q2E1"><code>spacy_stanza</code> library</a>, which is officially maintained by spaCy’s development team from Explosion, provides a wrapper for the Stanza NLP pipeline. So, you can use the spaCy-based blueprints of this chapter and still leverage the models of Stanza if you want. As of the time of writing this book, Stanza’s English models are more accurate than the models of spaCy 2.3.2 in our example. But they are huge in size and therefore much slower. The models in spaCy 3.0 are reported to be as accurate as Stanza’s and significantly faster. </p>

<p>Another popular <a contenteditable="false" data-type="indexterm" data-primary="Flair" id="idm45634175675112"/>NLP library with excellent NER models is <a href="https://oreil.ly/hKFSk">Flair</a>. Flair was developed by people from Humboldt University in Berlin and Zalando Research and is now part of the <a contenteditable="false" data-type="indexterm" data-primary="PyTorch" id="idm45634175673032"/>PyTorch ecosystem. It is definitely worth checking out.</p></div></aside>

<section data-type="sect2" class="blueprint" data-pdf-bookmark="Blueprint: Using Rule-Based Named-Entity Recognition"><div class="sect2" id="idm45634175671672">
<h2>Blueprint: Using Rule-Based Named-Entity Recognition</h2>

<p>If you want to identify domain-specific entities on which the model has not been trained, you can of course train your own model with <a href="https://oreil.ly/6EMig">spaCy</a>. But training a  model requires a lot of training data. Often it is sufficient to <a contenteditable="false" data-type="indexterm" data-primary="rule-based heuristics for knowledge graphs" id="ch12_term9"/><a contenteditable="false" data-type="indexterm" data-primary="rule-based named-entity recognition" id="ch12_term10"/>specify simple rules for custom entity types. In this <span class="keep-together">section</span>, we will show how to use rules to detect government organizations like the “Department of Justice” (or alternatively the “Justice Department”) in the Reuters dataset.</p>

<p>spaCy <a contenteditable="false" data-type="indexterm" data-primary="EntityRuler (spaCy)" id="idm45634175648968"/>provides an <a href="https://oreil.ly/A6MZ8"><code>EntityRuler</code></a> for this purpose, a pipeline component that can be used in combination with or instead of the statistical named-entity recognizer. Compared to regular expression search, <a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="tokenizers for" id="idm45634175646632"/><a contenteditable="false" data-type="indexterm" data-primary="tokenization/tokens" data-secondary="in spaCy linguistic processing" data-secondary-sortas="spaCy linguistic processing" id="idm45634175645320"/><a contenteditable="false" data-type="indexterm" data-primary="tokenization/tokens" data-secondary="in named-entity recognition" data-secondary-sortas="named-entity recognition" id="idm45634175643736"/>spaCy’s matching engine is more powerful because patterns are defined on sequences of spaCy’s tokens instead of just strings. Thus, you can use any token property like the lemma or the part-of-speech tag to build your patterns. </p>

<p>So, let’s define some pattern rules to match departments of the US government and the “Securities and Exchange Commission,” which is frequently mentioned in our corpus:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">spacy.pipeline</code> <code class="kn">import</code> <code class="n">EntityRuler</code>

<code class="n">departments</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'Justice'</code><code class="p">,</code> <code class="s1">'Transportation'</code><code class="p">]</code>
<code class="n">patterns</code> <code class="o">=</code> <code class="p">[{</code><code class="s2">"label"</code><code class="p">:</code> <code class="s2">"GOV"</code><code class="p">,</code>
             <code class="s2">"pattern"</code><code class="p">:</code> <code class="p">[{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="s2">"U.S."</code><code class="p">,</code> <code class="s2">"OP"</code><code class="p">:</code> <code class="s2">"?"</code><code class="p">},</code>
                         <code class="p">{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="s2">"Department"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="s2">"of"</code><code class="p">},</code>
                         <code class="p">{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="p">{</code><code class="s2">"IN"</code><code class="p">:</code> <code class="n">departments</code><code class="p">},</code> <code class="s2">"ENT_TYPE"</code><code class="p">:</code> <code class="s2">"ORG"</code><code class="p">}]},</code>
             <code class="p">{</code><code class="s2">"label"</code><code class="p">:</code> <code class="s2">"GOV"</code><code class="p">,</code>
              <code class="s2">"pattern"</code><code class="p">:</code> <code class="p">[{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="s2">"U.S."</code><code class="p">,</code> <code class="s2">"OP"</code><code class="p">:</code> <code class="s2">"?"</code><code class="p">},</code>
                          <code class="p">{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="p">{</code><code class="s2">"IN"</code><code class="p">:</code> <code class="n">departments</code><code class="p">},</code> <code class="s2">"ENT_TYPE"</code><code class="p">:</code> <code class="s2">"ORG"</code><code class="p">},</code>
                          <code class="p">{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="s2">"Department"</code><code class="p">}]},</code>
             <code class="p">{</code><code class="s2">"label"</code><code class="p">:</code> <code class="s2">"GOV"</code><code class="p">,</code>
              <code class="s2">"pattern"</code><code class="p">:</code> <code class="p">[{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="s2">"Securities"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="s2">"and"</code><code class="p">},</code>
                          <code class="p">{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="s2">"Exchange"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"TEXT"</code><code class="p">:</code> <code class="s2">"Commission"</code><code class="p">}]}]</code>
</pre>

<p>Each rule consists of a dictionary with a label, in our case the custom entity type <code>GOV</code>, and a pattern that the token sequence must match. You can specify multiple rules for the same label, as we did here.<sup><a data-type="noteref" id="idm45634175637736-marker" href="ch12.xhtml#idm45634175637736">5</a></sup> The first rule, for example, matches sequences of tokens with the texts <code>"U.S."</code> (optional, denoted by <code>"OP": "?"</code>), <code>"Department"</code>, <code>"of"</code>, and either <code>"Justice"</code> or <code>"Transportation"</code>. Note that this and the second rule refine already recognized entities of type <code>ORG</code>. Thus, these patterns must be applied on top and not instead of spaCy’s named-entity model.</p>

<p>Based on these patterns, we create an <code>EntityRuler</code> and add it to our pipeline:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">entity_ruler</code> <code class="o">=</code> <code class="n">EntityRuler</code><code class="p">(</code><code class="n">nlp</code><code class="p">,</code> <code class="n">patterns</code><code class="o">=</code><code class="n">patterns</code><code class="p">,</code> <code class="n">overwrite_ents</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">nlp</code><code class="o">.</code><code class="n">add_pipe</code><code class="p">(</code><code class="n">entity_ruler</code><code class="p">)</code>
</pre>

<p>Now, when we call <code>nlp</code>, those organizations will automatically be labeled with the new type <code>GOV</code>:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="s2">"""Justice Department is an alias for the U.S. Department of Justice.</code>
<code class="s2">Department of Transportation and the Securities and Exchange Commission</code>
<code class="s2">are government organisations, but the Sales Department is not."""</code>

<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="n">displacy</code><code class="o">.</code><code class="n">render</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">style</code><code class="o">=</code><code class="s1">'ent'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<figure><div class="figure">
<img src="Images/btap_12in02.jpg" width="1047" height="189"/>
<h6/>
</div></figure>

</div></section>

<section data-type="sect2" class="blueprint" data-pdf-bookmark="Blueprint: Normalizing Named Entities"><div class="sect2" id="idm45634175671080">
<h2>Blueprint: Normalizing Named Entities</h2>

<p>One approach <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term9" id="idm45634175387736"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term10" id="idm45634175386328"/>to simplify the resolution of different entity mentions to a <a contenteditable="false" data-type="indexterm" data-primary="normalization of text" id="ch12_term12"/><a contenteditable="false" data-type="indexterm" data-primary="prefixes in text analysis" id="ch12_term13"/><a contenteditable="false" data-type="indexterm" data-primary="suffixes in text analysis" id="ch12_term14"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for normalizing named entities" data-secondary-sortas="normalizing named entities" id="ch12_term15"/>single name is the normalization or standardization of mentions. Here, we will do a first normalization, which is generally helpful: the removal of unspecific suffixes and prefixes. Take a look at this example:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="s2">"Baker International's shares climbed on the New York Stock Exchange."</code>

<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="p">[([</code><code class="n">t</code><code class="o">.</code><code class="n">text</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">e</code><code class="p">],</code> <code class="n">e</code><code class="o">.</code><code class="n">label_</code><code class="p">)</code> <code class="k">for</code> <code class="n">e</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">ents</code><code class="p">],</code> <code class="n">sep</code><code class="o">=</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
(['Baker', 'International', "'s"], 'ORG')
(['the', 'New', 'York', 'Stock', 'Exchange'], 'ORG')
</pre>

<p>In the first sentence, the token sequence <code>Baker International's</code> was detected as an entity even though the genitive-s is not part of the company name. A similar case is the article in <code>the New York Stock Exchange</code>.  Regardless of whether the article is actually part of the name or not, entities will likely be referenced sometimes with and sometimes without the article. Thus, the general removal of the article and an apostrophe-s  simplifies the linking of mentions. </p>

<div data-type="warning" epub:type="warning"><h6>Warning</h6>

<p>As with any rules, there is a potential of errors: think of <code>The Wall Street Journal</code> or <code>McDonald's</code>. If you need to preserve the article or the apostrophe-s in such cases, you must define exceptions for the rules. </p></div>

<p>Our blueprint function shows how to implement normalizations such as removing a leading article and a trailing apostrophe-s in spaCy. As we are not allowed to update entities in place, we create a copy of the entities and apply our modifications to this copy:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">spacy.tokens</code> <code class="kn">import</code> <code class="n">Span</code>

<code class="k">def</code> <code class="nf">norm_entities</code><code class="p">(</code><code class="n">doc</code><code class="p">):</code>
    <code class="n">ents</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="k">for</code> <code class="n">ent</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">ents</code><code class="p">:</code>
        <code class="k">if</code> <code class="n">ent</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">pos_</code> <code class="o">==</code> <code class="s2">"DET"</code><code class="p">:</code> <code class="c1"># leading article</code>
            <code class="n">ent</code> <code class="o">=</code> <code class="n">Span</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">ent</code><code class="o">.</code><code class="n">start</code><code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="n">ent</code><code class="o">.</code><code class="n">end</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="n">ent</code><code class="o">.</code><code class="n">label</code><code class="p">)</code>
        <code class="k">if</code> <code class="n">ent</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">pos_</code> <code class="o">==</code> <code class="s2">"PART"</code><code class="p">:</code> <code class="c1"># trailing particle like 's</code>
            <code class="n">ent</code> <code class="o">=</code> <code class="n">Span</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">ent</code><code class="o">.</code><code class="n">start</code><code class="p">,</code> <code class="n">ent</code><code class="o">.</code><code class="n">end</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="n">ent</code><code class="o">.</code><code class="n">label</code><code class="p">)</code>
        <code class="n">ents</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">ent</code><code class="p">)</code>
    <code class="n">doc</code><code class="o">.</code><code class="n">ents</code> <code class="o">=</code> <code class="nb">tuple</code><code class="p">(</code><code class="n">ents</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">doc</code>
</pre>

<p>An entity in <a contenteditable="false" data-type="indexterm" data-primary="Span objects" id="idm45634175311816"/>spaCy is a <code>Span</code> object with a defined start and end plus an additional label denoting the type of the entity. We loop through the entities and <a contenteditable="false" data-type="indexterm" data-primary="tokenization/tokens" data-secondary="in named-entity recognition" data-secondary-sortas="named-entity recognition" id="idm45634175186504"/>adjust the position of the first and last token of the entity if necessary. Finally, we replace <code>doc.ents</code> with our modified copy.</p>

<p>The function takes a spaCy <code>Doc</code> object (named <code>doc</code>) as a parameter and returns a <code>Doc</code>. Therefore, we can use it as a another pipeline component and simply add it to the existing pipeline:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">nlp</code><code class="o">.</code><code class="n">add_pipe</code><code class="p">(</code><code class="n">norm_entities</code><code class="p">)</code>
</pre>

<p>Now we can repeat the process on the example sentences and <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term12" id="idm45634175178184"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term13" id="idm45634181296344"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term14" id="idm45634181294968"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term15" id="idm45634181293592"/>check the result:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="p">[([</code><code class="n">t</code><code class="o">.</code><code class="n">text</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">e</code><code class="p">],</code> <code class="n">e</code><code class="o">.</code><code class="n">label_</code><code class="p">)</code> <code class="k">for</code> <code class="n">e</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">ents</code><code class="p">],</code> <code class="n">sep</code><code class="o">=</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
(['Baker', 'International'], 'ORG')
(['New', 'York', 'Stock', 'Exchange'], 'ORG')
</pre>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Merging Entity Tokens"><div class="sect2" id="idm45634175389080">
<h2>Merging Entity Tokens</h2>

<p>In many cases, it makes sense to treat <a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for merging entities" data-secondary-sortas="merging entities" id="idm45634175058824"/><a contenteditable="false" data-type="indexterm" data-primary="compound phrases/names" id="idm45634175057208"/>compound names like the ones from the previous example as single tokens because it simplifies the sentence structure. spaCy provides a <a contenteditable="false" data-type="indexterm" data-primary="merge_entity function (spaCy)" id="idm45634175055832"/>built-in pipeline function <code>merge_entities</code> for that purpose. We add it to our NLP pipeline and get exactly one token per named-entity:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">spacy.pipeline</code> <code class="kn">import</code> <code class="n">merge_entities</code>
<code class="n">nlp</code><code class="o">.</code><code class="n">add_pipe</code><code class="p">(</code><code class="n">merge_entities</code><code class="p">)</code>

<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="p">[(</code><code class="n">t</code><code class="o">.</code><code class="n">text</code><code class="p">,</code> <code class="n">t</code><code class="o">.</code><code class="n">ent_type_</code><code class="p">)</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">doc</code> <code class="k">if</code> <code class="n">t</code><code class="o">.</code><code class="n">ent_type_</code> <code class="o">!=</code> <code class="s1">''</code><code class="p">])</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
('Baker International', 'ORG') ('New York Stock Exchange', 'ORG')
</pre>

<p>Even though merging entities simplifies our blueprints later in this chapter, it may not always be a good idea. Think, for example, about compound entity names like <code>London Stock Exchange</code>. After merging into a single token, the implicit relation of this entity to the <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term6" id="idm45634174980920"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term7" id="idm45634174979544"/>city of London will be lost.</p>

</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Coreference Resolution"><div class="sect1" id="idm45634175883880">
<h1>Coreference Resolution</h1>

<p>One of the greatest <a contenteditable="false" data-type="indexterm" data-primary="coreference resolution" id="ch12_term16"/>obstacles in information extraction is the fact that entity mentions appear in many <a contenteditable="false" data-type="indexterm" data-primary="spelling discrepancies" id="idm45634174975144"/>different spellings (also called <em>surface forms</em>). Look at the following sentences:</p>

<blockquote>
  <p>Hughes Tool Co Chairman W.A. Kistler said its merger with Baker International Corp. was still under consideration. We hope to come to a mutual agreement, Kistler said. Baker will force Hughes to complete the merger. A review by the U.S. Department of Justice was completed today. The Justice Department will block the merger after consultation with the SEC.</p>
</blockquote>

<p>As we can see, entities are frequently introduced by their full name, while later mentions use abbreviated versions. This is one type of coreference that must resolved to understand what’s going on.
<a data-type="xref" href="#fig-cooc-baker-hughes">Figure 12-3</a> shows a <a contenteditable="false" data-type="indexterm" data-primary="co-occurrence graphs" id="idm45634174970664"/>co-occurrence graph without (left) and with (right) unified names. Such a co-occurrence graph, as we will build in the next section, is a visualization of entity pairs appearing in the same article.</p>

<figure><div id="fig-cooc-baker-hughes" class="figure">
<img src="Images/btap_1203.jpg" width="1405" height="495"/>
<h6><span class="label">Figure 12-3. </span>A co-occurrence graph of the same articles before (left) and after coreference resolution (right).</h6></div></figure>

<p><em>Coreference resolution</em> is the task of determining the different mentions of an entity within a single text, for example, abbreviated names, aliases, or pronouns. The result of this step is a <a contenteditable="false" data-type="indexterm" data-primary="mention clusters" id="idm45634174966648"/>group of coreferencing mentions called a <em>mention cluster</em>, for example, <code>{Hughes Tool Co, Hughes, its}</code>. Our target in this section is to identify related mentions and link them within a document.</p>

<p>For this purpose, we develop a couple of blueprints for coreference resolution and name unification (see <a data-type="xref" href="#fig-coref-pipeline">Figure 12-4</a>). We will restrict ourselves to organizations and persons, as these are the entity types we are interested in. First, we will <a contenteditable="false" data-type="indexterm" data-primary="aliases, resolution of" id="idm45634174962600"/>resolve aliases like <em>SEC</em> by a dictionary lookup. Then we will match names within a document to the first mention. For example, we will create a link from “Kistler” to “W.A. Kistler.” After that, indirect <a contenteditable="false" data-type="indexterm" data-primary="indirect references, resolution of" id="idm45634174960712"/><a contenteditable="false" data-type="indexterm" data-primary="anaphora, resolution of" id="idm45634174959640"/>references (<em>anaphora</em>) like the pronoun <em>its</em> in the first sentence will be resolved. Finally, we will <a contenteditable="false" data-type="indexterm" data-primary="normalization of text" id="idm45634174957512"/>normalize again the names of the resolved entities. All of these steps will be implemented as additional pipeline functions. </p>

<figure><div id="fig-coref-pipeline" class="figure">
<img src="Images/btap_1204.jpg" width="1357" height="171"/>
<h6><span class="label">Figure 12-4. </span>Pipeline for named-entity recognition and coreference resolution.</h6></div></figure>

<p><em>Entity linking</em> goes <a contenteditable="false" data-type="indexterm" data-primary="entity linking" id="idm45634174954024"/>one step further. Here the mentions of an entity are disambiguated on a semantic level and linked to a unique entry in an existing knowledge base. Because entity linking is itself a challenging task, we will not provide a blueprint for that but just discuss it at the end of this section.</p>

<section data-type="sect2" class="blueprint" data-pdf-bookmark="Blueprint: Using spaCy’s Token Extensions"><div class="sect2" id="idm45634174952328">
  <h2>Blueprint: Using spaCy’s Token Extensions</h2>

<p>We need a way to <a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for entity linking" data-secondary-sortas="entity linking" id="idm45634174927992"/><a contenteditable="false" data-type="indexterm" data-primary="extensions (spaCy)" id="idm45634174926424"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="extensions for" id="idm45634174925288"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="tokenizers for" id="idm45634174923944"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for coreference resolution" data-secondary-sortas="coreference resolution" id="idm45634174922552"/><a contenteditable="false" data-type="indexterm" data-primary="tokenization/tokens" data-secondary="for coreference resolution" data-secondary-sortas="coreference resolution" id="idm45634174920872"/><a contenteditable="false" data-type="indexterm" data-primary="tokenization/tokens" data-secondary="in spaCy linguistic processing" data-secondary-sortas="spaCy linguistic processing" id="idm45634174919208"/>technically create the link from the different mentions of an entity to the main reference, the <em>referent</em>. After coreference resolution, the token for “Kistler” of the example article should point to “(W.A. Kistler, PERSON).” spaCy’s extension mechanism allows us to define custom attributes, and this is the perfect way to store this kind of information with tokens. Thus, we create <a contenteditable="false" data-type="indexterm" data-primary="ref_n and ref_t spaCy extensions" id="ch12_term18"/>two token extensions <code>ref_n</code> (referent’s name) and <code>ref_t</code> (referent’s type). The attributes will be initialized for each token with the specified default values by spaCy for each token:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">spacy.tokens</code> <code class="kn">import</code> <code class="n">Token</code>
<code class="n">Token</code><code class="o">.</code><code class="n">set_extension</code><code class="p">(</code><code class="s1">'ref_n'</code><code class="p">,</code> <code class="n">default</code><code class="o">=</code><code class="s1">''</code><code class="p">)</code>
<code class="n">Token</code><code class="o">.</code><code class="n">set_extension</code><code class="p">(</code><code class="s1">'ref_t'</code><code class="p">,</code> <code class="n">default</code><code class="o">=</code><code class="s1">''</code><code class="p">)</code>
</pre>

<p>The function <code>init_coref</code> shown next ensures that each entity mention of type <code>ORG</code>, <code>GOV</code>, and <code>PERSON</code> gets an initial reference to itself. This initialization is required for the succeeding functions:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">init_coref</code><code class="p">(</code><code class="n">doc</code><code class="p">):</code>
    <code class="k">for</code> <code class="n">e</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">ents</code><code class="p">:</code>
        <code class="k">if</code> <code class="n">e</code><code class="o">.</code><code class="n">label_</code> <code class="ow">in</code> <code class="p">[</code><code class="s1">'ORG'</code><code class="p">,</code> <code class="s1">'GOV'</code><code class="p">,</code> <code class="s1">'PERSON'</code><code class="p">]:</code>
            <code class="n">e</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code><code class="p">,</code> <code class="n">e</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code> <code class="o">=</code> <code class="n">e</code><code class="o">.</code><code class="n">text</code><code class="p">,</code> <code class="n">e</code><code class="o">.</code><code class="n">label_</code>
    <code class="k">return</code> <code class="n">doc</code>
</pre>

<p>The custom attributes are accessed via the underscore property of the token. Note that <a contenteditable="false" data-type="indexterm" data-primary="merge_entity function (spaCy)" id="idm45634174889576"/>after <code>merge_entities</code>, each entity mention <code>e</code> consists of a single token <code>e[0]</code> where we set the attributes. We could also define the attributes on the entity spans instead of tokens, but we want to use the same mechanism for pronoun resolution later.</p>
</div></section>

<section data-type="sect2" class="blueprint" data-pdf-bookmark="Blueprint: Performing Alias Resolution"><div class="sect2" id="idm45634174797848">
<h2>Blueprint: Performing Alias Resolution</h2>

<p>Our first targets are well-known domain <a contenteditable="false" data-type="indexterm" data-primary="aliases, resolution of" id="ch12_term19"/><a contenteditable="false" data-type="indexterm" data-primary="acronyms, resolution of" id="ch12_term21"/>aliases like <em>Transportation Department</em> for “U.S. Department of Transportation” and acronyms like SEC or TWA. A simple solution to resolve such aliases is to use a lookup dictionary. We prepared such a dictionary for all the acronyms and some common aliases of the Reuters corpus and provided it as part of the blueprints module for this chapter.<sup><a data-type="noteref" id="idm45634174792232-marker" href="ch12.xhtml#idm45634174792232">6</a></sup> Here are some example lookups:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">blueprints.knowledge</code> <code class="kn">import</code> <code class="n">alias_lookup</code>

<code class="k">for</code> <code class="n">token</code> <code class="ow">in</code> <code class="p">[</code><code class="s1">'Transportation Department'</code><code class="p">,</code> <code class="s1">'DOT'</code><code class="p">,</code> <code class="s1">'SEC'</code><code class="p">,</code> <code class="s1">'TWA'</code><code class="p">]:</code>
    <code class="k">print</code><code class="p">(</code><code class="n">token</code><code class="p">,</code> <code class="s1">':'</code><code class="p">,</code> <code class="n">alias_lookup</code><code class="p">[</code><code class="n">token</code><code class="p">])</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Transportation Department : ('U.S. Department of Transportation', 'GOV')
DOT : ('U.S. Department of Transportation', 'GOV')
SEC : ('Securities and Exchange Commission', 'GOV')
TWA : ('Trans World Airlines Inc', 'ORG')
</pre>

<p>Each token alias is mapped to a tuple consisting of an entity name and a type. The function <code>alias_resolver</code> shown next checks whether an entity’s text is found in the dictionary. If so, its <code>ref</code> attributes are updated to the looked-up value:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">alias_resolver</code><code class="p">(</code><code class="n">doc</code><code class="p">):</code>
    <code class="sd">"""Lookup aliases and store result in ref_t, ref_n"""</code>
    <code class="k">for</code> <code class="n">ent</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">ents</code><code class="p">:</code>
        <code class="n">token</code> <code class="o">=</code> <code class="n">ent</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">text</code>
        <code class="k">if</code> <code class="n">token</code> <code class="ow">in</code> <code class="n">alias_lookup</code><code class="p">:</code>
            <code class="n">a_name</code><code class="p">,</code> <code class="n">a_type</code> <code class="o">=</code> <code class="n">alias_lookup</code><code class="p">[</code><code class="n">token</code><code class="p">]</code>
            <code class="n">ent</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code><code class="p">,</code> <code class="n">ent</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code> <code class="o">=</code> <code class="n">a_name</code><code class="p">,</code> <code class="n">a_type</code>
    <code class="k">return</code> <code class="n">propagate_ent_type</code><code class="p">(</code><code class="n">doc</code><code class="p">)</code>
</pre>

<p>Once we have resolved the aliases, we can also correct the type of the named-entity in case it was misidentified. This is done by the function <code>propagate_ent_type</code>. It updates all resolved aliases and will also be used in the next blueprint for name-based coreference resolution:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">propagate_ent_type</code><code class="p">(</code><code class="n">doc</code><code class="p">):</code>
    <code class="sd">"""propagate entity type stored in ref_t"""</code>
    <code class="n">ents</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="k">for</code> <code class="n">e</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">ents</code><code class="p">:</code>
        <code class="k">if</code> <code class="n">e</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code> <code class="o">!=</code> <code class="s1">''</code><code class="p">:</code> <code class="c1"># if e is a coreference</code>
            <code class="n">e</code> <code class="o">=</code> <code class="n">Span</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">e</code><code class="o">.</code><code class="n">start</code><code class="p">,</code> <code class="n">e</code><code class="o">.</code><code class="n">end</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="n">e</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code><code class="p">)</code>
        <code class="n">ents</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">e</code><code class="p">)</code>
    <code class="n">doc</code><code class="o">.</code><code class="n">ents</code> <code class="o">=</code> <code class="nb">tuple</code><code class="p">(</code><code class="n">ents</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">doc</code>
</pre>

<p>Again, we add the <code>alias_resolver</code> to our pipeline:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">nlp</code><code class="o">.</code><code class="n">add_pipe</code><code class="p">(</code><code class="n">alias_resolver</code><code class="p">)</code>
</pre>

<p>Now we can inspect the results. For this purpose, our <a contenteditable="false" data-type="indexterm" data-primary="display_ner function" id="idm45634174535208"/>provided blueprints package includes a utility function <code>display_ner</code> that creates a <code>DataFrame</code> for the tokens in a <code>doc</code> object with the relevant attributes for this chapter: </p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">blueprints.knowledge</code> <code class="kn">import</code> <code class="n">display_ner</code>
<code class="n">text</code> <code class="o">=</code> <code class="s2">"""The deal of Trans World Airlines is under investigation by the</code>
<code class="s2">U.S. Department of Transportation.</code>
<code class="s2">The Transportation Department will block the deal of TWA."""</code>
<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="n">display_ner</code><code class="p">(</code><code class="n">doc</code><code class="p">)</code><code class="o">.</code><code class="n">query</code><code class="p">(</code><code class="s2">"ref_n != ''"</code><code class="p">)[[</code><code class="s1">'text'</code><code class="p">,</code> <code class="s1">'ent_type'</code><code class="p">,</code> <code class="s1">'ref_n'</code><code class="p">,</code> <code class="s1">'ref_t'</code><code class="p">]]</code>
</pre>

<p><code>Out:</code></p>

<table class="dataframe tex2jax_ignore">
  <thead>
    <tr>
      <th/>
      <th>text</th>
      <th>ent_type</th>
      <th>ref_n</th>
      <th>ref_t</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>Trans World Airlines</td>
      <td>ORG</td>
      <td>Trans World Airlines Inc</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>9</th>
      <td>U.S. Department of Transportation</td>
      <td>GOV</td>
      <td>U.S. Department of Transportation</td>
      <td>GOV</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Transportation Department</td>
      <td>GOV</td>
      <td>U.S. Department of Transportation</td>
      <td>GOV</td>
    </tr>
    <tr>
      <th>18</th>
      <td>TWA</td>
      <td>ORG</td>
      <td>Trans World Airlines Inc</td>
      <td>ORG</td>
    </tr>
  </tbody>
</table>

</div></section>

<section data-type="sect2" class="blueprint" data-pdf-bookmark="Blueprint: Resolving Name Variations"><div class="sect2" id="idm45634174797224">
<h2>Blueprint: Resolving Name Variations</h2>

<p>Alias resolution works only if the aliases are known up front. But because articles contain variations of almost any names, it is not feasible to build a dictionary for <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term19" id="idm45634174421784"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term21" id="idm45634174420408"/>all of them. Take a look again at the recognized named entities in the first sentences of our introductory example:</p>

<figure><div class="figure">
<img src="Images/btap_12in03.jpg" width="1264" height="180"/>
<h6/>
</div></figure>

<p>Here you find the coreference “Kistler” for W.A. Kistler (<code>PERSON</code>), “Baker” for Baker International Corp (<code>ORG</code>), and “Hughes” for Hughes Tool Co (<code>ORG</code>). And as you can see, abbreviated company names are often mistaken for people, especially when they are used in impersonated form, as in the examples. In this blueprint, we will resolve those coreferences and assign the correct entity types to each mention.</p>

<p>For that, we will exploit a common pattern in news articles. An entity is usually introduced first by its full name, while later mentions use abbreviated versions. Thus, we will resolve the secondary references by matching the names to the first mention of an entity. Of course, <a contenteditable="false" data-type="indexterm" data-primary="rule-based heuristics for knowledge graphs" id="idm45634174414840"/>this is a heuristic rule that could produce false matches. For example, <em>Hughes</em> could also refer in the same article to the company and to the legendary entrepreneur Howard Hughes (who indeed founded Hughes Tool Co.). But such cases are rare in our dataset, and we decide to accept that uncertainty in favor of the many cases where our heuristics works correctly.</p>

<p>We define a simple rule for name matching: a secondary mention matches a primary mention if all of its words appear in the primary mention in the same order. To check this, the function <code>name_match</code> shown next transforms a secondary mention <code>m2</code> into a regular expression and searches for a match in the primary mention <code>m1</code>: </p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">name_match</code><code class="p">(</code><code class="n">m1</code><code class="p">,</code> <code class="n">m2</code><code class="p">):</code>
    <code class="n">m2</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">sub</code><code class="p">(</code><code class="s-Affix">r</code><code class="s1">'[()\.]'</code><code class="p">,</code> <code class="s1">''</code><code class="p">,</code> <code class="n">m2</code><code class="p">)</code> <code class="c1"># ignore parentheses and dots</code>
    <code class="n">m2</code> <code class="o">=</code> <code class="s-Affix">r</code><code class="s1">'\b'</code> <code class="o">+</code> <code class="n">m2</code> <code class="o">+</code> <code class="s-Affix">r</code><code class="s1">'\b'</code> <code class="c1"># \b marks word boundary</code>
    <code class="n">m2</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">sub</code><code class="p">(</code><code class="s-Affix">r</code><code class="s1">'\s+'</code><code class="p">,</code> <code class="s-Affix">r</code><code class="s1">'</code><code class="se">\\</code><code class="s1">b.*</code><code class="se">\\</code><code class="s1">b'</code><code class="p">,</code> <code class="n">m2</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">re</code><code class="o">.</code><code class="n">search</code><code class="p">(</code><code class="n">m2</code><code class="p">,</code> <code class="n">m1</code><code class="p">,</code> <code class="n">flags</code><code class="o">=</code><code class="n">re</code><code class="o">.</code><code class="n">I</code><code class="p">)</code> <code class="ow">is</code> <code class="ow">not</code> <code class="bp">None</code>
</pre>

<p>The secondary mention of Hughes Co., for example, would be converted into <code>'\bHughes\b.*\bCo\b'</code>, which matches Hughes Tool Co. The <code>\b</code> ensures that only whole words match and not subwords like <em>Hugh</em>.</p>

<p>Based on this matching logic, the function <code>name_resolver</code> shown next implements the name-based coreference resolution for organizations and persons: </p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">name_resolver</code><code class="p">(</code><code class="n">doc</code><code class="p">):</code>
    <code class="sd">"""create name-based reference to e1 as primary mention of e2"""</code>
    <code class="n">ents</code> <code class="o">=</code> <code class="p">[</code><code class="n">e</code> <code class="k">for</code> <code class="n">e</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">ents</code> <code class="k">if</code> <code class="n">e</code><code class="o">.</code><code class="n">label_</code> <code class="ow">in</code> <code class="p">[</code><code class="s1">'ORG'</code><code class="p">,</code> <code class="s1">'PERSON'</code><code class="p">]]</code>
    <code class="k">for</code> <code class="n">i</code><code class="p">,</code> <code class="n">e1</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">ents</code><code class="p">):</code>
        <code class="k">for</code> <code class="n">e2</code> <code class="ow">in</code> <code class="n">ents</code><code class="p">[</code><code class="n">i</code><code class="o">+</code><code class="mi">1</code><code class="p">:]:</code>
            <code class="k">if</code> <code class="n">name_match</code><code class="p">(</code><code class="n">e1</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code><code class="p">,</code> <code class="n">e2</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">text</code><code class="p">):</code>
                <code class="n">e2</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code> <code class="o">=</code> <code class="n">e1</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code>
                <code class="n">e2</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code> <code class="o">=</code> <code class="n">e1</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code>
    <code class="k">return</code> <code class="n">propagate_ent_type</code><code class="p">(</code><code class="n">doc</code><code class="p">)</code>
</pre>

<p>First, we create a list of all organization and person entities. Then all pairs of entities <code>e1</code> and <code>e2</code> are compared against each other. The logic ensures that entity <code>e1</code> always comes before <code>e2</code> in the document. If <code>e2</code> matches <code>e1</code>, its referent is set to the same as <span class="keep-together">in <code>e1</code>.</span> Thus, the first matching entity is automatically propagated to its subsequent <span class="keep-together">coreferences</span>.</p>

<p>We add this function to the <code>nlp</code> pipeline and check the result:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">nlp</code><code class="o">.</code><code class="n">add_pipe</code><code class="p">(</code><code class="n">name_resolver</code><code class="p">)</code>

<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="n">displacy</code><code class="o">.</code><code class="n">render</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">style</code><code class="o">=</code><code class="s1">'ent'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<figure><div class="figure">
<img src="Images/btap_12in04.jpg" width="1264" height="180"/>
<h6/>
</div></figure>

<p>Now each named-entity in our example has the correct type. We can also check that the entities are mapped to their first mention:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">display_ner</code><code class="p">(</code><code class="n">doc</code><code class="p">)</code><code class="o">.</code><code class="n">query</code><code class="p">(</code><code class="s2">"ref_n != ''"</code><code class="p">)[[</code><code class="s1">'text'</code><code class="p">,</code> <code class="s1">'ent_type'</code><code class="p">,</code> <code class="s1">'ref_n'</code><code class="p">,</code> <code class="s1">'ref_t'</code><code class="p">]]</code>
</pre>

<p><code>Out:</code></p>


<table class="dataframe tex2jax_ignore">
  <thead>
    <tr>
      <th> </th>
      <th>text</th>
      <th>ent_type</th>
      <th>ref_n</th>
      <th>ref_t</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Hughes Tool Co</td>
      <td>ORG</td>
      <td>Hughes Tool Co</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>2</th>
      <td>W.A. Kistler</td>
      <td>PERSON</td>
      <td>W.A. Kistler</td>
      <td>PERSON</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Baker International Corp.</td>
      <td>ORG</td>
      <td>Baker International Corp.</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Kistler</td>
      <td>PERSON</td>
      <td>W.A. Kistler</td>
      <td>PERSON</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Baker</td>
      <td>ORG</td>
      <td>Baker International Corp.</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Hughes</td>
      <td>ORG</td>
      <td>Hughes Tool Co</td>
      <td>ORG</td>
    </tr>
  </tbody>
</table>

</div></section>

<section data-type="sect2" class="blueprint" data-pdf-bookmark="Blueprint: Performing Anaphora Resolution with NeuralCoref"><div class="sect2" id="idm45634174423640">
<h2>Blueprint: Performing Anaphora Resolution with NeuralCoref</h2>

<p>In linguistics, <em>anaphora</em> are words <a contenteditable="false" data-type="indexterm" data-primary="anaphora, resolution of" id="ch12_term24"/><a contenteditable="false" data-type="indexterm" data-primary="indirect references, resolution of" id="ch12_term25"/><a contenteditable="false" data-type="indexterm" data-primary="NeuralCoref library" id="ch12_term27"/>whose interpretation depends on the preceding text. Consider this variation of our example sentences:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="s2">"""Hughes Tool Co said its merger with Baker</code>
<code class="s2">was still under consideration. Hughes had a board meeting today.</code>
<code class="s2">W.A. Kistler mentioned that the company hopes for a mutual agreement.</code>
<code class="s2">He is reasonably confident."""</code>
</pre>

<p>Here <em>its</em>, <em>the company</em>, and <em>he</em> are anaphora. <a href="https://oreil.ly/kQRhE">NeuralCoref</a> from Hugging <a contenteditable="false" data-type="indexterm" data-primary="Hugging Face" id="idm45634173999592"/>Face is a library to resolve these kind of coreferences. The algorithm uses feature vectors based on word embeddings (see <a data-type="xref" href="ch10.xhtml#ch-embeddings">Chapter 10</a>) in combination with two <a contenteditable="false" data-type="indexterm" data-primary="neural networks" id="idm45634173997224"/>neural networks to identify coreference clusters and their main mentions.<sup><a data-type="noteref" id="idm45634173992248-marker" href="ch12.xhtml#idm45634173992248">7</a></sup></p>

<p>NeuralCoref is implemented <a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for coreference resolution" data-secondary-sortas="coreference resolution" id="ch12_term28"/><a contenteditable="false" data-type="indexterm" data-primary="extensions (spaCy)" id="idm45634173988584"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="extensions for" id="idm45634173987480"/>as a pipeline extension for spaCy, so it fits perfectly into our process. We create the neural coreference resolver with a <code>greedyness</code> value of 0.45 and add it to our pipeline. The <code>greedyness</code> controls the sensitivity of the model, and after some experiments, we decided to choose a little more restrictive (better accuracy, lower recall) value than the default 0.5:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">neuralcoref</code> <code class="kn">import</code> <code class="n">NeuralCoref</code>
<code class="n">neural_coref</code> <code class="o">=</code> <code class="n">NeuralCoref</code><code class="p">(</code><code class="n">nlp</code><code class="o">.</code><code class="n">vocab</code><code class="p">,</code> <code class="n">greedyness</code><code class="o">=</code><code class="mf">0.45</code><code class="p">)</code>
<code class="n">nlp</code><code class="o">.</code><code class="n">add_pipe</code><code class="p">(</code><code class="n">neural_coref</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s1">'neural_coref'</code><code class="p">)</code>
</pre>

<p>NeuralCoref uses also spaCy’s extension mechanism to add custom attributes to <code>Doc</code>, <code>Span</code>, and <code>Token</code> objects. When a text is processed, we can access the detected coreference clusters with the <code>doc._.coref_clusters</code> attribute. In our example, three such clusters have been identified:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="n">doc</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">coref_clusters</code><code class="p">,</code> <code class="n">sep</code><code class="o">=</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Hughes Tool Co: [Hughes Tool Co, its]
Hughes: [Hughes, the company]
W.A. Kistler: [W.A. Kistler, He]
</pre>

<p>NeuralCoref <a contenteditable="false" data-type="indexterm" data-primary="Span objects" id="idm45634173883240"/>works on <code>Span</code> objects (sequences of token) because coreferences in general are not limited to named entities. Thus, the blueprint function <code>anaphor_coref</code> retrieves for each token the first coreference cluster and searches for the first named-entity with a value in its <code>ref_n</code> attribute. In our case, this will be organizations and people only. Once found, it sets the values in <code>ref_n</code> and <code>ref_t</code> of the anaphor token to the same values as in the primary reference:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">anaphor_coref</code><code class="p">(</code><code class="n">doc</code><code class="p">):</code>
    <code class="sd">"""anaphora resolution"""</code>
    <code class="k">for</code> <code class="n">token</code> <code class="ow">in</code> <code class="n">doc</code><code class="p">:</code>
        <code class="c1"># if token is coref and not already dereferenced</code>
        <code class="k">if</code> <code class="n">token</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">in_coref</code> <code class="ow">and</code> <code class="n">token</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code> <code class="o">==</code> <code class="s1">''</code><code class="p">:</code>
            <code class="n">ref_span</code> <code class="o">=</code> <code class="n">token</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">coref_clusters</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">main</code> <code class="c1"># get referred span</code>
            <code class="k">if</code> <code class="nb">len</code><code class="p">(</code><code class="n">ref_span</code><code class="p">)</code> <code class="o">&lt;=</code> <code class="mi">3</code><code class="p">:</code> <code class="c1"># consider only short spans</code>
                <code class="k">for</code> <code class="n">ref</code> <code class="ow">in</code> <code class="n">ref_span</code><code class="p">:</code> <code class="c1"># find first dereferenced entity</code>
                    <code class="k">if</code> <code class="n">ref</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code> <code class="o">!=</code> <code class="s1">''</code><code class="p">:</code>
                        <code class="n">token</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code> <code class="o">=</code> <code class="n">ref</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code>
                        <code class="n">token</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code> <code class="o">=</code> <code class="n">ref</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code>
                        <code class="k">break</code>
    <code class="k">return</code> <code class="n">doc</code>
</pre>

<p>Again, we add this resolver to our pipeline and check the result:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">nlp</code><code class="o">.</code><code class="n">add_pipe</code><code class="p">(</code><code class="n">anaphor_coref</code><code class="p">)</code>
<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="n">display_ner</code><code class="p">(</code><code class="n">doc</code><code class="p">)</code><code class="o">.</code><code class="n">query</code><code class="p">(</code><code class="s2">"ref_n != ''"</code><code class="p">)</code> \
  <code class="p">[[</code><code class="s1">'text'</code><code class="p">,</code> <code class="s1">'ent_type'</code><code class="p">,</code> <code class="s1">'main_coref'</code><code class="p">,</code> <code class="s1">'ref_n'</code><code class="p">,</code> <code class="s1">'ref_t'</code><code class="p">]]</code>
</pre>

<p><code>Out:</code></p>

<table class="dataframe tex2jax_ignore">
  <thead>
    <tr>
      <th/>
      <th>text</th>
      <th>ent_type</th>
      <th>main_coref</th>
      <th>ref_n</th>
      <th>ref_t</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Hughes Tool Co</td>
      <td>ORG</td>
      <td>Hughes Tool Co</td>
      <td>Hughes Tool Co</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>2</th>
      <td>its</td>
      <td/>
      <td>Hughes Tool Co</td>
      <td>Hughes Tool Co</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Baker</td>
      <td>PERSON</td>
      <td>None</td>
      <td>Baker</td>
      <td>PERSON</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Hughes</td>
      <td>ORG</td>
      <td>Hughes</td>
      <td>Hughes Tool Co</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>18</th>
      <td>W.A. Kistler</td>
      <td>PERSON</td>
      <td>W.A. Kistler</td>
      <td>W.A. Kistler</td>
      <td>PERSON</td>
    </tr>
    <tr>
      <th>21</th>
      <td>the</td>
      <td/>
      <td>Hughes</td>
      <td>Hughes Tool Co</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>22</th>
      <td>company</td>
      <td/>
      <td>Hughes</td>
      <td>Hughes Tool Co</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>29</th>
      <td>He</td>
      <td/>
      <td>W.A. Kistler</td>
      <td>W.A. Kistler</td>
      <td>PERSON</td>
    </tr>
  </tbody>
</table>


<p>Now our pipeline consists of all the steps shown in <a data-type="xref" href="#fig-coref-pipeline">Figure 12-4</a>. </p><div data-type="warning" epub:type="warning"><h6>Warning</h6>

<p>Beware of long runtimes! NeuralCoref <a contenteditable="false" data-type="indexterm" data-primary="execution time" id="idm45634173635320"/><a contenteditable="false" data-type="indexterm" data-primary="time, execution" id="idm45634173634344"/>increases the total processing time by a factor of 5–10. So, you should use anaphora resolution <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term24" id="idm45634173633128"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term25" id="idm45634173631912"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term27" id="idm45634173630696"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term28" id="idm45634173629480"/>only if necessary.</p></div>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Name Normalization"><div class="sect2" id="idm45634174013736">
<h2>Name Normalization</h2>

<p>Even though our <a contenteditable="false" data-type="indexterm" data-primary="normalization of text" id="idm45634173626760"/>name resolution unifies company mentions within an article, the company names are still inconsistent across articles. We find <em>Hughes Tool Co.</em> in one article and <em>Hughes Tool</em> in another one. An entity linker can be used to link different entity mentions to a unique canonical representation, but in absence of an entity linker we will use the (resolved) name entity as its unique identifier. Because of the previous steps for coreference resolution, the resolved names are always the first, and thus usually most complete, mentions in an article. So, the potential for errors is not that large. </p>

<p>Still, we have to <a contenteditable="false" data-type="indexterm" data-primary="suffixes in text analysis" id="idm45634173623672"/>harmonize company mentions by removing the legal suffixes like <em>Co.</em> or <em>Inc.</em> from company names. The following function uses a regular expression to achieve this:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">strip_legal_suffix</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">re</code><code class="o">.</code><code class="n">sub</code><code class="p">(</code><code class="s-Affix">r</code><code class="s1">'(\s+and)?(\s+|\b(Co|Corp|Inc|Plc|Ltd)\b\.?)*$'</code><code class="p">,</code> <code class="s1">''</code><code class="p">,</code> <code class="n">text</code><code class="p">)</code>

<code class="k">print</code><code class="p">(</code><code class="n">strip_legal_suffix</code><code class="p">(</code><code class="s1">'Hughes Tool Co'</code><code class="p">))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
Hughes Tool
</pre>

<p>The last pipeline function <code>norm_names</code> applies this final normalization to each of the coreference-resolved organization names stored in the <code>ref_n</code> attributes. Note that <code>Hughes (PERSON)</code> and <code>Hughes (ORG)</code> will still remain separate entities <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term16" id="idm45634173594840"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term18" id="idm45634173593464"/>with this approach.</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">norm_names</code><code class="p">(</code><code class="n">doc</code><code class="p">):</code>
    <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">doc</code><code class="p">:</code>
        <code class="k">if</code> <code class="n">t</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code> <code class="o">!=</code> <code class="s1">''</code> <code class="ow">and</code> <code class="n">t</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code> <code class="ow">in</code> <code class="p">[</code><code class="s1">'ORG'</code><code class="p">]:</code>
            <code class="n">t</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code> <code class="o">=</code> <code class="n">strip_legal_suffix</code><code class="p">(</code><code class="n">t</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code><code class="p">)</code>
            <code class="k">if</code> <code class="n">t</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code> <code class="o">==</code> <code class="s1">''</code><code class="p">:</code>
                <code class="n">t</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code> <code class="o">=</code> <code class="s1">''</code>
    <code class="k">return</code> <code class="n">doc</code>

<code class="n">nlp</code><code class="o">.</code><code class="n">add_pipe</code><code class="p">(</code><code class="n">norm_names</code><code class="p">)</code>
</pre>

<p>Sometimes the named-entity recognizer misclassifies a legal suffix like <em>Co.</em> or <em>Inc.</em> by itself as named-entity. If such an entity name gets stripped to the empty string, we just ignore it for later processing.</p>

</div></section>

<section data-type="sect2" data-pdf-bookmark="Entity Linking"><div class="sect2" id="idm45634173500888">
<h2>Entity Linking</h2>

<p>In the previous sections <a contenteditable="false" data-type="indexterm" data-primary="entity linking" id="ch12_term29"/>we developed a pipeline of operations with the purpose of unifying the different mentions of named entities. But all this is string based, and except for the syntactical representation, we have no connection between the string <em>U.S. Department of Justice</em> and the represented real-world entity. The task of an entity linker, in contrast, is to resolve named entities globally and link them to a uniquely identified real-world entity. Entity linking makes the step from “strings to things.”<sup><a data-type="noteref" id="idm45634173497096-marker" href="ch12.xhtml#idm45634173497096">8</a></sup> </p>

<p>Technically, this means that <a contenteditable="false" data-type="indexterm" data-primary="URIs (uniform resource identifiers)" id="idm45634173495528"/>each mention is mapped to a URI. URIs, in turn, address entities in an existing knowledge base. This can be a <a contenteditable="false" data-type="indexterm" data-primary="DBpedia" id="idm45634173494200"/><a contenteditable="false" data-type="indexterm" data-primary="Wikidata" id="idm45634173493096"/><a contenteditable="false" data-type="indexterm" data-primary="ontology" id="idm45634173491992"/>public ontology, like Wikidata or DBpedia, or a private knowledge base in your company. URIs can be URLs (e.g., web pages) but do not have to be. The U.S. Department of Justice, for example, has the Wikidata URI <a href="http://www.wikidata.org/entity/Q1553390"><em>http://www.wikidata.org/entity/Q1553390</em></a>, which is also a web page where you find information about this entity. If you build your own knowledge base, it is not necessary to have a web page for each URI; they just must be unique. <span class="keep-together">DBpedia</span> and Wikidata, by the way, use different URIs, but you will find the Wikidata <span class="keep-together">URI on</span> DBpedia as a cross-reference. Both, of course, contain links to the Wikipedia <span class="keep-together">web page</span>.</p>

<p>Entity linking is simple if an entity is mentioned by a fully qualified name, like the <em>U.S. Department of Justice</em>. But the term <em>Department of Justice</em> without <em>U.S.</em> is already quite ambiguous because many states have a “Department of Justice.” The actual meaning depends on the context, and the task of an entity linker is to map such an ambiguous mention context-sensitively to the correct URI. This is quite a challenge and still an area of ongoing research. A common solution for entity linking in business projects is the usage of a public service (see <a data-type="xref" data-xrefstyle="select:nopage" href="#services-entity-linking">“Services for Entity Linking”</a>).</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="services-entity-linking">
<h5>Services for Entity Linking</h5>

<p>There are several <a contenteditable="false" data-type="indexterm" data-primary="web services for entity linking" id="idm45634173482024"/>web services for named-entity resolution and linking. <a href="https://dbpedia-spotlight.org">DBpedia Spotlight</a>, for example, is an <a contenteditable="false" data-type="indexterm" data-primary="DBpedia Spotlight" id="idm45634173480040"/>open service that links to DBpedia resources. You can either use the public web service or deploy a copy in your own environment.
A <a contenteditable="false" data-type="indexterm" data-primary="Text Razor" id="idm45634173478632"/>commercial alternative for such a service is <a href="https://textrazor.com/demo">TextRazor</a>, which even provides a nice Python library for easy integration into your own project.</p></div></aside>

<p>Alternatively, you could create your own entity linker. A simple solution would be a name-based lookup dictionary. But that does not take the context into account and would not resolve ambiguous names for different entities. For that, you need a more sophisticated approach. State-of-the-art solutions use embeddings and neural models for entity linking. <a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for entity linking" data-secondary-sortas="entity linking" id="idm45634173476008"/>spaCy also provides such an <a href="https://oreil.ly/bqs8E">entity linking functionality</a>. To use spaCy’s entity linker, you first have to create embeddings (see <a data-type="xref" href="ch10.xhtml#ch-embeddings">Chapter 10</a>) for the real-world entities, which capture their semantics based on descriptions you specify. Then you can train a model to learn the context-sensitive mapping of mentions to the correct URI. The setup and training of an entity linker are, however, beyond the scope of this chapter. </p>
</div></section>
</div></section>

<section data-type="sect1" class="blueprint" data-pdf-bookmark="Blueprint: Creating a Co-Occurrence Graph"><div class="sect1" id="ch12-cooc">
<h1>Blueprint: Creating a Co-Occurrence Graph</h1>

<p>In the previous sections, we spent much effort to normalize named entities and to resolve at least the in-document coreferences. Now <a contenteditable="false" data-type="indexterm" data-primary="co-occurrence graphs" id="ch12_term31"/>we are finally ready to analyze a first relationship among pairs of entities: their joint mention in an article. For this, we will create a co-occurrence graph, the simplest form <span class="keep-together">of a knowledge</span> graph. The nodes in the co-occurrence graph are the entities, e.g., <span class="keep-together">organizations</span>. Two entities share an (undirected) edge if they are mentioned in the same context, for example, within an article, a paragraph, or a sentence.</p>

<p><a data-type="xref" href="#fig-cooc">Figure 12-5</a> shows part of the co-occurrence graph for companies mentioned together <a contenteditable="false" data-type="indexterm" data-primary="datasets, examples of" data-secondary="Reuters News Archive" id="idm45634173465208"/><a contenteditable="false" data-type="indexterm" data-primary="news archives" id="idm45634173463832"/><a contenteditable="false" data-type="indexterm" data-primary="Reuters News Archive" id="idm45634173462728"/><a contenteditable="false" data-type="indexterm" data-primary="visualization of data" data-secondary="with knowledge graphs" data-secondary-sortas="knowledge graphs" id="idm45634173461624"/>in articles of the Reuters corpus. The width of the edges visualizes the co-occurrence frequency. The <a href="https://oreil.ly/pGZ-s"><em>modularity</em></a>, a structural measure to identify closely related groups or communities in a network, was used to colorize the nodes and edges.<sup><a data-type="noteref" id="idm45634173458648-marker" href="ch12.xhtml#idm45634173458648">9</a></sup> </p>

<figure><div id="fig-cooc" class="figure">
<img src="Images/btap_1205.jpg" width="1609" height="954"/>
<h6><span class="label">Figure 12-5. </span>Largest connected component of the co-occurrence graph generated from the Reuters corpus.</h6></div></figure>

<p>Of course, we don’t know anything about the type of relationship here. In fact, the joint mentioning of two entities merely indicates that there <em>might be some</em> relationship. We won’t know for sure unless we really analyze the sentences, and we will do that in the next section. But even the simple exploration of co-occurrences can already be revealing. For example, the central node in <a data-type="xref" href="#fig-cooc">Figure 12-5</a> is the “Securities and Exchange Commission” because it is mentioned in many articles together with a great variety of other entities. Obviously, this entity plays a major role in mergers and acquisitions. The different clusters give us an impression about groups of companies (or communities) involved in certain deals.</p>

<p>To plot a co-occurrence graph, we have to extract entity pairs from a document. For longer articles covering multiple topic areas, it may be better to search for co-occurrences within paragraphs or even sentences. But the Reuters articles on mergers and acquisitions are very focused, so we stick to the document level here. Let’s briefly walk through the process to extract and visualize co-occurrences.</p>

<section data-type="sect2" data-pdf-bookmark="Extracting Co-Occurrences from a Document"><div class="sect2" id="idm45634173451896">
<h2>Extracting Co-Occurrences from a Document</h2>

<p>The <a contenteditable="false" data-type="indexterm" data-primary="extract_coocs function" id="idm45634173411048"/>function <code>extract_coocs</code> returns the list of entities pairs of the specified types from a given <code>Doc</code> object:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">itertools</code> <code class="kn">import</code> <code class="n">combinations</code>

<code class="k">def</code> <code class="nf">extract_coocs</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">include_types</code><code class="p">):</code>
    <code class="n">ents</code> <code class="o">=</code> <code class="nb">set</code><code class="p">([(</code><code class="n">e</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code><code class="p">,</code> <code class="n">e</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code><code class="p">)</code>
                <code class="k">for</code> <code class="n">e</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">ents</code> <code class="k">if</code> <code class="n">e</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code> <code class="ow">in</code> <code class="n">include_types</code><code class="p">])</code>
    <code class="k">yield from</code> <code class="n">combinations</code><code class="p">(</code><code class="nb">sorted</code><code class="p">(</code><code class="n">ents</code><code class="p">),</code> <code class="mi">2</code><code class="p">)</code>
</pre>

<p>We first create a set of the coreference-resolved entity names and types. Having this, we use the function <code>combinations</code> from the Python standard library <code>itertools</code> to create all the entity pairs. Each pair is sorted lexicographically (<code>sorted(ents)</code>) to prevent duplicate entries like “(Baker, Hughes)” and “(Hughes, Baker).”</p>

<p>To process the whole dataset efficiently, we use again spaCy’s streaming by calling <code>nlp.pipe</code> (introduced in <a data-type="xref" href="ch04.xhtml#ch-preparation">Chapter 4</a>). As we <a contenteditable="false" data-type="indexterm" data-primary="anaphora, resolution of" id="idm45634173341704"/><a contenteditable="false" data-type="indexterm" data-primary="indirect references, resolution of" id="idm45634173340568"/>do not need anaphora resolution to find in-document co-occurrences, we disable the respective components here:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">100</code>

<code class="n">coocs</code> <code class="o">=</code> <code class="p">[]</code>
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">df</code><code class="p">),</code> <code class="n">batch_size</code><code class="p">):</code>
    <code class="n">docs</code> <code class="o">=</code> <code class="n">nlp</code><code class="o">.</code><code class="n">pipe</code><code class="p">(</code><code class="n">df</code><code class="p">[</code><code class="s1">'text'</code><code class="p">][</code><code class="n">i</code><code class="p">:</code><code class="n">i</code><code class="o">+</code><code class="n">batch_size</code><code class="p">],</code>
                    <code class="n">disable</code><code class="o">=</code><code class="p">[</code><code class="s1">'neural_coref'</code><code class="p">,</code> <code class="s1">'anaphor_coref'</code><code class="p">])</code>
    <code class="k">for</code> <code class="n">j</code><code class="p">,</code> <code class="n">doc</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">docs</code><code class="p">):</code>
        <code class="n">coocs</code><code class="o">.</code><code class="n">extend</code><code class="p">([(</code><code class="n">df</code><code class="o">.</code><code class="n">index</code><code class="p">[</code><code class="n">i</code><code class="o">+</code><code class="n">j</code><code class="p">],</code> <code class="o">*</code><code class="n">c</code><code class="p">)</code>
                      <code class="k">for</code> <code class="n">c</code> <code class="ow">in</code> <code class="n">extract_coocs</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="p">[</code><code class="s1">'ORG'</code><code class="p">,</code> <code class="s1">'GOV'</code><code class="p">])])</code>
</pre>

<p>Let’s take a look at the identified co-occurrences of the first article:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="n">coocs</code><code class="p">[:</code><code class="mi">3</code><code class="p">],</code> <code class="n">sep</code><code class="o">=</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
(10, ('Computer Terminal Systems', 'ORG'), ('Sedio N.V.', 'ORG'))
(10, ('Computer Terminal Systems', 'ORG'), ('Woodco', 'ORG'))
(10, ('Sedio N.V.', 'ORG'), ('Woodco', 'ORG'))
</pre>

<p>In information extraction, it is always <a contenteditable="false" data-type="indexterm" data-primary="backups" id="idm45634173213672"/><a contenteditable="false" data-type="indexterm" data-primary="copies for traceability" id="idm45634173212472"/>recommended to have some kind of traceability that allows you to identify the source of the information in the case of problems. Therefore, we retain the index of the article, which in our case is the file ID of the Reuters corpus, with each co-occurrence tuple (here the ID 10). Based on this list, we generate a <code>DataFrame</code> with exactly one entry per entity combination, its frequency, and the article IDs (limited to five) where this co-occurrence was found.</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">coocs</code> <code class="o">=</code> <code class="p">[([</code><code class="nb">id</code><code class="p">],</code> <code class="o">*</code><code class="n">e1</code><code class="p">,</code> <code class="o">*</code><code class="n">e2</code><code class="p">)</code> <code class="k">for</code> <code class="p">(</code><code class="nb">id</code><code class="p">,</code> <code class="n">e1</code><code class="p">,</code> <code class="n">e2</code><code class="p">)</code> <code class="ow">in</code> <code class="n">coocs</code><code class="p">]</code>
<code class="n">cooc_df</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="o">.</code><code class="n">from_records</code><code class="p">(</code><code class="n">coocs</code><code class="p">,</code>
             <code class="n">columns</code><code class="o">=</code><code class="p">(</code><code class="s1">'article_id'</code><code class="p">,</code> <code class="s1">'ent1'</code><code class="p">,</code> <code class="s1">'type1'</code><code class="p">,</code> <code class="s1">'ent2'</code><code class="p">,</code> <code class="s1">'type2'</code><code class="p">))</code>
<code class="n">cooc_df</code> <code class="o">=</code> <code class="n">cooc_df</code><code class="o">.</code><code class="n">groupby</code><code class="p">([</code><code class="s1">'ent1'</code><code class="p">,</code> <code class="s1">'type1'</code><code class="p">,</code> <code class="s1">'ent2'</code><code class="p">,</code> <code class="s1">'type2'</code><code class="p">])[</code><code class="s1">'article_id'</code><code class="p">]</code> \
                 <code class="o">.</code><code class="n">agg</code><code class="p">([</code><code class="s1">'count'</code><code class="p">,</code> <code class="s1">'sum'</code><code class="p">])</code> \
                 <code class="o">.</code><code class="n">rename</code><code class="p">(</code><code class="n">columns</code><code class="o">=</code><code class="p">{</code><code class="s1">'count'</code><code class="p">:</code> <code class="s1">'freq'</code><code class="p">,</code> <code class="s1">'sum'</code><code class="p">:</code> <code class="s1">'articles'</code><code class="p">})</code> \
                 <code class="o">.</code><code class="n">reset_index</code><code class="p">()</code><code class="o">.</code><code class="n">sort_values</code><code class="p">(</code><code class="s1">'freq'</code><code class="p">,</code> <code class="n">ascending</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>
<code class="n">cooc_df</code><code class="p">[</code><code class="s1">'articles'</code><code class="p">]</code> <code class="o">=</code> <code class="n">cooc_df</code><code class="p">[</code><code class="s1">'articles'</code><code class="p">]</code><code class="o">.</code><code class="n">map</code><code class="p">(</code>
                        <code class="k">lambda</code> <code class="n">lst</code><code class="p">:</code> <code class="s1">','</code><code class="o">.</code><code class="n">join</code><code class="p">([</code><code class="nb">str</code><code class="p">(</code><code class="n">a</code><code class="p">)</code> <code class="k">for</code> <code class="n">a</code> <code class="ow">in</code> <code class="n">lst</code><code class="p">[:</code><code class="mi">5</code><code class="p">]]))</code>
</pre>

<p>Here are the three most frequent entity pairs we found in the corpus:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">cooc_df</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="mi">3</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<table class="dataframe tex2jax_ignore">
  <thead>
    <tr>
      <th/>
      <th>ent1</th>
      <th>type1</th>
      <th>ent2</th>
      <th>type2</th>
      <th>freq</th>
      <th>articles</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12667</th>
      <td>Trans World Airlines</td>
      <td>ORG</td>
      <td>USAir Group</td>
      <td>ORG</td>
      <td>22</td>
      <td>1735,1771,1836,1862,1996</td>
    </tr>
    <tr>
      <th>5321</th>
      <td>Cyclops</td>
      <td>ORG</td>
      <td>Dixons Group</td>
      <td>ORG</td>
      <td>21</td>
      <td>4303,4933,6093,6402,7110</td>
    </tr>
    <tr>
      <th>12731</th>
      <td>U.S. Department of Transportation</td>
      <td>GOV</td>
      <td>USAir Group</td>
      <td>ORG</td>
      <td>20</td>
      <td>1735,1996,2128,2546,2799</td>
    </tr>
  </tbody>
</table>

</div></section>

<section data-type="sect2" data-pdf-bookmark="Visualizing the Graph with Gephi"><div class="sect2" id="idm45634173451272">
<h2>Visualizing the Graph with Gephi</h2>

<p>Actually, this <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term31" id="idm45634172998392"/><code>DataFrame</code> already represents the list of edges for our graph. For the visualization <a contenteditable="false" data-type="indexterm" data-primary="Gephi" id="idm45634172975736"/><a contenteditable="false" data-type="indexterm" data-primary="visualization of data" data-secondary="with knowledge graphs" data-secondary-sortas="knowledge graphs" id="idm45634172974632"/>we prefer <a href="https://gephi.org">Gephi</a>, an open source tool for graph analysis. Because it is interactive, it is <a contenteditable="false" data-type="indexterm" data-primary="NetworkX graph library (Python)" id="idm45634172972136"/>much better to use than Python’s graph library NetworkX.<sup><a data-type="noteref" id="idm45634172970888-marker" href="ch12.xhtml#idm45634172970888">10</a></sup> To work with Gephi, we need to save the list of nodes and edges of the graph in Graph Exchange XML format. Fortunately, NetworkX provides a function to export graphs in this format. So, we can simply convert our <code>DataFrame</code> into a NetworkX graph and <a contenteditable="false" data-type="indexterm" data-primary="gexf file format" id="idm45634172968600"/>save it as a <code>.gexf</code> file. We discard rare entity pairs to keep the graph compact and rename the frequency column because Gephi automatically uses a <code>weight</code> attribute to adjust the width of edges:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">import</code> <code class="nn">networkx</code> <code class="kn">as</code> <code class="nn">nx</code>

<code class="n">graph</code> <code class="o">=</code> <code class="n">nx</code><code class="o">.</code><code class="n">from_pandas_edgelist</code><code class="p">(</code>
           <code class="n">cooc_df</code><code class="p">[[</code><code class="s1">'ent1'</code><code class="p">,</code> <code class="s1">'ent2'</code><code class="p">,</code> <code class="s1">'articles'</code><code class="p">,</code> <code class="s1">'freq'</code><code class="p">]]</code> \
           <code class="o">.</code><code class="n">query</code><code class="p">(</code><code class="s1">'freq &gt; 3'</code><code class="p">)</code><code class="o">.</code><code class="n">rename</code><code class="p">(</code><code class="n">columns</code><code class="o">=</code><code class="p">{</code><code class="s1">'freq'</code><code class="p">:</code> <code class="s1">'weight'</code><code class="p">}),</code>
           <code class="n">source</code><code class="o">=</code><code class="s1">'ent1'</code><code class="p">,</code> <code class="n">target</code><code class="o">=</code><code class="s1">'ent2'</code><code class="p">,</code> <code class="n">edge_attr</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>


<code class="n">nx</code><code class="o">.</code><code class="n">readwrite</code><code class="o">.</code><code class="n">write_gexf</code><code class="p">(</code><code class="n">graph</code><code class="p">,</code> <code class="s1">'cooc.gexf'</code><code class="p">,</code> <code class="n">encoding</code><code class="o">=</code><code class="s1">'utf-8'</code><code class="p">,</code>
                        <code class="n">prettyprint</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">version</code><code class="o">=</code><code class="s1">'1.2draft'</code><code class="p">)</code>
</pre>

<p>After importing the file into Gephi, we selected only the largest component (connected subgraph) and removed some nodes with only a few connections manually for the sake of clarity.<sup><a data-type="noteref" id="idm45634172964856-marker" href="ch12.xhtml#idm45634172964856">11</a></sup> The result is presented in <a data-type="xref" href="#fig-cooc">Figure 12-5</a>.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>

<p>Sometimes the most interesting relations are the ones that are not frequent. Take, for example, the first announcement on an upcoming merger or surprising relations that were mentioned a few times in the past but then forgotten. A sudden co-occurrence of entities that were previously unrelated can be a signal to start a deeper analysis <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term29" id="idm45634172837384"/>of the relation.</p></div>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Relation Extraction"><div class="sect1" id="idm45634172835752">
<h1>Relation Extraction</h1>

<p>Even though the co-occurrence graph already gave us some interesting insights about company networks, it <a contenteditable="false" data-type="indexterm" data-primary="relation extraction" id="ch12_term37"/>does not tell us anything about the types of the relations. Take, for example, the subgraph formed by the companies Schlumberger, Fairchild Semiconductor, and Fujitsu in the lower-left corner of <a data-type="xref" href="#fig-cooc">Figure 12-5</a>. So far, we know nothing about the relations between those companies; the information is still hidden in sentences like these:</p>

<p><em>Fujitsu wants to expand. It plans to acquire 80%
of Fairchild Corp, an industrial unit of Schlumberger.</em></p>

<p>In this section, we will introduce two blueprints for pattern-based relation extraction. The first and simpler blueprint searches for token phrases of the form “subject-predicate-object.” The second one uses the syntactical structure of a sentence, the dependency tree, to get more precise results at the price of more complex rules. In the end, we will generate a knowledge graph based on the four relations: <em>acquires</em>, <em>sells</em>, <em>subsidiary-of</em>, and <em>chairperson-of</em>. To be honest, we will use relaxed definitions of <em>acquires</em> and <em>sells</em>, which are easier to identify. They will also match sentences like “Fujitsu <em>plans to acquire 80%</em> of Fairchild Corp” or even “Fujitsu <em>withdraws the option to acquire</em> Fairchild Corp.”</p>

<p>Relation extraction is a complicated problem because of the ambiguity of natural language and the many different kinds and variations of relations. Model-based approaches to relation extraction are a current topic in research.<sup><a data-type="noteref" id="idm45634172825528-marker" href="ch12.xhtml#idm45634172825528">12</a></sup> There are also some <a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="data for" id="idm45634172823848"/>training datasets like <a href="http://zhuhao.me/fewrel">FewRel</a> publicly available. However, training a model to identify relations is still pretty much in the research stage and out of the scope of this book. </p>

<section data-type="sect2" class="blueprint" data-pdf-bookmark="Blueprint: Extracting Relations Using Phrase Matching"><div class="sect2" id="idm45634172821304">
<h2>Blueprint: Extracting Relations Using Phrase Matching</h2>

<p>The first blueprint works like <a contenteditable="false" data-type="indexterm" data-primary="rule-based heuristics for knowledge graphs" id="ch12_term36"/>rule-based entity recognition: it <a contenteditable="false" data-type="indexterm" data-primary="phrase matching for extracting relations" id="ch12_term34"/>tries to identify relations based on patterns for token sequences. Let’s start with a simplified version of the introductory example to explain the approach.</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="s2">"""Fujitsu plans to acquire 80</code><code class="si">% o</code><code class="s2">f Fairchild Corp, an industrial unit</code>
<code class="s2">of Schlumberger."""</code>
</pre>

<p>We could find the relations in this sentence by searching for patterns like these:</p>

<pre><code>ORG {optional words, not ORG} acquire {optional words, not ORG} ORG
ORG {optional words, not ORG} unit of {optional words, not ORG} ORG
</code></pre>

<p><a href="https://oreil.ly/Mxd3m">spaCy’s rule-based matcher</a><a contenteditable="false" data-type="indexterm" data-primary="rule-based matcher (spaCy)" id="ch12_term40"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for matching patterns" data-secondary-sortas="matching patterns" id="ch12_term41"/> allows us to find patterns that not only can involve the textual tokens but also their properties, like the lemma or part of speech. To use it, we must first define a matcher object. Then we can add rules with token patternsto the matcher:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">spacy.matcher</code> <code class="kn">import</code> <code class="n">Matcher</code>

<code class="n">matcher</code> <code class="o">=</code> <code class="n">Matcher</code><code class="p">(</code><code class="n">nlp</code><code class="o">.</code><code class="n">vocab</code><code class="p">)</code>

<code class="n">acq_synonyms</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'acquire'</code><code class="p">,</code> <code class="s1">'buy'</code><code class="p">,</code> <code class="s1">'purchase'</code><code class="p">]</code>
<code class="n">pattern</code> <code class="o">=</code> <code class="p">[{</code><code class="s1">'_'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'ref_t'</code><code class="p">:</code> <code class="s1">'ORG'</code><code class="p">}},</code> <code class="c1"># subject</code>
           <code class="p">{</code><code class="s1">'_'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'ref_t'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'NOT_IN'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'ORG'</code><code class="p">]}},</code> <code class="s1">'OP'</code><code class="p">:</code> <code class="s1">'*'</code><code class="p">},</code>
           <code class="p">{</code><code class="s1">'POS'</code><code class="p">:</code> <code class="s1">'VERB'</code><code class="p">,</code> <code class="s1">'LEMMA'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'IN'</code><code class="p">:</code> <code class="n">acq_synonyms</code><code class="p">}},</code>
           <code class="p">{</code><code class="s1">'_'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'ref_t'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'NOT_IN'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'ORG'</code><code class="p">]}},</code> <code class="s1">'OP'</code><code class="p">:</code> <code class="s1">'*'</code><code class="p">},</code>
           <code class="p">{</code><code class="s1">'_'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'ref_t'</code><code class="p">:</code> <code class="s1">'ORG'</code><code class="p">}}]</code> <code class="c1"># object</code>
<code class="n">matcher</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="s1">'acquires'</code><code class="p">,</code> <code class="bp">None</code><code class="p">,</code> <code class="n">pattern</code><code class="p">)</code>
</pre>

<pre data-code-language="python" data-type="programlisting">
<code class="n">subs_synonyms</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'subsidiary'</code><code class="p">,</code> <code class="s1">'unit'</code><code class="p">]</code>
<code class="n">pattern</code> <code class="o">=</code> <code class="p">[{</code><code class="s1">'_'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'ref_t'</code><code class="p">:</code> <code class="s1">'ORG'</code><code class="p">}},</code> <code class="c1"># subject</code>
           <code class="p">{</code><code class="s1">'_'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'ref_t'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'NOT_IN'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'ORG'</code><code class="p">]}},</code>
            <code class="s1">'POS'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'NOT_IN'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'VERB'</code><code class="p">]},</code> <code class="s1">'OP'</code><code class="p">:</code> <code class="s1">'*'</code><code class="p">},</code>
           <code class="p">{</code><code class="s1">'LOWER'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'IN'</code><code class="p">:</code> <code class="n">subs_synonyms</code><code class="p">}},</code> <code class="p">{</code><code class="s1">'TEXT'</code><code class="p">:</code> <code class="s1">'of'</code><code class="p">},</code>
           <code class="p">{</code><code class="s1">'_'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'ref_t'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'NOT_IN'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'ORG'</code><code class="p">]}},</code>
            <code class="s1">'POS'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'NOT_IN'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'VERB'</code><code class="p">]},</code> <code class="s1">'OP'</code><code class="p">:</code> <code class="s1">'*'</code><code class="p">},</code>
           <code class="p">{</code><code class="s1">'_'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'ref_t'</code><code class="p">:</code> <code class="s1">'ORG'</code><code class="p">}}]</code> <code class="c1"># object</code>
<code class="n">matcher</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="s1">'subsidiary-of'</code><code class="p">,</code> <code class="bp">None</code><code class="p">,</code> <code class="n">pattern</code><code class="p">)</code>
</pre>

<p>The first pattern is for the <code>acquires</code> relation. It returns all spans consisting of an organization, followed by arbitrary tokens that are not organizations, a verb matching several synonyms of <em>acquire</em>, again arbitrary tokens, and finally the second organization. The second pattern for <code>subsidiary-of</code> works similarly. </p>

<p>Granted, the expressions are hard to read. One reason is that we used the custom attribute <code>ref_t</code> instead of the standard <code>ENT_TYPE</code>. This is necessary to match coreferences that are not marked as entities, e.g., pronouns. Another one is that we have included some <code>NOT_IN</code> clauses. This is because rules with the asterisk operator (<code>*</code>) are always dangerous as they search patterns of unbounded length. Additional conditions on the tokens can reduce the risk for false matches. For example, we want to match “Fairchild, an industrial unit of Schlumberger” for the <code>subsidiary-of</code> relation, but not “Fujitsu mentioned a unit of Schlumberger.” When developing rules, you always have to pay for precision with complexity. We will discuss the problems of the <code>acquires</code> relation on that aspect in a minute.</p>

<p>The blueprint <a contenteditable="false" data-type="indexterm" data-primary="extract_rel_match function" id="idm45634172525528"/>function <code>extract_rel_match</code> now takes a processed <code>Doc</code> object and a matcher and transforms all matches to subject-predicate-object triples:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">extract_rel_match</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">matcher</code><code class="p">):</code>
    <code class="k">for</code> <code class="n">sent</code> <code class="ow">in</code> <code class="n">doc</code><code class="o">.</code><code class="n">sents</code><code class="p">:</code>
        <code class="k">for</code> <code class="n">match_id</code><code class="p">,</code> <code class="n">start</code><code class="p">,</code> <code class="n">end</code> <code class="ow">in</code> <code class="n">matcher</code><code class="p">(</code><code class="n">sent</code><code class="p">):</code>
            <code class="n">span</code> <code class="o">=</code> <code class="n">sent</code><code class="p">[</code><code class="n">start</code><code class="p">:</code><code class="n">end</code><code class="p">]</code>  <code class="c1"># matched span</code>
            <code class="n">pred</code> <code class="o">=</code> <code class="n">nlp</code><code class="o">.</code><code class="n">vocab</code><code class="o">.</code><code class="n">strings</code><code class="p">[</code><code class="n">match_id</code><code class="p">]</code> <code class="c1"># rule name</code>
            <code class="n">subj</code><code class="p">,</code> <code class="n">obj</code> <code class="o">=</code> <code class="n">span</code><code class="p">[</code><code class="mi">0</code><code class="p">],</code> <code class="n">span</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
            <code class="k">if</code> <code class="n">pred</code><code class="o">.</code><code class="n">startswith</code><code class="p">(</code><code class="s1">'rev-'</code><code class="p">):</code> <code class="c1"># reversed relation</code>
                <code class="n">subj</code><code class="p">,</code> <code class="n">obj</code> <code class="o">=</code> <code class="n">obj</code><code class="p">,</code> <code class="n">subj</code>
                <code class="n">pred</code> <code class="o">=</code> <code class="n">pred</code><code class="p">[</code><code class="mi">4</code><code class="p">:]</code>
            <code class="k">yield</code> <code class="p">((</code><code class="n">subj</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code><code class="p">,</code> <code class="n">subj</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code><code class="p">),</code> <code class="n">pred</code><code class="p">,</code>
                   <code class="p">(</code><code class="n">obj</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code><code class="p">,</code> <code class="n">obj</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code><code class="p">))</code>
</pre>

<p>The predicate is determined by the name of the rule; the involved entities are simply the first and last tokens of the matched span. We restrict the search to the sentence level because in a whole document we would have a high risk of finding false positives spanning multiple sentences.</p>

<p>Usually, the rules match in the order “subject-predicate-object,” but often the entities appear in the text in reversed order, like in “the Schlumberger unit Fairchild Corp.” Here, the order of entities with regard to the <code>subsidiary-of</code> relation is “object-predicate-subject.” <code>extract_rel_match</code> is prepared to handle this and switches the subject and object if a rule has the prefix <code>rev-</code> like this one: </p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">pattern</code> <code class="o">=</code> <code class="p">[{</code><code class="s1">'_'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'ref_t'</code><code class="p">:</code> <code class="s1">'ORG'</code><code class="p">}},</code> <code class="c1"># subject</code>
           <code class="p">{</code><code class="s1">'LOWER'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'IN'</code><code class="p">:</code> <code class="n">subs_synonyms</code><code class="p">}},</code> <code class="c1"># predicate</code>
           <code class="p">{</code><code class="s1">'_'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'ref_t'</code><code class="p">:</code> <code class="s1">'ORG'</code><code class="p">}}]</code> <code class="c1"># object</code>
<code class="n">matcher</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="s1">'rev-subsidiary-of'</code><code class="p">,</code> <code class="bp">None</code><code class="p">,</code> <code class="n">pattern</code><code class="p">)</code>
</pre>

<p>Now we are able to detect <code>acquires</code> and both variants of <code>subsidiary-of</code> in sentences like these:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="s2">"""Fujitsu plans to acquire 80</code><code class="si">% o</code><code class="s2">f Fairchild Corp, an industrial unit</code>
<code class="s2">of Schlumberger. The Schlumberger unit Fairchild Corp received an offer."""</code>
<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="n">extract_rel_match</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">matcher</code><code class="p">),</code> <code class="n">sep</code><code class="o">=</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
(('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))
(('Fairchild', 'ORG'), 'subsidiary-of', ('Schlumberger', 'ORG'))
(('Fairchild', 'ORG'), 'subsidiary-of', ('Schlumberger', 'ORG'))
</pre>

<p>Although the rules work nicely for our examples, the rule for <em>acquires</em> is not very reliable. The verb <em>acquire</em> can appear in many different constellations of entities. Thus, there is a high probability for false matches like this one:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="s2">"Fairchild Corp was acquired by Fujitsu."</code>
<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="n">extract_rel_match</code><code class="p">(</code><code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">),</code> <code class="n">matcher</code><code class="p">),</code> <code class="n">sep</code><code class="o">=</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
(('Fairchild', 'ORG'), 'acquires', ('Fujitsu', 'ORG'))
</pre>

<p>Or this one:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="s2">"Fujitsu, a competitor of NEC, acquired Fairchild Corp."</code>
<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="n">extract_rel_match</code><code class="p">(</code><code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">),</code> <code class="n">matcher</code><code class="p">),</code> <code class="n">sep</code><code class="o">=</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
(('NEC', 'ORG'), 'acquires', ('Fairchild', 'ORG'))
</pre>

<p>Obviously, our <a contenteditable="false" data-type="indexterm" data-primary="passive clauses" id="idm45634172137784"/>rule wasn’t made for passive clauses (“was acquired by”) where the subject and object switch positions. We also cannot handle insertions containing named entities or negations because they produce false matches. To treat those cases correctly, we need knowledge about the syntactical structure of the sentence. And we get that from the dependency tree.</p>

<p>But let’s first remove the unreliable rule for <em>acquires</em> from <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term34" id="idm45634172101816"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term40" id="idm45634172100408"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term41" id="idm45634172099032"/>the matcher:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">if</code> <code class="n">matcher</code><code class="o">.</code><code class="n">has_key</code><code class="p">(</code><code class="s2">"acquires"</code><code class="p">):</code>
    <code class="n">matcher</code><code class="o">.</code><code class="n">remove</code><code class="p">(</code><code class="s2">"acquires"</code><code class="p">)</code>
</pre>
</div></section>

<section data-type="sect2" class="blueprint" data-pdf-bookmark="Blueprint: Extracting Relations Using Dependency Trees"><div class="sect2" id="idm45634172820488">
<h2>Blueprint: Extracting Relations Using Dependency Trees</h2>

<p>The grammatical rules of a <a contenteditable="false" data-type="indexterm" data-primary="visualization of data" data-secondary="with knowledge graphs" data-secondary-sortas="knowledge graphs" id="ch12_term44"/><a contenteditable="false" data-type="indexterm" data-primary="dependency trees for extracting relations" id="ch12_term45"/><a contenteditable="false" data-type="indexterm" data-primary="syntactical dependencies in NLP" id="ch12_term47"/>language impose a syntactical structure on each sentence. Each word serves a certain role in relation to the other words. A noun, for example, can be the subject or the object in a sentence; it depends on its relation to the verb. In linguistic theory, the words of a sentence are hierarchically interdependent, and the task of the parser in an NLP pipeline is to reconstruct these dependencies.<sup><a data-type="noteref" id="idm45634172046632-marker" href="ch12.xhtml#idm45634172046632">13</a></sup> The result is a <em>dependency tree</em>, which can also be <a contenteditable="false" data-type="indexterm" data-primary="displacy (spaCy)" id="idm45634172045112"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="visualizations for" id="idm45634172043976"/><a contenteditable="false" data-type="indexterm" data-primary="visualization of data" data-secondary="with spaCy displacy module" data-secondary-sortas="spaCy displacy module" id="idm45634172042632"/>visualized by <code>displacy</code>:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="s2">"Fujitsu, a competitor of NEC, acquired Fairchild Corp."</code>
<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="n">displacy</code><code class="o">.</code><code class="n">render</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">style</code><code class="o">=</code><code class="s1">'dep'</code><code class="p">,</code>
                <code class="n">options</code><code class="o">=</code><code class="p">{</code><code class="s1">'compact'</code><code class="p">:</code> <code class="bp">False</code><code class="p">,</code> <code class="s1">'distance'</code><code class="p">:</code> <code class="mi">100</code><code class="p">})</code>
</pre>

<figure><div class="figure">
<img src="Images/btap_12in05.jpg" width="1057" height="297"/>
<h6/>
</div></figure>

<p>Each node in the dependency tree represents a word. The edges are labeled with the dependency information. The root is usually the predicate of the sentence, in this case <em>acquired</em>, having a subject (<code>nsubj</code>) and an object (<code>obj</code>) as direct children. This first level, root plus children, already represents the essence of the sentence “Fujitsu acquired Fairchild Corp.”</p>

<p>Let’s also take a look at the example with <a contenteditable="false" data-type="indexterm" data-primary="passive clauses" id="idm45634171983432"/>the passive clause. In this case, the auxiliary verb (<code>auxpass</code>) signals that <em>acquired</em> was used in passive form and <em>Fairchild</em> is the passive subject (<code>nsubjpass</code>):</p>

<figure><div class="figure">
<img src="Images/btap_12in06.jpg" width="1012" height="329"/>
<h6/>
</div></figure>

<div data-type="warning" epub:type="warning"><h6>Warning</h6>

<p>The values of the dependency labels depend on the corpus the parser model was trained on. They are also language dependent because different languages have different grammar rules. So, you definitely need to check which tag set is used by the dependency parser.</p></div>

<p>The <a contenteditable="false" data-type="indexterm" data-primary="extract_rel_dep function" id="idm45634171977576"/>function <code>extract_rel_dep</code> implements a rule to identify verb-based relations like <em>acquires</em> based on the dependencies:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">extract_rel_dep</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">pred_name</code><code class="p">,</code> <code class="n">pred_synonyms</code><code class="p">,</code> <code class="n">excl_prepos</code><code class="o">=</code><code class="p">[]):</code>
    <code class="k">for</code> <code class="n">token</code> <code class="ow">in</code> <code class="n">doc</code><code class="p">:</code>
        <code class="k">if</code> <code class="n">token</code><code class="o">.</code><code class="n">pos_</code> <code class="o">==</code> <code class="s1">'VERB'</code> <code class="ow">and</code> <code class="n">token</code><code class="o">.</code><code class="n">lemma_</code> <code class="ow">in</code> <code class="n">pred_synonyms</code><code class="p">:</code>
            <code class="n">pred</code> <code class="o">=</code> <code class="n">token</code>
            <code class="n">passive</code> <code class="o">=</code> <code class="n">is_passive</code><code class="p">(</code><code class="n">pred</code><code class="p">)</code>
            <code class="n">subj</code> <code class="o">=</code> <code class="n">find_subj</code><code class="p">(</code><code class="n">pred</code><code class="p">,</code> <code class="s1">'ORG'</code><code class="p">,</code> <code class="n">passive</code><code class="p">)</code>
            <code class="k">if</code> <code class="n">subj</code> <code class="ow">is</code> <code class="ow">not</code> <code class="bp">None</code><code class="p">:</code>
                <code class="n">obj</code> <code class="o">=</code> <code class="n">find_obj</code><code class="p">(</code><code class="n">pred</code><code class="p">,</code> <code class="s1">'ORG'</code><code class="p">,</code> <code class="n">excl_prepos</code><code class="p">)</code>
                <code class="k">if</code> <code class="n">obj</code> <code class="ow">is</code> <code class="ow">not</code> <code class="bp">None</code><code class="p">:</code>
                    <code class="k">if</code> <code class="n">passive</code><code class="p">:</code> <code class="c1"># switch roles</code>
                        <code class="n">obj</code><code class="p">,</code> <code class="n">subj</code> <code class="o">=</code> <code class="n">subj</code><code class="p">,</code> <code class="n">obj</code>
                    <code class="k">yield</code> <code class="p">((</code><code class="n">subj</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code><code class="p">,</code> <code class="n">subj</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code><code class="p">),</code> <code class="n">pred_name</code><code class="p">,</code>
                           <code class="p">(</code><code class="n">obj</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_n</code><code class="p">,</code> <code class="n">obj</code><code class="o">.</code><code class="n">_</code><code class="o">.</code><code class="n">ref_t</code><code class="p">))</code>
</pre>

<p>The main loop iterates through all tokens in a doc and searches for a verb signaling our relationship. This condition is the same as in the flat pattern rule we used before. But when we detect a possible predicate, we now traverse the dependency tree to find the correct subject and the object. <code>find_subj</code> searches the left subtree, and <code>find_obj</code> searches the right subtree of the predicate. Those functions are not printed in the book, but you can find them in the GitHub notebook for this chapter. They use breadth-first search to find the closest subject and object, as nested sentences may have multiple subjects and objects. Finally, if the predicate indicates a passive clause, the subject and object will be swapped.</p>

<p>Note, that this function also works for the <em>sells</em> relation:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">text</code> <code class="o">=</code> <code class="s2">"""Fujitsu said that Schlumberger Ltd has arranged</code>
<code class="s2">to sell its stake in Fairchild Inc."""</code>
<code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="o">*</code><code class="n">extract_rel_dep</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="s1">'sells'</code><code class="p">,</code> <code class="p">[</code><code class="s1">'sell'</code><code class="p">]),</code> <code class="n">sep</code><code class="o">=</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
(('Schlumberger', 'ORG'), 'sells', ('Fairchild', 'ORG'))
</pre>

<p>In this case, <em>Fairchild Inc.</em> is the closest object in the dependency tree to <em>sell</em> and identified correctly as the object of the investigated relation. But to be the “closest” is not always sufficient. Consider this example:</p>

<figure><div class="figure">
<img src="Images/btap_12in07.jpg" width="1220" height="227"/>
<h6/>
</div></figure>

<p>Actually, we have a three-way relation here: Schlumberger sells Fairchild to Fujitsu. Our <em>sells</em> relation is intended to have the meaning “one company sells [whole or parts of] another company.” The other part is covered by the <em>acquires</em> relation. But how can we detect the right object here? Both Fujitsu and Fairchild are prepositional objects in this sentence (dependency <code>pobj</code>), and Fujitsu is the closest. The preposition is the key: Schlumberger sells something “to” Fujitsu, so that’s not the relation we are looking for. The purpose of the <a contenteditable="false" data-type="indexterm" data-primary="excl_prepos function" id="idm45634171804472"/>parameter <code>excl_prepos</code> in the extraction function is to skip objects with the specified prepositions. Here is the output without (A) and with (B) preposition filter:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">print</code><code class="p">(</code><code class="s2">"A:"</code><code class="p">,</code> <code class="o">*</code><code class="n">extract_rel_dep</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="s1">'sells'</code><code class="p">,</code> <code class="p">[</code><code class="s1">'sell'</code><code class="p">]))</code>
<code class="k">print</code><code class="p">(</code><code class="s2">"B:"</code><code class="p">,</code> <code class="o">*</code><code class="n">extract_rel_dep</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="s1">'sells'</code><code class="p">,</code> <code class="p">[</code><code class="s1">'sell'</code><code class="p">],</code> <code class="p">[</code><code class="s1">'to'</code><code class="p">,</code> <code class="s1">'from'</code><code class="p">]))</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
A: (('Schlumberger', 'ORG'), 'sells', ('Fujitsu', 'ORG'))
B:
</pre>

<p>Let’s check how our new relation extraction function works on a few variations of the examples:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">texts</code> <code class="o">=</code> <code class="p">[</code>
     <code class="s2">"Fairchild Corp was bought by Fujitsu."</code><code class="p">,</code> <code class="c1"># 1</code>
     <code class="s2">"Fujitsu, a competitor of NEC Co, acquired Fairchild Inc."</code><code class="p">,</code> <code class="c1"># 2</code>
     <code class="s2">"Fujitsu is expanding."</code> <code class="o">+</code>
     <code class="s2">"The company made an offer to acquire 80</code><code class="si">% o</code><code class="s2">f Fairchild Inc."</code><code class="p">,</code> <code class="c1"># 3</code>
     <code class="s2">"Fujitsu plans to acquire 80</code><code class="si">% o</code><code class="s2">f Fairchild Corp."</code><code class="p">,</code> <code class="c1"># 4</code>
     <code class="s2">"Fujitsu plans not to acquire Fairchild Corp."</code><code class="p">,</code> <code class="c1"># 5</code>
     <code class="s2">"The competition forced Fujitsu to acquire Fairchild Corp."</code> <code class="c1"># 6</code>
<code class="p">]</code>

<code class="n">acq_synonyms</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'acquire'</code><code class="p">,</code> <code class="s1">'buy'</code><code class="p">,</code> <code class="s1">'purchase'</code><code class="p">]</code>
<code class="k">for</code> <code class="n">i</code><code class="p">,</code> <code class="n">text</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">texts</code><code class="p">):</code>
    <code class="n">doc</code> <code class="o">=</code> <code class="n">nlp</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
    <code class="n">rels</code> <code class="o">=</code> <code class="n">extract_rel_dep</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="s1">'acquires'</code><code class="p">,</code> <code class="n">acq_synonyms</code><code class="p">,</code> <code class="p">[</code><code class="s1">'to'</code><code class="p">,</code> <code class="s1">'from'</code><code class="p">])</code>
    <code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'{i+1}:'</code><code class="p">,</code> <code class="o">*</code><code class="n">rels</code><code class="p">)</code>
</pre>

<p><code>Out:</code></p>

<pre data-type="programlisting">
1: (('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))
2: (('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))
3: (('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))
4: (('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))
5: (('Fujitsu', 'ORG'), 'acquires', ('Fairchild', 'ORG'))
6:
</pre>

<p>As we can see, the relations in the first four sentences have been correctly extracted. Sentence 5, however, contains a negation and still returns <code>acquires</code>. This is a typical case of a false positive. We could extend our rules to handle this case correctly, but negations are rare in our corpus, and we accept the uncertainty in favor of the simpler algorithm. Sentence 6, in contrast, is an example for a possible false negative. Even though the relation was mentioned, it was not detected because the subject in this sentence is <em>competition</em> and not one of the companies.</p>

<p>Actually, dependency-based rules are inherently complex, and <a contenteditable="false" data-type="indexterm" data-primary="precision and recall" id="idm45634171578344"/>every approach to make them more precise results in even more complexity. It is a challenge to find a good balance between precision (fewer false positives) and <a contenteditable="false" data-type="indexterm" data-primary="recall" id="idm45634171576936"/>recall (fewer false negatives) without making the code too complex.</p>

<p>Despite those deficiencies, the dependency-based rule still yields good results. This last step in the process, however, depends on the correctness of named-entity recognition, coreference resolution, and dependency parsing, all of which are not working with 100% accuracy. So, there will always be some false positives and false negatives. But the approach is <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term37" id="idm45634171574904"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term44" id="idm45634171573528"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term45" id="idm45634171572152"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term47" id="idm45634171570776"/>good enough to produce highly interesting knowledge graphs, as we will do in the next section.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Creating the Knowledge Graph"><div class="sect1" id="idm45634172835416">
<h1>Creating the Knowledge Graph</h1>

<p>Now that we know how to extract certain relationships, we can put everything together and create a knowledge graph from the <a contenteditable="false" data-type="indexterm" data-primary="Reuters News Archive" id="ch12_term50"/><a contenteditable="false" data-type="indexterm" data-primary="datasets, examples of" data-secondary="Reuters News Archive" id="ch12_term51"/>entire Reuters corpus. We will extract organizations, persons and the four relations “acquires,” “sells,” “subsidiary-of,” and “executive-of.” <a data-type="xref" href="#fig-knowledge-graph">Figure 12-6</a> shows the <a contenteditable="false" data-type="indexterm" data-primary="visualization of data" data-secondary="with knowledge graphs" data-secondary-sortas="knowledge graphs" id="idm45634171563720"/>resulting graph with some selected <span class="keep-together">subgraphs.</span></p>




<p>To get <a contenteditable="false" data-type="indexterm" data-primary="Gephi" id="idm45634171560936"/>the best results in dependency parsing and named-entity recognition, we use <a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="NLP pipeline for" id="idm45634171559672"/>spaCy’s large model with our complete pipeline. If possible, we will use <a contenteditable="false" data-type="indexterm" data-primary="GPUs (graphics processing units)" id="idm45634171558104"/>the GPU to speed up NLP processing:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">if</code> <code class="n">spacy</code><code class="o">.</code><code class="n">prefer_gpu</code><code class="p">():</code>
    <code class="k">print</code><code class="p">(</code><code class="s2">"Working on GPU."</code><code class="p">)</code>
<code class="k">else</code><code class="p">:</code>
    <code class="k">print</code><code class="p">(</code><code class="s2">"No GPU found, working on CPU."</code><code class="p">)</code>
<code class="n">nlp</code> <code class="o">=</code> <code class="n">spacy</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="s1">'en_core_web_lg'</code><code class="p">)</code>
</pre>

<pre data-code-language="python" data-type="programlisting">
<code class="n">pipes</code> <code class="o">=</code> <code class="p">[</code><code class="n">entity_ruler</code><code class="p">,</code> <code class="n">norm_entities</code><code class="p">,</code> <code class="n">merge_entities</code><code class="p">,</code>
         <code class="n">init_coref</code><code class="p">,</code> <code class="n">alias_resolver</code><code class="p">,</code> <code class="n">name_resolver</code><code class="p">,</code>
         <code class="n">neural_coref</code><code class="p">,</code> <code class="n">anaphor_coref</code><code class="p">,</code> <code class="n">norm_names</code><code class="p">]</code>
<code class="k">for</code> <code class="n">pipe</code> <code class="ow">in</code> <code class="n">pipes</code><code class="p">:</code>
    <code class="n">nlp</code><code class="o">.</code><code class="n">add_pipe</code><code class="p">(</code><code class="n">pipe</code><code class="p">)</code>
</pre>

<p>Before we start the information extraction process, we create two additional rules for the “executive-of” relation similar to the “subsidiary-of” relation and add them to our <a contenteditable="false" data-type="indexterm" data-primary="rule-based matcher (spaCy)" id="idm45634171405016"/><a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="for matching patterns" data-secondary-sortas="matching patterns" id="idm45634171434664"/>rule-based <code>matcher</code>:</p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">ceo_synonyms</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'chairman'</code><code class="p">,</code> <code class="s1">'president'</code><code class="p">,</code> <code class="s1">'director'</code><code class="p">,</code> <code class="s1">'ceo'</code><code class="p">,</code> <code class="s1">'executive'</code><code class="p">]</code>
<code class="n">pattern</code> <code class="o">=</code> <code class="p">[{</code><code class="s1">'ENT_TYPE'</code><code class="p">:</code> <code class="s1">'PERSON'</code><code class="p">},</code>
           <code class="p">{</code><code class="s1">'ENT_TYPE'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'NOT_IN'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'ORG'</code><code class="p">,</code> <code class="s1">'PERSON'</code><code class="p">]},</code> <code class="s1">'OP'</code><code class="p">:</code> <code class="s1">'*'</code><code class="p">},</code>
           <code class="p">{</code><code class="s1">'LOWER'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'IN'</code><code class="p">:</code> <code class="n">ceo_synonyms</code><code class="p">}},</code> <code class="p">{</code><code class="s1">'TEXT'</code><code class="p">:</code> <code class="s1">'of'</code><code class="p">},</code>
           <code class="p">{</code><code class="s1">'ENT_TYPE'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'NOT_IN'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'ORG'</code><code class="p">,</code> <code class="s1">'PERSON'</code><code class="p">]},</code> <code class="s1">'OP'</code><code class="p">:</code> <code class="s1">'*'</code><code class="p">},</code>
           <code class="p">{</code><code class="s1">'ENT_TYPE'</code><code class="p">:</code> <code class="s1">'ORG'</code><code class="p">}]</code>
<code class="n">matcher</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="s1">'executive-of'</code><code class="p">,</code> <code class="bp">None</code><code class="p">,</code> <code class="n">pattern</code><code class="p">)</code>

<code class="n">pattern</code> <code class="o">=</code> <code class="p">[{</code><code class="s1">'ENT_TYPE'</code><code class="p">:</code> <code class="s1">'ORG'</code><code class="p">},</code>
           <code class="p">{</code><code class="s1">'LOWER'</code><code class="p">:</code> <code class="p">{</code><code class="s1">'IN'</code><code class="p">:</code> <code class="n">ceo_synonyms</code><code class="p">}},</code>
           <code class="p">{</code><code class="s1">'ENT_TYPE'</code><code class="p">:</code> <code class="s1">'PERSON'</code><code class="p">}]</code>
<code class="n">matcher</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="s1">'rev-executive-of'</code><code class="p">,</code> <code class="bp">None</code><code class="p">,</code> <code class="n">pattern</code><code class="p">)</code>
</pre>

<figure><div id="fig-knowledge-graph" class="figure">
  <img src="Images/btap_1206.jpg" width="1264" height="865"/>
  <h6><span class="label">Figure 12-6. </span>The knowledge graph extracted from the Reuters corpus with three selected subgraphs (visualized with the help of Gephi).</h6></div></figure>

<p>We then <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term36" id="idm45634171294696"/>define one function to extract all relationships. Two of our four relations are covered by the <code>matcher</code>, and the other two by the dependency-based matching <span class="keep-together">algorithm:</span></p>

<pre data-code-language="python" data-type="programlisting">
<code class="k">def</code> <code class="nf">extract_rels</code><code class="p">(</code><code class="n">doc</code><code class="p">):</code>
    <code class="k">yield from</code> <code class="n">extract_rel_match</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="n">matcher</code><code class="p">)</code>
    <code class="k">yield from</code> <code class="n">extract_rel_dep</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="s1">'acquires'</code><code class="p">,</code> <code class="n">acq_synonyms</code><code class="p">,</code> <code class="p">[</code><code class="s1">'to'</code><code class="p">,</code> <code class="s1">'from'</code><code class="p">])</code>
    <code class="k">yield from</code> <code class="n">extract_rel_dep</code><code class="p">(</code><code class="n">doc</code><code class="p">,</code> <code class="s1">'sells'</code><code class="p">,</code> <code class="p">[</code><code class="s1">'sell'</code><code class="p">],</code> <code class="p">[</code><code class="s1">'to'</code><code class="p">,</code> <code class="s1">'from'</code><code class="p">])</code>
</pre>

<p>The remaining steps to extract the relations, convert them <a contenteditable="false" data-type="indexterm" data-primary="NetworkX graph library (Python)" id="idm45634171290712"/>into a NetworkX graph, and store the graph <a contenteditable="false" data-type="indexterm" data-primary="gexf file format" id="idm45634171166616"/>in a <code>gexf</code> file for Gephi are basically following <a data-type="xref" href="#ch12-cooc">“Blueprint: Creating a Co-Occurrence Graph”</a>. We skip them here, but you will find the full code again in the GitHub repository. </p>

<p>Here are a few records of the final data frame containing the nodes and edges of the graph as they are written to the <code>gexf</code> file:</p>



<table class="dataframe tex2jax_ignore">
  <thead>
    <tr>
      <th/>
      <th>subj</th>
      <th>subj_type</th>
      <th>pred</th>
      <th>obj</th>
      <th>obj_type</th>
      <th>freq</th>
      <th>articles</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>883</th>
      <td>Trans World Airlines</td>
      <td>ORG</td>
      <td>acquires</td>
      <td>USAir Group</td>
      <td>ORG</td>
      <td>7</td>
      <td>2950,2948,3013,3095,1862,1836,7650</td>
    </tr>
    <tr>
      <th>152</th>
      <td>Carl Icahn</td>
      <td>PERSON</td>
      <td>executive-of</td>
      <td>Trans World Airlines</td>
      <td>ORG</td>
      <td>3</td>
      <td>1836,2799,3095</td>
    </tr>
    <tr>
      <th>884</th>
      <td>Trans World Airlines</td>
      <td>ORG</td>
      <td>sells</td>
      <td>USAir Group</td>
      <td>ORG</td>
      <td>1</td>
      <td>9487</td>
    </tr>
  </tbody>
</table>


<p>The visualization of the Reuters graph in <a data-type="xref" href="#fig-knowledge-graph">Figure 12-6</a> was again created with the help of Gephi. The graph consists of many rather small components (disconnected subgraphs); because most companies got mentioned in only one or two news articles and we extracted only the four relations, simple co-occurrences are not included here. We manually magnified three of those subgraphs in the figure. They represent company networks that already appeared in the co-occurrence graph (<a data-type="xref" href="#fig-cooc">Figure 12-5</a>), but now we know the relation types and get a <a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term50" id="idm45634171243528"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch12_term51" id="idm45634171242152"/>much clearer picture.</p>

<section data-type="sect2" data-pdf-bookmark="Don’t Blindly Trust the Results"><div class="sect2" id="idm45634171240520">
<h2>Don’t Blindly Trust the Results</h2>

<p>Each processing step we went through has a potential of errors. Thus, the information stored in the graph is not completely reliable. In fact, this starts with data quality in the articles themselves. If you look carefully at the upper-left example in <a data-type="xref" href="#fig-knowledge-graph">Figure 12-6</a>, you will notice that the two entities “Fujitsu” and “Futjitsu” appear in the graph. This is indeed a <a contenteditable="false" data-type="indexterm" data-primary="spelling discrepancies" id="idm45634171237832"/>spelling error in the original text. </p>

<p>In the magnified subnetwork to the right in <a data-type="xref" href="#fig-knowledge-graph">Figure 12-6</a> you can spot the seemingly contradictory information that “Piedmont acquires USAir” and “USAir acquires Piedmont.” In fact, both are true because both enterprises acquired parts of the shares of the other one. But it could also be a mistake by one of the involved rules or models. To track this kind of problem, it is indispensable to store some information about the source of the extracted relations. That’s why we included the list of articles in every record. </p>

<p>Finally, be aware that our analysis did not consider one aspect at all: the timeliness of information. The world is constantly changing and so are the relationships. Each edge in our graph should therefore get time stamped. So, there is still much to be done to create a knowledge base with trustable information, but our blueprint provides a solid foundation for getting started.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Closing Remarks"><div class="sect1" id="idm45634171568904">
<h1>Closing Remarks</h1>

<p>In this chapter, we explored <a contenteditable="false" data-type="indexterm" data-primary="knowledge graphs" id="idm45634171132920"/>how to build a knowledge graph by extracting structured information from unstructured text. We went through the whole process of information extraction, from named-entity recognition via coreference resolution to relation extraction. </p>

<p>As you have seen, each step is a challenge in itself, and we always have the choice between a rule-based and a model-based approach. <a contenteditable="false" data-type="indexterm" data-primary="rule-based heuristics for knowledge graphs" id="idm45634171131032"/>Rule-based approaches have the advantage that you don’t need <a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="data for" id="idm45634171129736"/>training data. So, you can start right away; you just need to define the rules. But if the entity type or relationship you try to capture is complex to describe, you end up either with rules that are too simple and return a lot of false matches or with rules that are extremely complex and hard to maintain. When using rules, it is always difficult to find a good balance between recall (find most of the matches) and precision (find only correct matches). And you need quite a bit of technical, linguistic, and domain expertise to write good rules. In practice, you will also have to test and experiment a lot until your rules are robust enough for your application.</p>

<p>Model-based <a contenteditable="false" data-type="indexterm" data-primary="machine learning models" data-secondary="training of" id="idm45634171127128"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="of machine learning models" data-secondary-sortas="machine learning models" id="idm45634171125720"/>approaches, in contrast, have the great advantage that they learn those rules from the training data. Of course, the downside is that you need lots of high-quality training data. And if those training data are specific to your application domain, you have to create them yourself. The manual labeling of training data is especially cumbersome and time-consuming in the area of text because somebody has to read and understand the text before the labels can be set. In fact, getting good training data is the biggest bottleneck today in machine learning.</p>

<p>A possible solution to the problem of <a contenteditable="false" data-type="indexterm" data-primary="missing data" id="idm45634171122888"/>missing training data is <a contenteditable="false" data-type="indexterm" data-primary="weak supervision learning" id="idm45634171121608"/>weak supervision. The idea is to create a large dataset by rules like the ones we defined in this chapter or even to generate them programmatically. Of course, this dataset will be noisy, as the rules are not perfect. But, surprisingly, it is possible to train a high-quality model on low-quality data. Weak supervision learning for named-entity recognition and relationship extraction is, like many other topics covered in this section, a current topic of research. If you want to learn more about the state of the art in information extraction and knowledge graph creation, you can check out the following references. They provide good starting points for further reading.</p>

</div></section>

<section data-type="sect1" class="pagebreak-before less_space" data-pdf-bookmark="Further Reading"><div class="sect1" id="idm45634171119496">
<h1>Further Reading</h1>
<ul class="author-date-bib">
<li>

<p>Barrière, Caroline. <em>Natural Language Understanding in a Semantic Web Context.</em> <span class="keep-together">Switzerland</span>: Springer Publishing. 2016. <a href="https://www.springer.com/de/book/9783319413358"><em>https://www.springer.com/de/book/9783319413358</em></a>.</p>
</li>
<li>

<p>Gao, Yuqing, Jisheng Liang, Benjamin Han, Mohamed Yakout, and Ahmed Mohamed. <em>Building a Large-scale, Accurate and Fresh Knowledge Graph</em>. Tutorial at KDD. 2018. <a href="https://kdd2018tutorialt39.azurewebsites.net"><em>https://kdd2018tutorialt39.azurewebsites.net</em></a>.</p>
</li>
<li>

<p>Han, Xu, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, and Maosong Sun. <em>FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation</em>. Proceedings of EMNLP, 2018. <a href="https://arxiv.org/abs/1810.10147"><em>https://arxiv.org/abs/1810.10147</em></a>.</p>
</li>
<li>

<p>Jurafsky, Dan, and James H. Martin. <em>Speech and Language Processing</em>. 3rd Edition (draft), Chapters 18 and 22. 2019. <a href="https://web.stanford.edu/~jurafsky/slp3"><em>https://web.stanford.edu/~jurafsky/slp3</em></a>.</p>
</li>
<li>

<p>Lison, Pierre, Aliaksandr Hubin, Jeremy Barnes, and Samia Touileb. <em>Named-Entity Recognition without Labelled Data: A Weak Supervision Approach</em>. Proceedings of ACL, 2020 <a href="https://arxiv.org/abs/2004.14723"><em>https://arxiv.org/abs/2004.14723</em></a>.</p>
</li>
</ul></div></section>

<div data-type="footnotes"><p data-type="footnote" id="idm45634176075192"><sup><a href="ch12.xhtml#idm45634176075192-marker">1</a></sup> See Natasha Noy, Yuqing Gao, Anshu Jain, Anant Narayanan, Alan Patterson, and Jamie Taylor. <em>Industry-scale Knowledge Graphs: Lessons and Challenges</em>. 2019. <a href="https://queue.acm.org/detail.cfm?id=3332266"><em>https://queue.acm.org/detail.cfm?id=3332266</em></a>.</p><p data-type="footnote" id="idm45634176061992"><sup><a href="ch12.xhtml#idm45634176061992-marker">2</a></sup> See <a href="https://oreil.ly/nzhUR"><em>https://oreil.ly/nzhUR</em></a> for details.</p><p data-type="footnote" id="idm45634176054984"><sup><a href="ch12.xhtml#idm45634176054984-marker">3</a></sup> Tim Berners-Lee et al., “The Semantic Web: a New Form of Web Content that is Meaningful to Computers Will Unleash a Revolution of New Possibilities.” <em>Scientific American</em> 284 No. 5: May 2001.</p><p data-type="footnote" id="idm45634175830936"><sup><a href="ch12.xhtml#idm45634175830936-marker">4</a></sup> The asterisk operator (*) unpacks the list into separate arguments for <code>print</code>.</p><p data-type="footnote" id="idm45634175637736"><sup><a href="ch12.xhtml#idm45634175637736-marker">5</a></sup> See <a href="https://oreil.ly/Hvtgs" class="">spaCy’s rule-based matching usage docs</a> for an explanation of the syntax, and check out the interactive pattern explorer on <a href="https://explosion.ai/demos/matcher"><em>https://explosion.ai/demos/matcher</em></a>.</p><p data-type="footnote" id="idm45634174792232"><sup><a href="ch12.xhtml#idm45634174792232-marker">6</a></sup> You will find an additional blueprint for acronym detection in the notebook for this chapter on <a href="https://oreil.ly/LlPHm">GitHub</a>.</p><p data-type="footnote" id="idm45634173992248"><sup><a href="ch12.xhtml#idm45634173992248-marker">7</a></sup> See Wolf (2017),<a href="https://oreil.ly/VV4Uy">“State-Of-The-Art Neural Coreference Resolution For Chatbots”</a> for more.</p><p data-type="footnote" id="idm45634173497096"><sup><a href="ch12.xhtml#idm45634173497096-marker">8</a></sup> This slogan was coined by Google when it introduced its knowledge graph in 2012.</p><p data-type="footnote" id="idm45634173458648"><sup><a href="ch12.xhtml#idm45634173458648-marker">9</a></sup> You’ll find the colorized figures in the electronic versions of this book and in our <a href="https://oreil.ly/2ju0k">GitHub repository</a>.</p><p data-type="footnote" id="idm45634172970888"><sup><a href="ch12.xhtml#idm45634172970888-marker">10</a></sup> You can find a NetworkX version of the graph in the notebook for this chapter on <a href="https://oreil.ly/OWTcO">GitHub</a>.</p><p data-type="footnote" id="idm45634172964856"><sup><a href="ch12.xhtml#idm45634172964856-marker">11</a></sup> We provide more details on that in our <a href="https://oreil.ly/nri01">GitHub repository</a> for this chapter.</p><p data-type="footnote" id="idm45634172825528"><sup><a href="ch12.xhtml#idm45634172825528-marker">12</a></sup> See an overview of the <a href="https://oreil.ly/l6DIH">state of the art</a>.</p><p data-type="footnote" id="idm45634172046632"><sup><a href="ch12.xhtml#idm45634172046632-marker">13</a></sup> Constituency parsers, in contrast to dependency parsers, create a hierarchical sentence structure based on nested phrases.</p></div></div></section></div>



  </body></html>