- en: Chapter 14\. Data Exchange
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data can be stored and exchanged in many different formats. Thus far, we’ve
    focused on plain-text delimited and fixed-width formats ([Chapter 8](ch08.html#ch-files)).
    In this chapter, we expand our horizons a bit and introduce a few other popular
    formats. While CSV, TSV, and FWF files are useful for organizing data into a dataframe,
    other file formats can save space or represent more complex data structures. *Binary*
    files (*binary* is a term for formats that aren’t plaintext) can be more economical
    than plain-text data sources. For example, in this chapter we introduce NetCDF,
    a popular binary format for exchanging large amounts of scientific data. Other
    plain-text formats like JSON and XML can organize data in ways that are more general
    and useful for complex data structures. Even HTML web pages, a close cousin to
    XML, often contain useful information that we can scrape and wrangle into shape
    for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we introduce these popular formats, describe a mental model
    for their organization, and provide examples. In addition to introducing these
    formats, we cover programmatic ways to acquire data online. Before the internet,
    data scientists had to physically move disk drives to share data with one another.
    Now we can freely retrieve datasets from computers across the world. We introduce
    HTTP, the primary communication protocol for the web, and REST, an architecture
    to transfer data. By learning a bit about these web technologies, we can take
    better advantage of the web as a data source.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, we have set an example of reproducible code for wrangling,
    exploring, and modeling with data. In this chapter, we address how to acquire
    data that are available online in a reproducible fashion.
  prefs: []
  type: TYPE_NORMAL
- en: We begin with a description of NetCDF, followed by JSON. Then, after an overview
    of web protocols for data exchange, we wrap up the chapter with an introduction
    to XML, HTML, and XPath, a tool for extracting content from these types of files.
  prefs: []
  type: TYPE_NORMAL
- en: NetCDF Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The [Network Common Data Form (NetCDF)](https://oreil.ly/_qZGj) is a convenient
    and efficient format for storing array-oriented scientific data. A mental model
    for this format represents a variable by a multidimensional grid of values. The
    diagram in [Figure 14-1](#netcdf-diagram) shows the concept. A variable such as
    rainfall is recorded daily at places around the globe. We can imagine these rainfall
    values arranged in a cube with longitude running along one side of the cube, latitude
    along another, and date in the third dimension. Each cell in the cube holds the
    rainfall recorded for one day at a particular location. A NetCDF file also contains
    information, which we call *metadata*, about the dimensions of the cube. The same
    information would be organized quite differently in a dataframe, where we would
    need three features for latitude, longitude, and date for each rainfall measurement.
    This would mean repeating lots of data. With a NetCDF file, we don’t need to repeat
    the latitude and longitude values for each day, nor the dates for each location.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_1401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-1\. This diagram represents a model for NetCDF data. The data are
    organized into a three-dimensional array that contains recordings of rainfall
    at locations in time (latitude, longitude, and time). The “X” marks one rainfall
    measurement for a specific location on a particular date.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'NetCDF has several other advantages, in addition to being more compact:'
  prefs: []
  type: TYPE_NORMAL
- en: Scalable
  prefs: []
  type: TYPE_NORMAL
- en: It provides efficient access to subsets of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Appendable
  prefs: []
  type: TYPE_NORMAL
- en: You can easily add new data without redefining the structure.
  prefs: []
  type: TYPE_NORMAL
- en: Sharable
  prefs: []
  type: TYPE_NORMAL
- en: It’s a common format that’s independent of the coding language and operating
    system.
  prefs: []
  type: TYPE_NORMAL
- en: Self-describing
  prefs: []
  type: TYPE_NORMAL
- en: The source file contains both a description of the data’s organization and the
    data itself.
  prefs: []
  type: TYPE_NORMAL
- en: Community
  prefs: []
  type: TYPE_NORMAL
- en: The tools are made available by a community of users.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The NetCDF format is an example of *binary* data—data that can’t directly be
    read into a text editor like `vim` or Visual Studio Code, unlike text formats
    like CSV. There are a multitude of other binary data formats, including SQLite
    databases (from [Chapter 7](ch07.html#ch-sql)), Feather, and Apache Arrow. Binary
    data formats provide flexibility in how datasets are stored, but they also typically
    need special tools to open and read them in.
  prefs: []
  type: TYPE_NORMAL
- en: NetCDF variables are not limited to three dimensions. For example, elevation
    could be added to our earth science application so that we have recordings of,
    say, temperature, in time, latitude, longitude, and elevation. And dimensions
    need not correspond to physical dimensions. Climate scientists often run several
    models and store the model number in a dimension along with the model output.
    While NetCDF was originally developed for atmospheric scientists at the University
    Corporation for Atmospheric Research (UCAR), the format has gained popularity
    and is now used at thousands of educational, research, and government sites around
    the world. And the applications have expanded to other areas, such as astronomy
    and physics with the [Smithsonian/NASA Astrophysics Data System (ADS)](https://oreil.ly/kg9kV)
    and medical imaging with [Medical Image NetCDF (MINC)](https://oreil.ly/6t3gJ).
  prefs: []
  type: TYPE_NORMAL
- en: 'NetCDF files have three basic components: dimensions, variables, and various
    sorts of metadata. The *variable* contains what we think of as the data, such
    as the rainfall recordings. Each variable has a name, storage type, and shape,
    meaning the number of dimensions. The *dimensions* component gives each dimension’s
    name and number of grid points. Additional information is provided by the *coordinates*—in
    particular, the points at which the measurements are made, such as for longitude,
    where these might be <math><mn>0.0</mn> <mo>,</mo> <mn>0.25</mn> <mo>,</mo> <mn>0.50</mn>
    <mo>,</mo> <mo>…</mo> <mo>,</mo> <mn>359.75</mn></math> . Other metadata include
    *attributes*. Attributes for a variable can hold ancillary information about the
    variables, and other attributes contain global information about the file, such
    as who published the dataset, their contact information, and permissions for using
    the data. This global information is critical to ensure reproducible results.'
  prefs: []
  type: TYPE_NORMAL
- en: The following example examines the components of a particular NetCDF file and
    demonstrates how to extract portions of data from variables.
  prefs: []
  type: TYPE_NORMAL
- en: The [Climate Data Store](https://oreil.ly/NAhRW) provides a collection of datasets
    from various climate sectors and services. We visited their site and requested
    measurements of temperature and total precipitation for a two-week period in December
    2022\. Let’s walk through a brief examination of these data to get a sense of
    the organization of the components in the file, how to extract subsets, and how
    to make visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data are in the NetCDF file *CDS_ERA5_22-12.nc*. Let’s first figure out
    how large the file is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Despite having only three variables (total precipitation, rain rate, temperature)
    for two weeks, the file is two GiB in size! These climate sources often tend to
    be quite large.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `xarray` package is useful for working with array-like data and, in particular,
    NetCDF. We use its functionality to explore the components of our climate file.
    First we open the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s check the dimensions component of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As in [Figure 14-1](#netcdf-diagram), our file has three dimensions: longitude,
    latitude, and time. The size of each dimension tells us that there are over 400,000
    cells of data values (1440 × 721 × 408). If these data were in a dataframe, then
    it would have 400,000 rows with latitude, longitude, and time columns in great
    repetition! Instead, we only need their values once, and the coordinates component
    gives them to us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Each variable in our file is three-dimensional. Actually, a variable doesn’t
    have to have all three dimensions, but in our example they do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Metadata for a variable provides the units and a longer description, while
    metadata for the source gives us information such as when we retrieved the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: By keeping all of these pieces of information in the source file itself, we
    don’t risk losing it or having the description get out of sync with the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like with `pandas`, `xarray` provides many different ways to select portions
    of the data to work with. We show two examples. First we focus on one specific
    location and examine the total precipitation in time with a line plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_14in01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next we choose one date, December 31, 2022, at 1 p.m., and narrow down the
    latitude and longitude to the continental US to make a map of temperature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Like `loc` for dataframes, `sel` returns a new `DataArray` whose data is determined
    by the index labels along the specified dimension, which for this example is the
    date. And like `np.where`, `xr.where` returns elements depending on the logical
    condition provided. We use `drop=True` to reduce the size of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make a choropleth map of temperature, where color represents the temperature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/leds_14in02.png)'
  prefs: []
  type: TYPE_IMG
- en: We can make out the shape of the US, the warm Caribbean, and the colder mountain
    ranges from this map.
  prefs: []
  type: TYPE_NORMAL
- en: 'We wrap up by closing the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This brief introduction to NetCDF is meant to touch on the basic concepts. Our
    main goal is to show that other kinds of data formats exist and can have advantages
    over plain-text read into a dataframe. For interested readers, NetCDF has a rich
    ecosystem of packages and functionality. For example, in addition to the `xarray`
    module, NetCDF files can be read with other Python modules like [`netCDF4`](https://oreil.ly/UlX_k)
    and [`gdal`](https://oreil.ly/fKeQh). The NetCDF community has also provided command-line
    tools for interacting with NetCDF data. And to make visualizations and maps, options
    include `matplotlib`, [`iris`](https://oreil.ly/ozNrI), which is built on top
    of `netCDF4`, and [`cartopy`](https://oreil.ly/9N7y7).
  prefs: []
  type: TYPE_NORMAL
- en: Next we consider the JSON format, which offers more flexibility to represent
    hierarchical data than the CSV and FWF formats.
  prefs: []
  type: TYPE_NORMAL
- en: JSON Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: JavaScript Object Notation (JSON) is a popular format for exchanging data on
    the web. This plain-text format has a simple and flexible syntax that aligns well
    with Python dictionaries, and it is easy for machines to parse and people to read.
  prefs: []
  type: TYPE_NORMAL
- en: 'Briefly, JSON has two main structures, the object and the array:'
  prefs: []
  type: TYPE_NORMAL
- en: Object
  prefs: []
  type: TYPE_NORMAL
- en: Like a Python `dict`, a JSON object is an unordered collection of name-value
    pairs. These pairs are contained in curly braces; each is formatted as `"name":value`,
    and separated by commas.
  prefs: []
  type: TYPE_NORMAL
- en: Array
  prefs: []
  type: TYPE_NORMAL
- en: Like a Python `list`, a JSON array is an ordered collection of values contained
    in square brackets, where the values are unnamed and separated by commas.
  prefs: []
  type: TYPE_NORMAL
- en: The values in an object and array can be of different types and can be nested.
    That is, an array can contain objects and vice versa. The primitive types are
    limited to string in double quotes, number in text representation, logical as
    true or false, and null.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following short JSON file demonstrates all of these syntactical features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we have an object that contains six name-value pairs. The values are heterogeneous;
    four are primitive values: string, number, logical, and null. The `status` value
    consists of an array of three (ordered) numbers, and `lender_dem` is an object
    with demographic information.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The built-in `json` package can be used to work with JSON files in Python.
    For example, we can load this small file into a Python dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The dictionary matches the format of the Kiva file. This format doesn’t naturally
    translate to a dataframe. The `json_normalize` method can organize this semistructured
    JSON data into a flat table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '|   | lender_id | loan_count | status | sponsored | sponsor_name | lender_dem.sex
    | lender_dem.age |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | matt | 23 | [2, 1, 3] | False | None | m | 77 |'
  prefs: []
  type: TYPE_TB
- en: Notice how the third element in this one-row dataframe is a list, whereas the
    nested object was converted into two columns.
  prefs: []
  type: TYPE_NORMAL
- en: There’s a tremendous amount of flexibility in how data can be structured in
    JSON, which means that if we want to create a dataframe from JSON content, we
    need to understand how the data are organized in the JSON file. We provide three
    structures that translate easily into a dataframe in the next example.
  prefs: []
  type: TYPE_NORMAL
- en: The list of PurpleAir sites used in the case study in [Chapter 12](ch12.html#ch-pa)
    was JSON-formatted. In that chapter, we didn’t call attention to the format and
    simply read the file contents into a dictionary with the `json` library’s `load`
    method and then into a dataframe. Here, we have simplified that file while maintaining
    the general structure so that it’s easier to examine.
  prefs: []
  type: TYPE_NORMAL
- en: We begin with an examination of the original file, and then reorganize it into
    two other JSON structures that might also be used to represent a dataframe. With
    these examples we aim to show the flexibility of JSON. The diagrams in [Figure 14-2](#json-diagram)
    give representations of the three possibilities.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_1402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-2\. Three different approaches for a JSON-formatted file to store
    a dataframe.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The leftmost dataframe in the diagram shows an organization by rows. Each row
    is an object of named values where the name corresponds to the column name of
    the dataframe. Rows would then be collected in an array. This structure coincides
    with that of the original file. In the following code, we display the file contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We see that the file consists of one object with two elements, named `Header`
    and `Data`. The `Data` element is an array with an element for each row in the
    dataframe, and as described earlier each element is an object. Let’s load the
    file into a dictionary and check its contents (see [Chapter 8](ch08.html#ch-files)
    for more on finding a pathname to a file and printing its contents):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We can quickly convert the array of objects into a dataframe with the following
    call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '|   | site | date | aqi |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | 0014 | 02-27 | 30.0 |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | 0014 | 02-24 | 17.0 |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | 0014 | 02-21 | 60.0 |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | 0014 | 01-15 | NaN |'
  prefs: []
  type: TYPE_TB
- en: 'The middle diagram in [Figure 14-2](#json-diagram) takes a column approach
    to organizing the data. Here the columns are provided as arrays and collected
    into an object with names that match the column names. The following file demonstrates
    the concept:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Since `pd.read_json()` expects this format, we can read the file into a dataframe
    directly without needing to first load it into a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '|   | site | date | aqi |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | 14 | 02-27 | 30.0 |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | 14 | 02-24 | 17.0 |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | 14 | 02-21 | 60.0 |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | 14 | 01-15 | NaN |'
  prefs: []
  type: TYPE_TB
- en: 'Lastly, we organize the data into a structure that resembles a matrix (the
    diagram on the right in the figure) and separately provide the column names for
    the features. The data matrix is organized as an array of arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We can provide `vars` and `data` to create the dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '|   | site | date | aqi |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **0** | 0014 | 02-27 | 30.0 |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | 0014 | 02-24 | 17.0 |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | 0014 | 02-21 | 60.0 |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | 0014 | 01-15 | NaN |'
  prefs: []
  type: TYPE_TB
- en: 'We’ve included these examples to show the versatility of JSON. The main takeaway
    is that JSON files can arrange data in different ways, so we typically need to
    examine the file before we can read the data into a dataframe successfully. JSON
    files are very common for data stored on the web: the examples in this section
    were files downloaded from the PurpleAir and Kiva websites. Although we downloaded
    the data manually in this section, we often want to download many datafiles at
    a time, or we want a reliable and reproducible record of the download. In the
    next section, we introduce HTTP, a protocol that will let us write programs to
    download data from the web automatically.'
  prefs: []
  type: TYPE_NORMAL
- en: HTTP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HTTP (HyperText Transfer Protocol) is an all-purpose infrastructure to access
    resources on the web. There are a tremendous number of datasets available to us
    on the internet, and with HTTP we can acquire these datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The internet allows computers to communicate with each other, and HTTP places
    a structure on the communication. HTTP is a simple *request-response* protocol,
    where a client submits a *request* to a server in a specially formatted text message,
    and the server sends a specially formatted text *response* back. The client might
    be a web browser or our Python session.
  prefs: []
  type: TYPE_NORMAL
- en: 'An HTTP request has two parts: a header and an optional body. The header must
    follow a specific syntax. An example request to obtain the Wikipedia page shown
    in [Figure 14-3](#fig-wiki-1500) looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The first line contains three pieces of information: it starts with the method
    of the request, which is `GET`; this is followed by the URL of the web page we
    want; and last is the protocol and version. Each of the three lines that follow
    give auxiliary information for the server. This information has the format `name:
    value`. Finally, a blank line marks the end of the header. Note that we’ve marked
    the blank line with `{blank_line}` in the preceding snippet; in the actual message,
    this is a blank line.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_1403.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-3\. Screenshot of the Wikipedia page with data on the world record
    for the 1,500-meter race
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The client’s computer sends this message over the internet to the Wikipedia
    server. The server processes the request and sends a response, which also consists
    of a header and body. The header for the response looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The first line states that the request completed successfully; the status code
    is 200\. The next lines give additional information for the client. We shortened
    this header quite a bit to focus on just a few pieces of information that tell
    us the content of the body is HTML and uses UTF-8 encoding, and the content is
    153,912 characters long. Finally, the blank line at the end of the header tells
    the client that the server has finished sending header information, and the response
    body follows.
  prefs: []
  type: TYPE_NORMAL
- en: HTTP is used in almost every application that interacts with the internet. For
    example, if you visit this same Wikipedia page in your web browser, the browser
    makes the same basic HTTP request as the one just shown. When it receives the
    response, it displays the body in your browser’s window, which looks like the
    screenshot in [Figure 14-3](#fig-wiki-1500).
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, we do not write out full HTTP requests ourselves. Instead, we
    use tools like the `requests` Python library to construct requests for us. The
    following code constructs the HTTP request for the page in [Figure 14-3](#fig-wiki-1500)
    for us. We simply pass the URL to `requests.get`. The “get” in the name indicates
    the `GET` method is being used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check our request’s status to make sure the server completed it successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We can thoroughly examine the request and response through the object’s attributes.
    As an example, let’s take a look at the key-value pairs in the header in our request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Although we did not specify any header information in our function call, `request.get`
    provided some basic information for us. If we need to send special header information,
    we can specify them in our call.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s examine the header of the response we received from the server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'As we saw earlier, there’s a lot of header information in the response. We
    just display the `date`, `content-type`, and `content-length`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we display the first several hundred characters of the response body
    (the entire content is too long to display nicely here):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: We confirm that the response is an HTML document and that it contains the title
    `1500 metres world record progression - Wikipedia`. We have successfully retrieved
    the web page shown in [Figure 14-3](#fig-wiki-1500).
  prefs: []
  type: TYPE_NORMAL
- en: Our HTTP request has been successful, and the server has returned a status code
    of `200`. There are hundreds of other HTTP status codes. Thankfully, they are
    grouped into categories to make them easier to remember (see [Table 14-1](#response-codes)).
  prefs: []
  type: TYPE_NORMAL
- en: Table 14-1\. Response status codes
  prefs: []
  type: TYPE_NORMAL
- en: '| Code | Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 100s | Informational | More input is expected from the client or server (100
    Continue, 102 Processing, etc.). |'
  prefs: []
  type: TYPE_TB
- en: '| 200s | Success | The client’s request was successful (200 OK, 202 Accepted,
    etc.). |'
  prefs: []
  type: TYPE_TB
- en: '| 300s | The redirection | Requested URL is located elsewhere and may need
    further action from the user (300 Multiple Choices, 301 Moved Permanently, etc.).
    |'
  prefs: []
  type: TYPE_TB
- en: '| 400s | Client error | A client-side error occurred (400 Bad Request, 403
    Forbidden, 404 Not Found, etc.). |'
  prefs: []
  type: TYPE_TB
- en: '| 500s | Server error | A server-side error occurred or the server is incapable
    of performing the request (500 Internal Server Error, 503 Service Unavailable,
    etc.). |'
  prefs: []
  type: TYPE_TB
- en: 'One common error code that might look familiar is 404, which tells us we have
    requested a resource that doesn’t exist. We send such a request here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The request we made to retrieve the web page was a `GET` HTTP request. There
    are four main HTTP request types: `GET`, `POST`, `PUT`, and `DELETE`. The two
    most commonly used methods are `GET` and `POST`. We just used `GET` to retrieve
    the web page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: The `POST` request is used to send specific information from the client to the
    server. In the next section, we use `POST` to retrieve data from Spotify.
  prefs: []
  type: TYPE_NORMAL
- en: REST
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Web services are increasingly implementing the REST (REpresentational State
    Transfer) architecture for developers to access their data. These include social
    media platforms like Twitter and Instagram, music apps like Spotify, real estate
    apps like Zillow, scientific sources of data such as the Climate Data Store, government
    data at the World Bank, and many, many more. The basic idea behind REST is that
    every URL identifies a resource (data).
  prefs: []
  type: TYPE_NORMAL
- en: 'REST is *stateless*, meaning that the server does not remember the client from
    one request to the next. This aspect of REST has a few advantages: the server
    and the client can understand any message received without seeing previous messages,
    code can be changed on either the client or server side without impacting the
    operation of the service, and access is scalable, fast, modular, and independent.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we work through an example to retrieve data from Spotify.
  prefs: []
  type: TYPE_NORMAL
- en: Our example follows [Steven Morse’s blog post](https://oreil.ly/zI-5z), where
    we use both `POST` and `GET` methods in a series of requests to retrieve data
    on songs by [The Clash](https://www.theclash.com).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In practice, we wouldn’t write `GET` and `POST` requests ourselves for Spotify.
    Instead, we’d use the [`spotipy`](https://oreil.ly/fPQX0) library, which has functions
    to interact with the [Spotify web API](https://oreil.ly/NH4ZO). That said, data
    scientists can often find themselves in the position of wanting to access data
    available via REST that doesn’t have a Python library available, so this section
    shows how to get data from a RESTful website like Spotify.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, a REST application provides documentation with examples on how to
    request its data. Spotify has extensive documentation geared to developers who
    want to build an app, but we can also access the service just to explore data.
    To do that, we need to register as a developer and get a client ID and secret.
    We then use these to identify us to Spotify in our HTTP requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'After we register, we can begin to request data. This process has two steps:
    authenticate and request resources.'
  prefs: []
  type: TYPE_NORMAL
- en: To authenticate, we issue a POST request, where we give the web service our
    client ID and secret. We provide these in the header of the request. In return,
    we receive a token from the server that authorizes us to make requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin the process and authenticate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'We provided our ID and secret in key-value pairs in the header of our POST
    request. We can check the status of our request to see if it was successful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s check the type of content in the body of the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The body of the response contains the token that we need in the next step to
    get the data. Since this information is JSON-formatted, we can check the keys
    and retrieve the token:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we hid our ID and secret so that others reading this book can’t
    imitate us. This request won’t be successful without a valid ID and secret. For
    example, here we make up an ID and secret and try to authenticate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'We check the status of this “bad” request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'According to [Table 14-1](#response-codes), a code of 400 means that we issued
    a bad request. For one more example, Spotify shuts us down if we take too much
    time making requests. We ran into this issue a couple of times when writing this
    section and received the following code, telling us our token had expired:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Now for the second step, let’s get some data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Requests for resources can be made via `GET` for Spotify. Other services may
    require POSTs. Requests must include the token we received from the web service
    when we authenticated, which we can use over and over. We pass the access token
    in the header of our `GET` request. We construct the name-value pairs as a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The developer API tells us that an artist’s albums are available at URLs that
    look like *https://api.spotify.com/v1/artists/3RGLhK1IP9jnYFH4BRFJBS/albums*,
    where the code between *artists/* and */albums* is an artist’s ID. This particular
    code is for The Clash. Information about the tracks on an album is available at
    a URL that looks like *https://api.spotify.com/v1/albums/49kzgMsxHU5CTeb2XmFHjo/tracks*,
    where the identifier here is for the album.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we know the ID for an artist, we can retrieve the IDs for its albums, and
    in turn, we can get data about the tracks on the albums. Our first step was to
    get the ID for The Clash from Spotify’s site:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Our first data request retrieves the group’s albums. We construct the URL using
    `artist_id` and pass our access token in the header:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Our request was successful. Now let’s check the `content-type` of the response
    body:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The resource returned is JSON, so we can load it into a Python dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'After poking around a bit, we can find that album information is in the `items`
    element. The keys for the first album are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s print the album IDs, names, and release dates for a few albums:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'We see that some albums are remastered and others are live performances. Next,
    we cycle through the albums, pick up their IDs, and for each album we request
    information about the tracks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Over a dozen features are available to explore on the tracks. Let’s close the
    example with a plot of danceability and loudness of The Clash songs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_14in03.png)'
  prefs: []
  type: TYPE_IMG
- en: This section covered REST APIs, which provide standardized approaches for programs
    to download data. The example shown here downloaded JSON data. At other times,
    the data from a REST request may be in an XML format. And sometimes a REST API
    isn’t available for the data we want, and we must extract the data from web pages
    themselves in HTML, a format similar to XML. We describe how to work with these
    formats next.
  prefs: []
  type: TYPE_NORMAL
- en: XML, HTML, and XPath
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The eXtensible Markup Language (XML ) can represent all types of information,
    such as data sent to and from web services, including web pages, spreadsheets,
    visual displays like SVG, social network structures, word processing documents
    like Microsoft’s docx, databases, and much more. For a data scientist, knowing
    a little about XML can come in handy.
  prefs: []
  type: TYPE_NORMAL
- en: Despite its name, XML is not a language. Rather, it is a very general structure
    we can use to define formats to represent and organize data. XML provides a basic
    structure and syntax for these “dialects” or vocabularies. If you read or compose
    HTML, you will recognize the format of XML.
  prefs: []
  type: TYPE_NORMAL
- en: The basic unit in XML is the *element*, which is also referred to as a *node*.
    An element has a name and may have attributes, child elements, and text.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following annotated snippet of an XML plant catalog provides an example
    of these pieces (this content is adapted from [W3Schools](https://oreil.ly/qPa6s)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: We added the indentation to this snippet of XML to make it easier to see the
    structure. It is not needed in the actual file.
  prefs: []
  type: TYPE_NORMAL
- en: 'XML documents are plain-text files with the following syntax rules:'
  prefs: []
  type: TYPE_NORMAL
- en: Each element begins with a start tag, like `<plant>`, and closes with an end
    tag of the same name, like `</plant>`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XML elements can contain other XML elements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XML elements can be plain-text, like “Columbine” in `<common>Columbine</common>`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XML elements can have optional attributes. The element `<price curr=“CAD”>`
    has an attribute `curr` with value `"CAD"`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the special case when a node has no children, the end tag can be folded into
    the start tag. An example is `<availability date="0199"/>`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We call an XML document well formed when it follows certain rules. The most
    important of these are:'
  prefs: []
  type: TYPE_NORMAL
- en: One root node contains all of the other elements in the document.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elements nest properly; an open node closes around all of its children and no
    more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tag names are case-sensitive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attribute values have a `name=“value”` format with single or double quotes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are additional rules for a document to be well formed. These relate to
    whitespace, special characters, naming conventions, and repeated attributes.
  prefs: []
  type: TYPE_NORMAL
- en: The hierarchical nature of well-formed XML means it can be represented as a
    tree. [Figure 14-4](#fig-xml-tree) shows a tree representation of the plant catalog
    XML.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_1404.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-4\. Hierarchy of an XML document; the lighter gray boxes represent
    text elements and, by design, these cannot have child nodes
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Like with JSON, an XML document is plaintext. We can read it with a plain-text
    viewer, and it’s easy for machines to read and create XML content. The extensible
    nature of XML allows content to be easily merged into higher-level container documents
    and easily exchanged with other applications. XML also supports binary data and
    arbitrary character sets.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned already, HTML looks a lot like XML. That’s no accident, and indeed,
    XHTML is a subset of HTML that follows the rules of well-formed XML. Let’s return
    to our earlier example of the Wikipedia page that we retrieved from the internet
    and show how to used XML tools to create a dataframe from the contents of one
    of its tables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Scraping Race Times from Wikipedia'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earlier in this chapter, we used an HTTP request to retrieve the HTML page from
    Wikipedia shown in [Figure 14-3](#fig-wiki-1500). The contents of this page are
    in HTML, which is essentially an XML vocabulary. We can use the hierarchical structure
    of the page and XML tools to access data in one of the tables and wrangle it into
    a dataframe. In particular, we are interested in the second table in the page,
    a portion of which appears in the screenshot in [Figure 14-5](#fig-html-table).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_1405.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-5\. Screenshot of the second table in a web page that contains the
    data we want to extract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Before we work on this table, we provide a quick summary of the format for
    a basic HTML table. Here is the HTML for a table with a header and two rows of
    three columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the table is laid out in rows with `<tr>` elements, and each cell
    in a row is a `<td>` element that contains the text to be displayed in the table.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first task is to create a tree structure from the content of the web page.
    To do this, we use the `lxml` library, which provides access to the C-library
    `libxml2` for handling XML content. Recall that `resp_1500` contains the response
    from our request, and the page is in the body of the response. We can parse the
    web page into a hierarchical structure with `fromstring` in the `lxml.html` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can work with the document using its tree structure. We can find all
    the tables in the HTML document with the following search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: This search uses the XPath `//table` expression, which we soon describe, to
    search for all table nodes anywhere in the document.
  prefs: []
  type: TYPE_NORMAL
- en: 'We found six tables in the document. If we examine the web page, including
    looking at its HTML source via the browser, we can figure out that the second
    table in the document contains the IAF-era times. This is the table we want. The
    screenshot in [Figure 14-5](#fig-html-table) shows that the first column contains
    the race times, the third holds names, and the fourth has the dates of the races.
    We can extract each of these pieces of information in turn. We do this with the
    following XPath expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'These return values behave like a list, but each value is an element of the
    tree. We can convert them to strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'For the times, we want to transform them into seconds. The function `get_sec`
    does this conversion. And we want to extract the race year from the date string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'We can create a dataframe and make a plot to show the progress in race times
    over the years:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_14in04.png)'
  prefs: []
  type: TYPE_IMG
- en: As you may have noticed, extracting data from an HTML page relies on careful
    examination of the source to find where in the document the numbers that we’re
    after are. We relied heavily on the XPath tool to do the extraction. Its elegant
    language is quite powerful. We introduce it next.
  prefs: []
  type: TYPE_NORMAL
- en: XPath
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we work with XML documents, we typically want to extract data from them
    and bring it into a dataframe. XPath can help here. XPath can recursively traverse
    an XML tree to find elements. For example, we used the expression `//table` in
    the previous example to locate all table nodes in our web page.
  prefs: []
  type: TYPE_NORMAL
- en: XPath expressions operate on the hierarchy of well-formed XML. They are succinct
    and similar in format to the way files are located in a hierarchy of directories
    in a computer filesystem. But they’re much more powerful. XPath is also similar
    to regular expressions in that we specify patterns to match content. Like with
    regular expressions, it takes experience to compose correct XPath expressions.
  prefs: []
  type: TYPE_NORMAL
- en: An XPath expression forms logical steps to identify and filter nodes in a tree.
    The result is a *node set* where each node occurs at most once. The node set also
    has an order that matches the order in which the nodes occur in the source; this
    can be quite handy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each XPath expression is made up of one or more *location steps*, separated
    by a “/”. Each location step has three parts—the *axis*, *node test*, and optional
    *predicate*:'
  prefs: []
  type: TYPE_NORMAL
- en: The axis specifies the direction to look in, such as down, up, or across the
    tree. We exclusively use shortcuts for the axis. The default is to look down one
    step at children in the tree. `//` says to look down the tree as far as possible,
    and `..` indicates one step up to the parent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The node test identifies the name or the type of node to look for. This is typically
    just a tag name or `text()` for text elements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A predicate acts like a filter to further restrict the node set. This is given
    in square brackets, like `[2]`, which keeps the second node in the node set, and
    `[ @date ]`, which keeps all nodes with a date attribute.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can tack together location steps to create powerful search instructions.
    [Table 14-2](#xpath-examples) provides some examples that cover the most common
    expressions. Refer back to the tree in [Figure 14-4](#fig-xml-tree) to follow
    along.
  prefs: []
  type: TYPE_NORMAL
- en: Table 14-2\. XPath examples
  prefs: []
  type: TYPE_NORMAL
- en: '| Expression | Result | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ‘//common’ | Two nodes | Look down the tree for any common nodes. |'
  prefs: []
  type: TYPE_TB
- en: '| ‘/catalog/plant/common’ | Two nodes | Travel the specific path from the root
    node *catalog* to all plant nodes to all common nodes within the plant nodes.
    |'
  prefs: []
  type: TYPE_TB
- en: '| ‘//common/text()’ | Bloodroot, Columbine | Locate the text content of all
    common nodes. |'
  prefs: []
  type: TYPE_TB
- en: '| ‘//plant[2]/price/text()’ | $9.37 | Locate plant nodes anywhere in the tree,
    then filter to take only the second. From this plant node, travel to its price
    child and locate its text. |'
  prefs: []
  type: TYPE_TB
- en: '| ‘//@date’ | 0399, 0199 | Locate the attribute value of any attribute named
    “date” in the tree. |'
  prefs: []
  type: TYPE_TB
- en: '| ‘//price[@curr=“CAD”]/text()’ | $9.37 | The text content of any price node
    that has a currency attribute value of “CAD.” |'
  prefs: []
  type: TYPE_TB
- en: 'You can try out the XPath expressions in the table with the catalog file. We
    load the file into Python using the `etree` module. The `parse` method reads the
    file into an element tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: The `lxml` library gives us access to XPath. Let’s try it out.
  prefs: []
  type: TYPE_NORMAL
- en: 'This simple XPath expression locates all text content of any `<light>` node
    in the tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that two elements are returned. Although the text content is identical,
    we have two `<light>` nodes in our tree and so are given the text content of each.
    The following expression is a bit more challenging:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: The expression locates all `<price>` nodes in the tree, then filters them according
    to whether their `curr` attribute is `CAD`. Then, for the remaining nodes (there’s
    only one in this case), travel up one step in the tree to the parent node and
    then back down to any child “common” nodes and on to their text content. Quite
    the trip!
  prefs: []
  type: TYPE_NORMAL
- en: Next, we provide an example that uses an HTTP request to retrieve XML-formatted
    data, and XPath to wrangle the content into a dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Accessing Exchange Rates from the ECB'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The European Central Bank (ECB) makes exchange rates available online in XML
    format. Let’s begin by getting the most recent exchange rates from the ECB with
    an HTTP request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we can use the `lxml` library to parse the text document we received
    from the ECB, but this time the contents are in a string returned from the ECB,
    not in a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to extract the data we want, we need to know how it is organized.
    Here is a snippet of the content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: This document appears quite different in structure from the plant catalog. The
    snippet shows three levels of tags, all with the same name, and none have text
    content. All of the relevant information is contained in attribute values. Other
    new features are the `xmlns` in the root `<Envelope>` node, and the odd tag names,
    like `gesmes:​Enve⁠lope`. These have to do with namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: XML allows content creators to use their own vocabularies, called *namespaces*.
    The namespace gives the rules for a vocabulary, such as allowable tag names and
    attribute names, and restrictions on how nodes can be nested. And XML documents
    can merge vocabularies from different applications. To keep it all straight, information
    about the namespace(s) is provided in the document.
  prefs: []
  type: TYPE_NORMAL
- en: The root node in the ECB file is `<Envelope>`. The additional “gesmes:” in the
    tag name indicates that the tags belong to the gesmes vocabulary, which is an
    international standard for the exchange of time-series information. Another namespace
    is also in `<Envelope>`. It is the default namespace for the file because it doesn’t
    have a prefix, like “`gesmes:`”. Whenever a namespace is not provided in a tag
    name, the default is assumed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The upshot of this is that we need to take into account these namespaces when
    we search for nodes. Let’s see how this works when we extract the dates. From
    the snippet, we see that the dates reside in “time” attributes. These `<Cube>`s
    are children of the top `<Cube>`. We can give a very specific XPath expression
    to step from the root to its `<Cube>` child node and on to the next level of `<Cube>`
    nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: The `.` in the expression is a shortcut to signify “from here,” and since we’re
    at the top of the tree, it’s equivalent to “from the root.” We specified the namespace
    in our expression as “`x:`”. Even though the `<Cube>` nodes are using the default
    namespace, we must specify it in our XPath expression. Fortunately, we can simply
    pass in the namespace as a parameter with our own label (“x” in this case) to
    keep our tag names short.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like with the HTML table, we can convert the date values into strings and from
    strings into timestamps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'As for the exchange rates, they also appear in `<Cube>` nodes, but these have
    a “rate” attribute. For example, we can access all exchange rates for the British
    pound with the following XPath expression (we’re ignoring the namespace for the
    moment):'
  prefs: []
  type: TYPE_NORMAL
- en: '`//Cube[@currency = "GBP"]/@rate`'
  prefs: []
  type: TYPE_NORMAL
- en: This expression says look for all `<Cube>` nodes anywhere in the document, filter
    them according to whether the node has a currency attribute value of “GBP,” and
    return their rate attribute values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we want to extract exchange rates for multiple currencies, we generalize
    this XPath expression. We also want to convert the exchange rates to a numeric
    storage type, and make them relative to the first day’s rate so that the different
    currencies are on the same scale, which makes them more amenable for plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'We wrap up this example with line plots of the exchange rates:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/leds_14in05.png)'
  prefs: []
  type: TYPE_IMG
- en: Combining knowledge of JSON, HTTP, REST, and HTML gives us access to a vast
    variety of data available on the web. For example, in this section we wrote code
    to scrape data from a Wikipedia page. One key advantage of this approach is that
    we can likely rerun this code in a few months to automatically update the data
    and the plots. One key drawback is that our approach is tightly coupled to the
    structure of the web page—if someone updates the Wikipedia page and the table
    is no longer the second table on the page, our code will also need some edits
    in order to work. That said, having the skills needed to scrape data from the
    web opens the door to a wide range of data and enables all kinds of useful analyses.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The internet abounds with data that are stored and exchanged in many different
    formats. In this chapter, our aim was to give you a taste of the variety of formats
    available and a basic understanding of how to acquire data from online sources
    and services. We also addressed the important goal of acquiring data in a reproducible
    fashion. Rather than copying and pasting from a web page or completing a form
    by hand, we demonstrated how to write code to acquire data. This code gives you
    a record of your workflow and of the data provenance.
  prefs: []
  type: TYPE_NORMAL
- en: With each format introduced, we described a model for its structure. A basic
    understanding of a dataset’s organization helps you uncover issues with quality,
    mistakes in reading a source file, and how best to wrangle and analyze the data.
    In the longer run, as you continue to develop your data science skills, you will
    be exposed to other forms of data exchange, and we expect this approach of considering
    the organizational model and getting your hands dirty with some simple cases will
    serve you well.
  prefs: []
  type: TYPE_NORMAL
- en: We only touched the surface of web services. There are many other useful topics,
    like keeping connections to a server alive as you issue multiple requests or retrieve
    data in batches, using cookies, and making multiple connections. But understanding
    the basics presented here can get you a long way. For example, if you use a library
    to retrieve data from an API but run into an error, you can start looking at the
    HTTP requests to debug your code. And you will know what’s possible when a new
    web service comes online.
  prefs: []
  type: TYPE_NORMAL
- en: Web etiquette is a topic that we must mention. If you plan to scrape data from
    a website, it’s a good idea to check that you have permission to do so. When we
    sign up to be a client for a web app, we typically check a box indicating our
    agreement to the terms of service.
  prefs: []
  type: TYPE_NORMAL
- en: If you use a web service or scrape web pages, be careful not to overburden the
    site with your requests. If a site offers a version of the data in a format like
    CSV, JSON, or XML, it’s better to download and use these than to scrape from a
    web page. Likewise, if there is a Python library that provides structured access
    to a web app, use it rather than writing your own code. When you make requests,
    start small to test your code, and consider saving the results so that you don’t
    have to repeat requests unnecessarily.
  prefs: []
  type: TYPE_NORMAL
- en: The aim of this chapter wasn’t to make you an expert in these specific data
    formats. Instead, we wanted to give you the confidence needed to learn more about
    a data format, to evaluate the pros and cons of different formats, and to participate
    in projects that might use formats that you haven’t seen before.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have experience working with different data formats, we return
    to the topic of modeling that we introduced in [Chapter 4](ch04.html#ch-modeling),
    picking it back up in earnest.
  prefs: []
  type: TYPE_NORMAL
