- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Spark’s long lineage of predecessors, from MPI (message passing interface)
    to MapReduce, made it possible to write programs that take advantage of massive
    resources while abstracting away the nitty-gritty details of distributed systems.
    As much as data processing needs have motivated the development of these frameworks,
    in a way the field of big data has become so related to them that its scope is
    defined by what these frameworks can handle. Spark’s original promise was to take
    this a little further—to make writing distributed programs feel like writing regular
    programs.
  prefs: []
  type: TYPE_NORMAL
- en: The rise in Spark’s popularity coincided with that of the Python data (PyData)
    ecosystem. So it makes sense that Spark’s Python API—PySpark—has significantly
    grown in popularity over the last few years. Although the PyData ecosystem has
    recently sprung up some distributed programming options, Apache Spark remains
    one of the most popular choices for working with large datasets across industries
    and domains. Thanks to recent efforts to integrate PySpark with the other PyData
    tools, learning the framework can help you boost your productivity significantly
    as a data science practitioner.
  prefs: []
  type: TYPE_NORMAL
- en: 'We think that the best way to teach data science is by example. To that end,
    we have put together a book of applications, trying to touch on the interactions
    between the most common algorithms, datasets, and design patterns in large-scale
    analytics. This book isn’t meant to be read cover to cover: page to a chapter
    that looks like something you’re trying to accomplish, or that simply ignites
    your interest, and start there.'
  prefs: []
  type: TYPE_NORMAL
- en: Why Did We Write This Book Now?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Spark experienced a major version upgrade in 2020—version 3.0\. One of
    the biggest improvements was the introduction of Spark Adaptive Execution. This
    feature takes away a big portion of the complexity around tuning and optimization.
    We do not refer to it in the book because it’s turned on by default in Spark 3.2
    and later versions, and so you automatically get the benefits.
  prefs: []
  type: TYPE_NORMAL
- en: The ecosystem changes, combined with Spark’s latest major release, make this
    edition a timely one. Unlike previous editions of *Advanced Analytics with Spark*,
    which chose Scala, we will use Python. We’ll cover best practices and integrate
    with the wider Python data science ecosystem when appropriate. All chapters have
    been updated to use the latest PySpark API. Two new chapters have been added and
    multiple chapters have undergone major rewrites. We will not cover Spark’s streaming
    and graph libraries. With Spark in a new era of maturity and stability, we hope
    that these changes will preserve the book as a useful resource on analytics for
    years to come.
  prefs: []
  type: TYPE_NORMAL
- en: How This Book Is Organized
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 1](ch01.xhtml#Introduction) places Spark and PySpark within the wider
    context of data science and big data analytics. After that, each chapter comprises
    a self-contained analysis using PySpark. [Chapter 2](ch02.xhtml#introduction_to_data_anlysis_with_pyspark)
    introduces the basics of data processing in PySpark and Python through a use case
    in data cleansing. The next few chapters delve into the meat and potatoes of machine
    learning with Spark, applying some of the most common algorithms in canonical
    applications. The remaining chapters are a bit more of a grab bag and apply Spark
    in slightly more exotic applications—for example, querying Wikipedia through latent
    semantic relationships in the text, analyzing genomics data, and identifying similar
    images.'
  prefs: []
  type: TYPE_NORMAL
- en: This book is not about PySpark’s merits and disadvantages. There are a few other
    things that it is not about either. It introduces the Spark programming model
    and basics of Spark’s Python API, PySpark. However, it does not attempt to be
    a Spark reference or provide a comprehensive guide to all Spark’s nooks and crannies.
    It does not try to be a machine learning, statistics, or linear algebra reference,
    although many of the chapters provide some background on these before using them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, this book will help the reader get a feel for what it’s like to use
    PySpark for complex analytics on large datasets by covering the entire pipeline:
    not just building and evaluating models, but also cleansing, preprocessing, and
    exploring data, with attention paid to turning results into production applications.
    We believe that the best way to teach this is by example.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are examples of some tasks that will be tackled in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: Predicting forest cover
  prefs: []
  type: TYPE_NORMAL
- en: We predict type of forest cover using relevant features like location and soil
    type by using decision trees (see [Chapter 4](ch04.xhtml#making_predictions_with_decision_trees_and_decision_forests)).
  prefs: []
  type: TYPE_NORMAL
- en: Querying Wikipedia for similar entries
  prefs: []
  type: TYPE_NORMAL
- en: We identify relationships between entries and query the Wikipedia corpus by
    using NLP (natural language processing) techniques (see [Chapter 6](ch06.xhtml#understanding_wikipedia_with_lda_and_spark_nlp)).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding utilization of New York cabs
  prefs: []
  type: TYPE_NORMAL
- en: We compute average taxi waiting time as a function of location by performing
    temporal and geospatial analysis (see [Chapter 7](ch07.xhtml#geospatial_and_temporal_data_analysis_on_taxi_trip_data)).
  prefs: []
  type: TYPE_NORMAL
- en: Reduce risk for an investment portfolio
  prefs: []
  type: TYPE_NORMAL
- en: We estimate financial risk for an investment portfolio using the Monte Carlo
    simulation (see [Chapter 9](ch09.xhtml#analyzing_genomics_data_and_and_the_bdg_project)).
  prefs: []
  type: TYPE_NORMAL
- en: When possible, we attempt not to just provide a “solution,” but to demonstrate
    the full data science workflow, with all of its iterations, dead ends, and restarts.
    This book will be useful for getting more comfortable with Python, Spark, and
    machine learning and data analysis. However, these are in service of a larger
    goal, and we hope that most of all this book will teach you how to approach tasks
    like those described earlier. Each chapter, in about 20 measly pages, will try
    to get as close as possible to demonstrating how to build one piece of these data
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Conventions Used in This Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following typographical conventions are used in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Italic*'
  prefs: []
  type: TYPE_NORMAL
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  prefs: []
  type: TYPE_NORMAL
- en: '`Constant width`'
  prefs: []
  type: TYPE_NORMAL
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  prefs: []
  type: TYPE_NORMAL
- en: '**`Constant width bold`**'
  prefs: []
  type: TYPE_NORMAL
- en: Shows commands or other text that should be typed literally by the user.
  prefs: []
  type: TYPE_NORMAL
- en: '*`Constant width italic`*'
  prefs: []
  type: TYPE_NORMAL
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  prefs: []
  type: TYPE_NORMAL
- en: This element signifies a tip or suggestion.
  prefs: []
  type: TYPE_NORMAL
- en: This element signifies a general note.
  prefs: []
  type: TYPE_NORMAL
- en: This element indicates a warning or caution.
  prefs: []
  type: TYPE_NORMAL
- en: Using Code Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Supplemental material (code examples, exercises, etc.) is available for download
    at [*https://github.com/sryza/aas*](https://github.com/sryza/aas).
  prefs: []
  type: TYPE_NORMAL
- en: If you have a technical question or a problem using the code examples, please
    send email to [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing examples
    from O’Reilly books does require permission. Answering a question by citing this
    book and quoting example code does not require permission. Incorporating a significant
    amount of example code from this book into your product’s documentation does require
    permission.
  prefs: []
  type: TYPE_NORMAL
- en: 'We appreciate, but do not require, attribution. An attribution usually includes
    the title, author, publisher, and ISBN. For example: “*Advanced Analytics with
    PySpark* by Akash Tandon, Sandy Ryza, Uri Laserson, Sean Owen, and Josh Wills
    (O’Reilly). Copyright 2022 Akash Tandon, 978-1-098-10365-1.”'
  prefs: []
  type: TYPE_NORMAL
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: O’Reilly Online Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For more than 40 years, [*O’Reilly Media*](https://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*https://oreilly.com*](https://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: How to Contact Us
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please address comments and questions concerning this book to the publisher:'
  prefs: []
  type: TYPE_NORMAL
- en: O’Reilly Media, Inc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1005 Gravenstein Highway North
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sebastopol, CA 95472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 800-998-9938 (in the United States or Canada)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-829-0515 (international or local)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-829-0104 (fax)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/adv-analytics-pyspark*](https://oreil.ly/adv-analytics-pyspark).
  prefs: []
  type: TYPE_NORMAL
- en: Email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com) to comment
    or ask technical questions about this book.
  prefs: []
  type: TYPE_NORMAL
- en: For news and information about our books and courses, visit [*https://oreilly.com*](https://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: 'Find us on LinkedIn: [*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow us on Twitter: [*https://twitter.com/oreillymedia*](https://twitter.com/oreillymedia)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Watch us on YouTube: [*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)'
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It goes without saying that you wouldn’t be reading this book if it were not
    for the existence of Apache Spark and MLlib. We all owe thanks to the team that
    has built and open sourced it and the hundreds of contributors who have added
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We would like to thank everyone who spent a great deal of time reviewing the
    content of the previous editions of the book with expert eyes: Michael Bernico,
    Adam Breindel, Ian Buss, Parviz Deyhim, Jeremy Freeman, Chris Fregly, Debashish
    Ghosh, Juliet Hougland, Jonathan Keebler, Nisha Muktewar, Frank Nothaft, Nick
    Pentreath, Kostas Sakellis, Tom White, Marcelo Vanzin, and Juliet Hougland again.
    Thanks all! We owe you one. This has greatly improved the structure and quality
    of the result.'
  prefs: []
  type: TYPE_NORMAL
- en: Sandy also would like to thank Jordan Pinkus and Richard Wang for helping with
    some of the theory behind the risk chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to Jeff Bleiel and O’Reilly for the experience and great support in getting
    this book published and into your hands.
  prefs: []
  type: TYPE_NORMAL
