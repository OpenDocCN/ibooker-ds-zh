- en: Chapter 3\. Introduction to Causal Diagrams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In fact, with few exceptions, correlation does imply causation. If we observe
    a systematic relationship between two variables, and we have ruled out the likelihood
    that this is simply due to a random coincidence, then something must be causing
    this relationship. When the audience at a Malay shadow theatre sees a solid round
    shadow on the screen they know that some three-dimensional object has cast it,
    though they may not know if the object is a ball or a rice bowl in profile. A
    more accurate sound bite for introductory statistics would be that a simple correlation
    implies an unresolved causal structure.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Bill Shipley, *Cause and Correlation in Biology* (2016)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Causal diagrams (CDs) may well be one of the most powerful tools for analysis
    most people have never heard of. As such they are one of the three extremities
    (vertices) of the causal-behavioral framework ([Figure 3-1](#the_causal_behavioral_framework_for_d)).
    They provide a language to express and analyze cause-to-effect relationships,
    which works especially well when dealing with behavioral data analyses.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/BEDA_0301.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-1\. The causal-behavioral framework for data analysis
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In the first section of this chapter, I’ll show how CDs fit into the framework
    from a conceptual perspective, that is, how they are connected to behaviors and
    data. In the second section, I’ll describe the three fundamental structures in
    CDs: chains, forks, and colliders. Finally, in the third section, we’ll see some
    common transformations that can be applied to CDs.'
  prefs: []
  type: TYPE_NORMAL
- en: Causal Diagrams and the Causal-Behavioral Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, let’s define what a CD is. A CD is a visual representation of variables,
    shown as boxes, and their relationships to each other shown as arrows going from
    one box to another.
  prefs: []
  type: TYPE_NORMAL
- en: In our C-Mart example in [Chapter 1](ch01.xhtml#the_causal_behavioral_framework_for_da),
    the variable *IcedCoffeeSales* was affected by a single cause, *Temperature*.
    [Figure 3-2](#our_very_first_causal_diagram) shows the corresponding causal diagram.
  prefs: []
  type: TYPE_NORMAL
- en: '![Our very first causal diagram](Images/BEDA_0302.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-2\. Our very first causal diagram
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Each rectangle represents a variable we can observe (one we have in our data
    set), and the arrow between them represents the existence and direction of a causal
    relationship. Here, the arrow between *Temperature* and *IcedCoffeeSales* indicates
    that the former is a cause of the latter.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, however, there will be an additional variable that we aren’t able
    to observe. If we still want to show it in a causal diagram, we can represent
    it with a shaded rectangle^([1](ch03.xhtml#idm45968167675832)) ([Figure 3-3](#a_causal_diagram_with_an_unobserved_var)).
  prefs: []
  type: TYPE_NORMAL
- en: '![A causal diagram with an unobserved variable](Images/BEDA_0303.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-3\. A causal diagram with an unobserved variable
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In [Figure 3-3](#a_causal_diagram_with_an_unobserved_var), *CustomerSweetTooth*
    is a cause of *IcedCoffeeSales*, meaning that customers with a stronger sweet
    tooth buy more iced coffee. However, we can’t observe the degree of a customer’s
    sweet tooth. We’ll discuss later the importance of unobserved confounders and
    more generally unobserved variables in causal analysis. For the time being, let’s
    just note that even if we have no way of observing a particular variable, it can
    still be included in a causal diagram by representing it as an oval.
  prefs: []
  type: TYPE_NORMAL
- en: Causal Diagrams Represent Behaviors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first way of looking at causal diagrams is to treat them as representations
    of causal relationships between behaviors, as well as other phenomena in the real
    world that impact behaviors ([Figure 3-4](#cds_are_connected_to_behaviors_in_our_f)).
    From this perspective, the elements of CDs represent real “things” that exist
    and have effects on each other. An analogy from physical sciences would be a magnet,
    a bar of iron, and the magnetic field around the magnet. You can’t see the magnetic
    field but it exists nonetheless, and it affects the iron bar. You may not have
    any data on the magnetic field and maybe you’ve never seen the equations describing
    it, but you can sense it as you move the bar, and you can develop intuitions as
    to what it does.
  prefs: []
  type: TYPE_NORMAL
- en: '![CDs are connected to behaviors in our framework](Images/BEDA_0304.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-4\. CDs are connected to behaviors in our framework
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The same perspective applies when we want to understand what drives behaviors.
    We intuitively understand that human beings have habits, preferences, and emotions,
    and we treat these as causes even though we often don’t have any numeric data
    about them. When we say, “Joe bought peanuts because he was hungry,” we are relying
    on our knowledge, experience, and beliefs about humans in general and Joe in particular.
    We treat hunger as a real thing, even if we’re not measuring Joe’s blood sugar
    or brain activation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we’re making a causal statement about reality: we’re saying that had
    Joe not been hungry, he wouldn’t have bought peanuts. Causality is so fundamental
    to our intuitive understanding of reality that even young children are able to
    make correct causal inferences (evidenced by their use of the word “because”)
    long before they have had any exposure to the scientific method or data analysis.
    Of course, intuition is subject to a variety of biases well known by behavioral
    scientists, even when it takes the more educated form of common sense or expertise.
    But more often than not, intuition guides us well in our daily lives even in the
    absence of quantitative data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You might worry that using CDs to represent intuitions and beliefs about the
    world introduces subjectivity, and that’s certainly true. But because CDs are
    tools for thinking and analysis, they don’t have to be “true.” You and I might
    have different ideas as to why Joe bought peanuts, which means we would draw different
    CDs. Even if we fully agreed on what causes what, we couldn’t represent everything
    and their relationships in one diagram; there is judgment involved in determining
    what variables and relationships to include or exclude. In some cases, when data
    is available, it will help: we’ll be able to reject a CD because it is incompatible
    with the data at hand. But in other cases, very different CDs will be equally
    compatible with the data and we won’t be able to choose between them, especially
    if we don’t have experimental data.'
  prefs: []
  type: TYPE_NORMAL
- en: This subjectivity might look like a (possibly fatal) flaw of CDs, but it’s actually
    a feature, not a bug. CDs don’t create uncertainty; they simply reflect the uncertainty
    that is already in our world. If there are several possible interpretations of
    the situation at hand that appear equally valid, you should explicitly say so.
    The alternative would be to allow people who have different mental models in their
    heads to each believe that they know the truth and others agree with them, when
    in reality that’s not the case. At least putting the uncertainty in the open will
    allow a principled discussion and guide your analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Causal Diagrams Represent Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While there is an art to building and interpreting CDs, there’s also a science
    to it, and we can use CDs to represent relationships between variables in our
    data ([Figure 3-5](#cds_are_also_connected_to_data)). When these relationships
    are entirely linear, or approximately so, CDs have clear equivalents in linear
    algebra. This means we can use the rules and tools of linear algebra to validate
    the “legality” of how we manipulate and transform CDs, thus ensuring that we draw
    correct conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: '![CDs are also connected to data](Images/BEDA_0305.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-5\. CDs are also connected to data
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The linearity requirement may seem very restrictive. However, some of the rules
    and tools of linear algebra continue to apply when some of these relationships
    are not linear but still belong to the broad category of models called generalized
    linear models (GLM). A logistic regression model for example is a GLM. This means
    that we can represent and handle a causal relationship where the effect variable
    is binary with CDs. As the sidebar shows, the math gets more convoluted in that
    case, but most of our intuitions about CDs remain true.
  prefs: []
  type: TYPE_NORMAL
- en: 'From this perspective, the causal diagram from [Figure 3-3](#a_causal_diagram_with_an_unobserved_var)
    connecting *Temperature* to *IcedCoffeeSales* would mean that:'
  prefs: []
  type: TYPE_NORMAL
- en: '*IcedCoffeeSales = β * Temperature + *ε**'
  prefs: []
  type: TYPE_NORMAL
- en: This linear regression means that if temperature were to increase by one degree,
    keeping everything else equal, then sales of iced coffee would increase by *β*
    dollars. Each box in the causal diagram represents a column of data, as with the
    simulated data in [Table 3-1](#simulated_data_illustrating_the_relatio).
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-1\. Simulated data illustrating the relationship in our causal diagram
  prefs: []
  type: TYPE_NORMAL
- en: '| Date | *Temperature* | *IcedCoffeeSales* | *β* * *Temperature* | *ε* = *IcedCoffeeSales*
    – *β* * *Temperature* |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 6/1/2019 | 71 | $70,945 | $71,000 | $55 |'
  prefs: []
  type: TYPE_TB
- en: '| 6/2/2019 | 57 | $56,969 | $57,000 | $31 |'
  prefs: []
  type: TYPE_TB
- en: '| 6/3/2019 | 79 | $78,651 | $79,000 | -$349 |'
  prefs: []
  type: TYPE_TB
- en: 'For people who are familiar with linear algebra notation, we can rewrite the
    previous equation as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math><mrow><mrow><mrow><mo>(</mo><mtable><mtr><mtd><mn>70</mn><mo>,</mo><mn>945</mn></mtd></mtr><mtr><mtd><mn>56</mn><mo>,</mo><mn>969</mn></mtd></mtr><mtr><mtd><mn>78</mn><mo>,</mo><mn>651</mn></mtd></mtr></mtable><mo>)</mo></mrow><mo>=</mo><mn>1000</mn><mo>*</mo><mrow><mo>(</mo><mtable><mtr><mtd><mn>71</mn></mtd></mtr><mtr><mtd><mn>57</mn></mtd></mtr><mtr><mtd><mn>79</mn></mtd></mtr></mtable><mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><mtable><mtr><mtd><mn>55</mn></mtd></mtr><mtr><mtd><mn>31</mn></mtd></mtr><mtr><mtd><mo>−</mo><mn>349</mn></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: From that perspective, CDs are all about data—variables and relationships between
    them. This generalizes immediately to multiple causes. Let’s draw a causal diagram
    showing that *Temperature* and *SummerMonth* both cause *IceCreamSales* ([Figure 3-8](#a_causal_diagram_with_more_than_one_cau)).
  prefs: []
  type: TYPE_NORMAL
- en: '![A causal diagram with more than one cause](Images/BEDA_0308.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-8\. A causal diagram with more than one cause
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Translating this CD in mathematical terms would yield the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*IceCreamSales = β[*T*].Temperature + β[*S*].SummerMonth + ε*'
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, this equation is a standard multiple linear regression, but the fact
    that it is based on a CD changes its interpretation. Outside of a causal framework,
    the only conclusion we would be able to draw from it is “an increase of one degree
    of temperature is associated with an increase of *β*[*T*] dollars in ice cream
    sales.” Because correlation is not causation, it would be illegitimate to infer
    anything further. However, when a regression is backed by a CD, as is the case
    here, we can make a significantly stronger statement—namely, “unless this CD is
    wrong, an increase of one degree of temperature will cause an increase of *β*[*T*]
    dollars in ice cream sales,” which is what the business cares about.
  prefs: []
  type: TYPE_NORMAL
- en: If you have a quantitative background such as data science, you may be tempted
    to focus on the connection between CDs and data at the expense of the connection
    with behaviors. It is certainly a viable path, and it has given birth to an entire
    category of statistical models called probabilistic graphical models. For instance,
    algorithms have been and are still developed to identify causal relationships
    in data without relying on human expertise or judgment. However, this field is
    still in its infancy, and when applied to real-life data, these algorithms are
    often unable to select between several possible CDs that lead to vastly different
    business implications. Business and common sense can frequently do a better job
    of selecting the most reasonable one. Therefore I strongly believe that you are
    better off using the mixed approach shown in this book’s framework and accepting
    the idea that you’ll need to use your judgment. The back and forth that CDs enable
    between your intuitions and your data is—literally, in many cases—where the money
    is.
  prefs: []
  type: TYPE_NORMAL
- en: Fundamental Structures of Causal Diagrams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Causal diagrams can take a bewildering variety of shapes. Fortunately, researchers
    have been working on causality for a while now, and they have brought some order
    to it:'
  prefs: []
  type: TYPE_NORMAL
- en: There exist only three fundamental structures—chains, forks, and colliders—and
    all causal diagrams can be represented as combinations of them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By looking at CDs as if they were family trees, we can easily describe relationships
    between variables that are far away from each other in the diagram, for example
    by saying that one is the “descendant” or the “child” of another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And really, that’s all there is to it! We’ll now see these fundamental structures
    in more detail, and once you have familiarized yourself with them and how to name
    relationships between variables, you’ll be able to fully describe any CD you work
    with.
  prefs: []
  type: TYPE_NORMAL
- en: Chains
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A chain is a causal diagram with three boxes, representing three variables,
    and two arrows connecting these boxes in a straight line. To show you one, I’ll
    have to introduce a new treat in our C-Mart example—namely, the mighty donut.
    For the sake of simplicity, let’s assume that only one of the variables we have
    already seen affects the sales of donuts: *IcedCoffeeSales*. Then *Temperature*,
    *IcedCoffeeSales*, and *DonutSales* are causally connected ([Figure 3-9](#causal_diagram_of_a_chain)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Causal diagram of a chain](Images/BEDA_0309.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-9\. Causal diagram of a chain
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: What makes this CD a chain is that the two arrows are going “in the same direction,”
    i.e., the first arrow goes from one box to another, and the second arrow goes
    from that second box to the last one. This CD is an expansion of the one in [Figure 3-3](#a_causal_diagram_with_an_unobserved_var).
    It represents the fact that temperature causes sales of iced coffee, which in
    turn causes sales of donuts.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s define a few terms that will allow us to characterize the relationships
    between variables. In this diagram, *Temperature* is called the *parent* of *IcedCoffeeSales*,
    and *IcedCoffeeSales* is a *child* of *Temperature*. But *IcedCoffeeSales* is
    also a parent of *DonutSales*, which is its child. When a variable has a parent/child
    relationship with another variable we call that a *direct relationship*. When
    there are intermediary variables between them, we call that an *indirect relationship*.
    The actual count of variables that makes a relationship indirect is not generally
    important, so you don’t have to count the number of boxes to describe the fundamental
    structure of the relationship between them.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, we say that a variable is the *ancestor* of another variable if
    the first variable is the parent of another, which may be the parent of another,
    and so on, ending up with our second variable as a child. In our example, *Temperature*
    is an ancestor of *DonutSales* because it’s a parent of *IcedCoffeeSales*, which
    is itself a parent of *DonutSales*. Very logically, this makes *DonutSales* a
    *descendant* of *Temperature* ([Figure 3-10](#relationships_between_variables_along_a)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Relationships between variables along a chain](Images/BEDA_0310.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-10\. Relationships between variables along a chain
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this situation, *IcedCoffeeSales* is also the *mediator* of the relationship
    between *Temperature* and *DonutSales*. We’ll explore mediation in more depth
    in [Chapter 12](ch12.xhtml#mediation_and_instrumental_variables). For now, let’s
    just note that if a mediator value does not change, then the variables earlier
    in a chain won’t influence the variables further along the chain unless they are
    otherwise connected. In our example, if C-Mart were to experience a shortage of
    iced coffee, we would expect that for the duration of that shortage, changes in
    temperature would not have any effect on the sales of donuts.
  prefs: []
  type: TYPE_NORMAL
- en: Collapsing chains
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The preceding causal diagram translates into the following regression equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '*IcedCoffeeSales* = *β[T].Temperature*'
  prefs: []
  type: TYPE_NORMAL
- en: '*DonutSales* = *β[I].IcedCoffeeSales*'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can replace *IcedCoffeeSales* by its expression in the second equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*DonutSales* = *β*[I].(*β[T]Temperature*) = (*β[I]β[T]*)*Temperature*'
  prefs: []
  type: TYPE_NORMAL
- en: 'But *β*[I]*β*[T] is just the product of two constant coefficients, so we can
    treat it as a new coefficient in itself: <math><mrow><mrow><mi>D</mi><mi>o</mi><mi>n</mi><mi>u</mi><mi>t</mi><mi>S</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>s</mi><mo>=</mo><msub><mrow><mover><mrow><mi>β</mi></mrow><mrow><mo>˜</mo></mrow></mover></mrow><mrow><mi>T</mi></mrow></msub><mn>.</mn><mi>T</mi><mi>e</mi><mi>m</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi></mrow></mrow></math>.
    We have managed to express *DonutSales* as a linear function of *Temperature*,
    which can in turn be translated into a causal diagram ([Figure 3-11](#collapsing_a_cd_into_another_cd)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Collapsing a CD into another CD](Images/BEDA_0311.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-11\. Collapsing a CD into another CD
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Here, we have *collapsed a chain*, that is, we have removed the variable in
    the middle and replaced it with an arrow going from the first variable to the
    last. By doing so, we have effectively simplified our original causal diagram
    to focus on the relationship that we’re interested in. This can be useful when
    the last variable in a chain is a business metric we’re interested in and the
    first one is actionable. In some circumstances, for example, we might be interested
    in the intermediary relations between *Temperature* and *IcedCoffeeSales* and
    between *IcedCoffeeSales* and *DonutSales* to manage pricing or promotions. In
    other circumstances, we might be interested only in the relation between *Temperature*
    and *DonutSales*—for example, to plan for inventory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The transitivity property of linear algebra also applies here: if *DonutSales*
    caused another variable, then that chain could also be collapsed around *DonutSales*,
    and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Expanding chains
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The collapsing operation can obviously be reversed: we can go from our last
    CD to the previous one by adding the *IcedCoffeeSales* variable in the middle.
    More generally, we say that we are *expanding a chain* whenever we inject an intermediary
    variable between two variables currently connected by an arrow. For example, let’s
    say that we start with the relationship between *Temperature* and *DonutSales*
    ([Figure 3-11](#collapsing_a_cd_into_another_cd)). This causal relationship translates
    into the equation *DonutSales* = *β[T]Temperature*. Let’s assume that *Temperature*
    affects *DonutSales* only through *IcedCoffeeSales*. We can add this variable
    in our CD, which brings us back to our original CD from [Figure 3-8](#a_causal_diagram_with_more_than_one_cau)
    ([Figure 3-12](#expanding_a_cd_into_another_cd)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Expanding a CD into another CD](Images/BEDA_0312.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-12\. Expanding a CD into another CD
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Expanding chains can be useful to better understand what’s happening in a given
    situation. For example, let’s say that temperature increased but sales of donuts
    did not. There could be two potential reasons for that:'
  prefs: []
  type: TYPE_NORMAL
- en: First, the increase in temperature did not increase the sales of iced coffee,
    perhaps because the store manager has been more aggressive with the AC. In other
    words, the first arrow in [Figure 3-11](#collapsing_a_cd_into_another_cd) disappeared
    or weakened.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatively, the increase in temperature *did* increase the sales of iced
    coffee, but the increase in the sales of iced coffee did not increase the sales
    of donuts, e.g., because people are buying the newly offered cookies instead.
    In other words, in [Figure 3-11](#collapsing_a_cd_into_another_cd), the first
    arrow is unchanged but the second one disappeared or weakened.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on which one is true, you might take very different corrective actions—either
    turning off the AC or changing the price of cookies. In many cases, looking at
    the variable in the middle of a chain, namely the mediator, will allow you to
    make better decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Because chains can be collapsed or expanded at will, in general we do not explicitly
    indicate when it has been done. It’s always assumed that any arrow could potentially
    be expanded to highlight an intermediary variable along the way.
  prefs: []
  type: TYPE_NORMAL
- en: 'This also implies that the definition of “direct” and “indirect” relationships
    mentioned earlier relates to a specific representation of a CD: when you collapse
    a chain, two variables that had an indirect relationship now have a direct relationship.'
  prefs: []
  type: TYPE_NORMAL
- en: Forks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When a variable causes two or more effects, the relationship creates a *fork*.
    *Temperature* causes both *IcedCoffeeSales* and *IceCreamSales*, so a representation
    of this fork is shown in [Figure 3-13](#a_fork_between_three_variables).
  prefs: []
  type: TYPE_NORMAL
- en: '![A fork between three variables](Images/BEDA_0313.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-13\. A fork between three variables
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This CD shows that *Temperature* influences both *IceCreamSales* and *IcedCoffeeSales*,
    but that they do not have a causal relationship with each other. If it is hot
    out, demand for both ice cream and iced coffee increases, but buying one does
    not make you want to buy the other, nor does it make you less likely to buy the
    other.
  prefs: []
  type: TYPE_NORMAL
- en: This situation where two variables have a common cause is very frequent but
    also potentially problematic, because it creates a correlation among these two
    variables. It makes sense that when it is hot out, we will see an increase in
    sales of both, and when it is cold fewer people will want both. A linear regression
    predicting *IceCreamSales* from *IcedCoffeeSales* would be fairly predictive,
    but here correlation does not equal causation, and since we know that the causal
    impact is 0, the coefficient provided by the model would not be accurate.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to look at this relationship is that if C-Mart experienced a shortage
    of iced coffee, we would not expect to see a change in the sales of ice cream.
    More generally, it would be only a slight exaggeration to say that forks are one
    of the main roots of evil in the world of data analysis. Whenever we observe a
    correlation between two variables that doesn’t reflect direct causality between
    them (i.e., neither is the cause of the other), more often than not it will be
    because they share a common cause. From that perspective, one of the main benefits
    of using CDs is that they can show very clearly and intuitively what’s going on
    in those cases and how to correct for it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Forks are also typical of situations where we look at demographic variables:
    age, gender, and place of residence all cause a variety of other variables that
    may or may not cause each other. You can picture a demographic variable such as
    age as being at the root of a fork with many teeth.'
  prefs: []
  type: TYPE_NORMAL
- en: A question that sometimes comes up when you have a fork in the middle of a CD
    is whether you can still collapse the chain around it. For example, let’s say
    that we’re interested in analyzing the relationship between *SummerMonth* and
    *IcedCoffeeSales* using the CD in [Figure 3-14](#a_cd_with_a_fork_and_a_chain).
  prefs: []
  type: TYPE_NORMAL
- en: '![A CD with a fork and a chain](Images/BEDA_0314.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-14\. A CD with a fork and a chain
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this CD, there’s a fork between *SummerMonth* on one side and *IceCreamSales*
    and *Temperature* on the other, but there’s also a chain *SummerMonth* → *Temperature*
    → *IcedCoffeeSales*. Can we collapse the chain?
  prefs: []
  type: TYPE_NORMAL
- en: In this case, yes. We’ll see in [Chapter 5](ch05.xhtml#using_causal_diagrams_to_deconfound_da)
    how to determine when a variable is a confounder of a relationship; here it will
    suffice to say that *IceCreamSales* is not a confounder of the relationship between
    *SummerMonth* and *IcedCoffeeSales*, which is the one we’re interested in. Therefore
    we can simplify our CD ([Figure 3-15](#a_collapsed_version_of_the_previous_cd)).
  prefs: []
  type: TYPE_NORMAL
- en: '![A collapsed version of the previous CD](Images/BEDA_0315.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-15\. A collapsed version of the previous CD
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Similarly, if we were interested in the relationship between *SummerMonth* and
    *IceCreamSales* in [Figure 3-14](#a_cd_with_a_fork_and_a_chain), we could neglect
    *IcedCoffeeSales* but not *Temperature.*
  prefs: []
  type: TYPE_NORMAL
- en: Because forks are so important to causal analysis, we’ll sometimes want to represent
    them even when we don’t know the joint cause. When that’s the case, we’ll represent
    the unknown fork with a two-headed arrow ([Figure 3-16](#a_fork_with_an_unknown_joint_cause)).
  prefs: []
  type: TYPE_NORMAL
- en: '![A fork with an unknown joint cause](Images/BEDA_0316.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-16\. A fork with an unknown joint cause
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The two-headed arrow also looks like the two variables are causing each other.
    This is by design, and we’ll also use a two-headed arrow when we observe a correlation
    between two variables but we don’t know which is causing which. Thus, a two-headed
    arrow encompasses the three possible reasons why two variables A and B would appear
    correlated: A causes B, B causes A, and/or A and B share a cause. Sometimes we’ll
    use a two-headed arrow as a placeholder until we clarify the true reason; if we
    don’t care about the reason, we may simply retain the two-headed arrow in our
    final CD.'
  prefs: []
  type: TYPE_NORMAL
- en: Colliders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Very few things in the world have only one cause. When two or more variables
    cause the same outcome, the relationship creates a *collider*. Since C-Mart’s
    concession stand sells only two flavors of ice cream, chocolate and vanilla, a
    causal diagram representing taste and ice cream purchasing behavior would show
    that appetite for either flavor would cause past purchases of ice cream at the
    stand ([Figure 3-17](#cd_of_a_collider)).
  prefs: []
  type: TYPE_NORMAL
- en: '![CD of a collider](Images/BEDA_0317.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-17\. CD of a collider
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Colliders are a common occurrence, and they can also be an issue in data analysis.
    A collider is in a sense the opposite of a fork, and the problems with them are
    also symmetric: a fork is problematic if we *don’t control* for the joint cause
    whereas a collider is a problem if we *do control* for the joint effect. We’ll
    explore these issues further in [Chapter 5](ch05.xhtml#using_causal_diagrams_to_deconfound_da).'
  prefs: []
  type: TYPE_NORMAL
- en: To recap this section, chains, forks, and colliders represent the only three
    possible ways for three variables to be related to each other in a CD. They are
    not exclusive of each other, however, and it’s actually reasonably common to have
    three variables that exhibit all three structures at the same time, as was the
    case in our very first example ([Figure 3-18](#a_three_variable_cd_containing_a_chainc)).
  prefs: []
  type: TYPE_NORMAL
- en: '![A three-variable CD containing a chain, a fork, and a collider at the same
    time](Images/BEDA_0318.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-18\. A three-variable CD containing a chain, a fork, and a collider
    at the same time
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here, *SummerMonth* influences *IceCreamSales* as well as *Temperature*, which
    itself influences *IceCreamSales*. The causal relationships at play are reasonably
    simple and easy to grasp, but this graph also contains all three types of basic
    relationships:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A chain: *SummerMonth* → *Temperature* → *IceCreamSales*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A fork, with SummerMonth causing both *Temperature* and *IceCreamSales*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A collider, with *IceCreamSales* being caused by both *Temperature* and *SummerMonth*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another thing to note in a situation like this one is that variables have more
    than one relationship with each other. For example, *SummerMonth* is the parent
    of *IceCreamSales* because there is an arrow going directly from the former to
    the latter (a direct relationship); but at the same time, *SummerMonth* is also
    indirectly an ancestor of *IceCreamSales* through the chain *SummerMonth → Temperature
    → IceCreamSales* (an indirect relationship). So you can see these are not exclusive!
  prefs: []
  type: TYPE_NORMAL
- en: While a CD is always made of these three structures, it is not static. A CD
    can be transformed by modifying the variables themselves as well as their relationships,
    as we’ll now see.
  prefs: []
  type: TYPE_NORMAL
- en: Common Transformations of Causal Diagrams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chains, forks, and colliders take the variables in a CD as given. But in the
    same way that a chain can be collapsed or expanded, variables can themselves be
    sliced or aggregated to “zoom” in and out of specific behaviors and categories.
    We may also decide to modify the arrows—for example, when we’re faced with otherwise
    intractable cycles.
  prefs: []
  type: TYPE_NORMAL
- en: Slicing/Disaggregating Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Forks and colliders are often created when you slice or disaggregate a variable
    to reveal its components. In a previous example, we looked at the relationship
    between *Temperature* and *DonutSales*, where *IcedCoffeeSales* was the mediator
    ([Figure 3-19](#the_chain_that_we_will_slice)).
  prefs: []
  type: TYPE_NORMAL
- en: '![The chain that we will slice](Images/BEDA_0319.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-19\. The chain that we will slice
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'But maybe we want to split *IcedCoffeeSales* by type to better understand demand
    dynamics. This is what I mean by “slicing” a variable. This is allowed per the
    rules of linear algebra, because we can express the total iced coffee sales as
    the sum of sales by type, say Americano and latte:'
  prefs: []
  type: TYPE_NORMAL
- en: '*IcedCoffeeSales* = *IcedAmericanoSales* + *IcedLatteSales*'
  prefs: []
  type: TYPE_NORMAL
- en: Our CD would now become [Figure 3-20](#a_chain_where_the_mediator_has_been_sli),
    with a fork on the left and a collider on the right.
  prefs: []
  type: TYPE_NORMAL
- en: '![A chain where the mediator has been sliced](Images/BEDA_0320.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-20\. A chain where the mediator has been sliced
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Each slice of the variable would now have its own equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*IcedAmericanoSales* = *β[*TA*].Temperature*'
  prefs: []
  type: TYPE_NORMAL
- en: '*IcedLatteSales* = *β[TL].Temperature*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the effect of *Temperature* is completely mediated by our *IcedCoffeeSales*
    slices, we can create a unified multiple regression for *DonutSales* as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*DonutSales* = *β[IA].IcedAmericanoSales + β[IL].IcedLatteSales*'
  prefs: []
  type: TYPE_NORMAL
- en: This would allow you to understand more finely what’s happening—should you plan
    for the same increase in sales in both types when temperature increases? Do they
    both have the same effect on *DonutSales* or should you try to favor one of them?
  prefs: []
  type: TYPE_NORMAL
- en: Aggregating Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you may have guessed, slicing variables can be reversed, and more generally
    we can aggregate variables that have the same causes and effects. This can be
    used to aggregate and disaggregate data analysis by product, region, line of business,
    and so on. But it can also be used more loosely to represent important causal
    factors that are not precisely defined. For example, let’s say that *Age* and
    *Gender* both impact *TasteForVanilla* as well as the propensity to buy ice cream
    at C-Mart concession stands, *PurchasedIceCream* ([Figure 3-21](#age_and_gender_are_shown_separately)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Age and Gender are shown separately](Images/BEDA_0321.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-21\. Age and Gender are shown separately
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Because *Age* and *Gender* have the same causal relationships, they can be aggregated
    into a *DemographicCharacteristics* variable ([Figure 3-22](#cd_where_age_and_gender_are_aggregated)).
  prefs: []
  type: TYPE_NORMAL
- en: '![CD where Age and Gender are aggregated into a single variable](Images/BEDA_0322.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-22\. CD where Age and Gender are aggregated into a single variable
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this case, we obviously don’t have a single column in our data called “Demographic
    Characteristics” or “Demographics”; we’re simply using that variable in our CD
    as a shortcut for a variety of variables that we may or may not want to explore
    in further detail later on. Let’s say that we want to run an A/B test and understand
    the causal relationships at hand. As we’ll see later, randomization can allow
    us to control for demographic factors so that we won’t have to include them in
    our analysis, but we might want to include them in our CD of the situation without
    randomization. If need be, we can always expand our diagram to accurately represent
    the demographic variables involved. Remember, however, that *any variable can
    be split, but only variables that have the same direct and indirect relationships
    can be aggregated.*
  prefs: []
  type: TYPE_NORMAL
- en: What About Cycles?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the three fundamental structures that we’ve seen, there has been only one
    arrow between two given boxes. More generally, it was not possible to reach the
    same variable twice by following the direction of arrows (e.g., A → B → C → A).
    A variable could be the effect of one variable and the cause of another, but it
    could not be at the same time the cause and the effect of one variable.
  prefs: []
  type: TYPE_NORMAL
- en: In real life, however, we often see variables that influence each other causally.
    This type of CD is called a *cycle*. Cycles can arise for a variety of reasons;
    two of the most common in behavioral data analysis are substitution effects and
    feedback loops. Fortunately, there are some workarounds that will allow you to
    deal with cycles when you encounter them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Understanding cycles: Substitution effects and feedback loops'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Substitution effects are a cornerstone of economics theory: customers might
    *substitute* a product for another, depending on the products’ availability and
    price and the customers’ desire for variety. For example, customers coming to
    the C-Mart concession store might choose between iced coffee and hot coffee based
    not only on temperature but also on special promotions and how often they had
    coffee this week. Therefore, there is a causal relationship from purchases of
    iced coffee to purchases of hot coffee, and another causal relationship in the
    opposite direction ([Figure 3-23](#a_cd_with_a_substitution_effect_generat)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![A CD with a substitution effect generating a cycle](Images/BEDA_0323.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-23\. A CD with a substitution effect generating a cycle
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: One thing to note is that the direction of the arrows shows the direction of
    causality (what is the cause and what is the effect), not the sign of the effect.
    In all of the CDs we looked at previously, the variables had a positive relationship
    where an increase in one caused an increase in the other. In this case, the relationships
    are negative, where an increase in one variable will cause a decrease in the other.
    The sign of the effect does not matter for causal diagrams, and a regression will
    be able to sort out the sign for the coefficient correctly as long as you correctly
    identify the relevant causal relationships.
  prefs: []
  type: TYPE_NORMAL
- en: Another common cycle is a feedback loop, where a person modifies their behavior
    in reaction to changes in the environment. For example, a store manager at C-Mart
    might keep an eye on the length of waiting lines and open new lines if the existing
    ones get too long, so that customers don’t give up and just leave ([Figure 3-24](#example_of_a_feedback_loop_generating_a)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Example of a feedback loop generating a cycle](Images/BEDA_0324.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-24\. Example of a feedback loop generating a cycle
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Managing cycles
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cycles reflect situations that are often complex to study and manage, which
    is why a whole field of research, called *systems thinking*, has sprouted for
    that purpose.^([2](ch03.xhtml#ch01fn7)) Complex mathematical methods, such as
    structural equation modeling, have been developed to deal accurately with cycles,
    but their analysis would take us beyond the scope of this book. I would be remiss,
    however, if I didn’t give you any solution, so I’ll mention two rules of thumb
    that should keep you from getting stuck with cycles.
  prefs: []
  type: TYPE_NORMAL
- en: The first one is to pay close attention to timing. In almost all cases, it takes
    some time for one variable to influence another, which means you can “break the
    cycle” and turn it into an “acyclical” CD, i.e., a CD without cycles (which you
    can then analyze with the tools presented in this book), by looking at your data
    at a more granular level of time. For example, let’s say that it takes 15 minutes
    for a store manager to react to an increasing waiting time by getting new lines
    open, and it similarly takes 15 minutes for customers to adjust their perception
    of waiting time. In that case, by clarifying the temporal order of things, we
    can split the waiting time variable in our CD ([Figure 3-25](#breaking_a_feedback_loop_into_time_incr)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Breaking a feedback loop into time increments](Images/BEDA_0325.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-25\. Breaking a feedback loop into time increments
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'I’ll explain this CD one piece at a time. On the left, we have an arrow from
    average waiting time to number of customers waiting:'
  prefs: []
  type: TYPE_NORMAL
- en: '*NbCustomersWaiting(t* + 15mn) = *β[1].AvgWaitingTime(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: This means that the number of customers waiting at, say, 9:15 a.m. would be
    expressed as a function of the average waiting time at 9:00 a.m. Then the number
    of customers waiting at 9:30 a.m. would have the same relation to the average
    waiting time at 9:15 a.m. and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, on the right, we have an arrow from average waiting time to number
    of lines open:'
  prefs: []
  type: TYPE_NORMAL
- en: '*NbLinesOpen(t* + 15mn) = *β[2].AvgWaitingTime(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: This means that the number of lines open at 9:15 a.m. would be expressed as
    a function of the average waiting time at 9:00 a.m. Then the number of lines open
    at 9:30 a.m. would have the same relation to the average waiting time at 9:15
    a.m. and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then in the middle, we have causal arrows from the number of customers waiting
    and from the number of lines open to the average waiting time. Assuming linear
    relationships here for the sake of simplicity, this would translate into the following
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*AvgWaitingTime(t)* = *β*[3].*NbCustomersWaiting(t)* + *β*[4].*NbLinesOpen(t)*'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In reality, the assumption of linear relationships is *very* unlikely to be
    true in this case. Specific models have been developed for queues, or for time-to-event
    variables (e.g., survival analysis). These models are part of the broader category
    of GLMs, and as such, a good rule of thumb is that for our purposes they’ll behave
    like logistic regressions.
  prefs: []
  type: TYPE_NORMAL
- en: This means that the average waiting time for customers reaching the checkout
    lines at 9:15 a.m. depends on the number of customers already present and the
    number of checkout lines open at 9:15 a.m. Then the average waiting time for customers
    reaching the checkout lines at 9:30 a.m. depends on the number of customers already
    present and the number of checkout lines open at 9:30 a.m. and so on.
  prefs: []
  type: TYPE_NORMAL
- en: By breaking down variables into time increments, we have been able to create
    a CD where there is no cycle in the strict sense. We can estimate the three preceding
    linear regression equations without introducing any circular logic.
  prefs: []
  type: TYPE_NORMAL
- en: The second rule of thumb for dealing with cycles is to simplify your CD and
    to keep only the arrows along the causal path you are most interested in. Feedback
    effects (where a variable influences the variable that just influenced it) are
    generally smaller, and often much smaller, than the first effect and can be ignored
    as a first approximation.
  prefs: []
  type: TYPE_NORMAL
- en: In our example of iced and hot coffee, you might be worried that the increase
    in sales of iced coffee when it is hot will decrease the sale of hot coffee; this
    is a reasonable concern that you should investigate. However, it’s unlikely that
    the decrease in sales of hot coffee would in turn trigger a further increase in
    sales of iced coffee, and you can ignore that feedback effect in your CD ([Figure 3-26](#simplifying_a_cd_by_neglecting_certain)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Simplifying a CD by neglecting certain relationships](Images/BEDA_0326.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-26\. Simplifying a CD by neglecting certain relationships
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In [Figure 3-26](#simplifying_a_cd_by_neglecting_certain), we delete the arrow
    from purchases of hot coffee to purchases of iced coffee and ignore that relationship
    as a reasonable approximation.
  prefs: []
  type: TYPE_NORMAL
- en: Once again, this is just a rule of thumb, and certainly not a blanket invitation
    to disregard cycles and feedback effects. These should be represented fully in
    your complete CD to guide future analyses.
  prefs: []
  type: TYPE_NORMAL
- en: Paths
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Having seen the various ways variables can interact, we can now introduce one
    last concept that encompasses all of them: *paths*. We say that there is a path
    between two variables *if there are arrows between them, regardless of the direction
    of the arrows, and if no variable appears twice along the way.* Let’s see what
    that looks like in a CD we have seen before ([Figure 3-27](#paths_in_a_causal_diagram)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Paths in a causal diagram](Images/BEDA_0327.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-27\. Paths in a causal diagram
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In the previous CD, there are two paths from *SummerMonth* to *IcedCoffeeSales*:'
  prefs: []
  type: TYPE_NORMAL
- en: One path along the chain *SummerMonth* → *Temperature* → *IcedCoffeeSales*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A second path through *IceCreamSales*, *SummerMonth* → *IceCreamSales* ← *Temperature*
    → *IcedCoffeeSales*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This means that a chain is a path, but so are a fork or a collider! Also note
    that two different paths between two variables can also share some arrows, as
    long as there is at least one difference between them, as is the case here: the
    arrow from *Temperature* to *IcedCoffeeSales* appears in both paths.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the following is not a valid path between *Temperature* and *IcedCoffeeSales*
    because *Temperature* appears twice:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Temperature* ← *SummerMonth* → *IceCreamSales* ← *Temperature* → *IcedCoffeeSales*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One consequence of these definitions is that if you pick two different variables
    in a CD, there is always at least one path between them. The definition of paths
    may seem so broad that it is useless, but as we’ll see in [Chapter 5](ch05.xhtml#using_causal_diagrams_to_deconfound_da),
    paths will actually play a crucial role in identifying confounders in a CD.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Correlation is not causation because confounders can introduce bias in our analyses.
    Unfortunately, as we’ve seen through examples, simply throwing all available variables
    and the kitchen sink into a regression is not sufficient to resolve confounding.
    Worse, controlling on the wrong variables can introduce spurious correlations
    and create new biases.
  prefs: []
  type: TYPE_NORMAL
- en: As a first step toward unbiased regression, I introduced a tool known as causal
    diagrams. CDs may be the best analytical tool you’ve never heard of. They can
    be used to represent our intuitions about causal relationships in the real world,
    as well as causal relationships between variables in our data; but they are most
    powerful as a bridge between the two, allowing us to connect our intuition and
    expert knowledge to observed data, and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'CDs can get convoluted and complex, but they are based on three simple building
    blocks: chains, forks, and colliders. They can also be collapsed or expanded,
    sliced, or aggregated, according to simple rules that are consistent with linear
    algebra. If you want to know more about CDs, Pearl and Mackenzie (2018) is a very
    readable and enjoyable book-length introduction.'
  prefs: []
  type: TYPE_NORMAL
- en: The full power of CDs will become apparent in [Chapter 5](ch05.xhtml#using_causal_diagrams_to_deconfound_da),
    where we’ll see that they allow us to optimally handle confounders in regression,
    even with nonexperimental data. But CDs are also helpful more broadly, to help
    us think better about data. In the next chapter, as we get into cleaning and prepping
    data for analysis, they will allow us to mitigate biases in our data prior to
    any analysis. This will give you the opportunity to get more familiar with CDs
    in a simple setting.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch03.xhtml#idm45968167675832-marker)) The most common way to represent
    unobserved variables in CDs is with ovals instead of rectangles.
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](ch03.xhtml#ch01fn7-marker)) Interested readers are referred to *Thinking
    in Systems: A Primer* by Meadows and Wright (2008), as well as *The Fifth Discipline:
    The Art & Practice of the Learning Organization* by Senge (2010).'
  prefs: []
  type: TYPE_NORMAL
