<html><head></head><body>
<div id="sbo-rt-content"><div class="readable-text" id="p1">
<h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">9</span></span> <span class="chapter-title-text">Time series data: Analysis</span></h1>
</div>
<div class="introduction-summary">
<h3 class="introduction-header sigil_not_in_toc">This chapter covers</h3>
<ul>
<li class="readable-text" id="p2">Analyzing time series data to answer a research question</li>
<li class="readable-text" id="p3">Uncovering hidden depth in seemingly simple time series</li>
<li class="readable-text" id="p4">Evaluating whether a time series dataset is appropriate for forecasting</li>
<li class="readable-text" id="p5">Examining the constituent parts of a time series</li>
<li class="readable-text" id="p6">Building a forecasting model</li>
</ul>
</div>
<div class="readable-text" id="p7">
<p>In this chapter, we continue exploring the value of time series data. In chapter 8, we explored raw time series data and decided which records to keep before analyzing the time series further. This chapter is about the second part of the process: analyzing time series data to look for patterns, as well as decomposition and forecasting. We will first recap the project brief from the previous chapter and summarize the work done so far before continuing with the analysis.</p>
</div>
<div class="readable-text" id="p8">
<h2 class="readable-text-h2" id="sigil_toc_id_112"><span class="num-string">9.1</span> Project 6 revisited: Analyzing time series to improve cycling infrastructure</h2>
</div>
<div class="readable-text" id="p9">
<p>We prepared our data, and it is ready for analysis. But before we start the analysis, let’s recap the problem statement and the data dictionary from the previous chapter. The data is available for you to attempt the project yourself at <a href="https://davidasboth.com/book-code">https://davidasboth.com/book-code</a>. You will find the files that you can use for the project, as well as the example solution in the form of a Jupyter notebook. The notebook for this chapter picks up where chapter 8 left off.</p>
</div>
<div class="readable-text" id="p10">
<h3 class="readable-text-h3" id="sigil_toc_id_113"><span class="num-string">9.1.1</span> Problem statement</h3>
</div>
<div class="readable-text" id="p11">
<p>You have been hired to work on a new government initiative, Bikes4Britain, which aims to improve cycling infrastructure in the United Kingdom. The aim of the first phase of the project is to identify the most suitable places around the country to improve infrastructure for cyclists. Specifically, your stakeholders are looking for recommendations of places with either already existing or increasing cycling traffic. They want to start with open data sources and have identified the road traffic statistics of the Department for Transport (the homepage is <a href="https://roadtraffic.dft.gov.uk">https://roadtraffic.dft.gov.uk</a>) as a way to measure cycling traffic across the country.</p>
</div>
<div class="readable-text print-book-callout" id="p12">
<p><span class="print-book-callout-head">NOTE:</span>  The dataset we will use in this project to look for patterns and make recommendations was originally taken from <a href="https://roadtraffic.dft.gov.uk/downloads">https://roadtraffic.dft.gov.uk/downloads</a>. Thank you to the Department for Transport for making this data available under the Open Government Licence.</p>
</div>
<div class="readable-text" id="p13">
<p>The data we are using from the Department for Transport’s statistics is the raw count data. This is a record of raw counts of vehicles that passed a particular counting location at various times. Some of the datasets are too high-level, such as area-level annual summaries, and some of them are estimates, such as the estimated annual average daily flows data (AADFs). The raw count dataset contains data at the most granular level, and we can always aggregate it to higher levels (e.g., annual values) if needed.</p>
</div>
<div class="readable-text" id="p14">
<h3 class="readable-text-h3" id="sigil_toc_id_114"><span class="num-string">9.1.2</span> Data dictionary</h3>
</div>
<div class="readable-text" id="p15">
<p>The data dictionary document, originally obtained from <a href="https://mng.bz/4ajw">https://mng.bz/4ajw</a>, is included in the project files, and table 9.1 shows the columns in detail.</p>
</div>
<div class="browsable-container browsable-table-container framemaker-table-container" id="p16">
<h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 9.1</span> The data dictionary, showing all column definitions</h5>
<table>
<thead>
<tr>
<th>
<div>
         Column name 
       </div></th>
<th>
<div>
         Definition 
       </div></th>
</tr>
</thead>
<tbody>
<tr>
<td> <code>Count_point_id</code> <br/></td>
<td>  A unique reference for the road link that links the AADFs to the road network <br/></td>
</tr>
<tr>
<td> <code>Direction_of_travel</code> <br/></td>
<td>  Direction of travel <br/></td>
</tr>
<tr>
<td> <code>Year</code> <br/></td>
<td>  Counts are shown for each year from 2000 onwards <br/></td>
</tr>
<tr>
<td> <code>Count_date</code> <br/></td>
<td>  The date when the actual count took place <br/></td>
</tr>
<tr>
<td> <code>Hour </code> <br/></td>
<td>  The time when the counts in question took place where 7 represents between 7 a.m. and 8 a.m. and 17 represents between 5 p.m. and 6 p.m. <br/></td>
</tr>
<tr>
<td> <code>Region_id</code> <br/></td>
<td>  Website region identifier <br/></td>
</tr>
<tr>
<td> <code>Region_name </code> <br/></td>
<td>  The name of the region that the CP sits within <br/></td>
</tr>
<tr>
<td> <code>Region_ons_code</code> <br/></td>
<td>  The Office for National Statistics code identifier for the region <br/></td>
</tr>
<tr>
<td> <code>Local_authority_id</code> <br/></td>
<td>  Website local authority identifier <br/></td>
</tr>
<tr>
<td> <code>Local_authority_name</code> <br/></td>
<td>  The local authority that the CP sits within <br/></td>
</tr>
<tr>
<td> <code>Local_authority_code </code> <br/></td>
<td>  The Office for National Statistics code identifier for the local authority <br/></td>
</tr>
<tr>
<td> <code>Road_name</code> <br/></td>
<td>  The road name (for instance, M25 or A3) <br/></td>
</tr>
<tr>
<td> <code>Road_category </code> <br/></td>
<td>  The classification of the road type (see data definitions for the full list) <br/></td>
</tr>
<tr>
<td> <code>Road_type </code> <br/></td>
<td>  Whether the road is a ‘major’ or ‘minor’ road <br/></td>
</tr>
<tr>
<td> <code>Start_junction_road_name </code> <br/></td>
<td>  The road name of the start junction of the link <br/></td>
</tr>
<tr>
<td> <code>End_junction_road_name </code> <br/></td>
<td>  The road name of the end junction of the link <br/></td>
</tr>
<tr>
<td> <code>Easting </code> <br/></td>
<td>  Easting coordinates of the CP location <br/></td>
</tr>
<tr>
<td> <code>Northing</code> <br/></td>
<td>  Northing coordinates of the CP location <br/></td>
</tr>
<tr>
<td> <code>Latitude</code> <br/></td>
<td>  Latitude of the CP location <br/></td>
</tr>
<tr>
<td> <code>Longitude</code> <br/></td>
<td>  Longitude of the CP location <br/></td>
</tr>
<tr>
<td> <code>Link_length_km</code> <br/></td>
<td>  Total length of the network road link for that CP (in kilometers) <br/></td>
</tr>
<tr>
<td> <code>Link_length_miles </code> <br/></td>
<td>  Total length of the network road link for that CP (in miles) <br/></td>
</tr>
<tr>
<td> <code>Pedal_cycles </code> <br/></td>
<td>  Counts for pedal cycles <br/></td>
</tr>
<tr>
<td> <code>Two_wheeled_motor_vehicles</code> <br/></td>
<td>  Counts for two-wheeled motor vehicles <br/></td>
</tr>
<tr>
<td> <code>Cars_and_taxis</code> <br/></td>
<td>  Counts for cars and taxis <br/></td>
</tr>
<tr>
<td> <code>Buses_and_coaches </code> <br/></td>
<td>  Counts for buses and coaches <br/></td>
</tr>
<tr>
<td> <code>LGVs</code> <br/></td>
<td>  Counts for LGVs <br/></td>
</tr>
<tr>
<td> <code>HGVs_2_rigid_axle </code> <br/></td>
<td>  Counts for two-rigid axle HGVs <br/></td>
</tr>
<tr>
<td> <code>HGVs_3_rigid_axle </code> <br/></td>
<td>  Counts for three-rigid axle HGVs <br/></td>
</tr>
<tr>
<td> <code>HGVs_4_or_more_rigid_axle</code> <br/></td>
<td>  Counts for four or more rigid axle HGVs <br/></td>
</tr>
<tr>
<td> <code>HGVs_3_or_4_articulated_axle </code> <br/></td>
<td>  Counts for three- or four-articulated axle HGVs <br/></td>
</tr>
<tr>
<td> <code>HGVs_5_articulated_axle</code> <br/></td>
<td>  Counts for five-articulated axle HGVs <br/></td>
</tr>
<tr>
<td> <code>HGVs_6_articulated_axle</code> <br/></td>
<td>  Counts for six-articulated axle HGVs <br/></td>
</tr>
<tr>
<td> <code>All_HGVs </code> <br/></td>
<td>  Counts for all HGVs <br/></td>
</tr>
<tr>
<td> <code>All_motor_vehicles </code> <br/></td>
<td>  Counts for all motor vehicles <br/></td>
</tr>
</tbody>
</table>
</div>
<div class="readable-text" id="p17">
<p>In the example solution, we will use a smaller, cleaned, and filtered version of the raw data as a starting point, which we created in chapter 8. This has the same structure as the raw data, so the data dictionary in table 9.1 is still applicable.</p>
</div>
<div class="readable-text" id="p18">
<h3 class="readable-text-h3" id="sigil_toc_id_115"><span class="num-string">9.1.3</span> Desired outcomes</h3>
</div>
<div class="readable-text" id="p19">
<p>The output of the project is a recommendation of which area, or areas, to concentrate initial efforts on. These might be areas that already have a lot of high cycle traffic, or they might be areas where cycling is on the rise or forecasted to have high cycling demand in the future. Our recommendation will likely contain suggestions to incorporate additional datasets to continue the analysis. There is probably more that we would like to know about these areas before any infrastructure work is undertaken, and we should outline this additional work to our stakeholders.</p>
</div>
<div class="readable-text intended-text" id="p20">
<p>The output of the example solution from the chapter 8 was an intermediate dataset, which was cleaned and filtered for analysis. The output of the part of the analysis covered by this chapter will be the conclusions and recommendations we set out.</p>
</div>
<div class="readable-text" id="p21">
<h2 class="readable-text-h2" id="sigil_toc_id_116"><span class="num-string">9.2</span> Where should cycling infrastructure improvements be focused?</h2>
</div>
<div class="readable-text" id="p22">
<p>Before we start analyzing our time series data, let’s recap the work we did in the previous chapter to prepare the data for analysis. Figure 9.1 shows the diagram of the work done so far, highlighting where alternative decisions could have been made.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p23">
<img alt="figure" height="1195" src="../Images/9-1.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.1</span> Diagram of the process of preparing time series data to be ready for analysis</h5>
</div>
<div class="readable-text intended-text" id="p24">
<p>Now, it’s time to look at an example walk-through of the analysis portion of the project. As always, I strongly recommend attempting the project yourself first. The example solution will be more relevant if you have your own analysis to compare it to. It bears repeating that the solution is not the solution, just one series of decisions you could make and conclusions you could reach along the way. Use it to generate more ideas and gain a different perspective on how you could have approached the same project brief.</p>
</div>
<div class="readable-text" id="p25">
<h3 class="readable-text-h3" id="sigil_toc_id_117"><span class="num-string">9.2.1</span> Analysis of time series data</h3>
</div>
<div class="readable-text" id="p26">
<p>So far, we have cleaned up our raw traffic data and filtered it down so that we have a long, complete time series of traffic counts. Now it’s time to focus our efforts on the problem at hand by looking specifically at cycling.</p>
</div>
<div class="readable-text" id="p27">
<h4 class="readable-text-h4 sigil_not_in_toc">Calculating distributions in time series data</h4>
</div>
<div class="readable-text" id="p28">
<p>At the end of chapter 8, we exported the data to a Parquet file to separate the data cleaning from the analysis. This section, therefore, begins with reading the same exported data again.</p>
</div>
<div class="readable-text intended-text" id="p29">
<p>We know that in the data, there was a single day in each calendar year when measurements took place. We want to look at long-term trends, so the hourly granularity introduces noise that we want to remove by summarizing data annually. Let’s start there. The following code does this, and a sample of the output is shown in figure 9.2:</p>
</div>
<div class="browsable-container listing-container" id="p30">
<div class="code-area-container">
<pre class="code-area">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
traffic = pd.read_parquet("./data/time_series.parquet.gz")

cycling = (
    traffic
    .groupby(["Count_point_id", "Year"])
    ["Pedal_cycles"]
    .sum()
    .reset_index()
)

cycling.head()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p31">
<img alt="figure" height="271" src="../Images/9-2.png" width="417"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.2</span> A snapshot of annual counts of cycles at each location</h5>
</div>
<div class="readable-text" id="p32">
<p>This data is now one row per location ID per calendar year. Figure 9.2 shows a location with cycling traffic, but there is a possible problem; many of the location IDs might barely have any cycling traffic. To check this, we will look at the distribution of the total number of bicycles seen per location ID across all years. First, we will aggregate the data again to remove the annual values and be left with one row per location ID. This data is created using the following code and shown in figure 9.3:</p>
</div>
<div class="browsable-container listing-container" id="p33">
<div class="code-area-container">
<pre class="code-area">cycling_totals = (
    cycling
    .groupby("Count_point_id")
    ["Pedal_cycles"]
    .sum()
)

cycling_totals.head()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p34">
<img alt="figure" height="196" src="../Images/9-3.png" width="387"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.3</span> Total number of bicycles seen per location ID</h5>
</div>
<div class="readable-text" id="p35">
<p>Now, we can investigate the distribution of these values to get a feel for just how many locations have little or no cycling traffic. We anticipate the data to be heavily skewed to the right, meaning most values are likely to be around zero with a long tail of higher values. To account for this, we will add more bins to the histogram to hopefully better understand the spread of the data. The following code creates the histogram presented in figure 9.4:</p>
</div>
<div class="browsable-container listing-container" id="p36">
<div class="code-area-container">
<pre class="code-area">fig, axis = plt.subplots()

cycling_totals.hist(bins=50, ax=axis)

axis.set(
    xlabel="Frequency",
    ylabel="Total cycling traffic",
    title="Distribution of total cycling traffic by location ID"
)

plt.show()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p37">
<img alt="figure" height="606" src="../Images/9-4.png" width="782"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.4</span> Distribution of total cycling traffic</h5>
</div>
<div class="readable-text" id="p38">
<p>As expected, a lot of locations have recorded almost no cycling traffic. Let’s focus on locations with over a certain amount of total cycling traffic. How do we know what value to use as a cutoff (i.e., consider only locations with over X bikes seen over time)? We should understand the quartiles of these values to get a sense of what cutoff values would constitute the top 25% or 50% of the data. The following code does this, and the output is shown in figure 9.5:</p>
</div>
<div class="browsable-container listing-container" id="p39">
<div class="code-area-container">
<pre class="code-area">cycling_totals.describe()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p40">
<img alt="figure" height="269" src="../Images/9-5.png" width="434"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.5</span> Descriptive statistics for the total cycling traffic values</h5>
</div>
<div class="readable-text" id="p41">
<p>This tells us that half of the locations have recorded 216 or more bicycles in total. Since we have focused on locations with at least 10 years of coverage, this translates to between 10 and 20 bicycles on average per measurement date. Whether that is enough traffic to warrant investigation and recommendations will depend on the business, so for this problem, we will make an assumption about what level of traffic is high enough for us to focus on.</p>
</div>
<div class="readable-text" id="p42">
<p>Before we start cutting this data down, let’s understand it a bit more. Where, for example, is the most cycling traffic? The following code produces the output in figure 9.6 and shows the top 10 location IDs by cycling traffic:</p>
</div>
<div class="browsable-container listing-container" id="p43">
<div class="code-area-container">
<pre class="code-area">cycling_totals.sort_values(ascending=False).head(10)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p44">
<img alt="figure" height="380" src="../Images/9-6.png" width="435"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.6</span> Top 10 location IDs by total cycling traffic</h5>
</div>
<div class="readable-text" id="p45">
<p>We have a location with over 19,000 bicycles recorded and many more with thousands. Personally, I like to put more context around tables like this, so let’s examine the specific location ID at the top of this table.</p>
</div>
<div class="readable-text" id="p46">
<h4 class="readable-text-h4 sigil_not_in_toc">Investigating individual data points for more context</h4>
</div>
<div class="readable-text" id="p47">
<p>Because our data contains many columns, we can use the trick of transposing it to show it as a single column instead. The following code does this, and we can review a single row of data as a vertical table, as shown in figure 9.7. For space reasons, some of the final columns are omitted from the figure but are present in the solution notebook:</p>
</div>
<div class="browsable-container listing-container" id="p48">
<div class="code-area-container">
<pre class="code-area">(
    traffic[traffic["Count_point_id"] == 942489]
    .head(1)
    .transpose()
)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p49">
<img alt="figure" height="1099" src="../Images/9-7.png" width="560"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.7</span> The location ID with the highest cycling traffic (part of a single row of data transposed as a column)</h5>
</div>
<div class="readable-text" id="p50">
<p>This is a minor road of some sort in Islington, which is a borough in North London. Specifically, which road this relates to is not mentioned. There are <code>Road_name</code> and <code>Road_category</code> columns that should tell us more, but they are not informative here. Let’s look at the data dictionary to understand what these specific values mean. As a reminder, the data dictionary is included in the chapter’s materials as a PDF. Table 9.2 shows the values we can expect in the <code>Road_category</code> column.</p>
</div>
<div class="browsable-container browsable-table-container framemaker-table-container" id="p51">
<h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 9.2</span> Data dictionary for the <code>Road_category</code> column</h5>
<table>
<thead>
<tr>
<th>
<div>
         Category 
       </div></th>
<th>
<div>
         Category description 
       </div></th>
</tr>
</thead>
<tbody>
<tr>
<td>  PM <br/></td>
<td>  M or class A principal motorway <br/></td>
</tr>
<tr>
<td>  PA <br/></td>
<td>  Class A principal road <br/></td>
</tr>
<tr>
<td>  TM <br/></td>
<td>  M or class A trunk motorway <br/></td>
</tr>
<tr>
<td>  TA <br/></td>
<td>  Class A trunk road <br/></td>
</tr>
<tr>
<td>  M <br/></td>
<td>  Minor road <br/></td>
</tr>
<tr>
<td>  MB <br/></td>
<td>  Class B road <br/></td>
</tr>
<tr>
<td>  MCU <br/></td>
<td>  Class C or unclassified road <br/></td>
</tr>
</tbody>
</table>
</div>
<div class="readable-text" id="p52">
<p>From this, we can gather that the top cycling location is a very minor or unclassified road. A note in the data dictionary says, “Unclassified roads (referred to as ‘U’ in datasets) include residential roads both in urban and rural situations,” so this is likely a residential road since Islington is not a rural location. These are the pieces of additional context you have as an analyst if you have relevant domain knowledge. If in doubt, ask a domain expert.</p>
</div>
<div class="readable-text intended-text" id="p53">
<p>If we really want to understand a particular location in the data, we have latitude and longitude coordinates we can use. The values for this location are <code>(51.52988,</code> <code>-0.106402)</code>, which, when put into a map, show the map point displayed in figure 9.8.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p54">
<img alt="figure" height="715" src="../Images/9-8.png" width="800"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.8</span> The OpenStreetMap location with the highest cycling traffic</h5>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p55">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Activity: Bring your data to life</h5>
</div>
<div class="readable-text" id="p56">
<p>In this project, whenever you want to find out more about a location ID, you can find it on a map with its coordinates. I encourage you to find opportunities to do so and even look at them with Google Street View, for example. As analysts, we don’t often get the chance to add this much context to our data points, so we should make the most of it!</p>
</div>
</div>
<div class="readable-text" id="p57">
<p>Without knowing more about this particular location, we can only guess why it has by far the highest cycling traffic in the data. Some ideas include</p>
</div>
<ul>
<li class="readable-text" id="p58"> It could simply be that the bicycle shop visible on the map, “Symphony Cycling,” is on this street. </li>
<li class="readable-text" id="p59"> This area might be particularly high in cyclists, but perhaps there is nothing special about this residential street, and any surrounding street would have yielded similar results. </li>
<li class="readable-text" id="p60"> This might be a popular shortcut for cyclists looking to avoid the traffic on the surrounding larger roads on their cycling commute. </li>
<li class="readable-text" id="p61"> There might be some bias around how counting points are chosen in the first place. Perhaps this location was chosen <em>because</em> of its high cycling traffic. </li>
</ul>
<div class="readable-text" id="p62">
<p>Whatever the reason, this poses many interesting questions, one of which is, is all cycling traffic on minor roads, or are there major roads of interest in the data? To answer this question, we will join the total cycling data back to the raw data and find locations where the total amount of cycling is at least X, where X is a value we set. Let’s see whether there were any major roads with over 1,000 bikes seen in total. The following code does this and produces the result in figure 9.9:</p>
</div>
<div class="browsable-container listing-container" id="p63">
<div class="code-area-container">
<pre class="code-area">(
  traffic
  .merge(
    cycling_totals
      .reset_index()    <span class="aframe-location"/> #1
      .rename(columns={
        "Pedal_cycles": "Total_cycles"
      }),
    on="Count_point_id"
  )
  .query("Total_cycles &gt; 1000 and Road_type=='Major'")
)<span class="aframe-location"/></pre>
<div class="code-annotations-overlay-container">
     #1 Converts the cycling totals to a DataFrame before joining to the raw traffic data
     <br/>
</div>
</div>
</div>
<div class="browsable-container figure-container" id="p64">
<img alt="figure" height="82" src="../Images/9-9.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.9</span> No rows returned when looking for major roads with over 1,000 bikes seen in total</h5>
</div>
<div class="readable-text" id="p65">
<p>This tells us that there are no instances of major roads where over 1000 bikes are seen in total. What if we lower that threshold to 100? This means major roads with only 5–10 bikes seen in a given day on average. The following code does this and produces the result in figure 9.10:</p>
</div>
<div class="browsable-container listing-container" id="p66">
<div class="code-area-container">
<pre class="code-area">bikes_100_plus = (
    traffic
    .merge(
        cycling_totals
            .reset_index()
            .rename(columns={"Pedal_cycles": "Total_cycles"}),
        on="Count_point_id"
    )
    .query("Total_cycles &gt; 100 and Road_type=='Major'")
)

bikes_100_plus<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p67">
<img alt="figure" height="82" src="../Images/9-10.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.10</span> Traffic data for locations on major roads with over 100 total bikes seen</h5>
</div>
<div class="readable-text" id="p68">
<p>Even when we only consider 100 bikes in total, there does not seem to be bike traffic on major roads, at least not in the cut-down version of the data we are using. It is therefore likely that, in this analysis, we will not focus on recommending improvements to the cycling infrastructure along major roads. However, perhaps the lack of cycling traffic is an interesting finding itself—something to discuss with our stakeholders as a deeper investigation into how cyclists are having to circumvent major roads may be interesting to them.</p>
</div>
<div class="readable-text intended-text" id="p69">
<p>Let’s add our investigation into the distribution of cycling traffic to our analysis diagram, the latest version of which is shown in figure 9.11.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p70">
<img alt="figure" height="1008" src="../Images/9-11.png" width="558"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.11</span> The analysis so far, up to investigating the distribution of cycling traffic</h5>
</div>
<div class="readable-text intended-text" id="p71">
<p>Focusing on the data at hand, let’s now start looking at locations of interest based on their cycling traffic patterns, starting with locations where cycling has increased since data was first captured.</p>
</div>
<div class="readable-text" id="p72">
<h4 class="readable-text-h4 sigil_not_in_toc">Finding time series that contain upward trends</h4>
</div>
<div class="readable-text" id="p73">
<p>Our first step is to define what we mean by “on the rise.” Do we want to see cycling increase year-on-year consistently for a location to qualify? Since we only have a day’s worth of data each year, there will be noise, so this criterion might be too strict. Let’s look for locations where the latest measurement figure was higher than the first. It’s a crude proxy for “increase in cycling,” but we can filter the data down to the locations with the largest increase.</p>
</div>
<div class="readable-text intended-text" id="p74">
<p>To achieve this, we need to take the rows for each location ID separately, ensure they are in chronological order, and then take the difference between the first and last rows. We should calculate both absolute and percentage changes to sanity-check our results. We also need to account for division by zero errors when calculating percentage change. The following code calculates both absolute and percentage change between the first and last values for each location, ending up with the dataset shown in figure 9.12:</p>
</div>
<div class="browsable-container listing-container" id="p75">
<div class="code-area-container">
<pre class="code-area">def cycling_diff(group):    <span class="aframe-location"/> #1
    return group.values[-1] - group.values[0]

def cycling_diff_pct(group):    <span class="aframe-location"/> #2
    if group.values[0] == 0:    <span class="aframe-location"/> #3
        return np.inf
    diff = group.values[-1] - group.values[0]
    return diff / group.values[0]

cycling_diffs = (
    cycling
    .sort_values(["Count_point_id", "Year"])
    .groupby("Count_point_id")
    .agg(    <span class="aframe-location"/> #4
        diff=("Pedal_cycles",cycling_diff),
        diff_pct=("Pedal_cycles",cycling_diff_pct)
    )
)

cycling_diffs<span class="aframe-location"/></pre>
<div class="code-annotations-overlay-container">
     #1 Defines a function to calculate the difference between the first and last values encountered in a group
     <br/>#2 Defines a function to calculate the change as a percentage
     <br/>#3 Accounts for division-by-zero errors
     <br/>#4 Applies these two functions to every location ID group
     <br/>
</div>
</div>
</div>
<div class="browsable-container figure-container" id="p76">
<img alt="figure" height="754" src="../Images/9-12.png" width="384"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.12</span> Absolute and percentage difference of cycling totals for each location</h5>
</div>
<div class="readable-text" id="p77">
<p>We have a variety of results here. There will be infinite values where the first measurement date yielded no bicycles, as well as instances of both positive and negative change over time. Before investigating this table further, it’s a good idea to verify our calculations. Let’s look at one of the locations and see if the raw data supports the change values we calculated. The following code does this to produce the result in figure 9.13:</p>
</div>
<div class="browsable-container listing-container" id="p78">
<div class="code-area-container">
<pre class="code-area">cycling[cycling["Count_point_id"] == 900056]<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p79">
<img alt="figure" height="694" src="../Images/9-13.png" width="449"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.13</span> Raw annual cycling data for location 900056</h5>
</div>
<div class="readable-text" id="p80">
<p>We found that in 2007, there were 24 bicycles encountered and only 14 in 2019, which is a reduction of 42%, which figure 9.12 also shows. We can spot-check a few more examples to convince ourselves that our calculations are correct. Then, we can look at some of the highest increases in cycling traffic in percentage terms. The following code does this and produces the table in figure 9.14:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p81">
<img alt="figure" height="678" src="../Images/9-14.png" width="384"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.14</span> The locations with the highest percentage change in cycling</h5>
</div>
<div class="browsable-container listing-container" id="p82">
<div class="code-area-container">
<pre class="code-area">biggest_diffs = (
    cycling_diffs
    [np.isinf(cycling_diffs["diff_pct"]) == False]    <span class="aframe-location"/> #1
    .sort_values("diff_pct", ascending=False)
    .head(10)
)

biggest_diffs</pre>
<div class="code-annotations-overlay-container">
     #1 Removes infinity values from consideration
     <br/>
</div>
</div>
</div>
<div class="readable-text print-book-callout" id="p83">
<p><span class="print-book-callout-head">Warning</span>  When encountering division-by-zero scenarios, make sure you understand how your chosen tool represents infinity. In <code>pandas,</code> we use <code>np.inf</code>, a specific value from the <code>numpy</code> library. It is considered greater than all other integers when sorting, so in this instance, we make sure to remove those rows from consideration before sorting.</p>
</div>
<div class="readable-text" id="p84">
<p>We have some interesting cases to investigate. It’s time to plot these time series rather than relying on numeric calculations to determine interesting patterns. The following code produces the plot in figure 9.15. I have included only a few of the time series for clarity:</p>
</div>
<div class="browsable-container listing-container" id="p85">
<div class="code-area-container">
<pre class="code-area">fig, axis = plt.subplots(figsize=(10, 6))

biggest_diff_ids = biggest_diffs.index

ids_to_plot = [943399, 931883, 946565, 990552]

diffs_to_plot = (
    cycling
    .query("Count_point_id in @ids_to_plot")
)

markers = ["o", "s", "P", "^"]

for i, point_id in enumerate(diffs_to_plot["Count_point_id"].unique()):
    point_series = cycling[cycling["Count_point_id"] == point_id]
    (
        point_series
        .set_index("Year")
        ["Pedal_cycles"]
        .plot(ax=axis,
              label=point_id,
              marker=markers[i],
              alpha=0.8)
    )

axis.set(
    xlabel="Year",
    ylabel="Pedal cycles encountered",
    title="Cycling traffic for locations with the highest increase"
)

axis.legend()

plt.show()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p86">
<img alt="figure" height="699" src="../Images/9-15.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.15</span> Some locations with the highest increase in cycling traffic</h5>
</div>
<div class="readable-text" id="p87">
<p>This shows that there are genuine increases in cycling traffic at various locations. We should, however, look at this problem from different angles because the nature of our data—the fact that we count vehicles on a single day each year—is such <span class="aframe-location"/>that all values are subject to bias. There could be special events such as road closures, public holidays, or just varying patterns across weekdays that could explain these increases. Let’s add this latest step to our growing analysis diagram, shown in figure 9.16.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p88">
<img alt="figure" height="1150" src="../Images/9-16.png" width="525"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.16</span> The analysis process, including the latest step of finding locations with cycling on the rise</h5>
</div>
<div class="readable-text intended-text" id="p89">
<p>Another angle we could consider is finding locations where cycling makes up a significant percentage of overall traffic. </p>
</div>
<div class="readable-text" id="p90">
<h4 class="readable-text-h4 sigil_not_in_toc">Identifying time series with certain characteristics</h4>
</div>
<div class="readable-text" id="p91">
<p>Let’s look at how we can calculate cycling as a percentage of overall traffic. We’ve been using the <code>Pedal_cycles</code> column to count cyclists and <code>All_motor_vehicles</code> to count all traffic. However, the phrase “motor vehicles” suggests that perhaps bikes aren’t included. This is something we need to verify before calculating anything. The data dictionary in table 8.1 doesn’t answer this question as it just says that the column measures “counts for all motor vehicles.” Fortunately, the PDF version includes more information. Page 10 contains a section called “Types of vehicle,” under which there is the following: “All motor vehicles: All vehicles except pedal cycles.” Figure 9.17 shows the relevant section of the document.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p92">
<img alt="figure" height="506" src="../Images/9-17.png" width="748"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.17</span> A screenshot of the part of the data dictionary referring to what “all motor vehicles” means</h5>
</div>
<div class="readable-text intended-text" id="p93">
<p>As suspected, to get the total number of vehicles seen, including bikes, we need to add those columns together. We also want to weight recent observations, so we will only take the last date for each location point. In some cases, this may be a few years in the past, but it will at least give us only the most recent data. The steps in the following code are as follows:</p>
</div>
<ol>
<li class="readable-text" id="p94"> Filter the traffic data to the <em>last observed date for each location ID.</em> </li>
<li class="readable-text" id="p95"> <em>Calculate the total traffic</em> by adding the relevant columns together. </li>
<li class="readable-text" id="p96"> <em>Group the data by location ID</em> to reduce the granularity to one row per location. </li>
<li class="readable-text" id="p97"> <em>Sum</em> the total traffic column and the bikes column. </li>
<li class="readable-text" id="p98"> <em>Calculate cycling as a percentage</em> for each location. </li>
</ol>
<div class="readable-text" id="p99">
<p>What follows is Python code for this, and a snapshot of the resulting dataset is shown in figure 9.18:</p>
</div>
<div class="browsable-container listing-container" id="p100">
<div class="code-area-container">
<pre class="code-area">annual_bike_traffic = (
    traffic
    [traffic['Count_date']
 == traffic.groupby('Count_point_id')['Count_date'].transform('max')]
    .assign(
        all_traffic=lambda x: x["Pedal_cycles"] + x["All_motor_vehicles"]
    )
    .groupby(["Count_point_id", "Year"])
    [["Pedal_cycles", "all_traffic"]]
    .sum()
    .assign(
        pct_cycles = lambda x: x["Pedal_cycles"] / x["all_traffic"]
    )
    .sort_values("pct_cycles", ascending=False)
)

annual_bike_traffic.head()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p101">
<img alt="figure" height="342" src="../Images/9-18.png" width="662"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.18</span> Total traffic and cycling as an absolute and percentage value for each location</h5>
</div>
<div class="readable-text" id="p102">
<p>Figure 9.18 shows each location ID, the most recent year for which we have data, and the traffic calculations, including the percentage of traffic attributed to cycling. We can already notice some locations with a high percentage of cycling traffic. Let’s investigate one of those examples in more detail. We will zoom in on just the first row from figure 9.18 and identify its location. The output is shown in figure 9.19.</p>
</div>
<div class="browsable-container listing-container" id="p103">
<div class="code-area-container code-area-with-html">
<pre class="code-area">(
  traffic[(traffic["Count_point_id"] == 942489)
<span class="">↪</span>  &amp; (traffic["Year"] == 2019)]
  .head(1)
  .transpose()
)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p104">
<img alt="figure" height="987" src="../Images/9-19.png" width="500"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.19</span> A specific location with a high cycling traffic percentage</h5>
</div>
<div class="readable-text" id="p105">
<p>If we looked at this point on a map, we would find the same location we saw in figure 9.7. This is in fact the same suburban street in Islington, North London, that had the highest volume of cycling traffic in absolute terms. It’s useful to see the same result verified from a different angle.</p>
</div>
<div class="readable-text print-book-callout" id="p106">
<p><span class="print-book-callout-head">NOTE</span>  Take a minute to look into some of the other locations that came up with high cycling traffic in the table produced in figure 9.6. Do you notice any patterns?</p>
</div>
<div class="readable-text" id="p107">
<p>Looking at some of these locations, we see they all seem to be small suburban streets, perhaps being used as commuting shortcuts. Figure 9.20 shows the process so far, highlighting the fact that we are doing some investigations in parallel, with the results coming together at the end.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p108">
<img alt="figure" height="705" src="../Images/9-20.png" width="594"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.20</span> The current state of the analysis</h5>
</div>
<div class="readable-text" id="p109">
<p>Following our train of thought about some of these top locations, commuter pathways seem like a useful avenue to explore further, so let’s move our focus to that.</p>
</div>
<div class="readable-text" id="p110">
<h4 class="readable-text-h4 sigil_not_in_toc">Identifying temporal patterns within time series</h4>
</div>
<div class="readable-text" id="p111">
<p>To investigate commuting patterns, we will do two things:</p>
</div>
<ul>
<li class="readable-text" id="p112"> Look at the most popular times of day for cycling at each location. In other words, what hour(s) of the day do people cycle the most? </li>
<li class="readable-text" id="p113"> Once we understand this, we will identify locations where cycling traffic is highest during commuting hours. </li>
</ul>
<div class="readable-text" id="p114">
<p>The first item requires us to calculate the average cycling traffic per hour. We can decide whether to average the results across all years of data or keep focusing on only the latest figures. Both approaches have pros and cons. Averaging across the entire data will negate possible changes in behavior over time if people don’t commute by bicycle the same way they did 10–20 years ago. Using only the most recent data means we amplify any particular biases that may have occurred that year (e.g., road closures that were otherwise not present). We still want to bias toward recency, so we will go with the latter option. A more sophisticated idea might be to perform a weighted average over time, weighting recent measurements higher than older ones.</p>
</div>
<div class="readable-text intended-text" id="p115">
<p>What does this particular calculation process look like? We will perform the following steps:</p>
</div>
<ol>
<li class="readable-text" id="p116"> <em>Filter the cycling data to the most recent year for each location </em>—This will give us an up-to-date view on cycling patterns. </li>
<li class="readable-text" id="p117"> <em>Calculate the percentage of bike traffic that occurred in each hour of the day —</em>Using a percentage means comparable results regardless of the popularity of the location. </li>
<li class="readable-text" id="p118"> <em>Visualize the distribution of these percentage values by hour —</em>Using our “start at the end” approach, we imagine the final visualization. In this case, it will be a series of box plots, each representing an hour of the day and individual points representing the percentage of bike traffic in that hour of the day for a location. </li>
</ol>
<div class="readable-text" id="p119">
<p>From a technical perspective, the tricky point here is the first step. We need to count the total amount of cycling traffic per location while simultaneously comparing hourly values to that daily total. This requires us to have both hourly and daily values side by side. If you are a SQL user, this would be achieved with a <em>window function</em> using the <code>PARTITION</code> <code>BY</code> keyword. In <code>pandas</code>, we need to do something slightly different, in fact, so different that we can enlist the help of our favorite LLM.</p>
</div>
<div class="readable-text intended-text" id="p120">
<p>I asked ChatGPT how to achieve this, and its first result suggested calculating hourly and daily totals separately and then joining the two tables by location ID. This is a perfectly good approach, but I specifically asked about using a window function-like approach. Figure 9.21 shows the part of the conversation where I steered ChatGPT to the result I wanted.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p121">
<img alt="figure" height="375" src="../Images/9-21.png" width="780"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.21</span> A snippet of a conversation with ChatGPT about window functions in <code>pandas</code></h5>
</div>
<div class="readable-text" id="p122">
<p>Therefore, we can use the <code>transform</code> method to achieve the desired result, which is to create a column alongside the raw data that captures the total daily cycling traffic for each location ID. Let’s first filter our traffic to include only the most recent date for each location:</p>
</div>
<div class="browsable-container listing-container" id="p123">
<div class="code-area-container">
<pre class="code-area">traffic_max_dates = (
    traffic[
        traffic['Count_date']
        == traffic.groupby('Count_point_id')['Count_date'].transform('max')
    ]
    .copy()
)</pre>
</div>
</div>
<div class="readable-text" id="p124">
<p>We will now aggregate this <code>traffic_max_dates</code> DataFrame to one row per location per hour. The following code does this and produces the output in figure 9.22:</p>
</div>
<div class="browsable-container listing-container" id="p125">
<div class="code-area-container">
<pre class="code-area">cycling_daily_hourly = (
    traffic_max_dates.groupby(
        ["Count_point_id", "Count_date", "hour"]
    )
    ["Pedal_cycles"]
    .sum()
    .reset_index()
)

cycling_daily_hourly.head()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p126">
<img alt="figure" height="267" src="../Images/9-22.png" width="546"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.22</span> Hourly cycling traffic per location for only the latest date for each location</h5>
</div>
<div class="readable-text" id="p127">
<p>Now, we need to create a column to measure total cycling traffic alongside this data to be able to calculate the percentage of cycling traffic attributable to each hour of the day for each location. This is where we use the trick that ChatGPT has shown us. The following code adds this column and calculates the percentage of traffic per hour, resulting in the data in figure 9.23:</p>
</div>
<div class="browsable-container listing-container" id="p128">
<div class="code-area-container">
<pre class="code-area">cycling_daily_hourly['TotalDailyCount'] = (
    cycling_daily_hourly
    .groupby(['Count_point_id', 'Count_date'])
    ['Pedal_cycles']
    .transform('sum')    <span class="aframe-location"/> #1
)

cycling_daily_hourly['hourly_pct'] = (
    cycling_daily_hourly['Pedal_cycles']
    / cycling_daily_hourly['TotalDailyCount']
)

cycling_daily_hourly<span class="aframe-location"/></pre>
<div class="code-annotations-overlay-container">
     #1 Transform calculates the total amount of traffic per location ID, so we can add it as an extra column without requiring an additional join.
     <br/>
</div>
</div>
</div>
<div class="browsable-container figure-container" id="p129">
<img alt="figure" height="631" src="../Images/9-23.png" width="891"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.23</span> Hourly data with additional percentage calculations appended</h5>
</div>
<div class="readable-text" id="p130">
<p>This is an instance where we want to verify those daily counts and percentage values before continuing. Let’s look at that first example, location 900056. First, we calculate the latest date for that location from the raw data to ensure we have the right data:</p>
</div>
<div class="browsable-container listing-container" id="p131">
<div class="code-area-container code-area-with-html">
<pre class="code-area">traffic_max_dates.loc[
<span class="">↪</span> traffic_max_dates["Count_point_id"] == 900056, "Count_date"].max()</pre>
</div>
</div>
<div class="readable-text" id="p132">
<p>The output is <code>2019-05-20,</code> which tallies with the table in figure 9.23. Now, we want to look at all the raw data for that location ID and date to see whether the total cycling count really was 14 and, therefore, whether the percentages are also correct. The following code finds the raw data, which is shown in figure 9.24:</p>
</div>
<div class="browsable-container listing-container" id="p133">
<div class="code-area-container">
<pre class="code-area">(
    cycling_daily_hourly
    [
        (cycling_daily_hourly["Count_point_id"] == 900056)
        &amp; (cycling_daily_hourly["Count_date"] == "2019-05-20")
    ]
)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p134">
<img alt="figure" height="642" src="../Images/9-24.png" width="885"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.24</span> Raw data used to verify calculations of hourly cycling traffic percentages</h5>
</div>
<div class="readable-text" id="p135">
<p>From this raw data, we can notice that adding up the <code>Pedal_cycles</code> column matches the total, and the percentages in the <code>hourly_pct</code> column are also correct. To summarize, we found that around a third of cycling traffic at this location is seen between 5 p.m. and 6 p.m., and the rest is scattered throughout the day. We can use this data across all location IDs to identify what percentage of cycling traffic is seen at different hours of the day in the box plot we imagined earlier. The following code creates the box plot shown in figure 9.25:</p>
</div>
<div class="browsable-container listing-container" id="p136">
<div class="code-area-container">
<pre class="code-area">fig, axis = plt.subplots()

cycling_daily_hourly.boxplot(
    column="hourly_pct",
    by="hour",
    ax=axis)

axis.set(
    xlabel="Hour",
    ylabel= "% of cycling traffic in an hour",
    title="What times of the day does most cycling traffic occur?"
)
plt.suptitle(None)

plt.show()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p137">
<img alt="figure" height="588" src="../Images/9-25.png" width="784"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.25</span> Box plots showing how cycling traffic is distributed throughout the hours of the day</h5>
</div>
<div class="readable-text" id="p138">
<p>There is a lot of noise and outliers in these box plots, but if we focus on the median lines, the middles of the boxes, we notice that there is a rise in traffic approaching 5 p.m. as well as a peak at 8 a.m. followed by a sharp drop. This tells us that there is a commuting pattern in the data as a higher percentage of cycling traffic occurs between 8 a.m. and 9 a.m., as well as between 5 p.m. and 6 p.m. The closeness of the medians between 3 p.m. and 6 p.m. also suggests that while people generally commute <em>to</em> <em>work</em> at the same time, the times at which people commute <em>from</em> <em>work</em> vary more.</p>
</div>
<div class="readable-text intended-text" id="p139">
<p>Equipped with this knowledge, we can now find locations where the highest percentage of cycling traffic occurs during commuting hours. We can think of these as “commuting hotspots”—areas where a significant proportion of cycling traffic is commute driven. We already have data aggregated at the hourly level, shown in figure 9.23, so from that, we can find the hour with the highest cycling traffic for each cycling location. There are a couple of edge cases to make decisions on first:</p>
</div>
<ul>
<li class="readable-text" id="p140"> What happens if all cycling traffic is zero? We should probably output a missing value to show that this particular operation doesn’t make sense for that location. </li>
<li class="readable-text" id="p141"> What if there are multiple hours with the same amount of cycling traffic? We could either take the first or last hour we encounter the maximum value or average the results somehow. Averaging two different hours of the day doesn’t sound meaningful, so we will make the decision to use the first hour where we encounter the maximum value. That is, if the highest cycling traffic is at 8 a.m. and 1 p.m., we output 8 a.m. </li>
</ul>
<div class="readable-text" id="p142">
<p>The following code defines a function to calculate the highest hour for a given group, that is, a single location ID, then uses it to create a dataset with one row per location ID containing the hour in which cycling traffic was highest in the last recorded measurement year. A snapshot of this aggregated data is shown in figure 9.26:</p>
</div>
<div class="browsable-container listing-container" id="p143">
<div class="code-area-container">
<pre class="code-area">def get_highest_hour(rows):
    if rows["Pedal_cycles"].min() == rows["Pedal_cycles"].max():
        return np.nan

    return (
        rows
        .sort_values(by=["Pedal_cycles", "hour"], ascending=[False, True])
        .head(1)
        ["hour"]
        .values[0]
    )

highest_hours = (
    cycling_daily_hourly
    .groupby("Count_point_id")
    .apply(get_highest_hour)
)

highest_hours.head()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p144">
<img alt="figure" height="251" src="../Images/9-26.png" width="221"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.26</span> Highest hour of cycling traffic per location ID</h5>
</div>
<div class="readable-text" id="p145">
<p>We may find a few instances of missing values where the lowest and highest cycling volume was the same, including when it was zero throughout. In figure 9.26, however, we see examples of an actual highest hour being output. One scenario we need to account for is cases where we need a tiebreak because the highest cycling traffic occurred in multiple hours. The following code retrieves raw data for such an example, which is shown in figure 9.27:</p>
</div>
<div class="browsable-container listing-container" id="p146">
<div class="code-area-container">
<pre class="code-area">cycling_daily_hourly[cycling_daily_hourly["Count_point_id"] == 941463]<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p147">
<img alt="figure" height="629" src="../Images/9-27.png" width="891"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.27</span> Hourly data for location 941463 showing that both hour values 8 and 16 had the highest cycling traffic</h5>
</div>
<div class="readable-text" id="p148">
<p>Because, inside our function, we sorted our data in ascending order of cycling traffic, and in ascending order by hour, we returned the earliest instance of encountering the highest traffic. We may choose to do something about this explicitly or accept that there may be a slight bias toward earlier times when calculating which hour is the busiest by location. We will do the latter in this instance because the occurrence of a tie is likely not that common.</p>
</div>
<div class="readable-text intended-text" id="p149">
<p>If we look at the distribution of the busiest hours, we will be able to see at what time most locations have their cycling traffic peaks. The following code creates the histogram shown in figure 9.28:</p>
</div>
<div class="browsable-container listing-container" id="p150">
<div class="code-area-container">
<pre class="code-area">fig, axis = plt.subplots()

highest_hours.hist(bins=20, ax=axis)

axis.set(
    xlabel="Hour of peak cycling traffic",
    ylabel="Frequency",
    title="Distribution of peak cycling traffic hours across locations"
)

plt.show()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p151">
<img alt="figure" height="864" src="../Images/9-28.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.28</span> Distribution of peak cycling hours across locations</h5>
</div>
<div class="readable-text" id="p152">
<p>This plot reinforces the idea that most locations have their peak cycling traffic during commuter hours. Let’s summarize what we’ve learned so far about cycling patterns:</p>
</div>
<ul>
<li class="readable-text" id="p153"> There is variation in cycling trends, but most importantly, there are multiple locations with increased cycling traffic over time. </li>
<li class="readable-text" id="p154"> There is also variation in what percentage of traffic is cycling, but crucially, there are locations where cycling is the majority of traffic. </li>
<li class="readable-text" id="p155"> There is also variation in when people cycle, but there are locations with commuting patterns of cycling traffic. </li>
<li class="readable-text" id="p156"> Following on from that, there are locations where commuting hours are the busiest for cycling. </li>
</ul>
<div class="readable-text" id="p157">
<p>Each of these criteria could be used to find places of interest with respect to cycling. How do we decide which criterion makes sense?</p>
</div>
<div class="readable-text print-book-callout" id="p158">
<p><span class="print-book-callout-head">Note</span>  If you’re interested in examples of where “deciding what is best” is the primary goal, see chapter 4, which is all about choosing the right metrics.</p>
</div>
<div class="readable-text" id="p159">
<p>We would need to use domain knowledge and talk to stakeholders to get a true sense of this, but for now, there doesn’t seem to be a good reason not to use all these criteria. Because we are trying to filter our locations down to the ones of most interest, let’s try finding locations that match all those criteria, specifically,</p>
</div>
<ul>
<li class="readable-text" id="p160"> Locations where the percentage of cycling traffic is high, that is, at least X%, where we have to define X </li>
<li class="readable-text" id="p161"> Locations where there has been an increase in cycling traffic, that is, an increase of at least Y% where we have to define Y </li>
<li class="readable-text" id="p162"> Locations where cycling is used for commuting, that is, peak cycling traffic is either 8 a.m.–9 a.m. or 5 p.m.–6 p.m. </li>
</ul>
<div class="readable-text" id="p163">
<p>If applying all these criteria yields too few results, we can always broaden them by looking for afternoon commuting times between 4 p.m. and 7 p.m., for example. Before combining our results to find cycling locations of interest, let’s recap the process. Figure 9.29 shows the latest state of the analysis.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p164">
<img alt="figure" height="719" src="../Images/9-29.png" width="887"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.29</span> The analysis process just before we combine our results into final recommendations</h5>
</div>
<div class="readable-text" id="p165">
<p>Let’s apply the different criteria we determined we would use to select locations of interest and see if we find anything.</p>
</div>
<div class="readable-text" id="p166">
<h4 class="readable-text-h4 sigil_not_in_toc">Combining criteria to identify time series of interest</h4>
</div>
<div class="readable-text" id="p167">
<p>To find locations that match multiple criteria, we could either perform a single, large query with multiple filters or create filtered versions of each criterion and combine them at the end. We will prefer the latter approach because it allows us to investigate each subset separately. This might be useful if we find nothing is returned and want to investigate which criterion is too strict and yields no results.</p>
</div>
<div class="readable-text intended-text" id="p168">
<p>Let’s first filter the locations to keep only those with a significant percentage of traffic being cycling. How do we know what percentage to use as a cutoff? We haven’t actually looked at the distribution of this percentage yet, so we’ll start there, and the resulting histogram will show us where the majority of the data lies. The following code creates the histogram in figure 9.30, which we will use to make this decision. We will use a DataFrame we have already created, which we called <code>annual_bike_traffic</code>, that contains the percentage of traffic attributed to cycling in the latest year:</p>
</div>
<div class="browsable-container listing-container" id="p169">
<div class="code-area-container">
<pre class="code-area">fig, axis = plt.subplots()

annual_bike_traffic["pct_cycles"].hist(bins=10, ax=axis)

axis.set(
    xlabel="Percentage of traffic that is cycling",
    ylabel="Frequency",
    title="Distribution of cycling traffic percentages"
)

plt.show()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p170">
<img alt="figure" height="529" src="../Images/9-30.png" width="677"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.30</span> Distribution of the percentage of traffic due to cycling at each location</h5>
</div>
<div class="readable-text" id="p171">
<p>This histogram shows that most locations have under 10% of their traffic due to cycling. That feels like a good cutoff to distinguish areas of significant cycling traffic. The following code implements this filter and creates a filtered list of location IDs, a snapshot of which is shown in figure 9.31:</p>
</div>
<div class="browsable-container listing-container" id="p172">
<div class="code-area-container">
<pre class="code-area">BIKE_PERCENTAGE_CUTOFF = 0.1

highest_cycling = (
    annual_bike_traffic
    [annual_bike_traffic["pct_cycles"] &gt;= BIKE_PERCENTAGE_CUTOFF]
    .reset_index()
    ["Count_point_id"]
    .to_list()
)

print(len(highest_cycling))

highest_cycling[:10]<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p173">
<img alt="figure" height="55" src="../Images/9-31.png" width="1023"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.31</span> Location IDs with significant cycling traffic</h5>
</div>
<div class="readable-text" id="p174">
<p>This shows there are 38 locations with at least 10% of traffic due to cycling. Now, we want to create a similar list of locations, but this time, locations that had at least a Y% increase in cycling between the first and last dates we measured. The value for Y will be somewhat arbitrary, and we may decide to tweak it if we want to return more locations. We will start with 50% and see what that gets us. The following code creates this filtered list, which yields a list of numbers similar to that shown in figure 9.31. Again, we already have the underlying values calculated from a previous DataFrame, <code>cycling_diffs</code>:</p>
</div>
<div class="browsable-container listing-container" id="p175">
<div class="code-area-container">
<pre class="code-area">DIFF_CUTOFF = 0.5

biggest_increases = (
    cycling_diffs
    [(cycling_diffs["diff_pct"] &gt;= DIFF_CUTOFF)
     &amp; (np.isinf(cycling_diffs["diff_pct"]) == False)]    <span class="aframe-location"/> #1
    .index
    .to_list()
)

print(len(biggest_increases))

print(biggest_increases[:10])</pre>
<div class="code-annotations-overlay-container">
     #1 We need to exclude infinity values, so they don’t show up in calculations.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p176">
<p>The result of this code tells us there are 230 such locations. Finally, we will create a third list of locations, which will be locations where the highest commuting time is either 8 a.m.–9 a.m. or 5 p.m.–6 p.m. The following code does this using the <code>highest_hours</code> DataFrame created earlier:</p>
</div>
<div class="browsable-container listing-container" id="p177">
<div class="code-area-container">
<pre class="code-area">highest_commuting = (
    highest_hours
    .loc[lambda x: x.isin([8, 17])]
    .index
    .to_list()
)

print(len(highest_commuting))

print(highest_commuting[:10])</pre>
</div>
</div>
<div class="readable-text" id="p178">
<p>The output is a list of 195 locations. We now have three lists of locations to combine. What we want to know is which location IDs appear in all three lists. In Python, we can do this quite easily using set theory. In this case, a <em>set</em> is the specific mathematical concept of a collection of unique elements.</p>
</div>
<div class="readable-text print-book-callout" id="p179">
<p><span class="print-book-callout-head">Tip</span>  If you’re a Python user, whenever you encounter problems with unique values, consider whether using sets is appropriate. They’re often a fast and simple way to get a complex result, such as finding values that appear in two or more collections.</p>
</div>
<div class="readable-text" id="p180">
<p>By converting our lists into sets, we can calculate the <em>intersection</em> of the sets, that is, elements that appear in both sets. You can think of this as finding the center of a Venn diagram of three circles, as illustrated in figure 9.32.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p181">
<img alt="figure" height="967" src="../Images/9-32.png" width="996"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.32</span> Illustration of identifying locations with multiple criteria using set theory</h5>
</div>
<div class="readable-text" id="p182">
<p>The following code converts our lists to sets and performs the intersection of all three to discover whether there are any overlaps. The result is shown in figure 9.33:</p>
</div>
<div class="browsable-container listing-container" id="p183">
<div class="code-area-container">
<pre class="code-area">top_cycling_locations = (
    set(highest_cycling)    <span class="aframe-location"/> #1
    .intersection(set(biggest_increases))    <span class="aframe-location"/> #2
    .intersection(set(highest_commuting))    <span class="aframe-location"/> #3
)

print(len(top_cycling_locations))

print(top_cycling_locations)<span class="aframe-location"/></pre>
<div class="code-annotations-overlay-container">
     #1 Converts the first list to a set
     <br/>#2 Finds the intersection between two of the sets
     <br/>#3 Finds the intersection between this result and the third set
     <br/>
</div>
</div>
</div>
<div class="browsable-container figure-container" id="p184">
<img alt="figure" height="55" src="../Images/9-33.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.33</span> The list of the final locations of interest</h5>
</div>
<div class="readable-text" id="p185">
<p>It looks like our criteria weren’t too restrictive, and we have some results—11, to be precise. These locations all have a significant percentage of traffic due to cycling, at least a 50% increase in cycling volume over time, and they have peaks at commuting times. It’s time to dig into these results and understand what locations they relate to. Let’s look these location IDs up in the raw traffic data, extract only location information, and limit each location to a single row. We will also sort the results by region and local authority to better see where these top locations are geographically. The following code does all this and produces the table in figure 9.34:</p>
</div>
<div class="browsable-container listing-container" id="p186">
<div class="code-area-container">
<pre class="code-area">LOCATION_COLUMNS = ['Count_point_id', 'Region_name',
                    'Region_ons_code', 'Local_authority_id',
                    'Local_authority_name', 'Local_authority_code',
                    'Road_name', 'Road_category', 'Road_type']

(
    traffic[traffic["Count_point_id"].isin(top_cycling_locations)]
    .drop_duplicates(subset=["Count_point_id"])
    [LOCATION_COLUMNS]
    .sort_values(["Region_name", "Local_authority_name"])
)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p187">
<img alt="figure" height="627" src="../Images/9-34.png" width="986"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.34</span> Information about the top cycling locations</h5>
</div>
<div class="readable-text" id="p188">
<p>There are locations scattered throughout the country. Unsurprisingly, perhaps, there are quite a few in London, but results stretch from Bristol in the southwest all the way to Edinburgh up north in Scotland. Once we go through and verify these locations to make sure none of them are just artifacts in the data, we are ready to present our preliminary findings to our stakeholders. However, before we summarize our findings, let’s take a detour into forecasting since that is one of the ways in which time series data can be powerful.</p>
</div>
<div class="readable-text" id="p189">
<h4 class="readable-text-h4 sigil_not_in_toc">Forecasting time series</h4>
</div>
<div class="readable-text" id="p190">
<p>We have enough to show stakeholders and start thinking about further work, but in the spirit of this being a time series problem, we should consider how well we can forecast cycling trends based on the available data. This would help us identify locations where we expect cycling to increase significantly soon, as well as open up other opportunities, such as proactive traffic management.</p>
</div>
<div class="readable-text intended-text" id="p191">
<p>To successfully forecast a time series, we typically need it to obey some properties:</p>
</div>
<ul>
<li class="readable-text" id="p192"> <em>The time series should be at consistent intervals. </em>We’ve already achieved this by creating an annual time series and removing the specific date component because measurements were not usually taken on the same day each year. </li>
<li class="readable-text" id="p193"> <em>The time series should have no gaps.</em> We filtered down our time series to ensure this was the case. </li>
<li class="readable-text" id="p194"> <em>There should be as many full cycles of data as possible.</em> In the case of annual data, we don’t necessarily have cycles, so in our case, this just means the more data we have, the better. </li>
<li class="readable-text" id="p195"> <em>There are other properties, such as stationarity, that some models require the time series to exhibit.</em> This is not exhaustive, though, since other models can account for this automatically. </li>
</ul>
<div class="readable-text" id="p196">
<p>To see whether our time series can be successfully forecasted, let’s examine one of them in more detail. Let’s choose a time series that exhibits a trend, that is, one of the time series from our “biggest increases” list that has the greatest possible coverage. The following code calculates the coverage of these time series and produces the table in figure 9.35, from which we will choose our sample:</p>
</div>
<div class="browsable-container listing-container" id="p197">
<div class="code-area-container">
<pre class="code-area">(
    traffic
    .query("Count_point_id in @biggest_increases")
    .groupby("Count_point_id")
    ["Year"]
    .agg(["min", "max"])
    .assign(diff=lambda df_: df_["max"] - df_["min"])
    .sort_values("diff", ascending=False)
    .head()
)<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p198">
<img alt="figure" height="324" src="../Images/9-35.png" width="370"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.35</span> Locations with the biggest increase in cycling and with their coverage calculated</h5>
</div>
<div class="readable-text" id="p199">
<p>Some of these locations have as much as 19 years of data, and we will pick one of those to investigate. We will arbitrarily use the first location in that list to test our ability to forecast these location-level time series. The following code takes the raw data for that location and creates a single annual time series of cycling volumes for us to use. The resulting time series is shown in figure 9.36:</p>
</div>
<div class="browsable-container listing-container" id="p200">
<div class="code-area-container">
<pre class="code-area">cycling_ts = (
    traffic[traffic["Count_point_id"] == 996188]
    .groupby("Year")
    ["Pedal_cycles"]
    .sum()
)

cycling_ts<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p201">
<img alt="figure" height="671" src="../Images/9-36.png" width="416"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.36</span> The cycling time series for location 996188</h5>
</div>
<div class="readable-text" id="p202">
<p>One Python-specific aspect to notice is that the index of the series is an integer, whereas to make time series manipulation easier, it should be a date. The following code fixes that and allows us to plot the time series, as shown in figure 9.37:</p>
</div>
<div class="browsable-container listing-container" id="p203">
<div class="code-area-container">
<pre class="code-area">cycling_ts.index = pd.to_datetime(cycling_ts.index, format='%Y')

fig, axis = plt.subplots()

cycling_ts.plot(ax=axis)

axis.set(
    xlabel="Time",
    ylabel="Number of bicycles observed",
    title="Cycling traffic over time at location 996188"
)

plt.show()<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p204">
<img alt="figure" height="861" src="../Images/9-37.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.37</span> Cycling traffic time series at a specific location</h5>
</div>
<div class="readable-text" id="p205">
<p>We have a time series of 19 annual values with an upward trend. We often want to see if a time series has seasonality, that is, patterns that repeat at the same point along the time series, but this makes less sense in the context of annual values.</p>
</div>
<div class="readable-text intended-text" id="p206">
<p>To understand the individual components of a time series, we can <em>decompose</em> the series into trend, seasonal, and residual components. Trend tells us whether there is a long-term change in the average of the values, that is, whether the values are moving in a particular direction. Seasonality is the regularly occurring movements that depend on where in the time series we are. Residuals are what is left after we have taken both trend and seasonality into account. Unexpectedly high residuals mean there was something unusual about a time series at that point, which cannot be explained by its underlying trend and seasonal patterns alone.</p>
</div>
<div class="readable-text intended-text" id="p207">
<p>In Python, the <code>statsmodels</code> module has various time series methods, including decomposition, which we will apply to our time series. We will implement STL (seasonal and trend decomposition using LOESS [locally estimated scatterplot smoothing]), and attempt to extract the trend, seasonal, and residual components of a time series. With a lot of these methods, we need to pick some parameter values that will alter the results. In the case of STL, we need to pick the period, how much smoothing to apply to the trend, and how many observations constitute a season.</p>
</div>
<div class="readable-text intended-text" id="p208">
<p>In our case, we have annual data with no clear, regular seasonal pattern. As annual time series are a special case for some of these methods, we can turn to our AI tools for further guidance. The documentation of the library we’re using may also contain hints on how to choose parameter values. In this instance, I asked ChatGPT to advise on picking these values for an annual time series with no real seasonality. A portion of its response is shown in figure 9.38.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p209">
<img alt="figure" height="1414" src="../Images/9-38.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.38</span> ChatGPT’s response regarding the parameters in the STL decomposition method</h5>
</div>
<div class="readable-text intended-text" id="p210">
<p>This answer suggests that in cases where there is no clear seasonality, choosing parameter values will come down to what fits the problem best. It recommends a low value for the seasonal parameter and to favor default values where possible. We will set the period to <code>2</code> and seasonal to <code>3</code> and examine the output. The code is as follows and produces the decomposition plot shown in figure 9.39:</p>
</div>
<div class="browsable-container listing-container" id="p211">
<div class="code-area-container">
<pre class="code-area">from statsmodels.tsa.seasonal import STL

stl = STL(cycling_ts, period=2, seasonal=3)
result = stl.fit()

result.plot();<span class="aframe-location"/></pre>
</div>
</div>
<div class="browsable-container figure-container" id="p212">
<img alt="figure" height="802" src="../Images/9-39.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.39</span> Seasonal decomposition of a single time series</h5>
</div>
<div class="readable-text" id="p213">
<p>This plot shows us (from top to bottom) the raw data, the trend component, the seasonal patterns, and the residuals. In the trend component, we find a smoothed version of the time series, which looks like a fairly steady rise throughout, perhaps leveling out at the end. Because we set a low smoothing value, the seasonal component mimics the peaks seen in the raw data. This is to reinforce the idea that there might not be a repeated seasonal variation, but there are distinct peaks to investigate. The residuals start off larger at the beginning and seem consistently centered around zero afterward. The peak we encounter around 2002 is unexpected if we were to simply model the series using the trend and seasonal variation, which tells us there are external factors that make the start of this series less predictable.</p>
</div>
<div class="readable-text intended-text" id="p214">
<p>All in all, we have learned that the time series seems mostly predictable, apart from perhaps around 2002. Our next step is to build a forecasting model. If we had domain expertise, we could investigate possible reasons behind the higher residuals around 2002 and build those reasons in as additional variables. For now, we will use a standard forecasting method, ARIMA, to predict cycling traffic in the next couple of years.</p>
</div>
<div class="readable-text intended-text" id="p215">
<p>Auto-regressive integrated moving average, or ARIMA, is another method that requires the user to choose certain parameters. Ideally, this is done automatically based on what combination of parameters produces the most accurate model. If you are an R user, you might have used R’s <code>auto.arima</code> method. There are equivalents in Python, such as the one in the <code>pmdarima</code> module, which we will use here. The following code calculates the best ARIMA model on the available data and then plots its predicted values against the observed values. The plot is shown in figure 9.40:</p>
</div>
<div class="browsable-container listing-container" id="p216">
<div class="code-area-container">
<pre class="code-area">import pmdarima as pm

model = pm.auto_arima(cycling_ts, seasonal=False)    <span class="aframe-location"/> #1

training_predictions = model.predict_in_sample()    <span class="aframe-location"/> #2
forecast = model.predict(3)    <span class="aframe-location"/> #3

predictions = pd.concat(    <span class="aframe-location"/> #4
    [training_predictions,
     forecast]
)

fig, axis = plt.subplots()

axis.plot(cycling_ts, label="Observed")
axis.plot(predictions,
          label="Predicted",
          marker="^",
          color="orange",
          alpha=0.8)

axis.set(
    xlabel="Time",
    ylabel="Number of bicycles observed",
    title="Actual vs. predicted cycling traffic"
)

axis.legend()

plt.show()<span class="aframe-location"/></pre>
<div class="code-annotations-overlay-container">
     #1 Automatically finds the best ARIMA model
     <br/>#2 Calculates predictions on the training data
     <br/>#3 Forecasts three time points ahead
     <br/>#4 Combines predicted and forecasted values into a single time series for plotting
     <br/>
</div>
</div>
</div>
<div class="browsable-container figure-container" id="p217">
<img alt="figure" height="867" src="../Images/9-40.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.40</span> Actual vs. predicted values for a particular location’s time series</h5>
</div>
<div class="readable-text" id="p218">
<p>What does this plot tell us?</p>
</div>
<ul>
<li class="readable-text" id="p219"> The ARIMA model misses a couple of peaks and tries to correct for them, which is especially clear around 2002. </li>
<li class="readable-text" id="p220"> Because the ARIMA model is somewhat self-correcting, it tries to match the observed data’s shape. </li>
<li class="readable-text" id="p221"> The unexpected flatline between 2008 and 2012 also takes ARIMA by surprise, as does the subsequent peak in 2013. </li>
<li class="readable-text" id="p222"> Ultimately, there isn’t enough future information to go on, and ARIMA reverts to predicting average behavior into the future by predicting a drop and then a peak. </li>
</ul>
<div class="readable-text" id="p223">
<p>This is a particularly difficult forecasting problem because we don’t have a lot of data, and there are not a lot of patterns to exploit, apart from the slightly rising trend. The fact that we only have measurements from a single day each year is an added difficulty. The best that ARIMA can do for us is predict average behavior in line with the more recent data points. To improve this forecast, ideally, we would have more historical data and additional variables that could help predict changes in cycling traffic.</p>
</div>
<div class="readable-text" id="p224">
<p>That being said, we could still run this forecasting code on all our cycling time series, and for those that have recent data, we could look at the forecast for the next time point. If these forecasts remain high compared to previous values, we could use that to identify time series with an upward trend. This might be a more sophisticated way to find locations with increased cycling because locations where cycling is in decline after a mid-series peak might be filtered out more successfully. However, as it stands, it doesn’t look like we would gain much for our recommendations, so it’s finally time to draw some conclusions and think about next steps.</p>
</div>
<div class="readable-text intended-text" id="p225">
<p>Before proceeding to the conclusion, let’s look at the final diagram that documents the analysis. There were three parallel investigations into how we could narrow down the data to locations of interest. Each of them came with a decision about cutoffs (e.g., what percentage increase we treat as significant). These decision points are combined into one on the diagram because we made them together at the final stage, but they represent three separate decisions we needed to make. Figure 9.41 shows the final path we took during our analysis.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p226">
<img alt="figure" height="1269" src="../Images/9-41.png" width="922"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 9.41</span> The final analysis diagram</h5>
</div>
<div class="readable-text intended-text" id="p227">
<p>Let’s now take our findings and summarize them into conclusions and recommendations.</p>
</div>
<div class="readable-text" id="p228">
<h3 class="readable-text-h3" id="sigil_toc_id_118"><span class="num-string">9.2.2</span> Project conclusions and recommendations</h3>
</div>
<div class="readable-text" id="p229">
<p>Let’s remind ourselves of our initial aims. The first phase of the project we are supporting is to identify the most suitable places around the country to improve infrastructure for cyclists. This meant finding places with already significant or increasing cycling traffic. Let’s also remind ourselves about what we ended up doing and the decisions we decided to make along the way.</p>
</div>
<div class="readable-text intended-text" id="p230">
<p>The output of our analysis would be the 11 locations identified as meeting multiple criteria for being relevant to our aims. We could present these as a list or even as points on a map. In fact, map visualizations would be a great way to bring the data story to life here. The important thing would be to discuss these findings with our domain experts.</p>
</div>
<div class="readable-text intended-text" id="p231">
<p>As for further work, this would be informed by our stakeholder conversations, but some directions we could go from here include</p>
</div>
<ul>
<li class="readable-text" id="p232"> <em>Revisiting some of our choices and assumptions</em>—One decision we made was to remove the time series that did not have enough coverage. However, we ended up not making use of forecasting, so if we relax this coverage criterion and allow shorter time series, we might find additional locations of interest. </li>
<li class="readable-text" id="p233"> <em>Including additional datasets in the analysis</em>—Cross-referencing our findings with data about special events, road closures, or even weather would give us a better picture of locations with organically increasing cycling traffic and which locations have increases that are likely caused by external factors. </li>
<li class="readable-text" id="p234"> <em>Visualizing data geographically</em>—This could also help pinpoint places where there are multiple locations of interest in close proximity. For example, three of our recommended locations of interest were in the borough of Lambeth. This sort of insight would be even easier to arrive at if locations were plotted on a map. </li>
</ul>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p235">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Activity: Further project ideas with this data</h5>
</div>
<div class="readable-text" id="p236">
<p>Consider some other research questions you could answer with this data that are unrelated to the project in this chapter. Here are some ideas to get you started:</p>
</div>
<ul>
<li class="readable-text" id="p237"> What happens when you compare traffic patterns at different levels of geography, such as regional or local authority level? </li>
<li class="readable-text" id="p238"> How are traffic patterns different for different types of vehicles? Where are the hotspots for, say, cars versus buses versus heavy-goods vehicles (HGVs)? </li>
<li class="readable-text" id="p239"> Based on the available data, which part of the country is most in need of additional road infrastructure? </li>
<li class="readable-text" id="p240"> If you’ve ever been interested in geospatial data analysis, this is an opportunity to experiment with it. The Department for Transport website contains shape files, which contain locations for the major road network and can be used for geospatial analysis and visualization. You can find them at <a href="https://roadtraffic.dft.gov.uk/downloads">https://roadtraffic.dft.gov.uk/downloads</a>. </li>
</ul>
</div>
<div class="readable-text" id="p241">
<h2 class="readable-text-h2" id="sigil_toc_id_119"><span class="num-string">9.3</span> Closing thoughts: Time series</h2>
</div>
<div class="readable-text" id="p242">
<p>There are two aspects of time series data you could target if you want to learn more. The first is getting familiar with the time series tools in your chosen toolbox. In Python, this might be understanding the various date and time-related data types in the <code>pandas</code> library or exploring some of the statistical methods in <code>statsmodels</code>. Understanding how dates and times are represented in your toolbox is vital to successfully manipulate this kind of data. For example, at some point, you will encounter time data across multiple time zones. This is a complex and frustrating aspect of working with time data and one that it is handy to be prepared for.</p>
</div>
<div class="readable-text intended-text" id="p243">
<p>The other angle you could take for further learning is to dive deeper into forecasting. There are many complex algorithms now to do accurate forecasting, but my recommendation is usually to start simple. Methods for time series forecasting have been around for decades in domains such as econometrics, long before the phrase “data science” even existed. To this end, I usually recommend the book <em>Forecasting: Principles and Practice</em> by Hyndman and Athanasopoulos (2021), available for free at <a href="https://otexts.com/fpp3">https://otexts.com/fpp3</a>. It is an excellent resource to walk you through the basics of forecasting, with code samples in R. Python translations are also available, such as <a href="https://github.com/zgana/fpp3-python-readalong">https://github.com/zgana/fpp3-python-readalong</a>.</p>
</div>
<div class="readable-text intended-text" id="p244">
<p>Only after this sort of introductory material do I recommend diving into a more complex, deeper tool, such as Facebook’s Prophet library (<a href="https://facebook.github.io/prophet">https://facebook.github.io/prophet</a>). In the end, this is the sort of tool you would turn to in practice when attempting to forecast a time series, but knowing the fundamentals makes it easier to tailor your methods to your specific problem and understand why your forecasts might go wrong from time to time.</p>
</div>
<div class="readable-text" id="p245">
<h3 class="readable-text-h3" id="sigil_toc_id_120"><span class="num-string">9.3.1</span> Skills for working with time series data for any project</h3>
</div>
<div class="readable-text" id="p246">
<p>Let’s recap the skills required to explore, manipulate, and analyze time series data. These skills, which are applicable to any time series data project, include</p>
</div>
<ul>
<li class="readable-text" id="p247"> Investigating time series data for completeness (e.g., are time series measured at different locations, or do all locations have the same amount of data?) </li>
<li class="readable-text" id="p248"> Establishing the granularity of the time series (i.e., is it hourly, daily, or weekly? Are there, in fact, multiple time series in the data, e.g., at different locations?) </li>
<li class="readable-text" id="p249"> Understanding the coverage of the data (i.e., what period does the data cover?) </li>
<li class="readable-text" id="p250"> Investigating whether the time series has gaps </li>
<li class="readable-text" id="p251"> Reshaping time series data to be at a different level of granularity (e.g., summarizing hourly data at a daily level) </li>
<li class="readable-text" id="p252"> Visualizing time series with appropriate charts (i.e., most often, line charts) </li>
<li class="readable-text" id="p253"> Calculating the distribution of the repeated measurement (e.g., for “Number of bikes seen in an hour,” what are the typical hourly counts?) </li>
<li class="readable-text" id="p254"> Diving down to the individual data point level to investigate anomalies </li>
<li class="readable-text" id="p255"> Decomposing a time series to identify whether it has a trend or seasonality </li>
<li class="readable-text" id="p256"> Identifying temporal patterns within time series (e.g., cycling locations with a high level of traffic in the morning) </li>
<li class="readable-text" id="p257"> Finding time series of interest based on multiple criteria </li>
<li class="readable-text" id="p258"> Forecasting a time series into the future to predict future trends </li>
</ul>
<div class="readable-text" id="p259">
<h2 class="readable-text-h2" id="sigil_toc_id_121">Summary</h2>
</div>
<ul>
<li class="readable-text" id="p260"> Time series analysis can reveal temporal patterns, such as peak times of activity or areas of growth. </li>
<li class="readable-text" id="p261"> Time series can be decomposed to investigate trends and seasonal behaviors separately. </li>
<li class="readable-text" id="p262"> Forecasting time series relies on having enough past data points with no gaps. </li>
<li class="readable-text" id="p263"> You can determine whether a time series can be forecasted successfully by building and evaluating a forecasting model. </li>
</ul>
</div></body></html>