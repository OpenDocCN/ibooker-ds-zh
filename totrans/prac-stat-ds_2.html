<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 2. Data and Sampling Distributions"><div class="chapter" id="Chapter_2">
<h1><span class="label">Chapter 2. </span>Data and Sampling Distributions</h1>


<p>A popular misconception holds that the era of big data means the end of a need for sampling.<a data-type="indexterm" data-primary="sampling" id="ix_smpl"/>
In fact, the proliferation of data of varying quality and relevance reinforces the need for sampling as a tool to work efficiently with a variety of data and to minimize bias.
Even in a big data project, predictive models are typically developed and piloted with samples.<a data-type="indexterm" data-primary="big data" data-secondary="predictive models in" id="idm46522863380632"/>
Samples are also used in tests of various sorts (e.g., comparing the effect of web page designs on clicks).</p>

<p><a data-type="xref" href="#sampling_schematic">Figure 2-1</a> shows a schematic that underpins the concepts we will discuss in this chapter—data and sampling distributions.
The lefthand side represents a population that, in statistics, is assumed to follow an underlying but <em>unknown</em> distribution.
All that is available is the <em>sample</em> data and its empirical distribution, shown on the righthand side.
To get from the lefthand side to the righthand side, a <em>sampling</em> procedure is used (represented by an arrow).
Traditional statistics focused very much on the lefthand side, using theory based on strong assumptions about the population.
Modern statistics has moved to the righthand side, where such assumptions are not needed.</p>

<p>In general, data scientists need not worry about the theoretical nature of the lefthand side and instead should focus on the sampling procedures and the data at hand.
There are some notable exceptions.
Sometimes data is generated from a physical process that can be modeled. The simplest example is flipping a coin: this follows a binomial distribution.
Any real-life binomial situation (buy or don’t buy, fraud or no fraud, click or don’t click) can be modeled effectively by a coin (with modified probability of landing heads, of course).
In these cases, we can gain additional insight by using our understanding of the population.</p>

<figure><div id="sampling_schematic" class="figure">
<img src="Images/psd2_0201.png" alt="images/sampling_schematic.png" width="946" height="792"/>
<h6><span class="label">Figure 2-1. </span>Population versus sample</h6>
</div></figure>






<section data-type="sect1" data-pdf-bookmark="Random Sampling and Sample Bias"><div class="sect1" id="randomSampling_bias">
<h1>Random Sampling and Sample Bias</h1>

<p>A <em>sample</em> is a subset of data from a larger data set; statisticians call this larger data set the <em>population</em>.<a data-type="indexterm" data-primary="random sampling" id="ix_rndsmpl"/><a data-type="indexterm" data-primary="sampling" data-secondary="random sampling and sample bias" id="ix_smplrnd"/>
A population in statistics is not the same thing as in biology—it is a large, defined (but sometimes theoretical or imaginary) set of data.<a data-type="indexterm" data-primary="population" id="idm46522863367672"/></p>

<p><em>Random sampling</em> is a process in which each available member of the population being sampled has an equal chance of being chosen for the sample at each draw.
The sample that results is called a <em>simple random sample</em>.<a data-type="indexterm" data-primary="simple random sample" id="idm46522863365496"/>
Sampling can be done <em>with replacement</em>,<a data-type="indexterm" data-primary="replacement (in sampling)" id="idm46522863364216"/> in which observations are put back in the population after each draw for possible future reselection.
Or it can be done <em>without replacement</em>, in which case observations, once selected, are unavailable for future draws.<a data-type="indexterm" data-primary="sampling" data-secondary="with and without replacement" data-secondary-sortas="replacement" id="idm46522863362856"/></p>

<p>Data quality often matters more than data quantity when making an estimate or a model based on a sample.<a data-type="indexterm" data-primary="data quality" id="idm46522863361208"/>
Data quality in data science involves completeness, consistency of format, cleanliness, and accuracy of individual data points.
Statistics adds the notion of <em>representativeness</em>.<a data-type="indexterm" data-primary="representativeness" id="idm46522863359816"/></p>
<aside data-type="sidebar" epub:type="sidebar" class="pagebreak-before less_space"><div class="sidebar" id="idm46522863358952">
<h5>Key Terms for Random Sampling</h5><dl>
<dt class="horizontal"><strong><em>Sample</em></strong></dt>
<dd>
<p>A subset from a larger data set.</p>
</dd>
<dt class="horizontal"><strong><em>Population</em></strong></dt>
<dd>
<p>The larger data set or idea of a data set.</p>
</dd>
<dt class="horizontal"><strong><em>N</em> (<em>n</em>)</strong></dt>
<dd>
<p>The size of the population (sample).</p>
</dd>
<dt class="horizontal"><strong><em>Random sampling</em></strong></dt>
<dd>
<p>Drawing elements into a sample at random.</p>
</dd>
<dt class="horizontal"><strong><em>Stratified sampling</em></strong></dt>
<dd>
<p>Dividing the population into strata and randomly sampling from each strata.</p>
</dd>
<dt class="horizontal"><strong><em>Stratum (pl., strata)</em></strong></dt>
<dd>
<p>A homogeneous subgroup of a population with common characteristics.</p>
</dd>
<dt class="horizontal"><strong><em>Simple random sample</em></strong></dt>
<dd>
<p>The sample that results from random sampling without stratifying the <span class="keep-together">population</span>.</p>
</dd>
<dt class="horizontal"><strong><em>Bias</em></strong></dt>
<dd>
<p>Systematic error.</p>
</dd>
<dt class="horizontal"><strong><em>Sample bias</em></strong></dt>
<dd>
<p>A sample that misrepresents the population.</p>
</dd>
</dl>
</div></aside>

<p>The classic example is the <em>Literary Digest</em> poll of 1936 that predicted a victory of Alf Landon over Franklin Roosevelt.<a data-type="indexterm" data-primary="Literary Digest poll of 1936" id="idm46522863338536"/>
The <em>Literary Digest</em>, a leading periodical of the day, polled its entire subscriber base plus additional lists of individuals, a total of over 10 million people, and predicted a landslide victory for Landon.<a data-type="indexterm" data-primary="Gallup Poll" id="idm46522863337016"/>
George Gallup, founder of the Gallup Poll, conducted biweekly polls of just 2,000 people and accurately predicted a Roosevelt victory.
The difference lay in the selection of those polled.</p>

<p>The <em>Literary Digest</em> opted for quantity, paying little attention to the method of selection.
They ended up polling those with relatively high socioeconomic status (their own subscribers, plus those who, by virtue of owning luxuries like telephones and automobiles, appeared in marketers’ lists).<a data-type="indexterm" data-primary="sample bias" id="idm46522863334632"/>
The result was <em>sample bias</em>; that is, the sample was different in some meaningful and nonrandom way from the larger population it was meant to represent.
The term <em>nonrandom</em> is important—hardly any sample, including random samples, will be exactly representative of the population.<a data-type="indexterm" data-primary="nonrandom samples" id="idm46522863332680"/>
Sample bias occurs when the difference is meaningful, and it can be expected to continue for other samples drawn in the same way as the first.</p>
<div data-type="note" epub:type="note"><h1>Self-Selection Sampling Bias</h1>
<p>The reviews of restaurants, hotels, cafés, and so on that you read on social media sites like Yelp are prone to bias because the people submitting them are not randomly selected; rather, they themselves have taken the initiative to write.<a data-type="indexterm" data-primary="self-selection sampling bias" id="idm46522863330328"/>  This leads to self-selection bias—the people motivated to write reviews may have had poor experiences, may have an association with the establishment, or may simply be a different type of person from those who do not write reviews.  Note that while self-selection samples can be unreliable indicators of the true state of affairs, they may be more reliable in simply comparing one establishment to a similar one; the same self-selection bias might apply to each.</p>
</div>








<section data-type="sect2" data-pdf-bookmark="Bias"><div class="sect2" id="idm46522863328696">
<h2>Bias</h2>

<p>Statistical bias refers to measurement or sampling errors that are systematic and produced by the measurement or sampling process.<a data-type="indexterm" data-primary="random sampling" data-secondary="bias" id="idm46522863327016"/><a data-type="indexterm" data-primary="bias" id="idm46522863326040"/>
An important distinction should be made between errors due to random chance and errors due to bias.
Consider the physical process of a gun shooting at a target.  It will not hit the absolute center of the target every time, or even much at all.  An unbiased process will produce error, but it is random and does not tend strongly in any direction (see <a data-type="xref" href="#gun1">Figure 2-2</a>).
The results shown in <a data-type="xref" href="#gun2">Figure 2-3</a> show a biased process—there is still random error in both the x and y direction, but there is also a bias.
Shots tend to fall in the upper-right quadrant.</p>

<figure><div id="gun1" class="figure">
<img src="Images/psd2_0202.png" alt="images/Target-scatter.png" width="342" height="297"/>
<h6><span class="label">Figure 2-2. </span>Scatterplot of shots from a gun with true aim</h6>
</div></figure>

<figure><div id="gun2" class="figure">
<img src="Images/psd2_0203.png" alt="images/Target-scatter-bias.png" width="365" height="279"/>
<h6><span class="label">Figure 2-3. </span>Scatterplot of shots from a gun with biased aim</h6>
</div></figure>

<p>Bias comes in different forms, and may be observable or invisible.
When a result does suggest bias (e.g., by reference to a benchmark or actual values), it is often an indicator that a statistical or machine learning model has been misspecified, or an important variable left out.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Random Selection"><div class="sect2" id="idm46522863158936">
<h2>Random Selection</h2>

<p>To avoid the problem of sample bias that led the <em>Literary Digest</em> to predict Landon over Roosevelt, George Gallup (shown in <a data-type="xref" href="#Gallup">Figure 2-4</a>) opted for more scientifically chosen methods to achieve a sample that was representative of the US voting electorate.<a data-type="indexterm" data-primary="random sampling" data-secondary="random selection" id="idm46522863156264"/>
There are now a variety of methods to achieve representativeness, but at the heart of all of them lies <em>random sampling</em>.<a data-type="indexterm" data-primary="representativeness" data-secondary="through random sampling" id="idm46522863154680"/></p>

<figure><div id="Gallup" class="figure">
<img src="Images/psd2_0204.png" alt="Gallup" width="150" height="222"/>
<h6><span class="label">Figure 2-4. </span>George Gallup, catapulted to fame by the <em>Literary Digest’s</em> “big data” failure</h6>
</div></figure>

<p>Random sampling is not always easy.
Proper definition of an accessible population is key.
Suppose we want to generate a representative profile of customers and we need to conduct a pilot customer survey.
The survey needs to be representative but is labor intensive.</p>

<p>First, we need to define who a customer is.
We might select all customer records where purchase amount &gt; 0.
Do we include all past customers?
Do we include refunds?
Internal test purchases?
Resellers?
Both billing agent and customer?</p>

<p>Next, we need to specify a sampling procedure.
It might be “select 100 customers at random.”
Where a sampling from a flow is involved (e.g., real-time customer transactions or web visitors), timing considerations may be important (e.g., a web visitor at 10 a.m. on a weekday may be different from a web visitor at 10 p.m. on a weekend).</p>

<p>In <em>stratified sampling</em>, the population is divided up into <em>strata</em>, and random samples are taken from each stratum.<a data-type="indexterm" data-primary="stratified sampling" id="idm46522863147864"/>
Political pollsters might seek to learn the electoral preferences of whites, blacks, and Hispanics.
A simple random sample taken from the population would yield too few blacks and Hispanics, so those strata could be overweighted in stratified sampling to yield equivalent sample sizes.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Size Versus Quality: When Does Size Matter?"><div class="sect2" id="idm46522863146600">
<h2>Size Versus Quality: When Does Size Matter?</h2>

<p>In the era of big data, it is sometimes surprising that smaller is better.<a data-type="indexterm" data-primary="random sampling" data-secondary="size versus quality" id="idm46522863145096"/> Time and effort spent on random sampling not only reduces bias but also allows greater attention to data exploration and data quality.<a data-type="indexterm" data-primary="data quality" data-secondary="sample size versus" id="idm46522863143848"/>  For example, missing data and outliers may contain useful information.
It might be prohibitively expensive to track down missing values or evaluate outliers in millions of records, but doing so in a sample of several thousand records may be feasible.
Data plotting and manual inspection bog down if there is too much data.</p>

<p>So when <em>are</em> massive amounts of data needed?</p>

<p>The classic scenario for the value of big data is when the data is not only big but sparse as well.<a data-type="indexterm" data-primary="big data" data-secondary="value of" id="idm46522863141080"/>
Consider the search queries received by Google, where columns are terms, rows are individual search queries, and cell values are either 0 or 1, depending on whether a query contains a term.<a data-type="indexterm" data-primary="search" data-secondary="need for enormous quantities of data" id="idm46522863139768"/>
The goal is to determine the best predicted search destination for a given query.
There are over 150,000 words in the English language, and Google processes over one trillion queries per year.
This yields a huge matrix, the vast majority of whose entries are “0.”</p>

<p>This is a true big data problem—only when such enormous quantities of data are accumulated can effective search results be returned for most queries.  And the more data accumulates, the better the results.
For popular search terms this is not such a problem—effective data can be found fairly quickly for the handful of extremely popular topics trending at a particular time.
The real value of modern search technology lies in the ability to return detailed and useful results for a huge variety of search queries, including those that occur with a frequency, say, of only one in a million.</p>

<p>Consider the search phrase “Ricky Ricardo and Little Red Riding Hood.”
In the early days of the internet, this query would probably have returned results on the bandleader Ricky Ricardo, the television show <em>I Love Lucy</em> in which that character appeared, and the children’s story <em>Little Red Riding Hood</em>. Both of those individual items would have had many searches to refer to, but the combination would have had very few. Later, now that trillions of search queries have been accumulated, this search query returns the exact <em>I Love Lucy</em> episode in which Ricky narrates, in dramatic fashion, the <em>Little Red Riding Hood</em> story to his infant son in a comic mix of English and Spanish.</p>

<p>Keep in mind that the <a data-type="indexterm" data-primary="pertinent records (in searches)" id="idm46522863134392"/>number of actual <em>pertinent</em> records—ones in which this exact search query, or something very similar, appears (together with information on what link people ultimately clicked on)—might need only be in the thousands to be effective.  However, many trillions of data points are needed to obtain these pertinent records (and random sampling, of course, will not help).  See also <a data-type="xref" href="#LongTailedData">“Long-Tailed Distributions”</a>.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Sample Mean Versus Population Mean"><div class="sect2" id="idm46522863131768">
<h2>Sample Mean Versus Population Mean</h2>

<p>The symbol
<math alttext="x overbar">
  <mover accent="true"><mi>x</mi> <mo>¯</mo></mover>
</math> (pronounced “x-bar”) is used to represent the mean of a sample from a population, whereas
<math alttext="mu">
  <mi>μ</mi>
</math>
is used to represent the mean of a population.<a data-type="indexterm" data-primary="random sampling" data-secondary="sample mean versus population mean" id="idm46522863127224"/><a data-type="indexterm" data-primary="mean" data-secondary="sample mean versus population mean" id="idm46522863126184"/><a data-type="indexterm" data-primary="population" data-secondary="population mean vs. sample mean" id="idm46522863125224"/>
Why make the distinction?
Information about samples is observed, and information about large populations is often inferred from smaller samples.
Statisticians like to keep the two things separate in the symbology.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522863123784">
<h5>Key Ideas</h5>
<ul>
<li>
<p>Even in the era of big data, random sampling remains an important arrow in the data scientist’s quiver.</p>
</li>
<li>
<p>Bias occurs when measurements or observations are systematically in error because they are not representative of the full population.</p>
</li>
<li>
<p>Data quality is often more important than data quantity, and random sampling can reduce bias and facilitate quality improvement that would otherwise be prohibitively expensive.</p>
</li>
</ul>
</div></aside>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522863119016">
<h2>Further Reading</h2>

<ul>
<li>
<p>A useful review of sampling procedures can be found in Ronald Fricker’s chapter “Sampling Methods for Online Surveys” in <em>The SAGE Handbook of Online Research Methods</em>, 2nd ed., edited by Nigel G. Fielding, Raymond M. Lee, and Grant Blank (SAGE Publications, 2016).
This chapter includes a review of the modifications to random sampling that are often used for practical reasons of cost or feasibility.</p>
</li>
<li>
<p>The story of the <em>Literary Digest</em> poll failure can be found on the <a href="https://oreil.ly/iSoQT">Capital Century website</a>.</p>
</li>
</ul>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Selection Bias"><div class="sect1" id="Selection_bias">
<h1>Selection Bias</h1>

<p>To paraphrase Yogi Berra: if you don’t know what you’re looking for, look hard enough <a data-type="indexterm" data-primary="random sampling" data-startref="ix_rndsmpl" id="idm46522863111800"/><a data-type="indexterm" data-primary="sampling" data-secondary="random sampling and sample bias" data-startref="ix_smplrnd" id="idm46522863110824"/>and you’ll find it.</p>

<p>Selection bias <a data-type="indexterm" data-primary="sampling" data-secondary="selection bias" id="ix_smplsebi"/><a data-type="indexterm" data-primary="bias" data-secondary="selection bias" id="ix_biassel"/><a data-type="indexterm" data-primary="selection bias" id="ix_selbias"/>refers to the practice of selectively choosing data—consciously or unconsciously—in a way that leads to a conclusion that is misleading or ephemeral.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522863105128">
<h5>Key Terms for Selection Bias</h5><dl>
<dt class="horizontal"><strong><em>Selection bias</em></strong></dt>
<dd>
<p>Bias resulting from the way in which observations are selected.</p>
</dd>
<dt class="horizontal"><strong><em>Data snooping</em></strong></dt>
<dd>
<p>Extensive hunting through data in search of something interesting.</p>
</dd>
<dt class="horizontal"><strong><em>Vast search effect</em></strong></dt>
<dd>
<p>Bias or nonreproducibility resulting from repeated data modeling, or modeling data with large numbers of predictor variables.</p>
</dd>
</dl>
</div></aside>

<p>If you specify a hypothesis and conduct a well-designed experiment to test it, you can have high confidence in the conclusion.
This is frequently not what occurs, however.  Often, one looks at available data and tries to discern patterns.
But are the patterns real?  Or are they just the product of <em>data snooping</em>—that is, extensive hunting through the data until something interesting emerges?<a data-type="indexterm" data-primary="data snooping" id="idm46522863096952"/>
There is a saying among statisticians: “If you torture the data long enough, sooner or later it will confess.”</p>

<p>The difference between a phenomenon that you verify when you test a hypothesis using an experiment and a phenomenon that you discover by perusing available data can be illuminated with the following thought experiment.</p>

<p>Imagine that someone tells you they can flip a coin and have it land heads on the next 10 tosses.
You challenge them (the equivalent of an experiment), and they proceed to toss the coin 10 times, with all flips landing heads.
Clearly you ascribe some special talent to this person—the probability that 10 coin tosses will land heads just by chance is 1 in 1,000.</p>

<p>Now imagine that the announcer at a sports stadium asks the 20,000 people in attendance each to toss a coin 10 times, and to report to an usher if they get 10 heads in a row.
The chance that <em>somebody</em> in the stadium will get 10 heads is extremely high (more than 99%—it’s 1 minus the probability that nobody gets 10 heads).
Clearly, selecting after the fact the person (or persons) who gets 10 heads at the stadium does not indicate they have any special talent—it’s most likely luck.</p>

<p>Since repeated review of large data sets is a key value proposition in data science, selection bias is something to worry about.
A form of selection bias of particular concern to data scientists is what John Elder (founder of Elder Research, a respected data mining consultancy) calls the <em>vast search effect</em>.<a data-type="indexterm" data-primary="vast search effect" id="idm46522863092088"/><a data-type="indexterm" data-primary="search" data-secondary="vast search effect" id="idm46522863091352"/><a data-type="indexterm" data-primary="Elder, John" id="idm46522863090408"/>
If you repeatedly run different models and ask different questions with a large data set, you are bound to find something interesting.
But is the result you found truly something interesting, or is it the chance outlier?</p>

<p>We can guard against this by using a holdout set, and sometimes more than one holdout set, against which to validate performance.
Elder also advocates the use of what he calls <em>target shuffling</em> (a permutation test, in essence) to test the validity of predictive associations that a data mining model suggests.<a data-type="indexterm" data-primary="target shuffling" id="idm46522863088248"/></p>

<p>Typical forms of<a data-type="indexterm" data-primary="selection bias" data-secondary="typical forms of" id="idm46522863087160"/> selection bias in statistics, in addition to the vast search effect, include nonrandom sampling (see <a data-type="xref" href="#randomSampling_bias">“Random Sampling and Sample Bias”</a>), cherry-picking data, selection of time intervals that accentuate a particular statistical effect, and stopping an experiment when the results look “interesting.”</p>








<section data-type="sect2" data-pdf-bookmark="Regression to the Mean"><div class="sect2" id="idm46522863084792">
<h2>Regression to the Mean</h2>

<p><em>Regression to the mean</em> refers to a phenomenon involving successive measurements on a given variable: extreme observations tend to be followed by more central ones.<a data-type="indexterm" data-primary="regression to the mean" id="idm46522863082808"/><a data-type="indexterm" data-primary="mean" data-secondary="regression to" id="idm46522863082104"/><a data-type="indexterm" data-primary="selection bias" data-secondary="regression to the mean" id="ix_selbiasregr"/>
Attaching special focus and meaning to the extreme value can lead to a form of selection bias.</p>

<p>Sports fans are familiar with the “rookie of the year, sophomore slump” phenomenon.
Among the athletes who begin their career in a given season (the rookie class), there is always one who performs better than all the rest.
Generally, this “rookie of the year” does not do as well in his second year.
Why not?</p>

<p>In nearly all major sports, at least those played with a ball or puck, there are two elements that play a role in overall performance:</p>

<ul>
<li>
<p>Skill</p>
</li>
<li>
<p>Luck</p>
</li>
</ul>

<p>Regression to the mean is a consequence of a particular form of selection bias.
When we select the rookie with the best performance, skill and good luck are probably contributing.
In his next season, the skill will still be there, but very often the luck will not be, so his performance will decline—it will regress.<a data-type="indexterm" data-primary="Galton, Francis" id="idm46522863075432"/>
The phenomenon was first identified by Francis Galton in 1886 <a data-type="link" href="bibliography01.xhtml#Galton-1886">[Galton-1886]</a>, who wrote of it in connection with genetic tendencies; for example, the children of extremely tall men tend not to be as tall as their father (see <a data-type="xref" href="#Galton">Figure 2-5</a>).</p>

<figure><div id="Galton" class="figure">
<img src="Images/psd2_0205.png" alt="Galton" width="600" height="520"/>
<h6><span class="label">Figure 2-5. </span>Galton’s study that identified the phenomenon of regression to the mean</h6>
</div></figure>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Regression to the mean, meaning to “go back,” is distinct from the statistical modeling method of linear regression, in which a linear relationship is estimated between predictor variables and an outcome variable.<a data-type="indexterm" data-primary="selection bias" data-secondary="regression to the mean" data-startref="ix_selbiasregr" id="idm46522863069464"/></p>
</div>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522863067960">
<h5>Key Ideas</h5>
<ul>
<li>
<p>Specifying a hypothesis and then collecting data following randomization and random sampling principles ensures against bias.</p>
</li>
<li>
<p>All other forms of data analysis run the risk of bias resulting from the data collection/analysis process (repeated running of models in data mining, data snooping in research, and after-the-fact selection of interesting events).</p>
</li>
</ul>
</div></aside>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522863064264">
<h2>Further Reading</h2>

<ul>
<li>
<p>Christopher J. Pannucci and Edwin G. Wilkins’ article “Identifying and Avoiding Bias in Research” in (surprisingly not a statistics journal) <em>Plastic and Reconstructive Surgery</em> (August 2010) has an excellent review of various types of bias that can enter into research, including selection bias.</p>
</li>
<li>
<p>Michael Harris’s article <a href="https://oreil.ly/v_Q0u">“Fooled by Randomness Through Selection Bias”</a> provides an interesting review of selection bias considerations in stock market trading schemes, from the perspective of traders.<a data-type="indexterm" data-primary="bias" data-secondary="selection bias" data-startref="ix_biassel" id="idm46522863059944"/><a data-type="indexterm" data-primary="sampling" data-secondary="selection bias" data-startref="ix_smplsebi" id="idm46522863058728"/><a data-type="indexterm" data-primary="selection bias" data-startref="ix_selbias" id="idm46522863057512"/></p>
</li>
</ul>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Sampling Distribution of a Statistic"><div class="sect1" id="idm46522863113352">
<h1>Sampling Distribution of a Statistic</h1>

<p>The term <em>sampling distribution</em> of a statistic refers to the distribution of some sample statistic over many samples drawn from the same population.<a data-type="indexterm" data-primary="sampling distribution" id="ix_smpldst"/>
Much of classical statistics is concerned with making inferences from (small) samples to (very large) populations.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522863052664">
<h5>Key Terms for Sampling Distribution</h5><dl>
<dt class="horizontal"><strong><em>Sample statistic</em></strong></dt>
<dd>
<p>A metric calculated for a sample of data drawn from a larger population.<a data-type="indexterm" data-primary="sample statistic" id="idm46522863049576"/></p>
</dd>
<dt class="horizontal"><strong><em>Data distribution</em></strong></dt>
<dd>
<p>The frequency distribution of individual <em>values</em> in a data set.<a data-type="indexterm" data-primary="data distribution" id="idm46522863046648"/></p>
</dd>
<dt class="horizontal"><strong><em>Sampling distribution</em></strong></dt>
<dd>
<p>The frequency distribution of a <em>sample statistic</em> over many samples or resamples.<a data-type="indexterm" data-primary="standard error" id="idm46522863043640"/></p>
</dd>
<dt class="horizontal"><strong><em>Central limit theorem</em></strong></dt>
<dd>
<p>The tendency of the sampling distribution to take on a normal shape as sample size rises.<a data-type="indexterm" data-primary="central limit theorem" id="idm46522863041016"/></p>
</dd>
<dt class="horizontal"><strong><em>Standard error</em></strong></dt>
<dd>
<p>The variability (standard deviation) of a sample <em>statistic</em> over many samples (not to be confused with <em>standard deviation</em>, which by itself, refers to variability of individual data <em>values</em>).</p>
</dd>
</dl>
</div></aside>

<p>Typically, a sample is drawn with the goal of measuring something (with a <em>sample statistic</em>) or modeling something (with a statistical or machine learning model).
Since our estimate or model is based on a sample, it might be in error; it might be different if we were to draw a different sample.
We are therefore interested in how different it might be—a key concern is <em>sampling variability</em>.<a data-type="indexterm" data-primary="sampling variability" id="idm46522863035544"/>
If we had lots of data, we could draw additional samples and observe the distribution of a sample statistic directly.
<span class="keep-together">Typically</span>, we will calculate our estimate or model using as much data as is easily available, so the option of drawing additional samples from the population is not readily available.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>It is important to distinguish between the distribution of the individual data points, known as <em>the data distribution</em>, and the distribution of a sample statistic, known as the <em>sampling distribution</em>.<a data-type="indexterm" data-primary="sampling distribution" data-secondary="data distribution versus" id="idm46522863031752"/><a data-type="indexterm" data-primary="data distribution" data-secondary="sampling distribution versus" id="idm46522863030680"/></p>
</div>

<p>The distribution of a sample statistic such as the mean is likely to be more regular and bell-shaped than the distribution of the data itself.
The larger the sample the statistic is based on, the more this is true.
Also, the larger the sample, the narrower the distribution of the sample statistic.</p>

<p>This is illustrated in an example using annual income for loan applicants to LendingClub (see <a data-type="xref" href="ch06.xhtml#LoanExampleKNN">“A Small Example: Predicting Loan Default”</a> for a description of the data).
Take three samples from this data: a sample  of 1,000 values, a sample of 1,000 means of 5 values, and a sample of 1,000 means of 20 values.
Then plot a histogram of each sample to produce <a data-type="xref" href="#loans-mean-hist">Figure 2-6</a>.</p>

<figure class="width-50"><div id="loans-mean-hist" class="figure">
<img src="Images/psd2_0206.png" alt="Loans histogram" width="856" height="1156"/>
<h6><span class="label">Figure 2-6. </span>Histogram of annual incomes of 1,000 loan applicants (top), then 1,000 means of n=5 applicants (middle), and finally 1,000 means of n=20 applicants (bottom)</h6>
</div></figure>

<p>The histogram of the individual data values is broadly spread out and skewed toward higher values, as is to be expected with income data.
The histograms of the means of 5 and 20 are increasingly compact and more bell-shaped.
Here is the <em>R</em> code to generate these histograms, using the visualization package <code>ggplot2</code>:</p>

<pre data-type="programlisting" data-code-language="r"><code class="nf">library</code><code class="p">(</code><code class="n">ggplot2</code><code class="p">)</code>
<code class="c1"># take a simple random sample</code>
<code class="n">samp_data</code> <code class="o">&lt;-</code> <code class="nf">data.frame</code><code class="p">(</code><code class="n">income</code><code class="o">=</code><code class="nf">sample</code><code class="p">(</code><code class="n">loans_income</code><code class="p">,</code> <code class="m">1000</code><code class="p">),</code>
                        <code class="n">type</code><code class="o">=</code><code class="s">'data_dist'</code><code class="p">)</code>
<code class="c1"># take a sample of means of 5 values</code>
<code class="n">samp_mean_05</code> <code class="o">&lt;-</code> <code class="nf">data.frame</code><code class="p">(</code>
  <code class="n">income</code> <code class="o">=</code> <code class="nf">tapply</code><code class="p">(</code><code class="nf">sample</code><code class="p">(</code><code class="n">loans_income</code><code class="p">,</code> <code class="m">1000</code><code class="o">*</code><code class="m">5</code><code class="p">),</code>
                  <code class="nf">rep</code><code class="p">(</code><code class="m">1</code><code class="o">:</code><code class="m">1000</code><code class="p">,</code> <code class="nf">rep</code><code class="p">(</code><code class="m">5</code><code class="p">,</code> <code class="m">1000</code><code class="p">)),</code> <code class="n">FUN</code><code class="o">=</code><code class="n">mean</code><code class="p">),</code>
  <code class="n">type</code> <code class="o">=</code> <code class="s">'mean_of_5'</code><code class="p">)</code>
<code class="c1"># take a sample of means of 20 values</code>
<code class="n">samp_mean_20</code> <code class="o">&lt;-</code> <code class="nf">data.frame</code><code class="p">(</code>
  <code class="n">income</code> <code class="o">=</code> <code class="nf">tapply</code><code class="p">(</code><code class="nf">sample</code><code class="p">(</code><code class="n">loans_income</code><code class="p">,</code> <code class="m">1000</code><code class="o">*</code><code class="m">20</code><code class="p">),</code>
                  <code class="nf">rep</code><code class="p">(</code><code class="m">1</code><code class="o">:</code><code class="m">1000</code><code class="p">,</code> <code class="nf">rep</code><code class="p">(</code><code class="m">20</code><code class="p">,</code> <code class="m">1000</code><code class="p">)),</code> <code class="n">FUN</code><code class="o">=</code><code class="n">mean</code><code class="p">),</code>
  <code class="n">type</code> <code class="o">=</code> <code class="s">'mean_of_20'</code><code class="p">)</code>
<code class="c1"># bind the data.frames and convert type to a factor</code>
<code class="n">income</code> <code class="o">&lt;-</code> <code class="nf">rbind</code><code class="p">(</code><code class="n">samp_data</code><code class="p">,</code> <code class="n">samp_mean_05</code><code class="p">,</code> <code class="n">samp_mean_20</code><code class="p">)</code>
<code class="n">income</code><code class="o">$</code><code class="n">type</code> <code class="o">=</code> <code class="nf">factor</code><code class="p">(</code><code class="n">income</code><code class="o">$</code><code class="n">type</code><code class="p">,</code>
                     <code class="n">levels</code><code class="o">=</code><code class="nf">c</code><code class="p">(</code><code class="s">'data_dist'</code><code class="p">,</code> <code class="s">'mean_of_5'</code><code class="p">,</code> <code class="s">'mean_of_20'</code><code class="p">),</code>
                     <code class="n">labels</code><code class="o">=</code><code class="nf">c</code><code class="p">(</code><code class="s">'Data'</code><code class="p">,</code> <code class="s">'Mean of 5'</code><code class="p">,</code> <code class="s">'Mean of 20'</code><code class="p">))</code>
<code class="c1"># plot the histograms</code>
<code class="nf">ggplot</code><code class="p">(</code><code class="n">income</code><code class="p">,</code> <code class="nf">aes</code><code class="p">(</code><code class="n">x</code><code class="o">=</code><code class="n">income</code><code class="p">))</code> <code class="o">+</code>
  <code class="nf">geom_histogram</code><code class="p">(</code><code class="n">bins</code><code class="o">=</code><code class="m">40</code><code class="p">)</code> <code class="o">+</code>
  <code class="nf">facet_grid</code><code class="p">(</code><code class="n">type</code> <code class="o">~</code> <code class="n">.)</code></pre>

<p>The <em>Python</em> code uses <code>seaborn</code>’s <code>FacetGrid</code> to show the three histograms:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">pandas</code> <code class="kn">as</code> <code class="nn">pd</code>
<code class="kn">import</code> <code class="nn">seaborn</code> <code class="kn">as</code> <code class="nn">sns</code>

<code class="n">sample_data</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code>
    <code class="s1">'income'</code><code class="p">:</code> <code class="n">loans_income</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">1000</code><code class="p">),</code>
    <code class="s1">'type'</code><code class="p">:</code> <code class="s1">'Data'</code><code class="p">,</code>
<code class="p">})</code>
<code class="n">sample_mean_05</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code>
    <code class="s1">'income'</code><code class="p">:</code> <code class="p">[</code><code class="n">loans_income</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code><code class="o">.</code><code class="n">mean</code><code class="p">()</code> <code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">1000</code><code class="p">)],</code>
    <code class="s1">'type'</code><code class="p">:</code> <code class="s1">'Mean of 5'</code><code class="p">,</code>
<code class="p">})</code>
<code class="n">sample_mean_20</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">({</code>
    <code class="s1">'income'</code><code class="p">:</code> <code class="p">[</code><code class="n">loans_income</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">20</code><code class="p">)</code><code class="o">.</code><code class="n">mean</code><code class="p">()</code> <code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">1000</code><code class="p">)],</code>
    <code class="s1">'type'</code><code class="p">:</code> <code class="s1">'Mean of 20'</code><code class="p">,</code>
<code class="p">})</code>
<code class="n">results</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">sample_data</code><code class="p">,</code> <code class="n">sample_mean_05</code><code class="p">,</code> <code class="n">sample_mean_20</code><code class="p">])</code>

<code class="n">g</code> <code class="o">=</code> <code class="n">sns</code><code class="o">.</code><code class="n">FacetGrid</code><code class="p">(</code><code class="n">results</code><code class="p">,</code> <code class="n">col</code><code class="o">=</code><code class="s1">'type'</code><code class="p">,</code> <code class="n">col_wrap</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">height</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">aspect</code><code class="o">=</code><code class="mi">2</code><code class="p">)</code>
<code class="n">g</code><code class="o">.</code><code class="n">map</code><code class="p">(</code><code class="n">plt</code><code class="o">.</code><code class="n">hist</code><code class="p">,</code> <code class="s1">'income'</code><code class="p">,</code> <code class="nb">range</code><code class="o">=</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">200000</code><code class="p">],</code> <code class="n">bins</code><code class="o">=</code><code class="mi">40</code><code class="p">)</code>
<code class="n">g</code><code class="o">.</code><code class="n">set_axis_labels</code><code class="p">(</code><code class="s1">'Income'</code><code class="p">,</code> <code class="s1">'Count'</code><code class="p">)</code>
<code class="n">g</code><code class="o">.</code><code class="n">set_titles</code><code class="p">(</code><code class="s1">'{col_name}'</code><code class="p">)</code></pre>








<section data-type="sect2" data-pdf-bookmark="Central Limit Theorem"><div class="sect2" id="central-limit-theorem">
<h2>Central Limit Theorem</h2>

<p>The phenomenon we’ve just described is termed the <em>central limit theorem</em>.<a data-type="indexterm" data-primary="central limit theorem" id="idm46522862864760"/><a data-type="indexterm" data-primary="sampling distribution" data-secondary="central limit theorem" id="idm46522862603048"/>
It says that the means drawn from multiple samples will resemble the familiar bell-shaped normal curve (see <a data-type="xref" href="#NormalDist">“Normal Distribution”</a>), even if the source population is not normally distributed, provided that the sample size is large enough and the departure of the data from normality is not too great.
The central limit theorem allows normal-approximation formulas like the t-distribution to be used in calculating sampling distributions for inference—that is, confidence intervals and hypothesis tests.</p>

<p>The central limit theorem receives a lot of attention in traditional statistics texts because it underlies the machinery of hypothesis tests and confidence intervals, which themselves consume half the space in such texts.
Data scientists should be aware of this role; however, since formal hypothesis tests and confidence intervals play a small role in data science, and the <em>bootstrap</em> (see <a data-type="xref" href="#bootstrap">“The Bootstrap”</a>) is available in any case, the central limit theorem is not so central in the practice of data science.<a data-type="indexterm" data-primary="bootstrap" id="idm46522862598488"/></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Standard Error"><div class="sect2" id="idm46522862597560">
<h2>Standard Error</h2>

<p>The <em>standard error</em> is a single metric that sums up the variability in the sampling distribution for a statistic.<a data-type="indexterm" data-primary="standard error" id="idm46522862595464"/><a data-type="indexterm" data-primary="sampling distribution" data-secondary="standard error" id="idm46522862594760"/>
The standard error can be estimated using a statistic based on the standard deviation <em>s</em> of the sample values, and the sample size <em>n</em>:</p>
<div data-type="equation">
<math display="block">
  <mrow>
    <mtext>Standard</mtext>
    <mspace width="4.pt"/>
    <mtext>error</mtext>
    <mo>=</mo>
    <mi>S</mi>
    <mi>E</mi>
    <mo>=</mo>
    <mfrac><mi>s</mi> <msqrt><mi>n</mi></msqrt></mfrac>
  </mrow>
</math>
</div>

<p>As the sample size increases, the standard error decreases, corresponding to what was observed in <a data-type="xref" href="#loans-mean-hist">Figure 2-6</a>.
The relationship between standard error and sample size is sometimes referred to as the <em>square root of n</em> rule: to reduce the standard error by a factor of 2, the sample size must be increased by a factor of 4.<a data-type="indexterm" data-primary="square-root of n rule" id="idm46522862584488"/></p>

<p>The validity of the standard error formula arises from the central limit theorem.
In fact, you don’t need to rely on the central limit theorem to understand  standard error.
Consider the following approach to measuring standard error:</p>
<ol>
<li>
<p>Collect a number of brand-new samples from the population.</p>
</li>
<li>
<p>For each new sample, calculate the statistic (e.g., mean).</p>
</li>
<li>
<p>Calculate the standard deviation of the statistics computed in step 2; use this as your estimate of standard error.</p>
</li>

</ol>

<p>In practice, this approach of collecting new samples to estimate the standard error is typically not feasible (and statistically very wasteful).
Fortunately, it turns out that it is not necessary to draw brand new samples; instead, you can use <em>bootstrap</em> resamples.<a data-type="indexterm" data-primary="bootstrap" data-secondary="standard error and" id="idm46522862578888"/>
In modern statistics, the bootstrap has become the standard way to estimate standard error.
It can be used for virtually any statistic and does not rely on the central limit theorem or other distributional assumptions.</p>
<div data-type="warning" epub:type="warning"><h1>Standard Deviation Versus Standard Error</h1>
<p>Do not confuse standard deviation (which measures the variability of individual data points) with standard error (which measures the variability of a sample metric).</p>
</div>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522862575784">
<h5>Key Ideas</h5>
<ul>
<li>
<p>The frequency distribution of a sample statistic tells us how that metric would turn out differently from sample to sample.</p>
</li>
<li>
<p>This sampling distribution can be estimated via the bootstrap, or via formulas that rely on the central limit theorem.</p>
</li>
<li>
<p>A key metric that sums up the variability of a sample statistic is its standard error.</p>
</li>
</ul>
</div></aside>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522862571304">
<h2>Further Reading</h2>

<p>David Lane’s <a href="https://oreil.ly/pe7ra">online multimedia resource in statistics</a> has a useful simulation that allows you to select a sample statistic, a sample size, and the number of iterations and visualize a histogram of the resulting frequency distribution.<a data-type="indexterm" data-primary="sampling distribution" data-startref="ix_smpldst" id="idm46522862569000"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="The Bootstrap"><div class="sect1" id="bootstrap">
<h1>The Bootstrap</h1>

<p>One easy and effective way to estimate the sampling distribution of a statistic, or of model parameters, is to draw additional samples, with replacement, from the sample itself and recalculate the statistic or model for each resample.<a data-type="indexterm" data-primary="sampling" data-secondary="bootstrap" id="ix_smplboot"/><a data-type="indexterm" data-primary="bootstrap" id="ix_boots"/>
This procedure is called the <em>bootstrap</em>, and it does not necessarily involve any assumptions about the data or the sample statistic being normally distributed.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522862562616">
<h5>Key Terms for the Bootstrap</h5><dl>
<dt class="horizontal"><strong><em>Bootstrap sample</em></strong></dt>
<dd>
<p>A sample taken with replacement from an observed data set.<a data-type="indexterm" data-primary="bootstrap sample" id="idm46522862559864"/><a data-type="indexterm" data-primary="resampling" id="idm46522862559160"/></p>
</dd>
<dt class="horizontal"><strong><em>Resampling</em></strong></dt>
<dd>
<p>The process of taking repeated samples from observed data; includes both bootstrap and permutation (shuffling) procedures.</p>
</dd>
</dl>
</div></aside>

<p>Conceptually, you can imagine the bootstrap as replicating the original sample thousands or millions of times so that you have a hypothetical population that embodies all the knowledge from your original sample (it’s just larger).
You can then draw samples from this hypothetical population for the purpose of estimating a sampling distribution; see <a data-type="xref" href="#bootstrap-schematic-1">Figure 2-7</a>.</p>

<figure><div id="bootstrap-schematic-1" class="figure">
<img src="Images/psd2_0207.png" alt="images/Bootstrap-schematic-1.png" width="1282" height="526"/>
<h6><span class="label">Figure 2-7. </span>The idea of the bootstrap</h6>
</div></figure>

<p>In practice, it is not necessary to actually replicate the sample a huge number of times.<a data-type="indexterm" data-primary="replacement (in sampling)" data-secondary="sample with replacement" id="idm46522862551976"/><a data-type="indexterm" data-primary="sampling" data-secondary="with and without replacement" data-secondary-sortas="replacement" id="idm46522862550936"/>
We simply replace each observation after each draw; that is, we <em>sample with replacement</em>.  In this way we effectively create an infinite population in which the probability of an element being drawn remains unchanged from draw to draw.<a data-type="indexterm" data-primary="bootstrap" data-secondary="algorithm for bootstrap resampling of the mean" id="idm46522862549032"/>
The algorithm for a bootstrap resampling of the mean, for a sample of size <em>n</em>, is as follows:</p>
<ol>
<li>
<p>Draw a sample value, record it, and then replace it.</p>
</li>
<li>
<p>Repeat <em>n</em> times.</p>
</li>
<li>
<p>Record the mean of the <em>n</em> resampled values.</p>
</li>
<li>
<p>Repeat steps 1–3 <em>R</em> times.</p>
</li>
<li>
<p>Use the <em>R</em> results to:</p>
<ol>
<li>
<p>Calculate their standard deviation (this estimates sample mean standard error).</p>
</li>
<li>
<p>Produce a histogram or boxplot.</p>
</li>
<li>
<p>Find a confidence interval.</p>
</li>

</ol>
</li>

</ol>

<p><em>R</em>, the number of iterations of the bootstrap, is set somewhat arbitrarily.
The more iterations you do, the more accurate the estimate of the standard error, or the confidence interval.
The result from this procedure is a bootstrap set of sample statistics or estimated model parameters, which you can then examine to see how variable they are.</p>

<p>The <em>R</em> package <code>boot</code> combines these steps in one function.
For example, the following applies the bootstrap to the incomes of people taking out loans:</p>

<pre data-type="programlisting" data-code-language="r"><code class="nf">library</code><code class="p">(</code><code class="n">boot</code><code class="p">)</code>
<code class="n">stat_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">x</code><code class="p">,</code> <code class="n">idx</code><code class="p">)</code> <code class="nf">median</code><code class="p">(</code><code class="n">x</code><code class="p">[</code><code class="n">idx</code><code class="p">])</code>
<code class="n">boot_obj</code> <code class="o">&lt;-</code> <code class="nf">boot</code><code class="p">(</code><code class="n">loans_income</code><code class="p">,</code> <code class="n">R</code><code class="o">=</code><code class="m">1000</code><code class="p">,</code> <code class="n">statistic</code><code class="o">=</code><code class="n">stat_fun</code><code class="p">)</code></pre>

<p>The function <code>stat_fun</code> computes the median for a given sample specified by the index <code>idx</code>.
The result is as follows:</p>

<pre data-type="programlisting" data-code-language="r"><code class="n">Bootstrap</code> <code class="n">Statistics</code> <code class="o">:</code>
    <code class="n">original</code>   <code class="n">bias</code>    <code class="n">std.</code> <code class="n">error</code>
<code class="n">t1</code><code class="o">*</code>    <code class="m">62000</code> <code class="m">-70.5595</code>    <code class="m">209.1515</code></pre>

<p>The original estimate of the median is $62,000.
The bootstrap distribution indicates that the estimate has a <em>bias</em> of about –$70 and a standard error of $209. The results will vary slightly between consecutive runs of the algorithm.</p>

<p>The major <em>Python</em> packages don’t provide implementations of the bootstrap approach. It can be implemented using the <code>scikit-learn</code> method <code>resample</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">results</code> <code class="o">=</code> <code class="p">[]</code>
<code class="k">for</code> <code class="n">nrepeat</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">1000</code><code class="p">):</code>
    <code class="n">sample</code> <code class="o">=</code> <code class="n">resample</code><code class="p">(</code><code class="n">loans_income</code><code class="p">)</code>
    <code class="n">results</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">sample</code><code class="o">.</code><code class="n">median</code><code class="p">())</code>
<code class="n">results</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">(</code><code class="n">results</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="s1">'Bootstrap Statistics:'</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'original: {loans_income.median()}'</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'bias: {results.mean() - loans_income.median()}'</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'std. error: {results.std()}'</code><code class="p">)</code></pre>

<p>The bootstrap can be used with multivariate data, where the rows are sampled as units (see <a data-type="xref" href="#bootstrap-multivariate">Figure 2-8</a>).
A model<a data-type="indexterm" data-primary="multivariate bootstrap sampling" id="idm46522862341048"/> might then be run on the bootstrapped data, for example, to estimate the stability (variability) of model parameters, or to improve predictive power.<a data-type="indexterm" data-primary="decision trees" data-secondary="running multiple on bootstrap samples" id="idm46522862340120"/>
With classification and regression trees (also called <em>decision trees</em>), running multiple trees on bootstrap samples and then averaging their predictions (or, with classification, taking a majority vote) generally performs better than using a <span class="keep-together">single tree</span>.<a data-type="indexterm" data-primary="bagging" id="idm46522862337816"/>  This process is called <em>bagging</em> (short for “bootstrap aggregating”; see <a data-type="xref" href="ch06.xhtml#Bagging">“Bagging and the Random Forest”</a>).</p>

<figure><div id="bootstrap-multivariate" class="figure">
<img src="Images/psd2_0208.png" alt="images/Bootstrap-multivariate-schematic.png" width="944" height="627"/>
<h6><span class="label">Figure 2-8. </span>Multivariate bootstrap sampling</h6>
</div></figure>

<p>The repeated resampling of the bootstrap is conceptually simple, and Julian Simon, an economist and demographer, published a compendium of resampling examples, including the bootstrap, in his 1969 text <em>Basic Research Methods in Social Science</em> (Random House).
However, it is also computationally intensive and was not a feasible option before the widespread availability of computing power.
The technique gained its name and took off with the publication of several journal articles and a book by Stanford statistician Bradley Efron in the late 1970s and early 1980s.
It was particularly popular among researchers who use statistics but are not statisticians, and for use with metrics or models where mathematical approximations are not readily available.
The sampling distribution of the mean has been well established since 1908; the sampling distribution of many other metrics has not.
The bootstrap can be used for sample size determination; experiment with different values for <em>n</em> to see how the sampling distribution is affected.</p>

<p>The bootstrap was met with considerable skepticism when it was first introduced; it had the aura to many of spinning gold from straw.
This skepticism stemmed from a misunderstanding of the bootstrap’s purpose.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>The bootstrap does not compensate for a small sample size; it does not create new data, nor does it fill in holes in an existing data set.
It merely informs us about how lots of additional samples would behave when drawn from a population like our original sample.</p>
</div>








<section data-type="sect2" data-pdf-bookmark="Resampling Versus Bootstrapping"><div class="sect2" id="idm46522862329352">
<h2>Resampling Versus Bootstrapping</h2>

<p>Sometimes the term <em>resampling</em> is used synonymously with the term <em>bootstrapping</em>, as just outlined.<a data-type="indexterm" data-primary="bootstrap" data-secondary="resampling versus bootstrapping" id="idm46522862326968"/><a data-type="indexterm" data-primary="resampling" data-secondary="bootstrapping versus" id="idm46522862325992"/>
More often, the term <em>resampling</em> also includes permutation procedures (see <a data-type="xref" href="ch03.xhtml#Permutation">“Permutation Test”</a>), where multiple samples are combined and the sampling may be done without replacement.
In any case, the term <em>bootstrap</em> always implies sampling with replacement from an observed data set.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522862323096">
<h5>Key Ideas</h5>
<ul>
<li>
<p>The bootstrap (sampling with replacement from a data set) is a powerful tool for assessing the variability of a sample statistic.</p>
</li>
<li>
<p>The bootstrap can be applied in similar fashion in a wide variety of circumstances, without extensive study of mathematical approximations to sampling distributions.</p>
</li>
<li>
<p>It also allows us to estimate sampling distributions for statistics where no mathematical approximation has been developed.</p>
</li>
<li>
<p>When applied to predictive models, aggregating multiple bootstrap sample predictions (bagging) outperforms the use of a single model.</p>
</li>
</ul>
</div></aside>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522862317288">
<h2>Further Reading</h2>

<ul>
<li>
<p><em>An Introduction to the Bootstrap</em> by Bradley Efron and Robert Tibshirani (Chapman &amp; Hall, 1993) was the first book-length treatment of the bootstrap. It is still widely read.</p>
</li>
<li>
<p>The retrospective on the bootstrap in the May 2003 issue of <em>Statistical Science</em> (vol. 18, no. 2), discusses (among other antecedents, in Peter Hall’s “A Short Prehistory of the Bootstrap”) Julian Simon’s initial publication of the bootstrap in 1969.</p>
</li>
<li>
<p>See <em>An Introduction to Statistical Learning</em> by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani (Springer, 2013) for sections on the bootstrap and, in particular, bagging.<a data-type="indexterm" data-primary="sampling" data-secondary="bootstrap" data-startref="ix_smplboot" id="idm46522862311960"/><a data-type="indexterm" data-primary="bootstrap" data-startref="ix_boots" id="idm46522862310744"/></p>
</li>
</ul>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Confidence Intervals"><div class="sect1" id="idm46522862567016">
<h1>Confidence Intervals</h1>

<p>Frequency tables, histograms, boxplots, and standard errors are all ways to understand the potential error in a sample estimate.<a data-type="indexterm" data-primary="sampling" data-secondary="confidence intervals" id="ix_smplcfint"/>
Confidence intervals are another.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522862306360">
<h5>Key Terms for Confidence Intervals</h5><dl>
<dt class="horizontal"><strong><em>Confidence level</em></strong></dt>
<dd>
<p>The percentage of confidence intervals, constructed in the same way from the same population, that are expected to contain the statistic of interest.<a data-type="indexterm" data-primary="interval endpoints" id="idm46522862303432"/></p>
</dd>
<dt class="horizontal"><strong><em>Interval endpoints</em></strong></dt>
<dd>
<p>The top and bottom of the confidence interval.</p>
</dd>
</dl>
</div></aside>

<p>There is a natural human aversion to uncertainty; people (especially experts) say “I don’t know” far too rarely.
Analysts and managers, while acknowledging uncertainty, nonetheless place undue faith in an estimate when it is presented as a single number (a <em>point estimate</em>).<a data-type="indexterm" data-primary="point estimates" id="idm46522862299432"/>
Presenting an estimate not as a single number but as a range is one way to counteract this tendency.
Confidence intervals do this in a manner grounded in statistical sampling principles.</p>

<p>Confidence intervals always come with a coverage level, expressed as a (high) percentage, say 90% or 95%.
One way to think of a 90% confidence interval is as follows:  it is the interval that encloses the central 90% of the bootstrap sampling distribution of a sample statistic (see  <a data-type="xref" href="#bootstrap">“The Bootstrap”</a>).
More generally, an <em>x</em>% confidence interval around a sample estimate should, on average, contain similar sample estimates <em>x</em>% of the time (when a similar sampling procedure is followed).</p>

<p>Given a sample of size <em>n</em>, and a sample statistic of interest, the algorithm for a bootstrap confidence interval<a data-type="indexterm" data-primary="confidence intervals" data-secondary="algorithm for bootstrap confidence interval" id="idm46522862295032"/><a data-type="indexterm" data-primary="bootstrap" data-secondary="confidence interval generation" id="idm46522862294024"/> is as follows:</p>
<ol>
<li>
<p>Draw a random sample of size <em>n</em> with replacement from the data (a resample).</p>
</li>
<li>
<p>Record the statistic of interest for the resample.</p>
</li>
<li>
<p>Repeat steps 1–2 many (<em>R</em>) times.</p>
</li>
<li>
<p>For an <em>x</em>% confidence interval, trim [(100-<em>x</em>) / 2]% of the <em>R</em> resample results from either end of the distribution.</p>
</li>
<li>
<p>The trim points are the endpoints of an <em>x</em>% bootstrap confidence interval.</p>
</li>

</ol>

<p><a data-type="xref" href="#bootstrap-ci">Figure 2-9</a> shows a 90% confidence interval for the mean annual income of loan applicants, based on a sample of 20 for which the mean was $62,231.</p>

<figure><div id="bootstrap-ci" class="figure">
<img src="Images/psd2_0209.png" alt="images/bootstrap-CI.png" width="1103" height="799"/>
<h6><span class="label">Figure 2-9. </span>Bootstrap confidence interval for the annual income of loan applicants, based on a sample of 20</h6>
</div></figure>

<p>The bootstrap is a general tool that can be used to generate confidence intervals for most statistics, or model parameters.
Statistical textbooks and software, with roots in over a half century of computerless statistical analysis, will also reference confidence intervals generated by formulas, especially the t-distribution (see <a data-type="xref" href="#t-distribution">“Student’s t-Distribution”</a>).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Of course, what we are really interested in when we have a sample result is, “What is the probability that the true value lies within a certain interval?”
This is not really the question that a confidence interval answers, but it ends up being how most people interpret the answer.</p>

<p>The probability<a data-type="indexterm" data-primary="probability" data-secondary="associated with a confidence interval" id="idm46522862262008"/> question associated with a confidence interval starts out with the phrase “Given a sampling procedure and a population, what is the probability that…”
To go in the opposite direction, “Given a sample result, what is the probability that (something is true about the population)?” involves more complex calculations and deeper imponderables.</p>
</div>

<p>The percentage associated with the confidence interval<a data-type="indexterm" data-primary="level of confidence" id="idm46522862259912"/><a data-type="indexterm" data-primary="confidence intervals" data-secondary="level of confidence" id="idm46522862259208"/> is termed the <em>level of confidence</em>.
The higher the level of confidence, the wider the interval.
Also, the smaller the sample, the wider the interval (i.e., the greater the uncertainty).
Both make sense:  the more confident you want to be, and the less data you have, the wider you must make the confidence interval to be sufficiently assured of capturing the true value.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>For a data scientist, a confidence interval is a tool that can be used to get an idea of how variable a sample result might be.<a data-type="indexterm" data-primary="confidence intervals" data-secondary="application to data science" id="idm46522862256216"/>
Data scientists would use this information not to publish a scholarly paper or submit a result to a regulatory agency (as a researcher might) but most likely to communicate the potential error in an estimate, and perhaps to learn whether a larger sample is needed.</p>
</div>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522862254552">
<h5>Key Ideas</h5>
<ul>
<li>
<p>Confidence intervals are the typical way to present estimates as an interval range.</p>
</li>
<li>
<p>The more data you have, the less variable a sample estimate will be.</p>
</li>
<li>
<p>The lower the level of confidence you can tolerate, the narrower the confidence interval will be.</p>
</li>
<li>
<p>The bootstrap is an effective way to construct confidence intervals.</p>
</li>
</ul>
</div></aside>








<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522862249400">
<h2>Further Reading</h2>

<ul>
<li>
<p>For a bootstrap approach to confidence intervals, see <em>Introductory Statistics and Analytics: A Resampling Perspective</em> by Peter Bruce (Wiley, 2014) or <em>Statistics: Unlocking the Power of Data</em>, 2nd ed., by Robin Lock and four other Lock family members (Wiley, 2016).</p>
</li>
<li>
<p>Engineers, who have a need to understand the precision of their measurements, use confidence intervals perhaps more than most disciplines, and <em>Modern Engineering Statistics</em> by Thomas Ryan (Wiley, 2007) discusses confidence intervals.<a data-type="indexterm" data-primary="prediction intervals" id="idm46522862245064"/>
It also reviews a tool that is just as useful and gets less attention: <em>prediction intervals</em> (intervals around a single value, as opposed to a mean or other summary <span class="keep-together">statistic</span>).<a data-type="indexterm" data-primary="sampling" data-secondary="confidence intervals" data-startref="ix_smplcfint" id="idm46522862243112"/></p>
</li>
</ul>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Normal Distribution"><div class="sect1" id="NormalDist">
<h1>Normal Distribution</h1>

<p>The bell-shaped <a data-type="indexterm" data-primary="normal distribution" id="ix_nrmldis"/><a data-type="indexterm" data-primary="sampling" data-secondary="normal distribution" id="ix_smplnrm"/>normal distribution is iconic in traditional statistics.<sup><a data-type="noteref" id="idm46522862237288-marker" href="ch02.xhtml#idm46522862237288">1</a></sup>
The fact that distributions of sample statistics are often normally shaped has made it a powerful tool in the development of mathematical formulas that approximate those <span class="keep-together">distributions</span>.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522862234840">
<h5>Key Terms for Normal Distribution</h5><dl>
<dt class="horizontal"><strong><em>Error</em></strong></dt>
<dd>
<p>The difference between a data point and a predicted or average value.<a data-type="indexterm" data-primary="errors" id="idm46522862231688"/><a data-type="indexterm" data-primary="standardization" id="idm46522862230904"/></p>
</dd>
<dt class="horizontal"><strong><em>Standardize</em></strong></dt>
<dd>
<p>Subtract the mean and divide by the standard deviation.</p>
</dd>
<dt class="horizontal"><strong><em>z-score</em></strong></dt>
<dd>
<p>The result of standardizing an individual data point.<a data-type="indexterm" data-primary="z-scores" id="idm46522862226456"/></p>
</dd>
<dt class="horizontal"><strong><em>Standard normal</em></strong></dt>
<dd>
<p>A normal distribution with mean = 0 and standard deviation = 1.<a data-type="indexterm" data-primary="standard normal distribution" id="idm46522862223944"/></p>
</dd>
<dt class="horizontal"><strong><em>QQ-Plot</em></strong></dt>
<dd>
<p>A plot to visualize how close a sample distribution is to a specified distribution, e.g., the normal distribution.<a data-type="indexterm" data-primary="QQ-Plots" id="idm46522862221208"/></p>
</dd>
</dl>
</div></aside>

<p>In a normal distribution (<a data-type="xref" href="#normal-curve">Figure 2-10</a>), 68% of the data lies within one standard deviation of the mean, and 95% lies within two standard deviations.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>It is a common misconception that the normal distribution is called that because most data follows a normal distribution—that is, it is the normal thing.<a data-type="indexterm" data-primary="normal distribution" data-secondary="misconceptions about" id="idm46522862217880"/>
Most of the variables used in a typical data science project—in fact, most raw data as a whole—are <em>not</em> normally distributed: see <a data-type="xref" href="#LongTailedData">“Long-Tailed Distributions”</a>.
The utility of the normal distribution derives from the fact that many statistics <em>are</em> normally distributed in their sampling distribution.
Even so, assumptions of normality are generally a last resort, used when empirical probability distributions, or bootstrap distributions, are not available.</p>
</div>

<figure><div id="normal-curve" class="figure">
<img src="Images/psd2_0210.png" alt="Normal_dist.PNG" width="748" height="539"/>
<h6><span class="label">Figure 2-10. </span>Normal curve</h6>
</div></figure>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The normal distribution is also referred to as a <em>Gaussian</em> distribution after Carl Friedrich Gauss, a prodigious German mathematician from the late 18th and early 19th centuries.<a data-type="indexterm" data-primary="Gaussian distribution" data-seealso="normal distribution" id="idm46522862211016"/>
Another name previously used for the normal distribution was the “error” distribution.
Statistically speaking, an <em>error</em> is the difference between an actual value and a statistical estimate like the sample mean.
For example, the standard deviation (see <a data-type="xref" href="ch01.xhtml#Variability">“Estimates of Variability”</a>) is based on the errors from the mean of the data.
Gauss’s development of the normal distribution came from his study of the errors of astronomical measurements that were found to be normally distributed.</p>
</div>








<section data-type="sect2" class="pagebreak-before less_space" data-pdf-bookmark="Standard Normal and QQ-Plots"><div class="sect2" id="StandardNormal">
<h2>Standard Normal and QQ-Plots</h2>

<p>A <em>standard normal</em> distribution is one in which the units on the x-axis are expressed in terms of standard deviations away from the mean.<a data-type="indexterm" data-primary="normal distribution" data-secondary="standard normal and QQ-Plots" id="idm46522862204904"/><a data-type="indexterm" data-primary="standard normal distribution" data-secondary="and QQ-Plots" id="idm46522862203912"/><a data-type="indexterm" data-primary="QQ-Plots" data-secondary="standard normal distribution and" id="idm46522862202952"/>
To compare data to a standard normal distribution, you subtract the mean and then divide by the standard deviation; this is also called <em>normalization</em> or <em>standardization</em> (see <a data-type="xref" href="ch06.xhtml#Standardization">“Standardization (Normalization, z-Scores)”</a>). Note that “standardization” in this sense is unrelated to database record standardization (conversion to a common format).<a data-type="indexterm" data-primary="standardization" id="idm46522862199864"/><a data-type="indexterm" data-primary="normalization" id="idm46522862199192"/>
The transformed value is termed a <em>z-score</em>, and the normal distribution is sometimes called the <em>z-distribution</em>.<a data-type="indexterm" data-primary="z-scores" id="idm46522862197592"/></p>

<p>A <em>QQ-Plot</em> is used to visually determine how close a sample is to a specified distribution—in this case, the normal distribution.
The QQ-Plot orders the <em>z</em>-scores from low to high and plots each value’s <em>z</em>-score on the y-axis; the x-axis is the corresponding quantile of a normal distribution for that value’s rank.
Since the data is normalized, the units correspond to the number of standard deviations away from the mean.
If the points roughly fall on the diagonal line, then the sample distribution can be considered close to normal.
<a data-type="xref" href="#qqnorm">Figure 2-11</a> shows a QQ-Plot for a sample of 100 values randomly generated from a normal distribution; as expected, the points closely follow the line.
This figure can be produced in <em>R</em> with the <code>qqnorm</code> function:</p>

<pre data-type="programlisting" data-code-language="r"><code class="n">norm_samp</code> <code class="o">&lt;-</code> <code class="nf">rnorm</code><code class="p">(</code><code class="m">100</code><code class="p">)</code>
<code class="nf">qqnorm</code><code class="p">(</code><code class="n">norm_samp</code><code class="p">)</code>
<code class="nf">abline</code><code class="p">(</code><code class="n">a</code><code class="o">=</code><code class="m">0</code><code class="p">,</code> <code class="n">b</code><code class="o">=</code><code class="m">1</code><code class="p">,</code> <code class="n">col</code><code class="o">=</code><code class="s">'grey'</code><code class="p">)</code></pre>

<p>In <em>Python</em>, use the method <code>scipy.stats.probplot</code> to create the QQ-Plot:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">4</code><code class="p">,</code> <code class="mi">4</code><code class="p">))</code>
<code class="n">norm_sample</code> <code class="o">=</code> <code class="n">stats</code><code class="o">.</code><code class="n">norm</code><code class="o">.</code><code class="n">rvs</code><code class="p">(</code><code class="n">size</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code>
<code class="n">stats</code><code class="o">.</code><code class="n">probplot</code><code class="p">(</code><code class="n">norm_sample</code><code class="p">,</code> <code class="n">plot</code><code class="o">=</code><code class="n">ax</code><code class="p">)</code></pre>

<figure class="width-75"><div id="qqnorm" class="figure">
<img src="Images/psd2_0211.png" alt="qqnorm.png" width="1109" height="1121"/>
<h6><span class="label">Figure 2-11. </span>QQ-Plot of a sample of 100 values drawn from a standard normal <span class="keep-together">distribution</span></h6>
</div></figure>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Converting data to <em>z</em>-scores (i.e., standardizing or normalizing the data) does <em>not</em> make the data normally distributed.<a data-type="indexterm" data-primary="z-scores" data-secondary="conversion of data to, normal distribution and" id="idm46522862099000"/>
It just puts the data on the same scale as the standard normal distribution, often for comparison purposes.</p>
</div>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522862097544">
<h5>Key Ideas</h5>
<ul>
<li>
<p>The normal distribution was essential to the historical development of statistics, as it permitted mathematical approximation of uncertainty and variability.<a data-type="indexterm" data-primary="normal distribution" data-secondary="key concepts" id="idm46522862095432"/></p>
</li>
<li>
<p>While raw data is typically not normally distributed, errors often are, as are averages and totals in large samples.</p>
</li>
<li>
<p>To convert data to <em>z</em>-scores, you subtract the mean of the data and divide by the standard deviation; you can then compare the data to a normal distribution.<a data-type="indexterm" data-primary="normal distribution" data-startref="ix_nrmldis" id="idm46522862092024"/><a data-type="indexterm" data-primary="sampling" data-secondary="normal distribution" data-startref="ix_smplnrm" id="idm46522862091048"/></p>
</li>
</ul>
</div></aside>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Long-Tailed Distributions"><div class="sect1" id="LongTailedData">
<h1>Long-Tailed Distributions</h1>

<p>Despite the importance of the normal distribution historically in statistics, and in contrast to what the name would suggest, data is generally not normally distributed.<a data-type="indexterm" data-primary="sampling" data-secondary="long-tailed distributions" id="ix_smpllt"/><a data-type="indexterm" data-primary="long-tail distributions" id="ix_longtl"/></p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522862085032">
<h5>Key Terms for Long-Tailed Distributions</h5><dl>
<dt class="horizontal"><strong><em>Tail</em></strong></dt>
<dd>
<p>The long narrow portion of a frequency distribution, where relatively extreme values occur at low frequency.<a data-type="indexterm" data-primary="tails" id="idm46522862082184"/><a data-type="indexterm" data-primary="skew" id="idm46522862081480"/></p>
</dd>
<dt class="horizontal"><strong><em>Skew</em></strong></dt>
<dd>
<p>Where one tail of a distribution is longer than the other.</p>
</dd>
</dl>
</div></aside>

<p>While the normal distribution is often appropriate and useful with respect to the distribution of errors and sample statistics, it typically does not characterize the distribution of raw data.
Sometimes, the distribution is highly <em>skewed</em> (asymmetric), such as with income data; or the distribution can be discrete, as with binomial data.
Both symmetric and asymmetric distributions may have <em>long tails</em>.
The tails of a distribution correspond to the extreme values (small and large).
Long tails, and guarding against them, are widely recognized in practical work.
Nassim Taleb has proposed the <em>black swan</em> theory, which predicts that anomalous events, such as a stock market crash, are much more likely to occur than would be predicted by the normal <span class="keep-together">distribution</span>.<a data-type="indexterm" data-primary="black swan theory" id="idm46522862075480"/></p>

<p>A good example to illustrate the long-tailed nature of data is stock returns.
<a data-type="xref" href="#nflx_qnorm">Figure 2-12</a> shows the QQ-Plot for the daily stock returns for Netflix (NFLX). This is generated in <em>R</em> by:</p>

<pre data-type="programlisting" data-code-language="r"><code class="n">nflx</code> <code class="o">&lt;-</code> <code class="n">sp500_px</code><code class="p">[,</code><code class="s">'NFLX'</code><code class="p">]</code>
<code class="n">nflx</code> <code class="o">&lt;-</code> <code class="nf">diff</code><code class="p">(</code><code class="nf">log</code><code class="p">(</code><code class="n">nflx</code><code class="p">[</code><code class="n">nflx</code><code class="o">&gt;</code><code class="m">0</code><code class="p">]))</code>
<code class="nf">qqnorm</code><code class="p">(</code><code class="n">nflx</code><code class="p">)</code>
<code class="nf">abline</code><code class="p">(</code><code class="n">a</code><code class="o">=</code><code class="m">0</code><code class="p">,</code> <code class="n">b</code><code class="o">=</code><code class="m">1</code><code class="p">,</code> <code class="n">col</code><code class="o">=</code><code class="s">'grey'</code><code class="p">)</code></pre>

<p>The corresponding <em>Python</em> code is:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">nflx</code> <code class="o">=</code> <code class="n">sp500_px</code><code class="o">.</code><code class="n">NFLX</code>
<code class="n">nflx</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">diff</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">log</code><code class="p">(</code><code class="n">nflx</code><code class="p">[</code><code class="n">nflx</code><code class="o">&gt;</code><code class="mi">0</code><code class="p">]))</code>
<code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">4</code><code class="p">,</code> <code class="mi">4</code><code class="p">))</code>
<code class="n">stats</code><code class="o">.</code><code class="n">probplot</code><code class="p">(</code><code class="n">nflx</code><code class="p">,</code> <code class="n">plot</code><code class="o">=</code><code class="n">ax</code><code class="p">)</code></pre>

<figure class="width-75"><div id="nflx_qnorm" class="figure">
<img src="Images/psd2_0212.png" alt="nflx_qnorm.png" width="1109" height="1121"/>
<h6><span class="label">Figure 2-12. </span>QQ-Plot of the returns for Netflix (NFLX)</h6>
</div></figure>

<p>In contrast to <a data-type="xref" href="#qqnorm">Figure 2-11</a>, the points are far below the line for low values and far above the line for high values, indicating the data are not normally distributed.<a data-type="indexterm" data-primary="QQ-Plots" data-secondary="for  returns of NFLX stock" id="idm46522861933944"/>
This means that we are much more likely to observe extreme values than would be expected if the data had a normal distribution.
<a data-type="xref" href="#nflx_qnorm">Figure 2-12</a> shows another common phenomenon: the points are close to the line for the data within one standard deviation of the mean.
Tukey refers to this phenomenon as data being “normal in the middle” but having much longer tails (see <a data-type="link" href="bibliography01.xhtml#Tukey-1987">[Tukey-1987]</a>).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>There is much statistical literature about the task of fitting statistical distributions to observed data.
Beware an excessively data-centric approach to this job, which is as much art as science.<a data-type="indexterm" data-primary="data-centric approach, excessive" id="idm46522861929544"/>
Data is variable, and often consistent, on its face, with more than one shape and type of distribution.
It is typically the case that domain and statistical knowledge must be brought to bear to determine what type of distribution is appropriate to model a given situation.
For example, we might have data on the level of internet traffic on a server over many consecutive five-second periods.
It is useful to know that the best distribution to model “events per time period” is the Poisson (see <a data-type="xref" href="#Poisson">“Poisson Distributions”</a>).</p>
</div>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522861927176">
<h5>Key Ideas</h5>
<ul>
<li>
<p>Most data is not normally distributed.</p>
</li>
<li>
<p>Assuming a normal distribution can lead to underestimation of extreme events (“black swans”).</p>
</li>
</ul>
</div></aside>








<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522861923720">
<h2>Further Reading</h2>

<ul>
<li>
<p><em>The Black Swan</em>, 2nd ed., by Nassim Nicholas Taleb (Random House, 2010)</p>
</li>
<li>
<p><em>Handbook of Statistical Distributions with Applications</em>, 2nd ed., by K. Krishnamoorthy (Chapman &amp; Hall/CRC Press, 2016)</p>
</li>
</ul>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Student’s t-Distribution"><div class="sect1" id="t-distribution">
<h1>Student’s t-Distribution</h1>

<p>The <em>t-distribution</em> is a normally shaped distribution, except that it is a bit thicker and longer on the tails.<a data-type="indexterm" data-primary="sampling" data-secondary="long-tailed distributions" data-startref="ix_smpllt" id="idm46522861917368"/><a data-type="indexterm" data-primary="long-tail distributions" data-startref="ix_longtl" id="idm46522861916152"/><a data-type="indexterm" data-primary="t-distribution" id="ix_tdis"/><a data-type="indexterm" data-primary="Student's t-distribution" id="ix_studt"/><a data-type="indexterm" data-primary="sampling" data-secondary="Student's t-distribution" id="ix_smplStut"/>
It is used extensively in depicting distributions of sample statistics.
Distributions of sample means are typically shaped like a t-distribution, and there is a family of t-distributions that differ depending on how large the sample is.
The larger the sample, the more normally shaped the t-distribution becomes.</p>
<aside data-type="sidebar" epub:type="sidebar" class="pagebreak-before less_space"><div class="sidebar" id="idm46522861911528">
<h5>Key Terms for Student’s t-Distribution</h5><dl>
<dt class="horizontal"><strong><em>n</em></strong></dt>
<dd>
<p>Sample size.</p>
</dd>
<dt class="horizontal"><strong><em>Degrees of freedom</em></strong></dt>
<dd>
<p>A parameter that allows the t-distribution to adjust to different sample sizes, statistics, and numbers of groups.</p>
</dd>
</dl>
</div></aside>

<p>The t-distribution is often called <em>Student’s t</em> because it was published in 1908 in <em>Biometrika</em> by W. S. Gosset under the name “Student.”
Gosset’s employer, the Guinness brewery, did not want competitors to know that it was using statistical methods, so it insisted that Gosset not use his name on the article.<a data-type="indexterm" data-primary="Gosset, W. S." id="idm46522861904600"/></p>

<p>Gosset wanted to answer the question “What is the sampling distribution of the mean of a sample, drawn from a larger population?”
He started out with a resampling experiment—drawing random samples of 4 from a data set of 3,000 measurements of criminals’ height and left-middle-finger length.
(This being the era of eugenics, there was much interest in data on criminals, and in discovering correlations between criminal tendencies and physical or psychological attributes.)
Gosset plotted the standardized results (the <em>z</em>-scores) on the x-axis and the frequency on the y-axis.
Separately, he had derived a function, now known as <em>Student’s t</em>, and he fit this function over the sample results, plotting the comparison (see <a data-type="xref" href="#Gosset-curve">Figure 2-13</a>).</p>

<figure><div id="Gosset-curve" class="figure">
<img src="Images/psd2_0213.png" alt="Gosset-curve" width="1350" height="606"/>
<h6><span class="label">Figure 2-13. </span>Gosset’s resampling experiment results and fitted t-curve (from his 1908 <em>Biometrika</em> paper)</h6>
</div></figure>

<p class="pagebreak-before">A number of different statistics can be compared, after standardization, to the t-distribution, to estimate confidence intervals in light of sampling variation.
Consider a sample of size <em>n</em> for which the sample mean <math alttext="x overbar">
  <mover accent="true"><mi>x</mi> <mo>¯</mo></mover>
</math> has been calculated.
If <em>s</em> is the sample standard deviation, a 90% confidence interval around the sample mean is given by:</p>
<div data-type="equation">
<math alttext="x overbar plus-or-minus t Subscript n minus 1 Baseline left-parenthesis 0.05 right-parenthesis dot StartFraction s Over StartRoot n EndRoot EndFraction" display="block">
  <mrow>
    <mover accent="true"><mi>x</mi> <mo>¯</mo></mover>
    <mo>±</mo>
    <msub><mi>t</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow> </msub>
    <mrow>
      <mo>(</mo>
      <mn>0</mn>
      <mo>.</mo>
      <mn>05</mn>
      <mo>)</mo>
    </mrow>
    <mo>·</mo>
    <mfrac><mi>s</mi> <msqrt><mi>n</mi></msqrt></mfrac>
  </mrow>
</math>
</div>

<p>where <math alttext="t Subscript n minus 1 Baseline left-parenthesis .05 right-parenthesis">
  <mrow>
    <msub><mi>t</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow> </msub>
    <mrow>
      <mo>(</mo>
      <mo>.</mo>
      <mn>05</mn>
      <mo>)</mo>
    </mrow>
  </mrow>
</math> is the value of the t-statistic, with (<em>n</em> – 1) degrees of freedom (see <a data-type="xref" href="ch03.xhtml#DOF">“Degrees of Freedom”</a>), that “chops off” 5% of the t-distribution at either end.<a data-type="indexterm" data-primary="degrees of freedom" data-secondary="t-distribution and" id="idm46522861848456"/>
The t-distribution has been used as a reference for the distribution of a sample mean,  the difference between two sample means,  regression parameters, and other statistics.</p>

<p>Had computing power been widely available in 1908, statistics would no doubt have relied much more heavily on computationally intensive resampling methods from the start.
Lacking computers, statisticians turned to mathematics and functions such as the t-distribution to approximate sampling distributions.
Computer power enabled practical resampling experiments in the 1980s, but by then, use of the t-distribution and similar distributions had become deeply embedded in textbooks and software.</p>

<p>The t-distribution’s accuracy in depicting the behavior of a sample statistic requires that the distribution of that statistic for that sample be shaped like a normal distribution.
It turns out that sample statistics <em>are</em> often normally distributed, even when the underlying population data is not (a fact which led to widespread application of the t-distribution).<a data-type="indexterm" data-primary="central limit theorem" data-secondary="Student's t-distribution and" id="idm46522861845064"/>  This brings us back to the phenomenon known as the <em>central limit theorem</em> (see <a data-type="xref" href="#central-limit-theorem">“Central Limit Theorem”</a>).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>What do data scientists need to know about the t-distribution and the central limit theorem?
Not a whole lot. The t-distribution is used in classical statistical inference but is not as central to the purposes of data science.
Understanding and quantifying uncertainty and variation are important to data scientists, but empirical bootstrap sampling can answer most questions about sampling error.
However, data scientists will routinely encounter t-statistics in output from statistical software and statistical procedures in <em>R</em>—for example, in A/B tests and regressions—so familiarity with its purpose is helpful.</p>
</div>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522861840296">
<h5>Key Ideas</h5>
<ul>
<li>
<p>The t-distribution is actually a family of distributions resembling the normal distribution but with thicker tails.</p>
</li>
<li>
<p>The t-distribution is widely used as a reference basis for the distribution of sample means, differences between two sample means, regression parameters, and more.</p>
</li>
</ul>
</div></aside>








<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522861836648">
<h2>Further Reading</h2>

<ul>
<li>
<p>The original W.S. Gosset paper as published in <em>Biometrika</em> in 1908 is available <a href="https://oreil.ly/J6gDg">as a PDF</a>.</p>
</li>
<li>
<p>A standard treatment of the t-distribution can be found in David Lane’s <a href="https://oreil.ly/QxUkA">online resource</a>.<a data-type="indexterm" data-primary="sampling" data-secondary="Student's t-distribution" data-startref="ix_smplStut" id="idm46522861831896"/><a data-type="indexterm" data-primary="t-distribution" data-startref="ix_tdis" id="idm46522861830600"/><a data-type="indexterm" data-primary="Student's t-distribution" data-startref="ix_studt" id="idm46522861829656"/></p>
</li>
</ul>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Binomial Distribution"><div class="sect1" id="idm46522861919272">
<h1>Binomial Distribution</h1>

<p>Yes/no (binomial) outcomes lie at the heart of analytics since they are often the culmination of a decision or other process; buy/don’t buy, click/don’t click, survive/die, and so on.
Central to understanding the binomial distribution is the idea of a set of <em>trials</em>, each trial having two possible outcomes with definite probabilities.</p>

<p>For example, flipping a coin 10 times is a binomial experiment with 10 trials, each trial having two possible outcomes (heads or tails); see <a data-type="xref" href="#nickel">Figure 2-14</a>.
Such yes/no or 0/1 outcomes are termed <em>binary</em> outcomes, and they need not have 50/50 probabilities.<a data-type="indexterm" data-primary="binary outcomes" id="idm46522861823848"/>
Any probabilities that sum to 1.0 are possible.
It is conventional in statistics to term the “1” outcome the <em>success</em> outcome; it is also common practice to assign “1” to the more rare outcome.
Use of the term <em>success</em> does not imply that the outcome is desirable or beneficial, but it does tend to indicate the outcome of interest.<a data-type="indexterm" data-primary="success" id="idm46522861821848"/>
For example, loan defaults or fraudulent transactions are relatively uncommon events that we may be interested in predicting, so they are termed “1s” or “successes.”</p>

<figure><div id="nickel" class="figure">
<img src="Images/psd2_0214.png" alt="images/Indian_Head_Buffalo_Nickel.png" width="127" height="126"/>
<h6><span class="label">Figure 2-14. </span>The tails side of a buffalo nickel</h6>
</div></figure>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522861818872">
<h5>Key Terms for Binomial Distribution</h5><dl>
<dt class="horizontal"><strong><em>Trial</em></strong></dt>
<dd>
<p>An event with <a data-type="indexterm" data-primary="trials" id="idm46522861815720"/>a discrete outcome (e.g., a coin flip).</p>
</dd>
<dt class="horizontal"><strong><em>Success</em></strong></dt>
<dd>
<p>The outcome of interest for a trial.<a data-type="indexterm" data-primary="binomial distribution" id="ix_bidis"/><a data-type="indexterm" data-primary="sampling" data-secondary="binomial distribution" id="ix_smplbidi"/></p>
<dl>
<dt>Synonym</dt>
<dd>
<p>“1” (as opposed to “0”)</p>
</dd>
</dl>
</dd>
<dt class="horizontal"><strong><em>Binomial</em></strong></dt>
<dd>
<p>Having two outcomes.</p>
<dl>
<dt>Synonyms</dt>
<dd>
<p>yes/no, 0/1, binary</p>
</dd>
</dl>
</dd>
<dt class="horizontal"><strong><em>Binomial trial</em></strong></dt>
<dd>
<p>A trial with two outcomes.<a data-type="indexterm" data-primary="binomial trials" id="idm46522861803528"/></p>
<dl>
<dt>Synonym</dt>
<dd>
<p>Bernoulli trial</p>
</dd>
</dl>
</dd>
<dt class="horizontal"><strong><em>Binomial distribution</em></strong></dt>
<dd>
<p>Distribution of number of successes in <em>x</em> trials.</p>
<dl>
<dt>Synonym</dt>
<dd>
<p>Bernoulli distribution</p>
</dd>
</dl>
</dd>
</dl>
</div></aside>

<p>The binomial distribution is the frequency distribution of the number of successes (<em>x</em>) in a given number of trials (<em>n</em>) with specified probability (<em>p</em>) of success in each trial.  There is a family of binomial distributions, depending on the values of <em>n</em> and <em>p</em>.  The binomial distribution would answer a question like:</p>
<blockquote>
<p>If the probability of a click converting to a sale is 0.02, what is the probability of observing 0 sales in 200 clicks?</p>
</blockquote>

<p>The <em>R</em> function  <code>dbinom</code>  calculates binomial probabilities.
For example:</p>

<pre data-type="programlisting" data-code-language="r"><code class="nf">dbinom</code><code class="p">(</code><code class="n">x</code><code class="o">=</code><code class="m">2</code><code class="p">,</code> <code class="n">size</code><code class="o">=</code><code class="m">5</code><code class="p">,</code> <code class="n">p</code><code class="o">=</code><code class="m">0.1</code><code class="p">)</code></pre>

<p>would return 0.0729, the probability of observing exactly <em>x</em> = 2 successes in <em>size</em> = 5 trials, where the probability of success for each trial is <em>p</em> = 0.1. For our example above, we use <em>x</em> = 0, <em>size</em> = 200, and <em>p</em> = 0.02. With these arguments, <code>dbinom</code> returns a probability of 0.0176.</p>

<p>Often we are interested in determining the probability of <em>x</em> or fewer successes in <em>n</em> trials.
In this case, we use the function <code>pbinom</code>:</p>

<pre data-type="programlisting" data-code-language="r"><code class="nf">pbinom</code><code class="p">(</code><code class="m">2</code><code class="p">,</code> <code class="m">5</code><code class="p">,</code> <code class="m">0.1</code><code class="p">)</code></pre>

<p>This would return 0.9914, the probability of observing two or fewer successes in five trials, where the probability of success for each trial is 0.1.</p>

<p>The <code>scipy.stats</code> module implements a large variety of statistical distributions. For the binomial distribution, use the functions <code>stats.binom.pmf</code> and <code>stats.binom.cdf</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">stats</code><code class="o">.</code><code class="n">binom</code><code class="o">.</code><code class="n">pmf</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="n">n</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> <code class="n">p</code><code class="o">=</code><code class="mf">0.1</code><code class="p">)</code>
<code class="n">stats</code><code class="o">.</code><code class="n">binom</code><code class="o">.</code><code class="n">cdf</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="n">n</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> <code class="n">p</code><code class="o">=</code><code class="mf">0.1</code><code class="p">)</code></pre>

<p>The mean of a binomial distribution is <math alttext="n times p">
  <mrow>
    <mi>n</mi>
    <mo>×</mo>
    <mi>p</mi>
  </mrow>
</math>; you can also think of this as the expected number of successes in <em>n</em> trials, for success probability = <em>p</em>.</p>

<p>The variance is <math alttext="n times p left-parenthesis 1 minus p right-parenthesis">
  <mrow>
    <mi>n</mi>
    <mo>×</mo>
    <mi>p</mi>
    <mo>(</mo>
    <mn>1</mn>
    <mo>-</mo>
    <mi>p</mi>
    <mo>)</mo>
  </mrow>
</math>.
With a large enough number of trials (particularly when <em>p</em> is close to 0.50), the binomial distribution is virtually indistinguishable from the normal distribution.
In fact, calculating binomial probabilities with large sample sizes is computationally demanding, and most statistical procedures use the normal distribution, with mean and variance, as an approximation.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522861665960">
<h5>Key Ideas</h5>
<ul>
<li>
<p>Binomial outcomes are important to model, since they represent, among other things, fundamental decisions (buy or don’t buy, click or don’t click, survive or die, etc.).</p>
</li>
<li>
<p>A binomial trial is an experiment with two possible outcomes: one with probability <em>p</em> and the other with probability <em>1 – p</em>.</p>
</li>
<li>
<p>With large <em>n</em>, and provided <em>p</em> is not too close to 0 or 1, the binomial distribution can be approximated by the normal distribution.</p>
</li>
</ul>
</div></aside>








<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522861659640">
<h2>Further Reading</h2>

<ul>
<li>
<p>Read about <a href="https://oreil.ly/nmkcs">the “quincunx”</a>, a pinball-like simulation device for illustrating the binomial distribution.</p>
</li>
<li>
<p>The binomial distribution is a staple of introductory statistics, and all introductory statistics texts will have a chapter or two on it.<a data-type="indexterm" data-primary="binomial distribution" data-startref="ix_bidis" id="idm46522861655928"/><a data-type="indexterm" data-primary="sampling" data-secondary="binomial distribution" data-startref="ix_smplbidi" id="idm46522861654952"/></p>
</li>
</ul>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Chi-Square Distribution"><div class="sect1" id="chi-square-dist">
<h1>Chi-Square Distribution</h1>

<p>An important idea in statistics is <em>departure from expectation</em>, especially with respect to category counts.<a data-type="indexterm" data-primary="expectation or expected" data-secondary="departure from" id="idm46522861651032"/><a data-type="indexterm" data-primary="departure from expectation" id="idm46522861650088"/><a data-type="indexterm" data-primary="chi-square distribution" id="idm46522861649352"/><a data-type="indexterm" data-primary="sampling" data-secondary="chi-square distribution" id="idm46522861648680"/> Expectation is defined loosely as “nothing unusual or of note in the data” (e.g., no correlation between variables or predictable patterns).  This is also termed the “null hypothesis” or “null model” (see <a data-type="xref" href="ch03.xhtml#Null_hypothesis">“The Null Hypothesis”</a>).
For example, you might want to test whether one variable (say, a row variable representing gender) is independent of another (say, a column variable representing “was promoted in job”), and you have counts of the number in each of the cells of the data table.
The statistic that measures the extent to which results depart from the null expectation of independence is the chi-square statistic.  It is the difference between the observed and expected values, divided by the square root of the expected value, squared, then summed across all categories.
This process standardizes the statistic so it can be compared to a reference distribution.
A more general way of putting this is to note that the chi-square statistic is a measure of the extent to which a set of observed values “fits” a specified distribution (a “goodness-of-fit” test).
It is useful for determining whether multiple treatments (an “A/B/C… test”) differ from one another in their effects.</p>

<p>The chi-square distribution is the distribution of this statistic under repeated resampled draws from the null model—see <a data-type="xref" href="ch03.xhtml#chi-square">“Chi-Square Test”</a> for a detailed algorithm, and the chi-square formula for a data table.  A low chi-square value for a set of counts indicates that they closely follow the expected distribution.  A high chi-square indicates that they differ markedly from what is expected. There are a variety of chi-square distributions associated with different degrees of freedom (e.g., number of observations—see <a data-type="xref" href="ch03.xhtml#DOF">“Degrees of Freedom”</a>).</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522861629656">
<h5>Key Ideas</h5>
<ul>
<li>
<p>The chi-square distribution is typically concerned with counts of subjects or items falling into categories.</p>
</li>
<li>
<p>The chi-square statistic measures the extent of departure from what you would expect in a null model.</p>
</li>
</ul>
</div></aside>








<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522861626072">
<h2>Further Reading</h2>

<ul>
<li>
<p>The chi-square distribution owes its place in modern statistics to the great statistician Karl Pearson and the birth of hypothesis testing—read about this and more in David Salsburg’s <em>The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century</em> (W. H. Freeman, 2001).</p>
</li>
<li>
<p>For a more detailed exposition, see the section in this book on the chi-square test (<a data-type="xref" href="ch03.xhtml#chi-square">“Chi-Square Test”</a>).</p>
</li>
</ul>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="F-Distribution"><div class="sect1" id="F-dist">
<h1>F-Distribution</h1>

<p>A common procedure in scientific experimentation is to test multiple treatments across groups—say, different fertilizers on different blocks of a field.<a data-type="indexterm" data-primary="F-distribution" id="idm46522861619208"/><a data-type="indexterm" data-primary="sampling" data-secondary="F-distribution" id="idm46522861618504"/>
This is similar to the A/B/C test referred to in the chi-square distribution (see <a data-type="xref" href="#chi-square-dist">“Chi-Square Distribution”</a>), except we are dealing with measured continuous values rather than counts.
In this case we are interested in the extent to which differences among group means are greater than we might expect under normal random variation.
The F-statistic measures this and is the ratio of the variability among the group means to the variability within each group (also called residual variability).<a data-type="indexterm" data-primary="variance" data-secondary="analysis of (ANOVA)" id="idm46522861616232"/><a data-type="indexterm" data-primary="analysis of variance (ANOVA)" id="idm46522861615288"/>
This comparison is termed an <em>analysis of variance</em> (see <a data-type="xref" href="ch03.xhtml#ANOVA">“ANOVA”</a>).
The distribution of the F-statistic is the frequency distribution of all the values that would be produced by randomly permuting data in which all the group means are equal (i.e., a null model).
There are a variety of F-distributions associated with different degrees of freedom (e.g., numbers of groups—see <a data-type="xref" href="ch03.xhtml#DOF">“Degrees of Freedom”</a>).
The calculation of F is illustrated in the section on ANOVA.
The F-statistic is also used in linear regression to compare the variation accounted for by the regression model to the overall variation in the data.
F-statistics are produced automatically by <em>R</em> and <em>Python</em> as part of regression and ANOVA routines.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522861610968">
<h5>Key Ideas</h5>
<ul>
<li>
<p>The F-distribution is used with experiments and linear models involving measured data.</p>
</li>
<li>
<p>The F-statistic compares variation due to factors of interest to overall variation.</p>
</li>
</ul>
</div></aside>








<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522861607624">
<h2>Further Reading</h2>

<p>George Cobb’s <em>Introduction to Design and Analysis of Experiments</em> (Wiley, 2008) contains an excellent exposition of the decomposition of variance components, which helps in understanding ANOVA and the F-statistic.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Poisson and Related Distributions"><div class="sect1" id="idm46522861605368">
<h1>Poisson and Related Distributions</h1>

<p>Many processes produce events randomly at a given overall rate—visitors arriving at a website, or cars arriving at a toll plaza (events spread over time); imperfections in a square meter of fabric, or typos per 100 lines of code (events spread over space).<a data-type="indexterm" data-primary="sampling" data-secondary="Poisson and related distributions" id="ix_smplPoi"/></p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522861602200">
<h5>Key Terms for Poisson and Related Distributions</h5><dl>
<dt class="horizontal"><strong><em>Lambda</em></strong></dt>
<dd>
<p>The rate (per unit of time or space) at which events occur.</p>
</dd>
<dt class="horizontal"><strong><em>Poisson distribution</em></strong></dt>
<dd>
<p>The frequency distribution of the number of events in sampled units of time or space.</p>
</dd>
<dt class="horizontal"><strong><em>Exponential distribution</em></strong></dt>
<dd>
<p>The frequency distribution of the time or distance from one event to the next event.</p>
</dd>
<dt class="horizontal"><strong><em>Weibull distribution</em></strong></dt>
<dd>
<p>A generalized version of the exponential distribution in which the event rate is allowed to shift over time.</p>
</dd>
</dl>
</div></aside>








<section data-type="sect2" data-pdf-bookmark="Poisson Distributions"><div class="sect2" id="Poisson">
<h2>Poisson Distributions</h2>

<p>From prior aggregate data (for example, number of flu infections per year), we can estimate the average number of events per unit of time or space (e.g., infections per day, or per census unit).<a data-type="indexterm" data-primary="sampling" data-secondary="Poisson and related distributions" data-tertiary="Poisson distributions" id="idm46522861591208"/><a data-type="indexterm" data-primary="Poisson distributions" id="idm46522861589896"/>  We might also want to know how different this might be from one unit of time/space to another. The Poisson distribution tells us the distribution of events per unit of time or space when we sample many such units.
It is useful when addressing queuing questions such as “How much capacity do we need to be 95% sure of fully processing the internet traffic that arrives on a server in any five-second period?”</p>

<p>The key parameter in a Poisson distribution is <math alttext="lamda">
  <mi>λ</mi>
</math>, or lambda.
This is the mean number of events that occurs in a specified interval of time or space.
The variance for a Poisson distribution is also <math alttext="lamda">
  <mi>λ</mi>
</math>.</p>

<p>A common technique is to <a data-type="indexterm" data-primary="random numbers, generation from Poisson distribution" id="idm46522861585176"/>generate random numbers from a Poisson distribution as part of a queuing simulation. The <code>rpois</code> function in <em>R</em> does this, taking only two arguments—the quantity of random numbers sought, and lambda:</p>

<pre data-type="programlisting" data-code-language="r"><code class="nf">rpois</code><code class="p">(</code><code class="m">100</code><code class="p">,</code> <code class="n">lambda</code><code class="o">=</code><code class="m">2</code><code class="p">)</code></pre>

<p>The corresponding <code>scipy</code> function is <code>stats.poisson.rvs</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">stats</code><code class="o">.</code><code class="n">poisson</code><code class="o">.</code><code class="n">rvs</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="n">size</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code></pre>

<p>This code will generate 100 random numbers from a Poisson distribution with <math alttext="lamda">
  <mi>λ</mi>
</math> = 2.
For example, if incoming customer service calls average two per minute, this code will simulate 100 minutes, returning the number of calls in each of those 100 minutes.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Exponential Distribution"><div class="sect2" id="idm46522861565784">
<h2>Exponential Distribution</h2>

<p>Using the same parameter <math alttext="lamda">
  <mi>λ</mi>
</math> that we used in the Poisson distribution, we can also model the distribution of the time between events:  time between visits to a website or between cars arriving at a toll plaza.<a data-type="indexterm" data-primary="sampling" data-secondary="Poisson and related distributions" data-tertiary="exponential distribution" id="idm46522861562728"/><a data-type="indexterm" data-primary="exponential distribution" id="idm46522861561544"/>
It is also used in engineering to model time to failure, and in process management to model, for example, the time required per service call.
The <em>R</em> code to generate random numbers from an exponential distribution takes two arguments: <code>n</code> (the quantity of numbers to be generated) and <code>rate</code> (the number of events per time period).  For example:</p>

<pre data-type="programlisting" data-code-language="r"><code class="nf">rexp</code><code class="p">(</code><code class="n">n</code><code class="o">=</code><code class="m">100</code><code class="p">,</code> <code class="n">rate</code><code class="o">=</code><code class="m">0.2</code><code class="p">)</code></pre>

<p>In the function <code>stats.expon.rvs</code>, the order of the arguments is reversed:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">stats</code><code class="o">.</code><code class="n">expon</code><code class="o">.</code><code class="n">rvs</code><code class="p">(</code><code class="mf">0.2</code><code class="p">,</code> <code class="n">size</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code></pre>

<p>This code would generate 100 random numbers from an exponential distribution where the mean number of events per time period is 0.2.
So you could use it to simulate 100 intervals, in minutes, between service calls, where the average rate of incoming calls is 0.2 per minute.</p>

<p>A key assumption in any simulation study for either the Poisson or exponential distribution is that the rate, <math alttext="lamda">
  <mi>λ</mi>
</math>, remains constant over the period being considered.
This is rarely reasonable in a global sense; for example, traffic on roads or data networks varies by time of day and day of week.
However, the time periods, or areas of space, can usually be divided into segments that are sufficiently homogeneous so that analysis or simulation within those periods is valid.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Estimating the Failure Rate"><div class="sect2" id="idm46522861493224">
<h2>Estimating the Failure Rate</h2>

<p>In many applications, the event rate, <math alttext="lamda">
  <mi>λ</mi>
</math>, is known or can be estimated from prior data.<a data-type="indexterm" data-primary="sampling" data-secondary="Poisson and related distributions" data-tertiary="estimating the failure rate" id="idm46522861490728"/><a data-type="indexterm" data-primary="failure rate, estimating" id="idm46522861489496"/>  However, for rare events, this is not necessarily so.
Aircraft engine failure, for example, is sufficiently rare (thankfully) that, for a given engine type, there may be little data on which to base an estimate of time between failures.
With no data at all, there is little basis on which to estimate an event rate.
However, you can make some guesses: if no events have been seen after 20 hours, you can be pretty sure that the rate is not 1 per hour.
Via simulation, or direct calculation of probabilities, you can assess different hypothetical event rates and estimate threshold values below which the rate is very unlikely to fall.
If there is some data but not enough to provide a <span class="keep-together">precise,</span> reliable estimate of the rate, a goodness-of-fit test (see <a data-type="xref" href="ch03.xhtml#chi-square">“Chi-Square Test”</a>) can be applied to various rates to determine how well they fit the observed data.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Weibull Distribution"><div class="sect2" id="idm46522861456376">
<h2>Weibull Distribution</h2>

<p>In many cases, the event rate does not remain constant over time.<a data-type="indexterm" data-primary="Weibull distribution" id="idm46522861454616"/><a data-type="indexterm" data-primary="sampling" data-secondary="Poisson and related distributions" data-tertiary="Weibull distribution" id="idm46522861453912"/>
If the period over which it changes is much longer than the typical interval between events, there is no problem; you just subdivide the analysis into the segments where rates are relatively constant, as mentioned before.
If, however, the event rate changes over the time of the interval, the exponential (or Poisson) distributions are no longer useful.
This is likely to be the case in mechanical failure—the risk of failure increases as time goes by.
The <em>Weibull</em> distribution is an extension of the exponential distribution in which the event rate is allowed to change, as specified by a <em>shape parameter</em>, <math alttext="beta">
  <mi>β</mi>
</math>.
If <math alttext="beta">
  <mi>β</mi>
</math> &gt; 1, the probability of an event increases over time; if <math alttext="beta">
  <mi>β</mi>
</math> &lt; 1, the probability decreases.
Because the Weibull distribution is used with time-to-failure analysis instead of event rate, the second parameter is expressed in terms of  characteristic life, rather than in terms of the rate of events per interval.  The symbol used is <math alttext="eta">
  <mi>η</mi>
</math>, the Greek letter eta.  It is also called the <em>scale</em> parameter.</p>

<p>With the Weibull, the estimation task now includes estimation of both parameters, <math alttext="beta">
  <mi>β</mi>
</math> and <math alttext="eta">
  <mi>η</mi>
</math>.
Software is used to model the data and yield an estimate of the best-fitting Weibull distribution.</p>

<p>The <em>R</em> code to generate random numbers from a Weibull distribution takes three arguments: <code>n</code> (the quantity of numbers to be generated), <code>shape</code>, and <code>scale</code>. For example, the following code would generate 100 random numbers (lifetimes) from a Weibull distribution with shape of 1.5 and characteristic life of 5,000:</p>

<pre data-type="programlisting" data-code-language="r"><code class="nf">rweibull</code><code class="p">(</code><code class="m">100</code><code class="p">,</code> <code class="m">1.5</code><code class="p">,</code> <code class="m">5000</code><code class="p">)</code></pre>

<p>To achieve the same in <em>Python</em>, use the function <code>stats.weibull_min.rvs</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">stats</code><code class="o">.</code><code class="n">weibull_min</code><code class="o">.</code><code class="n">rvs</code><code class="p">(</code><code class="mf">1.5</code><code class="p">,</code> <code class="n">scale</code><code class="o">=</code><code class="mi">5000</code><code class="p">,</code> <code class="n">size</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code></pre>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46522861374792">
<h5>Key Ideas</h5>
<ul>
<li>
<p>For events that occur at a constant rate, the number of events per unit of time or space can be modeled as a Poisson distribution.</p>
</li>
<li>
<p>You can also model the time or distance between one event and the next as an exponential distribution.</p>
</li>
<li>
<p>A changing event rate over time (e.g., an increasing probability of device failure) can be modeled with the Weibull distribution.</p>
</li>
</ul>
</div></aside>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Further Reading"><div class="sect2" id="idm46522861371304">
<h2>Further Reading</h2>

<ul>
<li>
<p><em>Modern Engineering Statistics</em> by Thomas Ryan (Wiley, 2007) has a chapter devoted to the probability distributions used in engineering applications.</p>
</li>
<li>
<p>Read an engineering-based perspective on the use of the Weibull distribution <a href="https://oreil.ly/1x-ga">here</a> and <a href="https://oreil.ly/9bn-U">here</a>.<a data-type="indexterm" data-primary="sampling" data-secondary="Poisson and related distributions" data-startref="ix_smplPoi" id="idm46522861366680"/></p>
</li>
</ul>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="idm46522861364920">
<h1>Summary</h1>

<p>In the era of big data, the principles of random sampling remain important when accurate estimates are needed.
Random selection of data can reduce bias and yield a higher quality data set than would result from just using the conveniently available data.
Knowledge of various sampling and data-generating distributions allows us to quantify potential errors in an estimate that might be due to random variation.
At the same time, the bootstrap (sampling with replacement from an observed data set) is an attractive “one size fits all” method to determine possible error in sample estimates.<a data-type="indexterm" data-primary="sampling" data-startref="ix_smpl" id="idm46522861363016"/></p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm46522862237288"><sup><a href="ch02.xhtml#idm46522862237288-marker">1</a></sup> The bell curve is iconic but perhaps overrated. George W. Cobb, the Mount Holyoke statistician noted for his contribution to the philosophy of teaching introductory statistics, argued in a November 2015 editorial in the <em>American Statistician</em> that the “standard introductory course, which puts the normal distribution at its center, had outlived the usefulness of its centrality.”</p></div></div></section></div>



  </body></html>