- en: Chapter 11\. Managing the Machine Learning Lifecycle with MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As machine learning gains prominence across industries and is deployed in production
    environments, the level of collaboration and complexity surrounding it has increased
    as well. Thankfully, platforms and tools have cropped up to help manage the machine
    learning lifecycle in a structured manner. One such platform that works well with
    PySpark is MLflow. In this chapter, we will show how MLflow can be used with PySpark.
    Along the way, we’ll introduce key practices that you can incorporate in your
    data science workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than starting from scratch, we’ll build upon the work that we did in
    [Chapter 4](ch04.xhtml#making_predictions_with_decision_trees_and_decision_forests).
    We will revisit our decision tree implementation using the Covtype dataset. Only
    this time, we’ll use MLflow for managing the machine learning lifecycle.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start by explaining the challenges and processes that encompass the machine
    learning lifecycle. We will then introduce MLflow and its components, as well
    as cover MLflow’s support for PySpark. This will be followed by an introduction
    to tracking machine learning training runs using MLflow. We’ll then learn how
    to manage machine learning models using MLflow Models. Then we’ll discuss deployment
    of our PySpark model and do an implementation for it. We’ll end the chapter by
    creating an MLflow Project. This will show how we can make our work so far reproducible
    for collaborators. Let’s get started by discussing the machine learning lifecycle.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning Lifecycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are multiple ways to describe the machine learning lifecycle. One simple
    way is to break it down into various components or steps, as shown in [Figure 11-1](#ml_lifecycle).
    These steps may not necessarily be in sequence for every project, and the lifecycle
    is cyclic more often than not.
  prefs: []
  type: TYPE_NORMAL
- en: Business project definition and stakeholder alignment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data acquisition and exploration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpretation and communication of results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model implementation and deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![machine learning lifecycle](assets/machine_learning_lifecycle.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-1\. ML lifecycle
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The speed at which you can iterate through the ML lifecycle affects how fast
    you can put your work to practical use. For example, an implemented model can
    become outdated due to a change in underlying data. In that case, you will need
    to revisit past work and build upon it again.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples of challenges that can show up during a machine learning project’s
    lifecycle are:'
  prefs: []
  type: TYPE_NORMAL
- en: Lack of reproducibility
  prefs: []
  type: TYPE_NORMAL
- en: Data scientists on the same team may not be able to reproduce each other’s results
    even if the code and parameters have been tracked. This can be a result of the
    execution environment (system configuration or library dependencies) being different.
  prefs: []
  type: TYPE_NORMAL
- en: Lack of standardization of models
  prefs: []
  type: TYPE_NORMAL
- en: Different teams may use different libraries and different conventions for storing
    machine learning models. This can become a problem when sharing work across teams.
  prefs: []
  type: TYPE_NORMAL
- en: Trying to structure your work while going through the ML lifecycle can quickly
    become overwhelming. In light of such challenges, multiple open source and proprietary
    platforms are available to help. One leading open source platform is MLflow, which
    we will introduce in the upcoming section.
  prefs: []
  type: TYPE_NORMAL
- en: MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MLflow is an open source platform for managing the end-to-end machine learning
    lifecycle. It helps us reproduce and share experiments, manage models, and deploy
    models for end users. In addition to a REST API and CLI, it also provides APIs
    for Python, R, and Java/Scala.
  prefs: []
  type: TYPE_NORMAL
- en: 'It has four main components, as shown in [Figure 11-2](#mlflow_components):'
  prefs: []
  type: TYPE_NORMAL
- en: MLflow Tracking
  prefs: []
  type: TYPE_NORMAL
- en: This component records parameters, metrics, code versions, models, and artifacts
    such as plots and text.
  prefs: []
  type: TYPE_NORMAL
- en: MLflow Projects
  prefs: []
  type: TYPE_NORMAL
- en: This component provides you with a reusable, reproducible format to share with
    other data scientists or transfer to production. It helps you manage the model
    training process.
  prefs: []
  type: TYPE_NORMAL
- en: MLflow Models
  prefs: []
  type: TYPE_NORMAL
- en: This component enables you to package models to deploy to a variety of model
    serving and inference platforms. It provides a consistent API for loading and
    applying models, regardless of the underlying library used to build the model.
  prefs: []
  type: TYPE_NORMAL
- en: MLflow Registry
  prefs: []
  type: TYPE_NORMAL
- en: This component enables you to collaboratively keep track of model lineage, model
    versions, stage transitions, and annotations in a central store.
  prefs: []
  type: TYPE_NORMAL
- en: '![MLflow components](assets/aaps_1102.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-2\. MLflow components
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s install MLflow. It’s straightforward to do so using pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: That’s it!
  prefs: []
  type: TYPE_NORMAL
- en: MLflow integrates with many popular machine learning frameworks such as Spark,
    TensorFlow, PyTorch, and others. We will be using its native support for Spark
    over the next few sections. Importing the Spark-specific MLflow component is as
    easy as running `import mlflow.spark`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll introduce MLflow Tracking and add it to our decision
    tree code from [Chapter 4](ch04.xhtml#making_predictions_with_decision_trees_and_decision_forests).
  prefs: []
  type: TYPE_NORMAL
- en: Experiment Tracking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A typical machine learning project involves experimenting with several algorithms
    and models to solve a problem. The associated datasets, hyperparameters, and metrics
    need to be tracked. Typically, experiment tracking is done using makeshift tools
    such as spreadsheets and can be inefficient or, worse, unreliable.
  prefs: []
  type: TYPE_NORMAL
- en: MLflow Tracking is an API and UI for logging parameters, code versions, metrics,
    and artifacts when running your machine learning code and for later visualizing
    the results. You can use MLflow Tracking in any environment (for example, a standalone
    script or a notebook) to log results to local files or to a server and then compare
    multiple runs. It is library-agnostic and integrates with multiple frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: 'MLflow Tracking is organized around the concept of *runs*, which are executions
    of some piece of data science code. MLflow Tracking provides a UI that lets you
    visualize, search, and compare runs, as well as download run artifacts or metadata
    for analysis in other tools. It contains the following key features:'
  prefs: []
  type: TYPE_NORMAL
- en: Experiment-based run listing and comparison
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Searching for runs by parameter or metric value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing run metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Downloading run results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s add MLflow Tracking to our decision tree code in the PySpark shell. It’s
    assumed that you have downloaded the [Covtype dataset](https://oreil.ly/0xyky)
    and are familiar with it. The Covtype dataset is available online as a compressed
    CSV-format data file, *covtype.data.gz*, and accompanying info file, *covtype.info*.
  prefs: []
  type: TYPE_NORMAL
- en: Start `pyspark-shell`. As mentioned previously, building decision trees can
    be resource intensive. If you have the memory, specify `--driver-memory 8g` or
    similar.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by preparing the data and machine learning pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To start logging with MLflow, we start a run using `mlflow.start_run`. We will
    use a `with` clause to automatically end the run at the end of the block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We can now access our experiment data via the tracking UI. Start it by running
    the `mlflow ui` command. By default it starts on port 5000\. You can use the `-p
    <port_name>` option to change the default port. Once you have successfully started
    the UI, go to *[*http://localhost:5000/*](http://localhost:5000/)*. You will see
    a UI as shown in [Figure 11-3](#mlflow_ui). You can search across all the runs,
    filter for those that meet particular criteria, compare runs side by side, etc.
    If you wish, you can also export the contents as a CSV file to analyze locally.
    Click the run in the UI named `decision-tree`.
  prefs: []
  type: TYPE_NORMAL
- en: '![MLflow UI 1](assets/aaps_1103.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-3\. MLflow UI 1
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When viewing an individual run, as shown in [Figure 11-4](#mlflow_ui_2), you’ll
    notice that MLflow stores all the corresponding parameters, metrics, etc. You
    can add notes about this run in free text, as well as tags.
  prefs: []
  type: TYPE_NORMAL
- en: '![MLflow UI 2](assets/aaps_1104.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-4\. MLflow UI 2
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We are now able to track and reproduce our experiments. Let’s now discuss managing
    our models using MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: Managing and Serving ML Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An MLflow Model is a standard format for packaging machine learning models that
    can be used in a variety of downstream tools—for example, real-time serving through
    a REST API or batch inference on Apache Spark. The format defines a convention
    that lets you save a model in different “flavors” that can be understood by different
    libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Flavors are the key concept that makes MLflow Models powerful. They make it
    possible to write tools that work with models from any ML library without having
    to integrate each tool with each library. MLflow defines several “standard” flavors
    that all of its built-in deployment tools support, such as a “Python function”
    flavor that describes how to run the model as a Python function. However, libraries
    can also define and use other flavors. For example, MLflow’s `mlflow.sklearn`
    library allows loading models back as a scikit-learn `Pipeline` object for use
    in code that is aware of scikit-learn, or as a generic Python function for use
    in tools that just need to apply the model (for example, the `mlflow.sagemaker`
    tool for deploying models to Amazon SageMaker).
  prefs: []
  type: TYPE_NORMAL
- en: An MLflow Model is a directory containing a set of files. We had earlier logged
    our model using the `log_model` API. This created a file called *MLmodel*. Open
    the decision-tree run and scroll down to the “Artifacts” section. Check out the
    *MLmodel* file. Its contents should be similar to what’s depicted in [Figure 11-5](#mlflow_model).
  prefs: []
  type: TYPE_NORMAL
- en: '![MLflow Model](assets/aaps_1105.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-5\. MLflow Model
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The file captures our model’s metadata, signature, and flavors. The Model signature
    defines the schema of a model’s inputs and outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our model file has two flavors: python_function and spark. The python_function
    flavor enables MLflow’s model deployment and serving tools to work with any Python
    model regardless of which ML library trained the model. As a result, any Python
    model can be easily productionalized in a variety of runtime environments.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The spark model flavor enables exporting Spark MLlib models as MLflow Models.
    For example, to make predictions on a Spark DataFrame using the logged model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: This ID can be obtained from the tracking UI in the relevant *MLmodel* file.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: We use Python f-strings for adding the relevant run ID.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use the `mlflow serve` command-line tool to serve the model corresponding
    to a particular run ID.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: You have successfully deployed your model as a REST API!
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now use this endpoint to perform inference. Let’s prepare and send a
    request to the endpoint to see it in action. We’ll use the `requests` library
    to do this. Install it using pip first if you don’t yet have it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now we’ll send a request containing a JSON object in a pandas-split orientation
    to the model server.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We not only loaded a saved model but also deployed it as a REST API and performed
    inference in real time!
  prefs: []
  type: TYPE_NORMAL
- en: Let us now learn how to create an MLflow Project for the work we have done so
    far.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and Using MLflow Projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MLflow Projects is a standard format for reusable and reproducible packaging.
    It’s a self-contained unit that bundles all the machine code and dependencies
    required to execute a machine learning workflow and enables you to produce a particular
    model run on any system or environment. MLflow Projects includes an API and command-line
    tools for running projects. It can also be used to chain projects together into
    workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Each project is simply a directory of files, or a Git repository, containing
    your code. MLflow can run some projects based on a convention for placing files
    in this directory (for example, a *conda.yml* file is treated as a Conda environment),
    but you can describe your project in more detail by adding an MLproject file,
    which is a YAML-formatted text file.
  prefs: []
  type: TYPE_NORMAL
- en: 'MLflow currently supports the following project environments: Conda environment,
    Docker container environment, and system environment. By default, MLflow uses
    the system path to find and run the Conda binary.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a basic MLflow project is straightforward. The required steps are listed
    in [Figure 11-6](#how_to_build_an_mflow_project).
  prefs: []
  type: TYPE_NORMAL
- en: '![How to build an MLflow Project](assets/aaps_1106.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-6\. How to build an MLflow Project
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We will start by creating our project directory named *decision_tree_project*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we’ll first create an MLproject file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We now need our *conda.yml* file. We can get this from the MLflow UI introduced
    in a previous section. Go inside the decision-tree run that we previously saw.
    Scroll down to the Artifacts, click the conda YAML file, and copy its contents
    into *conda.yml* in our project directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now create the Python script that will be used to train a decision
    tree model upon the MLflow project being executed. For this, we’ll use the code
    from a previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_managing_the_machine_learning___span_class__keep_together__lifecycle_with_mlflow__span__CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Data is assumed to be one directory level above the MLflow project directory
    being executed.
  prefs: []
  type: TYPE_NORMAL
- en: Data can also be included inside an MLflow project. In this case, we don’t do
    so because of the large size. In such a case, data can be shared using cloud storage
    such as AWS S3 or GCS.
  prefs: []
  type: TYPE_NORMAL
- en: You can simulate how it will work for a collaborator locally before sharing,
    too. We do that using the `mlflow run` command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We now have a reproducible MLflow project. We can upload it to a GitHub repository
    and share it with a collaborator who will be able to reproduce our work.
  prefs: []
  type: TYPE_NORMAL
- en: Where to Go from Here
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduced the MLflow project and guided you through its implementation
    for a straightforward project. There is a lot to explore within the MLflow project
    itself. You can find more information in the [official docs](https://mlflow.org).
    There are other tools out there that can serve as alternatives as well. These
    include open source projects, such as Metaflow and Kubeflow, as well as proprietary
    offerings by big cloud providers including Amazon SageMaker and the Databricks
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, tools are only part of the solution to the challenges that a real-world
    machine learning project offers. Processes need to be defined by the people working
    on any project. We hope that you will build upon the foundations offered in this
    chapter and contribute to successful machine learning projects in the wild.
  prefs: []
  type: TYPE_NORMAL
