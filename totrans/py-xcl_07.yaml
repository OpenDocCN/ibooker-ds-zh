- en: Chapter 5\. Data Analysis with pandas
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will introduce you to pandas, the Python Data Analysis Library
    or—how I like to put it—the Python-based spreadsheet with superpowers. It’s so
    powerful that some of the companies that I worked with have managed to get rid
    of Excel completely by replacing it with a combination of Jupyter notebooks and
    pandas. As a reader of this book, however, I assume you will keep Excel, in which
    case pandas will serve as an interface for getting data in and out of spreadsheets.
    pandas makes tasks that are particularly painful in Excel easier, faster, and
    less error-prone. Some of these tasks include getting big datasets from external
    sources and working with statistics, time series, and interactive charts. pandas’
    most important superpowers are vectorization and data alignment. As we’ve already
    seen in the previous chapter with NumPy arrays, vectorization allows you to write
    concise, array-based code while data alignment makes sure that there is no data
    mismatch when you work with multiple datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the whole data analysis journey: it starts with cleaning
    and preparing data before it shows you how to make sense out of bigger datasets
    via aggregation, descriptive statistics, and visualization. At the end of the
    chapter, we’ll see how we can import and export data with pandas. But first things
    first—let’s get started with an introduction to pandas’ main data structures:
    DataFrame and Series!'
  prefs: []
  type: TYPE_NORMAL
- en: DataFrame and Series
  prefs: []
  type: TYPE_NORMAL
- en: 'DataFrame and Series are the core data structures in pandas. In this section,
    I am introducing them with a focus on the main components of a DataFrame: index,
    columns, and data. A DataFrame is similar to a two-dimensional NumPy array, but
    it comes with column and row labels and each column can hold different data types.
    By extracting a single column or row from a DataFrame, you get a one-dimensional
    Series. Again, a Series is similar to a one-dimensional NumPy array with labels.
    When you look at the structure of a DataFrame in [Figure 5-1](#filepos485286),
    it won’t take a lot of imagination to see that DataFrames are going to be your
    Python-based spreadsheets.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/00069.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-1\. A pandas Series and DataFrame
  prefs: []
  type: TYPE_NORMAL
- en: To show you how easy it is to transition from a spreadsheet to a DataFrame,
    consider the following Excel table in [Figure 5-2](#filepos485969), which shows
    participants of an online course with their score. You will find the corresponding
    file course_participants.xlsx in the xl folder of the companion repo.
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/00077.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-2\. course_participants.xlsx
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this Excel table available in Python, start by importing pandas, then
    use its `read_excel` function, which returns a DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``1``]:``import``pandas``as``pd`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``2``]:``pd``.``read_excel``(``"xl/course_participants.xlsx"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[2]:    user_id   name  age  country  score continent         0     1001  
    Mark   55    Italy    4.5    Europe         1     1000   John   33      USA   
    6.7   America         2     1002    Tim   41      USA    3.9   America        
    3     1003  Jenny   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: THE READ_EXCEL FUNCTION WITH PYTHON 3.9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you are running `pd.read_excel` with Python 3.9 or above, make sure to use
    at least pandas 1.2 or you will get an error when reading xlsx files.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you run this in a Jupyter notebook, the DataFrame will be nicely formatted
    as an HTML table, which makes it even closer to how the table looks in Excel.
    I will spend the whole of [Chapter 7](index_split_019.html#filepos863345) on reading
    and writing Excel files with pandas, so this was only an introductory example
    to show you that spreadsheets and DataFrames are, indeed, very similar. Let’s
    now re-create this DataFrame from scratch without reading it from the Excel file:
    one way of creating a DataFrame is to provide the data as a nested list, along
    with values for `columns` and `index`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``3``]:``data``=``[[``"Mark"``,``55``,``"Italy"``,``4.5``,``"Europe"``],``[``"John"``,``33``,``"USA"``,``6.7``,``"America"``],``[``"Tim"``,``41``,``"USA"``,``3.9``,``"America"``],``[``"Jenny"``,``12``,``"Germany"``,``9.0``,``"Europe"``]]``df``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"name"``,``"age"``,``"country"``,``"score"``,``"continent"``],``index``=``[``1001``,``1000``,``1002``,``1003``])``df`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[3]:        name  age  country  score continent         1001   Mark   55   
    Italy    4.5    Europe         1000   John   33      USA    6.7   America        
    1002    Tim   41      USA    3.9   America         1003  Jenny   12  Germany   
    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'By calling the `info` method, you will get some basic information, most importantly
    the number of data points and the data types for each column:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``4``]:``df``.``info``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`<class ''pandas.core.frame.DataFrame''> Int64Index: 4 entries, 1001 to 1003
    Data columns (total 5 columns): #   Column     Non-Null Count  Dtype ---  ------    
    --------------  ----- 0   name       4 non-null      object 1   age        4 non-null     
    int64 2   country    4 non-null      object 3   score      4 non-null      float64
    4   continent  4 non-null      object dtypes: float64(1), int64(1), object(3)
    memory usage: 192.0+ bytes`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you are just interested in the data type of your columns, run `df.dtypes`
    instead. Columns with strings or mixed data types will have the data type `object`.
    [1](index_split_016.html#filepos767133) Let us now have a closer look at the index
    and columns of a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Index
  prefs: []
  type: TYPE_NORMAL
- en: 'The row labels of a DataFrame are called index. If you don’t have a meaningful
    index, leave it away when constructing a DataFrame. pandas will then automatically
    create an integer index starting at zero. We saw this in the very first example
    when we read the DataFrame from the Excel file. An index will allow pandas to
    look up data faster and is essential for many common operations, e.g., combining
    two DataFrames. You access the index object like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``5``]:``df``.``index`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[5]: Int64Index([1001, 1000, 1002, 1003], dtype=''int64'')`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If it makes sense, give the index a name. Let’s follow the table in Excel,
    and give it the name `user_id`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``6``]:``df``.``index``.``name``=``"user_id"``df`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[6]:           name  age  country  score continent         user_id        
    1001      Mark   55    Italy    4.5    Europe         1000      John   33     
    USA    6.7   America         1002       Tim   41      USA    3.9   America        
    1003     Jenny   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Unlike the primary key of a database, a DataFrame index can have duplicates,
    but looking up values may be slower in that case. To turn an index into a regular
    column use `reset_index`, and to set a new index use `set_index`. If you don’t
    want to lose your existing index when setting a new one, make sure to reset it
    first:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``7``]:``# "reset_index" turns the index into a column, replacing the``#
    index with the default index. This corresponds to the DataFrame``# from the beginning
    that we loaded from Excel.``df``.``reset_index``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[7]:    user_id   name  age  country  score continent         0     1001  
    Mark   55    Italy    4.5    Europe         1     1000   John   33      USA   
    6.7   America         2     1002    Tim   41      USA    3.9   America        
    3     1003  Jenny   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``8``]:``# "reset_index" turns "user_id" into a regular column and``#
    "set_index" turns the column "name" into the index``df``.``reset_index``()``.``set_index``(``"name"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[8]:        user_id  age  country  score continent         name        
    Mark      1001   55    Italy    4.5    Europe         John      1000   33     
    USA    6.7   America         Tim       1002   41      USA    3.9   America        
    Jenny     1003   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'By doing `df.reset_index().set_index("name")`, you are using method chaining:
    since `reset_index()` returns a DataFrame, you can directly call another DataFrame
    method without having to write out the intermediate result first.'
  prefs: []
  type: TYPE_NORMAL
- en: DATAFRAME METHODS RETURN COPIES
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Whenever you call a method on a DataFrame in the form `df.method_name()`, you
    will get back a copy of the DataFrame with that method applied, leaving the original
    DataFrame untouched. We have just done that by calling `df.reset_index()`. If
    you wanted to change the original DataFrame, you would have to assign the return
    value back to the original variable like the following:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df = df.reset_index()`'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Since we are not doing this, it means that our variable `df` is still holding
    its original data. The next samples also call DataFrame methods, i.e., don’t change
    the original DataFrame.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To change the index, use the `reindex` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``9``]:``df``.``reindex``([``999``,``1000``,``1001``,``1004``])`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[9]:          name   age country  score continent         user_id        
    999       NaN   NaN     NaN    NaN       NaN         1000     John  33.0     USA   
    6.7   America         1001     Mark  55.0   Italy    4.5    Europe         1004     
    NaN   NaN     NaN    NaN       NaN`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is a first example of data alignment at work: `reindex` will take over
    all rows that match the new index and will introduce rows with missing values
    (`NaN`) where no information exists. Index elements that you leave away will be
    dropped. I will introduce `NaN` properly a bit later in this chapter. Finally,
    to sort an index, use the `sort_index` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``10``]:``df``.``sort_index``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[10]:           name  age  country  score continent          user_id         
    1000      John   33      USA    6.7   America          1001      Mark   55   
    Italy    4.5    Europe          1002       Tim   41      USA    3.9   America
             1003     Jenny   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If, instead, you want to sort the rows by one or more columns, use `sort_values`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``11``]:``df``.``sort_values``([``"continent"``,``"age"``])`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[11]:           name  age  country  score continent          user_id         
    1000      John   33      USA    6.7   America          1002       Tim   41     
    USA    3.9   America          1003     Jenny   12  Germany    9.0    Europe         
    1001      Mark   55    Italy    4.5    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The sample shows how to sort first by `continent`, then by `age`. If you wanted
    to sort by only one column, you could also provide the column name as a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '`df.sort_values("continent")`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This has covered the basics of how indices work. Let’s now turn our attention
    to its horizontal equivalent, the DataFrame columns!
  prefs: []
  type: TYPE_NORMAL
- en: Columns
  prefs: []
  type: TYPE_NORMAL
- en: 'To get information about the columns of a DataFrame, run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``12``]:``df``.``columns`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[12]: Index([''name'', ''age'', ''country'', ''score'', ''continent''],
    dtype=''object'')`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you don’t provide any column names when constructing a DataFrame, pandas
    will number the columns with integers starting at zero. With columns, however,
    this is almost never a good idea as columns represent variables and are therefore
    easy to name. You assign a name to the column headers in the same way we did it
    with the index:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``13``]:``df``.``columns``.``name``=``"properties"``df`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[13]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1000        
    John   33      USA    6.7   America          1002          Tim   41      USA   
    3.9   America          1003        Jenny   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you don’t like the column names, rename them:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``14``]:``df``.``rename``(``columns``=``{``"name"``:``"First Name"``,``"age"``:``"Age"``})`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[14]: properties First Name  Age  country  score continent          user_id
             1001             Mark   55    Italy    4.5    Europe          1000            
    John   33      USA    6.7   America          1002              Tim   41      USA   
    3.9   America          1003            Jenny   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you want to delete columns, use the following syntax (the sample shows you
    how to drop columns and indices at the same time):'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``15``]:``df``.``drop``(``columns``=``[``"name"``,``"country"``],``index``=``[``1000``,``1003``])`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[15]: properties  age  score continent          user_id          1001        
    55    4.5    Europe          1002         41    3.9   America`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The columns and the index of a DataFrame are both represented by an `Index`
    object, so you can change your columns into rows and vice versa by transposing
    your DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``16``]:``df``.``T``# Shortcut for df.transpose()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[16]: user_id       1001     1000     1002     1003          properties
             name          Mark     John      Tim    Jenny          age            
    55       33       41       12          country      Italy      USA      USA  Germany
             score          4.5      6.7      3.9        9          continent   Europe 
    America  America   Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It’s worth remembering here that our DataFrame `df` is still unchanged, as
    we have never reassigned the returning DataFrame from the method calls back to
    the original `df` variable. If you would like to reorder the columns of a DataFrame,
    you could use the `reindex` method that we used with the index, but selecting
    the columns in the desired order is often more intuitive:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``17``]:``df``.``loc``[:,``[``"continent"``,``"country"``,``"name"``,``"age"``,``"score"``]]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[17]: properties continent  country   name  age  score          user_id
             1001          Europe    Italy   Mark   55    4.5          1000        
    America      USA   John   33    6.7          1002         America      USA   
    Tim   41    3.9          1003          Europe  Germany  Jenny   12    9.0`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This last example needs quite a few explanations: everything about `loc` and
    how data selection works is the topic of the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Data Manipulation
  prefs: []
  type: TYPE_NORMAL
- en: Real-world data hardly gets served on a silver platter, so before working with
    it, you need to clean it and bring it into a digestible form. We’ll begin this
    section by looking at how to select data from a DataFrame, how to change it, and
    how to deal with missing and duplicate data. We’ll then perform a few calculations
    with DataFrames and see how you work with text data. To wrap this section up,
    we’ll find out when pandas returns a view vs. a copy of the data. Quite a few
    concepts in this section are related to what we have already seen with NumPy arrays
    in the last chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting Data
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with accessing data by label and position before looking at other
    methods, including boolean indexing and selecting data by using a MultiIndex.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting by label
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common way of accessing the data of a DataFrame is by referring to
    its labels. Use the attribute `loc`, which stands for location, to specify which
    rows and columns you want to retrieve:'
  prefs: []
  type: TYPE_NORMAL
- en: '`df``.``loc``[``row_selection``,``column_selection``]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`loc` supports the slice notation and therefore accepts a colon to select all
    rows or columns, respectively. Additionally, you can provide lists with labels
    as well as a single column or row name. Have a look at [Table 5-1](#filepos526726)
    to see a few examples of how you select different parts from our sample DataFrame
    `df`.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-1\. Data selection by label
  prefs: []
  type: TYPE_NORMAL
- en: '|  Selection  |  Return Data Type  |  Example  |'
  prefs: []
  type: TYPE_TB
- en: '|  Single value  |  Scalar  |   `df.loc[1000, "country"]` |'
  prefs: []
  type: TYPE_TB
- en: '|  One column (1d)  |  Series  |   `df.loc[:, "country"]` |'
  prefs: []
  type: TYPE_TB
- en: '|  One column (2d)  |  DataFrame  |   `df.loc[:, ["country"]]` |'
  prefs: []
  type: TYPE_TB
- en: '|  Multiple columns  |  DataFrame  |   `df.loc[:, ["country", "age"]]` |'
  prefs: []
  type: TYPE_TB
- en: '|  Range of columns  |  DataFrame  |   `df.loc[:, "name":"country"]` |'
  prefs: []
  type: TYPE_TB
- en: '|  One row (1d)  |  Series  |   `df.loc[1000, :]` |'
  prefs: []
  type: TYPE_TB
- en: '|  One row (2d)  |  DataFrame  |   `df.loc[[1000], :]` |'
  prefs: []
  type: TYPE_TB
- en: '|  Multiple rows  |  DataFrame  |   `df.loc[[1003, 1000], :]` |'
  prefs: []
  type: TYPE_TB
- en: '|  Range of rows  |  DataFrame  |   `df.loc[1000:1002, :]` |'
  prefs: []
  type: TYPE_TB
- en: LABEL SLICING HAS CLOSED INTERVALS
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Using slice notation with labels is inconsistent with respect to how everything
    else in Python and pandas works: they include the upper end.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Applying our knowledge from [Table 5-1](#filepos526726), let’s use `loc` to
    select scalars, Series, and DataFrames:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``18``]:``# Using scalars for both row and column selection returns a
    scalar``df``.``loc``[``1001``,``"name"``]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[18]: ''Mark''`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``19``]:``# Using a scalar on either the row or column selection returns
    a Series``df``.``loc``[[``1001``,``1002``],``"age"``]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[19]: user_id          1001    55          1002    41          Name: age,
    dtype: int64`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``20``]:``# Selecting multiple rows and columns returns a DataFrame``df``.``loc``[:``1002``,``[``"name"``,``"country"``]]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[20]: properties  name country          user_id          1001        Mark  
    Italy          1000        John     USA          1002         Tim     USA`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It’s important for you to understand the difference between a DataFrame with
    one or more columns and a Series: even with a single column, DataFrames are two-dimensional,
    while Series are one-dimensional. Both DataFrame and Series have an index, but
    only the DataFrame has column headers. When you select a column as Series, the
    column header becomes the name of the Series. Many functions or methods will work
    on both Series and DataFrame, but when you perform arithmetic calculations, the
    behavior differs: with DataFrames, pandas aligns the data according to the column
    headers—more about that a little later in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: SHORTCUT FOR COLUMN SELECTION
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Since selecting columns is such a common operation, pandas offers a shortcut.
    Instead of:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df``.``loc``[:,``column_selection``]`'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'you can write:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df``[``column_selection``]`'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: For example, `df["country"]` returns a Series from our sample DataFrame and
    `df[["name", "country"]]` returns a DataFrame with two columns.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Selecting by position
  prefs: []
  type: TYPE_NORMAL
- en: 'Selecting a subset of a DataFrame by position corresponds to what we did at
    the beginning of this chapter with NumPy arrays. With DataFrames, however, you
    have to use the `iloc` attribute, which stands for integer location:'
  prefs: []
  type: TYPE_NORMAL
- en: '`df``.``iloc``[``row_selection``,``column_selection``]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When using slices, you deal with the standard half-open intervals. [Table 5-2](#filepos540243)
    gives you the same cases we looked at previously in [Table 5-1](#filepos526726).
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-2\. Data selection by position
  prefs: []
  type: TYPE_NORMAL
- en: '|  Selection  |  Return Data Type  |  Example  |'
  prefs: []
  type: TYPE_TB
- en: '|  Single value  |  Scalar  |   `df.iloc[1, 2]` |'
  prefs: []
  type: TYPE_TB
- en: '|  One column (1d)  |  Series  |   `df.iloc[:, 2]` |'
  prefs: []
  type: TYPE_TB
- en: '|  One column (2d)  |  DataFrame  |   `df.iloc[:, [2]]` |'
  prefs: []
  type: TYPE_TB
- en: '|  Multiple columns  |  DataFrame  |   `df.iloc[:, [2, 1]]` |'
  prefs: []
  type: TYPE_TB
- en: '|  Range of columns  |  DataFrame  |   `df.iloc[:, :3]` |'
  prefs: []
  type: TYPE_TB
- en: '|  One row (1d)  |  Series  |   `df.iloc[1, :]` |'
  prefs: []
  type: TYPE_TB
- en: '|  One row (2d)  |  DataFrame  |   `df.iloc[[1], :]` |'
  prefs: []
  type: TYPE_TB
- en: '|  Multiple rows  |  DataFrame  |   `df.iloc[[3, 1], :]` |'
  prefs: []
  type: TYPE_TB
- en: '|  Range of rows  |  DataFrame  |   `df.iloc[1:3, :]` |'
  prefs: []
  type: TYPE_TB
- en: 'Here is how you use `iloc`—again with the same samples that we used with `loc`
    before:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``21``]:``df``.``iloc``[``0``,``0``]``# Returns a Scalar`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[21]: ''Mark''`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``22``]:``df``.``iloc``[[``0``,``2``],``1``]``# Returns a Series`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[22]: user_id          1001    55          1002    41          Name: age,
    dtype: int64`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``23``]:``df``.``iloc``[:``3``,``[``0``,``2``]]``# Returns a DataFrame`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[23]: properties  name country          user_id          1001        Mark  
    Italy          1000        John     USA          1002         Tim     USA`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Selecting data by label or position is not the only means to access a subset
    of your DataFrame. Another important way is to use boolean indexing; let’s see
    how it works!
  prefs: []
  type: TYPE_NORMAL
- en: Selecting by boolean indexing
  prefs: []
  type: TYPE_NORMAL
- en: 'Boolean indexing refers to selecting subsets of a DataFrame with the help of
    a Series or a DataFrame whose data consists of only `True` or `False`. Boolean
    Series are used to select specific columns and rows of a DataFrame, while boolean
    DataFrames are used to select specific values across a whole DataFrame. Most commonly,
    you will use boolean indexing to filter the rows of a DataFrame. Think of it as
    the AutoFilter functionality in Excel. For example, this is how you filter your
    DataFrame so it only shows people who live in the USA and are older than 40 years:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``24``]:``tf``=``(``df``[``"age"``]``>``40``)``&``(``df``[``"country"``]``==``"USA"``)``tf``#
    This is a Series with only True/False`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[24]: user_id          1001    False          1000    False          1002    
    True          1003    False          dtype: bool`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``25``]:``df``.``loc``[``tf``,``:]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[25]: properties name  age country  score continent          user_id         
    1002        Tim   41     USA    3.9   America`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There are two things I need to explain here. First, due to technical limitations,
    you can’t use Python’s boolean operators from [Chapter 3](index_split_010.html#filepos178328)
    with DataFrames. Instead, you need to use the symbols as shown in [Table 5-3](#filepos554254).
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-3\. Boolean operators
  prefs: []
  type: TYPE_NORMAL
- en: '|  Basic Python Data Types  |  DataFrames and Series  |'
  prefs: []
  type: TYPE_TB
- en: '|   `and` |   `&` |'
  prefs: []
  type: TYPE_TB
- en: '|   `or` |   `&#124;` |'
  prefs: []
  type: TYPE_TB
- en: '|   `not` |   `~` |'
  prefs: []
  type: TYPE_TB
- en: 'Second, if you have more than one condition, make sure to put every boolean
    expression in between parentheses so operator precedence doesn’t get in your way:
    for example, `&` has higher operator precedence than `==`. Therefore, without
    parentheses, the expression from the sample would be interpreted as:'
  prefs: []
  type: TYPE_NORMAL
- en: '`df``[``"age"``]``>``(``40``&``df``[``"country"``])``==``"USA"`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you want to filter the index, you can refer to it as `df.index`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``26``]:``df``.``loc``[``df``.``index``>``1001``,``:]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[26]: properties   name  age  country  score continent          user_id
             1002          Tim   41      USA    3.9   America          1003       
    Jenny   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'For what you would use the `in` operator with basic Python data structures
    like lists, use `isin` with a Series. This is how you filter your DataFrame to
    participants from Italy and Germany:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``27``]:``df``.``loc``[``df``[``"country"``]``.``isin``([``"Italy"``,``"Germany"``]),``:]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[27]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1003       
    Jenny   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'While you use `loc` to provide a boolean Series, DataFrames offer a special
    syntax without `loc` to select values given the full DataFrame of booleans:'
  prefs: []
  type: TYPE_NORMAL
- en: '`df``[``boolean_df``]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is especially helpful if you have DataFrames that consist of only numbers.
    Providing a DataFrame of booleans returns the DataFrame with `NaN` wherever the
    boolean DataFrame is `False`. Again, a more detailed discussion of `NaN` will
    follow shortly. Let’s start by creating a new sample DataFrame called `rainfall`
    that consists of only numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``28``]:``# This could be the yearly rainfall in millimeters``rainfall``=``pd``.``DataFrame``(``data``=``{``"City
    1"``:``[``300.1``,``100.2``],``"City 2"``:``[``400.3``,``300.4``],``"City 3"``:``[``1000.5``,``1100.6``]})``rainfall`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[28]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``29``]:``rainfall``<``400`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[29]:    City 1  City 2  City 3          0    True   False   False         
    1    True    True   False`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``30``]:``rainfall``[``rainfall``<``400``]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[30]:    City 1  City 2  City 3          0   300.1     NaN     NaN         
    1   100.2   300.4     NaN`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note that in this example, I have used a dictionary to construct a new DataFrame—this
    is often convenient if the data already exists in that form. Working with booleans
    in this way is most commonly used to filter out specific values such as outliers.
  prefs: []
  type: TYPE_NORMAL
- en: To wrap up the data selection part, I will introduce a special type of index
    called the MultiIndex.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting by using a MultiIndex
  prefs: []
  type: TYPE_NORMAL
- en: 'A MultiIndex is an index with more than one level. It allows you to hierarchically
    group your data and gives you easy access to subsets. For example, if you set
    the index of our sample DataFrame `df` to a combination of `continent` and `country`,
    you can easily select all rows with a certain continent:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``31``]:``# A MultiIndex needs to be sorted``df_multi``=``df``.``reset_index``()``.``set_index``([``"continent"``,``"country"``])``df_multi``=``df_multi``.``sort_index``()``df_multi`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[31]: properties         user_id   name  age  score          continent
    country          America   USA         1000   John   33    6.7                   
    USA         1002    Tim   41    3.9          Europe    Germany     1003  Jenny  
    12    9.0                    Italy       1001   Mark   55    4.5`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``32``]:``df_multi``.``loc``[``"Europe"``,``:]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[32]: properties  user_id   name  age  score          country         
    Germany        1003  Jenny   12    9.0          Italy          1001   Mark   55   
    4.5`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Note that pandas prettifies the output of a MultiIndex by not repeating the
    leftmost index level (the continents) for each row. Instead, it only prints the
    continent when it changes. Selecting over multiple index levels is done by providing
    a tuple:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``33``]:``df_multi``.``loc``[(``"Europe"``,``"Italy"``),``:]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[33]: properties         user_id  name  age  score          continent country
             Europe    Italy       1001  Mark   55    4.5`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you want to selectively reset part of a MultiIndex, provide the level as
    an argument. Zero is the first column from the left:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``34``]:``df_multi``.``reset_index``(``level``=``0``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[34]: properties continent  user_id   name  age  score          country
             USA          America     1000   John   33    6.7          USA         
    America     1002    Tim   41    3.9          Germany       Europe     1003  Jenny  
    12    9.0          Italy         Europe     1001   Mark   55    4.5`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: While we won’t manually create a MultiIndex in this book, there are certain
    operations like `groupby`, which will cause pandas to return a DataFrame with
    a MultiIndex, so it’s good to know what it is. We will meet `groupby` later in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know various ways to select data, it’s time to learn how you change
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Data
  prefs: []
  type: TYPE_NORMAL
- en: 'The easiest way to change the data of a DataFrame is by assigning values to
    certain elements using the `loc` or `iloc` attributes. This is the starting point
    of this section before we turn to other ways of manipulating existing DataFrames:
    replacing values and adding new columns.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting data by label or position
  prefs: []
  type: TYPE_NORMAL
- en: 'As pointed out earlier in this chapter, when you call DataFrame methods like
    `df.reset_index()`, the method will always be applied to a copy, leaving the original
    DataFrame untouched. However, assigning values via the `loc` and `iloc` attributes
    changes the original DataFrame. Since I want to leave our DataFrame `df` untouched,
    I am working with a copy here that I am calling `df2`. If you want to change a
    single value, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``35``]:``# Copy the DataFrame first to leave the original untouched``df2``=``df``.``copy``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``36``]:``df2``.``loc``[``1000``,``"name"``]``=``"JOHN"``df2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[36]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1000        
    JOHN   33      USA    6.7   America          1002          Tim   41      USA   
    3.9   America          1003        Jenny   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'You can also change multiple values at the same time. One way to change the
    score of the users with ID 1000 and 1001 is to use a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``37``]:``df2``.``loc``[[``1000``,``1001``],``"score"``]``=``[``3``,``4``]``df2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[37]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.0    Europe          1000        
    JOHN   33      USA    3.0   America          1002          Tim   41      USA   
    3.9   America          1003        Jenny   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Changing data by position via `iloc` works the same way. Let’s now move on to
    see how you change the data by using boolean indexing.
  prefs: []
  type: TYPE_NORMAL
- en: Setting data by boolean indexing
  prefs: []
  type: TYPE_NORMAL
- en: 'Boolean indexing, which we used to filter rows, can also be used to assign
    values in a DataFrame. Imagine that you need to anonymize all names of people
    who are below 20 years old or from the USA:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``38``]:``tf``=``(``df2``[``"age"``]``<``20``)``|``(``df2``[``"country"``]``==``"USA"``)``df2``.``loc``[``tf``,``"name"``]``=``"xxx"``df2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[38]: properties  name  age  country  score continent          user_id
             1001        Mark   55    Italy    4.0    Europe          1000        
    xxx   33      USA    3.0   America          1002         xxx   41      USA   
    3.9   America          1003         xxx   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Sometimes, you have a dataset where you need to replace certain values across
    the board, i.e., not specific to certain columns. In that case, make use of the
    special syntax again and provide the whole DataFrame with booleans like this (the
    sample makes use again of the `rainfall` DataFrame):'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``39``]:``# Copy the DataFrame first to leave the original untouched``rainfall2``=``rainfall``.``copy``()``rainfall2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[39]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``40``]:``# Set the values to 0 wherever they are below 400``rainfall2``[``rainfall2``<``400``]``=``0``rainfall2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[40]:    City 1  City 2  City 3          0     0.0   400.3  1000.5         
    1     0.0     0.0  1100.6`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you just want to replace a value with another one, there is an easier way
    to do it, as I will show you next.
  prefs: []
  type: TYPE_NORMAL
- en: Setting data by replacing values
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to replace a certain value across your entire DataFrame or selected
    columns, use the `replace` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``41``]:``df2``.``replace``(``"USA"``,``"U.S."``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[41]: properties  name  age  country  score continent          user_id
             1001        Mark   55    Italy    4.0    Europe          1000        
    xxx   33     U.S.    3.0   America          1002         xxx   41     U.S.   
    3.9   America          1003         xxx   12  Germany    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If, instead, you only wanted to act on the `country` column, you could use
    this syntax instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '`df2``.``replace``({``"country"``:``{``"USA"``:``"U.S."``}})`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this case, since `USA` only turns up in the `country` column, it yields the
    same result as the previous sample. To wrap this section up, let’s see how you
    can add additional columns to a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Setting data by adding a new column
  prefs: []
  type: TYPE_NORMAL
- en: 'To add a new column to a DataFrame, assign values to a new column name. For
    example, you could add a new column to a DataFrame by using a scalar or list:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``42``]:``df2``.``loc``[:,``"discount"``]``=``0``df2``.``loc``[:,``"price"``]``=``[``49.9``,``49.9``,``99.9``,``99.9``]``df2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[42]: properties  name  age  country  score continent  discount  price
             user_id          1001        Mark   55    Italy    4.0    Europe        
    0   49.9          1000         xxx   33      USA    3.0   America         0  
    49.9          1002         xxx   41      USA    3.9   America         0   99.9
             1003         xxx   12  Germany    9.0    Europe         0   99.9`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Adding a new column often involves vectorized calculations:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``43``]:``df2``=``df``.``copy``()``# Let''s start with a fresh copy``df2``.``loc``[:,``"birth
    year"``]``=``2021``-``df2``[``"age"``]``df2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[43]: properties   name  age  country  score continent  birth year         
    user_id          1001         Mark   55    Italy    4.5    Europe        1966
             1000         John   33      USA    6.7   America        1988         
    1002          Tim   41      USA    3.9   America        1980          1003       
    Jenny   12  Germany    9.0    Europe        2009`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I will show you more about calculating with DataFrames in a moment, but before
    we get there, do you remember that I have used `NaN` a few times already? The
    next section will finally give you more context around the topic of missing data.
  prefs: []
  type: TYPE_NORMAL
- en: Missing Data
  prefs: []
  type: TYPE_NORMAL
- en: 'Missing data can be a problem as it has the potential to bias the results of
    your data analysis, thereby making your conclusions less robust. Nevertheless,
    it’s very common to have gaps in your datasets that you will have to deal with.
    In Excel, you usually have to deal with empty cells or `#N/A` errors, but pandas
    uses NumPy’s `np.nan` for missing data, displayed as `NaN`. `NaN` is the floating-point
    standard for Not-a-Number. For timestamps, `pd.NaT` is used instead, and for text,
    pandas uses `None`. Using `None` or `np.nan`, you can introduce missing values:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``44``]:``df2``=``df``.``copy``()``# Let''s start with a fresh copy``df2``.``loc``[``1000``,``"score"``]``=``None``df2``.``loc``[``1003``,``:]``=``None``df2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[44]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1000       
    John  33.0     USA    NaN   America          1002         Tim  41.0     USA   
    3.9   America          1003        None   NaN    None    NaN      None`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To clean a DataFrame, you often want to remove rows with missing data. This
    is as simple as:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``45``]:``df2``.``dropna``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[45]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1002        
    Tim  41.0     USA    3.9   America`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If, however, you only want to remove rows where all values are missing, use
    the `how` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``46``]:``df2``.``dropna``(``how``=``"all"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[46]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1000       
    John  33.0     USA    NaN   America          1002         Tim  41.0     USA   
    3.9   America`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To get a boolean DataFrame or Series depending on whether there is `NaN` or
    not, use `isna`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``47``]:``df2``.``isna``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[47]: properties   name    age  country  score  continent          user_id
             1001        False  False    False  False      False          1000       
    False  False    False   True      False          1002        False  False    False 
    False      False          1003         True   True     True   True       True`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To fill missing values, use `fillna`. For example, to replace `NaN` in the
    score column with its mean (I will introduce descriptive statistics like `mean`
    shortly):'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``48``]:``df2``.``fillna``({``"score"``:``df2``[``"score"``]``.``mean``()})`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[48]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1000       
    John  33.0     USA    4.2   America          1002         Tim  41.0     USA   
    3.9   America          1003        None   NaN    None    4.2      None`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Missing data isn’t the only condition that requires us to clean our dataset.
    The same is true for duplicate data, so let’s see what our options are!
  prefs: []
  type: TYPE_NORMAL
- en: Duplicate Data
  prefs: []
  type: TYPE_NORMAL
- en: 'Like missing data, duplicates negatively impact the reliability of your analysis.
    To get rid of duplicate rows, use the `drop_duplicates` method. Optionally, you
    can provide a subset of the columns as argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``49``]:``df``.``drop_duplicates``([``"country"``,``"continent"``])`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[49]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1000        
    John   33      USA    6.7   America          1003        Jenny   12  Germany   
    9.0    Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'By default, this will leave the first occurrence. To find out if a certain
    column contains duplicates or to get its unique values, use the following two
    commands (use `df.index` instead of `df["country"]` if you wanted to run this
    on the index instead):'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``50``]:``df``[``"country"``]``.``is_unique`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[50]: False`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``51``]:``df``[``"country"``]``.``unique``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[51]: array([''Italy'', ''USA'', ''Germany''], dtype=object)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'And finally, to understand which rows are duplicates, use the `duplicated`
    method, which returns a boolean Series: by default, it uses the parameter `keep="first"`,
    which keeps the first occurrence and marks only duplicates with `True`. By setting
    the parameter `keep=False`, it will return `True` for all rows, including its
    first occurrence, making it easy to get a DataFrame with all duplicate rows. In
    the following example, we look at the `country` column for duplicates, but in
    reality, you often look at the index or entire rows. In this case, you’d have
    to use `df.index.duplicated()` or `df.duplicated()` instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``52``]:``# By default, it marks only duplicates as True, i.e.``# without
    the first occurrence``df``[``"country"``]``.``duplicated``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[52]: user_id          1001    False          1000    False          1002    
    True          1003    False          Name: country, dtype: bool`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``53``]:``# To get all rows where "country" is duplicated, use``# keep=False``df``.``loc``[``df``[``"country"``]``.``duplicated``(``keep``=``False``),``:]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[53]: properties  name  age country  score continent          user_id         
    1000        John   33     USA    6.7   America          1002         Tim   41    
    USA    3.9   America`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Once you have cleaned your DataFrames by removing missing and duplicate data,
    you might want to perform some arithmetic operations—the next section gives you
    an introduction to how this works.
  prefs: []
  type: TYPE_NORMAL
- en: Arithmetic Operations
  prefs: []
  type: TYPE_NORMAL
- en: 'Like NumPy arrays, DataFrames and Series make use of vectorization. For example,
    to add a number to every value in the `rainfall` DataFrame, simply do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``54``]:``rainfall`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[54]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``55``]:``rainfall``+``100`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[55]:    City 1  City 2  City 3          0   400.1   500.3  1100.5         
    1   200.2   400.4  1200.6`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'However, the true power of pandas is its automatic data alignment mechanism:
    when you use arithmetic operators with more than one DataFrame, pandas automatically
    aligns them by their columns and row indices. Let’s create a second DataFrame
    with some of the same row and column labels. We then build the sum:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``56``]:``more_rainfall``=``pd``.``DataFrame``(``data``=``[[``100``,``200``],``[``300``,``400``]],``index``=``[``1``,``2``],``columns``=``[``"City
    1"``,``"City 4"``])``more_rainfall`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[56]:    City 1  City 4          1     100     200          2     300    
    400`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``57``]:``rainfall``+``more_rainfall`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[57]:    City 1  City 2  City 3  City 4          0     NaN     NaN    
    NaN     NaN          1   200.2     NaN     NaN     NaN          2     NaN    
    NaN     NaN     NaN`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The index and columns of the resulting DataFrame are the union of the indices
    and columns of the two DataFrames: the fields that have a value in both DataFrames
    show the sum, while the rest of the DataFrame shows `NaN`. This may be something
    you have to get used to if you come from Excel, where empty cells are automatically
    turned into zeros when you use them in arithmetic operations. To get the same
    behavior as in Excel, use the `add` method with a `fill_value` to replace `NaN`
    values with zeros:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``58``]:``rainfall``.``add``(``more_rainfall``,``fill_value``=``0``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[58]:    City 1  City 2  City 3  City 4          0   300.1   400.3  1000.5    
    NaN          1   200.2   300.4  1100.6   200.0          2   300.0     NaN    
    NaN   400.0`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This works accordingly for the other arithmetic operators as shown in [Table 5-4](#filepos625873).
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-4\. Arithmetic operators
  prefs: []
  type: TYPE_NORMAL
- en: '|  Operator  |  Method  |'
  prefs: []
  type: TYPE_TB
- en: '|   `*` |   `mul` |'
  prefs: []
  type: TYPE_TB
- en: '|   `+` |   `add` |'
  prefs: []
  type: TYPE_TB
- en: '|   `-` |   `sub` |'
  prefs: []
  type: TYPE_TB
- en: '|   `/` |   `div` |'
  prefs: []
  type: TYPE_TB
- en: '|   `**` |   `pow` |'
  prefs: []
  type: TYPE_TB
- en: 'When you have a DataFrame and a Series in your calculation, by default the
    Series is broadcast along the index:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``59``]:``# A Series taken from a row``rainfall``.``loc``[``1``,``:]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[59]: City 1     100.2          City 2     300.4          City 3    1100.6
             Name: 1, dtype: float64`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``60``]:``rainfall``+``rainfall``.``loc``[``1``,``:]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[60]:    City 1  City 2  City 3          0   400.3   700.7  2101.1         
    1   200.4   600.8  2201.2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Hence, to add a Series column-wise, you need to use the `add` method with an
    explicit `axis` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``61``]:``# A Series taken from a column``rainfall``.``loc``[:,``"City
    2"``]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[61]: 0    400.3          1    300.4          Name: City 2, dtype: float64`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``62``]:``rainfall``.``add``(``rainfall``.``loc``[:,``"City 2"``],``axis``=``0``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[62]:    City 1  City 2  City 3          0   700.4   800.6  1400.8         
    1   400.6   600.8  1401.0`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: While this section is about DataFrames with numbers and how they behave in arithmetic
    operations, the next section shows your options when it comes to manipulating
    text in DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Text Columns
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have seen at the beginning of this chapter, columns with text or mixed
    data types have the data type `object`. To perform operations on columns with
    text strings, use the `str` attribute that gives you access to Python’s string
    methods. We have already met a few string methods in [Chapter 3](index_split_010.html#filepos178328),
    but it won’t hurt to have a look at the available methods in the [Python docs](https://oreil.ly/-e7SC).
    For example, to remove leading and trailing white space, use the `strip` method;
    to make all first letters capitalized, there is the `capitalize` method. Chaining
    these together will clean up messy text columns that are often the result of manual
    data entry:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``63``]:``# Let''s create a new DataFrame``users``=``pd``.``DataFrame``(``data``=``[``"
    mArk "``,``"JOHN  "``,``"Tim"``,``" jenny"``],``columns``=``[``"name"``])``users`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[63]:      name          0   mArk          1  JOHN          2     Tim         
    3   jenny`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``64``]:``users_cleaned``=``users``.``loc``[:,``"name"``]``.``str``.``strip``()``.``str``.``capitalize``()``users_cleaned`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[64]: 0     Mark          1     John          2      Tim          3   
    Jenny          Name: name, dtype: object`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Or, to find all names that start with a “J”:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``65``]:``users_cleaned``.``str``.``startswith``(``"J"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[65]: 0    False          1     True          2    False          3    
    True          Name: name, dtype: bool`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The string methods are easy to use, but sometimes you may need to manipulate
    a DataFrame in a way that isn’t built-in. In that case, create your own function
    and apply it to your DataFrame, as the next section shows.
  prefs: []
  type: TYPE_NORMAL
- en: Applying a Function
  prefs: []
  type: TYPE_NORMAL
- en: 'DataFrames offer the `applymap` method, which will apply a function to every
    individual element, something that is useful if there are no NumPy ufuncs available.
    For example, there are no ufuncs for string formatting, so we can format every
    element of a DataFrame like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``66``]:``rainfall`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[66]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``67``]:``def``format_string``(``x``):``return``f``"{x:,.2f}"`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``68``]:``# Note that we pass in the function without calling it,``#
    i.e., format_string and not format_string()!``rainfall``.``applymap``(``format_string``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[68]:    City 1  City 2    City 3          0  300.10  400.30  1,000.50
             1  100.20  300.40  1,100.60`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To break this down: the following f-string returns `x` as a string: `f"{x}"`.
    To add formatting, append a colon to the variable followed by the formatting string
    `,.2f`. The comma is the thousands separator and `.2f` means fixed-point notation
    with two digits following the decimal point. To get more details about how to
    format strings, please refer to the [Format Specification Mini-Language](https://oreil.ly/NgsG8),
    which is part of the Python documentation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this sort of use case, lambda expressions (see sidebar) are widely used
    as they allow you to write the same in a single line without having to define
    a separate function. With lambda expressions, we can rewrite the previous example
    as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``69``]:``rainfall``.``applymap``(``lambda``x``:``f``"{x:,.2f}"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[69]:    City 1  City 2    City 3          0  300.10  400.30  1,000.50
             1  100.20  300.40  1,100.60`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: LAMBDA EXPRESSIONS
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Python allows you to define a function in a single line via lambda expressions.
    Lambda expressions are anonymous functions, which means that it is a function
    without a name. Consider this function:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`def``function_name``(``arg1``,``arg2``,``...``):``return``return_value`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This function can be rewritten as a lambda expression like this:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`lambda``arg1``,``arg2``,``...``:``return_value`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In essence, you replace `def` with `lambda`, leave away the `return` keyword
    and the function name, and put everything on one line. As we saw with the `applymap`
    method, this can be really convenient in this case as we don’t need to define
    a function for something that’s just being used a single time.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I have now mentioned all the important data manipulation methods, but before
    we move on, it’s important to understand when pandas uses a view of a DataFrame
    and when it uses a copy.
  prefs: []
  type: TYPE_NORMAL
- en: View vs. Copy
  prefs: []
  type: TYPE_NORMAL
- en: 'You may remember from the previous chapter that slicing NumPy arrays returns
    a view. With DataFrames, it’s unfortunately more complicated: it isn’t always
    easily predictable whether `loc` and `iloc` return views or copies, which makes
    it one of the more confusing topics. Since it’s a big difference whether you are
    changing the view or a copy of a DataFrame, pandas raises the following warning
    regularly when it thinks that you are setting the data in an unintended way: `SettingWithCopyWarning`.
    To circumvent this rather cryptic warning, here is some advice:'
  prefs: []
  type: TYPE_NORMAL
- en: Set values on the original DataFrame, not on a DataFrame that has been sliced
    off another DataFrame
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you want to have an independent DataFrame after slicing, make an explicit
    copy:'
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`selection``=``df``.``loc``[:,``[``"country"``,``"continent"``]]``.``copy``()`'
  prefs:
  - PREF_IND
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: While things are complicated with `loc` and `iloc`, it’s worth remembering that
    all DataFrame methods such as `df.dropna()` or `df.sort_values("column_name")`
    always return a copy.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we’ve mostly worked with one DataFrame at a time. The next section shows
    you various ways to combine multiple DataFrames into one, a very common task for
    which pandas offers powerful tools.
  prefs: []
  type: TYPE_NORMAL
- en: Combining DataFrames
  prefs: []
  type: TYPE_NORMAL
- en: Combining different datasets in Excel can be a cumbersome task and typically
    involves a lot of `VLOOKUP` formulas. Fortunately, combining DataFrames is one
    of pandas’ killer features where its data alignment capabilities will make your
    life really easy, thereby greatly reducing the possibility of introducing errors.
    Combining and merging DataFrames can be done in various ways; this section looks
    at just the most common cases using `concat`, `join`, and `merge`. While they
    have an overlap, each function makes a specific task very simple. I will start
    with the `concat` function, then explain the different options with `join`, and
    conclude by introducing `merge`, the most generic function of the three.
  prefs: []
  type: TYPE_NORMAL
- en: Concatenating
  prefs: []
  type: TYPE_NORMAL
- en: 'To simply glue multiple DataFrames together, the `concat` function is your
    best friend. As you can tell by the name of the function, this process has the
    technical name concatenation. By default, `concat` glues DataFrames together along
    the rows and aligns the columns automatically. In the following example, I create
    another DataFrame, `more_users`, and attach it to the bottom of our sample DataFrame
    `df`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``70``]:``data``=``[[``15``,``"France"``,``4.1``,``"Becky"``],``[``44``,``"Canada"``,``6.1``,``"Leanne"``]]``more_users``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"age"``,``"country"``,``"score"``,``"name"``],``index``=``[``1000``,``1011``])``more_users`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[70]:       age country  score    name          1000   15  France    4.1  
    Becky          1011   44  Canada    6.1  Leanne`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``71``]:``pd``.``concat``([``df``,``more_users``],``axis``=``0``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[71]:         name  age  country  score continent          1001    Mark  
    55    Italy    4.5    Europe          1000    John   33      USA    6.7   America
             1002     Tim   41      USA    3.9   America          1003   Jenny   12 
    Germany    9.0    Europe          1000   Becky   15   France    4.1       NaN
             1011  Leanne   44   Canada    6.1       NaN`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Note that you now have duplicate index elements, as `concat` glues the data
    together on the indicated axis (rows) and only aligns the data on the other one
    (columns), thereby matching the column names automatically—even if they are not
    in the same order in the two DataFrames! If you want to glue two DataFrames together
    along the columns, set `axis=1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``72``]:``data``=``[[``3``,``4``],``[``5``,``6``]]``more_categories``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"quizzes"``,``"logins"``],``index``=``[``1000``,``2000``])``more_categories`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[72]:       quizzes  logins          1000        3       4          2000       
    5       6`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``73``]:``pd``.``concat``([``df``,``more_categories``],``axis``=``1``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[73]:        name   age  country  score continent  quizzes  logins         
    1000   John  33.0      USA    6.7   America      3.0     4.0          1001   Mark 
    55.0    Italy    4.5    Europe      NaN     NaN          1002    Tim  41.0     
    USA    3.9   America      NaN     NaN          1003  Jenny  12.0  Germany    9.0   
    Europe      NaN     NaN          2000    NaN   NaN      NaN    NaN       NaN     
    5.0     6.0`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The special and very useful feature of `concat` is that it accepts more than
    two DataFrames. We will use this in the next chapter to make a single DataFrame
    out of multiple CSV files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pd``.``concat``([``df1``,``df2``,``df3``,``...``])`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: On the other hand, `join` and `merge` only work with two DataFrames, as we’ll
    see next.
  prefs: []
  type: TYPE_NORMAL
- en: Joining and Merging
  prefs: []
  type: TYPE_NORMAL
- en: When you join two DataFrames, you combine the columns of each DataFrame into
    a new DataFrame while deciding what happens with the rows by relying on set theory.
    If you have worked with relational databases before, it’s the same concept as
    the `JOIN` clause in SQL queries. [Figure 5-3](#filepos668317) shows how the four
    join types (that is the inner, left, right, and outer join) work by using two
    sample DataFrames, `df1` and `df2`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/00002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-3\. Join types
  prefs: []
  type: TYPE_NORMAL
- en: With `join`, pandas uses the indices of both DataFrames to align the rows. An
    inner join returns a DataFrame with only those rows where the indices overlap.
    A left join takes all the rows from the left DataFrame `df1` and matches the rows
    from the right DataFrame `df2` on the index. Where `df2` doesn’t have a matching
    row, pandas will fill in `NaN`. The left join corresponds to the `VLOOKUP` case
    in Excel. The right join takes all rows from the right table `df2` and matches
    them with rows from `df1` on the index. And finally, the outer join, which is
    short for full outer join, takes the union of indices from both DataFrames and
    matches the values where it can. [Table 5-5](#filepos669531) is the equivalent
    of [Figure 5-3](#filepos668317) in text form.
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-5\. Join types
  prefs: []
  type: TYPE_NORMAL
- en: '|  Type  |  Description  |'
  prefs: []
  type: TYPE_TB
- en: '|   `inner` |  Only rows whose index exists in both DataFrames  |'
  prefs: []
  type: TYPE_TB
- en: '|   `left` |  All rows from the left DataFrame, matching rows from the right
    DataFrame  |'
  prefs: []
  type: TYPE_TB
- en: '|   `right` |  All rows from the right DataFrame, matching rows from the left
    DataFrame  |'
  prefs: []
  type: TYPE_TB
- en: '|   `outer` |  The union of row indices from both DataFrames  |'
  prefs: []
  type: TYPE_TB
- en: 'Let’s see how this works in practice, bringing the examples from [Figure 5-3](#filepos668317)
    to life:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``74``]:``df1``=``pd``.``DataFrame``(``data``=``[[``1``,``2``],``[``3``,``4``],``[``5``,``6``]],``columns``=``[``"A"``,``"B"``])``df1`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[74]:    A  B          0  1  2          1  3  4          2  5  6`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``75``]:``df2``=``pd``.``DataFrame``(``data``=``[[``10``,``20``],``[``30``,``40``]],``columns``=``[``"C"``,``"D"``],``index``=``[``1``,``3``])``df2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[75]:     C   D          1  10  20          3  30  40`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``76``]:``df1``.``join``(``df2``,``how``=``"inner"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[76]:    A  B   C   D          1  3  4  10  20`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``77``]:``df1``.``join``(``df2``,``how``=``"left"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[77]:    A  B     C     D          0  1  2   NaN   NaN          1  3  4 
    10.0  20.0          2  5  6   NaN   NaN`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``78``]:``df1``.``join``(``df2``,``how``=``"right"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[78]:      A    B   C   D          1  3.0  4.0  10  20          3  NaN 
    NaN  30  40`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``79``]:``df1``.``join``(``df2``,``how``=``"outer"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[79]:      A    B     C     D          0  1.0  2.0   NaN   NaN         
    1  3.0  4.0  10.0  20.0          2  5.0  6.0   NaN   NaN          3  NaN  NaN 
    30.0  40.0`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you want to join on one or more DataFrame columns instead of relying on
    the index, use `merge` instead of `join`. `merge` accepts the `on` argument to
    provide one or more columns as the join condition: these columns, which have to
    exist on both DataFrames, are used to match the rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``80``]:``# Add a column called "category" to both DataFrames``df1``[``"category"``]``=``[``"a"``,``"b"``,``"c"``]``df2``[``"category"``]``=``[``"c"``,``"b"``]`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``81``]:``df1`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[81]:    A  B category          0  1  2        a          1  3  4       
    b          2  5  6        c`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``82``]:``df2`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[82]:     C   D category          1  10  20        c          3  30  40       
    b`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``83``]:``df1``.``merge``(``df2``,``how``=``"inner"``,``on``=``[``"category"``])`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[83]:    A  B category   C   D          0  3  4        b  30  40         
    1  5  6        c  10  20`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``84``]:``df1``.``merge``(``df2``,``how``=``"left"``,``on``=``[``"category"``])`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[84]:    A  B category     C     D          0  1  2        a   NaN   NaN
             1  3  4        b  30.0  40.0          2  5  6        c  10.0  20.0`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Since `join` and `merge` accept quite a few optional arguments to accommodate
    more complex scenarios, I invite you to have a look at the [official documentation](https://oreil.ly/OZ4WV)
    to learn more about them.
  prefs: []
  type: TYPE_NORMAL
- en: 'You know now how to manipulate one or more DataFrames, which brings us to the
    next step in our data analysis journey: making sense of data.'
  prefs: []
  type: TYPE_NORMAL
- en: Descriptive Statistics and Data Aggregation
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to make sense of big datasets is to compute a descriptive statistic
    like the sum or the mean on either the whole dataset or on meaningful subsets.
    This section starts by looking at how this works with pandas before it introduces
    two ways to aggregate data into subsets: the `groupby` method and the `pivot_table`
    function.'
  prefs: []
  type: TYPE_NORMAL
- en: Descriptive Statistics
  prefs: []
  type: TYPE_NORMAL
- en: 'Descriptive statistics allows you to summarize datasets by using quantitative
    measures. For example, the number of data points is a simple descriptive statistic.
    Averages like mean, median, or mode are other popular examples. DataFrames and
    Series allow you to access descriptive statistics conveniently via methods like
    `sum`, `mean`, and `count`, to name just a few. You will meet many of them throughout
    this book, and the full list is available via the [pandas documentation](https://oreil.ly/t2q9Q).
    By default, they return a Series along `axis=0`, which means you get the statistic
    of the columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``85``]:``rainfall`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[85]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``86``]:``rainfall``.``mean``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[86]: City 1     200.15          City 2     350.35          City 3    1050.55
             dtype: float64`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you want the statistic per row, provide the `axis` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``87``]:``rainfall``.``mean``(``axis``=``1``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[87]: 0    566.966667          1    500.400000          dtype: float64`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: By default, missing values are not included in descriptive statistics like `sum`
    or `mean`. This is in line with how Excel treats empty cells, so using Excel’s
    `AVERAGE` formula on a range with empty cells will give you the same result as
    the `mean` method applied on a Series with the same numbers and `NaN` values instead
    of empty cells.
  prefs: []
  type: TYPE_NORMAL
- en: Getting a statistic across all rows of a DataFrame is sometimes not good enough
    and you need more granular information—the mean per category, for example. Let’s
    see how it’s done!
  prefs: []
  type: TYPE_NORMAL
- en: Grouping
  prefs: []
  type: TYPE_NORMAL
- en: 'Using our sample DataFrame `df` again, let’s find out the average score per
    continent! To do this, you first group the rows by continent and subsequently
    apply the `mean` method, which will calculate the mean per group. All nonnumeric
    columns are automatically excluded:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``88``]:``df``.``groupby``([``"continent"``])``.``mean``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[88]: properties   age  score          continent          America     37.0  
    5.30          Europe      33.5   6.75`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you include more than one column, the resulting DataFrame will have a hierarchical
    index—the MultiIndex we met earlier on:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``89``]:``df``.``groupby``([``"continent"``,``"country"``])``.``mean``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[89]: properties         age  score          continent country         
    America   USA       37    5.3          Europe    Germany   12    9.0                   
    Italy     55    4.5`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Instead of `mean`, you can use most of the descriptive statistics that pandas
    offers and if you want to use your own function, use the `agg` method. For example,
    here is how you get the difference between the maximum and minimum value per group:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``90``]:``df``.``groupby``([``"continent"``])``.``agg``(``lambda``x``:``x``.``max``()``-``x``.``min``())`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[90]: properties  age  score          continent          America      
    8    2.8          Europe       43    4.5`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A popular way to get statistics per group in Excel is to use pivot tables. They
    introduce a second dimension and are great to look at your data from different
    perspectives. pandas has a pivot table functionality, too, as we will see next.
  prefs: []
  type: TYPE_NORMAL
- en: Pivoting and Melting
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using pivot tables in Excel, you will have no trouble applying pandas’
    `pivot_table` function, as it works in largely the same way. The data in the following
    DataFrame is organized similarly to how records are typically stored in a database;
    each row shows a sales transaction for a specific fruit in a certain region:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``91``]:``data``=``[[``"Oranges"``,``"North"``,``12.30``],``[``"Apples"``,``"South"``,``10.55``],``[``"Oranges"``,``"South"``,``22.00``],``[``"Bananas"``,``"South"``,``5.90``],``[``"Bananas"``,``"North"``,``31.30``],``[``"Oranges"``,``"North"``,``13.10``]]``sales``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"Fruit"``,``"Region"``,``"Revenue"``])``sales`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[91]:      Fruit Region  Revenue          0  Oranges  North    12.30         
    1   Apples  South    10.55          2  Oranges  South    22.00          3  Bananas 
    South     5.90          4  Bananas  North    31.30          5  Oranges  North   
    13.10`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To create a pivot table, you provide the DataFrame as the first argument to
    the `pivot_table` function. `index` and `columns` define which column of the DataFrame
    will become the pivot table’s row and column labels, respectively. `values` are
    going to be aggregated into the data part of the resulting DataFrame by using
    the `aggfunc`, a function that can be provided as a string or NumPy ufunc. And
    finally, `margins` correspond to `Grand Total` in Excel, i.e., if you leave `margins`
    and `margins_name` away, the `Total` column and row won’t be shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``92``]:``pivot``=``pd``.``pivot_table``(``sales``,``index``=``"Fruit"``,``columns``=``"Region"``,``values``=``"Revenue"``,``aggfunc``=``"sum"``,``margins``=``True``,``margins_name``=``"Total"``)``pivot`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[92]: Region   North  South  Total          Fruit          Apples     NaN 
    10.55  10.55          Bananas   31.3   5.90  37.20          Oranges   25.4  22.00 
    47.40          Total     56.7  38.45  95.15`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In summary, pivoting your data means to take the unique values of a column
    (`Region` in our case) and turn them into the column headers of the pivot table,
    thereby aggregating the values from another column. This makes it easy to read
    off summary information across the dimensions of interest. In our pivot table,
    you instantly see that there were no apples sold in the north region and that
    in the south region, most revenues come from oranges. If you want to go the other
    way around and turn the column headers into the values of a single column, use
    `melt`. In that sense, `melt` is the opposite of the `pivot_table` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``93``]:``pd``.``melt``(``pivot``.``iloc``[:``-``1``,:``-``1``]``.``reset_index``(),``id_vars``=``"Fruit"``,``value_vars``=``[``"North"``,``"South"``],``value_name``=``"Revenue"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[93]:      Fruit Region  Revenue          0   Apples  North      NaN         
    1  Bananas  North    31.30          2  Oranges  North    25.40          3   Apples 
    South    10.55          4  Bananas  South     5.90          5  Oranges  South   
    22.00`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here, I am providing our pivot table as the input, but I am using `iloc` to
    get rid of the total row and column. I also reset the index so that all information
    is available as regular columns. I then provide `id_vars` to indicate the identifiers
    and `value_vars` to define which columns I want to “unpivot.” Melting can be useful
    if you want to prepare the data so it can be stored back to a database that expects
    it in this format.
  prefs: []
  type: TYPE_NORMAL
- en: Working with aggregated statistics helps you understand your data, but nobody
    likes to read a page full of numbers. To make information easily understandable,
    nothing works better than creating visualizations, which is our next topic. While
    Excel uses the term charts, pandas generally refers to them as plots. I will use
    these terms interchangeably in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting
  prefs: []
  type: TYPE_NORMAL
- en: 'Plotting allows you to visualize the findings of your data analysis and may
    well be the most important step in the whole process. For plotting, we’re going
    to use two libraries: we start by looking at Matplotlib, pandas’ default plotting
    library, before we focus on Plotly, a modern plotting library that gives us a
    more interactive experience in Jupyter notebooks.'
  prefs: []
  type: TYPE_NORMAL
- en: Matplotlib
  prefs: []
  type: TYPE_NORMAL
- en: Matplotlib is a plotting package that has been around for a long time and is
    included in the Anaconda distribution. With it, you can generate plots in a variety
    of formats, including vector graphics for high-quality printing. When you call
    the `plot` method of a DataFrame, pandas will produce a Matplotlib plot by default.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use Matplotlib in a Jupyter notebook, you need to first run one of two magic
    commands (see the sidebar [“Magic Commands”](#filepos726690)): `%matplotlib inline`
    or `%matplotlib notebook`. They configure the notebook so that plots can be displayed
    in the notebook itself. The latter command adds a bit more interactivity, allowing
    you to change the size or zoom factor of the chart. Let’s get started and create
    a first plot with pandas and Matplotlib (see [Figure 5-4](#filepos726089)):'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``94``]:``import``numpy``as``np``%``matplotlib``inline``# Or %matplotlib
    notebook`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``95``]:``data``=``pd``.``DataFrame``(``data``=``np``.``random``.``rand``(``4``,``4``)``*``100000``,``index``=``[``"Q1"``,``"Q2"``,``"Q3"``,``"Q4"``],``columns``=``[``"East"``,``"West"``,``"North"``,``"South"``])``data``.``index``.``name``=``"Quarters"``data``.``columns``.``name``=``"Region"``data`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[95]: Region            East          West         North         South
             Quarters          Q1        23254.220271  96398.309860  16845.951895 
    41671.684909          Q2        87316.022433  45183.397951  15460.819455  50951.465770
             Q3        51458.760432   3821.139360  77793.393899  98915.952421         
    Q4        64933.848496   7600.277035  55001.831706  86248.512650`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``96``]:``data``.``plot``()``# Shortcut for data.plot.line()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[96]: <AxesSubplot:xlabel=''Quarters''>`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](images/00008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-4\. Matplotlib plot
  prefs: []
  type: TYPE_NORMAL
- en: Note that in this example, I have used a NumPy array to construct a pandas DataFrame.
    Providing NumPy arrays allows you to leverage NumPy’s constructors that we met
    in the last chapter; here, we use NumPy to generate a pandas DataFrame based on
    pseudorandom numbers. Therefore, when you run the sample on your end, you will
    get different values.
  prefs: []
  type: TYPE_NORMAL
- en: MAGIC COMMANDS
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The `%matplotlib inline` command we used to make Matplotlib work properly with
    Jupyter notebooks is a magic command. Magic commands are a set of simple commands
    that cause a Jupyter notebook cell to behave in a certain way or make cumbersome
    tasks so easy that it almost feels like magic. You write magic commands in cells
    like Python code, but they either start with `%%` or `%`. Commands that affect
    the whole cell start with `%%`, and commands that only affect a single line in
    a cell start with `%`.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We will see more magic commands in the next chapters, but if you want to list
    all currently available magic commands, run `%lsmagic`, and for a detailed description,
    run `%magic`.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Even if you use the magic command `%matplotlib notebook`, you will probably
    notice that Matplotlib was originally designed for static plots rather than for
    an interactive experience on a web page. That’s why we’re going to use Plotly
    next, a plotting library designed for the web.
  prefs: []
  type: TYPE_NORMAL
- en: Plotly
  prefs: []
  type: TYPE_NORMAL
- en: 'Plotly is a JavaScript-based library and can—since version 4.8.0—be used as
    a pandas plotting backend with great interactivity: you can easily zoom in, click
    on the legend to select or deselect a category, and get tooltips with more info
    about the data point you’re hovering over. Plotly is not included in the Anaconda
    installation, so if you haven’t installed it yet, do so now by running the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(base)>` `conda install plotly`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Once you run the following cell, the plotting backend of the whole notebook
    will be set to Plotly and if you would rerun the previous cell, it would also
    be rendered as a Plotly chart. For Plotly, instead of running a magic command,
    you just need to set it as backend before being able to plot Figures [5-5](#filepos731078)
    and [5-6](#filepos732496):'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``97``]:``# Set the plotting backend to Plotly``pd``.``options``.``plotting``.``backend``=``"plotly"`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``98``]:``data``.``plot``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](images/00016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-5\. Plotly line plot
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``99``]:``# Display the same data as bar plot``data``.``plot``.``bar``(``barmode``=``"group"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](images/00021.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-6\. Plotly bar plot
  prefs: []
  type: TYPE_NORMAL
- en: DIFFERENCES IN PLOTTING BACKENDS
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you use Plotly as plotting backend, you’ll need to check the accepted arguments
    of the plot methods directly on the Plotly docs. For example, you can take a look
    at the `barmode=group` argument in [Plotly’s bar charts documentation](https://oreil.ly/Ekurd).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: pandas and the underlying plotting libraries offer a wealth of chart types and
    options to format the charts in almost any desired way. It’s also possible to
    arrange multiple plots into a series of subplots. As an overview, [Table 5-6](#filepos733705)
    shows the available plot types.
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-6\. pandas plot types
  prefs: []
  type: TYPE_NORMAL
- en: '|  Type  |  Description  |'
  prefs: []
  type: TYPE_TB
- en: '|   `line` |  Line Chart, default when running  `df.plot()` |'
  prefs: []
  type: TYPE_TB
- en: '|   `bar` |  Vertical bar chart  |'
  prefs: []
  type: TYPE_TB
- en: '|   `barh` |  Horizontal bar chart  |'
  prefs: []
  type: TYPE_TB
- en: '|   `hist` |  Histogram  |'
  prefs: []
  type: TYPE_TB
- en: '|   `box` |  Box plot  |'
  prefs: []
  type: TYPE_TB
- en: '|   `kde` |  Density plot, can also be used via  `density` |'
  prefs: []
  type: TYPE_TB
- en: '|   `area` |  Area chart  |'
  prefs: []
  type: TYPE_TB
- en: '|   `scatter` |  Scatter plot  |'
  prefs: []
  type: TYPE_TB
- en: '|   `hexbin` |  Hexagonal bin plots  |'
  prefs: []
  type: TYPE_TB
- en: '|   `pie` |  Pie chart  |'
  prefs: []
  type: TYPE_TB
- en: On top of that, pandas offers some higher-level plotting tools and techniques
    that are made up of multiple individual components. For details, see the [pandas
    visualization documentation](https://oreil.ly/FxYg9).
  prefs: []
  type: TYPE_NORMAL
- en: OTHER PLOTTING LIBRARIES
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The scientific visualization landscape in Python is very active, and besides
    Matplotlib and Plotly, there are many other high-quality options to choose from
    that may be the better option for certain use cases:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Seaborn
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Seaborn](https://oreil.ly/a3U1t) is built on top of Matplotlib. It improves
    the default style and adds additional plots like heatmaps, which often simplify
    your work: you can create advanced statistical plots with only a few lines of
    code.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Bokeh
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Bokeh](https://docs.bokeh.org) is similar to Plotly in technology and functionality:
    it’s based on JavaScript and therefore also works great for interactive charts
    in Jupyter notebooks. Bokeh is included in Anaconda.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Altair
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Altair](https://oreil.ly/t06t7) is a library for statistical visualizations
    based on the [Vega project](https://oreil.ly/RN6A7). Altair is also JavaScript-based
    and offers some interactivity like zooming.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: HoloViews
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[HoloViews](https://holoviews.org) is another JavaScript-based package that
    focuses on making data analysis and visualization easy. With a few lines of code,
    you can achieve complex statistical plots.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: We will create more plots in the next chapter to analyze time series, but before
    we get there, let’s wrap this chapter up by learning how we can import and export
    data with pandas!
  prefs: []
  type: TYPE_NORMAL
- en: Importing and Exporting DataFrames
  prefs: []
  type: TYPE_NORMAL
- en: So far, we constructed DataFrames from scratch using nested lists, dictionaries,
    or NumPy arrays. These techniques are important to know, but typically, the data
    is already available and you simply need to turn it into a DataFrame. To do this,
    pandas offers various reader functions. But even if you need to access a proprietary
    system for which pandas doesn’t offer a built-in reader, you often have a Python
    package to connect to that system, and once you have the data, it’s easy enough
    to turn it into a DataFrame. In Excel, data import is the type of work you would
    usually handle with Power Query.
  prefs: []
  type: TYPE_NORMAL
- en: After analyzing and changing your dataset, you might want to push the results
    back into a database or export it to a CSV file or—given the title of the book—present
    it in an Excel workbook to your manager. To export pandas DataFrames, use one
    of the exporter methods that DataFrames offer. [Table 5-7](#filepos741567) shows
    an overview of the most common import and export methods.
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-7\. Importing and exporting DataFrames
  prefs: []
  type: TYPE_NORMAL
- en: '|  Data format/system  |  Import: pandas (pd) function  |  Export: DataFrame
    (df) method  |'
  prefs: []
  type: TYPE_TB
- en: '|  CSV files  |   `pd.read_csv` |   `df.to_csv` |'
  prefs: []
  type: TYPE_TB
- en: '|  JSON  |   `pd.read_json` |   `df.to_json` |'
  prefs: []
  type: TYPE_TB
- en: '|  HTML  |   `pd.read_html` |   `df.to_html` |'
  prefs: []
  type: TYPE_TB
- en: '|  Clipboard  |   `pd.read_clipboard` |   `df.to_clipboard` |'
  prefs: []
  type: TYPE_TB
- en: '|  Excel files  |   `pd.read_excel` |   `df.to_excel` |'
  prefs: []
  type: TYPE_TB
- en: '|  SQL Databases  |   `pd.read_sql` |   `df.to_sql` |'
  prefs: []
  type: TYPE_TB
- en: We will meet `pd.read_sql` and `pd.to_sql` in [Chapter 11](index_split_027.html#filepos1487255),
    where we will use them as part of a case study. And since I am going to dedicate
    the whole of [Chapter 7](index_split_019.html#filepos863345) to the topic of reading
    and writing Excel files with pandas, I will focus on importing and exporting CSV
    files in this section. Let’s start with exporting an existing DataFrame!
  prefs: []
  type: TYPE_NORMAL
- en: Exporting CSV Files
  prefs: []
  type: TYPE_NORMAL
- en: 'If you need to pass a DataFrame to a colleague who might not use Python or
    pandas, passing it in the form of a CSV file is usually a good idea: pretty much
    every program knows how to import them. To export our sample DataFrame `df` to
    a CSV file, use the `to_csv` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``100``]:``df``.``to_csv``(``"course_participants.csv"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you wanted to store the file in a different directory, supply the full path
    as a raw string, e.g., `r"C:\path\to\desired\location\msft.csv"`.
  prefs: []
  type: TYPE_NORMAL
- en: USE RAW STRINGS FOR FILE PATHS ON WINDOWS
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In strings, the backslash is used to escape certain characters. That’s why to
    work with file paths on Windows, you either need to use double backslashes (`C:\\path\\to\\file.csv`)
    or prefix the string with an `r` to turn it into a raw string that interprets
    the characters literally. This isn’t an issue on macOS or Linux, as they use forward
    slashes in paths.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'By providing only the file name as I do, it will produce the file course_participants.csv
    in the same directory as the notebook with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '`user_id,name,age,country,score,continent 1001,Mark,55,Italy,4.5,Europe 1000,John,33,USA,6.7,America
    1002,Tim,41,USA,3.9,America 1003,Jenny,12,Germany,9.0,Europe`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now that you know how to use the `df.to_csv` method, let’s see how importing
    a CSV file works!
  prefs: []
  type: TYPE_NORMAL
- en: Importing CSV Files
  prefs: []
  type: TYPE_NORMAL
- en: 'Importing a local CSV file is as easy as providing its path to the `read_csv`
    function. MSFT.csv is a CSV file that I downloaded from Yahoo! Finance and it
    contains the daily historical stock prices for Microsoft—you’ll find it in the
    companion repository, in the csv folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``101``]:``msft``=``pd``.``read_csv``(``"csv/MSFT.csv"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Often, you will need to supply a few more parameters to `read_csv` than just
    the file name. For example, `sep` allows you to tell pandas what separator or
    delimiter the CSV file uses in case it isn’t the default comma. We will use a
    few more parameters in the next chapter, but for the full overview, have a look
    at the [pandas documentation](https://oreil.ly/2GMhW).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we are dealing with big DataFrames with many thousands of rows, typically
    the first thing is to run the `info` method to get a summary of the DataFrame.
    Next, you may want to take a peek at the first and last few rows of the DataFrame
    using the `head` and `tail` methods. These methods return five rows by default,
    but this can be changed by providing the desired number of rows as an argument.
    You can also run the `describe` method to get some basic statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``102``]:``msft``.``info``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`<class ''pandas.core.frame.DataFrame''> RangeIndex: 8622 entries, 0 to 8621
    Data columns (total 7 columns): #   Column     Non-Null Count  Dtype ---  ------    
    --------------  ----- 0   Date       8622 non-null   object 1   Open       8622
    non-null   float64 2   High       8622 non-null   float64 3   Low        8622
    non-null   float64 4   Close      8622 non-null   float64 5   Adj Close  8622
    non-null   float64 6   Volume     8622 non-null   int64 dtypes: float64(5), int64(1),
    object(1) memory usage: 471.6+ KB`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``103``]:``# I am selecting a few columns because of space issues``#
    You can also just run: msft.head()``msft``.``loc``[:,``[``"Date"``,``"Adj Close"``,``"Volume"``]]``.``head``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[103]:          Date  Adj Close      Volume           0  1986-03-13   0.062205 
    1031788800           1  1986-03-14   0.064427   308160000           2  1986-03-17  
    0.065537   133171200           3  1986-03-18   0.063871    67766400          
    4  1986-03-19   0.062760    47894400`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``104``]:``msft``.``loc``[:,``[``"Date"``,``"Adj Close"``,``"Volume"``]]``.``tail``(``2``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[104]:             Date   Adj Close    Volume           8620  2020-05-26 
    181.570007  36073600           8621  2020-05-27  181.809998  39492600`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``105``]:``msft``.``loc``[:,``[``"Adj Close"``,``"Volume"``]]``.``describe``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[105]:          Adj Close        Volume           count  8622.000000  8.622000e+03
              mean     24.921952  6.030722e+07           std      31.838096  3.877805e+07
              min       0.057762  2.304000e+06           25%       2.247503  3.651632e+07
              50%      18.454313  5.350380e+07           75%      25.699224  7.397560e+07
              max     187.663330  1.031789e+09`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Adj Close` stands for adjusted close price and corrects the stock price for
    corporate actions such as stock splits. `Volume` is the number of stocks that
    were traded. I have summarized the various DataFrame exploration methods we’ve
    seen in this chapter in [Table 5-8](#filepos758607).'
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-8\. DataFrame exploration methods and attributes
  prefs: []
  type: TYPE_NORMAL
- en: '|  DataFrame (df) Method/Attribute  |  Description  |'
  prefs: []
  type: TYPE_TB
- en: '|   `df.info()` |  Provides number of data points, index type, dtype, and memory
    usage.  |'
  prefs: []
  type: TYPE_TB
- en: '|   `df.describe()` |  Provides basic statistics including count, mean, std,
    min, max, and percentiles.  |'
  prefs: []
  type: TYPE_TB
- en: '|   `df.head(n=5)` |  Returns the first  n rows of the DataFrame. |'
  prefs: []
  type: TYPE_TB
- en: '|   `df.tail(n=5)` |  Returns the last  n rows of the DataFrame. |'
  prefs: []
  type: TYPE_TB
- en: '|   `df.dtypes` |  Returns the dtype of each column.  |'
  prefs: []
  type: TYPE_TB
- en: 'The `read_csv` function also accepts a URL instead of a local CSV file. This
    is how you read the CSV file directly from the companion repo:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``106``]:``# The line break in the URL is only to make it fit on the
    page``url``=``(``"https://raw.githubusercontent.com/fzumstein/"``"python-for-excel/1st-edition/csv/MSFT.csv"``)``msft``=``pd``.``read_csv``(``url``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``107``]:``msft``.``loc``[:,``[``"Date"``,``"Adj Close"``,``"Volume"``]]``.``head``(``2``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[107]:          Date  Adj Close      Volume           0  1986-03-13   0.062205 
    1031788800           1  1986-03-14   0.064427   308160000`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We’ll continue with this dataset and the `read_csv` function in the next chapter
    about time series, where we will turn the `Date` column into a `DatetimeIndex`.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter was packed with new concepts and tools to analyze datasets in
    pandas. We learned how to load CSV files, how to deal with missing or duplicate
    data, and how to make use of descriptive statistics. We also saw how easy it is
    to turn your DataFrames into interactive plots. While it may take a while to digest
    everything, it probably won’t take long before you will understand the immense
    power you are gaining by adding pandas to your tool belt. Along the way, we compared
    pandas to the following Excel functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: AutoFilter functionality
  prefs: []
  type: TYPE_NORMAL
- en: See [“Selecting by boolean indexing”](index_split_015.html#filepos549613).
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: VLOOKUP formula
  prefs: []
  type: TYPE_NORMAL
- en: See [“Joining and Merging”](#filepos667627).
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Pivot Table
  prefs: []
  type: TYPE_NORMAL
- en: See [“Pivoting and Melting”](#filepos701398).
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Power Query
  prefs: []
  type: TYPE_NORMAL
- en: This is a combination of [“Importing and Exporting DataFrames”](#filepos740294),
    [“Data Manipulation”](index_split_015.html#filepos524268), and [“Combining DataFrames”](#filepos652519).
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: The next chapter is about time series analysis, the functionality that led to
    broad adoption of pandas by the financial industry. Let’s see why this part of
    pandas has such an edge over Excel!
  prefs: []
  type: TYPE_NORMAL
- en: '[1  ](index_split_015.html#filepos498666) pandas 1.0.0 introduced a dedicated
    `string` data type to make some operations easier and more consistent with text.
    As it is still experimental, I am not going to make use of it in this book.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
