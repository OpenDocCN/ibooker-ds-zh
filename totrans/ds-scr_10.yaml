- en: Chapter 9\. Getting Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第九章. 获取数据
- en: To write it, it took three months; to conceive it, three minutes; to collect
    the data in it, all my life.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要写它，用了三个月；要构思它，用了三分钟；要收集其中的数据，用了一生。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: F. Scott Fitzgerald
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: F. 斯科特·菲茨杰拉德
- en: In order to be a data scientist you need data. In fact, as a data scientist
    you will spend an embarrassingly large fraction of your time acquiring, cleaning,
    and transforming data. In a pinch, you can always type the data in yourself (or
    if you have minions, make them do it), but usually this is not a good use of your
    time. In this chapter, we’ll look at different ways of getting data into Python
    and into the right formats.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 要成为一名数据科学家，你需要数据。事实上，作为数据科学家，你将花费大量时间来获取、清理和转换数据。如果必要，你可以自己键入数据（或者如果有下属，让他们来做），但通常这不是你时间的好用法。在本章中，我们将探讨将数据引入Python及其转换为正确格式的不同方法。
- en: stdin and stdout
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: stdin和stdout
- en: 'If you run your Python scripts at the command line, you can *pipe* data through
    them using `sys.stdin` and `sys.stdout`. For example, here is a script that reads
    in lines of text and spits back out the ones that match a regular expression:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在命令行中运行Python脚本，你可以使用`sys.stdin`和`sys.stdout`将数据*管道*通过它们。例如，这是一个读取文本行并返回匹配正则表达式的脚本：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And here’s one that counts the lines it receives and then writes out the count:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个示例，它会计算接收到的行数并将其写出：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You could then use these to count how many lines of a file contain numbers.
    In Windows, you’d use:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以使用它们来计算文件中包含数字的行数。在Windows中，你会使用：
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'whereas in a Unix system you’d use:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在Unix系统中，你会使用：
- en: '[PRE3]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The | is the pipe character, which means “use the output of the left command
    as the input of the right command.” You can build pretty elaborate data-processing
    pipelines this way.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 管道符号`|`表示管道字符，意味着“使用左侧命令的输出作为右侧命令的输入”。你可以通过这种方式构建非常复杂的数据处理管道。
- en: Note
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you are using Windows, you can probably leave out the `python` part of this
    command:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用Windows，你可能可以在该命令中省略`python`部分：
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If you are on a Unix system, doing so requires [a couple more steps](https://stackoverflow.com/questions/15587877/run-a-python-script-in-terminal-without-the-python-command).
    First add a “shebang” as the first line of your script `#!/usr/bin/env python`.
    Then, at the command line, use `chmod` x egrep.py++ to make the file executable.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在Unix系统上，这样做需要[几个额外步骤](https://stackoverflow.com/questions/15587877/run-a-python-script-in-terminal-without-the-python-command)。首先在你的脚本的第一行添加一个“shebang”
    `#!/usr/bin/env python`。然后，在命令行中使用`chmod` x egrep.py++将文件设为可执行。
- en: 'Similarly, here’s a script that counts the words in its input and writes out
    the most common ones:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，这是一个计算其输入中单词数量并写出最常见单词的脚本：
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'after which you could do something like:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以像这样做一些事情：
- en: '[PRE6]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: (If you are using Windows, then use `type` instead of `cat`.)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: （如果你使用Windows，则使用`type`而不是`cat`。）
- en: Note
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you are a seasoned Unix programmer, you are probably familiar with a wide
    variety of command-line tools (for example, `egrep`) that are built into your
    operating system and are preferable to building your own from scratch. Still,
    it’s good to know you can if you need to.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一名经验丰富的Unix程序员，可能已经熟悉各种命令行工具（例如，`egrep`），这些工具已经内建到你的操作系统中，比从头开始构建更可取。不过，了解自己可以这样做也是很好的。
- en: Reading Files
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取文件
- en: You can also explicitly read from and write to files directly in your code.
    Python makes working with files pretty simple.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在代码中直接显式地读取和写入文件。Python使得处理文件变得非常简单。
- en: The Basics of Text Files
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本文件的基础知识
- en: 'The first step to working with a text file is to obtain a *file object* using
    `open`:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 处理文本文件的第一步是使用`open`获取一个*文件对象*：
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Because it is easy to forget to close your files, you should always use them
    in a `with` block, at the end of which they will be closed automatically:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因为很容易忘记关闭文件，所以你应该总是在`with`块中使用它们，在块结束时它们将自动关闭：
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you need to read a whole text file, you can just iterate over the lines
    of the file using `for`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要读取整个文本文件，可以使用`for`循环迭代文件的每一行：
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Every line you get this way ends in a newline character, so you’ll often want
    to `strip` it before doing anything with it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式获取的每一行都以换行符结尾，所以在处理之前通常会将其`strip`掉。
- en: 'For example, imagine you have a file full of email addresses, one per line,
    and you need to generate a histogram of the domains. The rules for correctly extracting
    domains are somewhat subtle—see, e.g., the [Public Suffix List](https://publicsuffix.org)—but
    a good first approximation is to just take the parts of the email addresses that
    come after the *@* (this gives the wrong answer for email addresses like *joel@mail.datasciencester.com*,
    but for the purposes of this example we’re willing to live with that):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你有一个文件，其中包含一个邮箱地址一行，你需要生成一个域名的直方图。正确提取域名的规则有些微妙，可以参考[公共后缀列表](https://publicsuffix.org)，但一个很好的初步方法是仅仅取邮箱地址中“@”后面的部分（对于像*joel@mail.datasciencester.com*这样的邮箱地址，这个方法会给出错误的答案，但在这个例子中我们可以接受这种方法）：
- en: '[PRE10]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Delimited Files
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分隔文件
- en: 'The hypothetical email addresses file we just processed had one address per
    line. More frequently you’ll work with files with lots of data on each line. These
    files are very often either *comma-separated* or *tab-separated*: each line has
    several fields, with a comma or a tab indicating where one field ends and the
    next field starts.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚处理的假设的邮箱地址文件每行一个地址。更频繁地，你将使用每行有大量数据的文件。这些文件往往是逗号分隔或制表符分隔的：每行有多个字段，逗号或制表符表示一个字段的结束和下一个字段的开始。
- en: This starts to get complicated when you have fields with commas and tabs and
    newlines in them (which you inevitably will). For this reason, you should never
    try to parse them yourself. Instead, you should use Python’s `csv` module (or
    the pandas library, or some other library that’s designed to read comma-separated
    or tab-delimited files).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的字段中有逗号、制表符和换行符时（这是不可避免的）。因此，你不应该尝试自己解析它们。相反，你应该使用Python的`csv`模块（或pandas库，或设计用于读取逗号分隔或制表符分隔文件的其他库）。
- en: Warning
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Never parse a comma-separated file yourself. You will screw up the edge cases!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 永远不要自己解析逗号分隔的文件。你会搞砸一些边缘情况！
- en: If your file has no headers (which means you probably want each row as a `list`,
    and which places the burden on you to know what’s in each column), you can use
    `csv.reader` to iterate over the rows, each of which will be an appropriately
    split list.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的文件没有表头（这意味着你可能希望每行作为一个`list`，并且需要你知道每一列中包含什么），你可以使用`csv.reader`来迭代行，每行都会是一个适当拆分的列表。
- en: 'For example, if we had a tab-delimited file of stock prices:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们有一个制表符分隔的股票价格文件：
- en: '[PRE11]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'we could process them with:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用以下方式处理它们：
- en: '[PRE12]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'If your file has headers:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的文件有表头：
- en: '[PRE13]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'you can either skip the header row with an initial call to `reader.next`, or
    get each row as a `dict` (with the headers as keys) by using `csv.DictReader`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过初始调用`reader.next`跳过表头行，或者通过使用`csv.DictReader`将每一行作为`dict`（表头作为键）来获取：
- en: '[PRE14]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Even if your file doesn’t have headers, you can still use `DictReader` by passing
    it the keys as a `fieldnames` parameter.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你的文件没有表头，你仍然可以通过将键作为`fieldnames`参数传递给`DictReader`来使用它。
- en: 'You can similarly write out delimited data using `csv.writer`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用`csv.writer`类似地写出分隔数据：
- en: '[PRE15]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '`csv.writer` will do the right thing if your fields themselves have commas
    in them. Your own hand-rolled writer probably won’t. For example, if you attempt:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的字段本身包含逗号，`csv.writer`会处理得很好。但是，如果你自己手动编写的写入器可能不会。例如，如果你尝试：
- en: '[PRE16]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You will end up with a *.csv* file that looks like this:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你将会得到一个如下的*.csv*文件：
- en: '[PRE17]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: and that no one will ever be able to make sense of.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 而且没有人能够理解。
- en: Scraping the Web
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网页抓取
- en: Another way to get data is by scraping it from web pages. Fetching web pages,
    it turns out, is pretty easy; getting meaningful structured information out of
    them less so.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种获取数据的方式是从网页中抓取数据。事实证明，获取网页很容易；但从中获取有意义的结构化信息却不那么容易。
- en: HTML and the Parsing Thereof
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HTML及其解析
- en: 'Pages on the web are written in HTML, in which text is (ideally) marked up
    into elements and their attributes:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 网页是用HTML编写的，文本（理想情况下）被标记为元素及其属性：
- en: '[PRE18]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In a perfect world, where all web pages were marked up semantically for our
    benefit, we would be able to extract data using rules like “find the `<p>` element
    whose `id` is `subject` and return the text it contains.” In the actual world,
    HTML is not generally well formed, let alone annotated. This means we’ll need
    help making sense of it.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个完美的世界中，所有网页都会被语义化地标记，为了我们的利益。我们将能够使用诸如“查找`id`为`subject`的`<p>`元素并返回其包含的文本”之类的规则来提取数据。但实际上，HTML通常并不规范，更不用说注释了。这意味着我们需要帮助来理解它。
- en: To get data out of HTML, we will use the [Beautiful Soup library](http://www.crummy.com/software/BeautifulSoup/),
    which builds a tree out of the various elements on a web page and provides a simple
    interface for accessing them. As I write this, the latest version is Beautiful
    Soup 4.6.0, which is what we’ll be using. We’ll also be using the [Requests library](http://docs.python-requests.org/en/latest/),
    which is a much nicer way of making HTTP requests than anything that’s built into
    Python.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要从HTML中获取数据，我们将使用[Beautiful Soup库](http://www.crummy.com/software/BeautifulSoup/)，它会构建一个网页上各种元素的树，并提供一个简单的接口来访问它们。在我写这篇文章时，最新版本是Beautiful
    Soup 4.6.0，这也是我们将使用的版本。我们还将使用[Requests库](http://docs.python-requests.org/en/latest/)，这是一种比Python内置的任何东西都更好的方式来进行HTTP请求。
- en: Python’s built-in HTML parser is not that lenient, which means that it doesn’t
    always cope well with HTML that’s not perfectly formed. For that reason, we’ll
    also install the `html5lib` parser.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Python内置的HTML解析器并不那么宽容，这意味着它不能很好地处理不完全形式的HTML。因此，我们还将安装`html5lib`解析器。
- en: 'Making sure you’re in the correct virtual environment, install the libraries:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您处于正确的虚拟环境中，安装库：
- en: '[PRE19]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To use Beautiful Soup, we pass a string containing HTML into the `BeautifulSoup`
    function. In our examples, this will be the result of a call to `requests.get`:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Beautiful Soup，我们将一个包含HTML的字符串传递给`BeautifulSoup`函数。在我们的示例中，这将是对`requests.get`调用的结果：
- en: '[PRE20]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: after which we can get pretty far using a few simple methods.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用几种简单的方法走得相当远。
- en: We’ll typically work with `Tag` objects, which correspond to the tags representing
    the structure of an HTML page.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常会使用`Tag`对象，它对应于表示HTML页面结构的标签。
- en: 'For example, to find the first `<p>` tag (and its contents), you can use:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要找到第一个`<p>`标签（及其内容），您可以使用：
- en: '[PRE21]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You can get the text contents of a `Tag` using its `text` property:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用其`text`属性获取`Tag`的文本内容：
- en: '[PRE22]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'And you can extract a tag’s attributes by treating it like a `dict`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过将其视为`dict`来提取标签的属性：
- en: '[PRE23]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can get multiple tags at once as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按以下方式一次获取多个标签：
- en: '[PRE24]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Frequently, you’ll want to find tags with a specific `class`:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 经常，您会想要找到具有特定`class`的标签：
- en: '[PRE25]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'And you can combine these methods to implement more elaborate logic. For example,
    if you want to find every `<span>` element that is contained inside a `<div>`
    element, you could do this:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以结合这些方法来实现更复杂的逻辑。例如，如果你想找到每个包含在`<div>`元素内的`<span>`元素，你可以这样做：
- en: '[PRE26]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Just this handful of features will allow us to do quite a lot. If you end up
    needing to do more complicated things (or if you’re just curious), check the [documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这些功能的几个特点就足以让我们做很多事情。如果你最终需要做更复杂的事情（或者你只是好奇），请查阅[文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)。
- en: Of course, the important data won’t typically be labeled as `class="important"`.
    You’ll need to carefully inspect the source HTML, reason through your selection
    logic, and worry about edge cases to make sure your data is correct. Let’s look
    at an example.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，重要的数据通常不会标记为`class="important"`。您需要仔细检查源HTML，通过选择逻辑推理，并担心边缘情况，以确保数据正确。让我们看一个例子。
- en: 'Example: Keeping Tabs on Congress'
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 例如：监控国会
- en: The VP of Policy at DataSciencester is worried about potential regulation of
    the data science industry and asks you to quantify what Congress is saying on
    the topic. In particular, he wants you to find all the representatives who have
    press releases about “data.”
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: DataSciencester的政策副总裁担心数据科学行业可能会受到监管，并要求您量化国会在该主题上的言论。特别是，他希望您找出所有发表关于“数据”内容的代表。
- en: At the time of publication, there is a page with links to all of the representatives’
    websites at *[*https://www.house.gov/representatives*](https://www.house.gov/representatives)*.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在发布时，有一个页面链接到所有代表的网站，网址为[*https://www.house.gov/representatives*](https://www.house.gov/representatives)。
- en: 'And if you “view source,” all of the links to the websites look like:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果“查看源代码”，所有指向网站的链接看起来像：
- en: '[PRE27]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let’s start by collecting all of the URLs linked to from that page:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始收集从该页面链接到的所有URL：
- en: '[PRE28]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This returns way too many URLs. If you look at them, the ones we want start
    with either *http://* or *https://*, have some kind of name, and end with either
    *.house.gov* or *.house.gov/*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回了太多的URL。如果你查看它们，我们想要的URL以*http://*或*https://*开头，有一些名称，并且以*.house.gov*或*.house.gov/*结尾。
- en: 'This is a good place to use a regular expression:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用正则表达式的好地方：
- en: '[PRE29]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'That’s still way too many, as there are only 435 representatives. If you look
    at the list, there are a lot of duplicates. Let’s use `set` to get rid of them:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这仍然太多了，因为只有435位代表。如果你看一下列表，会发现很多重复。让我们使用`set`来去重：
- en: '[PRE30]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'There are always a couple of House seats empty, or maybe there’s a representative
    without a website. In any case, this is good enough. When we look at the sites,
    most of them have a link to press releases. For example:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 总会有几个众议院席位是空缺的，或者可能有一个没有网站的代表。无论如何，这已经足够了。当我们查看这些站点时，大多数都有一个指向新闻稿的链接。例如：
- en: '[PRE31]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Notice that this is a relative link, which means we need to remember the originating
    site. Let’s do some scraping:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这是一个相对链接，这意味着我们需要记住原始站点。让我们来做一些抓取：
- en: '[PRE32]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Normally it is impolite to scrape a site freely like this. Most sites will have
    a *robots.txt* file that indicates how frequently you may scrape the site (and
    which paths you’re not supposed to scrape), but since it’s Congress we don’t need
    to be particularly polite.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，自由地抓取一个网站是不礼貌的。大多数网站会有一个*robots.txt*文件，指示您可以多频繁地抓取该站点（以及您不应该抓取的路径），但由于涉及到国会，我们不需要特别礼貌。
- en: If you watch these as they scroll by, you’ll see a lot of */media/press-releases*
    and *media-center/press-releases*, as well as various other addresses. One of
    these URLs is *[*https://jayapal.house.gov/media/press-releases*](https://jayapal.house.gov/media/press-releases)*.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看这些内容滚动显示，你会看到很多`/media/press-releases`和`media-center/press-releases`，以及各种其他地址。其中一个URL是[*https://jayapal.house.gov/media/press-releases*](https://jayapal.house.gov/media/press-releases)。
- en: Remember that our goal is to find out which congresspeople have press releases
    mentioning “data.” We’ll write a slightly more general function that checks whether
    a page of press releases mentions any given term.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们的目标是找出哪些国会议员在其新闻稿中提到了“数据”。我们将编写一个稍微更通用的函数，检查新闻稿页面是否提到了任何给定的术语。
- en: 'If you visit the site and view the source, it seems like there’s a snippet
    from each press release inside a `<p>` tag, so we’ll use that as our first attempt:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你访问该网站并查看源代码，似乎每篇新闻稿都有一个在`<p>`标签中的片段，所以我们将用它作为我们的第一个尝试：
- en: '[PRE33]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s write a quick test for it:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为此写一个快速的测试：
- en: '[PRE34]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'At last we’re ready to find the relevant congresspeople and give their names
    to the VP:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们准备好找到相关的国会议员，并把他们的名字交给副总裁：
- en: '[PRE35]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: When I run this I get a list of about 20 representatives. Your results will
    probably be different.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当我运行这个时，我得到了大约20位代表的列表。你的结果可能会有所不同。
- en: Note
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you look at the various “press releases” pages, most of them are paginated
    with only 5 or 10 press releases per page. This means that we only retrieved the
    few most recent press releases for each congressperson. A more thorough solution
    would have iterated over the pages and retrieved the full text of each press release.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看各种“新闻稿”页面，大多数页面都是分页的，每页只有5或10篇新闻稿。这意味着我们只检索了每位国会议员最近的几篇新闻稿。更彻底的解决方案将迭代每一页，并检索每篇新闻稿的全文。
- en: Using APIs
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用API
- en: Many websites and web services provide *application programming interfaces*
    (APIs), which allow you to explicitly request data in a structured format. This
    saves you the trouble of having to scrape them!
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 许多网站和Web服务提供*应用程序编程接口*（API），允许您以结构化格式显式请求数据。这样可以避免您必须进行抓取的麻烦！
- en: JSON and XML
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JSON和XML
- en: 'Because HTTP is a protocol for transferring *text*, the data you request through
    a web API needs to be *serialized* into a string format. Often this serialization
    uses *JavaScript Object Notation* (JSON). JavaScript objects look quite similar
    to Python `dict`s, which makes their string representations easy to interpret:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因为HTTP是一个用于传输*文本*的协议，通过Web API请求的数据需要被*序列化*为字符串格式。通常这种序列化使用*JavaScript对象表示法*（JSON）。JavaScript对象看起来非常类似于Python的`dict`，这使得它们的字符串表示易于解释：
- en: '[PRE36]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We can parse JSON using Python’s `json` module. In particular, we will use
    its `loads` function, which deserializes a string representing a JSON object into
    a Python object:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Python的`json`模块解析JSON。特别地，我们将使用它的`loads`函数，将表示JSON对象的字符串反序列化为Python对象：
- en: '[PRE37]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Sometimes an API provider hates you and provides only responses in XML:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 有时API提供者会讨厌你，并且只提供XML格式的响应：
- en: '[PRE38]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: You can use Beautiful Soup to get data from XML similarly to how we used it
    to get data from HTML; check its documentation for details.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以像从HTML中获取数据那样，使用Beautiful Soup从XML中获取数据；请查看其文档以获取详细信息。
- en: Using an Unauthenticated API
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用未经身份验证的API
- en: 'Most APIs these days require that you first authenticate yourself before you
    can use them. While we don’t begrudge them this policy, it creates a lot of extra
    boilerplate that muddies up our exposition. Accordingly, we’ll start by taking
    a look at [GitHub’s API](http://developer.github.com/v3/), with which you can
    do some simple things unauthenticated:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数API现在要求你先进行身份验证，然后才能使用它们。虽然我们不反对这种策略，但这会产生很多额外的样板代码，使我们的解释变得混乱。因此，我们将首先看一下[GitHub的API](http://developer.github.com/v3/)，它可以让你无需身份验证就能进行一些简单的操作：
- en: '[PRE39]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: At this point `repos` is a `list` of Python `dict`s, each representing a public
    repository in my GitHub account. (Feel free to substitute your username and get
    your GitHub repository data instead. You do have a GitHub account, right?)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此时`repos`是我GitHub账户中的公共仓库的Python `dict`列表。（随意替换你的用户名并获取你的GitHub仓库数据。你有GitHub账户，对吧？）
- en: 'We can use this to figure out which months and days of the week I’m most likely
    to create a repository. The only issue is that the dates in the response are strings:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用这个来找出我最有可能创建仓库的月份和星期几。唯一的问题是响应中的日期是字符串：
- en: '[PRE40]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Python doesn’t come with a great date parser, so we’ll need to install one:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Python自带的日期解析器不是很好用，所以我们需要安装一个：
- en: '[PRE41]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'from which you’ll probably only ever need the `dateutil.parser.parse` function:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 其中你可能只会需要`dateutil.parser.parse`函数：
- en: '[PRE42]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Similarly, you can get the languages of my last five repositories:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，你可以获取我最近五个仓库的语言：
- en: '[PRE43]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Typically we won’t be working with APIs at this low “make the requests and parse
    the responses ourselves” level. One of the benefits of using Python is that someone
    has already built a library for pretty much any API you’re interested in accessing.
    When they’re done well, these libraries can save you a lot of the trouble of figuring
    out the hairier details of API access. (When they’re not done well, or when it
    turns out they’re based on defunct versions of the corresponding APIs, they can
    cause you enormous headaches.)
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们不会在低层次（“自己发起请求并解析响应”）处理API。使用Python的好处之一是，几乎任何你有兴趣访问的API，都已经有人建立了一个库。如果做得好，这些库可以节省你很多访问API的复杂细节的麻烦。（如果做得不好，或者当它们基于已失效的API版本时，可能会带来巨大的麻烦。）
- en: Nonetheless, you’ll occasionally have to roll your own API access library (or,
    more likely, debug why someone else’s isn’t working), so it’s good to know some
    of the details.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，偶尔你会需要自己编写API访问库（或者更有可能，调试为什么别人的库不起作用），因此了解一些细节是很有用的。
- en: Finding APIs
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找API
- en: If you need data from a specific site, look for a “developers” or “API” section
    of the site for details, and try searching the web for “python <sitename> api”
    to find a library.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要从特定网站获取数据，请查找该网站的“开发者”或“API”部分以获取详细信息，并尝试在网上搜索“python <sitename> api”来找到相应的库。
- en: There are libraries for the Yelp API, for the Instagram API, for the Spotify
    API, and so on.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Yelp API、Instagram API、Spotify API等等，都有相应的库。
- en: If you’re looking for a list of APIs that have Python wrappers, there’s a nice
    one from [Real Python on GitHub](https://github.com/realpython/list-of-python-api-wrappers).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在寻找Python封装的API列表，[Real Python在GitHub上](https://github.com/realpython/list-of-python-api-wrappers)有一个很好的列表。
- en: And if you can’t find what you need, there’s always scraping, the last refuge
    of the data scientist.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果找不到你需要的内容，总有一种方法，那就是网页抓取，数据科学家的最后避风港。
- en: 'Example: Using the Twitter APIs'
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例：使用Twitter的API
- en: Twitter is a fantastic source of data to work with. You can use it to get real-time
    news. You can use it to measure reactions to current events. You can use it to
    find links related to specific topics. You can use it for pretty much anything
    you can imagine, just as long as you can get access to its data. And you can get
    access to its data through its APIs.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter是一个非常好的数据来源。你可以用它来获取实时新闻，也可以用它来衡量对当前事件的反应。你还可以用它来查找与特定主题相关的链接。你可以用它来做几乎任何你能想到的事情，只要你能访问到它的数据。通过它的API，你可以获取到它的数据。
- en: To interact with the Twitter APIs, we’ll be using the [Twython library](https://github.com/ryanmcgrath/twython)
    (`python -m pip install twython`). There are quite a few Python Twitter libraries
    out there, but this is the one that I’ve had the most success working with. You
    are encouraged to explore the others as well!
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 要与Twitter的API交互，我们将使用[Twython库](https://github.com/ryanmcgrath/twython)（`python
    -m pip install twython`）。目前有许多Python Twitter库，但这是我使用最成功的一个。当然，也鼓励你探索其他库！
- en: Getting Credentials
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取凭证
- en: 'In order to use Twitter’s APIs, you need to get some credentials (for which
    you need a Twitter account, which you should have anyway so that you can be part
    of the lively and friendly Twitter #datascience community).'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '为了使用 Twitter 的 API，你需要获取一些凭据（你需要一个 Twitter 帐户，这样你就可以成为活跃且友好的 Twitter #datascience
    社区的一部分）。'
- en: Warning
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Like all instructions that relate to websites that I don’t control, these may
    become obsolete at some point but will hopefully work for a while. (Although they
    have already changed multiple times since I originally started writing this book,
    so good luck!)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 像所有与我无法控制的网站相关的说明一样，这些说明可能在某个时候过时，但希望能够一段时间内工作。（尽管自我最初开始写这本书以来，它们已经多次发生变化，所以祝你好运！）
- en: 'Here are the steps:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是步骤：
- en: Go to [*https://developer.twitter.com/*](https://developer.twitter.com/).
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往 [*https://developer.twitter.com/*](https://developer.twitter.com/)。
- en: If you are not signed in, click “Sign in” and enter your Twitter username and
    password.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你没有登录，点击“登录”并输入你的 Twitter 用户名和密码。
- en: Click Apply to apply for a developer account.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击申请以申请开发者帐户。
- en: Request access for your own personal use.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为你自己的个人使用请求访问。
- en: Fill out the application. It requires 300 words (really) on why you need access,
    so to get over the limit you could tell them about this book and how much you’re
    enjoying it.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填写申请。 它需要 300 字（真的）解释为什么你需要访问，所以为了超过限制，你可以告诉他们关于这本书以及你有多么喜欢它。
- en: Wait some indefinite amount of time.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待一段不确定的时间。
- en: If you know someone who works at Twitter, email them and ask them if they can
    expedite your application. Otherwise, keep waiting.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你认识在 Twitter 工作的人，请给他们发电子邮件，询问他们是否可以加快你的申请。 否则，继续等待。
- en: Once you get approved, go back to [developer.twitter.com](https://developer.twitter.com/),
    find the “Apps” section, and click “Create an app.”
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你获得批准，返回到 [developer.twitter.com](https://developer.twitter.com/)，找到“Apps”部分，然后点击“创建应用程序”。
- en: Fill out all the required fields (again, if you need extra characters for the
    description, you could talk about this book and how edifying you’re finding it).
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填写所有必填字段（同样，如果你需要描述的额外字符，你可以谈论这本书以及你发现它多么有启发性）。
- en: Click CREATE.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击创建。
- en: Now your app should have a “Keys and tokens” tab with a “Consumer API keys”
    section that lists an “API key” and an “API secret key.” Take note of those keys;
    you’ll need them. (Also, keep them secret! They’re like passwords.)
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你的应用程序应该有一个“Keys and tokens”选项卡，其中包含一个“Consumer API keys”部分，列出了一个“API key”和一个“API
    secret key”。 记下这些密钥； 你会需要它们。（另外，保持它们保密！ 它们就像密码。）
- en: Caution
  id: totrans-165
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小心
- en: Don’t share the keys, don’t publish them in your book, and don’t check them
    into your public GitHub repository. One simple solution is to store them in a
    *credentials.json* file that doesn’t get checked in, and to have your code use
    `json.loads` to retrieve them. Another solution is to store them in environment
    variables and use `os.environ` to retrieve them.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 不要分享密钥，不要在书中发布它们，也不要将它们检入你的公共 GitHub 存储库。 一个简单的解决方案是将它们存储在一个不会被检入的 *credentials.json*
    文件中，并让你的代码使用 `json.loads` 来检索它们。 另一个解决方案是将它们存储在环境变量中，并使用 `os.environ` 来检索它们。
- en: Using Twython
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Twython
- en: The trickiest part of using the Twitter API is authenticating yourself. (Indeed,
    this is the trickiest part of using a lot of APIs.) API providers want to make
    sure that you’re authorized to access their data and that you don’t exceed their
    usage limits. They also want to know who’s accessing their data.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Twitter API 的最棘手的部分是验证身份。（事实上，这是使用许多 API 中最棘手的部分之一。） API 提供商希望确保你被授权访问他们的数据，并且你不会超出他们的使用限制。
    他们还想知道谁在访问他们的数据。
- en: Authentication is kind of a pain. There is a simple way, OAuth 2, that suffices
    when you just want to do simple searches. And there is a complex way, OAuth 1,
    that’s required when you want to perform actions (e.g., tweeting) or (in particular
    for us) connect to the Twitter stream.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 认证有点痛苦。 有一种简单的方法，OAuth 2，在你只想做简单搜索时足够使用。 还有一种复杂的方法，OAuth 1，在你想执行操作（例如，发推文）或（特别是对我们来说）连接到
    Twitter 流时需要使用。
- en: So we’re stuck with the more complicated way, which we’ll try to automate as
    much as we can.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们被迫使用更复杂的方式，我们会尽可能自动化它。
- en: 'First, you need your API key and API secret key (sometimes known as the consumer
    key and consumer secret, respectively). I’ll be getting mine from environment
    variables, but feel free to substitute in yours however you wish:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要你的 API 密钥和 API 密钥（有时也称为消费者密钥和消费者密钥）。 我将从环境变量中获取我的，但请随意以任何你希望的方式替换你的：
- en: '[PRE44]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now we can instantiate the client:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以实例化客户端：
- en: '[PRE45]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Tip
  id: totrans-175
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: At this point you may want to consider saving the `ACCESS_TOKEN` and `ACCESS_TOKEN_SECRET`
    somewhere safe, so that next time you don’t have to go through this rigmarole.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你可能希望考虑将`ACCESS_TOKEN`和`ACCESS_TOKEN_SECRET`保存在安全的地方，这样下次你就不必再经历这个烦琐的过程了。
- en: 'Once we have an authenticated `Twython` instance, we can start performing searches:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了一个经过身份验证的`Twython`实例，我们就可以开始执行搜索：
- en: '[PRE46]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'If you run this, you should get some tweets back like:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行这个程序，你应该会得到一些推文，比如：
- en: '[PRE47]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This isn’t that interesting, largely because the Twitter Search API just shows
    you whatever handful of recent results it feels like. When you’re doing data science,
    more often you want a lot of tweets. This is where the [Streaming API](https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data)
    is useful. It allows you to connect to (a sample of) the great Twitter firehose.
    To use it, you’ll need to authenticate using your access tokens.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不那么有趣，主要是因为Twitter搜索API只会显示出它觉得最近的结果。在进行数据科学时，更多时候你会想要大量的推文。这就是[Streaming
    API](https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data)有用的地方。它允许你连接到（部分）巨大的Twitter
    firehose。要使用它，你需要使用你的访问令牌进行身份验证。
- en: 'In order to access the Streaming API with Twython, we need to define a class
    that inherits from `TwythonStreamer` and that overrides its `on_success` method,
    and possibly its `on_error` method:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用Twython访问Streaming API，我们需要定义一个类，该类继承自`TwythonStreamer`并重写其`on_success`方法，可能还有其`on_error`方法：
- en: '[PRE48]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '`MyStreamer` will connect to the Twitter stream and wait for Twitter to feed
    it data. Each time it receives some data (here, a tweet represented as a Python
    object), it passes it to the `on_success` method, which appends it to our `tweets`
    list if its language is English, and then disconnects the streamer after it’s
    collected 1,000 tweets.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`MyStreamer`将连接到Twitter流并等待Twitter提供数据。每次接收到一些数据（在这里是表示为Python对象的推文）时，它都会将其传递给`on_success`方法，如果推文的语言是英语，则将其追加到我们的`tweets`列表中，然后在收集到1,000条推文后断开流。'
- en: 'All that’s left is to initialize it and start it running:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一剩下的就是初始化它并开始运行：
- en: '[PRE49]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'This will run until it collects 100 tweets (or until it encounters an error)
    and stop, at which point you can start analyzing those tweets. For instance, you
    could find the most common hashtags with:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这将持续运行，直到收集到100条推文（或遇到错误为止），然后停止，此时你可以开始分析这些推文。例如，你可以找出最常见的标签：
- en: '[PRE50]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Each tweet contains a lot of data. You can either poke around yourself or dig
    through the [Twitter API documentation](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 每条推文都包含大量的数据。你可以自己探索，或者查看[Twitter API文档](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object)。
- en: Note
  id: totrans-190
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In a non-toy project, you probably wouldn’t want to rely on an in-memory `list`
    for storing the tweets. Instead you’d want to save them to a file or a database,
    so that you’d have them permanently.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个非玩具项目中，你可能不想依赖于内存中的`list`来存储推文。相反，你可能想把它们保存到文件或数据库中，这样你就能永久地拥有它们。
- en: For Further Exploration
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步探索
- en: '[pandas](http://pandas.pydata.org/) is the primary library that data science
    types use for working with—and, in particular, importing—data.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pandas](http://pandas.pydata.org/)是数据科学家们用来处理数据，特别是导入数据的主要库。'
- en: '[Scrapy](http://scrapy.org/) is a full-featured library for building complicated
    web scrapers that do things like follow unknown links.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Scrapy](http://scrapy.org/)是一个用于构建复杂网络爬虫的全功能库，可以执行诸如跟踪未知链接等操作。'
- en: '[Kaggle](https://www.kaggle.com/datasets) hosts a large collection of datasets.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kaggle](https://www.kaggle.com/datasets)拥有大量的数据集。'
