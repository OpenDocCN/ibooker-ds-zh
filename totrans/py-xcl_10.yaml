- en: Chapter 7\. Excel File Manipulation with pandas
  prefs: []
  type: TYPE_NORMAL
- en: 'After six chapters of intense introductions to tools, Python, and pandas, I
    will give you a break and start this chapter with a practical case study that
    allows you to put your newly acquired skills to good use: with just ten lines
    of pandas code, you will consolidate dozens of Excel files into an Excel report,
    ready to be sent to your managers. After the case study, I’ll give you a more
    in-depth introduction to the tools that pandas offers to work with Excel files:
    the `read_excel` function and the `ExcelFile` class for reading, and the `to_excel`
    method and the `ExcelWriter` class for writing Excel files. pandas does not rely
    on the Excel application to read and write Excel files, which means that all code
    samples in this chapter run everywhere Python runs, including Linux.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Case Study: Excel Reporting'
  prefs: []
  type: TYPE_NORMAL
- en: 'This case study is inspired by a few real-world reporting projects I was involved
    in over the last few years. Even though the projects took place in completely
    different industries—including telecommunication, digital marketing, and finance—they
    were still remarkably similar: the starting point is usually a directory with
    Excel files that need to be processed into an Excel report—often on a monthly,
    weekly, or daily basis. In the companion repository, in the sales_data directory,
    you will find Excel files with fictitious sales transactions for a telecommunication
    provider selling different plans (Bronze, Silver, Gold) in a few stores throughout
    the United States. For every month, there are two files, one in the new subfolder
    for new contracts and one in the existing subfolder for existing customers. As
    the reports come from different systems, they come in different formats: the new
    customers are delivered as xlsx files, while the existing customers arrive in
    the older xls format. Each of the files has up to 10,000 transactions, and our
    goal is to produce an Excel report that shows the total sales per store and month.
    To get started, let’s have a look at the January.xlsx file from the new subfolder
    in [Figure 7-1](#filepos865924).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/00080.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. The first few rows of January.xlsx
  prefs: []
  type: TYPE_NORMAL
- en: 'The Excel files in the existing subfolder look practically the same, except
    that they are missing the `status` column and are stored in the legacy xls format.
    As a first step, let’s read the new transactions from January with pandas’ `read_excel`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``1``]:``import``pandas``as``pd`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``2``]:``df``=``pd``.``read_excel``(``"sales_data/new/January.xlsx"``)``df``.``info``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`<class ''pandas.core.frame.DataFrame''> RangeIndex: 9493 entries, 0 to 9492
    Data columns (total 7 columns): #   Column            Non-Null Count  Dtype --- 
    ------            --------------  ----- 0   transaction_id    9493 non-null  
    object 1   store             9493 non-null   object 2   status            9493
    non-null   object 3   transaction_date  9493 non-null   datetime64[ns] 4   plan             
    9493 non-null   object 5   contract_type     9493 non-null   object 6   amount           
    9493 non-null   float64 dtypes: datetime64[ns](1), float64(1), object(5) memory
    usage: 519.3+ KB`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: THE READ_EXCEL FUNCTION WITH PYTHON 3.9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is the same warning as in [Chapter 5](index_split_015.html#filepos482650):
    if you are running `pd.read_excel` with Python 3.9 or above, make sure to use
    at least pandas 1.2 or you will get an error when reading xlsx files.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As you can see, pandas has properly recognized the data types of all columns,
    including the date format of `transaction_date`. This allows us to work with the
    data without further preparation. As this sample is deliberately simple, we can
    move on with creating a short script called sales_report_pandas.py as shown in
    [Example 7-1](#filepos871029). This script will read in all Excel files from both
    directories, aggregate the data, and write the summary table into a new Excel
    file. Use VS Code to write the script yourself, or open it from the companion
    repository. For a refresher on how to create or open files in VS Code, have another
    look at [Chapter 2](index_split_008.html#filepos96824). If you create it yourself,
    make sure to place it next to the sales_data folder—this will allow you to run
    the script without having to adjust any file paths.
  prefs: []
  type: TYPE_NORMAL
- en: Example 7-1\. sales_report_pandas.py
  prefs: []
  type: TYPE_NORMAL
- en: '`from``pathlib``import``Path``import``pandas``as``pd``# Directory of this file``this_dir``=``Path``(``__file__``)``.``resolve``()``.``parent`![](images/00031.jpg)`#
    Read in all Excel files from all subfolders of sales_data``parts``=``[]``for``path``in``(``this_dir``/``"sales_data"``)``.``rglob``(``"*.xls*"``):`![](images/00039.jpg)`print``(``f``''Reading
    {path.name}''``)``part``=``pd``.``read_excel``(``path``,``index_col``=``"transaction_id"``)``parts``.``append``(``part``)``#
    Combine the DataFrames from each file into a single DataFrame``# pandas takes
    care of properly aligning the columns``df``=``pd``.``concat``(``parts``)``# Pivot
    each store into a column and sum up all transactions per date``pivot``=``pd``.``pivot_table``(``df``,``index``=``"transaction_date"``,``columns``=``"store"``,``values``=``"amount"``,``aggfunc``=``"sum"``)``#
    Resample to end of month and assign an index name``summary``=``pivot``.``resample``(``"M"``)``.``sum``()``summary``.``index``.``name``=``"Month"``#
    Write summary report to Excel file``summary``.``to_excel``(``this_dir``/``"sales_report_pandas.xlsx"``)`'
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/00031.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Up to this chapter, I was using strings to specify file paths. By using the
    `Path` class from the standard library’s `pathlib` module instead, you get access
    to a powerful set of tools: path objects enable you to easily construct paths
    by concatenating individual parts via forward slashes, as it’s done four lines
    below with `this_dir / "sales_data"`. These paths work across platforms and allow
    you to apply filters like `rglob` as explained under the next point. `__file__`
    resolves to the path of the source code file when you run it—using its `parent`
    will give you therefore the name of the directory of this file. The `resolve`
    method that we use before calling `parent` turns the path into an absolute path.
    If you would run this from a Jupyter notebook instead, you would have to replace
    this line with `this_dir = Path(".").resolve()`, with the dot representing the
    current directory. In most cases, functions and classes that accept a path in
    the form of a string also accept a path object.'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](images/00039.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The easiest way to read in all Excel files recursively from within a certain
    directory is to use the `rglob` method of the path object. `glob` is short for
    globbing, which refers to pathname expansion using wildcards. The `?` wildcard
    represents exactly one character, while `*` stands for any number of characters
    (including zero). The r in `rglob` means recursive globbing, i.e., it will look
    for matching files across all subdirectories—accordingly, `glob` would ignore
    subdirectories. Using `*.xls*` as the globbing expression makes sure that the
    old and new Excel files are found, as it matches both `.xls` and `.xlsx`. It’s
    usually a good idea to slightly enhance the expression like this: `[!~$]*.xls*`.
    This ignores temporary Excel files (their file name starts with `~$`). For more
    background on how to use globbing in Python, see the [Python docs](https://oreil.ly/fY0qG).'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Run the script, for example, by clicking the Run File button at the top right
    of VS Code. The script will take a moment to complete and once done, the Excel
    workbook sales_report_pandas.xlsx will show up in the same directory as the script.
    The content of Sheet1 should look like in [Figure 7-2](#filepos884738). That’s
    quite an impressive result for only ten lines of code—even if you will need to
    adjust the width of the first column to be able to see the dates!
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/00005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-2\. sales_report_pandas.xlsx (as-is, without adjusting any column width)
  prefs: []
  type: TYPE_NORMAL
- en: For simple cases like this one, pandas offers a really easy solution to work
    with Excel files. However, we can do much better—after all, a title, some formatting
    (including column width and a consistent number of decimals), and a chart wouldn’t
    hurt. That’s exactly what we will take care of in the next chapter by directly
    using the writer libraries that pandas uses under the hood. Before we get there,
    however, let’s have a more detailed look at how we can read and write Excel files
    with pandas.
  prefs: []
  type: TYPE_NORMAL
- en: Reading and Writing Excel Files with pandas
  prefs: []
  type: TYPE_NORMAL
- en: The case study was using `read_excel` and `to_excel` with their default arguments
    to keep things simple. In this section, I will show you the most commonly used
    arguments and options when reading and writing Excel files with pandas. We’ll
    start with the `read_excel` function and the `ExcelFile` class before looking
    at the `to_excel` method and the `ExcelWriter` class. Along the way, I’ll also
    introduce Python’s `with` statement.
  prefs: []
  type: TYPE_NORMAL
- en: The read_excel Function and ExcelFile Class
  prefs: []
  type: TYPE_NORMAL
- en: The case study used Excel workbooks where the data was conveniently in cell
    A1 of the first sheet. In reality, your Excel files are probably not so well organized.
    In this case, pandas offers parameters to fine-tune the reading process. For the
    next few samples, we’re going to use the stores.xlsx file that you will find in
    the xl folder of the companion repository. The first sheet is shown in [Figure 7-3](#filepos886927).
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/00012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-3\. The first sheet of stores.xlsx
  prefs: []
  type: TYPE_NORMAL
- en: 'By using the parameters `sheet_name`, `skiprows`, and `usecols`, we can tell
    pandas about the cell range that we want to read in. As usual, it’s a good idea
    to have a look at the data types of the returned DataFrame by running the `info`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``3``]:``df``=``pd``.``read_excel``(``"xl/stores.xlsx"``,``sheet_name``=``"2019"``,``skiprows``=``1``,``usecols``=``"B:F"``)``df`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[3]:            Store  Employees    Manager      Since Flagship        
    0       New York         10      Sarah 2018-07-20    False         1  San Francisco        
    12     Neriah 2019-11-02  MISSING         2        Chicago          4    Katelin
    2020-01-31      NaN         3         Boston          5  Georgiana 2017-04-01    
    True         4  Washington DC          3       Evan        NaT    False        
    5      Las Vegas         11       Paul 2020-01-06    False`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``4``]:``df``.``info``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`<class ''pandas.core.frame.DataFrame''> RangeIndex: 6 entries, 0 to 5 Data
    columns (total 5 columns): #   Column     Non-Null Count  Dtype ---  ------    
    --------------  ----- 0   Store      6 non-null      object 1   Employees  6 non-null     
    int64 2   Manager    6 non-null      object 3   Since      5 non-null      datetime64[ns]
    4   Flagship   5 non-null      object dtypes: datetime64[ns](1), int64(1), object(3)
    memory usage: 368.0+ bytes`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Everything looks good except for the `Flagship` column—its data type should
    be `bool` rather than `object`. To fix this, we can provide a converter function
    that deals with the offensive cells in that column (instead of writing the `fix_missing`
    function, we could have also provided a lambda expression instead):'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``5``]:``def``fix_missing``(``x``):``return``False``if``x``in``[``""``,``"MISSING"``]``else``x`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``6``]:``df``=``pd``.``read_excel``(``"xl/stores.xlsx"``,``sheet_name``=``"2019"``,``skiprows``=``1``,``usecols``=``"B:F"``,``converters``=``{``"Flagship"``:``fix_missing``})``df`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[6]:            Store  Employees    Manager      Since  Flagship        
    0       New York         10      Sarah 2018-07-20     False         1  San Francisco        
    12     Neriah 2019-11-02     False         2        Chicago          4    Katelin
    2020-01-31     False         3         Boston          5  Georgiana 2017-04-01     
    True         4  Washington DC          3       Evan        NaT     False        
    5      Las Vegas         11       Paul 2020-01-06     False`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``7``]:``# The Flagship column now has Dtype "bool"``df``.``info``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`<class ''pandas.core.frame.DataFrame''> RangeIndex: 6 entries, 0 to 5 Data
    columns (total 5 columns): #   Column     Non-Null Count  Dtype ---  ------    
    --------------  ----- 0   Store      6 non-null      object 1   Employees  6 non-null     
    int64 2   Manager    6 non-null      object 3   Since      5 non-null      datetime64[ns]
    4   Flagship   6 non-null      bool dtypes: bool(1), datetime64[ns](1), int64(1),
    object(2) memory usage: 326.0+ bytes`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The `read_excel` function also accepts a list of sheet names. In this case,
    it returns a dictionary with the DataFrame as value and the name of the sheet
    as key. To read in all sheets, you would need to provide `sheet_name=None`. Also,
    note the slight variation of how I am using `usecols` by providing the column
    names of the table:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``8``]:``sheets``=``pd``.``read_excel``(``"xl/stores.xlsx"``,``sheet_name``=``[``"2019"``,``"2020"``],``skiprows``=``1``,``usecols``=``[``"Store"``,``"Employees"``])``sheets``[``"2019"``]``.``head``(``2``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[8]:            Store  Employees         0       New York         10        
    1  San Francisco         12`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If the source file doesn’t have column headers, set `header=None` and provide
    them via `names`. Note that `sheet_name` also accepts sheet indices:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``9``]:``df``=``pd``.``read_excel``(``"xl/stores.xlsx"``,``sheet_name``=``0``,``skiprows``=``2``,``skipfooter``=``3``,``usecols``=``"B:C,F"``,``header``=``None``,``names``=``[``"Branch"``,``"Employee_Count"``,``"Is_Flagship"``])``df`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[9]:           Branch  Employee_Count Is_Flagship         0       New York             
    10       False         1  San Francisco              12     MISSING         2       
    Chicago               4         NaN`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'To handle `NaN` values, use a combination of `na_values` and `keep_default_na`.
    The next sample tells pandas to only interpret cells with the word `MISSING` as
    `NaN` and nothing else:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``10``]:``df``=``pd``.``read_excel``(``"xl/stores.xlsx"``,``sheet_name``=``"2019"``,``skiprows``=``1``,``usecols``=``"B,C,F"``,``skipfooter``=``2``,``na_values``=``"MISSING"``,``keep_default_na``=``False``)``df`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[10]:            Store  Employees Flagship          0       New York        
    10    False          1  San Francisco         12      NaN          2        Chicago         
    4          3         Boston          5     True`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'pandas offers an alternative way to read Excel files by using the `ExcelFile`
    class. This mostly makes a difference if you want to read in multiple sheets from
    a file in the legacy xls format: in this case, using `ExcelFile` will be faster
    as it prevents pandas from reading in the whole file multiple times. `ExcelFile`
    can be used as a context manager (see sidebar) so the file is properly closed
    again.'
  prefs: []
  type: TYPE_NORMAL
- en: CONTEXT MANAGERS AND THE WITH STATEMENT
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'First of all, the `with` statement in Python doesn’t have anything to do with
    the `With` statement in VBA: in VBA, it is used to run a series of statements
    on the same object, while in Python, it is used to manage resources like files
    or database connections. If you want to load the latest sales data to be able
    to analyze it, you may have to open a file or establish a connection to a database.
    After you’re done reading the data, it’s best practice to close the file or connection
    as soon as possible again. Otherwise, you may run into situations where you can’t
    open another file or can’t establish another connection to the database—file handlers
    and database connections are limited resources. Opening and closing a text file
    manually works like this (`w` stands for opening the file in `write` mode, which
    replaces the file if it already exists):'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``11``]:``f``=``open``(``"output.txt"``,``"w"``)``f``.``write``(``"Some
    text"``)``f``.``close``()`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Running this code will create a file called output.txt in the same directory
    as the notebook you are running it from and write “some text” to it. To read a
    file, you would use `r` instead of `w`, and to append to the end of the file,
    use `a`. Since files can also be manipulated from outside of your program, such
    an operation could fail. You could handle this by using the try/except mechanism
    that I will introduce in [Chapter 11](index_split_027.html#filepos1487255). However,
    since this is such a common operation, Python is providing the `with` statement
    to make things easier:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``12``]:``with``open``(``"output.txt"``,``"w"``)``as``f``:``f``.``write``(``"Some
    text"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When code execution leaves the body of the `with` statement, the file is automatically
    closed, whether or not there is an exception happening. This guarantees that the
    resources are properly cleaned up. Objects that support the `with` statement are
    called context managers; this includes the `ExcelFile` and `ExcelWriter` objects
    in this chapter, as well as database connection objects that we will look at in
    [Chapter 11](index_split_027.html#filepos1487255).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Let’s see the `ExcelFile` class in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``13``]:``with``pd``.``ExcelFile``(``"xl/stores.xls"``)``as``f``:``df1``=``pd``.``read_excel``(``f``,``"2019"``,``skiprows``=``1``,``usecols``=``"B:F"``,``nrows``=``2``)``df2``=``pd``.``read_excel``(``f``,``"2020"``,``skiprows``=``1``,``usecols``=``"B:F"``,``nrows``=``2``)``df1`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[13]:            Store  Employees Manager      Since Flagship         
    0       New York         10   Sarah 2018-07-20    False          1  San Francisco        
    12  Neriah 2019-11-02  MISSING`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`ExcelFile` also gives you access to the names of all sheets:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``14``]:``stores``=``pd``.``ExcelFile``(``"xl/stores.xlsx"``)``stores``.``sheet_names`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[14]: [''2019'', ''2020'', ''2019-2020'']`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Finally, pandas allows you to read Excel files from a URL, similar to how we
    did it with CSV files in [Chapter 5](index_split_015.html#filepos482650). Let’s
    read it directly from the companion repo:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``15``]:``url``=``(``"https://raw.githubusercontent.com/fzumstein/"``"python-for-excel/1st-edition/xl/stores.xlsx"``)``pd``.``read_excel``(``url``,``skiprows``=``1``,``usecols``=``"B:E"``,``nrows``=``2``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[15]:            Store  Employees Manager      Since          0       New
    York         10   Sarah 2018-07-20          1  San Francisco         12  Neriah
    2019-11-02`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: READING XLSB FILES VIA PANDAS
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you use pandas with a version below 1.3, reading xlsb files requires you
    to explicitly specify the engine in the `read_excel` function or `ExcelFile` class:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`pd``.``read_excel``(``"xl/stores.xlsb"``,``engine``=``"pyxlsb"``)`'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: This requires the pyxlsb package to be installed, as it isn’t part of Anaconda—we’ll
    get to that as well as to the other engines in the next chapter.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To summarize, [Table 7-1](#filepos927326) shows you the most commonly used `read_excel`
    parameters. You will find the complete list in the [official docs](https://oreil.ly/v8Yes).
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-1\. Selected parameters for read_excel
  prefs: []
  type: TYPE_NORMAL
- en: '|  Parameter  |  Description  |'
  prefs: []
  type: TYPE_TB
- en: '|   `sheet_name` |  Instead of providing a sheet name, you could also provide
    the index of the sheet (zero-based), e.g.,  `sheet_name=0`. If you set `sheet_name=None`,
    pandas will read the whole workbook and return a dictionary in the form of `{"sheetname":
    df}`. To read a selection of sheets, provide a list with sheet names or indices.
    |'
  prefs: []
  type: TYPE_TB
- en: '|   `skiprows` |  This allows you to skip over the indicated number of rows. 
    |'
  prefs: []
  type: TYPE_TB
- en: '|   `usecols` |  If the Excel file includes the names of the column headers,
    provide them in a list to select the columns, e.g.,  `["Store", "Employees"]`.
    Alternatively, it can also be a list of column indices, e.g., `[1, 2]`, or a string
    (not a list!) of Excel column names, including ranges, e.g., `"B:D,G"`. You can
    also provide a function: as an example, to only include the columns that start
    with `Manager`, use: `usecols=lambda x: x.startswith("Manager")`. |'
  prefs: []
  type: TYPE_TB
- en: '|   `nrows` |  Number of rows you want to read.  |'
  prefs: []
  type: TYPE_TB
- en: '|   `index_col` |  Indicates which column should be the index, accepts a column
    name or an index, e.g.,  `index_col=0`. If you provide a list with multiple columns,
    a hierarchical index will be created. |'
  prefs: []
  type: TYPE_TB
- en: '|   `header` |  If you set  `header=None`, the default integer headers are
    assigned except if you provide the desired names via the `names` parameter. If
    you provide a list of indices, hierarchical column headers will be created. |'
  prefs: []
  type: TYPE_TB
- en: '|   `names` |  Provide the desired names of your columns as list.  |'
  prefs: []
  type: TYPE_TB
- en: '|   `na_values` |  Pandas interprets the following cell values as  `NaN` by
    default (I introduced `NaN` in [Chapter 5](index_split_015.html#filepos482650)):
    empty cells, `#NA`, `NA`, `null`, `#N/A`, `N/A`, `NaN`, `n/a`, `-NaN`, `1.#IND`,
    `nan`, `#N/A N/A`, `-1.#QNAN`, `-nan`, `NULL`, `-1.#IND`, `<NA>`, `1.#QNAN`. If
    you’d like to add one or more values to that list, provide them via `na_values`.
    |'
  prefs: []
  type: TYPE_TB
- en: '|   `keep_default_na` |  If you’d like to ignore the default values that pandas
    interprets as  `NaN`, set `keep_default_na=False`. |'
  prefs: []
  type: TYPE_TB
- en: '|   `convert_float` |  Excel stores all numbers internally as floats and by
    default, pandas transforms numbers without meaningful decimals to integers. If
    you want to change that behavior, set  `convert_float=False` (this may be a bit
    faster). |'
  prefs: []
  type: TYPE_TB
- en: '|   `converters` |  Allows you to provide a function per column to convert
    its values. For example, to make the text in a certain column uppercase, use the
    following:  `converters={"column_name": lambda x: x.upper()}` |'
  prefs: []
  type: TYPE_TB
- en: So much for reading Excel files with pandas—let’s now switch sides and learn
    about writing Excel files in the next section!
  prefs: []
  type: TYPE_NORMAL
- en: The to_excel Method and ExcelWriter Class
  prefs: []
  type: TYPE_NORMAL
- en: 'The easiest way to write an Excel file with pandas is to use a DataFrame’s
    `to_excel` method. It allows you to specify to which cell of which sheet you want
    to write the DataFrame to. You can also decide whether or not to include the column
    headers and the index of the DataFrame and how to treat data types like `np.nan`
    and `np.inf` that don’t have an equivalent representation in Excel. Let’s start
    by creating a DataFrame with different data types and use its `to_excel` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``16``]:``import``numpy``as``np``import``datetime``as``dt`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``17``]:``data``=``[[``dt``.``datetime``(``2020``,``1``,``1``,``10``,``13``),``2.222``,``1``,``True``],``[``dt``.``datetime``(``2020``,``1``,``2``),``np``.``nan``,``2``,``False``],``[``dt``.``datetime``(``2020``,``1``,``2``),``np``.``inf``,``3``,``True``]]``df``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"Dates"``,``"Floats"``,``"Integers"``,``"Booleans"``])``df``.``index``.``name``=``"index"``df`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Out[17]:                     Dates  Floats  Integers  Booleans          index
             0     2020-01-01 10:13:00   2.222         1      True          1    
    2020-01-02 00:00:00     NaN         2     False          2     2020-01-02 00:00:00    
    inf         3      True`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In``[``18``]:``df``.``to_excel``(``"written_with_pandas.xlsx"``,``sheet_name``=``"Output"``,``startrow``=``1``,``startcol``=``1``,``index``=``True``,``header``=``True``,``na_rep``=``"<NA>"``,``inf_rep``=``"<INF>"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Running the `to_excel` command will create the Excel file as shown in [Figure 7-4](#filepos948095)
    (you will need to make column `C` wider to see the dates properly):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/00062.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-4\. written_with_pandas.xlsx
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to write multiple DataFrames to the same or different sheets, you
    will need to use the `ExcelWriter` class. The following sample writes the same
    DataFrame to two different locations on Sheet1 and one more time to Sheet2:'
  prefs: []
  type: TYPE_NORMAL
- en: '`In``[``19``]:``with``pd``.``ExcelWriter``(``"written_with_pandas2.xlsx"``)``as``writer``:``df``.``to_excel``(``writer``,``sheet_name``=``"Sheet1"``,``startrow``=``1``,``startcol``=``1``)``df``.``to_excel``(``writer``,``sheet_name``=``"Sheet1"``,``startrow``=``10``,``startcol``=``1``)``df``.``to_excel``(``writer``,``sheet_name``=``"Sheet2"``)`'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Since we’re using the `ExcelWriter` class as a context manager, the file is
    automatically written to disk when it exits the context manager, i.e., when the
    indentation stops. Otherwise, you will have to call `writer.save()` explicitly.
    For a summary of the most commonly used parameters that `to_excel` accepts, have
    a look at [Table 7-2](#filepos953686). You will find the full list of parameters
    in the [official docs](https://oreil.ly/ESKAG).
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-2\. Selected parameters for to_excel
  prefs: []
  type: TYPE_NORMAL
- en: '|  Parameter  |  Description  |'
  prefs: []
  type: TYPE_TB
- en: '|   `sheet_name` |  Name of the sheet to write to.  |'
  prefs: []
  type: TYPE_TB
- en: '|   `startrow` and `startcol` |   `startrow` is the first row where the DataFrame
    will be written to and `startcol` is the first column. This uses zero-based indexing,
    so if you want to write your DataFrame into cell B3, use `startrow=2` and `startcol=1`.
    |'
  prefs: []
  type: TYPE_TB
- en: '|   `index` and `header` |  If you want to hide the index and/or header, set
    them to  `index=False` and `header=False`, respectively. |'
  prefs: []
  type: TYPE_TB
- en: '|   `na_rep` and `inf_rep` |  By default,  `np.nan` will be converted to an
    empty cell, while `np.inf`, NumPy’s representation of infinity, will be converted
    to the string `inf`. Providing values allows you to change this behavior. |'
  prefs: []
  type: TYPE_TB
- en: '|   `freeze_panes` |  Freeze the first couple of rows and columns by supplying
    a tuple: for example  `(2, 1)` will freeze the first two rows and the first column.
    |'
  prefs: []
  type: TYPE_TB
- en: As you can see, reading and writing simple Excel files with pandas works well.
    There are limitations, though—let’s see which ones!
  prefs: []
  type: TYPE_NORMAL
- en: Limitations When Using pandas with Excel Files
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the pandas interface to read and write Excel files works great for simple
    cases, but there are limits:'
  prefs: []
  type: TYPE_NORMAL
- en: When writing DataFrames to files, you can’t include a title or a chart.
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: There is no way to change the default format of the header and index in Excel.
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: When reading files, pandas automatically transforms cells with errors like `#REF!`
    or `#NUM!` into `NaN`, making it impossible to search for specific errors in your
    spreadsheets.
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Working with big Excel files may require extra settings that are easier to control
    by using the reader and writer packages directly, as we will see in the next chapter.
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Conclusion
  prefs: []
  type: TYPE_NORMAL
- en: The nice thing about pandas is that it offers a consistent interface to work
    with all supported Excel file formats, whether that’s xls, xlsx, xlsm, or xlsb.
    This made it easy for us to read a directory of Excel files, aggregate the data,
    and dump the summary into an Excel report—in only ten lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: 'pandas, however, doesn’t do the heavy lifting itself: under the hood, it selects
    a reader or writer package to do the job. In the next chapter, I will show you
    which reader and writer packages pandas uses and how you use them directly or
    in combination with pandas. This will allow us to work around the limitations
    we saw in the previous section.'
  prefs: []
  type: TYPE_NORMAL
