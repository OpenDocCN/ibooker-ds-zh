<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 7. Measuring Uncertainty with the Bootstrap"><div class="chapter" id="measuring_uncertainty_with_the_bootstra">
<h1><span class="label">Chapter 7. </span>Measuring Uncertainty with the Bootstrap</h1>
<p>With ideal data, you are now able to draw robust conclusions<a contenteditable="false" data-type="indexterm" data-primary="time study (time-and-motion study)" data-secondary="about uncertainty" id="idm45968157121240"/><a contenteditable="false" data-type="indexterm" data-primary="uncertainty" data-secondary="about" id="idm45968157119896"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="about  uncertainty" id="idm45968157118520"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="suboptimal" data-seealso="Bootstrap; uncertainty" id="idm45968157117144"/><a contenteditable="false" data-type="indexterm" data-primary="C-Mart fictional supermarket chain" data-secondary="Bootstrap for uncertainty" data-tertiary="about uncertainty" id="idm45968157115496"/> from behavioral data and measure the causal impact of a business/environment change on human behaviors. But how can you proceed if you have suboptimal data? In academic research, one can always fall back to the null hypothesis when faced with inconclusive data and refuse to pass judgment. But in applied research there is no null hypothesis, only alternative courses of action to choose from.</p>
<p>Small sample sizes, weirdly shaped variables, or situations that require advanced analytical tools (e.g., hierarchical modeling, which we’ll see later in the book) can all result in shaky conclusions. Certainly, a linear regression algorithm will spit out a coefficient under all but the most extreme cases, but should you trust it? Can you confidently advise your boss to stake millions of dollars on it?</p>
<p>In this chapter, I’ll introduce you to an <a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="small sample with outlier" data-tertiary="about Bootstrap" id="idm45968157112056"/>extremely powerful and general simulation tool, the Bootstrap, which will allow us to draw robust conclusions from any data, however small or weird. It works by creating and analyzing slightly different versions of your data based on random numbers. A great feature of the Bootstrap is that you literally can never go wrong by applying it: in situations that are best-case scenarios for traditional statistical methods (e.g., running a basic linear regression on a large and well-behaved data set), the Bootstrap is slower and less accurate, but it is still in the ballpark. But as soon as you move away from such best-case scenarios, the Bootstrap quickly outperforms traditional statistical methods, often by a wide margin.<sup><a data-type="noteref" id="ch01fn10-marker" href="ch07.xhtml#ch01fn10">1</a></sup> Therefore, we’ll rely on it extensively throughout the rest of the book. In particular, we’ll use it when designing and analyzing experiments in <a data-type="xref" href="part04.xhtml#designing_and_analyzing_experiments">Part IV</a>, to build simulated equivalents of p-values that are more intuitive than the traditional, statistical, ones.</p>
<p>In the first section, we’ll focus on exploratory/descriptive data analysis, and we’ll see that the Bootstrap can already be of use at that stage. In the second section, we’ll use the Bootstrap in the context of regression. We’ll then broaden our perspective to discuss when to use the Bootstrap and what tools you can use to make your life easier with it.</p>
<section data-type="sect1" data-pdf-bookmark="Intro to the Bootstrap: “Polling” Oneself Up"><div class="sect1" id="intro_to_the_bootstrap_quotation_markpo">
<h1>Intro to the Bootstrap: “Polling” Oneself Up</h1>
<p>While our ultimate goal is to use the Bootstrap for regression, <a contenteditable="false" data-type="indexterm" data-primary="time study (time-and-motion study)" data-secondary="introduction to Bootstrap" id="ch07-btintro2"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="introduction to" id="ch07-btintro3"/><a contenteditable="false" data-type="indexterm" data-primary="uncertainty" data-secondary="Bootstrap" data-tertiary="introduction to" id="idm45968157101240"/><a contenteditable="false" data-type="indexterm" data-primary="C-Mart fictional supermarket chain" data-secondary="Bootstrap for uncertainty" data-tertiary="introduction to Bootstrap" id="ch07-btintro"/>we can start with the simpler example of descriptive statistics: getting the mean of a sample data set.</p>
<section data-type="sect2" data-pdf-bookmark="Packages"><div class="sect2" id="libraries-id00051">
<h2>Packages</h2>
<p>In this chapter, we’ll use the following packages in addition to the common ones:<a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="QQ-plot" id="idm45968157015144"/><a contenteditable="false" data-type="indexterm" data-primary="QQ-plot" data-secondary="package" id="idm45968157013768"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="Cook’s distance" id="idm45968157012392"/><a contenteditable="false" data-type="indexterm" data-primary="Cook’s distance" id="idm45968157011016"/></p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python</code>
<code class="kn">import</code> <code class="nn">statsmodels.api</code> <code class="kn">as</code> <code class="nn">sm</code> <code class="c1"># For QQ-plot</code>
<code class="kn">import</code> <code class="nn">statsmodels.stats.outliers_influence</code> <code class="kn">as</code> <code class="nn">st_inf</code> <code class="c1"># For Cook distance</code></pre>
</div></section>
<section data-type="sect2" data-pdf-bookmark="The Business Problem: Small Data with an Outlier"><div class="sect2" id="the_business_problem_small_data_with_an">
<h2>The Business Problem: Small Data with an Outlier</h2>
<p>C-Mart’s management is interested in understanding how long<a contenteditable="false" data-type="indexterm" data-primary="uncertainty" data-secondary="Bootstrap" data-tertiary="about business problem" id="idm45968156998776"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="small sample with outlier" data-tertiary="about business problem" id="idm45968156991352"/><a contenteditable="false" data-type="indexterm" data-primary="C-Mart fictional supermarket chain" data-secondary="Bootstrap for uncertainty" data-tertiary="cake time study" id="ch07-ckts"/><a contenteditable="false" data-type="indexterm" data-primary="time study (time-and-motion study)" data-secondary="cake time study" id="ch07-ckts2"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="outlier in small data" id="ch07-ckts3"/><a contenteditable="false" data-type="indexterm" data-primary="outliers" data-secondary="small sample size" id="ch07-ckts4"/> it takes its bakers to prepare made-to-order cakes, for the purpose of possibly revising its pricing structure. To that end, they have asked C-Mart’s industrial engineer to do a time study. <a contenteditable="false" data-type="indexterm" data-primary="time study (time-and-motion study)" data-secondary="about" id="idm45968156982536"/><a contenteditable="false" data-type="indexterm" data-primary="duration" data-secondary="time study" id="ch07-ckts5"/>As its name indicates, a time study (a.k.a. time-and-motion study) is the direct observation of a production process to measure the duration of the tasks involved. Given that the process is time-consuming (pun intended), the engineer has selected ten different stores that are somewhat representative of C-Mart’s business. In each store they observed one baker preparing one cake. They also recorded each baker’s work experience, measured in months on the job.</p>
<p>All together the engineer has 10 observations, which is not a very large sample size to begin with. <a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="small sample  with outlier" id="idm45968156978488"/>Even if all of the data conformed very consistently to a clear relationship, the sample size alone would suggest using the Bootstrap. However, when exploring their data, the engineer observed the presence of an outlier (<a data-type="xref" href="#experience_and_preparation_time_by_bake">Figure 7-1</a>).</p>
<p>We have one extreme point in the upper left corner, corresponding to a new employee who spent most of a day on a complex cake for a corporate retreat. How should the engineer report the data from their study? They might be tempted to treat the largest observation as an outlier, which is the polite way of saying “discard it and pretend it didn’t happen.” But that observation, while unusual, is not an aberration per se. There was no measurement error, and those circumstances probably occur from time to time. An alternative would be to only report the overall mean duration, 56 minutes, but that would also be misleading because it would not convey the variability and uncertainty in the data. The traditional recommendation in that situation would be to use a confidence interval around the mean. <a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="calculating via regression" id="idm45968156974552"/><a contenteditable="false" data-type="indexterm" data-primary="regression" data-secondary="confidence intervals via" id="idm45968156973144"/>Let’s calculate the normal 95% confidence interval through a regression. (Using a regression is overkill in this case—there are much simpler ways to calculate a mean—but it will serve as a gentle introduction to the process we’ll use later in the chapter.)</p>
<figure><div id="experience_and_preparation_time_by_bake" class="figure">
<img src="Images/BEDA_0701.png" alt="Experience and preparation time by baker" width="1457" height="891"/>
<h6><span class="label">Figure 7-1. </span>Experience and preparation time by baker</h6>
</div></figure>
<p>We first run the regression <code>times~1</code>, i.e., with only the intercept.<a contenteditable="false" data-type="indexterm" data-primary="regression" data-secondary="times~1 with only intercept" id="idm45968156948216"/><a contenteditable="false" data-type="indexterm" data-primary="standard error calculated via regression" id="idm45968156946776"/><a contenteditable="false" data-type="indexterm" data-primary="dependent variable" data-secondary="mean via regression" id="idm45968156945576"/><a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="calculating via regression" data-tertiary="standard error relationship" id="idm45968156944200"/> We then extract the resulting estimate for the intercept coefficient that, in case you’re not familiar with that calculation, is equal to the mean of our dependent variable. We also extract the standard error for that coefficient. As you’ll learn in any stats class, the lower limit of a normal 95%-CI is equal to the mean minus 1.96 times the standard error, and the upper limit is equal to the mean plus 1.96 times the standard error:<a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="confidence intervals" id="idm45968156941912"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="confidence intervals" id="idm45968156940536"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R (output not shown)</code>
<code class="n">lin_mod_summ</code> <code class="o">&lt;-</code> <code class="nf">summary</code><code class="p">(</code><code class="nf">lm</code><code class="p">(</code><code class="n">times</code><code class="o">~</code><code class="m">1</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">dat</code><code class="p">))</code>
<code class="n">est</code> <code class="o">&lt;-</code> <code class="n">lin_mod_summ</code><code class="o">$</code><code class="n">coefficients</code><code class="p">[</code><code class="m">1</code><code class="p">,</code><code class="m">1</code><code class="p">]</code>
<code class="n">se</code> <code class="o">&lt;-</code> <code class="n">lin_mod_summ</code><code class="o">$</code><code class="n">coefficients</code><code class="p">[</code><code class="m">1</code><code class="p">,</code><code class="m">2</code><code class="p">]</code>
<code class="n">LL</code> <code class="o">&lt;-</code> <code class="n">est</code><code class="m">-1.96</code><code class="o">*</code><code class="n">se</code>
<code class="n">UL</code> <code class="o">&lt;-</code> <code class="n">est</code><code class="m">+1.96</code><code class="o">*</code><code class="n">se</code>
</pre>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python</code>
<code class="n">lin_mod</code> <code class="o">=</code> <code class="n">ols</code><code class="p">(</code><code class="s2">"times~1"</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">data_df</code><code class="p">)</code><code class="o">.</code><code class="n">fit</code><code class="p">()</code>
<code class="n">est</code> <code class="o">=</code> <code class="n">lin_mod</code><code class="o">.</code><code class="n">params</code><code class="p">[</code><code class="s1">'Intercept'</code><code class="p">]</code>
<code class="n">se</code> <code class="o">=</code> <code class="n">lin_mod</code><code class="o">.</code><code class="n">bse</code><code class="p">[</code><code class="s1">'Intercept'</code><code class="p">]</code>
<code class="n">LL</code> <code class="o">=</code> <code class="n">est</code><code class="o">-</code><code class="mf">1.96</code><code class="o">*</code><code class="n">se</code> <code class="c1">#Lower limit</code>
<code class="n">UL</code> <code class="o">=</code> <code class="n">est</code><code class="o">+</code><code class="mf">1.96</code><code class="o">*</code><code class="n">se</code> <code class="c1">#Upper limit</code>
<code class="k">print</code><code class="p">(</code><code class="s2">"LL = "</code><code class="p">,</code> <code class="n">LL</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="s2">"UL = "</code><code class="p">,</code><code class="n">UL</code><code class="p">)</code>

<code class="n">LL</code> <code class="o">=</code>  <code class="o">-</code><code class="mf">23.040199740431333</code>
<code class="n">UL</code> <code class="o">=</code>  <code class="mf">134.64019974043134</code></pre>
<p>Unfortunately, the 95%-CI in this case is [−23; 135], which is obviously nonsensical because duration times can’t be negative. This happened because traditional CIs assume that the variable at hand follows a normal distribution around its mean, which in this case is incorrect. We can imagine that the engineer’s audience would not take too kindly to negative durations, but that is one of the problems that the Bootstrap can solve.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Bootstrap Confidence Interval for the Sample Mean"><div class="sect2" id="bootstrap_confidence_interval_for_the_s">
<h2>Bootstrap Confidence Interval for the Sample Mean</h2>
<p>The Bootstrap allows us to make full use of the data that we do<a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="small sample with outlier" data-tertiary="about Bootstrap" id="idm45968156792872"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="confidence intervals" id="idm45968156791368"/><a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="Bootstrap" data-tertiary="about" id="idm45968156789992"/><a contenteditable="false" data-type="indexterm" data-primary="sample size" data-secondary="Bootstrap" id="idm45968156788376"/> have available and to draw reasonable conclusions regardless of sample size or data shape challenges. It does so by creating multiple imaginary data sets based on the data that we have available. Comparing these data sets with each other allows us to cut through noise and more accurately represent the importance of outlier values. It can also provide tighter confidence intervals, since it removes some of the uncertainty created by noise.</p>
<p>This is different from just choosing a narrower range from the start (e.g., selecting the 80%-CI instead of the 95%-CI) because the Bootstrap’s generated data sets reflect true probability distributions given the available data. There will be no generated data set with a negative duration because the data does not reflect that possibility, but there will be data sets that reflect very long durations because the original data does include that as a possibility. So a confidence interval generated using the Bootstrap would be expected to remove more from the negative side of the range, but it might not remove as much (or might even add to) the positive side of the range.</p>
<p>The process to build a Bootstrap CI is conceptually simple:</p>
<ol>
<li><p>We simulate new samples of the same size by drawing with replacement from our observed sample.</p></li>
<li><p>Then, for each simulated sample we calculate our statistic of interest (here the mean, which is what our industrial engineer wants to measure).</p></li>
<li><p>Finally, we build our CI by looking at the percentiles of the values obtained in step 2.</p></li>
</ol>
<p>Drawing with replacement means that each value has the same probability of being drawn each time, regardless of whether or not it has already been drawn.</p>
<p>For example, drawing with replacement from (A, B, C) is equally likely to yield (B, C, C) or (A, C, B) or (B, B, B), etc. Because there are three possibilities for each of the three positions, there are 3 x 3 x 3 = 27 possible simulated samples. If we drew without replacement, this would mean that a value cannot be drawn more than once, and the only possible combinations would be permutations of the original sample, such as (A, C, B) or (B, A, C). This would simply amount to shuffling the values around, which would be pointless because the mean (or any other statistic of interest) would remain exactly the same.</p>
<p>Drawing with replacement is very simple in both R and Python:<a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="confidence intervals" data-tertiary="drawing with replacement" id="idm45968156780360"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="confidence intervals" data-tertiary="drawing with replacement" id="idm45968156778696"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">boot_dat</code> <code class="o">&lt;-</code> <code class="nf">slice_sample</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">n</code><code class="o">=</code><code class="nf">nrow</code><code class="p">(</code><code class="n">dat</code><code class="p">),</code> <code class="n">replace</code> <code class="o">=</code> <code class="kc">TRUE</code><code class="p">)</code>
</pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
<code class="n">boot_df</code> <code class="o">=</code> <code class="n">data_df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">data_df</code><code class="p">),</code> <code class="n">replace</code> <code class="o">=</code> <code class="bp">True</code><code class="p">)</code></pre>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="bootstrap_and_the_meaning_of_statistics">
<h5>Bootstrap and the Meaning of Statistics</h5>
<p>Why are we drawing with replacement? To really grasp what’s happening with the Bootstrap,<a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="Bootstrap" data-tertiary="about statistics" id="idm45968156750808"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="confidence intervals" data-tertiary="about statistics" id="idm45968156749224"/> it’s worth taking a step back and remembering the point of statistics: we have a population that we cannot fully examine, so we’re trying to make inferences about this population based on a limited sample. To do so, we create an “imaginary” population through either statistical assumptions or the Bootstrap. With statistical assumptions we say, “imagine that this sample is drawn from a population with a normal distribution,” and then make inferences based on that. With the Bootstrap we’re saying, “imagine that the population has exactly the same probability distribution as the sample,” or equivalently, “imagine that the sample is drawn from a population made of a large (or infinite) number of copies of that sample.” Then drawing with replacement from that sample is equivalent to drawing without replacement from that imaginary population. As statisticians will say, “the Bootstrap sample is to the sample what the sample is to the population.”</p>
</div></aside>
<p>The beauty of generating new samples by drawing only from our observed sample is that it avoids making any distributional assumption about data outside of the sample we observed. To see what this means, let’s simulate B = 2,000 Bootstrap samples (to avoid confusion, I’ll always use B for the number of Bootstrap samples and N for the sample size) and calculate the mean of each. Our code proceeds as follows (the callout numbers are shared between R and Python):<a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="Bootstrap" data-tertiary="mean of simulated samples" id="idm45968156676488"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="Bootstrap" data-tertiary="mean of simulated samples" id="idm45968156674824"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="small sample size" data-tertiary="mean of simulated samples" id="idm45968156673160"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code><code>
</code><code class="n">mean_lst</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">list</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" id="comarker71" href="#c7011"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code class="n">B</code><code> </code><code class="o">&lt;-</code><code> </code><code class="m">2000</code><code>
</code><code class="n">N</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">nrow</code><code class="p">(</code><code class="n">dat</code><code class="p">)</code><code>
</code><code class="nf">for</code><code class="p">(</code><code class="n">i</code><code> </code><code class="n">in</code><code> </code><code class="m">1</code><code class="o">:</code><code class="n">B</code><code class="p">)</code><code class="p">{</code><code>  </code><a class="co" id="comarker72" href="#c7021"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
  </code><code class="n">boot_dat</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">slice_sample</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code><code> </code><code class="n">n</code><code class="o">=</code><code class="n">N</code><code class="p">,</code><code> </code><code class="n">replace</code><code> </code><code class="o">=</code><code> </code><code class="kc">TRUE</code><code class="p">)</code><code>
  </code><code class="n">M</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">mean</code><code class="p">(</code><code class="n">boot_dat</code><code class="o">$</code><code class="n">times</code><code class="p">)</code><code>
  </code><code class="n">mean_lst</code><code class="p">[[</code><code class="n">i</code><code class="p">]]</code><code> </code><code class="o">&lt;-</code><code> </code><code class="n">M</code><code class="p">}</code><code>
</code><code class="n">mean_summ</code><code> </code><code class="o">&lt;-</code><code> </code><code class="nf">tibble</code><code class="p">(</code><code class="n">means</code><code> </code><code class="o">=</code><code> </code><code class="nf">unlist</code><code class="p">(</code><code class="n">mean_lst</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" id="comarker73" href="#c7031"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python </code><code>
</code><code class="n">res_boot_sim</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code> </code><img src="Images/1.png" alt="1" width="12" height="12"/><code>
</code><code class="n">B</code><code> </code><code class="o">=</code><code> </code><code class="mi">2000</code><code>
</code><code class="n">N</code><code> </code><code class="o">=</code><code> </code><code class="nb">len</code><code class="p">(</code><code class="n">data_df</code><code class="p">)</code><code>
</code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="n">B</code><code class="p">)</code><code class="p">:</code><code> </code><img src="Images/2.png" alt="2" width="12" height="12"/><code>
</code><code>    </code><code class="n">boot_df</code><code> </code><code class="o">=</code><code> </code><code class="n">data_df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">N</code><code class="p">,</code><code> </code><code class="n">replace</code><code> </code><code class="o">=</code><code> </code><code class="bp">True</code><code class="p">)</code><code>
</code><code>    </code><code class="n">M</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">boot_df</code><code class="o">.</code><code class="n">times</code><code class="p">)</code><code>
</code><code>    </code><code class="n">res_boot_sim</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">M</code><code class="p">)</code></pre>

<dl class="calloutlist">
 <dt><a class="co" id="c7011" href="#comarker71"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
  <dd><p>First I initialize an empty list for the results, as well as B and N.</p></dd> 
 <dt><a class="co" id="c7021" href="#comarker72"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
  <dd><p>Then I use a <code>for</code> loop to generate the Bootstrap samples by drawing with replacement from the original data, each time calculating the mean and adding it to the list of results.</p></dd> 
   <dt><a class="co" id="c7031" href="#comarker73"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
  <dd><p>Finally, in R I reformat the list into a tibble, for ease of use with <code>ggplot2</code>.</p></dd> 
</dl>

<p><a data-type="xref" href="#distribution_of_the_means_of_twocommaz">Figure 7-2</a> shows the distribution of the means.<a contenteditable="false" data-type="indexterm" data-primary="histograms" data-secondary="distribution of means of Bootstrap samples" id="idm45968156451256"/></p>
<figure><div id="distribution_of_the_means_of_twocommaz" class="figure">
<img src="Images/BEDA_0702.png" alt="Distribution of the means of 2,000 samples" width="1903" height="1158"/>
<h6><span class="label">Figure 7-2. </span>Distribution of the means of 2,000 samples</h6>
</div></figure>
<p>As you can see, the histogram is very irregular: there is a big peak close to the mean of our original data set along with smaller peaks corresponding to certain patterns. Given how extreme our outlier is, each of the seven peaks corresponds to its number of repetitions in the Bootstrap sample, from zero to six. In other words, it doesn’t appear at all in the samples whose means are in the first (leftmost) peak, it appears exactly once in the samples whose means are in the second peak, and so on. It’s worth noting that even if we increased the number of Bootstrap samples, the irregularity of the histogram would not disappear (i.e., the “valleys” between the peaks would not get filled), because it reflects the roughness of our data and not the limitations of our random process. The range of values within our data is so extreme that the highest possible means when the outlier is excluded are still rarely high enough to meet the lowest possible means when the outlier is included. If the value of the outlier were cut in half, and thus were closer to the rest of the population, the histogram would appear to smooth out considerably because the edges of the outlier count peaks would overlap each other.</p>
<p>The number of Bootstrap samples matters nonetheless, <a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="Bootstrap" data-tertiary="number of samples" id="idm45968156416648"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="small sample size" data-tertiary="number of samples" id="idm45968156415192"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="number of samples" id="idm45968156413736"/>but for a different reason: the higher that number, the more you’ll be able to see very unlikely samples and therefore extreme values. Here, the absolute highest possible value for a sample mean would be 413 if we drew the outlier 10 times. This has a probability of (0.1)<sup>10</sup> (one-tenth to the power of 10), meaning it will happen about one time per 10 billion samples. With our mere 2,000 samples, we are barely seeing values around 200. But the overall mean or median of our samples would remain the same plus or minus negligible sampling variations.</p>
<p>Here are some general guidelines for number of samples:</p>
<ul>
<li><p>100 to 200 samples to get an accurate <a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="central estimate" id="idm45968156410280"/><a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="central estimate" data-tertiary="Bootstrap number of samples" id="idm45968156409064"/><a contenteditable="false" data-type="indexterm" data-primary="central estimate" id="idm45968156407608"/><a contenteditable="false" data-type="indexterm" data-primary="central estimate" data-secondary="Bootstrap number of samples" id="idm45968156406632"/>central estimate (e.g., a coefficient in a regression; it’s called “central” because it’s roughly speaking at the center of a CI, as opposed to the CI’s bounds or limits)</p></li>
<li><p>1,000 to 2,000 samples to get accurate 90%-CI bounds</p></li>
<li><p>5,000 samples to get accurate 99%-CI bounds</p></li>
</ul>
<p>In general, start low, and if in doubt increase the number and try again. <a contenteditable="false" data-type="indexterm" data-primary="statistical significance (p-value)" data-secondary="p-value hacking" id="idm45968156403560"/><a contenteditable="false" data-type="indexterm" data-primary="p-value" data-secondary="p-hacking" id="idm45968156402344"/>This is fundamentally different from, for example, running multiple analyses on your data until you get numbers you like (a.k.a. “p-value hacking” or “p-hacking”); it’s more like changing the resolution of your screen when looking at a figure. It entails no risk for your analyses; it simply takes more or less of your time, depending on the size of your data and the computational power of your machine.</p>
<p>Given the data that we have, the only way we could increase the smoothness of the histogram would be to <a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="small sample with outlier" data-tertiary="smoothing with larger sample size" id="idm45968156400056"/>increase the sample size. However, we would have to increase the size of the original sample from the real world, not the size of the Bootstrap samples. Why can’t we increase the size of the Bootstrap samples (e.g., drawing 100 values with replacement from our sample of 10 values)? Because our goal is not to create new samples but to determine how far off our estimate of the mean could be when we make the assumption that the population is proportionately identical to our original sample. To do this we need to use all the information in the original sample—no less and no more. Creating larger samples from our 10 original values would be “pretending” that we have more information than we actually have.</p>
<p>The engineer is ready to use the Bootstrap to determine the <a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="confidence intervals" data-tertiary="code" id="idm45968156397128"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="Bootstrap" data-tertiary="confidence intervals" id="idm45968156395672"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="Bootstrap" data-tertiary="confidence intervals" id="idm45968156394216"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="confidence intervals" data-tertiary="Bootstrap code" id="idm45968156392760"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="confidence intervals" data-tertiary="Bootstrap code" id="idm45968156391304"/><a contenteditable="false" data-type="indexterm" data-primary="quantiles for confidence intervals" id="idm45968156389848"/><a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="Bootstrap" data-tertiary="code" id="idm45968156388872"/>bounds of the CI for the duration of cake preparation. These bounds are determined from the <em>empirical</em> distribution of the preceding means. This means that instead of trying to fit a statistical distribution (e.g., normal), they can simply order the values from smallest to largest and then look at the 2.5% quantile and the 97.5% quantile to find the two-tailed 95%-CI. With 2,000 samples, the 2.5% quantile is equal to the value of the 50th smallest mean (because 2,000 * 0.025 = 50), and the 97.5% quantile is equal to the value of the 1950th mean from smaller to larger, or the 50th largest mean (because both tails have the same number of values). Fortunately, we don’t have to calculate these by hand:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R (output not shown)</code>
<code class="n">LL_b</code> <code class="o">&lt;-</code> <code class="nf">as.numeric</code><code class="p">(</code><code class="nf">quantile</code><code class="p">(</code><code class="n">mean_summ</code><code class="o">$</code><code class="n">means</code><code class="p">,</code> <code class="nf">c</code><code class="p">(</code><code class="m">0.025</code><code class="p">)))</code>
<code class="n">UL_b</code> <code class="o">&lt;-</code> <code class="nf">as.numeric</code><code class="p">(</code><code class="nf">quantile</code><code class="p">(</code><code class="n">mean_summ</code><code class="o">$</code><code class="n">means</code><code class="p">,</code> <code class="nf">c</code><code class="p">(</code><code class="m">0.975</code><code class="p">)))</code>
</pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python </code>
<code class="n">LL_b</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">quantile</code><code class="p">(</code><code class="n">mean_lst</code><code class="p">,</code> <code class="mf">0.025</code><code class="p">)</code>  
<code class="n">UL_b</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">quantile</code><code class="p">(</code><code class="n">mean_lst</code><code class="p">,</code> <code class="mf">0.975</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="s2">"LL_b = "</code><code class="p">,</code> <code class="n">LL_b</code><code class="p">)</code>
<code class="k">print</code><code class="p">(</code><code class="s2">"UL_b = "</code><code class="p">,</code><code class="n">UL_b</code><code class="p">)</code>

<code class="n">LL_b</code> <code class="o">=</code>  <code class="mf">7.4975000000000005</code>
<code class="n">UL_b</code> <code class="o">=</code>  <code class="mf">140.80249999999998</code></pre>
<p>The Bootstrap 95%-CI is [7.50; 140.80] (plus or minus some sampling difference), which is much more realistic.<a contenteditable="false" data-type="indexterm" data-primary="histograms" data-secondary="distribution of means of Bootstrap samples" id="idm45968156251912"/> <a data-type="xref" href="#distribution_of_the_means_of_twocommaze">Figure 7-3</a> shows the same histogram as <a data-type="xref" href="#distribution_of_the_means_of_twocommaz">Figure 7-2</a> but adds the mean of the means, the normal CI bounds and the Bootstrap CI bounds.</p>
<figure><div id="distribution_of_the_means_of_twocommaze" class="figure">
<img src="Images/BEDA_0703.png" alt="Distribution of the means of 2,000 samples, with mean of the means (thick line), normal 95%-CI bounds (dotted lines), and Bootstrap CI bounds (dashed lines)" width="1903" height="1158"/>
<h6><span class="label">Figure 7-3. </span>Distribution of the means of 2,000 samples, with mean of the means (thick line), normal 95%-CI bounds (dotted lines), and Bootstrap CI bounds (dashed lines)</h6>
</div></figure>
<p>In addition to the Bootstrap lower bound being above zero, we can also note that the Bootstrap upper bound is slightly higher than the normal upper bound, which better reflects the asymmetry of the distribution toward the right.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07-ckts" id="idm45968156288024"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07-ckts2" id="idm45968156286648"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07-ckts3" id="idm45968156285272"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07-ckts4" id="idm45968156283896"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07-ckts5" id="idm45968156282520"/></p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Bootstrap Confidence Intervals for Ad Hoc Statistics"><div class="sect2" id="bootstrap_confidence_intervals_for_ad_h">
<h2>Bootstrap Confidence Intervals for Ad Hoc Statistics</h2>
<p>Using the Bootstrap has allowed us to build a reasonable<a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="small sample of proportions" id="ch07-smsa"/><a contenteditable="false" data-type="indexterm" data-primary="C-Mart fictional supermarket chain" data-secondary="Bootstrap for uncertainty" id="idm45968156277848"/> CI when the traditional statistical approach was failing. We can also use it to build CIs in situations where there is no other way to do so. Let’s imagine, for example, that C-Mart’s management is considering instituting a time promise—“your cake in three hours or 50% off”—and wants to know how often a cake currently takes more than three hours to be baked. Our estimate would be the sample percentage: it happens in 1 of the 10 observed cases, or 10%. But we can’t leave it at that, because there is significant uncertainty around that estimate, which we need to convey. Ten percent out of 10 observations is much more uncertain than 10% out of 100 or 1,000 observations.</p>
<p>So how can we build a CI around that 10% value? With the Bootstrap, of course. The process is exactly the same as earlier, except that instead of taking the mean of each simulated sample, we’ll measure the percentage of the values in the sample that are above 180 minutes: <a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="confidence intervals" data-tertiary="code" id="idm45968156274904"/><a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="Bootstrap" data-tertiary="code" id="idm45968156273256"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="Bootstrap" data-tertiary="confidence intervals" id="idm45968156271592"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="Bootstrap" data-tertiary="confidence intervals" id="idm45968156269944"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="confidence intervals" data-tertiary="Bootstrap code" id="idm45968156268296"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="confidence intervals" data-tertiary="Bootstrap code" id="idm45968156266648"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">promise_lst</code> <code class="o">&lt;-</code> <code class="nf">list</code><code class="p">()</code>
<code class="n">N</code> <code class="o">&lt;-</code> <code class="nf">nrow</code><code class="p">(</code><code class="n">dat</code><code class="p">)</code>
<code class="n">B</code> <code class="o">&lt;-</code> <code class="m">2000</code>
<code class="nf">for</code><code class="p">(</code><code class="n">i</code> <code class="n">in</code> <code class="m">1</code><code class="o">:</code><code class="n">B</code><code class="p">){</code>
  <code class="n">boot_dat</code> <code class="o">&lt;-</code> <code class="nf">slice_sample</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">n</code><code class="o">=</code><code class="n">N</code><code class="p">,</code> <code class="n">replace</code> <code class="o">=</code> <code class="kc">TRUE</code><code class="p">)</code>
  <code class="n">above180</code> <code class="o">&lt;-</code> <code class="nf">sum</code><code class="p">(</code><code class="n">boot_dat</code><code class="o">$</code><code class="n">times</code> <code class="o">&gt;=</code> <code class="m">180</code><code class="p">)</code><code class="o">/</code><code class="n">N</code>
  <code class="n">promise_lst</code><code class="p">[[</code><code class="n">i</code><code class="p">]]</code> <code class="o">&lt;-</code> <code class="n">above180</code><code class="p">}</code>
<code class="n">promise_summ</code> <code class="o">&lt;-</code> <code class="nf">tibble</code><code class="p">(</code><code class="n">above180</code> <code class="o">=</code> <code class="nf">unlist</code><code class="p">(</code><code class="n">promise_lst</code><code class="p">))</code>
<code class="n">LL_b</code> <code class="o">&lt;-</code> <code class="nf">as.numeric</code><code class="p">(</code><code class="nf">quantile</code><code class="p">(</code><code class="n">promise_summ</code><code class="o">$</code><code class="n">above180</code><code class="p">,</code> <code class="nf">c</code><code class="p">(</code><code class="m">0.025</code><code class="p">)))</code>
<code class="n">UL_b</code> <code class="o">&lt;-</code> <code class="nf">as.numeric</code><code class="p">(</code><code class="nf">quantile</code><code class="p">(</code><code class="n">promise_summ</code><code class="o">$</code><code class="n">above180</code><code class="p">,</code> <code class="nf">c</code><code class="p">(</code><code class="m">0.975</code><code class="p">)))</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python</code>
<code class="n">promise_lst</code> <code class="o">=</code> <code class="p">[]</code>
<code class="n">B</code> <code class="o">=</code> <code class="mi">2000</code>
<code class="n">N</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">data_df</code><code class="p">)</code>
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">B</code><code class="p">):</code>
    <code class="n">boot_df</code> <code class="o">=</code> <code class="n">data_df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">N</code><code class="p">,</code> <code class="n">replace</code> <code class="o">=</code> <code class="bp">True</code><code class="p">)</code>
    <code class="n">above180</code> <code class="o">=</code>  <code class="nb">len</code><code class="p">(</code><code class="n">boot_df</code><code class="p">[</code><code class="n">boot_df</code><code class="o">.</code><code class="n">times</code> <code class="o">&gt;=</code> <code class="mi">180</code><code class="p">])</code> <code class="o">/</code> <code class="n">N</code>
    <code class="n">promise_lst</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">above180</code><code class="p">)</code>
<code class="n">LL_b</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">quantile</code><code class="p">(</code><code class="n">promise_lst</code><code class="p">,</code> <code class="mf">0.025</code><code class="p">)</code>  
<code class="n">UL_b</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">quantile</code><code class="p">(</code><code class="n">promise_lst</code><code class="p">,</code> <code class="mf">0.975</code><code class="p">)</code></pre>
<p>The histogram of the results is shown in<a contenteditable="false" data-type="indexterm" data-primary="histograms" data-secondary="count of samples of proportions" id="idm45968156131512"/> <a data-type="xref" href="#histogram_of_count_of_samples_with_a_gi">Figure 7-4</a>. There’s “white space” between the bars again because we have only 10 data points, so percentages are multiples of 10%. That would not be the case with more data points; in general percentages will be multiples of 1/N with N the sample size (e.g., with 20 points, percentages would be multiples of 5%).</p>
<figure><div id="histogram_of_count_of_samples_with_a_gi" class="figure">
<img src="Images/BEDA_0704.png" alt="Histogram of count of samples with a given proportion of durations above 180 minutes" width="1903" height="1169"/>
<h6><span class="label">Figure 7-4. </span>Histogram of count of samples with a given proportion of durations above 180 minutes</h6>
</div></figure>
<p>In about 700 of the 2,000 simulated samples, there was no cake with a preparation time above 180 minutes. In about 750, there was exactly one such cake, and so on. The corresponding 95%-CI is [0; 0.3]: the 50th lowest value is 0 and the 50th highest value is 0.3.</p>
<p>In other words, even with such limited data, we can quite confidently say that it’s very unlikely (although not impossible) that more than 30% of the cakes take more than three hours to prepare. That’s still a pretty large confidence interval, but not too shabby for only 10 observations and such a unique statistic!</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If this is hard to wrap your mind around, you can reframe the preceding problem by calculating the confidence interval for a binomial distribution with 1 success in 10 observations. Approximation methods are available in R and Python to calculate CIs in that case. These tend to be more conservative (i.e., broader) than our Bootstrap CI, but not vastly so.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07-smsa" id="idm45968156006792"/></p>
</div>
<p>By using the Bootstrap, the engineer can sharpen the analyses they would regularly want to perform with their data. They’re able to use limited data to answer a variety of questions with a reasonable amount of certainty (and correspondingly tolerable uncertainty).<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07-btintro" id="idm45968156004584"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07-btintro2" id="idm45968156003208"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07-btintro3" id="idm45968156001832"/></p>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="The Bootstrap for Regression Analysis"><div class="sect1" id="the_bootstrap_for_regression_analysis">
<h1>The Bootstrap for Regression Analysis</h1>
<p>While building a confidence interval around the mean can be useful, <a contenteditable="false" data-type="indexterm" data-primary="outliers" data-secondary="regression analysis" id="idm45968155998552"/><a contenteditable="false" data-type="indexterm" data-primary="regression" data-secondary="Bootstrap for regression analysis" id="idm45968155997176"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="regression analysis code" id="ch07btrg"/><a contenteditable="false" data-type="indexterm" data-primary="C-Mart fictional supermarket chain" data-secondary="Bootstrap for regression analysis" id="ch07btrg2"/><a contenteditable="false" data-type="indexterm" data-primary="C-Mart fictional supermarket chain" data-secondary="causal diagrams" data-tertiary="experience and baking time" id="idm45968155992536"/>regression is really what this book is about, so let’s see how we can use the Bootstrap for that purpose. Our industrial engineer at C-Mart wants to determine the effect of experience on baking time using the same data about cake preparation. The corresponding CD is very simple (<a data-type="xref" href="#causal_diagram_for_our_relationship_of">Figure 7-5</a>).</p>
<figure><div id="causal_diagram_for_our_relationship_of" class="figure">
<img src="Images/BEDA_0705.png" alt="Causal diagram for our relationship of interest" width="1059" height="139"/>
<h6><span class="label">Figure 7-5. </span>Causal diagram for our relationship of interest</h6>
</div></figure>
<p>Running a regression on our data is straightforward, given that the causal diagram did not reveal any confounder. However, the resulting coefficient is not significant:<a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="regression analysis" id="idm45968155986776"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="regression analysis" id="idm45968155985400"/></p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python (output not shown)</code>
<code class="k">print</code><code class="p">(</code><code class="n">ols</code><code class="p">(</code><code class="s2">"times~experience"</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">data_df</code><code class="p">)</code><code class="o">.</code><code class="n">fit</code><code class="p">()</code><code class="o">.</code><code class="n">summary</code><code class="p">())</code></pre>
<pre data-type="programlisting" data-code-language="r">
<code class="c1">## R </code>
<code class="n">mod</code> <code class="o">&lt;-</code> <code class="nf">lm</code><code class="p">(</code><code class="n">times</code><code class="o">~</code><code class="n">experience</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">dat</code><code class="p">)</code>
<code class="n">mod_summ</code> <code class="o">&lt;-</code> <code class="nf">summary</code><code class="p">(</code><code class="n">mod</code><code class="p">)</code>
<code class="n">mod_summ</code>
<code class="kc">...</code>
<code class="n">Coefficients</code><code class="o">:</code>
            <code class="n">Estimate</code> <code class="n">Std.</code> <code class="n">Error</code> <code class="n">t</code> <code class="n">value</code> <code class="nf">Pr</code><code class="p">(</code><code class="o">&gt;|</code><code class="n">t</code><code class="o">|</code><code class="p">)</code>  
<code class="p">(</code><code class="n">Intercept</code><code class="p">)</code>  <code class="m">132.389</code>     <code class="m">61.750</code>   <code class="m">2.144</code>   <code class="m">0.0644</code>
<code class="n">experience</code>    <code class="m">-9.819</code>      <code class="m">6.302</code>  <code class="m">-1.558</code>   <code class="m">0.1578</code> 
<code class="kc">...</code></pre>
<p>Our estimated coefficient is −9.8, meaning that every additional month of experience is expected to remove 9.8 minutes of preparation time. However, the traditional CI based on the regression standard error would be [–22.2; 2.5]. From a traditional perspective, this would be game over: the CI includes zero, meaning that months of experience could have a positive, negative, or zero effect on baking time, so we would decline to draw any substantive conclusion. Let’s see instead what the Bootstrap tells us. The process is exactly the same as before: we simulate samples of 10 data points by drawing with replacement from our original sample a large number of times, then save the regression coefficient. Last time we used B = 2,000 samples. This time let’s use B = 4,000, as it makes the corresponding histogram look smoother<a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="Bootstrap" data-tertiary="regression analysis" id="idm45968155847720"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="Bootstrap" data-tertiary="regression analysis" id="idm45968155846232"/> (<a data-type="xref" href="#distribution_of_the_regression_coeffic">Figure 7-6</a>):</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R (output not shown)</code>
<code class="n">reg_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">B</code><code class="p">){</code>
  <code class="n">N</code> <code class="o">&lt;-</code> <code class="nf">nrow</code><code class="p">(</code><code class="n">dat</code><code class="p">)</code>
  <code class="n">reg_lst</code> <code class="o">&lt;-</code> <code class="nf">list</code><code class="p">()</code>
  <code class="nf">for</code><code class="p">(</code><code class="n">i</code> <code class="n">in</code> <code class="m">1</code><code class="o">:</code><code class="n">B</code><code class="p">){</code>
    <code class="n">boot_dat</code> <code class="o">&lt;-</code> <code class="nf">slice_sample</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">n</code><code class="o">=</code><code class="n">N</code><code class="p">,</code> <code class="n">replace</code> <code class="o">=</code> <code class="kc">TRUE</code><code class="p">)</code>
    <code class="n">summ</code> <code class="o">&lt;-</code> <code class="nf">summary</code><code class="p">(</code><code class="nf">lm</code><code class="p">(</code><code class="n">times</code><code class="o">~</code><code class="n">experience</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">boot_dat</code><code class="p">))</code>
    <code class="n">coeff</code> <code class="o">&lt;-</code> <code class="n">summ</code><code class="o">$</code><code class="n">coefficients</code><code class="p">[</code><code class="s">'experience'</code><code class="p">,</code><code class="s">'Estimate'</code><code class="p">]</code>
    <code class="n">reg_lst</code><code class="p">[[</code><code class="n">i</code><code class="p">]]</code> <code class="o">&lt;-</code> <code class="n">coeff</code><code class="p">}</code>
  <code class="n">reg_summ</code> <code class="o">&lt;-</code> <code class="nf">tibble</code><code class="p">(</code><code class="n">coeff</code> <code class="o">=</code> <code class="nf">unlist</code><code class="p">(</code><code class="n">reg_lst</code><code class="p">))</code>
  <code class="nf">return</code><code class="p">(</code><code class="n">reg_summ</code><code class="p">)}</code>
<code class="n">reg_summ</code> <code class="o">&lt;-</code> <code class="nf">reg_fun</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">B</code><code class="o">=</code><code class="m">4000</code><code class="p">)</code></pre>
<pre data-type="programlisting" data-code-language="python">
<code class="c1">## Python (output not shown)</code>
<code class="n">reg_lst</code> <code class="o">=</code> <code class="p">[]</code>
<code class="n">B</code> <code class="o">=</code> <code class="mi">4000</code>
<code class="n">N</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">data_df</code><code class="p">)</code>
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">B</code><code class="p">):</code>
    <code class="n">boot_df</code> <code class="o">=</code> <code class="n">data_df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">N</code><code class="p">,</code> <code class="n">replace</code> <code class="o">=</code> <code class="bp">True</code><code class="p">)</code>
    <code class="n">lin_mod</code> <code class="o">=</code> <code class="n">ols</code><code class="p">(</code><code class="s2">"times~experience"</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">boot_df</code><code class="p">)</code><code class="o">.</code><code class="n">fit</code><code class="p">()</code>
    <code class="n">coeff</code> <code class="o">=</code> <code class="n">lin_mod</code><code class="o">.</code><code class="n">params</code><code class="p">[</code><code class="s1">'experience'</code><code class="p">]</code>
    <code class="n">reg_lst</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">coeff</code><code class="p">)</code>
<code class="n">LL_b</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">quantile</code><code class="p">(</code><code class="n">reg_lst</code><code class="p">,</code> <code class="mf">0.025</code><code class="p">)</code>  
<code class="n">UL_b</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">quantile</code><code class="p">(</code><code class="n">reg_lst</code><code class="p">,</code> <code class="mf">0.975</code><code class="p">)</code></pre>
<figure><div id="distribution_of_the_regression_coeffic" class="figure">
<img src="Images/BEDA_0706.png" alt="Distribution of the regression coefficients of preparation time on experience, with their mean (thick line), Bootstrap CI bounds (thick dashed lines), and normal CI bounds (thin dotted lines) (B=4,000 Bootstrap samples)" width="1903" height="1166"/>
<h6><span class="label">Figure 7-6. </span>Distribution of the regression coefficients of preparation time on experience, with their mean (thick line), Bootstrap CI bounds (thick dashed lines), and normal CI bounds (thin dotted lines) (B = 4,000 Bootstrap samples)</h6>
</div></figure>
<p>The Bootstrap CI is [–28; –0.2]. As you can see in<a contenteditable="false" data-type="indexterm" data-primary="histograms" data-secondary="Bootstrap regression analysis" id="idm45968155577656"/> <a data-type="xref" href="#distribution_of_the_regression_coeffic">Figure 7-6</a>, it’s again asymmetric compared to the symmetric normal bounds, with a long tail to the left of the mean. The highly irregular shape of the distribution reflects the existence of two competing hypotheses:</p>
<ul class="pagebreak-before less_space">
<li><p>The tall and narrow peak near zero is made of samples that don’t include the outlier, and as such it corresponds with the view that the outlier is a freak accident that won’t repeat itself. That’s the confidence interval you would get if you discarded the outlier.</p></li>
<li><p>The broad and flat hump to the left is made of samples that include the outlier one or several times. It reflects the hypothesis that the outlier is truly representative of our data and that its true frequency may be even higher than in our small sample.</p></li>
</ul>
<p>You can think of this as data-driven scenario analysis. What if this pattern didn’t exist? What if it dominated our data? Instead of having to choose between discarding the outlier or letting it drive our results, the Bootstrap allows us to consider all possibilities at once.</p>
<p>In addition to building a CI, we can use the Bootstrap to determine the equivalent of a p-value.<a contenteditable="false" data-type="indexterm" data-primary="statistical significance (p-value)" data-secondary="Bootstrap to simulate" id="idm45968155571256"/><a contenteditable="false" data-type="indexterm" data-primary="p-value" data-secondary="Bootstrap to simulate" id="idm45968155569912"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="p-value simulation" id="idm45968155568536"/><a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="p-value simulation with Bootstrap" id="idm45968155567160"/> If you look at the output of our regression at the beginning of this section, you’ll see the value 0.16 for experience in the column for the p-values (i.e., the column with the label Pr(&gt;|t|)). <a contenteditable="false" data-type="indexterm" data-primary="p-value" data-secondary="about" id="idm45968155565416"/><a contenteditable="false" data-type="indexterm" data-primary="statistical significance (p-value)" data-secondary="about" id="idm45968155564040"/>You have probably already been told that a coefficient is statistically significant (i.e., statistically significantly different from zero) if its p-value is less than 0.05, or 0.01 in more stringent cases. Mathematically speaking, the p-value is such that the (1 minus p-value)-CI has zero as one of its bounds. In the case of the normal regression, zero is the upper bound of the 84%-CI. Because 84% is less than 95% or 99%, the coefficient for experience would not be considered statistically significant. The exact same logic can be used with the Bootstrap; we just have to calculate the fraction of the Bootstrap sample whose coefficient is above zero, and multiply it by 2 because it’s a two-tailed test:<sup><a data-type="noteref" id="ch01fn11-marker" href="ch07.xhtml#ch01fn11">2</a></sup><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="Bootstrap" data-tertiary="p-value simulation" id="idm45968155560664"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="Bootstrap" data-tertiary="p-value simulation" id="idm45968155559048"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="p-value simulation" id="idm45968155557400"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="p-value simulation" id="idm45968155556024"/></p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python (output not shown)</code>
<code class="n">pval</code> <code class="o">=</code> <code class="mi">2</code> <code class="o">*</code> <code class="nb">sum</code><code class="p">(</code><code class="mi">1</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">reg_lst</code> <code class="k">if</code> <code class="n">x</code> <code class="o">&gt;</code> <code class="mi">0</code><code class="p">)</code> <code class="o">/</code> <code class="n">B</code>
</pre>
<pre data-type="programlisting" data-code-language="r">
<code class="c1">## R</code>
<code class="n">reg_summ</code> <code class="o">%&gt;%</code> <code class="nf">summarise</code><code class="p">(</code><code class="n">pval</code> <code class="o">=</code> <code class="m">2</code> <code class="o">*</code> <code class="nf">sum</code><code class="p">(</code><code class="n">coeff</code> <code class="o">&gt;</code> <code class="m">0</code><code class="p">)</code><code class="o">/</code><code class="nf">n</code><code class="p">())</code>
<code class="c1"># A tibble: 1 x 1</code>
    <code class="n">pval</code>
  <code class="o">&lt;</code><code class="n">dbl</code><code class="o">&gt;</code>
<code class="m">1</code> <code class="m">0.04</code></pre>
<p>This means that our empirical Bootstrap<a contenteditable="false" data-type="indexterm" data-primary="achieved significance level (ASL)" id="idm45968155463016"/> p-value<sup><a data-type="noteref" id="ch01fn12-marker" href="ch07.xhtml#ch01fn12">3</a></sup> is about 0.04, as opposed to the traditional p-value of 0.16 rooted in statistical assumptions. This is helpful because <span class="keep-together">people</span> are often familiar with statistical p-values, and Bootstrap p-values can be used instead. From a business perspective, we can now be confident that the regression coefficient is between null and strongly negative. In addition, we could easily calculate the equivalent of a p-value for any other threshold (e.g., if we wanted to use −1 instead of zero as a threshold), or for any interval, such as [−1; +1], if we wanted.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07btrg" id="idm45968155459608"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07btrg2" id="idm45968155458232"/></p>
</div></section>
<section data-type="sect1" data-pdf-bookmark="When to Use the Bootstrap"><div class="sect1" id="when_to_use_the_bootstrap">
<h1>When to Use the Bootstrap</h1>
<p>Hopefully, by now you’re convinced of the virtues of the<a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="when to use Bootstrap" id="ch07-when"/><a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="Bootstrap" data-tertiary="when to use Bootstrap" id="ch07when2"/><a contenteditable="false" data-type="indexterm" data-primary="central estimate" data-secondary="when to use Bootstrap" id="ch07when3"/><a contenteditable="false" data-type="indexterm" data-primary="confidence intervals (CI)" data-secondary="central estimate" data-tertiary="when to use Bootstrap" id="ch07when4"/> Bootstrap for small and oddly shaped data sets. But what about large or evenly shaped data sets? Should you always use the Bootstrap? The short answer is that it is never wrong to use it, but it can be impractical or overkill. For experimental data, we’ll rely extensively on the Bootstrap, as we’ll see in <a data-type="xref" href="part04.xhtml#designing_and_analyzing_experiments">Part IV</a> of the book. For observational data analysis, which is the focus of this chapter, things are more complicated. <a data-type="xref" href="#decision_tree_to_use_the_bootstrap">Figure 7-7</a> presents the decision tree we’ll use. It may look a bit intimidating, but it can be broken down conceptually into three blocks:</p>
<ul>
<li><p>If you only want a central estimate (e.g., a regression coefficient) and the conditions for the traditional estimate to be sufficient are fulfilled, you can use it.</p></li>
<li><p>If you want a CI and the conditions for the traditional CI to be sufficient are fulfilled, you can use it.</p></li>
<li><p>In any other case or when in doubt, use the Bootstrap CI.</p></li>
</ul>
<p>Let’s review these blocks in turn.</p>
<figure><div id="decision_tree_to_use_the_bootstrap" class="figure">
<img src="Images/BEDA_0707.png" alt="Decision tree to use the Bootstrap" width="1457" height="842"/>
<h6><span class="label">Figure 7-7. </span>Decision tree to use the Bootstrap</h6>
</div></figure>
<section data-type="sect2" data-pdf-bookmark="Conditions for the Traditional Central Estimate to Be Sufficient"><div class="sect2" id="conditions_for_the_traditional_central">
<h2>Conditions for the Traditional Central Estimate to Be Sufficient</h2>
<p>The first thing to keep in mind is that the Bootstrap yields a central estimate or coefficient that is very close to the one obtained by traditional methods (i.e., whatever you would have done if you didn’t know about the Bootstrap). Therefore, it never makes sense to start directly with the Bootstrap, when a traditional estimate is one line of code away.</p>
<p>However, if your data is small (typically less than 100 rows) or in any regard weird (e.g., it has multiple peaks or is asymmetric), then that central estimate can be misleading. In that case, you should really use the Bootstrap to calculate a confidence interval instead, ideally displaying its results in the form of a histogram as we did in <a data-type="xref" href="#distribution_of_the_regression_coeffic">Figure 7-6</a>.</p>
<p>Similarly, if the coefficient is close to a boundary or threshold, and therefore not economically clear-cut, you’ll need to use a CI and the central estimate won’t be <span class="keep-together">sufficient.</span></p>
<p>Even when things are as clean and clear-cut as they can be, you may still want to have a CI, for example because your boss or your business partner required it.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Conditions for the Traditional CI to Be Sufficient"><div class="sect2" id="conditions_for_the_traditional_ci_to_be">
<h2>Conditions for the Traditional CI to Be Sufficient</h2>
<p>If you want to have a CI but your data is not so small or weird that the Bootstrap CI is required, the question becomes whether a traditional CI would be reliable and sufficient for your purpose. There are two tests you need to run in that situation:</p>
<ul>
<li><p>Check the presence or not of influential points.</p></li>
<li><p>Check the normality of the regression residuals (only if the regression is linear).</p></li>
</ul>
<p>Only if your data is devoid of influential points and you don’t see any issue with the residuals can you use the traditional CI.</p>
<p>Influential points are points whose deletion would substantially<a contenteditable="false" data-type="indexterm" data-primary="influential points" id="idm45968155404328"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="influential points" id="idm45968155403224"/><a contenteditable="false" data-type="indexterm" data-primary="Cook’s distance" id="idm45968155401848"/> modify the regression, and there is a statistic, <a href="https://oreil.ly/0OS4s">Cook’s distance</a>, which measures precisely that. For our purposes here, it’s enough to know that a data point is considered influential if its Cook’s distance is more than one. R and Python have one-liners to calculate Cook’s distance for points with respect to a regression model:<a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="Cook’s distance" id="idm45968155399576"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="Cook’s distance" id="idm45968155398200"/></p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python (output not shown)</code>
<code class="n">CD</code> <code class="o">=</code> <code class="n">st_inf</code><code class="o">.</code><code class="n">OLSInfluence</code><code class="p">(</code><code class="n">lin_mod</code><code class="p">)</code><code class="o">.</code><code class="n">summary_frame</code><code class="p">()[</code><code class="s1">'cooks_d'</code><code class="p">]</code>
<code class="n">CD</code><code class="p">[</code><code class="n">CD</code> <code class="o">&gt;</code> <code class="mi">1</code><code class="p">]</code></pre>
<pre data-type="programlisting" data-code-language="r">
<code class="c1">## R</code>
<code class="o">&gt;</code> <code class="n">CD</code> <code class="o">&lt;-</code> <code class="nf">cooks.distance</code><code class="p">(</code><code class="n">mod</code><code class="p">)</code>
<code class="o">&gt;</code> <code class="n">CD</code><code class="p">[</code><code class="n">CD</code> <code class="o">&gt;</code> <code class="m">1</code><code class="p">]</code>
     <code class="m">10</code> 
<code class="m">1.45656</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>By definition, an influential point doesn’t follow the same pattern as the other points (otherwise deleting it would not drastically change the results of our regression). This means that an influential point is always an outlier, but an outlier is not always an influential point: an outlier lies far out from the cloud that the other points form, but it could still be close to the regression line calculated without it and have a small Cook’s distance. In our baking example, the outlier point is also an influential point.</p>
</div>
<p>If you have any influential point in your data, it suggests that the standard distributional assumptions are not met, and using the Bootstrap may be wiser.</p>
<p>If you don’t have influential points in your data, there is a second check you need to do in the case of a linear regression:<a contenteditable="false" data-type="indexterm" data-primary="regression" data-secondary="residuals" data-tertiary="Bootstrap" id="idm45968155358872"/><a contenteditable="false" data-type="indexterm" data-primary="linear regression" data-secondary="residuals" data-tertiary="Bootstrap" id="idm45968155324440"/> you need to make sure that the regression residuals are approximately normal. This doesn’t apply to <a contenteditable="false" data-type="indexterm" data-primary="logistic regressions" data-secondary="residuals" id="idm45968155322552"/>logistic regression because its residuals follow a Bernoulli distribution and not a normal distribution. This check answers both the questions of “How non-normal is non-normal?” and “How large is large?” because they are related: larger data dampens minor deviations from normality, so a degree of non-normality that would be problematic with a hundred points might be OK with a hundred thousand.</p>
<p>Let’s extract the regression residuals and visually assess their normality. In R, we obtain the residuals by applying the function <code>resid()</code> to our linear regression model:<a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="regression residuals" id="idm45968155319656"/></p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">res_dat</code> <code class="o">&lt;-</code> <code class="nf">tibble</code><code class="p">(</code><code class="n">res</code> <code class="o">=</code> <code class="nf">resid</code><code class="p">(</code><code class="n">mod</code><code class="p">))</code>
<code class="n">p1</code> <code class="o">&lt;-</code> <code class="nf">ggplot</code><code class="p">(</code><code class="n">res_dat</code><code class="p">,</code> <code class="nf">aes</code><code class="p">(</code><code class="n">res</code><code class="p">))</code> <code class="o">+</code> <code class="nf">geom_density</code><code class="p">()</code> <code class="o">+</code> <code class="nf">xlab</code><code class="p">(</code><code class="s">"regression residuals"</code><code class="p">)</code>
<code class="n">p2</code> <code class="o">&lt;-</code> <code class="nf">ggplot</code><code class="p">(</code><code class="n">res_dat</code><code class="p">,</code> <code class="nf">aes</code><code class="p">(</code><code class="n">sample</code><code class="o">=</code><code class="n">res</code><code class="p">))</code> <code class="o">+</code> <code class="nf">geom_qq</code><code class="p">()</code> <code class="o">+</code> <code class="nf">geom_qq_line</code><code class="p">()</code> <code class="o">+</code> 
  <code class="nf">coord_flip</code><code class="p">()</code>
<code class="nf">ggarrange</code><code class="p">(</code><code class="n">p1</code><code class="p">,</code> <code class="n">p2</code><code class="p">,</code> <code class="n">ncol</code><code class="o">=</code><code class="m">2</code><code class="p">,</code> <code class="n">nrow</code><code class="o">=</code><code class="m">1</code><code class="p">)</code></pre>
<p>The syntax in Python is also straightforward: we first get the residuals from the model, then draw a density plot from the Seaborn package, and draw the QQ-plot with the statsmodels package:<a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="regression residuals" id="idm45968155316536"/><a contenteditable="false" data-type="indexterm" data-primary="packages" data-secondary="Cook’s distance" id="idm45968155231992"/></p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python </code>
<code class="n">res_df</code> <code class="o">=</code> <code class="n">lin_mod</code><code class="o">.</code><code class="n">resid</code>
<code class="n">sns</code><code class="o">.</code><code class="n">kdeplot</code><code class="p">(</code><code class="n">res_df</code><code class="p">)</code>
<code class="n">fig</code> <code class="o">=</code> <code class="n">sm</code><code class="o">.</code><code class="n">qqplot</code><code class="p">(</code><code class="n">res_df</code><code class="p">,</code> <code class="n">line</code><code class="o">=</code><code class="s1">'s'</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
<p><a data-type="xref" href="#density_plot_left_parenthesisleftright">Figure 7-8</a> displays the two plots we created in R, a density plot and a QQ-plot.</p>
<figure><div id="density_plot_left_parenthesisleftright" class="figure">
<img src="Images/BEDA_0708.png" alt="Density plot (left) and QQ-plot (right) of regression residuals" width="1928" height="1166"/>
<h6><span class="label">Figure 7-8. </span>Density plot (left) and QQ-plot (right) of regression residuals</h6>
</div></figure>
<p>Let’s first look at the density plot on the left. For a normal density, we would expect to see a curve with a single peak centered on zero and with smoothly decreasing, symmetric left and right tails. This is clearly not the case here due to the presence of an outlier with a large residual, so we conclude that the residuals are not normally <span class="keep-together">distributed.</span></p>
<p>The plot on the right is a QQ-plot (QQ stands for Quantile-Quantile), <a contenteditable="false" data-type="indexterm" data-primary="QQ-plot" id="idm45968155205688"/><a contenteditable="false" data-type="indexterm" data-primary="linear regression" data-secondary="residuals" data-tertiary="QQ-plot" id="idm45968155204584"/><a contenteditable="false" data-type="indexterm" data-primary="regression" data-secondary="residuals" data-tertiary="QQ-plot" id="idm45968155202936"/>plotted with <code>geom_qq()</code> or <code>qqplot()</code>, which shows the values of our residuals on the x-axis and a theoretical normal distribution on the y-axis. For a normal density, we would expect all the points to be on the line or very close to it, which is again not the case here because of the outlier.</p>
<p>Whenever the residuals of a linear regression are not normally distributed, the Bootstrap will give you better results for CIs and p-values than the traditional approach.</p>
<p>To recap, it is never wrong to build Bootstrap CIs and you can always fall back on them. But when you only need the central estimate and you can safely rely on it, or when you can safely rely on a traditional CI, it can be overkill to jump to the<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07-when" id="idm45968155198712"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07when2" id="idm45968155197336"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07when3" id="idm45968155195960"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch07when4" id="idm45968155194584"/> <span class="keep-together">Bootstrap.</span></p>
<p>Finally, let’s see in a bit more detail how you can determine the number of Bootstrap samples to use.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Determining the Number of Bootstrap Samples"><div class="sect2" id="determining_the_number_of_bootstrap_sam">
<h2>Determining the Number of Bootstrap Samples</h2>
<p>Once you have decided to use the Bootstrap, you need to<a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="number of samples" id="idm45968155190520"/><a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="small sample with outlier" data-tertiary="number of samples" id="idm45968155189144"/> determine the number of samples to use in your simulation. If you just want to get a broad sense of the variability of an estimate, B = 25 to 200 gives reasonably robust results for main estimates, according to Efron, the “inventor” of the Bootstrap. Think of it as a 75%-CI. You wouldn’t bet the farm on it, but it tells you more than just a mean.</p>
<p>On the other hand, let’s say you want a precise p-value or 95%-CI because there is uncertainty as to whether or not a critical threshold, usually zero, is in it or not. Then you’ll need a much larger B, because we’re typically looking at the 2.5% smallest or 2.5% highest values of the Bootstrap distribution. With B = 200, the lower bound of a two-tailed 95%-CI is equal to 200 * 2.5%, or the fifth-smallest value, and similarly the upper bound is equal to the fifth-largest value. Five is a pretty small number. You can pretty easily get unlucky and get five numbers that are smaller or larger than expected, and throw off your CI bound. Let’s visualize that by repeating the Bootstrap regression from the previous section with only 200 samples. As you can see in <a data-type="xref" href="#distribution_of_the_regression_coeffici">Figure 7-9</a>, the shape of the distribution is overall similar to <a data-type="xref" href="#causal_diagram_for_our_relationship_of">Figure 7-5</a>, but now the upper bound for our CI is <em>above</em> zero.</p>
<figure><div id="distribution_of_the_regression_coeffici" class="figure">
<img src="Images/BEDA_0709.png" alt="Distribution of the regression coefficients of preparation time on experience, with their mean (thick line), the Bootstrap CI bounds (thick dashed lines) and the normal CI bounds (thin dotted lines) (B=200 Bootstrap samples)" width="1903" height="1166"/>
<h6><span class="label">Figure 7-9. </span>Distribution of the regression coefficients of preparation time on experience, with their mean (thick line), the Bootstrap CI bounds (thick dashed lines) and the normal CI bounds (thin dotted lines) (B = 200 Bootstrap samples)</h6>
</div></figure>
<p>Therefore, if a business decision hinges on where that bound is in relation to zero, you’ll need to make sure that you estimate it accurately by increasing B. Having 1,000 or even 2,000 samples is a generally accepted guideline in such circumstances. At B = 2,000 the 2.5% quantile is equal to the 50th value, so the odds are much more in your favor. In addition, with very small data sets such as the one used in this chapter, even simulating 4,000 samples takes no more than a few seconds, which is why I have used such a large B.</p>
<p>Let’s recap when to use the Bootstrap with observational data, bringing together the test conditions and the number of samples:</p>
<ul>
<li><p>Always start with your traditional regression model to get the main estimate.</p></li>
<li><p>If you have less than 100 points in your data, always use the Bootstrap with B between 25 and 200 to assess the uncertainty around that estimate.</p></li>
<li><p>With N &gt; 100, check your data for signs of influential points (with Cook’s distance) or non-normality (with the density plot and QQ-plot of residuals). If anything looks fishy, use the Bootstrap, again with B between 25 and 200 for main estimates.</p></li>
<li><p>Regardless of N, if you need a precise confidence interval or achieved significance level (a.k.a. p-value), do another Bootstrap simulation with B between 1,000 and 2,000.</p></li>
<li><p>Once you’ve gotten a sense of how long it takes to run a Bootstrap simulation on your data with a small to medium B, and what the corresponding histogram or CI looks like, always feel free to push the dial on B. Feel free to run a simulation with B = 10,000 overnight to get a nicely dented graph and an exactingly precise CI bound.</p></li>
</ul>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Optimizing the Bootstrap in R and Python"><div class="sect1" id="optimizing_the_bootstrap_in_r_and_pytho">
<h1>Optimizing the Bootstrap in R and Python</h1>
<p>I have shown you how to apply the Bootstrap algorithm “by hand,” so that you can understand what it does, but there are packages that will do it in fewer lines of code and will run faster. They will also allow you to use improved versions of the Bootstrap that would be impractical to code manually.</p>
<section data-type="sect2" data-pdf-bookmark="R: The boot Package"><div class="sect2" id="r_the_boot_package">
<h2>R: The boot Package</h2>
<p>The <code>boot</code> package and its <code>boot()</code> function provide a <a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="optimizing in R" id="idm45968155102616"/><a contenteditable="false" data-type="indexterm" data-primary="R" data-secondary="Bootstrap" data-tertiary="optimizing" id="idm45968155101208"/>one-stop shop for Bootstrap analyses. For all its simplicity, the way it generates Bootstrap samples is not intuitive, so it’s worth looking at that feature separately first.</p>
<p>Remember that in the earlier section on Bootstrap for regression analysis, I generated Bootstrap samples with the <code>slice_sample()</code> function before running our regression of interest on them:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="p">(</code><code class="kc">...</code><code class="p">)</code>
<code class="nf">for</code><code class="p">(</code><code class="n">i</code> <code class="n">in</code> <code class="m">1</code><code class="o">:</code><code class="n">B</code><code class="p">){</code>
  <code class="n">boot_dat</code> <code class="o">&lt;-</code> <code class="nf">slice_sample</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">n</code><code class="o">=</code><code class="n">N</code><code class="p">,</code> <code class="n">replace</code> <code class="o">=</code> <code class="kc">TRUE</code><code class="p">)</code>
  <code class="n">summ</code> <code class="o">&lt;-</code> <code class="nf">summary</code><code class="p">(</code><code class="nf">lm</code><code class="p">(</code><code class="n">times</code><code class="o">~</code><code class="n">experience</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">boot_dat</code><code class="p">))</code>
<code class="p">(</code><code class="kc">...</code><code class="p">)</code></pre>
<p>An alternative approach to generate Bootstrap samples is to take a list of indices, sample from it with replacement, then subset our data based on that list:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="o">&gt;</code> <code class="n">I</code> <code class="o">&lt;-</code> <code class="nf">c</code><code class="p">(</code><code class="m">1</code><code class="o">:</code><code class="m">10</code><code class="p">)</code>
<code class="o">&gt;</code> <code class="n">I</code>
 <code class="p">[</code><code class="m">1</code><code class="p">]</code>  <code class="m">1</code>  <code class="m">2</code>  <code class="m">3</code>  <code class="m">4</code>  <code class="m">5</code>  <code class="m">6</code>  <code class="m">7</code>  <code class="m">8</code>  <code class="m">9</code> <code class="m">10</code>
<code class="o">&gt;</code> <code class="n">J</code> <code class="o">&lt;-</code> <code class="nf">sample</code><code class="p">(</code><code class="n">I</code><code class="p">,</code> <code class="m">10</code><code class="p">,</code> <code class="n">replace</code> <code class="o">=</code> <code class="kc">TRUE</code><code class="p">)</code>
<code class="o">&gt;</code> <code class="n">J</code>
 <code class="p">[</code><code class="m">1</code><code class="p">]</code> <code class="m">10</code>  <code class="m">3</code>  <code class="m">1</code>  <code class="m">1</code>  <code class="m">6</code>  <code class="m">1</code>  <code class="m">9</code>  <code class="m">3</code>  <code class="m">4</code>  <code class="m">3</code>
<code class="o">&gt;</code> <code class="n">boot_dat</code> <code class="o">&lt;-</code> <code class="n">dat</code><code class="p">[</code><code class="n">J</code><code class="p">,]</code></pre>
<p>This is the approach used in the <code>boot()</code> function. We must create a function taking as arguments our original data and a list of index J and returning our variable of interest (here, the regression estimate for experience). The <code>boot()</code> function will take care of generating that list for each iteration; we only need to subset our data with it within our function:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="n">boot_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">J</code><code class="p">){</code>
  <code class="n">Boot_dat</code> <code class="o">&lt;-</code> <code class="n">dat</code><code class="p">[</code><code class="n">J</code><code class="p">,]</code>
  <code class="n">summ</code> <code class="o">&lt;-</code> <code class="nf">summary</code><code class="p">(</code><code class="nf">lm</code><code class="p">(</code><code class="n">times</code><code class="o">~</code><code class="n">experience</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">boot_dat</code><code class="p">))</code>
  <code class="n">coeff</code> <code class="o">&lt;-</code> <code class="n">summ</code><code class="o">$</code><code class="n">coefficients</code><code class="p">[</code><code class="s">'experience'</code><code class="p">,</code><code class="s">'Estimate'</code><code class="p">]</code>
  <code class="nf">return</code><code class="p">(</code><code class="n">coeff</code><code class="p">)</code>
<code class="p">}</code></pre>
<p>After creating that function, we pass it to the <code>boot()</code> function as the argument <code>statistic</code>, as well as our original data as <code>data</code>, and the number of Bootstrap samples as <code>R</code> (for replications). The <code>boot()</code> function returns an object that we then pass to the <code>boot.ci()</code> function to get our CI:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R</code>
<code class="o">&gt;</code> <code class="n">boot.out</code> <code class="o">&lt;-</code> <code class="nf">boot</code><code class="p">(</code><code class="n">data</code> <code class="o">=</code> <code class="n">dat</code><code class="p">,</code> <code class="n">statistic</code> <code class="o">=</code> <code class="n">boot_fun</code><code class="p">,</code> <code class="n">R</code> <code class="o">=</code> <code class="m">2000</code><code class="p">)</code>
<code class="o">&gt;</code> <code class="nf">boot.ci</code><code class="p">(</code><code class="n">boot.out</code><code class="p">,</code> <code class="n">conf</code> <code class="o">=</code> <code class="m">0.95</code><code class="p">,</code> <code class="n">type</code> <code class="o">=</code> <code class="nf">c</code><code class="p">(</code><code class="s">'norm'</code><code class="p">,</code> <code class="s">'perc'</code><code class="p">,</code> <code class="s">'bca'</code><code class="p">))</code>
<code class="n">BOOTSTRAP</code> <code class="n">CONFIDENCE</code> <code class="n">INTERVAL</code> <code class="n">CALCULATIONS</code>
<code class="n">Based</code> <code class="n">on</code> <code class="m">2000</code> <code class="n">bootstrap</code> <code class="n">replicates</code>

<code class="n">CALL</code> <code class="o">:</code> 
<code class="nf">boot.ci</code><code class="p">(</code><code class="n">boot.out</code> <code class="o">=</code> <code class="n">boot.out</code><code class="p">,</code> <code class="n">conf</code> <code class="o">=</code> <code class="m">0.95</code><code class="p">,</code> <code class="n">type</code> <code class="o">=</code> <code class="nf">c</code><code class="p">(</code><code class="s">"norm"</code><code class="p">,</code> <code class="s">"perc"</code><code class="p">,</code> 
    <code class="s">"bca"</code><code class="p">))</code>

<code class="n">Intervals</code> <code class="o">:</code> 
<code class="n">Level</code>      <code class="n">Normal</code>             <code class="n">Percentile</code>            <code class="n">BCa</code>          
<code class="m">95</code>%   <code class="p">(</code><code class="m">-25.740</code><code class="p">,</code>   <code class="m">6.567</code> <code class="p">)</code>   <code class="p">(</code><code class="m">-28.784</code><code class="p">,</code>  <code class="m">-0.168</code> <code class="p">)</code>   <code class="p">(</code><code class="m">-38.144</code><code class="p">,</code>  <code class="m">-0.383</code> <code class="p">)</code>  
<code class="n">Calculations</code> <code class="n">and</code> <code class="n">Intervals</code> <code class="n">on</code> <code class="n">Original</code> <code class="n">Scale</code></pre>
<p>The <code>boot.ci()</code> function can return a variety of CIs, as determined by the parameter <code>type</code>. “norm” is the traditional CI based on a normal distribution. “perc” is the percentile, or quantile, Bootstrap that we calculated by hand previously. “bca” is the bias-corrected and accelerated percentile Bootstrap (BC<sub>a</sub>). The BC<sub>a</sub> Bootstrap refines the percentile Bootstrap by leveraging some of its statistical properties; these are beyond our scope here. You can learn more about them in any of the sources listed as references; suffice it to say that the BC<sub>a</sub> Bootstrap is considered best practice when using Bootstrap simulations. It can be pretty demanding in terms of computations however, so I would recommend using the percentile Bootstrap first, and once you have a reasonably final version of your code, try switching to the BC<sub>a</sub> Bootstrap.</p>
<p>In the present case, the normal and percentile CIs are very close to what we calculated by hand, as expected. The BC<sub>a</sub> CI shifts to the left, strengthening our original conclusions that the coefficient is most likely strongly negative.</p>
<p>Now that you understand the intuition behind the use of the <code>boot</code> package, let’s create a reusable function:</p>
<pre data-type="programlisting" data-code-language="r"><code class="c1">## R </code>
<code class="n">boot_CI_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">metric_fun</code><code class="p">){</code>
  <code class="c1">#Setting the number of bootstrap samples</code>
  <code class="n">B</code> <code class="o">&lt;-</code> <code class="m">100</code>
  
  <code class="n">boot_metric_fun</code> <code class="o">&lt;-</code> <code class="nf">function</code><code class="p">(</code><code class="n">dat</code><code class="p">,</code> <code class="n">J</code><code class="p">){</code>
    <code class="n">boot_dat</code> <code class="o">&lt;-</code> <code class="n">dat</code><code class="p">[</code><code class="n">J</code><code class="p">,]</code>
    <code class="nf">return</code><code class="p">(</code><code class="nf">metric_fun</code><code class="p">(</code><code class="n">boot_dat</code><code class="p">))</code>
  <code class="p">}</code>
  <code class="n">boot.out</code> <code class="o">&lt;-</code> <code class="nf">boot</code><code class="p">(</code><code class="n">data</code><code class="o">=</code><code class="n">dat</code><code class="p">,</code> <code class="n">statistic</code><code class="o">=</code><code class="n">boot_metric_fun</code><code class="p">,</code> <code class="n">R</code><code class="o">=</code><code class="n">B</code><code class="p">)</code>
  <code class="n">confint</code> <code class="o">&lt;-</code> <code class="nf">boot.ci</code><code class="p">(</code><code class="n">boot.out</code><code class="p">,</code> <code class="n">conf</code> <code class="o">=</code> <code class="m">0.90</code><code class="p">,</code> <code class="n">type</code> <code class="o">=</code> <code class="nf">c</code><code class="p">(</code><code class="s">'perc'</code><code class="p">))</code>
  <code class="n">CI</code> <code class="o">&lt;-</code> <code class="n">confint</code><code class="o">$</code><code class="n">percent</code><code class="nf">[c</code><code class="p">(</code><code class="m">4</code><code class="p">,</code><code class="m">5</code><code class="p">)]</code>
  
  <code class="nf">return</code><code class="p">(</code><code class="n">CI</code><code class="p">)</code>
<code class="p">}</code></pre>
<p>The <code>boot_CI_fun()</code> function takes as arguments a data set and a metric function and returns a 90% confidence interval for that metric function on that data set, based on 100 Bootstrap samples and the percentile approach.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="high_performance_bootstrap">
<h5>High-Performance Bootstrap</h5>
<p>Using the <code>boot</code> package can typically make your code two to five times faster, but sometimes that’s just not enough. Should you need more computational oomph, the <code>Rfast</code> package offers a bare-bones implementation of regression that will give you an additional order of magnitude improvement (e.g., twenty to fifty times faster than our original code).</p>
</div></aside>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Python Optimization"><div class="sect2" id="python_optimization">
<h2>Python Optimization</h2>
<p>Python offers very different trade-offs to the analyst compared to<a contenteditable="false" data-type="indexterm" data-primary="Bootstrap" data-secondary="optimizing in Python" id="idm45968154587992"/><a contenteditable="false" data-type="indexterm" data-primary="Python" data-secondary="Bootstrap" data-tertiary="optimizing" id="idm45968154586616"/> R: on the one hand, it has fewer statistical packages and there is no equivalent of the R <code>boot</code> package that would implement the Bootstrap algorithm directly. On the other hand, I find it to be more forgiving of beginners in terms of performance. This is especially true for bootstrapping, because <code>for</code> loops, which beginners tend to use a lot, are comparatively much less costly. Therefore, I expect Python users to get much more mileage out of the naive implementation we started with.</p>
<p>Still, should you need to add computational oomph to your Bootstrap implementation in Python, you can do so by going “full NumPy”:<a contenteditable="false" data-type="indexterm" data-primary="NumPy" data-secondary="Bootstrap optimization in Python" id="idm45968154582904"/></p>
<pre data-type="programlisting" data-code-language="python"><code class="c1">## Python</code><code>
</code><code class="c1"># Creating unique numpy array for sampling</code><code>
</code><code class="n">data_ar</code><code> </code><code class="o">=</code><code> </code><code class="n">data_df</code><code class="o">.</code><code class="n">to_numpy</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" id="comarker771" href="ch11.xhtml#c01"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>                                        </code><code>
</code><code class="n">rng</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">default_rng</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" id="comarker772" href="ch11.xhtml#c02"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>           </code><code>
</code><code>
</code><code class="n">np_lst</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>
</code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="n">B</code><code class="p">)</code><code class="p">:</code><code> </code><code>
</code><code>    </code><code class="c1"># Extracting the relevant columns from array</code><code>
</code><code>    </code><code class="n">boot_ar</code><code> </code><code class="o">=</code><code> </code><code class="n">rng</code><code class="o">.</code><code class="n">choice</code><code class="p">(</code><code class="n">data_ar</code><code class="p">,</code><code> </code><code class="n">size</code><code class="o">=</code><code class="n">N</code><code class="p">,</code><code> </code><code class="n">replace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code> </code><a class="co" id="comarker773" href="ch11.xhtml#c03"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>          </code><code>
</code><code>    </code><code class="n">X</code><code> </code><code class="o">=</code><code> </code><code class="n">boot_ar</code><code class="p">[</code><code class="p">:</code><code class="p">,</code><code class="mi">1</code><code class="p">]</code><code> </code><a class="co" id="comarker774" href="ch11.xhtml#c04"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>
</code><code>    </code><code class="n">X</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">c_</code><code class="p">[</code><code class="n">X</code><code class="p">,</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">ones</code><code class="p">(</code><code class="n">N</code><code class="p">)</code><code class="p">]</code><code>
</code><code>    </code><code class="n">Y</code><code> </code><code class="o">=</code><code> </code><code class="n">boot_ar</code><code class="p">[</code><code class="p">:</code><code class="p">,</code><code class="mi">0</code><code class="p">]</code><code> </code><a class="co" id="comarker775" href="ch11.xhtml#c05"><img src="Images/5.png" alt="5" width="12" height="12"/></a><code>                                           </code><code>
</code><code>    </code><code>
</code><code>    </code><code class="c1">### LSTQ implementation</code><code>
</code><code>    </code><code class="n">np_lst</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">linalg</code><code class="o">.</code><code class="n">lstsq</code><code class="p">(</code><code class="n">X</code><code class="p">,</code><code> </code><code class="n">Y</code><code class="p">,</code><code> </code><code class="n">rcond</code><code class="o">=</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code> </code><a class="co" id="comarker776" href="ch11.xhtml#c06"><img src="Images/6.png" alt="6" width="12" height="12"/></a></pre>          
    
<dl class="calloutlist">
 <dt><a class="co" id="c701" href="#comarker771"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
  <dd><p>We convert our original pandas dataframe to a NumPy array.</p></dd> 
 <dt><a class="co" id="c702" href="#comarker772"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
  <dd><p>We initialize the NumPy random number generator only once, outside of the loop.</p></dd> 
 <dt><a class="co" id="c703" href="#comarker773"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
  <dd><p>We create our bootstrapped data set by using the NumPy random number generator, which is significantly faster than the pandas <code>.sample()</code> method for <span class="keep-together">dataframes.</span></p></dd> 
 <dt><a class="co" id="c704" href="#comarker774"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
  <dd><p>We extract the predictor columns from our array and in the following line manually add a constant column for the intercept (whereas <code>statsmodel</code> was previously handling that under the hood for us).</p></dd>  
 <dt><a class="co" id="c705" href="#comarker775"><img src="Images/5.png" alt="5" width="12" height="12"/></a></dt>
  <dd><p>We extract the column for the dependent variable from our array.</p></dd> 
 <dt><a class="co" id="c706" href="#comarker776"><img src="Images/6.png" alt="6" width="12" height="12"/></a></dt>
  <dd><p>Reading the function calls from the right to the left: we fit the linear regression model with the <code>np.linalg.lstsq()</code> function to the predictor and dependent variable data. The <code>rcond=-1</code> parameter removes an unimportant warning. The value we want is in the <code>[0][0]</code> cell for this particular model; you can find the specific cell you need by running <code>np.linalg.lstsq(X, Y, rcond=-1)</code> once and inspecting its output. Finally, we append the value to our result list.</p></dd> 
</dl>

<p>Going full NumPy can significantly improve your performance, to the order of fifty times faster or so for larger data sets. However, our original code did just fine for our small data set, and it was more readable and less error-prone. Moreover, if you go beyond straightforward linear or logistic regressions, you’ll have to search on the Internet for a NumPy implementation of the algorithm you want. But should you need to improve the performance of your Bootstrap code in Python, you now know how to do so.</p>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="conclusion-id00012">
<h1>Conclusion</h1>
<p>Behavioral data analyses often have to deal with smaller or weirder data. Fortunately, the advent of computer simulations has given us in the Bootstrap a great tool to deal with such situations. Bootstrap confidence intervals allow us to correctly assess the uncertainty in our estimates without relying on potentially faulty statistical assumptions about the distribution of our data. With observational data, the Bootstrap is most useful when our data exhibits signs of influential points or non-normality; otherwise, it is often overkill. With experimental data, however, the heavy reliance on p-values to make decisions means that we’ll use it extensively, as we’ll see in the next part of the book.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="ch01fn10"><sup><a href="ch07.xhtml#ch01fn10-marker">1</a></sup> See Wilcox (2010), which shows the danger of assuming normality as a matter of course.</p><p data-type="footnote" id="ch01fn11"><sup><a href="ch07.xhtml#ch01fn11-marker">2</a></sup> To see why, note that if you have a 90%-CI, you’ll have 5% of values remaining on each side out of it because (1 − 0.9) / 2 = 0.05. Conversely, if you see that you have 5% of values on one side out of a CI, then it’s the 90%-CI, because (1 − 2 * 0.05) = 0.9.</p><p data-type="footnote" id="ch01fn12"><sup><a href="ch07.xhtml#ch01fn12-marker">3</a></sup> To be fully accurate, our Bootstrap p-value would better be called the Bootstrap achieved significance level (ASL).</p></div></div></section></div></body></html>