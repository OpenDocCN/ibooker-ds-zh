<html><head></head><body><div id="sbo-rt-content"><section data-type="preface" epub:type="preface" data-pdf-bookmark="Preface"><div class="preface" id="_preface">
<h1>Preface</h1>

<p>The written word is a powerful thing. The ancient Sumerians invented the first written language, and the introduction of the Gutenberg press allowed the written word to spread knowledge and enlightenment across the world. Language is in fact so important to human thinking that anthropologists claim that our ability for complex reasoning evolved at the same time that we developed language. Language represented in the form of text captures most of human thought, deeds, and actions, and our life is increasingly dominated by it. We communicate with colleagues through emails, with friends and family via messengers, and with others who share our passions using social media tools. Leaders inspire huge populations through speeches (and tweets) that are recorded as text, leading researchers communicate their findings via published research papers, and companies communicate their health through quarterly reports. Even this book uses text to spread knowledge. Analyzing and understanding text gives us the ability to gain knowledge and make decisions. <a contenteditable="false" data-type="indexterm" data-primary="text analytics, introduction" id="idm45634210678168"/>Text analytics is about writing computer programs that can analyze vast amounts of information available in the form of text. Before making a product purchase or visiting a restaurant, we read customer reviews. A company could then use the same reviews <span class="keep-together">to improve</span> their product or service. A publisher could analyze discussions on the <span class="keep-together">internet</span> to estimate the demand for a certain programming language before commissioning a book on it.</p>

<p>It is much harder for a computer to understand text compared to other types of data. While there are rules of grammar and guidelines to forming sentences, these are often not strictly followed and depend heavily on context. Even with the correct grammar, it is hard for a machine to interpret the text correctly. The words that a person chooses while tweeting would be quite different from writing an email to express the same thought. There have been recent advances in statistical techniques and machine learning algorithms that allow us to get past many of these obstacles to derive value from text data. New models are able to capture the semantic meaning of text better than previous approaches based on word frequencies alone. But there are also many business tasks where these simple models perform surprisingly well.</p>

<p>In one of our client projects, for example, a home appliance manufacturer was able to understand the key topics affecting customer purchases by analyzing product reviews and adjust their marketing message to focus on these aspects. In another case, an e-commerce retailer used a deep neural network to classify customer queries and route them to the correct department for faster resolution. Analyzing abstracts from scientific journals has allowed an R&amp;D company to detect trends in new materials and adjust their research accordingly. A fashion company identified mega-topics in their customer group by taking a look at posts in social networks. With this book we have tried to transfer our experiences from these and many other projects into blueprints that you can easily reuse in your own projects.</p>

<section data-type="sect1" data-pdf-bookmark="Approach of the Book"><div class="sect1" id="pre_approach">
<h1>Approach of the Book</h1>

<p>This book is intended to support data scientists and developers so they can quickly enter the area of text analytics and natural language processing. Thus, we put the focus on developing practical solutions that can serve as blueprints in your daily business. A blueprint, in our definition, is a best-practice solution for a common problem. It is a template that you can easily copy and adapt for reuse. For these blueprints we use production-ready Python frameworks for data analysis, natural language <span class="keep-together">processing</span>, and machine learning. Nevertheless, we also introduce the underlying <span class="keep-together">models</span> and algorithms.</p>

<p>We do not expect any previous knowledge in the field of natural language processing but provide you with the necessary background knowledge to get started quickly. In each chapter, we explain and discuss different solution approaches for the respective tasks with their potential strengths and weaknesses. Thus, you will not only acquire the knowledge about how to solve a certain kind of problem but also get a set <span class="keep-together">of ready-to-use</span> blueprints that you can take and customize to your data and <span class="keep-together">requirements</span>.</p>

<p>Each of the 13 <a contenteditable="false" data-type="indexterm" data-primary="datasets, examples of" data-secondary="overview of" id="idm45634209981768"/>chapters includes <a contenteditable="false" data-type="indexterm" data-primary="use cases" data-secondary="overview of" id="idm45634209980232"/>a self-contained use case for a specific aspect of text analytics (see <a data-type="xref" href="#preface_approach_table">Table P-1</a>). Based on an example dataset, we develop and explain the blueprints step by step.</p>

<table id="preface_approach_table">
	<caption><span class="label">Table P-1. </span>Overview of the chapters</caption>
	<thead>
		<tr>
			<th>Chapter</th>
			<th>Dataset</th>
			<th>Libraries</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch01.xhtml#ch-exploration">Chapter 1, <em>Gaining Early Insights from Textual Data</em></a></p>

			<p>Getting started with the statistical exploration of textual data</p>
			</td>
			<td>
			<p>UN General Debates</p>
			</td>
			<td>
			<p>Pandas, Regex</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch02.xhtml#ch-api">Chapter 2, <em>Extracting Textual Insights with APIs</em></a></p>

			<p>Using different Python modules to extract data from popular APIs</p>
			</td>
			<td>
			<p>GitHub, Twitter, and Wikipedia API</p>
			</td>
			<td>
			<p>Requests, Tweepy</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch03.xhtml#ch-scraping">Chapter 3, <em>Scraping Websites and Extracting Data</em></a></p>

			<p>Using Python libraries to download web pages and extract content</p>
			</td>
			<td>
			<p>Reuters website</p>
			</td>
			<td>
			<p>Requests, Beautiful Soup, Readability-lxml, Scrapy</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch04.xhtml#ch-preparation">Chapter 4, <em>Preparing Textual Data for Statistics and Machine Learning</em></a></p>

			<p>Introduction to data cleaning and linguistic processing</p>
			</td>
			<td>
			<p>Reddit Selfposts</p>
			</td>
			<td>
			<p>Regex, spaCy</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch05.xhtml#ch-vectorization">Chapter 5, <em>Feature Engineering and <span class="keep-together">Syntactic Similarity</span></em></a></p>

			<p>Introduction to features and vectorization</p>
			</td>
			<td>
			<p>1 million headlines from ABC News</p>
			</td>
			<td>
			<p>scikit-learn, NumPy</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch06.xhtml#ch-classification">Chapter 6, <em>Text Classification Algorithms</em></a>. Text Classification Algorithms</p>

			<p>Using machine learning algorithms to classify software bugs</p>
			</td>
			<td>
			<p>Java Development Tools bug reports</p>
			</td>
			<td>
			<p>scikit-learn</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch07.xhtml#ch-explain">Chapter 7, <em>How to Explain a Text Classifier</em></a></p>

			<p>Explaining models and classification results</p>
			</td>
			<td>
			<p>Java Development Tools bug reports</p>
			</td>
			<td>
			<p>scikit-learn, Lime, Anchor, ELI5</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch08.xhtml#ch-topicmodels">Chapter 8, <em>Unsupervised Methods: Topic Modeling and Clustering</em></a></p>

			<p>Using unsupervised methods to gain unbiased insights into text</p>
			</td>
			<td>
			<p>UN General Debates</p>
			</td>
			<td>
			<p>scikit-learn, Gensim</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch09.xhtml#ch-summarization">Chapter 9, <em>Text Summarization</em></a></p>

			<p>Creating short summaries of news articles and forum threads using rule-based and machine learning approaches</p>
			</td>
			<td>
			<p>Reuters News articles, Travel Forum threads</p>
			</td>
			<td>
			<p>Sumy, scikit-learn</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch10.xhtml#ch-embeddings">Chapter 10, <em>Exploring Semantic Relationships with Word Embeddings</em></a></p>

			<p>Using word embeddings to explore and visualize semantic similarities in a specific data set</p>
			</td>
			<td>
			<p>Reddit Selfposts</p>
			</td>
			<td>
			<p>Gensim</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch11.xhtml#ch-sentiment">Chapter 11, <em>Performing Sentiment Analysis <span class="keep-together">on Text Data</span></em></a></p>

			<p>Identifying customer sentiment in Amazon product reviews</p>
			</td>
			<td>
			<p>Amazon product reviews</p>
			</td>
			<td>
			<p>Transformers, scikit-learn, NLTK</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch12.xhtml#ch-knowledge">Chapter 12, <em>Building a Knowledge Graph</em></a></p>

			<p>How to extract named entities and their relationships using pretrained models and custom rules</p>
			</td>
			<td>
			<p>Reuters news on mergers and acquisitions</p>
			</td>
			<td>
			<p>spaCy</p>
			</td>
		</tr>
		<tr>
			<td>
			<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch13.xhtml#ch-production">Chapter 13, <em>Using Text Analytics in Production</em></a></p>

			<p>Deploy and scale the sentiment analysis blueprint as an API on Google Cloud Platform</p>
			</td>
			<td>
			<p> </p>
			</td>
			<td>
			<p>FastAPI, Docker, conda, Kubernetes, gcloud</p>
			</td>
		</tr>
	</tbody>
</table>

<p>The choice of topics reflects the most common types of problems in our daily text analytics work. Typical tasks include data acquisition, statistical data exploration, and the use of supervised and unsupervised machine learning. The business questions range from content analysis (“What are people talking about?”) to automatic text <span class="keep-together">categorization.</span></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Prerequisites"><div class="sect1" id="prereq">
<h1>Prerequisites</h1>

<p>In this book you will learn how to solve text analytics problems efficiently with the Python ecosystem. We will explain all concepts specific to text analytics and machine learning in detail but assume that you already have basic knowledge of Python, including fundamental libraries like Pandas. You should also be familiar with Jupyter notebooks so that you can experiment with the code while reading the book. If not, check out the tutorials on <a href="https://www.learnpython.org/" class="orm:hideurl"><em>learnpython.org</em></a>, <a href="https://docs.python.org/3/tutorial" class="orm:hideurl"><em>docs.python.org</em></a>, or <a href="https://oreil.ly/oB-eH">DataCamp</a>.</p>

<p>Even though we explain the general ideas of the algorithms used, we won’t go too much into the details. You should be able to follow the examples and reuse the code without completely understanding the mathematics behind it. College-level knowledge of linear algebra and statistics is helpful, though.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Some Important Libraries to Know"><div class="sect1" id="important-libs-to-know">
<h1>Some Important Libraries to Know</h1>

<p>Every data analytics project starts with data exploration and data processing. The most popular <a contenteditable="false" data-type="indexterm" data-primary="Pandas library" data-secondary="about" id="idm45634210796488"/>Python library for those tasks is definitely <a href="https://pandas.pydata.org"><em>Pandas</em></a>. It offers rich functionality to access, transform, analyze, and visualize data. If you have never worked with this framework, we recommend checking out the official introduction, <a href="https://oreil.ly/eWlId"><em>10 minutes to Pandas</em></a>, or one of the other free tutorials available on the internet before reading the book.</p>

<p>For <a contenteditable="false" data-type="indexterm" data-primary="scikit-learn" data-secondary="about" id="idm45634210871880"/>years, <a href="https://scikit-learn.org"><em>scikit-learn</em></a> has been the machine learning toolkit for Python. It implements a large variety of supervised and unsupervised machine learning algorithms as well as many functions for data preprocessing. We use scikit-learn in several of the chapters to transform text into numerical vectors and for text classification.</p>

<p>When it comes to deep neural models, however, frameworks like <a contenteditable="false" data-type="indexterm" data-primary="PyTorch" id="idm45634210868568"/>PyTorch or <a contenteditable="false" data-type="indexterm" data-primary="TensorFlow Embedding Projector" id="idm45634210867336"/>TensorFlow are clearly superior to scikit-learn. Instead of using those libraries directly, we <a contenteditable="false" data-type="indexterm" data-primary="Transformers library" id="idm45634210865992"/>use the <a href="https://oreil.ly/f5Ped"><em>Transformers library</em></a> from <a contenteditable="false" data-type="indexterm" data-primary="Hugging Face" id="idm45634210881720"/>Hugging Face in <a data-type="xref" href="ch11.xhtml#ch-sentiment">Chapter 11</a> for sentiment analysis. Since the publication of <a contenteditable="false" data-type="indexterm" data-primary="BERT (Bidirectional Encoder Representations from Transformers) model" id="idm45634210879432"/>BERT,<sup><a data-type="noteref" id="idm45634210878232-marker" href="preface01.xhtml#idm45634210878232">1</a></sup> transformer-based models outperform previous approaches on tasks that require an understanding of the meaning of text, and the Transformers library provides easy access to many pretrained models.</p>

<p>Our favorite <a contenteditable="false" data-type="indexterm" data-primary="spaCy, linguistic processing with" data-secondary="about" id="idm45634210875832"/>library for natural language processing is <em>spaCy</em>. Since its first release in 2016, spaCy enjoys a constantly growing user base. Though open source, it is primarily developed by the company <a href="https://explosion.ai">Explosion</a>. Pretrained neural language models for part-of-speech tagging, dependency parsing, and named-entity recognition are available for many languages. We used spaCy version 2.3.2 for the development of this book, especially for data preparation (<a data-type="xref" href="ch04.xhtml#ch-preparation">Chapter 4</a>) and knowledge extraction (<a data-type="xref" href="ch12.xhtml#ch-knowledge">Chapter 12</a>). At the time of publication, spaCy 3.0 will be out with completely new, transformer-based models, support for custom models in PyTorch and TensorFlow, and templates for defining end-to-end workflows.</p>

<p>Another NLP <a contenteditable="false" data-type="indexterm" data-primary="Gensim" data-secondary="about" id="idm45634210751640"/>library we use is <a href="https://oreil.ly/YJ4Pz">Gensim</a>, which is maintained by Radim Řehůřek. Gensim puts the focus on semantic analysis and provides all that is necessary to learn topic models (<a data-type="xref" href="ch08.xhtml#ch-topicmodels">Chapter 8</a>) and word embeddings (<a data-type="xref" href="ch10.xhtml#ch-embeddings">Chapter 10</a>).</p>

<p>There are many other libraries for natural language processing that can be helpful but are not or only briefly mentioned in the book. These include <a contenteditable="false" data-type="indexterm" data-primary="NLTK library" id="idm45634210746664"/>NLTK (feature-rich grandfather of Python NLP libraries), TextBlob (easy to get started), Stanford’s <a contenteditable="false" data-type="indexterm" data-primary="Stanza" id="idm45634210745320"/>Stanza and CoreNLP, as well as <a contenteditable="false" data-type="indexterm" data-primary="Flair" id="idm45634210744088"/>Flair (state-of-the-art models for advanced tasks). Our goal was not to give an overview on everything that’s out there but to choose and explain those libraries that worked best in our projects.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Books to Read"><div class="sect1" id="books-to-read-along">
<h1>Books to Read</h1>

<p>As we focus on practical solutions for our use cases, you might want to check out some additional books for further details or topics we did not cover. Below you will find some recommendations for books to read alongside this one:</p>

<ul class="author-date-bib">
	<li>
	<p><a href="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/" class="orm:hideurl"><em>Practical Natural Language Processing</em></a> by Sowmya Vajjala, Bodhisattwa Majumder, Anuj Gupta, and Harshit Surana (O’Reilly, 2020), ISBN 978-1-492-05405-4.</p>
	</li>
	<li>
	<p><a href="https://www.oreilly.com/library/view/natural-language-processing/9781617294631/" class="orm:hideurl"><em>Natural Language Processing in Action</em></a> by Hobson Lane, Cole Howard, and Hannes Hapke (Manning Publications, 2019), ISBN 978-1-617-29463-1.</p>
	</li>
	<li>
	<p><a href="https://www.oreilly.com/library/view/mining-the-social/9781491973547/" class="orm:hideurl"><em>Mining the Social Web</em>, 3rd Edition</a> by Matthew A. Russell and Mikhail Klassen (O’Reilly, 2019), ISBN 978-1-491-98504-5.</p>
	</li>
	<li>
	<p><a href="https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/" class="orm:hideurl"><em>Applied Text Analysis with Python</em></a> by Benjamin Bengfort, Rebecca Bilbro, and Tony Ojeda (O’Reilly 2018), ISBN 978-1-491-96304-3.</p>
	</li>
	<li>
	<p><a href="https://www.oreilly.com/library/view/python-for-data/9781491957653/" class="orm:hideurl"><em>Python for Data Analysis</em>, 2nd Edition</a> by Wes McKinney (O’Reilly, 2017), ISBN 978-1-491-95766-0.</p>
	</li>
</ul>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Conventions Used in This Book"><div class="sect1" id="_conventions_used_in_this_book">
<h1>Conventions Used in This Book</h1>

<p>The following typographical conventions are used in this book:</p>

<dl>
	<dt><em>Italic</em></dt>
	<dd>
	<p>Indicates new terms, URLs, email addresses, filenames, and file extensions.</p>
	</dd>
	<dt><code>Constant width</code></dt>
	<dd>
	<p>Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.</p>
	</dd>
	<dt><strong><code>Constant width bold</code></strong></dt>
	<dd>
	<p>Shows commands or other text that should be typed literally by the user.</p>
	</dd>
	<dt><em><code>Constant width italic</code></em></dt>
	<dd>
	<p>Shows text that should be replaced with user-supplied values or by values determined by context.</p>
	</dd>
</dl>

<div data-type="tip"><h6>Tip</h6>
<p>This element signifies a tip or suggestion.</p>
</div>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>This element signifies a general note.</p>
</div>

<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>This element indicates a warning or caution.</p>
</div>

<div class="blueprint" data-type="note" epub:type="note"><h6>Note</h6>
<p>This element indicates a blueprint.</p>
</div>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Using Code Examples"><div class="sect1" id="_using_code_examples">
<h1>Using Code Examples</h1>
<!--PROD: Please reach out to author to find out if they will be uploading code examples to oreilly.com or their own site (e.g., GitHub). If there is no code download, delete this whole section. If there is, when you email digidist with the link, let them know what you filled in for title_title (should be as close to book title as possible, i.e., learning_python_2e). This info will determine where digidist loads the files.-->

<p>The whole purpose of a blueprint is to be copied. Thus, we provide all the code developed in this book in our <a href="https://oreil.ly/btap-code">GitHub repository</a>.</p>

<p>For each chapter, you will find an executable Jupyter notebook with the code from the book and possibly some additional functions or blueprints that have been omitted. The repository also contains the necessary datasets and some additional information.</p>

<p>The easiest way to <a contenteditable="false" data-type="indexterm" data-primary="Google Colab" id="idm45634211143144"/>run the notebooks is on <a href="https://oreil.ly/colab">Google Colab</a>, Google’s public cloud platform for machine learning. You don’t even have to install Python on your local computer; just click on the Colab link for the respective chapter on GitHub (Google account required). However, we also added instructions for setting up your own (virtual) Python environment in the GitHub repository. We designed the Jupyter notebooks in a way that allows you to run them both locally and on Google Colab.</p>
<!-- <p>Supplemental material (code examples, exercises, etc.) is available for download at <a href="https://github.com/oreillymedia/title_title">https://github.com/oreillymedia/title_title</a>.</p> -->

<p>Libraries, data, and websites are subject to continuous change. Therefore, it can easily happen that the verbatim code in the book will not run properly in the future. To overcome this, we will keep the repository up to date. If you discover any technical problems or have recommendations on how to improve the code, do not hesitate to create an issue in the repository or send us a pull request.</p>

<p>If you have a technical question or a problem using the code examples, please email <a class="email" href="mailto:bookquestions@oreilly.com"><em>bookquestions@oreilly.com</em></a>. In the case of technical problems, we recommend <a href="https://oreil.ly/ApUgF">creating an issue in the GitHub repo</a> and refer to O’Reilly’s errata page for errors in the book.</p>

<p>This book is here to help you get your job done. In general, if example code is offered with this book, you may use it in your programs and documentation. You do not need to contact us for permission unless you’re reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing examples from O’Reilly books does require permission. Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount <span class="keep-together">of example</span> code from this book into your product’s documentation does require <span class="keep-together">permission</span>.</p>

<p>You may use our code freely in your own projects without asking for permission. Especially if you publicly republish our code, we appreciate attribution. An attribution usually includes the title, author, publisher, and ISBN. For example: “<em>Blueprints for Text Analytics Using Python</em> by Jens Albrecht, Sidharth Ramachandran, and Christian Winkler (O’Reilly, 2021), 978-1-492-07408-3.”</p>

<p>If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at <a class="email" href="mailto:permissions@oreilly.com"><em>permissions@oreilly.com</em></a>.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="O’Reilly Online Learning"><div class="sect1" id="_safari_books_online">
<h1>O’Reilly Online Learning</h1>

<div class="ormenabled" data-type="note" epub:type="note"><h6>Note</h6>
<p>For more than 40 years, <a class="orm:hideurl" href="http://oreilly.com"><em class="hyperlink">O’Reilly Media</em></a> has provided technology and business training, knowledge, and insight to help companies succeed.</p>
</div>

<p>Our unique network of experts and innovators share their knowledge and expertise through books, articles, and our online learning platform. O’Reilly’s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from O’Reilly and 200+ other publishers. For more information, visit <a class="orm:hideurl" href="http://oreilly.com"><em>http://oreilly.com</em></a>.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="How to Contact Us"><div class="sect1" id="_how_to_contact_us">
<h1>How to Contact Us</h1>

<p>Please address comments and questions concerning this book to the publisher:</p>

<ul class="simplelist">
	<li>O’Reilly Media, Inc.</li>
	<li>1005 Gravenstein Highway North</li>
	<li>Sebastopol, CA 95472</li>
	<li>800-998-9938 (in the United States or Canada)</li>
	<li>707-829-0515 (international or local)</li>
	<li>707-829-0104 (fax)</li>
</ul>

<p>We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at <a href="https://oreil.ly/text-analytics-with-python" class="orm:hideurl"><em>https://oreil.ly/text-analytics-with-python</em></a>.</p>
<!--Don't forget to update the link above.-->

<p>Email <a class="email" href="mailto:bookquestions@oreilly.com"><em>bookquestions@oreilly.com</em></a> to comment or ask technical questions about this book.</p>

<p>For news and information about our books and courses, visit <a href="http://oreilly.com"><em>http://oreilly.com</em></a>.</p>

<p>Find us on Facebook: <a href="http://facebook.com/oreilly"><em>http://facebook.com/oreilly</em></a></p>

<p>Follow us on Twitter: <a href="http://twitter.com/oreillymedia"><em>http://twitter.com/oreillymedia</em></a></p>

<p>Watch us on YouTube: <a href="http://youtube.com/oreillymedia"><em>http://youtube.com/oreillymedia</em></a></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Acknowledgments"><div class="sect1" id="_acknowledgments">
<h1>Acknowledgments</h1>

<p>Writing a book is a challenge, not only for the authors but also for their families and friends. All of us expected that it would take a lot of time, but still we were surprised by how much time we needed to develop the stories for each of the chapters. As we are all working full-time jobs, the time for discussing, coding, writing, and rewriting had to be taken from our families.</p>

<p>Working with O’Reilly has been a great pleasure for all of us. From the original proposal, during the time of writing, and in the production phase, we enjoyed working with professionals and immensely benefited from their hints and suggestions. The most intense time for us was writing the individual chapters. During that, we were perfectly supported by our development editor, Amelia Blevins. Without her help and improvements, the book would have been stuck in a less-readable state.</p>

<p>We would also like to express our gratitude to our reviewers, Oliver Zeigermann, Benjamin Bock, Alexander Schneider, and Darren Cook. They used their expertise and a lot of their time to make excellent suggestions and improvements and also to find errors in the text and the notebooks.</p>

<p>As we used state-of-the-art features of libraries, we sometimes encountered problems or incompatibilities. With spaCy as a central component in our analytics pipeline, working with the super responsive team from Explosion (Ines Montani, Sofie Van Landeghem, and Adriane Boyd) was a great pleasure. Their comments on the sections covering spaCy have been extremely helpful. Thanks also to Burton DeWilde, the developer behind textacy, for checking parts of the code.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="idm45634210878232"><sup><a href="preface01.xhtml#idm45634210878232-marker">1</a></sup> Devlin, Jacob, et al., “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” 2018. <a href="https://arxiv.org/abs/1810.04805"><em>https://arxiv.org/abs/1810.04805</em></a>.</p></div></div></section></div>



  </body></html>