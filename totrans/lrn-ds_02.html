<html><head></head><body><section data-pdf-bookmark="Chapter 1. The Data Science Lifecycle" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch-lifecycle">&#13;
<h1><span class="label">Chapter 1. </span>The Data Science Lifecycle</h1>&#13;
&#13;
<p>Data<a contenteditable="false" data-primary="lifecycle, data science" data-type="indexterm" id="ix_lifecycle_data_sci"/> science is a rapidly evolving field. At the time of this writing, people are still trying to pin down exactly what data science is, what data scientists do, and what skills data scientists should have. What we do know, though, is that data science uses a combination of methods and principles from statistics and computer science to work with and draw insights from data. And learning computer science and statistics in combination makes us better data scientists. We also know that any insights we glean need to be interpreted in the context of the problem that we are working on.</p>&#13;
&#13;
<p>This book<a contenteditable="false" data-primary="data tables" data-secondary="shape of" data-see="shape of data table" data-type="indexterm" id="id599"/><a contenteditable="false" data-primary="data tables" data-secondary="grouping rows in" data-see="grouping in data tables" data-type="indexterm" id="id600"/><a contenteditable="false" data-primary="Drug Abuse Warning Network" data-see="DAWN" data-type="indexterm" id="id601"/><a contenteditable="false" data-primary="aggregation" data-secondary="smoothing" data-see="smoothing" data-type="indexterm" id="id602"/><a contenteditable="false" data-primary="American Kennel Club" data-see="dog breeds dataset" data-type="indexterm" id="id603"/><a contenteditable="false" data-primary="AQS (Air Quality System)" data-see="air quality sensors study" data-type="indexterm" id="id604"/><a contenteditable="false" data-primary="baby names dataset" data-see="dataframes; SQL" data-type="indexterm" id="id605"/><a contenteditable="false" data-primary="classification" data-secondary="fake news detection" data-see="fake news detection case study" data-type="indexterm" id="id606"/><a contenteditable="false" data-primary="dates and times" data-see="times and dates" data-type="indexterm" id="id607"/><a contenteditable="false" data-primary="distributions" data-see="data distributions" data-type="indexterm" id="id608"/><a contenteditable="false" data-primary="donkey weight prediction case study" data-see="weighing a donkey case study" data-type="indexterm" id="id609"/><a contenteditable="false" data-primary="EDA" data-see="exploratory data analysis" data-type="indexterm" id="id610"/><a contenteditable="false" data-primary="feature engineering" data-secondary="transforming features" data-see="transformations" data-type="indexterm" id="id611"/><a contenteditable="false" data-primary="features and feature types" data-secondary="transforming features" data-see="transformations" data-type="indexterm" id="id612"/><a contenteditable="false" data-primary="functions" data-secondary="loss functions" data-see="loss functions" data-type="indexterm" id="id613"/><a contenteditable="false" data-primary="linear modeling" data-secondary="inference and prediction" data-see="theory for inference and prediction" data-type="indexterm" id="id614"/><a contenteditable="false" data-primary="linear modeling" data-secondary="model selection" data-see="model selection" data-type="indexterm" id="id615"/><a contenteditable="false" data-primary="modeling" data-secondary="fitting" data-see="fitting the model" data-type="indexterm" id="id616"/><a contenteditable="false" data-primary="modeling" data-secondary="linear model" data-see="linear modeling" data-type="indexterm" id="id617"/><a contenteditable="false" data-primary="modeling" data-secondary="urn model" data-see="urn model" data-type="indexterm" id="id618"/><a contenteditable="false" data-primary="plots for data distributions" data-see="visualization, data" data-type="indexterm" id="id619"/><a contenteditable="false" data-primary="predictions and predicting" data-secondary="donkey weight" data-see="weighing a donkey case study" data-type="indexterm" id="id620"/><a contenteditable="false" data-primary="quantitative data and features" data-see="numeric data" data-type="indexterm" id="id621"/><a contenteditable="false" data-primary="rectangular data" data-see="dataframes; relations" data-type="indexterm" id="id622"/><a contenteditable="false" data-primary="San Francisco Bay area home prices" data-see="home sale prices example" data-type="indexterm" id="id623"/><a contenteditable="false" data-primary="San Francisco restaurant" data-see="restaurant food safety dataset" data-type="indexterm" id="id624"/><a contenteditable="false" data-primary="scope of data consideration" data-see="data scope" data-type="indexterm" id="id625"/><a contenteditable="false" data-primary="structured query language" data-see="SQL" data-type="indexterm" id="id626"/><a contenteditable="false" data-primary="weights" data-see="parameters" data-type="indexterm" id="id627"/> covers fundamental principles and skills that data scientists need to help make all sorts of important decisions. With both technical skills and conceptual understanding we can work on data-centric problems to, say, assess whether a vaccine works, filter out fake news automatically, calibrate air quality sensors, and advise analysts on policy changes.</p>&#13;
&#13;
<p>To help you keep track of the bigger picture, we’ve organized topics around a workflow that we call the <em>data science lifecycle</em>. In this chapter, we introduce this lifecycle. Unlike other data science books, which tend to focus on one part of the lifecycle or address only computational or statistical topics, we cover the entire cycle from start to finish and consider both statistical and computational aspects together.</p>&#13;
&#13;
<section data-pdf-bookmark="The Stages of the Lifecycle" data-type="sect1"><div class="sect1" id="the-stages-of-the-lifecycle">&#13;
<h1>The Stages of the Lifecycle</h1>&#13;
&#13;
<p><a class="reference internal" data-type="xref" href="#ds-lifecycle">Figure 1-1</a> shows the data science lifecycle<a contenteditable="false" data-primary="lifecycle, data science" data-secondary="stages of" data-type="indexterm" id="ix_lifecycle_stage"/>, which is divided into four stages: Ask a Question, Obtain Data, Understand the Data, and Understand the World. We’ve purposefully made these stages broad. In our experience, the mechanics of the lifecycle change frequently. Computer scientists and statisticians continue to build new software packages and programming languages for working with data, and they develop new methodologies that are more specialized.</p>&#13;
&#13;
<figure><div class="figure" id="ds-lifecycle"><img src="assets/leds_0101.png"/>&#13;
<h6><span class="label">Figure 1-1. </span>The four high-level stages of the data science lifecycle with arrows indicating how the stages can lead into one another</h6>&#13;
</div></figure>&#13;
&#13;
<p> Despite these changes, we’ve found that almost every data project consists of these four stages:</p>&#13;
&#13;
<dl class="simple myst">&#13;
	<dt>Ask a Question</dt>&#13;
	<dd>&#13;
	<p>Asking good questions is at the heart of data science, and recognizing different kinds of questions guides us in our analyses. We cover four categories of questions: descriptive, exploratory, inferential, and predictive. For example, “How have house prices changed over time?” is descriptive in nature, whereas “Which aspects of houses are related to sale price?” is exploratory. Narrowing down a broad question into one that can be answered with data is a key element of this first stage in the lifecycle. It can involve consulting the people participating in a study, figuring out how to measure something, and designing data collection protocols. A clear and focused research question helps us determine the data we need, the patterns to look for, and how to interpret results. It can also help us refine our question, recognize the type of question being asked, and plan the data collection phase of the lifecycle.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<dl class="simple myst">&#13;
	<dt>Obtain Data</dt>&#13;
	<dd>&#13;
	<p>When data are expensive and hard to gather and when our goal is to generalize from the data to the world, we aim to define precise protocols for collecting the data. Other times, data are cheap and easily accessed. This is especially true for online data sources. For example, <a class="reference external" href="https://oreil.ly/WvUhe">Twitter</a> lets people quickly download millions of data points. When data are plentiful, we can start an analysis by obtaining and exploring the data, and then honing a research question. In both situations, most data have missing or unusual values and other anomalies that we need to account for. No matter the source, we need to check the data quality. Considering the scope of the data is equally important; for example, we identify how representative the data are and look for potential sources of bias in the collection process. These considerations help us determine how much faith we can place in our findings. And, typically, we must manipulate the data before we can analyze it more formally. We may need to modify structure, clean data values, and transform measurements to prepare for analysis.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<dl class="simple myst">&#13;
	<dt>Understand the Data</dt>&#13;
	<dd>&#13;
	<p>After <a contenteditable="false" data-primary="exploratory data analysis (EDA)" data-type="indexterm" id="id628"/>obtaining and preparing data, we want to carefully examine them, and <em>exploratory data analysis</em> is often key. In our explorations, we make plots to uncover interesting patterns and summarize the data visually. We also continue to look for problems with the data. As we search for patterns and trends, we use summary statistics and build statistical models, like linear and logistic regression. In our experience, this stage of the lifecycle is highly iterative. Understanding the data can also lead us back to earlier stages in the data science lifecycle. We may find that we need to modify or redo the data cleaning and manipulation, acquire more data to supplement our analysis, or refine our research question given the limitations of the data. The descriptive and exploratory analyses that we carry out in this stage may adequately answer our question, or we may need to go on to the next stage in order to make generalizations beyond our data.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<dl class="simple myst">&#13;
	<dt>Understand the World</dt>&#13;
	<dd>&#13;
	<p>When our goals are purely descriptive or exploratory, the analysis ends at the Understand the Data stage of the lifecycle. At other times, we aim to quantify how well the trends we find generalize beyond our data. We may want to use a model that we have fit to our data to make inferences about the world or give predictions for future observations. To draw inferences from a sample to a population, we use statistical techniques like A/B testing and confidence intervals. And to make predictions for future observations, we create prediction intervals and use train-test splits of the data.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>For each stage of the lifecycle, we explain theoretical concepts, introduce data technologies and statistical methodologies, and show how they work in practical examples. Throughout, we rely on authentic data and analyses by other data scientists, not made-up data, so you can learn how to perform your own data acquisition, cleaning, exploration, and formal analyses, and draw sound conclusions. Each chapter in this book tends to focus on one stage of the data science lifecycle, but we also include chapters with case studies that demonstrate the full lifecycle.<a contenteditable="false" data-primary="" data-startref="ix_lifecycle_stage" data-type="indexterm" id="id629"/></p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
	<p>Understanding the differences between exploration, inference, prediction, and causation can be a challenge. We can easily slip into confusing a correlation<a contenteditable="false" data-primary="causation versus correlation" data-type="indexterm" id="id630"/><a contenteditable="false" data-primary="correlation versus causation" data-type="indexterm" id="id631"/> found in data with a causal relationship. For example, an exploratory or inferential analysis might look for correlations in response to the question “Do people who have a greater exposure to air pollution have a higher rate of lung disease?” Whereas a causal question might ask “Does giving an award to a Wikipedia contributor increase productivity?” We typically cannot answer causal questions unless we have a randomized experiment (or approximate one). We point out these important distinctions throughout the book.</p>&#13;
	</div>&#13;
	&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Examples of the Lifecycle" data-type="sect1"><div class="sect1" id="examples-of-the-lifecycle">&#13;
<h1>Examples of the Lifecycle</h1>&#13;
&#13;
<p>Several case<a contenteditable="false" data-primary="lifecycle, data science" data-secondary="examples" data-type="indexterm" id="id632"/><a contenteditable="false" data-primary="case studies, purpose of" data-type="indexterm" id="id633"/> studies that address the entire data science lifecycle are placed throughout this book. These cases serve double duty. They focus on one stage in the lifecycle to provide a specific example of the topics in the part of the book where they are located, and they also demonstrate the entire cycle.</p>&#13;
&#13;
<p>The focus of <a class="reference internal" data-type="xref" href="ch05.html#ch-bus">Chapter 5</a> is on the interplay between a question of interest and how data can be used to answer the question. The simple question “Why is my bus always late?” provides a rich case study that is basic enough for the beginning data scientist to track the stages of the lifecycle, and yet nuanced enough to demonstrate how we apply both statistical and computational thinking to answer the question. In this case study, we build a simulation study to inform us about the distribution of wait times for riders. And we fit a simple model to summarize the wait times with a statistic. This case study also demonstrates how, as a data scientist, you can collect your own data to answer questions that interest you.</p>&#13;
&#13;
<p><a class="reference internal" data-type="xref" href="ch12.html#ch-pa">Chapter 12</a> studies the accuracy of mass-market air sensors that are used across the United States. We devise a way to leverage data from highly accurate sensors maintained by the Environmental Protection Agency to improve readings from less expensive sensors. This case study shows how crowdsourced, open data can be improved with data from rigorously maintained, precise, government-monitored equipment. In the process, we focus on cleaning and merging data from multiple sources, but we also fit models to adjust and improve air quality measurements.</p>&#13;
&#13;
<p>In <a class="reference internal" data-type="xref" href="ch18.html#ch-donkey">Chapter 18</a> our focus is on model building and prediction. But we cover the full lifecycle and see how the question of interest impacts the model that we build. Our aim is to enable veterinarians in rural Kenya, who have no access to a scale to weigh a donkey, to prescribe medication for a sick animal. As we learn about the design of the study, clean the data, and balance simplicity with accuracy, we assess the predictive capabilities of our model and show how scientists can partner with people facing practical problems and assist them with solutions.</p>&#13;
&#13;
<p>Finally, in <a class="reference internal" data-type="xref" href="ch21.html#ch-fake-news">Chapter 21</a> we examine hand-classified news stories in an effort to algorithmically differentiate fake news from real news. In this case study, we again see how readily accessible information creates amazing opportunities for data scientists to develop new technologies and investigate today’s important problems. These data have been scraped from news stories on the web and classified as fake or real news by people reading the stories. We also see how data scientists thinking creatively can take general information, such as the content of a news article, and transform it into analyzable data to address topical questions.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="sec-lifecycle-summary">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>The data science lifecycle provides an organizing structure for this book. We keep the lifecycle in mind as we work with many datasets from a wide range of sources, including science, medicine, politics, social media, and government. The first time we use a dataset, we provide the context in which the data were collected, the question of interest in examining the data, and descriptions needed to understand the data. In this way, we aim to practice good data science throughout the book.<a contenteditable="false" data-primary="" data-startref="ix_lifecycle_data_sci" data-type="indexterm" id="id634"/></p>&#13;
&#13;
<p>The first stage of the lifecycle—asking a question—is often seen in books as a question that requires an application of a technique to get a number, such as “What’s the <em>p</em>-value for this A/B test?” Or a vague question that is often seen in practice, like “Can we restore the American Dream?” Answering the first sort of question gives little practice in developing a research question. Answering the second is hard to do without guidance on how to turn a general area of interest into a question that can be answered with data. The interplay between asking a question and understanding the limitations of data to answer it is the topic of the next chapter.</p>&#13;
</div></section>&#13;
</div></section></body></html>