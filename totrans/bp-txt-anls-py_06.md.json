["```py\ndf = pd.read_csv('eclipse_jdt.csv')\nprint (df.columns)\ndf[['Issue_id','Priority','Component','Title','Description']].sample(2)\n\n```", "```py\nIndex(['Issue_id', 'Priority', 'Component', 'Duplicated_issue', 'Title',\n       'Description', 'Status', 'Resolution', 'Version', 'Created_time',\n       'Resolved_time'],\n      dtype='object')\n\n```", "```py\ndf.sample(1).T\n\n```", "```py\ndf['Priority'].value_counts().sort_index().plot(kind='bar')\n\n```", "```py\ndf['Component'].value_counts()\n\n```", "```py\nUI       17479\nCore     13669\nDebug    7542\nText     5901\nAPT      406\nDoc      299\nName: Component, dtype: int64\n\n```", "```py\ndf = df[['Title','Description','Priority']]\ndf = df.dropna()\ndf['text'] = df['Title'] + ' ' + df['Description']\ndf = df.drop(columns=['Title','Description'])\ndf.columns\n\n```", "```py\n\tIndex(['Priority', 'text'], dtype='object')\n\n```", "```py\n\tdf['text'] = df['text'].apply(clean)\n\tdf = df[df['text'].str.len() > 50]\n\tdf.sample(2)\n\n```", "```py\nX_train, X_test, Y_train, Y_test = train_test_split(df['text'],\n                                                    df['Priority'],\n                                                    test_size=0.2,\n                                                    random_state=42,\n                                                    stratify=df['Priority'])\n\nprint('Size of Training Data ', X_train.shape[0])\nprint('Size of Test Data ', X_test.shape[0])\n\n```", "```py\nSize of Training Data  36024\nSize of Test Data  9006\n\n```", "```py\ntfidf = TfidfVectorizer(min_df = 10, ngram_range=(1,2), stop_words=\"english\")\nX_train_tf = tfidf.fit_transform(X_train)\n\n```", "```py\nmodel1 = LinearSVC(random_state=0, tol=1e-5)\nmodel1.fit(X_train_tf, Y_train)\n\n```", "```py\nLinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n          verbose=0)\n\n```", "```py\nX_test_tf = tfidf.transform(X_test)\n\nY_pred = model1.predict(X_test_tf)\nprint ('Accuracy Score - ', accuracy_score(Y_test, Y_pred))\n\n```", "```py\nAccuracy Score -  0.8748612036420165\n\n```", "```py\nclf = DummyClassifier(strategy='most_frequent')\nclf.fit(X_train, Y_train)\nY_pred_baseline = clf.predict(X_test)\nprint ('Accuracy Score - ', accuracy_score(Y_test, Y_pred_baseline))\n\n```", "```py\nAccuracy Score -  0.8769709082833667\n\n```", "```py\nY_pred = model1.predict(X_test_tf)\nconfusion_matrix(Y_test, Y_pred)\n\n```", "```py\narray([[  17,    6,  195,    5,    0],\n       [   7,   14,  579,    7,    0],\n       [  21,   43, 7821,   13,    0],\n       [   0,    7,  194,   27,    0],\n       [   0,    0,   50,    0,    0]])\n\n```", "```py\nplot_confusion_matrix(model1,X_test_tf,\n                      Y_test, values_format='d',\n                      cmap=plt.cm.Blues)\nplt.show()\n\n```", "```py\nprint(classification_report(Y_test, Y_pred))\n\n```", "```py\n              precision    recall  f1-score   support\n\n          P1       0.38      0.08      0.13       223\n          P2       0.20      0.02      0.04       607\n          P3       0.88      0.99      0.93      7898\n          P4       0.52      0.12      0.19       228\n          P5       0.00      0.00      0.00        50\n\n    accuracy                           0.87      9006\n   macro avg       0.40      0.24      0.26      9006\nweighted avg       0.81      0.87      0.83      9006\n\n```", "```py\n# Filter bug reports with priority P3 and sample 4000 rows from it\ndf_sampleP3 = df[df['Priority'] == 'P3'].sample(n=4000)\n\n# Create a separate DataFrame containing all other bug reports\ndf_sampleRest = df[df['Priority'] != 'P3']\n\n# Concatenate the two DataFrame to create the new balanced bug reports dataset\ndf_balanced = pd.concat([df_sampleRest, df_sampleP3])\n\n# Check the status of the class imbalance\ndf_balanced['Priority'].value_counts()\n\n```", "```py\nP3    4000\nP2    3036\nP4    1138\nP1    1117\nP5    252\nName: Priority, dtype: int64\n\n```", "```py\n# Loading the balanced DataFrame\n\ndf = df_balanced[['text', 'Priority']]\ndf = df.dropna()\n\n# Step 1 - Data Preparation\n\ndf['text'] = df['text'].apply(clean)\n\n# Step 2 - Train-Test Split\nX_train, X_test, Y_train, Y_test = train_test_split(df['text'],\n                                                    df['Priority'],\n                                                    test_size=0.2,\n                                                    random_state=42,\n                                                    stratify=df['Priority'])\nprint('Size of Training Data ', X_train.shape[0])\nprint('Size of Test Data ', X_test.shape[0])\n\n# Step 3 - Training the Machine Learning model\n\ntfidf = TfidfVectorizer(min_df=10, ngram_range=(1, 2), stop_words=\"english\")\nX_train_tf = tfidf.fit_transform(X_train)\n\nmodel1 = LinearSVC(random_state=0, tol=1e-5)\nmodel1.fit(X_train_tf, Y_train)\n\n# Step 4 - Model Evaluation\n\nX_test_tf = tfidf.transform(X_test)\nY_pred = model1.predict(X_test_tf)\nprint('Accuracy Score - ', accuracy_score(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))\n\n```", "```py\nSize of Training Data  7634\nSize of Test Data  1909\nAccuracy Score -  0.4903090623363017\n              precision    recall  f1-score   support\n\n          P1       0.45      0.29      0.35       224\n          P2       0.42      0.47      0.44       607\n          P3       0.56      0.65      0.61       800\n          P4       0.39      0.29      0.33       228\n          P5       0.00      0.00      0.00        50\n\n    accuracy                           0.49      1909\n   macro avg       0.37      0.34      0.35      1909\nweighted avg       0.47      0.49      0.48      1909\n\n```", "```py\nclf = DummyClassifier(strategy='stratified')\nclf.fit(X_train, Y_train)\nY_pred_baseline = clf.predict(X_test)\nprint ('Accuracy Score - ', accuracy_score(Y_test, Y_pred_baseline))\n\n```", "```py\nAccuracy Score -  0.30434782608695654\n\n```", "```py\n# Create a DataFrame combining the Title and Description,\n# Actual and Predicted values that we can explore\nframe = { 'text': X_test, 'actual': Y_test, 'predicted': Y_pred }\nresult = pd.DataFrame(frame)\n\nresult[((result['actual'] == 'P1') | (result['actual'] == 'P2')) &\n       (result['actual'] == result['predicted'])].sample(2)\n\n```", "```py\nresult[((result['actual'] == 'P1') | (result['actual'] == 'P2')) &\n       (result['actual'] != result['predicted'])].sample(2)\n\n```", "```py\n# Vectorization\n\ntfidf = TfidfVectorizer(min_df = 10, ngram_range=(1,2), stop_words=\"english\")\ndf_tf = tfidf.fit_transform(df['text']).toarray()\n\n# Cross Validation with 5 folds\n\nscores = cross_val_score(estimator=model1,\n                         X=df_tf,\n                         y=df['Priority'],\n                         cv=5)\n\nprint (\"Validation scores from each iteration of the cross validation \", scores)\nprint (\"Mean value across of validation scores \", scores.mean())\nprint (\"Standard deviation of validation scores \", scores.std())\n\n```", "```py\nValidation scores from each iteration of the cross validation\n[0.47773704 0.47302252 0.45468832 0.44054479 0.3677318 ]\nMean value across of validation scores  0.44274489261393396\nStandard deviation of validation scores  0.03978852971586144\n\n```", "```py\ntraining_pipeline = Pipeline(\n    steps=[('tfidf', TfidfVectorizer(stop_words=\"english\")),\n            ('model', LinearSVC(random_state=42, tol=1e-5))])\n\ngrid_param = [{\n    'tfidf__min_df': [5, 10],\n    'tfidf__ngram_range': [(1, 3), (1, 6)],\n    'model__penalty': ['l2'],\n    'model__loss': ['hinge'],\n    'model__max_iter': [10000]\n}, {\n    'tfidf__min_df': [5, 10],\n    'tfidf__ngram_range': [(1, 3), (1, 6)],\n    'model__C': [1, 10],\n    'model__tol': [1e-2, 1e-3]\n}]\n\ngridSearchProcessor = GridSearchCV(estimator=training_pipeline,\n                                   param_grid=grid_param,\n                                   cv=5)\ngridSearchProcessor.fit(df['text'], df['Priority'])\n\nbest_params = gridSearchProcessor.best_params_\nprint(\"Best alpha parameter identified by grid search \", best_params)\n\nbest_result = gridSearchProcessor.best_score_\nprint(\"Best result identified by grid search \", best_result)\n\n```", "```py\nBest alpha parameter identified by grid search  {'model__loss': 'hinge',\n'model__max_iter': 10000, 'model__penalty': 'l2', 'tfidf__min_df': 10,\n'tfidf__ngram_range': (1, 6)}\nBest result identified by grid search  0.46390780513357777\n\n```", "```py\ngridsearch_results = pd.DataFrame(gridSearchProcessor.cv_results_)\ngridsearch_results[['rank_test_score', 'mean_test_score',\n                    'params']].sort_values(by=['rank_test_score'])[:5]\n\n```", "```py\n# Flag that determines the choice of SVC and LinearSVC\nrunSVC = True\n\n# Loading the DataFrame\n\ndf = pd.read_csv('eclipse_jdt.csv')\ndf = df[['Title', 'Description', 'Component']]\ndf = df.dropna()\ndf['text'] = df['Title'] + df['Description']\ndf = df.drop(columns=['Title', 'Description'])\n\n# Step 1 - Data Preparation\ndf['text'] = df['text'].apply(clean)\ndf = df[df['text'].str.len() > 50]\n\nif (runSVC):\n    # Sample the data when running SVC to ensure reasonable run-times\n    df = df.groupby('Component', as_index=False).apply(pd.DataFrame.sample,\n                                                       random_state=21,\n                                                       frac=.2)\n\n# Step 2 - Train-Test Split\nX_train, X_test, Y_train, Y_test = train_test_split(df['text'],\n                                                    df['Component'],\n                                                    test_size=0.2,\n                                                    random_state=42,\n                                                    stratify=df['Component'])\nprint('Size of Training Data ', X_train.shape[0])\nprint('Size of Test Data ', X_test.shape[0])\n\n# Step 3 - Training the Machine Learning model\ntfidf = TfidfVectorizer(stop_words=\"english\")\n\nif (runSVC):\n    model = SVC(random_state=42, probability=True)\n    grid_param = [{\n        'tfidf__min_df': [5, 10],\n        'tfidf__ngram_range': [(1, 3), (1, 6)],\n        'model__C': [1, 100],\n        'model__kernel': ['linear']\n    }]\nelse:\n    model = LinearSVC(random_state=42, tol=1e-5)\n    grid_param = {\n        'tfidf__min_df': [5, 10],\n        'tfidf__ngram_range': [(1, 3), (1, 6)],\n        'model__C': [1, 100],\n        'model__loss': ['hinge']\n    }\n\ntraining_pipeline = Pipeline(\n    steps=[('tfidf', TfidfVectorizer(stop_words=\"english\")), ('model', model)])\n\ngridSearchProcessor = GridSearchCV(estimator=training_pipeline,\n                                   param_grid=grid_param,\n                                   cv=5)\n\ngridSearchProcessor.fit(X_train, Y_train)\n\nbest_params = gridSearchProcessor.best_params_\nprint(\"Best alpha parameter identified by grid search \", best_params)\n\nbest_result = gridSearchProcessor.best_score_\nprint(\"Best result identified by grid search \", best_result)\n\nbest_model = gridSearchProcessor.best_estimator_\n\n# Step 4 - Model Evaluation\n\nY_pred = best_model.predict(X_test)\nprint('Accuracy Score - ', accuracy_score(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))\n\n```", "```py\nSize of Training Data  7204\nSize of Test Data  1801\nBest alpha parameter identified by grid search  {'model__C': 1,\n'model__kernel': 'linear', 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 6)}\nBest result identified by grid search  0.739867279666898\nAccuracy Score -  0.7368128817323709\n              precision    recall  f1-score   support\n\n         APT       1.00      0.25      0.40        16\n        Core       0.74      0.77      0.75       544\n       Debug       0.89      0.77      0.82       300\n         Doc       0.50      0.17      0.25        12\n        Text       0.61      0.45      0.52       235\n          UI       0.71      0.81      0.76       694\n\n    accuracy                           0.74      1801\n   macro avg       0.74      0.54      0.58      1801\nweighted avg       0.74      0.74      0.73      1801\n\n```", "```py\nclf = DummyClassifier(strategy='most_frequent')\nclf.fit(X_train, Y_train)\nY_pred_baseline = clf.predict(X_test)\nprint ('Accuracy Score - ', accuracy_score(Y_test, Y_pred_baseline))\n\n```", "```py\nAccuracy Score -  0.38534147695724597\n\n```", "```py\n# Create a DataFrame combining the Title and Description,\n# Actual and Predicted values that we can explore\nframe = { 'text': X_test, 'actual': Y_test, 'predicted': Y_pred }\nresult = pd.DataFrame(frame)\n\nresult[result['actual'] == result['predicted']].sample(2)\n\n```", "```py\nresult[result['actual'] != result['predicted']].sample(2)\n\n```"]