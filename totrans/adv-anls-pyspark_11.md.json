["```py\n$ pip3 install mlflow\n```", "```py\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import DecisionTreeClassifier\n\ndata_without_header = spark.read.option(\"inferSchema\", True).\\\n                                option(\"header\", False).\\\n                                csv(\"data/covtype.data\")\n\ncolnames = [\"Elevation\", \"Aspect\", \"Slope\",\n            \"Horizontal_Distance_To_Hydrology\",\n            \"Vertical_Distance_To_Hydrology\",\n            \"Horizontal_Distance_To_Roadways\",\n            \"Hillshade_9am\", \"Hillshade_Noon\",\n            \"Hillshade_3pm\", \"Horizontal_Distance_To_Fire_Points\"] + \\\n[f\"Wilderness_Area_{i}\" for i in range(4)] + \\\n[f\"Soil_Type_{i}\" for i in range(40)] + \\\n[\"Cover_Type\"]\n\ndata = data_without_header.toDF(*colnames).\\\n                            withColumn(\"Cover_Type\",\n                                        col(\"Cover_Type\").\\\n                                        cast(DoubleType()))\n\n(train_data, test_data) = data.randomSplit([0.9, 0.1])\n\ninput_cols = colnames[:-1]\nvector_assembler = VectorAssembler(inputCols=input_cols,outputCol=\"featureVector\")\n\nclassifier = DecisionTreeClassifier(seed = 1234,\n                                    labelCol=\"Cover_Type\",\n                                    featuresCol=\"featureVector\",\n                                    predictionCol=\"prediction\")\n\npipeline = Pipeline(stages=[vector_assembler, classifier])\n```", "```py\nimport mlflow\nimport mlflow.spark\nimport pandas as pd\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nwith mlflow.start_run(run_name=\"decision-tree\"):\n    # Log param: max_depth\n    mlflow.log_param(\"max_depth\", classifier.getMaxDepth())\n    # Log model\n    pipeline_model = pipeline.fit(train_data)\n    mlflow.spark.log_model(pipeline_model, \"model\")\n    # Log metrics: Accuracy and F1\n    pred_df = pipeline_model.transform(test_data)\n    evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\",\n                                                predictionCol=\"prediction\")\n    accuracy = evaluator.setMetricName(\"accuracy\").evaluate(pred_df)\n    f1 = evaluator.setMetricName(\"f1\").evaluate(pred_df)\n    mlflow.log_metrics({\"accuracy\": accuracy, \"f1\": f1})\n    # Log artifact: feature importance scores\n    tree_model = pipeline_model.stages[-1]\n    feature_importance_df = (pd.DataFrame(list(\n                                    zip(vector_assembler.getInputCols(),\n                                    tree_model.featureImportances)),\n                            columns=[\"feature\", \"importance\"])\n                .sort_values(by=\"importance\", ascending=False))\n    feature_importance_df.to_csv(\"feature-importance.csv\", index=False)\n    mlflow.log_artifact(\"feature-importance.csv\")\n```", "```py\nimport mlflow\n\nrun_id = \"0433bb047f514e28a73109bbab767222\" ![1](assets/1.png)\nlogged_model = f'runs:/{run_id}/model' ![2](assets/2.png)\n\n# Load model as a Spark UDF.\nloaded_model = mlflow.spark.load_model(model_uri=logged_model)\n\n# Predict on a Spark DataFrame.\npreds = loaded_model.transform(test_data)\npreds.select('Cover_Type', 'rawPrediction', 'probability', 'prediction').\\\n        show(1, vertical=True)\n...\n-RECORD 0-----------------------------\n Cover_Type    | 6.0\n rawPrediction | [0.0,0.0,605.0,15...\n probability   | [0.0,0.0,0.024462...\n prediction    | 3.0\nonly showing top 1 row\n```", "```py\n$ mlflow models serve --model-uri runs:/0433bb047f514e28a73109bbab767222/model \\\n        -p 7000\n\n...\n\n2021/11/13 12:13:49 INFO mlflow.models.cli: Selected backend for...\n2021/11/13 12:13:52 INFO mlflow.utils.conda: === Creating conda ...\nCollecting package metadata (repodata.json): done\nSolving environment: done ...\n```", "```py\npip3 install requests\n```", "```py\nimport requests\n\nhost = '0.0.0.0'\nport = '7001'\n\nurl = f'http://{host}:{port}/invocations'\n\nheaders = {\n    'Content-Type': 'application/json;',\n    'format': 'pandas-split';\n}\n\nhttp_data = '{\"columns\":[\"Elevation\",\"Aspect\",\"Slope\", \\\n \"Horizontal_Distance_To_Hydrology\", \\\n \"Vertical_Distance_To_Hydrology\",\"Horizontal_Distance_To_Roadways\", \\\n \"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\",\\\n \"Horizontal_Distance_To_Fire_Points\",\\\n \"Wilderness_Area_0\",\"Wilderness_Area_1\",\"Wilderness_Area_2\",\\\n \"Wilderness_Area_3\",\"Soil_Type_0\",\"Soil_Type_1\",\"Soil_Type_2\",\\\n \"Soil_Type_3\",\"Soil_Type_4\",\"Soil_Type_5\",\"Soil_Type_6\",\\\n \"Soil_Type_7\",\"Soil_Type_8\",\"Soil_Type_9\",\"Soil_Type_10\",\\\n \"Soil_Type_11\",\"Soil_Type_12\",\"Soil_Type_13\",\\\n \"Soil_Type_14\",\"Soil_Type_15\",\"Soil_Type_16\",\\\n \"Soil_Type_17\",\"Soil_Type_18\",\"Soil_Type_19\",\\\n \"Soil_Type_20\",\"Soil_Type_21\",\"Soil_Type_22\",\\\n \"Soil_Type_23\",\"Soil_Type_24\",\"Soil_Type_25\",\\\n \"Soil_Type_26\",\"Soil_Type_27\",\"Soil_Type_28\",\\\n \"Soil_Type_29\",\"Soil_Type_30\",\"Soil_Type_31\",\\\n \"Soil_Type_32\",\"Soil_Type_33\",\"Soil_Type_34\",\\\n \"Soil_Type_35\",\"Soil_Type_36\",\"Soil_Type_37\",\\\n \"Soil_Type_38\",\"Soil_Type_39\",\"Cover_Type\"],\\\n \"index\":[0],\\\n \"data\":[[2596,51,3,258,0,510,221,232,148,6279,1,\\\n 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\\\n 0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,5.0]]'\\\n\nr = requests.post(url=url, headers=headers, data=http_data)\n\nprint(f'Predictions: {r.text}')\n...\nPredictions: [2.0]\n```", "```py\nmkdir decision_tree_project\ncd decision_tree_project\n```", "```py\nname: decision_tree_project\n\nconda_env: conda.yml\n\nentry_points:\n  main:\n    command: \"python train.py\"\n```", "```py\nchannels:\n- conda-forge\ndependencies:\n- python=3.6.12\n- pip\n- pip:\n  - mlflow\n  - pyspark==3.2.1\n  - scipy==1.5.3\nname: mlflow-env\n```", "```py\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nspark = SparkSession.builder.appName(\"App\").getOrCreate()\n\ndef main():\n    data_without_header = spark.read.option(\"inferSchema\", True).\\\n                                    option(\"header\", False).\\\n                                    csv(\"../data/covtype.data\") ![1](assets/1.png)\n\n    colnames = [\"Elevation\", \"Aspect\", \"Slope\",\n                \"Horizontal_Distance_To_Hydrology\",\n                \"Vertical_Distance_To_Hydrology\",\n                \"Horizontal_Distance_To_Roadways\",\n                \"Hillshade_9am\", \"Hillshade_Noon\",\n                \"Hillshade_3pm\",\n                \"Horizontal_Distance_To_Fire_Points\"] + \\\n    [f\"Wilderness_Area_{i}\" for i in range(4)] + \\\n    [f\"Soil_Type_{i}\" for i in range(40)] + \\\n    [\"Cover_Type\"]\n\n    data = data_without_header.toDF(*colnames).\\\n                                withColumn(\"Cover_Type\",\n                                            col(\"Cover_Type\").\\\n                                            cast(DoubleType()))\n\n    (train_data, test_data) = data.randomSplit([0.9, 0.1])\n\n    input_cols = colnames[:-1]\n    vector_assembler = VectorAssembler(inputCols=input_cols,\n                                outputCol=\"featureVector\")\n\n    classifier = DecisionTreeClassifier(seed = 1234,\n                                        labelCol=\"Cover_Type\",\n                                        featuresCol=\"featureVector\",\n                                        predictionCol=\"prediction\")\n\n    pipeline = Pipeline(stages=[vector_assembler, classifier])\n\n    pipeline_model = pipeline.fit(train_data)\n    # Log metrics: Accuracy and F1\n    pred_df = pipeline_model.transform(test_data)\n    evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\",\n                                                predictionCol=\"prediction\")\n    accuracy = evaluator.setMetricName(\"accuracy\").evaluate(pred_df)\n    f1 = evaluator.setMetricName(\"f1\").evaluate(pred_df)\n    print({\"accuracy\": accuracy, \"f1\": f1})\n\nif __name__ == \"__main__\":\n    main()\n```", "```py\nmlflow run decision_tree_project\n...\n[...]\n{'accuracy': 0.6988990605087336, 'f1': 0.6805617730220171}\n```"]