- en: Chapter 4\. Optimization For Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*I have lived each and every day of my life optimizing… My first aha moment
    was when I learned that our brain too, learns a model of the world.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Various artificial neural networks have fully connected layers in their architecture.
    In this chapter, we explain how the mathematics of a fully connected neural network
    works and walk through an end to end example with a real data set. We design and
    experiment with various training and loss functions. We also explain that the
    optimization and back-propagation steps used when training neural networks are
    similar to how learning happens in our brain. The brain learns by reinforcing
    neuron connections when faced with a concept it has seen before and weakening
    connections if it learns new information that undoes or contradicts previously
    learned concepts. Machines only understand numbers. Mathematically, stronger connections
    correspond to larger numbers, and weaker connections correspond to smaller numbers.
  prefs: []
  type: TYPE_NORMAL
- en: We finally walk through various regularization techniques, explaining their
    advantages, disadvantages, and use cases.
  prefs: []
  type: TYPE_NORMAL
- en: The Brain Cortex And Artificial Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural networks are modeled after the brain cortex, which involves billions
    of neurons arranged in a layered structure. [Figure 4-1](#Fig_Cajal_cortex_drawings)
    shows an image of three vertical cross sections of the brain neocortex and [Figure 4-2](#Fig_neural_network)
    shows a diagram of a fully connected artificial neural network.
  prefs: []
  type: TYPE_NORMAL
- en: '![300](assets/emai_0401.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4-1\. Three drawings of cortical lamination by Santiago Ramon y Cajal,
    taken from the book Comparative study of the sensory areas of the human cortex.
    Each drawing shows a vertical cross-section of the cortex, with the surface (outermost
    side which is the closest to the skull) of the cortex at the top. Left: Nissl
    stained visual cortex of a human adult. Middle: Nissl stained motor cortex of
    a human adult. Right: Golgi-stained cortex of a month and a half old infant. The
    Nissl stain shows the cell bodies of neurons. The Golgi stain shows the dendrites
    and axons of a random subset of neurons.Image source: [Wikipedia](https://commons.wikimedia.org/wiki/File:Cajal_cortex_drawings.png).
    The layered structure of the neurons in the cortex is evident in all three cross-sections.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![300](assets/emai_0402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-2\. A fully connected or dense artificial neural network with four
    layers.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Even though different regions of the cortex are responsible for different functions,
    such as vision, auditory perception, logical thinking, language, speech, *etc.*,
    what actually determines the function of a specific region are its *connections*:
    Which sensory and motor skills input and output regions it connects to. This means
    that if a cortical region is connected to a different sensory input/output region,
    for example, a vision instead of an auditory locality, then it will perform vision
    tasks (computations), not auditory tasks. In a very simplified sense, the cortex
    performs one basic function at the neuron level. In an artificial neural network,
    the basic computation unit is *the perceptron*, and it functions in the same way
    across the whole network. The various connections, layers, and architechture of
    the neural network (both the brain cortex and artificial neural networks) are
    what allows these computational structures to do very impressive things.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Training Function: Fully Connected, Or Dense, Feed Forward Neural Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a *fully connected* or *dense* artificial neural network (see [Figure 4-2](#Fig_neural_network)),
    every neuron, represented by a node (the circles) in every layer is connected
    to all the neurons in the next layer. The first layer is the input layer, the
    last layer is the output layer, and the intermediate layers are called *hidden
    layers*. The neural network itself, whether fully connected or not (the networks
    that we will encounter in the new few chapters are *convolutional* and are not
    fully connected), is a computational graph representing the formula of the training
    function. Recall that it is this function that we use to make predictions after
    training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Training in the neural networks context means finding the parameter values,
    or weights, that enter into the formula of the training function, via minimizing
    a loss function. This is similar to training linear regression, logistic regression,
    softmax regression and support vector machine models that we discussed in [Chapter 3](ch03.xhtml#ch03).
    The mathematical structure here remains the same:'
  prefs: []
  type: TYPE_NORMAL
- en: Training function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Loss function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The only difference is that for the simple models of [Chapter 3](ch03.xhtml#ch03),
    the formulas of the training functions are very uncomplicated. They linearly combine
    the data features, add a bias term ( <math alttext="omega 0"><msub><mi>ω</mi>
    <mn>0</mn></msub></math> ), and pass the result into at most one nonlinear function
    (for example, the logistic function in logistic regression). As a consequence,
    the results of these models are also simple: a linear (flat) function for linear
    regression, a linear division boundary between different classes in logistic regression,
    softmax regression and support vector machines. Even when we use these simple
    models to represent nonlinear data, such as in the cases of polynomial regression
    (fitting the data into polynomial functions of the features) or support vector
    machines with the kernel trick, we still end up with linear functions or division
    boundaries, but in higher dimensions (for polynomial regression, the dimensions
    will be the feature and its powers) or in transformed dimensions (such as when
    we use the kernel trick with support vector machines).'
  prefs: []
  type: TYPE_NORMAL
- en: 'For neural network models, on the other hand, the process of linearly combining
    the features, adding a bias term, then passing the result through a nonlinear
    function (now called *activation function*), is the computation that happens *only
    in one neuron*. This simple process happens over and over again in dozens, hundreds,
    thousands, or sometimes millions of neurons, arranged in layers, where the output
    of one layer acts as the input of the next layer. Similar to the brain cortex,
    the aggregation of simple and similar processes over many neurons and layers produces,
    or allows for the representation, of much more complex functionalities. This is
    sort of miraculous. Thankfully, we are able to understand much more about artificial
    neural networks than our brain’s neural networks, mainly because we design them,
    and after all, an artificial neural network is just one mathematical function.
    No *black box* remains dark once we dissect it under the lens of mathematics.
    That said, the mathematical analysis of artificial neural networks is a relatively
    new field: There are still many questions to be answered and a lot to be discovered.'
  prefs: []
  type: TYPE_NORMAL
- en: A Neural Network Is A Computational Graph Representation Of The Training Function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Even for a network with only five neurons, such as the one in [Figure 4-3](#Fig_five_neurons),
    it is pretty messy to write the formula of the training function. This justifies
    the use of computational graphs to represent neural networks in an organized and
    easy way. Graphs are characterized by two things: nodes and edges (congratulations,
    this was *lesson one in graph theory*). In a neural network, an edge connecting
    node i in layer m to node j in layer n is assigned a weight <math alttext="omega
    Subscript m n comma i j"><msub><mi>ω</mi> <mrow><mi>m</mi><mi>n</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub></math>
    . That is four indices for only one edge! At the risk of drowning in a deep ocean
    of indices, we must organize a neural network’s weights in matrices.'
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_0403.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-3\. A fully connected (or dense) feed forward neural network with only
    five neurons arranged in three layers. The first layer (the three black dots on
    the very left) is the input layer, the second layer is the only hidden layer with
    three neurons, and the last layer is the output layer with two neurons.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let’s model the training function of a *feed forward* fully connected neural
    network. Feed forward means that the information flows forward through the computational
    graph representing the network’s training function.
  prefs: []
  type: TYPE_NORMAL
- en: Linearly Combine, Add Bias, Then Activate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'What kind computations happen as the information flows through one neuron:
    Linearly combine the input information using different weights, add a bias term,
    then use a nonlinear function to *activate* the neuron. We will go through this
    process one step at a time.'
  prefs: []
  type: TYPE_NORMAL
- en: The weights
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let the matrix <math alttext="upper W Superscript 1"><msup><mi>W</mi> <mn>1</mn></msup></math>
    contain the weights of the edges *incident to* hidden layer 1, <math alttext="upper
    W squared"><msup><mi>W</mi> <mn>2</mn></msup></math> contain the weights of the
    edges incident to hidden layer 2, and so on, until we reach the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'So for the small neural network represented in [Figure 4-3](#Fig_five_neurons),
    we only have *h=1* hidden layer, obtaining two matrices of weights:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper W Superscript 1 Baseline equals Start 3 By
    3 Matrix 1st Row 1st Column omega 11 Superscript 1 Baseline 2nd Column omega 12
    Superscript 1 Baseline 3rd Column omega 13 Superscript 1 Baseline 2nd Row 1st
    Column omega 21 Superscript 1 Baseline 2nd Column omega 22 Superscript 1 Baseline
    3rd Column omega 23 Superscript 1 Baseline 3rd Row 1st Column omega 31 Superscript
    1 Baseline 2nd Column omega 32 Superscript 1 Baseline 3rd Column omega 33 Superscript
    1 Baseline EndMatrix and upper W Superscript h plus 1 Baseline equals upper W
    squared equals upper W Superscript o u t p u t Baseline equals Start 2 By 3 Matrix
    1st Row 1st Column omega 11 squared 2nd Column omega 12 squared 3rd Column omega
    13 squared 2nd Row 1st Column omega 21 squared 2nd Column omega 22 squared 3rd
    Column omega 23 squared EndMatrix comma dollar-sign"><mrow><msup><mi>W</mi> <mn>1</mn></msup>
    <mo>=</mo> <mfenced close=")" open="("><mtable><mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow>
    <mn>1</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi> <mrow><mn>12</mn></mrow> <mn>1</mn></msubsup></mtd>
    <mtd><msubsup><mi>ω</mi> <mrow><mn>13</mn></mrow> <mn>1</mn></msubsup></mtd></mtr>
    <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow> <mn>1</mn></msubsup></mtd>
    <mtd><msubsup><mi>ω</mi> <mrow><mn>22</mn></mrow> <mn>1</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi>
    <mrow><mn>23</mn></mrow> <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>ω</mi>
    <mrow><mn>31</mn></mrow> <mn>1</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi> <mrow><mn>32</mn></mrow>
    <mn>1</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi> <mrow><mn>33</mn></mrow> <mn>1</mn></msubsup></mtd></mtr></mtable></mfenced>
    <mtext>and</mtext> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <mo>=</mo> <msup><mi>W</mi> <mn>2</mn></msup> <mo>=</mo> <msup><mi>W</mi> <mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow></msup>
    <mo>=</mo> <mfenced close=")" open="("><mtable><mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow>
    <mn>2</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi> <mrow><mn>12</mn></mrow> <mn>2</mn></msubsup></mtd>
    <mtd><msubsup><mi>ω</mi> <mrow><mn>13</mn></mrow> <mn>2</mn></msubsup></mtd></mtr>
    <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow> <mn>2</mn></msubsup></mtd>
    <mtd><msubsup><mi>ω</mi> <mrow><mn>22</mn></mrow> <mn>2</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi>
    <mrow><mn>23</mn></mrow> <mn>2</mn></msubsup></mtd></mtr></mtable></mfenced> <mo>,</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'where the superscripts indicate the layer which the edges point to. Note that
    if we only had one node at the output layer instead of two, then the last matrix
    of weights <math alttext="upper W Superscript h plus 1 Baseline equals upper W
    Superscript o u t p u t"><mrow><msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <mo>=</mo> <msup><mi>W</mi> <mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow></msup></mrow></math>
    will only be a row vector:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper W Superscript h plus 1 Baseline equals upper
    W squared equals upper W Superscript o u t p u t Baseline equals Start 1 By 3
    Matrix 1st Row 1st Column omega 11 squared 2nd Column omega 12 squared 3rd Column
    omega 13 squared EndMatrix dollar-sign"><mrow><msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <mo>=</mo> <msup><mi>W</mi> <mn>2</mn></msup> <mo>=</mo> <msup><mi>W</mi> <mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow></msup>
    <mo>=</mo> <mfenced close=")" open="("><mtable><mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow>
    <mn>2</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi> <mrow><mn>12</mn></mrow> <mn>2</mn></msubsup></mtd>
    <mtd><msubsup><mi>ω</mi> <mrow><mn>13</mn></mrow> <mn>2</mn></msubsup></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Now at one node of this neural network two computations take place:'
  prefs: []
  type: TYPE_NORMAL
- en: A linear combination plus bias.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Passing the result through a nonlinear activation function (the composition
    operation from calculus).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We elaborate on these two then ultimately construct the training function of
    the fully connected feed forward neural network represented in [Figure 4-3](#Fig_five_neurons).
  prefs: []
  type: TYPE_NORMAL
- en: A linear combination plus bias
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At the first node in the first hidden layer (the only hidden layer for this
    small network), we linearly combine the inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign z 1 Superscript 1 Baseline equals omega 11 Superscript
    1 Baseline x 1 plus omega 12 Superscript 1 Baseline x 2 plus omega 13 Superscript
    1 Baseline x 3 plus omega 01 Superscript 1 dollar-sign"><mrow><msubsup><mi>z</mi>
    <mn>1</mn> <mn>1</mn></msubsup> <mo>=</mo> <msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow>
    <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi>
    <mrow><mn>12</mn></mrow> <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>13</mn></mrow> <mn>1</mn></msubsup> <msub><mi>x</mi>
    <mn>3</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>01</mn></mrow> <mn>1</mn></msubsup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'At the second node in the first hidden layer, we linearly combine the inputs
    using different weights than the previous linear combination:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign z 2 Superscript 1 Baseline equals omega 21 Superscript
    1 Baseline x 1 plus omega 22 Superscript 1 Baseline x 2 plus omega 23 Superscript
    1 Baseline x 3 plus omega 02 Superscript 1 dollar-sign"><mrow><msubsup><mi>z</mi>
    <mn>2</mn> <mn>1</mn></msubsup> <mo>=</mo> <msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow>
    <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi>
    <mrow><mn>22</mn></mrow> <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>23</mn></mrow> <mn>1</mn></msubsup> <msub><mi>x</mi>
    <mn>3</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>02</mn></mrow> <mn>1</mn></msubsup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'At the third node in the first hidden layer, we inearly combine the inputs
    using different weights than the previous two linear combinations:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign z 3 Superscript 1 Baseline equals omega 31 Superscript
    1 Baseline x 1 plus omega 32 Superscript 1 Baseline x 2 plus omega 33 Superscript
    1 Baseline x 3 plus omega 03 Superscript 1 dollar-sign"><mrow><msubsup><mi>z</mi>
    <mn>3</mn> <mn>1</mn></msubsup> <mo>=</mo> <msubsup><mi>ω</mi> <mrow><mn>31</mn></mrow>
    <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi>
    <mrow><mn>32</mn></mrow> <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>33</mn></mrow> <mn>1</mn></msubsup> <msub><mi>x</mi>
    <mn>3</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>03</mn></mrow> <mn>1</mn></msubsup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s express the three equations above using vector and matrix notation. This
    will be extremely convenient for our optimization task later, and of course it
    will preserve our sanity:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign Start 3 By 1 Matrix 1st Row  z 1 Superscript 1 Baseline
    2nd Row  z 2 Superscript 1 Baseline 3rd Row  z 3 Superscript 1 Baseline EndMatrix
    equals Start 3 By 1 Matrix 1st Row  omega 11 Superscript 1 Baseline 2nd Row  omega
    21 Superscript 1 Baseline 3rd Row  omega 31 Superscript 1 Baseline EndMatrix x
    1 plus Start 3 By 1 Matrix 1st Row  omega 12 Superscript 1 Baseline 2nd Row  omega
    22 Superscript 1 Baseline 3rd Row  omega 32 Superscript 1 Baseline EndMatrix x
    2 plus Start 3 By 1 Matrix 1st Row  omega 13 Superscript 1 Baseline 2nd Row  omega
    23 Superscript 1 Baseline 3rd Row  omega 33 Superscript 1 Baseline EndMatrix x
    3 plus Start 3 By 1 Matrix 1st Row  omega 01 Superscript 1 Baseline 2nd Row  omega
    02 Superscript 1 Baseline 3rd Row  omega 03 Superscript 1 Baseline EndMatrix equals
    Start 3 By 3 Matrix 1st Row 1st Column omega 11 Superscript 1 Baseline 2nd Column
    omega 12 Superscript 1 Baseline 3rd Column omega 13 Superscript 1 Baseline 2nd
    Row 1st Column omega 21 Superscript 1 Baseline 2nd Column omega 22 Superscript
    1 Baseline 3rd Column omega 23 Superscript 1 Baseline 3rd Row 1st Column omega
    31 Superscript 1 Baseline 2nd Column omega 32 Superscript 1 Baseline 3rd Column
    omega 33 Superscript 1 Baseline EndMatrix Start 3 By 1 Matrix 1st Row  x 1 2nd
    Row  x 2 3rd Row  x 3 EndMatrix plus Start 3 By 1 Matrix 1st Row  omega 01 Superscript
    1 Baseline 2nd Row  omega 02 Superscript 1 Baseline 3rd Row  omega 03 Superscript
    1 Baseline EndMatrix period dollar-sign"><mrow><mfenced close=")" open="("><mtable><mtr><mtd><msubsup><mi>z</mi>
    <mn>1</mn> <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>z</mi> <mn>2</mn>
    <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>z</mi> <mn>3</mn> <mn>1</mn></msubsup></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close=")" open="("><mtable><mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>31</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr></mtable></mfenced> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <mfenced close=")" open="("><mtable><mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>12</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>22</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>32</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr></mtable></mfenced> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mfenced close=")" open="("><mtable><mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>13</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>23</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>33</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr></mtable></mfenced> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>+</mo> <mfenced close=")" open="("><mtable><mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>01</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>02</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>03</mn></mrow>
    <mn>1</mn></msubsup></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close=")"
    open="("><mtable><mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow> <mn>1</mn></msubsup></mtd>
    <mtd><msubsup><mi>ω</mi> <mrow><mn>12</mn></mrow> <mn>1</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi>
    <mrow><mn>13</mn></mrow> <mn>1</mn></msubsup></mtd></mtr> <mtr><mtd><msubsup><mi>ω</mi>
    <mrow><mn>21</mn></mrow> <mn>1</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi> <mrow><mn>22</mn></mrow>
    <mn>1</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi> <mrow><mn>23</mn></mrow> <mn>1</mn></msubsup></mtd></mtr>
    <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>31</mn></mrow> <mn>1</mn></msubsup></mtd>
    <mtd><msubsup><mi>ω</mi> <mrow><mn>32</mn></mrow> <mn>1</mn></msubsup></mtd> <mtd><msubsup><mi>ω</mi>
    <mrow><mn>33</mn></mrow> <mn>1</mn></msubsup></mtd></mtr></mtable></mfenced> <mfenced
    close=")" open="("><mtable><mtr><mtd><msub><mi>x</mi> <mn>1</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi>
    <mn>3</mn></msub></mtd></mtr></mtable></mfenced> <mo>+</mo> <mfenced close=")"
    open="("><mtable><mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>01</mn></mrow> <mn>1</mn></msubsup></mtd></mtr>
    <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>02</mn></mrow> <mn>1</mn></msubsup></mtd></mtr>
    <mtr><mtd><msubsup><mi>ω</mi> <mrow><mn>03</mn></mrow> <mn>1</mn></msubsup></mtd></mtr></mtable></mfenced>
    <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now summarize the above expression compactly as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ModifyingAbove z With right-arrow Superscript 1 Baseline
    equals upper W Superscript 1 Baseline ModifyingAbove x With right-arrow plus ModifyingAbove
    omega With right-arrow Subscript 0 Superscript 1 dollar-sign"><mrow><msup><mover
    accent="true"><mi>z</mi> <mo>→</mo></mover> <mn>1</mn></msup> <mo>=</mo> <msup><mi>W</mi>
    <mn>1</mn></msup> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>+</mo>
    <msubsup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn> <mn>1</mn></msubsup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Pass the result through a nonlinear activation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Linearly combining the features and adding bias are not enough to pick up on
    more complex information in the data, and neural networks would have never been
    successful without this crucial but very simple step: Compose with a *nonlinear*
    function at each node of the hidden layers.'
  prefs: []
  type: TYPE_NORMAL
- en: Linear combination of a linear combination is still a linear combination
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we skip the step of composing with a nonlinear function, and pass the information
    from the first layer to the next layer using only linear combinations, then our
    network will not learn anything new in the next layer. It will not be able to
    pick up on more complex features from one layer to the next. The math of why this
    is the case is straightforward. Suppose for simplicity that we only have two input
    features, the first hidden layer has only two nodes, and the second one has two
    nodes as well. Then the outputs of the first hidden layer without a nonlinear
    activation function would be:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartLayout 1st Row 1st Column z 1 Superscript 1
    2nd Column equals omega 11 Superscript 1 Baseline x 1 plus omega 12 Superscript
    1 Baseline x 2 plus omega 01 Superscript 1 Baseline 2nd Row 1st Column z 2 Superscript
    1 2nd Column equals omega 21 Superscript 1 Baseline x 1 plus omega 22 Superscript
    1 Baseline x 2 plus omega 02 Superscript 1 EndLayout dollar-sign"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msubsup><mi>z</mi> <mn>1</mn> <mn>1</mn></msubsup></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow>
    <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi>
    <mrow><mn>12</mn></mrow> <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>01</mn></mrow> <mn>1</mn></msubsup></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><msubsup><mi>z</mi> <mn>2</mn> <mn>1</mn></msubsup></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow>
    <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi>
    <mrow><mn>22</mn></mrow> <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>02</mn></mrow> <mn>1</mn></msubsup></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'At the second hidden layer, these will be linearly combined again, so the output
    of the first node of this layer would be:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartLayout 1st Row 1st Column z 1 squared 2nd Column
    equals omega 11 squared z 1 Superscript 1 Baseline plus omega 12 squared z 2 Superscript
    1 Baseline plus omega 01 squared 2nd Row 1st Column Blank 2nd Column equals omega
    11 squared left-parenthesis omega 11 Superscript 1 Baseline x 1 plus omega 12
    Superscript 1 Baseline x 2 plus omega 01 Superscript 1 Baseline right-parenthesis
    plus omega 21 squared left-parenthesis omega 21 Superscript 1 Baseline x 1 plus
    omega 22 Superscript 1 Baseline x 2 plus omega 02 Superscript 1 Baseline right-parenthesis
    plus omega 01 squared 3rd Row 1st Column Blank 2nd Column equals left-parenthesis
    omega 11 squared omega 11 Superscript 1 Baseline plus omega 21 squared omega 21
    Superscript 1 Baseline right-parenthesis x 1 plus left-parenthesis omega 11 squared
    omega 12 Superscript 1 Baseline plus omega 21 squared omega 22 Superscript 1 Baseline
    right-parenthesis x 2 plus left-parenthesis omega 11 squared omega 01 Superscript
    1 Baseline plus omega 21 squared omega 02 Superscript 1 Baseline plus omega 01
    squared right-parenthesis 4th Row 1st Column Blank 2nd Column equals omega 1 x
    1 plus omega 2 x 2 plus omega 3 period EndLayout dollar-sign"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msubsup><mi>z</mi> <mn>1</mn> <mn>2</mn></msubsup></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow>
    <mn>2</mn></msubsup> <msubsup><mi>z</mi> <mn>1</mn> <mn>1</mn></msubsup> <mo>+</mo>
    <msubsup><mi>ω</mi> <mrow><mn>12</mn></mrow> <mn>2</mn></msubsup> <msubsup><mi>z</mi>
    <mn>2</mn> <mn>1</mn></msubsup> <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>01</mn></mrow>
    <mn>2</mn></msubsup></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mo>=</mo>
    <msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow> <mn>2</mn></msubsup> <mrow><mo>(</mo>
    <msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow> <mn>1</mn></msubsup> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>12</mn></mrow> <mn>1</mn></msubsup>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>01</mn></mrow>
    <mn>1</mn></msubsup> <mo>)</mo></mrow> <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow>
    <mn>2</mn></msubsup> <mrow><mo>(</mo> <msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow>
    <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <msubsup><mi>ω</mi>
    <mrow><mn>22</mn></mrow> <mn>1</mn></msubsup> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>02</mn></mrow> <mn>1</mn></msubsup> <mo>)</mo></mrow>
    <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>01</mn></mrow> <mn>2</mn></msubsup></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mrow><mo>=</mo> <mrow><mo>(</mo> <msubsup><mi>ω</mi>
    <mrow><mn>11</mn></mrow> <mn>2</mn></msubsup> <msubsup><mi>ω</mi> <mrow><mn>11</mn></mrow>
    <mn>1</mn></msubsup> <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow> <mn>2</mn></msubsup>
    <msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow> <mn>1</mn></msubsup> <mo>)</mo></mrow>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mrow><mo>(</mo> <msubsup><mi>ω</mi>
    <mrow><mn>11</mn></mrow> <mn>2</mn></msubsup> <msubsup><mi>ω</mi> <mrow><mn>12</mn></mrow>
    <mn>1</mn></msubsup> <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow> <mn>2</mn></msubsup>
    <msubsup><mi>ω</mi> <mrow><mn>22</mn></mrow> <mn>1</mn></msubsup> <mo>)</mo></mrow>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo> <mrow><mo>(</mo> <msubsup><mi>ω</mi>
    <mrow><mn>11</mn></mrow> <mn>2</mn></msubsup> <msubsup><mi>ω</mi> <mrow><mn>01</mn></mrow>
    <mn>1</mn></msubsup> <mo>+</mo> <msubsup><mi>ω</mi> <mrow><mn>21</mn></mrow> <mn>2</mn></msubsup>
    <msubsup><mi>ω</mi> <mrow><mn>02</mn></mrow> <mn>1</mn></msubsup> <mo>+</mo> <msubsup><mi>ω</mi>
    <mrow><mn>01</mn></mrow> <mn>2</mn></msubsup> <mo>)</mo></mrow></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mrow><mo>=</mo> <msub><mi>ω</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>ω</mi> <mn>2</mn></msub>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>ω</mi> <mn>3</mn></msub>
    <mo>.</mo></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: This output is nothing but a simple linear combination of the original features
    plus bias. Hence, adding a layer without any nonlinear activation contributes
    nothing new. In other words, the training function would remain linear and would
    lack the ability to pick up on any nonlinear relationships in the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are the ones who decide on the formula for the nonlinear activation function,
    and different nodes can have different activation functions, even though it is
    rare to do this in practice. Let f be this activation function, then the output
    of the first hidden layer will be:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ModifyingAbove s With right-arrow Superscript 1 Baseline
    equals ModifyingAbove f With right-arrow left-parenthesis ModifyingAbove z With
    right-arrow Superscript 1 Baseline right-parenthesis equals ModifyingAbove f With
    right-arrow left-parenthesis upper W Superscript 1 Baseline ModifyingAbove x With
    right-arrow plus ModifyingAbove omega With right-arrow Subscript 0 Superscript
    1 Baseline right-parenthesis period dollar-sign"><mrow><msup><mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mn>1</mn></msup> <mo>=</mo> <mover accent="true"><mi>f</mi>
    <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mover accent="true"><mi>z</mi> <mo>→</mo></mover>
    <mn>1</mn></msup> <mo>)</mo></mrow> <mo>=</mo> <mover accent="true"><mi>f</mi>
    <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mi>W</mi> <mn>1</mn></msup> <mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>+</mo> <msubsup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mn>0</mn> <mn>1</mn></msubsup> <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'It is now straightforward to see that if we had more hidden layers, their outputs
    will be *chained* with those of previous layers, making writing the training function
    a bit tedious:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartLayout 1st Row 1st Column ModifyingAbove s With
    right-arrow squared 2nd Column ModifyingAbove f With right-arrow left-parenthesis
    ModifyingAbove z With right-arrow squared right-parenthesis equals ModifyingAbove
    f With right-arrow left-parenthesis upper W squared ModifyingAbove s With right-arrow
    Superscript 1 Baseline plus ModifyingAbove omega With right-arrow Subscript 0
    Superscript 2 Baseline right-parenthesis equals ModifyingAbove f With right-arrow
    left-parenthesis upper W squared left-parenthesis ModifyingAbove f With right-arrow
    left-parenthesis upper W Superscript 1 Baseline ModifyingAbove x With right-arrow
    plus ModifyingAbove omega With right-arrow Subscript 0 Superscript 1 Baseline
    right-parenthesis right-parenthesis plus ModifyingAbove omega With right-arrow
    Subscript 0 Superscript 2 Baseline right-parenthesis comma 2nd Row 1st Column
    ModifyingAbove s With right-arrow cubed 2nd Column ModifyingAbove f With right-arrow
    left-parenthesis ModifyingAbove z With right-arrow cubed right-parenthesis equals
    ModifyingAbove f With right-arrow left-parenthesis upper W cubed ModifyingAbove
    s With right-arrow squared plus ModifyingAbove omega With right-arrow Subscript
    0 Superscript 3 Baseline right-parenthesis equals ModifyingAbove f With right-arrow
    left-parenthesis upper W cubed left-parenthesis ModifyingAbove f With right-arrow
    left-parenthesis upper W squared left-parenthesis ModifyingAbove f With right-arrow
    left-parenthesis upper W Superscript 1 Baseline ModifyingAbove x With right-arrow
    plus ModifyingAbove omega With right-arrow Subscript 0 Superscript 1 Baseline
    right-parenthesis right-parenthesis plus ModifyingAbove omega With right-arrow
    Subscript 0 Superscript 2 Baseline right-parenthesis right-parenthesis plus ModifyingAbove
    omega With right-arrow Subscript 0 Superscript 3 Baseline right-parenthesis period
    EndLayout dollar-sign"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msup><mover
    accent="true"><mi>s</mi> <mo>→</mo></mover> <mn>2</mn></msup></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mover accent="true"><mi>f</mi> <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mover
    accent="true"><mi>z</mi> <mo>→</mo></mover> <mn>2</mn></msup> <mo>)</mo></mrow>
    <mo>=</mo> <mover accent="true"><mi>f</mi> <mo>→</mo></mover> <mrow><mo>(</mo>
    <msup><mi>W</mi> <mn>2</mn></msup> <msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover>
    <mn>1</mn></msup> <mo>+</mo> <msubsup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mn>0</mn> <mn>2</mn></msubsup> <mo>)</mo></mrow> <mo>=</mo> <mover accent="true"><mi>f</mi>
    <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mi>W</mi> <mn>2</mn></msup> <mrow><mo>(</mo>
    <mover accent="true"><mi>f</mi> <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mi>W</mi>
    <mn>1</mn></msup> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>+</mo>
    <msubsup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn> <mn>1</mn></msubsup>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>+</mo> <msubsup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mn>0</mn> <mn>2</mn></msubsup> <mo>)</mo></mrow> <mo>,</mo></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover>
    <mn>3</mn></msup></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <mover accent="true"><mi>f</mi>
    <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mover accent="true"><mi>z</mi> <mo>→</mo></mover>
    <mn>3</mn></msup> <mo>)</mo></mrow> <mo>=</mo> <mover accent="true"><mi>f</mi>
    <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mi>W</mi> <mn>3</mn></msup> <msup><mover
    accent="true"><mi>s</mi> <mo>→</mo></mover> <mn>2</mn></msup> <mo>+</mo> <msubsup><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn> <mn>3</mn></msubsup> <mo>)</mo></mrow>
    <mo>=</mo> <mover accent="true"><mi>f</mi> <mo>→</mo></mover> <mrow><mo>(</mo>
    <msup><mi>W</mi> <mn>3</mn></msup> <mrow><mo>(</mo> <mover accent="true"><mi>f</mi>
    <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mi>W</mi> <mn>2</mn></msup> <mrow><mo>(</mo>
    <mover accent="true"><mi>f</mi> <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mi>W</mi>
    <mn>1</mn></msup> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>+</mo>
    <msubsup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn> <mn>1</mn></msubsup>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>+</mo> <msubsup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mn>0</mn> <mn>2</mn></msubsup> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>+</mo> <msubsup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn>
    <mn>3</mn></msubsup> <mo>)</mo></mrow> <mo>.</mo></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: This chaining goes on, until we reach the output layer. What happens at this
    very last layer depends on the task of the network. If the goal is regression
    (predict one numerical value) or binary classification (classify into two classes)
    then we only have one output node (see [Figure 4-4](#Fig_network_regression)).
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_0404.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-4\. A fully connected (or dense) feed forward neural network with only
    nine neurons arranged in four layers. The first layer on the very left is the
    input layer, the second and third layers are the two hidden layers with four neurons
    each, and the last layer is the output layer with only one neuron (this network
    performs either a regression task or a binary classification task).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If the task is regression, we linearly combine the outputs of the previous
    layer at the final output node, add bias, and go home (we *do not* pass the result
    through a nonlinear function in this case). Since the output layer only has one
    node, the output matrix is just a row vector <math alttext="upper W Superscript
    o u t p u t Baseline equals upper W Superscript h plus 1"><mrow><msup><mi>W</mi>
    <mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow></msup>
    <mo>=</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></math>
    , and one bias <math alttext="omega 0 Superscript h plus 1"><msubsup><mi>ω</mi>
    <mn>0</mn> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup></math> . The
    prediction of the network will now be:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign y Subscript p r e d i c t Baseline equals upper W
    Superscript h plus 1 Baseline ModifyingAbove s With right-arrow Superscript h
    Baseline plus omega 0 Superscript h plus 1 Baseline comma dollar-sign"><mrow><msub><mi>y</mi>
    <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>=</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mi>h</mi></msup> <mo>+</mo>
    <msubsup><mi>ω</mi> <mn>0</mn> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup>
    <mo>,</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where h is the total number of hidden layers in the network (this does not include
    the input and output layers).
  prefs: []
  type: TYPE_NORMAL
- en: 'If on the other hand the task is binary classification, then again we have
    only one output node, where we linearly combine the outputs of the previous layer,
    add bias, then pass the result through the logistic function <math alttext="sigma
    left-parenthesis s right-parenthesis equals StartFraction 1 Over 1 plus e Superscript
    negative s Baseline EndFraction"><mrow><mi>σ</mi> <mrow><mo>(</mo> <mi>s</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>s</mi></mrow></msup></mrow></mfrac></mrow></math> , resulting
    in the network’s prediction:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign y Subscript p r e d i c t Baseline equals sigma left-parenthesis
    upper W Superscript h plus 1 Baseline ModifyingAbove s With right-arrow Superscript
    h Baseline plus omega 0 Superscript h plus 1 Baseline right-parenthesis dollar-sign"><mrow><msub><mi>y</mi>
    <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mi>h</mi></msup> <mo>+</mo>
    <msubsup><mi>ω</mi> <mn>0</mn> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If the task is to classify into multiple classes, say five classes, then the
    output layer would include five nodes. At each of these nodes, we linearly combine
    the outputs of the previous layer, add bias, then pass the result through the
    softmax function:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartLayout 1st Row 1st Column sigma left-parenthesis
    z Superscript 1 Baseline right-parenthesis 2nd Column equals StartFraction e Superscript
    z Super Superscript 1 Superscript Baseline Over e Superscript z Super Superscript
    1 Superscript Baseline plus e Superscript z squared Baseline plus e Superscript
    z cubed Baseline plus e Superscript z Super Superscript 4 Superscript Baseline
    plus e Superscript z Super Superscript 5 Superscript Baseline EndFraction comma
    2nd Row 1st Column sigma left-parenthesis z squared right-parenthesis 2nd Column
    equals StartFraction e Superscript z squared Baseline Over e Superscript z Super
    Superscript 1 Superscript Baseline plus e Superscript z squared Baseline plus
    e Superscript z cubed Baseline plus e Superscript z Super Superscript 4 Superscript
    Baseline plus e Superscript z Super Superscript 5 Superscript Baseline EndFraction
    comma 3rd Row 1st Column sigma left-parenthesis z cubed right-parenthesis 2nd
    Column equals StartFraction e Superscript z cubed Baseline Over e Superscript
    z Super Superscript 1 Superscript Baseline plus e Superscript z squared Baseline
    plus e Superscript z cubed Baseline plus e Superscript z Super Superscript 4 Superscript
    Baseline plus e Superscript z Super Superscript 5 Superscript Baseline EndFraction
    comma 4th Row 1st Column sigma left-parenthesis z Superscript 4 Baseline right-parenthesis
    2nd Column equals StartFraction e Superscript z Super Superscript 4 Superscript
    Baseline Over e Superscript z Super Superscript 1 Superscript Baseline plus e
    Superscript z squared Baseline plus e Superscript z cubed Baseline plus e Superscript
    z Super Superscript 4 Superscript Baseline plus e Superscript z Super Superscript
    5 Superscript Baseline EndFraction comma 5th Row 1st Column sigma left-parenthesis
    z Superscript 5 Baseline right-parenthesis 2nd Column equals StartFraction e Superscript
    z Super Superscript 5 Superscript Baseline Over e Superscript z Super Superscript
    1 Superscript Baseline plus e Superscript z squared Baseline plus e Superscript
    z cubed Baseline plus e Superscript z Super Superscript 4 Superscript Baseline
    plus e Superscript z Super Superscript 5 Superscript Baseline EndFraction period
    EndLayout dollar-sign"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>σ</mi>
    <mo>(</mo> <msup><mi>z</mi> <mn>1</mn></msup> <mo>)</mo></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mfrac><msup><mi>e</mi> <msup><mi>z</mi> <mn>1</mn></msup></msup> <mrow><msup><mi>e</mi>
    <msup><mi>z</mi> <mn>1</mn></msup></msup> <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi>
    <mn>2</mn></msup></msup> <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi> <mn>3</mn></msup></msup>
    <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi> <mn>4</mn></msup></msup> <mo>+</mo><msup><mi>e</mi>
    <msup><mi>z</mi> <mn>5</mn></msup></msup></mrow></mfrac> <mo>,</mo></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mi>σ</mi> <mo>(</mo> <msup><mi>z</mi> <mn>2</mn></msup>
    <mo>)</mo></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <mfrac><msup><mi>e</mi>
    <msup><mi>z</mi> <mn>2</mn></msup></msup> <mrow><msup><mi>e</mi> <msup><mi>z</mi>
    <mn>1</mn></msup></msup> <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi> <mn>2</mn></msup></msup>
    <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi> <mn>3</mn></msup></msup> <mo>+</mo><msup><mi>e</mi>
    <msup><mi>z</mi> <mn>4</mn></msup></msup> <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi>
    <mn>5</mn></msup></msup></mrow></mfrac> <mo>,</mo></mrow></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><mi>σ</mi> <mo>(</mo> <msup><mi>z</mi> <mn>3</mn></msup>
    <mo>)</mo></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <mfrac><msup><mi>e</mi>
    <msup><mi>z</mi> <mn>3</mn></msup></msup> <mrow><msup><mi>e</mi> <msup><mi>z</mi>
    <mn>1</mn></msup></msup> <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi> <mn>2</mn></msup></msup>
    <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi> <mn>3</mn></msup></msup> <mo>+</mo><msup><mi>e</mi>
    <msup><mi>z</mi> <mn>4</mn></msup></msup> <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi>
    <mn>5</mn></msup></msup></mrow></mfrac> <mo>,</mo></mrow></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><mi>σ</mi> <mo>(</mo> <msup><mi>z</mi> <mn>4</mn></msup>
    <mo>)</mo></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <mfrac><msup><mi>e</mi>
    <msup><mi>z</mi> <mn>4</mn></msup></msup> <mrow><msup><mi>e</mi> <msup><mi>z</mi>
    <mn>1</mn></msup></msup> <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi> <mn>2</mn></msup></msup>
    <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi> <mn>3</mn></msup></msup> <mo>+</mo><msup><mi>e</mi>
    <msup><mi>z</mi> <mn>4</mn></msup></msup> <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi>
    <mn>5</mn></msup></msup></mrow></mfrac> <mo>,</mo></mrow></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><mi>σ</mi> <mo>(</mo> <msup><mi>z</mi> <mn>5</mn></msup>
    <mo>)</mo></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <mfrac><msup><mi>e</mi>
    <msup><mi>z</mi> <mn>5</mn></msup></msup> <mrow><msup><mi>e</mi> <msup><mi>z</mi>
    <mn>1</mn></msup></msup> <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi> <mn>2</mn></msup></msup>
    <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi> <mn>3</mn></msup></msup> <mo>+</mo><msup><mi>e</mi>
    <msup><mi>z</mi> <mn>4</mn></msup></msup> <mo>+</mo><msup><mi>e</mi> <msup><mi>z</mi>
    <mn>5</mn></msup></msup></mrow></mfrac> <mo>.</mo></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Group the above into a vector function <math alttext="ModifyingAbove sigma
    With right-arrow"><mover accent="true"><mi>σ</mi> <mo>→</mo></mover></math> that
    also takes vectors as input: <math alttext="ModifyingAbove sigma With right-arrow
    left-parenthesis ModifyingAbove z With right-arrow right-parenthesis"><mrow><mover
    accent="true"><mi>σ</mi> <mo>→</mo></mover> <mrow><mo>(</mo> <mover accent="true"><mi>z</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> , then the final prediction
    of the neural network is a vector of five probability scores that a data instance
    belongs to each of the five classes:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartLayout 1st Row 1st Column ModifyingAbove y With
    right-arrow Subscript p r e d i c t 2nd Column equals ModifyingAbove sigma With
    right-arrow left-parenthesis ModifyingAbove z With right-arrow right-parenthesis
    2nd Row 1st Column Blank 2nd Column equals ModifyingAbove sigma With right-arrow
    left-parenthesis upper W Superscript o u t p u t Baseline ModifyingAbove s With
    right-arrow Superscript h Baseline plus ModifyingAbove omega 0 With right-arrow
    Superscript h plus 1 Baseline right-parenthesis EndLayout dollar-sign"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mover accent="true"><mi>y</mi>
    <mo>→</mo></mover> <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi></mrow></msub></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mover accent="true"><mi>σ</mi> <mo>→</mo></mover>
    <mrow><mo>(</mo> <mover accent="true"><mi>z</mi> <mo>→</mo></mover> <mo>)</mo></mrow></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mrow><mo>=</mo> <mover accent="true"><mi>σ</mi>
    <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mi>W</mi> <mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow></msup>
    <msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mi>h</mi></msup> <mo>+</mo>
    <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover>
    <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: Notation overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will try to remain consistent with notation throughout our discussion of
    neural networks: The x’s are the input features, the W’s are the matrices or column
    vectors containing the weights that we use for linear combinations, the <math
    alttext="omega 0"><msub><mi>ω</mi> <mn>0</mn></msub></math> ’s are the biases
    which are sometimes grouped into a vector, the z’s are the results of linear combinations
    plus biases, and the *s*’s are the results of passing those into the nonlinear
    activation functions.'
  prefs: []
  type: TYPE_NORMAL
- en: Common Activation Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In theory, we can use any nonlinear function to *activate our nodes* (think
    of all calculus functions we’ve ever encountered). In practice, there are some
    popular ones, listed below and graphed in [Figure 4-5](#Fig_activation_functions).
  prefs: []
  type: TYPE_NORMAL
- en: '![275](assets/emai_0405.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-5\. Various activation functions for neural networks. The first row
    consists of sigmoidal-type activation functions, shaped like the letter S. These
    saturate (become flat and output the same values) for inputs large in magnitude.
    The second row consists of ReLU- type activation functions, which do not saturate.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: By far the Rectified Linear Unit function (abbreviated ReLU) is the most commonly
    used in nowaday’s networks, and [AlexNet](https://en.wikipedia.org/wiki/AlexNet)’s
    success in 2012 is partially attributed to the use of this activation function,
    as opposed to the hyperbolic tangent and logistic functions (sigmoid) that were
    commonly used in neural networks at the time (and are still in use). The first
    four functions in the list below and in [Figure 4-5](#Fig_activation_functions)
    are all inspired from computational neuroscience, where they attempt to model
    a threshold for the activation (firing) of one neuron cell. Their graphs look
    similar to each other, some are smoother variants of others, some output only
    positive numbers, others output more balanced numbers between -1 and 1, or between
    <math alttext="minus StartFraction pi Over 2 EndFraction"><mrow><mo>-</mo> <mfrac><mi>π</mi>
    <mn>2</mn></mfrac></mrow></math> and <math alttext="StartFraction pi Over 2 EndFraction"><mfrac><mi>π</mi>
    <mn>2</mn></mfrac></math> . They all *saturate* for small or large inputs, meaning
    their graphs become flat for inputs large in mangnitude. This creates a problem
    for *learning*, since if these functions output the same numbers over and over
    again, there will not be much learning happening. Mathematically, this manifests
    itself as what is known as *the vanishing gradient problem*. The second set of
    activation functions attempts to rectify this saturation problem, which it does,
    as we see in the graphs of the second row in [Figure 4-5](#Fig_activation_functions).
    This however, introduces another problem, called *the exploding gradient problem*,
    since these activation functions are unbounded and can now output big numbers,
    and if these numbers grow over multiple layers, we have a problem. Every new set
    of problems that gets introduced comes with its own set of techniques attempting
    to fix it, such as *gradient clipping*, normalizing the outputs after each layer,
    *etc.*. The take home lesson is that none of this is magic. A lot of it is trial
    and error, and new methods emerge in order to fix problems that other new methods
    introduced. We only need to understand the principles, the why and the how, get
    a descent exposure to what is popular in the field, while keeping an open mind
    for improving things, or doing things entirely differently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s state the formulas of common activation functions, as well as their derivatives.
    We need to calculate one derivative of the training function when we optimize
    the loss function, in our search for the best weights of the neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step function: <math alttext="f left-parenthesis z right-parenthesis equals
    StartLayout Enlarged left-brace 1st Row 1st Column Blank 2nd Column 0 if z less-than
    0 2nd Row 1st Column Blank 2nd Column 1 if z greater-than-or-equal-to 0 EndLayout"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="" open="{"
    separators=""><mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mn>0</mn>
    <mtext>if</mtext> <mi>z</mi> <mo><</mo> <mn>0</mn></mrow></mtd></mtr> <mtr><mtd
    columnalign="left"><mrow><mn>1</mn> <mtext>if</mtext> <mi>z</mi> <mo>≥</mo> <mn>0</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Its derivative: <math alttext="f prime left-parenthesis z right-parenthesis
    equals StartLayout Enlarged left-brace 1st Row 1st Column Blank 2nd Column 0 if
    z not-equals 0 2nd Row 1st Column Blank 2nd Column u n d e f i n e d if z equals
    0 EndLayout"><mrow><msup><mi>f</mi> <mo>''</mo></msup> <mrow><mo>(</mo> <mi>z</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mfenced close="" open="{" separators=""><mtable
    displaystyle="true"><mtr><mtd columnalign="left"><mrow><mn>0</mn> <mtext>if</mtext>
    <mi>z</mi> <mo>≠</mo> <mn>0</mn></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mi>u</mi>
    <mi>n</mi> <mi>d</mi> <mi>e</mi> <mi>f</mi> <mi>i</mi> <mi>n</mi> <mi>e</mi> <mi>d</mi>
    <mtext>if</mtext> <mi>z</mi> <mo>=</mo> <mn>0</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Logistic function: <math alttext="sigma left-parenthesis z right-parenthesis
    equals StartFraction 1 Over 1 plus e Superscript negative z Baseline EndFraction"><mrow><mi>σ</mi>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow></math> .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Its derivative: <math alttext="sigma prime left-parenthesis z right-parenthesis
    equals StartFraction e Superscript negative z Baseline Over left-parenthesis 1
    plus e Superscript negative z Baseline right-parenthesis squared EndFraction equals
    sigma left-parenthesis z right-parenthesis left-parenthesis 1 minus sigma left-parenthesis
    z right-parenthesis right-parenthesis"><mrow><msup><mi>σ</mi> <mo>''</mo></msup>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup> <msup><mrow><mo>(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup> <mo>)</mo></mrow> <mn>2</mn></msup></mfrac>
    <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow></mrow></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hyperbolic tangent function: <math alttext="hyperbolic tangent left-parenthesis
    z right-parenthesis equals StartFraction e Superscript z Baseline minus e Superscript
    negative z Baseline Over e Superscript z Baseline plus e Superscript negative
    z Baseline EndFraction equals StartFraction 2 Over 1 plus e Superscript minus
    2 z Baseline EndFraction minus 1"><mrow><mo form="prefix">tanh</mo> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><msup><mi>e</mi> <mi>z</mi></msup>
    <mo>-</mo><msup><mi>e</mi> <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow> <mrow><msup><mi>e</mi>
    <mi>z</mi></msup> <mo>+</mo><msup><mi>e</mi> <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>2</mn> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi> <mrow><mo>-</mo><mn>2</mn><mi>z</mi></mrow></msup></mrow></mfrac>
    <mo>-</mo> <mn>1</mn></mrow></math>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Its derivative: <math alttext="hyperbolic tangent prime left-parenthesis z
    right-parenthesis equals StartFraction 4 Over left-parenthesis e Superscript z
    Baseline plus e Superscript negative z Baseline right-parenthesis squared EndFraction
    equals 1 minus f left-parenthesis z right-parenthesis squared"><mrow><msup><mo
    form="prefix">tanh</mo> <mo>''</mo></msup> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mn>4</mn> <msup><mrow><mo>(</mo><msup><mi>e</mi> <mi>z</mi></msup>
    <mo>+</mo><msup><mi>e</mi> <mrow><mo>-</mo><mi>z</mi></mrow></msup> <mo>)</mo></mrow>
    <mn>2</mn></msup></mfrac> <mo>=</mo> <mn>1</mn> <mo>-</mo> <mi>f</mi> <msup><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></math>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Inverse tangent function: <math alttext="f left-parenthesis z right-parenthesis
    equals arc tangent left-parenthesis z right-parenthesis"><mrow><mi>f</mi> <mo>(</mo>
    <mi>z</mi> <mo>)</mo> <mo>=</mo> <mo form="prefix">arctan</mo> <mo>(</mo> <mi>z</mi>
    <mo>)</mo></mrow></math> .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Its derivative: <math alttext="f prime left-parenthesis z right-parenthesis
    equals StartFraction 1 Over 1 plus z squared EndFraction"><mrow><msup><mi>f</mi>
    <mo>''</mo></msup> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mn>1</mn>
    <mrow><mn>1</mn><mo>+</mo><msup><mi>z</mi> <mn>2</mn></msup></mrow></mfrac></mrow></math>
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rectified Linear Unit function or ReLU(z): <math alttext="f left-parenthesis
    z right-parenthesis equals StartLayout Enlarged left-brace 1st Row 1st Column
    Blank 2nd Column 0 if z less-than 0 2nd Row 1st Column Blank 2nd Column z if z
    greater-than-or-equal-to 0 EndLayout"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>z</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mfenced close="" open="{" separators=""><mtable
    displaystyle="true"><mtr><mtd columnalign="left"><mrow><mn>0</mn> <mtext>if</mtext>
    <mi>z</mi> <mo><</mo> <mn>0</mn></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mi>z</mi>
    <mtext>if</mtext> <mi>z</mi> <mo>≥</mo> <mn>0</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Its derivative: <math alttext="f prime left-parenthesis z right-parenthesis
    equals StartLayout Enlarged left-brace 1st Row 1st Column Blank 2nd Column 0 if
    z less-than 0 2nd Row 1st Column Blank 2nd Column u n d e f i n e d if z equals
    0 3rd Row 1st Column Blank 2nd Column 1 if z greater-than 0 EndLayout"><mrow><msup><mi>f</mi>
    <mo>''</mo></msup> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced
    close="" open="{" separators=""><mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mn>0</mn>
    <mtext>if</mtext> <mi>z</mi> <mo><</mo> <mn>0</mn></mrow></mtd></mtr> <mtr><mtd
    columnalign="left"><mrow><mi>u</mi> <mi>n</mi> <mi>d</mi> <mi>e</mi> <mi>f</mi>
    <mi>i</mi> <mi>n</mi> <mi>e</mi> <mi>d</mi> <mtext>if</mtext> <mi>z</mi> <mo>=</mo>
    <mn>0</mn></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mn>1</mn> <mtext>if</mtext>
    <mi>z</mi> <mo>></mo> <mn>0</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Leaky Rectified Linear Unit function (or parametric linear unit): <math alttext="f
    left-parenthesis z right-parenthesis equals StartLayout Enlarged left-brace 1st
    Row 1st Column Blank 2nd Column alpha z if z less-than 0 2nd Row 1st Column Blank
    2nd Column z if z greater-than-or-equal-to 0 EndLayout"><mrow><mi>f</mi> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="" open="{" separators=""><mtable
    displaystyle="true"><mtr><mtd columnalign="left"><mrow><mi>α</mi> <mi>z</mi> <mtext>if</mtext>
    <mi>z</mi> <mo><</mo> <mn>0</mn></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mi>z</mi>
    <mtext>if</mtext> <mi>z</mi> <mo>≥</mo> <mn>0</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Its derivative: <math alttext="f prime left-parenthesis z right-parenthesis
    equals StartLayout Enlarged left-brace 1st Row 1st Column Blank 2nd Column alpha
    if z less-than 0 2nd Row 1st Column Blank 2nd Column u n d e f i n e d if z equals
    0 3rd Row 1st Column Blank 2nd Column 1 if z greater-than 0 EndLayout"><mrow><msup><mi>f</mi>
    <mo>''</mo></msup> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced
    close="" open="{" separators=""><mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mi>α</mi>
    <mtext>if</mtext> <mi>z</mi> <mo><</mo> <mn>0</mn></mrow></mtd></mtr> <mtr><mtd
    columnalign="left"><mrow><mi>u</mi> <mi>n</mi> <mi>d</mi> <mi>e</mi> <mi>f</mi>
    <mi>i</mi> <mi>n</mi> <mi>e</mi> <mi>d</mi> <mtext>if</mtext> <mi>z</mi> <mo>=</mo>
    <mn>0</mn></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mn>1</mn> <mtext>if</mtext>
    <mi>z</mi> <mo>></mo> <mn>0</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exponential Linear Unit function: <math alttext="f left-parenthesis z right-parenthesis
    equals StartLayout Enlarged left-brace 1st Row 1st Column Blank 2nd Column alpha
    left-parenthesis e Superscript z Baseline minus 1 right-parenthesis if z less-than
    0 2nd Row 1st Column Blank 2nd Column z if z greater-than-or-equal-to 0 EndLayout"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="" open="{"
    separators=""><mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mi>α</mi>
    <mo>(</mo> <msup><mi>e</mi> <mi>z</mi></msup> <mo>-</mo> <mn>1</mn> <mo>)</mo>
    <mtext>if</mtext> <mi>z</mi> <mo><</mo> <mn>0</mn></mrow></mtd></mtr> <mtr><mtd
    columnalign="left"><mrow><mi>z</mi> <mtext>if</mtext> <mi>z</mi> <mo>≥</mo> <mn>0</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Its derivative: <math alttext="f prime left-parenthesis z right-parenthesis
    equals StartLayout Enlarged left-brace 1st Row 1st Column Blank 2nd Column f left-parenthesis
    z right-parenthesis plus alpha if z less-than 0 2nd Row 1st Column Blank 2nd Column
    1 if z greater-than-or-equal-to 0 EndLayout"><mrow><msup><mi>f</mi> <mo>''</mo></msup>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="" open="{"
    separators=""><mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mi>f</mi>
    <mo>(</mo> <mi>z</mi> <mo>)</mo> <mo>+</mo> <mi>α</mi> <mtext>if</mtext> <mi>z</mi>
    <mo><</mo> <mn>0</mn></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mn>1</mn>
    <mtext>if</mtext> <mi>z</mi> <mo>≥</mo> <mn>0</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Softplus function: <math alttext="f left-parenthesis z right-parenthesis equals
    ln left-parenthesis 1 plus e Superscript z Baseline right-parenthesis"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mo form="prefix">ln</mo>
    <mrow><mo>(</mo> <mn>1</mn> <mo>+</mo> <msup><mi>e</mi> <mi>z</mi></msup> <mo>)</mo></mrow></mrow></math>
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Its derivative: <math alttext="f prime left-parenthesis z right-parenthesis
    equals StartFraction 1 Over 1 plus e Superscript negative z Baseline EndFraction
    equals sigma left-parenthesis z right-parenthesis"><mrow><msup><mi>f</mi> <mo>''</mo></msup>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac> <mo>=</mo> <mi>σ</mi>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></math>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that all of these activations are rather elementary functions. This is
    a good thing, since both they and their derivatives are usually involved in massive
    computations with thousands of parameters (weights) and data instances during
    training, testing, and deployment of neural networks, so better keep them elementary.
    The other reason is that in theory, is doesn’t really matter what activation function
    we end up choosing, because of the *universal function approximation theorems*,
    discussed next. Careful here: Operationally, it definitely matters what activation
    function we choose for our neural network nodes. As we mentioned earlier in this
    section, AlexNet’s success in image classification tasks is partly due to its
    use of the Rectified Linear Unit function ReLU(z). Theory and practice do not
    contradict each other in this case, even though it seems so on the surface. We
    explain this in the next subsection.'
  prefs: []
  type: TYPE_NORMAL
- en: Universal Function Approximation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Approximation theorems, when available, are awesome, because they tell us, with
    mathematical confidence and authority, that if we have a function that we do not
    know, or that we know but is difficult to include in our computations, then we
    do not have to deal with this unknown or difficult function altogether. We can,
    instead, approximate it using known functions that are much easier to compute,
    to a great degree of precision. This means that under certain conditions on both
    the unknown or complicated function, and the known and simple (sometimes elemetary)
    functions, we can use the simple functions and be confident that our computations
    are doing the right thing. These types of approximation theorems quantify how
    far off the true function is from its approximation, so we know exactly how much
    error we are committing when substituting the true function with this approximation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fact that neural networks, even sometimes *nondeep* neural networks with
    only one hidden layer, have proved so successful for accomplishing various tasks
    in vision, speech recognition, classification, regression, and others, means that
    they have some universal approximation property going on for them: The training
    function that a neural network represents (built from elementary linear combinations,
    biases, and very simple activation functions) approximates the underlying unknown
    function that truly represents or generates the data rather well.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The natural questions that mathematicians must now answer with a theorem, or
    a bunch of theorems are:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Given some function that we don’t know but we really care for (because we
    think it is the true function underlying or generating our data), is there a neural
    network that can approximate it to a good degree of precision (without ever having
    to know this true function)?* Practice using neural networks successfully suggests
    that the answer is yes, and universal approximation theorems for neural networks
    *prove* that the answer is yes, for a certain class of functions and networks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*If there is a neural network that approximates this true and elusive data
    generating function, how do we construct it? How many layers should it have? How
    many nodes in each layer? What type of activation function should it include?*
    In other words, what is the *architecture* of this network? Sadly, as of now,
    little is known on how to construct these networks, and experimentation with various
    architectures and activations is the only way forward, until more mathematicians
    get on this.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Are there multiple neural network architecture that work well? Are there some
    that are better than others?* Experiments suggest that the answer is yes, given
    the comparable performance of various architectures on the same tasks and data
    sets.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Note that having definite answers for the above questions is very useful. Affirmative
    answer to the first question tells us: Hey, there is no magic here, neural networks
    do approximate a *wide class of functions* rather well! This *wide coverage*,
    or universality, is crucial, because recall that we do not know the underlying
    generating function of the data, but if the approximation theorem covers a wide
    class of functions, our unknown and elusive function might as well be included,
    hence the success of the neural network. Answering the second and third questions
    is even more useful for practical applications, because if we know which architecture
    works best for each task type and data set, then we would be saved from so much
    experimentation, and we’d immediately choose a well performing architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before stating the universal approximation theorems for neural networks and
    discussing their proofs, let’s go over two examples where we had already encountered
    approximation type theorems, even when we were as young as middle school. The
    same principle applies for all examples: We have an unruly quantity that for whatever
    reason is difficult to deal with or is unknown, and we want to approximate it
    using another quantity that is easier to deal with. If we want universal results,
    we need to specify three things:'
  prefs: []
  type: TYPE_NORMAL
- en: What class or what kind of *space* does the unruly quantity or function belong
    to? Is it the set of real numbers <math alttext="double-struck upper R"><mi>ℝ</mi></math>
    ? The set of irrational numbers? The space of continuous functions on an interval?
    The space of compactly supported functions on <math alttext="double-struck upper
    R"><mi>ℝ</mi></math> ? The space of Lebesgue measurable functions (I did slide
    in some *measure theory* stuff in here, hoping that no one notices or runs away)?
    *Etc.*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What kind of easier quantities or functions are we using to approximate the
    unruly entities, and how does using these quantities instead of the true function
    benefit us? How do these approximations fair against *other approximations*, if
    there are already some other popular approximations?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*In what sense* is the approximation happening, meaning that when we say we
    can approximate <math alttext="f Subscript t r u e"><msub><mi>f</mi> <mrow><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub></math>
    using <math alttext="f Subscript a p p r o x i m a t e"><msub><mi>f</mi> <mrow><mi>a</mi><mi>p</mi><mi>p</mi><mi>r</mi><mi>o</mi><mi>x</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub></math>
    , how exactly are we measuring the distance between <math alttext="f Subscript
    t r u e"><msub><mi>f</mi> <mrow><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub></math>
    and <math alttext="f Subscript a p p r o x i m a t e"><msub><mi>f</mi> <mrow><mi>a</mi><mi>p</mi><mi>p</mi><mi>r</mi><mi>o</mi><mi>x</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow></msub></math>
    ? Recall that in math we can measure sizes of objects, including distances, in
    many ways. So exactly which way are we using for our particular approximations?
    This is where we hear about the Euclidean norm, uniform norm, *supremum* norm,
    <math alttext="upper L squared"><msup><mi>L</mi> <mn>2</mn></msup></math> norm,
    *etc.* What do norms (sizes) have to do with distances? A norm induces a distance.
    This is intuitive: If our space allows us to talk about sizes of objects, then
    it better allow us talk about distances as well. We’ll formalize this later in
    the probability chapter.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Example 1: Approximating irrational numbers with rational numbers'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Any irrational number can be approximated by a rational number, up to any precision
    that we desire. Rational numbers are so well behaved and useful, since they are
    just pairs of whole numbers. Our minds can easily intuit about whole numbers and
    fractions. Irrational numbers are quite the opposite. Have you ever been asked,
    in grade 6, to calculate <math alttext="StartRoot 47 EndRoot equals 6.8556546
    period period period"><mrow><msqrt><mn>47</mn></msqrt> <mo>=</mo> <mn>6</mn> <mo>.</mo>
    <mn>8556546</mn> <mo>.</mo> <mo>.</mo> <mo>.</mo></mrow></math> , without a calculator,
    and stay at it until you had a definite answer? I have. Pretty mean! Even calculators
    and computers approximate irrational numbers with rationals. But I had to sit
    there thinking I could keep writing digits until I either found a pattern or the
    computation terminated. Of course neither happened, and around 30 digits later,
    I learned that some numbers are just irrational.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'There is more than one way to write a mathematical statement quantifying this
    approximation. They are all equivalent and useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The approximating entity can be made arbitrarily close to the true quantity*:
    This is the most intuitive way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given an irrational number *s* and any precision <math alttext="epsilon"><mi>ϵ</mi></math>
    , no matter how small, we can find a rational number *q* within a distance <math
    alttext="epsilon"><mi>ϵ</mi></math> from *s*.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartAbsoluteValue s minus q EndAbsoluteValue less-than
    epsilon period dollar-sign"><mrow><mo>|</mo> <mi>s</mi> <mo>-</mo> <mi>q</mi>
    <mo>|</mo> <mo><</mo> <mi>ϵ</mi> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This means that rational and irrational numbers live arbitrarily close to each
    other on the real line <math alttext="double-struck upper R"><mi>ℝ</mi></math>
    . This introduces the idea of denseness.
  prefs: []
  type: TYPE_NORMAL
- en: '*Densness and closure*: Approximating entities are *dense* in the space where
    the true quantities live.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means that if we focus only on the space of approximating members, then
    add in all the limits of all their sequences, we get the whole space of the true
    members. Adding in all the limiting points of a certain space S is called *closing*
    the space, or taking its *closure*, <math alttext="upper S overbar"><mover accent="true"><mi>S</mi>
    <mo>¯</mo></mover></math> . For example, when we add to the open interval <math
    alttext="left-parenthesis a comma b right-parenthesis"><mrow><mo>(</mo> <mi>a</mi>
    <mo>,</mo> <mi>b</mi> <mo>)</mo></mrow></math> its limit points *a* and *b*, we
    get the *closed* interval [a,b]. Thus the *closure* of <math alttext="left-parenthesis
    a comma b right-parenthesis"><mrow><mo>(</mo> <mi>a</mi> <mo>,</mo> <mi>b</mi>
    <mo>)</mo></mrow></math> is [a,b]. We write <math alttext="ModifyingAbove left-parenthesis
    a comma b right-parenthesis With bar equals"><mrow><mover accent="true"><mrow><mo>(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo>)</mo></mrow>
    <mo>¯</mo></mover> <mo>=</mo></mrow></math> [a,b].
  prefs: []
  type: TYPE_NORMAL
- en: The set of rational numbers <math alttext="double-struck upper Q"><mi>ℚ</mi></math>
    is *dense* in the real line <math alttext="double-struck upper R"><mi>ℝ</mi></math>
    . In other words, the *closure* of <math alttext="double-struck upper Q"><mi>ℚ</mi></math>
    is <math alttext="double-struck upper R"><mi>ℝ</mi></math> . We write <math alttext="double-struck
    upper Q overbar equals double-struck upper R"><mrow><mover accent="true"><mi>ℚ</mi>
    <mo>¯</mo></mover> <mo>=</mo> <mi>ℝ</mi></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: '*Limits of sequences*: The true quantity is the limit of a sequence of the
    approximating entities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The idea of *adding in* the *limit points* in the previous bullet introduces
    approximation using the terminology of sequences and their limits.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the context of rational numbers approximating irrational numbers, we can
    therefore write: For any irrational number *s*, there is a sequence <math alttext="q
    Subscript n"><msub><mi>q</mi> <mi>n</mi></msub></math> of rational numbers such
    that <math alttext="limit Underscript n right-arrow normal infinity Endscripts
    q Subscript n Baseline equals s"><mrow><msub><mo form="prefix" movablelimits="true">lim</mo>
    <mrow><mi>n</mi><mo>→</mo><mi>∞</mi></mrow></msub> <msub><mi>q</mi> <mi>n</mi></msub>
    <mo>=</mo> <mi>s</mi></mrow></math> . This gives us the chance to write as an
    example one of the favorite definitions of the most famous irrational number:
    *e=2.71828182…*'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign limit Underscript n right-arrow normal infinity Endscripts
    left-parenthesis 1 plus StartFraction 1 Over n EndFraction right-parenthesis Superscript
    n Baseline equals e dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">lim</mo>
    <mrow><mi>n</mi><mo>→</mo><mi>∞</mi></mrow></msub> <msup><mrow><mo>(</mo><mn>1</mn><mo>+</mo><mfrac><mn>1</mn>
    <mi>n</mi></mfrac><mo>)</mo></mrow> <mi>n</mi></msup> <mo>=</mo> <mi>e</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: That is, the *irrational* number *e* is the limit of the sequence of *rational*
    numbers <math alttext="left-parenthesis 1 plus one-first right-parenthesis Superscript
    1 Baseline comma left-parenthesis 1 plus one-half right-parenthesis squared comma
    left-parenthesis 1 plus one-third right-parenthesis cubed comma ellipsis"><mrow><msup><mrow><mo>(</mo><mn>1</mn><mo>+</mo><mfrac><mn>1</mn>
    <mn>1</mn></mfrac><mo>)</mo></mrow> <mn>1</mn></msup> <mo>,</mo> <msup><mrow><mo>(</mo><mn>1</mn><mo>+</mo><mfrac><mn>1</mn>
    <mn>2</mn></mfrac><mo>)</mo></mrow> <mn>2</mn></msup> <mo>,</mo> <msup><mrow><mo>(</mo><mn>1</mn><mo>+</mo><mfrac><mn>1</mn>
    <mn>3</mn></mfrac><mo>)</mo></mrow> <mn>3</mn></msup> <mo>,</mo> <mo>⋯</mo></mrow></math>
    which is equivalent to <math alttext="2 comma 2.25 comma 2.370370 period period
    comma ellipsis"><mrow><mn>2</mn> <mo>,</mo> <mn>2</mn> <mo>.</mo> <mn>25</mn>
    <mo>,</mo> <mn>2</mn> <mo>.</mo> <mn>370370</mn> <mo>.</mo> <mo>.</mo> <mo>,</mo>
    <mo>⋯</mo></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: 'Whether we approximate an irrational number with a rational number using the
    *arbitrarily close* concept, the *denseness and closure* concepts, or the *limits
    of sequences* concept, any distance involved in the mathematical statements is
    measured using the usual Euclidean norm: <math alttext="d left-parenthesis s comma
    q right-parenthesis equals StartAbsoluteValue s minus q EndAbsoluteValue"><mrow><mi>d</mi>
    <mo>(</mo> <mi>s</mi> <mo>,</mo> <mi>q</mi> <mo>)</mo> <mo>=</mo> <mo>|</mo> <mi>s</mi>
    <mo>-</mo> <mi>q</mi> <mo>|</mo></mrow></math> , which is the normal distance
    between two numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Closeness Statements Need to Be Accompanied By a Specific Norm'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We might wonder: What if we change the norm? Would the approximation property
    still hold? Can we still approximate irrationals using rationals if we measure
    the distance between them using some other definition of distance than the usual
    Eclidean norm? Welcome to *mathematical analysis*. In general, the answer is *no*.
    Quantities can be close to each other using some norm and very far using another
    norm. So in mathematics, when we say that quantities are close to each other,
    approximate others, or converge somewhere, we need to mention the accompanying
    norm, in order to pin point *in what sense these closeness statements are happening*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Example 2: Approximating continuous functions with polynomials'
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuous functions can be anything. A child can draw a wiggly line on a piece
    of paper and that would be a continuous function that no one knows the formula
    of. Polynomials, on the other hand, are a special type of continuous functions
    that are extremely easy to evaluate, differentiate, integrate, explain, and do
    computations with. The only operations involved in polynomial functions are powers,
    scalar multiplication, addition and subtraction. A polynomial of degree *n* has
    a simple formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign p Subscript n Baseline left-parenthesis x right-parenthesis
    equals a 0 plus a 1 x plus a 2 x squared plus a 3 x cubed plus ellipsis plus a
    Subscript n Baseline x Superscript n Baseline comma dollar-sign"><mrow><msub><mi>p</mi>
    <mi>n</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <msub><mi>a</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>a</mi> <mn>1</mn></msub> <mi>x</mi> <mo>+</mo>
    <msub><mi>a</mi> <mn>2</mn></msub> <msup><mi>x</mi> <mn>2</mn></msup> <mo>+</mo>
    <msub><mi>a</mi> <mn>3</mn></msub> <msup><mi>x</mi> <mn>3</mn></msup> <mo>+</mo>
    <mo>⋯</mo> <mo>+</mo> <msub><mi>a</mi> <mi>n</mi></msub> <msup><mi>x</mi> <mi>n</mi></msup>
    <mo>,</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where the <math alttext="a Subscript i"><msub><mi>a</mi> <mi>i</mi></msub></math>
    ’s are scalar numbers. Naturally, it is extremely desirable to be able to approximate
    non-polynomial continuous functions using polynomial functions. The wonderful
    news is that we can, up to any precision <math alttext="epsilon"><mi>ϵ</mi></math>
    . This is a classical result in mathematical analysis, called Weierstrass Approximation
    Theorem.
  prefs: []
  type: TYPE_NORMAL
- en: '**Weierstrass Approximation Theorem**: Suppose *f* is a continuous real-valued
    function defined on a real interval [a,b]. For any precision <math alttext="epsilon
    greater-than 0"><mrow><mi>ϵ</mi> <mo>></mo> <mn>0</mn></mrow></math> , there exists
    a polynomial <math alttext="p Subscript n"><msub><mi>p</mi> <mi>n</mi></msub></math>
    such that for all *x* in [a,b], we have <math alttext="StartAbsoluteValue f left-parenthesis
    x right-parenthesis minus p Subscript n Baseline left-parenthesis x right-parenthesis
    EndAbsoluteValue less-than epsilon"><mrow><mrow><mo>|</mo> <mi>f</mi> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>-</mo></mrow> <msub><mi>p</mi> <mi>n</mi></msub>
    <mrow><mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>|</mo> <mo><</mo> <mi>ϵ</mi></mrow></mrow></math>
    , or equivalently, the supremum norm <math alttext="parallel-to f minus p Subscript
    n Baseline parallel-to less-than epsilon"><mrow><mrow><mo>∥</mo> <mi>f</mi> <mo>-</mo></mrow>
    <msub><mi>p</mi> <mi>n</mi></msub> <mrow><mo>∥</mo> <mo><</mo> <mi>ϵ</mi></mrow></mrow></math>
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the same principle as the one that we disucssed for using rational
    numbers to approximate irrationals applies here: The theorem asserts that we can
    always find polynomials that are *arbitrarily close* to a continuous function;
    which means that the set of polynomials is *dense* in the space of continuous
    functions over the interval [a,b]; or equivalently, for any continuous function
    *f*, we can find a sequence of polynomial functions that converges to *f* (so
    *f* is the *limit of a sequence of polynomials*). In all of these variations of
    the same fact, the distances are measured with respect to the *supremum* norm.
    In [Figure 4-6](#Fig_polyn_approx), we verify that the continuous function <math
    alttext="sine x"><mrow><mo form="prefix">sin</mo> <mi>x</mi></mrow></math> is
    the limit of the sequence of the polynomial functions <math alttext="StartSet
    x comma x minus StartFraction x cubed Over 3 factorial EndFraction comma x minus
    StartFraction x cubed Over 3 factorial EndFraction plus StartFraction x Superscript
    5 Baseline Over 5 factorial EndFraction comma ellipsis EndSet"><mrow><mo>{</mo>
    <mi>x</mi> <mo>,</mo> <mi>x</mi> <mo>-</mo> <mfrac><msup><mi>x</mi> <mn>3</mn></msup>
    <mrow><mn>3</mn><mo>!</mo></mrow></mfrac> <mo>,</mo> <mi>x</mi> <mo>-</mo> <mfrac><msup><mi>x</mi>
    <mn>3</mn></msup> <mrow><mn>3</mn><mo>!</mo></mrow></mfrac> <mo>+</mo> <mfrac><msup><mi>x</mi>
    <mn>5</mn></msup> <mrow><mn>5</mn><mo>!</mo></mrow></mfrac> <mo>,</mo> <mo>⋯</mo>
    <mo>}</mo></mrow></math>'
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_0406.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-6\. Approximation of the continuous function <math alttext="sine x"><mrow><mo
    form="prefix">sin</mo> <mi>x</mi></mrow></math> by a sequence of polynomials.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Statement of the Universal Approximation Theorem For Neural Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we understand the principles of approximation, let’s state the most
    recent approximation theorems for neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that a neural network is the representation of the training function
    as a computational graph. We want this training function to approximate the unknown
    function that generates the data well. This allows us to use the training function,
    instead of the underlying true function which we do not know, and probably will
    never know, to make predictions. The following approximation theorems assert that
    neural networks can approximate the underlying functions up to any precision.
    When we compare the statements of these theorems to the two examples on irrational
    numbers and continuous functions above, we notice that they are the same kind
    of mathematical statements.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following result is due to Hornik, Stinchombe, and White 1989: Let f be
    a continuous function on a compact set K (this is the true but unknown function
    underlying the data) whose outputs are in <math alttext="double-struck upper R
    Superscript d"><msup><mi>ℝ</mi> <mi>d</mi></msup></math> . Then:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Arbitrarily close*: There exists a feedforward neural network, having only
    a single hidden layer, which uniformly approximates f to within an arbitrary <math
    alttext="epsilon greater-than 0"><mrow><mi>ϵ</mi> <mo>></mo> <mn>0</mn></mrow></math>
    on K.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Denseness*: The set of neural networks, with prescribed nonlinear activations
    and bounds on the number of neurons and layers depending on d, is dense in the
    uniform topology of <math alttext="upper C left-parenthesis upper K comma double-struck
    upper R Superscript d Baseline right-parenthesis"><mrow><mi>C</mi> <mo>(</mo>
    <mi>K</mi> <mo>,</mo> <msup><mi>ℝ</mi> <mi>d</mi></msup> <mo>)</mo></mrow></math>
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In both variations of the same fact, the distances are measured with respect
    to the *supremum* norm on continuous functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The proof needs mathematical concepts from *measure theory* and *functional
    analysis*. We will introduce measure theory in [Chapter 11](ch11.xhtml#ch11) on
    *Probability*. For now we only list what is needed for the proof without any details:
    Borel and Radon measures; Hahn Banach Theorem; and Reiz Representation Theorem.'
  prefs: []
  type: TYPE_NORMAL
- en: Approximation Theory For Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After motivating approximation theory and stating one of its main results for
    deep learning, we point to the state of the art results such as [the ability of
    neural networks to learn probability distributions](https://arxiv.org/pdf/1702.07028.pdf),
    Barron’s theorem, the neural tangent kernel, [and others](https://arxiv.org/pdf/1901.02220.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Loss Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Even though in this chapter we transitioned from [Chapter 3](ch03.xhtml#ch03)’s
    traditional machine learning to era of deep learning, the structure of training
    function, loss function, and optimization is still exactly the same. The loss
    functions used for neural networks are not different than those discussed in [Chapter 3](ch03.xhtml#ch03),
    since the goal of a loss function has not changed: To capture the error between
    the ground truth and prediction made by the training function. In deep learning,
    the neural network represents the training function, and for feed forward neural
    networks, we saw that this is nothing more than a sequence of linear combinations
    followed by compositions with nonlinear activation functions.'
  prefs: []
  type: TYPE_NORMAL
- en: The most popular loss functions used in deep learning are still the mean squared
    error for regression tasks and the cross entropy function for classification tasks.
    Go back to [Chapter 3](ch03.xhtml#ch03) for a thorough explanation of these functions.
  prefs: []
  type: TYPE_NORMAL
- en: There are other loss functions that we sometimes come across in the field. When
    we encounter a new loss function, usually the designers of the model have a certain
    reason to prefer it over the other more popular ones, so make sure you go through
    their rationale for using that specific loss function for their particular set
    up. Ideally, a good loss function penalizes bad predictions, is not expensive
    to compute, and has one derivative that is easy to compute. We need this derivative
    to exist so that our optimization method behaves well. As we discussed in [Chapter 3](ch03.xhtml#ch03),
    functions with one good derivative have smoother terrains than functions with
    discontinuous derivatives, and hence easier to navigate during the optimization
    process, when searching for minimizers of the loss function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Minimizing the cross entropy loss function is the same as maximizing
    the log likelihood function. KL divergence for probability distributions is closely
    related.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recall that the cross entropy function is borrowed from information theory
    and statistical mechanics, and it quantifies the cross entropy between the true
    (empirical) distribution of the data and the distribution (of predictions) produced
    by the neural network’s training function. The cross entropy function has a negative
    sign and a <math alttext="log"><mo form="prefix">log</mo></math> function in its
    formula. Minimizing the minus of a function is the same as maximizing the same
    function without the minus sign, so sometimes you encounter the following statement
    in the field: *Maximizing the log likelihood function*, which for us is equivalent
    to *minimizing the cross entropy loss function*. A closely related concept is
    the *Kullback-Leibler divergence, also called KL divergence*. Sometimes, as in
    the cases where we generate images or machine audio, we need to learn a probability
    distribution, not a deterministic function. Our loss function in this case should
    capture the *difference* (I will not say a distance since its mathematical formula
    is not a distance metric) between the true probability distribution of the data
    and the learned probability distribution. KL divergence is an example of such
    a loss function, which quantifies the amount of information lost when the learned
    distribution is used to approximate the true distribution, or the relative entropy
    of the true distribution with respect to the learned distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Faithful to our *training function*, *loss function* and *optimization* mathematical
    structure, we now discuss the optimization step. Our goal is to perform an efficient
    search of the landscape of the loss function <math alttext="upper L left-parenthesis
    ModifyingAbove omega With right-arrow right-parenthesis"><mrow><mi>L</mi> <mo>(</mo>
    <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math> in
    order to find the minimizing <math alttext="omega"><mi>ω</mi></math> ’s. Note
    that when we explicitly wrote formulas for the training functions of the neural
    network in the early sections, we bundled up the <math alttext="omega"><mi>ω</mi></math>
    weights in matrices *W* and the biases in vectors <math alttext="ModifyingAbove
    omega With right-arrow Subscript 0"><msub><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mn>0</mn></msub></math> . In this section, for the sake of simplifying notation
    and in order to keep the focus on the mathematics, we put all the weights and
    biases in one very long vector <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> . That is, we write the loss
    function as <math alttext="upper L left-parenthesis ModifyingAbove omega With
    right-arrow right-parenthesis"><mrow><mi>L</mi> <mo>(</mo> <mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> , while in reality, for a fully connected
    neural network with *h* hidden layers, it is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign Loss function equals upper L left-parenthesis upper
    W Superscript 1 Baseline comma ModifyingAbove omega With right-arrow Subscript
    0 Superscript 1 Baseline comma upper W squared comma ModifyingAbove omega With
    right-arrow Subscript 0 Superscript 2 Baseline comma ellipsis comma upper W Superscript
    h plus 1 Baseline comma ModifyingAbove omega With right-arrow Subscript 0 Superscript
    h plus 1 Baseline right-parenthesis period dollar-sign"><mrow><mtext>Loss</mtext>
    <mtext>function</mtext> <mo>=</mo> <mi>L</mi> <mo>(</mo> <msup><mi>W</mi> <mn>1</mn></msup>
    <mo>,</mo> <msubsup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn>
    <mn>1</mn></msubsup> <mo>,</mo> <msup><mi>W</mi> <mn>2</mn></msup> <mo>,</mo>
    <msubsup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn> <mn>2</mn></msubsup>
    <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <mo>,</mo> <msubsup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn>
    <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup> <mo>)</mo> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: We only need the above representation when we explicitly compute the derivative
    of the loss function using *backpropagation*, which we postpone till later in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'For deep learning, the number of <math alttext="omega"><mi>ω</mi></math> ’s
    in the vector <math alttext="ModifyingAbove omega With right-arrow"><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover></math> can be extremely high, as in tens of thousands, millions,
    or even billions: [OpenAI’s GPT-2 for natural language](https://en.wikipedia.org/wiki/GPT-2)
    has 1.5 billion parameters, and was trained on a dataset of 8 million web pages.
    We need to solve for this many unknowns!'
  prefs: []
  type: TYPE_NORMAL
- en: Using optimization methods, such as Newton-type methods, that require computing
    matrices of second derivatives of the loss function in that many unknowns is simply
    unfeasible even with our current powerful computational abilities. This is a great
    example where the mathematical theory of a numerical method works perfectly fine
    but is impractical for computational and real life implementation. The sad part
    here is that numerical optimization methods that use the second derivative usually
    converge faster than those that use only the first derivative, because they take
    advantage of the extra knowledge about the concavity of the function (the shape
    of its bowl), as opposed to only using the information on whether the function
    is increasing or decreasing that the first derivative provides. Until we invent
    even more powerful computers, we have to satisfy ourselves with first order methods
    that use only one derivative of the loss function with respect to the unknown
    <math alttext="omega"><mi>ω</mi></math> ’s. These are the *gradient-descent-type*
    methods, and luckily, they perform extremely well for many real life AI systems
    that are currently deployed for use in our everyday life, such as Amazon’s Alexa.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematics And The Mysterious Success of Neural Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is worth pausing here to reflect on the success of neural networks, which
    in this section’s context translates to: Our ability to locate a minimizer for
    the loss function <math alttext="upper L left-parenthesis ModifyingAbove omega
    With right-arrow right-parenthesis"><mrow><mi>L</mi> <mo>(</mo> <mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> that makes the training function generalize
    to new and unseen data really well. I do not have a North American accent and
    Amazon’s Alexa understands me perfectly fine. Mathematically, this success of
    neural networks is still puzzling for various reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: The loss function’s <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> -domain <math alttext="upper
    L left-parenthesis ModifyingAbove omega With right-arrow right-parenthesis"><mrow><mi>L</mi>
    <mo>(</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    where the search for the minimum is happening is very high dimensional (can reach
    billions of dimensions). We have billions or even trillions of options. How are
    we finding the right one?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The landscape of the loss function itself is non-convex, so it has a bunch of
    local minima and saddle points where optimization methods can get stuck or converge
    to the wrong local minimum. Again, how are we finding the right one?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In some AI applications, such as computer vision, there are much more <math
    alttext="omega"><mi>ω</mi></math> ’s than data points (images). Recall that for
    images each pixel is a feature, so that is already a lot of <math alttext="omega"><mi>ω</mi></math>
    ’s only at the input level. For such applications, there are much more unknowns
    (the <math alttext="omega"><mi>ω</mi></math> ’s) than information required to
    determine them (the data points). Mathematically, this is an *under-determined*
    system, and such systems have *infinitely many possible solutions*! So exaclty
    how is the optimization method for our network picking up on the good solutions?
    The ones that generalize well?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some of this mysterious success is attributed to techniques that have become
    a staple during the training process, such as regularization (discussed in a later
    section of this chapter), validation, testing, *etc*. However, deep learning still
    lacks a solid theoretical foundation. This is why a lot of mathematicians have
    recently converged to answer such questions. The National Science Foundation (NSF)
    efforts in this direction, and the quotes (*in italics*) that we copy next from
    its announcements are quite informative and give a great insight on how mathematics
    is interwined with advancing AI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[The NSF has recently established 11 new artificial intelligence research institutes](https://www.nsf.gov/cise/ai.jsp)
    *to advance AI in various fields, such as human-AI interaction and collaboration,
    AI for advances in optimization, AI and advanced cyberinfrastructure, AI in computer
    and network systems, AI in dynamic systems, AI-augmented learning and AI-driven
    innovation in agriculture and the food system. The NSF’s ability to bring together
    numerous fields of scientific inquiry, including computer and information science
    and engineering, along with cognitive science and psychology, economics and game
    theory, engineering and control theory, ethics, linguistics, mathematics and philosophy,
    uniquely positions the agency to lead the nation in expanding the frontiers of
    AI. NSF-funding will help the U.S. capitalize on the full potential of AI to strengthen
    the economy, advance job growth, and bring benefits to society for decades to
    come*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is quoted from NSF’s [mathematical and scientific foundations
    of deep learning SCALE MoDl](https://www.nsf.gov/events/event_summ.jsp?cntn_id=302168):
    *Deep learning has met with impressive empirical success that has fueled fundamental
    scientific discoveries and transformed numerous application domains of artificial
    intelligence. Our incomplete theoretical understanding of the field, however,
    impedes accessibility to deep learning technology by a wider range of participants.
    Confronting our incomplete understanding of the mechanisms underlying the success
    of deep learning should serve to overcome its limitations and expand its applicability.
    The SCALE MoDL program will sponsor new research collaborations consisting of
    mathematicians, statisticians, electrical engineers, and computer scientists.
    Research activities should be focused on explicit topics involving some of the
    most challenging theoretical questions in the general area of Mathematical and
    Scientific Foundations of Deep Learning. Each collaboration should conduct training
    through research involvement of recent doctoral degree recipients, graduate students,
    and/or undergraduate students from across this multi-disciplinary spectrum. A
    wide range of scientific themes on theoretical foundations of deep learning may
    be addressed in these proposals. Likely topics include but are not limited to
    geometric, topological, Bayesian, or game-theoretic formulations, to analysis
    approaches exploiting optimal transport theory, optimization theory, approximation
    theory, information theory, dynamical systems, partial differential equations,
    or mean field theory, to application-inspired viewpoints exploring efficient training
    with small data sets, adversarial learning, and closing the decision-action loop,
    not to mention foundational work on understanding success metrics, privacy safeguards,
    causal inference, and algorithmic fairness*.'
  prefs: []
  type: TYPE_NORMAL
- en: Gradient Descent <math alttext="ModifyingAbove omega With right-arrow Superscript
    i plus 1 Baseline equals ModifyingAbove omega With right-arrow Superscript i Baseline
    minus eta normal nabla upper L left-parenthesis ModifyingAbove omega With right-arrow
    Superscript i Baseline right-parenthesis"><mrow><msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msup> <mo>=</mo>
    <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mi>i</mi></msup> <mo>-</mo>
    <mi>η</mi> <mi>∇</mi> <mi>L</mi> <mrow><mo>(</mo> <msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mi>i</mi></msup> <mo>)</mo></mrow></mrow></math>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The widely used gradient descent method for optimization in deep learning is
    so simple that we could fit its formula in this subsection’s title. This is how
    gradient descent searches the landscape of the loss function <math alttext="upper
    L left-parenthesis ModifyingAbove omega With right-arrow right-parenthesis"><mrow><mi>L</mi>
    <mo>(</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    for a local minimum:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Initialize somewhere at <math alttext="ModifyingAbove omega With right-arrow
    Superscript 0"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn></msup></math>**
    : Randomly pick starting numerical values for <math alttext="ModifyingAbove omega
    With right-arrow Superscript 0 Baseline equals left-parenthesis omega 0 comma
    omega 1 comma ellipsis comma omega Subscript n Baseline right-parenthesis"><mrow><msup><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn></msup> <mo>=</mo> <mrow><mo>(</mo>
    <msub><mi>ω</mi> <mn>0</mn></msub> <mo>,</mo> <msub><mi>ω</mi> <mn>1</mn></msub>
    <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>ω</mi> <mi>n</mi></msub> <mo>)</mo></mrow></mrow></math>
    . This choice places us somewhere in the search space and at the landscape of
    <math alttext="upper L left-parenthesis ModifyingAbove omega With right-arrow
    right-parenthesis"><mrow><mi>L</mi> <mo>(</mo> <mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> . One big warning here: *Where we
    start matters*! Do not initialize with all zeros or all equal numbers. This will
    dimish the network’s ability to learn different features, since different nodes
    will output exactly the same numbers. We will discuss initialization shorlty in
    an upcoming subsection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Move to a new point <math alttext="ModifyingAbove omega With right-arrow
    Superscript 1"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>1</mn></msup></math>**
    : The gradient descent moves in the direction opposite to the gradient vector
    of the loss function <math alttext="minus normal nabla upper L left-parenthesis
    ModifyingAbove omega With right-arrow Superscript 0 Baseline right-parenthesis"><mrow><mo>-</mo>
    <mi>∇</mi> <mi>L</mi> <mo>(</mo> <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mn>0</mn></msup> <mo>)</mo></mrow></math> . This is guaranteed to decrease the
    gradient if the step size <math alttext="eta"><mi>η</mi></math> , also called
    the *learning rate* is not too large:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ModifyingAbove omega With right-arrow Superscript
    1 Baseline equals ModifyingAbove omega With right-arrow Superscript 0 Baseline
    minus eta normal nabla upper L left-parenthesis ModifyingAbove omega With right-arrow
    Superscript 0 Baseline right-parenthesis dollar-sign"><mrow><msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mn>1</mn></msup> <mo>=</mo> <msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mn>0</mn></msup> <mo>-</mo> <mi>η</mi> <mi>∇</mi> <mi>L</mi>
    <mrow><mo>(</mo> <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn></msup>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: '**Move to a new point <math alttext="ModifyingAbove omega With right-arrow
    squared"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>2</mn></msup></math>**
    : Again, the gradient descent moves in the direction opposite to the gradient
    vector of the loss function <math alttext="minus normal nabla upper L left-parenthesis
    ModifyingAbove omega With right-arrow Superscript 1 Baseline right-parenthesis"><mrow><mo>-</mo>
    <mi>∇</mi> <mi>L</mi> <mo>(</mo> <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mn>1</mn></msup> <mo>)</mo></mrow></math> . This is again guaranteed to decrease
    the gradient if the learning <math alttext="eta"><mi>η</mi></math> is not too
    large:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ModifyingAbove omega With right-arrow squared equals
    ModifyingAbove omega With right-arrow Superscript 1 Baseline minus eta normal
    nabla upper L left-parenthesis ModifyingAbove omega With right-arrow Superscript
    1 Baseline right-parenthesis dollar-sign"><mrow><msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mn>2</mn></msup> <mo>=</mo> <msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mn>1</mn></msup> <mo>-</mo> <mi>η</mi> <mi>∇</mi> <mi>L</mi>
    <mrow><mo>(</mo> <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>1</mn></msup>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: '**Keep going until the sequence of points <math alttext="StartSet ModifyingAbove
    omega With right-arrow Superscript 0 Baseline comma ModifyingAbove omega With
    right-arrow Superscript 1 Baseline comma ModifyingAbove omega With right-arrow
    squared comma ellipsis EndSet"><mrow><mo>{</mo> <msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mn>0</mn></msup> <mo>,</mo> <msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mn>1</mn></msup> <mo>,</mo> <msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mn>2</mn></msup> <mo>,</mo> <mo>⋯</mo> <mo>}</mo></mrow></math>
    converges**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 4-7](#Fig_gradient_descent_steps) shows a picture of minimizing a certain
    loss function <math alttext="upper L left-parenthesis omega 1 comma omega 2 right-parenthesis"><mrow><mi>L</mi>
    <mo>(</mo> <msub><mi>ω</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>ω</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></math> using gradient descent. We as humans are limited to the
    three dimensional space that we exist in so we cannot visualize beyond three dimensions.
    This is a severe limitation for us in terms of visualization since our loss functions
    usually act on very high dimensional spaces. They are functions of many <math
    alttext="omega"><mi>ω</mi></math> ’s, but we can only visualize them accurately
    if they depend on at most two <math alttext="omega"><mi>ω</mi></math> ’s. That
    is, we can visualize a loss function <math alttext="upper L left-parenthesis omega
    1 comma omega 2 right-parenthesis"><mrow><mi>L</mi> <mo>(</mo> <msub><mi>ω</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>ω</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>
    depending on two <math alttext="omega"><mi>ω</mi></math> ’s but not a loss function
    <math alttext="upper L left-parenthesis omega 1 comma omega 2 comma omega 3 right-parenthesis"><mrow><mi>L</mi>
    <mo>(</mo> <msub><mi>ω</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>ω</mi> <mn>2</mn></msub>
    <mo>,</mo> <msub><mi>ω</mi> <mn>3</mn></msub> <mo>)</mo></mrow></math> depending
    on three (or more) <math alttext="omega"><mi>ω</mi></math> ’s. Even with this
    severe limitation on our capacity to visualize loss functions acting on high dimensional
    spaces, [Figure 4-7](#Fig_gradient_descent_steps) gives an accurate picture of
    how the gradient descent method operates in general. In [Figure 4-7](#Fig_gradient_descent_steps),
    the search happens in the two dimensional <math alttext="left-parenthesis omega
    1 comma omega 2 right-parenthesis"><mrow><mo>(</mo> <msub><mi>ω</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>ω</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math> -plane
    (the flat ground in [Figure 4-7](#Fig_gradient_descent_steps)), and we track the
    progress on the landscape of the function <math alttext="upper L left-parenthesis
    omega 1 comma omega 2 right-parenthesis"><mrow><mi>L</mi> <mo>(</mo> <msub><mi>ω</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>ω</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>
    that is embedded in <math alttext="double-struck upper R cubed"><msup><mi>ℝ</mi>
    <mn>3</mn></msup></math> . The search space always has one dimension less than
    the dimension of the space in which the landscape of the loss function is embedded.
    This makes the optimization process harder, since we are looking for a minimizer
    of a busy landscape in a flattened or squooshed version of its terrain (the ground
    level in [Figure 4-7](#Fig_gradient_descent_steps)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_0407.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-7\. Two gradient descent steps. Note that if we start on the other
    side of the mountain, we wouldn’t converge to the minimum. So when we are searching
    for the minimum of a non-convex function, where we start, or how we initiate the
    <math alttext="omega"><mi>ω</mi></math> ’s, matters a lot.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Explaining The Role Of The Learning Rate Hyperparameter <math alttext="eta"><mi>η</mi></math>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At each iteration, the gradient descent method <math alttext="ModifyingAbove
    omega With right-arrow Superscript i plus 1 Baseline equals ModifyingAbove omega
    With right-arrow Superscript i Baseline minus eta normal nabla upper L left-parenthesis
    ModifyingAbove omega With right-arrow Superscript i Baseline right-parenthesis"><mrow><msup><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover> <mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <mo>=</mo> <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mi>i</mi></msup>
    <mo>-</mo> <mi>η</mi> <mi>∇</mi> <mi>L</mi> <mrow><mo>(</mo> <msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mi>i</mi></msup> <mo>)</mo></mrow></mrow></math> moves us
    from the point <math alttext="ModifyingAbove omega With right-arrow Superscript
    i"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mi>i</mi></msup></math>
    in the search space to another point <math alttext="ModifyingAbove omega With
    right-arrow Superscript i plus 1"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msup></math> . The gradient descent
    adds <math alttext="minus eta normal nabla upper L left-parenthesis ModifyingAbove
    omega With right-arrow Superscript i Baseline right-parenthesis"><mrow><mo>-</mo>
    <mi>η</mi> <mi>∇</mi> <mi>L</mi> <mo>(</mo> <msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mi>i</mi></msup> <mo>)</mo></mrow></math> to the current <math
    alttext="ModifyingAbove omega With right-arrow Superscript i"><msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mi>i</mi></msup></math> in order to obtain <math alttext="ModifyingAbove
    omega With right-arrow Superscript i plus 1"><msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msup></math> .
    The quantity <math alttext="minus eta normal nabla upper L left-parenthesis ModifyingAbove
    omega With right-arrow Superscript i Baseline right-parenthesis"><mrow><mo>-</mo>
    <mi>η</mi> <mi>∇</mi> <mi>L</mi> <mo>(</mo> <msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mi>i</mi></msup> <mo>)</mo></mrow></math> is made up of scalar
    number <math alttext="eta"><mi>η</mi></math> multiplied by the negative of the
    gradient vector <math alttext="minus normal nabla upper L left-parenthesis ModifyingAbove
    omega With right-arrow Superscript i Baseline right-parenthesis"><mrow><mo>-</mo>
    <mi>∇</mi> <mi>L</mi> <mo>(</mo> <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mi>i</mi></msup> <mo>)</mo></mrow></math> , which points in the direction of
    the steepest decrease of the loss function from the point <math alttext="ModifyingAbove
    omega With right-arrow Superscript i"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mi>i</mi></msup></math> . Thus, the scaled <math alttext="minus eta normal nabla
    upper L left-parenthesis ModifyingAbove omega With right-arrow Superscript i Baseline
    right-parenthesis"><mrow><mo>-</mo> <mi>η</mi> <mi>∇</mi> <mi>L</mi> <mo>(</mo>
    <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mi>i</mi></msup> <mo>)</mo></mrow></math>
    tells us how far in the search space we are going to go along the steepest descent
    direction in order to choose the next point <math alttext="ModifyingAbove omega
    With right-arrow Superscript i plus 1"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msup></math> . In other words, the
    vector <math alttext="minus normal nabla upper L left-parenthesis ModifyingAbove
    omega With right-arrow Superscript i Baseline right-parenthesis"><mrow><mo>-</mo>
    <mi>∇</mi> <mi>L</mi> <mo>(</mo> <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mi>i</mi></msup> <mo>)</mo></mrow></math> specifies in which direction we will
    move away from our current point, and the scalar number <math alttext="eta"><mi>η</mi></math>
    , called the *learning rate*, controls how far we are going to step along that
    direction. [Figure 4-8](#Fig_different_learning_rate) shows one step of gradient
    descent with two different learning rates <math alttext="eta"><mi>η</mi></math>
    . Too large of a learning rate might overshoot the minimum and cross to the other
    side of the valley. On the other hand, too small of a learning rate takes a while
    to get to the minimum. So the tradeoff is between choosing a large learning rate
    and risking overshooting the minimum, and choosing a small learning rate and increasing
    computational cost and time for convergence.
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_0408.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-8\. One step gradient descent with two different learning rates. On
    the left, the learning rate is too large so the gradient descent overshoots the
    minimum (the star point) and lands on the other side of the valley. On the right,
    the learning rate is small, however, it will take a while to get to the minimum
    (the star point). Note how the gradient vector at a point is perpendicular to
    the level set at that point.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The learning rate <math alttext="eta"><mi>η</mi></math> is another example of
    a hyperparameter of a machine learning model. It is not one of the weights that
    goes into the formula of the training function. It is a parameter that is intrinsic
    to the algorithm that we employ in order to estimate the weights of the training
    function.
  prefs: []
  type: TYPE_NORMAL
- en: The scale of the features affects the performance of the gradient descent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is one of the reasons to standarize the features ahead of time. Standarizing
    a feature means subtracting from each data instance the mean and dividing by the
    standard deviation. This forces all the data values to have the same scale, with
    mean zero and standard deviation one, as opposed to having vastly different scales,
    such as a feature measured in the millions and another measured in 0.001\. But
    why does this affect the performance of the gradient descent method? Read on.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that the values of the input features get multiplied by the weights in
    the training function, and the training function in turn enters into the formula
    of the loss function. Very different scales of the input features change the shape
    of the bowl of the loss function, making minimization process harder. [Figure 4-9](#Fig_shapes_of_bowl)
    shows the level sets of the function <math alttext="upper L left-parenthesis omega
    1 comma omega 2 right-parenthesis equals omega 1 squared plus a omega 2 squared"><mrow><mi>L</mi>
    <mrow><mo>(</mo> <msub><mi>ω</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>ω</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow> <mo>=</mo> <msubsup><mi>ω</mi> <mn>1</mn>
    <mn>2</mn></msubsup> <mo>+</mo> <mi>a</mi> <msubsup><mi>ω</mi> <mn>2</mn> <mn>2</mn></msubsup></mrow></math>
    with different values of *a*, mimicking different scales of input features. Note
    how the level sets of loss function become much more narrow and elongated as the
    value of *a* increases. This means that the shape of the bowl of the loss function
    is a long narrow valley.
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_0409.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-9\. The level sets of the loss function <math alttext="upper L left-parenthesis
    omega 1 comma omega 2 right-parenthesis equals omega 1 squared plus a omega 2
    squared"><mrow><mi>L</mi> <mrow><mo>(</mo> <msub><mi>ω</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>ω</mi> <mn>2</mn></msub> <mo>)</mo></mrow> <mo>=</mo> <msubsup><mi>ω</mi>
    <mn>1</mn> <mn>2</mn></msubsup> <mo>+</mo> <mi>a</mi> <msubsup><mi>ω</mi> <mn>2</mn>
    <mn>2</mn></msubsup></mrow></math> become much more narrow and elongated as the
    value of *a* increases from 1 to 20 to 40.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When the gradient descent method tries to operate in such a narrow valley, its
    points hop from one side of the valley to the other, zig-zagging as it tries to
    locate the minimum, and slowing down the convergence considerably. Imagine zig-zagging
    along all the streets of Rome before arriving at the Vatican, as opposed to taking
    a helicopter straight to the Vatican.
  prefs: []
  type: TYPE_NORMAL
- en: But why does this zig-zagging behavior happen? One hallmark of the gradient
    vector of a function is that it is perpendicular to the level sets of that function.
    We do this computation in the appendix of this book. So if the valley of the loss
    function is so long and narrow, its level sets almost look like lines that are
    parallel to each other *and* with a large enough step size (learning rate), we
    can literary cross from one side of the valley to the other, since it is so narrow.
    Google *gradient descent zigzag* and you will see many images illustrating this
    behavior.
  prefs: []
  type: TYPE_NORMAL
- en: One fix against zig-zagging, even with a narrow long valley (assuming we did
    not scale the input feature values ahead of time), is to choose a very small learning
    rate, preventing the gradient descent method to step from one side of the valley
    to the other. That, however, slows down arrival to the minimum in its own way,
    since the method will step only incrementally at each iteration. This way, we
    will eventually arrive to the Vatican from Rome, but at a turtle’s pace.
  prefs: []
  type: TYPE_NORMAL
- en: Near the minima (local and/or global), flat regions, or saddle points of the
    loss function’s landscape, the gradient descent method crawls
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The gradient descent method updates the current point <math alttext="ModifyingAbove
    omega With right-arrow Superscript i"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mi>i</mi></msup></math> by adding the vector <math alttext="minus eta normal
    nabla upper L left-parenthesis ModifyingAbove omega With right-arrow Superscript
    i Baseline right-parenthesis"><mrow><mo>-</mo> <mi>η</mi> <mi>∇</mi> <mi>L</mi>
    <mo>(</mo> <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mi>i</mi></msup>
    <mo>)</mo></mrow></math> . Therefore, the exact length of the step from the point
    <math alttext="ModifyingAbove omega With right-arrow Superscript i"><msup><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover> <mi>i</mi></msup></math> in the direction
    of the negative gradient vector is <math alttext="eta"><mi>η</mi></math> multiplied
    by the length of the gradient vector <math alttext="normal nabla upper L left-parenthesis
    ModifyingAbove omega With right-arrow Superscript i Baseline right-parenthesis"><mrow><mi>∇</mi>
    <mi>L</mi> <mo>(</mo> <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mi>i</mi></msup> <mo>)</mo></mrow></math> . At a mininum, maximum, saddle point,
    or any flat region of the landscape of the loss function, the gradient vector
    is zero, hence, its length is zero as well. This means that near a minimum, maximum,
    saddle point, or any flat region, the step size of the gradient descent method
    becomes very small, and the method slows down significantly. If this happens near
    a minimum, then there is not much worry since this can be used as a stopping criterion,
    unless this minimum is a local minimum very far from the global minimum. If on
    the other hand in happens in a flat region or near a saddle point, then the method
    will get stuck there for a while, and that is undersirable. Some practitioners
    put the learning rate <math alttext="eta"><mi>η</mi></math> on a schedule, changing
    its value during the optimization process. When we look into these, we notice
    that the goals are to avoid crawling, save computational time, and speed up convergence.
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss stochastic (random) gradient descent later in this chapter.
    Due to the random nature of this method, the points hop around a lot, as opposed
    to following a more consistent route towards the minimum. This works to our advantage
    in situations where we are stuck, such as saddle points or local minima, since
    we might get randomly propelled out of the local minimum or away from the saddle
    point into a part of the landscape with a better route towards the minimum.
  prefs: []
  type: TYPE_NORMAL
- en: Convex *vs*. Non-Convex Landscapes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We cannot have an optimization chapter without discussing *convexity*. In fact,
    entire mathematical fields are dedicated solely for [*convex optimization*](https://en.wikipedia.org/wiki/Convex_optimization).
    It is equally important to immediately note that optimization for neural networks
    is in general, *non-convex*.
  prefs: []
  type: TYPE_NORMAL
- en: When we use nonconvex activation functions, such as the sigmoid-type functions
    in the first row of [Figure 4-5](#Fig_activation_functions), the landscapes of
    the loss functions involved in the resulting neural networks are not convex. This
    is why we spend a good amount of time talking about getting stuck at local minima,
    flat regions, and saddle points, which we wouldn’t worry about for convex landscapes.
    The contrast between convex and non-convex landscapes is obvious in [Figure 4-10](#Fig_contours_convex),
    which shows a convex loss function and its level sets, and [Figure 4-11](#Fig_contours_nonconvex3)
    and [Figure 4-12](#Fig_contours_nonconvex4), which show non-convex functions and
    their level sets.
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_0410.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-10\. Plot of three dimensional convex function and its level sets.
    Gradient vectors live in the same space ( <math alttext="double-struck upper R
    squared"><msup><mi>ℝ</mi> <mn>2</mn></msup></math> ) as the level sets, not in
    <math alttext="double-struck upper R cubed"><msup><mi>ℝ</mi> <mn>3</mn></msup></math>
    .
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![250](assets/emai_0411.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-11\. Plots of three dimensional non-convex functions and their level
    sets. Gradient vectors live in the same space ( <math alttext="double-struck upper
    R squared"><msup><mi>ℝ</mi> <mn>2</mn></msup></math> ) as the level sets, not
    in <math alttext="double-struck upper R cubed"><msup><mi>ℝ</mi> <mn>3</mn></msup></math>
    .
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![250](assets/emai_0412.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-12\. Plots of three dimensional non-convex functions and their level
    sets. Gradient vectors live in the same space ( <math alttext="double-struck upper
    R squared"><msup><mi>ℝ</mi> <mn>2</mn></msup></math> ) as the level sets, not
    in <math alttext="double-struck upper R cubed"><msup><mi>ℝ</mi> <mn>3</mn></msup></math>
    .
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When we use convex activation functions throughout the network, such as the
    ReLU-type functions in the second row of [Figure 4-5](#Fig_activation_functions),
    *and* convex loss functions, we can still end up with a *conconvex* optimization
    problem, because the composition of two convex functions is not necessarily convex.
    If the loss function happens to be non-decreasing and convex, then its composition
    with a convex function is convex. The loss functions which are popular for neural
    networks, such as the mean squared error, the cross entropy, and the hinge loss
    are all convex but not non-decreasing.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to become familiar with central concepts from convex optimization.
    If you do not know where to start, keep in mind that convexity replaces linearity
    when linearity is too simplistic or unavailable, then learn everything about the
    following (which will be tied to AI, deep learning, and reinforcement learning
    in our chapter on Operations Research):'
  prefs: []
  type: TYPE_NORMAL
- en: Max of linear functions is convex
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Max min and min max
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saddle points
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two player zero sum games
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since convex optimization is such a well developed and understood field (at
    least more than the mathematical foundations for neural networks) and neural networks
    still have long ways to go mathematically, it would be nice if we could exploit
    our knowledge about convexity inorder to gain a deeper understanding of neural
    networks. Research in this area is ongoing. For example, in a [recent paper (2020)](https://proceedings.mlr.press/v108/ergen20a.xhtml)
    titled *Convex Geometry of Two-Layer ReLU Networks: Implicit Autoencoding and
    Interpretable Models*, the authors frame the problem of training two layered ReLU
    networks as a convex analytic optimization problem. The following is the abstract
    of the paper:'
  prefs: []
  type: TYPE_NORMAL
- en: '*We develop a convex analytic framework for ReLU neural networks which elucidates
    the inner workings of hidden neurons and their function space characteristics.
    We show that rectified linear units in neural networks act as convex regularizers,
    where simple solutions are encouraged via extreme points of a certain convex set.
    For one dimensional regression and classification, we prove that finite two-layer
    ReLU networks with norm regularization yield linear spline interpolation. In the
    more general higher dimensional case, we show that the training problem for two-layer
    networks can be cast as a convex optimization problem with infinitely many constraints.
    We then provide a family of convex relaxations to approximate the solution, and
    a cutting-plane algorithm to improve the relaxations. We derive conditions for
    the exactness of the relaxations and provide simple closed form formulas for the
    optimal neural network weights in certain cases. Our results show that the hidden
    neurons of a ReLU network can be interpreted as convex autoencoders of the input
    layer. We also establish a connection to <math alttext="l 0 minus l 1"><mrow><msub><mi>l</mi>
    <mn>0</mn></msub> <mo>-</mo> <msub><mi>l</mi> <mn>1</mn></msub></mrow></math>
    equivalence for neural networks analogous to the minimal cardinality solutions
    in compressed sensing. Extensive experimental results show that the proposed approach
    yields interpretable and accurate models*.'
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic Gradient Descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far, training a feed forward neural network has progressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Fix an initial set of weights <math alttext="ModifyingAbove omega With right-arrow
    Superscript 0"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn></msup></math>
    for the training function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate this training function at *all* the data points in the training subset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the individual losses at *all* the data points in the training subset
    by comparing their true labels to the predictions made by the training function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do this for *all* the data in the training subset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Average *all* these individual losses. This average is the loss function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the gradient of this loss function at this initial set of weights.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the next set of weights according to the steepest descent rule.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat until you converge somewhere, or stop after a certain number of iterations
    determined by the performance of the training function on the validation set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The problem with the above process is that when we have a large training subset
    with thousands of points, and a neural network with thousands of weights, it gets
    too expensive to evaluate the training function, the loss function, and the gradient
    of the loss function on *all* the data points in the training subset. The remedy
    is to randomize the process: Randomly choose a very small portion of the training
    subset to evaluate the training function, loss function, and gradient of this
    loss function at each step. This slashes the computational cost dramatically at
    each step.'
  prefs: []
  type: TYPE_NORMAL
- en: Keep repeating this random selection (in principle with replacement but in practice
    without replacement) of small portions of the training subset until you converge
    somewhere, or stop after a certain number of iterations determined by the performance
    of the training function on the validation set. One pass through the whole training
    subset is called *one epoch*.
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic gradient descent performs remarkably well, and it has become a staple
    in training neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Initializing The Weights <math alttext="ModifyingAbove omega With right-arrow
    Superscript 0"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn></msup></math>
    For The Optimization Process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already established that initializing with all zero weights or all the
    same weights is a really bad idea. The next logical step, and what had been the
    traditional practice (before 2010), would be to choose the weights in the initial
    <math alttext="ModifyingAbove omega With right-arrow Superscript 0"><msup><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>0</mn></msup></math> randomly,
    sampled either from the uniform distribution over small intervals such as [-1,1],
    [0,1], or [-0.3,0.3], or from the Gaussian distribution with a pre-selected mean
    and variance. Even though this has not been studied in depth, it seems from empirical
    evidence that it doesn’t matter whether the initial weights are sampled from the
    uniform distribution or Gaussian distribution, but it does seem that the scale
    of the initial weights matters when it comes to both the progress of the optimization
    process and the ability of the network to generalize well to unseen data. It turns
    out that some choices are better than others in this respect. Currently, the two
    state-of-the-art choices depend on the choice of the activation function, whether
    it is sigmoid-type or ReLu-type.
  prefs: []
  type: TYPE_NORMAL
- en: Xavier Glorot Initialization
  prefs: []
  type: TYPE_NORMAL
- en: Here, initial weights are sampled from uniform distribution over the interval
    [ <math alttext="minus StartFraction StartRoot 6 EndRoot Over StartRoot n plus
    m EndRoot EndFraction comma StartFraction StartRoot 6 EndRoot Over StartRoot n
    plus m EndRoot EndFraction"><mrow><mo>-</mo> <mfrac><msqrt><mn>6</mn></msqrt>
    <msqrt><mrow><mi>n</mi><mo>+</mo><mi>m</mi></mrow></msqrt></mfrac> <mo>,</mo>
    <mfrac><msqrt><mn>6</mn></msqrt> <msqrt><mrow><mi>n</mi><mo>+</mo><mi>m</mi></mrow></msqrt></mfrac></mrow></math>
    ], where n is the number of inputs to the node (e.g. number of nodes in the previous
    layer) and m is the number of outputs from the layer (e.g. number of nodes in
    the current layer).
  prefs: []
  type: TYPE_NORMAL
- en: He Initialiation
  prefs: []
  type: TYPE_NORMAL
- en: Here, the initial weights are sampled from the Gaussian distribution with zero
    mean and variance 2/n, where n is the number of inputs to the node.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Regularization helps us arrive at a good choice for the weights of the training
    function while at the same time avoiding overfitting the data. We want our trained
    function to follow the signal in the data rather than the noise, so it can generalize
    well to unseen data. Here we include four simple yet popular regularization techniques
    that are used while training a neural network: Dropout, early stopping, batch
    normalization, and weight decay (Ridge, Lasso, and elastic net) regularizations.'
  prefs: []
  type: TYPE_NORMAL
- en: Dropout
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Drop some randomly selected neurons from each layer during training. Usually,
    about twenty percent of the input layer’s nodes and about half of each of the
    hidden layers’ nodes are randomly dropped. No nodes from the output layer are
    dropped. Dropout is partially inspired by genetic reproduction, where half a parent’s
    genes are dropped and there is a small random mutation. This has the effect of
    training at once different networks (with different number of nodes at each layer)
    and averaging their results, which typically produces more reliable results.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to implement dropout is by introducing a hyperparameter *p* for each
    layer that specifies the probability at which each node in that layer will be
    dropped. Recall the basic operations that take place at each node: Linearly combine
    the outputs of the nodes of the previous layer, then activate. With dropout, each
    of the outputs of the nodes of the previous layer (starting with the input layer),
    is multiplied by a random number *r*, which can be either zero or one with probability
    *p*. Thus when a node’s *r* takes the value zero, that node is essentially dropped
    from the network which now forces the other *retained* nodes to *pick up the slack*
    when adjusting the weights in one gradient descent step. We will explain this
    further in the backpropagation section, and this [link](https://www.tech-quantum.com/implementing-drop-out-regularization-in-neural-networks/)
    provides a step by step route to implement dropout.'
  prefs: []
  type: TYPE_NORMAL
- en: For a deeper mathematical exploration, the following [paper (2015)](https://arxiv.org/abs/1506.02142)
    connects dropout to Bayesian approximations of model uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Early Stopping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we update the weights during training, in particular during gradient descent,
    after each epoch, we evaluate the error made by the training function at the current
    weights on the validation subset of the data. This error should be decreasing
    as the model *learns* the training data, however, after a certain number of epochs,
    this error will start increasing, indicating that the training function has now
    started overfitting the training data and is failing to generalize well to the
    validation data. Once we observe this increase in the model’s prediction over
    the validation subset, we stop training, and go back to the set of weights where
    that error was lowest, right before we started observing the increase.
  prefs: []
  type: TYPE_NORMAL
- en: Batch Normalization Of Each Layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main idea here is to normalize the inputs to each layer of the network.
    This means that the inputs to each layer will have mean zero and variance one.
    This is usually accomplished by subtracting the mean and dividing by the variance
    for each of the layer’s inputs. We will detail this in a moment. The reason this
    is good to do at each hidden layer is similar to why it is good at the original
    input layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Applying *batch normalization* often eliminates the need for dropout, and allows
    us to be less particular about initialization. It makes the training faster and
    safer from vanishing and exploding gradients. It also has the added advantage
    of regularization. The cost for all of these gains is not too high, as it usually
    involves training only two additional parameters, one for scaling, and one for
    shifting, at each layer. The [paper by Ioffe and Szegedy(2015)](http://proceedings.mlr.press/v37/ioffe15.pdf)
    introduced the method. The abstract of their paper describes the batch normalization
    process and the problems it addresses (the brackets are my own comments):'
  prefs: []
  type: TYPE_NORMAL
- en: '*Training Deep Neural Networks is complicated by the fact that the distribution
    of each layer’s inputs changes during training, as the parameters of the previous
    layers change. This slows down the training by requiring lower learning rates
    and careful parameter initialization, and makes it notoriously hard to train models
    with saturating nonlinearities* [such as the sigmoid type activation functions,
    in [Figure 4-5](#Fig_activation_functions), which become almost constant, outputting
    the same value when the input is large in magnitude. This renders the nonlinearity
    useless in the training process, and the network stops learning at subsequent
    layers]. *We refer to this phenomenon* [the change in the distribution of the
    inputs to each layer] *as internal covariate shift, and address the problem by
    normalizing layer inputs. Our method draws its strength from making normalization
    a part of the model architecture and performing the normalization for each training
    mini-batch. Batch Normalization allows us to use much higher learning rates and
    be less careful about initialization, and in some cases eliminates the need for
    Dropout. Applied to a state-of-the-art image classification model, Batch Normalization
    achieves the same accuracy with 14 times fewer training steps, and beats the original
    model by a significant margin. Using an ensemble of batch-normalized networks,
    we improve upon the best published result on ImageNet classification: reaching
    4.82% top-5 test error, exceeding the accuracy of human raters.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Batch normalization is often implemented in the architecture of a network either
    in its own layer before the activation step, or after activation. The process,
    *during training*, usually follows these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Choose a batch from the training data of size b. Each data point in this has
    feature vector <math alttext="ModifyingAbove x Subscript i Baseline With right-arrow"><mover
    accent="true"><msub><mi>x</mi> <mi>i</mi></msub> <mo>→</mo></mover></math> , so
    the whole batch has feature vectors <math alttext="ModifyingAbove x 1 With right-arrow
    comma ModifyingAbove x 2 With right-arrow comma ellipsis comma ModifyingAbove
    x Subscript b Baseline With right-arrow"><mrow><mover accent="true"><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>→</mo></mover> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <mover accent="true"><msub><mi>x</mi>
    <mi>b</mi></msub> <mo>→</mo></mover></mrow></math> .
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate the vector whose entries are the means of each feature in this particular
    batch: <math alttext="ModifyingAbove mu With right-arrow equals StartFraction
    ModifyingAbove x 1 With right-arrow plus ModifyingAbove x 2 With right-arrow plus
    ellipsis plus ModifyingAbove x Subscript b Baseline With right-arrow Over b EndFraction"><mrow><mover
    accent="true"><mi>μ</mi> <mo>→</mo></mover> <mo>=</mo> <mfrac><mrow><mover accent="true"><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>→</mo></mover><mo>+</mo><mover accent="true"><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>→</mo></mover><mo>+</mo><mo>⋯</mo><mo>+</mo><mover accent="true"><msub><mi>x</mi>
    <mi>b</mi></msub> <mo>→</mo></mover></mrow> <mi>b</mi></mfrac></mrow></math> .'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate the variance across the batch: Subtract <math alttext="ModifyingAbove
    mu With right-arrow"><mover accent="true"><mi>μ</mi> <mo>→</mo></mover></math>
    from each <math alttext="ModifyingAbove x 1 With right-arrow comma ModifyingAbove
    x 2 With right-arrow comma ellipsis comma ModifyingAbove x Subscript b Baseline
    With right-arrow"><mrow><mover accent="true"><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><msub><mi>x</mi> <mn>2</mn></msub>
    <mo>→</mo></mover> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <mover accent="true"><msub><mi>x</mi>
    <mi>b</mi></msub> <mo>→</mo></mover></mrow></math> , calculate the result’s <math
    alttext="l squared"><msup><mi>l</mi> <mn>2</mn></msup></math> norm, add, and divide
    by *b*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Normalize each of <math alttext="ModifyingAbove x 1 With right-arrow comma
    ModifyingAbove x 2 With right-arrow comma ellipsis comma ModifyingAbove x Subscript
    b Baseline With right-arrow"><mrow><mover accent="true"><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><msub><mi>x</mi> <mn>2</mn></msub>
    <mo>→</mo></mover> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <mover accent="true"><msub><mi>x</mi>
    <mi>b</mi></msub> <mo>→</mo></mover></mrow></math> by subtracting the mean and
    dividing by the square root of the variance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scale and shift by trainable parameters that can be initialized and learned
    by gradient descent, the same way the weights of the training function are learned.
    This becomes the input to the first hidden layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do the same for the input of each of the subsequent layers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat for the next batch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*During testing and prediction*, there is no batch of data to train on, and
    the parameters at each layer are already learned. The batch normalization step,
    however, is already incorporated into the formula of the training function. During
    training, we were changing these *per batch* of training data. This in turn was
    changing the formula of the loss function slightly per batch. However, the point
    of normalization was partly *not to change the formula of the loss function too
    much*, because that in turn would change the locations of its minima, and that
    would cause us to *forever chase a moving target*. Alright, we fixed that with
    batch normalization during training, and now we want to validate, test, and predict.
    Which mean vector and variance do we then use for a particular data point that
    we are testing/predicting at? Do we use the means and variances of the features
    of the original data set? We have to make such decisions.'
  prefs: []
  type: TYPE_NORMAL
- en: Control The Size Of The Weights By Penalizing Their Norm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another way to regularize the training function, in order to avoid overfitting
    the data, is to introduce a *competing term* into the minimization problem. Instead
    of solving for the set of weights <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> that minimizes *only* the loss
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript ModifyingAbove omega With right-arrow
    Endscripts upper L left-parenthesis ModifyingAbove omega With right-arrow right-parenthesis
    comma dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo>
    <mover accent="true"><mi>ω</mi> <mo>→</mo></mover></msub> <mi>L</mi> <mrow><mo>(</mo>
    <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>,</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'we introduce a new term <math alttext="alpha parallel-to ModifyingAbove omega
    With right-arrow parallel-to"><mrow><mrow><mi>α</mi> <mo>∥</mo></mrow> <mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover> <mrow><mo>∥</mo></mrow></mrow></math>
    and solve for the set of weights <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> that minimizes:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript ModifyingAbove omega With right-arrow
    Endscripts upper L left-parenthesis ModifyingAbove omega With right-arrow right-parenthesis
    plus alpha parallel-to ModifyingAbove omega With right-arrow parallel-to period
    dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo> <mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></msub> <mi>L</mi> <mrow><mo>(</mo>
    <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>+</mo>
    <mi>α</mi> <mrow><mo>∥</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mo>∥</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, for the mean squared error loss function usually used for regression
    problems, the minimization problem looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript ModifyingAbove omega With right-arrow
    Endscripts StartFraction 1 Over m EndFraction sigma-summation Underscript i equals
    1 Overscript m Endscripts StartAbsoluteValue y Subscript p r e d i c t Baseline
    left-parenthesis ModifyingAbove omega With right-arrow right-parenthesis minus
    y Subscript t r u e Baseline EndAbsoluteValue squared plus alpha parallel-to ModifyingAbove
    omega With right-arrow parallel-to dollar-sign"><mrow><msub><mo form="prefix"
    movablelimits="true">min</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover></msub>
    <mfrac><mn>1</mn> <mi>m</mi></mfrac> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>m</mi></msubsup> <mrow><mo>|</mo></mrow> <msub><mi>y</mi> <mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi></mrow></msub>
    <mrow><mo>(</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>-</mo> <msub><mi>y</mi> <mrow><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub>
    <msup><mrow><mo>|</mo></mrow> <mn>2</mn></msup> <mo>+</mo> <mi>α</mi> <mrow><mo>∥</mo>
    <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>∥</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that so far we have established two ways to solve the above minimization
    problem:'
  prefs: []
  type: TYPE_NORMAL
- en: The minimum happens at points where the derivative (gradient) is equal to zero
  prefs: []
  type: TYPE_NORMAL
- en: 'So the minimizing <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> must satisfy <math alttext="normal
    nabla upper L left-parenthesis ModifyingAbove omega With right-arrow right-parenthesis
    plus alpha normal nabla left-parenthesis parallel-to ModifyingAbove omega With
    right-arrow parallel-to right-parenthesis equals 0"><mrow><mi>∇</mi> <mi>L</mi>
    <mrow><mo>(</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>+</mo> <mrow><mi>α</mi> <mi>∇</mi> <mo>(</mo> <mo>∥</mo></mrow> <mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mrow><mo>∥</mo> <mo>)</mo></mrow> <mo>=</mo> <mn>0</mn></mrow></math>
    . Then we solve this equation for <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> if we have the luxury to get
    a *closed form* for the solution. In the case of linear regression (which we can
    think about as an extremely simplified neural network, with only one layer and
    zero nonlinear activation function), we do have this luxury, and for this *regularized*
    case the formula for the minimizing <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ModifyingAbove omega With right-arrow equals left-parenthesis
    upper X Superscript t Baseline upper X plus alpha upper B right-parenthesis Superscript
    negative 1 Baseline upper X Superscript t Baseline ModifyingAbove y With right-arrow
    Subscript t r u e Baseline comma dollar-sign"><mrow><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mo>=</mo> <msup><mrow><mo>(</mo><msup><mi>X</mi> <mi>t</mi></msup>
    <mi>X</mi><mo>+</mo><mi>α</mi><mi>B</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi>X</mi> <mi>t</mi></msup> <msub><mover accent="true"><mi>y</mi> <mo>→</mo></mover>
    <mrow><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub> <mo>,</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'where the columns of X are the feature columns of the data augmented with a
    vector of ones and B is the identity matrix (if we use ridge regression, discussed
    below). *The closed form solution for the extremely simple linear regression problem
    with regularization helps us appreciate weight decay type regularization and see
    the important role it plays*: Instead of inverting the matrix <math alttext="left-parenthesis
    upper X Superscript t Baseline upper X right-parenthesis"><mrow><mo>(</mo> <msup><mi>X</mi>
    <mi>t</mi></msup> <mi>X</mi> <mo>)</mo></mrow></math> in the *unregularized* solution
    and worrying about its ill-conditioning (for example, from highly correlated input
    features) and the resulting instabilities, we invert <math alttext="left-parenthesis
    upper X Superscript t Baseline upper X plus alpha upper B right-parenthesis"><mrow><mo>(</mo>
    <msup><mi>X</mi> <mi>t</mi></msup> <mi>X</mi> <mo>+</mo> <mi>α</mi> <mi>B</mi>
    <mo>)</mo></mrow></math> in the *regularized* solution. Adding this <math alttext="alpha
    upper B"><mrow><mi>α</mi> <mi>B</mi></mrow></math> term is equivalent to adding
    a small positive term to the denominator of a scalar number that helps us avoid
    division by zero: Instead of using <math alttext="1 slash x"><mrow><mn>1</mn>
    <mo>/</mo> <mi>x</mi></mrow></math> where *x* runs the risk of being zero, we
    use <math alttext="1 slash left-parenthesis x plus alpha right-parenthesis"><mrow><mn>1</mn>
    <mo>/</mo> <mo>(</mo> <mi>x</mi> <mo>+</mo> <mi>α</mi> <mo>)</mo></mrow></math>
    where <math alttext="alpha"><mi>α</mi></math> is a positive constant. Recall that
    matrix inversion is the analogue of scalar number division.'
  prefs: []
  type: TYPE_NORMAL
- en: Gradient Descent
  prefs: []
  type: TYPE_NORMAL
- en: We use gradient descent or any of its variations, such as stochastic gradient
    descent, when we do not have the luxury of obtaining closed form solutions for
    the derivative equals zero equation, and when our problem is very large that computing
    second order derivatives is extremely expensive.
  prefs: []
  type: TYPE_NORMAL
- en: Commonly used weight decay regularizations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are three popular regularizations that control the size of the weights
    that we are forever searching for in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Ridge regression*: Penalize the <math alttext="l squared"><msup><mi>l</mi>
    <mn>2</mn></msup></math> norm of <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> . In this case, we add the
    term <math alttext="alpha sigma-summation Underscript i equals 1 Overscript n
    Endscripts StartAbsoluteValue omega Subscript i Baseline EndAbsoluteValue squared"><mrow><mi>α</mi>
    <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <msup><mrow><mo>|</mo><msub><mi>ω</mi> <mi>i</mi></msub> <mo>|</mo></mrow> <mn>2</mn></msup></mrow></math>
    to the loss function then we minimize.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Lasso regression*: Penalize the <math alttext="l Superscript 1"><msup><mi>l</mi>
    <mn>1</mn></msup></math> norm of the <math alttext="omega"><mi>ω</mi></math> ’s.
    In this case, we add the term <math alttext="alpha sigma-summation Underscript
    i equals 1 Overscript n Endscripts StartAbsoluteValue omega Subscript i Baseline
    EndAbsoluteValue"><mrow><mi>α</mi> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <mrow><mo>|</mo> <msub><mi>ω</mi> <mi>i</mi></msub> <mo>|</mo></mrow></mrow></math>
    to the loss function then we minimize.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Elastic net*: This is a middle ground case between Ridge and Lasso regressions.
    We introduce one additional hyper-parameter <math alttext="gamma"><mi>γ</mi></math>
    which can take any value between zero and one, and add a term to the loss function
    that combines both Ridge and Lasso regressions through <math alttext="gamma"><mi>γ</mi></math>
    : <math alttext="gamma alpha sigma-summation Underscript i equals 1 Overscript
    n Endscripts StartAbsoluteValue omega Subscript i Baseline EndAbsoluteValue squared
    plus left-parenthesis 1 minus gamma right-parenthesis alpha sigma-summation Underscript
    i equals 1 Overscript n Endscripts StartAbsoluteValue omega Subscript i Baseline
    EndAbsoluteValue"><mrow><mi>γ</mi> <mi>α</mi> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <mrow><mo>|</mo></mrow> <msub><mi>ω</mi> <mi>i</mi></msub>
    <msup><mrow><mo>|</mo></mrow> <mn>2</mn></msup> <mo>+</mo> <mrow><mo>(</mo> <mn>1</mn>
    <mo>-</mo> <mi>γ</mi> <mo>)</mo></mrow> <mi>α</mi> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <mrow><mo>|</mo> <msub><mi>ω</mi> <mi>i</mi></msub> <mo>|</mo></mrow></mrow></math>
    . When <math alttext="gamma equals 0"><mrow><mi>γ</mi> <mo>=</mo> <mn>0</mn></mrow></math>
    this becomes Lasso regression, when it is equal to one it is Ridge regression,
    and when it is between zero and one it is some sort of a middle ground.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When do we use plain linear regression, Ridge, Lasso, or Elastic Net?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you are already confused and slightly overwhelmed by the multitude of choices
    that are available for building machine learning models, join the club, but do
    not get frustrated. Until the mathematical analysis that tells us exactly which
    choices are better than others and under what circumstances becomes available
    (or catches us with mathematical computation and experimentation), think about
    the enormity of available choices the same way you think about a home renovation:
    We have to choose from many available materials, designs, and architectures to
    produce a final product. This is a home renovation, not a home decoration, so
    our decisions are fateful and more consequential than a mere home decoration.
    They do affect the *quality* and the *function* of our final product, but they
    are choices nevertheless. Rest easy, there is more than one way to skin AI:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some regularization is always good: Adding a term that controls the sizes of
    the weights and competes with minimizing the loss function is good in general.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ridge regression is usually a good choice because the <math alttext="l squared"><msup><mi>l</mi>
    <mn>2</mn></msup></math> norm is differentiable. Minimizing this is more stable
    than minimizing the <math alttext="l Superscript 1"><msup><mi>l</mi> <mn>1</mn></msup></math>
    norm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we decide to go with the <math alttext="l Superscript 1"><msup><mi>l</mi>
    <mn>1</mn></msup></math> norm, even though it is not differentiable at 0, we can
    define its sub-differential or sub-gradient at zero to be zero (f(x)= <math alttext="StartAbsoluteValue
    x EndAbsoluteValue"><mrow><mo>|</mo> <mi>x</mi> <mo>|</mo></mrow></math> is differentiable
    when <math alttext="x not-equals 0"><mrow><mi>x</mi> <mo>≠</mo> <mn>0</mn></mrow></math>
    . It has derivative 1 when x>0 and -1 when x<0).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we suspect only few features are useful, then it is good to use either Lasso
    or Elastic Net as a data preprocessing step, to kill off the less important features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Elastic Net is usually preferred over Lasso because Lasso might behave badly
    when the number of features is greater than the number of training instances or
    when several features are strongly correlated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Penalizing The <math alttext="l squared"><msup><mi>l</mi> <mn>2</mn></msup></math>
    Norm *vs* Penalizing the <math alttext="l Superscript 1"><msup><mi>l</mi> <mn>1</mn></msup></math>
    Norm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our goal is to find <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> that solves the minimization:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript ModifyingAbove omega With right-arrow
    Endscripts upper L left-parenthesis ModifyingAbove omega With right-arrow comma
    ModifyingAbove omega 0 With right-arrow right-parenthesis plus alpha parallel-to
    ModifyingAbove omega With right-arrow parallel-to period dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover></msub>
    <mi>L</mi> <mrow><mo>(</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mo>,</mo> <mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>+</mo> <mi>α</mi> <mrow><mo>∥</mo> <mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mo>∥</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The first term wants to decrease the loss <math alttext="upper L left-parenthesis
    ModifyingAbove omega With right-arrow comma ModifyingAbove omega 0 With right-arrow
    right-parenthesis"><mrow><mi>L</mi> <mo>(</mo> <mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> . The other term wants to decrease
    the values of the coordinates of <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> , all the way to zeros. The
    type of the norm that we choose for <math alttext="parallel-to ModifyingAbove
    omega With right-arrow parallel-to"><mrow><mrow><mo>∥</mo></mrow> <mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mrow><mo>∥</mo></mrow></mrow></math> determines the path <math
    alttext="ModifyingAbove omega With right-arrow"><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover></math> follows on its way to <math alttext="ModifyingAbove
    0 With right-arrow"><mover accent="true"><mn>0</mn> <mo>→</mo></mover></math>
    . * If we use the <math alttext="l Superscript 1"><msup><mi>l</mi> <mn>1</mn></msup></math>
    norm, the coordinates of <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> will decrease, however, a lot
    of them might encounter premature death, hitting zero before others. That is,
    the <math alttext="l Superscript 1"><msup><mi>l</mi> <mn>1</mn></msup></math>
    norm encourages sparsity: When a weight dies, it kills the contribution of the
    associated feature to the training function. The plot on the right in [Figure 4-13](#Fig_l1_vs_l2)
    shows the diamond shaped level sets of <math alttext="parallel-to ModifyingAbove
    omega With right-arrow parallel-to equals StartAbsoluteValue omega 1 EndAbsoluteValue
    plus StartAbsoluteValue omega 2 EndAbsoluteValue"><mrow><mrow><mo>∥</mo></mrow>
    <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <msub><mrow><mo>∥</mo></mrow>
    <msup><mi>l</mi> <mn>1</mn></msup></msub> <mrow><mo>=</mo> <mo>|</mo></mrow> <msub><mi>ω</mi>
    <mn>1</mn></msub> <mrow><mo>|</mo> <mo>+</mo> <mo>|</mo></mrow> <msub><mi>ω</mi>
    <mn>2</mn></msub> <mrow><mo>|</mo></mrow></mrow></math> in two dimensions (if
    we only had two features), namely, <math alttext="StartAbsoluteValue omega 1 EndAbsoluteValue
    plus StartAbsoluteValue omega 2 EndAbsoluteValue equals c"><mrow><mrow><mo>|</mo></mrow>
    <msub><mi>ω</mi> <mn>1</mn></msub> <mrow><mo>|</mo> <mo>+</mo> <mo>|</mo></mrow>
    <msub><mi>ω</mi> <mn>2</mn></msub> <mrow><mo>|</mo> <mo>=</mo> <mi>c</mi></mrow></mrow></math>
    for various values of *c*. If a minimization algorithm follows the path of steepest
    descent, such as the gradient descent, then we must travel in the direction perpendicular
    to the level sets, and as the arrow shows in the plot, <math alttext="omega 2"><msub><mi>ω</mi>
    <mn>2</mn></msub></math> becomes zero pretty fast since going perpendicular to
    the diamond shaped level sets is bound to hit one of the coordinate axes, effectively
    killing the respective feature. <math alttext="omega 1"><msub><mi>ω</mi> <mn>1</mn></msub></math>
    then travels to zero along the horizontal axis.'
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_0413.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-13\. The plot on the left shows the circular level sets of the <math
    alttext="l squared"><msup><mi>l</mi> <mn>2</mn></msup></math> norm of <math alttext="ModifyingAbove
    omega With right-arrow"><mover accent="true"><mi>ω</mi> <mo>→</mo></mover></math>
    , along with the direction the gradient descent follows towards the minimum at
    <math alttext="left-parenthesis 0 comma 0 right-parenthesis"><mrow><mo>(</mo>
    <mn>0</mn> <mo>,</mo> <mn>0</mn> <mo>)</mo></mrow></math> . The plot on the left
    shows the diamond shaped level sets of the <math alttext="l Superscript 1"><msup><mi>l</mi>
    <mn>1</mn></msup></math> norm of <math alttext="ModifyingAbove omega With right-arrow"><mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover></math> , along with the direction
    the gradient descent follows towards the minimum at <math alttext="left-parenthesis
    0 comma 0 right-parenthesis"><mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <mn>0</mn>
    <mo>)</mo></mrow></math> .
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If we use the <math alttext="l squared"><msup><mi>l</mi> <mn>2</mn></msup></math>
    norm, the weights’ sizes get smaller without necessarily killing them. The plot
    on the left in [Figure 4-13](#Fig_l1_vs_l2) shows the circular shaped level sets
    of <math alttext="parallel-to ModifyingAbove omega With right-arrow parallel-to
    equals omega 1 squared plus omega 2 squared"><mrow><mrow><mo>∥</mo></mrow> <mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover> <msub><mrow><mo>∥</mo></mrow> <msup><mi>l</mi>
    <mn>2</mn></msup></msub> <mo>=</mo> <msubsup><mi>ω</mi> <mn>1</mn> <mn>2</mn></msubsup>
    <mo>+</mo> <msubsup><mi>ω</mi> <mn>2</mn> <mn>2</mn></msubsup></mrow></math> in
    two dimensions, namely, <math alttext="omega 1 squared plus omega 2 squared equals
    c"><mrow><msubsup><mi>ω</mi> <mn>1</mn> <mn>2</mn></msubsup> <mo>+</mo> <msubsup><mi>ω</mi>
    <mn>2</mn> <mn>2</mn></msubsup> <mo>=</mo> <mi>c</mi></mrow></math> for various
    values of *c*. We see that following the path perpendicular to the circular level
    sets towards the minimum at <math alttext="left-parenthesis 0 comma 0 right-parenthesis"><mrow><mo>(</mo>
    <mn>0</mn> <mo>,</mo> <mn>0</mn> <mo>)</mo></mrow></math> decreases the values
    of both <math alttext="omega 1"><msub><mi>ω</mi> <mn>1</mn></msub></math> and
    <math alttext="omega 2"><msub><mi>ω</mi> <mn>2</mn></msub></math> without either
    of them becoming zero before the other.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which norm to choose depends on our use cases. Note that in all cases, we do
    not regularize the bias weights <math alttext="ModifyingAbove omega 0 With right-arrow"><mover
    accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover></math> . This
    is why in this section we wrote them separately in the loss function <math alttext="upper
    L left-parenthesis ModifyingAbove omega With right-arrow comma ModifyingAbove
    omega 0 With right-arrow right-parenthesis"><mrow><mi>L</mi> <mo>(</mo> <mover
    accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>,</mo> <mover accent="true"><msub><mi>ω</mi>
    <mn>0</mn></msub> <mo>→</mo></mover> <mo>)</mo></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: Explaining The Role Of The Regularization Hyper-parameter <math alttext="alpha"><mi>α</mi></math>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The minimization problem with weight decay regularization looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript ModifyingAbove omega With right-arrow
    Endscripts upper L left-parenthesis ModifyingAbove omega With right-arrow right-parenthesis
    plus alpha parallel-to ModifyingAbove omega With right-arrow parallel-to dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover></msub>
    <mi>L</mi> <mrow><mo>(</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>+</mo> <mi>α</mi> <mrow><mo>∥</mo> <mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mo>∥</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand the role of the regularization hyper-parameter <math alttext="alpha"><mi>α</mi></math>
    , we observe the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a competition between the first term, where the loss function <math
    alttext="upper L left-parenthesis ModifyingAbove omega With right-arrow right-parenthesis"><mrow><mi>L</mi>
    <mo>(</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    chooses <math alttext="omega"><mi>ω</mi></math> ’s that fit the training function
    to the training data, and the second term that just cares about making the <math
    alttext="omega"><mi>ω</mi></math> values small. These two objectives are not necessarily
    in sync: The values of <math alttext="omega"><mi>ω</mi></math> ’s that make the
    first term smaller might make the second term bigger and vice-versa.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If <math alttext="alpha"><mi>α</mi></math> is big, then the minimization process
    will compensate by making values of <math alttext="omega"><mi>ω</mi></math> ’s
    very small, regardless of whether these small values of <math alttext="omega"><mi>ω</mi></math>
    ’s will make the first term small as well. So the more we increase <math alttext="alpha"><mi>α</mi></math>
    , the more important minimizing the second term becomes than the first term, so
    our ultimate model might end up not fitting the data perfectly (high bias), but
    this is sometimes desired (low variance) so that it generalizes well to unseen
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If on the other hand <math alttext="alpha"><mi>α</mi></math> is small (say close
    to zero), then we can choose larger <math alttext="omega"><mi>ω</mi></math> values,
    and minimizing the first term becomes more important. Here, the minimization process
    will result in <math alttext="omega"><mi>ω</mi></math> values that make the first
    term happy, so the data will fit into the model nicely (low bias) but the variance
    might be high. In this case, our model would work well on seen data (it is designed
    to fit it nicely through minimizing <math alttext="upper L left-parenthesis ModifyingAbove
    omega With right-arrow right-parenthesis"><mrow><mi>L</mi> <mo>(</mo> <mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> ), but might not generalize well to
    unseen data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As <math alttext="alpha right-arrow 0"><mrow><mi>α</mi> <mo>→</mo> <mn>0</mn></mrow></math>
    , we can prove mathematically that the solution of the regularized problem converges
    to the solution of the un-regularized problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyper-parameter Examples That Appear In Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have now encountered many hyper-parameters that enter machine learning models.
    It is good practice to list the ones that enter our particular model along with
    their values. Let’s list the ones we have come across and recall that tuning these
    enhances the performance of our models. Most of the time, there are pre-recommended
    values for us to use. These are usually implemented as default values in machine
    learning libraries and software packages. However, it is always good to experiment
    with different values during the validation stage of our modeling process, given
    that we have the available time and resources.
  prefs: []
  type: TYPE_NORMAL
- en: The learning rate in gradient descent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weight decay coefficients such as the ones that appear in Ridge, Lasso and Elastic
    Net regularizations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of epochs before we stop training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sizes of data split into training, validation, and testing subsets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sizes of mini-batches during stochastic gradient descent and its variants.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The acceleration coefficients in momentum methods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The architecture of a neural network: number of layers, number of neurons in
    each layer, what happens at each layer (batch normalization, type of activation
    function), type of regularization (dropout, ridge, lasso), type of network (feedforward,
    dense, convolutional, adversarial, recurrent), type of loss functions, *etc.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chain Rule And Back-Propagation: Calculating <math alttext="normal nabla upper
    L left-parenthesis ModifyingAbove omega With right-arrow Superscript i Baseline
    right-parenthesis"><mrow><mi>∇</mi> <mi>L</mi> <mo>(</mo> <msup><mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mi>i</mi></msup> <mo>)</mo></mrow></math>'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is time to get our hands dirty and compute something important: The gradient
    of the loss function, namely, <math alttext="normal nabla upper L left-parenthesis
    ModifyingAbove omega With right-arrow Superscript i Baseline right-parenthesis"><mrow><mi>∇</mi>
    <mi>L</mi> <mo>(</mo> <msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mi>i</mi></msup> <mo>)</mo></mrow></math> . Whether we decide to find our optimal
    weights using gradient descent, stochastic gradient descent, mini-batch gradient
    descent, or any other variant of gradient descent, there is no escape from calculating
    this quantity. Recall that the loss function includes in its formula the neural
    network’s training function, which in turn is made up of subsequent linear combinations
    and compositions with activation functions. This means that we have to use the
    chain rule. Cleverly. Back in Calculus, we only used the single variable chain
    rule for derivatives, but now, we somehow have to transition to a chain rule of
    several variables: Several, as in, sometimes billions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is the layered architecture of a neural network that forces us to pause
    and think: How exaclty are we going to compute this one derivative of the loss
    function. The work horse here is the *back-propagation* algorithm (also called
    *backward mode automatic differentiation*), and it is a powerful one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before writing formulas, let’s summarize the steps that we follow as we train
    a neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The training function is a function of <math alttext="ModifyingAbove omega
    With right-arrow"><mover accent="true"><mi>ω</mi> <mo>→</mo></mover></math> ,
    so the outcome of the neural network after a data point passes through it, which
    is the same as evaluating the training function at the data point, is: <math alttext="o
    u t c o m e equals f u n c t i o n left-parenthesis ModifyingAbove omega With
    right-arrow right-parenthesis"><mrow><mi>o</mi> <mi>u</mi> <mi>t</mi> <mi>c</mi>
    <mi>o</mi> <mi>m</mi> <mi>e</mi> <mo>=</mo> <mi>f</mi> <mi>u</mi> <mi>n</mi> <mi>c</mi>
    <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>(</mo> <mover accent="true"><mi>ω</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> . This is made up of linear combinations
    of node outputs followed by compositions with activation functions, repeated over
    all of the network’s layers. The output layer might or might not have an activation
    function and could have one node or multiple nodes, depending on the ultimate
    task of the network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The loss function provides a measure of how badly the outcome of the training
    function diverged from what is true.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We initialize our learning function with a *random* set of weights <math alttext="ModifyingAbove
    omega With right-arrow Superscript 0"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mn>0</mn></msup></math> , according to preferred initialization rules prescribed
    in the previous sections. Then we compute the loss, or error that we committed
    because of using these particular weight values. *This is the forward pass of
    the data point through the net*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want to move to the next set of weights <math alttext="ModifyingAbove omega
    With right-arrow Superscript 1"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mn>1</mn></msup></math> that gives a lower error. We move in the direction opposite
    to the gradient vector of the loss function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'BUT: The training function is built into the loss function, and given the layered
    structure of this function, which comes from the architechture of the neural network,
    along with its high dimensionality, how do we efficiently perform the multivariable
    chain rule in order to find the gradient and evaluate it at the current set of
    weights?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The answer is that we send the data point back through the network, computing
    the gradient *backwards* from the output layer all the way to the input layer,
    evaluating along the way *how each node contributed to the error*. In essence,
    we compute <math alttext="StartFraction normal partial-differential upper L Over
    normal partial-differential node functions EndFraction"><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><mtext>node</mtext><mtext>functions</mtext></mrow></mfrac></math>
    , *then we tweak the weights accordingly*, updating them from <math alttext="ModifyingAbove
    omega With right-arrow Superscript 0"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover>
    <mn>0</mn></msup></math> to <math alttext="ModifyingAbove omega With right-arrow
    Superscript 1"><msup><mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mn>1</mn></msup></math>
    . The process continues as we pass more data points into the network, usually
    in batches. One *epoch* is then counted each time the network has *seen* the full
    training set.
  prefs: []
  type: TYPE_NORMAL
- en: Back-Propagation Is Not Too Different From How Our Brain Learns
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When we encounter a new math concept, the neurons in our brain make certain
    connections. The next time we see the same concept, the same neurons connect better.
    The analogy for our neural network is that the value <math alttext="omega"><mi>ω</mi></math>
    of the edge connecting the neurons increases. When we see the same concept again
    and again, it becomes part of our brain’s model. This model will not change, unless
    we learn new information that undoes the previous information. In that case, the
    connection between the neurons weakens. For our neural network, the <math alttext="omega"><mi>ω</mi></math>
    value connecting the neurons decreases. Tweaking the <math alttext="omega"><mi>ω</mi></math>
    ’s via minimizing the loss function accomplishes exactly that: *Establishing the
    correct connections between the neurons*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The brain neuroscientist Donald Hebb mentions in his 1949 book (paraphrased):
    *When a biological neuron triggers another neuron often, the connection between
    these two neurons grows stronger. In other words, cells that fire together, wire
    together.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, a neural network’s computational model takes into account the error
    made by the network when it produces an outcome: Since computers only understand
    numbers, the <math alttext="omega"><mi>ω</mi></math> of an edge increases if the
    node contributes to lowering the error, and decsreases if the node contributes
    to increasing the error function. So a neural network’s learning rule reinforces
    the connections that reduce the error by increasing the corresponding <math alttext="omega"><mi>ω</mi></math>
    ’s, and weakens the connections that increase the error by decreasing the corresponding
    <math alttext="omega"><mi>ω</mi></math> ’s.'
  prefs: []
  type: TYPE_NORMAL
- en: Why It Is Better To Back-Propagate?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Back-propagation computes the derivative of the training function with respect
    to each node, moving *backwards* through the network. This measures the contribution
    of each node to both the training function and the loss function <math alttext="upper
    L left-parenthesis ModifyingAbove omega With right-arrow right-parenthesis"><mrow><mi>L</mi>
    <mo>(</mo> <mover accent="true"><mi>ω</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    .
  prefs: []
  type: TYPE_NORMAL
- en: 'The most important formula to recall here is: *The chain rule from Calculus*.
    This calculates the derivatives of *chained* functions (or function compositions).
    Calculus’s chain rule mostly dealt with functions depending only on one variable
    <math alttext="omega"><mi>ω</mi></math> , for example, for three chained functions,
    the derivative with respect to <math alttext="omega"><mi>ω</mi></math> is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartFraction d Over d omega EndFraction f 3 left-parenthesis
    f 2 left-parenthesis f 1 left-parenthesis omega right-parenthesis right-parenthesis
    right-parenthesis equals StartSet StartFraction d Over d omega EndFraction f 1
    left-parenthesis omega right-parenthesis EndSet StartSet StartFraction d Over
    d f 1 EndFraction f 2 left-parenthesis f 1 left-parenthesis omega right-parenthesis
    right-parenthesis EndSet StartSet StartFraction d Over f 2 EndFraction f 3 left-parenthesis
    f 2 left-parenthesis f 1 left-parenthesis omega right-parenthesis right-parenthesis
    right-parenthesis EndSet dollar-sign"><mrow><mfrac><mi>d</mi> <mrow><mi>d</mi><mi>ω</mi></mrow></mfrac>
    <msub><mi>f</mi> <mn>3</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>2</mn></msub>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>ω</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mrow><mo>{</mo>
    <mfrac><mi>d</mi> <mrow><mi>d</mi><mi>ω</mi></mrow></mfrac> <msub><mi>f</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <mi>ω</mi> <mo>)</mo></mrow> <mo>}</mo></mrow> <mrow><mo>{</mo>
    <mfrac><mi>d</mi> <mrow><mi>d</mi><msub><mi>f</mi> <mn>1</mn></msub></mrow></mfrac>
    <msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <mi>ω</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>}</mo></mrow>
    <mrow><mo>{</mo> <mfrac><mi>d</mi> <msub><mi>f</mi> <mn>2</mn></msub></mfrac>
    <msub><mi>f</mi> <mn>3</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>2</mn></msub>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>ω</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>}</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: For neural networks, we must apply the chain rule to the loss function that
    depends on matrices and vectors of variables *W* and <math alttext="ModifyingAbove
    omega 0 With right-arrow"><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub>
    <mo>→</mo></mover></math> . So we have to generalize the above rule to *a many
    variables chain rule*. The easiest way to do this is to follow the structure of
    the network computing the derivatives backwards, from the outcome layer all the
    way back to the input layer.
  prefs: []
  type: TYPE_NORMAL
- en: If instead we decide to compute the derivatives forward through the network,
    we would not know whether these derivatives with respect to each variable will
    ultimately contribute to our final outcome because we do not know if they will
    connect through the graph of the network. Even when the graph is fully connected,
    the weights for deeper layers are not present in earlier layers, so it is a big
    waste to compute for their derivatives in the early layers.
  prefs: []
  type: TYPE_NORMAL
- en: When we compute the derivatives backward through the network, we start with
    the output and follow the edges of the graph of the network backwards, computing
    the derivatives at each node. Each node’s contribution is calculated only from
    the edges leading to it and edges going out of it. This is computationally much
    cheaper because now we are sure of how and when these nodes contribute to the
    network’s outcome.
  prefs: []
  type: TYPE_NORMAL
- en: 'In linear algebra, it is much cheaper to compute the multiplication of a matrix
    with a vector than computing the multiplication of two matrices together. We must
    always avoid multiplying two matrices with each other: Computing <math alttext="upper
    A left-parenthesis upper B bold v right-parenthesis"><mrow><mi>A</mi> <mo>(</mo>
    <mi>B</mi> <mi>𝐯</mi> <mo>)</mo></mrow></math> is cheaper than computing <math
    alttext="left-parenthesis upper A upper B right-parenthesis bold v"><mrow><mo>(</mo>
    <mi>A</mi> <mi>B</mi> <mo>)</mo> <mi>𝐯</mi></mrow></math> , even though in theory,
    these two are exactly the same. Over large matrices and vectors, this simple observation
    provides enormous cost savings.'
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation In Detail
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s pause and be thankful that software packages exist so that we never have
    to implement the following computation ourselves. Let’s also not forget to be
    grateful to the creators of these software packages. Now we compute.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a neural network with *h* hidden layers, we can write the loss function
    as a function of the training function which in turn is a function of all the
    weights that appear in the network:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper L equals upper L left-parenthesis g left-parenthesis
    upper W Superscript 1 Baseline comma ModifyingAbove omega 0 With right-arrow Superscript
    1 Baseline comma upper W squared comma ModifyingAbove omega 0 With right-arrow
    squared comma ellipsis comma upper W Superscript h Baseline comma ModifyingAbove
    omega 0 With right-arrow Superscript h Baseline comma upper W Superscript h plus
    1 Baseline comma ModifyingAbove omega 0 With right-arrow Superscript h plus 1
    Baseline right-parenthesis right-parenthesis dollar-sign"><mrow><mi>L</mi> <mo>=</mo>
    <mi>L</mi> <mo>(</mo> <mi>g</mi> <mrow><mo>(</mo> <msup><mi>W</mi> <mn>1</mn></msup>
    <mo>,</mo> <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover>
    <mn>1</mn></msup> <mo>,</mo> <msup><mi>W</mi> <mn>2</mn></msup> <mo>,</mo> <msup><mover
    accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover> <mn>2</mn></msup>
    <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msup><mi>W</mi> <mi>h</mi></msup> <mo>,</mo>
    <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover>
    <mi>h</mi></msup> <mo>,</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <mo>,</mo> <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover>
    <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup> <mo>)</mo></mrow> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: We will compute the partial derivatives of *L* backwards, starting with <math
    alttext="StartFraction normal partial-differential upper L Over normal partial-differential
    upper W Superscript h plus 1 Baseline EndFraction"><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mfrac></math>
    and <math alttext="StartFraction normal partial-differential upper L Over normal
    partial-differential ModifyingAbove omega 0 With right-arrow Superscript h plus
    1 Baseline EndFraction"><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow> <mrow><mi>∂</mi><msup><mover
    accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mfrac></math>
    and working our way back to <math alttext="StartFraction normal partial-differential
    upper L Over normal partial-differential upper W Superscript 1 Baseline EndFraction"><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><msup><mi>W</mi> <mn>1</mn></msup></mrow></mfrac></math> and <math
    alttext="StartFraction normal partial-differential upper L Over normal partial-differential
    ModifyingAbove omega 0 With right-arrow Superscript 1 Baseline EndFraction"><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub>
    <mo>→</mo></mover> <mn>1</mn></msup></mrow></mfrac></math> . Their derivatives
    are taken with respect to each entry in the corresponding matrix or vector.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose for simplicity, but without loss of generality, that the network is
    a regression network predicting a single numerical value, so that the training
    function *g* is scalar (not a vector). Suppose also that we use the same activation
    function *f* for each neuron throughout the network. The output neuron has no
    activation since this is a regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Derivatives with respect to the weights pointing to the output layer:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper L equals upper L left-parenthesis upper W Superscript
    h plus 1 Baseline ModifyingAbove s With right-arrow Superscript h Baseline plus
    omega 0 Superscript h plus 1 Baseline right-parenthesis dollar-sign"><mrow><mi>L</mi>
    <mo>=</mo> <mi>L</mi> <mo>(</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mi>h</mi></msup> <mo>+</mo>
    <msubsup><mi>ω</mi> <mn>0</mn> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup>
    <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: so that
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartFraction normal partial-differential upper L
    Over normal partial-differential omega 0 Superscript h plus 1 Baseline EndFraction
    equals 1 times upper L prime left-parenthesis upper W Superscript h plus 1 Baseline
    ModifyingAbove s With right-arrow Superscript h Baseline plus omega 0 Superscript
    h plus 1 Baseline right-parenthesis dollar-sign"><mrow><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><msubsup><mi>ω</mi> <mn>0</mn> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></mfrac>
    <mo>=</mo> <mn>1</mn> <mo>×</mo> <msup><mi>L</mi> <mo>'</mo></msup> <mrow><mo>(</mo>
    <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup> <msup><mover
    accent="true"><mi>s</mi> <mo>→</mo></mover> <mi>h</mi></msup> <mo>+</mo> <msubsup><mi>ω</mi>
    <mn>0</mn> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartFraction normal partial-differential upper L
    Over normal partial-differential upper W Superscript h plus 1 Baseline EndFraction
    equals left-parenthesis ModifyingAbove s With right-arrow Superscript h Baseline
    right-parenthesis Superscript t Baseline upper L prime left-parenthesis upper
    W Superscript h plus 1 Baseline ModifyingAbove s With right-arrow Superscript
    h Baseline plus omega 0 Superscript h plus 1 Baseline right-parenthesis period
    dollar-sign"><mrow><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow> <mrow><mi>∂</mi><msup><mi>W</mi>
    <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mfrac> <mo>=</mo> <msup><mrow><mo>(</mo><msup><mover
    accent="true"><mi>s</mi> <mo>→</mo></mover> <mi>h</mi></msup> <mo>)</mo></mrow>
    <mi>t</mi></msup> <msup><mi>L</mi> <mo>'</mo></msup> <mrow><mo>(</mo> <msup><mi>W</mi>
    <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup> <msup><mover accent="true"><mi>s</mi>
    <mo>→</mo></mover> <mi>h</mi></msup> <mo>+</mo> <msubsup><mi>ω</mi> <mn>0</mn>
    <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup> <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Recall that <math alttext="ModifyingAbove s With right-arrow Superscript h"><msup><mover
    accent="true"><mi>s</mi> <mo>→</mo></mover> <mi>h</mi></msup></math> is the output
    of the last layer, so it depends on all the weights of the previous layers, namely,
    <math alttext="left-parenthesis upper W Superscript 1 Baseline comma ModifyingAbove
    omega 0 With right-arrow Superscript 1 Baseline comma upper W squared comma ModifyingAbove
    omega 0 With right-arrow squared comma ellipsis comma upper W Superscript h Baseline
    comma ModifyingAbove omega 0 With right-arrow Superscript h Baseline right-parenthesis"><mrow><mo>(</mo>
    <msup><mi>W</mi> <mn>1</mn></msup> <mo>,</mo> <msup><mover accent="true"><msub><mi>ω</mi>
    <mn>0</mn></msub> <mo>→</mo></mover> <mn>1</mn></msup> <mo>,</mo> <msup><mi>W</mi>
    <mn>2</mn></msup> <mo>,</mo> <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub>
    <mo>→</mo></mover> <mn>2</mn></msup> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msup><mi>W</mi>
    <mi>h</mi></msup> <mo>,</mo> <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub>
    <mo>→</mo></mover> <mi>h</mi></msup> <mo>)</mo></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: Derivatives with respect to the weights pointing to the last hidden layer
  prefs: []
  type: TYPE_NORMAL
- en: 'To compute these, we show them explicitly in the formula of the loss function:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper L equals upper L left-parenthesis upper W Superscript
    h plus 1 Baseline left-parenthesis f left-parenthesis upper W Superscript h Baseline
    ModifyingAbove s With right-arrow Superscript h minus 1 Baseline plus ModifyingAbove
    omega 0 With right-arrow Superscript h Baseline right-parenthesis right-parenthesis
    plus omega 0 Superscript h plus 1 Baseline right-parenthesis dollar-sign"><mrow><mi>L</mi>
    <mo>=</mo> <mi>L</mi> <mo>(</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <mrow><mo>(</mo> <mi>f</mi> <mrow><mo>(</mo> <msup><mi>W</mi> <mi>h</mi></msup>
    <msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow></msup>
    <mo>+</mo> <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover>
    <mi>h</mi></msup> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>+</mo> <msubsup><mi>ω</mi>
    <mn>0</mn> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: so that
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartFraction normal partial-differential upper L
    Over normal partial-differential ModifyingAbove omega 0 With right-arrow Superscript
    h Baseline EndFraction equals ModifyingAbove 1 With right-arrow left-parenthesis
    upper W Superscript h plus 1 Baseline f prime left-parenthesis upper W Superscript
    h Baseline ModifyingAbove s With right-arrow Superscript h minus 1 Baseline plus
    ModifyingAbove omega 0 With right-arrow Superscript h Baseline right-parenthesis
    right-parenthesis upper L prime left-parenthesis upper W Superscript h plus 1
    Baseline left-parenthesis f left-parenthesis upper W Superscript h Baseline ModifyingAbove
    s With right-arrow Superscript h minus 1 Baseline plus ModifyingAbove omega 0
    With right-arrow Superscript h Baseline right-parenthesis right-parenthesis plus
    omega 0 Superscript h plus 1 Baseline right-parenthesis dollar-sign"><mrow><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub>
    <mo>→</mo></mover> <mi>h</mi></msup></mrow></mfrac> <mo>=</mo> <mover accent="true"><mn>1</mn>
    <mo>→</mo></mover> <mrow><mo>(</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <msup><mi>f</mi> <mo>'</mo></msup> <mrow><mo>(</mo> <msup><mi>W</mi> <mi>h</mi></msup>
    <msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow></msup>
    <mo>+</mo> <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover>
    <mi>h</mi></msup> <mo>)</mo></mrow> <mo>)</mo></mrow> <msup><mi>L</mi> <mo>'</mo></msup>
    <mrow><mo>(</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <mrow><mo>(</mo> <mi>f</mi> <mrow><mo>(</mo> <msup><mi>W</mi> <mi>h</mi></msup>
    <msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow></msup>
    <mo>+</mo> <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover>
    <mi>h</mi></msup> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>+</mo> <msubsup><mi>ω</mi>
    <mn>0</mn> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartFraction normal partial-differential upper L
    Over normal partial-differential upper W Superscript h Baseline EndFraction equals
    ModifyingAbove s With right-arrow Superscript h minus 1 Baseline left-parenthesis
    upper W Superscript h plus 1 Baseline f prime left-parenthesis upper W Superscript
    h Baseline ModifyingAbove s With right-arrow Superscript h minus 1 Baseline plus
    ModifyingAbove omega 0 With right-arrow Superscript h Baseline right-parenthesis
    right-parenthesis upper L prime left-parenthesis upper W Superscript h plus 1
    Baseline left-parenthesis f left-parenthesis upper W Superscript h Baseline ModifyingAbove
    s With right-arrow Superscript h minus 1 Baseline plus ModifyingAbove omega 0
    With right-arrow Superscript h Baseline right-parenthesis right-parenthesis plus
    omega 0 Superscript h plus 1 Baseline right-parenthesis dollar-sign"><mrow><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><msup><mi>W</mi> <mi>h</mi></msup></mrow></mfrac> <mo>=</mo> <msup><mover
    accent="true"><mi>s</mi> <mo>→</mo></mover> <mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow></msup>
    <mrow><mo>(</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <msup><mi>f</mi> <mo>'</mo></msup> <mrow><mo>(</mo> <msup><mi>W</mi> <mi>h</mi></msup>
    <msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow></msup>
    <mo>+</mo> <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover>
    <mi>h</mi></msup> <mo>)</mo></mrow> <mo>)</mo></mrow> <msup><mi>L</mi> <mo>'</mo></msup>
    <mrow><mo>(</mo> <msup><mi>W</mi> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msup>
    <mrow><mo>(</mo> <mi>f</mi> <mrow><mo>(</mo> <msup><mi>W</mi> <mi>h</mi></msup>
    <msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow></msup>
    <mo>+</mo> <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub> <mo>→</mo></mover>
    <mi>h</mi></msup> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>+</mo> <msubsup><mi>ω</mi>
    <mn>0</mn> <mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow></msubsup> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Recall that <math alttext="ModifyingAbove s With right-arrow Superscript h minus
    1"><msup><mover accent="true"><mi>s</mi> <mo>→</mo></mover> <mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow></msup></math>
    is the output of the hidden layer before the last hidden layer, so it depends
    on all the weights of the previous layers, namely, <math alttext="left-parenthesis
    upper W Superscript 1 Baseline comma ModifyingAbove omega 0 With right-arrow Superscript
    1 Baseline comma upper W squared comma ModifyingAbove omega 0 With right-arrow
    squared comma ellipsis comma upper W Superscript h minus 1 Baseline comma ModifyingAbove
    omega 0 With right-arrow Superscript h minus 1 Baseline right-parenthesis"><mrow><mo>(</mo>
    <msup><mi>W</mi> <mn>1</mn></msup> <mo>,</mo> <msup><mover accent="true"><msub><mi>ω</mi>
    <mn>0</mn></msub> <mo>→</mo></mover> <mn>1</mn></msup> <mo>,</mo> <msup><mi>W</mi>
    <mn>2</mn></msup> <mo>,</mo> <msup><mover accent="true"><msub><mi>ω</mi> <mn>0</mn></msub>
    <mo>→</mo></mover> <mn>2</mn></msup> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msup><mi>W</mi>
    <mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow></msup> <mo>,</mo> <msup><mover accent="true"><msub><mi>ω</mi>
    <mn>0</mn></msub> <mo>→</mo></mover> <mrow><mi>h</mi><mo>-</mo><mn>1</mn></mrow></msup>
    <mo>)</mo></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: We continue the process systematically until we reach the input layer.
  prefs: []
  type: TYPE_NORMAL
- en: Assessing The Significance Of The Features Of The Input Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One goal of data analysts is to assess the significance of the input variables
    (data features) with respect to the output or target variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main question to answer here is: *If we tweak the value of a certain input
    variable, what is the relative change of the output?*'
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we add one more bus on a given bus route, would that affect
    the overall bus ridership?
  prefs: []
  type: TYPE_NORMAL
- en: 'The math question that we are asking is a *derivative* question: Find the partial
    derivative of the output with respect to the input variable in question.'
  prefs: []
  type: TYPE_NORMAL
- en: We have plenty of literature in statistics on variable significance when the
    models are linear (sensitivity analysis). When the models are nonlinear, such
    as our neural network models, there isn’t as much literature. We cannot make our
    predictions based on nonlinear models then employ variable significance analysis
    that’s built for linear models. Many data analysts who use built in software packages
    for their analysis fall into this trap. This is another reason to seek to understand
    deeply the assumptions of the models that we base our business decisions on.
  prefs: []
  type: TYPE_NORMAL
- en: Summary And Looking Ahead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter represents our official transition to the deep learning era in
    the AI field. While [Chapter 3](ch03.xhtml#ch03) presented traditional yet still
    very useful machine learning models, [Chapter 4](#ch04) adds neural networks to
    our arsenal of machine learning models. Both chapters built the models with the
    general mathematical structure of: Training function, loss function, and optimization,
    where each of these was tailored to the particular task and model at hand.'
  prefs: []
  type: TYPE_NORMAL
- en: By employing nonlinear activation functions at each neuron of a neural network,
    over multiple layers, our training function is able to pick up on complex features
    in the data that is otherwise hard to describe using an explicit formula of a
    nonlinear function. Mathematical analysis, in particular, universal approximation
    theorems for neural networks, back up this intuition and provide a theoretical
    background that justifies the wild success of neural networks. These theorems,
    however, still lack the ability to provide us with a map to construct special
    networks tailored to specific tasks and data sets, so we must experiment with
    various architectures, regularizations, hyperparameters, until we obtain a neural
    network model that performs well on new and unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks are well tailored for large problems with large data sets. The
    optimization task for such large problems requires efficient and computationally
    inexpensive methods, though all computations at that scale can be considered expensive.
    Stochastic gradient descent is the popular optimization method of choice, and
    the back-propagation algorithm is the work horse of this method. More specifically,
    the back-propagation algorithm computes the gradient of the loss function (or
    the objective function when we add weight decay regularization) at the current
    weight choice. Understanding the landscape of the objective function remains central
    for any optimization task, and as a rule of thumb, convex problems are easier
    to optimize than non-convex ones. Loss functions involved in neural network models
    are generally non-convex.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 4](#ch04) is the last foundational (and long) chapter in this book.
    We can finally discuss more specialized AI models, as well as deeper mathematics,
    when needed. The next chapters are independent from each other, so read them in
    the order that feels more relevant to your immediate application area.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s summarize the mathematics that appeared in this chapter, which
    we must elaborate more on as we progress in the field:'
  prefs: []
  type: TYPE_NORMAL
- en: Probability and measure
  prefs: []
  type: TYPE_NORMAL
- en: This is needed to prove universal approximation type theorems, and will be discussed
    in the probability chapter. It is also related to uncertainty analysis related
    to Dropout.
  prefs: []
  type: TYPE_NORMAL
- en: Statistics
  prefs: []
  type: TYPE_NORMAL
- en: Input standarizing steps during batch normalization at each layer of the neural
    network, and the resulting reshaping of the related distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent, stochastic gradient descent, convex and non-convex landscapes.
  prefs: []
  type: TYPE_NORMAL
- en: Calculus on Linear Algebra
  prefs: []
  type: TYPE_NORMAL
- en: 'Back-propagation algorithm: This is the chain rule from calculus applied on
    functions of matrices of variables.'
  prefs: []
  type: TYPE_NORMAL
