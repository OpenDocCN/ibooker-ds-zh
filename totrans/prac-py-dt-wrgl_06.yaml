- en: Chapter 6\. Assessing Data Quality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the past two chapters, we’ve focused our efforts on identifying and accessing
    different formats of data in different locations—from spreadsheets to websites.
    But getting our hands on (potentially) interesting data is really only the beginning.
    The next step is conducting a thorough quality assessment to understand if what
    we have is useful, salvageable, or just straight up garbage.
  prefs: []
  type: TYPE_NORMAL
- en: As you may have gleaned from reading [Chapter 3](ch03.html#chapter3), crafting
    quality data is a complex and time-consuming business. The process is roughly
    equal parts research, experimentation, and dogged perseverance. Most importantly,
    committing to data quality means that you have to be willing to invest significant
    amounts of time and energy—and *still be willing to throw it all out and start
    over* if, despite your best efforts, the data you have just can’t be brought up
    to par.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes down to it, in fact, that last criterion is probably what makes
    doing really high-quality, meaningful work with data truly difficult. The technical
    skills, as I hope you are already discovering, take some effort to master but
    are still highly achievable with sufficient practice. Research skills are a bit
    harder to document and convey, but working through the examples in this book will
    help you develop many of them, especially those related to the information discovery
    and collation needed for assessing and improving data quality.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to reconciling yourself to the fact that, after dozens of hours
    of work, you may need to “give up” on a dataset because its flaws are too deep
    or widespread, the only advice I can offer is that you try to remember that *learning
    meaningful things about the world is a “long game.”* That’s why I always suggest
    that folks interested in learning about how to do data wrangling and analysis
    start by identifying a question about the world that is truly interesting and/or
    important to them. To do this work well, you have to care *more* about getting
    it right than about getting it “done.” But it also helps if you truly value what
    you learn in the *process* of data wrangling—whether because you learn a new Python
    or data wrangling strategy or because you make contact with a new expert or discover
    a new information resource. In truth, the effort of doing good data work is never
    wasted if you really care about the topic you’re exploring. It’s just that it
    can lead you in a different direction than you expected.
  prefs: []
  type: TYPE_NORMAL
- en: Often, you will find that while a dataset cannot answer your original question,
    it can still shed light on some key aspect of it. Other times, you may find that
    there’s *no* data on the subject you’re exploring, and you may be able to leverage
    that fact to get help—discovering what data *doesn’t* exist may prompt you—and
    others—to change focus entirely. And since there will *never* be a “perfect” dataset,
    there are times when you may choose to *very carefully* share data that you know
    has flaws, because even the partial insight it offers has important public interest
    benefits. What matters in every case is that you are willing to personally take
    responsibility for the choices you make—because no matter what the “original”
    data was or where it came from, the cleaned, augmented, transformed, and/or analyzed
    dataset is still *yours*.
  prefs: []
  type: TYPE_NORMAL
- en: If this feels a little overwhelming—well, that’s not entirely an accident. We
    are living in a moment when it is too easy to wield powerful digital tools without
    considering their real-world consequences, and where the people building “advanced”
    technologies are writing the algorithmic rules largely in their own favor.^([1](ch06.html#idm45143406437120))
    In the end, data can be a mechanism for informing *and* manipulating, for explaining
    *and* exploiting. Ensuring which side of those lines your work falls on is ultimately
    up to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'But what does achieving data quality really mean in practice? To get a sense
    of this, we’ll spend the remainder of this chapter evaluating real-world data
    in terms of the aspects of data *integrity* and data *fit* introduced in [Chapter 3](ch03.html#chapter3).
    The dataset we’ll use for this is a single instance of loan data from the US Paycheck
    Protection Program (PPP), which contains information about millions of loans to
    small businesses during the COVID-19 pandemic. As we’ll encounter firsthand throughout
    the remainder of this chapter, the PPP data exemplifies many of the challenges
    common in “found” data, whether it is compiled by government agencies or private
    companies: unclear terms and unexplained changes from one version of the data
    to the next leave room for data *fit* issues that will require additional research
    to address. More straightforward (though not necessarily faster to resolve) are
    the data *integrity* issues—like confirming whether a given bank is spelled the
    same way throughout the dataset or that our data file(s) contain the values and
    time ranges they ought to. While we will find our way through most of these challenges,
    in the end our insights will be high confidence, *not* incontrovertible. As with
    all data work, they will be the cumulative result of informed decisions, logical
    reasoning, and a whole *lot* of data wrangling. To get that wrangling done, the
    Python library we’ll rely on most is *pandas*, which offers a popular and powerful
    set of tools for working with table-type data. Let’s get started!'
  prefs: []
  type: TYPE_NORMAL
- en: The Pandemic and the PPP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the spring of 2020, the US government announced a loan program designed to
    help stabilize the American economy in the face of job losses related to the COVID-19
    pandemic. With designated funding of nearly $1 trillion,^([2](ch06.html#idm45143406492528))
    the objective of the PPP was ostensibly to help small businesses pay rent and
    keep paying employees despite sometimes mandatory closures and other restrictions.
    Although a drop in unemployment appeared to follow the first roll-out of funds,
    some parts of the federal government seemed determined to resist calls for transparency
    about where the money had gone.^([3](ch06.html#idm45143406490368))
  prefs: []
  type: TYPE_NORMAL
- en: So did the PPP loans help save American small businesses? Now that some time
    has passed, one might imagine that would be a straightforward enough question
    to answer—but we’re here to find out for ourselves. To do that we’ll look at the
    data, of course, starting with a systematic assessment of its overall quality,
    in which we review our PPP loan data for each of the characteristics of data *integrity*
    and data *fit*, in turn. Just as importantly, we’re going to *carefully document*
    each part of this process so that we have a record of what we did, the choices
    we made, and the reasoning behind them. This data diary will be a crucial resource
    for us in the future, especially should we need to explain or reproduce any of
    our work. While you can use whatever form and format you prefer, I like to keep
    my formatting simple and have my data diary live near my code, so I’m going to
    document my work in a markdown file that I can easily back up to and read on GitHub.^([4](ch06.html#idm45143406483424))
    Since this file is really a running tally of everything I’m doing, I’m going to
    call it *ppp_process_log.md*.
  prefs: []
  type: TYPE_NORMAL
- en: Assessing Data Integrity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Should you begin your data wrangling process by assessing data integrity or
    data fit? Unsurprisingly: a little of both. As discussed in [“What Is “Data Wrangling”?”](ch01.html#describing_data_wrangling),
    you should never really start a data wrangling process unless you have some sort
    of question you’re looking to answer and some sense that a particular dataset
    can help you answer it—in other words, until you have some idea where your data
    wrangling process is going and that your data is “fit” for it. At the same time,
    fully assessing a dataset’s fit is often difficult until its integrity has been
    explored. For example, if there are gaps in the data, can they be filled in somehow?
    Can missing metadata be located? If so, then we may be able to resolve these integrity
    issues and return to the assessment of fit with more complete information. If
    we then find that we can improve the data’s fit by augmenting it (which we’ll
    explore in detail in [Chapter 7](ch07.html#chapter7)), of course, this will initiate
    *another* round of data integrity assessments. And then the cycle begins again.'
  prefs: []
  type: TYPE_NORMAL
- en: If you suspect that this will lead to an infinite loop of data wrangling, you’re
    not *entirely* wrong; all good questions will generate others, so there’s always
    more to learn. That said, the time, energy, and other resources we can dedicate
    to data wrangling are *not* infinite, which is why we have to make informed decisions
    and document them. Thoroughly assessing our data’s quality will help us make those
    decisions well. By methodically examining your data for integrity and fit, you
    ensure that you not only end up with high-quality data but also that you make
    and document decisions that you can use to describe (and even defend, if necessary)
    any insights you generate. This doesn’t mean that everyone will agree with your
    conclusions. It does, however, help ensure you can have a meaningful discussion
    about them—and that’s what really advances knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: So without further ado, let’s dive into our data integrity evaluation!
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Much of the data used in this chapter has since been removed from the internet
    and/or replaced with other files—this is not unusual. I have intentionally left
    the content of this chapter largely intact despite these changes, because they
    reflect the very real and typical challenges of trying to do data wrangling work
    in anything close to real time.
  prefs: []
  type: TYPE_NORMAL
- en: It also illustrates how quickly—and almost untraceably—data can evolve and change
    in the digital world. Something to keep in mind. In the meantime, you can find
    all of the datasets referenced in this chapter on this [Google Drive folder](https://drive.google.com/file/d/1EtUB0nK9aQeWWWGUOiayO9Oe-avsKvXH/view?usp=sharing).
  prefs: []
  type: TYPE_NORMAL
- en: Is It of Known Pedigree?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the time of this writing, the first search result for the phrase “most recent
    PPP loan data” is a page on the US Department of the Treasury website that links
    to data from August 2020.^([5](ch06.html#idm45143406687968)) The second result
    links to more recent data, from the Small Business Administration (SBA)—the government
    department charged with actually administering the funds.^([6](ch06.html#idm45143406684480))
  prefs: []
  type: TYPE_NORMAL
- en: While both of these are legitimate sites for government agencies whose work
    is relevant to the PPP, it makes more sense for us to work principally with data
    published by the SBA. Still, it was *not* the first thing I found when I first
    went to look for this data.
  prefs: []
  type: TYPE_NORMAL
- en: I really want to highlight this because the Treasury Department is obviously
    both a reasonable and reputable source for the data we were seeking, but it was
    still not the *best* one available. That’s why it matters to evaluate not just
    *where* your data came from but *how* you came to find it.
  prefs: []
  type: TYPE_NORMAL
- en: Is It Timely?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we want to use data to learn something about the state of the world as it
    is *now*, the first thing we need to establish is *when* our data dates from—and
    confirm that it’s the most recent available.
  prefs: []
  type: TYPE_NORMAL
- en: If this seems like it should be straightforward, think again—many websites don’t
    automatically date every post, so even determining when something went online
    is often a challenge. Alternatively, a website that *does* date its content may
    change it any time a change (even an insubstantial one) is made; some sites may
    regularly update the “published” date in an attempt to game search engine algorithms
    that favor more recent content.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, determining what is *actually* the most recent, relevant data
    for your particular data wrangling problem may well require some digging. The
    only way to know for sure will be to try a few different search terms, click through
    several sets of results, and maybe reach out to an expert for advice. In the process,
    you’ll most likely find enough references to reassure you what the most recently
    available data is.
  prefs: []
  type: TYPE_NORMAL
- en: Is It Complete?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far, we know that there have been multiple data releases for the PPP. While
    we can be pretty confident that we’ve successfully located the most *recent* data,
    the next question is: is this *all* the data?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we’re primarily interested in businesses that received larger loans,
    we only have to worry about examining one file: *public_150k_plus.csv*.^([7](ch06.html#idm45143406648768))
    But how can we know if this includes all phases of the program to date, or just
    the loans made since the *first* data release in August 2020? Since we have access
    to both sets of data,^([8](ch06.html#idm45143406646448)) we have a few strategies
    we can use:'
  prefs: []
  type: TYPE_NORMAL
- en: Find the earliest date(s) in our “recent” data file and confirm that they are
    *before* August 8, 2020.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the file sizes and/or row counts of the two datasets to confirm that
    the more recent file is larger than the older file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the data they contain to confirm that all the records in the earlier
    file already exist in the later file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point you might be thinking, “Hang on, isn’t confirming the earliest
    date enough? Why would we do the other two? Both of those seem much more difficult.”
    Well, sure—in *theory*, just confirming that we have data from the earlier phases
    should be enough. But in truth, that’s a pretty cursory check. Obviously, we cannot
    confirm that the data the federal government has released is complete by trying
    to go out and collect more comprehensive data ourselves. On the other hand (and
    as we’ll see shortly), the data collection processes of governments and large
    organizations (including—and perhaps especially—banks) are far from perfect.^([9](ch06.html#idm45143406638368))
    Since we’ll be taking ownership of this data if we use it to draw conclusions,
    I think it’s worth being thorough.
  prefs: []
  type: TYPE_NORMAL
- en: 'Happily, conducting our first “completeness” check is quite simple: just by
    opening the data in a text editor, we can see that the first entry contains a
    “DateApproved” value of *05/01/2020*, suggesting that the recent dataset *does*
    in fact include data from the first round of PPP loans, which were disbursed in
    the spring of 2020, as shown in [Figure 6-1](#ppp_loan_data_recent).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Quick text editor view of recent PPP loan data.](assets/ppdw_0601.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-1\. Quick text editor view of recent PPP loan data
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: That was easy! If we want to go a little bit further, we can always write a
    quick script to find the oldest and most recent `LoanStatus` dates in the recent
    data. To avoid confusion, I’ve renamed the more recent file *public_150k_plus_recent.csv*.
    Currently,^([10](ch06.html#idm45143406630688)) following the data linked from
    [*https://home.treasury.gov/policy-issues/cares-act/assistance-for-small-businesses/sba-paycheck-protection-program-loan-level-data*](https://home.treasury.gov/policy-issues/cares-act/assistance-for-small-businesses/sba-paycheck-protection-program-loan-level-data)
    leads to a *different* folder on the SBA Box account, which shows an upload date
    of [August 14, 2020](https://sba.app.box.com/s/ox4mwmvli4ndbp14401xr411m8sefx3i).
    We have to download the entire folder, *150k plus 0808.zip*, but we can pull out
    the CSV and rename it *public_150k_plus_080820.csv*.
  prefs: []
  type: TYPE_NORMAL
- en: To help us with this process, we will, as usual, be looking for a library to
    smooth the way—this time in the form of Pandas, a well-known Python library for
    manipulating table-type data. While we won’t examine the *pandas* library in detail
    here (there is already an excellent O’Reilly book, *Python for Data Analysis*,
    written by the creator of Pandas, Wes McKinney!), we will definitely make use
    of its many helpful features in carrying out our data quality checks going forward.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with, we’ll need to install the library by running the following from
    the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s use it to pull in the recent PPP loan data and see what the earliest
    and latest dates are in that file, as shown in [Example 6-1](#ppp_date_range).
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-1\. ppp_date_range.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_assessing_data_quality_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Using the `as` keyword here lets us create a nickname for the library so that
    we can refer to it in fewer characters later in our code.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_assessing_data_quality_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: In order to find the oldest and most recent dates, we need to first convert
    the (string) values in our dataset to *actual* `Date` data types. Here, we’ll
    use the Pandas `to_datetime()` function and provide it with (1) [the column we
    want converted](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html),
    and (2) [the format of the dates](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)
    as they *currently* appear in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see from the following output, the earliest loan in this dataset
    was made on April 3, 2020, and the most recent was made on January 31, 2021:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note that while we don’t *absolutely* have to pass the `format` ingredient to
    the Pandas `to_datetime()` function, it’s always a good idea to do so; if we don’t
    provide this information, then Pandas has to try to “guess” what date format it’s
    looking at, which can make the actual processing take a long time. Here it only
    saves us about a second of processing time—but with larger datasets (or more than
    one), that can quickly add up!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s compare the file size of the recent data with the one that was released
    in August 2020\. Just looking at the *public_150k_plus_recent.csv* and the *public_150k_plus_080820.csv*
    files in a finder window, we can see that the file size of the more recent data
    is *much* larger than the earlier one: the August data is ~124 MB, while the recent
    data is several hundred megabytes. So far so good.'
  prefs: []
  type: TYPE_NORMAL
- en: Drawing on the techniques we used in [Example 4-7](ch04.html#fixed_width_parsing)
    and [Example 5-10](ch05.html#downloading_the_data), let’s write a quick script
    to determine how many rows of data are in each file, as shown in [Example 6-2](#ppp_numrows).
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-2\. ppp_numrows.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_assessing_data_quality_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Once the `readlines()` method has put the lines of our data file into a list,
    we can use the built-in `len()` method to determine how many there are. To print
    the result, we have to cast that number as a string with the built-in `str()`
    function first, or Python will yell at us.
  prefs: []
  type: TYPE_NORMAL
- en: Running this script confirms that while the file from August 2020 contains 662,516
    rows, the more recent version (from February 1, 2021) contains 766,500 rows.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let’s look at comparing the contents of the two files to confirm that
    everything in the earlier file appears in the newer file. This will undoubtedly
    be a multistep process, but let’s start by opening up the August data file in
    a text editor, as shown in [Figure 6-2](#ppp_loan_data_august).
  prefs: []
  type: TYPE_NORMAL
- en: '![Quick text editor view of August, 2020 PPP loan data.](assets/ppdw_0602.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-2\. Quick text editor view of August 2020 PPP loan data
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Right away it’s clear there are some…differences, which will make this particular
    check even more complicated than we might have anticipated. First, it’s clear
    that there are *many* more columns of data in the more recent file, which means
    that we’ll need to devise a strategy for matching up the records from the earlier
    dataset to the most recent one.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to get a handle on which data columns seem to overlap between
    the two files. We’ll do that by creating and comparing two small *sample* CSV
    files, each containing the first several rows of data from each dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll write a quick script that converts each of our source files into
    a `DataFrame`—a special Pandas data type for table-type data—and then writes the
    first few rows to a separate CSV, as shown in [Example 6-3](#ppp_data_samples).
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-3\. ppp_data_samples.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_assessing_data_quality_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The *pandas* `to_csv()` method encapsulates several steps we’ve previously
    done in plain-old Python: opening a new writable file and saving data to it. Because
    Pandas adds an index column (which essentially includes row numbers) to every
    DataFrame it creates, however, we need to include the second “ingredient” of `index=False`
    because we *don’t* want those row numbers to appear in our output CSV.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our two smaller file samples, let’s open them up and just look
    through them to visually compare both the column headers and their contents. You
    can see screenshots of the August data in [Figure 6-3](#august_data_sample), while
    the more recent data is shown in [Figure 6-4](#recent_data_sample).
  prefs: []
  type: TYPE_NORMAL
- en: '![First few lines of August PPP loan data file.](assets/ppdw_0603.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-3\. First few lines of August PPP loan data file
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![First few lines of recent PPP loan data file.](assets/ppdw_0604.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-4\. First few lines of recent PPP loan data file
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Luckily, it looks like the first few rows of both files contain at least *some*
    of the same entries. This will make it easier for us to compare their contents
    and (hopefully) identify which columns we can use to match up the rows.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by choosing a single entry to work with, ideally one with as many
    completed fields as possible. For example, something called `SUMTER COATINGS,
    INC.` appears on line 6 of the August data sample (as labeled in the spreadsheet
    interface) under the column heading `BusinessName`. On line 2 of the recent data
    sample, the same value appears under the column heading `BorrowerName`. In the
    August sample file, the term `Synovus Bank` appears in a column called `Lender`,
    while that term appears in the recent sample file in a column called `ServicingLenderName`.
    So far so good—or is it?
  prefs: []
  type: TYPE_NORMAL
- en: Although many details between these rows seem to match across the two data files,
    some seemingly important ones *don’t*. For example, in the August data sample,
    the value in the `DateApproved` column is `05/03/2020`; in the recent data sample,
    it is `05/01/2020`. If we look at another seemingly shared entry, we see that
    for the business/borrower called `PLEASANT PLACES, INC.` (row 5 in the August
    data and row 3 in the recent data), the column titled `CD` in both files (spreadsheet
    column AF in the recent file, column P in the August file) has different values,
    showing `SC-01` in the August data and `SC-06` in the recent data. What’s going
    on?
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have to make some judgment calls about *which* column values
    need to match in order for us to treat a particular loan row as the same between
    the two. Requiring that the business name and the lender name match seems like
    a good starting point. Since we know that multiple rounds of loans have been made
    by now, we probably want to require that the values in the `DateApproved` column
    match as well (even though it seems unlikely that Synovus Bank made two loans
    to Sumter Coatings, Inc. two days apart). What about the mismatched congressional
    district? If we look at a map of South Carolina’s congressional districts, it’s
    clear that their boundaries haven’t been changed since 2013,^([11](ch06.html#idm45143405919056))
    though it does seem like the 1st and the 6th district share a boundary. Given
    that, we might conclude that the discrepancy here is just a mistake.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we’re already finding some significant data quality issues—and
    we’ve only looked at five rows of data! Since we obviously can’t resolve all of
    these differences at once, we need to start by putting together the rows that
    (we hope) really match, while making sure to keep track of any that don’t. To
    do this, we’ll need to *join* or *merge* the two datasets. Because we already
    know there will be discrepancies, however, we need a way to keep track of those
    as well. In other words, we want the file created by our join process to include
    *every* row from *both* datasets, whether they match or not. To do this, we need
    what’s called [an *outer* join](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#brief-primer-on-merge-methods-relational-algebra).
    We’ll make use of this in [Example 6-4](#ppp_data_join).
  prefs: []
  type: TYPE_NORMAL
- en: Note that because an outer join preserves *all* data rows, it’s possible that
    our resulting dataset could have as many rows as the individual datasets combined—in
    this case about *1.4 million rows*. Don’t worry, though! Python can handle it.
    But can your device?
  prefs: []
  type: TYPE_NORMAL
- en: If you have a Macintosh or Windows machine, chances are that working with the
    ~500 MB of data that we need to in these examples will be no problem. If, like
    me, you’re working on a Chromebook or something similar, now’s the moment to move
    to the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-4\. ppp_data_join.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_assessing_data_quality_CO4-1)'
  prefs: []
  type: TYPE_NORMAL
- en: We’re passing the `indicator=True` parameter here because it will create a new
    column that lets us know which rows appeared in one or both files.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_assessing_data_quality_CO4-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Using `indicator=True` produces a column called `merge`, whose value for each
    row shows which dataset that particular row matched on. As we’ll see from the
    output, that value will be `both`, `left_only`, or `right_only`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If everything went well, you get an output like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: So what does this mean? It looks like our effort to match the August data with
    the recent data on business name, servicing lender name, and the date of the loan
    successfully matched 595,866 loans. The `right_only` loans are the *recent* loans
    that weren’t matched (`recent_ppp_data` was the second argument to our `pd.merge()`
    function, so it is considered to be in the “right”); we found 171,334 of these.
    This seems perfectly plausible, since we can imagine that many new loans may have
    been issued since August.
  prefs: []
  type: TYPE_NORMAL
- en: 'The troubling number here is `left_only`: 67,333 loans that appear in the August
    data that were *not* matched to any loan row contained our recent dataset. That
    suggests that either our recent data is incomplete or we have some serious quality
    issues lurking.'
  prefs: []
  type: TYPE_NORMAL
- en: From our very cursory examination of the sample data earlier, we already know
    that the `DateApproved` columns may have some problems, so let’s see what happens
    if we eliminate the need to match on date. To do this, we’ll just add the snippet
    in [Example 6-5](#ppp_data_join_cont) to [Example 6-4](#ppp_data_join) but without
    specifying that the dates need to match. Let’s see what happens.
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-5\. ppp_data_join.py (continued)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we get an output something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In other words, if we only require that the business name and lender match,
    then we “find” another ~45,000 loans from the August data in the recent data.
    Of course, what we *don’t* know is how many of those new “matches” are the result
    of data entry errors (along the lines of our `05/03/2020` versus `05/01/2020`
    problem) and how many of them represent multiple loans.^([12](ch06.html#idm45143405666608))
    All we know is that we’re down to 22,634 loans from the August data that we can’t
    locate in the recent data.
  prefs: []
  type: TYPE_NORMAL
- en: 'So what if we simply check whether a given business shows up in both datasets?
    This seems like the most basic form of comparison: in theory, the bank or lender
    servicing the PPP loan could change over the course of many months, or there could
    be additional mismatches because of (possibly) minor data-entry differences. Remember:
    our goal right now is simply to evaluate how far we can trust that the *recent*
    data includes all of the August data.'
  prefs: []
  type: TYPE_NORMAL
- en: So let’s add on a final, *very* relaxed merge to see what happens. Adding the
    snippet in [Example 6-6](#ppp_data_join_cont2), we’ll match *only* on business
    name and see what we get.
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-6\. ppp_data_join.py (continued)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'And now our output is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Things are looking a little bit better: out of a total of 790,620 (706,349
    + 77,064 + 7,207) possible loans, we’ve “found” all but 7,207—a little less than
    0.1%. That’s *pretty* good; we might be tempted to call that quantity of missing
    data a “rounding error” and move on. But before we get complacent about having
    accounted for 99.9% of all the PPP loans, let’s stop for a moment and consider
    what that “small” amount of missing data really represents. Even if we assume
    that every one of those “missing” loans was for the minimum possible amount (recall
    that we’re only looking at loans of $150,000 or more), that still means that our
    recent dataset has *at least* $1,081,050,000—over $1 billion!—in possible loans
    that are unaccounted for. Given how hard I work to figure (and pay) my taxes every
    year, I certainly hope the federal government isn’t simply going to “lose” $1
    billion in taxpayer money and not worry about it. But what can *we* do to account
    for it? This is where we get to the part of data work that can be both daunting
    and energizing: it’s time to talk to people!'
  prefs: []
  type: TYPE_NORMAL
- en: 'While reaching out to subject matter experts is always a great place to start
    your data quality investigations, in this instance we have something even better:
    information about the lenders and loan recipients themselves. Between the business
    names and locations contained in the file, we can probably track down contact
    information for at least a handful of our “lost” 7,207 loans from the August dataset
    and try to find out what happened.'
  prefs: []
  type: TYPE_NORMAL
- en: Before you pick up the phone and start calling people (and yes, most of the
    time you should be *calling*), however, figure out what you’re going to ask. While
    it may be tempting to imagine that something nefarious is going on (are the lenders
    hiding money? Are the businesses misrepresenting themselves?), there is an old
    (and very malleable) quote that goes something like “Never attribute to malice
    that which can be explained by incompetence/stupidity/neglect.”^([13](ch06.html#idm45143405581136))
    In other words, it’s likely that these loans don’t appear in the more recent data
    because of some data-entry error, or even because *the loans simply never came
    through*.
  prefs: []
  type: TYPE_NORMAL
- en: 'And in fact, after calling a few autobody repair and barber shops around the
    country, that was the story I heard most often. Multiple people I spoke with described
    a similar pattern: they applied for a loan, had been told it was approved, and
    then—the money simply never came through. While it would be impractical to try
    to confirm that this was the case for every single “missing” loan, hearing basically
    the same story from multiple businesses that are thousands of miles apart makes
    me *reasonably* confident that these loans don’t appear in the final dataset because
    the money was never actually sent.^([14](ch06.html#idm45143405576560))'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, it seems fairly clear that our recent PPP loan data is, in fact,
    “complete” for our purposes. While this may have felt like a lot of work to test
    our dataset for just one of almost a dozen data integrity measures, keep in mind
    that in the process, we’ve learned valuable information that will make many of
    our later “tests” much faster—or even trivial—to complete. So with that, let’s
    turn to our next criterion.
  prefs: []
  type: TYPE_NORMAL
- en: Is It Well-Annotated?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having satisfied ourselves that our data is appropriately *timely* and *complete*,
    we need to turn to understanding in detail what information the data columns in
    our recent PPP loan data actually contain.^([15](ch06.html#idm45143405548048))
    As with our completeness assessment, one place we can start is with the data itself.
    By looking at the column names and some of the values they contain, we can start
    to get a sense of what we need more information about. If the column name seems
    descriptive and the data values we find in that column align with our interpretation
    of the column name, that’s a pretty good starting point.
  prefs: []
  type: TYPE_NORMAL
- en: While we have a couple of options for reviewing our column names and their corresponding
    values, let’s go ahead and take advantage of the sample files we created earlier.
    Because our screen width will generally prevent us from easily printing lots of
    columns of data (whereas we can easily scroll down to see more rows), we’re going
    to start by *transposing* our sample data (that is, converting the columns to
    row and rows to columns) to make seeing the column titles easier.^([16](ch06.html#idm45143405541024))
    We’re also going to apply some additional data type filtering to make it easier
    for us to see what data is missing. Our first pass at this can be seen in [Example 6-7](#ppp_columns_review).
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-7\. ppp_columns_review.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_assessing_data_quality_CO5-1)'
  prefs: []
  type: TYPE_NORMAL
- en: For the sake of speed, the Pandas `read_csv()` method converts all missing entries
    to `NaN` (Not a Number), as described at [*https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html*](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html).
    To get these values converted to the more general (and intuitive) *<NA>* label,
    we apply the `convertdtypes()` method to the entire DataFrame, as described at
    [*https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data-na-conversion*](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data-na-conversion).
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in [Figure 6-5](#transposed_sample_recent), this lets us see
    all of the original column names as rows, along with a couple of the original
    rows as columns of data. By looking through these, we can start to get a sense
    of what we know—and what we don’t.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to their relatively descriptive names, we can start to guess at what
    we are likely to find in many of these columns. For example, columns like `DateApproved`,
    `ProcessingMethod`, `BorrowerName`, `BorrowerAddress`, `BorrowerCity`, `BorrowerCity`,
    `BorrowerState`, and `BorrowerZip` are fairly straightforward. In some cases,
    the name is descriptive but doesn’t give us all the information we need. For example,
    while `SBAGuarantyPercentage` gives us information about both the column’s content
    and its units (presumably the amount of the loan guaranteed by the SBA, as a percentage),
    the `Term` column doesn’t tell us if the value should be interpreted as 24 days,
    weeks, months, or years. Likewise, while the values in `BusinessAgeDescription`
    are themselves descriptive (e.g., `Existing or more than 2 years old`), a `LoanStatus`
    value of `Exemption 4` doesn’t really help us understand what happened to the
    loan. Finally, there are column names like `LMIIndicator` that might be easy for
    an expert to interpret but difficult for those of us not well-versed in loan jargon
    to identify.
  prefs: []
  type: TYPE_NORMAL
- en: What we really need at this point is a “data dictionary”—the term sometimes
    used to refer to the document that describes the contents of (especially) table-type
    data. Data dictionaries are important because while table-type data is very handy
    for conducting analyses, it doesn’t inherently offer a way to include the type
    of *metadata*—that is, data *about* the data—that we need to answer questions
    like “What units should be used?” or “What do coded categories mean?” which are
    exactly the kinds of questions that come up frequently with complex datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The most likely place to find a data dictionary should be the same location
    where we originally obtained the data (remember that in [Chapter 4](ch04.html#chapter4),
    we found the description of the *ghcnd-stations.txt* file linked from the *readme.txt*
    file in the same folder where the data was located). In this instance, that means
    going back to [the SBA website](https://sba.gov/funding-programs/loans/coronavirus-relief-options/paycheck-protection-program/ppp-data)
    and seeing what we can find.
  prefs: []
  type: TYPE_NORMAL
- en: '![ppdw 0605](assets/ppdw_0605.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-5\. Recent sample data transposed
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: At first, things look fairly promising. Under the “All Data” section on that
    page, we see a link promising a summary of “key data aspects,” as shown in [Figure 6-6](#ppp_data_landing_page).^([17](ch06.html#idm45143405428640))
  prefs: []
  type: TYPE_NORMAL
- en: '![Landing page for PPP loan data on the SBA''s website](assets/ppdw_0606.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-6\. Landing page for PPP loan data on the SBA’s website
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Following the link](https://sba.gov/document/report-paycheck-protection-program-ppp-loan-data-key-aspects)
    brings us to a page that (as of this writing) lists two PDF documents from the
    summer of 2020\. Unfortunately, neither of them seems to contain what we need—they
    are mostly filled with disclaimer-type text about how PPP loans are processed,
    though they do confirm our discovery that “canceled” loans will not appear in
    the database, as shown in [Figure 6-7](#ppp_data_aspects).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Excerpt of ''Information to keep in mind when reviewing Paycheck Protection
    Program (PPP) data''](assets/ppdw_0607.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-7\. Excerpt of *information to keep in mind when reviewing PPP data*
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now what? We have a few options. We can turn to a more general research strategy
    in order to learn more about the PPP and hopefully fill in some of the blanks
    for ourselves. For example, reading enough articles on websites targeting potential
    PPP applicants will make clear that the appropriate units for the `Term` column
    is almost certainly weeks. Likewise, if we do enough web searches for the term
    `LMIIndicator`, `LMI Indicator`, and `LMI Indicator loans`, we’ll eventually come
    across a Wikipedia page that suggests this term *may* be shorthand for “Loan Mortgage
    Insurance Indicator”—but we hardly know for sure.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, it’s once again time to look for some human help. But who can
    we reach out to? Scholars who have looked at the PPP data already are one place
    to start, but they might be hard to find if the data release is relatively recent.
    So, just as we did when trying to confirm what happened to all those missing loans
    from the August dataset, we’re going to go straight to the source: the SBA. And
    fortunately, if we go back to the site where we downloaded our actual data files,
    as shown in [Figure 6-8](#ppp_box_site), it turns out there is a name attached
    to those uploads: Stephen Morris.^([18](ch06.html#idm45143405416416))'
  prefs: []
  type: TYPE_NORMAL
- en: '![PPP data download portal](assets/ppdw_0608.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-8\. PPP data download portal
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'After placing a call and sending an email, I learned that, at the time of my
    inquiry, the SBA hadn’t yet created a data dictionary for the PPP loan data, though
    Morris did refer me to both the original PDF and a data dictionary for the SBA’s
    7a loan program, on which the PPP loan structure was based. While the latter file
    (located at [*https://data.sba.gov/dataset/7-a-504-foia*](https://data.sba.gov/dataset/7-a-504-foia))
    still differed significantly from the PPP loan data columns, it did provide insight
    into some key elements. For example, that file included a description of a column
    also called `LoanStatus`, whose possible values seem to parallel at least some
    of what we’ve found in the PPP loan data so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: So is this data “well-annotated”? Somewhat. It’s not as well annotated as, say,
    the NOAA data we worked with in [“Finally, Fixed-Width”](ch04.html#fixed_width),
    but with some effort we’ll probably be able to build up our own data dictionary
    for the PPP loan data that we can be pretty confident in.
  prefs: []
  type: TYPE_NORMAL
- en: Is It High Volume?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we have already finished our “completeness” review, we have largely already
    answered the question of whether the data we’re using is *generally* high volume.
    There are few instances in which having more than 750,000 rows of data won’t be
    sufficient for conducting at least *some* useful form of analysis.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, we also can’t say yet exactly what types of analyses we’ll
    be able to conduct, because the number of data rows we have doesn’t matter if
    most of them are empty. So how can we check this? For columns where we only expect
    to find a few possible values, like `LoanStatus`, we can use the Pandas `value_counts()`
    method to summarize the contents. For columns that have very diverse values (such
    as `BorrowerName` or `BorrowerAddress`), we’ll need to instead check specifically
    for *missing* values and then compare that to the total row count to get a sense
    of how much data might be missing. To start off with, we’ll summarize the columns
    we expect will only contain a handful of distinct values, as shown in [Example 6-8](#ppp_columns_summary).
    We’ll also count the `NA` entries in a more varied column—in this case, `BorrowerAddress`.
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-8\. ppp_columns_summary.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The output from [Example 6-8](#ppp_columns_summary), shown in [Example 6-9](#recent_col_summaries),
    starts to paint a picture of what kind of data is actually contained in our dataset’s
    ~750,000 rows. For example, the status of most loans is “Exemption 4,” which we
    know from our annotation investigation means it is “exempt from disclosure under
    FOIA Exemption 4.”^([19](ch06.html#idm45143405275328)) Similarly, we can see that
    more than two-thirds of loan applicants did not indicate their gender when applying,
    and 17 loans don’t even list the borrower’s address!
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-9\. Recent data column summaries
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: So is this data “high volume”? Yes—while we’re missing quite a lot of data overall,
    there seems to be useful information in a relatively high proportion of the rows
    and columns that we have. Keep in mind that in some cases, it’s possible to generate
    useful insights about something with as little as a *few dozen* rows of data—as
    long as they contain truly meaningful information. That’s why it’s not sufficient
    to simply look at the size of a data file or even the number of rows it contains
    to confirm that it’s truly “high volume”—we actually have to really examine the
    data in some detail in order to be sure.
  prefs: []
  type: TYPE_NORMAL
- en: Is It Consistent?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another thing we know from our earlier completeness check is that the format
    of the PPP loan data absolutely was *not* consistent between August and later
    releases: the data published beginning in December 2020 was [much more detailed
    than what had been released previously](https://washingtonpost.com/business/2020/06/11/trump-administration-wont-say-who-got-511-billion-taxpayer-backed-coronavirus-loans),
    and even most of the column names differed between the two files.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we’re now relying only on the more recent data files, there is a different
    kind of consistency we need to think about: how consistent are the values within
    the dataset itself? We might hope, for example, that the same units will have
    been used in the dollar amount columns like `InitialApprovalAmount` and `CurrentApprovalAmount`.
    Still, it’s better to check for errors just in case. In [Example 6-10](#ppp_min_max_loan),
    we’ll do another quick min/max confirmation to ensure that the figures for these
    fall within the range we expect.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-10\. ppp_min_max_loan.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on the title of our data file—*150k_plus*—we would expect that the *minimum*
    loan amount we’ll find approved is $150,000\. A quick web search for “maximum
    loan under ppp” leads to a document on the SBA website that indicates that for
    most types of businesses,^([20](ch06.html#idm45143405217296)) the maximum loan
    amount is $10 million. Indeed, running our script seems to confirm that this minimum
    and maximum are reflected in our data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we also want to check for one of the most common (and insidious)
    forms of inconsistency: spelling differences. *Anytime* you’re dealing with data
    that has been entered by humans, there are going to be spelling issues: extra
    spaces, typos, and differences in punctuation, at minimum. This is a problem because
    if we want to be able to answer a seemingly simple question like “How many loans
    originated with lender X?” we need the spelling of that bank’s name to be consistent
    throughout the data. And it’s almost guaranteed that it won’t be—at least at first.'
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, because this is such a common data problem, there are a number
    of well-developed approaches for dealing with it. Here we’re going to use an approach
    called *fingerprinting* to begin checking the consistency of bank name spellings
    in our dataset. While there are many ways that we could cluster these company
    names (phonetically, for example) when looking for differently spelled duplicates,
    we’re choosing fingerprinting because it follows a simple, strict-but-effective
    *algorithm* (really, just a set of sets) that minimizes the risk that we’ll end
    up matching up two names that really *shouldn’t* be the same.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, the fingerprinting algorithm we’ll be using does the following
    things:^([21](ch06.html#idm45143405172768))
  prefs: []
  type: TYPE_NORMAL
- en: Removes leading and trailing whitespace
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Changes all characters to their lowercase representation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Removes all punctuation and control characters
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Normalizes extended Western characters to their ASCII representation (for example
    “gödel” → “godel”)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Splits the string into whitespace-separated *tokens*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sorts the tokens and removes duplicates
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Joins the tokens back together
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As usual, while we could write the code for this ourselves, we’re lucky that
    someone in the Python community has already done this and has created the library
    *fingerprints*, which we can install using pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: For the moment, our main concern is confirming whether we have any spelling
    discrepancies to speak of; actually transforming our data to address these differences
    is something we’ll look at in [Chapter 7](ch07.html#chapter7). So for now, we’re
    just going to count all the unique bank names in our dataset and then see how
    many unique fingerprints there are in that list. If all the bank names in the
    file are truly distinct, then in *theory* the two lists should be the same length.
    If, on the other hand, some of the bank names in our dataset are “unique” only
    because of minor punctuation and whitespace differences, for example, then our
    list of fingerprints will be *shorter* than our list of “unique” bank names. This
    would suggest that we’ll need to do some data transformations in order to reconcile
    multiple spellings of the same bank name to ensure that, for example, we’re really
    able to pull up *all* of the loans associated with a single bank if we want to
    ([Example 6-11](#ppp_lender_names)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-11\. ppp_lender_names.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Running this script yields the output:^([22](ch06.html#idm45143405153824))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The length difference between the two lists certainly suggests that there are
    some spelling discrepancies in our dataset: the number of “unique” names in the
    raw data is 4,337, but the number of distinct fingerprints for those names is
    only 4,242\. While the difference here is “only” ~100 items, these discrepancies
    may well affect thousands of rows of data, since on average each bank has issued
    hundreds of loans (750,000/4337 = ~173). As a result, we cannot say how many rows
    of our original dataset contain a given “misspelled” name (nor can we be sure
    that this is exhaustive). In [“Correcting for Spelling Inconsistencies”](ch07.html#correcting_inconsistencies),
    we’ll go through the process of transforming our data using these fingerprints
    to better identify specific lenders and borrowers.'
  prefs: []
  type: TYPE_NORMAL
- en: Is It Multivariate?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In much the same way that a dataset is more likely to be high volume if it contains
    many rows, it is more likely to be multivariate if it has many columns. Just like
    our quality check for volume, however, determining whether the columns we have
    make our data truly multivariate means doing a quality check on the data they
    contain as well.
  prefs: []
  type: TYPE_NORMAL
- en: For example, while our PPP loan data contains 50 data columns, about a dozen
    of these are essentially expanded addresses, since the location of the borrower,
    originating lender, and servicing lender are each broken out into a separate column
    for street address, city, state, and zip code. While many of the remaining columns
    may contain unique data, we need to get a sense of what they contain to understand
    how many data characteristics or *features* we actually have to work with.
  prefs: []
  type: TYPE_NORMAL
- en: For example, how many of the loans in our dataset have reported requesting money
    for something other than payroll costs? While the data structure (and the loan
    program) allows borrowers to use the loans for other things (such as [healthcare
    costs and rent](https://sba.gov/funding-programs/loans/covid-19-relief-options/paycheck-protection-program/first-draw-ppp-loan)),
    to what extent does that show up in the data?
  prefs: []
  type: TYPE_NORMAL
- en: Just as we did when assessing how high volume our data really was, we’ll look
    at the contents of a few more columns to determine whether the detail that they
    appear to offer is really borne out in the amount of data they contain. In this
    instance ([Example 6-12](#ppp_loan_uses)), we’ll look at how many rows for each
    of the `PROCEED` columns do *not* contain a value.
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-12\. ppp_loan_uses.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the output shown in [Example 6-13](#reported_use_of_funds),
    the vast majority of businesses (all but 1,828) said that they intended to use
    money for payroll expenses when they applied, with less than one-third reporting
    that they would (probably also) use the money to pay utilities. Another portion
    provided information about using the money for rent. Our last test, meanwhile,
    shows that well over two-thirds of all businesses listed *only* payroll expenses
    as the intended use of their PPP funds.
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-13\. Reported uses of PPP loan funds
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: What does this mean about how “multivariate” our data is? Even if we decide
    to discount the additional columns dedicated to address details, or the seemingly
    underutilized `PROCEED` columns, there’s still quite a lot of information in this
    dataset to explore. It seems likely that we’ll be able to use it to at least begin
    to draw conclusions about who has received PPP loans and how they used the money.
    As always, however, we cannot take for granted that the columns or rows of our
    dataset have data content until we’ve checked and confirmed for ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: Is It Atomic?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is another instance where our previous work on the data lets us say “Yes!”
    fairly quickly on this measure of data integrity. While the August version of
    our data contained only loan amount ranges, we know that this dataset contains
    one loan per row, including their exact dollar amounts. Since we have specific
    numbers rather than summary or aggregate values, we can feel pretty confident
    that our data is sufficiently granular or “atomic” to support a wide range of
    possible data analyses later on.
  prefs: []
  type: TYPE_NORMAL
- en: Is It Clear?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although this dataset did *not* turn out to be especially well annotated, we’ve
    been able to make our way through many of our data integrity checks nonetheless
    because, for the most part, its column labels and their meanings *are* fairly
    clear. For example, if we weren’t sure what `CD` stood for, a peek at some of
    the values (such as `SC-05`) makes inferring that this stands for “congressional
    district” fairly straightforward. As we gain more experience working with public
    and government datasets (or working in a particular subject area), more of the
    codes and jargon will make sense more quickly.
  prefs: []
  type: TYPE_NORMAL
- en: For the columns whose labels weren’t so clear, exchanging a few emails with
    Stephen Morris at the SBA was enlightening. For example, he confirmed that the
    appropriate units for the `Term` column was months (not weeks, as first seemed
    likely) and that the `PROCEED` columns describe what the loan funds would be used
    for, according to “what the lender submitted to SBA (as stated by the borrower
    to them on the borrower application).”
  prefs: []
  type: TYPE_NORMAL
- en: My correspondence with Morris also illustrated why going to a primary source
    expert, if at all possible, is an essential step in conducting data integrity
    checks. If you recall, one of the column headers whose meaning was *not* clear
    at the start was `LMIIndicator`. Since my sample data rows did not contain values
    for this column, I started doing some web searches and ended up with results that
    included “lenders’ mortgage insurance” (as shown in [Figure 6-9](#lmi_indicator_search_results));
    at the time, this *seemed* like a reasonable interpretation of the column heading.
  prefs: []
  type: TYPE_NORMAL
- en: '![Search results for LMI Indicator loans](assets/ppdw_0609.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-9\. Search results for LMI indicator loans
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The only problem? It’s wrong. As Morris clarified via email, “The LMI Indicator
    tells whether a borrower is geographically located in a Low-Moderate Income zone.”
  prefs: []
  type: TYPE_NORMAL
- en: The lesson here is that if you don’t have an official data dictionary, you always
    want to be a bit cautious about how much you try to infer from column headers;
    even those that *seem* clear may not mean what you think. If there’s any doubt,
    be sure to reach out to some experts (ideally the folks who compiled the data)
    to confirm your inferences.
  prefs: []
  type: TYPE_NORMAL
- en: Is It Dimensionally Structured?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the idea of *dimensionally structured* data seemed a bit abstract when we
    discussed it in [Chapter 3](ch03.html#chapter3), hopefully it makes a bit more
    sense now that we have a real dataset in front of us. Dimensionally structured
    data includes information about useful categories or classes that we can use to
    group our data, alongside the more atomic features that help us conduct more granular
    analyses.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of our PPP loan data, I would say that some of those usefully “dimensional”
    data columns include ones like `RuralUrbanIndicator`, `HubzoneIndicator`, the
    newly clarified `LMIIndicator`, `NAICSCode`, and to some extent even `SBAOfficeCode`.
    Columns like `RaceEthnicity`, `Gender`, and `Veteran` could also be dimensionally
    useful, but as we know that many of them are “Unanswered,” this limits what we
    can infer from them. The others, meanwhile, can help us answer useful questions
    about the location and types of businesses that have so far benefited from the
    PPP.
  prefs: []
  type: TYPE_NORMAL
- en: Even more than that, columns like `NAICSCode` offer the possibility of usefully
    *augmenting* our dataset by allowing us to understand what industries benefiting
    businesses belong to, which we can potentially compare to things like Bureau of
    Labor Statistics and other datasets about employment sectors in the United States.
    We’ll dive into this process more deeply in [“Augmenting Your Data”](ch07.html#augmenting_data).
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we’ve been able to answer some of our data integrity questions with
    a resounding “Yes!”, while others have been more qualified, suggesting the need
    for additional transformations and evaluations before we move on to the data analysis
    phase. Before we do that, however, we need to turn to the crucial question(s)
    of data *fit*: whether our data demonstrates the *validity*, *reliability*, and
    *representativeness* we need in order to draw meaningful conclusions about (in
    this case) how the PPP is affecting small businesses in the United States.'
  prefs: []
  type: TYPE_NORMAL
- en: Assessing Data Fit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we’ve evaluated our dataset’s integrity with respect to nearly a dozen
    different measures, it’s time to assess the extent to which it is *fit* for our
    purposes; that is, whether this data can really give us answers to the question(s)
    that we’re asking. To do that, we’ll turn to our three main criteria for data
    *fitness*: validity, reliability, and representativeness. Now is the time that
    we need to examine our dataset with our original question in mind: did the PPP
    help save American small businesses?'
  prefs: []
  type: TYPE_NORMAL
- en: Validity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Remember that our working definition of validity is “the extent that something
    measures what it’s supposed to.” Even if our PPP loan data was perfect, we’d need
    to somehow determine whether it can answer that question in some way. At this
    point, we know that our dataset provides one essential piece of that answer, because
    we are pretty confident now that it accurately details which businesses currently
    have *approved* PPP loans. Through our investigations into its integrity (especially
    around completeness and in our search for annotating information, or *metadata*),
    we are also pretty confident that already *canceled* loans are not showing up
    in the dataset—we confirmed this both through the SBA’s published information
    about the PPP program and by reaching out directly to businesses.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use elements of the dataset (specifically `LoanStatus` and `LoanStatusDate`)
    to get a sense of which businesses—among the more than 750,000 that have been
    approved for a loan—have actually received the money. We can check this by first
    summarizing the `LoanStatus` column using the `value_counts()` method as we have
    before, as shown in [Example 6-14](#ppp_loan_status).
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-14\. ppp_loan_status.py
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_assessing_data_quality_CO6-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Note that because the `value_counts()` method will *not* include `NA` values,
    I am also summing the entries to make sure every row has been accounted for.
  prefs: []
  type: TYPE_NORMAL
- en: The output from this script, shown in [Example 6-15](#loanstatus_summary), confirms
    that of the 766,499 loans currently in our dataset, the funds for over 100,000
    of them have not actually been sent to businesses yet, while more than another
    100,000 businesses appear to have repaid their loans already.
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-15\. `LoanStatus` summary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: If we’re hoping to evaluate the fate of small businesses that received PPP loans,
    then, we need to start by making sure that we look only at those that have actually
    *received* the funds—meaning that we should restrict our inquiry to those whose
    `LoanStatus` value is either “Exemption 4” or “Paid in Full.”
  prefs: []
  type: TYPE_NORMAL
- en: In theory, when businesses applied for PPP loans, they asked for enough money
    to keep their businesses afloat, so we might be tempted to assume that if a business
    has gotten the PPP money, it should be doing all right. But just as potentially
    too-loose criteria may have allowed many businesses to [fraudulently get PPP loans](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3906395),
    the fact that a business *received* PPP money is no guarantee that it’s still
    doing OK. This reality is exemplified by this *Wall Street Journal* article, [which
    tells the story of one company that filed for bankruptcy despite receiving a PPP
    loan](https://wsj.com/articles/hundreds-of-companies-that-got-stimulus-aid-have-failed-11605609180).
    Since we already know that this business filed for bankruptcy, finding its record
    within our dataset can help give us a sense of what these records potentially
    look like, as shown in [Example 6-16](#ppp_find_waterford).
  prefs: []
  type: TYPE_NORMAL
- en: Example 6-16\. *ppp_find_waterford.py*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_assessing_data_quality_CO7-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Pandas cannot search for a string within any column that has `NA` values, so
    we need to create a DataFrame that doesn’t have any of those in our target column,
    just for review purposes (obviously we might want to investigate loans with no
    named borrower).
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_assessing_data_quality_CO7-2)'
  prefs: []
  type: TYPE_NORMAL
- en: While `str.contains()` will match successfully on only part of a string, it
    *is* case-sensitive. This means that the fact that borrower names are in ALL CAPS
    matters!
  prefs: []
  type: TYPE_NORMAL
- en: 'The following output from this script is telling: the loan shows up with a
    status of “Exemption 4,” and perhaps even more interestingly, with a `LoanStatusDate`
    of `NA`. But otherwise, there’s no indicator that this business is, well, no longer
    in business.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In fact, if we quickly check how many loans appear with a `LoanStatusDate`
    of `NA` by adding the following line to the end of our script, we see that it
    is a perfect match for those with a `LoanStatus` of `Exemption 4`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: So does this PPP loan data *measure what it is supposed to measure*? I would
    say yes, but that’s not the whole story. As we saw from our summary of the `LoanStatus`
    information, not all of the businesses that appear in this dataset *have actually
    gotten a loan*; they have been approved and still *could* receive the money (we
    know their loans have not been canceled)—but 107,368 of them have not yet taken
    the money, and we can’t know for sure if they ever will.
  prefs: []
  type: TYPE_NORMAL
- en: We also can’t say from this dataset alone what has happened to the businesses
    that have received the money. Some may still be in operation; others have gone
    bankrupt. Still others could have liquidated without filing for bankruptcy. In
    other words, while the PPP data has strong validity when it comes to answering
    certain parts of our question, answering the whole question will require much
    more than just this one dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Reliability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When it comes to *reliability*, the primary criteria we are interested in are
    *accuracy* and *stability*. In other words, how well does the PPP data reflect
    who has gotten PPP loans, and how likely is it that the picture of who has gotten
    those loans will change over time?
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to our previous investigations, we know by now that the *stability* of
    this dataset is far from perfect. Several thousand businesses that were approved
    for loans and appeared in the August dataset do *not* appear in the current one
    (we’ll address the implications this has for *representativeness* in the next
    section), which comports with documentation from the SBA^([23](ch06.html#idm45143404387856))
    that canceled loans are not included.^([24](ch06.html#idm45143404385984)) It’s
    also not clear whether, as updates are made, previous versions of the data will
    still be available, making it difficult to determine what has changed unless we
    begin downloading and archiving each release ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: Even the figures within the dataset itself may not be especially stable over
    time. For example, we know that 538,905 businesses reported that they would only
    be using their PPP loan for payroll costs. But as SBA representative Stephen Morris
    explained via email, “This data is speculative to some extent because it’s not
    required that the borrower use the funds for the purpose they selected on their
    application.” In other words, unless some part of the loan forgiveness or repayment
    process *requires* that PPP loan recipients detail how the money was spent (and
    that information is subsequently updated in this dataset), we can’t know for sure
    whether the figures we see in the various `PROCEED` columns are either accurate
    or stable.
  prefs: []
  type: TYPE_NORMAL
- en: Representativeness
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Is the PPP loan data representative of everyone who actually received a PPP
    loan? Most likely. After a public outcry [led many large and/or publicly traded
    companies to return early PPP loans](https://nbcnews.com/business/business-news/which-companies-are-returning-their-ppp-loan-here-s-list-n1194566),
    the SBA indicated that they would be closely scrutinizing loans over $2 million,
    and [almost $30 billion in loans had been returned or canceled by early July](https://cnbc.com/2020/07/06/companies-returned-30-billion-in-small-business-loans-from-ppp.html).
    After our relatively exhaustive comparisons between the August and February datasets,
    we can feel pretty confident that the dataset we have is at least representative
    of who has received PPP loans to date.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, this doesn’t really tell us as much as we might think. We
    already know that the vast majority of PPP loan recipients that appear in this
    data did not disclose their gender, race, ethnicity, or veteran status, meaning
    that we have no real way of knowing how well (if at all) the demographics of PPP
    loan recipients reflect the population of small business owners in the United
    States. In fact, as we’ll see in [Chapter 9](ch09.html#chapter9) it’s very unlikely
    that we can draw conclusions about the demographics of PPP loan recipients at
    all, because the number of applicants who included this information is so small.
  prefs: []
  type: TYPE_NORMAL
- en: 'But the question of representativeness actually goes deeper than that, back
    to (and beyond) those 7,207 loans that disappeared between the August data release
    and the more recent one(s). Those missing loans reflect businesses that applied
    for loans and were approved, but in the words of one employee: “The money just
    never arrived.” That means that while we know how many businesses *got* a PPP
    loan, we have no way of knowing *how many applied*. Because those canceled loans
    have been removed from the data, we are now left with an instance of what I like
    to call the “denominator” problem.'
  prefs: []
  type: TYPE_NORMAL
- en: The denominator problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The denominator problem is recognized—albeit under different names—across almost
    every field of data-driven inquiry. Sometimes called the *benchmarking* or *baseline*
    problem,^([25](ch06.html#idm45143404363328)) the denominator problem encapsulates
    the difficulty of trying to draw meaning from data when you lack sufficient comparative
    information to put it into context. In most cases, this is because the comparison
    data you really need was never collected.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our exploration of the PPP data, we’ve already encountered one version of
    this problem: we know which businesses have received loans, but we don’t know
    who applied and was rejected or why (in at least some cases, it seems, the recipients
    don’t know, either). This is a problem for assessing the PPP loan process, because
    we don’t know if legitimate applicants have been rejected even as some businesses
    are granted multiple rounds of loans. If we want to know whether the distribution
    of loans was fair—or even effective—knowing who *hasn’t* been included is as important
    as finding out who *has*.'
  prefs: []
  type: TYPE_NORMAL
- en: Some of the denominator problems we’ve encountered so far may be answerable
    using complementary data of some kind—that’s what *The Wall Street Journal* did
    in comparing PPP loan data to bankruptcy filings. In others, the solution will
    be for us to build our own archive if—as seems to be the case here—the earlier
    datasets are not being offered by the data provider along with the updated versions.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, did the Paycheck Protection Program help save small businesses? *Maybe*.
    On the one hand, it’s hard to imagine that so much money could be spent without
    *some* positive benefit. On the other hand, both the real world—and the data we
    have about it—is a complicated, interdependent mess. If a PPP loan recipient pivoted
    its business model and found new revenue streams, would we put it in the “saved
    by the PPP” category or not? Similarly, if a business that didn’t receive a loan
    fails, is that *because* it didn’t receive a loan, or would it have failed anyway?
    The more of these “what ifs” we propose, the more likely it is that a couple of
    things will happen:'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll develop a violent headache, decide it isn’t possible to *really* know
    anything, and look for a reassuring way to procrastinate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After enough time playing games/reading the internet/complaining to confused
    friends and relations about how we spent all this time wrangling a dataset that
    we’re not sure is worth anything and we can hardly remember why we started this
    whole thing in the first place, we’ll come across something that gives us an idea
    for a *slightly* different, possibly *much* narrower question to explore, and
    excitedly return to our dataset, eager to see if we can somehow answer this new
    question any better than the last one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is this process arduous and circuitous? Yes. It is also reminiscent of our discussion
    about construct validity in [“How? And for Whom?”](ch03.html#how_for_whom). In
    the end, it is also *actually how new knowledge is formed.* The uncertain, frustrating,
    and slippery work of considering new options, thinking them through, testing them
    out, and then (potentially) starting the whole process over again with a bit more
    information and understanding the next time is how genuinely *original* insights
    are made. It’s the thing that every algorithmic system in the world is desperately
    trying to approximate, or imitate. But if you’re willing to put the effort in,
    *you can* actually succeed.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, I feel like I’ve learned quite a bit about this dataset—enough
    that I know I probably *cannot* answer my original question with it but can still
    imagine some interesting insights it could yield. For example, I feel confident
    that the most recent data accurately reflects the state of currently approved
    loans, because I confirmed that loans missing from more recent files were (for
    some reason or other) probably never actually made. At the same time, while the
    SBA announced that as of early January 2021, over [$100 billion in PPP loans had
    been forgiven](https://sba.gov/article/2021/jan/12/11-million-paycheck-protection-program-loans-forgiven-so-far-totaling-over-100-billion),
    there didn’t seem to be a distinct value in the `LoanStatus` column to indicate
    forgiven loans, even more than six weeks later. While the SBA’s Stephen Morris
    stopped responding to my emails in early March, as of early May 2021, a data dictionary
    does seem to be available,^([26](ch06.html#idm45143404333728)) even if neither
    it—nor the updated data—contains this information, either.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, there’s still plenty more to learn here: about who has received
    loans and where they’re located, how much they were approved for, and who is making
    those loans. And while the data is far from perfect, I can keep copies of past
    datasets on hand to reassure myself that if anything in the future changes significantly,
    I will at least have the resources on hand to spot it. Given that, it’s time to
    move on from the assessment phase of our work and apply ourselves to the task
    of actually cleaning and transforming our data, which we’ll tackle in [Chapter 7](ch07.html#chapter7).'
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch06.html#idm45143406437120-marker)) Even if they don’t always realize
    it.
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch06.html#idm45143406492528-marker)) See [*https://en.wikipedia.org/wiki/Paycheck_Protection_Program*](https://en.wikipedia.org/wiki/Paycheck_Protection_Program)
    for details on the PPP.
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch06.html#idm45143406490368-marker)) “Who Got Half a Trillion in COVID
    Loans? The Trump Administration Won’t Say,” [*https://marketplace.org/shows/make-me-smart-with-kai-and-molly/who-got-half-a-billion-in-covid-loans-the-trump-administration-wont-say*](https://marketplace.org/shows/make-me-smart-with-kai-and-molly/who-got-half-a-billion-in-covid-loans-the-trump-administration-wont-say).
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch06.html#idm45143406483424-marker)) You can find a good markdown cheatsheet
    at [*https://github.com/adam-p/markdown-here/wiki/Markdown-Here-Cheatsheet*](https://github.com/adam-p/markdown-here/wiki/Markdown-Here-Cheatsheet).
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch06.html#idm45143406687968-marker)) The original link for this content
    was [*https://home.treasury.gov/policy-issues/cares-act/assistance-for-small-businesses/sba-paycheck-protection-program-loan-level-data*](https://home.treasury.gov/policy-issues/cares-act/assistance-for-small-businesses/sba-paycheck-protection-program-loan-level-data),
    however it is now found at [*https://home.treasury.gov/policy-issues/coronavirus/assistance-for-small-businesses/paycheck-protection-program*](https://home.treasury.gov/policy-issues/coronavirus/assistance-for-small-businesses/paycheck-protection-program).
  prefs: []
  type: TYPE_NORMAL
- en: ^([6](ch06.html#idm45143406684480-marker)) And this second link is [*https://sba.gov/funding-programs/loans/coronavirus-relief-options/paycheck-protection-program/ppp-data*](https://sba.gov/funding-programs/loans/coronavirus-relief-options/paycheck-protection-program/ppp-data).
  prefs: []
  type: TYPE_NORMAL
- en: ^([7](ch06.html#idm45143406648768-marker)) You can download this file at [*https://drive.google.com/file/d/1EtUB0nK9aQeWWWGUOiayO9Oe-avsKvXH/view?usp=sharing*](https://drive.google.com/file/d/1EtUB0nK9aQeWWWGUOiayO9Oe-avsKvXH/view?usp=sharing).
  prefs: []
  type: TYPE_NORMAL
- en: ^([8](ch06.html#idm45143406646448-marker)) Data for August 2020 can be found
    at [*https://drive.google.com/file/d/11wTOapbAzcfeCQVVB-YJFIpsQVaZxJAm/view?usp=sharing*](https://drive.google.com/file/d/11wTOapbAzcfeCQVVB-YJFIpsQVaZxJAm/view?usp=sharing);
    data for February 2021 can be found at [*https://drive.google.com/file/d/1EtUB0nK9aQeWWWGUOiayO9Oe-avsKvXH/view?usp=sharing*](https://drive.google.com/file/d/1EtUB0nK9aQeWWWGUOiayO9Oe-avsKvXH/view?usp=sharing).
  prefs: []
  type: TYPE_NORMAL
- en: ^([9](ch06.html#idm45143406638368-marker)) Following the 2008 financial crisis,
    for example, it became clear that many banks had not kept proper records as they
    repackaged and sold—or “securitized”—home mortgages, leading some courts to [reject
    their attempts to foreclose on homeowners](https://nytimes.com/2009/10/25/business/economy/25gret.html).
  prefs: []
  type: TYPE_NORMAL
- en: ^([10](ch06.html#idm45143406630688-marker)) The following links are included
    for posterity, as they represent the original locations from which the datasets
    provided with this chapter are drawn.
  prefs: []
  type: TYPE_NORMAL
- en: ^([11](ch06.html#idm45143405919056-marker)) For South Carolina congressional
    districts, see Wikipedia’s page at [*https://en.wikipedia.org/wiki/South_Carolina%27s_congressional_districts#Historical_and_present_district_boundaries*](https://en.wikipedia.org/wiki/South_Carolina%27s_congressional_districts#Historical_and_present_district_boundaries).
  prefs: []
  type: TYPE_NORMAL
- en: ^([12](ch06.html#idm45143405666608-marker)) The SBA began accepting applications
    for so-called “second-round” PPP loans on [January 31, 2021](https://uschamber.com/co/run/business-financing/second-draw-ppp-loans).
  prefs: []
  type: TYPE_NORMAL
- en: ^([13](ch06.html#idm45143405581136-marker)) Attempting to attribute axioms is
    always problematic, but while I prefer the phrasing of *incompetence* or *neglect*,
    I like the attribution of this expression as “Hanlon’s Razor” found in [“The Jargon
    File”](https://jargon-file.org/archive/jargon-4.4.7.dos.txt), mostly because that
    document explains the origin of a lot of computer/programming slang.
  prefs: []
  type: TYPE_NORMAL
- en: ^([14](ch06.html#idm45143405576560-marker)) Of course, *why* it was never sent
    is an interesting question unto itself.
  prefs: []
  type: TYPE_NORMAL
- en: ^([15](ch06.html#idm45143405548048-marker)) You may have noticed that in this
    chapter, I haven’t addressed our data integrity criteria in precisely the order
    I listed them in [Chapter 3](ch03.html#chapter3). Because the PPP was [modeled
    on the existing 7(a) loan program](https://journalofaccountancy.com/news/2020/apr/paycheck-protection-program-ppp-loans-sba-details-coronavirus.html),
    I made the (questionable) assumption that this data would be well-annotated. Of
    course, these were also the *only* datasets available about the PPP, so my options
    were limited (as they so often are when working with real-world data).
  prefs: []
  type: TYPE_NORMAL
- en: ^([16](ch06.html#idm45143405541024-marker)) I sometimes find it easier to think
    of transposing data as “turning it on its side.”
  prefs: []
  type: TYPE_NORMAL
- en: ^([17](ch06.html#idm45143405428640-marker)) This page has changed considerably
    since this chapter was originally written. Notably, the main data location now
    includes a “data dictionary”—but this was released only several months after the
    data was first posted.
  prefs: []
  type: TYPE_NORMAL
- en: ^([18](ch06.html#idm45143405416416-marker)) It seems slightly noteworthy that
    this attribution was changed to `SM` shortly after I reached out to him.
  prefs: []
  type: TYPE_NORMAL
- en: ^([19](ch06.html#idm45143405275328-marker)) For more information on FOIA requests
    and exemptions, see [“FOIA/L Requests”](app03.html#foia_requests) and the full
    text of the exemption on the [Department of Justice’s website](https://justice.gov/oip/exemption-4-after-supreme-courts-ruling-food-marketing-institute-v-argus-leader-media).
  prefs: []
  type: TYPE_NORMAL
- en: '^([20](ch06.html#idm45143405217296-marker)) Specifically, “Paycheck Protection
    Program: How to Calculate Maximum Loan Amounts for First Draw PPP Loans and What
    Documentation to Provide by Business Type,” which can be found at [*https://sba.gov/sites/default/files/2021-01/PPP%20--%20How%20to%20Calculate%20Maximum%20Loan%20Amounts%20for%20First%20Draw%20PPP%20Loans%20%281.17.2021%29-508.pdf*](https://sba.gov/sites/default/files/2021-01/PPP%20--%20How%20to%20Calculate%20Maximum%20Loan%20Amounts%20for%20First%20Draw%20PPP%20Loans%20%281.17.2021%29-508.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: ^([21](ch06.html#idm45143405172768-marker)) See [*https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth*](https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth)
    for more information on clustering.
  prefs: []
  type: TYPE_NORMAL
- en: '^([22](ch06.html#idm45143405153824-marker)) When you run this script, you may
    see a warning about installing pyICU. Installing this library is a little bit
    complicated, however, and won’t change our results for this exercise. If you plan
    to use this fingerprinting process extensively, though, you may want to invest
    the additional time to setup pyICU. You can find more information about this process
    here: [*https://pypi.org/project/PyICU*](https://pypi.org/project/PyICU).'
  prefs: []
  type: TYPE_NORMAL
- en: ^([23](ch06.html#idm45143404387856-marker)) Which can be downloaded from [*https://sba.gov/document/report-paycheck-protection-program-ppp-loan-data-key-aspects*](https://sba.gov/document/report-paycheck-protection-program-ppp-loan-data-key-aspects).
  prefs: []
  type: TYPE_NORMAL
- en: ^([24](ch06.html#idm45143404385984-marker)) Again, understanding why and how
    these loans were canceled might be instructive, but we won’t find that information
    here—only some bread crumbs about where to start looking.
  prefs: []
  type: TYPE_NORMAL
- en: ^([25](ch06.html#idm45143404363328-marker)) The term *denominator problem* appears
    to have a very specific meaning when it comes to US property law, but needless
    to say, that is not precisely how I am using it here.
  prefs: []
  type: TYPE_NORMAL
- en: ^([26](ch06.html#idm45143404333728-marker)) And can be found at [*https://data.sba.gov/dataset/ppp-foia/resource/aab8e9f9-36d1-42e1-b3ba-e59c79f1d7f0*](https://data.sba.gov/dataset/ppp-foia/resource/aab8e9f9-36d1-42e1-b3ba-e59c79f1d7f0).
  prefs: []
  type: TYPE_NORMAL
