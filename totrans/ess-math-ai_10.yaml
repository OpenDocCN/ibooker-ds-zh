- en: Chapter 10\. Operations Research
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Many scientists owe their greatness not to their skill in solving problems
    but to their wisdom in choosing them*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: E. Bright Wilson (1908–1992), American chemist
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this chapter, we explore the integration of AI into the field of operations
    research, leveraging the best of both worlds for more efficient and more informed
    decision making. Although this introductory statement sounds like an ad, it is
    precisely what operations research is all about. Advances in machine learning
    can only help move the field forward.
  prefs: []
  type: TYPE_NORMAL
- en: 'Operations research is one of the most attractive and stimulating areas of
    applied mathematics. It is the science of balancing different needs and available
    resources in the most time and cost efficient ways. Many problems in operations
    research reduce to searching for an optimal point, the holy grail, at which everything
    functions smoothly and efficiently: No backups, no interruptions to timely services,
    no waste, balanced costs, and good revenues for everyone involved. A lot of applications
    never find the holy grail, but many operations reasearch methods allow us to come
    very close, at least for the simplified models of the complex reality. Constrained
    mathematical optimization penetrates every industry, every network, and every
    aspect of our lives. Done properly, we enjoy its benefits; done improperly, we
    suffer its impact: Global and local economies are still experiencing the ramifications
    of covid19, the war on Ukraine, and the eventual interruptions to the supply chain.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before exploring how machine learning is starting to make its way into operations
    research, we highlight few ideas that an interested person must internalize if
    they want to get involved in the field. Since we only have one chapter to spend
    on this beautiful topic, we must distill it into its essence:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The *no free lunch* theorem: This makes us shift our attention into devising
    and analyzing methods that work best for the special case scenario at hand, as
    opposed to looking for the most general and most widely applicable methods, like
    many mathematicians are naturally inclined to do. It essentially asks all these
    mathematicians to pretty much *chill*, and be satisfied with specialized solutions
    for specific types of problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Complexity analysis of problems and asymptotic analysis of algorithms*: *Asymptotic
    analysis* tells us that even if the algorithm is ultra innovative and genius,
    it is useless if its computational requirements skyrocket with the size the of
    the problem. Operations research solutions need to scale to big scenarios with
    many variables. *Complexity analysis*, on the other hand, addresses the *level
    of difficulty* of the problems themselves rather than the algorithms devised to
    tackle them. Combinatorial problems, which are <math alttext="upper O left-parenthesis
    n factorial right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <mi>n</mi> <mo>!</mo>
    <mo>)</mo></mrow></math> are ultra bad: <math alttext="n factorial"><mrow><mi>n</mi>
    <mo>!</mo></mrow></math> is bigger than <math alttext="k Superscript n"><msup><mi>k</mi>
    <mi>n</mi></msup></math> for n large enough, but an exponential <math alttext="k
    Superscript n"><msup><mi>k</mi> <mi>n</mi></msup></math> complexity would already
    be very bad!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Important topics and applications in operations research*: These we can find
    in any good book on operations research. We always need to keep one at hand. Moving
    from a specific application and business objectives to a mathematical formulation
    is the skill that cannot be stressed enough in order to thrive this field.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Various types of optimization methods and algorithms*: This is the workhorse
    of operations research solutions and software packages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Software packages*: The wide availability of these, along with the limited
    number of pages, are my excuse not to elaborate on anything algorithmic or computational
    in this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To sum operations research in six words: *Mathematical formulation, optimization,
    algorithms, software, and decisions*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When reading through this chapter, it is helpful to think of the concepts in
    the context of how the companies that we interact with in our daily lives manage
    their operations. Consider for example Amazon’s logistics. Amazon is the largest
    e-commerce company in the world. Its share of the US e-commerce market in 2022
    is 45%, selling and delivering millions of units of merchandise everyday, around
    $5000 in sales every second. How do they succeed at doing this? How do they manage
    their inventory, warehouses, transportation, and extremely efficient delivery
    system? How do they formulate their sub-problems and how do they integrate them
    into one big successful operation? Same with transportation logistics, such as
    Uber: Everyday Uber provides up to 15 million shared rides worldwide, matching
    available drivers with nearby riders, routing and timing pickups and drop offs,
    pricing trips, predicting driver revenues, supply and demand patterns, and performing
    countless analytics.'
  prefs: []
  type: TYPE_NORMAL
- en: The complex and highly interconnected optimization problems that allow such
    massive systems to run relatively smoothly are typical to operations research.
    Moreover, a lot of the involved problems are NP-hard (in computational complexity,
    this means they have nondeterministic polynomial time level of hardness- in English
    words, *very expensive to compute*). Add on top of that their stochastic nature,
    and we have interesting math problems that need to be solved.
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, the mathematical methods and algorithms of operations research save
    the world billions of dollars annually. A survey of the largest 500 companies
    in the United States showed that 85% of them use linear programming (which is
    another name for linear optimization, a massive part of operations research, and
    a reason we spend some descent time on the simplex method and duality in this
    chapter). Coupled with tools from the AI industry, now is the perfect time to
    get into the field. The rewards will be on many levels: Intellectual, financial,
    and meaningful contribution to the greater good of humanity. So in no way should
    the few selected topics for this chapter dim the significance of other equally
    important topics in the field.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To dive deeper into operations research (after reading this chapter, of course),
    the best way is to learn from the best:'
  prefs: []
  type: TYPE_NORMAL
- en: Browse through the winner and finalist projects of the [Franz Edelman Award
    for Achievement in Advanced Analytics, Operations Research, and Management Science](https://www.informs.org/Recognizing-Excellence/INFORMS-Prizes/Franz-Edelman-Award).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep the book *Introduction To Operations Research, by Hillier and Lieberman,
    McGraw Hill (2021)* close to your heart.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No Free Lunch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The *no free lunch theorems for optimization* states that there is no one particular
    optimization algorithm that works best for every problem. All algorithms that
    look for an optimizer of an objective function (cost function, loss function,
    utility function, likelihood function) have similar performance when averaged
    over all possible objective functions. So if some algorithm performs better than
    another on some class of objective functions, there are other objective functions
    where the other algorithm performs better. There is no superior algorithm that
    works for all kinds of problems. Therefore, picking an algorithm should be problem
    (or domain) dependent. Depending on our application area, there is plenty of information
    on which algorithms practitioners use, their justifications for why these are
    their chosen ones, their comparisons with others on both high dimensional and
    reasonable-dimension problems, and their constant attempts for better performace,
    which means two things: Faster (computationally less expensive), and more accurate.'
  prefs: []
  type: TYPE_NORMAL
- en: Complexity Analysis And O() Notation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Many times, the problem of *efficiently allocating limited resources* under
    *various constraints* boils down to devising efficient algorithms for *discrete*
    optimization. Linear programming, integer programming, combinatorial optimization,
    and optimization on graph structures (networks), are all interwined (sometimes
    these are nothing more than two different names for the same thing) and deal with
    one objective: Finding an optimizer from a *discrete and finite set* of valid
    options, the *feasible set*. If the feasible set is not discrete to start with,
    sometimes we can reduce it to a discrete set if we are to take advantage of the
    wealth of tools developed for this field. Here is the main issue: Exhaustive search
    is usually not tractable. This means that if we list all the available options
    in the feasible set and evaluate the objective function at each of them, we would
    spend an ungodly amount of time to find the point(s) that give the optimal answer.
    No one said that a finite feasible means that it is not enormous. We need specialized
    algorithms that efficiently rule out large swaths of the search space. Some algorithms
    pinpoint the exact solution for some poroblems and others can only find approximate
    solutions, which we have no option but to settle for.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now make the following distiction upfront, since this confuses a lot
    of people:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Complexity analysis is for the problems that we want solve** (routing, traveling
    saleman, knapsack, *etc.*). The intrinsic complexity of a problem is independent
    of the algorithms used to tackle it. In fact, it sometimes tells us that we cannot
    hope for a more efficient algorithm for such kind of problem, or whether we can
    do better in other cases. In any case, complexity analysis for problems is a rich
    science on its own, and the field of operations research provides a wealth of
    *complex* problems to ponder on. This is where the following terms appear: Polynomial
    problem, non-deterministic polynomial problem, non-deterministic polynomial complete
    problem, non-deterministic polynomial time hard problem, complement nondeterministic
    polynomial problem, and complement nondeterministic polynomial complete problem.
    The above terms are so confusing and someone seriously needs to reconsider their
    nomenclature. We will not define each here (mainly because the theory is not yet
    set on the boundaries between these classes of problems), but we will make the
    following divide: Problems that can be solved in polynomial time or less, and
    problems for which we cannot find an exact solution in polynomial time, no matter
    what algorithm is used, in which case, we have to settle for approximation algorithms
    (for example, the traveling salesman problem). Note that sometimes polynomial
    time problems might not be such a great thing, because for example <math alttext="upper
    O left-parenthesis n squared 000 right-parenthesis"><mrow><mi>O</mi> <mo>(</mo>
    <msup><mi>n</mi> <mn>2</mn></msup> <mn>000</mn> <mo>)</mo></mrow></math> is not
    so fast afterall.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Asymptotic analysis is for the algorithms that we design to solve these problems**.
    This is where we attempt to estimate the number of operations that the algorithm
    requires and quantify it relative to the size of the problem. We usually use the
    big *O* notation, which means the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Big O() notation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A function *g(n)* is *O(f(n))* when <math alttext="g left-parenthesis n right-parenthesis
    less-than-or-equal-to c f left-parenthesis n right-parenthesis"><mrow><mi>g</mi>
    <mo>(</mo> <mi>n</mi> <mo>)</mo> <mo>≤</mo> <mi>c</mi> <mi>f</mi> <mo>(</mo> <mi>n</mi>
    <mo>)</mo></mrow></math> for some constant *c*, and for all <math alttext="n greater-than-or-equal-to
    n 0"><mrow><mi>n</mi> <mo>≥</mo> <msub><mi>n</mi> <mn>0</mn></msub></mrow></math>
    .
  prefs: []
  type: TYPE_NORMAL
- en: For example, *2n+1* is *O(n)*, <math alttext="5 n cubed minus 7 n squared plus
    1"><mrow><mn>5</mn> <msup><mi>n</mi> <mn>3</mn></msup> <mo>-</mo> <mn>7</mn> <msup><mi>n</mi>
    <mn>2</mn></msup> <mo>+</mo> <mn>1</mn></mrow></math> is <math alttext="upper
    O left-parenthesis n cubed right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>n</mi>
    <mn>3</mn></msup> <mo>)</mo></mrow></math> , <math alttext="n squared 2 Superscript
    n minus 55 n Superscript 1 Baseline 00"><mrow><msup><mi>n</mi> <mn>2</mn></msup>
    <msup><mn>2</mn> <mi>n</mi></msup> <mo>-</mo> <mn>55</mn> <msup><mi>n</mi> <mn>1</mn></msup>
    <mn>00</mn></mrow></math> is <math alttext="upper O left-parenthesis n squared
    2 Superscript n Baseline right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>n</mi>
    <mn>2</mn></msup> <msup><mn>2</mn> <mi>n</mi></msup> <mo>)</mo></mrow></math>
    , <math alttext="15 n l o g left-parenthesis n right-parenthesis minus 5 n"><mrow><mn>15</mn>
    <mi>n</mi> <mi>l</mi> <mi>o</mi> <mi>g</mi> <mo>(</mo> <mi>n</mi> <mo>)</mo> <mo>-</mo>
    <mn>5</mn> <mi>n</mi></mrow></math> is <math alttext="upper O left-parenthesis
    n l o g left-parenthesis n right-parenthesis right-parenthesis"><mrow><mi>O</mi>
    <mo>(</mo> <mi>n</mi> <mi>l</mi> <mi>o</mi> <mi>g</mi> <mo>(</mo> <mi>n</mi> <mo>)</mo>
    <mo>)</mo></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: Do not forget the constant asymptotics case *O(1)*, where the operation count
    of an algorithm is independent of the size of the problem (awesome thing, because
    this means that it scale without any worries to enormous problems).
  prefs: []
  type: TYPE_NORMAL
- en: For some algorithms, we can count the exact number of operations, for example,
    to compute the scalar product (dot product) of two vectors of length *n*, a simple
    algorithm uses exactly 2n-1 multiplications and additions, which makes it *O(n)*.
    For multiplying two matrices each of size <math alttext="n times n"><mrow><mi>n</mi>
    <mo>×</mo> <mi>n</mi></mrow></math> , a simple algorithm computing the dot product
    of each row from the first matrix with each column from the second matrix requires
    exactly <math alttext="left-parenthesis 2 n minus 1 right-parenthesis n squared"><mrow><mrow><mo>(</mo>
    <mn>2</mn> <mi>n</mi> <mo>-</mo> <mn>1</mn> <mo>)</mo></mrow> <msup><mi>n</mi>
    <mn>2</mn></msup></mrow></math> operations, so this will be <math alttext="upper
    O left-parenthesis n cubed right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>n</mi>
    <mn>3</mn></msup> <mo>)</mo></mrow></math> . Matrix inversion is also usually
    <math alttext="upper O left-parenthesis n cubed right-parenthesis"><mrow><mi>O</mi>
    <mo>(</mo> <msup><mi>n</mi> <mn>3</mn></msup> <mo>)</mo></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: For anyone interested in asymptotic analysis for algorithms, it quickly becomes
    obvious that it is slightly more involved than operation counts, because sometimes
    we have to make estimates or averages on the size of input (what does *n* stand
    for?), how to count the operations in an algorithm (by each line of code?), and
    we cannot ignore the fact that doing computations on large numbers is more consuming
    in time and memory than doing operations on smaller numbers. Finally, we prefer
    algorithms that run in polynomial time or less and not in exponential time or
    more. Let’s demonstrate with a very simple example.
  prefs: []
  type: TYPE_NORMAL
- en: Polynomial algorithm <math alttext="upper O left-parenthesis n Superscript k
    Baseline right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>n</mi> <mi>k</mi></msup>
    <mo>)</mo></mrow></math> vs exponential algorithm <math alttext="upper O left-parenthesis
    k Superscript n Baseline right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>k</mi>
    <mi>n</mi></msup> <mo>)</mo></mrow></math>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Suppose we are working on a machine that is able to execute <math alttext="10
    Superscript 7"><msup><mn>10</mn> <mn>7</mn></msup></math> operations per second
    (10 million). Let’s run it for 1000 seconds which is around 16 minutes on two
    different algorithms, one exponential in the size of the problem, say, <math alttext="upper
    O left-parenthesis 2 Superscript n Baseline right-parenthesis"><mrow><mi>O</mi>
    <mo>(</mo> <msup><mn>2</mn> <mi>n</mi></msup> <mo>)</mo></mrow></math> and the
    other polynomial <math alttext="upper O left-parenthesis n cubed right-parenthesis"><mrow><mi>O</mi>
    <mo>(</mo> <msup><mi>n</mi> <mn>3</mn></msup> <mo>)</mo></mrow></math> . The size
    of the problem is *n* in this case, and refers to a measure of the dimensionality
    of the input, for example the number of nodes of a graph, the number of entries
    of a matrix, the number of features of a data set or the number of instances.
    What is the largest size problem that each algorithm can handle for 16 minutes
    on this machine?
  prefs: []
  type: TYPE_NORMAL
- en: For the exponential time algorithm, the number of operations it requires is
    at most (worst case scenario) <math alttext="c 2 Superscript n Baseline equals
    10 Superscript 7 Baseline asterisk 1000"><mrow><mi>c</mi> <msup><mn>2</mn> <mi>n</mi></msup>
    <mo>=</mo> <msup><mn>10</mn> <mn>7</mn></msup> <mo>*</mo> <mn>1000</mn></mrow></math>
    for some preferably small *c*. Thus, the size of the problem it can run for a
    1000 seconds with 10 million operations per second is <math alttext="n equals
    10 log Subscript 2 Baseline left-parenthesis 10 right-parenthesis minus log Subscript
    2 Baseline left-parenthesis c right-parenthesis almost-equals 33"><mrow><mi>n</mi>
    <mo>=</mo> <mn>10</mn> <msub><mo form="prefix">log</mo> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mn>10</mn> <mo>)</mo></mrow> <mo>-</mo> <msub><mo form="prefix">log</mo> <mn>2</mn></msub>
    <mrow><mo>(</mo> <mi>c</mi> <mo>)</mo></mrow> <mo>≈</mo> <mn>33</mn></mrow></math>
    .
  prefs: []
  type: TYPE_NORMAL
- en: Now contrast this with the polynomial time algorithm, whose worst case is <math
    alttext="c n cubed equals 10 Superscript 7 Baseline asterisk 1000"><mrow><mi>c</mi>
    <msup><mi>n</mi> <mn>3</mn></msup> <mo>=</mo> <msup><mn>10</mn> <mn>7</mn></msup>
    <mo>*</mo> <mn>1000</mn></mrow></math> , so <math alttext="n equals StartFraction
    1 Over cubed StartRoot c EndRoot EndFraction cubed StartRoot 10 Superscript 10
    Baseline EndRoot almost-equals 2100"><mrow><mi>n</mi> <mo>=</mo> <msup><mfrac><mn>1</mn>
    <mrow><msup><mn>3</mn></msup> <msqrt><mi>c</mi></msqrt></mrow></mfrac> <mn>3</mn></msup>
    <msqrt><msup><mn>10</mn> <mn>10</mn></msup></msqrt> <mo>≈</mo> <mn>2100</mn></mrow></math>
    . This is almost two orders of magnitude larger than exponential time algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The conclusion is that given the same hardware and amount of time, polynomial
    time algorithms <math alttext="upper O left-parenthesis n Superscript k Baseline
    right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>n</mi> <mi>k</mi></msup>
    <mo>)</mo></mrow></math> allow us to solve much larger problems than exponential
    time algorithms <math alttext="upper O left-parenthesis k Superscript n Baseline
    right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>k</mi> <mi>n</mi></msup>
    <mo>)</mo></mrow></math> . Combinatorial time algorithms <math alttext="upper
    O left-parenthesis n factorial right-parenthesis"><mrow><mi>O</mi> <mo>(</mo>
    <mi>n</mi> <mo>!</mo> <mo>)</mo></mrow></math> are hopeless. Moreover, we *always*
    want *k* to be small. The smaller the better.
  prefs: []
  type: TYPE_NORMAL
- en: 'A person who is used to operating in *exact* realms and not in *approximate*
    or *asymptotic* realms might be troubled by the above discussion, because sometimes,
    some higher order algorithms are better for smaller size problems than lower order
    ones. For example: Suppose the exact operation count of an *O(n)* algorithm is
    20n-99, and that of an <math alttext="upper O left-parenthesis n squared right-parenthesis"><mrow><mi>O</mi>
    <mo>(</mo> <msup><mi>n</mi> <mn>2</mn></msup> <mo>)</mo></mrow></math> is <math
    alttext="n squared plus 1"><mrow><msup><mi>n</mi> <mn>2</mn></msup> <mo>+</mo>
    <mn>1</mn></mrow></math> , then it is true that asymptotically (or for large enough
    *n*), the *O(n)* algorithm is better than the <math alttext="upper O left-parenthesis
    n squared right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>n</mi> <mn>2</mn></msup>
    <mo>)</mo></mrow></math> , but that is not the case if *n* is smaller than 10,
    because in this case, <math alttext="n squared plus 1 less-than 20 n minus 99"><mrow><msup><mi>n</mi>
    <mn>2</mn></msup> <mo>+</mo> <mn>1</mn> <mo><</mo> <mn>20</mn> <mi>n</mi> <mo>-</mo>
    <mn>99</mn></mrow></math> . This is okay for small enough problems, but never
    for larger problems.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Two optimization methods that we will soon mention in this chapter are the
    simplex method and interior point method for linear optimization (optimization
    where both the objective function and the constraints are linear). The interior
    point method is polynomial time algorithm and the simplex method is exponential
    time, so you’d expect that everyone would use the cheaper interior point and abandon
    simplex, but this is not true. The simplex method (and the dual simplex) is still
    widely used for linear optimization instead of interior point because that exponential
    time is a worst case scenario and most applications are not worst cases. Moreover,
    there are usually tradeoffs between algorithms in terms of: Computational effort
    per iteration, number of iterations required, the effect of better starting points,
    does the algorithm converge or will it need *extra help* near the end, how much
    computation this extra help would require, and can the algorithm take advantage
    of parallel processing? For this reason, computer packages for linear optimization
    have efficient implementations of both the simplex and the interior point methods
    (and many other algorithms as well). Ultimately, we choose what works best for
    our use cases.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Optimization: The Heart Of Operations Research'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We found our way back to optimization. In machine learning, optimization is
    about minimizing the loss function for models that learn deterministic functions
    or maximizing the likelihood function for models that learn probability distributions.
    We do not want a solution that matches the data exactly, since that would not
    generalize well to unseen data. Hence regularization methods, early stopping,
    and others. In machine learning, we use the available data to learn the model:
    The deterministic function or the probability distribution that are the source
    of the data (the data generating rule or process), then we use this learned function
    or distribution to make inference. Optimization is just one step along the way:
    Minimize the loss function, with or without regularization terms. The loss functions
    that appear in machine learning are usually differentiable and nonlinear, and
    the optimization is unconstrained. We can add constraints to *guide* the process
    into some desired realm, depending on the application.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Methods for optimization can either include computing derivatives of the objective
    function <math alttext="f left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    , such as machine learning’s favorite gradient descent (stochastic gradient descent,
    ADAM, *etc.*), or not. There are optimization algorithms that are derivative free:
    These are very useful when the objective function is not differentiable (such
    as functions with corners) or when the formula of the objective function is not
    even available. Examples of derivative free optimization methods include Bayesian
    search, Cuckoo search, and genetic algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Optimization, *in particular linear optimization*, has been the heart of operations
    research since the Second World War, when methods for linear optimization such
    as the *simplex method* were developed to aid in military logistics and operations.
    The goal, as always, is to minimize an objective function (cost, distance, time,
    *etc.*) given certain constraints (budget, deadlines, capacity, *etc.*):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign m i n Subscript c o n s t r a i n t s Baseline f
    left-parenthesis ModifyingAbove x With right-arrow right-parenthesis dollar-sign"><mrow><mi>m</mi>
    <mi>i</mi> <msub><mi>n</mi> <mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow></msub>
    <mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn optimization for operations research, a typical course usually spends
    a lot of time on linear optimization, integer optimization, and optimization on
    networks (graphs), since many real life logistics and resource allocation problems
    fit perfectly into these formulations. To become thriving operations researchers,
    we need to learn:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear optimization**, where both the objective function and the constraints
    are linear: Here we learn about the simplex method, duality, [Lagrangian relaxation](http://www.mi.fu-berlin.de/wiki/pub/Main/GunnarKlauP1winter0708/discMath_klau_script_lag_I.pdf),
    and sensitivity analysis. In linear problems, the boundaries of our world are
    flat, made of lines, planes and hyperplanes. This (hyper)polygonal geometry, or
    *polyhedron*, usually has corner points which are candidates for being optimizers,
    so we devise systematic ways to sift through these points and test them for optimality
    (this is what the simplex method and the dual simplex method do).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interior point methods**: For large scale linear optimization problems which
    could be beyond the reach of the simplex method. In short, the simplex method
    goes around the *boundary* of the feasible search space (the edges of the polyhedron),
    checks each corner it arrives at for optimality, then moves to another corner
    at the boundary. The interior point method, on the other hand, goes *through the
    interior* of the feasible search space, arriving at an optimal corner form the
    inside of the feasible search space as opposed to from the boundary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integer programming**: Optimization where the entries of the optimizing vector
    must all be integers. Sometimes they can only be zero or one (send the truck to
    the warehouse in Ohio or not). The [knapsack problem](https://en.wikipedia.org/wiki/Knapsack_problem)
    is a very simple prototype example. Here we learn about the branch and bound method
    for large integer programming problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimization on networks**: We can reformulate many network problems as linear
    optimization problems where the simplex methods and specialized versions of it
    work, but it is much better to exploit the network structure and tap into useful
    results from graph theory, such as the max flow min cut theorem, for more efficient
    algorithms. Many problems on networks boil down to optimizing for one of the following:
    Shortest path on the network (path from one node to another with minimum distance
    or minimum cost), minimum spanning tree of a network (this is great for optimizing
    *the design* of networks), maximum flow (from origin to destination or from source
    to sink), minimum cost flow; multicommodity flow; or traveling salesman: Finding
    the minimum cost (or distance or weight) cyclic route that passes through all
    the network’s nodes only once (Hamiltonian circuit).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Nonlinear optimization**: The objective function and/or the constraints are
    nonlinear: One recurring example throughout this book is minimizing nonlinear
    loss functions for machine learning models. These are always nonlinear, and we
    commonly use gradient descent type algorithms. For smaller problems we can use
    Newton type algorithms (second derivatives). In operations research, nonlinearities
    in the objective function and/or constraints might appear because the cost of
    shipping goods from one location to another might not be fixed (for example depends
    on the distance or on the quantity), or a flow through a network might include
    losses or gains. A special type of nonlinear optimization that we know a lot about
    is *quadratic* optimization with linear constraints. This appears in applications
    such as network equations for electric circuits, and elasticity theory for structures
    where we consider displacements, stresses, strains, and balance of forces in a
    structure. Think of how easy it is to find the minimum of the quadratic function
    <math alttext="f left-parenthesis x right-parenthesis equals s x squared"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>s</mi> <msup><mi>x</mi>
    <mn>2</mn></msup></mrow></math> , where *s* is a positive constant. This ease
    translates nicely to higher dimensions, where our objective function looks like
    <math alttext="f left-parenthesis ModifyingAbove x With right-arrow right-parenthesis
    equals ModifyingAbove x With right-arrow Superscript t Baseline upper S ModifyingAbove
    x With right-arrow"><mrow><mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>=</mo> <msup><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mi>t</mi></msup> <mi>S</mi> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></mrow></math> where *S* is a positive semidefinite matrix,
    playing the same role for high dimensions as a positive constant for one dimension.
    Here we even have duality theory that we can take advantage of, similar to the
    linear optimization case. In optimization, when we lose linearity, we hope our
    functions are quadratic and our constraints are linear. When we lose that, we
    hope our functions and/or feasible set are convex. When we lose convexity, we
    are all on our own, hoping our methods don’t get stuck at local minima of high
    dimensional landscapes, and somehow find their way to optimal solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dynamic programming and Markov decision processes**: Dynamic programming
    has to do with projects with multiple stages, where decisions have to be made
    at each stage, and each decision generates some immediate cost. The decision at
    each stage has to do with the current state, together with a policy to transition
    to the next state (choose the next state via a minimization of a deterministic
    function or a probability). Dynamic programming is all about devising efficient
    ways, usually recursive methods, to finding the *optimal sequence of interrelated
    decisions* to fulfill a certain goal. The idea is to avoid having to list all
    the options for each stage of the decision process, then selecting the best combination
    of decisions. Such an exhaustive search is extremely expensive for problems with
    many decision stages each having many states. Now if the transition policy from
    one stage to the other is probabilistic rather than deterministic, and if the
    stages of the decision process continue to recur indefinitely, meaning if the
    project has an infinite number of stages, then we have a Markov decision process
    (or Markov chain) on our hands. This is a process that evolves over time in a
    probabilistic manner. A very special property of a Markov decision process is
    that the probabilities involving how the process evolves in the future is independent
    of past events, and depend only on the system’s *current state*. Both discrete
    time and continuous time Markov chains model important systems, such as [queueing
    systems](https://www.sciencedirect.com/topics/computer-science/queueing-system),
    dynamic traffic light control to minimize car waiting time, and flexible call
    center staffing. The important math objects are the transition matrix and people
    solve for the steady state probabilities. They end up having to compute the eigenspace
    of the transition matrix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stochastic algorithms**: Dynamic programming with probabilistic transition
    policy and Markov chain are both examples of stochastic algorithms. So are stochastic
    gradient descent and random walks on graphs. Any algorithm that involves an element
    of randomness is stochastic. The mathematics transitions to the language of probabilities,
    expectations, stationary states, convergence, *etc.* Another example where stochastic
    algorithms and analysis of processes appear is *queueing theory*, such as queues
    at a hospital emergency room or at a ship maintainance yard. This builds on probability
    distributions of arrival times of customers and service times by the service facility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metaheuristics**: For many optimization problems, finding the optimal solution
    might be impractical, so people (who still need to make decisions) resort to *heuristic
    methods*, which find an *answer* (I will not call it a solution) which is not
    necessarily optimal, but is good enough for the problem at hand. Metaheuristics
    are general solution methods that provide strategy guidelines and general frameworks
    for developing heuristic methods to fit certain families of problems. We cannot
    guarantee the optimality of an answer from a heuristic method, but heuristics
    do speed up the process of finding satisfactory solutions where optimal solutions
    too expensive to compute or completely are out of reach. There is also the topic
    of *satisfiability*: Since problems in operations research are almost always constrained,
    the natural question is: Are the constraints satisfiable? Meaning is the feasible
    set nonempty? Some operations research problems get reformulated as satisfiability
    problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In real world problems, a big part of the work of operations research departments
    is formulating their specific use cases and objectives in a way that can fit into
    one of the above optimization frameworks. Here it is important to recognize special
    structures (such as sparsity in the involved matrices) or substructures that we
    can exploit for more efficient algorithms. This is crucial for complicated and
    large scale systems.
  prefs: []
  type: TYPE_NORMAL
- en: Thinking About Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we encounter an optimization problem in mathematics,
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript ModifyingAbove x With right-arrow
    element-of some feasible set Endscripts f left-parenthesis ModifyingAbove x With
    right-arrow right-parenthesis comma dollar-sign"><mrow><msub><mo form="prefix"
    movablelimits="true">min</mo> <mrow><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>∈</mo><mtext>some</mtext><mtext>feasible</mtext><mtext>set</mtext></mrow></msub>
    <mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>,</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'where the feasible set is defined by some constraints that the vector <math
    alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    must satisfy (or it could be totally unconstrained), we usually pause and brainstorm
    a little:'
  prefs: []
  type: TYPE_NORMAL
- en: Is <math alttext="f left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    linear?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is <math alttext="f left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    convex? Bounded below?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the minimum value finite, or does it <math alttext="negative normal infinity"><mrow><mo>→</mo>
    <mo>-</mo> <mi>∞</mi></mrow></math> ?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the feasible set nonempty? Meaning are there <math alttext="ModifyingAbove
    x With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    ’s that actually satisfy the constraints?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the feasible set convex?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does a minimizer exist?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is a minimizer unique, or are there others?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we find the minimizer?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the value of the minimum?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much does minimizer and the value of the minimum change if something changes
    in our constraints or in our objective function?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on the type of problem at hand, we might be able to answer the above
    questions independently, meaning sometimes we can answer only some of them and
    not others. This fine because any information about the optimizer and the value
    of the optimum is valuable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s explore common types of optimization problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Optimization- Finite Dimensions- Unconstrained
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is similar to the optimization that we do in calculus classes, and the
    optimization we do when training a machine learning model, minimizing the loss
    function. The objective function <math alttext="f left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> is differentiable:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript ModifyingAbove x With right-arrow
    element-of double-struck upper R Superscript d Baseline Endscripts f left-parenthesis
    ModifyingAbove x With right-arrow right-parenthesis period dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mrow><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover><mo>∈</mo><msup><mi>ℝ</mi> <mi>d</mi></msup></mrow></msub> <mi>f</mi>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: In unconstrained and differentiable optimization, the minimizer <math alttext="ModifyingAbove
    x With right-arrow Superscript asterisk"><msup><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>*</mo></msup></math> satisfies <math alttext="normal nabla
    f left-parenthesis ModifyingAbove x With right-arrow right-parenthesis equals
    0"><mrow><mi>∇</mi> <mi>f</mi> <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo> <mo>=</mo> <mn>0</mn></mrow></math> . Moreover, the Hessian (matrix
    of second derivatives) is positive semidefinite at <math alttext="ModifyingAbove
    x With right-arrow Superscript asterisk"><msup><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>*</mo></msup></math> . When discussing optimization for
    machine learning we settled on stochastic gradient descent and its variants for
    very high dimensional problems. For smaller problems Newton type (working with
    second derivatives not only first ones) methods work as well. For very few problems
    such a the mean squared error loss function for linear regression, we can get
    analytical solutions. Examples where we can get analytical solutions are usually
    carefully constructed (such as all the examples in our calculus books), and very
    low dimensional.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization- Finite Dimensions- Constrained- Lagrange Multipliers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s think of the case where we only have one constraint <math alttext="g
    left-parenthesis ModifyingAbove x With right-arrow right-parenthesis equals b"><mrow><mi>g</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo> <mo>=</mo>
    <mi>b</mi></mrow></math> . This explains what we need rather well. The minimization
    problem looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column g left-parenthesis ModifyingAbove x With right-arrow right-parenthesis
    equals b 2nd Row 1st Column Blank 2nd Column x element-of double-struck upper
    R Superscript d Baseline EndLayout Endscripts f left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis period dollar-sign"><mrow><msub><mo form="prefix"
    movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mi>g</mi><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo><mo>=</mo><mi>b</mi></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mrow><mi>x</mi><mo>∈</mo><msup><mi>ℝ</mi> <mi>d</mi></msup></mrow></mtd></mtr></mtable></msub>
    <mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If <math alttext="f left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    and <math alttext="g left-parenthesis ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>g</mi>
    <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    are differentiable functions from <math alttext="double-struck upper R Superscript
    d Baseline right-arrow double-struck upper R"><mrow><msup><mi>ℝ</mi> <mi>d</mi></msup>
    <mo>→</mo> <mi>ℝ</mi></mrow></math> , we can introduce Lagrange multipliers (a
    method from 1797) to change our problem into an *unconstrained* one, but in higher
    dimensions (corresponding to the new Lagrange multipliers that we introduce to
    the optimization problem). Nothing is free. In this case, we add a multiple of
    our constraint to the objective function, then minimize, which means look for
    the points where the gradient is zero. The new objective function for the unconstrained
    problem is called the Lagrangian, and it is a function of both the decision vector
    <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> and the new variable <math alttext="lamda"><mi>λ</mi></math>
    which we multiplied by our constraint, called the *Lagrange multiplier*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign script upper L left-parenthesis ModifyingAbove x
    With right-arrow semicolon lamda right-parenthesis equals f left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis plus lamda left-parenthesis b minus g left-parenthesis
    ModifyingAbove x With right-arrow right-parenthesis right-parenthesis period dollar-sign"><mrow><mi>ℒ</mi>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo>
    <mi>λ</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>+</mo> <mi>λ</mi> <mrow><mo>(</mo> <mi>b</mi>
    <mo>-</mo> <mi>g</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: If we have more than one constraint, say five constraints, then we introduce
    a Lagrange multiplier for each, ending up with adding five extra dimensions to
    our optimization problem, inorder to move it from the constrained regime to the
    unconstrained one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The optimizer <math alttext="left-parenthesis ModifyingAbove x With right-arrow
    Superscript asterisk Baseline comma lamda Superscript asterisk Baseline right-parenthesis"><mrow><mo>(</mo>
    <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mo>,</mo>
    <msup><mi>λ</mi> <mo>*</mo></msup> <mo>)</mo></mrow></math> of the unconstrained
    problem must satisfy: <math alttext="normal nabla script upper L left-parenthesis
    ModifyingAbove x With right-arrow semicolon lamda right-parenthesis equals 0"><mrow><mi>∇</mi>
    <mi>ℒ</mi> <mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo>
    <mi>λ</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn></mrow></math> . We go about finding
    it the same way we go about general unconstrained problems (see the previous case).
    The <math alttext="ModifyingAbove x With right-arrow Superscript asterisk"><msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup></math> from <math
    alttext="left-parenthesis ModifyingAbove x With right-arrow Superscript asterisk
    Baseline comma lamda Superscript asterisk Baseline right-parenthesis"><mrow><mo>(</mo>
    <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mo>,</mo>
    <msup><mi>λ</mi> <mo>*</mo></msup> <mo>)</mo></mrow></math> *is the solution of
    the constrained problem* that we were originally searching for. This means that
    it is the point on the hypersurface defined by the constraint <math alttext="g
    left-parenthesis ModifyingAbove x With right-arrow Superscript asterisk Baseline
    right-parenthesis equals b"><mrow><mi>g</mi> <mo>(</mo> <msup><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>*</mo></msup> <mo>)</mo> <mo>=</mo> <mi>b</mi></mrow></math>
    where the value of *f* is smallest.'
  prefs: []
  type: TYPE_NORMAL
- en: If the problem has a special structure that we can exploit, such as if *f* is
    quadratic and the constraint *g* is linear, or if both *f* and *g* are linear,
    then we have more convenient methods to go about this constrained optimization,
    both if we decide to use Lagrange multipliers (which introduces duality) and without
    using Lagrange multipliers. Luckily optimization problems with simple structures
    are very well studied, not only because they make the mathematics and computations
    easier, but also because they appear all the time in science and in real life
    applications, which gives some credibility to my theory that nature is simpler
    than mathematicians think it is. We will revisit Lagrange multipliers for constrained
    problems in the section on duality, where we focus solely on fully linear problems
    or on quadratic problems with linear constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 'The nice thing that we should make a permanent mental note of is that the Lagrange
    multiplier <math alttext="lamda"><mi>λ</mi></math> is not some worthless auxiliary
    scalar that helped us change a constrained problem into an unconstrained one.
    It has a meaning that is very helpful for sensitivity analysis, for finance and
    operations research applications, and for duality theory (which are all related
    to each other). Mathematically, by observing the formula of the Lagrangian <math
    alttext="script upper L left-parenthesis ModifyingAbove x With right-arrow semicolon
    lamda right-parenthesis equals f left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis plus lamda left-parenthesis b minus g left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis right-parenthesis"><mrow><mi>ℒ</mi> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo> <mi>λ</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>+</mo> <mi>λ</mi> <mrow><mo>(</mo> <mi>b</mi> <mo>-</mo>
    <mi>g</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math> , <math alttext="lamda"><mi>λ</mi></math>
    is the rate of change of the Lagrangian as a function of *b*, if we were allowed
    to vary *b* (the value of the constraint; in applications we care about the effect
    of pushing or relaxing the constraints). That is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartFraction normal partial-differential script
    upper L left-parenthesis left-parenthesis ModifyingAbove x With right-arrow semicolon
    lamda comma b right-parenthesis right-parenthesis Over normal partial-differential
    b EndFraction equals StartFraction normal partial-differential f left-parenthesis
    ModifyingAbove x With right-arrow right-parenthesis plus lamda left-parenthesis
    b minus g left-parenthesis ModifyingAbove x With right-arrow right-parenthesis
    right-parenthesis Over normal partial-differential b EndFraction equals StartFraction
    normal partial-differential f left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis Over normal partial-differential b EndFraction plus StartFraction
    lamda left-parenthesis b minus g left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis right-parenthesis Over normal partial-differential b EndFraction
    equals 0 plus lamda equals lamda period dollar-sign"><mrow><mfrac><mrow><mi>∂</mi><mi>ℒ</mi><mo>(</mo><mrow><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>;</mo><mi>λ</mi><mo>,</mo><mi>b</mi><mo>)</mo></mrow><mo>)</mo></mrow>
    <mrow><mi>∂</mi><mi>b</mi></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>f</mi><mrow><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow><mo>+</mo><mi>λ</mi><mrow><mo>(</mo><mi>b</mi><mo>-</mo><mi>g</mi><mrow><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow><mo>)</mo></mrow></mrow>
    <mrow><mi>∂</mi><mi>b</mi></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>f</mi><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow> <mrow><mi>∂</mi><mi>b</mi></mrow></mfrac>
    <mo>+</mo> <mfrac><mrow><mi>λ</mi><mo>(</mo><mi>b</mi><mo>-</mo><mi>g</mi><mrow><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow><mo>)</mo></mrow>
    <mrow><mi>∂</mi><mi>b</mi></mrow></mfrac> <mo>=</mo> <mn>0</mn> <mo>+</mo> <mi>λ</mi>
    <mo>=</mo> <mi>λ</mi> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, we can interpret the optimal value <math alttext="lamda Superscript
    asterisk"><msup><mi>λ</mi> <mo>*</mo></msup></math> corresponding to the optimizer
    <math alttext="ModifyingAbove x With right-arrow Superscript asterisk"><msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup></math> as *the marginal
    effect of b* on the optimal attainable value of the objective function <math alttext="f
    left-parenthesis ModifyingAbove x With right-arrow Superscript asterisk Baseline
    right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <msup><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>*</mo></msup> <mo>)</mo></mrow></math> . Hence, if <math
    alttext="lamda Superscript asterisk Baseline equals 2.1"><mrow><msup><mi>λ</mi>
    <mo>*</mo></msup> <mo>=</mo> <mn>2</mn> <mo>.</mo> <mn>1</mn></mrow></math> ,
    then increasing *b* by one unit (pushing the constraint by one unit) will increase
    the optimal value of *f* by *2.1* units. This is very valuable information for
    applications in finance and operations research. Let’s see why this is the case.
    We want to prove that:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartFraction d f left-parenthesis ModifyingAbove
    x With right-arrow Superscript asterisk Baseline left-parenthesis b right-parenthesis
    right-parenthesis Over d b EndFraction equals lamda Superscript asterisk Baseline
    period dollar-sign"><mrow><mfrac><mrow><mi>d</mi><mi>f</mi><mo>(</mo><msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mrow><mo>(</mo><mi>b</mi><mo>)</mo></mrow><mo>)</mo></mrow>
    <mrow><mi>d</mi><mi>b</mi></mrow></mfrac> <mo>=</mo> <msup><mi>λ</mi> <mo>*</mo></msup>
    <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that two things happen at the optimizer <math alttext="ModifyingAbove
    x With right-arrow Superscript asterisk Baseline left-parenthesis b right-parenthesis"><mrow><msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mrow><mo>(</mo>
    <mi>b</mi> <mo>)</mo></mrow></mrow></math> , which we get when we set the gradient
    of the Lagrangian to zero: <math alttext="normal nabla f left-parenthesis ModifyingAbove
    x With right-arrow Superscript asterisk Baseline left-parenthesis b right-parenthesis
    right-parenthesis equals lamda Superscript asterisk Baseline normal nabla g left-parenthesis
    ModifyingAbove x With right-arrow Superscript asterisk Baseline left-parenthesis
    b right-parenthesis right-parenthesis"><mrow><mi>∇</mi> <mi>f</mi> <mrow><mo>(</mo>
    <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mrow><mo>(</mo>
    <mi>b</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>λ</mi> <mo>*</mo></msup>
    <mi>∇</mi> <mi>g</mi> <mrow><mo>(</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>*</mo></msup> <mrow><mo>(</mo> <mi>b</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
    , and <math alttext="g left-parenthesis ModifyingAbove x With right-arrow Superscript
    asterisk Baseline left-parenthesis b right-parenthesis right-parenthesis equals
    b"><mrow><mi>g</mi> <mo>(</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>*</mo></msup> <mrow><mo>(</mo> <mi>b</mi> <mo>)</mo></mrow> <mo>)</mo> <mo>=</mo>
    <mi>b</mi></mrow></math> . Using this information and the chain rule for derivatives
    (go back to your calculus book and master the chain rule, we use it all the time),
    we now have:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign StartFraction d f left-parenthesis ModifyingAbove
    x With right-arrow Superscript asterisk Baseline left-parenthesis b right-parenthesis
    right-parenthesis Over d b EndFraction equals normal nabla f left-parenthesis
    ModifyingAbove x With right-arrow Superscript asterisk Baseline left-parenthesis
    b right-parenthesis right-parenthesis period StartFraction d ModifyingAbove x
    With right-arrow Superscript asterisk Baseline left-parenthesis b right-parenthesis
    Over d b EndFraction equals lamda Superscript asterisk Baseline normal nabla g
    left-parenthesis ModifyingAbove x With right-arrow Superscript asterisk Baseline
    left-parenthesis b right-parenthesis right-parenthesis StartFraction d ModifyingAbove
    x With right-arrow Superscript asterisk Baseline left-parenthesis b right-parenthesis
    Over d b EndFraction equals lamda Superscript asterisk Baseline StartFraction
    d g left-parenthesis ModifyingAbove x With right-arrow Superscript asterisk Baseline
    left-parenthesis b right-parenthesis right-parenthesis Over d b EndFraction equals
    lamda Superscript asterisk Baseline StartFraction d b Over d b EndFraction equals
    lamda Superscript asterisk Baseline times 1 equals lamda Superscript asterisk
    Baseline period dollar-sign"><mrow><mfrac><mrow><mi>d</mi><mi>f</mi><mo>(</mo><msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mrow><mo>(</mo><mi>b</mi><mo>)</mo></mrow><mo>)</mo></mrow>
    <mrow><mi>d</mi><mi>b</mi></mrow></mfrac> <mo>=</mo> <mi>∇</mi> <mi>f</mi> <mrow><mo>(</mo>
    <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mrow><mo>(</mo>
    <mi>b</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>.</mo> <mfrac><mrow><mi>d</mi><msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mrow><mo>(</mo><mi>b</mi><mo>)</mo></mrow></mrow>
    <mrow><mi>d</mi><mi>b</mi></mrow></mfrac> <mo>=</mo> <msup><mi>λ</mi> <mo>*</mo></msup>
    <mi>∇</mi> <mi>g</mi> <mrow><mo>(</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>*</mo></msup> <mrow><mo>(</mo> <mi>b</mi> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mfrac><mrow><mi>d</mi><msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>*</mo></msup> <mrow><mo>(</mo><mi>b</mi><mo>)</mo></mrow></mrow> <mrow><mi>d</mi><mi>b</mi></mrow></mfrac>
    <mo>=</mo> <msup><mi>λ</mi> <mo>*</mo></msup> <mfrac><mrow><mi>d</mi><mi>g</mi><mo>(</mo><msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mrow><mo>(</mo><mi>b</mi><mo>)</mo></mrow><mo>)</mo></mrow>
    <mrow><mi>d</mi><mi>b</mi></mrow></mfrac> <mo>=</mo> <msup><mi>λ</mi> <mo>*</mo></msup>
    <mfrac><mrow><mi>d</mi><mi>b</mi></mrow> <mrow><mi>d</mi><mi>b</mi></mrow></mfrac>
    <mo>=</mo> <msup><mi>λ</mi> <mo>*</mo></msup> <mo>×</mo> <mn>1</mn> <mo>=</mo>
    <msup><mi>λ</mi> <mo>*</mo></msup> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: In other words, the Lagrange multiplier <math alttext="lamda Superscript asterisk"><msup><mi>λ</mi>
    <mo>*</mo></msup></math> is the rate of change of the optimal cost (value of the
    objective function) due to the relaxation of the corresponding constraint. In
    economics, <math alttext="lamda Superscript asterisk"><msup><mi>λ</mi> <mo>*</mo></msup></math>
    is called the *marginal cost* with respect to the constraint, or the *shadow price*.
    When we discuss duality later in this chapter, we use the letters *p* for the
    decision variables of the dual problem for this *price* reason.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization- Infinite dimensions- Calculus of Variations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The field of calculus of variations is an optimization field, but instead of
    searching for optimizing points in finite dimensional spaces, we are searching
    for optimizing *functions* in infinite dimensional spaces.
  prefs: []
  type: TYPE_NORMAL
- en: In finite dimensions, the *optimizing point* (or points) satisfies an equation
    based on setting the gradient of the *objective function* equal to zero.
  prefs: []
  type: TYPE_NORMAL
- en: In infinite dimensions, the *optimizing function* satisfies a *differential
    equation* based on setting the gradient of the *objective functional* (a functional
    is a function whose input is a function and whose output is a real number, for
    example the integral of a continuous function on the interval [0,1] is a functional)
    equal to zero, that is, if we manage to define the gradient of a *functional*.
    To find the optimizer, we either have to solve the differential equation, or follow
    some optimization scheme. Everything in math ties neatly together.
  prefs: []
  type: TYPE_NORMAL
- en: The minimizing *function* satisfies a differential equation called the *Euler
    Lagrange equation*. You can skip the rest of this section if you are not interested
    in PDEs, as it is not essential to operations research.
  prefs: []
  type: TYPE_NORMAL
- en: Example 1
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have some familiarity with partial differential equations, this is a
    nice way to think about a harmonic function as the minimizer of an energy functional:
    The minimizer of the Dirichlet energy <math alttext="upper E left-parenthesis
    u left-parenthesis x right-parenthesis right-parenthesis equals integral Underscript
    upper D Endscripts one-half StartAbsoluteValue normal nabla u left-parenthesis
    x right-parenthesis EndAbsoluteValue squared d x"><mrow><mi>E</mi> <mrow><mo>(</mo>
    <mi>u</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo>
    <msub><mo>∫</mo> <mi>D</mi></msub> <mfrac><mn>1</mn> <mn>2</mn></mfrac> <msup><mrow><mo>|</mo><mi>∇</mi><mi>u</mi><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>|</mo></mrow>
    <mn>2</mn></msup> <mi>d</mi> <mi>x</mi></mrow></math> where *u(x)* belongs to
    an appropriate function space, and *u(x)=h(x)* on the boundary <math alttext="normal
    partial-differential upper D"><mrow><mi>∂</mi> <mi>D</mi></mrow></math> satisfies
    the Euler Lagrange equation <math alttext="normal upper Delta u equals 0"><mrow><mi>Δ</mi>
    <mi>u</mi> <mo>=</mo> <mn>0</mn></mrow></math> , *u=h(x)* on <math alttext="normal
    partial-differential upper D"><mrow><mi>∂</mi> <mi>D</mi></mrow></math> (so the
    minimizer must be a harmonic function satisfying the given boundary condition).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, the heat equation <math alttext="u Subscript t Baseline equals normal
    upper Delta u"><mrow><msub><mi>u</mi> <mi>t</mi></msub> <mo>=</mo> <mi>Δ</mi>
    <mi>u</mi></mrow></math> with *u(x,t)=0* on <math alttext="normal partial-differential
    upper D"><mrow><mi>∂</mi> <mi>D</mi></mrow></math> and some initial condition
    *u(x,0)=g(x)* does <math alttext="upper L squared"><msup><mi>L</mi> <mn>2</mn></msup></math>
    -steepest descent of the Dirichlet energy: This means that starting initially
    at <math alttext="u left-parenthesis x comma 0 right-parenthesis equals g left-parenthesis
    x right-parenthesis"><mrow><mi>u</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo> <mn>0</mn>
    <mo>)</mo> <mo>=</mo> <mi>g</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math>
    , the fastest way to arrive to the minimizer on the Dirichlet energy landscape,
    is through solving the heat equation. Therefore, the heat equation gives an idea
    for a minimizing scheme for the minimization problem:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript u equals 0 on normal partial-differential
    upper D Endscripts one-half integral Underscript upper D Endscripts StartAbsoluteValue
    normal nabla u left-parenthesis x comma t right-parenthesis EndAbsoluteValue squared
    d x period dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo>
    <mrow><mi>u</mi><mo>=</mo><mn>0</mn><mtext>on</mtext><mi>∂</mi><mi>D</mi></mrow></msub>
    <mfrac><mn>1</mn> <mn>2</mn></mfrac> <msub><mo>∫</mo> <mi>D</mi></msub> <msup><mrow><mo>|</mo><mi>∇</mi><mi>u</mi><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow><mo>|</mo></mrow>
    <mn>2</mn></msup> <mi>d</mi> <mi>x</mi> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Example 2
  prefs: []
  type: TYPE_NORMAL
- en: The shortest path between two points in <math alttext="double-struck upper R
    squared"><msup><mi>ℝ</mi> <mn>2</mn></msup></math> is a straight line. To do this,
    we minimize the arc length of the curve connecting two points <math alttext="left-parenthesis
    x 1 comma y 1 right-parenthesis"><mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>y</mi> <mn>1</mn></msub> <mo>)</mo></mrow></math> and <math
    alttext="left-parenthesis x 2 comma y 2 right-parenthesis"><mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>,</mo> <msub><mi>y</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>
    , namely,
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript y left-parenthesis x 1 right-parenthesis
    equals y 1 and y left-parenthesis x 2 right-parenthesis equals y 2 Endscripts
    integral Subscript x 1 Superscript x 2 Baseline StartRoot 1 plus y prime left-parenthesis
    x right-parenthesis squared EndRoot d x period dollar-sign"><mrow><msub><mo form="prefix"
    movablelimits="true">min</mo> <mrow><mi>y</mi><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow><mo>=</mo><msub><mi>y</mi> <mn>1</mn></msub>
    <mtext>and</mtext><mi>y</mi><mrow><mo>(</mo><msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow><mo>=</mo><msub><mi>y</mi> <mn>2</mn></msub></mrow></msub> <msubsup><mo>∫</mo>
    <mrow><msub><mi>x</mi> <mn>1</mn></msub></mrow> <msub><mi>x</mi> <mn>2</mn></msub></msubsup>
    <msqrt><mrow><mn>1</mn> <mo>+</mo> <msup><mi>y</mi> <mo>'</mo></msup> <msup><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></msqrt> <mi>d</mi> <mi>x</mi> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: We then write the Euler-Lagrange equation, leading to the minimizing funtion
    *y(x)=mx+b*, where *m* and *b* are respectively the slope and the *y*-intercept
    of the straight line connecting the two given points.
  prefs: []
  type: TYPE_NORMAL
- en: Other introductory examples to calculus of variations
  prefs: []
  type: TYPE_NORMAL
- en: The minimal surface problem and the isoperimetric problems are other examples
    which we can solve using an appropriate variational principle.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization On Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I wanted to start with optimization on networks *before* the simplex method
    for linear optimization because more people are used to thinking in terms of algebraic
    forms (equations and functions) than in terms of graph or network structures,
    despite the abundance of network structures in nature and operations rersearch
    applications. We need to become very comfortable with graph models. Optimization
    problems on network structures tend to be combinatorial in nature <math alttext="upper
    O left-parenthesis n factorial right-parenthesis"><mrow><mi>O</mi> <mo>(</mo>
    <mi>n</mi> <mo>!</mo> <mo>)</mo></mrow></math> , which is *no bueno*, so we need
    algorithms that somehow circumvent this and efficiently sift through the search
    space (remember the order of a problem is usually a worst case scenario, and in
    worst cases we suffice ourselves with approximate solutions).
  prefs: []
  type: TYPE_NORMAL
- en: We discuss typical network problems, which happen to capture a wide variety
    of real life applications. The traveling salesman problem is one of the oldest
    and most famous so we start there. We live in an age where we have open source
    software packages and cloud computing resources that include powerful algorithms
    for solving all the problems mentioned in this chapter, so in this section we
    focus on understanding the type of the network problem and its applications instead
    of the algorithms devised to solve them.
  prefs: []
  type: TYPE_NORMAL
- en: Traveling Salesman Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is one famous problem in operations research that fits into many real
    world situations: A salesman is required to visit a number of cities during a
    trip. Given the distances between the cities, in what order should he travel so
    as to visit every city precisely once and return home, with the objective of keeping
    the distance traveled at a minimum ([Figure 10-1](#Fig_traveling_salesman))?'
  prefs: []
  type: TYPE_NORMAL
- en: '![280](assets/emai_1001.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-1\. Traveling salesman problem ([*image source*](https://xkcd.com/399/))
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Applications are numerous: A delivery truck leaving a warehouse and must deliver
    packages to every address, in the least costly way (measured by time or distance);
    finding the most efficient hole sequence to drill on a printed ciruit board during
    manufacturing electronic chips.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We represent the traveling saleman problem as an optimization problem on a
    graph: The cities are the nodes, there are edges between each pair of cities (making
    the graph complete), and each edge has a weight (or attribute or feature) representing
    the distance between the two cities. This graph has many paths passing through
    all the cities only once and returning to the one we started with (a *Hamiltonian
    circuit*), but we want the one with the smallest sum of distances.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s think of the complexity of this problem: The total number of different
    Hamiltonian circuits in a complete graph of n nodes is (n−1)!/2: Starting at any
    node we have n-1 edges to choose from to pick the next city to visit, then n−2
    options from the second city, n−3 from the third city, and so on. These choices
    are independent, so we have a total of (n−1)! choices. We must divide by 2 to
    account for symmetry, in the sense that we can traverse the same Hamiltonian circuit
    forward or backward and still get the exact same total distance traveled. This
    counting problem is a circular permutation with symmetry. An exhaustive solution
    of the traveling salesman would list all (n−1)!/2 Hamiltonian circuits, adding
    up the distance traveled in each, then choosing the one with the shortest distance.
    Even for a reasonable value of n, it is too expensive: To visit all 50 US state
    capitals (say we want to minimize total trip cost), we would need to try <math
    alttext="left-parenthesis 50 minus 1 right-parenthesis factorial slash 2 equals
    3.04 times 10 Superscript 6 Baseline 2"><mrow><mrow><mo>(</mo> <mn>50</mn> <mo>-</mo>
    <mn>1</mn> <mo>)</mo></mrow> <mo>!</mo> <mo>/</mo> <mn>2</mn> <mo>=</mo> <mn>3</mn>
    <mo>.</mo> <mn>04</mn> <mo>×</mo> <msup><mn>10</mn> <mn>6</mn></msup> <mn>2</mn></mrow></math>
    options! We do not have an efficient algorithm for problems of arbitrary size.
    Heuristic methods are able to provide excellent approximate solutions. Moreover,
    great algorithms based on an approach called *branch and cut* have solved this
    problem to optimality for very large number of cities.'
  prefs: []
  type: TYPE_NORMAL
- en: Minimum Spanning Tree
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I put the minimum spanning tree problem right after the traveling salesman because
    sometimes people confuse the two. This is a good place to clear the confusion.
    Here, we have a fully connected network with positive weights associated with
    each edge, which again can represent distance, time, capacity, or cost of connecting
    infrastrcuture such as water, electric, or phone lines. Similar to the traveling
    salesman, we want to find the set of edges that includes all the nodes of the
    graph and minimizes the total weight. The requirement here that is different than
    the traveling salesman is that we want to make sure we choose the set of edges
    in a way provides a path between any two pairs of nodes, meaning we can reach
    any node in the graph from any other node. In the traveling salesman, we need
    to visit every city only once then return to the starting city, which means that
    each node cannot get more than two edges (no such requirement for a spanning tree).
    The fact that we return to the last city in the traveling salesman means that
    we have an extra circuit closing edge in traveling salesman that we do not need
    for spanning trees. If we remove that last edge of a traveling salesman solution,
    then we definitely get a spanning tree, however there is no guarantee that it
    is the one with minimal cost. [Figure 10-2](#Fig_TS_MS) shows Minimum spanning
    tree and traveling salesman solutions of the same graph.
  prefs: []
  type: TYPE_NORMAL
- en: '![280](assets/emai_1002.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-2\. Minimum spanning tree and traveling salesman solutions of the
    same graph
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note that for any network, if we have n nodes then we only need n-1 edges so
    that we have a path between every two nodes, so we should never use more than
    n-1 edges for a minimal spanning tree because that would increase our cost. We
    need to choose the set of edges that minimizes the cost.
  prefs: []
  type: TYPE_NORMAL
- en: We have already mentioned some applications, such as designing telecommunication
    networks, routing and transportation networks, electric networks, and infrastructure
    networks (pipelines). These networks are so expensive to develop and designing
    them optimally saves millions of dollars.
  prefs: []
  type: TYPE_NORMAL
- en: Shortest Path
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The simplest version of the shortest path problem is that we have two nodes
    on a graph and we want to connect them with a set of edges so that the total sum
    of the edge weights (distance, time) is minimal. This is different than the traveling
    salesman and the minimal spanning tree problems because we don’t care about covering
    all the nodes of the graph. All we care for is getting ourselves from the origin
    to the destination in the least costly way.
  prefs: []
  type: TYPE_NORMAL
- en: One obvious application is travel from one destination to another with minimal
    distance, cost, time, *etc.*. Other applications which are not immediately obvious
    but nevertheless are ultra important are activity networks. Instead of an origin
    and a destination we might have a beginning of a project and an end. Each node
    represents an activity and each edge weight represents the cost or the time incurred
    if activity i is adjacent to activity j (if we have a directed graph, then it
    would be the cost or time incurred if activity i happens after activity j). The
    goal is to choose the sequence of activities that minimize the total cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'Othe versions of the shortest path problem include: Find the shortest path
    from an origin to *all other nodes*. Others include finding the shortest paths
    between *all pairs of nodes*.'
  prefs: []
  type: TYPE_NORMAL
- en: Many vehicle routing algorithms and network design algorithms include shortest
    path algorithms as subroutines.
  prefs: []
  type: TYPE_NORMAL
- en: We can also formulate the shortest path problem as a linear optimization problem
    and use the methods available for linear optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Max Flow Min Cut
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here we also have an origin and a destination, each *directed* edge has a capacity
    of some sort (max number of vehicles allowed on a route, max number of commodities
    shipped on a route, max amount of material or natural resource such as oil or
    water that a pipeline can handle) and we want to find the set the edges that maximizes
    the *flow* from the origin to the destination. Note that all edges point away
    from the origin and point towards the destination.
  prefs: []
  type: TYPE_NORMAL
- en: 'A very important theorem from graph theory plays a crucial role in determining
    the optimality (max flow) of a set of edges connecting the origin to the destination:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Max flow min cut theorem**: This theorem says the maximum flow from the origin
    to the destination through the directed network is equal to the minimal sum of
    weights of the edges required to cut any communication between the origin and
    the destination. That is, we can cut through the network to prevent communication
    between the origin and the destination in more than one way. The set of edges
    that cuts communication *and* has the least weight is the minimal cut set. The
    value of this minimal cut set is equal to the value of the maximum flow possible
    in the network. This result is pretty intuitive: What’s the most that we can send
    through the edges of the network? This is bounded from above by the capacities
    of the edges crucial for connecting the origin to the destination.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can reformulate the max flow problem as a linear optimization problem, and
    of course, the min cut problem will be its dual, so of course they have the same
    solution! We will see this soon in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, suppose we have more than one origin and more than one destination,
    similar to a distribution network, then we can still maximize the flow through
    the network by solving the exact same problem, except now we add a fictional *super
    origin* pointing to all the real origins, and another fictional *super destination*
    that all the real destinations point towards, with infinite capacities, then do
    business as usual, solving for the max flow on this new graph with two new fictional
    *super nodes*.
  prefs: []
  type: TYPE_NORMAL
- en: Max Flow Min Cost
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is similar to the max flow problem, except that now we have a cost associated
    with sending a flow through each edge proportional to the number of units of flow.
    The goal is obviously to minimize the cost while satisfying the supply from all
    the origins to all the destinations. We can formulate this problem as a linear
    optimization problem and solve it using a simplex method optimized for networks.
    Applications are ubiquous and so important: All kinds of distribution networks,
    with supply nodes, transshipment nodes, and demand nodes, supply chains (of goods,
    blood, nuclear materials, food), solid waste management networks, coordinating
    the types of products to produce or to spend resources inorder to satisfy the
    market, cash flow management, assignment problems, such as assigning employees
    to tasks, time slots to tasks, or job applicants to available jobs.'
  prefs: []
  type: TYPE_NORMAL
- en: The assignment problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The assignment problem is also called the matching problem. The number of assignees
    should be the same as the number of tasks and each can be assigned only one tasks,
    and each task can be performed by only one assignee. There is a cost to assigning
    task i to assignee j. The objective is to choose the matching between tasks and
    assignees that minimizes the total cost. The graph of such a problem is a special
    type of graph called bipartite graph. Such a graph can be divided into two parts,
    where all the edges go from one node in the first part to one node in the second
    part. An assignment problem where all the weights are the same is a max flow problem
    on a bipartite graph. All we have to do is assign a fictional super origin and
    another fictional super destination and solve the problem the same way we solve
    the max flow problem in the upcoming section on linear optimization and duality.
    There are many efficient algorithms for these problems.
  prefs: []
  type: TYPE_NORMAL
- en: The Critical Path Method (CPM) for Project Design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The critical path method is an optimization method on a network representing
    all the involved activities in a project, the total budget, the total time constraint,
    which ones need to happen before others, how much time and cost each activity
    incurs, and which activities can happen simultaneously. Think for example of a
    house construction project, from start to finish. The critical path method for
    time and cost tradeoffs is a great tool to aid in designing a project that incorporates
    tradeoffs between time and cost, makes sure the project meets its deadlines at
    a minimal total cost. Similar to the critical path method is the Program Evaluation
    Review Technique (PERT) which is a project management planning tool which computes
    the amount of time it will take to complete a project. The methods provides three
    timelines: A shortest possible timeline, a longest possible timeline, and a most
    probable timeline.'
  prefs: []
  type: TYPE_NORMAL
- en: The n-Queens Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before moving on to linear optimization, the simplex method, and duality, we
    make a tiny detour and mention an interesting combinatorial problem that has puzzled
    mathematicians for 150 years, mainly because its utter lack of structure: The
    n-queens problem, such as the one in [Figure 10-3](#Fig_n_queens). Michael Simkin
    [has finally (July 2021) answered the 150-year-old chess-based n-queens problem](https://www.quantamagazine.org/mathematician-answers-chess-problem-about-attacking-queens-20210921/).
    Here is an edited part of the abstract of his solution paper titled [*The Number
    of n-Queens Configurations*](https://arxiv.org/abs/2107.13460): *The n-queens
    problem is to determine the number of ways to place n mutually nonthreatening
    queens on an <math alttext="n times n"><mrow><mi>n</mi> <mo>×</mo> <mi>n</mi></mrow></math>
    [chess] board. We show that there exists a constant <math alttext="alpha equals
    1.942 plus-or-minus 3 times 10 Superscript negative 3"><mrow><mi>α</mi> <mo>=</mo>
    <mn>1</mn> <mo>.</mo> <mn>942</mn> <mo>±</mo> <mn>3</mn> <mo>×</mo> <msup><mn>10</mn>
    <mrow><mo>-</mo><mn>3</mn></mrow></msup></mrow></math> such that [the number of
    ways to place the mutually nonthreatening queens on the board is] <math alttext="left-parenthesis
    1 plus-or-minus o left-parenthesis 1 right-parenthesis n e Superscript negative
    alpha Baseline right-parenthesis Superscript n Baseline left-parenthesis left-parenthesis
    1 plus-or-minus o left-parenthesis 1 right-parenthesis right-parenthesis n e Superscript
    negative alpha Baseline right-parenthesis Superscript n"><mrow><msup><mrow><mo>(</mo><mn>1</mn><mo>±</mo><mi>o</mi><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow><mi>n</mi><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>α</mi></mrow></msup> <mo>)</mo></mrow> <mi>n</mi></msup> <msup><mrow><mo>(</mo><mrow><mo>(</mo><mn>1</mn><mo>±</mo><mi>o</mi><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow><mo>)</mo></mrow><mi>n</mi><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>α</mi></mrow></msup> <mo>)</mo></mrow> <mi>n</mi></msup></mrow></math>
    . The constant α is characterized as the solution to a convex optimization problem
    in P([−1/2,1/2] <math alttext="squared right-parenthesis"><mrow><msup><mn>2</mn></msup>
    <mrow><mo>)</mo></mrow></mrow></math> , the space of Borel probability measures
    on the square.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![300](assets/emai_1003.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-3\. 8 queens in mutually nonthreatening positions on an 8 by 8 chess
    board.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The following [page](https://www.geeksforgeeks.org/n-queen-problem-backtracking-3/)
    has an easy *backtracking* algorithm for solving the n-queens problem. Note that
    the solution by Simkin quantifies the total number of viable queen configurations,
    while algorithms only find one or some of these configurations.
  prefs: []
  type: TYPE_NORMAL
- en: Linear Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Any optimization problem in finite dimensions, whether linear or nonlinear,
    looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column g 1 left-parenthesis ModifyingAbove x With right-arrow right-parenthesis
    less-than-or-equal-to 0 2nd Row 1st Column Blank 2nd Column g 2 left-parenthesis
    ModifyingAbove x With right-arrow right-parenthesis less-than-or-equal-to 0 3rd
    Row 1st Column Blank 2nd Column  ellipsis 4th Row 1st Column Blank 2nd Column
    g Subscript m Baseline left-parenthesis ModifyingAbove x With right-arrow right-parenthesis
    less-than-or-equal-to 0 EndLayout Endscripts f left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis period dollar-sign"><mrow><msub><mo form="prefix"
    movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><msub><mi>g</mi>
    <mn>1</mn></msub> <mrow><mo>(</mo><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow><mo>≤</mo><mn>0</mn></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mrow><msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow><mo>≤</mo><mn>0</mn></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mo>⋯</mo></mtd></mtr><mtr><mtd columnalign="left"><mrow><msub><mi>g</mi>
    <mi>m</mi></msub> <mrow><mo>(</mo><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>)</mo></mrow><mo>≤</mo><mn>0</mn></mrow></mtd></mtr></mtable></msub>
    <mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the following cases:'
  prefs: []
  type: TYPE_NORMAL
- en: 'There exists a unique optimal solution: Think that the basin has one lowest
    point.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There exist multiple optimal solutions: In this case the set of optimal solutions
    can be bounded or unbounded.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The optimal cost goes to <math alttext="negative normal infinity"><mrow><mo>-</mo>
    <mi>∞</mi></mrow></math> , and no feasible solution is optimal: The landscape
    of the objective function goes downhill indefinitely.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The feasible set is empty and the minimization problem has no solution: No
    one cares about the objective function and its low values here, since there are
    no points that satisfy all the constraints at the same time!'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The optimal cost is finite but not attained: there is no optimizer even when
    the feasible set is nonempty. For example <math alttext="inf Underscript x greater-than-or-equal-to
    0 Endscripts StartFraction 1 Over x EndFraction"><mrow><msub><mo form="prefix"
    movablelimits="true">inf</mo> <mrow><mi>x</mi><mo>≥</mo><mn>0</mn></mrow></msub>
    <mfrac><mn>1</mn> <mi>x</mi></mfrac></mrow></math> is equal to zero but there
    is no finite *x* such that 1/*x*=0\. This never happens for linear problems.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For an optimization problem to be linear, the objective function *f* and all
    the constraints *g* must be linear functions. Linear optimization gets a lion’s
    share in operations research, since we can model many operations research problems
    as a minimization of a linear function with linear constraints, that could be
    equalities or inequalities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Linearity is such a great thing. We can express any linear optimization problem
    using linear algebra language (vectors and matrices), and there are two forms
    that people usually work with:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The general form*: This is convenient for developing the theory of linear
    programming. There is no restriction on the signs of the entries of the vector
    <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> , the decision variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript upper A ModifyingAbove x With right-arrow
    greater-than-or-equal-to ModifyingAbove b With right-arrow Endscripts ModifyingAbove
    c With right-arrow period ModifyingAbove x With right-arrow dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mrow><mi>A</mi><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover><mo>≥</mo><mover accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></msub>
    <mover accent="true"><mi>c</mi> <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The feasible set <math alttext="upper A ModifyingAbove x With right-arrow greater-than-or-equal-to
    ModifyingAbove b With right-arrow"><mrow><mi>A</mi> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>≥</mo> <mover accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></math>
    is a polyhedron (add a picture of a polyhedron), which we can think of as the
    intersection of a finite number of half spaces. This polyhedron could be bounded
    or unbounded (add a picture).
  prefs: []
  type: TYPE_NORMAL
- en: '*The standard form*: This is convenient for computations and developing algorithms,
    like the simplex and interior point methods. The decision variables must be nonnegative,
    so we are only searching in the *first hypeoctant*, the high dimensional analogue
    of the first quadrant, where all the coordinates are non-negative. Moreover, the
    constraints must always be equalities, not inequalities, so we must be on the
    boundary of the half space, not on the interior. This is how a linear optimization
    problem in standard form looks like:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column upper A ModifyingAbove x With right-arrow equals ModifyingAbove b With
    right-arrow comma 2nd Row 1st Column Blank 2nd Column ModifyingAbove x With right-arrow
    greater-than-or-equal-to ModifyingAbove 0 With right-arrow EndLayout Endscripts
    ModifyingAbove c With right-arrow period ModifyingAbove x With right-arrow dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd
    columnalign="left"><mrow><mi>A</mi><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>=</mo><mover
    accent="true"><mi>b</mi> <mo>→</mo></mover><mo>,</mo></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mrow><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>≥</mo><mover
    accent="true"><mn>0</mn> <mo>→</mo></mover></mrow></mtd></mtr></mtable></msub>
    <mover accent="true"><mi>c</mi> <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The linear problem in standard form has an easy way for us to internalize:
    Synthesize the vector <math alttext="ModifyingAbove b With right-arrow"><mover
    accent="true"><mi>b</mi> <mo>→</mo></mover></math> from the columns of *A* in
    such a way that minimizes the cost <math alttext="ModifyingAbove c With right-arrow
    period ModifyingAbove x With right-arrow"><mrow><mover accent="true"><mi>c</mi>
    <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math>
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can go back and forth between the standard form and general form of a linear
    optimization problem easily (for example, by introducing surplus and slack variables
    to covert general linear optimization problem to standard form), but note that
    we end up solving the same problem in different dimensions: If we introduce a
    variable so change an inequality into an equality, such as introducing <math alttext="s
    1"><msub><mi>s</mi> <mn>1</mn></msub></math> to convert the inequality <math alttext="x
    1 minus 3 x 2 greater-than-or-equal-to 4"><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>-</mo> <mn>3</mn> <msub><mi>x</mi> <mn>2</mn></msub> <mo>≥</mo> <mn>4</mn></mrow></math>
    to the equality <math alttext="x 1 minus 3 x 2 minus s 1 equals 4"><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>-</mo> <mn>3</mn> <msub><mi>x</mi> <mn>2</mn></msub> <mo>-</mo>
    <msub><mi>s</mi> <mn>1</mn></msub> <mo>=</mo> <mn>4</mn></mrow></math> , then
    we increase the dimension (in this example from two to three). That is fine. It
    is actually one of the nice things about math that we can model unlimited amount
    of dimensions even though we only live in a three dimensional world.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Graphical representation of a linear optimization problem in two dimensions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Figure 10-4](#Fig_simplex) shows a graphical representation of the linear
    optimization problem:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column x plus 2 y less-than-or-equal-to 3 2nd Row 1st Column Blank 2nd Column
    2 x plus y less-than-or-equal-to 3 3rd Row 1st Column Blank 2nd Column x greater-than-or-equal-to
    0 4th Row 1st Column Blank 2nd Column y greater-than-or-equal-to 0 EndLayout Endscripts
    minus x minus y period dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo>
    <mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mi>x</mi><mo>+</mo><mn>2</mn><mi>y</mi><mo>≤</mo><mn>3</mn></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mrow><mn>2</mn><mi>x</mi><mo>+</mo><mi>y</mi><mo>≤</mo><mn>3</mn></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mrow><mi>x</mi><mo>≥</mo><mn>0</mn></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mrow><mi>y</mi><mo>≥</mo><mn>0</mn></mrow></mtd></mtr></mtable></msub>
    <mo>-</mo> <mi>x</mi> <mo>-</mo> <mi>y</mi> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This problem is two dimensional (and neither in general form nor in stardard
    form, but we can easily convert to either).
  prefs: []
  type: TYPE_NORMAL
- en: Note that the optimal value of -x-y is -2 attained at the point (1,1), which
    is one of the corners of the feasible set. If this was an unconstrained problem,
    then the infimum would be <math alttext="negative normal infinity"><mrow><mo>-</mo>
    <mi>∞</mi></mrow></math> . Constraints make a huge difference. The fact that the
    optimal value is at one of the corners of the polygon (two dimensional polyhedron)
    is not a coincidence. If we draw the straight line -x-y=c for some c that places
    part of the line inside the feasible set, then move in the direction of the negative
    of the gradient vector (recall that this is the direction of fastest descent),
    the line would move in the direction of the vector <math alttext="minus normal
    nabla left-parenthesis negative x minus y right-parenthesis equals minus left-parenthesis
    negative 1 comma negative 1 right-parenthesis equals left-parenthesis 1 comma
    1 right-parenthesis"><mrow><mo>-</mo> <mi>∇</mi> <mo>(</mo> <mo>-</mo> <mi>x</mi>
    <mo>-</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mo>-</mo> <mo>(</mo> <mo>-</mo> <mn>1</mn>
    <mo>,</mo> <mo>-</mo> <mn>1</mn> <mo>)</mo> <mo>=</mo> <mo>(</mo> <mn>1</mn> <mo>,</mo>
    <mn>1</mn> <mo>)</mo></mrow></math> (it is a coincidence here that the gradient
    vector has the same coordinates as the optimizing point these two are completely
    unrelated). As long as the line has parts of it inside the feasible set we can
    *keep pushing* and making *c* smaller, until we can’t push anymore, because if
    we do we’d exit the feasible set, become infeasible, and lose all our pushing
    work. This happens exactly when the whole line is outside the feasible set and
    barely hanging at the point (1,1), which is still in the feasible set. We found
    our optimizer, the point which makes the value of -x-y smallest. We will get back
    to moving through the corners of feasible sets of linear problems soon, because
    that’s where the optimizers are.
  prefs: []
  type: TYPE_NORMAL
- en: '![280](assets/emai_1004.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-4\. Feasible set and the optimal value of -x-y is -2 attained at the
    corner point (1,1).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Convex to Linear
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even if the objective function is nonlinear, in many cases we can reformulate
    the problem as a linear problem and use linear optimization techniques to either
    obtain an exact solution or an approximation to the exact solution. We can approximate
    a convex (and differentiable) function by a piecewise linear convex function [Figure 10-5](#Fig_approx_convex_linear).
    We can turn an optimization problem with piecwise linear objective function into
    one with a linear objective function. This however makes us lose differentiability
    (the function stops being smooth). Nothing is free. In optimization problems,
    after linearity, convexity is the next desirable thing, because we wouldn’t worry
    about getting stuck at local minima. A local minimum for a convex is a global
    minimum.
  prefs: []
  type: TYPE_NORMAL
- en: '![280](assets/emai_1005.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-5\. Approximating a convex function by piecewise linear functions
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A *convex optimization* problem has a convex objective function and a convex
    feasible set. Convex optimization is a whole field of its own.
  prefs: []
  type: TYPE_NORMAL
- en: Convex function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A function <math alttext="f colon double-struck upper R Superscript n Baseline
    right-arrow double-struck upper R"><mrow><mi>f</mi> <mo>:</mo> <msup><mi>ℝ</mi>
    <mi>n</mi></msup> <mo>→</mo> <mi>ℝ</mi></mrow></math> is convex if and only if
    <math alttext="f left-parenthesis lamda x plus left-parenthesis 1 minus lamda
    right-parenthesis y right-parenthesis less-than-or-equal-to lamda f left-parenthesis
    x right-parenthesis plus left-parenthesis 1 minus lamda right-parenthesis f left-parenthesis
    y right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mi>λ</mi> <mi>x</mi> <mo>+</mo>
    <mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>λ</mi> <mo>)</mo> <mi>y</mi> <mo>)</mo> <mo>≤</mo>
    <mi>λ</mi> <mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>1</mn>
    <mo>-</mo> <mi>λ</mi> <mo>)</mo> <mi>f</mi> <mo>(</mo> <mi>y</mi> <mo>)</mo></mrow></math>
    , for all <math alttext="x comma y element-of double-struck upper R Superscript
    n"><mrow><mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>∈</mo> <msup><mi>ℝ</mi> <mi>n</mi></msup></mrow></math>
    and <math alttext="0 less-than-or-equal-to lamda less-than-or-equal-to 1"><mrow><mn>0</mn>
    <mo>≤</mo> <mi>λ</mi> <mo>≤</mo> <mn>1</mn></mrow></math> . This means that the
    segment connecting any two points on the graph of *f* lies above the graph of
    *f* (draw a picture).
  prefs: []
  type: TYPE_NORMAL
- en: 'Helpful facts about convex functions:'
  prefs: []
  type: TYPE_NORMAL
- en: A convex function cannot have a local minimum that fails to be global minimum.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the functions <math alttext="f 1 comma f 2 comma ellipsis comma f Subscript
    m Baseline colon double-struck upper R Superscript n Baseline right-arrow double-struck
    upper R"><mrow><msub><mi>f</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>f</mi>
    <mn>2</mn></msub> <mo>,</mo> <mo>...</mo> <mo>,</mo> <msub><mi>f</mi> <mi>m</mi></msub>
    <mo>:</mo> <msup><mi>ℝ</mi> <mi>n</mi></msup> <mo>→</mo> <mi>ℝ</mi></mrow></math>
    are convex functions, then the function <math alttext="f left-parenthesis x right-parenthesis
    equals max Underscript i Endscripts f Subscript i Baseline left-parenthesis x
    right-parenthesis"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mo form="prefix" movablelimits="true">max</mo> <mi>i</mi></msub>
    <msub><mi>f</mi> <mi>i</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    is also convex. *f* may lose smoothness in this case so optimization methods wouldn’t
    be able to use derivatives.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The function <math alttext="f left-parenthesis x right-parenthesis equals max
    left-brace m 1 x plus d 1 comma m 2 x plus d 2 comma ellipsis comma m Subscript
    n Baseline x plus d Subscript n Baseline right-brace"><mrow><mi>f</mi> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mo form="prefix" movablelimits="true">max</mo>
    <mrow><mo>{</mo> <msub><mi>m</mi> <mn>1</mn></msub> <mi>x</mi> <mo>+</mo> <msub><mi>d</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>m</mi> <mn>2</mn></msub> <mi>x</mi> <mo>+</mo>
    <msub><mi>d</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <msub><mi>m</mi>
    <mi>n</mi></msub> <mi>x</mi> <mo>+</mo> <msub><mi>d</mi> <mi>n</mi></msub> <mo>}</mo></mrow></mrow></math>
    or more compactly <math alttext="f left-parenthesis x right-parenthesis equals
    max Underscript i equals 1 comma 2 ellipsis comma n Endscripts left-brace m Subscript
    i Baseline x plus d Subscript i Baseline right-brace"><mrow><mi>f</mi> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <msub><mo form="prefix" movablelimits="true">max</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>⋯</mo><mo>,</mo><mi>n</mi></mrow></msub>
    <mrow><mo>{</mo> <msub><mi>m</mi> <mi>i</mi></msub> <mi>x</mi> <mo>+</mo> <msub><mi>d</mi>
    <mi>i</mi></msub> <mo>}</mo></mrow></mrow></math> is piecewise linear [Figure 10-6](#Fig_max_piecewise_linear).
    This is a convex function since each <math alttext="m Subscript i Baseline x plus
    d Subscript i"><mrow><msub><mi>m</mi> <mi>i</mi></msub> <mi>x</mi> <mo>+</mo>
    <msub><mi>d</mi> <mi>i</mi></msub></mrow></math> is convex (linear functions are
    convex and concave at the same time), and maximum of convex functions is also
    convex.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![280](assets/emai_1006.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-6\. The maximum of linear functions is piecewise linear and convex
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For example, the absolute value function f(x)=|x|=max{x,-x} is piecewise linear
    and convex (draw a picture).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can reformulate optimization problems with piecewise linear convex objective
    functions as linear optimization problems:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript upper A x greater-than-or-equal-to
    b Endscripts max Underscript i Endscripts m Subscript i Baseline period x plus
    d Subscript i Baseline left-right-arrow min Underscript StartLayout 1st Row 1st
    Column Blank 2nd Column z greater-than-or-equal-to m Subscript i Baseline period
    x plus d Subscript i Baseline 2nd Row 1st Column Blank 2nd Column upper A x greater-than-or-equal-to
    b EndLayout Endscripts z dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo>
    <mrow><mi>A</mi><mi>x</mi><mo>≥</mo><mi>b</mi></mrow></msub> <msub><mo form="prefix"
    movablelimits="true">max</mo> <mi>i</mi></msub> <msub><mi>m</mi> <mi>i</mi></msub>
    <mo>.</mo> <mi>x</mi> <mo>+</mo> <msub><mi>d</mi> <mi>i</mi></msub> <mo>↔</mo>
    <msub><mo form="prefix" movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd
    columnalign="left"><mrow><mi>z</mi><mo>≥</mo><msub><mi>m</mi> <mi>i</mi></msub>
    <mo>.</mo><mi>x</mi><mo>+</mo><msub><mi>d</mi> <mi>i</mi></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mrow><mi>A</mi><mi>x</mi><mo>≥</mo><mi>b</mi></mrow></mtd></mtr></mtable></msub>
    <mi>z</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, an optimization problem where the objective function has absolute
    values of the decision variables can be reformulated as a linear optimization
    problem in two ways (here the <math alttext="c Subscript i"><msub><mi>c</mi> <mi>i</mi></msub></math>
    in the objective function are nonnegative, otherwise the objective function might
    be nonconvex):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript upper A x greater-than-or-equal-to
    b Endscripts sigma-summation Underscript i equals 1 Overscript n Endscripts c
    Subscript i Baseline StartAbsoluteValue x Subscript i Baseline EndAbsoluteValue
    left-right-arrow min Underscript StartLayout 1st Row 1st Column upper A x 2nd
    Column b 2nd Row 1st Column x Subscript i Baseline 2nd Column z Subscript i Baseline
    3rd Row 1st Column minus x Subscript i Baseline 2nd Column z Subscript i Baseline
    EndLayout Endscripts sigma-summation Underscript i equals 1 Overscript n Endscripts
    c Subscript i Baseline z Subscript i Baseline left-right-arrow min Underscript
    StartLayout 1st Row 1st Column Blank 2nd Column upper A x Superscript plus Baseline
    minus upper A x Superscript minus Baseline greater-than-or-equal-to b 2nd Row
    1st Column Blank 2nd Column x Superscript plus Baseline comma x Superscript minus
    Baseline greater-than-or-equal-to 0 EndLayout Endscripts sigma-summation Underscript
    i equals 1 Overscript n Endscripts c Subscript i Baseline left-parenthesis x Subscript
    i Superscript plus Baseline plus x Subscript i Superscript minus Baseline right-parenthesis
    dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo> <mrow><mi>A</mi><mi>x</mi><mo>≥</mo><mi>b</mi></mrow></msub>
    <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <msub><mi>c</mi> <mi>i</mi></msub> <mrow><mo>|</mo> <msub><mi>x</mi> <mi>i</mi></msub>
    <mo>|</mo></mrow> <mo>↔</mo> <msub><mo form="prefix" movablelimits="true">min</mo>
    <mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>A</mi><mi>x</mi></mrow></mtd><mtd
    columnalign="left"><mrow><mo>≥</mo><mi>b</mi></mrow></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>x</mi>
    <mi>i</mi></msub></mtd> <mtd columnalign="left"><mrow><mo>≤</mo><msub><mi>z</mi>
    <mi>i</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><mo>-</mo><msub><mi>x</mi>
    <mi>i</mi></msub></mrow></mtd> <mtd columnalign="left"><mrow><mo>≤</mo><msub><mi>z</mi>
    <mi>i</mi></msub></mrow></mtd></mtr></mtable></msub> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <msub><mi>c</mi> <mi>i</mi></msub> <msub><mi>z</mi> <mi>i</mi></msub>
    <mo>↔</mo> <msub><mo form="prefix" movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd
    columnalign="left"><mrow><mi>A</mi><msup><mi>x</mi> <mo>+</mo></msup> <mo>-</mo><mi>A</mi><msup><mi>x</mi>
    <mo>-</mo></msup> <mo>≥</mo><mi>b</mi></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><msup><mi>x</mi>
    <mo>+</mo></msup> <mo>,</mo><msup><mi>x</mi> <mo>-</mo></msup> <mo>≥</mo><mn>0</mn></mrow></mtd></mtr></mtable></msub>
    <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <msub><mi>c</mi> <mi>i</mi></msub> <mrow><mo>(</mo> <msubsup><mi>x</mi> <mi>i</mi>
    <mo>+</mo></msubsup> <mo>+</mo> <msubsup><mi>x</mi> <mi>i</mi> <mo>-</mo></msubsup>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The Geometry of Linear Optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s think of the geometry of a linear optimization problem in standard form.
    Without loss of generality, we assume that the rows of *A* are linearly independent.
    In other words, there are no redundant constraints. This guarantees the existence
    of at least one set of *m* linearly independent columns of *A* (or *rank(A)=m*):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column upper A ModifyingAbove x With right-arrow equals ModifyingAbove b With
    right-arrow 2nd Row 1st Column Blank 2nd Column ModifyingAbove x With right-arrow
    greater-than-or-equal-to ModifyingAbove 0 With right-arrow EndLayout Endscripts
    ModifyingAbove c With right-arrow period ModifyingAbove x With right-arrow dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd
    columnalign="left"><mrow><mi>A</mi><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>=</mo><mover
    accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>≥</mo><mover accent="true"><mn>0</mn>
    <mo>→</mo></mover></mrow></mtd></mtr></mtable></msub> <mover accent="true"><mi>c</mi>
    <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned before, if we change from general form to standard form, then
    we jump up in dimension. Therefore, even if a polyhedron has no corners in general
    form, it will always have corners in its higher dimensional standard form: Due
    to the positivity condition of the coordinates in standard form, the polyhedron
    becomes situated in the first hyperoctant, hence cannot possibly have full lines.
    Now we have theorems guaranteeing that for a linear optimization problem, either
    the optimal cost is <math alttext="negative normal infinity"><mrow><mo>-</mo>
    <mi>∞</mi></mrow></math> , or there exists a finite optimal cost happening at
    a corner of the polyhedron (at a basic feasible solution).'
  prefs: []
  type: TYPE_NORMAL
- en: The Simplex Algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our goal is to construct an algorithm that finds an optimal solution for the
    linear optimization problem in standard form:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column upper A ModifyingAbove x With right-arrow equals ModifyingAbove b With
    right-arrow 2nd Row 1st Column Blank 2nd Column ModifyingAbove x With right-arrow
    greater-than-or-equal-to ModifyingAbove 0 With right-arrow EndLayout Endscripts
    ModifyingAbove c With right-arrow period ModifyingAbove x With right-arrow dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd
    columnalign="left"><mrow><mi>A</mi><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>=</mo><mover
    accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>≥</mo><mover accent="true"><mn>0</mn>
    <mo>→</mo></mover></mrow></mtd></mtr></mtable></msub> <mover accent="true"><mi>c</mi>
    <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: '*A* is <math alttext="m times n"><mrow><mi>m</mi> <mo>×</mo> <mi>n</mi></mrow></math>
    with *m* linearly independent rows (so <math alttext="m less-than-or-equal-to
    n"><mrow><mi>m</mi> <mo>≤</mo> <mi>n</mi></mrow></math> ), <math alttext="ModifyingAbove
    b With right-arrow"><mover accent="true"><mi>b</mi> <mo>→</mo></mover></math>
    is <math alttext="m times 1"><mrow><mi>m</mi> <mo>×</mo> <mn>1</mn></mrow></math>
    , <math alttext="ModifyingAbove c With right-arrow"><mover accent="true"><mi>c</mi>
    <mo>→</mo></mover></math> and <math alttext="ModifyingAbove x With right-arrow"><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></math> are <math alttext="n times
    1"><mrow><mi>n</mi> <mo>×</mo> <mn>1</mn></mrow></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: The main idea of the simplex method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Start at a vertex of the polyhedron (a corner, also called a basic feasible
    solution), move to another vertex in a direction that is guaranteed to reduce
    the objective function, or the cost (reduced costs <math alttext="c overbar"><mover
    accent="true"><mi>c</mi> <mo>¯</mo></mover></math> ), until you either reach an
    optimal solution, or discover that the problem is unbounded, and the optimal cost
    is <math alttext="negative normal infinity"><mrow><mo>-</mo> <mi>∞</mi></mrow></math>
    (these you know using the optimality conditions, and become the termination criteria
    for your algorithm). There is a chance of cycling in the case for degenerate problems,
    but that can be avoided by making smart choices (systematic way of choosing) when
    there are ties in the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Tracing the path taken by the simplex method on the graph of the polyhedron'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Figure 10-7](#Fig_polyhedron) shows the polyhedron of the following linear
    optimization problem in three dimensions. We start at a basic feasible solution
    then trace the path followed by simplex method, moving from one vertex of the
    polyhedron to the next, reducing the cost (the value of the objective function)
    at each step until it arrives at the vertex with the minimal cost.'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column x
    1 plus x 2 plus x 3 2nd Column 4 2nd Row 1st Column x 1 2nd Column 2 3rd Row 1st
    Column x 3 2nd Column 3 4th Row 1st Column 3 x 2 plus x 3 2nd Column 6 5th Row
    1st Column x 1 comma x 2 comma x 3 2nd Column 0 EndLayout Endscripts minus x 1
    plus 5 x 2 minus x 3 dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo>
    <mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo><msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo><msub><mi>x</mi>
    <mn>3</mn></msub></mrow></mtd> <mtd columnalign="left"><mrow><mo>≤</mo><mn>4</mn></mrow></mtd></mtr><mtr><mtd
    columnalign="right"><msub><mi>x</mi> <mn>1</mn></msub></mtd> <mtd columnalign="left"><mrow><mo>≤</mo><mn>2</mn></mrow></mtd></mtr><mtr><mtd
    columnalign="right"><msub><mi>x</mi> <mn>3</mn></msub></mtd> <mtd columnalign="left"><mrow><mo>≤</mo><mn>3</mn></mrow></mtd></mtr><mtr><mtd
    columnalign="right"><mrow><mn>3</mn><msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo><msub><mi>x</mi>
    <mn>3</mn></msub></mrow></mtd> <mtd columnalign="left"><mrow><mo>≤</mo><mn>6</mn></mrow></mtd></mtr><mtr><mtd
    columnalign="right"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>,</mo><msub><mi>x</mi> <mn>3</mn></msub></mrow></mtd> <mtd
    columnalign="left"><mrow><mo>≥</mo><mn>0</mn></mrow></mtd></mtr></mtable></msub>
    <mo>-</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mn>5</mn> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>-</mo> <msub><mi>x</mi> <mn>3</mn></msub></mrow></math>![250](assets/emai_1007.png)
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10-7\. The simplex method moves from one vertex of the polyhedron to
    the next until it finds an optimizing vertex.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can skip the rest of this subsection and go straight to the examples on
    transportation and assignment problems, unless you are interested in the details
    of the simplex method and its different implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start at a vertex of the polyhedron (basic feasible solution *x*: zero non-basic
    coordinates and <math alttext="x Subscript upper B Baseline equals upper B Superscript
    negative 1 Baseline b"><mrow><msub><mi>x</mi> <mi>B</mi></msub> <mo>=</mo> <msup><mi>B</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>b</mi></mrow></math> ). This requires
    a basis matrix *B* made up of *m* linearly independent columns of *A*;'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For example, if <math alttext="upper A equals Start 4 By 7 Matrix 1st Row 1st
    Column 1 2nd Column 1 3rd Column 2 4th Column 1 5th Column 0 6th Column 0 7th
    Column 0 2nd Row 1st Column 0 2nd Column 1 3rd Column 6 4th Column 0 5th Column
    1 6th Column 0 7th Column 0 3rd Row 1st Column 1 2nd Column 0 3rd Column 0 4th
    Column 0 5th Column 0 6th Column 1 7th Column 0 4th Row 1st Column 0 2nd Column
    1 3rd Column 0 4th Column 0 5th Column 0 6th Column 0 7th Column 1 EndMatrix"><mrow><mi>A</mi>
    <mo>=</mo> <mfenced close=")" open="("><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd>
    <mtd><mn>2</mn></mtd> <mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd> <mtd><mn>6</mn></mtd>
    <mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd>
    <mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd>
    <mtd><mn>1</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd> <mtd><mn>0</mn></mtd>
    <mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></math>
    , and <math alttext="b equals Start 4 By 1 Matrix 1st Row  8 2nd Row  12 3rd Row  4
    4th Row  6 EndMatrix"><mrow><mi>b</mi> <mo>=</mo> <mfenced close=")" open="("><mtable><mtr><mtd><mn>8</mn></mtd></mtr>
    <mtr><mtd><mn>12</mn></mtd></mtr> <mtr><mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>6</mn></mtd></mtr></mtable></mfenced></mrow></math>
    , then we can choose <math alttext="a 4 comma a 5 comma a 6 comma a 7"><mrow><msub><mi>a</mi>
    <mn>4</mn></msub> <mo>,</mo> <msub><mi>a</mi> <mn>5</mn></msub> <mo>,</mo> <msub><mi>a</mi>
    <mn>6</mn></msub> <mo>,</mo> <msub><mi>a</mi> <mn>7</mn></msub></mrow></math>
    as a set of basic columns, giving x=(0,0,0,8,12,4,6) as a basic feasible solution
    (coordinates of one vertex of the polyhedron). We can alternatively choose <math
    alttext="a 3 comma a 5 comma a 6 comma a 7"><mrow><msub><mi>a</mi> <mn>3</mn></msub>
    <mo>,</mo> <msub><mi>a</mi> <mn>5</mn></msub> <mo>,</mo> <msub><mi>a</mi> <mn>6</mn></msub>
    <mo>,</mo> <msub><mi>a</mi> <mn>7</mn></msub></mrow></math> as another set of
    basic columns, giving x=(0,0,4,0,-12,4,6) as basic solution but *not* basic feasible,
    because it has a negative coordinate.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Move to another vertex <math alttext="y equals x plus theta Superscript asterisk
    Baseline d"><mrow><mi>y</mi> <mo>=</mo> <mi>x</mi> <mo>+</mo> <msup><mi>θ</mi>
    <mo>*</mo></msup> <mi>d</mi></mrow></math> in a feasible direction *d* that increases
    only one non-basic variable <math alttext="x Subscript j"><msub><mi>x</mi> <mi>j</mi></msub></math>
    and keeps the other non-basic variables at zero level (coordinates of *d*: <math
    alttext="d Subscript j Baseline equals 1"><mrow><msub><mi>d</mi> <mi>j</mi></msub>
    <mo>=</mo> <mn>1</mn></mrow></math> , <math alttext="d Subscript i Baseline equals
    0"><mrow><msub><mi>d</mi> <mi>i</mi></msub> <mo>=</mo> <mn>0</mn></mrow></math>
    if <math alttext="i not-equals j"><mrow><mi>i</mi> <mo>≠</mo> <mi>j</mi></mrow></math>
    or *i* non-basic, and <math alttext="d Subscript upper B Baseline equals minus
    upper B Superscript negative 1 Baseline upper A Subscript j"><mrow><msub><mi>d</mi>
    <mi>B</mi></msub> <mo>=</mo> <mo>-</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msub><mi>A</mi> <mi>j</mi></msub></mrow></math> ) that is guaranteed to reduce
    the cost (reduced cost associated with introducing <math alttext="x Subscript
    j"><msub><mi>x</mi> <mi>j</mi></msub></math> is <math alttext="c overbar Subscript
    j Baseline equals c Subscript j Baseline minus c Subscript upper B Baseline period
    upper B Superscript negative 1 Baseline upper A Subscript j Baseline"><mrow><msub><mover
    accent="true"><mi>c</mi> <mo>¯</mo></mover> <mi>j</mi></msub> <mo>=</mo> <msub><mi>c</mi>
    <mi>j</mi></msub> <mo>-</mo> <msub><mi>c</mi> <mi>B</mi></msub> <mo>.</mo> <msup><mi>B</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msub><mi>A</mi> <mi>j</mi></msub></mrow></math>
    , so choose a *j* for which this quantity is negative). Value of <math alttext="theta
    Superscript asterisk"><msup><mi>θ</mi> <mo>*</mo></msup></math>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign theta Superscript asterisk Baseline equals min Underscript
    all basic indices for which d Subscript upper B left-parenthesis i right-parenthesis
    Baseline less-than 0 Endscripts left-brace minus StartFraction x Subscript upper
    B left-parenthesis i right-parenthesis Baseline Over d Subscript upper B left-parenthesis
    i right-parenthesis Baseline EndFraction right-brace colon equals minus StartFraction
    x Subscript upper B left-parenthesis l right-parenthesis Baseline Over d Subscript
    upper B left-parenthesis l right-parenthesis Baseline EndFraction semicolon dollar-sign"><mrow><msup><mi>θ</mi>
    <mo>*</mo></msup> <mo>=</mo> <msub><mo form="prefix" movablelimits="true">min</mo>
    <mrow><mtext>all</mtext><mtext>basic</mtext><mtext>indices</mtext><mtext>for</mtext><mtext>which</mtext><msub><mi>d</mi>
    <mrow><mi>B</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub> <mo><</mo><mn>0</mn></mrow></msub>
    <mfenced close="}" open="{" separators=""><mo>-</mo> <mfrac><msub><mi>x</mi> <mrow><mi>B</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub>
    <msub><mi>d</mi> <mrow><mi>B</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub></mfrac></mfenced>
    <mo>:</mo> <mo>=</mo> <mo>-</mo> <mfrac><msub><mi>x</mi> <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub>
    <msub><mi>d</mi> <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub></mfrac>
    <mo>;</mo></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="upper A Subscript upper B left-parenthesis l right-parenthesis"><msub><mi>A</mi>
    <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub></math> exits the
    basis *B* and <math alttext="upper A Subscript j"><msub><mi>A</mi> <mi>j</mi></msub></math>
    replaces it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat until we either reach a finite optimal solution (when no <math alttext="upper
    A Subscript j"><msub><mi>A</mi> <mi>j</mi></msub></math> from all the available
    columns of *A* gives us a negative <math alttext="c Subscript j"><msub><mi>c</mi>
    <mi>j</mi></msub></math> ), or discover that the problem is unbounded and the
    optimal cost is <math alttext="negative normal infinity"><mrow><mo>-</mo> <mi>∞</mi></mrow></math>
    (this happens when we have <math alttext="d greater-than-or-equal-to 0"><mrow><mi>d</mi>
    <mo>≥</mo> <mn>0</mn></mrow></math> , so <math alttext="y equals x plus theta
    d greater-than-or-equal-to 0"><mrow><mi>y</mi> <mo>=</mo> <mi>x</mi> <mo>+</mo>
    <mi>θ</mi> <mi>d</mi> <mo>≥</mo> <mn>0</mn></mrow></math> making it feasible no
    matter how large <math alttext="theta"><mi>θ</mi></math> gets, thus pushing <math
    alttext="theta"><mi>θ</mi></math> to <math alttext="normal infinity"><mi>∞</mi></math>
    will keep reducing the cost <math alttext="c period y equals c period x plus theta
    left-parenthesis c Subscript j Baseline minus c Subscript upper B Baseline period
    upper B Superscript negative 1 Baseline upper A Subscript j Baseline right-parenthesis"><mrow><mi>c</mi>
    <mo>.</mo> <mi>y</mi> <mo>=</mo> <mi>c</mi> <mo>.</mo> <mi>x</mi> <mo>+</mo> <mi>θ</mi>
    <mo>(</mo> <msub><mi>c</mi> <mi>j</mi></msub> <mo>-</mo> <msub><mi>c</mi> <mi>B</mi></msub>
    <mo>.</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msub><mi>A</mi>
    <mi>j</mi></msub> <mo>)</mo></mrow></math> all the way to <math alttext="negative
    normal infinity"><mrow><mo>-</mo> <mi>∞</mi></mrow></math> ).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Notes on the simplex method described above
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The last item above gives the two termination criteria for the simplex algorithm:
    No negative reduced cost <math alttext="c overbar Subscript j"><msub><mover accent="true"><mi>c</mi>
    <mo>¯</mo></mover> <mi>j</mi></msub></math> or all the coordinates of a feasible
    reducing cost direction *d* are nonnegative.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the feasible set is non-empty and every basic feasible solution is non-degenerate,
    then the simplex method is guaranteed to terminate after finitely many iterations,
    with either a finite optimal solution or a <math alttext="negative normal infinity"><mrow><mo>-</mo>
    <mi>∞</mi></mrow></math> optimal cost.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Suppose some of the basic feasible solutions are degenerate (some of the *basic*
    variables are also zero) and we end up at one of them. In this case, there is
    a chance that when we change the basis by introducing <math alttext="upper A Subscript
    j"><msub><mi>A</mi> <mi>j</mi></msub></math> and making <math alttext="upper A
    Subscript upper B left-parenthesis l right-parenthesis"><msub><mi>A</mi> <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub></math>
    exit, we stay at the same point *y=x+0d* (this happens when <math alttext="x Subscript
    upper B left-parenthesis l right-parenthesis Baseline equals 0"><mrow><msub><mi>x</mi>
    <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub> <mo>=</mo> <mn>0</mn></mrow></math>
    so <math alttext="theta Superscript asterisk Baseline equals minus StartFraction
    x Subscript upper B left-parenthesis l right-parenthesis Baseline Over d Subscript
    upper B left-parenthesis l right-parenthesis Baseline EndFraction equals 0"><mrow><msup><mi>θ</mi>
    <mo>*</mo></msup> <mo>=</mo> <mo>-</mo> <mfrac><msub><mi>x</mi> <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub>
    <msub><mi>d</mi> <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub></mfrac>
    <mo>=</mo> <mn>0</mn></mrow></math> )! In this case, choose a new <math alttext="upper
    A Subscript j"><msub><mi>A</mi> <mi>j</mi></msub></math> until you actually move
    from *x* to <math alttext="y equals x plus theta Superscript asterisk Baseline
    d"><mrow><mi>y</mi> <mo>=</mo> <mi>x</mi> <mo>+</mo> <msup><mi>θ</mi> <mo>*</mo></msup>
    <mi>d</mi></mrow></math> , <math alttext="theta Superscript asterisk Baseline
    greater-than 0"><mrow><msup><mi>θ</mi> <mo>*</mo></msup> <mo>></mo> <mn>0</mn></mrow></math>
    . One really bad thing that could happen here: After we stop at *x* and keep changing
    basis (stalling for a little while at *x*) until we find one that actually moves
    us away from *x* to <math alttext="y equals x plus theta Superscript asterisk
    Baseline d"><mrow><mi>y</mi> <mo>=</mo> <mi>x</mi> <mo>+</mo> <msup><mi>θ</mi>
    <mo>*</mo></msup> <mi>d</mi></mrow></math> in a cost reducing direction, we might
    end up with the same basis we started the algorithm with! This will lead to cycling
    and the algorithm may loop indefinitely. Cycling can be avoided by making smart
    choices on which columns of *A* will enter and exit the basis: Systematic way
    of choosing <math alttext="upper A Subscript j"><msub><mi>A</mi> <mi>j</mi></msub></math>
    and later *B(l)* in <math alttext="theta Superscript asterisk"><msup><mi>θ</mi>
    <mo>*</mo></msup></math> when there are ties in the process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When there are ties in the process (we have more than one reducing cost option
    <math alttext="upper A Subscript j"><msub><mi>A</mi> <mi>j</mi></msub></math>
    that gives <math alttext="c overbar Subscript j Baseline less-than 0"><mrow><msub><mover
    accent="true"><mi>c</mi> <mo>¯</mo></mover> <mi>j</mi></msub> <mo><</mo> <mn>0</mn></mrow></math>
    , and/or more than one minimizing index *B(l)* for <math alttext="theta Superscript
    asterisk"><msup><mi>θ</mi> <mo>*</mo></msup></math> ) we can devise rules to choose
    entering <math alttext="upper A Subscript j"><msub><mi>A</mi> <mi>j</mi></msub></math>
    and/or exiting <math alttext="upper A Subscript upper B left-parenthesis l right-parenthesis"><msub><mi>A</mi>
    <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub></math> at a step
    with such tie. The choosing rules we decide to follow when there are such ties
    are called *pivoting* rules.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A very simple and computationally inexpensive pivoting rule is *Bland’s rule*:
    choose <math alttext="upper A Subscript j"><msub><mi>A</mi> <mi>j</mi></msub></math>
    with smallest index *j* for which <math alttext="c overbar Subscript j Baseline
    less-than 0"><mrow><msub><mover accent="true"><mi>c</mi> <mo>¯</mo></mover> <mi>j</mi></msub>
    <mo><</mo> <mn>0</mn></mrow></math> to enter the basis, and choose <math alttext="upper
    A Subscript upper B left-parenthesis l right-parenthesis"><msub><mi>A</mi> <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub></math>
    with smallest eligible index *B(l)* to exit the basis. This smallest subscript
    pivoting rule helps us avoid cycling. Another pivoting rule is *Lexicography*:
    see book page 108.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If *n-m=2* (so *A* has only *2* more column than rows), then the simplex method
    will not cycle no matter which pivoting rule is used.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Choosing an initial basis to start the simplex method*: For problems that
    did not originate from a general form problem, especially those with a large number
    of variables, it might not always be obvious how to choose the initial basis *B*
    and associated basic feasible solution *x* (because it wouldn’t be clear which
    *m* columns of *A* are linearly independent. In this case, we introduce *artificial
    variables* and solve an *auxiliary linear programming problem* in order to: determine
    whether the original problem is *infeasible* and hence their is no solution; or,
    if the problem is feasible, drive the artificial variables out of the basis and
    obtain an initial basis and associated basic feasible solution for our original
    problem. This process is called *Phase I* of the simplex method.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is a method that combines Phase I and Phase II of the simplex method called
    *The big-M Method*. Here we use the simplex method to solve
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column upper A x plus b equals 0 2nd Row 1st Column Blank 2nd Column x greater-than-or-equal-to
    0 comma y greater-than-or-equal-to 0 EndLayout Endscripts c period x plus upper
    M left-parenthesis y 1 plus y 2 plus period period period plus y Subscript m Baseline
    right-parenthesis dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo>
    <mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mi>A</mi><mi>x</mi><mo>+</mo><mi>b</mi><mo>=</mo><mn>0</mn></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mrow><mi>x</mi><mo>≥</mo><mn>0</mn><mo>,</mo><mi>y</mi><mo>≥</mo><mn>0</mn></mrow></mtd></mtr></mtable></msub>
    <mi>c</mi> <mo>.</mo> <mi>x</mi> <mo>+</mo> <mi>M</mi> <mrow><mo>(</mo> <msub><mi>y</mi>
    <mn>1</mn></msub> <mo>+</mo> <msub><mi>y</mi> <mn>2</mn></msub> <mo>+</mo> <mo>.</mo>
    <mo>.</mo> <mo>.</mo> <mo>+</mo> <msub><mi>y</mi> <mi>m</mi></msub> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: For sufficiently large choice of *M*, if the original problem is feasible and
    its optimal cost is finite, all of the artificial variables <math alttext="y 1
    comma y 2 comma ellipsis comma y Subscript m Baseline"><mrow><msub><mi>y</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>y</mi> <mn>2</mn></msub> <mo>,</mo> <mo>⋯</mo>
    <mo>,</mo> <msub><mi>y</mi> <mi>m</mi></msub></mrow></math> are eventually driven
    to zero which takes us back to our original problem. *M* can be treated as an
    undetermined parameter and let the reduced costs be functions of *M*, and treat
    *M* as a very large number when determining whether a reduced cost is negative.
  prefs: []
  type: TYPE_NORMAL
- en: The Revised Simplex Method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The revised simplex method is a computationally less expensive implementation.
    It provides a cheaper way to compute <math alttext="upper B overbar Superscript
    negative 1"><msup><mover accent="true"><mi>B</mi> <mo>¯</mo></mover> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    by exploiting the relationship between the old basis *B* and the new basis <math
    alttext="upper B overbar"><mover accent="true"><mi>B</mi> <mo>¯</mo></mover></math>
    : They only have one different column (the two vertices involved are adjacent).
    So we can obtain the new <math alttext="upper B overbar Superscript negative 1"><msup><mover
    accent="true"><mi>B</mi> <mo>¯</mo></mover> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    from the previous <math alttext="upper B Superscript negative 1"><msup><mi>B</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a typical iteration of the revised simplex algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Start with a *B* consisting of *m* basic columns from *A* and the associated
    basic feasible solution *x* with <math alttext="x Subscript upper B Baseline equals
    upper B Superscript negative 1 Baseline b"><mrow><msub><mi>x</mi> <mi>B</mi></msub>
    <mo>=</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>b</mi></mrow></math>
    and <math alttext="x Subscript i Baseline equals 0"><mrow><msub><mi>x</mi> <mi>i</mi></msub>
    <mo>=</mo> <mn>0</mn></mrow></math> otherwise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute <math alttext="upper B Superscript negative 1"><msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    (it is <math alttext="upper B Superscript negative 1"><msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    not *B* that appears in the simplex method computations).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For *j* nonbasic, compute the reduced costs <math alttext="c overbar Subscript
    j Baseline equals c Subscript j Baseline minus c Subscript upper B Baseline period
    upper B Superscript negative 1 Baseline upper A Subscript j Baseline"><mrow><msub><mover
    accent="true"><mi>c</mi> <mo>¯</mo></mover> <mi>j</mi></msub> <mo>=</mo> <msub><mi>c</mi>
    <mi>j</mi></msub> <mo>-</mo> <msub><mi>c</mi> <mi>B</mi></msub> <mo>.</mo> <msup><mi>B</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msub><mi>A</mi> <mi>j</mi></msub></mrow></math>
    (this will give you *n-m* reduced costs).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If all the <math alttext="c overbar Subscript j"><msub><mover accent="true"><mi>c</mi>
    <mo>¯</mo></mover> <mi>j</mi></msub></math> are nonnegative, the current basic
    feasible solution *x* is optimal and the algorithm terminates with *x* as the
    optimizer and *c.x* as the optimal cost (there is no <math alttext="upper A Subscript
    j"><msub><mi>A</mi> <mi>j</mi></msub></math> that could enter the basis and reduce
    the cost even more).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*else*, choose a *j* for which <math alttext="c overbar Subscript j Baseline
    less-than 0"><mrow><msub><mover accent="true"><mi>c</mi> <mo>¯</mo></mover> <mi>j</mi></msub>
    <mo><</mo> <mn>0</mn></mrow></math> (Bland’s pivoting rule tells us to choose
    the smallest such *j*). *Note*: This makes <math alttext="upper A Subscript j"><msub><mi>A</mi>
    <mi>j</mi></msub></math> enter the basis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Compute feasible direction *d*: <math alttext="d Subscript j Baseline equals
    1"><mrow><msub><mi>d</mi> <mi>j</mi></msub> <mo>=</mo> <mn>1</mn></mrow></math>
    , <math alttext="d Subscript upper B Baseline equals minus upper B Superscript
    negative 1 Baseline upper A Subscript j"><mrow><msub><mi>d</mi> <mi>B</mi></msub>
    <mo>=</mo> <mo>-</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msub><mi>A</mi> <mi>j</mi></msub></mrow></math> and <math alttext="d Subscript
    i Baseline equals 0"><mrow><msub><mi>d</mi> <mi>i</mi></msub> <mo>=</mo> <mn>0</mn></mrow></math>
    otherwise.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If all the components of <math alttext="d Subscript upper B"><msub><mi>d</mi>
    <mi>B</mi></msub></math> are non-negative, the algorithm terminates with optimal
    cost <math alttext="negative normal infinity"><mrow><mo>-</mo> <mi>∞</mi></mrow></math>
    and no optimizer.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*else* (choose the components of <math alttext="d Subscript upper B"><msub><mi>d</mi>
    <mi>B</mi></msub></math> that are negative), let'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign theta Superscript asterisk Baseline equals min Underscript
    all basic indices for which d Subscript upper B left-parenthesis i right-parenthesis
    Baseline less-than 0 Endscripts left-brace minus StartFraction x Subscript upper
    B left-parenthesis i right-parenthesis Baseline Over d Subscript upper B left-parenthesis
    i right-parenthesis Baseline EndFraction right-brace colon equals minus StartFraction
    x Subscript upper B left-parenthesis l right-parenthesis Baseline Over d Subscript
    upper B left-parenthesis l right-parenthesis Baseline EndFraction dollar-sign"><mrow><msup><mi>θ</mi>
    <mo>*</mo></msup> <mo>=</mo> <msub><mo form="prefix" movablelimits="true">min</mo>
    <mrow><mtext>all</mtext><mtext>basic</mtext><mtext>indices</mtext><mtext>for</mtext><mtext>which</mtext><msub><mi>d</mi>
    <mrow><mi>B</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub> <mo><</mo><mn>0</mn></mrow></msub>
    <mfenced close="}" open="{" separators=""><mo>-</mo> <mfrac><msub><mi>x</mi> <mrow><mi>B</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub>
    <msub><mi>d</mi> <mrow><mi>B</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub></mfrac></mfenced>
    <mo>:</mo> <mo>=</mo> <mo>-</mo> <mfrac><msub><mi>x</mi> <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub>
    <msub><mi>d</mi> <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This step computes <math alttext="theta Superscript asterisk"><msup><mi>θ</mi>
    <mo>*</mo></msup></math> and assigns *B(l)* as the index of the exiting column.
  prefs: []
  type: TYPE_NORMAL
- en: Compute the new basic feasible solution <math alttext="y equals x plus theta
    Superscript asterisk Baseline d"><mrow><mi>y</mi> <mo>=</mo> <mi>x</mi> <mo>+</mo>
    <msup><mi>θ</mi> <mo>*</mo></msup> <mi>d</mi></mrow></math> (this new basic feasible
    solution corresponds to the new basis <math alttext="upper B overbar"><mover accent="true"><mi>B</mi>
    <mo>¯</mo></mover></math> which has <math alttext="upper A Subscript j"><msub><mi>A</mi>
    <mi>j</mi></msub></math> replace <math alttext="upper A Subscript upper B left-parenthesis
    l right-parenthesis"><msub><mi>A</mi> <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub></math>
    in *B*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This step computes the new <math alttext="upper B overbar Superscript negative
    1"><msup><mover accent="true"><mi>B</mi> <mo>¯</mo></mover> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    for the next iteration without forming the new basis <math alttext="upper B overbar"><mover
    accent="true"><mi>B</mi> <mo>¯</mo></mover></math> then inverting it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Form the <math alttext="m times m plus 1"><mrow><mi>m</mi> <mo>×</mo> <mi>m</mi>
    <mo>+</mo> <mn>1</mn></mrow></math> augmented matrix <math alttext="left-parenthesis
    upper B Superscript negative 1 Baseline vertical-bar upper B Superscript negative
    1 Baseline upper A Subscript j Baseline right-parenthesis"><mrow><mo>(</mo> <msup><mi>B</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mo>|</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msub><mi>A</mi> <mi>j</mi></msub> <mo>)</mo></mrow></math> . Perform row operations
    using the *l*‘th row (add to each row a multiple of the *l*‘th row) to make the
    last column the unit vector <math alttext="e Subscript l"><msub><mi>e</mi> <mi>l</mi></msub></math>
    which is zero everywhere except for *1* in the *l*‘th coordinate. The first *m*
    columns of the result is your new <math alttext="upper B overbar Superscript negative
    1"><msup><mover accent="true"><mi>B</mi> <mo>¯</mo></mover> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    .
  prefs: []
  type: TYPE_NORMAL
- en: Justification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let <math alttext="u equals upper B Superscript negative 1 Baseline upper A
    Subscript j"><mrow><mi>u</mi> <mo>=</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msub><mi>A</mi> <mi>j</mi></msub></mrow></math> and note that <math alttext="upper
    B Superscript negative 1 Baseline upper B overbar equals left-parenthesis e 1
    e 2 ellipsis u ellipsis e Subscript m Baseline right-parenthesis"><mrow><msup><mi>B</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mover accent="true"><mi>B</mi> <mo>¯</mo></mover>
    <mo>=</mo> <mrow><mo>(</mo> <msub><mi>e</mi> <mn>1</mn></msub> <msub><mi>e</mi>
    <mn>2</mn></msub> <mo>⋯</mo> <mi>u</mi> <mo>⋯</mo> <msub><mi>e</mi> <mi>m</mi></msub>
    <mo>)</mo></mrow></mrow></math> where <math alttext="e Subscript i"><msub><mi>e</mi>
    <mi>i</mi></msub></math> is the unit column vector with *1* in the *i*‘th entry
    and zero everywhere else, and *u* is the *l*‘th column. The above matrix becomes
    the identity matrix if we perform row operations using the *l*‘th row and transformed
    *u* into <math alttext="e Subscript l"><msub><mi>e</mi> <mi>l</mi></msub></math>
    . All row operations can be bundled together in an invertible matrix *Q* applied
    from the left: <math alttext="upper Q upper B Superscript negative 1 Baseline
    upper B overbar equals upper I"><mrow><mi>Q</mi> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mover accent="true"><mi>B</mi> <mo>¯</mo></mover> <mo>=</mo> <mi>I</mi></mrow></math>
    . Now right multiply by <math alttext="upper B overbar Superscript negative 1"><msup><mover
    accent="true"><mi>B</mi> <mo>¯</mo></mover> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    , we get <math alttext="upper Q upper B Superscript negative 1 Baseline equals
    upper B overbar Superscript negative 1"><mrow><mi>Q</mi> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mo>=</mo> <msup><mover accent="true"><mi>B</mi> <mo>¯</mo></mover> <mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math>
    . This means that to obtain <math alttext="upper B overbar Superscript negative
    1"><msup><mover accent="true"><mi>B</mi> <mo>¯</mo></mover> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    , perform on <math alttext="upper B Superscript negative 1"><msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    the same row operations that will transform *u* to <math alttext="e Subscript
    l"><msub><mi>e</mi> <mi>l</mi></msub></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating <math alttext="upper B overbar Superscript negative 1"><msup><mover
    accent="true"><mi>B</mi> <mo>¯</mo></mover> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    using <math alttext="upper B Superscript negative 1"><msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    in the revised simplex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This method does not start from the original *m* columns of *A* and finds the
    inverse, instead, it does row operations on previously calculated <math alttext="upper
    B Superscript negative 1"><msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    , which could include roundoff errors. Doing this over many iterations will accumulate
    these errors, so it will be better to compute <math alttext="upper B overbar Superscript
    negative 1"><msup><mover accent="true"><mi>B</mi> <mo>¯</mo></mover> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    straight from the columns of *A* every now and then to avoid error accumulation.
  prefs: []
  type: TYPE_NORMAL
- en: The Full Tableuax Implementation of the Simplex Method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **full tableaux implementation of the simplex method** has the advantage
    of only storing and updating one matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, instead of maintaining and updating <math alttext="upper B Superscript
    negative 1"><msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math> ,
    maintain and update the <math alttext="m times n plus 1"><mrow><mi>m</mi> <mo>×</mo>
    <mi>n</mi> <mo>+</mo> <mn>1</mn></mrow></math> matrix <math alttext="x Subscript
    upper B Baseline vertical-bar upper B Superscript negative 1 Baseline upper A
    right-parenthesis equals left-parenthesis upper B Superscript negative 1 Baseline
    b vertical-bar upper B Superscript negative 1 Baseline upper A"><mrow><msub><mi>x</mi>
    <mi>B</mi></msub> <mrow><mo>|</mo></mrow> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mrow><mi>A</mi> <mo>)</mo> <mo>=</mo> <mo>(</mo></mrow> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mrow><mi>b</mi> <mo>|</mo></mrow> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mi>A</mi></mrow></math> . The column <math alttext="u equals upper B Superscript
    negative 1 Baseline upper A Subscript j"><mrow><mi>u</mi> <mo>=</mo> <msup><mi>B</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msub><mi>A</mi> <mi>j</mi></msub></mrow></math>
    corresponding to the variable entering the basis is called the *pivot column*.
    If the *l* th basic variable exits the basis, then the *l* th row is called the
    *pivot row*. The element belonging to both the pivot row and the pivot column
    is called the *pivot element*. Now add a *zeroth row* on top of your *tableau*
    that keeps track of negative of the current cost <math alttext="negative c period
    x equals minus c Subscript upper B Baseline period x Subscript upper B Baseline
    equals c Subscript upper B Baseline period upper B Superscript negative 1 Baseline
    b"><mrow><mo>-</mo> <mi>c</mi> <mo>.</mo> <mi>x</mi> <mo>=</mo> <mo>-</mo> <msub><mi>c</mi>
    <mi>B</mi></msub> <mo>.</mo> <msub><mi>x</mi> <mi>B</mi></msub> <mo>=</mo> <msub><mi>c</mi>
    <mi>B</mi></msub> <mo>.</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mi>b</mi></mrow></math> and the reduced costs <math alttext="c minus c Subscript
    upper B Baseline period upper B Superscript negative 1 Baseline upper A"><mrow><mi>c</mi>
    <mo>-</mo> <msub><mi>c</mi> <mi>B</mi></msub> <mo>.</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mi>A</mi></mrow></math> . So the tableau looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign Start 2 By 2 Matrix 1st Row 1st Column minus c Subscript
    upper B Baseline period upper B Superscript negative 1 Baseline b 2nd Column c
    minus c Subscript upper B Baseline period upper B Superscript negative 1 Baseline
    upper A 2nd Row 1st Column upper B Superscript negative 1 Baseline b 2nd Column
    upper B Superscript negative 1 Baseline upper A EndMatrix dollar-sign"><mfenced
    close=")" open="("><mtable><mtr><mtd><mrow><mo>-</mo> <msub><mi>c</mi> <mi>B</mi></msub>
    <mo>.</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>b</mi></mrow></mtd>
    <mtd><mrow><mi>c</mi> <mo>-</mo> <msub><mi>c</mi> <mi>B</mi></msub> <mo>.</mo>
    <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>A</mi></mrow></mtd></mtr>
    <mtr><mtd><mrow><msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>b</mi></mrow></mtd>
    <mtd><mrow><msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>A</mi></mrow></mtd></mtr></mtable></mfenced></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'or more expanded:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign Start 4 By 2 Matrix 1st Row 1st Column minus c Subscript
    upper B Baseline period x Subscript upper B Baseline 2nd Column c overbar Subscript
    1 Baseline ellipsis c overbar Subscript n 2nd Row 1st Column x Subscript upper
    B left-parenthesis 1 right-parenthesis 2nd Column StartAbsoluteValue ellipsis
    EndAbsoluteValue 3rd Row 1st Column  ellipsis 2nd Column upper B Superscript negative
    1 Baseline upper A 1 ellipsis upper B Superscript negative 1 Baseline upper A
    Subscript n 4th Row 1st Column x Subscript upper B left-parenthesis m right-parenthesis
    2nd Column StartAbsoluteValue ellipsis EndAbsoluteValue EndMatrix dollar-sign"><mfenced
    close=")" open="("><mtable><mtr><mtd><mrow><mo>-</mo> <msub><mi>c</mi> <mi>B</mi></msub>
    <mo>.</mo> <msub><mi>x</mi> <mi>B</mi></msub></mrow></mtd> <mtd><mrow><msub><mover
    accent="true"><mi>c</mi> <mo>¯</mo></mover> <mn>1</mn></msub> <mo>⋯</mo> <msub><mover
    accent="true"><mi>c</mi> <mo>¯</mo></mover> <mi>n</mi></msub></mrow></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mrow><mi>B</mi><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msub></mtd>
    <mtd><mrow><mo>|</mo> <mo>⋯</mo> <mo>|</mo></mrow></mtd></mtr> <mtr><mtd><mo>⋮</mo></mtd>
    <mtd><mrow><msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msub><mi>A</mi>
    <mn>1</mn></msub> <mo>⋯</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msub><mi>A</mi> <mi>n</mi></msub></mrow></mtd></mtr> <mtr><mtd><msub><mi>x</mi>
    <mrow><mi>B</mi><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msub></mtd> <mtd><mrow><mo>|</mo>
    <mo>⋯</mo> <mo>|</mo></mrow></mtd></mtr></mtable></mfenced></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a typical iteration of the full tableau implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: Start with a tableau associated with a basis matrix *B* and the corresponding
    basic feasible solution *x* (with <math alttext="x Subscript upper B Baseline
    equals upper B Superscript negative 1 Baseline b"><mrow><msub><mi>x</mi> <mi>B</mi></msub>
    <mo>=</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>b</mi></mrow></math>
    and rest of coordinates zero).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Examine the reduced costs in the zeroth row of the tableau. If none of them
    is negative, then the current basic feasible solution *x* is optimal and the algorithm
    terminates. *Else*, choose some *j* for which <math alttext="c overbar Subscript
    j Baseline less-than 0"><mrow><msub><mover accent="true"><mi>c</mi> <mo>¯</mo></mover>
    <mi>j</mi></msub> <mo><</mo> <mn>0</mn></mrow></math> (this *j* tells you which
    <math alttext="upper A Subscript j"><msub><mi>A</mi> <mi>j</mi></msub></math>
    entered the basis and you have your pivot column <math alttext="u equals upper
    B Superscript negative 1 Baseline upper A Subscript j"><mrow><mi>u</mi> <mo>=</mo>
    <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msub><mi>A</mi> <mi>j</mi></msub></mrow></math>
    ).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Examine the pivot column <math alttext="u equals upper B Superscript negative
    1 Baseline upper A Subscript j"><mrow><mi>u</mi> <mo>=</mo> <msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msub><mi>A</mi> <mi>j</mi></msub></mrow></math> . If all the components of *u*
    are negative, the optimal cost is <math alttext="negative normal infinity"><mrow><mo>-</mo>
    <mi>∞</mi></mrow></math> and the algorithm terminates. *Else*, for each positive
    component <math alttext="u Subscript i"><msub><mi>u</mi> <mi>i</mi></msub></math>
    , compute <math alttext="StartFraction x Subscript upper B left-parenthesis i
    right-parenthesis Baseline Over u Subscript i Baseline EndFraction"><mfrac><msub><mi>x</mi>
    <mrow><mi>B</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub> <msub><mi>u</mi>
    <mi>i</mi></msub></mfrac></math> , choose the smallest ratio and let *l* be the
    index of the row that corresponds to the smallest ratio. This is your pivot row.
    (So what’s happening now is <math alttext="upper A Subscript upper B left-parenthesis
    l right-parenthesis"><msub><mi>A</mi> <mrow><mi>B</mi><mo>(</mo><mi>l</mi><mo>)</mo></mrow></msub></math>
    is exiting the basis and <math alttext="upper A Subscript j"><msub><mi>A</mi>
    <mi>j</mi></msub></math> is entering the basis, but none of this is explicitly
    shown here, since the columns of the tableau stay in the same place at all steps,
    it’s only a mental note.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now use the pivot row to perform row operations in order to change the pivot
    column to <math alttext="e Subscript l"><msub><mi>e</mi> <mi>l</mi></msub></math>
    (the pivot element becomes one and all the other entries in the pivot column zero).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now you have a new tableau with new <math alttext="x Subscript upper B"><msub><mi>x</mi>
    <mi>B</mi></msub></math> at the zeroth column, new negative of optimal cost at
    the upper left corner, new basis <math alttext="upper B overbar"><mover accent="true"><mi>B</mi>
    <mo>¯</mo></mover></math> not explicitly written but instead given in terms of
    <math alttext="upper B overbar Superscript negative 1 Baseline upper A"><mrow><msup><mover
    accent="true"><mi>B</mi> <mo>¯</mo></mover> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mi>A</mi></mrow></math> in the body of the tableau. So go back to step (a) until
    the algorithm terminates.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Most efficient implementation is the revised simplex (memory usage is <math
    alttext="upper O left-parenthesis m squared right-parenthesis"><mrow><mi>O</mi>
    <mo>(</mo> <msup><mi>m</mi> <mn>2</mn></msup> <mo>)</mo></mrow></math> , worst
    case time for single iteration is <math alttext="upper O left-parenthesis m n
    right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <mi>m</mi> <mi>n</mi> <mo>)</mo></mrow></math>
    , best case time for single iteration is <math alttext="upper O left-parenthesis
    m squared right-parenthesis"><mrow><mi>O</mi> <mo>(</mo> <msup><mi>m</mi> <mn>2</mn></msup>
    <mo>)</mo></mrow></math> while all the above measures for the full tableau method
    are <math alttext="upper O left-parenthesis m n right-parenthesis"><mrow><mi>O</mi>
    <mo>(</mo> <mi>m</mi> <mi>n</mi> <mo>)</mo></mrow></math> ), but that also depends
    on how sparse the matrices are.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'One helpful thing that is nice to master: Extracting <math alttext="upper B
    Superscript negative 1"><msup><mi>B</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>
    and *B* easily from a given simplex tableau (like in the movie: *The Matrix*).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples: Transportation and assignment problems'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We mentioned the transportation and assignment problems in the network section
    since they are linear optimization problems which we can formulate as min cost
    network flow problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Transportation problem: Allocating products to warehouses, minimize costs.
    Assignment problem: Allocate assignees to tasks, number of assignees is equal
    to the number of tasks, and each assignee performs one task. There is a cost when
    assignee i performs task j. The objective is to select an assignment that minimizes
    the cost. One example is assigning Uber drivers to customers, or machines to tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: We exploit the fact that the involved matrices are sparse so we don’t have to
    do full implementation of the simplex algorithm, only a special *streamlined*
    version, which solves both the assignment and transportation problems. This is
    related to the *network simplex method* which solves any minimum cost flow problem,
    including both transportation and assignment problems. The transportation and
    assignment problems are special cases of the minimum flow problem. The Hungarian
    method is special for the assignment problem. Since it is specialized for it,
    it is more efficient. These special purpose algorithms are included in some linear
    programming software packages.
  prefs: []
  type: TYPE_NORMAL
- en: Duality, Langrange Relaxation, Shadow Prices, Max Mins, Min Maxs, And All That
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We hinted and danced around the idea of *duality* earlier in this chapter when
    discussing finite dimensional constrained optimization and relaxing the constraints
    using Lagrange multipliers. Duality is really helpful when our constrained problems
    are linear, or quadratic with linear constraints. It gives us the option to either
    solve the optimization problem at hand (the *primal*) or another related problem
    (its *dual*), whichever happens to be easier or less expensive, and get the same
    solution. Usually, having more decision variables (dimensions of the problem)
    is not as strenuous for an algorithm as having more constraints. Since the dual
    problem flips the roles of decision variables and constraints, then solving it
    instead of the primal problem makes more sense when we have too many constraints
    (another way here is using the dual simplex method to solve the primal problem
    which we will talk about soon). Another way the dual problem helps is that it
    sometimes provides shortcuts to the solution of the primal problem. A feasible
    vector <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> to the primal problem will end up being the optimizer
    if there happens to be a feasible vector <math alttext="ModifyingAbove p With
    right-arrow"><mover accent="true"><mi>p</mi> <mo>→</mo></mover></math> to the
    dual problem such that <math alttext="ModifyingAbove c With right-arrow period
    ModifyingAbove x With right-arrow equals ModifyingAbove p With right-arrow period
    ModifyingAbove b With right-arrow"><mrow><mover accent="true"><mi>c</mi> <mo>→</mo></mover>
    <mo>.</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>=</mo> <mover
    accent="true"><mi>p</mi> <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>b</mi>
    <mo>→</mo></mover></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: 'When learning about duality in the next few paragraphs, think of it in the
    same way you see [Figure 10-8](#Fig_duality): Something is happening in the primal
    realm, some form of related shadow or echo is happening in the dual realm (some
    alternate universe), and the two meet at the optimizer, like a gate that the two
    universes meet at.'
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_1008.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-8\. Duality, shadow problems, shadow prices (I want an uncopy righted
    graphic that looks like this one).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: So if we are maximizing in one universe, we are minimizing in the other, if
    we are doing something with the constraints in one universe, we do something to
    the decision variables in the other and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: Motivation For Duality- Lagrange Multipliers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For any optimization problem (linear or nonlinear)
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript ModifyingAbove x With right-arrow
    element-of feasible set Endscripts f left-parenthesis ModifyingAbove x With right-arrow
    right-parenthesis comma dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo>
    <mrow><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>∈</mo><mtext>feasible</mtext><mtext>set</mtext></mrow></msub>
    <mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>,</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: instead of finding the minimizer <math alttext="ModifyingAbove x With right-arrow
    Superscript asterisk"><msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>*</mo></msup></math> by setting the gradient equal to zero, look for an upper
    bound of <math alttext="f left-parenthesis ModifyingAbove x With right-arrow Superscript
    asterisk Baseline right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mo>)</mo></mrow></math>
    (easy by plugging any element of the feasible set into <math alttext="f left-parenthesis
    ModifyingAbove x With right-arrow right-parenthesis"><mrow><mi>f</mi> <mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow></math> ),
    and for a lower bound of <math alttext="f left-parenthesis ModifyingAbove x With
    right-arrow Superscript asterisk Baseline right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup>
    <mo>)</mo></mrow></math> (this is a harder inequality and usually requires clever
    ideas). Now we would have *lower bound* <math alttext="f left-parenthesis ModifyingAbove
    x With right-arrow Superscript asterisk Baseline right-parenthesis less-than-or-equal-to"><mrow><mo>≤</mo>
    <mi>f</mi> <mo>(</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>*</mo></msup> <mo>)</mo> <mo>≤</mo></mrow></math> *upper bound*, so we *tighten*
    these bounds to get closer to the actual solution <math alttext="f left-parenthesis
    ModifyingAbove x With right-arrow Superscript asterisk Baseline right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup>
    <mo>)</mo></mrow></math> . We tighten the bounds by minimizing the upper bounds
    (this brings us back to the original minimization problem), and *maximizing the
    lower bounds* (this establishes the dual problem).
  prefs: []
  type: TYPE_NORMAL
- en: Now for a linear minimization problem in *any form* (standard form, general
    form, or neither),
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript linear constraints on ModifyingAbove
    x With right-arrow Endscripts ModifyingAbove c With right-arrow period ModifyingAbove
    x With right-arrow dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo>
    <mrow><mtext>linear</mtext><mtext>constraints</mtext><mtext>on</mtext><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></mrow></msub> <mover accent="true"><mi>c</mi> <mo>→</mo></mover>
    <mo>.</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: what is the clever idea that gives us lower bounds for <math alttext="f left-parenthesis
    ModifyingAbove x With right-arrow right-parenthesis equals ModifyingAbove c With
    right-arrow period ModifyingAbove x With right-arrow"><mrow><mi>f</mi> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>=</mo>
    <mover accent="true"><mi>c</mi> <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></mrow></math> ? We look for lower bounds for <math alttext="f
    left-parenthesis ModifyingAbove x With right-arrow right-parenthesis equals ModifyingAbove
    c With right-arrow period ModifyingAbove x With right-arrow"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>=</mo> <mover accent="true"><mi>c</mi> <mo>→</mo></mover> <mo>.</mo> <mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math> made up of a *linear
    combination* of the problem constraints. So we multiply each of our constraints
    by multipliers <math alttext="p Subscript i"><msub><mi>p</mi> <mi>i</mi></msub></math>
    (Lagrange multipliers), choosing their signs in a way that the constraint inequality
    is in the <math alttext="greater-than-or-equal-to"><mo>≥</mo></math> direction.
    How so? Well, the linear constraints are linear combinations of the entries of
    <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> , the objective function <math alttext="ModifyingAbove
    c With right-arrow period ModifyingAbove x With right-arrow"><mrow><mover accent="true"><mi>c</mi>
    <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math>
    is also a linear combination of the entries of <math alttext="ModifyingAbove x
    With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math> ,
    a linear combination of a linear combination is still a linear combination, so
    we can totally pick a linear combination of the constraints that we can compare
    to <math alttext="ModifyingAbove c With right-arrow period ModifyingAbove x With
    right-arrow"><mrow><mover accent="true"><mi>c</mi> <mo>→</mo></mover> <mo>.</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: Namely, if we have *m* linear constraints, we need
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign p 1 b 1 plus p 2 b 2 plus ellipsis plus p Subscript
    m Baseline b Subscript m Baseline less-than-or-equal-to ModifyingAbove c With
    right-arrow period ModifyingAbove x With right-arrow dollar-sign"><mrow><msub><mi>p</mi>
    <mn>1</mn></msub> <msub><mi>b</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>p</mi>
    <mn>2</mn></msub> <msub><mi>b</mi> <mn>2</mn></msub> <mo>+</mo> <mo>⋯</mo> <mo>+</mo>
    <msub><mi>p</mi> <mi>m</mi></msub> <msub><mi>b</mi> <mi>m</mi></msub> <mo>≤</mo>
    <mover accent="true"><mi>c</mi> <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The sign of a multiplier <math alttext="p Subscript i"><msub><mi>p</mi> <mi>i</mi></msub></math>
    would be free if the constraint has an equality. Once we have these lower bounds,
    we tighten them by maximizing on <math alttext="p Subscript i"><msub><mi>p</mi>
    <mi>i</mi></msub></math> , which gives us the dual problem.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the dual linear optimization problem from the primal linear optimization
    problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is important to get the sizes of the inputs to a linear optimization problem
    right. The inputs are: *A* which is <math alttext="m times n"><mrow><mi>m</mi>
    <mo>×</mo> <mi>n</mi></mrow></math> , <math alttext="ModifyingAbove c With right-arrow"><mover
    accent="true"><mi>c</mi> <mo>→</mo></mover></math> which is <math alttext="n times
    1"><mrow><mi>n</mi> <mo>×</mo> <mn>1</mn></mrow></math> , <math alttext="ModifyingAbove
    b With right-arrow"><mover accent="true"><mi>b</mi> <mo>→</mo></mover></math>
    which is <math alttext="m times 1"><mrow><mi>m</mi> <mo>×</mo> <mn>1</mn></mrow></math>
    . The decision variables in the primal problem are in the vector <math alttext="ModifyingAbove
    x With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    which is <math alttext="n times 1"><mrow><mi>n</mi> <mo>×</mo> <mn>1</mn></mrow></math>
    . The decision variables in the dual problem are in the vector <math alttext="ModifyingAbove
    p With right-arrow"><mover accent="true"><mi>p</mi> <mo>→</mo></mover></math>
    which is <math alttext="m times 1"><mrow><mi>m</mi> <mo>×</mo> <mn>1</mn></mrow></math>
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, if *A* appears in the primal problem then <math alttext="upper
    A Superscript t"><msup><mi>A</mi> <mi>t</mi></msup></math> appears in the dual
    problem. So in the primal problem we have the dot product of the *rows* of *A*
    and <math alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></math> . In the dual problem we have the dot product of the
    *columns* of *A* and <math alttext="ModifyingAbove p With right-arrow"><mover
    accent="true"><mi>p</mi> <mo>→</mo></mover></math> . If the linear optimization
    problem is in *any form*, it’s easy to write its dual following this process:'
  prefs: []
  type: TYPE_NORMAL
- en: If the primal is a minimization then the dual is a maximization and vice-versa.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The primal cost function is <math alttext="ModifyingAbove c With right-arrow
    period ModifyingAbove x With right-arrow"><mrow><mover accent="true"><mi>c</mi>
    <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math>
    and the dual cost function is <math alttext="ModifyingAbove p With right-arrow
    period ModifyingAbove b With right-arrow"><mrow><mover accent="true"><mi>p</mi>
    <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></math>
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In a *minimization* primal problem, we separate the constraints into two types:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type One
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Constraints telling us about the sign of the decision variable, for example:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="x 3 greater-than-or-equal-to 0"><mrow><msub><mi>x</mi> <mn>3</mn></msub>
    <mo>≥</mo> <mn>0</mn></mrow></math> . Then in the dual this will correspond to
    <math alttext="upper A 3 period ModifyingAbove p With right-arrow less-than-or-equal-to
    c 3"><mrow><msub><mi>A</mi> <mn>3</mn></msub> <mo>.</mo> <mover accent="true"><mi>p</mi>
    <mo>→</mo></mover> <mo>≤</mo> <msub><mi>c</mi> <mn>3</mn></msub></mrow></math>
    where <math alttext="upper A 3"><msub><mi>A</mi> <mn>3</mn></msub></math> is the
    third column of *A* and <math alttext="c 3"><msub><mi>c</mi> <mn>3</mn></msub></math>
    is the third entry of <math alttext="ModifyingAbove c With right-arrow"><mover
    accent="true"><mi>c</mi> <mo>→</mo></mover></math> .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="x 12 less-than-or-equal-to 0"><mrow><msub><mi>x</mi> <mn>12</mn></msub>
    <mo>≤</mo> <mn>0</mn></mrow></math> . Then in the dual this will correspond to
    <math alttext="upper A 12 period p greater-than-or-equal-to c 12"><mrow><msub><mi>A</mi>
    <mn>12</mn></msub> <mo>.</mo> <mi>p</mi> <mo>≥</mo> <msub><mi>c</mi> <mn>12</mn></msub></mrow></math>
    where <math alttext="upper A 12"><msub><mi>A</mi> <mn>12</mn></msub></math> is
    the twelveth column of *A* and <math alttext="c 12"><msub><mi>c</mi> <mn>12</mn></msub></math>
    is the twelveth entry of <math alttext="ModifyingAbove c With right-arrow"><mover
    accent="true"><mi>c</mi> <mo>→</mo></mover></math> .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="x 5"><msub><mi>x</mi> <mn>5</mn></msub></math> is free meaning
    has no specified sign. Then in the dual this will correspond to <math alttext="upper
    A 5 period p equals c 5"><mrow><msub><mi>A</mi> <mn>5</mn></msub> <mo>.</mo> <mi>p</mi>
    <mo>=</mo> <msub><mi>c</mi> <mn>5</mn></msub></mrow></math> where <math alttext="upper
    A 5"><msub><mi>A</mi> <mn>5</mn></msub></math> is the fifth column of *A* and
    <math alttext="c 5"><msub><mi>c</mi> <mn>5</mn></msub></math> is the fifth entry
    of <math alttext="ModifyingAbove c With right-arrow"><mover accent="true"><mi>c</mi>
    <mo>→</mo></mover></math> .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type Two
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Constraints of the form <math alttext="a Subscript i Baseline period x greater-than-or-equal-to
    less-than-or-equal-to equals b Subscript i Baseline"><mrow><msub><mi>a</mi> <mi>i</mi></msub>
    <mo>.</mo> <mi>x</mi> <mo>≥</mo> <mo>≤</mo> <mo>=</mo> <msub><mi>b</mi> <mi>i</mi></msub></mrow></math>
    where <math alttext="a Subscript i"><msub><mi>a</mi> <mi>i</mi></msub></math>
    is the _i_th row of A. In the dual these will correspond to constraints on the
    sign of <math alttext="p Subscript i"><msub><mi>p</mi> <mi>i</mi></msub></math>
    , for example:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <math alttext="a 2 period x greater-than-or-equal-to b 2"><mrow><msub><mi>a</mi>
    <mn>2</mn></msub> <mo>.</mo> <mi>x</mi> <mo>≥</mo> <msub><mi>b</mi> <mn>2</mn></msub></mrow></math>
    . Then in the dual this will correspond to <math alttext="p 2 greater-than-or-equal-to
    0"><mrow><msub><mi>p</mi> <mn>2</mn></msub> <mo>≥</mo> <mn>0</mn></mrow></math>
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="a 7 period x less-than-or-equal-to b 7"><mrow><msub><mi>a</mi>
    <mn>7</mn></msub> <mo>.</mo> <mi>x</mi> <mo>≤</mo> <msub><mi>b</mi> <mn>7</mn></msub></mrow></math>
    . Then in the dual this will correspond to <math alttext="p 5 less-than-or-equal-to
    0"><mrow><msub><mi>p</mi> <mn>5</mn></msub> <mo>≤</mo> <mn>0</mn></mrow></math>
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <math alttext="a 8 period x equals b 8"><mrow><msub><mi>a</mi> <mn>8</mn></msub>
    <mo>.</mo> <mi>x</mi> <mo>=</mo> <msub><mi>b</mi> <mn>8</mn></msub></mrow></math>
    . Then the sign of <math alttext="p 8"><msub><mi>p</mi> <mn>8</mn></msub></math>
    is free.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In particular if the linear optimization problem is in standard form:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column upper A ModifyingAbove x With right-arrow equals ModifyingAbove b With
    right-arrow 2nd Row 1st Column Blank 2nd Column ModifyingAbove x With right-arrow
    greater-than-or-equal-to ModifyingAbove 0 With right-arrow EndLayout Endscripts
    ModifyingAbove c With right-arrow period ModifyingAbove x With right-arrow comma
    dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo> <mtable
    displaystyle="true"><mtr><mtd columnalign="left"><mrow><mi>A</mi><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover><mo>=</mo><mover accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mrow><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>≥</mo><mover
    accent="true"><mn>0</mn> <mo>→</mo></mover></mrow></mtd></mtr></mtable></msub>
    <mover accent="true"><mi>c</mi> <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>,</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'then its dual is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign max Underscript StartLayout 1st Row 1st Column Blank
    2nd Column ModifyingAbove p With right-arrow is free 2nd Row 1st Column Blank
    2nd Column upper A Superscript upper T Baseline ModifyingAbove p With right-arrow
    less-than-or-equal-to ModifyingAbove c With right-arrow EndLayout Endscripts ModifyingAbove
    p With right-arrow period ModifyingAbove b With right-arrow period dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">max</mo> <mtable displaystyle="true"><mtr><mtd
    columnalign="left"><mrow><mover accent="true"><mi>p</mi> <mo>→</mo></mover><mtext>is</mtext><mtext>free</mtext></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mrow><msup><mi>A</mi> <mi>T</mi></msup> <mover accent="true"><mi>p</mi>
    <mo>→</mo></mover><mo>≤</mo><mover accent="true"><mi>c</mi> <mo>→</mo></mover></mrow></mtd></mtr></mtable></msub>
    <mover accent="true"><mi>p</mi> <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>b</mi>
    <mo>→</mo></mover> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If the linear optimization problem is in general form:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column upper A ModifyingAbove x With right-arrow greater-than-or-equal-to
    ModifyingAbove b With right-arrow 2nd Row 1st Column Blank 2nd Column ModifyingAbove
    x With right-arrow is free EndLayout Endscripts ModifyingAbove c With right-arrow
    period ModifyingAbove x With right-arrow dollar-sign"><mrow><msub><mo form="prefix"
    movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mi>A</mi><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>≥</mo><mover accent="true"><mi>b</mi>
    <mo>→</mo></mover></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mtext>is</mtext><mtext>free</mtext></mrow></mtd></mtr></mtable></msub>
    <mover accent="true"><mi>c</mi> <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: then its dual is
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign max Underscript StartLayout 1st Row 1st Column Blank
    2nd Column ModifyingAbove p With right-arrow greater-than-or-equal-to ModifyingAbove
    0 With right-arrow 2nd Row 1st Column Blank 2nd Column upper A Superscript upper
    T Baseline ModifyingAbove p With right-arrow equals ModifyingAbove c With right-arrow
    EndLayout Endscripts ModifyingAbove p With right-arrow period ModifyingAbove b
    With right-arrow dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">max</mo>
    <mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mover accent="true"><mi>p</mi>
    <mo>→</mo></mover><mo>≥</mo><mover accent="true"><mn>0</mn> <mo>→</mo></mover></mrow></mtd></mtr><mtr><mtd
    columnalign="left"><mrow><msup><mi>A</mi> <mi>T</mi></msup> <mover accent="true"><mi>p</mi>
    <mo>→</mo></mover><mo>=</mo><mover accent="true"><mi>c</mi> <mo>→</mo></mover></mrow></mtd></mtr></mtable></msub>
    <mover accent="true"><mi>p</mi> <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>b</mi>
    <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: How to solve the dual problem? The simplex method solves the dual problem however
    now you move to basic feasible solutions that *increase* the cost rather than
    *decrease* the cost.
  prefs: []
  type: TYPE_NORMAL
- en: Derivation for the dual of a linear optimization problem in standard form
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There is another way to think about deriving the dual problem, but for this
    one the linear problem has to be in its standard form. Here’s the idea of it:
    We relax the constraint <math alttext="upper A ModifyingAbove x With right-arrow
    equals ModifyingAbove b With right-arrow"><mrow><mi>A</mi> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>=</mo> <mover accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></math>
    but introduce Lagrange multipliers <math alttext="ModifyingAbove p With right-arrow"><mover
    accent="true"><mi>p</mi> <mo>→</mo></mover></math> (pay a penalty <math alttext="ModifyingAbove
    p With right-arrow"><mover accent="true"><mi>p</mi> <mo>→</mo></mover></math>
    when the constraint is violated). So'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column upper A ModifyingAbove x With right-arrow equals ModifyingAbove b With
    right-arrow 2nd Row 1st Column Blank 2nd Column ModifyingAbove x With right-arrow
    greater-than-or-equal-to ModifyingAbove 0 With right-arrow EndLayout Endscripts
    ModifyingAbove c With right-arrow period ModifyingAbove x With right-arrow dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd
    columnalign="left"><mrow><mi>A</mi><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>=</mo><mover
    accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>≥</mo><mover accent="true"><mn>0</mn>
    <mo>→</mo></mover></mrow></mtd></mtr></mtable></msub> <mover accent="true"><mi>c</mi>
    <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: becomes
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript ModifyingAbove x With right-arrow
    greater-than-or-equal-to ModifyingAbove 0 With right-arrow Endscripts ModifyingAbove
    c With right-arrow period ModifyingAbove x With right-arrow plus ModifyingAbove
    p With right-arrow period left-parenthesis ModifyingAbove b With right-arrow minus
    upper A ModifyingAbove x With right-arrow right-parenthesis equals g left-parenthesis
    ModifyingAbove p With right-arrow right-parenthesis period dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mrow><mover accent="true"><mi>x</mi>
    <mo>→</mo></mover><mo>≥</mo><mover accent="true"><mn>0</mn> <mo>→</mo></mover></mrow></msub>
    <mover accent="true"><mi>c</mi> <mo>→</mo></mover> <mo>.</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>+</mo> <mover accent="true"><mi>p</mi> <mo>→</mo></mover>
    <mo>.</mo> <mrow><mo>(</mo> <mover accent="true"><mi>b</mi> <mo>→</mo></mover>
    <mo>-</mo> <mi>A</mi> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>=</mo> <mi>g</mi> <mrow><mo>(</mo> <mover accent="true"><mi>p</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Now prove that <math alttext="g left-parenthesis ModifyingAbove p With right-arrow
    right-parenthesis"><mrow><mi>g</mi> <mo>(</mo> <mover accent="true"><mi>p</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></math> is a lower bound for the original
    <math alttext="ModifyingAbove c With right-arrow period ModifyingAbove x With
    right-arrow Superscript asterisk"><mrow><mover accent="true"><mi>c</mi> <mo>→</mo></mover>
    <mo>.</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup></mrow></math>
    (this is the weak duality theorem) then maximize over *p*. The dual problem appears
    in the process (my lecture notes on duality for full derivation).
  prefs: []
  type: TYPE_NORMAL
- en: The *strong duality theorem* says that the <math alttext="min"><mo form="prefix"
    movablelimits="true">min</mo></math> of the primal problem and the <math alttext="max"><mo
    form="prefix" movablelimits="true">max</mo></math> of the dual problem are equal.
    Note that if the primal problem is unbounded then the dual problem is infeasible
    and if the dual problem is unbounded then the primal problem is infeasible.
  prefs: []
  type: TYPE_NORMAL
- en: '[Farkas lemma](https://en.wikipedia.org/wiki/Farkas%27_lemma) is at the core
    of duality theory and has many economical and financial applications.'
  prefs: []
  type: TYPE_NORMAL
- en: Dual Simplex Method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The dual simplex method solves the primal problem (not the dual problem) using
    duality theory. The main difference between the simplex method and the dual simplex
    method is this: the regular simplex method starts with a basic feasible solution
    which is not optimal and it moves towards optimality, while the dual simplex method
    starts with an infeasible solution which is optimal and works towards feasibility.
    The dual simplex method is like a mirror image of the simplex method.'
  prefs: []
  type: TYPE_NORMAL
- en: First, note that when we solve the primal problem using the simplex method,
    we obtain the optimal cost for the dual problem for free (equal to the primal
    optimal cost), but also, *we can read off the solution (optimizer) to the dual
    problem from the final tableaux for the primal problem*. An optimal dual variable
    is nonzero only if its associated constraint in the primal is binding. This should
    be intuitively clear, since the optimal dual variables are the shadow prices (Lagrange
    multipliers) associated with the constraints. We can interpret these shadow prices
    as values assigned to the scarce resources (binding constraints), so that the
    value of these resources equals the value of the primal objective function. The
    optimal dual variables satisfy the optimality conditions of the simplex method.
    In the final tableau of the simplex method, the reduced costs of the basic variables
    must be zero. The optimal dual variables must be the shadow prices associated
    with an optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: Another way is to think of the dual simplex method as a disguised simplex method
    solving the dual problem. However we do so without explicitly writing the dual
    problem and applying the simplex method to maximize.
  prefs: []
  type: TYPE_NORMAL
- en: Morever, the simplex method produces a sequence of primal basic feasible solutions
    (corners of the polyhedron), as soon as it finds one which is also dual feasible,
    the method terminates. On the other hand, the dual simplex method produces a sequence
    of dual basic feasible solutions, as soon as it finds one which is also primal
    feasible, the method terminates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Networks, linear optimization and duality'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Consider the network in [Figure 10-9](#Fig_max_flow). The numbers indicate
    the edge capacity, which is the maximum amount of flow that each edge can handle.
    The *max flow* problem is to send the maximum flow from the origin node to the
    destination node. Intuitively, the maximum flow through the network will be limited
    by the capacities that the edges can transmit. In fact, this observation underlies
    a dual problem that takes place: Maximizing the flow through the network is equivalent
    to minimizing the total capacities of the edges that if we cut then we cannot
    get from the origin to the destination. This is *max flow min cut theorem*.'
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_1009.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10-9\. Duality: Maximum flow through the network is equal to the smallest
    cut capacity.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 10-9](#Fig_max_flow) shows the values of all the cuts (the set of edges
    that if we cut together we will not be able to get from the origin to the destination)
    through the network, along with the cut of minimal total edge capacity, which
    is 16\. By the *max flow min cut* theorem, the max flow that we can send through
    the network would be 16: Send <math alttext="y 1 equals 12"><mrow><msub><mi>y</mi>
    <mn>1</mn></msub> <mo>=</mo> <mn>12</mn></mrow></math> units through the edge
    with capacity 19, and <math alttext="y 2 equals 4"><mrow><msub><mi>y</mi> <mn>2</mn></msub>
    <mo>=</mo> <mn>4</mn></mrow></math> units through the edge with capacity 4\. Of
    those, <math alttext="y 3 equals 1"><mrow><msub><mi>y</mi> <mn>3</mn></msub> <mo>=</mo>
    <mn>1</mn></mrow></math> unit will flow through the edge with capacity 1, <math
    alttext="y 4 equals 11"><mrow><msub><mi>y</mi> <mn>4</mn></msub> <mo>=</mo> <mn>11</mn></mrow></math>
    units will flow through the edge with capacity 11, and <math alttext="y 5 equals
    1 plus 4 equals 5"><mrow><msub><mi>y</mi> <mn>5</mn></msub> <mo>=</mo> <mn>1</mn>
    <mo>+</mo> <mn>4</mn> <mo>=</mo> <mn>5</mn></mrow></math> units will flow through
    the bottom edge with capacity 6\. All 12 units will make their way to the destination
    through the last two edges connected to it, with <math alttext="y 6 equals 0"><mrow><msub><mi>y</mi>
    <mn>6</mn></msub> <mo>=</mo> <mn>0</mn></mrow></math> (no units need to flow through
    the vertical edge with capacity 7), <math alttext="y 7 equals 11"><mrow><msub><mi>y</mi>
    <mn>7</mn></msub> <mo>=</mo> <mn>11</mn></mrow></math> units flow through the
    right most edge with capacity 12, and <math alttext="y 8 equals 5"><mrow><msub><mi>y</mi>
    <mn>8</mn></msub> <mo>=</mo> <mn>5</mn></mrow></math> units flow through right
    most edge with capacity 6\. The solution to the max flow problem is now <math
    alttext="left-parenthesis y 1 comma y 2 comma y 3 comma y 4 comma y 5 comma y
    6 comma y 7 comma y 8 right-parenthesis equals left-parenthesis 12 comma 4 comma
    1 comma 11 comma 5 comma 0 comma 11 comma 5 right-parenthesis"><mrow><mrow><mo>(</mo>
    <msub><mi>y</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>y</mi> <mn>2</mn></msub>
    <mo>,</mo> <msub><mi>y</mi> <mn>3</mn></msub> <mo>,</mo> <msub><mi>y</mi> <mn>4</mn></msub>
    <mo>,</mo> <msub><mi>y</mi> <mn>5</mn></msub> <mo>,</mo> <msub><mi>y</mi> <mn>6</mn></msub>
    <mo>,</mo> <msub><mi>y</mi> <mn>7</mn></msub> <mo>,</mo> <msub><mi>y</mi> <mn>8</mn></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mrow><mo>(</mo> <mn>12</mn> <mo>,</mo> <mn>4</mn>
    <mo>,</mo> <mn>1</mn> <mo>,</mo> <mn>11</mn> <mo>,</mo> <mn>5</mn> <mo>,</mo>
    <mn>0</mn> <mo>,</mo> <mn>11</mn> <mo>,</mo> <mn>5</mn> <mo>)</mo></mrow></mrow></math>
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to formulate this network problem as a linear optimization problem
    (which we just solved graphically using our knowledge of the value of the minimal
    cut, which is the solution of the dual problem), we need to add one more fictional
    edge with flow value <math alttext="y 9"><msub><mi>y</mi> <mn>9</mn></msub></math>
    that connects the destination to the origin, and assume that the flow that gets
    to the destination fictionally finds its way back to the origin. In other words,
    we *close the circuit*, and apply *Kirchhoff’s current law* which says *the sum
    of currents in a network of conductors meeting at a point is zero*, or the flow
    into a node is equal to the flow out of it. The linear maximization problem now
    becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign max Underscript StartLayout 1st Row 1st Column Blank
    2nd Column upper A ModifyingAbove y With right-arrow equals ModifyingAbove 0 With
    right-arrow 2nd Row 1st Column Blank 2nd Column StartAbsoluteValue y Subscript
    i Baseline EndAbsoluteValue less-than-or-equal-to upper M Subscript i Baseline
    EndLayout Endscripts y 9 dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">max</mo>
    <mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mi>A</mi><mover
    accent="true"><mi>y</mi> <mo>→</mo></mover><mo>=</mo><mover accent="true"><mn>0</mn>
    <mo>→</mo></mover></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mrow><mo>|</mo></mrow><msub><mi>y</mi>
    <mi>i</mi></msub> <mrow><mo>|</mo><mo>≤</mo></mrow><msub><mi>M</mi> <mi>i</mi></msub></mrow></mtd></mtr></mtable></msub>
    <msub><mi>y</mi> <mn>9</mn></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where *A* ([Figure 10-10](#Fig_incidence_matrix)) is the incidence matrix of
    our network, <math alttext="ModifyingAbove y With right-arrow equals left-parenthesis
    y 1 comma y 2 comma y 3 comma y 4 comma y 5 comma y 6 comma y 7 comma y 8 comma
    y 9 right-parenthesis Superscript t"><mrow><mover accent="true"><mi>y</mi> <mo>→</mo></mover>
    <mo>=</mo> <msup><mrow><mo>(</mo><msub><mi>y</mi> <mn>1</mn></msub> <mo>,</mo><msub><mi>y</mi>
    <mn>2</mn></msub> <mo>,</mo><msub><mi>y</mi> <mn>3</mn></msub> <mo>,</mo><msub><mi>y</mi>
    <mn>4</mn></msub> <mo>,</mo><msub><mi>y</mi> <mn>5</mn></msub> <mo>,</mo><msub><mi>y</mi>
    <mn>6</mn></msub> <mo>,</mo><msub><mi>y</mi> <mn>7</mn></msub> <mo>,</mo><msub><mi>y</mi>
    <mn>8</mn></msub> <mo>,</mo><msub><mi>y</mi> <mn>9</mn></msub> <mo>)</mo></mrow>
    <mi>t</mi></msup></mrow></math> is the vector of *signed* maximum flow (we allow
    the *y* values to be negative so that the flow in would cancel the flow out) that
    we can send through each edge and that we need to solve for (we just found its
    solution without the signs by inspection using the minimal cut intuition), <math
    alttext="upper M Subscript i"><msub><mi>M</mi> <mi>i</mi></msub></math> is the
    max capacity of each edge in the network, and the condition <math alttext="upper
    A ModifyingAbove y With right-arrow equals ModifyingAbove 0 With right-arrow"><mrow><mi>A</mi>
    <mover accent="true"><mi>y</mi> <mo>→</mo></mover> <mo>=</mo> <mover accent="true"><mn>0</mn>
    <mo>→</mo></mover></mrow></math> guarantees that the flow into a node is equal
    to the flow out of a node. Of course in this case the network will have directed
    edges showing in which direction the optimal flow will go through each edge.
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_1010.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-10\. Incidence matrix of the network in [Figure 10-9](#Fig_max_flow).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now that we have a linear formulation of the max flow problem, we can write
    its dual easily using the methods we learned in this chapter (the minimum cut
    problem), and solve either the primal or the dual. Note that all we need for this
    formulation is the incidence matrix of the network, the edge capacities, and the
    Kirchoff’s condition that the flow into a node is equal to the flow out of the
    node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: Two person zero sum games, linear optimization and duality'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another relevant setting where duality and linear optimization are built in
    is the two person zero sum game from game theory. A gain to one player is a loss
    to the other (hint: duality). To articulate the problem mathematically, we need
    the *payoff matrix* for all the options in the game for each of <math alttext="p
    l a y e r 1"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi>
    <mn>1</mn></msub></mrow></math> and <math alttext="p l a y e r 2"><mrow><mi>p</mi>
    <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>2</mn></msub></mrow></math>
    . Each player wants to devise a strategy that maximizes their pay given their
    options (no one said that the payoff matrices for the games have to be fair).
    We need to solve for the optimal strategy for each player. If we set up the optimization
    problem for <math alttext="p l a y e r 1"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi>
    <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math> , we do
    not to start from scratch to get the optimization problem for the strategy of
    <math alttext="p l a y e r 2"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi> <mi>y</mi>
    <mi>e</mi> <msub><mi>r</mi> <mn>2</mn></msub></mrow></math> : We just write its
    dual. The sum expected payoff of the game will be the same for both players, assuming
    that both of them act rationally and follow their optimal strategies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider for example the payoff matrix in [Figure 10-11](#Fig_payoff_matrix).
    The game goes like this: <math alttext="p l a y e r 1"><mrow><mi>p</mi> <mi>l</mi>
    <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math>
    chooses a row and <math alttext="p l a y e r 2"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi>
    <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>2</mn></msub></mrow></math> chooses
    a column at the same time. <math alttext="p l a y e r 1"><mrow><mi>p</mi> <mi>l</mi>
    <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math>
    pays the number in the chosen row and column to <math alttext="p l a y e r 2"><mrow><mi>p</mi>
    <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>2</mn></msub></mrow></math>
    . Therefore, <math alttext="p l a y e r 1"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi>
    <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math> wants to
    minimize and <math alttext="p l a y e r 2"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi>
    <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>2</mn></msub></mrow></math> wants to
    maximize. The players repeat the game many times.'
  prefs: []
  type: TYPE_NORMAL
- en: What is the optimal strategy for each of <math alttext="p l a y e r 1"><mrow><mi>p</mi>
    <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math>
    and <math alttext="p l a y e r 2"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi> <mi>y</mi>
    <mi>e</mi> <msub><mi>r</mi> <mn>2</mn></msub></mrow></math> and what is the expected
    payoff of the game?
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_1011.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-11\. Payoff matrix.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To find the optimal strategy, Suppose <math alttext="p l a y e r 1"><mrow><mi>p</mi>
    <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math>
    chooses <math alttext="r o w 1"><mrow><mi>r</mi> <mi>o</mi> <msub><mi>w</mi> <mn>1</mn></msub></mrow></math>
    with probability <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    and <math alttext="r o w 2"><mrow><mi>r</mi> <mi>o</mi> <msub><mi>w</mi> <mn>2</mn></msub></mrow></math>
    with probability <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    . Then <math alttext="x 1 plus x 2 equals 1"><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>=</mo> <mn>1</mn></mrow></math>
    , <math alttext="0 less-than-or-equal-to x 1 less-than-or-equal-to 1"><mrow><mn>0</mn>
    <mo>≤</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>≤</mo> <mn>1</mn></mrow></math>
    , and <math alttext="0 less-than-or-equal-to x 2 less-than-or-equal-to 1"><mrow><mn>0</mn>
    <mo>≤</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>≤</mo> <mn>1</mn></mrow></math>
    . <math alttext="p l a y e r 1"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi> <mi>y</mi>
    <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math> rationalizes that
    if he uses an <math alttext="left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></math> mixed strategy, there would be another row in the payoff
    matrix corresponding to this new strategy (see [Figure 10-11](#Fig_payoff_matrix)).
    Now <math alttext="p l a y e r 1"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi> <mi>y</mi>
    <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math> knows that <math alttext="p
    l a y e r 2"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi>
    <mn>2</mn></msub></mrow></math> wants to choose the column that maximizes their
    payoff, so <math alttext="p l a y e r 1"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi>
    <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math> must choose
    <math alttext="left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></math> that make the worst payoff (maximum of the third row)
    as small as possible. Therefore, <math alttext="p l a y e r 1"><mrow><mi>p</mi>
    <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math>
    must solve the *min max* problem
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column 0 less-than-or-equal-to x 1 less-than-or-equal-to 1 2nd Row 1st Column
    Blank 2nd Column 0 less-than-or-equal-to x 2 less-than-or-equal-to 1 3rd Row 1st
    Column Blank 2nd Column x 1 plus x 2 equals 1 EndLayout Endscripts max x 1 plus
    3 x 2 comma minus x 2 comma 4 x 1 plus 2 x 2 dollar-sign"><mrow><msub><mo form="prefix"
    movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd columnalign="left"><mrow><mn>0</mn><mo>≤</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>≤</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mn>0</mn><mo>≤</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>≤</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo><msub><mi>x</mi> <mn>2</mn></msub> <mo>=</mo><mn>1</mn></mrow></mtd></mtr></mtable></msub>
    <mo form="prefix" movablelimits="true">max</mo> <mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <mn>3</mn> <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mo>-</mo>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>,</mo> <mn>4</mn> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <mn>2</mn> <msub><mi>x</mi> <mn>2</mn></msub></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that the maximum of linear functions is a convex piecewise linear function.
    We can easily change such a *min max(linear functions)* problem to a linear minimization
    problem:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript StartLayout 1st Row 1st Column Blank
    2nd Column z greater-than-or-equal-to x 1 plus 3 x 2 2nd Row 1st Column Blank
    2nd Column z greater-than-or-equal-to minus x 2 3rd Row 1st Column Blank 2nd Column
    z greater-than-or-equal-to 4 x 1 plus 2 x 2 4th Row 1st Column Blank 2nd Column
    0 less-than-or-equal-to x 1 less-than-or-equal-to 1 5th Row 1st Column Blank 2nd
    Column 0 less-than-or-equal-to x 2 less-than-or-equal-to 1 6th Row 1st Column
    Blank 2nd Column x 1 plus x 2 equals 1 EndLayout Endscripts z dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mtable displaystyle="true"><mtr><mtd
    columnalign="left"><mrow><mi>z</mi><mo>≥</mo><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo><mn>3</mn><msub><mi>x</mi> <mn>2</mn></msub></mrow></mtd></mtr> <mtr><mtd
    columnalign="left"><mrow><mi>z</mi><mo>≥</mo><mo>-</mo><msub><mi>x</mi> <mn>2</mn></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mrow><mi>z</mi><mo>≥</mo><mn>4</mn><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo><mn>2</mn><msub><mi>x</mi> <mn>2</mn></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mrow><mn>0</mn><mo>≤</mo><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>≤</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mn>0</mn><mo>≤</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>≤</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo><msub><mi>x</mi> <mn>2</mn></msub> <mo>=</mo><mn>1</mn></mrow></mtd></mtr></mtable></msub>
    <mi>z</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 10-12](#Fig_write_dual) shows the formulation of the dual of the above
    problem, which [Figure 10-13](#Fig_same_problem) shows that this is exactly the
    problem that <math alttext="p l a y e r 2"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi>
    <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>2</mn></msub></mrow></math> is trying
    to solve.'
  prefs: []
  type: TYPE_NORMAL
- en: '![250](assets/emai_1012.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-12\. The dual of <math alttext="p l a y e r 1"><mrow><mi>p</mi> <mi>l</mi>
    <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math>
    ’s problem.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![250](assets/emai_1013.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-13\. The dual of <math alttext="p l a y e r 1"><mrow><mi>p</mi> <mi>l</mi>
    <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math>
    ’s *min max* problem is the same as <math alttext="p l a y e r 2"><mrow><mi>p</mi>
    <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>2</mn></msub></mrow></math>
    ’s *max min* problem.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note that the constraints <math alttext="y 1 less-than-or-equal-to 1"><mrow><msub><mi>y</mi>
    <mn>1</mn></msub> <mo>≤</mo> <mn>1</mn></mrow></math> , <math alttext="y 2 less-than-or-equal-to
    1"><mrow><msub><mi>y</mi> <mn>2</mn></msub> <mo>≤</mo> <mn>1</mn></mrow></math>
    , and <math alttext="y 3 less-than-or-equal-to 1"><mrow><msub><mi>y</mi> <mn>3</mn></msub>
    <mo>≤</mo> <mn>1</mn></mrow></math> are redundant since we have that all the y’s
    are nonnegative and they add up to 1\. Similarly with the constraints <math alttext="x
    1 less-than-or-equal-to 1"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>≤</mo>
    <mn>1</mn></mrow></math> and <math alttext="x 2 less-than-or-equal-to 1"><mrow><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>≤</mo> <mn>1</mn></mrow></math> . This happens a lot when
    formulating linear optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Solving either the primal or the dual problem, we find each player’s optimal
    strategy: <math alttext="p l a y e r 1"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi>
    <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math> must go
    with the first row <math alttext="x 1 equals 0.25"><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>25</mn></mrow></math> of the time and with
    the second row <math alttext="x 2 equals 0.75"><mrow><msub><mi>x</mi> <mn>2</mn></msub>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>75</mn></mrow></math> of the time, for an
    expected payoff of 2.5, which means <math alttext="p l a y e r 1"><mrow><mi>p</mi>
    <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>1</mn></msub></mrow></math>
    expects to lose no more than 2.5 with this strategy. <math alttext="p l a y e
    r 2"><mrow><mi>p</mi> <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi>
    <mn>2</mn></msub></mrow></math> must go with the first column <math alttext="y
    1 equals 0.5"><mrow><msub><mi>y</mi> <mn>1</mn></msub> <mo>=</mo> <mn>0</mn> <mo>.</mo>
    <mn>5</mn></mrow></math> of the time and with the third column <math alttext="y
    3 equals 0.5"><mrow><msub><mi>y</mi> <mn>3</mn></msub> <mo>=</mo> <mn>0</mn> <mo>.</mo>
    <mn>5</mn></mrow></math> of the time (never with the second column <math alttext="y
    2 equals 0"><mrow><msub><mi>y</mi> <mn>2</mn></msub> <mo>=</mo> <mn>0</mn></mrow></math>
    ), for an expected payoff of 2.5, which means <math alttext="p l a y e r 2"><mrow><mi>p</mi>
    <mi>l</mi> <mi>a</mi> <mi>y</mi> <mi>e</mi> <msub><mi>r</mi> <mn>2</mn></msub></mrow></math>
    expects to gain no less than 2.5 with this strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: Quadratic optimization with linear constraints, Lagrangian, min max theorem,
    and duality
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A *nonlinear* optimization problem that has a nice structure, appears in all
    kinds of applications, and has a lot to teach us on how things tie together, is
    a quadratic problem with linear constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript upper A ModifyingAbove x With right-arrow
    equals ModifyingAbove b With right-arrow Endscripts one-half ModifyingAbove x
    With right-arrow Superscript t Baseline upper S ModifyingAbove x With right-arrow
    dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo> <mrow><mi>A</mi><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover><mo>=</mo><mover accent="true"><mi>b</mi>
    <mo>→</mo></mover></mrow></msub> <mfrac><mn>1</mn> <mn>2</mn></mfrac> <msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mi>t</mi></msup> <mi>S</mi> <mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Here, *S* is a symmetric and positive semidefinite matrix, which means that
    its eigenvalues are nonnegative. For high dimensions, this plays the role of keeping
    the objective function convex and bounded below, or shaped like the bowl of the
    one dimensional function <math alttext="f left-parenthesis x right-parenthesis
    equals x squared"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msup><mi>x</mi> <mn>2</mn></msup></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, this is a two dimensional quadratic optimization problem with
    one linear constraint:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript a 1 x 1 plus a 2 x 2 equals b Endscripts
    one-half left-parenthesis s 1 x 1 squared plus s 2 x 2 squared right-parenthesis
    dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo> <mrow><msub><mi>a</mi>
    <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo><msub><mi>a</mi>
    <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub> <mo>=</mo><mi>b</mi></mrow></msub>
    <mfrac><mn>1</mn> <mn>2</mn></mfrac> <mrow><mo>(</mo> <msub><mi>s</mi> <mn>1</mn></msub>
    <msubsup><mi>x</mi> <mn>1</mn> <mn>2</mn></msubsup> <mo>+</mo> <msub><mi>s</mi>
    <mn>2</mn></msub> <msubsup><mi>x</mi> <mn>2</mn> <mn>2</mn></msubsup> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, <math alttext="upper S equals Start 2 By 2 Matrix 1st Row 1st Column
    s 1 2nd Column 0 2nd Row 1st Column 0 2nd Column s 2 EndMatrix"><mrow><mi>S</mi>
    <mo>=</mo> <mfenced close=")" open="("><mtable><mtr><mtd><msub><mi>s</mi> <mn>1</mn></msub></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><msub><mi>s</mi> <mn>2</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
    where the *s* entries are nonnegative, and <math alttext="upper A equals Start
    1 By 2 Matrix 1st Row 1st Column a 1 2nd Column a 2 EndMatrix"><mrow><mi>A</mi>
    <mo>=</mo> <mfenced close=")" open="("><mtable><mtr><mtd><msub><mi>a</mi> <mn>1</mn></msub></mtd>
    <mtd><msub><mi>a</mi> <mn>2</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
    . Inspecting this problem, we are searching for the point <math alttext="left-parenthesis
    x 1 comma x 2 right-parenthesis"><mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math> on the
    straight line <math alttext="a 1 x 1 plus a 2 x 2 equals b"><mrow><msub><mi>a</mi>
    <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>a</mi>
    <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub> <mo>=</mo> <mi>b</mi></mrow></math>
    that minimizes the quantity <math alttext="f left-parenthesis ModifyingAbove x
    With right-arrow right-parenthesis equals s 1 x 1 squared plus s 2 x 2 squared"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mi>s</mi> <mn>1</mn></msub> <msubsup><mi>x</mi> <mn>1</mn> <mn>2</mn></msubsup>
    <mo>+</mo> <msub><mi>s</mi> <mn>2</mn></msub> <msubsup><mi>x</mi> <mn>2</mn> <mn>2</mn></msubsup></mrow></math>
    . The level sets of the objective function <math alttext="s 1 x 1 squared plus
    s 2 x 2 squared equals k"><mrow><msub><mi>s</mi> <mn>1</mn></msub> <msubsup><mi>x</mi>
    <mn>1</mn> <mn>2</mn></msubsup> <mo>+</mo> <msub><mi>s</mi> <mn>2</mn></msub>
    <msubsup><mi>x</mi> <mn>2</mn> <mn>2</mn></msubsup> <mo>=</mo> <mi>k</mi></mrow></math>
    are concentric ellipses that cover the whole <math alttext="double-struck upper
    R squared"><msup><mi>ℝ</mi> <mn>2</mn></msup></math> plane. The winning ellipse
    (the one with smallest level set value) is the one that is tangent to straight
    line at the winning point ([Figure 10-14](#Fig_quadratic_optimization)). At this
    point, the gradient vector of the ellipse and the gradient vector of the constraint
    align, which is exactly what Lagrange multiplier formulation gives us: To formulate
    the Lagrangian, relax the constraint, but pay a penalty equal to the lagrange
    multiplier *p* times how much we relaxed it in the objective function, minimizing
    the uncontrained problem'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign script upper L left-parenthesis ModifyingAbove x
    With right-arrow semicolon p right-parenthesis equals f left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis plus p left-parenthesis b minus g left-parenthesis
    ModifyingAbove x With right-arrow right-parenthesis right-parenthesis equals s
    1 x 1 squared plus s 2 x 2 squared plus p left-parenthesis b minus a 1 x 1 minus
    a 2 x 2 right-parenthesis dollar-sign"><mrow><mi>ℒ</mi> <mrow><mo>(</mo> <mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>;</mo> <mi>p</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>+</mo> <mi>p</mi> <mrow><mo>(</mo> <mi>b</mi> <mo>-</mo>
    <mi>g</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <msub><mi>s</mi> <mn>1</mn></msub>
    <msubsup><mi>x</mi> <mn>1</mn> <mn>2</mn></msubsup> <mo>+</mo> <msub><mi>s</mi>
    <mn>2</mn></msub> <msubsup><mi>x</mi> <mn>2</mn> <mn>2</mn></msubsup> <mo>+</mo>
    <mi>p</mi> <mrow><mo>(</mo> <mi>b</mi> <mo>-</mo> <msub><mi>a</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo> <msub><mi>a</mi> <mn>2</mn></msub>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: When we minimize the Lagrangian, we set its gradient equal to zero, and that
    leads to <math alttext="normal nabla f left-parenthesis ModifyingAbove x With
    right-arrow right-parenthesis equals p normal nabla g left-parenthesis ModifyingAbove
    x With right-arrow right-parenthesis"><mrow><mi>∇</mi> <mi>f</mi> <mrow><mo>(</mo>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>)</mo></mrow> <mo>=</mo>
    <mi>p</mi> <mi>∇</mi> <mi>g</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow></mrow></math> . This says that the gradient
    vector of the objective function is parallel to the gradient vector of the constraint
    at the optimizing point(s). Since the gradient vector of any function is perpendicular
    to its level sets, this means that the constraint is in fact tangent to the level
    set of the objective function at the minimizing point(s). Therefore, to find the
    optimizing point(s), we look for the level sets of the objective function where
    it happens to be tangent to the constraint.
  prefs: []
  type: TYPE_NORMAL
- en: '![150](assets/emai_1014.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-14\. The level sets of the quadratic function <math alttext="x 1 squared
    plus 4 x squared"><mrow><msubsup><mi>x</mi> <mn>1</mn> <mn>2</mn></msubsup> <mo>+</mo>
    <mn>4</mn> <msup><mi>x</mi> <mn>2</mn></msup></mrow></math> are concentric ellipses,
    each of them has a constant value. When we impose the linear constraint <math
    alttext="x 1 plus x 2 equals 2.5"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo>
    <msub><mi>x</mi> <mn>2</mn></msub> <mo>=</mo> <mn>2</mn> <mo>.</mo> <mn>5</mn></mrow></math>
    , we get the optimizer (2,0.5) at exactly the point where one of the level sets
    is tangent to the constraint. The value of the optimal level set is <math alttext="x
    1 squared plus 4 x squared equals 5"><mrow><msubsup><mi>x</mi> <mn>1</mn> <mn>2</mn></msubsup>
    <mo>+</mo> <mn>4</mn> <msup><mi>x</mi> <mn>2</mn></msup> <mo>=</mo> <mn>5</mn></mrow></math>
    .
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Another example that helps us visualize Lagrangian and the upcoming *min max
    theorem* is a trivial one dimensional example:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript x equals 1 Endscripts x squared dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mrow><mi>x</mi><mo>=</mo><mn>1</mn></mrow></msub>
    <msup><mi>x</mi> <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The Lagrangian is <math alttext="script upper L left-parenthesis x semicolon
    p right-parenthesis equals x squared minus p left-parenthesis 1 minus x right-parenthesis"><mrow><mi>ℒ</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>;</mo> <mi>p</mi> <mo>)</mo></mrow> <mo>=</mo>
    <msup><mi>x</mi> <mn>2</mn></msup> <mo>-</mo> <mi>p</mi> <mrow><mo>(</mo> <mn>1</mn>
    <mo>-</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math> . We use this toy example
    whose optimizer is obviously <math alttext="x equals 1"><mrow><mi>x</mi> <mo>=</mo>
    <mn>1</mn></mrow></math> with minimal value 1 so that we can visualize the Lagrangian.
    Recall that the Lagrange formulation makes the dimension jump up, in this case
    we have one constraint so the dimension increases from one to two, and in our
    limited three dimensional world we can only visualize functions of two variables
    (*x* and *p*). [Figure 10-15](#Fig_saddle_lagrange) shows the landscape of our
    trivial Lagrangian function which is now representative for Lagrangian formulations
    for quadratic optimization problems with linear constraints. The main thing to
    pay attention to in [Figure 10-15](#Fig_saddle_lagrange) is that the optimizers
    of these kinds of problems <math alttext="left-parenthesis x Superscript asterisk
    Baseline semicolon p Superscript asterisk Baseline right-parenthesis"><mrow><mo>(</mo>
    <msup><mi>x</mi> <mo>*</mo></msup> <mo>;</mo> <msup><mi>p</mi> <mo>*</mo></msup>
    <mo>)</mo></mrow></math> happen at *saddle points* of the Lagrangian: These are
    points where the *second derivative* is positive in one variable and negative
    in another, so the landscape of the Lagrangian function is convex in one variable
    (*x*) and concave in the other (*p*).'
  prefs: []
  type: TYPE_NORMAL
- en: '![150](assets/emai_1015.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-15\. The optimizer of the constrained problem happens at the saddle
    point of the Lagrangian (note that the minimum of the Lagrangian itself is <math
    alttext="negative normal infinity"><mrow><mo>-</mo> <mi>∞</mi></mrow></math> ,
    but that is not what we care for, because we care about the optimizer of the quadratic
    function with linear constraints).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: One way to locate the saddle points of the Lagrangian (which give us the optimizers
    of the corresponding constrained problems) is to solve <math alttext="normal nabla
    script upper L left-parenthesis x semicolon p right-parenthesis equals ModifyingAbove
    0 With right-arrow"><mrow><mi>∇</mi> <mi>ℒ</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>;</mo>
    <mi>p</mi> <mo>)</mo></mrow> <mo>=</mo> <mover accent="true"><mn>0</mn> <mo>→</mo></mover></mrow></math>
    for *x* and *p*, but that is the brute force way which works for simple problems
    (like the trivial one at hand) or for small size problems. Another way to find
    these saddle points is to minimize in *x* then maximize in *p* ([Figure 10-16](#Fig_maxmin)).
    Yet another way is to maximize in *p* then minimize in *x*. The *min max theorem*
    says that these two paths are the same.
  prefs: []
  type: TYPE_NORMAL
- en: '![150](assets/emai_1016.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-16\. Minimizing over x then maximizing over *p* gives <math alttext="max
    Underscript p Endscripts x Superscript asterisk Baseline left-parenthesis p right-parenthesis
    equals x Superscript asterisk Baseline left-parenthesis p Superscript asterisk
    Baseline right-parenthesis"><mrow><msub><mo form="prefix" movablelimits="true">max</mo>
    <mi>p</mi></msub> <msup><mi>x</mi> <mo>*</mo></msup> <mrow><mo>(</mo> <mi>p</mi>
    <mo>)</mo></mrow> <mo>=</mo> <msup><mi>x</mi> <mo>*</mo></msup> <mrow><mo>(</mo>
    <msup><mi>p</mi> <mo>*</mo></msup> <mo>)</mo></mrow></mrow></math> =the saddle
    point. This will give the same answer as maximizng over *p* then minimizing over
    *x*.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Therefore, at the saddle point <math alttext="left-parenthesis x Superscript
    asterisk Baseline comma p Superscript asterisk Baseline right-parenthesis"><mrow><mo>(</mo>
    <msup><mi>x</mi> <mo>*</mo></msup> <mo>,</mo> <msup><mi>p</mi> <mo>*</mo></msup>
    <mo>)</mo></mrow></math> , we have <math alttext="normal nabla script upper L
    left-parenthesis x semicolon p right-parenthesis equals 0"><mrow><mi>∇</mi> <mi>ℒ</mi>
    <mo>(</mo> <mi>x</mi> <mo>;</mo> <mi>p</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn></mrow></math>
    (which is the same as <math alttext="StartFraction normal partial-differential
    script upper L left-parenthesis x semicolon p right-parenthesis Over normal partial-differential
    x EndFraction equals 0"><mrow><mfrac><mrow><mi>∂</mi><mi>ℒ</mi><mo>(</mo><mi>x</mi><mo>;</mo><mi>p</mi><mo>)</mo></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mo>=</mo> <mn>0</mn></mrow></math>
    and <math alttext="StartFraction normal partial-differential script upper L left-parenthesis
    x semicolon p right-parenthesis Over normal partial-differential p EndFraction
    equals 0"><mrow><mfrac><mrow><mi>∂</mi><mi>ℒ</mi><mo>(</mo><mi>x</mi><mo>;</mo><mi>p</mi><mo>)</mo></mrow>
    <mrow><mi>∂</mi><mi>p</mi></mrow></mfrac> <mo>=</mo> <mn>0</mn></mrow></math>
    ), *and*
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript x Endscripts max Underscript p comma
    hold x fixed Endscripts script upper L left-parenthesis x semicolon p right-parenthesis
    equals max Underscript p Endscripts min Underscript x comma hold p fixed Endscripts
    script upper L left-parenthesis x semicolon p right-parenthesis dollar-sign"><mrow><msub><mo
    form="prefix" movablelimits="true">min</mo> <mi>x</mi></msub> <msub><mo form="prefix"
    movablelimits="true">max</mo> <mrow><mi>p</mi><mo>,</mo><mtext>hold</mtext><mtext>x</mtext><mtext>fixed</mtext></mrow></msub>
    <mi>ℒ</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>;</mo> <mi>p</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mo form="prefix" movablelimits="true">max</mo> <mi>p</mi></msub>
    <msub><mo form="prefix" movablelimits="true">min</mo> <mrow><mi>x</mi><mo>,</mo><mtext>hold</mtext><mtext>p</mtext><mtext>fixed</mtext></mrow></msub>
    <mi>ℒ</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>;</mo> <mi>p</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: We have gone a full circle to yet again demonstrate that accompanying in a constrained
    minimization problem in *x* we have another constrained maximization problem in
    the Lagrange multipliers *p*. The interplay between Lagrange multipliers, duality,
    and constrained optimization is at full display.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we went through the important ideas, let’s go back and put them in
    the context of the higher dimensional quadratic problem with linear constraints
    that we started this subsection with:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min Underscript upper A ModifyingAbove x With right-arrow
    equals ModifyingAbove b With right-arrow Endscripts one-half ModifyingAbove x
    With right-arrow Superscript t Baseline upper S ModifyingAbove x With right-arrow
    comma dollar-sign"><mrow><msub><mo form="prefix" movablelimits="true">min</mo>
    <mrow><mi>A</mi><mover accent="true"><mi>x</mi> <mo>→</mo></mover><mo>=</mo><mover
    accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></msub> <mfrac><mn>1</mn> <mn>2</mn></mfrac>
    <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mi>t</mi></msup> <mi>S</mi>
    <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>,</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'where *S* is a symmetric and positive definite matrix. The Lagrange formulation
    with *relaxed* constraints is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign min script upper L left-parenthesis ModifyingAbove
    x With right-arrow semicolon ModifyingAbove p With right-arrow right-parenthesis
    equals min one-half ModifyingAbove x With right-arrow Superscript t Baseline upper
    S ModifyingAbove x With right-arrow plus ModifyingAbove p With right-arrow period
    left-parenthesis ModifyingAbove b With right-arrow minus upper A ModifyingAbove
    x With right-arrow right-parenthesis period dollar-sign"><mrow><mo form="prefix"
    movablelimits="true">min</mo> <mi>ℒ</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>;</mo> <mover accent="true"><mi>p</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <mo form="prefix" movablelimits="true">min</mo> <mfrac><mn>1</mn>
    <mn>2</mn></mfrac> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mi>t</mi></msup>
    <mi>S</mi> <mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>+</mo> <mover
    accent="true"><mi>p</mi> <mo>→</mo></mover> <mo>.</mo> <mrow><mo>(</mo> <mover
    accent="true"><mi>b</mi> <mo>→</mo></mover> <mo>-</mo> <mi>A</mi> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>)</mo></mrow> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Solving this unconstrained problem, whether by setting <math alttext="normal
    nabla script upper L left-parenthesis ModifyingAbove x With right-arrow semicolon
    ModifyingAbove p With right-arrow right-parenthesis equals ModifyingAbove 0 With
    right-arrow"><mrow><mi>∇</mi> <mi>ℒ</mi> <mrow><mo>(</mo> <mover accent="true"><mi>x</mi>
    <mo>→</mo></mover> <mo>;</mo> <mover accent="true"><mi>p</mi> <mo>→</mo></mover>
    <mo>)</mo></mrow> <mo>=</mo> <mover accent="true"><mn>0</mn> <mo>→</mo></mover></mrow></math>
    , or by minimizing over <math alttext="ModifyingAbove x With right-arrow"><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover></math> then maximizing over <math
    alttext="ModifyingAbove p With right-arrow"><mover accent="true"><mi>p</mi> <mo>→</mo></mover></math>
    , or by maximizing over <math alttext="ModifyingAbove p With right-arrow"><mover
    accent="true"><mi>p</mi> <mo>→</mo></mover></math> then minimizing over <math
    alttext="ModifyingAbove x With right-arrow"><mover accent="true"><mi>x</mi> <mo>→</mo></mover></math>
    , we get the same solution <math alttext="left-parenthesis ModifyingAbove x With
    right-arrow Superscript asterisk Baseline semicolon ModifyingAbove p Superscript
    asterisk Baseline With right-arrow right-parenthesis"><mrow><mo>(</mo> <msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mo>;</mo> <mover
    accent="true"><msup><mi>p</mi> <mo>*</mo></msup> <mo>→</mo></mover> <mo>)</mo></mrow></math>
    , which happens at the *saddle point* of our high dimensional Lagrangian, and
    gives the optimal value of the objective function (the advantage of this problem
    with simple structure is that we can solve it by hand):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign minimum cost f equals one-half ModifyingAbove b With
    right-arrow period left-parenthesis upper A upper S Superscript negative 1 Baseline
    upper A Superscript t Baseline right-parenthesis Superscript negative 1 Baseline
    ModifyingAbove b With right-arrow dollar-sign"><mrow><mtext>minimum</mtext> <mtext>cost</mtext>
    <mtext>f</mtext> <mo>=</mo> <mfrac><mn>1</mn> <mn>2</mn></mfrac> <mover accent="true"><mi>b</mi>
    <mo>→</mo></mover> <mo>.</mo> <msup><mrow><mo>(</mo><mi>A</mi><msup><mi>S</mi>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msup><mi>A</mi> <mi>t</mi></msup> <mo>)</mo></mrow>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mover accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, the optimal *shadow prices* are: <math alttext="ModifyingAbove p
    With right-arrow Superscript asterisk Baseline equals StartFraction d f Over d
    ModifyingAbove b With right-arrow EndFraction equals left-parenthesis upper A
    upper S Superscript negative 1 Baseline upper A Superscript t Baseline right-parenthesis
    Superscript negative 1 Baseline ModifyingAbove b With right-arrow"><mrow><msup><mover
    accent="true"><mi>p</mi> <mo>→</mo></mover> <mo>*</mo></msup> <mo>=</mo> <mfrac><mrow><mi>d</mi><mi>f</mi></mrow>
    <mrow><mi>d</mi><mover accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></mfrac>
    <mo>=</mo> <msup><mrow><mo>(</mo><mi>A</mi><msup><mi>S</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi>A</mi> <mi>t</mi></msup> <mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mover accent="true"><mi>b</mi> <mo>→</mo></mover></mrow></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: 'The last thing we need to learn here is the characterization of saddle points
    in higher dimensions. For the one dimensional constrained problem, the hallmark
    was having the second derivative of the Lagrangian (which was a function of *x*
    and *p*) negative in one variable and positive in the other. The high dimensional
    analogue is this: The eigenvalues of the Hessian matrix (matrix of second derivatives)
    is negative in one set of variables and positive in the other set of variables,
    so it is concave in one set of variable and convex in the other. Our discussion
    applies to optimizing any higher dimensional objective function that is convex
    in one set of variables and concave in the other. This is the hallmark that the
    landscape has saddle points. For the Lagrangian function, the saddle point is
    exactly where the constrained problem attains its minimum.'
  prefs: []
  type: TYPE_NORMAL
- en: Does this apply to linear optimization problems with linear constraints, which
    are everywhere in operations research? Yes, as long as we have the correct signs
    for all the coefficients in the problem, such as the max flow min cut and the
    two person zero sum game examples we saw in the previous subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Sensitivity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here we care for the sensitivity of the optimization problem and its solution
    with respect to changes in its input data. That is, what happens to the optimal
    solution <math alttext="ModifyingAbove x With right-arrow Superscript asterisk"><msup><mover
    accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup></math> and the optimal
    cost <math alttext="ModifyingAbove c With right-arrow period ModifyingAbove x
    With right-arrow Superscript asterisk"><mrow><mover accent="true"><mi>c</mi> <mo>→</mo></mover>
    <mo>.</mo> <msup><mover accent="true"><mi>x</mi> <mo>→</mo></mover> <mo>*</mo></msup></mrow></math>
    if we slightly change <math alttext="ModifyingAbove c With right-arrow"><mover
    accent="true"><mi>c</mi> <mo>→</mo></mover></math> , or *A*, or <math alttext="ModifyingAbove
    b With right-arrow"><mover accent="true"><mi>b</mi> <mo>→</mo></mover></math>
    ? Can we obtain the new optimal solution from the old one? Under what conditions
    can we do that? These are some important cases that sensitivity analysis addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have already interpreted the optimal <math alttext="ModifyingAbove p With
    right-arrow"><mover accent="true"><mi>p</mi> <mo>→</mo></mover></math> in the
    dual problem as the vector of marginal prices. This is related to sensitivity
    analysis: The rate of change of the optimal cost with respect to the constraint
    value.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we add a new decision variable, we check its reduced cost, and if it is negative,
    we add a new column to the tableau and proceed from there.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If an entry of <math alttext="ModifyingAbove b With right-arrow"><mover accent="true"><mi>b</mi>
    <mo>→</mo></mover></math> or <math alttext="ModifyingAbove c With right-arrow"><mover
    accent="true"><mi>c</mi> <mo>→</mo></mover></math> is changed by <math alttext="delta"><mi>δ</mi></math>
    , we obtain an interval of values of <math alttext="delta"><mi>δ</mi></math> for
    which the same basis remains optimal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If an entry of *A* is changed by <math alttext="delta"><mi>δ</mi></math> , a
    similar analysis is possible. However, this case is somewhat complicated if the
    change affects an entry of a basic column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In general, if we have a function and we want its sensitivity to variations
    with respect to one of its inputs, then that is similar to asking about its first
    derivative with respect to that input (at a certain state), or a discrete first
    derivative (finite difference) at that state. What makes sensitivity questions
    more interesting here is the fact that we are dealing with *constrained* problems
    and checking the effect of small variations in all kinds of inputs to the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Game Theory And Multiagents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Game theory is so important for economics, politics, military operations, multi-agent
    AI, and basically for modeling any environment where there are adversaries or
    competitors, and we have to make decisions or strategize in these conditions.
    Our optimal strategies are heavily influenced by our adversaries’ strategies,
    whether we know them or are only speculating about them.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest and most well understood game theoretic setting is that of *two
    person zero sum games*, which we saw when discussing duality. Here, there are
    two competing entities, where the loss of one entity is the win of the other,
    for example, two political campaigns or two competing firms. Extending the theory
    to more complex real life situations with many competitors with varying advantages
    and disadvantages over each other, varying degrees of cooperation, along with
    many interrelated strategies, has been a challenge. There is still a gap between
    the situations that the theory can accurately portray and analyze, and real life
    situations. Progress is happening and many researchers are on this case, due to
    the incredible benefits such a complete theory would bring to the world. Imagine
    being able to view the whole network of adversaries from above, with their movements,
    connections, possible strategies and their consequences.
  prefs: []
  type: TYPE_NORMAL
- en: For multiagent environments, game theory models the rational behavior or decision
    making process for each involved agent (player, firm, country, military, polictical
    campaign, etc.). In this sense game theory for multiagents is similar to decision
    theory for a single agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most important concept for non-cooperative game theory (where the agents
    make their decisions independently) is that of *Nash equilibrium*: A strategy
    outline for the game where each agent has no incentive to deviate from the outline’s
    prescribed strategy. That is, the agent will be worse off if they deviate from
    the strategy, of course, assuming everyone is acting rationally.'
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in the section on duality, for two person zero sum games, we can model
    them as a min max problem, and use *min max theorem*. We can also model them as
    a linear optimization problem, where one player is solving the primal problem,
    and the other one is solving the dual problem. This means that we can either set
    up the optimization problem for the first player, or for the second player. Both
    problems will end up with the same solution. Here we are given the payoff chart
    for all strageties in the game for both players, and the objective is to find
    the strategy combination that maximizes the pay (or minimize the loss) for each
    player. Intuitively, we can see why duality is built into this problem. The two
    players are pushing against each other and the optimal strategy for each player
    solves both the primal and the dual problems.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use graphs and results from graph theory to analyze two person games.
    This is similar to how we can formulate the max flow through a network as a linear
    optimization problem. Ultimately, many things in math connect neatly together,
    and one of the most satisfying feelings is when we understand these connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'For multiagents, there are certain techniques available for decision making,
    which include: Voting procedures, auctions for allocating scarce resources, bargaining
    for reaching agreements, and contract net protocol for task sharing. In terms
    of mathematical modeling for multiagent games, we will discuss in [Chapter 13](ch13.xhtml#ch13)
    (AI and Partial Differential Equations) the *Hamilton Jacobi Bellman* partial
    differential equation. Here, to find the optimal strategy for each player, we
    have to solve a high dimensional Hamilton Jacobi Bellman type partial differential
    equation for the game’s value function. Before deep learning, these types of high
    dimensional partial differential equations have been intractable, and one had
    to make many approximations, or not consider all the participating entities. Recently
    (2018), a [deep learning technique](https://www.pnas.org/doi/10.1073/pnas.1718942115)
    has been applied to solve these high dimensional partial differential equations,
    once reformulated as a backward stochastic differential equation with terminal
    conditions (don’t worry if you do not know what this means. It is not important
    for this chapter).'
  prefs: []
  type: TYPE_NORMAL
- en: We encountered another two person adversarial game theoric setting earlier in
    this book, when discussing generative adversarial networks in [Chapter 8](ch08.xhtml#ch08),
    on probabilistic generative models.
  prefs: []
  type: TYPE_NORMAL
- en: Queuing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Queues are everywhere: Computing jobs for machines, service queues at a shipyard,
    queues at the emergency room, airport check in queues, and queues at the local
    Starbucks shop. Well designed queue systems would save different facilities and
    our entire economy an invaluable amount of time, energy, and money. They will
    enhance our overall well-being.'
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical modeling of queues has the objective of determining the appropriate
    level of service in order to minimize waiting times. The model might include a
    priority discipline, which means that there are priority groups and the order
    in which the members get serviced depends on their priority groups. It might also
    include different type of services that happen sequentially or in parallel, or
    some in sequence and others in parallel (for example, in a ship maintainance facility).
    Some models include multiple service facilities, a queuing network.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are thousands of papers on queuing theory. It is important to recognize
    the basic ingredients of a queueing mathematical model:'
  prefs: []
  type: TYPE_NORMAL
- en: The members of the queue (customers, ships, jobs, patients) arrive at certain
    interarrival times. If the arrival process is random, then the math model must
    decide on a probability distribution that this interarrival time adheres to, either
    from the data, or from mathematical distributions know to model such times. Some
    models assume constant arrival times. Others assume the exponential distribution
    (a Markovian process) as it facilitates the mathematical analysis and mimics the
    real life process better. Others assume the *Erlang* distribution which allows
    different exponential distributions for different time intervals. Others assume
    even more general distributions. The more general the distribution, the less easy
    the mathematical analysis. Numerical simulations are our best friend forever.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The number of servers (parallel and sequential) available: An integer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The service times also follow a certain probability distribution that we must
    decide on. Common distributions are similar to those used for interarrival times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition, the mathematical model must also keep track of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The initial number of members in the full queueing system (those waiting and
    those being currently serviced).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The probability of having *n* members in the full queueing system at a given
    later time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, the model wants to compute the *steady state of the queuing system*:'
  prefs: []
  type: TYPE_NORMAL
- en: The probability of having *n* members in the full queuing system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The expected number of new members arriving per unit time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The expected number of members completing their service per unit time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The expected waiting time for each member in the system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Members enter the queue at a certain mean rate, wait to get serviced, get serviced
    at a certain mean rate, then leave the facility. The mathematical model must quantify
    these and balance them.
  prefs: []
  type: TYPE_NORMAL
- en: Inventory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the current shortages in the supply chain, the symptoms are empty shelves
    at the grocery stores, shortages of car repair parts, new cars, materials for
    home renovation, and many others, there is obviously a gap between supply and
    demand. The times between replenishing the supplies at stores have increased in
    a way that is causing backlogs, low productivity, and an overall slowed economy.
    Mathematical models for inventory management quantify the supply (stochastically
    or deterministically), the demand, and devise an optimal inventory policy for
    timing replenishing and deciding on the quantity required at each replenish. Ideally,
    the model must have access to an information processing system that gathers data
    on current inventory levels and signals when and by how much to replenish them.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning For Operations Research
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For starters, what is extremely exciting nowadays in operations research, as
    opposed to ten years ago, is the ability to solve massive operations research
    problems, sometimes involving tens of millions of constraints and decision variables.
    We have to thank the computational power explosion and the contuining improvement
    of computer implementations of operations research algorithms for this.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, machine learning can help predict the values of many parameters that
    enter into operations research models using volumes of available data. If these
    parameters were hard to measure, modelers had to either remove them from the model
    or make assumptions about their values. This doesn’t have to be the case anymore
    because of more accurate machine learning models that are able to take thousands
    of variables into account.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, machine learning can help speed up searching through combinatorially
    large search spaces by *learning* which parts of the space to focus on or which
    subproblems to prioritize. This is exactly what the article [*Learning to Delegate
    for Large-scale Vehicle Routing (2021)*](https://arxiv.org/abs/2107.04139) does,
    speeding up vehicle routing 10 to 100 more times than the state of the art available
    routing algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar research at the intersection of machine learning and operations research
    is booming with great progress and scalable solutions. The following list of abstracts
    from the conference [Operations Research Meets Machine Learning](https://www.euro-online.org/websites/or-in-practice/wp-content/uploads/sites/8/2019/04/OR_meets_ML_abstract_booklet_final.pdf)
    offers a great variety of relevant projects, such as real time data sysnthesis
    and treatment from sensors in waste bins (tracking the volume) for more efficient
    waste collection operation (since this relies on real time data the team relies
    on dynamic routing. Another great example is a bike sharing system, where the
    objective is to predict the number of bikes needed at each location and allocating
    teams to distribute the required number of bikes efficiently. Here is the abstract:
    *Operators in a bike sharing system control room are constantly re-allocating
    bikes where they are most likely to be needed, this requires an insight on the
    optimum number of bikes needed in each station, and the most efficient way to
    distribute teams to move the bikes around. Forecasting engines and Decision Optimization
    is used to calculate the optimal number of bikes for each station at any given
    time, and plan efficient routes to help the redistribution of bikes accordingly.
    A solution delivered by DecisionBrain and IBM for the bike sharing system in London
    is the first application of its kind that uses both optimization and machine learning
    to solve cycle hire inventory, distribution and maintenance problems, and could
    easily be re-deployed for other cycle sharing systems around the world.* In fact
    [DecisionBrain](https://decisionbrain.com)’s projects are worth browsing and thinking
    through.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Currently, my team and I are working on a problem with the Department of Public
    Transporation in my city. This is a perfect setting where machine learning meets
    operations research: Using historical ridership data, in particular daily boardings
    and alightings at each bus stop in the city, along with population density, demographics,
    vulerability, and city zoning data, car ownership, university enrollment and parking
    data, we use neural networks to predict supply and demand patterns at each stop,
    then we use this data and optimal network design from operations research to re-design
    the bus routes so that the bus stops, in particular those in the most socially
    vulnerable areas in the city, are adequately and efficiently serviced.'
  prefs: []
  type: TYPE_NORMAL
- en: Hamilton–Jacobi–Bellman Equation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fields of operations research, game theory, and partial differential equations
    intersect through dynamic programming and the *Hamilton Jacobi Bellman* partial
    differential equation. It is Richard Bellman (mathematician, 1920-1984) who first
    coined the term *curse of dimensionality*, in the context of dynamic programming.
    Now the curse of dimensionality has rendered real life applications of this very
    useful equation limited and unable to incorporate all the players of a game (or
    competing markers, countries, militaries), and solve for their optimal strategies,
    or the thousands of variables that can be involved in operations research problems
    such as for optimal resource allocation problems. The tides have turned with deep
    learning. The paper [*Solving high-dimensional partial differential equations
    using deep learning (2018)*](https://www.pnas.org/doi/10.1073/pnas.1718942115)
    presents a method to solve this equation and others for very high dimensions.
    We will discuss the idea of how the authors do it in [Chapter 13](ch13.xhtml#ch13)
    on AI and partial differential equations.
  prefs: []
  type: TYPE_NORMAL
- en: Operations Research For AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Operations research is the science of decision making based on optimal solutions.
    Humans are always trying to make decisions based on the available circumstances.
    Artificial intelligence aims to replicate all aspects of human intelligence, including
    decision making. In this sense, the decision making methods that operations research
    employs automatically fit into AI. The ideas in dynamic programming, Markov chains,
    optimal control and Hamilton Jacobi Bellman equation, advances in game theory
    and multiagent games, network optimization, and others, have evolved along with
    AI throughout the decades. In fact, many startups market themselves as AI companies
    while in reality they are doing good old (and awesome) operations research.
  prefs: []
  type: TYPE_NORMAL
- en: Summary And Looking Ahead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Operations research is the field of making the best decisions given the current
    knowledge and circumstances. It always comes down to finding clever ways to search
    for optimizers in very high dimensional spaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'One theme throughout this book is the curse of dimensionality, and all the
    effort researchers do to find ways around it. In no field this curse shows up
    as broadly as operations research. Here, the search spaces grow combinatorially
    with the number of players in a particular problem: Number of cities on a route,
    number of competing entities, number of people, number of commodities, *etc.*
    There are very powerful exact methods and heuristic methods, but there is much
    room for improvement in terms of speed and scale.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Machine learning, in particular deep learning, provides a way to learn from
    previously solved problems, from labeled data, or from simulated data. This speeds
    up optimization searches if we identify the bottlenecks and are able to articulate
    the source of the bottle neck as a machine learning problem. For example, a bottle
    neck can be: *We have too many subproblems to solve but we do not know which ones
    to prioritize in order to quickly get us closer to the optimum*. To use machine
    learning to address this, we need a data set of already solved problems and subproblems
    and have a machine learning model learn which subproblems should be prioritized.
    Once the models learns this we can use it to speed up new problems.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other uses of machine learning in operations research include *business as
    usual* type of machine learning: Predict demand from available data, either real
    time or historical data, then use operations research to optimize resource allocation.
    Here machine learning helps make better predictions for demand and hence increases
    efficiency and reduces waste.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we gave a broad overview of the field of operations research
    and its most important types of problems. We especially emphasized linear optimization,
    networks, and duality. Powerful software packages are available for many useful
    problems. We hope that these packages keep integrating the latest progeresses
    in the field.
  prefs: []
  type: TYPE_NORMAL
- en: Two topics are that usually not taught in an introductory operations research
    class are the Hamilton Jacobi Bellman partial differential equation for optimal
    control and strategies of multiplayer games, and optimizing *functionals* using
    calculus of variations. These are usually considered advanced topics in partial
    differential equations. We discussed them here because they both tie naturally
    into optimization and operations research. Moreover, viewing them in this context
    demystifies their corresponding fields.
  prefs: []
  type: TYPE_NORMAL
- en: When doing operations research and optimizing for cost reduction, revenue increase,
    time efficiency, *etc.*, it is important that our optimization models do not ignore
    the human factor. If the output of a scheduling model messes up low wage workers’
    lives through erratic schedules to keep a certain *on time* company performance,
    then that is not a good model and the quality of lives and livelihoods of the
    workers that a company relies on need to be quantified then factored into the
    model. Yes, *the quality of life* needs to be quantified, since everything else
    is being factored in, and we cannot leave this out. Companies with hundreds of
    thousands of low wage workers like Amazon, Starbucks, McDonalds, and other have
    a responsibility that their operations research algorithms do not end up trapping
    their workers into poverty.
  prefs: []
  type: TYPE_NORMAL
- en: 'We leave this chapter with this excerpt from a paper authored by [Charled Hitch](https://www.informs.org/Explore/History-of-O.R.-Excellence/Biographical-Profiles/Hitch-Charles-J)
    on [Uncertainties In Operations Research](https://www.rand.org/pubs/papers/P1959.xhtml)
    from 1960\. Reading this (the brackets are my edits), one cannot help but ponder
    on how far the operations research field has come since 1960:'
  prefs: []
  type: TYPE_NORMAL
- en: '*No other characteristic of decision making is as pervasive as uncertainty.
    When, as operationis researchers, to si.mplify a first cut at an analysis, we
    assume that the situation can be described by certainty equivalents, we may be
    doing violence to the facts and indeed the violence may be so grievous as to falsify
    the problem and give us a nonsense solution. How, for example, can we help the
    military make development decisions—decisions about which aircraft or missiles
    to develop when the essence of the problem is that no one can predict with accuracy
    how long it will take to develop any of the competing equipments, or to get them
    operational, how much they will cost, what their performance will be, or what
    the world will be like at whatever uncertain future date turns out to be relevant
    (if indeed, the world still exists then)? When I say “cannot predict with accuracy”
    I am not exaggerating. We find that typically, for example, the production costs
    of new equipment are underestimated in the early stages of development by factors
    of two to twenty (not 2 to 20 per cent, but factors of two to twenty). Why they
    are always underestimated, never overestimated, I leave to your fertile imaginations.
    […] Another thing that [an operations researcher] can frequently do, especially
    in problems involving research and developmnent, is to ascertain the critical
    uncertainties and recommend strategies to reduce them—to buy information. If you
    do not know which of two dissimilar techniques for missile guidance will turn
    out to be better, your best recommendation is very likely to be: keep them both
    in development a while longer and choose between them when more and better information
    is available. Never mind the people who call you indecisive. You can prove that
    this kind of indecisiveness can save both money and time. Of course you can ‘t
    afford to try everything. There isn’t enough budget. There aren’t enough resources.
    You remember when we used to say “If you gave the military services everything
    they asked for they’d try to fortify the moon!” (We’ll have to change that figure
    of speech.) Actually, it is because of limitations on resources that operations
    research. and operations researchers are important. There’d be no problems for
    us if there were no constraints on resources. It is our job and opportunity to
    find, or invent, within the constraints, some better pattern of adjusting to an
    uncertain world than our betters would find if we weren’t here; or some better
    way, taking costs and pay-offs into account, to buy information to reduce the
    uncertainty.*'
  prefs: []
  type: TYPE_NORMAL
