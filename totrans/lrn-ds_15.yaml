- en: 'Chapter 12\. Case Study: How Accurate Are Air Quality Measurements?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章 案例研究：空气质量测量的准确性有多高？
- en: California is prone to wildfires, so much so that its residents (like the authors
    of this book) sometimes say that California is “always on fire.” In 2020, 40 separate
    fires covered the state in smoke, forced thousands of people to evacuate, and
    caused more than $12 billion in damages ([Figure 12-1](#fig-ca-fires)).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 加利福尼亚州容易发生森林大火，以至于该州的居民（如本书的作者们）有时会说加利福尼亚州“总是在火灾中”。2020年，40起不同的火灾使得整个州笼罩在烟雾之中，迫使成千上万的人撤离，并造成超过120亿美元的损失（[图 12-1](#fig-ca-fires)）。
- en: '![ca-fires](assets/leds_1201.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![ca-fires](assets/leds_1201.png)'
- en: Figure 12-1\. Satellite image from August 2020 showing smoke covering California
    (image from [Wikipedia](https://oreil.ly/CrDld) licensed under CC BY-SA 3.0 IGO)
  id: totrans-3
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-1 卫星图像，显示2020年8月加利福尼亚州被烟雾覆盖的情况（图片来源于[Wikipedia](https://oreil.ly/CrDld)，根据CC
    BY-SA 3.0 IGO许可）。
- en: In places like California, people use air quality measurements to learn what
    kinds of protective measures they need to take. Depending on conditions, people
    may wish to wear a mask, use air filters, or avoid going outside altogether.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在像加利福尼亚这样的地方，人们利用空气质量测量来了解他们需要采取哪些保护措施。根据情况，人们可能希望戴口罩、使用空气过滤器或完全避免外出。
- en: 'In the US, one important source of air quality information is the [Air Quality
    System](https://www.epa.gov/aqs) (AQS), run by the US government. AQS places high-quality
    sensors at locations across the US and makes their data available to the public.
    These sensors are carefully calibrated to strict standards—in fact, the AQS sensors
    are generally seen as the gold standard for accuracy. However, they have a few
    downsides. The sensors are expensive: typically between $15,000 and $40,000 each.
    This means that there are fewer sensors, and they are farther apart. Someone living
    far away from a sensor might not be able to access AQS data for their personal
    use. Also, AQS sensors do not provide real-time data. Since the data undergo extensive
    calibration, they are only released hourly and have a time lag of one to two hours.
    In essence, the AQS sensors are accurate but not timely.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在美国，一个重要的空气质量信息来源是由美国政府运行的[空气质量系统](https://www.epa.gov/aqs)（AQS）。AQS在美国各地的位置上安装了高质量的传感器，并向公众提供它们的数据。这些传感器经过严格的校准到严格的标准——实际上，AQS传感器通常被视为准确度的黄金标准。然而，它们也有一些缺点。这些传感器很昂贵：每台通常在15,000至40,000美元之间。这意味着传感器数量较少，并且它们之间的距离较远。住在传感器远离的人可能无法获取AQS数据用于个人使用。此外，AQS传感器不提供实时数据。由于数据经过广泛的校准，它们仅每小时发布一次，并且有一到两小时的时间滞后。实质上，AQS传感器精确但不及时。
- en: In contrast, [PurpleAir](https://www2.purpleair.com) sensors, which we introduced
    in [Chapter 3](ch03.html#ch-theory-datadesign), sell for about $250 and can be
    easily installed at home. With the lower price point, thousands of people across
    the US have purchased these sensors for personal use. The sensors can connect
    to a home WiFi network so that air quality can be easily monitored, and they can
    report data back to PurpleAir. In 2020, thousands of owners of PurpleAir sensors
    made their sensors’ measurements publicly available. Compared to the AQS sensors,
    PurpleAir sensors are timelier. They report measurements every two minutes rather
    than every hour. Since there are more deployed PurpleAir sensors, more people
    live close enough to a sensor to make use of the data. However, PurpleAir sensors
    are less accurate. To make the sensors affordable, PurpleAir uses a simpler method
    to count particles in the air. This means that PurpleAir measurements can report
    that air quality is worse than it really is (see [Josh Hug’s blog post](https://oreil.ly/ZH5aj)).
    In essence, PurpleAir sensors tend to be timely but less accurate.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，[PurpleAir](https://www2.purpleair.com)传感器，我们在[第3章](ch03.html#ch-theory-datadesign)介绍过，售价约250美元，可以轻松安装在家中。由于价格较低，成千上万的美国人购买了这些传感器用于个人使用。这些传感器可以连接到家庭WiFi网络，因此可以轻松监测空气质量，并可以向PurpleAir报告数据。2020年，数千名PurpleAir传感器的所有者将他们传感器的测量数据公开发布。与AQS传感器相比，PurpleAir传感器更及时。它们每两分钟报告一次测量结果，而不是每小时。由于部署了更多的PurpleAir传感器，更多的人住在接近传感器的地方，可以利用这些数据。然而，PurpleAir传感器的准确性较低。为了使传感器价格更加合理，PurpleAir使用了更简单的方法来计算空气中的颗粒物。这意味着PurpleAir的测量可能会报告空气质量比实际情况更差（见[Josh
    Hug的博客文章](https://oreil.ly/ZH5aj)）。实质上，PurpleAir传感器倾向于及时但准确性较低。
- en: In this chapter, we plan to use the AQS sensor measurements to improve the PurpleAir
    measurements. It’s a big task, and we follow the analysis first developed by [Karoline
    Barkjohn, Brett Gantt, and Andrea Clements](https://oreil.ly/XPxZu) from the US
    Environmental Protection Agency. Barkjohn and her colleagues’ work was so successful
    that, as of this writing, the official US government maps, like the AirNow [Fire
    and Smoke](https://fire.airnow.gov) map, include both AQS and PurpleAir sensors
    and apply Barkjohn’s correction to the PurpleAir data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们计划利用AQS传感器的测量结果来改进PurpleAir的测量。这是一项重大任务，我们首先采用了由[卡洛琳·巴克约恩、布雷特·甘特和安德里亚·克莱门斯](https://oreil.ly/XPxZu)从美国环境保护署开发的分析方法。巴克约恩及其同事的工作非常成功，以至于截至撰写本文时，类似AirNow的官方美国政府地图，如[火灾与烟雾](https://fire.airnow.gov)地图，都包括AQS和PurpleAir传感器，并对PurpleAir数据应用了巴克约恩的校正。
- en: Our work follows the data science lifecycle, beginning with considering the
    question and the scope of the available data. Much of our effort is spent cleaning
    and wrangling the data into shape for analysis, but we also carry out an exploratory
    data analysis and build a model for generalization. We begin by considering the
    question and the design and scope of the data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作遵循数据科学生命周期，从考虑问题和可用数据的设计和范围开始。我们大部分的工作都花费在清洗和整理数据以进行分析，但我们也进行了探索性数据分析并建立了一个泛化模型。我们首先考虑问题、设计和数据的范围。
- en: Question, Design, and Scope
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题、设计和范围
- en: Ideally, measures of air quality should be both *accurate* and *timely*. Inaccurate
    or biased measurements can mean people do not take air quality as seriously as
    they should. Delayed alerts can expose people to harmful air. The context provided
    in the introduction about the popularity of inexpensive air quality sensors got
    us wondering about their quality and usefulness.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，空气质量的测量应该既*准确*又*及时*。不准确或有偏差的测量可能意味着人们对空气质量的重视程度不够。延迟的警报可能会使人们暴露于有害空气中。在引言中提到廉价空气质量传感器的流行背景让我们对它们的质量和实用性产生了兴趣。
- en: 'Two different kinds of instruments measure a natural phenomenon—the amount
    of particulate matter in the air. The AQS sensor has the advantage of small measurement
    error and negligible bias (see [Chapter 2](ch02.html#ch-data-scope)). On the other
    hand, the PurpleAir instrument is less accurate; the measurements have greater
    variability and are also biased. Our initial question is: can we use the AQS measurements
    to make the PurpleAir measurements better?'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 两种不同类型的仪器测量了一个自然现象——空气中颗粒物的数量。AQS传感器具有测量误差小和偏差可以忽略不计的优势（参见[第2章](ch02.html#ch-data-scope)）。另一方面，PurpleAir仪器的精度较低；测量值具有更大的变异性并且也有偏差。我们最初的问题是：我们能否利用AQS测量结果使PurpleAir的测量更准确？
- en: We are in the situation where we have a lot of data available to us. We have
    access to a small number of high-quality measurements from AQS, and we can get
    data from thousands of PurpleAir sensors. To narrow the focus of our question,
    we consider how we might use these two sources of data to improve PurpleAir measurements.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在处于一个有大量可用数据的情况中。我们可以访问少量来自AQS的高质量测量数据，并且可以从成千上万个PurpleAir传感器中获取数据。为了缩小我们问题的焦点，我们考虑如何利用这两个数据源来改进PurpleAir的测量。
- en: The data from these two sources includes the locations of the sensors. So we
    can try to pair them up, finding a PurpleAir sensor close to each AQS sensor.
    If they’re close, then these sensors are essentially measuring the same air. We
    can treat the AQS sensors as the ground truth (because they are so accurate) and
    study the variation in the PurpleAir measurements given the true air quality.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个来源的数据包括传感器的位置。因此，我们可以尝试将它们配对，找到接近每个AQS传感器的PurpleAir传感器。如果它们很接近，那么这些传感器实际上就是在测量相同的空气。我们可以将AQS传感器视为地面真实情况（因为它们非常精确），并研究给定真实空气质量情况下PurpleAir测量值的变化。
- en: Even though there are relatively few pairs of collocated AQS and PurpleAir sensors,
    it seems reasonable to generalize any relationship we find to other PurpleAir
    sensors. If there’s a simple relationship between AQS and PurpleAir measurements,
    then we can use this relationship to adjust measurements from any PurpleAir sensor
    so that they are more accurate.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 即使合并的AQS和PurpleAir传感器对相对较少，将我们发现的任何关系普遍化到其他PurpleAir传感器似乎是合理的。如果AQS和PurpleAir测量之间存在简单的关系，那么我们可以利用这种关系来调整来自任何PurpleAir传感器的测量结果，使其更加准确。
- en: 'We have narrowed down our question quite a bit: can we model the relationship
    between PurpleAir sensor readings and neighboring AQS sensor readings? If yes,
    then hopefully we can use the model to improve PurpleAir readings. Spoiler alert:
    indeed we can!'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经明确了我们的问题：我们能否建立PurpleAir传感器读数与相邻AQS传感器读数之间的关系模型？如果可以，那么希望可以利用该模型改进PurpleAir的读数。剧透警告：确实可以！
- en: This case study nicely integrates the concepts introduced in this part of the
    book. It gives us an opportunity to see how data scientists wrangle, explore,
    and visualize data in a real-world setting. In particular, we see how a large,
    less-accurate dataset can amplify the usefulness of a small, accurate dataset.
    Combining large and small datasets like this is particularly exciting to data
    scientists and applies broadly to other domains ranging from social science to
    medicine.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本案例研究很好地整合了本书这一部分介绍的概念。它为我们提供了一个机会，看看数据科学家如何在实际环境中处理、探索和可视化数据。特别是，我们看到了如何通过大型、不太精确的数据集来增强小型、精确的数据集的有用性。像这样结合大型和小型数据集对数据科学家来说尤为激动人心，并广泛适用于从社会科学到医学等其他领域。
- en: In the next section, we begin our wrangling by finding the pairs of AQS and
    PurpleAir sensors that are near each other. We focus specifically on readings
    for PM2.5 particles, which are particles that are smaller than 2.5 micrometers
    in diameter. These particles are small enough to be inhaled into the lungs, pose
    the greatest risk to health, and are especially common in wood smoke.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们通过寻找彼此靠近的AQS和PurpleAir传感器配对来进行数据处理。我们特别关注PM2.5颗粒的读数，这些颗粒直径小于2.5微米。这些颗粒足以吸入到肺部，对健康构成最大风险，并且在木材燃烧中特别常见。
- en: Finding Collocated Sensors
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找配对传感器
- en: Our analysis begins by finding collocated pairs of AQS and PurpleAir sensors—sensors
    that are placed essentially next to each other. This step is important because
    it lets us reduce the effects of other variables that might cause differences
    in sensor readings. Consider what would happen if we compared an AQS sensor placed
    in a park with a PurpleAir sensor placed along a busy freeway. The two sensors
    would have different readings, in part because the sensors are exposed to different
    environments. Ensuring that sensors are truly collocated lets us claim the differences
    in sensor readings are due to how the sensors are built and to small, localized
    air fluctuations, rather than other potential confounding variables.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分析始于寻找AQS和PurpleAir传感器的配对，即安装在基本相邻位置的传感器。这一步骤很重要，因为它使我们能够减少可能导致传感器读数差异的其他变量的影响。想象一下，如果我们比较一个放置在公园中的AQS传感器和一个放置在繁忙高速公路旁的PurpleAir传感器会发生什么。这两个传感器将有不同的读数，部分原因是传感器暴露在不同的环境中。确保传感器真正配对让我们可以声明传感器读数差异是由传感器构造方式和小范围空气波动引起的，而不是其他潜在混淆变量的影响。
- en: Barkjohn’s analysis conducted by the EPA group found pairs of AQS and PurpleAir
    sensors that are installed within 50 meters of each other. The group contacted
    each AQS site to see whether the PurpleAir sensor was also maintained there. This
    extra effort gave them confidence that their sensor pairs were truly collocated.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 由EPA小组进行的Barkjohn分析找到了在彼此距离不到50米的AQS和PurpleAir传感器配对。该小组联系了每个AQS站点，确认是否也安装了PurpleAir传感器。这额外的工作让他们对传感器配对的真实配对性充满信心。
- en: In this section, we explore and clean location data from AQS and PurpleAir.
    Then we perform a join of sorts to construct a list of potentially collocated
    sensors. We won’t contact AQS sites ourselves; instead, we proceed in later sections
    with Barkjohn’s list of confirmed collocated sensors.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们探索和清理来自AQS和PurpleAir的位置数据。然后，我们进行一种连接操作，构建一个潜在的配对传感器列表。我们不会自己联系AQS站点；相反，我们将在后续章节中使用Barkjohn确认的配对传感器列表。
- en: 'We downloaded a list of AQS and PurpleAir sensors and saved the data in the
    files *data/list_of_aqs_sites.csv* and *data/list_of_purpleair_sensors.json*.
    Let’s begin by reading these files into `pandas DataFrames`. First, we check file
    sizes to see whether they are reasonable to load into memory:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下载了AQS和PurpleAir传感器列表，并将数据保存在文件 *data/list_of_aqs_sites.csv* 和 *data/list_of_purpleair_sensors.json*
    中。让我们开始将这些文件读入 `pandas DataFrames`。首先，我们检查文件大小，看看它们是否可以合理地加载到内存中：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Both files are relatively small. Let’s start with the list of AQS sites.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 两个文件都相对较小。让我们从AQS站点列表开始。
- en: Wrangling the List of AQS Sites
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理AQS站点列表
- en: 'We have filtered the [AQS map of sites](https://oreil.ly/EkZcB) to show only
    the AQS sites that measure PM2.5, and then downloaded the list of sites as a CSV
    file using the map’s web app. Now we can load it into a `pandas DataFrame`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已过滤出仅显示测量PM2.5的AQS站点的[AQS站点地图](https://oreil.ly/EkZcB)，然后使用该地图的Web应用程序下载站点列表作为CSV文件。现在我们可以将其加载到`pandas
    DataFrame`中：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'There are 28 columns in the table. Let’s check the column names:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 表中有28列。让我们检查列名：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To find out which columns are most useful for us, we reference the [data dictionary](https://oreil.ly/GvMPI)
    that the AQS provides on its website. There we confirm that the data table contains
    information about the AQS sites. So we might expect the granularity corresponds
    to an AQS site, meaning each row represents a single site and the column labeled
    `AQS_Site_ID` is the primary key. We can confirm this with a count of records
    for each ID:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找出对我们最有用的哪些列，我们参考了AQS在其网站上提供的[数据字典](https://oreil.ly/GvMPI)。在那里，我们确认数据表包含有关AQS站点的信息。因此，我们可能期望粒度对应于AQS站点，即每行表示一个单个站点，标记为`AQS_Site_ID`的列是主键。我们可以通过每个ID的记录计数来确认这一点：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It looks like some sites appear multiple times in this dataframe. Unfortunately,
    this means that the granularity is finer than the individual site level. To figure
    out why sites are duplicated, let’s take a closer look at the rows for one duplicated
    site:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来有些站点在这个数据框中出现了多次。不幸的是，这意味着粒度比单个站点级别更细。为了弄清楚站点重复的原因，让我们更仔细地查看一个重复站点的行：
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We select a few columns to examine based on their names—those that sound like
    they might shed some light on the reason for duplicates:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 根据列名选择几列进行检查——那些听起来可能会揭示重复原因的列：
- en: '[PRE9]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '|   | POC | Monitor_Start_Date | Last_Sample_Date | Sample_Collection_Method
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|   | POC | Monitor_Start_Date | Last_Sample_Date | Sample_Collection_Method
    |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **458** | 1 | 1/27/1999 | 8/31/2021 | R & P Model 2025 PM-2.5 Sequential
    Air Sampler... |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| **458** | 1 | 1/27/1999 | 8/31/2021 | R & P Model 2025 PM-2.5 Sequential
    Air Sampler... |'
- en: '| **459** | 2 | 2/9/2013 | 8/26/2021 | R & P Model 2025 PM-2.5 Sequential Air
    Sampler... |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| **459** | 2 | 2/9/2013 | 8/26/2021 | R & P Model 2025 PM-2.5 Sequential Air
    Sampler... |'
- en: '| **460** | 3 | 1/1/2019 | 9/30/2021 | Teledyne T640 at 5.0 LPM |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| **460** | 3 | 1/1/2019 | 9/30/2021 | Teledyne T640 at 5.0 LPM |'
- en: '| **461** | 4 | 1/1/2019 | 9/30/2021 | Teledyne T640 at 5.0 LPM |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| **461** | 4 | 1/1/2019 | 9/30/2021 | Teledyne T640 at 5.0 LPM |'
- en: 'The `POC` column looks to be useful for distinguishing between rows in the
    table. The data dictionary states this about the column:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`POC`列看起来对于区分表中的行是有用的。数据字典对该列有以下说明：'
- en: This is the “Parameter Occurrence Code” used to distinguish different instruments
    that measure the same parameter at the same site.
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是用于区分在同一站点上测量相同参数的不同仪器的“参数发生代码”。
- en: So, the site `19-163-0015` has four instruments that all measure PM2.5\. The
    granularity of the dataframe is at the level of a single instrument.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，站点`19-163-0015`有四个仪器都测量PM2.5。数据框的粒度是单个仪器级别。
- en: 'Since our aim is to match AQS and PurpleAir sensors, we can adjust the granularity
    by selecting one instrument from each AQS site. To do this, we group rows according
    to site ID, then take the first row in each group:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的目标是匹配AQS和PurpleAir传感器，我们可以通过选择每个AQS站点的一个仪器来调整粒度。为此，我们根据站点ID对行进行分组，然后在每个组中取第一行：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now the number of rows matches the number of unique IDs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在行数与唯一ID的数量匹配。
- en: 'To match AQS sites with PurpleAir sensors, we only need the site ID, latitude,
    and longitude. So we further adjust the structure and keep only those columns:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要与PurpleAir传感器匹配AQS站点，我们只需要站点ID、纬度和经度。因此，我们进一步调整结构，仅保留这些列：
- en: '[PRE13]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now the `aqs_sites` dataframe is ready, and we move to the PurpleAir sites.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在`aqs_sites`数据框已准备就绪，我们转向PurpleAir站点。
- en: Wrangling the List of PurpleAir Sites
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 整理PurpleAir站点列表
- en: 'Unlike the AQS sites, the file containing PurpleAir sensor data comes in a
    JSON format. We address this format in more detail in [Chapter 14](ch14.html#ch-web).
    For now, we use shell tools (see [Chapter 8](ch08.html#ch-files)) to peek at the
    file contents:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 不同于AQS站点，包含PurpleAir传感器数据的文件是以JSON格式提供的。我们将在[第14章](ch14.html#ch-web)中更详细地讨论这种格式。现在，我们使用shell工具（参见[第8章](ch08.html#ch-files)）来查看文件内容：
- en: '[PRE15]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'From the first few lines of the file, we can guess that the data are stored
    in the `"data"` key and the column labels in the `"fields"` key. We can use Python’s
    `json` library to read in the file as a Python `dict`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从文件的前几行可以猜测数据存储在`"data"`键中，列标签存储在`"fields"`键中。我们可以使用Python的`json`库将文件读取为Python的`dict`：
- en: '[PRE17]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can create a dataframe from the values in `data` and label the columns with
    the content of `fields`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '|   | ID | pm | pm_cf_1 | pm_atm | ... | Voc | Ozone1 | Adc | CH |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: '| **0** | 20 | 0.0 | 0.0 | 0.0 | ... | NaN | NaN | 0.01 | 1 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| **1** | 47 | NaN | NaN | NaN | ... | NaN | 0.72 | 0.72 | 0 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: '| **2** | 53 | 0.0 | 0.0 | 0.0 | ... | NaN | NaN | 0.00 | 1 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: '| **3** | 74 | 0.0 | 0.0 | 0.0 | ... | NaN | NaN | 0.05 | 1 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
- en: '| **4** | 77 | 9.8 | 9.8 | 9.8 | ... | NaN | NaN | 0.01 | 1 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
- en: '[PRE20]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Like the AQS data, there are many more columns in this dataframe than we need:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this case, we can guess that the columns we’re most interested in are the
    sensor IDs (`ID`), sensor labels (`Label`), latitude (`Lat`), and longitude (`Lon`).
    But we did consult the data dictionary on the PurpleAir website to double-check.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s check the `ID` column for duplicates, as we did for the AQS data:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Since the `value_counts()` method lists the counts in descending order, we
    can see that every ID was included only once. So we have verified the granularity
    is at the individual sensor level. Next, we keep only the columns needed to match
    sensor locations from the two sources:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Notice there are tens of thousands more PurpleAir sensors than AQS sensors.
    Our next task is to find the PurpleAir sensor close to each AQS sensor.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Matching AQS and PurpleAir Sensors
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our goal is to match sensors in the two dataframes by finding a PurpleAir sensor
    near each AQS instrument. We consider near to mean within 50 meters. This kind
    of matching is a bit more challenging than the joins we’ve seen thus far. For
    instance, the naive approach to use the `merge` method of `pandas` fails us:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '|   | site_id | lat | lon | id | label |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
- en: '| **0** | 06-111-1004 | 34.45 | -119.23 | 48393 | VCAPCD OJ |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
- en: We cannot simply match instruments with the exact same latitude and longitude;
    we need to find the PurpleAir sites that are close enough to the AQS instrument.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'To figure out how far apart two locations are, we use a basic approximation:
    `111,111` meters in the north-south direction roughly equals one degree of latitude,
    and `111,111 * cos(latitude)` in the east-west direction corresponds to one degree
    of longitude.^([1](ch12.html#id1449)) So we can find the latitude and longitude
    ranges that correspond to 25 meters in each direction (to make a 50-meter-by-50-meter
    rectangle around each point):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To simplify even more, we use the median latitude for the AQS sites:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now we can match coordinates to within the `offset_in_lat` and `offset_in_lon`.
    Doing this in SQL is much easier than in `pandas`, so we push the tables into
    a temporary SQLite database, then run a query to read the tables back into a dataframe:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '|   | aqs_id | pa_id | pa_label | aqs_lat | aqs_lon | pa_lat | pa_lon |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
- en: '| **0** | 06-019-0011 | 6568 | IMPROVE_FRES2 | 36.79 | -119.77 | 36.79 | -119.77
    |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
- en: '| **1** | 06-019-0011 | 13485 | AMTS_Fresno | 36.79 | -119.77 | 36.79 | -119.77
    |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 06-019-0011 | 13485 | AMTS_Fresno | 36.79 | -119.77 | 36.79 | -119.77
    |'
- en: '| **2** | 06-019-0011 | 44427 | Fresno CARB CCAC | 36.79 | -119.77 | 36.79
    | -119.77 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 06-019-0011 | 44427 | Fresno CARB CCAC | 36.79 | -119.77 | 36.79
    | -119.77 |'
- en: '| **...** | ... | ... | ... | ... | ... | ... | ... |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| **...** | ... | ... | ... | ... | ... | ... | ... |'
- en: '| **146** | 53-061-1007 | 3659 | Marysville 7th | 48.05 | -122.17 | 48.05 |
    -122.17 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| **146** | 53-061-1007 | 3659 | Marysville 7th | 48.05 | -122.17 | 48.05 |
    -122.17 |'
- en: '| **147** | 53-063-0021 | 54603 | Augusta 1 SRCAA | 47.67 | -117.36 | 47.67
    | -117.36 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| **147** | 53-063-0021 | 54603 | Augusta 1 SRCAA | 47.67 | -117.36 | 47.67
    | -117.36 |'
- en: '| **148** | 56-021-0100 | 50045 | WDEQ-AQD Cheyenne NCore | 41.18 | -104.78
    | 41.18 | -104.78 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| **148** | 56-021-0100 | 50045 | WDEQ-AQD Cheyenne NCore | 41.18 | -104.78
    | 41.18 | -104.78 |'
- en: '[PRE35]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We’ve achieved our goal—we matched 149 AQS sites with PurpleAir sensors. Our
    wrangling of the locations is complete, and we turn to the task of wrangling and
    cleaning the sensor measurements. We start with the measurements taken from an
    AQS site.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经达到了我们的目标——我们匹配了 149 个 AQS 站点与 PurpleAir 传感器。我们对位置的整理完成了，现在转向整理和清理传感器测量数据的任务。我们从
    AQS 站点获取的测量值开始。
- en: Wrangling and Cleaning AQS Sensor Data
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整理和清理 AQS 传感器数据
- en: Now that we have located sensors that are near each other, we are ready to wrangle
    and clean the files that contain the measurement data for these sites. We demonstrate
    the tasks involved with one AQS instrument and its matching PurpleAir sensor.
    We picked a pair located in Sacramento, California. The AQS sensor ID is `06-067-0010`,
    and the PurpleAir sensor name is `AMTS_TESTINGA`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经找到彼此附近的传感器，我们准备整理和清理这些站点的测量数据文件。我们演示了一个 AQS 仪器及其匹配的 PurpleAir 传感器涉及的任务。我们选择了位于加利福尼亚州萨克拉门托的一对。AQS
    传感器 ID 是 `06-067-0010`，PurpleAir 传感器名称是 `AMTS_TESTINGA`。
- en: 'The AQS provides a website and [API](https://oreil.ly/tl_nc) to download sensor
    data. We downloaded the daily measurements from May 20, 2018, to December 29,
    2019, into the *data/aqs_06-067-0010.csv* file. Let’s begin by loading this file
    into a dataframe:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: AQS 提供了一个网站和 [API](https://oreil.ly/tl_nc) 用于下载传感器数据。我们下载了从2018年5月20日到2019年12月29日的每日测量数据，保存在
    *data/aqs_06-067-0010.csv* 文件中。让我们从加载这个文件到数据框架开始：
- en: '[PRE36]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: From the [data dictionary](https://oreil.ly/e1PjI), we find out that the column
    called `arithmetic_mean` corresponds to the actual PM2.5 measurements. Some AQS
    sensors take a measurement every hour. For our analysis, we downloaded the 24-hour
    averages (the arithmetic mean) of the hourly sensor measurements.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [数据字典](https://oreil.ly/e1PjI) 中我们发现，`arithmetic_mean` 列对应于实际的 PM2.5 测量。一些
    AQS 传感器每小时进行一次测量。对于我们的分析，我们下载了每日平均值（算术平均值）的 24 小时平均值的传感器测量。
- en: 'Let’s carry out some quality checks and clean the data where necessary. We
    focus on checks related to scope and quality of values:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行一些质量检查和必要的数据清理。我们关注与值的范围和质量相关的检查：
- en: Check and correct the granularity of the data.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查和修正数据的粒度。
- en: Remove unneeded columns.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除不需要的列。
- en: Check values in the `date_local` column.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `date_local` 列中的值。
- en: Check values in the `arithmetic_mean` column.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `arithmetic_mean` 列中的值。
- en: For the sake of brevity, we’ve chosen a few important quality checks that specifically
    reinforce ideas we’ve covered in data wrangling, EDA, and visualization.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为简洁起见，我们选择了一些重要的质量检查，特别是加强了我们在数据整理、探索性数据分析和可视化中涵盖的思想。
- en: Checking Granularity
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查粒度
- en: 'We would like each row of our data to correspond to a single date with an average
    PM2.5 reading for that date. As we saw earlier, a simple way to check is to see
    whether there are repeat values in the `date_local` column:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望我们数据的每一行对应于单个日期，具有该日期的平均 PM2.5 读数。正如我们之前看到的，一个简单的检查方法是查看 `date_local` 列中是否有重复值：
- en: '[PRE38]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Indeed, there are 12 rows for each date, so the granularity is *not* at the
    individual date level.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，每个日期有 12 行数据，因此粒度并不是在个体日期级别上。
- en: 'From the data dictionary, we learn that there are multiple standards for computing
    the final measurements from the raw sensor data. The `pollutant_standard` column
    contains the name of each standard. The `event_type` column marks whether data
    measured during “exceptional events” are included in the measurement. Let’s check
    how different these average values are by calculating the range of 12 measurements:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据字典中我们得知，有多种标准用于从原始传感器数据计算最终测量结果。`pollutant_standard` 列包含每个标准的名称。`event_type`
    列标记了是否包括“异常事件”期间测得的数据。让我们通过计算这 12 个测量的范围来检查这些平均值有多么不同：
- en: '[PRE40]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'For all 189 dates, the max PM2.5–min PM2.5 is 0\. This means that we can simply
    take the first PM2.5 measurement for each date:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 189 个日期，最大 PM2.5–最小 PM2.5 为 0。这意味着我们只需取每个日期的第一个 PM2.5 测量值：
- en: '[PRE42]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This data-cleaning step gives us the desired granularity: each row represents
    a single date, with an average PM2.5 measurement for that date. Next, we further
    modify the structure of the dataframe and drop unneeded columns.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据清理步骤使我们获得了所需的细粒度：每一行代表一个单独的日期，具有该日期的平均 PM2.5 测量值。接下来，我们进一步修改数据框的结构并删除不需要的列。
- en: Removing Unneeded Columns
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移除不必要的列
- en: 'We plan to match the PM2.5 measurements in the AQS dataframe with the PurpleAir
    PM2.5 measurements for each date. To simplify the structure, we can drop all but
    the date and PM2.5 columns. We also rename the PM2.5 column so that it’s easier
    to understand:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计划将 AQS 数据框中的 PM2.5 测量与 PurpleAir 的 PM2.5 测量进行匹配，以每日为单位。为简化结构，我们可以舍弃除日期和 PM2.5
    列外的所有列。我们还将 PM2.5 列重命名，以便更容易理解：
- en: '[PRE45]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '|   | date_local | pm25 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '|   | date_local | pm25 |'
- en: '| --- | --- | --- |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **0** | 2018-05-20 | 6.5 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 2018-05-20 | 6.5 |'
- en: '| **1** | 2018-05-23 | 2.3 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 2018-05-23 | 2.3 |'
- en: '| **2** | 2018-05-29 | 11.8 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 2018-05-29 | 11.8 |'
- en: '| **3** | 2018-06-01 | 6.0 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 2018-06-01 | 6.0 |'
- en: '| **4** | 2018-06-04 | 8.0 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| **4** | 2018-06-04 | 8.0 |'
- en: Now that we have the desired shape for our data table, we turn to checking the
    data values.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为数据表获得了所需的形状，我们转而检查数据值。
- en: Checking the Validity of Dates
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查日期的有效性
- en: 'Let’s take a closer look at the dates. We have already seen that there are
    gaps when there are no PM2.5 readings, so we expect there are missing dates. Let’s
    parse the dates as timestamp objects to make it easier to figure out which dates
    are missing. As we did in [Chapter 9](ch09.html#ch-wrangling), we check the format:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细查看日期。我们已经看到当没有 PM2.5 读数时存在间隙，因此我们预计存在缺失日期。让我们将日期解析为时间戳对象，以便更容易确定缺失的日期。与我们在
    [第 9 章](ch09.html#ch-wrangling) 中所做的一样，我们检查格式：
- en: '[PRE47]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The dates are represented as YYYY-MM-DD, so we describe the format in the Python
    representation `''%Y-%m-%d''`. To parse the dates, we use the `pd.to_datetime()`
    function, and we reassign the `date_local` column as `pd.TimeStamp`s:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 日期以 YYYY-MM-DD 表示，因此我们在 Python 表示中描述为 `'%Y-%m-%d'`。为了解析日期，我们使用 `pd.to_datetime()`
    函数，并将 `date_local` 列重新分配为 `pd.TimeStamp`：
- en: '[PRE49]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The method runs without erroring, indicating that all the strings matched the
    format.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法运行无误，表明所有字符串都匹配了格式。
- en: Note
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Just because the dates can be parsed doesn’t mean that the dates are immediately
    ready to use for further analysis. For instance, the string `9999-01-31` can be
    parsed into a `pd.TimeStamp`, but the date isn’t valid.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅因为日期可以解析，这并不意味着日期立即可以用于进一步的分析。例如，字符串 `9999-01-31` 可以解析为 `pd.TimeStamp`，但该日期无效。
- en: 'Now that the dates have been converted to timestamps, we can calculate how
    many dates are missing. We find the number of days between the earliest and latest
    dates—this corresponds to the maximum number of measurements we could have recorded:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在日期已转换为时间戳，我们可以计算缺失的日期数。我们找到最早日期和最晚日期之间的天数——这对应于我们可能记录的最大测量次数：
- en: '[PRE51]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Subtracting timestamps gives `Timedelta` objects, which as we see have a few
    useful properties. There are many dates missing from the data. However, when we
    combine these data for this sensor with other sensors, we expect to have enough
    data to fit a model.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 减去时间戳会得到 `Timedelta` 对象，正如我们所看到的，它们具有一些有用的属性。数据中有很多日期缺失。然而，当我们将此传感器的这些数据与其他传感器的数据结合起来时，我们希望有足够的数据来拟合一个模型。
- en: Our final wrangling step is to check the quality of the PM2.5 measurements.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最终整理步骤是检查 PM2.5 测量的质量。
- en: Checking the Quality of PM2.5 Measurements
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查 PM2.5 测量质量
- en: Particulate matter is measured in micrograms per cubic meter of air (µg/m³).
    (There are 1 million micrograms in 1 gram, and 1 pound is equal to about 450 grams.)
    The [EPA has set a standard](https://oreil.ly/XqVqG) of 35 µg/m³ for a daily average
    of PM2.5 and 12 µg/m³ for an annual average. We can use this information to make
    a few basic checks on the PM2.5 measurements. First, PM2.5 can’t go below 0\.
    Second, we can look for abnormally high PM2.5 values and see whether they correspond
    to major events like a wildfire.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 颗粒物浓度以每立方米空气中的微克数（µg/m³）来衡量。（1 克中有 1 百万微克，1 磅约等于 450 克。）[EPA 制定了标准](https://oreil.ly/XqVqG)，即
    PM2.5 的日均值为 35 µg/m³，年均值为 12 µg/m³。我们可以利用这些信息对 PM2.5 测量进行几项基本检查。首先，PM2.5 不能低于
    0。其次，我们可以寻找异常高的 PM2.5 值，并查看它们是否对应于重大事件，如野火。
- en: 'One visual way to perform these checks is to plot the PM2.5 measurement against
    the date:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 进行这些检查的一种视觉方法是将 PM2.5 测量值绘制成日期图：
- en: '[PRE53]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '![](assets/leds_12in01.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/leds_12in01.png)'
- en: We see that the PM2.5 measurements don’t go below 0 and are typically lower
    than the EPA level. We also found a large spike in PM2.5 around mid-November of
    2018\. This sensor is located in Sacramento, so we can check if there was a fire
    around that area.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现 PM2.5 的测量数值不会低于 0，通常低于 EPA 的标准。我们还发现 2018 年 11 月中旬 PM2.5 出现了大幅上升。该传感器位于萨克拉门托，因此我们可以检查该地区是否发生了火灾。
- en: Indeed, November 8, 2018, marks the start of the Camp Fire, the “deadliest and
    most destructive wildfire in California history” (see the [Camp Fire page](https://oreil.ly/tqxtH)
    managed by the US Census Bureau). The fire started just 80 miles north of Sacramento,
    so this AQS sensor captured the dramatic spike in PM2.5.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，2018 年 11 月 8 日标志着“加州历史上最致命和破坏性的野火”——“大火营”（见由美国人口普查局管理的[大火营页面](https://oreil.ly/tqxtH)）。火灾发生在距离萨克拉门托仅
    80 英里的地方，因此这个 AQS 传感器捕捉到了 PM2.5 的剧烈增长。
- en: We’ve cleaned and explored the data for one AQS sensor. In the next section,
    we do the same for its collocated PurpleAir sensor.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经清理和探索了一个 AQS 传感器的数据。在下一节中，我们将对其附近的 PurpleAir 传感器进行相同的操作。
- en: Wrangling PurpleAir Sensor Data
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整理 PurpleAir 传感器数据
- en: 'In the previous section, we analyzed data from AQS site `06-067-0010`. The
    matching PurpleAir sensor is named `AMTS_TESTINGA`, and we’ve used the PurpleAir
    website to download the data for this sensor into the *data/purpleair_AMTS* folder:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们分析了 AQS 站点 `06-067-0010` 的数据。匹配的 PurpleAir 传感器命名为 `AMTS_TESTINGA`，我们已经使用
    PurpleAir 网站将此传感器的数据下载到 *data/purpleair_AMTS* 文件夹中：
- en: '[PRE54]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'There are four CSV files. Their names are quite long, and the beginning of
    each is identical. The data dictionary for the PurpleAir data says that each sensor
    has two separate instruments, A and B, that each record data. Note that the PurpleAir
    site we used to collect these data and the accompanying data dictionary has been
    downgraded. The data are now available through a REST API. The [site that documents
    the API](https://oreil.ly/WSciR) also contains information about the fields. (The
    topic of REST is covered in [Chapter 14](ch14.html#ch-web).) Let’s examine the
    later portions of the filenames:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 有四个 CSV 文件。它们的名称相当长，并且每个的开头都相同。PurpleAir 数据的数据字典表明，每个传感器都有两个单独的仪器 A 和 B，每个都记录数据。请注意，我们用于收集这些数据和配套数据字典的
    PurpleAir 网站已降级。数据现在通过 REST API 可用。[记录 API 的站点](https://oreil.ly/WSciR)还包含有关字段的信息。（REST
    的主题在[第 14 章](ch14.html#ch-web)中涵盖。）让我们检查文件名的后部分：
- en: '[PRE56]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: We can see that the first two CSV files correspond to instrument A and the last
    two to B. Having two instruments is useful for data cleaning; if A and B disagree
    about a measurement, we might question the integrity of the measurement and decide
    to remove it.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到前两个 CSV 文件对应于仪器 A，最后两个对应于 B。拥有两个仪器对数据清理很有用；如果 A 和 B 对某个测量结果有异议，我们可能会质疑测量结果的完整性，并决定删除它。
- en: 'The data dictionary also mentions that each instrument records Primary and
    Secondary data. The Primary data contains the fields we’re interested in: PM2.5,
    temperature, and humidity. The Secondary data contains data for other particle
    sizes, like PM1.0 and PM10\. So we work only with the Primary files.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 数据字典还提到，每个仪器记录主要和次要数据。主要数据包含我们感兴趣的字段：PM2.5、温度和湿度。次要数据包含其他粒径的数据，如 PM1.0 和 PM10。因此我们只使用主文件。
- en: Our tasks are similar to those of the previous section, with the addition of
    addressing readings from two instruments.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的任务与上一节类似，只是增加了处理两台仪器读数的内容。
- en: 'We begin by loading in the data. When CSV files have long names, we can assign
    the filenames into a Python variable to more easily load the files:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载数据。当 CSV 文件名很长时，我们可以将文件名分配给 Python 变量，以更轻松地加载文件：
- en: '[PRE58]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Let’s look at the columns to see which ones we need:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下列，确定我们需要哪些列：
- en: '[PRE62]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Although we’re interested in PM2.5, it appears there are two columns that contain
    PM2.5 data: `PM2.5_CF1_ug/m3` and `PM2.5_ATM_ug/m3`. We investigate the difference
    between these two columns to find that PurpleAir sensors use two different methods
    to convert a raw laser recording into a PM2.5 number. These two calculations correspond
    to the CF1 and ATM columns. Barkjohn found that using CF1 produced better results
    than ATM, so we keep that column, along with the date, temperature, and relative
    humidity:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们对 PM2.5 感兴趣，但似乎有两列包含 PM2.5 数据：`PM2.5_CF1_ug/m3` 和 `PM2.5_ATM_ug/m3`。我们调查了这两列之间的差异，发现
    PurpleAir 传感器使用两种不同的方法将原始激光记录转换为 PM2.5 数值。这两种计算对应于 CF1 和 ATM 列。Barkjohn 发现使用 CF1
    比 ATM 产生了更好的结果，因此我们保留该列，以及日期、温度和相对湿度：
- en: '[PRE64]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '|   | timestamp | PM25cf1 | TempF | RH |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '|   | 时间戳 | PM25cf1 | TempF | RH |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **0** | 2018-05-20 00:00:35 UTC | 1.23 | 83.0 | 32.0 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 2018-05-20 00:00:35 UTC | 1.23 | 83.0 | 32.0 |'
- en: '| **1** | 2018-05-20 00:01:55 UTC | 1.94 | 83.0 | 32.0 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 2018-05-20 00:01:55 UTC | 1.94 | 83.0 | 32.0 |'
- en: '| **2** | 2018-05-20 00:03:15 UTC | 1.80 | 83.0 | 32.0 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 2018-05-20 00:03:15 UTC | 1.80 | 83.0 | 32.0 |'
- en: '| **3** | 2018-05-20 00:04:35 UTC | 1.64 | 83.0 | 32.0 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 2018-05-20 00:04:35 UTC | 1.64 | 83.0 | 32.0 |'
- en: '| **4** | 2018-05-20 00:05:55 UTC | 1.33 | 83.0 | 32.0 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| **4** | 2018-05-20 00:05:55 UTC | 1.33 | 83.0 | 32.0 |'
- en: Next we check granularity.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们检查粒度。
- en: Checking the Granularity
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查粒度
- en: In order for the granularity of these measurements to match the AQS data, we
    want one average PM2.5 for each date (a 24-hour period). PurpleAir states that
    sensors take measurements every two minutes. Let’s double-check the granularity
    of the raw measurements before we aggregate them to 24-hour periods.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这些测量的粒度与 AQS 数据匹配，我们希望每个日期（24 小时）有一个平均 PM2.5。PurpleAir 表示传感器每两分钟进行一次测量。在我们将其聚合到
    24 小时期间之前，让我们再次检查原始测量的粒度。
- en: 'To do this we convert the column containing the date information from strings
    to `pd.TimeStamp` objects. The format of the date is different than the AQS format,
    which we describe as `''%Y-%m-%d %X %Z''`. As we soon see, `pandas` has special
    support for dataframes with an index of timestamps:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这一点，我们将包含日期信息的列从字符串转换为 `pd.TimeStamp` 对象。日期的格式与 AQS 格式不同，我们描述为 `'%Y-%m-%d
    %X %Z'`。正如我们所见，`pandas` 对于具有时间戳索引的数据框架有特殊支持：
- en: '[PRE65]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '|   | PM25cf1 | TempF | RH |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|   | PM25cf1 | TempF | RH |'
- en: '| --- | --- | --- | --- |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| timestamp |   |   |   |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 时间戳 |   |   |   |'
- en: '| --- | --- | --- | --- |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **2018-05-20 00:00:35+00:00** | 1.23 | 83.0 | 32.0 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| **2018-05-20 00:00:35+00:00** | 1.23 | 83.0 | 32.0 |'
- en: '| **2018-05-20 00:01:55+00:00** | 1.94 | 83.0 | 32.0 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| **2018-05-20 00:01:55+00:00** | 1.94 | 83.0 | 32.0 |'
- en: 'Timestamps are tricky—notice that the original timestamps were given in the
    UTC time zone. However, the AQS data were averaged according to the *local time
    in California*, which is either seven or eight hours behind UTC time, depending
    on whether daylight saving time is in effect. This means we need to change the
    time zone of the PurpleAir timestamps to match the local time zone. The `df.tz_convert()`
    method operates on the index of the dataframe, which is one reason why we set
    the index of `pa` to the timestamps:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 时间戳很棘手 — 注意原始时间戳是以 UTC 时区给出的。然而，AQS 数据根据 *加利福尼亚州当地时间* 平均，这比 UTC 时间晚七或八小时，这取决于是否实行夏令时。这意味着我们需要更改
    PurpleAir 时间戳的时区以匹配当地时区。`df.tz_convert()` 方法作用于数据框架的索引，这也是我们将 `pa` 的索引设置为时间戳的一个原因：
- en: '[PRE66]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '|   | PM25cf1 | TempF | RH |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '|   | PM25cf1 | TempF | RH |'
- en: '| --- | --- | --- | --- |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| timestamp |   |   |   |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 时间戳 |   |   |   |'
- en: '| --- | --- | --- | --- |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **2018-05-19 17:00:35-07:00** | 1.23 | 83.0 | 32.0 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| **2018-05-19 17:00:35-07:00** | 1.23 | 83.0 | 32.0 |'
- en: '| **2018-05-19 17:01:55-07:00** | 1.94 | 83.0 | 32.0 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| **2018-05-19 17:01:55-07:00** | 1.94 | 83.0 | 32.0 |'
- en: If we compare the first two rows of this version of the dataframe to the previous
    one, we see that the time has changed to indicate the seven-hour difference from
    UTC.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将此版本的数据框架的前两行与上一个进行比较，我们会看到时间已更改以表明与 UTC 相差七个小时。
- en: Visualizing timestamps can help us check the granularity of the data.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化时间戳可以帮助我们检查数据的粒度。
- en: Visualizing timestamps
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化时间戳
- en: 'One way to visualize timestamps is to count how many appear in each 24-hour
    period, then plot those counts over time. To group time-series data in `pandas`,
    we can use the `df.resample()` method. This method works on dataframes that have
    an index of timestamps. It behaves like `df.groupby()`, except that we can specify
    how we want the timestamps to be grouped—we can group into dates, weeks, months,
    and many more options (the `D` argument tells `resample` to aggregate timestamps
    into individual dates):'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化时间戳的一种方法是计算每个24小时内出现的次数，然后绘制这些计数随时间的变化。要在 `pandas` 中对时间序列数据进行分组，可以使用 `df.resample()`
    方法。此方法适用于具有时间戳索引的数据框。它的行为类似于 `df.groupby()`，但我们可以指定希望如何分组时间戳——可以分组为日期、周、月等多种选项（`D`
    参数告诉 `resample` 将时间戳聚合成单独的日期）：
- en: '[PRE67]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'We see that the number of measurements in a day varies widely. A line plot
    of these counts gives us a better sense of these variations:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到每天的测量次数变化很大。这些计数的折线图能更好地展示这些变化：
- en: '[PRE70]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '![](assets/leds_12in02.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_12in02.png)'
- en: 'This is a fascinating plot. We see clear gaps in the data where there are no
    measurements. It appears that significant portions of data in July 2018 and September
    2019 are missing. Even when the sensor appears to be working, the number of measurements
    per day is slightly different. For instance, the plot is “bumpy” between August
    and October 2018, where dates have a varying number of measurements. We need to
    decide what we want to do with missing data. But perhaps more urgently: there
    are strange “steps” in the plot. Some dates have around 1,000 readings, some around
    2,000, some around 700, and some around 1,400\. If a sensor takes measurements
    every two minutes, there should be a maximum of 720 measurements per day. For
    a perfect sensor, the plot would display a flat line at 720 measurements. This
    is clearly not the case. Let’s investigate.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个引人入胜的图表。我们可以看到数据中存在明显的缺失测量间隙。在2018年7月和2019年9月，数据的大部分似乎都丢失了。即使传感器运行正常，每天的测量次数也略有不同。例如，在2018年8月至10月之间的折线图上“崎岖不平”，日期上的测量次数有所变化。我们需要决定如何处理缺失数据。但也许更紧迫的是：折线图上出现了奇怪的“阶梯”。一些日期大约有1,000个读数，一些大约有2,000个，一些大约有700个，一些大约有1,400个。如果传感器每两分钟进行一次测量，则每天的最大测量次数应为720次。对于完美的传感器，折线图应显示为720次的平直线。显然情况并非如此。让我们来调查一下。
- en: Checking the sampling rate
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检查采样率
- en: 'Deeper digging reveals that although PurpleAir sensors currently record data
    every 120 seconds, this was not always the case. Before May 30, 2019, sensors
    recorded data every 80 seconds, or 1,080 points a day. The change in sampling
    rate does explain the drop on May 30, 2019\. Let’s next look at the time periods
    where there were many more points than expected. This could mean that some measurements
    were duplicated in the data. We can check this by looking at the measurements
    for one day, say, January 1, 2019\. We pass a string into `.loc` to filter timestamps
    for that date:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步的挖掘显示，尽管PurpleAir传感器当前每120秒记录一次数据，但以前并非如此。2019年5月30日之前，传感器每80秒记录一次数据，即每天1,080个数据点。采样率的变化确实解释了2019年5月30日的数据下降。接下来我们看看时间段内存在远高于预期点数的情况。这可能意味着数据中存在重复的测量。我们可以通过查看一天的测量数据来验证这一点，例如2019年1月1日。我们通过向
    `.loc` 传入字符串来筛选该日期的时间戳：
- en: '[PRE71]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'There are almost double the 1,080 expected readings. Let’s check to see if
    readings are duplicated:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎有1,080个预期读数的两倍。让我们检查是否存在重复读数：
- en: '[PRE73]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Each timestamp appears exactly twice, and we can verify that all duplicated
    dates contain the same PM2.5 reading. Since this is also true for both temperature
    and humidity, we drop the duplicate rows from the dataframe:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 每个时间戳正好出现两次，我们可以验证所有重复的日期包含相同的 PM2.5 读数。由于温度和湿度也是如此，我们从数据框中删除重复行：
- en: '[PRE75]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'To check, we remake the line plot of the number of records for a day, and this
    time we shade the regions where the counts are supposed to be contained:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查，我们重新制作了每天记录数的折线图，这次我们会在预期包含的区域内填充颜色：
- en: '[PRE77]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '![](assets/leds_12in03.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_12in03.png)'
- en: After dropping duplicate dates, the plot of measurements per day looks much
    more consistent with the counts we expect. Careful readers will see two spikes
    above the maximum measurements around November of each year when daylight saving
    time is no longer in effect. When clocks are rolled back one hour, that day has
    25 hours instead of the usual 24 hours. Timestamps are tricky!
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 去除重复日期后，每天的测量数据图与我们预期的计数更一致。细心的读者会发现每年11月左右，在取消夏令时后，有两次高于最大测量值的峰值。当时钟被倒退一小时时，那一天有25小时而不是通常的24小时。时间戳确实很棘手！
- en: But there are still missing measurements, and we need to decide what to do about
    them.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 但仍然有缺失的测量值，我们需要决定如何处理。
- en: Handling Missing Values
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理缺失值
- en: 'The plan is to create 24-hour averages of the measurements, but we don’t want
    to use days when there are not enough measurements. We follow Barkjohn’s analysis
    and only keep a 24-hour average if there are at least 90% of the possible points
    for that day. Remember that before May 30, 2019, there are 1,080 possible points
    in a day, and after that there are 720 possible points. We calculate the minimum
    number of measurements needed to keep per day:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 计划是创建测量值的24小时平均，但我们不想使用测量不足的日子。我们遵循Barkjohn的分析，仅在该日有至少90%可能数据点时保留24小时平均。请记住，在2019年5月30日之前，一天有1080个可能数据点，之后为720个可能数据点。我们计算了每天需要保留的最少测量数：
- en: '[PRE79]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Now we can determine which of the days have enough measurements to keep:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以确定哪些日子有足够的测量数据可以保留：
- en: '[PRE80]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'We’re ready to average together the readings for each day and then remove the
    days without enough readings:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好将每天的读数进行平均，并删除不足的天数：
- en: '[PRE83]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '|   | PM25cf1 | TempF | RH |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '|   | PM25cf1 | TempF | RH |'
- en: '| --- | --- | --- | --- |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| timestamp |   |   |   |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| timestamp |   |   |   |'
- en: '| --- | --- | --- | --- |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **2018-05-20 00:00:00-07:00** | 2.48 | 83.35 | 28.72 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| **2018-05-20 00:00:00-07:00** | 2.48 | 83.35 | 28.72 |'
- en: '| **2018-05-21 00:00:00-07:00** | 3.00 | 83.25 | 29.91 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| **2018-05-21 00:00:00-07:00** | 3.00 | 83.25 | 29.91 |'
- en: Now we have the average daily PM2.5 readings for instrument A, and we need to
    repeat on instrument B the data wrangling we just performed on instrument A. Fortunately,
    we can reuse the same pipeline. For brevity, we don’t include that wrangling here.
    But we need to decide what to do if the PM2.5 averages differ. Barkjohn dropped
    rows if the PM2.5 values for A and B differed by more than 61%, or by more than
    5 µg m⁻³. For this pair of sensors, that leads to dropping 12 of the 500+ rows.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了仪器A的平均每日PM2.5读数，需要在仪器B上重复刚才在仪器A上执行的数据整理工作。幸运的是，我们可以重复使用同样的流程。为了简洁起见，我们不在此处包含该数据整理步骤。但我们需要决定如果PM2.5的平均值不同要怎么办。如果A和B的PM2.5值相差超过61%，或者超过5
    µg m⁻³，Barkjohn会删除12行中的一对传感器中的此行。
- en: 'As you can see, it takes a lot of work to prepare and clean these data: we
    handled missing data, aggregated the readings for each instrument, averaged the
    readings together from the two instruments, and removed rows where they disagreed.
    This work has given us a set of PM2.5 readings that we are more confident in.
    We know that each PM2.5 value in the final dataframe is the daily average from
    two separate instruments that generated consistent and complete readings.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，准备和清理这些数据需要大量工作：我们处理了缺失数据，对每个仪器的读数进行了聚合，将两个仪器的读数平均在一起，并删除了它们不一致的行。这项工作使我们对PM2.5读数更加自信。我们知道最终数据框中的每个PM2.5值都是来自生成一致且完整读数的两个独立仪器的日均值。
- en: To fully replicate Barkjohn’s analysis, we would need to repeat this process
    over all the PurpleAir sensors. Then we would repeat the AQS cleaning procedure
    on all the AQS sensors. Finally, we would merge the PurpleAir and AQS data together.
    This procedure produces daily average readings for each collocated sensor pair.
    For brevity, we omit this code. Instead, we proceed with the final steps of the
    analysis using the group’s dataset. We begin with an EDA with an eye toward modeling.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 要完全复制Barkjohn的分析，我们需要在所有PurpleAir传感器上重复此过程。然后我们会在所有AQS传感器上重复AQS清洁程序。最后，我们将PurpleAir和AQS数据合并在一起。这个过程产生了每对同位置传感器的日均读数。为了简洁起见，我们略过此代码。而是继续使用小组数据集进行分析的最后步骤。我们从EDA开始，着眼于建模。
- en: Exploring PurpleAir and AQS Measurements
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索PurpleAir和AQS的测量数据
- en: Let’s explore the cleaned dataset of matched AQS and PurpleAir PM2.5 readings
    and look for insights that might help us in modeling. Our main interest is in
    the relationship between the two sources of air quality measurements. But we want
    to keep in mind the scope of the data, like how these data are situated in time
    and place. We learned from our data cleaning that we are working with daily averages
    of PM2.5 for a couple of years and that we have data from dozens of locations
    across the US.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索匹配的AQS和PurpleAir PM2.5读数的清理数据集，并寻找可能帮助我们建模的见解。我们主要关注两种空气质量测量数据之间的关系。但我们要记住数据的范围，比如这些数据在时间和地点上的分布。从数据清理中我们了解到，我们处理的是几年内的PM2.5日均值数据，并且我们有来自美国数十个地点的数据。
- en: 'First we review the entire cleaned dataframe:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们回顾整个清理过的数据框：
- en: '[PRE84]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '|   | date | id | region | pm25aqs | pm25pa | temp | rh | dew |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '|   | date | id | region | pm25aqs | pm25pa | temp | rh | dew |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| **0** | 2019-05-17 | AK1 | Alaska | 6.7 | 8.62 | 18.03 | 38.56 | 3.63 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 2019-05-17 | AK1 | 阿拉斯加 | 6.7 | 8.62 | 18.03 | 38.56 | 3.63 |'
- en: '| **1** | 2019-05-18 | AK1 | Alaska | 3.8 | 3.49 | 16.12 | 49.40 | 5.44 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 2019-05-18 | AK1 | 阿拉斯加 | 3.8 | 3.49 | 16.12 | 49.40 | 5.44 |'
- en: '| **2** | 2019-05-21 | AK1 | Alaska | 4.0 | 3.80 | 19.90 | 29.97 | 1.73 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 2019-05-21 | AK1 | 阿拉斯加 | 4.0 | 3.80 | 19.90 | 29.97 | 1.73 |'
- en: '| **...** | ... | ... | ... | ... | ... | ... | ... | ... |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| **...** | ... | ... | ... | ... | ... | ... | ... | ... |'
- en: '| **12427** | 2019-02-20 | WI6 | North | 15.6 | 25.30 | 1.71 | 65.78 | -4.08
    |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| **12427** | 2019-02-20 | WI6 | 北部 | 15.6 | 25.30 | 1.71 | 65.78 | -4.08 |'
- en: '| **12428** | 2019-03-04 | WI6 | North | 14.0 | 8.21 | -14.38 | 48.21 | -23.02
    |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| **12428** | 2019-03-04 | WI6 | 北部 | 14.0 | 8.21 | -14.38 | 48.21 | -23.02
    |'
- en: '| **12429** | 2019-03-22 | WI6 | North | 5.8 | 9.44 | 5.08 | 52.20 | -4.02
    |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| **12429** | 2019-03-22 | WI6 | 北部 | 5.8 | 9.44 | 5.08 | 52.20 | -4.02 |'
- en: '[PRE85]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'We include an explanation for each of the columns in our dataframe in the following
    table:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在下表中为数据框中的每一列提供解释：
- en: '| Column | Description |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 列名 | 描述 |'
- en: '| --- | --- |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| date | Date of the observation |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| date | 观测日期 |'
- en: '| id | A unique label for a site, formatted as the US state abbreviation with
    a number (we performed data cleaning for site ID `CA1`) |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| id | 一个唯一标识符，格式为带有数字的美国州缩写（我们为站点ID `CA1` 执行了数据清理） |'
- en: '| region | The name of the region, which corresponds to a group of sites (the
    `CA1` site is located in the `West` region) |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| region | 地区的名称，对应一组站点（`CA1`站点位于`西部`地区） |'
- en: '| pm25aqs | The PM2.5 measurement from the AQS sensor |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| pm25aqs | AQS传感器测量的PM2.5 |'
- en: '| pm25pa | The PM2.5 measurement from the PurpleAir sensor |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| pm25pa | 紫外传感器测量的PM2.5 |'
- en: '| temp | Temperature, in Celsius |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| temp | 温度，摄氏度 |'
- en: '| rh | Relative humidity, ranging from 0% to 100% |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| rh | 相对湿度，范围从0%到100% |'
- en: '| dew | The dew point (a higher dew point means more moisture is in the air)
    |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| dew | 露点（较高的露点意味着空气中有更多的湿气） |'
- en: 'Let’s start with making a few simple visualizations to gain insight. Since
    the scope involves measurements over time at particular locations, we can choose
    one location with many measurements and make a line plot of the weekly average
    air quality. To choose, let’s find the sites with many records:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从制作几个简单的可视化图开始获取见解。由于范围涉及特定位置的时间测量，我们可以选择一个有很多测量记录的位置，并制作每周平均空气质量的折线图。首先，让我们找出记录较多的站点：
- en: '[PRE86]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'The location labeled `NC4` has nearly 700 observations. To smooth the line
    plot a bit, let’s plot weekly averages:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 标记为`NC4`的位置有近700次观测记录。为了稍微平滑折线图，让我们制作每周平均值图：
- en: '[PRE88]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '![](assets/leds_12in04.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_12in04.png)'
- en: We see that most PM2.5 values for the AQS sensor (solid line) range between
    5.0 and 15.0 µg m⁻³. The PurpleAir sensor follows the up-and-down pattern of the
    AQS sensor, which is reassuring. But the measurements are consistently higher
    than AQS and, in some cases, quite a bit higher, which tells us that a correction
    might be helpful.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到大多数AQS传感器（实线）测得的PM2.5值介于5.0到15.0 µg m⁻³之间。PurpleAir传感器跟随AQS传感器的上下波动模式，这让人感到安心。但测量值始终高于AQS，并且在某些情况下相当高，这表明可能需要进行修正。
- en: 'Next, let’s consider the distributions of the PM2.5 readings for the two sensors:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们考虑两个传感器PM2.5读数的分布情况：
- en: '[PRE91]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '![](assets/leds_12in05.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_12in05.png)'
- en: 'Both distributions are skewed right, which often happens when there’s a lower
    bound on values (in this case, 0). A better way to compare these two distributions
    is with a quantile–quantile plot (see [Chapter 10](ch10.html#ch-eda)). With a
    q–q plot it can be easier to compare means, spreads, and tails:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个分布都是右偏的，这在值有下限时经常发生（在这种情况下是 0）。比较这两个分布的更好方法是使用量化-量化图（见 [第 10 章](ch10.html#ch-eda)）。使用
    q-q 图可以更容易地比较均值、扩展和尾部。
- en: '[PRE92]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '![](assets/leds_12in06.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_12in06.png)'
- en: The quantile–quantile plot is roughly linear. We overlaid a dashed line with
    a slope of 2.2; it lines up the quantiles well, which indicates the spread of
    the PurpleAir measurements is about twice that of AQS.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 量化-量化图大致是线性的。我们叠加了一个斜率为 2.2 的虚线，它很好地对齐了分位数，这表明 PurpleAir 测量的分布约是 AQS 的两倍。
- en: 'What we can’t see in the q–q plot or the side-by-side histograms is how the
    sensor readings vary together. Let’s look at this next. First, we take a look
    at the distribution of difference between the two readings:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在 q-q 图或并排直方图中看不到的是传感器读数如何一起变化。让我们来看看这个。首先，我们看一下两个读数之间的差异分布：
- en: '[PRE94]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '![](assets/leds_12in07.png)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_12in07.png)'
- en: If the instruments are in perfect agreement, we will see a spike at 0\. If the
    instruments are in agreement and there is a measurement error with no bias, we
    expect to see a distribution centered at 0\. Instead, we see that 90% of the time,
    the PurpleAir measurement is larger than the AQS 24-hour average, and about 25%
    of the time it is more than 10 µg/m³ higher, which is a lot given the AQS averages
    tend to be between 5 µg/m³ and 10 µg/m³.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仪器完全一致，我们会在 0 处看到一个尖峰。如果仪器一致且没有偏差的测量误差，我们期望看到以 0 为中心的分布。然而，我们看到 90% 的时间，PurpleAir
    测量大于 AQS 的 24 小时平均值，大约 25% 的时间高出 10 µg/m³，考虑到 AQS 的平均值通常在 5 µg/m³ 到 10 µg/m³ 之间，这是很多的。
- en: 'A scatterplot can give us additional insight into the relationship between
    the measurements from these two instruments. Since we are interested in finding
    a general relationship, regardless of time and location, we include all of our
    average readings in the plot:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图可以让我们进一步了解这两台仪器的测量之间的关系。由于我们有兴趣找到一个总体关系，不论时间和地点，我们在图中包含所有的平均读数：
- en: '[PRE96]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '![](assets/leds_12in08.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_12in08.png)'
- en: 'While the relationship looks linear, all but a handful of readings are in the
    bottom-left corner of the plot. Let’s remake the scatterplot and zoom in on the
    bulk of the data to get a better look. We also add a smooth curve to the plot
    to help us see the relationship better:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然关系看起来是线性的，但除了少数几个读数外，其余都集中在图的左下角。让我们重新制作散点图并放大数据的大部分，以便更好地观察。我们还向图中添加了一个平滑曲线，以帮助更好地看到关系：
- en: '[PRE97]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '![](assets/leds_12in09.png)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_12in09.png)'
- en: 'The relationship looks roughly linear, but there is a slight bend in the curve
    for small values of AQS. When the air is very clean, the PurpleAir sensor doesn’t
    pick up as much particulate matter and so is more accurate. Also, we can see that
    the curve should go through the point (0, 0). Despite the slight bend in the relationship,
    the linear association (correlation) between these two measurements is high:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 这种关系看起来大致是线性的，但在 AQS 的小值区间中曲线略微弯曲。当空气非常清洁时，PurpleAir 传感器不会检测到太多颗粒物质，因此更准确。此外，我们可以看到曲线应通过点
    (0, 0)。尽管关系中有轻微弯曲，但这两个测量之间的线性关联（相关性）很高：
- en: '[PRE99]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Before starting this analysis, we expected that PurpleAir measurements would
    generally overestimate the PM2.5\. And indeed, this is reflected in the scatterplot,
    but we also see that there appears to be a strong linear relationship between
    the measurements from these two instruments that will be helpful in calibrating
    the PurpleAir sensor.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始这项分析之前，我们预期 PurpleAir 测量通常会高估 PM2.5。事实上，在散点图中反映了这一点，但我们也看到这两台仪器的测量之间似乎有强烈的线性关系，这将有助于校准
    PurpleAir 传感器。
- en: Creating a Model to Correct PurpleAir Measurements
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建校正 PurpleAir 测量的模型
- en: 'Now that we’ve explored the relationship between PM2.5 readings from AQS and
    PurpleAir sensors, we’re ready for the final step of the analysis: creating a
    model that corrects PurpleAir measurements. Barkjohn’s original analysis fits
    many models to the data in order to find the most appropriate one. In this section,
    we fit a simple linear model using the techniques from [Chapter 4](ch04.html#ch-modeling).
    We also briefly describe the final model Barkjohn chose for real-world use. Since
    these models use methods that we introduce later in the book, we won’t explain
    the technical details very deeply here. Instead, we encourage you to revisit this
    section after reading [Chapter 15](ch15.html#ch-linear).'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了AQS和PurpleAir传感器之间PM2.5读数的关系，我们准备进行分析的最后一步：创建一个修正PurpleAir测量的模型。Barkjohn的原始分析对数据拟合了许多模型，以找到最合适的模型。在本节中，我们使用来自[第四章](ch04.html#ch-modeling)的技术来拟合一个简单的线性模型。我们还简要描述了Barkjohn为实际应用选择的最终模型。由于这些模型使用了本书后面介绍的方法，我们不会在这里深入解释技术细节。相反，我们鼓励您在阅读[第十五章](ch15.html#ch-linear)后重新访问本节。
- en: First, let’s go over our modeling goals. We want to create a model that predicts
    PM2.5 as accurately as possible. To do this, we build a model that adjusts PurpleAir
    measurements based on AQS measurements. We treat the AQS measurements as the true
    PM2.5 values because they are taken from carefully calibrated instruments and
    are actively used by the US government for decision making. So we have reason
    to trust the AQS PM2.5 values as being precise and close to the truth.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们总结一下我们的建模目标。我们希望创建一个尽可能准确预测PM2.5的模型。为此，我们建立了一个根据AQS测量调整PurpleAir测量的模型。我们将AQS测量视为真实的PM2.5值，因为它们来自精确校准的仪器，并且被美国政府积极用于决策制定。因此，我们有理由信任AQS
    PM2.5值的精度和接近真实的特性。
- en: After we build the model that adjusts the PurpleAir measurements using AQS,
    we then flip the model around and use it to predict the true air quality in the
    future from PurpleAir measurements when we don’t have a nearby AQS instrument.
    This is a *calibration* scenario. Since the AQS measurements are close to the
    truth, we fit the more variable PurpleAir measurements to them; this is the calibration
    procedure. Then we use the calibration curve to correct future PurpleAir measurements.
    This two-step process is encapsulated in the upcoming simple linear model and
    its flipped form.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们建立了通过AQS调整PurpleAir测量的模型之后，我们将模型反转并使用它来预测未来的真实空气质量，这是一个*校准*场景。由于AQS测量接近真实值，我们将更为变化的PurpleAir测量与之对齐；这就是校准过程。然后我们使用校准曲线来纠正未来的PurpleAir测量。这个两步过程包含在即将介绍的简单线性模型及其反转形式中。
- en: 'First, we fit a line to predict a PurpleAir (PA) measurement from the ground
    truth, as recorded by an AQS instrument:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们拟合一条线来预测从真实数据（由AQS仪器记录）中记录的PurpleAir（PA）测量：
- en: <math display="block"><mtext>PA</mtext> <mo>≈</mo> <mi>b</mi> <mo>+</mo> <mi>m</mi>
    <mtext>AQS</mtext></math>
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtext>PA</mtext> <mo>≈</mo> <mi>b</mi> <mo>+</mo> <mi>m</mi>
    <mtext>AQS</mtext></math>
- en: 'Next, we flip the line around to use a PA measurement to predict the air quality:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将线条反转，使用PA测量来预测空气质量：
- en: <math display="block"><mtext>True air quality</mtext> <mo>≈</mo> <mo>−</mo>
    <mi>b</mi> <mrow><mo>/</mo></mrow> <mi>m</mi> <mo>+</mo> <mn>1</mn> <mrow><mo>/</mo></mrow>
    <mi>m</mi> <mtext>PA</mtext></math>
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtext>True air quality</mtext> <mo>≈</mo> <mo>−</mo>
    <mi>b</mi> <mrow><mo>/</mo></mrow> <mi>m</mi> <mo>+</mo> <mn>1</mn> <mrow><mo>/</mo></mrow>
    <mi>m</mi> <mtext>PA</mtext></math>
- en: The scatterplot and histograms that we made during our exploratory data analysis
    suggest that the PurpleAir measurements are more variable, which supports the
    calibration approach. And we saw that the PurpleAir measurements are about twice
    as high as the AQS measurements, which suggests that <math><mi>m</mi></math> may
    be close to 2 and <math><mn>1</mn> <mrow><mo>/</mo></mrow> <mi>m</mi></math> close
    to <math><mn>1</mn> <mrow><mo>/</mo></mrow> <mn>2</mn></math> .
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的探索性数据分析期间制作的散点图和直方图表明PurpleAir测量更为变化，这支持校准方法。我们发现PurpleAir测量值大约是AQS测量值的两倍，这表明<math><mi>m</mi></math>可能接近2，而<math><mn>1</mn>
    <mrow><mo>/</mo></mrow> <mi>m</mi></math>可能接近<math><mn>1</mn> <mrow><mo>/</mo></mrow>
    <mn>2</mn></math>。
- en: 'Now let’s fit the model. Following the notion from [Chapter 4](ch04.html#ch-modeling),
    we choose a loss function and minimize the average error. Recall that a *loss
    function* measures how far away our model is from the actual data. We use squared
    loss, which in this case is <math><mo stretchy="false">[</mo> <mi>P</mi> <mi>A</mi>
    <mo>−</mo> <mo stretchy="false">(</mo> <mi>b</mi> <mo>+</mo> <mi>m</mi> <mi>A</mi>
    <mi>Q</mi> <mi>S</mi> <mo stretchy="false">)</mo> <msup><mo stretchy="false">]</mo>
    <mn>2</mn></msup></math> . And to fit the model to our data, we minimize the average
    squared loss over our data:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们拟合模型。根据[第4章](ch04.html#ch-modeling)的概念，我们选择一个损失函数并最小化平均误差。回想一下，*损失函数*衡量我们的模型与实际数据的差距。我们使用平方损失，在这种情况下是<math><mo
    stretchy="false">[</mo> <mi>P</mi> <mi>A</mi> <mo>−</mo> <mo stretchy="false">(</mo>
    <mi>b</mi> <mo>+</mo> <mi>m</mi> <mi>A</mi> <mi>Q</mi> <mi>S</mi> <mo stretchy="false">)</mo>
    <msup><mo stretchy="false">]</mo> <mn>2</mn></msup></math> 。为了使模型与我们的数据拟合，我们最小化数据上的平均平方损失：
- en: <math display="block"><mtable columnalign="right" displaystyle="true" rowspacing="3pt"><mtr><mtd><mfrac><mn>1</mn>
    <mi>n</mi></mfrac> <munderover><mo>∑</mo> <mrow><mi>i</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mrow><mi>n</mi></mrow></munderover> <mo stretchy="false">[</mo> <mi>P</mi> <msub><mi>A</mi>
    <mi>i</mi></msub> <mo>−</mo> <mo stretchy="false">(</mo> <mi>b</mi> <mo>+</mo>
    <mi>m</mi> <mi>A</mi> <mi>Q</mi> <msub><mi>S</mi> <mi>i</mi></msub> <msup><mo
    stretchy="false">]</mo> <mn>2</mn></msup></mtd></mtr></mtable></math>
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" displaystyle="true" rowspacing="3pt"><mtr><mtd><mfrac><mn>1</mn>
    <mi>n</mi></mfrac> <munderover><mo>∑</mo> <mrow><mi>i</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mrow><mi>n</mi></mrow></munderover> <mo stretchy="false">[</mo> <mi>P</mi> <msub><mi>A</mi>
    <mi>i</mi></msub> <mo>−</mo> <mo stretchy="false">(</mo> <mi>b</mi> <mo>+</mo>
    <mi>m</mi> <mi>A</mi> <mi>Q</mi> <msub><mi>S</mi> <mi>i</mi></msub> <msup><mo
    stretchy="false">]</mo> <mn>2</mn></msup></mtd></mtr></mtable></math>
- en: 'We use the linear modeling functionality provided by `scikit-learn` to do this
    (again, don’t worry about these details for now):'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`scikit-learn`提供的线性建模功能来做到这一点（现在不必担心这些细节）：
- en: '[PRE101]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'By inverting the line, we get the estimate:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 通过反转线路，我们得到估计：
- en: '[PRE102]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: This is close to what we expected. The adjustment to PurpleAir measurements
    is about <math><mn>1</mn> <mrow><mo>/</mo></mrow> <mn>2</mn></math> .
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 这接近我们的预期。对PurpleAir测量的调整约为<math><mn>1</mn> <mrow><mo>/</mo></mrow> <mn>2</mn></math>
    。
- en: 'The model that Barkjohn settled on incorporated the relative humidity:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: Barkjohn确定的模型包含了相对湿度：
- en: <math display="block"><mtable columnalign="right" displaystyle="true" rowspacing="3pt"><mtr><mtd><mtext>PA</mtext>
    <mo>≈</mo> <mi>b</mi> <mo>+</mo> <msub><mi>m</mi> <mn>1</mn></msub> <mtext>AQS</mtext>
    <mo>+</mo> <msub><mi>m</mi> <mn>2</mn></msub> <mtext>RH</mtext></mtd></mtr></mtable></math>
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" displaystyle="true" rowspacing="3pt"><mtr><mtd><mtext>PA</mtext>
    <mo>≈</mo> <mi>b</mi> <mo>+</mo> <msub><mi>m</mi> <mn>1</mn></msub> <mtext>AQS</mtext>
    <mo>+</mo> <msub><mi>m</mi> <mn>2</mn></msub> <mtext>RH</mtext></mtd></mtr></mtable></math>
- en: 'This is an example of a multivariable linear regression model—it uses more
    than one variable to make predictions. We can fit it by minimizing the average
    squared error over the data:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个多变量线性回归模型的示例—它使用多个变量进行预测。我们可以通过最小化数据上的平均平方误差来拟合它：
- en: <math display="block"><mtable columnalign="right" displaystyle="true" rowspacing="3pt"><mtr><mtd><mfrac><mn>1</mn>
    <mi>n</mi></mfrac> <munderover><mo>∑</mo> <mrow><mi>i</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mrow><mi>n</mi></mrow></munderover> <mo stretchy="false">[</mo> <mi>P</mi> <msub><mi>A</mi>
    <mi>i</mi></msub> <mo>−</mo> <mo stretchy="false">(</mo> <mi>b</mi> <mo>+</mo>
    <msub><mi>m</mi> <mn>1</mn></msub> <mi>A</mi> <mi>Q</mi> <msub><mi>S</mi> <mi>i</mi></msub>
    <mo>+</mo> <msub><mi>m</mi> <mn>2</mn></msub> <mi>R</mi> <msub><mi>H</mi> <mi>i</mi></msub>
    <msup><mo stretchy="false">]</mo> <mn>2</mn></msup></mtd></mtr></mtable></math>
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" displaystyle="true" rowspacing="3pt"><mtr><mtd><mfrac><mn>1</mn>
    <mi>n</mi></mfrac> <munderover><mo>∑</mo> <mrow><mi>i</mi> <mo>=</mo> <mn>1</mn></mrow>
    <mrow><mi>n</mi></mrow></munderover> <mo stretchy="false">[</mo> <mi>P</mi> <msub><mi>A</mi>
    <mi>i</mi></msub> <mo>−</mo> <mo stretchy="false">(</mo> <mi>b</mi> <mo>+</mo>
    <msub><mi>m</mi> <mn>1</mn></msub> <mi>A</mi> <mi>Q</mi> <msub><mi>S</mi> <mi>i</mi></msub>
    <mo>+</mo> <msub><mi>m</mi> <mn>2</mn></msub> <mi>R</mi> <msub><mi>H</mi> <mi>i</mi></msub>
    <msup><mo stretchy="false">]</mo> <mn>2</mn></msup></mtd></mtr></mtable></math>
- en: 'Then we invert the calibration to find the prediction model using the following
    equation:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 接着我们反转校准，使用以下方程找到预测模型：
- en: <math display="block"><mtable columnalign="right left" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtext>True air quality</mtext></mtd> <mtd><mo>≈</mo>
    <mo>−</mo> <mfrac><mi>b</mi> <msub><mi>m</mi> <mn>1</mn></msub></mfrac> <mo>+</mo>
    <mfrac><mn>1</mn> <msub><mi>m</mi> <mn>1</mn></msub></mfrac> <mtext>PA</mtext>
    <mo>−</mo> <mfrac><msub><mi>m</mi> <mn>2</mn></msub> <msub><mi>m</mi> <mn>1</mn></msub></mfrac>
    <mtext>RH</mtext></mtd></mtr></mtable></math>
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right left" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtext>True air quality</mtext></mtd> <mtd><mo>≈</mo>
    <mo>−</mo> <mfrac><mi>b</mi> <msub><mi>m</mi> <mn>1</mn></msub></mfrac> <mo>+</mo>
    <mfrac><mn>1</mn> <msub><mi>m</mi> <mn>1</mn></msub></mfrac> <mtext>PA</mtext>
    <mo>−</mo> <mfrac><msub><mi>m</mi> <mn>2</mn></msub> <msub><mi>m</mi> <mn>1</mn></msub></mfrac>
    <mtext>RH</mtext></mtd></mtr></mtable></math>
- en: 'We fit this model and check the coefficients:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拟合这个模型并检查系数：
- en: '[PRE104]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: In Chapters [15](ch15.html#ch-linear) and [16](ch16.html#ch-risk), we will learn
    how to compare these two models by examining things like the size of and patterns
    in prediction errors. For now, we note that the model that incorporates relative
    humidity performs the best.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[15](ch15.html#ch-linear)和[16](ch16.html#ch-risk)章中，我们将学习如何通过检查预测误差的大小和模式等因素来比较这两个模型。目前，我们注意到包含相对湿度的模型表现最佳。
- en: Summary
  id: totrans-350
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we replicated Barkjohn’s analysis. We created a model that
    corrects PurpleAir measurements so that they closely match AQS measurements. The
    accuracy of this model enables the PurpleAir sensors to be included on official
    US government maps, like the AirNow Fire and Smoke map. Importantly, this model
    gives people timely *and* accurate measurements of air quality.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们复制了Barkjohn的分析。我们创建了一个模型，校正PurpleAir测量，使其与AQS测量接近。这个模型的准确性使得PurpleAir传感器可以包含在官方的美国政府地图上，比如AirNow
    Fire and Smoke地图。重要的是，这个模型提供了及时的*和*准确的空气质量测量。
- en: We saw how crowdsourced, open data can be improved with data from precise, rigorously
    maintained, government-monitored equipment. In the process, we focused on cleaning
    and merging data from multiple sources, but we also fit models to adjust and improve
    air quality measurements.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到众包开放数据如何通过来自精确、严格维护、政府监控设备的数据进行改进。在这个过程中，我们专注于清理和合并来自多个来源的数据，但我们也适合模型以调整和改进空气质量测量。
- en: For this case study, we applied many concepts covered in this part of the book.
    As you saw, wrangling files and data tables into a form we can analyze is a large
    and important part of data science. We used file wrangling and the notions of
    granularity from [Chapter 8](ch08.html#ch-files) to prepare two sources for merging.
    We got them into structures where we could match neighboring air quality sensors.
    This “grungy” part of data science was essential to widening the reach of data
    from rigorously maintained, precise government-monitored equipment by augmenting
    it with crowdsourced, open data.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个案例研究，我们应用了本书的这一部分涵盖的许多概念。正如您所见，整理文件和数据表以便分析是数据科学中的一个重要部分。我们使用文件整理和来自[第8章](ch08.html#ch-files)的粒度概念来准备两个来源以进行合并。我们将它们组织成结构，以便匹配相邻的空气质量传感器。数据科学中的这个“肮脏”部分对于通过增加众包开放数据来扩展严格维护的精确政府监控设备的数据的覆盖范围至关重要。
- en: This preparation process involved intensive, careful examination, cleaning,
    and improvement of the data to ensure their compatibility across the two sources
    and their trustworthiness in our analysis. Concepts from [Chapter 9](ch09.html#ch-wrangling)
    helped us work with time data effectively and find and correct numerous issues
    like missing data points and even duplicated data values.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 这个准备过程涉及了对数据的深入、仔细的检查、清理和改进，以确保它们在两个来源之间的兼容性和在我们的分析中的可信度。来自[第 9 章](ch09.html#ch-wrangling)的概念帮助我们有效地处理时间数据，并找到和修正了许多问题，如缺失数据点甚至是重复的数据值。
- en: File and data wrangling, exploratory data analysis, and visualization are major
    parts of many analyses. While fitting models may seem to be the most exciting
    part of data science, getting to know and trust the data is crucial and often
    leads to important insights in the modeling phase. Topics related to modeling
    make up most of the rest of this book. However, before we begin, we cover two
    more topics related to data wrangling. In the next chapter, we show how to create
    analyzable data from text, and in the following chapter we examine other formats
    for source files that we mentioned in [Chapter 8](ch08.html#ch-files).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 文件和数据整理、探索性数据分析以及可视化是许多分析工作的重要组成部分。虽然拟合模型可能看起来是数据科学中最激动人心的部分，但了解和信任数据是至关重要的，通常会在建模阶段带来重要的见解。与建模相关的主题占据了本书其余大部分内容。然而，在我们开始之前，我们会涵盖与数据整理相关的另外两个主题。在下一章中，我们将展示如何从文本创建可分析的数据，而在接下来的一章中，我们将研究我们在[第
    8 章](ch08.html#ch-files)中提到的其他源文件格式。
- en: Before you head to the next chapter, take stock of what you’ve learned so far.
    Pat yourself on the back—you’ve already come a long way! The principles and techniques
    we’ve covered here are useful for nearly every type of data analysis, and you
    can readily start applying them toward analyses of your own.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 在你进入下一章之前，回顾一下你到目前为止学到的内容。对自己的成就感到自豪——你已经走了很长的一段路！我们在这里涵盖的原则和技术对几乎每一种数据分析都很有用，你可以立即开始将它们应用到你自己的分析中。
- en: ^([1](ch12.html#id1449-marker)) This estimation works by assuming that the Earth
    is perfectly spherical. Then, one degree of latitude is the radius of the Earth
    in meters. Plugging in the average radius of the Earth gives 111,111 meters per
    degree of latitude. Longitude is the same, but the radius of each “ring” around
    the Earth decreases as we get closer to the poles, so we adjust by a factor of
    <math><mrow><mo form="prefix">cos</mo> <mo>(</mo> <mtext>lat</mtext> <mo>)</mo></mrow></math>
    . It turns out that the Earth isn’t perfectly spherical, so these estimations
    can’t be used for precise calculations, like landing a rocket. But for our purposes,
    they do just fine.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch12.html#id1449-marker)) 这种估算是基于假设地球是完美的球体。然后，一度纬度是地球的半径（以米为单位）。插入地球的平均半径后，得到每度纬度
    111,111 米。经度也是一样的，但是每个“环”围绕地球的半径随着接近极点而减小，所以我们通过一个<math><mrow><mo form="prefix">cos</mo>
    <mo>(</mo> <mtext>lat</mtext> <mo>)</mo></mrow></math> 因子进行调整。事实证明地球并不是完美的球体，所以这些估算不能用于像着陆火箭这样精确计算的目的。但对于我们的目的来说，它们表现得相当好。
