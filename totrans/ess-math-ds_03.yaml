- en: Chapter 3\. Descriptive and Inferential Statistics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章。描述性和推断性统计
- en: '*Statistics* is the practice of collecting and analyzing data to discover findings
    that are useful or predict what causes those findings to happen. Probability often
    plays a large role in statistics, as we use data to estimate how likely an event
    is to happen.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*统计学*是收集和分析数据以发现有用发现或预测导致这些发现发生的原因的实践。概率在统计学中经常起着重要作用，因为我们使用数据来估计事件发生的可能性。'
- en: It may not always get credit, but statistics is the heart of many data-driven
    innovations. Machine learning in itself is a statistical tool, searching for possible
    hypotheses to correlate relationships between different variables in data. However
    there are a lot of blind sides in statistics, even for professional statisticians.
    We can easily get caught up in what the data says that we forget to ask where
    the data comes from. These concerns become all the more important as big data,
    data mining, and machine learning all accelerate the automation of statistical
    algorithms. Therefore, it is important to have a solid foundation in statistics
    and hypothesis testing so you do not treat these automations as black boxes.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学可能并不总是受到赞誉，但它是许多数据驱动创新的核心。机器学习本身就是一种统计工具，寻找可能的假设来相关不同变量之间的关系。然而，即使对于专业统计学家来说，统计学也存在许多盲点。我们很容易陷入数据所说的内容，而忘记了要问数据来自何处。随着大数据、数据挖掘和机器学习加速推动统计算法的自动化，这些问题变得更加重要。因此，拥有扎实的统计学和假设检验基础非常重要，这样你就不会把这些自动化处理当作黑匣子。
- en: In this section we will cover the fundamentals of statistics and hypothesis
    testing. Starting with descriptive statistics, we will learn common ways to summarize
    data. After that, we will venture into inferential statistics, where we try to
    uncover attributes of a population based on a sample.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍统计学和假设检验的基础知识。从描述性统计开始，我们将学习总结数据的常见方法。之后，我们将进入推断统计，试图根据样本揭示总体属性。
- en: What Is Data?
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是数据？
- en: It may seem odd to define “data,” something we all use and take for granted.
    But I think it needs to be done. Chances are if you asked any person what data
    is, they might answer to the effect of “you know…data! It’s…you know…information!”
    and not venture farther than that. Now it seems to be marketed as the be-all and
    end-all. The source of not just truth…but intelligence! It’s the fuel for artificial
    intelligence and it is believed that the more data you have, the more truth you
    have. Therefore, you can never have enough data. It will unlock the secrets needed
    to redefine your business strategy and maybe even create artificial general intelligence.
    But let me offer a pragmatic perspective on what data is. Data is not important
    in itself. It’s the analysis of data (and how it is produced) that is the driver
    of all these innovations and solutions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 定义“数据”可能看起来有些奇怪，因为我们都使用并认为理所当然。但我认为有必要这样做。如果你问任何人数据是什么，他们可能会回答类似于“你知道的...数据！就是...你知道的...信息！”而不会深入探讨。现在它似乎被宣传为至关重要的事物。不仅是真相的来源...还有智慧！这是人工智能的燃料，人们相信你拥有的数据越多，你就拥有的真相就越多。因此，你永远不可能拥有足够的数据。它将揭示重新定义你的业务策略所需的秘密，甚至可能创造人工通用智能。但让我提供一个关于数据是什么的实用观点。数据本身并不重要。数据的分析（以及它是如何产生的）是所有这些创新和解决方案的驱动力。
- en: Imagine you were provided a photo of a family. Can you glean this family’s story
    based on this one photo? What if you had 20 photos? 200 photos? 2,000 photos?
    How many photos do you need to know their story? Do you need photos of them in
    different situations? Alone and together? With relatives and friends? At home
    and at work?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果你拿到一张一个家庭的照片。你能根据这张照片揭示这个家庭的故事吗？如果你有20张照片呢？200张照片？2,000张照片？你需要多少张照片才能了解他们的故事？你需要他们在不同情况下的照片吗？一个人和一起的照片？和亲戚朋友在一起的照片？在家里和工作中的照片？
- en: '*Data* is just like photographs; it provides snapshots of a story. The continuous
    reality and contexts are not fully captured, nor the infinite number of variables
    driving that story. As we will discuss, data may be biased. It can have gaps and
    be missing relevant variables. Ideally, we would love to have an infinite amount
    of data capturing an infinite number of variables, with so much detail we could
    virtually re-create reality and construct alternate ones! But is this possible?
    Currently, no. Not even the greatest supercomputers in the world combined can
    come close to capturing the entirety of the world as data.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据*就像照片一样；它提供了故事的快照。连续的现实和背景并没有完全捕捉到，也没有驱动这个故事的无限数量的变量。正如我们将讨论的，数据可能存在偏见。它可能存在缺口，缺少相关变量。理想情况下，我们希望有无限量的数据捕捉无限数量的变量，有如此之多的细节，我们几乎可以重新创造现实并构建替代现实！但这可能吗？目前，不可能。即使将全球最强大的超级计算机组合在一起，也无法接近以数据形式捕捉整个世界的全部内容。'
- en: Therefore, we have to narrow our scope to make our objectives feasible. A few
    strategic photos of the father playing golf can easily tell us whether he is good
    at golf. But trying to decipher his entire life story just through photos? That
    might be impossible. There is so much that cannot be captured in snapshots. These
    practical concerns should also be applied when working with data projects, because
    data is actually just snapshots of a given time capturing only what it is aimed
    at (much like a camera). We need to keep our objectives focused as this hones
    in on gathering data that is relevant and complete. If we make our objectives
    broad and open-ended, we can get into trouble with spurious findings and incomplete
    datasets. This practice, known as *data mining*, has a time and place but it must
    be done carefully. We will revisit this at the end of the chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们必须缩小范围，使我们的目标变得可行。父亲打高尔夫球的几张战略照片可以很容易地告诉我们他是否擅长高尔夫。但是仅凭照片来解读他的整个人生故事？那可能是不可能的。有很多东西是无法在快照中捕捉到的。这些实际问题也应该在处理数据项目时应用，因为数据实际上只是捕捉特定时间的快照，只捕捉到了它所针对的内容（就像相机一样）。我们需要保持我们的目标集中，这有助于收集相关和完整的数据。如果我们的目标过于宽泛和开放，我们可能会遇到虚假发现和不完整数据集的问题。这种实践，被称为*数据挖掘*，有其时机和地点，但必须小心进行。我们将在本章末重新讨论这个问题。
- en: Even with narrowly defined objectives, we can still run into problems with our
    data. Let’s return to the question of determining whether a few strategic photos
    can tell whether the father is good at golf. Perhaps if you had a photo of him
    midswing you would be able to tell if he had good form. Or perhaps if you saw
    him cheering and fist-pumping at a hole, you can infer he got a good score. Maybe
    you can just take a photo of his scorecard! But it’s important to note all these
    instances can be faked or taken out of context. Maybe he was cheering for someone
    else, or maybe the scorecard was not his or even forged. Just like these photographs,
    data does not capture context or explanations. This is an incredibly important
    point because data provides clues, not truth. These clues can lead us to the truth
    or mislead us into erroneous conclusions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 即使目标明确，我们仍然可能在数据方面遇到问题。让我们回到确定几张战略照片是否能告诉我们父亲是否擅长高尔夫的问题。也许如果你有一张他挥杆中的照片，你就能看出他的动作是否正确。或者也许如果你看到他在一个洞位上欢呼和击掌，你可以推断他得了一个好成绩。也许你只需拍一张他的记分卡的照片！但重要的是要注意所有这些情况都可能是伪造的或脱离了上下文。也许他在为别人欢呼，或者记分卡不是他的，甚至是伪造的。就像这些照片一样，数据并不能捕捉到背景或解释。这是一个非常重要的观点，因为数据提供线索，而不是真相。这些线索可以引导我们找到真相，也可能误导我们得出错误的结论。
- en: This is why being curious about where data comes from is such an important skill.
    Ask questions about how the data was created, who created it, and what the data
    is not capturing. It is too easy to get caught up in what the data says and forget
    to ask where it came from. Even worse there are widespread sentiments that one
    can shovel data into machine learning algorithms and expect the computer to work
    it all out. But as the adage goes, “garbage in, garbage out.” No wonder only [13%
    of machine learning projects succeed, according to VentureBeat](https://oreil.ly/8hFrO).
    Successful machine learning projects put thought and analysis into the data, as
    well as what produced the data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么对数据来源感到好奇是如此重要的技能。询问数据是如何创建的，由谁创建的，以及数据未捕捉到什么。很容易陷入数据所说的内容而忘记询问数据来自何处。更糟糕的是，有广泛的观点认为可以将数据填入机器学习算法中，并期望计算机解决所有问题。但正如谚语所说，“垃圾进，垃圾出”。难怪根据VentureBeat的数据，只有[13%的机器学习项目成功](https://oreil.ly/8hFrO)。成功的机器学习项目对数据进行了思考和分析，以及产生数据的过程。
- en: Descriptive Versus Inferential Statistics
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 描述性统计与推断性统计
- en: What comes to mind when you hear the word “statistics”? Is it calculating mean,
    median, mode, charts, bell curves, and other tools to describe data? This is the
    most commonly understood part of statistics, called *descriptive statistics*,
    and we use it to summarize data. After all, is it more meaningful to scroll through
    a million records of data or have it summarized? We will cover this area of statistics
    first.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当你听到“统计学”这个词时，你会想到什么？是计算平均值、中位数、众数、图表、钟形曲线和其他用于描述数据的工具吗？这是统计学最常被理解的部分，称为*描述性统计*，我们用它来总结数据。毕竟，浏览百万条数据记录还是对其进行总结更有意义？我们将首先涵盖统计学的这一领域。
- en: '*Inferential statistics* tries to uncover attributes about a larger population,
    often based on a sample. It is often misunderstood and less intuitive than descriptive
    statistics. Often we are interested in studying a group that is too large to observe
    (e.g., average height of adolescents in North America) and we have to resort to
    using only a few members of that group to infer conclusions about them. As you
    can guess, this is not easy to get right. After all, we are trying to represent
    a population with a sample that may not be representative. We will explore these
    caveats along the way.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*推断性统计*试图揭示关于更大总体的属性，通常基于样本。它经常被误解，比描述性统计更难理解。通常我们对研究一个太大以至无法观察的群体感兴趣（例如，北美地区青少年的平均身高），我们必须仅使用该群体的少数成员来推断关于他们的结论。正如你所猜测的那样，这并不容易做到。毕竟，我们试图用一个可能不具代表性的样本来代表一个总体。我们将在探讨过程中探讨这些警告。'
- en: Populations, Samples, and Bias
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总体、样本和偏差
- en: Before we dive deeper into descriptive and inferential statistics, it might
    be a good idea to lay out some definitions and relate them to tangible examples.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入研究描述性和推断性统计之前，将一些定义和与之相关的具体示例联系起来可能是一个好主意。
- en: A *population* is a particular group of interest we want to study, such as “all
    seniors over the age of 65 in the North America,” “all golden retrievers in Scotland,”
    or “current high school sophomores at Los Altos High School.” Notice how we have
    boundaries on defining our population. Some of these boundaries are broad and
    capture a large group over a vast geography or age group. Others are highly specific
    and small such as the sophomores at Los Altos High School. How you hone in on
    defining a population depends on what you are interested in studying.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*总体*是我们想要研究的特定感兴趣的群体，比如“北美地区所有65岁以上的老年人”，“苏格兰所有金毛猎犬”，或者“洛斯阿尔托斯高中目前的高中二年级学生”。请注意我们对定义总体的边界。有些边界很宽泛，涵盖了广阔地理区域或年龄组的大群体。其他则非常具体和小，比如洛斯阿尔托斯高中的高中二年级学生。如何确定总体的定义取决于你对研究感兴趣的内容。'
- en: A *sample* is a subset of the population that is ideally random and unbiased,
    which we use to infer attributes about the population. We often have to study
    samples because polling the entire population is not always possible. Of course,
    some populations are easier to get hold of if they are small and accessible. But
    measuring all seniors over 65 in North America? That is unlikely to be practical!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*样本*是总体的一个理想随机和无偏子集，我们用它来推断总体的属性。我们经常不得不研究样本，因为调查整个总体并不总是可能的。当然，如果人口小且易接触，那么获取一些人口是更容易的。但是测量北美地区所有65岁以上的老年人？那不太可能实际可行！'
- en: Populations Can Be Abstract!
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总体可以是抽象的！
- en: 'It is important to note that populations can be theoretical and not physically
    tangible. In these cases our population acts more like a sample from something
    abstract. Here’s my favorite example: we are interested in flights that depart
    between 2 p.m. and 3 p.m. at an airport, but we lack enough flights at that time
    to reliably predict how often these flights are late. Therefore, we may treat
    this population as a sample instead from an underlying population of all theoretical
    flights taking off between 2 p.m. and 3 p.m.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，人口可以是理论的，而不是实际可触及的。在这些情况下，我们的人口更像是从抽象事物中抽取的样本。这里是我最喜欢的例子：我们对一个机场在下午2点到3点之间起飞的航班感兴趣，但在那个时间段内的航班数量不足以可靠地预测这些航班的延误情况。因此，我们可能将这个人口视为从所有在下午2点到3点之间起飞的理论航班中抽取的样本。
- en: Problems like this are why many researchers resort to simulations to generate
    data. Simulations can be useful but rarely are accurate, as simulations capture
    only so many variables and have assumptions built in.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这类问题是为什么许多研究人员借助模拟生成数据的原因。模拟可能是有用的，但很少是准确的，因为模拟只捕捉了有限的变量，并且内置了假设。
- en: If we are going to infer attributes about a population based on a sample, it’s
    important the sample be as random as possible so we do not skew our conclusions.
    Here’s an example. Let’s say I’m a college student at Arizona State University.
    I want to find the average number of hours college students watch television per
    week in the United States. I walk right outside my dorm and start polling random
    students walking by, finishing my data gathering in a few hours. What’s the problem
    here?
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要根据样本推断人口的属性，那么样本尽可能随机是很重要的，这样我们才不会扭曲我们的结论。这里举个例子。假设我是亚利桑那州立大学的一名大学生。我想找出美国大学生每周观看电视的平均小时数。我走出宿舍，开始随机询问路过的学生，几个小时后完成了数据收集。问题在哪里？
- en: The problem is our student sample is going to have *bias*, meaning it skews
    our findings by overrepresenting a certain group at the expense of other groups.
    My study defined the population to be “college students in the United States,”
    not “college students at Arizona State University.” I am only polling students
    at one specific university to represent all college students in the entire United
    States! Is that really fair?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于我们的学生样本可能存在*偏见*，这意味着它通过过度代表某一群体而牺牲其他群体来扭曲我们的发现。我的研究将人口定义为“美国的大学生”，而不是“亚利桑那州立大学的大学生”。我只是在一个特定大学对学生进行调查，代表整个美国的所有大学生！这真的公平吗？
- en: It is unlikely all colleges across the country homogeneously have the same student
    attributes. What if Arizona State students watch far more TV than other students
    at other universities? Would using them to represent the entire country not distort
    the results? Maybe this is possible because it is usually too hot to go outside
    in Tempe, Arizona. Therefore TV is a common pastime (anecdotally, I would know;
    I lived in Phoenix for many years). Other college students in milder climates
    may do more outdoor activities and watch less TV.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 不太可能全国各地的大学都具有相同的学生属性。如果亚利桑那州立大学的学生比其他大学的学生观看电视时间更长怎么办？使用他们来代表整个国家难道不会扭曲结果吗？也许这是可能的，因为在亚利桑那州的坦佩市通常太热了，所以看电视是一种常见的消遣（据说，我会知道；我在凤凰城住了很多年）。其他气候较温和的地方的大学生可能会进行更多的户外活动，看电视时间更少。
- en: This is just one possible variable showing why it’s a bad idea to represent
    college students across the entire United States with just a sample of students
    from one university. Ideally, I should be randomly polling college students all
    over the country at different universities. That way I have a more representative
    sample.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个可能的变量，说明用一个大学的学生样本来代表整个美国的大学生是一个不好的主意。理想情况下，我应该随机调查全国各地不同大学的大学生。这样我就有了更具代表性的样本。
- en: However, bias is not always geographic. Let’s say I make a sincere effort to
    poll students across the United States. I arrange a social media campaign to have
    a poll shared by various universities on Twitter and Facebook. This way their
    students see it and hopefully fill it out. I get hundreds of responses on students’
    TV habits across the country and feel I’ve conquered the bias beast…or have I?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，偏见并不总是地理性的。假设我竭尽全力在全美各地调查学生。我策划了一个社交媒体活动，在Twitter和Facebook上让各大学分享调查，这样他们的学生就会看到并填写。我收到了数百份关于全国学生电视习惯的回复，觉得我已经征服了偏见的野兽...或者我真的做到了吗？
- en: What if students who are on social media enough to see the poll are also likely
    to watch more TV? If they are on social media a lot, they probably do not mind
    recreational screen time. It’s easy to imagine they have Netflix and Hulu ready
    to stream on that other tab! This particular type of bias where a specific group
    is more likely to include themselves in a sample is known as *self-selection bias*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果那些足够在社交媒体上看到投票的学生也更有可能看更多电视呢？如果他们在社交媒体上花很多时间，他们可能不介意娱乐性的屏幕时间。很容易想象他们已经准备好在另一个标签上流媒体Netflix和Hulu！这种特定类型的偏见，即特定群体更有可能加入样本的偏见，被称为*自我选择偏差*。
- en: Darn it! You just can’t win, can you? If you think about it long enough, data
    bias just feels inevitable! And often it is. So many *confounding variables*,
    or factors we did not account for, can influence our study. This problem of data
    bias is expensive and difficult to overcome, and machine learning is especially
    vulnerable to it.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 糟糕！你就是赢不了，是吗？如果你足够长时间地考虑，数据偏差似乎是不可避免的！而且通常确实如此。许多*混杂变量*，或者我们没有考虑到的因素，都会影响我们的研究。数据偏差问题昂贵且难以克服，而机器学习尤其容易受到影响。
- en: The way to overcome this problem is to truly at random select students from
    the entire population, and they cannot elect themselves into or out of the sample
    voluntarily. This is the most effective way to mitigate bias, but as you can imagine,
    it takes a lot of coordinated resources to do.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 克服这个问题的方法是真正随机地从整个人口中选择学生，他们不能自愿地加入或退出样本。这是减轻偏见的最有效方法，但正如你所想象的那样，这需要大量协调的资源。
- en: Alright, enough talk about populations, samples, and bias. Let’s move on to
    some math and descriptive statistics. Just remember that math and computers do
    not recognize bias in your data. That is on you as a good data science professional
    to detect! Always ask questions about how the data was obtained, and then scrutinize
    how that process could have biased the data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，关于人口、样本和偏差的讨论就到此为止。让我们继续进行一些数学和描述性统计。只要记住，数学和计算机不会意识到数据中的偏差。这取决于你作为一名优秀的数据科学专业人员来检测！始终要问关于数据获取方式的问题，然后仔细审查该过程可能如何使数据产生偏差。
- en: Samples and Bias in Machine Learning
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的样本和偏差
- en: These problems with sampling and bias extends to machine learning as well. Whether
    it is linear regression, logistic regression, or neural networks, a sample of
    data is used to infer predictions. If that data is biased then it will steer the
    machine learning algorithm to make biased conclusions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些与抽样和偏差有关的问题也延伸到机器学习领域。无论是线性回归、逻辑回归还是神经网络，都会使用数据样本来推断预测。如果数据存在偏差，那么它将引导机器学习算法做出有偏见的结论。
- en: There are many documented cases of this. Criminal justice has been a precarious
    application of machine learning because it has repeatedly shown to be biased in
    every sense of the word, discriminating against minorities due to minority-heavy
    datasets. In 2017, Volvo tested self-driving cars that were trained on datasets
    capturing deer, elk, and caribou. However, it had no driving data in Australia
    and therefore could not recognize kangaroos, much less make sense of their jumping
    movements! Both of these are examples of biased data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这方面有许多记录的案例。刑事司法一直是机器学习的一个棘手应用，因为它一再显示出在每个意义上都存在偏见，由于数据集中存在少数族群，导致对少数族群进行歧视。2017年，沃尔沃测试了训练过捕捉鹿、麋鹿和驯鹿数据集的自动驾驶汽车。然而，它在澳大利亚没有驾驶数据，因此无法识别袋鼠，更不用说理解它们的跳跃动作了！这两个都是有偏见数据的例子。
- en: Descriptive Statistics
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 描述性统计
- en: Descriptive statistics is the area most people are familiar with. We will touch
    on the basics like mean, median, and mode followed by variance, standard deviation,
    and the normal distribution.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 描述性统计是大多数人熟悉的领域。我们将介绍一些基础知识，如均值、中位数和众数，然后是方差、标准差和正态分布。
- en: Mean and Weighted Mean
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 均值和加权均值
- en: 'The *mean* is the average of a set of values. The operation is simple to do:
    sum the values and divide by the number of values. The mean is useful because
    it shows where the “center of gravity” exists for an observed set of values.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*均值*是一组值的平均值。这个操作很简单：将值相加，然后除以值的数量。均值很有用，因为它显示了观察到的一组值的“重心”在哪里。'
- en: The mean is calculated the same way for both populations and samples. [Example 3-1](#sOAVldvmng)
    shows a sample of eight values and how to calculate their mean in Python.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 均值的计算方式对于人口和样本是相同的。[示例 3-1](#sOAVldvmng)展示了八个值的样本以及如何在Python中计算它们的均值。
- en: Example 3-1\. Calculating mean in Python
  id: totrans-38
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-1\. 在Python中计算均值
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, we polled eight people on the number of pets they own. The sum
    of the sample is 23 and the number of items in the sample is 8, so this gives
    us a mean of 2.875 as 23/8 = 2.875.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们对八个人关于他们拥有的宠物数量进行了调查。样本的总和为23，样本中的项目数为8，因此这给我们一个均值为2.875，因为23/8 =
    2.875。
- en: 'There are two versions of the mean you will see: the sample mean <math alttext="x
    overbar"><mover><mi>x</mi> <mo>¯</mo></mover></math> and the population mean <math
    alttext="mu"><mi>μ</mi></math> as expressed here:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到两个版本的均值：样本均值<math alttext="x overbar"><mover><mi>x</mi> <mo>¯</mo></mover></math>和总体均值<math
    alttext="mu"><mi>μ</mi></math>如此表达：
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover><mi>x</mi>
    <mo>¯</mo></mover> <mo>=</mo> <mfrac><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo><msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo><msub><mi>x</mi> <mn>3</mn></msub>
    <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msub><mi>x</mi> <mi>n</mi></msub></mrow>
    <mi>n</mi></mfrac> <mo>=</mo> <munderover><mo>∑</mo></munderover> <mfrac><msub><mi>x</mi>
    <mi>i</mi></msub> <mi>n</mi></mfrac></mrow></mtd></mtr></mtable></math> <math
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>μ</mi>
    <mo>=</mo> <mfrac><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>+</mo><msub><mi>x</mi> <mn>3</mn></msub> <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msub><mi>x</mi>
    <mi>n</mi></msub></mrow> <mi>N</mi></mfrac> <mo>=</mo> <munderover><mo>∑</mo></munderover>
    <mfrac><msub><mi>x</mi> <mi>i</mi></msub> <mi>N</mi></mfrac></mrow></mtd></mtr></mtable></math>
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover><mi>x</mi>
    <mo>¯</mo></mover> <mo>=</mo> <mfrac><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo><msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo><msub><mi>x</mi> <mn>3</mn></msub>
    <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msub><mi>x</mi> <mi>n</mi></msub></mrow>
    <mi>n</mi></mfrac> <mo>=</mo> <munderover><mo>∑</mo></munderover> <mfrac><msub><mi>x</mi>
    <mi>i</mi></msub> <mi>n</mi></mfrac></mrow></mtd></mtr></mtable></math> <math
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>μ</mi>
    <mo>=</mo> <mfrac><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>+</mo><msub><mi>x</mi> <mn>3</mn></msub> <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msub><mi>x</mi>
    <mi>n</mi></msub></mrow> <mi>N</mi></mfrac> <mo>=</mo> <munderover><mo>∑</mo></munderover>
    <mfrac><msub><mi>x</mi> <mi>i</mi></msub> <mi>N</mi></mfrac></mrow></mtd></mtr></mtable></math>
- en: 'Recall the summation symbol <math alttext="sigma-summation"><mo>∑</mo></math>
    means add all the items together. The *n* and the *N* represent the sample and
    population size, respectively, but mathematically they represent the same thing:
    the number of items. The same goes for calling the sample mean <math alttext="x
    overbar"><mover><mi>x</mi> <mo>¯</mo></mover></math> (“x-bar”) and the population
    mean <math alttext="mu"><mi>μ</mi></math> (“mu”). Both <math alttext="x overbar"><mover><mi>x</mi>
    <mo>¯</mo></mover></math> and <math alttext="mu"><mi>μ</mi></math> are the same
    calculation, just different names depending on whether it’s a sample or population
    we are working with.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下求和符号<math alttext="sigma-summation"><mo>∑</mo></math>表示将所有项目相加。*n*和*N*分别代表样本和总体大小，但在数学上它们表示相同的东西：项目的数量。对于称为样本均值<math
    alttext="x overbar"><mover><mi>x</mi> <mo>¯</mo></mover></math>（“x-bar”）和总体均值<math
    alttext="mu"><mi>μ</mi></math>（“mu”）的命名也是如此。无论是<math alttext="x overbar"><mover><mi>x</mi>
    <mo>¯</mo></mover></math>还是<math alttext="mu"><mi>μ</mi></math>都是相同的计算，只是根据我们处理的是样本还是总体而有不同的名称。
- en: 'The mean is likely familiar to you, but here’s something less known about the
    mean: the mean is actually a weighted average called the *weighted mean*. The
    mean we commonly use gives equal importance to each value. But we can manipulate
    the mean and give each item a different weight:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 均值可能对你来说很熟悉，但关于均值有一些不太为人知的东西：均值实际上是一种称为*加权均值*的加权平均值。我们通常使用的均值给予每个值相同的重要性。但我们可以操纵均值，给每个项目赋予不同的权重：
- en: <math alttext="weighted mean equals StartFraction left-parenthesis x 1 dot w
    1 right-parenthesis plus left-parenthesis x 2 dot w 2 right-parenthesis plus left-parenthesis
    x 3 dot w 3 right-parenthesis plus period period period left-parenthesis x Subscript
    n Baseline dot w Subscript n Baseline right-parenthesis Over w 1 plus w 2 plus
    w 3 plus period period period plus w Subscript n Baseline EndFraction" display="block"><mrow><mtext>weighted</mtext>
    <mtext>mean</mtext> <mo>=</mo> <mfrac><mrow><mrow><mo>(</mo><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>·</mo><msub><mi>w</mi> <mn>1</mn></msub> <mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>·</mo><msub><mi>w</mi> <mn>2</mn></msub> <mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>3</mn></msub> <mo>·</mo><msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow><mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>n</mi></msub> <mo>·</mo><msub><mi>w</mi> <mi>n</mi></msub> <mo>)</mo></mrow></mrow>
    <mrow><msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo><msub><mi>w</mi> <mn>2</mn></msub>
    <mo>+</mo><msub><mi>w</mi> <mn>3</mn></msub> <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msub><mi>w</mi>
    <mi>n</mi></msub></mrow></mfrac></mrow></math>
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="weighted mean equals StartFraction left-parenthesis x 1 dot w
    1 right-parenthesis plus left-parenthesis x 2 dot w 2 right-parenthesis plus left-parenthesis
    x 3 dot w 3 right-parenthesis plus period period period left-parenthesis x Subscript
    n Baseline dot w Subscript n Baseline right-parenthesis Over w 1 plus w 2 plus
    w 3 plus period period period plus w Subscript n Baseline EndFraction" display="block"><mrow><mtext>weighted</mtext>
    <mtext>mean</mtext> <mo>=</mo> <mfrac><mrow><mrow><mo>(</mo><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>·</mo><msub><mi>w</mi> <mn>1</mn></msub> <mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>·</mo><msub><mi>w</mi> <mn>2</mn></msub> <mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>3</mn></msub> <mo>·</mo><msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow><mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>n</mi></msub> <mo>·</mo><msub><mi>w</mi> <mi>n</mi></msub> <mo>)</mo></mrow></mrow>
    <mrow><msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo><msub><mi>w</mi> <mn>2</mn></msub>
    <mo>+</mo><msub><mi>w</mi> <mn>3</mn></msub> <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msub><mi>w</mi>
    <mi>n</mi></msub></mrow></mfrac></mrow></math>
- en: This can be helpful when we want some values to contribute to the mean more
    than others. A common example of this is weighting academic exams to give a final
    grade. If you have three exams and a final exam, and we give each of the three
    exams 20% weight and the final exam 40% weight of the final grade, how we express
    it is in [Example 3-2](#lquLdtDTuF).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望某些值对均值的贡献大于其他值时，这将会很有帮助。一个常见的例子是对学术考试进行加权以得出最终成绩。如果你有三次考试和一次期末考试，我们给予每次考试20%的权重，期末考试40%的权重，我们如何表达它在[示例
    3-2](#lquLdtDTuF)中。
- en: Example 3-2\. Calculating a weighted mean in Python
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-2. 在Python中计算加权均值
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We weight each exam score through multiplication accordingly and instead of
    dividing by the value count, we divide by the sum of weights. Weightings don’t
    have to be percentages, as any numbers used for weights will end up being proportionalized.
    In [Example 3-3](#TbhpvAuILG), we weight each exam with “1” but weight the final
    exam with “2,” giving it twice the weight of the exams. We will still get the
    same answer of 81.4 as these values will still be proportionalized.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过相应的乘法对每个考试分数进行加权，而不是通过值计数进行除法，而是通过权重总和进行除法。权重不必是百分比，因为用于权重的任何数字最终都将被比例化。在[示例 3-3](#TbhpvAuILG)中，我们对每个考试赋予“1”的权重，但对最终考试赋予“2”的权重，使其比考试的权重大一倍。我们仍然会得到相同的答案81.4，因为这些值仍然会被比例化。
- en: Example 3-3\. Calculating a weighted mean in Python
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-3\. 在Python中计算加权平均值
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Median
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 中位数
- en: 'The *median* is the middlemost value in a set of ordered values. You sequentially
    order the values, and the median will be the centermost value. If you have an
    even number of values, you average the two centermost values. We can see in [Example 3-4](#uFgEneENrp)
    that the median number of pets owned in our sample is 7:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*中位数*是一组有序值中间最靠近的值。您按顺序排列值，中位数将是中间的值。如果您有偶数个值，您将平均两个中间值。我们可以看到在[示例 3-4](#uFgEneENrp)中，我们样本中拥有的宠物数量的中位数为7：'
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Example 3-4\. Calculating the median in Python
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-4\. 在Python中计算中位数
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The median can be a helpful alternative to the mean when data is skewed by *outliers*,
    or values that are extremely large and small compared to the rest of the values.
    Here’s an interesting anecdote to understand why. In 1986, the mean annual starting
    salary of geography graduates from the University of North Carolina at Chapel
    Hill was $250,000\. Other universities averaged $22,000\. Wow, UNC-CH must have
    an amazing geography program!
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据被*异常值*或与其他值相比极端大和小的值所扭曲时，中位数可以成为均值的有用替代。这里有一个有趣的轶事来理解为什么。1986年，北卡罗来纳大学教堂山分校地理学毕业生的年起薪平均值为$250,000。其他大学平均为$22,000。哇，UNC-CH一定有一个了不起的地理学项目！
- en: But in reality, what was so lucrative about UNC’s geography program? Well…Michael
    Jordan was one of their graduates. One of the most famous NBA players of all time
    indeed graduated with a geography degree from UNC. However, he started his career
    playing basketball, not studying maps. Obviously, this is a confounding variable
    that has created a huge outlier, and it majorly skewed the income average.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 但实际上，为什么北卡罗来纳大学的地理学项目如此赚钱呢？嗯...迈克尔·乔丹是他们的毕业生之一。确实，有史以来最著名的NBA球员之一，确实是从北卡罗来纳大学获得地理学学位的。然而，他开始他的职业生涯是打篮球，而不是学习地图。显然，这是一个造成了巨大异常值的混杂变量，它严重扭曲了收入平均值。
- en: This is why the median can be preferable in outlier-heavy situations (such as
    income-related data) over the mean. It is less sensitive to outliers and cuts
    data strictly down the middle based on their relative order, rather than where
    they fall exactly on a number line. When your median is very different from your
    mean, that means you have a skewed dataset with outliers.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么在受异常值影响较大的情况下（例如与收入相关的数据）中，中位数可能比均值更可取。它对异常值不太敏感，并严格根据它们的相对顺序将数据划分到中间，而不是准确地落在数字线上。当您的中位数与均值非常不同时，这意味着您的数据集具有异常值。
- en: Mode
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 众数
- en: The *mode* is the most frequently occurring set of values. It primarily becomes
    useful when your data is repetitive and you want to find which values occur the
    most frequently.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*众数*是出现频率最高的一组值。当您的数据重复时，想要找出哪些值出现最频繁时，它就变得很有用。'
- en: When no value occurs more than once, there is no mode. When two values occur
    with an equal amount of frequency, then the dataset is considered *bimodal*. In
    [Example 3-5](#svAgdpFjKu) we calculate the mode for our pet dataset, and sure
    enough we see this is bimodal as both 2 and 3 occur the most (and equally) as
    often.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当没有任何值出现超过一次时，就没有众数。当两个值出现的频率相等时，数据集被认为是*双峰的*。在[示例 3-5](#svAgdpFjKu)中，我们计算了我们的宠物数据集的众数，果然我们看到这是双峰的，因为2和3都出现最多（并且相等）。
- en: Example 3-5\. Calculating the mode in Python
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-5\. 在Python中计算众数
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In practicality, the mode is not used a lot unless your data is repetitive.
    This is commonly encountered with integers, categories, and other discrete variables.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，除非您的数据重复，否则众数不经常使用。这通常在整数、类别和其他离散变量中遇到。
- en: Variance and Standard Deviation
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方差和标准差
- en: When we start talking about variance and standard deviation, this is where it
    gets interesting. One thing that confuses people with variance and standard deviation
    is there are some calculation differences for the sample versus the population.
    We will do our best to cover these differences clearly.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始讨论方差和标准差时，这就变得有趣起来了。方差和标准差让人们感到困惑的一点是，对于样本和总体有一些计算差异。我们将尽力清楚地解释这些差异。
- en: Population Variance and Standard Deviation
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总体方差和标准差
- en: In describing data, we are often interested in measuring the differences between
    the mean and every data point. This gives us a sense of how “spread out” the data
    is.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在描述数据时，我们经常对测量平均值和每个数据点之间的差异感兴趣。这让我们对数据的“分布”有了一种感觉。
- en: Let’s say I’m interested in studying the number of pets owned by members of
    my work staff (note that I’m defining this as my population, not a sample). I
    have seven people on my staff.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我对研究我的工作人员拥有的宠物数量感兴趣（请注意，我将这定义为我的总体，而不是样本）。我的工作人员有七个人。
- en: I take the mean of all the numbers of pets they own, and I get 6.571\. Let’s
    subtract this mean from each value. This will show us how far each value is from
    the mean as shown in [Table 3-1](#WJeDlEQbNR).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我取得他们拥有的所有宠物数量的平均值，我得到6.571。让我们从每个值中减去这个平均值。这将展示给我们每个值距离平均值有多远，如[表 3-1](#WJeDlEQbNR)所示。
- en: Table 3-1\. Number of pets my staff owns
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-1. 我的员工拥有的宠物数量
- en: '| Value | Mean | Difference |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| Value | Mean | Difference |'
- en: '| --- | --- | --- |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0 | 6.571 | -6.571 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 6.571 | -6.571 |'
- en: '| 1 | 6.571 | -5.571 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 6.571 | -5.571 |'
- en: '| 5 | 6.571 | -1.571 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 6.571 | -1.571 |'
- en: '| 7 | 6.571 | 0.429 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 6.571 | 0.429 |'
- en: '| 9 | 6.571 | 2.429 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 6.571 | 2.429 |'
- en: '| 10 | 6.571 | 3.429 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 6.571 | 3.429 |'
- en: '| 14 | 6.571 | 7.429 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 6.571 | 7.429 |'
- en: Let’s visualize this on a number line with “X” showing the mean in [Figure 3-1](#egJmAmDQtl).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在数轴上用“X”表示平均值来可视化这一点，见[图 3-1](#egJmAmDQtl)。
- en: '![emds 0301](Images/emds_0301.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0301](Images/emds_0301.png)'
- en: Figure 3-1\. Visualizing the spread of our data, where “X” is the mean
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1. 可视化我们数据的分布，其中“X”是平均值
- en: Hmmm…now consider why this information can be useful. The differences give us
    a sense of how spread out the data is and how far values are from the mean. Is
    there a way we can consolidate these differences into a single number to quickly
    describe how spread out the data is?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯...现在考虑为什么这些信息有用。这些差异让我们了解数据的分布情况以及值距离平均值有多远。有没有一种方法可以将这些差异合并成一个数字，快速描述数据的分布情况？
- en: You may be tempted to take the average of the differences, but the negatives
    and positives will cancel each other out when they are summed. We could sum the
    absolute values (rid the negative signs and make all values positive). An even
    better approach would be to square these differences before summing them. This
    not only rids the negative values (because squaring a negative number makes it
    positive), but it amplifies larger differences and is mathematically easier to
    work with (derivatives are not straightforward with absolute values). After that,
    average the squared differences. This will give us the *variance*, a measure of
    how spread out our data is.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想要取这些差异的平均值，但当它们相加时，负数和正数会互相抵消。我们可以对绝对值求和（去掉负号并使所有值为正）。一个更好的方法是在求和之前对这些差异进行平方。这不仅消除了负值（因为平方一个负数会使其变为正数），而且放大了较大的差异，并且在数学上更容易处理（绝对值的导数不直观）。之后，对平方差异取平均值。这将给我们*方差*，一个衡量数据分布范围的指标。
- en: 'Here is a math formula showing how to calculate variance:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个数学公式，展示如何计算方差：
- en: <math alttext="population variance equals StartFraction left-parenthesis x 1
    minus m e a n right-parenthesis squared plus left-parenthesis x 2 minus m e a
    n right-parenthesis squared plus period period period plus left-parenthesis x
    Subscript n Baseline minus m e a n right-parenthesis squared Over upper N EndFraction"
    display="block"><mrow><mtext>population</mtext> <mtext>variance</mtext> <mo>=</mo>
    <mfrac><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>+</mo><msup><mrow><mo>(</mo><msub><mi>x</mi> <mn>2</mn></msub>
    <mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>)</mo></mrow> <mn>2</mn></msup>
    <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>n</mi></msub> <mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mi>N</mi></mfrac></mrow></math>
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="population variance equals StartFraction left-parenthesis x 1
    minus m e a n right-parenthesis squared plus left-parenthesis x 2 minus m e a
    n right-parenthesis squared plus period period period plus left-parenthesis x
    Subscript n Baseline minus m e a n right-parenthesis squared Over upper N EndFraction"
    display="block"><mrow><mtext>population</mtext> <mtext>variance</mtext> <mo>=</mo>
    <mfrac><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>+</mo><msup><mrow><mo>(</mo><msub><mi>x</mi> <mn>2</mn></msub>
    <mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>)</mo></mrow> <mn>2</mn></msup>
    <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>n</mi></msub> <mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mi>N</mi></mfrac></mrow></math>
- en: 'More formally, here is the variance for a population:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地，这是总体的方差：
- en: <math alttext="sigma squared equals StartFraction sigma-summation left-parenthesis
    x Subscript i Baseline minus mu right-parenthesis squared Over upper N EndFraction"
    display="block"><mrow><msup><mi>σ</mi> <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></mrow></math>
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="sigma squared equals StartFraction sigma-summation left-parenthesis
    x Subscript i Baseline minus mu right-parenthesis squared Over upper N EndFraction"
    display="block"><mrow><msup><mi>σ</mi> <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></mrow></math>
- en: Calculating the population variance of our pet example in Python is shown in
    [Example 3-6](#HSvEsubgVk).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中计算我们宠物示例的总体方差在[示例 3-6](#HSvEsubgVk)中展示。
- en: Example 3-6\. Calculating variance in Python
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-6. 在Python中计算方差
- en: '[PRE6]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: So the variance for number of pets owned by my office staff is 21.387755\. OK,
    but what does it exactly mean? It’s reasonable to conclude that a higher variance
    means more spread, but how do we relate this back to our data? This number is
    larger than any of our observations because we did a lot squaring and summing,
    putting it on an entirely different metric. So how do we squeeze it back down
    so it’s back on the scale we started with?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我的办公室员工拥有的宠物数量的方差为21.387755。好的，但这到底意味着什么？可以合理地得出结论，更高的方差意味着更广泛的分布，但我们如何将其与我们的数据联系起来？这个数字比我们的任何观察结果都要大，因为我们进行了大量的平方和求和，将其放在完全不同的度量标准上。那么我们如何将其压缩回原来的尺度？
- en: 'The opposite of a square is a square root, so let’s take the square root of
    the variance, which gives us the *standard deviation*. This is the variance scaled
    into a number expressed in terms of “number of pets,” which makes it a bit more
    meaningful:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 平方的反面是平方根，所以让我们取方差的平方根，得到*标准差*。这是将方差缩放为以“宠物数量”表示的数字，这使得它更有意义：
- en: <math alttext="sigma equals StartRoot StartFraction sigma-summation left-parenthesis
    x Subscript i Baseline minus mu right-parenthesis squared Over upper N EndFraction
    EndRoot" display="block"><mrow><mi>σ</mi> <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></msqrt></mrow></math>
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="sigma equals StartRoot StartFraction sigma-summation left-parenthesis
    x Subscript i Baseline minus mu right-parenthesis squared Over upper N EndFraction
    EndRoot" display="block"><mrow><mi>σ</mi> <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></msqrt></mrow></math>
- en: To implement in Python, we can reuse the `variance()` function and `sqrt()`
    its result. We now have a `std_dev()` function, shown in [Example 3-7](#WjBdnoKtlB).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Python中实现，我们可以重用`variance()`函数并对其结果进行`sqrt()`。现在我们有了一个`std_dev()`函数，如[示例 3-7](#WjBdnoKtlB)所示。
- en: Example 3-7\. Calculating standard deviation in Python
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-7\. 在Python中计算标准差
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Running the code in [Example 3-7](#WjBdnoKtlB), you will see our standard deviation
    is approximately 4.62 pets. So we can express our spread on a scale we started
    with, and this makes our variance a bit easier to interpret. We will see some
    important applications of the standard deviation in [Chapter 5](ch05.xhtml#ch05).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 运行[示例 3-7](#WjBdnoKtlB)中的代码，你会看到我们的标准差约为4.62只宠物。因此，我们可以用我们开始的尺度来表示我们的扩散，这使得我们的方差更容易解释。我们将在[第5章](ch05.xhtml#ch05)中看到标准差的一些重要应用。
- en: Why the Square?
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么是平方？
- en: Regarding variance, if the exponent in <math alttext="sigma squared"><msup><mi>σ</mi>
    <mn>2</mn></msup></math> bothers you, it’s because it is prompting you to take
    the square root of it to get the standard deviation. It’s a little nagging reminder
    you are dealing with squared values that need to be square-rooted.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 关于方差，如果<math alttext="sigma squared"><msup><mi>σ</mi> <mn>2</mn></msup></math>中的指数让你感到困扰，那是因为它提示你对其进行平方根运算以获得标准差。这是一个小小的提醒，告诉你正在处理需要进行平方根运算的平方值。
- en: Sample Variance and Standard Deviation
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 样本方差和标准差
- en: 'In the previous section we talked about variance and standard deviation for
    a population. However, there is an important tweak we need to apply to these two
    formulas when we calculate for a sample:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们讨论了总体的方差和标准差。然而，当我们为样本计算这两个公式时，我们需要应用一个重要的调整：
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>s</mi>
    <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>s</mi>
    <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></msqrt></mrow></mtd></mtr></mtable></math>
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>s</mi>
    <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>s</mi>
    <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></msqrt></mrow></mtd></mtr></mtable></math>
- en: Did you catch the difference? When we average the squared differences, we divide
    by *n*–1 rather than the total number of items *n*. Why would we do this? We do
    this to decrease any bias in a sample and not underestimate the variance of the
    population based on our sample. By counting values short of one item in our divisor,
    we increase the variance and therefore capture greater uncertainty in our sample.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你注意到了区别吗？当我们对平方差值求平均时，我们除以*n*-1而不是总项目数*n*。为什么要这样做？我们这样做是为了减少样本中的任何偏差，不低估基于我们的样本的总体方差。通过在除数中计算少一个项目的值，我们增加了方差，因此捕捉到了样本中更大的不确定性。
- en: If our pets data were a sample, not a population, we should make that adjustment
    accordingly. In [Example 3-8](#pRSherqejI), I modify my previous `variance()`
    and `std_dev()` Python code to optionally provide a parameter `is_sample`, which
    if `True` will subtract 1 from the divisor in the variance.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的宠物数据是一个样本，而不是一个总体，我们应相应地进行调整。在[示例 3-8](#pRSherqejI)中，我修改了之前的`variance()`和`std_dev()`
    Python代码，可选择提供一个参数`is_sample`，如果为`True`，则从方差的除数中减去1。
- en: Example 3-8\. Calculating standard deviation for a sample
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-8\. 计算样本的标准差
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Notice in [Example 3-8](#pRSherqejI) my variance and standard deviation have
    increased compared to previous examples that treated them as a population, not
    a sample. Recall in [Example 3-7](#WjBdnoKtlB) that the standard deviation was
    about 4.62 treating as a population. But here treating as a sample (by subtracting
    1 from the variance denominator), we get approximately 4.99\. This is correct
    as a sample could be biased and imperfect representing the population. Therefore,
    we increase the variance (and thus the standard deviation) to increase our estimate
    of how spread out the values are. A larger variance/standard deviation shows less
    confidence with a larger range.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在[示例 3-8](#pRSherqejI)中，我的方差和标准差与之前将它们视为总体而不是样本的示例相比有所增加。回想一下，在[示例 3-7](#WjBdnoKtlB)中，将其视为总体时，标准差约为4.62。但是在这里将其视为样本（通过从方差分母中减去1），我们得到的值约为4.99。这是正确的，因为样本可能存在偏差，不完全代表总体。因此，我们增加方差（从而增加标准差）以增加对值分布范围的估计。较大的方差/标准差显示出较大范围的不确定性。
- en: 'Just like the mean ( <math alttext="x overbar"><mover><mi>x</mi> <mo>¯</mo></mover></math>
    for sample and <math alttext="mu"><mi>μ</mi></math> for population), you will
    often see certain symbols for variance and standard deviation. The standard deviation
    for a sample and mean are specified by *s* and <math alttext="sigma"><mi>σ</mi></math>
    , respectively. Here again are the sample and population standard deviation formulas:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 就像均值（样本为 <math alttext="x overbar"><mover><mi>x</mi> <mo>¯</mo></mover></math>，总体为
    <math alttext="mu"><mi>μ</mi></math>），你经常会看到一些符号表示方差和标准差。样本和均值的标准差分别由*s*和<math
    alttext="sigma"><mi>σ</mi></math>指定。这里再次是样本和总体标准差的公式：
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>s</mi>
    <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></msqrt></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>σ</mi>
    <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></msqrt></mrow></mtd></mtr></mtable></math>
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>s</mi>
    <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></msqrt></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>σ</mi>
    <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></msqrt></mrow></mtd></mtr></mtable></math>
- en: 'The variance will be the square of these two formulas, undoing the square root.
    Therefore, the variance for sample and population are <math alttext="s squared"><msup><mi>s</mi>
    <mn>2</mn></msup></math> and <math alttext="sigma squared"><msup><mi>σ</mi> <mn>2</mn></msup></math>
    , respectively:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '方差将是这两个公式的平方，撤销平方根。因此，样本和总体的方差分别为<math alttext="s squared"><msup><mi>s</mi>
    <mn>2</mn></msup></math>和<math alttext="sigma squared"><msup><mi>σ</mi> <mn>2</mn></msup></math>： '
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>s</mi>
    <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>σ</mi>
    <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></mrow></mtd></mtr></mtable></math>
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>s</mi>
    <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>σ</mi>
    <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></mrow></mtd></mtr></mtable></math>
- en: Again, the square helps imply that a square root should be taken to get the
    standard deviation.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，平方有助于暗示应该取平方根以获得标准差。
- en: The Normal Distribution
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正态分布
- en: We touched on probability distributions in the last chapter, particularly the
    binomial distribution and beta distribution. However the most famous distribution
    of all is the normal distribution. The *normal distribution*, also known as the
    *Gaussian distribution*, is a symmetrical bell-shaped distribution that has most
    mass around the mean, and its spread is defined as a standard deviation. The “tails”
    on either side become thinner as you move away from the mean.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中我们提到了概率分布，特别是二项分布和贝塔分布。然而，最著名的分布是正态分布。*正态分布*，也称为*高斯分布*，是一种对称的钟形分布，大部分质量集中在均值附近，其传播程度由标准差定义。两侧的“尾巴”随着远离均值而变得更细。
- en: '[Figure 3-2](#BKlqpacWKn) is a normal distribution for golden retriever weights.
    Notice how most of the mass is around the mean of 64.43 pounds.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3-2](#BKlqpacWKn)是金毛犬体重的正态分布。请注意，大部分质量集中在64.43磅的均值附近。'
- en: '![emds 0302](Images/emds_0302.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0302](Images/emds_0302.png)'
- en: Figure 3-2\. A normal distribution
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2\. 一个正态分布
- en: Discovering the Normal Distribution
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发现正态分布
- en: The normal distribution is seen a lot in nature, engineering, science, and other
    domains. How do we discover it? Let’s say we sample the weight of 50 adult golden
    retrievers and plot them on a number line as shown in [Figure 3-3](#vtFcGtuatD).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正态分布在自然界、工程、科学和其他领域中经常出现。我们如何发现它呢？假设我们对50只成年金毛犬的体重进行抽样，并将它们绘制在数轴上，如[图3-3](#vtFcGtuatD)所示。
- en: '![emds 0303](Images/emds_0303.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0303](Images/emds_0303.png)'
- en: Figure 3-3\. A sample of 50 golden retriever weights
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-3\. 50只金毛犬体重的样本
- en: Notice how we have more values toward the center, but as we move farther left
    or right we see fewer values. Based on our sample, it seems highly unlikely we
    would see a golden retriever with a weight of 57 or 71\. But having a weight of
    64 or 65? Yeah, that certainly seems likely.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在中心附近有更多的值，但随着向左或向右移动，我们看到的值越来越少。根据我们的样本，看起来我们很不可能看到体重为57或71磅的金毛犬。但体重为64或65磅？是的，这显然很可能。
- en: Is there a better way to visualize this likelihood to see which golden retriever
    weights we are more likely to see sampled from the population? We can try to create
    a *histogram*, which buckets (or “bins”) up values based on numeric ranges of
    equal length, and then uses a bar chart showing the number of values within each
    range. In [Figure 3-4](#TjJQqiIbsG) we create a histogram that bins up values
    in ranges of .5 pounds.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 有没有更好的方法来可视化这种可能性，以查看我们更有可能从人群中抽样到哪些金毛犬的体重？我们可以尝试创建一个*直方图*，它根据相等长度的数值范围将值分组（或“箱”），然后使用柱状图显示每个范围内的值的数量。在[图3-4](#TjJQqiIbsG)中，我们创建了一个将值分组为0.5磅范围的直方图。
- en: This histogram does not reveal any meaningful shape to our data. The reason
    is because our bins are too small. We do not have an extremely large or infinite
    amount of data to meaningfully have enough points in each bin. Therefore we will
    have to make our bins larger. Let’s make the bins each have a length of three
    pounds, as in [Figure 3-5](#SBRNaBNfkM).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这个直方图并没有显示出数据的任何有意义的形状。原因是因为我们的箱太小了。我们没有足够大或无限的数据量来有意义地在每个箱中有足够的点。因此，我们必须使我们的箱更大。让我们使每个箱的长度为三磅，如[图3-5](#SBRNaBNfkM)所示。
- en: '![emds 0304](Images/emds_0304.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0304](Images/emds_0304.png)'
- en: Figure 3-4\. A histogram of golden retriever weights
  id: totrans-129
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-4\. 一张金毛犬体重的直方图
- en: '![emds 0305](Images/emds_0305.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0305](Images/emds_0305.png)'
- en: Figure 3-5\. A more productive histogram
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-5\. 一个更有意义的直方图
- en: Now we are getting somewhere! As you can see, if we get the bin sizes just right
    (in this case, each has a range of three pounds), we start to get a meaningful
    bell shape to our data. It’s not a perfect bell shape because our samples are
    never going to be perfectly representative of the population, but this is likely
    evidence our sample follows a normal distribution. If we fit a histogram with
    adequate bin sizes, and scale it so it has an area of 1.0 (which a probability
    distribution requires), we see a rough bell curve representing our sample. Let’s
    show it alongside our original data points in [Figure 3-6](#EtIlwoQQLS).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了进展！正如你所看到的，如果我们将箱的大小调整得恰到好处（在本例中，每个箱的范围为三磅），我们开始在数据中看到一个有意义的钟形。这不是一个完美的钟形，因为我们的样本永远不会完全代表人群，但这很可能是我们的样本遵循正态分布的证据。如果我们使用适当的箱大小拟合一个直方图，并将其缩放为面积为1.0（这是概率分布所需的），我们会看到一个粗略的钟形曲线代表我们的样本。让我们在[图3-6](#EtIlwoQQLS)中将其与我们的原始数据点一起展示。
- en: Looking at this bell curve, we can reasonably expect a golden retriever to have
    a weight most likely around 64.43 (the mean) but unlikely at 55 or 73\. Anything
    more extreme than that becomes very unlikely.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 看着这个钟形曲线，我们可以合理地期望金毛寻回犬的体重最有可能在64.43（均值）左右，但在55或73时不太可能。比这更极端的情况变得非常不太可能。
- en: '![emds 0306](Images/emds_0306.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0306](Images/emds_0306.png)'
- en: Figure 3-6\. A normal distribution fitted to data points
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-6。拟合到数据点的正态分布
- en: Properties of a Normal Distribution
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 正态分布的性质
- en: 'The normal distribution has several important properties that make it useful:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 正态分布具有几个重要的属性，使其有用：
- en: It’s symmetrical; both sides are identically mirrored at the mean, which is
    the center.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是对称的；两侧在均值处完全镜像，这就是中心。
- en: Most mass is at the center around the mean.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大部分质量在均值周围的中心。
- en: It has a spread (being narrow or wide) that is specified by standard deviation.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它具有由标准偏差指定的传播（狭窄或宽广）。
- en: The “tails” are the least likely outcomes and approach zero infinitely but never
    touch zero.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “尾部”是最不可能的结果，并且无限接近于零，但永远不会触及零。
- en: It resembles a lot of phenomena in nature and daily life, and even generalizes
    nonnormal problems because of the central limit theorem, which we will talk about
    shortly.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它类似于自然和日常生活中的许多现象，甚至由于中心极限定理而概括了非正态问题，我们很快会谈论到。
- en: The Probability Density Function (PDF)
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 概率密度函数（PDF）
- en: 'The standard deviation plays an important role in the normal distribution,
    because it defines how “spread out” it is. It is actually one of the parameters
    alongside the mean. The *probability density function (PDF)* that creates the
    normal distribution is as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 标准偏差在正态分布中起着重要作用，因为它定义了它的“扩散程度”。实际上，它是与均值一起的参数之一。创建正态分布的*概率密度函数（PDF）*如下：
- en: <math alttext="f left-parenthesis x right-parenthesis equals StartFraction 1
    Over sigma EndFraction asterisk StartRoot 2 pi EndRoot asterisk e Superscript
    minus one-half left-parenthesis StartFraction x minus mu Over sigma EndFraction
    squared right-parenthesis" display="block"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mfrac><mn>1</mn> <mi>σ</mi></mfrac> <mo>*</mo> <msqrt><mrow><mn>2</mn>
    <mi>π</mi></mrow></msqrt> <mo>*</mo> <msup><mi>e</mi> <mrow><mo>-</mo><mfrac><mn>1</mn>
    <mn>2</mn></mfrac><mrow><mo>(</mo><msup><mfrac><mrow><mi>x</mi><mo>-</mo><mi>μ</mi></mrow>
    <mi>σ</mi></mfrac> <mn>2</mn></msup> <mo>)</mo></mrow></mrow></msup></mrow></math>
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="f left-parenthesis x right-parenthesis equals StartFraction 1
    Over sigma EndFraction asterisk StartRoot 2 pi EndRoot asterisk e Superscript
    minus one-half left-parenthesis StartFraction x minus mu Over sigma EndFraction
    squared right-parenthesis" display="block"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mfrac><mn>1</mn> <mi>σ</mi></mfrac> <mo>*</mo> <msqrt><mrow><mn>2</mn>
    <mi>π</mi></mrow></msqrt> <mo>*</mo> <msup><mi>e</mi> <mrow><mo>-</mo><mfrac><mn>1</mn>
    <mn>2</mn></mfrac><mrow><mo>(</mo><msup><mfrac><mrow><mi>x</mi><mo>-</mo><mi>μ</mi></mrow>
    <mi>σ</mi></mfrac> <mn>2</mn></msup> <mo>)</mo></mrow></mrow></msup></mrow></math>
- en: Wow that’s a mouthful, isn’t it? We even see our friend Euler’s Number <math
    alttext="e"><mi>e</mi></math> from [Chapter 1](ch01.xhtml#ch01) and some crazy
    exponents. Here is how we can express it in Python in [Example 3-9](#sCChGpgKUG).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，这真是一个冗长的话题，不是吗？我们甚至在[第1章](ch01.xhtml#ch01)中看到我们的朋友欧拉数<math alttext="e"><mi>e</mi></math>和一些疯狂的指数。这是我们如何在Python中表达它的[示例3-9](#sCChGpgKUG)。
- en: Example 3-9\. The normal distribution function in Python
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例3-9。Python中的正态分布函数
- en: '[PRE9]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: There’s a lot to take apart here in this formula, but what’s important is that
    it accepts a mean and standard deviation as parameters, as well as an x-value
    so you can look up the likelihood at that given value.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式中有很多要解开的内容，但重要的是它接受均值和标准偏差作为参数，以及一个x值，这样你就可以查找给定值的可能性。
- en: Just like the beta distribution in [Chapter 2](ch02.xhtml#ch02), the normal
    distribution is continuous. This means to retrieve a probability we need to integrate
    a range of *x* values to find an area.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 就像[第2章](ch02.xhtml#ch02)中的贝塔分布一样，正态分布是连续的。这意味着要获取一个概率，我们需要积分一系列*x*值以找到一个区域。
- en: In practice though, we will use SciPy to do these calculations for us.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们将使用SciPy来为我们进行这些计算。
- en: The Cumulative Distribution Function (CDF)
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 累积分布函数（CDF）
- en: With the normal distribution, the vertical axis is not the probability but rather
    the likelihood for the data. To find the probability we need to look at a given
    range, and then find the area under the curve for that range. Let’s say I want
    to find the probability of a golden retriever weighing between 62 and 66 pounds.
    [Figure 3-7](#dJHChnUOST) shows the range we want to find the area for.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 对于正态分布，垂直轴不是概率，而是数据的可能性。要找到概率，我们需要查看一个给定范围，然后找到该范围下曲线的面积。假设我想找到金毛寻回犬体重在62到66磅之间的概率。[图3-7](#dJHChnUOST)显示了我们要找到面积的范围。
- en: '![emds 0307](Images/emds_0307.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0307](Images/emds_0307.png)'
- en: Figure 3-7\. A CDF measuring probability between 62 and 66 pounds
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-7。测量62到66磅之间概率的CDF
- en: We already did this task in [Chapter 2](ch02.xhtml#ch02) with the beta distribution,
    and just like the beta distribution there is a cumulative density function (CDF).
    Let’s follow this approach.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[第2章](ch02.xhtml#ch02)中用贝塔分布完成了这个任务，就像贝塔分布一样，这里也有一个累积密度函数（CDF）。让我们遵循这种方法。
- en: As we learned in the last chapter, the CDF provides the area *up to* a given
    x-value for a given distribution. Let’s see what the CDF looks like for our golden
    retriever normal distribution and put it alongside the PDF for reference in [Figure 3-8](#ueeLmpiIon).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一章中学到的，CDF提供了给定分布的给定x值的面积*直到*。让我们看看我们的金毛寻回犬正态分布的CDF是什么样子，并将其与PDF放在[图3-8](#ueeLmpiIon)中进行参考。
- en: '![emds 0308](Images/emds_0308.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0308](Images/emds_0308.png)'
- en: Figure 3-8\. A PDF alongside its CDF
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-8\. PDF与其CDF并排
- en: Notice there’s a relationship between the two graphs. The CDF, which is an S-shaped
    curve (called a sigmoid curve), projects the area up to that range in the PDF.
    Observe in [Figure 3-9](#gOlcaGmALR) that when we capture the area from negative
    infinity up to 64.43 (the mean), our CDF shows a value of exactly .5 or 50%!
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 注意两个图之间的关系。CDF是一个S形曲线（称为Sigmoid曲线），它在PDF中投影到该范围的面积。观察[图 3-9](#gOlcaGmALR)，当我们捕捉从负无穷到64.43（均值）的面积时，我们的CDF显示的值恰好为.5或50%！
- en: '![emds 0309](Images/emds_0309.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0309](Images/emds_0309.png)'
- en: Figure 3-9\. A PDF and CDF for golden retriever weights measuring probability
    up to the mean
  id: totrans-162
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-9\. 金毛寻回犬体重的PDF和CDF，测量均值的概率
- en: This area of .5 or 50% up to the mean is known because of the symmetry of our
    normal distribution, and we can expect the other side of the bell curve to also
    have 50% of the area.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这个区域的面积为0.5或50%，这是由于我们正态分布的对称性，我们可以期望钟形曲线的另一侧也有50%的面积。
- en: To calculate this area up to 64.43 in Python using SciPy, use the `norm.cdf()`
    function as shown in [Example 3-10](#UQGWRWMSRm).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Python中使用SciPy计算到64.43的面积，使用`norm.cdf()`函数，如[示例 3-10](#UQGWRWMSRm)所示。
- en: Example 3-10\. The normal distribution CDF in Python
  id: totrans-165
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-10\. Python中的正态分布CDF
- en: '[PRE10]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Just like we did in [Chapter 2](ch02.xhtml#ch02), we can deductively find the
    area for a middle range by subtracting areas. If we wanted to find the probability
    of observing a golden retriever between 62 and 66 pounds, we would calculate the
    area up to 66 and subtract the area up to 62 as visualized in [Figure 3-10](#fJPuwPHaRa).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在[第2章](ch02.xhtml#ch02)中所做的那样，我们可以通过减去面积来演绎地找到中间范围的面积。如果我们想找到62到66磅之间观察到金毛寻回犬的概率，我们将计算到66的面积并减去到62的面积，如[图 3-10](#fJPuwPHaRa)所示。
- en: '![emds 0310](Images/emds_0310.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0310](Images/emds_0310.png)'
- en: Figure 3-10\. Finding a middle range of probability
  id: totrans-169
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-10\. 寻找中间范围的概率
- en: Doing this in Python using SciPy is as simple as subtracting the two CDF operations
    shown in [Example 3-11](#FIrGMukClQ).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中使用SciPy进行这个操作就像在[示例 3-11](#FIrGMukClQ)中所示的两个CDF操作相减一样简单。
- en: Example 3-11\. Getting a middle range probability using the CDF
  id: totrans-171
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-11\. 使用CDF获取中间范围概率
- en: '[PRE11]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You should find the probability of observing a golden retriever between 62 and
    66 pounds to be 0.4920, or approximately 49.2%.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该发现在62到66磅之间观察到金毛寻回犬的概率为0.4920，或者大约为49.2%。
- en: The Inverse CDF
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逆CDF
- en: When we start doing hypothesis testing later in this chapter, we will encounter
    situations where we need to look up an area on the CDF and then return the corresponding
    x-value. Of course this is a backward usage of the CDF, so we will need to use
    the inverse CDF, which flips the axes as shown in [Figure 3-11](#IWjuSwEAcw).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在本章后面开始进行假设检验时，我们会遇到需要查找CDF上的一个区域然后返回相应x值的情况。当然，这是对CDF的反向使用，所以我们需要使用逆CDF，它会翻转轴，如[图 3-11](#IWjuSwEAcw)所示。
- en: This way, we can now look up a probability and then return the corresponding
    x-value, and in SciPy we would use the `norm.ppf()` function. For example, I want
    to find the weight that 95% of golden retrievers fall under. This is easy to do
    when I use the inverse CDF in [Example 3-12](#nbHwvKHrPf).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们现在可以查找一个概率然后返回相应的x值，在SciPy中我们会使用`norm.ppf()`函数。例如，我想找到95%的金毛寻回犬体重在以下。当我使用[示例 3-12](#nbHwvKHrPf)中的逆CDF时，这很容易做到。
- en: '![emds 0311](Images/emds_0311.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0311](Images/emds_0311.png)'
- en: Figure 3-11\. The inverse CDF, also called the PPF or quantile function
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-11\. 逆CDF，也称为PPF或分位数函数
- en: Example 3-12\. Using the inverse CDF (called `ppf()`) in Python
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-12\. 在Python中使用逆CDF（称为`ppf()`）
- en: '[PRE12]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: I find that 95% of golden retrievers are 69.348 or fewer pounds.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现95%的金毛寻回犬体重为69.348磅或更少。
- en: You can also use the inverse CDF to generate random numbers that follow the
    normal distribution. If I want to create a simulation that generates one thousand
    realistic golden retriever weights, I just generate a random value between 0.0
    and 1.0, pass it to the inverse CDF, and return the weight value as shown in [Example 3-13](#jEhKndTTjH).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用逆CDF生成遵循正态分布的随机数。如果我想创建一个模拟，生成一千个真实的金毛寻回犬体重，我只需生成一个介于0.0和1.0之间的随机值，传递给逆CDF，然后返回体重值，如[示例 3-13](#jEhKndTTjH)所示。
- en: Example 3-13\. Generating random numbers from a normal distribution
  id: totrans-183
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-13\. 从正态分布生成随机数
- en: '[PRE13]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Of course NumPy and other libraries can generate random values off a distribution
    for you, but this highlights one use case where the inverse CDF is handy.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，NumPy和其他库可以为您生成分布的随机值，但这突出了逆CDF很方便的一个用例。
- en: CDF and Inverse CDF from Scratch
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从头开始实现CDF和逆CDF
- en: To learn how to implement the CDF and inverse CDF from scratch in Python, refer
    to [Appendix A](app01.xhtml#appendix).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 要学习如何在Python中从头开始实现CDF和逆CDF，请参考[附录A](app01.xhtml#appendix)。
- en: Z-Scores
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Z分数
- en: It is common to rescale a normal distribution so that the mean is 0 and the
    standard deviation is 1, which is known as the *standard normal distribution*.
    This makes it easy to compare the spread of one normal distribution to another
    normal distribution, even if they have different means and variances.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 将正态分布重新缩放，使均值为0，标准差为1是很常见的，这被称为*标准正态分布*。这样可以轻松比较一个正态分布的扩展与另一个正态分布，即使它们具有不同的均值和方差。
- en: 'Of particular importance with the standard normal distribution is it expresses
    all x-values in terms of standard deviations, known as *Z-scores*. Turning an
    x-value into a Z-score uses a basic scaling formula:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 特别重要的是，标准正态分布将所有x值表示为标准差，称为*Z分数*。将x值转换为Z分数使用基本的缩放公式：
- en: <math alttext="dollar-sign z equals StartFraction x minus mu Over sigma EndFraction
    dollar-sign"><mrow><mi>z</mi> <mo>=</mo> <mfrac><mrow><mi>x</mi><mo>-</mo><mi>μ</mi></mrow>
    <mi>σ</mi></mfrac></mrow></math>
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="dollar-sign z equals StartFraction x minus mu Over sigma EndFraction
    dollar-sign"><mrow><mi>z</mi> <mo>=</mo> <mfrac><mrow><mi>x</mi><mo>-</mo><mi>μ</mi></mrow>
    <mi>σ</mi></mfrac></mrow></math>
- en: Here is an example. We have two homes from two different neighborhoods. Neighborhood
    A has a mean home value of $140,000 and standard deviation of $3,000\. Neighborhood
    B has a mean home value of $800,000 and standard deviation of $10,000.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个例子。我们有两个来自两个不同社区的房屋。社区A的平均房屋价值为$140,000，标准差为$3,000。社区B的平均房屋价值为$800,000，标准差为$10,000。
- en: <math display="block"><mrow><msub><mi>μ</mi> <mi>A</mi></msub> <mo>=</mo> <mn>140,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>μ</mi> <mi>B</mi></msub> <mo>=</mo> <mn>800,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>σ</mi> <mi>A</mi></msub> <mo>=</mo> <mn>3,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>σ</mi> <mi>B</mi></msub> <mo>=</mo> <mn>10,000</mn></mrow></math>
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mi>μ</mi> <mi>A</mi></msub> <mo>=</mo> <mn>140,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>μ</mi> <mi>B</mi></msub> <mo>=</mo> <mn>800,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>σ</mi> <mi>A</mi></msub> <mo>=</mo> <mn>3,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>σ</mi> <mi>B</mi></msub> <mo>=</mo> <mn>10,000</mn></mrow></math>
- en: Now we have two homes from each neighborhood. House A from neighborhood A is
    worth $150,000 and house B from neighborhood B is worth $815,000\. Which home
    is more expensive relative to the average home in its neighborhood?
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有两个来自每个社区的房屋。社区A的房屋价值为$150,000，社区B的房屋价值为$815,000。哪个房屋相对于其社区的平均房屋更昂贵？
- en: <math display="block"><mrow><msub><mi>x</mi> <mi>A</mi></msub> <mo>=</mo> <mn>150,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>x</mi> <mi>B</mi></msub> <mo>=</mo> <mn>815,000</mn></mrow></math>
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mi>x</mi> <mi>A</mi></msub> <mo>=</mo> <mn>150,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>x</mi> <mi>B</mi></msub> <mo>=</mo> <mn>815,000</mn></mrow></math>
- en: 'If we express these two values in terms of standard deviations, we can compare
    them relative to each neighborhood mean. Use the Z-score formula:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这两个值用标准差表示，我们可以相对于每个社区的均值进行比较。使用Z分数公式：
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>z</mi>
    <mo>=</mo> <mfrac><mrow><mi>x</mi><mo>-</mo><mtext>mean</mtext></mrow> <mrow><mtext>standard</mtext><mtext>deviation</mtext></mrow></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>z</mi>
    <mi>A</mi></msub> <mo>=</mo> <mfrac><mrow><mn>150000</mn><mo>-</mo><mn>140000</mn></mrow>
    <mn>3000</mn></mfrac> <mo>=</mo> <mn>3.</mn> <mover><mn>333</mn> <mo>¯</mo></mover></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>z</mi>
    <mi>B</mi></msub> <mo>=</mo> <mfrac><mrow><mn>815000</mn><mo>-</mo><mn>800000</mn></mrow>
    <mn>10000</mn></mfrac> <mo>=</mo> <mn>1.5</mn></mrow></mtd></mtr></mtable></math>
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>z</mi>
    <mo>=</mo> <mfrac><mrow><mi>x</mi><mo>-</mo><mtext>mean</mtext></mrow> <mrow><mtext>standard</mtext><mtext>deviation</mtext></mrow></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>z</mi>
    <mi>A</mi></msub> <mo>=</mo> <mfrac><mrow><mn>150000</mn><mo>-</mo><mn>140000</mn></mrow>
    <mn>3000</mn></mfrac> <mo>=</mo> <mn>3.</mn> <mover><mn>333</mn> <mo>¯</mo></mover></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>z</mi>
    <mi>B</mi></msub> <mo>=</mo> <mfrac><mrow><mn>815000</mn><mo>-</mo><mn>800000</mn></mrow>
    <mn>10000</mn></mfrac> <mo>=</mo> <mn>1.5</mn></mrow></mtd></mtr></mtable></math>
- en: So the house in neighborhood A is actually much more expensive relative to its
    neighborhood than the house in neighborhood B, as they have Z-scores of <math
    display="inline"><mrow><mn>3.</mn> <mover><mn>333</mn> <mo>¯</mo></mover></mrow></math>
    and 1.5, respectively.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，A社区的房屋实际上相对于其社区要昂贵得多，因为它们的Z分数分别为<math display="inline"><mrow><mn>3.</mn>
    <mover><mn>333</mn> <mo>¯</mo></mover></mrow></math>和1.5。
- en: Here is how we can convert an x-value coming from a given distribution with
    a mean and standard deviation into a Z-score, and vice versa, as shown in [Example 3-14](#wDIlIrjbrg).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们如何将来自具有均值和标准差的给定分布的x值转换为Z分数，反之亦然，如[示例 3-14](#wDIlIrjbrg)所示。
- en: Example 3-14\. Turn Z-scores into x-values and vice versa
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-14\. 将Z分数转换为x值，反之亦然
- en: '[PRE14]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `z_score()` function will take an x-value and scale it in terms of standard
    deviations, given a mean and standard deviation. The `z_to_x()` function takes
    a Z-score and converts it back to an x-value. Studying the two functions, you
    can see their algebraic relationship, one solving for the Z-score and the other
    for the x-value. We then turn an x-value of 8.0 into a Z-score of <math display="inline"><mrow><mn>3.</mn>
    <mover><mn>333</mn> <mo>¯</mo></mover></mrow></math> and then turn that Z-score
    back into an x-value.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`z_score()`函数将接受一个x值，并根据均值和标准差将其按标准偏差进行缩放。`z_to_x()`函数将接受一个Z分数，并将其转换回x值。研究这两个函数，你可以看到它们的代数关系，一个解决Z分数，另一个解决x值。然后，我们将一个x值为8.0转换为<math
    display="inline"><mrow><mn>3.</mn> <mover><mn>333</mn> <mo>¯</mo></mover></mrow></math>的Z分数，然后将该Z分数转换回x值。'
- en: Inferential Statistics
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推断统计学
- en: Descriptive statistics, which we have covered so far, is commonly understood.
    However, when we get into inferential statistics the abstract relationships between
    sample and population come into full play. These abstract nuances are not something
    you want to rush through but rather take your time and absorb thoughtfully. As
    stated earlier, we are wired as humans to be biased and quickly come to conclusions.
    Being a good data science professional requires you to suppress that primal desire
    and consider the possibility that other explanations can exist. It is acceptable
    (perhaps even enlightened) to theorize there is no explanation at all and a finding
    is just coincidental and random.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止所涵盖的描述性统计学是常见的。然而，当我们涉及推断统计学时，样本和总体之间的抽象关系得以充分发挥。这些抽象的微妙之处不是你想要匆忙通过的，而是要花时间仔细吸收。正如前面所述，我们作为人类有偏见，很快就会得出结论。成为一名优秀的数据科学专业人员需要你抑制那种原始的欲望，并考虑其他解释可能存在的可能性。推测没有任何解释，某一发现只是巧合和随机的也是可以接受的（也许甚至是开明的）。
- en: First let’s start with the theorem that lays the foundation for all inferential
    statistics.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们从为所有推断统计学奠定基础的定理开始。
- en: The Central Limit Theorem
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 中心极限定理
- en: One of the reasons the normal distribution is useful is because it appears a
    lot in nature, such as adult golden retriever weights. However, it shows up in
    a more fascinating context outside of natural populations. When we start measuring
    large enough samples from a population, even if that population does not follow
    a normal distribution, the normal distribution still makes an appearance.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 正态分布之所以有用的原因之一是因为它在自然界中经常出现，比如成年金毛犬的体重。然而，在自然人口之外的更迷人的背景下，它也会出现。当我们开始从人口中抽取足够大的样本时，即使该人口不遵循正态分布，正态分布仍然会出现。
- en: Let’s pretend I am measuring a population that is truly and uniformly random.
    Any value between 0.0 and 1.0 is equally likely, and no value has any preference.
    But something fascinating happens when we take increasingly large samples from
    this population, take the average of each, and then plot them into a histogram.
    Run this Python code in [Example 3-15](#svVtluPQuu) and observe the plot in [Figure 3-12](#GdjvwgQAuP).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我正在测量一个真正随机且均匀的人口。0.0到1.0之间的任何值都是同等可能的，没有任何值有任何偏好。但当我们从这个人口中抽取越来越大的样本，计算每个样本的平均值，然后将它们绘制成直方图时，会发生一些有趣的事情。在[示例
    3-15](#svVtluPQuu)中运行这段Python代码，并观察[图 3-12](#GdjvwgQAuP)中的图表。
- en: Example 3-15\. Exploring the central limit theorem in Python
  id: totrans-209
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-15\. 在Python中探索中心极限定理
- en: '[PRE15]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![emds 0312](Images/emds_0312.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0312](Images/emds_0312.png)'
- en: Figure 3-12\. Taking the means of samples (each of size 31) and plotting them
  id: totrans-212
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-12\. 取样本均值（每个大小为31）并绘制它们
- en: Wait, how did uniformly random numbers, when sampled as groups of 31 and then
    averaged, roughly form a normal distribution? Any number is equally likely, right?
    Shouldn’t the distribution be flat rather than bell-curved?
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 等等，当作为31个一组的均匀随机数取样然后求平均时，为什么会大致形成正态分布？任何数字都是等可能的，对吧？分布不应该是平坦的而不是钟形曲线吗？
- en: Here’s what is happening. The individual numbers in the samples alone will not
    create a normal distribution. The distribution will be flat where any number is
    equally likely (known as a *uniform distribution*). But when we group them as
    samples and average them, they form a normal distribution.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 发生了什么呢？样本中的单个数字本身不会产生正态分布。分布将是平坦的，其中任何数字都是等可能的（称为*均匀分布*）。但当我们将它们作为样本分组并求平均时，它们形成一个正态分布。
- en: 'This is because of the *central limit theorem*, which states that interesting
    things happen when we take large enough samples of a population, calculate the
    mean of each, and plot them as a distribution:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为*中心极限定理*，它表明当我们对一个人口取足够大的样本，计算每个样本的均值，并将它们作为一个分布绘制时，会发生有趣的事情：
- en: The mean of the sample means is equal to the population mean.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 样本均值的平均值等于总体均值。
- en: If the population is normal, then the sample means will be normal.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果总体是正态的，那么样本均值将是正态的。
- en: If the population is not normal, but the sample size is greater than 30, the
    sample means will still roughly form a normal distribution.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果总体不是正态分布，但样本量大于30，样本均值仍然会大致形成正态分布。
- en: 'The standard deviation of the sample means equals the population standard deviation
    divided by the square root of *n*:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 样本均值的标准差等于总体标准差除以*n*的平方根：
- en: <math alttext="dollar-sign sample standard deviation equals StartFraction population
    standard deviation Over StartRoot sample size EndRoot EndFraction dollar-sign"><mrow><mtext>sample</mtext>
    <mtext>standard</mtext> <mtext>deviation</mtext> <mo>=</mo> <mfrac><mrow><mtext>population</mtext><mtext>standard</mtext><mtext>deviation</mtext></mrow>
    <msqrt><mrow><mtext>sample</mtext><mtext>size</mtext></mrow></msqrt></mfrac></mrow></math>
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="dollar-sign sample standard deviation equals StartFraction population
    standard deviation Over StartRoot sample size EndRoot EndFraction dollar-sign"><mrow><mtext>sample</mtext>
    <mtext>standard</mtext> <mtext>deviation</mtext> <mo>=</mo> <mfrac><mrow><mtext>population</mtext><mtext>standard</mtext><mtext>deviation</mtext></mrow>
    <msqrt><mrow><mtext>sample</mtext><mtext>size</mtext></mrow></msqrt></mfrac></mrow></math>
- en: Why is all of the above important? These behaviors allows us to infer useful
    things about populations based on samples, even for nonnormal populations. If
    you modify the preceding code and try smaller sample sizes of 1 or 2, you will
    not see a normal distribution emerge. But as you approach 31 or more, you will
    see that we converge onto a normal distribution as shown in [Figure 3-13](#UIUIWJGfbo).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么上述所有内容很重要？这些行为使我们能够根据样本推断出关于人口的有用信息，即使对于非正态分布的人口也是如此。如果你修改前面的代码并尝试较小的样本量，比如1或2，你将看不到正态分布出现。但当你接近31或更多时，你会看到我们收敛到一个正态分布，如[图3-13](#UIUIWJGfbo)所示。
- en: '![emds 0313](Images/emds_0313.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0313](Images/emds_0313.png)'
- en: Figure 3-13\. Larger sample sizes approach the normal distribution
  id: totrans-223
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-13。较大的样本量接近正态分布
- en: Thirty-one is the textbook number in statistics because that is when our sample
    distribution often converges onto the population distribution, particularly when
    we measure sample means or other parameters. When you have fewer than 31 items
    in your sample, that is when you have to rely on the T-distribution rather than
    the normal distribution, which has increasingly fatter tails the smaller your
    sample size. We will briefly talk about this later, but first let’s assume we
    have at least 31 items in our samples when we talk about confidence intervals
    and testing.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 三十一是统计学中的教科书数字，因为这时我们的样本分布通常会收敛到总体分布，特别是当我们测量样本均值或其他参数时。当你的样本少于31个时，这时你必须依赖T分布而不是正态分布，随着样本量的减小，正态分布的尾部会变得越来越厚。我们稍后会简要讨论这一点，但首先让我们假设在谈论置信区间和检验时，我们的样本至少有31个。
- en: Confidence Intervals
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 置信区间
- en: You may have heard the term “confidence interval,” which often confuses statistics
    newcomers and students. A *confidence interval* is a range calculation showing
    how confidently we believe a sample mean (or other parameter) falls in a range
    for the population mean.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听过“置信区间”这个术语，这经常让统计新手和学生感到困惑。*置信区间*是一个范围计算，显示我们有多大信心相信样本均值（或其他参数）落在总体均值的范围内。
- en: '*Based on a sample of 31 golden retrievers with a sample mean of 64.408 and
    a sample standard deviation of 2.05, I am 95% confident that the population mean
    lies between 63.686 and 65.1296.* How do I know this? Let me show you, and if
    you get confused, circle back to this paragraph and remember what we are trying
    to achieve. I highlighted it for a reason!'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '*基于31只金毛猎犬的样本，样本均值为64.408，样本标准差为2.05，我有95%的信心总体均值在63.686和65.1296之间。* 我怎么知道这个？让我告诉你，如果你感到困惑，回到这段话，记住我们试图实现什么。我有意突出了它！'
- en: I first start out by choosing a *level of confidence (LOC)*, which will contain
    the desired probability for the population mean range. I want to be 95% confident
    that my sample mean falls in the population mean range I will calculate. That’s
    my LOC. We can leverage the central limit theorem and infer what this range for
    the population mean is. First, I need the *critical z-value* which is the symmetrical
    range in a standard normal distribution that gives me 95% probability in the center
    as highlighted in [Figure 3-14](#WosQdAULOW).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我首先选择一个*置信水平（LOC）*，这将包含所需概率的总体均值范围。我希望有95%的信心，我的样本均值落在我将计算的总体均值范围内。这就是我的LOC。我们可以利用中心极限定理并推断出总体均值的这个范围是什么。首先，我需要*关键z值*，这是在标准正态分布中给出95%概率的对称范围，如[图3-14](#WosQdAULOW)中所示。
- en: How do we calculate this symmetrical range containing .95 of the area? It’s
    easier to grasp as a concept than as a calculation. You may instinctively want
    to use the CDF, but then you may realize there are a few more moving parts here.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何计算包含0.95面积的对称范围？这作为一个概念比作为一个计算更容易理解。你可能本能地想使用CDF，但随后你可能会意识到这里有更多的变动部分。
- en: First you need to leverage the inverse CDF. Logically, to get 95% of the symmetrical
    area in the center, we would chop off the tails that have the remaining 5% of
    area. Splitting that remaining 5% area in half would give us 2.5% area in each
    tail. Therefore, the areas we want to look up the x-values for are .025 and .975
    as shown in [Figure 3-15](#UIhCfkqhJv).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要利用逆CDF。从逻辑上讲，为了获得中心对称区域的95%面积，我们将切掉剩余5%面积的尾部。将剩余的5%面积分成两半，每个尾部将给我们2.5%的面积。因此，我们想要查找x值的面积是0.025和0.975，如[图3-15](#UIhCfkqhJv)所示。
- en: '![emds 0314](Images/emds_0314.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0314](Images/emds_0314.png)'
- en: Figure 3-14\. 95% symmetrical probability in the center of a standard normal
    distribution
  id: totrans-232
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-14。标准正态分布中心的95%对称概率
- en: '![emds 0315](Images/emds_0315.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0315](Images/emds_0315.png)'
- en: Figure 3-15\. We want the x-values that give us areas .025 and .975
  id: totrans-234
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-15。我们想要给出面积为0.025和0.975的x值
- en: We can look up the x-value for area .025 and the x-value for area .975, and
    that will give us our center range containing 95% of the area. We will then return
    the corresponding lower and upper z-values containing this area. Remember, we
    are using standard normal distribution here so they will be the same other than
    being positive/negative. Let’s calculate this in Python as shown in [Example 3-16](#atphsKnwca).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查找面积为0.025和面积为0.975的x值，这将给出包含95%面积的中心范围。然后我们将返回包含这个区域的相应下限和上限z值。请记住，我们在这里使用标准正态分布，因此它们除了是正/负之外是相同的。让我们按照Python中[示例3-16](#atphsKnwca)中所示的方式计算这个。
- en: Example 3-16\. Retrieving a critical z-value
  id: totrans-236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例3-16。检索关键的z值
- en: '[PRE16]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'OK, so we get ±1.95996, which is our critical z-value capturing 95% of probability
    at the center of the standard normal distribution. Next I’m going to leverage
    the central limit theorem to produce the *margin of error (E)*, which is the range
    around the sample mean that contains the population mean at that level of confidence.
    Recall that our sample of 31 golden retrievers has a mean of 64.408 and standard
    deviation of 2.05\. The formula to get this margin of error is:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，所以我们得到了±1.95996，这是我们在标准正态分布中心捕获95%概率的关键z值。接下来，我将利用中心极限定理来产生*误差边界（E）*，这是样本均值周围包含在该置信水平下的总体均值的范围。回想一下，我们的31只金毛猎犬样本的均值为64.408，标准差为2.05。计算这个误差边界的公式是：
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi>
    <mo>=</mo> <mo>±</mo> <msub><mi>z</mi> <mi>c</mi></msub> <mfrac><mi>s</mi> <msqrt><mi>n</mi></msqrt></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi>
    <mo>=</mo> <mo>±</mo> <mn>1.95996</mn> <mo>*</mo> <mfrac><mrow><mn>2.05</mn></mrow>
    <msqrt><mn>31</mn></msqrt></mfrac></mrow></mtd></mtr></mtable></math> <math display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi> <mo>=</mo>
    <mo>±</mo> <mn>0.72164</mn></mrow></mtd></mtr></mtable></math>
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi>
    <mo>=</mo> <mo>±</mo> <msub><mi>z</mi> <mi>c</mi></msub> <mfrac><mi>s</mi> <msqrt><mi>n</mi></msqrt></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi>
    <mo>=</mo> <mo>±</mo> <mn>1.95996</mn> <mo>*</mo> <mfrac><mrow><mn>2.05</mn></mrow>
    <msqrt><mn>31</mn></msqrt></mfrac></mrow></mtd></mtr></mtable></math> <math display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi> <mo>=</mo>
    <mo>±</mo> <mn>0.72164</mn></mrow></mtd></mtr></mtable></math>
- en: If we apply that margin of error against the sample mean, we finally get the
    confidence interval!
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这个误差边界应用于样本均值，最终我们就得到了置信区间！
- en: <math display="block"><mrow><mn>95%</mn> <mtext>confidence interval</mtext>
    <mo>=</mo> <mn>64.408</mn> <mo>±</mo> <mn>0.72164</mn></mrow></math>
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mn>95%</mn> <mtext>confidence interval</mtext>
    <mo>=</mo> <mn>64.408</mn> <mo>±</mo> <mn>0.72164</mn></mrow></math>
- en: Here is how we calculate this confidence interval in Python from beginning to
    end in [Example 3-17](#bqurVLiIGN).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是如何在Python中从头到尾计算这个置信区间的，详见[示例3-17](#bqurVLiIGN)。
- en: Example 3-17\. Calculating a confidence interval in Python
  id: totrans-243
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例3-17\. 在Python中计算置信区间
- en: '[PRE17]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: So the way to interpret this is “based on my sample of 31 golden retriever weights
    with sample mean 64.408 and sample standard deviation of 2.05, I am 95% confident
    the population mean lies between 63.686 and 65.1296.” That is how we describe
    our confidence interval.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，解释这个的方式是“基于我的31只金毛犬体重样本，样本均值为64.408，样本标准差为2.05，我有95%的信心总体均值在63.686和65.1296之间。”
    这就是我们描述置信区间的方式。
- en: One interesting thing to note here too is that in our margin of error formula,
    the larger *n* becomes, the narrower our confidence interval becomes! This makes
    sense because if we have a larger sample, we are more confident in the population
    mean falling in a smaller range, hence why it’s called a confidence interval.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一件有趣的事情要注意，就是在我们的误差边界公式中，*n* 变大时，我们的置信区间变得更窄！这是有道理的，因为如果我们有一个更大的样本，我们对于总体均值落在更小范围内的信心就更大，这就是为什么它被称为置信区间。
- en: One caveat to put here is that for this to work, our sample size must be at
    least 31 items. This goes back to the central limit theorem. If we want to apply
    a confidence interval to a smaller sample, we need to use a distribution with
    higher variance (fatter tails reflecting more uncertainty). This is what the T-distribution
    is for, and we will visit that at the end of this chapter.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的一个警告是，为了使这个工作起效，我们的样本大小必须至少为31个项目。这回到了中心极限定理。如果我们想将置信区间应用于更小的样本，我们需要使用方差更高的分布（更多不确定性的更胖尾巴）。这就是T分布的用途，我们将在本章末讨论它。
- en: In [Chapter 5](ch05.xhtml#ch05) we will continue to use confidence intervals
    for linear regressions.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第五章](ch05.xhtml#ch05)中，我们将继续使用线性回归的置信区间。
- en: Understanding P-Values
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解P值
- en: When we say something is *statistically significant*, what do we mean by that?
    We hear it used loosely and frequently but what does it mean mathematically? Technically,
    it has to do with something called the p-value, which is a hard concept for many
    folks to grasp. But I think the concept of p-values makes more sense when you
    trace it back to its invention. While this is an imperfect example, it gets across
    some big ideas.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们说某事是*统计显著*时，我们指的是什么？我们经常听到这个词被随意地使用，但在数学上它意味着什么？从技术上讲，这与一个叫做p值的东西有关，这对许多人来说是一个难以理解的概念。但我认为当你将p值的概念追溯到它的发明时，它会更有意义。虽然这只是一个不完美的例子，但它传达了一些重要的思想。
- en: In 1925, mathematician Ronald Fisher was at a party. One of his colleagues Muriel
    Bristol claimed she could detect when tea was poured before milk simply by tasting
    it. Intrigued by the claim, Ronald set up an experiment on the spot.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 1925年，数学家罗纳德·费舍尔在一个聚会上。他的同事穆里尔·布里斯托尔声称她能通过品尝来区分是先倒茶还是先倒牛奶。对这一说法感到好奇，罗纳德当场设置了一个实验。
- en: He prepared eight cups of tea. Four had milk poured first; the other four had
    tea poured first. He then presented them to his connoisseur colleague and asked
    her to identify the pour order for each. Remarkably, she identified them all correctly,
    and the probability of this happening by chance is 1 in 70, or 0.01428571.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 他准备了八杯茶。四杯先倒牛奶，另外四杯先倒茶。然后他把它们呈现给他的鉴赏家同事，并要求她识别每一杯的倒入顺序。令人惊讶的是，她全部正确识别了，这种情况发生的概率是70分之1，或者0.01428571。
- en: This 1.4% probability is what we call the *p-value*, the probability of something
    occurring by chance rather than because of a hypothesized explanation. Without
    going down a rabbit hole of combinatorial math, the probability that Muriel completely
    guessed the cups correctly is 1.4%. What exactly does that tell you?
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这个1.4%的概率就是我们所谓的*p值*，即某事发生的概率是偶然而非因为一个假设的解释。不深入组合数学的兔子洞，穆里尔完全猜对杯子的概率是1.4%。这到底告诉了你什么？
- en: When we frame an experiment, whether it is determining if organic donuts cause
    weight gain or living near power lines causes cancer, we always have to entertain
    the possibility that random luck played a role. Just like there is a 1.4% chance
    Muriel identified the cups of tea correctly simply by guessing, there’s always
    a chance randomness just gave us a good hand like a slot machine. This helps us
    frame our *null hypothesis (H[0])*, saying that the variable in question had no
    impact on the experiment and any positive results are just random luck. The *alternative
    hypothesis (H[1])* poses that a variable in question (called the *controlled variable*)
    is causing a positive result.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们设计一个实验，无论是确定有机甜甜圈是否导致体重增加，还是住在电力线附近是否导致癌症，我们总是要考虑到随机运气起了作用的可能性。就像穆里尔仅仅通过猜测正确识别茶杯的概率为1.4%一样，总是有一种可能性，即随机性给了我们一个好手牌，就像老虎机一样。这有助于我们构建我们的*零假设（H[0])*，即所研究的变量对实验没有影响，任何积极的结果只是随机运气。*备择假设（H[1])*
    提出所研究的变量（称为*控制变量*) 导致了积极的结果。
- en: Traditionally, the threshold for statistical significance is a p-value of 5%
    or less, or .05\. Since .014 is less than .05, this would mean we can reject our
    null hypothesis that Muriel was randomly guessing. We can then promote the alternative
    hypothesis that Muriel had a special ability to detect whether tea or milk was
    poured first.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，统计显著性的阈值是5%或更低的p值，即0.05。由于0.014小于0.05，这意味着我们可以拒绝零假设，即穆里尔是随机猜测的。然后我们可以提出备择假设，即穆里尔有特殊能力判断是先倒茶还是牛奶。
- en: Now one thing this tea-party example did not capture is that when we calculate
    a p-value, we capture all probability of that event or rarer. We will address
    this as we dive into the next example using the normal distribution.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这个茶会的例子没有捕捉到的一点是，当我们计算p值时，我们捕捉到了所有该事件或更罕见事件的概率。当我们深入研究下一个使用正态分布的例子时，我们将解决这个问题。
- en: Hypothesis Testing
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 假设检验
- en: Past studies have shown that the mean recovery time for a cold is 18 days, with
    a standard deviation of 1.5 days, and follows a normal distribution.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 过去的研究表明，感冒的平均恢复时间为18天，标准偏差为1.5天，并且符合正态分布。
- en: This means there is approximately 95% chance of recovery taking between 15 and
    21 days as shown in [Figure 3-16](#BGsosDGqFb) and [Example 3-18](#kQakNUgcMw).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在15到21天之间恢复的概率约为95%，如[图3-16](#BGsosDGqFb)和[示例3-18](#kQakNUgcMw)所示。
- en: '![emds 0316](Images/emds_0316.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0316](Images/emds_0316.png)'
- en: Figure 3-16\. There is 95% chance of recovery between 15 and 21 days
  id: totrans-261
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-16。在15到21天之间有95%的恢复机会。
- en: Example 3-18\. Calculating the probability of recovery between 15 and 21 days
  id: totrans-262
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例3-18。计算在15到21天之间恢复的概率
- en: '[PRE18]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can infer then from the remaining 5% probability that there’s a 2.5% chance
    of recovery taking longer than 21 days and a 2.5% chance of it taking fewer than
    15 days. Hold onto that bit of information because it will be critical later!
    That drives our p-value.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从剩下的5%概率推断出，恢复需要超过21天的概率为2.5%，而少于15天的概率也为2.5%。记住这一点，因为这将在后面至关重要！这驱动了我们的p值。
- en: Now let’s say an experimental new drug was given to a test group of 40 people,
    and it took an average of 16 days for them to recover from the cold as shown in
    [Figure 3-17](#cnqKOunjTF).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设一个实验性新药物被给予了一个由40人组成的测试组，他们从感冒中恢复需要平均16天，如[图3-17](#cnqKOunjTF)所示。
- en: '![emds 0317](Images/emds_0317.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0317](Images/emds_0317.png)'
- en: Figure 3-17\. A group taking a drug took 16 days to recover
  id: totrans-267
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-17。服用药物的一组人恢复需要16天。
- en: 'Did the drug have an impact? If you reason long enough, you may realize what
    we are asking is this: does the drug show a statistically signficant result? Or
    did the drug not work and the 16-day recovery was a coincidence with the test
    group? That first question frames our alternative hypothesis, while the second
    question frames our null hypothesis.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这种药物有影响吗？如果你思考足够长时间，你可能会意识到我们所问的是：这种药物是否显示出统计上显著的结果？或者这种药物没有起作用，16天的恢复只是与测试组的巧合？第一个问题构成了我们的备择假设，而第二个问题构成了我们的零假设。
- en: 'There are two ways we can calculate this: the one-tailed and two-tailed test.
    We will start with the one-tailed.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过两种方式来计算这个问题：单尾检验和双尾检验。我们将从单尾检验开始。
- en: One-Tailed Test
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单尾检验
- en: 'When we approach the *one-tailed test*, we typically frame our null and alternative
    hypotheses using inequalities. We hypothesize around the population mean and say
    that it either is greater than/equal to 18 (the null hypothesis <math alttext="upper
    H 0"><msub><mi>H</mi> <mn>0</mn></msub></math> ) or less than 18 (the alternative
    hypothesis <math alttext="upper H 1"><msub><mi>H</mi> <mn>1</mn></msub></math>
    ):'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行*单尾检验*时，通常使用不等式来构建零假设和备择假设。我们假设围绕着总体均值，并说它要么大于/等于18（零假设 <math alttext="upper
    H 0"><msub><mi>H</mi> <mn>0</mn></msub></math> ），要么小于18（备择假设 <math alttext="upper
    H 1"><msub><mi>H</mi> <mn>1</mn></msub></math> ）：
- en: <math display="block"><mrow><msub><mi>H</mi> <mn>0</mn></msub> <mo>:</mo> <mtext>population</mtext>
    <mtext>mean</mtext> <mo>≥</mo> <mn>18</mn></mrow></math> <math display="block"><mrow><msub><mi>H</mi>
    <mn>1</mn></msub> <mo>:</mo> <mtext>population</mtext> <mtext>mean</mtext> <mo><</mo>
    <mn>18</mn></mrow></math>
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mi>H</mi> <mn>0</mn></msub> <mo>:</mo> <mtext>总体</mtext>
    <mtext>均值</mtext> <mo>≥</mo> <mn>18</mn></mrow></math> <math display="block"><mrow><msub><mi>H</mi>
    <mn>1</mn></msub> <mo>:</mo> <mtext>总体</mtext> <mtext>均值</mtext> <mo><</mo> <mn>18</mn></mrow></math>
- en: To reject our null hypothesis, we need to show that our sample mean of the patients
    who took the drug is not likely to have been coincidental. Since a p-value of
    .05 or less is traditionally considered statistically signficant, we will use
    that as our threshold ([Figure 3-17](#cnqKOunjTF)). When we calculate this in
    Python using the inverse CDF as shown in [Figure 3-18](#DwEsFifKbh) and [Example 3-19](#VgUvpVkMBd),
    we find that approximately 15.53 is the number of recovery days that gives us
    .05 area on the left tail.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 要拒绝我们的零假设，我们需要表明服用药物的患者的样本均值不太可能是巧合的。由于传统上认为小于或等于.05的p值在统计上是显著的，我们将使用这个作为我们的阈值（[图3-17](#cnqKOunjTF)）。当我们在Python中使用逆CDF计算时，如[图3-18](#DwEsFifKbh)和[示例3-19](#VgUvpVkMBd)所示，我们发现大约15.53是给我们左尾部分.05面积的恢复天数。
- en: '![emds 0318](Images/emds_0318.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0318](Images/emds_0318.png)'
- en: Figure 3-18\. Getting the x-value with 5% of area behind it
  id: totrans-275
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-18\. 获取其后面5%面积的x值
- en: Example 3-19\. Python code for getting x-value with 5% of area behind it
  id: totrans-276
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例3-19\. 获取其后面5%面积的x值的Python代码
- en: '[PRE19]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Therefore, if we achieve an average 15.53 or fewer days of recovery time in
    our sample group, our drug is considered statistically significant enough to have
    shown an impact. However, our sample mean of recovery time is actually 16 days
    and does not fall into this null hypothesis rejection zone. Therefore, the statistical
    significance test has failed as shown in [Figure 3-19](#niSmcfcALK).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们在样本组中实现平均15.53天或更少的恢复时间，我们的药物被认为在统计上足够显著地显示了影响。然而，我们的恢复时间的样本均值实际上是16天，不在这个零假设拒绝区域内。因此，如[图3-19](#niSmcfcALK)所示，统计显著性测试失败了。
- en: '![emds 0319](Images/emds_0319.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0319](Images/emds_0319.png)'
- en: Figure 3-19\. We have failed to prove our drug test result is statistically
    significant
  id: totrans-280
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-19\. 我们未能证明我们的药物测试结果在统计上是显著的
- en: The area up to that 16-day mark is our p-value, which is .0912, and we calculate
    it in Python as shown in [Example 3-20](#BRkUBWLuFH).
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 到达那个16天标记的面积是我们的p值，为.0912，并且我们在Python中计算如[示例3-20](#BRkUBWLuFH)所示。
- en: Example 3-20\. Calculating the one-tailed p-value
  id: totrans-282
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例3-20\. 计算单尾p值
- en: '[PRE20]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Since the p-value of .0912 is greater than our statistical significance threshold
    of .05, we do not consider the drug trial a success and fail to reject our null
    hypothesis.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 由于.0912的p值大于我们的统计显著性阈值.05，我们不认为药物试验是成功的，并且未能拒绝我们的零假设。
- en: Two-Tailed Test
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 双尾检验
- en: The previous test we performed is called the one-tailed test because it looks
    for statistical significance only on one tail. However, it is often safer and
    better practice to use a two-tailed test. We will elaborate why, but first let’s
    calculate it.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前进行的测试称为单尾检验，因为它只在一个尾部寻找统计显著性。然而，通常更安全和更好的做法是使用双尾检验。我们将详细说明原因，但首先让我们计算它。
- en: 'To do a *two-tailed test*, we frame our null and alternative hypothesis in
    an “equal” and “not equal” structure. In our drug test, we will say the null hypothesis
    has a mean recovery time of 18 days. But our alternative hypothesis is the mean
    recovery time is not 18 days, thanks to the new drug:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行*双尾检验*，我们将零假设和备择假设构建在“相等”和“不相等”的结构中。在我们的药物测试中，我们会说零假设的平均恢复时间为18天。但我们的备择假设是平均恢复时间不是18天，这要归功于新药物：
- en: <math display="block"><mrow><msub><mi>H</mi> <mn>0</mn></msub> <mo>:</mo> <mtext>population</mtext>
    <mtext>mean</mtext> <mo>=</mo> <mn>18</mn></mrow></math> <math display="block"><mrow><msub><mi>H</mi>
    <mn>1</mn></msub> <mo>:</mo> <mtext>population</mtext> <mtext>mean</mtext> <mo>≠</mo>
    <mn>18</mn></mrow></math>
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mi>H</mi> <mn>0</mn></msub> <mo>:</mo> <mtext>总体</mtext>
    <mtext>均值</mtext> <mo>=</mo> <mn>18</mn></mrow></math> <math display="block"><mrow><msub><mi>H</mi>
    <mn>1</mn></msub> <mo>:</mo> <mtext>总体</mtext> <mtext>均值</mtext> <mo>≠</mo> <mn>18</mn></mrow></math>
- en: This has an important implication. We are structuring our alternative hypothesis
    to not test whether the drug improves cold recovery time, but if it had *any*
    impact. This includes testing if it increased the duration of the cold. Is this
    helpful? Hold that thought.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这有一个重要的含义。我们构建我们的备择假设不是测试药物是否改善感冒恢复时间，而是是否有*任何*影响。这包括测试它是否增加了感冒的持续时间。这有帮助吗？记住这个想法。
- en: Naturally, this means we spread our p-value statistical significance threshold
    to both tails, not just one. If we are testing for a statistical significance
    of 5%, then we split it and give each 2.5% half to each tail. If our drug’s mean
    recovery time falls in either region, our test is successful and we reject the
    null hypothesis ([Figure 3-20](#sSFGsGWdtJ)).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，这意味着我们将 p 值的统计显著性阈值扩展到两个尾部，而不仅仅是一个。如果我们正在测试 5% 的统计显著性，那么我们将其分割，并将每个尾部分配
    2.5%。如果我们的药物的平均恢复时间落在任一区域内，我们的测试将成功，并拒绝零假设（[图 3-20](#sSFGsGWdtJ)）。
- en: '![emds 0320](Images/emds_0320.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0320](Images/emds_0320.png)'
- en: Figure 3-20\. A two-tailed test
  id: totrans-292
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-20\. 双尾检验
- en: The x-values for the lower tail and upper tail are 15.06 and 20.93, meaning
    if we are under or over, respectively, we reject the null hypothesis. Those two
    values are calculated using the inverse CDF shown in [Figure 3-21](#IdTSDnDpVp)
    and [Example 3-21](#tjLSjCvgep). Remember, to get the upper tail we take .95 and
    then add the .025 piece of significance threshold to it, giving us .975.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 下尾和上尾的 x 值分别为 15.06 和 20.93，这意味着如果我们低于或高于这些值，我们将拒绝零假设。这两个值是使用[图 3-21](#IdTSDnDpVp)和[示例 3-21](#tjLSjCvgep)中显示的逆
    CDF 计算的。记住，为了得到上尾，我们取 .95 然后加上显著性阈值的 .025 部分，得到 .975。
- en: '![emds 0321](Images/emds_0321.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0321](Images/emds_0321.png)'
- en: Figure 3-21\. Calculating the central 95% of normal distribution area
  id: totrans-295
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-21\. 计算正态分布中心 95% 的区域
- en: Example 3-21\. Calculating a range for a statistical significance of 5%
  id: totrans-296
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-21\. 计算 5% 统计显著性范围
- en: '[PRE21]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The sample mean value for the drug test group is 16, and 16 is not less than
    15.06 nor greater than 20.9399\. So like the one-tailed test, we still fail to
    reject the null hypothesis. Our drug still has not shown any statistical significance
    to have any impact as shown in [Figure 3-22](#AHaOnNhrAe).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 药物测试组的样本均值为 16，16 既不小于 15.06 也不大于 20.9399。因此，就像单尾检验一样，我们仍然未能拒绝零假设。我们的药物仍然没有显示出任何统计显著性，也没有任何影响，如[图 3-22](#AHaOnNhrAe)所示。
- en: '![emds 0322](Images/emds_0322.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0322](Images/emds_0322.png)'
- en: Figure 3-22\. The two-tailed test has failed to prove statistical significance
  id: totrans-300
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-22\. 双尾检验未能证明统计显著性
- en: But what is the p-value? This is where it gets interesting with two-tailed tests.
    Our p-value is going to capture not just the area to the left of 16 but also the
    symmetrical equivalent area on the right tail. Since 16 is 4 days below the mean,
    we will also capture the area above 20, which is 4 days above the mean ([Figure 3-23](#FoGdeWjlNK)).
    This is capturing the probability of an event or rarer, on both sides of the bell
    curve.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 但是 p 值是什么？这就是双尾检验变得有趣的地方。我们的 p 值将捕捉不仅仅是 16 左侧的区域，还将捕捉右尾的对称等效区域。由于 16 比均值低 4
    天，我们还将捕捉高于 20 的区域，即比均值高 4 天（[图 3-23](#FoGdeWjlNK)）。这是捕捉事件或更罕见事件的概率，位于钟形曲线的两侧。
- en: '![emds 0323](Images/emds_0323.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0323](Images/emds_0323.png)'
- en: Figure 3-23\. The p-value adds symmetrical sides for statistical significance
  id: totrans-303
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-23\. p 值添加对称侧以获得统计显著性
- en: When we sum both those areas, we get a p-value of .1824\. This is a lot greater
    than .05, so it definitely does not pass our p-value threshold of .05 ([Example 3-22](#SaVqCVlGfH)).
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将这两个区域相加时，我们得到一个 p 值为 .1824。这远大于 .05，因此绝对不符合我们的 p 值阈值为 .05（[示例 3-22](#SaVqCVlGfH)）。
- en: Example 3-22\. Calculating the two-tailed p-value
  id: totrans-305
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-22\. 计算双尾 p 值
- en: '[PRE22]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'So why do we also add the symmetrical area on the opposite side in a two-tailed
    test? This may not be the most intuitive concept, but first remember how we structured
    our hypotheses:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 那么为什么在双尾检验中还要添加对称区域的相反侧？这可能不是最直观的概念，但首先记住我们如何构建我们的假设：
- en: <math display="block"><mrow><msub><mi>H</mi> <mn>0</mn></msub> <mo>:</mo> <mtext>population</mtext>
    <mtext>mean</mtext> <mo>=</mo> <mn>18</mn></mrow></math> <math display="block"><mrow><msub><mi>H</mi>
    <mn>1</mn></msub> <mo>:</mo> <mtext>population</mtext> <mtext>mean</mtext> <mo>≠</mo>
    <mn>18</mn></mrow></math>
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mi>H</mi> <mn>0</mn></msub> <mo>:</mo> <mtext>总体</mtext>
    <mtext>均值</mtext> <mo>=</mo> <mn>18</mn></mrow></math> <math display="block"><mrow><msub><mi>H</mi>
    <mn>1</mn></msub> <mo>:</mo> <mtext>总体</mtext> <mtext>均值</mtext> <mo>≠</mo> <mn>18</mn></mrow></math>
- en: If we are testing in an “equals 18” versus “not equals 18” capacity, we have
    to capture any probability that is of equal or less value on both sides. After
    all, we are trying to prove significance, and that includes anything that is equally
    or less likely to happen. We did not have this special consideration with the
    one-tailed test that used only “greater/less than” logic. But when we are dealing
    with “equals/not equals” our interest area goes in both directions.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在“等于18”与“不等于18”的情况下进行测试，我们必须捕捉两侧任何等于或小于的概率。毕竟，我们试图证明显著性，这包括任何同样或更不可能发生的事情。我们在只使用“大于/小于”逻辑的单尾检验中没有这种特殊考虑。但当我们处理“等于/不等于”时，我们的兴趣范围向两个方向延伸。
- en: 'So what are the practical implications of the two-tailed test? How does it
    affect whether we reject the null hypothesis? Ask yourself this: which one sets
    a higher threshold? You will notice that even when our objective is to show we
    may have lessened something (the cold-recovery time using a drug), reframing our
    hypothesis to show any impact (greater or lesser) creates a higher significance
    threshold. If our significance threshold is a p-value of .05 or less, our one-tailed
    test was closer to acceptance at p-value .0912 as opposed to the two-tailed test,
    which was about double that at p-value .182.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 那么双尾检验有什么实际影响？它如何影响我们是否拒绝零假设？问问自己：哪一个设定了更高的阈值？你会注意到，即使我们的目标是表明我们可能减少了某些东西（使用药物减少感冒恢复时间），重新构建我们的假设以显示任何影响（更大或更小）会创建一个更高的显著性阈值。如果我们的显著性阈值是小于或等于0.05的p值，我们的单尾检验在p值0.0912时更接近接受，而双尾检验则是大约两倍的p值0.182。
- en: 'This means the two-tailed test makes it harder to reject the null hypothesis
    and demands stronger evidence to pass a test. Also think of this: what if our
    drug could worsen colds and make them last longer? It may be helpful to capture
    that probability too and account for variation in that direction. This is why
    two-tailed tests are preferable in most cases. They tend to be more reliable and
    not bias the hypothesis in just one direction.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着双尾检验更难拒绝零假设，并需要更强的证据来通过测试。还要考虑这一点：如果我们的药物可能加重感冒并使其持续时间更长呢？捕捉这种可能性并考虑该方向的变化可能会有所帮助。这就是为什么在大多数情况下双尾检验更可取。它们往往更可靠，不会偏向于某一个方向的假设。
- en: We will use hypothesis testing and p-values again in Chapters [5](ch05.xhtml#ch05)
    and [6](ch06.xhtml#ch06).
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第[5](ch05.xhtml#ch05)章和第[6](ch06.xhtml#ch06)章再次使用假设检验和p值。
- en: 'The T-Distribution: Dealing with Small Samples'
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: T分布：处理小样本
- en: Let’s briefly address how to deal with smaller samples of 30 or fewer; we will
    need this when we do linear regression in [Chapter 5](ch05.xhtml#ch05). Whether
    we are calculating confidence intervals or doing hypothesis testing, if we have
    30 or fewer items in a sample we would opt to use a T-distribution instead of
    a normal distribution. The *T-distribution* is like a normal distribution but
    has fatter tails to reflect more variance and uncertainty. [Figure 3-24](#flanKcrbds)
    shows a normal distribution (dashed) alongside a T-distribution with one degree
    of freedom (solid).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要讨论如何处理30个或更少的较小样本；当我们在[第5章](ch05.xhtml#ch05)进行线性回归时，我们将需要这个。无论是计算置信区间还是进行假设检验，如果样本中有30个或更少的项目，我们会选择使用T分布而不是正态分布。*T分布*类似于正态分布，但尾部更胖，以反映更多的方差和不确定性。[图3-24](#flanKcrbds)显示了一个正态分布（虚线）和一个自由度为1的T分布（实线）。
- en: '![emds 0324](Images/emds_0324.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![emds 0324](Images/emds_0324.png)'
- en: Figure 3-24\. The T-distribution alongside a normal distribution; note the fatter
    tails
  id: totrans-316
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-24。T分布与正态分布并列；请注意更胖的尾部。
- en: The smaller the sample size, the fatter the tails get in a T-distribution. But
    what’s interesting is after you approach 31 items, the T-distribution is nearly
    indistinguishable from the normal distribution, which neatly reflects the ideas
    behind the central limit theorem.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 样本大小越小，T分布的尾部就越胖。但有趣的是，在接近31个项目后，T分布几乎无法与正态分布区分开来，这很好地反映了中心极限定理的思想。
- en: '[Example 3-23](#qHcbJNTpsD) shows how to find the *critical t-value* for 95%
    confidence. You can use this for confidence intervals and hypothesis testing when
    you have a sample size of 30 or less. It’s conceptually the same as the critical
    z-value, but we are using a T-distribution instead of a normal distribution to
    reflect greater uncertainty. The smaller the sample size, the larger the range,
    reflecting greater uncertainty.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 3-23](#qHcbJNTpsD)展示了如何找到95%置信度的*临界t值*。当样本量为30或更少时，您可以在置信区间和假设检验中使用这个值。概念上与关键z值相同，但我们使用T分布而不是正态分布来反映更大的不确定性。样本量越小，范围越大，反映了更大的不确定性。'
- en: Example 3-23\. Getting a critical value range with a T-distribution
  id: totrans-319
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-23\. 用T分布获取临界值范围
- en: '[PRE23]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note that `df` is the “degrees of freedom” parameter, and as outlined earlier
    it should be one less of the sample size.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`df`是“自由度”参数，正如前面所述，它应该比样本量少一个。
- en: Big Data Considerations and the Texas Sharpshooter Fallacy
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大数据考虑和得克萨斯神枪手谬误
- en: One final thought before we close this chapter. As we have discussed, randomness
    plays such a role in validating our findings and we always have to account for
    its possibility. Unfortunately with big data, machine learning, and other data-mining
    tools, the scientific method has suddenly become a practice done backward. This
    can be precarious; allow me to demonstrate why, adapting an example from Gary
    Smith’s book *Standard Deviations* (Overlook Press).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束本章之前，最后一个想法。正如我们所讨论的，随机性在验证我们的发现中起着如此重要的作用，我们总是要考虑到它的可能性。不幸的是，随着大数据、机器学习和其他数据挖掘工具的出现，科学方法突然变成了一种倒退的实践。这可能是危险的；请允许我演示一下，从加里·史密斯的书*标准偏差*（Overlook
    Press）中借鉴一个例子。
- en: Let’s pretend I draw four playing cards from a fair deck. There’s no game or
    objective here other than to draw four cards and observe them. I get two 10s,
    a 3, and a 2\. “This is interesting,” I say. “I got two 10s, a 3, and a 2\. Is
    this meaningful? Are the next four cards I draw also going to be two consecutive
    numbers and a pair? What’s the underlying model here?”
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我从一副公平的牌中抽取四张牌。这里没有游戏或目标，只是抽取四张牌并观察它们。我得到两个10，一个3和一个2。我说：“这很有趣，我得到两个10，一个3和一个2。这有意义吗？接下来我抽的四张牌也会是两个连续的数字和一对吗？这里的潜在模型是什么？”
- en: See what I did there? I took something that was completely random and I not
    only looked for patterns, but I tried to make a predictive model out of them.
    What has subtly happened here is I never made it my objective to get these four
    cards with these particular patterns. I observed them *after* they occurred.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 看到我做了什么吗？我拿了完全随机的东西，不仅寻找了模式，而且试图从中建立一个预测模型。这里微妙发生的是，我从未把得到这四张具有特定模式的牌作为我的目标。我是在它们发生*之后*观察到它们。
- en: 'This is exactly what data mining falls victim to every day: finding coincidental
    patterns in random events. With huge amounts of data and fast algorithms looking
    for patterns, it’s easy to find things that look meaningful but actually are just
    random coincidences.'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是数据挖掘每天都会遇到的问题：在随机事件中找到巧合的模式。随着大量数据和快速算法寻找模式，很容易找到看起来有意义但实际上只是随机巧合的东西。
- en: This is also analogous to me firing a gun at a wall. I then draw a target around
    the hole and bring my friends over to show off my amazing marksmanship. Silly,
    right? Well, many people in data science figuratively do this every day and it
    is known as the *Texas Sharpshooter Fallacy*. They set out to act without an objective,
    stumble on something rare, and then point out that what they found somehow creates
    predictive value.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这也类似于我朝墙壁开枪。然后我在弹孔周围画一个靶子，然后邀请朋友过来炫耀我的惊人射击技巧。荒谬，对吧？嗯，很多数据科学家每天都在比喻性地做这件事，这就是*得克萨斯神枪手谬误*。他们开始行动而没有目标，偶然发现了一些罕见的东西，然后指出他们发现的东西在某种程度上具有预测价值。
- en: 'The problem is the law of truly large numbers says rare events are likely to
    be found; we just do not know which ones. When we encounter rare events, we highlight
    and even speculate what might have caused them. The issue is this: the probability
    of a specific person winning the lottery is highly unlikely, but yet someone *is*
    going to win the lottery. Why should we be surprised when there is a winner? Unless
    somebody predicted the winner, nothing meaningful happened other than a random
    person got lucky.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于大数定律表明罕见事件很可能会发生；我们只是不知道是哪些。当我们遇到罕见事件时，我们会突出显示甚至推测可能导致它们的原因。问题在于：某个特定人赢得彩票的概率极低，但总会有人*赢得*彩票。当有人赢得彩票时，我们为什么会感到惊讶？除非有人预测了赢家，否则除了一个随机的人走运之外，没有发生任何有意义的事情。
- en: This also applies to correlations, which we will study in [Chapter 5](ch05.xhtml#ch05).
    With an enormous dataset with thousands of variables, is it easy to find statistically
    significant findings with a .05 p-value? You betcha! I’ll find thousands of those.
    I’ll even show evidence that [the number of Nicolas Cage movies correlates with
    the number of pool drownings in a year](https://oreil.ly/eGxm0).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这也适用于相关性，我们将在[第5章](ch05.xhtml#ch05)中学习。在具有数千个变量的庞大数据集中，很容易找到具有0.05 p值的统计显著性发现吗？当然！我会找到成千上万个这样的发现。我甚至会展示证据表明[尼古拉斯·凯奇电影的数量与一年中溺水的人数相关](https://oreil.ly/eGxm0)。
- en: So to prevent the Texas Sharpshooter Fallacy and falling victim to big data
    fallacies, try to use structured hypothesis testing and gather data for that objective.
    If you utilize data mining, try to obtain fresh data to see if your findings still
    hold up. Finally, always consider the possibility that things can be coincidental;
    if there is not a commonsense explanation, then it probably was coincidental.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了防止得到德克萨斯神枪手谬误并成为大数据谬论的受害者，请尝试使用结构化的假设检验并为此目标收集数据。如果您使用数据挖掘，请尝试获取新鲜数据以查看您的发现是否仍然成立。最后，始终考虑事情可能是巧合的可能性；如果没有常识性的解释，那么很可能是巧合。
- en: We learned how to hypothesize before gathering data, but data mining gathers
    data, then hypothesizes. Ironically, we are often more objective starting with
    a hypothesis, because we then seek out data to deliberately prove and disprove
    our hypothesis.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学会了在收集数据之前进行假设，但数据挖掘是先收集数据，然后进行假设。具有讽刺意味的是，我们在开始时更客观，因为我们会寻找数据来有意识地证明和反驳我们的假设。
- en: Conclusion
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We learned a lot in this chapter, and you should feel good about getting this
    far. This was probably one of the harder topics in this book! We not only learned
    descriptive statistics from the mean to the normal distribution but also tackled
    confidence intervals and hypothesis testing.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章学到了很多，你应该为走到这一步感到自豪。这可能是本书中较难的主题之一！我们不仅学习了从平均值到正态分布的描述性统计，还解决了置信区间和假设检验的问题。
- en: Hopefully, you see data a little differently. It is snapshots of something rather
    than a complete capturing of reality. Data on its own is not very useful, and
    we need context, curiosity, and analysis of where it came from before we can make
    meaningful insights with it. We covered how to describe data as well as infer
    attributes about a larger population based on a sample. Finally, we addressed
    some of the data-mining fallacies we can stumble into if we are not careful, and
    how to remedy that with fresh data and common sense.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你能稍微不同地看待数据。数据是某种东西的快照，而不是对现实的完全捕捉。单独的数据并不是很有用，我们需要背景、好奇心和分析数据来源的地方，然后我们才能对其进行有意义的洞察。我们讨论了如何描述数据以及根据样本推断更大人口的属性。最后，我们解决了一些数据挖掘中可能遇到的谬论，以及如何通过新鲜数据和常识来纠正这些谬论。
- en: Do not feel bad if you need to go back and review some of the content in this
    chapter, because there’s a lot to digest. It is also important to get in the hypothesis-testing
    mindset if you want to be successful at a data science and machine learning career.
    Few practitioners take time to link statistics and hypothesis-testing concepts
    to machine learning, and that is unfortunate.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要回顾本章内容，不要感到难过，因为需要消化的内容很多。如果您想在数据科学和机器学习职业中取得成功，进入假设检验的思维模式也很重要。很少有从业者将统计和假设检验概念与机器学习联系起来，这是不幸的。
- en: Understandability and explainability is the next frontier of machine learning,
    so continue to learn and integrate these ideas as you progress throughout the
    rest of this book and the rest of your career.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 理解性和可解释性是机器学习的下一个前沿，因此在阅读本书的其余部分和职业生涯中继续学习和整合这些想法。
- en: Exercises
  id: totrans-337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'You bought a spool of 1.75 mm filament for your 3D printer. You want to measure
    how close the filament diameter really is to 1.75 mm. You use a caliper tool and
    sample the diameter five times on the spool:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你购买了一卷 1.75 毫米的线材用于你的 3D 打印机。你想测量线材直径与 1.75 毫米的实际接近程度。你使用卡钳工具在卷轴上抽取了五次直径值：
- en: 1.78, 1.75, 1.72, 1.74, 1.77
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 1.78, 1.75, 1.72, 1.74, 1.77
- en: Calculate the mean and standard deviation for this set of values.
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计算这组数值的均值和标准差。
- en: A manufacturer says the Z-Phone smart phone has a mean consumer life of 42 months
    with a standard deviation of 8 months. Assuming a normal distribution, what is
    the probability a given random Z-Phone will last between 20 and 30 months?
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一家制造商表示 Z-Phone 智能手机的平均使用寿命为 42 个月，标准差为 8 个月。假设服从正态分布，一个随机的 Z-Phone 使用寿命在 20
    到 30 个月之间的概率是多少？
- en: I am skeptical that my 3D printer filament is not 1.75 mm in average diameter
    as advertised. I sampled 34 measurements with my tool. The sample mean is 1.715588
    and the sample standard deviation is 0.029252.
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我怀疑我的 3D 打印机线材的平均直径不是广告中宣传的 1.75 毫米。我用我的工具抽取了 34 个测量值。样本均值为 1.715588，样本标准差为
    0.029252。
- en: What is the 99% confidence interval for the mean of my entire spool of filament?
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我整个线轴的均值的 99% 置信区间是多少？
- en: Your marketing department has started a new advertising campaign and wants to
    know if it affected sales, which in the past averaged $10,345 a day with a standard
    deviation of $552\. The new advertising campaign ran for 45 days and averaged
    $11,641 in sales.
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你的营销部门开始了一项新的广告活动，并想知道它是否影响了销售。过去销售额平均为每天 $10,345，标准差为 $552。新的广告活动持续了 45 天，平均销售额为
    $11,641。
- en: Did the campaign affect sales? Why or why not? (Use a two-tailed test for more
    reliable significance.)
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这次广告活动是否影响了销售？为什么？（使用双尾检验以获得更可靠的显著性。）
- en: Answers are in [Appendix B](app02.xhtml#exercise_answers).
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 答案在[附录 B](app02.xhtml#exercise_answers)中。
