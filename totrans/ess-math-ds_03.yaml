- en: Chapter 3\. Descriptive and Inferential Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Statistics* is the practice of collecting and analyzing data to discover findings
    that are useful or predict what causes those findings to happen. Probability often
    plays a large role in statistics, as we use data to estimate how likely an event
    is to happen.'
  prefs: []
  type: TYPE_NORMAL
- en: It may not always get credit, but statistics is the heart of many data-driven
    innovations. Machine learning in itself is a statistical tool, searching for possible
    hypotheses to correlate relationships between different variables in data. However
    there are a lot of blind sides in statistics, even for professional statisticians.
    We can easily get caught up in what the data says that we forget to ask where
    the data comes from. These concerns become all the more important as big data,
    data mining, and machine learning all accelerate the automation of statistical
    algorithms. Therefore, it is important to have a solid foundation in statistics
    and hypothesis testing so you do not treat these automations as black boxes.
  prefs: []
  type: TYPE_NORMAL
- en: In this section we will cover the fundamentals of statistics and hypothesis
    testing. Starting with descriptive statistics, we will learn common ways to summarize
    data. After that, we will venture into inferential statistics, where we try to
    uncover attributes of a population based on a sample.
  prefs: []
  type: TYPE_NORMAL
- en: What Is Data?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It may seem odd to define “data,” something we all use and take for granted.
    But I think it needs to be done. Chances are if you asked any person what data
    is, they might answer to the effect of “you know…data! It’s…you know…information!”
    and not venture farther than that. Now it seems to be marketed as the be-all and
    end-all. The source of not just truth…but intelligence! It’s the fuel for artificial
    intelligence and it is believed that the more data you have, the more truth you
    have. Therefore, you can never have enough data. It will unlock the secrets needed
    to redefine your business strategy and maybe even create artificial general intelligence.
    But let me offer a pragmatic perspective on what data is. Data is not important
    in itself. It’s the analysis of data (and how it is produced) that is the driver
    of all these innovations and solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you were provided a photo of a family. Can you glean this family’s story
    based on this one photo? What if you had 20 photos? 200 photos? 2,000 photos?
    How many photos do you need to know their story? Do you need photos of them in
    different situations? Alone and together? With relatives and friends? At home
    and at work?
  prefs: []
  type: TYPE_NORMAL
- en: '*Data* is just like photographs; it provides snapshots of a story. The continuous
    reality and contexts are not fully captured, nor the infinite number of variables
    driving that story. As we will discuss, data may be biased. It can have gaps and
    be missing relevant variables. Ideally, we would love to have an infinite amount
    of data capturing an infinite number of variables, with so much detail we could
    virtually re-create reality and construct alternate ones! But is this possible?
    Currently, no. Not even the greatest supercomputers in the world combined can
    come close to capturing the entirety of the world as data.'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we have to narrow our scope to make our objectives feasible. A few
    strategic photos of the father playing golf can easily tell us whether he is good
    at golf. But trying to decipher his entire life story just through photos? That
    might be impossible. There is so much that cannot be captured in snapshots. These
    practical concerns should also be applied when working with data projects, because
    data is actually just snapshots of a given time capturing only what it is aimed
    at (much like a camera). We need to keep our objectives focused as this hones
    in on gathering data that is relevant and complete. If we make our objectives
    broad and open-ended, we can get into trouble with spurious findings and incomplete
    datasets. This practice, known as *data mining*, has a time and place but it must
    be done carefully. We will revisit this at the end of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Even with narrowly defined objectives, we can still run into problems with our
    data. Let’s return to the question of determining whether a few strategic photos
    can tell whether the father is good at golf. Perhaps if you had a photo of him
    midswing you would be able to tell if he had good form. Or perhaps if you saw
    him cheering and fist-pumping at a hole, you can infer he got a good score. Maybe
    you can just take a photo of his scorecard! But it’s important to note all these
    instances can be faked or taken out of context. Maybe he was cheering for someone
    else, or maybe the scorecard was not his or even forged. Just like these photographs,
    data does not capture context or explanations. This is an incredibly important
    point because data provides clues, not truth. These clues can lead us to the truth
    or mislead us into erroneous conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: This is why being curious about where data comes from is such an important skill.
    Ask questions about how the data was created, who created it, and what the data
    is not capturing. It is too easy to get caught up in what the data says and forget
    to ask where it came from. Even worse there are widespread sentiments that one
    can shovel data into machine learning algorithms and expect the computer to work
    it all out. But as the adage goes, “garbage in, garbage out.” No wonder only [13%
    of machine learning projects succeed, according to VentureBeat](https://oreil.ly/8hFrO).
    Successful machine learning projects put thought and analysis into the data, as
    well as what produced the data.
  prefs: []
  type: TYPE_NORMAL
- en: Descriptive Versus Inferential Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What comes to mind when you hear the word “statistics”? Is it calculating mean,
    median, mode, charts, bell curves, and other tools to describe data? This is the
    most commonly understood part of statistics, called *descriptive statistics*,
    and we use it to summarize data. After all, is it more meaningful to scroll through
    a million records of data or have it summarized? We will cover this area of statistics
    first.
  prefs: []
  type: TYPE_NORMAL
- en: '*Inferential statistics* tries to uncover attributes about a larger population,
    often based on a sample. It is often misunderstood and less intuitive than descriptive
    statistics. Often we are interested in studying a group that is too large to observe
    (e.g., average height of adolescents in North America) and we have to resort to
    using only a few members of that group to infer conclusions about them. As you
    can guess, this is not easy to get right. After all, we are trying to represent
    a population with a sample that may not be representative. We will explore these
    caveats along the way.'
  prefs: []
  type: TYPE_NORMAL
- en: Populations, Samples, and Bias
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we dive deeper into descriptive and inferential statistics, it might
    be a good idea to lay out some definitions and relate them to tangible examples.
  prefs: []
  type: TYPE_NORMAL
- en: A *population* is a particular group of interest we want to study, such as “all
    seniors over the age of 65 in the North America,” “all golden retrievers in Scotland,”
    or “current high school sophomores at Los Altos High School.” Notice how we have
    boundaries on defining our population. Some of these boundaries are broad and
    capture a large group over a vast geography or age group. Others are highly specific
    and small such as the sophomores at Los Altos High School. How you hone in on
    defining a population depends on what you are interested in studying.
  prefs: []
  type: TYPE_NORMAL
- en: A *sample* is a subset of the population that is ideally random and unbiased,
    which we use to infer attributes about the population. We often have to study
    samples because polling the entire population is not always possible. Of course,
    some populations are easier to get hold of if they are small and accessible. But
    measuring all seniors over 65 in North America? That is unlikely to be practical!
  prefs: []
  type: TYPE_NORMAL
- en: Populations Can Be Abstract!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is important to note that populations can be theoretical and not physically
    tangible. In these cases our population acts more like a sample from something
    abstract. Here’s my favorite example: we are interested in flights that depart
    between 2 p.m. and 3 p.m. at an airport, but we lack enough flights at that time
    to reliably predict how often these flights are late. Therefore, we may treat
    this population as a sample instead from an underlying population of all theoretical
    flights taking off between 2 p.m. and 3 p.m.'
  prefs: []
  type: TYPE_NORMAL
- en: Problems like this are why many researchers resort to simulations to generate
    data. Simulations can be useful but rarely are accurate, as simulations capture
    only so many variables and have assumptions built in.
  prefs: []
  type: TYPE_NORMAL
- en: If we are going to infer attributes about a population based on a sample, it’s
    important the sample be as random as possible so we do not skew our conclusions.
    Here’s an example. Let’s say I’m a college student at Arizona State University.
    I want to find the average number of hours college students watch television per
    week in the United States. I walk right outside my dorm and start polling random
    students walking by, finishing my data gathering in a few hours. What’s the problem
    here?
  prefs: []
  type: TYPE_NORMAL
- en: The problem is our student sample is going to have *bias*, meaning it skews
    our findings by overrepresenting a certain group at the expense of other groups.
    My study defined the population to be “college students in the United States,”
    not “college students at Arizona State University.” I am only polling students
    at one specific university to represent all college students in the entire United
    States! Is that really fair?
  prefs: []
  type: TYPE_NORMAL
- en: It is unlikely all colleges across the country homogeneously have the same student
    attributes. What if Arizona State students watch far more TV than other students
    at other universities? Would using them to represent the entire country not distort
    the results? Maybe this is possible because it is usually too hot to go outside
    in Tempe, Arizona. Therefore TV is a common pastime (anecdotally, I would know;
    I lived in Phoenix for many years). Other college students in milder climates
    may do more outdoor activities and watch less TV.
  prefs: []
  type: TYPE_NORMAL
- en: This is just one possible variable showing why it’s a bad idea to represent
    college students across the entire United States with just a sample of students
    from one university. Ideally, I should be randomly polling college students all
    over the country at different universities. That way I have a more representative
    sample.
  prefs: []
  type: TYPE_NORMAL
- en: However, bias is not always geographic. Let’s say I make a sincere effort to
    poll students across the United States. I arrange a social media campaign to have
    a poll shared by various universities on Twitter and Facebook. This way their
    students see it and hopefully fill it out. I get hundreds of responses on students’
    TV habits across the country and feel I’ve conquered the bias beast…or have I?
  prefs: []
  type: TYPE_NORMAL
- en: What if students who are on social media enough to see the poll are also likely
    to watch more TV? If they are on social media a lot, they probably do not mind
    recreational screen time. It’s easy to imagine they have Netflix and Hulu ready
    to stream on that other tab! This particular type of bias where a specific group
    is more likely to include themselves in a sample is known as *self-selection bias*.
  prefs: []
  type: TYPE_NORMAL
- en: Darn it! You just can’t win, can you? If you think about it long enough, data
    bias just feels inevitable! And often it is. So many *confounding variables*,
    or factors we did not account for, can influence our study. This problem of data
    bias is expensive and difficult to overcome, and machine learning is especially
    vulnerable to it.
  prefs: []
  type: TYPE_NORMAL
- en: The way to overcome this problem is to truly at random select students from
    the entire population, and they cannot elect themselves into or out of the sample
    voluntarily. This is the most effective way to mitigate bias, but as you can imagine,
    it takes a lot of coordinated resources to do.
  prefs: []
  type: TYPE_NORMAL
- en: Alright, enough talk about populations, samples, and bias. Let’s move on to
    some math and descriptive statistics. Just remember that math and computers do
    not recognize bias in your data. That is on you as a good data science professional
    to detect! Always ask questions about how the data was obtained, and then scrutinize
    how that process could have biased the data.
  prefs: []
  type: TYPE_NORMAL
- en: Samples and Bias in Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These problems with sampling and bias extends to machine learning as well. Whether
    it is linear regression, logistic regression, or neural networks, a sample of
    data is used to infer predictions. If that data is biased then it will steer the
    machine learning algorithm to make biased conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: There are many documented cases of this. Criminal justice has been a precarious
    application of machine learning because it has repeatedly shown to be biased in
    every sense of the word, discriminating against minorities due to minority-heavy
    datasets. In 2017, Volvo tested self-driving cars that were trained on datasets
    capturing deer, elk, and caribou. However, it had no driving data in Australia
    and therefore could not recognize kangaroos, much less make sense of their jumping
    movements! Both of these are examples of biased data.
  prefs: []
  type: TYPE_NORMAL
- en: Descriptive Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Descriptive statistics is the area most people are familiar with. We will touch
    on the basics like mean, median, and mode followed by variance, standard deviation,
    and the normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Mean and Weighted Mean
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The *mean* is the average of a set of values. The operation is simple to do:
    sum the values and divide by the number of values. The mean is useful because
    it shows where the “center of gravity” exists for an observed set of values.'
  prefs: []
  type: TYPE_NORMAL
- en: The mean is calculated the same way for both populations and samples. [Example 3-1](#sOAVldvmng)
    shows a sample of eight values and how to calculate their mean in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-1\. Calculating mean in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we polled eight people on the number of pets they own. The sum
    of the sample is 23 and the number of items in the sample is 8, so this gives
    us a mean of 2.875 as 23/8 = 2.875.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two versions of the mean you will see: the sample mean <math alttext="x
    overbar"><mover><mi>x</mi> <mo>¯</mo></mover></math> and the population mean <math
    alttext="mu"><mi>μ</mi></math> as expressed here:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mover><mi>x</mi>
    <mo>¯</mo></mover> <mo>=</mo> <mfrac><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo><msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo><msub><mi>x</mi> <mn>3</mn></msub>
    <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msub><mi>x</mi> <mi>n</mi></msub></mrow>
    <mi>n</mi></mfrac> <mo>=</mo> <munderover><mo>∑</mo></munderover> <mfrac><msub><mi>x</mi>
    <mi>i</mi></msub> <mi>n</mi></mfrac></mrow></mtd></mtr></mtable></math> <math
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>μ</mi>
    <mo>=</mo> <mfrac><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>+</mo><msub><mi>x</mi> <mn>3</mn></msub> <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msub><mi>x</mi>
    <mi>n</mi></msub></mrow> <mi>N</mi></mfrac> <mo>=</mo> <munderover><mo>∑</mo></munderover>
    <mfrac><msub><mi>x</mi> <mi>i</mi></msub> <mi>N</mi></mfrac></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall the summation symbol <math alttext="sigma-summation"><mo>∑</mo></math>
    means add all the items together. The *n* and the *N* represent the sample and
    population size, respectively, but mathematically they represent the same thing:
    the number of items. The same goes for calling the sample mean <math alttext="x
    overbar"><mover><mi>x</mi> <mo>¯</mo></mover></math> (“x-bar”) and the population
    mean <math alttext="mu"><mi>μ</mi></math> (“mu”). Both <math alttext="x overbar"><mover><mi>x</mi>
    <mo>¯</mo></mover></math> and <math alttext="mu"><mi>μ</mi></math> are the same
    calculation, just different names depending on whether it’s a sample or population
    we are working with.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean is likely familiar to you, but here’s something less known about the
    mean: the mean is actually a weighted average called the *weighted mean*. The
    mean we commonly use gives equal importance to each value. But we can manipulate
    the mean and give each item a different weight:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="weighted mean equals StartFraction left-parenthesis x 1 dot w
    1 right-parenthesis plus left-parenthesis x 2 dot w 2 right-parenthesis plus left-parenthesis
    x 3 dot w 3 right-parenthesis plus period period period left-parenthesis x Subscript
    n Baseline dot w Subscript n Baseline right-parenthesis Over w 1 plus w 2 plus
    w 3 plus period period period plus w Subscript n Baseline EndFraction" display="block"><mrow><mtext>weighted</mtext>
    <mtext>mean</mtext> <mo>=</mo> <mfrac><mrow><mrow><mo>(</mo><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>·</mo><msub><mi>w</mi> <mn>1</mn></msub> <mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>·</mo><msub><mi>w</mi> <mn>2</mn></msub> <mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>3</mn></msub> <mo>·</mo><msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow><mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>n</mi></msub> <mo>·</mo><msub><mi>w</mi> <mi>n</mi></msub> <mo>)</mo></mrow></mrow>
    <mrow><msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo><msub><mi>w</mi> <mn>2</mn></msub>
    <mo>+</mo><msub><mi>w</mi> <mn>3</mn></msub> <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msub><mi>w</mi>
    <mi>n</mi></msub></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This can be helpful when we want some values to contribute to the mean more
    than others. A common example of this is weighting academic exams to give a final
    grade. If you have three exams and a final exam, and we give each of the three
    exams 20% weight and the final exam 40% weight of the final grade, how we express
    it is in [Example 3-2](#lquLdtDTuF).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-2\. Calculating a weighted mean in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We weight each exam score through multiplication accordingly and instead of
    dividing by the value count, we divide by the sum of weights. Weightings don’t
    have to be percentages, as any numbers used for weights will end up being proportionalized.
    In [Example 3-3](#TbhpvAuILG), we weight each exam with “1” but weight the final
    exam with “2,” giving it twice the weight of the exams. We will still get the
    same answer of 81.4 as these values will still be proportionalized.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-3\. Calculating a weighted mean in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Median
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The *median* is the middlemost value in a set of ordered values. You sequentially
    order the values, and the median will be the centermost value. If you have an
    even number of values, you average the two centermost values. We can see in [Example 3-4](#uFgEneENrp)
    that the median number of pets owned in our sample is 7:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Example 3-4\. Calculating the median in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The median can be a helpful alternative to the mean when data is skewed by *outliers*,
    or values that are extremely large and small compared to the rest of the values.
    Here’s an interesting anecdote to understand why. In 1986, the mean annual starting
    salary of geography graduates from the University of North Carolina at Chapel
    Hill was $250,000\. Other universities averaged $22,000\. Wow, UNC-CH must have
    an amazing geography program!
  prefs: []
  type: TYPE_NORMAL
- en: But in reality, what was so lucrative about UNC’s geography program? Well…Michael
    Jordan was one of their graduates. One of the most famous NBA players of all time
    indeed graduated with a geography degree from UNC. However, he started his career
    playing basketball, not studying maps. Obviously, this is a confounding variable
    that has created a huge outlier, and it majorly skewed the income average.
  prefs: []
  type: TYPE_NORMAL
- en: This is why the median can be preferable in outlier-heavy situations (such as
    income-related data) over the mean. It is less sensitive to outliers and cuts
    data strictly down the middle based on their relative order, rather than where
    they fall exactly on a number line. When your median is very different from your
    mean, that means you have a skewed dataset with outliers.
  prefs: []
  type: TYPE_NORMAL
- en: Mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *mode* is the most frequently occurring set of values. It primarily becomes
    useful when your data is repetitive and you want to find which values occur the
    most frequently.
  prefs: []
  type: TYPE_NORMAL
- en: When no value occurs more than once, there is no mode. When two values occur
    with an equal amount of frequency, then the dataset is considered *bimodal*. In
    [Example 3-5](#svAgdpFjKu) we calculate the mode for our pet dataset, and sure
    enough we see this is bimodal as both 2 and 3 occur the most (and equally) as
    often.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-5\. Calculating the mode in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In practicality, the mode is not used a lot unless your data is repetitive.
    This is commonly encountered with integers, categories, and other discrete variables.
  prefs: []
  type: TYPE_NORMAL
- en: Variance and Standard Deviation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we start talking about variance and standard deviation, this is where it
    gets interesting. One thing that confuses people with variance and standard deviation
    is there are some calculation differences for the sample versus the population.
    We will do our best to cover these differences clearly.
  prefs: []
  type: TYPE_NORMAL
- en: Population Variance and Standard Deviation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In describing data, we are often interested in measuring the differences between
    the mean and every data point. This gives us a sense of how “spread out” the data
    is.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say I’m interested in studying the number of pets owned by members of
    my work staff (note that I’m defining this as my population, not a sample). I
    have seven people on my staff.
  prefs: []
  type: TYPE_NORMAL
- en: I take the mean of all the numbers of pets they own, and I get 6.571\. Let’s
    subtract this mean from each value. This will show us how far each value is from
    the mean as shown in [Table 3-1](#WJeDlEQbNR).
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-1\. Number of pets my staff owns
  prefs: []
  type: TYPE_NORMAL
- en: '| Value | Mean | Difference |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 6.571 | -6.571 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 6.571 | -5.571 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 6.571 | -1.571 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 6.571 | 0.429 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 6.571 | 2.429 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 6.571 | 3.429 |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | 6.571 | 7.429 |'
  prefs: []
  type: TYPE_TB
- en: Let’s visualize this on a number line with “X” showing the mean in [Figure 3-1](#egJmAmDQtl).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0301](Images/emds_0301.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-1\. Visualizing the spread of our data, where “X” is the mean
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Hmmm…now consider why this information can be useful. The differences give us
    a sense of how spread out the data is and how far values are from the mean. Is
    there a way we can consolidate these differences into a single number to quickly
    describe how spread out the data is?
  prefs: []
  type: TYPE_NORMAL
- en: You may be tempted to take the average of the differences, but the negatives
    and positives will cancel each other out when they are summed. We could sum the
    absolute values (rid the negative signs and make all values positive). An even
    better approach would be to square these differences before summing them. This
    not only rids the negative values (because squaring a negative number makes it
    positive), but it amplifies larger differences and is mathematically easier to
    work with (derivatives are not straightforward with absolute values). After that,
    average the squared differences. This will give us the *variance*, a measure of
    how spread out our data is.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a math formula showing how to calculate variance:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="population variance equals StartFraction left-parenthesis x 1
    minus m e a n right-parenthesis squared plus left-parenthesis x 2 minus m e a
    n right-parenthesis squared plus period period period plus left-parenthesis x
    Subscript n Baseline minus m e a n right-parenthesis squared Over upper N EndFraction"
    display="block"><mrow><mtext>population</mtext> <mtext>variance</mtext> <mo>=</mo>
    <mfrac><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>+</mo><msup><mrow><mo>(</mo><msub><mi>x</mi> <mn>2</mn></msub>
    <mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>)</mo></mrow> <mn>2</mn></msup>
    <mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>n</mi></msub> <mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mi>N</mi></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'More formally, here is the variance for a population:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sigma squared equals StartFraction sigma-summation left-parenthesis
    x Subscript i Baseline minus mu right-parenthesis squared Over upper N EndFraction"
    display="block"><mrow><msup><mi>σ</mi> <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the population variance of our pet example in Python is shown in
    [Example 3-6](#HSvEsubgVk).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-6\. Calculating variance in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: So the variance for number of pets owned by my office staff is 21.387755\. OK,
    but what does it exactly mean? It’s reasonable to conclude that a higher variance
    means more spread, but how do we relate this back to our data? This number is
    larger than any of our observations because we did a lot squaring and summing,
    putting it on an entirely different metric. So how do we squeeze it back down
    so it’s back on the scale we started with?
  prefs: []
  type: TYPE_NORMAL
- en: 'The opposite of a square is a square root, so let’s take the square root of
    the variance, which gives us the *standard deviation*. This is the variance scaled
    into a number expressed in terms of “number of pets,” which makes it a bit more
    meaningful:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sigma equals StartRoot StartFraction sigma-summation left-parenthesis
    x Subscript i Baseline minus mu right-parenthesis squared Over upper N EndFraction
    EndRoot" display="block"><mrow><mi>σ</mi> <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></msqrt></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: To implement in Python, we can reuse the `variance()` function and `sqrt()`
    its result. We now have a `std_dev()` function, shown in [Example 3-7](#WjBdnoKtlB).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-7\. Calculating standard deviation in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Running the code in [Example 3-7](#WjBdnoKtlB), you will see our standard deviation
    is approximately 4.62 pets. So we can express our spread on a scale we started
    with, and this makes our variance a bit easier to interpret. We will see some
    important applications of the standard deviation in [Chapter 5](ch05.xhtml#ch05).
  prefs: []
  type: TYPE_NORMAL
- en: Why the Square?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regarding variance, if the exponent in <math alttext="sigma squared"><msup><mi>σ</mi>
    <mn>2</mn></msup></math> bothers you, it’s because it is prompting you to take
    the square root of it to get the standard deviation. It’s a little nagging reminder
    you are dealing with squared values that need to be square-rooted.
  prefs: []
  type: TYPE_NORMAL
- en: Sample Variance and Standard Deviation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous section we talked about variance and standard deviation for
    a population. However, there is an important tweak we need to apply to these two
    formulas when we calculate for a sample:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>s</mi>
    <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>s</mi>
    <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></msqrt></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: Did you catch the difference? When we average the squared differences, we divide
    by *n*–1 rather than the total number of items *n*. Why would we do this? We do
    this to decrease any bias in a sample and not underestimate the variance of the
    population based on our sample. By counting values short of one item in our divisor,
    we increase the variance and therefore capture greater uncertainty in our sample.
  prefs: []
  type: TYPE_NORMAL
- en: If our pets data were a sample, not a population, we should make that adjustment
    accordingly. In [Example 3-8](#pRSherqejI), I modify my previous `variance()`
    and `std_dev()` Python code to optionally provide a parameter `is_sample`, which
    if `True` will subtract 1 from the divisor in the variance.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-8\. Calculating standard deviation for a sample
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Notice in [Example 3-8](#pRSherqejI) my variance and standard deviation have
    increased compared to previous examples that treated them as a population, not
    a sample. Recall in [Example 3-7](#WjBdnoKtlB) that the standard deviation was
    about 4.62 treating as a population. But here treating as a sample (by subtracting
    1 from the variance denominator), we get approximately 4.99\. This is correct
    as a sample could be biased and imperfect representing the population. Therefore,
    we increase the variance (and thus the standard deviation) to increase our estimate
    of how spread out the values are. A larger variance/standard deviation shows less
    confidence with a larger range.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like the mean ( <math alttext="x overbar"><mover><mi>x</mi> <mo>¯</mo></mover></math>
    for sample and <math alttext="mu"><mi>μ</mi></math> for population), you will
    often see certain symbols for variance and standard deviation. The standard deviation
    for a sample and mean are specified by *s* and <math alttext="sigma"><mi>σ</mi></math>
    , respectively. Here again are the sample and population standard deviation formulas:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>s</mi>
    <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></msqrt></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>σ</mi>
    <mo>=</mo> <msqrt><mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></msqrt></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The variance will be the square of these two formulas, undoing the square root.
    Therefore, the variance for sample and population are <math alttext="s squared"><msup><mi>s</mi>
    <mn>2</mn></msup></math> and <math alttext="sigma squared"><msup><mi>σ</mi> <mn>2</mn></msup></math>
    , respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>s</mi>
    <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>σ</mi>
    <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mo>∑</mo><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mi>μ</mi><mo>)</mo></mrow> <mn>2</mn></msup></mrow>
    <mi>N</mi></mfrac></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: Again, the square helps imply that a square root should be taken to get the
    standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: The Normal Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We touched on probability distributions in the last chapter, particularly the
    binomial distribution and beta distribution. However the most famous distribution
    of all is the normal distribution. The *normal distribution*, also known as the
    *Gaussian distribution*, is a symmetrical bell-shaped distribution that has most
    mass around the mean, and its spread is defined as a standard deviation. The “tails”
    on either side become thinner as you move away from the mean.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3-2](#BKlqpacWKn) is a normal distribution for golden retriever weights.
    Notice how most of the mass is around the mean of 64.43 pounds.'
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0302](Images/emds_0302.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-2\. A normal distribution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Discovering the Normal Distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The normal distribution is seen a lot in nature, engineering, science, and other
    domains. How do we discover it? Let’s say we sample the weight of 50 adult golden
    retrievers and plot them on a number line as shown in [Figure 3-3](#vtFcGtuatD).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0303](Images/emds_0303.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-3\. A sample of 50 golden retriever weights
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Notice how we have more values toward the center, but as we move farther left
    or right we see fewer values. Based on our sample, it seems highly unlikely we
    would see a golden retriever with a weight of 57 or 71\. But having a weight of
    64 or 65? Yeah, that certainly seems likely.
  prefs: []
  type: TYPE_NORMAL
- en: Is there a better way to visualize this likelihood to see which golden retriever
    weights we are more likely to see sampled from the population? We can try to create
    a *histogram*, which buckets (or “bins”) up values based on numeric ranges of
    equal length, and then uses a bar chart showing the number of values within each
    range. In [Figure 3-4](#TjJQqiIbsG) we create a histogram that bins up values
    in ranges of .5 pounds.
  prefs: []
  type: TYPE_NORMAL
- en: This histogram does not reveal any meaningful shape to our data. The reason
    is because our bins are too small. We do not have an extremely large or infinite
    amount of data to meaningfully have enough points in each bin. Therefore we will
    have to make our bins larger. Let’s make the bins each have a length of three
    pounds, as in [Figure 3-5](#SBRNaBNfkM).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0304](Images/emds_0304.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-4\. A histogram of golden retriever weights
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![emds 0305](Images/emds_0305.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-5\. A more productive histogram
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now we are getting somewhere! As you can see, if we get the bin sizes just right
    (in this case, each has a range of three pounds), we start to get a meaningful
    bell shape to our data. It’s not a perfect bell shape because our samples are
    never going to be perfectly representative of the population, but this is likely
    evidence our sample follows a normal distribution. If we fit a histogram with
    adequate bin sizes, and scale it so it has an area of 1.0 (which a probability
    distribution requires), we see a rough bell curve representing our sample. Let’s
    show it alongside our original data points in [Figure 3-6](#EtIlwoQQLS).
  prefs: []
  type: TYPE_NORMAL
- en: Looking at this bell curve, we can reasonably expect a golden retriever to have
    a weight most likely around 64.43 (the mean) but unlikely at 55 or 73\. Anything
    more extreme than that becomes very unlikely.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0306](Images/emds_0306.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-6\. A normal distribution fitted to data points
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Properties of a Normal Distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The normal distribution has several important properties that make it useful:'
  prefs: []
  type: TYPE_NORMAL
- en: It’s symmetrical; both sides are identically mirrored at the mean, which is
    the center.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most mass is at the center around the mean.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a spread (being narrow or wide) that is specified by standard deviation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The “tails” are the least likely outcomes and approach zero infinitely but never
    touch zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It resembles a lot of phenomena in nature and daily life, and even generalizes
    nonnormal problems because of the central limit theorem, which we will talk about
    shortly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Probability Density Function (PDF)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The standard deviation plays an important role in the normal distribution,
    because it defines how “spread out” it is. It is actually one of the parameters
    alongside the mean. The *probability density function (PDF)* that creates the
    normal distribution is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="f left-parenthesis x right-parenthesis equals StartFraction 1
    Over sigma EndFraction asterisk StartRoot 2 pi EndRoot asterisk e Superscript
    minus one-half left-parenthesis StartFraction x minus mu Over sigma EndFraction
    squared right-parenthesis" display="block"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mfrac><mn>1</mn> <mi>σ</mi></mfrac> <mo>*</mo> <msqrt><mrow><mn>2</mn>
    <mi>π</mi></mrow></msqrt> <mo>*</mo> <msup><mi>e</mi> <mrow><mo>-</mo><mfrac><mn>1</mn>
    <mn>2</mn></mfrac><mrow><mo>(</mo><msup><mfrac><mrow><mi>x</mi><mo>-</mo><mi>μ</mi></mrow>
    <mi>σ</mi></mfrac> <mn>2</mn></msup> <mo>)</mo></mrow></mrow></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Wow that’s a mouthful, isn’t it? We even see our friend Euler’s Number <math
    alttext="e"><mi>e</mi></math> from [Chapter 1](ch01.xhtml#ch01) and some crazy
    exponents. Here is how we can express it in Python in [Example 3-9](#sCChGpgKUG).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-9\. The normal distribution function in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: There’s a lot to take apart here in this formula, but what’s important is that
    it accepts a mean and standard deviation as parameters, as well as an x-value
    so you can look up the likelihood at that given value.
  prefs: []
  type: TYPE_NORMAL
- en: Just like the beta distribution in [Chapter 2](ch02.xhtml#ch02), the normal
    distribution is continuous. This means to retrieve a probability we need to integrate
    a range of *x* values to find an area.
  prefs: []
  type: TYPE_NORMAL
- en: In practice though, we will use SciPy to do these calculations for us.
  prefs: []
  type: TYPE_NORMAL
- en: The Cumulative Distribution Function (CDF)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the normal distribution, the vertical axis is not the probability but rather
    the likelihood for the data. To find the probability we need to look at a given
    range, and then find the area under the curve for that range. Let’s say I want
    to find the probability of a golden retriever weighing between 62 and 66 pounds.
    [Figure 3-7](#dJHChnUOST) shows the range we want to find the area for.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0307](Images/emds_0307.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-7\. A CDF measuring probability between 62 and 66 pounds
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We already did this task in [Chapter 2](ch02.xhtml#ch02) with the beta distribution,
    and just like the beta distribution there is a cumulative density function (CDF).
    Let’s follow this approach.
  prefs: []
  type: TYPE_NORMAL
- en: As we learned in the last chapter, the CDF provides the area *up to* a given
    x-value for a given distribution. Let’s see what the CDF looks like for our golden
    retriever normal distribution and put it alongside the PDF for reference in [Figure 3-8](#ueeLmpiIon).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0308](Images/emds_0308.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-8\. A PDF alongside its CDF
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Notice there’s a relationship between the two graphs. The CDF, which is an S-shaped
    curve (called a sigmoid curve), projects the area up to that range in the PDF.
    Observe in [Figure 3-9](#gOlcaGmALR) that when we capture the area from negative
    infinity up to 64.43 (the mean), our CDF shows a value of exactly .5 or 50%!
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0309](Images/emds_0309.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-9\. A PDF and CDF for golden retriever weights measuring probability
    up to the mean
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This area of .5 or 50% up to the mean is known because of the symmetry of our
    normal distribution, and we can expect the other side of the bell curve to also
    have 50% of the area.
  prefs: []
  type: TYPE_NORMAL
- en: To calculate this area up to 64.43 in Python using SciPy, use the `norm.cdf()`
    function as shown in [Example 3-10](#UQGWRWMSRm).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-10\. The normal distribution CDF in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Just like we did in [Chapter 2](ch02.xhtml#ch02), we can deductively find the
    area for a middle range by subtracting areas. If we wanted to find the probability
    of observing a golden retriever between 62 and 66 pounds, we would calculate the
    area up to 66 and subtract the area up to 62 as visualized in [Figure 3-10](#fJPuwPHaRa).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0310](Images/emds_0310.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-10\. Finding a middle range of probability
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Doing this in Python using SciPy is as simple as subtracting the two CDF operations
    shown in [Example 3-11](#FIrGMukClQ).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-11\. Getting a middle range probability using the CDF
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: You should find the probability of observing a golden retriever between 62 and
    66 pounds to be 0.4920, or approximately 49.2%.
  prefs: []
  type: TYPE_NORMAL
- en: The Inverse CDF
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we start doing hypothesis testing later in this chapter, we will encounter
    situations where we need to look up an area on the CDF and then return the corresponding
    x-value. Of course this is a backward usage of the CDF, so we will need to use
    the inverse CDF, which flips the axes as shown in [Figure 3-11](#IWjuSwEAcw).
  prefs: []
  type: TYPE_NORMAL
- en: This way, we can now look up a probability and then return the corresponding
    x-value, and in SciPy we would use the `norm.ppf()` function. For example, I want
    to find the weight that 95% of golden retrievers fall under. This is easy to do
    when I use the inverse CDF in [Example 3-12](#nbHwvKHrPf).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0311](Images/emds_0311.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-11\. The inverse CDF, also called the PPF or quantile function
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Example 3-12\. Using the inverse CDF (called `ppf()`) in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: I find that 95% of golden retrievers are 69.348 or fewer pounds.
  prefs: []
  type: TYPE_NORMAL
- en: You can also use the inverse CDF to generate random numbers that follow the
    normal distribution. If I want to create a simulation that generates one thousand
    realistic golden retriever weights, I just generate a random value between 0.0
    and 1.0, pass it to the inverse CDF, and return the weight value as shown in [Example 3-13](#jEhKndTTjH).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-13\. Generating random numbers from a normal distribution
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Of course NumPy and other libraries can generate random values off a distribution
    for you, but this highlights one use case where the inverse CDF is handy.
  prefs: []
  type: TYPE_NORMAL
- en: CDF and Inverse CDF from Scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To learn how to implement the CDF and inverse CDF from scratch in Python, refer
    to [Appendix A](app01.xhtml#appendix).
  prefs: []
  type: TYPE_NORMAL
- en: Z-Scores
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is common to rescale a normal distribution so that the mean is 0 and the
    standard deviation is 1, which is known as the *standard normal distribution*.
    This makes it easy to compare the spread of one normal distribution to another
    normal distribution, even if they have different means and variances.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of particular importance with the standard normal distribution is it expresses
    all x-values in terms of standard deviations, known as *Z-scores*. Turning an
    x-value into a Z-score uses a basic scaling formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign z equals StartFraction x minus mu Over sigma EndFraction
    dollar-sign"><mrow><mi>z</mi> <mo>=</mo> <mfrac><mrow><mi>x</mi><mo>-</mo><mi>μ</mi></mrow>
    <mi>σ</mi></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example. We have two homes from two different neighborhoods. Neighborhood
    A has a mean home value of $140,000 and standard deviation of $3,000\. Neighborhood
    B has a mean home value of $800,000 and standard deviation of $10,000.
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>μ</mi> <mi>A</mi></msub> <mo>=</mo> <mn>140,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>μ</mi> <mi>B</mi></msub> <mo>=</mo> <mn>800,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>σ</mi> <mi>A</mi></msub> <mo>=</mo> <mn>3,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>σ</mi> <mi>B</mi></msub> <mo>=</mo> <mn>10,000</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Now we have two homes from each neighborhood. House A from neighborhood A is
    worth $150,000 and house B from neighborhood B is worth $815,000\. Which home
    is more expensive relative to the average home in its neighborhood?
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>x</mi> <mi>A</mi></msub> <mo>=</mo> <mn>150,000</mn></mrow></math>
    <math display="block"><mrow><msub><mi>x</mi> <mi>B</mi></msub> <mo>=</mo> <mn>815,000</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If we express these two values in terms of standard deviations, we can compare
    them relative to each neighborhood mean. Use the Z-score formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>z</mi>
    <mo>=</mo> <mfrac><mrow><mi>x</mi><mo>-</mo><mtext>mean</mtext></mrow> <mrow><mtext>standard</mtext><mtext>deviation</mtext></mrow></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>z</mi>
    <mi>A</mi></msub> <mo>=</mo> <mfrac><mrow><mn>150000</mn><mo>-</mo><mn>140000</mn></mrow>
    <mn>3000</mn></mfrac> <mo>=</mo> <mn>3.</mn> <mover><mn>333</mn> <mo>¯</mo></mover></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>z</mi>
    <mi>B</mi></msub> <mo>=</mo> <mfrac><mrow><mn>815000</mn><mo>-</mo><mn>800000</mn></mrow>
    <mn>10000</mn></mfrac> <mo>=</mo> <mn>1.5</mn></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: So the house in neighborhood A is actually much more expensive relative to its
    neighborhood than the house in neighborhood B, as they have Z-scores of <math
    display="inline"><mrow><mn>3.</mn> <mover><mn>333</mn> <mo>¯</mo></mover></mrow></math>
    and 1.5, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Here is how we can convert an x-value coming from a given distribution with
    a mean and standard deviation into a Z-score, and vice versa, as shown in [Example 3-14](#wDIlIrjbrg).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-14\. Turn Z-scores into x-values and vice versa
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `z_score()` function will take an x-value and scale it in terms of standard
    deviations, given a mean and standard deviation. The `z_to_x()` function takes
    a Z-score and converts it back to an x-value. Studying the two functions, you
    can see their algebraic relationship, one solving for the Z-score and the other
    for the x-value. We then turn an x-value of 8.0 into a Z-score of <math display="inline"><mrow><mn>3.</mn>
    <mover><mn>333</mn> <mo>¯</mo></mover></mrow></math> and then turn that Z-score
    back into an x-value.
  prefs: []
  type: TYPE_NORMAL
- en: Inferential Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Descriptive statistics, which we have covered so far, is commonly understood.
    However, when we get into inferential statistics the abstract relationships between
    sample and population come into full play. These abstract nuances are not something
    you want to rush through but rather take your time and absorb thoughtfully. As
    stated earlier, we are wired as humans to be biased and quickly come to conclusions.
    Being a good data science professional requires you to suppress that primal desire
    and consider the possibility that other explanations can exist. It is acceptable
    (perhaps even enlightened) to theorize there is no explanation at all and a finding
    is just coincidental and random.
  prefs: []
  type: TYPE_NORMAL
- en: First let’s start with the theorem that lays the foundation for all inferential
    statistics.
  prefs: []
  type: TYPE_NORMAL
- en: The Central Limit Theorem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the reasons the normal distribution is useful is because it appears a
    lot in nature, such as adult golden retriever weights. However, it shows up in
    a more fascinating context outside of natural populations. When we start measuring
    large enough samples from a population, even if that population does not follow
    a normal distribution, the normal distribution still makes an appearance.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s pretend I am measuring a population that is truly and uniformly random.
    Any value between 0.0 and 1.0 is equally likely, and no value has any preference.
    But something fascinating happens when we take increasingly large samples from
    this population, take the average of each, and then plot them into a histogram.
    Run this Python code in [Example 3-15](#svVtluPQuu) and observe the plot in [Figure 3-12](#GdjvwgQAuP).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-15\. Exploring the central limit theorem in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![emds 0312](Images/emds_0312.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-12\. Taking the means of samples (each of size 31) and plotting them
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Wait, how did uniformly random numbers, when sampled as groups of 31 and then
    averaged, roughly form a normal distribution? Any number is equally likely, right?
    Shouldn’t the distribution be flat rather than bell-curved?
  prefs: []
  type: TYPE_NORMAL
- en: Here’s what is happening. The individual numbers in the samples alone will not
    create a normal distribution. The distribution will be flat where any number is
    equally likely (known as a *uniform distribution*). But when we group them as
    samples and average them, they form a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is because of the *central limit theorem*, which states that interesting
    things happen when we take large enough samples of a population, calculate the
    mean of each, and plot them as a distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: The mean of the sample means is equal to the population mean.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the population is normal, then the sample means will be normal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the population is not normal, but the sample size is greater than 30, the
    sample means will still roughly form a normal distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The standard deviation of the sample means equals the population standard deviation
    divided by the square root of *n*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign sample standard deviation equals StartFraction population
    standard deviation Over StartRoot sample size EndRoot EndFraction dollar-sign"><mrow><mtext>sample</mtext>
    <mtext>standard</mtext> <mtext>deviation</mtext> <mo>=</mo> <mfrac><mrow><mtext>population</mtext><mtext>standard</mtext><mtext>deviation</mtext></mrow>
    <msqrt><mrow><mtext>sample</mtext><mtext>size</mtext></mrow></msqrt></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Why is all of the above important? These behaviors allows us to infer useful
    things about populations based on samples, even for nonnormal populations. If
    you modify the preceding code and try smaller sample sizes of 1 or 2, you will
    not see a normal distribution emerge. But as you approach 31 or more, you will
    see that we converge onto a normal distribution as shown in [Figure 3-13](#UIUIWJGfbo).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0313](Images/emds_0313.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-13\. Larger sample sizes approach the normal distribution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Thirty-one is the textbook number in statistics because that is when our sample
    distribution often converges onto the population distribution, particularly when
    we measure sample means or other parameters. When you have fewer than 31 items
    in your sample, that is when you have to rely on the T-distribution rather than
    the normal distribution, which has increasingly fatter tails the smaller your
    sample size. We will briefly talk about this later, but first let’s assume we
    have at least 31 items in our samples when we talk about confidence intervals
    and testing.
  prefs: []
  type: TYPE_NORMAL
- en: Confidence Intervals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may have heard the term “confidence interval,” which often confuses statistics
    newcomers and students. A *confidence interval* is a range calculation showing
    how confidently we believe a sample mean (or other parameter) falls in a range
    for the population mean.
  prefs: []
  type: TYPE_NORMAL
- en: '*Based on a sample of 31 golden retrievers with a sample mean of 64.408 and
    a sample standard deviation of 2.05, I am 95% confident that the population mean
    lies between 63.686 and 65.1296.* How do I know this? Let me show you, and if
    you get confused, circle back to this paragraph and remember what we are trying
    to achieve. I highlighted it for a reason!'
  prefs: []
  type: TYPE_NORMAL
- en: I first start out by choosing a *level of confidence (LOC)*, which will contain
    the desired probability for the population mean range. I want to be 95% confident
    that my sample mean falls in the population mean range I will calculate. That’s
    my LOC. We can leverage the central limit theorem and infer what this range for
    the population mean is. First, I need the *critical z-value* which is the symmetrical
    range in a standard normal distribution that gives me 95% probability in the center
    as highlighted in [Figure 3-14](#WosQdAULOW).
  prefs: []
  type: TYPE_NORMAL
- en: How do we calculate this symmetrical range containing .95 of the area? It’s
    easier to grasp as a concept than as a calculation. You may instinctively want
    to use the CDF, but then you may realize there are a few more moving parts here.
  prefs: []
  type: TYPE_NORMAL
- en: First you need to leverage the inverse CDF. Logically, to get 95% of the symmetrical
    area in the center, we would chop off the tails that have the remaining 5% of
    area. Splitting that remaining 5% area in half would give us 2.5% area in each
    tail. Therefore, the areas we want to look up the x-values for are .025 and .975
    as shown in [Figure 3-15](#UIhCfkqhJv).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0314](Images/emds_0314.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-14\. 95% symmetrical probability in the center of a standard normal
    distribution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![emds 0315](Images/emds_0315.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-15\. We want the x-values that give us areas .025 and .975
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can look up the x-value for area .025 and the x-value for area .975, and
    that will give us our center range containing 95% of the area. We will then return
    the corresponding lower and upper z-values containing this area. Remember, we
    are using standard normal distribution here so they will be the same other than
    being positive/negative. Let’s calculate this in Python as shown in [Example 3-16](#atphsKnwca).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-16\. Retrieving a critical z-value
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'OK, so we get ±1.95996, which is our critical z-value capturing 95% of probability
    at the center of the standard normal distribution. Next I’m going to leverage
    the central limit theorem to produce the *margin of error (E)*, which is the range
    around the sample mean that contains the population mean at that level of confidence.
    Recall that our sample of 31 golden retrievers has a mean of 64.408 and standard
    deviation of 2.05\. The formula to get this margin of error is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi>
    <mo>=</mo> <mo>±</mo> <msub><mi>z</mi> <mi>c</mi></msub> <mfrac><mi>s</mi> <msqrt><mi>n</mi></msqrt></mfrac></mrow></mtd></mtr></mtable></math>
    <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi>
    <mo>=</mo> <mo>±</mo> <mn>1.95996</mn> <mo>*</mo> <mfrac><mrow><mn>2.05</mn></mrow>
    <msqrt><mn>31</mn></msqrt></mfrac></mrow></mtd></mtr></mtable></math> <math display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi> <mo>=</mo>
    <mo>±</mo> <mn>0.72164</mn></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: If we apply that margin of error against the sample mean, we finally get the
    confidence interval!
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mn>95%</mn> <mtext>confidence interval</mtext>
    <mo>=</mo> <mn>64.408</mn> <mo>±</mo> <mn>0.72164</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Here is how we calculate this confidence interval in Python from beginning to
    end in [Example 3-17](#bqurVLiIGN).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-17\. Calculating a confidence interval in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: So the way to interpret this is “based on my sample of 31 golden retriever weights
    with sample mean 64.408 and sample standard deviation of 2.05, I am 95% confident
    the population mean lies between 63.686 and 65.1296.” That is how we describe
    our confidence interval.
  prefs: []
  type: TYPE_NORMAL
- en: One interesting thing to note here too is that in our margin of error formula,
    the larger *n* becomes, the narrower our confidence interval becomes! This makes
    sense because if we have a larger sample, we are more confident in the population
    mean falling in a smaller range, hence why it’s called a confidence interval.
  prefs: []
  type: TYPE_NORMAL
- en: One caveat to put here is that for this to work, our sample size must be at
    least 31 items. This goes back to the central limit theorem. If we want to apply
    a confidence interval to a smaller sample, we need to use a distribution with
    higher variance (fatter tails reflecting more uncertainty). This is what the T-distribution
    is for, and we will visit that at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 5](ch05.xhtml#ch05) we will continue to use confidence intervals
    for linear regressions.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding P-Values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we say something is *statistically significant*, what do we mean by that?
    We hear it used loosely and frequently but what does it mean mathematically? Technically,
    it has to do with something called the p-value, which is a hard concept for many
    folks to grasp. But I think the concept of p-values makes more sense when you
    trace it back to its invention. While this is an imperfect example, it gets across
    some big ideas.
  prefs: []
  type: TYPE_NORMAL
- en: In 1925, mathematician Ronald Fisher was at a party. One of his colleagues Muriel
    Bristol claimed she could detect when tea was poured before milk simply by tasting
    it. Intrigued by the claim, Ronald set up an experiment on the spot.
  prefs: []
  type: TYPE_NORMAL
- en: He prepared eight cups of tea. Four had milk poured first; the other four had
    tea poured first. He then presented them to his connoisseur colleague and asked
    her to identify the pour order for each. Remarkably, she identified them all correctly,
    and the probability of this happening by chance is 1 in 70, or 0.01428571.
  prefs: []
  type: TYPE_NORMAL
- en: This 1.4% probability is what we call the *p-value*, the probability of something
    occurring by chance rather than because of a hypothesized explanation. Without
    going down a rabbit hole of combinatorial math, the probability that Muriel completely
    guessed the cups correctly is 1.4%. What exactly does that tell you?
  prefs: []
  type: TYPE_NORMAL
- en: When we frame an experiment, whether it is determining if organic donuts cause
    weight gain or living near power lines causes cancer, we always have to entertain
    the possibility that random luck played a role. Just like there is a 1.4% chance
    Muriel identified the cups of tea correctly simply by guessing, there’s always
    a chance randomness just gave us a good hand like a slot machine. This helps us
    frame our *null hypothesis (H[0])*, saying that the variable in question had no
    impact on the experiment and any positive results are just random luck. The *alternative
    hypothesis (H[1])* poses that a variable in question (called the *controlled variable*)
    is causing a positive result.
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, the threshold for statistical significance is a p-value of 5%
    or less, or .05\. Since .014 is less than .05, this would mean we can reject our
    null hypothesis that Muriel was randomly guessing. We can then promote the alternative
    hypothesis that Muriel had a special ability to detect whether tea or milk was
    poured first.
  prefs: []
  type: TYPE_NORMAL
- en: Now one thing this tea-party example did not capture is that when we calculate
    a p-value, we capture all probability of that event or rarer. We will address
    this as we dive into the next example using the normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Past studies have shown that the mean recovery time for a cold is 18 days, with
    a standard deviation of 1.5 days, and follows a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: This means there is approximately 95% chance of recovery taking between 15 and
    21 days as shown in [Figure 3-16](#BGsosDGqFb) and [Example 3-18](#kQakNUgcMw).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0316](Images/emds_0316.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-16\. There is 95% chance of recovery between 15 and 21 days
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Example 3-18\. Calculating the probability of recovery between 15 and 21 days
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We can infer then from the remaining 5% probability that there’s a 2.5% chance
    of recovery taking longer than 21 days and a 2.5% chance of it taking fewer than
    15 days. Hold onto that bit of information because it will be critical later!
    That drives our p-value.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s say an experimental new drug was given to a test group of 40 people,
    and it took an average of 16 days for them to recover from the cold as shown in
    [Figure 3-17](#cnqKOunjTF).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0317](Images/emds_0317.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-17\. A group taking a drug took 16 days to recover
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Did the drug have an impact? If you reason long enough, you may realize what
    we are asking is this: does the drug show a statistically signficant result? Or
    did the drug not work and the 16-day recovery was a coincidence with the test
    group? That first question frames our alternative hypothesis, while the second
    question frames our null hypothesis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways we can calculate this: the one-tailed and two-tailed test.
    We will start with the one-tailed.'
  prefs: []
  type: TYPE_NORMAL
- en: One-Tailed Test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When we approach the *one-tailed test*, we typically frame our null and alternative
    hypotheses using inequalities. We hypothesize around the population mean and say
    that it either is greater than/equal to 18 (the null hypothesis <math alttext="upper
    H 0"><msub><mi>H</mi> <mn>0</mn></msub></math> ) or less than 18 (the alternative
    hypothesis <math alttext="upper H 1"><msub><mi>H</mi> <mn>1</mn></msub></math>
    ):'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>H</mi> <mn>0</mn></msub> <mo>:</mo> <mtext>population</mtext>
    <mtext>mean</mtext> <mo>≥</mo> <mn>18</mn></mrow></math> <math display="block"><mrow><msub><mi>H</mi>
    <mn>1</mn></msub> <mo>:</mo> <mtext>population</mtext> <mtext>mean</mtext> <mo><</mo>
    <mn>18</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: To reject our null hypothesis, we need to show that our sample mean of the patients
    who took the drug is not likely to have been coincidental. Since a p-value of
    .05 or less is traditionally considered statistically signficant, we will use
    that as our threshold ([Figure 3-17](#cnqKOunjTF)). When we calculate this in
    Python using the inverse CDF as shown in [Figure 3-18](#DwEsFifKbh) and [Example 3-19](#VgUvpVkMBd),
    we find that approximately 15.53 is the number of recovery days that gives us
    .05 area on the left tail.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0318](Images/emds_0318.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-18\. Getting the x-value with 5% of area behind it
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Example 3-19\. Python code for getting x-value with 5% of area behind it
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Therefore, if we achieve an average 15.53 or fewer days of recovery time in
    our sample group, our drug is considered statistically significant enough to have
    shown an impact. However, our sample mean of recovery time is actually 16 days
    and does not fall into this null hypothesis rejection zone. Therefore, the statistical
    significance test has failed as shown in [Figure 3-19](#niSmcfcALK).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0319](Images/emds_0319.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-19\. We have failed to prove our drug test result is statistically
    significant
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The area up to that 16-day mark is our p-value, which is .0912, and we calculate
    it in Python as shown in [Example 3-20](#BRkUBWLuFH).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-20\. Calculating the one-tailed p-value
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Since the p-value of .0912 is greater than our statistical significance threshold
    of .05, we do not consider the drug trial a success and fail to reject our null
    hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: Two-Tailed Test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The previous test we performed is called the one-tailed test because it looks
    for statistical significance only on one tail. However, it is often safer and
    better practice to use a two-tailed test. We will elaborate why, but first let’s
    calculate it.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do a *two-tailed test*, we frame our null and alternative hypothesis in
    an “equal” and “not equal” structure. In our drug test, we will say the null hypothesis
    has a mean recovery time of 18 days. But our alternative hypothesis is the mean
    recovery time is not 18 days, thanks to the new drug:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>H</mi> <mn>0</mn></msub> <mo>:</mo> <mtext>population</mtext>
    <mtext>mean</mtext> <mo>=</mo> <mn>18</mn></mrow></math> <math display="block"><mrow><msub><mi>H</mi>
    <mn>1</mn></msub> <mo>:</mo> <mtext>population</mtext> <mtext>mean</mtext> <mo>≠</mo>
    <mn>18</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This has an important implication. We are structuring our alternative hypothesis
    to not test whether the drug improves cold recovery time, but if it had *any*
    impact. This includes testing if it increased the duration of the cold. Is this
    helpful? Hold that thought.
  prefs: []
  type: TYPE_NORMAL
- en: Naturally, this means we spread our p-value statistical significance threshold
    to both tails, not just one. If we are testing for a statistical significance
    of 5%, then we split it and give each 2.5% half to each tail. If our drug’s mean
    recovery time falls in either region, our test is successful and we reject the
    null hypothesis ([Figure 3-20](#sSFGsGWdtJ)).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0320](Images/emds_0320.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-20\. A two-tailed test
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The x-values for the lower tail and upper tail are 15.06 and 20.93, meaning
    if we are under or over, respectively, we reject the null hypothesis. Those two
    values are calculated using the inverse CDF shown in [Figure 3-21](#IdTSDnDpVp)
    and [Example 3-21](#tjLSjCvgep). Remember, to get the upper tail we take .95 and
    then add the .025 piece of significance threshold to it, giving us .975.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0321](Images/emds_0321.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-21\. Calculating the central 95% of normal distribution area
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Example 3-21\. Calculating a range for a statistical significance of 5%
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The sample mean value for the drug test group is 16, and 16 is not less than
    15.06 nor greater than 20.9399\. So like the one-tailed test, we still fail to
    reject the null hypothesis. Our drug still has not shown any statistical significance
    to have any impact as shown in [Figure 3-22](#AHaOnNhrAe).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0322](Images/emds_0322.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-22\. The two-tailed test has failed to prove statistical significance
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: But what is the p-value? This is where it gets interesting with two-tailed tests.
    Our p-value is going to capture not just the area to the left of 16 but also the
    symmetrical equivalent area on the right tail. Since 16 is 4 days below the mean,
    we will also capture the area above 20, which is 4 days above the mean ([Figure 3-23](#FoGdeWjlNK)).
    This is capturing the probability of an event or rarer, on both sides of the bell
    curve.
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0323](Images/emds_0323.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-23\. The p-value adds symmetrical sides for statistical significance
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When we sum both those areas, we get a p-value of .1824\. This is a lot greater
    than .05, so it definitely does not pass our p-value threshold of .05 ([Example 3-22](#SaVqCVlGfH)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-22\. Calculating the two-tailed p-value
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'So why do we also add the symmetrical area on the opposite side in a two-tailed
    test? This may not be the most intuitive concept, but first remember how we structured
    our hypotheses:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>H</mi> <mn>0</mn></msub> <mo>:</mo> <mtext>population</mtext>
    <mtext>mean</mtext> <mo>=</mo> <mn>18</mn></mrow></math> <math display="block"><mrow><msub><mi>H</mi>
    <mn>1</mn></msub> <mo>:</mo> <mtext>population</mtext> <mtext>mean</mtext> <mo>≠</mo>
    <mn>18</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: If we are testing in an “equals 18” versus “not equals 18” capacity, we have
    to capture any probability that is of equal or less value on both sides. After
    all, we are trying to prove significance, and that includes anything that is equally
    or less likely to happen. We did not have this special consideration with the
    one-tailed test that used only “greater/less than” logic. But when we are dealing
    with “equals/not equals” our interest area goes in both directions.
  prefs: []
  type: TYPE_NORMAL
- en: 'So what are the practical implications of the two-tailed test? How does it
    affect whether we reject the null hypothesis? Ask yourself this: which one sets
    a higher threshold? You will notice that even when our objective is to show we
    may have lessened something (the cold-recovery time using a drug), reframing our
    hypothesis to show any impact (greater or lesser) creates a higher significance
    threshold. If our significance threshold is a p-value of .05 or less, our one-tailed
    test was closer to acceptance at p-value .0912 as opposed to the two-tailed test,
    which was about double that at p-value .182.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This means the two-tailed test makes it harder to reject the null hypothesis
    and demands stronger evidence to pass a test. Also think of this: what if our
    drug could worsen colds and make them last longer? It may be helpful to capture
    that probability too and account for variation in that direction. This is why
    two-tailed tests are preferable in most cases. They tend to be more reliable and
    not bias the hypothesis in just one direction.'
  prefs: []
  type: TYPE_NORMAL
- en: We will use hypothesis testing and p-values again in Chapters [5](ch05.xhtml#ch05)
    and [6](ch06.xhtml#ch06).
  prefs: []
  type: TYPE_NORMAL
- en: 'The T-Distribution: Dealing with Small Samples'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s briefly address how to deal with smaller samples of 30 or fewer; we will
    need this when we do linear regression in [Chapter 5](ch05.xhtml#ch05). Whether
    we are calculating confidence intervals or doing hypothesis testing, if we have
    30 or fewer items in a sample we would opt to use a T-distribution instead of
    a normal distribution. The *T-distribution* is like a normal distribution but
    has fatter tails to reflect more variance and uncertainty. [Figure 3-24](#flanKcrbds)
    shows a normal distribution (dashed) alongside a T-distribution with one degree
    of freedom (solid).
  prefs: []
  type: TYPE_NORMAL
- en: '![emds 0324](Images/emds_0324.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-24\. The T-distribution alongside a normal distribution; note the fatter
    tails
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The smaller the sample size, the fatter the tails get in a T-distribution. But
    what’s interesting is after you approach 31 items, the T-distribution is nearly
    indistinguishable from the normal distribution, which neatly reflects the ideas
    behind the central limit theorem.
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 3-23](#qHcbJNTpsD) shows how to find the *critical t-value* for 95%
    confidence. You can use this for confidence intervals and hypothesis testing when
    you have a sample size of 30 or less. It’s conceptually the same as the critical
    z-value, but we are using a T-distribution instead of a normal distribution to
    reflect greater uncertainty. The smaller the sample size, the larger the range,
    reflecting greater uncertainty.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-23\. Getting a critical value range with a T-distribution
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Note that `df` is the “degrees of freedom” parameter, and as outlined earlier
    it should be one less of the sample size.
  prefs: []
  type: TYPE_NORMAL
- en: Big Data Considerations and the Texas Sharpshooter Fallacy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One final thought before we close this chapter. As we have discussed, randomness
    plays such a role in validating our findings and we always have to account for
    its possibility. Unfortunately with big data, machine learning, and other data-mining
    tools, the scientific method has suddenly become a practice done backward. This
    can be precarious; allow me to demonstrate why, adapting an example from Gary
    Smith’s book *Standard Deviations* (Overlook Press).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s pretend I draw four playing cards from a fair deck. There’s no game or
    objective here other than to draw four cards and observe them. I get two 10s,
    a 3, and a 2\. “This is interesting,” I say. “I got two 10s, a 3, and a 2\. Is
    this meaningful? Are the next four cards I draw also going to be two consecutive
    numbers and a pair? What’s the underlying model here?”
  prefs: []
  type: TYPE_NORMAL
- en: See what I did there? I took something that was completely random and I not
    only looked for patterns, but I tried to make a predictive model out of them.
    What has subtly happened here is I never made it my objective to get these four
    cards with these particular patterns. I observed them *after* they occurred.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is exactly what data mining falls victim to every day: finding coincidental
    patterns in random events. With huge amounts of data and fast algorithms looking
    for patterns, it’s easy to find things that look meaningful but actually are just
    random coincidences.'
  prefs: []
  type: TYPE_NORMAL
- en: This is also analogous to me firing a gun at a wall. I then draw a target around
    the hole and bring my friends over to show off my amazing marksmanship. Silly,
    right? Well, many people in data science figuratively do this every day and it
    is known as the *Texas Sharpshooter Fallacy*. They set out to act without an objective,
    stumble on something rare, and then point out that what they found somehow creates
    predictive value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem is the law of truly large numbers says rare events are likely to
    be found; we just do not know which ones. When we encounter rare events, we highlight
    and even speculate what might have caused them. The issue is this: the probability
    of a specific person winning the lottery is highly unlikely, but yet someone *is*
    going to win the lottery. Why should we be surprised when there is a winner? Unless
    somebody predicted the winner, nothing meaningful happened other than a random
    person got lucky.'
  prefs: []
  type: TYPE_NORMAL
- en: This also applies to correlations, which we will study in [Chapter 5](ch05.xhtml#ch05).
    With an enormous dataset with thousands of variables, is it easy to find statistically
    significant findings with a .05 p-value? You betcha! I’ll find thousands of those.
    I’ll even show evidence that [the number of Nicolas Cage movies correlates with
    the number of pool drownings in a year](https://oreil.ly/eGxm0).
  prefs: []
  type: TYPE_NORMAL
- en: So to prevent the Texas Sharpshooter Fallacy and falling victim to big data
    fallacies, try to use structured hypothesis testing and gather data for that objective.
    If you utilize data mining, try to obtain fresh data to see if your findings still
    hold up. Finally, always consider the possibility that things can be coincidental;
    if there is not a commonsense explanation, then it probably was coincidental.
  prefs: []
  type: TYPE_NORMAL
- en: We learned how to hypothesize before gathering data, but data mining gathers
    data, then hypothesizes. Ironically, we are often more objective starting with
    a hypothesis, because we then seek out data to deliberately prove and disprove
    our hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We learned a lot in this chapter, and you should feel good about getting this
    far. This was probably one of the harder topics in this book! We not only learned
    descriptive statistics from the mean to the normal distribution but also tackled
    confidence intervals and hypothesis testing.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, you see data a little differently. It is snapshots of something rather
    than a complete capturing of reality. Data on its own is not very useful, and
    we need context, curiosity, and analysis of where it came from before we can make
    meaningful insights with it. We covered how to describe data as well as infer
    attributes about a larger population based on a sample. Finally, we addressed
    some of the data-mining fallacies we can stumble into if we are not careful, and
    how to remedy that with fresh data and common sense.
  prefs: []
  type: TYPE_NORMAL
- en: Do not feel bad if you need to go back and review some of the content in this
    chapter, because there’s a lot to digest. It is also important to get in the hypothesis-testing
    mindset if you want to be successful at a data science and machine learning career.
    Few practitioners take time to link statistics and hypothesis-testing concepts
    to machine learning, and that is unfortunate.
  prefs: []
  type: TYPE_NORMAL
- en: Understandability and explainability is the next frontier of machine learning,
    so continue to learn and integrate these ideas as you progress throughout the
    rest of this book and the rest of your career.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You bought a spool of 1.75 mm filament for your 3D printer. You want to measure
    how close the filament diameter really is to 1.75 mm. You use a caliper tool and
    sample the diameter five times on the spool:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1.78, 1.75, 1.72, 1.74, 1.77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Calculate the mean and standard deviation for this set of values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A manufacturer says the Z-Phone smart phone has a mean consumer life of 42 months
    with a standard deviation of 8 months. Assuming a normal distribution, what is
    the probability a given random Z-Phone will last between 20 and 30 months?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I am skeptical that my 3D printer filament is not 1.75 mm in average diameter
    as advertised. I sampled 34 measurements with my tool. The sample mean is 1.715588
    and the sample standard deviation is 0.029252.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the 99% confidence interval for the mean of my entire spool of filament?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Your marketing department has started a new advertising campaign and wants to
    know if it affected sales, which in the past averaged $10,345 a day with a standard
    deviation of $552\. The new advertising campaign ran for 45 days and averaged
    $11,641 in sales.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Did the campaign affect sales? Why or why not? (Use a two-tailed test for more
    reliable significance.)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers are in [Appendix B](app02.xhtml#exercise_answers).
  prefs: []
  type: TYPE_NORMAL
