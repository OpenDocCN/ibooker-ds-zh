- en: Chapter 2\. Core Storm concepts
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2章\. 核心Storm概念
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Core Storm concepts and terminology
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心Storm概念和术语
- en: Basic code for your first Storm project
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个Storm项目的基本代码
- en: The core concepts in Storm are simple once you understand them, but this understanding
    can be hard to come by. Encountering a description of “executors” and “tasks”
    on your first day can be hard to understand. There are just too many concepts
    you need to hold in your head at one time. In this book, we’ll introduce concepts
    in a progressive fashion and try to minimize the number of concepts you need to
    think about at one time. This approach will often mean that an explanation isn’t
    entirely “true,” but it’ll be accurate enough at that point in your journey. As
    you slowly pick up on different pieces of the puzzle, we’ll point out where our
    earlier definitions can be expanded on.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你理解了Storm的核心概念，它们就很简单，但这种理解可能很难获得。第一天遇到“执行器”和“任务”的描述可能很难理解。你需要一次记住太多概念。在这本书中，我们将逐步介绍概念，并尽量减少你需要一次思考的概念数量。这种方法通常意味着解释并不完全“正确”，但在你的旅程的这个阶段，它将足够准确。随着你逐渐拼凑起不同的碎片，我们会指出我们早期的定义可以如何扩展。
- en: '2.1\. Problem definition: GitHub commit count dashboard'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 问题定义：GitHub提交计数仪表板
- en: 'Let’s begin by doing work in a domain that should be familiar: source control
    in GitHub. Most developers are familiar with GitHub, having used it for a personal
    project, for work, or for interacting with other open source projects.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从在一个应该熟悉的领域开始工作：GitHub的源代码控制。大多数开发者都熟悉GitHub，因为他们在个人项目、工作或与其他开源项目互动时使用过它。
- en: Let’s say we want to implement a dashboard that shows a running count of the
    most active developers against any repository. This count has some real-time requirements
    in that it must be updated immediately after any change is made to the repository.
    The dashboard being requested by GitHub may look something like [figure 2.1](#ch02fig01).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要实现一个仪表板，显示针对任何仓库的最活跃开发者的运行计数。这个计数有一些实时要求，即在仓库的任何更改发生后必须立即更新。GitHub请求的仪表板可能看起来像[图2.1](#ch02fig01)。
- en: Figure 2.1\. Mock-up of dashboard for a running count of changes made to a repository
  id: totrans-8
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.1\. 对一个仓库更改计数仪表板的草图
- en: '![](02fig01_alt.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig01_alt.jpg)'
- en: The dashboard is quite simple. It contains a listing of the email of every developer
    who has made a commit to the repository along with a running total of the number
    of commits each has made. Before we dive into how we’d design a solution with
    Storm, let’s break down the problem a bit further in terms of the data that’ll
    be used.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 该仪表板相当简单。它包含了一个列表，列出了每个向仓库提交过代码的开发者的电子邮件，以及他们各自提交的总数。在我们深入探讨如何使用Storm设计解决方案之前，让我们进一步分解问题，从将要使用的数据的角度来看。
- en: '2.1.1\. Data: starting and ending points'
  id: totrans-11
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1\. 数据：起始点和结束点
- en: For our scenario, we’ll say GitHub provides a live feed of commits being made
    to any repository. Each commit comes into the feed as a single string that contains
    the commit ID, followed by a space, followed by the email of the developer who
    made the commit. The following listing shows a sampling of 10 individual commits
    in the feed.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的场景，我们将说GitHub提供了一个任何仓库提交的实时流。每个提交作为一个包含提交ID、一个空格和提交该提交的开发者电子邮件的单个字符串进入流。以下列表显示了流中的10个单独提交的样本。
- en: Listing 2.1\. Sample commit data for the GitHub commit feed
  id: totrans-13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.1\. GitHub提交流的示例提交数据
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This feed gives us a starting point for our data. We’ll need to go from this
    live feed to a UI displaying a running count of commits per email address. For
    the sake of simplicity, let’s say all we need to do is maintain an in-memory map
    with email address as the key and number of commits as the value. The map may
    look something like this in code:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据流为我们提供了数据的起点。我们需要从这个实时流到一个显示每个电子邮件地址提交数运行计数的UI。为了简化，让我们说我们只需要维护一个内存映射，其中电子邮件地址是键，提交数是值。这个映射在代码中可能看起来像这样：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that we’ve defined the data, the next step is to define the steps we need
    to take to make sure our in-memory map correctly reflects the commit data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了数据，下一步就是定义我们需要采取的步骤，以确保我们的内存映射正确地反映了提交数据。
- en: 2.1.2\. Breaking down the problem
  id: totrans-18
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.2\. 问题分解
- en: 'We know we want to go from a feed of commit messages to an in-memory map of
    emails/commit counts, but we haven’t defined how to get there. At this point,
    breaking down the problem into a series of smaller steps helps. We define these
    steps in terms of components that accept input, perform a calculation on that
    input, and produce some output. The steps should provide a way to get from our
    starting point to our desired ending point. We’ve come up with the following components
    for this problem:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道我们想要从提交消息的流中转换到内存中的电子邮件/提交计数映射，但我们还没有定义如何实现。在这个阶段，将问题分解为一系列较小的步骤有助于。我们定义这些步骤为接受输入、对输入进行计算并产生输出的组件。这些步骤应该提供一种从起点到终点的方法。我们为这个问题提出了以下组件：
- en: A component that reads from the live feed of commits and produces a single commit
    message
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个组件从实时提交流中读取并生成单个提交消息
- en: A component that accepts a single commit message, extracts the developer’s email
    from that commit, and produces an email
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个组件接受单个提交消息，从中提取开发者的电子邮件，并生成一封电子邮件
- en: A component that accepts the developer’s email and updates an in-memory map
    where the key is the email and the value is the number of commits for that email
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个组件接受开发者的电子邮件并更新一个内存映射，其中键是电子邮件，值是该电子邮件的提交次数
- en: In this chapter we break down the problem into several components. In the next
    chapter, we’ll go over how to think about mapping a problem onto the Storm domain
    in much greater detail. But before we get ahead of ourselves, take a look at [figure
    2.2](#ch02fig02), which illustrates the components, the input they accept, and
    the output they produce.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将问题分解为几个组件。在下一章中，我们将更详细地介绍如何将问题映射到Storm域。但在我们继续之前，看看[图2.2](#ch02fig02)，它说明了组件、它们接受的输入和产生的输出。
- en: Figure 2.2\. The commit count problem broken down into a series of steps with
    defined inputs and outputs
  id: totrans-24
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.2. 将提交计数问题分解为一系列步骤，具有定义明确的输入和输出
- en: '![](02fig02.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![02fig02.jpg]'
- en: '[Figure 2.2](#ch02fig02) shows our basic solution for going from a live feed
    of commits to something that stores the commit counts for each email. We have
    three components, each with a singular purpose. Now that we have a well-formed
    idea of how we want to solve this problem, let’s frame our solution within the
    context of Storm.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2.2](#ch02fig02)展示了我们将实时提交流转换为存储每个电子邮件提交计数的解决方案。我们有三个组件，每个组件都有单一的目的。现在我们已经对如何解决这个问题有了很好的理解，让我们在Storm的背景下构建我们的解决方案。'
- en: 2.2\. Basic Storm concepts
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2. Storm的基本概念
- en: 'To help you understand the core concepts in Storm, we’ll go over the common
    terminology used in Storm. We’ll do this within the context of our sample design.
    Let’s begin with the most basic component in Storm: the topology.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您理解Storm的核心概念，我们将介绍Storm中使用的常见术语。我们将在我们的示例设计中这样做。让我们从Storm中最基本的组件开始：拓扑。
- en: 2.2.1\. Topology
  id: totrans-29
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1. 拓扑结构
- en: Let’s take a step back from our example in order to understand what a topology
    is. Think of a simple linear graph with some nodes connected by directed edges.
    Now imagine that each one of those nodes represents a single process or computation
    and each edge represents the result of one computation being passed as input to
    the next computation. [Figure 2.3](#ch02fig03) illustrates this more clearly.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们退一步，从我们的例子中理解什么是拓扑。想象一个简单的线性图，一些节点通过有向边连接。现在想象每个节点代表一个单独的过程或计算，每条边代表一个计算的结果作为输入传递给下一个计算。[图2.3](#ch02fig03)更清楚地说明了这一点。
- en: Figure 2.3\. A topology is a graph with nodes representing computations and
    edges representing results of computations.
  id: totrans-31
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.3. 拓扑是一个图，节点代表计算，边代表计算的结果。
- en: '![](02fig03_alt.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![02fig03_alt.jpg]'
- en: A Storm topology is a graph of computation where the nodes represent some individual
    computations and the edges represent the data being passed between nodes. We then
    feed data into this graph of computation in order to achieve some goal. What does
    this mean exactly? Let’s go back to our dashboard example to show you what we’re
    talking about.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Storm拓扑是一个计算图，节点代表一些单个计算，边代表节点之间传递的数据。然后我们向这个计算图输入数据以实现某个目标。这究竟意味着什么呢？让我们回到我们的仪表板示例，看看我们说的是什么。
- en: Looking at the modular breakdown of our problem, we’re able to identify each
    of the components from our definition of a topology. [Figure 2.4](#ch02fig04)
    illustrates this correlation; there’s a lot to take in here, so take your time.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看问题的模块化分解，我们能够从拓扑的定义中识别出每个组件。[图2.4](#ch02fig04)说明了这种关联；这里有很多内容需要消化，所以请慢慢来。
- en: Figure 2.4\. Design mapped to the definition of a Storm topology
  id: totrans-35
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.4\. 将设计映射到Storm拓扑的定义
- en: '![](02fig04_alt.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig04_alt.jpg)'
- en: Each concept we mentioned in the definition of a topology can be found in our
    design. The actual topology consists of the nodes and edges. This topology is
    then driven by the continuous live feed of commits. Our design fits quite well
    within the framework of Storm. Now that you understand what a topology is, we’ll
    dive into the individual components that make up a topology.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在拓扑定义中提到的每个概念都可以在我们的设计中找到。实际的拓扑由节点和边组成。这个拓扑随后由提交的持续实时流驱动。我们的设计非常适合Storm框架。现在你已经了解了什么是拓扑，我们将深入了解构成拓扑的各个组件。
- en: 2.2.2\. Tuple
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2\. 元组
- en: The nodes in our topology send data between one another in the form of tuples.
    A *tuple* is an ordered list of values, where each value is assigned a name. A
    node can create and then (optionally) send tuples to any number of nodes in the
    graph. The process of sending a tuple to be handled by any number of nodes is
    called *emitting* a tuple.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拓扑中的节点以元组的形式相互发送数据。一个*元组*是有序值列表，其中每个值都被分配了一个名称。一个节点可以创建并（可选地）向图中任意数量的节点发送元组。将元组发送给任意数量的节点进行处理的过程称为*发射*元组。
- en: It’s important to note that just because each value in a tuple has a name, doesn’t
    mean a tuple is a list of name-value pairs. A list of name-value pairs implies
    there may be a map behind the scenes and that the name is actually a part of the
    tuple. Neither of these statements is true. A tuple is an ordered list of values
    and Storm provides mechanisms for assigning names to the values within this list;
    we’ll get into how these names are assigned later in this chapter.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，尽管元组中的每个值都有一个名称，但这并不意味着元组是名称-值对的列表。名称-值对的列表意味着背后可能有一个映射，并且名称实际上是元组的一部分。这两个陈述都不正确。元组是有序值列表，Storm提供了为列表中的值分配名称的机制；我们将在本章后面讨论这些名称是如何分配的。
- en: When we display tuples in figures throughout the rest of the book, the names
    associated with the values are important, so we’ve settled on a convention that
    includes both the name and value ([figure 2.5](#ch02fig05)).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在本书其余部分中的图中显示元组时，与值关联的名称很重要，因此我们确定了一个包括名称和值的约定（[图2.5](#ch02fig05)）。
- en: Figure 2.5\. Format for displaying tuples in figures throughout the book
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.5\. 在本书中显示元组的格式
- en: '![](02fig05_alt.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig05_alt.jpg)'
- en: 'With the standard format for displaying tuples in hand, let’s identify the
    two types of tuples in our topology:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在掌握了显示元组的标准格式后，让我们确定我们的拓扑中的两种元组类型：
- en: The commit message containing the commit ID and developer email
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含提交ID和开发者电子邮件的提交消息
- en: The developer email
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发者电子邮件
- en: We need to assign each of these a name, so we’ll go with “commit” and “email”
    for now (more details on how this is done in code later). [Figure 2.6](#ch02fig06)
    provides an illustration of where the tuples are flowing in our topology.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为这些分配一个名称，所以我们现在使用“提交”和“电子邮件”（关于如何在代码中实现这一点的更多细节将在后面介绍）。[图2.6](#ch02fig06)展示了我们的拓扑中元组的流动情况。
- en: 'Figure 2.6\. Two types of tuples in the topology: one for the commit message
    and another for the email'
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.6\. 拓扑中的两种元组：一个用于提交消息，另一个用于电子邮件
- en: '![](02fig06.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig06.jpg)'
- en: The types of the values within a tuple are dynamic and don’t need to be declared.
    But Storm does need to know how to serialize these values so it can send the tuple
    between nodes in the topology. Storm already knows how to serialize primitive
    types but will require custom serializers for any custom type you define and can
    fall back to standard Java serialization when a custom serializer isn’t present.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 元组内值的类型是动态的，不需要声明。但是Storm需要知道如何序列化这些值，以便在拓扑中的节点之间发送元组。Storm已经知道如何序列化原始类型，但对于你定义的任何自定义类型，它将需要自定义序列化器，并在没有自定义序列化器的情况下回退到标准的Java序列化。
- en: 'We’ll get to the code for all of this soon, but for now the important thing
    is to understand the terminology and relationships between concepts. With an understanding
    of tuples in hand, we can move on to the core abstraction in Storm: the stream.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快就会看到所有这些代码，但现在的重点是理解术语和概念之间的关系。在掌握了元组的概念之后，我们可以继续学习Storm的核心抽象：流。
- en: 2.2.3\. Stream
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.3\. 流
- en: According to the Storm wiki, a stream is an “unbounded sequence of tuples.”
    This is a great explanation of what a stream is, with maybe one addition. *A stream*
    is an unbounded sequence of tuples between two nodes in the topology. A topology
    can contain any number of streams. Other than the very first node in the topology
    that reads from the data feed, nodes can accept one or more streams as input.
    Nodes will then normally perform some computation or transformation on the input
    tuples and emit new tuples, thus creating a new output stream. These output streams
    then act as input streams for other nodes, and so on.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Storm维基百科，流是“元组的无界序列。”这是对什么是流的很好解释，也许可以补充一点。*流*是拓扑中两个节点之间元组的无界序列。一个拓扑可以包含任意数量的流。除了拓扑中第一个从数据源读取的节点之外，节点可以接受一个或多个流作为输入。节点随后通常会对输入元组进行一些计算或转换，并发出新的元组，从而创建一个新的输出流。这些输出流然后作为其他节点的输入流，依此类推。
- en: There are two streams in our GitHub commit count topology. The first stream
    starts with the node that continuously reads commits from a feed. This node emits
    a tuple with the commit to another node that extracts the email. The second stream
    starts with the node that extracts the email from the commit. This node transforms
    its input stream (containing commits) by emitting a new stream containing only
    emails. The resulting output stream serves as input into the node that updates
    the in-memory map. You can see these streams in [figure 2.7](#ch02fig07).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的GitHub提交计数拓扑中，有两个流。第一个流从持续读取提交的节点开始。该节点发出一个包含提交的元组到另一个提取电子邮件的节点。第二个流从提取提交中的电子邮件的节点开始。该节点通过发出只包含电子邮件的新流来转换其输入流（包含提交）。结果输出流作为更新内存映射的节点的输入。您可以在[图2.7](#ch02fig07)中看到这些流。
- en: Figure 2.7\. Identifying the two streams in our topology
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.7\. 识别我们的拓扑中的两个流
- en: '![](02fig07.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig07.jpg)'
- en: Our Storm GitHub scenario is an example of a simple chained stream (multiple
    streams chained together).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的Storm GitHub场景是一个简单链式流（多个流连接在一起）的例子。
- en: Complex streams
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 复杂流
- en: Streams may not always be as straightforward as those in our topology. Take
    the example in [figure 2.8](#ch02fig08). This figure shows a topology with four
    different streams. The first node emits a tuple that’s consumed by two different
    nodes; this results in two separate streams. Each of those nodes then emits tuples
    to their own new output stream.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 流可能并不总是像我们的拓扑中那样简单。以[图2.8](#ch02fig08)中的例子为例。这张图显示了一个包含四个不同流的拓扑。第一个节点发出一个元组，被两个不同的节点消费；这导致了两个独立的流。然后，每个节点都会向它们自己的新输出流发出元组。
- en: Figure 2.8\. Topology with four streams
  id: totrans-60
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.8\. 包含四个流的拓扑
- en: '![](02fig08.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig08.jpg)'
- en: The combinations are endless with regard to the number of streams that may be
    created, split, and then joined again. The examples later in this book will delve
    into the more complex chains of streams and why it’s beneficial to design a topology
    in such a way. For now, we’ll continue with our straightforward example and move
    on to the source of a stream for a topology.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建、拆分和再次连接流的数量方面，组合是无限的。本书后面的例子将深入探讨更复杂的流链，以及为什么以这种方式设计拓扑是有益的。现在，我们将继续我们的简单例子，并转向拓扑的流来源。
- en: 2.2.4\. Spout
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.4\. 泄露
- en: A *spout* is the source of a stream in the topology. Spouts normally read data
    from an external data source and emit tuples into the topology. Spouts can listen
    to message queues for incoming messages, listen to a database for changes, or
    listen to any other source of a feed of data. In our example, the spout is listening
    to the real-time feed of commits being made to the Storm repository ([figure 2.9](#ch02fig09)).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*Spout*是拓扑中流的来源。Spout通常从外部数据源读取数据并将元组发射到拓扑中。Spout可以监听消息队列中的传入消息，监听数据库中的变化，或监听任何其他数据源。在我们的例子中，spout正在监听Storm仓库中提交的实时流([图2.9](#ch02fig09))。'
- en: Figure 2.9\. A spout reads from the feed of commit messages.
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.9\. Spout从提交消息的流中读取。
- en: '![](02fig09.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig09.jpg)'
- en: 'Spouts don’t perform any processing; they simply act as a source of streams,
    reading from a data source and emitting tuples to the next type of node in a topology:
    the bolt.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 喷发器不执行任何处理；它们只是作为流源，从数据源读取并将元组发射到拓扑中的下一个节点类型：螺栓。
- en: 2.2.5\. Bolt
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.5\. 螺栓
- en: Unlike a spout, whose sole purpose is to listen to a stream of data, a *bolt*
    accepts a tuple from its input stream, performs some computation or transformation—filtering,
    aggregation, or a join, perhaps—on that tuple, and then optionally emits a new
    tuple (or tuples) to its output stream(s).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 与仅用于监听数据流的目的的喷发器不同，*螺栓*从其输入流接受一个元组，对该元组执行一些计算或转换——可能是过滤、聚合或连接——然后可选地向其输出流（或多个输出流）发射新的元组（或多个元组）。
- en: 'The bolts in our example are as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们例子中的螺栓如下：
- en: '***A bolt that extracts the developer’s email from the commit*—** This bolt
    accepts a tuple containing a commit with a commit ID and email from its input
    stream. It transforms that input stream and emits a new tuple containing only
    the email address to its output stream.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***一个从提交中提取开发者电子邮件的螺栓*—** 这个螺栓从其输入流接受包含提交ID和电子邮件的元组。它转换输入流，并向其输出流发射只包含电子邮件地址的新元组。'
- en: '***A bolt that updates the map of emails to commit counts*—** This bolt accepts
    a tuple containing an email address from its input stream. Because this bolt updates
    an in-memory map and doesn’t emit a new tuple, it doesn’t produce an output stream.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***一个更新提交计数电子邮件映射的螺栓*—** 这个螺栓从其输入流接受包含电子邮件地址的元组。因为这个螺栓更新内存映射并不会发射新的元组，所以它不会产生输出流。'
- en: Both of these bolts are shown in [figure 2.10](#ch02fig10).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个螺栓都在[图2.10](#ch02fig10)中展示。
- en: Figure 2.10\. Bolts perform processing on the commit messages and associated
    emails within those messages.
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.10\. 螺栓对提交消息及其中的相关电子邮件进行处理。
- en: '![](02fig10_alt.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig10_alt.jpg)'
- en: The bolts in our example are extremely simple. As you move along in the book,
    you’ll create bolts that do much more complex transformations, sometimes even
    reading from multiple input streams and producing multiple output streams. We’re
    getting ahead of ourselves here, though. First you need to understand how bolts
    and spouts work in practice.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们例子中的螺栓非常简单。随着你在书中继续前进，你会创建执行更复杂转换的螺栓，有时甚至从多个输入流读取并产生多个输出流。不过，我们在这里有点超前了。首先，你需要了解螺栓和喷发器在实际中的工作方式。
- en: How Bolts and Spouts Work Under the Covers
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 在幕后螺栓和喷发器是如何工作的
- en: In [figures 2.9](#ch02fig09) and [2.10](#ch02fig10), both the spout and bolts
    were shown as single components. This is true from a logical standpoint. But when
    it comes to how spouts and bolts work in reality, there’s a little more to it.
    In a running topology, there are normally numerous instances of each type of spout/bolt
    performing computations in parallel. See [figure 2.11](#ch02fig11), where the
    bolt for extracting the email from the commit and the bolt for updating the email
    count are each running across three different instances. Notice how a single instance
    of one bolt is emitting a tuple to a single instance of another bolt.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图2.9](#ch02fig09)和[2.10](#ch02fig10)中，喷发器和螺栓都被显示为单个组件。从逻辑角度来看这是正确的。但是，当涉及到喷发器和螺栓在实际中的工作方式时，情况就更加复杂。在一个运行拓扑中，通常有大量每种类型的喷发器/螺栓实例并行执行计算。参见[图2.11](#ch02fig11)，其中提取提交中的电子邮件和更新电子邮件计数的螺栓各自在三个不同的实例上运行。注意一个螺栓的单个实例是如何向另一个螺栓的单个实例发射元组的。
- en: Figure 2.11\. There are normally multiple instances of a particular bolt emitting
    tuples to multiple instances of another bolt.
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.11\. 通常有多个特定螺栓的实例向多个另一个螺栓的实例发射元组。
- en: '![](02fig11_alt.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig11_alt.jpg)'
- en: '[Figure 2.11](#ch02fig11) shows just one possible scenario of how the tuples
    would be sent between instances of the two bolts. In reality, the picture is more
    like [figure 2.12](#ch02fig12), where each bolt instance on the left is emitting
    tuples to several different bolt instances on the right.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2.11](#ch02fig11)展示了两个螺栓实例之间元组发送的几种可能场景。实际上，情况更像是[图2.12](#ch02fig12)，其中左侧的每个螺栓实例都在向右侧的多个不同螺栓实例发射元组。'
- en: Figure 2.12\. Individual instances of a bolt can emit to any number of instances
    of another bolt.
  id: totrans-82
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.12\. 一个螺栓的单独实例可以向任何数量的另一个螺栓的实例发射。
- en: '![](02fig12_alt.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig12_alt.jpg)'
- en: 'Understanding the breakdown of spout and bolt instances is extremely important,
    so let’s pause for a moment and summarize what you know before diving into our
    final concept:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 理解喷发器和螺栓实例的分解非常重要，因此让我们暂停一下，总结一下在深入探讨最终概念之前你所知道的内容：
- en: A *topology* consists of *nodes* and *edges*.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *topology* 由 *nodes* 和 *edges* 组成。
- en: '*Nodes* represent either *spouts* or *bolts*.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Nodes* 代表 *spouts* 或 *bolts*。'
- en: '*Edges* represent *streams of tuples* between these spouts and bolts.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Edges* 代表这些 spout 和 bolt 之间的元组流。'
- en: A *tuple* is an ordered list of values, where each value is assigned a name.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *tuple* 是值的有序列表，其中每个值都被分配了一个名称。
- en: A *stream* is an unbounded sequence of tuples between a spout and a bolt or
    between two bolts.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *stream* 是 spout 和 bolt 或两个 bolt 之间的无界元组序列。
- en: A *spout* is the source of a stream in a topology, usually listening to some
    sort of live feed of data.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *spout* 是拓扑中流的来源，通常监听某种实时数据流。
- en: A *bolt* accepts a stream of tuples from a spout or another bolt, typically
    performing some sort of computation or transformation on these input tuples. The
    bolt can then optionally emit new tuples that serve as the input stream to another
    bolt in the topology.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *bolt* 接受来自 spout 或另一个 bolt 的元组流，通常对这些输入元组执行某种计算或转换。然后，bolt 可以选择性地发射新的元组，这些元组作为拓扑中另一个
    bolt 的输入流。
- en: Each spout and bolt will have one or many individual instances that perform
    all of this processing in parallel.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个 spout 和 bolt 都将有一个或多个单独的实例，这些实例并行执行所有这些处理。
- en: 'That’s quite a bit of material, so be sure to let this sink in before you move
    on. Ready? Good. Before we get into actual code, let’s tackle one more important
    concept: stream grouping.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一大堆内容，所以在继续之前请确保你已经消化了这些内容。准备好了吗？很好。在我们进入实际代码之前，让我们再解决一个重要概念：流分组。
- en: 2.2.6\. Stream grouping
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.6\. Stream grouping
- en: You know by now that a stream is an unbounded sequence of tuples between a spout
    and bolt or two bolts. A stream grouping defines how the tuples are sent between
    instances of those spouts and bolts. What do we mean by this? Let’s take a step
    back and look at our commit count topology. We have two streams in our GitHub
    commit count topology. Each of these streams will have their own stream grouping
    defined, telling Storm how to send individual tuples between instances of the
    spout and bolts ([figure 2.13](#ch02fig13)).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你知道流是一个无界的元组序列，在 spout 和 bolt 或两个 bolt 之间。流分组定义了元组如何在那些 spout 和 bolt 的实例之间发送。我们这是什么意思？让我们退一步，看看我们的提交计数拓扑。在我们的
    GitHub 提交计数拓扑中，我们有两个流。这些流中的每一个都将有自己的流分组定义，告诉 Storm 如何在 spout 和 bolt 的实例之间发送单个元组（[图
    2.13](#ch02fig13)）。
- en: Figure 2.13\. Each stream in the topology will have its own stream grouping.
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.13\. 拓扑中的每个流都将有自己的流分组。
- en: '![](02fig13.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig13.jpg)'
- en: 'Storm comes with several stream groupings out of the box. We’ll cover most
    of these throughout this book, starting with the two most common groupings in
    this chapter: the shuffle grouping and fields grouping.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Storm 默认提供几种流分组。我们将在本书中介绍这些分组中的大多数，从本章中两种最常见的分组开始：shuffle grouping 和 fields
    grouping。
- en: Shuffle grouping
  id: totrans-99
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Shuffle grouping
- en: The stream between our spout and first bolt uses a shuffle grouping. A *shuffle
    grouping* is a type of stream grouping where tuples are emitted to instances of
    bolts at random, as shown in [figure 2.14](#ch02fig14).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们 spout 和第一个 bolt 之间的流使用 shuffle grouping。一个 *shuffle grouping* 是一种流分组，其中元组随机发射到
    bolt 实例，如图 [2.14](#ch02fig14) 所示。
- en: Figure 2.14\. Using a shuffle grouping between our spout and first bolt
  id: totrans-101
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.14\. 在我们的 spout 和第一个 bolt 之间使用 shuffle grouping
- en: '![](02fig14_alt.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig14_alt.jpg)'
- en: In this example, we don’t care how tuples are passed to the instances of our
    bolts, so we choose the shuffle grouping to distribute tuples at random. Using
    a shuffle grouping will guarantee that each bolt instance should receive a relatively
    equal number of tuples, thus spreading the load across all bolt instances. Shuffle
    grouping assignment is done randomly rather than round robin so exact equality
    of distribution isn’t guaranteed.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们不在乎元组是如何传递到我们 bolt 实例的，所以我们选择 shuffle grouping 来随机分配元组。使用 shuffle grouping
    可以保证每个 bolt 实例应该接收相对相等数量的元组，从而在所有 bolt 实例之间分配负载。shuffle grouping 分配是随机进行的，而不是轮询，因此不能保证分配的精确平等。
- en: This grouping is useful in many basic cases where you don’t have special requirements
    about how your data is passed to bolts. But sometimes you have scenarios where
    sending tuples to random bolt instances won’t work based on your requirements—as
    in the case of our scenario for sending tuples between the bolt that extracts
    the email and the bolt that updates the email. We’ll need a different type of
    stream grouping for this.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分组在许多基本情况下都很有用，在这些情况下您没有关于如何将数据传递给bolt的特殊要求。但有时您会遇到一些场景，在这些场景中，根据您的需求，将元组发送到随机bolt实例将不起作用——就像我们在螺栓提取电子邮件和更新电子邮件之间发送元组的场景一样。我们需要不同类型的流分组来完成这项工作。
- en: Fields grouping
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 字段分组
- en: The stream between the bolt that extracts the email and the bolt that updates
    the email will need to use a fields grouping. A *fields grouping* ensures that
    tuples with the same value for a particular field name are always emitted to the
    same instance of a bolt. To understand why a fields grouping is necessary for
    our second stream, let’s look at the consequences of using an in-memory map to
    track the number of commits per email.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 提取电子邮件的bolt和更新电子邮件的bolt之间的流需要使用字段分组。*字段分组*确保具有特定字段名相同值的元组始终被发射到bolt的同一实例。为了理解为什么字段分组对我们第二个流是必要的，让我们看看使用内存映射来跟踪每个电子邮件提交数量的后果。
- en: Each bolt instance will have its own map for the email/commit count pairs, so
    it’s necessary that the same email go to the same bolt instance in order for the
    count for each email to be accurate across all bolt instances. A fields grouping
    provides exactly this ([figure 2.15](#ch02fig15)).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 每个bolt实例都将有自己的电子邮件/提交计数对映射，因此确保相同的电子邮件发送到同一bolt实例对于确保所有bolt实例中每个电子邮件的计数准确是必要的。字段分组正好提供了这一点([图2.15](#ch02fig15))。
- en: Figure 2.15\. Use a fields grouping for the bolt that will have a separate in-memory
    map for each bolt instance.
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.15\. 使用字段分组来处理将具有单独内存映射的每个螺栓实例的螺栓。
- en: '![](02fig15_alt.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![02fig15_alt.jpg](02fig15_alt.jpg)'
- en: In this example, the decision to use an in-memory map for the email count implementation
    resulted in the need for a fields grouping. We could’ve used a resource that was
    shared across bolt instances and eliminated that need. We’ll explore design and
    implementation considerations like this one in [chapter 3](kindle_split_011.html#ch03)
    and beyond, but for now let’s shift our focus to the code that we’ll need to get
    our topology up and running.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，使用内存映射来实现电子邮件计数决策导致了需要字段分组。我们本可以使用跨bolt实例共享的资源来消除这一需求。我们将在[第3章](kindle_split_011.html#ch03)及以后探讨类似的设计和实现考虑因素，但就目前而言，让我们将重点转移到我们需要使拓扑运行起来的代码上。
- en: 2.3\. Implementing a GitHub commit count dashboard in Storm
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 在Storm中实现GitHub提交计数仪表板
- en: Now that we’ve covered all the important concepts in Storm, it’s time to get
    into writing the code for our topology. This section will start with the code
    for the individual spout and bolts and introduce the relevant Storm interfaces
    and classes. Some of these interfaces and classes you’ll use directly and some
    you won’t; regardless, understanding the overall Storm API hierarchy will give
    you a fuller understanding of your topology and associated code.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了Storm中的所有重要概念，是时候开始编写我们拓扑的代码了。本节将从单个spout和bolt的代码开始，并介绍相关的Storm接口和类。其中一些接口和类您将直接使用，而另一些则不会；无论如何，理解Storm
    API的整体层次结构将使您对拓扑及其相关代码有更全面的理解。
- en: After we’ve introduced the code for the spout and bolts, we’ll go over the code
    required for putting it all together. If you remember from our earlier discussion,
    our topology contains streams and stream groupings. The code for the spout and
    bolts is only part of the picture—you still need to define where and how tuples
    are emitted between components in the topology. In our discussion of the code
    needed for building the topology, you’ll encounter some of Storm’s configuration
    options, most of which will be covered in greater detail later in the book.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们介绍了spout和bolt的代码之后，我们将讨论将所有这些放在一起所需的代码。如果您还记得我们之前的讨论，我们的拓扑包含流和流分组。spout和bolt的代码只是其中一部分——您仍然需要定义元组在拓扑组件之间发射的位置和方式。在讨论构建拓扑所需的代码时，您将遇到一些Storm的配置选项，其中大部分将在本书的后面部分进行更详细的介绍。
- en: Finally, after we’ve wired everything up by defining the streams and stream
    groupings in the topology, we’ll show you how to run your topology locally, allowing
    you to test whether everything works as expected. But before we dive into all
    this code, let’s set you up with a basic Storm project.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在我们通过在拓扑中定义流和流分组连接好一切之后，我们将向您展示如何在本地运行您的拓扑，让您可以测试一切是否按预期工作。但在我们深入所有这些代码之前，让我们为您设置一个基本的Storm项目。
- en: 2.3.1\. Setting up a Storm project
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1\. 设置Storm项目
- en: The easiest way to get the Storm JARs on your classpath for development is to
    use Apache Maven.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 将Storm JAR文件添加到您的类路径以进行开发的最简单方法是使用Apache Maven。
- en: '|  |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: You can find other ways to set up Storm at [http://storm.apache.org/documentation/Creating-a-new-Storm-project.html](http://storm.apache.org/documentation/Creating-a-new-Storm-project.html),
    but Maven is by far the simplest. Check out [http://maven.apache.org/](http://maven.apache.org/)
    for information on Maven.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[http://storm.apache.org/documentation/Creating-a-new-Storm-project.html](http://storm.apache.org/documentation/Creating-a-new-Storm-project.html)找到设置Storm的其他方法，但Maven无疑是其中最简单的。有关Maven的信息，请访问[http://maven.apache.org/](http://maven.apache.org/)。
- en: '|  |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Add the code shown in the next listing to your project’s pom.xml file.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 将下一列表中的代码添加到您的项目pom.xml文件中。
- en: Listing 2.2\. pom.xml
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.2\. pom.xml
- en: '![](025fig01_alt.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](025fig01_alt.jpg)'
- en: Once you’ve made these additions to your pom.xml file, you should have all the
    necessary dependencies for writing code and running Storm topologies locally on
    your development machine.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将这些添加到pom.xml文件中，您应该拥有编写代码和在本地的开发机器上运行Storm拓扑所必需的所有依赖项。
- en: 2.3.2\. Implementing the spout
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2\. 实现喷口
- en: Because the spout is where data enters a topology, this is where we’ll begin
    our coding. Before diving into the details, let’s examine the general interface
    and class structure within Storm for the spout. [Figure 2.16](#ch02fig16) explains
    this class hierarchy.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 因为拓扑中的数据入口是喷口（spout），所以我们将从这里开始编码。在深入细节之前，让我们先检查Storm中喷口的一般接口和类结构。[图2.16](#ch02fig16)解释了这个类层次结构。
- en: Figure 2.16\. Storm’s class hierarchy for the spout
  id: totrans-127
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.16\. Storm的喷口类层次结构
- en: '![](02fig16_alt.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig16_alt.jpg)'
- en: In this design, the spout listens to a live feed of commits being made to a
    particular GitHub project using the GitHub API and emits tuples, each containing
    an entire commit message, as shown in [figure 2.17](#ch02fig17).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个设计中，喷口通过GitHub API监听对特定GitHub项目的提交实时流，并发出包含整个提交信息的元组，如图[图2.17](#ch02fig17)所示。
- en: Figure 2.17\. The spout listens to the feed of commit messages and emits a tuple
    for each commit message.
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.17\. 喷口监听提交信息流并为每个提交信息发出一个元组。
- en: '![](02fig17.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig17.jpg)'
- en: Setting up a spout to listen to a live feed requires a bit of work that we feel
    is a distraction from understanding the basic code. Because of this, we’re going
    to cheat and simulate a live feed by having our spout continuously read from a
    file of commit messages, emitting a tuple for each line in the file. Don’t worry;
    in later chapters we’ll wire up spouts to live feeds, but for now our focus is
    on the basics. The file changelog.txt will live next to the class for our spout
    and contain a list of commit messages in the expected format (shown in the following
    listing).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 设置一个喷口以监听实时流需要一些工作，我们认为这会分散对基本代码的理解。因此，我们将采取作弊的方式，通过让我们的喷口持续读取一个包含提交信息的文件来模拟实时流，并为文件中的每一行发出一个元组。不用担心；在后面的章节中，我们将连接喷口到实时流，但现在我们的重点是基础知识。changelog.txt文件将位于我们的喷口类旁边，并包含预期格式的提交信息列表（如下所示）。
- en: 'Listing 2.3\. An excerpt from our simple data source: changelog.txt'
  id: totrans-133
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.3\. 我们简单数据源的摘录：changelog.txt
- en: '[PRE2]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Once we’ve defined the source of our data, we can move to the spout implementation,
    as shown in the next listing.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义了数据源，我们就可以转向喷口的实现，如下一列表所示。
- en: Listing 2.4\. CommitFeedListener.java
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.4\. CommitFeedListener.java
- en: '![](ch02ex04-0.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](ch02ex04-0.jpg)'
- en: '![](ch02ex04-1.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](ch02ex04-1.jpg)'
- en: Quite a bit is going on with our spout. We start by extending `BaseRichSpout`,
    which gives us three methods that need to be overridden. The first of these methods
    is `declareOutputFields`. Remember earlier in the chapter when we said we’d discuss
    how Storm assigns names to tuples? Well, here we are. The `declareOutputFields`
    method is where we define the names for the values in tuples being emitted by
    this spout. Defining names for emitted tuple values is done with the `Fields`
    class, whose constructor accepts multiple strings; each string is the name of
    a value in an emitted tuple. The order of the names in the `Fields` constructor
    must match the order of the values emitted in the tuple via the `Values` class.
    Because the tuple emitted by our spout contains a single value, we have a single
    argument, `commit`, passed into `Fields`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的spout中正在进行很多事情。我们首先通过扩展`BaseRichSpout`，这给了我们三个需要重写的方法。这些方法中的第一个是`declareOutputFields`。记得在章节开头我们提到过我们会讨论Storm如何为元组分配名称吗？嗯，这里就是。`declareOutputFields`方法是我们定义这个spout发射的元组中值的名称的地方。为发射的元组值定义名称是通过`Fields`类完成的，其构造函数接受多个字符串；每个字符串是发射元组中值的名称。`Fields`构造函数中名称的顺序必须与通过`Values`类在元组中发射的值的顺序相匹配。因为我们的spout发射的元组包含单个值，所以我们向`Fields`传递了一个单个参数，`commit`。
- en: The next method we need to override is `open`; this is where we read the contents
    of changelog.txt into our list of strings. If we’re writing code for a spout that
    deals with a live data source, such as a message queue, this is where we’d put
    the code for connecting to that data source. You’ll see more on this beginning
    in [chapter 3](kindle_split_011.html#ch03).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个我们需要重写的方法是`open`；这是我们将changelog.txt的内容读入我们的字符串列表中的地方。如果我们为处理实时数据源（如消息队列）的spout编写代码，这就是我们放置连接到该数据源代码的地方。你将在第3章开始时看到更多关于这个的内容。[第3章](kindle_split_011.html#ch03)。
- en: The final method we need to override is `nextTuple`. This is the method Storm
    calls when it’s ready for the spout to read and emit a new tuple and is usually
    invoked periodically as determined by Storm. In our example we’re emitting a new
    tuple for each value in our list every time `nextTuple` is called, but for something
    that reads from a live data source, such as a message queue, a new tuple will
    only be emitted if a new piece of data is available.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要重写的最后一个方法是`nextTuple`。这是Storm在准备好让spout读取和发射一个新的元组时调用的方法，通常根据Storm的周期性调用。在我们的例子中，每次调用`nextTuple`时，我们都会为列表中的每个值发射一个新的元组，但对于从实时数据源读取的东西，例如消息队列，只有当有新的数据可用时，才会发射新的元组。
- en: You’ll also notice a class called `SpoutOutputCollector`. Output collectors
    are something you’ll see quite a bit for both spouts and bolts. They’re responsible
    for emitting and failing tuples.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 你还会注意到一个名为`SpoutOutputCollector`的类。输出收集器是你在spout和bolt中都会经常看到的东西。它们负责发射和失败元组。
- en: Now that we know how our spout obtains commit messages from our data source
    and emits new tuples for each commit message, we need to implement the code that
    transforms these commit messages into a map of emails to commit counts.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了我们的spout如何从数据源获取提交消息并为每个提交消息发射新的元组，我们需要实现将这些提交消息转换成电子邮件到提交计数映射的代码。
- en: 2.3.3\. Implementing the bolts
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.3\. 实现bolt
- en: We’ve implemented the spout that serves as the source of a stream, so now it’s
    time to move on to the bolts. [Figure 2.18](#ch02fig18) explains the general interface
    and class structure within Storm for bolts.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经实现了作为流源头的spout，现在该转向bolt了。[图2.18](#ch02fig18)解释了Storm中bolt的一般接口和类结构。
- en: Figure 2.18\. Storm’s class hierarchy for the bolt
  id: totrans-146
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.18\. Bolt的Storm类层次结构
- en: '![](02fig18_alt.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图2.18的替代文本](02fig18_alt.jpg)'
- en: You’ll notice in [figure 2.18](#ch02fig18) that the class hierarchy for a bolt
    is a little more complex than that of a spout. The reason is that Storm has additional
    classes for bolts that have incredibly simple implementations (`IBasicBolt`/`BaseBasicBolt`).
    These take over the responsibilities usually accessible to a developer with `IRichBolt`,
    so it makes simpler bolt implementations more concise. The simplicity of `IBasic-Bolt`
    does come at the cost of taking away some of the fluency of the rich feature set
    made accessible through `IRichBolt`. We’ll cover the differences between `BaseRichBolt`
    and `Base-BasicBolt` and explain when to use either in more detail in [chapter
    4](kindle_split_012.html#ch04). In this chapter, we’ll use `BaseBasicBolt` because
    the bolt implementations are quite straightforward.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你会在 [图 2.18](#ch02fig18) 中注意到，bolt 的类层次结构比 spout 的稍微复杂一些。原因是 Storm 为那些具有极其简单实现（`IBasicBolt`/`BaseBasicBolt`）的
    bolt 提供了额外的类。这些类接管了通常由 `IRichBolt` 可用的责任，因此使得 bolt 的简单实现更加简洁。`IBasicBolt` 的简单性是以牺牲通过
    `IRichBolt` 可用的丰富功能集的流畅性为代价的。我们将在 [第 4 章](kindle_split_012.html#ch04) 中详细说明 `BaseRichBolt`
    和 `Base-BasicBolt` 之间的区别，并解释何时使用任一。在本章中，我们将使用 `BaseBasicBolt`，因为 bolt 的实现相当直接。
- en: To revisit our design, remember that we have two bolts in our topology (see
    [figure 2.19](#ch02fig19)). One bolt accepts a tuple containing the full commit
    message, extracts the email from the commit message, and emits a tuple containing
    the email. The second bolt maintains an in-memory map of emails to commit counts.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 要回顾我们的设计，请记住，在我们的拓扑中有两个 bolt（见图 2.19）。一个 bolt 接受包含完整提交消息的元组，从中提取电子邮件，并发射包含电子邮件的元组。第二个
    bolt 维护一个电子邮件到提交计数的内存映射。
- en: 'Figure 2.19\. The two bolts in our topology: the first bolt extracts the email
    from the commit message and the second bolt maintains an in-memory map of emails
    to commit counts.'
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.19\. 我们拓扑中的两个 bolt：第一个 bolt 从提交消息中提取电子邮件，第二个 bolt 维护一个电子邮件到提交计数的内存映射。
- en: '![](02fig19.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](02fig19.jpg)'
- en: Let’s take a look at the code for these bolts, starting with EmailExtractor.java
    in the next listing.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些 bolt 的代码，从下一列表中的 EmailExtractor.java 开始。
- en: Listing 2.5\. EmailExtractor.java
  id: totrans-153
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.5\. EmailExtractor.java
- en: '![](029fig01_alt.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](029fig01_alt.jpg)'
- en: The implementation for EmailExtractor.java is quite small, which is the main
    reason we decided to extend `BaseBasicBolt`. If you look a little deeper into
    the code, you’ll notice some similarities to our spout code, namely the manner
    in which we declare the names for the values in tuples emitted by this bolt. Here
    we’ve defined a single field with a name of `email`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: EmailExtractor.java 的实现相当小，这也是我们决定扩展 `BaseBasicBolt` 的主要原因。如果你稍微深入一点查看代码，你会注意到它与我们的
    spout 代码有一些相似之处，即我们声明这个 bolt 发射的元组中值的名称的方式。在这里，我们定义了一个名为 `email` 的单个字段。
- en: As far as the bolt’s `execute` method is concerned, all we’re doing is splitting
    the string on the whitespace in order to obtain the email and emitting a new tuple
    with that email. Remember the output collector we mentioned in the previous spout
    implementation? We have something similar here with `BasicOutputCollector`, which
    emits this tuple, sending it to the next bolt in the topology, the email counter.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 就 bolt 的 `execute` 方法而言，我们只是在空白处拆分字符串以获取电子邮件，并发射一个包含该电子邮件的新元组。还记得我们之前在 spout
    实现中提到的输出收集器吗？这里我们也有类似的东西，即 `BasicOutputCollector`，它发射这个元组，将其发送到拓扑中的下一个 bolt，即电子邮件计数器。
- en: The code in the email counter is similar in structure to EmailExtractor.java
    but with a little more setup and implementation, as shown in the next listing.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件计数器中的代码结构与 EmailExtractor.java 类似，但设置和实现稍微多一点，如下一列表所示。
- en: Listing 2.6\. EmailCounter.java
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.6\. EmailCounter.java
- en: '![](ch02ex06-0.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](ch02ex06-0.jpg)'
- en: '![](ch02ex06-1.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](ch02ex06-1.jpg)'
- en: Again, we’ve decided to extend `BaseBasicBolt`. Even though EmailCounter.java
    is more complex than EmailExtractor.java, we can still get away with the functionality
    accessible by `BaseBasicBolt`. One difference you’ll notice is that we’ve overridden
    the `prepare` method. This method gets called as Storm prepares the bolt before
    execution and is the method where we’d perform any setup for our bolt. In our
    case, this means instantiating the in-memory map.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们决定扩展 `BaseBasicBolt`。尽管 EmailCounter.java 比 EmailExtractor.java 更复杂，但我们仍然可以通过
    `BaseBasicBolt` 获取的功能来实现。你会注意到的一个区别是我们重写了 `prepare` 方法。这个方法在 Storm 准备 bolt 执行之前被调用，是我们为
    bolt 执行任何设置的方法。在我们的情况下，这意味着实例化内存映射。
- en: Speaking of the in-memory map, you’ll notice this is a private member variable
    that’s specific to a single instance of this bolt. This should ring a bell, as
    it’s something we mentioned in [section 2.2.6](#ch02lev2sec8), and it’s why we
    were forced to use a fields grouping for the stream between our two bolts.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到内存映射，你会发现这是一个针对单个bolt实例的私有成员变量。这应该让你想起我们在[2.2.6节](#ch02lev2sec8)中提到的事情，这也是我们被迫在两个bolt之间的流中使用fields分组的理由。
- en: So here we are; we have code for our spout and two bolts. What’s next? We need
    to somehow tell Storm where the streams are and identify the stream groupings
    for each of those streams. And we imagine you’re eager to run this topology and
    see it in action. Here’s where wiring everything together comes into play.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们现在有了我们的spout和两个bolt的代码。接下来是什么？我们需要以某种方式告诉Storm流的位置，并为每个流标识流分组。我们想象你很渴望运行这个拓扑并看到它的实际效果。这就是将所有组件连接起来发挥作用的地方。
- en: 2.3.4\. Wiring everything together to form the topology
  id: totrans-164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.4\. 将所有组件连接起来形成拓扑结构
- en: 'Our spout and bolt implementations aren’t useful on their own. We need to build
    up the topology, defining the streams and stream groupings between the spout and
    bolts. After that, we’d like to be able to run a test to make sure it all works
    as expected. Storm provides all the classes you need to do this. These classes
    include the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们spout和bolt的实现本身并没有什么用处。我们需要构建拓扑，定义spout和bolt之间的流和流分组。之后，我们希望能够运行一个测试来确保一切按预期工作。Storm提供了你完成这个任务所需的所有类。这些类包括以下内容：
- en: '**`TopologyBuilder`—** This class is used to piece together spouts and bolts,
    defining the streams and stream groupings between them.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`TopologyBuilder`—** 这个类用于拼接spout和bolt，定义它们之间的流和流分组。'
- en: '**`Config`—** This class is used for defining topology-level configuration.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`Config`—** 这个类用于定义拓扑级别的配置。'
- en: '**`StormTopology`—** This class is what `TopologyBuilder` builds and is what’s
    submitted to the cluster to be run.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`StormTopology`—** 这个类是`TopologyBuilder`构建的，也是提交给集群运行的内容。'
- en: '**`LocalCluster`—** This class simulates a Storm cluster in-process on our
    local machine, allowing us to easily run our topologies for testing purposes.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`LocalCluster`—** 这个类在本地机器上模拟Storm集群，允许我们轻松地运行拓扑进行测试。'
- en: With a basic understanding of these classes, we’ll build our topology and submit
    it to a local cluster, as seen in the next listing.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在对这些类有了基本理解之后，我们将构建拓扑并将其提交给本地集群，如下一列表所示。
- en: Listing 2.7\. LocalTopologyRunner.java
  id: totrans-171
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.7\. LocalTopologyRunner.java
- en: '![](ch02ex07-0.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](ch02ex07-0.jpg)'
- en: '![](ch02ex07-1.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](ch02ex07-1.jpg)'
- en: You can think of the main method as being split into three sections. The first
    is where we build the topology and tell Storm where the streams are and identify
    the stream groupings for each of these streams. The next part is creating the
    configuration. In our example, we’ve turned on debug logging. Many more configuration
    options are available that we’ll cover later in this book. The final part is where
    we submit both the configuration and built topology to the local cluster to be
    run. Here we run the local cluster for 10 minutes, continuously emitting tuples
    for each commit message in our changelog.txt file. This should provide plenty
    of activity within our topology.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将主方法想象成分为三个部分。第一部分是我们构建拓扑并告诉Storm流的位置，以及为这些流标识流分组。下一部分是创建配置。在我们的例子中，我们已经打开了调试日志。本书后面还会介绍更多配置选项。最后一部分是将配置和构建的拓扑提交给本地集群以运行。在这里，我们运行本地集群10分钟，持续发出我们的changelog.txt文件中每个提交消息的tuple。这应该在拓扑中提供足够的活动。
- en: If we were to run the main method of LocalTopologyRunner.java via `java -jar`,
    we would see debug log messages flying by in the console showing tuples being
    emitted by our spout and processed by our bolts. And there you have it; you’ve
    built your first topology! With the basics covered, we still need to address some
    of the topics we alluded to in this chapter. We’ll start with addressing some
    good topology design practices to follow in [chapter 3](kindle_split_011.html#ch03).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们通过`java -jar`运行LocalTopologyRunner.java的主方法，我们会在控制台看到调试日志消息飞快地闪过，显示我们的spout发出的tuple和我们的bolt处理的tuple。就这样；你已经构建了你的第一个拓扑！在掌握了基础知识之后，我们仍需要解决本章中提到的某些问题。我们将从解决一些好的拓扑设计实践开始，这些实践将在[第3章](kindle_split_011.html#ch03)中介绍。
- en: 2.4\. Summary
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4\. 概述
- en: In this chapter, you learned that
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了以下内容
- en: A topology is a graph where the nodes represent a single process or computation
    and the edges represent the result of one computation being passed as the input
    to another computation.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拓扑是一个图，其中节点代表单个进程或计算，边代表一个计算的结果作为另一个计算的输入。
- en: A tuple is an ordered list of values where each value in the list is assigned
    a name. A tuple represents the data passed between two components.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元组是有序值列表，其中列表中的每个值都分配了一个名称。元组代表两个组件之间传递的数据。
- en: The flow of tuples between two components is called a stream.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个组件之间元组的流动称为流。
- en: Spouts act as the source of a stream; their sole purpose is to read data from
    a source and emit tuples to its output stream.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发射器充当流的来源；它们唯一的目的就是从源读取数据并将其元组发出到输出流。
- en: Bolts are where the core logic in a topology exists, performing operations such
    as filters, aggregations, joins, and talking to databases.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 螺栓是拓扑中核心逻辑所在之处，执行如过滤器、聚合、连接和与数据库通信等操作。
- en: Both spouts and bolts (called components) execute as one or more individual
    instances, emitting tuples to other instances of bolts.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集合器和螺栓（称为组件）作为单个或多个实例执行，向其他螺栓实例发出元组。
- en: The manner in which tuples flow between individual instances of components is
    defined with a stream grouping.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元组在组件的各个实例之间流动的方式由流分组定义。
- en: Implementing the code for your spouts and bolts is only part of the picture;
    you still need to wire them together and define the streams and stream groupings.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为您的发射器和螺栓实现代码只是其中一部分；您还需要将它们连接起来并定义流和流分组。
- en: Running a topology in local mode is the quickest way to test that your topology
    is working.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本地模式下运行拓扑是测试您的拓扑是否正常工作的最快方式。
