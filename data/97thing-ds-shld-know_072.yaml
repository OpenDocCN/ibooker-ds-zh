- en: Chapter 67\. Should Chatbots Be Held to a Higher Ethical Standard than Humans?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第67章。聊天机器人是否应该比人类拥有更高的道德标准？
- en: Naomi Arcadia Kaduwela
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Naomi Arcadia Kaduwela
- en: '![](Images/Naomi_Arcadia_Kaduwela.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/Naomi_Arcadia_Kaduwela.png)'
- en: Head of Kavi Labs, Kavi Global
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Kavi Labs的负责人，Kavi Global
- en: 'We have seen an explosion of chatbots in the market. AI has become ingrained
    into the daily fabric of our lives. Service industries have turned to AI-driven
    chatbots to manage customer interactions, increasing speed and quality of resolution
    while decreasing cost. Millennials increasingly prefer to interact with chatbots
    rather than humans. As we embrace chatbots in our lives, it is paramount to evaluate
    the role they play in reinforcing and perpetuating societal biases and stereotypes.
    With the proliferation of chatbots creating a new paradigm of human and machine
    collaboration, an interesting ethical question emerges: should we hold chatbots
    to a higher ethical standard than we hold ourselves?'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到市场上聊天机器人的爆炸性增长。AI已经深深融入到我们日常生活的织物中。服务行业已经转向由AI驱动的聊天机器人来管理客户互动，提高解决问题的速度和质量，同时降低成本。千禧一代越来越倾向于与聊天机器人而不是与人类进行互动。当我们在生活中接纳聊天机器人时，评估它们在强化和延续社会偏见和刻板印象中所扮演角色至关重要。随着聊天机器人的普及，一种有趣的伦理问题浮现出来：我们是否应该对聊天机器人提出比对自己更高的道德标准？
- en: Underlying chatbots are natural language processing (NLP) models made up of
    deep learning algorithms called neural networks. Deep learning models have the
    ability to accurately map complex relationships from messy data—in text as well
    as images. So what are popular NLP models like convolutional neural networks (CNNs),
    recurrent neural networks (RNNs), and long short-term memory networks (LSTMs)
    doing in chatbots? They are mathematically defining relationships between words,
    as explicitly or implicitly defined in the training corpus.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人的核心是由称为神经网络的深度学习算法组成的自然语言处理（NLP）模型。深度学习模型具有从杂乱数据（文本和图像）中精确映射复杂关系的能力。那么像卷积神经网络（CNNs）、循环神经网络（RNNs）和长短期记忆网络（LSTMs）这样的流行NLP模型在聊天机器人中做些什么呢？它们数学地定义单词之间的关系，如同训练语料库中明确或隐含定义的那样。
- en: Examples of Chatbots Inheriting Human Biases
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聊天机器人继承人类偏见的例子
- en: There have been several disconcerting NLP algorithm mishaps. Amazon’s secret
    AI recruiting tool showed bias against women. Microsoft’s now-infamous chatbot
    Tay14, a machine learning experiment in social interaction, had to be decommissioned
    when it picked up a series of racial slurs.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 已经发生过几起令人不安的NLP算法失误。亚马逊的秘密AI招聘工具显示出对女性的偏见。微软那个如今臭名昭著的聊天机器人Tay14，在社交互动的机器学习实验中，由于接受了一系列种族歧视言论，不得不被停用。
- en: These stories shock and outrage us. We are quick to blame the company or the
    AI developer. Yet it is human-generated data that these NLP models are trained
    on. NLP models are only exposing the existing human bias learned from the training
    data. NLP mishaps are a reflection of humanity’s dark side.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这些故事让我们感到震惊和愤慨。我们往往责怪公司或AI开发者。然而，这些NLP模型所训练的是人类生成的数据。NLP模型仅仅是暴露了从训练数据中学到的现有人类偏见。NLP的失误反映了人类的黑暗面。
- en: How Chatbots Perpetuate Human Biases
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何聊天机器人延续人类偏见
- en: Just as a child’s code of ethics is shaped by its parents and environment, machine
    learning models learn from human-generated training data specified by their creators.
    Just as humans grow wiser with experience, machine learning models require large
    training corpuses to learn robust and generalizable relationships. And just as
    children grow up and pass on their code of ethics, as well as their biases, machines
    too will perpetuate their code of ethics and their biases through interactions
    with future generations. The difference is that these machines are immortal and
    will transcend generations in time. Thus our chatbots must be held to the highest
    ethical standard and must correct for the biases in training data generated by
    fallible humans.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 就像一个孩子的道德准则是由其父母和环境塑造的一样，机器学习模型从其创建者指定的人类生成的训练数据中学习。就像人类通过经验变得更加睿智一样，机器学习模型需要大量的训练语料库来学习强健且具有泛化能力的关系。正如孩子长大并传递他们的道德准则和偏见一样，机器也将通过与未来世代的互动延续它们的道德准则和偏见。不同的是，这些机器是不朽的，将在时间中超越世代。因此，我们的聊天机器人必须被置于最高的道德标准，并且必须纠正由有缺陷的人类生成的训练数据中存在的偏见。
- en: Ways to Correct Biases in Chatbots
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 纠正聊天机器人偏见的方法
- en: In continuous pursuit of excellence, we must admit our fallibility and look
    to correct it in generations to come. From an NLP modeling perspective, three
    bias correction methods exist to help chatbots overcome human biases in their
    training data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在追求卓越的不断过程中，我们必须承认我们的过失，并寻求在未来几代中加以纠正。从NLP建模的角度看，存在三种偏见校正方法，帮助聊天机器人克服其训练数据中的人类偏见。
- en: One option is to completely remove the biased concept from the NLP model. For
    example, in preparation for an NLP model, words and phrases in a training corpus
    are mapped to a vector of real numbers called word embeddings. Mathematically,
    gender can be subtracted from these vectors. However, completely removing the
    concept of gender might not prove practical in applications where it is a key
    predictor or segmentation variable. An alternative for removing gender stereotypes,
    while still keeping the concept of gender, is to simply remove gender stereotypes
    we don’t want (e.g., receptionist) and keep those we do (e.g., CEO). Finally,
    additional data can be synthetically generated by flipping pronouns (i.e., “he”
    and “she”) so that the model does not learn any unintended bias due to lack of
    representation in the training data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一种选择是从NLP模型中完全删除有偏见的概念。例如，在准备NLP模型时，训练语料库中的单词和短语被映射到称为词嵌入的实数向量中。从数学上讲，可以从这些向量中减去性别。然而，在性别是关键预测变量或分割变量的应用中，完全删除性别的概念可能不实际。在保留性别概念的同时消除性别刻板印象的一种替代方法是简单地删除我们不希望的性别刻板印象（例如接待员），并保留我们希望的（例如CEO）。最后，可以通过翻转代词（即“他”和“她”）来合成生成额外的数据，以使模型不会由于训练数据中表现不足而学习到任何意外的偏见。
- en: Why Continuous Learning Is Required for Chatbots
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为何聊天机器人需要持续学习
- en: We see that our code of ethics has continually evolved over thousands of years.
    Recent progress has been made with civil rights, women’s rights, and the LGBT
    movement. Though the core principles of ethics have not fundamentally changed
    since the time of Socrates, the practical application of ethics is fluid and is
    constantly evolving alongside society. If we hardcode today’s biases into immortal
    machines, we will pollute the minds of future generations with the biases of generations
    past, slowing the ethical evolution of the human race. Instead, we can leverage
    techniques to help chatbots overcome today’s human biases, so they can in turn
    make the human race better, ethically speaking!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，我们的道德准则在数千年间不断发展演变。近年来，公民权利、妇女权利和LGBT运动取得了进展。尽管自苏格拉底时代以来道德的核心原则并未根本改变，道德的实际应用是流动的，并且随着社会的不断发展而不断演变。如果我们把今天的偏见硬编码到永恒的机器中，我们将用过去几代人的偏见来污染未来几代人的思想，从而减缓人类道德进化的步伐。相反，我们可以利用技术手段帮助聊天机器人克服今天的人类偏见，这样它们反过来可以使人类在道德上变得更好！
