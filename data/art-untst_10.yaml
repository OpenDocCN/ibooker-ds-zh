- en: 7 Trustworthy tests
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 可信的测试
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: How to know you trust a test
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何知道你信任一个测试
- en: Detecting untrustworthy failing tests
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测不可靠的失败测试
- en: Detecting untrustworthy passing tests
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测不可靠的通过测试
- en: Dealing with flaky tests
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理不可靠的测试
- en: 'No matter how you organize your tests, or how many you have, they’re worth
    very little if you can’t trust them, maintain them, or read them. The tests that
    you write should have three properties that together make them good:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你如何组织你的测试，或者你有多少测试，如果你不能信任它们，维护它们，或者阅读它们，那么它们的价值非常小。你编写的测试应该具有三个属性，这三个属性共同使它们变得很好：
- en: '*Trustworthiness*—Developers will want to run trustworthy tests, and they’ll
    accept the test results with confidence. Trustworthy tests don’t have bugs, and
    they test the right things.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可信度*——开发者会想要运行可信的测试，并且会自信地接受测试结果。可信的测试没有错误，并且测试了正确的事情。'
- en: '*Maintainability*—Unmaintainable tests are nightmares because they can ruin
    project schedules, or they may be sidelined when the project is put on a more
    aggressive schedule. Developers will simply stop maintaining and fixing tests
    that take too long to change or that need to change often on very minor production
    code changes.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可维护性*——不可维护的测试是噩梦，因为它们可能会破坏项目进度，或者当项目被安排得更激进时，它们可能会被搁置。开发者会简单地停止维护和修复那些改变时间过长或需要经常在非常小的生产代码更改上更改的测试。'
- en: '*Readability*—This refers not only to being able to read a test but also figuring
    out the problem if the test seems to be wrong. Without readability, the other
    two pillars fall pretty quickly. Maintaining tests becomes harder, and you can’t
    trust them anymore because you don’t understand them.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可读性*——这不仅指的是能够阅读测试，还包括如果测试看起来是错误的，能够找出问题。如果没有可读性，其他两个支柱会很快倒塌。维护测试变得更加困难，而且你不再信任它们，因为你不理解它们。'
- en: This chapter and the next two present a series of practices related to each
    of these pillars that you can use when doing test reviews. Together, the three
    pillars ensure your time is well used. Drop one of them, and you run the risk
    of wasting everyone’s time.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章和接下来的两章将介绍一系列与这些支柱相关的实践，你可以在进行测试审查时使用。这三个支柱共同确保你的时间得到有效利用。去掉任何一个，你都有浪费大家时间的风险。
- en: Trust is the first of the three pillars that I like to evaluate good unit tests
    on, so it’s fitting that we start with it. If we don’t trust the tests, what’s
    the point in running them? What’s the point in fixing them or fixing the code
    if they fail? What’s the point of maintaining them?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 信任是我喜欢评估良好单元测试的三个支柱中的第一个，所以我们从它开始。如果我们不相信测试，运行它们有什么意义？如果它们失败了，修复它们或修复代码有什么意义？维护它们有什么意义？
- en: 7.1 How to know you trust a test
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 如何知道你信任一个测试
- en: What does “trust” mean for a software developer in the context of a test? Perhaps
    it’s easier to explain based on what we do or don’t do when a test fails or passes.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于软件开发者来说，“信任”在测试的背景下意味着什么？也许我们可以根据测试失败或通过时我们做什么或不做什么来解释得更清楚。
- en: You might not trust a test if
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能不会信任一个测试，如果
- en: It fails and you’re not worried (you believe it’s a false positive).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它失败了，但你并不担心（你相信这是一个假阳性）。
- en: You feel like it’s fine to ignore the results of this test, either because it
    passes every once in a while or because you feel it’s not relevant or buggy.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你觉得忽略这个测试的结果是可以接受的，要么是因为它偶尔会通过，要么是因为你觉得它不相关或存在错误。
- en: It passes and you are worried (you believe it’s a false negative).
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通过了，但你很担心（你相信这是一个假阴性）。
- en: You still feel the need to manually debug or test the software “just in case.”
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你仍然觉得有必要手动调试或测试软件“以防万一”。
- en: You might trust the test if
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会信任这个测试，如果
- en: The test fails and you’re genuinely worried that something broke. You don’t
    move on, assuming the test is wrong.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试失败了，你真正担心的是出了问题。你不会继续前进，假设测试是错误的。
- en: The test passes and you feel relaxed, not feeling the need to test or debug
    manually.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试通过了，你感到放松，不需要手动测试或调试。
- en: In the next few sections, we’ll look at test failures as a way to identify untrustworthy
    tests, and we’ll look at passing tests’ code and see how to detect untrustworthy
    test code. Finally, we’ll cover a few generic practices that can enhance trustworthiness
    in tests.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将通过查看测试失败作为识别不可信测试的方法，我们将查看通过测试的代码，看看如何检测不可信的测试代码。最后，我们将介绍一些通用的实践，这些实践可以提高测试的可信度。
- en: 7.2 Why tests fail
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 为什么测试会失败
- en: Ideally, your tests (any tests, not just unit tests) should only be failing
    for *a good reason*. That good reason is, of course, that a real bug was uncovered
    in the underlying production code.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，你的测试（任何测试，而不仅仅是单元测试）应该只因为*一个好理由*而失败。当然，这个好理由是在底层生产代码中发现了真实错误。
- en: Unfortunately, tests can fail for a multitude of reasons. We can assume that
    a test failing for any reason other than that one good reason should trigger an
    “untrustworthy” warning, but not all tests fail the same way, and recognizing
    the reasons tests may fail can help us build a roadmap for what we’d like to do
    in each case.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，测试可能因为多种原因而失败。我们可以假设，除了那个好理由之外，任何其他原因导致的测试失败都应该触发一个“不可信”的警告，但并非所有测试都以相同的方式失败，识别测试可能失败的原因可以帮助我们为每种情况制定一个路线图。
- en: 'Here are some reasons that tests fail:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些测试失败的原因：
- en: A real bug has been uncovered in the production code
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产代码中已发现一个真实错误
- en: A buggy test gives a false failure
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有错误的测试会导致错误失败
- en: The test is out of date due to a change in functionality
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于功能更改，测试已过时
- en: The test conflicts with another test
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试与另一个测试冲突
- en: The test is flaky
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试是不稳定的
- en: Except for the first point here, all these reasons are the test telling you
    it should not be trusted in its current form. Let’s go through them.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这里提到的第一个点之外，所有这些原因都是测试在告诉你，它当前的形式不可信。让我们逐一分析。
- en: 7.2.1 A real bug has been uncovered in the production code
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.1 生产代码中已发现一个真实错误
- en: The first reason a test will fail is when there is a bug in the production code.
    That’s good! That’s why we have tests. Let’s move on to the other reasons tests
    fail.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 测试失败的第一个原因是生产代码中存在错误。那很好！这就是我们为什么要有测试。让我们继续探讨测试失败的其他原因。
- en: 7.2.2 A buggy test gives a false failure
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.2 有错误的测试会导致错误失败
- en: A test will fail if the test is buggy. The production code might be correct,
    but that doesn’t matter if the test itself has a bug that causes the test to fail.
    It could be that you’re asserting on the wrong expected result of an exit point,
    or that you’re using the system under test incorrectly. It could be that you’re
    setting up the context for the test wrong or that you misunderstand what you were
    supposed to test.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试有错误，测试将失败。生产代码可能正确，但如果测试本身存在导致测试失败的错误，那就没关系了。可能是你断言了错误的退出点预期结果，或者你错误地使用了正在测试的系统。也可能是你设置测试上下文错误，或者你误解了你应该测试的内容。
- en: Either way, a buggy test can be quite dangerous, because a bug in a test can
    also cause it to *pass* and leave you unsuspecting of what’s really going on.
    We’ll talk more about tests that don’t fail but should later in the chapter.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 无论哪种方式，有错误的测试都可能非常危险，因为测试中的错误也可能导致它*通过*，让你对实际情况毫无察觉。我们将在本章后面更多地讨论那些不应该失败但确实失败的测试。
- en: How to recognize a buggy test
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如何识别有错误的测试
- en: You have a failing test, but you might have already debugged the production
    code and couldn’t find any bug there. This is when you should start suspecting
    the failing test. There’s no way around it. You’re going to have to slowly debug
    the test code.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你有一个失败的测试，但你可能已经调试了生产代码，在那里没有找到任何错误。这时你应该开始怀疑失败的测试。没有其他办法。你将不得不慢慢调试测试代码。
- en: 'Here are some potential causes of false failures:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些可能导致错误失败的可能原因：
- en: Asserting on the wrong thing or on the wrong exit point
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在错误的事物或错误的退出点上断言
- en: Injecting a wrong value into the entry point
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将错误值注入入口点
- en: Invoking the entry point incorrectly
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误调用入口点
- en: It could also be some other small mistake that happens when you write code at
    2 A.M. (That’s not a sustainable coding strategy, by the way. Stop doing that.)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 也可能是你凌晨2点编写代码时犯的一些其他小错误。（顺便说一句，这不是一个可持续的编码策略。停止这样做。）
- en: What do you do once you’ve found a buggy test?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 找到有错误的测试后，你该怎么办？
- en: When you find a buggy test, don’t panic. This might be the millionth time you’ve
    found one, so you might be panicking and thinking “our tests suck.” You might
    also be right about that. But that doesn’t mean you should panic. Fix the bug,
    and run the test to see if it now passes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当你找到一个有错误的测试时，不要慌张。这可能是你第无数次找到这样的测试，所以你可能正在想“我们的测试很糟糕。”你也许是对的。但这并不意味着你应该慌张。修复错误，然后运行测试，看看它现在是否通过。
- en: If the test passes, don’t be happy too soon! Go to the production code and place
    an obvious bug that should be caught by the newly fixed test. For example, change
    a Boolean to always be `true`. Or `false`. Then run the test again, and make sure
    it fails. If it doesn’t, you might still have a bug in your test. Fix the test
    until it can find the production bug and you can see it fail.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试通过了，也不要太早高兴！去生产代码中放置一个应该被新修复的测试捕获的明显错误。例如，将布尔值始终设置为`true`。或者`false`。然后再次运行测试，确保它失败。如果它没有失败，你可能在测试中仍然有一个错误。修复测试，直到它可以找到生产错误并且你可以看到它失败。
- en: Once you are sure the test is failing for an obvious production code issue,
    fix the production code issue you just made and run the test again. It should
    pass. If the test is now passing, you’re done. You’ve now seen the test passing
    when it should and failing when it should. Commit the code and move on.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你确定测试因一个明显的生产代码问题而失败，修复你刚才制造的生产代码问题，然后再次运行测试。它应该通过。如果测试现在通过了，你就完成了。你现在已经看到了测试在应该通过时通过，在应该失败时失败。提交代码并继续。
- en: If the test is still failing, it might have another bug. Repeat the whole process
    again until you verify that the test fails and passes when it should. If the test
    is still failing, you might have come across a real bug in production code. In
    which case, good for you!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试仍然失败，可能还有另一个错误。重复整个过程，直到你验证测试在应该失败时失败，在应该通过时通过。如果测试仍然失败，你可能在生产代码中遇到了真正的错误。在这种情况下，恭喜你！
- en: How to avoid buggy tests in the future
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如何避免未来的有缺陷的测试
- en: One of the best ways I know to detect and prevent buggy tests is to write your
    code in a test-driven manner. I explained a bit about this technique in chapter
    1 of this book. I also practice this technique in real life.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道的最佳方法之一来检测和防止有缺陷的测试是采用测试驱动的方式来编写代码。我在本书的第1章中简要解释了这种技术。我还在现实生活中实践了这种方法。
- en: 'Test-driven development (TDD) allows us to see both states of a test: both
    that it fails when it should (that’s the initial state we start in) and that it
    passes when it should (when the production code under test is written to make
    the test pass). If the test continues to fail, we’ve found a bug in the production
    code. If the test starts out passing, we have a bug in the test.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 测试驱动开发（TDD）使我们能够看到测试的两种状态：它应该在失败时失败（这是我们开始时的初始状态）以及它应该在通过时通过（当测试下的生产代码被编写以使测试通过时）。如果测试继续失败，我们在生产代码中找到了一个错误。如果测试一开始就通过，我们在测试中有一个错误。
- en: Another great way to reduce the likelihood of bugs in tests is to remove logic
    from them. More on this in section 7.3.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种减少测试中错误可能性的好方法是移除测试中的逻辑。关于这一点，在第7.3节中会有更多介绍。
- en: 7.2.3 The test is out of date due to a change in functionality
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.3 测试因功能更改而过时
- en: A test can fail if it’s no longer compatible with the current feature that’s
    being tested. Say you have a login feature, and in an earlier version, you needed
    to provide a username and a password to log in. In the new version, a two-factor
    authentication scheme replaced the old login. The existing test will start failing
    because it’s not providing the right parameters to the login functions.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试不再与正在测试的当前功能兼容，测试可能会失败。比如说，你有一个登录功能，在早期版本中，你需要提供用户名和密码来登录。在新版本中，双因素认证方案取代了旧的登录方式。现有的测试将开始失败，因为它没有向登录函数提供正确的参数。
- en: What can you do now?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在能做什么？
- en: 'You now have two options:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在有两个选择：
- en: Adapt the test to the new functionality.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将测试适应新的功能。
- en: Write a new test for the new functionality, and remove the old test because
    it has now become irrelevant.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为新的功能编写一个新的测试，并删除旧的测试，因为它现在已经变得无关紧要了。
- en: Avoiding or preventing this in the future
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 避免或预防未来的这种情况
- en: Things change. I don’t think it’s possible to not have out-of-date tests at
    some point in time. We’ll deal with change in the next chapter, relating to the
    maintainability of tests and how well tests can handle changes in the application.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 事情会变化。我认为在某个时间点不可能没有过时的测试。我们将在下一章中处理变化，涉及测试的可维护性和测试如何处理应用程序中的变化。
- en: 7.2.4 The test conflicts with another test
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.4 测试与另一个测试冲突
- en: 'Let’s say you have two tests: one of them is failing and one is passing. Let’s
    also say they cannot pass together. You’ll usually only see the failing test,
    because the passing one is, well, passing.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有两个测试：一个失败，一个通过。假设它们不能同时通过。你通常会只看到失败的测试，因为通过的那个，嗯，通过了。
- en: For instance, a test may fail because it suddenly conflicts with a new behavior.
    On the other hand, a conflicting test may expect a new behavior but doesn’t find
    it. The simplest example is when the first test verifies that calling a function
    with two parameters produces “3,” whereas the second test expects the same function
    to produce “4.”
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个测试可能因为突然与新的行为冲突而失败。另一方面，一个冲突的测试可能期望出现新的行为，但并未找到。最简单的例子是，第一个测试验证调用具有两个参数的函数会产生“3”，而第二个测试期望相同的函数产生“4”。
- en: What can you do now?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在能做什么？
- en: The root cause is that one of the tests has become irrelevant, which means it
    needs to be removed. Which one should be removed? That’s a question we’d need
    to ask a product owner, because the answer is related to which behavior is correct
    and expected from the application.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 根本原因是其中一个测试已经变得不相关，这意味着它需要被移除。应该移除哪一个？这是一个我们需要向产品负责人提问的问题，因为答案与期望的应用程序的正确行为有关。
- en: Avoiding this in the future
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 避免未来出现这种情况
- en: I feel this is a healthy dynamic, and I’m fine with not avoiding it.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我觉得这是一种健康的动态，我不介意不避免它。
- en: 7.2.5 The test is flaky
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.5 测试不可靠
- en: A test can fail inconsistently. Even if the production code under test hasn’t
    changed, a test can suddenly fail without any apparent reason, then pass again,
    then fail again. We call a test like that “flaky.”
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一个测试可能会不一致地失败。即使被测试的生产代码没有改变，一个测试可能会突然失败，然后再次通过，然后再次失败。我们称这样的测试为“不可靠的”。
- en: Flaky tests are a special beast, and I’ll deal with them in section 7.5.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 不可靠的测试是一种特殊的怪物，我将在第7.5节中处理它们。
- en: 7.3 Avoiding logic in unit tests
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 避免在单元测试中使用逻辑
- en: The chances of having bugs in your tests increase almost exponentially as you
    include more and more logic in them. I’ve seen plenty of tests that should have
    been simple become dynamic, random-number-generating, thread-creating, file-writing
    monsters that are little test engines in their own right. Sadly, because they
    were *“tests,”* the writer didn’t consider that they might have bugs or didn’t
    write them in a maintainable manner. Those test monsters take more time to debug
    and verify than they save.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在测试中包含越来越多的逻辑时，测试中存在错误的可能性几乎呈指数增长。我见过很多应该简单的测试变得动态、生成随机数、创建线程、写入文件的怪物，它们本身就是小小的测试引擎。遗憾的是，因为它们是*“测试”，作者没有考虑到它们可能存在错误，或者没有以可维护的方式编写。这些测试怪物调试和验证所需的时间比它们节省的时间要多。
- en: But all monsters start out small. Often, an experienced developer in the company
    will look at a test and start thinking, “What if we made the function loop and
    create random numbers as input? We’d surely find lots more bugs that way!” And
    you will, especially in your tests.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 但所有怪物都是从小的开始的。通常，公司的一个经验丰富的开发者会看看一个测试，然后开始想，“如果我们让函数循环并创建随机数作为输入呢？我们肯定能找到更多错误！”而且你确实会在你的测试中这样做。
- en: Test bugs are one of the most annoying things for developers, because you’ll
    almost never search for the cause of a failing test in the test itself. I’m not
    saying that tests with logic don’t have any value. In fact, I’m likely to write
    such tests myself in some special situations. But I try to avoid this practice
    as much as possible.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 测试错误是开发者最烦恼的事情之一，因为你几乎永远不会在测试本身中寻找失败测试的原因。我并不是说带有逻辑的测试没有任何价值。事实上，在某些特殊情况下，我可能自己会编写这样的测试。但我尽可能地避免这种做法。
- en: 'If you have any of the following inside a unit test, your test contains logic
    that I usually recommend be reduced or removed completely:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个单元测试中包含以下任何一项，你的测试包含了我通常建议减少或完全删除的逻辑：
- en: '`switch`, `if`, or `else` statements'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`switch`、`if`或`else`语句'
- en: '`foreach`, `for`, or `while` loops'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`foreach`、`for`或`while`循环'
- en: Concatenations (+ sign, etc.)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接操作（+符号等）
- en: '`try`, `catch`'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`try`、`catch`'
- en: '7.3.1 Logic in asserts: Creating dynamic expected values'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.1 断言中的逻辑：创建动态期望值
- en: Here’s a quick example of a concatenation to start us off.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个快速示例，以一个连接操作开始。
- en: Listing 7.1 A test with logic in it
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.1 包含逻辑的测试
- en: '[PRE0]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Logic in the assertion part
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 断言部分的逻辑
- en: To understand the problem with this test, the following listing shows the code
    being tested. Notice that the `+` sign makes an appearance in both.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这个测试的问题，以下列表显示了正在被测试的代码。注意，`+`符号出现在两者中。
- en: Listing 7.2 Code under test
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.2 被测试的代码
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ The same logic as in the production code
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 与生产代码相同的逻辑
- en: 'Notice how the algorithm (very simple, but still an algorithm) of connecting
    a name with a `"hello"` string is repeated in both the test and the code under
    test:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到连接一个名字与 `"hello"` 字符串的算法（虽然很简单，但仍然是一个算法）在测试和被测试的代码中都重复出现：
- en: '[PRE2]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Our test
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们的测试
- en: ❷ The code under test
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 被测试的代码
- en: My issue with this test is that the algorithm under test is repeated in the
    test itself. This means that if there is a bug in the algorithm, the test also
    contains *the same bug*. The test will not catch the bug, but instead will expect
    the incorrect result from the code under test.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我对这个测试的问题在于，被测试的算法在测试本身中也重复出现。这意味着如果算法中存在错误，测试也会包含*相同的错误*。测试不会捕获错误，反而会期望从被测试的代码中得到错误的结果。
- en: In this case, the incorrect result is that we’re missing a space character between
    the concatenated words, but hopefully you can see how the same issue could become
    much more complex with a more complex algorithm.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，错误的结果是我们遗漏了连接词之间的空格字符，但希望你能看到，同样的问题在更复杂的算法中可能会变得更加复杂。
- en: This is a trust issue. We can’t trust this test to tell us the truth, since
    its logic is a repeat of the logic being tested. The test might pass when the
    bug exists in the code, so we can’t trust the test’s result.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个信任问题。我们不能信任这个测试告诉我们真相，因为它的逻辑是重复被测试的逻辑。当代码中存在错误时，测试可能会通过，所以我们不能信任测试的结果。
- en: Warning Avoid dynamically creating the expected value in your asserts; use hardcoded
    values when possible.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 警告 避免在断言中动态创建期望值；尽可能使用硬编码的值。
- en: A more trustworthy version of this test can be rewritten as follows.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个测试的更可靠版本可以重写如下。
- en: Listing 7.3 A more trustworthy test
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.3 更可靠的测试
- en: '[PRE3]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Using a hardcoded value
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用硬编码的值
- en: Because the inputs in this test are so simple, it’s easy to write a hardcoded
    expected value. This is what I usually recommend—make the test inputs so simple
    that it is trivial to create a hardcoded version of the expected value. Note that
    this is mostly true of unit tests. For higher-level tests, this is a bit harder
    to do, which is another reason why higher-level tests should be considered a bit
    riskier; they often create expected results dynamically, which you should try
    to avoid any time you can.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个测试中的输入非常简单，所以很容易编写一个硬编码的期望值。这就是我通常推荐的做法——使测试输入如此简单，以至于可以轻松创建期望值的硬编码版本。请注意，这主要适用于单元测试。对于高级测试，这要困难一些，这也是为什么高级测试应该被认为有一定的风险；它们通常动态创建期望结果，你应该尽量避免在可能的情况下这样做。
- en: “But Roy,” you might say, “Now we are repeating ourselves—the string `"abc"`
    is repeated twice. We were able to avoid this in the previous test.” When push
    comes to shove, trust should trump maintainability. What good is a highly maintainable
    test that I cannot trust? You can read more about code duplication in tests in
    Vladimir Khorikov’s article, “DRY vs. DAMP in Unit Tests,” ([https://enterprisecraftsmanship.com/posts/dry-damp-unit-tests/](https://enterprisecraftsmanship.com/posts/dry-damp-unit-tests/)).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: “但是罗伊，”你可能会说，“现在我们正在重复自己——字符串 `"abc"` 被重复了两次。我们在之前的测试中能够避免这种情况。”当事情变得棘手时，信任应该胜过可维护性。一个高度可维护但我不信任的测试有什么用？你可以在Vladimir
    Khorikov的文章“单元测试中的DRY vs. DAMP”中了解更多关于代码重复的内容，[https://enterprisecraftsmanship.com/posts/dry-damp-unit-tests/](https://enterprisecraftsmanship.com/posts/dry-damp-unit-tests/).
- en: 7.3.2 Other forms of logic
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.2 其他逻辑形式
- en: 'Here’s the opposite case: creating the inputs dynamically (using a loop) forces
    us to dynamically decide what the expected output should be. Suppose we have the
    following code to test.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是相反的情况：动态创建输入（使用循环）迫使我们动态地决定期望的输出应该是什么。假设我们有以下代码来测试。
- en: Listing 7.4 A name-finding function
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.4 一个查找名字的函数
- en: '[PRE4]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The following listing shows a clear antipattern for a test.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了一个测试的明显反模式。
- en: Listing 7.5 Loops and ifs in a test
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.5 测试中的循环和if语句
- en: '[PRE5]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Declaring multiple inputs
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 声明多个输入
- en: ❷ Production code logic leaking into the test
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 生产代码逻辑泄露到测试中
- en: Notice how we’re using multiple inputs for the test. This forces us to loop
    over those inputs, which in itself complicates the test. Remember, loops can have
    bugs too.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们是如何使用多个输入进行测试的。这迫使我们遍历这些输入，这本身就会使测试变得复杂。记住，循环也可能有错误。
- en: Additionally, because we have different scenarios for the values (with and without
    spaces) we need an `if`/`else` to know what the assertion is expecting, and the
    `if`/`else` can have bugs too. We are also repeating a part of the production
    algorithm, which brings us back to the previous concatenation example and its
    problems.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，因为我们有不同的值场景（带空格和不带空格），我们需要一个`if`/`else`来知道断言期望的是什么，而`if`/`else`也可能有错误。我们也在重复生产算法的一部分，这让我们回到了之前的连接示例及其问题。
- en: Finally, our test name is too generic. We can only title it as “it works” because
    we have to account for multiple scenarios and expected outcomes. That’s bad for
    readability.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们的测试名称过于通用。我们只能将其命名为“它工作”，因为我们必须考虑到多个场景和预期结果。这对可读性很不好。
- en: 'This is an all-around bad test. It’s better to separate this into two or three
    tests, each with its own scenario and name. This would allow us to use hardcoded
    inputs and assertions and to remove any loops and `if`/`else` logic from the code.
    Anything more complex causes the following problems:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个全面糟糕的测试。最好将其拆分为两个或三个测试，每个测试都有自己的场景和名称。这将使我们能够使用硬编码的输入和断言，并从代码中移除任何循环和`if`/`else`逻辑。任何更复杂的东西都会导致以下问题：
- en: The test is harder to read and understand.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试更难阅读和理解。
- en: The test is hard to recreate. For example, imagine a multithreaded test or a
    test with random numbers that suddenly fails.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试难以重现。例如，想象一个多线程测试或包含随机数的测试突然失败。
- en: The test is more likely to have a bug or to verify the wrong thing.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试更有可能存在错误或验证错误的事情。
- en: Naming the test may be harder because it does multiple things.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试的命名可能更困难，因为它做了多件事。
- en: Generally, monster tests replace original simpler tests, and that makes it harder
    to find bugs in the production code. If you must create a monster test, it should
    be added as a new test and not be a replacement for existing tests. Also, it should
    reside in a project or folder explicitly titled to hold tests other than unit
    tests. I call these “integration tests” or “complex tests” and try to keep their
    number to an acceptable minimum.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，巨型测试会取代原始的简单测试，这使得在生产代码中查找错误更困难。如果你必须创建一个巨型测试，它应该作为一个新的测试添加，而不是替代现有测试。此外，它应该位于一个明确命名为包含测试（除了单元测试以外的测试）的项目或文件夹中。我称这些为“集成测试”或“复杂测试”，并试图将它们的数量保持在可接受的最低限度。
- en: 7.3.3 Even more logic
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.3 更多的逻辑
- en: Logic can be found not only in tests but also in test helper methods, handwritten
    fakes, and test utility classes. Remember, every piece of logic you add in these
    places makes the code that much harder to read and increases the chances of a
    bug in a utility method that your tests use.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑不仅存在于测试中，还存在于测试辅助方法、手写的模拟和测试实用类中。记住，你在这这些地方添加的每一块逻辑都会使代码更难阅读，并增加你的测试使用的实用方法中存在错误的几率。
- en: If you find that you need to have complicated logic in your test suite for some
    reason (though that’s generally something I do with integration tests, not unit
    tests), at least make sure you have a couple of tests against the logic of your
    utility methods in the test project. This will save you many tears down the road.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果因为某种原因你发现在你的测试套件中需要复杂的逻辑（尽管这通常是我对集成测试而不是单元测试所做的事情），至少确保你在测试项目中针对你的实用方法逻辑编写了几个测试。这将为你节省很多未来的眼泪。
- en: 7.4 Smelling a false sense of trust in passing tests
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 在通过的测试中嗅出虚假的信任感
- en: We’ve now covered failed tests as a means of detecting tests we shouldn’t trust.
    What about all those quiet, green tests we have lying all over the place? Should
    we trust them? What about a test that we need to do a code review for, before
    it’s pushed into a main branch? What should we look for?
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经讨论了失败测试作为检测我们不应该信任的测试的手段。那么，我们到处都有的所有那些安静、绿色的测试呢？我们应该信任它们吗？对于一个需要在推送到主分支之前进行代码审查的测试，我们应该寻找什么？
- en: 'Let’s use the term “false-trust” to describe trusting a test that you really
    shouldn’t, but you don’t know it yet. Being able to review tests and find possible
    false-trust issues has immense value because, not only can you fix those tests
    yourself, you’re affecting the trust of everyone else who’s ever going to read
    or run those tests. Here are some reasons I reduce my trust in tests, even if
    they are passing:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用“虚假信任”这个词来描述信任一个你实际上不应该信任的测试，但你还没有意识到这一点。能够审查测试并发现可能的虚假信任问题具有巨大的价值，因为，你不仅能够自己修复这些测试，你还影响了所有将要阅读或运行这些测试的其他人的信任。以下是我减少对测试信任的原因，即使它们正在通过：
- en: The test contains no asserts.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试不包含断言。
- en: I can’t understand the test.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我无法理解测试。
- en: Unit tests are mixed with flaky integration tests.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单元测试与不稳定的集成测试混合。
- en: The test verifies multiple concerns or exit points.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试验证了多个关注点或退出点。
- en: The test keeps changing.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试不断变化。
- en: 7.4.1 Tests that don’t assert anything
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.1 没有断言的测试
- en: We all agree that a test that doesn’t actually verify that something is true
    or false is less than helpful, right? Less than helpful because it also costs
    in maintenance time, refactoring, and reading time, and sometimes unnecessary
    noise if it needs changing due to API changes in production code.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都同意，一个实际上没有验证某事是真是假的测试是不太有帮助的，对吧？不太有帮助，因为它也增加了维护时间、重构和阅读时间，有时如果由于生产代码中的API更改需要更改，它还会产生不必要的噪音。
- en: 'If you see a test with no asserts, consider that there may be hidden asserts
    in a function call. This causes a readability problem if the function is not named
    to explain this. Sometimes people also write a test that exercises a piece of
    code simply to make sure that the code does not throw an exception. This does
    have some value, and if that’s the test you choose to write, make sure that the
    name of the test indicates this with a term such as “does not throw.” To be even
    more specific, many test APIs support the ability to specify that something does
    not throw an exception. This is how you can do this in Jest:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看到一个没有断言的测试，考虑可能存在函数调用中的隐藏断言。如果函数没有命名来解释这一点，这会导致可读性问题。有时人们也会编写一个测试来测试一段代码，只是为了确保代码不会抛出异常。这确实有一些价值，如果你选择编写这样的测试，确保测试的名称使用“不抛出”之类的术语来表明这一点。为了更加具体，许多测试API支持指定某物不会抛出异常的能力。这是你在Jest中这样做的：
- en: '[PRE6]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you do have such tests, make sure there’s a very small number of them. I
    don’t recommend it as a standard, but only for really special cases.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你确实有这样的测试，确保它们的数量非常少。我不建议将其作为标准，而只是针对真正特殊的情况。
- en: Sometimes people simply forget to write an assert due to lack of experience.
    Consider adding the missing assert or removing the test if it brings no value.
    People may also actively write tests to achieve some imagined test coverage goal
    set by management. Those tests usually serve no real value except to get management
    off people’s backs so they can do real work.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 有时人们只是因为缺乏经验而忘记编写断言。考虑添加缺失的断言，或者如果它没有带来价值，则删除测试。人们也可能积极编写测试，以达到管理层设定的某些想象的测试覆盖率目标。这些测试通常除了让管理层不再打扰人们以便他们可以真正工作之外，没有实际价值。
- en: TIP Code coverage shouldn’t ever be a goal on its own. It doesn’t mean “code
    quality.” In fact, it often causes developers to write meaningless tests that
    will cost even more time to maintain. Instead, measure “escaped bugs,” “time to
    fix,” and other metrics that we’ll discuss in chapter 11.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：代码覆盖率永远不应该是一个目标本身。它并不意味着“代码质量”。事实上，它往往导致开发者编写无意义的测试，这将花费更多的时间来维护。相反，衡量“逃逸的缺陷”、“修复时间”和其他我们在第11章中将要讨论的指标。
- en: 7.4.2 Not understanding the tests
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.2 不理解测试
- en: 'This is a huge issue, and I’ll deal with it in depth in chapter 9\. There are
    several possible issues:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个大问题，我将在第9章中深入探讨。有几个可能的问题：
- en: Tests with bad names
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命名不好的测试
- en: Tests that are too long or have convoluted code
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过长或代码复杂的测试
- en: Tests containing confusing variable names
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含令人困惑的变量名的测试
- en: Tests containing hidden logic or assumptions that cannot be understood easily
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含难以理解的隐藏逻辑或假设的测试
- en: Test results that are inconclusive (neither failed nor passed)
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无法确定的测试结果（既未失败也未通过）
- en: Test messages that don’t provide enough information
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供信息不足的测试消息
- en: If you don’t understand the test that’s failing or passing, you don’t know if
    you should be worried or not.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不知道失败的测试或通过的测试，你不知道你是否应该担心。
- en: 7.4.3 Mixing unit tests and flaky integration tests
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.3 混合单元测试和不稳定的集成测试
- en: They say that one rotten apple spoils the bunch. The same is true for flaky
    tests mixed in with nonflaky tests. Integration tests are much more likely to
    be flaky than unit tests because they have more dependencies. If you find that
    you have a mix of integration and unit tests in the same folder or test execution
    command, you should be suspicious.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 他们常说“一个坏苹果会坏一筐”，对于混合了非稳定测试的测试也是如此。集成测试比单元测试更容易出现不稳定，因为它们有更多的依赖。如果你发现你在同一个文件夹或测试执行命令中混合了集成和单元测试，你应该感到怀疑。
- en: Humans like to take the path of least resistance, and it’s no different when
    it comes to coding. Suppose that a developer runs all the tests and one of them
    fails—if there’s a way to blame a missing configuration or a network issue instead
    of spending time investigating and fixing a real problem, they will. That’s *especially*
    true if they’re under serious time pressure or they’re overcommitted to delivering
    things they’re already late on.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 人类喜欢走阻力最小的路，在编码方面也不例外。假设一个开发者运行了所有测试，其中一个测试失败——如果有一种方法可以将责任归咎于缺失的配置或网络问题，而不是花时间调查和修复真实问题，他们会的。这*尤其*适用于他们在严重的时间压力下，或者他们已经迟到，却还要承诺交付更多事情的情况。
- en: The easiest thing is to accuse any failing test of being a flaky test. Because
    flaky and nonflaky tests are mixed up with each other, that’s a simple thing to
    do, and it’s a good way to ignore the issue and work on something more fun. Because
    of this human factor, it’s best to remove the option to blame a test for being
    flaky. What should you do to prevent this? Aim to have a *safe green zone* by
    keeping your integration and unit tests in separate places.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的事情就是指责任何失败的测试是故障测试。因为故障和非故障测试混合在一起，所以这是一件简单的事情，也是忽视问题并专注于更有趣事情的好方法。由于这个人为因素，最好移除将测试归咎于故障的选项。你该怎么做来防止这种情况？通过将集成测试和单元测试放在不同的地方，努力保持一个*安全绿色区域*。
- en: A safe green test area should contain only nonflaky, fast tests, where developers
    know that they can get the latest code version, they can run all the tests in
    that namespace or folder, and the tests should all be green (given no changes
    to production code). If some tests in the safe green zone don’t pass, a developer
    is much more likely to be concerned.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 一个安全的绿色测试区域应该只包含非故障的、快速的测试，开发者知道他们可以获取最新的代码版本，他们可以运行该命名空间或文件夹中的所有测试，并且测试应该都是绿色的（假设没有对生产代码的更改）。如果安全绿色区域中的某些测试未通过，开发者更有可能感到担忧。
- en: An added benefit to this separation is that developers are more likely to run
    the unit tests more often, now that the run time is faster without the integration
    tests. It’s better to have some feedback than no feedback, right? The automated
    build pipeline should take care of running any of the “missing” feedback tests
    that developers can’t or won’t run on their local machines.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分离的额外好处是，由于运行时间更快，开发者更有可能更频繁地运行单元测试。有反馈总比没有反馈好，对吧？自动构建管道应该负责运行开发者无法或不愿意在本地机器上运行的任何“缺失”的反馈测试。
- en: 7.4.4 Testing multiple exit points
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.4 测试多个退出点
- en: 'An *exit point* (I’ll also refer to it as a *concern*) is explained in chapter
    1\. It’s a single end result from a unit of work: a return value, a change to
    system state, or a call to a third-party object.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*退出点*（我还会将其称为*关注点*）在第1章中有解释。它是从一项工作中的单个最终结果：返回值、系统状态的变化或对第三方对象的调用。'
- en: 'Here’s a simple example of a function that has two exit points, or two concerns.
    It both returns a value and triggers a passed-in callback function:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个函数的简单示例，它有两个退出点，或两个关注点。它既返回一个值，又触发一个传入的回调函数：
- en: '[PRE7]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We could write a test that checks both of these exit points at the same time.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以编写一个测试来同时检查这两个退出点。
- en: Listing 7.6 Checking two exit points in the same test
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.6 在同一测试中检查两个退出点
- en: '[PRE8]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The first reason testing more than one concern in a test can backfire is that
    your test name suffers. I’ll discuss readability in chapter 9, but here’s a quick
    note on naming: naming tests is hugely important for both debugging and documentation
    purposes. I spend a lot of time thinking about good names for tests, and I’m not
    ashamed to admit it.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试中测试多个关注点可能适得其反的第一个原因是你的测试名称会受到影响。我将在第9章讨论可读性，但这里有一个关于命名的快速说明：命名测试对于调试和文档目的都至关重要。我花了很多时间思考测试的好名称，并且不羞于承认这一点。
- en: Naming a test may seem like a simple task, but if you’re testing more than one
    thing, giving the test a good name that indicates what’s being tested is difficult.
    Often you end up with a very generic test name that forces the reader to read
    the test code. When you test just one concern, naming the test is easy. But wait,
    there’s more.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 给测试命名可能看起来是一个简单的任务，但如果你正在测试多个事物，给测试起一个能表明正在测试什么的良好名称是困难的。通常你最终会得到一个非常通用的测试名称，迫使读者阅读测试代码。当你只测试一个关注点时，给测试命名是容易的。但是等等，还有更多。
- en: More disturbingly, in most unit test frameworks, a failed assert throws a special
    type of exception that’s caught by the test framework runner. When the test framework
    catches that exception, it means the test has failed. Most exceptions in most
    languages, by design, don’t let the code continue. So if this line,
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 更令人不安的是，在大多数单元测试框架中，失败的断言会抛出一个特殊的异常类型，该异常被测试框架运行器捕获。当测试框架捕获该异常时，意味着测试失败了。大多数语言中的大多数异常，按照设计，不允许代码继续执行。所以如果这一行，
- en: '[PRE9]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'fails the assert, this line will not execute at all:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果断言失败，这一行将完全不会执行：
- en: '[PRE10]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The test method exits on the same line where the exception is thrown. Each of
    these asserts can and should be considered different requirements, and they can
    also, and in this case likely should, be implemented separately and incrementally,
    one after the other.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 测试方法在抛出异常的同一行退出。每个断言都可以，并且应该被视为不同的要求，它们也可以，在这种情况下很可能应该，分别和逐步地实现。
- en: Consider assert failures as symptoms of a disease. The more symptoms you can
    find, the easier the disease will be to diagnose. After a failure, subsequent
    asserts aren’t executed, and you’ll miss seeing other possible symptoms that could
    provide valuable data (symptoms) that would help you narrow your focus and discover
    the underlying problem. Checking multiple concerns in a single unit test adds
    complexity with little value. You should run additional concern checks in separate,
    self-contained unit tests so that you can see what really fails.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 将断言失败视为疾病的症状。你能找到的症状越多，诊断疾病就越容易。在失败之后，后续的断言不会执行，你将错过看到其他可能的症状，这些症状可能会提供有价值的数据（症状），帮助你缩小关注范围并发现根本问题。在一个单元测试中检查多个关注点会增加复杂性而价值不大。你应该在单独的、自包含的单元测试中运行额外的关注点检查，这样你才能看到真正失败的地方。
- en: Let’s break it up into two separate tests.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将它拆分为两个单独的测试。
- en: Listing 7.7 Checking the two exit points in separate tests
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.7 在单独的测试中检查两个退出点
- en: '[PRE11]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now we can clearly separate the concerns, and each one can fail separately.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以清楚地分离关注点，每个都可以单独失败。
- en: Sometimes it’s perfectly okay to assert multiple things in the same test, as
    long as they are not multiple concerns. Take the following function and its associated
    test as an example. `makePerson` is designed to build a new `person` object with
    some properties.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，在同一个测试中断言多个事物是完全正常的，只要它们不是多个关注点。以下是一个函数及其相关测试的例子。`makePerson` 被设计用来使用一些属性构建一个新的
    `person` 对象。
- en: Listing 7.8 Using multiple asserts to verify a single exit point
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.8 使用多个断言验证单个退出点
- en: '[PRE12]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In our test, we are asserting on both name and age together, because they are
    part of the same concern (building the `person` object). If the first assert fails,
    we likely don’t care about the second assert because something might have gone
    terribly wrong while building the object in the first place.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的测试中，我们同时在名称和年龄上断言，因为它们是同一个关注点（构建 `person` 对象）的一部分。如果第一个断言失败，我们很可能不会关心第二个断言，因为可能在最初构建对象时出了大问题。
- en: 'Tip Here’s a test break-up hint: If the first assert fails, do you still care
    what the result of the next assert is? If you do, you should probably separate
    the test into two tests.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：以下是一个测试拆分提示：如果第一个断言失败，你是否仍然关心下一个断言的结果？如果你关心，你可能应该将测试拆分为两个测试。
- en: 7.4.5 Tests that keep changing
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.5 持续变化的测试
- en: If a test is using the current date and time as part of its execution or assertions,
    then we can claim that every time the test runs, it’s a different test. The same
    can be said of tests that use random numbers, machine names, or anything that
    depends on grabbing a current value from outside the test’s environment. There’s
    a big chance its results won’t be consistent, and that means they can be flaky.
    For us, as developers, flaky tests reduce our trust in the failed results of the
    test (as I’ll discuss in the next section).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个测试在执行或断言过程中使用当前日期和时间作为其一部分，那么我们可以断言每次测试运行时，它都是一个不同的测试。同样，对于使用随机数、机器名称或任何依赖于从测试环境外部获取当前值的测试，也是如此。有很大可能性其结果不会一致，这意味着它们可能是不可靠的。对我们这些开发者来说，不可靠的测试会降低我们对测试失败结果的信任（我将在下一节中讨论）。
- en: Another huge potential issue with dynamically generated values is that if we
    don’t know ahead of time what the input into the system might be, we also have
    to compute the expected *output* of the system, and that can lead to a buggy test
    that depends on repeating production logic, as mentioned in section 7.3.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 动态生成值的一个巨大潜在问题是，如果我们事先不知道系统可能输入的内容，我们还得计算系统的预期*输出*，这可能导致一个有缺陷的测试，该测试依赖于重复生产逻辑，正如第7.3节中提到的。
- en: 7.5 Dealing with flaky tests
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.5 处理不稳定测试
- en: I’m not sure who came up with the term *flaky tests*, but it does fit the bill.
    It’s used to describe tests that, given no changes to the code, return inconsistent
    results. This might happen frequently or very rarely, but it does happen.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我不确定是谁提出了“flaky tests”（不稳定测试）这个术语，但它确实符合这个描述。它用来描述那些在没有对代码进行任何更改的情况下，返回不一致结果的测试。这种情况可能经常发生，也可能非常罕见，但确实会发生。
- en: 'Figure 7.1 illustrates where flakiness comes from. The figure is based on the
    number of real dependencies the tests have. Another way to think about this is
    how many moving parts the tests have. For this book, we’re mostly concerning ourselves
    with the bottom third of this diagram: unit and component tests. However, I want
    to touch on the higher-level flakiness so I can give you some pointers on what
    to research.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1说明了不稳定测试的来源。该图基于测试所具有的真实依赖项数量。另一种思考方式是测试有多少变动部分。对于这本书，我们主要关注这个图的下三分之一：单元测试和组件测试。然而，我想谈谈更高层的不稳定测试，这样我可以给你一些研究方向的提示。
- en: '![07-01](../Images/07-01.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![07-01](../Images/07-01.png)'
- en: Figure 7.1 The higher the level of the tests, the more real dependencies they
    use, which gives us confidence in the overall system correctness but results in
    more flakiness.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1 测试的层级越高，它们使用的真实依赖项越多，这让我们对整体系统正确性有信心，但结果却导致更多的不稳定。
- en: At the lowest level, our tests have full control over all of their dependencies
    and therefore have no moving parts, either because they’re faking them or because
    they run purely in memory and can be configured. We did this in chapters 3 and
    4\. Execution paths in the code are fully deterministic because all the initial
    states and expected return values from various dependencies have been predetermined.
    The code path is almost static—if it returns the wrong expected result, then something
    important might have changed in the production code’s execution path or logic.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在最低层级，我们的测试对其所有依赖项都有完全的控制权，因此没有变动部分，要么是因为它们在伪造它们，要么是因为它们纯在内存中运行并且可以配置。我们在第3章和第4章中就是这样做的。代码中的执行路径是完全确定的，因为所有初始状态和来自各种依赖项的预期返回值都已经预先确定。代码路径几乎是静态的——如果它返回了错误的预期结果，那么生产代码的执行路径或逻辑可能已经发生了重要变化。
- en: As we go up the levels, our tests shed more and more stubs and mocks and start
    using more and more real dependencies, such as databases, networks, configuration,
    and more. This, in turn, means more moving parts that we have less control over
    and that might change our execution path, return unexpected values, or fail to
    execute at all.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们向上提升层级，我们的测试会逐渐减少stub和mock的使用，并开始使用越来越多的真实依赖项，例如数据库、网络、配置等。这反过来意味着我们控制力更弱的部分更多，可能会改变我们的执行路径，返回意外的值，或者根本无法执行。
- en: At the highest level, there are no fake dependencies. Everything our tests rely
    on is real, including any third-party services, security and network layers, and
    configuration. These types of tests usually require us to set up an environment
    that is as close to a production scenario as possible, if they’re not running
    right on the production environments.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在最高层级，没有伪造的依赖项。我们的测试所依赖的一切都是真实的，包括任何第三方服务、安全和网络层以及配置。这类测试通常要求我们设置一个尽可能接近生产场景的环境，如果它们不是在生产环境中运行的话。
- en: The higher up we go in the test diagram, we should get higher confidence that
    our code works, unless we don’t trust the tests’ results. Unfortunately, the higher
    up we go in the diagram, the more chances there are for our tests to become flaky
    because of how many moving parts are involved.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试图中的层级越高，我们应该对我们的代码工作有更高的信心，除非我们不信任测试结果。不幸的是，随着我们在图中层级上升，我们的测试因为涉及的变动部分越来越多，变得不稳定的机会也越大。
- en: 'We might assume that tests at the lowest level shouldn’t have any flakiness
    issues because there shouldn’t be any moving parts that cause flakiness. That’s
    theoretically true, but in reality people still manage to add moving parts in
    lower-level tests: using the current date and time, the machine name, the network,
    the filesystem, and more can cause a test to be flaky.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能认为最低级别的测试不应该有任何的不稳定性问题，因为不应该有任何移动部件导致不稳定性。这在理论上是对的，但在现实中，人们仍然在低级别的测试中添加移动部件：使用当前日期和时间、机器名称、网络、文件系统等都可以导致测试变得不稳定。
- en: 'A test fails sometimes without us touching production code. For example:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 测试有时会失败，而我们并没有修改生产代码。例如：
- en: A test fails every third run.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次运行测试时，大约有三分之一会失败。
- en: A test fails once every unknown number of times.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试每次都会在未知次数后失败。
- en: A test fails when various external conditions fail, such as network or database
    availability, other APIs not being available, environment configuration, and more.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当各种外部条件失败时，测试会失败，例如网络或数据库可用性、其他API不可用、环境配置等。
- en: To add to that salad of pain, each dependency the test uses (network, filesystem,
    threads, etc.) usually adds time to the test run. Calls to the network and the
    database take time. The same goes for waiting for threads to finish, reading configurations,
    and waiting for asynchronous tasks.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，测试使用的每个依赖项（网络、文件系统、线程等）通常都会增加测试运行的时间。对网络和数据库的调用需要时间。等待线程完成、读取配置和等待异步任务也是如此。
- en: It also takes longer to figure out why a test is failing. Debugging a test or
    reading through huge amounts of logs is heartbreakingly time consuming and will
    drain your soul slowly into the abyss of “time to update my resume” land.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 确定为什么测试失败也需要更长的时间。调试测试或阅读大量日志是令人心碎的耗时工作，会慢慢地将你的灵魂拖入“更新我的简历”的时间深渊。
- en: 7.5.1 What can you do once you’ve found a flaky test?
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.1 找到不稳定的测试后，你可以做什么？
- en: 'It’s important to realize that flaky tests can be costly to an organization.
    You should aim to have zero flaky tests as a long-term goal. Here are some ways
    to reduce the costs associated with handling flaky tests:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要认识到，不稳定的测试可能会对一个组织造成成本。你应该以零不稳定的测试作为长期目标。以下是一些减少处理不稳定的测试相关成本的方法：
- en: '*Define*—Agree on what “flaky” means to your organization. For example, run
    your test suite 10 times without any production code changes, and count all the
    tests that were not consistent in their results (i.e., ones that did not fail
    all 10 times or did not pass all 10 times).'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*定义*—就组织中的“不稳定”达成一致。例如，在不更改任何生产代码的情况下运行测试套件10次，并计算所有结果不一致的测试（即没有10次都失败或没有10次都通过）。'
- en: 'Place any test deemed flaky in a special category or folder of tests that can
    be run separately. I recommend removing all flaky tests from the regular delivery
    build so they do not create noise, and quarantining them in their own little pipeline
    temporarily. Then, go over each of the flaky tests and play my favorite flaky
    game, “fix, convert, or kill”:'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将任何被认为是不稳定的测试放在一个特殊的测试类别或文件夹中，这些测试可以单独运行。我建议从常规交付构建中移除所有不稳定的测试，以免产生噪音，并将它们暂时隔离在自己的小管道中。然后，逐一检查每个不稳定的测试，玩我最喜欢的“不稳定”游戏，“修复、转换或淘汰”：
- en: '*Fix*—Make the test not flaky by controlling its dependencies, if possible.
    For example, if it requires data in the database, insert the data into the database
    as part of the test.'
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*修复*—如果可能，通过控制其依赖项来使测试不再不稳定。例如，如果它需要数据库中的数据，可以在测试过程中将数据插入数据库。'
- en: '*Convert*—Remove flakiness by converting the test into a lower-level test by
    removing and controlling one or more of its dependencies. For example, simulate
    a network endpoint with a stub instead of using a real one.'
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*转换*—通过将测试转换为更底层的测试，通过移除和控制其一个或多个依赖项来消除不稳定性。例如，使用存根模拟网络端点而不是使用真实的端点。'
- en: '*Kill*—Seriously consider whether the value the test brings is enough to continue
    to run it and pay the maintenance costs it creates. Sometimes old flaky tests
    are better off dead and buried. Sometimes they are already covered by newer, better
    tests, and the old tests are pure technical debt that we can get rid of. Sadly,
    many engineering managers are reluctant to remove these old tests because of the
    sunken cost fallacy—there was so much effort put into them that it would be a
    waste to delete them. However, at this point, it might cost you more to keep the
    test than to delete it, so I recommend seriously considering this option for many
    of your flaky tests.'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*杀死*—认真考虑测试带来的价值是否足以继续运行它并支付其产生的维护成本。有时，老旧的不可靠测试最好是死去并埋葬。有时，它们已经被更新、更好的测试所覆盖，而旧的测试纯粹是技术债务，我们可以将其消除。遗憾的是，许多工程经理由于沉没成本谬误而不愿意移除这些旧测试——投入了如此多的努力，删除它们将是浪费。然而，此时，保留测试可能比你删除它所花费的成本还要高，所以我建议你认真考虑为许多不可靠测试选择这个选项。'
- en: 7.5.2 Preventing flakiness in higher-level tests
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.2 防止高级测试出现不可靠性
- en: 'If you’re interested in preventing flakiness in higher-level tests, your best
    bet is to make sure that your tests are repeatable on any environment after any
    deployment. That could involve the following:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣的是防止高级测试出现不可靠性，最好的办法是确保你的测试在部署后任何环境中都是可重复的。这可能包括以下内容：
- en: Roll back any changes your tests have made to external shared resources.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回滚测试对外部共享资源所做的任何更改。
- en: Do not depend on other tests changing external state.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要依赖于其他测试更改外部状态。
- en: Gain some control over external systems and dependencies by ensuring you have
    the ability to recreate them at will (do an internet search on “infrastructure
    as code”), creating dummies of them that you can control, or creating special
    test accounts on them and pray that they stay safe.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过确保你有能力随意重新创建它们（在互联网上搜索“基础设施即代码”），创建你可以控制的它们的人工制品，或者创建特殊测试账户并祈祷它们保持安全，从而在一定程度上控制外部系统和依赖。
- en: 'On this last point, controlling external dependencies can be difficult or impossible
    when using external systems managed by other companies. When that’s true, it’s
    worth considering these options:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 关于最后一点，当使用由其他公司管理的外部系统时，控制外部依赖可能很困难或不可能。当这种情况发生时，考虑以下选项是值得的：
- en: Remove some of the higher-level tests if some low-level tests already cover
    those scenarios.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一些低级测试已经覆盖了那些场景，则移除一些高级测试。
- en: Convert some of the higher-level tests to a set of lower-level tests.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一些高级测试转换为一系列低级测试。
- en: If you’re writing new tests, consider a pipeline-friendly testing strategy with
    test recipes (such as the one I’ll explain in chapter 10).
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在编写新的测试，请考虑一个对管道友好的测试策略，包括测试配方（例如，我将在第10章中解释的那个）。
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: If you don’t trust a test when it’s failing, you might ignore a real bug, and
    if you don’t trust a test when it’s passing, you’ll end up doing lots of manual
    debugging and testing. Both of these outcomes are supposed to be reduced by having
    good tests, but if we don’t reduce them, *and* we spend all this time writing
    tests that we don’t trust, what’s the point in writing them in the first place?
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你不相信失败的测试，你可能会忽略一个真实的错误，如果你不相信通过的测试，你最终会进行大量的手动调试和测试。这两种结果都应通过拥有良好的测试来减少，但如果我们不减少它们，*并且*我们花费所有这些时间编写我们不信任的测试，那么最初编写它们的目的是什么呢？
- en: 'Tests might fail for multiple reasons: a real bug found in production code,
    a bug in the test resulting in a false failure, a test being out of date due to
    a change in functionality, a test conflicting with another test, or test flakiness.
    Only the first reason is a valid one. All the others tell us the test shouldn’t
    be trusted.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试可能因多种原因而失败：在生产代码中发现的真实错误、导致虚假失败的测试中的错误、由于功能更改而变得过时的测试、与另一个测试冲突的测试或测试不可靠。只有第一个原因是有效的。所有其他原因都告诉我们不应该信任这个测试。
- en: Avoid complexity in tests, such as creating dynamic expected values or duplicating
    logic from the underlying production code. Such complexity increases the chances
    of introducing bugs in tests and the time it takes to understand them.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免在测试中引入复杂性，例如创建动态预期值或复制底层生产代码中的逻辑。这种复杂性增加了在测试中引入错误的可能性，以及理解它们所需的时间。
- en: If a test doesn’t have any asserts, you can’t understand what's it’s doing,
    it runs alongside flaky tests (even if this test itself isn’t flaky), it verifies
    multiple exit points, or it keeps changing, it can’t be fully trusted.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个测试没有任何断言，你就无法理解它在做什么，它和易出错的测试并行运行（即使这个测试本身不是易出错的），它验证多个退出点，或者它不断变化，那么它就不能完全信赖。
- en: Flaky tests are tests that fail unpredictably. The higher the level of the test,
    the more real dependencies it uses, which gives us confidence in the overall system’s
    correctness but results in more flakiness. To better identify flaky tests, put
    them in a special category or folder that can be run separately.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易出错的测试是指那些不可预测地失败的测试。测试的层级越高，它使用的实际依赖项就越多，这让我们对整个系统的正确性更有信心，但同时也导致了更多的不稳定性。为了更好地识别易出错的测试，可以将它们放入一个特殊的类别或文件夹中，以便单独运行。
- en: To reduce test flakiness, either fix the tests, convert flaky higher-level tests
    into less flaky lower-level ones, or delete them.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了减少测试的不稳定性，可以选择修复测试、将不稳定的较高层测试转换为更稳定的较低层测试，或者删除它们。
