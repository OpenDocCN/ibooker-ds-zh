- en: Part 1\. Foundations
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1部分. 基础
- en: What is machine learning? What is the game of Go, and why was it such an important
    milestone for game AI? How is teaching a computer to play Go different from teaching
    it to play chess or checkers?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是机器学习？围棋是什么游戏，为什么它对游戏人工智能如此重要？教计算机下围棋与教它下棋或跳棋有何不同？
- en: In this part, we answer all those questions, and you’ll build a flexible Go
    game logic library that will provide a foundation for the rest of the book.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这部分，我们回答所有这些问题，并且你将构建一个灵活的Go游戏逻辑库，这将为本书的其余部分提供基础。
- en: 'Chapter 1\. Toward deep learning: a machine-learning introduction'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1章. 深度学习：机器学习入门
- en: '*This chapter covers:*'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖内容：*'
- en: Machine learning and its differences from traditional programming
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习及其与传统编程的区别
- en: Problems that can and can’t be solved with machine learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以和不能用机器学习解决的问题
- en: Machine learning’s relationship to artificial intelligence
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习与人工智能的关系
- en: The structure of a machine-learning system
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习系统的结构
- en: Disciplines of machine learning
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的学科
- en: 'As long as computers have existed, programmers have been interested in *artificial
    intelligence* (AI): implementing human-like behavior on a computer. Games have
    long been a popular subject for AI researchers. During the personal computer era,
    AIs have overtaken humans at checkers, backgammon, chess, and almost all classic
    board games. But the ancient strategy game Go remained stubbornly out of reach
    for computers for decades. Then in 2016, Google DeepMind’s AlphaGo AI challenged
    14-time world champion Lee Sedol and won four out of five games. The next revision
    of AlphaGo was completely out of reach for human players: it won 60 straight games,
    taking down just about every notable Go player in the process.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 只要计算机存在，程序员就对*人工智能*（AI）感兴趣：在计算机上实现类似人类的行为。游戏一直是人工智能研究人员的热门主题。在个人电脑时代，人工智能在跳棋、国际象棋、双陆棋以及几乎所有经典棋类游戏中都超越了人类。但古老的策略游戏围棋在几十年里一直让计算机望尘莫及。然后在2016年，谷歌DeepMind的AlphaGo人工智能挑战了14次世界冠军李世石，并赢得了五场比赛中的四场。AlphaGo的下一次修订版本对人类玩家来说完全无法触及：它连续赢了60场比赛，在这个过程中击败了几乎所有知名的围棋选手。
- en: AlphaGo’s breakthrough was enhancing classical AI algorithms with machine learning.
    More specifically, AlphaGo used modern techniques known as *deep learning*—algorithms
    that can organize raw data into useful layers of abstraction. These techniques
    aren’t limited to games at all. You’ll also find deep learning in applications
    for identifying images, understanding speech, translating natural languages, and
    guiding robots. Mastering the foundations of deep learning will equip you to understand
    how all these applications work.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: AlphaGo的突破在于将经典人工智能算法与机器学习相结合。更具体地说，AlphaGo使用了现代的称为*深度学习*的技术——可以将原始数据组织成有用的抽象层。这些技术并不仅限于游戏。你还会在识别图像、理解语音、翻译自然语言和引导机器人等应用中找到深度学习。掌握深度学习的基础将使你能够理解所有这些应用是如何工作的。
- en: Why write a whole book about computer Go? You might suspect that the authors
    are die-hard Go nuts—OK, guilty as charged. But the real reason to study Go, as
    opposed to chess or backgammon, is that a strong Go AI requires deep learning.
    A top-tier chess engine such as Stockfish is full of chess-specific logic; you
    need a certain amount of knowledge about the game to write something like that.
    With deep learning, you can teach a computer to imitate strong Go players, even
    if you don’t understand what they’re doing. And that’s a powerful technique that
    opens up all kinds of applications, both in games and in the real world.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要写一本关于计算机围棋的书？你可能怀疑作者们是围棋的死忠粉——好吧，罪有应得。但真正学习围棋而不是国际象棋或双陆棋的原因是，强大的围棋人工智能需要深度学习。像Stockfish这样的顶级国际象棋引擎充满了针对国际象棋的逻辑；你需要一定量的游戏知识来编写这样的东西。有了深度学习，你可以教会计算机模仿强大的围棋选手，即使你不懂他们在做什么。这是一种强大的技术，它为游戏和现实世界中的各种应用打开了大门。
- en: Chess and checkers AIs are designed around reading out the game further and
    more accurately than human players can. There are two problems with applying this
    technique to Go. First, you can’t read far ahead, because the game has too many
    moves to consider. Second, even if you could read ahead, you don’t know how to
    evaluate whether the result is good. It turns out that deep learning is the key
    to unlocking both problems.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 国际象棋和国际跳棋的AI设计是为了比人类玩家更深入、更准确地阅读游戏。将这种技术应用于围棋有两个问题。首先，你无法看得太远，因为游戏中有太多的走法需要考虑。其次，即使你能看得远，你也不知道如何评估结果是否好。结果证明，深度学习是解决这两个问题的关键。
- en: This book provides a practical introduction to deep learning by covering the
    techniques that powered AlphaGo. You don’t need to study the game of Go in much
    detail to do this; instead, you’ll look at the general principles of the way a
    machine can learn. This chapter introduces machine learning and the kinds of problems
    it can (and can’t) solve. You’ll work through examples that illustrate the major
    branches of machine learning, and see how deep learning has brought machine learning
    into new domains.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本书通过介绍推动AlphaGo的技术，提供了对深度学习的实用介绍。你不需要详细研究围棋游戏来做这件事；相反，你将研究机器可以学习的一般原则。本章介绍了机器学习以及它可以（和不能）解决的问题。你将通过示例了解机器学习的各个主要分支，并看到深度学习如何将机器学习带入新的领域。
- en: 1.1\. What is machine learning?
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1. 什么是机器学习？
- en: Consider the task of identifying a photo of a friend. This is effortless for
    most people, even if the photo is badly lit, or your friend got a haircut or is
    wearing a new shirt. But suppose you want to program a computer to do the same
    thing. Where would you even begin? This is the kind of problem that machine learning
    can solve.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑识别朋友照片的任务。对大多数人来说，即使照片光线昏暗，或者你的朋友剪了头发或穿了新衬衫，这也是轻而易举的。但假设你想编程让计算机做同样的事情。你甚至从哪里开始？这正是机器学习可以解决的问题。
- en: 'Traditionally, computer programming is about applying clear rules to structured
    data. A human developer programs a computer to execute a set of instructions on
    data, and out comes the desired result, as shown in [figure 1.1](#ch01fig01).
    Think of a tax form: every box has a well-defined meaning, and detailed rules
    indicate how to make various calculations from them. Depending on where you live,
    these rules may be extremely complicated. It’s easy for people to make a mistake
    here, but this is exactly the kind of task that computer programs excel at.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，计算机编程是关于将明确的规则应用于结构化数据。人类开发者编写计算机程序来执行数据上的一系列指令，并得到期望的结果，如图1.1[图1.1](#ch01fig01)所示。想想税务表格：每个框都有一个明确的含义，详细的规则说明了如何从它们中进行各种计算。根据你所在的地方，这些规则可能非常复杂。人们在这里犯错很容易，但这正是计算机程序擅长处理的那种任务。
- en: Figure 1.1\. The standard programming paradigm that most software developers
    are familiar with. The developer identifies the algorithm and implements the code;
    the users supply the data.
  id: totrans-18
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.1. 大多数软件开发者所熟悉的标准化编程范式。开发者识别算法并实现代码；用户提供数据。
- en: '![](Images/01fig01_alt.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片1.1](Images/01fig01_alt.jpg)'
- en: In contrast to the traditional programming paradigm, *machine learning* is a
    family of techniques for inferring a program or algorithm from example data, rather
    than implementing it directly. So, with machine learning, you still feed your
    computer data, but instead of imposing instructions and expecting output, *you
    provide the expected output and let the machine find an algorithm by itself*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的编程范式相比，*机器学习*是一系列从示例数据中推断程序或算法的技术，而不是直接实现它。因此，在机器学习中，你仍然向你的电脑提供数据，但不是施加指令并期望输出，而是*提供预期的输出，让机器自己找到算法*。
- en: To build a computer program that can identify who’s in a photo, you can apply
    an algorithm that analyzes a large collection of images of your friend and generates
    a function that matches them. If you do this correctly, the generated function
    will also match new photos that you’ve never seen before. Of course, the program
    will have no knowledge of its purpose; all it can do is identify things that are
    similar to the original images you fed it.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个可以识别照片中是谁的计算机程序，你可以应用一个算法，该算法分析你朋友的大量照片集合，并生成一个匹配它们的函数。如果你这样做正确，生成的函数也将匹配你之前从未见过的新的照片。当然，程序将没有关于其目的的知识；它能做的只是识别与它提供给你的原始图像相似的事物。
- en: In this situation, you call the images you provide the machine *training data*,
    and the names of the person on the picture *labels*. After you’ve *trained* an
    algorithm for your purpose, you can use it to *predict* labels on new data to
    test it. [Figure 1.2](#ch01fig02) displays this example alongside a schema of
    the machine-learning paradigm.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你将提供给机器的图像称为*训练数据*，而图片上的人的名字称为*标签*。在你为特定目的训练了一个算法之后，你可以使用它来*预测*新数据上的标签以测试它。[图1.2](#ch01fig02)展示了这个例子以及机器学习范式的架构。
- en: 'Figure 1.2\. The machine-learning paradigm: during development, you generate
    an algorithm from a data set, and then incorporate that into your final application.'
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.2\. 机器学习范式：在开发过程中，你从一个数据集中生成一个算法，然后将其整合到你的最终应用程序中。
- en: '![](Images/01fig02_alt.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/01fig02_alt.jpg)'
- en: Machine learning comes in when rules aren’t clear; it can solve problems of
    the “I’ll know it when I see it” variety. Instead of programming the function
    directly, you provide data that indicates what the function should do, and then
    methodically generate a function that matches your data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当规则不明确时，机器学习就派上用场；它可以解决“当我看到它时我会知道”这类问题。你不需要直接编程函数，而是提供指示函数应该做什么的数据，然后系统地生成一个与你的数据匹配的函数。
- en: In practice, you usually combine machine learning with traditional programming
    to build a useful application. For our face-detection app, you have to instruct
    the computer on how to find, load, and transform the example images before you
    can apply a machine-learning algorithm. Beyond that, you might use hand-rolled
    heuristics to separate headshots from photos of sunsets and latte art; then you
    can apply machine learning to put names to faces. Often a mixture of traditional
    programming techniques and advanced machine-learning algorithms will be superior
    to either one alone.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，你通常将机器学习与传统的编程相结合来构建一个有用的应用程序。对于我们的面部检测应用程序，在应用机器学习算法之前，你必须指导计算机如何找到、加载和转换示例图像。除此之外，你可能使用手工制作的启发式方法来区分头像和日落照片以及拿铁艺术照片；然后你可以应用机器学习来给面孔命名。通常，传统的编程技术和高级机器学习算法的结合将优于单独使用其中任何一个。
- en: 1.1.1\. How does machine learning relate to AI?
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.1.1\. 机器学习如何与人工智能相关？
- en: '*Artificial intelligence*, in the broadest sense, refers to any technique for
    making computers imitate human behavior. AI includes a huge range of techniques,
    including the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在最广泛的意义上，*人工智能*指的是任何使计算机模仿人类行为的技巧。AI包括一系列广泛的技术，包括以下内容：
- en: Logic production systems, which apply formal logic to evaluate statements
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑生产系统，它将形式逻辑应用于评估陈述
- en: Expert systems, in which programmers try to directly encode human knowledge
    into software
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专家系统，其中程序员试图直接将人类知识编码到软件中
- en: Fuzzy logic, which defines algorithms to help computers process imprecise statements
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模糊逻辑，它定义算法以帮助计算机处理不精确的陈述
- en: These sorts of rules-based techniques are sometimes called *classical AI* or
    *GOFAI* (good old-fashioned AI).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这类基于规则的技巧有时被称为*经典人工智能*或*GOFAI*（老式的传统人工智能）。
- en: 'Machine learning is just one of many fields in AI, but today it’s arguably
    the most successful one. In particular, the subfield of deep learning is behind
    some of the most exciting breakthroughs in AI, including tasks that eluded researchers
    for decades. In classical AI, researchers would study human behavior and try to
    encode rules that match it. Machine learning and deep learning flip the problem
    on its head: now you collect examples of human behavior and apply mathematical
    and statistical techniques to extract the rules.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习只是人工智能众多领域中的一个，但今天它可能是最成功的一个。特别是深度学习这一子领域，它背后的一些最令人兴奋的AI突破，包括那些让研究人员困扰了几十年的任务。在经典人工智能中，研究人员会研究人类行为并尝试编码与之匹配的规则。机器学习和深度学习则完全颠覆了这个问题：现在你收集人类行为的数据样本，并应用数学和统计技术来提取规则。
- en: Deep learning is so ubiquitous that some people in the community use *AI* and
    *deep learning* interchangeably. For clarity, we’ll use *AI* to refer to the general
    problem of imitating human behavior with computers, and *machine learning* or
    *deep learning* to refer to mathematical techniques for extracting algorithms
    from examples.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习如此普遍，以至于社区中的一些人将*AI*和*深度学习*互换使用。为了清晰起见，我们将使用*AI*来指代用计算机模仿人类行为的普遍问题，而使用*机器学习*或*深度学习*来指代从示例中提取算法的数学技术。
- en: 1.1.2\. What you can and can’t do with machine learning
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.1.2\. 你可以用机器学习做什么，不能做什么
- en: 'Machine learning is a specialized technique. You wouldn’t use machine learning
    to update database records or render a user interface. Traditional programming
    should be preferred in the following situations:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一种专业化的技术。你不会使用机器学习来更新数据库记录或渲染用户界面。在以下情况下，应优先考虑传统编程：
- en: '***Traditional algorithms solve the problem directly.*** If you can directly
    write code to solve a problem, it’ll be easier to understand, maintain, test,
    and debug.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***传统算法直接解决问题。*** 如果你可以直接编写代码来解决问题，那么它将更容易理解、维护、测试和调试。'
- en: '***You expect perfect accuracy.*** All complex software contains bugs. But
    in traditional software engineering, you expect to methodically identify and fix
    bugs. That’s not always possible with machine learning. You can improve machine-learning
    systems, but focusing too much on a specific error often makes the overall system
    worse.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***你期望完美的准确性。*** 所有复杂的软件都包含错误。但在传统软件工程中，你期望系统地识别和修复错误。但在机器学习中，这并不总是可能的。你可以改进机器学习系统，但过分关注特定错误往往会使整个系统变得更差。'
- en: '***Simple heuristics work well.*** If you can implement a rule that’s good
    enough with just a few lines of code, do so and be happy. A simple heuristic,
    implemented clearly, will be easy to understand and maintain. Functions that are
    implemented with machine learning are opaque and require a separate training process
    to update. (On the other hand, if you’re maintaining a complicated sequence of
    heuristics, that’s a good candidate to replace with machine learning.)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***简单的启发式方法效果很好。*** 如果你可以用几行代码实现一个足够好的规则，那么就这样做并感到高兴。一个简单的启发式方法，如果清晰实现，将很容易理解和维护。用机器学习实现的函数是透明的，并且需要单独的训练过程来更新。（另一方面，如果你在维护一个复杂的启发式方法序列，那么用机器学习替换它是一个很好的候选方案。）'
- en: Often there’s a fine line between problems that are feasible to solve with traditional
    programming and problems that are virtually impossible to solve, even with machine
    learning. Detecting faces in images versus tagging faces with names is just one
    example we’ve seen. Determining what language a text is written in versus translating
    that text into a given language is another such example.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在可以用传统编程解决的问题和几乎不可能解决的问题之间有一条很细的界限，即使使用机器学习也是如此。在图像中检测人脸与用名字标记人脸只是我们看到的例子之一。确定文本是用哪种语言写的与将该文本翻译成特定语言是另一个这样的例子。
- en: 'We often resort to traditional programming in situations where machine learning
    might help—for instance, when the complexity of the problem is extremely high.
    When confronted with highly complex, information-dense scenarios, humans tend
    to settle for rules of thumb and narratives: think macroeconomics, stock-market
    predictions, or politics. Process managers and so-called experts can often vastly
    benefit from enhancing their intuition with insights gained from machine learning.
    Often, real-world data has more structure than anticipated, and we’re just beginning
    to harvest the benefits of automation and augmentation in many of these areas.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常在机器学习可能有所帮助的情况下求助于传统编程——例如，当问题的复杂性极高时。面对高度复杂、信息密集的场景时，人类往往满足于经验法则和叙述：想想宏观经济学、股市预测或政治。流程经理和所谓的专家往往可以从增强他们的直觉中受益于从机器学习中获得的认识。通常，现实世界的数据比预期的更有结构，我们才刚刚开始收获在这些许多领域的自动化和增强的好处。
- en: 1.2\. Machine learning by example
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2\. 通过示例学习机器学习
- en: The goal of machine learning is to construct a function that would be hard to
    implement directly. You do this by selecting a *model*, a large family of generic
    functions. Then you need a procedure for selecting a function from that family
    that matches your goal; this process is called *training* or *fitting* the model.
    You’ll work through a simple example.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的目标是构建一个难以直接实现的函数。你通过选择一个 *模型*，一个大型通用函数族来实现这一点。然后你需要一个从该族中选择与你的目标匹配的函数的程序；这个过程被称为
    *训练* 或 *拟合* 模型。你将通过一个简单的例子来操作。
- en: Let’s say you collect the height and weight of some people and plot those values
    on a graph. [Figure 1.3](#ch01fig03) shows some data points that were pulled from
    the roster of a professional soccer team.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你收集了一些人的身高和体重数据，并将这些值绘制在图表上。[图1.3](#ch01fig03) 展示了一些从职业足球队名单中提取的数据点。
- en: Figure 1.3\. A simple example data set. Each point on the graph represents a
    soccer player’s height and weight. Your goal is to fit a model to these points.
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.3\. 一个简单的示例数据集。图表上的每个点代表一名足球运动员的身高和体重。你的目标是拟合一个模型到这些点上。
- en: '![](Images/01fig03_alt.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/01fig03_alt.jpg)'
- en: 'Suppose you want to describe these points with a mathematical function. First,
    notice that the points, more or less, make a straight line going up and to the
    right. If you think back to high school algebra, you may recall that functions
    of the form *f*(*x*) = *ax* + *b* describe straight lines. You might suspect that
    you could find values of *a* and *b* so that *ax* + *b* matches your data points
    fairly closely. The values of *a* and *b* are the *parameters*, or *weights*,
    that you need to figure out. This is your model. You can write Python code that
    can generate any function in this family:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想用数学函数描述这些点。首先，注意这些点或多或少地形成了一条向上向右的直线。如果你回想起高中代数，你可能还记得形式为 *f*(*x*) = *ax*
    + *b* 的函数描述了直线。你可能怀疑你可以找到 *a* 和 *b* 的值，使得 *ax* + *b* 与你的数据点相当接近。*a* 和 *b* 的值是你要找出的*参数*或*权重*。这是你的模型。你可以编写Python代码来生成这个家族中的任何函数：
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: How would you find out the right values of *a* and *b*? You can use rigorous
    algorithms to do this, but for a quick and dirty solution, you could just draw
    a line through your graph with a ruler and try to work out its formula. [Figure
    1.4](#ch01fig04) shows such a line that follows the general trend of the data
    set.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何找到 *a* 和 *b* 的正确值？你可以使用严格的算法来做这件事，但为了一个快速而简单的解决方案，你只需用直尺在你的图上画一条线，并尝试找出它的公式。[图1.4](#ch01fig04)
    显示了一条遵循数据集总体趋势的线。
- en: Figure 1.4\. First you note that your data set roughly follows a linear trend,
    then you find the formula for a specific line that fits the data.
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.4。首先，你注意到你的数据集大致遵循线性趋势，然后你找到适合数据的特定线的公式。
- en: '![](Images/01fig04_alt.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/01fig04_alt.jpg)'
- en: 'If you eyeball a couple of points that the line passes through, you can calculate
    a formula for the line; you’ll get something like *f*(*x*) = 4.2*x* – 137\. Now
    you have a specific function that matches your data. If you measure the height
    of a new person, you could then use your formula to estimate that person’s weight.
    It won’t be exactly right, but it may be close enough to be useful. You can turn
    your `GenericLinearFunction` into a specific function:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你用眼睛观察这条线通过的几个点，你可以计算出这条线的公式；你将得到类似 *f*(*x*) = 4.2*x* – 137 的结果。现在你有一个与你的数据匹配的特定函数。如果你测量一个新人的身高，然后你可以使用你的公式来估计这个人的体重。它可能不会完全正确，但它可能足够接近以有用。你可以将你的
    `GenericLinearFunction` 转换为特定函数：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This should be a pretty good estimate, so long as your new person is also a
    professional soccer player. All the people in your data set are adult men, in
    a fairly narrow age range, who train for the same sport every day. If you try
    to apply your function to female soccer players, or Olympic weightlifters, or
    babies, you’ll get wildly inaccurate results. Your function is only as good as
    your training data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 只要你的新人是职业足球运动员，这应该是一个相当好的估计。你数据集中的所有人都是成年男性，年龄范围相当窄，每天都进行相同的运动训练。如果你尝试将你的函数应用于女性足球运动员、奥运举重运动员或婴儿，你将得到极其不准确的结果。你的函数只和你训练的数据一样好。
- en: 'This is the basic process of machine learning. Here, your model is the family
    of all functions that look like *f*(x) = *ax* + *b*. And in fact, even something
    that simple is a useful model that statisticians use all the time. As you tackle
    more-complex problems, you’ll use more-sophisticated models and more-advanced
    training techniques. But the core idea is the same: first describe a large family
    of possible functions and then identify the best function from that family.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是机器学习的基本过程。在这里，你的模型是所有看起来像 *f*(x) = *ax* + *b* 的函数的集合。实际上，即使是如此简单的东西也是一个统计学家经常使用的有用模型。随着你解决更复杂的问题，你会使用更复杂的模型和更先进的训练技术。但核心思想是相同的：首先描述一个可能的函数的大类，然后从该类中识别出最好的函数。
- en: '|  |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Python and machine learning**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python与机器学习**'
- en: All the code samples in this book are written in Python. Why Python? First,
    Python is an expressive high-level language for general application development.
    In addition, Python is among the most popular languages for machine learning and
    mathematical programming. This combination makes Python a natural choice for an
    application that integrates machine learning.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有代码示例都是用Python编写的。为什么是Python？首先，Python是一种用于通用应用程序开发的表达性高级语言。此外，Python是机器学习和数学编程中最受欢迎的语言之一。这种组合使得Python成为集成机器学习的应用程序的自然选择。
- en: 'Python is popular for machine learning because of its amazing collection of
    numerical computing packages. Packages we use in this book include the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Python因其惊人的数值计算包集合而受到机器学习的青睐。本书中我们使用的包包括以下内容：
- en: '***NumPy*—** This library provides efficient data structures to represent numerical
    vectors and arrays, and an extensive library of fast mathematical operations.
    NumPy is the bedrock of Python’s numerical computing ecosystem: every notable
    library for machine learning or statistics integrates with NumPy.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***NumPy*—** 这个库提供了高效的数据结构来表示数值向量和数组，以及一个广泛的快速数学运算库。NumPy 是 Python 数值计算生态系统的基石：每个知名的机器学习或统计学库都与
    NumPy 集成。'
- en: '***TensorFlow and Theano*—** These are two graph computation libraries (*graph*
    in the sense of a network of connected steps, not *graph* as in *diagram*). They
    allow you to specify complex sequences of mathematical operations, and then generate
    highly optimized implementations.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***TensorFlow 和 Theano*—** 这是有两个图计算库（这里的“图”指的是一系列连接的步骤，而不是“图”作为图表的意思）。它们允许你指定复杂的数学运算序列，然后生成高度优化的实现。'
- en: '***Keras*—** This is a high-level library for deep learning. It provides a
    convenient way for you to specify neural networks, and relies on TensorFlow or
    Theano to handle the raw computation.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Keras*—** 这是一个用于深度学习的高级库。它为你提供了一个方便的方式来指定神经网络，并依赖于 TensorFlow 或 Theano 来处理原始计算。'
- en: We wrote the code examples in this book with Keras 2.2 and TensorFlow 1.8 in
    mind. You should be able to use any Keras version in the 2.*x* series with minimal
    modifications.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这本书中编写的代码示例是以 Keras 2.2 和 TensorFlow 1.8 为背景的。你应该能够使用 2.*x* 系列中的任何 Keras
    版本，只需进行最小修改。
- en: '|  |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 1.2.1\. Using machine learning in software applications
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.1\. 在软件应用中使用机器学习
- en: In the previous section, you looked at a purely mathematical model. How can
    you apply machine learning to a real software application?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你查看了一个纯粹数学模型。你如何将机器学习应用于实际的软件应用？
- en: Suppose you’re working on a photo-sharing app, in which users have uploaded
    millions of pictures with tags. You’d like to add a feature that suggests tags
    for a new photo. This feature is a perfect candidate for machine learning.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在开发一个照片分享应用，用户已经上传了数百万张带有标签的图片。你想要添加一个为新照片建议标签的功能。这个功能是机器学习的完美候选。
- en: 'First, you have to be specific about the function you’re trying to learn. Say
    you had a function like this:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你必须明确你想要学习的函数。比如说，你有一个这样的函数：
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Then the rest of the work is relatively straightforward. But it’s not at all
    obvious how to start implementing a function like `suggest_tags`. That’s where
    machine learning comes in.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，剩下的工作相对直接。但是，如何开始实现一个像 `suggest_tags` 这样的函数并不明显。这就是机器学习发挥作用的地方。
- en: If this were an ordinary Python function, you’d expect it to take some kind
    of `Image` object as input and perhaps return a list of strings as output. Machine-learning
    algorithms aren’t so flexible about their inputs and outputs; they generally work
    on vectors and matrices. So as a first step, you need to represent your input
    and output mathematically.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个普通的 Python 函数，你可能会期望它接受某种 `Image` 对象作为输入，并可能返回一个字符串列表作为输出。机器学习算法对它们的输入和输出并不那么灵活；它们通常在向量和矩阵上工作。因此，作为第一步，你需要用数学方式表示你的输入和输出。
- en: 'If you resize the input photo to a fixed size—say, 128 × 128 pixels—then you
    can encode it as a matrix with 128 rows and 128 columns: one float value per pixel.
    What about the output? One option is to restrict the set of tags you’ll identify;
    you could select perhaps the 1,000 most popular tags on the app. The output could
    then be a vector of size 1,000, where each element of the vector corresponds to
    a particular tag. If you allow the output values to vary anywhere between 0 and
    1, you can generate ranked lists of suggested tags. [Figure 1.5](#ch01fig05) illustrates
    this sort of mapping between concepts in your application and mathematical structures.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将输入照片调整到固定大小——比如说，128 × 128 像素——那么你可以将其编码为一个 128 行 128 列的矩阵：每个像素一个浮点值。输出怎么办？一个选择是限制你将识别的标签集；你可能会选择应用上最受欢迎的
    1,000 个标签。输出可以是一个大小为 1,000 的向量，其中向量的每个元素对应一个特定的标签。如果你允许输出值在 0 到 1 之间变化，你可以生成建议标签的排名列表。[图
    1.5](#ch01fig05) 展示了这种在应用概念和数学结构之间的映射。
- en: 'Figure 1.5\. Machine-learning algorithms operate on mathematical structures,
    such as vectors and matrices. Your photo tags are stored in a standard computer
    data structure: a list of strings. This is one possible scheme for encoding that
    list as a mathematical vector.'
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.5\. 机器学习算法在数学结构上操作，如向量和矩阵。你的照片标签存储在标准的计算机数据结构中：字符串列表。这是将列表编码为数学向量的一个可能方案。
- en: '![](Images/01fig05_alt.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/01fig05_alt.jpg)'
- en: This data preprocessing step you just carried out is an integral part of every
    machine-learning system. Usually, you load the data in raw format and carry out
    preprocessing steps to create *features*—input data that can be fed into a machine-learning
    algorithm.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚才执行的数据预处理步骤是每个机器学习系统的基本组成部分。通常，你以原始格式加载数据，并执行预处理步骤以创建*特征*——可以输入到机器学习算法中的输入数据。
- en: 1.2.2\. Supervised learning
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.2\. 监督学习
- en: Next, you need an algorithm for training your model. In this case, you have
    millions of correct examples already—all the photos that users have already uploaded
    and manually tagged in your app. You can learn a function that attempts to match
    these examples as closely as possible, and you hope that it’ll generalize to new
    photos in a sensible way. This technique is known as *supervised learning*, so-called
    because the *labels* of human-curated examples provide guidance for the training
    process.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要一个算法来训练你的模型。在这种情况下，你已经有了数百万个正确的例子——所有用户已经上传并手动标记在你应用程序中的照片。你可以学习一个函数，该函数试图尽可能接近地匹配这些例子，并希望它能以合理的方式推广到新照片。这种技术被称为*监督学习*，之所以称为监督学习，是因为人工编辑的例子*标签*为训练过程提供了指导。
- en: When training is complete, you can deliver the final learned function with your
    application. Every time a user uploads a new photo, you pass it into the trained
    model function and get a vector back. You can match each value in the vector back
    to the tag it represents; then you can select the tags with the largest values
    and show them to the user. Schematically, the procedure you just outlined can
    be represented as shown in [figure 1.6](#ch01fig06).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练完成后，你可以将最终学习到的函数与应用程序一起交付。每次用户上传一张新照片时，你将其传递到训练好的模型函数中，并得到一个向量。你可以将向量中的每个值匹配回它所代表的标签；然后你可以选择具有最大值的标签并展示给用户。从方案上讲，你刚才概述的程序可以表示如图1.6所示。[图1.6](#ch01fig06)。
- en: Figure 1.6\. A machine-learning pipeline for supervised learning
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.6\. 监督学习的机器学习流程
- en: '![](Images/01fig06_alt.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图1.6的替代文本](Images/01fig06_alt.jpg)'
- en: How do you test your trained model? The standard practice is to set aside some
    of your original labeled data for that purpose. Before starting training, you
    can set aside a chunk of your data, say 10%, as a *validation set*. The validation
    set *isn’t* included as part of the training data in any way. Then you can apply
    your trained model to the images in the validation set and compare the suggested
    tags to the known good tags. This lets you compute the accuracy of your model.
    If you want to experiment with different models, you have a consistent metric
    for measuring which is better.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何测试你的训练模型？标准做法是留出一部分原始标记数据用于此目的。在开始训练之前，你可以留出一部分数据，比如10%，作为*验证集*。验证集*不*以任何方式包含在训练数据中。然后你可以将你的训练模型应用于验证集中的图像，并将建议的标签与已知的良好标签进行比较。这让你可以计算模型的准确度。如果你想尝试不同的模型，你有一个一致的指标来衡量哪个更好。
- en: 'In game AI, you can extract labeled training data from records of human games.
    And online gaming is a huge boon for machine learning: when people play a game
    online, the game server may save a computer-readable record. Examples of how to
    apply supervised learning to games are as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在游戏人工智能中，你可以从人类游戏记录中提取标记的训练数据。在线游戏对机器学习来说是一个巨大的福音：当人们在线玩游戏时，游戏服务器可能会保存一个可读的计算机记录。以下是如何将监督学习应用于游戏的示例：
- en: Given a collection of complete records of chess games, represent the game state
    in vector or matrix form and learn to predict the next move from data.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一组完整的象棋游戏记录，以向量或矩阵形式表示游戏状态，并从数据中学习预测下一步棋。
- en: Given a board position, learn to predict the likelihood of winning for that
    state.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一个棋盘位置，学习预测该状态获胜的可能性。
- en: 1.2.3\. Unsupervised learning
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.3\. 无监督学习
- en: In contrast to supervised learning, the subfield of machine learning called
    *unsupervised learning* doesn’t come with any labels to guide the learning process.
    In unsupervised learning, the algorithm has to learn to find patterns in the input
    data on its own. The only difference from [figure 1.6](#ch01fig06) is that you’re
    missing the labels, so you can’t evaluate your predictions the way you did before.
    All other components stay the same.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 与监督学习相反，机器学习的一个子领域称为*无监督学习*，在学习过程中没有提供任何标签来指导学习过程。在无监督学习中，算法必须学会自己从输入数据中找到模式。与[图1.6](#ch01fig06)的唯一区别是缺少标签，因此你不能像以前那样评估你的预测。所有其他组件保持不变。
- en: An example of this is *outlier detection*—identifying data points that don’t
    fit with the general trend of the data set. In the soccer player data set, outliers
    would indicate players who don’t match the typical physique of their teammates.
    For instance, you could come up with an algorithm that measures the distance of
    a height-width pair to the line you eyeballed. If a data point exceeds a certain
    distance to the average line, you declare it an outlier.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况的例子是 *异常检测*——识别与数据集总体趋势不符的数据点。在足球运动员数据集中，异常值将表明与队友典型体型不匹配的球员。例如，你可以提出一个算法来测量身高-宽度对与目测线的距离。如果一个数据点超过平均线的某个距离，你就可以将其宣布为异常值。
- en: In board-game AI, a natural question to ask is which pieces on the board belong
    together or form a group. In the next chapter, you’ll see what this means for
    the game of Go in more detail. Finding groups of pieces that have a relationship
    is sometimes called *clustering* or *chunking*. [Figure 1.7](#ch01fig07) shows
    an example of what this could look like for chess.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在棋盘游戏人工智能中，一个自然的问题是要问棋盘上的哪些棋子属于一组或形成一个群体。在下一章中，你将更详细地了解这对围棋游戏意味着什么。寻找具有关系的棋子组有时被称为
    *聚类* 或 *分块*。[图 1.7](#ch01fig07) 展示了这可能在棋类游戏中看起来是什么样子。
- en: Figure 1.7\. An unsupervised machine-learning pipeline for finding clusters
    or chunks of chess pieces
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.7\. 寻找棋子簇或块的无监督机器学习流程
- en: '![](Images/01fig07_alt.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图片 1.7](Images/01fig07_alt.jpg)'
- en: 1.2.4\. Reinforcement learning
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.4\. 强化学习
- en: 'Supervised learning is powerful, but finding quality training data can be a
    major obstacle. Suppose you’re building a house-cleaning robot. The robot has
    various sensors that can detect when it’s near obstacles, and motors that let
    it scoot around the floor and steer left or right. You need a control system:
    a function that can analyze the sensor input and decide how it should move. But
    supervised learning is impossible here. You have no examples to use as training
    data—your robot doesn’t even exist yet.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习很强大，但找到高质量的训练数据可能是一个主要障碍。假设你正在构建一个清洁机器人。机器人有各种传感器可以检测它接近障碍物时的情况，以及让它在地面上滑动和左右转向的电机。你需要一个控制系统：一个可以分析传感器输入并决定如何移动的函数。但在这里，监督学习是不可能的。你没有例子可以用作训练数据——你的机器人甚至还没有存在。
- en: Instead, you can apply *reinforcement learning*, a sort of trial-and-error approach.
    You start with an inefficient or inaccurate control system, and then you let the
    robot attempt its task. During the task, you record all the inputs your control
    system sees and the decisions it makes. When it’s done, you need a way to evaluate
    how well it did, perhaps by calculating the fraction of the floor it vacuumed
    and how far it drained its battery. That whole experience gives you a small chunk
    of training data, and you can use it to improve the control system. By repeating
    the whole process over and over, you can gradually home in on an efficient control
    function. [Figure 1.8](#ch01fig08) shows this process as a flowchart.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，你可以应用 *强化学习*，这是一种试错方法。你从一个低效或不准确的控制系统开始，然后让机器人尝试其任务。在任务过程中，你记录下控制系统看到的所有输入和它所做的决策。完成后，你需要一种方法来评估它的表现如何，可能通过计算它吸尘的地面比例和电池消耗的距离。整个经历为你提供了一小块训练数据，你可以用它来改进控制系统。通过反复进行整个过程，你可以逐渐找到有效的控制函数。[图
    1.8](#ch01fig08) 将此过程展示为流程图。
- en: Figure 1.8\. In reinforcement learning, agents learn to interact with their
    environment by trial and error. You repeatedly have your agent attempt its task
    to get a supervised signal to learn from. With every cycle, you can make an incremental
    improvement.
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.8\. 在强化学习中，智能体通过试错来学习与环境互动。你反复让你的智能体尝试其任务以获得监督信号来学习。在每一个循环中，你可以进行增量改进。
- en: '![](Images/01fig08_alt.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图片 1.8](Images/01fig08_alt.jpg)'
- en: 1.3\. Deep learning
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3\. 深度学习
- en: 'This book is made up of sentences. The sentences are made of words; the words
    are made of letters; the letters are made of lines and curves; and, ultimately,
    those lines and curves are made of tiny dots of ink. When teaching a child to
    read, you start with the smallest parts and work your way up: first letters, then
    words, then sentences, and finally complete books. (Normally, children learn to
    recognize lines and curves on their own.) This kind of hierarchy is the natural
    way for people to learn complex concepts. At each level, you ignore some detail,
    and the concepts become more abstract.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书由句子组成。句子由单词组成；单词由字母组成；字母由线条和曲线组成；最终，这些线条和曲线由微小的墨点组成。当教孩子阅读时，你从最小的部分开始，逐步向上：首先是字母，然后是单词，然后是句子，最后是完整的书籍。（通常，孩子们会自己学会识别线条和曲线。）这种层次结构是人们学习复杂概念的自然方式。在每一级，你忽略一些细节，概念变得更加抽象。
- en: '*Deep learning* applies the same idea to machine learning. Deep learning is
    a subfield of machine learning that uses a specific family of models: sequences
    of simple functions chained together. These chains of functions are known as *neural
    networks* because they were loosely inspired by the structure of natural brains.
    The core idea of deep learning is that these sequences of functions can analyze
    a complex concept as a hierarchy of simpler ones. The first layer of a deep model
    can learn to take raw data and organize it in basic ways—for example, grouping
    dots into lines. Each successive layer organizes the previous layer into more-advanced
    and more-abstract concepts. The process of learning these abstract concepts is
    called *representation learning*.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*深度学习* 将相同的思想应用于机器学习。深度学习是机器学习的一个子领域，它使用特定系列模型：简单函数的链式连接。这些函数链被称为 *神经网络*，因为它们在结构上受到了自然大脑的启发。深度学习的核心思想是这些函数序列可以分析复杂概念作为更简单概念的层次结构。深度模型的第一层可以学习从原始数据中提取并按基本方式组织它——例如，将点分组成线条。每一层后续组织前一层，形成更高级和更抽象的概念。学习这些抽象概念的过程称为
    *表示学习*。'
- en: The amazing thing about deep learning is that you don’t need to know what the
    intermediate concepts are in advance. If you select a model with enough layers
    and provide enough training data, the training process will gradually organize
    the raw data into increasingly high-level concepts. But how does the training
    algorithm know what concepts to use? It doesn’t; it just organizes the input in
    any way that helps it to better match the training examples. There’s no guarantee
    that this representation matches the way humans would think about the data. [Figure
    1.9](#ch01fig09) shows how representation learning fits into the supervised learning
    flow.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的惊人之处在于你事先不需要知道中间概念是什么。如果你选择一个具有足够层数的模型并提供足够的训练数据，训练过程将逐步将原始数据组织成越来越高级的概念。但是，训练算法如何知道使用哪些概念呢？它不知道；它只是以任何有助于它更好地匹配训练示例的方式组织输入。没有保证这种表示与人类思考数据的方式相匹配。[图
    1.9](#ch01fig09) 展示了表示学习如何融入监督学习流程。
- en: Figure 1.9\. Deep learning and representation learning
  id: totrans-100
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.9\. 深度学习和表示学习
- en: '![](Images/01fig09_alt.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/01fig09_alt.jpg)'
- en: 'All this power comes with a cost. Deep models have huge numbers of weights
    to learn. Recall the simple *ax* + *b* model you used for your height and weight
    data set; that model had just two weights to learn. A deep model suitable for
    your image-tagging app could have a million weights. As a result, deep learning
    demands larger data sets, more computing power, and a more hands-on approach to
    training. Both techniques have their place. Deep learning is a good choice in
    the following circumstances:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些能力都伴随着代价。深度模型需要学习大量的权重。回想一下你用来处理身高和体重数据集的简单 *ax* + *b* 模型；那个模型只需要学习两个权重。一个适合你图像标签应用的深度模型可能有百万个权重。因此，深度学习需要更大的数据集、更多的计算能力和更实际的方法来训练。这两种技术都有其适用场景。在以下情况下，深度学习是一个不错的选择：
- en: '***Your data is in an unstructured form.*** Images, audio, and written language
    are good candidates for deep learning. It’s possible to apply simple models to
    that kind of data, but it generally requires sophisticated preprocessing.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***你的数据是无结构的。*** 图像、音频和书面语言是深度学习的良好候选。虽然可以将简单模型应用于此类数据，但通常需要复杂的预处理。'
- en: '***You have large amounts of data available or have a plan for acquiring more.***
    In general, the more complex your model is, the more data you need to train it.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***你有大量可用数据或计划获取更多数据。*** 通常，你的模型越复杂，你需要训练它的数据就越多。'
- en: '***You have plenty of computing power or plenty of time.*** Deep models involve
    more calculation for both training and evaluation.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您拥有充足的计算能力或充足的时间**。深度模型在训练和评估过程中都涉及更多的计算。'
- en: 'You should prefer traditional models with fewer parameters in the following
    cases:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下情况下，您应该更喜欢参数更少的传统模型：
- en: '***You have structured data.*** If your inputs look more like database records,
    you can often apply simple models directly.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您拥有结构化数据**。如果你的输入看起来更像是数据库记录，你通常可以直接应用简单模型。'
- en: '***You want a descriptive model.*** With simple models, you can look at the
    final learned function and examine how an individual input affects the output.
    This can give you insight about how the real-world system you’re studying works.
    In deep models, the connection between a specific piece of the input and the final
    output is long and winding; it’s difficult to interpret the model.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您需要一个描述性的模型**。对于简单的模型，您可以查看最终学习到的函数，并检查单个输入如何影响输出。这可以为您提供有关您正在研究的现实世界系统如何工作的见解。在深度模型中，输入的特定部分与最终输出之间的联系既长又曲折；很难解释模型。'
- en: Because *deep learning* refers to the type of model you use, you can apply deep
    learning to any of the major machine-learning branches. For example, you can do
    supervised learning with a deep model or a simple model, depending on the type
    of training data you have.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 因为**深度学习**指的是您使用的模型类型，所以您可以将深度学习应用于机器学习的任何主要分支。例如，您可以使用深度模型或简单模型进行监督学习，具体取决于您拥有的训练数据类型。
- en: 1.4\. What you’ll learn in this book
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4. 本书您将学到什么
- en: 'This book provides a practical introduction to deep learning and reinforcement
    learning. To get the most out of this book, you should be comfortable reading
    and writing Python code, and have some familiarity with linear algebra and calculus.
    In this book, we teach the following:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 本书提供了深度学习和强化学习的实用介绍。为了最大限度地利用本书，您应该能够舒适地阅读和编写Python代码，并对线性代数和微积分有所了解。在本书中，我们教授以下内容：
- en: How to design, train, and test neural networks by using the Keras deep-learning
    library
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用Keras深度学习库设计、训练和测试神经网络
- en: How to set up supervised deep-learning problems
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何设置监督式深度学习问题
- en: How to set up reinforcement-learning problems
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何设置强化学习问题
- en: How to integrate deep learning with a useful application
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将深度学习与有用的应用集成
- en: 'Throughout the book, we use a concrete and fun example: building an AI that
    plays Go. Our Go bot combines deep learning with standard computer algorithms.
    We’ll use straightforward Python to enforce the rules of the game, track the game
    state, and look ahead through possible game sequences. Deep learning will help
    the bot identify which moves are worth examining and evaluate who’s ahead during
    a game. At each stage, you can play against your bot and watch it improve as you
    apply more-sophisticated techniques.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们使用一个具体且有趣示例：构建一个玩围棋的AI。我们的围棋机器人结合了深度学习和标准的计算机算法。我们将使用简单的Python来执行游戏规则，跟踪游戏状态，并通过可能的游戏序列进行前瞻。深度学习将帮助机器人识别哪些移动值得检查，并在游戏中评估谁领先。在每一个阶段，你都可以与你的机器人对战，并观察它在应用更高级的技术时如何改进。
- en: If you’re interested in Go specifically, you can use the bot you’ll build in
    the book as a starting point for experimenting with your own ideas. You can adapt
    the same techniques to other games. You’ll also be able to add features powered
    by deep learning to other applications beyond games.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你特别对围棋感兴趣，你可以使用书中构建的机器人作为你实验自己想法的起点。你可以将相同的技巧应用到其他游戏中。你还将能够将深度学习驱动的功能添加到游戏以外的其他应用中。
- en: 1.5\. Summary
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5. 摘要
- en: Machine learning is a family of techniques for generating functions from data
    instead of writing them directly. You can use machine learning to solve problems
    that are too ambiguous to solve directly.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习是一系列从数据生成函数而不是直接编写函数的技术。您可以使用机器学习来解决直接解决过于模糊的问题。
- en: Machine learning generally involves first choosing a *model*—a generic family
    of mathematical functions. Next you *train* the model—apply an algorithm to find
    the best function in that family. Much of the art of machine learning lies in
    selecting the right model and transforming your particular data set to work with
    it.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习通常涉及首先选择一个**模型**——一个通用的数学函数族。接下来，您**训练**模型——应用算法来找到该族中最好的函数。机器学习的许多艺术在于选择正确的模型，并将您的特定数据集转换为与之兼容。
- en: Three of the major areas of machine learning are supervised learning, unsupervised
    learning, and reinforcement learning.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的三个主要领域是监督学习、无监督学习和强化学习。
- en: Supervised learning involves learning a function from examples you already know
    to be correct. When you have examples of human behavior or knowledge available,
    you can apply supervised learning to imitate them on a computer.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习涉及从你已经知道是正确的例子中学习一个函数。当你有可用的人类行为或知识示例时，你可以将监督学习应用于在计算机上模仿它们。
- en: Unsupervised learning involves extracting structure from data without knowing
    what the structure is in advance. A common application is splitting a data set
    into logical groups.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习涉及在没有事先知道结构的情况下从数据中提取结构。一个常见的应用是将数据集分成逻辑组。
- en: Reinforcement learning involves learning a function through trial and error.
    If you can write code to evaluate how well a program achieves a goal, you can
    apply reinforcement learning to incrementally improve a program over many trials.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习涉及通过试错来学习一个函数。如果你可以编写代码来评估程序实现目标的好坏，你就可以将强化学习应用于在多次尝试中逐步改进程序。
- en: Deep learning is machine learning with a particular type of model that performs
    well on unstructured inputs, such as images or written text. It’s one of the most
    exciting fields in computer science today; it’s constantly expanding our ideas
    about what computers can do.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习是一种机器学习，它使用一种在非结构化输入上表现良好的特定模型，例如图像或书面文本。它是当今计算机科学中最激动人心的领域之一；它不断扩展我们对计算机能做什么的想法。
- en: Chapter 2\. Go as a machine-learning problem
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二章\. 围棋作为机器学习问题
- en: '*This chapter covers*'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Why are games a good subject for AI?
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么游戏是人工智能的好主题？
- en: Why is Go a good problem for deep learning?
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么围棋是深度学习的好问题？
- en: What are the rules of Go?
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 围棋的规则是什么？
- en: What aspects of game playing can you solve with machine learning?
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以用机器学习解决哪些游戏方面的挑战？
- en: 2.1\. Why games?
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 为什么是游戏？
- en: Games are a favorite subject for AI research, and it’s not just because they’re
    fun. They also simplify some of the complexities of real life, so you can focus
    on the algorithms you’re studying.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏是人工智能研究的热门主题，不仅仅是因为它们很有趣。它们还简化了现实生活中的一些复杂性，这样你就可以专注于你正在研究的算法。
- en: 'Imagine you see a comment on Twitter or Facebook: something like, “Ugh, I forgot
    my umbrella.” You’d quickly conclude that your friend got caught out in the rain.
    But that information isn’t included anywhere in the sentence. How did you reach
    that conclusion? First, you applied common knowledge about what umbrellas are
    for. Second, you applied social knowledge about the kinds of comments people bother
    to make: it’d be strange to say, “I forgot my umbrella” on a bright, sunny day.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你在Twitter或Facebook上看到一条评论：比如，“哎呀，我忘记了我的雨伞。”你会很快得出结论，你的朋友被雨淋到了。但是，这个信息并没有在任何句子中提到。你是怎么得出这个结论的？首先，你应用了关于雨伞用途的常识。其次，你应用了关于人们会费心发表的评论的社会知识：在一个晴朗明媚的日子里说“我忘记了我的雨伞”会很奇怪。
- en: As humans, we effortlessly factor in all this context when reading a sentence.
    This isn’t so easy for computers. Modern deep-learning techniques are effective
    at processing the information you supply them. But you’re limited in your ability
    to find all the relevant information and feed it to computers. Games sidestep
    that problem. They take place in an artificial universe, where all the information
    you need in order to make a decision is spelled out in the rules.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 作为人类，我们在阅读句子时可以毫不费力地考虑到所有这些上下文。这对计算机来说并不那么容易。现代深度学习技术在处理你提供给它们的信息方面非常有效。但是，你在找到所有相关信息并将其提供给计算机的能力上有限。游戏规避了这个问题。它们发生在一个人工宇宙中，你做出决策所需的所有信息都明确地体现在规则中。
- en: Games are especially well suited for reinforcement learning. Recall that reinforcement
    learning requires repeatedly running your program and evaluating how well it has
    accomplished a task. Imagine you’re using reinforcement learning to train a robot
    to move around a building. Before the control system is finely tuned, you risk
    the robot falling down a flight of stairs or knocking over your furniture. Another
    option is to build a computer simulation of the environment in which the robot
    will operate. This eliminates the risks of letting an untrained robot run around
    in the real world but creates new problems. First, you have to invest in developing
    a detailed computer simulation, which is a significant project in its own right.
    Second, there’s always a chance that your simulation isn’t completely accurate.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏非常适合强化学习。回想一下，强化学习需要反复运行你的程序并评估它完成任务的优劣。想象一下，你正在使用强化学习来训练一个机器人绕着建筑物移动。在控制系统精细调整之前，机器人可能会从楼梯上摔下来或者撞倒你的家具。另一个选择是构建机器人将运行的模拟环境。这消除了让未经训练的机器人在现实世界中四处乱跑的风险，但同时也带来了新的问题。首先，你必须投资开发一个详细的计算机模拟，这本身就是一个重大的项目。其次，你的模拟可能并不完全准确。
- en: With games, on the other hand, all you need to do is have your AI play. If it
    loses a few hundred thousand matches while it’s learning, so what? In reinforcement
    learning, games are essential to serious research. Many cutting-edge algorithms
    were first demonstrated on Atari video games such as Breakout.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，使用游戏，你只需要让你的AI进行游戏。如果它在学习过程中输了几百万场，那又如何呢？在强化学习中，游戏对于严肃的研究至关重要。许多前沿算法最初都是在Atari视频游戏如《Breakout》上展示的。
- en: To be clear, you *can* successfully apply reinforcement learning to problems
    in the physical world. Many researchers and engineers have done so. But starting
    with games solves the problem of creating a realistic training environment and
    lets you focus on the mechanics and principles of reinforcement learning.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为了明确起见，你*可以*成功地将强化学习应用于物理世界中的问题。许多研究人员和工程师已经这样做了。但从游戏开始可以解决创建一个真实训练环境的问题，并让你专注于强化学习的机制和原理。
- en: In this chapter, we introduce the rules of the game of Go. Next, we describe
    the structure of board-game AI at a high level, and identify points where you
    can introduce deep learning. Finally, we cover how you can evaluate the progress
    of your game AI throughout development.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了围棋的规则。接下来，我们以高层次描述了棋盘游戏AI的结构，并确定了可以引入深度学习的地方。最后，我们介绍了如何评估你在开发过程中游戏AI的进展。
- en: 2.2\. A lightning introduction to the game of Go
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 围棋的闪电速成
- en: You don’t need to be a strong Go player to read this book, but you do need to
    understand the rules well enough to enforce them in a computer program. Fortunately,
    the rules are famously simple. In short, two players alternate placing black and
    white stones on a board, starting with the black player. The goal is to control
    as much of the board as possible with your own stones.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要是一位强大的围棋高手才能阅读这本书，但你确实需要足够了解规则，以便在计算机程序中执行它们。幸运的是，规则众所周知很简单。简而言之，两名玩家轮流在棋盘上放置黑白棋子，从黑方开始。目标是尽可能多地控制棋盘上的区域。
- en: Although the rules are simple, Go strategy has endless depth, and we don’t even
    attempt to cover it in this book. If you’re interested in learning more, we provide
    some resources at the end of this section.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然规则很简单，但围棋的策略却有着无尽的深度，我们甚至不试图在这本书中涵盖它。如果你对了解更多感兴趣，我们将在本节末尾提供一些资源。
- en: 2.2.1\. Understanding the board
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1\. 理解棋盘
- en: A Go board is a square grid, shown in [figure 2.1](#ch02fig01). Stones go on
    the intersections, not inside the squares. The standard board is 19 × 19, but
    sometimes players use a smaller board for a quick game. The most popular smaller
    options are 9 × 9 and 13 × 13 boards. (The size refers to the number of intersections
    on the board, not the number of squares.)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 围棋棋盘是一个正方形网格，如图2.1所示。棋子放在交点上，而不是方格内。标准棋盘是19×19，但有时玩家会使用更小的棋盘进行快速游戏。最受欢迎的小型选项是9×9和13×13棋盘。（大小指的是棋盘上的交点数，而不是方格数。）
- en: Figure 2.1\. A standard 19 × 19 Go board. The intersections marked with the
    dots are the star points, which are solely for players’ reference. Stones go on
    the intersections.
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.1\. 标准的19×19围棋棋盘。用点标记的交点是星点，仅供玩家参考。棋子放在交点上。
- en: '![](Images/02fig01_alt.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig01_alt.jpg)'
- en: Notice that nine points are marked with a dot. These points are called the *star
    points*. Their main purpose is to help players judge distances on the board; they
    have no effect on game play.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到有九个点被标记了一个点。这些点被称为*星位*。它们的主要目的是帮助玩家判断棋盘上的距离；它们对游戏没有影响。
- en: 2.2.2\. Placing and capturing stones
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2\. 放置和捕获棋子
- en: One player plays with black stones, and the other plays with white stones. The
    two players alternate placing stones on the board, starting with the black player.
    Stones don’t move after they’re on the board, although they can be captured and
    removed entirely. To capture your opponent’s stones, you must completely surround
    them with your own. Here’s how that works.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 一名玩家使用黑子，另一名玩家使用白子。两名玩家轮流在棋盘上放置棋子，先手是黑子玩家。棋子一旦放在棋盘上就不能移动，尽管它们可以被完全包围并移除。要捕获对手的棋子，你必须用你自己的棋子完全包围它们。下面是如何操作的。
- en: Stones of the same color that are touching are considered connected together,
    as shown in [figure 2.2](#ch02fig02). For the purposes of connection, we consider
    only straight up, down, left, or right; diagonals don’t count. Any empty point
    touching a connected group is called a *liberty* of that group. Every group needs
    at least one liberty to stay on the board. You can capture your opponent’s stones
    by filling their liberties.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 相邻的同色棋子被认为是连接在一起的，如[图2.2](#ch02fig02)所示。为了连接的目的，我们只考虑垂直、水平、左或右；对角线不计。任何接触连接组的空点被称为该组的*空位*。每个组至少需要一个空位才能留在棋盘上。你可以通过填充对手的空位来捕获对手的棋子。
- en: Figure 2.2\. The three black stones are connected. They have four liberties
    on the points marked with squares. White can capture the black stones by placing
    white stones on all the liberties.
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.2\. 三个黑子是相连的。它们在标有方形的点上共有四个空位。白子可以通过在所有空位上放置白子来捕获黑子。
- en: '![](Images/02fig02.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig02.jpg)'
- en: When you place a stone in the last liberty of an opponent’s group, that group
    is captured and removed from the board. The newly empty points are then available
    for either player to play on (so long as the move is legal). On the flip side,
    you may not play a stone that would have zero liberties, *unless you’re completing
    a capture*.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在对手的棋组最后一个空位放置棋子时，那个棋组就被捕获并从棋盘上移除。然后，新空出的点对任何玩家都是可用的（只要移动是合法的）。另一方面，你不能下棋子，使其没有空位，*除非你是在完成一次捕获*。
- en: 'An interesting consequence arises from the capturing rules. If a group of stones
    has two completely separate internal liberties, it can never be captured. See
    [figure 2.3](#ch02fig03): black can’t play at A, because that black stone would
    have no liberties and its placement wouldn’t complete a capture because of the
    remaining liberty at B. Nor can black play at B, for the same reason. So black
    has no way to fill the last two liberties of the white group. These internal liberties
    are called *eyes*. In contrast, black can play at C to capture five white stones,
    because even though that black stone would have no liberties, it completes the
    capture. That white group has only one eye and is doomed to get captured at some
    point.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 从捕获规则中产生了一个有趣的后果。如果一个棋组的两个内部空位完全分开，它永远无法被捕获。参见[图2.3](#ch02fig03)：黑子不能在A处下棋，因为那个黑子将没有任何空位，并且由于B处的剩余空位，它的放置不会完成捕获。同样，黑子也不能在B处下棋，原因相同。所以黑子没有填充白子组最后两个空位的方法。这些内部空位被称为*眼*。相比之下，黑子可以在C处下棋来捕获五个白子，因为尽管那个黑子将没有任何空位，但它完成了捕获。那个白子组只有一个眼，注定会在某个时候被捕获。
- en: 'Figure 2.3\. The white stones on the left can never be captured: black can
    play at neither A nor B. A black stone there would have no liberties, and is therefore
    an illegal play. On the other hand, black can play at C to capture five white
    stones.'
  id: totrans-155
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.3\. 左边的白子永远无法被捕获：黑子既不能在A处也不能在B处下棋。那里的黑子将没有任何空位，因此是不合法的走法。另一方面，黑子可以在C处下棋来捕获五个白子。
- en: '![](Images/02fig03.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig03.jpg)'
- en: Although it’s not explicitly part of the rules, the idea that a group with two
    eyes can’t be captured is the most basic part of Go strategy. In fact, this is
    the only strategy you’ll specifically code into your bot’s logic. All the more
    advanced Go strategies will be inferred through machine learning.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这并不是规则中明确的部分，但一个有双目的棋组无法被捕获的想法是围棋策略中最基本的部分。实际上，这是你唯一会具体编码到你的机器人逻辑中的策略。所有更高级的围棋策略都将通过机器学习推断出来。
- en: 2.2.3\. Ending the game and counting
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.3\. 结束游戏和计分
- en: 'Either player may pass any turn instead of placing a stone. When both players
    pass consecutive turns, the game is over. Before scoring, the players identify
    any dead stones: stones that have no chance of making two eyes or connecting up
    to friendly stones. Dead stones are treated exactly the same as captures when
    scoring the game. If a disagreement occurs, the players can resolve it by resuming
    play. But this is rare: if the status of any group is unclear, players usually
    try to resolve it before passing.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 任何一方都可以选择弃权，而不是下棋。当双方连续弃权时，游戏结束。在计分之前，玩家需要识别任何已死的棋子：那些没有机会形成两个眼或连接到友军棋子的棋子。计分时，已死的棋子与捕获的棋子处理方式相同。如果发生分歧，玩家可以通过继续游戏来解决。但这很少见：如果任何一组的状态不明确，玩家通常会在弃权之前尝试解决。
- en: The goal of the game is to control a larger section of the board than your opponent.
    There are two ways to add up the score, but they nearly always give the same result.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏的目的是控制比对手更大的棋盘区域。有两种计算分数的方法，但它们几乎总是给出相同的结果。
- en: The most common counting method is *territory scoring*. In this case, you get
    one point for every point on the board that’s completely surrounded by your own
    stones, plus one point for every opponent’s stone that you captured. The player
    with more points is the winner.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的计数方法是*地盘计分法*。在这种情况下，你得到棋盘上每个完全被你自己的棋子包围的点1分，以及每个你捕获的对手棋子1分。得分更高的玩家是赢家。
- en: 'An alternative counting method is *area scoring*. With area scoring, you get
    one point for every point of territory, plus another point for every stone you
    have on the board. Except in rare cases, you’ll get the same winner by either
    method: if neither player passes early, the difference in captures will equal
    the difference in stones on the board.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种计数方法是*面积计分法*。在面积计分法中，你得到每个地盘点1分，以及你在棋盘上的每个棋子1分。除非在罕见的情况下，你将通过任何一种方法得到相同的赢家：如果双方都没有提前弃权，捕获的差异将等于棋盘上棋子的差异。
- en: Territory scoring is more common in casual play, but it turns out that area
    scoring is slightly more convenient for computers. Throughout the book, our AI
    assumes it’s playing under area scoring, unless otherwise noted.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 地盘计分法在休闲游戏中更为常见，但结果表明，面积计分法对计算机来说稍微方便一些。在本书中，我们的AI假设它是在面积计分法下进行游戏，除非另有说明。
- en: In addition, the white player gets extra points as compensation for going second.
    This compensation is called *komi*. Komi is usually 6.5 points under territory
    scoring or 7.5 points under area scoring—the extra half point ensures there are
    no ties. We assume 7.5 points komi throughout the book.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，白方为了补偿后手而获得额外的分数。这种补偿称为*komi*。komi通常在地盘计分法下为6.5分，在面积计分法下为7.5分——额外的半分确保没有平局。本书中我们假设komi为7.5分。
- en: '[Figure 2.4](#ch02fig04) shows the final position of an example 9 × 9 game.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2.4](#ch02fig04)显示了示例9×9游戏的最终位置。'
- en: Figure 2.4\. The final positions of a 9 × 9 game. Dead stones are marked with
    an ×. Black territory is marked with a triangle. White territory is marked with
    a square.
  id: totrans-166
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.4。9×9游戏的最终位置。已死的棋子用×标记。黑方地盘用三角形标记。白方地盘用方框标记。
- en: '![](Images/02fig04.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig04.jpg)'
- en: 'Here’s how you score this game:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何计算这个游戏的分数：
- en: 'The stones marked with an X are considered dead: they count as captures, even
    though the players didn’t make the capture in the game. Black also made a capture
    earlier in the game (not shown). So black has 3 captures, and white has 2 captures.'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 被标记为X的棋子被认为是已死的：它们算作捕获，尽管玩家在游戏中没有进行捕获。黑方在游戏早期也进行了一次捕获（未显示）。因此，黑方有3个捕获，白方有2个捕获。
- en: 'Black has 12 points of territory: the 10 points marked with a triangle, plus
    the 2 points underneath the dead white stones.'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 黑方有12个地盘点：用三角形标记的10个点，加上死去的白子下面的2个点。
- en: 'White has 17 points of territory: the 15 points marked with a square, plus
    the 2 points underneath the dead black stones.'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 白方有17个地盘点：15个用方框标记的点，加上死去的黑子下面的2个点。
- en: Black has 27 stones on the board, after removing the dead black stones.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 黑方在棋盘上有27颗棋子，在移除已死去的黑子后。
- en: White has 25 stones on the board, after removing the dead white stones.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在移除已死去的白子后，白方在棋盘上有25颗棋子。
- en: By territory scoring, white has 17 points of territory + 2 captures + 6.5 komi
    for a total of 25.5 points. Black has 12 points of territory + 3 captures for
    a total of 15 points.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照地盘计分法，白方有17个地盘点 + 2个捕获 + 6.5个 komi，总共25.5个点。黑方有12个地盘点 + 3个捕获，总共15个点。
- en: By area scoring, white has 17 points of territory + 25 stones on the board +
    7.5 komi for a total of 49.5 points. Black has 12 points of territory + 27 stones
    on the board for a total of 39 points.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过面积计分法，白方有17个地盘点 + 棋盘上的25颗子 + 7.5个komi，总共49.5个点。黑方有12个地盘点 + 棋盘上的27颗子，总共39个点。
- en: By either counting method, white wins by 10.5 points.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无论是哪种计分方法，白方都以10.5个点的优势获胜。
- en: 'A game can end in one more way: either player can resign at any point. In a
    game between experienced players, it’s considered courteous to resign when you’re
    clearly behind. For our AI to be a good opponent, it should learn to detect when
    it should resign.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一款游戏还可以以另一种方式结束：任何一位玩家都可以在任何时候认输。在经验丰富的玩家之间进行的比赛中，当你明显处于劣势时认输被认为是一种礼貌的行为。为了让我们的AI成为一个好的对手，它应该学会在何时应该认输。
- en: 2.2.4\. Understanding ko
  id: totrans-178
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.4\. 理解“劫”
- en: One more restriction exists on where you can place stones. To ensure that the
    game ends, it’s illegal to play a move that will return the board to a previous
    state. [Figure 2.5](#ch02fig05) shows an example of how this can happen.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在放置棋子的位置上存在一个额外的限制。为了确保游戏结束，进行一个将棋盘恢复到之前状态的移动是不合法的。[图2.5](#ch02fig05)展示了这种情况可能发生的一个例子。
- en: Figure 2.5\. An illustration of the ko rule. First, black captures one white
    stone. White would like to capture back by playing at A, but that would revert
    the board to the previous position. The ko rule forbids such a play, in order
    to prevent an endless cycle of capture and recapture. White must play somewhere
    else on the board first. After that, the overall board position is new, so white
    can come back to capture at A later—assuming black doesn’t protect it first.
  id: totrans-180
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.5\. “劫”规则的示意图。首先，黑方吃掉了一颗白子。白方可能希望在A点反击以吃回黑子，但这样会将棋盘恢复到之前的位置。劫规则禁止这种玩法，以防止无休止的吃子和反吃的循环。白方必须先在棋盘的其他地方下棋。之后，整体棋盘位置就不同了，因此白方可以在稍后回到A点吃子——前提是黑方没有先保护它。
- en: '![](Images/02fig05.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig05.jpg)'
- en: In the diagram, black has just captured one stone. White might like to play
    at the point marked A to recapture the new black stone. But that would put the
    board back in the same position it was in two moves ago. Instead, white must play
    somewhere else on the board first. After that, if white captures at A, the global
    board position is different, so it’s legal. Of course, this gives black the opportunity
    to protect the vulnerable stone. In order to recapture the black stone, the white
    player must create a distraction big enough to draw black’s attention elsewhere
    on the board.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，黑方刚刚吃掉了一颗白子。白方可能希望在下标记为A的点进行反击，以重新吃回新生的黑子。但这样会将棋盘恢复到两步之前的同一位置。相反，白方必须先在棋盘的其他地方下棋。之后，如果白方在A点吃子，全局棋盘位置就不同了，因此这是合法的。当然，这给了黑方保护脆弱棋子的机会。为了重新吃回黑子，白方必须制造出足够大的干扰，以吸引黑方的注意力到棋盘的其他地方。
- en: This situation is called a *ko*, from the Japanese word for *eternity*. Players
    adopt special strategies when a ko is on the board, and this was a weak spot for
    previous generations of Go-playing programs. In [chapter 7](kindle_split_019.xhtml#ch07),
    we show how to give your neural networks a hint to help them learn ko tactics.
    This is a general technique for training neural networks effectively. Even when
    you can’t articulate the rules that you want the neural network to learn, you
    can encode your inputs in a way that emphasizes the situations you want it to
    pay attention to.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况被称为“劫”，源自日语中的“永恒”一词。当棋盘上有劫时，玩家会采取特殊的策略，这是前几代围棋程序的一个弱点。在[第7章](kindle_split_019.xhtml#ch07)中，我们展示了如何给你的神经网络提供提示，以帮助它们学习劫的战术。这是一种训练神经网络的有效通用技术。即使你不能明确表达你希望神经网络学习的规则，你也可以以强调你希望它关注的情况的方式来编码你的输入。
- en: 2.3\. Handicaps
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 让子
- en: When two players of unequal strength play, a simple system keeps the game interesting.
    The weaker player takes black and gets to place a few stones on the board before
    the game starts; these stones are called handicap stones. Then the stronger player
    takes white and makes the first move. In addition, in a handicap game, komi is
    usually reduced to just half a point. Normally, the purpose of komi is to negate
    the advantage a player gets from playing first; but the point of a handicap is
    to give black an extra advantage, so the two would work at cross purposes. The
    remaining half point of komi is just to break ties.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当两位实力不同的玩家对弈时，一个简单的系统可以让游戏保持趣味性。实力较弱的玩家执黑，并在游戏开始前在棋盘上放置几颗子；这些子被称为让子。然后实力较强的玩家执白，并做出第一手棋。此外，在让子棋中，
    komi 通常会减少到只有半点。通常， komi 的目的是抵消先手玩家获得的优势；但让子的目的是给黑方额外的优势，所以这两个目的相互矛盾。 komi 剩余的半点只是为了打破平局。
- en: It’s traditional to place the handicap stones on the star points, but some players
    allow the black player to choose where to put them.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统上，我们会在星位放置让子，但有些玩家允许黑方选择放置的位置。
- en: 2.4\. Where to learn more
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4\. 哪里可以了解更多
- en: 'Although we’ve covered the rules of the game, we haven’t even scratched the
    surface of what makes Go so engrossing and addictive. That’s beyond the scope
    of this book, but we encourage you to play a few games and learn more on your
    own. Here are a few resources for further exploration:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经介绍了游戏的规则，但我们甚至还没有触及到围棋如此吸引人和上瘾的原因。这超出了本书的范围，但我们鼓励你玩几局游戏，并自己学习更多。以下是一些进一步探索的资源：
- en: The best way to get into Go is to dive in and start playing, and it’s easier
    than ever to find a casual game online. The popular Online Go Server ([http://online-go.com](http://online-go.com))
    enables you to play directly in your web browser. Even if you just learned the
    rules, its ranking system will help you find a competitive game. Other popular
    Go servers include the KGS Go Server ([http://gokgs.com](http://gokgs.com)) and
    Tygem ([www.tygembaduk.com](http://www.tygembaduk.com)).
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最好的进入围棋的方式是直接跳进去开始玩，而且现在在网上找到休闲游戏比以往任何时候都要容易。流行的在线围棋服务器 ([http://online-go.com](http://online-go.com))
    允许你在网页浏览器中直接进行游戏。即使你刚刚学习了规则，它的排名系统也会帮助你找到一场竞争性的游戏。其他流行的围棋服务器包括 KGS 围棋服务器 ([http://gokgs.com](http://gokgs.com))
    和 Tygem ([www.tygembaduk.com](http://www.tygembaduk.com))。
- en: Sensei’s Library ([https://senseis.xmp.net](https://senseis.xmp.net)) is a wiki-style
    reference, full of strategy, tips, history, and trivia.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 感觉师图书馆 ([https://senseis.xmp.net](https://senseis.xmp.net)) 是一个维基风格的参考资料，充满了策略、技巧、历史和趣闻。
- en: 'Janice Kim’s *Learn to Play Go* series ranks among the best English-language
    Go books. We highly recommend volumes 1 and 2 for complete beginners: they’ll
    quickly get you to the point where you can make sense of a game.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Janice Kim 的 *Learn to Play Go* 系列被认为是最好的英语围棋书籍之一。我们强烈推荐第 1 卷和第 2 卷给初学者：它们能让你迅速达到能够理解游戏的地步。
- en: 2.5\. What can we teach a machine?
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5\. 我们能教会机器什么？
- en: Whether you’re programming a computer to play Go or tic-tac-toe, most board-game
    AIs share a similar overall structure. In this section, we provide a high-level
    overview of that structure, and identify specific problems the AI needs to solve.
    Depending on the game, the best solutions may involve game-specific logic, machine
    learning, or both.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是编写计算机程序来玩围棋还是井字棋，大多数棋类游戏的 AI 都具有相似的整体结构。在本节中，我们提供了一个高级概述，并确定了 AI 需要解决的具体问题。根据游戏的不同，最佳解决方案可能涉及游戏特定的逻辑、机器学习，或者两者兼而有之。
- en: 2.5.1\. Selecting moves in the opening
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.5.1\. 开局时的走法选择
- en: 'Early in the game, it’s difficult to evaluate a particular move because of
    the huge number of variations in the rest of the game. Both chess and Go AIs often
    use an opening book: a database of opening sequences taken from expert human games.
    To build this, you need a collection of game records from strong players. You
    analyze the game records, looking for common positions. In any common position,
    if a strong consensus exists about the next move—say, one or two moves account
    for 80% of the follow-ups—you add those moves to the opening book. The bot can
    then consult the book when playing a game. If any early game position appears
    in the opening book, the bot just looks up the expert move.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在游戏早期，由于剩余游戏中的巨大变化数量，很难评估特定的走法。象棋和围棋人工智能通常使用开局库：从专家人类游戏中提取的开局序列数据库。为了构建这个数据库，你需要一组强手的游戏记录。你分析游戏记录，寻找常见的位置。在任何常见位置，如果关于下一步的强共识存在——比如说，一两个走法占后续80%——你就将这些走法添加到开局库中。机器人可以在玩游戏时查阅这本书。如果任何早期游戏位置出现在开局库中，机器人只需查找专家走法。
- en: 'In chess and checkers, where pieces are removed from the board as the game
    progresses, AIs also contain similar endgame databases: when just a few pieces
    remain on the board, you can calculate all the variations in advance. This technique
    doesn’t apply to Go, where the board fills up toward the end.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在象棋和国际象棋中，随着游戏的进行，棋子从棋盘上移除，人工智能也包含类似的残局数据库：当棋盘上只剩下几个棋子时，你可以预先计算出所有变化。这种技术不适用于围棋，因为棋盘在游戏结束时填满。
- en: 2.5.2\. Searching game states
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.5.2. 搜索游戏状态
- en: The core idea behind board-game AI is tree search. Think about how humans play
    a strategy game. First, we consider a possible move for our next turn. Then we
    need to think of how our opponent is likely to respond, then plan how we’d respond
    to that, and so on. We read out the variation as far as we can, and then judge
    whether the result is good. Then we backtrack a bit and look at a different variation
    to see if it’s better.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 棋盘游戏人工智能背后的核心思想是树搜索。想想人类如何玩策略游戏。首先，我们考虑我们下一回合的可能走法。然后我们需要考虑对手可能如何回应，然后计划我们如何回应，依此类推。我们尽可能多地读出变化，然后判断结果是否好。然后我们稍微回溯一点，看看不同的变化是否更好。
- en: This closely describes how the tree-search algorithms used in game AI work.
    Of course, humans can keep only a few variations in their heads at once, while
    computers can juggle millions with no trouble. Humans make up for their lack of
    raw computing power with intuition. Experienced chess and Go players are scary
    good at spotting the handful of moves worth considering.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这紧密描述了在游戏人工智能中使用的树搜索算法的工作方式。当然，人类一次只能在大脑中保留几种变化，而计算机可以轻松地处理数百万种。人类用直觉来弥补他们原始计算能力的不足。经验丰富的象棋和围棋选手在发现值得考虑的少数走法方面非常出色。
- en: 'Ultimately, raw computing power won out in chess. But a Go AI that could compete
    with top human players took an interesting twist: bringing human intuition to
    computers.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，在象棋中，原始计算能力胜出。但能够与顶级人类选手竞争的围棋人工智能有一个有趣的转折：将人类的直觉引入计算机。
- en: 2.5.3\. Reducing the number of moves to consider
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.5.3. 减少需要考虑的走法数量
- en: In the context of game tree search, the number of possible moves on a given
    turn is the branching factor.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在游戏树搜索的背景下，给定回合的可能走法数量称为分支因子。
- en: In chess, the average branching factor is about 30\. At the start of the game,
    each player has 20 legal options for the first move; the number increases a bit
    as the board opens up. At that scale, it’s realistic to read out every single
    possible move to four or five moves ahead, and a chess engine will read out the
    more promising lines much deeper than that.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在国际象棋中，平均分支因子大约是30。游戏开始时，每位玩家在第一步有20种合法的选择；随着棋盘的展开，这个数字会略有增加。在这个规模上，现实的做法是读出每一个可能的走法，直到四到五步，而象棋引擎会深入读取更有希望的线路。
- en: By comparison, the branching factor in Go is enormous. On the first move of
    the game, there are 361 legal moves, and the number decreases slowly. The average
    branching factor is around 250 valid moves per turn. Looking ahead just four moves
    requires evaluating nearly 4 billion positions. It’s crucial to narrow down the
    number of possibilities. [Table 2.1](#ch02table01) shows how the branching factor
    affects the number of possible game positions by comparing chess to Go.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，围棋的分支因子巨大。在游戏的第一步，有361种合法的走法，这个数字缓慢减少。平均分支因子大约是每回合250种有效走法。仅仅展望四步就需要评估近40亿个位置。缩小可能性数量至关重要。[表2.1](#ch02table01)通过比较象棋和围棋，展示了分支因子如何影响可能的棋局位置数量。
- en: Table 2.1\. Approximate number of possible board states in games
  id: totrans-205
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表2.1. 游戏中可能的棋盘状态的大致数量
- en: '|   | Branching factor 30 (chess) | Branching factor 250 (Go) |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|   | 分支因子 30（象棋） | 分支因子 250（围棋） |'
- en: '| --- | --- | --- |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| After two moves | 900 | 62,500 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 经过两步棋 | 900 | 62500 |'
- en: '| After three moves | 27,000 | 15 million |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 经过三步棋 | 27000 | 1500万 |'
- en: '| After four moves | 810,000 | 4 billion |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 经过四步棋 | 81万 | 40亿 |'
- en: '| After five moves | 24 million | 1 trillion |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 经过五步棋 | 2400万 | 10万亿 |'
- en: 'In Go, rules-based approaches to move selection turn out to be mediocre at
    this task: it’s extremely difficult to write out rules that reliably identify
    the most important area of the board. But deep learning is perfectly suited to
    the problem. You can apply supervised learning to train a computer to imitate
    a human Go player.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在围棋中，基于规则的移动选择方法在此任务中表现平庸：编写出可靠识别棋盘上最重要区域的规则极为困难。但深度学习非常适合解决这个问题。你可以应用监督学习来训练计算机模仿人类围棋选手。
- en: 'You start with a large collection of game records between strong human players;
    online gaming servers are a great resource here. Then you replay all the games
    on a computer, extracting each board position and the following move. That’s your
    training set. With a suitably deep neural network, it’s possible to predict the
    human move with better than 50% accuracy. You can build a bot that just plays
    the predicted human move, and it’s already a credible opponent. But the real power
    comes when you combine these move predictions with tree search: the predicted
    moves give you a ranked list of branches to explore.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 你从一个强大的人类选手之间的游戏记录的大集合开始；在线游戏服务器在这里是一个很好的资源。然后你在计算机上重放所有游戏，提取每个棋盘位置和随后的移动。这就是你的训练集。使用一个足够深的神经网络，你可以以超过50%的准确率预测人类的移动。你可以构建一个只玩预测的人类移动的机器人，它已经是一个可信的对手。但真正的力量来自于当你将这些移动预测与树搜索相结合时：预测的移动为你提供了一个要探索的分支的排名列表。
- en: 2.5.4\. Evaluating game states
  id: totrans-214
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.5.4. 评估游戏状态
- en: 'The branching factor limits how far an AI can look ahead. If you could read
    out a hypothetical sequence all the way to the end of the game, you’d know who’d
    win; it’s easy to decide whether that’s a good sequence. But that’s not practical
    in any game more complex than tic-tac-toe: the number of possible variations is
    just too large. At some point, you have to stop and pick one of the incomplete
    sequences you’ve looked at. To do so, you take the final board position you’ve
    read out and assign it a numerical score. Of all the variations you analyzed,
    you select the move that leads to the best-scoring position. Figuring out how
    to compute that score is the tricky part: that’s the problem of position evaluation.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 分支因子限制了人工智能可以展望多远。如果你能读出一个假设的序列直到游戏结束，你就会知道谁会赢；判断那是否是一个好序列很容易。但在任何比井字游戏更复杂的游戏中，这都是不切实际的：可能的变体数量太多。在某个时候，你必须停下来并选择你查看的不完整序列中的一个。为此，你将读取的最终棋盘位置分配一个数值分数。在所有你分析的变体中，你选择导致得分最高的移动。弄清楚如何计算这个分数是棘手的部分：这就是位置评估的问题。
- en: 'In chess AIs, position evaluation is based on logic that makes sense to chess
    players. You can start with simple rules like this: if you capture my pawn, and
    I capture your rook, that’s good for me. Top chess engines go far beyond that,
    factoring sophisticated rules about where on the board the pieces ended up and
    what other pieces are blocking their movement.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在象棋人工智能中，位置评估基于对棋手有意义的逻辑。你可以从像这样的简单规则开始：如果你抓住我的兵，而我抓住你的车，那对我有好处。顶级象棋引擎远远超出了这一点，考虑了关于棋子最终落在棋盘上的位置以及哪些棋子阻碍了它们的移动的复杂规则。
- en: 'In Go, position evaluation may be even more difficult than move selection.
    The goal of the game is to cover more territory, but it’s surprisingly difficult
    to count territory: the boundaries tend to remain vague until late in the game.
    Counting captures doesn’t help much either; sometimes you can make it all the
    way to the end of a game with only a couple of captures. This is another area
    where human intuition reigns supreme.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在围棋中，位置评估可能比移动选择更困难。游戏的目标是占领更多领地，但计算领地却出奇地困难：边界往往在游戏后期才变得模糊。计算捕获的棋子也没有太大帮助；有时你只需捕获几枚棋子就能玩到游戏结束。这是另一个人类直觉至高无上的领域。
- en: Deep learning was a major breakthrough here as well. The kinds of neural networks
    that are suitable for move selection can also be trained to evaluate board positions.
    Instead of training a neural network to predict what the next move will be, you
    train it to predict who will win. You can design the network so it expresses its
    prediction as a probability; that gives you a numeric score to evaluate the board
    position.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在这里也是一个重大的突破。适合用于走棋选择的神经网络也可以训练来评估棋盘位置。你不需要训练一个神经网络来预测下一步棋会是什么，而是训练它来预测谁会获胜。你可以设计这个网络，使其以概率的形式表达其预测；这为你提供了一个数值分数来评估棋盘位置。
- en: 2.6\. How to measure your Go AI’s strength
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.6\. 如何衡量你的Go AI的强度
- en: As you work on your Go AI, you’ll naturally want to know how strong it is. Most
    Go players are familiar with the traditional Japanese ranking system, so you want
    to measure your bot’s strength on that scale. The only way to calibrate its level
    is by playing against other opponents; you can use other AIs or human players
    for that purpose.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在开发你的围棋AI时，你自然会想知道它的强度如何。大多数围棋选手都熟悉传统的日本排名系统，因此你希望在这个尺度上衡量你的机器人的强度。唯一校准其水平的方法是通过与其他对手对弈；你可以使用其他AI或人类玩家来达到这个目的。
- en: 2.6.1\. Traditional Go ranks
  id: totrans-221
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.6.1\. 传统的围棋段位
- en: 'Go players generally use the traditional Japanese system, where players are
    given kyu (beginner) or dan (expert) ranks. The dan levels, in turn, are divided
    into amateur dan and professional dan. The strongest kyu rating is 1 kyu, and
    larger numbers are weaker. Dan ranks go in the opposite direction: 1 dan is one
    level stronger than 1 kyu, and larger dan ranks are stronger. For amateur players,
    the scale traditionally tops out at 7 dan. Amateur players can get a rating from
    their regional Go association, and online servers will also track a rating for
    their players. [Table 2.2](#ch02table02) shows how the ranks stack up.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 围棋选手通常使用传统的日本段位系统，其中选手被授予初段（初学者）或段位（专家）等级。段位级别反过来又分为业余段位和专业段位。最强的初段评级是1段，数字越大表示段位越低。段位等级是相反的方向：1段比1初段高一个级别，段位数字越大表示段位越高。对于业余选手，传统上段位最高到7段。业余选手可以从他们所在的围棋协会获得评级，在线服务器也会跟踪他们的评级。[表2.2](#ch02table02)显示了这些段位的排列。
- en: Table 2.2\. Traditional Go ranks
  id: totrans-223
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表2.2\. 传统的围棋段位
- en: '| 25 kyu | Complete beginners who have just learned the rules |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 25初段 | 完全的初学者，刚刚学习规则 |'
- en: '| 20 kyu to 11 kyu | Beginners |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 20初段到11初段 | 初学者 |'
- en: '| 10 kyu to 1 kyu | Intermediate players |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 10初段到1初段 | 中级选手 |'
- en: '| 1 dan and up | Strong amateur players |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 1段及以上 | 强大的业余选手 |'
- en: '| 7 dan | Top amateur players, close to professional strength |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 7段 | 最高业余选手，接近专业水平 |'
- en: '| Professional 1 dan to professional 9 dan | World’s strongest players |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 专业1段到专业9段 | 世界上最强的选手 |'
- en: Amateur ranks are based on the number of handicap stones required to make up
    the difference in strength between two players. For example, if Alice is 2 kyu
    and Bob is 5 kyu, Alice will usually give Bob three handicap stones so that they
    have an equal chance of winning.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 业余段位是根据需要补足两名选手实力差距的手数来确定的。例如，如果Alice是2段，Bob是5段，Alice通常会给予Bob三颗让子，以便他们有平等的机会获胜。
- en: 'Professional ranks work a little differently: they’re more like titles. A regional
    Go association awards top players a professional rank based on results in major
    tournaments, and that rank is held for life. The amateur and professional scales
    aren’t directly comparable, but you can safely assume that any player with a professional
    rank is at least as strong as an amateur 7 dan player. The top pros are significantly
    stronger than that.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 专业段位的工作方式略有不同：它们更像是一种称号。地区围棋协会根据主要赛事的结果授予顶尖选手专业段位，并且这个段位终身保留。业余和专业段位不可直接比较，但你可以安全地假设任何拥有专业段位的选手至少与业余7段选手一样强大。顶尖职业选手比这要强得多。
- en: 2.6.2\. Benchmarking your Go AI
  id: totrans-232
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.6.2\. 对Go AI进行基准测试
- en: An easy way to estimate the strength of your own bots is to play against other
    bots of known strength. Open source Go engines such as GNU Go and Pachi provide
    good benchmarks. GNU Go plays at around a 5 kyu level, and Pachi is about 1 dan
    (Pachi’s level varies a bit depending on the amount of computing power you provide
    it). So if you have your bot play GNU Go 100 times, and it wins about 50 games,
    you can conclude that your bot is also somewhere in the neighborhood of 5 kyu.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 评估你自己的机器人强度的一个简单方法是与已知强度的其他机器人进行对弈。开源围棋引擎，如 GNU Go 和 Pachi，提供了良好的基准。GNU Go 的水平大约是
    5 段，而 Pachi 大约是 1 段（Pachi 的水平会因你提供的计算能力而略有不同）。所以如果你让你的机器人与 GNU Go 对弈 100 次，大约赢得
    50 场比赛，你可以得出结论，你的机器人也大约在 5 段的水平。
- en: To get a more precise rank, you can set up your AI to play on a public Go server
    with a rating system. A few dozen games should be enough to get a reasonable estimate.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更精确的排名，你可以设置你的 AI 在具有评分系统的公共围棋服务器上对弈。几局游戏应该足以得到一个合理的估计。
- en: 2.7\. Summary
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.7. 概述
- en: Games are a popular subject for AI research because they create controlled environments
    with known rules.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 游戏是人工智能研究的热门主题，因为它们创造了具有已知规则的控制环境。
- en: The strongest Go AIs today rely on machine learning rather than game-specific
    knowledge. In part because of the huge number of possible variations to consider,
    rule-based Go AIs were historically not strong.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强大的围棋 AI 依赖于机器学习而不是特定于游戏的规则。部分原因是因为需要考虑的可能的变体数量巨大，基于规则的围棋 AI 在历史上并不强大。
- en: Two places you can apply deep learning in Go are move selection and position
    evaluation.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在围棋中应用深度学习的两个地方是走棋选择和位置评估。
- en: Move selection is the problem of narrowing the set of moves you need to consider
    in a particular board position. Without good move selection, your Go AI will have
    too many branches to read.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 走棋选择是在特定棋盘位置中缩小需要考虑的走棋集的问题。没有良好的走棋选择，你的围棋 AI 将有太多的分支去阅读。
- en: Position evaluation is the problem of estimating which player is ahead and by
    how much. Without good position evaluation, your Go AI will have no ability to
    select a good variation.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 位置评估是估计哪个玩家领先以及领先多少的问题。没有良好的位置评估，你的围棋 AI 将无法选择一个好的变体。
- en: You can measure the strength of your AI by playing against widely available
    bots of known strength, such as GNU Go or Pachi.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过与广泛可用的、已知强度的机器人（如 GNU Go 或 Pachi）对弈来衡量你的人工智能的强度。
- en: Chapter 3\. Implementing your first Go bot
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 3 章. 实现你的第一个围棋机器人
- en: '*This chapter covers*'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Implementing a Go board by using Python
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 实现围棋盘
- en: Placing sequences of stones and simulating a game
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 放置石子序列并模拟游戏
- en: Encoding Go rules for this board to ensure legal moves are played
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为确保合法走棋而编码围棋规则
- en: Building a simple bot that can play against a copy of itself
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个简单的机器人，它可以与自己的副本对弈
- en: Playing a full game against your bot
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与你的机器人进行完整游戏
- en: In this chapter, you’ll build a flexible library that provides data structures
    to represent Go games and algorithms that enforce the Go rules. As you saw in
    the preceding chapter, the rules of Go are simple, but in order to implement them
    on a computer, you have to consider all the edge cases carefully. If you’re a
    novice to the game of Go or need a refresher of the rules, make sure you’ve read
    [chapter 2](kindle_split_013.xhtml#ch02). This chapter is technical and requires
    a good working knowledge of the Go rules to fully appreciate the details.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将构建一个灵活的库，它提供表示围棋游戏的数据结构和强制执行围棋规则算法。正如你在上一章中看到的，围棋的规则很简单，但为了在计算机上实现它们，你必须仔细考虑所有边缘情况。如果你是围棋的新手或需要复习规则，请确保你已经阅读了[第
    2 章](kindle_split_013.xhtml#ch02)。本章是技术性的，需要良好的围棋规则知识才能完全理解细节。
- en: Representing the Go rules is immensely important, because it’s the foundation
    for creating smart bots. Your bot needs to understand legal and illegal moves
    before you can teach it good and bad moves.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 表示围棋规则非常重要，因为它是创建智能机器人的基础。在你教它好和坏的动作之前，你的机器人需要理解合法和非法的动作。
- en: At the end of this chapter, you’ll have implemented your first Go bot. This
    bot is still weak but has all the knowledge about the game of Go it needs to evolve
    into much stronger versions in the following chapters.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，你将实现了你的第一个围棋机器人。这个机器人仍然很弱，但它拥有在接下来的章节中进化成更强大版本所需的关于围棋的所有知识。
- en: 'You’ll start by formally introducing the board and fundamental concepts used
    to play a game of Go with a computer: what is a player, a stone, or a move? Next,
    you’ll be concerned with game-play aspects. How can a computer quickly check which
    stones need to be captured or when the ko rule applies? When and how does a game
    come to an end? We’ll answer all these questions throughout this chapter.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 你将从正式介绍棋盘和用于在计算机上玩围棋的基本概念开始：什么是玩家，什么是棋子，什么是走法？接下来，你将关注游戏方面。计算机如何快速检查哪些棋子需要被捕获或何时适用ko规则？游戏何时以及如何结束？我们将在本章中回答所有这些问题。
- en: 3.1\. Representing a game of Go in Python
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1. 在Python中表示围棋游戏
- en: The game of Go is played on a square board. Usually, beginners start playing
    on a 9 × 9 or 13 × 13 board, and advanced and pro players play on a 19 × 19 board.
    But in principle, Go can be played on a board of any size. Implementing a square
    grid for the game is fairly simple, but you’ll need to take care of a lot of intricacies
    down the line.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 围棋是在一个方形棋盘上进行的。通常，初学者从9×9或13×13的棋盘开始，而高级和专业玩家则在19×19的棋盘上对弈。但原则上，围棋可以在任何大小的棋盘上玩。实现一个方形网格的游戏相对简单，但你需要注意很多细节。
- en: You represent a Go game in Python by building a module we’ll call *dlgo* step-by-step.
    Throughout the chapter, you’ll be asked to create files and implement classes
    and functions that will eventually lead to your first bot. All the code from this
    and later chapters can be found on GitHub at [http://mng.bz/gYPe](http://mng.bz/gYPe).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 你通过逐步构建一个名为*dlgo*的模块来在Python中表示围棋游戏。在整个章节中，你将被要求创建文件并实现类和函数，最终将导致你的第一个机器人的诞生。本章和后续章节的所有代码都可以在GitHub上找到，网址为[http://mng.bz/gYPe](http://mng.bz/gYPe)。
- en: Although you should definitely clone this repository for reference, we strongly
    encourage you to follow along by creating the files from scratch to see how the
    library builds up piece by piece. The master branch of our GitHub repository contains
    all the code used in this book (and more). From this chapter on, there’s additionally
    a specific Git branch for each chapter that has only the code you need for the
    given chapter. For instance, the code for this chapter can be found in branch
    chapter_3. The next chapters follow the same naming convention. Note that we’ve
    included extensive tests for most of the code found here and in later chapters
    in the GitHub repository.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你应该肯定地克隆这个仓库以供参考，但我们强烈建议你从头开始创建文件，以了解库是如何逐步构建的。我们的GitHub仓库的master分支包含本书中使用的所有代码（以及更多）。从本章开始，还有一个针对每个章节的特定Git分支，其中只包含给定章节所需的代码。例如，本章的代码可以在branch
    chapter_3中找到。下一章遵循相同的命名约定。请注意，我们在GitHub仓库中为这里和后续章节中的大多数代码都包含了广泛的测试。
- en: 'To build a Python library to represent Go, you need a data model that’s flexible
    enough to support a few use cases:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个表示围棋的Python库，你需要一个足够灵活的数据模型来支持几个用例：
- en: Track the progress of a game you’re playing against a human opponent.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪你与人类对手对弈的游戏进度。
- en: Track the progress of a game between two bots. This might seem to be exactly
    the same as the preceding point, but as it turns out, a few subtle differences
    exist. Most notably, naive bots have a hard time recognizing when the game is
    over. Playing two simple bots against each other is an important technique used
    in later chapters, so it’s worth calling out here.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪两个机器人之间的游戏进度。这看起来似乎与前面的点完全相同，但事实上，存在一些细微的差别。最值得注意的是，简单的机器人很难识别游戏何时结束。在后续章节中，将使用到两个简单机器人相互对弈的重要技术，所以这里值得提一下。
- en: Compare many prospective sequences from the same board position.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较同一棋盘位置下的许多潜在序列。
- en: Import game records and generate training data from them.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从游戏记录中导入并生成训练数据。
- en: We start with a few simple concepts, such as what a player or move is. These
    concepts lay the foundations for tackling all of the preceding tasks in later
    chapters.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一些简单概念开始，比如玩家或走法是什么。这些概念为解决后续章节中所有前面的任务奠定了基础。
- en: 'First, create a new folder, dlgo, and place an empty __init__.py file into
    it to initiate it as a Python module. Also, create two additional files called
    gotypes.py and goboard_slow.py in which you’ll put all board- and game-play functionality.
    Your folder structure at this point should look as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个新的文件夹，名为dlgo，并在其中放置一个空的__init__.py文件以将其初始化为Python模块。此外，创建两个额外的文件，分别命名为gotypes.py和goboard_slow.py，你将在其中放置所有棋盘和游戏功能。此时，你的文件夹结构应该如下所示：
- en: '[PRE3]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Black and white players take turns in Go, and you use `enum` to represent the
    different-colored stones. A `Player` is either `black` or `white`. After a player
    places a stone, you can switch the color by calling the `other` method on a `Player`
    instance. Put this `Player` class into gotypes.py.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在围棋中，黑白双方轮流走棋，您使用 `enum` 来表示不同颜色的棋子。`Player` 可以是 `black` 或 `white`。在玩家放置棋子后，您可以通过在
    `Player` 实例上调用 `other` 方法来切换颜色。将此 `Player` 类放入 `gotypes.py`。
- en: Listing 3.1\. Using an `enum` to represent players
  id: totrans-266
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.1\. 使用 `enum` 来表示玩家
- en: '[PRE4]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As noted in the front matter, we’re using Python 3 for this book. One of the
    reasons is that many modern aspects of the language, such as enums in gotypes.py,
    are part of the standard library in Python 3.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如前言所述，我们在这本书中使用 Python 3。其中一个原因是许多现代语言特性，如 `gotypes.py` 中的枚举，都是 Python 3 的标准库的一部分。
- en: Next, to represent coordinates on the board, tuples are an obvious choice. The
    following `Point` class also goes into gotypes.py.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了表示棋盘上的坐标，元组是一个明显的选择。以下 `Point` 类也放入 `gotypes.py`。
- en: Listing 3.2\. Using tuples to represent points of a Go board
  id: totrans-270
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.2\. 使用元组来表示围棋棋盘的点
- en: '[PRE5]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: A `namedtuple` lets you access the coordinates as `point.row` and `point.col`
    instead of `point[0]` and `point[1]`, which makes for much better readability.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '`namedtuple` 允许您通过 `point.row` 和 `point.col` 访问坐标，而不是 `point[0]` 和 `point[1]`，这使得可读性大大提高。'
- en: You also need a structure to represent the actions a player can take on a turn.
    Normally, a turn involves placing a stone on the board, but a player can also
    pass or resign at any time. Following American Go Association (AGA) conventions,
    we use the term *move* to mean any of those three actions, whereas a *play* refers
    to placing a stone. In the `Move` class, you therefore encode all three types
    of move (play, pass, resign) and make sure a move has precisely one of these types.
    For actual plays, you need to pass a `Point` to be placed. You add this `Move`
    class to the file goboard_slow.py.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要一个结构来表示玩家在回合中可以采取的行动。通常，一个回合涉及在棋盘上放置一个棋子，但玩家也可以在任何时候跳过或认输。遵循美国围棋协会（AGA）的惯例，我们使用术语
    *move* 来表示这三种行动中的任何一种，而 *play* 则指放置棋子。在 `Move` 类中，因此您编码了所有三种类型的移动（放置、跳过、认输），并确保移动恰好具有这些类型之一。对于实际的游戏，您需要传递一个要放置的
    `Point`。您将此 `Move` 类添加到文件 `goboard_slow.py` 中。
- en: 'Listing 3.3\. Setting moves: plays, passes, or resigns'
  id: totrans-274
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.3\. 设置移动：放置、跳过或认输
- en: '[PRE6]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '***1* Any action a player can play on a turn—is_play, is_pass, or is_resign—will
    be set.**'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 玩家在回合中可以采取的任何行动——是玩、跳过还是认输——都将被设置。**'
- en: '***2* This move places a stone on the board.**'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 这一步是在棋盘上放置一个棋子。**'
- en: '***3* This move passes.**'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 这一步跳过。**'
- en: '***4* This move resigns the current game.**'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 这一步将当前游戏认输。**'
- en: In what follows, clients generally won’t call the `Move` constructor directly.
    Instead, you usually call `Move.play`, `Move.pass_turn`, or `Move.resign` to construct
    an instance of a move.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的内容中，客户端通常不会直接调用 `Move` 构造函数。相反，您通常调用 `Move.play`、`Move.pass_turn` 或 `Move.resign`
    来构建一个移动实例。
- en: Note that so far, the `Player`, `Point`, and `Move` classes are all plain data
    types. Although they’re fundamental to representing the board, they don’t contain
    any game logic. This is done on purpose, and you’ll benefit from separating game-play
    concerns like this.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，到目前为止，`Player`、`Point` 和 `Move` 类都是纯数据类型。尽管它们对于表示棋盘是基本的，但它们不包含任何游戏逻辑。这是故意为之，您将从这个分离的游戏玩法关注点中受益。
- en: 'Next, you implement classes that can update the game state by using the preceding
    three classes:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您实现可以更新游戏状态的类，使用前面提到的三个类：
- en: The `Board` class is responsible for the logic of placing and capturing stones.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Board` 类负责放置和捕获棋子的逻辑。'
- en: The `GameState` class includes all the stones of the board, as well as tracking
    whose turn it is and what the previous state was.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GameState` 类包括棋盘上的所有棋子，以及跟踪轮到谁以及之前的状态。'
- en: 3.1.1\. Implementing the Go board
  id: totrans-285
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1\. 实现围棋棋盘
- en: 'Before turning to `GameState`, let’s first implement the `Board` class. Your
    first idea might be to create a 19 × 19 array tracking the state of each point
    in the board, and that’s a good starting point. Now, think about the algorithm
    for checking when you need to remove stones from the board. Recall that the number
    of liberties of a single stone is defined by the number of empty points in its
    direct neighborhood. If all four neighboring points are occupied by an enemy stone,
    the stone has no liberties left and is captured. For larger groups of connected
    stones, the situation is more difficult to check. For instance, after placing
    a black stone, you have to check all neighboring white stones to see whether black
    captured any stones that you have to remove. Specifically, you have to check the
    following:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在转向 `GameState` 之前，让我们首先实现 `Board` 类。你的第一个想法可能是创建一个 19 × 19 的数组来跟踪棋盘上每个点的状态，这是一个很好的起点。现在，考虑一下检查何时需要从棋盘上移除石子的算法。回想一下，单个石子的自由度由其直接邻域中的空点数定义。如果所有四个相邻点都被敌方石子占据，那么该石子就没有自由度了，会被捕获。对于更大的一组连接的石子，检查的情况会更复杂。例如，放置一个黑子后，你必须检查所有相邻的白子，看看黑子是否捕获了你必须移除的石子。具体来说，你必须检查以下内容：
- en: You see whether any neighbors have any liberties left.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你是否看到任何邻居还有自由度。
- en: You check whether any of the neighbors’ neighbors have any liberties left.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你检查邻居的邻居是否还有自由度。
- en: You examine the neighbors’ neighbors’ neighbors, and so forth.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你检查邻居的邻居的邻居，依此类推。
- en: This procedure could require hundreds of steps to finish. Imagine a long chain
    snaking through the opponent’s territory on a board with 200 moves played already.
    To speed this up, you can explicitly track all directly connected stones as a
    unit.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可能需要数百步才能完成。想象一下在一个已经下了 200 步棋的棋盘上，一条长链蜿蜒穿过对手的领地。为了加快这个过程，你可以明确地将所有直接连接的石子作为一个单元来跟踪。
- en: '3.1.2\. Tracking connected groups of stones in Go: strings'
  id: totrans-291
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2\. 跟踪围棋中连接的石子组：字符串
- en: You saw in the preceding section that viewing stones in isolation can lead to
    an increased computational complexity. Instead, you’ll keep track of groups of
    connected stones of the same color *and their liberties* at the same time. Doing
    so is much more efficient when implementing game logic.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，你看到孤立地看待石子会导致计算复杂度的增加。相反，你将同时跟踪相同颜色的连接石子组及其自由度。在实现游戏逻辑时这样做要高效得多。
- en: You call a group of connected stones of the same color a *string of stones*,
    or simply a *string*, as shown in [figure 3.1](#ch03fig01). You can build this
    structure efficiently with the Python `set` type as in the following `GoString`
    implementation, which you also put into goboard_slow.py.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 你将相同颜色的连接石子组称为 *石子字符串*，或简单地称为 *字符串*，如图 [3.1](#ch03fig01) 所示。你可以通过以下 `GoString`
    实现有效地构建这个结构，你也将它放入 goboard_slow.py 中。
- en: Listing 3.4\. Encoding strings of stones with `set`
  id: totrans-294
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.4\. 使用 `set` 对石子字符串进行编码
- en: '[PRE7]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '***1* Go strings are a chain of connected stones of the same color.**'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* Go 字符串是相同颜色的连接石子的链。**'
- en: '***2* Returns a new Go string containing all stones in both strings**'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 返回包含两个字符串中所有石子的新 Go 字符串**'
- en: Figure 3.1\. In this Go game, black has three strings of stones, and white has
    two. The large white string has six liberties, and the single white stone has
    only three.
  id: totrans-298
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.1\. 在这场围棋比赛中，黑子有三个石子组，白子有两个。大的白子组有六个自由度，而单个白子只有三个。
- en: '![](Images/03fig01.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/03fig01.jpg)'
- en: Note that `GoString` directly tracks its own liberties, and you can access the
    number of liberties at any point by calling `num_liberties`, which is much more
    efficient than the preceding naive approach starting from individual stones.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`GoString` 直接跟踪其自己的自由度，你可以通过调用 `num_liberties` 来访问任何点的自由度数，这比从单个石子开始的先前简单方法要高效得多。
- en: Also, you have the ability to add and remove liberties from the given string
    by using `remove_liberty` and `add_liberty`. Liberties of a string will usually
    decrease when opponents play next to this string, and increase when this or another
    group captures opposing stones adjacent to this string.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还有能力通过使用 `remove_liberty` 和 `add_liberty` 从给定的字符串中添加和移除自由度。当对手在这个字符串旁边下棋时，字符串的自由度通常会减少，而当这个或另一个组捕获与这个字符串相邻的对手石子时，自由度会增加。
- en: Furthermore, note the `merged_with` method of `GoString`, which is called when
    a player connects two of its groups by placing a stone.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，注意 `GoString` 的 `merged_with` 方法，当玩家通过放置一个石子连接两个组时会被调用。
- en: 3.1.3\. Placing and capturing stones on a Go board
  id: totrans-303
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.3\. 在 Go 棋盘上放置和捕获石头
- en: 'After having discussed stones and strings of stones, the natural next step
    is to discuss how to place stones on the board. Using the `GoString` class from
    [listing 3.4](#ch03ex04), the algorithm for placing a stone looks like this:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论了石头和石头字符串之后，自然的下一步是讨论如何在棋盘上放置石头。使用[列表 3.4](#ch03ex04)中的`GoString`类，放置石头的算法看起来是这样的：
- en: Merge any adjacent strings of the same color.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并任何相邻的同色字符串。
- en: Reduce liberties of any adjacent strings of the opposite color.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 减少相邻的异色字符串的自由度。
- en: If any opposite-color strings now have zero liberties, remove them.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果现在有任何异色字符串的自由度为零，则移除它们。
- en: Also, if the newly created string has zero liberties, you reject the move. This
    leads naturally to the following implementation of the Go `Board` class, which
    you also place at goboard_slow.py. You allow boards to have any number of rows
    or columns by instantiating them with `num_rows` and `num_cols` appropriately.
    To keep track of the board state internally, you use the private variable `_grid`,
    a dictionary you use to store strings of stones. First off, let’s initiate a Go
    board instance by specifying its size.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果新创建的字符串的自由度为零，则拒绝该移动。这自然导致以下 Go `Board` 类的实现，你也将它放在 goboard_slow.py 中。你可以通过使用适当的
    `num_rows` 和 `num_cols` 实例化来允许棋盘有任意数量的行或列。为了在内部跟踪棋盘状态，你使用私有变量 `_grid`，这是一个你用来存储石头字符串的字典。首先，让我们通过指定其大小来初始化一个
    Go 棋盘实例。
- en: Listing 3.5\. Creating a Go `Board` instance
  id: totrans-309
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.5\. 创建 Go `Board` 实例
- en: '[PRE8]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '***1* A board is initialized as an empty grid with the specified number of
    rows and columns.**'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 棋盘初始化为一个具有指定行数和列数的空网格。**'
- en: Next, we discuss the `Board` method to place stones. In `place_stone`, you first
    have to inspect all neighboring stones of a given point for liberties.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们讨论放置石头的`Board`方法。在`place_stone`中，你首先必须检查给定点的所有相邻石头以检查自由度。
- en: Listing 3.6\. Checking neighboring points for liberties
  id: totrans-313
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.6\. 检查相邻点以确定自由度
- en: '[PRE9]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '***1* First, you examine direct neighbors of this point.**'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 首先，你检查这个点的直接邻居。**'
- en: Note that the first two lines in [listing 3.6](#ch03ex06) use utility methods
    to check whether the point is within bounds for the given board and that the point
    hasn’t been played yet. These two methods are defined as follows.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，[列表 3.6](#ch03ex06)中的前两行使用实用方法来检查该点是否在给定棋盘的范围内，并且该点尚未被下棋。这两个方法定义如下。
- en: Listing 3.7\. Utility methods for placing and removing stones
  id: totrans-317
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.7\. 放置和移除石头的实用方法
- en: '[PRE10]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '***1* Returns the content of a point on the board: a Player if a stone is on
    that point, or else None**'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 返回棋盘上某点的内容：如果该点有石头，则返回玩家，否则返回 None**'
- en: '***2* Returns the entire string of stones at a point: a GoString if a stone
    is on that point, or else None**'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 返回某点的整个石头字符串：如果该点有石头，则返回 GoString，否则返回 None**'
- en: Note that you also define `get_go_string` to return the string of stones associated
    with a given point. This functionality can be helpful in general, but it’s particularly
    valuable to prevent *self-capture*, which we’ll discuss in more detail in [section
    3.2](#ch03lev1sec2).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你还定义了`get_go_string`来返回与给定点关联的石头字符串。这种功能在一般情况下可能很有用，但特别有价值的是可以防止*自我捕获*，我们将在[第
    3.2 节](#ch03lev1sec2)中更详细地讨论。
- en: Continuing with the definition of `place_stone` in [listing 3.6](#ch03ex06),
    right after defining `new_string`, you follow the outlined three-step approach
    shown next.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续[列表 3.6](#ch03ex06)中`place_stone`的定义之后，在定义`new_string`之后，你将遵循下面展示的概述的三步方法。
- en: Listing 3.8\. Continuing our definition of `place_stone`
  id: totrans-323
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.8\. 继续定义 `place_stone`
- en: '[PRE11]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '***1* Merge any adjacent strings of the same color.**'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 合并任何相邻的同色字符串。**'
- en: '***2* Reduce liberties of any adjacent strings of the opposite color.**'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 减少相邻的异色字符串的自由度。**'
- en: '***3* If any opposite-color strings now have zero liberties, remove them.**'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 如果现在有任何异色字符串的自由度为零，则移除它们。**'
- en: Now, the only thing missing in our definition of a Go board is how to remove
    a string of stones, as required in `remove_string` in the last line of [listing
    3.8](#ch03ex08). This is fairly simple, as shown in [listing 3.9](#ch03ex09),
    but you have to keep in mind that other stones might *gain* liberties when removing
    an enemy string. For instance, in [figure 3.2](#ch03fig02), you can see that black
    can capture a white stone, thereby gaining one additional liberty for each black
    string of stones.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们定义围棋棋盘时唯一缺少的是如何移除一行棋子，如[列表3.8](#ch03ex08)最后一行的`remove_string`所要求的。这相当简单，如[列表3.9](#ch03ex09)所示，但你必须记住，移除敌方棋子时，其他棋子可能会*获得*眼位。例如，在[图3.2](#ch03fig02)中，你可以看到黑子可以捕获一颗白子，从而为每个相邻的黑子棋子赢得一个额外的眼位。
- en: Listing 3.9\. Continuing our definition of `place_stone`
  id: totrans-329
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.9\. 继续我们`place_stone`的定义
- en: '[PRE12]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '***1* Removing a string can create liberties for other strings.**'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 移除一行棋子可以为其他棋子创造眼位。**'
- en: Figure 3.2\. Black can capture a white stone, thereby regaining a liberty for
    each of the Go strings adjacent to the captured stone.
  id: totrans-332
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.2\. 黑子可以捕获一颗白子，从而为捕获的棋子相邻的每个围棋棋子恢复一个眼位。
- en: '![](Images/03fig02_alt.jpg)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/03fig02_alt.jpg)'
- en: This definition concludes our `Board` implementation.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定义结束了我们的`Board`实现。
- en: 3.2\. Capturing game state and checking for illegal moves
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 捕获游戏状态和检查非法移动
- en: Now that you’ve implemented the rules for placing and capturing stones on a
    `Board`, let’s move on to playing games by capturing the current state of a game
    in a `GameState` class. Roughly speaking, *game state* knows about the board position,
    the next player, the previous game state, and the last move that has been played.
    What follows is just the beginning of the definition. You’ll add more functionality
    to `GameState` throughout this section. Again, you put this into goboard_slow.py.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经实现了在`Board`上放置和捕获棋子的规则，让我们继续通过在`GameState`类中捕获游戏当前状态来玩游戏。粗略地说，*游戏状态*了解棋盘位置、下一个玩家、上一个游戏状态以及最后一步所下的棋。以下只是定义的开始。你将在本节中添加更多功能到`GameState`。再次提醒，你将这段代码放入goboard_slow.py中。
- en: Listing 3.10\. Encoding game state for a game of Go
  id: totrans-337
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.10\. 编码围棋游戏状态
- en: '[PRE13]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '***1* Returns the new GameState after applying the move**'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 返回应用移动后的新`GameState`**'
- en: At this point, you can already decide when a game is over by adding the following
    code to your `GameState` class.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可以在`GameState`类中添加以下代码来决定游戏何时结束。
- en: Listing 3.11\. Deciding when a game of Go is over
  id: totrans-341
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.11\. 判断围棋游戏何时结束
- en: '[PRE14]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now that you’ve implemented how to apply a move to the current game state,
    using `apply_move`, you should also write code to identify which moves are legal.
    Humans may accidentally attempt an illegal move. Bots might attempt illegal moves
    because they don’t know any better. You need to check three rules:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经实现了如何使用`apply_move`将移动应用到当前游戏状态，你也应该编写代码来识别哪些移动是合法的。人类可能会意外尝试非法移动。机器人可能会尝试非法移动，因为它们不知道更好的方法。你需要检查三个规则：
- en: Confirm that the point you want to play is empty.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确认你想要下棋的点为空。
- en: Check that the move isn’t a self-capture.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查移动不是自我捕获。
- en: Confirm that the move doesn’t violate the ko rule.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确认移动没有违反禁入点规则。
- en: Although the first point is trivial to implement, the other two deserve separate
    treatment, because they’re rather tricky to handle properly.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然第一个点很容易实现，但其他两个值得单独处理，因为它们处理起来相当棘手。
- en: 3.2.1\. Self-capture
  id: totrans-348
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1\. 自我捕获
- en: When a string of your stones has only one liberty left and you play at the point
    that removes that liberty, we call that a *self-capture*. For instance, in [figure
    3.3](#ch03fig03), the black stones are doomed.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的一行棋子只剩下一个眼位，而你又在移除那个眼位的点上下棋时，我们称之为*自我捕获*。例如，在[图3.3](#ch03fig03)中，黑子注定要失败。
- en: Figure 3.3\. In this Go board state, the three black stones have one liberty
    left; namely, the marked point. You enforce the self-capture rule, so black isn’t
    allowed to play there. White, on the other hand, can capture the three black stones
    by playing on the marked point.
  id: totrans-350
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.3\. 在这个围棋棋盘状态下，三颗黑子只剩下一个眼位；即标记的点。你执行自我捕获规则，因此黑子不允许在那个点下棋。另一方面，白子可以通过在标记的点下棋来捕获三颗黑子。
- en: '![](Images/03fig03.jpg)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/03fig03.jpg)'
- en: White can capture them at any time by playing on the marked point, and black
    has no way to prevent it. But what if black played on the marked point? The entire
    group would have no liberties and would then be captured. Most rule sets forbid
    such a play, although a few exceptions exist. Most notably, self-capture is allowed
    in the quadrennial Ing Cup, which is one of the biggest prizes in international
    Go.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 白方可以在任何时间通过在标记点上落子来捕获它们，而黑方无法阻止。但如果黑方在标记点上落子呢？整个组合将没有眼位，然后就会被捕获。大多数规则集禁止这种玩法，尽管存在一些例外。最值得注意的是，在每四年一次的英皇杯（Ing
    Cup）中允许自杀，这是国际围棋中最大的奖项之一。
- en: You’ll enforce the self-capture rule in your code. This is consistent with the
    most popular rule sets, and it also reduces the number of moves your bots need
    to consider. It’s possible to contrive a position where self-capture is the best
    move, but such situations are basically unheard of in serious games.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在代码中执行自杀规则。这与最受欢迎的规则集一致，并且它还减少了你的机器人需要考虑的步数。虽然可以设计出自杀是最佳走法的局面，但在严肃的比赛中，这种情况基本上是闻所未闻的。
- en: If you alter the surrounding stones in [figure 3.3](#ch03fig03) slightly, you
    end up with a completely different situation, shown in [figure 3.4](#ch03fig04).
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你稍微改变[图3.3](#ch03fig03)周围的棋子，你将得到一个完全不同的局面，如[图3.4](#ch03fig04)所示。
- en: Figure 3.4\. In this situation, the marked point is a capture for black, not
    suicide, because black will capture two white stones and thereby regain two liberties.
  id: totrans-355
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.4。在这种情况下，标记点对黑方来说是一个捕获，而不是自杀，因为黑方将捕获两个白棋，从而重新获得两个眼位。
- en: '![](Images/03fig04.jpg)'
  id: totrans-356
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/03fig04.jpg)'
- en: Note that in [figure 3.4](#ch03fig04), and in general, you must remove opponent
    stones first before checking whether the newly played stone has any liberties.
    In all rule sets, this next move is a valid capture, not a self-capture, because
    black will regain two liberties by capturing the two white stones.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在[图3.4](#ch03fig04)中，以及一般情况下，你必须先移除对手的棋子，然后再检查新下放的棋子是否有任何眼位。在所有规则集中，这一步棋是一个有效的捕获，而不是自杀，因为黑方通过捕获两个白棋将重新获得两个眼位。
- en: Note that the `Board` class does permit self-capture, but in `GameState` you’ll
    enforce the rule by applying the move to a copy of the board and checking the
    number of liberties afterward.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`Board`类允许自杀，但在`GameState`中，你将通过将这一步棋应用到棋盘的副本上并在之后检查眼位数来执行这一规则。
- en: Listing 3.12\. Continuing our definition of `GameState` to enforce the self-capture
    rule
  id: totrans-359
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.12。继续定义`GameState`以执行自杀规则
- en: '[PRE15]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 3.2.2\. Ko
  id: totrans-361
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2. 提子
- en: Having checked for self-capture, you can now move on to implement the ko rule.
    [Chapter 2](kindle_split_013.xhtml#ch02) briefly covered ko and its importance
    in the game of Go. Roughly speaking, the ko rule applies if a move would return
    the board to the exact previous position. This doesn’t imply that a player can’t
    hit back immediately, as the following sequence of diagrams shows. In [figure
    3.5](#ch03fig05), white has just played the isolated stone on the bottom. Black’s
    two stones now have only a single liberty left—but so does this white stone.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查了自杀之后，你现在可以继续实现提子规则。[第2章](kindle_split_013.xhtml#ch02)简要介绍了提子规则及其在围棋游戏中的重要性。简而言之，如果一步棋会使棋盘回到精确的先前位置，则适用提子规则。这并不意味着玩家不能立即反击，以下图示序列显示了这一点。在[图3.5](#ch03fig05)中，白方刚刚在底部落下一颗孤子。现在黑方的两颗棋子只剩下一个眼位——但白方的这颗棋子也是如此。
- en: Figure 3.5\. White wants to capture the two black stones in this situation,
    but white’s stone has only one liberty left.
  id: totrans-363
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.5。在这种情况下，白方想要捕获两颗黑棋，但白方的棋子只剩下一个眼位。
- en: '![](Images/03fig05.jpg)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/03fig05.jpg)'
- en: Black can now try to save its two stones by capturing this white stone, as shown
    in [figure 3.6](#ch03fig06).
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 黑方现在可以尝试通过捕获这颗白棋来挽救其两颗棋子，如[图3.6](#ch03fig06)所示。
- en: Figure 3.6\. Continuing, black tries to rescue its two stones by capturing the
    isolated white stone.
  id: totrans-366
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.6。继续，黑方试图通过捕获孤立的这颗白棋来挽救其两颗棋子。
- en: '![](Images/03fig06.jpg)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/03fig06.jpg)'
- en: But white can immediately play at *the same point* that was played in [figure
    3.5](#ch03fig05), as shown in [figure 3.7](#ch03fig07).
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 但白方可以立即在[图3.5](#ch03fig05)中落子的相同点上落子，如[图3.7](#ch03fig07)所示。
- en: You can see that white can immediately recapture the three black stones, and
    the ko rule doesn’t apply, because the overall board positions in [figures 3.5](#ch03fig05)
    and [3.7](#ch03fig07) are different. This play is known as a *snapback*. In simple
    situations, the ko rule boils down to not being able to immediately recapture
    a stone. But snapbacks are common, and the existence of such positions shows that
    you have to be careful when implementing ko.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到白方可以立即夺回三个黑子，劫争规则不适用，因为图 3.5（#ch03fig05）和图 3.7（#ch03fig07）中的整体棋盘位置不同。这种玩法被称为*立即夺回*。在简单情况下，劫争规则归结为不能立即夺回一个棋子。但立即夺回是常见的，这种位置的存在表明在实现劫争时你必须小心。
- en: Figure 3.7\. In this situation, white can just snap back (retake the three black
    stones) without violating the ko rule.
  id: totrans-370
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.7\. 在这种情况下，白方可以简单地立即收回（夺回三个黑子）而不违反劫争规则。
- en: '![](Images/03fig07.jpg)'
  id: totrans-371
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/03fig07.jpg)'
- en: You can specify the ko rule in many ways, but those ways are practically equivalent
    except in rare situations. The rule you’ll enforce in your code is that a player
    may not play a stone that would re-create a previous game state, where the game
    state includes both the stones on the board and the player whose turn is next.
    This particular formulation is known as the *situational superko* rule.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过许多方式指定劫争规则，但这些方式在罕见情况下实际上等效。你将在代码中实施的规则是，玩家不得下出一个会重新创建先前游戏状态的棋子，其中游戏状态包括棋盘上的棋子和下一个回合的玩家。这种特定的表述被称为*情境超劫*规则。
- en: Because each `GameState` instance keeps a pointer to the previous state, you
    can enforce the ko rule by walking back up the tree and checking the new state
    against the whole history. You do so by adding the following method to your `GameState`
    implementation.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 因为每个 `GameState` 实例都保留了对上一个状态的指针，你可以通过向上遍历树并检查新状态与整个历史记录来实施劫争规则。你通过向你的 `GameState`
    实现添加以下方法来完成。
- en: Listing 3.13\. Does the current game state violate the ko rule?
  id: totrans-374
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.13\. 当前游戏状态是否违反了劫争规则？
- en: '[PRE16]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This implementation is simple and correct, but it’s relatively slow. For each
    move, you create a deep copy of the board state and have to compare this state
    against all previous states, which adds up over time. In [section 3.5](#ch03lev1sec5),
    you’ll encounter an interesting technique to speed up this step.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 这种实现简单且正确，但相对较慢。对于每个移动，你都会创建一个棋盘状态的深拷贝，并必须将此状态与所有先前状态进行比较，这会随着时间的推移而累积。在第 3.5
    节（#ch03lev1sec5）中，你将遇到一种有趣的技术来加快这一步骤。
- en: To wrap up your `GameState` definition, you can now decide whether a move is
    valid by using knowledge from [section 3.2](#ch03lev1sec2) about both ko and self-capture.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成你的 `GameState` 定义，你现在可以使用关于劫争和自我捕获的知识来决定一个移动是否有效。
- en: Listing 3.14\. Is this move valid for the given game state?
  id: totrans-378
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.14\. 在给定的游戏状态下，这个移动是否有效？
- en: '[PRE17]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 3.3\. Ending a game
  id: totrans-380
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 结束游戏
- en: A key concept in computer Go is *self-play*. In self-play, you usually start
    with a weak Go-playing agent, have it play against itself, and use the game results
    to build a stronger bot. In [chapter 4](kindle_split_016.xhtml#ch04), you’ll use
    self-play to evaluate board positions. In [chapters 9](kindle_split_021.xhtml#ch09)
    through [12](kindle_split_024.xhtml#ch12), you’ll use self-play to evaluate individual
    moves and the algorithms that selected them.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机围棋中，一个关键概念是*自我对弈*。在自我对弈中，你通常从一个弱的围棋代理开始，让它与自己对弈，并使用游戏结果来构建一个更强的机器人。在第 4
    章（kindle_split_016.xhtml#ch04）中，你将使用自我对弈来评估棋盘位置。在第 9 章（kindle_split_021.xhtml#ch09）到第
    12 章（kindle_split_024.xhtml#ch12）中，你将使用自我对弈来评估单个移动及其选择的算法。
- en: To take advantage of this technique, you need to make sure your self-play games
    end. Human games end when neither player can gain an advantage with their next
    move. This is a tricky concept even for humans. Beginners often end games by playing
    hopeless moves in the opponent’s territory, or watching their opponent cut into
    what they believed to be solid territory. For computers, it’s even more difficult.
    If our bot continues playing as long as legal moves remain available, it’ll eventually
    fill up its own liberties and lose all of its stones.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 为了利用这项技术，你需要确保你的自我对弈游戏结束。人类游戏在双方都无法通过下一步移动获得优势时结束。即使对于人类来说，这也是一个棘手的概念。初学者经常通过在对手领土上玩无望的移动或观察对手切入他们认为稳固的领土来结束游戏。对于计算机来说，这更加困难。如果我们的机器人只要还有合法的移动就继续玩，它最终会填满自己的领地并失去所有的棋子。
- en: 'You could think up some heuristics to help the bot finish the game in a sensible
    manner. For example:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想出一些启发式方法来帮助机器人以合理的方式结束游戏。例如：
- en: Don’t play in a region that’s completely surrounded by stones of the same color.
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要在一个完全被同色棋子包围的区域下棋。
- en: Don’t play a stone that would have only one liberty.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要下只有一个眼位的棋子。
- en: Always capture an opposing stone with only one liberty.
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总是用只有一个眼位的情况下吃掉对方的棋子。
- en: Unfortunately, *all of those rules are too strict*. If our bots followed these
    rules, strong opponents would take advantage to kill groups that should live,
    rescue groups that should die, or simply gain a better position. Generally, our
    handcrafted rules should restrict the bot’s options as little as possible, so
    that more sophisticated algorithms are free to learn the advanced tactics.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，*所有这些规则都过于严格*。如果我们的机器人遵循这些规则，强大的对手会利用这些规则杀死应该活着的组，拯救应该死亡的组，或者简单地获得更好的位置。一般来说，我们手工编写的规则应该尽可能限制机器人的选项，以便更复杂的算法可以自由学习高级策略。
- en: To solve this problem, you can look to the history of the game. In ancient times,
    the winner was simply the player with the most stones on the board. Players would
    end the game by filling every point they could, leaving only eyes for their groups
    empty. This could make the end of a game drag out for a long time, so players
    came up with a way to speed it up. If black clearly controlled a region of the
    board (any white stone played there would eventually get captured), there was
    no need for black to fill that region with stones. The players would just agree
    to count that area for black. This is where the concept of territory came from,
    and over centuries the rules evolved so that territory was counted explicitly.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 要解决这个问题，您可以参考游戏的悠久历史。在古代，胜利者仅仅是棋盘上棋子最多的玩家。玩家们会通过填满他们能填的点来结束游戏，只留下他们组的眼位为空。这可能会使游戏的结束拖得很长，因此玩家们想出了一个加快游戏速度的方法。如果黑方明显控制了棋盘上的某个区域（任何白方在那里放的棋子最终都会被吃掉），那么黑方就没有必要用棋子填满那个区域。玩家们只需同意为黑方计算那个区域。这就是领地概念的产生，几个世纪以来，规则逐渐演变，以至于领地被明确计算。
- en: Scoring in this method avoids the question of what is territory and what isn’t,
    but you still have to prevent your bot from killing its own stones; see [figure
    3.8](#ch03fig08).
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法计分避免了关于什么是领地，什么不是领地的问题，但您仍然需要防止您的机器人杀死自己的棋子；参见[图3.8](#ch03fig08)。
- en: Figure 3.8\. White has two eyes in the corner, at A and B, and shouldn’t place
    a stone at either point. Otherwise, black can capture the whole group. Your naive
    bot won’t be allowed to fill its own eye.
  id: totrans-390
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.8\. 白方在角落A和B有两个眼位，不应在这两个点放置棋子。否则，黑方可以吃掉整个组。您的天真机器人将不允许填充自己的眼位。
- en: '![](Images/03fig08.jpg)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/03fig08.jpg)'
- en: You’ll hardcode a rule that prevents the bot from filling in its own eyes, under
    the strictest possible definition. For our purposes, an *eye* is an empty point
    where all adjacent points and at least three out of four diagonally adjacent points
    are filled with friendly stones.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 您将硬编码一个规则，以防止机器人按照最严格的定义填充自己的眼位。就我们的目的而言，一个*眼位*是一个空点，其中所有相邻的点以及至少三个四对角相邻的点都填满了友军棋子。
- en: '|  |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-394
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: Experienced Go players may notice that the preceding definition of *eye* will
    miss a valid eye in some cases. We’ll accept those errors to keep the implementation
    simple.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 经验丰富的围棋玩家可能会注意到，前面关于*眼位*的定义在某些情况下会错过一个有效的眼位。我们将接受这些错误以保持实现简单。
- en: '|  |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: You have to create a special case for eyes on the edge of the board; in that
    case, all the diagonally adjacent points must contain friendly stones.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须为棋盘边缘的眼睛创建一个特殊情况；在这种情况下，所有对角相邻的点都必须包含友军棋子。
- en: You create a new submodule of dlgo called *agent* (by creating a new folder
    named *agent* and an empty __init__.py file within that folder) and place the
    following `is_point_an_eye` function into a file called helpers.py.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 您创建一个名为*agent*的新dlgo子模块（通过创建一个名为*agent*的新文件夹，并在该文件夹内创建一个空的__init__.py文件）并将以下`is_point_an_eye`函数放入一个名为helpers.py的文件中。
- en: Listing 3.15\. Is the given point on the board an eye?
  id: totrans-399
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.15\. 给定的点是否是眼位？
- en: '[PRE18]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '***1* An eye is an empty point.**'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 眼位是一个空点。**'
- en: '***2* All adjacent points must contain friendly stones.**'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 所有相邻的点都必须包含友军棋子。**'
- en: '***3* We must control three out of four corners if the point is in the middle
    of the board; on the edge, you must control all corners.**'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 如果点位于棋盘中间，我们必须控制四个角落中的三个；在边缘，你必须控制所有角落。**'
- en: '***4* Point is on the edge or corner.**'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 点位于边缘或角落。**'
- en: '***5* Point is in the middle.**'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 点位于中间。**'
- en: You aren’t explicitly concerned with determining the result of a game yet in
    this chapter, but counting points at the end of a game is definitely an important
    topic. Different tournaments and Go federations enforce slightly different rule
    sets. Throughout the book, you’ll have your bots follow the AGA rules for *area
    counting*, also known as *Chinese counting*. Although *Japanese rules* are more
    popular in casual play, the AGA rules are a little easier for computers, and the
    rule differences rarely affect the outcome of a game.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你还没有明确关注确定游戏结果，但计算游戏结束时的分数绝对是一个重要的话题。不同的锦标赛和围棋联合会执行略有不同的规则集。在整个书中，你的机器人将遵循AGA的*面积计数*规则，也称为*中国计数*。尽管*日本规则*在休闲游戏中更为流行，但AGA规则对计算机来说更容易一些，规则差异很少影响游戏结果。
- en: '3.4\. Creating your first bot: the weakest Go AI imaginable'
  id: totrans-407
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4\. 创建你的第一个机器人：想象中最弱的围棋AI
- en: Having finished the implementation of the Go board and encoded game state, you
    can build your first Go-playing bot. This bot will be a weak player, but it’ll
    lay the foundation for all of your improved bots to come. First, you define the
    interface that all of your bots will follow. You put the definition of an agent
    into base.py in the agent module.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 完成了围棋盘的实现和游戏状态的编码后，你可以构建你的第一个围棋机器人。这个机器人将是一个弱手，但它将为所有后续改进的机器人打下基础。首先，你定义所有机器人将遵循的接口。你将代理的定义放入agent模块中的base.py文件中。
- en: Listing 3.16\. Your central interface for Go agents
  id: totrans-409
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.16\. 围棋代理的中心接口
- en: '[PRE19]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: That’s it, just this one method. All a bot does is select a move given the current
    game state. Of course, internally this may require other complex tasks such as
    evaluating the current position, but to play a game, that’s all our bot will ever
    need.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 就这么简单，只有一个方法。机器人所做的只是根据当前游戏状态选择一个移动。当然，在内部这可能需要其他复杂的任务，例如评估当前位置，但为了玩游戏，我们的机器人永远只需要这些。
- en: 'Our first implementation will be as naive as possible: it’ll randomly select
    any valid move that doesn’t fill in one of its own eyes. If no such move exists,
    it’ll pass. You place this random bot into naive.py under agents. Recall from
    [chapter 2](kindle_split_013.xhtml#ch02) that student ranks in Go usually range
    from 30 kyu to 1 kyu. By that scale, your random bot plays at the 30 kyu level,
    an absolute beginner.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一种实现将尽可能简单：它将随机选择任何有效的移动，但不会填充自己的一个眼位。如果没有这样的移动，它将放弃。你将这个随机机器人放入agents目录下的naive.py文件中。回想一下[第2章](kindle_split_013.xhtml#ch02)，围棋的学生段位通常从30段位到1段位不等。按照这个标准，你的随机机器人处于30段位水平，这是一个绝对的初学者。
- en: Listing 3.17\. A random Go bot, playing at about 30 kyu strength
  id: totrans-413
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.17\. 一个随机围棋机器人，大约30段位水平
- en: '[PRE20]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'At this point, your module structure should look as follows (make sure to place
    an empty __init__.py in the folder to initialize the submodule):'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你的模块结构应该如下所示（确保在文件夹中放置一个空的__init__.py文件以初始化子模块）：
- en: '[PRE21]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Finally, you can set up a driver program that plays a full game between two
    instances of your random bot. First, you define convenient helper functions, such
    as printing the full board or an individual move on the console.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以设置一个驱动程序，让两个随机机器人实例之间进行完整游戏。首先，你定义方便的辅助函数，例如在控制台上打印整个棋盘或单个移动。
- en: Go board coordinates can be specified in many ways, but in Europe it’s most
    common to label the columns with letters of the alphabet, starting with A, and
    the rows with increasing numbers, starting at 1\. In these coordinates, on a standard
    19 × 19 board, the lower-left corner would be A1, and the top-right corner T19\.
    Note that by convention the letter I is omitted to avoid confusion with 1.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 围棋盘坐标可以用多种方式指定，但在欧洲，最常见的是用字母表中的字母标记列，从A开始，行用递增的数字标记，从1开始。在这些坐标中，在一个标准的19×19棋盘上，左下角是A1，右上角是T19。请注意，按照惯例省略了字母I，以避免与数字1混淆。
- en: You define a string variable `COLS = 'ABCDEFGHJKLMNOPQRST'`, whose characters
    stand for the columns of the Go board. To display the board on the command line,
    you encode an empty field with a point (`.`), a black stone with an `x`, and a
    white one with an `o`. The following code goes into a new file we call utils.py
    in the dlgo package. You create a `print_move` function that prints the next move
    to the command line, and a `print_board` function that prints the current board
    with all its stones. You put this code in a file called bot_v_bot.py outside the
    dlgo module.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 你定义了一个字符串变量 `COLS = 'ABCDEFGHJKLMNOPQRST'`，其中的字符代表围棋棋盘的列。为了在命令行上显示棋盘，你用一个点(`.`)表示空场，用`x`表示黑子，用`o`表示白子。以下代码放入我们称为
    utils.py 的新文件中，在 dlgo 包中。你创建了一个 `print_move` 函数，用于将下一个移动打印到命令行，以及一个 `print_board`
    函数，用于打印带有所有石头的当前棋盘。你将此代码放入 dlgo 模块外的名为 bot_v_bot.py 的文件中。
- en: Listing 3.18\. Utility functions for bot vs. bot games
  id: totrans-420
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.18\. 对战机器人游戏的实用函数
- en: '[PRE22]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: You can set up a script that initiates two random bots that play each other
    on a 9 × 9 board until they decide the game is over.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以设置一个脚本，启动两个随机机器人，它们在一个 9 × 9 的棋盘上相互对战，直到它们决定游戏结束。
- en: Listing 3.19\. A script to let a bot play against itself
  id: totrans-423
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.19\. 让机器人自我对战的脚本
- en: '[PRE23]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '***1* You set a sleep timer to 0.3 seconds so that bot moves aren’t printed
    too fast to observe.**'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 你设置了一个 0.3 秒的睡眠计时器，以便机器人移动不会打印得太快而无法观察。**'
- en: '***2* Before each move, you clear the screen. This way, the board is always
    printed to the same position on the command line.**'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 在每一步之前，你清除屏幕。这样，棋盘总是打印在命令行的相同位置。**'
- en: 'You can start a bot game on the command line by running the following:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过在命令行运行以下命令来开始机器人游戏：
- en: '[PRE24]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You should see a lot of moves printed on the screen, and the game will end
    in both players passing. Recall that you encoded black stones as `x`, white stones
    as `o`, and empty points as a point (`.`). Here’s an example of the last white
    move in a generated game:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在屏幕上看到很多移动，游戏将以双方都认输结束。回想一下，你将黑子编码为`x`，白子编码为`o`，空点编码为一个点(`.`)。以下是一个生成游戏中最后一步白子的示例：
- en: '[PRE25]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This bot is not only weak, but also a frustrating opponent: it’ll keep stubbornly
    placing stones until the whole board is filled in, even if its position is hopeless.
    Moreover, no matter how often you let these bots play against each other, no *learning*
    is involved. This random bot will remain at its current level forever.'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 这个机器人不仅弱，而且是一个令人沮丧的对手：它会固执地放置石头，直到整个棋盘被填满，即使它的位置已经无望。此外，无论你让这些机器人相互对战多少次，都没有涉及任何*学习*。这个随机机器人将永远停留在当前的水平。
- en: Throughout the rest of the book, you’ll slowly improve on both of those weaknesses,
    building up an ever more interesting and powerful Go engine.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的其余部分，你将逐渐改进这两个弱点，构建一个越来越有趣和强大的围棋引擎。
- en: 3.5\. Speeding up game play with Zobrist hashing
  id: totrans-433
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5\. 使用 Zobrist 哈希加速游戏
- en: Before wrapping up the chapter by describing how to play against your random
    bot, let’s quickly address a speed issue in your current implementation by introducing
    an important technique. If you’re not interested in ways to speed up your implementation,
    it’s safe to skip to [section 3.6](#ch03lev1sec6) right away.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 在描述如何对抗你的随机机器人之前，让我们快速解决当前实现中的一个速度问题，通过介绍一个重要的技术。如果你对加快实现的方法不感兴趣，可以直接跳转到[第 3.6
    节](#ch03lev1sec6)。
- en: 'Recall from [section 3.2](#ch03lev1sec2) that to check for situational superko,
    you need to go through the entire history of positions of that game to see whether
    the current position has been there before. This is computationally expensive.
    To avoid this problem, you alter your setup slightly: instead of storing past
    board positions altogether, you simply store much smaller *hash values* of it.'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下[第 3.2 节](#ch03lev1sec2)，要检查情境超 ko，你需要遍历该游戏的所有位置历史，以查看当前位置是否之前出现过。这是计算上昂贵的。为了避免这个问题，你稍微改变一下设置：不是存储过去的所有棋盘位置，而是只存储它的小得多的*哈希值*。
- en: 'Hashing techniques are omnipresent in computer science. One in particular is
    widely used in other games, such as chess: *Zobrist hashing* (named after computer
    scientist Albert Zobrist, who built one of the first Go bots in the early 1970s).
    In Zobrist hashing, you assign a hash value to each possible Go move on the board.
    For best results, you should choose each hash value randomly. In Go, each move
    is either black or white, so on a 19 × 19 board, a full Zobrist hash table consists
    of 2 × 19 × 19 = 722 hash values. You use this small number of 722 hashes representing
    individual moves to encode the most complex of board positions. [Figure 3.9](#ch03fig09)
    shows how it works.'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希技术在计算机科学中无处不在。其中一种特别广泛地应用于其他游戏，如国际象棋：*Zobrist哈希*（以计算机科学家阿尔伯特·Zobrist命名，他在20世纪70年代初构建了第一个围棋机器人）。在Zobrist哈希中，你为棋盘上每个可能的围棋走法分配一个哈希值。为了获得最佳结果，你应该随机选择每个哈希值。在围棋中，每一步要么是黑子要么是白子，因此在19
    × 19的棋盘上，完整的Zobrist哈希表包含2 × 19 × 19 = 722个哈希值。你使用这722个代表单个走法的哈希值来编码最复杂的棋盘位置。[图3.9](#ch03fig09)展示了它是如何工作的。
- en: Figure 3.9\. Using Zobrist hashes to encode moves and efficiently store game
    state
  id: totrans-437
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.9\. 使用Zobrist哈希值编码走法和高效存储游戏状态
- en: '![](Images/03fig09_alt.jpg)'
  id: totrans-438
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/03fig09_alt.jpg)'
- en: What’s interesting about the procedure shown in [figure 3.9](#ch03fig09) is
    that a full board state can be encoded by a single hash value. You start with
    the hash value of the empty board, which you can choose to be 0 for simplicity.
    The first move has a hash value, and you can apply this move to the board by carrying
    out an `XOR` operation of the board with the move hash. We call this operation
    *applying the hash*. Following this convention, for each new move, you can apply
    its current hash to the board. This allows you to track the current board state
    as one hash value.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3.9](#ch03fig09)中展示的过程有趣之处在于，一个完整的棋盘状态可以通过一个单一的哈希值来编码。你从空棋盘的哈希值开始，为了简单起见，你可以选择将其设为0。第一步有一个哈希值，你可以通过在棋盘上执行与走法哈希值的`XOR`操作来应用这个走法。我们称这个操作为*应用哈希值*。按照这个惯例，对于每个新的走法，你都可以将其当前的哈希值应用到棋盘上。这允许你跟踪当前棋盘状态为一个哈希值。'
- en: Note that you can reverse any move by applying its hash again (a convenient
    feature of the `XOR` operation). We call this *unapplying the hash value*. This
    is important, because with this property, you can easily remove stones from the
    board when they’re captured. For instance, if a single black stone at C3 on the
    board is captured, you can remove it from the current board state hash by applying
    the hash value of C3\. Of course, in this scenario, the hash value of the white
    stone capturing C3 has to be applied as well. If a white move captures multiple
    black stones, you unapply all of their hashes.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你可以通过再次应用其哈希值来撤销任何走法（`XOR`操作的便利特性）。我们称这个操作为*撤销哈希值*。这一点很重要，因为有了这个特性，你可以在走法被捕获时轻松地从棋盘上移除石头。例如，如果棋盘上C3位置的一个黑子被捕获，你可以通过应用C3的哈希值从当前棋盘状态哈希值中移除它。当然，在这种情况下，捕获C3的白子的哈希值也必须被应用。如果一个白子走法捕获了多个黑子，你将撤销所有它们的哈希值。
- en: Given that you’ve chosen your hash values sufficiently large and general, so
    that no hash collisions occur (two different game states never result in the same
    hash value), you can encode any board position like this. In practice, you don’t
    check for hash collisions, but simply assume there are none.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你选择了足够大且通用的哈希值，因此不会发生哈希冲突（两个不同的游戏状态永远不会产生相同的哈希值），你可以这样编码任何棋盘位置。在实践中，你不需要检查哈希冲突，只需简单地假设没有冲突发生。
- en: To implement Zobrist hashing for your Go board implementation, you first need
    to generate the hashes. You generate 64-bit random integers by using Python’s
    `random` library for each of the 3 × 19 × 19 possible point states. Note that
    in Python the symbol `^` carries out an `XOR` operation. For the empty board,
    you choose a value of `0`.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 要为你的围棋棋盘实现实现Zobrist哈希，你首先需要生成哈希值。你使用Python的`random`库为3 × 19 × 19个可能的位置状态生成64位随机整数。请注意，在Python中，符号`^`执行`XOR`操作。对于空棋盘，你选择值为`0`。
- en: Listing 3.20\. Generating Zobrist hashes
  id: totrans-443
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.20\. 生成Zobrist哈希值
- en: '[PRE26]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Running this script prints the desired hashes on the command line. Executing
    the preceding code generates Python code printed to the command line. Place this
    output in the file zobrist.py in the dlgo module.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此脚本将在命令行上打印所需的哈希值。执行前面的代码将在命令行上生成Python代码。将此输出放置在dlgo模块中的zobrist.py文件中。
- en: Now that you have the hashes available, all you need to do is to replace your
    old state-tracking mechanism by storing hashes instead. Create a copy of goboard_slow.py
    called goboard.py, in which you’ll make all the necessary changes for the rest
    of this section. Alternatively, you can follow the code in goboard.py from our
    GitHub repository. You start with a slight modification to make `GoString` and
    both `stones` and `liberties` immutable, meaning they can’t by modified after
    they’re created. You can do this by using Python’s `frozenset` instead of `set`.
    A `frozenset` doesn’t have methods to add or remove items, so you need to create
    a new set instead of modifying an existing one.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了散列值，你只需要用散列值替换你的旧状态跟踪机制。创建一个名为goboard.py的goboard_slow.py副本，你将在其中为本节其余部分进行所有必要的更改。或者，你可以遵循GitHub仓库中的goboard.py中的代码。你从一个轻微的修改开始，使`GoString`和`stones`以及`liberties`不可变，这意味着它们在创建后不能被修改。你可以通过使用Python的`frozenset`而不是`set`来实现这一点。`frozenset`没有添加或删除项的方法，因此你需要创建一个新的集合而不是修改现有的集合。
- en: Listing 3.21\. `GoString` instances with immutable sets of stones and liberties
  id: totrans-447
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.21\. 具有不可变棋子和气集合的`GoString`实例
- en: '[PRE27]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '***1* Stones and liberties are now immutable frozenset instances.**'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 石子和气现在是不可变的frozenset实例。**'
- en: '***2* The without_liberty method replaces the previous remove_liberty method...**'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* `without_liberty`方法替换了之前的`remove_liberty`方法...**'
- en: '***3* ... and with_liberty replaces add_liberty.**'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* ...并且with_liberty替换了add_liberty。**'
- en: In `GoString`, you replace two methods to account for immutable state and leave
    the other helper methods, such as `merged_with` or `num_liberties`, untouched.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 在`GoString`中，你替换了两个方法来处理不可变状态，并保留了其他辅助方法，如`merged_with`或`num_liberties`。
- en: Next, you update relevant parts of the Go board. Remember to place all the code
    for the rest of this section in goboard.py, your copy of goboard_slow.py.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你更新围棋盘的相关部分。请记住，将本节其余部分的全部代码放在goboard.py中，你的goboard_slow.py副本。
- en: Listing 3.22\. Instantiating the Go board with a _`hash` value for the empty
    board
  id: totrans-454
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.22\. 使用空棋盘的`hash`值初始化围棋盘
- en: '[PRE28]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Next, in your `place_stone` method, whenever a new stone is placed, you apply
    the hash of the respective color. Make sure to apply these changes to the goboard.py
    file as well, just as with every other piece of code in this section.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在你的`place_stone`方法中，每次放置一个新的棋子时，你应用相应颜色的散列值。确保将这些更改应用到goboard.py文件中，就像应用到本节其他所有代码一样。
- en: Listing 3.23\. Placing a stone means applying the hash of that stone
  id: totrans-457
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.23\. 放置一个棋子意味着应用该棋子的散列值
- en: '[PRE29]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '***1* Until this line, place_stone remains the same.**'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 到这一行为止，place_stone保持不变。**'
- en: '***2* You merge any adjacent strings of the same color.**'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 你合并任何相邻的同色棋子。**'
- en: '***3* Next, you apply the hash code for this point and player.**'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 接下来，你应用这个点和玩家的散列码。**'
- en: '***4* Then you reduce liberties of any adjacent strings of the opposite color.**'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 然后减少相邻异色棋子的气数。**'
- en: '***5* If any opposite-color strings now have zero liberties, remove them.**'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 如果现在有任何异色棋子没有气，则移除它们。**'
- en: To remove a stone, you apply its hash to the board once again.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 要移除一个棋子，你将其散列值再次应用于棋盘。
- en: Listing 3.24\. Removing a stone means unapplying the hash value of the stone
  id: totrans-465
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.24\. 移除一个棋子意味着取消应用该棋子的散列值
- en: '[PRE30]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '***1* This new helper method updates your Go board grid.**'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 这个新的辅助方法更新你的围棋盘网格。**'
- en: '***2* Removing a string can create liberties for other strings.**'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 移除一个字符串可以为其他字符串创造气。**'
- en: '***3* With Zobrist hashing, you need to unapply the hash for this move.**'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 使用Zobrist散列，你需要取消应用这个移动的散列。**'
- en: The last thing you add to the `Board` class is a utility method to return the
    current Zobrist hash.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 你添加到`Board`类的最后一件事是一个实用方法，用于返回当前的Zobrist散列值。
- en: Listing 3.25\. Returning the current Zobrist hash of the board
  id: totrans-471
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.25\. 返回棋盘的当前Zobrist散列值
- en: '[PRE31]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Now that you’ve encoded your Go board with Zobrist hashing values, let’s see
    how to improve `GameState` with it.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经使用Zobrist散列值编码了围棋盘，让我们看看如何利用它来改进`GameState`。
- en: 'Before, the previous game state was set like this: `self.previous_state = previous`,
    which we argued was too expensive, because you had to cycle through all past states
    to check for ko. Instead, you want to store Zobrist hashes, and you do this by
    using the new variable `previous_states`, as shown in the next code listing.'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前，游戏状态被设置为这样：`self.previous_state = previous`，我们认为这太昂贵了，因为你必须遍历所有过去的状态来检查劫争。相反，你想要存储Zobrist散列值，你可以通过使用新的变量`previous_states`来实现，如下一段代码所示。
- en: Listing 3.26\. Initializing game state with Zobrist hashes
  id: totrans-475
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.26\. 使用 Zobrist 哈希初始化游戏状态
- en: '[PRE32]'
  id: totrans-476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'If the board is empty, `self.previous_states` is an empty immutable `frozenset`.
    Otherwise, you augment the states by a pair: the color of the next player and
    the Zobrist hash of the previous game state.'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 如果棋盘为空，`self.previous_states` 是一个空的不可变 `frozenset`。否则，你通过一对来增强状态：下一个玩家的颜色和上一个游戏状态的
    Zobrist 哈希。
- en: Having set up all this, you can finally drastically improve on your `does_move_violate_ko`
    implementation.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置好所有这些之后，你最终可以大幅改进你的 `does_move_violate_ko` 实现。
- en: Listing 3.27\. Fast checking of game states for ko with Zobrist hashes
  id: totrans-479
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.27\. 使用 Zobrist 哈希快速检查 ko 状态
- en: '[PRE33]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Checking previous board states by the single line `next_situation in self.previous_states`
    is an order of magnitude faster than the explicit loop over board states you had
    before.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 通过单行 `next_situation in self.previous_states` 检查之前的棋盘状态比之前显式遍历棋盘状态的效率高了一个数量级。
- en: This interesting hashing trick will enable much faster self-play in later chapters,
    leading to much quicker improvements in game play.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 这个有趣的哈希技巧将使后续章节中的自我对弈更快，从而在游戏玩法上带来更快的改进。
- en: '|  |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Further speeding up your Go board implementation**'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '**进一步加速你的围棋盘实现**'
- en: We gave an in-depth treatment of the original goboard_slow.py implementation
    and showed how to speed it up with Zobrist hashing to arrive at goboard.py. In
    the GitHub repository, you’ll see yet another Go board implementation called goboard_fast.py,
    in which you can further speed up game play. These speed improvements are extremely
    valuable in later chapters, but come as a trade-off for readability.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对原始的 goboard_slow.py 实现进行了深入分析，并展示了如何通过 Zobrist 哈希来加速它，从而得到 goboard.py。在 GitHub
    仓库中，你还会看到另一个名为 goboard_fast.py 的围棋盘实现，其中你可以进一步加快游戏速度。这些速度提升在后续章节中非常有价值，但这是以可读性为代价的。
- en: If you’re interested in how to make your Go board even quicker, look at goboard_fast.py
    and the comments found there. Most of the optimizations are tricks to avoid constructing
    and copying Python objects.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣，想了解如何使你的围棋盘更快，请查看 goboard_fast.py 以及那里的注释。大多数优化都是避免构造和复制 Python 对象的技巧。
- en: '|  |'
  id: totrans-487
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 3.6\. Playing against your bot
  id: totrans-488
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6\. 与你的机器人对抗
- en: Having created a weak bot that plays against itself, you may wonder whether
    you can test your knowledge from [chapter 2](kindle_split_013.xhtml#ch02) to play
    against it yourself. This is indeed possible and doesn’t require a lot of changes
    compared to the setup for bot versus bot.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建了一个与自己对抗的弱机器人之后，你可能想知道你是否可以测试你的知识从 [第 2 章](kindle_split_013.xhtml#ch02) 开始，自己与它对抗。这确实可能，并且与机器人对抗机器人的设置相比，不需要太多改变。
- en: You need one more utility function that you put into utils.py to help you read
    coordinates from human input.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要一个额外的实用函数，将其放入 utils.py 中，以帮助你从人类输入中读取坐标。
- en: Listing 3.28\. Transforming human input into coordinates for your Go board
  id: totrans-491
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.28\. 将人类输入转换为围棋盘坐标
- en: '[PRE34]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This function transforms inputs like `C3` or `E7` into Go board coordinates.
    With this in mind, you can now set up your program for a 9 × 9 game in human_v_bot.py
    like this.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将像 `C3` 或 `E7` 这样的输入转换为围棋盘坐标。考虑到这一点，你现在可以在 human_v_bot.py 中设置程序以进行 9 × 9
    游戏如下。
- en: Listing 3.29\. Setting up a script so you can play your own bot
  id: totrans-494
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.29\. 设置脚本以便你可以玩自己的机器人
- en: '[PRE35]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'You, the human player, will play as black. Your random bot takes white. Start
    the script with the following:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 你，作为人类玩家，将扮演黑方。你的随机机器人扮演白方。用以下方式启动脚本：
- en: '[PRE36]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'You’ll be prompted to type in a move and confirm with `enter`. For instance,
    if you choose to play `G3` as your first move, the bot’s response may look as
    follows:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 你将被提示输入一个移动，并通过 `enter` 确认。例如，如果你选择将 `G3` 作为你的第一个移动，机器人的响应可能如下所示：
- en: '[PRE37]'
  id: totrans-499
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: If you wish, you can continue and play a full game against this bot. But because
    the bot plays random moves, it isn’t interesting to do so yet.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，你可以继续与这个机器人进行完整游戏。但由于机器人玩的是随机移动，目前这样做并不有趣。
- en: Note that in terms of following the Go rules, this bot is complete already.
    It knows everything about the game of Go it’ll ever need to know. This fact is
    important, because it frees you to completely focus on the algorithms that improve
    game play from now on. This bot represents the baseline you start from. In the
    following chapters, you’ll introduce more-interesting techniques to create stronger
    bots.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在遵循围棋规则方面，这个机器人已经完整了。它知道它将需要的所有关于围棋的知识。这个事实很重要，因为它让你可以完全专注于从现在开始提高游戏算法。这个机器人代表了你的起点。在接下来的章节中，你将介绍更多有趣的技巧来创建更强大的机器人。
- en: 3.7\. Summary
  id: totrans-502
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.7\. 摘要
- en: The two players of a game of Go are best encoded by using an enum.
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 围棋游戏中两位玩家的最佳编码方式是使用枚举。
- en: A point on the Go board is characterized by its immediate neighborhood.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 围棋棋盘上的一个点由其直接邻域来表征。
- en: A move in Go is either playing, passing, or resigning.
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 围棋中的一步棋可以是落子、认输或投降。
- en: Strings of stones are connected groups of stones of the same color. Strings
    are important to efficiently check for captured stones after placing a stone.
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 石子串是由相同颜色的石子组成的连接组。石子串对于放置石子后高效检查被捕获的石子非常重要。
- en: The Go `Board` has all the logic of placing and capturing stones.
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 围棋的`Board`包含了放置和捕获石子的所有逻辑。
- en: In contrast, `GameState` keeps track of whose turn it is, the stones currently
    on the board, and the history of previous states.
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比之下，`GameState`跟踪的是轮到谁走，当前棋盘上的石子，以及之前状态的历史。
- en: Ko can be implemented by using the situational superko rule.
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ko可以通过使用情境超级ko规则来实现。
- en: Zobrist hashing is an important technique to efficiently encode game-play history
    and speed up checking for ko.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zobrist哈希是一种重要的技术，可以高效地编码游戏历史并加快ko的检查。
- en: 'A Go-playing agent can be defined with one method: `select_move`.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个围棋玩棋代理可以通过一个方法来定义：`select_move`。
- en: Your random bot can play against itself, other bots, and human opponents.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的随机机器人可以与自己、其他机器人以及人类对手进行对弈。
