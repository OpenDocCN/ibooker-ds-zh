- en: Chapter 12\. Deploying microservices
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 12 章\. 部署微服务
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: 'The four key deployment patterns, how they work, and their benefits and drawbacks:'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 四种关键部署模式，它们的工作原理以及它们的优缺点：
- en: Language-specific packaging format
  id: totrans-3
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言特定的打包格式
- en: Deploying a service as a VM
  id: totrans-4
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将服务作为虚拟机部署
- en: Deploying a service as a container
  id: totrans-5
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将服务作为容器部署
- en: Serverless deployment
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器部署
- en: Deploying services with Kubernetes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 部署服务
- en: Using a service mesh to separate deployment from release
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用服务网格将部署与发布分离
- en: Deploying services with AWS Lambda
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AWS Lambda 部署服务
- en: Picking a deployment pattern
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择部署模式
- en: Mary and her team at FTGO are almost finished writing their first service. Although
    it’s not yet feature complete, it’s running on developer laptops and the Jenkins
    CI server. But that’s not good enough. Software has no value to FTGO until it’s
    running in production and available to users. FTGO needs to deploy their service
    into production.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在 FTGO，玛丽和她的小组几乎完成了他们的第一个服务的编写。尽管它还没有完全具备所有功能，但它已经在开发者的笔记本电脑和 Jenkins CI 服务器上运行。但这还不够。软件在
    FTGO 中没有价值，除非它在生产环境中运行并对用户可用。FTGO 需要将他们的服务部署到生产环境中。
- en: '*Deployment* is a combination of two interrelated concepts: process and architecture.
    The deployment process consists of the steps that must be performed by people—developers
    and operations—in order to get software into production. The deployment architecture
    defines the structure of the environment in which that software runs. Both aspects
    of deployment have changed radically since I first started developing Enterprise
    Java applications in the late 1990s. The manual process of developers throwing
    code over the wall to production has become highly automated. As [figure 12.1](#ch12fig01)
    shows, physical production environments have been replaced by increasingly lightweight
    and ephemeral computing infrastructure.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*部署* 是两个相互关联的概念的组合：过程和架构。部署过程包括人们（开发人员和运维人员）必须执行的一系列步骤，以便将软件投入生产。部署架构定义了软件运行的环境结构。自我在
    1990 年代后期开始开发企业级 Java 应用程序以来，这两个部署方面都发生了根本性的变化。开发者将代码扔过墙到生产环境的手动过程已经高度自动化。如图 [12.1](#ch12fig01)
    所示，物理生产环境已被越来越轻量级和短暂的计算基础设施所取代。'
- en: Figure 12.1\. Heavyweight and long-lived physical machines have been abstracted
    away by increasingly lightweight and ephemeral technologies.
  id: totrans-13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 12.1\. 重量级和长期存在的物理机器已被越来越轻量级和短暂的科技所抽象化。
- en: '![](Images/12fig01_alt.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig01_alt.jpg)'
- en: Back in the 1990s, if you wanted to deploy an application into production, the
    first step was to throw your application along with a set of operating instructions
    over the wall to operations. You might, for example, file a trouble ticket asking
    operations to deploy the application. Whatever happened next was entirely the
    responsibility of operations, unless they encountered a problem they needed your
    help to fix. Typically, operations bought and installed expensive and heavyweight
    application servers such as WebLogic or WebSphere. Then they would log in to the
    application server console and deploy your applications. They would lovingly care
    for those machines, as if they were pets, installing patches and updating the
    software.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 回到 1990 年代，如果你想将应用程序部署到生产环境，第一步是将你的应用程序以及一系列操作说明扔过墙给运维。例如，你可能提交一个故障单，要求运维部署应用程序。接下来发生的一切完全由运维负责，除非他们遇到了需要你帮助解决的问题。通常，运维会购买并安装昂贵的、重量级的应用程序服务器，如
    WebLogic 或 WebSphere。然后他们会登录到应用程序服务器控制台并部署你的应用程序。他们会像照顾宠物一样爱护这些机器，安装补丁和更新软件。
- en: In the mid 2000s, the expensive application servers were replaced with open
    source, lightweight web containers such as Apache Tomcat and Jetty. You could
    still run multiple applications on each web container, but having one application
    per web container became feasible. Also, virtual machines started to replace physical
    machines. But machines were still treated as beloved pets, and deployment was
    still a fundamentally manual process.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2000 年代中期，昂贵的应用服务器被开源、轻量级的 Web 容器如 Apache Tomcat 和 Jetty 所取代。你仍然可以在每个 Web
    容器上运行多个应用程序，但每个 Web 容器运行一个应用程序变得可行。此外，虚拟机开始取代物理机器。但机器仍然被视为心爱的宠物，部署仍然是一个基本的手动过程。
- en: Today, the deployment process is radically different. Instead of handing off
    code to a separate production team, the adoption of DevOps means that the development
    team is also responsible for deploying their application or services. In some
    organizations, operations provides developers with a console for deploying their
    code. Or, better yet, once the tests pass, the deployment pipeline automatically
    deploys the code into production.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，部署过程已经发生了根本性的变化。不再是将代码交给单独的生产团队，DevOps的采用意味着开发团队也负责部署他们的应用程序或服务。在某些组织中，运维为开发者提供了一个用于部署代码的控制台。或者，更好的是，一旦测试通过，部署管道会自动将代码部署到生产环境中。
- en: The computing resources used in a production environment have also changed radically
    with physical machines being abstracted away. Virtual machines running on a highly
    automated cloud, such as AWS, have replaced the long-lived, pet-like physical
    and virtual machines. Today’s virtual machines are immutable. They’re treated
    as disposable cattle instead of pets and are discarded and recreated rather than
    being reconfigured. *Containers*, an even more lightweight abstraction layer of
    top of virtual machines, are an increasingly popular way of deploying applications.
    You can also use an even more lightweight *serverless* deployment platform, such
    as AWS Lambda, for many use cases.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中使用的计算资源也发生了根本性的变化，因为物理机器被抽象化。在高度自动化的云平台上，如AWS上运行的虚拟机已经取代了长期存在的、类似宠物的物理和虚拟机。今天的虚拟机是不可变的。它们被视为可丢弃的牛群而不是宠物，因此被丢弃并重新创建，而不是重新配置。"容器"，作为虚拟机之上的更轻量级的抽象层，正成为部署应用程序越来越受欢迎的方式。你也可以使用更轻量级的无服务器部署平台，例如AWS
    Lambda，来处理许多用例。
- en: It’s no coincidence that the evolution of deployment processes and architectures
    has coincided with the growing adoption of the microservice architecture. An application
    might have tens or hundreds of services written in a variety of languages and
    frameworks. Because each service is a small application, that means you have tens
    or hundreds of applications in production. It’s no longer practical, for example,
    for system administrators to hand configure servers and services. If you want
    to deploy microservices at scale, you need a highly automated deployment process
    and infrastructure.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 部署过程和架构的演变与微服务架构的日益采用不谋而合并非巧合。一个应用程序可能有数十或数百个用各种语言和框架编写的服务。由于每个服务都是一个小的应用程序，这意味着在生产中有数十或数百个应用程序。例如，系统管理员手动配置服务器和服务已不再实用。如果你想要大规模部署微服务，你需要一个高度自动化的部署流程和基础设施。
- en: '[Figure 12.2](#ch12fig02) shows a high-level view of a production environment.
    The production environment enables developers to configure and manage their services,
    the deployment pipeline to deploy new versions of services, and users to access
    functionality implemented by those services.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.2](#ch12fig02) 展示了生产环境的高级视图。生产环境使开发者能够配置和管理他们的服务，部署管道以部署服务的最新版本，以及用户访问由这些服务实现的功能。'
- en: 'Figure 12.2\. A simplified view of the production environment. It provides
    four main capabilities: service management enables developers to deploy and manage
    their services, runtime management ensures that the services are running, monitoring
    visualizes service behavior and generates alerts, and request routing routes requests
    from users to the services.'
  id: totrans-21
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.2\. 生产环境的简化视图。它提供了四个主要功能：服务管理使开发者能够部署和管理他们的服务，运行时管理确保服务正在运行，监控可视化服务行为并生成警报，请求路由将用户的请求路由到服务。
- en: '![](Images/12fig02_alt.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig02_alt.jpg)'
- en: 'A production environment must implement four key capabilities:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 生产环境必须实现四个关键能力：
- en: '***Service management interface*—** Enables developers to create, update, and
    configure services. Ideally, this interface is a REST API invoked by command-line
    and GUI deployment tools.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***服务管理界面*—** 使开发者能够创建、更新和配置服务。理想情况下，此界面是一个由命令行和GUI部署工具调用的REST API。'
- en: '***Runtime service management*—** Attempts to ensure that the desired number
    of service instances is running at all times. If a service instance crashes or
    is somehow unable to handle requests, the production environment must restart
    it. If a machine crashes, the production environment must restart those service
    instances on a different machine.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***运行时服务管理*—** 试图确保始终运行着所需数量的服务实例。如果一个服务实例崩溃或以某种方式无法处理请求，生产环境必须重新启动它。如果机器崩溃，生产环境必须在不同的机器上重新启动那些服务实例。'
- en: '***Monitoring*—** Provides developers with insight into what their services
    are doing, including log files and metrics. If there are problems, the production
    environment must alert the developers. [Chapter 11](kindle_split_019.xhtml#ch11)
    describes monitoring, also called *observability*.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**—**为开发者提供对其服务正在做什么的洞察，包括日志文件和指标。如果有问题，生产环境必须通知开发者。[第 11 章](kindle_split_019.xhtml#ch11)
    描述了监控，也称为 *可观察性*。'
- en: '***Request routing*—** Routes requests from users to the services.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**请求路由**—**将用户请求路由到服务。'
- en: 'In this chapter I discuss the four main deployment options:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我讨论了四种主要的部署选项：
- en: Deploying services as language-specific packages, such as Java JAR or WAR files.
    It’s worthwhile exploring this option, because even though I recommend using one
    of the other options, its drawbacks motivate the other options.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将服务作为特定语言的打包格式部署，例如 Java JAR 或 WAR 文件。探索这个选项是值得的，因为尽管我推荐使用其他选项之一，但其缺点促使其他选项的产生。
- en: Deploying services as virtual machines, which simplifies deployment by packaging
    a service as a virtual machine image that encapsulate the service’s technology
    stack.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将服务作为虚拟机部署，通过将服务打包成虚拟机镜像来封装服务的技术堆栈，从而简化部署。
- en: Deploying services as containers, which are more lightweight than virtual machines.
    I show how to deploy the FTGO application’s `Restaurant Service` using Kubernetes,
    a popular Docker orchestration framework.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将服务作为容器部署，容器比虚拟机更轻量。我将展示如何使用 Kubernetes，一个流行的 Docker 集成框架，来部署 FTGO 应用程序的 `Restaurant
    Service`。
- en: Deploying services using serverless deployment, which is even more modern than
    containers. We’ll look at how to deploy `Restaurant Service` using AWS Lambda,
    a popular serverless platform.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用无服务器部署来部署服务，这比容器更现代。我们将探讨如何使用 AWS Lambda，一个流行的无服务器平台，来部署 `Restaurant Service`。
- en: Let’s first look at how to deploy services as language-specific packages.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看如何将服务作为特定语言的打包格式部署。
- en: 12.1\. Deploying services using the Language-specific packaging format pattern
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1\. 使用特定语言的打包格式模式部署服务
- en: Let’s imagine that you want to deploy the FTGO application’s `Restaurant Service`,
    which is a Spring Boot-based Java application. One way to deploy this service
    is by using the Service as a language-specific package pattern. When using this
    pattern, what’s deployed in production and what’s managed by the service runtime
    is a service in its language-specific package. In the case of `Restaurant Service`,
    that’s either the executable JAR file or a WAR file. For other languages, such
    as NodeJS, a service is a directory of source code and modules. For some languages,
    such as GoLang, a service is an operating system-specific executable.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设想，你想要部署 FTGO 应用程序的 `Restaurant Service`，这是一个基于 Spring Boot 的 Java 应用程序。部署此服务的一种方法是将服务作为特定语言的打包模式。当使用此模式时，在生产环境中部署并由服务运行时管理的，是一个特定语言的打包格式的服务。在
    `Restaurant Service` 的例子中，这可能是可执行的 JAR 文件或 WAR 文件。对于其他语言，例如 NodeJS，服务是一个源代码和模块的目录。对于某些语言，例如
    GoLang，服务是一个特定操作系统的可执行文件。
- en: '|  |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Pattern: Language-specific packaging format**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**模式：特定语言的打包格式**'
- en: Deploy a language-specific package into production. See [http://microservices.io/patterns/deployment/language-specific-packaging.html](http://microservices.io/patterns/deployment/language-specific-packaging.html).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 将特定语言的打包格式部署到生产环境中。请参阅 [http://microservices.io/patterns/deployment/language-specific-packaging.html](http://microservices.io/patterns/deployment/language-specific-packaging.html)。
- en: '|  |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: To deploy `Restaurant Service` on a machine, you would first install the necessary
    runtime, which in this case is the JDK. If it’s a WAR file, you also need to install
    a web container such as Apache Tomcat. Once you’ve configured the machine, you
    copy the package to the machine and start the service. Each service instance runs
    as a JVM process.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要在机器上部署 `Restaurant Service`，你首先需要安装必要的运行时，在这个例子中是 JDK。如果是 WAR 文件，你还需要安装一个 Web
    容器，例如 Apache Tomcat。一旦配置好机器，你将包复制到机器上并启动服务。每个服务实例都作为一个 JVM 进程运行。
- en: Ideally, you’ve set up your deployment pipeline to automatically deploy the
    service to production, as shown in [figure 12.3](#ch12fig03). The deployment pipeline
    builds an executable JAR file or WAR file. It then invokes the production environment’s
    service management interface to deploy the new version.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，你已经设置了部署管道以自动将服务部署到生产环境，如图 12.3 所示。部署管道构建一个可执行的 JAR 文件或 WAR 文件。然后它调用生产环境的服务管理接口以部署新版本。
- en: Figure 12.3\. The deployment pipeline builds an executable JAR file and deploys
    it into production. In production, each service instance is a JVM running on a
    machine that has the JDK or JRE installed.
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.3\. 部署管道构建可执行的JAR文件并将其部署到生产环境中。在生产环境中，每个服务实例是在安装了JDK或JRE的机器上运行的JVM。
- en: '![](Images/12fig03_alt.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig03_alt.jpg)'
- en: A service instance is typically a single process but sometimes may be a group
    of processes. A Java service instance, for example, is a process running the JVM.
    A NodeJS service might spawn multiple worker processes in order to process requests
    concurrently. Some languages support deploying multiple service instances within
    the same process.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 服务实例通常是单个进程，但有时也可能是一组进程。例如，Java服务实例是一个运行JVM的进程。NodeJS服务可能会产生多个工作进程以并发处理请求。一些语言支持在同一个进程中部署多个服务实例。
- en: Sometimes you might deploy a single service instance on a machine, while retaining
    the option to deploy multiple service instances on the same machine. For example,
    as [figure 12.4](#ch12fig04) shows, you could run multiple JVMs on a single machine.
    Each JVM runs a single service instance.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有时你可能会在机器上部署单个服务实例，同时保留在相同机器上部署多个服务实例的选项。例如，如图12.4所示，你可以在单台机器上运行多个JVM。每个JVM运行一个服务实例。
- en: Figure 12.4\. Deploying multiple service instances on the same machine. They
    might be instances of the same service or instances of different services. The
    overhead of the OS is shared among the service instances. Each service instance
    is a separate process, so there’s some isolation between them.
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.4\. 在同一台机器上部署多个服务实例。它们可能是同一服务的实例，也可能是不同服务的实例。操作系统的开销在服务实例之间共享。每个服务实例是一个单独的进程，因此它们之间有一定的隔离。
- en: '![](Images/12fig04.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig04.jpg)'
- en: Some languages also let you run multiple services instances in a single process.
    For example, as [figure 12.5](#ch12fig05) shows, you can run multiple Java services
    on a single Apache Tomcat.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一些语言也允许你在单个进程中运行多个服务实例。例如，如图12.5所示，你可以在单个Apache Tomcat上运行多个Java服务。
- en: Figure 12.5\. Deploying multiple services instances on the same web container
    or application server. They might be instances of the same service or instances
    of different services. The overhead of the OS and runtime is shared among all
    the service instances. But because the service instances are in the same process,
    there’s no isolation between them.
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.5\. 在同一Web容器或应用服务器上部署多个服务实例。它们可能是同一服务的实例，也可能是不同服务的实例。操作系统和运行时的开销在所有服务实例之间共享。但由于服务实例在同一个进程中，它们之间没有隔离。
- en: '![](Images/12fig05.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig05.jpg)'
- en: This approach is commonly used when deploying applications on traditional expensive
    and heavyweight application servers, such as WebLogic and WebSphere. You can also
    package services as OSGI bundles and run multiple service instances in each OSGI
    container.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法通常用于在传统的昂贵且重量级的应用服务器上部署应用程序，如WebLogic和WebSphere。你还可以将服务打包成OSGI包，并在每个OSGI容器中运行多个服务实例。
- en: The Service as a language-specific package pattern has both benefits and drawbacks.
    Let’s first look at the benefits.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 服务作为特定语言包模式既有优点也有缺点。让我们首先看看优点。
- en: 12.1.1\. Benefits of the Service as a language-specific package pattern
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.1.1\. 服务作为特定语言包模式的优点
- en: 'The Service as a language-specific package pattern has a few benefits:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 服务作为特定语言包模式有几个优点：
- en: Fast deployment
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速部署
- en: Efficient resource utilization, especially when running multiple instances on
    the same machine or within the same process
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有效利用资源，尤其是在同一台机器或同一进程中运行多个实例时
- en: Let’s look at each one.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一查看。
- en: Fast deployment
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 快速部署
- en: 'One major benefit of this pattern is that deploying a service instance is relatively
    fast: you copy the service to a host and start it. If the service is written in
    Java, you copy a JAR or WAR file. For other languages, such as NodeJS or Ruby,
    you copy the source code. In either case, the number of bytes copied over the
    network is relatively small.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式的主要好处之一是部署服务实例相对较快：你将服务复制到主机并启动它。如果服务是用Java编写的，你将复制一个JAR或WAR文件。对于其他语言，如NodeJS或Ruby，你将复制源代码。在两种情况下，通过网络复制的字节数相对较小。
- en: Also, starting a service is rarely time consuming. If the service is its own
    process, you start it. Otherwise, if the service is one of several instances running
    in the same container process, you either dynamically deploy it into the container
    or restart the container. Because of the lack of overhead, starting a service
    is usually fast.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，启动服务很少耗时。如果服务是其自己的进程，您就启动它。否则，如果服务是同一容器进程中运行的多个实例之一，您要么将其动态部署到容器中，要么重启容器。由于缺乏开销，启动服务通常很快。
- en: Efficient resource utilization
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 资源利用效率高
- en: Another major benefit of this pattern is that it uses resources relatively efficiently.
    Multiple service instances share the machine and its operating system. It’s even
    more efficient if multiple service instances run within the same process. For
    example, multiple web applications could share the same Apache Tomcat server and
    JVM.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式的另一个主要好处是它相对高效地使用资源。多个服务实例共享机器及其操作系统。如果多个服务实例在同一个进程中运行，则效率更高。例如，多个网络应用程序可以共享同一个Apache
    Tomcat服务器和JVM。
- en: 12.1.2\. Drawbacks of the Service as a language-specific package pattern
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.1.2. 作为特定语言包模式的“服务”的缺点
- en: 'Despite its appeal, the Service as a language-specific package pattern has
    several significant drawbacks:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种模式具有吸引力，但作为特定语言包模式的“服务”存在几个显著的缺点：
- en: Lack of encapsulation of the technology stack.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技术栈缺乏封装。
- en: No ability to constrain the resources consumed by a service instance.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无法限制服务实例消耗的资源。
- en: Lack of isolation when running multiple service instances on the same machine.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在同一台机器上运行多个服务实例时缺乏隔离。
- en: Automatically determining where to place service instances is challenging.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动确定服务实例放置位置具有挑战性。
- en: Let’s look at each drawback.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看每个缺点。
- en: Lack of encapsulation of the technology stack
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 技术栈缺乏封装
- en: The operation team must know the specific details of how to deploy each and
    every service. Each service needs a particular version of the runtime. A Java
    web application, for example, needs particular versions of Apache Tomcat and the
    JDK. Operations must install the correct version of each required software package.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 运维团队必须了解如何部署每个服务的具体细节。每个服务都需要特定版本的运行时。例如，一个Java网络应用程序需要特定版本的Apache Tomcat和JDK。运维团队必须安装每个所需软件包的正确版本。
- en: To make matters worse, services can be written in a variety of languages and
    frameworks. They might also be written in multiple versions of those languages
    and frameworks. Consequently, the development team must share lots of details
    with operations. This complexity increases the risk of errors during deployment.
    A machine might, for example, have the wrong version of the language runtime.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 情况变得更糟，服务可以是用各种语言和框架编写的。它们也可能使用这些语言和框架的多个版本。因此，开发团队必须与运维团队分享大量细节。这种复杂性增加了部署过程中出现错误的风险。例如，一台机器可能运行着错误的语言运行时版本。
- en: No ability to constrain the resources consumed by a service instance
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 无法限制服务实例消耗的资源
- en: Another drawback is that you can’t constrain the resources consumed by a service
    instance. A process can potentially consume all of a machine’s CPU or memory,
    starving other service instances and operating systems of resources. This might
    happen, for example, because of a bug.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个缺点是您无法限制服务实例消耗的资源。一个进程可能会消耗机器的所有CPU或内存，导致其他服务实例和操作系统资源匮乏。这种情况可能是因为一个错误。
- en: Lack of isolation when running multiple service instances on the same machine
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 在同一台机器上运行多个服务实例时缺乏隔离
- en: The problem is even worse when running multiple instances on the same machine.
    The lack of isolation means that a misbehaving service instance can impact other
    service instances. As a result, the application risks being unreliable, especially
    when running multiple service instances on the same machine.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当在同一台机器上运行多个实例时，问题更为严重。缺乏隔离意味着一个行为不当的服务实例可能会影响其他服务实例。因此，应用程序可能会变得不可靠，尤其是在同一台机器上运行多个服务实例时。
- en: Automatically determining where to place service instances is challenging
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 自动确定服务实例放置位置具有挑战性
- en: Another challenge with running multiple service instances on the same machine
    is determining the placement of service instances. Each machine has a fixed set
    of resources, CPU, memory, and so on, and each service instance needs some amount
    of resources. It’s important to assign service instances to machines in a way
    that uses the machines efficiently without overloading them. As I explain shortly,
    VM-based clouds and container orchestration frameworks handle this automatically.
    When deploying services natively, it’s likely that you’ll need to manually decide
    the placement.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一台机器上运行多个服务实例的另一个挑战是确定服务实例的位置。每台机器都有固定的一组资源，如 CPU、内存等，每个服务实例都需要一定量的资源。重要的是以高效使用机器且不过载的方式分配服务实例到机器上。我稍后会解释，基于
    VM 的云和容器编排框架会自动处理这个问题。当原生部署服务时，你可能需要手动决定位置。
- en: As you can see, despite its familiarity, the Service as a language-specific
    package pattern has some significant drawbacks. You should rarely use this approach,
    except perhaps when efficiency outweighs all other concerns.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，尽管这种模式很熟悉，但作为语言特定包模式的 Service 也有一些显著的缺点。你应该很少使用这种方法，除非效率比其他所有问题都更重要。
- en: Let’s now look at modern ways of deploying services that avoid these problems.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看避免这些问题的现代服务部署方式。
- en: 12.2\. Deploying services using the Service as a virtual machine pattern
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2\. 使用 Service 作为虚拟机模式部署服务
- en: Once again, imagine you want to deploy the FTGO `Restaurant Service`, except
    this time it’s on AWS EC2\. One option would be to create and configure an EC2
    instance and copy onto it the executable or WAR file. Although you would get some
    benefit from using the cloud, this approach suffers from the drawbacks described
    in the preceding section. A better, more modern approach is to package the service
    as an Amazon Machine Image (AMI), as shown in [figure 12.6](#ch12fig06). Each
    service instance is an EC2 instance created from that AMI. The EC2 instances would
    typically be managed by an AWS Auto Scaling group, which attempts to ensure that
    the desired number of healthy instances is always running.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 再次想象，你想要部署 FTGO 的 `Restaurant Service`，但这次是在 AWS EC2 上。一个选择是创建并配置一个 EC2 实例，并将可执行文件或
    WAR 文件复制到上面。尽管使用云会带来一些好处，但这种方法存在前面章节中描述的缺点。一个更好、更现代的方法是将服务打包成亚马逊机器镜像（AMI），如图 12.6
    所示。每个服务实例都是由该 AMI 创建的 EC2 实例。这些 EC2 实例通常由 AWS 自动扩展组管理，该组试图确保始终运行着所需数量的健康实例。
- en: '|  |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Pattern: Deploy a service as a VM**'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**模式：将服务作为 VM 部署**'
- en: Deploy services packaged as VM images into production. Each service instance
    is a VM. See [http://microservices.io/patterns/deployment/service-per-vm.html](http://microservices.io/patterns/deployment/service-per-vm.html).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 将打包为 VM 镜像的服务部署到生产环境中。每个服务实例都是一个 VM。见 [http://microservices.io/patterns/deployment/service-per-vm.html](http://microservices.io/patterns/deployment/service-per-vm.html)。
- en: '|  |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Figure 12.6\. The deployment pipeline packages a service as a virtual machine
    image, such as an EC2 AMI, containing everything required to run the service,
    including the language runtime. At runtime, each service instance is a VM, such
    as an EC2 instance, instantiated from that image. An EC2 Elastic Load Balancer
    routes requests to the instances.
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 12.6\. 部署管道将服务打包成虚拟机镜像，如 EC2 AMI，其中包含运行服务所需的一切，包括语言运行时。在运行时，每个服务实例都是一个 VM，如
    EC2 实例，由该镜像实例化。EC2 弹性负载均衡器将请求路由到这些实例。
- en: '![](Images/12fig06_alt.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/12fig06_alt.jpg)'
- en: The virtual machine image is built by the service’s deployment pipeline. The
    deployment pipeline, as [figure 12.6](#ch12fig06) shows, runs a VM image builder
    to create a VM image that contains the service’s code and whatever software is
    required to run it. For example, the VM builder for a FTGO service installs the
    JDK and the service’s executable JAR. The VM image builder configures the VM image
    machine to run the application when the VM boots, using Linux’s `init` system,
    such as upstart.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机镜像是由服务的部署管道构建的。如图 12.6 所示，部署管道运行一个 VM 镜像构建器来创建包含服务代码和运行它所需的任何软件的 VM 镜像。例如，FTGO
    服务的 VM 构建器安装了 JDK 和服务的可执行 JAR。VM 镜像构建器配置 VM 镜像机器在 VM 启动时运行应用程序，使用 Linux 的 `init`
    系统，如 upstart。
- en: There are a variety of tools that your deployment pipeline can use to build
    VM images. One early tool for creating EC2 AMIs is Aminator, created by Netflix,
    which used it to deploy its video-streaming service on AWS ([https://github.com/Netflix/aminator](https://github.com/Netflix/aminator)).
    A more modern VM image builder is Packer, which unlike Aminator supports a variety
    of virtualization technologies, including EC2, Digital Ocean, Virtual Box, and
    VMware ([www.packer.io](http://www.packer.io)). To use Packer to create an AMI,
    you write a configuration file that specifies the base image and a set of provisioners
    that install software and configure the AMI.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 部署管道可以使用各种工具来构建虚拟机镜像。一个早期的用于创建EC2 AMI的工具是Netflix创建的Aminator，它使用它来在AWS上部署其视频流媒体服务（[https://github.com/Netflix/aminator](https://github.com/Netflix/aminator)）。一个更现代的虚拟机镜像构建器是Packer，与Aminator不同，它支持多种虚拟化技术，包括EC2、Digital
    Ocean、Virtual Box和VMware（[www.packer.io](http://www.packer.io)）。要使用Packer创建AMI，你需要编写一个配置文件，该文件指定了基础镜像和一组安装软件并配置AMI的provisioners。
- en: '|  |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**About Elastic Beanstalk**'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**关于Elastic Beanstalk**'
- en: Elastic Beanstalk, which is provided by AWS, is an easy way to deploy your services
    using VMs. You upload your code, such as a WAR file, and Elastic Beanstalk deploys
    it as one or more load-balanced and managed EC2 instances. Elastic Beanstalk is
    perhaps not quite as fashionable as, say, Kubernetes, but it’s an easy way to
    deploy a microservices-based application on EC2.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: AWS提供的Elastic Beanstalk是一个使用虚拟机部署服务的简单方法。你上传你的代码，例如WAR文件，Elastic Beanstalk将其作为一个或多个负载均衡和管理EC2实例部署。Elastic
    Beanstalk可能不像Kubernetes那样时尚，但它是一个在EC2上部署基于微服务的应用程序的简单方法。
- en: Interestingly, Elastic Beanstalk combines elements of the three deployment patterns
    described in this chapter. It supports several packaging formats for several languages,
    including Java, Ruby, and .NET. It deploys the application as VMs, but rather
    than building an AMI, it uses a base image that installs the application on startup.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，Elastic Beanstalk结合了本章中描述的三个部署模式的元素。它支持多种语言的多种打包格式，包括Java、Ruby和.NET。它以虚拟机（VM）的形式部署应用程序，但与构建AMI不同，它使用一个基础镜像，该镜像在启动时安装应用程序。
- en: Elastic Beanstalk can also deploy Docker containers. Each EC2 instance runs
    a collection of one or more containers. Unlike a Docker orchestration framework,
    covered later in the chapter, the unit of scaling is the EC2 instance rather than
    a container.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic Beanstalk还可以部署Docker容器。每个EC2实例运行一个或多个容器的集合。与本章后面将要介绍的Docker编排框架不同，扩展的单位是EC2实例而不是容器。
- en: '|  |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Let’s look at the benefits and drawbacks of using this approach.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看使用这种方法的好处和缺点。
- en: 12.2.1\. The benefits of deploying services as VMs
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.2.1\. 将服务作为虚拟机部署的好处
- en: 'The Service as a virtual machine pattern has a number of benefits:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 作为虚拟机的服务模式具有许多好处：
- en: The VM image encapsulates the technology stack.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟机镜像封装了技术堆栈。
- en: Isolated service instances.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隔离的服务实例。
- en: Uses mature cloud infrastructure.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用成熟的云基础设施。
- en: Let’s look at each one.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一来看。
- en: The VM image encapsulates the technology stack
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 虚拟机镜像封装了技术堆栈
- en: An important benefit of this pattern is that the VM image contains the service
    and all of its dependencies. It eliminates the error-prone requirement to correctly
    install and set up the software that a service needs in order to run. Once a service
    has been packaged as a virtual machine, it becomes a black box that encapsulates
    your service’s technology stack. The VM image can be deployed anywhere without
    modification. The API for deploying the service becomes the VM management API.
    Deployment becomes much simpler and more reliable.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式的一个重要好处是虚拟机镜像包含了服务和所有依赖项。它消除了正确安装和设置服务运行所需软件的错误风险。一旦服务被封装为虚拟机，它就变成了一个封装了服务技术堆栈的黑盒。虚拟机镜像可以在不修改的情况下部署到任何地方。部署服务的API变成了虚拟机管理API。部署变得简单且更可靠。
- en: Service instances are isolated
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 服务实例是隔离的
- en: A major benefit of virtual machines is that each service instance runs in complete
    isolation. That, after all, is one of the main goals of virtual machine technology.
    Each virtual machine has a fixed amount of CPU and memory and can’t steal resources
    from other services.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机的一个主要好处是每个服务实例都在完全隔离的环境中运行。毕竟，这是虚拟机技术的主要目标之一。每个虚拟机都有固定数量的CPU和内存，并且不能从其他服务中窃取资源。
- en: Uses mature cloud infrastructure
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用成熟的云基础设施
- en: Another benefit of deploying your microservices as virtual machines is that
    you can leverage mature, highly automated cloud infrastructure. Public clouds
    such as AWS attempt to schedule VMs on physical machines in a way that avoids
    overloading the machine. They also provide valuable features such as load balancing
    of traffic across VMs and autoscaling.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 将您的微服务作为虚拟机部署的另一个好处是您可以利用成熟的、高度自动化的云基础设施。公共云如AWS试图以避免过载机器的方式在物理机上调度虚拟机。它们还提供了如跨虚拟机的流量负载均衡和自动扩展等有价值的功能。
- en: 12.2.2\. The drawbacks of deploying services as VMs
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.2.2\. 将服务作为虚拟机部署的缺点
- en: 'The Service as a VM pattern also has some drawbacks:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 服务作为虚拟机模式也有一些缺点：
- en: Less-efficient resource utilization
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源利用率较低
- en: Relatively slow deployments
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相对较慢的部署
- en: System administration overhead
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统管理开销
- en: Let’s look at each drawback in turn.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一分析每个缺点。
- en: Less-efficient resource utilization
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 资源利用率较低
- en: Each service instance has the overhead of an entire virtual machine, including
    its operating system. Moreover, a typical public IaaS virtual machine offers a
    limited set of VM sizes, so the VM will probably be underutilized. This is less
    likely to be a problem for Java-based services because they’re relatively heavyweight.
    But this pattern might be an inefficient way of deploying lightweight NodeJS and
    GoLang services.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 每个服务实例都有整个虚拟机的开销，包括其操作系统。此外，典型的公共IaaS虚拟机提供有限的虚拟机大小，因此虚拟机可能会被过度使用。这对于基于Java的服务来说不太可能成为问题，因为它们相对较重。但这种方法可能不是部署轻量级的NodeJS和GoLang服务的有效方式。
- en: Relatively slow deployments
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 相对较慢的部署
- en: Building a VM image typically takes some number of minutes because of the size
    of the VM. There are lots of bits to be moved over the network. Also, instantiating
    a VM from a VM image is time consuming because of, once again, the amount of data
    that must be moved over the network. The operating system running inside the VM
    also takes some time to boot, though *slow* is a relative term. This process,
    which perhaps takes minutes, is much faster than the traditional deployment process.
    But it’s much slower than the more lightweight deployment patterns you’ll read
    about soon.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 构建虚拟机镜像通常需要一些时间，因为虚拟机的大小。需要通过网络传输大量的数据。此外，从虚拟机镜像实例化虚拟机由于再次需要通过网络传输大量数据而耗时。虚拟机内部运行的操作系统也需要一些时间来启动，尽管“慢”是一个相对术语。这个过程可能需要几分钟，比传统的部署过程快得多。但它比您即将读到的更轻量级的部署模式慢得多。
- en: System administration overhead
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 系统管理开销
- en: You’re responsible for patching the operation system and runtime. System administration
    may seem inevitable when deploying software, but later in [section 12.5](#ch12lev1sec5),
    I describe serverless deployment, which eliminates this kind of system administration.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您负责修补操作系统和运行时。在部署软件时，系统管理似乎是不可避免的，但在[第12.5节](#ch12lev1sec5)中，我将描述无服务器部署，它消除了这种类型的系统管理。
- en: Let’s now look at an alternative way to deploy microservices that’s more lightweight,
    yet still has many of the benefits of virtual machines.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看一种更轻量级但仍然具有许多虚拟机优点的方式来部署微服务。
- en: 12.3\. Deploying services using the Service as a container pattern
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3\. 使用服务作为容器模式部署服务
- en: Containers are a more modern and lightweight deployment mechanism. They’re an
    operating-system-level virtualization mechanism. A container, as [figure 12.7](#ch12fig07)
    shows, consists of usually one but sometimes multiple processes running in a sandbox,
    which isolates it from other containers. A container running a Java service, for
    example, would typically consist of the JVM process.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 容器是一种更现代且轻量级的部署机制。它们是操作系统级别的虚拟化机制。正如[图12.7](#ch12fig07)所示，容器通常包含一个但有时是多个在沙盒中运行的进程，这将其与其他容器隔离开来。例如，运行Java服务的容器通常包含JVM进程。
- en: Figure 12.7\. A container consists of one or more processes running in an isolated
    sandbox. Multiple containers usually run on a single machine. The containers share
    the operating system.
  id: totrans-125
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.7\. 容器由一个或多个在隔离沙盒中运行的进程组成。通常多个容器运行在单个机器上。容器共享操作系统。
- en: '![](Images/12fig07.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/12fig07.jpg)'
- en: From the perspective of a process running in a container, it’s as if it’s running
    on its own machine. It typically has its own IP address, which eliminates port
    conflicts. All Java processes can, for example, listen on port 8080\. Each container
    also has its own root filesystem. The container runtime uses operating system
    mechanisms to isolate the containers from each other. The most popular example
    of a container runtime is Docker, although there are others, such as Solaris Zones.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 从容器中运行的过程的角度来看，它就像是在自己的机器上运行一样。它通常有自己的IP地址，这消除了端口冲突。例如，所有Java进程都可以监听8080端口。每个容器也有自己的根文件系统。容器运行时使用操作系统机制来隔离容器。最流行的容器运行时示例是Docker，尽管还有其他，如Solaris
    Zones。
- en: '|  |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Pattern: Deploy a service as a container**'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**模式：将服务作为容器部署**'
- en: Deploy services packaged as container images into production. Each service instance
    is a container. See [http://microservices.io/patterns/deployment/service-per-container.html](http://microservices.io/patterns/deployment/service-per-container.html).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 将打包为容器镜像的服务部署到生产环境中。每个服务实例都是一个容器。请参阅[http://microservices.io/patterns/deployment/service-per-container.html](http://microservices.io/patterns/deployment/service-per-container.html)。
- en: '|  |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: When you create a container, you can specify its CPU, memory resources, and,
    depending on the container implementation, perhaps the I/O resources. The container
    runtime enforces these limits and prevents a container from hogging the resources
    of its machine. When using a Docker orchestration framework such as Kubernetes,
    it’s especially important to specify a container’s resources. That’s because the
    orchestration framework uses a container’s requested resources to select the machine
    to run the container and thereby ensure that machines aren’t overloaded.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建一个容器时，你可以指定它的CPU、内存资源，以及根据容器实现的不同，可能还有I/O资源。容器运行时强制执行这些限制，并防止容器占用其机器的资源。当使用如Kubernetes这样的Docker编排框架时，指定容器的资源尤为重要。这是因为编排框架使用容器请求的资源来选择运行容器的机器，从而确保机器不会被过载。
- en: '[Figure 12.8](#ch12fig08) shows the process of deploying a service as a container.
    At build-time, the deployment pipeline uses a container image-building tool, which
    reads the service’s code and a description of the image, to create the container
    image and stores it in a registry. At runtime, the container image is pulled from
    the registry and used to create containers.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.8](#ch12fig08)展示了将服务作为容器部署的过程。在构建时，部署管道使用容器镜像构建工具，读取服务的代码和镜像描述，以创建容器镜像并将其存储在注册表中。在运行时，从注册表中拉取容器镜像并用于创建容器。'
- en: Figure 12.8\. A service is packaged as a container image, which is stored in
    a registry. At runtime the service consists of multiple containers instantiated
    from that image. Containers typically run on virtual machines. A single VM will
    usually run multiple containers.
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.8\. 服务被打包为容器镜像，并存储在注册表中。在运行时，服务由从该镜像实例化的多个容器组成。容器通常在虚拟机上运行。单个虚拟机通常会运行多个容器。
- en: '![](Images/12fig08_alt.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/12fig08_alt.jpg)'
- en: Let’s take a look at build-time and runtime steps in more detail.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看构建时和运行时步骤。
- en: 12.3.1\. Deploying services using Docker
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.3.1\. 使用Docker部署服务
- en: To deploy a service as a container, you must package it as a container image.
    A *container image* is a filesystem image consisting of the application and any
    software required to run the service. It’s often a complete Linux root filesystem,
    although more lightweight images are also used. For example, to deploy a Spring
    Boot-based service, you build a container image containing the service’s executable
    JAR and the correct version of the JDK. Similarly, to deploy a Java web application,
    you would build a container image containing the WAR file, Apache Tomcat, and
    the JDK.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要将服务作为容器部署，你必须将其打包为容器镜像。*容器镜像*是一个包含应用程序和运行服务所需的任何软件的文件系统镜像。它通常是一个完整的Linux根文件系统，尽管也使用了更轻量级的镜像。例如，要部署基于Spring
    Boot的服务，你需要构建一个包含服务的可执行JAR文件和正确版本的JDK的容器镜像。同样，要部署Java Web应用程序，你将构建一个包含WAR文件、Apache
    Tomcat和JDK的容器镜像。
- en: Building a Docker image
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 构建Docker镜像
- en: The first step in building an image is to create a Dockerfile. A *Dockerfile*
    describes how to build a Docker container image. It specifies the base container
    image, a series of instructions for installing software and configuring the container,
    and the shell command to run when the container is created. [Listing 12.1](#ch12ex01)
    shows the Dockerfile used to build an image for `Restaurant Service`. It builds
    a container image containing the service’s executable JAR file. It configures
    the container to run the `java -jar` command on startup.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 构建镜像的第一步是创建一个 Dockerfile。一个 *Dockerfile* 描述了如何构建 Docker 容器镜像。它指定了基础容器镜像、一系列用于安装软件和配置容器的指令，以及容器创建时运行的
    shell 命令。[列表 12.1](#ch12ex01) 展示了用于构建 `Restaurant Service` 镜像的 Dockerfile。它构建了一个包含服务可执行
    JAR 文件的容器镜像。它配置容器在启动时运行 `java -jar` 命令。
- en: Listing 12.1\. The `Dockerfile` used to build `Restaurant Service`
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.1\. 构建 `Restaurant Service` 所使用的 `Dockerfile`
- en: '[PRE0]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '***1* The base image**'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 基础镜像**'
- en: '***2* Install curl for use by the health check.**'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 安装 curl 以供健康检查使用。**'
- en: '***3* Configure Docker to run java -jar .. when the container is started.**'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 配置 Docker 在容器启动时运行 java -jar 命令。**'
- en: '***4* Configure Docker to invoke the health check endpoint.**'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 配置 Docker 调用健康检查端点。**'
- en: '***5* Copies the JAR in Gradle’s build directory into the image**'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 将 Gradle 构建目录中的 JAR 复制到镜像中**'
- en: The base image `openjdk:8u171-jre-alpine` is a minimal footprint Linux image
    containing the JRE. The Dockerfile copies the service’s JAR into the image and
    configures the image to execute the JAR on startup. It also configures Docker
    to periodically invoke the health check endpoint, described in [chapter 11](kindle_split_019.xhtml#ch11).
    The `HEALTHCHECK` directive says to invoke the health check endpoint API, described
    in [chapter 11](kindle_split_019.xhtml#ch11), every 5 seconds after an initial
    30-second delay, which gives the service time to start.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 基础镜像 `openjdk:8u171-jre-alpine` 是一个包含 JRE 的最小化 Linux 镜像。Dockerfile 将服务的 JAR
    文件复制到镜像中，并配置镜像在启动时执行 JAR 文件。它还配置 Docker 定期调用 [第 11 章](kindle_split_019.xhtml#ch11)
    中描述的健康检查端点。`HEALTHCHECK` 指令表示在初始 30 秒延迟后每 5 秒调用一次健康检查端点 API，这给服务提供了启动时间。
- en: Once you’ve written the `Dockerfile`, you can then build the image. The following
    listing shows the shell commands to build the image for `Restaurant Service`.
    The script builds the service’s JAR file and executes the `docker build` command
    to create the image.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦编写了 `Dockerfile`，就可以构建镜像。以下列表展示了构建 `Restaurant Service` 镜像的 shell 命令。脚本构建了服务的
    JAR 文件，并执行 `docker build` 命令以创建镜像。
- en: Listing 12.2\. The shell commands used to build the container image for `Restaurant
    Service`
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.2\. 构建 `Restaurant Service` 容器镜像所使用的 shell 命令
- en: '[PRE1]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '***1* Change to the service’s directory.**'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 切换到服务的目录。**'
- en: '***2* Build the service’s JAR.**'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 构建服务的 JAR 文件。**'
- en: '***3* Build the image.**'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 构建镜像。**'
- en: 'The `docker build` command has two arguments: the `-t` argument specifies the
    name of the image, and the `.` specifies what Docker calls the context. The *context*,
    which in this example is the current directory, consists of `Dockerfile` and the
    files used to build the image. The `docker build` command uploads the context
    to the Docker daemon, which builds the image.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker build` 命令有两个参数：`-t` 参数指定镜像的名称，`.` 指定 Docker 所称的上下文。在这个例子中，上下文是当前目录，包括
    `Dockerfile` 和构建镜像所使用的文件。`docker build` 命令将上下文上传到 Docker 守护进程，该守护进程构建镜像。'
- en: Pushing a Docker image to a registry
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 将 Docker 镜像推送到注册库
- en: The final step of the build process is to push the newly built Docker image
    to what is known as a registry. A Docker *registry* is the equivalent of a Java
    Maven repository for Java libraries, or a NodeJS npm registry for NodeJS packages.
    Docker hub is an example of a public Docker registry and is equivalent to Maven
    Central or NpmJS.org. But for your applications you’ll probably want to use a
    private registry provided by services, such as Docker Cloud registry or AWS EC2
    Container Registry.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 构建过程的最后一步是将新构建的 Docker 镜像推送到称为注册库的地方。Docker *注册库* 等同于 Java Maven 仓库中的 Java 库，或者
    NodeJS npm 仓库中的 NodeJS 包。Docker Hub 是一个公共 Docker 注册库的例子，相当于 Maven Central 或 NpmJS.org。但对你自己的应用程序来说，你可能希望使用由服务提供者提供的私有注册库，例如
    Docker Cloud 注册库或 AWS EC2 容器注册库。
- en: 'You must use two Docker commands to push an image to a registry. First, you
    use the `docker tag` command to give the image a name that’s prefixed with the
    hostname and optional port of the registry. The image name is also suffixed with
    the version, which will be important when you make a new release of the service.
    For example, if the hostname of the registry is `registry.acme.com`, you would
    use this command to tag the image:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须使用两个 Docker 命令将镜像推送到注册表。首先，您使用 `docker tag` 命令给镜像一个以注册表的主机名和可选端口为前缀的名称。镜像名称还附加了版本号，这在您发布服务的新版本时将非常重要。例如，如果注册表的主机名是
    `registry.acme.com`，您将使用此命令标记镜像：
- en: '[PRE2]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next you use the `docker push` command to upload that tagged image to the registry:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您使用 `docker push` 命令将标记的镜像上传到注册表：
- en: '[PRE3]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This command often takes much less time than you might expect. That’s because
    a Docker image has what’s known as a *layered file system*, which enables Docker
    to only transfer part of the image over the network. An image’s operating system,
    Java runtime, and the application are in separate layers. Docker only needs to
    transfer those layers that don’t exist in the destination. As a result, transferring
    an image over a network is quite fast when Docker only has to move the application’s
    layers, which are a small fraction of the image.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令通常比您预期的要快得多。这是因为 Docker 镜像有一个被称为 *分层文件系统* 的特性，这使得 Docker 只需要通过网络传输镜像的一部分。镜像的操作系统、Java
    运行时和应用程序位于不同的层。Docker 只需要传输那些在目标中不存在的层。因此，当 Docker 只需要移动应用程序的层（这些层是镜像的一小部分）时，通过网络传输镜像就非常快了。
- en: Now that we’ve pushed the image to a registry, let’s look at how to create a
    container.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将镜像推送到注册表，让我们看看如何创建一个容器。
- en: Running a Docker container
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 运行 Docker 容器
- en: Once you’ve packaged your service as a container image, you can then create
    one or more containers. The container infrastructure will pull the image from
    the registry onto a production server. It will then create one or more containers
    from that image. Each container is an instance of your service.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将服务打包成容器镜像，您就可以创建一个或多个容器。容器基础设施将从注册表将镜像拉取到生产服务器上。然后，它将从这个镜像创建一个或多个容器。每个容器都是您服务的实例。
- en: As you might expect, Docker provides a `docker run` command that creates and
    starts a container. [Listing 12.3](#ch12ex03) shows how to use this command to
    run `Restaurant Service`. The `docker run` command has several arguments, including
    the container image and a specification of environment variables to set in the
    runtime container. These are used to pass an externalized configuration, such
    as the database’s network location and more.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所预期的那样，Docker 提供了一个 `docker run` 命令来创建并启动一个容器。[列表 12.3](#ch12ex03) 展示了如何使用此命令运行
    `Restaurant Service`。`docker run` 命令有几个参数，包括容器镜像和在运行时容器中设置的指定环境变量。这些用于传递外部化配置，例如数据库的网络位置等。
- en: Listing 12.3\. Using `docker run` to run a containerized service
  id: totrans-167
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.3\. 使用 `docker run` 运行容器化服务
- en: '[PRE4]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '***1* Runs it as a background daemon**'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 作为后台守护进程运行**'
- en: '***2* The name of the container**'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 容器的名称**'
- en: '***3* Binds port 8080 of the container to port 8082 of the host machine**'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 将容器的 8080 端口绑定到主机的 8082 端口**'
- en: '***4* Environment variables**'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 环境变量**'
- en: '***5* Image to run**'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 要运行的镜像**'
- en: The `docker run` command pulls the image from the registry if necessary. It
    then creates and starts the container, which runs the `java -jar` command specified
    in the `Dockerfile`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker run` 命令在必要时从注册表拉取镜像。然后它创建并启动容器，该容器运行 `Dockerfile` 中指定的 `java -jar`
    命令。'
- en: Using the `docker run` command may seem simple, but there are a couple of problems.
    One is that `docker run` isn’t a reliable way to deploy a service, because it
    creates a container running on a single machine. The Docker engine provides some
    basic management features, such as automatically restarting containers if they
    crash or if the machine is rebooted. But it doesn’t handle machine crashes.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `docker run` 命令可能看起来很简单，但有几个问题。一个是 `docker run` 并不是一个可靠的服务部署方式，因为它创建了一个在单个机器上运行的容器。Docker
    引擎提供了一些基本的管理功能，例如在容器崩溃或机器重启时自动重启容器。但它不处理机器崩溃的情况。
- en: Another problem is that services typically don’t exist in isolation. They depend
    on other services, such as databases and message brokers. It would be nice to
    deploy or undeploy a service and its dependencies as a unit.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是在通常情况下，服务并不是孤立的存在的。它们依赖于其他服务，例如数据库和消息代理。能够作为一个单元部署或卸载服务及其依赖项将是非常好的。
- en: A better approach that’s especially useful during development is to use Docker
    Compose. Docker Compose is a tool that lets you declaratively define a set of
    containers using a YAML file, and then start and stop those containers as a group.
    What’s more, the YAML file is a convenient way to specify numerous externalized
    configuration properties. To learn more about Docker Compose, I recommend reading
    *Docker in Action* by Jeff Nickoloff (Manning, 2016) and looking at the docker-compose.yml
    file in the example code.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更好的方法，尤其是在开发期间非常有用，是使用Docker Compose。Docker Compose是一个工具，它允许你使用YAML文件声明性地定义一组容器，然后作为一个组启动和停止这些容器。更重要的是，YAML文件是一种方便的方式来指定许多外部化配置属性。要了解更多关于Docker
    Compose的信息，我建议阅读Jeff Nickoloff的《Docker实战》（Manning，2016年）并查看示例代码中的docker-compose.yml文件。
- en: The problem with Docker Compose, though, is that it’s limited to a single machine.
    To deploy services reliably, you must use a Docker orchestration framework, such
    as Kubernetes, which turns a set of machines into a pool of resources. I describe
    how to use Kubernetes later, in [section 12.4](#ch12lev1sec4). First, let’s review
    the benefits and drawbacks of using containers.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose的问题在于它仅限于单台机器。为了可靠地部署服务，你必须使用Docker编排框架，例如Kubernetes，它将一组机器转换成一个资源池。我将在[第12.4节](#ch12lev1sec4)中描述如何使用Kubernetes。首先，让我们回顾一下使用容器的好处和缺点。
- en: 12.3.2\. Benefits of deploying services as containers
  id: totrans-179
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.3.2. 将服务作为容器部署的好处
- en: 'Deploying services as containers has several benefits. First, containers have
    many of the benefits of virtual machines:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 将服务作为容器部署有几个好处。首先，容器具有许多虚拟机的优点：
- en: Encapsulation of the technology stack in which the API for managing your services
    becomes the container API.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技术堆栈的封装，其中管理你的服务的API成为容器API。
- en: Service instances are isolated.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务实例是隔离的。
- en: Service instances’s resources are constrained.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务实例的资源受到限制。
- en: But unlike virtual machines, containers are a lightweight technology. Container
    images are typically fast to build. For example, on my laptop it takes as little
    as five seconds to package a Spring Boot application as a container image. Moving
    a container image over the network, such as to and from the container registry,
    is also relatively fast, primarily because only a subset of an image’s layers
    need to be transferred. Containers also start very quickly, because there’s no
    lengthy OS boot process. When a container starts, all that runs is the service.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 但与虚拟机不同，容器是一种轻量级技术。容器镜像通常构建得很快。例如，在我的笔记本电脑上，将Spring Boot应用程序打包成容器镜像只需要大约五秒钟。在网络上移动容器镜像，例如到和从容器注册库，也相对较快，主要是因为只需要传输镜像层的一个子集。容器启动也非常快，因为没有漫长的操作系统启动过程。当容器启动时，只运行服务。
- en: 12.3.3\. Drawbacks of deploying services as containers
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.3.3. 将服务作为容器部署的缺点
- en: One significant drawback of containers is that you’re responsible for the undifferentiated
    heavy lifting of administering the container images. You must patch the operating
    system and runtime. Also, unless you’re using a hosted container solution such
    as Google Container Engine or AWS ECS, you must administer the container infrastructure
    and possibly the VM infrastructure it runs on.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 容器的一个显著缺点是，你必须负责管理容器镜像的无差别的繁重工作。你必须修补操作系统和运行时。此外，除非你使用托管容器解决方案，如Google Container
    Engine或AWS ECS，否则你必须管理容器基础设施，以及可能运行在其上的虚拟机基础设施。
- en: 12.4\. Deploying the FTGO application with Kubernetes
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4. 使用Kubernetes部署FTGO应用程序
- en: Now that we’ve looked at containers and their trade-offs, let’s look at how
    to deploy the FTGO application’s `Restaurant Service` using Kubernetes. Docker
    Compose, described in [section 12.3.1](#ch12lev2sec5), is great for development
    and testing. But to reliably run containerized services in production, you need
    to use a much more sophisticated container runtime, such as Kubernetes. Kubernetes
    is a Docker orchestration framework, a layer of software on top of Docker that
    turns a set of machines into a single pool of resources for running services.
    It endeavors to keep the desired number of instances of each service running at
    all times, even when service instances or machines crash. The agility of containers
    combined with the sophistication of Kubernetes is a compelling way to deploy services.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了容器及其权衡，让我们看看如何使用Kubernetes部署FTGO应用的`Restaurant Service`。如[12.3.1节](#ch12lev2sec5)中描述的Docker
    Compose非常适合开发和测试。但要在生产中可靠地运行容器化服务，您需要使用更复杂的容器运行时，例如Kubernetes。Kubernetes是一个Docker编排框架，它是Docker之上的一个软件层，将一组机器转换成一个单一的资源池来运行服务。它努力保持每个服务所需实例的数量始终运行，即使服务实例或机器崩溃。容器的灵活性与Kubernetes的复杂性相结合，是部署服务的一种有吸引力的方式。
- en: In this section, I first give an overview of Kubernetes, its functionality,
    and its architecture. After that, I show how to deploy a service using Kubernetes.
    Kubernetes is a complex topic, and covering it exhaustively is beyond the scope
    of this book, so I only show how to use Kubernetes from the perspective of a developer.
    For more information, I recommend *Kubernetes in Action* by Marko Luksa (Manning,
    2018).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我首先概述Kubernetes的功能和架构。之后，我将展示如何使用Kubernetes部署服务。Kubernetes是一个复杂的话题，全面覆盖它超出了本书的范围，因此我只从开发者的角度展示如何使用Kubernetes。有关更多信息，我推荐Marko
    Luksa所著的《Kubernetes实战》（Manning, 2018）。
- en: 12.4.1\. Overview of Kubernetes
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.4.1\. Kubernetes概述
- en: Kubernetes is a Docker orchestration framework. A *Docker orchestration framework*
    treats a set of machines running Docker as a pool of resources. You tell the Docker
    orchestration framework to run *N* instances of your service, and it handles the
    rest. [Figure 12.9](#ch12fig09) shows the architecture of a Docker orchestration
    framework.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个Docker编排框架。*Docker编排框架*将运行Docker的一组机器视为资源池。您告诉Docker编排框架运行您服务的*N*个实例，然后它处理其余部分。[图12.9](#ch12fig09)显示了Docker编排框架的架构。
- en: Figure 12.9\. A Docker orchestration framework turns a set of machines running
    Docker into a cluster of resources. It assigns containers to machines. The framework
    attempts to keep the desired number of healthy containers running at all times.
  id: totrans-192
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.9\. Docker编排框架将运行Docker的一组机器转换成一个资源集群。它将容器分配到机器上。该框架试图始终保持所需数量的健康容器运行。
- en: '![](Images/12fig09.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/12fig09.jpg)'
- en: 'A Docker orchestration framework, such as Kubernetes, has three main functions:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 例如Kubernetes这样的Docker编排框架有三个主要功能：
- en: '***Resource management*—** Treats a cluster of machines as a pool of CPU, memory,
    and storage volumes, turning the collection of machines into a single machine.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***资源管理*—** 将机器集群视为CPU、内存和存储卷的资源池，将机器集合转换成一个单一机器。'
- en: '***Scheduling*—** Selects the machine to run your container. By default, scheduling
    considers the resource requirements of the container and each node’s available
    resources. It might also implement *affinity*, which colocates containers on the
    same node, and *anti-affinity*, which places containers on different nodes.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***调度*—** 选择运行您的容器的机器。默认情况下，调度会考虑容器的资源需求以及每个节点的可用资源。它还可能实现*亲和性*，将容器放置在同一节点上，以及*反亲和性*，将容器放置在不同的节点上。'
- en: '***Service management*—** Implements the concept of named and versioned services
    that map directly to services in the microservice architecture. The orchestration
    framework ensures that the desired number of healthy instances is running at all
    times. It load balances requests across them. The orchestration framework performs
    rolling upgrades of services and lets you roll back to an old version.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***服务管理*—** 实现了命名和版本化服务的概念，这些服务直接映射到微服务架构中的服务。编排框架确保始终运行着所需数量的健康实例。它在这些实例之间进行负载均衡。编排框架执行服务的滚动升级，并允许您回滚到旧版本。'
- en: Docker orchestration frameworks are an increasingly popular way to deploy applications.
    Docker Swarm is part of the Docker engine, so is easy to set up and use. Kubernetes
    is much more complex to set up and administer, but it’s much more sophisticated.
    At the time of writing, Kubernetes has tremendous momentum, with a massive open
    source community. Let’s take a closer look at how it works.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Docker编排框架是部署应用程序越来越受欢迎的方式。Docker Swarm是Docker引擎的一部分，因此易于设置和使用。Kubernetes的设置和管理要复杂得多，但功能更强大。在撰写本文时，Kubernetes具有巨大的动力，拥有庞大的开源社区。让我们更深入地了解一下它是如何工作的。
- en: Kubernetes architecture
  id: totrans-199
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Kubernetes架构
- en: Kubernetes runs on a cluster of machines. [Figure 12.10](#ch12fig10) shows the
    architecture of a Kubernetes cluster. Each machine in a Kubernetes cluster is
    either a master or a node. A typical cluster has a small number of masters—perhaps
    just one—and many nodes. A *master* machine is responsible for managing the cluster.
    A *node* is a worker than runs one or more pods. A *pod* is Kubernetes’s unit
    of deployment and consists of a set of containers.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes运行在机器集群上。[图12.10](#ch12fig10)显示了Kubernetes集群的架构。Kubernetes集群中的每台机器要么是主节点，要么是节点。一个典型的集群拥有少量主节点——可能只有一个——以及许多节点。*主节点*负责管理集群。*节点*是一个运行一个或多个Pod的工作节点。*Pod*是Kubernetes的部署单元，由一组容器组成。
- en: Figure 12.10\. A Kubernetes cluster consists of a master, which manages the
    cluster, and nodes, which run the services. Developers and the deployment pipeline
    interact with Kubernetes through the API server, which along with other cluster-management
    software runs on the master. Application containers run on nodes. Each node runs
    a Kubelet, which manages the application container, and a kube-proxy, which routes
    application requests to the pods, either directly as a proxy or indirectly by
    configuring iptables routing rules built into the Linux kernel.
  id: totrans-201
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.10\. Kubernetes集群由一个主节点组成，该节点管理集群，以及运行服务的节点。开发人员和部署管道通过API服务器与Kubernetes交互，该服务器与其他集群管理软件一起运行在主节点上。应用程序容器在节点上运行。每个节点运行一个Kubelet，它管理应用程序容器，以及一个kube-proxy，它将应用程序请求路由到Pod，要么直接作为代理，要么通过配置Linux内核中内置的iptables路由规则间接地。
- en: '![](Images/12fig10_alt.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig10_alt.jpg)'
- en: 'A master runs several components, including the following:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点运行以下组件：
- en: '***API server*—** The REST API for deploying and managing services, used by
    the `kubectl` command-line interface, for example.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***API服务器*—** 部署和管理服务的REST API，例如`kubectl`命令行界面所使用的。'
- en: '***Etcd*—** A key-value NoSQL database that stores the cluster data.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Etcd*—** 一个键值NoSQL数据库，用于存储集群数据。'
- en: '***Scheduler*—** Selects a node to run a pod.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***调度器*—** 选择一个节点来运行Pod。'
- en: '***Controller manager*—** Runs the controllers, which ensure that the state
    of the cluster matches the intended state. For example, one type of controller
    known as a *replication* controller ensures that the desired number of instances
    of a service are running by starting and terminating instances.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***控制器管理器*—** 运行控制器，确保集群的状态与预期状态相匹配。例如，一种称为 *复制* 控制器的控制器确保通过启动和终止实例来运行所需数量的服务实例。'
- en: 'A node runs several components, including the following:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 节点运行以下组件：
- en: '***Kubelet*—** Creates and manages the pods running on the node'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Kubelet*—** 创建和管理节点上运行的Pod'
- en: '***Kube-proxy*—** Manages networking, including load balancing across pods'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Kube-proxy*—** 管理网络，包括跨Pod的负载均衡'
- en: '***Pods*—** The application services'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Pods*—** 应用程序服务'
- en: Let’s now look at key Kubernetes concepts you’ll need to master to deploy services
    on Kubernetes.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看您需要掌握的关键Kubernetes概念，以便在Kubernetes上部署服务。
- en: Key Kubernetes concepts
  id: totrans-213
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 关键Kubernetes概念
- en: 'As mentioned in the introduction to this section, Kubernetes is quite complex.
    But it’s possible to use Kubernetes productively once you master a few key concepts,
    called *objects*. Kubernetes defines many types of objects. From a developer’s
    perspective, the most important objects are the following:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 如本节引言中所述，Kubernetes相当复杂。但一旦掌握了几个关键概念，即所谓的 *对象*，就可以有效地使用Kubernetes。Kubernetes定义了许多类型的对象。从开发人员的角度来看，最重要的对象如下：
- en: '***Pod*—** A pod is the basic unit of deployment in Kubernetes. It consists
    of one or more containers that share an IP address and storage volumes. The pod
    for a service instance often consists of a single container, such as a container
    running the JVM. But in some scenarios a pod contains one or more *sidecar* containers,
    which implement supporting functions. For example, an NGINX server could have
    a sidecar that periodically does a `git pull` to download the latest version of
    the website. A pod is ephemeral, because either the pod’s containers or the node
    it’s running on might crash.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Pod***—**Pod 是 Kubernetes 中部署的基本单元。它由一个或多个共享 IP 地址和存储卷的容器组成。服务实例的 pod 通常只包含一个容器，例如运行
    JVM 的容器。但在某些场景下，pod 包含一个或多个 *sidecar* 容器，这些容器实现支持功能。例如，一个 NGINX 服务器可以有一个 sidecar，它定期执行
    `git pull` 来下载网站的最新版本。Pod 是短暂的，因为 pod 的容器或其运行的节点可能会崩溃**。'
- en: '***Deployment*—** A declarative specification of a pod. A deployment is a controller
    that ensures that the desired number of instances of the pod (service instances)
    are running at all times. It supports versioning with rolling upgrades and rollbacks.
    Later in [section 12.4.2](#ch12lev2sec9), you’ll see that each service in a microservice
    architecture is a Kubernetes deployment.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***部署***—**一个 pod 的声明性规范。部署是一个控制器，确保 pod（服务实例）的期望实例数始终在运行。它支持通过滚动升级和回滚进行版本控制。在[第
    12.4.2 节](#ch12lev2sec9)的后面，你将看到在微服务架构中，每个服务都是一个 Kubernetes 部署**。'
- en: '***Service*—** Provides clients of an application service with a static/stable
    network location. It’s a form of infrastructure-provided service discovery, described
    in [chapter 3](kindle_split_011.xhtml#ch03). A service has an IP address and a
    DNS name that resolves to that IP address and load balances TCP and UDP traffic
    across one or more pods. The IP address and a DNS name are only accessible within
    the Kubernetes. Later, I describe how to configure services that are accessible
    from outside the cluster.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***服务***—**为应用程序服务的客户端提供一个静态/稳定的网络位置。它是一种基础设施提供的服务发现形式，在[第 3 章](kindle_split_011.xhtml#ch03)中进行了描述。服务有一个
    IP 地址和一个解析到该 IP 地址的 DNS 名称，并在一个或多个 pod 上进行 TCP 和 UDP 流量的负载均衡。IP 地址和 DNS 名称仅在 Kubernetes
    内部可访问。稍后，我将描述如何配置可以从集群外部访问的服务。'
- en: '***ConfigMap*—** A named collection of name-value pairs that defines the externalized
    configuration for one or more application services (see [chapter 11](kindle_split_019.xhtml#ch11)
    for an overview of externalized configuration). The definition of a pod’s container
    can reference a ConfigMap to define the container’s environment variables. It
    can also use a ConfigMap to create configuration files inside the container. You
    can store sensitive information, such as passwords, in a form of ConfigMap called
    a Secret.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***ConfigMap***—**一个命名集合，包含一组键值对，用于定义一个或多个应用程序服务的外部化配置（有关外部化配置的概述，请参阅[第 11
    章](kindle_split_019.xhtml#ch11)）。pod 容器的定义可以引用 ConfigMap 来定义容器的环境变量。它还可以使用 ConfigMap
    在容器内创建配置文件。你可以将敏感信息，如密码，以 ConfigMap 的形式存储在 Secret 中。'
- en: Now that we’ve reviewed the key Kubernetes concepts, let’s see them in action
    by looking at how to deploy an application service on Kubernetes.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经回顾了关键 Kubernetes 概念，让我们通过查看如何在 Kubernetes 上部署应用程序服务来观察它们在实际中的应用。
- en: 12.4.2\. Deploying the Restaurant service on Kubernetes
  id: totrans-220
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.4.2\. 在 Kubernetes 上部署 Restaurant 服务
- en: As mentioned earlier, to deploy a service on Kubernetes, you need to define
    a deployment. The easiest way to create a Kubernetes object such as a deployment
    is by writing a YAML file. [Listing 12.4](#ch12ex04) is a YAML file defining a
    deployment for `Restaurant Service`. This deployment specifies running two replicas
    of a pod. The pod has just one container. The container definition specifies the
    Docker image running along with other attributes, such as the values of environment
    variables. The container’s environment variables are the service’s externalized
    configuration. They are read by Spring Boot and made available as properties in
    the application context.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，要在 Kubernetes 上部署服务，你需要定义一个部署。创建 Kubernetes 对象（如部署）的最简单方法是编写一个 YAML 文件。[列表
    12.4](#ch12ex04) 是一个定义 `Restaurant Service` 部署的 YAML 文件。此部署指定运行两个 pod 实例。该 pod
    只有一个容器。容器定义指定了运行的 Docker 镜像以及其他属性，如环境变量的值。容器的环境变量是服务的外部化配置。Spring Boot 读取这些环境变量，并在应用程序上下文中作为属性提供。
- en: Listing 12.4\. Kubernetes `Deployment` for `ftgo-restaurant-service`
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.4\. Kubernetes `Deployment` for `ftgo-restaurant-service`
- en: '[PRE5]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '***1* Specifies that this is an object of type Deployment**'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 指定这是一个类型为 Deployment 的对象**'
- en: '***2* The name of the deployment**'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 部署的名称**'
- en: '***3* Number of pod replicas**'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* Pod 副本的数量**'
- en: '***4* Gives each pod a label called app whose value is ftgo-restaurant-service**'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 为每个 Pod 分配一个名为 app 的标签，其值为 ftgo-restaurant-service**'
- en: '***5* The specification of the pod, which defines just one container**'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* Pod 的规范，仅定义了一个容器**'
- en: '***6* The container’s port**'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 容器的端口**'
- en: '***7* The container’s environment variables, which are read by Spring Boot**'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 容器的环境变量，这些变量由 Spring Boot 读取**'
- en: '***8* Sensitive values that are retrieved from the Kubernetes Secret called
    ftgo-db-secret**'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 从名为 ftgo-db-secret 的 Kubernetes Secret 中检索的敏感值**'
- en: '***9* Configure Kubernetes to invoke the health check endpoint.**'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 配置 Kubernetes 调用健康检查端点。**'
- en: This deployment definition configures Kubernetes to invoke `Restaurant Service`’s
    health check endpoint. As described in [chapter 11](kindle_split_019.xhtml#ch11),
    a health check endpoint enables Kubernetes to determine the health of the service
    instance. Kubernetes implements two different checks. The first check is `readinessProbe`,
    which it uses to determine whether it should route traffic to a service instance.
    In this example, Kubernetes invokes the `/actuator/health` HTTP endpoint every
    20 seconds after an initial 30-second delay, which gives it a chance to initialize.
    If some number (default is 1) of consecutive `readinessProbes` succeeds, Kubernetes
    considers the service to be ready, whereas if some number (default, 3) of consecutive
    `readinessProbes` fail, it’s considered not to be ready. Kubernetes will only
    route traffic to the service instance when the `readinessProbe` indicates that
    it’s ready.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 此部署定义配置 Kubernetes 调用 `Restaurant Service` 的健康检查端点。如第 11 章所述（[kindle_split_019.xhtml#ch11](kindle_split_019.xhtml#ch11)），健康检查端点使
    Kubernetes 能够确定服务实例的健康状况。Kubernetes 实现了两种不同的检查。第一种检查是 `readinessProbe`，它用于确定是否应将流量路由到服务实例。在此示例中，Kubernetes
    在初始 30 秒延迟后每 20 秒调用一次 `/actuator/health` HTTP 端点，这给了它初始化的机会。如果连续出现一定数量（默认为 1）的
    `readinessProbes` 成功，Kubernetes 认为服务已就绪；而如果连续出现一定数量（默认为 3）的 `readinessProbes`
    失败，则认为服务未就绪。只有当 `readinessProbe` 指示服务就绪时，Kubernetes 才会将流量路由到服务实例。
- en: The second health check is the `livenessProbe`. It’s configured the same way
    as the `readinessProbe`. But rather than determine whether traffic should be routed
    to a service instance, the `livenessProbe` determines whether Kubernetes should
    terminate and restart the service instance. If some number (default, 3) of consecutive
    `livenessProbes` fail in a row, Kubernetes will terminate and restart the service.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个健康检查是 `livenessProbe`。它的配置方式与 `readinessProbe` 相同。但与确定是否将流量路由到服务实例不同，`livenessProbe`
    确定Kubernetes是否应该终止并重新启动服务实例。如果连续出现一定数量（默认为 3）的 `livenessProbes` 失败，Kubernetes
    将终止并重新启动服务。
- en: 'Once you’ve written the YAML file, you can create or update the deployment
    by using the `kubectl apply` command:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦编写了 YAML 文件，您可以使用 `kubectl apply` 命令创建或更新部署：
- en: '[PRE6]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This command makes a request to the Kubernetes API server that results in the
    creation of the deployment and the pods.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令向 Kubernetes API 服务器发出请求，导致部署和 Pod 的创建。
- en: 'To create this deployment, you must first create the Kubernetes Secret called
    `ftgo-db-secret`. One quick and insecure way to do that is as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建此部署，您必须首先创建名为 `ftgo-db-secret` 的 Kubernetes Secret。一种快速但不安全的方法如下：
- en: '[PRE7]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This command creates a secret containing the database user ID and password specified
    on the command line. See the Kubernetes documentation ([https://kubernetes.io/docs/concepts/configuration/secret/#creating-your-own-secrets](https://kubernetes.io/docs/concepts/configuration/secret/#creating-your-own-secrets))
    for more secure ways to create secrets.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令创建一个包含在命令行上指定的数据库用户 ID 和密码的 secret。有关创建 secret 的更安全方法，请参阅 Kubernetes 文档（[https://kubernetes.io/docs/concepts/configuration/secret/#creating-your-own-secrets](https://kubernetes.io/docs/concepts/configuration/secret/#creating-your-own-secrets)）。
- en: Creating a Kubernetes service
  id: totrans-241
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 创建 Kubernetes 服务
- en: At this point the pods are running, and the Kubernetes deployment will do its
    best to keep them running. The problem is that the pods have dynamically assigned
    IP addresses and, as such, aren’t that useful to a client that wants to make an
    HTTP request. As described in [chapter 3](kindle_split_011.xhtml#ch03), the solution
    is to use a service discovery mechanism. One approach is to use a client-side
    discovery mechanism and install a service registry, such as Netflix OSS Eureka.
    Fortunately, we can avoid doing that by using the service discovery mechanism
    built in to Kubernetes and define a Kubernetes service.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，Pod正在运行，Kubernetes部署将尽力保持它们运行。问题是Pod具有动态分配的IP地址，因此对于想要发起HTTP请求的客户端来说并不那么有用。如[第3章](kindle_split_011.xhtml#ch03)所述，解决方案是使用服务发现机制。一种方法是在客户端使用发现机制并安装服务注册表，例如Netflix
    OSS Eureka。幸运的是，我们可以通过使用Kubernetes内置的服务发现机制并定义Kubernetes服务来避免这样做。
- en: A *service* is a Kubernetes object that provides the clients of one or more
    pods with a stable endpoint. It has an IP address and a DNS name that resolves
    that IP address. The service load balances traffic to that IP address across the
    pods. [Listing 12.5](#ch12ex05) shows the Kubernetes service for `Restaurant Service`.
    This service routes traffic from `http://ftgo-restaurant-service:8080` to the
    pods defined by the deployment shown in the listing.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '*服务*是Kubernetes对象，为一个或多个Pod的客户端提供一个稳定的端点。它有一个IP地址和一个DNS名称，该名称解析该IP地址。服务将流量负载均衡到该IP地址的Pod上。[列表12.5](#ch12ex05)显示了`Restaurant
    Service`的Kubernetes服务。此服务将流量从`http://ftgo-restaurant-service:8080`路由到列表中定义的部署所定义的Pod。'
- en: Listing 12.5\. The YAML definition of the Kubernetes service for `ftgo-restaurant-service`
  id: totrans-244
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.5\. `ftgo-restaurant-service`的Kubernetes服务的YAML定义
- en: '[PRE8]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '***1* The name of the service, also the DNS name**'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 服务的名称，也是DNS名称**'
- en: '***2* The exposed port**'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 暴露的端口**'
- en: '***3* The container port to route traffic to**'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 路由流量的容器端口**'
- en: '***4* Selects the containers to route traffic to**'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 选择要路由流量的容器**'
- en: The key part of the service definition is `selector`, which selects the target
    pods. It selects those pods that have a label named `app` with the value `ftgo-restaurant-service`.
    If you look closely, you’ll see that the container defined in [listing 12.4](#ch12ex04)
    has such a label.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 服务定义的关键部分是`selector`，它选择目标Pod。它选择那些具有名为`app`且值为`ftgo-restaurant-service`的标签的Pod。如果你仔细看，你会看到[列表12.4](#ch12ex04)中定义的容器具有这样的标签。
- en: 'Once you’ve written the YAML file, you can create the service using this command:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你编写了YAML文件，你可以使用以下命令创建服务：
- en: '[PRE9]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now that we’ve created the Kubernetes service, any clients of `Restaurant Service`
    that are running inside the Kubernetes cluster can access its REST API via `http://ftgo-restaurant-service:8080`.
    Later, I discuss how to upgrade running services, but first let’s take a look
    at how to make the services accessible from outside the Kubernetes cluster.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了Kubernetes服务，任何在Kubernetes集群内部运行的`Restaurant Service`客户端都可以通过`http://ftgo-restaurant-service:8080`访问其REST
    API。稍后我将讨论如何升级运行中的服务，但首先让我们看看如何使服务从Kubernetes集群外部可访问。
- en: 12.4.3\. Deploying the API gateway
  id: totrans-254
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.4.3\. 部署API网关
- en: 'The Kubernetes service for `Restaurant Service`, shown in [listing 12.5](#ch12ex05),
    is only accessible from within the cluster. That’s not a problem for `Restaurant
    Service`, but what about `API Gateway`? Its role is to route traffic from the
    outside world to the service. It therefore needs to be accessible from outside
    the cluster. Fortunately, a Kubernetes service supports this use case as well.
    The service we looked at earlier is a `ClusterIP` service, which is the default,
    but there are, however, two other types of services: `NodePort` and `LoadBalancer`.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes的`Restaurant Service`服务，如[列表12.5](#ch12ex05)所示，仅可在集群内部访问。这对`Restaurant
    Service`来说没问题，但`API Gateway`怎么办？它的作用是将外部世界的流量路由到服务。因此，它需要从集群外部可访问。幸运的是，Kubernetes服务也支持这种用例。我们之前查看的服务是一个`ClusterIP`服务，这是默认设置，但事实上还有两种其他类型的服务：`NodePort`和`LoadBalancer`。
- en: A `NodePort` service is accessible via a cluster-wide port on all the nodes
    in the cluster. Any traffic to that port on any cluster node is load balanced
    to the backend pods. You must select an available port in the range of 30000–32767\.
    For example, [listing 12.6](#ch12ex06) shows a service that routes traffic to
    port 30000 of `Consumer Service`.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '`NodePort`服务可通过集群中所有节点的集群端口访问。任何集群节点上的该端口的流量都将负载均衡到后端Pod。你必须选择30000-32767范围内的可用端口。例如，[列表12.6](#ch12ex06)显示了一个将流量路由到`Consumer
    Service`的30000端口的服务的示例。'
- en: Listing 12.6\. The YAML definition of a `NodePort` service that routes traffic
    to port 8082 of `Consumer Service`
  id: totrans-257
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.6\. `NodePort`服务的YAML定义，该服务将流量路由到`Consumer Service`的8082端口
- en: '[PRE10]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '***1* Specifies a type of NodePort**'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 指定NodePort类型**'
- en: '***2* The cluster-wide port**'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 集群端口**'
- en: '`API Gateway` is within the cluster using the URL `http://ftgo-api-gateway`
    and outside the URL `http://<node-ip-address>:3000/`, where `node-ip-address`
    is the IP address of one of the nodes. After configuring a `NodePort` service
    you can, for example, configure an AWS Elastic Load Balancer (ELB) to load balance
    requests from the internet across the nodes. A key benefit of this approach is
    that the ELB is entirely under your control. You have complete flexibility when
    configuring it.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '`API Gateway`位于集群内部，使用URL `http://ftgo-api-gateway`，外部URL为`http://<node-ip-address>:3000/`，其中`node-ip-address`是集群中某个节点的IP地址。配置一个`NodePort`服务后，例如，你可以配置一个AWS弹性负载均衡器（ELB）来在节点之间负载均衡来自互联网的请求。这种方法的优点是ELB完全受你控制。在配置它时，你拥有完全的灵活性。'
- en: A `NodePort` type service isn’t the only option, though. You can also use a
    `LoadBalancer` service, which automatically configures a cloud-specific load balancer.
    The load balancer will be an ELB if Kubernetes is running on AWS. One benefit
    of this type of service is that you no longer have to configure your own load
    balancer. The drawback, however, is that although Kubernetes does give a few options
    for configuring the ELB, such the SSL certificate, you have a lot less control
    over its configuration.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`NodePort`类型服务不是唯一的选择，你也可以使用`LoadBalancer`服务，它会自动配置一个特定于云的负载均衡器。如果Kubernetes运行在AWS上，负载均衡器将是一个ELB。这种类型服务的优点是，你不再需要配置自己的负载均衡器。然而，缺点是，尽管Kubernetes确实提供了一些配置ELB的选项，例如SSL证书，但你对其配置的控制力大大降低。
- en: 12.4.4\. Zero-downtime deployments
  id: totrans-263
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.4.4\. 无停机部署
- en: 'Imagine you’ve updated `Restaurant Service` and want to deploy those changes
    into production. Updating a running service is a simple three-step process when
    using Kubernetes:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你已经更新了`Restaurant Service`并希望将这些更改部署到生产环境中。当使用Kubernetes时，更新运行中的服务是一个简单的三步过程：
- en: Build a new container image and push it to the registry using the same process
    described earlier. The only difference is that the image will be tagged with a
    different version tag—for example, `ftgo-restaurant-service:1.1.0.RELEASE`.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前面描述的相同过程构建一个新的容器镜像并将其推送到注册表。唯一的不同之处在于，该镜像将带有不同的版本标签——例如，`ftgo-restaurant-service:1.1.0.RELEASE`。
- en: Edit the YAML file for the service’s deployment so that it references the new
    image.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑服务的部署的YAML文件，使其引用新的镜像。
- en: Update the deployment using the `kubectl apply -f` command.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl apply -f`命令更新部署。
- en: Kubernetes will then perform a rolling upgrade of the pods. It will incrementally
    create pods running version `1.1.0.RELEASE` and terminate the pods running version
    `1.0.0.RELEASE`. What’s great about how Kubernetes does this is that it doesn’t
    terminate old pods until their replacements are ready to handle requests. It uses
    the `readinessProbe` mechanism, a health check mechanism described earlier in
    this section, to determine whether a pod is ready. As a result, there will always
    be pods available to handle requests. Eventually, assuming the new pods start
    successfully, all the deployment’s pods will be running the new version.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes随后将对Pod执行滚动升级。它将逐步创建运行版本`1.1.0.RELEASE`的Pod，并终止运行版本`1.0.0.RELEASE`的Pod。Kubernetes这样做的好处是，它不会在替代Pod准备好处理请求之前终止旧Pod。它使用前面在本节中描述的`readinessProbe`机制来确定Pod是否就绪。因此，始终会有Pod可用于处理请求。最终，假设新Pod启动成功，所有部署的Pod都将运行新版本。
- en: But what if there’s a problem and the version `1.1.0.RELEASE` pods don’t start?
    Perhaps there’s a bug, such as a misspelled container image name or a missing
    environment variable for a new configuration property. If the pods fail to start,
    the deployment will become stuck. At that point, you have two options. One option
    is to fix the YAML file and rerun `kubectl apply -f` to update the deployment.
    The other option is to roll back the deployment.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果出现问题，版本 `1.1.0.RELEASE` 的 pod 无法启动怎么办？可能是因为存在错误，例如容器镜像名称拼写错误或新配置属性缺少环境变量。如果
    pod 启动失败，部署将陷入停滞。在这种情况下，您有两个选择。一个选择是修复 YAML 文件并重新运行 `kubectl apply -f` 来更新部署。另一个选择是回滚部署。
- en: 'A deployment maintains the history of what are termed *rollouts*. Each time
    you update the deployment, it creates a new rollout. As a result, you can easily
    roll back a deployment to a previous version by executing the following command:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 每次更新部署时，都会维护所谓的 *发布历史*。每次更新部署，它都会创建一个新的发布。因此，您可以通过执行以下命令轻松地将部署回滚到以前的版本：
- en: '[PRE11]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Kubernetes will then replace the pods running version `1.1.0.RELEASE` with pods
    running the older version, `1.0.0.RELEASE`.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 将用运行旧版本 `1.0.0.RELEASE` 的 pod 替换运行版本 `1.1.0.RELEASE` 的 pod。
- en: A Kubernetes deployment is a good way to deploy a service without downtime.
    But what if a bug only appears after the pod is ready and receiving production
    traffic? In that situation, Kubernetes will continue to roll out new versions,
    so a growing number of users will be impacted. Though your monitoring system will
    hopefully detect the issue and quickly roll back the deployment, you won’t avoid
    impacting at least some users. To address this issue and make rolling out a new
    version of a service more reliable, we need to separate *deploying*, which means
    getting the service running in production, from *releasing* the service, which
    means making it available to handle production traffic. Let’s look at how to accomplish
    that using a service mesh.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 部署是一种在不中断服务的情况下部署服务的好方法。但是，如果错误仅在 pod 准备就绪并接收生产流量后出现怎么办？在这种情况下，Kubernetes
    将继续推出新版本，因此越来越多的用户将受到影响。尽管您的监控系统可能会检测到问题并快速回滚部署，但您仍然无法避免至少影响一些用户。为了解决这个问题并使服务的新版本发布更加可靠，我们需要将
    *部署*（意味着使服务在生产中运行）与 *发布*（意味着使其能够处理生产流量）分开。让我们看看如何使用服务网格来实现这一点。
- en: 12.4.5\. Using a service mesh to separate deployment from release
  id: totrans-274
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.4.5\. 使用服务网格将部署与发布分离
- en: The traditional way to roll out a new version of a service is to first test
    it in a staging environment. Then, once it’s passed the test in staging, you deploy
    in production by doing a rolling upgrade that replaces old instances of the service
    with new service instances. On one hand, as you just saw, Kubernetes deployments
    make doing a rolling upgrade very straightforward. On the other hand, this approach
    assumes that once a service version has passed the tests in the staging environment,
    it will work in production. Sadly, this is not always the case.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 部署服务新版本的传统方式是首先在预发布环境中进行测试。然后，一旦它通过了预发布环境的测试，您就可以通过滚动升级来部署到生产环境中，用新的服务实例替换旧的服务实例。一方面，正如您刚才看到的，Kubernetes
    部署使滚动升级变得非常简单。另一方面，这种方法假设一旦服务版本通过了预发布环境的测试，它将在生产中工作。遗憾的是，这并不总是如此。
- en: One reason is because staging is unlikely to be an exact clone, if for no other
    reason than the production environment is likely to be much larger and handle
    much more traffic. It’s also time consuming to keep the two environments synchronized.
    As a result of discrepancies, it’s likely that some bugs will only show up in
    production. And even it were an exact clone, you can’t guarantee that testing
    will catch all bugs.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 一个原因是，如果只是为了生产环境可能要大得多并处理更多的流量，那么预发布环境不太可能是一个精确的克隆。保持两个环境同步也很耗时。由于差异，一些错误可能仅在生产环境中出现。即使是一个精确的克隆，您也无法保证测试会捕获所有错误。
- en: 'A much more reliable way to roll out a new version is to separate deployment
    from release:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 将部署与发布分离是一种推出新版本的更可靠的方法：
- en: '***Deployment*—** Running in the production environment'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***部署*—** 在生产环境中运行'
- en: '***Releasing a service*—** Making it available to end users'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***发布服务*—** 使其可供最终用户使用'
- en: 'You then deploy a service into production using the following steps:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下步骤将服务部署到生产环境中：
- en: Deploy the new version into production without routing any end-user requests
    to it.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将新版本部署到生产环境中，而不将任何最终用户请求路由到它。
- en: Test it in production.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在生产环境中测试它。
- en: Release it to a small number of end users.
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其发布给少数最终用户。
- en: Incrementally release it to an increasingly larger number of users until it’s
    handling all the production traffic.
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 逐步将其发布给越来越多的用户，直到它处理所有生产流量。
- en: If at any point there’s an issue, revert back to the old version—otherwise,
    once you’re confident the new version is working correctly, delete the old version.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果在任何时候出现问题，则回滚到旧版本——否则，一旦您确信新版本运行正确，则删除旧版本。
- en: Ideally, those steps will be performed by a fully automated deployment pipeline
    that carefully monitors the newly deployed service for errors.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，这些步骤将由一个完全自动化的部署管道执行，该管道会仔细监控新部署的服务以查找错误。
- en: Traditionally, separating deployments and releases in this way has been challenging
    because it requires a lot of work to implement it. But one of the benefits of
    using a service mesh is that using this style of deployment is a lot easier. A
    *service mesh* is, as described in [chapter 11](kindle_split_019.xhtml#ch11),
    networking infrastructure that mediates all communication between a service and
    other services and external applications. In addition to taking on some of the
    responsibilities of the microservice chassis framework, a service mesh provides
    rule-based load balancing and traffic routing that lets you safely run multiple
    versions of your services simultaneously. Later in this section, you’ll see that
    you can route test users to one version of a service and end-users to a different
    version, for example.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，以这种方式分离部署和发布一直具有挑战性，因为它需要大量工作来实现。但使用服务网格的一个好处是，采用这种部署风格要容易得多。正如[第11章](kindle_split_019.xhtml#ch11)所述，*服务网格*是一种网络基础设施，它介助于服务与其他服务和外部应用程序之间的所有通信。除了承担一些微服务框架的责任外，服务网格还提供基于规则的负载均衡和流量路由，让您能够安全地同时运行多个服务版本。在本节稍后，您将看到您可以路由测试用户到服务的一个版本，而最终用户则使用另一个版本，例如。
- en: As described in [chapter 11](kindle_split_019.xhtml#ch11), there are several
    service meshes to choose from. In this section, I show you how to use Istio, a
    popular, open source service mesh originally developed by Google, IBM, and Lyft.
    I begin by providing a brief overview of Istio and a few of its many features.
    Next I describe how to deploy an application using Istio. After that, I show how
    to use its traffic-routing capabilities to deploy and release an upgrade to a
    service.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[第11章](kindle_split_019.xhtml#ch11)所述，有几种服务网格可供选择。在本节中，我将向您展示如何使用Istio，这是一个由Google、IBM和Lyft最初开发的开源服务网格。我首先提供一个关于Istio及其众多功能的简要概述。接下来，我描述了如何使用Istio部署应用程序。之后，我将展示如何使用其流量路由功能来部署和发布服务的升级。
- en: Overview of the Istio service mesh
  id: totrans-289
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Istio服务网格概述
- en: 'The Istio website describes Istio as an “An open platform to connect, manage,
    and secure microservices” ([https://istio.io](https://istio.io)). It’s a networking
    layer through which all of your services’ network traffic flows. Istio has a rich
    set of features organized into four main categories:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: Istio网站将Istio描述为“一个用于连接、管理和保护微服务的开放平台” ([https://istio.io](https://istio.io))。它是一个网络层，所有服务的网络流量都通过它流动。Istio具有丰富的功能集，分为四大类：
- en: '***Traffic management*—** Includes service discovery, load balancing, routing
    rules, and circuit breakers'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流量管理**—** 包括服务发现、负载均衡、路由规则和断路器'
- en: '***Security*—** Secures interservice communication using Transport Layer Security
    (TLS)'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全**—** 使用传输层安全（TLS）确保服务间通信的安全'
- en: '***Telemetry*—** Captures metrics about network traffic and implements distributed
    tracing'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遥测**—** 捕获关于网络流量的指标并实现分布式跟踪'
- en: '***Policy enforcement*—** Enforces quotas and rate limits'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**策略执行**—** 执行配额和速率限制'
- en: This section focuses on Istio’s traffic-management capabilities.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 本节重点介绍Istio的流量管理功能。
- en: '[Figure 12.11](#ch12fig11) shows Istio’s architecture. It consists of a control
    plane and a data plane. The control plane implements management functions, including
    configuring the data plane to route traffic. The data plane consists of Envoy
    proxies, one per service instance.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.11](#ch12fig11)显示了Istio的架构。它由控制平面和数据平面组成。控制平面实现管理功能，包括配置数据平面以路由流量。数据平面由Envoy代理组成，每个服务实例一个。'
- en: Figure 12.11\. Istio consists of a control plane, whose components include the
    Pilot and the Mixer, and a data plane, which consists of Envoy proxy servers.
    The Pilot extracts information about deployed services from the underlying infrastructure
    and configures the data plane. The Mixer enforces policies such as quotas and
    gathers telemetry, reporting it to the monitoring infrastructure servers. The
    Envoy proxy servers route traffic in and out of services. There’s one Envoy proxy
    server per service instance.
  id: totrans-297
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 12.11\. Istio 由一个控制平面组成，其组件包括 Pilot 和 Mixer，以及一个数据平面，该数据平面由 Envoy 代理服务器组成。Pilot
    从底层基础设施中提取已部署服务的相关信息并配置数据平面。Mixer 强制执行诸如配额等策略并收集遥测数据，将其报告给监控基础设施服务器。Envoy 代理服务器在服务之间路由流量。每个服务实例都有一个
    Envoy 代理服务器。
- en: '![](Images/12fig11_alt.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig11_alt.jpg)'
- en: The two main components of the control plane are the Pilot and the Mixer. The
    *Pilot* extracts information about deployed services from the underlying infrastructure.
    When running on Kubernetes, for example, the Pilot retrieves the services and
    healthy pods. It configures the Envoy proxies to route traffic according to the
    defined routing rules. The *Mixer* collects telemetry from the Envoy proxies and
    enforces policies.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面的两个主要组件是 Pilot 和 Mixer。*Pilot* 从底层基础设施中提取已部署服务的相关信息。例如，当在 Kubernetes 上运行时，Pilot
    获取服务和健康 pod。它配置 Envoy 代理以根据定义的路由规则路由流量。*Mixer* 从 Envoy 代理收集遥测数据并强制执行策略。
- en: The Istio Envoy proxy is a modified version of Envoy ([www.envoyproxy.io](http://www.envoyproxy.io)).
    It’s a high-performance proxy that supports a variety of protocols, including
    TCP, low-level protocols such as HTTP and HTTPS, and higher-level protocols. It
    also understands MongoDB, Redis, and DynamoDB protocols. Envoy also supports robust
    interservice communication with features such as circuit breakers, rate limiting,
    and automatic retries. It can secure communication within the application by using
    TLS for inter-Envoy communication.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: Istio Envoy 代理是 Envoy 的修改版本 ([www.envoyproxy.io](http://www.envoyproxy.io))。它是一个高性能代理，支持多种协议，包括
    TCP、低级协议如 HTTP 和 HTTPS，以及高级协议。它还理解 MongoDB、Redis 和 DynamoDB 协议。Envoy 还支持具有断路器、速率限制和自动重试等功能的强大跨服务通信。它可以通过使用
    TLS 进行 Envoy 之间的通信来保护应用程序内的通信。
- en: Istio uses Envoy as a sidecar, a process or container that runs alongside the
    service instance and implements cross-cutting concerns. When running on Kubernetes,
    the Envoy proxy is a container within the service’s pod. In other environments
    that don’t have the pod concept, Envoy runs in the same container as the service.
    All traffic to and from a service flows through its Envoy proxy, which routes
    traffic according to the routing rules given to it by the control plane. For example,
    direct Service → Service communication becomes Service → Source Envoy → Destination
    Envoy → Service.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Istio 使用 Envoy 作为边车，一个与服务实例并行运行的进程或容器，并实现跨切面关注点。当在 Kubernetes 上运行时，Envoy 代理是服务
    pod 内的一个容器。在其他没有 pod 概念的环境中，Envoy 在与服务的同一容器中运行。所有进入和离开服务的流量都通过其 Envoy 代理流动，该代理根据控制平面提供的路由规则路由流量。例如，直接服务
    → 服务通信变为服务 → 源 Envoy → 目标 Envoy → 服务。
- en: '|  |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Pattern: Sidecar**'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '**模式：边车**'
- en: Implement cross-cutting concerns in a sidecar process or container that runs
    alongside the service instance. See [http://microservices.io/patterns/deployment/sidecar.html](http://microservices.io/patterns/deployment/sidecar.html).
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在与服务实例并行运行的边车进程或容器中实现跨切面关注点。请参阅 [http://microservices.io/patterns/deployment/sidecar.html](http://microservices.io/patterns/deployment/sidecar.html)。
- en: '|  |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Istio is configured using Kubernetes-style YAML configuration files. It has
    a command-line tool called `istioctl` that’s similar to `kubectl`. You use `istioctl`
    for creating, updating, and deleting rules and policies. When using Istio on Kubernetes,
    you can also use `kubectl`.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: Istio 使用类似 Kubernetes 风格的 YAML 配置文件进行配置。它有一个名为 `istioctl` 的命令行工具，类似于 `kubectl`。您使用
    `istioctl` 创建、更新和删除规则和政策。当在 Kubernetes 上使用 Istio 时，您也可以使用 `kubectl`。
- en: Let’s look at how to deploy a service with Istio.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 Istio 部署服务。
- en: Deploying a service with Istio
  id: totrans-308
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用 Istio 部署服务
- en: 'Deploying a service on Istio is quite straightforward. You define a Kubernetes
    `Service` and a `Deployment` for each of your application’s services. [Listing
    12.7](#ch12ex07) shows the definition of `Service` and `Deployment` for `Consumer
    Service`. Although it’s almost identical to the definitions I showed earlier,
    there are a few differences. That’s because Istio has a few requirements for the
    Kubernetes services and pods:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Istio 上部署服务相当简单。你为你的应用程序服务的每个服务定义一个 Kubernetes `Service` 和一个 `Deployment`。[列表
    12.7](#ch12ex07) 展示了 `Consumer Service` 的 `Service` 和 `Deployment` 定义。尽管它与之前我展示的定义几乎相同，但有一些差异。这是因为
    Istio 对 Kubernetes 服务和 Pod 有一些要求：
- en: A Kubernetes service port must use the Istio naming convention of `<protocol>[-<suffix>]`,
    where protocol is `http`, `http2`, `grpc`, `mongo`, or `redis`. If the port is
    unnamed, Istio will treat the port as a TCP port and won’t apply rule-based routing.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 服务端口必须使用 Istio 命名约定 `<protocol>[-<suffix>]`，其中协议是 `http`、`http2`、`grpc`、`mongo`
    或 `redis`。如果端口未命名，Istio 将该端口视为 TCP 端口，并且不会应用基于规则的路由。
- en: 'A pod should have an `app` label such as `app: ftgo-consumer-service`, which
    identifies the service, in order to support Istio distributed tracing.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pod 应该有一个 `app` 标签，例如 `app: ftgo-consumer-service`，以标识服务，以便支持 Istio 分布式跟踪。'
- en: 'In order to run multiple versions of a service simultaneously, the name of
    a Kubernetes deployment must include the version, such as `ftgo-consumer-service-v1`,
    `ftgo-consumer-service-v2`, and so on. A deployment’s pods should have a `version`
    label, such as `version: v1`, which specifies the version, so that Istio can route
    to a specific version.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '为了同时运行服务的多个版本，Kubernetes 部署的名称必须包含版本，例如 `ftgo-consumer-service-v1`、`ftgo-consumer-service-v2`
    等。部署的 Pod 应该有一个 `version` 标签，例如 `version: v1`，以指定版本，这样 Istio 就可以路由到特定版本。'
- en: Listing 12.7\. Deploying Consumer Service with Istio
  id: totrans-313
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.7\. 使用 Istio 部署消费者服务
- en: '[PRE12]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '***1* Named port**'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 命名端口**'
- en: '***2* Versioned deployment**'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 版本化部署**'
- en: '***3* Recommended labels**'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 推荐标签**'
- en: '***4* Image version**'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 镜像版本**'
- en: 'By now, you may be wondering how to run the Envoy proxy container in the service’s
    pod. Fortunately, Istio makes that remarkably easy by automating modifying the
    pod definition to include the Envoy proxy. There are two ways to do that. The
    first is to use *manual sidecar injection* and run the `istioctl kube-inject`
    command:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能想知道如何在服务的 Pod 中运行 Envoy 代理容器。幸运的是，Istio 通过自动化修改 Pod 定义以包含 Envoy 代理，使得这个过程变得非常简单。有两种方法可以实现这一点。第一种是使用
    *手动边车注入* 并运行 `istioctl kube-inject` 命令：
- en: '[PRE13]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This command reads a Kubernetes YAML file and outputs the modified configuration
    containing the Envoy proxy. The modified configuration is then piped into `kubectl
    apply`.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令读取 Kubernetes YAML 文件，并输出包含 Envoy 代理的修改后的配置。然后，修改后的配置被管道传输到 `kubectl apply`。
- en: The second way to add the Envoy sidecar to the pod is to use *automatic sidecar
    injection*. When this feature is enabled, you deploy a service using `kubectl
    apply`. Kubernetes automatically invokes Istio to modify the pod definition to
    include the Envoy proxy.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Envoy 边车添加到 Pod 的第二种方法是使用 *自动边车注入*。当此功能启用时，你使用 `kubectl apply` 部署服务。Kubernetes
    会自动调用 Istio 修改 Pod 定义以包含 Envoy 代理。
- en: 'If you describe your service’s pod, you’ll see that it consists of more than
    your service’s container:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你描述你的服务 Pod，你会看到它由你的服务容器以外的更多内容组成：
- en: '[PRE14]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '***1* Initializes the pod**'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 初始化 Pod**'
- en: '***2* The service container**'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 服务容器**'
- en: '***3* The Envoy container**'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* Envoy 容器**'
- en: Now that we’ve deployed the service, let’s look at how to define routing rules.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经部署了服务，让我们看看如何定义路由规则。
- en: Create routing rules to route to the v1 version
  id: totrans-329
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 创建路由规则以路由到 v1 版本
- en: Let’s imagine that you deployed the `ftgo-consumer-service-v2` deployment. In
    the absence of routing rules, Istio load balances requests across all versions
    of a service. It would, therefore, load balance across versions 1 and 2 of `ftgo-consumer-service`,
    which defeats the purpose of using Istio. In order to safely roll out a new version,
    you must define a routing rule that routes all traffic to the current v1 version.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设你已经部署了 `ftgo-consumer-service-v2` 部署。在没有路由规则的情况下，Istio 会将请求负载均衡到服务的所有版本。因此，它会在
    `ftgo-consumer-service` 的版本 1 和 2 之间进行负载均衡，这违背了使用 Istio 的目的。为了安全地推出新版本，你必须定义一个路由规则，将所有流量路由到当前的
    v1 版本。
- en: '[Figure 12.12](#ch12fig12) shows the routing rule for `Consumer Service` that
    routes all traffic to `v1`. It consists of two Istio objects: a `VirtualService`
    and a `DestinationRule`.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.12](#ch12fig12) 显示了将所有流量路由到 `v1` 的 `Consumer Service` 路由规则。它由两个 Istio
    对象组成：一个 `VirtualService` 和一个 `DestinationRule`。'
- en: 'Figure 12.12\. The routing rule for `Consumer Service`, which routes all traffic
    to the v1 pods. It consists of a `VirtualService`, which routes its traffic to
    the v1 subset, and a `DestinationRule`, which defines the v1 subset as the pods
    labeled with `version: v1`. Once you’ve defined this rule, you can safely deploy
    a new version without routing any traffic to it initially.'
  id: totrans-332
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '图 12.12。将所有流量路由到 v1 pod 的 `Consumer Service` 路由规则。它由一个 `VirtualService` 组成，该
    `VirtualService` 将其流量路由到 v1 子集，以及一个 `DestinationRule`，该 `DestinationRule` 将 v1
    子集定义为带有 `version: v1` 标签的 pod。一旦定义了此规则，就可以安全地部署新版本，而无需最初将其路由到任何流量。'
- en: '![](Images/12fig12_alt.jpg)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig12_alt.jpg)'
- en: 'A `VirtualService` defines how to route requests for one or more hostnames.
    In this example, `VirtualService` defines the routes for a single hostname: `ftgo-consumer-service`.
    Here’s the definition of `VirtualService` for `Consumer Service`:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `VirtualService` 定义了如何路由一个或多个主机名的请求。在这个例子中，`VirtualService` 定义了单个主机名 `ftgo-consumer-service`
    的路由。以下是 `Consumer Service` 的 `VirtualService` 定义：
- en: '[PRE15]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '***1* Applies to the Consumer Service**'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 适用于消费者服务**'
- en: '***2* Routes to Consumer Service**'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 路由到消费者服务**'
- en: '***3* The v1 subset**'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* v1 子集**'
- en: It routes all requests for the `v1` subset of the pods of `Consumer Service`.
    Later, I show more complex examples that route based on HTTP requests and load
    balance across multiple weighted destinations.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 它路由了 `Consumer Service` pod 的 `v1` 子集的所有请求。稍后，我将展示更复杂的示例，这些示例基于 HTTP 请求进行路由并在多个加权目的地之间进行负载均衡。
- en: 'In addition to `VirtualService`, you must also define a `DestinationRule`,
    which defines one or more subsets of pods for a service. A subset of pods is typically
    a service version. A `DestinationRule` can also define traffic policies, such
    as the load-balancing algorithm. Here’s the `DestinationRule` for `Consumer Service`:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 `VirtualService` 之外，还必须定义一个 `DestinationRule`，该 `DestinationRule` 定义了服务的一个或多个
    pod 子集。pod 子集通常是服务版本。`DestinationRule` 还可以定义流量策略，例如负载均衡算法。以下是 `Consumer Service`
    的 `DestinationRule`：
- en: '[PRE16]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '***1* The name of the subset**'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 子集的名称**'
- en: '***2* The pod selector for the subset**'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 子集的 pod 选择器**'
- en: 'This `DestinationRule` defines two subsets of pods: `v1` and `v2`. The `v1`
    subset selects pods with the label `version: v1`. The `v2` subset selects pods
    with the label `version: v2`.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '此 `DestinationRule` 定义了两个 pod 子集：`v1` 和 `v2`。`v1` 子集选择带有标签 `version: v1` 的
    pod。`v2` 子集选择带有标签 `version: v2` 的 pod。'
- en: 'Once you’ve defined these rules, Istio will only route traffic pods labeled
    `version: v1`. It’s now safe to deploy `v2`.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '一旦定义了这些规则，Istio 将仅路由带有 `version: v1` 标签的 pod 流量。现在可以安全地部署 `v2`。'
- en: Deploying version 2 of Consumer Service
  id: totrans-346
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 部署消费者服务的版本 2
- en: 'Here’s an excerpt of the version 2 `Deployment` for `Consumer Service`:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 `Consumer Service` 版本 2 的 `Deployment` 的摘录：
- en: '[PRE17]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '***1* Version 2**'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 版本 2**'
- en: '***2* Pod is labeled with the version**'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* Pod 带有版本标签**'
- en: 'This deployment is called `ftgo-consumer-service-v2`. It labels its pods with
    `version: v2`. After creating this deployment, both versions of the `ftgo-consumer-service`
    will be running. But because of the routing rules, Istio won’t route any traffic
    to `v2`. You’re now ready to route some test traffic to `v2`.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '此部署称为 `ftgo-consumer-service-v2`。它使用 `version: v2` 标签其 pod。创建此部署后，`ftgo-consumer-service`
    的两个版本都将运行。但由于路由规则，Istio 不会将任何流量路由到 `v2`。你现在可以开始将一些测试流量路由到 `v2`。'
- en: Routing test traffic to version 2
  id: totrans-352
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 将测试流量路由到版本 2
- en: 'Once you’ve deployed a new version of a service, the next step is to test it.
    Let’s suppose that requests from test users have a `testuser` header. We can enhance
    the `ftgo-consumer-service VirtualService` to route requests with this header
    to `v2` instances by making the following change:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 部署服务的新版本后，下一步是测试它。假设测试用户的请求有一个 `testuser` 标头。我们可以通过以下更改增强 `ftgo-consumer-service
    VirtualService`，将带有此标头的请求路由到 `v2` 实例：
- en: '[PRE18]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '***1* Matches a nonblank testuser header**'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 匹配非空 testuser 标头**'
- en: '***2* Routes test users to v2**'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将测试用户路由到 v2**'
- en: '***3* Routes everyone else to v1**'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 将所有人路由到 v1**'
- en: In addition to the original default route, `VirtualService` has a routing rule
    that routes requests with the `testuser` header to the `v2` subset. After you’ve
    updated the rules, you can now test `Consumer Service`. Then, once you feel confident
    that the v2 is working, you can route some production traffic to it. Let’s look
    at how to do that.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 除了原始的默认路由外，`VirtualService`还有一个路由规则，将带有`testuser`头部的请求路由到`v2`子集。更新规则后，你现在可以测试`Consumer
    Service`。然后，一旦你确信v2正在正常工作，你可以将一些生产流量路由到它。让我们看看如何做到这一点。
- en: Routing production traffic to version 2
  id: totrans-359
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 将生产流量路由到版本2
- en: 'After you’ve tested a newly deployed service, the next step is to start routing
    production traffic to it. A good strategy is to initially only route a small amount
    of traffic. Here, for example, is a rule that routes 95% of traffic to v1 and
    5% to v2:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试了新部署的服务之后，下一步是将生产流量开始路由到它。一个好的策略是最初只路由一小部分流量。例如，这里有一条将95%的流量路由到v1，5%路由到v2的规则：
- en: '[PRE19]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As you gain confidence that the service can handle production traffic, you can
    incrementally increase the amount of traffic going to the version 2 pods until
    it reaches 100%. At that point, Istio isn’t routing any traffic to the v1 pods.
    You could leave them running for a little while longer before deleting the version
    1 `Deployment`.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你对服务能够处理生产流量的信心增强，你可以逐步增加流向版本2 pod的流量，直到达到100%。在这个时候，Istio不再将任何流量路由到v1 pod。你可以在删除版本1的`Deployment`之前让它们运行一段时间。
- en: By letting you easily separate deployment from release, Istio makes rolling
    out a new version of a service much more reliable. Yet I’ve barely scratched the
    surface of Istio’s capabilities. As of the time of writing, the current version
    of Istio is 0.8\. I’m excited to watch it and the other service meshes mature
    and become a standard part of a production environment.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 通过让你轻松地将部署与发布分离，Istio使得推出服务的新版本变得更加可靠。然而，我对Istio的功能只是略知一二。截至写作时，Istio的当前版本是0.8。我非常期待看到它和其他服务网格成熟并成为生产环境的标准部分。
- en: 12.5\. Deploying services using the Serverless deployment pattern
  id: totrans-364
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5\. 使用无服务器部署模式部署服务
- en: The Language-specific packaging ([section 12.1](#ch12lev1sec1)), Service as
    a VM ([section 12.2](#ch12lev1sec2)), and Service as a container ([section 12.3](#ch12lev1sec3))
    patterns are all quite different, but they share some common characteristics.
    The first is that with all three patterns you must preprovision some computing
    resources—either physical machines, virtual machines, or containers. Some deployment
    platforms implement autoscaling, which dynamically adjusts the number of VMs or
    containers based on the load. But you’ll always need to pay for some VMs or containers,
    even if they’re idle.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 语言特定的打包（[第12.1节](#ch12lev1sec1)）、作为VM的服务（[第12.2节](#ch12lev1sec2)）和作为容器的服务（[第12.3节](#ch12lev1sec3)）模式都相当不同，但它们有一些共同的特征。第一个特征是，在所有三种模式中，你必须预先配置一些计算资源——无论是物理机器、虚拟机器还是容器。一些部署平台实现了自动扩展，根据负载动态调整VM或容器的数量。但即使它们处于空闲状态，你也需要为一些VM或容器付费。
- en: 'Another common characteristic is that you’re responsible for system administration.
    If you’re running any kind of machine, you must patch the operating system. In
    the case of physical machines, this also includes racking and stacking. You’re
    also responsible for administering the language runtime. This is an example of
    what Amazon called “undifferentiated heavy lifting.” Since the early days of computing,
    system administration has been one of those things you need to do. As it turns
    out, though, there’s a solution: serverless.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的特征是你需要负责系统管理。如果你在运行任何类型的机器，你必须修补操作系统。在物理机器的情况下，这也包括上架和堆叠。你还需要负责管理语言运行时。这是亚马逊所说的“无差别的重劳动”的例子。自从计算机的早期，系统管理就是那些你需要做的事情之一。然而，事实证明，有一个解决方案：无服务器。
- en: 12.5.1\. Overview of serverless deployment with AWS Lambda
  id: totrans-367
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.5.1\. 使用AWS Lambda的无服务器部署概述
- en: At AWS Re:Invent 2014, Werner Vogels, the CTO of Amazon, introduced AWS Lambda
    with the amazing phrase “magic happens at the intersection of functions, events,
    and data.” As this phrase suggests, AWS Lambda was initially for deploying event-driven
    services. It’s “magic” because, as you’ll see, AWS Lambda is an example of serverless
    deployment technology.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在2014年的AWS Re:Invent大会上，亚马逊的首席技术官Werner Vogels用一句惊人的话介绍了AWS Lambda：“在函数、事件和数据交汇处发生魔法。”正如这句话所暗示的，AWS
    Lambda最初是为了部署事件驱动的服务。它的“魔法”之处在于，正如你将看到的，AWS Lambda是服务器无部署技术的例子。
- en: '|  |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Serverless deployment technologies**'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '**无服务器部署技术**'
- en: The main public clouds all provide a serverless deployment option, although
    AWS Lambda is the most advanced. Google Cloud has Google Cloud functions, which
    as of the time writing is in beta ([https://cloud.google.com/functions/](https://cloud.google.com/functions/)).
    Microsoft Azure has Azure functions ([https://azure.microsoft.com/en-us/services/functions](https://azure.microsoft.com/en-us/services/functions)).
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 所有主要公共云都提供无服务器部署选项，尽管AWS Lambda是最先进的。Google Cloud有Google Cloud functions，截至写作时仍在测试阶段([https://cloud.google.com/functions/](https://cloud.google.com/functions/))。Microsoft
    Azure有Azure functions([https://azure.microsoft.com/en-us/services/functions](https://azure.microsoft.com/en-us/services/functions))。
- en: There are also open source serverless frameworks, such as Apache Openwhisk ([https://openwhisk.apache.org](https://openwhisk.apache.org))
    and Fission for Kubernetes ([https://fission.io](https://fission.io)), that you
    can run on your own infrastructure. But I’m not entirely convinced of their value.
    You need to manage the infrastructure that runs the serverless framework—which
    doesn’t exactly sound like *serverless*. Moreover, as you’ll see later in this
    section, serverless provides a constrained programming model in exchange for minimal
    system administration. If you need to manage infrastructure, then you have the
    constraints without the benefit.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一些开源的无服务器框架，如Apache Openwhisk([https://openwhisk.apache.org](https://openwhisk.apache.org))和针对Kubernetes的Fission([https://fission.io](https://fission.io))，您可以在自己的基础设施上运行。但我并不完全确信它们的价值。您需要管理运行无服务器框架的基础设施——这听起来并不完全像是*无服务器*。此外，正如您将在本节后面看到的那样，无服务器以最小的系统管理为代价提供了一个受限的编程模型。如果您需要管理基础设施，那么您将面临限制而没有好处。
- en: '|  |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: AWS Lambda supports Java, NodeJS, C#, GoLang, and Python. A *lambda* function
    is a stateless service. It typically handles requests by invoking AWS services.
    For example, a lambda function that’s invoked when an image is uploaded to an
    S3 bucket could insert an item into a DynamoDB IMAGES table and publish a message
    to Kinesis to trigger image processing. A lambda function can also invoke third-party
    web services.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda支持Java、NodeJS、C#、GoLang和Python。一个*lambda*函数是一个无状态服务。它通常通过调用AWS服务来处理请求。例如，当图像上传到S3存储桶时被调用的lambda函数可以将项目插入到DynamoDB的IMAGES表中，并向Kinesis发布消息以触发图像处理。lambda函数还可以调用第三方网络服务。
- en: To deploy a service, you package your application as a ZIP file or JAR file,
    upload it to AWS Lambda, and specify the name of the function to invoke to handle
    a request (also called an *event*). AWS Lambda automatically runs enough instances
    of your microservice to handle incoming requests. You’re billed for each request
    based on the time taken and the memory consumed. Of course, the devil is in the
    details, and later you’ll see that AWS Lambda has limitations. But the notion
    that neither you as a developer nor anyone in your organization need worry about
    any aspect of servers, virtual machines, or containers is incredibly powerful.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署服务，您将应用程序打包成ZIP文件或JAR文件，上传到AWS Lambda，并指定要调用的函数名称以处理请求（也称为*事件*）。AWS Lambda会自动运行足够的实例来处理传入的请求。您将根据所花费的时间和消耗的内存为每个请求付费。当然，细节才是关键，稍后您将看到AWS
    Lambda有一些限制。但您作为开发人员或您组织中的任何人都无需担心服务器、虚拟机或容器的任何方面的观念是非常强大的。
- en: '|  |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Pattern: Serverless deployment**'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '**模式：无服务器部署**'
- en: Deploy services using a serverless deployment mechanism provided by a public
    cloud. See [http://microservices.io/patterns/deployment/serverless-deployment.html](http://microservices.io/patterns/deployment/serverless-deployment.html).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 使用公共云提供的服务器无部署机制部署服务。请参阅[http://microservices.io/patterns/deployment/serverless-deployment.html](http://microservices.io/patterns/deployment/serverless-deployment.html)。
- en: '|  |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 12.5.2\. Developing a lambda function
  id: totrans-380
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.5.2. 开发lambda函数
- en: 'Unlike when using the other three patterns, you must use a different programming
    model for your lambda functions. A lambda function’s code and the packaging depend
    on the programming language. A Java lambda function is a class that implements
    the generic interface `RequestHandler`, which is defined by the AWS Lambda Java
    core library and shown in the following listing. This interface takes two type
    parameters: `I`, which is the input type, and `O`, which is the output type. The
    type of `I` and `O` depend on the specific kind of request that the lambda handles.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 与使用其他三种模式不同，您必须为 lambda 函数使用不同的编程模型。lambda 函数的代码和打包依赖于编程语言。Java lambda 函数是一个实现了
    AWS Lambda Java 核心库中定义的通用接口 `RequestHandler` 的类。该接口定义在下面的列表中。此接口接受两个类型参数：`I`，它是输入类型，`O`，它是输出类型。`I`
    和 `O` 的类型取决于 lambda 处理的特定请求类型。
- en: Listing 12.8\. A Java lambda function is a class that implements the `RequestHandler`
    interface.
  id: totrans-382
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.8\. Java lambda 函数是一个实现了 `RequestHandler` 接口的类。
- en: '[PRE20]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The `RequestHandler` interface defines a single `handleRequest()` method. This
    method has two parameters, an input object and a context, which provide access
    to the lambda execution environment, such as the request ID. The `handleRequest()`
    method returns an output object. For lambda functions that handle HTTP requests
    that are proxied by an AWS API Gateway, `I` and `O` are `APIGatewayProxyRequestEvent`
    and `APIGatewayProxyResponseEvent`, respectively. As you’ll soon see, the handler
    functions are quite similar to old-style Java EE servlets.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '`RequestHandler` 接口定义了一个单独的 `handleRequest()` 方法。此方法有两个参数，一个输入对象和一个上下文，它们提供了对
    lambda 执行环境的访问，例如请求 ID。`handleRequest()` 方法返回一个输出对象。对于由 AWS API Gateway 代理处理的
    HTTP 请求的 lambda 函数，`I` 和 `O` 分别是 `APIGatewayProxyRequestEvent` 和 `APIGatewayProxyResponseEvent`。正如您很快就会看到的，处理函数与旧式的
    Java EE servlets 非常相似。'
- en: A Java lambda is packaged as either a ZIP file or a JAR file. A JAR file is
    an uber JAR (or fat JAR) created by, for example, the Maven Shade plugin. A ZIP
    file has the classes in the root directory and JAR dependencies in the `lib` directory.
    Later, I show how a Gradle project can create a ZIP file. But first, let’s look
    at the different ways of invoking lambda function.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: Java lambda 函数打包为 ZIP 文件或 JAR 文件。JAR 文件是一个由 Maven Shade 插件等创建的超级 JAR（或胖 JAR）。ZIP
    文件在根目录中有类，在 `lib` 目录中有 JAR 依赖项。稍后，我将展示如何使用 Gradle 项目创建 ZIP 文件。但首先，让我们看看调用 lambda
    函数的不同方式。
- en: 12.5.3\. Invoking lambda functions
  id: totrans-386
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.5.3\. 调用 lambda 函数
- en: 'There are four ways to invoke a lambda function:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 lambda 函数有四种方式：
- en: HTTP requests
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP 请求
- en: Events generated by AWS services
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS 服务生成的事件
- en: Scheduled invocations
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计划调用
- en: Directly using an API call
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接使用 API 调用
- en: Let’s look at each one.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一查看。
- en: Handling HTTP requests
  id: totrans-393
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 处理 HTTP 请求
- en: One way to invoke a lambda function is to configure an AWS API Gateway to route
    HTTP requests to your lambda. The API gateway exposes your lambda function as
    an HTTPS endpoint. It functions as an HTTP proxy, invokes the lambda function
    with an HTTP request object, and expects the lambda function to return an HTTP
    response object. By using the API gateway with AWS Lambda you can, for example,
    deploy RESTful services as lambda functions.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 lambda 函数的一种方式是配置 AWS API Gateway 将 HTTP 请求路由到您的 lambda。API 网关将您的 lambda
    函数公开为 HTTPS 端点。它作为一个 HTTP 代理，使用 HTTP 请求对象调用 lambda 函数，并期望 lambda 函数返回一个 HTTP 响应对象。通过使用
    AWS Lambda 和 API 网关，您可以将 RESTful 服务作为 lambda 函数部署。
- en: Handling events generated by AWS services
  id: totrans-395
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 处理 AWS 服务生成的事件
- en: 'The second way to invoke a lambda function is to configure your lambda function
    to handle events generated by an AWS service. Examples of events that can trigger
    a lambda function include the following:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 lambda 函数的第二种方式是将您的 lambda 函数配置为处理由 AWS 服务生成的事件。可以触发 lambda 函数的事件示例包括以下内容：
- en: An object is created in an S3 bucket.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 S3 存储桶中创建一个对象。
- en: An item is created, updated, or deleted in a DynamoDB table.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 DynamoDB 表中创建、更新或删除一个条目。
- en: A message is available to read from a Kinesis stream.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以从 Kinesis 流中读取一条消息。
- en: An email is received via the Simple email service.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过简单电子邮件服务收到一封电子邮件。
- en: Because of this integration with other AWS services, AWS Lambda is useful for
    a wide range of tasks.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 由于与其他 AWS 服务的这种集成，AWS Lambda 对于广泛的任务非常有用。
- en: Defining scheduled lambda functions
  id: totrans-402
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 定义计划中的 lambda 函数
- en: Another way to invoke a lambda function is to use a Linux `cron`-like schedule.
    You can configure your lambda function to be invoked periodically—for example,
    every minute, 3 hours, or 7 days. Alternatively, you can use a `cron` expression
    to specify when AWS should invoke your lambda. `cron` expressions give you tremendous
    flexibility. For example, you can configure a lambda to be invoked at 2:15 p.m.
    Monday through Friday.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种调用 Lambda 函数的方式是使用类似 Linux `cron` 的计划。您可以配置 Lambda 函数定期调用——例如，每分钟、3小时或7天。或者，您可以使用
    `cron` 表达式来指定 AWS 应该何时调用您的 Lambda。`cron` 表达式提供了极大的灵活性。例如，您可以将 Lambda 配置为在周一至周五下午2:15调用。
- en: Invoking a lambda function using a web service request
  id: totrans-404
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用网络服务请求调用 Lambda 函数
- en: The fourth way to invoke a lambda function is for your application to invoke
    it using a web service request. The web service request specifies the name of
    the lambda function and the input event data. Your application can invoke a lambda
    function synchronously or asynchronously. If your application invokes the lambda
    function synchronously, the web service’s HTTP response contains the response
    of the lambda function. Otherwise, if it invokes the lambda function asynchronously,
    the web service response indicates whether the execution of the lambda was successfully
    initiated.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 Lambda 函数的第四种方式是您的应用程序通过网络服务请求来调用它。网络服务请求指定 Lambda 函数的名称和输入事件数据。您的应用程序可以同步或异步地调用
    Lambda 函数。如果您的应用程序同步调用 Lambda 函数，则网络服务的 HTTP 响应包含 Lambda 函数的响应。否则，如果它异步调用 Lambda
    函数，则网络服务响应指示 Lambda 执行是否成功启动。
- en: 12.5.4\. Benefits of using lambda functions
  id: totrans-406
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.5.4\. 使用 Lambda 函数的好处
- en: 'Deploying services using lambda functions has several benefits:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Lambda 函数部署服务具有以下好处：
- en: '***Integrated with many AWS services*—** It’s remarkably straightforward to
    write lambdas that consume events generated by AWS services, such as DynamoDB
    and Kinesis, and handle HTTP requests via the AWS API Gateway.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***与许多 AWS 服务集成***—**编写消费 AWS 服务生成的事件（如 DynamoDB 和 Kinesis）并通过 AWS API Gateway
    处理 HTTP 请求的 Lambda 非常简单**。'
- en: '***Eliminates many system administration tasks*—** You’re no longer responsible
    for low-level system administration. There are no operating systems or runtimes
    to patch. As a result, you can focus on developing your application.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***消除许多系统管理任务***—**您不再负责低级系统管理。没有操作系统或运行时需要修补。因此，您可以专注于开发您的应用程序**。'
- en: '***Elasticity*—** AWS Lambda runs as many instances of your application as
    are needed to handle the load. You don’t have the challenge of predicting needed
    capacity or run the risk of underprovisioning or overprovisioning VMs or containers.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***弹性***—**AWS Lambda 会根据需要运行您应用程序的实例。您不需要预测所需的容量，也不会面临虚拟机或容器配置不足或配置过量的风险**。'
- en: '***Usage-based pricing*—** Unlike a typical IaaS cloud, which charges by the
    minute or hour for a VM or container even when it’s idle, AWS Lambda only charges
    you for the resources that are consumed while processing each request.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***按使用量计费***—**与典型的 IaaS 云不同，即使虚拟机或容器空闲，IaaS 云也会按分钟或小时计费，而 AWS Lambda 只对处理每个请求时消耗的资源收费**。'
- en: 12.5.5\. Drawbacks of using lambda functions
  id: totrans-412
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.5.5\. 使用 Lambda 函数的缺点
- en: 'As you can see, AWS Lambda is an extremely convenient way to deploy services,
    but there are some significant drawbacks and limitations:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，AWS Lambda 是部署服务的一种极其方便的方式，但也有一些显著的缺点和限制：
- en: '***Long-tail latency*—** Because AWS Lambda dynamically runs your code, some
    requests have high latency because of the time it takes for AWS to provision an
    instance of your application and for the application to start. This is particularly
    challenging when running Java-based services because they typically take at least
    several seconds to start. For instance, the example lambda function described
    in the next section takes a while to start up. Consequently, AWS Lambda may not
    be suited for latency-sensitive services.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***长尾延迟***—**由于 AWS Lambda 动态运行您的代码，一些请求由于 AWS 分配您的应用程序实例和应用程序启动所需的时间而具有高延迟。这在运行基于
    Java 的服务时尤其具有挑战性，因为它们通常至少需要几秒钟才能启动。例如，下一节中描述的示例 Lambda 函数启动需要一段时间。因此，AWS Lambda
    可能不适合对延迟敏感的服务**。'
- en: '***Limited event/request-based programming model*—** AWS Lambda isn’t intended
    to be used to deploy long-running services, such as a service that consumes messages
    from a third-party message broker.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***基于事件/请求的有限编程模型***—**AWS Lambda 并不打算用于部署长时间运行的服务，例如从第三方消息代理消费消息的服务**。'
- en: Because of these drawbacks and limitations, AWS Lambda isn’t a good fit for
    all services. But when choosing a deployment pattern, I recommend first evaluating
    whether serverless deployment supports your service’s requirements before considering
    alternatives.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些缺点和限制，AWS Lambda 并不适合所有服务。但在选择部署模式时，我建议首先评估无服务器部署是否支持您服务的需求，然后再考虑其他替代方案。
- en: 12.6\. Deploying a RESTful service using AWS Lambda and AWS Gateway
  id: totrans-417
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.6\. 使用 AWS Lambda 和 AWS Gateway 部署 RESTful 服务
- en: Let’s take a look at how to deploy `Restaurant Service` using AWS Lambda. It’s
    a service that has a REST API for creating and managing restaurants. It doesn’t
    have long-lived connections to Apache Kafka, for example, so it’s a good fit for
    AWS lambda. [Figure 12.13](#ch12fig13) shows the deployment architecture for this
    service. The service consists of several lambda functions, one for each REST endpoint.
    An AWS API Gateway is responsible for routing HTTP requests to the lambda functions.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 AWS Lambda 部署 `Restaurant Service`。这是一个具有创建和管理餐厅的 REST API 的服务。例如，它没有与
    Apache Kafka 的长期连接，因此非常适合 AWS Lambda。[图 12.13](#ch12fig13) 显示了该服务的部署架构。该服务由几个
    lambda 函数组成，每个 REST 端点一个。AWS API Gateway 负责将 HTTP 请求路由到 lambda 函数。
- en: Figure 12.13\. Deploying `Restaurant Service` as AWS Lambda functions. The AWS
    API Gateway routes HTTP requests to the AWS Lambda functions, which are implemented
    by request handler classes defined by `Restaurant Service`.
  id: totrans-419
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 12.13\. 将 `Restaurant Service` 部署为 AWS Lambda 函数。AWS API Gateway 将 HTTP 请求路由到
    AWS Lambda 函数，这些函数由 `Restaurant Service` 定义的请求处理类实现。
- en: '![](Images/12fig13_alt.jpg)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig13_alt.jpg)'
- en: Each lambda function has a request handler class. The `ftgo-create-restaurant`
    lambda function invokes the `CreateRestaurantRequestHandler` class, and the `ftgo-find-restaurant`
    lambda function invokes `FindRestaurantRequestHandler`. Because these request
    handler classes implement closely related aspects of the same service, they’re
    packaged together in the same ZIP file, `restaurant-service-aws-lambda.zip`. Let’s
    look at the design of the service, including those handler classes.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 每个lambda函数都有一个请求处理类。`ftgo-create-restaurant` lambda 函数调用 `CreateRestaurantRequestHandler`
    类，而 `ftgo-find-restaurant` lambda 函数调用 `FindRestaurantRequestHandler`。由于这些请求处理类实现了同一服务的紧密相关方面，它们被打包在同一
    ZIP 文件 `restaurant-service-aws-lambda.zip` 中。让我们看看包括这些处理类在内的服务设计。
- en: 12.6.1\. The design of the AWS Lambda version of Restaurant Service
  id: totrans-422
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.6.1\. `Restaurant Service` 的 AWS Lambda 版本设计
- en: The architecture of the service, shown in [figure 12.14](#ch12fig14), is quite
    similar to that of a traditional service. The main difference is that Spring MVC
    controllers have been replaced by AWS Lambda request handler classes. The rest
    of the business logic is unchanged.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 服务架构，如图 [12.14](#ch12fig14) 所示，与传统服务的架构相当相似。主要区别是 Spring MVC 控制器已被 AWS Lambda
    请求处理类所取代。其余的业务逻辑保持不变。
- en: Figure 12.14\. The design of the AWS Lambda-based `Restaurant Service`. The
    presentation layer consists of request handler classes, which implement the lambda
    functions. They invoke the business tier, which is written in a traditional style
    consisting of a service class, an entity, and a repository.
  id: totrans-424
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 12.14\. 基于 AWS Lambda 的 `Restaurant Service` 设计。表示层由请求处理类组成，这些类实现了 lambda
    函数。它们调用业务层，业务层采用传统风格编写，包括一个服务类、一个实体和一个仓库。
- en: '![](Images/12fig14_alt.jpg)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig14_alt.jpg)'
- en: The service consists of a presentation tier consisting of the request handlers,
    which are invoked by AWS Lambda to handle the HTTP requests, and a traditional
    business tier. The business tier consists of `RestaurantService`, the `Restaurant`
    JPA entity, and `RestaurantRepository`, which encapsulates the database.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 该服务由一个表示层组成，包括请求处理程序，这些处理程序由 AWS Lambda 调用以处理 HTTP 请求，以及一个传统的业务层。业务层包括 `RestaurantService`、`Restaurant`
    JPA 实体和 `RestaurantRepository`，后者封装了数据库。
- en: Let’s take a look at the `FindRestaurantRequestHandler` class.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看 `FindRestaurantRequestHandler` 类。
- en: The FindRestaurantRequestHandler class
  id: totrans-428
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '`FindRestaurantRequestHandler` 类'
- en: The `FindRestaurantRequestHandler` class implements the `GET /restaurant/{restaurantId}`
    endpoint. This class along with the other request handler classes are the leaves
    of the class hierarchy shown in [figure 12.15](#ch12fig15). The root of the hierarchy
    is `RequestHandler`, which is part of the AWS SDK. Its abstract subclasses handle
    errors and inject dependencies.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '`FindRestaurantRequestHandler`类实现了`GET /restaurant/{restaurantId}`端点。这个类以及其他的请求处理类是[图12.15](#ch12fig15)中显示的类层次结构的叶子。层次结构的根是`RequestHandler`，它是AWS
    SDK的一部分。它的抽象子类处理错误和注入依赖项。'
- en: Figure 12.15\. The design of the request handler classes. The abstract superclasses
    implement dependency injection and error handling.
  id: totrans-430
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.15。请求处理类的设计。抽象超类实现了依赖注入和错误处理。
- en: '![](Images/12fig15.jpg)'
  id: totrans-431
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig15.jpg)'
- en: The `AbstractHttpHandler` class is the abstract base class for HTTP request
    handlers. It catches unhandled exceptions thrown during request handling and returns
    a `500 - internal server error` response. The `AbstractAutowiringHttpRequestHandler`
    class implements dependency injection for request handlers. I’ll describe these
    abstract superclasses shortly, but first let’s look at the code for `FindRestaurantRequestHandler`.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '`AbstractHttpHandler`类是HTTP请求处理程序的抽象基类。它捕获在请求处理过程中抛出的未处理异常，并返回一个`500 - 内部服务器错误`响应。`AbstractAutowiringHttpRequestHandler`类实现了请求处理程序的依赖注入。我将在稍后描述这些抽象超类，但首先让我们看看`FindRestaurantRequestHandler`的代码。'
- en: '[Listing 12.9](#ch12ex09) shows the code for the `FindRestaurantRequestHandler`
    class. The `FindRestaurantRequestHandler` class has a `handleHttpRequest()` method,
    which takes an `APIGatewayProxyRequestEvent` representing an HTTP request as a
    parameter. It invokes `RestaurantService` to find the restaurant and returns an
    `APIGatewayProxyResponseEvent` describing the HTTP response.'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表12.9](#ch12ex09) 展示了`FindRestaurantRequestHandler`类的代码。`FindRestaurantRequestHandler`类有一个`handleHttpRequest()`方法，该方法接受一个表示HTTP请求的`APIGatewayProxyRequestEvent`作为参数。它调用`RestaurantService`来查找餐厅，并返回一个描述HTTP响应的`APIGatewayProxyResponseEvent`。'
- en: Listing 12.9\. The handler class for `GET /restaurant/{restaurantId}`
  id: totrans-434
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.9。`GET /restaurant/{restaurantId}`的处理类
- en: '[PRE21]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '***1* The Spring Java configuration class to use for the application context**'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 用于应用程序上下文的Spring Java配置类**'
- en: '***2* Returns a 400 - bad request response if the restaurantId is missing or
    invalid**'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 如果缺少或无效的restaurantId，则返回400 - 错误请求响应**'
- en: '***3* Returns either the restaurant or a 404 - not found response**'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 返回餐厅或404 - 未找到响应**'
- en: As you can see, it’s quite similar to a servlet, except that instead of a `service()`
    method, which takes an `HttpServletRequest` and returns `HttpServletResponse`,
    it has a `handleHttpRequest()`, which takes an `APIGatewayProxyRequestEvent` and
    returns `APIGatewayProxyResponseEvent`.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，它与servlet非常相似，只是它没有接受`HttpServletRequest`并返回`HttpServletResponse`的`service()`方法，而是有一个`handleHttpRequest()`，它接受`APIGatewayProxyRequestEvent`并返回`APIGatewayProxyResponseEvent`。
- en: Let’s now take a look at its superclass, which implements dependency injection.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它的超类，它实现了依赖注入。
- en: Dependency injection using the AbstractAutowiringHttpRequestHandler class
  id: totrans-441
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用`AbstractAutowiringHttpRequestHandler`类进行依赖注入
- en: An AWS Lambda function is neither a web application nor an application with
    a `main()` method. But it would be a shame to not be able to use the features
    of Spring Boot that we’ve been accustomed to. The `AbstractAutowiringHttpRequestHandler`
    class, shown in the following listing, implements dependency injection for request
    handlers. It creates an `ApplicationContext` using `SpringApplication.run()` and
    autowires dependencies prior to handling the first request. Subclasses such as
    `FindRestaurantRequestHandler` must implement the `getApplicationContextClass()`
    method.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda函数既不是Web应用程序，也不是具有`main()`方法的程序。但是，如果不能使用我们习惯的Spring Boot功能，那就太遗憾了。下面的列表中显示的`AbstractAutowiringHttpRequestHandler`类实现了请求处理程序的依赖注入。它使用`SpringApplication.run()`创建一个`ApplicationContext`，并在处理第一个请求之前自动装配依赖项。例如`FindRestaurantRequestHandler`这样的子类必须实现`getApplicationContextClass()`方法。
- en: Listing 12.10\. An abstract `RequestHandler` that implements dependency injection
  id: totrans-443
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.10。实现依赖注入的抽象`RequestHandler`
- en: '[PRE22]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '***1* Creates the Spring Boot application context just once**'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 只创建一次Spring Boot应用程序上下文**'
- en: '***2* Injects dependencies into the request handler using autowiring before
    handling the first request**'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 在处理第一个请求之前使用自动装配将依赖项注入到请求处理程序中**'
- en: '***3* Returns the @Configuration class used to create ApplicationContext**'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 返回用于创建ApplicationContext的@Configuration类**'
- en: This class overrides the `beforeHandling()` method defined by `AbstractHttpHandler`.
    Its `beforeHandling()` method injects dependencies using autowiring before handling
    the first request.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 该类覆盖了 `AbstractHttpHandler` 定义的 `beforeHandling()` 方法。其 `beforeHandling()` 方法在处理第一个请求之前使用自动装配注入依赖项。
- en: The AbstractHttpHandler class
  id: totrans-449
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '`AbstractHttpHandler` 类'
- en: The request handlers for `Restaurant Service` ultimately extend `AbstractHttpHandler`,
    shown in [listing 12.11](#ch12ex11). This class implements `RequestHandler<APIGatewayProxyRequestEvent`
    and `APIGatewayProxyResponseEvent>`. Its key responsibility is to catch exceptions
    thrown when handling a request and throw a 500 error code.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '`Restaurant Service` 的请求处理器最终扩展了 `AbstractHttpHandler`，如 [列表 12.11](#ch12ex11)
    所示。该类实现了 `RequestHandler<APIGatewayProxyRequestEvent` 和 `APIGatewayProxyResponseEvent>`。其关键责任是在处理请求时捕获抛出的异常，并抛出
    500 错误代码。'
- en: Listing 12.11\. An abstract `RequestHandler` that catches exceptions and returns
    a 500 HTTP response
  id: totrans-451
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.11\. 一个捕获异常并返回 500 HTTP 响应的抽象 `RequestHandler`
- en: '[PRE23]'
  id: totrans-452
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 12.6.2\. Packaging the service as ZIP file
  id: totrans-453
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.6.2\. 将服务打包成 ZIP 文件
- en: 'Before the service can be deployed, we must package it as a ZIP file. We can
    easily build the ZIP file using the following Gradle task:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务可以部署之前，我们必须将其打包成 ZIP 文件。我们可以使用以下 Gradle 任务轻松构建 ZIP 文件：
- en: '[PRE24]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This task builds a ZIP with the classes and resources at the top level and the
    JAR dependencies in the `lib` directory.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 此任务构建一个 ZIP 文件，其中包含顶级目录中的类和资源以及 `lib` 目录中的 JAR 依赖项。
- en: Now that we’ve built the ZIP file, let’s look at how to deploy the lambda function.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了 ZIP 文件，让我们看看如何部署 Lambda 函数。
- en: 12.6.3\. Deploying lambda functions using the Serverless framework
  id: totrans-458
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12.6.3\. 使用 Serverless 框架部署 Lambda 函数
- en: Using the tools provided by AWS to deploy lambda functions and configure the
    API gateway is quite tedious. Fortunately, the Serverless open source project
    makes using lambda functions a lot easier. When using Serverless, you write a
    simple `serverless.yml` file that defines your lambda functions and their RESTful
    endpoints. Serverless then deploys the lambda functions and creates and configures
    an API gateway that routes requests to them.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 AWS 提供的工具部署 Lambda 函数和配置 API 网关相当繁琐。幸运的是，Serverless 开源项目使得使用 Lambda 函数变得更加容易。当使用
    Serverless 时，你只需编写一个简单的 `serverless.yml` 文件，该文件定义了你的 Lambda 函数及其 RESTful 端点。然后
    Serverless 部署 Lambda 函数并创建和配置一个 API 网关，将请求路由到这些函数。
- en: The following listing is an excerpt of the `serverless.yml` that deploys `Restaurant
    Service` as a lambda.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表是 `serverless.yml` 的摘录，它将 `Restaurant Service` 部署为 Lambda。
- en: Listing 12.12\. The `serverless.yml` deploys `Restaurant Service`.
  id: totrans-461
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.12\. `serverless.yml` 部署 `Restaurant Service`。
- en: '[PRE25]'
  id: totrans-462
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '***1* Tells serverless to deploy on AWS**'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 告诉无服务器在 AWS 上部署**'
- en: '***2* Supplies the service’s externalized configuration via environment variables**'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 通过环境变量提供服务的外部化配置**'
- en: '***3* The ZIP file containing the lambda functions**'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 包含 Lambda 函数的 ZIP 文件**'
- en: '***4* Lambda function definitions consisting of the handler function and HTTP
    endpoint**'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 由处理函数和 HTTP 端点组成的 Lambda 函数定义**'
- en: You can then use the `serverless deploy` command, which reads the `serverless.yml`
    file, deploys the lambda functions, and configures the AWS API Gateway. After
    a short wait, your service will be accessible via the API gateway’s endpoint URL.
    AWS Lambda will provision as many instances of each `Restaurant Service` lambda
    function that are needed to support the load. If you change the code, you can
    easily update the lambda by rebuilding the ZIP file and rerunning `serverless
    deploy`. No servers involved!
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以使用 `serverless deploy` 命令，该命令读取 `serverless.yml` 文件，部署 Lambda 函数，并配置 AWS
    API 网关。稍等片刻后，你的服务将通过 API 网关的端点 URL 可访问。AWS Lambda 将根据需要为每个 `Restaurant Service`
    Lambda 函数提供所需数量的实例以支持负载。如果你更改了代码，你可以通过重新构建 ZIP 文件并重新运行 `serverless deploy` 来轻松更新
    Lambda。无需服务器！
- en: The evolution of infrastructure is remarkable. Not that long ago, we manually
    deployed applications on physical machines. Today, highly automated public clouds
    provide a range of virtual deployment options. One option is to deploy services
    as virtual machines. Or better yet, we can package services as containers and
    deploy them using sophisticated Docker orchestration frameworks such as Kubernetes.
    Sometimes we even avoid thinking about infrastructure entirely and deploy services
    as lightweight, ephemeral lambda functions.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施的演变是显著的。不久前，我们手动在物理机上部署应用程序。今天，高度自动化的公共云提供了一系列虚拟部署选项。一个选项是将服务作为虚拟机部署。或者更好，我们可以将服务打包成容器，并使用复杂的Docker编排框架（如Kubernetes）进行部署。有时我们甚至完全不考虑基础设施，并将服务作为轻量级、短暂的lambda函数部署。
- en: Summary
  id: totrans-469
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: 'You should choose the most lightweight deployment pattern that supports your
    service’s requirements. Evaluate the options in the following order: serverless,
    containers, virtual machines, and language-specific packages.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该选择最轻量级的部署模式，以满足你的服务需求。以下顺序评估选项：无服务器、容器、虚拟机和语言特定的包。
- en: A serverless deployment isn’t a good fit for every service, because of long-tail
    latencies and the requirement to use an event/request-based programming model.
    When it is a good fit, though, serverless deployment is an extremely compelling
    option because it eliminates the need to administer operating systems and runtimes
    and provides automated elastic provisioning and request-based pricing.
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于长尾延迟和需要使用基于事件/请求的编程模型，无服务器部署并不适合每个服务。然而，当它适合时，无服务器部署是一个极具吸引力的选项，因为它消除了管理操作系统和运行时的需要，并提供了自动弹性供应和基于请求的定价。
- en: Docker containers, which are a lightweight, OS-level virtualization technology,
    are more flexible than serverless deployment and have more predictable latency.
    It’s best to use a Docker orchestration framework such as Kubernetes, which manages
    containers on a cluster of machines. The drawback of using containers is that
    you must administer the operating systems and runtimes and most likely the Docker
    orchestration framework and the VMs that it runs on.
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker容器，这是一种轻量级的、操作系统级别的虚拟化技术，比无服务器部署更灵活，并且具有更可预测的延迟。最好使用Docker编排框架，如Kubernetes，它管理机器集群上的容器。使用容器的缺点是，你必须管理操作系统和运行时，以及很可能是Docker编排框架和它运行的虚拟机。
- en: The third deployment option is to deploy your service as a virtual machine.
    On one hand, virtual machines are a heavyweight deployment option, so deployment
    is slower and it will most likely use more resources than the second option. On
    the other hand, modern clouds such as Amazon EC2 are highly automated and provide
    a rich set of features. Consequently, it may sometimes be easier to deploy a small,
    simple application using virtual machines than to set up a Docker orchestration
    framework.
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个部署选项是将你的服务作为虚拟机部署。一方面，虚拟机是一个重量级的部署选项，因此部署较慢，并且它可能比第二个选项使用更多的资源。另一方面，现代云服务如Amazon
    EC2高度自动化，并提供了一组丰富的功能。因此，有时使用虚拟机部署小型、简单的应用程序可能比设置Docker编排框架更容易。
- en: Deploying your services as language-specific packages is generally best avoided
    unless you only have a small number of services. For example, as described in
    [chapter 13](kindle_split_021.xhtml#ch13), when starting on your journey to microservices
    you’ll probably deploy the services using the same mechanism you use for your
    monolithic application, which is most likely this option. You should only consider
    setting up a sophisticated deployment infrastructure such as Kubernetes once you’ve
    developed some services.
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将你的服务作为语言特定的包部署通常最好避免，除非你只有少量服务。例如，如第13章[所述](kindle_split_021.xhtml#ch13)，当你开始你的微服务之旅时，你可能会使用与你的单体应用相同的机制来部署服务，这很可能是这个选项。一旦你开发了一些服务，你才应该考虑设置复杂的部署基础设施，如Kubernetes。
- en: One of the many benefits of using a service mesh—a networking layer that mediates
    all network traffic in and out of services—is that it enables you to deploy a
    service in production, test it, and only then route production traffic to it.
    Separating deployment from release improves the reliability of rolling out new
    versions of services.
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用服务网格——一个充当所有服务进出网络流量的中介的网络层——的许多好处之一是，它使你能够在生产中部署一个服务，测试它，然后才将生产流量路由到它。将部署与发布分离可以提高推出新版本服务的可靠性。
