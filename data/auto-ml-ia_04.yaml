- en: 3 Deep learning in a nutshell
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 深度学习概述
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The basics of building and training deep learning models
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习模型构建和训练的基本原理
- en: Using a multilayer perceptron for regression on tabular data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多层感知器对表格数据进行回归
- en: Classifying image data with a multilayer perceptron and a convolutional neural
    network
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多层感知器和卷积神经网络对图像数据进行分类
- en: Classifying text data with a recurrent neural network
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用循环神经网络对文本数据进行分类
- en: '*Deep learning*, a subfield of ML, has become a scorching topic in the AI community
    and beyond. It drives numerous applications across various fields and has achieved
    superior performance compared with many of the more traditional models introduced
    earlier. This chapter will present the basic building blocks of deep learning
    and show you how to apply three popular types of models to solve supervised learning
    tasks on different data types. The chapter will also serve as a stepping stone
    to help you better understand the AutoML methods for generating and tuning deep
    learning methods introduced in the second part of the book.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习，作为机器学习的一个子领域，已经成为人工智能社区乃至更广泛的领域的热门话题。它推动了众多领域中的应用，并且与许多早期介绍的传统模型相比，取得了优越的性能。本章将介绍深度学习的基本构建块，并展示如何将三种流行的模型类型应用于解决不同数据类型上的监督学习任务。本章还将作为垫脚石，帮助您更好地理解书中第二部分介绍的用于生成和调整深度学习方法的AutoML方法。
- en: 3.1 What is deep learning?
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 什么是深度学习？
- en: The “deep” in “deep learning” refers to the successively added *layers*, as
    shown in figure 3.1\. The number of layers stacked together is called the *depth*
    of the deep learning model. For example, the depth of the model in figure 3.1
    is four. You can think of the layers as sets of operations to transform features,
    such as multiplying the features with a matrix. The layers are jointly trained
    to perform the transformation for us instead of us performing them one by one.
    We call the output of each layer a *representation* (or *embedding*) of the original
    input. For example, the cat image on the left side of figure 3.1 is the model’s
    input. The pixel values of the image can be treated as the original representation
    of the image. The first layer of the model takes the image as input and outputs
    five different images, which are transformed representations of the original image.
    Finally, the output of layer 4 is a vector indicating that the predicted label
    of the image is “cat.”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: “深度学习”中的“深度”指的是依次添加的*层*，如图3.1所示。堆叠在一起的层数称为深度学习模型的*深度*。例如，图3.1中模型的深度是四层。您可以将层视为一系列操作，用于转换特征，例如用矩阵乘以特征。层共同训练以执行为我们进行的转换，而不是我们逐个执行。我们将每个层的输出称为原始输入的*表示*（或*嵌入*）。例如，图3.1左侧的猫图像是模型的输入。图像的像素值可以被视为图像的原始表示。模型的第1层将图像作为输入并输出五个不同的图像，这些是原始图像的转换表示。最后，第4层的输出是一个向量，表示预测的图像标签是“猫”。
- en: '![03-01](../Images/03-01.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![03-01](../Images/03-01.png)'
- en: Figure 3.1 A deep learning model for animal classification
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 用于动物分类的深度学习模型
- en: Deep learning models are often collectively called *neural networks* because
    they are mainly based on *artificial neural networks* (ANNs), a type of model
    loosely inspired by the biological architecture of the brain.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型通常统称为*神经网络*，因为它们主要基于*人工神经网络*（ANNs），这是一种从大脑的生物结构中得到启发而松散构建的模型。
- en: 'Applying deep learning in practice follows the same ML pipeline introduced
    in chapter 2\. But the following two properties of deep learning models distinguish
    them from the models introduced before:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中应用深度学习遵循第2章中介绍的相同的机器学习流程。但以下两个特性将深度学习模型与之前介绍的模型区分开来：
- en: The model structure reduces the effort of feature engineering, such as doing
    principal component analysis (PCA) for dimensionality reduction in images. The
    feature transformations learned with the layers can bring about similar effects,
    as you will see.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型结构减少了特征工程的工作量，例如在图像中进行主成分分析（PCA）以降低维度。通过层学习到的特征变换可以产生类似的效果，您将看到。
- en: Deeper models introduce more parameters to be learned and hyperparameters to
    be tuned than “shallower” models like the traditional models introduced in the
    previous chapters (such as decision trees and linear regression models) or neural
    networks with no more than two layers.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度模型比“较浅”的模型（如前几章中介绍的传统的模型，例如决策树和线性回归模型）或最多两层神经网络的模型引入了更多的学习参数和需要调整的超参数。
- en: Deep learning models offer high performance on a broad range of problems, especially
    problems with large amounts of data. This chapter will walk through three typical
    deep learning applications with code examples to help you understand these distinctions
    and the way to apply deep learning in practice. Before we get to the examples,
    though, let’s take a quick look at the tools you’ll use to implement deep learning.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型在广泛的问题上表现出高性能，尤其是在大量数据的问题上。本章将通过带有代码示例的三个典型深度学习应用来指导你理解这些区别以及如何在实践中应用深度学习。在我们进入示例之前，让我们快速了解一下你将使用的实现深度学习的工具。
- en: 3.2 TensorFlow and Keras
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 TensorFlow 和 Keras
- en: TensorFlow is an open source platform for machine learning. It has a comprehensive,
    flexible ecosystem of tools and libraries that researchers and developers can
    use to build and deploy ML-powered applications. TensorFlow implements a comprehensive
    set of math operations to run on different hardware, including CPUs, GPUs, and
    *tensor processing units* (TPUs) for deep model training. The training can scale
    up to multiple GPUs on multiple machines, and the trained model can be deployed
    in a variety of environments, like web pages and embedded systems.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 是一个开源的机器学习平台。它拥有一个全面、灵活的工具和库生态系统，研究人员和开发者可以使用它来构建和部署机器学习驱动的应用程序。TensorFlow
    实现了一套全面的数学运算，可以在不同的硬件上运行，包括 CPU、GPU 和 *张量处理单元*（TPU）用于深度模型训练。训练可以扩展到多台机器上的多个 GPU，并且训练好的模型可以在各种环境中部署，如网页和嵌入式系统。
- en: Note TPUs are dedicated hardware specially designed for *tensor* computations.
    GPUs and TPUs are heavily used in deep learning to facilitate the model training
    and inference speed.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，TPU 是专门为 *张量* 计算设计的专用硬件。GPU 和 TPU 在深度学习中被广泛使用，以促进模型训练和推理速度。
- en: 'A *tensor*, the most commonly used data type in deep learning, is an *n*-dimensional
    array. Tensors are a generalization of vectors and matrices that can have more
    than two dimensions: a vector is a one-dimensional tensor, and a matrix is a two-dimensional
    tensor. In practical terms, an RGB image can be treated as a three-dimensional
    tensor (color channel × height × width), and a video can be viewed as a four-dimensional
    tensor, where the extra dimension is the time (or frame) dimension.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*张量* 是深度学习中应用最广泛的数据类型，是一个 *n* 维数组。张量是向量和矩阵的推广，可以具有超过两个维度：向量是一维张量，矩阵是二维张量。在实践中，一个
    RGB 图像可以被视为一个三维张量（颜色通道 × 高度 × 宽度），而视频可以被视为一个四维张量，额外的维度是时间（或帧）维度。'
- en: '*Keras* is a Python library that provides a simpler set of APIs for building
    and training ML models by encapsulating the functionality of TensorFlow. It vastly
    reduces the effort required to build up deep learning algorithms and is well received
    by the community. Keras originated as a separate Python package but has been integrated
    into the TensorFlow package as a high-level API, facilitating customization, scaling,
    and deployment of deep learning models. From now on, we will mainly use the Keras
    API in TensorFlow to implement all our deep learning workflows.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*Keras* 是一个 Python 库，它通过封装 TensorFlow 的功能，提供了一套更简单的 API 来构建和训练机器学习模型。它极大地减少了构建深度学习算法所需的工作量，并且得到了社区的广泛认可。Keras
    最初作为一个独立的 Python 包出现，但后来已被集成到 TensorFlow 包中，作为一个高级 API，便于深度学习模型的定制、扩展和部署。从现在开始，我们将主要使用
    TensorFlow 中的 Keras API 来实现所有的深度学习工作流程。'
- en: 3.3 California housing price prediction with a multilayer perceptron
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3 使用多层感知器进行加利福尼亚房价预测
- en: 'The first problem we will target is one we worked on in chapter 2: the California
    housing price-prediction problem. It’s a regression problem where the aim is to
    predict the average price of a housing block based on eight features, such as
    the average number of rooms in the houses in the block. We will follow the typical
    process for creating an ML pipeline to proceed with the analysis, but I’ll skate
    over the duplicate parts and emphasize the distinct parts in the context of deep
    learning.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要解决的第一个问题是我们在第 2 章中研究过的问题：加利福尼亚房价预测问题。这是一个回归问题，目标是根据八个特征（例如，该区域房屋的平均房间数）预测一个住宅区的平均房价。我们将遵循创建机器学习管道的典型流程来进行分析，但我会跳过重复的部分，并在深度学习的背景下强调不同的部分。
- en: 3.3.1 Assembling and preparing the data
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.1 组装和准备数据
- en: We follow the same process we used earlier to collect the data using the scikit-learn
    library and prepare it for the deep learning model. The first step is to load
    the California housing dataset and split out 20% of the data for testing, as shown
    in the next listing.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循之前使用 scikit-learn 库收集数据并为其深度学习模型准备数据的过程。第一步是加载加利福尼亚住房数据集，并将 20% 的数据分割出来用于测试，如下面的列表所示。
- en: Listing 3.1 Loading and splitting the California housing dataset
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.1 加载和分割加利福尼亚住房数据集
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Loads the dataset
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 加载数据集
- en: ❷ Splits out 20% of the data for testing
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将 20% 的数据分割出来用于测试
- en: 'As we’ve seen before, the shapes of the feature matrices in the training and
    test sets are (16512, 8) and (4128, 8), respectively, as shown next:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，训练集和测试集中的特征矩阵的形状分别是 (16512, 8) 和 (4128, 8)，如下所示：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Because all the dataset features are numerical features without missing values,
    as we learned in section 2.3, the data is already suitable for feeding into a
    neural network. However, different features have different scales. This could
    be a problem in practice, causing the training process to be much slower. At worst,
    training may not *converge*, which means the optimization loss or the weights
    of the network does not settle to within an error range around the optimal value.
    Typically, the training of a neural network will stop when the weights converge.
    Otherwise, we consider the training to have failed, and the produced model often
    will not be able to work well. To deal with the different feature scales, *feature-wise
    normalization* is a good idea. We do this by subtracting the means of the features
    and dividing by their standard deviations, as shown in the following listing.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因为所有数据集的特征都是数值特征，没有缺失值，正如我们在第 2.3 节所学，数据已经适合输入到神经网络中。然而，不同的特征有不同的尺度。这在实践中可能是一个问题，会导致训练过程变得非常缓慢。在最坏的情况下，训练可能不会*收敛*，这意味着优化损失或网络的权重没有稳定在最优值周围的误差范围内。通常，当权重收敛时，神经网络的训练会停止。否则，我们考虑训练失败，产生的模型通常无法很好地工作。为了处理不同的特征尺度，*特征归一化*是一个好主意。我们通过从特征均值中减去并除以它们的标准差来实现这一点，如下面的列表所示。
- en: Listing 3.2 Performing feature-wise normalization on the training and test data
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.2 在训练和测试数据上执行特征归一化
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Defines a function to do the feature-wise normalization
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义一个函数来进行特征归一化
- en: ❷ Calculates the mean and standard deviation for each feature
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算每个特征的均值和标准差
- en: ❸ Normalizes the training and test data
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 归一化训练和测试数据
- en: 'Notice that we use the mean and std calculated for the training data to normalize
    the test data for the following two reasons:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用为训练数据计算的均值和标准差来归一化测试数据，以下两个原因：
- en: We assume the training and test data follow the same distribution.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们假设训练和测试数据遵循相同的分布。
- en: The test data may not always have enough instances for calculating trustworthy
    mean and std values.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试数据可能没有足够多的实例来计算可靠的均值和标准差值。
- en: This normalization will be the only feature engineering done in this example.
    It can also be done with shallow models, but we didn’t do it in chapter 2 because
    the optimization algorithms for linear regression and decision tree models would
    not benefit much from it. To learn more about this, see Joel Grus’s *Data Science
    from Scratch*, 2nd edition (O’Reilly, 2019).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，这种归一化将是唯一进行的特征工程。它也可以用浅层模型来完成，但我们没有在第 2 章中这样做，因为线性回归和决策树模型的优化算法不会从它那里获得太多好处。要了解更多信息，请参阅
    Joel Grus 的 *Data Science from Scratch*，第 2 版（O'Reilly，2019）。
- en: We’re now ready to create the deep learning algorithm.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好创建深度学习算法。
- en: 3.3.2 Building up the multilayer perceptron
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.2 构建多层感知器
- en: 'To implement the deep learning algorithm, let’s first import Keras in TensorFlow
    as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现深度学习算法，让我们首先在 TensorFlow 中导入 Keras，如下所示：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As a quick recap, building an ML algorithm requires you to specify four components:
    the model type, the measurement to measure the quality of the current model, the
    optimization method for updating the model weights, and the stopping criterion
    to terminate the updating process. We’ll begin with the first component and instantiate
    a three-layer neural network. We use the following code to build up the network,
    and the network structure is shown in figure 3.2.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 作为快速回顾，构建机器学习算法需要你指定四个组件：模型类型、用于衡量当前模型质量的度量、用于更新模型权重的优化方法以及用于终止更新过程的停止标准。我们将从第一个组件开始，并实例化一个三层神经网络。我们使用以下代码构建网络，网络结构如图
    3.2 所示。
- en: '![03-02](../Images/03-02.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![03-02](../Images/03-02.png)'
- en: Figure 3.2 A three-layer network
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 三层网络
- en: Listing 3.3 Creating a three-layer neural network
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.3 创建一个三层神经网络
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Creates a multilayer perceptron model with the Keras API
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用 Keras API 创建一个多层感知器模型
- en: The three layers are of the same type, known as *fully connected* or *dense*.
    The first two, which are closer to the input, are also called *hidden* *layers*.
    The last layer, for generating the predicted housing price, is called the *output*
    *layer*. The inputs and outputs of a dense layer are all tensors (*n*-dimensional
    arrays). The keras.Sequential indicates that the model we chose is a Keras model
    constructed by stacking multiple layers sequentially. A sequential model constituting
    multiple dense layers is called a *multilayer perceptron* (MLP).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这三层都是同一类型，被称为 *全连接* 或 *密集层*。前两层，离输入更近，也被称为 *隐藏层*。最后一层，用于生成预测的房价，被称为 *输出层*。密集层的输入和输出都是张量
    (*n* 维数组)。keras.Sequential 表示我们选择的模型是一个由多个层顺序堆叠构建的 Keras 模型。由多个密集层组成的顺序模型被称为 *多层感知器*
    (MLP)。
- en: 'To better understand the code, let’s dig in and see how a dense layer works.
    A dense layer can be formulated as *output* = *activation*(*dot*(*input*, *weight_matrix*)
    + *bias*). It is composed of the following three operations:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解代码，让我们深入探究一下密集层是如何工作的。密集层可以表示为 *输出* = *激活函数*(*点积*(*输入*, *权重矩阵*) + *偏置*)。它由以下三个操作组成：
- en: '*Tensor-matrix dot product*—This is a generalization of matrix-matrix multiplication.
    The tensor-matrix dot product will multiply the input tensor with a matrix (often
    called the *kernel matrix*) to convert it into a new tensor, whose last dimension
    is different from the original tensor’s. When defining the layer, we should explicitly
    define this last dimension’s shape, or the number of *units* of this layer. For
    example, in this problem each input housing block instance is a one-dimensional
    vector with eight elements. The first dense layer has 64 units. It will create
    an 8×64-weight matrix (that can be learned) to transform each input vector to
    a new vector (tensor) of length 64\. If each input sample is a three-dimensional
    tensor of size 3×10×10, by defining the dense layer with the same code, we will
    create a 20×64-weight matrix to transform the input tensor to a 3×10×64 tensor.
    The specific calculation is done in a matrix-matrix multiplication fashion, which
    means the input will be split into multiple matrices and multiplied by the weight
    matrix. We use a toy example to illustrate the calculation in figure 3.3.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*张量-矩阵点积*—这是矩阵-矩阵乘法的推广。张量-矩阵点积会将输入张量与一个矩阵（通常称为 *核矩阵*）相乘，将其转换为一个新张量，其最后一个维度与原始张量不同。在定义层时，我们应该明确定义这个最后一个维度的形状，或者这个层的
    *单元数*。例如，在这个问题中，每个输入的住房块实例是一个包含八个元素的 一维向量。第一个密集层有 64 个单元。它将创建一个 8×64 的权重矩阵（可以学习），将每个输入向量转换为一个长度为
    64 的新向量（张量）。如果每个输入样本是一个大小为 3×10×10 的三维张量，通过使用相同的代码定义密集层，我们将创建一个 20×64 的权重矩阵，将输入张量转换为一个
    3×10×64 的张量。具体的计算是以矩阵-矩阵乘法的方式进行，这意味着输入将被分成多个矩阵，并与权重矩阵相乘。我们使用一个玩具示例在图 3.3 中说明计算过程。'
- en: '*Bias addition operation*—After doing the dot product, we add a bias weight
    to each instance. The bias weight is a tensor of the same shape as the instance
    representation after the dot product. For example, in this problem, the first
    dense layer will create a learnable bias vector of shape 64.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*偏置加法操作*—在执行点积之后，我们向每个实例添加一个偏置权重。偏置权重是一个与点积后实例表示形状相同的张量。例如，在这个问题中，第一个密集层将创建一个形状为
    64 的可学习偏置向量。'
- en: '*Activation operation*—The selected activation function defines an activation
    operation. Because the concept of the neural network was originally inspired by
    neurobiology, each element in the representation (tensor) output by a layer is
    called a *neuron*. An activation function is introduced to approximate the influence
    of an extracellular field on the neuron. Equipped with the view of a neural network,
    we often choose the activation function as a nonlinear mapping function applied
    on each neuron to introduce nonlinearities in the transformation defined by each
    layer. If we use linear activations, stacking multiple linear layers will result
    in a constrained representation space with only linear transformations. Thus,
    the produced neural network would not be a universal approximator transformation.
    Some commonly used activation functions include ReLU (rectified linear unit),
    sigmoid, and tanh (hyperbolic tangent). Their shapes are shown in figure 3.4.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*激活操作*——选定的激活函数定义了一个激活操作。因为神经网络的原始概念是受神经生物学启发的，所以每一层输出的表示（张量）中的每个元素被称为一个*神经元*。引入激活函数是为了近似细胞外场对神经元的影响。从神经网络的视角来看，我们通常选择激活函数作为应用于每个神经元的非线性映射函数，以在每个层定义的转换中引入非线性。如果我们使用线性激活，堆叠多个线性层将导致一个仅包含线性变换的约束表示空间。因此，产生的神经网络将不会是一个通用逼近变换。一些常用的激活函数包括
    ReLU（修正线性单元）、sigmoid 和 tanh（双曲正切）。它们的形状如图 3.4 所示。'
- en: '![03-03](../Images/03-03.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![03-03](../Images/03-03.png)'
- en: 'Figure 3.3 Tensor dot product: A 3-D tensor multiplied by a 2-D matrix'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 张量点积：一个三维张量乘以一个二维矩阵
- en: '![03-04](../Images/03-04.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![03-04](../Images/03-04.png)'
- en: 'Figure 3.4 Three common activation functions: From left to right, ReLU, sigmoid,
    and tanh'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 三种常见的激活函数：从左到右，ReLU、sigmoid 和 tanh
- en: When instantiating a dense layer, you need to specify the shape of its output
    (number of units). If it’s the first layer, you also need to provide the shape
    of the input. This is not needed for the rest of the layers, because their input
    shape can be automatically determined from the output of the previous layers.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当实例化一个密集层时，你需要指定其输出形状（单元数）。如果是第一层，你还需要提供输入形状。对于其余的层，这不需要，因为它们的输入形状可以从前一层输出中自动确定。
- en: When applying the MLP model to the dataset, we can feed the data points in one
    at a time or provide a batch of instances at a time. The number of data points
    fed into the network at any one time is called the *batch size*. It does not need
    to be specified for the model until the data is fed into the network. The flow
    of passing inputs through a neural network to achieve outputs is called a *forward
    pass*. Let’s try out the created model now, slicing an example batch of five data
    points from the training data and doing a forward pass as shown in the next code
    listing.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当将 MLP 模型应用于数据集时，我们可以一次输入一个数据点，或者一次提供一批实例。在任何时候输入到网络中的数据点数量称为*批次大小*。在将数据输入到网络之前，不需要指定模型。通过神经网络传递输入以实现输出的流程称为*前向传递*。现在让我们尝试创建的模型，从训练数据中切片一个包含五个数据点的示例批次，并执行如下一代码列表所示的前向传递。
- en: Listing 3.4 Trying out the model with an example batch of data
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.4 使用示例数据批次尝试模型
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Slices a batch of the first five normalized data points
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 切片前五个归一化数据点
- en: ❷ Feeds the data batch into the model for predictions
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将数据批次输入模型进行预测
- en: 'Because we haven’t trained the weights in the network, the predictions are
    calculated based on randomly initialized weights in each layer. The Keras API
    provides a convenient way to visualize the output shape and weights of each layer
    in the defined model using the summary function, as shown here:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有训练网络中的权重，预测是基于每层的随机初始化权重计算的。Keras API 提供了一种方便的方法，可以使用 summary 函数可视化定义的模型中每层的输出形状和权重，如下所示：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The model can accept data batches of any size. The first dimension of the output
    shape is None in each layer because we do not predefine the number of data points
    in each batch. The model will identify the number of data points in each batch
    after they’ve been fed in. The parameters include the weight matrix in the tensor-matrix
    dot product and the bias vector. For example, the first layer has 8 * 64 + 64
    = 576 parameters. Again, these parameters are all randomly initialized before
    training, so they can not transform the features into correct predictions. But
    the exercise of checking the weight and output shape can help us debug the model
    structure. Now let’s begin to train the network and test its performance.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以接受任何大小的数据批次。每个层的输出形状的第一个维度是None，因为我们没有预先定义每个批次中的数据点数量。模型将在数据被输入后识别每个批次中的数据点数量。参数包括张量-矩阵点积中的权重矩阵和偏置向量。例如，第一层有8
    * 64 + 64 = 576个参数。再次强调，这些参数在训练之前都是随机初始化的，因此它们不能将特征转换为正确的预测。但是，检查权重和输出形状的练习可以帮助我们调试模型结构。现在让我们开始训练网络并测试其性能。
- en: 3.3.3 Training and testing the neural network
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.3 训练和测试神经网络
- en: 'Training the network requires a complete deep learning algorithm with the folowing
    three remaining components selected:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 训练网络需要一套完整的深度学习算法，并选择以下三个剩余组件：
- en: '*Optimizer*—The optimization method used to update the weights of a neural
    network.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*优化器*—用于更新神经网络权重的优化方法。'
- en: '*Loss function*—A function to measure the performance of the neural network
    and guide the optimizer during training. It usually measures the difference between
    the ground-truth values and the predicted values. For example, mean squared error
    (introduced in section 2.5) is an acceptable loss function for regression tasks.
    During training, the optimizer will try to update the weights to achieve minimum
    loss.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*损失函数*—一个用于衡量神经网络性能并在训练过程中指导优化器的函数。它通常衡量真实值和预测值之间的差异。例如，均方误差（在第2.5节中介绍）是回归任务的可接受损失函数。在训练过程中，优化器将尝试更新权重以实现最小损失。'
- en: '*Metrics*—Statistics to monitor during the training and testing process, such
    as the accuracy of a classification task. These will not affect the training process
    but will be calculated and recorded for both the training and the validation set.
    These values are used as auxiliary information to analyze and adjust the designed
    algorithm.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*指标*—在训练和测试过程中要监控的统计数据，例如分类任务的准确率。这些数据不会影响训练过程，但将被计算并记录在训练集和验证集上。这些值用作辅助信息，以分析和调整设计的算法。'
- en: What is the most commonly used optimizer in deep learning, and how does it work?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习中常用的优化器是什么，它是如何工作的？
- en: The most widely used optimization method for training neural networks is called
    *stochastic gradient descent* (SGD). The following figure illustrates how a naive
    SGD optimizer works. In this figure, the *y*-axis is the loss value of a neural
    network, and the *x*-axis represents the weights of the network to be updated.
    We consider only one weight here for the purposes of illustration. The goal of
    applying SGD is to update this singular to find the *global optimum* *point* in
    the curve, whose *y*-value corresponds to the minimum value of the loss function.
    This goal may not always be reached, depending on the hyperparameters and the
    complexity of the network. We may end up identifying an inferior point instead,
    such as the *local optimum* *point* in the figure.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 训练神经网络最广泛使用的优化方法被称为*随机梯度下降*（SGD）。以下图示说明了原始的SGD优化器是如何工作的。在这个图中，*y*轴是神经网络的损失值，*x*轴表示要更新的网络权重。为了说明目的，我们这里只考虑一个权重。应用SGD的目标是更新这个权重，以找到曲线中的*全局最优*点，其*y*值对应于损失函数的最小值。这个目标可能并不总是能达到，这取决于超参数和网络复杂性。我们可能最终识别出一个次优点，如图中的*局部最优*点。
- en: '![03-04-unnumb](../Images/03-04-unnumb.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![03-04-unnumb](../Images/03-04-unnumb.png)'
- en: Illustration of stochastic gradient descent down a 1-D loss curve (one learnable
    parameter)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 随机梯度下降在1-D损失曲线（一个可学习参数）下的示意图
- en: At every iteration, SGD uses a subset of the training data to calculate the
    gradients of the parameters by taking derivative of the loss function. The weights
    are then updated by adding the gradients to them. Usually, the gradients are not
    directly added to the weights but instead are multiplied by a value called the
    *learning rate*, which is a hyperparameter controlling the rate of updating. The
    pseudocode for this process is shown in the following listing.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次迭代中，SGD使用训练数据的一个子集通过求损失函数的导数来计算参数的梯度。然后通过将梯度加到权重上来更新权重。通常，梯度不是直接加到权重上，而是乘以一个称为*学习率*的值，这是一个控制更新速率的超参数。此过程的伪代码如下所示。
- en: Listing 3.5 Pseudocode of stochastic gradient descent
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.5 随机梯度下降的伪代码
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Each arrow in the figure indicates the changing direction of the weight at an
    iteration. Its length is the value of gradients * learning_rate. If the weight
    starts at *t*[0], it will end up at *t*[2], which is a local optimum. However,
    the weight initialized at *t'*[0] reaches the global optimum on the right side.
    As this example shows, the initialization values and the learning rate selected
    can lead to different optimization results. Variants of the naive SGD optimizer
    such as RMSprop and Adam try to increase the optimization effectiveness and efficiency,
    which is why you will see them introduced in our code implementations.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的每个箭头表示在迭代中权重的变化方向。其长度是梯度*学习率的值。如果权重从*t*[0]开始，它最终会到达*t*[2]，这是一个局部最优。然而，从*t'*[0]初始化的权重在右侧达到了全局最优。正如这个例子所示，初始化值和选择的学习率可以导致不同的优化结果。像RMSprop和Adam这样的原始SGD优化器的变体试图提高优化效果和效率，这就是为什么你会在我们的代码实现中看到它们被引入。
- en: In this example, we have only one weight to update. But because neural networks
    often have multiple layers with multiple weights in each layer, computing the
    gradients can become very complicated. The most common way of calculating the
    gradients for all the weights is called *backpropagation*. It treats the layers
    as a chain of composed functions (tensor operations) and applies the chain rule
    to calculate the gradients for the weights in each layer. The gradients of a later
    layer can be used to calculate the gradients of the previous layer, so that they
    are eventually passed back from the last layer to the first layer of the neural
    network.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们只有一个权重需要更新。但是，由于神经网络通常具有多层，每层有多个权重，计算梯度可能会变得非常复杂。计算所有权重梯度的最常见方法称为*反向传播*。它将层视为一系列组合函数（张量运算）的链，并应用链式法则来计算每层中权重的梯度。后续层的梯度可以用来计算前一层梯度，从而使它们最终从神经网络的最后一层反向传递到第一层。
- en: 'Setting the loss function, optimizer, and metrics of the deep learning algorithm
    can be done with the following one line of code:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下一行代码可以设置深度学习算法的损失函数、优化器和指标：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The compile method configures the model for training. We use the mean squared
    error (MSE) as the loss function to measure the performance of the neural network
    during training, as we did for the linear regression model in chapter 2\. The
    optimizer selected is RMSprop, which is a variant of SGD. We apply two metrics,
    mean absolute error (MAE) and MSE, to evaluate the model. We can also customize
    the configuration of the optimizer, such as the learning rate, as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 编译方法配置模型以进行训练。我们使用均方误差（MSE）作为损失函数来衡量神经网络在训练过程中的性能，正如我们在第2章中为线性回归模型所做的那样。选择的优化器是RMSprop，它是SGD的一种变体。我们应用两个指标，平均绝对误差（MAE）和MSE，来评估模型。我们还可以自定义优化器的配置，例如学习率，如下所示：
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After preparing the network for training, we can feed the data to it with the
    fit method like so:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在为训练准备网络后，我们可以使用fit方法如下向其提供数据：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The training process will terminate based on predefined stopping criteria, such
    as the number of *epochs* to train for. Because the inputs are split into batches
    (1,024 per batch here), an epoch in this case means feeding all the batches into
    the neural network and updating its weights once. For example, if we have 100
    examples for training and the batch size is 1, an epoch equals 100 iterations
    of model update.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程将根据预定义的停止标准终止，例如训练的*epochs*数量。因为输入被分成批次（这里每个批次1,024个），在这种情况下，一个epoch意味着将所有批次输入神经网络并更新其权重一次。例如，如果我们有100个训练示例，批大小为1，那么一个epoch等于模型更新的100次迭代。
- en: Recapping the general learning process of ML introduced in chapter 1, a counterpart
    workflow for training a neural network is depicted in figure 3.5\. Given a batch
    of input data, the loss function will measure the accuracy of the current network’s
    predictions by comparing them to the targets. The optimizer will take the feedback
    from the loss function and use it to update the network’s weights in each layer.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾第 1 章中介绍的机器学习的一般学习过程，训练神经网络的对应工作流程如图 3.5 所示。给定一批输入数据，损失函数将通过将当前网络的预测与目标进行比较来衡量当前网络的预测准确性。优化器将根据损失函数的反馈来更新网络中每一层的权重。
- en: '![03-05](../Images/03-05.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![03-05](../Images/03-05.png)'
- en: Figure 3.5 The workflow of training a neural network (converted from the general
    ML training workflow)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5 训练神经网络的流程（从通用机器学习训练流程转换而来）
- en: 'To test the trained network, we can call the evaluate function. Our model trained
    for 300 epochs reaches an MSE of 0.34 on the test set, as shown in the following
    code snippet:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试训练好的网络，我们可以调用 evaluate 函数。我们的模型经过 300 轮训练后，在测试集上达到 MSE 0.34，如下代码片段所示：
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We have successfully trained and tested our first deep learning model. The next
    step is to tune the hyperparameters to see if we can improve its performance.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功训练并测试了我们的第一个深度学习模型。下一步是调整超参数，看看我们是否可以提高其性能。
- en: 3.3.4 Tuning the number of epochs
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.4 调整训练轮数
- en: Tuning a deep learning algorithm is crucial to improving its performance, but
    it is often a time-consuming and expensive process because a deep neural network
    contains many hyperparameters (number of layers, layer types, number of units,
    and so on). The learning process is often treated as a black box, without many
    theoretical guarantees being discovered in the existing literature. Here, we take
    the simple example of tuning the number of epochs using a holdout validation set.
    The tuning of more complex hyperparameters, such as the number of layers and the
    number of units in the layers, will be introduced in later chapters using advanced
    AutoML tools.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 调整深度学习算法对于提高其性能至关重要，但这个过程通常既耗时又昂贵，因为深度神经网络包含许多超参数（层数、层类型、单元数等）。学习过程通常被视为一个黑盒，现有文献中很少发现理论保证。在这里，我们以使用留出验证集调整训练轮数（epochs）的简单例子为例。更复杂的超参数调整，如层数和层中单元数，将在后续章节中介绍，使用高级的
    AutoML 工具。
- en: As shown in listing 3.6, we split off 20% of the data to use as the validation
    set and use holdout cross-validation to decide the number of epochs. We train
    the neural network for a high number of epochs, save the training history into
    a pandas DataFrame, and plot the MSE curves by epoch for both the training and
    validation sets.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如列表 3.6 所示，我们将 20% 的数据分割出来作为验证集，并使用留出交叉验证来确定训练轮数（epochs）。我们训练神经网络以高轮数进行，将训练历史保存到
    pandas DataFrame 中，并按轮数绘制训练和验证集的 MSE 曲线。
- en: Listing 3.6 Validating the MLP model with holdout cross-validation
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.6 使用留出交叉验证验证 MLP 模型
- en: '[PRE12]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Creates a function to help repeatedly build fresh compiled models
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个函数来帮助反复构建新的编译模型
- en: ❷ Creates a new compiled model
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建一个新的编译模型
- en: ❸ Holds out 20% of the data for validation during training
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在训练过程中留出 20% 的数据用于验证
- en: ❹ Retrieves the history into a DataFrame—history.history is a dictionary containing
    the loss, MAE, and MSE results at each epoch on both training and validation sets.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将历史数据检索到 DataFrame 中——history.history 是一个字典，包含每个轮次在训练和验证集上的损失、平均绝对误差（MAE）和
    MSE 结果。
- en: ❺ Appends an epoch column to the DataFrame for plotting purposes
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 为绘图目的向 DataFrame 添加一个轮数列
- en: ❻ Plots the training and validation MSE curves
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 绘制训练和验证 MSE 曲线
- en: The training and validation MSE curves are shown in figure 3.6.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和验证均方误差（MSE）曲线显示在图 3.6 中。
- en: '![03-06](../Images/03-06.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![03-06](../Images/03-06.png)'
- en: Figure 3.6 Training and validation MSE by epoch
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6 按轮数显示的训练和验证 MSE
- en: It’s not easy to interpret these curves due to the scale variation and the fluctuation
    between epochs, especially when the number of epochs is large. Using the code
    in listing 3.7, we can limit the *y*-axis to values below 0.5 to zoom in and smooth
    the training and validation curves with Gaussian smoothing (see Shapiro and Stockman,
    *Computer Vision*, Prentice Hall, 2001, pp. 137, 150).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于尺度变化和轮次间的波动，这些曲线的解释并不容易，尤其是在轮数较多的情况下。使用列表 3.7 中的代码，我们可以将 *y*-轴限制在 0.5 以下，以便放大并使用高斯平滑来平滑训练和验证曲线（参见
    Shapiro 和 Stockman 的 *Computer Vision*，Prentice Hall，2001，第 137、150 页）。
- en: Listing 3.7 Smoothing the accuracy curves
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.7 平滑准确率曲线
- en: '[PRE13]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Smoothes a list of values with a Gaussian smoothing function
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用高斯平滑函数对一系列值进行平滑处理
- en: The adjusted plot is shown in figure 3.7\. It shows that the training MSE continues
    decreasing during the 500 epochs. In comparison, the validation MSE displays an
    increased tendency to fluctuate after around 150 epochs. This means that the network
    tends to overfit the training data after about 150 epochs.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 调整后的图示如图3.7所示。它显示在500个轮次期间，训练MSE持续下降。相比之下，验证MSE在约150个轮次后显示出增加的波动趋势。这意味着网络在约150个轮次后倾向于过拟合训练数据。
- en: '![03-07](../Images/03-07.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![03-07](../Images/03-07.png)'
- en: Figure 3.7 Training and validation MSE by epoch (smoothed), with the *y*-axis
    limited to values below 0.5
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 每个轮次的训练和验证MSE（平滑），y轴限制在0.5以下
- en: With the optimal number of epochs selected, we can now retrain the model on
    the full dataset (training and validation sets) and do the testing, as shown in
    the next code listing.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择了最佳轮数后，我们现在可以在完整的数据集（训练集和验证集）上重新训练模型并进行测试，如下面的代码列表所示。
- en: Listing 3.8 Retraining the final model on the full training set
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.8 在完整训练集上重新训练最终模型
- en: '[PRE14]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The final MSE for the test set is 0.31, which is better than we achieved with
    the model trained for 300 epochs, as shown here:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集的最终均方误差（MSE）为0.31，这比我们用训练了300个轮次的模型所达到的结果要好，如下所示：
- en: '[PRE15]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In this example, we trained the model only once to select the best number of
    epochs. Tuning other hyperparameters may require some trial and error. For example,
    you can use the grid search method to tune the depth of the network—that is, build
    up multiple MLPs with different numbers of layers and try them on the same split
    of training and validation sets to select the optimal network depth. We’ll introduce
    more convenient ways to implement this in the second part of the book.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们只训练了模型一次以选择最佳的轮数。调整其他超参数可能需要一些尝试和错误。例如，你可以使用网格搜索方法来调整网络的深度——即构建多个具有不同层数的MLP，并在相同的训练和验证集分割上尝试它们，以选择最佳的网络深度。我们将在本书的第二部分介绍更方便的实现方法。
- en: We have now built our first deep neural network, an MLP, to address a tabular
    data regression problem. In the next two sections, you will learn about two more
    deep learning models that you can use to address classification problems with
    image data and text data, respectively.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经构建了我们第一个深度神经网络，一个MLP，来解决表格数据回归问题。在接下来的两个部分中，你将了解另外两种深度学习模型，你可以使用它们分别解决图像数据和文本数据的分类问题。
- en: 3.4 Classifying handwritten digits with convolutional neural networks
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.4 使用卷积神经网络对手写数字进行分类
- en: In this section, we will explore a new model, the *convolutional neural network*
    (CNN), which is the dominant deep learning model in computer vision applications.
    We’ll use handwritten digit classification to explain how it works and build an
    MLP network for comparison.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨一种新的模型，即*卷积神经网络*（CNN），它是计算机视觉应用中占主导地位的深度学习模型。我们将通过手写数字分类来解释其工作原理，并构建一个MLP网络进行比较。
- en: 3.4.1 Assembling and preparing the dataset
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.1 组装和准备数据集
- en: Let’s first collect the dataset and make a few preparations. In chapter 1, we
    used a dataset that comes with scikit-learn containing 1,797 8×8-pixel images
    of handwritten digits. In this example, we’ll use a similar but larger dataset
    called *MNIST*, which is commonly used as a starter kit for deep learning. It
    contains 60,000 training images and 10,000 testing images collected by the National
    Institute of Standards and Technology (NIST). Each image is of size 28×28 and
    is labeled with a number from 0 to 9\. The dataset can be assembled with the Keras
    API, as shown in the following listing.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先收集数据集并做一些准备工作。在第一章中，我们使用了scikit-learn附带的数据集，其中包含1797张8×8像素的手写数字图像。在这个例子中，我们将使用一个类似但更大的数据集，称为*MNIST*，它通常用作深度学习的入门套件。它包含由国家标准与技术研究院（NIST）收集的60,000张训练图像和10,000张测试图像。每个图像的大小为28×28，并标记为0到9的数字。该数据集可以使用Keras
    API组装，如下面的列表所示。
- en: Listing 3.9 Loading the MNIST dataset with TensorFlow Keras API
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.9 使用TensorFlow Keras API加载MNIST数据集
- en: '[PRE16]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The loaded data is already split into training and test sets. The images and
    labels are in the form of NumPy arrays. Let’s take a look at the training and
    test data in the next listing.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 加载的数据已经分为训练集和测试集。图像和标签以NumPy数组的形式存在。让我们在下一个列表中查看训练和测试数据。
- en: Listing 3.10 Exploring the shape of the training and test data
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.10 探索训练和测试数据的形状
- en: '[PRE17]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We can also visualize a sample image using the following code.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用以下代码可视化一个样本图像。
- en: Listing 3.11 Visualizing a training image
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.11 可视化训练图像
- en: '[PRE18]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In figure 3.8, we can see that the values of each pixel in the image range from
    0 to 255, and the label of the image is 5.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在图3.8中，我们可以看到图像中每个像素的值范围从0到255，图像的标签是5。
- en: '![03-08](../Images/03-08.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![03-08](../Images/03-08.png)'
- en: Figure 3.8 A training sample in MNIST
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 MNIST中的一个训练样本
- en: Similar to the normalization we did in the previous problem, we can normalize
    the image by rescaling the values of the pixels to the range of 0 to 1\. We use
    a normalization method called *min-max rescaling* in listing 3.12\. It rescales
    the pixel values by dividing them by the difference between the maximum possible
    value (255) and the minimum possible value (0). The normalization methods we use
    here and in the previous example are quite common in deep learning to improve
    the effectiveness of the learning algorithm.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在上一个问题中进行的归一化类似，我们可以通过调整像素值的范围到0到1之间来归一化图像。在列表3.12中，我们使用了一种称为*最小-最大缩放*的归一化方法。这种方法通过将像素值除以最大可能值（255）和最小可能值（0）之间的差值来缩放像素值。我们在这里和上一个例子中使用归一化方法在深度学习中相当常见，以提高学习算法的有效性。
- en: Listing 3.12 Rescaling the image
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.12 缩放图像
- en: '[PRE19]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: After preparing the data, we can start to build the network. Before we create
    our first CNN, let’s build an MLP that we can use as a baseline model for comparison.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备数据之后，我们可以开始构建网络。在我们创建第一个CNN之前，让我们构建一个MLP，我们可以将其用作基准模型进行比较。
- en: 3.4.2 Addressing the problem with an MLP
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.2 使用MLP解决问题
- en: We know that an MLP model is composed of multiple dense (fully connected) layers,
    where the dot product in each layer is applied between the last axis of the input
    tensor and the kernel matrix. To make sure the first layer computes the dot product
    using all the features of an image, we can first convert each 28×28 image to a
    1×784 vector with a Keras layer called Flatten. We’ll stack it with two Dense
    layers to create a joint pipeline. Figure 3.9 provides a visual illustration of
    the Flatten layer.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道MLP模型由多个密集（全连接）层组成，其中每一层的点积应用于输入张量的最后一个轴和核矩阵。为了确保第一层使用图像的所有特征来计算点积，我们可以首先使用Keras的Flatten层将每个28×28的图像转换为1×784的向量。我们将它与两个Dense层堆叠以创建一个联合管道。图3.9提供了Flatten层的视觉说明。
- en: '![03-09](../Images/03-09.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![03-09](../Images/03-09.png)'
- en: Figure 3.9 Reshape the 2-D image to a 1-D vector (with a Keras Flatten layer)
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9 使用Keras Flatten层将2-D图像重塑为1-D向量
- en: The code for building the MLP is shown in the following listing.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 构建MLP的代码如下所示。
- en: Listing 3.13 Building an MLP for MNIST handwritten digit classification
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.13 为MNIST手写数字分类构建MLP
- en: '[PRE20]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The flattening layer takes the shape of an image as input, and it does not
    have any weights to be learned. You may have noticed the following main differences
    by comparing this MLP to the one we built up in the previous regression task:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 展平层接受图像的形状作为输入，并且没有需要学习的权重。通过比较这个MLP与我们之前构建的回归任务中的MLP，你可能已经注意到了以下主要区别：
- en: In the previous model, we set the units in the output layer to 1, to output
    a predicted housing price. In this multiclass classification problem, the number
    of units of the last dense layer is 10, to align with the number of classes for
    classification purposes (0-9). The 10 values output by the last dense layer are
    called *logits*.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在先前的模型中，我们将输出层的单元数设置为1，以输出预测的房价。在这个多类分类问题中，最后一个密集层的单元数是10，以与分类目的的类别数（0-9）相匹配。最后一个密集层输出的10个值称为*logits*。
- en: We do not apply the activation function in the last dense layer but add a layer
    called Softmax layer at the end, which applies a *softmax function* to transform
    the 10 logits into the probabilities of the input belonging to each class to perform
    the final prediction. The image will be assigned to the class with the highest
    transformed probability. The softmax function can be written as ![03-09-EQ01](../Images/03-09-EQ01.png),
    where *c* is the number of classes. *y[i]* indicates the logits. There is no parameter
    to be learned in the Softmax layer, and the shapes of its input and output are
    the same. The Softmax layer can also be treated as the activation function of
    the last dense layer, which allows us to write the model specification more concisely,
    as shown next.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在最后一个密集层中不应用激活函数，而是在最后添加一个名为Softmax层的层，该层应用 *softmax函数* 将10个logits转换为输入属于每个类的概率，以执行最终预测。图像将被分配给具有最高转换概率的类别。softmax函数可以表示为
    ![03-09-EQ01](../Images/03-09-EQ01.png)，其中 *c* 是类别的数量。*y[i]* 表示logits。Softmax层没有需要学习的参数，其输入和输出的形状相同。Softmax层也可以被视为最后一个密集层的激活函数，这允许我们更简洁地编写模型规范，如下所示。
- en: Listing 3.14 The same MLP structure with a softmax activation for the output
    dense layer
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.14 具有softmax激活输出密集层的相同MLP结构
- en: '[PRE21]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We can now compile the model for training by specifying the loss function, optimizer,
    and some evaluation metrics to be retrieved, as shown here.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过指定损失函数、优化器和一些要检索的评估指标来编译用于训练的模型，如下所示。
- en: Listing 3.15 Compiling the MLP model
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.15 编译MLP模型
- en: '[PRE22]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We use classification accuracy as the evaluation metric. The adam optimizer
    is selected, which is a variant of the sgd optimizer. Both adam and rmsprop are
    commonly used optimization schemes, and you can try out different schemes to select
    the most suitable one based on its performance. The loss function is a type of
    cross-entropy loss, which measures the distance between two discrete probability
    distributions. Here it measures the difference between the predicted probabilities
    of images belonging to each of the 10 classes and the ground-truth probabilities.
    The ground-truth probabilities will be 1 for the correct label of the image and
    0 for all the other labels. Note that we use SparseCategoricalCrossentropy in
    listing 3.15, which requires the input labels to be integers (0-9 in this example).
    If you want to use a *one-hot* representation of the ground-truth labels—for example,
    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] for the label 2—you should use tf.keras.losses.CategoricalCrossentropy.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用分类准确率作为评估指标。选择adam优化器，它是sgd优化器的一种变体。adam和rmsprop都是常用的优化方案，你可以尝试不同的方案，根据其性能选择最合适的一个。损失函数是一种交叉熵损失，它衡量两个离散概率分布之间的距离。在这里，它衡量的是属于每个10个类别的图像预测概率与真实概率之间的差异。真实概率将为图像的正确标签为1，其他所有标签为0。请注意，我们在列表3.15中使用SparseCategoricalCrossentropy，它要求输入标签为整数（本例中的0-9）。如果你想使用真实标签的
    *one-hot* 表示——例如，标签2的表示为[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]——你应该使用tf.keras.losses.CategoricalCrossentropy。
- en: 'Let’s fit the network and check its performance. Here, we train the network
    for five epochs with 64 images fed into the network in each training batch (the
    number of epochs and batch size can be tuned):'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们拟合网络并检查其性能。在这里，我们以64张图像每个训练批次输入网络的方式训练网络五个周期（周期数和批量大小可以调整）：
- en: '[PRE23]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The test accuracy is 97.57%, meaning that the MLP network could classify approximately
    98 of 100 images correctly, which is not bad.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 测试准确率为97.57%，这意味着MLP网络能够正确分类大约98张中的100张图像，这还不错。
- en: 3.4.3 Addressing the problem with a CNN
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.3 使用CNN解决问题
- en: In this section, we introduce a CNN model to solve the problem. The core idea
    of CNNs is to extract some local patterns, such as the edges, arcs, and textures
    in an image, and gradually condense them into more complex patterns layer by layer,
    such as *arcs, edges* → *tire* and *headlight* → *car*.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍一个卷积神经网络（CNN）模型来解决该问题。CNN的核心思想是提取一些局部模式，例如图像中的边缘、弧线和纹理，并逐层将这些模式逐渐浓缩成更复杂的模式，例如
    *弧线、边缘* → *轮胎* 和 *车灯* → *汽车*。
- en: 'To achieve this goal, in addition to dense layers, a simple CNN often contains
    two more types of layers: the *convolutional layer* and the *pooling layer*. Let’s
    first build the CNN and then examine the two layers by looking at the shapes of
    their input and output tensors. The code for creating a simple CNN is shown next.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这个目标，除了密集层之外，一个简单的CNN通常还包含两种其他类型的层：*卷积层*和*池化层*。让我们首先构建CNN，然后通过查看它们输入和输出张量的形状来检查这两个层。创建简单CNN的代码如下。
- en: Listing 3.16 Building a simple CNN model
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.16 构建简单的CNN模型
- en: '[PRE24]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: ❶ Builds up the CNN model structure
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建CNN模型结构
- en: ❷ Compiles the model for training
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 编译模型以进行训练
- en: 'After the Flatten layer, the network structure is the same as with a simple
    MLP, apart from the difference in the number of units. The first five layers consist
    of three convolutional layers interleaved with two pooling layers. They’re all
    two-dimensional layers aiming to extract the spatial characteristics of an image.
    Before introducing the specific operations, let’s display the shapes of the inputs
    and outputs for each layer here:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在Flatten层之后，网络结构与简单的MLP相同，除了单元数量不同。前五个层由三个卷积层和两个池化层交替组成。它们都是二维层，旨在提取图像的空间特征。在介绍具体操作之前，让我们在这里显示每个层的输入和输出形状：
- en: '[PRE25]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Regardless of the first batch-size dimension, a convolutional layer takes inputs
    of three dimensions (height, width, channels) and outputs a three-dimensional
    tensor, which we often call a *feature map*. The first two dimensions are the
    spatial dimensions indicating the size of the image (28×28 for MNIST images).
    The last dimension denotes the number of channels in the feature map. For the
    original input image, the channel dimension is the number of color channels. For
    example, an RGB image has three channels: red, blue, and green. A grayscale image,
    like those in the MNIST dataset, has only one channel.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 无论第一个批量大小维度如何，卷积层都接受三个维度的输入（高度、宽度、通道）并输出一个三维张量，我们通常称之为*特征图*。前两个维度是空间维度，表示图像的大小（MNIST图像为28×28）。最后一个维度表示特征图中的通道数。对于原始输入图像，通道维度是颜色通道的数量。例如，RGB图像有三个通道：红色、蓝色和绿色。像MNIST数据集中的图像这样的灰度图像只有一个通道。
- en: How the convolutional layer works
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层是如何工作的
- en: When instantiating a convolutional layer, we need to specify two main arguments.
    The first is the number of filters (or kernels), which determines the number of
    channels (size of the last dimension) in the output feature map. The second argument
    is the size of each filter. A *filter* is a trainable tensor that tries to discover
    a certain pattern in the input feature map. It scans through the input feature
    map and outputs a matrix indicating where in the inputs the target feature appears.
    By aggregating the output matrices of different filters, we get the output feature
    map of the convolutional layer. Each channel in the output feature map is generated
    from a unique filter. Using the first convolutional layer in listing 3.16 as an
    example, we set its channel to 32, and the size of each filter is 3×3×1\. Each
    of the filters will generate a 26×26 matrix (I’ll explain why later). Because
    we have 32 filters, they will generate 32 26×26 matrices, which together compose
    the output feature map of shape (26, 26, 32). The number of trainable weights
    in a convolutional layer is equal to the sum of the number of elements in the
    filters plus the channel number (the length of the bias vector). For example,
    in the first convolutional layer, there are 3 * 3 * 32 + 32 = 320 parameters to
    be learned.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在实例化卷积层时，我们需要指定两个主要参数。第一个是滤波器（或核）的数量，它决定了输出特征图中的通道数（最后一个维度的尺寸）。第二个参数是每个滤波器的大小。*滤波器*是一个可训练的张量，它试图在输入特征图中发现某种模式。它扫描输入特征图，并输出一个矩阵，指示目标特征出现在输入中的位置。通过聚合不同滤波器的输出矩阵，我们得到卷积层的输出特征图。输出特征图中的每个通道都是由一个独特的滤波器生成的。以列表3.16中的第一个卷积层为例，我们将其通道数设置为32，每个滤波器的大小为3×3×1。每个滤波器将生成一个26×26的矩阵（我稍后会解释原因）。因为我们有32个滤波器，所以它们将生成32个26×26的矩阵，这些矩阵共同构成了形状为（26,
    26, 32）的输出特征图。卷积层中的可训练权重数量等于滤波器中元素数量的总和加上通道数（偏置向量的长度）。例如，在第一个卷积层中，有3 * 3 * 32
    + 32 = 320个参数需要学习。
- en: Now let’s see how a three-dimensional filter transforms a three-dimensional
    input feature map into another three-dimensional feature map and how to calculate
    the shape of the output feature map. We’ll use a 4×4×1 input feature map with
    filter size 3×3 as an example (see figure 3.10). The filter walks step-by-step
    through the feature map. We can also specify the step size, called the *stride*.
    Here we assume the step size is one, which means a 3×3×1 filter has to take two
    steps to go either horizontally or vertically through the 4×4×1 feature map. At
    each step, it will cover a region in the input feature map of the same size as
    itself and do a convolution operation (this is where the name of the convolutional
    layer comes from).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一个三维滤波器如何将一个三维输入特征图转换成另一个三维特征图，以及如何计算输出特征图的形状。我们将使用一个4×4×1的输入特征图和大小为3×3的滤波器作为例子（见图3.10）。滤波器会逐步遍历特征图。我们还可以指定步长，称为*步长*。在这里，我们假设步长为1，这意味着一个3×3×1的滤波器必须水平或垂直移动两步才能通过4×4×1特征图。在每一步中，它将覆盖与自身大小相同的输入特征图区域并执行卷积操作（这就是卷积层名称的由来）。
- en: '![03-10](../Images/03-10.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![03-10](../Images/03-10.png)'
- en: Figure 3.10 Convolution operation between one 4×4×1 feature map and one 3×3×1
    filter with stride 1 to produce a 2×2×1 feature map
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 4×4×1特征图与3×3×1滤波器进行步长为1的卷积操作，生成2×2×1特征图
- en: Mathematically, at each step, it first does an element-wise multiplication between
    the covered feature map and the filter. This will result in a three-dimensional
    tensor of the same size as the filter. Then it sums up all the elements in the
    tensor into a single value. By walking through the input feature map, we will
    achieve a matrix (or a three-dimensional tensor if we take the channel axis into
    account). The size of this matrix is decided by both the filter size and the stride.
    Generally, the size of the output feature map is equal to the number of valid
    steps that the stride can take. For example, in figure 3.11, we will achieve a
    matrix of 2×2 because the stride can take two valid steps along both the height
    and width dimensions. Similarly, in the MNIST example, each 3×3 filter can take
    26 steps along each dimension, transforming a 28×28 image into a 26×26 feature
    map.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，在每一步中，它首先在覆盖的特征图和滤波器之间进行逐元素乘法。这将产生一个与滤波器大小相同的三个维度的张量。然后，它将张量中的所有元素加起来得到一个单一值。通过遍历输入特征图，我们将得到一个矩阵（或者如果我们考虑通道轴，则是一个三维张量）。这个矩阵的大小由滤波器大小和步长共同决定。通常，输出特征图的大小等于步长可以采取的有效步数的数量。例如，在图3.11中，我们将得到一个2×2的矩阵，因为步长可以在高度和宽度维度上采取两个有效的步数。同样，在MNIST示例中，每个3×3滤波器可以在每个维度上移动26步，将28×28的图像转换成26×26的特征图。
- en: If we set stride=(2,2) when defining the Conv2D layer, each filter will take
    two steps along each dimension. Suppose we define the filter size as (3, 3) and
    have a 4×4 input feature map. There is no room for the filter to take two steps
    vertically and horizontally, and some pixels along the borders cannot be covered
    and considered, as shown in figure 3.11\. If we set the stride to be (1, 1), the
    filter will be able to take two steps along each dimension. However, the pixels
    on the boundaries will be considered in fewer steps than the ones in the middle.
    This is called the *border effect*.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在定义Conv2D层时将步长设置为(2,2)，则每个滤波器将沿着每个维度移动两步。假设我们将滤波器大小定义为(3, 3)并有一个4×4的输入特征图。滤波器在垂直和水平方向上无法移动两步，边界上的一些像素无法覆盖并考虑，如图3.11所示。如果我们将步长设置为(1,
    1)，滤波器将能够沿着每个维度移动两步。然而，边界上的像素在较少的步数中被考虑，这被称为*边界效应*。
- en: '![03-11](../Images/03-11.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![03-11](../Images/03-11.png)'
- en: Figure 3.11 Convolution without padding
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11 无填充的卷积
- en: To help the filter achieve full coverage of the feature map, we can extend the
    boundaries of the input feature by adding zeros around its edges. This *padding*
    will add rows and columns as appropriate to ensure the pixels are considered equally
    (in both convolutional and pooling layers). For example, as shown in figure 3.12,
    adding one column or row along each edge allows a 3×3 filter to keep the shape
    of the 4×4 input feature map when the stride is (1, 1). Each pixel in the padded
    feature map will be considered in the same number of steps in the convolution
    operation.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助过滤器实现特征图的全覆盖，我们可以通过在其边缘添加零来扩展输入特征的范围。这种*填充*将根据需要添加行和列，以确保像素被同等考虑（在卷积层和池化层中）。例如，如图3.12所示，在每个边缘添加一列或一行允许3×3的过滤器在步长为(1,
    1)时保持4×4输入特征图的形状。填充特征图中的每个像素在卷积操作中将被考虑相同数量的步骤。
- en: '![03-12](../Images/03-12.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![03-12](../Images/03-12.png)'
- en: Figure 3.12 Comparison of output dimensions without and with padding of the
    input feature maps with zeros
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 比较了带零填充和不带零填充的输入特征图的输出维度
- en: How the pooling layer works
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层的工作原理
- en: 'Now let’s talk about pooling. Figure 3.13 shows how a pooling layer works.
    This kind of layer is used to reduce the size of a feature map along the spatial
    dimension for the following two purposes:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来谈谈池化。图3.13展示了池化层是如何工作的。这类层用于在空间维度上减小特征图的大小，以达到以下两个目的：
- en: To reduce the computational complexity and the number of parameters to be learned
    in the later layers (especially the fully connected layers whose weight sizes
    correspond to the input sizes).
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了降低计算复杂度和后续层（尤其是权重大小与输入大小相对应的全连接层）中需要学习的参数数量。
- en: To maintain scale, rotation, and translation invariance while reducing the size
    of the feature map. In figure 3.13, each small piece of the image is not scaled
    or rotated after passing the pooling layer. They are aggregated into a coarse
    image that keeps the meaning of the original one.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在减小特征图尺寸的同时，保持尺度、旋转和平移不变性。在图3.13中，图像的每个小块在通过池化层后不会进行缩放或旋转。它们被聚合成一个粗略的图像，保持了原始图像的意义。
- en: '![03-13](../Images/03-13.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![03-13](../Images/03-13.png)'
- en: Figure 3.13 Pooling can keep the image properties invariant to a certain extent.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13 池化可以在一定程度上保持图像属性的不变性。
- en: Pooling layers conduct similar operations to convolutional layers but do not
    have any filters (kernels) to learn. The convolution operation is replaced by
    a particular hardcoded operation such as the max operation in the MaxPooling2D
    layers we defined in our first CNN. When instantiating a pooling layer, we need
    to specify which type we want to use, such as MaxPooling2D in our example, and
    define a pooling size (similar to the kernel size) to identify the regions of
    the feature map, to which to apply the pooling operation. The stride of a pooling
    layer is required to be the same as the pooling size, which means the pooling
    size for each dimension should be a factor of the size of that dimension. If it’s
    not, a padding operation must be applied beforehand; this is done by specifying
    the padding='valid' argument when instantiating a pooling layer with the Keras
    API.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层执行与卷积层类似的操作，但没有用于学习的任何过滤器（核）。卷积操作被替换为特定的硬编码操作，例如我们在第一个CNN中定义的MaxPooling2D层中的最大操作。当实例化一个池化层时，我们需要指定我们想要使用哪种类型，例如我们例子中的MaxPooling2D，并定义一个池化大小（类似于核大小）以识别应用池化操作的特征图区域。池化层的步长必须与池化大小相同，这意味着每个维度的池化大小应该是该维度大小的因子。如果不是，则必须在之前应用填充操作；这是通过在用Keras
    API实例化池化层时指定padding='valid'参数来完成的。
- en: Applying a pooling layer will divide the input feature map into a set of patches
    of the same size as the user-specified pooling size. In each patch, it will apply
    a pooling operation. For example, the MaxPooling2D layer will select the maximum
    value in each patch of the feature map (see figure 3.14).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 应用池化层会将输入特征图划分为与用户指定的池化大小相同的多个块。在每个块中，它将应用池化操作。例如，MaxPooling2D层将选择特征图每个块中的最大值（见图3.14）。
- en: '![03-14](../Images/03-14.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![03-14](../Images/03-14.png)'
- en: Figure 3.14 Max pooling on a 4×4 feature map with pooling size (2, 2)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 在4×4特征图上应用池化大小为(2, 2)的最大池化
- en: Practically, pooling layers are often interleaved with convolutional or dense
    layers to gradually reduce the size of the feature map.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，池化层通常与卷积层或密集层交替使用，以逐步减小特征图的大小。
- en: Training and testing the CNN
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和测试CNN
- en: 'Before feeding the MNIST data into our CNN, we need to add an extra channel
    dimension for the original images, as shown here:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在将MNIST数据输入我们的CNN之前，我们需要为原始图像添加一个额外的通道维度，如图所示：
- en: '[PRE26]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Compiling and training a CNN model is no different from an MLP. By checking
    the performance, as shown here, we can see that the simple CNN model achieves
    99.02% accuracy, decreasing the error rate by over 40%:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 编译和训练CNN模型与MLP没有不同。通过检查性能，如图所示，我们可以看到简单的CNN模型达到了99.02%的准确率，将错误率降低了40%以上：
- en: '[PRE27]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Also, although the CNN has more layers than the MLP we designed, the total number
    of parameters is less than in the MLP thanks to the pooling layer for reducing
    the size of the feature map.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，尽管CNN的层数比我们设计的MLP多，但由于池化层减少了特征图的大小，总参数数量比MLP少。
- en: Again, we could tune the CNN model by tuning hyperparameters such as filter
    size, stride size, pooling size, number and combination of convolutional and pooling
    layers, learning rate, optimizer, and so on. There are too many options to cover
    here, but you should be able to tune them manually by writing a simple loop function,
    trying different values of the concerned hyperparameters, and comparing their
    performance with cross-validation. I’ll introduce AutoML methods to help you do
    this more conveniently in the second part of the book.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以通过调整超参数（如滤波器大小、步长大小、池化大小、卷积和池化层的数量和组合、学习率、优化器等）来调整CNN模型。这里有很多选项，但您应该能够通过编写一个简单的循环函数，尝试不同的超参数值，并使用交叉验证比较它们的性能来手动调整它们。我将在本书的第二部分介绍AutoML方法，以帮助您更方便地完成这项工作。
- en: 3.5 IMDB review classification with recurrent neural networks
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.5 使用循环神经网络进行IMDB评论分类
- en: In this last example of the chapter, I’ll show you how to solve a text classification
    problem with a classic deep learning model for sequential data called the *recurrent
    neural network* (RNN). The dataset we will use is the IMDB movie reviews dataset.
    The goal is to predict whether the reviews written by the users are positive or
    negative.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后一个例子中，我将向您展示如何使用经典的用于序列数据的深度学习模型——**循环神经网络**（RNN）来解决文本分类问题。我们将使用的数据集是IMDB电影评论数据集。目标是预测用户撰写的评论是正面还是负面。
- en: 3.5.1 Preparing the data
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5.1 准备数据
- en: Similar to the MNIST dataset, the IMDB dataset can be loaded with Keras, as
    shown next.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 与MNIST数据集类似，IMDB数据集也可以使用Keras加载，如下所示。
- en: Listing 3.17 Loading the IMDB data
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.17 加载IMDB数据
- en: '[PRE28]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: ❶ Loads the data and keeps only the num_words most frequent words
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 加载数据并仅保留出现频率最高的num_words个单词
- en: 'This code loads the reviews into train_data and test_data and the labels (positive
    or negative) into train_labels and test_labels. The dataset has already been converted
    from raw text reviews to lists of integers via tokenization. The tokenization
    process first splits each review into a list of words and then assigns an integer
    to each of the words based on a word-integer mapping dictionary. The integers
    don’t have special meaning but provide a numerical representation for words that
    can be fed into the network. The labels are Boolean values of whether each review
    is positive or negative. Let’s inspect the data, shown next:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将评论加载到train_data和test_data中，并将标签（正面或负面）加载到train_labels和test_labels中。数据集已经通过标记化从原始文本评论转换为整数列表。标记化过程首先将每个评论分割成单词列表，然后根据单词-整数映射字典为每个单词分配一个整数。这些整数没有特殊含义，但为可以输入网络的单词提供了数值表示。标签是表示每个评论是正面还是负面的布尔值。让我们检查以下数据：
- en: '[PRE29]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Because reviews may be of different lengths, as this output shows, we pad the
    sequences to be the same length to format them into a matrix. The padding operation
    is illustrated in figure 3.15\. We first select a maximum length (max_len) to
    which all the sequences will be converted. If the sequence is shorter than max_len,
    we add zeros at the end; if it’s longer, we cut off the excess.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 由于评论可能具有不同的长度，如这个输出所示，我们将序列填充到相同的长度以将其格式化为矩阵。填充操作如图3.15所示。我们首先选择一个最大长度（max_len），所有序列都将转换为这个长度。如果序列短于max_len，我们在末尾添加零；如果它更长，我们截断多余的长度。
- en: '![03-15](../Images/03-15.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![03-15](../Images/03-15.png)'
- en: Figure 3.15 Pad the sequences to the same length.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 展示了如何将序列填充到相同的长度。
- en: We select a maximum length of 100 in this example and implement this with Keras
    as shown in listing 3.18.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们选择最大长度为100，并使用Keras实现，如列表3.18所示。
- en: Listing 3.18 Truncating and padding the data to the same length
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.18 截断和填充数据以达到相同的长度
- en: '[PRE30]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The returned padded training data is grouped into a matrix, which is of shape
    (25000, 100), as shown next:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的填充训练数据被分组成一个矩阵，其形状为(25000, 100)，如下所示：
- en: '[PRE31]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Each integer in the matrix is only a numerical representation of a word, so
    they do not have specific meanings for the network to learn. To provide meaningful
    input to the network, we use a technique called *word embedding* to create a learnable
    vector for each word, which we call the *embedding vector*. The method will randomly
    initialize an embedding vector for each word. These vectors serve as inputs for
    the network and are jointly learned with the weights of the network. Word embeddings
    provide a flexible way to map human language into a geometric space, which is
    very powerful when you have enough learning data. If you don’t have a large dataset,
    you can use embedding vectors learned for other datasets (*pretrained* word embeddings)
    as an initialization to help the algorithm learn the task-specific embeddings
    better and faster.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '矩阵中的每个整数只是单词的数值表示，因此它们对网络学习没有具体含义。为了向网络提供有意义的输入，我们使用一种称为*词嵌入*的技术为每个单词创建一个可学习的向量，我们称之为*嵌入向量*。该方法将为每个单词随机初始化一个嵌入向量。这些向量作为网络的输入，并与网络的权重一起学习。词嵌入提供了一种将人类语言映射到几何空间的方法，当有足够的训练数据时非常强大。如果您没有大量数据集，可以使用为其他数据集学习到的嵌入向量（*预训练*词嵌入）作为初始化，以帮助算法更好地、更快地学习特定任务的嵌入。 '
- en: Because the embedding vectors are learnable parameters, the word-embedding method
    is encapsulated as a layer in Keras named Embedding. It can be stacked together
    with the RNN. We can implement the whole pipeline by creating a Keras sequential
    model and adding an embedding layer as the first layer, as shown here.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 因为嵌入向量是可学习的参数，所以词嵌入方法被封装为Keras中的一个层，命名为Embedding。它可以与RNN一起堆叠。我们可以通过创建一个Keras顺序模型并添加一个嵌入层作为第一层来实现整个流程，如下所示。
- en: Listing 3.19 Adding an embedding layer to the model
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.19 向模型添加嵌入层
- en: '[PRE32]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: ❶ Creates a Keras sequential model object
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个Keras顺序模型对象
- en: ❷ Adds an embedding layer into the sequential model
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在顺序模型中添加嵌入层
- en: The max_words parameter defines the vocabulary size, or the maximum possible
    number of words contained in the input data. The embedding dimension here (32)
    indicates the length of each word-embedding vector. The output tensor of the embedding
    layer is of shape (batch_size, max_len, embedding_dim), where max_len is the length
    of the padded sequences we used before. Each review sequence is now a matrix composed
    of a set of word-embedding vectors.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: max_words参数定义了词汇表大小，或输入数据中可能包含的最大单词数量。这里的嵌入维度（32）表示每个词嵌入向量的长度。嵌入层的输出张量形状为(batch_size,
    max_len, embedding_dim)，其中max_len是我们之前使用的填充序列的长度。现在，每个评论序列都是一个由一组词嵌入向量组成的矩阵。
- en: 3.5.2 Building up the RNN
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5.2 构建RNN
- en: 'After the embedding layer, we build an RNN for classification. An RNN handles
    sequential inputs, which are formatted as vectors. It takes one embedding vector
    at a time along with a *state vector* and generates a new state vector for the
    next step to use (see figure 3.16). You can think of the state vector as the memory
    of the RNN: it extracts and memorizes the information in the previous words of
    the sequence to take the sequential correlation among words in the same sequence
    into account. In fact, each RNN cell in the figure is a copy of the same cell
    that contains certain transformations defined by some learnable weight matrices.
    In the first step, the RNN has no previous words to remember. It takes the first
    word-embedding vector and an initial state, which is usually empty (a zero vector),
    as input. The output of the first step is the state to be input to the second
    step. For the rest of the steps, the RNN will take the previous output and the
    current input as input and output the state for the next step. For the last step,
    the output state is the final output we will use for the classification.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在嵌入层之后，我们构建一个用于分类的 RNN。RNN 处理序列输入，这些输入格式化为向量。它一次取一个嵌入向量以及一个 *状态向量*，为下一步使用生成一个新的状态向量（见图
    3.16）。你可以把状态向量看作 RNN 的记忆：它提取并记住序列中前面的单词的信息，以考虑同一序列中单词之间的序列相关性。实际上，图中的每个 RNN 单元都是包含由某些可学习权重矩阵定义的特定转换的相同单元的副本。在第一步中，RNN
    没有前面的单词可以记住。它以第一个词嵌入向量和初始状态（通常是空的零向量）作为输入。第一步的输出是第二步要输入的状态。对于其余的步骤，RNN 将前一步的输出和当前输入作为输入，输出下一步的状态。对于最后一步，输出状态是我们将用于分类的最终输出。
- en: '![03-16](../Images/03-16.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![03-16](../Images/03-16.png)'
- en: Figure 3.16 Basic architecture of a vanilla recurrent neural network
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.16 基本循环神经网络架构
- en: We can use the Python code in the following listing to illustrate the process.
    The returned state is the final output of the RNN.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下列表中的 Python 代码来说明这个过程。返回的状态是 RNN 的最终输出。
- en: Listing 3.20 Pseudocode of the RNN
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.20 RNN 的伪代码
- en: '[PRE33]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: ❶ Sets the number of recurrent states
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设置循环状态的数量
- en: ❷ Recurrently generates new state
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 递归生成新的状态
- en: Sometimes, we may also need to collect the output of each step as shown in figure
    3.17\. We can collect not only the last state vector as output but also all the
    state vectors. Because the output now is a sequence of vectors, we can make the
    RNN deeper by stacking multiple RNN layers and use the outputs of one layer as
    the inputs for the next. It is worth pointing out that the dimensions of each
    output vector do not have to be the same as those of the input vectors.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们可能还需要收集如图 3.17 所示的每个步骤的输出。我们可以收集不仅最后一个状态向量作为输出，还可以收集所有状态向量。因为现在的输出是一个向量序列，我们可以通过堆叠多个
    RNN 层来使 RNN 深度化，并使用一个层的输出作为下一层的输入。值得注意的是，每个输出向量的维度不必与输入向量的维度相同。
- en: '![03-17](../Images/03-17.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![03-17](../Images/03-17.png)'
- en: Figure 3.17 Recurrent neural network with multiple vector outputs
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.17 具有多个向量输出的循环神经网络
- en: We can also stack multiple RNN chains into a multilayer RNN model (see figure
    3.18). The output states of each RNN layer will be collected as inputs for the
    subsequent layer.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将多个 RNN 链堆叠成一个多层 RNN 模型（见图 3.18）。每个 RNN 层的输出状态将被收集作为后续层的输入。
- en: '![03-18](../Images/03-18.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![03-18](../Images/03-18.png)'
- en: Figure 3.18 Multilayer recurrent neural network with multiple vector outputs
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.18 多层循环神经网络具有多个向量输出
- en: To implement the RNN, we can use the SimpleRNN class in Keras. In listing 3.21,
    we stack four RNN layers to form a multilayer RNN. Each SimpleRNN creates an RNN
    chain (not a single RNN cell). The output states in each of the first three RNN
    layers are collected as inputs for the subsequent layer. The output state of the
    fourth RNN layer is fed into the dense layer for final classification.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现 RNN，我们可以使用 Keras 中的 SimpleRNN 类。在列表 3.21 中，我们堆叠了四个 RNN 层来形成一个多层 RNN。每个
    SimpleRNN 创建一个 RNN 链（而不是单个 RNN 单元）。前三个 RNN 层中的输出状态被收集作为后续层的输入。第四个 RNN 层的输出状态被输入到密集层进行最终分类。
- en: Listing 3.21 Creating the RNN model
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.21 创建 RNN 模型
- en: '[PRE34]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: ❶ Stacks four RNN layers
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 堆叠四个 RNN 层
- en: ❷ Adds a dense layer to generate the final classification probability
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 添加一个密集层以生成最终的分类概率
- en: The units argument defines the length of each output vector (or state vector),
    which is the same as the length of the input vectors here. The return_sequences
    argument controls whether to collect all the output vectors of an RNN or only
    the final output. It is set to False by default. The last layer is a dense layer
    with a sigmoid activation function to map the state vector of length 32 to a single
    value (unit), indicating the probability of a review belonging to the positive
    class.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 单元参数定义了每个输出向量（或状态向量）的长度，这与输入向量的长度相同。`return_sequences` 参数控制是否收集 RNN 的所有输出向量或仅收集最终输出。默认设置为
    False。最后一层是一个具有 sigmoid 激活函数的密集层，将长度为 32 的状态向量映射到单个值（单元），表示评论属于正面类别的概率。
- en: 3.5.3 Training and validating the RNN
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5.3 训练和验证 RNN
- en: We can compile and train the model using a similar process to the MNIST example.
    We choose binary_crossentropy as the loss function, as shown in the next listing,
    which is a special case of cross-entropy loss for binary classification.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用与 MNIST 示例类似的过程来编译和训练模型。我们选择二元交叉熵作为损失函数，如下一列表所示，它是二元分类交叉熵损失的特殊情况。
- en: Listing 3.22 Adding a classification layer
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.22 添加分类层
- en: '[PRE35]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'For illustration purposes, we train for just two epochs with a batch size of
    128\. The trained RNN model can then be evaluated on the test set like so:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明目的，我们仅用 128 个批次的规模训练了两个时期。训练好的 RNN 模型可以像这样在测试集上进行评估：
- en: '[PRE36]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Again, we’ll skip the tuning of RNNs here and leave that for the next part of
    the book, with the help of AutoML toolkits.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们将跳过 RNN 的调整，并将这部分内容留到本书的下一部分，借助 AutoML 工具包来完成。
- en: Summary
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning models are composed of multiple layers stacked together to distill
    the input data and generate hierarchical representations. They can be jointly
    trained in an iterative process via feeding the data forward, determining the
    loss (error) in the output, and updating the parameters in each layer through
    the selected optimization method using backpropagation.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习模型由多个层堆叠而成，用于提炼输入数据并生成层次化的表示。它们可以通过迭代过程联合训练，通过正向传递数据，确定输出中的损失（错误），并通过反向传播使用选定的优化方法更新每层的参数。
- en: TensorFlow and Keras help us easily implement deep learning models. You should
    now be able to implement three classic deep learning models, including MLPs for
    tabular data classification, CNNs for image classification, and RNNs for text
    classification.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 和 Keras 帮助我们轻松实现深度学习模型。你现在应该能够实现三种经典的深度学习模型，包括用于表格数据分类的多层感知器（MLPs）、用于图像分类的卷积神经网络（CNNs）和用于文本分类的循环神经网络（RNNs）。
- en: Compiling and training a deep learning model requires the specification of a
    loss function, an optimizer, metrics to retrieve, and a stopping criterion (such
    as the number of epochs to train for).
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译和训练深度学习模型需要指定损失函数、优化器、检索指标和停止标准（例如训练的时期数）。
- en: Deep learning models usually require less data preprocessing and feature engineering
    than classic ML models. However, the algorithms often have multiple hyperparameters
    to be tuned, such as the number of layers, the type of layers, the specific configurations
    in each layer, and the hyperparameters of the optimization method.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习模型通常比经典机器学习模型需要更少的数据预处理和特征工程。然而，这些算法通常有多个超参数需要调整，例如层数、层类型、每层的具体配置以及优化方法中的超参数。
