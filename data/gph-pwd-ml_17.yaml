- en: appendix A. Machine learning algorithms taxonomy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录A. 机器学习算法分类法
- en: 'Machine learning is a deep and wide domain. Consequently, there are many different
    branches of machine learning. The algorithms can be classified or organized into
    broad categories based on four criteria:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个深度且广泛的领域。因此，存在许多不同的机器学习分支。根据四个标准，算法可以被分类或组织到广泛的类别中：
- en: Whether they are trained with human-provided labeled data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否使用人类提供的标记数据进行训练
- en: Whether they can learn incrementally
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否可以增量学习
- en: Whether they work by building a predictive model or by comparing new data points
    with known data points
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否通过构建预测模型或通过将新数据点与已知数据点进行比较来工作
- en: Whether the learner actively interacts with the environment or passively observes
    the information provided by the environment
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习者是否积极与环境互动或被动地观察环境提供的信息
- en: This taxonomy provides an overview of the plethora of machine learning algorithms
    and is not exhaustive. Its purpose is to help you identify the right set of algorithms
    for your specific problem, considering also the data available and how it can
    flow into the system. Such a classification is useful for understanding
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分类法提供了对大量机器学习算法的概述，但并不详尽。其目的是帮助您确定适合您特定问题的正确算法集，同时考虑可用的数据和它如何流入系统。这种分类对于理解
- en: The kinds of data needed and how to prepare the data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要的数据类型以及如何准备数据
- en: How often and in which way to retrain the model (if at all)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多久以及以何种方式重新训练模型（如果需要的话）
- en: How the quality of prediction could be affected over time
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着时间的推移，预测质量可能会受到哪些影响
- en: The architectural constraints of the solution to be designed
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要设计的解决方案的架构限制
- en: A.1 Supervised vs. unsupervised learning
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.1 监督学习与无监督学习
- en: Learning requires interaction between the learner and the environment. The first
    classification presented is based on the nature of this interaction during the
    training phase. Depending on the amount and type of supervision, we can distinguish
    between supervised and unsupervised learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 学习需要学习者和环境之间的交互。首先提出的分类是基于训练阶段这种交互的性质。根据监督的数量和类型，我们可以区分监督学习和无监督学习。
- en: If we look at learning as a process of using experience to gain expertise, supervised
    learning requires training examples/samples (the experience) that contain significant
    information explicitly. A typical example of this learning process is the spam
    filter. The learner requires labels, such as “spam” and “not spam” (the significant
    information), in the training dataset for each element (emails). It learns from
    these labels how to classify an email. These types of algorithms, generally speaking,
    have higher performance in terms of prediction accuracy. On the other hand, the
    effort required to provide labeled data is high and in some cases impossible to
    perform. Some of the most important supervised learning algorithms (some of which
    are covered in this book) are
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将学习视为使用经验获得专业知识的过程，那么监督学习需要包含显著信息的训练示例/样本（经验）。这个学习过程的典型例子是垃圾邮件过滤器。学习者在训练数据集中需要标签，例如“垃圾邮件”和“非垃圾邮件”（显著信息），对于每个元素（电子邮件）。它从这些标签中学习如何分类电子邮件。一般来说，这类算法在预测准确性方面具有更高的性能。另一方面，提供标记数据所需的工作量很大，在某些情况下甚至无法执行。一些最重要的监督学习算法（其中一些在本书中有所涉及）包括
- en: k-nearest neighbors (k-NN)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k-最近邻（k-NN）
- en: Decision trees and random forests
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树和随机森林
- en: Bayesian networks
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯网络
- en: Linear regression
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归
- en: Logistic regression
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Support vector machines
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: At the other end of the spectrum, unsupervised learning doesn’t require labeled
    data, so there is no distinction between training and test data. The learner processes
    input data with the goal of coming up with some insight about or a summary or
    compressed version of the data. Some of the most important unsupervised learning
    algorithms (again, some of which are covered in this book) are
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在光谱的另一端，无监督学习不需要标记数据，因此没有训练数据和测试数据之间的区别。学习者处理输入数据的目标是得出关于数据的一些见解或总结或压缩版本。一些最重要的无监督学习算法（其中一些在本书中有所涉及）包括
- en: Clustering (k-means)
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类（k-means）
- en: Graph clustering
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图聚类
- en: Association rule mining
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则挖掘
- en: PageRank
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PageRank
- en: An intermediate learning process type can deal with partially labeled training
    data, usually composed of a mixture of labeled and unlabeled data. This process
    is referred to as semisupervised learning. Most semisupervised algorithms are
    combinations of supervised and unsupervised algorithms. An example of this type
    of algorithm is semisupervised label propagation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一种中间学习过程类型可以处理部分标记的训练数据，通常由标记和无标记数据混合组成。这个过程被称为半监督学习。大多数半监督算法是监督和无监督算法的组合。这种类型算法的一个例子是半监督标签传播。
- en: An outlier of this classification criteria is reinforcement learning, in which
    the learner can only observe the environment (defined as the set of information
    available at the current time), select and perform actions, and get rewards in
    return. As a result of this interaction between the environment and the learner,
    the algorithm learns the optimal strategy (called a policy) to pursue to get the
    greatest reward over time. A policy defines the best actions for the system to
    perform given a specific condition of the environment. Reinforcement learning
    is used mostly for moving robots in a room or for playing chess and other games.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分类标准的异常是强化学习，其中学习者只能观察环境（定义为当前时间可用的信息集），选择并执行动作，并获得相应的奖励。由于这种环境与学习者的相互作用，算法学习到追求最大奖励的最优策略（称为策略）。策略定义了系统在特定环境条件下执行的最佳动作。强化学习主要用于在房间内移动机器人或玩象棋和其他游戏。
- en: A.2 Batch vs. online learning
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.2 批量学习与在线学习
- en: The second classification is based on the capability of the learner to adapt
    online, or in a short time, to streams of incoming data. Some algorithms, called
    online *learners*, can learn incrementally from new data as it comes. Others,
    called batch learners, need to use the whole dataset again, or a big portion of
    it, when data changes [Géron, 2017].
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种分类是基于学习者适应在线或短时间内适应数据流的能力。一些被称为在线*学习者*的算法可以从新数据中增量学习。其他被称为批量学习者的算法，在数据变化时需要再次使用整个数据集或其大部分。
    [Géron, 2017]
- en: In batch learning, the system is trained with all the available data. Such a
    learning process can take a lot of time and computing resources, depending on
    the size of the data to be processed, so it is typically performed offline. For
    this reason, batch learning is also known as offline learning. To inform the batch
    learning system of new data, a new version needs to be trained from scratch on
    the full dataset. When the new model is ready for production, the old one can
    be replaced. Classical data mining processes, such as market-basket analysis,[¹](#pgfId-999852)
    belong to this category. The data miner has large amounts of training data to
    play with before having to output conclusions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在批量学习中，系统使用所有可用数据进行训练。这种学习过程可能需要大量时间和计算资源，这取决于要处理的数据量，因此通常在离线时进行。因此，批量学习也被称为离线学习。为了通知批量学习系统新的数据，需要从头开始在新数据集上训练一个新版本。当新模型准备好投入生产时，旧模型可以被替换。经典的数据挖掘过程，如市场篮子分析，[¹](#pgfId-999852)属于这一类别。数据挖掘者在输出结论之前，有大量的训练数据可以操作。
- en: In online learning, the system is trained incrementally; data points are fed
    to it sequentially, one by one or in mini batches. In this case, the learning
    process is fast and cheap, and can be performed quite often. Online learning is
    great for systems that receive data continuously and need to adapt to changes
    rapidly and autonomously, such as a stock-prediction algorithm that has to make
    daily or hourly decisions based on stock prices collected so far.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在在线学习中，系统是增量训练的；数据点依次输入，一个接一个或以小批量形式。在这种情况下，学习过程快速且成本低，可以非常频繁地进行。在线学习非常适合接收连续数据并需要快速自主适应变化的系统，例如必须基于迄今为止收集的股价做出每日或每小时决策的股票预测算法。
- en: 'Online learning can also be used to train a system by using large amounts of
    data that cannot fit in the resources available. This type of learning is called
    out-of-core learning. The algorithm loads mini batches of the data, performs a
    training step, purges the data, and proceeds to the next batch. Online learning
    is generally preferred (when applicable), for two reasons:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在线学习也可以用于使用大量无法适应可用资源的数据进行系统训练。这种学习类型被称为离核学习。算法加载数据的小批量，执行一个训练步骤，清除数据，然后进行下一批。在线学习通常更受欢迎（当适用时），有两个原因：
- en: It provides a better fit to the current data and current status.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了对当前数据和当前状态的更好拟合。
- en: It is more efficient in terms of resource consumption.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在资源消耗方面更有效率。
- en: Such learning is sensitive to bad data, however. To reduce the risk associated
    with bad data, it is necessary to monitor the system continuously and eventually
    switch off the learning. It is worth noting that online and offline learning algorithms
    can be supervised or unsupervised.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种学习对不良数据很敏感。为了减少与不良数据相关的风险，有必要持续监控系统并最终关闭学习。值得注意的是，在线和离线学习算法可以是监督的或非监督的。
- en: A.3 Instance-based vs. model-based learning
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.3 基于实例学习与基于模型学习
- en: Another way to categorize learners is based on the capability of the system
    to generalize the data used during training to create a model for prediction.
    The two main approaches are instance-based and model-based learning [Géron, 2017].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种根据系统将训练期间使用的数据泛化以创建预测模型的能力来分类学习者的方法是。两种主要的方法是实例学习和基于模型学习 [Géron, 2017]。
- en: In *instance-based learning*, the system first learns all the training examples;
    then, for new instances (data points), it finds the closest instances from the
    training examples. This approach requires a way to measure the distance between
    elements, such as calculating the cosine distance between vectors created with
    TF-IDF [²](#pgfId-999873) or counting the number of words they have in common.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在*基于实例的学习*中，系统首先学习所有训练示例；然后，对于新的实例（数据点），它从训练示例中找到最近的实例。这种方法需要一种测量元素之间距离的方法，例如计算使用TF-IDF
    [²](#pgfId-999873)创建的向量之间的余弦距离，或者计算它们共有的单词数量。
- en: In *model-based learning*, the system builds a model from the training dataset
    that generalizes the training examples and then is used for making predictions.
    A typical example is the collaborative filtering technique for recommendation
    engines. Such algorithms use user-item interactions—buy, view, click, and so on—as
    training data to build a model. Then the model is used to predict the interest
    of users in unseen or unbought items and to promote the items with the highest
    predicted interest.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在*基于模型的学习*中，系统从训练数据集中构建一个模型，该模型泛化训练示例，然后用于进行预测。一个典型的例子是推荐引擎的协同过滤技术。此类算法使用用户-项目交互（购买、查看、点击等）作为训练数据来构建模型。然后，该模型用于预测用户对未见或未购买项目的兴趣，并推广预测兴趣最高的项目。
- en: Using the training dataset to generalize a prediction model is generally a preferable
    solution in terms of prediction performance, defined in terms of response time
    and result quality. The issues related to this approach are
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练数据集来泛化预测模型通常在预测性能方面是一个更好的解决方案，预测性能由响应时间和结果质量来定义。与此方法相关的问题包括
- en: The time required to build the model.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建模型所需的时间。
- en: Overfitting the training data, which happens when the training dataset doesn’t
    contain examples that cover the spectrum of possible cases. In this case, the
    model knows only few examples and doesn’t generalize enough to handle unseen samples
    properly.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过拟合训练数据，这发生在训练数据集不包含覆盖所有可能情况的示例时。在这种情况下，模型只知道少数示例，并且没有足够泛化来正确处理未见过的样本。
- en: A.4 Active vs. passive learning
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.4 主动学习与被动学习
- en: Learning paradigms can also vary according to the role played by the learner
    during the training phase. Passive learners observe information provided by the
    environment. In the spam filter example, the passive learner would wait for the
    user to mark emails. Active learners proactively interact with the environment
    at training time by asking questions or performing experiments. In the spam filter
    example, the active learner would choose emails and ask the user to label them
    as spam or not. This approach may lead to better performance in terms of prediction
    quality, because the active learner can choose the right data to label (avoiding
    overfitting, for example), but the interaction with users or the environment affects
    the user experience.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 学习范式也可以根据学习者在训练阶段所扮演的角色而变化。被动学习者观察环境提供的信息。在垃圾邮件过滤器示例中，被动学习者会等待用户标记电子邮件。主动学习者在训练时间通过提问或进行实验来主动与环境互动。在垃圾邮件过滤器示例中，主动学习者会选择电子邮件并要求用户将其标记为垃圾邮件或非垃圾邮件。这种方法可能在预测质量方面有更好的表现，因为主动学习者可以选择正确的数据进行标记（例如避免过拟合），但与用户或环境的交互会影响用户体验。
- en: Reference
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Géron, 2017] Géron, Aurélien. *Hands-on Machine Learning with Scikit-Learn
    and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems*.
    Sebastopol, CA: O’Reilly, 2017.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[Géron, 2017] Géron, Aurélien. *《使用Scikit-Learn和TensorFlow进行机器学习实践：构建智能系统的概念、工具和技术》*.
    Sebastopol, CA: O’Reilly, 2017.'
- en: '* * *'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.)Market-basket analysis is the process of analyzing customer buying habits
    by finding associations between the items that customers place in their shopping
    baskets. The discovery of such associations can help retailers develop marketing
    strategies by gaining insight into which items customers frequently purchase together.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: (1.) 市场篮子分析是通过寻找客户在购物篮中放置的商品之间的关联来分析客户购买习惯的过程。发现这样的关联可以帮助零售商通过了解哪些商品客户经常一起购买来制定营销策略。
- en: ^(2.)TF-IDF refers to a vector in which each element represents a word and its
    value is the term frequency-inverse document frequency, a numerical statistic
    intended to reflect how important a word is for a document in a collection of
    documents (or corpus).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: (2.) TF-IDF 指的是一个向量，其中每个元素代表一个词及其值是词频-逆文档频率，这是一个旨在反映一个词在文档集合（或语料库）中对于文档重要性的数值统计量。
