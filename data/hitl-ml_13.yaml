- en: 10 Annotation quality for different machine learning tasks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 不同机器学习任务的标注质量
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Adapting annotation quality control methods from labeling to continuous tasks
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将标注质量控制方法从标注扩展到连续任务
- en: Managing annotation quality for computer vision tasks
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理计算机视觉任务中的标注质量
- en: Managing annotation quality for natural language processing tasks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理自然语言处理任务的标注质量
- en: Understanding annotation quality for other tasks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解其他任务中的标注质量
- en: Most machine learning tasks are more complicated than labeling an entire image
    or document. Imagine that you need to generate subtitles for movies in a creative
    way. Creating transcriptions of spoken and signed language is a language generation
    task. If you want to emphasize angry language with bold text, that task is an
    additional sequence labeling task. If you want to display the transcriptions like
    the speech bubbles of text in comics, you could use object detection to make sure
    that the speech bubble comes from the right person, and you could also use semantic
    segmentation to ensure that the speech bubble is placed over background elements
    in the scene. You might also want to predict what a given person might rate the
    film as part of a recommendation system or feed the content into a search engine
    that can find matches for abstract phrases such as *motivational speeches.*
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习任务比标注整个图像或文档要复杂。想象一下，你需要以创造性的方式为电影生成字幕。创建口语和手语语言的转录本是语言生成任务。如果你想用粗体文本强调愤怒的语言，那么这个任务就是一个额外的序列标注任务。如果你想像漫画中的文字泡泡一样显示转录本，你可以使用目标检测来确保文字泡泡来自正确的人，你也可以使用语义分割来确保文字泡泡放置在场景中的背景元素上。你可能还想要预测某个人对电影的评价作为推荐系统的一部分，或者将内容输入到一个可以找到类似*励志演讲*等抽象短语的搜索引擎。
- en: For this one simple application to add subtitles to video, you need many types
    of annotation to train your models. Chapters 8 and 9 covered introductory and
    advanced techniques for annotation, using image- or document-level labeling as
    the example task in most cases. This chapter covers methods of managing annotation
    quality for additional types of machine learning tasks.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个简单的应用，为视频添加字幕，你需要许多类型的标注来训练你的模型。第8章和第9章介绍了标注的入门和高级技术，在大多数情况下以图像或文档级别的标注作为示例任务。本章涵盖了管理其他类型机器学习任务的标注质量的方法。
- en: You are most likely to use the methods in isolation and can skip to the section
    of interest. If you have a more complicated task such as the movie example, however,
    or if you are interested in adapting different types of annotation techniques,
    it is valuable to understand all the methods for machine learning problems. Ground
    truth data, interannotator agreement, machine-learning-driven methods, and synthetic
    data are all useful, and their effectiveness and actual implementation designs
    vary among machine learning tasks. Therefore, each section of this chapter highlights
    the pros and cons of annotation quality control strategies. We will start with
    the simplest task beyond simple labeling—annotating continuous data—and expand
    into more complicated machine learning scenarios.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你很可能会单独使用这些方法，并可以直接跳到感兴趣的章节。然而，如果你有一个更复杂的任务，比如电影示例，或者你对适应不同类型的标注技术感兴趣，了解所有机器学习问题的方法是有价值的。真实数据、标注者间一致性、机器学习驱动的方法和合成数据都很有用，它们在机器学习任务中的有效性和实际实施设计各不相同。因此，本章的每个部分都突出了标注质量控制策略的优缺点。我们将从最简单的任务开始，即简单的标注之外的标注连续数据，并扩展到更复杂的机器学习场景。
- en: 10.1 Annotation quality for continuous tasks
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 连续任务的标注质量
- en: If you are annotating data that is continuous, than many of the quality control
    strategies are the same the same as for labeling at the image/document level,
    but there are important differences about what counts as ground truth, agreement,
    subjectivity, and (especially) aggregating multiple judgments. We will cover each
    topic in turn in the following sections.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在标注连续数据，那么许多质量控制策略与图像/文档级别的标注相同，但在什么是真实数据、一致性、主观性和（尤其是）聚合多个判断方面存在重要差异。我们将在以下各节中依次介绍每个主题。
- en: 10.1.1 Ground truth for continuous tasks
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 连续任务的真实数据
- en: Ground truth for continuous tasks is most often implemented as an acceptable
    range of responses. If you have a sentiment analysis task on a 0–100 scale and
    have a positive item, you might accept any annotation in an 80–100 range as being
    correct and anything below 80 as incorrect. This approach allows you to treat
    quality control as though it were labeling, so all the methods in chapter 9 can
    be applied.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于持续任务，真实值通常实现为一个可接受的响应范围。如果您有一个基于0-100刻度的情感分析任务，并且有一个正面项目，您可能接受80-100范围内的任何注释为正确，而低于80的为不正确。这种方法允许您将质量控制视为标记，因此可以应用第9章中所有的方法。
- en: The acceptable range will depend on your exact task. If you are asking people
    to read a number in an image—such as the time, temperature, or battery charge—you
    might allow only exact matches.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 可接受的范围将取决于您的具体任务。如果您要求人们读取图像中的数字——例如时间、温度或电池充电量——您可能只允许精确匹配。
- en: 'If you have established a range of acceptable answers, you can calculate the
    individual annotator accuracy in the same way that you did for labeling tasks:
    calculate how often they fall within the acceptable range for each ground truth
    response.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经确定了一个可接受的答案范围，您可以像为标记任务那样计算单个标注者的准确性：计算他们每次落在每个真实响应的可接受范围内的频率。
- en: 10.1.2 Agreement for continuous tasks
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.2 持续任务协议
- en: If your data is ordinal—such as a three-point “Bad,” “Neutral,” “Good” scale—you
    should also look into the Krippendorff’s alpha example for ordinal values in chapter
    8\. You need to change the label weight inputs only to adapt from a labeling task
    to a continuous task.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据是序数的——例如三个点的“差”、“中性”、“好”刻度——您还应该查看第8章中关于序数值的Krippendorff的alpha示例。您只需要更改标签权重输入，以从标记任务适应到持续任务。
- en: As with ground truth data, you can treat two annotations within an acceptable
    range of each other as being in agreement and use the methods in chapter 9 to
    calculate agreement for labeling tasks. For expected agreement, you can calculate
    how many annotations would randomly be in a given range. If you are accepting
    an 80–100 range for a sentiment task, you will calculate how many annotations
    are in the 80–100 across all your annotations (figure 10.1).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 与真实值数据一样，您可以将彼此在可接受范围内的两个注释视为一致，并使用第9章中的方法计算标记任务的协议。对于预期协议，您可以计算有多少注释会随机落在给定范围内。如果您接受情感任务的80-100范围，您将计算所有注释中80-100范围内的注释数量（图10.1）。
- en: '![](../Images/CH10_F01_Munro.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F01_Munro.png)'
- en: 'Figure 10.1 Two ways of calculating the expected agreement in a continuous
    task: the chance that a random number falls in that range, and the percentage
    of annotations across the entire dataset that fall into the range'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1展示了在持续任务中计算预期协议的两种方式：随机数字落在该范围内的概率，以及整个数据集中落在该范围内的注释百分比
- en: The expected agreement might be smaller if your dataset has mostly negative
    sentiment, like the example in figure 10.1 for the 80–100 range. For a response
    in the 10–30 range, where there are many more responses, the expected agreement
    will be much higher.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据集大部分是负面情感，如图10.1中80-100范围的示例，预期协议可能较小。对于10-30范围内的响应，其中有很多响应，预期协议将高得多。
- en: The distributional properties of the data allow more detailed agreement calculations.
    If you have a normal distribution, you could use standard deviations instead of
    the ranges in our example. So if you are confident in your statistical abilities,
    look at the 10.1.3 distributional properties of the data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的分布特性允许更详细的协议计算。如果您有一个正态分布，您可以使用标准差而不是我们示例中的范围。所以如果您对自己的统计能力有信心，请查看第10.1.3节的数据分布特性。
- en: 10.1.3  Subjectivity in continuous tasks
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.3 持续任务中的主观性
- en: Continuous datasets can be deterministic or subjective, or a dataset might be
    deterministic for some items but not for others. Figure 10.2 shows an example.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 持续数据集可以是确定性的或主观的，或者数据集可能对某些项目是确定性的，而对其他项目则不是。图10.2展示了示例。
- en: '![](../Images/CH10_F02_Munro.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F02_Munro.png)'
- en: 'Figure 10.2 An example of deterministic and nondeterministic continuous tasks:
    estimating the speed of a car from an image of the odometer. Imagine that you
    had two annotations, 73 and 78\. For the left image, the image is digital, so
    you know that there is a correct answer. Perhaps the image is blurry, which made
    the 3 look like an 8\. So the correct strategy is to pick the better annotation
    (73 or 78). But for the analog odometer on the right, 73 and 78 are both reasonable
    estimates, and the average of 75.5 is probably better. So the correct strategy
    is to aggregate the annotations.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 确定性和非确定性连续任务的示例：从里程表图像估计汽车的速度。想象一下，你有两个标注，73和78。对于左侧的图像，图像是数字的，所以你知道有一个正确答案。也许图像模糊，使得3看起来像8。所以正确的策略是选择更好的标注（73或78）。但对于右侧的模拟里程表，73和78都是合理的估计，75.5的平均值可能更好。所以正确的策略是汇总标注。
- en: As figure 10.2 shows, you might have deterministic and nondeterministic data
    even within one dataset. For this reason, this book can’t give you one techniques
    that will apply to every possible dataset; you will need to estimate how much
    of your dataset is subjective and factor this estimate into your quality control
    strategy.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如图10.2所示，你甚至可能在同一个数据集中拥有确定性和非确定性数据。因此，这本书不能给你一个适用于所有可能数据集的技术；你需要估计你的数据集中有多少是主观的，并将这个估计纳入你的质量控制策略中。
- en: For inherently ambiguous or subjective items, you can ask the annotators for
    a range instead of a single value. You can reduce accomodation bias by asking
    what range annotators think other people will annotate, as in chapter 9 for subjectivity
    for categorical labeling (section 9.1) but in this case for ranges.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本质上模糊或主观的项目，你可以要求标注者提供一个范围而不是单一值。你可以通过询问标注者认为其他人会标注的范围来减少适应偏差，就像在第9章中讨论的类别标注的主观性（第9.1节）一样，但在这个情况下是针对范围。
- en: 10.1.4 Aggregating continuous judgments to create training data
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.4 将连续判断汇总以创建训练数据
- en: Aggregation for continuous variables can use the wisdom of the crowds. The classic
    examples are guessing the weight of a cow or the number of marbles in a jar; the
    average guess is typically closer to the correct value than most people’s guesses.
    Figure 10.3 shows an example distribution.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于连续变量，可以使用群体智慧进行汇总。经典的例子是猜测一头牛的重量或罐子中弹珠的数量；通常，平均猜测比大多数人的猜测更接近正确值。图10.3显示了这样一个分布。
- en: '![](../Images/CH10_F03_Munro.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F03_Munro.png)'
- en: Figure 10.3 An example of wisdom of the crowds. Although the average score of
    the 20 annotators (the dashed line) is not correct, it is closer to the correct
    (ground truth) score than 15 of the 20 annotators’ individual scores. Therefore,
    the average number is more accurate than most annotators.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 群体智慧的示例。尽管20个标注者的平均分数（虚线）不正确，但它比20个标注者中的15个个人分数更接近正确的（地面真实）分数。因此，平均数比大多数标注者更准确。
- en: 'As figure 10.3 shows, we expect the average annotation to be better than most
    annotators’ annotations, with two caveats:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如图10.3所示，我们期望平均标注比大多数标注者的标注更好，但有两条注意事项：
- en: Although the average will be better than most people, it is not necessarily
    optimal or better than selecting the best annotation in all cases.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然平均值可能比大多数人更好，但这并不一定是最佳选择，也不一定在所有情况下都比选择最佳标注更好。
- en: In some cases, the average is not better than most people for a task, which
    is more likely when only a few people are annotating each item.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在某些情况下，对于一项任务来说，平均值可能不如大多数人，这更可能在只有少数人标注每个项目时发生。
- en: This second point is especially important for training data. Most academic papers
    that look at continuous tasks for wisdom of the crowds assume that there is a
    crowd! It would be too expensive to have hundreds of people annotate every data
    point; it is more typical to have five or fewer people. So when people talk about
    wisdom of the crowds in relation to crowdsourcing, it applies least well to typical
    crowdsourced annotation systems.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这个第二点对于训练数据来说尤为重要。大多数研究连续任务的群体智慧的学术论文都假设存在一个群体！让数百人标注每一个数据点将过于昂贵；更常见的情况是只有五人或更少的人参与。因此，当人们谈论与众包相关的群体智慧时，它最不适用于典型的众包标注系统。
- en: As a general guideline, if you have fewer than five annotators, you should consider
    selecting the best annotator; if you have hundreds of annotators, you should take
    the average. For anything in between, you’ll have to choose the right strategy
    for your data and problem. Figure 10.4 illustrates when to apply the wisdom-of-the-crowds
    methodology.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一般准则，如果你有不到五位标注者，你应该考虑选择最佳标注者；如果你有成百上千位标注者，你应该取平均。对于介于两者之间的任何情况，你将不得不为你的数据和问题选择正确的策略。图10.4说明了何时应用群体智慧方法。
- en: '![](../Images/CH10_F04_Munro.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图10.4](../Images/CH10_F04_Munro.png)'
- en: Figure 10.4 For wisdom of the crowds, you need the crowds. This graph shows
    how often the average score of the annotators is closer to the ground truth score
    than most annotators. If there are three annotators, about 70% of the time, the
    average score of those annotators will be closer to the actual score than at least
    two of those annotators. It is rare to have more than ten annotators for each
    item when creating training data, and this graph shows that the average annotation
    is better than most annotators about 90% of the time when there are ten annotators.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 对于群体智慧，你需要群体。这张图显示了标注者的平均分数有多经常比大多数标注者的分数更接近真实分数。如果有三位标注者，大约70%的时间，这些标注者的平均分数将比至少两位标注者的分数更接近实际分数。在创建训练数据时，每个项目通常不会超过十位标注者，这张图显示，当有十位标注者时，平均标注比大多数标注者的标注好大约90%的时间。
- en: Figure 10.4 shows what the wisdom-of-the-crowds distribution looks like on a
    dataset that assumes a normal distribution. In this example, for three or more
    annotators, you are still better off taking the average score than picking the
    score of one of the annotators at random. This example data assumes a normal distribution
    in which the correct score is the mean, median, and mode of the annotators’ individual
    scores. Your own data’s distribution is probably less reliable, with the mean
    (average) annotation drawn from non-normal distributions that will tend to be
    higher or lower than the true scores. So you should calculate your own graph as
    in figure 10.4, using your ground truth data, and see how reliably you can use
    the average score for continuous data. You may find that selecting one annotator’s
    score is more reliable than taking the average, especially if you have a small
    number of annotators.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4展示了在假设数据集呈正态分布的情况下，群体智慧分布看起来是什么样子。在这个例子中，对于三位或更多标注者，你仍然最好选择平均分数，而不是随机选择其中一位标注者的分数。这个示例数据假设标注者的正确分数是平均分、中位数和众数。你自己的数据分布可能不太可靠，平均（平均）标注可能来自非正态分布，这些分布往往会高于或低于真实分数。因此，你应该像图10.4中那样计算自己的图表，使用你的真实数据，并看看你能否可靠地使用平均分数来处理连续数据。你可能发现选择一位标注者的分数比取平均更可靠，尤其是如果你只有少数几位标注者。
- en: 'For the normal distribution in figure 10.4 and for most other distributions,
    at least one annotator will be closer to the ground truth than the average most
    of the time, which sets up competing observations about your aggregation strategy:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图10.4中的正态分布以及大多数其他分布，大多数情况下至少有一位标注者比平均标注更接近真实值，这为你的聚合策略设定了竞争性的观察：
- en: Most of the time, the average annotation will be better than randomly selecting
    any single annotation.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数情况下，平均标注会比随机选择任何单个标注更好。
- en: Most of the time, at least one annotation will be better than the average annotation.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数情况下，至少有一位标注者的标注会比平均标注更好。
- en: You can tune your strategy based on how many annotations you have and how confident
    you are in individual annotators. If your data looks like figure 10.4, and you
    have only two annotators, you should randomly choose one of those two rather than
    taking the average. If you have three annotators and are not certain whether any
    of those annotators is more accurate than the others, you should use the average.
    If you have three annotators and are more than 73.34% certain that one of those
    annotators is more correct than the others, you should choose that annotation
    instead of the average.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以根据你拥有的标注数量以及你对单个标注者的信心来调整你的策略。如果你的数据看起来像图10.4，而你只有两位标注者，你应该随机选择这两位中的任意一位，而不是取平均。如果你有三位标注者，并且不确定其中任何一位是否比其他标注者更准确，你应该使用平均分数。如果你有三位标注者，并且有超过73.34%的把握认为其中一位标注者比其他标注者更准确，你应该选择那位标注者的分数而不是平均分数。
- en: If your data is inherently nondeterministic, you might choose not to aggregate
    at all; you might include every annotation that you trust as a training item.
    Having a valid range of responses in your training data will also help stop your
    model from overfitting.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据本质上是非确定性的，你可能选择根本不进行聚合；你可能包括你信任的每个注释作为训练项。在训练数据中拥有有效的响应范围也将有助于防止你的模型过拟合。
- en: 10.1.5 Machine learning for aggregating continuous tasks to create training
    data
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.5 将连续任务聚合以创建训练数据的机器学习
- en: Continuous tasks lend themselves well to machine-learning-driven quality control.
    You can apply most of the machine learning techniques from quality control for
    labeling tasks in chapter 9, but instead of predicting the labels, your machine
    learning model can use regression to predict a continuous value.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 连续任务非常适合机器学习驱动的质量控制。你可以应用第9章中用于标签任务的几乎所有机器学习技术，但你的机器学习模型可以使用回归来预测连续值，而不是预测标签。
- en: To predict the correct annotation using sparse features, you should be able
    to encode the actual annotations directly. The feature space will look more or
    less the same as for labeled data, but instead of the 1 or 0 values, you will
    have the actual number that each annotator annotated. If an annotator regularly
    annotates too high in the ground truth data, the model will take that fact into
    account when predicting the correct annotation. You may need to scale the annotations
    to a 0–1 range, depending on your architecture, but should otherwise be able to
    include these sparse features without additional processing. If you have a large
    number of annotators, your data might be too sparse, and as with labeling tasks,
    you can aggregate some of the annotations for a denser representation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用稀疏特征预测正确的注释，你应该能够直接编码实际的注释。特征空间将与标签数据大致相同，但除了1或0的值，你将拥有每个注释者标注的实际数字。如果一个注释者在真实数据中经常标注过高，模型在预测正确注释时会考虑这一事实。根据你的架构，你可能需要将注释缩放到0-1的范围，但通常可以在不进行额外处理的情况下包含这些稀疏特征。如果你有大量的注释者，你的数据可能过于稀疏，并且与标签任务一样，你可以聚合一些注释以获得更密集的表示。
- en: If you have data that is homogenous across the possible ranges, you might get
    better results by encoding the annotations relative to the average score. Figure
    10.5 shows an example.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据在可能的范围内是同质的，通过将注释编码为相对于平均分数，你可能会得到更好的结果。图10.5展示了示例。
- en: '![](../Images/CH10_F05_Munro.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F05_Munro.png)'
- en: Figure 10.5 A comparison of absolute and relative encodings when using machine
    learning to predict the correct number from the annotations. Here, Alex, Blake,
    and Cameron have annotated 0.3, 0.4, and 0.8 for a ground truth item for which
    the actual value is 0.55\. We can encode the absolute values of the annotations
    with the ground truth as the label (target value) for this training-data item.
    Alternatively, we can take the average of the annotators, which is 0.5, and encode
    the fact that this value should be 0.05 higher. We similarly encode each annotation
    by how much it differs from the average. Another way to think of the relative
    encoding is that it is encoding the *error* of our average instead of the values.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 使用机器学习预测注释中正确数字的绝对编码和相对编码的比较。在这里，Alex、Blake和Cameron对一个真实值为0.55的地面真实项分别标注了0.3、0.4和0.8。我们可以使用地面真实值作为标签（目标值）来编码注释的绝对值。或者，我们可以取注释者的平均值，即0.5，并编码这个值应该比平均值高0.05的事实。我们同样通过注释与平均值的差异来编码每个注释。相对编码的另一种思考方式是，它编码的是我们平均值的*误差*而不是值。
- en: 'If your data is homogenous—if 0.05 error is equally likely in all parts of
    your data, for example—the relative encoding in figure 10.5 is likely to be a
    more accurate representation for machine learning to assist in quality control.
    You can also combine all these features into one model: absolute features, relative
    features, aggregate (dense) features, metadata, model predictions, model embeddings,
    and so on. As with the categorical data examples, you need to be conscious about
    how many dimensions you end up with, because you are likely to have limited ground
    truth data for the training data. Start with simpler models and a small number
    of aggregate features to establish a baseline, and build from there.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据是同质的——例如，如果你的数据中0.05的错误在所有部分中同样可能，那么图10.5中的相对编码可能对机器学习辅助质量控制来说是一个更准确的表现。你还可以将这些所有特征组合成一个模型：绝对特征、相对特征、聚合（密集）特征、元数据、模型预测、模型嵌入等。与分类数据示例一样，你需要意识到你最终会有多少维度，因为你可能只有有限的训练数据真实标签。从简单的模型和少量聚合特征开始，建立基线，然后在此基础上构建。
- en: 10.2 Annotation quality for object detection
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 目标检测的标注质量
- en: Object detection is often divided into object labeling (identifying the label
    of an object) and object localization (identifying the boundaries of that object).
    In our examples, such as active learning for object detection in chapter 6, we
    assume that a bounding box is used for localization, but other types are possible,
    such as polygons or dots marking the center.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测通常分为目标标注（识别对象的标签）和目标定位（识别该对象的边界）。在我们的示例中，例如第6章中关于目标检测的主动学习，我们假设使用边界框进行定位，但其他类型也是可能的，例如多边形或标记中心的点。
- en: 'Object labeling follows the same quality control methods as image labeling,
    the main example in chapters 8 and 9\. Quality control for object localization
    annotation quality control is most often completed via workflows, for practical
    reasons: it takes only a few seconds to evaluate the quality of a bounding box
    that may have taken a few minutes to draw. So you are typically adding less than
    10% more time and cost to an annotation task by adding a review step to a workflow
    for bounding-box annotation. This approach is often more efficient than implementing
    automated quality controls. The example workflow in chapter 8, repeated in figure
    10.6, is one such case.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 目标标注遵循与图像标注相同的质量控制方法，第8章和第9章的主要示例。由于实际原因，目标定位标注的质量控制通常通过工作流程完成：评估可能花费几分钟绘制的边界框的质量只需几秒钟。因此，通过将审查步骤添加到边界框标注的工作流程中，你通常只会为标注任务增加不到10%的时间和成本。这种方法通常比实施自动化质量控制更有效。第8章中的示例工作流程，在图10.6中重复，就是这种情况之一。
- en: '![](../Images/CH10_F06_Munro.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F06_Munro.png)'
- en: Figure 10.6 A review task in which an annotator is evaluating whether a bounding
    box (typically created by a different annotator) is correct or incorrect. Review
    tasks form the backbone of many quality control strategies when programmatic quality
    control is difficult or will take more resources.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 一个审查任务，其中注释者正在评估一个边界框（通常由不同的注释者创建）是否正确或错误。当程序化质量控制困难或需要更多资源时，审查任务构成了许多质量控制策略的核心。
- en: Including a review task like the one shown in figure 10.6 can reduce the overall
    cost because you won’t need to give the bounding-box drawing task to many people.
    Review tasks with a simple accept/reject distinction will not tell you how big
    the errors were, however, so it can still be useful to compare the bounding boxes
    with ground truth data bounding boxes in some cases. It can also be useful to
    look at agreement between annotators for all the reasons outlined in chapter 8
    on the benefits of agreement, especially for identifying potentially ambiguous
    items. Having some statistical quality control for object detection annotations
    is typically a good idea in addition to reviewing tasks in workflows.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 包含如图10.6所示的审查任务可以降低整体成本，因为你不需要将边界框绘制任务分配给许多人。然而，具有简单接受/拒绝区分的审查任务不会告诉你错误有多大，因此在某些情况下，仍然可以比较边界框与真实数据边界框。此外，查看注释者之间的协议对于第8章中概述的所有原因，特别是识别可能含糊不清的项目，也是有用的。在流程中审查任务之外，通常对目标检测注释进行一些统计质量控制是个好主意。
- en: Next, we’ll revisit the metrics of model uncertainty introduced in chapter 6,
    applying them to human quality and uncertainty. Note that some of this section
    duplicates the section on active learning for object detection in chapter 6, because
    the metrics for uncertainty in human quality are the same as for model uncertainty.
    Because you may be reading the chapters out of order or after a break, some important
    metrics are repeated here.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将回顾第6章中引入的模型不确定性度量，将其应用于人类质量和不确定性。请注意，本节中的一些内容与第6章中关于对象检测的主动学习部分重复，因为人类质量的不确定性度量与模型不确定性相同。由于你可能是在顺序之外或中断后阅读这些章节，因此这里重复了一些重要的度量。
- en: 10.2.1 Ground truth for object detection
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.1 对象检测的地面真实
- en: Ground truth examples for object detection are most often created by a small
    number of expert annotators. To align incentives, it is generally better to pay
    people by the hour when you want the most accurate bounding boxes possible, because
    it can be a time-consuming process to get a box as accurate as possible, and paying
    per task does not align effective hourly compensation with the need for good data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对象检测的地面真实示例通常由少数几位专家标注者创建。为了对齐激励，当你希望获得尽可能精确的边界框时，通常最好按小时支付报酬，因为获取尽可能精确的边界框可能是一个耗时的过程，而按任务支付报酬并不能使有效的小时补偿与良好的数据需求相一致。
- en: You can create ground truth data as part of a workflow, too. Figure 10.7 shows
    how figure 10.6 can be extended so that an expert annotator can turn a nonexpert
    annotation into a ground truth example, editing the actual box only when necessary.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以将创建地面真实数据作为工作流程的一部分。图10.7展示了如何将图10.6扩展，以便专家标注者可以将非专家标注转换为地面真实示例，仅在必要时编辑实际框。
- en: '![](../Images/CH10_F07_Munro.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F07_Munro.png)'
- en: Figure 10.7 Extending the review task in figure 10.6 so that an expert annotator
    can edit the bounding box created by nonexpert annotators. This approach is one
    way to create ground truth data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 将图10.6中的审查任务扩展，以便专家标注者可以编辑非专家标注者创建的边界框。这种方法是创建地面真实数据的一种方式。
- en: It is common to allow a margin of error when comparing an annotation with a
    ground truth example because the boundary might be ambiguous at the level of a
    few pixels. You can use the experts to calibrate the margin of error for your
    data. If expert annotators disagree by up to 3 pixels relatively often, it may
    be OK to forgive any errors that are 3 pixels or less. You might also allow for
    a wider margin of error when people are estimating the boundaries of objects that
    are not fully in view (occluded behind another object) or out of frame.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在将标注与地面真实示例进行比较时，通常允许一定的误差范围，因为边界在几个像素级别上可能是不明确的。你可以使用专家来校准你数据的误差范围。如果专家标注者相对频繁地不同意3个像素以内，那么可能可以原谅任何3个像素或更小的错误。当人们估计的对象边界不在视野内（被另一个对象遮挡）或超出画面时，你可能还需要允许更宽的误差范围。
- en: As with labeling tasks, you may want to specifically sample ground truth items
    for diversity. In addition to labels and real-world diversity, the sample could
    include diversity in object size, object dimensions, and the location of the object
    within the image.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 与标注任务一样，你可能希望特别采样地面真实项目以实现多样性。除了标签和现实世界的多样性之外，样本可能还包括对象大小、对象维度以及对象在图像中的位置多样性。
- en: Intersection over union (IoU) is the most common metric for calculating annotator
    accuracy compared with ground truth. Figure 10.8 shows an example of IoU. Accuracy
    is calculated as the area where the predicted and actual bounding boxes intersect,
    divided by the total area covered by those two boxes.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 交并比（IoU）是计算标注者与地面真实之间的准确性的最常用度量。图10.8展示了IoU的一个示例。准确性是通过预测边界框和实际边界框相交的面积除以这两个框覆盖的总面积来计算的。
- en: '![](../Images/CH10_F08_Munro.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F08_Munro.png)'
- en: Figure 10.8 An example of IoU for measuring the accuracy of a bounding box (location
    accuracy). The accuracy is calculated as the area that intersects the annotator’s
    bounding box with the ground truth bounding box, divided by the area that is the
    union of the two boxes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8 用于测量边界框（位置精度）准确性的IoU示例。准确性是通过将标注者的边界框与地面真实边界框相交的面积除以两个框的并集面积来计算的。
- en: It is rare for IoU to be corrected for random-chance guessing for object detection.
    If the objects are small relative to the image size, the difference may not matter
    because the random chance of guessing a meaningfully overlapping box is so low.
    You may have cases, however, in which the objects take up a large percentage of
    the image, especially if you have workflows in which people are asked to add or
    edit a box on a zoomed-in image.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对象检测中很少对随机猜测进行IoU的校正。如果物体相对于图像大小较小，差异可能无关紧要，因为猜测一个有意义的重叠框的概率很低。然而，你可能有一些情况，其中物体占据了图像的大部分，特别是如果你有要求人们在放大图像上添加或编辑框的工作流程。
- en: 'If you want to adjust for random chance, you can take the percentage of the
    image that is within the box as the baseline. Suppose that an annotation has an
    IoU of 0.8, and the object takes up 10% of the image:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想调整随机概率，可以将图像中在框内的百分比作为基线。假设一个标注的IoU为0.8，且物体占据了图像的10%：
- en: Adjusted IoU = 0.8 – (0.1 / (1 – 0.1)) = 0.6889
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 调整后的IoU = 0.8 – (0.1 / (1 – 0.1)) = 0.6889
- en: This adjustment calculation is the same as though the entire image were said
    to be the object because the IoU of 10% of the image, compared with all of the
    image, is 10%.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这种调整计算与整个图像被认为是对象的情况相同，因为与整个图像相比，10%图像的IoU是10%。
- en: 'IoU is stricter than precision, recall, and F-score in that it tends to have
    lower values over the same data. Think of IoU in terms of the amount of area (or
    pixels) that are correct or incorrectly predicted:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: IoU比精确率、召回率和F-score更严格，因为它在相同的数据上往往有更低的值。将IoU视为正确或错误预测的面积（或像素）的数量：
- en: '![](../Images/CH10_F08_Munro_E01.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F08_Munro_E01.png)'
- en: 'IoU is more frequently used in computer vision, which does not allow a direct
    comparison with accuracy on tasks that use precision, recall, or a combination
    of the two (such as F-score, the harmonic mean of precision and recall). If you
    use precision, recall, and F-score instead of IoU, you should still use the whole
    image object as the basis for adjusting for chance, but note that you will have
    a different number. Suppose that the annotation has an F-score of 0.9 for the
    same object that takes up 10% of the image:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: IoU在计算机视觉中更常用，它不允许在那些使用精确率、召回率或两者组合（如F-score，精确率和召回率的调和平均值）的任务上直接与准确率进行比较。如果你使用精确率、召回率和F-score而不是IoU，你应该仍然使用整个图像对象作为调整随机概率的基础，但请注意，你将得到不同的数值。假设对于占据图像10%的同一物体，标注的F-score为0.9：
- en: Expected precision = 0.1
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 预期精确率 = 0.1
- en: Expected recall = 1.0
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 预期召回率 = 1.0
- en: Expected F-score = (2 * 0.1 * 1.0) / (0.1 + 1.0) = 0.1818
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 预期F-score = (2 * 0.1 * 1.0) / (0.1 + 1.0) = 0.1818
- en: Adjusted F-score = 0.9 – (0.1818)/(1 – 0.1818) = 0.6778
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 调整后的F-score = 0.9 – (0.1818)/(1 – 0.1818) = 0.6778
- en: You can see that although we started with 10% different accuracies for IoU and
    F-score (0.8 and 0.9), when we adjusted for chance, they end up much closer to
    a 1% difference (0.6889 and 0.6778). You can experiment with your dataset to see
    whether there is a significant difference between the two approaches to accuracy.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，尽管我们最初在IoU和F-score（0.8和0.9）的准确率上存在10%的差异，但在调整随机概率后，它们最终相差1%左右（0.6889和0.6778）。你可以通过实验你的数据集来查看两种准确率方法之间是否存在显著差异。
- en: 10.2.2 Agreement for object detection
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.2 对象检测的一致性
- en: 'Label agreement for object detection is the same as for image labeling; you
    can calculate the level of agreement between each label and adjust it according
    to the baseline of random-chance guessing one of those labels. As with image labeling,
    you need to decide which baseline calculation is most appropriate for your data:
    random label, data frequency, or most frequent. (See section 8.1 for definitions.)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对象检测的标签一致性与图像标注相同；你可以计算每个标签之间的一致性水平，并根据随机猜测这些标签的基线进行调整。与图像标注一样，你需要决定哪种基线计算最适合你的数据：随机标签、数据频率或最频繁的。（参见第8.1节中的定义。）
- en: Localization agreement between two annotators is calculated as the IoU of their
    two boxes. The agreement for the entire object is the average of all pairwise
    IoUs. Figure 10.9 shows an example of multiple bounding boxes annotated for one
    image.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 两个标注者之间的定位一致性是通过他们两个框的IoU计算的。整个对象的一致性是所有成对IoU的平均值。图10.9显示了为一张图像标注的多个边界框的示例。
- en: '![](../Images/CH10_F09_Munro.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F09_Munro.png)'
- en: Figure 10.9 An example of multiple bounding boxes from multiple annotators.
    Overall agreement is calculated as the average pairwise IoU of all boxes.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9 多个标注者标注的多个边界框的示例。整体一致性是通过所有框的平均成对IoU计算的。
- en: You can use the same adjustment for random chance that you used for ground truth,
    but note that this practice is rare; most people look at agreement in object detection
    by using only unadjusted IoU.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用与用于真实值的相同调整来处理随机性，但请注意，这种做法很少见；大多数人通过仅使用未调整的IoU来查看目标检测中的协议。
- en: 10.2.3 Dimensionality and accuracy in object detection
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.3 目标检测中的维度和精度
- en: Object detection can produce lower scores than other machine learning tasks
    as a result of the dimensionality of the problem. If an annotator’s box is 20%
    bigger than the ground truth on each side, it is 40% bigger per dimension. For
    two dimensions, 140%^2 = 196%, making the error almost twice the size, so an annotator’s
    20% error can become an IoU score of about 51%. This figure goes up with dimensions.
    A 3D bounding box that is 20% larger in all dimensions produces an IOU of about
    36%.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 由于问题的维度，目标检测可能产生低于其他机器学习任务的分数。如果一个标注者的框在每一边都比真实值大20%，那么在每个维度上就大了40%。对于两个维度，140%^2
    = 196%，使得误差几乎翻倍，因此标注者的20%误差可以变成大约51%的IoU分数。这个数字会随着维度的增加而上升。一个在所有维度上比真实值大20%的3D边界框会产生大约36%的IOU。
- en: 'This example highlights one reason why annotation accuracy for object detection
    can be so difficult: the metrics we use for comparison will compound the errors.
    This margin of error can be important for some tasks. Suppose that you are trying
    to predict the volume of cardboard boxes for shipping logistics or stocking supermarket
    shelves. If you forgave the annotators within a 5% margin of error, which sounds
    like a reasonable error, and an annotator goes over by 5% on all dimensions, 33%
    (110%^3 = 133.1%) is added to the total volume! If your model is trained on data
    with 33% error, you can’t expect it to predict with greater accuracy when deployed.
    So you should be careful when designing your task and deciding the acceptable
    level of annotation accuracy. If you are tracking the annotators’ accuracy across
    different types of work, such as image-level labeling, it may be simplest to track
    their accuracy for object detection separately from other tasks rather than let
    their low object detection results bring down their general accuracy score.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子突出了标注精度对于目标检测可能如此困难的一个原因：我们用于比较的指标会放大错误。这种误差范围对于某些任务来说可能很重要。假设你正在尝试预测用于物流或超市货架补货的纸箱体积。如果你在5%的误差范围内原谅标注者，这听起来像是一个合理的误差，但标注者在所有维度上超出了5%，那么总体体积会增加33%（110%^3
    = 133.1%）！如果你的模型是在包含33%误差的数据上训练的，那么你无法期望它在部署时能预测得更加准确。因此，在设计任务和决定可接受的标注精度水平时，你应该格外小心。如果你正在跟踪标注者在不同类型工作（如图像级标注）中的精度，那么将标注者在目标检测中的精度与其他任务分开跟踪可能更简单，而不是让他们的低目标检测结果拉低他们的总体精度得分。
- en: 10.2.4 Subjectivity for object detection
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.4 目标检测的主观性
- en: 'You can treat subjectivity for object detection the same way that you treat
    subjectivity for continuous tasks: you can ask the annotators whether multiple
    viable boxes are possible for an object and ask them to annotate those boxes.
    You can treat each of those boxes as a viable annotation and potentially end up
    with multiple boxes per object.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将目标检测的主观性处理方式与处理连续任务的主观性方式相同：你可以询问标注者一个对象是否可能有多个可行的框，并要求他们标注这些框。你可以将每个这样的框视为一个可行的标注，并最终可能为每个对象得到多个框。
- en: You can also ask annotators what they think other people would annotate to elicit
    a more diverse range of responses and to make annotators more comfortable annotating
    a valid but minority interpretation.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以询问标注者他们认为其他人会如何标注，以激发更多样化的回答，并使标注者更舒适地标注一个有效但少数派解释。
- en: 10.2.5 Aggregating object annotations to create training data
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.5 将目标标注聚合以创建训练数据
- en: 'The problem with aggregating multiple annotations into a single bounding box
    is similar to the problem with continuous values: there is no guarantee that the
    average bounding box is the correct one or that any single annotator has the correct
    one. For example, if you are putting a bounding box around a “Pedestrian” wearing
    a backpack, it may be correct to include or exclude the backpack, but the average
    of half a backpack won’t be correct.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 将多个标注聚合到一个单一边界框中的问题与连续值的问题类似：无法保证平均边界框是正确的，或者任何单个标注者拥有的边界框是正确的。例如，如果你正在围绕一个背着背包的“行人”放置边界框，包含或排除背包可能是正确的，但半个背包的平均值是不正确的。
- en: 'You can use multiple strategies to aggregate bounding boxes. This list is loosely
    ordered from the most effective to the least effective strategies I have encountered:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用多种策略来聚合边界框。以下列表大致按从最有效到最无效的策略顺序排列：
- en: Add a task for experts to review or adjudicate each box.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为专家添加一个任务来审查或裁决每个框。
- en: Use the average bounding box (but note the limitations).
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用平均边界框（但请注意局限性）。
- en: Use the most accurate annotator’s box.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最准确的标注者的框。
- en: Create the minimum box that surrounds the boxes of *N* annotators.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个最小框，该框包围了*N*个标注者的框。
- en: Use machine learning to predict the best box (section 10.2.6).
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用机器学习预测最佳框（第10.2.6节）。
- en: The most effective strategy might not be the first one for your particular dataset.
    You may need a combination of strategies instead of one. For the fourth strategy,
    you also need to decide what *N* should be. If you have four annotators, should
    you aggregate by the smallest box that surrounds the annotations of two or three
    annotators? There might not be a right answer.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于您特定的数据集，最有效的策略可能不是第一个。您可能需要结合使用多种策略而不是单一策略。对于第四种策略，您还需要决定*N*应该是多少。如果您有四个标注者，您应该通过包围两个或三个标注者注释的最小框来聚合吗？可能没有正确答案。
- en: Overlapping objects can also present a tough problem for aggregating bounding
    boxes. Figure 10.10 shows an example of overlapping bounding boxes where two annotators
    have a different number of boxes.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 重叠对象也可能在聚合边界框时提出一个难题。图10.10显示了两个标注者具有不同数量框的重叠边界框的示例。
- en: '![](../Images/CH10_F10_Munro.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F10_Munro.png)'
- en: Figure 10.10 An example of overlapping bounding boxes. It is difficult to distinguish
    which box from different annotators applies to the same object. One annotator
    (long dashes) has annotated two objects. The other annotator (short dashes) has
    annotated three objects.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 重叠边界框的示例。很难区分来自不同标注者的哪个框适用于同一对象。一个标注者（长虚线）标注了两个对象。另一个标注者（短虚线）标注了三个对象。
- en: 'You can use several methods to determine how many objects are within one area
    of an image, often in combination:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用多种方法来确定图像中某个区域内的对象数量，通常这些方法会组合使用：
- en: Create a separate task to ask how many objects appear.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个单独的任务来询问出现多少个对象。
- en: Add a task for experts to review and adjudicate overlapping boxes.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为专家添加一个任务来审查和裁决重叠的框。
- en: Use a greedy search technique to combine boxes from different annotators.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用贪婪搜索技术来组合来自不同标注者的框。
- en: You have different options for aggregation, as in the third strategy. A simple
    option is to use the maximum IoU as the criteria for which two boxes to combine
    next. You can assume one box per object per annotator (although there may be errors)
    and an IoU threshold below which you won’t combine.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 您有不同的聚合选项，如第三种策略中所述。一个简单的选项是使用最大IoU作为确定下一个要组合的两个框的标准。您可以假设每个标注者每个对象一个框（尽管可能存在错误）和一个IoU阈值，低于该阈值您不会进行组合。
- en: A greedy search is not necessarily optimal, so in theory, you could extend this
    strategy to a more exhaustive search of your data. In practice, if you can’t resolve
    overlapping objects with a simple greedy search, you should use a separate review
    or adjudication task.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 贪婪搜索不一定是最优的，所以从理论上讲，您可以将这种策略扩展到对您数据的更彻底搜索。在实践中，如果您无法通过简单的贪婪搜索解决重叠对象，您应该使用单独的审查或裁决任务。
- en: 10.2.6 Machine learning for object annotations
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.6 对象标注的机器学习
- en: The most powerful way to use machine learning for bounding-box annotation is
    to predict the IoU of every annotated box. This approach allows us to get a confidence
    score for each annotation that will be more accurate than taking the average IoU
    of each annotator.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 使用机器学习进行边界框标注的最强大方式是预测每个标注框的IoU。这种方法使我们能够为每个注释获得一个置信度分数，该分数将比取每个标注者的平均IoU更准确。
- en: For every bounding box that annotators created on the ground truth data, the
    IoU of that bounding box becomes the target for your model to predict. In addition
    to the image itself, you can encode the features related to each annotation, which
    can include
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标注者在真实数据上创建的每个边界框，该边界框的IoU成为您模型预测的目标。除了图像本身之外，您还可以编码与每个注释相关的特征，这可以包括
- en: The bounding box from each annotator
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个标注者的边界框
- en: The identity of each annotator
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个标注者的身份
- en: The label that the annotator provided in their annotation
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标注者在他们的注释中提供的标签
- en: These features will help the model weight the relative accuracies of the annotators,
    taking into account the fact that they can be more or less accurate on different
    types of images. Having encoded the training data, you can train your model with
    a continuous-output function to predict the IoU. Apply that model to predict the
    IoU of any new bounding box created by an annotator to get an estimate of the
    IoU for that annotator for that bounding box.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这些功能将帮助模型权衡标注者的相对准确性，考虑到他们在不同类型的图像上可能更准确或更不准确。在编码了训练数据后，你可以使用连续输出函数来训练你的模型以预测IoU。将此模型应用于预测由标注者创建的任何新边界框的IoU，以获得该标注者对该边界框的IoU估计。
- en: You can also experiment with ensembles of models and/or Monte Carlo sampling
    within one model to get multiple predictions per bounding box. This approach will
    give you a clearer idea of the range of possible IoUs for that annotator for that
    image. Note that you need to be confident in your sampling strategy for ground
    truth data because you are using these images as part of your model. Any bias
    in the ground truth data can lead to bias in this technique for predicting the
    confidence of each annotator.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在单个模型内进行模型集成和/或蒙特卡洛抽样的实验，以获得每个边界框的多个预测。这种方法将为你提供对该标注者对该图像可能IoU范围的更清晰了解。请注意，你需要对你的采样策略有信心，因为你在使用这些图像作为模型的一部分。地面真实数据中的任何偏差都可能导致预测每个标注者置信度的技术出现偏差。
- en: By looking at the predicted IoU of your annotators and their agreement, you
    can tune your overall workflow. You might decide, for example, to trust all annotations
    with predicted IoU over 95%, get an expert to review all annotations with predicted
    IoU between 70% and 85%, and ignore all annotations below 70%. The exact numbers
    can be tuned based on your data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看你的标注者的预测IoU及其一致性，你可以调整你的整体工作流程。例如，你可能会决定信任所有预测IoU超过95%的标注，让专家审查所有预测IoU在70%到85%之间的标注，并忽略所有预测IoU低于70%的标注。确切的数字可以根据你的数据进行调整。
- en: You can also use machine learning to aggregate bounding boxes from different
    annotators into a single bounding box. Although this approach is the most accurate
    way to aggregate bounding boxes, you might still have a workflow that experts
    review because often, it is too difficult to automate the aggregation process
    so that no errors get through.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用机器学习将来自不同标注者的边界框聚合到一个边界框中。尽管这种方法是聚合边界框最准确的方法，但你可能仍然需要一个专家审查的工作流程，因为通常自动化聚合过程以避免错误通过是非常困难的。
- en: As with continuous data, you can encode bounding-box locations by using absolute
    or relative encodings. Figure 10.11 shows an example of relative encodings.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 与连续数据一样，你可以通过使用绝对或相对编码来编码边界框的位置。图10.11显示了相对编码的一个示例。
- en: '![](../Images/CH10_F11_Munro.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F11_Munro.png)'
- en: Figure 10.11 Relative encodings for bounding boxes. The image is cropped and
    stretched so that every training item has identical dimensions and position. The
    relative encoding addresses the problem with objects being in different locations
    within the image and lets the model focus on a smaller number of features to make
    the predictions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11.边界框的相对编码。图像被裁剪并拉伸，以确保每个训练项具有相同的尺寸和位置。相对编码解决了图像中对象位置不同的问题，并使模型能够关注更少的功能以进行预测。
- en: The relative encodings in figure 10.11 are built on the same principles as the
    absolute and relative encodings for continuous tasks, covered in section 10.1.5\.
    If your data is homogenous—if a 5-pixel error is equally likely in all parts of
    your images, for example—the relative encoding is likely to be a more accurate
    representation for machine learning to assist in quality control.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11中的相对编码与第10.1.5节中介绍的绝对和相对编码的连续任务原理相同。如果你的数据是同质的——例如，如果你的图像所有部分的5像素误差可能性相同——那么相对编码可能是机器学习辅助质量控制的更准确表示。
- en: You can use many augmentation techniques to improve machine learning for aggregating
    bounding boxes. These techniques include flipping; rotating; resizing; blurring;
    and adjusting colors, brightness, and contrast. If you have worked in computer
    vision, you are probably familiar with these techniques for improving your machine
    learning model. If you have not worked in computer vision, learning about these
    techniques from an algorithm-focused computer vision book would be the best place
    to start.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用许多增强技术来提高聚合边界框的机器学习。这些技术包括翻转；旋转；调整大小；模糊；以及调整颜色、亮度和对比度。如果你在计算机视觉领域工作过，你可能会熟悉这些用于改进你的机器学习模型的技术。如果你没有在计算机视觉领域工作过，从以算法为重点的计算机视觉书籍中学习这些技术将是最好的开始。
- en: 10.3 Annotation quality for semantic segmentation
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 语义分割的标注质量
- en: In *semantic segmentation* also known as *pixel labeling*, annotators label
    every pixel in an image. Figure 10.12 shows an example repeated from chapter 6,
    in the section on active learning for semantic segmentation (section 6.2). Also
    see chapter 6 for more information about the distinction between object detection
    and semantic segmentation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在*语义分割*，也称为*像素标注*中，标注员会对图像中的每个像素进行标注。图10.12展示了从第6章重复的一个例子，在关于语义分割的主动学习部分（6.2节）。有关目标检测和语义分割之间区别的更多信息，请参阅第6章。
- en: '![](../Images/CH10_F12_Munro.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F12_Munro.png)'
- en: 'Figure 10.12 An example of semantic segmentation in which every pixel is labeled
    as “Person,” “Plant,” “Ground,” “Bicycle,” “Bird,” or “Sky.” This kind of colored
    photograph is what a lot of semantic segmentation tools look like: a coloring-in
    exercise. We’ll cover those tools in chapter 11\. If you’re looking at this image
    in black and white, the contrastive shades of gray should give you a good idea
    of what the image would look like in color. If the different objects of the same
    class receive a label (the four trees are labeled separately, for example), the
    task is known as *instance segmentation*.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12 一个语义分割的例子，其中每个像素都被标注为“人”、“植物”、“地面”、“自行车”、“鸟”或“天空”。这类彩色照片是许多语义分割工具的外观：一个填色练习。我们将在第11章中介绍这些工具。如果你以黑白形式查看这张图片，对比度的灰色阴影应该能给你一个关于彩色图像的好印象。如果同一类别的不同物体收到一个标签（例如，四棵树分别标注），这个任务就被称为*实例分割*。
- en: For most of the quality control that you need for semantic segmentation, you
    are simply adapting the methods for image-level labeling. But in this case, you
    are looking at the accuracy of every pixel instead of the label as a whole. You
    typically average the per-pixel annotation accuracy to get the overall annotation
    accuracy for the image.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数你需要用于语义分割的质量控制，你只是简单地调整了图像级别标注的方法。但在这个情况下，你是在查看每个像素的准确度，而不是整个标签。你通常将每个像素的标注准确度平均，以获得图像的整体标注准确度。
- en: 10.3.1 Ground truth for semantic segmentation annotation
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.1 语义分割标注的地面实况
- en: 'Comparing semantic segmentation annotations with ground truth data is like
    labeling at the pixel level: the percentage of pixels that the person labeled
    correctly relative to random chance. You might accept a small buffer (such as
    a few pixels) when an incorrectly labeled pixel is within a certain distance of
    a pixel with the correct label. You can treat those errors as though they were
    correct or ignore those pixels in your accuracy calculations.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 将语义分割标注与地面实况数据进行比较就像在像素级别进行标注：相对于随机机会，被标注正确的人像素百分比。当错误标注的像素在具有正确标签的像素一定距离内时，你可能接受一个小缓冲区（例如几个像素）。你可以将这些错误视为正确，或者在准确度计算中忽略这些像素。
- en: If you forgive errors that occur within a few pixels of the correct answers,
    look carefully for errors that all annotators make on the same pixels near boundaries,
    because these errors can be the result of annotation tools. More than any other
    machine learning task, semantic segmentation uses smart tools, such a magic wand
    or lasso tool to select a region, to speed up the process. Those tools are typically
    based on simple heuristics such as contrast in adjacent pixels. If the annotators
    don’t notice errors from using these tools, you will teach your model the simple
    heuristics of the tools instead of the correct boundaries between your labels.
    Errors from tooling can happen in any machine learning task, and chapter 11 goes
    into these problems more deeply, but this problem is flagged here because of how
    commonly it occurs in semantic segmentation.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你原谅在正确答案附近几个像素内发生的错误，仔细寻找所有标注者在边界附近相同像素上犯的错误，因为这些错误可能是标注工具的结果。与任何其他机器学习任务相比，语义分割更多地使用智能工具，如魔法棒或套索工具来选择区域，以加快处理过程。这些工具通常基于简单的启发式规则，如相邻像素的对比度。如果标注者没有注意到使用这些工具产生的错误，你将教会你的模型工具的简单启发式规则，而不是标签之间的正确边界。工具错误可能发生在任何机器学习任务中，第11章将更深入地探讨这些问题，但这个问题在这里被标记出来，是因为它在语义分割中发生的频率很高。
- en: You looked at the pattern of errors between labels for image labeling, and you
    should also look at the pattern of errors between pixel labels. You can weight
    some labels more than others if they are more important. If you care about bicycles
    more than the sky, for example, you can weight bicycles higher. Taking the macro
    average is the most common way to weight all labels equally. In some cases, you
    might even ignore some labels in the calculation of the accuracy, especially if
    you have a generic background label for everything you don’t care about except
    when it is confused with other labels.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你观察了图像标注标签之间的错误模式，你也应该查看像素标签之间的错误模式。如果某些标签比其他标签更重要，你可以给它们更高的权重。例如，如果你对自行车的关注程度高于天空，你可以提高自行车的权重。取宏观平均是使所有标签权重相等的最常见方式。在某些情况下，你甚至可以在计算准确率时忽略一些标签，特别是当你有一个通用的背景标签，除了它与其他标签混淆时，你对其不关心。
- en: 10.3.2 Agreement for semantic segmentation
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.2 语义分割的协议
- en: 'You measure agreement for each pixel exactly the same as for image labeling:
    measuring the agreement between annotators on the label of that pixel. You can
    calculate the expected agreement in the same three ways: the frequency of that
    label across all the data, the frequency of the most common label, or the inverse
    of the total number of labels. You should choose the most appropriate expected
    frequency for your dataset. If you have a generic background label, the overall
    frequency of this label might be a good candidate for the expected agreement.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你测量每个像素的协议与图像标注完全相同：测量标注者对该像素标签的协议。你可以用相同的三种方式计算预期的协议：该标签在所有数据中的频率、最常见标签的频率，或者标签总数的倒数。你应该为你的数据集选择最合适的预期频率。如果你有一个通用的背景标签，这个标签的整体频率可能是预期协议的好候选。
- en: 10.3.3 Subjectivity for semantic segmentation annotations
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.3 语义分割标注的主观性
- en: In practice, the most common way to resolve ambiguity for semantic segmentation
    is via review or adjudication. If a region is annotated as uncertain, or if annotators
    disagree, an additional annotator can adjudicate.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，解决语义分割歧义最常见的方式是通过复查或裁决。如果一个区域被标注为不确定，或者标注者意见不一致，可以增加一个额外的标注者进行裁决。
- en: It is common for semantic segmentation tasks to require that all pixels receive
    a label, which can be problematic when annotators are uncertain about some regions
    or multiple interpretations are valid. The simplest way to elicit subjectivity
    for semantic segmentation is to have an extra label called “Uncertain” that the
    annotator can use to indicate that they don’t know the correct label for that
    region. The “Uncertain” region can be a separate region, or you can ask the annotator
    to layer the “Uncertain” region on top of a completed segmentation so that you
    know what the most likely label was despite the confusion.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在语义分割任务中，通常要求所有像素都获得标签，当标注者对某些区域不确定或存在多个有效解释时，这可能会带来问题。为了激发语义分割的主观性，最简单的方法是添加一个名为“不确定”的额外标签，标注者可以使用它来表示他们不知道该区域的正确标签。“不确定”区域可以是一个独立的区域，或者你可以要求标注者在完成的分割上叠加“不确定”区域，这样即使存在混淆，你也能知道最可能的标签是什么。
- en: See section 10.7 for examples of how Bayesian Truth Serum (BTS) can be extended
    beyond labeling tasks. I am not aware of any work extending BTS to subjective
    semantic segmentation tasks, but the papers listed in section 10.7 would be the
    best places to start.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 有关贝叶斯真理血清（BTS）如何扩展到标注任务之外的示例，请参阅第10.7节。我了解到没有将BTS扩展到主观语义分割任务的工作，但第10.7节中列出的论文将是开始的地方。
- en: 10.3.4 Aggregating semantic segmentation to create training data
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.4 聚合语义分割以创建训练数据
- en: 'Aggregating training data from multiple annotations is the same as for labeling
    tasks, but at per-pixel level. Although all the same strategies are available,
    however, it is expensive to give an entire image to an additional annotator when
    only a small amount of disagreement exists. So using workflows to adjudicate certain
    regions of the image is a better option in cases such as these:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 从多个标注中聚合训练数据与标注任务相同，但在像素级别上。尽管所有相同的策略都是可用的，但是当只有少量不一致存在时，将整个图像交给额外的标注者是很昂贵的。因此，在这些情况下，使用工作流程来裁决图像的某些区域是一个更好的选择：
- en: Give images with low agreement over the entire image to additional annotators.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将整个图像上的一致性较低的图像交给额外的标注者。
- en: Use experts to adjudicate images that have low agreement in localized regions
    within an image.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用专家来裁决图像中局部区域内一致性较低的图像。
- en: Figure 10.13 shows an example of the adjudication process.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13展示了裁决过程的示例。
- en: '![](../Images/CH10_F13_Munro.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F13_Munro.png)'
- en: 'Figure 10.13 An example of semantic segmentation aggregation via workflows.
    Two annotators disagreed about a region, and that region is passed to a third
    annotator to review and adjudicate. There are two interface options: the adjudicator
    can select one of the two regions from the first two annotators, or they might
    annotate directly on the image, where the region with disagreement is presented
    as unannotated.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13展示了通过工作流程进行语义分割聚合的示例。两位标注者在某个区域上存在分歧，该区域被传递给第三位标注者进行审查和裁决。有两种界面选项：裁决者可以从前两位标注者的两个区域中选择一个，或者他们可以直接在图像上标注，其中存在分歧的区域以未标注的形式呈现。
- en: 'As figure 10.13 shows, you can define a region of disagreement as any set of
    contiguous pixels where there is low agreement among annotators. You can define
    agreement at the pixel level in the same way as for labels: percentage of agreement
    among annotators, potentially taking into account your confidence in their accuracy.
    In practice, you are unlikely to have more than two or three annotators per image
    because semantic segmentation is a time-consuming task. You might simply treat
    any disagreement as a region that needs to be adjudicated instead of setting a
    threshold via performance on ground truth data.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如图10.13所示，你可以将不一致区域定义为任何连续像素集，其中标注者之间的一致性较低。你可以在像素级别上以与标签相同的方式定义一致性：标注者之间的一致性百分比，可能还需要考虑你对他们准确性的信心。在实践中，你每张图像可能不会超过两个或三个标注者，因为语义分割是一项耗时的工作。你可能会简单地将任何不一致视为需要裁决的区域，而不是通过真实数据上的性能设置阈值。
- en: Assuming that you have a limited budget to adjudicate the disagreements, you
    can rank-order disagreements across the dataset by size and adjudicate from largest
    to smallest. You can also take the level of disagreement into account.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有限的时间内可以裁决不一致，你可以根据大小对数据集中的不一致进行排序，并从大到小进行裁决。你也可以考虑不一致的程度。
- en: If you care about some labels more than others, stratify the adjudication according
    to how much you care about each label. If you care about bicycles ten times more
    than you care about the sky, adjudicate ten disagreements that might be “Bicycle”
    for every one disagreement that might be “Sky.” Don’t try to apply that 10:1 ratio
    as a weighting to the region size, because it is too difficult to hand-tune these
    kinds of heuristics.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更关心某些标签而不是其他标签，可以根据你对每个标签的关心程度对裁决进行分层。如果你对自行车的关心程度是天空的十倍，那么对于每一个可能被标记为“天空”的不一致，你可以裁决十个可能被标记为“自行车”的不一致。不要尝试将10:1的比例作为区域大小的权重来应用，因为这太难手动调整这些启发式方法了。
- en: 10.3.5 Machine learning for aggregating semantic segmentation tasks to create
    training data
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.5 使用机器学习聚合语义分割任务以创建训练数据
- en: You can use the same machine learning methods for semantic segmentation that
    you did for labeling, but at the individual pixel level. One added complication
    is that you might need to resolve disagreements within unrealistic patchworks
    of pixels. If the wing of the birds in figure 10.13 became a checkerboard of “Sky”
    and “Bird” pixels, that result might be worse than incorrectly calling the entire
    wing “Sky” because you would be erroneously teaching your downstream model that
    checkerboard patterns are possible.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用与标注相同的机器学习方法进行语义分割，但需在单个像素级别上操作。一个额外的复杂性是您可能需要解决像素块中不切实际的“拼贴”之间的分歧。如果图10.13中鸟的翅膀变成了“天空”和“鸟”像素的棋盘，那么这种结果可能比错误地将整个翅膀称为“天空”还要糟糕，因为您可能会错误地向您的下游模型传授棋盘图案是可能的。
- en: To simplify the application of machine learning, you can implement a model to
    predict the binary “correct”/“incorrect” distinction for each pixel. Using your
    held-out ground truth data, build a model to predict which pixels were labeled
    incorrectly by your annotators, apply all your newly labeled data, and generate
    candidate “incorrect” regions for expert review.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化机器学习的应用，您可以实现一个模型来预测每个像素的二元“正确”/“错误”区分。使用您的保留真实数据，构建一个模型来预测您的注释员标注错误的像素，应用所有您的新标注数据，并生成候选的“错误”区域供专家审查。
- en: This machine-learning-driven method can be especially effective for discovering
    errors that come from the tooling, such as a smart selection tool. It is likely
    that in some cases, two or more annotators will have the same errors due to the
    tooling, and agreement won’t discover these regions as being potential errors.
    Your ground truth data, however, should tell you what kind of errors to expect
    from tooling (maybe “Sky” is called “Trees” too often); therefore, your model
    will predict the errors in similar parts of other images.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这种由机器学习驱动的方 法对于发现来自工具的错误（例如智能选择工具）特别有效。在某些情况下，由于工具的原因，两个或更多注释员可能会犯相同的错误，并且一致性的检查可能不会将这些区域识别为潜在的错误。然而，您的真实数据应该告诉您从工具中可以期望出现哪种类型的错误（也许“天空”被错误地称为“树木”太频繁了）；因此，您的模型将在其他图像的相似部分预测错误。
- en: 10.4 Annotation quality for sequence labeling
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 序列标注的注释质量
- en: In practice, sequence labeling uses human-in-the-loop methods for annotation
    more often than not. The most common use case is identifying rare sequences of
    text, such as the names of locations in long documents. Annotation interfaces
    for sequence labeling, therefore, typically present candidate sequences for review
    or generate sequences with autocompletes rather than ask annotators to annotate
    raw text.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，序列标注通常比标注更常使用人机交互方法。最常见的情况是识别稀有文本序列，例如长文档中的地点名称。因此，序列标注的注释界面通常呈现候选序列以供审查或生成带有自动完成的序列，而不是要求注释员标注原始文本。
- en: 'You can use different kinds of interfaces for this kind of review task in sequence
    labeling, and chapter 11 covers them. For review tasks, quality control can be
    implemented in the same way as labeling tasks, which is an additional advantage
    of this approach to sequence labeling: it is easier to perform annotation quality
    control on a binary or categorical labeling task than on a sequence labeling task.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在序列标注中，您可以使用不同类型的界面进行此类审查任务，第11章将介绍它们。对于审查任务，质量控制可以像标注任务一样实施，这是序列标注方法的一个额外优势：在二元或分类标注任务上执行标注质量控制比在序列标注任务上更容易。
- en: You can’t always annotate sequence data as a review task, however, especially
    at the start of a project, when you don’t yet have a model that can be used to
    predict sequence candidates in unlabeled data. You also run the risk of perpetuating
    model bias by surfacing only candidates from your existing model. So it is still
    useful to run some annotations on raw, unlabeled data.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您并不总是可以将序列数据作为审查任务进行标注，尤其是在项目开始时，您还没有一个可以用于预测未标记数据中序列候选者的模型。您还面临只展示现有模型候选者的风险，从而持续模型偏差。因此，在原始、未标记数据上运行一些标注仍然是有用的。
- en: 'The quality control methods for sequence labeling follow many of the methods
    in chapter 6 on active learning for sequence labeling. This section will revise
    them, assuming that you might not have read the section on active learning (or
    not recently). Let’s revisit the example from that section:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 序列标注的质量控制方法遵循第6章中关于序列标注主动学习的许多方法。本节将回顾它们，假设您可能没有阅读关于主动学习的部分（或者不是最近阅读的）。让我们回顾一下该部分中的示例：
- en: '*“The E-Coli outbreak was first seen in a San Francisco supermarket"*'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '*“E-Coli outbreak was first seen in a San Francisco supermarket”*'
- en: If you are implementing a model to track outbreaks from text reports, you may
    want to extract information from the sentence, such as the syntactic category
    (part of speech [POS]) of each word (“Nouns,” “Proper Nouns,” “Determiners,” “Verbs,”
    and “Adverbs”), the name of the disease, any locations in the data, and the important
    keywords, as shown in table 10.1.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在实现一个从文本报告中追踪爆发的模型，你可能想从句子中提取信息，例如每个词的句法类别（词性[POS]），“Nouns”（名词）、“Proper
    Nouns”（专有名词）、“Determiners”（限定词）、“Verbs”（动词）和“Adverbs”（副词），疾病名称，数据中的任何地点，以及重要的关键词，如表10.1所示。
- en: 'Table 10.1 Types of sequence labels: POS; keyword detection; and two types
    of named entities, diseases, and locations. The POS labels are one per token and
    can be treated similarly to labeling tasks for quality control. “B” (Beginning)
    is applied to the beginning of the span, and “I” (Inside) is applied to the other
    words within the span. Marking the start explicitly allows us to unambiguously
    distinguish spans that are next to each other, such as “San Francisco” and “supermarket.”
    This encoding technique is called IOB tagging, in which “O” (Outside) is the nonlabel.
    (“O” is omitted from this table for readability.) For multispan tasks, such as
    keywords and entities, quality control is more complicated than for labeling tasks.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.1 序列标签类型：词性标注；关键词检测；以及两种类型的命名实体，疾病和地点。词性标注标签每个标记一个，可以类似于质量控制的标注任务。“B”（开始）应用于跨度的开始，而“I”（内部）应用于跨度内的其他单词。明确标记开始允许我们明确地区分相邻的跨度，例如“San
    Francisco”和“supermarket”。这种编码技术称为IOB标记，其中“O”（外部）是非标签。（“O”因可读性而从表中省略。）对于多跨度任务，如关键词和实体，质量控制比标注任务更复杂。
- en: '![](../Images/10_T1.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10_T1.png)'
- en: In the literature, you will most commonly see IOB tagging for spans, as in table
    10.1\. You might define multitoken spans in different ways for different types
    of labels. “E-Coli” is the one word as an entity but two words for the keyword
    phrase “E-Coli outbreak,” for example. Strictly, the annotation convention in
    table 10.1 is called IOB2 tagging, and vanilla IOB uses “B” only when there are
    multiple tokens in a single span.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在文献中，你通常会看到跨度使用IOB标记，如表10.1所示。你可能为不同类型的标签以不同的方式定义多标记跨度。“E-Coli”作为一个实体是一个单词，但对于关键词短语“E-Coli
    outbreak”，则是两个单词。严格来说，表10.1中的注释约定称为IOB2标记，而vanilla IOB仅在单个跨度中有多个标记时使用“B”。
- en: For longer sequences, such as splitting a document into sentences or identifying
    people taking turns in speech, you may want to annotate only the start or end
    of each sequence rather than the sequence as a whole for annotator efficiency.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较长的序列，例如将文档拆分为句子或识别说话中轮流的人，你可能只想标注每个序列的开始或结束，而不是整个序列，以提高标注者的效率。
- en: 10.4.1 Ground truth for sequence labeling
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.1 序列标注的真相
- en: For most sequence labeling tasks with multitoken spans, quality control is evaluated
    over the correctness of the entire span. If an annotator identified “San” as an
    entity but did not identify “Francisco” as part of that same entity, the annotator
    is not awarded partial accuracy. Unlike object detection in computer vision, there
    is no widely used convention like IoU for sequences of text.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数具有多标记跨度的序列标注任务，质量控制是评估整个跨度的正确性。如果一个标注者将“San”识别为实体，但没有将“Francisco”识别为该实体的部分，则该标注者不会获得部分准确率。与计算机视觉中的目标检测不同，对于文本序列没有广泛使用的IoU等约定。
- en: 'If you have a contiguous task such as our named entity example, it can be insightful
    to look at per-token accuracy in addition to full span accuracy. My recommendation
    is to separate the label task from the span task when evaluating annotator accuracy:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个连续的任务，比如我们的命名实体示例，除了全跨度准确率外，查看每个标记的准确率也是有洞察力的。我的建议是在评估标注者准确率时，将标签任务与跨度任务分开：
- en: Calculate *label* accuracy on a per-token basis. If someone labels only “San”
    as a location, they get that label correct, but “Francisco” would be a false negative
    for location and a false positive for whichever other label was chosen.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按每个标记计算*标签*准确率。如果某人只将“San”标记为地点，则该标签正确，但“Francisco”对于地点来说将是假阴性，对于选择的任何其他标签将是假阳性。
- en: Calculate *span* accuracy on the entire span. If someone labels only “San” as
    a location, they get 0% credit for the span.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在整个跨度上计算*跨度*准确率。如果某人只将“San”标记为地点，则该跨度获得0%的信用。
- en: This distinction allows you to separate an annotator’s pragmatic understanding
    of what words belong to which labels from their syntactic understanding of what
    constitutes a multitoken phrase in the instructions.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这种区分使你能够将标注者对哪些单词属于哪些标签的实用理解与他们对指令中构成多词短语的句法理解区分开来。
- en: 'You can combine per-label accuracies with micro or macro average to calculate
    the overall accuracy for that annotator. You might drop the “O” (nonspans) from
    this calculation if you have sparse data, especially if you are calculating the
    micro average, because otherwise, the “O” tokens will dominate the accuracy. You
    can make this decision based on how you are evaluating your downstream model:
    if you are ignoring the “O” tokens when evaluating your model accuracy (except
    as false positives and false negatives in other labels), you can ignore the “O”
    label for evaluating annotator quality.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将每个标签的准确率与微观或宏观平均相结合，以计算该标注者的整体准确率。如果你有稀疏数据，特别是如果你正在计算微观平均，你可以从计算中省略“O”（非跨度），因为否则“O”标记将主导准确率。你可以根据你如何评估你的下游模型来做出这个决定：如果你在评估模型准确率时忽略“O”标记（除了在其他标签中的假阳性和假阴性之外），你可以忽略“O”标签来评估标注者质量。
- en: If you want to compare the accuracy of the annotator on this task with their
    accuracy on other tasks, you need to include the “O” label and adjust for random-chance.
    Although ignoring the “O” task is similar to adjusting for random chance, it will
    not produce the same final accuracy score, because ignoring the “O” does not account
    for its actual frequency.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要比较标注者在该任务上的准确性与他们在其他任务上的准确性，你需要包含“O”标签并调整随机性。虽然忽略“O”任务与调整随机性相似，但它不会产生相同的最终准确度分数，因为忽略“O”没有考虑到它的实际频率。
- en: Get the instructions correct!
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 确保指令正确！
- en: I have built named entity datasets for almost every major tech company and for
    specific use cases including public health, auto, and finance. In all cases, we
    spent more time on refining the definition of what goes into a span than on any
    other part of the task, working closely with the annotators to incorporate their
    expertise into the decision process. An example is when “San Francisco” is written
    as “San Francisco city,” should “city” be part of the location? What if it was
    “New York city”? We often see “New York City” or the abbreviation “NYC,” but not
    “SFC,” so these cases might be different. Also, in the San Francisco Bay area,
    San Francisco is known as “The City.” When should this name be called a location—only
    when capitalized, and if so, what about in social media, where it may not be capitalized
    regularly? What about other languages, which use capitals for entities rarely
    or not at all?
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我为几乎每家主要科技公司以及包括公共卫生、汽车和金融在内的特定用例构建了命名实体数据集。在所有情况下，我们花费更多的时间来细化定义哪些内容可以包含在一个跨度中，而不是任务的任何其他部分，我们与标注者紧密合作，将他们的专业知识纳入决策过程。例如，当“San
    Francisco”被写成“San Francisco city”时，"city"是否应该是地点的一部分？如果它是“New York city”，又会怎样？我们经常看到“New
    York City”或缩写“NYC”，但不是“SFC”，所以这些案例可能不同。此外，在旧金山湾区，旧金山被称为“The City”。当这个名称被称作地点时——只有当它被大写时，那么在社交媒体上，它可能不会经常被大写，又该如何？其他语言又如何，它们很少或根本不使用大写来表示实体？
- en: These types of cases are where most errors occur in most sequence tasks, both
    in annotation and machine learning models. It’s important to work closely with
    annotators to identify tough cases and add them to instruction. You can also include
    some of these cases in the nonrepresentative portion of your ground truth data.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类型的案例是大多数序列任务中错误最常发生的地方，无论是标注还是机器学习模型。与标注者紧密合作以识别困难案例并将它们添加到指令中非常重要。你还可以将这些案例中的一些包含在真实数据集的非代表性部分中。
- en: 10.4.2 Ground truth for sequence labeling in truly continuous data
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.2 真实连续数据中的序列标注真实数据
- en: Unlike our text examples, which are contiguous sequences, some sequence tasks
    are truly continuous. Speech and signed languages are two good examples. Unlike
    text, spoken language doesn’t leave gaps between most words, and signers don’t
    pause between words when signing them. In both cases, our brains add most gaps
    between words later from a continuous input, so there isn’t always a single obvious
    point where one word ends and the next one begins.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们的连续序列文本示例不同，一些序列任务实际上是连续的。语音和手语是两个很好的例子。与文本不同，口语在大多数单词之间不留空隙，而手势者在做手势时也不会在单词之间停顿。在这两种情况下，我们的大脑从连续输入中在单词之间添加大多数空隙，所以并不总是有一个明显的点，一个单词结束而下一个单词开始。
- en: This example is similar to the bounding-box examples in computer vision in section
    10.2, where IoU is used to measure ground truth accuracy. The convention for quality
    control in most sequence tasks, however, is to allow a margin of error from a
    ground truth example and not use IoU.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子与第10.2节中计算机视觉中的边界框示例类似，在那里使用IoU来衡量真实标签的准确度。然而，在大多数序列任务中，质量控制的传统做法是允许从真实标签示例中有一个误差范围，而不使用IoU。
- en: 'But there is no reason not to use IoU if it makes sense for your particular
    sequence task, even though it has not been the convention for language data. In
    that case, you can use the methods for ground truth accuracy and agreement in
    section 10.2\. You will gain one advantage, too: because sequences are 1D, the
    effects of the margin of error won’t be as bad as the 2D and 3D annotations that
    are more common in computer vision.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在语言数据中这不是惯例，但如果对于你特定的序列任务有意义，就没有理由不使用交并比（IoU）。在这种情况下，你可以使用第10.2节中关于真实标签准确性和一致性的方法。你还将获得一个优势：因为序列是1维的，误差范围的影响不会像计算机视觉中更常见的2维和3维标注那样严重。
- en: 10.4.3 Agreement for sequence labeling
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.3 序列标注的一致性
- en: For tasks in which every token or pre-segmented sequence receives a label, as
    in POS tagging, you can treat each token or segment like a single labeling task
    and apply the labeling methods from chapters 8 and 9.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个标记或预分割序列都分配标签的任务，例如词性标注，你可以将每个标记或分割视为一个单独的标注任务，并应用第8章和第9章中的标注方法。
- en: 'For text sequence tasks with sparse labels, such as the keyword extraction
    and named entity recognition examples, agreement can be calculated on a per-token
    basis or across the span. I recommend separating the prediction of the span itself
    from the label, along the same division as for ground truth data:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有稀疏标签的文本序列任务，例如关键词提取和命名实体识别示例，可以在每个标记的基础上或在整个跨度上计算一致性。我建议将跨度的预测与标签分开，与真实标签数据的划分方式相同：
- en: Calculate label agreement on a per-token basis. If one annotator labels only
    “San” as a location, and another labels “San Francisco,” there is 50% agreement
    for the label.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个标记的基础上计算标签一致性。如果一个标注者只将“San”标注为地点，而另一个标注“San Francisco”，则标签的一致性为50%。
- en: Calculate span agreement on the entire span. If one annotator labels only “San”
    as a location, and another labels “San Francisco,” there is 0% agreement for the
    span.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在整个跨度上计算跨度一致性。如果一个标注者只将“San”标注为地点，而另一个标注“San Francisco”，则跨度的标签一致性为0%。
- en: Use review and adjudication tasks to resolve disagreements. If annotators disagree
    on the boundaries of two overlapping spans, have another annotator resolve that
    disagreement. It is typically prohibitively expensive to have an entire document
    annotated by a large number of annotators to resolve a single dispute, so a simple
    adjudication system is typically your best bet.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 使用审查和裁决任务来解决分歧。如果标注者在两个重叠跨度的边界上意见不一致，可以让另一个标注者解决这个分歧。通常，让大量标注者对整个文档进行标注以解决单个争议的成本过高，因此一个简单的裁决系统通常是最佳选择。
- en: 10.4.4 Machine learning and transfer learning for sequence labeling
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.4 序列标注的机器学习和迁移学习
- en: All state-of-the-art sequence classifiers use pretrained contextual models.
    You should experiment with these models for your own sequence tasks, keeping in
    mind that as you get more training data, different pretrained models may be more
    or less helpful than others. It is easy to understand why pretrained models help.
    For our location example, a model pretrained on billions of sentences will have
    learned that “City,” “Village,” “Town,” and other location names are semantically
    similar and that the words preceding them are more likely to be locations. But
    it probably takes millions of documents before you see enough examples of “City,”
    “Village,” and “Town” in enough similar contexts that a pretrained model can make
    that generalization, and you are unlikely to be annotating millions of documents
    annotated for your sequence labeling task.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 所有最先进的序列分类器都使用预训练的上下文模型。你应该为自己的序列任务尝试这些模型，同时记住，随着训练数据的增加，不同的预训练模型可能比其他模型更有用或不太有用。理解预训练模型如何帮助是很容易的。对于我们关于地点的例子，一个在数十亿句子上预训练的模型将学会“城市”、“乡村”、“镇”和其他地点名称在语义上是相似的，并且它们前面的单词更有可能是地点。但可能需要数百万份文档，你才能在足够相似的环境中看到足够多的“城市”、“乡村”和“镇”的例子，以便预训练模型能够进行这种泛化，而你不太可能对用于你的序列标注任务的数百万份文档进行标注。
- en: If you have pretrained models and also have access to those models’ training
    data, you should use representative sampling as one of your active learning strategies
    to sample items that are most similar to your target domain. If you have a large
    amount of unlabeled data in your target domain, you can also try tuning the pretrained
    models to your domain.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你拥有预训练模型并且可以访问这些模型的训练数据，你应该将代表性采样作为你的主动学习策略之一，以采样与你的目标领域最相似的项目。如果你在目标领域中有大量未标记的数据，你也可以尝试调整预训练模型以适应你的领域。
- en: As section 10.4 stated, most real-world annotation strategies for sequence labeling
    use model predictions as candidate sequences for human review. The model is used
    to predict candidate sequences, and annotators can accept or reject those annotations
    as a binary task that allows for easy quality control. Make sure that you create
    some ground truth examples of good and bad examples so that you can evaluate annotators
    against ground truth on the binary review task, in addition to looking at agreement.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如第10.4节所述，大多数现实世界的序列标注策略都使用模型预测作为人类审查的候选序列。模型用于预测候选序列，标注者可以将这些注释作为二进制任务接受或拒绝，这允许轻松的质量控制。确保你创建一些好和坏的示例的真相示例，这样你就可以在二元审查任务中评估标注者与真相，而不仅仅是查看一致性。
- en: There is a risk of bias by using model predictions to generate candidates. Annotators
    might be primed to trust the model predictions when the model is incorrect. This
    type of bias is covered in chapter 11.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模型预测来生成候选序列存在偏差的风险。当模型错误时，标注者可能会被诱导信任模型预测。这种类型的偏差在第11章中有详细说明。
- en: Another potential source of bias from using model predictions is that you will
    miss sequences that the model did not predict with any confidence. This bias can
    amplify the bias in your model if you are not careful. A good solution that can
    also help with embeddings is to have a simple task in which all texts are evaluated
    for whether they contain a sequence. Figure 10.14 shows an example for location
    entities.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模型预测的另一个潜在偏差来源是，你可能会错过模型没有以任何信心预测的序列。如果不小心，这种偏差可能会放大你模型中的偏差。一个很好的解决方案是，有一个简单的任务，其中所有文本都被评估是否包含序列。图10.14展示了用于位置实体的示例。
- en: '![](../Images/CH10_F14_Munro.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F14_Munro.png)'
- en: Figure 10.14 An example of a labeling task that asks whether a sequence is present
    in the text without asking the annotator to label that sequence. This approach
    is especially useful for quickly ensuring that no text is missed for potential
    entities, and it can use a broader workforce that might not be as accurate in
    identifying the entity boundaries.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14展示了询问序列是否存在于文本中而不要求标注者标注该序列的标注任务示例。这种方法特别适用于快速确保没有遗漏任何文本以供潜在实体使用，并且可以使用可能不太准确识别实体边界的更广泛的劳动力。
- en: Using a workflow like the one shown in figure 10.14 and using a separate task
    to get the actual sequence span reduces the chance that the sequences will be
    missed because they were not candidates from your model.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 使用如图10.14所示的工作流程，并使用单独的任务获取实际序列范围，可以减少因序列不是模型候选而错过序列的机会。
- en: One byproduct of using a task to reduce bias and engage a broader workforce
    is that you can build a model specifically to predict whether a sequence occurs.
    This model can be used as an embedding for your actual sequence model, as in fig-ure
    10.15.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 使用任务来减少偏差和吸引更广泛的劳动力的一种潜在副产品是，你可以构建一个专门用于预测序列是否出现的模型。这个模型可以用作你的实际序列模型的嵌入，如图10.15所示。
- en: '![](../Images/CH10_F15_Munro.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F15_Munro.png)'
- en: Figure 10.15 An example of a labeling task that asks whether a sequence is present
    in the text, which creates a model that can be used as an embedding within the
    sequence labeling task. This approach is especially useful when there is a much
    larger volume of data with annotations for the labeling task than for the sequence
    task (ten times or more) which can be the byproduct of workflows aimed at reducing
    bias and engaging nonexpert annotators.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.15展示了询问序列是否存在于文本中的标注任务示例，这创建了一个可以作为序列标注任务中嵌入的模型。这种方法在标注任务的数据量远大于序列任务的数据量（多十倍或更多）时特别有用，这可能是旨在减少偏差和吸引非专家标注者的工作流程的副产品。
- en: If you have a much larger volume of data that is labeled as containing or not
    containing the sequence, architectures like the one shown in figure 10.15 can
    improve the accuracy of your downstream model. See section 9.4 for strategies
    for annotating data on adjacent tasks to create representations for transfer learning.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个大量标记为包含或不包含序列的数据集，如图10.15所示的结构可以提高你下游模型的准确性。请参阅第9.4节，了解在相邻任务上注释数据以创建迁移学习表示的策略。
- en: 10.4.5 Rule-based, search-based, and synthetic data for sequence labeling
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.5 用于序列标记的基于规则、基于搜索和合成数据
- en: Rule-based, search-based, and synthetic data generation methods are especially
    useful for generating candidates within sparse data. With our location example
    identifying sequences like “San Francisco,” there are several ways to use automated
    annotation to get a quick start on generating candidates. You might use a list
    of known place names as a rule-based system or construct synthetic sentences from
    that same list of place names, for example.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 基于规则的、基于搜索的以及合成数据生成方法在生成稀疏数据中的候选者特别有用。以我们的位置示例识别“旧金山”这样的序列为例，有几种方法可以使用自动化注释来快速开始生成候选者。例如，你可以使用已知地名列表作为基于规则的系统，或者从该地名列表构建合成句子。
- en: I’ve used all these methods for sequence annotations, typically taking the ratio
    of relevant annotations in something like 100:1 when randomly sampled to an initial
    ratio closer to 2:1\. These methods allows the model to be bootstrapped quickly
    when there is little initial data.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经使用过所有这些序列注释的方法，通常在随机抽样时将相关注释的比例保持在100:1，接近初始的2:1比例。这些方法使得模型在初始数据很少的情况下能够快速启动。
- en: Using synthetic data also improves the coverage. When I have built named entity
    systems for organizations, for example, I typically made sure that there were
    at least a few synthetic training-data examples with the names of all the products,
    people, locations, and other entities that were important to that organization.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 使用合成数据也提高了覆盖率。例如，当我为组织构建命名实体系统时，我通常会确保至少有一些合成训练数据示例，包含所有对该组织重要的产品、人员、地点和其他实体的名称。
- en: 10.5 Annotation quality for language generation
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 语言生成中的注释质量
- en: For most language generation tasks, quality control is done by human experts,
    not automated. When humans create translations of sentences from one language
    into another, for example, quality control is typically implemented by an expert
    translator who reviews the work and evaluates the quality of the translations.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数语言生成任务，质量控制通常由人工专家完成，而不是自动化。例如，当人类将一种语言的句子翻译成另一种语言时，质量控制通常由一位专家翻译员来执行，他们审查工作并评估翻译的质量。
- en: This situation is also true of the models themselves. Most of the literature
    for language generation quality control is about how to trust the human experts
    for their subjective judgments. There is a large body of literature about how
    to judge the quality of machine translation output on a 1–5 scale, knowing that
    each 1–5 judgment can be a subjective task. Data sampling for evaluation data
    is important in these cases too, because instead of using held-out data for automated
    analysis, people need to spend time evaluating the output manually, which is expensive.
    So it is extra-important to evaluate on a combination of randomly sampled data
    and/or data that is representative of the diversity of data where your model is
    deployed.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况也适用于模型本身。关于语言生成质量控制的大多数文献都是关于如何信任人类专家的主观判断。关于如何根据1-5的评分来判断机器翻译输出的质量，有大量的文献，知道每个1-5的判断都可能是一个主观任务。在这些情况下，数据采样对于评估数据也很重要，因为在这种情况下，人们需要花费时间手动评估输出，这是昂贵的。因此，在随机抽样的数据和/或代表模型部署的数据多样性的数据上评估尤为重要。
- en: The right workforce is the most important factor in creating quality training
    data for language generation tasks. As stated in chapter 7, it can take a lot
    of careful planning to make sure that you have the required language fluency and
    diversity among your annotators. See the following sidebar for an interesting
    story about the lengths you may need to go to find the right people.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建语言生成任务的质量训练数据时，合适的劳动力是最重要的因素。正如第7章所述，确保你的注释员具有所需的语言流利性和多样性可能需要大量的精心规划。请参阅以下侧边栏，了解你可能需要走多远才能找到合适的人的故事。
- en: Confessions about sourcing languages
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 关于语言来源的忏悔
- en: '*Expert anecdote by Daniela Braga*'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '*丹妮拉·布拉加的专家轶事*'
- en: At our company, we pride ourselves on going the extra mile to ensure that we’re
    getting the best data, which sometimes leads to hilarious situations. For text
    and speech data, the hardest problem is often finding fluent speakers. Finding
    people with the right qualifications and who speak the right language is one of
    the most difficult and overlooked problems in machine learning.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们公司，我们自豪于走得更远，以确保我们获得最佳数据，这有时会导致一些令人捧腹的情况。对于文本和语音数据，最困难的问题通常是找到流利的说话者。找到具有正确资格并能说正确语言的人是机器学习中最为困难和被忽视的问题之一。
- en: Recently, we were doing a major project collection for a client with specific
    language requirements. After a few missed attempts to source the right people
    for a rare language, one of our people went to a church where he knew he’d find
    individuals who would meet the requirements. Although he found the people he needed
    for our client, he accidentally turned up during confession time. The priest assumed
    that he was there for this reason, so true to form, he made his full confession,
    including about sourcing languages.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我们为一个有特定语言需求的客户进行了一项主要项目收集工作。在几次尝试寻找合适的人选以解决稀有语言的问题后，我们其中一位员工去了一个他知道的可以找到符合要求的人的教堂。尽管他找到了我们客户所需的人，但他不小心在忏悔时间出现了。牧师认为他是为此而来，因此一如既往地，他做了完整的忏悔，包括关于寻找语言的事情。
- en: '*Daniela Braga is founder and CEO of DefinedCrowd, a company that provides
    training data for language and vision tasks (including text and speech in more
    than 50 languages)*.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '*丹妮拉·布拉加是DefinedCrowd的创始人兼首席执行官，该公司为语言和视觉任务（包括50多种语言中的文本和语音）提供训练数据*。'
- en: 10.5.1 Ground truth for language generation
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.1 语言生成的基准事实
- en: When automated analysis *is* possible with ground truth data, there are often
    multiple acceptable ground truth answers, and the best match is used. Machine
    translation datasets often have multiple translations of the same sentence, for
    example. A machine-translated sentence is compared with each of the ground truth
    translations, and the best match is considered to be the appropriate one for calculating
    accuracy.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用基准事实数据进行自动化分析时，通常存在多个可接受的基准事实答案，最佳匹配被使用。机器翻译数据集通常有多个相同句子的翻译，例如。机器翻译的句子与每个基准事实翻译进行比较，最佳匹配被认为是计算准确性的适当选择。
- en: For machine translation, you have many ways of calculating the match, the simplest
    and most widespread being bilingual evaluation understudy (BLEU), which calculates
    the percentage of matching subsequences between the machine translation and the
    ground truth example. Most automated quality control metrics for sequence tasks
    use simple methods like BLEU, looking at the percentage of overlap between the
    output and a set of ground truth examples.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器翻译，你有许多计算匹配的方法，最简单和最普遍的是双语评估助手（BLEU），它计算机器翻译与基准事实示例之间匹配子序列的百分比。大多数用于序列任务的自动化质量控制指标都使用像BLEU这样的简单方法，查看输出与一组基准事实示例之间的重叠百分比。
- en: For annotation quality, you often need to create multiple ground truth examples
    for evaluation data. Depending on that type of task, those examples could be multiple
    valid translations of one sentence, multiple summaries of a longer text, or multiple
    replies that a chatbot could make to a prompt
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标注质量，你通常需要为评估数据创建多个基准事实示例。根据那种任务类型，这些示例可能是多个有效翻译的句子、多个对较长的文本的摘要，或者聊天机器人对提示的多个回复。
- en: You should ask annotators to come up with multiple solutions each in addition
    to giving the task to multiple annotators in parallel. For more sophisticated
    quality control, you could have the experts rank the quality of the ground truth
    data examples and incorporate that ranking into your evaluation metrics.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该要求标注者提出多个解决方案，除了将任务分配给多个标注者并行处理之外。为了更复杂的质量控制，你可以让专家对基准事实数据示例的质量进行排名，并将该排名纳入你的评估指标中。
- en: 10.5.2 Agreement and aggregation for language generation
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.2 语言生成的协议和聚合
- en: Interannotator agreement is rarely used for language generation tasks itself,
    although it can be used for people judging the quality of the generated text.
    In theory, you could track when an annotator is disagreeing with other annotators
    by looking at the difference between their text and other annotators using BLEU,
    cosine distance, or other metrics. In practice, it is much easier to have an expert
    quickly review their output for quality.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在语言生成任务本身中很少使用标注者间一致性，尽管它可以用于评判生成文本质量的人。理论上，您可以通过查看标注者之间文本差异（使用BLEU、余弦距离或其他指标）来追踪标注者何时与其他标注者意见不一致。在实践中，让专家快速审查他们的输出以评估质量要容易得多。
- en: It is rarely meaningful to aggregate multiple language generation outputs into
    a single training data item. If the model requires a single piece of text, that
    task is most often done by selecting the best candidate from the examples. Although
    this task could be done programmatically, it is rarely done that way in practice.
    If you have multiple annotators generating text for the same task, having one
    expert select the best one takes little additional time.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 将多个语言生成输出汇总为单个训练数据项通常没有意义。如果模型需要一个文本片段，那么这项任务通常是通过从示例中选择最佳候选者来完成的。尽管这项任务可以程序化完成，但在实践中很少这样做。如果您有多个标注者为同一任务生成文本，让一位专家选择最佳方案只需额外花费很少的时间。
- en: 10.5.3 Machine learning and transfer learning for language generation
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.3 语言生成的机器学习和迁移学习
- en: Because it takes a lot of time to create data for language generation manually,
    you can get great speed-up from machine learning. In fact, you probably use one
    example of this kind of technology regularly. If your phone or email client offers
    predictive next-word or sentence-completion functionality, you are the human in
    human-in-the-loop sequence generation! Depending on the technology, the application
    might be using transfer learning by starting with a general sentence-completion
    algorithm and gradually adapting the model to your text.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 由于手动创建语言生成数据需要花费大量时间，因此您可以从机器学习中获得极大的加速。事实上，您可能经常使用这种技术的例子。如果您的手机或电子邮件客户端提供预测下一个单词或句子补全功能，您就是人机交互序列生成中的人类！根据技术，应用程序可能通过从通用的句子补全算法开始，并逐渐调整模型以适应您的文本来使用迁移学习。
- en: You can implement this kind of architecture in many ways; it doesn’t need to
    have real-time interactions like the sentence-completion technologies. If your
    sequence generation model can produce a large number of potential outputs, you
    can use an expert-review task to choose the best one, which can speed things greatly.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过多种方式实现这种架构；它不需要像句子补全技术那样具有实时交互功能。如果您的序列生成模型能够产生大量潜在输出，您可以使用专家评审任务来选择最佳方案，这样可以大大加快速度。
- en: 10.5.4 Synthetic data for language generation
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.4 语言生成的合成数据
- en: Synthetic data is popular for many language generation tasks, especially when
    there are gaps in the diversity of available raw data. One solution for translation
    is to give the annotators the word and ask them to create both the original sentence
    containing that word and the translation. You can use other annotators to evaluate
    how realistic the examples sentences are. For transcription, you can ask someone
    to speak a sentence with certain words and transcribe it; for question-answering,
    you can ask someone to provide both the question and answer. Quality control in
    all cases becomes a labeling task for evaluating the quality of the generated
    examples and can follow the quality control methods in chapters 8 and 9.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据在许多语言生成任务中很受欢迎，尤其是在可用原始数据的多样性存在差距时。对于翻译任务，您可以给标注者提供单词并要求他们创建包含该单词的原始句子和翻译。您可以使用其他标注者来评估示例句子的真实性。对于转录任务，您可以要求某人说出包含特定单词的句子并将其转录下来；对于问答任务，您可以要求某人提供问题和答案。在所有情况下，质量控制都成为评估生成示例质量的标注任务，可以遵循第8章和第9章中的质量控制方法。
- en: Figure 10.16 shows a workflow for language generation. The annotators are given
    two types of data that they need to create and use that data to create synthetic
    examples. For the machine translation example, the two types might be two words
    that don’t currently occur in the training data, and the annotators are asked
    to create multiple sentences using those words and the translations of those words.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.16展示了语言生成的流程图。标注员被提供了两种类型的数据，他们需要创建并使用这些数据来生成合成示例。对于机器翻译的例子，这两种类型可能是不在训练数据中出现的两个单词，标注员被要求使用这些单词及其翻译来创建多个句子。
- en: '![](../Images/CH10_F16_Munro.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F16_Munro.png)'
- en: Figure 10.16 A workflow for generating data in contexts where no unlabeled data
    exists. This workflow looks similar to the other human-in-the-loop workflows,
    but there is no automation on the data-creation side. Humans look at existing
    examples and are given instructions about the types of examples that they need
    to create (Type A and Type B here). Those examples are added to the training data.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.16展示了在没有未标记数据存在的情况下生成数据的流程图。这个流程图看起来与其他人工介入的流程图相似，但在数据创建方面没有自动化。人类查看现有示例，并被告知需要创建的示例类型（此处为A型和B型）。这些示例被添加到训练数据中。
- en: The hardest part of synthetic data generation is diversity. It is relatively
    easy to prompt people to use certain words or to talk about certain events. When
    they’re put on the spot, however, people tend to use more formal language and
    much shorter sentences compared with natural language, in which people are not
    self-conscious. Chapter 11 covers some techniques to get data that is as natural
    as possible.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据生成的最难部分是多样性。提示人们使用某些单词或谈论某些事件相对容易。然而，当人们处于压力之下时，他们往往会使用比自然语言中更正式的语言和更短的句子，在自然语言中人们并不那么自我意识。第11章介绍了一些获取尽可能自然的数据的技术。
- en: 10.6 Annotation quality for other machine learning tasks
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.6 其他机器学习任务的标注质量
- en: The same quality control techniques using ground truth data, interannotator
    agreement, and machine-learning-driven annotation apply to many other machine
    learning tasks. This section covers a few more at a high level to highlight important
    similarities and differences.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 使用真实数据、标注员间的一致性和机器学习驱动的标注的相同质量控制技术适用于许多其他机器学习任务。本节从高层次概述了更多内容，以突出重要的相似性和差异性。
- en: 10.6.1 Annotation for information retrieval
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.1 信息检索的标注
- en: '*Information* *retrieval* is machine learning field that covers systems that
    drive search engines and recommendation systems. Many annotators are employed
    to tune the results of search engines. These systems are some of the oldest and
    most sophisticated human-in-the-loop machine learning systems.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '*信息检索*是机器学习领域，涵盖了驱动搜索引擎和推荐系统的系统。许多标注员被雇佣来调整搜索引擎的结果。这些系统是一些最古老和最复杂的带有人工介入的机器学习系统。'
- en: 'In the case of search engines, model accuracy is typically evaluated in terms
    of whether the relevant results are returned for a given query. To weight the
    first results more highly than the later results, information retrieval is typically
    evaluated with methods such as discounted cumulative gain (DCG), where rel[i]
    is the graded relevance of the result at a ranked position p :'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在搜索引擎的情况下，模型准确性通常通过是否为给定查询返回相关结果来评估。为了使第一个结果比后续结果有更高的权重，信息检索通常使用如折现累积增益（DCG）等方法进行评估，其中rel[i]是排名位置p的结果的分级相关性：
- en: '![](../Images/CH10_F16_Munro_E01.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F16_Munro_E01.png)'
- en: The `log``()` is used to de-weight the lower entries. You may want the first
    search result to be the most accurate; you care slightly less about the second
    search result and slightly less again for the third search result, and so on.
    For ground truth data, annotators can be evaluated by producing a ranking of candidate
    responses that maximizes DCG. In other words, the optimal ranking is one that
    puts the most-relevant first, the second-most-relevant second, and so on. A good
    annotator is someone whose ranking is closest to ground truth examples.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`log()`函数用于降低低级别条目的权重。你可能希望第一个搜索结果是最准确的；你对第二个搜索结果的关心稍微少一些，对第三个搜索结果的关心又少一些，依此类推。对于真实数据，标注员可以通过产生一个最大化DCG的候选响应排名来评估。换句话说，最佳排名是将最相关的放在第一位，第二相关的放在第二位，依此类推。一个好的标注员是那些排名最接近真实示例的人。'
- en: It is rare for DCG to be adjusted for random chance in information retrieval,
    typically because there are so many potential responses for “needle-in-the-haystack”
    search and recommendation systems that random chance is low. In other words, the
    data is sparse, and random chance is often close to zero.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息检索中，DCG很少因随机机会进行调整，通常是因为“大海捞针”搜索和推荐系统有如此多的潜在响应，随机机会很低。换句话说，数据是稀疏的，随机机会通常接近于零。
- en: The sparseness can prevent effective random sampling, too.If an annotator searches
    for “basketballs” on a web search engine and has to choose results on a randomly
    selected page, chances are that all the results will be irrelevant. Similarly,
    if an annotator searches for “basketballs” on a shopping site, and random products
    are returned, all the results are probably irrelevant. The annotation interface
    will use existing models to return relevant results instead of random samples.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏性也可能阻止有效的随机抽样。如果一个注释者在搜索引擎上搜索“篮球”，并需要在随机选择的页面上选择结果，那么所有结果都可能是不相关的。同样，如果一个注释者在购物网站上搜索“篮球”，并返回随机产品，所有结果可能都是不相关的。注释界面将使用现有模型来返回相关结果，而不是随机样本。
- en: To get a 0–1 score for the annotator, normalized discounted cumulative gain
    (NDCG) can be calculated. NDCG is the annotator’s actual score divided by the
    highest possible score (a perfect ranking from the ground truth data that was
    presented to the annotator). This score, which normalizes based on what an annotator
    saw (maybe 10 to 15 candidates) rather than across all possible candidates, is
    the most popular alternative to random-chance-adjusted accuracy for information
    retrieval.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得注释者的0-1评分，可以计算归一化折现累积增益（NDCG）。NDCG是注释者实际评分除以最高可能评分（注释者所看到的最佳排名，即从展示给注释者的真实数据中得出的完美排名）。这个评分基于注释者所看到的内容（可能是10到15个候选人）进行归一化，而不是所有可能的候选人，是信息检索中随机机会调整准确度的最流行替代方案。
- en: Because they oversample higher-likelihood candidates, information systems have
    the potential to amplify bias, because only high-probability items are returned
    as candidates. This bias can potentially be balanced by adding a small number
    of low-probability results to increase the diversity of potential choices. NDCG
    should be used in these cases; otherwise, the score from the annotator will be
    artificially low.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们对高概率候选人进行过采样，信息系统有可能放大偏差，因为只有高概率的项目被作为候选人返回。这种偏差可以通过添加少量低概率结果来平衡，以增加潜在选择的多样性。在这些情况下应使用NDCG；否则，注释者的评分将人为地偏低。
- en: Information retrieval systems can also be biased if they are tuned by end users’
    selections, because most queries tend to be about a small number of high-frequency
    phrases. Annotators who are employed to tune the models can also be used to balance
    the training data by being given disproportionately more diverse phrases to evaluate.
    Knowing how much of your training data comes from annotators or end users informs
    your active learning strategies too.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果通过最终用户的选取进行调整，信息检索系统也可能存在偏差，因为大多数查询往往涉及少数高频短语。被雇佣来调整模型的注释者也可以通过给予不成比例更多样化的短语来评估，以平衡训练数据。了解你的训练数据中有多少来自注释者或最终用户，也指导你的主动学习策略。
- en: 'Sometimes, you can’t simulate someone using an information retrieval by asking
    annotators to judge relevance, because you are not optimizing for relevance. In
    these cases, the machine learning model is often optimized for business-oriented
    metrics: the number of purchases a person makes, the number of clicks or seconds
    between a search and when a purchase is made, the value of the customer over the
    next six months, and so on. Because they are about the actual use of the model,
    these metrics are sometimes called *online metrics*, as opposed to F-score and
    IoU, which are *offline metrics*.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你不能通过要求注释者判断相关性来模拟信息检索的使用，因为你不是在优化相关性。在这些情况下，机器学习模型通常优化为面向商业的指标：一个人购买的数量，搜索和购买之间的点击次数或秒数，未来六个月内客户的价值等等。因为它们关于模型的实际使用，这些指标有时被称为*在线指标*，与F分数和IoU相对，后者是*离线指标*。
- en: 'Information retrieval systems often use other types of machine learning to
    provide additional features/metadata that will help the information retrieval
    system. A movie will likely be tagged with the genre of film, for example, and
    a recommendation system will suggest movies in a genre that it thinks you will
    like. Examples of tasks that feed into information systems include:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 信息检索系统通常使用其他类型的机器学习来提供有助于信息检索系统的额外功能/元数据。例如，一部电影可能会被标记为电影类型，而推荐系统会建议你认为你会喜欢的电影类型。以下是一些向信息系统提供输入的任务示例：
- en: Labeling query phrases by topic, such as classifying “basketball” searches as
    types of “sports equipment” to narrow the search results
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据主题对查询短语进行标注，例如将“basketball”搜索分类为“体育设备”类型，以缩小搜索结果
- en: Performing object detection to allow search, such as allowing someone to search
    for products by uploading a photograph of that product
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行对象检测以允许搜索，例如允许某人通过上传该产品的照片来搜索产品
- en: Labeling genres of content, such as classifying music into categories such as
    “uplifting” and “dark” to make music recommendations suited to the user’s taste
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标注内容类型，例如将音乐分类为“振奋人心”和“阴暗”等类别，以制作适合用户口味的音乐推荐
- en: Labeling the types of locations on a map, such as classifying whether a shop
    is a grocery or a retail store to improve geographic searches
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在地图上标注位置类型，例如将商店分类为杂货店或零售店以改进地理搜索
- en: Extracting sequences within the content, such as extracting the name, size,
    color, brand, and similar qualities of a product to support advanced search systems
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从内容中提取序列，例如提取产品的名称、尺寸、颜色、品牌和类似特性，以支持高级搜索系统
- en: 'In all cases, the tasks are simpler than information retrieval itself: labeling,
    object detection, and sequence labeling. But the components were used by information
    retrieval systems optimized for user behavior, such as how often the user returned
    to that company’s website. In these cases, the people who build the actual information
    systems track the importance of these components.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有情况下，任务本身比信息检索本身要简单：标注、对象检测和序列标注。但这些组件被用于针对用户行为优化的信息检索系统，例如用户多久返回一次该公司的网站。在这些情况下，构建实际信息系统的个人会跟踪这些组件的重要性。
- en: Another useful technique in information retrieval is query reformation, an augmentation
    technique strategy used by most search engines. If someone searches for “BBall”
    and doesn’t click any results but immediately searches for “Basketball,” that
    fact tells you that “BBall” and “Basketball” are closely related terms, and results
    for “Basketball” should be similar to those for “BBall.” This simple but smart
    technique produces free additional training data that also adapts your model closer
    to your end users’ preferred interactions.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 信息检索中的另一种有用技术是查询重构，这是大多数搜索引擎使用的增强技术策略。如果某人搜索“BBall”但没有点击任何结果，而是立即搜索“Basketball”，这一事实告诉你“BBall”和“Basketball”是密切相关的术语，并且“Basketball”的结果应该与“BBall”的结果相似。这种简单但聪明的技术产生了额外的免费训练数据，同时也使你的模型更接近最终用户的偏好交互。
- en: 10.6.2 Annotation for multifield tasks
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.2 多字段任务的注释
- en: 'If your annotation task has multiple fields, you should consider breaking the
    task into subtasks and connecting the subtasks via workflows. Either way, evaluate
    quality on the individual fields in addition to the task as a whole. Consider
    the example of tracking outbreaks from text like this:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的注释任务包含多个字段，你应该考虑将任务分解为子任务，并通过工作流连接这些子任务。无论如何，除了对整个任务进行评估外，还应该对各个字段进行质量评估。考虑以下从类似文本中追踪疫情的事例：
- en: “*The E-Coli outbreak was first seen in a San Francisco supermarket*"
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: “*大肠杆菌疫情首次在旧金山的超市被发现*”
- en: 'If you explicitly wanted to capture the information about this event, the annotation
    might look something like this:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你明确想要捕捉关于这一事件的详细信息，注释可能看起来像这样：
- en: 'Disease: E-Coli; Location: San Francisco.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 疾病：大肠杆菌；位置：旧金山。
- en: 'So you could evaluate accuracy on “Disease” and “Location” separately, and
    also evaluate accuracy on the entire event. Note that our example is a simple
    one, but not all text will be so obvious. Consider these two examples:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以分别评估“疾病”和“位置”的准确性，也可以评估整个事件的准确性。请注意，我们的例子很简单，但并非所有文本都如此明显。考虑以下两个例子：
- en: “*The E-Coli outbreak was first seen in a supermarket far from San Francisco*"
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: “*大肠杆菌疫情首次在远离旧金山的超市被发现*”
- en: “*E-Coli and Listeria were detected in San Francisco and Oakland respectively*"
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: “*在旧金山和奥克兰分别检测到大肠杆菌和李斯特菌*”
- en: 'In the first example, we don’t want to include the location. The second example
    has two events that we want to capture separately. The task isn’t simply a matter
    of matching every location in a sentence with every disease; it’s a more complicated
    problem of annotation and machine learning. You could break this task its subtasks
    and semi-automate it with machine learning so that it becomes three labeling tasks:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个例子中，我们不希望包括位置。第二个例子有两个我们想要分别捕捉的事件。任务不仅仅是将句子中的每个位置与每种疾病匹配；这是一个更复杂的标注和机器学习问题。你可以将这个任务分解成其子任务，并使用机器学习半自动化，使其成为三个标注任务：
- en: Label sentences yes/no as to whether they talk about disease outbreaks.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标注句子是否讨论疾病爆发为是/否。
- en: Label candidate locations and candidate diseases.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标注候选位置和候选疾病。
- en: Label candidate combinations of locations and diseases as the same event.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将位置和疾病的候选组合标注为同一事件。
- en: With the right workflows, interfaces, and reviews and adjudications, the system
    for annotating complicated events can become a series of labeling tasks for which
    quality control is much easier than for quality control over the entire event.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 通过正确的流程、界面、审查和裁决，复杂的标注事件系统可以变成一系列标注任务，其质量控制比整个事件的质量控制要容易得多。
- en: Most more complicated annotation tasks like this example can be broken into
    simpler tasks. The exact interface, quality controls, and machine learning components
    depend on how you break up the task, the workforce(s) you are using, and the nature
    of the task itself. But most people can follow the pattern of breaking a complicated
    task into simpler review tasks on machine learning predictions.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数像这个例子一样更复杂的标注任务可以分解成更简单的任务。确切的接口、质量控制以及机器学习组件取决于你如何分解任务、使用的劳动力以及任务本身的性质。但大多数人可以遵循将复杂任务分解成更简单的机器学习预测审查任务的模式。
- en: 10.6.3 Annotation for video
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.3 视频标注
- en: Most quality control methods for images also apply to object detection and/or
    semantic segmentation in videos. If you need to identify points in time or segments
    in the videos, the methods from continuous data and sequence labeling also apply.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数图像质量控制方法也适用于视频中的目标检测和/或语义分割。如果你需要识别视频中的时间点或片段，连续数据和序列标注的方法也适用。
- en: For object tracking, you are combining the methods for localization (the bounding
    box), sequence labeling (the frames in which the object is visible), and labeling
    (the label applied to the object). As in those examples, it is easier to track
    those metrics separately than try to combine them into a single annotator accuracy
    score.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 对于目标跟踪，你正在结合定位（边界框）、序列标注（物体可见的帧）和标注（应用于物体的标签）的方法。正如那些例子所示，单独跟踪这些指标比尝试将它们组合成一个单一标注准确度分数要容易。
- en: Some common video annotation tasks can be treated purely as sequence labeling
    tasks. A camera recording a person driving a car, for example, can be annotated
    for the sequences when they don’t appear to be looking at the road. The methods
    for sequence labeling can be applied to these tasks.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的视频标注任务可以纯粹被视为序列标注任务。例如，一个摄像机记录一个人开车，可以在他们似乎没有看路的时候进行标注。序列标注的方法可以应用于这些任务。
- en: Ground truth for object detection and/or semantic segmentation in videos is
    typically calculated on individual frames. If your videos vary greatly in length,
    you may want to sample an equal number of frames from each video data instead
    of randomly sampling frames across all your videos, which would bias toward the
    longer videos.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 视频中的目标检测和/或语义分割的真实数据通常是在单个帧上计算的。如果你的视频长度差异很大，你可能想要从每个视频数据中抽取相同数量的帧，而不是随机抽取所有视频中的帧，这会偏向于较长的视频。
- en: 'Interannotator agreement for video tasks is calculated according to whichever
    subtask is being evaluated: labeling, object detection, sequence identification,
    and so on. Those methods should apply to video annotation. As with ground truth
    data, I recommend that you track agreement separately rather than try to combine
    them into a single agreement calculation.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 视频任务中的标注者间一致性是根据正在评估的子任务计算的：标注、目标检测、序列识别等。这些方法应适用于视频标注。与真实数据一样，我建议你单独跟踪一致性，而不是尝试将它们组合成一个单一的一致性计算。
- en: Video annotation lends itself well to machine learning automation. A machine
    learning model can track the movement of objects, for example, and an annotator
    needs to correct the frames only when the prediction is wrong. This practice can
    provide substantial speed-up but also perpetuate bias in the model.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 视频标注非常适合机器学习自动化。例如，机器学习模型可以跟踪对象的移动，标注员只需要在预测错误时纠正帧。这种做法可以提供实质性的加速，但也可能使模型中的偏差持续存在。
- en: Synthetic data can also be effective for video annotation but has limited diversity.
    If you are creating the objects yourself in a simulated 3D environment, you already
    have perfect annotations for where those objects move, and you can create many
    orders of magnitude more data than by human annotation for the same budget. The
    synthetic data is likely to lack diversity, however, and may introduce pathological
    errors into the data, making models worse on real-world data. You typically have
    to be careful with this method and use it in combination with real-world data,
    using representative sampling to make sure that your annotators work on real-world
    data that is the most different from your synthetic data.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据对于视频标注也有效，但多样性有限。如果你在一个模拟的3D环境中自己创建对象，你已经有了关于这些对象移动的完美标注，并且可以比通过人工标注以相同预算创造更多数量级的数据。然而，合成数据可能缺乏多样性，并可能将病态错误引入数据，使模型在现实世界数据上的表现更差。你通常需要小心使用这种方法，并将其与真实世界数据结合使用，使用代表性采样确保你的标注员在真实世界数据上工作，这些数据与你的合成数据最不同。
- en: 10.6.4 Annotation for audio data
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.4 音频数据标注
- en: Speech annotation professionals often have highly specialized annotation tools.
    Professional transcribers use foot pedals that allow them to move a recording
    backward and forward quickly, for example. Speech segmentation and transcription
    interfaces predate computers, with many of the specialized technologies having
    been developed for tape recorders almost a century ago. We’ll cover the intersection
    of quality control and interfaces for audio in chapter 11.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 语音标注专业人士通常拥有高度专业化的标注工具。专业转录员使用脚控，例如，可以快速前后移动录音。语音分割和转录界面在计算机出现之前就已经存在，许多专门技术几乎一个世纪前就已经为磁带录音机开发了。我们将在第11章中介绍质量控制与音频界面的交集。
- en: Audio can be annotated as a labeling task, a sequence task, or a generation
    task, depending on the annotation requirements. Identifying whether human speech
    occurs is a labeling task, annotating when a certain person is speaking is a sequence
    task, and transcribing speech is a generation task. You can apply those techniques
    to these tasks.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 根据标注要求，音频可以标注为标记任务、序列任务或生成任务。识别人类语音是否发生是一个标记任务，标注某人在何时讲话是一个序列任务，转录语音是一个生成任务。你可以将这些技术应用于这些任务。
- en: Synthetic data is common in speech, especially when humans are asked to speak
    certain phrases. There aren’t many recordings of people speaking different languages
    that are available as open data. Where those recordings do exist, speech is often
    sensitive, so even a company that could capture a lot of speech data, such as
    a mobile-phone company, generally shouldn’t capture that data and should be careful
    about who can hear that data to annotate it. Therefore, asking someone to read
    text out loud is often the main way that many speech recognition datasets are
    created.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据在语音中很常见，尤其是在要求人类说出某些短语时。可用的公开数据中，关于人们说不同语言的录音并不多。在这些录音存在的地方，语音通常很敏感，因此即使是能够捕获大量语音数据的公司，如手机公司，通常也不应该捕获这些数据，并且应该小心谁可以听到这些数据来进行标注。因此，要求某人朗读文本通常是许多语音识别数据集创建的主要方式。
- en: Synthetic data is also used to ensure diversity of speech. Some combinations
    of phonemes (individual spoken sounds) are rare in most languages, for example.
    To make sure that the rarer combinations exist in the training data, people are
    often be given scripts of nonsensical text to read aloud; the words are carefully
    chosen to cover the rarer phoneme combinations. This approach might be repeated
    for people who speak with different accents.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据也用于确保语音的多样性。例如，某些音素（单个发音声音）在大多数语言中都很罕见。为了确保这些罕见的组合存在于训练数据中，人们通常会给出一些无意义的文本脚本，要求大声朗读；这些单词被仔细选择，以涵盖罕见的音素组合。这种方法可能需要为讲不同口音的人重复进行。
- en: 'Because of the sensitivity, companies that make smart devices have entire fake
    living rooms, bedrooms, and kitchens constructed to collect data. Actors are paid
    to interact with the devices, saying many commands while following instructions
    such as “Sit on the sofa facing away from the device.” If you already work in
    this area, I recommend inviting your friends and family members to visit one of
    these studios without giving them any context. It is truly bizarre to walk into
    a large, dark warehouse with a fake living room set up in the center, populated
    by people speaking nonsensical words: the experience feels like shape-shifting
    aliens are preparing to infiltrate the Earth.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 由于敏感性，制造智能设备的公司构建了完整的假客厅、卧室和厨房来收集数据。演员被雇佣与设备互动，在遵循诸如“坐在沙发上背对设备”的指示的同时发出许多命令。如果你已经在这个领域工作，我建议邀请你的朋友和家人参观这些工作室之一，而不要给他们任何背景信息。走进一个中心设有假客厅的大型、昏暗的仓库，里面充满了说些无意义话语的人，这种感觉就像变形外星人正在准备入侵地球，真是奇怪。
- en: 10.7 Further reading for annotation quality for different machine learning tasks
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.7 不同机器学习任务注释质量进一步阅读
- en: The literature for quality control for different tasks is sparser than for the
    other topics in this book, but some relevant papers discuss almost everything
    covered in the chapter.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书中其他主题相比，不同任务的质量控制文献较为稀少，但一些相关论文几乎讨论了章节中涵盖的所有内容。
- en: 10.7.1 Further reading for computer vision
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.7.1 计算机视觉进一步阅读
- en: A good recent paper on agreement is “Assessing Data Quality of Annotations with
    Krippendorff Alpha for Applications in Computer Vision,” by Joseph Nassar, Viveca
    Pavon-Harr, Marc Bosch, and Ian McCulloh ([http://mng.bz/7Vqg](http://mng.bz/7Vqg).)
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇关于数据质量评估的优秀论文是“使用Krippendorff Alpha评估计算机视觉应用中注释数据质量”，由Joseph Nassar、Viveca
    Pavon-Harr、Marc Bosch和Ian McCulloh撰写([http://mng.bz/7Vqg](http://mng.bz/7Vqg).)
- en: 'One of the most in-depth studies showing that there is no one right interface
    for all computer vision tasks is “Two Tools Are Better Than One: Tool Diversity
    As a means of Improving Aggregate Crowd Performance,” by Jean Y. Song, Raymond
    Fok, Alan Lundgard, Fan Yang, Juho Kim, and Walter S. Lasecki ([http://mng.bz/mg5M](http://mng.bz/mg5M)).
    This paper is also a good source of references to other recent work in annotation
    for computer vision.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 展示没有一种接口适合所有计算机视觉任务的深入研究的论文之一是“两个工具胜过一：工具多样性作为提高总体众包性能的手段”，由Jean Y. Song、Raymond
    Fok、Alan Lundgard、Fan Yang、Juho Kim和Walter S. Lasecki撰写([http://mng.bz/mg5M](http://mng.bz/mg5M))。这篇论文也是其他近期计算机视觉注释工作的良好参考资料。
- en: 'For data augmentation techniques in computer visions that are used for models
    but can be applied to annotation, I highly recommend *Computer Vision: Algorithms
    and Applications*, 2nd ed., by Richard Szeliski ([http://szeliski.org/Book](http://szeliski.org/Book)).'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 对于计算机视觉中用于模型但也可应用于注释的数据增强技术，我强烈推荐Richard Szeliski所著的《计算机视觉：算法与应用》，第2版([http://szeliski.org/Book](http://szeliski.org/Book))。
- en: For an interesting example of automating whether drawing a bounding box or having
    a review task is optimal for a certain image, see “Learning Intelligent Dialogs
    for Bounding Box Annotation,” by Ksenia Konyushkova, Jasper Uijlings, Christoph
    H. Lampert, and Vittorio Ferrari ([http://mng.bz/5jqD](http://mng.bz/5jqD)).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 对于自动化判断是否为特定图像绘制边界框或进行审查任务是否最优的有趣示例，请参阅“学习智能对话框进行边界框注释”，由Ksenia Konyushkova、Jasper
    Uijlings、Christoph H. Lampert和Vittorio Ferrari撰写([http://mng.bz/5jqD](http://mng.bz/5jqD))。
- en: 10.7.2 Further reading for annotation for natural language processing
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.7.2 自然语言处理注释进一步阅读
- en: Specific to natural language processing, “Inter-Coder Agreement for Computational
    Linguistics,” by Ron Artstein and Massimo Poesio, is a good foundational work
    that is especially strong for its discussion of agreement in sequence labeling
    and the complications with overlapping spans and identifying tokens or segments
    ([http://mng.bz/6gq6](http://mng.bz/6gq6)).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 专门针对自然语言处理，“计算语言学中的编码者间一致性”，由Ron Artstein和Massimo Poesio撰写，这是一项良好的基础工作，特别是在讨论序列标签中的协议及其与重叠范围和识别标记或段落的复杂性方面表现突出([http://mng.bz/6gq6](http://mng.bz/6gq6))。
- en: 'For language generation, a good recent paper is “Agreement is overrated: A
    plea for correlation to assess human evaluation reliability,” by Jacopo Amidei,
    Paul Piwek, and Alistair Willis ([http://mng.bz/opov](http://mng.bz/opov)). Note
    that they are talking about evaluating machine output, so the paper focuses on
    evaluation data, but this method can be applied to training data.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '对于语言生成，一篇不错的近期论文是“Agreement is overrated: A plea for correlation to assess
    human evaluation reliability”，作者是Jacopo Amidei、Paul Piwek和Alistair Willis ([http://mng.bz/opov](http://mng.bz/opov))。请注意，他们讨论的是评估机器输出，因此论文侧重于评估数据，但这种方法可以应用于训练数据。'
- en: 'A recent paper that looks at automated ways to evaluate text generation using
    machine learning methods that take advantage of pretrained models is “BLEURT:
    Learning Robust Metrics for Text Generation,” by Thibault Sellam, Dipanjan Das,
    and Ankur P. Parikh ([http://mng.bz/nM64](http://mng.bz/nM64)). See the references
    within the paper for other recent work on automated approaches to evaluating the
    quality of text generation systems.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '最近一篇关于使用利用预训练模型的优势的机器学习方法的自动评估文本生成的论文是“BLEURT: Learning Robust Metrics for
    Text Generation”，作者是Thibault Sellam、Dipanjan Das和Ankur P. Parikh ([http://mng.bz/nM64](http://mng.bz/nM64))。在论文中查看其他关于自动评估文本生成系统质量的新近工作的参考文献。'
- en: 10.7.3 Further reading for annotation for information retrieval
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.7.3 信息检索标注的进一步阅读
- en: 'See “How Many Workers to Ask?: Adaptive Exploration for Collecting High Quality
    Labels,” by Ittai Abraham, Omar Alonso, Vasileios Kandylas, Rajesh Patel, Steven
    Shelford, and Aleksandrs Slivkins ([http://mng.bz/vzQr](http://mng.bz/vzQr)).'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '参见“Ittai Abraham、Omar Alonso、Vasileios Kandylas、Rajesh Patel、Steven Shelford和Aleksandrs
    Slivkins的《How Many Workers to Ask?: Adaptive Exploration for Collecting High Quality
    Labels》”，[http://mng.bz/vzQr](http://mng.bz/vzQr)。'
- en: Summary
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: All machine learning tasks can take advantage of annotation strategies such
    as ground truth data, interannotator agreement, breaking tasks into subtasks,
    expert review and adjudication tasks, synthetic data, and (semi)automation via
    machine learning. Each approach has strengths and weaknesses, depending on the
    task, the data, and the problem that you are addressing.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有机器学习任务都可以利用诸如真实数据、标注者间一致性、将任务分解为子任务、专家评审和裁决任务、合成数据以及通过机器学习的（半）自动化等标注策略。每种方法都有其优势和劣势，这取决于任务、数据以及你正在解决的问题。
- en: Continuous tasks can accept a range of acceptable answers and in some cases
    can use wisdom of the crowds to determine whether it is better to accept the annotation
    of the best annotator instead of the average annotation value for an item.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续任务可以接受一系列可接受的答案，在某些情况下可以使用群体智慧来确定是否接受最佳标注者的标注而不是项目的平均标注值。
- en: Object detection tasks should track localization accuracy and label accuracy
    separately. Be cautious that IoU will produce lower scores in higher dimensions
    for the same general level of annotator performance.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标检测任务应分别跟踪定位准确性和标签准确性。请注意，IoU在维度较高时，对于相同的一般标注者性能水平，将产生较低的分数。
- en: Semantic segmentation can take advantage of review tasks in which expert annotators
    can adjudicate regions of disagreement instead of reannotating the entire image.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语义分割可以利用专家标注者可以裁决不同意见区域而不是重新标注整个图像的评审任务。
- en: Sequence labeling tasks typically use human-in-the-loop systems to generate
    candidates, especially when the important sequences are relatively rare.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列标注任务通常使用人类在环系统生成候选者，尤其是在重要序列相对罕见时。
- en: Language generation tasks typically have multiple acceptable answers. These
    answers can be evaluated against multiple ground truth examples per item or evaluated
    by humans who rate the output and are in turn evaluated on the accuracy and agreement
    of their ratings.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言生成任务通常有多个可接受的答案。这些答案可以针对每个项目进行多个真实示例的评估，或者由评估输出并对其准确性及一致性进行评估的人类进行评估。
- en: Other machine learning tasks, such as information retrieval, often use human-in-the-loop
    annotation systems, especially when a random sample of data would rarely surface
    relevant items.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他机器学习任务，如信息检索，通常使用人类在环的标注系统，尤其是在随机样本数据很少出现相关项目时。
