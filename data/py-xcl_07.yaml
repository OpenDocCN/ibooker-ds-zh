- en: Chapter 5\. Data Analysis with pandas
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第 5 章\. 使用 pandas 进行数据分析
- en: This chapter will introduce you to pandas, the Python Data Analysis Library
    or—how I like to put it—the Python-based spreadsheet with superpowers. It’s so
    powerful that some of the companies that I worked with have managed to get rid
    of Excel completely by replacing it with a combination of Jupyter notebooks and
    pandas. As a reader of this book, however, I assume you will keep Excel, in which
    case pandas will serve as an interface for getting data in and out of spreadsheets.
    pandas makes tasks that are particularly painful in Excel easier, faster, and
    less error-prone. Some of these tasks include getting big datasets from external
    sources and working with statistics, time series, and interactive charts. pandas’
    most important superpowers are vectorization and data alignment. As we’ve already
    seen in the previous chapter with NumPy arrays, vectorization allows you to write
    concise, array-based code while data alignment makes sure that there is no data
    mismatch when you work with multiple datasets.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将为您介绍 pandas，即 Python 数据分析库，或者——我喜欢这样说——具有超能力的基于 Python 的电子表格。它非常强大，以至于我曾与一些公司合作时，他们完全放弃了
    Excel，而是用 Jupyter 笔记本和 pandas 的组合来替代它。然而，作为本书的读者，我假设您会继续使用 Excel，在这种情况下，pandas
    将作为在电子表格中获取数据的接口。pandas 使在 Excel 中特别痛苦的任务变得更加简单、快速和少出错。其中一些任务包括从外部源获取大型数据集以及处理统计数据、时间序列和交互式图表。pandas
    最重要的超能力是向量化和数据对齐。正如我们在上一章中看到的使用 NumPy 数组一样，向量化使您能够编写简洁的基于数组的代码，而数据对齐则确保在处理多个数据集时不会出现数据不匹配的情况。
- en: 'This chapter covers the whole data analysis journey: it starts with cleaning
    and preparing data before it shows you how to make sense out of bigger datasets
    via aggregation, descriptive statistics, and visualization. At the end of the
    chapter, we’ll see how we can import and export data with pandas. But first things
    first—let’s get started with an introduction to pandas’ main data structures:
    DataFrame and Series!'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这一章涵盖了整个数据分析过程：从清洗和准备数据开始，然后通过聚合、描述统计和可视化来理解更大的数据集。在本章末尾，我们将看到如何使用 pandas 导入和导出数据。但首先，让我们从介绍
    pandas 的主要数据结构开始：DataFrame 和 Series！
- en: DataFrame and Series
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 和 Series
- en: 'DataFrame and Series are the core data structures in pandas. In this section,
    I am introducing them with a focus on the main components of a DataFrame: index,
    columns, and data. A DataFrame is similar to a two-dimensional NumPy array, but
    it comes with column and row labels and each column can hold different data types.
    By extracting a single column or row from a DataFrame, you get a one-dimensional
    Series. Again, a Series is similar to a one-dimensional NumPy array with labels.
    When you look at the structure of a DataFrame in [Figure 5-1](#filepos485286),
    it won’t take a lot of imagination to see that DataFrames are going to be your
    Python-based spreadsheets.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 和 Series 是 pandas 中的核心数据结构。在本节中，我将介绍它们，并重点介绍 DataFrame 的主要组成部分：索引、列和数据。DataFrame
    类似于二维 NumPy 数组，但它带有列和行标签，每列可以容纳不同的数据类型。通过从 DataFrame 中提取单列或单行，您会得到一个一维 Series。同样，Series
    类似于带有标签的一维 NumPy 数组。当您查看 [图 5-1](#filepos485286) 中 DataFrame 的结构时，您会很容易想象到，DataFrame
    就是您基于 Python 的电子表格。
- en: '![](images/00069.jpg)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00069.jpg)'
- en: Figure 5-1\. A pandas Series and DataFrame
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-1\. 一个 pandas Series 和 DataFrame
- en: To show you how easy it is to transition from a spreadsheet to a DataFrame,
    consider the following Excel table in [Figure 5-2](#filepos485969), which shows
    participants of an online course with their score. You will find the corresponding
    file course_participants.xlsx in the xl folder of the companion repo.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 要展示从电子表格转换到 DataFrame 有多容易，请考虑下面的 Excel 表格 [图 5-2](#filepos485969)，它显示了在线课程的参与者及其分数。您可以在伴随仓库的
    xl 文件夹中找到相应的文件 course_participants.xlsx。
- en: '![](images/00077.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00077.jpg)'
- en: Figure 5-2\. course_participants.xlsx
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-2\. course_participants.xlsx
- en: 'To make this Excel table available in Python, start by importing pandas, then
    use its `read_excel` function, which returns a DataFrame:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Python 中使用这个 Excel 表格，首先导入 pandas，然后使用它的`read_excel`函数，该函数返回一个 DataFrame：
- en: '`In``[``1``]:``import``pandas``as``pd`'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``1``]:``import``pandas``as``pd`'
- en: '`In``[``2``]:``pd``.``read_excel``(``"xl/course_participants.xlsx"``)`'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``2``]:``pd``.``read_excel``(``"xl/course_participants.xlsx"``)`'
- en: '`Out[2]:    user_id   name  age  country  score continent         0     1001  
    Mark   55    Italy    4.5    Europe         1     1000   John   33      USA   
    6.7   America         2     1002    Tim   41      USA    3.9   America        
    3     1003  Jenny   12  Germany    9.0    Europe`'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[2]:    user_id   name  age  country  score continent         0     1001  
    Mark   55    Italy    4.5    Europe         1     1000   John   33      USA   
    6.7   America         2     1002    Tim   41      USA    3.9   America        
    3     1003  Jenny   12  Germany    9.0    Europe`'
- en: THE READ_EXCEL FUNCTION WITH PYTHON 3.9
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: PYTHON 3.9下的READ_EXCEL函数
- en: If you are running `pd.read_excel` with Python 3.9 or above, make sure to use
    at least pandas 1.2 or you will get an error when reading xlsx files.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你在使用Python 3.9或更高版本运行`pd.read_excel`，请确保至少使用pandas 1.2，否则在读取xlsx文件时会出错。
- en: 'If you run this in a Jupyter notebook, the DataFrame will be nicely formatted
    as an HTML table, which makes it even closer to how the table looks in Excel.
    I will spend the whole of [Chapter 7](index_split_019.html#filepos863345) on reading
    and writing Excel files with pandas, so this was only an introductory example
    to show you that spreadsheets and DataFrames are, indeed, very similar. Let’s
    now re-create this DataFrame from scratch without reading it from the Excel file:
    one way of creating a DataFrame is to provide the data as a nested list, along
    with values for `columns` and `index`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在Jupyter笔记本中运行这段代码，DataFrame将以HTML表格的形式进行漂亮的格式化，这使得它与Excel中的表格更加接近。我将在[第7章](index_split_019.html#filepos863345)中详细介绍使用pandas读写Excel文件，因此这只是一个介绍性的示例，展示电子表格和DataFrame确实非常相似。现在让我们从头开始重新创建这个DataFrame，而不是从Excel文件中读取它：创建DataFrame的一种方法是提供数据作为嵌套列表，并为`columns`和`index`提供值：
- en: '`In``[``3``]:``data``=``[[``"Mark"``,``55``,``"Italy"``,``4.5``,``"Europe"``],``[``"John"``,``33``,``"USA"``,``6.7``,``"America"``],``[``"Tim"``,``41``,``"USA"``,``3.9``,``"America"``],``[``"Jenny"``,``12``,``"Germany"``,``9.0``,``"Europe"``]]``df``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"name"``,``"age"``,``"country"``,``"score"``,``"continent"``],``index``=``[``1001``,``1000``,``1002``,``1003``])``df`'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``3``]:``data``=``[[``"Mark"``,``55``,``"Italy"``,``4.5``,``"Europe"``],``[``"John"``,``33``,``"USA"``,``6.7``,``"America"``],``[``"Tim"``,``41``,``"USA"``,``3.9``,``"America"``],``[``"Jenny"``,``12``,``"Germany"``,``9.0``,``"Europe"``]]``df``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"name"``,``"age"``,``"country"``,``"score"``,``"continent"``],``index``=``[``1001``,``1000``,``1002``,``1003``])``df`'
- en: '`Out[3]:        name  age  country  score continent         1001   Mark   55   
    Italy    4.5    Europe         1000   John   33      USA    6.7   America        
    1002    Tim   41      USA    3.9   America         1003  Jenny   12  Germany   
    9.0    Europe`'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[3]:        name  age  country  score continent         1001   Mark   55   
    Italy    4.5    Europe         1000   John   33      USA    6.7   America        
    1002    Tim   41      USA    3.9   America         1003  Jenny   12  Germany   
    9.0    Europe`'
- en: 'By calling the `info` method, you will get some basic information, most importantly
    the number of data points and the data types for each column:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用`info`方法，您将获得一些基本信息，最重要的是数据点的数量和每列的数据类型：
- en: '`In``[``4``]:``df``.``info``()`'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``4``]:``df``.``info``()`'
- en: '`<class ''pandas.core.frame.DataFrame''> Int64Index: 4 entries, 1001 to 1003
    Data columns (total 5 columns): #   Column     Non-Null Count  Dtype ---  ------    
    --------------  ----- 0   name       4 non-null      object 1   age        4 non-null     
    int64 2   country    4 non-null      object 3   score      4 non-null      float64
    4   continent  4 non-null      object dtypes: float64(1), int64(1), object(3)
    memory usage: 192.0+ bytes`'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`<class ''pandas.core.frame.DataFrame''> Int64Index: 4 entries, 1001 to 1003
    Data columns (total 5 columns): #   Column     Non-Null Count  Dtype ---  ------    
    --------------  ----- 0   name       4 non-null      object 1   age        4 non-null     
    int64 2   country    4 non-null      object 3   score      4 non-null      float64
    4   continent  4 non-null      object dtypes: float64(1), int64(1), object(3)
    memory usage: 192.0+ bytes`'
- en: If you are just interested in the data type of your columns, run `df.dtypes`
    instead. Columns with strings or mixed data types will have the data type `object`.
    [1](index_split_016.html#filepos767133) Let us now have a closer look at the index
    and columns of a DataFrame.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只对列的数据类型感兴趣，请运行`df.dtypes`。字符串或混合数据类型的列将具有数据类型`object`。[1](index_split_016.html#filepos767133)
    现在让我们更详细地看一下DataFrame的索引和列。
- en: Index
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 索引
- en: 'The row labels of a DataFrame are called index. If you don’t have a meaningful
    index, leave it away when constructing a DataFrame. pandas will then automatically
    create an integer index starting at zero. We saw this in the very first example
    when we read the DataFrame from the Excel file. An index will allow pandas to
    look up data faster and is essential for many common operations, e.g., combining
    two DataFrames. You access the index object like the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame的行标签称为索引。如果没有有意义的索引，请在构造DataFrame时将其省略。pandas将自动创建从零开始的整数索引。我们在从Excel文件读取DataFrame的第一个示例中看到了这一点。索引将允许pandas更快地查找数据，并对许多常见操作至关重要，例如合并两个DataFrame。您可以像以下方式访问索引对象：
- en: '`In``[``5``]:``df``.``index`'
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``5``]:``df``.``index`'
- en: '`Out[5]: Int64Index([1001, 1000, 1002, 1003], dtype=''int64'')`'
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[5]: Int64Index([1001, 1000, 1002, 1003], dtype=''int64'')`'
- en: 'If it makes sense, give the index a name. Let’s follow the table in Excel,
    and give it the name `user_id`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有意义，给索引起个名字。让我们按照Excel表格的方式，并给它命名为`user_id`：
- en: '`In``[``6``]:``df``.``index``.``name``=``"user_id"``df`'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``6``]:``df``.``index``.``name``=``"user_id"``df`'
- en: '`Out[6]:           name  age  country  score continent         user_id        
    1001      Mark   55    Italy    4.5    Europe         1000      John   33     
    USA    6.7   America         1002       Tim   41      USA    3.9   America        
    1003     Jenny   12  Germany    9.0    Europe`'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[6]:           name  age  country  score continent         user_id        
    1001      Mark   55    Italy    4.5    Europe         1000      John   33     
    USA    6.7   America         1002       Tim   41      USA    3.9   America        
    1003     Jenny   12  Germany    9.0    Europe`'
- en: 'Unlike the primary key of a database, a DataFrame index can have duplicates,
    but looking up values may be slower in that case. To turn an index into a regular
    column use `reset_index`, and to set a new index use `set_index`. If you don’t
    want to lose your existing index when setting a new one, make sure to reset it
    first:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 与数据库的主键不同，DataFrame索引可以具有重复项，但在这种情况下查找值可能较慢。要将索引转换为常规列，请使用`reset_index`，要设置新索引，请使用`set_index`。如果您不想在设置新索引时丢失现有索引，请确保首先重置它：
- en: '`In``[``7``]:``# "reset_index" turns the index into a column, replacing the``#
    index with the default index. This corresponds to the DataFrame``# from the beginning
    that we loaded from Excel.``df``.``reset_index``()`'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``7``]:``# "reset_index"将索引转换为列，用默认索引替换``# 从最开始加载的DataFrame对应的数据框``df``.``reset_index``()`'
- en: '`Out[7]:    user_id   name  age  country  score continent         0     1001  
    Mark   55    Italy    4.5    Europe         1     1000   John   33      USA   
    6.7   America         2     1002    Tim   41      USA    3.9   America        
    3     1003  Jenny   12  Germany    9.0    Europe`'
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[7]:    user_id   name  age  country  score continent         0     1001  
    Mark   55    Italy    4.5    Europe         1     1000   John   33      USA   
    6.7   America         2     1002    Tim   41      USA    3.9   America        
    3     1003  Jenny   12  Germany    9.0    Europe`'
- en: '`In``[``8``]:``# "reset_index" turns "user_id" into a regular column and``#
    "set_index" turns the column "name" into the index``df``.``reset_index``()``.``set_index``(``"name"``)`'
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``8``]:``# "reset_index"将"user_id"转换为常规列，而``# "set_index"将列"name"转换为索引``df``.``reset_index``()``.``set_index``(``"name"``)`'
- en: '`Out[8]:        user_id  age  country  score continent         name        
    Mark      1001   55    Italy    4.5    Europe         John      1000   33     
    USA    6.7   America         Tim       1002   41      USA    3.9   America        
    Jenny     1003   12  Germany    9.0    Europe`'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[8]:        user_id  age  country  score continent         name        
    Mark      1001   55    Italy    4.5    Europe         John      1000   33     
    USA    6.7   America         Tim       1002   41      USA    3.9   America        
    Jenny     1003   12  Germany    9.0    Europe`'
- en: 'By doing `df.reset_index().set_index("name")`, you are using method chaining:
    since `reset_index()` returns a DataFrame, you can directly call another DataFrame
    method without having to write out the intermediate result first.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`df.reset_index().set_index("name")`时，您正在使用方法链接：因为`reset_index()`返回一个DataFrame，所以您可以直接调用另一个DataFrame方法，而不必先编写中间结果。
- en: DATAFRAME METHODS RETURN COPIES
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: DATAFRAME METHODS RETURN COPIES
- en: 'Whenever you call a method on a DataFrame in the form `df.method_name()`, you
    will get back a copy of the DataFrame with that method applied, leaving the original
    DataFrame untouched. We have just done that by calling `df.reset_index()`. If
    you wanted to change the original DataFrame, you would have to assign the return
    value back to the original variable like the following:'
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 每当您在DataFrame上调用形式为`df.method_name()`的方法时，您将获得一个应用了该方法的DataFrame副本，保留原始DataFrame不变。我们刚刚通过调用`df.reset_index()`做到了这一点。如果您想要更改原始DataFrame，您需要将返回值分配回原始变量，如下所示：
- en: '`df = df.reset_index()`'
  id: totrans-38
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df = df.reset_index()`'
- en: Since we are not doing this, it means that our variable `df` is still holding
    its original data. The next samples also call DataFrame methods, i.e., don’t change
    the original DataFrame.
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由于我们没有这样做，这意味着我们的变量 `df` 仍然保留其原始数据。接下来的示例也调用了 DataFrame 方法，即不更改原始 DataFrame。
- en: 'To change the index, use the `reindex` method:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要更改索引，请使用 `reindex` 方法：
- en: '`In``[``9``]:``df``.``reindex``([``999``,``1000``,``1001``,``1004``])`'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``9``]:``df``.``reindex``([``999``,``1000``,``1001``,``1004``])`'
- en: '`Out[9]:          name   age country  score continent         user_id        
    999       NaN   NaN     NaN    NaN       NaN         1000     John  33.0     USA   
    6.7   America         1001     Mark  55.0   Italy    4.5    Europe         1004     
    NaN   NaN     NaN    NaN       NaN`'
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[9]:          name   age country  score continent         user_id        
    999       NaN   NaN     NaN    NaN       NaN         1000     John  33.0     USA   
    6.7   America         1001     Mark  55.0   Italy    4.5    Europe         1004     
    NaN   NaN     NaN    NaN       NaN`'
- en: 'This is a first example of data alignment at work: `reindex` will take over
    all rows that match the new index and will introduce rows with missing values
    (`NaN`) where no information exists. Index elements that you leave away will be
    dropped. I will introduce `NaN` properly a bit later in this chapter. Finally,
    to sort an index, use the `sort_index` method:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据对齐的第一个示例：`reindex` 将接管所有匹配新索引的行，并将在不存在信息的地方引入带有缺失值（`NaN`）的行。你留下的索引元素将被删除。稍后在本章中，我将适当地介绍
    `NaN`。最后，要对索引进行排序，请使用 `sort_index` 方法：
- en: '`In``[``10``]:``df``.``sort_index``()`'
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``10``]:``df``.``sort_index``()`'
- en: '`Out[10]:           name  age  country  score continent          user_id         
    1000      John   33      USA    6.7   America          1001      Mark   55   
    Italy    4.5    Europe          1002       Tim   41      USA    3.9   America
             1003     Jenny   12  Germany    9.0    Europe`'
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[10]:           name  age  country  score continent          user_id         
    1000      John   33      USA    6.7   America          1001      Mark   55   
    Italy    4.5    Europe          1002       Tim   41      USA    3.9   America
             1003     Jenny   12  Germany    9.0    Europe`'
- en: 'If, instead, you want to sort the rows by one or more columns, use `sort_values`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想按一列或多列对行进行排序，请使用 `sort_values`：
- en: '`In``[``11``]:``df``.``sort_values``([``"continent"``,``"age"``])`'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``11``]:``df``.``sort_values``([``"continent"``,``"age"``])`'
- en: '`Out[11]:           name  age  country  score continent          user_id         
    1000      John   33      USA    6.7   America          1002       Tim   41     
    USA    3.9   America          1003     Jenny   12  Germany    9.0    Europe         
    1001      Mark   55    Italy    4.5    Europe`'
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[11]:           name  age  country  score continent          user_id         
    1000      John   33      USA    6.7   America          1002       Tim   41     
    USA    3.9   America          1003     Jenny   12  Germany    9.0    Europe         
    1001      Mark   55    Italy    4.5    Europe`'
- en: 'The sample shows how to sort first by `continent`, then by `age`. If you wanted
    to sort by only one column, you could also provide the column name as a string:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例展示了如何首先按 `continent`，然后按 `age` 进行排序。如果只想按一列排序，也可以将列名作为字符串提供：
- en: '`df.sort_values("continent")`'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df.sort_values("continent")`'
- en: This has covered the basics of how indices work. Let’s now turn our attention
    to its horizontal equivalent, the DataFrame columns!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这涵盖了索引如何工作的基础知识。现在让我们将注意力转向其水平对应物，即 DataFrame 的列！
- en: Columns
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 列
- en: 'To get information about the columns of a DataFrame, run the following code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取 DataFrame 的列信息，请运行以下代码：
- en: '`In``[``12``]:``df``.``columns`'
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``12``]:``df``.``columns``'
- en: '`Out[12]: Index([''name'', ''age'', ''country'', ''score'', ''continent''],
    dtype=''object'')`'
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[12]: Index([''name'', ''age'', ''country'', ''score'', ''continent''],
    dtype=''object'')`'
- en: 'If you don’t provide any column names when constructing a DataFrame, pandas
    will number the columns with integers starting at zero. With columns, however,
    this is almost never a good idea as columns represent variables and are therefore
    easy to name. You assign a name to the column headers in the same way we did it
    with the index:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在构建 DataFrame 时没有提供任何列名，pandas 将使用从零开始的整数为列编号。然而，对于列来说，这几乎从来不是一个好主意，因为列表示变量，因此易于命名。你可以像设置索引一样给列头分配一个名称：
- en: '`In``[``13``]:``df``.``columns``.``name``=``"properties"``df`'
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``13``]:``df``.``columns``.``name``=``"properties"``df`'
- en: '`Out[13]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1000        
    John   33      USA    6.7   America          1002          Tim   41      USA   
    3.9   America          1003        Jenny   12  Germany    9.0    Europe`'
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[13]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1000        
    John   33      USA    6.7   America          1002          Tim   41      USA   
    3.9   America          1003        Jenny   12  Germany    9.0    Europe`'
- en: 'If you don’t like the column names, rename them:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不喜欢列名，可以重命名它们：
- en: '`In``[``14``]:``df``.``rename``(``columns``=``{``"name"``:``"First Name"``,``"age"``:``"Age"``})`'
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``14``]:``df``.``rename``(``columns``=``{``"name"``:``"First Name"``,``"age"``:``"Age"``})`'
- en: '`Out[14]: properties First Name  Age  country  score continent          user_id
             1001             Mark   55    Italy    4.5    Europe          1000            
    John   33      USA    6.7   America          1002              Tim   41      USA   
    3.9   America          1003            Jenny   12  Germany    9.0    Europe`'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[14]: properties First Name  Age  country  score continent          user_id
             1001             Mark   55    Italy    4.5    Europe          1000            
    John   33      USA    6.7   America          1002              Tim   41      USA   
    3.9   America          1003            Jenny   12  Germany    9.0    Europe`'
- en: 'If you want to delete columns, use the following syntax (the sample shows you
    how to drop columns and indices at the same time):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要删除列，请使用以下语法（示例显示如何同时删除列和索引）：
- en: '`In``[``15``]:``df``.``drop``(``columns``=``[``"name"``,``"country"``],``index``=``[``1000``,``1003``])`'
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``15``]:``df``.``drop``(``columns``=``[``"name"``,``"country"``],``index``=``[``1000``,``1003``])`'
- en: '`Out[15]: properties  age  score continent          user_id          1001        
    55    4.5    Europe          1002         41    3.9   America`'
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[15]: properties  age  score continent          user_id          1001        
    55    4.5    Europe          1002         41    3.9   America`'
- en: 'The columns and the index of a DataFrame are both represented by an `Index`
    object, so you can change your columns into rows and vice versa by transposing
    your DataFrame:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame的列和索引都由一个`Index`对象表示，因此可以通过转置DataFrame来将列变为行，反之亦然：
- en: '`In``[``16``]:``df``.``T``# Shortcut for df.transpose()`'
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``16``]:``df``.``T``# df.transpose()的快捷方式`'
- en: '`Out[16]: user_id       1001     1000     1002     1003          properties
             name          Mark     John      Tim    Jenny          age            
    55       33       41       12          country      Italy      USA      USA  Germany
             score          4.5      6.7      3.9        9          continent   Europe 
    America  America   Europe`'
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[16]: user_id       1001     1000     1002     1003          properties
             name          Mark     John      Tim    Jenny          age            
    55       33       41       12          country      Italy      USA      USA  Germany
             score          4.5      6.7      3.9        9          continent   Europe 
    America  America   Europe`'
- en: 'It’s worth remembering here that our DataFrame `df` is still unchanged, as
    we have never reassigned the returning DataFrame from the method calls back to
    the original `df` variable. If you would like to reorder the columns of a DataFrame,
    you could use the `reindex` method that we used with the index, but selecting
    the columns in the desired order is often more intuitive:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 值得在这里记住的是，我们的DataFrame `df` 仍然没有改变，因为我们从未将方法调用返回的DataFrame重新分配给原始的 `df` 变量。如果想要重新排列DataFrame的列，可以使用我们与索引一起使用的`reindex`方法，但通常更直观的是按所需顺序选择列：
- en: '`In``[``17``]:``df``.``loc``[:,``[``"continent"``,``"country"``,``"name"``,``"age"``,``"score"``]]`'
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``17``]:``df``.``loc``[:,``[``"continent"``,``"country"``,``"name"``,``"age"``,``"score"``]]`'
- en: '`Out[17]: properties continent  country   name  age  score          user_id
             1001          Europe    Italy   Mark   55    4.5          1000        
    America      USA   John   33    6.7          1002         America      USA   
    Tim   41    3.9          1003          Europe  Germany  Jenny   12    9.0`'
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[17]: properties continent  country   name  age  score          user_id
             1001          Europe    Italy   Mark   55    4.5          1000        
    America      USA   John   33    6.7          1002         America      USA   
    Tim   41    3.9          1003          Europe  Germany  Jenny   12    9.0`'
- en: 'This last example needs quite a few explanations: everything about `loc` and
    how data selection works is the topic of the next section.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最后这个例子需要解释的地方很多：关于`loc`以及数据选择工作方式的所有内容都是下一节的主题。
- en: Data Manipulation
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 数据操作
- en: Real-world data hardly gets served on a silver platter, so before working with
    it, you need to clean it and bring it into a digestible form. We’ll begin this
    section by looking at how to select data from a DataFrame, how to change it, and
    how to deal with missing and duplicate data. We’ll then perform a few calculations
    with DataFrames and see how you work with text data. To wrap this section up,
    we’ll find out when pandas returns a view vs. a copy of the data. Quite a few
    concepts in this section are related to what we have already seen with NumPy arrays
    in the last chapter.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界中的数据很少是一成不变的，因此在处理数据之前，您需要清理数据并将其转换为可消化的形式。我们将从查找如何从DataFrame中选择数据开始，如何更改数据，以及如何处理缺失和重复数据。然后，我们将对DataFrame执行几个计算，并查看如何处理文本数据。最后，我们将了解pandas在返回数据视图与副本时的情况。本节中有许多概念与我们在上一章中使用NumPy数组时所见的概念相关。
- en: Selecting Data
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 数据选择
- en: Let’s start with accessing data by label and position before looking at other
    methods, including boolean indexing and selecting data by using a MultiIndex.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先在查看其他方法之前，通过标签和位置访问数据，包括布尔索引和使用 MultiIndex 选择数据。
- en: Selecting by label
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 按标签选择
- en: 'The most common way of accessing the data of a DataFrame is by referring to
    its labels. Use the attribute `loc`, which stands for location, to specify which
    rows and columns you want to retrieve:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 访问 DataFrame 数据的最常见方法是引用其标签。使用属性 `loc`，代表位置，指定要检索的行和列：
- en: '`df``.``loc``[``row_selection``,``column_selection``]`'
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df``.``loc``[``row_selection``,``column_selection``]`'
- en: '`loc` supports the slice notation and therefore accepts a colon to select all
    rows or columns, respectively. Additionally, you can provide lists with labels
    as well as a single column or row name. Have a look at [Table 5-1](#filepos526726)
    to see a few examples of how you select different parts from our sample DataFrame
    `df`.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`loc` 支持切片表示法，因此可以接受冒号来分别选择所有行或列。另外，您还可以提供标签列表以及单个列或行名称。请查看[表格 5-1](#filepos526726)以查看从我们的样本
    DataFrame `df` 中选择不同部分的几个示例。'
- en: Table 5-1\. Data selection by label
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-1\. 按标签选择数据
- en: '|  Selection  |  Return Data Type  |  Example  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '|  选择  |  返回数据类型  |  示例  |'
- en: '|  Single value  |  Scalar  |   `df.loc[1000, "country"]` |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  单个值  |  标量  |   `df.loc[1000, "country"]` |'
- en: '|  One column (1d)  |  Series  |   `df.loc[:, "country"]` |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|  单列（1d）  |  Series  |   `df.loc[:, "country"]` |'
- en: '|  One column (2d)  |  DataFrame  |   `df.loc[:, ["country"]]` |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '|  单列（2d）  |  DataFrame  |   `df.loc[:, ["country"]]` |'
- en: '|  Multiple columns  |  DataFrame  |   `df.loc[:, ["country", "age"]]` |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '|  多列  |  DataFrame  |   `df.loc[:, ["country", "age"]]` |'
- en: '|  Range of columns  |  DataFrame  |   `df.loc[:, "name":"country"]` |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  列范围  |  DataFrame  |   `df.loc[:, "name":"country"]` |'
- en: '|  One row (1d)  |  Series  |   `df.loc[1000, :]` |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|  单行（1d）  |  Series  |   `df.loc[1000, :]` |'
- en: '|  One row (2d)  |  DataFrame  |   `df.loc[[1000], :]` |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '|  单行（2d）  |  DataFrame  |   `df.loc[[1000], :]` |'
- en: '|  Multiple rows  |  DataFrame  |   `df.loc[[1003, 1000], :]` |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|  多行  |  DataFrame  |   `df.loc[[1003, 1000], :]` |'
- en: '|  Range of rows  |  DataFrame  |   `df.loc[1000:1002, :]` |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  行范围  |  DataFrame  |   `df.loc[1000:1002, :]` |'
- en: LABEL SLICING HAS CLOSED INTERVALS
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 标签切片具有闭合间隔
- en: 'Using slice notation with labels is inconsistent with respect to how everything
    else in Python and pandas works: they include the upper end.'
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用标签的切片表示法与 Python 和 pandas 中其他一切的工作方式不一致：它们包括上限端点。
- en: 'Applying our knowledge from [Table 5-1](#filepos526726), let’s use `loc` to
    select scalars, Series, and DataFrames:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 应用我们从[表格 5-1](#filepos526726)中获得的知识，让我们使用 `loc` 来选择标量、Series 和 DataFrames：
- en: '`In``[``18``]:``# Using scalars for both row and column selection returns a
    scalar``df``.``loc``[``1001``,``"name"``]`'
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``18``]:``# 对行和列选择使用标量返回标量``df``.``loc``[``1001``,``"name"``]`'
- en: '`Out[18]: ''Mark''`'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[18]: ''Mark''`'
- en: '`In``[``19``]:``# Using a scalar on either the row or column selection returns
    a Series``df``.``loc``[[``1001``,``1002``],``"age"``]`'
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``19``]:``# 在行或列选择上使用标量返回 Series``df``.``loc``[[``1001``,``1002``],``"age"``]`'
- en: '`Out[19]: user_id          1001    55          1002    41          Name: age,
    dtype: int64`'
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[19]: user_id          1001    55          1002    41          Name: age,
    dtype: int64`'
- en: '`In``[``20``]:``# Selecting multiple rows and columns returns a DataFrame``df``.``loc``[:``1002``,``[``"name"``,``"country"``]]`'
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``20``]:``# 选择多行和多列返回 DataFrame``df``.``loc``[:``1002``,``[``"name"``,``"country"``]]`'
- en: '`Out[20]: properties  name country          user_id          1001        Mark  
    Italy          1000        John     USA          1002         Tim     USA`'
  id: totrans-99
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[20]: properties  name country          user_id          1001        Mark  
    Italy          1000        John     USA          1002         Tim     USA`'
- en: 'It’s important for you to understand the difference between a DataFrame with
    one or more columns and a Series: even with a single column, DataFrames are two-dimensional,
    while Series are one-dimensional. Both DataFrame and Series have an index, but
    only the DataFrame has column headers. When you select a column as Series, the
    column header becomes the name of the Series. Many functions or methods will work
    on both Series and DataFrame, but when you perform arithmetic calculations, the
    behavior differs: with DataFrames, pandas aligns the data according to the column
    headers—more about that a little later in this chapter.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，您要理解 DataFrame 与 Series 之间的区别：即使有单个列，DataFrame 也是二维的，而 Series 是一维的。DataFrame
    和 Series 都有索引，但只有 DataFrame 有列标题。当您将列选择为 Series 时，列标题将成为 Series 的名称。许多函数或方法将同时适用于
    Series 和 DataFrame，但在执行算术计算时，行为会有所不同：对于 DataFrame，pandas 根据列标题对齐数据—稍后在本章中会详细介绍。
- en: SHORTCUT FOR COLUMN SELECTION
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 列选择的快捷方式
- en: 'Since selecting columns is such a common operation, pandas offers a shortcut.
    Instead of:'
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由于选择列是一个如此常见的操作，pandas 提供了一个快捷方式。而不是：
- en: '`df``.``loc``[:,``column_selection``]`'
  id: totrans-103
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df``.``loc``[:,``column_selection``]`'
- en: 'you can write:'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以这样写：
- en: '`df``[``column_selection``]`'
  id: totrans-105
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df``[``column_selection``]`'
- en: For example, `df["country"]` returns a Series from our sample DataFrame and
    `df[["name", "country"]]` returns a DataFrame with two columns.
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，`df["country"]` 从我们的示例 DataFrame 返回一个 Series，而 `df[["name", "country"]]`
    返回一个包含两列的 DataFrame。
- en: Selecting by position
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 按位置选择
- en: 'Selecting a subset of a DataFrame by position corresponds to what we did at
    the beginning of this chapter with NumPy arrays. With DataFrames, however, you
    have to use the `iloc` attribute, which stands for integer location:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 通过位置选择 DataFrame 的子集对应于我们在本章开始时使用 NumPy 数组所做的事情。但是，对于 DataFrame，你必须使用 `iloc`
    属性，它代表整数位置：
- en: '`df``.``iloc``[``row_selection``,``column_selection``]`'
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df``.``iloc``[``row_selection``,``column_selection``]`'
- en: When using slices, you deal with the standard half-open intervals. [Table 5-2](#filepos540243)
    gives you the same cases we looked at previously in [Table 5-1](#filepos526726).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用切片时，你要处理标准的半开区间。[表 5-2](#filepos540243) 给出了与我们之前在 [表 5-1](#filepos526726)
    中查看的相同案例。
- en: Table 5-2\. Data selection by position
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-2\. 按位置选择数据
- en: '|  Selection  |  Return Data Type  |  Example  |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  选择  |  返回数据类型  |  示例  |'
- en: '|  Single value  |  Scalar  |   `df.iloc[1, 2]` |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|  单个值  |  Scalar  |   `df.iloc[1, 2]` |'
- en: '|  One column (1d)  |  Series  |   `df.iloc[:, 2]` |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '|  一列（1d）  |  Series  |   `df.iloc[:, 2]` |'
- en: '|  One column (2d)  |  DataFrame  |   `df.iloc[:, [2]]` |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  一列（2d）  |  DataFrame  |   `df.iloc[:, [2]]` |'
- en: '|  Multiple columns  |  DataFrame  |   `df.iloc[:, [2, 1]]` |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  多列  |  DataFrame  |   `df.iloc[:, [2, 1]]` |'
- en: '|  Range of columns  |  DataFrame  |   `df.iloc[:, :3]` |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  列范围  |  DataFrame  |   `df.iloc[:, :3]` |'
- en: '|  One row (1d)  |  Series  |   `df.iloc[1, :]` |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|  一行（1d）  |  Series  |   `df.iloc[1, :]` |'
- en: '|  One row (2d)  |  DataFrame  |   `df.iloc[[1], :]` |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  一行（2d）  |  DataFrame  |   `df.iloc[[1], :]` |'
- en: '|  Multiple rows  |  DataFrame  |   `df.iloc[[3, 1], :]` |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|  多行  |  DataFrame  |   `df.iloc[[3, 1], :]` |'
- en: '|  Range of rows  |  DataFrame  |   `df.iloc[1:3, :]` |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '|  行范围  |  DataFrame  |   `df.iloc[1:3, :]` |'
- en: 'Here is how you use `iloc`—again with the same samples that we used with `loc`
    before:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何使用 `iloc` 的方法——与之前使用 `loc` 的样本相同：
- en: '`In``[``21``]:``df``.``iloc``[``0``,``0``]``# Returns a Scalar`'
  id: totrans-123
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``21``]:``df``.``iloc``[``0``,``0``]``# 返回一个 Scalar`'
- en: '`Out[21]: ''Mark''`'
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[21]: ''Mark''`'
- en: '`In``[``22``]:``df``.``iloc``[[``0``,``2``],``1``]``# Returns a Series`'
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``22``]:``df``.``iloc``[[``0``,``2``],``1``]``# 返回一个 Series`'
- en: '`Out[22]: user_id          1001    55          1002    41          Name: age,
    dtype: int64`'
  id: totrans-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[22]: user_id          1001    55          1002    41          Name: age,
    dtype: int64`'
- en: '`In``[``23``]:``df``.``iloc``[:``3``,``[``0``,``2``]]``# Returns a DataFrame`'
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``23``]:``df``.``iloc``[:``3``,``[``0``,``2``]]``# 返回一个 DataFrame`'
- en: '`Out[23]: properties  name country          user_id          1001        Mark  
    Italy          1000        John     USA          1002         Tim     USA`'
  id: totrans-128
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[23]: properties  name country          user_id          1001        Mark  
    Italy          1000        John     USA          1002         Tim     USA`'
- en: Selecting data by label or position is not the only means to access a subset
    of your DataFrame. Another important way is to use boolean indexing; let’s see
    how it works!
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 按标签或位置选择数据并不是访问 DataFrame 子集的唯一方式。另一种重要的方式是使用布尔索引；让我们看看它是如何工作的！
- en: Selecting by boolean indexing
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 按布尔索引选择
- en: 'Boolean indexing refers to selecting subsets of a DataFrame with the help of
    a Series or a DataFrame whose data consists of only `True` or `False`. Boolean
    Series are used to select specific columns and rows of a DataFrame, while boolean
    DataFrames are used to select specific values across a whole DataFrame. Most commonly,
    you will use boolean indexing to filter the rows of a DataFrame. Think of it as
    the AutoFilter functionality in Excel. For example, this is how you filter your
    DataFrame so it only shows people who live in the USA and are older than 40 years:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 布尔索引是指使用仅包含 `True` 或 `False` 的 Series 或 DataFrame 来选择 DataFrame 的子集。布尔 Series
    用于选择 DataFrame 的特定列和行，而布尔 DataFrame 用于选择整个 DataFrame 中的特定值。最常见的用法是用布尔索引来过滤 DataFrame
    的行。可以把它看作是 Excel 中的自动筛选功能。例如，这是如何筛选只显示住在美国且年龄超过 40 岁的人的 DataFrame 的方法：
- en: '`In``[``24``]:``tf``=``(``df``[``"age"``]``>``40``)``&``(``df``[``"country"``]``==``"USA"``)``tf``#
    This is a Series with only True/False`'
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``24``]:``tf``=``(``df``[``"age"``]``>``40``)``&``(``df``[``"country"``]``==``"USA"``)``tf``#
    这是一个仅包含 True/False 的 Series`'
- en: '`Out[24]: user_id          1001    False          1000    False          1002    
    True          1003    False          dtype: bool`'
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[24]: user_id          1001    False          1000    False          1002    
    True          1003    False          dtype: bool`'
- en: '`In``[``25``]:``df``.``loc``[``tf``,``:]`'
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``25``]:``df``.``loc``[``tf``,``:]`'
- en: '`Out[25]: properties name  age country  score continent          user_id         
    1002        Tim   41     USA    3.9   America`'
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[25]: properties name  age country  score continent          user_id         
    1002        Tim   41     USA    3.9   America`'
- en: There are two things I need to explain here. First, due to technical limitations,
    you can’t use Python’s boolean operators from [Chapter 3](index_split_010.html#filepos178328)
    with DataFrames. Instead, you need to use the symbols as shown in [Table 5-3](#filepos554254).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两件事需要解释。首先，由于技术限制，你不能在数据框（DataFrames）中像[第三章](index_split_010.html#filepos178328)中那样使用Python的布尔运算符。相反，你需要使用如[表5-3](#filepos554254)所示的符号。
- en: Table 5-3\. Boolean operators
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 表5-3\. 布尔运算符
- en: '|  Basic Python Data Types  |  DataFrames and Series  |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '|  基本Python数据类型  |  数据框和Series  |'
- en: '|   `and` |   `&` |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|   `and` |   `&` |'
- en: '|   `or` |   `&#124;` |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '|   `or` |   `&#124;` |'
- en: '|   `not` |   `~` |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '|   `not` |   `~` |'
- en: 'Second, if you have more than one condition, make sure to put every boolean
    expression in between parentheses so operator precedence doesn’t get in your way:
    for example, `&` has higher operator precedence than `==`. Therefore, without
    parentheses, the expression from the sample would be interpreted as:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，如果你有多个条件，请确保将每个布尔表达式放在括号中，以避免运算符优先级成为问题：例如，`&`的运算符优先级高于`==`。因此，如果没有括号，示例中的表达式将被解释为：
- en: '`df``[``"age"``]``>``(``40``&``df``[``"country"``])``==``"USA"`'
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df``[``"age"``]``>``(``40``&``df``[``"country"``])``==``"USA"`'
- en: 'If you want to filter the index, you can refer to it as `df.index`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要过滤索引，你可以引用它作为`df.index`：
- en: '`In``[``26``]:``df``.``loc``[``df``.``index``>``1001``,``:]`'
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``26``]:``df``.``loc``[``df``.``index``>``1001``,``:]`'
- en: '`Out[26]: properties   name  age  country  score continent          user_id
             1002          Tim   41      USA    3.9   America          1003       
    Jenny   12  Germany    9.0    Europe`'
  id: totrans-146
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[26]: properties   name  age  country  score continent          user_id
             1002          Tim   41      USA    3.9   America          1003       
    Jenny   12  Germany    9.0    Europe`'
- en: 'For what you would use the `in` operator with basic Python data structures
    like lists, use `isin` with a Series. This is how you filter your DataFrame to
    participants from Italy and Germany:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在基本的Python数据结构（如列表）中使用`in`操作符，那么在Series中使用`isin`来过滤你的数据框（DataFrame）以选择来自意大利和德国的参与者：
- en: '`In``[``27``]:``df``.``loc``[``df``[``"country"``]``.``isin``([``"Italy"``,``"Germany"``]),``:]`'
  id: totrans-148
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``27``]:``df``.``loc``[``df``[``"country"``]``.``isin``([``"Italy"``,``"Germany"``]),``:]`'
- en: '`Out[27]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1003       
    Jenny   12  Germany    9.0    Europe`'
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[27]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1003       
    Jenny   12  Germany    9.0    Europe`'
- en: 'While you use `loc` to provide a boolean Series, DataFrames offer a special
    syntax without `loc` to select values given the full DataFrame of booleans:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用`loc`来提供一个布尔Series时，数据框提供了一个特殊的语法，无需`loc`即可选择给定完整布尔DataFrame的值：
- en: '`df``[``boolean_df``]`'
  id: totrans-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df``[``boolean_df``]`'
- en: 'This is especially helpful if you have DataFrames that consist of only numbers.
    Providing a DataFrame of booleans returns the DataFrame with `NaN` wherever the
    boolean DataFrame is `False`. Again, a more detailed discussion of `NaN` will
    follow shortly. Let’s start by creating a new sample DataFrame called `rainfall`
    that consists of only numbers:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据框（DataFrame）仅包含数字，这将特别有帮助。提供一个布尔DataFrame将在布尔DataFrame为`False`时在数据框中返回`NaN`。稍后将更详细地讨论`NaN`。让我们从创建一个名为`rainfall`的新样本数据框开始，其中只包含数字：
- en: '`In``[``28``]:``# This could be the yearly rainfall in millimeters``rainfall``=``pd``.``DataFrame``(``data``=``{``"City
    1"``:``[``300.1``,``100.2``],``"City 2"``:``[``400.3``,``300.4``],``"City 3"``:``[``1000.5``,``1100.6``]})``rainfall`'
  id: totrans-153
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``28``]:``# 这可能是以毫米为单位的年降雨量``rainfall``=``pd``.``DataFrame``(``data``=``{``"City
    1"``:``[``300.1``,``100.2``],``"City 2"``:``[``400.3``,``300.4``],``"City 3"``:``[``1000.5``,``1100.6``]})``rainfall`'
- en: '`Out[28]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
  id: totrans-154
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[28]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
- en: '`In``[``29``]:``rainfall``<``400`'
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``29``]:``rainfall``<``400`'
- en: '`Out[29]:    City 1  City 2  City 3          0    True   False   False         
    1    True    True   False`'
  id: totrans-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[29]:    City 1  City 2  City 3          0    True   False   False         
    1    True    True   False`'
- en: '`In``[``30``]:``rainfall``[``rainfall``<``400``]`'
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``30``]:``rainfall``[``rainfall``<``400``]`'
- en: '`Out[30]:    City 1  City 2  City 3          0   300.1     NaN     NaN         
    1   100.2   300.4     NaN`'
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[30]:    City 1  City 2  City 3          0   300.1     NaN     NaN         
    1   100.2   300.4     NaN`'
- en: Note that in this example, I have used a dictionary to construct a new DataFrame—this
    is often convenient if the data already exists in that form. Working with booleans
    in this way is most commonly used to filter out specific values such as outliers.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这个例子中，我使用了字典来构建一个新的DataFrame——如果数据已经以这种形式存在，这通常很方便。以这种方式使用布尔值通常用于过滤特定值，如异常值。
- en: To wrap up the data selection part, I will introduce a special type of index
    called the MultiIndex.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 结束数据选择部分之前，我将介绍一种特殊类型的索引称为MultiIndex。
- en: Selecting by using a MultiIndex
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 使用MultiIndex进行选择
- en: 'A MultiIndex is an index with more than one level. It allows you to hierarchically
    group your data and gives you easy access to subsets. For example, if you set
    the index of our sample DataFrame `df` to a combination of `continent` and `country`,
    you can easily select all rows with a certain continent:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**MultiIndex**是一个具有多个层级的索引。它允许你按层次分组数据，并轻松访问子集。例如，如果将我们示例DataFrame `df` 的索引设置为
    `continent` 和 `country` 的组合，你可以轻松选择特定大陆的所有行：
- en: '`In``[``31``]:``# A MultiIndex needs to be sorted``df_multi``=``df``.``reset_index``()``.``set_index``([``"continent"``,``"country"``])``df_multi``=``df_multi``.``sort_index``()``df_multi`'
  id: totrans-163
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In[31]:` # MultiIndex 需要排序`df_multi`=`df`.`reset_index`()`.`set_index`([``"continent"``,``"country"``])`df_multi`=`df_multi`.`sort_index`()``df_multi`'
- en: '`Out[31]: properties         user_id   name  age  score          continent
    country          America   USA         1000   John   33    6.7                   
    USA         1002    Tim   41    3.9          Europe    Germany     1003  Jenny  
    12    9.0                    Italy       1001   Mark   55    4.5`'
  id: totrans-164
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[31]: properties         user_id   name  age  score          continent
    country          America   USA         1000   John   33    6.7                   
    USA         1002    Tim   41    3.9          Europe    Germany     1003  Jenny  
    12    9.0                    Italy       1001   Mark   55    4.5`'
- en: '`In``[``32``]:``df_multi``.``loc``[``"Europe"``,``:]`'
  id: totrans-165
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In[32]:` `df_multi``.``loc``[``"Europe"``,``:]`'
- en: '`Out[32]: properties  user_id   name  age  score          country         
    Germany        1003  Jenny   12    9.0          Italy          1001   Mark   55   
    4.5`'
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[32]: properties  user_id   name  age  score          country         
    Germany        1003  Jenny   12    9.0          Italy          1001   Mark   55   
    4.5`'
- en: 'Note that pandas prettifies the output of a MultiIndex by not repeating the
    leftmost index level (the continents) for each row. Instead, it only prints the
    continent when it changes. Selecting over multiple index levels is done by providing
    a tuple:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，pandas通过不重复左侧索引级别（大陆）来美化MultiIndex的输出。而是在每行更改时仅打印大陆。通过提供元组来选择多个索引级别：
- en: '`In``[``33``]:``df_multi``.``loc``[(``"Europe"``,``"Italy"``),``:]`'
  id: totrans-168
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In[33]:` `df_multi`.`loc``[(``"Europe"``,``"Italy"``),``:]`'
- en: '`Out[33]: properties         user_id  name  age  score          continent country
             Europe    Italy       1001  Mark   55    4.5`'
  id: totrans-169
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[33]: properties         user_id  name  age  score          continent country
             Europe    Italy       1001  Mark   55    4.5`'
- en: 'If you want to selectively reset part of a MultiIndex, provide the level as
    an argument. Zero is the first column from the left:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要选择性地重置MultiIndex的部分，请提供级别作为参数。从左侧开始，零是第一列：
- en: '`In``[``34``]:``df_multi``.``reset_index``(``level``=``0``)`'
  id: totrans-171
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In[34]:` `df_multi`.`reset_index`(``level``=``0``)`'
- en: '`Out[34]: properties continent  user_id   name  age  score          country
             USA          America     1000   John   33    6.7          USA         
    America     1002    Tim   41    3.9          Germany       Europe     1003  Jenny  
    12    9.0          Italy         Europe     1001   Mark   55    4.5`'
  id: totrans-172
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[34]: properties continent  user_id   name  age  score          country
             USA          America     1000   John   33    6.7          USA         
    America     1002    Tim   41    3.9          Germany       Europe     1003  Jenny  
    12    9.0          Italy         Europe     1001   Mark   55    4.5`'
- en: While we won’t manually create a MultiIndex in this book, there are certain
    operations like `groupby`, which will cause pandas to return a DataFrame with
    a MultiIndex, so it’s good to know what it is. We will meet `groupby` later in
    this chapter.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们在本书中不会手动创建MultiIndex，但像`groupby`这样的某些操作将导致pandas返回带有MultiIndex的DataFrame，因此了解它是很好的。我们将在本章后面介绍`groupby`。
- en: Now that you know various ways to select data, it’s time to learn how you change
    data.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道了各种选择数据的方法，现在是时候学习如何更改数据了。
- en: Setting Data
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 数据设置
- en: 'The easiest way to change the data of a DataFrame is by assigning values to
    certain elements using the `loc` or `iloc` attributes. This is the starting point
    of this section before we turn to other ways of manipulating existing DataFrames:
    replacing values and adding new columns.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 更改DataFrame数据的最简单方法是使用`loc`或`iloc`属性为特定元素分配值。这是本节的起点，在转向操作现有DataFrame的其他方法之前：替换值和添加新列。
- en: Setting data by label or position
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 通过标签或位置设置数据
- en: 'As pointed out earlier in this chapter, when you call DataFrame methods like
    `df.reset_index()`, the method will always be applied to a copy, leaving the original
    DataFrame untouched. However, assigning values via the `loc` and `iloc` attributes
    changes the original DataFrame. Since I want to leave our DataFrame `df` untouched,
    I am working with a copy here that I am calling `df2`. If you want to change a
    single value, do the following:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本章前面所指出的，当你调用`df.reset_index()`等数据框方法时，该方法总是应用于一个副本，保持原始数据框不变。然而，通过`loc`和`iloc`属性赋值会改变原始数据框。由于我想保持我们的数据框`df`不变，因此在这里我使用了一个称为`df2`的副本。如果你想改变单个值，请按照以下步骤操作：
- en: '`In``[``35``]:``# Copy the DataFrame first to leave the original untouched``df2``=``df``.``copy``()`'
  id: totrans-179
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``35``]:``# 先复制数据框以保留原始数据不变``df2``=``df``.``copy``()`'
- en: '`In``[``36``]:``df2``.``loc``[``1000``,``"name"``]``=``"JOHN"``df2`'
  id: totrans-180
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``36``]:``df2``.``loc``[``1000``,``"name"``]``=``"JOHN"``df2`'
- en: '`Out[36]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1000        
    JOHN   33      USA    6.7   America          1002          Tim   41      USA   
    3.9   America          1003        Jenny   12  Germany    9.0    Europe`'
  id: totrans-181
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[36]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1000        
    JOHN   33      USA    6.7   America          1002          Tim   41      USA   
    3.9   America          1003        Jenny   12  Germany    9.0    Europe`'
- en: 'You can also change multiple values at the same time. One way to change the
    score of the users with ID 1000 and 1001 is to use a list:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以同时更改多个值。改变ID为1000和1001的用户的分数的一种方法是使用列表：
- en: '`In``[``37``]:``df2``.``loc``[[``1000``,``1001``],``"score"``]``=``[``3``,``4``]``df2`'
  id: totrans-183
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``37``]:``df2``.``loc``[[``1000``,``1001``],``"score"``]``=``[``3``,``4``]``df2`'
- en: '`Out[37]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.0    Europe          1000        
    JOHN   33      USA    3.0   America          1002          Tim   41      USA   
    3.9   America          1003        Jenny   12  Germany    9.0    Europe`'
  id: totrans-184
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[37]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.0    Europe          1000        
    JOHN   33      USA    3.0   America          1002          Tim   41      USA   
    3.9   America          1003        Jenny   12  Germany    9.0    Europe`'
- en: Changing data by position via `iloc` works the same way. Let’s now move on to
    see how you change the data by using boolean indexing.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 通过位置使用`iloc`来改变数据的方式与此相同。现在我们继续看看如何通过布尔索引来改变数据。
- en: Setting data by boolean indexing
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 通过布尔索引设置数据
- en: 'Boolean indexing, which we used to filter rows, can also be used to assign
    values in a DataFrame. Imagine that you need to anonymize all names of people
    who are below 20 years old or from the USA:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 布尔索引，我们用来过滤行的方式，也可以用来在数据框中赋值。想象一下，你需要匿名化所有年龄低于20岁或来自美国的人的姓名：
- en: '`In``[``38``]:``tf``=``(``df2``[``"age"``]``<``20``)``|``(``df2``[``"country"``]``==``"USA"``)``df2``.``loc``[``tf``,``"name"``]``=``"xxx"``df2`'
  id: totrans-188
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``38``]:``tf``=``(``df2``[``"age"``]``<``20``)``|``(``df2``[``"country"``]``==``"USA"``)``df2``.``loc``[``tf``,``"name"``]``=``"xxx"``df2`'
- en: '`Out[38]: properties  name  age  country  score continent          user_id
             1001        Mark   55    Italy    4.0    Europe          1000        
    xxx   33      USA    3.0   America          1002         xxx   41      USA   
    3.9   America          1003         xxx   12  Germany    9.0    Europe`'
  id: totrans-189
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[38]: properties  name  age  country  score continent          user_id
             1001        Mark   55    Italy    4.0    Europe          1000        
    xxx   33      USA    3.0   America          1002         xxx   41      USA   
    3.9   America          1003         xxx   12  Germany    9.0    Europe`'
- en: 'Sometimes, you have a dataset where you need to replace certain values across
    the board, i.e., not specific to certain columns. In that case, make use of the
    special syntax again and provide the whole DataFrame with booleans like this (the
    sample makes use again of the `rainfall` DataFrame):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，你有一个数据集，需要跨整个数据框替换某些值，即不特定于某些列。在这种情况下，再次使用特殊语法，并像这样提供整个数据框与布尔值（此示例再次使用`rainfall`数据框）。
- en: '`In``[``39``]:``# Copy the DataFrame first to leave the original untouched``rainfall2``=``rainfall``.``copy``()``rainfall2`'
  id: totrans-191
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``39``]:``# 先复制数据框以保留原始数据不变``rainfall2``=``rainfall``.``copy``()``rainfall2`'
- en: '`Out[39]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
  id: totrans-192
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[39]:    城市 1  城市 2  城市 3          0   300.1   400.3  1000.5          1  
    100.2   300.4  1100.6`'
- en: '`In``[``40``]:``# Set the values to 0 wherever they are below 400``rainfall2``[``rainfall2``<``400``]``=``0``rainfall2`'
  id: totrans-193
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``40``]:``# 将低于400的值设为0``rainfall2``[``rainfall2``<``400``]``=``0``rainfall2`'
- en: '`Out[40]:    City 1  City 2  City 3          0     0.0   400.3  1000.5         
    1     0.0     0.0  1100.6`'
  id: totrans-194
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[40]:    City 1  City 2  City 3          0     0.0   400.3  1000.5         
    1     0.0     0.0  1100.6`'
- en: If you just want to replace a value with another one, there is an easier way
    to do it, as I will show you next.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果只想用另一个值替换一个值，有一种更简单的方法，我将在下面展示给你。
- en: Setting data by replacing values
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 通过替换值设置数据
- en: 'If you want to replace a certain value across your entire DataFrame or selected
    columns, use the `replace` method:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要在整个DataFrame或选定列中替换某个值，请使用`replace`方法：
- en: '`In``[``41``]:``df2``.``replace``(``"USA"``,``"U.S."``)`'
  id: totrans-198
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``41``]:``df2``.``replace``(``"USA"``,``"U.S."``)`'
- en: '`Out[41]: properties  name  age  country  score continent          user_id
             1001        Mark   55    Italy    4.0    Europe          1000        
    xxx   33     U.S.    3.0   America          1002         xxx   41     U.S.   
    3.9   America          1003         xxx   12  Germany    9.0    Europe`'
  id: totrans-199
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[41]: properties  name  age  country  score continent          user_id
             1001        Mark   55    Italy    4.0    Europe          1000        
    xxx   33     U.S.    3.0   America          1002         xxx   41     U.S.   
    3.9   America          1003         xxx   12  Germany    9.0    Europe`'
- en: 'If, instead, you only wanted to act on the `country` column, you could use
    this syntax instead:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只想在`country`列上执行操作，您可以改用以下语法：
- en: '`df2``.``replace``({``"country"``:``{``"USA"``:``"U.S."``}})`'
  id: totrans-201
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df2``.``replace``({``"country"``:``{``"USA"``:``"U.S."``}})`'
- en: In this case, since `USA` only turns up in the `country` column, it yields the
    same result as the previous sample. To wrap this section up, let’s see how you
    can add additional columns to a DataFrame.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，由于`USA`只出现在`country`列中，它产生了与前一个示例相同的结果。让我们看看如何向DataFrame添加额外列，以结束这一节。
- en: Setting data by adding a new column
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 通过添加新列设置数据
- en: 'To add a new column to a DataFrame, assign values to a new column name. For
    example, you could add a new column to a DataFrame by using a scalar or list:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 要向DataFrame添加新列，请为新列名称分配值。例如，您可以使用标量或列表向DataFrame添加新列：
- en: '`In``[``42``]:``df2``.``loc``[:,``"discount"``]``=``0``df2``.``loc``[:,``"price"``]``=``[``49.9``,``49.9``,``99.9``,``99.9``]``df2`'
  id: totrans-205
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``42``]:``df2``.``loc``[:,``"discount"``]``=``0``df2``.``loc``[:,``"price"``]``=``[``49.9``,``49.9``,``99.9``,``99.9``]``df2`'
- en: '`Out[42]: properties  name  age  country  score continent  discount  price
             user_id          1001        Mark   55    Italy    4.0    Europe        
    0   49.9          1000         xxx   33      USA    3.0   America         0  
    49.9          1002         xxx   41      USA    3.9   America         0   99.9
             1003         xxx   12  Germany    9.0    Europe         0   99.9`'
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[42]: properties  name  age  country  score continent  discount  price
             user_id          1001        Mark   55    Italy    4.0    Europe        
    0   49.9          1000         xxx   33      USA    3.0   America         0  
    49.9          1002         xxx   41      USA    3.9   America         0   99.9
             1003         xxx   12  Germany    9.0    Europe         0   99.9`'
- en: 'Adding a new column often involves vectorized calculations:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 添加新列通常涉及矢量化计算：
- en: '`In``[``43``]:``df2``=``df``.``copy``()``# Let''s start with a fresh copy``df2``.``loc``[:,``"birth
    year"``]``=``2021``-``df2``[``"age"``]``df2`'
  id: totrans-208
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``43``]:``df2``=``df``.``copy``()``# 让我们从头开始复制``df2``。``df2``.``loc``[:,``"birth
    year"``]``=``2021``-``df2``[``"age"``]``df2`'
- en: '`Out[43]: properties   name  age  country  score continent  birth year         
    user_id          1001         Mark   55    Italy    4.5    Europe        1966
             1000         John   33      USA    6.7   America        1988         
    1002          Tim   41      USA    3.9   America        1980          1003       
    Jenny   12  Germany    9.0    Europe        2009`'
  id: totrans-209
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[43]: properties   name  age  country  score continent  birth year         
    user_id          1001         Mark   55    Italy    4.5    Europe        1966
             1000         John   33      USA    6.7   America        1988         
    1002          Tim   41      USA    3.9   America        1980          1003       
    Jenny   12  Germany    9.0    Europe        2009`'
- en: I will show you more about calculating with DataFrames in a moment, but before
    we get there, do you remember that I have used `NaN` a few times already? The
    next section will finally give you more context around the topic of missing data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我稍后会向你展示更多关于DataFrame计算的内容，但在我们到达那之前，请记住我已经多次使用了`NaN`吗？下一节将为您提供有关缺失数据主题的更多背景。
- en: Missing Data
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据
- en: 'Missing data can be a problem as it has the potential to bias the results of
    your data analysis, thereby making your conclusions less robust. Nevertheless,
    it’s very common to have gaps in your datasets that you will have to deal with.
    In Excel, you usually have to deal with empty cells or `#N/A` errors, but pandas
    uses NumPy’s `np.nan` for missing data, displayed as `NaN`. `NaN` is the floating-point
    standard for Not-a-Number. For timestamps, `pd.NaT` is used instead, and for text,
    pandas uses `None`. Using `None` or `np.nan`, you can introduce missing values:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据可能会影响数据分析结果的偏差，从而使你的结论不够健壮。然而，在数据集中有空白是非常常见的，你需要处理它们。在 Excel 中，通常需要处理空单元格或
    `#N/A` 错误，但是 pandas 使用 NumPy 的 `np.nan` 表示缺失数据，显示为 `NaN`。`NaN` 是浮点数的标准表示为“非数字”。对于时间戳，使用
    `pd.NaT`，对于文本，pandas 使用 `None`。使用 `None` 或 `np.nan`，你可以引入缺失值：
- en: '`In``[``44``]:``df2``=``df``.``copy``()``# Let''s start with a fresh copy``df2``.``loc``[``1000``,``"score"``]``=``None``df2``.``loc``[``1003``,``:]``=``None``df2`'
  id: totrans-213
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``44``]:``df2``=``df``.``copy``()``# 让我们从一个新的副本开始``df2``.``loc``[``1000``,``"score"``]``=``None``df2``.``loc``[``1003``,``:]``=``None``df2`'
- en: '`Out[44]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1000       
    John  33.0     USA    NaN   America          1002         Tim  41.0     USA   
    3.9   America          1003        None   NaN    None    NaN      None`'
  id: totrans-214
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[44]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1000       
    John  33.0     USA    NaN   America          1002         Tim  41.0     USA   
    3.9   America          1003        None   NaN    None    NaN      None`'
- en: 'To clean a DataFrame, you often want to remove rows with missing data. This
    is as simple as:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 清理 DataFrame，通常需要删除具有缺失数据的行。这很简单：
- en: '`In``[``45``]:``df2``.``dropna``()`'
  id: totrans-216
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``45``]:``df2``.``dropna``()`'
- en: '`Out[45]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1002        
    Tim  41.0     USA    3.9   America`'
  id: totrans-217
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[45]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1002        
    Tim  41.0     USA    3.9   America`'
- en: 'If, however, you only want to remove rows where all values are missing, use
    the `how` parameter:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你只想删除所有值都缺失的行，请使用 `how` 参数：
- en: '`In``[``46``]:``df2``.``dropna``(``how``=``"all"``)`'
  id: totrans-219
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``46``]:``df2``.``dropna``(``how``=``"all"``)`'
- en: '`Out[46]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1000       
    John  33.0     USA    NaN   America          1002         Tim  41.0     USA   
    3.9   America`'
  id: totrans-220
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[46]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1000       
    John  33.0     USA    NaN   America          1002         Tim  41.0     USA   
    3.9   America`'
- en: 'To get a boolean DataFrame or Series depending on whether there is `NaN` or
    not, use `isna`:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得一个布尔 DataFrame 或 Series，根据是否存在 `NaN`，使用 `isna`：
- en: '`In``[``47``]:``df2``.``isna``()`'
  id: totrans-222
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``47``]:``df2``.``isna``()`'
- en: '`Out[47]: properties   name    age  country  score  continent          user_id
             1001        False  False    False  False      False          1000       
    False  False    False   True      False          1002        False  False    False 
    False      False          1003         True   True     True   True       True`'
  id: totrans-223
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[47]: properties   name    age  country  score  continent          user_id
             1001        False  False    False  False      False          1000       
    False  False    False   True      False          1002        False  False    False 
    False      False          1003         True   True     True   True       True`'
- en: 'To fill missing values, use `fillna`. For example, to replace `NaN` in the
    score column with its mean (I will introduce descriptive statistics like `mean`
    shortly):'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 要填充缺失值，使用 `fillna`。例如，将分数列中的 `NaN` 替换为其平均值（稍后我将介绍描述统计信息如 `mean`）：
- en: '`In``[``48``]:``df2``.``fillna``({``"score"``:``df2``[``"score"``]``.``mean``()})`'
  id: totrans-225
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``48``]:``df2``.``fillna``({``"score"``:``df2``[``"score"``]``.``mean``()})`'
- en: '`Out[48]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1000       
    John  33.0     USA    4.2   America          1002         Tim  41.0     USA   
    3.9   America          1003        None   NaN    None    4.2      None`'
  id: totrans-226
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[48]: properties  name   age country  score continent          user_id
             1001        Mark  55.0   Italy    4.5    Europe          1000       
    John  33.0     USA    4.2   America          1002         Tim  41.0     USA   
    3.9   America          1003        None   NaN    None    4.2      None`'
- en: Missing data isn’t the only condition that requires us to clean our dataset.
    The same is true for duplicate data, so let’s see what our options are!
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据不是唯一需要清理数据集的条件。对于重复数据也是如此，所以让我们看看我们的选择！
- en: Duplicate Data
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 重复数据
- en: 'Like missing data, duplicates negatively impact the reliability of your analysis.
    To get rid of duplicate rows, use the `drop_duplicates` method. Optionally, you
    can provide a subset of the columns as argument:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '像缺失数据一样，重复项会对分析的可靠性产生负面影响。要删除重复行，请使用`drop_duplicates`方法。您可以选择提供一列子集作为参数：  '
- en: '`In``[``49``]:``df``.``drop_duplicates``([``"country"``,``"continent"``])`'
  id: totrans-230
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``49``]:``df``.``drop_duplicates``([``"country"``,``"continent"``])`  '
- en: '`Out[49]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1000        
    John   33      USA    6.7   America          1003        Jenny   12  Germany   
    9.0    Europe`'
  id: totrans-231
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[49]: properties   name  age  country  score continent          user_id
             1001         Mark   55    Italy    4.5    Europe          1000        
    John   33      USA    6.7   America          1003        Jenny   12  Germany   
    9.0    Europe`  '
- en: 'By default, this will leave the first occurrence. To find out if a certain
    column contains duplicates or to get its unique values, use the following two
    commands (use `df.index` instead of `df["country"]` if you wanted to run this
    on the index instead):'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '默认情况下，这将保留第一次出现。要查找某列是否包含重复项或获取其唯一值，请使用以下两个命令（如果您希望在索引上运行此操作，请使用`df.index`而不是`df["country"]`）：  '
- en: '`In``[``50``]:``df``[``"country"``]``.``is_unique`'
  id: totrans-233
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``50``]:``df``[``"country"``]``.``is_unique`  '
- en: '`Out[50]: False`'
  id: totrans-234
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[50]: False`  '
- en: '`In``[``51``]:``df``[``"country"``]``.``unique``()`'
  id: totrans-235
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``51``]:``df``[``"country"``]``.``unique``()  '
- en: '`Out[51]: array([''Italy'', ''USA'', ''Germany''], dtype=object)`'
  id: totrans-236
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[51]: array([''Italy'', ''USA'', ''Germany''], dtype=object)`  '
- en: 'And finally, to understand which rows are duplicates, use the `duplicated`
    method, which returns a boolean Series: by default, it uses the parameter `keep="first"`,
    which keeps the first occurrence and marks only duplicates with `True`. By setting
    the parameter `keep=False`, it will return `True` for all rows, including its
    first occurrence, making it easy to get a DataFrame with all duplicate rows. In
    the following example, we look at the `country` column for duplicates, but in
    reality, you often look at the index or entire rows. In this case, you’d have
    to use `df.index.duplicated()` or `df.duplicated()` instead:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '最后，要了解哪些行是重复的，请使用`duplicated`方法，它返回一个布尔值系列：默认情况下，它使用参数`keep="first"`，保留第一次出现并仅标记重复为`True`。通过设置参数`keep=False`，它将对所有行返回`True`，包括第一次出现，从而轻松获取包含所有重复行的DataFrame。在以下示例中，我们查看`country`列是否有重复，但实际上，您经常查看索引或整个行。在这种情况下，您必须使用`df.index.duplicated()`或`df.duplicated()`代替：  '
- en: '`In``[``52``]:``# By default, it marks only duplicates as True, i.e.``# without
    the first occurrence``df``[``"country"``]``.``duplicated``()`'
  id: totrans-238
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``52``]:``# 默认情况下，它仅标记重复项为True，即没有第一次出现``df``[``"country"``]``.``duplicated``()`  '
- en: '`Out[52]: user_id          1001    False          1000    False          1002    
    True          1003    False          Name: country, dtype: bool`'
  id: totrans-239
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[52]: user_id          1001    False          1000    False          1002    
    True          1003    False          Name: country, dtype: bool`  '
- en: '`In``[``53``]:``# To get all rows where "country" is duplicated, use``# keep=False``df``.``loc``[``df``[``"country"``]``.``duplicated``(``keep``=``False``),``:]`'
  id: totrans-240
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``53``]:``# 要获取所有重复“country”的行，请使用``keep=False``df``.``loc``[``df``[``"country"``]``.``duplicated``(``keep``=``False``),``:]`  '
- en: '`Out[53]: properties  name  age country  score continent          user_id         
    1000        John   33     USA    6.7   America          1002         Tim   41    
    USA    3.9   America`'
  id: totrans-241
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[53]: properties  name  age country  score continent          user_id         
    1000        John   33     USA    6.7   America          1002         Tim   41    
    USA    3.9   America`  '
- en: Once you have cleaned your DataFrames by removing missing and duplicate data,
    you might want to perform some arithmetic operations—the next section gives you
    an introduction to how this works.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '一旦您通过删除缺失和重复数据清理了您的DataFrame，您可能希望执行一些算术运算-下一节将为您介绍如何执行这些操作。  '
- en: Arithmetic Operations
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '算术运算  '
- en: 'Like NumPy arrays, DataFrames and Series make use of vectorization. For example,
    to add a number to every value in the `rainfall` DataFrame, simply do the following:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '像NumPy数组一样，DataFrame和Series利用向量化。例如，要将数字添加到`rainfall` DataFrame中的每个值，只需执行以下操作：  '
- en: '`In``[``54``]:``rainfall`'
  id: totrans-245
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``54``]:``rainfall`  '
- en: '`Out[54]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
  id: totrans-246
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[54]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`  '
- en: '`In``[``55``]:``rainfall``+``100`'
  id: totrans-247
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``55``]:``rainfall``+``100`  '
- en: '`Out[55]:    City 1  City 2  City 3          0   400.1   500.3  1100.5         
    1   200.2   400.4  1200.6`'
  id: totrans-248
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[55]:    City 1  City 2  City 3          0   400.1   500.3  1100.5         
    1   200.2   400.4  1200.6`'
- en: 'However, the true power of pandas is its automatic data alignment mechanism:
    when you use arithmetic operators with more than one DataFrame, pandas automatically
    aligns them by their columns and row indices. Let’s create a second DataFrame
    with some of the same row and column labels. We then build the sum:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，pandas 的真正力量在于其自动数据对齐机制：当你使用多个 DataFrame 进行算术运算时，pandas 会自动根据它们的列和行索引进行对齐。让我们创建第二个具有一些相同行和列标签的
    DataFrame，然后进行求和操作：
- en: '`In``[``56``]:``more_rainfall``=``pd``.``DataFrame``(``data``=``[[``100``,``200``],``[``300``,``400``]],``index``=``[``1``,``2``],``columns``=``[``"City
    1"``,``"City 4"``])``more_rainfall`'
  id: totrans-250
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``56``]:``more_rainfall``=``pd``.``DataFrame``(``data``=``[[``100``,``200``],``[``300``,``400``]],``index``=``[``1``,``2``],``columns``=``[``"City
    1"``,``"City 4"``])``more_rainfall`'
- en: '`Out[56]:    City 1  City 4          1     100     200          2     300    
    400`'
  id: totrans-251
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[56]:    City 1  City 4          1     100     200          2     300    
    400`'
- en: '`In``[``57``]:``rainfall``+``more_rainfall`'
  id: totrans-252
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``57``]:``rainfall``+``more_rainfall`'
- en: '`Out[57]:    City 1  City 2  City 3  City 4          0     NaN     NaN    
    NaN     NaN          1   200.2     NaN     NaN     NaN          2     NaN    
    NaN     NaN     NaN`'
  id: totrans-253
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[57]:    City 1  City 2  City 3  City 4          0     NaN     NaN    
    NaN     NaN          1   200.2     NaN     NaN     NaN          2     NaN    
    NaN     NaN     NaN`'
- en: 'The index and columns of the resulting DataFrame are the union of the indices
    and columns of the two DataFrames: the fields that have a value in both DataFrames
    show the sum, while the rest of the DataFrame shows `NaN`. This may be something
    you have to get used to if you come from Excel, where empty cells are automatically
    turned into zeros when you use them in arithmetic operations. To get the same
    behavior as in Excel, use the `add` method with a `fill_value` to replace `NaN`
    values with zeros:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 结果 DataFrame 的索引和列是两个 DataFrame 索引和列的并集：那些两个 DataFrame 中都有值的字段显示其和，而其余的 DataFrame
    显示 `NaN`。如果你来自 Excel，这可能是你需要适应的地方，因为在 Excel 中，当你在算术运算中使用空单元格时，它们会自动转换为零。要获得与 Excel
    中相同的行为，请使用 `add` 方法并使用 `fill_value` 替换 `NaN` 值为零：
- en: '`In``[``58``]:``rainfall``.``add``(``more_rainfall``,``fill_value``=``0``)`'
  id: totrans-255
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``58``]:``rainfall``.``add``(``more_rainfall``,``fill_value``=``0``)`'
- en: '`Out[58]:    City 1  City 2  City 3  City 4          0   300.1   400.3  1000.5    
    NaN          1   200.2   300.4  1100.6   200.0          2   300.0     NaN    
    NaN   400.0`'
  id: totrans-256
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[58]:    City 1  City 2  City 3  City 4          0   300.1   400.3  1000.5    
    NaN          1   200.2   300.4  1100.6   200.0          2   300.0     NaN    
    NaN   400.0`'
- en: This works accordingly for the other arithmetic operators as shown in [Table 5-4](#filepos625873).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于其他算术运算符也适用，如表 [Table 5-4](https://example.org/filepos625873) 所示。
- en: Table 5-4\. Arithmetic operators
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Table 5-4\. 算术运算符
- en: '|  Operator  |  Method  |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '|  Operator  |  Method  |'
- en: '|   `*` |   `mul` |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '|   `*` |   `mul` |'
- en: '|   `+` |   `add` |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '|   `+` |   `add` |'
- en: '|   `-` |   `sub` |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '|   `-` |   `sub` |'
- en: '|   `/` |   `div` |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '|   `/` |   `div` |'
- en: '|   `**` |   `pow` |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '|   `**` |   `pow` |'
- en: 'When you have a DataFrame and a Series in your calculation, by default the
    Series is broadcast along the index:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在计算中有一个 DataFrame 和一个 Series 时，默认情况下 Series 会沿着索引进行广播：
- en: '`In``[``59``]:``# A Series taken from a row``rainfall``.``loc``[``1``,``:]`'
  id: totrans-266
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``59``]:``# 从一行中提取的 Series``rainfall``.``loc``[``1``,``:]`'
- en: '`Out[59]: City 1     100.2          City 2     300.4          City 3    1100.6
             Name: 1, dtype: float64`'
  id: totrans-267
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[59]: City 1     100.2          City 2     300.4          City 3    1100.6
             Name: 1, dtype: float64`'
- en: '`In``[``60``]:``rainfall``+``rainfall``.``loc``[``1``,``:]`'
  id: totrans-268
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``60``]:``rainfall``+``rainfall``.``loc``[``1``,``:]`'
- en: '`Out[60]:    City 1  City 2  City 3          0   400.3   700.7  2101.1         
    1   200.4   600.8  2201.2`'
  id: totrans-269
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[60]:    City 1  City 2  City 3          0   400.3   700.7  2101.1         
    1   200.4   600.8  2201.2`'
- en: 'Hence, to add a Series column-wise, you need to use the `add` method with an
    explicit `axis` argument:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，要按列添加一个 Series，你需要使用 `add` 方法并显式指定 `axis` 参数：
- en: '`In``[``61``]:``# A Series taken from a column``rainfall``.``loc``[:,``"City
    2"``]`'
  id: totrans-271
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``61``]:``# 从一列中提取的 Series``rainfall``.``loc``[:,``"City 2"``]`'
- en: '`Out[61]: 0    400.3          1    300.4          Name: City 2, dtype: float64`'
  id: totrans-272
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[61]: 0    400.3          1    300.4          Name: City 2, dtype: float64`'
- en: '`In``[``62``]:``rainfall``.``add``(``rainfall``.``loc``[:,``"City 2"``],``axis``=``0``)`'
  id: totrans-273
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``62``]:``rainfall``.``add``(``rainfall``.``loc``[:,``"City 2"``],``axis``=``0``)`'
- en: '`Out[62]:    City 1  City 2  City 3          0   700.4   800.6  1400.8         
    1   400.6   600.8  1401.0`'
  id: totrans-274
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[62]:    City 1  City 2  City 3          0   700.4   800.6  1400.8         
    1   400.6   600.8  1401.0`'
- en: While this section is about DataFrames with numbers and how they behave in arithmetic
    operations, the next section shows your options when it comes to manipulating
    text in DataFrames.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本节讨论的是带有数字的 DataFrame 在算术运算中的行为，但下一节将展示你在处理 DataFrame 中文本时的选项。
- en: Working with Text Columns
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 处理文本列
- en: 'As we have seen at the beginning of this chapter, columns with text or mixed
    data types have the data type `object`. To perform operations on columns with
    text strings, use the `str` attribute that gives you access to Python’s string
    methods. We have already met a few string methods in [Chapter 3](index_split_010.html#filepos178328),
    but it won’t hurt to have a look at the available methods in the [Python docs](https://oreil.ly/-e7SC).
    For example, to remove leading and trailing white space, use the `strip` method;
    to make all first letters capitalized, there is the `capitalize` method. Chaining
    these together will clean up messy text columns that are often the result of manual
    data entry:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章开头所见，包含文本或混合数据类型的列具有数据类型`object`。要对包含文本字符串的列执行操作，请使用`str`属性，该属性使您可以访问Python的字符串方法。我们在[第3章](index_split_010.html#filepos178328)中已经了解了一些字符串方法，但查看一下[Python文档](https://oreil.ly/-e7SC)中提供的方法也无妨。例如，要去除前导和尾随空格，请使用`strip`方法；要将所有首字母大写，可以使用`capitalize`方法。将这些方法链在一起将清理手动输入数据产生的混乱文本列：
- en: '`In``[``63``]:``# Let''s create a new DataFrame``users``=``pd``.``DataFrame``(``data``=``[``"
    mArk "``,``"JOHN  "``,``"Tim"``,``" jenny"``],``columns``=``[``"name"``])``users`'
  id: totrans-278
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``63``]:``# 让我们创建一个新的DataFrame``users``=``pd``.``DataFrame``(``data``=``[``"
    mArk "``,``"JOHN  "``,``"Tim"``,``" jenny"``],``columns``=``[``"name"``])``users`'
- en: '`Out[63]:      name          0   mArk          1  JOHN          2     Tim         
    3   jenny`'
  id: totrans-279
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[63]:      name          0   mArk          1  JOHN          2     Tim         
    3   jenny`'
- en: '`In``[``64``]:``users_cleaned``=``users``.``loc``[:,``"name"``]``.``str``.``strip``()``.``str``.``capitalize``()``users_cleaned`'
  id: totrans-280
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``64``]:``users_cleaned``=``users``.``loc``[:,``"name"``]``.``str``.``strip``()``.``str``.``capitalize``()``users_cleaned`'
- en: '`Out[64]: 0     Mark          1     John          2      Tim          3   
    Jenny          Name: name, dtype: object`'
  id: totrans-281
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[64]: 0     Mark          1     John          2      Tim          3   
    Jenny          Name: name, dtype: object`'
- en: 'Or, to find all names that start with a “J”:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，要查找所有以“J”开头的名称：
- en: '`In``[``65``]:``users_cleaned``.``str``.``startswith``(``"J"``)`'
  id: totrans-283
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``65``]:``users_cleaned``.``str``.``startswith``(``"J"``)`'
- en: '`Out[65]: 0    False          1     True          2    False          3    
    True          Name: name, dtype: bool`'
  id: totrans-284
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[65]: 0    False          1     True          2    False          3    
    True          Name: name, dtype: bool`'
- en: The string methods are easy to use, but sometimes you may need to manipulate
    a DataFrame in a way that isn’t built-in. In that case, create your own function
    and apply it to your DataFrame, as the next section shows.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串方法很容易使用，但有时您可能需要以不内置的方式操作DataFrame。在这种情况下，创建自己的函数并将其应用于DataFrame，如下一节所示。
- en: Applying a Function
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 应用函数
- en: 'DataFrames offer the `applymap` method, which will apply a function to every
    individual element, something that is useful if there are no NumPy ufuncs available.
    For example, there are no ufuncs for string formatting, so we can format every
    element of a DataFrame like so:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框提供了`applymap`方法，该方法将应用于每个单独的元素，如果没有NumPy ufuncs可用，则非常有用。例如，没有用于字符串格式化的ufuncs，因此我们可以像这样格式化DataFrame的每个元素：
- en: '`In``[``66``]:``rainfall`'
  id: totrans-288
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``66``]:``rainfall`'
- en: '`Out[66]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
  id: totrans-289
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[66]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
- en: '`In``[``67``]:``def``format_string``(``x``):``return``f``"{x:,.2f}"`'
  id: totrans-290
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``67``]:``def``format_string``(``x``):``return``f``"{x:,.2f}"`'
- en: '`In``[``68``]:``# Note that we pass in the function without calling it,``#
    i.e., format_string and not format_string()!``rainfall``.``applymap``(``format_string``)`'
  id: totrans-291
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``68``]:``# 注意，我们传递函数时不要调用它，即format_string而不是format_string()！``rainfall``.``applymap``(``format_string``)`'
- en: '`Out[68]:    City 1  City 2    City 3          0  300.10  400.30  1,000.50
             1  100.20  300.40  1,100.60`'
  id: totrans-292
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[68]:    City 1  City 2    City 3          0  300.10  400.30  1,000.50
             1  100.20  300.40  1,100.60`'
- en: 'To break this down: the following f-string returns `x` as a string: `f"{x}"`.
    To add formatting, append a colon to the variable followed by the formatting string
    `,.2f`. The comma is the thousands separator and `.2f` means fixed-point notation
    with two digits following the decimal point. To get more details about how to
    format strings, please refer to the [Format Specification Mini-Language](https://oreil.ly/NgsG8),
    which is part of the Python documentation.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 要分解这个过程：下面的f-string将`x`返回为一个字符串：`f"{x}"`。要添加格式化，将冒号附加到变量后面，然后是格式化字符串`,.2f`。逗号是千位分隔符，`.2f`表示小数点后两位的固定点表示法。要获取有关如何格式化字符串的更多详细信息，请参阅[格式规范迷你语言](https://oreil.ly/NgsG8)，它是Python文档的一部分。
- en: 'For this sort of use case, lambda expressions (see sidebar) are widely used
    as they allow you to write the same in a single line without having to define
    a separate function. With lambda expressions, we can rewrite the previous example
    as the following:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种用例，lambda 表达式（见侧边栏）被广泛使用，因为它们允许你在一行内写出同样的内容，而无需定义单独的函数。利用 lambda 表达式，我们可以将前面的例子重写为以下形式：
- en: '`In``[``69``]:``rainfall``.``applymap``(``lambda``x``:``f``"{x:,.2f}"``)`'
  id: totrans-295
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``69``]:``降雨量``.``applymap``(``lambda``x``:``f``"{x:,.2f}"``)`'
- en: '`Out[69]:    City 1  City 2    City 3          0  300.10  400.30  1,000.50
             1  100.20  300.40  1,100.60`'
  id: totrans-296
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[69]:    城市 1  城市 2    城市 3          0  300.10  400.30  1,000.50         
    1  100.20  300.40  1,100.60`'
- en: LAMBDA EXPRESSIONS
  id: totrans-297
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: LAMBDA 表达式
- en: 'Python allows you to define a function in a single line via lambda expressions.
    Lambda expressions are anonymous functions, which means that it is a function
    without a name. Consider this function:'
  id: totrans-298
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Python 允许你通过 lambda 表达式在一行内定义函数。Lambda 表达式是匿名函数，这意味着它是一个没有名称的函数。考虑这个函数：
- en: '`def``function_name``(``arg1``,``arg2``,``...``):``return``return_value`'
  id: totrans-299
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`def``函数名``(``参数1``,``参数2``,``...``):``return``返回值`'
- en: 'This function can be rewritten as a lambda expression like this:'
  id: totrans-300
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这个函数可以重写为如下的 lambda 表达式：
- en: '`lambda``arg1``,``arg2``,``...``:``return_value`'
  id: totrans-301
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`lambda``参数1``,``参数2``,``...``:``返回值`'
- en: In essence, you replace `def` with `lambda`, leave away the `return` keyword
    and the function name, and put everything on one line. As we saw with the `applymap`
    method, this can be really convenient in this case as we don’t need to define
    a function for something that’s just being used a single time.
  id: totrans-302
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本质上，你用 lambda 替换 `def`，省略 `return` 关键字和函数名，并把所有内容放在一行上。就像我们在 `applymap` 方法中看到的那样，在这种情况下，这样做非常方便，因为我们不需要为仅被使用一次的事情定义一个函数。
- en: I have now mentioned all the important data manipulation methods, but before
    we move on, it’s important to understand when pandas uses a view of a DataFrame
    and when it uses a copy.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经提到了所有重要的数据操作方法，但在我们继续之前，理解 pandas 何时使用数据框的视图和何时使用副本是很重要的。
- en: View vs. Copy
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 视图 vs. 副本
- en: 'You may remember from the previous chapter that slicing NumPy arrays returns
    a view. With DataFrames, it’s unfortunately more complicated: it isn’t always
    easily predictable whether `loc` and `iloc` return views or copies, which makes
    it one of the more confusing topics. Since it’s a big difference whether you are
    changing the view or a copy of a DataFrame, pandas raises the following warning
    regularly when it thinks that you are setting the data in an unintended way: `SettingWithCopyWarning`.
    To circumvent this rather cryptic warning, here is some advice:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得上一章节中，切片 NumPy 数组返回一个视图。但是对于数据框而言，情况更加复杂：`loc` 和 `iloc` 是否返回视图或副本往往难以预测，这使得它成为比较令人困惑的话题之一。因为改变视图和数据框副本是很大的区别，当
    pandas 认为你以不合适的方式设置数据时，它经常会提出如下警告：`SettingWithCopyWarning`。为了避免这种颇为神秘的警告，这里有一些建议：
- en: Set values on the original DataFrame, not on a DataFrame that has been sliced
    off another DataFrame
  id: totrans-306
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在原始数据框上设置值，而不是在从另一个数据框切片得到的数据框上设置值
- en: 'If you want to have an independent DataFrame after slicing, make an explicit
    copy:'
  id: totrans-307
  prefs:
  - PREF_UL
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你想要在切片后得到一个独立的数据框，那么要显式地复制：
- en: '`selection``=``df``.``loc``[:,``[``"country"``,``"continent"``]]``.``copy``()`'
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`选择``=``df``.``loc``[:,``[``"国家"``,``"大陆"``]]``.``copy``()`'
- en: While things are complicated with `loc` and `iloc`, it’s worth remembering that
    all DataFrame methods such as `df.dropna()` or `df.sort_values("column_name")`
    always return a copy.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在处理 `loc` 和 `iloc` 时情况复杂，但值得记住的是，所有数据框方法如 `df.dropna()` 或 `df.sort_values("列名")`
    总是返回一个副本。
- en: So far, we’ve mostly worked with one DataFrame at a time. The next section shows
    you various ways to combine multiple DataFrames into one, a very common task for
    which pandas offers powerful tools.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们大多数时间都是在处理一个数据框。接下来的章节将展示多种将多个数据框合并为一个的方法，这是 pandas 提供的一个非常常见的强大工具。
- en: Combining DataFrames
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 合并数据框
- en: Combining different datasets in Excel can be a cumbersome task and typically
    involves a lot of `VLOOKUP` formulas. Fortunately, combining DataFrames is one
    of pandas’ killer features where its data alignment capabilities will make your
    life really easy, thereby greatly reducing the possibility of introducing errors.
    Combining and merging DataFrames can be done in various ways; this section looks
    at just the most common cases using `concat`, `join`, and `merge`. While they
    have an overlap, each function makes a specific task very simple. I will start
    with the `concat` function, then explain the different options with `join`, and
    conclude by introducing `merge`, the most generic function of the three.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在Excel中组合不同的数据集可能是一个繁琐的任务，通常涉及大量的`VLOOKUP`公式。幸运的是，pandas的合并DataFrame功能是其杀手级功能之一，其数据对齐能力将极大地简化你的生活，从而大大减少引入错误的可能性。合并和连接DataFrame可以通过各种方式进行；本节只讨论使用`concat`、`join`和`merge`的最常见情况。虽然它们有重叠之处，但每个函数都使特定任务变得非常简单。我将从`concat`函数开始，然后解释使用`join`的不同选项，最后介绍最通用的`merge`函数。
- en: Concatenating
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 连接
- en: 'To simply glue multiple DataFrames together, the `concat` function is your
    best friend. As you can tell by the name of the function, this process has the
    technical name concatenation. By default, `concat` glues DataFrames together along
    the rows and aligns the columns automatically. In the following example, I create
    another DataFrame, `more_users`, and attach it to the bottom of our sample DataFrame
    `df`:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地将多个DataFrame粘合在一起，`concat`函数是你的好帮手。正如函数名称所示，这个过程有一个技术名字叫做连接。默认情况下，`concat`沿着行将DataFrame粘合在一起，并自动对齐列。在下面的示例中，我创建了另一个DataFrame
    `more_users`，并将其附加到我们样本DataFrame `df`的底部：
- en: '`In``[``70``]:``data``=``[[``15``,``"France"``,``4.1``,``"Becky"``],``[``44``,``"Canada"``,``6.1``,``"Leanne"``]]``more_users``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"age"``,``"country"``,``"score"``,``"name"``],``index``=``[``1000``,``1011``])``more_users`'
  id: totrans-315
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``70``]:``data``=``[[``15``,``"法国"``,``4.1``,``"贝基"``],``[``44``,``"加拿大"``,``6.1``,``"莉安"``]]``more_users``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"年龄"``,``"国家"``,``"得分"``,``"姓名"``],``index``=``[``1000``,``1011``])``more_users`'
- en: '`Out[70]:       age country  score    name          1000   15  France    4.1  
    Becky          1011   44  Canada    6.1  Leanne`'
  id: totrans-316
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[70]:       年龄 国家  得分    姓名          1000   15  法国    4.1   贝基         
    1011   44  加拿大    6.1  莉安`'
- en: '`In``[``71``]:``pd``.``concat``([``df``,``more_users``],``axis``=``0``)`'
  id: totrans-317
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``71``]:``pd``.``concat``([``df``,``more_users``],``axis``=``0``)`'
- en: '`Out[71]:         name  age  country  score continent          1001    Mark  
    55    Italy    4.5    Europe          1000    John   33      USA    6.7   America
             1002     Tim   41      USA    3.9   America          1003   Jenny   12 
    Germany    9.0    Europe          1000   Becky   15   France    4.1       NaN
             1011  Leanne   44   Canada    6.1       NaN`'
  id: totrans-318
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[71]:         姓名  年龄  国家  得分 大陆          1001    马克   55    意大利    4.5   
    欧洲          1000    约翰   33      美国    6.7   美洲          1002     蒂姆   41     
    美国    3.9   美洲          1003   珍妮   12  德国    9.0    欧洲          1000   贝基   15  
    法国    4.1       NaN          1011  莉安   44   加拿大    6.1       NaN`'
- en: 'Note that you now have duplicate index elements, as `concat` glues the data
    together on the indicated axis (rows) and only aligns the data on the other one
    (columns), thereby matching the column names automatically—even if they are not
    in the same order in the two DataFrames! If you want to glue two DataFrames together
    along the columns, set `axis=1`:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你注意到，由于`concat`在指定轴（行）上将数据粘合在一起，并且仅在另一个轴（列）上对齐数据，所以你现在有重复的索引元素！即使两个DataFrame中的列名不同序，它们也会自动匹配列名！如果你想沿着列将两个DataFrame粘合在一起，请设置`axis=1`：
- en: '`In``[``72``]:``data``=``[[``3``,``4``],``[``5``,``6``]]``more_categories``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"quizzes"``,``"logins"``],``index``=``[``1000``,``2000``])``more_categories`'
  id: totrans-320
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``72``]:``data``=``[[``3``,``4``],``[``5``,``6``]]``more_categories``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"测验"``,``"登录"``],``index``=``[``1000``,``2000``])``more_categories`'
- en: '`Out[72]:       quizzes  logins          1000        3       4          2000       
    5       6`'
  id: totrans-321
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[72]:       测验  登录          1000        3       4          2000       
    5       6`'
- en: '`In``[``73``]:``pd``.``concat``([``df``,``more_categories``],``axis``=``1``)`'
  id: totrans-322
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``73``]:``pd``.``concat``([``df``,``more_categories``],``axis``=``1``)`'
- en: '`Out[73]:        name   age  country  score continent  quizzes  logins         
    1000   John  33.0      USA    6.7   America      3.0     4.0          1001   Mark 
    55.0    Italy    4.5    Europe      NaN     NaN          1002    Tim  41.0     
    USA    3.9   America      NaN     NaN          1003  Jenny  12.0  Germany    9.0   
    Europe      NaN     NaN          2000    NaN   NaN      NaN    NaN       NaN     
    5.0     6.0`'
  id: totrans-323
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[73]:        name   age  country  score continent  quizzes  logins         
    1000   John  33.0      USA    6.7   America      3.0     4.0          1001   Mark 
    55.0    Italy    4.5    Europe      NaN     NaN          1002    Tim  41.0     
    USA    3.9   America      NaN     NaN          1003  Jenny  12.0  Germany    9.0   
    Europe      NaN     NaN          2000    NaN   NaN      NaN    NaN       NaN     
    5.0     6.0`'
- en: 'The special and very useful feature of `concat` is that it accepts more than
    two DataFrames. We will use this in the next chapter to make a single DataFrame
    out of multiple CSV files:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '`concat` 的特殊且非常有用的特性是它可以接受超过两个 DataFrame。我们将在下一章节中使用它将多个 CSV 文件合并成一个单独的 DataFrame：'
- en: '`pd``.``concat``([``df1``,``df2``,``df3``,``...``])`'
  id: totrans-325
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`pd``.``concat``([``df1``,``df2``,``df3``,``...``])`'
- en: On the other hand, `join` and `merge` only work with two DataFrames, as we’ll
    see next.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`join` 和 `merge` 仅适用于两个 DataFrame，下面我们将看到。
- en: Joining and Merging
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 连接与合并
- en: When you join two DataFrames, you combine the columns of each DataFrame into
    a new DataFrame while deciding what happens with the rows by relying on set theory.
    If you have worked with relational databases before, it’s the same concept as
    the `JOIN` clause in SQL queries. [Figure 5-3](#filepos668317) shows how the four
    join types (that is the inner, left, right, and outer join) work by using two
    sample DataFrames, `df1` and `df2`.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 当你连接两个 DataFrame 时，你将每个 DataFrame 的列合并到一个新的 DataFrame 中，同时根据集合理论决定行的处理方式。如果你之前有过与关系数据库的工作经验，那么这与
    SQL 查询中的 `JOIN` 子句是相同的概念。[图 5-3](#filepos668317) 显示了内连接、左连接、右连接和外连接四种连接类型如何通过使用两个示例
    DataFrame `df1` 和 `df2` 进行操作。
- en: '![](images/00002.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00002.jpg)'
- en: Figure 5-3\. Join types
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-3\. 连接类型
- en: With `join`, pandas uses the indices of both DataFrames to align the rows. An
    inner join returns a DataFrame with only those rows where the indices overlap.
    A left join takes all the rows from the left DataFrame `df1` and matches the rows
    from the right DataFrame `df2` on the index. Where `df2` doesn’t have a matching
    row, pandas will fill in `NaN`. The left join corresponds to the `VLOOKUP` case
    in Excel. The right join takes all rows from the right table `df2` and matches
    them with rows from `df1` on the index. And finally, the outer join, which is
    short for full outer join, takes the union of indices from both DataFrames and
    matches the values where it can. [Table 5-5](#filepos669531) is the equivalent
    of [Figure 5-3](#filepos668317) in text form.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `join` 方法，pandas 使用两个 DataFrame 的索引来对齐行。内连接返回仅在索引重叠的行的 DataFrame。左连接获取左侧
    DataFrame `df1` 的所有行，并在右侧 DataFrame `df2` 上匹配索引。在 `df2` 中没有匹配行的地方，pandas 将填充 `NaN`。左连接对应于
    Excel 中的 `VLOOKUP` 情况。右连接获取右表 `df2` 的所有行，并将它们与 `df1` 的行在索引上匹配。最后，全外连接（即完全外连接）获取两个
    DataFrame 的索引的并集，并在可能的情况下匹配值。[表 5-5](#filepos669531) 是文本形式中 [图 5-3](#filepos668317)
    的等效内容。
- en: Table 5-5\. Join types
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-5\. 连接类型
- en: '|  Type  |  Description  |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '|  类型  |  描述  |'
- en: '|   `inner` |  Only rows whose index exists in both DataFrames  |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '|   `inner` |  仅包含索引存在于两个 DataFrame 中的行  |'
- en: '|   `left` |  All rows from the left DataFrame, matching rows from the right
    DataFrame  |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '|   `left` |  从左 DataFrame 中获取所有行，匹配右 DataFrame 的行  |'
- en: '|   `right` |  All rows from the right DataFrame, matching rows from the left
    DataFrame  |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '|   `right` |  从右 DataFrame 中获取所有行，匹配左 DataFrame 的行  |'
- en: '|   `outer` |  The union of row indices from both DataFrames  |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '|   `outer` |  从两个 DataFrame 中获取所有行的并集  |'
- en: 'Let’s see how this works in practice, bringing the examples from [Figure 5-3](#filepos668317)
    to life:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看实际操作中的情况，将 [图 5-3](#filepos668317) 中的示例活现出来：
- en: '`In``[``74``]:``df1``=``pd``.``DataFrame``(``data``=``[[``1``,``2``],``[``3``,``4``],``[``5``,``6``]],``columns``=``[``"A"``,``"B"``])``df1`'
  id: totrans-339
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``74``]:``df1``=``pd``.``DataFrame``(``data``=``[[``1``,``2``],``[``3``,``4``],``[``5``,``6``]],``columns``=``[``"A"``,``"B"``])``df1`'
- en: '`Out[74]:    A  B          0  1  2          1  3  4          2  5  6`'
  id: totrans-340
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[74]:    A  B          0  1  2          1  3  4          2  5  6`'
- en: '`In``[``75``]:``df2``=``pd``.``DataFrame``(``data``=``[[``10``,``20``],``[``30``,``40``]],``columns``=``[``"C"``,``"D"``],``index``=``[``1``,``3``])``df2`'
  id: totrans-341
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``75``]:``df2``=``pd``.``DataFrame``(``data``=``[[``10``,``20``],``[``30``,``40``]],``columns``=``[``"C"``,``"D"``],``index``=``[``1``,``3``])``df2`'
- en: '`Out[75]:     C   D          1  10  20          3  30  40`'
  id: totrans-342
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[75]:     C   D          1  10  20          3  30  40`'
- en: '`In``[``76``]:``df1``.``join``(``df2``,``how``=``"inner"``)`'
  id: totrans-343
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``76``]:``df1``.``join``(``df2``,``how``=``"inner"``)`'
- en: '`Out[76]:    A  B   C   D          1  3  4  10  20`'
  id: totrans-344
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[76]:    A  B   C   D          1  3  4  10  20`'
- en: '`In``[``77``]:``df1``.``join``(``df2``,``how``=``"left"``)`'
  id: totrans-345
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``77``]:``df1``.``join``(``df2``,``how``=``"left"``)`'
- en: '`Out[77]:    A  B     C     D          0  1  2   NaN   NaN          1  3  4 
    10.0  20.0          2  5  6   NaN   NaN`'
  id: totrans-346
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[77]:    A  B     C     D          0  1  2   NaN   NaN          1  3  4 
    10.0  20.0          2  5  6   NaN   NaN`'
- en: '`In``[``78``]:``df1``.``join``(``df2``,``how``=``"right"``)`'
  id: totrans-347
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``78``]:``df1``.``join``(``df2``,``how``=``"right"``)`'
- en: '`Out[78]:      A    B   C   D          1  3.0  4.0  10  20          3  NaN 
    NaN  30  40`'
  id: totrans-348
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[78]:      A    B   C   D          1  3.0  4.0  10  20          3  NaN 
    NaN  30  40`'
- en: '`In``[``79``]:``df1``.``join``(``df2``,``how``=``"outer"``)`'
  id: totrans-349
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``79``]:``df1``.``join``(``df2``,``how``=``"outer"``)`'
- en: '`Out[79]:      A    B     C     D          0  1.0  2.0   NaN   NaN         
    1  3.0  4.0  10.0  20.0          2  5.0  6.0   NaN   NaN          3  NaN  NaN 
    30.0  40.0`'
  id: totrans-350
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[79]:      A    B     C     D          0  1.0  2.0   NaN   NaN         
    1  3.0  4.0  10.0  20.0          2  5.0  6.0   NaN   NaN          3  NaN  NaN 
    30.0  40.0`'
- en: 'If you want to join on one or more DataFrame columns instead of relying on
    the index, use `merge` instead of `join`. `merge` accepts the `on` argument to
    provide one or more columns as the join condition: these columns, which have to
    exist on both DataFrames, are used to match the rows:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要根据一个或多个DataFrame列进行连接而不是依赖索引，使用`merge`而不是`join`。`merge`接受`on`参数作为连接条件：这些列必须存在于两个DataFrame中，并用于匹配行：
- en: '`In``[``80``]:``# Add a column called "category" to both DataFrames``df1``[``"category"``]``=``[``"a"``,``"b"``,``"c"``]``df2``[``"category"``]``=``[``"c"``,``"b"``]`'
  id: totrans-352
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``80``]:``# 给两个DataFrame都添加一个名为"category"的列``df1``[``"category"``]``=``[``"a"``,``"b"``,``"c"``]``df2``[``"category"``]``=``[``"c"``,``"b"``]`'
- en: '`In``[``81``]:``df1`'
  id: totrans-353
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``81``]:``df1`'
- en: '`Out[81]:    A  B category          0  1  2        a          1  3  4       
    b          2  5  6        c`'
  id: totrans-354
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[81]:    A  B category          0  1  2        a          1  3  4       
    b          2  5  6        c`'
- en: '`In``[``82``]:``df2`'
  id: totrans-355
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``82``]:``df2`'
- en: '`Out[82]:     C   D category          1  10  20        c          3  30  40       
    b`'
  id: totrans-356
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[82]:     C   D category          1  10  20        c          3  30  40       
    b`'
- en: '`In``[``83``]:``df1``.``merge``(``df2``,``how``=``"inner"``,``on``=``[``"category"``])`'
  id: totrans-357
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``83``]:``df1``.``merge``(``df2``,``how``=``"inner"``,``on``=``[``"category"``])`'
- en: '`Out[83]:    A  B category   C   D          0  3  4        b  30  40         
    1  5  6        c  10  20`'
  id: totrans-358
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[83]:    A  B category   C   D          0  3  4        b  30  40         
    1  5  6        c  10  20`'
- en: '`In``[``84``]:``df1``.``merge``(``df2``,``how``=``"left"``,``on``=``[``"category"``])`'
  id: totrans-359
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``84``]:``df1``.``merge``(``df2``,``how``=``"left"``,``on``=``[``"category"``])`'
- en: '`Out[84]:    A  B category     C     D          0  1  2        a   NaN   NaN
             1  3  4        b  30.0  40.0          2  5  6        c  10.0  20.0`'
  id: totrans-360
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[84]:    A  B category     C     D          0  1  2        a   NaN   NaN
             1  3  4        b  30.0  40.0          2  5  6        c  10.0  20.0`'
- en: Since `join` and `merge` accept quite a few optional arguments to accommodate
    more complex scenarios, I invite you to have a look at the [official documentation](https://oreil.ly/OZ4WV)
    to learn more about them.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`join`和`merge`接受许多可选参数来适应更复杂的场景，我建议你查看[官方文档](https://oreil.ly/OZ4WV)以了解更多信息。
- en: 'You know now how to manipulate one or more DataFrames, which brings us to the
    next step in our data analysis journey: making sense of data.'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在知道如何操作一个或多个DataFrame，这将引导我们数据分析旅程的下一步：理解数据。
- en: Descriptive Statistics and Data Aggregation
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 描述性统计和数据聚合
- en: 'One way to make sense of big datasets is to compute a descriptive statistic
    like the sum or the mean on either the whole dataset or on meaningful subsets.
    This section starts by looking at how this works with pandas before it introduces
    two ways to aggregate data into subsets: the `groupby` method and the `pivot_table`
    function.'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解大数据集的一种方法是计算描述统计，如总和或平均值，可以针对整个数据集或有意义的子集。本节首先介绍了在pandas中如何进行这种操作，然后介绍了两种数据聚合到子集的方式：`groupby`方法和`pivot_table`函数。
- en: Descriptive Statistics
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 描述性统计
- en: 'Descriptive statistics allows you to summarize datasets by using quantitative
    measures. For example, the number of data points is a simple descriptive statistic.
    Averages like mean, median, or mode are other popular examples. DataFrames and
    Series allow you to access descriptive statistics conveniently via methods like
    `sum`, `mean`, and `count`, to name just a few. You will meet many of them throughout
    this book, and the full list is available via the [pandas documentation](https://oreil.ly/t2q9Q).
    By default, they return a Series along `axis=0`, which means you get the statistic
    of the columns:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 描述性统计允许你通过使用定量的方法对数据集进行总结。例如，数据点的数量是一个简单的描述性统计量。像均值、中位数或众数这样的平均数也是其他流行的例子。DataFrame和Series允许你通过诸如`sum`、`mean`和`count`之类的方法方便地访问描述性统计信息。在本书中你将会遇到许多这样的方法，并且完整的列表可以通过[pandas文档](https://oreil.ly/t2q9Q)获取。默认情况下，它们返回沿着`axis=0`的Series，这意味着你得到了列的统计信息：
- en: '`In``[``85``]:``rainfall`'
  id: totrans-367
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``85``]:``rainfall`'
- en: '`Out[85]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
  id: totrans-368
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[85]:    City 1  City 2  City 3          0   300.1   400.3  1000.5         
    1   100.2   300.4  1100.6`'
- en: '`In``[``86``]:``rainfall``.``mean``()`'
  id: totrans-369
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``86``]:``rainfall``.``mean``()`'
- en: '`Out[86]: City 1     200.15          City 2     350.35          City 3    1050.55
             dtype: float64`'
  id: totrans-370
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[86]: City 1     200.15          City 2     350.35          City 3    1050.55
             dtype: float64`'
- en: 'If you want the statistic per row, provide the `axis` argument:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要每行的统计信息，请提供`axis`参数：
- en: '`In``[``87``]:``rainfall``.``mean``(``axis``=``1``)`'
  id: totrans-372
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``87``]:``rainfall``.``mean``(``axis``=``1``)`'
- en: '`Out[87]: 0    566.966667          1    500.400000          dtype: float64`'
  id: totrans-373
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[87]: 0    566.966667          1    500.400000          dtype: float64`'
- en: By default, missing values are not included in descriptive statistics like `sum`
    or `mean`. This is in line with how Excel treats empty cells, so using Excel’s
    `AVERAGE` formula on a range with empty cells will give you the same result as
    the `mean` method applied on a Series with the same numbers and `NaN` values instead
    of empty cells.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，描述性统计不包括缺失值，这与Excel处理空单元格的方式一致，因此在带有空单元格的范围上使用Excel的`AVERAGE`公式将给出与在具有相同数字和`NaN`值而不是空单元格的Series上应用`mean`方法相同的结果。
- en: Getting a statistic across all rows of a DataFrame is sometimes not good enough
    and you need more granular information—the mean per category, for example. Let’s
    see how it’s done!
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 有时仅仅获取DataFrame所有行的统计数据是不够的，你需要更详细的信息——例如每个类别的平均值。让我们看看如何实现！
- en: Grouping
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 分组
- en: 'Using our sample DataFrame `df` again, let’s find out the average score per
    continent! To do this, you first group the rows by continent and subsequently
    apply the `mean` method, which will calculate the mean per group. All nonnumeric
    columns are automatically excluded:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的示例DataFrame `df`，让我们再次找出每个大陆的平均分数！为此，首先按大陆分组行，然后应用`mean`方法，该方法将计算每个组的平均值。所有非数字列将自动排除：
- en: '`In``[``88``]:``df``.``groupby``([``"continent"``])``.``mean``()`'
  id: totrans-378
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``88``]:``df``.``groupby``([``"continent"``])``.``mean``()`'
- en: '`Out[88]: properties   age  score          continent          America     37.0  
    5.30          Europe      33.5   6.75`'
  id: totrans-379
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[88]: properties   age  score          continent          America     37.0  
    5.30          Europe      33.5   6.75`'
- en: 'If you include more than one column, the resulting DataFrame will have a hierarchical
    index—the MultiIndex we met earlier on:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 如果包括多于一个列，生成的DataFrame将具有层次化索引——我们之前遇到的MultiIndex：
- en: '`In``[``89``]:``df``.``groupby``([``"continent"``,``"country"``])``.``mean``()`'
  id: totrans-381
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``89``]:``df``.``groupby``([``"continent"``,``"country"``])``.``mean``()`'
- en: '`Out[89]: properties         age  score          continent country         
    America   USA       37    5.3          Europe    Germany   12    9.0                   
    Italy     55    4.5`'
  id: totrans-382
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[89]: properties         age  score          continent country         
    America   USA       37    5.3          Europe    Germany   12    9.0                   
    Italy     55    4.5`'
- en: 'Instead of `mean`, you can use most of the descriptive statistics that pandas
    offers and if you want to use your own function, use the `agg` method. For example,
    here is how you get the difference between the maximum and minimum value per group:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用大多数由pandas提供的描述性统计量，如果想使用自己的函数，可以使用`agg`方法。例如，这是如何获取每个组最大值与最小值之差的方法：
- en: '`In``[``90``]:``df``.``groupby``([``"continent"``])``.``agg``(``lambda``x``:``x``.``max``()``-``x``.``min``())`'
  id: totrans-384
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``90``]:``df``.``groupby``([``"continent"``])``.``agg``(``lambda``x``:``x``.``max``()``-``x``.``min``())`'
- en: '`Out[90]: properties  age  score          continent          America      
    8    2.8          Europe       43    4.5`'
  id: totrans-385
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[90]: properties  age  score          continent          America      
    8    2.8          Europe       43    4.5`'
- en: A popular way to get statistics per group in Excel is to use pivot tables. They
    introduce a second dimension and are great to look at your data from different
    perspectives. pandas has a pivot table functionality, too, as we will see next.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Excel 中，获取每个分组的统计数据的一种流行方式是使用数据透视表。它们引入了第二个维度，非常适合从不同角度查看数据。pandas 也有数据透视表功能，我们接下来会看到。
- en: Pivoting and Melting
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 数据透视和数据融合
- en: 'If you are using pivot tables in Excel, you will have no trouble applying pandas’
    `pivot_table` function, as it works in largely the same way. The data in the following
    DataFrame is organized similarly to how records are typically stored in a database;
    each row shows a sales transaction for a specific fruit in a certain region:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在Excel中使用数据透视表，可以毫不费力地应用 pandas 的`pivot_table`函数，因为它的使用方式基本相同。下面的 DataFrame
    中的数据组织方式与通常在数据库中存储记录的方式类似；每一行显示了特定水果在特定地区的销售交易：
- en: '`In``[``91``]:``data``=``[[``"Oranges"``,``"North"``,``12.30``],``[``"Apples"``,``"South"``,``10.55``],``[``"Oranges"``,``"South"``,``22.00``],``[``"Bananas"``,``"South"``,``5.90``],``[``"Bananas"``,``"North"``,``31.30``],``[``"Oranges"``,``"North"``,``13.10``]]``sales``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"Fruit"``,``"Region"``,``"Revenue"``])``sales`'
  id: totrans-389
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``91``]:``data``=``[[``"Oranges"``,``"North"``,``12.30``],``[``"Apples"``,``"South"``,``10.55``],``[``"Oranges"``,``"South"``,``22.00``],``[``"Bananas"``,``"South"``,``5.90``],``[``"Bananas"``,``"North"``,``31.30``],``[``"Oranges"``,``"North"``,``13.10``]]``sales``=``pd``.``DataFrame``(``data``=``data``,``columns``=``[``"Fruit"``,``"Region"``,``"Revenue"``])``sales`'
- en: '`Out[91]:      Fruit Region  Revenue          0  Oranges  North    12.30         
    1   Apples  South    10.55          2  Oranges  South    22.00          3  Bananas 
    South     5.90          4  Bananas  North    31.30          5  Oranges  North   
    13.10`'
  id: totrans-390
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[91]:      Fruit Region  Revenue          0  Oranges  North    12.30         
    1   Apples  South    10.55          2  Oranges  South    22.00          3  Bananas 
    South     5.90          4  Bananas  North    31.30          5  Oranges  North   
    13.10`'
- en: 'To create a pivot table, you provide the DataFrame as the first argument to
    the `pivot_table` function. `index` and `columns` define which column of the DataFrame
    will become the pivot table’s row and column labels, respectively. `values` are
    going to be aggregated into the data part of the resulting DataFrame by using
    the `aggfunc`, a function that can be provided as a string or NumPy ufunc. And
    finally, `margins` correspond to `Grand Total` in Excel, i.e., if you leave `margins`
    and `margins_name` away, the `Total` column and row won’t be shown:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建数据透视表，将 DataFrame 作为`pivot_table`函数的第一个参数提供。`index`和`columns`定义了 DataFrame
    的哪一列将成为数据透视表的行和列标签。`values`将根据`aggfunc`聚合到生成的 DataFrame 的数据部分中，`aggfunc`是一个可以作为字符串或
    NumPy ufunc 提供的函数。最后，`margins`对应于 Excel 中的`Grand Total`，即如果不指定`margins`和`margins_name`，则不会显示`Total`列和行：
- en: '`In``[``92``]:``pivot``=``pd``.``pivot_table``(``sales``,``index``=``"Fruit"``,``columns``=``"Region"``,``values``=``"Revenue"``,``aggfunc``=``"sum"``,``margins``=``True``,``margins_name``=``"Total"``)``pivot`'
  id: totrans-392
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``92``]:``pivot``=``pd``.``pivot_table``(``sales``,``index``=``"Fruit"``,``columns``=``"Region"``,``values``=``"Revenue"``,``aggfunc``=``"sum"``,``margins``=``True``,``margins_name``=``"Total"``)``pivot`'
- en: '`Out[92]: Region   North  South  Total          Fruit          Apples     NaN 
    10.55  10.55          Bananas   31.3   5.90  37.20          Oranges   25.4  22.00 
    47.40          Total     56.7  38.45  95.15`'
  id: totrans-393
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[92]: Region   North  South  Total          Fruit          Apples     NaN 
    10.55  10.55          Bananas   31.3   5.90  37.20          Oranges   25.4  22.00 
    47.40          Total     56.7  38.45  95.15`'
- en: 'In summary, pivoting your data means to take the unique values of a column
    (`Region` in our case) and turn them into the column headers of the pivot table,
    thereby aggregating the values from another column. This makes it easy to read
    off summary information across the dimensions of interest. In our pivot table,
    you instantly see that there were no apples sold in the north region and that
    in the south region, most revenues come from oranges. If you want to go the other
    way around and turn the column headers into the values of a single column, use
    `melt`. In that sense, `melt` is the opposite of the `pivot_table` function:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，对数据进行透视意味着获取某一列的唯一值（在我们的例子中是`Region`），并将其转换为数据透视表的列标题，从而聚合另一列的值。这样可以轻松地查看所关心维度的汇总信息。在我们的数据透视表中，您立即可以看到北部地区没有销售苹果，而南部地区的大部分收入来自橙子。如果您希望反过来，将列标题转换为单列的值，请使用`melt`。从这个意义上说，`melt`是`pivot_table`函数的反义词：
- en: '`In``[``93``]:``pd``.``melt``(``pivot``.``iloc``[:``-``1``,:``-``1``]``.``reset_index``(),``id_vars``=``"Fruit"``,``value_vars``=``[``"North"``,``"South"``],``value_name``=``"Revenue"``)`'
  id: totrans-395
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``93``]:``pd``.``melt``(``pivot``.``iloc``[:``-``1``,:``-``1``]``.``reset_index``(),``id_vars``=``"Fruit"``,``value_vars``=``[``"North"``,``"South"``],``value_name``=``"Revenue"``)`'
- en: '`Out[93]:      Fruit Region  Revenue          0   Apples  North      NaN         
    1  Bananas  North    31.30          2  Oranges  North    25.40          3   Apples 
    South    10.55          4  Bananas  South     5.90          5  Oranges  South   
    22.00`'
  id: totrans-396
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[93]:      Fruit Region  Revenue          0   Apples  North      NaN         
    1  Bananas  North    31.30          2  Oranges  North    25.40          3   Apples 
    South    10.55          4  Bananas  South     5.90          5  Oranges  South   
    22.00`'
- en: Here, I am providing our pivot table as the input, but I am using `iloc` to
    get rid of the total row and column. I also reset the index so that all information
    is available as regular columns. I then provide `id_vars` to indicate the identifiers
    and `value_vars` to define which columns I want to “unpivot.” Melting can be useful
    if you want to prepare the data so it can be stored back to a database that expects
    it in this format.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我将我们的透视表作为输入提供，但我使用`iloc`来去除总行和列。我还重置索引，以便所有信息都作为常规列可用。然后，我提供`id_vars`以指示标识符，并提供`value_vars`以定义我要“解构”的列。如果您希望准备数据以便将其存储回预期以此格式存储的数据库中，熔断可能会很有用。
- en: Working with aggregated statistics helps you understand your data, but nobody
    likes to read a page full of numbers. To make information easily understandable,
    nothing works better than creating visualizations, which is our next topic. While
    Excel uses the term charts, pandas generally refers to them as plots. I will use
    these terms interchangeably in this book.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 使用聚合统计数据有助于理解数据，但没有人喜欢阅读满篇数字。为了使信息易于理解，创建可视化效果最有效，这是我们接下来要讨论的内容。虽然Excel使用术语图表，但pandas通常称之为图。在本书中，我会交替使用这些术语。
- en: Plotting
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图
- en: 'Plotting allows you to visualize the findings of your data analysis and may
    well be the most important step in the whole process. For plotting, we’re going
    to use two libraries: we start by looking at Matplotlib, pandas’ default plotting
    library, before we focus on Plotly, a modern plotting library that gives us a
    more interactive experience in Jupyter notebooks.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图允许您可视化数据分析的发现，可能是整个过程中最重要的一步。对于绘图，我们将使用两个库：首先是Matplotlib，pandas的默认绘图库，然后是Plotly，这是一个现代绘图库，在Jupyter笔记本中提供更交互式的体验。
- en: Matplotlib
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: Matplotlib
- en: Matplotlib is a plotting package that has been around for a long time and is
    included in the Anaconda distribution. With it, you can generate plots in a variety
    of formats, including vector graphics for high-quality printing. When you call
    the `plot` method of a DataFrame, pandas will produce a Matplotlib plot by default.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: Matplotlib是一个长期存在的绘图包，包含在Anaconda发行版中。您可以使用它生成多种格式的图表，包括高质量打印的矢量图形。当您调用DataFrame的`plot`方法时，pandas默认会生成一个Matplotlib图。
- en: 'To use Matplotlib in a Jupyter notebook, you need to first run one of two magic
    commands (see the sidebar [“Magic Commands”](#filepos726690)): `%matplotlib inline`
    or `%matplotlib notebook`. They configure the notebook so that plots can be displayed
    in the notebook itself. The latter command adds a bit more interactivity, allowing
    you to change the size or zoom factor of the chart. Let’s get started and create
    a first plot with pandas and Matplotlib (see [Figure 5-4](#filepos726089)):'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Jupyter笔记本中使用Matplotlib，您需要首先运行两个魔术命令中的一个（参见侧边栏[“魔术命令”](#filepos726690)）：`%matplotlib
    inline`或`%matplotlib notebook`。它们配置笔记本以便在笔记本本身中显示图表。后者命令增加了一些交互性，允许您更改图表的大小或缩放系数。让我们开始，并使用pandas和Matplotlib创建第一个图表（见[图5-4](#filepos726089)）：
- en: '`In``[``94``]:``import``numpy``as``np``%``matplotlib``inline``# Or %matplotlib
    notebook`'
  id: totrans-404
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``94``]:``import``numpy``as``np``%``matplotlib``inline``# Or %matplotlib
    notebook`'
- en: '`In``[``95``]:``data``=``pd``.``DataFrame``(``data``=``np``.``random``.``rand``(``4``,``4``)``*``100000``,``index``=``[``"Q1"``,``"Q2"``,``"Q3"``,``"Q4"``],``columns``=``[``"East"``,``"West"``,``"North"``,``"South"``])``data``.``index``.``name``=``"Quarters"``data``.``columns``.``name``=``"Region"``data`'
  id: totrans-405
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``95``]:``data``=``pd``.``DataFrame``(``data``=``np``.``random``.``rand``(``4``,``4``)``*``100000``,``index``=``[``"Q1"``,``"Q2"``,``"Q3"``,``"Q4"``],``columns``=``[``"East"``,``"West"``,``"North"``,``"South"``])``data``.``index``.``name``=``"Quarters"``data``.``columns``.``name``=``"Region"``data`'
- en: '`Out[95]: Region            East          West         North         South
             Quarters          Q1        23254.220271  96398.309860  16845.951895 
    41671.684909          Q2        87316.022433  45183.397951  15460.819455  50951.465770
             Q3        51458.760432   3821.139360  77793.393899  98915.952421         
    Q4        64933.848496   7600.277035  55001.831706  86248.512650`'
  id: totrans-406
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[95]: Region            East          West         North         South
             Quarters          Q1        23254.220271  96398.309860  16845.951895 
    41671.684909          Q2        87316.022433  45183.397951  15460.819455  50951.465770
             Q3        51458.760432   3821.139360  77793.393899  98915.952421         
    Q4        64933.848496   7600.277035  55001.831706  86248.512650`'
- en: '`In``[``96``]:``data``.``plot``()``# Shortcut for data.plot.line()`'
  id: totrans-407
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``96``]:``data``.``plot``()``# 快捷方式用于 data.plot.line()``'
- en: '`Out[96]: <AxesSubplot:xlabel=''Quarters''>`'
  id: totrans-408
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[96]: <AxesSubplot:xlabel=''Quarters''>`'
- en: '![](images/00008.jpg)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00008.jpg)'
- en: Figure 5-4\. Matplotlib plot
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-4\. Matplotlib 绘图
- en: Note that in this example, I have used a NumPy array to construct a pandas DataFrame.
    Providing NumPy arrays allows you to leverage NumPy’s constructors that we met
    in the last chapter; here, we use NumPy to generate a pandas DataFrame based on
    pseudorandom numbers. Therefore, when you run the sample on your end, you will
    get different values.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在此示例中，我使用了 NumPy 数组来构建 pandas DataFrame。提供 NumPy 数组允许你利用上一章介绍的 NumPy 构造函数；在这里，我们使用
    NumPy 根据伪随机数生成了一个 pandas DataFrame。因此，当你在自己的环境中运行示例时，会得到不同的值。
- en: MAGIC COMMANDS
  id: totrans-412
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 魔术命令
- en: The `%matplotlib inline` command we used to make Matplotlib work properly with
    Jupyter notebooks is a magic command. Magic commands are a set of simple commands
    that cause a Jupyter notebook cell to behave in a certain way or make cumbersome
    tasks so easy that it almost feels like magic. You write magic commands in cells
    like Python code, but they either start with `%%` or `%`. Commands that affect
    the whole cell start with `%%`, and commands that only affect a single line in
    a cell start with `%`.
  id: totrans-413
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们在 Jupyter 笔记本中使用的 `%matplotlib inline` 命令是一个魔术命令。魔术命令是一组简单的命令，可以让 Jupyter
    笔记本单元格以特定方式运行，或者使繁琐的任务变得异常简单，几乎像魔术一样。你可以像写 Python 代码一样在单元格中编写这些命令，但它们以 `%%` 或
    `%` 开头。影响整个单元格的命令以 `%%` 开头，而仅影响单行的命令以 `%` 开头。
- en: We will see more magic commands in the next chapters, but if you want to list
    all currently available magic commands, run `%lsmagic`, and for a detailed description,
    run `%magic`.
  id: totrans-414
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中看到更多的魔术命令，但如果你想列出当前所有可用的魔术命令，请运行 `%lsmagic`，并运行 `%magic` 获取详细说明。
- en: Even if you use the magic command `%matplotlib notebook`, you will probably
    notice that Matplotlib was originally designed for static plots rather than for
    an interactive experience on a web page. That’s why we’re going to use Plotly
    next, a plotting library designed for the web.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 即使使用 `%matplotlib notebook` 魔术命令，你可能会注意到 Matplotlib 最初设计用于静态绘图，而不是在网页上进行交互体验。这就是为什么接下来我们将使用
    Plotly，这是一个专为 Web 设计的绘图库。
- en: Plotly
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: Plotly
- en: 'Plotly is a JavaScript-based library and can—since version 4.8.0—be used as
    a pandas plotting backend with great interactivity: you can easily zoom in, click
    on the legend to select or deselect a category, and get tooltips with more info
    about the data point you’re hovering over. Plotly is not included in the Anaconda
    installation, so if you haven’t installed it yet, do so now by running the following
    command:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: Plotly 是基于 JavaScript 的库，自版本 4.8.0 起，可以作为 pandas 的绘图后端，具有出色的交互性：你可以轻松缩放，单击图例以选择或取消选择类别，并获取有关悬停数据点的更多信息。Plotly
    不包含在 Anaconda 安装中，因此如果尚未安装，请通过运行以下命令安装：
- en: '`(base)>` `conda install plotly`'
  id: totrans-418
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`(base)>` `conda install plotly`'
- en: 'Once you run the following cell, the plotting backend of the whole notebook
    will be set to Plotly and if you would rerun the previous cell, it would also
    be rendered as a Plotly chart. For Plotly, instead of running a magic command,
    you just need to set it as backend before being able to plot Figures [5-5](#filepos731078)
    and [5-6](#filepos732496):'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此单元格后，整个笔记本的绘图后端将设置为 Plotly，如果重新运行之前的单元格，它也将呈现为 Plotly 图表。对于 Plotly，你只需在能够绘制
    [5-5](#filepos731078) 和 [5-6](#filepos732496) 图形之前将其设置为后端：
- en: '`In``[``97``]:``# Set the plotting backend to Plotly``pd``.``options``.``plotting``.``backend``=``"plotly"`'
  id: totrans-420
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``97``]:``# 将绘图后端设置为 Plotly``pd``.``options``.``plotting``.``backend``=``"plotly"`'
- en: '`In``[``98``]:``data``.``plot``()`'
  id: totrans-421
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``98``]:``data``.``plot``()``'
- en: '![](images/00016.jpg)'
  id: totrans-422
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00016.jpg)'
- en: Figure 5-5\. Plotly line plot
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-5\. Plotly 折线图
- en: '`In``[``99``]:``# Display the same data as bar plot``data``.``plot``.``bar``(``barmode``=``"group"``)`'
  id: totrans-424
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``99``]:``# 显示相同数据的条形图``data``.``plot``.``bar``(``barmode``=``"group"``)`'
- en: '![](images/00021.jpg)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00021.jpg)'
- en: Figure 5-6\. Plotly bar plot
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-6\. Plotly 条形图
- en: DIFFERENCES IN PLOTTING BACKENDS
  id: totrans-427
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 绘图后端的差异
- en: If you use Plotly as plotting backend, you’ll need to check the accepted arguments
    of the plot methods directly on the Plotly docs. For example, you can take a look
    at the `barmode=group` argument in [Plotly’s bar charts documentation](https://oreil.ly/Ekurd).
  id: totrans-428
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果您使用 Plotly 作为绘图后端，您需要直接在 Plotly 文档中检查绘图方法的接受参数。例如，您可以查看 [Plotly 条形图文档](https://oreil.ly/Ekurd)
    中的 `barmode=group` 参数。
- en: pandas and the underlying plotting libraries offer a wealth of chart types and
    options to format the charts in almost any desired way. It’s also possible to
    arrange multiple plots into a series of subplots. As an overview, [Table 5-6](#filepos733705)
    shows the available plot types.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 和底层绘图库提供了丰富的图表类型和选项，可以以几乎任何期望的方式格式化图表。也可以将多个图表安排到子图系列中。总览见 [表 5-6](#filepos733705)
    显示了可用的绘图类型。
- en: Table 5-6\. pandas plot types
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-6\. pandas 绘图类型
- en: '|  Type  |  Description  |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '|  类型  |  描述  |'
- en: '|   `line` |  Line Chart, default when running  `df.plot()` |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '|   `line` |  线性图表，默认运行 `df.plot()` 时的默认设置 |'
- en: '|   `bar` |  Vertical bar chart  |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '|   `bar` |  垂直条形图  |'
- en: '|   `barh` |  Horizontal bar chart  |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '|   `barh` |  水平条形图  |'
- en: '|   `hist` |  Histogram  |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '|   `hist` |  直方图  |'
- en: '|   `box` |  Box plot  |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '|   `box` |  箱线图  |'
- en: '|   `kde` |  Density plot, can also be used via  `density` |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '|   `kde` |  密度图，也可以通过 `density` 使用 |'
- en: '|   `area` |  Area chart  |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '|   `area` |  面积图  |'
- en: '|   `scatter` |  Scatter plot  |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '|   `scatter` |  散点图  |'
- en: '|   `hexbin` |  Hexagonal bin plots  |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '|   `hexbin` |  六角形箱形图  |'
- en: '|   `pie` |  Pie chart  |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '|   `pie` |  饼图  |'
- en: On top of that, pandas offers some higher-level plotting tools and techniques
    that are made up of multiple individual components. For details, see the [pandas
    visualization documentation](https://oreil.ly/FxYg9).
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，pandas 还提供了一些由多个独立组件组成的高级绘图工具和技术。详情请见 [pandas 可视化文档](https://oreil.ly/FxYg9)。
- en: OTHER PLOTTING LIBRARIES
  id: totrans-443
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 其他绘图库
- en: 'The scientific visualization landscape in Python is very active, and besides
    Matplotlib and Plotly, there are many other high-quality options to choose from
    that may be the better option for certain use cases:'
  id: totrans-444
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Python 的科学可视化领域非常活跃，除了 Matplotlib 和 Plotly 外，还有许多其他高质量的选择，可能更适合特定用例：
- en: Seaborn
  id: totrans-445
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Seaborn
- en: '[Seaborn](https://oreil.ly/a3U1t) is built on top of Matplotlib. It improves
    the default style and adds additional plots like heatmaps, which often simplify
    your work: you can create advanced statistical plots with only a few lines of
    code.'
  id: totrans-446
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Seaborn](https://oreil.ly/a3U1t) 建立在 Matplotlib 之上。它改进了默认样式，并添加了额外的绘图，如热图，通常简化了您的工作：您可以仅使用几行代码创建高级统计图。'
- en: Bokeh
  id: totrans-447
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Bokeh
- en: '[Bokeh](https://docs.bokeh.org) is similar to Plotly in technology and functionality:
    it’s based on JavaScript and therefore also works great for interactive charts
    in Jupyter notebooks. Bokeh is included in Anaconda.'
  id: totrans-448
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Bokeh](https://docs.bokeh.org) 类似于 Plotly 在技术和功能上：它基于 JavaScript，因此在 Jupyter
    笔记本中也非常适合交互式图表。Bokeh 包含在 Anaconda 中。'
- en: Altair
  id: totrans-449
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Altair
- en: '[Altair](https://oreil.ly/t06t7) is a library for statistical visualizations
    based on the [Vega project](https://oreil.ly/RN6A7). Altair is also JavaScript-based
    and offers some interactivity like zooming.'
  id: totrans-450
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Altair](https://oreil.ly/t06t7) 是一个基于 [Vega 项目](https://oreil.ly/RN6A7) 的统计可视化库。Altair
    也是基于 JavaScript 的，提供一些像缩放这样的交互功能。'
- en: HoloViews
  id: totrans-451
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: HoloViews
- en: '[HoloViews](https://holoviews.org) is another JavaScript-based package that
    focuses on making data analysis and visualization easy. With a few lines of code,
    you can achieve complex statistical plots.'
  id: totrans-452
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[HoloViews](https://holoviews.org) 是另一个基于 JavaScript 的包，专注于使数据分析和可视化变得简单。只需几行代码，您就可以实现复杂的统计图。'
- en: We will create more plots in the next chapter to analyze time series, but before
    we get there, let’s wrap this chapter up by learning how we can import and export
    data with pandas!
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章节创建更多的图表来分析时间序列，但在此之前，让我们通过学习如何使用 pandas 导入和导出数据来结束本章节！
- en: Importing and Exporting DataFrames
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 导入和导出数据帧
- en: So far, we constructed DataFrames from scratch using nested lists, dictionaries,
    or NumPy arrays. These techniques are important to know, but typically, the data
    is already available and you simply need to turn it into a DataFrame. To do this,
    pandas offers various reader functions. But even if you need to access a proprietary
    system for which pandas doesn’t offer a built-in reader, you often have a Python
    package to connect to that system, and once you have the data, it’s easy enough
    to turn it into a DataFrame. In Excel, data import is the type of work you would
    usually handle with Power Query.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用嵌套列表、字典或NumPy数组从头构建了 DataFrame。了解这些技术很重要，但通常数据已经可用，您只需将其转换为 DataFrame。为此，pandas
    提供了各种读取函数。但即使您需要访问 pandas 不提供内置读取器的专有系统，您通常也可以使用 Python 包连接到该系统，一旦获取数据，将其转换为 DataFrame
    就很容易。在 Excel 中，数据导入通常是使用 Power Query 处理的工作类型。
- en: After analyzing and changing your dataset, you might want to push the results
    back into a database or export it to a CSV file or—given the title of the book—present
    it in an Excel workbook to your manager. To export pandas DataFrames, use one
    of the exporter methods that DataFrames offer. [Table 5-7](#filepos741567) shows
    an overview of the most common import and export methods.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 分析和更改数据集后，您可能希望将结果推回数据库或将其导出为 CSV 文件或者——考虑到本书的标题——将其呈现在 Excel 工作簿中供您的经理查看。要导出
    pandas DataFrame，请使用DataFrame提供的导出器方法之一。[表格 5-7](#filepos741567)显示了最常见的导入和导出方法概述。
- en: Table 5-7\. Importing and exporting DataFrames
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 5-7\. 导入和导出数据框
- en: '|  Data format/system  |  Import: pandas (pd) function  |  Export: DataFrame
    (df) method  |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '|  数据格式/系统  |  导入：pandas（pd）函数  |  导出：DataFrame（df）方法  |'
- en: '|  CSV files  |   `pd.read_csv` |   `df.to_csv` |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '|  CSV 文件  |   `pd.read_csv` |   `df.to_csv` |'
- en: '|  JSON  |   `pd.read_json` |   `df.to_json` |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '|  JSON  |   `pd.read_json` |   `df.to_json` |'
- en: '|  HTML  |   `pd.read_html` |   `df.to_html` |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '|  HTML  |   `pd.read_html` |   `df.to_html` |'
- en: '|  Clipboard  |   `pd.read_clipboard` |   `df.to_clipboard` |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '|  剪贴板  |   `pd.read_clipboard` |   `df.to_clipboard` |'
- en: '|  Excel files  |   `pd.read_excel` |   `df.to_excel` |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '|  Excel 文件  |   `pd.read_excel` |   `df.to_excel` |'
- en: '|  SQL Databases  |   `pd.read_sql` |   `df.to_sql` |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '|  SQL 数据库  |   `pd.read_sql` |   `df.to_sql` |'
- en: We will meet `pd.read_sql` and `pd.to_sql` in [Chapter 11](index_split_027.html#filepos1487255),
    where we will use them as part of a case study. And since I am going to dedicate
    the whole of [Chapter 7](index_split_019.html#filepos863345) to the topic of reading
    and writing Excel files with pandas, I will focus on importing and exporting CSV
    files in this section. Let’s start with exporting an existing DataFrame!
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第 11 章](index_split_027.html#filepos1487255)中遇到 `pd.read_sql` 和 `pd.to_sql`，在那里我们将把它们作为案例研究的一部分使用。并且由于我打算在整个[第
    7 章](index_split_019.html#filepos863345)中专门讨论使用 pandas 读取和写入 Excel 文件的主题，因此在本节中我将重点讨论导入和导出
    CSV 文件。让我们从导出现有的 DataFrame 开始！
- en: Exporting CSV Files
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 导出 CSV 文件
- en: 'If you need to pass a DataFrame to a colleague who might not use Python or
    pandas, passing it in the form of a CSV file is usually a good idea: pretty much
    every program knows how to import them. To export our sample DataFrame `df` to
    a CSV file, use the `to_csv` method:'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要将 DataFrame 传递给可能不使用 Python 或 pandas 的同事，以 CSV 文件的形式传递通常是个好主意：几乎每个程序都知道如何导入它们。要将我们的示例
    DataFrame `df` 导出到 CSV 文件，使用 `to_csv` 方法：
- en: '`In``[``100``]:``df``.``to_csv``(``"course_participants.csv"``)`'
  id: totrans-468
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``100``]:``df``.``to_csv``(``"course_participants.csv"``)`'
- en: If you wanted to store the file in a different directory, supply the full path
    as a raw string, e.g., `r"C:\path\to\desired\location\msft.csv"`.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想将文件存储在不同的目录中，请提供完整路径作为原始字符串，例如，`r"C:\path\to\desired\location\msft.csv"`。
- en: USE RAW STRINGS FOR FILE PATHS ON WINDOWS
  id: totrans-470
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在 Windows 上使用原始字符串处理文件路径
- en: In strings, the backslash is used to escape certain characters. That’s why to
    work with file paths on Windows, you either need to use double backslashes (`C:\\path\\to\\file.csv`)
    or prefix the string with an `r` to turn it into a raw string that interprets
    the characters literally. This isn’t an issue on macOS or Linux, as they use forward
    slashes in paths.
  id: totrans-471
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在字符串中，反斜杠用于转义某些字符。这就是为什么在 Windows 上处理文件路径时，您需要使用双反斜杠（`C:\\path\\to\\file.csv`）或在字符串前加上`r`来将其转换为原始字符串，以字面上解释字符。这在
    macOS 或 Linux 上不是问题，因为它们在路径中使用正斜杠。
- en: 'By providing only the file name as I do, it will produce the file course_participants.csv
    in the same directory as the notebook with the following content:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仅提供文件名如我所做的那样，它将在与笔记本相同的目录中生成文件`course_participants.csv`，内容如下：
- en: '`user_id,name,age,country,score,continent 1001,Mark,55,Italy,4.5,Europe 1000,John,33,USA,6.7,America
    1002,Tim,41,USA,3.9,America 1003,Jenny,12,Germany,9.0,Europe`'
  id: totrans-473
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`user_id,name,age,country,score,continent 1001,Mark,55,Italy,4.5,Europe 1000,John,33,USA,6.7,America
    1002,Tim,41,USA,3.9,America 1003,Jenny,12,Germany,9.0,Europe`'
- en: Now that you know how to use the `df.to_csv` method, let’s see how importing
    a CSV file works!
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解如何使用`df.to_csv`方法，让我们看看如何导入 CSV 文件！
- en: Importing CSV Files
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 CSV 文件
- en: 'Importing a local CSV file is as easy as providing its path to the `read_csv`
    function. MSFT.csv is a CSV file that I downloaded from Yahoo! Finance and it
    contains the daily historical stock prices for Microsoft—you’ll find it in the
    companion repository, in the csv folder:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 导入本地 CSV 文件就像将其路径提供给`read_csv`函数一样简单。MSFT.csv 是我从 Yahoo! Finance 下载的 CSV 文件，包含了微软的日常历史股价
    —— 你可以在伴随的存储库中的 csv 文件夹找到它：
- en: '`In``[``101``]:``msft``=``pd``.``read_csv``(``"csv/MSFT.csv"``)`'
  id: totrans-477
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``101``]:``msft``=``pd``.``read_csv``(``"csv/MSFT.csv"``)`'
- en: Often, you will need to supply a few more parameters to `read_csv` than just
    the file name. For example, `sep` allows you to tell pandas what separator or
    delimiter the CSV file uses in case it isn’t the default comma. We will use a
    few more parameters in the next chapter, but for the full overview, have a look
    at the [pandas documentation](https://oreil.ly/2GMhW).
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 经常需要向`read_csv`提供比仅文件名更多的参数。例如，`sep`参数允许您告诉 pandas CSV 文件使用的分隔符或分隔符，以防它不是默认的逗号。在下一章中，我们将使用更多的参数，但是为了全面了解，请查看[pandas文档](https://oreil.ly/2GMhW)。
- en: 'Now that we are dealing with big DataFrames with many thousands of rows, typically
    the first thing is to run the `info` method to get a summary of the DataFrame.
    Next, you may want to take a peek at the first and last few rows of the DataFrame
    using the `head` and `tail` methods. These methods return five rows by default,
    but this can be changed by providing the desired number of rows as an argument.
    You can also run the `describe` method to get some basic statistics:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们正在处理具有数千行的大型 DataFrame，通常第一步是运行`info`方法以获取 DataFrame 的摘要信息。接下来，您可能希望使用`head`和`tail`方法查看
    DataFrame 的前几行和最后几行。这些方法默认返回五行，但可以通过提供所需行数作为参数来更改。您还可以运行`describe`方法获取一些基本统计信息：
- en: '`In``[``102``]:``msft``.``info``()`'
  id: totrans-480
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``102``]:``msft``.``info``()`'
- en: '`<class ''pandas.core.frame.DataFrame''> RangeIndex: 8622 entries, 0 to 8621
    Data columns (total 7 columns): #   Column     Non-Null Count  Dtype ---  ------    
    --------------  ----- 0   Date       8622 non-null   object 1   Open       8622
    non-null   float64 2   High       8622 non-null   float64 3   Low        8622
    non-null   float64 4   Close      8622 non-null   float64 5   Adj Close  8622
    non-null   float64 6   Volume     8622 non-null   int64 dtypes: float64(5), int64(1),
    object(1) memory usage: 471.6+ KB`'
  id: totrans-481
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`<class ''pandas.core.frame.DataFrame''> RangeIndex: 8622 entries, 0 to 8621
    Data columns (total 7 columns): #   Column     Non-Null Count  Dtype ---  ------    
    --------------  ----- 0   Date       8622 non-null   object 1   Open       8622
    non-null   float64 2   High       8622 non-null   float64 3   Low        8622
    non-null   float64 4   Close      8622 non-null   float64 5   Adj Close  8622
    non-null   float64 6   Volume     8622 non-null   int64 dtypes: float64(5), int64(1),
    object(1) memory usage: 471.6+ KB`'
- en: '`In``[``103``]:``# I am selecting a few columns because of space issues``#
    You can also just run: msft.head()``msft``.``loc``[:,``[``"Date"``,``"Adj Close"``,``"Volume"``]]``.``head``()`'
  id: totrans-482
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``103``]:``# 由于空间问题，我只选择了几列``# 您也可以直接运行：msft.head()``msft``.``loc``[:,``[``"Date"``,``"Adj
    Close"``,``"Volume"``]]``.``head``()`'
- en: '`Out[103]:          Date  Adj Close      Volume           0  1986-03-13   0.062205 
    1031788800           1  1986-03-14   0.064427   308160000           2  1986-03-17  
    0.065537   133171200           3  1986-03-18   0.063871    67766400          
    4  1986-03-19   0.062760    47894400`'
  id: totrans-483
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[103]:          Date  Adj Close      Volume           0  1986-03-13   0.062205 
    1031788800           1  1986-03-14   0.064427   308160000           2  1986-03-17  
    0.065537   133171200           3  1986-03-18   0.063871    67766400          
    4  1986-03-19   0.062760    47894400`'
- en: '`In``[``104``]:``msft``.``loc``[:,``[``"Date"``,``"Adj Close"``,``"Volume"``]]``.``tail``(``2``)`'
  id: totrans-484
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``104``]:``msft``.``loc``[:,``[``"Date"``,``"Adj Close"``,``"Volume"``]]``.``tail``(``2``)`'
- en: '`Out[104]:             Date   Adj Close    Volume           8620  2020-05-26 
    181.570007  36073600           8621  2020-05-27  181.809998  39492600`'
  id: totrans-485
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[104]:             Date   Adj Close    Volume           8620  2020-05-26 
    181.570007  36073600           8621  2020-05-27  181.809998  39492600`'
- en: '`In``[``105``]:``msft``.``loc``[:,``[``"Adj Close"``,``"Volume"``]]``.``describe``()`'
  id: totrans-486
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``105``]:``msft``.``loc``[:,``[``"Adj Close"``,``"Volume"``]]``.``describe``()`'
- en: '`Out[105]:          Adj Close        Volume           count  8622.000000  8.622000e+03
              mean     24.921952  6.030722e+07           std      31.838096  3.877805e+07
              min       0.057762  2.304000e+06           25%       2.247503  3.651632e+07
              50%      18.454313  5.350380e+07           75%      25.699224  7.397560e+07
              max     187.663330  1.031789e+09`'
  id: totrans-487
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[105]:          Adj Close        Volume           count  8622.000000  8.622000e+03
              mean     24.921952  6.030722e+07           std      31.838096  3.877805e+07
              min       0.057762  2.304000e+06           25%       2.247503  3.651632e+07
              50%      18.454313  5.350380e+07           75%      25.699224  7.397560e+07
              max     187.663330  1.031789e+09`'
- en: '`Adj Close` stands for adjusted close price and corrects the stock price for
    corporate actions such as stock splits. `Volume` is the number of stocks that
    were traded. I have summarized the various DataFrame exploration methods we’ve
    seen in this chapter in [Table 5-8](#filepos758607).'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '`Adj Close` 代表调整后的收盘价格，校正了股票价格如股票拆分等公司行动。 `Volume` 是交易的股票数量。我总结了本章中看到的各种 DataFrame
    探索方法在 [表 5-8](#filepos758607) 中。'
- en: Table 5-8\. DataFrame exploration methods and attributes
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 5-8\. DataFrame 探索方法和属性
- en: '|  DataFrame (df) Method/Attribute  |  Description  |'
  id: totrans-490
  prefs: []
  type: TYPE_TB
  zh: '|  DataFrame（df）方法/属性  |  描述  |'
- en: '|   `df.info()` |  Provides number of data points, index type, dtype, and memory
    usage.  |'
  id: totrans-491
  prefs: []
  type: TYPE_TB
  zh: '|   `df.info()` |  提供数据点数量、索引类型、数据类型和内存使用情况。  |'
- en: '|   `df.describe()` |  Provides basic statistics including count, mean, std,
    min, max, and percentiles.  |'
  id: totrans-492
  prefs: []
  type: TYPE_TB
  zh: '|   `df.describe()` |  提供基本统计信息，包括计数、均值、标准差、最小值、最大值和百分位数。  |'
- en: '|   `df.head(n=5)` |  Returns the first  n rows of the DataFrame. |'
  id: totrans-493
  prefs: []
  type: TYPE_TB
  zh: '|   `df.head(n=5)` |  返回DataFrame的前  n 行。 |'
- en: '|   `df.tail(n=5)` |  Returns the last  n rows of the DataFrame. |'
  id: totrans-494
  prefs: []
  type: TYPE_TB
  zh: '|   `df.tail(n=5)` |  返回DataFrame的最后  n 行。 |'
- en: '|   `df.dtypes` |  Returns the dtype of each column.  |'
  id: totrans-495
  prefs: []
  type: TYPE_TB
  zh: '|   `df.dtypes` |  返回每列的数据类型。  |'
- en: 'The `read_csv` function also accepts a URL instead of a local CSV file. This
    is how you read the CSV file directly from the companion repo:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_csv` 函数还可以接受 URL 而不是本地 CSV 文件。以下是直接从配套仓库读取 CSV 文件的方法：'
- en: '`In``[``106``]:``# The line break in the URL is only to make it fit on the
    page``url``=``(``"https://raw.githubusercontent.com/fzumstein/"``"python-for-excel/1st-edition/csv/MSFT.csv"``)``msft``=``pd``.``read_csv``(``url``)`'
  id: totrans-497
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``106``]:``# URL 中的换行符仅是为了使其适合页面``url``=``(``"https://raw.githubusercontent.com/fzumstein/"``"python-for-excel/1st-edition/csv/MSFT.csv"``)``msft``=``pd``.``read_csv``(``url``)`'
- en: '`In``[``107``]:``msft``.``loc``[:,``[``"Date"``,``"Adj Close"``,``"Volume"``]]``.``head``(``2``)`'
  id: totrans-498
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``107``]:``msft``.``loc``[:,``[``"Date"``,``"Adj Close"``,``"Volume"``]]``.``head``(``2``)`'
- en: '`Out[107]:          Date  Adj Close      Volume           0  1986-03-13   0.062205 
    1031788800           1  1986-03-14   0.064427   308160000`'
  id: totrans-499
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[107]:          Date  Adj Close      Volume           0  1986-03-13   0.062205 
    1031788800           1  1986-03-14   0.064427   308160000`'
- en: We’ll continue with this dataset and the `read_csv` function in the next chapter
    about time series, where we will turn the `Date` column into a `DatetimeIndex`.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章关于时间序列的章节中，我们将继续使用此数据集和 `read_csv` 函数，将 `Date` 列转换为 `DatetimeIndex`。
- en: Conclusion
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 结论
- en: 'This chapter was packed with new concepts and tools to analyze datasets in
    pandas. We learned how to load CSV files, how to deal with missing or duplicate
    data, and how to make use of descriptive statistics. We also saw how easy it is
    to turn your DataFrames into interactive plots. While it may take a while to digest
    everything, it probably won’t take long before you will understand the immense
    power you are gaining by adding pandas to your tool belt. Along the way, we compared
    pandas to the following Excel functionality:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 本章充满了分析 pandas 数据集的新概念和工具。我们学会了如何加载 CSV 文件，如何处理缺失或重复数据，以及如何利用描述性统计信息。我们还看到了如何将
    DataFrame 转换为交互式图表。虽然消化这些内容可能需要一些时间，但加入 pandas 工具箱后，您将很快理解其强大之处。在此过程中，我们将 pandas
    与以下 Excel 功能进行了比较：
- en: AutoFilter functionality
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 自动筛选功能
- en: See [“Selecting by boolean indexing”](index_split_015.html#filepos549613).
  id: totrans-504
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 参见 [“通过布尔索引进行选择”](index_split_015.html#filepos549613)。
- en: VLOOKUP formula
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: VLOOKUP 公式
- en: See [“Joining and Merging”](#filepos667627).
  id: totrans-506
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 参见 [“连接和合并”](#filepos667627)。
- en: Pivot Table
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 数据透视表
- en: See [“Pivoting and Melting”](#filepos701398).
  id: totrans-508
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 参见 [“数据透视和融合”](#filepos701398)。
- en: Power Query
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: Power Query
- en: This is a combination of [“Importing and Exporting DataFrames”](#filepos740294),
    [“Data Manipulation”](index_split_015.html#filepos524268), and [“Combining DataFrames”](#filepos652519).
  id: totrans-510
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是 [“导入和导出数据框”](#filepos740294)、[“数据操作”](index_split_015.html#filepos524268)
    和 [“合并数据框”](#filepos652519) 的结合。
- en: The next chapter is about time series analysis, the functionality that led to
    broad adoption of pandas by the financial industry. Let’s see why this part of
    pandas has such an edge over Excel!
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章讲述的是时间序列分析，这一功能使得 pandas 在金融行业广泛应用。让我们看看为什么 pandas 的这一部分比 Excel 更具优势！
- en: '[1  ](index_split_015.html#filepos498666) pandas 1.0.0 introduced a dedicated
    `string` data type to make some operations easier and more consistent with text.
    As it is still experimental, I am not going to make use of it in this book.'
  id: totrans-512
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[1  ](index_split_015.html#filepos498666) pandas 1.0.0 引入了专门的`string`数据类型，以使某些操作更容易且与文本更一致。由于它仍处于实验阶段，我在本书中不打算使用它。'
