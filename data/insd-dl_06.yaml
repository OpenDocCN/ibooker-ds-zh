- en: 5 Modern training techniques
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 现代训练技术
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Improving long-term training using a learning rate schedule
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用学习率调度改进长期训练
- en: Improving short-term training using optimizers
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用优化器改进短期训练
- en: Combining learning rate schedules and optimizers to improve any deep model’s
    results
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合学习率调度和优化器来提高任何深度模型的结果
- en: Tuning network hyperparameters with Optuna
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Optuna调整网络超参数
- en: 'At this point, we have learned the basics of neural networks and three types
    of architectures: fully connected, convolutional, and recurrent. These networks
    have been trained with an approach called stochastic gradient descent (SGD), which
    has been in use since at least the 1960s. Newer improvements to learning the parameters
    of our network have been invented since then, like momentum and learning rate
    decay, which can improve *any neural network for any problem* by converging to
    better solutions in fewer updates. In this chapter, we learn about some of the
    most successful and widely used variants of SGD in deep learning.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了神经网络的基础知识以及三种类型的架构：全连接、卷积和循环。这些网络使用一种称为随机梯度下降（SGD）的方法进行训练，这种方法自20世纪60年代以来一直被使用。自那时以来，已经发明了新的改进方法来学习我们网络的参数，如动量和学习率衰减，这些方法可以通过在更少的更新中收敛到更好的解决方案来提高**任何问题**的**任何神经网络**。在本章中，我们将了解深度学习中一些最成功和最广泛使用的SGD变体。
- en: Because there are no constraints on a neural network, they often end up with
    complex optimization problems with many local minima, as shown figure 5.1\. The
    minima appear to reduce the loss by the most possible, which would mean our model
    has learned, but the global context reveals that other minima may be better. Not
    all local minima are “bad”; if a minimum is sufficiently close to the global minimum,
    we will probably get good results. But some local minima are just not going to
    give us a model with the predictive accuracy we want. Because gradient descent
    makes its decisions “locally,” once we hit a local minimum, we have no idea how
    “good” that minimum is or which direction to head if we want to try to find a
    new one.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 因为神经网络没有约束，它们往往最终会陷入具有许多局部最小值的复杂优化问题，如图5.1所示。这些最小值似乎通过尽可能多的减少损失来实现，这意味着我们的模型已经学习到了，但全局上下文表明其他最小值可能更好。并非所有局部最小值都是“坏的”；如果一个最小值足够接近全局最小值，我们可能会得到好的结果。但有些局部最小值根本无法给我们提供我们想要的预测准确性的模型。因为梯度下降是“局部”做出决定的，一旦我们达到局部最小值，我们就不知道这个最小值有多“好”，或者如果我们想要尝试找到一个新的最小值，我们应该朝哪个方向前进。
- en: '![](../Images/CH05_F01_Raff.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F01_Raff.png)'
- en: Figure 5.1 Example of a loss landscape that a neural network might encounter.
    The loss on the y-axis is what we want to minimize, but there are many local minima.
    There is one global minima that is the best solution, with two local minima that
    are almost as good—and one bad minima that will not work well.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 神经网络可能遇到的损失景观示例。y轴上的损失是我们想要最小化的，但有许多局部最小值。有一个全局最小值是最佳解决方案，有两个局部最小值几乎一样好——还有一个坏的最小值，它将不起作用。
- en: In this chapter, we learn about *learning rate schedules* and *optimizers* that
    can help us reach better minima faster, resulting in neural networks that reach
    higher accuracies in fewer epochs. Again, this applies to *every* network you
    will ever train and are ubiquitous in modern designs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了**学习率调度**和**优化器**，这些可以帮助我们更快地达到更好的最小值，从而使得神经网络在更少的epoch中达到更高的准确性。同样，这适用于**你将训练的每一个网络**，并且在现代设计中无处不在。
- en: 'To do this, we do a quick review of gradient descent and see how it can be
    broken up into two parts: the gradient and the learning rate *schedule*. PyTorch
    has special classes for both of these, so we write a new `train_network` function
    that will replace the `train_simple_network` function we have seen through the
    book that incorporates both of these abstractions. These new abstractions will
    be covered in section 5.1\. Then we start filling in the details of these abstractions
    and how they work, first with the learning rate schedule in section 5.2 followed
    by gradient update strategies in section 5.3.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们快速回顾一下梯度下降，看看它如何可以被分成两部分：梯度和学习率**调度**。PyTorch为这两者都提供了特殊的类，因此我们编写了一个新的`train_network`函数，将我们通过书籍看到的`train_simple_network`函数替换掉，该函数结合了这两个抽象。这些新的抽象将在5.1节中介绍。然后我们开始填充这些抽象的细节以及它们是如何工作的，首先是学习率调度在5.2节中，然后是梯度更新策略在5.3节中。
- en: There is a *second* optimization problem we have been ignoring, which is how
    to choose all these hyperparameters like the number of layers, the number of neurons
    in each layer, and so on. In section 5.4, we are going to learn about how to select
    hyperparameters using a tool called Optuna. Optuna has special features that make
    it great at setting hyperparameters even when we have a lot of them and to avoid
    the full cost of training many different networks to try the parameters.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还忽略了一个**第二个**优化问题，那就是如何选择所有这些超参数，比如层数、每层的神经元数量等等。在第 5.4 节中，我们将学习如何使用一个名为 Optuna
    的工具来选择超参数。Optuna 具有特殊功能，使其在拥有许多超参数时设置超参数变得非常出色，并且避免了训练许多不同网络以尝试参数的完整成本。
- en: This chapter is a bit longer because we explain why these newer techniques for
    using gradients reduce the number of epochs you need to get a good solution, where
    many other materials just jump right to using these improved methods. This is
    also important because researchers are constantly working on improved strategies,
    and the extra work we do to go from the original SGD to modern approaches will
    help you appreciate the potential for future improvements and to reason about
    why they may be helping. The Optuna section in particular may seem odd because
    we will not use this topic in other chapters, as it can get in the way of learning
    about other techniques. But Optuna and its approach to tuning hyperparameters
    is a critical real-world skill in deep learning that will help keep you productive
    and building more accurate solutions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章篇幅略长，因为我们解释了为什么这些使用梯度的较新技术可以减少获得良好解决方案所需的迭代次数，而许多其他资料则直接跳到使用这些改进方法。这一点也很重要，因为研究人员一直在努力改进策略，而我们从原始的随机梯度下降（SGD）到现代方法的额外努力将帮助你欣赏未来改进的潜力，并理解为什么它们可能有所帮助。特别是
    Optuna 部分，可能会显得有些奇怪，因为我们不会在其他章节中使用这个主题，因为它可能会妨碍学习其他技术。但 Optuna 及其调整超参数的方法是深度学习中的一个关键实际技能，这将帮助你保持高效并构建更精确的解决方案。
- en: 5.1 Gradient descent in two parts
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 两部分的梯度下降
- en: So far, we have been using and thinking about learning via gradient descent
    as one monolithic equation and process. We pick a loss function ℓ and a network
    architecture f, and gradient descent just goes and updates the weights. Because
    we want to improve how gradient descent works, we first need to recognize and
    understand its two components. By recognizing that these two components have different
    behaviors, we can develop strategies for improving each one to get our networks
    to learn more accurate solutions in fewer epochs. Let’s start with a quick review
    of how gradient descent works.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直将学习通过梯度下降视为一个单一的方程和过程。我们选择一个损失函数 ℓ 和一个网络架构 f，然后梯度下降就更新权重。因为我们想改进梯度下降的工作方式，我们首先需要识别和理解它的两个组成部分。通过认识到这两个组成部分具有不同的行为，我们可以制定策略来改进每一个，以便我们的网络在更少的迭代次数中学习更精确的解决方案。让我们先快速回顾一下梯度下降是如何工作的。
- en: Remember that everything we do in deep learning works by treating the network
    as one giant function *f*[Θ](**x**), where we need to use the gradient (∇) with
    respect to the parameters (Θ) of f to adjust its weights. So we perform
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们在深度学习中所做的一切都是通过将网络视为一个巨大的函数 *f*[Θ](**x**) 来实现的，我们需要使用相对于 f 的参数 (Θ) 的梯度
    (∇) 来调整其权重。因此，我们执行
- en: '![](../Images/ch5-eqs-to-illustrator0x.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![梯度下降示意图](../Images/ch5-eqs-to-illustrator0x.png)'
- en: This is called *gradient descent* and is the basis for how all modern training
    of neural networks is done. However, there is room for significant improvement
    in how we perform this critical step. We use **g**^t as shorthand for the gradient
    since we talk about it a *lot* in this section. Notice that we included this ^t
    superscript as if it was part of a sequence. That’s because when we learn, we
    get a new gradient for every batch of data we process, so our model is learning
    from a sequence of gradients. We use this to our advantage later.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为**梯度下降**，是所有现代神经网络训练的基础。然而，我们在如何执行这个关键步骤方面还有很大的改进空间。我们用 **g**^t 作为梯度的简写，因为我们在这个部分中经常提到它。请注意，我们像它是一个序列的一部分那样包含了这个
    ^t 上标。这是因为当我们学习时，我们为处理的数据的每一批都得到一个新的梯度，因此我们的模型是从一系列梯度中学习的。我们将在后面利用这一点。
- en: 'With this shorthand, it becomes clearer that there are just two parts to this
    process: the gradient **g**^t and the learning rate η, as we can see here. Those
    are the only two parts we can alter to try to improve this:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种简写，可以更清楚地看出这个过程只有两个部分：梯度 **g**^t 和学习率 η，正如我们在这里所看到的。我们只能改变这两个部分来尝试改进：
- en: '![](../Images/CH05_UN01_Raff.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_UN01_Raff.png)'
- en: 5.1.1  Adding a learning rate schedule
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1  添加学习率调度器
- en: Let’s discuss the problems with the earlier update equation. First, there is
    an issue with the learning rate η. We choose *one* learning rate for *every batch
    of every epoch of training*. This can be an unreasonable expectation. Consider,
    as an analogy, a train traveling from one city to another. The train does not
    travel *full speed* and then instantaneously come to a stop once it reaches the
    destination. Instead, the train slows down as it approaches the destination. Otherwise,
    the train would go barreling past the destination.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论早期更新方程的问题。首先，存在一个关于学习率 η 的问题。我们为 *每个epoch的训练中的每个批次* 选择 *一个* 学习率。这可能是一个不合理的期望。以一个类比来说明，想象一辆火车从一个城市开往另一个城市。火车不会以全速行驶，然后到达目的地后立即停下来。相反，火车在接近目的地时会减速。否则，火车会呼啸而过目的地。
- en: 'So, the first type of improvement we can discuss is to alter the learning rate
    η as a function of how far along we are in the optimization process (t). Let’s
    call this function L and give it an *initial* learning rate *η*[0] and the current
    iteration step t as inputs:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以讨论的第一种改进类型是将学习率 η 作为优化过程中我们进展程度的函数来调整（t）。让我们称这个函数为 L，并给它一个 *初始* 学习率 *η*[0]
    和当前的迭代步骤 t 作为输入：
- en: '![](../Images/ch5-eqs-to-illustrator1x.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/ch5-eqs-to-illustrator1x.png)'
- en: We review the details of how we define *L*(*η*[0],*t*) shortly. Right now, the
    important thing is to understand that we have created an abstraction for altering
    the learning rate, and this abstraction is called a *learning rate schedule*.
    We can use this to replace L with different schedules based on our needs or problem.
    Before we start showing this with code, we need to discuss a second part of the
    update equation that is tightly coupled with the learning rate schedule *L*(⋅,⋅)
    in PyTorch.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快会回顾如何定义 *L*(*η*[0],*t*) 的细节。现在，重要的是要理解我们已经创建了一个用于调整学习率的抽象，这个抽象被称为 *学习率调度器*。我们可以根据需要或问题使用这个调度器来替换
    L。在我们用代码展示这个功能之前，我们需要讨论更新方程的第二个部分，它与 PyTorch 中的学习率调度器 *L*(⋅,⋅) 密切相关。
- en: 5.1.2  Adding an optimizer
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2  添加优化器
- en: This part does not have a satisfying name; PyTorch calls it the optimizer, but
    that also describes the process as a whole. Still, we will use that name since
    it’s the mostcommon—and it’s how we *use* the gradient **g**^t. All of the information
    and learning come from **g**^t; it controls what the network learns and how well
    it learns. The learning rate η simply controls how quickly we follow that information.
    But the gradient **g**^t is only as good as the data we use to train the model.
    If our data is noisy (and it almost always is), our gradients will also be noisy.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分没有令人满意的名称；PyTorch 称之为优化器，但这也描述了整个过程。尽管如此，我们仍将使用这个名字，因为它是最常见的——这是我们 *使用*
    梯度 **g**^t 的方式。所有信息和学习都来自 **g**^t；它控制网络学习的内容以及学习效果的好坏。学习率 η 简单地控制我们跟随该信息的速度。但梯度
    **g**^t 的好坏取决于我们用来训练模型的数据。如果我们的数据有噪声（而且几乎总是如此），我们的梯度也会有噪声。
- en: These noisy gradients and how they impact learning are shown in figure 5.2 with
    three other situations. One is the ideal gradient descent path, which almost never
    happens. The other two are real problems. Say, for example, that we sometimes
    get a gradient **g**^t that is just *too large*. This can happen when we add hundreds
    of layers to our network and is a common problem called an *exploding gradient*.
    Mathematically, that would be a situation where ∥**g**^t∥[2] → ∞. If we use that
    gradient, we may take a far larger step than we ever intended (even with a small
    η), which can degrade performance or even completely prevent us from learning.
    The opposite situation occurs too; the gradient could be too small ∥**g**^t∥[2]
    → 0, causing us to make no progress toward training (even with a large η). This
    is called a *vanishing* gradient and can occur in almost any architecture but
    is particularly common when we use the tanh (⋅) and *σ*(⋅) activation functions.[¹](#fn9)
    When looking at these four situations, remember that optimization also means *minimization*,
    so the process of going from a high value (red) down to a low value (green) is
    literally how a neural network “learns.”
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些噪声梯度及其对学习的影响在图5.2中用三种其他情况展示。一个是理想的梯度下降路径，这几乎从未发生。其他两个是真实问题。例如，我们有时会得到一个**g**^t
    梯度，它只是*太大*。这发生在我们向网络添加数百层时，是一个常见的问题，称为*梯度爆炸*。从数学上讲，这将是一个∥**g**^t∥[2] → ∞的情况。如果我们使用这个梯度，我们可能采取比我们原本打算的更大的步骤（即使η很小），这可能会降低性能甚至完全阻止我们学习。相反的情况也会发生；梯度可能太小∥**g**^t∥[2]
    → 0，导致我们无法在训练中取得进展（即使η很大）。这被称为*梯度消失*，几乎在任何架构中都会发生，但当我们使用tanh(⋅)和*σ*(⋅)激活函数时尤其常见。[¹](#fn9)
    在查看这四种情况时，请记住，优化也意味着*最小化*，因此从高值（红色）到低值（绿色）的过程实际上是神经网络“学习”的方式。
- en: '![](../Images/CH05_F02_Raff.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F02_Raff.png)'
- en: Figure 5.2 A toy example showing three scenarios for gradient descent. Each
    is a contour plot of a 2D optimization going from red (high values, bad) to dark
    green (low values, good). The ideal case is at the top left, where each gradient
    heads exactly toward the solution. The top right shows *noisy* gradients that
    cause the descent to head in not quite the correct direction, requiring more steps.
    The bottom left shows exploding gradients, where we begin to take steps that are
    far too large and head away from the solution. The bottom right shows vanishing
    gradients, where the gradient becomes so small that we have to take an excessive
    number of steps to get to the solution.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2展示了梯度下降的三个场景的玩具示例。每个场景都是一个从红色（高值，不好）到深绿色（低值，好）的2D优化等高线图。理想情况在左上角，每个梯度正好指向解。右上角显示了*噪声*梯度，导致下降方向不完全正确，需要更多步骤。左下角显示了梯度爆炸，我们开始采取过大的步骤，远离解。右下角显示了梯度消失，梯度变得如此之小，以至于我们必须采取过多的步骤才能到达解。
- en: 'In these situations, naively using the raw gradient *g*^t could mislead us.
    Again, we probably want to introduce an abstraction that takes *g*^t in as input
    and do something more clever to avoid these situations. We call that function
    G that *alters* the gradient to make it better behaved and help accelerate the
    learning. So now we again update our equation and get:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，天真地使用原始梯度 *g*^t 可能会误导我们。再次强调，我们可能需要引入一个抽象，它将 *g*^t 作为输入，并执行更聪明的操作以避免这些情况。我们称这个函数为
    G，它*改变*梯度，使其表现更好并帮助加速学习。因此，我们现在再次更新我们的方程，得到：
- en: '![](../Images/CH05_UN02_Raff.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_UN02_Raff.png)'
- en: Now we have a new gradient descent equation. It has all the base components
    as before, plus some extra abstractions to make it more flexible. These two strategies—adjusting
    the learning rate and gradient—are ubiquitous in modern deep learning. As such,
    they both have interfaces in PyTorch. So let’s define a new version of our `train_simple_network`
    function we have been using that allows for these two kinds of improvements. We
    can then use this new function to compare the effect of the new techniques and
    continue to use them later.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个新的梯度下降方程。它具有之前所有的基本组件，还有一些额外的抽象使其更加灵活。这两种策略——调整学习率和梯度——在现代深度学习中无处不在。因此，它们在PyTorch中都有接口。所以让我们定义一个新的`train_simple_network`函数版本，它允许这两种改进。然后我们可以使用这个新函数来比较新技术的效果，并在以后继续使用它们。
- en: The interplay between *L*(⋅,⋅) and *G*(⋅)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*L*(⋅,⋅) 和 *G*(⋅) 之间的相互作用'
- en: The learning rate schedule and gradient updates ultimately tackle similar goals,
    so why have both instead of picking one? You can think of them as working on two
    time scales. The learning rate schedule *L*(⋅,⋅) operates *once per epoch* to
    adjust the global rate of progress. The gradient update functions *G*(⋅) operate
    on *every* batch, so if you have millions of data points, you may be calling *G*(⋅)
    millions of times but calling *L*(⋅,⋅) at most a few hundred times. So you can
    think of these things as balancing between long-term and short-term strategies
    to minimize a function. Like most things in life, it’s better to play the balance
    than focus purely on short- or long-term goals.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率计划和梯度更新最终解决类似的目标，那么为什么要有两者而不是选择其一？你可以把它们看作是在两个时间尺度上工作。学习率计划*L*(⋅,⋅)在每个epoch中*运行一次*来调整全局进度率。梯度更新函数*G*(⋅)在每个batch上操作，所以如果你有数百万个数据点，你可能要调用*G*(⋅)数百万次，但最多只调用*L*(⋅,⋅)几百次。所以你可以把这些东西看作是在长期和短期策略之间进行平衡，以最小化函数。像生活中的许多事情一样，保持平衡比仅仅关注短期或长期目标要好。
- en: 5.1.3  Implementing optimizers and schedulers
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.3 实现优化器和调度器
- en: PyTorch provides two interfaces for us to implement the *L*(⋅,⋅) and *G*(⋅)
    functions we have described. First is the `torch.optim.Optimizer` class that you
    have already been using. We’ve been using a naive `SGD` optimizer thus far. We
    start replacing the `SGD` object, but with other optimizers that use the same
    interface, so almost no code has to change. The new class is `_LRScheduler`, which
    has several options for us to choose from. To implement our `train_network` function,
    we’ll make just a few modifications to the `train_simple_network` code. Figure
    5.3 shows the high-level process, which has only one new step in yellow, with
    a slight change to the update step to use *G*(⋅) to denote that we can change
    how gradients are used.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch为我们提供了两个接口来实现我们描述的*L*(⋅,⋅)和*G*(⋅)函数。第一个是`torch.optim.Optimizer`类，你之前已经使用过。我们开始替换`SGD`对象，但使用具有相同接口的其他优化器，所以几乎不需要更改代码。新的类是`_LRScheduler`，它为我们提供了几个选项。为了实现我们的`train_network`函数，我们只需对`train_simple_network`代码进行一些修改。图5.3显示了高级过程，其中只有黄色中的一个新步骤，对更新步骤的轻微更改，使用*G*(⋅)表示我们可以更改梯度使用的方式。
- en: '![](../Images/CH05_F03_Raff.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F03_Raff.png)'
- en: Figure 5.3 Diagram of the new training loop process. The major change is the
    new step 1 in yellow, showing that we have a learning rate schedule *L*(⋅,⋅).
    The schedule determines the learning rate *η*[t] used by the process in step 4\.
    Everything else remains the same as before.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 新的训练循环过程图。主要变化是黄色的新步骤1，显示我们有一个学习率计划*L*(⋅,⋅)。该计划决定了步骤4中过程使用的学习率*η*[t]。其他一切保持不变。
- en: Updating the training code
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 更新训练代码
- en: 'Now let’s talk about the three changes we need to make to the `train_simple_network`
    code. The first thing we change is the function signature so there are two new
    options available: the optimizer and scheduler. The new signature is shown here,
    with `optimizer` for *G*(⋅) and `lr_schedule` for *L*(⋅,⋅), respectively:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们谈谈我们需要对`train_simple_network`代码进行的三个更改。我们首先更改的是函数签名，因此现在有两个新的选项可用：优化器和调度器。新的签名如下所示，其中`optimizer`用于*G*(⋅)，而`lr_schedule`用于*L*(⋅,⋅)：
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Notice that we set both to have a `None` default value. Specifying a schedule
    is *always* optional, and you may want to change the schedule used, depending
    on the task at hand. Some problems take just a few epochs, others take hundreds
    to thousands, and both of these factors change based on how much data you have.
    For these reasons, I don’t like *requiring* a learning rate schedule to *always*
    be used. I like to work without one first and then add one based on the problem
    at hand. However, we must *always* use some kind of optimizer. So if none is given,
    we add the following code to use a good default (we get to how it works later
    in this chapter):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们将两者都设置为默认值为`None`。指定一个计划是*始终*可选的，你可能想根据手头的任务更改所使用的计划。一些问题只需要几个epoch，而另一些则需要数百甚至数千个epoch，这两个因素都取决于你有多少数据。出于这些原因，我不喜欢*要求*学习率计划*始终*被使用。我更喜欢先不使用它，然后根据问题添加它。然而，我们必须*始终*使用某种类型的优化器。所以如果没有给出，我们将添加以下代码来使用一个好的默认值（我们将在本章后面了解它是如何工作的）：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ AdamW is a good default optimizer.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ AdamW是一个好的默认优化器。
- en: 'Surprisingly, we are halfway done with the new code. We do not need to make
    any changes to the `run_epoch` method because it is customary to alter the learning
    rate after each *epoch* rather than each *batch* (and an epoch is made up of many
    batches). So after our `run_epoch` function is done, we can add the following
    code:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 意想不到的是，我们已完成了一半的新代码。我们不需要对`run_epoch`方法进行任何修改，因为通常是在每个*epoch*之后而不是每个*batch*（一个epoch由多个batch组成）更改学习率。因此，在我们的`run_epoch`函数完成后，我们可以添加以下代码：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ In PyTorch, the convention is to update the learning rate after every epoch.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在PyTorch中，惯例是在每个epoch后更新学习率。
- en: Again, we learn about `ReduceLROnPlateau` in a moment. It is an idiosyncratic
    and special member of the learning rate scheduler family that requires an extra
    argument. Otherwise, we simply call the `step()` function at the end of each epoch,
    and the learning rate schedule is updated automatically. You may recognize this
    as the same approach we use for the `Optimizer` class inside of `run_epoch`, which
    calls `optimizer.step()` at the end of every batch. This is an intentional design
    choice to make the two closely coupled classes consistent. You can find the complete
    function definition in the code in the idlmam.py file ([https://github.com/EdwardRaff/Inside-Deep-Learning/blob/main/idlmam.py](https://github.com/EdwardRaff/Inside-Deep-Learning/blob/main/idlmam.py)).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们将在稍后了解`ReduceLROnPlateau`。它是学习率调度器家族中的一个独特且特殊的成员，它需要一个额外的参数。否则，我们只需在每个epoch结束时调用`step()`函数，学习率调度就会自动更新。你可能认识这个方法是我们用于`run_epoch`中的`Optimizer`类的相同方法，它在每个batch结束时调用`optimizer.step()`。这是一个有意的设计选择，以使两个紧密耦合的类保持一致。你可以在idlmam.py文件中的代码中找到完整的函数定义（[https://github.com/EdwardRaff/Inside-Deep-Learning/blob/main/idlmam.py](https://github.com/EdwardRaff/Inside-Deep-Learning/blob/main/idlmam.py)）。
- en: Using the new training code
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新的训练代码
- en: That is all it takes to prepare our code for some new and improved learning.
    Now that we have a new loading function implemented, let’s train a neural network.
    We use the Fashion-MNIST dataset because it is slightly more challenging while
    retaining the same size and shape as the original MNIST corpus, which will let
    us accomplish some testing in a reasonable time.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是准备我们的代码以进行一些新的改进学习所需的所有步骤。现在我们已经实现了新的加载函数，让我们训练一个神经网络。我们使用Fashion-MNIST数据集，因为它稍微更具挑战性，同时保留了与原始MNIST语料库相同的大小和形状，这将使我们能够在合理的时间内完成一些测试。
- en: 'Here we load Fashion-MNIST, define a multilayer fully connected network, and
    then train it in a manner equivalent to using our old `train_simple_network` method.
    To do this, we need slightly more ceremony by specifying the SGD optimizer ourselves:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们加载Fashion-MNIST，定义一个多层全连接网络，然后以与使用我们旧的`train_simple_network`方法等效的方式进行训练。为此，我们需要通过指定SGD优化器来稍微增加一些仪式感：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ 50 epochs of training
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 50个epoch的训练
- en: ❷ A respectable average batch size
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 一个可尊敬的平均批量大小
- en: 'Now we write some more familiar code, a fully connected network with three
    hidden layers:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们编写一些更熟悉的代码，一个包含三个隐藏层的全连接网络：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ How many values are in the input? We use this to help determine the size of
    subsequent layers.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 输入中有多少个值？我们使用这个值来帮助确定后续层的大小。
- en: ❷ Hidden layer size
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 隐藏层大小
- en: ❸ How many channels are in the input?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 输入中有多少个通道？
- en: ❹ How many classes are there?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 有多少个类别？
- en: 'Last, we need to settle on a default starting learning rate *η*[0]. If we do
    not provide any kind of learning rate schedule *L*(⋅,⋅), then *η*[0] will be used
    for every epoch of training. We’ll use *η*[0] = 0.1, which is more aggressive
    (read, *large* ) than you usually want. I chose this larger value to make it easier
    to show the impacts of the schedules we can choose from. Under normal use, different
    optimizers tend to have different preferred defaults, but using *η*[0] = 0.001
    is usually a good starting point:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要确定一个默认的起始学习率*η*[0]。如果我们不提供任何类型的学习率调度*L*(⋅,⋅)，则*η*[0]将用于每个epoch的训练。我们将使用*η*[0]
    = 0.1，这比通常想要的更激进（也就是说，*大*）。我选择这个较大的值是为了更容易展示我们可以选择的调度的影响。在正常使用中，不同的优化器往往有不同的首选默认值，但使用*η*[0]
    = 0.001通常是一个好的起点：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'With that in place, we can define a naive `SGD` optimizer the same as we did
    before. We just need to explicitly call `torch.optim.SGD` and pass it in ourselves,
    which you can see in the following code. Notice that we set the default learning
    rate *η*[0] in the `optimizer`’s constructor. This is the standard process in
    PyTorch, and any `LRSchedule` object we might use will reach into the `optimizer`
    object to alter the learning rate:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在此基础上，我们可以定义一个与之前相同的简单`SGD`优化器。我们只需要显式调用`torch.optim.SGD`并将其传递给我们自己，这可以在以下代码中看到。注意，我们在`optimizer`的构造函数中设置了默认学习率*η*[0]。这是PyTorch中的标准流程，我们可能使用的任何`LRSchedule`对象都将进入`optimizer`对象以改变学习率：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Just like before, we can use seaborn with the return `fc_results` pandas dataframe
    to quickly plot the results. The following code and output show the kinds of results
    we get, clearly learning with more training but having occasional regressions.
    This is because our learning rate is a bit too aggressive, but it’s the kind of
    behavior you often see on real-world problems with non-aggressive learning rates
    (like *η*[0] = 0.001):'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前一样，我们可以使用seaborn库，通过返回`fc_results` pandas数据框来快速绘制结果。以下代码和输出显示了我们可以得到的结果，明显地，随着训练的深入，我们得到了更清晰的学习效果，但偶尔也会出现回归。这是因为我们的学习率有点过于激进，但这种行为在具有非激进学习率（如*η*[0]
    = 0.001）的实际问题中是常见的：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/CH05_UN03_Raff.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_UN03_Raff.png)'
- en: 5.2 Learning rate schedules
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 学习率调度
- en: Now let’s talk about ways to implement the learning rate adjustment (*L*(*η*[0],*t*))
    we described earlier. In PyTorch, these are called *learning rate schedulers*,
    and they take the `optimizer` object as an input because they directly alter the
    learning rate η used within the `optimizer` object. The high-level approach is
    shown in figure 5.4\. The *only* thing we need to change is the equation used
    for *L*(*η*[0],*t*) to switch between schedules.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来谈谈实现我们之前描述的学习率调整（*L*(*η*[0],*t*)）的方法。在PyTorch中，这些被称为*学习率调度器*，它们将`optimizer`对象作为输入，因为它们直接改变`optimizer`对象中使用的学习率η。高级方法如图5.4所示。我们唯一需要改变的是用于*L*(*η*[0],*t*)的方程，以在调度方案之间切换。
- en: '![](../Images/CH05_F04_Raff.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F04_Raff.png)'
- en: Figure 5.4 General process for every learning rate schedule. We set up before
    training starts with initial values, do one epoch of training, and then alter
    *η*[*t* + 1], which is used by the next epoch. The gradient optimizer *G*(⋅) is
    used multiple times per epoch and operates independently of the learning rate
    schedule.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 每个学习率调度的通用过程。我们在训练开始前设置初始值，进行一次训练epoch，然后改变*η*[*t* + 1]，这是下一个epoch使用的。梯度优化器*G*(⋅)在每个epoch中被多次使用，并且独立于学习率调度。
- en: We will talk about four approaches to adjusting the learning rate that you should
    be aware of. Each of these schedules has different pros and cons. You may select
    your schedule to try to stabilize a model that isn’t training consistently (accuracy
    oscillating up and down between epochs), reduce the number of epochs needed to
    train to save time, or maximize the accuracy of your final model. For most of
    the content of this book, we are using very few training iterations (10 to 50)
    to make sure the run in a reasonable amount of time. When you work on a problem
    in real life, it is common to train for 100 to 500 epochs. The more epochs of
    training you perform, the bigger the impact a learning rate schedule can have,
    because there are more opportunities to alter the learning rate. So while we may
    not use these heavily in the rest of this book, you should still be aware of them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论四种调整学习率的方案，你应该了解。每个方案都有其优缺点。你可以选择你的方案来尝试稳定一个训练不一致的模型（准确率在各个epoch之间上下波动），减少训练所需的epoch数量以节省时间，或者最大化最终模型的准确率。对于本书的大部分内容，我们使用非常少的训练迭代（10到50次）以确保运行在合理的时间内。当你处理现实生活中的问题时，通常需要训练100到500个epoch。你进行的训练epoch越多，学习率调度方案的影响就越大，因为改变学习率的机会就越多。所以虽然我们在这本书的其余部分可能不会大量使用这些方案，但你仍然应该了解它们。
- en: We first talk about four of the most fundamental learning rate schedules in
    modern use and the kinds of minimization issues they help resolve, and how. We’ll
    talk about these at an *intuitive* level, as proving them is more math than we
    want to do in this book. Once we have reviewed the four approaches, we’ll do a
    bake-off to compare their results.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先讨论现代使用中最基本的四种学习率调度方案以及它们帮助解决的优化问题类型，以及如何解决。我们将从直观的角度来讨论这些内容，因为证明它们比我们在这本书中想要做的数学要复杂得多。一旦我们回顾了这四种方法，我们将进行一次比较它们的实验。
- en: '5.2.1  Exponential decay: Smoothing erratic training'
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 指数衰减：平滑波动训练
- en: 'The first approach we discuss may not be the most common but is one of the
    simplest. It is called an *exponential decay rate*. The exponential decay rate
    is a good choice if your model behaves erratically, with loss or accuracy increasing
    and decreasing by large amounts. You can use the exponential decay to help stabilize
    the training and get a more consistent result. We pick a value 0 < *γ* < 1 that
    is multiplied by our learning rate after every epoch. It is defined by the following
    function, where t represents the current epoch:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先讨论的方法可能不是最常见的方法，但它是其中最简单的一种。它被称为*指数衰减率*。如果你的模型行为不稳定，损失或准确率大幅增加和减少，指数衰减率是一个不错的选择。你可以使用指数衰减来帮助稳定训练并获得更一致的结果。我们选择一个
    0 < *γ* < 1 的值，在每次 epoch 后乘以我们的学习率。它由以下函数定义，其中 t 代表当前 epoch：
- en: '![](../Images/ch5-eqs-to-illustrator2x.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/ch5-eqs-to-illustrator2x.png)'
- en: 'PyTorch provides this using the `torch.optim.lr_scheduler.ExponentialLR` class.
    Because we usually do many epochs, it is important to make sure γ is not set too
    aggressively: it’s a good idea to start with a desired *final* learning rate and
    call that *η*[min]. Then, if you train for a total of T epochs, you can set'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 通过 `torch.optim.lr_scheduler.ExponentialLR` 类提供这一功能。因为我们通常进行很多个epoch，所以确保
    γ 不要设置得太激进是很重要的：从期望的*最终*学习率开始是一个好主意，并将其称为*η*[min]。然后，如果你总共训练了 T 个 epoch，你可以设置
- en: '![](../Images/CH05_F04_Raff_EQ01.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_F04_Raff_EQ01.png)'
- en: to ensure that you pick a value of γ that reaches your desired minimum and results
    in learning throughout.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你选择的 γ 值能够达到你期望的最小值，并确保学习过程持续进行。
- en: 'For example, say the initial learning rate is *η*[0] = 0.001, you want the
    minimum to be *η*[min] = 0.0001, and you train for *T* = 50 epochs. You need to
    set *γ* ≈ 0.91201. The following code simulates this process and shows how to
    write the code to calculate γ:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设初始学习率是 *η*[0] = 0.001，你希望最小值为 *η*[min] = 0.0001，并且你训练了 *T* = 50 个 epoch。你需要设置
    *γ* ≈ 0.91201。以下代码模拟了这一过程，并展示了如何编写代码来计算 γ：
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Total epochs
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 总 epoch 数
- en: ❶ Generates all the t values
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 生成所有 t 值
- en: ❶ Pretend initial learning rate *η*[0]
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 假设初始学习率 *η*[0]
- en: ❶ Pretend desired minimum learning rate *η*[min]
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 假设期望的最小学习率 *η*[min]
- en: ❶ Computes the decay rate γ
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算衰减率 γ
- en: ❶ All the *η*[t] values
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 所有 *η*[t] 值
- en: '![](../Images/CH05_UN04_Raff.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_UN04_Raff.png)'
- en: The exponential decay rate smoothly and consistently decreases the learning
    rate every epoch. At a high level, there are many ways to do this. Some people
    use linear decay (*η*[0]/(*γ*⋅*t*)) instead of exponential (*η*[0] ⋅ *γ*^t), and
    a variety of other approaches achieve the same goal; no one can give you a definitive
    playbook or flowchart to choose between exponential decay and its related family
    members. They all follow a similar intuition for why they work, which we will
    walk through.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 指数衰减率会平滑且一致地降低每个epoch的学习率。从高层次来看，有很多人实现这一目标的方法。有些人使用线性衰减 (*η*[0]/(*γ*⋅*t*))
    而不是指数衰减 (*η*[0] ⋅ *γ*^t)，还有各种其他方法可以达到相同的目标；没有人能给你一个明确的操作手册或流程图来选择指数衰减及其相关家族成员。它们都遵循一个相似的理由来解释为什么它们有效，我们将通过以下内容进行讲解。
- en: In particular, the exponential learning rate schedule helps solve the problem
    of getting *near* the solution but not quite making it *to* the solution. Figure
    5.5 shows how this happens. The black lines show the path that the parameters
    Θ take as they are altered from one step to the next. The initial weights are
    random, so we start with a bad set of weights Θ, and initially, updates move us
    toward the local minima. But as we get closer, we start bouncing around the minimum—sometimes
    getting closer than a previous step and sometimes moving farther away—which causes
    the loss to fluctuate up and down.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是指数学习率调度器有助于解决接近解但未能完全达到解的问题。图 5.5 展示了这种情况。黑色线条显示了参数 Θ 随着它们从一个步骤到下一个步骤的变化所采取的路径。初始权重是随机的，所以我们从一个不好的权重集
    Θ 开始，并且最初更新将我们推向局部最小值。但随着我们接近最小值，我们开始在该最小值周围弹跳——有时比前一步更接近，有时又远离，这导致损失上下波动。
- en: '![](../Images/CH05_F05_Raff.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_F05_Raff.png)'
- en: Figure 5.5 Example of the minimization problem that an exponential learning
    rate helps solve. When you are far from the solution, a large η helps you get
    to the right *area* faster. But once you are in the right area, η is too large
    to *reach* the best solution. Instead, it keeps overshooting the local minima
    (in this case, it’s the only minima and so also the global minima).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 指数学习率帮助解决的极小化问题示例。当你离解还很远时，大的 η 有助于你更快地到达正确的 *区域*。但一旦你处于正确的区域，η 就太大，无法
    *达到* 最佳解。相反，它不断超过局部最小值（在这种情况下，它是唯一的极小值，因此也是全局最小值）。
- en: Returning to our analogy of a train traveling to its destination, going *fast*
    is great when you are *far* from your goal because it gets you closer faster.
    But once you are near your destination, it’s a good idea to *slow down*. If the
    station was only 100 feet away and the train was going 100 miles per hour, the
    train would barrel past the station. You want the train to start slowing down
    so it can reach a precise location, and that’s what the exponential learning rate
    does; an example is shown in figure 5.6.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们关于火车前往目的地的类比，当你离目标还很远时，开 *快* 是很棒的，因为它能更快地让你接近目标。但一旦你接近目的地，减速是个好主意。如果车站只有100英尺远，火车以每小时100英里的速度行驶，火车就会飞快地驶过车站。你希望火车开始减速，以便到达一个精确的位置，这就是指数学习率的作用；示例见图5.6。
- en: '![](../Images/CH05_F06_Raff.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F06_Raff.png)'
- en: Figure 5.6 Shrinking η at every step causes the optimization to slow down as
    it gets closer to the destination. This helps it converge to the local minimum
    instead of bouncing around it.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 在每一步缩小 η 会使得优化随着接近目的地而减速。这有助于它收敛到局部最小值而不是在其周围弹跳。
- en: 'The trick to using the exponential learning rate well is setting *η*[min].
    I usually recommend making it 10 to 100 times smaller than *η*[0]. A reduction
    of 10 to 100× is normal in machine learning and a theme you will see across the
    schedules we use. The following code shows how we can create the exponential decay
    schedule by passing in the `optimizer` as an argument at construction. We also
    use the first line to reset the learned weights to be random so we don’t have
    to keep re-specifying the same neural network over and over again:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指数学习率的高招是设置 *η*[min]。我通常建议将其设置为 *η*[0] 的10到100倍小。在机器学习中，10到100倍的减少是正常的，这也是我们在使用的计划中会看到的一个主题。以下代码展示了我们如何通过在构造时传入
    `optimizer` 作为参数来创建指数衰减计划。我们还使用第一行将学习到的权重重置为随机值，这样我们就不必一次又一次地重新指定相同的神经网络：
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Re-randomizes the model weights so we don’t need to define the model again
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 重新随机化模型权重，这样我们就不需要再次定义模型
- en: ❷ Desired final learning rate *η*[min]
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 所需的最终学习率 *η*[min]
- en: ❸ Computes γ that results in *η*[min]
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算导致 *η*[min] 的 γ
- en: ❹ Sets up the optimizer
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 设置优化器
- en: ❺ Picks a schedule and passes in the optimizer
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 选择一个计划并传入优化器
- en: '5.2.2  Step drop adjustment: Better smoothing'
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 步长下降调整：更好的平滑
- en: The second strategy is an especially popular variant of the exponential decay
    we just discussed. The *step drop* approach has the same motivation and is also
    useful to stabilize learning but usually delivers improved accuracy after training.
    What is the difference between step drop and exponential decay? Instead of constantly
    adjusting the learning rate ever so slightly, we let it stay fixed for a while
    and then drop it dramatically just a few times. This is shown in figure 5.7.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种策略是我们刚刚讨论的指数衰减的一个特别受欢迎的变体。*步长下降* 方法具有相同的动机，也有助于稳定学习，但通常在训练后提供更高的精度。步长下降和指数衰减之间的区别是什么？我们不是不断略微调整学习率，而是让它保持固定一段时间，然后仅几次大幅下降。这如图5.7所示。
- en: '![](../Images/CH05_F07_Raff.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F07_Raff.png)'
- en: Figure 5.7 The step drop strategy requires us to decide on an initial learning
    rate, a decay factor γ, and a frequency S. Every S epochs of training, we decrease
    the learning rate by a factor of γ.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 步长下降策略要求我们决定一个初始学习率、衰减因子 γ 和频率 S。每经过 S 个训练周期，我们就将学习率按 γ 的因子减少。
- en: The logic behind this approach is that early in the optimization, we are still
    far from the solution, so we should go as fast as possible. For the first S epochs,
    we head toward the solution at the maximum speed *η*[0]. This is (hopefully) better
    than exponential decay because the exponential decay starts slowing down *immediately*
    and is therefore counterproductive (at least in the beginning). Instead, let’s
    keep going at our maximum speed and simply drop the learning rate instantaneously
    once or twice. That way, we go maximum speed for as long as possible but eventually
    slow down to converge on the solution.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的逻辑是，在优化的早期，我们仍然离解很远，所以我们应该尽可能快地前进。对于前 S 个轮次，我们以最大速度 *η*[0] 向解前进。这（希望）比指数衰减更好，因为指数衰减会立即减速，因此（至少在开始时）是反效果的。相反，让我们以最大速度继续前进，并简单地一次性或两次立即降低学习率。这样，我们可以尽可能长时间地以最大速度前进，但最终会减速以收敛到解。
- en: We can also express this strategy in a more mathematical notation. If we want
    to drop the learning rate every S epochs, we obtain
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以用更数学的符号表达这种策略。如果我们想每 S 个轮次降低一次学习率，我们得到
- en: '![](../Images/ch5-eqs-to-illustrator3x.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/ch5-eqs-to-illustrator3x.png)'
- en: If you compare this equation to the exponential day, you should notice that
    they look *almost identical* and are deeply connected. If we set the step drop
    strategy to drop every epoch (*S* = 1), we get *γ*^(⌊*t*/1⌋) = *γ*^t, which is
    *exactly* exponential decay. So the step drop strategy reduces the frequency at
    which we decrease the learning rate and balances that out by instead increasing
    the amount by which we decay.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将这个方程与指数衰减日进行比较，你应该注意到它们看起来**几乎相同**并且紧密相连。如果我们将步长下降策略设置为每轮都下降（*S* = 1），我们得到
    *γ*^(⌊*t*/1⌋) = *γ*^t，这**正好**是指数衰减。因此，步长下降策略减少了我们降低学习率的频率，并通过增加衰减量来平衡这一点。
- en: 'The same rule of thumb about a 10 to 100× drop from *η*[0] to *η*[min] applies,
    so we usually set γ to a value in the range of 0.1, 0.5 and set S such that the
    learning rate is adjusted only two or three times during training. Again, PyTorch
    provides this using the `StepLR` class. The following code shows what a StepLR
    might look like compared to the exponential decay; you can see that it has a higher
    learning rate for *most* of the epochs but a lower learning rate for longer at
    the end of training:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 关于从 *η*[0] 到 *η*[min] 下降 10 到 100 倍的规则同样适用，所以我们通常将 γ 设置在 0.1、0.5 的范围内，并设置 S
    以确保学习率在训练过程中只调整两到三次。同样，PyTorch 使用 `StepLR` 类提供了这一点。以下代码显示了 StepLR 与指数衰减相比可能的样子；你可以看到，它在大多数轮次中具有更高的学习率，但在训练结束时的学习率较低：
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/CH05_UN05_Raff.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH05_UN05_Raff.png)'
- en: 'As with all learning rate schedules, we pass in the `optimizer` at construction
    time. This is shown in the following code, where we train with four drops in learning
    rate, each by a factor of *γ* = 0.3. The last drop happens in the last few epochs,
    and we have far fewer total epochs, which means the first three are much more
    important. Although four drops equal a 1/0.3⁴ ≈ 123× reduction in the learning
    rate, most of the training happens with a 1/0.3³ ≈ 37× drop (or less):'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有学习率调度一样，我们在构造时传入`optimizer`。以下代码显示了这一点，其中我们通过一个因子 *γ* = 0.3 进行四次学习率下降。最后一次下降发生在最后几个轮次，我们总共的轮次要少得多，这意味着前三次非常重要。尽管四次下降等于学习率减少了
    1/0.3⁴ ≈ 123 倍，但大多数训练都是在 1/0.3³ ≈ 37 倍的下降（或更少）下进行的：
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Tells it to step down by a factor f γ every epochs //4 so this happens four
    times total.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 指示它每 4 个轮次下降一个因子 f γ，所以总共发生四次。
- en: '5.2.3  Cosine annealing: Greater accuracy but less stability'
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3  余弦退火：更高的精度但更低的稳定性
- en: 'The next learning rate is odd but effective: *cosine annealing*. Cosine annealing
    has a different logic and strategy than exponential decay and the step learning
    rate. The latter two only decrease the learning rate, but cosine annealing decreases
    and increases the learning rate. This approach is very effective for getting the
    best possible results but does not provide the same degree of stabilization, so
    it might not work on poorly behaved datasets and networks.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个学习率策略既奇特又有效：**余弦退火**。余弦退火与指数衰减和步长学习率的逻辑和策略不同。后两者只降低学习率，但余弦退火会降低和增加学习率。这种方法对于获得最佳结果非常有效，但并不提供相同程度的不稳定性，因此可能不适合表现不佳的数据集和网络。
- en: 'Cosine annealing also has an initial learning rate *η*[0] and a minimum rate
    *η*[min]; the difference is that we alternate between the minimum and maximum
    learning rates. The math follows this equation, where *T*[max] is the number of
    epochs between cycles:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦退火也有一个初始学习率 *η*[0] 和一个最小率 *η*[min]；区别在于我们在最小和最大学习率之间交替。数学遵循以下方程，其中 *T*[max]
    是周期之间的epoch数量：
- en: '![](../Images/ch5-eqs-to-illustrator4x.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/ch5-eqs-to-illustrator4x.png)'
- en: 'The cos term fluctuates up and down like the cosine function normally does,
    and we rescale its cosine to have a maximum at *η*[0] instead of 1 and a minimum
    at *η*[min] instead of –1\. PyTorch provides this with the `CosineAnnealingLR`
    class. The value *T*[max] becomes a new hyperparameter for the model. I like to
    set *T*[max] so we have 10 to 50 oscillation dips total, and we want to always
    end on a dip (to end by slowing down for the destination). For example, if we
    want S dips, we use *T*[max] = *T*/(*S*⋅2−1). The following code shows two dips
    of oscillation in the cosine schedule by setting *T*[max] = *T*/(2⋅2−1):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦项上下波动，就像余弦函数通常所做的那样，我们将余弦重新缩放，使其在 *η*[0] 处达到最大值而不是1，在 *η*[min] 处达到最小值而不是-1。PyTorch通过
    `CosineAnnealingLR` 类提供这一点。*T*[max] 成为模型的新超参数。我喜欢将 *T*[max] 设置为10到50个总振荡波谷，并且我们希望始终结束在一个波谷（通过减速到达目的地）。例如，如果我们想要S个波谷，我们使用
    *T*[max] = *T*/(*S*⋅2−1)。以下代码通过设置 *T*[max] = *T*/(2⋅2−1) 显示了余弦调度中的两个振荡波谷：
- en: '[PRE12]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Computes the cosine schedule *η*[t] for every value of t
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算每个t值的余弦调度 *η*[t]
- en: '![](../Images/CH05_UN06_Raff.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_UN06_Raff.png)'
- en: At first glance, this cosine schedule does not make sense. Why would we want
    to fluctuate the learning rate up and down? It makes more sense when we remember
    that neural networks are not *convex*. A convex function has only one local minimum,
    and *every* gradient leads us to the optimal solution. But neural networks are
    non-convex and can have many local minima, which may not be a good solution. If
    our model first heads towards one of these local minima, and we decrease only
    the learning rate, we may get stuck in this sub-optimal area.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，这个余弦调度似乎没有道理。我们为什么要上下波动学习率呢？当我们记得神经网络不是**凸函数**时，这就有意义了。凸函数只有一个局部最小值，并且**每个**梯度都会引导我们到达最优解。但神经网络是非凸的，可能有很多局部最小值，这些可能不是好的解。如果我们的模型首先走向这些局部最小值之一，而我们只减少学习率，我们可能会陷入这个次优区域。
- en: Figure 5.8 shows what can go wrong when training a neural network that has multiple
    minima. The network starts in a bad position (because initial weights Θ are random)
    and makes progress toward a local minimum. It’s an OK solution, but a better one
    exists nearby. Optimization is hard, and we have no way of knowing how good our
    minima are or how many exist; so we end up stuck in a sub-optimal position.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8显示了在训练具有多个最小值的神经网络时可能出错的情况。网络从一个糟糕的位置开始（因为初始权重 Θ 是随机的）并朝着局部最小值前进。这是一个不错的解决方案，但附近存在更好的解决方案。优化很困难，我们无法知道我们的最小值有多好或有多少个；所以我们最终陷入次优位置。
- en: '![](../Images/CH05_F08_Raff.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_F08_Raff.png)'
- en: Figure 5.8 If we get an unlucky starting point (because it leads to a sub-optimal
    minimum), our search may take us to the sub-optimal minimum (light green). If
    we shrink the learning rate, our search may get stuck. The only way to escape
    is to increase the learning rate.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 如果我们得到一个不幸的起点（因为它导致次优最小值），我们的搜索可能会带我们到次优最小值（浅绿色）。如果我们缩小学习率，我们的搜索可能会卡住。唯一的逃脱方式是增加学习率。
- en: There is a sliver of hope, though. Through experimentation (and hard math that
    we aren’t going to look at), there is a common phenomenon that sub-optimal local
    minima exist on the way toward a better minimum (figure 5.8 shows this). So if
    we shrink and then later increase the learning rate η, we can give our model a
    chance to escape the current local minimum and find a new alternative minimum.
    The larger learning rate hopefully gets us to a new and better area, and the decay
    again allows us to hone in on a more refined solution. Figure 5.9 shows how this
    works with cosine annealing.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，还有一线希望。通过实验（以及我们不打算看的困难数学），存在一个共同现象，即次优局部最小值存在于通往更好最小值的过程中（图5.8显示了这一点）。因此，如果我们缩小学习率，然后后来增加学习率
    η，我们可以给我们的模型一个机会逃离当前局部最小值并找到一个新的替代最小值。较大的学习率希望带我们到一个新的更好的区域，而衰减又允许我们更精确地聚焦于一个更精细的解决方案。图5.9显示了余弦退火如何工作。
- en: '![](../Images/CH05_F09_Raff.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_F09_Raff.png)'
- en: Figure 5.9 Gradient descent first takes us to the sub-optimal minimum, but as
    the learning rateincreases again, we bounce out of that area and toward a better
    solution. The search continues to bounce around the better solution until the
    cosine schedule again decreases the learning rate, allowing the model to converge
    toward a more precise answer.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9 梯度下降首先将我们带到次优最小值，但随着学习率的再次增加，我们跳出该区域，向更好的解决方案靠近。搜索继续在更好的解决方案周围弹跳，直到余弦调度再次降低学习率，使模型收敛到一个更精确的答案。
- en: You may wonder what stops us from bouncing out of a better solution into a worse
    one. Technically, nothing stops that from happening. However, researchers have
    developed a lot of theory about neural networks that gives us some confidence
    that bouncing out of a good solution is unlikely. The gist of these results is
    that gradient descent likes to find wide basins as good solutions, and it would
    be difficult for the optimization to bounce out because the solution is wide.
    This gives us a little more confidence that this crazy cosine schedule is a good
    idea, and empirically it has performed well on a number of tasks (image classification,
    natural language processing, and many more). In fact, cosine annealing has been
    so successful that there have been dozens of proposed alternatives.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道什么阻止我们从更好的解决方案弹跳到一个更差的解决方案。技术上，没有什么可以阻止这种情况发生。然而，研究人员已经开发了许多关于神经网络的理论，这让我们有信心认为从好的解决方案弹跳出来是不太可能的。这些结果的核心是，梯度下降喜欢找到宽的盆地作为好的解决方案，并且由于解决方案是宽的，因此优化很难跳出。这让我们对这种疯狂的余弦调度有更多的信心，并且从经验上看，它在许多任务（图像分类、自然语言处理等）上都表现良好。事实上，余弦退火已经如此成功，以至于已经提出了几十种替代方案。
- en: 'The code to implement this approach again is very similar to the previous learning
    rate schedules. This example uses `epochs//3` for the *T*[max] value, which means
    it performs two dips. I always stick with an odd number for the divisor of epochs
    so the learning ends with a dip down to a small learning rate. It is also important
    that the number of dips be no more than one-quarter the number of epochs—otherwise,
    the learning rate will fluctuate too much from one epoch to the next. Here’s the
    code:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 实现此方法的代码与之前的学习率调度非常相似。本例使用 `epochs//3` 作为 *T*[max] 的值，这意味着它执行了两次下降。我总是坚持使用奇数作为周期的除数，以便学习以一个下降到小学习率结束。此外，下降的次数不应超过周期数的四分之一——否则，学习率将在每个周期之间波动过大。以下是代码：
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Tells the cosine to go down, then up, and then down (that’s three). If we
    were doing more than 10 epochs, I would push this higher.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 告诉余弦先下降，然后上升，再下降（总共三次）。如果我们进行超过10个周期，我会将这个值推得更高。
- en: Many friends and flavors of cosine annealing
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 许多关于余弦退火的版本和风味
- en: 'Cosine annealing is an effective learning rate schedule on its own, but its
    original design was for a slightly different purpose. You may recall from your
    prior work or training in machine learning that *ensembling* is a great way to
    improve predictiveaccuracy on a task: train a bunch of models, and average your
    predictions to get a final, better, answer. But training 20 to 100 neural networks
    just to average themtogether is very expensive. That’s where cosine annealing
    comes in. Instead of training 20 models, train *1* model with cosine annealing.
    Every time the learning rate bottoms out in a dip, take a copy of those weights
    and use that as one of your models. So if you want an ensemble of 20 networks
    and you are doing T epochs of training, you use *T*[max] = *T*/(20⋅2−1). This
    results in exactly 20 dips in the learning rate.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦退火本身是一种有效的学习率调度，但其原始设计是为了一个稍微不同的目的。你可能还记得你在之前的工作或机器学习培训中，*集成*是提高任务预测准确性的好方法：训练许多模型，然后平均你的预测以得到一个最终更好、更准确的答案。但是，仅仅为了平均而训练20到100个神经网络是非常昂贵的。这就是余弦退火发挥作用的地方。与其训练20个模型，不如用余弦退火训练一个模型。每次学习率在下降中达到最低点时，就复制那些权重，并使用它们作为你的模型之一。所以，如果你想有一个由20个网络组成的集成，并且你正在进行T个周期的训练，你使用
    *T*[max] = *T*/(20⋅2−1)。这会在学习率中产生恰好20次下降。
- en: Since PyTorch 1.6, an even fancier version of this idea called *stochastic weight
    averaging* (SWA) is built in ([https://pytorch.org/docs/stable/optim.html#stochastic-weight-averaging](https://pytorch.org/docs/stable/optim.html#stochastic-weight-averaging)).
    With SWA, you can *average* the parameters Θ from each dip, giving you *one* model
    that is closer in accuracy to an ensemble of models. This is a rare best of both
    worlds, where you get the benefits of ensembling at the cost and storage of just
    one model.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 自 PyTorch 1.6 以来，一个更花哨的版本，称为*随机权重平均*（SWA）的想法被内置了([https://pytorch.org/docs/stable/optim.html#stochastic-weight-averaging](https://pytorch.org/docs/stable/optim.html#stochastic-weight-averaging))。使用
    SWA，你可以*平均*每个波谷的参数 Θ，给你一个*一个*模型，其准确性更接近于模型集合。这是一个罕见的好处，你以一个模型的成本和存储来获得集合的优势。
- en: '5.2.4  Validation plateau: Data-based adjustments'
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.4 验证平台期：基于数据的调整
- en: 'None of the learning rate schedules we have talked about so far rely on external
    information. All you need to know is an initial learning rate *η*[0], a minimum
    rate *η*[min], and not much else. None of them use information about *how well
    the learning is going*. But what information do we have available to use, and
    how should we use it? The primary information we have is the loss ℓ for each epoch
    of training, and we can add it into our approach to try to maximize the accuracy
    of our final model. This is what the plateau-based strategy does, and it will
    often get you the best possible accuracy for your final model. Let’s look at the
    training and testing set loss from the baseline network `fc_model`:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论的所有学习率计划都不依赖于外部信息。你所需要知道的就是一个初始学习率 *η*[0]，一个最小学习率 *η*[min]，以及不多的事情。它们都不使用关于*学习进展如何*的信息。但我们有什么可用信息可以使用，我们应该如何使用它？我们拥有的主要信息是每个训练epoch的损失
    ℓ，我们可以将其添加到我们的方法中，以尝试最大化我们最终模型的准确性。这就是基于平台期的策略所做的事情，它通常会为你提供最终模型的最佳可能准确性。让我们看看基线网络
    `fc_model` 的训练和测试集损失：
- en: '[PRE14]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/CH05_UN07_Raff.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_UN07_Raff.png)'
- en: 'The training loss consistently heads down, which is normal since neural networks
    rarely underfit the data. When our model trains on a specific set of data and
    sees the same data over and over (that’s what an epoch is: seeing all the data
    once), the model gets *unreasonably* good at predicting the right answer for the
    training data. That’s classic overfitting, which occurs to different degrees depending
    on how big your network is. We expect the training loss to always go down, so
    it isn’t a good source of information about how well the learning is going. But
    if we look at the test loss, we see that it does *not* consistently get better
    with each epoch. The test loss begins to stabilize or plateau after a certain
    point.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 训练损失持续下降，这是正常的，因为神经网络很少会欠拟合数据。当我们的模型在特定数据集上训练并反复看到相同的数据（这就是一个epoch：看一次所有数据），模型在预测训练数据的正确答案方面会变得*不合理地*好。这就是典型的过拟合，它发生的程度取决于你的网络有多大。我们期望训练损失总是下降，所以它不是关于学习进展的好信息来源。但如果我们看看测试损失，我们会看到它并不总是随着每个epoch而持续改善。测试损失在某个点开始稳定或平台期。
- en: If the test loss has stabilized, that would be a good time to reduce the learning
    rate.[²](#fn10) If we are already at an optimal location, reducing the learning
    rate will not hurt anything. If we are bouncing around a better solution, reducing
    the learning rate can help us improve based on the same logic we used to justify
    exponential decay. But now we are reducing the learning rate *when doing so appears
    necessary based on the data*, rather than based on a fixed arbitrary schedule.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试损失已经稳定，那么这就是降低学习率的良好时机。[²](#fn10) 如果我们已经处于一个最佳位置，降低学习率不会造成任何伤害。如果我们正在围绕一个更好的解决方案弹跳，降低学习率可以帮助我们根据我们用来证明指数衰减合理性的相同逻辑来改进。但现在我们是在根据数据，而不是基于一个固定的任意计划来降低学习率，这样做似乎是有必要的。
- en: This is the idea behind the *reduce learning rate on plateau* schedule, implemented
    by the `ReduceLROnPlateau` class in PyTorch. This is also why the `step` function
    needs the last validation loss passed in as an argument in our code, which looks
    like `lr_schedule.step(results["val loss"][-1])`. That way, the `ReduceLROnPlateau`
    class can compare the current loss to the recent history of losses.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是“在平台期降低学习率”计划的背后思想，该计划由 PyTorch 中的 `ReduceLROnPlateau` 类实现。这也是为什么我们的代码中需要将最后一个验证损失作为参数传递给
    `step` 函数，看起来像 `lr_schedule.step(results["val loss"][-1])`。这样，`ReduceLROnPlateau`
    类就可以将当前损失与最近的损失历史进行比较。
- en: '`ReduceLROnPlateau` has three primary arguments to control how well it works.
    First is `patience`, which tells us how many epochs of no improvement we want
    to see before reducing the learning rate. A value of 10 is common, as you don’t
    want to drop the learning rate prematurely. Instead, you want some consistent
    evidence that no more progress is being made before changing speed.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`ReduceLROnPlateau`有三个主要参数来控制其工作效果。首先是`patience`，它告诉我们降低学习率之前想要看到多少个没有改进的epoch。10是一个常见的值，因为你不希望过早地降低学习率。相反，你希望在改变速度之前有一些一致的证据表明没有更多的进步。'
- en: 'The second argument is `threshold`, which defines what counts as not improving.
    A threshold of exactly 0 says that we are improving if there is *any* amount lower
    than the previous best loss in the past `patience` epochs. That might be *too*
    pedantic because the loss could be decreasing by tiny but meaningless amounts
    every epoch. If we use a threshold of 0.01, we are saying that the loss needs
    to decrease by more than 1% to count as an improvement. But that could also be
    a little too loose: when you train for hundreds of epochs, you could be making
    slow but steady progress, and *reducing* the learning rate is unlikely to speed
    up convergence. It can take some work to setting this *just* right, so we stick
    the default value of `0.0001`, but this is a hyperparameter worth playing with
    if you want to squeeze out the maximum possible performance.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数是`threshold`，它定义了什么算是没有改进。精确的0阈值意味着如果过去`patience`个epoch中任何低于之前最佳损失的量都算作改进。这可能会过于刻板，因为损失可能每epoch都在以微小的、无意义的量下降。如果我们使用0.01的阈值，这意味着损失需要下降超过1%才能算作改进。但这也可能过于宽松：当你训练数百个epoch时，你可能会取得缓慢但稳定的进步，而*降低*学习率不太可能加快收敛。设置这个值需要一些工作，所以我们坚持使用默认值`0.0001`，但如果你想要榨取最大可能的性能，这是一个值得尝试的超参数。
- en: The last parameter is the `factor` by which we want to drop the learning rate
    η every time we determine that we have hit a plateau. This works the same way
    γ does for the `StepLR` class. Again, values in the range of 0.1 to 0.5 are all
    reasonable choices.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个参数是`factor`，它表示每次我们确定已经达到一个平台期时，想要降低学习率η的倍数。这与`StepLR`类中的γ参数作用相同。再次强调，0.1到0.5范围内的值都是合理的选项。
- en: '*But* we need to recognize one critical thing before using the `ReduceLROnPlateau`
    schedule: you can’t use the test data to choose when to alter the learning rate.
    Doing so *will* cause overfitting because you are using information about the
    test data to make decisions and then using the test data to evaluate your results.
    Instead, you need to have training, validation, and testing splits. Our normal
    code has been using validation as the test data, which was fine because we were
    not *looking* at the validation data to make decisions while training. The process
    of `ReduceLROnPlateau` with this important detail is summarized in figure 5.10.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*但是*，在使用`ReduceLROnPlateau`调度之前，我们需要认识到一个关键问题：你不能使用测试数据来选择何时改变学习率。这样做*将会*导致过拟合，因为你正在使用关于测试数据的信息来做出决策，然后使用测试数据来评估你的结果。相反，你需要有训练、验证和测试的分割。我们正常的代码一直使用验证数据作为测试数据，这是可以接受的，因为我们没有在训练时查看验证数据来做出决策。`ReduceLROnPlateau`的这个重要细节过程在图5.10中得到了总结。'
- en: '![](../Images/CH05_F10_Raff.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_F10_Raff.png)'
- en: Figure 5.10 Plateau-based learning rate schedule strategy. The bottom part,
    in red, shows us slicing off a portion of the training data to use as our validation
    set. Doing this, or having a special validation set along with a test set, is
    necessary to avoid overfitting. The upper part, in green, shows how we reduce
    only the learning rate η when our validation loss is not reducing.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.10展示了基于平台期的学习率调度策略。底部部分，用红色表示，展示了从训练数据中切下一部分作为我们的验证集。这样做，或者与测试集一起有一个特殊的验证集，是避免过拟合的必要条件。上部部分，用绿色表示，展示了当我们的验证损失没有减少时，我们只降低学习率η。
- en: 'The following code shows how to do this properly. First, we use the `random_split`
    class to create an 80/20 split of the *training* data. The 20% split will become
    our validation set, which `ReduceLROnPlateau` uses to check whether we should
    drop the learning rate; and the 80% is used to train the model parameters Θ. Pay
    attention to the call to *train_network*, where we use the `train_loader`, `val_loader`,
    and `test_loader` to set each of the three components properly. In the results
    of this model, we need to make sure we are looking at the *test* results and not
    the *val* results. Other than these careful precautions, this code is not much
    different from before:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何正确地执行此操作。首先，我们使用 `random_split` 类来创建80/20的 *训练* 数据分割。20%的分割将成为我们的验证集，`ReduceLROnPlateau`
    将使用它来检查我们是否应该降低学习率；而80%用于训练模型参数 Θ。请注意对 *train_network* 的调用，我们使用 `train_loader`、`val_loader`
    和 `test_loader` 正确设置每个组件。在模型的结果中，我们需要确保我们正在查看 *测试* 结果而不是 *验证* 结果。除了这些谨慎的预防措施外，此代码与之前没有太大不同：
- en: '[PRE15]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Resets the weights again so we don’t have to define a new model
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 再次重置权重，这样我们就不需要定义一个新的模型
- en: ❷ Creates training and validation subsets since we do not have explicit validation
    and test sets
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 由于我们没有明确的验证集和测试集，因此创建训练集和验证集
- en: ❸ Creates loaders for the train and validation subsets. Our test loader stays
    the same—never alter your test data!
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 为训练集和验证集创建加载器。我们的测试加载器保持不变——永远不要更改你的测试数据！
- en: ❹ Sets up our plateau schedule using gamma=0.2
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用 gamma=0.2 设置我们的平台期计划
- en: ❺ Train up the model!
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 训练模型！
- en: Don’t shoot yourself in the foot!
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 不要自食其果！
- en: Plateau-based adjustments to the learning rate are a *very* popular and successful
    strategy. Using information about how well the current model appears to be doing
    gets the best results on many problems. *But* you should not blindly use it in
    all circumstances. There are two particular cases where `ReduceLROnPlateau` may
    perform poorly or even mislead you into an overconfident result.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 基于平台期的学习率调整是一种非常流行且成功的策略。使用关于当前模型表现如何的信息，在许多问题上都能得到最佳结果。*但是*，你不应该在所有情况下盲目使用它。有两个特殊情况，`ReduceLROnPlateau`
    可能表现不佳，甚至可能误导你得到过于自信的结果。
- en: First is the case where you don’t have much data. The `ReduceLROnPlateau` strategy
    requires training and validation sets to work and thus reduces the amount of data
    you have for learning the model parameters. If you have only 100 training points,
    it may be painful to use 10 to 30% for validation. You need enough data both to
    estimate the parameters Θ and tell whether the learning has plateaued—and if you
    don’t have a lot of data, that may be too tall an order to fill.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是一种情况，就是你没有太多数据。`ReduceLROnPlateau` 策略需要训练集和验证集来工作，因此减少了你用于学习模型参数的数据量。如果你只有100个训练点，可能很难用10到30%的数据进行验证。你需要足够的数据来估计参数
    Θ 并判断学习是否已经达到平台期——如果你没有很多数据，这可能是一个过于艰巨的任务。
- en: The second case is when your data strongly violates the identically and independently
    distributed (IID) assumption. For example, if your data includes multiple samples
    from the same person, or events that depend on the date they occur (e.g., if you
    want to predict the weather, you can’t have data from the future!), naively applying
    a random split to create the validation set can lead to poor results. In this
    situation, you need to make sure your training, validation, and testing splits
    don’t have any accidental leakage from one to the other. Using the weather example,
    you might want to make sure your training split has data from *only* the years
    1980 through 2004, validation data 2005 through 2010, and test data 2011 through
    2016\. This way, no accidental time traveling will occur, which would be a big
    IID violation.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种情况是当你的数据严重违反了相同且独立分布（IID）的假设。例如，如果你的数据包括来自同一人的多个样本，或者依赖于事件发生日期的事件（例如，如果你想预测天气，你不能有来自未来的数据！），天真地应用随机分割来创建验证集可能会导致结果不佳。在这种情况下，你需要确保你的训练、验证和测试分割之间没有任何意外的泄漏。以天气为例，你可能想确保你的训练分割只包含1980年至2004年的数据，验证数据为2005年至2010年，测试数据为2011年至2016年。这样，就不会发生意外的时空旅行，这将是一个重大的IID违规。
- en: 5.2.5  Comparing the schedules
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.5  比较计划
- en: 'Now that we have trained four common learning rate schedules, we can compare
    their results and see which performed best. The results are shown in the following
    plot, with the test accuracy on the y-axis. Some trends are quickly obvious and
    worth talking about. The vanilla SGD does fine but constantly fluctuates up and
    down from epoch to epoch. Every learning rate schedule we are looking at provides
    *some* kind of benefit:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练了四种常见的学习率调度，我们可以比较它们的结果，看看哪种表现最好。结果如下面的图表所示，测试精度在y轴上。一些趋势很快就会很明显，值得讨论。简单的SGD表现不错，但始终在epoch之间上下波动。我们正在查看的每个学习率调度都提供了一种*某种*好处：
- en: '[PRE16]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/CH05_UN08_Raff.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_UN08_Raff.png)'
- en: 'Exponential decay has the benefit of being *smooth and consistent*: from epoch
    to epoch, it has almost identical behavior. Unfortunately, it trends toward the
    lower side of accuracy and does a little worse than naive SGD. But consistency
    has value, and if we ended one epoch sooner, SGD would perform worse.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 指数衰减的好处是*平滑且一致*：从epoch到epoch，它几乎具有相同的行为。不幸的是，它趋向于精度较低的一侧，并且比简单的SGD表现略差。但一致性是有价值的，如果我们提前结束一个epoch，SGD的表现会更差。
- en: The `StepLR` schedule is very similar to the exponential one in behavior, with
    a bit more asperity in the beginning as it goes fast before slowing down and stabilizing
    later in training. This ends up on the higher end of SGD in performance.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`StepLR`的调度在行为上与指数调度非常相似，但在开始时由于快速增加而在后期减速并稳定，因此在训练的后期表现得更好。'
- en: The cosine schedule ultimately does even better, reaching the highest accuracy
    of naive SGD, `StepLR`, or exponential decay. About 27 epochs in, performance
    drops suddenly as the learning rate ramps back up; then performance restabilizes
    at a higher accuracy when the learning rate decays again. This is why I recommend
    setting the cosine approach so that it ends on a dip.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦调度最终表现得更好，达到了简单SGD、`StepLR`或指数衰减的最高精度。大约在27个epoch时，性能突然下降，因为学习率再次增加；然后当学习率再次衰减时，性能在更高的精度上重新稳定。这就是为什么我建议将余弦方法设置为以一个低谷结束。
- en: The Plateau approach also does a good job, and happens to just get second place
    in this set of tests. With more epochs, the Plateau would self-stabilize by dropping
    the learning rate further. Using feedback from how the model is actually doing,
    rather than assuming behavior, can help get every last bit of accuracy out of
    your model.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 平台期方法也做得很好，并且恰好在这个测试集中获得了第二名。随着epoch的增加，平台期会通过进一步降低学习率来自我稳定。使用模型实际表现的反馈，而不是假设行为，可以帮助从模型中获得最后一丝精度。
- en: Table 5.1 summarizes the pros and cons and when you might want to use each method.
    Unfortunately, no one size fits all, and each will have cases where it doesn’t
    pan out. That depends heavily on your data, and you won’t know until you train
    the data and find out. This is why I like to start with no learning rate schedule
    and then add one of these four based on what happens.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1总结了各种方法的优缺点以及何时可能需要使用每种方法。不幸的是，没有一种方法适合所有情况，每种方法都有可能不奏效的情况。这很大程度上取决于你的数据，你只有在训练数据并找出结果后才会知道。这就是为什么我喜欢从没有学习率调度开始，然后根据发生的情况添加这四种方法之一。
- en: Table 5.1 Flow `control` statements
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1 流程`控制`语句
- en: '|  | Exponential decay | StepLR | CosineLR | Plateau |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '|  | 指数衰减 | StepLR | 余弦LR | 平台期 |'
- en: '| Pros | Very consistentresults. Little tuningneeded. | Consistent results.
    Little tuning needed. Often improves accuracy. | Often improves accuracy. Advanced
    versions can significantly improve accuracy. | Often improves accuracy significantly
    and reduces epochs of training. |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 优点 | 结果非常一致。几乎不需要调整。 | 结果一致。几乎不需要调整。通常可以提高精度。 | 通常可以提高精度。高级版本可以显著提高精度。 |
    通常可以显著提高精度并减少训练的epoch数。 |'
- en: '| Cons | Can modestlyreduce final accuracy. | Most helpful when training for
    100+ epochs. | Requires someparameter tuning; doesn’t always work. | Not all data
    is used for training. More risk of overfitting. |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 优点 | 可以适度降低最终精度。 | 在训练100+个epoch时最有帮助。 | 需要一些参数调整；不一定总是有效。 | 并非所有数据都用于训练。过度拟合的风险更高。
    |'
- en: '| When to use | Training the same model, but with different initial weights,
    can give wildly different results. Exponential decay can help fix stabilize training.
    | You want toimprove your final model’s accuracy with minimal work. | You want
    to squeeze out maximum performance without too much extra work, and ideally you
    have enough time to do a few extra training runs. | You want to squeeze out maximum
    performance without too much extra work, and ideally you have a lot of data. |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 当何时使用 | 训练相同的模型，但使用不同的初始权重，可能会得到截然不同的结果。指数衰减可以帮助稳定训练。| 你希望以最少的努力提高最终模型的准确性。|
    你希望在不做太多额外工作的前提下，榨取最大性能，并且理想情况下你有足够的时间进行几次额外的训练。| 你希望在不做太多额外工作的前提下，榨取最大性能，并且理想情况下你有大量数据。|'
- en: Despite how well the plateau approach does, we won’t use it much in this book.
    Part of the reason is that it requires extra code that can be distracting when
    we are trying to focus on new concepts. Also, sometimes we will set up learning
    problems in a *specific* way so you see real-world behavior for problems that
    take only a few minutes to run instead of hours or more, and the plateau approach
    makes it harder to set up some of these scenarios. But these initial results show
    that you should keep it in mind as a powerful tool in your arsenal.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管平台方法表现良好，但我们在这本书中不会过多使用它。部分原因是它需要额外的代码，这可能会在我们试图关注新概念时分散注意力。此外，有时我们会以*特定*的方式设置学习问题，以便你看到仅需要几分钟而不是数小时或更长时间运行的实际问题行为，而平台方法使得设置这些场景变得更加困难。但这些初步结果表明，你应该将其作为你工具箱中一个强大的工具铭记在心。
- en: 5.3 Making better use of gradients
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 更好地利用梯度
- en: We now know several ways to alter the learning rate η to improve how quickly
    our model learns and allow it to learn more accurate solutions. We did this by
    defining different learning rate schedules *L*(⋅,⋅), which look at the long term.
    Think of *L*(⋅,⋅) as setting the desired speed for the journey. But detours, potholes,
    and other obstacles in the short term may require a change in speed. This is why
    we also want to modify the gradient g with a function *G*(⋅). We focus on gradient
    update schemes on their own first and then combine them with learning rate schedules
    to get improved results. First, we talk about some broad motivations and then
    dive into the most common approaches. All three approaches are one-line changes
    to your code with PyTorch (they are built in) and can dramatically improve the
    accuracy of your models.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在知道了几种方法可以改变学习率 η，以改善模型的学习速度，并允许它学习更准确的解决方案。我们通过定义不同的学习率计划 *L*(⋅,⋅)，这些计划着眼于长期。将
    *L*(⋅,⋅) 视为设定旅程的期望速度。但短期内的绕道、坑洼和其他障碍可能需要改变速度。这就是为什么我们还想用函数 *G*(⋅) 修改梯度 g。我们首先单独关注梯度更新方案，然后将它们与学习率计划结合起来以获得更好的结果。首先，我们讨论一些广泛的动机，然后深入探讨最常见的方法。这三种方法都是用
    PyTorch（它们是内置的）对代码进行一行更改，并且可以显著提高你模型的准确性。
- en: Remember that we are using **g**^t to indicate the tth gradient that we are
    receiving to update the network. Because we are doing stochastic gradient descent
    in batches, this is a noisy gradient. Even with the noise in **g**^t, there is
    valuable information in **g**^t that we are not fully utilizing. Consider the
    jth parameter’s gradient **g**[j]^t. What if it’s consistently almost the same
    value every time? Mathematically, that would be a situation where
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们使用 **g**^t 来表示我们用于更新网络的第 t 个梯度。因为我们是在批量中进行随机梯度下降，这是一个有噪声的梯度。即使在 **g**^t
    中存在噪声，**g**^t 中仍然有价值的信息我们没有充分利用。考虑第 j 个参数的梯度 **g**[j]^t。如果它每次都几乎保持相同的值呢？从数学上讲，这将是一个情况，其中
- en: '**g**[j]^t ≈ **g**[j]^(*t* − 1) ≈ **g**[j]^(*t* − 2) ≈ **g**[j]^(*t* − 3) ≈
    …'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**g**[j]^t ≈ **g**[j]^(*t* − 1) ≈ **g**[j]^(*t* − 2) ≈ **g**[j]^(*t* − 3) ≈
    …'
- en: This tells us the jth parameter needs to be moved in the same direction each
    time. Figure 5.11 shows such a situation.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们第 j 个参数需要每次都向同一方向移动。图 5.11 展示了这种情况。
- en: '![](../Images/CH05_F11_Raff.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F11_Raff.png)'
- en: Figure 5.11 Example where the gradient value could consistently return the same
    value over and over. We are heading on a direct path toward the solution, but
    we could get there faster if we used a larger learning rate.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 示例中，梯度值可能持续不断地返回相同的值。我们正在直接走向解决方案，但如果使用更大的学习率，我们可以更快地到达那里。
- en: We don’t necessarily want to increase the learning rate η, because other dimensions
    may have different behavior. Every network parameter gets its own gradient value,
    and networks can have millions of parameters. So if the gradient at index j is
    consistently the same, maybe we should be increasing how far we step (i.e., increase
    learning rate η) for *just* index j. We would need to ensure that this was done
    only with respect to index j, because the gradient for a different index i might
    not be as consistent.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不一定想增加学习率 η，因为其他维度可能有不同的行为。每个网络参数都得到其自己的梯度值，而网络可以有数百万个参数。所以如果索引 j 的梯度持续相同，我们可能应该增加我们迈出的距离（即增加学习率
    η）仅针对索引 j。我们需要确保这仅与索引 j 相关，因为不同索引 i 的梯度可能并不一致。
- en: So, we would like to have a global learning rate η and individualized learning
    rates *η*[j] for all of the parameters. While the global learning rate stays fixed
    (unless we use a learning rate schedule), we let some algorithms adjust each of
    the *η*[j] values to try to improve convergence. Most gradient update schemes
    work by rescaling the gradient **g**^t, which is equivalent to giving each parameter
    its own personalized learning rate *η*[j].
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们希望有一个全局学习率 η 和所有参数的个性化学习率 *η*[j]。当全局学习率保持固定（除非我们使用学习率计划）时，我们让一些算法调整每个 *η*[j]
    值，以尝试提高收敛性。大多数梯度更新方案通过重新缩放梯度 **g**^t 来工作，这相当于为每个参数提供其个性化的学习率 *η*[j]。
- en: '5.3.1  SGD with momentum: Adapting to gradient consistency'
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1  带有动量的 SGD：适应梯度一致性
- en: We want to increase the learning rate if the gradient for parameter j consistently
    heads in the same direction. We can describe this as wanting the gradient to build
    momentum. If the gradient in one direction keeps returning similar values, it
    should start taking bigger and bigger steps in the same direction. Figure 5.12
    shows an example problem that momentum can help fix.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果参数 j 的梯度持续指向同一方向，我们希望增加学习率。我们可以将这描述为希望梯度积累动量。如果在一个方向上的梯度持续返回相似值，它应该开始在该方向上迈出更大和更大的步伐。图
    5.12 展示了一个动量可以帮助解决的问题的例子。
- en: '![](../Images/CH05_F12_Raff.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F12_Raff.png)'
- en: Figure 5.12 The naive optimization is almost stuck oscillating between the top-left
    and bottom-right directions, but it is slowly and consistently making progress
    in the top-right direction that leads to the solution. If we could build some
    momentum in that direction, we would not need so many steps.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 原始优化几乎被困在左上角和右下角之间来回振荡，但它却在右上角缓慢而持续地取得进展，这有助于找到解决方案。如果我们能在那个方向上积累一些动量，我们就不需要那么多步骤。
- en: This momentum strategy was one of the first developed for improving SGD and
    solving the problem shown in the figure and is still widely used today. Let’s
    talk about the math of how it works.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这种动量策略是早期为改进 SGD 和解决图中显示的问题而开发的，至今仍被广泛使用。让我们谈谈它是如何工作的数学原理。
- en: 'Our normal gradient update equation, again, looks like this:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正常的梯度更新方程，再次，看起来是这样的：
- en: '*Θ*[*t* + 1] = *Θ*[t] − *η* ⋅ **g**^t'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '*Θ*[*t* + 1] = *Θ*[t] − *η* ⋅ **g**^t'
- en: 'The initial version of the momentum idea is to have a momentum weight μ, which
    has some value in the range (0,1) (i.e., *μ* ∈ (0,1)).[³](#fn11) Next, we add
    a velocity term called v, which accumulates our momentum. So our velocity v contains
    a fraction (μ) of our previous gradient step, as detailed in the following equation:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 动量思想的初始版本是拥有一个动量权重 μ，它在范围 (0,1) 内具有一些值（即 *μ* ∈ (0,1))[³](#fn11)。接下来，我们添加一个称为
    v 的速度项，它累积我们的动量。因此，我们的速度 v 包含了我们之前梯度步长的一部分（μ），具体细节如下面的方程所示：
- en: '![](../Images/ch5-eqs-to-illustrator5x.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ch5-eqs-to-illustrator5x.png)'
- en: 'Because our velocity depends on our previous velocity, it takes into account
    all of our previous gradient updates. Next, we simply use v in place of g to perform
    the gradient update:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们的速度依赖于我们之前的速度，它考虑了所有之前的梯度更新。接下来，我们简单地用 v 代替 g 来执行梯度更新：
- en: Θ^(*t* + 1) = Θ^t − **v**^(*t* + 1)
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Θ^(t + 1) = Θ^t − **v**(t + 1)
- en: The amazing shrinking history
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 惊人的缩小历史
- en: The equation for momentum relies heavily on the fact that μ is a value smaller
    than 1\. This is because it has a shrinking effect on old gradients. One way to
    look at this is to write out what happens to the equations as we repeatedly apply
    momentum. Let’s write this out in detail.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '动量方程高度依赖于 μ 是一个小于 1 的值这一事实。这是因为它对旧梯度有缩小作用。一种看待这个问题的方式是写出我们反复应用动量时方程的变化。让我们详细写出这一点。 '
- en: The following table shows what happens to the velocity v as we keep applying
    momentum μ. The left-most column is the new value of Θ, and we start with Θ[1]
    as the initial random weights. There is no previous velocity v yet, so nothing
    happens. Starting with the second round, we can expand the velocity term, as shown
    on the right.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了当我们持续应用动量 μ 时速度 v 发生的情况。最左边的列是新值 Θ，我们以 Θ[1] 作为初始随机权重开始。还没有之前的速度 v，所以没有发生任何变化。从第二轮开始，我们可以扩展速度项，如右图所示。
- en: '![](../Images/ch5-eqs-to-illustrator6x.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/ch5-eqs-to-illustrator6x.png)'
- en: Notice that every time we update with momentum, *every previous gradient* contributes
    to the current update! Also notice that the exponents above μ get larger every
    time we apply another round of momentum. This makes the contributions of very
    old gradients become essentially zero as we keep updating. If we use a standard
    momentum of *μ* = 0.9, old gradients contribute less than 0.01% of their value
    after just 88 updates. Since we often do thousands to hundreds of thousands of
    updates per epoch, this is a very short-term effect.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，每次我们用动量更新时，*每个以前的梯度* 都会对当前更新做出贡献！也请注意，每次我们应用另一轮动量时，μ 上方的指数都会变大。这使得非常旧的梯度的贡献在持续更新时几乎为零。如果我们使用标准的动量
    *μ* = 0.9，旧梯度在经过仅仅 88 次更新后，其贡献不到 0.01%。由于我们通常在每个 epoch 中进行数千到数百万次更新，这是一个非常短期的影响。
- en: 'You may look at the previous equations and be concerned: if we are taking into
    account all of our old gradients, what if some of them are no longer useful? That’s
    why we keep the momentum term *μ* ∈ (0,1). If we are currently at update t, and
    we think about the past gradient from k steps ago, its contribution is *μ*^k**g**^t,
    which quickly becomes small. If we have *μ* = 0.9, the gradient 40 steps ago is
    contributing a weight of only 0.9^(40) ≈ 0.01 to the current velocity v. The value
    μ helps us forget past gradients so that learning can adapt and is able to grow
    larger if we are always heading in the same direction.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会查看之前的方程并担心：如果我们考虑了所有的旧梯度，如果其中一些不再有用怎么办？这就是为什么我们保持动量项 *μ* ∈ (0,1)。如果我们目前处于更新
    t，并且考虑 k 步之前的过去梯度，其贡献是 *μ*^k**g**^t，这会迅速变得很小。如果我们有 *μ* = 0.9，40 步之前的梯度对当前速度 v
    的贡献仅为 0.9^(40) ≈ 0.01。值 μ 帮助我们忘记过去的梯度，以便学习可以适应，并且如果我们始终朝同一方向前进，学习可以增长得更大。
- en: This strategy is a simple way to significantly improve your model’s accuracy
    and training time. It can solve both problems we have looked at; figure 5.13 shows
    the solutions.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这种策略是显著提高你的模型精度和训练时间的一种简单方法。它可以解决我们查看的两个问题；图 5.13 展示了解决方案。
- en: '![](../Images/CH05_F13_Raff.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_F13_Raff.png)'
- en: Figure 5.13 On the left, momentum solves the problem of a small learning rate.
    The direction is consistent, so the momentum builds and increases the effective
    learning rate. On the right, the momentum builds consistently—but initially, slowly—in
    the top-right direction. The oscillation may continue, but fewer steps are needed
    to reach the minimum.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13 左边，动量解决了小学习率的问题。方向一致，因此动量积累并增加了有效学习率。右边，动量持续积累——但最初，在右上方向上缓慢积累。振荡可能会继续，但达到最小值所需的步骤更少。
- en: If you want to get the *best possible* accuracy from your network, SGD with
    some form of momentum is still considered one of the best options. The downside
    is that finding the combination of μ and η values that gives the *absolute best
    results* is not easy and requires training many models. We talk about smarter
    ways to search for μ and η in the last section of this chapter.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要从你的网络中获得 *最佳可能* 的精度，使用带有某种形式的动量的 SGD 仍然被认为是最佳选择之一。缺点是找到给出 *绝对最佳结果* 的 μ
    和 η 值的组合并不容易，并且需要训练许多模型。我们将在本章的最后部分讨论更智能地搜索 μ 和 η 的方法。
- en: 'Nesterov momentum: Adapting to changing consistency'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Nesterov 动量：适应变化的一致性
- en: A second flavor of momentum exists and is worth mentioning, as it often performs
    better in practice. This version is called *Nesterov momentum*.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 存在第二种动量类型，并且值得提及，因为它在实践中通常表现更好。这种版本被称为 *Nesterov 动量*。
- en: In normal momentum, we take the gradient with respect to the current weights
    (that is, **g**^t) and then move in the direction of our gradient and velocity
    combined. If we have built up a *lot* of momentum, it can be difficult to make
    turns during the optimization. Let’s look at a toy example of what can go wrong
    in figure 5.14.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规动量中，我们取当前权重（即 **g**^t）的梯度，然后朝着我们的梯度与速度结合的方向移动。如果我们积累了大量的动量，在优化过程中进行转弯可能会很困难。让我们看看图
    5.14 中可能出现的错误示例。
- en: '![](../Images/CH05_F14_Raff.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F14_Raff.png)'
- en: Figure 5.14 Imagine that it has taken a long time to reach this point, so the
    optimizer has built up a large momentum (i.e., ∥**v**^t∥[2] > 0). When we reach
    the purple point, the momentum causes us to swerve *around* the desired area because
    the momentum, even after decay, is larger than the gradient. Since it is larger,
    it carries the weights more in the same direction rather than a new direction.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.14 想象一下，到达这个点已经花费了很长时间，因此优化器已经积累了大量的动量（即 ∥**v**^t∥[2] > 0）。当我们到达紫色点时，动量使我们绕着期望的区域
    *转弯*，因为动量，即使在衰减后，也大于梯度。由于它更大，它将权重更多地保持在同一方向，而不是新的方向。
- en: 'Technically, this problem shows momentum behaving correctly: the momentum is
    carrying *Θ*[*t* + 1] in a consistent direction. It’s just not a good idea anymore,
    and it will take a few iterations for the momentum to be corrected and start heading
    toward the actual solution.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上来说，这个问题展示了动量表现正确：动量以一致的方向携带 *Θ*[*t* + 1]。但这已经不再是一个好主意了，需要经过几次迭代才能纠正动量并开始朝向实际解的方向前进。
- en: In Nesterov momentum, we instead decide to be patient. Normal momentum at step
    t immediately calculates the new gradient **g**^t and adds the velocity **v**^t.
    Nesterov first acts on the velocity and *then* calculates a new gradient *after*
    letting the momentum move us. This way, if we are moving in the *wrong* direction,
    Nesterov will likely have a larger gradient to push us back in the correct direction
    sooner. This looks like the following sequence of equations, where I’m using *t*′
    to denote the patient steps.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Nesterov 动量中，我们选择耐心等待。在步骤 t 时，正常动量立即计算新的梯度 **g**^t 并将速度 **v**^t 相加。Nesterov
    首先对速度进行操作，然后在我们移动后计算一个新的梯度。这样，如果我们移动的方向是错误的，Nesterov 很可能有一个更大的梯度来更快地将我们推回正确的方向。这看起来像以下的一系列方程，其中我使用
    *t*′ 来表示耐心步骤。
- en: 'First we compute *Θ*^(*t*′) based only on the previous velocity. We don’t look
    at the new data yet, meaning this could be a bad direction if things are changing
    (or it could be good—we don’t know because we haven’t looked at the data):'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们仅基于之前的速度计算 *Θ*^(*t*′)。我们还没有查看新数据，这意味着如果情况发生变化（或者这可能是个好方向——我们不知道，因为我们还没有查看数据）：
- en: '![](../Images/ch5-eqs-to-illustrator7x.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ch5-eqs-to-illustrator7x.png)'
- en: 'Second, we finally look at the new data x using our modified weights *Θ*^(*t*′).
    This is like peeking at the near future so we can change or correct our answer
    about how we want to update the parameters. If the velocity was in the correct
    direction, nothing really changes. But if the velocity was going to take us in
    a bad direction, we can change course and counteract the effect more quickly:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，我们最终使用修改后的权重 *Θ*^(*t*′) 来查看新的数据 x。这就像窥视近未来，以便我们可以改变或纠正我们关于如何更新参数的答案。如果速度在正确的方向上，实际上没有什么变化。但如果速度将带我们走向错误的方向，我们可以改变航向并更快地抵消这种影响：
- en: '![](../Images/ch5-eqs-to-illustrator8x.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ch5-eqs-to-illustrator8x.png)'
- en: 'Finally, we modify *Θ*^(*t*′) again using the new velocity that contains the
    fresh gradient, giving us the ultimate updated weights *Θ*^(*t* + 1):'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们再次使用包含新鲜梯度的新的速度来修改 *Θ*^(*t*′)，从而得到最终的更新权重 *Θ*^(*t* + 1)：
- en: '![](../Images/ch5-eqs-to-illustrator9x.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ch5-eqs-to-illustrator9x.png)'
- en: 'To recap: the first equation alters the parameters Θ based on *only* the current
    velocity (no new batch and no new information). The second equation computes a
    *new* velocity using the old velocity and the gradient *after* having altered
    Θ from the first equation. Finally, the third equation takes a step based on these
    results. While this looks like extra work, there is a clever way to organize it
    so that it takes exactly the same amount of time as normal momentum (which we
    won’t go into because it’s a little confusing). Figure 5.15 shows how Nesterov
    momentum affects the previous example.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下：第一个方程根据 *仅* 当前的速度（没有新的批次和新的信息）来改变参数 Θ。第二个方程使用旧速度和经过第一个方程改变 Θ 后的梯度来计算一个新的速度。最后，第三个方程根据这些结果进行一步操作。虽然这看起来像是额外的工作，但有一种巧妙的方法可以组织它，使其所需的时间与正常动量（我们不会深入讨论，因为它有点复杂）完全相同。图
    5.15 展示了 Nesterov 动量如何影响前面的例子。
- en: '![](../Images/CH05_F15_Raff.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F15_Raff.png)'
- en: Figure 5.15 At the same purple point, the right side shows how the update is
    calculated. Instead of computing **g**^t at the starting point, we first follow
    the momentum, which is in the *wrong* direction. This causes the gradient at this
    new location to be larger back in the *correct* direction. Combined, we get a
    smaller step that is closer to the solution. The original standard momentum result
    is shown faded in black.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.15 在相同的紫色点上，右侧显示了更新是如何计算的。我们不是在起点计算 **g**^t，而是首先跟随动量，这是*错误*的方向。这导致在新位置处的梯度在*正确*的方向上更大。结合起来，我们得到一个更接近解的更小步长。原始的标准动量结果以黑色淡出显示。
- en: Let’s reason through another scenario to exercise our mental model of what is
    happening. Try drawing a diagram of this yourself to help you follow along.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过另一个场景来推理，以锻炼我们对正在发生的事情的心理模型。试着自己画一个图来帮助你理解。
- en: Consider the standard momentum case where our momentum has been useful, allowing
    us to head in the correct direction, and assume that we have just reached our
    goal. We are at the function’s minimum, and the problem is solved. But, *we don’t
    ever know for sure that we are at the minimum*, so we run the next step of the
    optimization process. Because of the momentum we have built up, we are about to
    roll past the minimum. In normal momentum, we compute the gradient—and if we are
    at the solution, the gradient **g**^t = 0, so there is no change. Then we add
    the velocity **v**^t, and it carries us away.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑标准动量情况，我们的动量已经很有用，使我们能够朝正确的方向前进，并假设我们已经达到了目标。我们现在处于函数的最小值，问题已经解决。但是，*我们永远无法确定我们是否处于最小值*，所以我们运行优化过程的下一步。由于我们已经积累的动量，我们即将滚过最小值。在正常动量中，我们计算梯度——如果我们处于解的位置，梯度
    **g**^t = 0，因此没有变化。然后我们添加速度 **v**^t，它将我们带离。
- en: Now, think about this scenario under Nesterov momentum. We are at the solution,
    and first we follow the velocity, pushing us away from the goal. Then we calculate
    the gradient, which recognizes that we need to head back in the opposite direction
    and thus move toward the goal. When we add these two together, they almost cancel
    out (we take a smaller step forward or backward, depending on which has a larger
    magnitude, **g**^t or **v**^t). In one step, we have started to change the direction
    in which our optimizer is headed, whereas normal momentum would take two steps.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑在 Nesterov 动量下的这种场景。我们处于解的位置，首先我们跟随速度，将我们推向目标之外。然后我们计算梯度，它认识到我们需要朝相反的方向前进，因此朝向目标移动。当我们把这两个结合起来时，它们几乎相互抵消（我们向前或向后迈出更小的一步，具体取决于哪个的幅度更大，**g**^t
    或 **v**^t）。在一步之内，我们已经开始改变我们的优化器前进的方向，而正常动量则需要两步。
- en: This is the intuition and reasoning for why Nesterov momentum is usually the
    preferred version of momentum. Now that we’ve talked about the ideas, we can turn
    them into code. The `SGD` class simply requires us to set the `momentum` flag
    to a nonzero value if we would like momentum and `nesterov=True` if we want it
    to be Nesterov momentum. The following code trains our network with both versions.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么 Nesterov 动量通常是首选动量版本的原因。现在我们已经讨论了这些想法，我们可以将它们转化为代码。`SGD` 类只需要我们设置 `momentum`
    标志为一个非零值，如果我们想要动量，并且 `nesterov=True` 如果我们想要它是 Nesterov 动量。以下代码使用两种版本训练我们的网络。
- en: '[PRE17]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Comparing SGD with momentums
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 比较带有动量的 SGD
- en: 'Here we plot the results from vanilla SGD and both flavors of momentum. Both
    momentum versions perform dramatically better, learning faster and giving more
    accurate solutions. But you won’t usually see one version of momentum perform
    dramatically better or worse than the other. While Nesterov does solve a real
    problem, normal momentum will *eventually* correct itself after more gradient
    updates. Still, I prefer to use the Nesterov flavor because in my experience,
    if one momentum is better by a nontrivial amount, it is usually Nesterov:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们绘制了 vanilla SGD 和两种动量版本的结果。两种动量版本都表现出显著更好的性能，学习速度更快，给出的解更准确。但你通常不会看到动量的一种版本比另一种版本表现得更好或更差。虽然
    Nesterov 解决了一个实际问题，但正常动量在更多梯度更新后最终会自行纠正。然而，我更喜欢使用 Nesterov 版本，因为在我的经验中，如果一个动量比另一个好很多，通常就是
    Nesterov：
- en: '[PRE18]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/CH05_UN09_Raff.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_UN09_Raff.png)'
- en: '5.3.2  Adam: Adding variance to momentum'
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2  Adam：向动量添加方差
- en: 'One of the currently most popular optimization techniques is called *adaptive
    moment estimation*, or Adam for short. Adam is strongly related to the SGD with
    momentum that we just described. Adam is my current favorite approach because
    it has default parameters that just work, so I don’t have to spend time tuning
    them. This is not true for SGD with momentum (normal or Nesterov flavored). We
    have to rename a few terms to make the math consistent with how you will read
    about it elsewhere: the velocity v becomes m, and the momentum weight μ becomes
    *β*[1]. Now we can describe the first step of Adam, which has one major change
    shown in red:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 目前最受欢迎的优化技术之一被称为 *自适应矩估计*，简称 Adam。Adam 与我们刚刚描述的带有动量的 SGD 密切相关。Adam 是我目前最喜欢的方案，因为它有默认参数，直接使用，所以我无需花时间调整它们。对于带有动量的
    SGD（普通或 Nesterov 风味）则不是这样。我们必须重命名一些术语，以便使数学与你将在其他地方了解的方式一致：速度 v 变为 m，动量权重 μ 变为
    *β*[1]。现在我们可以描述 Adam 的第一步，其中有一个主要的变化用红色标出：
- en: '![](../Images/ch5-eqs-to-illustrator10x.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ch5-eqs-to-illustrator10x.png)'
- en: This describes the momentum update equation, but we are now down-weighting the
    *current* gradient **g**^t by (1 − *β*[1]). This makes **m**^t a *weighted average*
    between the previous velocity and the current gradient. More specifically, because
    we added the (1−*β*[1]) term, this is now called an *exponential moving average*.
    It’s called *exponential* because the gradient from z steps ago **g**^(*t* − *z*)
    has an exponentiated contribution of *β*[1]^z, and it’s a *moving average* because
    it is computing a kind of weighted average where most of the weight is on the
    most recent items, so the average moves with the most recent data.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这描述了动量更新方程，但现在我们正在通过 (1 − *β*[1]) 对 *当前* 梯度 **g**^t 进行降权。这使得 **m**^t 成为先前速度和当前梯度的
    *加权平均*。更具体地说，因为我们添加了 (1−*β*[1]) 项，现在这被称为 *指数移动平均*。它被称为 *指数*，因为 z 步之前的梯度 **g**^(*t*
    − *z*) 有一个指数化的贡献 *β*[1]^z，它被称为 *移动平均*，因为它计算的是一种加权平均，其中大部分权重在最近的项上，所以平均随着最近的数据移动。
- en: Since we are now discussing momentum as an *average* or *mean* gradient over
    multiple updates, we can talk about the *variance* of the gradient as well. If
    one parameter *g*[j]^t has high variance, we probably don’t want to let it contribute
    too much to the momentum because it will likely change again. If a parameter *g*[j]^t
    has *low* variance, it’s a reliable direction to head in, so we should give it
    *more* weight in the momentum calculation.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们现在讨论的是多个更新过程中的 *平均* 或 *均值* 梯度，我们可以谈论梯度的 *方差*。如果一个参数 *g*[j]^t 具有高方差，我们可能不希望让它对动量贡献太多，因为它很可能会再次改变。如果一个参数
    *g*[j]^t 具有低方差，它是一个可靠的方向，因此我们应该在动量计算中给它 *更多* 的权重。
- en: 'To implement this idea, we can calculate information about the variance over
    time by looking at squared gradient values. Normally, for variance, we would subtract
    the mean before squaring, but that is hard to do in this scenario. So we use the
    squared values as an *approximation* of the variance and keep in mind that it
    does not provide perfect information. Using ⊙ to denote the elementwise multiplication
    between two vectors (**a** ⊙ **b** = [*a*[1]⋅*b*[1],*a*[2]⋅*b*[2],…]) leads to
    this equation for variance of velocity v:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这个想法，我们可以通过观察梯度的平方值来计算随时间变化的信息方差。通常，对于方差，我们会在平方之前减去平均值，但在这个场景中这样做很困难。因此，我们使用平方值作为方差的近似，并记住它并不提供完美的信息。使用
    ⊙ 表示两个向量之间的逐元素乘积（**a** ⊙ **b** = [*a*[1]⋅*b*[1],*a*[2]⋅*b*[2],…])，可以得到速度方差 v 的这个方程：
- en: '![](../Images/ch5-eqs-to-illustrator11x.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ch5-eqs-to-illustrator11x.png)'
- en: We save **m**^t and **v**^t, but we perform one more alteration before using
    them. Why? Because when we are early in the optimization process, meaning t is
    a small value, **m**^t and **v**^t give us biased estimates of the mean and variance.
    They are biased because they are initialized to zero (i.e., **m**⁰ = **v**⁰ =
    ![](../Images/vec_0.png)), so the early estimates will be *too small* if we use
    them naively.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们保存 **m**^t 和 **v**^t，但在使用它们之前进行一次修改。为什么？因为我们处于优化过程的早期，意味着 t 是一个小的值，**m**^t
    和 **v**^t 给出的均值和方差的估计是有偏的。它们是有偏的，因为它们被初始化为零（即 **m**⁰ = **v**⁰ = ![](../Images/vec_0.png))，所以如果我们天真地使用它们，早期的估计将会
    *太小*。
- en: 'Think about when *t* = 1. In that case, the value of **m**¹ = (1−*β*[1]) ⋅
    **g**. The true average is just g, but instead we have discounted it by a factor
    of 1 − *β*[1]. To fix this, we just adjust as so:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑当 *t* = 1 时的情况。在这种情况下，**m**¹ = (1−*β*[1]) ⋅ **g**。真正的平均值只是 g，但我们通过一个因子 1 −
    *β*[1] 对其进行了折价。为了解决这个问题，我们只需进行如下调整：
- en: '![](../Images/CH05_F15_Raff_EQ01.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_F15_Raff_EQ01.png)'
- en: 'Now we have m̂ and v̂, which give us the unbiased estimates of the mean and
    variance, respectively, and we use them together to update our weights Θ:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了 m̂ 和 v̂，它们分别给出了均值和无偏估计的方差，我们将它们一起用来更新我们的权重 Θ：
- en: '![](../Images/CH05_UN10_Raff.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_UN10_Raff.png)'
- en: What is going on here? The numerator *η* ⋅ *m̂* is computing the SGD with momentum
    term, but now we are normalizing each dimension by the variance. That way, if
    a parameter has naturally large swings in its value, we won’t adjust as quickly
    to a new large swing—because it usually is quite noisy. If a parameter usually
    has a small variance and is very consistent, we adapt quickly to any observed
    change. The ϵ term is a very small value so we never end up dividing by zero.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生了什么？分子 *η* ⋅ *m̂* 正在计算带有动量项的 SGD，但现在我们正在通过方差对每个维度进行归一化。这样，如果一个参数的值自然波动很大，我们不会那么快地调整到新的大幅波动——因为它通常相当嘈杂。如果一个参数通常具有很小的方差并且非常一致，我们就会快速适应任何观察到的变化。ϵ
    项是一个非常小的值，所以我们永远不会除以零。
- en: 'That gives you the intuition behind Adam. The original authors proposed using
    the following values: *η* = 0.001, *β*[1] = 0.9, *β*[2] = 0.999, and *ϵ* = 10^(−8).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 Adam 的直觉。原始作者提出了以下值：*η* = 0.001，*β*[1] = 0.9，*β*[2] = 0.999，和 *ϵ* = 10^(-8)。
- en: Personally, I recommend using Adam or one of its descendants as the default
    choice for any optimization problem. Why? Because it’s an optimizer that, using
    the default values, usually performs well with no further alteration. It may not
    get you the *best possible* performance, and you can often improve results by
    adjusting the parameters, but the defaults usually work well. And if they don’t
    work, other parameter settings usually won’t, either.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 个人而言，我推荐将 Adam 或其衍生版本作为任何优化问题的默认选择。为什么？因为它是一个优化器，使用默认值通常表现良好，无需进一步调整。它可能不会给你带来
    *最佳可能* 的性能，但你通常可以通过调整参数来提高结果，但默认值通常效果不错。而且如果它们不起作用，其他参数设置通常也不会起作用。
- en: 'Most optimizers don’t share this property, or not to the degree that Adam exhibits
    it. For example, SGD is very sensitive to the momentum and learning rate terms,
    and you usually need to do some tuning to get good performance out of normal SGD.
    Since Adam does not *require* this finicky tuning, you don’t have to do as much
    experimentation to figure out what works. Thus, you can save a detailed optimization
    process until after you have settled on your final architecture and are ready
    to squeeze out every last drop of accuracy. Ultimately, this makes Adam a great
    time saver: spend the time on your architecture, and leave the optimizer changes
    for the end.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数优化器都不具备这种属性，或者至少没有 Adam 表现得那么明显。例如，SGD 对动量和学习率项非常敏感，你通常需要进行一些调整才能从正常的 SGD
    中获得良好的性能。由于 Adam 不 *需要* 这种挑剔的调整，你不需要进行太多的实验来找出什么有效。因此，你可以在确定最终架构并准备好榨取最后一点精度之前，先保存一个详细的优化过程。最终，这使得
    Adam 成为一个节省时间的好方法：在架构上花时间，将优化器的调整留到最后。
- en: Other flavors of Adam
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: Adam 的其他版本
- en: The original paper for the Adam algorithm contained a mistake, but the proposed
    algorithm still worked well for the vast majority of problems. A version that
    fixes this mistake is called `AdamW` and is the default we use in this book.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Adam 算法的原始论文中包含了一个错误，但提出的算法仍然对绝大多数问题表现良好。修复这个错误的版本被称为 `AdamW`，并且是我们在这本书中使用的默认版本。
- en: Another extension of Adam is NAdam, where the *N* stands for Nesterov. As you
    might guess, this version adapts Adam to use Nesterov momentum rather than standard
    momentum. A third flavor is AdaMax, which replaces some of the multiplication
    operations in Adam with max operations to improve the algorithm’s numerical stability.
    All of these flavors have pros and cons that are beyond the scope of this book,
    but any Adam variant will serve you well.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: Adam 的另一个扩展是 NAdam，其中 *N* 代表 Nesterov。正如你可能猜到的，这个版本将 Adam 调整为使用 Nesterov 动量而不是标准动量。第三种版本是
    AdaMax，它用 max 操作替换了 Adam 中的一些乘法操作，以提高算法的数值稳定性。所有这些版本都有其优缺点，但这本书的范围之外，但任何 Adam
    变体都会为你服务得很好。
- en: 'Now that we have learned about Adam, let’s try it. The following code again
    resets the weights for the neural network we have been training over and over,
    but using `AdamW` this time:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 Adam，让我们试试它。以下代码再次重置了我们反复训练的神经网络的权重，但这次使用 `AdamW`：
- en: '[PRE19]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ We don’t set the learning rate for Adam because you should always use the
    default, and Adam can be more sensitive to large changes in the learning rate.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们不设置 Adam 的学习率，因为您应该始终使用默认值，并且 Adam 对学习率的较大变化更为敏感。
- en: 'Now we can plot `AdamW` along with the three versions of SGD we have already
    looked at. The result shows that AdamW performs as well as SGD with either flavor
    of momentum, but its behavior is a bit more stable when the dips down are not
    as frequent or dramatic:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以绘制 `AdamW` 以及我们之前已经查看的三个 SGD 版本。结果显示，AdamW 在具有动量两种风格的 SGD 中的表现一样好，但其行为在下降不那么频繁或剧烈时更为稳定：
- en: '[PRE20]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](../Images/CH05_UN11_Raff.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH05_UN11_Raff.png)'
- en: 'We can also combine these new optimizers with the learning rate schedules we
    have learned about. Here, we train Adam and SGD with Nesterov momentum combined
    with the cosine annealing schedule:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将这些新的优化器与我们所学到的学习率计划相结合。在这里，我们使用 Nesterov 动量结合余弦退火计划来训练 Adam 和 SGD：
- en: '[PRE21]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Adam with cosine annealing
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 带有余弦退火的 Adam
- en: ❶ SGD+Nesterov with cosine annealing
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 带有余弦退火的 SGD+Nesterov
- en: 'Now we can compare the results with and without the cosine schedule in the
    following code and plot. Again we see a similar trend, that adding the learning
    rate schedule gives a bump to accuracy and that the version with `AdamW` is *slightly*
    better behaved:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以比较以下代码和图中带有和没有余弦计划的比较结果。我们再次看到相似的趋势，即添加学习率计划会给准确度带来提升，并且带有 `AdamW` 的版本表现得更稳定：
- en: '[PRE22]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](../Images/CH05_UN12_Raff.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH05_UN12_Raff.png)'
- en: '5.3.3  Gradient clipping: Avoiding exploding gradients'
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.3 梯度裁剪：避免梯度爆炸
- en: 'We have one last trick to talk about, which is compatible with both optimizers
    like Adam and SGD as well as learning rate schedules. It is called *gradient clipping*,
    and it helps us solve the exploding gradient problem. Unlike all the mathematical
    intuition and logic that went into everything we have discussed so far, gradient
    clipping is refreshingly simple: if any (absolute) value in a gradient is larger
    than some threshold z, just set it to a maximum value of z. So if we use *z* =
    5 and our gradient is **g** = [1,−2,1000,3,−7], the clipped version becomes clip[5](**g**)
    = [1,−2,5,3,−5]. The idea is that any value larger than our threshold z clearly
    indicates the *direction*; but it is set to an unreasonable *distance*, so we
    forcibly clip it to something reasonable.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有一个技巧要讨论，它与 Adam 和 SGD 这样的优化器以及学习率计划都兼容。它被称为 *梯度裁剪*，它帮助我们解决梯度爆炸问题。与迄今为止我们所讨论的所有内容中的数学直觉和逻辑不同，梯度裁剪非常简单：如果梯度的任何（绝对）值大于某个阈值
    z，只需将其设置为 z 的最大值。所以如果我们使用 *z* = 5，我们的梯度是 **g** = [1,−2,1000,3,−7]，裁剪后的版本变为 clip[5](**g**)
    = [1,−2,5,3,−5]。其想法是，任何大于我们的阈值 z 的值明显表明了 *方向*；但它被设置为不合理的 *距离*，所以我们强制将其裁剪为合理的值。
- en: 'The following code shows how to add gradient clipping to any neural network.
    We grab the parameters Θ using the `model.parameters()` function and use `register_hook`
    to register a callback that is executed every time the gradients are used. In
    this case, we simply take the tensor `grad` that represents the gradients and
    use the `clamp` function that returns a new version of `grad` where nothing is
    smaller than `-5` or larger than `5`. That’s all it takes:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何将梯度裁剪添加到任何神经网络中。我们使用 `model.parameters()` 函数获取参数 Θ，并使用 `register_hook`
    注册一个在每次使用梯度时执行的回调。在这种情况下，我们简单地取表示梯度的张量 `grad` 并使用 `clamp` 函数，该函数返回一个新版本的 `grad`，其中没有任何值小于
    `-5` 或大于 `5`。就这么简单：
- en: '[PRE23]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Plotting the results, you see that they are *usually* the same. In this case,
    they are a little worse, but they could have been better, instead. It depends
    on the problem:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制结果，您会发现它们通常是一样的。在这种情况下，它们稍微差一点，但本可以更好。这取决于问题：
- en: '[PRE24]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](../Images/CH05_UN13_Raff.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH05_UN13_Raff.png)'
- en: Exploding gradients are usually a *catastrophic* problem. If your model has
    them, it’s probably learning a degenerate solution or not converging at all. Since
    this dataset and network don’t have that problem, gradient clipping isn’t beneficial.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度爆炸通常是一个 *灾难性的* 问题。如果你的模型有这个问题，它可能是在学习一个退化的解或者根本不收敛。由于这个数据集和网络没有这个问题，梯度裁剪并不有益。
- en: In most applications, I don’t use gradient clipping unless my models are not
    learning well to begin with. If they learn well, I probably don’t have exploding
    gradients, so I focus on other changes. If the model isn’t good, I test gradient
    clipping to see if that fixes the problem. If I’m working with recurrent neural
    networks, I *always* use gradient clipping because the recurrent connections tend
    to cause exploding gradients, making them a common issue in that scenario. But
    if you want to always include clipping, doing so is an equally valid strategy.
    Using a clip value of *z* = 5 or *z* = 10 is common and works well for most problems.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数应用中，除非我的模型一开始就学不好，否则我不会使用梯度裁剪。如果它们学得很好，我可能不会有爆炸性梯度，所以我专注于其他变化。如果模型不好，我会测试梯度裁剪，看看是否能解决这个问题。如果我正在处理循环神经网络，我*总是*使用梯度裁剪，因为循环连接往往会引起爆炸性梯度，这在那种情况下是一个常见问题。但如果你想要始终包含裁剪，这样做也是一个同样有效的策略。使用裁剪值
    *z* = 5 或 *z* = 10 是常见的，并且对大多数问题都有效。
- en: 5.4 Hyperparameter optimization with Optuna
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 使用 Optuna 进行超参数优化
- en: 'Now that we have improved how to do training, we will reuse many of these techniques
    throughout the book because they are useful for *any and every* neural network
    you will ever train. The improvements so far have focused on optimizing when we
    have gradients. But hyperparameters are things we would like to optimize for which
    we do not have any gradients, such as the initial learning rate η to use and the
    value of the momentum term μ. We would also like to optimize the architecture
    of our networks: should we use two layers or three? How about the number of neurons
    in each hidden layer?'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经改进了训练方法，我们将在整本书中重用许多这些技术，因为它们对*任何和每一个*你将要训练的神经网络都很有用。到目前为止的改进主要集中在我们在有梯度时进行优化。但超参数是我们想要优化但没有梯度的事物，例如要使用的初始学习率
    η 和动量项 μ 的值。我们还想优化我们网络的架构：我们应该使用两层还是三层？每个隐藏层的神经元数量又是多少？
- en: The first hyperparameter tuning method most people learn in machine learning
    is called *grid search*. While valuable, grid search works well only for optimizing
    one or two variables at a time due to its exponential cost as more variables are
    added. When training a neural network, we usually have at least three parameters
    we want to optimize (number of layers, number of neurons in each layer, and learning
    rate η). We instead use a newer approach—Optuna—to tuning hyperparameters, which
    works much better. Unlike grid search, it requires fewer decisions, finds better
    parameter values, can handle more hyperparameters, and can be adapted to your
    computational budget (i.e., how long you are willing to wait).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中大多数人首先学习的超参数调整方法是称为*网格搜索*。虽然很有价值，但由于其随着变量增加而呈指数增长的代价，网格搜索一次只能优化一个或两个变量。在训练神经网络时，我们通常至少有三个参数想要优化（层数、每层的神经元数量和学习率
    η）。我们改用一种更新的方法——Optuna——来调整超参数，它效果更好。与网格搜索不同，它需要的决策更少，能找到更好的参数值，可以处理更多的超参数，并且可以适应你的计算预算（即你愿意等待多长时间）。
- en: With all that said, hyperparameter tuning is still very expensive, and these
    examples can’t run in a few minutes because they require training tens of models.
    In the real world, there could even be hundreds of models. This makes Optuna impractical
    for use in future chapters because we do not have the time, but using it is still
    a critical skill for you to know.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，超参数调整仍然非常昂贵，这些示例不能在几分钟内运行，因为它们需要训练数十个模型。在现实世界中，甚至可能有数百个模型。这使得 Optuna 在未来章节中的应用变得不切实际，因为我们没有时间，但了解它仍然是你需要掌握的关键技能。
- en: 5.4.1  Optuna
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.1 Optuna
- en: 'To perform a smarter type of hyperparameter optimization, we use a library
    called Optuna. Optuna can be used with any framework, as long as you can describe
    the goal as a single numeric value. Luckily for us, we have the accuracy or error
    as our goal, so we can use Optuna. Optuna does a better job of hyperparameter
    optimization by using a Bayesian technique to model the hyperparameter problem
    as its own machine learning task. We could spend a whole chapter (or more) on
    the technical details of how Optuna works: in short, it trains its own machine
    learning algorithm to predict a model’s accuracy (the label) based on its hyperparameters
    (the features). Optuna then sequentially tries new models based on what it predicts
    to be good hyperparameters, trains the model to find out how well it did, adds
    that information to improve the model, and then selects a new guess. But for now,
    let’s focus on how to use Optuna as a tool.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行一种更智能的超参数优化类型，我们使用一个名为 Optuna 的库。只要您可以将目标描述为一个单一的数值，Optuna 就可以与任何框架一起使用。幸运的是，我们有准确度或误差作为我们的目标，因此我们可以使用
    Optuna。Optuna 通过使用贝叶斯技术将超参数问题建模为其自己的机器学习任务，从而在超参数优化方面做得更好。我们本可以花整整一章（或更多）来详细说明
    Optuna 的工作原理的技术细节：简而言之，它训练自己的机器学习算法来根据其超参数（特征）预测模型的准确度（标签）。然后 Optuna 根据它预测为良好的超参数顺序尝试新的模型，训练模型以了解其表现如何，将此信息添加到模型中以提高模型，然后选择一个新的猜测。但就目前而言，让我们专注于如何将
    Optuna 作为工具使用。
- en: To start, let’s see a little about how Optuna works. Similar to PyTorch, it
    has a “define by run” concept. For Optuna, we define a function that we want to
    minimize (or maximize), which takes as input a `trial` object. This `trial` object
    is used to get `guesses` for each parameter we want to tune and returns a score
    at the end. The returned values are floats and integers, just as we would use
    ourselves, making it easy to use. Figure 5.16 shows how this works.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们简要了解一下 Optuna 的工作原理。类似于 PyTorch，它有一个“通过运行定义”的概念。对于 Optuna，我们定义一个函数，我们希望最小化（或最大化），该函数接受一个
    `trial` 对象作为输入。这个 `trial` 对象用于获取我们想要调整的每个参数的“猜测”，并在结束时返回一个分数。返回的值是浮点数和整数，就像我们亲自使用的那样，这使得它很容易使用。图
    5.16 展示了这是如何工作的。
- en: '![](../Images/CH05_F16_Raff.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F16_Raff.png)'
- en: Figure 5.16 You supply Optuna with a function that does the three steps outlined
    in this diagram. Optuna uses its own algorithm to pick values for each hyperparameter,
    which you tell Optuna about using the `trial.suggest` functions; this function
    also informs Optuna about the minimum and maximum values you want to consider.
    You tell Optuna how many times to do this process, and each time it does, the
    black box gets better at picking new values to try.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.16 您为 Optuna 提供一个函数，该函数执行图中概述的三个步骤。Optuna 使用自己的算法为每个超参数选择值，您可以使用 `trial.suggest`
    函数告诉 Optuna 关于这些超参数的信息；此函数还告知 Optuna 您希望考虑的最小值和最大值。您告诉 Optuna 进行此过程多少次，每次执行时，黑盒都会在挑选新值尝试时变得更好。
- en: 'Let’s look at a toy function that we want to minimize: *f*(*x*,*y*) = abs ((*x*−3)⋅(*y*+2)).
    It’s easy to tell that one minimum exists at *x* = 3 and *y* = − 2. But can Optuna
    figure that out? First we need to import the Optuna library, which is a simple
    `pip` command:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们想要最小化的玩具函数：*f*(*x*,*y*) = abs ((*x*−3)⋅(*y*+2))。很容易看出，存在一个最小值在 *x* =
    3 和 *y* = − 2。但 Optuna 能否找出这个值？首先，我们需要导入 Optuna 库，这是一个简单的 `pip` 命令：
- en: '[PRE25]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now we can import Optuna:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以导入 Optuna：
- en: '[PRE26]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Next we need to define the function to be minimized. `toyFunc` takes in the
    `trial` object. Optuna figures out how many hyperparameters exist by means of
    us using the `trial` object to obtain a guess for each parameter. This happens
    with the `suggest_uniform` function, which requires us to provide a range of possible
    values (something we must do for any hyperparameter optimization approach):'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要定义要最小化的函数。`toyFunc` 接收一个 `trial` 对象。Optuna 通过使用 `trial` 对象获取每个参数的猜测来确定存在多少个超参数。这是通过
    `suggest_uniform` 函数完成的，该函数要求我们提供一个可能的值范围（我们必须为任何超参数优化方法做这件事）：
- en: '[PRE27]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ These two calls ask Optuna for two parameters and define the minimum and maximum
    value for each one.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这两个调用请求 Optuna 提供两个参数，并为每个参数定义最小值和最大值。
- en: ❷ *x* ∼ 𝒰(−10,10)
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ *x* ∼ 𝒰(−10,10)
- en: ❸ *y* ∼ 𝒰(−10,10)
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ *y* ∼ 𝒰(−10,10)
- en: '❹ Computes and returns the result. Optuna tries to minimize this value: |(x-3)(y+2)|.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 计算并返回结果。Optuna 尝试最小化这个值：| (x-3)(y+2) |。
- en: 'That’s all we needed to do. Now we can use the `create_study` function to build
    the task and call `optimize` with the number of trials we want to let Optuna have
    to minimize the function:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们需要的全部。现在我们可以使用 `create_study` 函数构建任务，并使用 `optimize` 调用指定 Optuna 进行最小化函数的试验次数：
- en: '[PRE28]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: ❶ If you use direction=‘maximize’, Optuna will try to maximize the value returned
    by toyFunc.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 如果你使用direction=‘maximize’，Optuna将尝试最大化toyFunc返回的值。
- en: ❷ Tells Optuna which function to minimize and that it gets 100 attempts to do
    so
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 告诉Optuna要最小化的函数，以及它有100次尝试的机会。
- en: 'When you run the code, you should see a long list of output something like
    this:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行代码时，你应该会看到一个长长的输出列表，类似于以下内容：
- en: '[PRE29]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'When I ran this code, Optuna got a very precise answer: 5.04 ⋅ 10^(−5) is very
    close to the true minimum of zero. The values it returned were also close to what
    we knew was the true answer. We can access these using `study.best_params`, which
    contains a `dict` object mapping the hyperparameters to the values that, in combination,
    gave the best result:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 当我运行这段代码时，Optuna得到了一个非常精确的答案：5.04 ⋅ 10^(−5)非常接近真正的最小值零。它返回的值也接近我们所知的真正答案。我们可以通过`study.best_params`来访问这些信息，它包含一个`dict`对象，将超参数映射到组合起来给出最佳结果的值：
- en: '[PRE30]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: ❶ This dictionary holds the parameter values Optuna found to be best.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这个字典包含了Optuna找到的最佳参数值。
- en: We can also use the `study` object to get information about the optimization
    process that happened. Optuna is powerful because it uses machine learning to
    explore the space of parameter values. By specifying the parameters with min and
    max values, we give Optuna the constraints—and it attempts to balance exploring
    the space to understand what it looks like and minimizing the score based on its
    current understanding of the space.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`study`对象来获取有关优化过程的信息。Optuna之所以强大，是因为它使用机器学习来探索参数值的空间。通过指定具有最小和最大值的参数，我们为Optuna提供了约束条件——它试图在探索空间以了解其外观和根据其对空间的当前理解最小化分数之间取得平衡。
- en: 'We can use a contour plot to see an example:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用等高线图来查看一个示例：
- en: '[PRE31]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![](../Images/CH05_UN14_Raff.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_UN14_Raff.png)'
- en: Notice how Optuna has spent most of its effort testing values near the minimum
    and very little in the larger, extreme areas of the space. Optuna quickly figures
    out that there is no way to find a better solution in these parts of the space
    and stops exploring those areas. This allows it to spend more time looking for
    the best solution and to better handle more than just two parameters.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 注意看Optuna如何花费大部分精力测试接近最小值的值，而在空间的大范围极端区域投入的精力却非常少。Optuna很快就能判断在这些空间区域中找不到更好的解决方案，因此停止探索这些区域。这使得它有更多时间寻找最佳解决方案，并能更好地处理超过两个参数的情况。
- en: 5.4.2  Optuna with PyTorch
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.2 Optuna与PyTorch
- en: 'You now know all the basics of using Optuna; it’s time to combine it with PyTorch
    to do some advanced parameter searching. We’ll define a new function for Optuna
    to optimize our neural network. We do not want to go crazy, as optimizing without
    any gradients is still very difficult and Optuna is not a magic bullet. But we
    can use Optuna to help us make some decisions. For example, how many neurons should
    we have in each layer, and how many layers? Figure 5.17 shows how we can define
    a function to do this:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经了解了使用Optuna的所有基础知识；是时候将它与PyTorch结合，进行一些高级参数搜索了。我们将为Optuna定义一个新的函数来优化我们的神经网络。我们不想做得太过分，因为没有梯度的情况下优化仍然非常困难，Optuna也不是万能的子弹。但我们可以使用Optuna来帮助我们做出一些决策。例如，每个层应该有多少个神经元，以及有多少层？图5.17展示了我们如何定义一个函数来完成这个任务：
- en: Create train/validation splits (we did that with the plateau schedule).
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练/验证分割（我们使用plateau schedule完成了这个步骤）。
- en: Ask Optuna to give us three critical hyperparameters.
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请求Optuna给我们提供三个关键的超参数。
- en: Define our model using the parameters.
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用参数定义我们的模型。
- en: Compute and return the result from the validation split.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从验证分割中计算并返回结果。
- en: '![](../Images/CH05_F17_Raff.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH05_F17_Raff.png)'
- en: Figure 5.17 The four steps of defining an `objective` function that Optuna can
    use to optimize our neural network training. The two most important steps shown
    as code are getting the hyperparameters and computing the result!
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.17 Optuna可以用来优化我们的神经网络训练的`objective`函数定义的四个步骤。显示为代码的两个最重要的步骤是获取超参数和计算结果！
- en: An important thing to note here is that we have to create new training and validation
    splits using only the original training data. Why? Because we will reuse the validation
    set multiple times, and we do not want to overfit to the specifics of our validation
    data. So, we create a new validation set and save our original validation data
    until the very end. That way, we only use the true validation data once to determine
    how well we did at optimizing our network architecture.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的一个重要事项是，我们必须仅使用原始训练数据创建新的训练和验证分割。为什么？因为我们将会多次重用验证集，我们不希望过度拟合到验证数据的特定细节。因此，我们创建一个新的验证集，并保存我们的原始验证数据直到最后。这样，我们只使用真正的验证数据一次来确定我们在优化网络架构方面的表现。
- en: This function has very little *new* code; most of it is the same code we have
    used for several chapters to create data loaders, construct a network `Module`,
    and call our `train_network` function. Some significant PyTorch changes are that
    we set `disable_``tqdm=True` because Optuna does not play nicely with progress
    bars in the function it is trying to optimize.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数几乎没有多少**新**代码；大部分都是我们在几个章节中用来创建数据加载器、构建网络 `Module` 和调用我们的 `train_network`
    函数的相同代码。PyTorch 的一些重要变化是我们设置了 `disable_tqdm=True`，因为 Optuna 在它试图优化的函数中与进度条不兼容。
- en: Adding a dynamic number of layers
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 添加动态数量的层
- en: 'It may not be obvious at first, but we can very easily use the variable number
    of layers with our `nn.Sequential` object to adapt to what Optuna tells us to
    use. The code is as follows:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 起初可能并不明显，但我们可以非常容易地使用 `nn.Sequential` 对象的变量数量层来适应 Optuna 告诉我们使用的内容。代码如下：
- en: '[PRE32]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: ❶ At least one hidden layer that takes in D inputs
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 至少有一个接受D个输入的隐藏层
- en: ❶ Adds a variable number of hidden layers, depending on what Optuna gave us
    for the “layers" parameter
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 根据Optuna为“layers”参数提供的变量数量添加隐藏层
- en: ❶ Output layer
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 输出层
- en: ❶ Turns the list of layers into a PyTorch sequential module
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将层列表转换为PyTorch顺序模块
- en: This breaks up the model specification into a few parts so that the number of
    hidden layers is a variable filled in with a `for` loop, `for _ in range(layers-1):`.
    It’s a little more verbose for small networks but makes the same code able to
    handle a variety of layers, and it’s less code if we want to add more layers.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 这将模型规范拆分成几个部分，以便隐藏层的数量是一个通过 `for _ in range(layers-1):` 循环填充的变量。对于小型网络来说，这会稍微啰嗦一些，但可以使相同的代码能够处理各种层，如果我们想添加更多层，代码会更少。
- en: Getting suggestions from Optuna
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Optuna 获取建议
- en: 'The other changes are different `suggest` functions that Optuna provides via
    the `trial` object. There is `suggest_int` for integers, which makes sense for
    links like the number of neurons (76.8 neurons does not make sense) and the number
    of layers. We already saw `suggest_uniform`, which works for float values that
    are covered by a simple random range (like the momentum term μ, which should be
    between 0 and 1). The other important option is `suggest_loguniform`, which gives
    *exponentially spaced* random values. This is the function you should use for
    parameters that are altered by orders of magnitude, like the learning rate (*η*
    = 0.001, 0.01, and 0.1 differ by a factor of 10). The next code snippet shows
    how we can get three hyperparameter suggestions from Optuna by specifying the
    appropriate `suggest` function and providing minimum and maximum values that we
    are willing to consider:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 其他变化是 Optuna 通过 `trial` 对象提供的不同 `suggest` 函数。有 `suggest_int` 用于整数，这对于像神经元数量（76.8个神经元没有意义）和层数这样的链接是有意义的。我们之前看到了
    `suggest_uniform`，它适用于被简单随机范围覆盖的浮点值（如动量项 μ，应该在0和1之间）。另一个重要的选项是 `suggest_loguniform`，它提供**指数间隔**的随机值。这是你应该用于参数按数量级改变的情况，如学习率（*η*
    = 0.001, 0.01和0.1相差10倍）。下一个代码片段展示了我们如何通过指定适当的 `suggest` 函数并提供我们愿意考虑的最小和最大值来从 Optuna
    获取三个超参数建议：
- en: '[PRE33]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This ends by simply training our network and taking the validation accuracy
    from the last epoch. You must remember that this is a *validation split* and that
    we have not used the test set. We should only use the test set *after* the hyperparameters
    have been found, to determine the overall accuracy. The following code searches
    for the hyperparameters for this problem:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这最后只是简单地训练我们的网络，并从最后一个epoch中获取验证准确率。你必须记住这是一个**验证分割**，我们没有使用测试集。我们应该在找到超参数后**仅**使用测试集来确定整体准确率。以下代码搜索此问题的超参数：
- en: '[PRE34]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: ❶ Normally we would do more like 50 to 100 trials, but we are using fewer so
    this notebook runs in a reasonable amount of time.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 通常我们会进行50到100次试验，但这里我们使用较少的试验，以便这个笔记本在合理的时间内运行。
- en: You can see the parameters that Optuna selected. Now that we have trained our
    network, an exercise for you is to train a new model with this information to
    determine what final validation accuracy you get on the true validation set. Doing
    so completes the entire hyperparameter optimization process, which is outlined
    in figure 5.18.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到 Optuna 选定的参数。现在我们已经训练了网络，一个练习是使用这些信息训练一个新的模型，以确定你在真实验证集上得到的最终验证准确度。这样做就完成了整个超参数优化过程，如图5.18所示。
- en: '![](../Images/CH05_F18_Raff.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_F18_Raff.png)'
- en: Figure 5.18 All the steps you need to follow to do hyperparameter optimization
    correctly. It may be tempting to merge or skip some of these steps, but doing
    so could give you misleading results about how well your model will actually do.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.18 正确进行超参数优化所需遵循的所有步骤。合并或跳过这些步骤可能很有吸引力，但这样做可能会给你关于模型实际表现如何的误导性结果。
- en: Visualizing Optuna results
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化 Optuna 结果
- en: Beyond just looking at the *final* answer, we can also look at the progress
    Optuna made over time and other views of the optimization process. Doing so can
    help us build some intuition about the range of “good” parameters. This information
    can be helpful when we set up new experiments so that we can hopefully start the
    optimization process closer to the true solution and thus reduce the number of
    optimization attempts required.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅仅是查看*最终*答案，我们还可以查看 Optuna 随时间所取得的进展以及其他优化过程的视图。这样做可以帮助我们建立一些关于“良好”参数范围的直觉。当设置新的实验时，这些信息可能会有所帮助，这样我们就可以希望优化过程更接近真实解，从而减少所需的优化尝试次数。
- en: 'The following is one of the simplest options: plotting the validation accuracy
    (and individual trials) based on how many trials have been attempted. The red
    line on top shows the current best result, and each blue dot shows the result
    from one experiment. If big improvements in accuracy are still occurring (red
    line going up), we have a good reason to increase the number of trials we let
    Optuna run. If accuracy has plateaued for a long time, we can reduce the number
    of trials in the future:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是最简单的选项之一：根据尝试的试验次数来绘制验证准确度（和个别试验）图。顶部的红线显示当前最佳结果，每个蓝色点表示一次实验的结果。如果准确度的大幅提升仍在发生（红线上升），我们有很好的理由增加
    Optuna 运行的试验次数。如果准确度已经长时间处于平台期，我们可以在未来减少试验次数：
- en: '[PRE35]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![](../Images/CH05_UN15_Raff.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_UN15_Raff.png)'
- en: 'We might also want to get an idea of how each hyperparameter performs with
    respect to the objective (accuracy). That can be done with a *slice plot*. The
    following example makes a scatter plot for each hyperparameter, with the objective
    on the y-axis; the color of the dot indicates which trial the result came from.
    This way, you can see if any one hyperparameter has a particularly strong relationship
    with your objective and how long it took Optuna to figure it out. In this specific
    example, in most cases, three to six hidden layers perform well, and learning
    rates above *η* > 0.001 are also consistently good. This kind of information can
    help us reduce the search range in future trials or even eliminate a hyperparameter
    if it seems to have little impact on the objective. Both of these will help Optuna
    converge to solutions with fewer attempts in future runs. Here’s the code:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可能想要了解每个超参数相对于目标（准确度）的表现。这可以通过*切片图*来完成。以下示例为每个超参数制作散点图，目标值位于y轴上；点的颜色表示结果来自哪个试验。这样，你可以看到是否有任何超参数与目标有特别强的关系，以及
    Optuna 解决这个问题需要多长时间。在这个特定例子中，大多数情况下，三到六个隐藏层表现良好，学习率高于*η* > 0.001也是一致的。这类信息可以帮助我们在未来的试验中缩小搜索范围，甚至如果某个超参数似乎对目标影响不大，可以消除该超参数。这两者都将帮助
    Optuna 在未来的运行中通过更少的尝试收敛到解决方案。以下是代码：
- en: '[PRE36]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![](../Images/CH05_UN16_Raff.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_UN16_Raff.png)'
- en: Optuna can also help you understand the interactions between hyperparameters.
    One option is the `plot_contour()` function, which creates a grid showing how
    every combination of two different hyperparameters impacts the results. The other
    option is the `plot_parallel_coordinate()` function, which shows all the results
    of every trial in one graph. Both of these are a little harder to read and require
    more trials to produce really interesting results, so I recommend trying them
    on your own when you have a chance to do 100 trials for a model.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna 还可以帮助你理解超参数之间的相互作用。一个选项是 `plot_contour()` 函数，它创建一个网格，显示每对不同的超参数组合如何影响结果。另一个选项是
    `plot_parallel_coordinate()` 函数，它在一个图表中显示每个试验的所有结果。这两个都稍微难读一些，并且需要更多的试验来产生真正有趣的结果，所以我建议你在有机会进行
    100 次试验时自己尝试它们。
- en: 5.4.3  Pruning trials with Optuna
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.3 使用 Optuna 进行剪枝试验
- en: 'Another feature that Optuna supports that is particularly useful when training
    neural networks is *pruning* trials early. The idea is that optimizing a neural
    network is iterative: we take multiple epochs through the dataset, and we (hopefully)
    improve with every epoch. This is valuable information we are not using. If we
    can determine early in the process that a model won’t pan out, we can save a lot
    of time.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna 支持的另一个特别有用的功能是在训练神经网络时提前剪枝试验。其想法是优化神经网络是迭代的：我们多次遍历数据集，并且我们（希望）每次迭代都会有所改进。这是我们未使用的信息。如果我们能在处理过程中早期确定一个模型不会成功，我们可以节省大量时间。
- en: Say we start testing a set of parameters, and learning fails from the start,
    with terrible results on the first few epochs. Why continue training until the
    end? The model is *very unlikely* to start as degenerate and later become one
    of the best performers. If we report intermediate results to Optuna, Optuna can
    prune out trials that look bad based on the trials that have already completed.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们开始测试一组参数，学习从一开始就失败，前几个周期结果非常糟糕。为什么还要继续训练到结束？模型极不可能一开始就退化，后来成为最佳表现者之一。如果我们向
    Optuna 报告中间结果，Optuna 可以基于已经完成的试验剪枝掉看起来不好的试验。
- en: 'We can accomplish this by replacing the last two lines of code from the`def objective(trial):`
    function. Instead of calling `train_network` once with 10 epochs, we call it 10
    times in a loop for 1 epoch each. After each epoch, we use the `report` function
    of the `trial` object to let Optuna know how we are *currently* doing and ask
    Optuna if we should stop. The revised code looks like this:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过替换 `def objective(trial):` 函数的最后两行代码来实现这一点。我们不是用 10 个周期调用一次 `train_network`，而是用循环调用
    10 次，每次 1 个周期。在每个周期之后，我们使用 `trial` 对象的 `report` 函数让 Optuna 了解我们当前的进展，并询问 Optuna
    我们是否应该停止。修改后的代码如下：
- en: '[PRE37]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: ❶ Do a loop for each epoch ourselves.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们自己为每个周期进行循环。
- en: ❷ Do just one epoch of training, but reuse the same model and optimizer. This
    continues training the same model over and over.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 只进行一次训练周期，但重用相同的模型和优化器。这会反复训练同一个模型。
- en: ❸ Lets Optuna know how well we are doing
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 让 Optuna 了解我们的表现如何
- en: ❹ Asks Optuna if this looks hopeless
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 询问 Optuna 是否看起来没有希望
- en: ❺ If so, stop trying.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 如果是这样，就停止尝试。
- en: '❻ We made it to the end: give the final answer.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 我们已经到达了终点：给出最终答案。
- en: 'With this code change, I’m going to run a new trial with Optuna but intentionally
    set the number of neurons to go down to 1 (way too small) and the learning rate
    to go up to *η* = 100 (way too big). This will create some *really* bad models
    that are easy to prune out, just to show off this new pruning feature. All of
    these changes only needed to happen in the `objective` function: we call the same
    `create_study` and `optimize` functions and get pruning automatically. The following
    snippet shows this, but I set `n_trials=20` to give pruning more opportunities
    to occur since it depends on the best *current* models found by Optuna (it does
    not know what a bad run looks like until it sees a good run to compare against):'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个代码更改，我将使用 Optuna 运行一个新的试验，但故意将神经元的数量设置为下降到 1（太小了）和将学习率设置为 *η* = 100（太大了）。这将创建一些
    *非常糟糕* 的模型，这些模型很容易被剪枝掉，只是为了展示这个新的剪枝功能。所有这些更改只需要在 `objective` 函数中发生：我们调用相同的 `create_study`
    和 `optimize` 函数，并自动获得剪枝。下面的代码片段展示了这一点，但我将 `n_trials=20` 设置为给剪枝更多机会发生，因为它依赖于 Optuna
    找到的最佳 *当前* 模型（它不知道坏运行看起来像什么，直到它看到可以与之比较的好运行）：
- en: '[PRE38]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now you should see several `TrialState.PRUNED` logs from Optuna when you run
    this code. When I ran it, 10 of the 20 trials were pruned early. How many epochs
    into training were these models before they got pruned? We can have Optuna plot
    the results of all the trials with their intermediate values to help us understand
    that better. This is done with the `plot_intermediate_values()` function, as shown
    next:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该能在运行此代码时看到几个来自Optuna的`TrialState.PRUNED`日志。当我运行它时，20次试验中有10次在早期就被剪枝了。这些模型在剪枝之前经过了多少个epoch的训练？我们可以让Optuna绘制所有试验及其中间值的图表，以帮助我们更好地理解这一点。这是通过`plot_intermediate_values()`函数完成的，如下所示：
- en: '[PRE39]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '![](../Images/CH05_UN17_Raff.png)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_UN17_Raff.png)'
- en: 'It looks like all 10 trials were pruned after just 1 or 2 epochs through the
    dataset. That’s very early in the process: Optuna has reduced the number of effective
    trials almost by half. We also see some cases where models that did not perform
    well were allowed to run until completion, even though “better” models were pruned
    early. This happens because pruning is based on the best models Optuna has seen
    *so far*. Early on, Optuna lets bad models run to completion because it does not
    yet know they are bad models. Only after more trials and seeing much better models
    does it learn that the original ones could have been pruned. So pruning does not
    avoid *all* bad models, but it can avoid many of them.'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来所有10次试验都在经过数据集的1个或2个epoch后就被剪枝了。这是过程非常早的阶段：Optuna几乎将有效试验的数量减少了一半。我们也看到一些案例，即使有“更好”的模型被提前剪枝，表现不佳的模型仍然被允许运行到完成。这是因为剪枝是基于Optuna到目前为止看到的最佳模型。在早期，Optuna允许不良模型运行到完成，因为它还没有意识到它们是坏模型。只有经过更多的试验并看到更好的模型后，它才会意识到原始模型本可以剪枝。因此，剪枝并不能避免*所有*不良模型，但它可以避免许多不良模型。
- en: Looking at the graph carefully, you should be able to see some cases where Optuna
    pruned models that were diverging (getting worse) and some that looked like they
    would improve but were not doing well enough that they would become competitive
    with what Optuna had already seen. These are also good cases for pruning and part
    of how Optuna saves us time.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察图表，你应该能够看到Optuna剪枝了一些正在发散（变差）的模型，以及一些看起来可能会改进但表现不佳，以至于无法与Optuna已经看到的模型竞争的模型。这些也是很好的剪枝案例，也是Optuna节省我们时间的一部分。
- en: Note While Optuna is one of my favorite tools, we won’t use it again in this
    book. This is purely a computational concern, as I want to stick with examples
    that run in just a few minutes. Optuna needs to train multiple networks, which
    means *multiplying* training time. Just 10 trials is not a lot, but an example
    that would take 6 minutes with no hyperparameters would take an hour or more with
    Optuna. However, when you are working on the job, you should *definitely* use
    Optuna to help you build your neural networks.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：虽然Optuna是我最喜欢的工具之一，但我们在这本书中不会再使用它。这纯粹是一个计算问题，因为我想要坚持使用只需几分钟就能运行的示例。Optuna需要训练多个网络，这意味着*乘以*训练时间。仅仅10次试验并不多，但如果没有任何超参数，一个需要6分钟的示例，使用Optuna可能需要一个小时或更长时间。然而，当你工作时，你应该*绝对*使用Optuna来帮助你构建你的神经网络。
- en: Exercises
  id: totrans-363
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: Share and discuss your solutions on the Manning online platform at Inside Deep
    Learning Exercises ([https://liveproject.manning.com/project/945](https://liveproject.manning.com/project/945)).
    Once you submit your own answers, you will be able to see the solutions submitted
    by other readers, and see which ones the author judges to be the best.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在Manning在线平台上的Inside Deep Learning Exercises部分分享和讨论你的解决方案（[https://liveproject.manning.com/project/945](https://liveproject.manning.com/project/945)）。一旦你提交了自己的答案，你将能够看到其他读者提交的解决方案，并查看作者认为哪些是最好的。
- en: Modify the `train_network` function to accept `lr_schedule=ReduceLROnPlateau`
    as a valid argument. If the `train_network` function gets this string argument,
    it should check whether validation and test sets have been provided and, if so,
    set up the `ReduceLROnPlateau` scheduler appropriately.
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改`train_network`函数，使其能够接受`lr_schedule=ReduceLROnPlateau`作为一个有效的参数。如果`train_network`函数接收到这个字符串参数，它应该检查是否提供了验证和测试集，如果是的话，适当地设置`ReduceLROnPlateau`调度器。
- en: Rerun the experiments with `AdamW`, SGD with Nesterov momentum, and the cosine
    annealing schedule using batch sizes of *B* = 1, 4, 32, 64, 128. How does the
    change in batch size impact the effectiveness and accuracy of these three tools?
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用批大小*B* = 1, 4, 32, 64, 128重新运行使用`AdamW`、带有Nesterov动量的SGD和余弦退火计划的实验。批大小变化如何影响这三个工具的有效性和准确性？
- en: Write code that creates a neural network with *n* = 256 neurons and an argument
    to control how many hidden layers are in the network. Then train networks with
    1, 6, 12, and 24 hidden layers using naive SGD and again using `AdamW` with cosine
    annealing. How do these new optimizers impact your ability to learn these deeper
    networks?
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写代码创建一个具有 *n* = 256 个神经元的神经网络，并添加一个参数来控制网络中隐藏层的数量。然后使用简单的随机梯度下降法（SGD）和带有余弦退火的
    `AdamW` 训练具有 1、6、12 和 24 个隐藏层的网络。这些新的优化器如何影响你学习这些深层网络的能力？
- en: Retrain the three-layer bidirectional RNN from the last chapter with each of
    the new optimizers from this chapter. How do they impact the results?
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用本章中的每个新优化器重新训练上一章中的三层双向循环神经网络（RNN）。它们如何影响结果？
- en: Add gradient clipping to the experiments from exercise 4\. Does it help or hurt
    the RNN?
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在练习 4 的实验中添加梯度裁剪。这有助于 RNN 吗？
- en: Write your own function that uses Optuna to optimize the parameters of a fully
    connected neural network. Once it’s done, create a new network with those hyperparameters,
    train it using all of the training data, and test it on the held-out test set.
    What results do you get on FashionMNIST, and how close is Optuna’s guess at the
    accuracy compared to your test-set performance?
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写你自己的函数，使用 Optuna 优化全连接神经网络的参数。一旦完成，使用这些超参数创建一个新的网络，使用所有训练数据对其进行训练，并在保留的测试集上进行测试。你在
    FashionMNIST 上得到的结果是什么，Optuna 对准确率的猜测与你的测试集性能有多接近？
- en: Redo exercise 6, but replace the hidden layers with convolutional ones and add
    a new argument that controls how many rounds of max pooling to perform. How does
    it perform on FashionMNIST compared with your results from exercise 6?
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新做练习 6，但将隐藏层替换为卷积层，并添加一个新参数来控制执行多少轮最大池化。与练习 6 的结果相比，它在 FashionMNIST 上的表现如何？
- en: Summary
  id: totrans-372
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The two main components of gradient descent are how we use gradients (optimizers)
    and how fast we follow them (learning rate schedules).
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度下降的两个主要组成部分是我们如何使用梯度（优化器）以及我们跟随它们的速度（学习率计划）。
- en: By using information about the history of gradients, we can increase how quickly
    our models learn.
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用关于梯度历史的信息，我们可以加快模型的学习速度。
- en: Adding momentum to optimizers allows training even when gradients become very
    small.
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将动量添加到优化器中允许在梯度变得非常小的情况下进行训练。
- en: Gradient clipping mitigates exploding gradients, allowing training even when
    gradients become very large.
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度裁剪减轻了梯度爆炸的问题，即使在梯度变得非常大时也能进行训练。
- en: By altering the learning rate, we can ease the optimization view of learning
    for further improvements.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过调整学习率，我们可以缓解优化的学习视图，以实现进一步的改进。
- en: Instead of grid search, we can use powerful tools like Optuna to find the hyperparameters
    of a neural network such as the number of layers and number of neurons.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用像 Optuna 这样的强大工具，而不是网格搜索，来寻找神经网络（如层数和神经元数量）的超参数。
- en: By checking the results after each epoch, we can accelerate the hyperparameter
    tuning process by pruning bad models early.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过检查每个周期的结果，我们可以通过早期剪枝不良模型来加速超参数调整过程。
- en: '* * *'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ¹ More on that in the chapter 6.[↩](#fnref9)
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 更多内容请见第 6 章。[↩](#fnref9)
- en: ² If the test loss starts increasing, which indicates more severe overfitting,
    that is another good reason to slow down learning. That helps slow the overfitting.
    But ideally, the test loss has stabilized.[↩](#fnref10)
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: ² 如果测试损失开始增加，这表明更严重的过拟合，那么这也是减缓学习速度的另一个好理由。这有助于减缓过拟合。但理想情况下，测试损失应该已经稳定。[↩](#fnref10)
- en: ³ I think using μ for momentum is confusing, but it’s the most common notation,
    so I’m sticking with it so you can learn it.[↩](#fnref11)
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: ³ 我认为用 μ 表示动量很令人困惑，但这是最常用的符号，所以我会坚持使用它，这样你可以学习它。[↩](#fnref11)
