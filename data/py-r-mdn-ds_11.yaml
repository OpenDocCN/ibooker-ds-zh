- en: Chapter 7\. A Case Study in Bilingual Data Science
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 7 章\. 双语数据科学的案例研究
- en: Rick J. Scavetta
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Rick J. Scavetta
- en: Boyan Angelov
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Boyan Angelov
- en: In this final chapter, our goal is to present a case study that demonstrates
    a sample of all the concepts and tools we’ve shown throughout this book. Although
    data science provides a practically overwhelming diversity of methods and applications,
    we typically rely on a core toolkit in our daily work. Thus, it’s unlikely that
    you’ll make use of *all* the tools presented in this book (or this case study,
    for that matter). But that’s alright! We hope that you’ll focus on those parts
    of the case study that are most relevant to your work and that you’ll be inspired
    to be a modern, bilingual data scientist.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后一部分，我们的目标是展示一个案例研究，演示本书中展示的所有概念和工具的样本。尽管数据科学提供了几乎令人难以置信的多样的方法和应用，但我们通常在日常工作中依赖于核心工具包。因此，您不太可能使用本书（或本案例研究，同样如此）中提出的所有工具。但这没关系！我们希望您专注于案例研究中与您工作最相关的部分，并且受到启发，成为一名现代的双语数据科学家。
- en: 24 years and 1.88 million wildfires
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 24 年间发生了 1.88 百万次野火。
- en: Our case study will focus on the *US Wildfires dataset* ^([1](ch07.xhtml#idm45127447555192)).
    This dataset, released by the US Department of Agriculture (USDA), contains 1.88
    million geo-referenced wildfire records. Collectively, these fires have resulted
    in the loss of 140 million acres of forest over 24 years. If you want to execute
    the code in this chapter, download the SQLite data set from the [USDA website](https://doi.org/10.2737/RDS-2013-0009.4)
    directly or from [Kaggle](https://www.kaggle.com/rtatman/188-million-us-wildfires).
    Some preprocessing has already been performed, e.g., duplicate removal.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的案例研究将集中在*美国野火数据集* ^([1](ch07.xhtml#idm45127447555192))。这个数据集由美国农业部（USDA）发布，包含了
    1.88 百万个地理参考的野火记录。这些火灾总共导致了 24 年间 1.4 亿英亩森林的损失。如果您想在本章中执行代码，请直接从[USDA网站](https://doi.org/10.2737/RDS-2013-0009.4)或[Kaggle](https://www.kaggle.com/rtatman/188-million-us-wildfires)下载SQLite数据集。一些预处理已经完成，例如去重。
- en: There are 39 features, plus another shape variable in raw format. Many of these
    are unique identifiers or redundant categorical and continuous representations.
    Thus, to simplify our case study, we’ll focus on a few features listed in [Table 7-1](#csFeatures).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 有 39 个特征，再加上原始格式中的另一个形状变量。其中许多是唯一标识符或冗余的分类和连续表示。因此，为了简化我们的案例研究，我们将专注于[表 7-1](#csFeatures)中列出的少数几个特征。
- en: Table 7-1\. The `fires` table contains 39 features describing over 1.88 million
    wildfires in the US from 1992-2015
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7-1\. `fires`表包含描述 1992-2015 年间美国 1.88 百万次野火的 39 个特征
- en: '| Variable | Description |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 变量 | 描述 |'
- en: '| --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| STAT_CAUSE_DESCR | Cause of the fire (The target variable) |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| STAT_CAUSE_DESCR | 火灾原因（目标变量） |'
- en: '| OWNER_CODE | Code for primary owner of the land |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| OWNER_CODE | 土地主要所有者的代码 |'
- en: '| DISCOVERY_DOY | Day of year of fire discovery or confirmation |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| DISCOVERY_DOY | 火灾发现或确认的年度日期 |'
- en: '| FIRE_SIZE | Estimate of the final fire size (acres) |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| FIRE_SIZE | 最终火灾规模的估计（英亩） |'
- en: '| LATITUDE | Latitude (NAD83) of the fire |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| LATITUDE | 火灾的纬度（NAD83） |'
- en: '| LONGITUDE | Longitude (NAD83) of the fire |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| LONGITUDE | 火灾的经度（NAD83） |'
- en: We’ll develop a classification model to predict the cause of a fire (`STAT_CAUSE_CODE`)
    using the five other features as features. The target and the model are secondary;
    this is not an ML case study. Thus, we’re not going to focus on details such as
    cross-validation or hyperparameter tuning^([2](ch07.xhtml#idm45127447535416)).
    We’ll also limit ourselves to observations from 2015 and exclude Hawaii and Alaska
    to reduce the data set to a more manageable size. The end product of our case
    study will be to produce an interactive document that will allow us to input new
    predictor values, as depicted in [Figure 7-1](#case_arch)^([3](ch07.xhtml#idm45127447533464)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开发一个分类模型来预测火灾的原因（`STAT_CAUSE_CODE`），使用其他五个特征作为特征。目标和模型是次要的；这不是一个机器学习案例研究。因此，我们不会关注诸如交叉验证或超参数调整等细节^([2](ch07.xhtml#idm45127447535416))。我们还将限制自己仅使用
    2015 年的观察数据，并排除夏威夷和阿拉斯加，以减少数据集的规模。我们案例研究的最终产品将是生成一个交互式文档，允许我们输入新的预测者数值，如[图 7-1](#case_arch)^([3](ch07.xhtml#idm45127447533464))所示。
- en: Before we dig in, it’s worth taking a moment to consider data lineage - from
    raw to product. Answering the following questions will help orientate us.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入研究之前，值得花一点时间考虑数据谱系 - 从原始到产品。回答以下问题将有助于我们定位方向。
- en: What is the end product?
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终产品是什么？
- en: How will it be used, and by whom?
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何使用，由谁使用？
- en: Can we break down the project into component pieces?
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们是否可以将项目分解为组件？
- en: How will each component be built? i.e., Python or R? Which additional packages
    may be necessary?
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个组件将如何构建？即 Python 还是 R？可能需要哪些额外的包？
- en: How will these component pieces work together?
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些组件如何协同工作？
- en: Answering these questions allows us to draw a path from the raw data to the
    end product, hopefully avoiding bottlenecks along the way. For question 1, we’ve
    already stated that we want to build an interactive document. For the second question,
    to keep things simple, let’s assume it’s for us to easily input new feature values
    and see the model’s prediction.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 回答这些问题使我们能够从原始数据到最终产品中找到一条路径，希望能避免瓶颈。对于第一个问题，我们已经说明我们想构建一个交互式文档。对于第二个问题，为了保持简单，让我们假设它是为了轻松输入新的特征值并查看模型的预测。
- en: Questions 3-5 are what we’ve considered in this book. In question 3, we imagine
    the parts as a series of steps for our overall workflow. Question 4 was addressed
    in [Chapter 4](ch04.xhtml#ch05) and [Chapter 5](ch05.xhtml#ch06). We summarize
    those steps in [Table 7-2](#csOverview).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 3-5 是我们在本书中考虑的内容。在问题 3 中，我们将部分想象为我们整体工作流程的一系列步骤。问题 4 已在[第 4 章](ch04.xhtml#ch05)和[第
    5 章](ch05.xhtml#ch06)中讨论过。我们在[表 7-2](#csOverview)中总结了这些步骤。
- en: Table 7-2\. The steps in our case study and their respective languages.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7-2\. 我们案例研究的步骤及其对应的语言。
- en: '| Component/Step | Language | Additional packages? |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 组件/步骤 | 语言 | 额外的包？ |'
- en: '| --- | --- | --- |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1\. Data Importing | R | `RSQLite`, `DBI` |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 1\. 数据导入 | R | `RSQLite`, `DBI` |'
- en: '| 2\. EDA & Data Visualization | R | `ggplot2`, `GGally`, `visdat`, `nanair`
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 2\. EDA & Data Visualization | R | `ggplot2`, `GGally`, `visdat`, `nanair`
    |'
- en: '| 4\. Feature Engineering | Python | `scikit-learn` |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 4\. 特征工程 | Python | `scikit-learn` |'
- en: '| 5\. Machine Learning | Python | `scikit-learn` |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 5\. 机器学习 | Python | `scikit-learn` |'
- en: '| 6\. Mapping | R | `leaflet` |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 6\. 地图 | R | `leaflet` |'
- en: '| 7\. Interactive web interface | R | `shiny` runtime in an RMarkdown |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 7\. 交互式网络界面 | R | 在 RMarkdown 中运行的`shiny` |'
- en: Finally, question 5 asks us to consider the project architecture. The diagram
    presented in [Figure 7-1](#case_arch) shows how each of the steps in [Table 7-2](#csOverview)
    will be linked together.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，第 5 个问题要求我们考虑项目的架构。[图 7-1](#case_arch)中呈现的图表显示了[表 7-2](#csOverview)中的每个步骤将如何链接在一起。
- en: '![](Images/prds_0701.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0701.png)'
- en: Figure 7-1\. Architecture for our case study project.
  id: totrans-36
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-1\. 我们案例研究项目的架构。
- en: Alright, now that we know where we’re going, let’s choose our tools with care
    and assemble all the components into a unified whole.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，现在我们知道我们要去哪里了，让我们精心选择我们的工具，并将所有组件组装成一个统一的整体。
- en: Note
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: We prepared this case study exclusively using the RStudio IDE. As we discussed
    in the [Chapter 6](ch06.xhtml#ch07), if we’re writing in R and accessing Python
    functions, this would be the way to go. The reason is the built-in capabilities
    in executing Python code chunks within RMarkdown, the features of the Environment
    and Plot panes, and finally, the tooling around `shiny`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们专门使用 RStudio IDE 准备了这个案例研究。正如我们在[第 6 章](ch06.xhtml#ch07)中讨论的那样，如果我们在 R 中访问
    Python 函数，这将是正确的方式。原因在于 RMarkdown 中执行 Python 代码块的内置功能，环境和绘图窗格的特性，以及围绕`shiny`的工具。
- en: Setup and data import
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置和数据导入
- en: 'We can see from our diagram that our end product will be an interactive RMarkdown
    document. So let’s begin as we have done in [Chapter 5](ch05.xhtml#ch06). Our
    YAML^([4](ch07.xhtml#idm45127447463752)) header will consist of at least:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的图表中可以看出，我们的最终产品将是一个交互式的 RMarkdown 文档。所以让我们像在[第 5 章](ch05.xhtml#ch06)中所做的那样开始。我们的
    YAML^([4](ch07.xhtml#idm45127447463752)) 头部至少包括：
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: To have nicer formatting, we’ll exclude the characters specifying an RMarkdown
    chunk from the following examples. Naturally, if you are following along, you
    need to add them.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了具有更好的格式，我们将在以下示例中排除指定 RMarkdown 代码块的字符。自然地，如果您在跟随，您需要添加它们。
- en: 'Since the data is stored in an SQLite database, we need to use some additional
    packages in addition to ones we’ve already seen. Our first code chunk is:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据存储在 SQLite 数据库中，除了我们已经看到的包外，我们需要使用一些额外的包。我们的第一个代码块是：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In our second code chunk, we’ll connect to the database and list all of the
    33 available tables.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第二个代码块中，我们将连接到数据库并列出所有的 33 个可用表格。
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Creating a connection (`con`) object is a standard practice in establishing
    programmatic access to databases. In contrast to R, Python has built-in support
    for opening such files with the `sqlite3` package. This is preferable to R since
    we don’t need to install and load two additional packages. Nonetheless, R is a
    core language for the initial steps, so we might as well just import the data
    in R from the outset.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 创建连接（`con`）对象是建立对数据库进行程序化访问的标准做法。与 R 不同，Python 内置支持使用 `sqlite3` 包打开此类文件。这比 R
    更可取，因为我们不需要安装和加载两个额外的包。尽管如此，R 是初始步骤的核心语言，因此我们最好从一开始就在 R 中导入数据。
- en: Our data is stored in the `Fires` table. As we know the columns we want to access,
    we can specify that while importing.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据存储在 `Fires` 表中。由于我们知道要访问的列，因此可以在导入时指定。
- en: It’s also important to remember to close the connections when working with remote
    or shared databases, since that might prevent other users from accessing the database
    and cause issues^([5](ch07.xhtml#idm45127447406008)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用远程或共享数据库时，记得关闭连接非常重要，因为这可能会阻止其他用户访问数据库并引发问题^([5](ch07.xhtml#idm45127447406008))。
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We limit our dataset size already at this very first importing step. It’s a
    shame to throw out so much data. Still, we do this since older data, especially
    in climate applications, tends to be less representative of the current or near-future
    situation. Predictions based on old data can be inherently biased. By limiting
    the size of the data set, we also reduce the amount of memory used, improving
    performance.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第一次导入时已经限制了数据集的大小。抛弃这么多数据是一件令人遗憾的事情。但我们这样做是因为旧数据，尤其是在气候应用中，往往不太代表当前或近期的情况。基于旧数据的预测可能存在固有偏见。通过限制数据集的大小，我们还减少了内存使用量，提高了性能。
- en: Performance tip
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能提示
- en: Often in the case of enormous datasets (those barely or not fitting into the
    memory of your machine), you can use such an ingestion command to select just
    a sample, such as `LIMIT 1000`.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理庞大数据集的情况下（几乎或完全不适合您机器内存的数据集），您可以使用此类摄取命令仅选择样本，例如 `LIMIT 1000`。
- en: 'We can get a quick preview of the data using the `tidyverse` function `dplyr::glimpse()`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `tidyverse` 函数 `dplyr::glimpse()` 快速预览数据：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: EDA & Data Visualization
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性数据分析与数据可视化
- en: 'Since the dataset is still relatively large, we should think carefully about
    the best data visualization strategy. Our first instinct may be to plot a map
    since we have latitude and longitude coordinates. This can be fed into `ggplot2`
    directly as x and y-axis coordinates as such:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集仍然相对较大，我们应该仔细考虑最佳的数据可视化策略。我们的第一反应可能是绘制地图，因为我们有纬度和经度坐标。这可以直接作为 x 和 y 轴坐标输入到
    `ggplot2` 中：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](Images/prds_0702.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0702.png)'
- en: Figure 7-2\. Plotting the sizes of individual fires.
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-2。绘制个别火灾的大小。
- en: By mapping `OWNER_CODE` onto the color aesthetic, we can see a strong correlation
    in some states. We can predict that this will have a substantial effect on our
    model’s performance. In the above code snippet, we assigned the plot to the object
    `g`. This is not strictly necessary, but we did it in this case to showcase the
    strength of the `ggplot2` layering method. We can add a `facet_wrap()` layer to
    this plot and separate it into 13 facets, or *small multiples*, one for each type
    of `STAT_CAUSE_DESCR`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '通过将 `OWNER_CODE` 映射到颜色美学，我们可以看到一些州之间存在强烈的相关性。我们可以预测这将对我们模型的性能产生重大影响。在上述代码片段中，我们将绘图分配给对象
    `g`。这并不是绝对必要的，但在这种情况下我们这样做是为了展示 `ggplot2` 层叠方法的强大之处。我们可以在此图中添加一个 `facet_wrap()`
    层，并将其分为 13 个面板，或 *小多面体*，每个 `STAT_CAUSE_DESCR` 类型一个。  '
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](Images/prds_0703.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0703.png)'
- en: Figure 7-3\. Faceting the fires plot, based on the fire cause.
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-3。根据火灾原因分组的火灾图。
- en: This allows us to appreciate that some causes are abundant while others are
    rare, an observation we’ll see again shortly in a different way. We can also begin
    to assess any strong associations between, e.g., region, owner code, and cause
    of a fire.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够欣赏到一些原因很常见，而另一些很少见的情况，这是我们很快会以另一种方式再次看到的观察结果。我们还可以开始评估，例如，地区、所有者代码和火灾原因之间是否存在强烈的关联。
- en: Returning to the entirety of the data set, an easy way to get a comprehensive
    overview is to use a pairs plot, sometimes called a splom (or “scatter plot matrix”
    if it consists of purely numeric data). The `GGally` package^([6](ch07.xhtml#idm45127447143208))
    provides an exceptional function, `ggpairs()` that produces a matrix of plots.
    Each pair-wise bi-variate plot is shown as univariate density plots or histograms
    on the diagonal. In the upper triangle, the correlation between continuous features
    is available.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 回到整个数据集，一个全面了解的简便方法是使用配对图，有时称为 splom（如果它完全由数值数据组成则称为“散点图矩阵”）。`GGally` 包^([6](ch07.xhtml#idm45127447143208))
    提供了一个出色的函数 `ggpairs()`，它生成一个图表矩阵。对角线上显示每对双变量图的单变量密度图或直方图。在上三角区域，连续特征之间的相关性也可见。
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](Images/prds_0704.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0704.png)'
- en: Figure 7-4\. A pairs plot.
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-4\. 一个配对图。
- en: 'This information-rich visualization demands some time to process. It’s handy
    as an *exploratory* plot, in EDA, but not necessarily as an *explanatory* in reporting
    our results. Can you spot any unusual patterns? First, `STAT_CAISE_DESCR` looks
    imbalanced^([7](ch07.xhtml#idm45127447128744)), meaning there is a significant
    difference between the number of observations per class. Additionally, `OWNER_CODE`
    appears to be bimodal (having two maxima). Those properties can negatively affect
    our analysis depending on which model we choose. Second, all correlations seem
    to be relatively low, making our job easier (since correlated data is not good
    for ML). Still, we already know there is a strong association between location
    (`LATITUDE` & `LONGITUDE`) and OWNER CODE from our previous plot. So we should
    take these correlations with a grain of salt. We would expect to detect this issue
    in feature engineering. Third, `FIRE_SIZE` has a very unusual distribution. It
    looks like that plot is empty, with just the x and y axes present. We see a density
    plot with a very high and narrow peak at the very low range and an extremely long
    positive skew. We can quickly generate a `log10` transformed density plot:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这个信息丰富的可视化需要一些时间来处理。它作为*探索性*绘图在探索性数据分析中非常方便，但不一定适用于结果报告中的*解释性*。你能发现任何异常模式吗？首先，`STAT_CAISE_DESCR`
    看起来是不平衡的^([7](ch07.xhtml#idm45127447128744))，意味着每个类别的观察数量之间存在显著差异。另外，`OWNER_CODE`
    似乎是双峰的（有两个峰值）。这些属性可能会根据我们选择的模型对我们的分析产生负面影响。其次，所有的相关性似乎都相对较低，这使得我们的工作更加轻松（因为相关的数据对机器学习不利）。尽管如此，我们已经知道位置（`LATITUDE`
    和 `LONGITUDE`）与 `OWNER CODE` 之间存在强关联关系，这是从我们之前的图中得出的。因此，我们应该对这些相关性持谨慎态度。我们期望在特征工程中能检测到这个问题。第三，`FIRE_SIZE`
    的分布非常不寻常。它看起来像是空的图表，只有 x 轴和 y 轴。我们看到一个密度图，在非常低的范围内有一个非常高且狭窄的峰值，以及一个极长的正偏态。我们可以快速生成一个`log10`转换后的密度图：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](Images/prds_0705.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0705.png)'
- en: Figure 7-5\. Density plot of the log-transformed `FIRE_SIZE` feature.
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-5\. 对数转换后的 `FIRE_SIZE` 特征的密度图。
- en: Additional visualizations
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他可视化内容
- en: For the case study, we’ll keep the tasks to a minimum, but there might be a
    few other interesting things to visualize that can help tell a story for the end-user.
    For example, note that the dataset has a temporal dimension. It would be interesting
    how forest fires’ quantity (and quality) has been changing over time. We’ll leave
    this to the motivated user to explore with the excellent `gganimate` package.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于案例研究，我们将任务保持在最低限度，但可能有一些其他有趣的可视化内容可以帮助最终用户讲述故事。例如，请注意数据集具有时间维度。了解随时间变化的森林火灾数量（和质量）将会很有趣。我们将这些内容留给有兴趣的用户使用优秀的
    `gganimate` 包进行探索。
- en: 'Interactive data visualization is often overused, without a special purpose
    in mind. Even for the most popular packages, the documentation shows just basic
    usage. In our case, since we have so many data points in a spatial setting, and
    we want to have a final deliverable that is accessible, creating an interactive
    map is an obvious choice. As in [Chapter 5](ch05.xhtml#ch06) we use `leaflet`:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 交互式数据可视化通常被滥用，没有特定的目的。即使对于最流行的包，文档也只展示了基本的用法。在我们的情况下，由于我们在空间设置中有如此多的数据点，并且我们希望得到一个易于访问的最终交付成果，创建一个交互地图是一个明显的选择。如同
    [第5章](ch05.xhtml#ch06) 中我们使用 `leaflet`：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](Images/prds_0706.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0706.png)'
- en: Figure 7-6\. Interactive map showing the locations of forest fires.
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-6\. 显示森林火灾位置的交互地图。
- en: Note how using `clusterOptions` allows us to simultaneously present all of the
    data without overwhelming the user or reducing visibility. For our purposes, this
    satisfies our curiosity using some great visualizations in EDA. There are plenty
    of other statistics we can apply, but let’s move machine learning in Python.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意如何使用`clusterOptions`允许我们同时呈现所有数据，而不会使用户感到不知所措或降低可见性。对于我们的目的，这满足了我们在探索性数据分析中使用一些出色可视化的好奇心。我们可以应用许多其他统计方法，但让我们转向Python中的机器学习。
- en: Machine Learning
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: By now, we have some idea about the factors that may influence the cause of
    a fire. Let’s dive into building a machine learning model using `scikit-learn`
    in Python^([8](ch07.xhtml#idm45127446950648)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经对可能影响火灾原因的因素有了一些了解。让我们深入使用Python中的`scikit-learn`来构建机器学习模型^([8](ch07.xhtml#idm45127446950648))。
- en: 'We argued that ML is best done in Python as we saw in [Chapter 5](ch05.xhtml#ch06).
    We’ll use a Random Forest algorithm. There are several reasons for this choice:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为在Python中进行机器学习是最好的选择，正如我们在[第5章](ch05.xhtml#ch06)中所见。我们将使用随机森林算法。选择这种算法有几个原因：
- en: It’s a well-established algorithm
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个成熟的算法
- en: It’s relatively easy to understand
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这相对容易理解
- en: It does not require feature scaling before training
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练之前不需要进行特征缩放
- en: There are other reasons why it’s good, such as working well with missing data
    and having out-of-the-box explainability.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他一些原因使其优秀，比如良好的缺失数据处理能力和开箱即用的可解释性。
- en: Setting up our Python Environment
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置我们的Python环境
- en: 'As discussed in [Chapter 6](ch06.xhtml#ch07), there are a few ways to access
    Python using the `reticulate` package. The choice depends on the circumstances,
    which we laid out in our project architecture. Here, we’ll pass our R `data.frame`
    to a Python virtual environment. If you followed the steps in [Chapter 6](ch06.xhtml#ch07),
    you’d already have the `modern_data` virtual environment set up. We already installed
    some packages into this environment. To recap, we executed the following commands:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在[第6章](ch06.xhtml#ch07)中讨论的那样，使用`reticulate`包有几种访问Python的方式。选择取决于情况，我们在项目架构中已经说明。在这里，我们将我们的R
    `data.frame`传递给Python虚拟环境。如果你按照[第6章](ch06.xhtml#ch07)中的步骤进行操作，你已经设置好了`modern_data`虚拟环境。我们已经在此环境中安装了一些包。简而言之，我们执行了以下命令：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If you don’t have the `modern_data` virtualenv or you’re using Windows, please
    refer to the steps in the files `0 - setup.R` and `1 - activate.R` and discussed
    in [Chapter 6](ch06.xhtml#ch07). You may want to restart R at this point to make
    sure that you’ll be able to activate your virtual environment using the following
    command:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有安装`modern_data`虚拟环境，或者你使用的是Windows，请参考文件`0 - setup.R`和`1 - activate.R`中的步骤，并在[第6章](ch06.xhtml#ch07)中讨论。在此时，你可能需要重新启动R，以确保可以使用以下命令激活你的虚拟环境：
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We’ll include all the Python steps into a single script; you can find this script
    in the book [repository](https://github.com/moderndatadesign/PyR4MDS) under `ml.py`.
    First, we’ll import the necessary modules.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将所有Python步骤都包含在一个单独的脚本中；你可以在书的[仓库](https://github.com/moderndatadesign/PyR4MDS)的`ml.py`下找到此脚本。首先，我们将导入必要的模块。
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Feature engineering
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程
- en: There are features in the dataset that might be informative to a data analyst
    but are at best useless for training the model, and at worst - can reduce its
    accuracy. This is called “adding noise” to the dataset, and we want to avoid it
    at all costs. This is the purpose behind feature engineering. Let’s select just
    the features we need, as specified in [Table 7-1](#csFeatures). We also use standard
    ML convention in storing them in `X`, and our target in ‘y’.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中有些特征对数据分析师可能有信息意义，但对于训练模型来说最好是无用的，甚至会降低其准确性。这被称为向数据集中“添加噪音”，我们要尽量避免这种情况。这就是特征工程的目的。让我们只选择我们需要的特征，如[表7-1](#csFeatures)中所指定的那样。我们还使用了标准的机器学习约定，将它们存储在`X`中，我们的目标在‘y’中。
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here, we create an instance of the `LaberEncoder`. We use this to encode a
    categorical feature to numeric. In our case, we apply it to our target:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个`LaberEncoder`的实例。我们用它来将分类特征编码为数值。在我们的案例中，我们将其应用于我们的目标：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here, we split the dataset into a training and a test set (note that we are
    also using the handy `stratify` parameter to make sure the splitting function
    samples our imbalanced classes fairly):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将数据集分为训练集和测试集（请注意，我们还使用了便捷的`stratify`参数，以确保分割函数公平地对我们的不平衡类别进行采样）：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Model training
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'To apply the Random Forest classifier, we’ll make an instance of `RandomForestClassifier`.
    As in [Chapter 5](ch05.xhtml#ch06) we use the `fit/predict` paradigm and store
    the predicted values in `preds`:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用随机森林分类器，我们将创建一个 `RandomForestClassifier` 的实例。如同 [第 5 章](ch05.xhtml#ch06)
    中使用 `fit/predict` 范式并将预测值存储在 `preds` 中一样：
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the final step, we’ll assign the confusion matrix and the accuracy score
    to objects.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一步，我们将为对象分配混淆矩阵和准确率得分。
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'After we have complete our script, we can source it into R:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成我们的脚本之后，我们可以将其导入 R：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: After running this command, we’ll have access to all the Python objects directly
    in our environment. The accuracy is `0.58`, which is not phenomenal, but certainly
    much better than random!
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此命令后，我们将直接在我们的环境中访问所有 Python 对象。准确率为 `0.58`，这并不是非凡的，但肯定比随机要好得多！
- en: The power of sourcing Python scripts
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用 Python 脚本的优势
- en: When we use the `source_python` function from `reticulate` we can significantly
    increase our productivity, especially if we are working in a bilingual team. Imagine
    the scenario when a coworker of yours builds the ML part in Python and you need
    to include their work in yours. It would be as easy as sourcing without worrying
    about re-coding everything. This scenario is also plausible when joining a new
    company or project and inheriting Python code that you need to use straight away.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用 `reticulate` 中的 `source_python` 函数时，我们可以显著提高我们的生产力，特别是在与双语团队合作时。想象一下，你的同事在
    Python 中构建了 ML 部分，而你需要将他们的工作包含在你的工作中。这只需像源代码一样简单，而不用担心重新编码一切。当加入一个新公司或项目并继承需要立即使用的
    Python 代码时，这种情况也是可能的。
- en: If we want to take advantage of `ggplot` to examine the confusion matrix, we
    first need to convert to an R `data.frame`. The `value` is then the number of
    observations of each case, which we map onto `size`, and change the `shape` to
    1 (a circle). The result is shown on [Figure 7-7](#conf_mat_plot).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想利用 `ggplot` 来检查混淆矩阵，我们首先需要转换为 R 的 `data.frame`。`value` 然后是每种情况的观察次数，我们将其映射到
    `size`，并将 `shape` 更改为 1（圆形）。结果显示在 [图 7-7](#conf_mat_plot) 上。
- en: '[PRE20]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](Images/prds_0707.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0707.png)'
- en: Figure 7-7\. Plot of the classifier confusion matrix.
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-7\. 分类器混淆矩阵的绘图。
- en: It’s not surprising that we have some groups with a very high match since we
    already knew that our data was imbalanced to begin with. Now, what do we do with
    this nice Python code and output? At the end of [Chapter 6](ch06.xhtml#ch07),
    we saw a simple and effective way to create an interactive document (remember
    what you learned in [Chapter 5](ch05.xhtml#ch06)) using an RMarkdown with a `shiny`
    runtime. Let’s implement the same concept here.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 并不奇怪，我们有一些组具有非常高的匹配度，因为我们已经知道我们的数据一开始就不平衡。现在，我们如何处理这段漂亮的 Python 代码和输出呢？在 [第
    6 章](ch06.xhtml#ch07) 的结尾，我们看到了创建交互式文档的简单有效方法（记住你在 [第 5 章](ch05.xhtml#ch06) 学到的东西），使用带有
    `shiny` 运行时的 RMarkdown。让我们在这里实现相同的概念。
- en: Prediction and UI
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测和用户界面
- en: Once we have established a Python model, it’s general practice to test it with
    mock input. This allows us to ensure our model can handle the correct input data
    and is standard practice in ML engineering before connecting it with real user
    input. To this end, we’ll create five `sliderInputs` for the five features of
    our model. Here, we’ve hard-coded the min and max values for the sake of simplicity,
    but these can, of course, be dynamic.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们建立了 Python 模型，通常的做法是使用模拟输入进行测试。这使我们能够确保我们的模型能处理正确的输入数据，在 ML 工程中连接实际用户输入之前都是标准做法。为此，我们将为我们模型的五个特征创建五个
    `sliderInputs`。在这里，我们为简单起见硬编码了最小和最大值，但这些当然可以是动态的。
- en: '[PRE21]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Similar to what we did at the end of [Chapter 6](ch06.xhtml#ch07), we’ll access
    these values in the internal `input` list and use a `shiny` package function to
    render the appropriate output.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们在 [第 6 章](ch06.xhtml#ch07) 结尾所做的，我们将访问内部 `input` 列表中的这些值，并使用 `shiny` 包函数来呈现适当的输出。
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](Images/prds_0708.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0708.png)'
- en: Figure 7-8\. The result of our case study.
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-8\. 我们案例研究的结果。
- en: Those elements will respond dynamically to changes in user input. This is precisely
    what we need for our work since this is an interactive product and not a static
    one. You can see all of the different code blocks that we used in preparation
    for this project. They should require little change, with the most notable one
    being the ability to capture the user input in the inference part. This can be
    done by accessing the `input` object.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些元素将根据用户输入的更改动态响应。这正是我们工作所需的，因为这是一个互动产品，而不是静态产品。您可以看到我们在准备这个项目时使用的所有不同代码块。它们应该需要很少的更改，最显著的一个是在推断部分捕捉用户输入的能力。这可以通过访问`input`对象来完成。
- en: Final thoughts
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结思路
- en: In this case study, we demonstrated how one could take the best of both worlds
    and combine such excellent tools that modern data scientists have at our disposal
    to create remarkable user experiences, which delight visually and inform decision-making.
    This is but a basic example of such an elegant system, and we are confident that
    by showing you what’s possible, you - our readers - will create the data science
    products of the future!
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例研究中，我们展示了如何将现代数据科学家所拥有的优秀工具结合起来，以创建令人惊叹的用户体验，这些体验在视觉上令人愉悦并且促进决策。这只是这样一个优雅系统的基本例子，我们相信通过展示可能性，我们的读者——您——将创建未来的数据科学产品！
- en: '^([1](ch07.xhtml#idm45127447555192-marker)) Short, Karen C. 2017\. Spatial
    wildfire occurrence data for the United States, 1992-2015, FPA_FOD_20170508\.
    4th Edition. Fort Collins, CO: Forest Service Research Data Archive. [*https://doi.org/10.2737/RDS-2013-0009.4*](https://doi.org/10.2737/RDS-2013-0009.4)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch07.xhtml#idm45127447555192-marker)) 短，卡伦C. 2017年。美国1992-2015年空间野火发生数据，FPA_FOD_20170508。第4版。科林斯堡，科罗拉多州：森林服务研究数据档案馆。[*https://doi.org/10.2737/RDS-2013-0009.4*](https://doi.org/10.2737/RDS-2013-0009.4)
- en: ^([2](ch07.xhtml#idm45127447535416-marker)) We’ll leave a thorough development
    of a robust classification model to our motivated readers. Indeed you may also
    be interested in a regression that predicts the final fire size in acres. Curious
    readers will note that a few interesting notebooks are available on Kaggle to
    get you started.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch07.xhtml#idm45127447535416-marker)) 我们将详细开发一个强大的分类模型留给我们有动力的读者。事实上，您可能还对预测英亩最终火灾大小的回归感兴趣。有好奇心的读者可以注意到，在Kaggle上有一些有趣的笔记本可以帮助您入门。
- en: ^([3](ch07.xhtml#idm45127447533464-marker)) This is a far cry from developing,
    hosting, and deploying robust ML models, which, in any case, is not the focus
    of this book.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch07.xhtml#idm45127447533464-marker)) 这与开发、托管和部署强大的ML模型大相径庭，而且，在任何情况下，这也不是本书的重点。
- en: ^([4](ch07.xhtml#idm45127447463752-marker)) Some readers might not be familiar
    with this language. It is commonly used to specify configuration options as code,
    such as in this case.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch07.xhtml#idm45127447463752-marker)) 有些读者可能对这种语言不太熟悉。它通常用于像这种情况下的代码配置选项。
- en: ^([5](ch07.xhtml#idm45127447406008-marker)) This part can also be done very
    well within R, by using packages such as `dbplyr` or the using the Connections
    panel in RStudio.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch07.xhtml#idm45127447406008-marker)) 这部分也可以通过在R中使用`dbplyr`包或在RStudio中使用连接面板来很好地完成。
- en: ^([6](ch07.xhtml#idm45127447143208-marker)) This package is used to extend the
    `ggplot2` functionality for transformed datasets.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch07.xhtml#idm45127447143208-marker)) 这个包用于扩展`ggplot2`在转换数据集方面的功能。
- en: ^([7](ch07.xhtml#idm45127447128744-marker)) As another example of the modularity
    of the Python ML ecosystem have a look at the `imbalanced-learn` package [here](https://imbalanced-learn.org/)
    if you are looking for a solution to this.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch07.xhtml#idm45127447128744-marker)) 作为Python ML生态系统模块化的另一个例子，请查看`imbalanced-learn`包[这里](https://imbalanced-learn.org/)，如果您正在寻找解决方案。
- en: ^([8](ch07.xhtml#idm45127446950648-marker)) This is not a thorough exposition
    of all possible methods or optimizations since our focus is on building a bilingual
    workflow, not exploring machine learning techniques in detail. Readers may choose
    to refer to the official `scikit-learn` documentation for further guidance, in
    the aptly named [“Choosing the right estimator”](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch07.xhtml#idm45127446950648-marker)) 这不是所有可能方法或优化的全面阐述，因为我们的重点是建立双语工作流程，而不是详细探讨机器学习技术。读者可以选择参考官方的`scikit-learn`文档以获取进一步的指导，位于适当命名的[“选择正确的估计器”](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)页面。
