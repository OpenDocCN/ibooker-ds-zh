- en: 7 Statistical hypothesis testing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 统计假设检验
- en: This section covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖
- en: Comparing sample means to population means
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较样本均值和总体均值
- en: Comparing means of two distinct samples
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较两个不同样本的均值
- en: What is statistical significance?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是统计显著性？
- en: Common statistical errors and how to avoid them
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见统计错误及其避免方法
- en: 'Many ordinary people are forced to make hard choices every day. This is especially
    true of jurors in the American justice system. Jurors preside over a defendant’s
    fate during a trial. They consider the evidence and then decide between two competing
    hypotheses:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 许多普通人每天都要做出艰难的选择。这一点在美国司法系统中尤其如此。陪审团在审判中决定被告的命运。他们考虑证据，然后决定在两个相互竞争的假设之间做出选择：
- en: The defendant is innocent.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 被告是无辜的。
- en: The defendant is guilty.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 被告是有罪的。
- en: 'The two hypotheses are not weighted equally: the defendant is presumed to be
    innocent until proven guilty. Thus, the jurors assume that the innocence hypothesis
    is true. They can only reject the innocence hypothesis if the prosecution’s evidence
    is convincing. Yet the evidence is rarely 100% conclusive, and some doubt of the
    defendant’s guilt remains. That doubt is factored into the legal process. The
    jury is instructed to accept the innocence hypothesis if there is “reasonable
    doubt” of the defendant’s guilt. They can only reject the innocence hypothesis
    if the defendant appears guilty “beyond a reasonable doubt.”'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个假设并不等量齐观：被告在证明有罪之前被假定为无罪。因此，陪审团假定无罪假设是真实的。他们只能在控方的证据令人信服的情况下拒绝无罪假设。然而，证据很少达到100%的确定性，对被告罪行的怀疑仍然存在。这种怀疑被纳入法律程序。陪审团被告知，如果对被告的罪行有“合理的怀疑”，则应接受无罪假设。他们只能在被告看起来有罪“超出合理怀疑”的情况下拒绝无罪假设。
- en: 'Reasonable doubt is an abstract concept that’s hard to define precisely. Nonetheless,
    we can distinguish between reasonable and unreasonable doubt across a range of
    real-world scenarios. Consider the following two trial cases:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 合理怀疑是一个难以精确定义的抽象概念。尽管如此，我们可以在一系列现实场景中区分合理和不合理的怀疑。考虑以下两个审判案例：
- en: DNA evidence links the defendant directly to the crime. There is a 1 in a billion
    chance that the DNA does not belong to the defendant.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DNA证据直接将被告与犯罪联系起来。DNA不属于被告的可能性是1亿分之一。
- en: Blood-type evidence links the defendant directly to the crime. There is a 1
    in 15 chance that the blood does not belong to the defendant.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 血型证据直接将被告与犯罪联系起来。血型不属于被告的可能性是15分之一。
- en: In the first scenario, the jury cannot be 100% certain of the defendant’s guilt.
    There is a 1 in a billion chance that an innocent defendant is on trial. Such
    circumstances, however, are incredibly unlikely. It’s not reasonable to assume
    that this is the case. Thus, the jury should reject the innocence hypothesis.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个场景中，陪审团不能100%确信被告的罪行。有1亿分之一的可能性是无辜的被告正在受审。然而，这种情况极其不可能。认为这是合理的假设是不合理的。因此，陪审团应该拒绝无罪假设。
- en: 'Meanwhile, in the second scenario, the doubt is much more prevalent: 1 in 15
    people share the same blood type as the defendant. It’s reasonable to assume that
    someone else could have been present at the crime scene. While the jurors might
    doubt the defendant’s innocence, they will also reasonably doubt the defendant’s
    guilt. Thus, the jurors can’t reject the innocence hypothesis unless additional
    proof of guilt is offered.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，在第二个场景中，怀疑更为普遍：15个人中就有1人与被告有相同的血型。有理由假设可能还有其他人出现在犯罪现场。尽管陪审团可能会怀疑被告的无罪，但他们也会合理地怀疑被告的罪行。因此，除非提供额外的罪行证据，否则陪审团不能拒绝无罪假设。
- en: In our two scenarios, the jurors are carrying out a *statistical hypothesis
    test*. Such tests allow statisticians to choose between two competing hypotheses,
    both of which arise from uncertain data. One of the hypotheses is accepted or
    rejected based on a measured level of doubt. In this section, we explore several
    well-known statistical hypothesis testing techniques. We begin with a simple test
    to measure whether a sample mean noticeably deviates from an existing population.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的两个场景中，陪审团正在进行**统计假设检验**。这类检验允许统计学家在两个相互竞争的假设之间进行选择，这两个假设都源于不确定的数据。其中一个假设根据测量的怀疑程度被接受或拒绝。在本节中，我们将探讨几种著名的统计假设检验技术。我们从一个简单的测试开始，以测量样本均值是否明显偏离现有总体。
- en: 7.1 Assessing the divergence between sample mean and population mean
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 评估样本均值与总体均值之间的差异
- en: In section 6, we used statistics to analyze a single fifth-grade classroom.
    Now, let’s imagine a scenario where we analyze every fifth-grade classroom in
    North Dakota. One spring day, all fifth graders in the state are given the same
    assessment exam. The exam grades are fed into North Dakota’s assessment database,
    and the population mean and variance are computed across all grades in the state.
    According to the records, the population mean is 80, and the population variance
    is 100\. Let’s quickly store these values for later use.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在第6节中，我们使用统计学分析了一个五年级班级。现在，让我们想象一个场景，即我们分析北达科他州所有五年级班级的情况。一个春天的日子，该州的所有五年级学生都参加了相同的评估考试。考试分数被输入北达科他州的评估数据库，并计算了全州所有年级的平均值和方差。根据记录，总体平均值为80，总体方差为100。让我们快速将这些值存储起来以备后用。
- en: Listing 7.1 Population mean and variance of North Dakota grades
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.1 北达科他州年级的总体平均数和方差
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, suppose we travel to South Dakota and encounter a fifth-grade class whose
    mean exam grade equals 84%. This 18-student class has outperformed North Dakota’s
    population by 4 percentage points. Are fifth graders in South Dakota better educated
    than their North Dakota counterparts? If so, North Dakota should incorporate South
    Dakotan teaching methods into the curriculum. The curriculum adjustment would
    be costly, but the payoff to the students would be worth it. Of course, it’s also
    possible that the observed exam difference is a mere statistical fluke. Which
    is it? We’ll try to find out using hypothesis testing.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，假设我们前往南达科他州，并遇到一个五年级班级，其平均考试分数为84%。这个18人的班级比北达科他州的人口高出4个百分点。南达科他州的五年级学生是否比北达科他州的学生受教育程度更高？如果是这样，北达科他州应该将南达科他州的教学方法纳入课程。课程调整可能会很昂贵，但对学生来说，回报将是值得的。当然，也有可能观察到的考试差异只是一个统计上的偶然。它是哪一个？我们将通过假设检验来试图找出答案。
- en: We face two rival possibilities. First, it’s possible that the overall student
    population is identical across the neighboring states. In other words, a typical
    South Dakota classroom is no different from a typical North Dakota classroom.
    Under such circumstances, South Dakota’s population mean and variance values would
    be indistinguishable from those of its neighbor. Statisticians refer to this hypothetical
    parameter equivalency as the *null hypothesis*. If the null hypothesis is true,
    then our high-performing South Dakota classroom is simply an outlier and doesn’t
    represent the actual mean.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们面临两种可能的情形。首先，有可能相邻各州的整体学生人口是相同的。换句话说，一个典型的南达科他州班级与一个典型的北达科他州班级没有区别。在这种情况下，南达科他州的总体平均数和方差值将与邻州的可区分性相同。统计学家将这种假设参数等价性称为*零假设*。如果零假设成立，那么我们表现优异的南达科他州班级只是一个异常值，并不代表实际平均值。
- en: Alternatively, it’s feasible that the classroom’s high performance is representative
    of South Dakota’s general population. Thus the state’s mean and variance values
    would differ from North Dakota’s population parameters. Statisticians call this
    the *alternative hypothesis*. If the alternative hypothesis is true, we’ll update
    North Dakota’s fifth-grade curriculum. However, the alternative hypothesis is
    only true when the null hypothesis is false (and vice versa). Therefore, to justify
    the curriculum overhaul, we must first show that the null hypothesis is unlikely
    to be true. We can measure this likelihood using the central limit theorem.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，也有可能这个班级的高成绩代表了南达科他州的一般人口。因此，该州的平均数和方差值将与北达科他州的人口参数不同。统计学家称这为*备择假设*。如果备择假设成立，我们将更新北达科他州的五年级课程。然而，备择假设只有在零假设不成立时才成立（反之亦然）。因此，为了证明课程改革是合理的，我们必须首先证明零假设不太可能成立。我们可以使用中心极限定理来衡量这种可能性。
- en: Let’s temporarily assume that the null hypothesis is true and both Dakotas share
    the same population mean and variance. Consequently, we can model our 18-student
    classroom as a random sample taken from a normal distribution. That distribution’s
    mean will equal `population_mean`, and its standard deviation will equal the standard
    error of the mean (SEM), defined as `(population_variance / 18) ** 0.5`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时假设零假设成立，并且两个达科他州共享相同的总体平均数和方差。因此，我们可以将我们的18人班级建模为从正态分布中抽取的随机样本。该分布的平均值将等于`population_mean`，其标准差将等于平均误差（SEM），定义为`(population_variance
    / 18) ** 0.5`。
- en: Listing 7.2 Normal curve parameters if the null hypothesis is true
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.2 如果零假设成立，则正态曲线参数
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If the null hypothesis is true, the probability of encountering an average exam
    grade of at least 84% is equal to `stats.norm.sf(84 mean, sem)`. Let’s check that
    probability.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果零假设为真，遇到至少84%的平均考试成绩的概率等于 `stats.norm.sf(84, mean, sem)`。让我们检查这个概率。
- en: Listing 7.3 Finding the probability of a high-performance grade
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.3 查找高成绩概率
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Under the null hypothesis, a random South Dakotan classroom will obtain an average
    grade of at least 84% with a probability of 0.044\. This probability is low, and
    hence the 4% grade difference with the population mean appears extreme. But is
    it actually extreme? In section 1, we asked a similar question when we examined
    the likelihood of observing 8 heads out of 10 coin flips. In our coin analysis,
    we summed the probability of overperformance with the probability of underperformance.
    In other words, we summed the probability of observing eight or more heads with
    the probability of observing two heads or fewer. Here, our dilemma is identical.
    Analyzing exam overperformance is insufficient to evaluate extremeness; we must
    also consider the likelihood of an equally extreme underperformance. Therefore,
    we need to compute the probability of observing a sample mean that is at least
    four percentage points below the population mean of 80%.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在零假设下，一个随机的南达科他州教室获得至少84%的平均成绩的概率为0.044。这个概率很低，因此与总体平均值的4%的成绩差异看起来非常极端。但实际上它真的极端吗？在第1节中，当我们检查观察10次抛硬币中出现8次头的可能性时，我们提出了一个类似的问题。在我们的硬币分析中，我们将过度表现的概率与不足表现的概率相加。换句话说，我们将观察八次或更多头的概率与观察两次或更少头的概率相加。在这里，我们的困境是相同的。分析考试过度表现不足以评估极端性；我们还必须考虑同样极端的不足表现的可能性。因此，我们需要计算观察到样本均值至少低于总体均值80%四个百分点的概率。
- en: We will now compute the probability of observing an exam average that’s less
    than or equal to 76%. The calculation can be carried out with SciPy’s `stats.norm.cdf`
    method, which computes the *cumulative distribution function* of the normal curve.
    A cumulative distribution function is the direct opposite of the survival function,
    as seen in figure 7.1\. Applying `stats.norm.cdf` to `x` returns the area under
    a normal curve that ranges from negative infinity to `x`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将计算观察到低于或等于76%的考试平均成绩的概率。这个计算可以使用SciPy的 `stats.norm.cdf` 方法来完成，该方法计算正态曲线的
    *累积分布函数*。累积分布函数是生存函数的直接对立面，如图7.1所示。将 `stats.norm.cdf` 应用到 `x` 上返回从负无穷大到 `x` 的正态曲线下的面积。
- en: '![](../Images/07-01.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07-01.png)'
- en: Figure 7.1 Two areas are highlighted beneath a normal curve. The leftmost area
    covers all x-values that are less than or equal to 76%. We can compute that area
    using the cumulative distribution function. To execute the function, we simply
    need to call `stats.norm.cdf(76,` `mean,` `sem)`. Meanwhile, the rightmost area
    covers all x-values that are at least 84%. We can compute that area using the
    survival function. To execute the function, we call `stats.norm.sf(84,` `mean,`
    `sem)`.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1 在正态曲线下突出显示了两个区域。最左侧的区域覆盖了所有小于或等于76%的x值。我们可以使用累积分布函数来计算这个区域。要执行该函数，我们只需调用
    `stats.norm.cdf(76, mean, sem)`。同时，最右侧的区域覆盖了所有至少为84%的x值。我们可以使用生存函数来计算这个区域。要执行该函数，我们调用
    `stats.norm.sf(84, mean, sem)`。
- en: We now use `stats.norm.cdf` to find the probability of observing an unusually
    low average grade.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用 `stats.norm.cdf` 来找到观察到异常低平均成绩的概率。
- en: Listing 7.4 Finding the probability of a low-performance grade
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.4 查找低成绩概率
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It appears that `prob_low_grade` is equal to `prob_high_grade`. This equality
    arises from the symmetric shape of the normal curve. The cumulative distribution
    and the survival function are mirror images that are reflected across the mean.
    Thus, `stats.norm.sf(mean + x, mean, sem)` always equals `stats.norm.cdf(mean
    - x, mean, sem)` for any input `x`. Next, we visualize both functions to confirm
    their reflection across a vertically plotted mean (figure 7.2).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来 `prob_low_grade` 等于 `prob_high_grade`。这种等式源于正态曲线的对称形状。累积分布函数和生存函数是镜像，它们在均值处反射。因此，对于任何输入
    `x`，`stats.norm.sf(mean + x, mean, sem)` 总是等于 `stats.norm.cdf(mean - x, mean,
    sem)`。接下来，我们将可视化这两个函数，以确认它们在垂直绘制的均值处的反射（图7.2）。
- en: '![](../Images/07-02.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07-02.png)'
- en: Figure 7.2 A cumulative distribution function of a normal distribution plotted
    together with the survival function. The cumulative distribution function and
    the survival function are mirror images. They are reflected across the normal
    curve’s mean, which is plotted as a vertical line.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 正态分布的累积分布函数与生存函数一起绘制。累积分布函数和生存函数是镜像关系。它们在正态曲线的均值处反射，该均值以垂直线绘制。
- en: Listing 7.5 Comparing the survival and cumulative distribution functions
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.5 比较生存和累积分布函数
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now we are ready to sum `prob_high_grade` and `prob_low_grade`. Due to symmetry,
    that sum equals `2 * prob_high_grade`. Conceptually, the sum represents the probability
    of observing an extreme deviation from the population mean when the null hypothesis
    is true. Statisticians refer to this null-hypothesis-driven probability as the
    *p-value*. Let’s print the p-value arising from our data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备求和`prob_high_grade`和`prob_low_grade`。由于对称性，这个和等于`2 * prob_high_grade`。从概念上讲，这个和代表在零假设为真时观察到与总体均值极端偏差的概率。统计学家将这种由零假设驱动的概率称为*p值*。让我们打印出由我们的数据产生的p值。
- en: Listing 7.6 Computing the null-hypothesis-driven p-value
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.6 计算零假设驱动的p值
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Under the null hypothesis, there is approximately a 9% chance of observing the
    grade extreme at random. It’s therefore plausible that the null hypothesis is
    true and the extreme test average is just a random fluctuation. We haven’t definitively
    proved this, but our calculations raise serious doubts about restructuring North
    Dakota’s fifth-grade curriculum. What if the average of the South Dakotan class
    had equaled 85%, not 84%? Let’s check if that slight grade shift would have influenced
    our p-value.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在零假设下，随机观察到成绩极端的可能性大约为9%。因此，零假设可能是真实的，极端的测试平均成绩只是随机波动。我们还没有最终证明这一点，但我们的计算对重组北达科他州五年级课程提出了严重怀疑。如果南达科他州班级的平均成绩是85%，而不是84%呢？让我们检查这种微小的成绩变化是否会影响我们的p值。
- en: Listing 7.7 Computing the p-value for an adjusted sample mean
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.7 计算调整样本均值的p值
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: A tiny increase in the average grade has caused a threefold decrease in the
    p-value. Now, under the null hypothesis, there’s only a 3.3% chance of observing
    an average test grade that’s at least as extreme as 85%. This likelihood is low,
    and we might therefore be tempted to reject the null hypothesis. Should we accept
    the alternative hypothesis and invest our time and money in revamping North Dakota’s
    school system?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 平均成绩的微小增加导致了p值的降低三倍。现在，在零假设下，观察到平均测试成绩至少与85%一样极端的可能性只有3.3%。这种可能性很低，因此我们可能会倾向于拒绝零假设。我们应该接受备择假设，并投资时间和金钱来翻新北达科他州的教育体系吗？
- en: 'This is not an easy question to answer. Generally, statisticians tend to reject
    the null hypothesis if the p-value is less than or equal to 0.05\. The threshold
    of 0.05 is called the *significance level*, and p-values below that threshold
    are deemed to be *statistically significant.* However, 0.05 is just an arbitrary
    cutoff intended to heuristically uncover interesting data, not to make critical
    decisions. The threshold was first introduced in 1935 by famed statistician Ronald
    Fisher; later, Fisher said that the significance level should not remain static
    and should be manually adjusted based on the nature of the analysis. Regrettably,
    by then it was too late: the 0.05 cutoff had been adopted as our standard measure
    of significance. Today, most statisticians agree that a p-value below 0.05 implies
    an interesting signal in the data, so a p-value of 0.033 is sufficient to temporarily
    reject the null hypothesis and get one’s data published in a scientific journal.
    Unfortunately, the threshold of 0.05 doesn’t actually arise from the laws of mathematics
    and statistics: it’s an ad hoc value chosen by the academic community as a requirement
    for research publication. As a consequence, many research journals are flooded
    with *type I errors*. A type I error is defined as an erroneous rejection of the
    null hypothesis. Such errors occur when random data fluctuations are interpreted
    as genuine deviations from the population mean. Scientific articles containing
    type I errors falsely assert a difference between means where none exists.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个不容易回答的问题。通常，统计学家如果p值小于或等于0.05，就会拒绝零假设。0.05的阈值被称为*显著性水平*，低于该阈值的p值被认为是*统计显著的*。然而，0.05只是一个任意截止值，旨在启发式地揭示有趣的数据，而不是做出关键决策。这个阈值最早是在1935年由著名的统计学家罗纳德·费希尔提出的；后来，费希尔表示，显著性水平不应保持静态，而应根据分析的性质手动调整。遗憾的是，那时已经太晚了：0.05的截止值已经被采纳为我们衡量显著性的标准度量。今天，大多数统计学家都认为，p值低于0.05意味着数据中存在有趣的信号，因此0.033的p值就足以暂时拒绝零假设，并将数据发表在科学期刊上。不幸的是，0.05的阈值实际上并不是来自数学和统计学的定律：它是由学术社区作为一个研究发表的要求而选择的临时值。因此，许多研究期刊都充斥着*第一类错误*。第一类错误被定义为错误地拒绝零假设。这种错误发生在将随机数据波动解释为从总体均值的真实偏差时。包含第一类错误的科学文章错误地断言存在均值之间的差异，而实际上并不存在。
- en: How do we limit type I errors? Well, some scientists believe that a threshold
    of 0.05 is unreasonably high and that we should only reject the null hypothesis
    if the p-value is much lower. But there is currently no consensus on whether using
    a lower threshold is appropriate, since doing so would lead to an increase in
    *type II errors*, in which we wrongly reject the alternative hypothesis. When
    scientists commit a type II error, they fail to notice a legitimate discovery.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何限制第一类错误？嗯，一些科学家认为0.05的阈值不合理，我们应该只在p值远低于这个值时拒绝零假设。但目前还没有关于使用更低阈值是否合适的共识，因为这样做会导致*第二类错误*的增加，在第二类错误中，我们会错误地拒绝备择假设。当科学家犯第二类错误时，他们未能注意到一个合法的发现。
- en: Selecting an optimal significance level is difficult. Nevertheless, let’s temporarily
    set the significance level to a very stringent value of 0.001\. What would be
    the minimum grade average that would fall below this threshold? Let’s find out.
    We loop through all grade averages above 80%, computing the p-value as we go.
    We stop when we encounter a p-value that’s less than or equal to 0.001.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个最佳显著性水平是困难的。然而，让我们暂时将显著性水平设定为一个非常严格的值0.001。那么，最低的平均成绩是多少会低于这个阈值？让我们来找出答案。我们遍历所有超过80%的平均成绩，在过程中计算p值。当我们遇到一个小于或等于0.001的p值时，我们停止。
- en: Listing 7.8 Scanning for a stringent p-value result
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.8 搜索严格的p值结果
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Given the new threshold, we would require an average grade of at least 88%
    to reject the null hypothesis. Thus, an average grade of 87% would not be considered
    statistically significant, even though it’s noticeably higher than the population
    mean. Our lowering of the cutoff has inevitably exposed us to an increased risk
    of type II errors. Consequently, in this book, we maintain the commonly accepted
    p-value cutoff of 0.05\. But we also proceed with excessive caution to avoid erroneously
    rejecting the null hypothesis. In particular, we do our best to minimize the most
    common cause of type I errors and the topic of the next subsection: data dredging.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 给定新的阈值，我们需要平均成绩至少达到88%才能拒绝零假设。因此，平均成绩为87%不会被视为具有统计学意义的，尽管它明显高于总体均值。我们降低截止点的做法不可避免地增加了我们犯第二类错误的概率。因此，在这本书中，我们维持了普遍接受的p值截止点0.05。但我们同时也采取了过度的谨慎，以避免错误地拒绝零假设。特别是，我们尽最大努力减少最常见的第一类错误的成因，这也是下一小节的主题：数据挖掘。
- en: '7.2 Data dredging: Coming to false conclusions through oversampling'
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 数据挖掘：通过过度采样得出错误结论
- en: 'Sometimes, statistics students utilize the p-value incorrectly. Consider the
    following simple scenario. Two roommates pour out a bag of candy. The bag contains
    multiple candy pieces in five different colors. There are more blue candies in
    the bag than any other individual color. The first roommate assumes that blue
    is the dominant color in any candy bag. The second roommate disagrees: she computes
    the p-value based on the null hypothesis that all colors occur with equal likelihood.
    That p-value is greater than 0.05\. However, the first roommate refuses to back
    down. He opens another bag of candy. The p-value is recomputed from the contents
    of that bag. This time, the p-value is equal to 0.05\. The first roommate claims
    victory: he asserts that given the low p-value, the null hypothesis is probably
    false. Yet he is wrong.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，统计学学生使用p值的方式不正确。考虑以下简单场景。两个室友倒出一袋糖果。袋子里有五种不同颜色的糖果。蓝色糖果的数量比任何其他单一颜色都多。第一个室友认为蓝色是任何糖果袋中的主导颜色。第二个室友不同意：她根据所有颜色出现概率相等的零假设计算p值。这个p值大于0.05。然而，第一个室友拒绝退让。他打开另一袋糖果。这次，p值是根据那袋糖果的内容重新计算的。这次，p值等于0.05。第一个室友宣称胜利：他断言，鉴于低p值，零假设很可能是错误的。然而，他是错的。
- en: 'The first roommate fundamentally misconstrued the meaning of the p-value. He
    wrongly assumed it represents the probability of the null hypothesis being true.
    In fact, the p-value represents the probability of observing deviations if the
    null hypothesis is true. The difference between the definitions is subtle but
    very important: the first definition implies that the null hypothesis is likely
    to be false if the p-value is low; but the second definition guarantees that we’ll
    eventually observe a low p-value by repeatedly counting candies, even when the
    null hypothesis is true. Furthermore, the frequency of low p-value observations
    will equal the p-value itself. Hence, if we open 100 bags of candy, we should
    expect to observe a p-value of 0.05 approximately five times. By taking random
    measurements repeatedly, we will eventually obtain a statistically significant
    result, even if no statistical significance exists!'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个室友根本误解了p值的含义。他错误地认为它代表的是零假设为真的概率。实际上，p值代表的是如果零假设为真，观察到偏差的概率。这两种定义之间的区别虽然微妙但非常重要：第一种定义暗示如果p值低，零假设很可能是错误的；但第二种定义保证我们最终会观察到低p值，即使零假设为真。此外，低p值观察的频率将等于p值本身。因此，如果我们打开100袋糖果，我们应该期望观察到大约五次的p值为0.05。通过重复随机测量，我们最终会得到一个具有统计学意义的结论，即使实际上不存在统计学上的显著性！
- en: Running the same experiment too many times increases our risk of type I errors.
    Let’s explore this notion in the context of our fifth-grade exam analysis. Suppose
    that North Dakota’s statewide test performance does not diverge from the exam
    results in the other 49 states. More precisely, we’ll assume that the national
    mean and variance equal North Dakota’s `population_mean` and `population_variance`
    exam-grade results. Thus, the null hypothesis is true for all the states in the
    United States.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 进行相同的实验次数过多会增加我们犯第一类错误的概率。让我们在五年级考试分析的情况下探讨这个概念。假设北达科他州的州级测试表现与其他49个州的考试结果没有差异。更确切地说，我们将假设全国平均数和方差等于北达科他州的`population_mean`和`population_variance`考试成绩结果。因此，对于美国所有州来说，零假设都是成立的。
- en: Furthermore, let’s assume we don’t yet know that the null hypothesis is always
    true. The only things we know for sure are North Dakota’s population mean and
    variance. We set out on a road trip in search of a state whose grade distribution
    differs from North Dakota’s distribution. Unfortunately, our search is bound to
    be futile because no such state exists.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，让我们假设我们还没有意识到零假设总是真实的。我们唯一确定的是北达科他州的人口均值和方差。我们开始了一次公路旅行，寻找一个成绩分布与北达科他州不同的州。不幸的是，我们的搜索注定是徒劳的，因为不存在这样的州。
- en: Our first stop is Montana. There, we choose a random fifth-grade classroom of
    18 students. We then compute the classroom’s average grade. Since the null hypothesis
    is secretly true, we can simulate the value of that average grade by sampling
    from a normal distribution defined by `mean` and `sem`. Let’s simulate the exam
    performance of the class by calling `np.random.normal(mean, sem)`. The method
    call samples from a normal distribution defined by the inputted variables.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一站是蒙大拿州。在那里，我们随机选择了一个有18名学生的五年级教室。然后我们计算这个教室的平均成绩。由于零假设在秘密中是真实的，我们可以通过从由`mean`和`sem`定义的正态分布中采样来模拟这个平均成绩的值。让我们通过调用`np.random.normal(mean,
    sem)`来模拟这个班级的考试成绩。这个方法调用从由输入变量定义的正态分布中采样。
- en: Listing 7.9 Randomly sampling Montana’s exam performance
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.9 随机采样蒙大拿州考试成绩
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The average exam grade in the class equals approximately 84.16\. We can determine
    if that average is statistically significant by checking if its p-value is less
    than or equal to 0.05.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 班级平均考试成绩约为84.16分。我们可以通过检查其p值是否小于或等于0.05来确定这个平均值是否具有统计学意义。
- en: Listing 7.10 Testing the significance of Montana’s exam performance
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.10 测试蒙大拿州考试成绩的显著性
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The average grade is not statistically significant. We will continue our journey
    and visit a single 18-student classroom in each of the remaining 48 states, computing
    the grade average for each classroom. The p-value will also be computed. Once
    we discover a statistically significant p-value, our journey will end.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 平均成绩不具有统计学意义。我们将继续我们的旅程，并访问剩余的48个州中的每个18名学生教室，计算每个教室的平均成绩。同时也会计算p值。一旦我们发现一个具有统计学意义的p值，我们的旅程将结束。
- en: The following code simulates our travels. It iterates through the remaining
    48 states, randomly drawing a grade average for each state. Once a statistically
    significant grade average is discovered, the iteration loop will stop.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码模拟了我们的旅行。它遍历剩余的48个州，为每个州随机抽取一个平均成绩。一旦发现一个具有统计学意义的平均成绩，迭代循环将停止。
- en: Listing 7.11 Randomly searching for a significant state result
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.11 随机搜索具有显著州结果的州
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The fifth state that we visit produces a statistically significant result! A
    classroom in the state has a grade average of 85.28\. The associated p-value of
    0.025 falls below our 0.05 cutoff. It appears we can reject the null hypothesis!
    However, this conclusion is erroneous since the null hypothesis is true. What
    went wrong? Well, as stated earlier, the frequency of low p-value observations
    will equal the p-value itself. Therefore, we expect to encounter a p-value of
    0.025 approximately 2.5% of the time, even if the null hypothesis is true. Since
    we are traveling across 49 states, and 2.5% of 49 is 1.225, we should expect to
    visit approximately one state with a random p-value of roughly 0.025.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们访问的第五个州产生了具有统计学意义的成果！该州的一个教室的平均成绩为85.28分。相关的p值为0.025，低于我们的0.05截止值。看起来我们可以拒绝零假设！然而，这个结论是错误的，因为零假设是真实的。出了什么问题？嗯，如前所述，低p值观察的频率将等于p值本身。因此，即使零假设是真实的，我们也期望大约2.5%的时间遇到p值约为0.025的情况。由于我们穿越了49个州，49的2.5%是1.225，我们应该期望大约访问一个随机p值约为0.025的州。
- en: Our quest to find a statistically significant result was doomed from the start
    because we have misused statistics. We have indulged in the cardinal statistical
    sin of *data dredging*, also known as *data fishing* or *p-hacking*. In data dredging,
    experiments are repeated over and over until a statistically significant result
    is found. Then the statistically significant result is presented to others, while
    the remaining failed experiments are discarded. Data dredging is the most common
    cause of type I errors in scientific publications. Sadly, sometimes researchers
    formulate a hypothesis and repeat an experiment until the particular false hypothesis
    is validated as true. For instance, a researcher might hypothesize that certain
    candies cause cancer in mice. The researcher proceeds to feed a specific candy
    brand to a group of mice, but no cancer link is found. The researcher then switches
    the brand of candy and runs the experiment again. And again. And again. Years
    later, a brand of candy linked to cancer is finally found. Of course, the actual
    experiment outcome is borderline fraudulent. No real statistical link exists between
    cancer and candy—the researcher has simply run the experiment too many times,
    until a low p-value was randomly measured.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们寻找统计学上显著结果的努力从一开始就注定要失败，因为我们误用了统计学。我们沉溺于统计学的根本性错误*数据挖掘*，也称为*数据钓鱼*或*p-hacking*。在数据挖掘中，实验一次又一次地重复，直到找到统计学上显著的结果。然后，统计学上显著的结果被展示给他人，而其余失败的实验被丢弃。数据挖掘是科学出版物中第一类错误最常见的原因。遗憾的是，有时研究人员提出一个假设，并重复实验，直到特定的错误假设被验证为真。例如，研究人员可能假设某些糖果会导致老鼠患癌症。研究人员继续给一组老鼠喂食特定的糖果品牌，但没有发现癌症的联系。然后，研究人员更换糖果品牌并再次进行实验。再次。再次。多年后，终于发现了一种与癌症有关的糖果品牌。当然，实际的实验结果几乎是有欺诈性的。癌症和糖果之间不存在真正的统计联系——研究人员只是进行了太多的实验，直到随机测量到一个低的p值。
- en: 'Avoiding data dredging is not difficult: we must simply choose in advance a
    finite number of experiments to run. Then we set our significance level to 0.05
    divided by the planned experiment count. This simple technique is known as the
    *Bonferroni correction*. Let’s repeat our analysis of US exam performance using
    the Bonferroni correction. The analysis requires us to visit 49 states to evaluate
    49 classrooms, so our significance level should be set to 0.05 / 49.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 避免数据挖掘并不困难：我们只需事先选择一个有限的实验数量进行。然后我们将显著性水平设置为0.05除以计划实验的数量。这种简单技术被称为*Bonferroni校正*。让我们重复使用Bonferroni校正分析美国考试表现。分析需要我们访问49个州以评估49个教室，因此我们的显著性水平应设置为0.05
    / 49。
- en: Listing 7.12 Using the Bonferroni correction to adjust significance
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.12 使用Bonferroni校正调整显著性
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We rerun our analysis, which will terminate if we encounter a p-value that’s
    less than or equal to `significance_level`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重新运行我们的分析，如果遇到小于或等于`significance_level`的p值，分析将终止。
- en: Listing 7.13 Rerunning an analysis using an adjusted significance level
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.13 使用调整后的显著性水平重新运行分析
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We’ve visited 49 states and found no statistically significant deviations from
    North Dakota’s population mean and variance. The Bonferroni correction has allowed
    us to avoid a type I error.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们访问了49个州，发现与北达科他州的人口均值和方差没有统计学上显著的差异。Bonferroni校正使我们避免了第一类错误。
- en: As a final word of caution, the Bonferroni correction only works if we divide
    0.05 by the number of planned experiments. It is not effective if we divide by
    the count of completed experiments. For instance, if we plan to run 1,000 experiments,
    but the p-value of our very first experiment equals 0.025, we should not alter
    our significance level to 0.05 / 1\. Similarly, if the p-value of the second completed
    experiment equals 0.025, we should maintain a significance level of 0.05 / 1000
    rather than adjust it to 0.05 / 2\. Otherwise, we risk wrongly biasing our conclusions
    toward our first few experimental outcomes. All experiments must be treated equally
    for us to draw a fair, correct conclusion.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最后提醒一句，Bonferroni校正只有在我们将0.05除以计划进行的实验数量时才有效。如果我们除以已完成实验的数量，则它不起作用。例如，如果我们计划进行1000次实验，但我们的第一次实验的p值等于0.025，我们不应将显著性水平调整为0.05
    / 1。同样，如果第二次完成的实验的p值等于0.025，我们应该保持显著性水平为0.05 / 1000，而不是将其调整为0.05 / 2。否则，我们可能会错误地偏向我们的前几个实验结果。为了得出公平、正确的结论，我们必须对所有实验一视同仁。
- en: The Bonferroni correction is a useful technique for more accurate hypothesis
    testing. It can be applied to all kinds of statistical hypothesis tests beyond
    just simple tests that exploit both population mean and variance. This is fortunate
    because statistical tests vary in their levels of complexity. In the next subsection,
    we explore a more complicated test that does not depend on knowing the population
    variance.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Bonferroni校正是一种用于更准确假设检验的有用技术。它可以应用于所有类型的统计假设检验，而不仅仅是利用总体均值和方差的简单测试。这是幸运的，因为统计测试的复杂程度各不相同。在下一个小节中，我们将探讨一个更复杂的测试，该测试不依赖于知道总体方差。
- en: '7.3 Bootstrapping with replacement: Testing a hypothesis when the population
    variance is unknown'
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 使用替换法进行自助法：在总体方差未知时检验假设
- en: We are easily able to compute a p-value using the population mean and variance.
    Regrettably, in many real-life circumstances, the population variance is not known.
    Consider the following scenario, in which we own a very large aquarium. It holds
    20 tropical fish of lengths varying from 2 cm to nearly 120 cm. The average fish
    length equals 27 cm. We represent these fish lengths using the `fish_lengths`
    array.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很容易就能使用总体均值和方差计算p值。遗憾的是，在许多现实情况下，总体方差是未知的。考虑以下场景，我们拥有一一个非常大的水族箱。它容纳了20条从2厘米到近120厘米不等长度的热带鱼。平均鱼长度为27厘米。我们使用`fish_lengths`数组来表示这些鱼长度。
- en: Listing 7.14 Defining lengths of fish in an aquarium
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.14 定义水族箱中鱼的长度
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Does our aquarium accurately capture the distributed lengths of real tropical
    fish? We would like to find out. A trusted source informs us that the population
    mean length of wild tropical fish equals 37 cm. There is a sizable 10 cm difference
    between the population mean and our sample mean. That difference feels significant,
    but feelings have no place in rigorous statistics. We must determine if the difference
    is statistically significant in order to draw a valid conclusion.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的水族箱是否准确地捕捉到了真实热带鱼的分布长度？我们想找出答案。一个可靠的来源告诉我们，野生热带鱼的总体平均长度为37厘米。总体均值和样本均值之间有10厘米的显著差异。这种差异感觉很重要，但在严格的统计学中，感觉没有位置。我们必须确定这种差异是否在统计学上显著，以便得出有效的结论。
- en: Thus far, we have measured statistical significance using our `compute_p_value`
    function. However, we cannot apply this function to our fish data since we don’t
    know the population variance! Without the population variance, we cannot compute
    the SEM, which is a variable required to run `compute_p_value`. How do we find
    the standard error of the mean when the population variance is not known?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用`compute_p_value`函数来衡量统计显著性。然而，我们不能将此函数应用于我们的鱼数据，因为我们不知道总体方差！没有总体方差，我们无法计算SEM，这是运行`compute_p_value`所需的变量。当总体方差未知时，我们如何找到平均误差的标准？
- en: 'At first glance, it appears we have no way of finding the SEM. We could naively
    treat our sample variance as an estimate of the population variance by executing
    `fish_lengths.var()`. Unfortunately, small samples are prone to random variance
    fluctuations, so any such estimate is highly unreliable. Thus, we are stuck. We
    face a seemingly impenetrable problem and must rely on a seemingly impossible
    solution: *bootstrapping with replacement*. The term *bootstrapping* originates
    from the phrase “pull yourself up by your bootstraps.” The phrase refers to lifting
    yourself into the air by pulling on the laces of your boots. Of course, doing
    so is impossible. In bootstrapping with replacement, we’ll attempt something equally
    impossible by computing a p-value directly from our limited data! Despite this
    seemingly ludicrous solution, we will be successful in our efforts.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 初看之下，我们似乎没有找到SEM的方法。我们可以天真地通过执行`fish_lengths.var()`将样本方差视为总体方差的估计。不幸的是，小样本容易受到随机方差波动的影响，因此任何此类估计都极其不可靠。因此，我们陷入了困境。我们面临一个看似无法攻克的难题，必须依赖一个看似不可能的解决方案：*替换法自助法*。术语*自助法*源自短语“拔自己的靴带”。这个短语指的是通过拉动靴子的鞋带将自己拉入空中。当然，这样做是不可能的。在替换法自助法中，我们将尝试同样不可能的事情，即直接从我们的有限数据中计算p值！尽管这个看似荒谬的解决方案，我们仍然会成功。
- en: We begin the bootstrapping procedure by removing a random fish from the aquarium.
    The length of the selected fish is measured for later use.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始自助法过程，首先从水族箱中随机移除一条鱼。所选鱼的长度将被测量以供后续使用。
- en: Listing 7.15 Sampling a random fish from the aquarium
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.15 从水族箱中随机抽取一条鱼
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now we place the chosen fish back into the aquarium. This replacement step is
    where bootstrapping with replacement gets its name. After we return the fish,
    we reach into the aquarium again and choose another fish at random. There is a
    1 in 20 chance that we’ll select the same fish as before, which is perfectly acceptable.
    We record the length of the chosen fish and place it back into the water. Then
    we repeat the procedure 18 more times until 20 random fish lengths have been measured.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将选中的鱼放回水族箱。这个替换步骤就是有放回抽样的名字由来。在我们将鱼放回后，我们再次伸入水族箱并随机选择另一条鱼。我们有1/20的机会会再次选择到之前选中的鱼，这是完全可以接受的。我们记录所选鱼的长径并将其放回水中。然后我们重复此过程18次，直到测量了20个随机鱼长。
- en: Listing 7.16 Sampling 20 random fish with repetition
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.16 重复抽样20条随机鱼
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The `sampled_fish_lengths` list contains 20 measurements, all taken from the
    20-element `fish_lengths` array. However, the elements of `fish_lengths` and `sampled_fish_lengths`
    are not identical. Due to random sampling, the mean values of the array and the
    list are likely to differ.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`sampled_fish_lengths`列表包含20个测量值，所有这些测量值都来自20个元素的`fish_lengths`数组。然而，`fish_lengths`和`sampled_fish_lengths`的元素并不相同。由于随机抽样，数组和列表的平均值很可能会不同。'
- en: Listing 7.17 Comparing the sample mean to the aquarium mean
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.17 比较样本均值与水族箱均值
- en: '[PRE16]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The mean of the sampled fish lengths is 26.03 cm. It deviates from our original
    mean by 0.97 cm. Thus, sampling with replacement has introduced some variance
    into our observations. If we sample another 20 measurements from the aquarium,
    we can expect the subsequent sample mean to also deviate from 27 cm. Let’s confirm
    by repeating our sampling using a single line of code: `np.random.choice(fish_lengths,
    size=20, replace=True)`. Setting the `replace` parameter to `True` ensures that
    we sample with replacement from the `fish_lengths array`.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样鱼长度的平均值是26.03厘米。它比我们的原始平均值偏离了0.97厘米。因此，有放回抽样在我们的观察中引入了一些方差。如果我们从水族箱中再抽取20个测量值，我们可以预期后续的样本平均值也将偏离27厘米。让我们通过重复我们的抽样过程来确认，使用一行代码：`np.random.choice(fish_lengths,
    size=20, replace=True)`。将`replace`参数设置为`True`确保我们从`fish_lengths数组`中进行有放回抽样。
- en: Listing 7.18 Sampling with replacement using NumPy
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.18 使用NumPy进行有放回抽样
- en: '[PRE17]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ As a side note, the replace parameter is currently set to True by default
    within the function.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 作为旁注，函数中当前默认将replace参数设置为True。
- en: 'The new sample mean equals 26.16 cm. Our mean values will fluctuate when we
    sample with replacement: fluctuation implies randomness, and thus our mean values
    are randomly distributed. Let’s explore the shape of this random distribution
    by repeating our sampling process 150,000 times. During iteration, we compute
    the mean of 20 random fish; then we plot a histogram of the 150,000 sampled means
    (figure 7.3).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 新的样本均值等于26.16厘米。当我们进行有放回抽样时，我们的均值值将会波动：波动意味着随机性，因此我们的均值值是随机分布的。让我们通过重复我们的抽样过程150,000次来探索这个随机分布的形状。在迭代过程中，我们计算20条随机鱼的平均值；然后我们绘制150,000个抽样均值的直方图（图7.3）。
- en: Listing 7.19 Plotting the distribution of 150,000 sampled means
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.19 绘制150,000个抽样均值的分布
- en: '[PRE18]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/07-03.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/07-03.png)'
- en: Figure 7.3 A histogram of sample means computed using sampling with replacement.
    The histogram is not bell shaped; it’s asymmetric.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 使用有放回抽样计算出的样本均值直方图。直方图不是钟形；它是不对称的。
- en: 'The histogram we’ve generated is not a normal curve. The shape is not symmetric:
    its left side rises more steeply than its right side. Mathematicians refer to
    this asymmetry as a *skew*. We can confirm the skew in our histogram by calling
    `stats.skew(sample_means)`. The `stats.skew` method returns a nonzero value when
    the inputted data is asymmetric.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成的直方图不是正态曲线。形状不对称：其左侧比右侧上升得更陡峭。数学家将这种不对称性称为*偏度*。我们可以通过调用`stats.skew(sample_means)`来确认我们直方图中的偏度。当输入的数据不对称时，`stats.skew`方法返回一个非零值。
- en: Listing 7.20 Computing the skew of an asymmetric distribution
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.20 计算不对称分布的偏度
- en: '[PRE19]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ No data is ever perfectly symmetric, and the skew is rarely 0.0, even if the
    data is sampled from a normal curve. However, normal data tends to have a skew
    that is exceedingly close to 0.0\. Any data with a skew whose absolute value is
    greater than 0.04 is very unlikely to come from a normal distribution.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 没有数据是完全对称的，偏度很少为0.0，即使数据是从正态曲线中抽取的也是如此。然而，正态数据往往具有非常接近0.0的偏度。任何偏度的绝对值大于0.04的数据几乎不可能来自正态分布。
- en: Our asymmetric histogram cannot be modeled using a normal distribution. Nevertheless,
    the histogram represents a continuous probability distribution. Like all continuous
    distributions, the histogram can be mapped to a probability density function,
    a cumulative distribution function, and a survival function. Knowing the function
    outputs would be useful. For instance, the survival function would give us the
    probability of observing a sample mean that’s greater than our population mean.
    We could obtain the function outputs by manually writing code that computes the
    curve area using the `bin_edges` and `likelihoods` arrays.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的不对称直方图不能用正态分布来建模。尽管如此，直方图代表了一个连续概率分布。像所有连续分布一样，直方图可以被映射到概率密度函数、累积分布函数和生存函数。了解函数输出将是有用的。例如，生存函数会给我们观察到的样本均值大于总体均值的概率。我们可以通过手动编写代码，使用`bin_edges`和`likelihoods`数组计算曲线面积来获得函数输出。
- en: Alternatively, we can just use SciPy, which provides us with a method for obtaining
    all three functions from the histogram. That method is `stats.rv_histogram`, which
    takes as input a tuple defined by the `bin_edges` and `likelihoods` arrays. Calling
    `stats.rv_histogram`((`likelihoods,` `bin_edges))` returns a `random_variable`
    SciPy object containing `pdf`, `cdf`, and `sf` methods, just like `stats.norm.`
    The `random_variable .pdf` method outputs the probability density for the histogram.
    Likewise, the `random_ variable.cdf` and `random_variable.sf` methods output the
    cumulative distribution function and the survival function, respectively.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们也可以直接使用SciPy，它为我们提供了一种从直方图中获取所有三个函数的方法。这个方法是`stats.rv_histogram`，它接受由`bin_edges`和`likelihoods`数组定义的元组作为输入。调用`stats.rv_histogram((`likelihoods,`
    `bin_edges))`会返回一个包含`pdf`、`cdf`和`sf`方法的`random_variable` SciPy对象，就像`stats.norm.`一样。`random_variable
    .pdf`方法输出直方图的概率密度。同样，`random_variable.cdf`和`random_variable.sf`方法分别输出累积分布函数和生存函数。
- en: The following code computes the `random_variable` object arising from the histogram.
    Then we plot the probability density function by calling `random_variable.pdf
    (bin_edges)` (figure 7.4).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码计算由直方图产生的`random_variable`对象。然后我们通过调用`random_variable.pdf (bin_edges)`绘制概率密度函数（图7.4）。
- en: Listing 7.21 Fitting data to a generic distribution using SciPy
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.21 使用SciPy将数据拟合到通用分布
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](../Images/07-04.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片7-04](../Images/07-04.png)'
- en: Figure 7.4 An asymmetric histogram overlaid with its probability density function.
    We used SciPy to learn the probability density function from the histogram.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 一个不对称直方图及其概率密度函数的重叠。我们使用了SciPy从直方图中学习概率密度函数。
- en: As expected, the probability density function perfectly resembles the histogram
    shape. Let’s now plot both the cumulative distribution function and the survival
    function associated with `random_variable`. We should anticipate that the two
    plotted functions will not be symmetric around the mean. To check for this asymmetry,
    we plot the distribution’s mean using a vertical line. We obtain that mean by
    calling `random_ variable.mean()` (figure 7.5).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，概率密度函数与直方图形状完美相似。现在让我们绘制与`random_variable`相关的累积分布函数和生存函数。我们应该预期这两个绘制的函数将不会围绕均值对称。为了检查这种不对称性，我们使用垂直线绘制分布的均值。我们通过调用`random_variable.mean()`获得这个均值（图7.5）。
- en: Listing 7.22 Plotting the mean and interval areas for a generic distribution
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.22 绘制通用分布的均值和区间面积
- en: '[PRE21]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](../Images/07-05.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图片7-05](../Images/07-05.png)'
- en: Figure 7.5 A cumulative distribution function of an asymmetric distribution
    plotted together with the survival function. The two functions no longer symmetrically
    reflect across the mean as they did in our normal-curve analysis. Therefore, we
    can no longer compute the p-value simply by doubling the survival function output.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 一个不对称分布的累积分布函数与生存函数一起绘制。这两个函数不再像我们在正态曲线分析中那样对称地反映在均值两侧。因此，我们不能再简单地通过将生存函数输出加倍来计算p值。
- en: The mean of the distribution is approximately 27 cm, which is also the mean
    length of the fish in our aquarium. A random fish sample is likely to produce
    a value that is close to the aquarium’s mean. However, sampling with replacement
    sometimes produces a value greater than 37 cm or less than 17 cm. The probabilities
    of observing these extremes can be computed from our two plotted functions. Let’s
    examine these two functions in more detail.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 分布的均值大约为27厘米，这也是我们水族馆中鱼的平均长度。随机鱼样本很可能产生一个接近水族馆均值的值。然而，有放回的抽样有时会产生大于37厘米或小于17厘米的值。观察这些极端值的概率可以通过我们的两个绘图函数来计算。让我们更详细地检查这两个函数。
- en: Based on our plot, the cumulative distribution function and the survival function
    are not mirror images. Nor do they intersect directly at the mean, as they did
    in our normal-curve analysis. Our distribution doesn’t behave like a symmetric
    normal curve, which leads to certain consequences. Using the symmetric curve,
    we could compute the p-value by doubling the survival function. In our asymmetric
    distribution, the survival function by itself is insufficient for computing tail-end
    probabilities. Fortunately, we can use both the survival function and the cumulative
    distribution function to uncover probabilities of extreme observations. Using
    these probabilities, we can evaluate the statistical significance.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的图表，累积分布函数和生存函数并不是镜像关系。它们也没有直接在均值处相交，就像我们在正态曲线分析中所做的那样。我们的分布不像对称的正态曲线，这导致了一些后果。使用对称曲线，我们可以通过将生存函数加倍来计算p值。在我们的非对称分布中，仅凭生存函数本身不足以计算尾部概率。幸运的是，我们可以使用生存函数和累积分布函数来揭示极端观测值的概率。使用这些概率，我们可以评估统计显著性。
- en: 'We can measure significance by answering this question: what is the probability
    that 20 sampled (with replacement) fish produce a mean as extreme as the population
    mean? As a reminder, the population mean is 37 cm, which is 10 cm greater than
    our distribution mean. Therefore, *extremeness* is defined as a sampled output
    that’s at least 10 cm away from `rv_mean`. Based on our previous discussions,
    the problem can be broken down into computing two distinct values. First we must
    compute the probability of observing a sample mean that’s at least 37 cm, and
    then we must compute the probability of observing a sample mean that’s less than
    or equal to 17 cm. The former probability equals `random_variable.sf(37)`, while
    the latter equals `random_variable .cdf(17)`. Summing these two values will provide
    us with our answer.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过回答以下问题来衡量显著性：20个样本（有放回）产生与总体均值一样极端的均值的概率是多少？作为提醒，总体均值为37厘米，比我们的分布均值大10厘米。因此，“极端性”定义为至少比`rv_mean`远10厘米的样本输出。根据我们之前的讨论，问题可以分解为计算两个不同的值。首先，我们必须计算观察到至少37厘米的样本均值的概率，然后我们必须计算观察到小于或等于17厘米的样本均值的概率。前者概率等于`random_variable.sf(37)`，而后者等于`random_variable.cdf(17)`。将这两个值相加将为我们提供答案。
- en: Listing 7.23 Computing the probability of an extreme sample mean
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.23 计算极端样本均值的概率
- en: '[PRE22]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The probability of observing an extreme value from our sampling is approximately
    0.10\. In other words, one-tenth of random aquarium samplings will produce a mean
    that’s at least as extreme as the population mean. Our population mean is not
    as far from the aquarium mean as we thought. In fact, a mean discrepancy of 10
    cm or more will appear in 10% of sampled fish outputs. Thus, the difference between
    our sample mean of 27 cm and our population mean of 37 cm is not statistically
    significant.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 观察到极端值的概率大约为0.10。换句话说，十分之一的随机水族馆样本将产生至少与总体均值一样极端的均值。我们的总体均值并不像我们想象的那么远离水族馆均值。事实上，10厘米或更多的均值差异将出现在10%的样本鱼产量中。因此，我们的样本均值27厘米和总体均值37厘米之间的差异在统计学上并不显著。
- en: By now, all this should seem familiar. The `prob_extreme` value is just the
    p-value in disguise. When the null hypothesis is true, the difference between
    the sample mean and population mean will be at least 10 cm in 10% of sampled cases.
    This p-value of 0.1 is greater than our cutoff of 0.05\. So, we cannot reject
    the null hypothesis. There is no statistically significant difference between
    our sample mean and population mean.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，所有这些都应该看起来很熟悉。`prob_extreme`值只是伪装成p值。当零假设为真时，样本均值与总体均值之间的差异将在10%的样本案例中至少为10厘米。这个0.1的p值大于我们的阈值0.05。因此，我们不能拒绝零假设。我们的样本均值和总体均值之间没有统计学上的显著差异。
- en: We’ve computed a p-value in a roundabout way. Some readers may be suspicious
    of our methods—after all, sampling from our limited collection of 20 fish seems
    like a strange way to draw statistical insights. Nevertheless, the described technique
    is legitimate. Bootstrapping with replacement is a reliable procedure for extracting
    the p-value, especially when dealing with limited data.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以一种迂回的方式计算了p值。一些读者可能对我们的方法表示怀疑——毕竟，从我们有限的20条鱼中抽取样本似乎是一种奇怪的获取统计洞察的方法。尽管如此，描述的技术是合法的。带替换的bootstrap是一种可靠的提取p值的方法，尤其是在处理有限数据时。
- en: Useful methods for bootstrapping with replacement
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 带替换的bootstrap的有用方法
- en: '`rv = stats.rv_histogram((likelihoods, bin_edges))`—Creates a random variable
    object `rv` based on the histogram output of `likelihoods, bin_edges = np.hist(data)`.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rv = stats.rv_histogram((likelihoods, bin_edges))`—基于`likelihoods, bin_edges
    = np.hist(data)`的直方图输出创建一个随机变量对象`rv`。'
- en: '`p_value = rv.sf(head_extreme) + random_variable.cdf(tail_extreme)`—Computes
    a p-value from a random variable object based on the survival output and the cumulative
    distribution output of the head extreme and tail extreme, respectively.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`p_value = rv.sf(head_extreme) + random_variable.cdf(tail_extreme)`—根据随机变量对象基于生存输出和头极端和尾极端的累积分布输出计算p值。'
- en: '`z = np.random.choice(x, size=y, replace=True)`—Samples `y` elements from array
    `x` with replacement. The samples are stored in array `z`. In bootstrapping with
    replacement, `y == x.size`.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`z = np.random.choice(x, size=y, replace=True)`—从数组`x`中带替换地抽取`y`个元素。样本存储在数组`z`中。在带替换的bootstrap中，`y
    == x.size`。'
- en: The bootstrapping technique has been rigorously studied for more than four decades.
    Statisticians have uncovered multiple variations of this technique for accurate
    p-value computation. We’ve just reviewed one such variation; now we will briefly
    introduce another. It has been shown that sampling with replacement approximates
    a dataset’s SEM. Basically, the standard deviation of the sampled distribution
    is equal to the SEM when the null hypothesis is true. Thus, if the null hypothesis
    is true, our missing SEM is equal to `random_variable.std`. This gives us yet
    another way of finding the p-value. We simply need to execute `compute_p_value(27,
    37, random_variable.std)`; that computed p-value should equal approximately 0.1\.
    Let’s confirm.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: bootstrap技术已经经过四十多年的严格研究。统计学家已经发现了多种这种技术的变体，用于准确计算p值。我们刚刚回顾了一种变体；现在我们将简要介绍另一种。已经证明，带替换的抽样近似于数据集的SEM。基本上，当零假设为真时，抽样分布的标准差等于SEM。因此，如果零假设为真，我们缺失的SEM等于`random_variable.std`。这为我们找到了另一种找到p值的方法。我们只需执行`compute_p_value(27,
    37, random_variable.std)`；计算出的p值应该大约为0.1。让我们来确认。
- en: Listing 7.24 Using bootstrapping to estimate the SEM
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.24 使用bootstrap估计SEM
- en: '[PRE23]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'As expected, the computed p-value is approximately 0.1\. We’ve shown how bootstrapping
    with replacement provides us with two divergent approaches for computing the p-value.
    The first approach requires us to do the following:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，计算出的p值大约为0.1。我们已经展示了带替换的bootstrap方法为我们提供了两种计算p值的分歧方法。第一种方法要求我们执行以下操作：
- en: Sample with replacement from the data. Repeat tens of thousands of times to
    obtain a list of sample means.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据中带替换地抽取样本。重复数十万次以获得样本均值列表。
- en: Generate a histogram from the sample means.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从样本均值生成直方图。
- en: Convert the histogram to a distribution using the `stats.rv_histogram` method.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`stats.rv_histogram`方法将直方图转换为分布。
- en: Take the area beneath the left and right extremes of the distribution curve
    using the survival function and the cumulative distribution function.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用生存函数和累积分布函数计算分布曲线左右极端下的面积。
- en: 'Meanwhile, the second approach appears to be slightly simpler:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，第二种方法看起来稍微简单一些：
- en: Sample with replacement from the data. Repeat tens of thousands of times to
    obtain a list of sample means.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据中带替换地抽取样本。重复数十万次以获得样本均值列表。
- en: Compute the standard deviation of the means to approximate the SEM.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算均值的标准差以近似SEM。
- en: Use the estimated SEM to carry out basic hypothesis testing using our `compute_p_value`
    function.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用估计的SEM通过我们的`compute_p_value`函数执行基本的假设检验。
- en: Let’s briefly discuss a third approach, which is even easier to implement. This
    approach does not require a histogram, nor does it rely on a custom `compute_value_
    function`. Instead, the technique uses the law of large numbers introduced in
    section 2\. According to that law, the frequency of observed events approximates
    the probability of event occurrence if the sample count is sufficiently large.
    Thus, we can estimate the p-value simply by computing the frequency of extreme
    observations. Let’s quickly apply this technique to `sample_means` by counting
    means that do not fall between 17 cm and 37 cm. We will divide the count by `len(sample_means)`
    in order to compute the p-value.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要讨论第三种方法，这种方法甚至更容易实现。这种方法不需要直方图，也不依赖于自定义的 `compute_value_` 函数。相反，该技术使用了在第
    2 节中引入的大数定律。根据该定律，如果样本计数足够大，观察到的事件的频率近似于事件发生的概率。因此，我们可以通过计算极端观察值的频率来简单地估计 p 值。让我们快速应用这种技术到
    `sample_means` 上，通过计算不在 17 厘米和 37 厘米之间的均值来计数。我们将这个计数除以 `len(sample_means)` 来计算
    p 值。
- en: Listing 7.25 Computing the p-value from direct counts
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.25 从直接计数计算 p 值
- en: '[PRE24]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Bootstrapping with replacement is a simple but powerful technique for making
    inferences from limited data. However, the technique still presupposes the knowledge
    of a population mean. Unfortunately, in real-life situations, the population mean
    is rarely known. For instance, in this case study, we are required to analyze
    an online ad-click table that does not include a population mean. This missing
    information will not stop us: in the next subsection, we learn how to compare
    collected samples when both the population mean and the population variance are
    unknown.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 有放回的 Bootstrapping 是一种简单但强大的从有限数据中得出结论的技术。然而，该技术仍然假设我们知道总体均值。不幸的是，在现实生活中的情况下，总体均值很少为人所知。例如，在本案例研究中，我们被要求分析一个不包含总体均值的在线广告点击表。这个缺失的信息不会阻止我们：在下一小节中，我们将学习如何在总体均值和总体方差都未知的情况下比较收集到的样本。
- en: '7.4 Permutation testing: Comparing means of samples when the population parameters
    are unknown'
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 排列检验：在总体参数未知时比较样本均值
- en: Sometimes, in statistics, we need to compare two distinct sample means while
    the population parameters remain unknown. Let’s explore one such scenario.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，在统计学中，我们需要比较两个不同的样本均值，而总体参数仍然未知。让我们探索这样一个场景。
- en: Suppose our neighbor also owns an aquarium. Her aquarium contains 10 fish whose
    average length is 46 cm. We represent these new fish lengths using the `new_ fish_lengths`
    array.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的邻居也拥有一座鱼缸。她的鱼缸里有 10 条鱼，平均长度为 46 厘米。我们使用 `new_fish_lengths` 数组来表示这些新鱼的长度。
- en: Listing 7.26 Defining lengths of fish in a new aquarium
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.26 在新鱼缸中定义鱼的长度
- en: '[PRE25]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We want to compare the contents of our neighbor’s aquarium with our own. We
    begin by measuring the difference between `new_fish_lengths.mean()` and `fish_
    lengths.mean()`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想比较邻居鱼缸中的内容与我们的鱼缸。我们首先测量 `new_fish_lengths.mean()` 和 `fish_lengths.mean()`
    之间的差异。
- en: Listing 7.27 Computing the difference between two sample means
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.27 计算两个样本均值之间的差异
- en: '[PRE26]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: There is a 19 cm difference between the two aquarium means. That difference
    is substantial, but is it statistically significant? We want to find out. However,
    all our previous analyses have relied on a population mean. Currently, we have
    two sample means but no population mean. This makes it difficult to evaluate the
    null hypothesis, which assumes that fish from both aquariums share a population
    mean. This presumed shared value is now unknown. What should we do?
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 两个鱼缸均值之间有 19 厘米的差异。这个差异是显著的，但它是统计上显著的吗？我们想找出答案。然而，我们之前的所有分析都依赖于总体均值。目前，我们有两个样本均值但没有总体均值。这使得评估零假设变得困难，该假设认为来自两个鱼缸的鱼共享一个总体均值。这个假设的共享值现在未知。我们应该怎么办？
- en: We need to reframe the null hypothesis so that it doesn’t directly depend on
    the population mean. If the null hypothesis is true, then the 20 fish in the first
    aquarium and the 10 fish in the second aquarium are all drawn from the same population.
    Under the hypothesis, it doesn’t really matter which 20 fish wind up in aquarium
    A and which 10 fish wind up in aquarium B. The arrangements of fish between the
    two aquariums will have little effect. Random rearrangements of the fish will
    cause the `mean_diff` variable to fluctuate, but that difference between means
    should fluctuate in a predictable manner.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要重新定义零假设，使其不直接依赖于总体均值。如果零假设为真，那么第一个水族箱中的 20 条鱼和第二个水族箱中的 10 条鱼都来自同一个总体。在假设下，实际上并不重要是哪
    20 条鱼最终进入水族箱 A，哪 10 条鱼最终进入水族箱 B。两个水族箱之间鱼类的排列将几乎没有影响。鱼类的随机重新排列将导致 `mean_diff` 变量波动，但均值之间的差异应该以可预测的方式波动。
- en: Hence, we don’t need to know the sample mean to evaluate the null hypothesis.
    Instead, we can focus on the random permutations of fish between the two aquariums.
    This will allow us to carry out a *permutation test*, where `mean_diff` is used
    to compute statistical significance. Like bootstrapping with replacement, the
    permutation test relies on random sampling of data.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们不需要知道样本均值来评估零假设。相反，我们可以专注于两个水族箱之间鱼类的随机排列。这将允许我们进行 *排列测试*，其中使用 `mean_diff`
    来计算统计显著性。与有放回的 bootstrapping 类似，排列测试依赖于数据的随机抽样。
- en: We begin the permutation test by placing all 30 fish into a single aquarium.
    The unification of our fish can be modeled using the `np.hstack` method. The method
    takes as input a list of NumPy arrays, which are then merged together into a single
    NumPy array.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始进行排列测试，将所有 30 条鱼放入一个单独的水族箱中。我们鱼类的统一可以通过使用 `np.hstack` 方法来建模。该方法接受一个 NumPy
    数组的列表作为输入，然后将它们合并成一个单一的 NumPy 数组。
- en: Listing 7.28 Merging two arrays using `np.hstack`
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.28 使用 `np.hstack` 合并两个数组
- en: '[PRE27]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Once the fish are grouped together, we allow them to swim in random directions.
    This fully randomizes the positions of the fish in the aquarium. We use the `np.random
    .shuffle` method to shuffle the positions of the fish.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦鱼被分组在一起，我们就允许它们随机游动。这完全随机化了水族箱中鱼的位置。我们使用 `np.random.shuffle` 方法来打乱鱼的位置。
- en: Listing 7.29 Shuffling the positions of merged fish
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.29 打乱合并鱼的位置
- en: '[PRE28]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Next, we choose 20 of our randomly shuffled fish. These 20 fish will be moved
    to a separate aquarium. The other 10 fish will remain. Once more, we’ll have 20
    fish in aquarium A and 10 fish in aquarium B. However, the mean lengths of the
    fish in each aquarium will probably differ from `fish_lengths.mean()` and `new_fish_lengths.mean()`,
    so the difference between mean fish lengths will also change. Let’s confirm.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们选择我们随机打乱的 20 条鱼。这 20 条鱼将被移动到另一个水族箱中。其余的 10 条鱼将保持不变。再次，我们将有 20 条鱼在水族箱 A
    中，10 条鱼在水族箱 B 中。然而，每个水族箱中鱼的平均长度可能会与 `fish_lengths.mean()` 和 `new_fish_lengths.mean()`
    不同，因此平均鱼长度之间的差异也会改变。让我们来确认。
- en: Listing 7.30 Computing the difference between two random sample means
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.30 计算两个随机样本均值之间的差异
- en: '[PRE29]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The sampled difference between fish lengths is no longer 19 cm: now it is 14.33
    cm. As expected, `mean_diff` is a fluctuating random variable, so we can find
    its distribution through random sampling. Next, we repeat our fish-shuffling procedure
    30,000 times to obtain a histogram of `mean_diff` values (figure 7.6).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 样本鱼长度的差异不再是 19 厘米：现在它是 14.33 厘米。正如预期的那样，`mean_diff` 是一个波动的随机变量，因此我们可以通过随机抽样找到其分布。接下来，我们重复我们的鱼打乱程序
    30,000 次，以获得 `mean_diff` 值的直方图（图 7.6）。
- en: Listing 7.31 Plotting the fluctuating difference between means
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.31 绘制均值波动差异图
- en: '[PRE30]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![](../Images/07-06.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07-06.png)'
- en: Figure 7.6 A histogram of sample mean differences computed using random rearrangements
    of samples into two distinct groups
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6 使用随机重新排列样本到两个不同组计算样本均值差异的直方图
- en: Next, we fit the histogram to a random variable using the `stats.rv_histogram`
    method.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用 `stats.rv_histogram` 方法将直方图拟合到随机变量。
- en: Listing 7.32 Fitting the histogram to a random variable
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.32 将直方图拟合到随机变量
- en: '[PRE31]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Finally, we use the `random_variable` object to carry out hypothesis testing.
    We want to know the probability of observing an extreme value when the null hypothesis
    is true. We define extremeness as a difference between means whose absolute value
    is at least 19 cm. Thus, our p-value will equal `random_variable.cdf(-19) + random_variable
    .sf(19)`.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`random_variable`对象来进行假设检验。我们想知道在零假设为真时观察极端值的概率。我们将极端性定义为均值之间的差异，其绝对值至少为19厘米。因此，我们的p值将等于`random_variable.cdf(-19)
    + random_variable.sf(19)`。
- en: Listing 7.33 Computing the permutation p-value
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.33 计算排列p值
- en: '[PRE32]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The p-value is approximately 0.04, which falls below our significance threshold
    of 0.05\. Hence, the mean difference between fish lengths is statistically significant.
    The fish in the two aquariums do not originate from a shared distribution.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: p值约为0.04，低于我们的显著性阈值0.05。因此，鱼长度的均值差异在统计上是有意义的。两个水族箱中的鱼并非来自相同的分布。
- en: As an aside, we can simplify our permutation test by using the law of large
    numbers. We simply need to compute the frequency of extreme recorded samples,
    just as we did with bootstrapping with replacement. Let’s use this alternative
    method to recompute our p-value of approximately 0.04.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 作为旁注，我们可以通过使用大数定律来简化我们的排列检验。我们只需要计算极端记录样本的频率，就像我们在带替换的bootstrap中做的那样。让我们使用这种方法重新计算我们的约0.04的p值。
- en: Listing 7.34 Computing the permutation p-value from direct counts
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.34 从直接计数计算排列p值
- en: '[PRE33]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The permutation test allows us to statistically compare differences between
    two lists of collected samples. The nature of these samples isn’t important; they
    could be fish lengths, or they could be ad-click counts. Hence, the permutation
    test could be very useful when we compare our recorded ad-click counts to uncover
    optimal ad colors during the case study resolution.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 排列检验使我们能够从统计上比较两组收集到的样本之间的差异。这些样本的性质并不重要；它们可能是鱼长度，也可能是广告点击次数。因此，当我们比较我们的广告点击次数以揭示案例研究解决过程中的最佳广告颜色时，排列检验可能非常有用。
- en: Summary
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Statistical hypothesis testing requires us to choose between two competing hypotheses.
    According to the *null hypothesis*, a pair of populations are identical. According
    to the *alternative hypothesis*, the pair of populations are not identical.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计假设检验要求我们在两个相互竞争的假设之间做出选择。根据**零假设**，一对总体是相同的。根据**备择假设**，这对总体是不相同的。
- en: To evaluate the null hypothesis, we must compute a *p-value*. The p-value equals
    the probability of observing our data when the null hypothesis is true. The null
    hypothesis is rejected if the p-value is lower than a specified *significance
    level* threshold. Typically, the significance level is set to 0.05.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了评估零假设，我们必须计算一个**p值**。p值等于在零假设为真时观察我们数据的概率。如果p值低于指定的**显著性水平**阈值，则拒绝零假设。通常，显著性水平设置为0.05。
- en: If we reject the null hypothesis, and the null hypothesis is true, we commit
    a *type I error*. If we fail to reject the null hypothesis and the alternative
    hypothesis is true, we commit a type II error.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们拒绝零假设，而零假设是真实的，我们犯了**第一类错误**。如果我们未能拒绝零假设，而备择假设是真实的，我们犯了**第二类错误**。
- en: '*Data dredging* increases our risk of type I errors. In data dredging, an experiment
    is repeated until the p-value falls below the significance level. We can minimize
    data dredging by carrying out a *Bonferroni correction*, in which the significance
    level is divided by the experiment count.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据挖掘**增加了我们犯第一类错误的概率。在数据挖掘中，实验会重复进行，直到p值低于显著性水平。我们可以通过执行**Bonferroni校正**来最小化数据挖掘，其中显著性水平被除以实验次数。'
- en: We can compare a sample mean to a population mean and variance by relying on
    the central limit theorem. The population variance is needed to compute the SEM.
    If we’re not provided with the population variance, we can estimate the SEM using
    *bootstrapping with replacement*.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过依赖中心极限定理来比较样本均值和总体均值以及方差。需要总体方差来计算SEM。如果我们没有提供总体方差，我们可以使用**带替换的bootstrap**来估计SEM。
- en: We can compare the means of two distinct samples by running a *permutation test*.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过运行**排列检验**来比较两个不同样本的均值。
