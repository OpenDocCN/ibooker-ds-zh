- en: 8 Driving logs with Docker and Kubernetes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 使用Docker和Kubernetes驱动日志
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节涵盖
- en: Setting Docker to use Fluentd as its log driver
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Docker以使用Fluentd作为其日志驱动程序
- en: Understanding components used for Kubernetes logging
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解用于Kubernetes日志的组件
- en: Tailoring Kubernetes DaemonSets for Fluentd
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化Kubernetes DaemonSets以适应Fluentd
- en: Configuring Fluentd to collect Kubernetes component log events
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置Fluentd以收集Kubernetes组件日志事件
- en: Discovering how Kubernetes node monitoring works
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现Kubernetes节点监控的工作原理
- en: Previous chapters have referred to Fluentd’s relationship with Docker and Kubernetes,
    but we have focused on running Fluentd independently of these technologies to
    minimize complexity. This has helped underpin the point that despite the association
    with CNCF, Fluentd certainly is not restricted to cloud-native use cases.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 前几章提到了Fluentd与Docker和Kubernetes的关系，但我们专注于独立于这些技术运行Fluentd以最小化复杂性。这有助于支持观点，尽管与CNCF有关联，Fluentd绝对不仅限于云原生用例。
- en: In this chapter, we will now look at how Fluentd can be used with Docker and
    Kubernetes. We should recognize that the more advanced configuration of Docker
    and Kubernetes is not trivial; both technologies deserve and have many dedicated
    books. We can view the different technologies as layers of a “cake” that form
    a cloud-native microservice development platform—each layer adding increased sophistication,
    abstraction, and scaling. Typically, each layer assumes an understanding of the
    one preceding it. Operating systems provide a bedrock on which containers provide
    the first layer, commonly through Docker. The next layer is container orchestration—Kubernetes
    for us (but others, such as Mesos and OpenShift, exist). A further layer could
    be added to provide a service mesh like Istio or Linkerd. However, as they bring
    another layer of components from telemetry to mutual TLS, we’ve opted not to address
    this.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何使用Fluentd与Docker和Kubernetes结合。我们应该认识到，Docker和Kubernetes的更高级配置并非易事；这两种技术都值得拥有许多专门的书籍。我们可以将这些不同技术视为“蛋糕”的层，这些层构成了云原生微服务开发平台——每一层都增加了更多的复杂性、抽象和扩展。通常，每一层都假设对前一层的理解。操作系统提供了一个坚实的基础，容器通过Docker提供第一层。下一层是容器编排——对我们来说就是Kubernetes（但其他如Mesos和OpenShift也存在）。可以添加另一层来提供像Istio或Linkerd这样的服务网格。然而，由于它们带来了从遥感到互信TLS的另一层组件，我们选择不涉及这一点。
- en: However, we want to look at a small slice through these layers to understand
    how logging fits into each technology layer in turn. To get this perspective,
    we will assume that you have a basic conceptual appreciation of Docker and Kubernetes.
    The explanations of Docker and Kubernetes will only be at a high level as we aim
    to provide insight into how Fluentd and the prebuilt solutions support logging
    can be applied. We’ll keep the setup and illustration of the different points
    as minimalist as possible, so the approaches and considerations don’t need a deep
    hands-on experience of every layer. By the end of the chapter, you will have grasped
    the ideas and seen how to deploy Fluentd to work with Docker and Kubernetes. If
    you’d like to know more about these technologies, appendix E provides recommendations
    for additional book resources.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们想要通过这些层的小部分来了解日志如何逐层适应每种技术。为了获得这个视角，我们假设您对Docker和Kubernetes有一个基本的概念理解。Docker和Kubernetes的解释将仅限于高层次，因为我们旨在提供关于如何应用Fluentd和预构建解决方案以支持日志的见解。我们将尽可能保持设置和不同点的说明最小化，以便方法和考虑不需要对每一层有深入的实际经验。到本章结束时，您将掌握这些概念，并看到如何部署Fluentd与Docker和Kubernetes一起工作。如果您想了解更多关于这些技术的信息，附录E提供了额外的书籍资源推荐。
- en: 8.1 Fluentd out of the box from Docker Hub
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 从Docker Hub获取开箱即用的Fluentd
- en: 'The previous chapter illustrated a range of deployment configurations, including
    patterns applicable in a Kubernetes environment. These use cases can be addressed
    directly using predefined containers provided by Fluentd and others and published
    in the central Docker Hub repository ([https://hub.docker.com/r/fluent/fluentd/](https://hub.docker.com/r/fluent/fluentd/)).
    The container has been configured so that it is possible to pass a location to
    write output log files—this allows appropriate mount points to be used and allows
    the logs to be accessed from outside of the container, avoiding the issue of losing
    logs when a container terminates. In addition to the location for log files, we
    can also pass in our own custom Fluentd configuration if the default is insufficient.
    The default settings include the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章展示了各种部署配置，包括适用于 Kubernetes 环境的模式。这些用例可以直接使用 Fluentd 和其他提供并由中央 Docker Hub
    仓库发布的预定义容器来解决（[https://hub.docker.com/r/fluent/fluentd/](https://hub.docker.com/r/fluent/fluentd/)）。容器已配置，以便可以传递一个位置来写入输出日志文件——这允许使用适当的挂载点，并允许从容器外部访问日志，从而避免容器终止时丢失日志的问题。除了日志文件的位置外，我们还可以传递自己的自定义
    Fluentd 配置，如果默认设置不足。默认设置包括以下内容：
- en: Port 24224 is used for receiving logs using the forward plugin.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端口 24224 用于接收使用转发插件的日志。
- en: Logs tagged with `Docker.**` are written to `/fluentd/log/docker.log.`
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记为 `Docker.**` 的日志被写入到 `/fluentd/log/docker.log.`。
- en: All other logs go to `/fluentd/log/data.*.log.`
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有其他日志都发送到 `/fluentd/log/data.*.log.`。
- en: 8.1.1 Official Docker images
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.1 官方 Docker 镜像
- en: The Fluentd has a single official image, according to Docker Hub. The official
    image means we can be assured the image is being maintained and can be found at
    [https://hub.docker.com/_/fluentd](https://hub.docker.com/_/fluentd) (you will
    need at least a free Docker Hub account to access this). This isn’t the only Fluentd-provided
    Docker image available, but the other images don’t come with the same assurances.
    Other than the official image, the other image of particular interest is the DaemonSet,
    which was first referenced in chapter 2\. The DaemonSet, as you may recall, provides
    the means to ensure each Kubernetes worker node (host machine) runs a pod that
    provides foundation services, such as logging and monitoring of infrastructure
    health. The Docker files are available in the Fluentd GitHub repository if you
    want to use them as a starting point.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Docker Hub，Fluentd 有一个官方镜像。官方镜像意味着我们可以确信该镜像正在得到维护，并且可以在 [https://hub.docker.com/_/fluentd](https://hub.docker.com/_/fluentd)
    找到（你需要至少一个免费的 Docker Hub 账户才能访问此链接）。这不是唯一可用的 Fluentd 提供的 Docker 镜像，但其他镜像并不提供相同的保证。除了官方镜像外，另一个特别感兴趣的镜像是由
    DaemonSet 提供的，这在第 2 章中首次提到。你可能还记得，DaemonSet 提供了一种确保每个 Kubernetes 工作节点（主机机器）运行一个提供基础服务的
    pod 的方法，例如日志记录和基础设施健康监控。如果你想将它们作为起点使用，Docker 文件可以在 Fluentd GitHub 仓库中找到。
- en: If you search the Docker Hub for Fluentd, you will find hundreds of entries.
    This is because many organizations (including many vendors who want to make it
    easy for you to send log events to their product) use Fluentd and have their own
    image configurations. It is worth keeping in mind that the official Docker images
    only include the core plugins. To use your custom or community-contributed plugins,
    the Docker image needs to be modified to retrieve that plugin and install it,
    along with any dependencies. It is worth considering where the Docker image you
    elect to use has originated. Doing so will enable us to track whether the image
    provider maintains the image with the latest patches and releases to the OS and
    software, including Fluentd in the image.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你搜索 Docker Hub 上的 Fluentd，你会找到数百个条目。这是因为许多组织（包括许多希望让你轻松将日志事件发送到他们产品的供应商）使用
    Fluentd 并有自己的镜像配置。值得记住的是，官方 Docker 镜像仅包括核心插件。要使用你自定义的或社区贡献的插件，需要修改 Docker 镜像以检索该插件并安装它，以及任何依赖项。值得考虑的是你选择使用的
    Docker 镜像的来源。这样做将使我们能够跟踪镜像提供者是否维护最新的补丁和发布到操作系统和软件中，包括镜像中的 Fluentd。
- en: 8.1.2 Docker log drivers
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.2 Docker 日志驱动程序
- en: The purpose of the log drivers is to capture the output streams for `stdin`,
    `stdout`, and `stderr` (i.e., the content you would expect to see on a console)
    and direct them to a suitable destination; otherwise, this information will “disappear
    into the ether.” Docker supplies, out of the box, several bundled log drivers
    covering
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 日志驱动程序的目的在于捕获 `stdin`、`stdout` 和 `stderr`（即你会在控制台上看到的内容）的输出流，并将它们导向一个合适的目的地；否则，这些信息将会“消失在虚空中。”Docker
    默认提供了一些捆绑的日志驱动程序，包括
- en: '*Fluentd*—Communicates with the Fluentd forward endpoint, which must be on
    the host machine.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Fluentd*——与主机机器上的 Fluentd 前向端点通信。'
- en: '*JSON file*—The default setting; stores events in a file using JSON format.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*JSON 文件*——默认设置；使用 JSON 格式将事件存储在文件中。'
- en: '*local*—A file-based storage custom to Docker and optimized for its operations.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*local*——基于文件存储，专为 Docker 操作优化。'
- en: '*Syslog*—Integrates with the Syslog product.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Syslog*——与 Syslog 产品集成。'
- en: '*journald*—A daemon service that uses the same API as Syslog but produces a
    more structured file. This comes with systemd which provides a range of OS services
    beyond the Linux core ([http://mng.bz/XWZ6](http://mng.bz/XWZ6)).'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*journald*——一个使用与 Syslog 相同 API 但产生更结构化文件的守护程序服务。它随 systemd 一起提供，systemd 提供了除
    Linux 内核之外的一系列操作系统服务（[http://mng.bz/XWZ6](http://mng.bz/XWZ6)）。'
- en: '*GELF*—Graylog Extended Log Format; a format adopted by several logging frameworks
    such as Graylog and Logstash ([https://docs.graylog.org/en/4.0/pages/gelf.html](https://docs.graylog.org/en/4.0/pages/gelf.html)).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*GELF*——Graylog 扩展日志格式；被多个日志框架如 Graylog 和 Logstash 采用（[https://docs.graylog.org/en/4.0/pages/gelf.html](https://docs.graylog.org/en/4.0/pages/gelf.html)）。'
- en: '*ETW logs*—Windows log events ([http://mng.bz/y4vq](http://mng.bz/y4vq)).'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ETW 日志*——Windows 日志事件（[http://mng.bz/y4vq](http://mng.bz/y4vq)）。'
- en: '*Google Cloud Platform, AWS CloudWatch, Rapid7, Splunk*—Some of the vendors
    and platforms that have provided log drivers to their services.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Google Cloud Platform、AWS CloudWatch、Rapid7、Splunk*——一些为他们的服务提供日志驱动程序的供应商和平台。'
- en: In addition to these Docker-shipped log drivers, you can also build your own.
    But unless you want to tightly couple Docker logging to a product or platform,
    there are plenty of options without resorting to development.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些 Docker 提供的日志驱动程序之外，你还可以构建自己的。但除非你想要将 Docker 日志与某个产品或平台紧密耦合，否则有很多选项无需进行开发。
- en: 8.1.3 Getting set up for Docker log drivers
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.3 为 Docker 日志驱动程序做好准备
- en: To use Fluentd log drivers, we will need to get Docker installed (as well as
    Kubernetes for later parts of this chapter). As these technologies have significant
    differences between Windows and Linux, we will adjust our approach to accommodate
    both platforms (a practice that recognizes many people who work from a Windows
    machine but often work with Linux in production). Microsoft and Docker have made
    several significant advancements that allow Linux containers to run on Windows
    servers. This is through using the *Windows Linux Subsystem*(*WSL*), but this
    isn’t available on all versions of Windows OSes (but if you have the means to
    use WSL, it is a great way forward). For this chapter, we will focus on just Linux
    containers. This means working with WSL, *Hyper-V*' or *VirtualBox* for Windows
    users. In appendix A, we have provided the resources to help you get set up.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Fluentd 日志驱动程序，我们需要安装 Docker（以及本章后续部分所需的 Kubernetes）。由于这些技术在 Windows 和 Linux
    之间存在显著差异，我们将调整我们的方法以适应这两个平台（这种做法承认了许多人在 Windows 机器上工作，但在生产中经常使用 Linux）。微软和 Docker
    已经做出了几个重大进步，允许 Linux 容器在 Windows 服务器上运行。这是通过使用 *Windows Linux 子系统*（*WSL*）实现的，但并非所有版本的
    Windows 操作系统都提供 WSL（但如果你有使用 WSL 的条件，这是一个很好的前进方式）。在本章中，我们将专注于 Linux 容器。这意味着 Windows
    用户需要与 WSL、*Hyper-V* 或 *VirtualBox* 合作。在附录 A 中，我们提供了帮助你设置的资源。
- en: 8.2 Using Docker log drivers
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 使用 Docker 日志驱动程序
- en: Docker provides the means to control what happens to logs. By default, Docker
    uses a JSON log driver that writes to `stdout` and `stderr` (i.e., our console
    unless you’ve overridden the routing of these outputs in your environment). There
    are two ways to control the log driver, either with additional parameters in the
    Docker run command or by modifying the Docker configuration. The difference is
    that the command-line approach means you can use alternative configurations for
    specific Docker containers. The downside of the command-line approach is the parameters
    need to be provided every time.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Docker提供了控制日志发生情况的方法。默认情况下，Docker使用一个JSON日志驱动程序，它将日志写入`stdout`和`stderr`（即我们的控制台，除非你已更改了这些输出的路由）。有两种方法可以控制日志驱动程序，要么在Docker运行命令中添加额外的参数，要么修改Docker配置。区别在于，命令行方法意味着你可以为特定的Docker容器使用替代配置。命令行方法的缺点是每次都需要提供参数。
- en: 8.2.1 Docker drivers via the command line
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 通过命令行使用Docker驱动程序
- en: For our first use of log drivers, we’re going to use the command-line approach.
    It is the least invasive approach to tailoring log driver behavior; therefore,
    experimenting with configuration controls involves the least disruptive change.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们第一次使用日志驱动程序，我们将使用命令行方法。这是调整日志驱动程序行为最不具侵入性的方法；因此，实验配置控制涉及的最小破坏性更改。
- en: 'We’ll continue to run a configuration of Fluentd on our host computer to receive
    and output log events. First, we will run the `Hello-World` Docker image from
    within the Linux VM (virtual machine) established using the guidance in appendix
    A. If your host operating system is Linux, this may seem a little perverse, but
    this approach has the following benefits:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续在我们的主机计算机上运行Fluentd配置来接收和输出日志事件。首先，我们将按照附录A中的指导，在Linux虚拟机（虚拟机）内部运行`Hello-World`
    Docker镜像。如果你的主机操作系统是Linux，这可能会显得有些奇怪，但这种方法有以下优点：
- en: Clear separation of network layers, as the virtualization layer will provide
    a separate network layer besides the network abstractions from the Docker layer.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络层的清晰分离，因为虚拟化层将提供除Docker层网络抽象之外的单独网络层。
- en: Keeps the number of VMs needed down and the resource overhead that virtualization
    creates.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持所需的虚拟机数量和虚拟化产生的资源开销最低。
- en: The outcomes will be the same regardless of the host operating system. This
    can be particularly beneficial if your host is Windows, as it helps to emphasize
    that Fluentd is platform-agnostic.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无论主机操作系统如何，结果都将相同。如果你的主机是Windows，这尤其有益，因为它有助于强调Fluentd是平台无关的。
- en: Personally, this is going to be done using my Windows 10 Pro host running Hyper-V
    with an Ubuntu 18 LTS VM. This means we will be using Ubuntu to run Docker containers.
    We can visualize the deployment as shown in figure 8.1.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 个人来说，这将在我的Windows 10 Pro主机上运行，该主机运行Hyper-V和Ubuntu 18 LTS虚拟机。这意味着我们将使用Ubuntu来运行Docker容器。我们可以将部署可视化如图8.1所示。
- en: '![](../Images/CH08_F01_Wilkins.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F01_Wilkins.png)'
- en: Figure 8.1 The layers of the operating system and virtualization and containerization
    being used to ensure our host environment isn’t disturbed with just Docker
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 操作系统层、虚拟化和容器化层的使用，以确保我们的主机环境不会因为仅使用Docker而受到干扰
- en: 8.2.2 A quick check of network connections
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 快速检查网络连接
- en: Getting network configurations correct is a significant consideration for using
    Docker, Kubernetes, and virtual machines. This means it is always worth doing
    quick and easy checks to ensure the network connectivity works as expected, such
    as using curl or Postman to send HTTP log events to Fluentd. To help with this
    and use the Fluentd log driver, we have prepared a simple Fluentd configuration
    to send anything received to `stdout`. We can start Fluentd just as we have many
    times before using the command
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 获取正确的网络配置是使用Docker、Kubernetes和虚拟机时的重要考虑因素。这意味着始终值得进行快速简单的检查，以确保网络连接按预期工作，例如使用curl或Postman将HTTP日志事件发送到Fluentd。为了帮助实现这一点并使用Fluentd日志驱动程序，我们已准备了一个简单的Fluentd配置，将接收到的任何内容发送到`stdout`。我们可以像以前多次做的那样，使用以下命令启动Fluentd：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once Fluentd is running from the Linux environment, we can execute a variation
    on our “Hello World” test used in chapter 2\. In the following configurations
    and commands, we need to replace `w.x.y.z` with the host computer’s IP, as seen
    by the Linux guest. You can get the IPs of a machine with the command `ipconfig`
    on Windows and `ip addr show` on Linux hosts (`ifconfig` may also work but is
    deprecated). Our test command on the Linux VM or container has to be
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦Fluentd在Linux环境中运行，我们可以执行第2章中使用的“Hello World”测试的变体。在以下配置和命令中，我们需要将`w.x.y.z`替换为Linux虚拟机看到的宿主机的IP地址。您可以在Windows上使用`ipconfig`命令和在Linux主机上使用`ip
    addr show`命令（`ifconfig`也可能工作，但已弃用）来获取机器的IP地址。我们的测试命令在Linux虚拟机或容器上必须是
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This should result in the JSON details `{"foo":"bar"}` being displayed on the
    console where Fluentd is running on the host.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该在Fluentd在主机上运行的控制台上显示JSON详细信息`{"foo":"bar"}`。
- en: Strict bind controls
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 严格的绑定控制
- en: Strict bind controls can be an excellent thing. They allow us to apply security
    controls when dealing with components that may reside on machines with multiple
    network connections, regardless of whether those connections are physical or virtual
    (as is the case for Docker and Kubernetes environments). The bind configuration
    attribute for input plugins like `forward` will ensure Fluentd invocations will
    come through the relevant networks. But when Docker and Kubernetes create network
    addresses, we must be a lot more aware. When connections fail, it is easy to start
    looking at host firewalls, network configurations, and so on. The reality is that
    the target system is at fault for listening to only one specific network connection.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 严格的绑定控制可以是一件非常好的事情。它们允许我们在处理可能位于具有多个网络连接的机器上的组件时应用安全控制，无论这些连接是物理的还是虚拟的（如Docker和Kubernetes环境中的情况）。对于`forward`等输入插件，绑定配置属性将确保Fluentd调用将通过相关网络进行。但是，当Docker和Kubernetes创建网络地址时，我们必须更加警觉。当连接失败时，很容易开始检查主机防火墙、网络配置等等。实际上，目标系统因为只监听一个特定的网络连接而存在故障。
- en: 8.2.3 Running Docker command line
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.3 运行Docker命令行
- en: Having set and checked our deployment, particularly networking, we can move
    on to using the Docker daemon. Rather than build our own Docker image, we will
    retrieve a traditional “Hello World” one from the Docker Hub website. The `hello-world`
    Docker image is straightforward, and when people are finding their way with Docker,
    it’s a good starting place. Details of the image are available at [https://hub.docker.com/_/hello-world](https://hub.docker.com/_/hello-world).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置和检查了我们的部署，特别是网络之后，我们可以继续使用Docker守护进程。我们不会构建自己的Docker镜像，而是从Docker Hub网站检索传统的“Hello
    World”镜像。`hello-world` Docker镜像很简单，当人们在使用Docker时，这是一个好的起点。该镜像的详细信息可在[https://hub.docker.com/_/hello-world](https://hub.docker.com/_/hello-world)找到。
- en: We can stipulate a specific version through the use of tags. The tag is added
    after the name with a colon separator. As the `hello-world` Docker image has been
    tagged following the convention of using a `latest` tag for the most recent stable
    version, we can add `:latest` to the command. This can be done by running on the
    VM the Docker CLI command
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用标签来指定特定的版本。标签添加在名称之后，用冒号分隔。由于`hello-world` Docker镜像已经按照使用`latest`标签为最新稳定版本的习惯进行了标记，我们可以在命令中添加`:latest`。这可以通过在虚拟机上运行以下Docker
    CLI命令来完成
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We haven’t made any changes to the Docker configuration, which means we will
    see the standard Docker log driver behavior when asking the Docker daemon to run
    our image. While the location of Docker logs can vary, typically we should locate
    them in the folder `/var/lib/docker`, where we will see a folder called `containers`.
    We can see this as highlighted in section 1 of figure 8.2, with each container
    instance having its own folder created using its unique ID. Of course, there won’t
    be any containers present initially. With a local copy of the image now available,
    we should tell Docker daemon via the CLI to run the `hello-world` image using
    the command
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有对Docker配置进行任何更改，这意味着当请求Docker守护进程运行我们的镜像时，我们将看到标准的Docker日志驱动程序行为。虽然Docker日志的位置可能不同，但通常我们应该在`/var/lib/docker`文件夹中找到它们，在那里我们将看到一个名为`containers`的文件夹。我们可以将其视为图8.2的第1节中突出显示的内容，每个容器实例都使用其唯一的ID创建了自己的文件夹。当然，最初不会有任何容器。现在有了镜像的本地副本，我们应该通过CLI命令告诉Docker守护进程运行`hello-world`镜像
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If we now refresh our view of the folder `/var/lib/docker/containers`, the folder
    will have a new entry, highlighted in section 2 of figure 8.2\. In the new container’s
    folder structure, we will see a log file with a long name (Docker image instance;
    e.g., `b361e69a1 . . .`). Navigating into a container’s folder, we’ll see the
    resources for that Docker instance, including a folder called `local-logs` (highlighted
    in section 3 of figure 8.2). Finally, navigating into the `local-logs` folder,
    we can see the container’s log file called `container.log` (highlighted in section
    4 of figure 8.2). The log file contents will be unreadable because it’s stored
    in its own custom format (section 5 of figure 8.2).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在刷新对文件夹 `/var/lib/docker/containers` 的视图，该文件夹将新增一个条目，在图8.2的第2节中被突出显示。在新容器的文件夹结构中，我们将看到一个具有长名称的日志文件（例如，Docker镜像实例；例如，`b361e69a1 . . .`）。进入容器的文件夹，我们将看到该Docker实例的资源，包括一个名为`local-logs`的文件夹（在图8.2的第3节中被突出显示）。最后，进入`local-logs`文件夹，我们可以看到名为`container.log`的容器日志文件（在图8.2的第4节中被突出显示）。由于日志文件以自己的自定义格式存储（图8.2的第5节），其内容将无法阅读。
- en: '![](../Images/CH08_F02_Wilkins.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F02_Wilkins.png)'
- en: Figure 8.2 Directory structures holding Docker and the folders per container
    instance, followed by the listing of a container and a container log, which is
    encoded in a custom manner (numbers in the screen shot are explained in the preceding
    text)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2显示了包含Docker和每个容器实例的文件夹结构，随后是容器及其以自定义方式编码的日志的列表（屏幕截图中的数字在前面文本中已解释）
- en: 'To make things more practical, we want to configure Docker to log using a more
    consumable format. We can override the default settings, so Docker uses the Fluentd
    log driver. This is done by telling the Docker daemon to use an alternative with
    the parameter `-–log-driver=fluentd`. We don’t need to do anything more, as the
    Fluentd driver is bundled in the deployment of Docker. We also need to tell the
    driver where to find our Fluentd node to receive the log events. This and other
    configuration options are provided using the parameter `-–log-opt` followed by
    a name-value pair separated by the equals (`=`) character. In our case, we need
    to give the address (just like the previous curl command) of our host machine’s
    Fluentd. As the Docker log driver can use the forward plugin (and benefit from
    msgpack providing compression), we need to ensure the network address, including
    that port, is provided. This results in the command to run `hello-world` like
    this:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使事情更加实用，我们希望配置Docker使用更易于消费的格式来记录日志。我们可以覆盖默认设置，使Docker使用Fluentd日志驱动程序。这是通过告诉Docker守护进程使用带有参数`-–log-driver=fluentd`的替代方案来完成的。由于Fluentd驱动程序包含在Docker的部署中，我们不需要做更多的事情。我们还需要告诉驱动程序在哪里可以找到我们的Fluentd节点以接收日志事件。这和其他配置选项是通过参数`-–log-opt`来提供的，后面跟着一个由等号(`=`)分隔的名称-值对。在我们的情况下，我们需要提供主机机的Fluentd的地址（就像之前的curl命令一样）。由于Docker日志驱动程序可以使用转发插件（并从msgpack提供的压缩中受益），我们需要确保包括端口号在内的网络地址被提供。这导致运行`hello-world`的命令如下所示：
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The outcome of executing the statement will be to see log events from the Docker
    image being output on the Fluentd console. If the Docker command returns with
    an error message such as
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 执行该语句的结果将是看到Docker镜像的日志事件在Fluentd控制台上输出。如果Docker命令返回错误消息，例如
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: then something is wrong on the network or in Fluentd (e.g., it is not binding
    to the correct network). The order in which the docker image and the target Fluentd
    node are started up should also be noted. This will become particularly important
    when moving into container orchestration with Kubernetes, as it manages the order
    in which pods start up. In the event of such issues, we would recommend checking
    the Docker configuration values for network ports to ensure network traffic is
    allowed out of the container. If any port number mapping is happening, then that
    is fine.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 那么网络或Fluentd（例如，它没有绑定到正确的网络）存在问题。启动Docker镜像和目标Fluentd节点时的顺序也应该被注意。当迁移到与Kubernetes的容器编排时，这一点尤其重要，因为Kubernetes管理pods启动的顺序。在出现此类问题时，我们建议检查Docker配置的网络端口值，以确保允许容器外的网络流量。如果发生任何端口号映射，那么这是可以的。
- en: The Fluentd driver can use any of the standard features Fluentd offers, such
    as making communication asynchronous (i.e., exploiting the memory buffer capabilities;
    more on this in chapter 9). But we’ll look at more of these when we move to the
    complete configuration.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd驱动程序可以使用Fluentd提供的任何标准功能，例如使通信异步（即利用内存缓冲区功能；更多内容请参阅第9章）。但当我们转向完整的配置时，我们将探讨更多这些功能。
- en: 'In figure 8.3, we can see the output generated from running our command. Notice
    how the log events include the following attributes:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在图8.3中，我们可以看到运行我们的命令所生成的输出。注意日志事件中包含以下属性：
- en: '`container_id`—The complete 64-character ID of the container uniquely identifying
    an individual container.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`container_id`—容器的完整64字符ID，唯一标识单个容器。'
- en: '`container_name`—The name of the container when the container was started.
    Any renaming actions after the startup aren’t reflected until restarted.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`container_name`—容器启动时的容器名称。启动后的任何重命名操作都不会反映出来，直到重启。'
- en: '`source`—Details whether the log came from `stdout`, etc.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source`—详细说明日志是否来自`stdout`等。'
- en: '`log`—The content from the source (e.g., a line from `stdout`).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log`—来自源的内容（例如，`stdout`的一行）。'
- en: '![](../Images/CH08_F03_Wilkins.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F03_Wilkins.png)'
- en: Figure 8.3 The console output from Fluentd received from executing the `hello-world`
    container from Docker
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 从Docker执行`hello-world`容器收到的Fluentd控制台输出
- en: 8.2.4 Switching to driver configuration through a configuration file
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.4 通过配置文件切换到驱动程序配置
- en: With a parameterized solution proven, we can advance the configuration in a
    more readable manner and add further options that are relevant. Given all the
    possible configuration options, using a command line for an advanced configuration
    will make for a challenging maintenance task. By default, changing the Docker
    daemon configuration file will impact all Docker images being run. The Docker
    command line also allows us to point to a configuration file with the parameter
    `–-config`, followed by the filename for alternate configuration.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 证明参数化解决方案后，我们可以以更可读的方式推进配置，并添加相关的进一步选项。考虑到所有可能的配置选项，使用命令行进行高级配置将是一项具有挑战性的维护任务。默认情况下，更改Docker守护进程配置文件将影响所有正在运行的Docker镜像。Docker命令行还允许我们使用参数`–-config`指向配置文件，后跟备用配置文件的名称。
- en: The Docker daemon keeps its configuration, including the log driver configuration,
    in a file called `daemon.json`. The default location for the file is `/etc/docker/`
    for Linux setups. If you use an instance of Docker on Windows (rather than the
    indirect approach we’ve chosen to adopt), the location is `ProgramData\docker\
    config\` (`ProgramData` is typically found on the C drive root). It is possible
    that the file does not exist if the Docker setup is running entirely on default
    values.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Docker守护进程将其配置（包括日志驱动程序配置）保存在一个名为`daemon.json`的文件中。对于Linux设置，文件的默认位置是`/etc/docker/`。如果你在Windows上使用Docker实例（而不是我们选择的间接方法），位置是`ProgramData\docker\
    config\`（`ProgramData`通常位于C驱动器的根目录）。如果Docker设置完全运行在默认值上，则该文件可能不存在。
- en: 'In the daemon configuration file, we clearly want to include the setting of
    the type of log driver and connection to our Fluentd instance. To do this, we
    include into the JSON file the configuration version of the command line parameter
    `"log-driver": "fluentd"`. In the command line, we also provided the `fluentd-address`
    attribute. When it comes to the `fluentd-address`, we can provide the address
    as `tcp://w.x.y.z:28080` or as an explicit path reference to the relevant socket
    file (e.g., `unix:///usr/var/fluentd/fluent.sock`).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '在守护进程配置文件中，我们明确希望包括日志驱动程序类型和连接到我们的Fluentd实例的设置。为此，我们在JSON文件中包含命令行参数的配置版本`"log-driver":
    "fluentd"`。在命令行中，我们还提供了`fluentd-address`属性。当涉及到`fluentd-address`时，我们可以提供地址为`tcp://w.x.y.z:28080`或作为对相关套接字文件的显式路径引用（例如，`unix:///usr/var/fluentd/fluent.sock`）。'
- en: In addition to the address, we should also introduce several additional parameters
    directly related to the log driver and other general parameters relevant to logging.
    The general settings we’ve included are
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 除了地址之外，我们还应该直接引入与日志驱动程序和其他与日志相关的通用参数相关的几个附加参数。我们包括的一般设置是
- en: '`raw-logs`*—*Should be set to either `true` or `false`. If specified as `false`,
    then a complete ANSI timestamp is applied (e.g., `YYYY-MM-DD HH:MM:SS`), and the
    coloring of the log text through the use of escape codes is switched off from
    any encoding.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`raw-logs`*—*应设置为`true`或`false`。如果指定为`false`，则应用完整的ANSI时间戳（例如，`YYYY-MM-DD HH:MM:SS`），并通过使用转义码关闭日志文本的着色。'
- en: '`log-driver`—As shown in the command line example used to set the log driver.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log-driver`—如用于设置日志驱动程序的命令行示例所示。'
- en: '`log-level`—The log filter threshold to apply to Docker daemon. The accepted
    levels are `debug`, `info`, `warn`, `error`, and `fatal`, with the default being
    `info`.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log-level`—应用于Docker守护进程的日志过滤器阈值。接受的级别是`debug`、`info`、`warn`、`error`和`fatal`，默认为`info`。'
- en: Within the configuration file, we can start an inner group of attributes called
    `log-opts`; these logging specific options include
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置文件中，我们可以启动一个名为 `log-opts` 的内部属性组；这些特定的日志选项包括
- en: '`env`—We can ask the driver to capture and include specific environment variables.
    This is done by defining a comma-separated list. For our purposes, we can use
    `"os, customer"`. This does assume that something has set such values. It is also
    possible to define a regular expression version of this by using the attribute
    `env-regex`.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`env`—我们可以要求驱动程序捕获并包含特定的环境变量。这通过定义一个以逗号分隔的列表来完成。就我们的目的而言，我们可以使用 `"os, customer"`。这假设已经设置了这样的值。也可以通过使用属性
    `env-regex` 定义这个的正则表达式版本。'
- en: '`labels`—This works very much in the same way as `env`, insofar as a list of
    labels (Docker metadata name-value pairs) can be specified, or a regular expression
    can be provided via `labels-regex`.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`—这与 `env` 非常相似，在某种程度上，可以指定标签列表（Docker 元数据名称-值对），或者可以通过 `labels-regex`
    提供正则表达式。'
- en: '`fluentd-retry-wait`—Each time a connection fails, a waiting period is applied
    before retrying again. The value needs to include the duration type (e.g., `s`
    for seconds, `h` for hours).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fluentd-retry-wait`—每次连接失败后，在再次尝试之前应用一个等待期。该值需要包括持续时间类型（例如，`s` 表示秒，`h` 表示小时）。'
- en: '`fluentd-max-retries`—The maximum number of connection retries before giving
    up. This defaults to `4294967295`—that is, `(2**32 - 1)`. We don’t want things
    hanging for that many retries. Given that we have set retry to one per second,
    up to 10 minutes retrying would be plenty, meaning a value of `600`.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fluentd-max-retries`—在放弃之前尝试连接的最大次数。默认值为 `4294967295`——即 `(2**32 - 1)`。我们不希望事情因为那么多次重试而挂起。鉴于我们已经将重试设置为每秒一次，最多10分钟的重试就足够了，这意味着值为
    `600`。'
- en: '`fluentd-subsecond-precision`—Allows us to get the timestamp precision to millisecond
    accuracy if the hardware is capable of it. While the default value is `false`,
    it is worth setting explicitly, even if it’s to the default value. By explicitly
    setting the value, we’re reminded that we won’t have such precision.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fluentd-subsecond-precision`—允许我们在硬件支持的情况下，将时间戳精度设置为毫秒级。虽然默认值是 `false`，但明确设置它是有意义的，即使它只是默认值。通过明确设置值，我们会提醒自己我们不会拥有这样的精度。'
- en: '`tag`—The tag to associate with the log event record. This can be built using
    several predefined values (the complete list is in appendix A) using a notation
    defined by Docker. In our case, let’s define the tag using the shortened ID and
    Image ID using the following representation: `{{.ID}}-{{.ImageID}}`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tag`—与日志事件记录关联的标签。这可以使用 Docker 定义的符号（附录 A 中有完整列表）构建。在我们的情况下，让我们使用以下表示法定义标签：`{{.ID}}-{{.ImageID}}`。'
- en: '`fluentd-address`—As in the command-line configuration, this is the location
    of the Fluentd server to talk with. This, as with the parameter approach, needs
    to be tailored to the host IP of the Fluentd instance.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fluentd-address`—与命令行配置一样，这是与 Fluentd 服务器通信的位置。这与参数方法一样，需要根据 Fluentd 实例的主机
    IP 地址进行定制。'
- en: The outcome of addressing these other needs means we arrive at the code shown
    in listing 8.1\. Running the Docker daemon process in debug mode is the easiest
    way to ensure that the configuration file is processed correctly. This means that
    as this is a daemon service, we need to stop the current process using the command
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 满足这些其他需求的结果意味着我们到达了列表 8.1 中所示的代码。以调试模式运行 Docker 守护进程是确保配置文件正确处理的最简单方法。这意味着这是一个守护进程服务，我们需要使用以下命令停止当前进程
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Listing 8.1 Chapter8/Docker/daemon.json configuration for Docker Fluentd log
    driver
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.1 第8章/Docker/daemon.json 配置文件，用于 Docker Fluentd 日志驱动程序
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ This tells Fluentd to use the Fluentd version of the log driver.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这告诉 Fluentd 使用 Fluentd 版本的日志驱动程序。
- en: ❷ This is setting Docker to use raw logs, so the formatting isn’t used, and
    the ANSI timestamp is applied.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 这设置 Docker 使用原始日志，因此不使用格式化，并应用 ANSI 时间戳。
- en: ❸ This tailors the tag to be used in the log events.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 这定制了用于日志事件的标签。
- en: ❹ This specifies to the log driver where the Fluentd server is.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 这指定了日志驱动程序中 Fluentd 服务器的位置。
- en: Once the service has stopped, we need to copy our modified daemon configuration
    file to the default location `/etc/docker/`. Then we can start the process manually
    with the command
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦服务停止，我们需要将修改后的守护进程配置文件复制到默认位置 `/etc/docker/`。然后我们可以使用以下命令手动启动进程
- en: '[PRE8]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This will launch Docker in debug mode, picking up the configuration from the
    default location. If there are any issues with the configuration file, the Docker
    daemon will almost immediately stop or generate warnings about not parsing the
    configuration. Messages will be displayed on the console, such as
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动 Docker 以调试模式，从默认位置获取配置。如果配置文件有任何问题，Docker 守护进程将几乎立即停止或生成有关无法解析配置的警告。信息将显示在控制台上，例如
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once the file is read okay, the Docker daemon will direct log events to our
    Fluentd instance, including the output when running the `Hello-World` docker image.
    As our previous command has started the Docker daemon in the foreground, we need
    to use an additional shell to run the docker image. We can use the same command
    as before:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文件读取正常，Docker 守护进程将日志事件直接发送到我们的 Fluentd 实例，包括运行 `Hello-World` Docker 镜像时的输出。由于我们之前的命令已在前台启动了
    Docker 守护进程，我们需要使用另一个 shell 来运行 Docker 镜像。我们可以使用之前的相同命令：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you’re feeling brave, then you can jump straight to running Docker as a service
    again. This means terminating the current execution of the Docker daemon process
    in debug mode. Then execute the command
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感到勇敢，可以直接跳转到再次以服务形式运行 Docker。这意味着终止当前以调试模式执行的 Docker 守护进程。然后执行以下命令
- en: '[PRE11]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'When you’re confident about any further changes to the configuration file (`daemon.json`),
    rather than running the Docker daemon manually, we can adopt an approach of simply
    restarting the daemon to force it to pick up the latest config. This is done by
    replacing the `start` command with `restart`. For example:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 当你对配置文件（`daemon.json`）的任何进一步更改有信心时，而不是手动运行 Docker 守护进程，我们可以采用简单地重启守护进程以强制它获取最新配置的方法。这是通过将
    `start` 命令替换为 `restart` 来实现的。例如：
- en: '[PRE12]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Suppose you want to verify that config attributes have been accepted by the
    Docker daemon. In that case, it is possible to run the command `docker --info`,
    which will display all the settings being used, including those defaulted values
    on the console.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想验证配置属性是否已被 Docker 守护进程接受。在这种情况下，你可以运行命令 `docker --info`，这将显示所有正在使用的设置，包括控制台上的默认值。
- en: 8.3 Kubernetes components logging and the use of Fluentd
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 Kubernetes 组件日志记录和 Fluentd 的使用
- en: The nature of Kubernetes and the model making it highly pluggable means that
    the landscape can become complex. To illustrate this, if we look at the containerization
    aspect of Kubernetes, Docker may be the most predominant container technology
    today. Still, Kubernetes, through the API model, allows us to use other container
    technologies such as *containerd* ([https://containerd.io/](https://containerd.io/))
    and *cri-o* ([https://cri-o.io/](https://cri-o.io/)), both under the governance
    of CNCF. Some of the complexity is addressed through the *Open Container Initiative*
    ([https://opencontainers.org/](https://opencontainers.org/)), also under CNCF
    governance, which helps abstract the interaction between the container implementation
    and Kubernetes’s orchestration of containers. The essential question here is how
    does that impact us and the use of Fluentd?
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的本质及其高度可插拔的模型意味着其生态系统可能会变得复杂。为了说明这一点，如果我们看看 Kubernetes 的容器化方面，Docker
    可能是今天最占主导地位的容器技术。然而，通过 API 模型，Kubernetes 允许我们使用其他容器技术，如 *containerd* ([https://containerd.io/](https://containerd.io/))
    和 *cri-o* ([https://cri-o.io/](https://cri-o.io/))，这两者都受 CNCF 管理。部分复杂性通过 *Open
    Container Initiative* ([https://opencontainers.org/](https://opencontainers.org/))
    得到解决，它也受 CNCF 管理，有助于抽象容器实现与 Kubernetes 容器编排之间的交互。这里的基本问题是这如何影响我们以及 Fluentd 的使用？
- en: The important thing here is that, as we have seen, we can configure Docker to
    capture the events propagating through `stdout` and `stderr`; therefore, do the
    other containers support such a capability? Not all containers are as mature as
    Docker when it comes to logging. Many simply line up with Kubernetes’s internal
    logging framework *klog* ([https://github.com/kubernetes/klog](https://github.com/kubernetes/klog)),
    which adopts the logging approach of using *journald* when it is deployed, and
    otherwise logging to a default file location.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这里重要的是，正如我们所看到的，我们可以配置 Docker 以捕获通过 `stdout` 和 `stderr` 传播的事件；因此，其他容器是否支持这种功能？并非所有容器在日志记录方面都像
    Docker 那样成熟。许多容器只是与 Kubernetes 内部日志框架 *klog* ([https://github.com/kubernetes/klog](https://github.com/kubernetes/klog))
    保持一致，该框架在部署时采用 *journald* 的日志方法，否则将日志记录到默认文件位置。
- en: Klog’s evolution
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Klog 的演变
- en: Klog goes back to the Google C++ libraries ([https://github.com/google/glog](https://github.com/google/glog)).
    As Kubernetes is implemented in Go, C++ libraries aren’t an option, and along
    the way, a Go implementation was developed ([https://github.com/golang/glog](https://github.com/golang/glog)).
    Since then, the Kubernetes developers determined that glog presented some challenges
    regarding containerization and thus forked the code base, leading us to klog.
    The APIs remain essentially the same. In all cases, the logging mechanisms are
    streamlined for optimal performance; thus, plugging and configuring logging is
    very much down to command-line options offered by an application using the library
    rather than a configuration file.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Klog 追溯到 Google C++ 库（[https://github.com/google/glog](https://github.com/google/glog)）。由于
    Kubernetes 是用 Go 实现的，C++ 库不是一种选择，因此在这个过程中，开发了一个 Go 实现（[https://github.com/golang/glog](https://github.com/golang/glog)）。从那时起，Kubernetes
    开发者确定 glog 在容器化方面存在一些挑战，因此分叉了代码库，从而产生了 klog。API 基本上保持不变。在所有情况下，日志机制都经过优化以实现最佳性能；因此，插入和配置日志很大程度上取决于使用该库的应用程序提供的命令行选项，而不是配置文件。
- en: 8.3.1 Kubernetes components and structured logging
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.1 Kubernetes 组件和结构化日志
- en: The application of structured logging today in Kubernetes components is an evolving
    journey. Not all components within Kubernetes have adopted structured logging
    yet (although this is changing). We should be prepared for the possibility that
    any additional system components or extensions used in the future might not apply
    structure. This reinforces the recommendation that it is better to actively adopt
    logging and deployment patterns outlined in chapter 7 (Fluentd as a sidecar pattern,
    embedded with the application, etc.) rather than try to harvest logs out of Kubernetes.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 组件中，今天结构化日志的应用是一个不断发展的旅程。Kubernetes 中的所有组件尚未全部采用结构化日志（尽管这一状况正在改变）。我们应该准备好应对未来可能出现的任何额外系统组件或扩展可能不应用结构化日志的可能性。这强化了这样的建议：最好是积极采用第
    7 章中概述的日志和部署模式（如 Fluentd 作为边车模式、与应用程序内嵌等），而不是试图从 Kubernetes 中提取日志。
- en: 8.3.2 Kubernetes default log retention and log rotation
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.2 Kubernetes 默认日志保留和日志轮转
- en: When the logs come through to Kubernetes from a container because of the container
    configuration, Kubernetes will push the log entries into a log file for each container
    instance. To manage the size and log rotation, it is our responsibility to establish
    a log rotation tool, which can control how many log files and how frequently they
    are rotated.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当日志由于容器配置从容器传入 Kubernetes 时，Kubernetes 将将日志条目推送到每个容器实例的日志文件中。为了管理大小和日志轮转，我们的责任是建立一个日志轮转工具，它可以控制日志文件的数量以及它们轮转的频率。
- en: Kubernetes doesn’t have its own log rotator; it is the responsibility of the
    deployer of Kubernetes worker nodes to address log rotation challenges. That said,
    if the worker node is set up using a Kubernetes provided script (`kube-up.sh`,
    [http://mng.bz/M25n](http://mng.bz/M25n)), it will deploy the open source tool
    logrotate ([https://github.com/logrotate/logrotate](https://github.com/logrotate/logrotate)).
    Logrotate can be configured to retain a specified number of files. Some flavors
    of Linux will have logrotate deployed, so it is a matter of additional configuration.
    How logrotate is set up can vary across Linux flavors only because of how the
    Linux configuration is applied. Some flavors use systemd, and logrotate is provided
    as part of that. Where logrotate isn’t already deployed, it is typical to be able
    to perform an independent installation via the Linux flavor’s package manager
    of choice.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 没有自己的日志轮转器；处理日志轮转挑战是 Kubernetes 工作节点部署者的责任。话虽如此，如果工作节点是使用 Kubernetes
    提供的脚本（`kube-up.sh`，[http://mng.bz/M25n](http://mng.bz/M25n)）设置的，它将部署开源工具 logrotate（[https://github.com/logrotate/logrotate](https://github.com/logrotate/logrotate)）。logrotate
    可以配置为保留指定数量的文件。某些 Linux 发行版已经部署了 logrotate，因此这是一个额外的配置问题。logrotate 的设置可能因 Linux
    发行版而异，这仅仅是因为 Linux 配置的应用方式不同。某些发行版使用 systemd，而 logrotate 是其一部分。在 logrotate 还未部署的地方，通常可以通过选择
    Linux 发行版的包管理器独立安装。
- en: Logrotate is not cross-platform as a solution, so running Kubernetes on Windows
    needs another answer to achieve log rotation, which isn’t obvious and more challenging
    when examining the Kubernetes discussions on the subject. Regardless of log rotation,
    logs generated by klog are automatically truncated when they reach 1.8 GB. So
    any log rotation needs to be established to occur before hitting that threshold.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Logrotate 作为解决方案并不是跨平台的，因此，在 Windows 上运行 Kubernetes 需要另一个答案来实现日志轮转，这在查看 Kubernetes
    关于此主题的讨论时并不明显，而且更具挑战性。无论日志轮转如何，klog 生成的日志在达到 1.8 GB 时会自动截断。因此，任何日志轮转都需要在达到该阈值之前建立。
- en: Kubernetes will automatically delete all except the current log files when a
    container is removed. If the process of capturing such log events is too far behind,
    there is a risk of losing log events—something to be considered when establishing
    log capture.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器被移除时，Kubernetes 会自动删除所有除了当前日志文件之外的所有文件。如果捕获此类日志事件的进程落后太多，可能会丢失日志事件——在建立日志捕获时需要考虑的问题。
- en: The takeaway from this is that managing logs at the Kubernetes layer presents
    challenges with potential differences based on the deployment approach and infrastructure
    setup. As a result, our preference is to minimize the issues by focusing on log
    capture in the layers where we can see more consistency and the means to assert
    more control. We can’t entirely ignore Kubernetes logs, but intercepting the log
    events elsewhere means the loss of Kubernetes log events isn’t as critical.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个例子中我们可以看出，在 Kubernetes 层面管理日志会面临挑战，这些挑战可能基于部署方法和基础设施设置的差异。因此，我们倾向于通过专注于我们能够看到更多一致性和更多控制手段的层中的日志捕获来最小化问题。我们无法完全忽视
    Kubernetes 日志，但在其他地方拦截日志事件意味着 Kubernetes 日志事件的丢失并不那么关键。
- en: Easing of deployments into Kubernetes
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 部署的简化
- en: The easing of deployments into Kubernetes for solutions is necessary. Within
    the Kubernetes ecosystem, several tools, such as Helm ([https://helm.sh](https://helm.sh))
    and Rancher ([https://rancher.com](https://rancher.com)), have been developed
    to ease the challenges. Helm (the more dominant solution) even refers to itself
    as the package manager for Kubernetes. Given Helm’s dominance, the Fluentd committers
    have developed Helm configuration files (known as *charts*) to support Fluentd
    deployment. The charts consolidate and define the configuration details unique
    to deployment, and then Helm uses templates and scripts to complete the rest.
    The DaemonSet chart included in the GitHub Fluentd repository ([https://github.com/fluent/helm-charts](https://github.com/fluent/helm-charts))
    provides a baseline start, leaving you to just apply configurations for your specific
    needs. If you’re involved with the regular development of Kubernetes deployments,
    then we recommend investigating Helm and leveraging the Fluentd charts.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对于解决方案来说，简化 Kubernetes 部署是必要的。在 Kubernetes 生态系统中，已经开发了几种工具，如 Helm ([https://helm.sh](https://helm.sh))
    和 Rancher ([https://rancher.com](https://rancher.com))，以简化挑战。Helm（更占主导地位的解决方案）甚至将自己称为
    Kubernetes 的包管理器。鉴于 Helm 的主导地位，Fluentd 的贡献者已经开发了 Helm 配置文件（称为 *charts*）以支持 Fluentd
    部署。这些 charts 整合并定义了特定于部署的独特配置细节，然后 Helm 使用模板和脚本完成剩余部分。GitHub Fluentd 存储库中包含的 DaemonSet
    chart ([https://github.com/fluent/helm-charts](https://github.com/fluent/helm-charts))
    提供了一个基本起点，让您只需为特定需求应用配置。如果您参与 Kubernetes 部署的常规开发，我们建议调查 Helm 并利用 Fluentd charts。
- en: 8.3.3 kubectl with logging
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.3 使用 kubectl 进行日志记录
- en: As you may well already know, *kubectl* is the primary CLI tool for interacting
    with Kubernetes. When Kubernetes understands where the logs are being written,
    we can utilize kubectl to perform various tasks, such as tailing one or more log
    files, forwarding logs to different ports, and supporting the everyday log file
    activities. Rather than describe kubectl log commands, all the details can be
    found in the kubectl command reference at [http://mng.bz/aDJB](http://mng.bz/aDJB).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经知道，*kubectl* 是与 Kubernetes 交互的主要 CLI 工具。当 Kubernetes 理解日志被写入的位置时，我们可以利用
    kubectl 执行各种任务，例如跟踪一个或多个日志文件、将日志转发到不同的端口，以及支持日常的日志文件活动。而不是描述 kubectl 日志命令，所有详细信息都可以在
    kubectl 命令参考中找到，请参阅[http://mng.bz/aDJB](http://mng.bz/aDJB)。
- en: 8.4 Demonstrating logging with Kubernetes
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 使用 Kubernetes 展示日志
- en: We need to collect Kubernetes process logs and understand whether internal container
    processes such as Kubelet are logging errors. Kubernetes has plenty of mechanisms
    to help us check the health of containers. Still, understanding that everything
    is running without issue in Kubernetes is essential to knowing whether the containers
    are being cared for, or the nodes are slowly failing. If an application is logging
    into the console and events go to Kubernetes, where do we retrieve the events?
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要收集Kubernetes进程日志，并了解内部容器进程，如Kubelet是否在记录错误。Kubernetes有许多机制可以帮助我们检查容器的健康状况。然而，了解Kubernetes中一切运行正常，对于知道容器是否得到妥善照顾，或者节点是否缓慢失败至关重要。如果一个应用程序正在控制台记录日志，事件流向Kubernetes，那么我们在哪里检索这些事件？
- en: To address this, we will deploy a ready-built pod containing the LogSimulator,
    which is configured to direct the log events to `stdout`. The log events will
    propagate through the container mechanism and let Fluentd intercept them in the
    Kubernetes layer, so we will be capturing the Kubernetes and container internal
    logs. This may reflect the recommended setup described by the twelve-factor app
    ([https://12factor.net/logs](https://12factor.net/logs)). But it does, in many
    ways, represent a worst-case scenario, as we have to invest effort in deriving
    the context (separating multiple log events in `stdout` that could have been from
    the platform or container versus the application, etc.) and restructuring the
    log events.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们将部署一个预构建的包含LogSimulator的pod，该pod配置为将日志事件定向到`stdout`。日志事件将通过容器机制传播，并让Fluentd在Kubernetes层拦截它们，因此我们将捕获Kubernetes和容器内部日志。这可能会反映十二要素应用中描述的推荐设置（[https://12factor.net/logs](https://12factor.net/logs)）。但在许多方面，它代表了一个最坏的情况，因为我们必须投入精力来推导上下文（在`stdout`中分离可能来自平台或容器而不是应用程序的多个日志事件等）并重新结构日志事件。
- en: At this point, if you haven’t followed appendix A to install minikube as our
    Kubernetes implementation, then now is the ideal time. Once complete, your environment
    will look like the layout shown in figure 8.4.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，如果你还没有按照附录A安装minikube作为我们的Kubernetes实现，那么现在正是理想的时间。一旦完成，你的环境将看起来像图8.4中所示的结构。
- en: '![](../Images/CH08_F04_Wilkins.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F04_Wilkins.png)'
- en: Figure 8.4 The layers of operating system and virtualization and containerization
    being used to ensure our host environment isn’t disturbed with minikube
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4 操作系统层、虚拟化和容器化使用的层次结构，以确保我们的宿主环境不会被minikube打扰
- en: 8.4.1 Kubernetes setup
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.1 Kubernetes设置
- en: 'To demonstrate the Kubernetes configuration to keep things nice and compact,
    we’re going to use minikube. Minikube is a version of Kubernetes pared down to
    keep the footprint as compact as possible. If you haven’t already followed the
    instructions in appendix A, that is the first step to perform on the Linux virtual
    machine. It also happens to be the Kubernetes implementation used in *Kubernetes
    in Action* by Marko Lukša ([http://mng.bz/g4wE](http://mng.bz/g4wE)). Once minikube
    is installed, let’s fire it up and use the Kubernetes dashboard to look around
    at the initial state. We do this with the following command for Windows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示保持配置简洁的Kubernetes配置，我们将使用minikube。Minikube是Kubernetes的一个版本，经过精简以保持尽可能小的足迹。如果你还没有按照附录A中的说明进行操作，那么在Linux虚拟机上执行的第一步就是这一步。这也恰好是Marko
    Lukša在《Kubernetes实战》一书中使用的Kubernetes实现（[http://mng.bz/g4wE](http://mng.bz/g4wE)）。一旦minikube安装完成，让我们启动它并使用Kubernetes仪表板查看初始状态。我们使用以下命令在Windows上执行此操作：
- en: '[PRE13]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The Linux equivalent is
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Linux的等效版本是
- en: '[PRE14]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This will establish a single node “cluster” of Kubernetes stripped down to
    the minimum. The download package for this chapter contains Linux shell and Windows
    batch scripts, which will perform this command (making it a lot easier than remembering
    or copying the commands every time). Then we can start up the dashboard with this
    command in either Windows or Linux:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这将建立一个单节点“集群”的Kubernetes，简化到最小。本章的下载包包含Linux shell和Windows批处理脚本，这些脚本将执行此命令（使每次记住或复制命令变得容易得多）。然后我们可以在Windows或Linux上使用以下命令启动仪表板：
- en: '[PRE15]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This command starts a foreground process that will deploy the necessary pods
    to run the dashboard UI and provide the dashboard page URL. With the dashboard
    page open, we can navigate using the UI’s left-hand menu to see what DaemonSets,
    Deployments, and Pods are currently deployed (as part of the Workloads section
    of the menu). As you can see in figure 8.5, there are no DaemonSets currently
    deployed. You will find the basic `hello-minikube` deployment and associated pod
    running.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令启动一个前台进程，该进程将部署必要的 pod 以运行仪表板 UI 并提供仪表板页面 URL。当仪表板页面打开时，我们可以使用 UI 的左侧菜单进行导航，以查看当前部署了哪些守护进程集、部署和
    pod（作为菜单的工作负载部分）。如图 8.5 所示，目前没有部署任何守护进程集。您将找到基本的 `hello-minikube` 部署及其关联的 pod
    正在运行。
- en: '![](../Images/CH08_F05_Wilkins.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F05_Wilkins.png)'
- en: Figure 8.5 Kubernetes dashboard running on minikube, currently only showing
    the default namespace rather than the kube system or where most DaemonSets will
    be.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 在 minikube 上运行的 Kubernetes 仪表板，目前只显示默认命名空间，而不是 kube 系统，或者大多数守护进程集将运行的地方。
- en: Simplify navigation with all namespaces
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用所有命名空间简化导航
- en: Simplifying the UI navigation can be done by setting the drop-down next to the
    Kubernetes logo to All Namespaces rather than default (as shown in figure 8.5);
    this will make seeing details easier. Otherwise, you will likely get tripped up
    when you navigate the UI, wondering why you cannot see expected information, such
    as the Fluentd DaemonSets. Within our environment, displaying everything (i.e.,
    all namespaces) is not going to be problematic, although in a production setup,
    this is not something we would recommend.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将 Kubernetes 标志旁边的下拉菜单设置为“所有命名空间”而不是默认（如图 8.5 所示）来简化 UI 导航，这将使查看详细信息更容易。否则，您在导航
    UI 时可能会遇到障碍，想知道为什么看不到预期的信息，例如 Fluentd 守护进程集。在我们的环境中，显示所有内容（即，所有命名空间）不会有问题，尽管在生产设置中，我们不会推荐这样做。
- en: 8.4.2 Creating logs to capture
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.2 创建日志以捕获
- en: We first need an application to generate log events so we can observe a log
    DaemonSet collecting events from Kubernetes and the applications not logging more
    directly to an endpoint (i.e., they are simply sending logs to `stdout` and `stderr`).
    For this, we can use a containerized version of LogSimulator. The containerized
    version of this tool is, by default, configured to loop through a simple data
    set several times and then stop. Each log event is simply written to `stdout`;
    thus, log events will get collected by Kubernetes. When the LogSimulator pod completes
    its run, it will stop the pod, at which point, Kubernetes will intervene to restart
    the deployment. The LogSimulator Docker image already exists within Docker Hub.
    The Kubernetes configuration to use this Docker image within a pod is shown in
    the following listing, which can be retrieved from [http://mng.bz/5KQB](http://mng.bz/5KQB).
    As there is no need for any configuration or external facing endpoints, the YAML
    configuration is straightforward.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要一个应用程序来生成日志事件，这样我们就可以观察一个日志守护进程集从 Kubernetes 和不直接将日志发送到端点（即，它们只是将日志发送到
    `stdout` 和 `stderr`）的应用程序收集事件。为此，我们可以使用 LogSimulator 的容器化版本。默认情况下，该工具的容器化版本配置为循环遍历一个简单的数据集多次，然后停止。每个日志事件都简单地写入
    `stdout`；因此，日志事件将被 Kubernetes 收集。当 LogSimulator 容器完成其运行时，它将停止容器，此时 Kubernetes
    将介入以重启部署。LogSimulator Docker 镜像已经在 Docker Hub 中存在。以下列出的是在 pod 中使用此 Docker 镜像的
    Kubernetes 配置，可以从 [http://mng.bz/5KQB](http://mng.bz/5KQB) 获取，该配置显示如下。由于不需要任何配置或外部端点，YAML
    配置非常简单。
- en: Listing 8.2 Chapter8/LogGenerator/Kubernetes/log-simulator-deployment.yaml
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.2 第 8 章/LogGenerator/Kubernetes/log-simulator-deployment.yaml
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ This is the reference to the Docker Hub image, which, when deployed, will
    be downloaded. If a newer version of this pod needs deploying, the version reference
    at the end of the name (i.e., :v1) must be updated. Without this, Kubernetes will
    ignore the request as it already has that version of the LogSimulator.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这是 Docker Hub 镜像的引用，当部署时，将会被下载。如果需要部署此 pod 的新版本，必须在名称末尾的版本引用（即，:v1）进行更新。如果没有这样做，Kubernetes
    将忽略请求，因为它已经有了该版本的 LogSimulator。
- en: 'To deploy this pod, you need to ensure the environment variable `LogSimulatorHome`
    is defined, which references the root folder of the LogGenerator that has been
    previously installed. Alternatively, edit the provided script (`deploy-log-sim-k8.bat`
    or `deploy-log-sim-k8.sh`), replacing the environment variable reference with
    the absolute path. If you use the script, it will always try to remove any possible
    existing pod deployment first to be safe. This means that if you want to keep
    redeploying, then just use the script. To issue the deployment command yourself,
    then, in a shell, issue the following statement:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署此 pod，您需要确保环境变量 `LogSimulatorHome` 已定义，它引用了之前已安装的 LogGenerator 的根文件夹。或者，编辑提供的脚本（`deploy-log-sim-k8.bat`
    或 `deploy-log-sim-k8.sh`），将环境变量引用替换为绝对路径。如果您使用脚本，它将始终尝试先删除任何可能存在的 pod 部署以确保安全。这意味着如果您想重新部署，则只需使用脚本。然后，在
    shell 中，输入以下语句以自行发出部署命令：
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Minikube should confirm the deployment as being successful.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube 应该会确认部署为成功。
- en: Difference between minikube CLI and kubectl
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: minikube CLI 和 kubectl 之间的差异
- en: The difference between kubectl and minikube commands is minimal. Minikube has
    wrapped the use of kubectl so that the minikube command can provide additional
    commands and the kubectl commands. If you have installed kubectl, it is possible
    to configure it to direct instructions to the minikube instance of Kubernetes.
    Then you can replace the first part of the commands, which appear as `minikube
    kubectl –-`, with just `kubectl`. An alternate approach to this for Linux hosts
    is to introduce an alias into the Linux environment. This is done by using the
    command `- alias kubectl="minikube kubectl --`". Now when you use the command
    `kubectl`, Linux will substitute it for the full expression. If you find yourself
    having to prefix a lot of the calls with `sudo` to ensure the privileges are correct,
    you could incorporate that into the alias as well.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: kubectl 和 minikube 命令之间的差异很小。Minikube 包装了 kubectl 的使用，以便 minikube 命令可以提供额外的命令和
    kubectl 命令。如果您已安装 kubectl，则可以配置它将指令直接指向 Kubernetes 的 minikube 实例。然后，您可以将命令的前一部分，即显示为
    `minikube kubectl –-` 的部分，替换为仅 `kubectl`。对于 Linux 主机，此方法的替代方法是向 Linux 环境中引入别名。这是通过使用命令
    `- alias kubectl="minikube kubectl --`" 来完成的。现在，当您使用命令 `kubectl` 时，Linux 将将其替换为完整表达式。如果您发现自己需要经常在调用前加上
    `sudo` 以确保正确的权限，则可以将此也包含到别名中。
- en: Understanding LogSimulator’s view
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 理解 LogSimulator 的视图
- en: Before we move on to look at the DaemonSet, it is worth taking a “little peek
    under the hood” to see things happening. As we’ve previously started the Kubernetes
    dashboard, we can use this to help us. We need to access the list of pods (left
    menu option); thus, we will see a list like the details shown in figure 8.6\.
    We need to access the `log-simulator` pod instance, which can be done by clicking
    on the name that starts with `log-simulator`.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续查看 DaemonSet 之前，值得“稍微窥视一下引擎盖下”看看正在发生的事情。因为我们之前已经启动了 Kubernetes 仪表板，我们可以使用它来帮助我们。我们需要访问
    pod 列表（左侧菜单选项）；因此，我们将看到类似于图 8.6 中显示的列表。我们需要访问 `log-simulator` pod 实例，这可以通过点击以
    `log-simulator` 开头的名称来完成。
- en: '![](../Images/CH08_F06_Wilkins.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F06_Wilkins.png)'
- en: Figure 8.6 Kubernetes dashboard showing the instances of pods that contain our
    LogSimulator and Fluentd
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 Kubernetes 仪表板显示包含我们的 LogSimulator 和 Fluentd 的 pod 实例
- en: This will display the details about the specific pod, and the top of the screen
    will look something like the details shown in figure 8.7.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示有关特定 pod 的详细信息，屏幕顶部将类似于图 8.7 中显示的详细信息。
- en: '![](../Images/CH08_F07_Wilkins.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F07_Wilkins.png)'
- en: Figure 8.7 Kubernetes dashboard showing a specific instance of the log-simulator
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 显示特定 log-simulator 实例的 Kubernetes 仪表板
- en: As you’ll note in figure 8.7, there are four icons in the top right-hand side
    of the image. Clicking on the first icon will display a view like the one in figure
    8.8\. The figure shows us the `stdout` being generated by the LogGenerator.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在图 8.7 中所注意到的，图像右上角有四个图标。点击第一个图标将显示类似于图 8.8 的视图。该图显示了 LogGenerator 生成的 `stdout`。
- en: '![](../Images/CH08_F08_Wilkins.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F08_Wilkins.png)'
- en: Figure 8.8 The console (stdout) of our instance of the LogGenerator with its
    simple configuration generating events to be collected by our Fluentd setup
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 我们的 LogGenerator 实例的控制台（stdout），其简单配置生成要由我们的 Fluentd 设置收集的事件
- en: While this is useful and confirms the container is functioning as expected,
    we need to know which file Kubernetes is pushing this output to, as we need to
    set up a tail input plugin against that file. Returning to the screen, we saw
    in figure 8.7 that we want to use the arrow-based icon (second from left), as
    this will provide us with a shell view into the container being executed.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这很有用，并确认容器按预期运行，但我们还需要知道Kubernetes将输出推送到哪个文件，因为我们需要针对该文件设置一个tail输入插件。回到屏幕上，我们在图8.7中看到我们想要使用基于箭头的图标（从左数第二个），因为这将为我们提供正在执行的容器的shell视图。
- en: It is also worth logging into a shell provided by this container image, because
    you will see the environment as your application will. Any container exploration
    needs to be quickly done—once the LogGenerator has completed generating log events,
    it will stop. As a result, our container will die, taking our session with it.
    If you try to see what logs exist, you shouldn’t see anything, as the log events
    will be captured on the host running Kubernetes, not in the container. By doing
    this, we have clearly established the first of the requirements of our Kubernetes
    container—the fact that access to the host file system is needed to collect the
    logs generated.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，登录到由这个容器镜像提供的shell中，因为你会看到与应用程序相同的环境。任何容器探索都需要迅速完成——一旦LogGenerator完成生成日志事件，它就会停止。结果，我们的容器会死亡，带着我们的会话一起结束。如果你试图查看存在的日志，你不应该看到任何东西，因为日志事件将被捕获在运行Kubernetes的主机上，而不是在容器中。通过这样做，我们清楚地确立了我们的Kubernetes容器第一个要求的事实——即需要访问主机文件系统来收集生成的日志。
- en: 8.4.3 Understanding how Fluentd DaemonSets are put together
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.3 理解Fluentd DaemonSet的构建方式
- en: 'Our first contact with Kubernetes was in chapter 2, where we looked briefly
    at using a DaemonSet provided by Fluentd. We’ve said Kubernetes configuration
    gets complex. However, it would be easy to question this given the `Kubernetes.yaml`
    we’ve used for the LogGenerator. Let’s take a moment to step through what is involved
    with the Kubernetes and Docker resources for Fluentd. There are a couple of crucial
    repositories relevant to this, specifically the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们第一次接触Kubernetes是在第2章，我们简要地查看了一下使用Fluentd提供的DaemonSet。我们说过Kubernetes配置会变得复杂。然而，考虑到我们为LogGenerator使用的`Kubernetes.yaml`，这个问题很容易被质疑。让我们花点时间来了解一下Fluentd的Kubernetes和Docker资源所涉及的内容。与此相关的有几个关键仓库，具体如下：
- en: '*Kubernetes DaemonSet in GitHub*—This is where most of the necessary implementation
    details are ([http://mng.bz/6ZXo](http://mng.bz/6ZXo)).'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubernetes DaemonSet in GitHub*—这是大多数必要的实现细节所在 ([http://mng.bz/6ZXo](http://mng.bz/6ZXo))。'
- en: '*Docker file base images*—([https://github.com/fluent/fluentd-docker-image](https://github.com/fluent/fluentd-docker-image)).
    These are the Docker base images, including the template mechanism used to help
    generate the different OS variations.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Docker文件基础镜像*—([https://github.com/fluent/fluentd-docker-image](https://github.com/fluent/fluentd-docker-image))。这些是Docker基础镜像，包括用于帮助生成不同操作系统变体的模板机制。'
- en: '*Docker Hub repository*—This is where the Docker images are pulled from for
    the Kubernetes configuration ([https://hub.docker.com/u/fluent](https://hub.docker.com/u/fluent)).
    One or more Docker images form a pod based on the configuration provided.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Docker Hub仓库*—这是从Docker镜像中拉取Kubernetes配置的地方 ([https://hub.docker.com/u/fluent](https://hub.docker.com/u/fluent))。一个或多个Docker镜像根据提供的配置形成一个pod。'
- en: '*Metadata filter*—This is incorporated into the DaemonSet ([http://mng.bz/oa2d](http://mng.bz/oa2d)).
    The metadata filter enriches the Kubernetes log records with additional context
    to help you better understand what is happening.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*元数据过滤器*—这被集成到DaemonSet中 ([http://mng.bz/oa2d](http://mng.bz/oa2d))。元数据过滤器通过添加额外的上下文来丰富Kubernetes日志记录，帮助你更好地理解正在发生的事情。'
- en: When you visit the GitHub repository for Fluentd’s DaemonSets, you see a range
    of YAML files. The Fluentd community has provided a range of standardized configurations
    for capturing Kubernetes logging and sending the contents on to a single destination.
    The configurations range from forwarding the content to another Fluentd node,
    to sending to various cloud-native services provided by AWS, Azure, and Google,
    to dedicated services such as Graylog, Loggly, and the more common targets Elasticsearch
    and Syslog.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当你访问Fluentd的DaemonSet GitHub仓库时，你会看到一系列YAML文件。Fluentd社区提供了一系列标准化的配置，用于捕获Kubernetes日志并将内容发送到单个目的地。这些配置包括将内容转发到另一个Fluentd节点，发送到AWS、Azure和Google提供的各种云原生服务，以及像Graylog、Loggly这样的专用服务，以及更常见的目标Elasticsearch和Syslog。
- en: 'When examining the Kubernetes YAML configurations, you’ll see they are all
    very similar in nature, with the following characteristics:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当检查 Kubernetes YAML 配置时，你会发现它们在本质上都非常相似，具有以下特点：
- en: Setting the image up, so it will be deployed in the kube-system namespace
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置镜像，使其将在 kube-system 命名空间中部署
- en: Referencing a suitable container image
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引用合适的容器镜像
- en: Defining environment variables that can be used in the relevant Fluentd configuration
    file to connect with the external service—typically details such as the host and
    port of the target solution
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义可以在相关 Fluentd 配置文件中使用以连接外部服务的环境变量——通常是目标解决方案的主机和端口等详细信息
- en: Specifying the number of resources that should be allocated to the container
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定应分配给容器的资源数量
- en: Defining the host-file locations that need to be visible within the container—specifically
    `/var/log` and `/var/lib/docker/containers`—and how the path should be seen within
    the container.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义需要在容器内可见的主机文件位置——特别是`/var/log`和`/var/lib/docker/containers`——以及路径在容器内应该如何显示。
- en: What isn’t shown in the configurations is that some additional environment variables
    can be set and passed through, further changing the container’s behavior; for
    example, whether to try and interact with systemd. But we’ll see this in more
    detail shortly. We can assume that the “real magic” occurs in the container, and
    therefore in the Docker file.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 配置中没有显示的是，可以设置和传递一些额外的环境变量，从而进一步改变容器的行为；例如，是否尝试与 systemd 交互。但我们很快就会看到这一点。我们可以假设“真正的魔法”发生在容器中，因此也在
    Docker 文件中。
- en: Kubernetes Docker images
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes Docker 镜像
- en: 'If you examine the README in the repository’s root, you’ll see a list of Docker
    pull commands, with one or more references for each type of daemon. Looking through
    the list, you’ll note they have been broken into two major groups: `x86_64 images`
    and `arm64_images`. The need for this may not be immediately apparent until we
    remember that the Docker file has to ultimately reference binaries specific to
    the computer hardware. This is a downside of delivering virtualized or containerized
    solutions over using a more generic package manager. This means we have a lot
    of Docker images to maintain.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看存储库根目录下的 README，你会看到一个 Docker 拉取命令列表，其中每个守护进程类型都有一个或多个引用。查看列表时，你会注意到它们已经被分为两大组：`x86_64
    镜像`和`arm64_images`。这种需求可能直到我们想起 Docker 文件最终必须引用特定于计算机硬件的二进制文件时才变得明显。这是在虚拟化或容器化解决方案中使用更通用的包管理器的一个缺点。这意味着我们有很多
    Docker 镜像需要维护。
- en: 'The Kubernetes Docker images are also generated using templates, but we can
    characterize the activities as doing the following things:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes Docker 镜像也是使用模板生成的，但我们可以将活动描述为以下事情：
- en: Establishing a dependency on the relevant Docker image
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立对相关 Docker 镜像的依赖
- en: Setting up Ruby and Gem, including defining environment variables to the appropriate
    locations
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置 Ruby 和 Gem，包括将环境变量定义到适当的位置
- en: Installing various gem files
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装各种 gem 文件
- en: Configuring files covering Fluentd, systemd, Kubernetes, Prometheus
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置涵盖 Fluentd、systemd、Kubernetes、Prometheus 的文件
- en: 'Using an example such as [https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.12/arm64/debian-forward/conf,](https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.12/arm64/debian-forward/conf)
    we can examine the configuration and file relationships in detail. Figure 8.9
    also provides a visual representation of the file relationships:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 以[https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.12/arm64/debian-forward/conf,](https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.12/arm64/debian-forward/conf)为例，我们可以详细检查配置和文件关系。图
    8.9 也提供了文件关系的视觉表示：
- en: '`Fluent.conf` is in the root container and uses the `include` mechanism to
    bring in the contents of other configuration files, as we saw back in chapter
    5\. This configuration file also has a single match that, in the case of the forward
    DaemonSet, matches all log events and sends them on to the target server. It is
    worth noting that the forwarding configuration does not include any security (no
    TLS, etc.); this isn’t a problem if the logs are not sensitive. But if they are,
    then you will need to replace the configuration files with ones that include the
    necessary configuration. We’ll see more of how this can be done later in the chapter.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Fluent.conf` 位于根容器中，并使用 `include` 机制引入其他配置文件的内容，正如我们在第 5 章中看到的。此配置文件还有一个匹配项，在转发守护进程集的情况下，匹配所有日志事件并将它们发送到目标服务器。值得注意的是，转发配置不包括任何安全措施（没有
    TLS 等）；如果日志不敏感，这不是问题。但如果它们是敏感的，那么您需要用包含必要配置的配置文件替换它们。我们将在本章后面看到如何做到这一点。'
- en: The inclusion of the systemd and Prometheus configurations are subject to environment
    variable controls, specifically the existence of settings for `FLUENTD_SYSTEMD_CONF`
    and `FLUENTD_PROMETHEUS_CONF`.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: systemd 和 Prometheus 的配置受环境变量控制，具体来说，存在 `FLUENTD_SYSTEMD_CONF` 和 `FLUENTD_PROMETHEUS_CONF`
    的设置。
- en: The `Kubernetes.conf` is needed, so it is included. Finally, any configuration
    in the `conf.d` folder is included, so extending the configuration with any specific
    customizations is possible.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 需要 `Kubernetes.conf`，因此它被包含在内。最后，`conf.d` 文件夹中的任何配置都被包含，因此可以通过任何特定的自定义来扩展配置。
- en: '![](../Images/CH08_F09_Wilkins.png)'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F09_Wilkins.png)'
- en: Figure 8.9 A representation of the relationship between the configuration files
    and how they are influenced by environment variables
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.9 配置文件之间的关系及其受环境变量影响的表现
- en: The `Prometheus.conf` file is straightforward. It defines the use of the input
    plugins for Prometheus and `Prometheus_output_monitor` to monitor Prometheus.
    Environment variables define the server addresses to `bind`, `port`, and a `path`
    if the metrics URI are different using the variables `FLUENTD_PROMETHEUS_BIND`,
    `FLUENTD_PROMETHEUS_PORT`, and `FLUENTD_PROMETHEUS_ PATH`, respectively.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Prometheus.conf` 文件很简单。它定义了 Prometheus 输入插件的使用以及 `Prometheus_output_monitor`
    用于监控 Prometheus。环境变量定义了服务器的地址，包括 `bind`、`port` 以及如果指标 URI 不同，则使用变量 `FLUENTD_PROMETHEUS_BIND`、`FLUENTD_PROMETHEUS_PORT`
    和 `FLUENTD_PROMETHEUS_PATH` 分别定义 `path`。'
- en: The `Systemd.conf` file defines the sources for Docker, Kubelet (the Kubernetes
    node controller and bootkube service using the systemd source plugin). It is worth
    noting that this plugin is separate from the Fluent Git repository and has been
    separately authored (details at [https://github.com/fluent-plugin-systemd](https://github.com/fluent-plugin-systemd)).
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Systemd.conf` 文件定义了 Docker、Kubelet（使用 systemd 源插件）的来源（Kubernetes 节点控制器和 bootkube
    服务）。值得注意的是，此插件独立于 Fluent Git 仓库，并且是独立编写的（详细信息请参阅 [https://github.com/fluent-plugin-systemd](https://github.com/fluent-plugin-systemd)）。'
- en: 'The `Kubernetes.conf` file is the most interesting of the inclusions in the
    configuration. Like systemd, it also uses an external plugin, this time a filter
    called `kubernetes_metadata` (the details of which can be found at [https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter](https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter)).
    The filter’s job incorporates or excludes additional metadata into the log events.
    This is done by communicating with the Kubernetes API endpoint using the environment
    variables `FLUENT_FILTER_KUBERNETES_URL` or combining `KUBERNETES_ SERVICE_HOST`
    and `KUBERNETES_SERVICE_PORT`. This requires metadata from the log events for
    essential context to retrieve information from the Kubernetes API. The info can
    be drawn from the journald if being used or possibly from the log file names.
    Some of the attributes used with the plugin either assume the default values or
    are hardwired into the container. The controls that can be configured map to the
    plugin attributes as follows:'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Kubernetes.conf` 文件是配置中包含的最有趣的部分。像 systemd 一样，它也使用外部插件，这次是一个名为 `kubernetes_metadata`
    的过滤器（详细信息可在 [https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter](https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter)
    找到）。过滤器的任务是将额外的元数据合并到日志事件中或从日志事件中排除。这是通过使用环境变量 `FLUENT_FILTER_KUBERNETES_URL`
    或结合 `KUBERNETES_SERVICE_HOST` 和 `KUBERNETES_SERVICE_PORT` 与 Kubernetes API 端点通信来完成的。这需要从日志事件中获取元数据以获取从
    Kubernetes API 获取信息的基本上下文。信息可以来自 journald，如果正在使用它，或者可能来自日志文件名。与插件一起使用的某些属性要么假定默认值，要么直接嵌入到容器中。可以配置的控制映射到插件属性如下：'
- en: '`KUBERNETES_VERIFY_SSL`—`verify_ssl` sets a flag indicating whether the SSL/TLS
    certificates should be checked. If your environment has a certificate authority
    for the certificates used, we recommend this be set to yes.'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`KUBERNETES_VERIFY_SSL`—`verify_ssl` 设置一个标志，指示是否应该检查 SSL/TLS 证书。如果你的环境有用于证书的证书颁发机构，我们建议将其设置为是。'
- en: '`KUBERNETES_CA_FILE`—This attribute provides the path to the CA file for Kubernetes
    server certificate validation.'
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`KUBERNETES_CA_FILE`—此属性提供了 Kubernetes 服务器证书验证的 CA 文件路径。'
- en: '`FLUENT_KUBERNETES_METADATA_SKIP_LABELS`—Don’t retrieve the labels from the
    metadata if set to `true`.'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FLUENT_KUBERNETES_METADATA_SKIP_LABELS`—如果设置为 `true`，则不要从元数据中检索标签。'
- en: '`FLUENT_KUBERNETES_METADATA_SKIP_CONTAINER_METADATA`—If set to `true`, then
    the metadata relating to the container image and `image_id` will not be included.'
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FLUENT_KUBERNETES_METADATA_SKIP_CONTAINER_METADATA`—如果设置为 `true`，则不会包含与容器镜像和
    `image_id` 相关的元数据。'
- en: '`FLUENT_KUBERNETES_METADATA_SKIP_MASTER_URL`—If `true`, the `master_url` metadata
    will not be included.'
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FLUENT_KUBERNETES_METADATA_SKIP_MASTER_URL`—如果设置为 `true`，则不会包含 `master_url`
    元数据。'
- en: '`FLUENT_KUBERNETES_METADATA_SKIP_NAMESPACE_METADATA`—If set to `true`, then
    the metadata such as `namespace_id` will be excluded.'
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FLUENT_KUBERNETES_METADATA_SKIP_NAMESPACE_METADATA`—如果设置为 `true`，则不会包含如 `namespace_id`
    这样的元数据。'
- en: '`FLUENT_KUBERNETES_WATCH`—When set to `true`, it tells the plugin to watch
    for changes in the metadata held by the Kubernetes API server for the pods.'
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FLUENT_KUBERNETES_WATCH`—当设置为 `true` 时，它告诉插件监视 Kubernetes API 服务器持有的 pod 元数据的变化。'
- en: For a filter to do anything meaningful, the configuration needs to include sources.
    In this case, the tail source plugin is used multiple times to capture any logs
    generated in the folders `/var/log/containers/*.log`, `/var/log/salt/minion`,
    `/var/log/ startupscript.log`, `/var/log/docker.log`, `/var/log/etcd.log`, `/var/log/
    kubelet.log`, `/var/log/kube-apiserver.log`, `/``var/log/kube-controller-manager.log`,
    `/var/log/kube-scheduler.log`, `/var/log/rescheduler.log`, `/var/log/glbc.log`,
    `/var/log/cluster-autoscaler.log`, and `/var/log/kubernetes/kube-apiserver-audit.log`.
    You may have recognized these as the log files for the core Kubernetes processes.
    Based on this, we should see log events picked up as long as our container’s log
    events get written somewhere in the `/var/log/containers/` folder on the Kubernetes
    host.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让过滤器执行任何有意义的事情，配置需要包含源。在这种情况下，使用了多次 tail 源插件来捕获在文件夹 `/var/log/containers/*.log`、`/var/log/salt/minion`、`/var/log/startupscript.log`、`/var/log/docker.log`、`/var/log/etcd.log`、`/var/log/kubelet.log`、`/var/log/kube-apiserver.log`、`/var/log/kube-controller-manager.log`、`/var/log/kube-scheduler.log`、`/var/log/rescheduler.log`、`/var/log/glbc.log`、`/var/log/cluster-autoscaler.log`
    和 `/var/log/kubernetes/kube-apiserver-audit.log` 中生成的任何日志。你可能已经认出了这些是核心 Kubernetes
    进程的日志文件。基于此，我们应该看到日志事件被捕获，只要我们的容器日志事件被写入 Kubernetes 主机上的 `/var/log/containers/`
    文件夹中的某个位置。
- en: Fluent Bit in Kubernetes
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中的 Fluent Bit
- en: We have primarily focused on Fluentd with Docker and Kubernetes as the main
    way to provide a flexible means to capture log events. But in a containerized
    environment, Fluent Bit, with its smaller footprint, should be considered, especially
    if the goal is to push the log events out to a dedicated Fluentd node or log analytics
    platform like Elasticsearch and perform the “heavy lifting” with these parts of
    your solution. It is worth noting that Fluent Bit has its own projects within
    GitHub to provide a Docker base setup and to extend Docker images for different
    environments and operating systems, such as Debian, CentOS, Raspbian, and Amazon
    Linux. The Docker images support some possible targets and a Fluent Bit configuration
    deployed as a DaemonSet in Kubernetes.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们主要关注Fluentd与Docker和Kubernetes结合作为主要方式，以提供一种灵活的方式来捕获日志事件。但在容器化环境中，考虑到Fluent
    Bit具有更小的占用空间，应该考虑使用它，尤其是如果目标是将日志事件推送到专门的Fluentd节点或日志分析平台，如Elasticsearch，并使用这些部分来执行“重负载”。值得注意的是，Fluent
    Bit在GitHub上有自己的项目，提供Docker基础设置，并扩展不同环境和操作系统（如Debian、CentOS、Raspbian和Amazon Linux）的Docker镜像。这些Docker镜像支持一些可能的目标，以及作为Kubernetes中的DaemonSet部署的Fluent
    Bit配置。
- en: 8.5 Getting a peek at host logs
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5 查看主机日志
- en: Earlier in the chapter, we peeked at what our LogGenerator container could see
    of the environment and established that it couldn’t see any part of the host,
    and therefore any logs. This is because we didn’t configure the container to mount
    a file system. A folder mount wasn’t necessary, as we trusted the container to
    capture `stdout` and put the content in a suitable location. However, when we
    demonstrated that behavior, we had control of Docker. Now Docker will be managed
    by Kubernetes. Additionally, we need to think about how we monitor Kubernetes
    itself. A review of the prebuild Fluentd resources points to the log content residing
    in `/var/log`. Minikube provides a convenient tool that allows easy access to
    the host environment. Once we can access the host, we can examine the environment
    to locate the relevant log files and understand what needs to be captured. Using
    a new shell (Windows or Linux), we can use the command
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章早期，我们窥视了LogGenerator容器可以看到的环境，并确定它看不到主机上的任何部分，因此看不到任何日志。这是因为我们没有配置容器挂载文件系统。文件夹挂载不是必需的，因为我们信任容器捕获`stdout`并将内容放在合适的位置。然而，当我们演示这种行为时，我们控制着Docker。现在Docker将由Kubernetes管理。此外，我们需要考虑如何监控Kubernetes本身。对预构建的Fluentd资源的审查表明日志内容位于`/var/log`。Minikube提供了一个方便的工具，允许轻松访问主机环境。一旦我们可以访问主机，我们就可以检查环境以定位相关的日志文件并了解需要捕获的内容。使用新的shell（Windows或Linux），我们可以使用以下命令
- en: '[PRE18]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This will provide us with a secure shell into the host environment. Let’s look
    at the folders we’ve seen in the current configuration using the command
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们提供一个安全的shell进入主机环境。让我们使用以下命令查看当前配置中看到的文件夹
- en: '[PRE19]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The result is perhaps not as expected, given this is a folder of symbolic links
    to files in `/var/log/pods`, as shown in figure 8.10\. Fortunately, everyone can
    see the links.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可能并不像预期的那样，因为这是一个指向`/var/log/pods`中文件的符号链接文件夹，如图8.10所示。幸运的是，每个人都可以看到这些链接。
- en: '![](../Images/CH08_F10_Wilkins.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F10_Wilkins.png)'
- en: Figure 8.10 The result of looking at the /var/log/containers folder—you can
    see the files listed as symbolic links to another file in the pods folder
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10 查看文件夹`/var/log/containers`的结果——你可以看到列出的文件作为pods文件夹中另一个文件的符号链接
- en: If we follow the links to `/var/log/pods,` we see that each link resolves to
    a folder that reflects instances of the pods, as shown in figure 8.11.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们跟随链接到`/var/log/pods`，我们会看到每个链接解析到一个文件夹，该文件夹反映了pods的实例，如图8.11所示。
- en: '![](../Images/CH08_F11_Wilkins.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F11_Wilkins.png)'
- en: Figure 8.11 The result of looking at the /var/log/pods folder, which turn out
    to be directories
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11 查看文件夹`/var/log/pods`的结果，结果竟然是目录
- en: Examining one of the pod folders, such as `log-simulator`, previously deployed
    into the default namespace (hence the `default_` prefix), we see a folder with
    incrementing log file numbers and another layer of symbolic links, shown in figure
    8.12.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 检查一个之前部署到默认命名空间（因此有`default_`前缀）的pod文件夹，例如`log-simulator`，我们看到一个包含递增日志文件编号的文件夹和另一层符号链接，如图8.12所示。
- en: '![](../Images/CH08_F12_Wilkins.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F12_Wilkins.png)'
- en: Figure 8.12 The content of one of the pod folders in /var/log/pods, which again
    are symbolic links to another part of the file system
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12 `/var/log/pods`中的一个pod文件夹的内容，这些文件夹再次是文件系统另一部分的符号链接
- en: Following the link into `/var/lib/docker/containers` yields a new challenge—the
    privileges are greatly restricted, and we need to use a `sudo` command to list
    the folder’s contents, as shown in figure 8.13.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 通过链接进入 `/var/lib/docker/containers` 会带来一个新的挑战——权限被大大限制，我们需要使用 `sudo` 命令来列出文件夹的内容，如图
    8.13 所示。
- en: '![](../Images/CH08_F13_Wilkins.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F13_Wilkins.png)'
- en: Figure 8.13 The restricted contents of /var/lib/docker/containers can be seen
    here; note the very restrictive privileges.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13 这里可以看到 /var/lib/docker/containers 受限的内容；请注意非常受限的权限。
- en: If we look inside one of these folders, we find the log files shown in figure
    8.14\. But the last couple of steps have worked only with elevated permissions.
    It also helps us understand the different file paths being used in the predefined
    configuration. This means that in the YAML file, we need to ensure that the mounts
    work with appropriate permissions. It also confirms that the paths inside the
    containers are the same as the host.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看这些文件夹中的一个，我们会发现图 8.14 中显示的日志文件。但最后几个步骤只有在提升权限的情况下才有效。这也帮助我们理解了预定义配置中使用的不同文件路径。这意味着在
    YAML 文件中，我们需要确保挂载具有适当的权限。这也确认了容器内部的路径与主机相同。
- en: '![](../Images/CH08_F14_Wilkins.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F14_Wilkins.png)'
- en: Figure 8.14 Having overcome the restrictions, we can see the contents of /var/lib/docker/containers,
    which include a genuine log file rather than another symbolic link.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.14 在克服了限制之后，我们可以看到 `/var/lib/docker/containers` 的内容，其中包括一个真正的日志文件而不是另一个符号链接。
- en: We should also note that minikube’s log access security is very coarse-grained,
    and as a result, if you can see one log, you’ll be able to access them all if
    you interact with the host. In a production context, this is not very desirable
    from a security perspective. The takeaway is if you’re sensitive about logs in
    a containerized environment, control the visibility more directly using patterns
    such as the sidecar, as discussed in chapter 7\. Taking more active control of
    your container’s log events means you won’t be subject to how access controls
    are managed in Kubernetes.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该注意，minikube 的日志访问安全性非常粗粒度，因此，如果你可以看到一个日志，那么如果你与主机交互，你将能够访问所有日志。在生产环境中，从安全角度来看，这并不是非常理想。结论是，如果你对容器化环境中的日志敏感，请直接使用如第
    7 章中讨论的 sidecar 等模式来控制可见性。更积极地控制你容器的日志事件意味着你不会受到 Kubernetes 中访问控制管理方式的影响。
- en: Navigating through the file system makes it clear that the way Kubernetes is
    configured is not trivial. This brings us back to the point that the more we can
    monitor at the container and application levels, the easier things will be.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在文件系统中导航可以清楚地看出，Kubernetes 的配置并非易事。这让我们回到了这样一个观点：我们能够在容器和应用程序层面进行更多监控，事情就会变得更容易。
- en: 8.6 Configuring a Kubernetes logging DaemonSet
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.6 配置 Kubernetes 日志 DaemonSet
- en: Given the overview, it would be reasonable to assume that we can copy the configuration
    YAML to establish the Kubernetes DaemonSet for logging. We can leverage the existing
    Docker images provided by Fluentd in our configuration. The YAML configuration
    will need to give specific environment variable values and mount the right parts
    of the file system. If we wanted the DaemonSet to also apply some customized configuration,
    we would need to map additional configuration files into the system.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 根据概述，我们可以合理地假设我们可以复制配置 YAML 来建立用于日志记录的 Kubernetes DaemonSet。我们可以利用 Fluentd 在我们的配置中提供的现有
    Docker 镜像。YAML 配置需要提供特定的环境变量值并将文件系统的正确部分挂载。如果我们想让 DaemonSet 也应用一些自定义配置，我们需要将额外的配置文件映射到系统中。
- en: Rather than set a lot of environment values to control the current Fluentd configuration,
    we can look at how we can point Fluentd to an alternative configuration file and
    inject the modified configuration. This also gives us a chance to address content
    layout in a Docker file that can impact downstream applications.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是设置很多环境值来控制当前的 Fluentd 配置，我们可以看看如何将 Fluentd 指向一个替代配置文件并注入修改后的配置。这也给了我们机会来解决
    Docker 文件中的内容布局问题，这可能会影响下游应用程序。
- en: 8.6.1 Getting the Fluentd configuration ready to be used
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.1 准备 Fluentd 配置以供使用
- en: With the customized Fluentd configuration, we could deploy this by modifying
    the Docker build. However, a more elegant way is to exploit the features of the
    Kubernetes configuration. This means if we wish to alter the configuration, we
    only need to redeploy a configuration change rather than changing the Docker image
    and the subsequent steps involved in redeploying it. This is made possible because
    the Fluentd Docker files work by configuring Fluentd through environment variables
    and suitably placed additional configuration files that can be picked up through
    the includes statements.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 使用定制的Fluentd配置，我们可以通过修改Docker构建来部署它。然而，一种更优雅的方法是利用Kubernetes配置的功能。这意味着如果我们想更改配置，我们只需要重新部署配置更改，而不是更改Docker镜像及其重新部署的后续步骤。这是可能的，因为Fluentd
    Docker文件通过环境变量和适当放置的附加配置文件来配置Fluentd，这些配置文件可以通过include语句获取。
- en: With our Fluentd configuration established, we need to get it ready to be consumed
    by the container. We’ll do this using a Kubernetes ConfigMap, which we’ll explain
    a bit more shortly. We need to start by deploying the ConfigMap into Kubernetes,
    ready to be referenced. The ConfigMap can be included in our core Kubernetes YAML
    file, or we can use the Fluentd file, translate it to a suitable format, and deploy
    the configuration separately. This latter approach is more desirable, as we can
    check the configuration using the Fluentd dry-run feature we saw in chapter 3
    to validate the configuration before deploying. If the configuration is embedded
    in the larger configuration file, the validation step won’t be possible.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立Fluentd配置后，我们需要使其准备好被容器消费。我们将使用Kubernetes配置映射来完成此操作，我们将在稍后对其进行更多解释。我们需要首先将配置映射部署到Kubernetes中，以便进行引用。配置映射可以包含在我们的核心Kubernetes
    YAML文件中，或者我们可以使用Fluentd文件，将其转换为合适的格式，并单独部署配置。后一种方法更可取，因为我们可以使用第3章中看到的Fluentd dry-run功能来验证配置，然后再部署。如果配置嵌入在更大的配置文件中，验证步骤将无法进行。
- en: The Fluentd ConfigMap is associated with the kube-system namespace to match
    the fact that the standard Fluentd DaemonSet is deployed into that namespace.
    The use of this namespace makes sense; in this case we’re configuring and deploying
    a Kubernetes-wide service. Listing 8.3 shows the Fluentd configuration that we
    want to introduce. As you can see, it sources logs from the containers and pods
    and sends the log events to a configurable target. We also need to note the name
    of the ConfigMap (`fluentd-conf`), as this will be referenced in the YAML file.
    As with the LogSimulator deployment, we’ve bundled a batch and shell script, removing
    any previous configuration (`deploy-config.bat` and `.sh`).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd配置映射与kube-system命名空间相关联，以匹配标准Fluentd守护进程集部署到该命名空间的事实。使用此命名空间是有意义的；在这种情况下，我们正在配置和部署一个Kubernetes全局服务。列表8.3显示了我们要引入的Fluentd配置。如您所见，它从容器和Pod中收集日志并将日志事件发送到可配置的目标。我们还需要注意配置映射的名称（`fluentd-conf`），因为它将在YAML文件中引用。与LogSimulator部署一样，我们捆绑了一个批处理和shell脚本，移除了任何以前的配置（`deploy-config.bat`和`.sh`）。
- en: 'To deploy the configuration file, we need to use the minikube command:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署配置文件，我们需要使用minikube命令：
- en: '[PRE20]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: If you want to confirm the deployment, use the dashboard to view the configuration
    and select Config Maps (from the left-hand menu). Then, in the center part of
    the dashboard, you’ll see all the ConfigMaps, including our `fluentd-conf`. The
    content of the ConfigMap can then be displayed by clicking on the name of our
    ConfigMap. You may see each line terminated with `\r;` this is the Linux encoding
    of a carriage return and won’t present any issues when the file is processed.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想确认部署，请使用仪表板查看配置并选择配置映射（从左侧菜单）。然后，在仪表板的中心部分，您将看到所有的配置映射，包括我们的`fluentd-conf`。通过点击我们的配置映射名称，可以显示配置映射的内容。您可能会看到每行以`\r;`结尾，这是Linux对回车符的编码，在文件处理时不会出现任何问题。
- en: Listing 8.3 Chapter8/Fluentd/custom.conf overriding configuration for Kubernetes
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.3 第8章/Fluentd/custom.conf 覆盖Kubernetes的配置
- en: '[PRE21]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ This source is part of the secured file system and needs the privileges set
    to allow Fluentd to read.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 此源是安全文件系统的一部分，需要设置权限以允许Fluentd读取。
- en: ❷ We’ve set a very short-lived buffer so we can see the events flowing through
    quickly; given our deployment, the networking overheads aren’t an issue.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们设置了一个非常短暂的缓冲区，以便我们可以快速看到事件流过；鉴于我们的部署，网络开销不是问题。
- en: ❸ Allows the addressing of the server to be driven through the Kubernetes configuration
    file
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 允许通过Kubernetes配置文件驱动对服务器的寻址
- en: Passing content to the container through Kubernetes
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Kubernetes 将内容传递到容器
- en: Kubernetes provides a range of ways to share content into a container as a mount
    path. The number of options is such that *Kubernetes in Action* has several chapters
    dedicated to the subject. Essentially, the different techniques can impact whether
    the container can modify the file system, whether the storage has persisted beyond
    the container's life, and so on. A ConfigMap is immutable (read-only), which is
    ideal for our scenario. The contents of a ConfigMap can be consumed through environment
    variables, command-line values, and files, depending upon the options used. However,
    they are limited in size, so they may not be suitable if you wish to pass over
    a log file to be replayed.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 提供了多种方式将内容作为挂载路径共享到容器中。选项的数量如此之多，以至于《Kubernetes in Action》有数章专门讨论这个主题。本质上，不同的技术可能会影响容器是否可以修改文件系统，存储是否在容器生命周期之后持久化等问题。ConfigMap
    是不可变的（只读），这对于我们的场景是理想的。根据使用的选项，ConfigMap 的内容可以通过环境变量、命令行值和文件来消费。然而，它们的大小有限，所以如果希望传递一个要重放的日志文件，可能不适合使用。
- en: When sharing files into Kubernetes-managed containers, we must be mindful that
    any content already in the folder (volume) of the container receiving the shared
    folder will effectively get overwritten with the shared content from Kubernetes.
    So, pushing new configurations into the container needs to be done carefully.
    For example, replacing just the `Kubernetes.conf` file in the standard Docker
    setup wouldn’t be wise because it shares a common folder with all the configuration
    files. By adopting the approach used in the containers of putting the new configuration
    files into a different location and modifying the path to the configuration file
    Fluentd picks up via the environment variable, we protect ourselves from such
    issues. This means if we wanted, we could include the standard Kubernetes and
    Prometheus configurations and then replace them when necessary.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 当将文件共享到由 Kubernetes 管理的容器中时，我们必须注意，接收共享文件夹的容器中已经存在的任何内容将被共享内容覆盖。因此，将新配置推送到容器需要谨慎操作。例如，在标准的
    Docker 设置中仅替换 `Kubernetes.conf` 文件是不明智的，因为它与所有配置文件共享一个公共文件夹。通过采用在容器中使用的将新配置文件放入不同位置并修改
    Fluentd 通过环境变量获取的配置文件路径的方法，我们可以避免此类问题。这意味着如果我们愿意，我们可以包括标准的 Kubernetes 和 Prometheus
    配置，并在必要时替换它们。
- en: 8.6.2 Creating our Kubernetes deployment configuration
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.2 创建我们的 Kubernetes 部署配置
- en: Let’s adapt and deploy that standard Fluentd repository DaemonSet for our minikube
    environment. To do that, we need to download the file locally, as we need to make
    a couple of tweaks. This can be done by using either a `wget` command on the raw
    view ([http://mng.bz/OGpE)](http://mng.bz/OGpE) or by using the `git clone` command.
    My preference is `wget` (it’s the easiest way to retrieve lots of things in Docker
    files, etc.), which looks like
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们调整并部署标准 Fluentd 仓库的 DaemonSet 到我们的 minikube 环境中。为此，我们需要本地下载文件，因为我们需要做一些调整。这可以通过使用原始视图中的
    `wget` 命令（[http://mng.bz/OGpE](http://mng.bz/OGpE)）或使用 `git clone` 命令来完成。我的首选是
    `wget`（这是在 Docker 文件等中检索大量内容的最简单方法），其命令如下：
- en: '[PRE22]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We need to then make the following additions and modifications:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要添加以下内容并进行以下修改：
- en: Set the values for the location of our Fluentd node that we want to forward
    the log events to. This means we should replace the text `REMOTE_ENDPOINT` with
    the address or IP of the host machine (e.g., `192.168.1.2`). The value for the
    `FLUENT_FOWARD_PORT` also needs to be changed from `18080` to `28080.` This is
    to reflect the port being used in our Fluentd node configuration.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置我们想要将日志事件转发到的 Fluentd 节点的位置值。这意味着我们应该将文本 `REMOTE_ENDPOINT` 替换为主机机的地址或 IP（例如，`192.168.1.2`）。`FLUENT_FOWARD_PORT`
    的值也需要从 `18080` 更改为 `28080`。这是为了反映我们在 Fluentd 节点配置中使用的端口。
- en: In a production setup, we would always recommend this be a DNS address. That
    way, any changes in the environment or scaling Fluentd with load balancing are
    masked from the configuration. This will require understanding how DNS is handled
    within Kubernetes, which is not a subject for this book.
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在生产环境中，我们始终建议使用 DNS 地址。这样，环境中的任何变化或通过负载均衡扩展 Fluentd 都会从配置中隐藏。这需要了解 Kubernetes
    中 DNS 的处理方式，但这不是本书的主题。
- en: Add the environment variable `FLUENTD_SYSTEMD_CONF` into the `env` section of
    the YAML, and set its value to `"FALSE".`
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 YAML 的 `env` 部分中添加环境变量 `FLUENTD_SYSTEMD_CONF`，并将其值设置为 `"FALSE"`。
- en: Override the `FLUENTD_CONF` environment variable in the same section so that
    it points to our `custom.conf` file we’ve supplied via the ConfigMap.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在同一部分覆盖 `FLUENTD_CONF` 环境变量，使其指向我们通过 ConfigMap 提供的 `custom.conf` 文件。
- en: Add a `securityContext` section to the container’s part of the YAML file with
    the `privileged` attribute set to `true` to overcome the previously identified
    permissions challenge.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 YAML 文件的容器部分添加一个 `securityContext` 部分，将 `privileged` 属性设置为 `true` 以克服之前确定的权限挑战。
- en: Add the `volumeMount` entry for our ConfigMap so that the path is defined as
    expected. This means adding to the `volumeMounts` section an additional name called
    `config-volume`, a `mountPath` of `/fluentd/etc/custom.`
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为我们的 ConfigMap 添加 `volumeMount` 条目，以便定义路径。这意味着在 `volumeMounts` 部分添加一个额外的名称 `config-volume`，`mountPath`
    为 `/fluentd/etc/custom`。
- en: We then reference the volumes section as an additional entry with the name of
    `config-volume` (linking the volumes and `VolumeMounts`) with an attribute of
    `configMap,` which is then referenced by `name`, which we previously set up as
    `fluentd-conf.`
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接着将名为 `config-volume` 的卷部分（链接卷和 `VolumeMounts`）作为一个附加条目引用，其属性为 `configMap`，然后通过
    `name` 引用，这是我们之前设置的 `fluentd-conf`。
- en: As we have tailored the existing configuration, you will still reference the
    Docker image defined by the Docker file at [http://mng.bz/p2dz](http://mng.bz/p2dz).
    The actual Docker image will come from Docker Hub at [http://mng.bz/QWvG](http://mng.bz/QWvG).
    The result of tailoring the Kubernetes YAML file can be seen in the following
    listing.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们对现有配置进行了定制，您仍然会参考 Docker 文件中定义的 Docker 镜像，网址为 [http://mng.bz/p2dz](http://mng.bz/p2dz)。实际的
    Docker 镜像将来自 Docker Hub，网址为 [http://mng.bz/QWvG](http://mng.bz/QWvG)。定制 Kubernetes
    YAML 文件的结果可以在下面的列表中看到。
- en: Listing 8.4 Chapter8/Kubernetes/fluentd-daemonset.yaml modified for our requirements
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.4：针对我们的需求修改的 Chapter8/Kubernetes/fluentd-daemonset.yaml
- en: '[PRE23]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ We continue to reference the prebuilt Fluentd Docker image setup for managing
    logging for Kubernetes.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们继续参考预构建的 Fluentd Docker 镜像设置，用于管理 Kubernetes 的日志。
- en: ❷ The IP and port for the log events to be forwarded to, set by using environment
    variables
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 通过环境变量设置要转发日志事件的 IP 和端口
- en: ❸ Overrides the location of the configuration file to be used when Fluentd starts
    up
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 覆盖 Fluentd 启动时使用的配置文件的位置
- en: ❹ Defines the mount location that the container will see. This path is then
    mapped to a file system outside of Kubernetes, giving us assurance the logs can
    be safely retained.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 定义了容器将看到的挂载位置。然后，此路径映射到 Kubernetes 外部的文件系统，确保日志可以安全保留。
- en: ❺ The additional security setting so that the container can access the restricted
    folders and files we saw when exploring the host server
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 为了使容器能够访问在探索宿主服务器时看到的受限制的文件夹和文件，设置了额外的安全设置。
- en: ❻ Maps the volume to the ConfigMap that was loaded into Kubernetes earlier
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 将卷映射到之前加载到 Kubernetes 中的 ConfigMap
- en: 8.6.3 Putting the implementation of a Fluentd for Kubernetes into action
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.3 将 Fluentd for Kubernetes 的实现付诸实践
- en: Using the understanding gleaned from chapters 3 and 7 and exploiting the existing
    Fluentd configuration files for the DaemonSet (see [http://mng.bz/XWZv](http://mng.bz/XWZv)),
    construct a simple single configuration file that tails any relevant files from
    the Kubernetes cluster. As the log events are collected, forward them to the Fluentd
    node previously used with the Docker log driver configuration.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 利用第 3 章和第 7 章中获得的理解，并利用现有的 Fluentd 配置文件为 DaemonSet（见 [http://mng.bz/XWZv](http://mng.bz/XWZv)）构建一个简单的单个配置文件，该文件可以跟踪
    Kubernetes 集群中的任何相关文件。随着日志事件的收集，将它们转发到之前使用 Docker 日志驱动配置的 Fluentd 节点。
- en: Answer
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 答案
- en: A simple Fluentd configuration has been provided in the download pack as shown
    in listing 8.4, which we will utilize for the following steps. Still, there is
    nothing to stop you from substituting your configuration into the next steps.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 下载包中提供了一个简单的 Fluentd 配置，如列表 8.4 所示，我们将利用它进行以下步骤。但您也可以将您的配置替换到下一步中。
- en: 8.6.4 Deploying to minikube
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.4 在 minikube 上部署
- en: Before deploying the DaemonSet, we should start our local Fluentd instance ready
    to receive log events. This is the same step as we have done many times before
    with the command
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署 DaemonSet 之前，我们应该启动本地 Fluentd 实例，准备接收日志事件。这与我们之前多次使用的命令相同。
- en: '[PRE24]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The next step is to deploy to Kubernetes our DaemonSet:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将我们的 DaemonSet 部署到 Kubernetes：
- en: '[PRE25]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Again, we’ve made a batch and shell script in the download pack called `deploy
    -deamonset.bat` or `.sh,` which will remove any preexisting deployment and push
    the current configuration into Kubernetes. You can confirm the DaemonSet’s deployment
    for the other assets using the dashboard by selecting the menu option for Daemon
    Sets (in the left-hand navigation menu under Workloads); this should list `fluentd`.
    Clicking on the title will show the details of the pod containing our container.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们在下载包中创建了一个批处理和 shell 脚本，名为 `deploy -deamonset.bat` 或 `.sh`，它将删除任何现有的部署并将当前配置推送到
    Kubernetes。你可以通过选择菜单选项“守护集”（在左侧导航菜单下的“工作负载”下）使用仪表板确认其他资产的守护集部署；这应该列出 `fluentd`。点击标题将显示包含我们的容器的
    pod 的详细信息。
- en: If Kubernetes has been in a steady idle state, then we may not see any logs
    immediately. We can address this by redeploying our LogSimulator configuration
    as we had did earlier in the chapter using the script `deploy-log-sim-k8`. This
    will quickly result in various events from Kubernetes being sent across, including
    the `stdout` log events from the LogSimulator container. We can see an example
    of the output in figure 8.15.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Kubernetes 处于稳定的空闲状态，我们可能立即看不到任何日志。我们可以通过重新部署我们的 LogSimulator 配置来解决此问题，就像我们在本章前面使用脚本
    `deploy-log-sim-k8` 所做的那样。这将迅速导致 Kubernetes 发送各种事件，包括来自 LogSimulator 容器的 `stdout`
    日志事件。我们可以在图 8.15 中看到输出示例。
- en: '![](../Images/CH08_F15_Wilkins.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F15_Wilkins.png)'
- en: Figure 8.15 The received log events in our receiving Fluentd node
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.15 接收到的日志事件在我们的接收 Fluentd 节点
- en: 8.6.5 Tidying up
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.5 整理
- en: Having run Kubernetes and retrieved various Docker images and minikube assets,
    you’ll reach a point where you want to clear or refresh the environment. One of
    the simple but excellent features is that minikube will completely wipe the environment
    with a single command to release resources because you’ve finished, or reset and
    start again if you want to validate everything again. This is done with the command
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行 Kubernetes 并检索各种 Docker 镜像和 minikube 资产后，你会达到想要清除或刷新环境的地步。其中一个简单但出色的功能是
    minikube 可以通过单个命令完全清除环境以释放资源，因为你已经完成，或者如果你想再次验证一切，可以重置并重新开始。这是通过以下命令完成的
- en: '[PRE26]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 8.7 Kubernetes configuration in action
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.7 Kubernetes 配置实战
- en: We have established a basic configuration that gives us a sight of the log events
    within a Kubernetes environment. However, the configuration isn’t enterprise-ready.
    To get to enterprise readiness, we will need to improve the configuration. Your
    challenge is to identify the changes necessary and take the provided configurations
    and amend them as necessary.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经建立了一个基本配置，使我们能够看到 Kubernetes 环境中的日志事件。然而，该配置尚未达到企业级。为了达到企业级，我们需要改进该配置。你的挑战是确定必要的更改，并按照提供的配置进行必要的修改。
- en: 8.7.1 Answer
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.7.1 答案
- en: 'The changes you have identified should include the following points:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 你已识别的更改应包括以下要点：
- en: The tail source is not recording its tracking position in the file; thus, a
    restart could duplicate log events.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尾部源没有在文件中记录其跟踪位置；因此，重启可能会重复日志事件。
- en: The recorded `pos_file` needs to be mapped to a mount point so that if the pod
    is restarted, the position information is not lost.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录的 `pos_file` 需要映射到一个挂载点，这样如果 pod 重新启动，位置信息就不会丢失。
- en: The tail configuration needs to address this issue of log rotation being managed.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尾部配置需要解决日志轮转管理的问题。
- en: The additional Kubernetes metrics and Prometheus information should be available
    and controlled through the configuration.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该提供额外的 Kubernetes 指标和 Prometheus 信息，并通过配置进行控制。
- en: The Kubernetes core components (in the kube-system namespace) should have their
    logs tagged separately to hosted applications and the receiving end separating
    out the tags.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 核心组件（在 kube-system 命名空间中）的日志应该单独标记为托管应用程序和接收端，以分离标签。
- en: Exploit the Kubernetes plugin to tag the log events with the additional metadata.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用 Kubernetes 插件为日志事件添加额外的元数据。
- en: Tune the caching in Fluentd to be more production-friendly and take into account
    the resources provided by Kubernetes.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整 Fluentd 中的缓存以更符合生产环境，并考虑 Kubernetes 提供的资源。
- en: The log level should be moved from debug to info.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该将日志级别从调试移动到信息。
- en: 8.8 More Kubernetes monitoring and logging to watch for
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.8 需要监控和记录的更多 Kubernetes
- en: We have addressed the core logging considerations for Kubernetes, but there
    are additional areas you should be aware of that may need further consideration.
    Kubernetes is continuing to evolve and be extended rapidly. As a result, some
    features may not be provided, as the deployment being run on is not the latest
    iteration, or if you’re using a managed service, the service provider may have
    implemented certain features differently as the different capabilities are typically
    API-led. And, of course, you may wish to overlay Kubernetes with a mesh framework,
    like Istio or Linkerd, that will have its own logs. We believe the following areas
    are the most valuable areas to track with core Kubernetes.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经解决了 Kubernetes 的核心日志考虑因素，但还有一些额外的领域您应该了解，可能需要进一步考虑。Kubernetes 正在持续发展和快速扩展。因此，某些功能可能不会提供，因为运行的部署不是最新版本，或者如果您使用的是托管服务，服务提供商可能根据不同的能力以不同的方式实现了某些功能。当然，您可能希望将
    Kubernetes 与 Istio 或 Linkerd 等网格框架叠加，这将有自己的日志。我们认为以下领域是跟踪核心 Kubernetes 最有价值的领域。
- en: 8.8.1 Node monitoring
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.8.1 节点监控
- en: So far, we have focused on the core logs involved with our containers. But you
    may wish to also address the monitoring of the health of the underpinning of the
    Kubernetes node. There are various options around this, including using Fluentd
    or Fluent Bit on the native node and monitoring the server’s raw statistics. However,
    this may not be allowed in some environments. Kubernetes also provides an additional
    DaemonSet for a service called the *Node Problem Detector*.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们关注的是与我们的容器相关的核心日志。但您可能还希望监控 Kubernetes 节点基础结构的健康状态。在这方面有各种选择，包括在本地节点上使用
    Fluentd 或 Fluent Bit 并监控服务器的原始统计信息。然而，在某些环境中可能不允许这样做。Kubernetes 还提供了一个名为 *Node
    Problem Detector* 的额外 DaemonSet 服务。
- en: The node problem DaemonSet is an optional add-on for minikube, and some other
    prebuilt Kubernetes clusters provided by cloud vendors and others take this approach.
    As a result, the DaemonSet needs to be enabled. The Node Problem Detector monitors
    the kernel log file and reports on specific issues based on the configuration,
    which can be overridden with a ConfigMap, in the same manner as we have modified
    the Fluentd configuration. The detector includes an exporter element that sends
    the information to different endpoints, including the Kubernetes API server and
    the Stackdriver, which integrates to our Fluentd Daemon.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 节点问题 DaemonSet 是 minikube 的一个可选附加组件，以及一些云供应商和其他人提供的预构建 Kubernetes 集群也采用这种方法。因此，需要启用
    DaemonSet。节点问题检测器监控内核日志文件，并根据配置报告特定问题，这些配置可以通过 ConfigMap 覆盖，就像我们修改 Fluentd 配置一样。检测器包括一个导出元素，将信息发送到不同的端点，包括
    Kubernetes API 服务器和 Stackdriver，后者与我们的 Fluentd Daemon 集成。
- en: More information on this service can be found at [https://github.com/kubernetes/node-problem-detector](https://github.com/kubernetes/node-problem-detector).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于此服务的信息可以在 [https://github.com/kubernetes/node-problem-detector](https://github.com/kubernetes/node-problem-detector)
    找到。
- en: 8.8.2 Termination messages
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.8.2 终止消息
- en: Within the configuration of a pod, it is possible to configure the recording
    of information relating to a pod’s termination. So in the event of an abnormal
    termination, it is possible to perform a retrospective diagnosis. Within a container
    configuration, Kubernetes can be given a path to where the termination messages
    are in a container using the property `terminationMessagePath` (which is defaulted
    to `/dev/termination-log`). We need to verify that the Kubernetes configuration
    ensures the log event is directed to a location picked up by Fluentd or that Fluentd
    knows how to retrieve this information from Kubernetes. More information on this
    can be found at [http://mng.bz/y4aB](http://mng.bz/y4aB).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pod 的配置中，可以配置与 pod 终止相关的信息记录。因此，在发生异常终止的情况下，可以进行事后诊断。在容器配置中，可以通过 `terminationMessagePath`
    属性（默认为 `/dev/termination-log`）为 Kubernetes 指定容器中终止消息的路径。我们需要验证 Kubernetes 配置确保日志事件被导向
    Fluentd 可以抓取的位置，或者 Fluentd 知道如何从 Kubernetes 获取这些信息。更多相关信息可以在 [http://mng.bz/y4aB](http://mng.bz/y4aB)
    找到。
- en: Summary
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The default Docker log driver works in such a way that trying to track its log
    files directly using standard Fluentd plugins isn’t possible (e.g., use of compression).
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认的 Docker 日志驱动程序以这种方式工作，即无法通过标准的 Fluentd 插件直接跟踪其日志文件（例如，使用压缩）。
- en: Fluentd can be used as a log driver for Docker, making accessing and using Docker
    log events a lot easier.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd 可以用作 Docker 的日志驱动程序，这使得访问和使用 Docker 日志事件变得更加容易。
- en: Fluentd GitHub repository includes predefined DaemonSet configurations. Alternative
    Fluentd configurations are also made available in prebuilt images to accommodate
    OS differences and the possibility of routing logs directly to services such as
    Elasticsearch.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd GitHub 仓库包括预定义的 DaemonSet 配置。为了适应操作系统差异以及将日志直接路由到如 Elasticsearch 等服务的可能性，预构建镜像中也提供了替代的
    Fluentd 配置。
- en: Kubernetes configurations such as minikube are complex, with levels of indirection
    through symbolic links making it difficult to determine which files are the real
    logs if we want to monitor.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 配置，如 minikube，相当复杂，通过符号链接的间接层次使得在想要监控的情况下确定哪些文件是真实日志变得困难。
- en: Using the power of Kubernetes’s ConfigMaps, it is possible to tailor or extend
    the out-of-the-box Fluentd configuration. So, a prebuilt Fluentd Docker image
    will capture log events and send them to a different Fluentd node.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用 Kubernetes 的 ConfigMaps 功能，可以定制或扩展开箱即用的 Fluentd 配置。因此，预构建的 Fluentd Docker
    镜像可以捕获日志事件并将它们发送到不同的 Fluentd 节点。
