- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序言
- en: The written word is a powerful thing. The ancient Sumerians invented the first
    written language, and the introduction of the Gutenberg press allowed the written
    word to spread knowledge and enlightenment across the world. Language is in fact
    so important to human thinking that anthropologists claim that our ability for
    complex reasoning evolved at the same time that we developed language. Language
    represented in the form of text captures most of human thought, deeds, and actions,
    and our life is increasingly dominated by it. We communicate with colleagues through
    emails, with friends and family via messengers, and with others who share our
    passions using social media tools. Leaders inspire huge populations through speeches
    (and tweets) that are recorded as text, leading researchers communicate their
    findings via published research papers, and companies communicate their health
    through quarterly reports. Even this book uses text to spread knowledge. Analyzing
    and understanding text gives us the ability to gain knowledge and make decisions.
    Text analytics is about writing computer programs that can analyze vast amounts
    of information available in the form of text. Before making a product purchase
    or visiting a restaurant, we read customer reviews. A company could then use the
    same reviews to improve their product or service. A publisher could analyze discussions
    on the internet to estimate the demand for a certain programming language before
    commissioning a book on it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 书面文字是一种强大的东西。古苏美尔人发明了第一种书面语言，古腾堡印刷术的引入使书面文字传播知识和启蒙思想到全世界。语言对人类思维如此重要，以至于人类学家声称我们复杂推理能力的发展与语言同时发展。以文本形式呈现的语言捕捉了大多数人类思想、行为和行动，我们的生活日益被其主导。我们通过电子邮件与同事交流，通过通讯工具与朋友和家人联系，通过社交媒体工具与分享我们热情的其他人交流。领导人通过演讲（和推文）激励着大批人群，这些演讲被记录为文本，领先的研究人员通过发表的研究论文传达其发现，公司通过季度报告传达其健康状况。即使这本书也使用文本传播知识。分析和理解文本赋予我们获取知识和做出决策的能力。文本分析是关于编写能够分析大量以文本形式存在的信息的计算机程序。在购买产品或访问餐馆之前，我们会阅读客户评论。然后公司可以利用同样的评论来改进其产品或服务。出版商可以分析互联网上的讨论，以估算在委托书籍之前对某种编程语言的需求。
- en: It is much harder for a computer to understand text compared to other types
    of data. While there are rules of grammar and guidelines to forming sentences,
    these are often not strictly followed and depend heavily on context. Even with
    the correct grammar, it is hard for a machine to interpret the text correctly.
    The words that a person chooses while tweeting would be quite different from writing
    an email to express the same thought. There have been recent advances in statistical
    techniques and machine learning algorithms that allow us to get past many of these
    obstacles to derive value from text data. New models are able to capture the semantic
    meaning of text better than previous approaches based on word frequencies alone.
    But there are also many business tasks where these simple models perform surprisingly
    well.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 对于计算机来说，理解文本相比其他类型的数据要困难得多。虽然有语法规则和句子构成的指导，但这些规则通常不严格遵循，而且严重依赖上下文。即使语法正确，机器也很难正确解释文本。一个人在发布推文时选择的词语可能与写邮件表达相同的思想时大不相同。近年来，统计技术和机器学习算法取得了重大进展，使我们能够克服许多这些障碍，从文本数据中获取价值。新模型能够比仅基于词频的先前方法更好地捕捉文本的语义意义。但也有许多业务任务，这些简单模型表现出令人惊讶的良好性能。
- en: In one of our client projects, for example, a home appliance manufacturer was
    able to understand the key topics affecting customer purchases by analyzing product
    reviews and adjust their marketing message to focus on these aspects. In another
    case, an e-commerce retailer used a deep neural network to classify customer queries
    and route them to the correct department for faster resolution. Analyzing abstracts
    from scientific journals has allowed an R&D company to detect trends in new materials
    and adjust their research accordingly. A fashion company identified mega-topics
    in their customer group by taking a look at posts in social networks. With this
    book we have tried to transfer our experiences from these and many other projects
    into blueprints that you can easily reuse in your own projects.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在我们的一个客户项目中，一家家电制造商通过分析产品评论，能够理解影响客户购买的关键主题，并调整其营销信息以便专注于这些方面。在另一个案例中，一家电子商务零售商使用深度神经网络来分类客户查询，并将其路由到正确的部门以实现更快的解决方案。分析科学期刊摘要使一家研发公司能够检测新材料的趋势，并相应调整其研究。一家时尚公司通过查看社交网络中的帖子，确定了其客户群体中的超级主题。通过本书，我们试图将我们在这些以及许多其他项目中的经验转化为您可以轻松在自己项目中重复使用的蓝图。
- en: Approach of the Book
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 书籍的方法
- en: This book is intended to support data scientists and developers so they can
    quickly enter the area of text analytics and natural language processing. Thus,
    we put the focus on developing practical solutions that can serve as blueprints
    in your daily business. A blueprint, in our definition, is a best-practice solution
    for a common problem. It is a template that you can easily copy and adapt for
    reuse. For these blueprints we use production-ready Python frameworks for data
    analysis, natural language processing, and machine learning. Nevertheless, we
    also introduce the underlying models and algorithms.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在支持数据科学家和开发人员，使其能够快速进入文本分析和自然语言处理领域。因此，我们重点放在开发实用解决方案上，这些解决方案可以作为您日常业务中的蓝图。在我们的定义中，蓝图是常见问题的最佳实践解决方案。这是一个模板，您可以轻松复制并适应以供重复使用。对于这些蓝图，我们使用了生产就绪的
    Python 框架进行数据分析、自然语言处理和机器学习。尽管如此，我们也介绍了底层的模型和算法。
- en: We do not expect any previous knowledge in the field of natural language processing
    but provide you with the necessary background knowledge to get started quickly.
    In each chapter, we explain and discuss different solution approaches for the
    respective tasks with their potential strengths and weaknesses. Thus, you will
    not only acquire the knowledge about how to solve a certain kind of problem but
    also get a set of ready-to-use blueprints that you can take and customize to your
    data and requirements.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不要求您在自然语言处理领域有任何先前知识，但会为您提供快速入门所需的背景知识。在每章中，我们解释并讨论了不同的解决方案方法及其潜在优缺点。因此，您不仅会获得解决特定问题的知识，还会得到一组可立即使用并根据自己数据和需求进行定制的蓝图。
- en: Each of the 13 chapters includes a self-contained use case for a specific aspect
    of text analytics (see [Table P-1](#preface_approach_table)). Based on an example
    dataset, we develop and explain the blueprints step by step.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 每个包含在 13 章中的用例都涵盖了文本分析特定方面的自包含应用（见[表 P-1](#preface_approach_table)）。基于示例数据集，我们逐步开发和解释这些蓝图。
- en: Table P-1\. Overview of the chapters
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Table P-1\. 章节概述
- en: '| Chapter | Dataset | Libraries |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 章节 | 数据集 | 库 |'
- en: '| --- | --- | --- |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| [Chapter 1, *Gaining Early Insights from Textual Data*](ch01.xhtml#ch-exploration)Getting
    started with the statistical exploration of textual data | UN General Debates
    | Pandas, Regex |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| [第 1 章，*从文本数据中获取早期洞见*](ch01.xhtml#ch-exploration)开始统计探索文本数据 | 联合国大会辩论 | Pandas,
    Regex |'
- en: '| [Chapter 2, *Extracting Textual Insights with APIs*](ch02.xhtml#ch-api)Using
    different Python modules to extract data from popular APIs | GitHub, Twitter,
    and Wikipedia API | Requests, Tweepy |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| [第 2 章，*使用 API 提取文本洞见*](ch02.xhtml#ch-api)使用不同的 Python 模块从流行的 API 提取数据 |
    GitHub、Twitter 和 Wikipedia API | Requests, Tweepy |'
- en: '| [Chapter 3, *Scraping Websites and Extracting Data*](ch03.xhtml#ch-scraping)Using
    Python libraries to download web pages and extract content | Reuters website |
    Requests, Beautiful Soup, Readability-lxml, Scrapy |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| [第 3 章，*网页抓取和数据提取*](ch03.xhtml#ch-scraping)使用 Python 库下载网页并提取内容 | Reuters
    网站 | Requests, Beautiful Soup, Readability-lxml, Scrapy |'
- en: '| [Chapter 4, *Preparing Textual Data for Statistics and Machine Learning*](ch04.xhtml#ch-preparation)Introduction
    to data cleaning and linguistic processing | Reddit Selfposts | Regex, spaCy |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| [第 4 章，*为统计和机器学习准备文本数据*](ch04.xhtml#ch-preparation)数据清洗和语言处理简介 | Reddit 自发布帖子
    | Regex, spaCy |'
- en: '| [Chapter 5, *Feature Engineering and Syntactic Similarity*](ch05.xhtml#ch-vectorization)Introduction
    to features and vectorization | 1 million headlines from ABC News | scikit-learn,
    NumPy |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| [第 5 章，*特征工程和句法相似性*](ch05.xhtml#ch-vectorization)特征和向量化简介 | ABC 新闻的 100 万条头条新闻
    | scikit-learn, NumPy |'
- en: '| [Chapter 6, *Text Classification Algorithms*](ch06.xhtml#ch-classification).
    Text Classification AlgorithmsUsing machine learning algorithms to classify software
    bugs | Java Development Tools bug reports | scikit-learn |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| [第 6 章，*文本分类算法*](ch06.xhtml#ch-classification)文本分类算法使用机器学习算法对软件 Bug 进行分类
    | Java 开发工具的 Bug 报告 | scikit-learn |'
- en: '| [Chapter 7, *How to Explain a Text Classifier*](ch07.xhtml#ch-explain)Explaining
    models and classification results | Java Development Tools bug reports | scikit-learn,
    Lime, Anchor, ELI5 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| [第 7 章，*如何解释文本分类器*](ch07.xhtml#ch-explain)解释模型和分类结果 | Java 开发工具的 Bug 报告 |
    scikit-learn, Lime, Anchor, ELI5 |'
- en: '| [Chapter 8, *Unsupervised Methods: Topic Modeling and Clustering*](ch08.xhtml#ch-topicmodels)Using
    unsupervised methods to gain unbiased insights into text | UN General Debates
    | scikit-learn, Gensim |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| [第 8 章，*无监督方法：主题建模和聚类*](ch08.xhtml#ch-topicmodels)使用无监督方法获取文本的无偏见洞见 | 联合国大会辩论
    | scikit-learn, Gensim |'
- en: '| [Chapter 9, *Text Summarization*](ch09.xhtml#ch-summarization)Creating short
    summaries of news articles and forum threads using rule-based and machine learning
    approaches | Reuters News articles, Travel Forum threads | Sumy, scikit-learn
    |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| [第 9 章，*文本摘要*](ch09.xhtml#ch-summarization)使用基于规则和机器学习方法创建新闻文章和论坛帖子的简短摘要
    | 路透社新闻文章、旅行论坛帖子 | Sumy, scikit-learn |'
- en: '| [Chapter 10, *Exploring Semantic Relationships with Word Embeddings*](ch10.xhtml#ch-embeddings)Using
    word embeddings to explore and visualize semantic similarities in a specific data
    set | Reddit Selfposts | Gensim |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| [第 10 章，*使用词嵌入探索语义关系*](ch10.xhtml#ch-embeddings)使用词嵌入探索和可视化特定数据集中的语义相似性 |
    Reddit 自发布帖子 | Gensim |'
- en: '| [Chapter 11, *Performing Sentiment Analysis on Text Data*](ch11.xhtml#ch-sentiment)Identifying
    customer sentiment in Amazon product reviews | Amazon product reviews | Transformers,
    scikit-learn, NLTK |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| [第 11 章，*对文本数据进行情感分析*](ch11.xhtml#ch-sentiment)在亚马逊产品评论中识别客户情感 | 亚马逊产品评论
    | Transformers, scikit-learn, NLTK |'
- en: '| [Chapter 12, *Building a Knowledge Graph*](ch12.xhtml#ch-knowledge)How to
    extract named entities and their relationships using pretrained models and custom
    rules | Reuters news on mergers and acquisitions | spaCy |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| [第 12 章，*构建知识图谱*](ch12.xhtml#ch-knowledge)使用预训练模型和自定义规则提取命名实体及其关系 | 路透社有关并购的新闻
    | spaCy |'
- en: '| [Chapter 13, *Using Text Analytics in Production*](ch13.xhtml#ch-production)Deploy
    and scale the sentiment analysis blueprint as an API on Google Cloud Platform
    |  | FastAPI, Docker, conda, Kubernetes, gcloud |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| [第 13 章，*在生产环境中使用文本分析*](ch13.xhtml#ch-production)将情感分析蓝图部署为 Google Cloud
    平台上的 API 并进行扩展 |  | FastAPI, Docker, conda, Kubernetes, gcloud |'
- en: The choice of topics reflects the most common types of problems in our daily
    text analytics work. Typical tasks include data acquisition, statistical data
    exploration, and the use of supervised and unsupervised machine learning. The
    business questions range from content analysis (“What are people talking about?”)
    to automatic text categorization.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 选题反映了日常文本分析工作中最常见的问题类型。典型任务包括数据获取、统计数据探索以及监督和无监督机器学习的使用。业务问题涵盖内容分析（“人们在谈论什么？”）到自动文本分类。
- en: Prerequisites
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 先决条件
- en: In this book you will learn how to solve text analytics problems efficiently
    with the Python ecosystem. We will explain all concepts specific to text analytics
    and machine learning in detail but assume that you already have basic knowledge
    of Python, including fundamental libraries like Pandas. You should also be familiar
    with Jupyter notebooks so that you can experiment with the code while reading
    the book. If not, check out the tutorials on [*learnpython.org*](https://www.learnpython.org/),
    [*docs.python.org*](https://docs.python.org/3/tutorial), or [DataCamp](https://oreil.ly/oB-eH).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将教会您如何在Python生态系统中高效解决文本分析问题。我们将详细解释文本分析和机器学习的所有概念，但假设您已经掌握了Python的基本知识，包括像Pandas这样的基础库。您还应该熟悉Jupyter笔记本，以便在阅读本书时进行代码实验。如果还不熟悉，请参考[*learnpython.org*](https://www.learnpython.org/)、[*docs.python.org*](https://docs.python.org/3/tutorial)或[DataCamp](https://oreil.ly/oB-eH)上的教程。
- en: Even though we explain the general ideas of the algorithms used, we won’t go
    too much into the details. You should be able to follow the examples and reuse
    the code without completely understanding the mathematics behind it. College-level
    knowledge of linear algebra and statistics is helpful, though.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们解释了所使用算法的一般思想，我们不会深入细节。您应该能够按照示例进行操作并重复使用代码，而无需完全理解其背后的数学原理。尽管如此，具备大学水平的线性代数和统计知识会有所帮助。
- en: Some Important Libraries to Know
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一些重要的库
- en: Every data analytics project starts with data exploration and data processing.
    The most popular Python library for those tasks is definitely [*Pandas*](https://pandas.pydata.org).
    It offers rich functionality to access, transform, analyze, and visualize data.
    If you have never worked with this framework, we recommend checking out the official
    introduction, [*10 minutes to Pandas*](https://oreil.ly/eWlId), or one of the
    other free tutorials available on the internet before reading the book.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据分析项目都始于数据探索和数据处理。最受欢迎的Python库之一是[*Pandas*](https://pandas.pydata.org)。它提供丰富的功能来访问、转换、分析和可视化数据。如果您以前没有使用过这个框架，我们建议先查看官方介绍，[*10
    minutes to Pandas*](https://oreil.ly/eWlId)，或者其他免费的在线教程。
- en: For years, [*scikit-learn*](https://scikit-learn.org) has been the machine learning
    toolkit for Python. It implements a large variety of supervised and unsupervised
    machine learning algorithms as well as many functions for data preprocessing.
    We use scikit-learn in several of the chapters to transform text into numerical
    vectors and for text classification.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，[*scikit-learn*](https://scikit-learn.org)一直是Python的机器学习工具包。它实现了大量的监督和无监督机器学习算法，以及许多用于数据预处理的函数。我们在几章中使用scikit-learn来将文本转换为数值向量，并进行文本分类。
- en: When it comes to deep neural models, however, frameworks like PyTorch or TensorFlow
    are clearly superior to scikit-learn. Instead of using those libraries directly,
    we use the [*Transformers library*](https://oreil.ly/f5Ped) from Hugging Face
    in [Chapter 11](ch11.xhtml#ch-sentiment) for sentiment analysis. Since the publication
    of BERT,^([1](preface01.xhtml#idm45634210878232)) transformer-based models outperform
    previous approaches on tasks that require an understanding of the meaning of text,
    and the Transformers library provides easy access to many pretrained models.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当涉及到深度神经模型时，像PyTorch或TensorFlow这样的框架明显优于scikit-learn。我们在[第11章](ch11.xhtml#ch-sentiment)中用来进行情感分析的是来自Hugging
    Face的[*Transformers library*](https://oreil.ly/f5Ped)。自BERT发布以来，基于transformer的模型在需要理解文本含义的任务上表现优异，而Transformers库提供了方便访问多个预训练模型的途径。
- en: Our favorite library for natural language processing is *spaCy*. Since its first
    release in 2016, spaCy enjoys a constantly growing user base. Though open source,
    it is primarily developed by the company [Explosion](https://explosion.ai). Pretrained
    neural language models for part-of-speech tagging, dependency parsing, and named-entity
    recognition are available for many languages. We used spaCy version 2.3.2 for
    the development of this book, especially for data preparation ([Chapter 4](ch04.xhtml#ch-preparation))
    and knowledge extraction ([Chapter 12](ch12.xhtml#ch-knowledge)). At the time
    of publication, spaCy 3.0 will be out with completely new, transformer-based models,
    support for custom models in PyTorch and TensorFlow, and templates for defining
    end-to-end workflows.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最喜欢的自然语言处理库是*spaCy*。自2016年首次发布以来，spaCy拥有不断增长的用户群。尽管是开源的，但它主要由[Explosion](https://explosion.ai)公司开发。对于许多语言，可以使用预训练的神经语言模型进行词性标注、依赖解析和命名实体识别。我们在书的编写过程中使用了spaCy
    2.3.2，特别是用于数据准备（[第4章](ch04.xhtml#ch-preparation)）和知识提取（[第12章](ch12.xhtml#ch-knowledge)）。在出版时，spaCy
    3.0将推出全新的基于Transformer的模型，支持PyTorch和TensorFlow的自定义模型以及定义端到端工作流程的模板。
- en: Another NLP library we use is [Gensim](https://oreil.ly/YJ4Pz), which is maintained
    by Radim Řehůřek. Gensim puts the focus on semantic analysis and provides all
    that is necessary to learn topic models ([Chapter 8](ch08.xhtml#ch-topicmodels))
    and word embeddings ([Chapter 10](ch10.xhtml#ch-embeddings)).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的另一个NLP库是[Gensim](https://oreil.ly/YJ4Pz)，由Radim Řehůřek维护。Gensim侧重于语义分析，并提供了学习主题模型（[第8章](ch08.xhtml#ch-topicmodels)）和词嵌入（[第10章](ch10.xhtml#ch-embeddings)）所需的一切。
- en: There are many other libraries for natural language processing that can be helpful
    but are not or only briefly mentioned in the book. These include NLTK (feature-rich
    grandfather of Python NLP libraries), TextBlob (easy to get started), Stanford’s
    Stanza and CoreNLP, as well as Flair (state-of-the-art models for advanced tasks).
    Our goal was not to give an overview on everything that’s out there but to choose
    and explain those libraries that worked best in our projects.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书只简要提及了一些自然语言处理的其他库，这些库可能对您有所帮助。这些包括NLTK（Python NLP库的功能丰富的前辈）、TextBlob（易于上手）、Stanford的Stanza和CoreNLP，以及Flair（用于高级任务的最新模型）。我们的目标不是对所有现有的内容进行概述，而是选择和解释在我们项目中表现最佳的那些库。
- en: Books to Read
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可与本书并读的书籍
- en: 'As we focus on practical solutions for our use cases, you might want to check
    out some additional books for further details or topics we did not cover. Below
    you will find some recommendations for books to read alongside this one:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们专注于实际解决方案，您可能希望查阅一些额外的书籍以获取更多详细信息或我们未涵盖的主题。以下是一些建议，可与本书并读：
- en: '[*Practical Natural Language Processing*](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/)
    by Sowmya Vajjala, Bodhisattwa Majumder, Anuj Gupta, and Harshit Surana (O’Reilly,
    2020), ISBN 978-1-492-05405-4.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*实用自然语言处理*,](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/)，Sowmya
    Vajjala，Bodhisattwa Majumder，Anuj Gupta和Harshit Surana（O''Reilly，2020），ISBN 978-1-492-05405-4。'
- en: '[*Natural Language Processing in Action*](https://www.oreilly.com/library/view/natural-language-processing/9781617294631/)
    by Hobson Lane, Cole Howard, and Hannes Hapke (Manning Publications, 2019), ISBN
    978-1-617-29463-1.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*动手学自然语言处理*](https://www.oreilly.com/library/view/natural-language-processing/9781617294631/)，Hobson
    Lane，Cole Howard和Hannes Hapke（Manning Publications，2019），ISBN 978-1-617-29463-1。'
- en: '[*Mining the Social Web*, 3rd Edition](https://www.oreilly.com/library/view/mining-the-social/9781491973547/)
    by Matthew A. Russell and Mikhail Klassen (O’Reilly, 2019), ISBN 978-1-491-98504-5.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*挖掘社交网络*, 第3版](https://www.oreilly.com/library/view/mining-the-social/9781491973547/)，Matthew
    A. Russell和Mikhail Klassen（O''Reilly，2019），ISBN 978-1-491-98504-5。'
- en: '[*Applied Text Analysis with Python*](https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/)
    by Benjamin Bengfort, Rebecca Bilbro, and Tony Ojeda (O’Reilly 2018), ISBN 978-1-491-96304-3.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*Python文本分析实战*,](https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/)，Benjamin
    Bengfort，Rebecca Bilbro和Tony Ojeda（O''Reilly 2018），ISBN 978-1-491-96304-3。'
- en: '[*Python for Data Analysis*, 2nd Edition](https://www.oreilly.com/library/view/python-for-data/9781491957653/)
    by Wes McKinney (O’Reilly, 2017), ISBN 978-1-491-95766-0.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*Python数据分析*, 第2版](https://www.oreilly.com/library/view/python-for-data/9781491957653/)，Wes
    McKinney（O''Reilly，2017），ISBN 978-1-491-95766-0。'
- en: Conventions Used in This Book
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书使用的约定
- en: 'The following typographical conventions are used in this book:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用以下排版约定：
- en: '*Italic*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*斜体*'
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 指示新术语、URL、电子邮件地址、文件名和文件扩展名。
- en: '`Constant width`'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`常量宽度`'
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 用于程序清单，以及在段落内引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。
- en: '**`Constant width bold`**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**`常量宽度粗体`**'
- en: Shows commands or other text that should be typed literally by the user.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 显示用户应直接输入的命令或其他文本。
- en: '*`Constant width italic`*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*`常量宽度斜体`*'
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 显示应由用户提供的值或由上下文确定的值替换的文本。
- en: Tip
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: This element signifies a tip or suggestion.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示提示或建议。
- en: Note
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This element signifies a general note.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示一般注释。
- en: Warning
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: This element indicates a warning or caution.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素指示警告或注意。
- en: Note
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This element indicates a blueprint.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素指示蓝图。
- en: Using Code Examples
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用代码示例
- en: The whole purpose of a blueprint is to be copied. Thus, we provide all the code
    developed in this book in our [GitHub repository](https://oreil.ly/btap-code).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 蓝图的整个目的是被复制。因此，我们在我们的[GitHub存储库](https://oreil.ly/btap-code)中提供了本书中开发的所有代码。
- en: For each chapter, you will find an executable Jupyter notebook with the code
    from the book and possibly some additional functions or blueprints that have been
    omitted. The repository also contains the necessary datasets and some additional
    information.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 每章您将找到一个可执行的Jupyter笔记本，其中包含书中的代码以及可能省略的一些附加函数或蓝图。该存储库还包含必要的数据集和一些额外信息。
- en: The easiest way to run the notebooks is on [Google Colab](https://oreil.ly/colab),
    Google’s public cloud platform for machine learning. You don’t even have to install
    Python on your local computer; just click on the Colab link for the respective
    chapter on GitHub (Google account required). However, we also added instructions
    for setting up your own (virtual) Python environment in the GitHub repository.
    We designed the Jupyter notebooks in a way that allows you to run them both locally
    and on Google Colab.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 运行笔记本的最简单方法是在[Google Colab](https://oreil.ly/colab)，Google的公共云平台上。您甚至不需要在本地计算机上安装Python；只需单击GitHub上相应章节的Colab链接（需要Google帐号）。但是，我们还添加了在GitHub存储库中设置自己（虚拟）Python环境的说明。我们设计了Jupyter笔记本，使您可以在本地和Google
    Colab上运行它们。
- en: Libraries, data, and websites are subject to continuous change. Therefore, it
    can easily happen that the verbatim code in the book will not run properly in
    the future. To overcome this, we will keep the repository up to date. If you discover
    any technical problems or have recommendations on how to improve the code, do
    not hesitate to create an issue in the repository or send us a pull request.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 库、数据和网站可能会不断变化。因此，书中的逐字代码可能在将来无法正确运行。为了解决这个问题，我们将保持存储库的更新。如果您发现任何技术问题或有改进代码的建议，请毫不犹豫地在存储库中创建问题或发送拉取请求。
- en: If you have a technical question or a problem using the code examples, please
    email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com). In the
    case of technical problems, we recommend [creating an issue in the GitHub repo](https://oreil.ly/ApUgF)
    and refer to O’Reilly’s errata page for errors in the book.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有技术问题或在使用代码示例时遇到问题，请发送电子邮件至[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)。对于技术问题，我们建议[在GitHub存储库中创建问题](https://oreil.ly/ApUgF)，并参考O'Reilly的勘误页面了解书中的错误。
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing examples
    from O’Reilly books does require permission. Answering a question by citing this
    book and quoting example code does not require permission. Incorporating a significant
    amount of example code from this book into your product’s documentation does require
    permission.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在帮助您完成工作。通常，如果本书提供示例代码，您可以在自己的程序和文档中使用它。除非您复制了代码的大部分，否则无需征得我们的许可。例如，编写使用本书多个代码片段的程序无需许可。销售或分发奥莱利书籍的示例需要许可。引用本书并引用示例代码来回答问题无需许可。将本书的大量示例代码整合到产品文档中需要许可。
- en: 'You may use our code freely in your own projects without asking for permission.
    Especially if you publicly republish our code, we appreciate attribution. An attribution
    usually includes the title, author, publisher, and ISBN. For example: “*Blueprints
    for Text Analytics Using Python* by Jens Albrecht, Sidharth Ramachandran, and
    Christian Winkler (O’Reilly, 2021), 978-1-492-07408-3.”'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在自己的项目中自由使用我们的代码，无需征得许可。特别是如果您公开重新发布我们的代码，我们感谢您的署名。署名通常包括标题、作者、出版商和ISBN。例如：“*Python文本分析的蓝图*，作者Jens
    Albrecht、Sidharth Ramachandran和Christian Winkler（O’Reilly，2021），ISBN 978-1-492-07408-3。”
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您认为您使用的示例代码超出了公平使用范围或上述许可，请随时通过[*permissions@oreilly.com*](mailto:permissions@oreilly.com)与我们联系。
- en: O’Reilly Online Learning
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奥莱利在线学习
- en: Note
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For more than 40 years, [*O’Reilly Media*](http://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 40多年来，[*奥莱利媒体*](http://oreilly.com)为企业提供技术和商业培训、知识和洞察力，帮助公司取得成功。
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*http://oreilly.com*](http://oreilly.com).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们独特的专家和创新者网络通过书籍、文章和我们的在线学习平台分享他们的知识和专业知识。奥莱利的在线学习平台为您提供按需访问的实时培训课程、深度学习路径、交互式编码环境以及来自奥莱利和其他200多家出版商的大量文本和视频。欲了解更多信息，请访问[*http://oreilly.com*](http://oreilly.com)。
- en: How to Contact Us
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何联系我们
- en: 'Please address comments and questions concerning this book to the publisher:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请将有关本书的评论和问题发送给出版商：
- en: O’Reilly Media, Inc.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奥莱利媒体公司
- en: 1005 Gravenstein Highway North
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1005 Gravenstein Highway North
- en: Sebastopol, CA 95472
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加利福尼亚州塞巴斯托波尔95472
- en: 800-998-9938 (in the United States or Canada)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 800-998-9938（美国或加拿大）
- en: 707-829-0515 (international or local)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0515（国际或本地）
- en: 707-829-0104 (fax)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0104（传真）
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/text-analytics-with-python*](https://oreil.ly/text-analytics-with-python).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为本书制作了一个网页，列出勘误、示例和任何额外信息。您可以访问[*https://oreil.ly/text-analytics-with-python*](https://oreil.ly/text-analytics-with-python)获取此页面。
- en: Email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com) to comment
    or ask technical questions about this book.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 发送电子邮件至[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)以评论或询问有关本书的技术问题。
- en: For news and information about our books and courses, visit [*http://oreilly.com*](http://oreilly.com).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 获取关于我们的书籍和课程的新闻和信息，请访问[*http://oreilly.com*](http://oreilly.com)。
- en: 'Find us on Facebook: [*http://facebook.com/oreilly*](http://facebook.com/oreilly)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在Facebook上找到我们：[*http://facebook.com/oreilly*](http://facebook.com/oreilly)
- en: 'Follow us on Twitter: [*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在Twitter上关注我们：[*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)
- en: 'Watch us on YouTube: [*http://youtube.com/oreillymedia*](http://youtube.com/oreillymedia)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 观看我们在YouTube上的视频：[*http://youtube.com/oreillymedia*](http://youtube.com/oreillymedia)
- en: Acknowledgments
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: Writing a book is a challenge, not only for the authors but also for their families
    and friends. All of us expected that it would take a lot of time, but still we
    were surprised by how much time we needed to develop the stories for each of the
    chapters. As we are all working full-time jobs, the time for discussing, coding,
    writing, and rewriting had to be taken from our families.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 写一本书对于作者来说是一种挑战，对于他们的家人和朋友们也是如此。我们所有人都预料到这需要很多时间，但我们仍然对为每个章节开发故事所需的时间感到惊讶。由于我们都全职工作，因此讨论、编码、写作和重写的时间不得不从我们的家庭中抽取。
- en: Working with O’Reilly has been a great pleasure for all of us. From the original
    proposal, during the time of writing, and in the production phase, we enjoyed
    working with professionals and immensely benefited from their hints and suggestions.
    The most intense time for us was writing the individual chapters. During that,
    we were perfectly supported by our development editor, Amelia Blevins. Without
    her help and improvements, the book would have been stuck in a less-readable state.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 与O’Reilly合作对我们来说是一种极大的愉悦。从最初的提议到写作期间，再到生产阶段，我们都享受与专业人士合作，并且从他们的提示和建议中受益匪浅。对我们来说最紧张的时期是撰写各章节的时候。在那段时间里，我们得到了我们的开发编辑Amelia
    Blevins的完美支持。如果没有她的帮助和改进，这本书可能会一直停留在不易阅读的状态。
- en: We would also like to express our gratitude to our reviewers, Oliver Zeigermann,
    Benjamin Bock, Alexander Schneider, and Darren Cook. They used their expertise
    and a lot of their time to make excellent suggestions and improvements and also
    to find errors in the text and the notebooks.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还要感谢我们的审阅人员Oliver Zeigermann、Benjamin Bock、Alexander Schneider和Darren Cook。他们利用他们的专业知识和大量时间提出了卓越的建议和改进，并且找出了文本和笔记本中的错误。
- en: As we used state-of-the-art features of libraries, we sometimes encountered
    problems or incompatibilities. With spaCy as a central component in our analytics
    pipeline, working with the super responsive team from Explosion (Ines Montani,
    Sofie Van Landeghem, and Adriane Boyd) was a great pleasure. Their comments on
    the sections covering spaCy have been extremely helpful. Thanks also to Burton
    DeWilde, the developer behind textacy, for checking parts of the code.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用库的最新功能时，有时会遇到问题或不兼容性。作为我们分析流水线中的核心组件，与Explosion团队（Ines Montani、Sofie Van
    Landeghem和Adriane Boyd）的合作非常愉快。他们对涵盖spaCy的章节的评论非常有帮助。同样感谢textacy的开发者Burton DeWilde检查代码的部分。
- en: '^([1](preface01.xhtml#idm45634210878232-marker)) Devlin, Jacob, et al., “BERT:
    Pre-training of Deep Bidirectional Transformers for Language Understanding.” 2018\.
    [*https://arxiv.org/abs/1810.04805*](https://arxiv.org/abs/1810.04805).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '^([1](preface01.xhtml#idm45634210878232-marker)) Devlin, Jacob, et al., “BERT:
    Pre-training of Deep Bidirectional Transformers for Language Understanding.” 2018\.
    [*https://arxiv.org/abs/1810.04805*](https://arxiv.org/abs/1810.04805).'
