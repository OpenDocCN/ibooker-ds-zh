- en: 9 Wrapping up
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 总结
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Important takeaways from this book
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书的重要要点
- en: Open source toolkits and commercial platforms for AutoML
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoML 的开源工具包和商业平台
- en: The challenges and future of AutoML
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoML 的挑战和未来
- en: Resources for learning more and working in the field
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习更多和在该领域工作的资源
- en: We’ve almost reached the end of the book. This last chapter reviews the core
    concepts we’ve covered, while also aiming to expand your horizons. We’ll start
    with a quick recap of what you should take away from this book. Next, we’ll present
    an overview of some popular AutoML tools (both open source and commercial) outside
    the Keras ecosystem. An awareness of other emblematic toolkits in the current
    AutoML community will enable you to explore further based on your interests after
    reading the book. Finally, we offer some speculative thoughts about the core challenges
    and future evolution in the AutoML domain, which will be of particular interest
    if you’d like to delve into more fundamental research in this area. Understanding
    AutoML is a journey, and finishing this book is merely the first step. At the
    end of the chapter, we’ll provide you with a short list of resources and strategies
    for learning more about AutoML and staying up-to-date with the latest developments
    in the field.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎到达了本书的结尾。最后一章回顾了我们所涵盖的核心概念，同时旨在拓宽你的视野。我们将从快速回顾你应该从本书中汲取的内容开始。接下来，我们将概述一些流行的
    AutoML 工具（包括开源和商业），这些工具位于 Keras 生态系统之外。了解当前 AutoML 社区中的其他标志性工具包将使你能够在阅读本书后根据你的兴趣进一步探索。最后，我们提供了一些关于
    AutoML 领域的核心挑战和未来演变的推测性思考，这对于那些想要深入研究该领域基本研究的人来说将特别有趣。理解 AutoML 是一段旅程，完成本书只是第一步。在本章末尾，我们将为你提供一份关于学习更多
    AutoML 和了解该领域最新发展的资源和方法简短列表。
- en: 9.1 Key concepts in review
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 复习关键概念
- en: This section briefly summarizes the key takeaways from this book, to refresh
    your memory of what you’ve learned so far.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本节简要总结了本书的关键要点，以刷新你对所学内容的记忆。
- en: 9.1.1 The AutoML process and its key components
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 AutoML 流程及其关键组件
- en: AutoML allows a machine to mimic how humans design, tune, and apply ML algorithms
    so that we can adopt ML more easily. It aims to discover optimal machine learning
    solutions automatically when given an ML problem, thereby releasing data scientists
    from the burden of manual tuning and giving practitioners without extensive experience
    access to off-the-shelf machine learning techniques (see figure 9.1).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML 允许机器模仿人类设计、调整和应用机器学习算法的方式，以便我们更容易地采用机器学习。它旨在在给定机器学习问题时自动发现最佳机器学习解决方案，从而释放数据科学家手动调整的负担，并使没有丰富经验的专业人士能够访问现成的机器学习技术（见图
    9.1）。
- en: '![09-01](../Images/09-01.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![09-01](../Images/09-01.png)'
- en: Figure 9.1 ML versus AutoML
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 机器学习与 AutoML 对比
- en: 'The process of AutoML is an iterative one, typically consisting of three steps
    (figure 9.2):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML 的过程是迭代的，通常包括三个步骤（见图 9.2）：
- en: Select an ML pipeline from the search space for observation based on the search
    strategy. The search space defines the set of hyperparameters we want to tune
    and the ranges of each hyperparameter from which to select. The search strategy
    explores the search space and selects a combination of hyperparameters in each
    iteration to instantiate a complete ML pipeline to be evaluated.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据搜索策略从搜索空间中选择一个机器学习流程进行观察。搜索空间定义了我们想要调整的超参数集合以及每个超参数的取值范围。搜索策略探索搜索空间，并在每次迭代中选择一组超参数以实例化一个待评估的完整机器学习流程。
- en: Train the selected ML pipeline on the training dataset and retrieve its performance
    evaluated on the validation set.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据集上训练所选的机器学习流程，并检索其在验证集上评估的性能。
- en: Update the search strategy if it is able to leverage the historical evaluations
    to accelerate the process of discovering better pipelines.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果搜索策略能够利用历史评估来加速发现更好流程的过程，则更新搜索策略。
- en: '![09-02](../Images/09-02.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![09-02](../Images/09-02.png)'
- en: Figure 9.2 The search loop of a classic sequential AutoML process
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 经典顺序 AutoML 流程的搜索循环
- en: The three core components of AutoML are, therefore, the search space, the search
    strategy, and the validation process to evaluate and compare the selected pipelines.
    The search space is the part requiring most of your implementation work, whereas
    implementations of the other two are often built-in modules that you can select
    from an AutoML toolkit.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，AutoML的三个核心组件是搜索空间、搜索策略以及用于评估和比较所选管道的验证过程。搜索空间是需要你最多实现工作的部分，而其他两个的实现通常是内置模块，你可以从AutoML工具包中选择。
- en: 9.1.2 The machine learning pipeline
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 机器学习管道
- en: 'As we described in chapter 2, a typical machine learning workflow can be summarized
    as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第2章中描述的，典型的机器学习工作流程可以总结如下：
- en: '*Problem framing and data collection*—Define the goal of the problem, such
    as what kinds of things you want to predict or what kinds of patterns you want
    to extract from the data. Specify what kind of paradigm the problem belongs to,
    such as supervised learning, unsupervised learning, and so on. Identify a way
    to reliably measure the success of your final model, such as the prediction accuracy
    in an image-classification problem. You may need domain-specific metrics in many
    cases. Collect data to help train and evaluate your model.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*问题定义和数据收集*—定义问题的目标，例如你想要预测哪些类型的事物或从数据中提取哪些类型的模式。指定问题所属的范式，例如监督学习、无监督学习等。确定一种可靠地衡量最终模型成功的方法，例如在图像分类问题中的预测准确率。在许多情况下，你可能需要特定领域的指标。收集数据以帮助训练和评估你的模型。'
- en: '*Data preprocessing and feature engineering*—Process the data into a format
    suitable for feeding into an ML algorithm. Remove redundant features, and select
    or generate useful features, if needed, to help improve the performance of the
    algorithm. Think about how you will evaluate your model, and split the data into
    training, validation, and test sets to help with the evaluation process later.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据预处理和特征工程*—将数据处理成适合输入到机器学习算法的格式。移除冗余特征，并在需要的情况下选择或生成有用的特征，以帮助提高算法的性能。考虑你将如何评估你的模型，并将数据分割成训练集、验证集和测试集，以帮助后续的评估过程。'
- en: '*ML algorithm selection*—Select the proper ML algorithm based on your experience
    and prior knowledge of the problem. You may want to try out different ML algorithms
    iteratively and select the best one before applying it on the final test set and
    deploying it.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习算法选择*—根据你的经验和问题先验知识选择合适的机器学习算法。你可能想要迭代尝试不同的机器学习算法，并在将其应用于最终测试集和部署之前选择最佳的一个。'
- en: '*Model training and evaluation*—Apply the ML algorithm to train an ML model,
    and evaluate it on the validation dataset based on your predefined measure.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型训练和评估*—应用机器学习算法训练机器学习模型，并根据你预定义的度量在验证数据集上评估它。'
- en: '*Hyperparameter tuning*—Improve the pipeline to achieve better performance
    by iteratively tuning its hyperparameters. To avoid overfitting, make sure not
    to use the test set to select the ML algorithm and tune the hyperparameters.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*超参数调整*—通过迭代调整其超参数来改进管道以实现更好的性能。为了避免过拟合，确保不要使用测试集来选择机器学习算法和调整超参数。'
- en: '*Service deployment and model monitoring*—Deploy the final ML solution, and
    monitor its performance to continuously maintain and improve the pipeline.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*服务部署和模型监控*—部署最终的机器学习解决方案，并监控其性能以持续维护和改进管道。'
- en: 9.1.3 The taxonomy of AutoML
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.3 AutoML的分类
- en: 'Echoing the ML workflow, we can classify AutoML into the following three categories:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与机器学习工作流程相呼应，我们可以将AutoML分为以下三个类别：
- en: '*Automated feature engineering* often follows an iterative process of feature
    generation and selection. It intends to automatically discover informative and
    discriminative features for learning the best ML models based on predefined selection
    criteria.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动特征工程*通常遵循特征生成和选择的迭代过程。它的目的是自动发现信息丰富且具有区分度的特征，以便根据预定义的选择标准学习最佳的机器学习模型。'
- en: '*Automated hyperparameter tuning* aims to select the optimal hyperparameters
    for one or several components in the ML pipeline. Generally, the tunable hyperparameters
    can include any hyperparameter in the ML pipeline, such as the model type, different
    data preprocessing methods, the hyperparameters of the optimization algorithm,
    and so on.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动超参数调整*旨在为机器学习管道中的一个或多个组件选择最优的超参数。通常，可调整的超参数可以包括机器学习管道中的任何超参数，例如模型类型、不同的数据预处理方法、优化算法的超参数等。'
- en: '*Automated pipeline search* aims to generate the entire ML pipeline based on
    the input data and tasks we tell the AutoML system to perform, such as classification
    or regression.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动流水线搜索*旨在根据我们告诉AutoML系统执行的任务（如分类或回归）和输入数据，生成整个机器学习（ML）流水线。'
- en: In the context of deep learning, we often focus on the last two of these, but
    automated feature engineering is also of great importance (especially for improving
    the performance and learning speed of shallow models).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习的背景下，我们通常关注上述最后两个，但自动特征工程也非常重要（特别是对于提高浅层模型的性能和学习速度）。
- en: 9.1.4 Applications of AutoML
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.4 AutoML的应用
- en: 'AutoML has been applied to the task of designing and tuning ML pipelines for
    a vast array of ML tasks. The main differences in applying AutoML in different
    situations lie in the design of the search space and the evaluation strategy.
    The search space should consist of all the ML pipelines that are applicable to
    the task at hand, such as CNNs for image classification, RNNs for time-series
    data, and so on. Designing a suitable search space for your ML task requires preliminary
    knowledge of task-specific ML models, and such knowledge can help narrow down
    the search scope to obtain better search results. The evaluation strategy should
    be tailored to the application so that it can provide useful measurements to compare
    the ML pipelines. For example, in classification tasks we can use classification
    accuracy as a measure, in recommendation tasks we can use the area under the curve
    (AUC) or normalized discounted cumulative gain (NDCG), and so on. The search methods
    are often applicable without modifications. Some representative AutoML applications
    that have been studied in literature include the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML已被应用于设计调整机器学习（ML）流水线的各种机器学习任务。在不同情况下应用AutoML的主要差异在于搜索空间的设计和评估策略。搜索空间应包括所有适用于当前任务的机器学习流水线，例如用于图像分类的卷积神经网络（CNNs）、用于时间序列数据的循环神经网络（RNNs）等。为您的机器学习任务设计合适的搜索空间需要对该任务特定的机器学习模型有初步的了解，这种知识可以帮助缩小搜索范围以获得更好的搜索结果。评估策略应根据应用进行调整，以便它能提供有用的度量来比较机器学习流水线。例如，在分类任务中，我们可以使用分类准确率作为度量，在推荐任务中，我们可以使用曲线下面积（AUC）或归一化折现累积增益（NDCG）等。搜索方法通常无需修改即可适用。文献中研究的一些代表性AutoML应用包括以下内容：
- en: '*Automated object detection*—Object detection is a classic computer vision
    task that aims to detect objects of a certain class (such as humans, furniture,
    or cars) in images and videos. Automated object detection tries to generate a
    better fusion of multilevel object features and a better detection ML model structure
    to improve the object detection performance.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动目标检测*—目标检测是计算机视觉中的一个经典任务，旨在在图像和视频中检测特定类别的对象（如人类、家具或汽车）。自动目标检测试图生成多级目标特征的更好融合和更好的检测机器学习模型结构，以提高目标检测性能。'
- en: '*Automated semantic segmentation*—Semantic segmentation systems have two essential
    components: multiscale context modules and neural network architectures. The segmentation
    task is sensitive to spatial resolution changes. Thus, AutoML can be used to search
    different structures for every layer with appropriate spatial resolution.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动语义分割*—语义分割系统有两个基本组件：多尺度上下文模块和神经网络架构。分割任务对空间分辨率变化敏感。因此，AutoML可以用来搜索每个层具有适当空间分辨率的不同结构。'
- en: '*Automated generative adversarial networks*—The backbone of a generative adversarial
    network has two components: a generator network and a discriminator network. AutoML
    can be used to search for the optimal network structures for the generator and
    the discriminator.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动生成对抗网络*—生成对抗网络的核心有两个组成部分：生成网络和判别网络。AutoML可以用来搜索生成器和判别器的最佳网络结构。'
- en: '*Automated network compression*—AutoML can search for the optimal combination
    of layer sparsity, number of channels, and bit width for network parameters to
    compress neural networks without a drop in accuracy or latency.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动网络压缩*—自动化机器学习（AutoML）可以搜索网络参数的最佳组合，包括层稀疏性、通道数量和位宽，以压缩神经网络，而不会降低准确度或延迟。'
- en: '*Automated graph neural networks*—AutoML can search for suitable graph convolution
    components for graph neural networks in node classification tasks, such as the
    number of hidden dimensions, the number of attention heads, and various types
    of attention, aggregate, and combine functions.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动图神经网络*——AutoML可以在节点分类任务中搜索适合图神经网络的图卷积组件，例如隐藏维度的数量、注意力头的数量以及各种类型的注意力、聚合和组合函数。'
- en: '*Automated loss function search*—The most common loss functions used in machine
    learning are cross-entropy and RMSE. Apart from these, AutoML can account for
    the intraclass/interclass distance and the levels of difficulty of samples in
    the loss functions for different computer vision tasks.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动损失函数搜索*——机器学习中使用的最常见损失函数是交叉熵和RMSE。除了这些之外，AutoML还可以考虑不同计算机视觉任务中损失函数的类内/类间距离以及样本的难度水平。'
- en: '*Automated activation function search*—Activation functions play an essential
    role in deep neural networks. Besides selecting the best existing activation function
    to use, AutoML can search a set of binary and unary math functions for a predefined
    function structure to design a new activation function.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动激活函数搜索*——激活函数在深度神经网络中起着至关重要的作用。除了选择最佳现有激活函数外，AutoML还可以搜索一组二进制和一元数学函数，以设计预定义函数结构的新激活函数。'
- en: '*Automated click-through rate* (CTR) *prediction*—CTR prediction is an important
    task in recommender systems. AutoML can design effective neural architectures
    to capture both the explicit and implicit feature interactions for better CTR
    predictions.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动点击率*（CTR）*预测*——CTR预测是推荐系统中的一个重要任务。AutoML可以设计有效的神经网络架构来捕捉显式和隐式特征交互，以实现更好的CTR预测。'
- en: Other tasks include automated person re-identification, automated super-resolution,
    and automated video tasks in the computer vision domain; automated translation,
    automated language modeling, and automated keyword spotting in the natural language
    processing domain; and some model/algorithm/learning paradigm-specific and task-agnostic
    applications, such as automated unsupervised learning, automated reinforcement
    learning, automated federated learning, and so on. Generally speaking, the possible
    application domains of AutoML coincide with the ML space of possibilities. Wherever
    you can apply ML, you can apply AutoML to either generate the ML pipelines or
    improve a pipeline by changing its components or tuning its hyperparameters.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 其他任务包括计算机视觉领域的自动行人重识别、自动超分辨率和自动视频任务；自然语言处理领域的自动翻译、自动语言建模和自动关键词检测；以及一些特定于模型/算法/学习范式和任务无关的应用，例如自动无监督学习、自动强化学习、自动联邦学习等等。一般来说，AutoML的可能应用领域与机器学习（ML）的可能性空间相吻合。无论你可以在哪里应用机器学习，你都可以应用AutoML来生成机器学习管道，或者通过更改其组件或调整其超参数来改进管道。
- en: 9.1.5 Automated deep learning with AutoKeras
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.5 使用AutoKeras的自动深度学习
- en: 'Deep learning is a subfield of ML that has become a hot topic in the AI community
    and beyond. It shows promising performance and possibilities in a vast space of
    applications. Automated deep learning aims to design and tune deep learning pipelines
    automatically. Supported by the most popular open source deep learning library,
    AutoKeras, we’re able to conduct automated deep learning in the following scenarios
    based on our requirements and different AutoKeras APIs:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个子领域，已成为人工智能社区乃至更广泛的领域的热门话题。它在广泛的应用空间中展现出有希望的性能和可能性。自动深度学习的目标是自动设计和调整深度学习管道。在最受欢迎的开源深度学习库AutoKeras的支持下，我们能够根据我们的需求和不同的AutoKeras
    API在以下场景中进行自动深度学习：
- en: The AutoKeras task APIs can help us generate an end-to-end deep learning solution
    for a target ML task, such as image classification, in as few as three lines of
    code. These are the most straightforward AutoKeras APIs because they enable us
    to achieve the desired ML solution in a single step—feeding in the data—without
    knowing how to implement deep learning models ourselves. Six different task APIs
    support six different tasks in the latest release of AutoKeras, including classification
    and regression for image, text, and structured data. Before getting started, you
    should know clearly which API to use based on the ML problem you want to solve
    and prepare the raw data into one of the acceptable formats for AutoKeras.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoKeras的任务API可以帮助我们用尽可能少的代码行（如三行）生成针对目标机器学习任务（如图像分类）的端到端深度学习解决方案。这些是最直接的AutoKeras
    API，因为它们允许我们在单步中实现所需的机器学习解决方案——即输入数据——而无需我们自己知道如何实现深度学习模型。在AutoKeras的最新版本中，有六个不同的任务API支持六个不同的任务，包括图像、文本和结构化数据的分类和回归。在开始之前，你应该清楚地知道根据你想要解决的机器学习问题选择哪个API，并将原始数据准备成AutoKeras可接受的格式之一。
- en: The AutoKeras input/output (I/O) API is a more general solution for handling
    multimodal and multitask learning problems. It accepts different types and numbers
    of inputs and outputs and requires you to explicitly specify their formats during
    initialization.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoKeras的输入/输出（I/O）API是处理多模态和多任务学习问题的更通用解决方案。它接受不同类型和数量的输入和输出，并在初始化时要求你明确指定它们的格式。
- en: The functional API is AutoKeras’s most sophisticated API, dedicated to advanced
    users who want to tailor the search space to their needs. It resembles the TensorFlow
    Keras functional API and requires you to implement the AutoML pipeline by wiring
    together some AutoKeras building blocks. Each block represents a specific deep
    learning model (or data preprocessing method) composed of multiple Keras layers,
    such as a CNN, as well as the search space of the hyperparameters for the model.
    You can also specify the search space in each building block (or your own AutoML
    blocks) and wire them together with the built-in blocks to select and tune your
    own personalized deep neural networks.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 功能API是AutoKeras最复杂的API，专为希望根据需求定制搜索空间的先进用户设计。它类似于TensorFlow Keras功能API，要求你通过连接一些AutoKeras构建块来实现AutoML管道。每个块代表由多个Keras层组成的特定深度学习模型（或数据预处理方法），例如CNN，以及模型的超参数搜索空间。你还可以在每个构建块（或你自己的AutoML块）中指定搜索空间，并将它们与内置块连接起来，以选择和调整你自己的个性化深度神经网络。
- en: Figure 9.3 shows examples of the use of each of these.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3展示了这些API各自的使用示例。
- en: '![09-03](../Images/09-03.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![09-03](../Images/09-03.png)'
- en: Figure 9.3 Automated deep learning with the AutoKeras APIs
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3展示了使用AutoKeras API进行自动深度学习的示例。
- en: 'AutoKeras supports your need for automated deep learning solutions for supervised
    learning problems, such as classification and regression. Its built-in blocks
    also save you effort in creating the search spaces. However, if none of the built-in
    blocks satisfies your needs, or you have a complex AutoML application that requires
    tuning the loss function, selecting shallow models, designing models for unsupervised
    learning problems, and so on, we suggest that you use the other AutoML toolkit
    in the Keras ecosystem: KerasTuner.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: AutoKeras支持你对于监督学习问题（如分类和回归）的自动深度学习解决方案的需求，其内置块也节省了你创建搜索空间的努力。然而，如果你需要的内置块都不满足你的需求，或者你有一个复杂的AutoML应用程序，需要调整损失函数、选择浅层模型、为无监督学习问题设计模型等，我们建议你使用Keras生态系统中的其他AutoML工具包：KerasTuner。
- en: 9.1.6 Fully personalized AutoML with KerasTuner
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.6 使用KerasTuner进行完全个性化的AutoML
- en: 'KerasTuner is a library for selecting and tuning both deep learning and shallow
    ML models. Besides the tasks that can be solved by AutoKeras, it tackles the following
    three scenarios that are difficult or introduce an extra burden for AutoKeras
    to handle:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: KerasTuner是一个用于选择和调整深度学习和浅层机器学习模型的库。除了AutoKeras可以解决的任务外，它还处理以下三个AutoKeras难以处理或引入额外负担的场景：
- en: Pipelines in the search space have different training and evaluation strategies,
    such as shallow models implemented with scikit-learn and deep learning models
    implemented with TensorFlow Keras.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索空间中的管道有不同的训练和评估策略，例如使用scikit-learn实现的浅层模型和使用TensorFlow Keras实现的深度学习模型。
- en: You need to perform tasks other than supervised learning tasks.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要执行除了监督学习任务之外的任务。
- en: There are no built-in AutoML blocks in AutoKeras that are appropriate for use.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在AutoKeras中没有内置的AutoML块适合使用。
- en: As stated in chapter 6, tuning a model with KerasTuner requires implementing
    a model-building function (or a class-extending HyperModel) that characterizes
    the search space and initializing a tuner object specifying the search method,
    as shown in the following listing.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如第6章所述，使用KerasTuner调整模型需要实现一个模型构建函数（或扩展HyperModel的类）来表征搜索空间，并初始化一个指定搜索方法的调节器对象，如下所示。
- en: Listing 9.1 Using random search to tune an MLP model with KerasTuner
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.1 使用随机搜索调整KerasTuner的MLP模型
- en: '[PRE0]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Creates the model-building function, and specifies the search space
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建模型构建函数，并指定搜索空间
- en: ❷ Defines a random search tuner
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 定义随机搜索调节器
- en: 'A tuner contains a search method and organizes the training and evaluation
    of the selected pipelines during the search process. Because KerasTuner is designed
    for tuning deep learning models, the built-in tuners (except the SklearnTuner)
    are dedicated to tuning deep learning pipelines. Each of them wraps up the training
    and evaluation process of a deep learning pipeline, and the name denotes a specific
    search method: for example, RandomSearch is a tuner that adopts the random search
    method for tuning deep learning models.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 调节器包含一个搜索方法，并在搜索过程中组织所选管道的训练和评估。由于KerasTuner是为调整深度学习模型而设计的，因此内置的调节器（除SklearnTuner外）都是专门用于调整深度学习管道的。每个调节器都封装了深度学习管道的训练和评估过程，其名称表示特定的搜索方法：例如，RandomSearch是一个采用随机搜索方法调整深度学习模型的调节器。
- en: We can create the search space for tuning shallow models implemented with the
    scikit-learn library in the same way as for deep learning models by using the
    SklearnTuner, which wraps up the training and evaluation process for scikit-learn
    models or pipelines. In KerasTuner, the search method is called an oracle. So,
    we can choose a different search method by changing the oracle in the tuner. We
    can also customize a tuner to tune models implemented with other libraries (beyond
    Keras and scikit-learn). Pseudocode for customizing a tuner is shown in the following
    listing; it requires the implementation of a run_trial() function for executing
    the current trial and two auxiliary functions for saving and loading the evaluated
    models.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用SklearnTuner以与深度学习模型相同的方式创建用于调整使用scikit-learn库实现的浅层模型的搜索空间，SklearnTuner封装了scikit-learn模型或管道的训练和评估过程。在KerasTuner中，搜索方法被称为oracle。因此，我们可以通过更改调节器中的oracle来选择不同的搜索方法。我们还可以自定义调节器来调整使用其他库（超出Keras和scikit-learn）实现的模型。以下列出了自定义调节器的伪代码；它需要实现一个run_trial()函数来执行当前试验，以及两个用于保存和加载评估模型的辅助函数。
- en: Listing 9.2 Template for customizing a tuner
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.2 自定义调节器的模板
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Builds and fits a GBDT model
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建和拟合GBDT模型
- en: ❷ Builds, trains, evaluates, and saves the model selected in the current trial,
    and updates the oracle, if needed
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 构建、训练、评估和保存当前试验中选定的模型，并在需要时更新oracle
- en: ❸ Saves the model to disk
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将模型保存到磁盘
- en: ❹ The model-loading function
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 模型加载函数
- en: In addition to selecting different search methods for our custom tuner by changing
    the oracle, we can implement our own search techniques by customizing an oracle
    class, as shown in the next section.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除了通过更改oracle来选择我们自定义调节器的不同搜索方法外，我们还可以通过自定义oracle类来实现自己的搜索技术，如下一节所示。
- en: 9.1.7 Implementing search techniques
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.7 实现搜索技术
- en: Existing AutoML search methods can be classified as either history-independent
    or history-dependent, depending on whether they can take historical search results
    into account to improve their performance.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的AutoML搜索方法可以根据它们是否能够考虑历史搜索结果来提高性能，分为历史无关或历史相关。
- en: Random search and grid search are two representative history-independent methods.
    Heuristic methods such as evolutionary methods and model-based methods, such as
    the Bayesian optimization method, are the two most widely used types of history-dependent
    methods. An evolutionary method simulates the evolution of a biological population.
    It randomly initializes a population of trials, and samples several parent trials
    from the population to generate offspring based on mutation and crossover operations
    of hyperparameters. After the new offspring trial is evaluated, the population
    is updated based on certain selection strategies, such as ranking selection. Bayesian
    optimization adopts a surrogate model trained with the historical evaluations
    of the ML pipelines as a much cheaper way to approximate the performance of unseen
    models. An acquisition function will leverage the approximation of the surrogate
    model to help sample the next available trial.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 随机搜索和网格搜索是两种代表性的不依赖历史信息的方法。启发式方法，如进化方法和基于模型的方法，如贝叶斯优化方法，是两种最广泛使用的依赖历史信息的方法。进化方法模拟了生物种群的发展。它随机初始化一个试验种群，并从种群中随机选择几个父代试验，根据超参数的变异和交叉操作生成后代。在评估新的后代试验后，根据某些选择策略（如排名选择）更新种群。贝叶斯优化采用一个代理模型，该模型使用历史评估的机器学习管道作为近似未见模型性能的更便宜的方法。一个获取函数将利用代理模型的近似来帮助采样下一个可用的试验。
- en: Designing a history-dependent search method requires balancing exploitation
    and exploration. *Exploitation* means we want to take advantage of past experience,
    selecting the next hyperparameter based on its proximity to the best-performing
    ones at present because we’re confident about these points. *Exploration* means
    we want to explore more of the undeveloped regions in the search space to avoid
    getting trapped in local optima and missing the global optimum.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 设计一个依赖历史信息的搜索方法需要平衡利用和探索。*利用*意味着我们想要利用过去的经验，根据当前表现最佳的超参数的邻近性来选择下一个超参数，因为我们对这些点有信心。*探索*意味着我们想要探索搜索空间中更多未开发的区域，以避免陷入局部最优并错过全局最优。
- en: 'Implementing a history-dependent search method requires implementing two steps:
    hyperparameter sampling and algorithm update. The sampling and updating of a search
    method are implemented in the populate_space() function, as shown in the following
    listing.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 实现一个依赖历史信息的搜索方法需要实现两个步骤：超参数采样和算法更新。搜索方法的采样和更新在populate_space()函数中实现，如下所示。
- en: Listing 9.3 Template for customizing an oracle (search method)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.3 定制算子的模板（搜索方法）
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Extra initialization steps of search method can be put here
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 可以在这里放置搜索方法的额外初始化步骤
- en: ❷ Samples the hyperparameter values in the current trial
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在当前试验中采样超参数值
- en: ❸ Updates the search method based on the search history
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 基于搜索历史更新搜索方法
- en: Note In the research community, some recent advances focus on *reinforcement
    learning* and *gradient-based methods*, especially in the area of automated deep
    learning. We’ll provide references to some useful learning materials at the end
    of this chapter so that, after reading this book, you can do some further exploration
    to catch up with these advances.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在研究社区中，一些最近的研究进展集中在*强化学习*和*基于梯度的方法*上，尤其是在自动深度学习的领域。我们将在本章末尾提供一些有用的学习材料的参考文献，以便在阅读本书之后，您可以进行一些进一步的探索，以跟上这些进展。
- en: 9.1.8 Scaling up the AutoML process
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.8 扩展AutoML过程
- en: 'The biggest challenges of applying AutoML in practice are data scalability
    and time and space complexities. A typical way to tackle these challenges is to
    adopt parallelization techniques. As we discussed in chapter 8, the following
    three types of parallelization strategies exist (see figure 9.4):'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中应用AutoML的最大挑战是数据可扩展性以及时间和空间复杂性。解决这些挑战的一种典型方法是通过采用并行化技术。正如我们在第8章中讨论的，存在以下三种类型的并行化策略（见图9.4）：
- en: '*Data parallelism* makes it possible to work with large datasets by making
    use of multiple machines (or CPUs/GPUs/TPUs). With this approach, you train multiple
    copies of the same model on different machines with different batches of data
    and synchronize these machines periodically to update the model weights.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据并行性*使得通过利用多台机器（或CPU/GPU/TPU）来处理大型数据集成为可能。这种方法允许你在不同的机器上使用不同的数据批次训练相同模型的多个副本，并定期同步这些机器以更新模型权重。'
- en: '*Model parallelism* is mainly used for large models that cannot be contained
    in a single GPU’s memory or for accelerating models whose inference processes
    can be parallelized. It breaks the model into different pieces and allocates them
    to different GPUs so that the entire model can fit in the available memory. During
    inference, some pieces of the model may run in parallel to save time.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型并行性*主要用于无法包含在单个GPU内存中的大型模型，或者用于加速推理过程可以并行化的模型。它将模型分解成不同的部分，并将它们分配到不同的GPU上，以便整个模型可以适应可用的内存。在推理过程中，模型的一些部分可能并行运行以节省时间。'
- en: '*Parallel tuning* is used to accelerate the AutoML process. With this approach,
    you put models with different hyperparameter settings on different GPUs and use
    the same dataset to train them, so the hyperparameter tuning process runs in parallel.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*并行调优*用于加速AutoML过程。采用这种方法，你将具有不同超参数设置的模型放在不同的GPU上，并使用相同的训练数据集来训练它们，因此超参数调优过程是并行运行的。'
- en: '![09-04](../Images/09-04.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![09-04](../Images/09-04.png)'
- en: Figure 9.4 Three types of parallelism
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 三种并行类型
- en: 'Besides leveraging more hardware resources, we can also accelerate the search
    process from the algorithm’s perspective in the following ways:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 除了利用更多的硬件资源外，我们还可以通过以下方式从算法的角度加速搜索过程：
- en: '*Using fidelity-based techniques*—We can use low-fidelity estimations to approximately
    compare the performance of different ML pipelines. Some typical methods include
    early stopping, subsampling data for training and evaluating the models discovered
    in the search process, and directly adopting an advanced scheduler method, such
    as Hyperband.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用基于保真度的技术*——我们可以使用低保真度估计来大致比较不同机器学习管道的性能。一些典型的方法包括早期停止、对训练和评估搜索过程中发现的模型的数据进行子采样，以及直接采用高级调度方法，如Hyperband。'
- en: '*Using pretrained weights and models*—We can use pretrained weights and share
    them (partially) across the discovered ML models to accelerate the training of
    these models. This is especially useful in automated deep learning.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用预训练权重和模型*——我们可以使用预训练的权重并将它们（部分）共享到发现的机器学习模型中，以加速这些模型的训练。这在自动深度学习中特别有用。'
- en: '*Warm-starting the search space*—We can inject some human prior knowledge into
    the search algorithm by hand-picking some good models and hyperparameters to evaluate
    before the search starts and letting the search algorithm build off of these.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预热搜索空间*——我们可以在搜索开始之前手动挑选一些好的模型和超参数来评估，并将一些人类先验知识注入到搜索算法中，让搜索算法基于这些信息进行构建。'
- en: 9.2 AutoML tools and platforms
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 AutoML工具和平台
- en: 'The development of tools and platforms has spurred the growth in the AutoML
    field. We introduce a selection of these here. Although the environment configurations
    for different tools are quite different, and some of them also provide GUIs for
    better visualization and easier human interaction, their APIs are often quite
    similar to those of AutoKeras and KerasTuner. They are all built around the three
    components of AutoML: the search space, the search algorithm, and the evaluation
    criteria. With the previous chapters as background, you should be able to adapt
    to any of these tools without a steep learning curve by exploring their repositories
    and tutorials.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 工具和平台的发展推动了AutoML领域的发展。我们在此介绍其中的一些。尽管不同工具的环境配置相当不同，其中一些还提供了GUI以实现更好的可视化和更简单的人机交互，但它们的API通常与AutoKeras和KerasTuner的API非常相似。它们都是围绕AutoML的三个组件构建的：搜索空间、搜索算法和评估标准。在前面章节的背景下，你应该能够通过探索它们的仓库和教程，无需陡峭的学习曲线就能适应这些工具。
- en: 9.2.1 Open source AutoML tools
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 开源AutoML工具
- en: 'The available open source AutoML toolkits can be divided into a few categories
    based on their core focus. These include the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的开源AutoML工具包可以根据其核心焦点分为几个类别。以下是一些：
- en: Tools for automated feature engineering
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动特征工程工具
- en: Tools for automated hyperparameter tuning, model selection, and end-to-end automated
    pipeline search
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动超参数调整、模型选择和端到端自动化管道搜索工具
- en: Tools for automated deep learning
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动深度学习工具
- en: Let’s take a look at a few representative examples of each.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些代表性的例子。
- en: FeatureTools is probably the most popular open source Python library for automated
    feature engineering at the time of writing. It abstracts the feature engineering
    operations as primitives and applies them to generate features from relational
    datasets and temporal datasets.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: FeatureTools可能是当时最受欢迎的开源Python库，用于自动特征工程。它将特征工程操作抽象为原语，并将它们应用于从关系数据集和时间数据集中生成特征。
- en: Most of the existing AutoML projects focus on hyperparameter tuning or generating
    end-to-end ML pipelines. One of the earliest projects in this area is Auto-WEKA,
    which was built on top of a data analysis package named Weka (Waikato Environment
    for Knowledge Analysis). It conducts hyperparameter tuning and generates ML pipelines
    leveraging the Bayesian optimization approach, mainly for supervised learning
    tasks. A similar attempt that’s built on top of the scikit-learn library, named
    Auto-Sklearn, has shown promising performance in many AutoML competitions. It
    also searches with the Bayesian optimization method and discovers ensemble models
    to boost performance. The latest version of Auto-Sklearn has a succinct API that
    is similar to the task API of AutoKeras, as you can see in the following listing.
    Some other popular libraries include TPOT, Hyperopt, Microsoft NNI, and the open
    source version of the H2O AutoML toolkit.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现有的AutoML项目都集中在超参数调整或生成端到端机器学习管道。这个领域最早的项目之一是Auto-WEKA，它建立在名为Weka（Waikato
    Environment for Knowledge Analysis）的数据分析包之上。它通过贝叶斯优化方法进行超参数调整并生成机器学习管道，主要用于监督学习任务。另一个基于scikit-learn库构建的项目，名为Auto-Sklearn，在许多AutoML竞赛中展示了有希望的性能。它也使用贝叶斯优化方法搜索并发现集成模型以提升性能。Auto-Sklearn的最新版本有一个简洁的API，类似于AutoKeras的任务API，如下所示。其他一些流行的库包括TPOT、Hyperopt、Microsoft
    NNI以及H2O AutoML工具包的开源版本。
- en: Listing 9.4 Comparing Auto-Sklearn and the AutoKeras task API
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.4比较Auto-Sklearn和AutoKeras任务API
- en: '[PRE3]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Initializes the automated classification learner of Auto-Sklearn
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 初始化Auto-Sklearn的自动分类学习器
- en: ❷ Initializes the automated classification learner of AutoKeras
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 初始化AutoKeras的自动分类学习器
- en: In recent years, most of the development effort has focused on automated deep
    learning. Besides AutoKeras, researchers from Amazon have proposed a package named
    AutoGluon, which is built on top of the Gluon deep learning API. It targets MXNet
    and PyTorch users and is designed to be easy to use on AWS cloud infrastructure.
    Other libraries, such as Auto-PyTorch, also provide neural architecture search
    capabilities with a similar API to AutoKeras.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大部分开发工作都集中在自动深度学习上。除了AutoKeras之外，亚马逊的研究人员还提出了一个名为AutoGluon的包，它建立在Gluon深度学习API之上。它针对MXNet和PyTorch用户，旨在在AWS云基础设施上易于使用。其他库，如Auto-PyTorch，也提供了与AutoKeras类似API的神经架构搜索功能。
- en: In additon to the tools mentioned here, many others offer AutoML components.
    For example, a famous distribution execution framework for ML named Ray has a
    module called Ray Tune, which collects a set of open source AutoML search algorithms
    and utilizes the Ray framework to enable distributed tuning. The Ludwig toolbox,
    which allows you to train and evaluate deep learning models without writing any
    code, also includes an AutoML module for hyperparameter tuning and model selection.
    A summary of these tools is presented in table 9.1.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这里提到的工具之外，许多其他工具也提供了AutoML组件。例如，一个著名的机器学习分布式执行框架Ray有一个名为Ray Tune的模块，它收集了一系列开源AutoML搜索算法，并利用Ray框架实现分布式调整。Ludwig工具箱允许您在不编写任何代码的情况下训练和评估深度学习模型，它还包括一个用于超参数调整和模型选择的AutoML模块。这些工具的总结见表9.1。
- en: Table 9.1 Selected open source AutoML tools
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.1选定的开源AutoML工具
- en: '| Core task | Framework | URL |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 核心任务 | 框架 | URL |'
- en: '| Automated feature engineering | FeatureTools | [https://www.featuretools.com](https://www.featuretools.com)
    |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 自动特征工程 | FeatureTools | [https://www.featuretools.com](https://www.featuretools.com)
    |'
- en: '| Automated hyperparameter tuning or pipeline search | Hyperopt | [http://hyperopt.github.io/hyperopt/](http://hyperopt.github.io/hyperopt/)
    |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 自动超参数调整或管道搜索 | Hyperopt | [http://hyperopt.github.io/hyperopt/](http://hyperopt.github.io/hyperopt/)
    |'
- en: '|  | Auto-WEKA | [https://www.cs.ubc.ca/labs/beta/Projects/autoweka/](https://www.cs.ubc.ca/labs/beta/Projects/autoweka/)
    |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  | Auto-WEKA | [https://www.cs.ubc.ca/labs/beta/Projects/autoweka/](https://www.cs.ubc.ca/labs/beta/Projects/autoweka/)
    |'
- en: '|  | Auto-Sklearn | [https://automl.github.io/auto-sklearn/master/](https://automl.github.io/auto-sklearn/master/)
    |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  | Auto-Sklearn | [https://automl.github.io/auto-sklearn/master/](https://automl.github.io/auto-sklearn/master/)
    |'
- en: '|  | Ray Tune | [https://docs.ray.io/en/master/tune/index.html](https://docs.ray.io/en/master/tune/index.html)
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | Ray Tune | [https://docs.ray.io/en/master/tune/index.html](https://docs.ray.io/en/master/tune/index.html)
    |'
- en: '|  | KerasTuner | [https://keras.io/keras_tuner/](https://keras.io/keras_tuner/)
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|  | KerasTuner | [https://keras.io/keras_tuner/](https://keras.io/keras_tuner/)
    |'
- en: '|  | TPOT | [http://epistasislab.github.io/tpot/](http://epistasislab.github.io/tpot/)
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | TPOT | [http://epistasislab.github.io/tpot/](http://epistasislab.github.io/tpot/)
    |'
- en: '|  | Microsoft NNI | [https://nni.readthedocs.io](https://nni.readthedocs.io)
    |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|  | 微软 NNI | [https://nni.readthedocs.io](https://nni.readthedocs.io) |'
- en: '|  | H2O AutoML toolkit | [https://www.h2o.ai/products/h2o-automl/](https://www.h2o.ai/products/h2o-automl/)
    |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '|  | H2O AutoML 工具包 | [https://www.h2o.ai/products/h2o-automl/](https://www.h2o.ai/products/h2o-automl/)
    |'
- en: '|  | Ludwig | [https://github.com/ludwig-ai/ludwig](https://github.com/ludwig-ai/ludwig)
    |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '|  | 洛德维希 | [https://github.com/ludwig-ai/ludwig](https://github.com/ludwig-ai/ludwig)
    |'
- en: '| Automated deep learning | AutoKeras | [https://autokeras.com](https://autokeras.com)
    |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 自动深度学习 | AutoKeras | [https://autokeras.com](https://autokeras.com) |'
- en: '|  | Auto-Gluon | [https://auto.gluon.ai/stable/index.html](https://auto.gluon.ai/stable/index.htm)
    |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|  | Auto-Gluon | [https://auto.gluon.ai/stable/index.html](https://auto.gluon.ai/stable/index.htm)
    |'
- en: 9.2.2 Commercial AutoML platforms
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 商业自动机器学习平台
- en: 'Besides the open source projects, many companies, especially those providing
    cloud services, are also exploring the commercial opportunity of AutoML. Some
    examples follow:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 除了开源项目之外，许多公司，尤其是那些提供云服务的公司，也在探索自动机器学习的商业机会。以下是一些例子：
- en: Google Cloud AutoML ([https://cloud.google.com/automl](https://cloud.google.com/automl))
    provides a graphical interface for customizing ML models based on their application
    domain and data structures. Google’s AutoML products include AutoML Vision for
    computer vision tasks, AutoML Natural Language for natural language processing
    tasks, Vertex AI for easy model building and deployment, and more.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谷歌 Cloud AutoML ([https://cloud.google.com/automl](https://cloud.google.com/automl))
    提供了一个图形界面，可以根据其应用领域和数据结构自定义机器学习模型。谷歌的 AutoML 产品包括用于计算机视觉任务的 AutoML Vision、用于自然语言处理任务的
    AutoML Natural Language、用于轻松构建和部署模型的 Vertex AI 以及更多。
- en: Amazon SageMaker Autopilot ([https://aws.amazon.com/sagemaker/autopilot/](https://aws.amazon.com/sagemaker/autopilot/))
    mainly focuses on the generation of end-to-end ML pipelines for tabular data classification
    or regression. It helps you automatically build, train, and tune the best ML model
    by simply feeding in the raw tabular data and the targets, and it can take advantage
    of the power of AWS for large-scale tasks. You can also deploy the model to production
    with a single click and iteratively improve it by leveraging Amazon SageMaker
    Studio.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊 SageMaker Autopilot ([https://aws.amazon.com/sagemaker/autopilot/](https://aws.amazon.com/sagemaker/autopilot/))
    主要专注于生成用于表格数据分类或回归的端到端机器学习管道。它可以帮助您通过简单地输入原始表格数据和目标，自动构建、训练和调整最佳机器学习模型，并且可以利用
    AWS 的强大功能来处理大规模任务。您还可以一键部署模型到生产环境，并通过利用 Amazon SageMaker Studio 逐步改进它。
- en: Microsoft Azure AutoML ([http://mng.bz/aDEm](http://mng.bz/aDEm)) offers experiences
    tailored to two different user groups. For users who are experienced with ML and
    know how to implement ML models with Python code, the Azure Machine Learning Python
    SDK can be a good choice, enabling you to build ML models with speed and scale.
    For users who do not have coding experience with ML, Azure Machine Learning Studio
    ([https://ml.azure.com](https://ml.azure.com)) is a good match; it provides a
    graphical interface to perform AutoML with a few simple clicks.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软 Azure AutoML ([http://mng.bz/aDEm](http://mng.bz/aDEm)) 提供了针对两个不同用户群体的定制化体验。对于熟悉机器学习并且知道如何使用
    Python 代码实现机器学习模型的用户，Azure 机器学习 Python SDK 可以是一个不错的选择，它使您能够快速、大规模地构建机器学习模型。对于没有机器学习编码经验的用户，Azure
    机器学习 Studio ([https://ml.azure.com](https://ml.azure.com)) 是一个很好的选择；它提供了一个图形界面，通过几个简单的点击即可执行自动机器学习。
- en: 'IBM Watson Studio AutoAI ([https://www.ibm.com/cloud/watson-studio/autoai](https://www.ibm.com/cloud/watson-studio/autoai))
    automates all four steps of the AI life cycle: data preparation, feature engineering,
    model development, and hyperparameter optimization. You can use the tool to manage
    the entire life cycle and deploy your model with one click.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IBM Watson Studio AutoAI ([https://www.ibm.com/cloud/watson-studio/autoai](https://www.ibm.com/cloud/watson-studio/autoai))
    自动化 AI 生命周期的所有四个步骤：数据准备、特征工程、模型开发和超参数优化。您可以使用此工具管理整个生命周期，并通过一键部署模型。
- en: As well as the previously mentioned platforms, efforts are also being made by
    many startups, including DataRobot, 4Paradigm, H2O.ai, Feature Labs, DarwinML,
    and more (see table 9.2). We believe that AutoML will continue to be used and
    show its benefits in more and more products in the future and will help democratize
    ML techniques so that they can be used by more companies for different industrial
    applications.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 除了之前提到的平台，许多初创公司也在努力，包括DataRobot、4Paradigm、H2O.ai、Feature Labs、DarwinML等（见表9.2）。我们相信AutoML将继续在越来越多的产品中应用并显示出其优势，并将有助于民主化ML技术，使更多公司能够用于不同的工业应用。
- en: Table 9.2 Selected commercial AutoML platforms
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.2选定的商业AutoML平台
- en: '| Company | Product | Examples of users |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 公司 | 产品 | 用户示例 |'
- en: '| Google | Google Cloud AutoML | Disney, ZSL, URBN |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| Google | Google Cloud AutoML | 迪士尼、ZSL、URBN |'
- en: '| Amazon | Amazon SageMaker Autopilot | Amazon AWS |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| Amazon | Amazon SageMaker Autopilot | Amazon AWS |'
- en: '| Microsoft | Microsoft Azure AutoML | Azure Machine Learning, Power BI, and
    other Microsoft products |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| Microsoft | Microsoft Azure AutoML | Azure机器学习、Power BI和其他Microsoft产品 |'
- en: '| IBM | IBM Watson Studio AutoAI | IBM Cloud |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| IBM | IBM Watson Studio AutoAI | IBM Cloud |'
- en: '| DataRobot | DataRobot enterprise AI platform | Snowflake, Reltio, Alteryx,
    AWS, Databricks |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| DataRobot | DataRobot企业AI平台 | Snowflake、Reltio、Alteryx、AWS、Databricks |'
- en: '| 4Paradigm | 4Paradigm AutoML platform | Bank of China, PICC, Zhihu |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 4Paradigm | 4Paradigm AutoML平台 | 中国银行、PICC、知乎 |'
- en: '| H2O.ai | H2O AutoML platform | AWS, Databricks, IBM, NVIDIA |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| H2O.ai | H2O AutoML平台 | AWS、Databricks、IBM、NVIDIA |'
- en: '| Feature Labs | Feature Labs AutoML platform | NASA, Monsanto, Kohl’s |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| Feature Labs | Feature Labs AutoML平台 | NASA、Monsanto、Kohl’s |'
- en: '| DarwinML | DarwinML AutoML platform | Intelligence Qubic |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| DarwinML | DarwinML AutoML平台 | Intelligence Qubic |'
- en: 9.3 The challenges and future of AutoML
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 AutoML的挑战和未来
- en: AutoML is still in its early stages, with a huge range of possibilities to be
    discovered and limitations to be addressed. In this section, we share our thoughts
    on the main challenges in the AutoML field today and provide a look forward to
    how these challenges may be tackled.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML仍然处于早期阶段，有巨大的可能性等待发现和限制需要解决。在本节中，我们分享了对当前AutoML领域主要挑战的看法，并展望了如何解决这些挑战。
- en: 9.3.1 Measuring the performance of AutoML
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 衡量AutoML的性能
- en: Before doing AutoML, we need to clarify the objective we want to use to measure
    its performance. Although in most of this book we used an accuracy metric, such
    as image classification accuracy, to decide whether a model discovered by the
    AutoML algorithm is good, AutoML is not just about improving model accuracy. In
    practice, we may want or need to consider many objectives when applying AutoML.
    For example, we may want to select a deep learning model with a small model size
    (limiting memory consumption) or lower training/inference speed so that we can
    deploy it on edge devices. In this case, we might need to consider complexity
    measures, such as floating-point operations per second (FLOPS) during the search
    process. As another example, we may want a model that’s able to generate results
    that are highly interpretable and convincing, rather than just providing accurate
    predictions. This is quite common in medical applications, where interpretability
    and transparency are of great importance. Morality and ethics also point to the
    importance of data privacy and prediction fairness of ML models, leading to some
    new research directions such as AutoML with federated learning to enhance these
    objectives. Because the exact objectives vary on a case-by-case basis, an ideal
    AutoML system should be able to take into account these task-specific requirements,
    and different AutoML algorithms should be better benchmarked to help users without
    much ML background easily select the best one to use.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行AutoML之前，我们需要明确我们想要用来衡量其性能的目标。尽管在这本书的大部分内容中，我们使用了准确率指标，如图像分类准确率，来决定AutoML算法发现的模型是否良好，但AutoML不仅仅是提高模型准确率。在实践中，在应用AutoML时，我们可能需要或需要考虑许多目标。例如，我们可能希望选择一个具有较小模型尺寸的深度学习模型（限制内存消耗）或较慢的训练/推理速度，以便我们可以在边缘设备上部署它。在这种情况下，我们可能需要考虑搜索过程中的复杂度指标，如每秒浮点运算次数（FLOPS）。作为另一个例子，我们可能希望一个能够生成高度可解释和令人信服的结果的模型，而不仅仅是提供准确的预测。这在医疗应用中相当常见，其中可解释性和透明度非常重要。道德和伦理也指出，数据隐私和ML模型的预测公平性很重要，这导致了一些新的研究方向，如具有联邦学习的AutoML来增强这些目标。由于具体目标因案例而异，理想的AutoML系统应该能够考虑这些特定任务的要求，并且不同的AutoML算法应该进行更好的基准测试，以帮助没有太多ML背景的用户轻松选择最佳使用方案。
- en: 9.3.2 Resource complexity
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 资源复杂性
- en: Resource consumption is one of the dominant challenges in the AutoML domain
    today. As datasets and ML models are becoming increasingly larger, it is often
    prohibitive for end users to adopt AutoML to design or tune their own ML models.
    We often have to settle for less due to resource constraints. Though some recent
    advances in the research community have aimed to propose *one-shot methods* to
    avoid the iterative tuning process, there is still a lot of exploration to do
    to reduce the time and space complexity of AutoML, from both an ML algorithm perspective
    and a hardware design perspective.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 资源消耗是当前AutoML领域的主要挑战之一。随着数据集和机器学习模型变得越来越庞大，终端用户往往难以采用AutoML来设计或调整他们自己的机器学习模型。由于资源限制，我们常常不得不妥协。尽管研究界最近的一些进展旨在提出*一次性方法*以避免迭代调整过程，但为了从机器学习算法和硬件设计两个方面降低AutoML的时间和空间复杂度，还有很多探索要做。
- en: 9.3.3 Interpretability and transparency
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.3 可解释性和透明性
- en: AutoML should ultimately facilitate convenient usage for its users and lighten
    their burden. This requires the AutoML system to be human-centric, meaning that
    users should be involved in the search process in several ways. First, the results
    provided by the AutoML system should be interpretable to convince users of its
    efficacy and foster trust in the adoption of AutoML solutions for domain-specific
    applications, such as medical applications. Second, users should be able to adjust
    the search space or the objective to accelerate the search process, which requires
    visibility. Third, the search method should be transparent to users to help them
    better understand the search process and ensure that data privacy is protected
    and predictions are fair. Ensuring the interpretability and transparency of AutoML
    also requires a deeper theoretical understanding of different ML pipelines and
    AutoML search techniques.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML最终应该方便用户使用，减轻他们的负担。这要求AutoML系统以人为中心，意味着用户应以多种方式参与到搜索过程中。首先，AutoML系统提供的结果应该是可解释的，以说服用户其有效性，并培养用户对AutoML解决方案在特定领域应用（如医疗应用）的信任。其次，用户应该能够调整搜索空间或目标以加速搜索过程，这需要可见性。第三，搜索方法应该对用户透明，以帮助他们更好地理解搜索过程，并确保数据隐私得到保护，预测是公平的。确保AutoML的可解释性和透明性还需要对不同的机器学习管道和AutoML搜索技术有更深入的理论理解。
- en: 9.3.4 Reproducibility and robustness
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.4 可重复性和鲁棒性
- en: The reproducibility of ML and the robustness of ML models are hot topics in
    the ML community. These issues are also important—and even more challenging—in
    the context of AutoML, because the AutoML system not only may control the training
    of multiple ML pipelines but also contains multiple “hyper-hyperparameters” that
    control the search algorithm. A difference in a single seed can lead to a huge
    difference in the training results of one ML pipeline and may also result in great
    variance in the hyperparameter sampling and the updating of the search algorithm.
    In addition, ML models, and especially deep learning models, are vulnerable to
    adversarial examples and human imperception perturbations. Ensuring the robustness
    of training and evaluating ML models and the robustness of hyperparameter sampling
    and search algorithm updates are indispensable for protecting the AutoML system.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的可重复性和机器学习模型的鲁棒性是机器学习社区的热门话题。这些问题在AutoML的背景下也同样重要——甚至更具挑战性，因为AutoML系统不仅可能控制多个机器学习管道的训练，还包含多个控制搜索算法的“超超参数”。单个种子差异可能导致单个机器学习管道的训练结果产生巨大差异，也可能导致超参数采样和搜索算法更新的巨大差异。此外，机器学习模型，尤其是深度学习模型，容易受到对抗性样本和人类感知干扰的影响。确保训练和评估机器学习模型以及超参数采样和搜索算法更新的鲁棒性对于保护AutoML系统至关重要。
- en: 9.3.5 Generalizability and transferability
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.5 泛化性和迁移性
- en: In a real-world application, we might have multiple datasets and tasks. A human-designed
    model is often applicable to different datasets and can even be transferred across
    multiple tasks. We expect an AutoML solution to also be able to generalize to
    different ML applications. It is also expected to have lifelong learning ability,
    meaning that the meta-knowledge learned from the previous AutoML tasks can be
    memorized and applied to new tasks, just like how we humans accumulate knowledge
    and experience.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，我们可能会有多个数据集和任务。一个由人类设计的模型通常适用于不同的数据集，甚至可以在多个任务之间迁移。我们期望AutoML解决方案也能推广到不同的机器学习应用中。还期望它具有终身学习能力，这意味着从先前AutoML任务中学习到的元知识可以被记住并应用于新任务，就像我们人类积累知识和经验一样。
- en: 9.3.6 Democratization and productionization
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.6 民主化和商业化
- en: AutoML plays an important role in democratizing advanced ML techniques, especially
    for users who do not have much ML expertise. Despite the open source community
    increasing their efforts in developing easy-to-use AutoML solutions, the learning
    curve of using most of these tools is still steep, requiring preliminary ML knowledge
    and understanding of the AutoML system. Also, because generating an AutoML solution
    from a universal search space is impractical, adopting AutoML methods to deal
    with ML tasks beyond the commonly-faced ones often requires extra manual data
    preprocessing work and domain-specific search space design. Commercializing and
    productionizing AutoML solutions also calls for more optimized system design.
    Deploying them can be even more complicated than embracing classic ML methods
    with manual design and tuning.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML在推广高级机器学习技术方面发挥着重要作用，尤其是对于没有太多机器学习专业知识的用户来说。尽管开源社区在开发易于使用的AutoML解决方案方面加大了努力，但使用这些工具的学习曲线仍然很陡峭，需要初步的机器学习知识和对AutoML系统的理解。此外，由于从通用搜索空间生成AutoML解决方案不切实际，采用AutoML方法处理超出常见问题的机器学习任务通常需要额外的手动数据预处理工作和特定领域的搜索空间设计。将AutoML解决方案商业化并投入生产还需要更优化的系统设计。部署它们甚至可能比采用经典机器学习方法和手动设计和调整更复杂。
- en: 9.4 Staying up-to-date in a fast-moving field
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 在快速发展的领域中保持最新
- en: 'To help you keep up with the fast-moving AutoML field, in this section we’ll
    point you toward some useful resources that can help you keep track of and learn
    about recent developments in AutoML technologies. Several research groups and
    individual researchers survey and organize the latest advances in AutoML toolkits
    and papers on their websites or GitHub pages, so we’ll start with a few of these
    (which are, at present, regularly updated). You can refer to the following resources
    for fast search and retrieval of materials from the AutoML literature:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您跟上快速发展的AutoML领域，在本节中，我们将向您推荐一些有用的资源，这些资源可以帮助您跟踪和学习AutoML技术领域的最新发展。一些研究小组和个人研究人员在其网站或GitHub页面上调查和整理了AutoML工具包和论文的最新进展，因此我们将从其中的一些开始（目前这些内容是定期更新的）。您可以通过以下资源快速搜索和检索AutoML文献中的材料：
- en: 'The website of the AutoML research group from the University of Freiburg, led
    by Professor Frank Hutter and Marius Lindauer: [https://www.automl.org](https://www.automl.org).
    In addition to hosting the project led by the research group, the site presents
    curated lists of AutoML papers and other resources based on categorizations such
    as neural architecture search (NAS).'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弗赖堡大学AutoML研究小组的网站，由弗兰克·胡特教授和马里乌斯·林道尔领导：[https://www.automl.org](https://www.automl.org)。除了托管研究小组的项目外，该网站还基于分类如神经架构搜索（NAS）等，提供了精选的AutoML论文和其他资源的列表。
- en: 'The GitHub web page initiated by Dr. Mark Lin, which provides a curated list
    of AutoML papers and other resources: [https://github.com/hibayesian/awesome-automl-papers](https://github.com/hibayesian/awesome-automl-papers).'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由马克·林博士发起的GitHub网页，提供了一份精选的AutoML论文和其他资源的列表：[https://github.com/hibayesian/awesome-automl-papers](https://github.com/hibayesian/awesome-automl-papers)。
- en: 'The GitHub web page started by Wayne Wei, which curates a list of AutoML-related
    literature and toolkits: [https://github.com/windmaple/awesome-AutoML](https://github.com/windmaple/awesome-AutoML)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由韦恩·韦发起的GitHub网页，整理了一份AutoML相关文献和工具包的列表：[https://github.com/windmaple/awesome-AutoML](https://github.com/windmaple/awesome-AutoML)
- en: 'Besides these reference websites, we also recommend the following three sites
    where you can search for and stay up to date with the latest AutoML research papers
    or practice with some of the code and implementations on real-world applications:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些参考网站，我们还推荐以下三个网站，你可以在这些网站上搜索最新的AutoML研究论文，或者在实际应用中练习一些代码和实现：
- en: arXiv ([https://arxiv.org](https://arxiv.org)) is an open-access preprint server
    for scientific research papers. Researchers in the ML community often post their
    findings or research ideas here, before their papers are even published. Though
    monitoring the vast numbers of papers on the site may be overwhelming, it’s still
    a good channel, allowing you to keep track of new findings in AutoML.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: arXiv ([https://arxiv.org](https://arxiv.org)) 是一个开放获取的科研论文预印本服务器。机器学习领域的科研人员经常在这里发布他们的发现或研究想法，甚至在他们的论文发表之前。尽管监控网站上大量的论文可能会让人感到压力山大，但这仍然是一个不错的渠道，让你能够跟踪AutoML领域的新发现。
- en: Papers with Code ([https://paperswithcode.com/](https://paperswithcode.com/))
    curates papers with free open source code for ML. You can browse cutting-edge
    AutoML papers as well as explore example code and datasets for learning and practicing.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Papers with Code ([https://paperswithcode.com/](https://paperswithcode.com/))
    精选了带有免费开源代码的机器学习论文。你可以浏览前沿的AutoML论文，以及探索用于学习和实践的学习示例代码和数据集。
- en: Kaggle ([https://kaggle.com](https://kaggle.com)) is an online community for
    data science and ML practitioners where participants can publish datasets, organize
    competitions, and solve data challenges with ML models. By participating in these
    competitions and learning about other practitioners’ ML or AutoML solutions for
    different tasks, you’ll gain a deeper understanding of ML models and AutoML techniques.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaggle ([https://kaggle.com](https://kaggle.com)) 是一个面向数据科学和机器学习实践者的在线社区，参与者可以发布数据集，组织比赛，并使用机器学习模型解决数据挑战。通过参与这些比赛并了解其他实践者在不同任务上的机器学习或AutoML解决方案，你将更深入地理解机器学习模型和AutoML技术。
- en: AutoML hasn’t been on the horizon for long, but without a doubt, it’s an important
    step toward general AI. Full automation of all ML problems is possible in the
    long term, but it’s unlikely to happen in the near future. We may be at the peak
    of the inflated expectations for AutoML, and the path to general AI still holds
    many challenges. Its development heavily relies on the participation of researchers,
    developers, and practitioners from many different domains. We encourage you to
    continue on your way toward learning about, using, questioning, and developing
    AutoML, which can be a lifelong journey. Although many people think that democratizing
    AI may render human experts useless, to be substituted by AI agents, we believe
    that the wisdom of machines will never completely transcend that of human beings,
    and instead we will grow and learn together. All in all, we can only imagine what
    the future will bring, based on what we know today—but when we look back to the
    past and how people imagined their futures then, we often find today’s reality
    is beyond their wildest dreams.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML 并非遥不可及，无疑，它是迈向通用人工智能的重要一步。长期来看，所有机器学习问题的完全自动化是可能的，但短期内不太可能实现。我们可能正处于对AutoML过度期望的顶峰，通往通用人工智能的道路仍然充满挑战。其发展高度依赖于来自多个不同领域的科研人员、开发者和实践者的参与。我们鼓励你继续你的AutoML学习之旅，包括使用、质疑和开发AutoML，这可以是一段终身的旅程。尽管许多人认为，民主化人工智能可能会使人类专家变得无用，被人工智能代理所取代，但我们相信，机器的智慧永远不会完全超越人类的智慧，相反，我们将共同成长和学习。总的来说，我们只能根据我们今天所知道的情况来想象未来会带来什么——但当我们回顾过去，看看人们当时是如何想象他们的未来的，我们常常发现今天的现实已经超越了他们的最狂野的梦想。
- en: Summary
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter summarized the core concepts you’ve learned in this book. We hope
    you’ve learned a thing or two about AutoML and how to apply it with the help of
    AutoKeras and KerasTuner, as well as caught a tempting glimpse of machine learning
    from the AutoML perspective.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章总结了你在本书中学到的核心概念。我们希望你已经从AutoML以及如何使用AutoKeras和KerasTuner来应用它中学到了一些东西，同时也对从AutoML视角看机器学习有了诱人的瞥见。
- en: An increasing number of open source and commercial AutoML toolkits have been
    proposed, and research in this area is active. These tools help democratize ML
    techniques to diverse research areas and industrial applications.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 越来越多的开源和商业AutoML工具包被提出，该领域的研究活跃。这些工具帮助将机器学习技术民主化到不同的研究领域和工业应用中。
- en: AutoML is still in its early stages, with a huge space of possibilities to be
    discovered and limitations to be addressed. We encourage you to learn from the
    provided resources to continue your exploration in this field and never stop moving
    toward understanding the mysteries of AutoML.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoML仍处于早期阶段，存在着巨大的可能性空间等待被发现，以及需要解决的局限性。我们鼓励您从提供的资源中学习，继续在这个领域进行探索，并且永远不要停止向理解AutoML奥秘迈进。
