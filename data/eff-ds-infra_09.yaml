- en: 9 Machine learning with the full stack
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 全栈机器学习
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Developing a custom framework that makes it easier to develop models and features
    for a particular problem domain
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发一个定制框架，使其更容易为特定问题域开发模型和功能
- en: Training a deep learning model in a workflow
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在工作流中训练深度学习模型
- en: Summarizing the lessons learned in this book
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总结本书学到的经验教训
- en: 'We have now covered all layers of the infrastructure stack, shown in figure
    9.1, except the topmost one: model development. We only scratched the surface
    of the feature engineering layer in chapter 7\. Isn’t it paradoxical that a book
    about machine learning and data science infrastructure spends so little time talking
    about the core concerns of machine learning: models and features?'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经涵盖了基础设施堆栈的所有层级，如图9.1所示，除了最顶层：模型开发。我们在第7章中只是触及了特征工程层。难道不是一种矛盾吗？一本关于机器学习与数据科学基础设施的书，却花了这么少的时间讨论机器学习的核心问题：模型和特征？
- en: 'The focus is deliberate. First, many excellent books already exist about these
    topics. Mature modeling libraries like TensorFlow and PyTorch come with a plethora
    of in-depth documentation and examples. As depicted in figure 9.1, these topics
    tend to be the core areas of expertise of professional data scientists and machine
    learning engineers, whereas the lower layers are not. To boost the day-to-day
    productivity of data scientists effectively, it makes sense to help them where
    help is needed the most: the lower layers of the stack.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这种关注是有意为之的。首先，关于这些主题已经存在许多优秀的书籍。成熟的建模库，如TensorFlow和PyTorch，都附带大量的深入文档和示例。如图9.1所示，这些主题往往是专业数据科学家和机器学习工程师的核心专业领域，而底层则不是。为了有效地提高数据科学家的日常生产力，有道理的是在需要帮助的地方提供帮助：堆栈的底层。
- en: '![CH09_F01_Tuulos](../../OEBPS/Images/CH09_F01_Tuulos.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F01_Tuulos](../../OEBPS/Images/CH09_F01_Tuulos.png)'
- en: Figure 9.1 Infrastructure stack with the data scientist’s areas of interest
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 基础设施堆栈与数据科学家的兴趣领域
- en: Also, the topmost layers tend to be very application-specific in contrast to
    the lower layers. For instance, the models and features required by a computer
    vision application are very different from those used for balancing marketing
    budgets. However, they both can use the same approach for accessing data from
    the cloud, running and orchestrating containers, and versioning and tracking projects.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，最顶层往往比底层更具有应用特定性。例如，计算机视觉应用所需的模型和特征与用于平衡营销预算的模型和特征非常不同。然而，它们都可以使用相同的方法从云中访问数据、运行和编排容器，以及版本控制和跟踪项目。
- en: Out of the four Vs discussed in chapter 1—volume, velocity, validity, and variety—it
    is the last one that’s hardest to address with a standardized solution. If the
    infrastructure addresses the first three Vs well, it becomes feasible to develop
    and deploy a wide variety of use cases, even when each project comes with its
    own data pipelines, bespoke models, and custom business logic.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章讨论的四个“V”中——体积、速度、有效性和多样性——最后一个最难用标准化的解决方案来解决。如果基础设施能够很好地解决前三个“V”，那么开发并部署各种用例就变得可行，即使每个项目都带有自己的数据管道、定制模型和自定义业务逻辑。
- en: Going back to another theme discussed in chapter 1, we can minimize accidental
    complexity caused by boilerplate code that deals with data, compute, and orchestration
    by providing a common, low-overhead solution to the lower layers of the stack.
    At the same time, we can accept the fact that real-world use cases come with some
    amount of inherent complexity, which the top layers need to manage. Not everything
    can be abstracted away.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 回到第一章讨论的另一个主题，我们可以通过为堆栈的底层提供一种通用、低开销的解决方案来最小化由处理数据、计算和编排的样板代码引起的意外复杂性。同时，我们可以接受这样一个事实：现实世界的用例都伴随着一定程度的固有复杂性，这是顶层需要管理的。并非所有东西都可以抽象化。
- en: Building on what you have learned in this book, you can design your own libraries
    that support modeling and feature engineering for your specific use cases, which
    further helps to keep complexity in check. In the same way that traditional software
    leverages features and services provided by an operating system like OS X or Linux,
    your libraries can treat the lower layers of the stack as an operating system
    for any data-intensive applications. However, you don’t need to rush into doing
    this. It is a good idea to build a few applications without any special abstractions
    to better understand if and where common patterns exist that would benefit from
    extra support and standardization.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书所学的基础上，你可以设计自己的库来支持特定用例的建模和特征工程，这有助于进一步控制复杂性。就像传统软件利用由操作系统如OS X或Linux提供的特性和服务一样，你的库可以将堆栈的底层视为任何数据密集型应用程序的操作系统。然而，你不需要急于这样做。先构建几个没有任何特殊抽象的应用程序是一个好主意，这样你就能更好地理解是否存在可以从额外支持和标准化中受益的常见模式。
- en: To show how all these concepts work together, including a custom library to
    support model development, the next section walks through a realistic project
    that touches all layers of the stack. After the comprehensive example, we conclude
    the book by summarizing the lessons learned throughout the book. You can find
    all code listings for this chapter at [http://mng.bz/N6d7](http://mng.bz/N6d7).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示所有这些概念是如何协同工作的，包括一个支持模型开发的定制库，下一节将带您通过一个涉及堆栈所有层的真实项目。在全面示例之后，我们通过总结本书学到的经验来结束本书。您可以在[http://mng.bz/N6d7](http://mng.bz/N6d7)找到本章的所有代码列表。
- en: 9.1 Pluggable feature encoders and models
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 可插拔的特征编码器和模型
- en: 'This section will expand the taxi-trip cost prediction example we started in
    chapter 7\. Our original version was very naive. We used linear regression to
    predict the price based on one variable: the distance traveled. You can probably
    spot at least one glaring issue in this model: the duration of the trip matters
    in addition to the distance.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将扩展我们在第7章开始讨论的出租车行程成本预测示例。我们的原始版本非常简单。我们使用线性回归根据一个变量：行程距离来预测价格。你可能会在这个模型中至少发现一个明显的问题：行程的持续时间除了距离外也很重要。
- en: Let’s imagine predicting trip prices accurately is a real business challenge.
    What would a realistic solution look like? For starters, it is unlikely that you
    would know the optimal solution to a real-life business problem from the get-go.
    To find a working solution, you have to experiment with a number of models and
    features, testing their performance through multiple iterations. You would certainly
    use more than one variable for prediction, so you would likely spend a good amount
    of time designing and implementing suitable features. Likely, you would test the
    features with different model architectures, too.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象准确预测行程价格是一个真正的商业挑战。一个现实解决方案会是什么样子？首先，你不太可能一开始就知道现实生活中的商业问题的最佳解决方案。为了找到一个可行的解决方案，你必须对多个模型和特征进行实验，通过多次迭代测试它们的性能。你肯定会使用多个变量进行预测，因此你可能会花大量时间设计和实现合适的特征。很可能，你也会用不同的模型架构测试这些特征。
- en: Also, real-life data is often lacking. As shown by the example in chapter 7,
    you can get reasonably good results with a simple model when high-quality features,
    like the actual distance of the trip, are available. What if our application doesn’t
    have access to the taxi meter or the car’s odometer but only to the rider’s smartphone?
    Maybe we know only the location of pick-up and drop-off, and we have to predict
    the price without knowing the exact distance traveled, which we will practice
    later.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，现实生活中的数据往往不足。正如第7章中的示例所示，当有高质量的特征，如实际行程距离时，使用简单模型可以得到相当好的结果。如果我们的应用程序无法访问出租车计费器或汽车的里程表，而只有乘客的智能手机怎么办？也许我们只知道接车和下车的位置，我们必须在不知道确切行驶距离的情况下预测价格，这我们将在后面练习。
- en: In this section, we will develop a more advanced model in a more realistic setting.
    Because we know we will need to iterate on multiple models and features—maybe
    we have a team of data scientists working on the problem—we standardize the model
    development setup by implementing a simple framework that allows us to plug in
    custom feature encoders and test various models flexibly.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将在一个更现实的设置中开发一个更高级的模型。因为我们知道我们需要在多个模型和特征上进行迭代——也许我们有一个数据科学家团队在解决这个问题——我们通过实现一个简单的框架来标准化模型开发设置，这个框架允许我们插入自定义特征编码器并灵活地测试各种模型。
- en: Using the framework, we develop features that use geographic locations to predict
    the price. To make this possible, we upgrade our model from the 1950s-style linear
    regression to a 2020s-style deep learning model built with Keras and TensorFlow.
    To validate our model, we put together a benchmark that compares the performance
    of various modeling approaches. As before, we access the raw data directly from
    a public S3 bucket.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用该框架，我们开发了使用地理位置来预测价格的特征。为了实现这一点，我们将我们的模型从20世纪50年代的线性回归升级到2020年代的深度学习模型，该模型使用Keras和TensorFlow构建。为了验证我们的模型，我们创建了一个基准，比较了各种建模方法的性能。与之前一样，我们直接从公共S3存储桶访问原始数据。
- en: 9.1.1 Developing a framework for pluggable components
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 开发可插拔组件的框架
- en: 'We have a few different ideas for the kinds of models and features that might
    perform well for the price-prediction task. We want to quickly prototype and evaluate
    them to determine the most promising approach. Technically, we could implement
    each idea as a separate workflow from scratch, but we would likely notice that
    many approaches for the task follow a similar pattern: they all load raw data,
    split it to train and test sets, run feature encoders, train a model, and evaluate
    it using the test data. The implementation of the model and the feature encoders
    varies but not the overall structure of the workflow.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有几个关于可能对价格预测任务表现良好的模型和特征的想法。我们希望快速原型设计和评估它们，以确定最有前途的方法。技术上，我们可以从头开始将每个想法实现为一个单独的工作流程，但我们可能会注意到，许多针对该任务的方案遵循一个类似的模式：它们都加载原始数据，将其分为训练集和测试集，运行特征编码器，训练模型，并使用测试数据进行评估。模型和特征编码器的实现各不相同，但工作流程的整体结构是相同的。
- en: To make the model development process more efficient, we implement the common
    pattern as a shared workflow, which allows different feature encoders and models
    to be plugged in easily. The approach is similar to how we compared various algorithms
    for computing a co-occurrence matrix in chapter 5\. Figure 9.2 illustrates the
    approach.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使模型开发过程更高效，我们将常见的模式实现为一个共享工作流程，这使得不同特征编码器和模型可以轻松插入。这种方法与我们在第5章中比较计算共现矩阵的各种算法的方法类似。图9.2展示了这种方法。
- en: '![CH09_F02_Tuulos](../../OEBPS/Images/CH09_F02_Tuulos.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F02_Tuulos](../../OEBPS/Images/CH09_F02_Tuulos.png)'
- en: Figure 9.2 Pluggable models and feature encoders (light gray) inside a shared
    workflow
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2：共享工作流程中的可插拔模型和特征编码器（浅灰色）
- en: 'To implement a new modeling approach, the scientist needs to develop three
    components, shown as light gray boxes in figure 9.2: first, feature encoders that
    turn raw input data, facts, to features. To make featurization efficient, we can
    parallelize it over multiple shards of data. Second, after all shards have been
    processed, we can merge the feature shards into an input dataset for the model.
    You may recognize this approach as the MapReduce pattern we introduced in chapter
    7\. Third, we need a set of functions to train a model.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现一种新的建模方法，科学家需要开发三个组件，如图9.2中的浅灰色框所示：首先，将原始输入数据、事实转换为特征的特性编码器。为了使特性化更高效，我们可以将它们并行化处理多个数据分片。其次，在所有分片都被处理之后，我们可以将特性分片合并为模型的输入数据集。你可能已经认识到了这种方法，就是我们第7章中介绍的MapReduce模式。第三，我们需要一组函数来训练模型。
- en: 'These three components can be implemented as pluggable modules. We develop
    two separate workflows to execute the plugins: one to process the features, and
    another to train a model. By keeping the data and training separate, we make it
    possible to schedule them independently. For instance, you can use the shared
    featurization workflow to produce data for a batch prediction workflow, if you
    want to follow the batch prediction pattern introduced in chapter 8\. Following
    this pattern, you could, say, retrain a model daily and price new data hourly.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个组件可以作为可插拔模块来实现。我们开发了两个独立的流程来执行插件：一个用于处理特征，另一个用于训练模型。通过将数据和训练分离，我们使得它们可以独立调度。例如，如果你想遵循第8章中介绍的批量预测模式，你可以使用共享的特征化工作流程来为批量预测工作流程生成数据。
- en: 'In Python, we typically define various implementations of the same interface
    as separate classes. Let’s start by defining the interfaces of the three components:
    *encoder*, *merge*, and *model training*. A feature encoder needs to implement
    two methods: encode, which converts a shard of input data—that is, a fact shard—represented
    as a PyArrow table, to a feature shard. The shards are then provided to another
    method, merge, which merges the shards into a dataset that can be processed by
    a model. Figure 9.3 illustrates the role of the two functions.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，我们通常将同一接口的不同实现定义为单独的类。让我们首先定义三个组件的接口：*编码器*、*合并*和*模型训练*。特征编码器需要实现两个方法：encode，它将一个输入数据碎片（即事实碎片）——表示为
    PyArrow 表——转换为特征碎片。然后，碎片被提供给另一个方法，merge，该方法将碎片合并成一个可以由模型处理的数据集。图 9.3 阐述了这两个函数的作用。
- en: '![CH09_F03_Tuulos](../../OEBPS/Images/CH09_F03_Tuulos.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F03_Tuulos](../../OEBPS/Images/CH09_F03_Tuulos.png)'
- en: Figure 9.3 Encoding sharded input data first to features and then to a merged
    dataset
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 首先将碎片化输入数据编码为特征，然后合并成数据集
- en: An encode function can output multiple named features, shown as A-D in figure
    9.3, which are output as a dictionary where the key is a feature name and the
    value is a data structure, chosen by the encoder, which stores the features. Our
    current code expects that all shards produce the same set of features, but as
    an exercise, you can change the code to relax that requirement. The merge function
    gets all feature shards as its inputs and chooses how to combine them to produce
    a final dataset.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 编码函数可以输出多个命名特征，如图 9.3 中的 A-D 所示，这些特征作为字典输出，其中键是特征名称，值是编码器选择的数据结构，用于存储特征。我们当前的代码期望所有碎片产生相同的一组特征，但作为一个练习，你可以更改代码以放宽这一要求。merge
    函数接收所有特征碎片作为输入，并选择如何将它们组合以生成最终数据集。
- en: Defining a feature encoder
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 定义特征编码器
- en: Many models can read data efficiently as NumPy arrays, so we start by defining
    a template for encoders that output NumPy arrays. The next listing shows a general-purpose
    superclass—a class that specific encoders can derive from—that expects that the
    encode function outputs a NumPy array. It takes care of merging NumPy arrays produced
    in shards without being opinionated about what the arrays contain exactly.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 许多模型可以高效地读取作为 NumPy 数组的数据，因此我们首先定义一个输出 NumPy 数组的编码器模板。接下来的列表显示了一个通用超类——一个特定编码器可以从中派生的类，它期望编码函数输出一个
    NumPy 数组。它负责合并碎片中产生的 NumPy 数组，而不对数组包含的确切内容有任何偏见。
- en: Listing 9.1 Feature encoder superclass that handles NumPy arrays
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.1 处理 NumPy 数组的特征编码器超类
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Defines the methods as class methods, so they can be used without instantiating
    the class
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将方法定义为类方法，因此可以在不实例化类的情况下使用它们
- en: ❷ Accepts a shard of facts as a PyArrow table
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 接受一个事实碎片作为 PyArrow 表
- en: ❸ Encoders will override this method to produce NumPy arrays with features.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 编码器将覆盖此方法以生成包含特征的 NumPy 数组
- en: ❹ Accepts a list of feature shards
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 接受一个特征碎片的列表
- en: ❺ Concatenates feature shards into one large array
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将特征碎片连接成一个大的数组
- en: ❻ Loops through all features
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 遍历所有特征
- en: We will be creating a number of small modules, so let’s create a dedicated directory
    for them, taxi_modules. Save the code in taxi_modules/numpy_encoder.py.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建许多小模块，因此让我们为它们创建一个专门的目录，taxi_modules。将代码保存到 taxi_modules/numpy_encoder.py。
- en: 'Next, let’s define a feature encoder that uses the NumpyArrayFeatureEncoder
    we just created. The encoder shown in the next listing will work as a baseline:
    it grabs the trip_distance column and the actual trip price, total_amount, from
    the dataset as-is, allowing us to compare the quality of our predictions that
    don’t use the distance feature directly.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们定义一个使用我们刚刚创建的 NumpyArrayFeatureEncoder 的特征编码器。下一个列表中显示的编码器将作为一个基准：它直接从数据集中获取行程距离列和实际行程价格、总金额，允许我们比较不直接使用距离特征的预测质量。
- en: Listing 9.2 Baseline feature encoder
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.2 基准特征编码器
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Reuses the merge method from NumpyArrayFeatureEncoder
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 重新使用来自 NumpyArrayFeatureEncoder 的合并方法
- en: ❷ Sets the encoder name
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 设置编码器名称
- en: ❸ Defines extra software dependencies for this encoder
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 为此编码器定义额外的软件依赖
- en: ❹ Defines what columns in the fact table should be cleaned
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 定义事实表中应清理的列
- en: ❺ Returns two features as NumPy arrays
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 返回两个特征作为 NumPy 数组
- en: 'Save the code in taxi_modules/feat_baseline.py. We will prefix all feature
    encoder modules with a feat_ prefix, so we can discover them automatically. The
    encoder defines a few top-level constants as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存到taxi_modules/feat_baseline.py中。我们将所有特征编码器模块的前缀设置为feat_，这样我们就可以自动发现它们。编码器定义了一些顶级常量，如下所示：
- en: NAME—Identifies this feature encoder.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NAME—标识这个特征编码器。
- en: FEATURE_LIBRARIES—Defines what extra software dependencies this encoder needs.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FEATURE_LIBRARIES—定义此编码器需要的额外软件依赖项。
- en: CLEAN_FIELDS—Determines what columns of the facts table need to be cleaned.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CLEAN_FIELDS—确定需要清理的事实表中的哪些列。
- en: The role of these constants will become more clear as we start using them. Next,
    let’s create a utility module that loads the plugins like the one defined earlier.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们开始使用这些常数，它们的作用将变得更加清晰。接下来，让我们创建一个实用模块，用于加载之前定义的插件。
- en: Packaging and loading plugins
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 打包和加载插件
- en: It should be possible to create a new feature or a model simply by adding a
    file in the taxi_modules directory. Based on the filename, we can determine whether
    the module is a feature encoder or a model. The following listing walks through
    all files in the taxi_modules directory, imports modules with an expected prefix,
    and makes them available through shared dictionaries.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 应该可以通过在taxi_modules目录中添加一个文件来简单地创建一个新的特征或模型。根据文件名，我们可以确定该模块是特征编码器还是模型。以下列表遍历taxi_modules目录中的所有文件，导入具有预期前缀的模块，并通过共享字典使它们可用。
- en: Listing 9.3 A flow with parameters
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.3 带参数的流程
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Maps model names to model classes
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将模型名称映射到模型类
- en: ❷ Maps feature encoder names to feature encoder classes
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将特征编码器名称映射到特征编码器类
- en: ❸ Records the libraries needed by encoders
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 记录编码器需要的库
- en: ❹ Records the libraries needed by models
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 记录模型需要的库
- en: ❺ Walks through all files in the taxi_modules directory
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 遍历taxi_modules目录中的所有文件
- en: ❻ Checks the file prefix
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 检查文件前缀
- en: ❼ Imports the module
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 导入模块
- en: ❽ Populates dictionaries containing encoders and models
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 填充包含编码器和模型的字典
- en: 'Save the code in taxi_modules/__init__.py. Note that the module needs to reside
    in the same directory with the feature encoders and models for the file discovery
    to work correctly. The filename __init__.py has a special meaning in Python: having
    an __init__.py file in a directory tells Python that the directory corresponds
    to a *Python package*. A Python package is a collection of modules that can be
    installed and imported as a unit. Read more about packages at [http://mng.bz/Dg8a](http://mng.bz/Dg8a).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存到taxi_modules/__init__.py中。请注意，该模块需要位于特征编码器和模型相同的目录中，以确保文件发现能够正确工作。Python中的__init__.py文件具有特殊含义：在目录中包含__init__.py文件告诉Python该目录对应一个*Python包*。Python包是一组可以作为一个单元安装和导入的模块。更多关于包的信息，请参阅[http://mng.bz/Dg8a](http://mng.bz/Dg8a)。
- en: 'Currently, our taxi_modules package (directory) contains the following files:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们的taxi_modules包（目录）包含以下文件：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We will be adding many more throughout the chapter. A benefit of arranging modules
    in a Python package is that you could publish and share it as a package that can
    be installed as any other Python package—imagine pip install taxi_modules or conda
    install taxi_modules. You can refer to [https://packaging.python.org/](https://packaging.python.org/)
    for detailed instructions. You could then include the package in your Metaflow
    projects using, say, the @conda decorator.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将添加更多内容。将模块组织成Python包的好处是，你可以将其发布并共享为一个可以像其他Python包一样安装的包——想象一下pip install
    taxi_modules或conda install taxi_modules。你可以参考[https://packaging.python.org/](https://packaging.python.org/)获取详细说明。然后，你可以使用，例如，@conda装饰器将包包含到你的Metaflow项目中。
- en: 'However, it is not necessary to publish the package. A simpler approach is
    to make sure that the package directory is adjacent to your flow scripts. For
    instance, a data science team could have a Git repository of the following structure:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，没有必要发布这个包。一个更简单的方法是确保包目录与你的流程脚本相邻。例如，一个数据科学团队可能有以下结构的Git仓库：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this case, flow1, flow2, and flow3 all have access to the shared taxi_modules
    package automatically, thanks to the fact that Metaflow packages all subdirectories
    automatically as described in chapter 6.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，flow1、flow2和flow3都可以自动访问共享的taxi_modules包，这得益于Metaflow在第六章中描述的自动将所有子目录作为包打包的事实。
- en: Recommendation If you have a relatively stable package that data scientists
    don’t have to modify as they work on their flows, you can package and publish
    it as a normal Python package, which can be included in flows like any other third-party
    library using @conda. If data scientists are expected to iterate rapidly on the
    contents of the package as a part of their projects, like in the case of feature
    encoders of this example, you can make the prototyping loop much smoother by including
    the package as a subdirectory, which Metaflow versions automatically.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 建议：如果您有一个相对稳定的包，数据科学家在处理他们的流程时不需要修改，您可以将其打包并作为正常的 Python 包发布，这样就可以使用 @conda
    将其包含在流程中，就像任何其他第三方库一样。如果预计数据科学家需要作为他们项目的一部分快速迭代包的内容，例如本例中的特征编码器，您可以通过将其作为子目录包含进来，使原型设计循环更加平滑，Metaflow
    版本会自动处理。
- en: 9.1.2 Executing feature encoders
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 执行特征编码器
- en: We are almost ready to start executing feature encoders. Before defining a flow
    to do that, we need two more utility modules. First, to preprocess facts, we use
    the utility functions from table_utils.py, which we introduced in chapter 7\.
    The next code sample shows the module again.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎准备好开始执行特征编码器了。在定义一个流程来执行此操作之前，我们需要两个额外的实用模块。首先，为了预处理事实，我们使用第 7 章中介绍的 table_utils.py
    中的实用函数。下一个代码示例再次展示了该模块。
- en: Listing 9.4 Removing outlier rows from an Arrow table
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.4 从 Arrow 表中删除异常行
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Accepts a pyarrow.Table and a list of columns to be cleaned
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 接受一个 pyarrow.Table 和一个要清理的列列表
- en: ❷ Starts with a filter that accepts all rows
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从接受所有行的过滤器开始
- en: ❸ Processes all columns one by one
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 逐个处理所有列
- en: ❹ Finds the top and bottom 2% of the value distribution
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 找到值分布的顶部和底部 2%
- en: ❺ Includes only rows that fall between 2-98% of the value distribution
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 只包含落在 2-98% 值分布之间的行
- en: ❻ Returns a subset of the rows that match the filter
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 返回与过滤器匹配的行子集
- en: ❼ Samples a random p% of rows of the given table
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 从给定表中随机采样 p% 的行
- en: ❽ Flips a biased coin on each row and returns the matching rows
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 在每一行上抛一个有偏的硬币并返回匹配的行
- en: Save the code in taxi_modules/table_utils.py. For more details about how these
    functions work, refer to chapter 7.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存在 taxi_modules/table_utils.py 中。有关这些函数如何工作的更多详细信息，请参阅第 7 章。
- en: 'Second, we define a helper module that executes the feature encoders. Listing
    9.5 shows a module with two functions: execute preprocesses the facts table by
    cleaning all fields listed in CLEAN_FIELDS. It also takes a sample of input rows,
    if sample_rate is smaller than 1.0\. After this, it executes all the discovered
    feature encoders, supplying them with the fact table. The merge function takes
    two lists of shards, features for training and testing separately, and merges
    each feature using the merge function specified by its encoder.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们定义一个辅助模块来执行特征编码器。列表 9.5 展示了一个包含两个函数的模块：execute 首先通过清理 CLEAN_FIELDS 中列出的所有字段来预处理事实表。它还接受一个输入行的样本，如果
    sample_rate 小于 1.0。在此之后，它执行所有发现的特征编码器，并为他们提供事实表。合并函数接受两个碎片列表，分别为训练和测试的特征，并使用由其编码器指定的合并函数合并每个特征。
- en: Listing 9.5 Executing feature encoders
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.5 执行特征编码器
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Imports discovered features
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 导入发现的特征
- en: ❷ Applies feature encoders to the fact table
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将特征编码器应用于事实表
- en: ❸ Produces a set of fields that need to be cleaned
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 生成需要清理的一组字段
- en: ❹ Cleans and samples facts
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 清理并采样事实
- en: ❺ Iterates over all encoders
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 遍历所有编码器
- en: ❻ Executes an encoder
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 执行一个编码器
- en: ❼ Merges training and test data separately
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 分别合并训练和测试数据
- en: ❽ Iterates over all features
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 遍历所有特征
- en: ❾ Merges feature shards for a feature
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 合并一个特征的特性碎片
- en: Save the code in taxi_modules/encoders.py. Now we have the machinery ready for
    pluggable feature encoders!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存在 taxi_modules/encoders.py 中。现在我们已经准备好了可插拔特征编码器的机制！
- en: We can put together a workflow, shown in listing 9.6, that discovers data, produces
    features for shards of data in parallel, and finally merges a final dataset. The
    structure of the workflow is similar to TaxiRegressionFlow from chapter 7, except
    that this time, we don’t hardcode features in the workflow itself but let plugins
    specify them. This way, data scientists can reuse the same workflow—making sure
    all results are comparable—and focus on developing new feature encoders and models.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以组合一个工作流程，如列表 9.6 所示，该工作流程发现数据，并行生成数据碎片的特征，并最终合并一个最终数据集。工作流程的结构类似于第 7 章中的
    TaxiRegressionFlow，但这次我们不在工作流程本身中硬编码特征，而是让插件指定它们。这样，数据科学家可以重用相同的流程——确保所有结果都是可比较的——并专注于开发新的特征编码器和模型。
- en: In this example, we will use two months of taxi trip data that was introduced
    in chapter 7, September and October 2014\. To test model performance, we use data
    from November. We will handle each month of data as a separate shard using foreach.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用第7章中介绍的两个月的出租车行程数据，即2014年9月和10月的数据。为了测试模型性能，我们使用11月的数据。我们将使用foreach将每个月的数据作为一个单独的分片来处理。
- en: Listing 9.6 Workflow that executes pluggable feature encoders
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.6 执行可插入特征编码器的工作流程
- en: '[PRE7]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Use two months of data for training
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用两个月的数据进行训练
- en: ❷ Tests with one month of data
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用一个月的数据进行测试
- en: ❸ Persists the set of features as artifacts for later analysis
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将特征集作为工件持久化，以供后续分析
- en: ❹ Discovers data shards
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 发现数据分片
- en: ❺ Ensures that libraries needed by encoders are available
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 确保编码器需要的库可用
- en: ❻ Downloads and decodes a shard
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 下载并解码分片
- en: ❼ Executes encoders for a shard
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 执行分片编码器
- en: ❽ Ensures the features artifact is available after the join step
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 确保在连接步骤之后特征工件可用
- en: ❾ Merges shards separately for train and test data
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 分别合并训练数据和测试数据的分片
- en: 'Save the code in taxi_regression_data.py next to (not inside) the taxi_modules
    directory. At this point, the directory structure should look like this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存到taxi_modules目录旁边（而不是内部），文件名为taxi_regression_data.py。此时，目录结构应该如下所示：
- en: '[PRE8]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can now test the workflow as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以按照以下方式测试工作流程：
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'It should print Processing features: baseline three times, once for each shard.
    If you are curious, you can open a notebook to inspect the train_data and test_data
    artifacts, which we will put in use soon.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 它应该打印“处理特征：基线”三次，每次对应一个分片。如果您好奇，可以打开一个笔记本来检查train_data和test_data工件，我们很快就会使用它们。
- en: 'If you have a compute layer like AWS Batch set up as discussed in chapter 4,
    you can execute the workflow in the cloud. For instance, you can try this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经像第4章中讨论的那样设置了计算层，例如AWS Batch，您可以在云中执行工作流程。例如，您可以尝试以下操作：
- en: '[PRE10]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As discussed earlier, this way you can scale the workflow to handle much larger
    datasets and produce the features faster, if needed.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这样您可以扩展工作流程以处理更大的数据集，并在需要时更快地生成特征。
- en: Pluggable encoders are the main exciting thing about this workflow. Let’s test
    how they work by creating another encoder. This time we create a feature that
    doesn’t depend on the trip_distance field in the input data—let’s assume our application
    doesn’t have it available or we don’t trust the taxi meter reading. Instead, we
    determine the distance traveled based on the coordinates of the pick-up and drop-off
    locations that are available in the fact table.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 可插入的编码器是这个工作流程中最令人兴奋的主要功能。让我们通过创建另一个编码器来测试它们是如何工作的。这次我们创建一个不依赖于输入数据中的trip_distance字段的特征——假设我们的应用程序没有它可用或者我们不信任出租车计价器的读数。相反，我们根据事实表中可用的接车和下车位置的坐标来确定行程距离。
- en: 'Our new feature, called Euclidean and defined in the next listing, measures
    the distance as a Euclidean distance between the locations. This is obviously
    inaccurate: taxi trips in a city are longer than a straight-line distance, and
    the earth is round, so we can’t use the simple Euclidean formula over long distances.
    However, as it is often the case, a simple approach with known deficiencies allows
    us to get started quickly.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的新特性，称为欧几里得距离，定义在下一列表中，它测量两个位置之间的欧几里得距离。这显然是不准确的：城市中的出租车行程通常比直线距离要长，而且地球是圆的，所以我们不能在长距离上使用简单的欧几里得公式。然而，正如通常情况那样，一个简单的方法，尽管有已知缺陷，也能让我们快速开始。
- en: Listing 9.7 Encoding Euclidean trip distance as a feature
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.7 将欧几里得行程距离编码为特征
- en: '[PRE11]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Extracts coordinates from the fact table
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从事实表中提取坐标
- en: ❷ Converts coordinates to NumPy arrays
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将坐标转换为NumPy数组
- en: ❸ Computes the Euclidean distance between the coordinates
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算坐标之间的欧几里得距离
- en: Save the code in taxi_modules/feat_euclidean.py. Note that the encoder performs
    all math using NumPy arrays, avoiding conversion to individual Python objects,
    which makes the encoder very performant—following the advice from chapter 5.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存到taxi_modules/feat_euclidean.py。请注意，编码器使用NumPy数组执行所有数学运算，避免了转换为单个Python对象，这使得编码器非常高效——遵循第5章的建议。
- en: 'After this, run the workflow again as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，再次按照以下方式运行工作流程：
- en: '[PRE12]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This time, you should see both Processing features: baseline and Processing
    features: euclidean. Adding a new feature was just a matter of writing the definition
    of the feature in listing 9.7—no changes in the workflow were needed. You can
    imagine multiple scientists collaborating and creating new features and models
    over time, which get evaluated and benchmarked using a shared workflow, ensuring
    the validity of results.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，你应该能看到两个处理特征：基线处理特征和欧几里得处理特征。添加新特征只需在列表9.7中编写特征的定义——不需要对工作流程进行任何更改。你可以想象多个科学家在一段时间内协作创建新的特征和模型，这些模型通过共享工作流程进行评估和基准测试，确保结果的可靠性。
- en: 'The modules in the taxi_modules directory demonstrated a useful pattern: we
    use the underlying general-purpose infrastructure and abstractions around it,
    like Metaflow, as the foundation. On top of it, we created a custom, domain-specific
    library, which makes it easier to iterate on a specific application—in this case,
    the trip price prediction. Figure 9.4 illustrates the pattern.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: taxi_modules目录中的模块演示了一个有用的模式：我们使用底层通用基础设施及其周围的抽象，如Metaflow，作为基础。在其之上，我们创建了一个定制的、特定领域的库，这使得针对特定应用（在这种情况下，是行程价格预测）进行迭代变得更加容易。图9.4说明了这种模式。
- en: '![CH09_F04_Tuulos](../../OEBPS/Images/CH09_F04_Tuulos.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F04_Tuulos](../../OEBPS/Images/CH09_F04_Tuulos.png)'
- en: Figure 9.4 A domain-specific library on top of the foundational infrastructure
    stack
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 基础基础设施堆栈之上的特定领域库
- en: This pattern allows you to handle a wide variety of use cases effectively. The
    general-purpose infrastructure can focus on foundational concerns, data, compute,
    orchestration, and versioning, whereas higher-level, domain-specific libraries
    can codify policies on how individual applications should be developed. It is
    also feasible to evolve the domain-specific libraries quickly as the needs of
    applications change while keeping the foundations stable.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式允许你有效地处理各种用例。通用基础设施可以专注于基础问题，如数据、计算、编排和版本控制，而高级、特定领域的库可以规范如何开发单个应用的策略。当应用的需求变化时，也可以快速演进特定领域库，同时保持基础稳定。
- en: Recommendation Use domain-specific libraries to codify application-specific
    policies and general-purpose infrastructure to handle low-level concerns. This
    way, you don’t need to optimize the whole stack for the needs of a specific use
    case.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 建议：使用特定领域库来规范应用特定的策略和通用基础设施来处理低级问题。这样，你就不需要针对特定用例优化整个堆栈。
- en: Now that we have a train and test datasets available, we can start benchmarking
    models. Similar to feature encoders, we want to be able to define new models easily
    as pluggable modules.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了训练和测试数据集，我们可以开始基准测试模型。与特征编码器类似，我们希望能够轻松地定义新的模型作为可插拔的模块。
- en: 9.1.3 Benchmarking models
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.3 基准测试模型
- en: 'For this project, we define a model as a combination of model architecture
    and training code, as well as a set of features. This allows us to test different
    model variants that use different feature sets easily. Similar to feature encoders,
    we define a common interface that all models must implement. The interface defines
    the following methods:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，我们将模型定义为模型架构和训练代码的组合，以及一组特征。这使得我们能够轻松地测试使用不同特征集的不同模型变体。与特征编码器类似，我们定义了一个所有模型都必须实现的通用接口。该接口定义了以下方法：
- en: fit(train_data) trains the model given the training data.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fit(train_data) 使用训练数据训练模型。
- en: mse(model, test_data) evaluates the model with test_data and returns the mean
    squared error measuring prediction accuracy.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: mse(model, test_data) 使用test_data评估模型，并返回衡量预测精度的均方误差。
- en: save_model(model) serializes the model to bytes.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: save_model(model) 将模型序列化为字节。
- en: load_model(blob) deserializes the model from bytes.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: load_model(blob) 从字节中反序列化模型。
- en: The last two methods are required to persist the model. By default, as described
    in chapter 3, Metaflow uses Python’s built-in serializer, Pickle, to serialize
    objects to bytes. Many machine learning models include their own serialization
    methods, which work more reliably than Pickle, so we allow model classes to use
    a custom serializer. Notably, the resulting bytes are still stored as a Metaflow
    artifact, so models are stored and accessed as any other workflow result.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个方法是必需的，用于持久化模型。默认情况下，如第3章所述，Metaflow使用Python内置序列化器Pickle将对象序列化为字节。许多机器学习模型包括它们自己的序列化方法，这些方法比Pickle更可靠，因此我们允许模型类使用自定义序列化器。值得注意的是，生成的字节仍然存储为Metaflow工件，因此模型存储和访问方式与其他任何工作流程结果相同。
- en: We start by defining a naive linear regression model that predicts the price
    using the actual distance, like the one we used in chapter 7\. We can compare
    other models that don’t rely on the actual_distance feature against this baseline.
    We will define code for a general-purpose regressor soon, but we start with a
    model specification, shown here.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义一个简单的线性回归模型，使用实际距离来预测价格，就像我们在第7章中使用的那样。我们可以将不依赖于actual_distance特征的模型与其他基准模型进行比较。我们将很快定义通用回归器的代码，但首先我们从一个模型规范开始，如下所示。
- en: Listing 9.8 Baseline linear regression model
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.8 基线线性回归模型
- en: '[PRE13]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Leverages a general-purpose regression model
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 利用通用回归模型
- en: ❷ Model name
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 模型名称
- en: ❸ Uses Scikit-Learn as the modeling library
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用Scikit-Learn作为建模库
- en: ❹ Requires a baseline feature encoder
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 需要基线特征编码器
- en: ❺ Uses the actual_distance variable to predict the price
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 使用actual_distance变量来预测价格
- en: Save the code in taxi_modules/model_baseline.py. Remember that listing 9.8 loads
    models from files that have the model_ prefix. The role of the FEATURES and regressor
    attributes becomes clearer in the context of the RegressionModel base class, which
    is defined in the next code sample.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存在taxi_modules/model_baseline.py中。请记住，列表9.8加载具有model_前缀的文件中的模型。在RegressionModel基类中，FEATURES和regressor属性的作用变得更加清晰，该类定义在下一个代码示例中。
- en: Listing 9.9 Superclass for linear regression models
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.9 线性回归模型的超类
- en: '[PRE14]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Fits a single-variable linear regression model using Scikit-Learn
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用Scikit-Learn拟合单变量线性回归模型
- en: ❷ Tests a single-variable linear regression model using Scikit-Learn
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用Scikit-Learn测试单变量线性回归模型
- en: ❸ Uses standard Python Pickle to serialize the model; nothing custom needed
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用标准的Python Pickle序列化模型；不需要任何自定义
- en: Save the code in taxi_modules/regression.py. The module defines a simple linear
    regression model using Scikit-Learn, which uses a single variable, defined in
    the regressor attribute, to predict the trip price, stored in the amount variable.
    We use Scikit-Learn’s mean_squared_error function to measure the model accuracy
    in the mse method. Nothing special is needed to serialize and deserialize the
    model in save_model and load_model, because Scikit-Learn models work well with
    Pickle.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存在taxi_modules/regression.py中。该模块定义了一个简单的线性回归模型，使用Scikit-Learn，它使用单个变量，定义在regressor属性中，来预测行程价格，存储在amount变量中。我们使用Scikit-Learn的mean_squared_error函数在mse方法中测量模型精度。在save_model和load_model中序列化和反序列化模型不需要任何特殊操作，因为Scikit-Learn模型与Pickle配合得很好。
- en: Model workflow
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 模型工作流程
- en: Let’s define a workflow to run the models. We allow each model to define the
    features they expect to be available. Only models that have all their features
    available are enabled. This way, models don’t fail randomly when you remove and
    add feature encoders during prototyping. The list of eligible models is determined
    in the start step. Figure 9.5 shows the structure of the workflow.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个工作流程来运行模型。我们允许每个模型定义它们期望可用的特征。只有所有特征都可用的模型才被启用。这样，在原型设计期间移除和添加特征编码器时，模型不会随机失败。合格模型的列表在启动步骤中确定。图9.5显示了工作流程的结构。
- en: '![CH09_F05_Tuulos](../../OEBPS/Images/CH09_F05_Tuulos.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F05_Tuulos](../../OEBPS/Images/CH09_F05_Tuulos.png)'
- en: 'Figure 9.5 The relationship between the two taxi workflows: Data and models'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.5 两个出租车工作流程之间的关系：数据和模型
- en: Each model, depicted by hypothetical models A, B, and C, are handled by a separate
    foreach branch. First, in the train step, we train a model using the train_data
    dataset produced by TaxiRegressionDataFlow. Then, in the eval step, we evaluate
    the model performance using test_data. In the join step, a summary of model evaluations
    is printed out. The next listing shows the code.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型，由假设的模型A、B和C表示，由一个单独的foreach分支处理。首先，在训练步骤中，我们使用TaxiRegressionDataFlow生成的train_data数据集训练一个模型。然后，在评估步骤中，我们使用test_data评估模型性能。在合并步骤中，打印出模型评估的摘要。下一个列表显示了代码。
- en: Listing 9.10 Workflow that executes pluggable models
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.10 执行可插拔模型的流程
- en: '[PRE15]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Accesses input data from the latest run of TaxiRegressionDataFlow
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从TaxiRegressionDataFlow的最新运行中访问输入数据
- en: ❷ Records features used by this run
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 记录本次运行使用的特征
- en: ❸ Determines which models can be executed based on their input features
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 根据它们的输入特征确定哪些模型可以执行
- en: ❹ Accesses training data
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 访问训练数据
- en: ❺ Trains the model
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 训练模型
- en: ❻ Saves the model in an artifact using a model-specific serializer
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 使用特定于模型的序列化器将模型保存在一个工件中
- en: ❼ Loads the model and deserializes it
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 加载模型并反序列化它
- en: ❽ Evaluates the model performance
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 评估模型性能
- en: ❾ Prints a summary of model scores
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 打印模型得分的摘要
- en: 'Save the code in taxi_regression_model.py. Because this flow accesses results
    produced by TaxiRegressionDataFlow, make sure you have run that flow first. At
    this point, the directory structure should look like this:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存到taxi_regression_model.py中。因为此流程访问由TaxiRegressionDataFlow生成的结果，请确保您已先运行该流程。此时，目录结构应该如下所示：
- en: '[PRE16]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You can run the flow as usual:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以像往常一样运行流程：
- en: '[PRE17]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You should see these lines in the output: Training model: distance_regression
    and Evaluating distance_regression. The final evaluation should look roughly as
    follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '你应该在输出中看到这些行：Training model: distance_regression和Evaluating distance_regression。最终的评估应该大致如下：'
- en: '[PRE18]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: To make things more interesting, let’s define another regression model that
    uses the Euclidean distance feature we defined earlier. See the next code listing.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使事情更有趣，让我们定义另一个使用我们之前定义的欧几里得距离特征的回归模型。请看下面的代码列表。
- en: Listing 9.11 Regression model that uses the Euclidean distance feature
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.11 使用欧几里得距离特征的回归模型
- en: '[PRE19]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Save the code in taxi_modules/model_euclidean.py, and run the workflow again
    as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存到taxi_modules/model_euclidean.py中，然后再次按照以下方式运行工作流程：
- en: '[PRE20]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This time, you should see two models being trained and evaluated in parallel:
    distance_regression and euclidean_regression. The output will look like the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，你应该会看到两个模型并行训练和评估：distance_regression和euclidean_regression。输出将如下所示：
- en: '[PRE21]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Not surprisingly, the mean squared error is higher for the model that uses Euclidean
    distance between the pick-up and drop-off locations to predict price, compared
    to the baseline model that uses the actual distance traveled. With these two models,
    we have established a solid baseline for future models. A more sophisticated model
    should be able to easily beat the performance of euclidean_regression. It would
    be great to get close to the performance of distance_regression just by relying
    on the location features. In the following section, we will build a much more
    sophisticated model to answer the challenge.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，使用起点和终点之间的欧几里得距离来预测价格的模型，其均方误差比使用实际行驶距离的基线模型要高。有了这两个模型，我们已经为未来的模型建立了一个坚实的基线。一个更复杂的模型应该能够轻松超越euclidean_regression的性能。如果能仅依靠位置特征就接近distance_regression的性能，那就太棒了。在下一节中，我们将构建一个更复杂的模型来应对这一挑战。
- en: 9.2 Deep regression model
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 深度回归模型
- en: If you have ever ridden in a taxi in a big city, you know that the Euclidean
    distance between two locations and even the actual route length can be bad predictors
    of the actual time it takes to complete the trip. Some locations are prone to
    traffic jams or are otherwise slow to travel through. A smart model would learn
    to recognize such slow spots based on historical data and estimate the price of
    the trip accordingly.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾在大城市乘坐过出租车，你就会知道两个地点之间的欧几里得距离甚至实际路线长度都可能不是完成行程所需实际时间的良好预测指标。一些地点容易发生交通堵塞或以其他方式行驶缓慢。一个智能模型会根据历史数据学习识别这些缓慢区域，并相应地估计行程价格。
- en: Let’s start by thinking how we can construct features that capture the notion
    of travel time and distance as a function of two locations. The first realization
    is that we don’t need an arbitrarily accurate location. The distance difference
    of a few city blocks typically doesn’t cause a systematic difference in price.
    Hence, instead of using exact coordinates, we can use a map grid, visualized in
    figure 9.6, to encode start and finish locations.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先思考如何构建能够捕捉两个地点的旅行时间和距离作为函数的特征。首先，我们不需要任意精确的位置。几个城市街区之间的距离差异通常不会导致价格的系统差异。因此，我们不是使用精确坐标，而是可以使用图9.6中可视化的地图网格来编码起点和终点位置。
- en: '![CH09_F06_Tuulos](../../OEBPS/Images/CH09_F06_Tuulos.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F06_Tuulos](../../OEBPS/Images/CH09_F06_Tuulos.png)'
- en: Figure 9.6 Hypothetical map grid over Manhattan
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6 曼哈顿的假设地图网格
- en: For instance, using the grid in figure 9.6, you can encode a trip between two
    locations as pairs of grid coordinates, such as A4-F2 and G7-B6\. Naturally a
    real-world application would use a more fine-grained grid than the one illustrated
    in the figure.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用图9.6中的网格，你可以将两个地点之间的行程编码为网格坐标对，例如A4-F2和G7-B6。当然，现实世界的应用会使用比图中展示的更精细的网格。
- en: How would you encode location pairs like this as features? We can treat grid
    locations like A4 and F2 as tokens or words, like we did with Yelp review clustering
    in chapter 5\. We could have a high-dimensional vector that represents each grid
    location as a separate dimension. We could then apply *multi-hot encoding* to
    mark the pick-up and drop-off locations as 1s and the other dimensions as 0s to
    produce a sparse trip vector. Figure 9.7 illustrates the idea.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 你会如何将这样的位置对编码为特征？我们可以将像A4和F2这样的网格位置视为标记或单词，就像我们在第5章中处理Yelp评论聚类时做的那样。我们可以有一个高维向量，代表每个网格位置作为一个单独的维度。然后我们可以应用*多热编码*来标记接车和下车位置为1，其他维度为0，从而产生一个稀疏的行程向量。图9.7说明了这个想法。
- en: '![CH09_F07_Tuulos](../../OEBPS/Images/CH09_F07_Tuulos.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F07_Tuulos](../../OEBPS/Images/CH09_F07_Tuulos.png)'
- en: Figure 9.7 Taxi trips encoded as multi-hot binary vectors
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7 将出租车行程编码为多热二进制向量
- en: An inconvenient detail about this approach is that we have to fix the dimensions,
    that is, the map grid, in advance. If we make the grid too small, we can’t handle
    trips outside the area. If we make it too big, the data becomes very sparse and
    possibly slow to process. Also, we must maintain a mapping between grid locations
    and the dimensions.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的一个不便之处在于，我们必须预先确定维度，即地图网格。如果我们使网格太小，我们无法处理区域外的行程。如果我们使它太大，数据就会变得非常稀疏，并且可能处理速度较慢。此外，我们必须维护网格位置和维度之间的映射。
- en: 'The same problem exists with any high-cardinality categorical variables. A
    well-known solution to the problem is *feature hashing*: instead of having a named
    dimension for each possible value, we produce a hash of each value and place them
    in a bin accordingly. Crucially, many fewer bins exist than distinct values originally.
    As long as the hash function stays consistent, the same value always ends up in
    the same bin, producing a multi-hot-encoded matrix with a fixed, lower dimensionality
    compared to the first approach. Figure 9.8 illustrates the idea.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 任何高基数分类变量都存在相同的问题。解决这个问题的著名方法之一是*特征哈希*：对于每个可能的值，我们不是为每个值创建一个命名的维度，而是生成每个值的哈希值，并相应地将其放入一个桶中。关键的是，桶的数量比原始的区分值要少得多。只要哈希函数保持一致，相同的值总是会落在同一个桶中，从而产生一个与第一种方法相比具有固定、较低维度的多热编码矩阵。图9.8说明了这个想法。
- en: '![CH09_F08_Tuulos](../../OEBPS/Images/CH09_F08_Tuulos.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F08_Tuulos](../../OEBPS/Images/CH09_F08_Tuulos.png)'
- en: Figure 9.8 Applying feature hashing to trip vectors
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.8 将特征哈希应用于行程向量
- en: In figure 9.8, we assume that hash(A4) = bin 2, hash(F2) = bin 4, and so forth.
    Notice that we could enlarge the grid and add, say, a coordinate A99 without affecting
    existing data, which is a benefit of the hashing approach. Also, we don’t have
    to explicitly store the mapping between coordinate labels and dimensions, making
    the implementation a bit simpler.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在图9.8中，我们假设hash(A4) = 桶2，hash(F2) = 桶4，等等。请注意，我们可以扩大网格并添加，比如说，坐标A99，而不会影响现有数据，这是哈希方法的一个好处。此外，我们不必显式存储坐标标签和维度之间的映射，这使得实现变得更加简单。
- en: When using hashing, we have no guarantee that two distinct values would always
    end up in distinct bins. It is possible that two distinct values end up in the
    same bin, causing random noise in the data. Despite this deficiency, feature hashing
    tends to work well in practice.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用哈希时，我们无法保证两个不同的值总是会落在不同的桶中。可能两个不同的值会落在同一个桶中，导致数据中出现随机噪声。尽管存在这种不足，特征哈希在实践中往往表现良好。
- en: 'Let’s assume that we want to test the idea of using a matrix of hashed grid-coordinate
    features, as shown in figure 9.8\. How should we encode and store the matrix in
    practice? We could build a feature encoder producing a suitable matrix without
    considering what model is going to consume it, but it doesn’t hurt to think through
    the problem end to end. Let’s look at the modeling problem at hand. Our model
    will be as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要测试使用哈希网格坐标特征矩阵的想法，如图9.8所示。在实际操作中，我们应该如何编码和存储这个矩阵呢？我们可以构建一个特征编码器，生成一个合适的矩阵，而不考虑将要使用它的模型，但思考整个问题的端到端是有益的。让我们看看手头的建模问题。我们的模型将如下所示：
- en: '*High-dimensional*—To keep the model reasonably accurate, grid cells should
    be in the range of hundreds of meters or less. Hence, an area of 100 square kilometers
    requires 10,000 grid cells, that is, 10,000 input dimensions.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*高维*——为了保持模型具有一定的准确性，网格单元应该在数百米或更小的范围内。因此，一个100平方公里的区域需要10,000个网格单元，即10,000个输入维度。'
- en: '*Large-scale*—We have tens of millions of trips in our input data that we can
    use to train the model.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*大规模*——在我们的输入数据中，我们有数千万的行程可以用来训练模型。'
- en: '*Nonlinear*—The relationship between the pick-up and drop-off locations and
    price is a complex function of various variables that we want to model.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*非线性*—接车和下车位置与价格之间的关系是各种变量的复杂函数，我们希望对其进行建模。'
- en: '*Sparse*—Trips are not spread uniformly over the map. We have limited data
    for some areas and plenty for others.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*稀疏*—行程在地图上不是均匀分布的。我们对某些地区的某些地区的数据有限，而对其他地区的数据则很充足。'
- en: '*Categorical regression model*—We use categorical variables, discrete locations
    on the map grid, to predict a continuous variable, the trip price.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分类回归模型*—我们使用分类变量，地图网格上的离散位置，来预测一个连续变量，即行程价格。'
- en: Given these characteristics, we may need something more powerful than a linear
    regression model. The scale and nonlinearity of the problem suggest that a deep
    learning model might be a suitable tool for the job. We choose to use Keras, an
    easy-to-use, popular package for deep learning, which is included in the TensorFlow
    package.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些特征，我们可能需要比线性回归模型更强大的东西。问题的规模和非线性表明，深度学习模型可能是这项工作的合适工具。我们选择使用 Keras，这是一个易于使用的、流行的深度学习包，它包含在
    TensorFlow 包中。
- en: Following the widely used nomenclature in the world of deep learning, we call
    the input matrices *tensors*. In this example, tensors behave pretty much like
    any other arrays, like NumPy arrays we have used earlier, so don’t let the fancy-sounding
    word scare you. In general, tensors can be thought of as multidimensional arrays
    that can be manipulated through well-defined mathematical operations. If you are
    curious, you can read more about them at [https://www.tensorflow.org/guide/tensor](https://www.tensorflow.org/guide/tensor).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 按照深度学习领域广泛使用的命名法，我们称输入矩阵为 *张量*。在这个例子中，张量表现得就像任何其他数组一样，比如我们之前使用的 NumPy 数组，所以不要让听起来很花哨的词吓到你。一般来说，张量可以被视为可以通过定义良好的数学操作进行操作的多维数组。如果你对此感兴趣，可以在
    [https://www.tensorflow.org/guide/tensor](https://www.tensorflow.org/guide/tensor)
    上了解更多关于它们的信息。
- en: Developing a high-quality deep neural network model involves art and science,
    as well as many rounds of trial and error. We trust that these topics are familiar
    to professional data scientists already, but if not, a plethora of high-quality
    online materials and books are already available. Hence, details of deep learning
    are out of the scope of this book. The goal of this book is to support data scientists
    who develop these models with effective infrastructure, like the scaffolding we
    have developed so far.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 开发高质量的深度神经网络模型涉及艺术和科学，以及许多次的试验和错误。我们相信这些主题对于专业数据科学家来说已经是熟悉的，但如果不是，已经有大量高质量的在线材料和书籍可供参考。因此，深度学习的细节超出了本书的范围。本书的目标是为开发这些模型的数据科学家提供有效的基础设施，比如我们迄今为止已经开发的脚手架。
- en: 9.2.1 Encoding input tensors
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 编码输入张量
- en: 'Let’s create a feature encoder that implements the previous idea. Our encoder
    should perform the following tasks:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个实现先前想法的特征编码器。我们的编码器应该执行以下任务：
- en: Convert coordinates to grid locations. We can use an off-the-shelf *geohashing*
    library, such as python-geohash, to accomplish this. Given a latitude and longitude
    pair, it produces a short string geotoken denoting the corresponding grid location.
    For more details about geohashes, see the Wikipedia article about the topic ([https://en.wikipedia.org/wiki/Geohash](https://en.wikipedia.org/wiki/Geohash)).
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将坐标转换为网格位置。我们可以使用现成的 *地理哈希* 库，例如 python-geohash，来完成这项工作。给定一对纬度和经度，它会产生一个表示相应网格位置的短字符串地理令牌。有关地理哈希的更多详细信息，请参阅维基百科上的相关文章([https://en.wikipedia.org/wiki/Geohash](https://en.wikipedia.org/wiki/Geohash))。
- en: Hash the geotokens to a fixed number of bins.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将地理令牌哈希到固定数量的桶中。
- en: Multi-hot-encode the bins to produce a sparse tensor.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将桶多热编码以生成稀疏张量。
- en: Merge and store feature shards, encoded as tensors, for subsequent use.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并并存储编码为张量的特征碎片，以供后续使用。
- en: 'You can tune the following two parameters in the encoder to adjust the resource
    consumption-accuracy tradeoff:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在编码器中调整以下两个参数来调整资源消耗-精度权衡：
- en: NUM_HASH_BINS—Determines the number of bins for feature hashing. The smaller
    the number, the more hash collisions and, hence, noise there will be in the data.
    On the other hand, a higher number will require a larger model, which is slower
    and more resource-consuming to train. You can experiment with a number that produces
    the best results—there isn’t a single right answer.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NUM_HASH_BINS—确定特征哈希的桶数。数字越小，哈希冲突越多，因此数据中的噪声也越多。另一方面，数字越大将需要更大的模型，这将使训练速度变慢且资源消耗更多。你可以尝试一个产生最佳结果的数字——没有唯一的正确答案。
- en: PRECISION—Determines the grain of the geohashes, that is, the grid size. The
    higher the number, the more accurate the locations are, but a higher number will
    require a higher NUM_HASH_BINS, too, to avoid collisions. Also, the higher the
    number, the more sparse the data will be, potentially hurting accuracy. The default
    PRECISION=6 corresponds to about 0.3 × 0.3-mile grid.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精度——确定geohash的粒度，即网格大小。数字越高，位置越准确，但数字越高也需要更高的NUM_HASH_BINS来避免冲突。此外，数字越高，数据越稀疏，可能会损害准确性。默认的PRECISION=6对应于大约0.3
    × 0.3英里网格。
- en: The encoder is implemented in the next listing.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器在下一列表中实现。
- en: Listing 9.12 Encoding hashed trip vectors as features
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 将列表9.12编码为特征的哈希行程向量
- en: '[PRE22]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Hashes geolocations to 10,000 bins
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 将地理定位哈希到10,000个桶
- en: ❷ Grid granularity
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 网格粒度
- en: ❸ Converts coordinates to grid locations
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 将坐标转换为网格位置
- en: ❹ Uses the geohash library to produce grid locations
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 使用geohash库生成网格位置
- en: ❺ Loops through all trips in the input table
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历输入表中的所有行程
- en: ❻ Produces a pair of geohashes for each trip
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 为每个行程生成一对geohash
- en: ❼ Stores the pairs in a list
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 将对存储在列表中的对进行存储
- en: ❽ Uses the Keras hashing layer to perform feature hashing
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Keras哈希层执行特征哈希
- en: ❾ Uses the Keras IntegerLookup layer to perform multi-hot encoding
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Keras IntegerLookup层执行多热编码
- en: ❿ Produces a tensor
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 生成一个张量
- en: ⓫ Merges tensors from feature shards into a large tensor
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 将特征碎片的张量合并到一个大张量中
- en: Save the code in taxi_modules/feat_gridtensor.py. For details about the Keras
    layers, Hashing and IntegerLookup, refer to the Keras documentation at [keras.io](https://keras.io/).
    In essence, they implement the hashing and multi-hot encoding ideas that we discussed
    earlier. In the case of tensors, the merge method can simply collate the shards
    in a dictionary. There’s no need to merge them in a large tensor, because we will
    feed the tensor to the model through a custom data loader, shown next.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存在taxi_modules/feat_gridtensor.py中。有关Keras层（哈希和IntegerLookup）的详细信息，请参阅Keras文档[keras.io](https://keras.io/)。本质上，它们实现了我们之前讨论的哈希和多热编码思想。在张量的情况下，合并方法可以简单地在一个字典中收集碎片。我们不需要将它们合并到一个大的张量中，因为我们将通过一个自定义数据加载器将张量喂给模型，如以下所示。
- en: Data loader
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加载器
- en: How to feed data into deep learning models efficiently is a deep topic of its
    own. A key challenge is that we may want to use GPUs to train the model, but a
    typical GPU doesn’t have enough memory to hold the whole dataset in GPU memory
    at once. To work around the limitation, we must feed data to the GPU in small
    batches.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如何有效地将数据喂入深度学习模型是一个深奥的话题。一个关键挑战是我们可能想使用GPU来训练模型，但典型的GPU没有足够的内存一次在GPU内存中存储整个数据集。为了克服这一限制，我们必须以小批量的方式将数据喂给GPU。
- en: The next listing shows a simple data loader that accepts features shards as
    tensor_ shards, produced by the merge method defined earlier. For training, we
    can specify a target variable, in our case a NumPy array containing the trip price,
    which is sliced and returned alongside the training data to the model.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 下一列表显示一个简单的数据加载器，该加载器接受由前面定义的合并方法产生的特征碎片作为tensor_碎片。对于训练，我们可以指定一个目标变量，在我们的例子中是一个包含行程价格的NumPy数组，该数组被切片并随训练数据一起返回给模型。
- en: Listing 9.13 Data loader for a Keras model
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.13 Keras模型的数据加载器
- en: '[PRE23]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Increase this value to speed up training.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 将此值增加以提高训练速度
- en: ❷ Defines the target variable for training; no target for testing
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 定义训练的目标变量；测试时没有目标
- en: ❸ Number of hash bins in input tensors
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 输入张量中的哈希桶数量
- en: ❹ Generates input batches with optional target vectors
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 生成带有可选目标向量的输入批次
- en: ❺ Converts the NumPy array to a tensor
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 将NumPy数组转换为张量
- en: ❻ Loops forever. Training code will stop when needed.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 无限循环。当需要时，训练代码将停止。
- en: ❼ Resets the target index after each epoch
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个epoch后重置目标索引
- en: ❽ Loops over all feature shards
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历所有特征碎片
- en: ❾ Resets the shard index
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 重置碎片索引
- en: ❿ Extracts batches from the shard until no more rows are left
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 从碎片中提取批次，直到没有更多行为止
- en: ⓫ Slices a batch from the shard
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 从碎片中切片一个批次
- en: ⓬ Gets the number of rows in the batch
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 获取批次的行数
- en: ⓭ If the batch is non-empty, yields it; otherwise, moves to the next shard
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果批次非空，则产生它；否则，移动到下一个碎片
- en: ⓮ Slices a vector from the target array
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 从目标数组中切片向量
- en: ⓯ If no target is specified, just returns input data
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未指定目标，则仅返回输入数据
- en: ⓰ Increments row indices to the next batch
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 增加行索引到下一个批次
- en: ⓱ Specifies the type of the input tensor
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 指定输入张量的类型
- en: ⓲ For testing, the dataset contains only input tensors.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 对于测试，数据集仅包含输入张量。
- en: ⓲ For training, the dataset also contains target vectors.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ⓲ 对于训练，数据集还包含目标向量。
- en: ⓳ Produces a dataset object wrapping the generator
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: ⓳ 生成一个封装生成器的数据集对象
- en: ⓴ Optimizes data access
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ⓴ 优化数据访问
- en: Save the code in taxi_modules/dnn_data.py. A slight complication is caused by
    the fact that the target is one large NumPy array, whereas training data is stored
    in multiple sparse tensor shards. We must make sure that features from both sources
    stay aligned. Figure 9.9 illustrates the situation.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存在taxi_modules/dnn_data.py中。一个轻微的复杂性是由于目标是一个大的NumPy数组，而训练数据存储在多个稀疏张量分片中。我们必须确保来自两个来源的特征保持对齐。图9.9展示了这种情况。
- en: '![CH09_F09_Tuulos](../../OEBPS/Images/CH09_F09_Tuulos.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F09_Tuulos](../../OEBPS/Images/CH09_F09_Tuulos.png)'
- en: Figure 9.9 Aligned batches between sharded tensors and a single NumPy target
    array
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.9 分片张量与单个NumPy目标数组之间的对齐批次
- en: 'Figure 9.9 illustrates three feature shards on the left and the target array
    on the right. Note how the last batch at the end of each shard, batches 5, 8,
    and 10, are smaller than the others. The sizes of feature shards are arbitrary
    and, hence, not always divisible by BATCH_SIZE. Listing 9.13 maintains two index
    variables: row to keep track of the row in the current shard, and idx to keep
    track of the index in the target array. The row index resets at each shard, whereas
    idx increments across shards.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.9展示了左侧的三个特征分片和右侧的目标数组。注意每个分片末尾的最后一个批次，即批次5、8和10，比其他批次小。特征分片的大小是任意的，因此不一定能被BATCH_SIZE整除。列表9.13维护了两个索引变量：row用于跟踪当前分片中的行，idx用于跟踪目标数组中的索引。行索引在每个分片时重置，而idx在分片间递增。
- en: Batches are returned by a generator function, data_loader, which loops over
    data forever. In the context of machine learning, one iteration over the whole
    dataset is commonly called an *epoch*. The training procedure runs over multiple
    epochs, optimizing the parameters of the model. Eventually, the training procedure
    hits a stopping condition, such as reaching a predefined number of epochs, and
    stops consuming data from the data loader.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 批次由一个生成器函数data_loader返回，该函数无限循环遍历数据。在机器学习的上下文中，整个数据集的一次迭代通常被称为一个*epoch*。训练过程在多个epoch上运行，优化模型的参数。最终，训练过程达到一个停止条件，例如达到预定义的epoch数，然后停止从数据加载器中消耗数据。
- en: The generator function is wrapped in a TensorFlow Dataset object that our Keras
    model is able to consume. We must manually specify the data types contained in
    the dataset. For training, the dataset contains tuples of a sparse sensor and
    a target variable. For testing, the dataset contains only sparse tensors.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器函数被封装在一个TensorFlow Dataset对象中，我们的Keras模型能够消费这个对象。我们必须手动指定数据集中包含的数据类型。对于训练，数据集包含稀疏传感器和目标变量的元组。对于测试，数据集只包含稀疏张量。
- en: 'Note the BATCH_SIZE parameter at the top of the file. Adjusting the batch size
    is one of the key knobs you can turn to fine-tune training performance: higher
    values will result in faster training, especially on GPUs, but the accuracy of
    the model may be hurt. In general, lower values lead to better accuracy at the
    cost of slower training time. Another small detail worth highlighting is the dataset.prefetch
    call at the end: this call instructs TensorFlow, which Keras uses under the hood,
    to load the next batch to GPU memory while a previous batch is being computed,
    giving a small boost to training performance.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 注意文件顶部的BATCH_SIZE参数。调整批次大小是你可以调整以微调训练性能的关键旋钮之一：更高的值将导致训练速度更快，尤其是在GPU上，但模型的准确性可能会受到影响。一般来说，较低的值会导致更好的准确性，但会以较慢的训练时间为代价。另一个值得强调的小细节是数据集.prefetch调用在末尾：这个调用指示TensorFlow（Keras在底层使用）在计算前一个批次的同时，将下一个批次加载到GPU内存中，从而为训练性能提供小幅提升。
- en: Now we have the machinery for producing input tensors that can be consumed by
    a custom data loader. The next step is to develop the model itself.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了可以由自定义数据加载器消费的输入张量的机制。下一步是开发模型本身。
- en: 9.2.2 Defining a deep regression model
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 定义深度回归模型
- en: To give you an idea of what a realistic model for our price-prediction task
    looks like, we define and train a deep neural network model in Keras. We show
    how to feed it with data, run it on GPUs, monitor its training, and evaluate its
    performance against other models. The example resembles the process that any data
    scientist developing a similar model would go through.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让你了解我们价格预测任务的实际模型看起来像什么，我们在 Keras 中定义并训练了一个深度神经网络模型。我们展示了如何用数据喂养它，在 GPU 上运行它，监控其训练，并评估其性能与其他模型。这个例子类似于任何开发类似模型的数据科学家都会经历的过程。
- en: For starters, we take care of some mundane bookkeeping matters. We start by
    defining two utility functions, load_model and save_model, which can be used to
    persist any Keras model. The KerasModel helper class we define in listing 9.14
    allows you to store models as artifacts, working around the fact that Keras models
    can’t be pickled by default.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们处理一些日常的账务问题。我们首先定义了两个实用函数，load_model 和 save_model，这些函数可以用来持久化任何 Keras 模型。我们在列表
    9.14 中定义的 KerasModel 辅助类允许你将模型作为工件存储，绕过 Keras 模型默认无法序列化的事实。
- en: The class leverages the built-in Keras functions to save and load a model to
    and from a file. We can’t use the Keras functions as-is, because local files won’t
    work across compute layers, for example, when you run -with batch. Also, we want
    to leverage Metaflow’s built-in versioning and datastore to keep track of models,
    which is easier than keeping local files organized manually.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 该课程利用内置的 Keras 函数将模型保存到文件和从文件加载。我们不能直接使用 Keras 函数，因为本地文件在计算层之间不会工作，例如，当你运行 -with
    batch 时。此外，我们希望利用 Metaflow 内置的版本控制和数据存储来跟踪模型，这比手动组织本地文件要容易得多。
- en: Listing 9.14 Superclass for Keras models
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.14 Keras 模型的超类
- en: '[PRE24]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: ❶ Saves the model to a temporary file
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将模型保存到临时文件
- en: ❷ Reads bytes representing the model from the temporary file
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从临时文件中读取表示模型的字节
- en: ❸ Writes bytes to a temporary file
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将字节写入临时文件
- en: ❹ Asks Keras to read the model from the temporary file
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 请求 Keras 从临时文件中读取模型
- en: Save the code in taxi_modules/keras_model.py. We can use these methods to handle
    any Keras model that subclasses KerasModel, like the one we define later.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存在 taxi_modules/keras_model.py 中。我们可以使用这些方法来处理任何子类 KerasModel 的 Keras 模型，就像我们稍后定义的那样。
- en: Next, we will define a model architecture for our nonlinear regression task
    in listing 9.15\. Although the listing presents a reasonable architecture, many
    others likely perform even better for this task. The process of finding an architecture
    that yields robust results involves a good amount of trial and error, the speeding
    up of which is a key motivation for data science infrastructure. As an exercise,
    you can try to find a better performing architecture, both when it comes to training
    speed as well as accuracy.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将为我们的非线性回归任务在列表 9.15 中定义一个模型架构。尽管列表展示了一个合理的架构，但许多其他架构可能在这个任务上表现更好。找到一个能够产生稳健结果的架构涉及大量的试错，加快这一过程是数据科学基础设施的关键动机。作为一个练习，你可以尝试找到一个性能更好的架构，无论是训练速度还是准确性。
- en: Listing 9.15 A flow with parameters
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.15 带参数的流程
- en: '[PRE25]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: ❶ Accepts the input tensor type signature as an argument
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 作为参数接受输入张量类型签名
- en: ❷ The input layer is shaped based on the input data signature.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 输入层根据输入数据签名进行形状定义。
- en: ❸ Defines the hidden layers
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定义隐藏层
- en: ❹ Target variable (trip price)
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 目标变量（行程价格）
- en: ❺ Minimizes mean squared error
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 最小化均方误差
- en: ❻ Accelerates processing on GPUs
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 加速 GPU 上的处理
- en: 'Save the code in taxi_modules/dnn_model.py. The model in listing 9.15 consists
    of a sparse input layer matching our input features, three hidden layers, and
    a dense output variable, representing the trip price we want to predict. Note
    that we compile the model with mean squared error as our loss function, which
    is the metric we care about. The steps_per_exeuction parameter speeds up processing
    on GPUs by loading multiple batches for processing at once. Next, we will specify
    a model plugin by putting together all the pieces we have developed this far as
    follows:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存在 taxi_modules/dnn_model.py 中。列表 9.15 中的模型由一个稀疏输入层组成，匹配我们的输入特征，三个隐藏层，以及一个密集输出变量，代表我们想要预测的行程价格。请注意，我们使用均方误差作为损失函数来编译模型，这是我们关心的指标。steps_per_exeuction
    参数通过一次加载多个批次来加速 GPU 上的处理。接下来，我们将通过以下方式指定一个模型插件，即组合到目前为止我们已经开发的所有组件：
- en: The model subclasses KerasModel for persistence.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是 KerasModel 的子类，用于持久化。
- en: Use data_loader from the dnn_data module to load data.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 dnn_data 模块中的 data_loader 加载数据。
- en: Load the model itself from the dnn_module module.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从dnn_module模块加载模型本身。
- en: The following code listing shows the model module.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码列表显示了模型模块。
- en: Listing 9.16 Model definition for the Keras model
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.16 Keras模型的模型定义
- en: '[PRE26]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ Number of training epochs. Increase for more accurate results.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 训练周期数。增加以获得更准确的结果。
- en: '❷ Change this to {''tensorflow-gpu'': ''2.6.2''} if you want to leverage GPUs.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '❷ 如果想利用GPU，请将其更改为{''tensorflow-gpu'': ''2.6.2''}。'
- en: ❸ Initializes a data loader
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 初始化数据加载器
- en: ❹ Creates a model
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 创建一个模型
- en: ❺ Monitors progress with TensorBoard
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 使用TensorBoard监控进度
- en: ❻ Number of batches
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 批次数
- en: ❼ Trains the model
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 训练模型
- en: ❽ Initializes a data loader in testing more; no target variable
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 在测试中初始化数据加载器；没有目标变量
- en: ❾ Converts the result tensor to a NumPy array
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 将结果张量转换为NumPy数组
- en: ❿ Computes the mean squared error between predictions and correct prices
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ❿ 计算预测值与正确价格之间的均方误差
- en: 'Save the code in taxi_modules/model_grid.py. The final directory structure
    should look like this:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码保存在taxi_modules/model_grid.py中。最终的目录结构应如下所示：
- en: '[PRE27]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This is starting to look like a real data science project! Luckily, each module
    is small, and the overall structure is quite understandable, especially when accompanied
    by documentation. We are now ready to start training the model.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 这开始看起来像是一个真正的数据科学项目！幸运的是，每个模块都很小，整体结构相当易于理解，尤其是在文档的辅助下。我们现在可以开始训练模型了。
- en: 9.2.3 Training a deep regression model
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 训练深度回归模型
- en: 'Let’s begin with a word of warning: training a deep neural network model is
    a very compute-intensive procedure. Whereas the linear regression models we defined
    earlier in this chapter train in seconds, the deep regression model we defined
    above can take hours or even days to train, depending on your hardware.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先说一句警告：训练深度神经网络模型是一个非常计算密集的过程。而我们在本章前面定义的线性回归模型可以在几秒钟内完成训练，而上面定义的深度回归模型可能需要数小时甚至数天才能训练，这取决于您的硬件。
- en: In general, it is a good idea to start with a quick round of smoke testing—does
    the workflow even complete successfully?—before spending hours to train an untested
    model. We start by testing the end-to-end workflow quickly, making sure that everything
    is working correctly. You should be able to complete the smoke test on any hardware,
    including your laptop, in a few minutes.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在花费数小时训练未经测试的模型之前，先进行快速烟雾测试是一个好主意——工作流程是否成功完成？——我们首先快速测试端到端工作流程，确保一切正常工作。您应该能够在几分钟内完成烟雾测试，包括您的笔记本电脑。
- en: Small-scale training
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 小规模训练
- en: 'The easiest way to make training fast is to reduce the amount of data. Hence,
    we start the smoke test by creating a tiny 1% sample of our full dataset. Run
    the data workflow, which we defined in listing 9.6, to create a sample as follows:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 使训练变得最快的方法是减少数据量。因此，我们通过创建我们完整数据集的1%的小样本来开始烟雾测试。运行我们定义在列表9.6中的数据工作流程，创建样本如下：
- en: '[PRE28]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, we can run the model workflow:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以运行模型工作流程：
- en: '[PRE29]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Assuming all the three model plugins exist in the taxi_modules directory, the
    start step should print the following line:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 假设所有三个模型插件都存在于taxi_modules目录中，启动步骤应打印以下行：
- en: '[PRE30]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'With a 1% sample, the workflow should execute for about 5-10 minutes, depending
    on your hardware. The result of the model benchmark is output in the join step.
    It is expected to look something like this:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 使用1%的样本，工作流程应运行约5-10分钟，具体取决于您的硬件。模型基准测试的结果在join步骤中输出。它应该看起来像这样：
- en: '[PRE31]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'As expected, the distance_regression model that uses the actual distance performs
    the best. Sadly but expectedly, our deep regression model, grid_dnn, performs
    worse than the model using the Euclidean trip distance when trained with a small
    amount of data. It is widely known that traditional machine learning methods often
    beat deep learning when the amount of data is limited. However, if you saw results
    like these, you should celebrate: the whole setup works end to end!'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，使用实际距离的距离回归模型表现最佳。遗憾的是，但也是意料之中的，我们的深度回归模型grid_dnn在少量数据训练时表现不如使用欧几里得行程距离的模型。众所周知，当数据量有限时，传统的机器学习方法往往优于深度学习。然而，如果您看到这样的结果，您应该庆祝：整个设置从头到尾都工作得很好！
- en: Large-scale training
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模训练
- en: 'For a more realistic, large-scale training, you can adopt a few best practices:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更真实、更大规模训练，您可以采用以下最佳实践：
- en: 'Use a GPU to speed up training. You can do this in the following ways:'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GPU加速训练。您可以通过以下方式完成：
- en: You can leverage GPUs on your laptop or desktop, if you have such hardware available.
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有这样的硬件可用，你可以利用你的笔记本电脑或台式机上的GPU。
- en: You can launch a GPU instance as a cloud workstation and execute the examples
    on the instance. Make sure you use an instance image (AMI) that includes CUDA
    kernel libraries, such as AWS Deep Learning AMI ([https://aws.amazon.com/machine-learning/amis/](https://aws.amazon.com/machine-learning/amis/)).
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将GPU实例作为云工作站启动，并在实例上执行示例。确保你使用包含CUDA内核库的实例镜像（AMI），例如AWS Deep Learning AMI
    ([https://aws.amazon.com/machine-learning/amis/](https://aws.amazon.com/machine-learning/amis/))。
- en: You can set up a remote compute layer, for example, Batch compute environment,
    with GPU instances.
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以设置一个远程计算层，例如，带有GPU实例的批处理计算环境。
- en: Make sure that your workstation doesn’t terminate during training (e.g., your
    laptop runs out of battery or the SSH connection to the workstation dies). If
    you use a cloud workstation, it is advisable to use a terminal multiplexer like
    screen or tmux to make sure the process stays running, even if the network connection
    dies. See, for example, [http://mng.bz/lxEB](http://mng.bz/lxEB) for instructions.
    Alternatively, if you use a GPU-powered compute layer, you can deploy the workflow
    to a production scheduler like AWS Step Functions, as discussed in chapter 6,
    which takes care of running the workflow reliably.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保你的工作站训练过程中不会终止（例如，你的笔记本电脑电量耗尽或与工作站的SSH连接断开）。如果你使用云工作站，建议使用终端多路复用器如screen或tmux来确保进程持续运行，即使网络连接断开。例如，查看[http://mng.bz/lxEB](http://mng.bz/lxEB)以获取说明。或者，如果你使用GPU驱动的计算层，可以将工作流程部署到生产调度器，如第6章中讨论的AWS
    Step Functions，它负责可靠地运行工作流程。
- en: Use a monitoring tool like TensorBoard, which is an open source package and
    service provided by Google for free, to monitor progress. Although this is not
    required, it gives peace of mind to see that the training task is making progress.
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用像TensorBoard这样的监控工具，它是Google免费提供的开源软件包和服务，以监控进度。尽管这不是必需的，但看到训练任务正在取得进展可以让人放心。
- en: If you want to leverage a GPU for training, replace this line
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要利用GPU进行训练，请替换此行
- en: '[PRE32]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: in model_grid.py with
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在model_grid.py中使用
- en: '[PRE33]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: to use a GPU-optimized version of TensorFlow.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 以使用TensorFlow的GPU优化版本。
- en: 'After your workstation is ready to go, create a larger dataset by executing,
    for example:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的工作站准备就绪后，通过执行，例如：
- en: '[PRE34]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You can test training with up to a 100% sample, depending on your hardware
    and patience. If you are executing the command on a cloud workstation, make sure
    to run these commands inside screen or tmux, so you can reattach to the process
    if your SSH session dies. You can start a training run as follows:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用高达100%的样本来测试训练，具体取决于你的硬件和耐心。如果你在云工作站上执行命令，请确保在screen或tmux中运行这些命令，以便在SSH会话断开时重新连接到进程。你可以按照以下方式启动训练运行：
- en: '[PRE35]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Note that we specify -max-workers 1, which limits the foreach to run only one
    process at a time. This ensures that the heavyweight GPU task doesn’t need to
    compete with other processes running on the workstation simultaneously.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们指定了`-max-workers 1`，这限制了`foreach`一次只能运行一个进程。这确保了重量级的GPU任务不需要与其他在工作站上同时运行的过程竞争。
- en: 'Because we enabled logging to TensorBoard in model_grid.py already, we can
    simply run TensorBoard in another terminal window to monitor progress. Open another
    terminal session and navigate to the directory where you started the run. Then,
    install TensorBoard by running the next code:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们在model_grid.py中已经启用了TensorBoard的日志记录，我们可以在另一个终端窗口中简单地运行TensorBoard来监控进度。打开另一个终端会话，导航到你开始运行的位置。然后，通过运行以下代码来安装TensorBoard：
- en: '[PRE36]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If you are running training on a local machine, you can open TensorBoard locally
    by executing the following:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个本地机器上运行训练，你可以通过执行以下命令在本地打开TensorBoard：
- en: '[PRE37]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'It should print out an URL like http://localhost:6006/, which you can copy
    and paste to a browser window. If you are running a cloud workstation, it might
    be easier to rely on a publicly hosted TensorBoard at [https://tensorboard.dev](https://tensorboard.dev)
    for monitoring. To use the service, simply execute the following:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 它应该会打印出一个类似http://localhost:6006/的URL，你可以将其复制并粘贴到浏览器窗口中。如果你在云工作站上运行，可能更容易依赖于公开托管的TensorBoard在[https://tensorboard.dev](https://tensorboard.dev)进行监控。要使用此服务，只需执行以下命令：
- en: '[PRE38]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: When you run the command for the first time, it asks you to authenticate and
    save a token locally. After doing this, it should print out a URL that looks like
    [https://tensorboard.dev/experiment/UeHdJZ7JRbGpN341gyOwrnQ/](https://tensorboard.dev/experiment/UeHdJZ7JRbGpN341gyOwrnQ/),
    which you can open with a browser.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 当你第一次运行命令时，它会要求你进行身份验证并本地保存令牌。完成此操作后，它应该会打印出一个看起来像 [https://tensorboard.dev/experiment/UeHdJZ7JRbGpN341gyOwrnQ/](https://tensorboard.dev/experiment/UeHdJZ7JRbGpN341gyOwrnQ/)
    的 URL，你可以用浏览器打开它。
- en: Both the local as well as the hosted TensorBoard should look like the screenshot
    in figure 9.10\. You can reload the page periodically to see the training making
    progress. If all goes well, the loss curve should trend downward as shown in the
    figure.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 本地以及托管在 TensorBoard 上的都应该看起来像图 9.10 中的截图。你可以定期重新加载页面以查看训练进度。如果一切顺利，损失曲线应该像图中所示那样呈下降趋势。
- en: '![CH09_F10_Tuulos](../../OEBPS/Images/CH09_F10_Tuulos.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F10_Tuulos](../../OEBPS/Images/CH09_F10_Tuulos.png)'
- en: Figure 9.10 Screenshot of tensorboard.dev showing model convergence
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.10 tensorboard.dev 的模型收敛截图
- en: Another handy command that may be available on a GPU-powered system is nvidia-smi,
    which shows statistics about GPU utilization. It should show all GPUs available
    in your system and a utilization figure that’s above 0%, if a GPU is being used
    by the training process.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可能在 GPU 系统上可用的实用命令是 nvidia-smi，它显示了 GPU 利用率的统计信息。它应该显示系统中所有可用的 GPU 以及一个利用率数值，如果
    GPU 正在被训练过程使用，这个数值应该大于 0%。
- en: 'On a powerful GPU instance (p3.8xlarge), training the model with a full dataset
    (100% sample) over four epochs takes about eight hours. If you want to attempt
    speeding up the training, you can experiment with different variants of the model
    as follows:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个强大的 GPU 实例（p3.8xlarge）上，使用完整数据集（100% 样本）进行四个周期的模型训练大约需要八个小时。如果你想尝试加快训练速度，你可以尝试以下不同变体的模型：
- en: You can decrease the value of NUM_HASH_BINS and precision in feat_gridtensor
    .py to make the input tensors small. Or experiment changing with only one of those
    parameters to change the hashing behavior.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过减小 feat_gridtensor.py 中 NUM_HASH_BINS 的值和精度来使输入张量变小。或者，你可以只改变其中一个参数来改变哈希行为进行实验。
- en: You can change the model architecture in dnn_model.py. For instance, you can
    remove hidden layers or make them smaller.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在 dnn_model.py 中更改模型架构。例如，你可以移除隐藏层或将它们变得更小。
- en: You can increase BATCH_SIZE to a very high number, say, 10,000, to make the
    model train much faster. You can use TensorBoard to monitor the effect of the
    batch size to model loss.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将 BATCH_SIZE 增加到一个非常高的数值，比如 10,000，以使模型训练得更快。你可以使用 TensorBoard 来监控批量大小的模型损失效果。
- en: You can make EPOCHS smaller to reduce the number of training iterations. Or
    you can change other parameters but increase EPOCHS.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过减小 EPOCHS 的值来减少训练迭代次数。或者，你可以更改其他参数，但增加 EPOCHS。
- en: 'A rewarding element of model development is that the results are perfectly
    quantifiable. You can experiment with the previous parameters and see the effect
    on model performance as soon as the training finishes. As a baseline for your
    experiments, training the models with a full dataset produces the following results:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发的回报之一是结果可以完美量化。你可以在训练完成后立即看到实验参数对模型性能的影响。作为实验的基线，使用完整数据集训练模型会产生以下结果：
- en: '[PRE39]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Our efforts are not in vain! When trained with a full dataset, the deep regression
    model handily beats the naive Euclidean model, approaching the performance of
    the actual distance measurement. In other words, it is possible to build a model
    that predicts the trip price relatively accurately by considering only the pick-up
    and drop-off locations, and such a model performs better than a model that considers
    only a straight-line distance between the locations.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的努力并非徒劳！当使用完整数据集进行训练时，深度回归模型轻松击败了简单的欧几里得模型，接近实际距离测量的性能。换句话说，我们可以构建一个仅考虑接车和下车位置的模型，以相对准确地预测行程价格，并且这种模型的性能优于仅考虑两地之间直线距离的模型。
- en: 'As an exercise, you can try to improve the model: you can include, for example,
    time of day as a feature, which surely affects traffic patterns. You can also
    test different variations of the model architecture or try to improve the performance
    of the data loader. After a few rounds of improvement, you should be able to beat
    the performance of the baseline model.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一项练习，你可以尝试改进模型：例如，你可以包括一天中的时间作为一个特征，这无疑会影响交通模式。你还可以测试模型架构的不同变体，或者尝试改进数据加载器的性能。经过几轮改进后，你应该能够超越基线模型的性能。
- en: However, this chapter is not about optimal models for price predictions. More
    important, we learned how to design and develop a simple domain-specific framework
    that allows a data scientist to define new features and models to solve this particular
    business problem effectively and test the performance of the new variants consistently.
    Although this example was a rather simple one, you can use it as an inspiration
    for your own, more sophisticated frameworks that stand on the shoulders of the
    full infrastructure stack.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，本章并非关于价格预测的最佳模型。更重要的是，我们学习了如何设计和开发一个简单的特定领域框架，允许数据科学家定义新的特征和模型，以有效地解决这个特定业务问题，并一致地测试新变体的性能。尽管这个例子相对简单，但你可以用它作为灵感，为你的更复杂框架提供支持，这些框架建立在完整的基础设施堆栈之上。
- en: 9.3 Summarizing lessons learned
  id: totrans-365
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 总结所学经验
- en: We began the book with a picture, shown again in figure 9.11, illustrating the
    full life cycle of a data science project. We promised to cover all parts of the
    life cycle, so your organization can increase the number of projects that are
    executed simultaneously (volume), speed up the time to market (velocity), ensure
    that the results are robust (validity), and make it possible to support a wider
    variety of projects. To summarize the book, let’s see how the chapters we covered
    map to the figure.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以一张图片开始了这本书，如图9.11所示，展示了数据科学项目的完整生命周期。我们承诺要涵盖生命周期的所有部分，以便你的组织可以增加同时执行的项目数量（数量），加快上市时间（速度），确保结果稳健（有效性），并使支持更广泛的项目种类成为可能。为了总结这本书，让我们看看我们涵盖的章节如何与这张图相对应。
- en: '![CH09_F11_Tuulos](../../OEBPS/Images/CH09_F11_Tuulos.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![CH09_F11_Tuulos](../../OEBPS/Images/CH09_F11_Tuulos.png)'
- en: Figure 9.11 The full life cycle of a data science project
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.11 数据科学项目的完整生命周期
- en: Models shouldn’t be built in isolation. We emphasized the importance of focusing
    on the business problem on a number of occasions. We introduced the idea of a
    spiral approach in chapter 3 and applied it to example projects throughout the
    book.
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型不应该孤立地构建。我们在多个场合强调了关注业务问题的重要性。我们在第三章介绍了螺旋式方法的概念，并在整本书中的应用示例中进行了应用。
- en: What tooling should data scientists use to develop projects effectively, and
    where and how to use the tooling? The entirety of chapter 2 was dedicated to the
    topic of notebooks, IDEs, cloud workstations, and workflows. We introduced a particular
    framework, Metaflow, in chapter 3, which addresses many of these concerns in a
    user-friendly manner. Also in this chapter, we demonstrated how custom libraries
    built on top of the stack can boost productivity in particular problem domains.
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家应该使用哪些工具来有效地开发项目，以及在哪里和如何使用这些工具？第二章全部内容都致力于笔记本、集成开发环境（IDE）、云工作站和工作流程这一主题。我们在第三章介绍了一个特定的框架，Metaflow，它以用户友好的方式解决了许多这些问题。在本章中，我们还展示了如何构建在堆栈之上的自定义库，以特定问题领域提高生产力。
- en: How do we benefit from off-the-shelf libraries without exposing projects to
    random breakage and performance degradation? We discussed the performance implications
    of libraries in chapter 5 and dug deeper into the question of dependency management
    in chapter 6\. We used a variety of open source ML libraries in examples, culminating
    in a deep neural network model showcased in this chapter.
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何从现成的库中获益，同时又不让项目暴露在随机崩溃和性能下降的风险中？我们在第五章讨论了库的性能影响，并在第六章深入探讨了依赖管理的问题。我们在示例中使用了各种开源机器学习库，最终在本章展示了展示了一个深度神经网络模型。
- en: How should we discover, access, and manage data? All of chapter 7 was dedicated
    to this broad and deep topic.
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该如何发现、访问和管理数据？第七章全部内容都致力于这个广泛而深入的主题。
- en: Machine learning projects tend to be very compute heavy—open-ended experimentation,
    model training, and large-scale data processing all need compute power. How should
    one provision and manage compute resources? Chapter 4 dove deep in the world of
    compute layers and modern container orchestration systems.
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器学习项目往往计算量很大——开放式的实验、模型训练和大规模数据处理都需要计算能力。一个人应该如何配置和管理计算资源？第四章深入探讨了计算层和现代容器编排系统。
- en: Once the results become available, how can they be connected to surrounding
    business systems? Crucially, production deployments should run reliably without
    human intervention, as discussed in chapter 6\. Chapter 8 discussed how the results
    can be leveraged in various contexts from relatively slow batch processes to millisecond-range
    real-time systems.
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦结果可用，如何将它们与周围的业务系统连接起来？关键的是，生产部署应在没有人为干预的情况下可靠运行，正如第6章所讨论的。第8章讨论了如何在各种环境中利用结果，从相对较慢的批量处理到毫秒级实时系统。
- en: Finally, the fruits of the data science project get used in practice. If the
    consumers of the project find the results promising, the cycle starts again because
    there’s an appetite to make the results even better. If the response is negative,
    the cycle starts again as the data scientist moves on to a new project.
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，数据科学项目的成果在实践中得到应用。如果项目的消费者认为结果有希望，循环就会再次开始，因为人们希望使结果变得更好。如果反应是消极的，循环就会再次开始，因为数据科学家将转向新的项目。
- en: The fact that the cycle never stops is the ultimate justification for investing
    in an effective data science infrastructure. If the cycle ran only once, any working
    solution would suffice. However, because the cycle repeats over multiple projects
    and multiple teams, each of which keeps improving applications they own, the need
    for a common, shared foundation becomes apparent.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 循环永不停止的事实是投资有效数据科学基础设施的最终理由。如果循环只运行一次，任何可行的解决方案都足够了。然而，由于循环在多个项目和多个团队之间重复，每个团队都在不断改进他们拥有的应用程序，因此对共同、共享基础的需求变得明显。
- en: Hopefully this book succeeded in giving you a solid understanding of the foundational
    layers, data, compute, orchestration, and versioning, in the context of data science
    projects. Using this knowledge, you are able to evaluate the relative merits of
    various technical systems and approaches, make informed decisions, and set up
    a stack that makes sense in your environment.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这本书能帮助你牢固地理解数据科学项目的基础层，包括数据、计算、编排和版本控制。利用这些知识，你能够评估各种技术系统和方法的相对优点，做出明智的决策，并设置一个适合你环境的合理堆栈。
- en: 'Although the foundation can be shared, the diversity of applications and approaches
    at the top of the stack will increase over time as data science is applied to
    new domains of life. When it comes to solving particular business problems, there’s
    no replacement for human creativity and domain expertise. A foundation is just
    a foundation: it is now your turn to grab a sketchpad, experiment, and start building
    new and exciting, well-tailored data science applications on top of the stack.'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基础可以共享，但随着数据科学应用于生活的新领域，堆栈顶部的应用和方法的多样性将随着时间的推移而增加。当涉及到解决特定的业务问题时，人类创造力和领域专业知识是无法替代的。基础只是基础：现在轮到你了，拿起草图本，进行实验，并开始在堆栈上构建新的、令人兴奋的、量身定制的数据科学应用。
- en: Summary
  id: totrans-379
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The top layers of the stack, model development and feature engineering, tend
    to be domain specific. You can create small, domain-specific libraries on top
    of the foundational infrastructure stack to address the needs of each project.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆栈的顶层，即模型开发和特征工程，往往具有领域特定性。你可以在基础基础设施堆栈之上创建小型、领域特定的库，以满足每个项目的需求。
- en: Models and feature encoders can be implemented as pluggable modules, enabling
    quick prototyping and benchmarking of ideas.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型和特征编码器可以作为可插拔模块实现，从而实现想法的快速原型设计和基准测试。
- en: Use a common workflow to load data, produce train and test splits, and execute
    feature encoders and models, making sure results are consistent and comparable
    between models.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一个共同的流程加载数据，生成训练和测试分割，并执行特征编码器和模型，确保结果在模型之间是一致的且可比较的。
- en: Modern deep learning libraries work well with the infrastructure stack, particularly
    when executed on a compute layer that supports GPUs.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代深度学习库与基础设施堆栈配合良好，尤其是在支持GPU的计算层上执行时。
- en: Use off-the-shelf monitoring tools and services like TensorBoard to monitor
    training in real time.
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用现成的监控工具和服务，如TensorBoard，实时监控训练过程。
