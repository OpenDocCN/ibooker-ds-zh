- en: 13 Observability and monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 13 可观测性和监控
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Logging with Spring Boot, Loki, and Fluent Bit
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Boot、Loki 和 Fluent Bit 进行日志记录
- en: Using health probes with Spring Boot Actuator and Kubernetes
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Boot Actuator 和 Kubernetes 中的健康检查
- en: Producing metrics with Spring Boot Actuator, Prometheus, and Grafana
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Boot Actuator、Prometheus 和 Grafana 生成指标
- en: Configuring distributed tracing with OpenTelemetry and Tempo
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenTelemetry 和 Tempo 配置分布式跟踪
- en: Managing applications with Spring Boot Actuator
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Boot Actuator 管理应用程序
- en: In the previous chapters, you learned about several patterns and technologies
    you can use to build secure, scalable, and resilient applications. However, we
    still lack visibility into the Polar Bookshop system, especially when something
    goes wrong. Before going to production, we should ensure our applications are
    observable and that the deployment platform provides all the tools needed to monitor
    and gain insights into the system.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，您学习了可以使用的一些模式和技术的几个示例，以构建安全、可扩展和有弹性的应用程序。然而，我们仍然缺乏对 Polar Bookshop 系统的可见性，尤其是在出现问题的时候。在投入生产之前，我们应该确保我们的应用程序是可观测的，并且部署平台提供了所有必要的工具来监控和深入了解系统。
- en: '*Monitoring* involves checking the telemetry available for the application
    and defining alerts for known failure states. *Observability* goes beyond that
    and aims at reaching a state where we can ask arbitrary questions about the system
    without knowing the question in advance. The product team should ensure their
    applications expose relevant information; and the platform team should provide
    an infrastructure for consuming that information and asking questions about their
    operations.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*监控* 涉及检查应用程序可用的遥测数据并定义已知故障状态的通知。*可观测性* 超越了这一点，旨在达到一种状态，我们可以对系统提出任意问题，而无需事先知道问题。产品团队应确保他们的应用程序暴露相关信息；平台团队应提供基础设施以消费这些信息并对其操作提出问题。'
- en: As you’ll remember from chapter 1, *observability* is one of the properties
    of cloud native applications. Observability is a measure of how well we can infer
    the internal state of an application from its outputs. In chapter 2, you learned
    about the 15-Factor methodology, which contains two factors that help build observable
    applications. Factor 14 suggests treating your applications as space probes and
    reasoning about what kind of telemetry you’d need to monitor and control your
    applications remotely, such as logs, metrics, and traces. Factor 6 recommends
    treating logs as a stream of events rather than dealing with log files.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从第 1 章中记得的，*可观测性* 是云原生应用程序的特性之一。可观测性是衡量我们能够从应用程序的输出中推断其内部状态的程度。在第 2 章中，您学习了
    15-Factor 方法论，其中包含两个有助于构建可观测应用程序的因素。第 14 个因素建议将您的应用程序视为太空探测器，并思考您需要什么样的遥测数据来远程监控和控制应用程序，例如日志、指标和跟踪。第
    6 个因素建议将日志视为事件流，而不是处理日志文件。
- en: In this chapter, you’ll learn how to ensure your Spring Boot applications expose
    relevant information to infer their internal states, such as logs, health probes,
    metrics, traces, and additional valuable data regarding schema migrations and
    builds. I’ll also show you how to use the Grafana open source observability stack
    to validate the changes you’ll make to your applications. However, I won’t go
    into too many details, because that’s something the platform team deploys and
    operates.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习如何确保您的 Spring Boot 应用程序暴露相关信息以推断其内部状态，例如日志、健康检查、指标、跟踪以及有关模式迁移和构建的额外有价值的数据。我还会向您展示如何使用
    Grafana 开源可观测性堆栈来验证您对应用程序所做的更改。然而，我不会过多地深入细节，因为这通常是平台团队部署和运营的内容。
- en: Note The source code for the examples in this chapter is available in the Chapter13/13-begin
    and Chapter13/13-end folders, which contain the initial and final states of the
    project ([https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本章示例的源代码可在 Chapter13/13-begin 和 Chapter13/13-end 文件夹中找到，其中包含项目的初始状态和最终状态
    ([https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action))。
- en: 13.1 Logging with Spring Boot, Loki, and Fluent Bit
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.1 使用 Spring Boot、Loki 和 Fluent Bit 进行日志记录
- en: Logs (or *event logs*) are discrete records of something that happened over
    time in a software application. They are composed of a timestamp necessary to
    answer the question “when did the event happen?” and some information providing
    details about the event and its context, which lets us answer questions like “what
    happened at this time?”, “which thread was processing the event?”, or “which user/tenant
    was in the context?”
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 日志（或*事件日志*）是软件应用程序中随时间发生的事件的离散记录。它们由一个时间戳组成，用于回答“事件何时发生？”的问题，以及一些提供事件及其上下文详细信息的其他信息，这使我们能够回答诸如“此时发生了什么？”、“哪个线程正在处理该事件？”或“哪个用户/租户处于上下文中？”等问题。
- en: During troubleshooting and debugging tasks, logs are among the essential tools
    we can use to reconstruct what happened at a specific point in time in a single
    application instance. They’re usually categorized according to the type or severity
    of the event, such as *trace*, *debug*, *info*, *warn*, and *error*. It’s a flexible
    mechanism that lets us log only the most severe events in production while still
    giving us the chance to change the log level temporarily during debugging.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在故障排除和调试任务期间，日志是我们可以使用的基本工具之一，用于重建单个应用程序实例在特定时间点发生的情况。它们通常根据事件类型或严重性进行分类，如*跟踪*、*调试*、*信息*、*警告*和*错误*。这是一个灵活的机制，允许我们在生产环境中仅记录最严重的事件，同时仍然在调试期间有机会临时更改日志级别。
- en: The format of a log record can vary, going from simple plain text to a more
    organized collection of key/value pairs to fully structured records produced in
    a JSON format.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录的格式可能有所不同，从简单的纯文本到更组织化的键/值对集合，再到以JSON格式产生的完全结构化记录。
- en: Traditionally we’ve configured logs to be printed out in files located on the
    host machine, which has resulted in applications dealing with filename conventions,
    file rotation, and file sizes. In the cloud we follow the 15-Factor methodology,
    which recommends treating logs as events streamed to the standard output. Cloud
    native applications stream logs and are not concerned with how they are processed
    or stored.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，我们配置日志输出到宿主机上的文件，这导致应用程序需要处理文件命名约定、文件轮转和文件大小。在云环境中，我们遵循15-Factor方法，该方法建议将日志视为流式传输到标准输出的事件。云原生应用程序会流式传输日志，并且不关心它们是如何被处理或存储的。
- en: This section will teach you how to add and configure logs in Spring Boot applications.
    Then I’ll explain how logs are collected and aggregated in a cloud native infrastructure.
    Finally, you’ll run Fluent Bit for log collection, run Loki for log aggregation,
    and use Grafana to query the logs produced by your Spring Boot applications.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将教会你如何在Spring Boot应用程序中添加和配置日志。然后我将解释如何在云原生基础设施中收集和聚合日志。最后，你将运行Fluent Bit进行日志收集，运行Loki进行日志聚合，并使用Grafana查询由你的Spring
    Boot应用程序产生的日志。
- en: 13.1.1 Logging with Spring Boot
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.1 使用Spring Boot进行日志记录
- en: Spring Boot comes with built-in support and auto-configuration for the most
    common logging frameworks, including Logback, Log4J2, Commons Logging, and Java
    Util Logging. By default, Logback is used ([https://logback.qos.ch](https://logback.qos.ch)),
    but you can easily replace it with another library thanks to the abstraction provided
    by the Simple Logging Facade for Java (SLF4J).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot自带了对最常见日志框架的支持和自动配置，包括Logback、Log4J2、Commons Logging和Java Util Logging。默认情况下，使用Logback
    ([https://logback.qos.ch](https://logback.qos.ch))，但你可以利用Java简单日志门面（SLF4J）提供的抽象轻松地替换它。
- en: Using the interfaces from SLF4J ([www.slf4j.org](http://www.slf4j.org)), you
    have the freedom to change the logging library without changing your Java code.
    Furthermore, cloud native applications should treat logs as events and stream
    them to the standard output. That’s precisely what Spring Boot does out of the
    box. Convenient, right?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SLF4J（[www.slf4j.org](http://www.slf4j.org)）的接口，你可以自由地更改日志库，而无需更改Java代码。此外，云原生应用程序应将日志视为事件并将它们流式传输到标准输出。这正是Spring
    Boot默认所做的。方便，对吧？
- en: Configuring logging in Spring Boot
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 配置Spring Boot中的日志
- en: 'Event logs are categorized by level with decreasing details and increasing
    importance: trace, debug, info, warn, error. By default, Spring Boot logs everything
    from the *info* level up.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 事件日志按级别分类，细节逐渐减少，重要性逐渐增加：跟踪（trace）、调试（debug）、信息（info）、警告（warn）、错误（error）。默认情况下，Spring
    Boot从*info*级别开始记录所有内容。
- en: 'A *logger* is a class that produces log events. You can set logger levels through
    configuration properties, with options to apply global configurations or to target
    specific packages or classes. For example, in chapter 9 we set a *debug* logger
    to get more details about the circuit breakers implemented with Resilience4J (in
    the application.yml file in the Edge Service project):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*记录器*是一个产生日志事件的类。你可以通过配置属性设置记录器级别，可以选择应用全局配置或针对特定的包或类。例如，在第9章中，我们设置了一个*调试*记录器以获取使用Resilience4J实现的断路器的更多详细信息（在Edge
    Service项目的application.yml文件中）：'
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Sets a debug logger for the Resilience4J library
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为Resilience4J库设置了一个调试记录器
- en: You might need to configure multiple loggers at the same time. In that case,
    you can collect them in a *log group* and apply the configuration to the group
    directly. Spring Boot provides two predefined log groups, web and sql, but you
    can also define your own. For example, to better analyze the behavior of the circuit
    breakers defined in the Edge Service application, you could define a log group
    and configure a log level for both Resilience4J and Spring Cloud Circuit Breaker.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要同时配置多个记录器。在这种情况下，你可以将它们收集到一个*日志组*中，并直接对该组应用配置。Spring Boot提供了两个预定义的日志组，web和sql，但你也可以定义自己的。例如，为了更好地分析Edge
    Service应用程序中定义的断路器的行为，你可以定义一个日志组并为Resilience4J和Spring Cloud Circuit Breaker配置日志级别。
- en: In the Edge Service project (edge-service), you can configure the new log group
    in the application.yml file as follows.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在Edge Service项目（edge-service）中，你可以在application.yml文件中按照以下方式配置新的日志组。
- en: Listing 13.1 Configuring a group to control the circuit breaker logs
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.1配置一个组以控制断路器日志
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Collects multiple loggers into a group to apply the same configuration
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将多个记录器收集到一个组中以应用相同的配置
- en: ❷ Sets an “info” logger for both Resilience4J and Spring Cloud Circuit Breaker,
    which is easy to change if you need to debug the circuit breakers
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 为Resilience4J和Spring Cloud Circuit Breaker设置了一个“info”记录器，如果需要调试断路器，则很容易更改
- en: By default, each event log provides essential information, including the date
    and time of the occurrence, the log level, the process identifier (PID), the name
    of the thread from which the event was triggered, the logger name, and the log
    message. If you check the application logs from a Terminal that supports ANSI,
    the log messages will also be colored to improve readability (figure 13.1). The
    logging format can be customized using the logging.pattern configuration property
    group.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，每个事件日志都提供基本的信息，包括事件发生的日期和时间、日志级别、进程标识符（PID）、触发事件的线程名称、记录器名称以及日志消息。如果你检查支持ANSI的终端中的应用程序日志，日志消息也会被着色以提高可读性（图13.1）。可以通过logging.pattern配置属性组自定义日志格式。
- en: '![13-01](../Images/13-01.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![13-01](../Images/13-01.png)'
- en: Figure 13.1 Event logs include a timestamp, contextual information, and a message
    about what happened.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1事件日志包括时间戳、上下文信息和关于发生的事情的消息。
- en: Note Spring Boot provides extensive options for configuring logging to files.
    Since that’s not useful for cloud native applications, I won’t cover it in this
    book. If you’re interested in the subject, see the official documentation to learn
    more about log files ([http://spring.io/projects/spring-boot](http://spring.io/projects/spring-boot)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意Spring Boot提供了广泛的配置日志到文件的选项。由于这对于云原生应用程序没有太大用处，因此本书不会涉及。如果你对这个主题感兴趣，请参阅官方文档以了解更多关于日志文件的信息（[http://spring.io/projects/spring-boot](http://spring.io/projects/spring-boot)）。
- en: Adding logs to Spring Boot applications
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 将日志添加到Spring Boot应用程序中
- en: Besides configuring loggers for the frameworks and libraries used in your project,
    you should define event logs in your code whenever applicable. How much logging
    is enough? It depends on the context. In general, I reckon that it’s better to
    have too much logging than too little. I’ve seen many deployments that just contain
    changes to add more logging, while it’s pretty rare to see the opposite.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 除了为项目中使用的框架和库配置记录器外，在适用的情况下，你应该在代码中定义事件日志。多少日志才算足够？这取决于上下文。一般来说，我认为日志过多比过少更好。我见过许多部署只是包含添加更多日志的更改，而看到相反的情况则非常罕见。
- en: 'Thanks to the SLF4J façade, the syntax for defining new event logs in Java
    is the same no matter which logging library you use: a Logger instance created
    from a LoggerFactory. Let’s see how it works by adding new log messages to the
    web controller in Catalog Service.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了SLF4J外观，无论使用哪个日志库，在Java中定义新事件日志的语法都是相同的：从LoggerFactory创建的Logger实例。让我们通过向Catalog
    Service的Web控制器添加新的日志消息来查看它是如何工作的。
- en: In the Catalog Service project (catalog-service), go to the BookController class,
    define a Logger instance from SLF4J, and add messages to be printed out whenever
    a client calls the application’s REST API.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Catalog Service 项目（catalog-service）中，转到 BookController 类，从 SLF4J 定义一个 Logger
    实例，并在客户端调用应用程序的 REST API 时添加要打印的消息。
- en: Listing 13.2 Defining log events using SL4FJ
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.2 使用 SL4FJ 定义日志事件
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Defines a logger for the BookController class
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为 BookController 类定义一个日志记录器
- en: ❷ Logs the given message at the “info” level
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在“info”级别记录给定的消息
- en: Note Go ahead and define new loggers and log events for all the applications
    composing the Polar Bookshop system wherever it makes sense. As a reference, you
    can look at the source code repository accompanying this book (Chapter13/13-end).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在 Polar Bookshop 系统的任何合适的地方定义新的日志记录器和日志事件。作为一个参考，你可以查看本书附带的源代码仓库（第 13 章/13-end）。
- en: The Mapped Diagnostic Context (MDC)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Mapped Diagnostic Context（MDC）
- en: You’ll likely need to add common information to your log messages, such as the
    identifier of the currently authenticated user, the tenant for the current context,
    or the request URI. You could directly add that information to your log message,
    as you did in the previous listing, and it would work, but the data would not
    be structured. Instead, I prefer working with structured data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要在日志消息中添加一些常见信息，例如当前认证用户的标识符、当前上下文的租户或请求 URI。你可以直接将那些信息添加到你的日志消息中，就像你在前面的列表中所做的那样，它会起作用，但数据将不会是结构化的。相反，我更喜欢处理结构化数据。
- en: SLF4J and common logging libraries, like Logback and Log4J2, support adding
    structured information depending on the request context (authentication, tenant,
    thread) through a tool named Mapped Diagnostic Context (MDC). If you’d like to
    know more about MDC, I recommend checking the official documentation for the specific
    logging library you’re using.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: SLF4J 和常见的日志库，如 Logback 和 Log4J2，通过一个名为 Mapped Diagnostic Context（MDC）的工具支持根据请求上下文（身份验证、租户、线程）添加结构化信息。如果你想了解更多关于
    MDC 的信息，我建议查看你使用的特定日志库的官方文档。
- en: Now that our applications log messages as an event stream, we need to collect
    and store them in a central place that we can query. The following section will
    provide a solution to accomplish that.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将应用程序的日志消息作为事件流记录，我们需要将它们收集并存储在一个中央位置，我们可以查询它。下一节将提供一个解决方案来完成这个任务。
- en: 13.1.2 Managing logs with Loki, Fluent Bit, and Grafana
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.2 使用 Loki、Fluent Bit 和 Grafana 管理日志
- en: When you move to distributed systems like microservices and complex environments
    like the cloud, managing logs becomes challenging and requires a different solution
    than in more traditional applications. If something goes wrong, where can we find
    data about the failure? Traditional applications would rely on log files stored
    on the host machine. Cloud native applications are deployed in dynamic environments,
    are replicated, and have different life spans. We need to collect the logs from
    all applications running in the environment and send them to a central component
    where they can be aggregated, stored, and searched.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当你迁移到分布式系统，如微服务和复杂环境，如云时，日志管理变得具有挑战性，需要比在更传统的应用程序中不同的解决方案。如果出现问题，我们可以在哪里找到关于故障的数据？传统的应用程序会依赖于存储在主机上的日志文件。云原生应用程序部署在动态环境中，是复制的，并且有不同的生命周期。我们需要收集环境中运行的所有应用程序的日志，并将它们发送到一个中央组件，在那里它们可以被聚合、存储和搜索。
- en: There are plenty of options for managing logs in the cloud. Cloud providers
    have their own offerings, like Azure Monitor Logs and Google Cloud Logging. There
    are also many enterprise solutions available on the market, such as Honeycomb,
    Humio, New Relic, Datadog, and Elastic.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在云中管理日志有很多选择。云服务提供商都有自己的产品，例如 Azure Monitor 日志和 Google Cloud Logging。市场上也有许多企业级解决方案，例如
    Honeycomb、Humio、New Relic、Datadog 和 Elastic。
- en: For Polar Bookshop, we’ll use a solution based on the Grafana observability
    stack ([https://grafana.com](https://grafana.com)). It’s composed of open source
    technologies, and you can run it yourself in any environment. It’s also available
    as a managed service (Grafana Cloud) offered by Grafana Labs.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Polar Bookshop，我们将使用基于 Grafana 可观察性堆栈的解决方案（[https://grafana.com](https://grafana.com)）。它由开源技术组成，你可以在任何环境中自行运行它。它还作为
    Grafana Labs 提供的托管服务（Grafana Cloud）提供。
- en: The components of the Grafana stack we’ll use for managing logs are Loki for
    log storage and search, Fluent Bit for log collection and aggregation, and Grafana
    for log data visualization and querying.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Grafana堆栈的以下组件来管理日志：Loki用于日志存储和搜索，Fluent Bit用于日志收集和聚合，以及Grafana用于日志数据可视化和查询。
- en: Note Which technology you use for managing logs is a platform choice and shouldn’t
    impact the applications at all. For example, you should be able to replace the
    Grafana stack with Humio without making any changes to the Polar Bookshop applications.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您用于管理日志的技术是平台选择，不应影响应用程序。例如，您应该能够在不修改Polar Bookshop应用程序的情况下用Humio替换Grafana堆栈。
- en: We need a *log collector* to fetch log messages from the standard output of
    all the running applications. Using the Grafana stack, you’re free to choose a
    log collector from among several options. For the Polar Bookshop system, we’ll
    use Fluent Bit, an open source and CNCF-graduated project that “enables you to
    collect logs and metrics from multiple sources, enrich them with filters, and
    distribute them to any defined destination” ([https://fluentbit.io](https://fluentbit.io)).
    Fluent Bit is a subproject of Fluentd, “an open source data collector for unified
    logging layer” ([www.fluentd.org](http://www.fluentd.org)).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个**日志收集器**来从所有运行的应用程序的标准输出中获取日志消息。使用Grafana堆栈，你可以从多个选项中选择一个日志收集器。对于Polar
    Bookshop系统，我们将使用Fluent Bit，这是一个开源的CNCF毕业项目，它“使您能够从多个来源收集日志和指标，通过过滤器丰富它们，并将它们分发到任何定义的目的地”([https://fluentbit.io](https://fluentbit.io))。Fluent
    Bit是Fluentd的一个子项目，“一个用于统一日志层的开源数据收集器”([www.fluentd.org](http://www.fluentd.org))。
- en: Fluent Bit will collect logs from all running containers and forward them to
    Loki, which will store them and make them searchable. Loki is “a log aggregation
    system designed to store and query logs from all your applications and infrastructure”
    ([https://grafana.com/oss/loki](https://grafana.com/oss/loki)).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Fluent Bit将从所有运行容器中收集日志并将它们转发到Loki，Loki将存储它们并使它们可搜索。Loki是一个“专为存储和查询来自您所有应用程序和基础设施的日志而设计的日志聚合系统”([https://grafana.com/oss/loki](https://grafana.com/oss/loki))。
- en: Finally, Grafana will use Loki as a data source and provide log visualization
    features. Grafana “allows you to query, visualize, alert on and understand” your
    telemetry, no matter where it is stored ([https://grafana.com/oss/grafana](https://grafana.com/oss/grafana)).
    Figure 13.2 illustrates this logging architecture.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Grafana将使用Loki作为数据源并提供日志可视化功能。Grafana“允许您查询、可视化、警报并理解”无论存储在何处您的遥测数据([https://grafana.com/oss/grafana](https://grafana.com/oss/grafana))。图13.2展示了这种日志架构。
- en: '![13-02](../Images/13-02.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![13-02](../Images/13-02.png)'
- en: Figure 13.2 Logging architecture for cloud native applications based on the
    Grafana stack
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2 基于 Grafana 堆栈的云原生应用程序的日志架构
- en: Let’s start by running Grafana, Loki, and Fluent Bit as containers. In your
    Polar Deployment project (polar-deployment), update the Docker Compose configuration
    (docker/docker-compose.yml) to include the new services. They are configured through
    files I have included in the source code repository accompanying this book (Chapter13/13-end/polar-deployment/docker/observability).
    Copy the observability folder over the same path in your own project.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先运行Grafana、Loki和Fluent Bit作为容器。在你的Polar Deployment项目（polar-deployment）中，更新Docker
    Compose配置（docker/docker-compose.yml），以包括新的服务。它们通过我包含在本书源代码库中的文件进行配置（Chapter13/13-end/polar-deployment/docker/observability）。将可观察性文件夹复制到你的项目中相同的路径。
- en: Listing 13.3 Defining containers for Grafana, Loki, and Fluent Bit
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.3 定义Grafana、Loki和Fluent Bit的容器
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Username and password to access Grafana
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 访问Grafana的用户名和密码
- en: ❷ Volumes are used to load configuration for data sources and dashboards.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 体积用于加载数据源和仪表板的配置。
- en: ❸ Defines the Loki URL used to forward log messages
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定义用于转发日志消息的Loki URL
- en: ❹ Volumes are used to load configuration for collecting and delivering logs.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 体积用于加载数据收集和交付的配置。
- en: 'Next, start all three containers with the following command:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用以下命令启动所有三个容器：
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Thanks to the dependencies defined in Docker Compose between containers, starting
    Grafana will also run Loki and Fluent Bit.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢Docker Compose在容器之间定义的依赖关系，启动Grafana也将运行Loki和Fluent Bit。
- en: Fluent Bit can be configured to collect logs from different sources. For Polar
    Bookshop we’ll rely on the Fluentd driver available in Docker to collect logs
    automatically from running containers. The Docker platform itself listens to the
    log events from each container and routes them to the specified service. In Docker,
    a logging driver can be configured directly on a container. For example, update
    the Catalog Service configuration in Docker Compose to use the Fluentd logging
    driver, which will send the logs over to the Fluent Bit container.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Fluent Bit 可以配置为从不同的来源收集日志。对于 Polar Bookshop，我们将依赖 Docker 中可用的 Fluentd 驱动程序来自动收集运行容器的日志。Docker
    平台本身会监听每个容器的日志事件并将它们路由到指定的服务。在 Docker 中，可以直接在容器上配置日志驱动程序。例如，更新 Docker Compose
    中的目录服务配置以使用 Fluentd 日志驱动程序，这将把日志发送到 Fluent Bit 容器。
- en: Listing 13.4 Using Fluentd driver to route container logs to Fluent Bit
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.4 使用 Fluentd 驱动程序将容器日志路由到 Fluent Bit
- en: '[PRE5]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Ensures the Fluent Bit container is started before Catalog Service
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 确保在启动目录服务之前启动 Fluent Bit 容器
- en: ❷ Section to configure the container logging driver
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 配置容器日志驱动程序的章节
- en: ❸ Which logging driver to use
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用哪个日志驱动程序
- en: ❹ The address of the Fluent Bit instance where the logs should be routed
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 应将日志路由到的 Fluent Bit 实例的地址
- en: 'Next, package Catalog Service as a container image (./gradlew bootBuildImage),
    and run the application container as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将目录服务打包为容器镜像（./gradlew bootBuildImage），并按以下方式运行应用程序容器：
- en: '[PRE6]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Thanks to the dependencies defined in Docker Compose between containers, Keycloak
    and PostgreSQL will automatically be started as well.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了容器之间在 Docker Compose 中定义的依赖关系，Keycloak 和 PostgreSQL 将会自动启动。
- en: 'Now we’re ready to test the logging setup. First, send a few requests to Catalog
    Service to trigger the generation of some log messages:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好测试日志设置。首先，向目录服务发送几个请求以触发生成一些日志消息：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, open a browser window, head to Grafana (http://localhost:3000), and use
    the credentials configured in Docker Compose to log in (user/password). Then select
    the Explore page from the left menu, choose Loki as the data source, choose Last
    1 Hour from the time drop-down menu, and run the following query to search for
    all the logs produced by the catalog-service container:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，打开一个浏览器窗口，转到 Grafana（http://localhost:3000），并使用 Docker Compose 中配置的凭据登录（用户/密码）。然后从左侧菜单选择“探索”页面，选择
    Loki 作为数据源，从时间下拉菜单中选择“过去 1 小时”，并运行以下查询以搜索由 catalog-service 容器产生的所有日志：
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The result should be similar to what you can see in figure 13.3, showing the
    logs from application startup as well as the custom log messages you added to
    the BookController class.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应类似于图 13.3 所示，显示应用程序启动的日志以及您添加到 BookController 类中的自定义日志消息。
- en: '![13-03](../Images/13-03.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![13-03](../Images/13-03.png)'
- en: Figure 13.3 In Grafana, you can browse and search log messages aggregated and
    stored by Loki.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.3 在 Grafana 中，您可以浏览和搜索由 Loki 聚合和存储的日志消息。
- en: When you’re done testing the logging setup, stop all containers with docker-compose
    down.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 测试完日志设置后，使用 docker-compose down 停止所有容器。
- en: Note Following the same approach, update the Docker Compose configuration for
    all the other Spring Boot applications in the Polar Bookshop system to use the
    Fluentd logging driver and rely on Fluent Bit for collecting logs. As a reference,
    you can look at the source code repository accompanying this book (Chapter13/13-end/polar-deployment/docker).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：采用相同的方法，更新 Polar Bookshop 系统中所有其他 Spring Boot 应用程序的 Docker Compose 配置，以使用
    Fluentd 日志驱动程序并依赖 Fluent Bit 收集日志。作为参考，您可以查看本书附带的源代码仓库（第13章/13-end/polar-deployment/docker）。
- en: Logs provide some information about how an application behaves, but they’re
    not enough to infer its internal state. The next section will cover how you can
    make applications expose more data about their health status.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 日志提供了一些关于应用程序行为的信息，但不足以推断其内部状态。下一节将介绍如何使应用程序更多地暴露其健康状态的数据。
- en: 13.2 Health probes with Spring Boot Actuator and Kubernetes
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.2 使用 Spring Boot Actuator 和 Kubernetes 的健康检查
- en: Once an application is deployed, how can we tell if it’s healthy? Is it capable
    of handling new requests? Did it enter a faulty state? Cloud native applications
    should provide information about their health so that monitoring tools and deployment
    platforms can detect when there’s something wrong and act accordingly. We need
    dedicated health endpoints to check on the status of the application and any components
    or services it might use.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦应用程序部署，我们如何判断它是否健康？它是否能够处理新的请求？它是否进入了故障状态？云原生应用程序应提供有关其健康状态的信息，以便监控工具和部署平台能够检测到有问题并相应地采取行动。我们需要专门的健康端点来检查应用程序的状态以及它可能使用的任何组件或服务。
- en: The deployment platform can periodically invoke health endpoints exposed by
    applications. A monitoring tool could trigger an alert or a notification when
    an application instance is unhealthy. In the case of Kubernetes, the platform
    will check the health endpoints and automatically replace the faulty instance
    or temporarily stop sending traffic to it until it’s ready to handle new requests
    again.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 部署平台可以定期调用应用程序暴露的健康端点。当应用程序实例不健康时，监控工具可以触发警报或通知。在 Kubernetes 的情况下，平台将检查健康端点，并自动替换故障实例或暂时停止向其发送流量，直到它准备好再次处理新请求。
- en: For Spring Boot applications, you can leverage the Actuator library to expose
    information about their health through a /actuator/health HTTP endpoint, including
    details about the application’s status and the components in use, like databases,
    event brokers, and config servers.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Spring Boot 应用程序，您可以使用 Actuator 库通过 /actuator/health HTTP 端点公开有关其健康状态的信息，包括应用程序状态和使用组件的详细信息，如数据库、事件代理和配置服务器。
- en: Spring Boot Actuator is a useful library, providing many endpoints for monitoring
    and managing Spring Boot applications. Such endpoints can be exposed through HTTP
    or JMX, but either way we must protect them from unauthorized access. We’ll limit
    ourselves to using the HTTP endpoints, so we can use Spring Security to define
    access policies like those for any other endpoint we’ve worked with so far.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot Actuator 是一个有用的库，提供了许多用于监控和管理 Spring Boot 应用程序的端点。这些端点可以通过 HTTP
    或 JMX 暴露，但无论哪种方式，我们都必须保护它们免受未经授权的访问。我们将限制自己使用 HTTP 端点，因此我们可以使用 Spring Security
    来定义访问策略，就像我们迄今为止所使用的任何其他端点一样。
- en: This section will cover configuring health endpoints in Spring Boot applications
    using Actuator. You’ll then see how you can define liveness and readiness probes
    so Kubernetes can use its self-healing functionality.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何使用 Actuator 在 Spring Boot 应用程序中配置健康端点。然后您将了解如何定义存活性和就绪性探针，以便 Kubernetes
    可以使用其自我修复功能。
- en: 13.2.1 Defining health probes for Spring Boot applications using Actuator
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.1 使用 Actuator 为 Spring Boot 应用程序定义健康探针
- en: First of all, open the build.gradle file in the Catalog Service project (catalog-service),
    and ensure that it contains a dependency on Spring Boot Actuator (we used it in
    chapter 4 for refreshing configuration at runtime).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，打开 Catalog 服务项目（catalog-service）中的 build.gradle 文件，并确保它包含对 Spring Boot Actuator
    的依赖（我们在第 4 章中使用它来刷新运行时配置）。
- en: Listing 13.5 Adding dependency for Spring Boot Actuator in Catalog Service
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.5 在 Catalog 服务中添加 Spring Boot Actuator 依赖项
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: There are a few viable solutions for protecting the Spring Boot Actuator endpoints.
    For example, you could enable HTTP Basic authentication just for the Actuator
    endpoints, while all the others will keep using OpenID Connect and OAuth2\. For
    simplicity, in the Polar Bookshop system, we’ll keep the Actuator endpoints unauthenticated
    from inside the Kubernetes cluster and block any access to them from the outside
    (as you’ll see in chapter 15).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种可行的方案可以保护 Spring Boot Actuator 端点。例如，您可以只为 Actuator 端点启用 HTTP Basic 认证，而所有其他端点将继续使用
    OpenID Connect 和 OAuth2。为了简单起见，在 Polar Bookshop 系统中，我们将保持 Actuator 端点在 Kubernetes
    集群内部未认证，并阻止从外部对其的任何访问（您将在第 15 章中看到）。
- en: Warning In a real production scenario, I would recommend protecting access to
    the Actuator endpoints even from within the cluster.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 警告 在实际的生产场景中，我建议即使是在集群内部也要保护 Actuator 端点的访问。
- en: Go to the SecurityConfig class of your Catalog Service project and update the
    Spring Security configuration to allow unauthenticated access to the Spring Boot
    Actuator endpoints.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 前往您的 Catalog 服务项目的 SecurityConfig 类，并更新 Spring Security 配置以允许对 Spring Boot Actuator
    端点进行未认证访问。
- en: Listing 13.6 Allowing unauthenticated access to the Actuator endpoints
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.6 允许对 Actuator 端点进行未认证访问
- en: '[PRE10]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Allows unauthenticated access to any Spring Boot Actuator endpoint
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 允许对任何 Spring Boot Actuator 端点进行未认证访问
- en: Finally, open the application.yml file in your Catalog Service project (catalog-service),
    and configure Actuator to expose the health HTTP endpoint. If you followed the
    examples in chapter 4, you might have an existing configuration for the refresh
    endpoint. In that case, go ahead and replace it with the health endpoint.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，打开您的 Catalog Service 项目（catalog-service）中的 application.yml 文件，并配置 Actuator
    以暴露健康 HTTP 端点。如果您遵循了第 4 章中的示例，您可能已经有了刷新端点的现有配置。在这种情况下，请将其替换为健康端点。
- en: Listing 13.7 Exposing the health Actuator endpoint
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.7 暴露健康 Actuator 端点
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Exposes the /actuator/health endpoint via HTTP
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 通过 HTTP 暴露 /actuator/health 端点
- en: 'Let’s check the result. First we need to run all the backing services used
    by Catalog Service: Config Service, Keycloak, and PostgreSQL. We’ll run them as
    containers. Package Config Service as a container image (./gradlew bootBuildImage).
    Then open a Terminal window, navigate to the folder where you keep your Docker
    Compose file (polar-deployment/docker), and run the following command:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查结果。首先，我们需要运行 Catalog Service 所使用的所有支持服务：Config Service、Keycloak 和 PostgreSQL。我们将以容器形式运行它们。将
    Config Service 打包为容器镜像（./gradlew bootBuildImage）。然后打开一个终端窗口，导航到您保存 Docker Compose
    文件（polar-deployment/docker）的文件夹，并运行以下命令：
- en: '[PRE12]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After ensuring that all the containers are ready, run Catalog Service on the
    JVM (./gradlew bootRun), open a Terminal window, and send an HTTP GET request
    to the health endpoint:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 确保所有容器都准备就绪后，在 JVM 上运行 Catalog Service（./gradlew bootRun），打开一个终端窗口，并向健康端点发送
    HTTP GET 请求：
- en: '[PRE13]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The endpoint will return the overall health status for the Catalog Service application,
    which can be one of UP, OUT_OF_SERVICE, DOWN, or UNKNOWN. When the health status
    is UP, the endpoint returns a 200 OK response. If it’s not, it produces a 503
    Service Unavailable response.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 该端点将返回 Catalog Service 应用程序的整体健康状态，可以是 UP、OUT_OF_SERVICE、DOWN 或 UNKNOWN 之一。当健康状态为
    UP 时，端点返回 200 OK 响应。如果不是，它将产生 503 服务不可用响应。
- en: '[PRE14]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: By default, Spring Boot Actuator only returns the overall health status. Through
    application properties, however, you can make it provide more specific information
    regarding several components used by the application. To better protect access
    to this kind of information, you can enable showing health details and components
    always (always) or only when the request is authorized (when_authorized). Since
    we’re not protecting the Actuator endpoints at the application level, let’s make
    the extra information always available.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Boot Actuator 只返回整体健康状态。然而，通过应用程序属性，您可以使其提供有关应用程序使用的几个组件的更具体信息。为了更好地保护此类信息的访问，您可以选择始终显示健康细节和组件（always）或仅在请求被授权时显示（when_authorized）。由于我们不在应用程序级别保护
    Actuator 端点，让我们使额外信息始终可用。
- en: Listing 13.8 Configuring the health endpoint to expose more information
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.8 配置健康端点以暴露更多信息
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Always shows details about the application’s health
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 总是显示应用程序的健康细节
- en: ❷ Always shows information about the components used by the application
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 总是显示应用程序使用的组件信息
- en: Once again, rerun Catalog Service (./gradlew bootRun), and send an HTTP GET
    request to http://localhost:9001/actuator/health. This time, the resulting JSON
    object contains more detailed information about the application’s health. Here’s
    a partial result as an example.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 再次运行 Catalog Service（./gradlew bootRun），并向 http://localhost:9001/actuator/health
    发送 HTTP GET 请求。这次，结果 JSON 对象包含有关应用程序健康状态的更详细信息。以下是一个部分结果的示例。
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Detailed health information about components and features used by the application
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 应用程序使用的组件和功能的详细健康信息
- en: ❷ Overall application health status
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 应用程序的整体健康状态
- en: The generic health endpoint provided by Spring Boot Actuator is useful for monitoring
    and configuring alerts or notifications, since it contains details regarding both
    the application and the integration with its backing services. In the next section,
    you’ll see how to expose more specific information that’s used by a deployment
    platform like Kubernetes to manage containers.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot Actuator 提供的通用健康端点对于监控和配置警报或通知很有用，因为它包含有关应用程序及其支持服务的详细信息的细节。在下一节中，您将了解如何暴露更具体的信息，这些信息被像
    Kubernetes 这样的部署平台用于管理容器。
- en: Before moving on, stop the application process (Ctrl-C), but keep all the current
    containers running. You’ll need them soon!
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，停止应用程序进程（Ctrl-C），但保留所有当前容器运行。您很快就会需要它们！
- en: 13.2.2 Configuring health probes in Spring Boot and Kubernetes
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.2 在 Spring Boot 和 Kubernetes 中配置健康检查
- en: 'Besides showing detailed information about the application’s health, Spring
    Boot Actuator automatically detects when the application runs on a Kubernetes
    environment and enables the *health probes* to return liveness (/actuator/health/liveness)
    and readiness (/actuator/health/readiness) states, as illustrated in figure 13.4:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 除了显示有关应用程序健康状态的详细信息外，Spring Boot Actuator 还会自动检测应用程序是否在 Kubernetes 环境上运行，并启用
    *健康探针* 返回存活状态（/actuator/health/liveness）和就绪状态（/actuator/health/readiness），如图 13.4
    所示：
- en: '*Liveness state*—When an application is not live, this means it has entered
    a faulty internal state from which it won’t recover. By default, Kubernetes will
    try restarting it to fix the problem.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*存活状态*——当应用未存活时，这意味着它已进入一个无法恢复的故障内部状态。默认情况下，Kubernetes 将尝试重启它以解决问题。'
- en: '*Readiness state*—When an application is not ready, this means it can’t process
    new requests, either because it’s still initializing all its components (during
    the startup phase) or because it’s overloaded. Kubernetes will stop forwarding
    requests to that instance until it’s ready to accept new requests again.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*就绪状态*——当应用未就绪时，这意味着它无法处理新请求，要么是因为它仍在初始化所有组件（在启动阶段），要么是因为它过载。Kubernetes 将停止将请求转发到该实例，直到它准备好再次接受新请求。'
- en: '![13-04](../Images/13-04.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![13-04](../Images/13-04.png)'
- en: Figure 13.4 Kubernetes uses liveness and readiness probes to accomplish its
    self-healing features in case of failures.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.4 Kubernetes 使用存活性和就绪性探针在出现故障时实现其自我修复功能。
- en: Customizing liveness and readiness probes
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义存活性和就绪性探针
- en: To extend support for the health probes in any environment, you can configure
    Spring Boot Actuator through the dedicated properties. Open the Catalog Service
    project (catalog-service), and update the application.yml file as follows.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要在任何环境中扩展对健康探针的支持，您可以通过专用属性配置 Spring Boot Actuator。打开 Catalog Service 项目（catalog-service），并按以下方式更新
    application.yml 文件。
- en: Listing 13.9 Enabling liveness and readiness probes in any environment
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.9 在任何环境中启用存活性和就绪性探针
- en: '[PRE17]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Enables support for the health probes
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 启用对健康探针的支持
- en: 'Let’s check the result. All the backing services for Catalog Service should
    be up and running on Docker from the previous section. If not, go back and follow
    the instructions to start them all (docker-compose up -d config-service polar-postgres
    polar-keycloak). Then run Catalog Service on the JVM (./gradlew bootRun), and
    invoke the endpoint for the liveness probe:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查结果。上一节中所有为 Catalog Service 提供支持的后台服务都应该在 Docker 上运行。如果不是这样，请返回并按照说明启动它们所有（docker-compose
    up -d config-service polar-postgres polar-keycloak）。然后，在 JVM 上运行 Catalog Service（./gradlew
    bootRun），并调用存活性探针的端点：
- en: '[PRE18]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The liveness state of a Spring Boot application indicates whether it’s in a
    correct or broken internal state. If the Spring application context has started
    successfully, the internal state is valid. It doesn’t depend on any external components.
    Otherwise, it will cause cascading failures, since Kubernetes will try to restart
    the broken instances.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot 应用的存活状态表示它处于正确或损坏的内部状态。如果 Spring 应用程序上下文已成功启动，则内部状态有效。它不依赖于任何外部组件。否则，它将导致级联故障，因为
    Kubernetes 将尝试重启损坏的实例。
- en: 'Finally, check the result for the readiness probe endpoint:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，检查就绪性探针端点的结果：
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The readiness state of a Spring Boot application indicates whether it’s ready
    to accept traffic and process new requests. During the startup phase or graceful
    shutdown, the application is not ready and will refuse any requests. It might
    also become temporarily not ready if, at some point, it’s overloaded. When it’s
    not ready, Kubernetes will not send any traffic to the application instance.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot 应用的就绪状态表示它是否准备好接受流量并处理新请求。在启动阶段或优雅关闭期间，应用未就绪并将拒绝任何请求。如果它在某个时刻过载，它也可能暂时不就绪。当它不就绪时，Kubernetes
    不会向应用实例发送任何流量。
- en: When you’re done testing the health endpoints, stop the application (Ctrl-C)
    and the containers (docker-compose down).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试完健康端点后，停止应用（Ctrl-C）和容器（docker-compose down）。
- en: Note Go ahead and add Spring Boot Actuator to all the applications composing
    the Polar Bookshop system. In Order Service and Edge Service, remember to configure
    unauthenticated access to the Actuator endpoints in the SecurityConfig class,
    as we did for Catalog Service. In Dispatcher Service you’ll also need to add a
    dependency on Spring WebFlux (org.springframework.boot:spring-boot-starter-webflux)
    because Actuator needs a web server configured to serve its endpoints over HTTP.
    Then configure the health endpoints for all the applications, as you learned in
    this section. As a reference, you can look at the source code repository accompanying
    this book (Chapter13/13-end).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：请继续将Spring Boot Actuator添加到组成Polar Bookshop系统的所有应用程序中。在Order Service和Edge
    Service中，记得在SecurityConfig类中配置对Actuator端点的未认证访问，就像我们对Catalog Service所做的那样。在Dispatcher
    Service中，您还需要添加对Spring WebFlux（org.springframework.boot:spring-boot-starter-webflux）的依赖，因为Actuator需要一个配置好的Web服务器来通过HTTP提供服务其端点。然后配置所有应用程序的健康端点，就像您在本节中学到的那样。作为一个参考，您可以查看本书附带的源代码存储库（第13章/13-end）。
- en: By default, the readiness probe in Spring Boot doesn’t depend on any external
    components. You can decide whether any external systems should be included in
    the readiness probe.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Boot中的就绪探针不依赖于任何外部组件。您可以决定是否将任何外部系统包含在就绪探针中。
- en: For example, Catalog Service is an external system for Order Service. Should
    you include it in the readiness probe? Since Order Service adopts resilience patterns
    to deal with the scenario where Catalog Service is unavailable, you should keep
    Catalog Service out of the readiness probe. When it’s not available, Order Service
    will keep working correctly, but with graceful functionality degradation.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Catalog Service是Order Service的外部系统。您是否应该将其包含在就绪探针中？由于Order Service采用弹性模式来处理Catalog
    Service不可用的情况，因此您应该将Catalog Service排除在就绪探针之外。当它不可用时，Order Service将继续正常工作，但会进行优雅的功能降级。
- en: Let’s consider another example. Edge Service depends on Redis for storing and
    retrieving web session data. Should you include it in the readiness probe? Since
    Edge Service can’t process any new requests without accessing Redis, including
    Redis in the readiness probe might be a good idea. Spring Boot Actuator will consider
    both the internal state of the application and the integration with Redis to determine
    whether the application is ready to accept new requests.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑另一个例子。Edge Service依赖于Redis来存储和检索Web会话数据。您是否应该将其包含在就绪探针中？由于Edge Service在未访问Redis的情况下无法处理任何新请求，因此将Redis包含在就绪探针中可能是个好主意。Spring
    Boot Actuator将考虑应用程序的内部状态以及与Redis的集成，以确定应用程序是否准备好接受新请求。
- en: 'In the Edge Service project (edge-service), open the application.yml file,
    and define which indicators to use in the readiness probe: the application standard
    readiness state and the Redis health status. I’ll assume you have already added
    Spring Boot Actuator to Edge Service and configured the health endpoints as described
    earlier.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在Edge Service项目（edge-service）中，打开application.yml文件，并定义在就绪探针中使用哪些指标：应用程序的标准就绪状态和Redis健康状态。我将假设您已经将Spring
    Boot Actuator添加到Edge Service中，并按照前面描述的方式配置了健康端点。
- en: Listing 13.10 Including Redis in the computation of the readiness state
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.10 在计算就绪状态时包含Redis
- en: '[PRE20]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ The readiness probe will combine the application’s readiness state and Redis’s
    availability.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 就绪探针将结合应用程序的就绪状态和Redis的可用性。
- en: Configuring liveness and readiness probes in Kubernetes
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中配置存活性和就绪探针
- en: Kubernetes relies on the health probes (liveness and readiness) to accomplish
    its tasks as a container orchestrator. For example, when the desired state of
    an application is to have three replicas, Kubernetes ensures there are always
    three application instances running. If any of them doesn’t return a 200 response
    from the liveness probe, Kubernetes will restart it. When starting or upgrading
    an application instance, we’d like the process to happen without downtime for
    the user. Therefore, Kubernetes will not enable an instance in the load balancer
    until it’s ready to accept new requests (when Kubernetes gets a 200 response from
    the readiness probe).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes依赖于健康探针（存活性和就绪性）来完成其作为容器编排器的任务。例如，当应用程序期望的状态是拥有三个副本时，Kubernetes确保始终有三个应用程序实例在运行。如果其中任何一个实例没有从存活探针返回200响应，Kubernetes将重新启动它。当启动或升级应用程序实例时，我们希望这个过程对用户来说没有停机时间。因此，Kubernetes将不会在负载均衡器中启用实例，直到它准备好接受新请求（当Kubernetes从就绪探针获得200响应时）。
- en: Since liveness and readiness information is application-specific, Kubernetes
    needs the application itself to declare how to retrieve that information. Relying
    on Actuator, Spring Boot applications provide liveness and readiness probes as
    HTTP endpoints. Let’s see how we can configure Kubernetes to use those endpoints
    for the health probes.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 由于活动状态和就绪状态信息是特定于应用的，Kubernetes需要应用本身声明如何检索这些信息。依赖Actuator，Spring Boot应用提供作为HTTP端点的活动状态和就绪状态探针。让我们看看我们如何配置Kubernetes使用这些端点进行健康探针。
- en: In your Catalog Service project (catalog-service), open the Deployment manifest
    (k8s/deployment.yml), and update it with configuration for liveness and readiness
    probes as follows.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的目录服务项目（catalog-service）中，打开部署清单（k8s/deployment.yml），并更新配置以包含活动状态和就绪状态探针，如下所示。
- en: Listing 13.11 Configuring liveness and readiness probes for Catalog Service
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.11 配置目录服务的活动状态和就绪状态探针
- en: '[PRE21]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Configuration for the liveness probe
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 活动探针的配置
- en: ❷ Uses an HTTP GET request to get the liveness state
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用HTTP GET请求获取活动状态
- en: ❸ The endpoint to call for the liveness state
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 调用以获取活动状态的端点
- en: ❹ The port to use to fetch the liveness state
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用该端口来获取活动状态
- en: ❺ An initial delay before starting checking the liveness state
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 在开始检查活动状态之前有一个初始延迟
- en: ❻ The frequency for checking the liveness state
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 检查活动状态的频率
- en: ❼ Configuration for the readiness probe
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 就绪探针的配置
- en: Both probes can be configured so that Kubernetes will start using them after
    an initial delay (initialDelaySeconds), and you can also define the frequency
    with which to invoke them (periodSeconds). The initial delay should consider that
    the application will take a few seconds to start, and it will depend on the available
    computational resources. The polling period should not be too long, to reduce
    the time between the application instance entering a faulty state and the platform
    taking action to self-heal.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个探针都可以配置，以便Kubernetes在初始延迟（initialDelaySeconds）后开始使用它们，您还可以定义调用它们的频率（periodSeconds）。初始延迟应考虑应用需要几秒钟才能启动，并且它将取决于可用的计算资源。轮询周期不应太长，以减少应用实例进入故障状态与平台采取自我修复措施之间的时间。
- en: 'Warning If you run these examples on resource-constrained environments, you
    might need to adjust the initial delay and the polling frequency to allow the
    application more time to start and get ready to accept requests. You might need
    to do the same when running these examples on Apple Silicon computers until ARM64
    support is part of Paketo Buildpacks (you can follow the updates here: [https://github.com/paketo-buildpacks/stacks/issues/51](https://github.com/paketo-buildpacks/stacks/issues/51)).
    That’s because AMD64 container images are run on the Apple Silicon computers (ARM64)
    through a compatibility layer based on Rosetta, which impacts application startup
    time.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：如果您在资源受限的环境中运行这些示例，您可能需要调整初始延迟和轮询频率，以便给应用更多时间启动并准备好接受请求。当在运行这些示例的Apple Silicon计算机上运行时，您可能也需要这样做，直到ARM64支持成为Paketo
    Buildpacks的一部分（您可以在此处跟踪更新：[https://github.com/paketo-buildpacks/stacks/issues/51](https://github.com/paketo-buildpacks/stacks/issues/51)）。这是因为AMD64容器镜像通过基于Rosetta的兼容层在Apple
    Silicon计算机（ARM64）上运行，这影响了应用的启动时间。
- en: Go ahead and configure the liveness and readiness probes in the Deployment manifests
    for all the applications composing the Polar Bookshop system. As a reference,
    you can look at the source code repository accompanying this book (Chapter13/13-end).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 请继续为组成Polar Bookshop系统的所有应用配置活动状态和就绪状态探针。作为一个参考，您可以查看本书附带的源代码仓库（第13章/13-end）。
- en: On top of event logs, health information improves the information we can infer
    about the application’s internal state, but it’s not enough to achieve complete
    visibility. The following section will introduce the concept of metrics and how
    we can configure them in Spring Boot.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件日志之上，健康信息提高了我们可以推断的应用程序内部状态的信息，但这不足以实现完全的可见性。接下来的部分将介绍指标的概念以及我们如何在Spring
    Boot中配置它们。
- en: 13.3 Metrics and monitoring with Spring Boot Actuator, Prometheus, and Grafana
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.3 使用Spring Boot Actuator、Prometheus和Grafana进行指标和监控
- en: To properly monitor, manage, and troubleshoot an application running in production,
    we need to be able to answer questions like “how much CPU and RAM is the application
    consuming?”, “how many threads are used over time?”, and “what’s the rate of failing
    requests?” Event logs and health probes can’t help us answer those questions.
    We need something more. We need more data.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确监控、管理和调试在生产环境中运行的应用程序，我们需要能够回答诸如“应用程序消耗了多少CPU和RAM？”，“随着时间的推移使用了多少线程？”，以及“失败的请求数量是多少？”等问题。事件日志和健康检查无法帮助我们回答这些问题。我们需要更多数据。
- en: Metrics are numeric data about the application, measured and aggregated in regular
    time intervals. We use metrics to track the occurrence of an event (such as an
    HTTP request being received), count items (such as the number of allocated JVM
    threads), measure the time taken to perform a task (such as the latency of a database
    query), or get the current value of a resource (such as current CPU and RAM consumption).
    This is all valuable information for understanding why an application behaves
    in a certain way. You can monitor metrics and set alerts or notifications for
    them.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 指标是关于应用程序的数值数据，在常规的时间间隔内进行测量和汇总。我们使用指标来跟踪事件的发生（例如收到HTTP请求），计数项目（例如分配的JVM线程数量），测量执行任务所需的时间（例如数据库查询的延迟），或获取资源的当前值（例如当前的CPU和RAM消耗）。这些都是理解应用程序为何以某种方式行为的有价值信息。您可以监控指标并为它们设置警报或通知。
- en: Spring Boot Actuator collects application metrics out of the box by leveraging
    the Micrometer library ([https://micrometer.io](https://micrometer.io)). Micrometer
    contains instrumentation code for collecting valuable metrics from common components
    in a JVM-based application. It provides a vendor-neutral façade so that you can
    export the metrics collected from Micrometer using different formats, such as
    Prometheus/Open Metrics, Humio, Datadog, and VMware Tanzu Observability. Just
    as SLF4J provides a vendor-neutral façade for logging libraries, Micrometer does
    the same for metrics exporters.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot Actuator通过利用Micrometer库([https://micrometer.io](https://micrometer.io))默认收集应用程序指标。Micrometer包含用于从基于JVM的应用程序中的常见组件收集有价值指标的仪器代码。它提供了一个供应商中立的界面，因此您可以使用不同的格式（如Prometheus/Open
    Metrics、Humio、Datadog和VMware Tanzu Observability）导出从Micrometer收集的指标。正如SLF4J为日志库提供了一个供应商中立的界面一样，Micrometer也为指标导出器做了同样的事情。
- en: On top of the default Micrometer instrumentation libraries that are configured
    by Spring Boot, you can import additional instrumentation to collect metrics from
    specific libraries like Resilience4J or even define your own without vendor lock-in.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spring Boot配置的默认Micrometer仪器库之上，您可以导入额外的仪器来收集来自特定库（如Resilience4J）的指标，甚至可以定义自己的而不受供应商锁定。
- en: The most common format for exporting metrics is the one used by Prometheus,
    which is “an open-source systems monitoring and alerting toolkit” ([https://prometheus.io](https://prometheus.io)).
    Just as Loki aggregates and stores event logs, Prometheus does the same with metrics.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 导出指标最常用的格式是Prometheus使用的格式，它是一个“开源的系统监控和警报工具包”([https://prometheus.io](https://prometheus.io))。正如Loki聚合和存储事件日志一样，Prometheus也对指标进行同样的处理。
- en: In this section you’ll see how to configure metrics in Spring Boot. Then you’ll
    use Prometheus to aggregate metrics and Grafana to visualize them in dashboards.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将了解如何在Spring Boot中配置指标。然后您将使用Prometheus来汇总指标，并使用Grafana在仪表板中可视化它们。
- en: 13.3.1 Configuring metrics with Spring Boot Actuator and Micrometer
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.1 使用Spring Boot Actuator和Micrometer配置指标
- en: Spring Boot Actuator auto-configures Micrometer out of the box to collect metrics
    about a Java application. One way of exposing such metrics is by enabling the
    /actuator/metrics HTTP endpoint implemented by Actuator. Let’s see how to do that.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot Actuator默认自动配置Micrometer来收集关于Java应用程序的指标。暴露此类指标的一种方法是通过启用Actuator实现的/actuator/metrics
    HTTP端点。让我们看看如何做到这一点。
- en: In your Catalog Service project (catalog-service), update the application.yml
    file to expose the metrics endpoint via HTTP.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的目录服务项目（catalog-service）中，更新application.yml文件以通过HTTP暴露指标端点。
- en: Listing 13.12 Exposing the metrics Actuator endpoint
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.12 暴露指标Actuator端点
- en: '[PRE22]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Exposes both health and metrics endpoints
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 暴露健康和指标端点
- en: 'Ensure the backing services required by Catalog Service are up and running
    with the following command:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 确保目录服务所需的支撑服务通过以下命令启动并运行：
- en: '[PRE23]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then run the application (./gradlew bootRun), and call the /actuator/metrics
    endpoint:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行应用程序（./gradlew bootRun），并调用/actuator/metrics端点：
- en: '[PRE24]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The result is a collection of metrics you can further explore by adding the
    name of a metric to the endpoint (for example, /actuator/metrics/jvm.memory.used).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是您可以进一步探索的指标集合，通过向端点添加指标名称（例如，/actuator/metrics/jvm.memory.used）。
- en: Micrometer provides the instrumentation to generate those metrics, but you might
    want to export them in a different format. After deciding which monitoring solution
    you’d like to use to collect and store the metrics, you’ll need to add a specific
    dependency on that tool. In the Grafana observability stack, that tool is Prometheus.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 提供了生成这些指标的仪表化工具，但您可能希望以不同的格式导出它们。在决定您想使用哪种监控解决方案来收集和存储指标之后，您需要添加对该工具的特定依赖项。在
    Grafana 可观察性堆栈中，该工具是 Prometheus。
- en: In the Catalog Service project (catalog-service), update the build.gradle file
    with a dependency on the Micrometer library that provides integration with Prometheus.
    Remember to refresh or reimport the Gradle dependencies after the new addition.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Catalog Service 项目（catalog-service）中，更新 build.gradle 文件，添加对提供 Prometheus 集成的
    Micrometer 库的依赖项。请记住，在添加新依赖项后，刷新或重新导入 Gradle 依赖项。
- en: Listing 13.13 Adding dependency for Micrometer Prometheus
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.13 为 Micrometer Prometheus 添加依赖项
- en: '[PRE25]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Then update the application.yml file to expose the prometheus Actuator endpoint
    via HTTP. You can also remove the more generic metrics endpoint, since we’re not
    going to use it anymore.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 然后更新 application.yml 文件，通过 HTTP 暴露 Prometheus Actuator 端点。您还可以删除更通用的指标端点，因为我们不再使用它了。
- en: Listing 13.14 Exposing the prometheus Actuator endpoint
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.14 暴露 Prometheus Actuator 端点
- en: '[PRE26]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ Exposes both health and prometheus endpoints
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 暴露健康和 Prometheus 端点
- en: 'The default strategy used by Prometheus is pull-based, meaning that a Prometheus
    instance scrapes (*pulls*) metrics in regular time intervals from the application
    via a dedicated endpoint, which is /actuator/prometheus in the Spring Boot scenario.
    Rerun the application (./gradlew bootRun), and call the Prometheus endpoint to
    check the result:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 使用的默认策略是拉取式，这意味着 Prometheus 实例通过专用端点（在 Spring Boot 场景中为 /actuator/prometheus）以固定的时间间隔从应用程序中抓取（拉取）指标。重新运行应用程序（./gradlew
    bootRun），并调用 Prometheus 端点以检查结果：
- en: '[PRE27]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The result is the same collection of metrics you got from the metrics endpoint,
    but this time they are exported using a format understood by Prometheus. The following
    snippet shows an extract of the complete response, highlighting metrics related
    to the current number of threads:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是与指标端点获取的相同指标集合，但这次它们使用 Prometheus 理解的格式导出。以下代码片段显示了完整响应的摘录，突出显示与当前线程数相关的指标：
- en: '[PRE28]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This format is based on plain text and is called *Prometheus exposition format*.
    Given the wide adoption of Prometheus for generating and exporting metrics, this
    format has been polished and standardized in OpenMetrics ([https://openmetrics.io](https://openmetrics.io)),
    a CNCF-incubating project. Spring Boot supports both the original Prometheus format
    (the default behavior) and OpenMetrics, depending on the Accept header of the
    HTTP request. If you’d like to get metrics according to the OpenMetrics format,
    you need to ask for it explicitly:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 此格式基于纯文本，称为 *Prometheus 展示格式*。鉴于 Prometheus 在生成和导出指标方面得到广泛采用，此格式已在 OpenMetrics（[https://openmetrics.io](https://openmetrics.io)）中经过打磨和标准化，OpenMetrics
    是一个 CNCF 孵化项目。Spring Boot 支持原始 Prometheus 格式（默认行为）和 OpenMetrics，具体取决于 HTTP 请求的
    Accept 标头。如果您想根据 OpenMetrics 格式获取指标，您需要明确请求：
- en: '[PRE29]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: When you’re done analyzing the Prometheus metrics, stop the application (Ctrl-C)
    and all the containers (docker-compose down).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 当您完成分析 Prometheus 指标后，停止应用程序（Ctrl-C）和所有容器（docker-compose down）。
- en: Note You might encounter scenarios where you need to collect metrics from ephemeral
    applications or batch jobs that don’t run long enough to be pulled. In that case,
    Spring Boot lets you adopt a push-based strategy so that the application itself
    sends metrics to the Prometheus server. The official documentation explains how
    to configure such behavior ([http://spring.io/projects/spring-boot](http://spring.io/projects/spring-boot)).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您可能会遇到需要从短暂运行的应用程序或批处理作业中收集指标的情况，这些作业运行时间不够长，无法被拉取。在这种情况下，Spring Boot 允许您采用基于推送的策略，以便应用程序本身将指标发送到
    Prometheus 服务器。官方文档解释了如何配置这种行为（[http://spring.io/projects/spring-boot](http://spring.io/projects/spring-boot)）。
- en: 'Spring Boot Actuator relies on the Micrometer instrumentation and provides
    auto-configuration to generate metrics for various technologies you might use
    in your applications: JVM, loggers, Spring MVC, Spring WebFlux, RestTemplate,
    WebClient, data sources, Hibernate, Spring Data, RabbitMQ, and more.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot Actuator 依赖于 Micrometer 仪表化，并为可能用于应用程序的各种技术提供自动配置以生成指标：JVM、日志记录器、Spring
    MVC、Spring WebFlux、RestTemplate、WebClient、数据源、Hibernate、Spring Data、RabbitMQ 等。
- en: When Spring Cloud Gateway is in the classpath, as in the case of Edge Service,
    additional metrics are exported regarding the gateway routes. Some libraries,
    like Resilience4J, contribute dedicated Micrometer instrumentation through specific
    dependencies to register additional metrics.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Spring Cloud Gateway 在类路径中，如 Edge Service 的情况时，将导出有关网关路由的附加指标。一些库，如 Resilience4J，通过特定的依赖项贡献了专门的
    Micrometer 仪表化，以注册额外的指标。
- en: Open the build.gradle file in the Edge Service project (edge-service), and add
    the following dependency to include Micrometer instrumentation for Resilience4J.
    Remember to refresh or reimport the Gradle dependencies after the new addition.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 Edge Service 项目（edge-service）中的 build.gradle 文件，并添加以下依赖项以包含 Resilience4J
    的 Micrometer 仪表化。记住在添加新内容后刷新或重新导入 Gradle 依赖项。
- en: Listing 13.15 Adding dependency for Micrometer Resilience4J
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.15 为 Micrometer Resilience4J 添加依赖项
- en: '[PRE30]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Now that we’ve configured Spring Boot to expose metrics, let’s see how we can
    configure Prometheus to scrape them and Grafana to visualize them.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经配置了 Spring Boot 以公开指标，让我们看看如何配置 Prometheus 以抓取它们以及如何配置 Grafana 以可视化它们。
- en: 13.3.2 Monitoring metrics with Prometheus and Grafana
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.2 使用 Prometheus 和 Grafana 监控指标
- en: Like Loki, Prometheus collects and stores metrics. It even provides a GUI to
    visualize them and to define alarms, but we’ll use Grafana for that since it’s
    a more comprehensive tool.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Loki 类似，Prometheus 收集并存储指标。它甚至提供了一个用于可视化和定义警报的 GUI，但我们将使用 Grafana，因为它是一个更全面的工具。
- en: Metrics are stored as time-series data, containing the timestamp when they were
    registered and, optionally, labels. In Prometheus, labels are key/value pairs
    that add more information to the metric being recorded. For example, a metric
    registering the number of threads used by the application could be enhanced with
    labels qualifying the state of the threads (such as blocked, waiting, or idle).
    Labels help aggregate and query metrics.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 指标以时间序列数据的形式存储，包含它们被注册的时间戳以及可选的标签。在 Prometheus 中，标签是键/值对，为记录的指标添加更多信息。例如，一个记录应用程序使用的线程数量的指标可以通过标签来增强，以说明线程的状态（如阻塞、等待或空闲）。标签有助于聚合和查询指标。
- en: Micrometer provides the concept of *tags*, which are equivalent to Prometheus’s
    *labels*. In Spring Boot you can leverage configuration properties to define common
    labels for all the metrics produced by an application. For example, it’s useful
    to add an application label that tags each metric with the name of the application
    that produces it.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: Micrometer 提供了 *标签* 的概念，与 Prometheus 的 *标签* 相当。在 Spring Boot 中，你可以利用配置属性来定义所有由应用程序产生的指标的共同标签。例如，添加一个应用程序标签，将每个指标标记为生成它的应用程序的名称是有用的。
- en: Open the Catalog Service project (catalog-service), go to the application.yml
    file, and define a Micrometer tag with the application’s name, which will result
    in a label that’s applied to all metrics. Since the application name is already
    defined in the spring.application.name property, let’s reuse that instead of duplicating
    the value.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 Catalog Service 项目（catalog-service），转到 application.yml 文件，并定义一个带有应用程序名称的
    Micrometer 标签，这将导致应用于所有指标的标签。由于应用程序名称已在 spring.application.name 属性中定义，让我们重用它而不是重复值。
- en: Listing 13.16 Tagging all metrics with the application name
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.16 使用应用程序名称标记所有指标
- en: '[PRE31]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: ❶ Adds a Micrometer common tag with the application name. This results in a
    Prometheus label being applied to all metrics.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 添加一个带有应用程序名称的 Micrometer 通用标签。这会导致 Prometheus 标签应用于所有指标。
- en: 'With this change, all metrics will have an application label with the application
    name, which is very useful when querying metrics and building dashboards to visualize
    them in Grafana:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这次更改，所有指标都将具有一个应用程序标签，包含应用程序名称，这在查询指标和构建用于在 Grafana 中可视化的仪表板时非常有用：
- en: '[PRE32]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: You have already encountered Grafana when working with logs. Just as you browsed
    logs using Loki as a data source for Grafana, you can query metrics using Prometheus
    as a data source. Furthermore, you can use the metrics stored by Prometheus to
    define dashboards, graphically visualize data, and set alarms or notifications
    when certain metrics return known critical values. For example, when the rate
    of failing HTTP requests per minute goes above a certain threshold, you might
    want to get an alarm or a notification so you can act on it. Figure 13.5 illustrates
    the monitoring architecture.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 当您处理日志时已经遇到了 Grafana。就像您使用 Loki 作为 Grafana 的数据源来浏览日志一样，您可以使用 Prometheus 作为数据源来查询指标。此外，您可以使用
    Prometheus 存储的指标来定义仪表板、图形化可视化数据，并在某些指标返回已知关键值时设置警报或通知。例如，当每分钟失败的 HTTP 请求率超过某个阈值时，您可能希望收到警报或通知，以便您可以采取行动。图
    13.5 阐述了监控架构。
- en: '![13-05](../Images/13-05.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![13-05](../Images/13-05.png)'
- en: Figure 13.5 Monitoring architecture for cloud native applications based on the
    Grafana stack
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5 基于 Grafana 堆栈的云原生应用程序监控架构
- en: In your Polar Deployment project (polar-deployment), update the Docker Compose
    configuration (docker/docker-compose.yml) to include Prometheus. Grafana is already
    configured to use Prometheus as a data source in the configuration files you imported
    into your project earlier from Chapter13/13-end/polar-deployment/docker/observability.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的 Polar 部署项目（polar-deployment）中，更新 Docker Compose 配置（docker/docker-compose.yml）以包含
    Prometheus。Grafana 已经配置为使用您之前从第 13 章/13-end/polar-deployment/docker/observability
    导入到项目中的配置文件中的 Prometheus 作为数据源。
- en: Listing 13.17 Defining Prometheus container for collecting metrics
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.17 定义 Prometheus 容器以收集指标
- en: '[PRE33]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: ❶ Ensures Prometheus is started before Grafana
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 确保 Prometheus 在 Grafana 之前启动
- en: ❷ Volumes are used to load configuration for Prometheus scraping.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用卷来加载 Prometheus 抓取的配置。
- en: Unlike Loki, we don’t need a dedicated component to collect metrics from the
    applications. The Prometheus Server container can both collect and store metrics.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Loki 不同，我们不需要一个专门的组件来从应用程序中收集指标。Prometheus 服务器容器既可以收集也可以存储指标。
- en: 'Next, open a Terminal window, navigate to the folder where you keep your Docker
    Compose file (polar-deployment/docker), and run the complete monitoring stack
    with the following command:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，打开一个终端窗口，导航到您保存 Docker Compose 文件（polar-deployment/docker）的文件夹，并使用以下命令运行完整的监控堆栈：
- en: '[PRE34]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The Prometheus container is configured to poll metrics every 2 seconds from
    all the Spring Boot applications in Polar Bookshop when they run as containers.
    Package Catalog Service as a container image (./gradlew bootBuildImage), and run
    it from Docker Compose:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 容器配置为每 2 秒从 Polar Bookshop 中的所有以容器形式运行的 Spring Boot 应用程序中轮询指标。将目录服务打包为容器镜像（./gradlew
    bootBuildImage），并使用 Docker Compose 运行：
- en: '[PRE35]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Send a few requests to Catalog Service (http :9001/books), and then open a
    browser window and go to Grafana at http://localhost:3000 (user/password). In
    the Explore section, you can query metrics like you browsed logs. Choose Prometheus
    as the data source, select Last 5 Minutes from the time drop-down menu, and query
    the metrics related to the JVM memory used by the application as follows (figure
    13.6):'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 向目录服务（http :9001/books）发送几个请求，然后打开一个浏览器窗口并转到 Grafana（http://localhost:3000）（用户/密码）。在探索部分，您可以查询像浏览日志一样的指标。选择
    Prometheus 作为数据源，从时间下拉菜单中选择过去 5 分钟，并查询应用程序使用的 JVM 内存相关的指标，如下所示（图 13.6）：
- en: '[PRE36]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![13-06](../Images/13-06.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![13-06](../Images/13-06.png)'
- en: Figure 13.6 In Grafana, you can browse and query metrics aggregated and stored
    by Prometheus.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 在 Grafana 中，您可以浏览和查询 Prometheus 聚合和存储的指标。
- en: The metrics data can be used to draw dashboards for monitoring different application
    aspects. Select Dashboards > Manage from the left menu, and explore the dashboards
    I have included in Grafana, grouped within the Application folder.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 指标数据可用于绘制用于监控不同应用程序方面的仪表板。从左侧菜单中选择仪表板 > 管理，并探索我在 Grafana 中包含在应用程序文件夹内的仪表板。
- en: For example, open the JVM Dashboard (figure 13.7). It visualizes different metrics
    regarding the JVM where Spring Boot applications run, such as CPU usage, heap
    memory, non-heap memory, garbage collections, and threads.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，打开 JVM 仪表板（图 13.7）。它可视化 Spring Boot 应用程序运行的 JVM 的不同指标，例如 CPU 使用率、堆内存、非堆内存、垃圾回收和线程。
- en: '![13-07](../Images/13-07.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![13-07](../Images/13-07.png)'
- en: Figure 13.7 In Grafana, dashboards can be used to visualize Prometheus metrics.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 在 Grafana 中，可以使用仪表板可视化 Prometheus 指标。
- en: On the Dashboards page, explore the other dashboards I have configured to get
    more visibility into the Polar Bookshop applications. Each dashboard is enhanced
    with additional information on its goal and how to use it.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在仪表板页面，探索我配置的其他仪表板，以获取更多关于 Polar Bookshop 应用程序的可视性。每个仪表板都增加了关于其目标和如何使用它的额外信息。
- en: When you’re done checking the application metrics in Grafana, stop all the containers
    (docker-compose down).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在 Grafana 中检查完应用程序指标后，停止所有容器（docker-compose down）。
- en: 13.3.3 Configuring Prometheus metrics in Kubernetes
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.3 在 Kubernetes 中配置 Prometheus 指标
- en: When running applications in Kubernetes, we can use dedicated annotations to
    mark which containers the Prometheus server should scrape and inform it about
    the HTTP endpoint and port number to call.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中运行应用程序时，我们可以使用专用注释来标记 Prometheus 服务器应该抓取哪些容器，并通知它要调用的 HTTP 端点和端口号。
- en: You’ll have the chance to test this setup later in the book, where we’ll deploy
    the full Grafana observability stack in a production Kubernetes cluster. For now,
    let’s prepare the Deployment manifests for all of the Spring Boot applications
    in Polar Bookshop. For example, the following listing shows how to change the
    Catalog Service manifest (catalog-service/k8s/deployment.yml).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在本书的后面有机会测试这个设置，我们将在一个生产 Kubernetes 集群中部署完整的 Grafana 可观察性堆栈。现在，让我们为 Polar
    Bookshop 中的所有 Spring Boot 应用程序准备部署清单。例如，以下列表显示了如何更改目录服务清单（catalog-service/k8s/deployment.yml）。
- en: Listing 13.18 Annotating Catalog Service for Prometheus metrics scraping
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.18 为 Prometheus 指标抓取注释目录服务
- en: '[PRE37]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: ❶ Signals that Prometheus should scrape containers in this Pod
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Prometheus 应在此 Pod 中抓取容器的信号
- en: ❷ Identifies the HTTP endpoint that exposes Prometheus metrics
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 识别暴露 Prometheus 指标的 HTTP 端点
- en: ❸ Specifies the port number where the metrics endpoint is available
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 指定指标端点可用的端口号
- en: Annotations in Kubernetes manifests should be of type String, which is why quotes
    are needed in the case of values that could be mistakenly parsed as numbers or
    Boolean.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 清单中的注释应该是 String 类型，这就是为什么在可能被错误解析为数字或布尔值的值的情况下需要引号。
- en: Go ahead and configure metrics and Prometheus for all the remaining applications
    in the Polar Bookshop system, including the configuration for the Kubernetes manifests.
    As a reference, you can look at the source code repository accompanying this book
    (Chapter13/13-end).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 继续配置 Polar Bookshop 系统中所有剩余应用程序的指标和 Prometheus，包括 Kubernetes 清单的配置。作为参考，您可以查看本书附带的源代码存储库（第13章/13-end）。
- en: 'The next section will cover another type of telemetry we need in order to monitor
    applications and make them observable: traces.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分将介绍另一种我们需要用于监控应用程序和使它们可观察的遥测类型：跟踪。
- en: 13.4 Distributed tracing with OpenTelemetry and Tempo
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.4 使用 OpenTelemetry 和 Tempo 进行分布式跟踪
- en: Event logs, health probes, and metrics provide a wide variety of valuable data
    for inferring the internal state of an application. However, none of them consider
    that cloud native applications are distributed systems. A user request is likely
    to be processed by multiple applications, but so far we have no way to correlate
    data across application boundaries.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 事件日志、健康检查和指标为推断应用程序的内部状态提供了广泛的有价值数据。然而，它们都没有考虑到云原生应用程序是分布式系统。用户请求可能被多个应用程序处理，但到目前为止，我们还没有一种方法可以在应用程序边界之间关联数据。
- en: A simple way to solve that problem could be to generate an identifier for each
    request at the edge of the system (a *correlation ID*), use it in event logs,
    and pass it over to the other services involved. By using that correlation ID,
    we could fetch all log messages related to a particular transaction from multiple
    applications.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 解决该问题的简单方法可能是为系统边缘的每个请求生成一个标识符（一个*关联ID*），在事件日志中使用它，并将其传递给其他相关服务。通过使用该关联ID，我们可以从多个应用程序中检索与特定事务相关的所有日志消息。
- en: 'If we follow that idea further, we’ll get to *distributed tracing*, a technique
    for tracking requests as they flow through a distributed system, letting us localize
    where errors occur and troubleshoot performance issues. There are three main concepts
    in distributed tracing:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们进一步遵循这个想法，我们将得到*分布式跟踪*，这是一种跟踪请求在分布式系统中流动的技术，使我们能够定位错误发生的位置并解决性能问题。分布式跟踪有三个主要概念：
- en: A *trace* represents the activities associated with a request or a transaction,
    identified uniquely by a *trace ID*. It’s composed of one or more spans across
    one or more services.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*跟踪*代表与请求或事务相关的活动，由一个唯一的*跟踪ID*来标识。它由一个或多个跨越一个或多个服务的跨度组成。'
- en: Each step of the request processing is called a *span*, characterized by start
    and end timestamps and identified uniquely by the pair trace ID and *span ID*.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求处理的每一步都称为一个*跨度*，它由开始和结束时间戳组成，并由跟踪ID和*跨度ID*的唯一对来标识。
- en: '*Tags* are metadata that provide additional information regarding the span
    context, such as the request URI, the username of the currently logged-in user,
    or the tenant identifier.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*标签*是元数据，提供了有关跨度上下文的额外信息，例如请求URI、当前登录用户的用户名或租户标识符。'
- en: 'Let’s consider an example. In Polar Bookshop, you can fetch books through the
    gateway (Edge Service), and the request is then forwarded to Catalog Service.
    The trace related to handling such a request would involve these two applications
    and at least three spans:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个例子。在极地书店，你可以通过网关（边缘服务）获取书籍，然后请求被转发到目录服务。处理此类请求的跟踪涉及这两个应用程序和至少三个跨度：
- en: The first span is the step performed by Edge Service to accept the initial HTTP
    request.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个跨度是边缘服务接受初始HTTP请求所执行的步骤。
- en: The second span is the step performed by Edge Service to route the request to
    Catalog Service.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个跨度是边缘服务将请求路由到目录服务所执行的步骤。
- en: The third span is the step performed by Catalog Service to handle the routed
    request.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个跨度是目录服务处理路由请求所执行的步骤。
- en: There are multiple choices related to distributed tracing systems. First, we
    must choose the format and protocol we’ll use to generate and propagate traces.
    For this we’ll use OpenTelemetry (also called *OTel* ), a CNCF-incubating project
    that is quickly becoming the de facto standard for distributed tracing and aims
    at unifying the collection of telemetry data ([https://opentelemetry.io](https://opentelemetry.io)).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 与分布式跟踪系统相关的选择有很多。首先，我们必须选择我们将用于生成和传播跟踪的格式和协议。为此，我们将使用OpenTelemetry（也称为*OTel*），这是一个CNCF孵化项目，正在迅速成为分布式跟踪的事实标准，旨在统一遥测数据的收集（[https://opentelemetry.io](https://opentelemetry.io)）。
- en: Next we need to choose whether to use OpenTelemetry directly (with the OpenTelemetry
    Java instrumentation) or rely on a façade that instruments the code in a vendor-neutral
    way and integrates with different distributed tracing systems (such as Spring
    Cloud Sleuth). We’ll go with the first option.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要选择是否直接使用OpenTelemetry（使用OpenTelemetry Java工具）或依赖一个以供应商中立的方式对代码进行配置并集成到不同的分布式跟踪系统（如Spring
    Cloud Sleuth）的代理。我们将选择第一种选项。
- en: Once the applications are instrumented for distributed tracing, we’ll need a
    tool to collect and store traces. In the Grafana observability stack, the distributed
    tracing backend of choice is Tempo, a project that “lets you scale tracing as
    far as possible with minimal operational cost and less complexity than ever before”
    ([https://grafana.com/oss/tempo](https://grafana.com/oss/tempo)). Unlike the way
    we used Prometheus, Tempo follows a push-based strategy where the application
    itself pushes data to the distributed tracing backend.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦应用程序为分布式跟踪进行了配置，我们就需要一个工具来收集和存储跟踪。在Grafana可观察性堆栈中，首选的分布式跟踪后端是Tempo，这是一个“让你以尽可能低的操作成本和比以往任何时候都少的复杂性来扩展跟踪”的项目（[https://grafana.com/oss/tempo](https://grafana.com/oss/tempo)）。与我们在Prometheus中使用的方式不同，Tempo遵循基于推送的策略，其中应用程序本身将数据推送到分布式跟踪后端。
- en: This section will show you how to complete the Grafana observability setup with
    Tempo and use it to collect and store traces. Then I’ll show you how to use the
    OpenTelemetry Java instrumentation in your Spring Boot applications to generate
    and send traces to Tempo. Finally, you’ll learn how to query traces from Grafana.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将向您展示如何使用Tempo完成Grafana可观察性设置，并使用它来收集和存储跟踪。然后，我将向您展示如何在Spring Boot应用程序中使用OpenTelemetry
    Java工具生成并发送跟踪到Tempo。最后，您将学习如何从Grafana查询跟踪。
- en: OpenTelemetry, Spring Cloud Sleuth, and Micrometer Tracing
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry、Spring Cloud Sleuth和Micrometer跟踪
- en: 'A few standards have emerged for implementing distributed tracing and defining
    guidelines for generating and propagating traces and spans. OpenZipkin is the
    more mature project ([https://zipkin.io](https://zipkin.io)). OpenTracing and
    OpenCensus are more recent projects that have tried to standardize ways of instrumenting
    application code to support distributed tracing. They are both deprecated now,
    since they joined forces to work on OpenTelemetry: the ultimate framework to “instrument,
    generate, collect, and export telemetry data (metrics, logs, and traces).” Tempo
    supports all those options.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 一些标准已经出现，用于实现分布式跟踪和定义生成和传播跟踪和跨度指南。OpenZipkin是更成熟的项目([https://zipkin.io](https://zipkin.io))。OpenTracing和OpenCensus是更近期的项目，它们试图标准化支持分布式跟踪的应用程序代码的仪器化方式。现在它们都已经弃用，因为它们已经联合起来致力于OpenTelemetry：一个“仪器化、生成、收集和导出遥测数据（指标、日志和跟踪）”的终极框架。Tempo支持所有这些选项。
- en: Spring Cloud Sleuth ([https://spring.io/projects/spring-cloud-sleuth](https://spring.io/projects/spring-cloud-sleuth))
    is a project that provides auto-configuration for distributed tracing in Spring
    Boot applications. It takes care of instrumenting commonly used libraries in Spring
    applications and provides an abstraction layer on top of specific distributed
    tracing libraries. OpenZipkin is the default choice.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Sleuth ([https://spring.io/projects/spring-cloud-sleuth](https://spring.io/projects/spring-cloud-sleuth))是一个项目，为Spring
    Boot应用程序提供分布式跟踪的自动配置。它负责对Spring应用程序中常用的库进行仪器化，并在特定的分布式跟踪库之上提供抽象层。OpenZipkin是默认选择。
- en: In this book, I decided to show you how to use the OpenTelemetry Java instrumentation
    directly for two main reasons. First, support for OpenTelemetry in Spring Cloud
    Sleuth is still experimental and not ready for production at the time of writing
    ([https://github.com/spring-projects-experimental/spring-cloud-sleuth-otel](https://github.com/spring-projects-experimental/spring-cloud-sleuth-otel)).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我决定向您展示如何直接使用OpenTelemetry Java仪器化，主要有两个原因。首先，Spring Cloud Sleuth对OpenTelemetry的支持仍然是实验性的，并且在撰写本文时尚未准备好投入生产([https://github.com/spring-projects-experimental/spring-cloud-sleuth-otel](https://github.com/spring-projects-experimental/spring-cloud-sleuth-otel))。
- en: Second, Spring Cloud Sleuth will not be developed further once Spring Framework
    6 and Spring Boot 3 are released. The Spring project donated the Sleuth core framework
    to Micrometer and created a new Micrometer Tracing subproject aiming to provide
    a vendor-neutral façade for traces, similar to what Micrometer already does for
    metrics. Micrometer Tracing will provide support for OpenZipkin and OpenTelemetry.
    Based on Micrometer Tracing, code instrumentation will become a core aspect of
    all Spring libraries as part of the Spring Observability initiative.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，一旦Spring Framework 6和Spring Boot 3发布，Spring Cloud Sleuth将不再进一步开发。Spring项目将Sleuth核心框架捐赠给了Micrometer，并创建了一个新的Micrometer
    Tracing子项目，旨在为跟踪提供一个供应商中立的界面，类似于Micrometer已经为指标所做的那样。Micrometer Tracing将为OpenZipkin和OpenTelemetry提供支持。基于Micrometer
    Tracing，代码仪器化将成为所有Spring库的核心方面，作为Spring Observability倡议的一部分。
- en: 13.4.1 Managing traces with Tempo and Grafana
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.4.1 使用Tempo和Grafana管理跟踪
- en: A distributed tracing backend is responsible for aggregating, storing, and making
    traces searchable. Tempo is the solution in the Grafana observability stack. Figure
    13.8 illustrates the tracing architecture.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式跟踪后端负责聚合、存储并使跟踪可搜索。Tempo是Grafana可观察性堆栈中的解决方案。图13.8说明了跟踪架构。
- en: '![13-08](../Images/13-08.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![13-08](../Images/13-08.png)'
- en: Figure 13.8 Distributed tracing architecture for cloud native applications based
    on the Grafana stack
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.8基于Grafana堆栈的云原生应用程序的分布式跟踪架构
- en: Note Most vendors support OpenTelemetry, so you can easily swap your distributed
    tracing backend without changing anything in your applications. For example, instead
    of Tempo, you could send traces to other platforms like Honeycomb, Lightstep,
    or VMware Tanzu Observability.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：大多数供应商支持OpenTelemetry，因此您可以在不更改应用程序中的任何内容的情况下轻松地交换您的分布式跟踪后端。例如，您可以将跟踪发送到其他平台，如Honeycomb、Lightstep或VMware
    Tanzu Observability，而不是使用Tempo。
- en: First, let’s update the Docker Compose file for Polar Bookshop to include Tempo
    (polar-deployment/docker/docker-compose.yml). Grafana is already configured to
    use Tempo as a data source in the configuration files you imported earlier into
    your project from Chapter13/13-end/polar-deployment/docker/observability.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们更新Polar Bookshop的Docker Compose文件以包括Tempo（polar-deployment/docker/docker-compose.yml）。Grafana已经配置为在您之前导入到项目中的配置文件中使用Tempo作为数据源，这些配置文件来自第13章/13-end/polar-deployment/docker/observability。
- en: Listing 13.19 Defining a Tempo container for collecting and storing traces
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.19 定义用于收集和存储跟踪的Tempo容器
- en: '[PRE38]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: ❶ Ensures Tempo is started before Grafana
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 确保在Grafana之前启动Tempo
- en: ❷ Loads the custom configuration during the startup phase
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在启动阶段加载自定义配置
- en: ❸ Port to accept traces using the OpenTelemetry protocol over gRPC
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 通过gRPC协议将OpenTelemetry协议用于接受跟踪的端口
- en: ❹ Volumes are used to load configuration for Tempo.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用卷加载Tempo的配置。
- en: 'Next let’s run the full Grafana observability stack on Docker. Open a Terminal
    window, navigate to the folder where you keep your Docker Compose file, and run
    the following command:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们在Docker上运行完整的Grafana可观察性堆栈。打开一个终端窗口，导航到您保存Docker Compose文件的文件夹，并运行以下命令：
- en: '[PRE39]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Tempo is now ready to accept OpenTelemetry traces over gRPC on port 4317\. In
    the next section, you’ll see how to update a Spring Boot application to generate
    traces and send them over to Tempo.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: Tempo现在已准备好在端口4317上接受通过gRPC的OpenTelemetry跟踪。在下一节中，您将看到如何更新Spring Boot应用程序以生成跟踪并将它们发送到Tempo。
- en: 13.4.2 Configuring tracing in Spring Boot with OpenTelemetry
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.4.2 使用OpenTelemetry配置Spring Boot中的跟踪
- en: The OpenTelemetry project includes instrumentation that generates traces and
    spans for the most common Java libraries, including Spring, Tomcat, Netty, Reactor,
    JDBC, Hibernate, and Logback. The OpenTelemetry Java Agent is a JAR artifact provided
    by the project that can be attached to any Java application. It injects the necessary
    bytecode dynamically to capture traces and spans from all those libraries, and
    it exports them in different formats without you having to change your Java source
    code.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry项目包括为最常见的Java库生成跟踪和范围的仪器，包括Spring、Tomcat、Netty、Reactor、JDBC、Hibernate和Logback。OpenTelemetry
    Java Agent是由项目提供的JAR工件，可以附加到任何Java应用程序。它动态注入必要的字节码以捕获所有这些库的跟踪和范围，并且可以以不同的格式导出它们，而无需更改您的Java源代码。
- en: Java agents are often provided to the application at runtime from the outside.
    For better dependency management capabilities, in this case, I prefer using Gradle
    (or Maven) to include the agent JAR file in the final application artifact. Let’s
    see how.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Java代理通常在运行时从外部提供给应用程序。为了更好地管理依赖关系，在这种情况下，我更倾向于使用Gradle（或Maven）将代理JAR文件包含在最终应用程序工件中。让我们看看如何操作。
- en: Open your Catalog Service project (catalog-service). Then add a dependency on
    the OpenTelemetry Java Agent in your build.gradle file. Remember to refresh or
    reimport the Gradle dependencies after the new addition.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 打开您的目录服务项目（catalog-service）。然后在您的build.gradle文件中添加对OpenTelemetry Java Agent的依赖项。记得在添加新内容后刷新或重新导入Gradle依赖项。
- en: Listing 13.20 Adding dependency for OpenTelemetry Java Agent in Catalog Service
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.20 在目录服务中添加OpenTelemetry Java Agent的依赖项
- en: '[PRE40]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: ❶ The OpenTelemetry version
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ OpenTelemetry版本
- en: ❷ The OpenTelemetry agent instrumenting the Java code dynamically via bytecode
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 通过字节码动态对Java代码进行仪器化的OpenTelemetry代理
- en: Besides instrumenting the Java code to capture traces, the OpenTelemetry Java
    Agent also integrates with SLF4J (and its implementation). It provides trace and
    span identifiers as contextual information that can be injected into log messages
    through the MDC abstraction provided by SLF4J. That makes it extremely simple
    to navigate from log messages to traces and vice versa, achieving better visibility
    into the application than querying the telemetry in isolation.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对Java代码进行仪器化以捕获跟踪外，OpenTelemetry Java Agent还与SLF4J（及其实现）集成。它提供跟踪和范围标识符作为上下文信息，可以通过SLF4J提供的MDC抽象注入到日志消息中。这使得从日志消息导航到跟踪以及反之亦然变得极其简单，比单独查询遥测提供了更好的应用程序可见性。
- en: 'Let’s expand on the default log format used by Spring Boot and add the following
    contextual information:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们扩展Spring Boot默认的日志格式，并添加以下上下文信息：
- en: Application name (value from the spring.application.name property we configured
    for all applications)
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序名称（来自我们为所有应用程序配置的spring.application.name属性的值）
- en: Trace identifier (value from the trace_id field populated by the OpenTelemetry
    agent, when enabled)
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪标识符（当启用时，由OpenTelemetry代理填充的trace_id字段的值）
- en: Span identifier (value from the span_id field populated by the OpenTelemetry
    agent, when enabled)
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 范围标识符（当启用时，由OpenTelemetry代理填充的span_id字段的值）
- en: In your Catalog Service project, open the application.yml file, and add the
    three new pieces of information next to the log level (represented by %5p) following
    the Logback syntax. This is the same format used by Spring Cloud Sleuth.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的目录服务项目中，打开application.yml文件，并在日志级别（由%5p表示）旁边添加三个新的信息项，遵循Logback语法。这是Spring
    Cloud Sleuth使用的相同格式。
- en: Listing 13.21 Adding contextual information to logs, next to the level field
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.21 在日志级别字段旁边添加上下文信息
- en: '[PRE41]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: ❶ Includes application name, trace ID, and span ID next to the log level (%5p)
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在日志级别（%5p）旁边包含应用程序名称、跟踪ID和跨度ID
- en: Next, open a Terminal window, navigate to the Catalog Service root folder, and
    run ./gradlew bootBuildImage to package the application as a container image.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，打开一个终端窗口，导航到目录服务根目录，并运行./gradlew bootBuildImage将应用程序打包为容器镜像。
- en: The final step is configuring and enabling the OpenTelemetry Java Agent. For
    simplicity, we’ll enable OpenTelemetry only when running applications in containers
    and rely on environment variables to configure it.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是配置和启用OpenTelemetry Java代理。为了简单起见，我们将在容器中运行应用程序时启用OpenTelemetry，并依赖环境变量来配置它。
- en: 'We need three pieces of configuration to successfully enable tracing:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要三块配置才能成功启用跟踪：
- en: '*Instruct the JVM to load the OpenTelemetry Java agent.* We can do that via
    the JAVA_TOOL_OPTIONS standard environment variable supported by OpenJDK to provide
    additional configuration to the JVM.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*指示JVM加载OpenTelemetry Java代理。* 我们可以通过OpenJDK支持的JAVA_TOOL_OPTIONS标准环境变量来实现，为JVM提供额外的配置。'
- en: '*Use the application name to tag and categorize traces.* We’ll use the OTEL_SERVICE_
    NAME environment variable supported by the OpenTelemetry Java agent.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用应用程序名称来标记和分类跟踪。* 我们将使用OpenTelemetry Java代理支持的OTEL_SERVICE_NAME环境变量。'
- en: '*Define the URL of the distributed tracing backend.* In our case, it’s Tempo
    on port 4317, and it can be configured via the OTEL_EXPORTER_OTLP_ENDPOINT environment
    variable supported by the OpenTelemetry Java agent. By default, traces are sent
    over gRPC.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*定义分布式跟踪后端的URL。* 在我们的案例中，它是端口4317的Tempo，可以通过OpenTelemetry Java代理支持的OTEL_EXPORTER_OTLP_ENDPOINT环境变量进行配置。默认情况下，跟踪通过gRPC发送。'
- en: Go to your Polar Deployment project (polar-deployment), and open the Docker
    Compose file (docker/docker-compose.yml). Then add the necessary configuration
    to Catalog Service to support tracing.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 前往您的Polar部署项目（polar-deployment），并打开Docker Compose文件（docker/docker-compose.yml）。然后添加必要的配置以支持目录服务的跟踪。
- en: Listing 13.22 Defining OpenTelemetry for the Catalog Service container
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.22 为目录服务容器定义OpenTelemetry
- en: '[PRE42]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: ❶ Ensures Tempo is started before Catalog Service
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 确保在目录服务之前启动节拍（Tempo）
- en: ❷ Instructs the JVM to run the OpenTelemetry Java agent from the path where
    Cloud Native Buildpacks placed the application dependencies
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 指示JVM从云原生构建包放置应用程序依赖项的路径运行OpenTelemetry Java代理
- en: ❸ The name of the application, used to tag the traces produced by Catalog Service
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 用于标记目录服务生成的跟踪的应用程序名称
- en: ❹ The URL of the distributed tracing backend supporting the OpenTelemetry protocol
    (OTLP)
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 支持OpenTelemetry协议（OTLP）的分布式跟踪后端URL
- en: 'Finally, from the same folder, run Catalog Service as a container:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，从同一文件夹中运行目录服务作为容器：
- en: '[PRE43]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Once the application is up and running, send a few requests to trigger the
    generation of some logs and traces about your HTTP requests:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦应用程序启动并运行，发送一些请求以触发生成一些关于您的HTTP请求的日志和跟踪：
- en: '[PRE44]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Then check the logs from the container (docker logs catalog-service). You’ll
    see that each log message now has a new section containing the application name
    and, when available, the trace and span identifiers:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 然后检查容器中的日志（docker logs catalog-service）。您会看到每条日志消息现在都有一个新部分，包含应用程序名称，当可用时，还包括跟踪和跨度标识符：
- en: '[PRE45]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Distributed tracing helps us follow a request through multiple services, so
    we need another application to test whether it works correctly. Go ahead and make
    the same changes to Edge Service to support OpenTelemetry. Then run the application
    as a container from your Docker Compose file:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式跟踪帮助我们跟踪请求通过多个服务，因此我们需要另一个应用程序来测试它是否正确工作。继续对边缘服务进行相同的更改以支持OpenTelemetry。然后根据您的Docker
    Compose文件运行应用程序作为容器：
- en: '[PRE46]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Once again, send a few requests to trigger the generation of some logs and
    traces about your HTTP requests. This time you should go through the gateway:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 再次发送一些请求以触发生成一些关于您的HTTP请求的日志和跟踪。这次您应该通过网关进行：
- en: '[PRE47]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Using the trace ID logged by Catalog Service, we can retrieve (*correlate*)
    all the steps involved in processing the HTTP request to the /books endpoint started
    in Edge Service. Being able to navigate from logs to traces (and the other way
    around) is extremely useful for getting more visibility into all the steps involved
    in processing a request throughout a distributed system. Let’s see how it works
    in the Grafana stack.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 使用目录服务记录的跟踪ID，我们可以检索（关联）处理Edge Service中启动的/books端点的HTTP请求所涉及的所有步骤。能够从日志导航到跟踪（以及相反）对于深入了解分布式系统中处理请求的所有步骤非常有用。让我们看看它在Grafana堆栈中的工作方式。
- en: Open a browser window, go to Grafana (http://localhost:3000), and log in with
    the credentials configured in Docker Compose (user/password). On the Explore page,
    check the logs for Catalog Service ({container_name="/catalog-service"}), much
    like we did earlier. Next, click on the most recent log message to get more details.
    You’ll see a Tempo button next to the trace identifier associated with that log
    message. If you click that, Grafana redirects you to the related trace using data
    from Tempo, all in the same view (figure 13.9).
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 打开浏览器窗口，访问Grafana（http://localhost:3000），并使用Docker Compose中配置的凭据（用户/密码）登录。在探索页面，检查目录服务（{container_name="/catalog-service"）的日志，就像我们之前做的那样。接下来，点击最近的日志消息以获取更多详细信息。你会在与该日志消息关联的跟踪标识符旁边看到一个Tempo按钮。如果你点击它，Grafana会使用Tempo的数据将你重定向到相关的跟踪，所有这些都在同一个视图中（图13.9）。
- en: '![13-09](../Images/13-09.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![13-09](../Images/13-09.png)'
- en: Figure 13.9 In Grafana, you can navigate from logs (Loki) to traces (Tempo)
    using the trace ID included in the logs.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.9 在Grafana中，你可以使用日志（Loki）中的跟踪ID导航到跟踪（Tempo）。
- en: When you’re done inspecting logs and traces, stop all the containers (docker-compose
    down). Before moving on, go ahead and configure OpenTelemetry for all the remaining
    applications in the Polar Bookshop system. As a reference, you can look at the
    source code repository accompanying this book (Chapter13/13-end).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成检查日志和跟踪后，停止所有容器（docker-compose down）。在继续之前，请为Polar Bookshop系统中剩余的所有应用程序配置OpenTelemetry。作为一个参考，你可以查看本书附带的源代码存储库（第13章/13-end）。
- en: 'So far, we have worked with the three main types of telemetry data: logs, metrics,
    and traces. We also enabled health endpoints to provide additional information
    regarding application status. The following section will cover how you can retrieve
    even more information from the applications and achieve better visibility into
    their operations.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经处理了三种主要的遥测数据类型：日志、指标和跟踪。我们还启用了健康端点，以提供有关应用程序状态的其他信息。下一节将介绍您如何从应用程序中检索更多信息，并更好地了解其操作。
- en: 13.5 Application management and monitoring with Spring Boot Actuator
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.5 使用Spring Boot Actuator进行应用程序管理和监控
- en: In the previous sections, I’ve shown you the primary telemetry data that all
    cloud native applications should provide to achieve better observability. This
    final section will be dedicated to some specific information you can retrieve
    from applications to further enhance what you can infer about their operations.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我向您展示了所有云原生应用程序为了实现更好的可观察性应该提供的核心遥测数据。本节的最后将专门介绍您可以从应用程序中检索的一些特定信息，以进一步增强您对其操作的推断。
- en: Spring Boot Actuator provides many features to make your applications production-ready.
    You have already learned about health and metrics endpoints, but there are more.
    Table 13.1 lists some of the most useful management and monitoring endpoints implemented
    by Actuator. This section will show you how to use some of them.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot Actuator提供了许多功能，使您的应用程序准备好投入生产。您已经了解了健康和度量端点，但还有更多。表13.1列出了Actuator实现的一些最有用的管理和监控端点。本节将向您展示如何使用其中的一些。
- en: Table 13.1 Some of the most useful management and monitoring endpoints exposed
    by Spring Boot Actuator.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 表13.1 Spring Boot Actuator公开的一些最有用的管理和监控端点。
- en: '| Endpoint | Description |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 端点 | 描述 |'
- en: '| /beans | Shows a list of all the Spring beans managed by the application
    |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| /beans | 显示应用程序管理的所有Spring bean的列表 |'
- en: '| /configprops | Shows a list of all the @ConfigurationProperties-annotated
    beans |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| /configprops | 显示所有使用@ConfigurationProperties注解的bean的列表 |'
- en: '| /env | Shows a list of all the properties available to the Spring Environment
    |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| /env | 显示Spring环境可用的所有属性的列表 |'
- en: '| /flyway | Lists all the migrations run by Flyway and their statuses |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| /flyway | 列出Flyway运行的所有迁移及其状态 |'
- en: '| /health | Shows information about the application’s health |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| /health | 显示有关应用程序健康状态的信息 |'
- en: '| /heapdump | Returns a heap dump file |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| /heapdump | 返回堆转储文件 |'
- en: '| /info | Shows arbitrary application information |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| /info | 显示任意应用程序信息 |'
- en: '| /loggers | Shows the configuration of all the loggers in the application
    and allows you to modify them |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| /loggers | 显示应用程序中所有日志记录器的配置，并允许你修改它们 |'
- en: '| /metrics | Returns metrics about the application |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| /metrics | 返回应用程序的指标 |'
- en: '| /mappings | Lists all the paths defined in web controllers |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| /mappings | 列出在 web 控制器中定义的所有路径 |'
- en: '| /prometheus | Returns metrics about the application either in Prometheus
    or OpenMetrics format |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| /prometheus | 返回应用程序的指标，格式为 Prometheus 或 OpenMetrics |'
- en: '| /sessions | Lists all the active sessions managed by Spring Session and allows
    you to delete them |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| /sessions | 列出由 Spring Session 管理的所有活动会话，并允许你删除它们 |'
- en: '| /threaddump | Returns a thread dump in JSON format |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| /threaddump | 返回 JSON 格式的线程转储 |'
- en: 13.5.1 Monitoring Flyway migrations in Spring Boot
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.5.1 在 Spring Boot 中监控 Flyway 迁移
- en: In chapters 5 and 8, you saw how to version-control your database schemas using
    Flyway migrations and integrate them with Spring Boot, both in imperative and
    reactive stacks. Flyway keeps the history of all the migrations run on the application
    in a dedicated table in the database. It would be convenient to extract such information
    and monitor it, so you could be alerted if any migration should fail.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 5 章和第 8 章中，你看到了如何使用 Flyway 迁移来版本控制数据库模式，并将其与 Spring Boot 集成，无论是在命令式还是响应式堆栈中。Flyway
    将应用程序上运行的所有迁移的历史记录保存在数据库中的一个专用表中。提取此类信息并对其进行监控将非常方便，这样你就可以在任何迁移失败时收到警报。
- en: Spring Boot Actuator provides a dedicated endpoint (/actuator/flyway) to display
    information about all the migrations run by Flyway, including their status, date,
    type, and version. As you learned in the previous sections, you can enable new
    HTTP endpoints to be implemented by Actuator through the management.endpoints.web.exposure.include
    property. Let’s see that in action.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot Actuator 提供了一个专门的端点 (/actuator/flyway)，用于显示 Flyway 运行的所有迁移信息，包括其状态、日期、类型和版本。正如你在前面的章节中学到的，你可以通过
    management.endpoints.web.exposure.include 属性启用 Actuator 实现新的 HTTP 端点。让我们看看它是如何工作的。
- en: Note If you use Liquibase instead of Flyway, Spring Boot Actuator provides an
    /actuator/liquibase endpoint.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果你使用 Liquibase 而不是 Flyway，Spring Boot Actuator 提供了一个 /actuator/liquibase
    端点。
- en: Open the Catalog Service project (catalog-service), go to the application.yml
    file, and configure the Flyway endpoint to be exposed over HTTP by Spring Boot
    Actuator.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 Catalog Service 项目（catalog-service），进入 application.yml 文件，并配置 Flyway 端点以通过
    Spring Boot Actuator 暴露。
- en: Listing 13.23 Exposing the flyway Actuator endpoint
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.23 暴露 flyway Actuator 端点
- en: '[PRE48]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: ❶ Adds flyway to the list of Actuator endpoints exposed over HTTP
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将 flyway 添加到通过 HTTP 暴露的 Actuator 端点列表中
- en: 'Then run the backing services required by Catalog Service as a container. From
    your Docker Compose file, execute the following command:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，以容器形式运行 Catalog Service 所需的后备服务。从你的 Docker Compose 文件中，执行以下命令：
- en: '[PRE49]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Next, run Catalog Service (./gradlew bootRun), and call the Flyway endpoint:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，运行 Catalog Service（./gradlew bootRun），并调用 Flyway 端点：
- en: '[PRE50]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The result is a JSON file containing the list of all migrations run by Flyway
    and their details. The following snippet shows an extract of the complete response:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个包含 Flyway 运行的所有迁移及其详细信息的 JSON 文件。以下片段显示了完整响应的摘录：
- en: '[PRE51]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: ❶ The checksum of the migration script, used to ensure the file has not been
    changed
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 迁移脚本的校验和，用于确保文件未被更改
- en: ❷ Description of the migration
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 迁移的描述
- en: ❸ When the migration was performed
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 迁移执行的时间
- en: ❹ The name of the script containing the migration code
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 包含迁移代码的脚本名称
- en: ❺ The state of the migration execution
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 迁移执行的状态
- en: ❻ The type of migration (SQL or Java)
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 迁移的类型（SQL 或 Java）
- en: ❼ The migration version (as defined in the script filename)
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 迁移版本（在脚本文件名中定义）
- en: 13.5.2 Exposing application information
  id: totrans-374
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.5.2 暴露应用程序信息
- en: Among all the endpoints implemented by Spring Boot Actuator, /actuator/info
    is the most peculiar one, since it doesn’t return any data. Instead, it’s up to
    you to define what data you consider useful.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Spring Boot Actuator 实现的所有端点中，/actuator/info 是最独特的一个，因为它不返回任何数据。相反，定义你认为是有用的数据取决于你。
- en: One way to contribute data for the endpoint is through configuration properties.
    For example, go to your Catalog Service project (catalog-service), open the application.yml
    file, and add the following property to include the name of the system of which
    Catalog Service is part. You’ll also need to enable the info endpoint to be exposed
    through HTTP (similar to what we did with the other endpoints) and enable the
    env contributor responsible for parsing all the properties with the info. prefix.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 为端点贡献数据的一种方式是通过配置属性。例如，转到您的 Catalog Service 项目（catalog-service），打开 application.yml
    文件，并添加以下属性以包含 Catalog Service 所属系统的名称。您还需要启用 info 端点通过 HTTP 暴露（类似于我们对其他端点所做的那样），并启用负责解析所有以
    info. 前缀开头的属性的 env 贡献者。
- en: Listing 13.24 Exposing and configuring the info Actuator endpoint
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.24 暴露和配置 info Actuator 端点
- en: '[PRE52]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: ❶ Any property starting with the “info.” prefix will be returned by the info
    endpoint.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 以“info.”前缀开始的任何属性都将由 info 端点返回。
- en: ❷ Adds info to the list of Actuator endpoints to be exposed over HTTP
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将信息添加到要暴露在 HTTP 上的 Actuator 端点列表中
- en: ❸ Enables environmental info fetched from “info.” properties
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 启用从“info.”属性获取的环境信息
- en: You can also include information that’s generated automatically by Gradle or
    Maven regarding the application build or the last Git commit. Let’s see how we
    can add details about the application’s build configuration. In your Catalog Service
    project, go to the build.gradle file and configure the springBoot task to generate
    build information that will be parsed into a BuildProperties object and included
    in the result from the info endpoint.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以包括 Gradle 或 Maven 自动生成的有关应用程序构建或最后 Git 提交的信息。让我们看看我们如何添加有关应用程序构建配置的详细信息。在您的
    Catalog Service 项目中，转到 build.gradle 文件，并配置 springBoot 任务以生成将被解析到 BuildProperties
    对象中的构建信息，并将其包含在 info 端点的结果中。
- en: Listing 13.25 Configuring Spring Boot to include build information
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.25 配置 Spring Boot 以包含构建信息
- en: '[PRE53]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: ❶ Stores build information in a META-INF/build-info.properties file parsed by
    a BuildProperties object.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将构建信息存储在由 BuildProperties 对象解析的 META-INF/build-info.properties 文件中。
- en: 'Let’s test it out. Rerun Catalog Service (./gradlew bootRun). Then invoke the
    info endpoint:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来测试一下。重新运行 Catalog Service（./gradlew bootRun）。然后调用 info 端点：
- en: '[PRE54]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The result will be a JSON object containing build information and the custom
    info .system property we defined explicitly:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将是一个包含构建信息和显式定义的 custom info .系统属性的 JSON 对象：
- en: '[PRE55]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: You can expose additional information about the operating system and the Java
    version in use. Both can be enabled via configuration properties. Let’s update
    the application.yml file for the Catalog Service project as follows.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以暴露有关正在使用的操作系统和 Java 版本的附加信息。这两个都可以通过配置属性启用。让我们更新 Catalog Service 项目的 application.yml
    文件，如下所示。
- en: Listing 13.26 Adding Java and OS details to the info Actuator endpoint
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.26 将 Java 和 OS 详细信息添加到 info Actuator 端点
- en: '[PRE56]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: ❶ Enables Java information in the info endpoint
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 启用 info 端点中的 Java 信息
- en: ❷ Enables OS information in the info endpoint
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 启用 info 端点中的 OS 信息
- en: 'Let’s test it out. Rerun Catalog Service (./gradlew bootRun). Then invoke the
    info endpoint:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来测试一下。重新运行 Catalog Service（./gradlew bootRun）。然后调用 info 端点：
- en: '[PRE57]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The result now includes additional information about the Java version and operating
    system in use, which will be different depending on where you run the application:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 结果现在包括有关正在使用的 Java 版本和操作系统的附加信息，这取决于您在哪里运行应用程序：
- en: '[PRE58]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 13.5.3 Generating and analyzing heap dumps
  id: totrans-399
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.5.3 生成和分析堆转储
- en: Among the most annoying errors to debug in Java applications, memory leaks are
    probably the first that come to mind. Monitoring tools should alert you when a
    memory leak pattern is detected, usually inferred if the JVM heap usage metric
    keeps increasing over time. If you don’t catch the memory leak in advance, the
    application will throw the dreaded OutOfMemoryError error and crash.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Java 应用程序中调试时最令人烦恼的错误可能首先是内存泄漏。监控工具应在检测到内存泄漏模式时提醒您，通常可以通过 JVM 堆使用量随时间持续增加来推断。如果您事先没有捕捉到内存泄漏，应用程序将抛出可怕的
    OutOfMemoryError 错误并崩溃。
- en: Once you suspect an application might suffer from a memory leak, you must find
    out which objects are held in memory and block the garbage collection. There are
    different ways to proceed with finding problematic objects. For example, you could
    enable the Java Flight Recorder or attach a profiler like jProfiler to the running
    application. Another way is to take a snapshot of all the Java objects in the
    JVM heap memory (a *heap dump*), and analyze it with a specialized tool to find
    the root cause of the memory leak.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦怀疑应用程序可能存在内存泄漏，就必须找出哪些对象被保留在内存中，并阻止垃圾回收。有不同方法可以找到有问题的对象。例如，您可以为运行中的应用程序启用Java
    Flight Recorder或将jProfiler之类的分析器附加到应用程序上。另一种方法是捕获JVM堆内存中所有Java对象的快照（一个*heap dump*），并使用专用工具分析它，以找到内存泄漏的根本原因。
- en: Spring Boot Actuator provides a convenient endpoint (/actuator/heapdump) that
    you can call to generate a heap dump. Let’s see that in action. Go to your Catalog
    Service project (catalog-service), open the application.yml file, and configure
    Actuator to expose the heapdump endpoint.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot Actuator提供了一个方便的端点（/actuator/heapdump），您可以通过它来生成heap dump。让我们看看它是如何工作的。转到您的目录服务项目（catalog-service），打开application.yml文件，并配置Actuator以公开heapdump端点。
- en: Listing 13.27 Exposing the heapdump Actuator endpoint
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.27公开heapdump Actuator端点
- en: '[PRE59]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: ❶ Adds heapdump to the list of Actuator endpoints to be exposed over HTTP
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将heapdump添加到要通过HTTP公开的Actuator端点列表中
- en: 'Next, build and run Catalog Service (./gradlew bootRun). Finally, invoke the
    heapdump endpoint:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，构建并运行目录服务（./gradlew bootRun）。最后，调用heapdump端点：
- en: '[PRE60]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: The command will save a heapdump.bin file in the current directory. You can
    then open it in a dedicated tool for heap analysis like VisualVM ([https://visualvm.github.io](https://visualvm.github.io))
    or JDK Mission Control ([https://adoptopenjdk.net/jmc.html](https://adoptopenjdk.net/jmc.html)).
    Figure 13.10 shows an example of heap analysis in VisualVM.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 命令将在当前目录中保存heapdump.bin文件。然后您可以在像VisualVM ([https://visualvm.github.io](https://visualvm.github.io))
    或 JDK Mission Control ([https://adoptopenjdk.net/jmc.html](https://adoptopenjdk.net/jmc.html))
    这样的专用工具中打开它，进行heap分析。图13.10显示了VisualVM中heap分析的一个示例。
- en: '![13-10](../Images/13-10.png)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![13-10](../Images/13-10.png)'
- en: Figure 13.10 VisualVM provides tools to analyze a Java application’s heap dump.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.10 VisualVM提供了分析Java应用程序heap dump的工具。
- en: Finally, stop the application process (Ctrl-C) and all containers (docker-compose
    down).
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，停止应用程序进程（Ctrl-C）和所有容器（docker-compose down）。
- en: I encourage you to check out the Spring Boot Actuator official documentation,
    try out all the supported endpoints, and make the applications of the Polar Bookshop
    system more observable. For inspiration, refer to the source code repository accompanying
    the book to see which endpoints I have enabled on each application (Chapter13/
    13-end). They’re powerful tools that you’ll likely find helpful and convenient
    in real-world applications running in production.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励您查看Spring Boot Actuator官方文档，尝试所有支持的端点，并使Polar Bookshop系统的应用更具可观察性。为了获得灵感，请参考书中附带的源代码存储库，以查看我在每个应用程序上启用了哪些端点（第13章/
    13-end）。它们是强大的工具，您可能会在现实世界的生产环境中运行的应用程序中找到它们非常有帮助和方便。
- en: Summary
  id: totrans-413
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Observability is a property of cloud native applications that measures how well
    we can infer the internal state of an application from its outputs.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可观察性是云原生应用程序的一个属性，它衡量了我们从应用程序的输出中推断其内部状态的能力。
- en: Monitoring is about controlling known faulty states. Observability goes beyond
    that and permits us to ask questions about the unknown.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控是关于控制已知故障状态。可观察性超越了这一点，并允许我们询问关于未知的问题。
- en: Logs (or event logs) are discrete records of something that happened over time
    in a software application.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志（或事件日志）是软件应用程序中随时间发生的事件的离散记录。
- en: Spring Boot supports logging through SLF4J, which provides a façade over the
    most common logging libraries.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Boot支持通过SLF4J进行日志记录，它为最常见的日志库提供了一个门面。
- en: By default, logs are printed through the standard output as recommended by the
    15-Factor methodology.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下，日志通过标准输出打印，这是15-Factor方法推荐的。
- en: Using the Grafana observability stack, Fluent Bit collects logs produced by
    all applications and forwards them to Loki, which stores them and makes them searchable.
    Then you can use Grafana to navigate the logs.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Grafana可观察性堆栈，Fluent Bit收集所有应用程序产生的日志，并将它们转发到Loki，Loki存储它们并使它们可搜索。然后您可以使用Grafana导航日志。
- en: Applications should expose health endpoints to check their status.
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序应公开健康端点以检查其状态。
- en: Spring Boot Actuator exposes an overall health endpoint showing the status of
    the application and all the components or services it might use. It also provides
    specialized endpoints to be used as liveness and readiness probes by Kubernetes.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Boot Actuator 提供了一个整体健康端点，显示应用程序的状态以及它可能使用的所有组件或服务。它还提供了专门的端点，供 Kubernetes
    用作存活性和就绪性探测。
- en: When the liveness probe is down, it means the application has entered an unrecoverable
    faulty state, so Kubernetes will try to restart it.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当存活性探测失败时，这意味着应用程序已进入一个无法恢复的错误状态，因此 Kubernetes 将尝试重启它。
- en: When the readiness probe is down, the application is not ready to handle requests,
    so Kubernetes will stop any traffic directed to that instance.
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当就绪性探测失败时，应用程序尚未准备好处理请求，因此 Kubernetes 将停止指向该实例的所有流量。
- en: Metrics are numeric data about the application, measured at regular time intervals.
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标是关于应用程序的数值数据，在固定的时间间隔内进行测量。
- en: Spring Boot Actuator leverages the Micrometer façade to instrument the Java
    code, generate metrics, and expose them through a dedicated endpoint.
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Boot Actuator 利用 Micrometer 外观来对 Java 代码进行仪器化，生成指标并通过专用端点公开它们。
- en: When the Prometheus client is on the classpath, Spring Boot can expose metrics
    in the Prometheus or OpenMetrics format.
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 Prometheus 客户端在类路径上时，Spring Boot 可以以 Prometheus 或 OpenMetrics 格式公开指标。
- en: Using the Grafana observability stack, Prometheus aggregates and stores metrics
    from all applications. Then you can use Grafana to query metrics, design dashboards,
    and set alerts.
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Grafana 可观察性堆栈，Prometheus 从所有应用程序中聚合和存储指标。然后您可以使用 Grafana 查询指标、设计仪表板并设置警报。
- en: Distributed tracing, a technique for tracking requests as they flow through
    a distributed system, lets us localize where errors occur in a distributed system
    and troubleshoot performance issues.
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式跟踪是一种跟踪请求在分布式系统中流动的技术，使我们能够定位分布式系统中错误发生的位置，并解决性能问题。
- en: Traces are characterized by a trace ID and are composed of multiple spans, representing
    steps in a transaction.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪由跟踪 ID 特征，并由多个跨度组成，代表事务中的步骤。
- en: The OpenTelemetry project includes APIs and instrumentation that generates traces
    and spans for the most common Java libraries.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenTelemetry 项目包括生成最常见 Java 库跟踪和跨度的 API 和仪器。
- en: The OpenTelemetry Java Agent is a JAR artifact provided by the project that
    can be attached to any Java application. It injects the necessary bytecode dynamically
    to capture traces and spans from all those libraries and export them in different
    formats without having to change your Java source code explicitly.
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenTelemetry Java Agent 是由项目提供的一个 JAR 艺术品，可以附加到任何 Java 应用程序上。它动态地注入必要的字节码，以捕获所有这些库的跟踪和跨度，并以不同的格式导出，而无需显式更改您的
    Java 源代码。
- en: Using the Grafana observability stack, Tempo aggregates and stores metrics from
    all applications. Then you can use Grafana to query traces and correlate them
    with logs.
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Grafana 可观察性堆栈，Tempo 从所有应用程序中聚合和存储指标。然后您可以使用 Grafana 查询跟踪并将它们与日志相关联。
- en: Spring Boot Actuator provides management and monitoring endpoints to fulfill
    any requirements you might have to make your applications production-ready.
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Boot Actuator 提供了管理和监控端点，以满足您使应用程序生产就绪可能需要的任何要求。
