- en: 11 Transfer learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11 迁移学习
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Using prebuilt and pretrained models from TF.Keras and TensorFlow Hub
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TF.Keras 和 TensorFlow Hub 中的预构建和预训练模型
- en: Performing transfer learning between tasks in similar and distinct domains
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在类似和不同领域之间执行任务迁移学习
- en: Initializing models with domain-specific weights for transfer learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用特定领域权重初始化迁移学习模型
- en: Determining when to reuse high-dimensionality or low-dimensionality latent space
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定何时重用高维或低维潜在空间
- en: TensorFlow and TF.Keras support a wide availability of prebuilt and pretrained
    models. *Pretrained* models can be used as is, while *prebuilt* models can be
    trained from scratch. By replacing the task group, pretrained models can also
    be reconfigured to perform any number of tasks. The process of replacing or reconfiguring
    the task group with retraining is called *transfer learning.*
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 和 TF.Keras 支持广泛的预构建和预训练模型。*预训练*模型可以直接使用，而*预构建*模型则可以从零开始训练。通过替换任务组，预训练模型也可以重新配置以执行任何数量的任务。用重新训练替换或重新配置任务组的过程称为*迁移学习*。
- en: 'In essence, transfer learning means transferring the knowledge for solving
    one task to solving another task. The benefit of transfer learning versus training
    a model from scratch is that the new task can be trained faster and with less
    data. Think of it as a form of reuse: we are reusing the model with its learned
    weights.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，迁移学习意味着将解决一个任务的知识迁移到解决另一个任务。与从头开始训练模型相比，迁移学习的优势是新的任务可以更快地训练，并且需要的数据更少。把它看作是一种重用：我们正在重用带有其学习权重的模型。
- en: 'You might ask, can I reuse the weights learned for one model architecture for
    another? No, the two models have to be the same architecture, such as ResNet50
    to a ResNet50\. Another common question: can I reuse the learned weights on *any*
    different task? You could, but the results will vary depending on the level of
    similarity between the domain of the pretrained model and the new dataset. So
    what we really mean by the learned weights are the learned essential features,
    the corresponding feature extraction, and latent space representation—the representational
    learning.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，我能否将一个模型架构学习到的权重重用于另一个模型？不，两个模型必须是相同的架构，例如 ResNet50 到 ResNet50。另一个常见的问题是：我能否将学习到的权重重用于*任何*不同的任务？你可以，但结果将取决于预训练模型的领域和新数据集之间的相似程度。所以我们真正所说的学习权重是指学习到的基本特征、相应的特征提取和潜在空间表示——表示学习。
- en: Let’s look at a couple of examples in which transfer learning may or may not
    produce desirable results. Say we have a pretrained model for types and varieties
    of fruits and we have a new dataset for types and varieties of vegetables. It
    is highly likely that the learned representations for fruits are reusable for
    vegetables, and we just need to train the task group. But what if our new dataset
    consists of makes and models of trucks and vans. In this case, the dataset domains
    are so different from each other, it is very unlikely that the representations
    learned for fruits can be reused for trucks and vans. In the case of similar domains,
    the task we want our new model to do works on a domain that is similar to the
    data the original model is trained on.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看几个例子，看看迁移学习是否会产生期望的结果。假设我们有一个针对水果种类和品种的预训练模型，我们还有一个针对蔬菜种类和品种的新数据集。高度可能的是，水果的学习表示可以用于蔬菜，我们只需要训练任务组。但如果我们的新数据集包括卡车和面包车的型号和制造商。在这种情况下，数据集领域之间的差异非常大，水果学习到的表示不太可能用于卡车和面包车。在类似领域的情况下，我们希望新模型执行的任务在领域上与原始模型训练的数据相似。
- en: Another approach for learned representations is to use a model trained on a
    massively diverse set of classes of images. Numerous AI companies provide this
    type of transfer learning service. Typically, their pretrained models are trained
    on the order of tens of thousands of image classes. The presumption here is that
    with such broad diversity, some portion of the learned representation is reusable
    on any arbitrary new dataset. The downside is that to cover such a broad diversity,
    the latent space must be very large—so you end up with a model that is very large
    (overparameterized) in the task group.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种学习表示的方法是使用在大量不同图像类别上训练的模型。许多 AI 公司提供这种类型的迁移学习服务。通常，他们的预训练模型是在数万个图像类别上训练的。这里的假设是，由于这种广泛的多样性，学习到的表示中的一部分可以在任何任意新的数据集上重用。缺点是，为了覆盖如此广泛的多样性，潜在空间必须非常大——因此你最终得到的是一个在任务组中非常大的模型（过参数化）。
- en: A third approach is to find a sweet spot between the two approaches, the parameter-efficient,
    narrow-domain-trained model and the massively trained model. Model architectures
    like ResNet50 and, more recently, EffcientNet-B7 are pretrained with an ImageNet
    dataset consisting of a diverse set of 1000 classes. DIY transfer learning projects
    often make use of these models. ResNet50, for example, has a reasonably efficient
    but large enough latent space, before the task component, for the purpose of transfer
    learning to a wide variety of image classification datasets; the latent space
    consists of 2048 4 × 4 feature maps.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种方法是在参数高效、窄域训练模型和大规模训练模型之间找到一个合适的平衡点。例如，ResNet50和更近期的EffcientNet-B7都是使用包含1000个不同类别图像的ImageNet数据集进行预训练的。DIY迁移学习项目通常使用这些模型。例如，ResNet50具有合理高效的潜在空间，但足够大，可以在任务组件之前用于迁移学习到各种图像分类数据集；潜在空间由2048个4×4特征图组成。
- en: 'Let’s summarize these three approaches:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结这三种方法：
- en: 'Similar domain transfer:'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相似领域迁移：
- en: Parameter-efficient, narrow-domain pretrained model
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数高效、窄域预训练模型
- en: Retrains a new task component
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新训练新的任务组件
- en: 'Distinct domain transfer:'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同领域迁移：
- en: Parameter-overcapacity, narrow-domain pretrained model
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数过剩、窄域预训练模型
- en: Retrains a new task component with fine-tuning of other components
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用其他组件的微调重新训练新的任务组件
- en: General transfer
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用迁移
- en: Parameter-overcapacity, general-domain pretrained model
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数过剩、通用领域预训练模型
- en: Retrains a new task component
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新训练新的任务组件
- en: A pretrained model can also be reused in transfer learning to learn a different
    type of task from the pretrained model. For example, let’s say we have a pretrained
    model that classifies the architectural style from pictures of the front exterior
    of the house. And let’s say now we want to learn to predict the selling price
    of the house. It’s highly likely that the essential features, feature extraction,
    and latent space will transfer over to a different type of task, such as a regressor—a
    model that outputs a single real number (for example, the selling price of a house).
    This type of transfer learning to another task type is generally possible if the
    other task type could also be trained with the original dataset.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型也可以在迁移学习中重复使用，以从预训练模型学习不同类型的任务。例如，假设我们有一个预训练模型，它可以从房屋前外部的图片中分类建筑风格。现在假设我们想要学习预测房屋的售价。很可能，基本特征、特征提取和潜在空间会转移到不同类型的任务上，例如回归器——一个输出单个实数的模型（例如，房屋的售价）。如果其他任务类型也可以使用原始数据集进行训练，那么这种将迁移学习应用于其他任务类型通常是可能的。
- en: 'This chapter covers obtaining prebuilt and pretrained SOTA models from public
    resources: TF.Keras and TensorFlow Hub. Then I’ll walk you through using these
    models out-of-the box. And finally, you’ll learn various ways of using the pretrained
    models for transfer learning.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了从公共资源中获取预构建和预训练的SOTA模型：TF.Keras和TensorFlow Hub。然后我将向您展示如何直接使用这些模型。最后，您将学习各种使用预训练模型进行迁移学习的方法。
- en: 11.1 TF.Keras prebuilt models
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.1 TF.Keras预构建模型
- en: The TF.Keras framework comes with prebuilt models that you can either use as
    is to train a new model, or modify and/or fine-tune for transfer learning. These
    are based on best-in-class models for image classification, award-winning models
    in competitions like ImageNet that are cited frequently in deep learning research
    papers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: TF.Keras框架附带预构建模型，您可以使用它们直接训练新模型，或者修改和/或微调以进行迁移学习。这些模型基于图像分类的最佳模型，在ImageNet等竞赛中获奖的模型，这些模型在深度学习研究论文中被频繁引用。
- en: Documentation on the prebuilt Keras models is found on the Keras website ([https://keras.io/api/applications/](https://keras.io/api/applications/)).
    Table 11.1 lists the Keras prebuilt model architectures.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 预构建Keras模型的文档可以在Keras网站上找到（[https://keras.io/api/applications/](https://keras.io/api/applications/)）。表11.1列出了Keras预构建模型架构。
- en: Table 11.1 Keras prebuilt models
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 表11.1 Keras预构建模型
- en: '| Model type | SOTA model architecture |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 模型类型 | SOTA模型架构 |'
- en: '| Sequential CNN | VGG16, VGG19 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 顺序CNN | VGG16, VGG19 |'
- en: '| Residual CNN | ResNet, ResNet v2 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 残差CNN | ResNet, ResNet v2 |'
- en: '| Wide residual CNN | ResNeXt, Inception v3, InceptionResNet v2 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 宽残差CNN | ResNeXt, Inception v3, InceptionResNet v2 |'
- en: '| Alternatively connected CNN | DenseNet, Xception, NASNet |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 交替连接的CNN | DenseNet, Xception, NASNet |'
- en: '| Mobile CNN | MobileNet, MobileNet v2 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 移动CNN | MobileNet, MobileNet v2 |'
- en: The prebuilt Keras models are imported from the `keras.applications` module.
    The following are examples of the prebuilt SOTA models that can be imported. For
    example, if you wanted to use VGG16, simply replace the VGG19 with VGG16\. Some
    of the model architectures can be selected with different numbers of layers, such
    as the VGG, ResNet, ResNeXt, and DenseNet.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 预构建的Keras模型是从`keras.applications`模块导入的。以下是可以导入的预构建SOTA模型的示例。例如，如果您想使用VGG16，只需将VGG19替换为VGG16即可。一些模型架构可以选择不同数量的层，例如VGG、ResNet、ResNeXt和DenseNet。
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 11.1.1 Base model
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.1 基础模型
- en: By default, the TF.Keras prebuilt models are complete but untrained, meaning
    the weights and biases are randomly initialized. Each untrained prebuilt CNN model
    is configured for a specific input shape (see the documentation), and number of
    output classes. In most cases, the input shape is either (224, 224, 3) or (299,
    299, 3). The models will also take input in channel-first format, as in (3, 224,
    224) and (3, 299, 299). The number of output classes is typically 1000, meaning
    the models can identify 1000 common image labels. These prebuilt but untrained
    models won’t be that useful to you as-is, since you would have to fully train
    them on a dataset with the same number of labels (1000). It’s important to know
    what’s in these prebuilt models, so you can reconfigure with either pretrained
    weights, new task components, or both. We will cover all three of these subsequent
    reconfigurations throughout this chapter.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，TF.Keras预构建模型是完整的但未训练的，这意味着权重和偏差是随机初始化的。每个未训练的预构建CNN模型都针对特定的输入形状（见文档）和输出类数量进行配置。在大多数情况下，输入形状是(224,
    224, 3)或(299, 299, 3)。模型还将以通道优先的格式接收输入，例如(3, 224, 224)和(3, 299, 299)。输出类数量通常是1000，这意味着模型可以识别1000个常见的图像标签。这些预构建但未训练的模型本身可能对您不太有用，因为您必须在一个具有相同数量标签（1000）的数据集上完全训练它们。了解这些预构建模型的内容很重要，这样您就可以使用预训练的权重、新的任务组件或两者结合来重新配置。我们将在本章中涵盖所有三种后续的重新配置。
- en: Figure 11.1 depicts the architecture of a prebuilt CNN model. The architecture
    consists of the stem convolutional group preset for an input shape, one for more
    convolutional groups (learner), the bottleneck layer, and the classifier layer
    preset for 1000 classes.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1展示了预构建CNN模型的架构。该架构包括为输入形状预设的茎卷积组、一个用于更多卷积组（学习者）的预设、瓶颈层以及预设为1000个类别的分类器层。
- en: '![](Images/CH11_F01_Ferlitsch.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH11_F01_Ferlitsch.png)'
- en: Listing 11.1 A prebuilt CNN model architecture with the layers of the task group
    in dark gray
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.1 以深灰色显示任务组层的预构建CNN模型架构
- en: 'The prebuilt models do not have an assigned loss function and optimizer. Prior
    to using them, we must issue the `compile()` method to assign the loss, optimizer,
    and performance measurements. In the following code example, we first import and
    then instantiate a ResNet50 prebuilt model, and then we compile the model:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 预构建模型没有分配损失函数和优化器。在使用它们之前，我们必须发出`compile()`方法来分配损失、优化器和性能度量。在下面的代码示例中，我们首先导入并实例化一个ResNet50预构建模型，然后编译模型：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Gets a complete and untrained prebuilt ResNet50 model
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取一个完整且未训练的预构建ResNet50模型
- en: ❷ Compiles the model for training as a classifier for a dataset
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将模型编译为用于数据集的分类器
- en: Using the prebuilt models in this manner is pretty limited, considering not
    only is the input size fixed, but so is the number of categories for the classifier,
    which is 1000\. It’s unlikely whatever you need to do will use the default configuration.
    Next we will explore ways to configure the prebuilt models to perform various
    tasks.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式使用预构建模型相当有限，不仅因为输入大小固定，而且分类器的类别数量也是固定的，即1000。您需要完成的任何任务很可能不会使用默认配置。接下来，我们将探讨配置预构建模型以执行各种任务的方法。
- en: 11.1.2 Pretrained ImageNet models for prediction
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.2 用于预测的预训练ImageNet模型
- en: All of the prebuilt models come with weights and biases pretrained from the
    *ImageNet 2012* dataset, which contains 1.2 million images across 1000 classes.
    If your need is simply to predict whether an image is within the 1000 classes
    of the ImageNet dataset, you can use the pretrained prebuilt models as is. The
    mapping of label identifiers to class names can be found on GitHub ([https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)).
    Examples of classes include things like bald eagle, toilet paper, strawberry,
    and balloon.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 所有预构建的模型都附带从*ImageNet 2012*数据集预训练的权重和偏差，该数据集包含1000个类别中的120万张图像。如果你的需求仅仅是预测图像是否在ImageNet数据集的1000个类别中，你可以直接使用预训练的预构建模型。标签标识符到类名的映射可以在GitHub上找到（[https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)）。类别的例子包括秃鹰、卫生纸、草莓和气球等。
- en: 'Let’s use the prebuilt ResNet model, pretrained with ImageNet weights, to classify
    (or predict) an image of an elephant. Here’s the process, step by step:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用预训练的ResNet模型，该模型使用ImageNet权重进行预训练，来对大象的图像进行分类（或预测）。以下是步骤，一步一步来：
- en: The `preprocess_input()` method will preprocess the image according to the method
    used by the prebuilt ResNet model.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`preprocess_input()`方法将根据预构建的ResNet模型使用的方法对图像进行预处理。'
- en: The `decode_predictions()` method will map label identifiers back to the class
    name.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`decode_predictions()`方法将标签标识符映射回类名。'
- en: The prebuilt ResNet model is instantiated with ImageNet weights.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用ImageNet权重实例化预构建的ResNet模型。
- en: An image of an elephant is read in by OpenCV and then resized to (224, 224)
    to fit the input shape of the model.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用OpenCV读取大象的图像，并将其调整大小为（224, 224）以适应模型的输入形状。
- en: The image is then preprocessed using the model’s `preprocessed_input()` method.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后使用模型的`preprocessed_input()`方法对图像进行预处理。
- en: The image is then reshaped into a batch.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后将图像重塑为一批。
- en: The image is then classified by the model by using the `predict()` method.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后使用`predict()`方法通过模型对图像进行分类。
- en: The top three predicted labels are then mapped to their class names by using
    `decode_predictions()` and printed. In this example, we might see African Elephant
    as the top prediction.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后使用`decode_predictions()`将前三个预测标签映射到其类名，并打印出来。在这个例子中，我们可能会看到非洲象作为最高预测。
- en: Figure 11.2 depicts a TF.Keras pretrained model with its accompanying preprocessing
    input and post-processing output functions.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2展示了TF.Keras预训练模型及其伴随的预处理输入和后处理输出函数。
- en: '![](Images/CH11_F02_Ferlitsch.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH11_F02_Ferlitsch.png)'
- en: Listing 11.2 TF.Keras pretrained model with accompanying model-specific functions
    for preprocessing the input and post-processing the output
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.2 TF.Keras预训练模型及其伴随的预处理输入和后处理输出特定函数
- en: 'Now let’s see how to code this process:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何编写这个过程：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Gets a ResNet50 model, pretrained on ImageNet
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取在ImageNet上预训练的ResNet50模型
- en: ❷ Reads the image to predict into memory as a NumPy array
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 读取图像并将其作为NumPy数组预测到内存中
- en: ❸ Resizes the image to fit the input shape of the pretrained model
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将图像调整大小以适应预训练模型的输入形状
- en: ❹ Preprocesses the image using the same image processing used by the pretrained
    model
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用与预训练模型相同的图像处理方法对图像进行预处理
- en: ❺ Reshapes from single image shape (224, 224, 3) to a batch of one image (1,
    224, 224, 3) for the predict() method
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将单个图像形状（224, 224, 3）重塑为单个图像的一批（1, 224, 224, 3）以供predict()方法使用
- en: ❻ Calls the predict() method to classify the image
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 调用predict()方法对图像进行分类
- en: ❼ Displays the class name based on the predicted label using the decode function
    for the pretrained model
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 使用预训练模型的解码函数根据预测标签显示类名
- en: 11.1.3 New classifier
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.3 新的分类器
- en: The final classifier layer in all the prebuilt models can be removed and replaced
    with a new classifier—as well as another task, such as a regressor. The new classifier
    can then be used to train the prebuilt model for a new dataset and set of classes.
    For example, if you had a dataset of 20 classes of noodle dishes, you would simply
    remove the existing classifier layer, replace it with a new 20-node classifier
    layer, compile the model, and train it with the noodle dishes dataset.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有预构建模型中，可以移除最终的分类器层并替换为新的分类器——以及另一个任务，如回归器。然后，可以使用新的分类器来训练预构建模型以适应新的数据集和类别集。例如，如果你有一个包含20种面条菜肴的数据集，你只需移除现有的分类器层，用新的20节点分类器层替换它，编译模型，并用面条菜肴数据集进行训练。
- en: In all the prebuilt models, the classifier layer is referred to as the *top
    layer*. For TF.Keras prebuilt models, the input shape defaults to (224, 224, 3),
    and the number of classes in the output layer is 1000\. When instantiating an
    instance of a TF.Keras prebuilt model, you would set the parameter `include_top`
    to `False` to get a model instance without the classifier layer. Additionally,
    when `include_top=False`, we can specify a different input shape of the model
    with the parameter `input_shape`.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有预构建的模型中，分类器层被称为*顶层*。对于TF.Keras预构建模型，输入形状默认为(224, 224, 3)，输出层的类别数为1000。当你实例化一个TF.Keras预构建模型时，你会设置参数`include_top`为`False`以获取一个不带分类器层的模型实例。另外，当`include_top=False`时，我们可以使用参数`input_shape`指定模型的不同输入形状。
- en: Let’s now describe this process and its uses in the context of our 20-noodle
    dish classifier. Let’s say you own a noodle restaurant, and the cooking staff
    continuously places various freshly cooked noodle dishes on an ordering counter.
    A customer can pick any dish and, for simplicity’s sake, let’s say that all noodle
    dishes have the same price. The cashier simply needs to count the number of noodle
    dishes. But you still have some kinks to work out. Sometimes your cooking staff
    prepares too many of one or more dishes, and they go cold and have to be tossed
    out, so you have lost revenue. Other times, your cooking staff prepares too few
    of one or more dishes, and customers go to another restaurant because their dish
    was not available—a case of loss opportunity.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来描述这个流程及其在我们20种面条菜品分类器中的应用。假设你拥有一家面条餐厅，厨师们不断地将各种新鲜烹制的面条菜品放在点餐柜台上。顾客可以挑选任何菜品，为了简化起见，让我们假设所有面条菜品的价格相同。收银员只需要计算面条菜品的数量。但你仍然有一些问题需要解决。有时你的厨师准备过多的一种或多种菜品，这些菜品变凉后不得不丢弃，因此你损失了收入。其他时候，你的厨师准备得太少的一种或多种菜品，顾客因为他们的菜品不可用而去了另一家餐厅——这是一个机会损失的情况。
- en: To solve both problems, you plan to place one camera at the checkout and another
    camera on the cooking area where the cold noodle dishes are tossed out. You want
    the cameras to classify both the noodle dishes purchased and those tossed out
    in real time, and display that information to the cooking staff so they can better
    estimate which dishes to prepare.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这两个问题，你计划在结账处放置一个摄像头，并在丢弃冷面条菜品的烹饪区域放置另一个摄像头。你希望摄像头能够实时分类购买的面条菜品和丢弃的菜品，并将这些信息显示给厨师，以便他们更好地估计需要准备哪些菜品。
- en: Let’s start implementing your plan. First, since you’re an existing noodle restaurant,
    you hire someone to take pictures of the dishes that are placed on the ordering
    counter. When a picture is taken, the chef shouts the name of the dish, which
    is recorded with the picture. Let’s say at the end of a business day, your volume
    is 500 noodle dishes. And let’s say you have a fairly even distribution of dishes,
    which would give you an average of 25 pictures per noodle dish. That might seem
    like a small number per class, but since they are your dishes and the backgrounds
    are always the same, it’s probably enough. Now you just need to label the pictures
    from the audio recordings.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始实施你的计划。首先，因为你是一家现有的面条餐厅，你雇佣了一个人来拍摄放在点餐柜台上的菜品照片。当拍照时，厨师会喊出菜品的名字，这个名字会与照片一起记录。假设在一天的业务结束时，你的面条菜品数量为500种。假设菜品的分布相当均匀，这将给你平均每种面条菜品25张照片。这可能看起来每个类别的数量很少，但既然它们是你的菜品，背景总是相同的，这可能是足够的。现在你只需要从音频录音中标记照片。
- en: Now you’re ready for training. You get a prebuilt model from TF.Keras and specify
    `include_top=False` to drop the 1000-class classifier dense layer—which you will
    subsequently replace with a 20-node dense layer. You want your model to predict
    fast because you move a lot of noodle dishes, so you want to reduce the number
    of parameters without a negative effect on the model’s accuracy. Instead of predicting
    from the ImageNet size of (224, 224, 3), you specify `input_shape=(100, 100, 3)`
    to change the input vector for the model to size (100, 100, 3).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经准备好进行训练了。你从TF.Keras获取一个预构建的模型，并指定`include_top=False`以删除1000类分类器的密集层——你将随后用20节点的密集层替换它。因为你移动很多面条菜品，所以你希望模型预测速度快，因此你想要减少参数数量，同时不影响模型的准确性。你不再从(224,
    224, 3)大小的ImageNet进行预测，而是指定`input_shape=(100, 100, 3)`以改变模型的输入向量大小为(100, 100,
    3)。
- en: We could also drop the final flattening/pooling layer (the bottleneck layer)
    in the prebuilt model, to replace with your own by setting the parameter `pooling=None`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以在预构建模型中删除最终的展平/池化层（瓶颈层），通过设置参数 `pooling=None` 来替换成你自己的。
- en: Figure 11.3 depicts a reconfigurable prebuilt CNN model architecture. It consists
    of a stem convolutional group whose input size is configurable, one or more convolutional
    groups (learner), and optionally a configurable bottleneck layer.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 描述了一个可重构的预构建 CNN 模型架构。它由一个可配置输入大小的茎卷积组、一个或多个卷积组（学习器）以及可选的可配置瓶颈层组成。
- en: '![](Images/CH11_F03_Ferlitsch.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH11_F03_Ferlitsch.png)'
- en: Listing 11.3 In this reconfigurable prebuilt model architecture without the
    classifier layer, retaining the pooling layers is optional.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.3 在这个没有分类器层的可重构预构建模型架构中，保留池化层是可选的。
- en: As for the input shape, the documentation for the prebuilt models has a limitation
    on the minimum input shape size. For most models, this is (32, 32, 3). I generally
    don’t advise using the prebuilt models in this manner, because for most of these
    architectures, the final feature maps before the global average pooling layer
    (bottleneck layer) will be 1 × 1 (single-pixel) feature maps—essentially losing
    all spatial relationships. However, researchers have found that when used with
    CIFAR-10 and CIFAR-100, which are (32, 32, 3) images, they are able to find good
    hyperparameter settings before advancing to competition-grade (such as ImageNet)
    image datasets (224, 224, 3).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 至于输入形状，预构建模型的文档对最小输入形状大小有限制。对于大多数模型，这是 (32, 32, 3)。我通常不建议以这种方式使用预构建模型，因为对于这些架构中的大多数，全局平均池化层（瓶颈层）之前的最终特征图将是
    1 × 1（单像素）特征图——本质上丢失了所有空间关系。然而，研究人员发现，当与 CIFAR-10 和 CIFAR-100（32, 32, 3）图像一起使用时，他们能够在进入竞赛级（如
    ImageNet）图像数据集（224, 224, 3）之前找到良好的超参数设置。
- en: 'In the following code, we instantiate a prebuilt ResNet50 model and replace
    it with a new classifier for our 20-noodle dish example:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们实例化了一个预构建的 ResNet50 模型，并用一个新的分类器替换了它，用于我们的 20 种面条菜肴示例：
- en: We remove the existing 1000-node classifier with the parameter `include_ top=False`.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用参数 `include_top=False` 移除了现有的 1000 个节点的分类器。
- en: We set the input shape to (100, 100, 3) with the parameter `input_shape` for
    our smaller input size.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用参数 `input_shape` 将输入形状设置为 (100, 100, 3)，以适应较小的输入尺寸。
- en: We decide to retain the final pooling/flattening layer (bottleneck layer) as
    a global average pooling layer with the parameter pooling.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们决定保留最终的池化/展平层（瓶颈层），将其作为全局平均池化层，参数为 `pooling`。
- en: We add back a replacement dense layer with 20 nodes, corresponding to the number
    of noodle dishes, and a softmax activation function as the top layer.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们添加了一个替换的密集层，包含 20 个节点，对应于面条菜肴的数量，以及一个 softmax 激活函数作为顶层。
- en: The last (output) layer in the prebuilt ResNet50 model is `model.output`. This
    corresponds to the bottleneck layer, since we dropped the default classifier.
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预构建 ResNet50 模型的最后一个（输出）层是 `model.output`。这对应于瓶颈层，因为我们删除了默认的分类器。
- en: We bind the prebuilt ResNet50 `model.output` as the input to our replacement
    dense layer.
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将预构建 ResNet50 的 `model.output` 绑定为替换密集层的输入。
- en: We build the model. The input is the input to the ResNet model, which is `models.input`.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们构建了模型。输入是 ResNet 模型的输入，即 `models.input`。
- en: Finally, we compile the model for training, and set the loss function to `categorical_crossentropy`
    and the optimizer to `adam`, as best practices for an image-classification model.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们编译模型以进行训练，并将损失函数设置为 `categorical_crossentropy`，优化器设置为 `adam`，这是图像分类模型的最佳实践。
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Gets a prebuilt model for input shape (100,100,3) and without the final classifier
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取输入形状为 (100,100,3) 且没有最终分类器的预构建模型
- en: ❷ Adds a classifier for 20 classes
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 添加了 20 个类别的分类器
- en: ❸ Compiles the model for training
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 编译模型以进行训练
- en: For most of the TF.Keras prebuilt models, the bottleneck layer is a global average
    pooling layer. This layer acts as both a final pooling layer for the feature maps
    and a flatten operation that converts the feature maps to a 1D vector. In some
    cases, we might want to replace this layer with our own custom final pooling/flatten
    layer. In this case, we either specify the parameter `pooling=None` or don’t specify
    it, which is the default setting. So why might we do this?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数 TF.Keras 预构建模型，瓶颈层是一个全局平均池化层。这个层既作为特征图的最终池化层，又作为一个展平操作，将特征图转换为 1D 向量。在某些情况下，我们可能想用我们自己的自定义最终池化/展平层替换这个层。在这种情况下，我们要么指定参数
    `pooling=None`，要么不指定它，这是默认设置。那么我们为什么要这样做呢？
- en: To answer this question, let’s go back to our noodle dishes. Let’s assume when
    you trained the model, you got 92% accuracy and want to do better. First, you
    decide to add in image augmentation. Well, we probably won’t bother with horizontal
    flip, since the noodle dish will never be seen upside down! Likewise, vertical
    flip probably won’t help since the bowl of noodles is fairly uniform (no mirror).
    We can skip rotation, since the bowl of noodles is fairly uniform, and we skip
    scaling since the position of the camera to the dishes is fixed. Hmm, so you ask,
    what’s left?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，让我们回到我们的面条菜肴。假设当您训练模型时，您得到了92%的准确率，并希望做得更好。首先，您决定添加图像增强。嗯，我们可能不会考虑水平翻转，因为面条菜肴永远不会被倒着看到！同样，垂直翻转可能也不会有帮助，因为面条碗相当均匀（没有镜像）。我们可以跳过旋转，因为面条碗相当均匀，我们跳过缩放，因为相机到菜肴的位置是固定的。嗯，所以您问，还有什么？
- en: How about shifting the location of the bowl, since bowls will shift around both
    at the checkout and toss-out counters? You do this and get 94% accuracy. But you
    want even more accuracy. On a hunch, we speculate that perhaps there isn’t enough
    retained in the feature information, when each final feature map is reduced to
    a single pixel for flattening into a 1D vector by the default pooling of `GlobalAveragePooling2D`.
    You look at your model summary and see the size of the final feature maps is 4
    × 4\. So you decide to drop the default pooling, and replace it with `MaxPooling2D`
    with stride of 2, so each feature map will be reduced to 2 × 2, 4 pixels versus
    a single pixel, and then do a flattening into a 1D vector.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 关于移动碗的位置怎么样，因为碗在结账和扔掉柜台时都会移动？您这样做并得到了94%的准确率。但您希望更高的准确率。凭直觉，我们推测可能特征信息保留得不够，当每个最终特征图通过默认的
    `GlobalAveragePooling2D` 池化减少到一个像素，然后展平成一个1D向量时。您查看您的模型摘要，看到最终特征图的大小是 4 × 4。因此，您决定取消默认池化，并用步长为2的
    `MaxPooling2D` 替换它，这样每个特征图将减少到 2 × 2，4个像素而不是一个像素，然后进行展平成一个1D向量。
- en: 'In this code example, we replace the bottleneck layer with a max pooling (`outputs
    = MaxPooling2D(model.ouputs)`) and flattening (`outputs = Flatten(outputs)`),
    for our 20-noodle dish classifier:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码示例中，我们用最大池化 (`outputs = MaxPooling2D(model.outputs)`) 和展平 (`outputs = Flatten(outputs)`)
    替换了瓶颈层，用于我们的20种面条菜肴分类器：
- en: '[PRE4]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Gets a prebuilt model for input shape (100,100,3) and without the classifier
    group
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取输入形状为 (100,100,3) 且不带分类器组的预建模型
- en: ❷ Pools and flattens the feature maps into a 1D vector
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将特征图池化并展平成一个1D向量
- en: ❸ Adds a classifier for 20 classes
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 添加了一个20类别的分类器
- en: In this section, we covered both prebuilt and pretrained models from TF.Keras.
    To summarize, a prebuilt model is an existing model, generally based on a SOTA
    architecture, whose input shape and task group are reconfigurable, and the weights
    are not trained. A prebuilt model is typically used for training a model from
    scratch, and has the advantage of reuse and can be reconfigured to suit your dataset
    and task. The drawback is that the architecture might not be tuned to your dataset/task,
    so you end up with a model that is less efficient in size as well as less accurate.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了 TF.Keras 的预建模型和预训练模型。总结一下，预建模型是一个现有的模型，通常基于SOTA架构，其输入形状和任务组是可重新配置的，且权重未经过训练。预建模型通常用于从头开始训练模型，具有可重用性和可重新配置以适应您的数据集和任务的优势。缺点是架构可能没有针对您的数据集/任务进行调整，因此最终得到的模型在尺寸和准确性方面可能都不够高效。
- en: A pretrained model is essentially the same, except the weights have been pretrained
    with another dataset, such as from the ImageNet dataset. Pretrained models are
    used for either out-of-the-box predicting or transfer learning, and have the advantage
    of representational learning reuse to train new datasets/tasks faster and with
    less data. The drawback is that the pretrained representational learning may not
    be well suited for the domain of your dataset/task.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型本质上与预建模型相同，只是权重已经使用另一个数据集（如ImageNet数据集）进行了预训练。预训练模型用于即插即用预测或迁移学习，具有通过代表性学习重用快速训练新数据集/任务并减少数据量的优势。缺点是预训练的代表性学习可能不适合您的数据集/任务领域。
- en: In the next section, we cover the same concepts using prebuilt models from the
    TensorFlow Hub repository.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将使用来自 TensorFlow Hub 存储库的预建模型介绍相同的概念。
- en: 11.2 TF Hub prebuilt models
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 TF Hub 预建模型
- en: '*TensorFlow Hub*, or *TF Hub*, is an open source public repository of both
    prebuilt and pretrained models, and vastly more extensive than TF.Keras. TF.Keras
    prebuilt/ pretrained models are good for learning and practicing transfer learning,
    but are too limited in offerings for production purposes. TF Hub consists of a
    substantially greater number of prebuilt SOTA architectures, an extensive category
    of tasks, pretrained weights specific to domains, and public submissions beyond
    the models provided directly by the TensorFlow organization.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*TensorFlow Hub*，或*TF Hub*，是一个开源公共仓库，包含预构建和预训练模型，比TF.Keras更为广泛。TF.Keras的预构建/预训练模型适合学习和练习迁移学习，但在生产目的上提供的选项过于有限。TF
    Hub包含大量预构建的SOTA架构、广泛的任务类别、特定领域的预训练权重以及超出TensorFlow组织直接提供的模型之外的公共提交。 '
- en: 'This section covers the prebuilt models for image classification. TF Hub provides
    two versions of each model, which are described as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了图像分类的预构建模型。TF Hub为每个模型提供两个版本，具体描述如下：
- en: Modules to do image classification with the particular classes that the module
    has been trained for. This process is the same as for the pretrained models.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于特定类别的图像分类的模块。这个过程与预训练模型相同。
- en: Modules to extract image feature vectors (bottleneck values) for use in custom
    image classifiers. These classifiers are the same as the new classifier we de-scribed
    for TF.Keras.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于提取图像特征向量（瓶颈值）的模块，用于在自定义图像分类器中使用。这些分类器与TF.Keras中描述的新分类器相同。
- en: We will be working with two prebuilt models, one that does out-of-the-box classification,
    and one that does transfer learning. We will download these from the TensorFlow
    Hub open source repository of prebuilt models, which is located [www.tensorflow.org/hub](https://www.tensorflow.org/hub).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用两个预构建模型，一个用于开箱即用的分类，另一个用于迁移学习。我们将从TensorFlow Hub的预构建模型开源仓库中下载这些模型，该仓库位于[www.tensorflow.org/hub](https://www.tensorflow.org/hub)。
- en: 'To use TF Hub, you will need to first install the `tensorflow_hub` Python module:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用TF Hub，您首先需要安装`tensorflow_hub` Python模块：
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In your Python script, you access the TF Hub by importing the `tensorflow_hub`
    module:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的Python脚本中，通过导入`tensorflow_hub`模块来访问TF Hub：
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You are now set up to download our two models.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已设置好下载我们两个模型。
- en: 11.2.1 Using TF Hub pretrained models
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.1 使用TF Hub预训练模型
- en: 'TF Hub is also very versatile, when compared to TF.Keras, for the model format
    types that you can load:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 与TF.Keras相比，TF Hub在可加载的模型格式类型方面非常灵活：
- en: '*TF2.x SavedModel*—Use as a local, REST, or microservice on cloud, desktop/
    laptop, or workstation.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TF2.x SavedModel*—在本地、REST或云上的微服务、桌面/笔记本电脑或工作站中使用。'
- en: '*TF Lite*—Use as an application service on a mobile or memory-constrained IoT
    device.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TF Lite*—在移动或内存受限的IoT设备上的应用程序服务中使用。'
- en: '*TF.js*—Use within a client-side browser application.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*TF.js*—在客户端浏览器应用程序中使用。'
- en: '*Coral*—Optimized to use as an application service on a Coral Edge/IoT device.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Coral*—优化用于在Coral Edge/IoT设备上作为应用程序服务使用。'
- en: 'We will cover only TF 2.x SavedFormat models in this section. To load a model,
    you will do the following:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将仅涵盖TF 2.x的SavedFormat模型。要加载一个模型，您需要执行以下操作：
- en: Get the URL to the image classifier model in the TF Hub repository.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取TF Hub仓库中图像分类器模型的URL。
- en: Retrieve the model data from the repository specified by the URL with `hub.KerasLayer().`
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`hub.KerasLayer()`从指定的URL指定的仓库中检索模型数据。
- en: Construct a TF.Keras SavedModel from the model data by using the TF.Keras sequential
    API.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用TF.Keras sequential API从模型数据构建一个TF.Keras SavedModel。
- en: Specify the input shape to (224, 224, 3), which matches the input shape the
    pretrained model was trained on for the ImageNet database.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入形状指定为(224, 224, 3)，这与预训练模型在ImageNet数据库上训练的输入形状相匹配。
- en: '[PRE7]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Location of model data for ResNet50 v2 in TF Hub repository
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ TF Hub仓库中ResNet50 v2模型数据的存储位置
- en: ❷ Retrieves model data and constructs a SavedModel format model
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从模型数据检索并构建SavedModel格式的模型
- en: 'When you do a `model.summary(),` the output will appear as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 当您执行`model.summary()`时，输出将如下所示：
- en: '[PRE8]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now you can use the model to do predictions, which is known as *inference*.
    Figure 11.4 depicts the following steps to use a TF Hub ImageNet pretrained model
    for prediction:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用该模型进行预测，这被称为*推理*。图11.4描述了使用TF Hub ImageNet预训练模型进行预测的以下步骤：
- en: Get the label (class names) information for ImageNet so we can convert the predicted
    label (numeric index) to the class name.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取ImageNet的标签（类别名称）信息，以便我们将预测的标签（数字索引）转换为类别名称。
- en: 'Preprocess the images to predict the following:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理图像以预测以下内容：
- en: 'Resize the image input to match the input of the model: (224, 224, 3).'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像输入调整大小以匹配模型的输入：(224, 224, 3)。
- en: 'Normalize the image data: divide by 255.'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化图像数据：除以255。
- en: Invoke `predict()` for the images.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对图像调用 `predict()`。
- en: Use `np.argmax()` to return the label index of the highest probability.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `np.argmax()` 返回最高概率的标签索引。
- en: Convert the predicted label index to the corresponding class name.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测的标签索引转换为相应的类名。
- en: '![](Images/CH11_F04_Ferlitsch.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH11_F04_Ferlitsch.png)'
- en: Listing 11.4 Using an ImageNet pretrained model from TF Hub to predict a label,
    and then using ImageNet mapping to show predicted class name
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.4 使用TF Hub的ImageNet预训练模型预测标签，然后使用ImageNet映射显示预测的类名
- en: Here is an example implementation of these five steps.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是这些五个步骤的一个示例实现。
- en: '[PRE9]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Gets the conversion from ImageNet label index to class names
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取从ImageNet标签索引到类名的转换
- en: ❷ Preprocesses an image for prediction
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 预处理图像以进行预测
- en: ❸ Makes prediction with the model
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用模型进行预测
- en: ❹ Converts predicted label index to class name
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将预测的标签索引转换为类名
- en: 11.2.2 New classifier
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.2 新的分类器
- en: For building new classifiers for pretrained models, we load the corresponding
    model URL denoted as the *feature vector* version of the model. This version loads
    the pretrained model without the model top, or classifier. This allows you to
    add your own top, or task group. The output from the model is the output layer.
    We can also specify a new input shape that is different from the default input
    shape of the TF Hub model.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 对于为预训练模型构建新的分类器，我们加载相应的模型URL，表示为模型的*特征向量*版本。这个版本加载了预训练模型，但没有模型顶部或分类器。这允许你添加自己的顶部或任务组。模型的输出是输出层。我们还可以指定一个与TF
    Hub模型默认输入形状不同的新输入形状。
- en: 'The following is an example implementation of loading a feature vector version
    of a pretrained ResNet50 v2 model, where we will add our own task component for
    training a CIFAR-10 model. Since our input size for CIFAR-10 is different from
    TF Hub’s version for ResNet50 v2, which is (224, 224, 3), we will also optionally
    specify the input shape:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个加载预训练ResNet50 v2模型特征向量版本的示例实现，我们将添加自己的任务组件以训练CIFAR-10模型。由于我们的CIFAR-10输入大小与TF
    Hub的ResNet50 v2版本不同，其大小为(224, 224, 3)，因此我们还可以选择指定输入形状：
- en: Get the URL to the image classifier model in the TF Hub repository.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取TF Hub存储库中图像分类器模型的URL。
- en: Use `hub.KerasLayer()` to retrieve the model data from the repository specified
    by the URL`.`
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `hub.KerasLayer()` 从由URL指定的存储库中检索模型数据。
- en: Specify a new input shape of (32, 32, 3) for the CIFAR-10 dataset.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为CIFAR-10数据集指定新的输入形状为(32, 32, 3)。
- en: '[PRE10]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Location of the feature vector version model data for ResNet50 v2 in the TF
    Hub repository
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ TF Hub存储库中ResNet50 v2特征向量版本模型数据的存储位置
- en: ❷ Retrieves model data as a TF.Keras layer and sets the input shape
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将模型数据作为TF.Keras层检索并设置输入形状
- en: 'Here is an example implementation of constructing a new classifier for CIFAR-10
    in SavedModel format:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是构建CIFAR-10新分类器的一个示例实现，格式为SavedModel：
- en: Create a SavedModel using the sequential API.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用顺序API创建SavedModel。
- en: Specify the feature vector version of the pretrained ResNet v2 as the model
    bottom.
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将预训练的ResNet v2的特征向量版本指定为模型底部。
- en: Specify a dense layer of 10 nodes (one per CIFAR-10 class) as the model top.
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定一个有10个节点（每个CIFAR-10类别一个）的密集层作为模型顶部。
- en: Compile the model.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译模型。
- en: '[PRE11]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'When you do a `model.summary()`, the output will appear as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 当你执行 `model.summary()` 时，输出将如下所示：
- en: '[PRE12]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: So far, we’ve covered using pretrained models for doing out-of-the-box prediction
    and using reconfigurable prebuilt models for more convenient training of new models.
    Next, we will cover how to use and reconfigure pretrained models for more efficient
    training and using less data for new tasks.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了使用预训练模型进行即插即用预测和使用可重新配置的预构建模型进行更方便的新模型训练。接下来，我们将介绍如何使用和重新配置预训练模型以实现更高效的训练并减少新任务所需的数据。
- en: 11.3 Transfer learning between domains
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3 领域间的迁移学习
- en: In transfer learning, we use pretrained models for one task and retrain the
    classifier and/or fine-tune layers for a new task. This process is similar to
    what we just did with building the new classifier onto a prebuilt model, but otherwise
    fully trained the model from scratch.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在迁移学习中，我们使用预训练模型完成一个任务，并重新训练分类器和/或微调层以完成新任务。这个过程与我们刚刚在预构建模型上构建新分类器类似，但除此之外，模型是从头开始完全训练的。
- en: 'Transfer learning has two general approaches:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习有两种一般方法：
- en: '*Similar tasks*—The pretrained dataset and new dataset are from similar domains
    (such as fruits to vegetables).'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*相似任务*——预训练数据集和新数据集来自相似的域（例如水果到蔬菜）。'
- en: '*Distinct tasks*—The pretrained dataset and new dataset are from dissimilar
    domains (such as fruits and trucks/vans).'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*不同任务*——预训练数据集和新数据集来自不同的域（例如水果和卡车/面包车）。'
- en: 11.3.1 Similar tasks
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.1 相似任务
- en: As discussed earlier in this chapter, when deciding on the approach, we look
    at the similarity of the source (pretrained) domain of images and the destination
    (new) domain. The more similar, the more of the existing bottom layers we can
    reuse without retraining. For example, if we had a model trained on fruits, it’s
    likely that all of the bottom layers of the pretrained model can be reused without
    retraining for building a new model to recognize vegetables.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章前面所讨论的，在决定方法时，我们查看源（预训练）图像域和目标（新）域的相似性。越相似，我们可以重用更多现有底层而无需重新训练。例如，如果我们有一个在水果上训练的模型，那么预训练模型的底层所有层很可能可以重用而无需重新训练来构建一个用于识别蔬菜的新模型。
- en: We are assuming that the coarse and detailed features learned at the bottom
    layers will be the same for the new classifier, and can be reused as is, prior
    to entering the topmost layer(s) for classification. Let’s consider reasons we
    could speculate that fruits and vegetables are from very similar domains. Both
    are natural food. While fruits generally grow above ground and vegetables below
    ground, they have similar physical characteristics in shape and texture, and adornments
    such as stems and leaves.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设在底层学习到的粗略和详细特征对于新分类器将是相同的，并且可以在进入最顶层（的）分类之前直接重用。让我们考虑一些我们可以推测水果和蔬菜来自非常相似域的原因。两者都是天然食品。虽然水果通常在地面上生长，而蔬菜在地下生长，但它们在形状和质地上有相似的物理特性，以及如茎和叶等装饰。
- en: When the source and destination domains have this high level of similarity,
    we generally can replace the existing topmost classifier layer with a new classifier
    layer, freeze the lower layers, and train only the classifier layer. Since we
    don’t need to learn the weights/biases for the other layers, we can generally
    train a model for the new domain with substantially less data and fewer epochs.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 当源域和目标域具有这种高水平相似性时，我们通常可以用新的分类器层替换现有的最顶层分类器层，冻结底层层，并仅训练分类器层。由于我们不需要学习其他层的权重/偏差，因此我们可以用大量更少的数据和更少的周期来训练新域的模型。
- en: 'While having more data is always better, transfer learning between similar
    source and destination domains provides the ability to train with substantially
    smaller datasets. The two best practices for the minimum size of the dataset are
    as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然拥有更多数据总是更好的，但相似源域和目标域之间的迁移学习提供了使用大量更小数据集进行训练的能力。关于数据集最小尺寸的两个最佳实践如下：
- en: Each class (label) is 10% as big as in the source dataset.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个类别（标签）的大小是源数据集的10%。
- en: Each class (label) has at least 100 images.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个类别（标签）至少有100张图片。
- en: In contrast to the method shown for the *new classifier*, we modify the code
    to freeze all the layers preceding the topmost classifier layer prior to training.
    Freezing prevents the weights/biases of these layer(s) from being updated (retrained)
    during training of the classifier (topmost) layer. In TF.Keras, each layer has
    the property `trainable`, which defaults to `True`.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 与*新分类器*所示的方法相反，我们在训练之前修改代码以冻结所有位于最顶层分类器层之前的层。冻结可以防止这些层（的）权重/偏差在分类器（最顶层）层的训练期间被更新（重新训练）。在TF.Keras中，每个层都有`trainable`属性，默认为`True`。
- en: 'Figure 11.5 depicts the retraining on the classifier layer of a pretrained
    model; here are the steps:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5描述了预训练模型分类器层的重新训练；以下是步骤：
- en: Use a prebuilt model with pretrained weights/biases (ImageNet 2012),
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用具有预训练权重/偏差的预构建模型（ImageNet 2012），
- en: Drop the existing classifier from the prebuilt model (topmost layer).
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从预构建模型中删除现有的分类器（最顶层）。
- en: Freeze the remaining layers.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 冻结剩余的层。
- en: Add a new classifier layer.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个新的分类器层。
- en: Train the model through transfer learning.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过迁移学习训练模型。
- en: '![](Images/CH11_F05_Ferlitsch.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH11_F05_Ferlitsch.png)'
- en: Listing 11.5 When the source and destination domains are similar, only the classifier
    weights are retrained, while the remaining model bottom weights are frozen.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.5 当源域和目标域相似时，只有分类器权重被重新训练，而剩余模型底层的权重被冻结。
- en: 'Here is an example implementation:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个示例实现：
- en: '[PRE13]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Gets a pretrained model without the classifier and retains the global average
    pooling layer
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取不带分类器的预训练模型并保留全局平均池化层
- en: ❷ Freezes the weights of the remaining layer
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 冻结剩余层的权重
- en: ❸ Adds a classifier for 20 classes
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 添加一个20个类别的分类器
- en: ❹ Compiles the model for training
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 编译模型以进行训练
- en: Note that in this code example, we retained the original input shape (224, 224,
    3). In practice, if we change the input shape, the preexisting trained weights/biases
    won’t match the resolution of the feature extraction they were trained on. In
    this case, it’s better to handle this as a distinct task case.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这个代码示例中，我们保留了原始输入形状（224, 224, 3）。在实际操作中，如果我们更改输入形状，现有的训练权重/偏差将不会匹配它们训练的特征提取分辨率。在这种情况下，最好将其作为一个独立任务案例处理。
- en: 11.3.2 Distinct tasks
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.2 独立任务
- en: 'When the source and destination domain of the image datasets are dissimilar,
    such as our example of fruits and trucks/vans, we start with the same steps as
    in the previous similar task approach, but then follow up with fine-tuning the
    bottom layers. The steps, depicted in figure 11.6, generally are as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 当图像数据集的源域和目标域不同，例如我们例子中的水果和卡车/面包车时，我们开始与之前相似任务方法中的相同步骤，然后继续微调底部层。步骤，如图11.6所示，通常如下：
- en: Add a new classifier layer and freeze the remaining bottom layers.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个新的分类器层并冻结剩余的底部层。
- en: Train the new classifier layer for the target number of epochs.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练新的分类器层以达到目标周期数。
- en: 'Repeat for fine-tuning:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复进行微调：
- en: Unfreeze the next bottom-most convolutional group (moving in the direction of
    top to bottom).
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解冻下一个最底部的卷积组（从顶部到底部的方向）。
- en: Train for a few epochs to fine-tune.
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练几个周期以进行微调。
- en: 'After the convolutional groups are fine-tuned:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在卷积组微调后：
- en: Unfreeze the convolutional stem group.
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解冻卷积主干组。
- en: Train for a few epochs to fine-tune.
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练几个周期以进行微调。
- en: 'In Figure 11.6, you can see the training cycles of steps 2 through 4: the classifier
    is retrained in cycle 1, the convolutional groups are fine-tuned in sequential
    order in cycles 2 through 4, and the stem is fine-tuned in cycle 5\. Note that
    this is different from when the source and destination domains are similar and
    we fine-tune only the classifier.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在图11.6中，你可以看到步骤2到4的训练周期：在周期1中重新训练分类器，在周期2到4中按顺序微调卷积组，在周期5中微调主干。请注意，这与源域和目标域相似且我们只微调分类器的情况不同。
- en: '![](Images/CH11_F06_Ferlitsch.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图像](Images/CH11_F06_Ferlitsch.png)'
- en: Listing 11.6 In this distinct source-to-destination transfer learning, the convolutional
    groups are progressively fine-tuned.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.6 在这种独特的源到目标迁移学习中，卷积组逐步微调。
- en: 'The following is an example implementation that demonstrates a coarse training
    for the new classifier level (cycle 1), followed by fine-tuning of each convolutional
    group (cycles 2 through 4), and finally the stem convolutional group (cycle 5).
    The steps are as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例实现，演示了对新分类器级别（周期1）的粗粒度训练，然后是每个卷积组（周期2到4）的微调，最后是主干卷积组（周期5）。步骤如下：
- en: The layers in the model bottom are frozen (`layer.trainable = False`).
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型底部的层被冻结（`layer.trainable = False`）。
- en: A classifier layer for 20 classes is added as the model top.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模型顶部添加一个20个类别的分类器层。
- en: 'The classifier layer is trained with 50 epochs:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类器层使用50个周期进行训练：
- en: '[PRE14]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Freezes the weights of all the pretrained layers
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 冻结所有预训练层的权重
- en: ❷ Adds a new untrained classifier
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 添加一个未训练的分类器
- en: ❸ Compiles the model for training
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 编译模型以进行训练
- en: ❹ Coarse level trains the new classifier
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 粗粒度训练新的分类器
- en: 'After the classifier is trained, the model is fine-tuned (cycles 2 through
    4):'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类器训练后，模型进行微调（周期2到4）：
- en: Traverse the layers from bottom to top, identifying the stem convolution and
    the end of each ResNet group, which is detected by an `Add()` layer.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从底部到顶部遍历层，识别主干卷积和每个ResNet组的结束，这通过一个`Add()`层检测到。
- en: For each convolutional group, build a list of each convolutional layer in the
    group.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个卷积组，构建该组中每个卷积层的列表。
- en: 'Build a list of the groups in reverse order (`groups.insert(0, conv2d)`) :
    top to bottom.'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '以相反的顺序构建组列表（`groups.insert(0, conv2d)`）: 从顶部到底部。'
- en: Traverse the convolutional groups from top to bottom and progressively train
    the groups, and predecessors, for five epochs.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从顶部到底部遍历卷积组，并逐步训练每个组和其前驱，共五个周期。
- en: The following is an example implementation of these four steps.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对这四个步骤的示例实现。
- en: '[PRE15]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ In ResNet50, the first Conv2D is the stem convolutional layer.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在ResNet50中，第一个Conv2D是主干卷积层。
- en: ❷ Keeps list of convolutional layers per convolutional group
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 为每个卷积组保持卷积层的列表
- en: ❸ Each convolutional group in residual networks ends with an Add() layer.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 残差网络中的每个卷积组都以一个Add()层结束。
- en: ❹ Maintains list in reverse order (topmost conv group is top of list)
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 以相反的顺序维护列表（最上面的卷积组是列表的顶部）
- en: ❺ Unfreezes a convolutional group at a time (from top to bottom)
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 一次解冻一个卷积组（从上到下）
- en: ❻ Fine-tunes (trains) that layer
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 微调（训练）该层
- en: 'Finally, the stem convolutional, and hence the whole model, is trained for
    an additional five epochs (cycle 5). Here is an example implementation of this
    last step:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，主干卷积以及整个模型额外训练了五个周期（周期5）。以下是最后一步的示例实现：
- en: '[PRE16]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Unfreezes the stem convolutional
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 解冻主干卷积
- en: ❷ Does a final fine-tuning
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 进行最终微调
- en: In this example, when unfreezing layers for fine-tuning, the model must be recompiled
    prior to issuing the next training session.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，当解冻层进行微调时，必须在发出下一个训练会话之前重新编译模型。
- en: 11.3.3 Domain-specific weights
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.3 特定领域权重
- en: In the previous examples for transfer learning, we initialized the frozen layers
    of the model with weights learned from the ImageNet 2012 dataset. But let’s say
    you want to use pretrained weights from a specific domain other than ImageNet
    2012, as in our example of fruits.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的迁移学习示例中，我们使用从ImageNet 2012数据集学习到的权重初始化了模型的冻结层。但让我们假设你想要使用除ImageNet 2012之外特定领域的预训练权重，就像我们关于水果的例子一样。
- en: For instance, if you’re building a domain transfer model for plants, you may
    want images of trees, shrubs, flowers, weeds, leaves, branches, fruits, vegetables,
    and seeds. But we don’t need every possible plant type—just enough to learn essential
    features and feature extraction that can be generalized to more specific and comprehensive
    plant domains. You might also consider the background you want to generalize to.
    For example, the destination domain might be houseplants, and so you have home
    interior backgrounds, or it might be produce, so you want a shelf background.
    You should have a certain number of these backgrounds in the source domain, so
    the source model has learned to filter them out from the latent space.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你正在构建一个植物领域的域迁移模型，你可能需要树木、灌木、花朵、杂草、叶子、树枝、水果、蔬菜和种子的图像。但我们不需要每种可能的植物类型——只需要足够的来学习基本特征和特征提取，这些可以推广到更具体和更全面的植物领域。你也可能考虑你想要推广的背景。例如，目标领域可能是室内植物，因此你有家庭室内背景，或者它可能是产品，因此你想要一个货架背景。你应该在源域中有一定数量的这些背景，这样源模型就学会了从潜在空间中过滤掉它们。
- en: In the next code example, we first train a ResNet50 prebuilt architecture for
    a specific domain; in this case, fruit produce. We then use the pretrained, domain-specific
    weights and initialization to train another ResNet50 model in a similar domain,
    such as vegetables.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个代码示例中，我们首先为特定领域（在这种情况下，是水果产品）训练一个预构建的ResNet50架构；然后，我们使用预训练的、特定领域的权重和初始化来训练另一个在类似领域（例如，蔬菜）中的ResNet50模型。
- en: 'Figure 11.7 depicts transferring domain-specific weights and fine-tuning a
    retraining from fruits to a similar domain, vegetables, as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.7描述了将特定领域的权重从水果迁移到类似领域（蔬菜）并进行微调的过程如下：
- en: Instantiate an uninitialized ResNet50 model without the classifier and pooling
    layer, which we designate as the base model.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个未初始化的ResNet50模型，不带分类器和池化层，我们将其指定为基础模型。
- en: Save the base model architecture for later reuse in transfer learning (`produce-model`).
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存基础模型架构以供以后在迁移学习中重复使用（`produce-model`）。
- en: Add a classifier (`Flatten` and `Dense` layers) and train for a specific (source)
    domain (for example, produce).
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个分类器（`Flatten`和`Dense`层）并针对特定的（源）领域（例如，产品）进行训练。
- en: Save the weights for the trained model (`produce-weights`).
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存训练模型的权重（`produce-weights`）。
- en: Load the base model architecture (`model-produce`), which does not contain the
    classifier layer.
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载基础模型架构（`model-produce`），它不包含分类器层。
- en: Initialize the base model architecture with the pretrained weights for the source
    domain (`model-produce`).
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用源域的预训练权重初始化基础模型架构（`model-produce`）。
- en: Add a classifier for the new similar domain.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为新类似领域添加一个分类器。
- en: Train the model/classifier for the new similar domain.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练新类似领域的模型/分类器。
- en: '![](Images/CH11_F07_Ferlitsch.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH11_F07_Ferlitsch.png)'
- en: Listing 11.7 Transfer learning between a pretrained model of a domain similar
    to a source domain
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.7：与源域类似领域的预训练模型之间的迁移学习
- en: 'Here is an example implementation for transferring the domain-specific weights
    for fruit for transfer learning to the similar domain of vegetables:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个将特定领域权重从水果迁移到类似领域蔬菜的迁移学习的示例实现：
- en: '[PRE17]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Saves the base model
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 保存基础模型
- en: ❷ Adds the classifier
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 添加分类器
- en: ❸ Saves the trained model weights
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 保存训练好的模型权重
- en: ❹ Trains the model
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 训练模型
- en: ❺ Reuses the base model and trained weights
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 重新使用基础模型和训练好的权重
- en: ❻ Adds a classifier
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 添加分类器
- en: ❼ Compiles and trains the new model for new dataset
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 编译并训练新数据集的新模型
- en: 11.3.4 Domain transfer weight initialization
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.4 领域迁移权重初始化
- en: Another form of transfer learning is the transfer of domain-specific weights
    to use as weight initialization in a model we will otherwise fully retrain. In
    this case, we are trying to improve on using an initializer based on a random
    weight distribution algorithm (for example, He-normal for ReLU activation functions)
    versus using the lottery hypothesis or numerical stabilization. Let’s look again
    at our produce example and assume we have fully trained a model for a dataset
    instance, such as fruits. Instead of transferring weights from a fully trained
    instance of the model, we use an earlier checkpoint where we have established
    numerical stability. We will reuse this earlier checkpoint as the initializer
    for full retraining of a domain-similar dataset, such as vegetables.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种迁移学习的形式是将特定领域权重迁移到作为我们将重新训练的模型的权重初始化。在这种情况下，我们试图改进基于随机权重分布算法（例如，对于ReLU激活函数的He-normal）的初始化器，而不是使用彩票假设或数值稳定性。让我们再次看看我们的产品示例，并假设我们已经为数据集实例（如水果）完全训练了一个模型。我们不是从完全训练的模型实例中迁移权重，而是使用一个更早的检查点，其中我们已经建立了数值稳定性。我们将重用这个更早的检查点作为重新训练领域相似数据集（如蔬菜）的初始化器。
- en: 'Transferring domain-specific weights is a one-shot weight initialization approach.
    The presumption is to generate a set of weight initializations that is generalized
    enough that model training will lead to the best local (or global) optimum. Ideally,
    during initial training, the weights of the model will do the following:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 转移特定领域权重是一种一次性权重初始化方法。假设是生成一组足够泛化的权重初始化，以便模型训练将导致最佳局部（或全局）最优解。理想情况下，在初始训练期间，模型的权重将执行以下操作：
- en: Point in the general right direction for convergence
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指向收敛的一般正确方向
- en: Be overgeneralized to prevent diving into an arbitrary local optimum
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防止过度泛化以避免陷入任意局部最优解
- en: Be used as the initialization weights for a single (one-shot initialization)
    training session that will converge on the best local optimum
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为单次（一次性）训练会话的初始化权重，该会话将收敛到最佳局部最优解
- en: Figure 11.8 depicts domain transfer for weight initialization.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.8描述了权重初始化的领域迁移。
- en: '![](Images/CH11_F08_Ferlitsch.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH11_F08_Ferlitsch.png)'
- en: Listing 11.8 Using earlier checkpoints from a similar domain as the weight initialization
    for full retraining of new mode
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.8 使用类似领域的早期检查点作为新模型完全重新训练的权重初始化
- en: 'The pretraining steps for this form of weight initialization are as follows:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这种权重初始化的预训练步骤如下：
- en: Instantiate a ResNet50 model, with a random weight distribution (for example,
    Xavier or He-normal).
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个ResNet50模型，具有随机权重分布（例如，Xavier或He-normal）。
- en: Use a high level of regularization (l2(0.001) to prevent fitting to the data
    and small learning rate.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用高水平的正则化（l2(0.001)）以防止拟合数据和小学习率。
- en: Run a few epochs (not shown).
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行几个时代（未展示）。
- en: Save the weights with the model method `save_weights()`.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型方法 `save_weights()` 保存权重。
- en: '[PRE18]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Instantiates base model with default weight initialization (He-normal)
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用默认权重初始化（He-normal）实例化基础模型
- en: ❷ Saves the model
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 保存模型
- en: ❸ Adds a dropout layer and classifier to the base ResNet model and uses an aggressive
    level of regularization
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在基础ResNet模型中添加dropout层和分类器，并使用激进的正则化级别
- en: ❹ Saves the model and weights after pretraining
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 预训练后保存模型和权重
- en: In the next code example, we then start a full training session using the saved
    pretrained weights. First we load the uninitialized base model (`base_model`),
    which does not include the topmost layer. Then we load into the model the saved
    pretrained weights (`weights-init`). Next, we add a new topmost layer that is
    a dense layer with 20 nodes for 20 classes. We build the new model, compile, and
    then start the full training.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个代码示例中，我们使用保存的预训练权重开始一个完整的训练会话。首先我们加载未初始化的基础模型(`base_model`)，它不包括最顶层。然后我们将保存的预训练权重(`weights-init`)加载到模型中。接下来，我们添加一个新的最顶层，它是一个有20个节点的密集层，用于20个类别。我们构建新的模型，编译，然后开始完整的训练。
- en: '[PRE19]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Reloads the base model
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 重新加载基础模型
- en: ❷ Initializes the weights using domain transfer weight initialization
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用域迁移权重初始化来初始化权重
- en: ❸ Adds classifier without dropout
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 添加不带dropout的分类器
- en: ❹ Compiles and trains the new model
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 编译并训练新模型
- en: 11.3.5 Negative transfer
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.5 负迁移
- en: 'In some cases, we will find that transfer learning results in lower accuracy
    than training from scratch: when using a pretrained model to train a new model,
    the overall accuracy during training is less than what it would be if the model
    was not pretrained. This is referred to as *negative transfer*.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，我们会发现迁移学习的结果比从头开始训练的准确度低：当使用预训练模型来训练新模型时，训练过程中的整体准确度低于如果没有预训练模型时的准确度。这被称为*负迁移*。
- en: In this case, the source and destination domains are so distinct that the learned
    weights for the source domain cannot be reused on the destination domain. Additionally,
    when the weights are reused, the model will not converge, and quite possibly will
    diverge. In general, we can usually spot negative transfer within five to ten
    epochs.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，源域和目标域非常不同，以至于源域的学习权重不能在目标域上重用。此外，当权重被重用时，模型将不会收敛，甚至可能会发散。一般来说，我们通常可以在五到十个epoch内发现负迁移。
- en: 11.4 Beyond computer vision
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.4 超越计算机视觉
- en: The methods for transfer learning discussed in this chapter for computer vision
    are applicable to NLU models. Except for some terminology, the process is the
    same. Removing the top is sometimes referred to as *removing the head* on NLU
    models.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论的用于计算机视觉的迁移学习方法也适用于NLU模型。除了某些术语外，过程是相同的。在NLU模型中，移除顶层有时被称为*移除头部*。
- en: In both cases, you’re removing all or a portion of the task component and replacing
    it with a new task. What you are relying on is like the latent space in computer
    vision; the intermediate representation has the essential context (features) for
    learning a new task. Methods for similar tasks and distinct tasks are the same
    for computer vision and NLU.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，你都是在移除所有或部分的任务组件，并用新的任务替换它。你所依赖的是类似于计算机视觉中的潜在空间；中间表示具有学习新任务所必需的上下文（特征）。对于相似任务和不同任务的方
    法，在计算机视觉和NLU中是相同的。
- en: The same is *not* true for structured data, however. Actually, transfer learning
    is not possible with pretrained models across domains (datasets). You can learn
    a different type of task (for instance, regression versus classification) on the
    same dataset, but you can’t reuse the learned weights across different datasets
    that have different features. There is no concept—at least not yet—of a latent
    space that has essential features that are reusable across datasets with different
    fields (columns).
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于结构化数据来说，情况并非如此。实际上，跨域（数据集）的预训练模型之间不可能进行迁移学习。你可以在同一个数据集上学习不同类型的工作（例如，回归与分类），但你不能在不同特征的数据集之间重用学习到的权重。至少目前还没有一个概念——即具有可跨不同领域（列）的数据集重用基本特征的潜在空间。
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Prebuilt and pretrained models from TF.Keras and TF Hub model repositories can
    be used for either reuse as-is for prediction or for transfer learning a new classifier.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自TF.Keras和TF Hub模型存储库的预构建和预训练模型可以用于直接用于预测的重用，或者用于迁移学习新的分类器。
- en: The classifier group of a pretrained model can be replaced, either generalized
    or with a similar domain, and retrained for a new domain with less training time
    and smaller size dataset.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预训练模型的分类器组可以被替换，无论是通用的还是与类似域的，并且可以在更少的训练时间和更小的数据集上重新训练以适应新域。
- en: In transfer learning, if the new domain is similar to the previous trained domain,
    you freeze all the layers except the new task layer and do fine-tuned training.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在迁移学习中，如果新域与之前训练的域相似，则冻结所有层除了新的任务层，并进行微调训练。
- en: In transfer learning, if the new domain is dissimilar to the previous trained
    domain, you sequentially freeze and unfreeze layers as you retrain, starting from
    the bottom of the model and moving toward the top.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在迁移学习中，如果新领域与之前训练的领域不同，你需要在重新训练时按顺序冻结和解冻层，从模型底部开始，逐步向上移动。
- en: In domain transfer weights, you use the weights of the trained model as the
    initial weights and fully train a new model.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在领域迁移权重中，你使用训练模型的权重作为初始权重，并完全训练一个新的模型。
