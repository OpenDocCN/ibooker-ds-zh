- en: Appendix B. Important statistical concepts
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录B. 重要统计概念
- en: Statistics is such a broad topic that we’ve only been able to pull pieces of
    it into our data science narrative. But it’s an important field that has a lot
    to say about what happens when you attempt to infer from data. We’ve assumed in
    this book that you already know some statistical ideas (in particular, summary
    statistics such as the mean, mode, median, variance, and standard deviation).
    In this appendix, we’ll demonstrate a few more important statistical concepts
    that relate to model fitting, characterizing uncertainty, and experimental design.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学是一个如此广泛的话题，我们只能将其一部分纳入我们的数据科学叙事中。但它是一个重要的领域，它有很多关于当你尝试从数据中推断时会发生什么的内容。在这本书中，我们假设你已经了解一些统计概念（特别是均值、众数、中位数、方差和标准差等汇总统计量）。在本附录中，我们将演示一些与模型拟合、不确定性描述和实验设计相关的重要统计概念。
- en: Statistics is math, so this appendix is a bit mathematical. It’s also intended
    to teach you the proper *statistical nomenclature*, so you can share your work
    with other data scientists. This appendix covers technical terms you will hear
    as part of “data science shop talk.” You’ve been doing the data science work;
    now, we’ll discuss tools to talk about and criticize the work.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学是数学，所以这个附录有点数学性。它还旨在教你正确的**统计术语**，这样你就可以与其他数据科学家分享你的工作。本附录涵盖了你在“数据科学行话”中会听到的技术术语。你已经做了数据科学工作；现在，我们将讨论讨论和批评工作的工具。
- en: A *statistic* is any sort of summary or measure of data. An example would be
    the number of people in a room. *Statistics* is the study of how observed summaries
    of samples relate to the (unobserved) true summaries of the entire population
    we hope to model. Statistics help us to describe and mitigate the variance (or
    variation) of estimates, uncertainty (ranges or estimated ranges of what we do
    not know), and bias (systematic errors our procedures unfortunately introduce).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**统计量**是数据的一种总结或度量。一个例子是房间里的人数。"统计学"是研究观察到的样本汇总如何与（未观察到的）我们希望建模的整个群体的真实汇总相关联的学科。统计学帮助我们描述和减轻估计的方差（或变异）、不确定性（我们不知道的范围或估计的范围）和偏差（我们的程序不幸引入的系统误差）。'
- en: For example, if we are using a database of *all* past marketing of our company,
    this is still at best a sample of all possible sales (including future marketing
    and sales we are hoping to predict with our models). If we do not account for
    the uncertainty in sampling (and also from many other causes), we will draw incorrect
    inferences and conclusions.^([[1](#app02fn1)])
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们使用的是我们公司所有过去营销的数据库，这最多仍然是对所有可能销售（包括我们希望用我们的模型预测的未来营销和销售）的样本。如果我们不考虑抽样中的不确定性（以及来自许多其他原因的不确定性），我们将得出错误的推断和结论。[^([[1](#app02fn1))]
- en: ¹
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹
- en: ''
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We like to call machine learning the optimistic view of data and statistics
    the pessimistic view. In our opinion, you need to understand both of these viewpoints
    to work with data.
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们喜欢将机器学习称为对数据的乐观看法，将统计学称为悲观看法。在我们看来，你需要理解这两个观点才能与数据工作。
- en: B.1\. Distributions
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.1\. 分布
- en: 'A distribution is a description of likelihoods of possible values in a set
    of data. For example, it could be the set of plausible heights of an adult, American,
    18-year-old male. For a simple numeric value, the distribution is defined thus:
    for a value `b`, the distribution is the probability of seeing a value `x`, with
    `x <= b`. This is called the *cumulative distribution function* (CDF).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 分布是对数据集中可能值的可能性的描述。例如，它可能是美国18岁成年男性可能的身高集合。对于一个简单的数值，分布的定义如下：对于值`b`，分布是看到值`x`的概率，其中`x
    <= b`。这被称为**累积分布函数**（CDF）。
- en: We can often summarize a set of possible outcomes by naming a distribution,
    and some summary statistics. For example, we can say that if we flip a fair coin
    10 times, the number of heads we observe should be binomially distributed (defined
    in section B.5.7) with an expected mean of 5 heads. In all cases, we are concerned
    with how values are generated, and getting a bit more detail beyond just a characterization
    of mean and standard deviation, such as getting the name and shape of the distribution.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常可以通过命名一个分布和一些汇总统计量来总结一组可能的结果。例如，我们可以这样说，如果我们公平地掷一枚硬币10次，我们观察到的正面数量应该是二项分布（在B.5.7节中定义）的，期望平均值为5个正面。在所有情况下，我们都关心值的生成方式，以及获取比仅仅描述均值和标准差更详细的信息，比如获取分布的名称和形状。
- en: 'In this section, we’ll outline a few important distributions: the normal distribution,
    the lognormal distribution, and the binomial distribution. As you work further,
    you’ll also want to learn many other key distributions (such as Poisson, beta,
    negative binomial, and many more), but the ideas we’ll present here should be
    enough to get you started.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将概述几个重要的分布：正态分布、对数正态分布和二项分布。随着你进一步学习，你还将想要学习许多其他关键分布（如泊松、贝塔、负二项分布等），但这里提出的想法应该足以让你开始。
- en: B.1.1\. Normal distribution
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1.1\. 正态分布
- en: The *normal* or *Gaussian distribution* is the classic symmetric bell-shaped
    curve, as shown in [figure B.1](#app02fig01). Many measured quantities, such as
    test scores from a group of students, or the age or height of a particular population,
    can often be approximated by the normal. Repeated measurements will tend to fall
    into a normal distribution. For example, if a doctor weighs a patient multiple
    times, using a properly calibrated scale, the measurements (if enough of them
    are taken) will fall into a normal distribution around the patient’s true weight.
    The variation will be due to measurement error (the variability of the scale).
    The normal distribution is defined over all real numbers.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正态分布或高斯分布是经典的对称钟形曲线，如图 B.1 所示。[#app02fig01](#app02fig01)。许多测量量，如一组学生的考试成绩，或特定人群的年龄或身高，通常可以用正态分布来近似。重复测量往往会落入正态分布。例如，如果一位医生使用经过正确校准的秤多次称量一位患者的体重，那么测量值（如果取足够多）将围绕患者的真实体重落入正态分布。这种变化将归因于测量误差（秤的变异性）。正态分布定义在所有实数上。
- en: Figure B.1\. The normal distribution with mean 0 and standard deviation 1
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.1\. 均值为 0，标准差为 1 的正态分布
- en: '![](Images/app02fig01_alt.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/app02fig01_alt.jpg)'
- en: In addition, the *central limit theorem* says that when you’re observing the
    sum (or mean) of many independent, bounded variance random variables, the distribution
    of your observations will approach the normal as you collect more data. For example,
    suppose you want to measure how many people visit your website every day between
    9 a.m. and 10 a.m. The proper distribution for modeling the number of visitors
    is the *Poisson distribution*; but if you have a high enough volume of traffic,
    and you observe long enough, the distribution of observed visitors will approach
    the normal distribution, and you can make acceptable estimates about your traffic
    by treating the number of visitors as if it were normally distributed.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，**中心极限定理**指出，当你观察许多独立、有界方差的随机变量的总和（或均值）时，随着你收集更多的数据，你的观察值的分布将趋近于正态分布。例如，假设你想要测量每天上午
    9 点到 10 点之间有多少人访问你的网站。用于建模访问人数的适当分布是**泊松分布**；但如果你有足够的流量，并且观察足够长的时间，观察到的访问者分布将趋近于正态分布，你可以通过将访问者数量视为正态分布来对流量做出可接受的估计。
- en: 'Many real-world distributions are approximately “normal”—in particular, any
    measurement where the notion of “close” tends to be additive. An example would
    be adult heights: a 6-inch difference in height is large both for people who are
    5''6" and for those who are 6".'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 许多现实世界的分布大约是“正态”的——特别是，任何“接近”的概念倾向于累加的测量。一个例子就是成年人的身高：6 英寸的身高差异对于身高 5'6" 的人和身高
    6' 的人都是很大的。
- en: 'The normal is described by two parameters: the mean `m` and the standard deviation
    `s` (or, alternatively, the variance, which is the square of `s`). The mean represents
    the distribution’s center (and also its peak); the standard deviation represents
    the distribution’s “natural unit of length”—you can estimate how rare an observation
    is by how many standard deviations it is from the mean. As we mention in [chapter
    4](../Text/04.xhtml#ch04), for a normally distributed variable'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正态分布由两个参数描述：均值 `m` 和标准差 `s`（或者，也可以说是方差，它是 `s` 的平方）。均值代表分布的中心（也是其峰值）；标准差代表分布的“自然长度单位”——你可以通过观察值与均值的多少个标准差来估计观察值的稀有程度。正如我们在[第
    4 章](../Text/04.xhtml#ch04)中提到的，对于一个正态分布的变量
- en: About 68% of observations will fall in the interval `(m-s,m+s)`.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大约 68% 的观察值将落在区间 `(m-s,m+s)` 内。
- en: About 95% of observations will fall in the interval `(m-2*s,m+2*s)`.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大约 95% 的观察值将落在区间 `(m-2*s,m+2*s)` 内。
- en: About 99.7% of observations will fall in the interval `(m-3*s,m+3*s)`.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大约 99.7% 的观察值将落在区间 `(m-3*s,m+3*s)` 内。
- en: So an observation more than three standard deviations away from the mean can
    be considered quite rare, in most applications.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个观察值如果比均值大三个标准差，在大多数应用中可以被认为是相当罕见的。
- en: Many machine learning algorithms and statistical methods (for example, linear
    regression) assume that the unmodeled errors are distributed normally. Linear
    regression is fairly robust to violations of this assumption; still, for continuous
    variables, you should at least check if the variable distribution is unimodal
    and somewhat symmetric. When this isn’t the case, you may wish to consider using
    a variable transformation, such as the log transformations that we discuss in
    [chapter 4](../Text/04.xhtml#ch04).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法和统计方法（例如，线性回归）假设未建模的误差是正态分布的。线性回归对违反这一假设的情况相当稳健；然而，对于连续变量，你至少应该检查变量的分布是否单峰且在一定程度上对称。当这种情况不成立时，你可能希望考虑使用变量转换，例如我们在
    [第 4 章](../Text/04.xhtml#ch04) 中讨论的对数转换。
- en: Using the normal distribution in R
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 中使用正态分布
- en: 'In R the function `dnorm(x, mean = m, sd = s)` is the *normal probability density
    function*: it will return the probability of observing `x` when it’s drawn from
    a normal distribution with mean `m` and standard deviation `s`. By default, `dnorm`
    assumes that `mean=0` and `sd = 1` (as do all the functions related to the normal
    distribution that we discuss here). Let’s use `dnorm()` to draw [figure B.1](#app02fig01).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 中，函数 `dnorm(x, mean = m, sd = s)` 是 *正态概率密度函数*：当它从均值为 `m` 和标准差 `s` 的正态分布中抽取时，将返回观察到
    `x` 的概率。默认情况下，`dnorm` 假设 `mean=0` 和 `sd = 1`（这里讨论的所有与正态分布相关的函数都如此）。让我们使用 `dnorm()`
    来绘制 [图 B.1](#app02fig01)。
- en: Listing B.1\. Plotting the theoretical normal density
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.1\. 绘制理论正态密度
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The function `rnorm(n, mean = m, sd = s)` will generate `n` points drawn from
    a normal distribution with mean `m` and standard deviation `s`.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `rnorm(n, mean = m, sd = s)` 将生成 `n` 个从均值为 `m` 和标准差 `s` 的正态分布中抽取的点。
- en: Listing B.2\. Plotting an empirical normal density
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.2\. 绘制经验正态密度
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As you can see in [figure B.2](#app02fig02), the empirical distribution of the
    points produced by `rnorm(1000)` is quite close to the theoretical normal. Distributions
    observed from finite datasets can never exactly match theoretical continuous distributions
    like the normal; and, as with all things statistical, there is a well-defined
    distribution for how far off you expect to be for a given sample size.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在 [图 B.2](#app02fig02) 中所见，由 `rnorm(1000)` 生成的点的经验分布与理论正态分布非常接近。从有限数据集中观察到的分布永远不能与理论上的连续分布（如正态分布）完全匹配；并且，与所有统计事物一样，对于给定样本大小，你期望偏离有多远有一个明确的分布。
- en: Figure B.2\. The empirical distribution of points drawn from a normal with mean
    0 and standard deviation 1\. The dotted line represents the theoretical normal
    distribution.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.2\. 从均值为 0 和标准差为 1 的正态分布中抽取的点的经验分布。虚线表示理论正态分布。
- en: '![](Images/app02fig02_alt.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/app02fig02_alt.jpg)'
- en: 'The function `pnorm(x, mean = m, sd = s)` is what R calls the *normal probability
    function*, otherwise called the *normal cumulative distribution function*: it
    returns the probability of observing a data point of value less than `x` from
    a normal with mean `m` and standard deviation `s`. In other words, it’s the area
    under the distribution curve that falls to the left of `x` (recall that a distribution
    has unit area under the curve). This is shown in the [listing B.3](#app02ex03).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `pnorm(x, mean = m, sd = s)` 是 R 所称的 *正态概率函数*，也称为 *正态累积分布函数*：它返回从均值为 `m`
    和标准差 `s` 的正态分布中观察到小于 `x` 的数据点的概率。换句话说，这是分布曲线下落在 `x` 左侧的区域（回想一下，分布曲线下的面积是单位面积）。这如图
    [B.3 列表](#app02ex03) 所示。
- en: Listing B.3\. Working with the normal CDF
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.3\. 处理正态 CDF
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The function `qnorm(p, mean = m, sd = s)` is the *quantile function* for the
    normal distribution with mean `m` and standard deviation `s`. It’s the inverse
    of `pnorm()`, in that `qnorm(p, mean = m, sd = s)` returns the value `x` such
    that `pnorm(x, mean = m, sd = s) == p`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `qnorm(p, mean = m, sd = s)` 是具有均值 `m` 和标准差 `s` 的正态分布的 *分位数函数*。它是 `pnorm()`
    的逆函数，其中 `qnorm(p, mean = m, sd = s)` 返回值 `x`，使得 `pnorm(x, mean = m, sd = s) ==
    p`。
- en: '[Figure B.3](#app02fig03) illustrates the use of `qnorm()`: the vertical line
    intercepts the x axis at `x = qnorm(0.75)`; the shaded area to the left of the
    vertical line represents the area 0.75, or 75% of the area under the normal curve.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 B.3](#app02fig03) 展示了 `qnorm()` 的使用：垂直线在 `x = qnorm(0.75)` 处截断 x 轴；垂直线左侧的阴影区域表示面积为
    0.75，即正态曲线下方的 75% 的面积。'
- en: Figure B.3\. Illustrating `x < qnorm(0.75)`
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.3\. 说明 `x < qnorm(0.75)`
- en: '![](Images/app02fig03_alt.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/app02fig03_alt.jpg)'
- en: The code to create [figure B.3](#app02fig03) (along with a few other examples
    of using `qnorm()`) is shown in the following listing.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 创建[图B.3](#app02fig03)（以及使用`qnorm()`的几个其他示例）的代码如下所示。
- en: Listing B.4\. Plotting `x < qnorm(0.75)`
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 列表B.4\. 绘制`x < qnorm(0.75)`
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: B.1.2\. Summarizing R’s distribution naming conventions
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1.2\. 总结R的分布命名约定
- en: 'Now that we’ve shown some concrete examples, we can summarize how R names the
    different functions associated with a given probability distribution. Suppose
    the probability distribution is called `DIST`. Then the following are true:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经展示了一些具体的例子，我们可以总结一下R是如何命名与给定概率分布相关的不同函数的。假设概率分布被命名为`DIST`。那么以下都是正确的：
- en: '`dDIST(x, ...)` is the *distribution function* (or *PDF*, see the next callout)
    that returns the probability of observing the value `x`.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dDIST(x, ...)`是*分布函数*（或*PDF*，见下一部分）返回观察值`x`的概率。'
- en: '`pDIST(x, ...)` is the cumulative distribution function that returns the probability
    of observing a value less than `x`. The flag `lower.tail = FALSE` will cause `pDIST(x,
    ...)` to return the probability of observing a value greater than `x` (the area
    under the right tail, rather than the left).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pDIST(x, ...)`是累积分布函数，返回观察值小于`x`的概率。标志`lower.tail = FALSE`将导致`pDIST(x, ...)`返回观察值大于`x`的概率（右尾下的面积，而不是左尾）。'
- en: '`rDIST(n, ...)` is the random number generator that returns `n` values drawn
    from the distribution `DIST`.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rDIST(n, ...)`是随机数生成器，返回从分布`DIST`中抽取的`n`个值。'
- en: '`qDIST(p, ...)` is the quantile function that returns the `x` corresponding
    to the `p`th percentile of `DIST`. The flag `lower.tail = FALSE` will cause `qDIST(p,
    ...)` to return the `x` that corresponds to the `1 - p`th percentile of `DIST`.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qDIST(p, ...)`是分位数函数，返回对应于`DIST`的第`p`百分位的`x`。标志`lower.tail = FALSE`将导致`qDIST(p,
    ...)`返回对应于`1 - p`百分位的`x`。'
- en: '* * *'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: R’s confusing naming convention
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: R的令人困惑的命名约定
- en: For some reason, R refers to the cumulative distribution function (or CDF) as
    the short term *distribution function*. Be careful to check if you want to use
    the probability density function or the CDF when working with R.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于某种原因，R将累积分布函数（或CDF）简称为*分布函数*。当使用R工作时，请注意检查您是想使用概率密度函数还是CDF。
- en: '* * *'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: B.1.3\. Lognormal distribution
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1.3\. 对数正态分布
- en: The *lognormal distribution* is the distribution of a random variable `X` whose
    natural log `log(X)` is normally distributed. The distribution of highly skewed
    positive data, like the value of profitable customers, incomes, sales, or stock
    prices, can often be modeled as a lognormal distribution. A lognormal distribution
    is defined over all non-negative real numbers; as shown in [figure B.4](#app02fig04)
    (top), it’s asymmetric, with a long tail out toward positive infinity. The distribution
    of `log(X)` ([figure B.4](#app02fig04), bottom) is a normal distribution centered
    at `mean(log(X))`. For lognormal populations, the mean is generally much higher
    than the median, and the bulk of the contribution toward the mean value is due
    to a small population of highest-valued data points.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*对数正态分布*是随机变量`X`的自然对数`log(X)`服从正态分布的分布。高度偏斜的正态数据，如盈利客户的值、收入、销售额或股价，通常可以建模为对数正态分布。对数正态分布定义在所有非负实数上；如图B.4（顶部）所示，它是不对称的，尾部向正无穷延伸。`log(X)`的分布（如图B.4（底部）所示）是一个以`mean(log(X))`为中心的正态分布。对于对数正态总体，均值通常远高于中位数，向均值贡献的大部分来自少量最高值的数据点。'
- en: 'Figure B.4\. Top: The lognormal distribution `X` such that `mean(log(X)) =
    0` and `sd(log(X)) = 1`. The dashed line is the theoretical distribution, and
    the solid line is the distribution of a random lognormal sample. Bottom: The solid
    line is the distribution of `log(X)`.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.4。顶部：对数正态分布`X`，其`mean(log(X)) = 0`和`sd(log(X)) = 1`。虚线是理论分布，实线是随机对数正态样本的分布。底部：实线是`log(X)`的分布。
- en: '![](Images/app02fig04_alt.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/app02fig04_alt.jpg)'
- en: '* * *'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Don’t use the mean as a “typical” value for a lognormal population
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 不要将对数正态总体的均值用作“典型”值
- en: For a population that’s approximately normally distributed, you can use the
    mean value of the population as a rough stand-in value for a typical member of
    the population. If you use the mean as a stand-in value for a lognormal population,
    you’ll overstate the value of the majority of your data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个近似正态分布的总体，你可以使用总体的平均值作为典型成员的大致替代值。如果你将平均值用作对数正态总体的替代值，你会高估大多数数据点的值。
- en: '* * *'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Intuitively, if variations in the data are expressed naturally as percentages
    or relative differences, rather than as absolute differences, then the data is
    a candidate to be modeled lognormally. For example, a typical sack of potatoes
    in your grocery store might weigh about five pounds, plus or minus half a pound.
    The distance that a specific type of bullet will fly when fired from a specific
    type of handgun might be about 2,100 meters, plus or minus 100 meters. The variations
    in these observations are naturally represented in absolute units, and the distributions
    can be modeled as normals. On the other hand, differences in monetary quantities
    are often best expressed as percentages: a population of workers might all get
    a 5% increase in salary (not an increase of $5,000/year across the board); you
    might want to project next quarter’s revenue to within 10% (not to within plus
    or minus $1,000). Hence, these quantities are often best modeled as having lognormal
    distributions.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，如果数据的变化自然地表示为百分比或相对差异，而不是绝对差异，那么数据就适合用对数正态分布来建模。例如，你杂货店中典型的土豆袋可能重约五磅，上下浮动半磅。从特定类型的枪支发射特定类型的子弹时，子弹飞行的距离可能约为
    2,100 米，上下浮动 100 米。这些观察结果的变化自然地用绝对单位表示，并且可以建模为正态分布。另一方面，货币数量的差异通常最好用百分比表示：一个工人群体的所有工人可能都会获得
    5% 的加薪（而不是每人每年增加 5,000 美元）；你可能希望将下季度的收入预测在 10% 以内（而不是在加减 1,000 美元以内）。因此，这些数量通常最好建模为具有对数正态分布。
- en: Using the lognormal distribution in R
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 中使用对数正态分布
- en: 'Let’s look at the functions for working with the lognormal distribution in
    R (see also section B.5.3). We’ll start with `dlnorm()` and `rlnorm()`:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 R 中处理对数正态分布的函数（也参见 B.5.3 节）。我们将从 `dlnorm()` 和 `rlnorm()` 开始：
- en: '`dlnorm(x, meanlog = m, sdlog = s)` is the *probability density function* (PDF)
    that returns the probability of observing the value `x` when it’s drawn from a
    lognormal distribution `X` such that `mean(log(X)) = m` and `sd(log(X)) = s`.
    By default, `meanlog = 0` and `sdlog = 1` for all the functions discussed in this
    section.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dlnorm(x, meanlog = m, sdlog = s)` 是返回从对数正态分布 `X` 中抽取的值 `x` 的概率密度的 *概率密度函数*
    (PDF)，其中 `mean(log(X)) = m` 和 `sd(log(X)) = s`。默认情况下，本节中讨论的所有函数的 `meanlog = 0`
    和 `sdlog = 1`。'
- en: '`rlnorm(n, meanlog = m, sdlog = s)` is the random number that returns `n` values
    drawn from a lognormal distribution with `mean(log(X)) = m` and `sd(log(X)) =
    s`.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rlnorm(n, meanlog = m, sdlog = s)` 是返回从具有 `mean(log(X)) = m` 和 `sd(log(X))
    = s` 的对数正态分布中抽取的 `n` 个随机数的随机数。'
- en: We can use `dlnorm()` and `rlnorm()` to produce [figure 8.4](../Text/08.xhtml#ch08fig04),
    shown earlier. The following listing demonstrates some properties of the lognormal
    distribution.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `dlnorm()` 和 `rlnorm()` 来生成前面显示的 [图 8.4](../Text/08.xhtml#ch08fig04)，以下列表演示了对数正态分布的一些特性。
- en: Listing B.5\. Demonstrating some properties of the lognormal distribution
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.5\. 展示对数正态分布的一些特性
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The remaining two functions are the CDF `plnorm()` and the quantile function
    `qlnorm()`:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的两个函数是累积分布函数 `plnorm()` 和分位数函数 `qlnorm()`：
- en: '`plnorm(x, meanlog = m, sdlog = s)` is the cumulative distribution function
    that returns the probability of observing a value less than `x` from a lognormal
    distribution with `mean(log(X)) = m` and `sd(log(X)) = s`.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plnorm(x, meanlog = m, sdlog = s)` 是累积分布函数，它返回从具有 `mean(log(X)) = m` 和 `sd(log(X))
    = s` 的对数正态分布中观察到的值小于 `x` 的概率。'
- en: '`qlnorm(p, meanlog = m, sdlog = s)` is the quantile function that returns the
    `x` corresponding to the `p`th percentile of a lognormal distribution with `mean(log(X))
    = m` and `sd(log(X)) = s`. It’s the inverse of `plnorm()`.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qlnorm(p, meanlog = m, sdlog = s)` 是分位数函数，它返回对应于对数正态分布中 `p` 百分位数的 `x` 值，其中
    `mean(log(X)) = m` 和 `sd(log(X)) = s`。它是 `plnorm()` 的逆函数。'
- en: The following listing demonstrates `plnorm()` and `qlnorm()`. It uses the data
    frame `lnormframe` from the previous listing.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表演示了 `plnorm()` 和 `qlnorm()`。它使用前一个列表中的数据框 `lnormframe`。
- en: Listing B.6\. Plotting the lognormal distribution
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.6\. 绘制对数正态分布图
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you can see in [figure B.5](#app02fig05), the majority of the data is concentrated
    on the left side of the distribution, with the remaining quarter of the data spread
    out over a very long tail.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在[图 B.5](#app02fig05) 中所见，大多数数据集中在分布的左侧，剩余的四分之一数据分布在非常长的尾部。
- en: Figure B.5\. The 75th percentile of the lognormal distribution with `meanlog
    = 1`, `sdlog = 0`
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.5. 均值为 `meanlog = 1`，标准差为 `sdlog = 0` 的对数正态分布的 75 分位数
- en: '![](Images/app02fig05_alt.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图 B.5 替代文本](Images/app02fig05_alt.jpg)'
- en: B.1.4\. Binomial distribution
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1.4. 二项分布
- en: Suppose you have a coin that has a probability `p` of landing on heads when
    you flip it (so for a fair coin, `p = 0.5`). In this case, the binomial distribution
    models the probability of observing `k` heads when you flip that coin `N` times.
    It’s used to model binary classification problems (as we discuss in relation to
    logistic regression in [chapter 8](../Text/08.xhtml#ch08)), where the positive
    examples can be considered “heads.”
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一枚硬币，当你翻转它时，它落在头部的概率为 `p`（因此对于公平的硬币，`p = 0.5`）。在这种情况下，二项分布用于模拟翻转该硬币 `N`
    次时观察到 `k` 个头部的概率。它用于建模二元分类问题（如我们在第 8 章中讨论的与逻辑回归相关的内容），其中正例可以被认为是“头部”。
- en: '[Figure B.6](#app02fig06) shows the shape of the binomial distribution for
    coins of different fairnesses, when flipped 50 times. Note that the binomial distribution
    is *discrete*; it’s only defined for (non-negative) integer values of `k`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 B.6](#app02fig06) 展示了不同公平性的硬币在翻转 50 次时的二项分布形状。请注意，二项分布是*离散的*；它只定义了 `k` 的（非负）整数值。'
- en: Figure B.6\. The binomial distributions for 50 coin tosses, with coins of various
    fairnesses (probability of landing on heads)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.6. 50 次抛掷硬币的二项分布，硬币的公平性各异（落在头部的概率）
- en: '![](Images/app02fig06_alt.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图 B.6 替代文本](Images/app02fig06_alt.jpg)'
- en: Using the binomial distribution in R
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 中使用二项分布
- en: 'Let’s look at the functions for working with the binomial distribution in R
    (see also section B.5.3). We’ll start with the probability density function `dbinom()`
    and the random number generator `rbinom()`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在 R 中处理二项分布的函数（参见 B.5.3 节）。我们将从概率密度函数 `dbinom()` 和随机数生成器 `rbinom()` 开始：
- en: '`dbinom(k, nflips, p)` is the PDF that returns the probability of observing
    exactly `k` heads from `nflips` of a coin with heads probability `p`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dbinom(k, nflips, p)` 是 PDF，它返回从具有头部概率 `p` 的硬币中抛掷 `nflips` 次时观察到恰好 `k` 个头部的概率。'
- en: '`rbinom(N, nflips,p)` is the random number generator that returns `N` values
    drawn from the binomial distribution corresponding to `nflips` of a coin with
    heads probability `p`.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rbinom(N, nflips, p)` 是随机数生成器，它返回从具有头部概率 `p` 的硬币中抽取的 `N` 个值，对应于 `nflips` 次抛掷。'
- en: You can use `dbinom()` (as in the following listing) to produce [figure B.6](#app02fig06).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `dbinom()`（如下面的列表所示）来生成[图 B.6](#app02fig06)。
- en: Listing B.7\. Plotting the binomial distribution
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.7. 绘制二项分布
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You can use `rbinom()` to simulate a coin-flipping-style experiment. For example,
    suppose you have a large population of students that’s 50% female. If students
    are assigned to classrooms at random, and you visit 100 classrooms with 20 students
    each, then how many girls might you expect to see in each classroom? A plausible
    outcome is shown in [figure B.7](#app02fig07), with the theoretical distribution
    superimposed.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `rbinom()` 来模拟抛硬币风格的实验。例如，假设你有一个 50% 女性的大型学生群体。如果学生随机分配到教室，并且你访问了有 20
    名学生的 100 个教室，那么你预计每个教室中会有多少女孩？一个合理的结果显示在[图 B.7](#app02fig07) 中，理论分布叠加在上面。
- en: Figure B.7\. The observed distribution of the count of girls in 100 classrooms
    of size 20, when the population is 50% female. The theoretical distribution is
    shown with the dashed line.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.7. 当人口为 50% 女性时，在 100 个大小为 20 的教室中观察到的女孩数量分布。理论分布用虚线表示。
- en: '![](Images/app02fig07_alt.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图 B.7 替代文本](Images/app02fig07_alt.jpg)'
- en: Let’s write the code to produce [figure B.7](#app02fig07).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写代码来生成[图 B.7](#app02fig07)。
- en: Listing B.8\. Working with the theoretical binomial distribution
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.8. 处理理论二项分布
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Because we didn’t call set.seed, we expect different results each time we
    run this line.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 因为我们没有调用 `set.seed`，所以我们预计每次运行此行时都会得到不同的结果。
- en: ❷ stat_summary is one of the ways to control data aggregation during plotting.
    In this case, we’re using it to place the dot and bar, measured from the empirical
    data, in with the theoretical density curve.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ `stat_summary` 是在绘图过程中控制数据聚合的一种方法。在这种情况下，我们使用它将来自经验数据的点状和条形图放置在理论密度曲线中。
- en: As you can see, even classrooms with as few as 4 or as many as 16 girls aren’t
    completely unheard of when students from this population are randomly assigned
    to classrooms. But if you observe too many such classrooms—or if you observe classes
    with fewer than 4 or more than 16 girls—you’d want to investigate whether student
    selection for those classes is biased in some way.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，即使只有 4 个或多达 16 个女孩的教室也不是完全闻所未闻，当来自这个群体中的学生随机分配到教室时。但是，如果您观察到太多的此类教室——或者观察到少于
    4 个或超过 16 个女孩的教室——您会想调查这些班级的学生选择是否以某种方式存在偏见。
- en: You can also use `rbinom()` to simulate flipping a single coin.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用 `rbinom()` 来模拟抛掷单个硬币。
- en: Listing B.9\. Simulating a binomial distribution
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.9\. 模拟二项分布
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The final two functions are the CDF `pbinom()` and the quantile function `qbinom()`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个函数是累积分布函数 `pbinom()` 和分位数函数 `qbinom()`：
- en: '`pbinom(k, nflips, p)` is the CDF that returns the probability of observing
    `k` heads or fewer from `nflips` of a coin with heads probability `p`. `pbinom(k,
    nflips, p, lower.tail = FALSE)` returns the probability of observing more than
    `k` heads from `nflips` of a coin with heads probability `p`. Note that the left
    tail probability is calculated over the inclusive interval `numheads <= k`, while
    the right tail probability is calculated over the exclusive interval `numheads
    > k`.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pbinom(k, nflips, p)` 是返回从 `nflips` 次抛掷中观察到 `k` 个或更少正面的概率的累积分布函数（CDF）。`pbinom(k,
    nflips, p, lower.tail = FALSE)` 返回从 `nflips` 次抛掷中观察到超过 `k` 个正面的概率。请注意，左尾概率是在包含区间
    `numheads <= k` 上计算的，而右尾概率是在排他区间 `numheads > k` 上计算的。'
- en: '`qbinom(q, nflips, p)` is the quantile function that returns the number of
    heads `k` that corresponds to the `q`th percentile of the binomial distribution
    corresponding to `nflips` of a coin with heads probability `p`.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qbinom(q, nflips, p)` 是分位数函数，它返回与 `nflips` 次抛掷中正面概率 `p` 对应的 `q` 百分位数所对应正面的数量
    `k`。'
- en: The next listing shows some examples of using `pbinom()` and `qbinom()`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表展示了使用 `pbinom()` 和 `qbinom()` 的几个示例。
- en: Listing B.10\. Working with the binomial distribution
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.10\. 使用二项分布
- en: '[PRE9]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: One thing to keep in mind is that because the binomial distribution is discrete,
    `pbinom()` and `qbinom()` won’t be perfect inverses of each other, as is the case
    with continuous distributions like the normal.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，由于二项分布是离散的，`pbinom()` 和 `qbinom()` 不会像连续分布（如正态分布）那样是彼此的完美逆函数。
- en: Listing B.11\. Working with the binomial CDF
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.11\. 使用二项累积分布函数
- en: '[PRE10]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: B.1.5\. More R tools for distributions
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1.5\. 用于分布的更多 R 工具
- en: R has many more tools for working with distributions beyond the PDF, CDF, and
    generation tools we’ve demonstrated. In particular, for fitting distributions,
    you may want to try the `fitdistr` method from the `MASS` package.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: R 有许多用于处理分布的工具，而不仅仅是我们在演示中展示的 PDF、CDF 和生成工具。特别是，对于拟合分布，您可能想尝试来自 `MASS` 包的 `fitdistr`
    方法。
- en: B.2\. Statistical theory
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.2\. 统计理论
- en: In this book, we necessarily concentrate on (correctly) processing data, without
    stopping to explain a lot of theory. The steps we use will be more understandable
    after we review a bit of statistical theory in this section.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们必然要专注于（正确地）处理数据，而不会停下来解释很多理论。在回顾本节中的一些统计理论之后，我们将使用的步骤将更容易理解。
- en: B.2.1\. Statistical philosophy
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2.1\. 统计哲学
- en: The predictive tools and machine learning methods we demonstrate in this book
    get their predictive power not from uncovering cause and effect (which would be
    a great thing to do), but by tracking and trying to eliminate differences in data
    and by reducing different sources of error. In this section, we’ll outline a few
    of the key concepts that describe what’s going on and why these techniques work.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这本书中展示的预测工具和机器学习方法，其预测能力并非来自揭示因果关系（那将是一件好事），而是通过跟踪和尝试消除数据中的差异，以及通过减少不同来源的错误。在本节中，我们将概述一些关键概念，描述正在发生的事情以及为什么这些技术有效。
- en: Exchangeability
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 可交换性
- en: Since basic statistical modeling isn’t enough to reliably attribute predictions
    to true causes, we’ve been quietly relying on a concept called *exchangeability*
    to ensure we can build useful predictive models.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 由于基本的统计建模不足以可靠地将预测归因于真实原因，我们一直在默默地依赖一个称为 *可交换性* 的概念，以确保我们可以构建有用的预测模型。
- en: 'The formal definition of exchangeability is this: suppose all the data in the
    world is `x[i,],y[i]` (`i=1,...m`). Then we call the data *exchangeable* if for
    any permutation `j_1, ...j_m` of `1, ...m`, the joint probability of seeing `x[i,],y[i]`
    is equal to the joint probability of seeing `x[j_i, ], y[j_i]`. In other words,
    the joint probability of seeing a tuple `x[i, ], y[i]` does *not* depend on *when*
    we see it, or where it comes in the sequence of observations.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 交换性的正式定义是这样的：假设世界上所有的数据都是`x[i,],y[i]`（`i=1,...m`）。如果对于`1, ...m`的任何排列`j_1, ...j_m`，看到`x[i,],y[i]`的联合概率等于看到`x[j_i,
    ], y[j_i]`的联合概率，那么我们称这些数据为*可交换的*。换句话说，看到元组`x[i, ], y[i]`的联合概率不依赖于*何时*我们看到它，或者它在观察序列中的位置。
- en: The idea is that if all permutations of the data are equally likely, then when
    we draw subsets from the data using only indices (not snooping the `x[i,],y[i]`),
    the data in each subset, though different, can be considered as independent and
    identically distributed. We rely on this when we make train/test splits (or even
    train/calibrate/test splits), and we hope (and should take steps to ensure) this
    is true between our training data and future data we’ll encounter in production.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是，如果数据的所有排列都是等可能的，那么当我们仅使用索引（而不是窥探`x[i,],y[i]`）从数据中抽取子集时，每个子集中的数据，尽管不同，可以被认为是独立同分布的。我们在进行训练/测试划分（甚至训练/校准/测试划分）时依赖于此，我们希望（并且应该采取措施确保）我们的训练数据和未来在生产中遇到的数据之间也是如此。
- en: Our hope in building a model is that in the unknown future, data the model will
    be applied to is exchangeable with our training data. If this is the case, then
    we’d expect good performance on training data to translate into good model performance
    in production. It’s important to defend exchangeability from problems such as
    overfit and concept drift.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建模型的目标是在未知的未来，模型将应用到的数据可以与我们的训练数据交换。如果这种情况成立，那么我们预期在训练数据上的良好表现将转化为生产环境中模型的良好表现。防御数据交换性免受过度拟合和概念漂移等问题的影响是非常重要的。
- en: Once we start examining training data, we (unfortunately) break its exchangeability
    with future data. Subsets that contain a lot of training data are no longer indistinguishable
    from subsets that don’t have training data (through the simple process of memorizing
    all of our training data). We attempt to measure the degree of damage by measuring
    performance on held-out test data. This is why generalization error is so important.
    Any data not looked at during model construction should be as exchangeable with
    future data as it ever was, so measuring performance on held-out data helps anticipate
    future performance. This is also why you don’t use test data for calibration (instead,
    you should further split your training data to do this); once you look at your
    test data, it’s less exchangeable with what will be seen in production in the
    future.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们开始检查训练数据，我们就（不幸地）破坏了它与未来数据的交换性。包含大量训练数据的子集不再与不包含训练数据的子集（通过简单地记住所有训练数据）区分开来。我们试图通过在保留的测试数据上的性能来衡量这种损害的程度。这就是为什么泛化误差如此重要的原因。在模型构建过程中没有查看的数据应该与未来数据保持与之前相同的可交换性，因此测量保留数据的性能有助于预测未来的性能。这也是为什么你不使用测试数据进行校准（相反，你应该进一步划分你的训练数据来做这件事）；一旦你查看你的测试数据，它就与未来在生产中看到的可交换性降低。
- en: 'Another potential huge loss of exchangeability in prediction is summarized
    is what’s called *Goodhart’s law*: “When a measure becomes a target, it ceases
    to be a good measure.” The point is this: factors that merely correlate with a
    prediction are good predictors—until you go too far in optimizing for them or
    when others react to your use of them. For example, email spammers can try to
    defeat a spam detection system by using more of the features and phrases that
    correlate highly with legitimate email, and changing phrases that the spam filter
    believes correlate highly with spam. This is an essential difference between actual
    causes (which do have an effect on outcome when altered) and mere correlations
    (which may be co-occurring with an outcome and are good predictors only through
    exchangeability of examples).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 预测中交换性可能遭受的另一巨大损失总结为所谓的*Goodhart定律*：“当一项度量成为目标时，它就不再是一个好的度量。”其要点是：仅仅与预测相关的因素是好的预测者——直到你过度优化它们，或者当其他人对你使用它们的反应时。例如，垃圾邮件发送者可能会通过使用与合法电子邮件高度相关的更多特征和短语，以及改变垃圾邮件过滤器认为与垃圾邮件高度相关的短语来尝试击败垃圾邮件检测系统。这是实际原因（当改变时确实对结果有影响）和仅仅相关性（可能与结果同时发生，并且只有通过示例的交换性才是好的预测者）之间的基本区别。
- en: Bias variance decomposition
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差方差分解
- en: Many of the modeling tasks in this book are what are called *regressions* where,
    for data of the form `y[i],x[i,]`, we try to find a model or function `f()` such
    that `f(x[i,])~E[y[j]|x[j,]~x[i,]]` (the expectation `E[]` being taken over all
    examples, where `x[j,]` is considered very close to `x[i,]`). Often this is done
    by picking `f()` to minimize `E[(y[i]-f(x[i,]))^2]`.^([[2](#app02fn2)]) Notable
    methods that fit closely to this formulation include regression, k-nearest neighbors
    (KNN), and neural nets.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的许多建模任务被称为*回归*，其中对于形式为`y[i],x[i,]`的数据，我们试图找到一个模型或函数`f()`，使得`f(x[i,])~E[y[j]|x[j,]~x[i,]]`（期望`E[]`是对所有示例取的，其中`x[j,]`被认为非常接近`x[i,]`）。通常这是通过选择`f()`来最小化`E[(y[i]-f(x[i,]))^2]`来实现的。^([[2](#app02fn2)])
    符合这种公式的显著方法包括回归、k-最近邻（KNN）和神经网络。
- en: ²
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ²
- en: ''
  id: totrans-128
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The fact that minimizing the squared error gets expected values right is an
    important fact that is used in method design again and again.
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最小化平方误差能够正确得到期望值是一个重要的事实，它在方法设计中反复被使用。
- en: 'Obviously, minimizing square error is not always your direct modeling goal.
    But when you work in terms of square error, you have an explicit decomposition
    of error into meaningful components, called the *bias/variance decomposition*
    (see *The Elements of Statistical Learning* by T. Hastie, R. Tibshirani, and J.
    Friedman; Springer, 2009). The bias/variance decomposition says this:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，最小化平方误差并不总是你的直接建模目标。但当你以平方误差为基准工作时，你可以将误差明确分解为有意义的组成部分，这被称为*偏差/方差分解*（参见T.
    Hastie、R. Tibshirani和J. Friedman所著的《统计学习的要素》；Springer，2009年）。偏差/方差分解指出：
- en: '[PRE11]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Model bias* is the portion of the error that your chosen modeling technique
    will never get right, often because some aspect of the true process isn’t expressible
    within the assumptions of the chosen model. For example, if the relationship between
    the outcome and the input variables is curved or nonlinear, you can’t fully model
    it with linear regression, which only considers linear relationships. You can
    often reduce bias by moving to more complicated modeling ideas: kernelizing, GAMs,
    adding interactions, and so on. Many modeling methods can increase model complexity
    (to try to reduce bias) on their own, for example, decision trees, KNN, support
    vector machines, and neural nets. But until you have a lot of data, increasing
    model complexity has a good chance of increasing model variance.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型偏差*是错误中你选择的建模技术永远无法正确处理的部分，通常是因为真实过程的某些方面无法在所选模型的假设中表示。例如，如果结果变量与输入变量之间的关系是曲线或非线性，你无法用只考虑线性关系的线性回归完全建模它。你通常可以通过转向更复杂的建模思想来减少偏差：核化、GAMs、添加交互作用等。许多建模方法可以自行增加模型复杂性（以尝试减少偏差），例如决策树、KNN、支持向量机和神经网络。但直到你拥有大量数据，增加模型复杂性有很大机会会增加模型方差。'
- en: '*Model variance* is the portion of the error that your modeling technique gets
    wrong due to incidental relations in the data. The idea is this: a retraining
    of the model on new data might make different errors (this is how variance differs
    from bias). An example would be running KNN with `k = 1`. When you do this, each
    test example is scored by matching to a single nearest training example. If that
    example happened to be positive, your classification will be positive. This is
    one reason we tend to run KNN with larger `k` values: it gives us the chance to
    get more reliable estimates of the nature of neighborhood (by including more examples)
    at the expense of making neighborhoods a bit less local or specific. More data
    and averaging ideas (like bagging) greatly reduce model variance.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型方差*是由于数据中的偶然关系而导致的错误部分。其想法是这样的：在新的数据上重新训练模型可能会产生不同的错误（这就是方差与偏差的区别）。一个例子是使用`k
    = 1`运行KNN。当你这样做时，每个测试示例都会通过匹配到单个最近的训练示例来评分。如果那个示例碰巧是正的，你的分类将是正的。这就是我们倾向于使用较大的`k`值运行KNN的原因之一：它给我们提供了通过包括更多示例来获得更可靠的邻域性质估计的机会，尽管这会使邻域稍微不那么局部或具体。更多的数据和平均思想（如bagging）可以大大减少模型方差。'
- en: '*Irreducible error* is the truly unmodelable portion of the problem (given
    the current variables). If we have two datums `x[i, ], y[i]` and `x[j,], y[j]`
    such that `x[i, ] == x[j, ]`, then `(y[i] - y[j])^2` contributes to the irreducible
    error. We emphasize that irreducible error is measured with respect to a given
    set of variables; add more variables, and you have a new situation that may have
    its own lower irreducible error.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*不可减少误差* 是问题的真正不可建模的部分（考虑到当前变量）。如果我们有两个数据 `x[i, ], y[i]` 和 `x[j,], y[j]`，使得
    `x[i, ] == x[j, ]`，那么 `(y[i] - y[j])^2` 会贡献到不可减少误差。我们强调，不可减少误差是相对于一组给定的变量来衡量的；添加更多变量，你就有了一个新的情况，可能具有其自己的更低不可减少误差。'
- en: 'The point is that you can always think of modeling error as coming from three
    sources: bias, variance, and irreducible error. When you’re trying to increase
    model performance, you can choose what to try based on which of these you are
    trying to reduce.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 重点是，你总是可以将建模误差视为来自三个来源：偏差、方差和不可减少误差。当你试图提高模型性能时，你可以根据你试图减少的这些因素来选择尝试的方法。
- en: '* * *'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Averaging is a powerful tool**'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**平均化是一个强大的工具**'
- en: Under fairly mild assumptions, averaging reduces variance. For example, for
    data with identically distributed independent values, averages of groups of size
    `n` have an expected variance of `1/n` of the variance of individual values. This
    is one of the reasons why you can build models that accurately forecast population
    or group rates even when predicting individual events is difficult. So although
    it may be easy to forecast the number of murders per year in San Francisco, you
    can’t predict who will be killed. In addition to shrinking variances, averaging
    also reshapes distributions to look more and more like the normal distribution
    (this is the central limit theorem and related to the law of large numbers).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在相当温和的假设下，平均化可以降低方差。例如，对于具有相同分布的独立值的数据，大小为 `n` 的组平均值的期望方差为单个值方差的 `1/n`。这就是为什么即使预测单个事件很困难，你仍然可以构建准确预测人口或群体率的模型的原因之一。所以尽管预测旧金山的谋杀案数量可能很容易，但你无法预测谁会被杀害。除了缩小方差外，平均化还会使分布越来越像正态分布（这是中心极限定理，与大量定律相关）。
- en: '* * *'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Statistical efficiency
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 统计效率
- en: 'The *efficiency* of an unbiased statistical procedure is defined as how much
    variance there is in the procedure for a given dataset size: that is, how much
    the estimates produced by that procedure will vary, when run on datasets of the
    same size and drawn from the same distribution. More efficient procedures require
    less data to get below a given amount of variance. This differs from computational
    efficiency, which is about how much work is needed to produce an estimate.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 无偏统计过程的 *效率* 定义为在给定数据集大小的情况下该过程有多少方差：也就是说，当在相同大小和来自相同分布的数据集上运行时，该过程产生的估计值会有多大的变化。更有效的程序需要更少的数据来达到给定的方差量。这与计算效率不同，计算效率是关于产生估计值需要多少工作量。
- en: When you have a lot of data, statistical efficiency becomes less critical (which
    is why we don’t emphasize it in this book). But when it’s expensive to produce
    more data (such as in drug trials), statistical efficiency is your primary concern.
    In this book, we take the approach that we usually have a lot of data, so we can
    prefer general methods that are somewhat statistically inefficient (such as using
    a test holdout set, and so on) over more specialized, statistically efficient
    methods (such as specific ready-made parametric tests like the Wald test and others).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当你拥有大量数据时，统计效率变得不那么关键（这就是为什么我们在这本书中不强调它）。但是，当产生更多数据成本很高时（例如在药物试验中），统计效率是你的主要关注点。在这本书中，我们采取的方法是通常我们有很多数据，因此我们可以优先考虑相对统计效率较低的一般方法（例如使用测试保留集等），而不是更专业、统计效率更高的方法（例如Wald检验等特定的现成参数检验）。
- en: 'Remember: it’s a luxury, not a right, to ignore statistical efficiency. If
    your project has such a need, you’ll want to consult with expert statisticians
    to get the advantages of best practices.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 记住：忽略统计效率是一种奢侈，而不是权利。如果你的项目有这样的需求，你将想要咨询专家统计学家，以获得最佳实践的益处。
- en: B.2.2\. A/B tests
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2.2\. A/B 测试
- en: 'Hard statistical problems usually arise from poor experimental design. This
    section describes a simple, good, statistical design philosophy called *A/B testing*
    that has very simple theory. The ideal experiment is one where you have two groups—control
    (A) and treatment (B)—and the following holds:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 硬统计问题通常源于糟糕的实验设计。本节描述了一种简单、良好的统计设计哲学，称为 *A/B 测试*，它具有非常简单的理论。理想的实验是拥有两个组——控制组（A）和治疗组（B），并且以下条件成立：
- en: Each group is big enough that you get a reliable measurement (this drives significance).
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个组都足够大，以至于你可以得到可靠的测量结果（这推动了显著性）。
- en: Each group is (up to a single factor) distributed exactly like populations you
    expect in the future (this drives relevance). In particular, both samples are
    run in parallel at the same time.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个组（直到单个因素）都精确地分布得像你未来预期的群体（这推动了相关性）。特别是，两个样本都是同时并行运行的。
- en: The two groups differ only with respect to the single factor you’re trying to
    test.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个组只在你要测试的单个因素上有所不同。
- en: In an A/B test, a new idea, treatment, or improvement is proposed and then tested
    for effect. A common example is a proposed change to a retail website that it
    is hoped will improve the rate of conversion from browsers to purchasers. Usually,
    the treatment group is called *B* and an untreated or control group is called
    *A*. As a reference, we recommend “Practical Guide to Controlled Experiments on
    the Web” (R. Kohavi, R. Henne, and D. Sommerfield; KDD, 2007).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在 A/B 测试中，提出一个新的想法、治疗方法或改进措施，然后对其进行效果测试。一个常见的例子是，对零售网站提出一个希望提高从浏览器到购买者转换率的改变。通常，治疗组被称为
    *B* 组，未处理或对照组被称为 *A* 组。作为参考，我们推荐“网络受控实验实用指南”（R. Kohavi, R. Henne, 和 D. Sommerfield；KDD，2007）。
- en: Setting up A/B tests
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 A/B 测试
- en: Some care must be taken in running an A/B test. It’s important that the A and
    B groups be run at the same time. This helps defend the test from any potential
    confounding effects that might be driving their own changes in conversion rate
    (hourly effects, source-of-traffic effects, day-of-week effects, and so on). Also,
    you need to know that differences you’re measuring are in fact due to the change
    you’re proposing and not due to differences in the control and test infrastructures.
    To control for infrastructure, you should run a few A/A tests (tests where you
    run the same experiment in both A and B).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行 A/B 测试时需要格外小心。确保 A 组和 B 组同时运行非常重要。这有助于防御任何可能影响转换率变化的潜在混杂效应（如每小时效应、流量来源效应、星期几效应等）。此外，你需要知道你正在测量的差异实际上是由于你提出的改变造成的，而不是由于控制组和测试基础设施之间的差异。为了控制基础设施，你应该运行几个
    A/A 测试（在 A 和 B 组中运行相同实验的测试）。
- en: Randomization is the key tool in designing A/B tests. But the split into A and
    B needs to be made in a sensible manner. For example, for user testing, you don’t
    want to split raw clicks from the same user session into A/B, because then A/B
    would both have clicks from users that may have seen either treatment site. Instead,
    you’d maintain per-user records and assign users permanently to either the A or
    the B group when they arrive. One trick to avoid a lot of record keeping between
    different servers is to compute a hash of the user information and assign a user
    to A or B depending on whether the hash comes out even or odd (thus, all servers
    make the same decision without having to communicate).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 随机化是设计 A/B 测试的关键工具。但是，将用户分为 A 组和 B 组的方式需要合理。例如，对于用户测试，你不想将同一用户会话中的原始点击量分为 A/B
    组，因为这样 A/B 组都会有可能看到过任何治疗网站的用户的点击。相反，你应该维护每个用户的记录，并在用户到达时永久性地将他们分配到 A 组或 B 组。避免在不同服务器之间进行大量记录保存的一个技巧是计算用户信息的哈希值，并根据哈希值是偶数还是奇数将用户分配到
    A 组或 B 组（这样，所有服务器都会做出相同的决定，而无需进行通信）。
- en: Evaluating A/B tests
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 评估 A/B 测试
- en: The key measurements in an A/B test are the size of effect measured and the
    significance of the measurement. The natural alternative (or null hypothesis)
    to B being a good treatment is that B makes no difference, or B even makes things
    worse. Unfortunately, a typical failed A/B test often doesn’t look like certain
    defeat. It usually looks like the positive effect you’re looking for is there
    and you just need a slightly larger follow-up sample size to achieve significance.
    Because of issues like this, it’s critical to reason through acceptance/rejection
    conditions before running tests.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: A/B测试中的关键测量是效果的大小和测量的显著性。B作为良好治疗的自然替代品（或零假设）是B没有差异，或者B甚至使事情变得更糟。不幸的是，典型的失败的A/B测试通常看起来并不像彻底的失败。它通常看起来是你正在寻找的积极效果确实存在，你只需要一个稍微大一点的后续样本大小来实现显著性。由于这类问题，在运行测试之前进行接受/拒绝条件的推理至关重要。
- en: Let’s work an example A/B test. Suppose we’ve run an A/B test about conversion
    rate and collected the following data.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一个A/B测试的例子。假设我们已经运行了一个关于转化率的A/B测试并收集了以下数据。
- en: Listing B.12\. Building simulated A/B test data
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 列表B.12\. 构建模拟的A/B测试数据
- en: '[PRE12]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Builds a data frame to store simulated examples
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建一个数据框来存储模拟示例
- en: ❷ Adds 100,000 examples from the A group simulating a conversion rate of 5%
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从A组添加100,000个示例，模拟5%的转化率
- en: ❸ Adds 10,000 examples from the B group simulating a conversion rate of 5.5%
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 从B组添加10,000个示例，模拟5.5%的转化率
- en: Once we have the data, we summarize it into the essential counts using a data
    structure called a *contingency table*.^([[3](#app02fn3)])
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了数据，我们就使用一种称为**列联表**的数据结构将其总结为基本计数。^([[3](#app02fn3)])
- en: ³
  id: totrans-162
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ³
- en: ''
  id: totrans-163
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The confusion matrices we used in [section 6.2.3](../Text/06.xhtml#ch06lev2sec7)
    are also examples of contingency tables.
  id: totrans-164
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们在[第6.2.3节](../Text/06.xhtml#ch06lev2sec7)中使用的混淆矩阵也是列联表的例子。
- en: Listing B.13\. Summarizing the A/B test into a contingency table
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 列表B.13\. 将A/B测试总结到列联表中
- en: '[PRE13]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The contingency table is what statisticians call a *sufficient statistic*:
    it contains all we need to know about the experiment outcome. We can print the
    observed conversion rates of the A and B groups.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 列联表是统计学家所说的**充分统计量**：它包含了我们关于实验结果所需知道的一切。我们可以打印出A组和B组的观察转化率。
- en: Listing B.14\. Calculating the observed A and B conversion rates
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 列表B.14\. 计算观察到的A和B转化率
- en: '[PRE14]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We see that the A group was measured at near 5%, and the B group was measured
    at near 6%. What we want to know is this: can we trust this difference? Could
    such a difference be likely for this sample size due to mere chance and measurement
    noise? We need to calculate a significance to see if we ran a large enough experiment
    (obviously, we’d want to design an experiment that was large enough—what we call
    *test power*, which we’ll discuss in section B.6.5). What follows are a few good
    tests that are quick to run.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到A组的测量值接近5%，B组的测量值接近6%。我们想知道的是：我们能信任这个差异吗？这样的差异可能是由于纯粹的偶然和测量噪声导致的这个样本大小吗？我们需要计算一个显著性来查看我们是否运行了一个足够大的实验（显然，我们希望设计一个足够大的实验——我们称之为*测试功效*，我们将在B.6.5节中讨论）。以下是一些快速运行的优秀测试。
- en: Fisher’s test for independence
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 费舍尔独立性检验
- en: The first test we can run is Fisher’s contingency table test. In the Fisher
    test, the null hypothesis that we’re hoping to reject is that conversion is independent
    of group, or that the A and B groups are exactly identical. The Fisher test gives
    a probability of seeing an independent dataset (A=B) show a departure from independence
    as large as what we observed. We run the test as shown in the next listing.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以运行的第一项测试是费舍尔的列联表检验。在费舍尔检验中，我们希望拒绝的零假设是转化与组别无关，或者说A组和B组完全相同。费舍尔检验给出了一个概率，即看到独立数据集（A=B）显示出与独立性偏离的程度，与我们观察到的程度一样大。我们按照下一列表中的方式进行测试。
- en: Listing B.15\. Calculating the significance of the observed difference in rates
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 列表B.15\. 计算观察到的差异在率上的显著性
- en: '[PRE15]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This is a great result. The p-value (which in this case is the probability
    of observing a difference this large if we in fact had A=B) is 2.469e-05, which
    is very small. This is considered a significant result. The other thing to look
    for is the *odds ratio*: the practical importance of the claimed effect (sometimes
    also called *clinical significance*, which is not a statistical significance).
    An odds ratio of 1.2 says that we’re measuring a 20% relative improvement in conversion
    rate between the A and B groups. Whether you consider this large or small (typically,
    20% is considered large) is an important business question.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常好的结果。p 值（在这种情况下，如果我们实际上有 A=B，观察到这种差异的概率）是 2.469e-05，非常小。这被认为是一个显著的结果。另一件需要关注的是
    *优势比*：所声称效果的实际重要性（有时也称为 *临床意义*，这不属于统计意义）。优势比为 1.2 表示我们在 A 和 B 组之间测量到 20% 的相对转换率提升。你是否认为这是一个大或小的提升（通常，20%
    被认为是大的）是一个重要的商业问题。
- en: Frequentist significance test
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 频率主义显著性测试
- en: Another way to estimate significance is to again temporarily assume that A and
    B come from an identical distribution with a common conversion rate, and see how
    likely it would be that the B group scores as high as it did by mere chance. If
    we consider a binomial distribution centered at the common conversion rate, we’d
    like to see that there’s not a lot of probability mass for conversion rates at
    or above B’s level. This would mean the observed difference is unlikely if A=B.
    We’ll work through the calculation in the following listing.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种估计显著性的方法是再次暂时假设 A 和 B 来自一个具有共同转换率的相同分布，并看看 B 组仅通过偶然机会获得如此高的分数的可能性有多大。如果我们考虑一个以共同转换率为中心的二项分布，我们希望看到在或高于
    B 的水平的转换率上没有太多的概率质量。这意味着如果 A=B，观察到的差异不太可能。我们将在下面的列表中进行计算。
- en: Listing B.16\. Computing frequentist significance
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.16\. 计算频率主义显著性
- en: '[PRE16]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Uses the pbinom() call to calculate how likely different observed counts are
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用 pbinom() 调用来计算不同观察计数出现的可能性
- en: ❷ Signals that we want the probability of being greater than a given q
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们想要计算大于给定 q 的概率的信号
- en: ❸ Asks for the probability of seeing at least as many conversions as our observed
    B groups did. We subtract one to make the comparison inclusive (greater than or
    equal to tab['B', '1']).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 询问看到至少与我们观察到的 B 组一样多的转换的概率。我们减去一个，使比较包括（大于或等于 tab['B', '1']）。
- en: ❹ Specifies the total number of trials as equal to what we saw in our B group
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 指定总试验次数等于我们在 B 组中看到的次数
- en: ❺ Specifies the conversion probability at the estimated common rate
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 指定估计的共同转换率下的转换概率
- en: This is again a great result. The calculated probability is small, meaning such
    a difference is hard to observe by chance if `A = B`.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这又是一个非常好的结果。计算出的概率很小，这意味着如果 `A = B`，那么这种差异很难偶然观察到。
- en: B.2.3\. Power of tests
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2.3\. 测试的效力
- en: 'To have reliable A/B test results, you must first design and run good A/B tests.
    We need to defend against two types of errors: failing to see a difference, assuming
    there is one (described as test power); and seeing a difference, assuming there
    is not one (described as significance). The closer the difference in A and B rates
    we are trying to measure, the harder it is to have a good probability of getting
    a correct measurement. Our only tools are to design experiments where we hope
    A and B are far apart, or to increase experiment size. A power calculator lets
    us choose experiment size.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得可靠的 A/B 测试结果，你必须首先设计和运行良好的 A/B 测试。我们需要防御两种类型的错误：未能看到差异，假设有差异（描述为测试效力）；以及看到差异，假设没有差异（描述为显著性）。我们试图测量的
    A 和 B 组之间的差异越接近，就越难获得一个好的正确测量的概率。我们唯一的工具是设计实验，希望 A 和 B 有很大的差异，或者增加实验规模。效力计算器让我们选择实验规模。
- en: '* * *'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example Designing a test to see if a new advertisement has a higher conversion
    rate
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：设计一个测试来查看新广告是否具有更高的转换率
- en: '*Suppose we’re running a travel site that has 6,000 unique visitors per day
    and a 4% conversion rate*^([[4](#app02fn4)]) *from page views to purchase inquiries
    (our measurable goal). We’d like to test a new design for the site to see if it
    increases our conversion rate. This is exactly the kind of problem A/B tests are
    made for! But we have one more question: how many users do we have to route to
    the new design to get a reliable measurement? How long will it take us to collect
    enough data? We’re allowed to route no more than 10% of the visitors to the new
    advertisement.*'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设我们正在运行一个每天有6,000个独立访客和4%的转化率*^([[4](#app02fn4)]) *从页面浏览到购买咨询（我们的可衡量目标）的旅游网站。我们希望测试网站的新设计，看看它是否能提高我们的转化率。这正是A/B测试旨在解决的问题！但我们还有一个问题：我们需要将多少用户路由到新设计才能得到可靠的测量？我们需要多长时间才能收集足够的数据？我们允许将不超过10%的访客路由到新广告。*'
- en: ⁴
  id: totrans-191
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁴
- en: ''
  id: totrans-192
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We’re taking the 4% rate from [http://mng.bz/7pT3](http://mng.bz/7pT3).
  id: totrans-193
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们从[http://mng.bz/7pT3](http://mng.bz/7pT3)获取4%的比率。
- en: '* * *'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'In this experiment, we’ll route 90% of our traffic to the old advertisement
    and 10% to the new advertisement. There is uncertainty in estimating the conversion
    rate of the old advertisement going forward, but for simplicity of example (and
    because nine times more traffic is going to the old advertisement) we will ignore
    that. So our problem is this: how much traffic should we route to the new advertisement?'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们将90%的流量路由到旧广告，10%路由到新广告。对旧广告的转化率进行估计存在不确定性，但为了示例的简单性（以及因为九倍的流量将流向旧广告），我们将忽略这一点。因此，我们的问题是：我们应该将多少流量路由到新广告？
- en: 'To solve this, we need some criteria for our experimental design:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们需要为我们的实验设计一些标准：
- en: What is our estimate of the old advertisement’s conversion rate? Let’s say this
    is 0.04 or 4%.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们对旧广告的转化率的估计是多少？让我们说这是0.04或4%。
- en: What is a lower bound on what we consider a big enough improvement for the new
    advertisement? For the test to work, this must be larger than the old conversion
    rate. Let’s say this is 0.046 or 4.5%, representing a slightly larger-than-10%
    relative improvement in conversion to sale.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们认为新广告足够大的改进的下限是多少？为了测试能够工作，这个值必须大于旧转化率。让我们说这是0.046或4.5%，代表相对于销售转化的10%以上的相对改进。
- en: With what probability are we willing to be wrong if the new ad was no better?
    That is, if the new ad is in fact no better than the old ad, how often are we
    willing to “cry wolf” and claim there is an improvement (when there is in fact
    no such thing)? Let’s say we are willing to be wrong in this way 5% of the time.
    Let’s call this the *significance level*.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果新广告没有更好的话，我们愿意以多大的概率出错？也就是说，如果新广告实际上并不比旧广告更好，我们愿意多频繁地“狼来了”并声称有改进（实际上并没有这种事）？让我们说，我们愿意以这种方式出错5%的时间。让我们称这个为*显著性水平*。
- en: With what probability do we want to be right when the new ad was substantially
    better? That is, if the new ad is in fact converting at a rate of at least 4.5%,
    how often do we want to detect this? This is called *power* (and related to sensitivity,
    which we saw when discussing classification models). Let’s say we want the power
    to be 0.8 or 80%. When there is an improvement, we want to find it 80% of the
    time.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当新广告实质上更好时，我们希望以多大的概率是正确的？也就是说，如果新广告实际上以至少4.5%的比率转化，我们希望多频繁地检测到这一点？这被称为*功效*（与敏感性相关，我们在讨论分类模型时看到了这一点）。让我们说，我们希望功效为0.8或80%。当有改进时，我们希望80%的时间内找到它。
- en: Obviously, what we *want* is to be able to detect improvements at sizes close
    to zero, at a significance level of zero, and at a power of 1\. However, if we
    insist on any of these parameters being at their “if wishes were horses value”
    (near zero for improvement size, near zero for significance level, and near 1
    for power), the required test size to ensure these guarantees becomes enormous
    (or even infinite!). So as part of setting expectations before a project (always
    a good practice), we must first negotiate these “asks” to more achievable values
    such as those we just described.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们*希望*能够检测到接近零的改进，在零的显著性水平，以及在1的功效。然而，如果我们坚持任何这些参数达到它们的“如果愿望是马的价值”（改进大小接近零，显著性水平接近零，功效接近1），为了确保这些保证所需的测试规模变得巨大（甚至无限大！）因此，在项目开始前设定期望（始终是一个好习惯）的一部分，我们必须首先将这些“要求”协商到更可实现的价值，就像我们刚才描述的那样。
- en: 'When trying to determine sample size or experiment duration, the important
    concept is *statistical test power*. Statistical test power is the probability
    of rejecting the null hypothesis when the null hypothesis is false.^([[5](#app02fn5)])
    Think of statistical test power as 1 minus a p-value. The idea is this: you can’t
    pick out useful treatments if you can’t even identify which treatments are useless.
    So you want to design your tests to have test power near 1, which means p-values
    near 0.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 当试图确定样本量或实验持续时间时，重要的概念是 *统计测试功效*。统计测试功效是在零假设错误时拒绝零假设的概率。^([[5](#app02fn5)])
    将统计测试功效视为 1 减去 p 值。其想法是这样的：如果你甚至无法识别哪些治疗方法是无用的，那么你就无法挑选出有用的治疗方法。因此，你希望设计你的测试以使测试功效接近
    1，这意味着 p 值接近 0。
- en: ⁵
  id: totrans-203
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁵
- en: ''
  id: totrans-204
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: See B. S. Everitt, *The Cambridge Dictionary of Statistics* (Cambridge University
    Press, 2010).
  id: totrans-205
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 参见 B. S. Everitt 所著的 *《剑桥统计学词典》* (剑桥大学出版社，2010年)。
- en: 'The standard way to estimate the number of visitors we want to direct to the
    new advertisement is called a *power calculation* and is supplied by the R package
    `pwr`. Here is how we use R to get the answer:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 估算我们希望引导到新广告的访客数量的标准方法被称为 *功效计算*，由 R 包 `pwr` 提供。以下是我们是怎样使用 R 来得到答案的：
- en: '[PRE17]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Notice that all we did was copy our asks into the `pwr.p.test` method, though
    we did put the two assumed rates we are trying to distinguish through the `ES.h()`
    method, which converts the difference of rates into a Cohen-style “effect size.”
    In this case. `ES.h(p1 = 0.045, p2 = 0.04)` is 0.025, which is considered quite
    small (and therefore hard to measure). Effect sizes are very roughly how big an
    effect you are trying to measure relative to the natural variation of individuals.
    So we are trying to measure a change in the likelihood of a sale that is 1/0.025
    or 40 times smaller than the individual variation in likelihood of a sale. This
    is unobservable for any small set of individuals, but observable with a large
    enough sample.^([[6](#app02fn6)])
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们只是将我们的要求复制到 `pwr.p.test` 方法中，尽管我们确实通过 `ES.h()` 方法输入了我们要区分的两个假设比率，该方法将比率差异转换为
    Cohen 风格的“效应量”。在这种情况下，`ES.h(p1 = 0.045, p2 = 0.04)` 为 0.025，这被认为相当小（因此难以测量）。效应量非常粗略地表示你试图测量的效应相对于个体自然变异的大小。因此，我们试图测量销售可能性变化，这是个体销售可能性变异的
    1/0.025 或 40 倍小。对于任何小样本集来说，这是不可观察的，但足够大的样本可以观察到。^([[6](#app02fn6)])
- en: ⁶
  id: totrans-209
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁶
- en: ''
  id: totrans-210
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Effect sizes are nice idea, and have a rule of thumb that 0.2 is small, 0.5
    is medium, and 1.0 is large. See [https://en.wikipedia.org/wiki/Effect_size](https://en.wikipedia.org/wiki/Effect_size).
  id: totrans-211
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 效应量是一个好主意，有一个经验法则，即 0.2 是小的，0.5 是中等的，1.0 是大的。参见 [https://en.wikipedia.org/wiki/Effect_size](https://en.wikipedia.org/wiki/Effect_size)。
- en: The `n = 10056` is the amount of traffic we would have to send to the new advertisement
    to get a test result with at least the specified quality parameters (significance
    level and power). So we would need to serve the new advertisement to 10056 visitors
    to achieve our A/B test measurement. Our site receives 6,000 visitors a day, and
    we are only allowed to send 10% of them, or 600, to the new advertisement each
    day. So it would take us 10056/600 or 16.8 days to complete this test.^([[7](#app02fn7)])
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`n = 10056` 是我们需要发送到新广告上的流量量，以获得至少满足指定质量参数（显著性水平和功效）的测试结果。因此，我们需要向 10056 位访客展示新广告，以完成我们的
    A/B 测试测量。我们的网站每天有 6,000 位访客，我们每天只能向其中 10%，即 600 位，展示新广告。因此，完成这项测试需要 10056/600
    或 16.8 天。^([[7](#app02fn7)])'
- en: ⁷
  id: totrans-213
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁷
- en: ''
  id: totrans-214
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is fact one of the dirty secrets of A/B tests: measuring small improvements
    of rare events such as conversion of an advertisement to a sale (often called
    “conversion to sale”) takes a lot of data, and acquiring a lot of data can take
    a lot of time.'
  id: totrans-215
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这实际上是 A/B 测试的一个不为人知的秘密：测量诸如广告转化成销售（通常称为“转化成销售”）等罕见事件的微小改进需要大量数据，而获取大量数据可能需要很长时间。
- en: '* * *'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Venue shopping reduces test power**'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**场所购物降低测试功效**'
- en: 'We’ve discussed test power and significance under the assumption you’re running
    one large test. In practice, you may run multiple tests trying many treatments
    to see if any treatment delivers an improvement. This reduces your test power.
    If you run 20 treatments, each with a p-value goal of 0.05, you would expect one
    test to appear to show significant improvement, even if all 20 treatments are
    useless. Testing multiple treatments or even reinspecting the same treatment many
    times is a form of “venue shopping” (you keep asking at different venues until
    you get a ruling in your favor). Calculating the loss of test power is formally
    called “applying the Bonferroni correction” and is as simple as multiplying your
    significance estimates by your number of tests (remember, large values are bad
    for significances or p-values). To compensate for this loss of test power, you
    can run each of the underlying tests at a tighter *p* cutoff: *p* divided by the
    number of tests you intend to run.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在假设你正在运行一个大型测试的情况下讨论了测试功效和显著性。在实践中，你可能需要运行多个测试，尝试多种处理方法，以查看是否有任何处理方法能带来改进。这会降低你的测试功效。如果你运行20种处理方法，每种处理方法的p值目标为0.05，你可能会期望有一个测试看起来显示出显著的改进，即使所有20种处理方法都毫无用处。测试多种处理方法或甚至多次重新检查同一处理方法是一种“地点购物”的形式（你会在不同的地点不断询问，直到得到对你有利的裁决）。计算测试功效的损失正式称为“应用Bonferroni校正”，其简单之处在于将你的显著性估计值乘以你的测试数量（记住，大数值对显著性或p值是不利的）。为了补偿这种测试功效的损失，你可以将每个基础测试在更紧的*p*截止值下运行：*p*除以你打算运行的测试数量。
- en: '* * *'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: B.2.4\. Specialized statistical tests
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2.4. 专用统计测试
- en: Throughout this book, we concentrate on building predictive models and evaluating
    significance, either through the modeling tool’s built-in diagnostics or through
    empirical resampling (such as bootstrap tests or permutation tests). In statistics,
    there’s an efficient correct test for the significance of just about anything
    you commonly calculate. Choosing the right standard test gives you a good implementation
    of the test and access to literature that explains the context and implications
    of the test. Let’s work on calculating a simple correlation and finding the matching
    correct test.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们专注于构建预测模型和评估显著性，无论是通过建模工具内置的诊断工具，还是通过经验重采样（如bootstrap测试或排列测试）。在统计学中，对于你通常计算的大多数内容，都有一个高效的正确测试来检验其显著性。选择正确的标准测试为你提供了一个良好的测试实现，并可以访问解释测试背景和影响的文献。让我们来计算一个简单的相关系数，并找到匹配的正确测试。
- en: We’ll work with a synthetic example that should remind you a bit of our PUMS
    Census work in [chapter 8](../Text/08.xhtml#ch08). Suppose we’ve measured both
    earned income (money earned in the form of salary) and capital gains (money received
    from investments) for 100 individuals. Further suppose that there’s no relation
    between the two for our individuals (in the real world, there’s a correlation,
    but we need to make sure our tools don’t report one even when there’s none). We’ll
    set up a simple dataset representing this situation with some lognormally distributed
    data.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个合成示例，这个示例应该会让你想起我们在第8章中进行的PUMS人口普查工作。[第8章](../Text/08.xhtml#ch08)。假设我们已经测量了100个人的收入（以工资形式获得的钱）和资本收益（从投资中获得的钱）。进一步假设，对于我们的个人来说，这两者之间没有关系（在现实世界中，存在相关性，但我们需要确保我们的工具即使在没有任何关系的情况下也不会报告出来）。我们将使用一些对数正态分布的数据设置一个简单的数据集来表示这种情况。
- en: Listing B.17\. Building synthetic uncorrelated income
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 列表B.17. 构建合成的非相关收入
- en: '[PRE18]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Sets the pseudo-random seed to a known value so the demonstration is repeatable
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将伪随机种子设置为已知值，以便演示可重复进行
- en: ❷ Generates our synthetic data
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 生成我们的合成数据
- en: ❸ The correlation is –0.01, which is very near 0—indicating (as designed) no
    relation.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 相关系数为-0.01，这非常接近0——表明（如设计所示）没有关系。
- en: We claim the observed correlation of -0.01 is statistically indistinguishable
    from 0 (or no effect). This is something we should quantify. A little research
    tells us the common correlation is called a *Pearson coefficient*, and the significance
    test for a Pearson coefficient for normally distributed data is a Student’s t-test
    (with the number of degrees of freedom equal to the number of items minus 2).
    We know our data is not normally distributed (it is, in fact, lognormally distributed),
    so we research further and find the preferred solution is to compare the data
    by rank (instead of by value) and use a test like Spearman’s rho or Kendall’s
    tau. We’ll use Spearman’s rho, as it can track both positive and negative correlations
    (whereas Kendall’s tau tracks degree of agreement).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声称观察到的-0.01的相关性在统计学上与0（或无效果）无法区分。这是我们应当量化的。一点研究告诉我们，常见的相关性被称为*皮尔逊系数*，对于正态分布数据的皮尔逊系数的显著性测试是学生t检验（自由度等于项目数减去2）。我们知道我们的数据不是正态分布的（实际上是对数正态分布），所以我们进一步研究，发现首选的解决方案是通过排名（而不是值）比较数据，并使用斯皮尔曼的ρ或肯德尔的τ这样的测试。我们将使用斯皮尔曼的ρ，因为它可以追踪正负相关性（而肯德尔的τ追踪的是一致性程度）。
- en: A fair question is, how do we know which is the exact right test to use? The
    answer is, by studying statistics. Be aware that there are a lot of tests, giving
    rise to books like *100 Statistical Tests in R* by N. D. Lewis (Heather Hills
    Press, 2013). We also suggest that if you know the name of a test, consult B.
    S.Everitt and A. Skrondal, *The Cambridge Dictionary of Statistics*, Fourth Edition
    (Cambridge University Press, 2010).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一个合理的问题是，我们如何知道使用哪个测试是正确的？答案是，通过学习统计学。请注意，有很多测试，这导致了像N. D. Lewis的《R中的100个统计测试》（Heather
    Hills Press，2013年）这样的书籍。我们还建议，如果你知道一个测试的名称，可以查阅B. S.Everitt和A. Skrondal的《剑桥统计学词典》，第四版（Cambridge
    University Press，2010年）。
- en: Another way to find the right test is using R’s help system. `help(cor)` tells
    us that `cor()` implements three different calculations (Pearson, Spearman, and
    Kendall) and that there’s a matching function called `cor.test()` that performs
    the appropriate significance test. Since we weren’t too far off the beaten path,
    we only need to read up on these three tests and settle on the one we’re interested
    in (in this case, Spearman). So let’s redo our correlation with the chosen test
    and check the significance.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种找到正确测试的方法是使用R的帮助系统。`help(cor)`告诉我们`cor()`实现了三种不同的计算（皮尔逊、斯皮尔曼和肯德尔），并且有一个匹配的函数叫做`cor.test()`，它执行适当的显著性测试。由于我们并没有偏离常规路径太远，我们只需要了解这三种测试，并确定我们感兴趣的测试（在这种情况下，斯皮尔曼）。因此，让我们用选定的测试重新进行相关性计算，并检查显著性。
- en: Listing B.18\. Calculating the (non)significance of the observed correlation
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: B.18. 列表：计算观察到的相关性的（非）显著性
- en: '[PRE19]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We see the Spearman correlation is 0.03 with a p-value of 0.7604, which means
    truly uncorrelated data would show a coefficient this large about 76% of the time.
    So there’s no significant effect (which is exactly how we designed our synthetic
    example).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到斯皮尔曼相关系数为0.03，p值为0.7604，这意味着真正不相关的数据大约有76%的时间会显示出这样大的系数。因此，没有显著效果（这正是我们设计合成示例的方式）。
- en: In our own work, we use the `sigr` package to wrap up these test results for
    more succinct formal presentation. The format is similar to the APA (American
    Psychological Association) style, and `n.s.` means “not significant.”
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们自己的工作中，我们使用`sigr`包来封装这些测试结果，以便进行更简洁的正式展示。格式类似于APA（美国心理学会）风格，而`n.s.`表示“不显著”。
- en: '[PRE20]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: B.3\. Examples of the statistical view of data
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.3. 示例：数据的统计观点
- en: 'Compared to statistics, machine learning and data science have an optimistic
    view of working with data. In data science, you quickly pounce on noncausal relations
    in the hope that they’ll hold up and help with future prediction. Much of statistics
    is about how data can lie to you and how such relations can mislead you. We only
    have space for a couple of examples, so we’ll concentrate on two of the most common
    issues: sampling bias and missing-variable bias.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 与统计学相比，机器学习和数据科学对数据处理持乐观态度。在数据科学中，你迅速抓住非因果关系，希望它们会持续并有助于未来的预测。统计学的大部分内容是关于数据如何欺骗你以及这些关系如何误导你。我们只有空间举几个例子，所以我们将集中在两个最常见的问题上：抽样偏差和缺失变量偏差。
- en: B.3.1\. Sampling bias
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3.1. 抽样偏差
- en: '*Sampling bias* is any process that systematically alters the distribution
    of observed data.^([[8](#app02fn8)]) The data scientist must be aware of the possibility
    of sampling bias and be prepared to detect it and fix it. The most effective way
    is to fix your data collection methodology.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '*抽样偏差*是指任何系统地改变观察数据分布的过程.^([[8](#app02fn8)]) 数据科学家必须意识到抽样偏差的可能性，并准备好检测和修复它。最有效的方法是修复你的数据收集方法。'
- en: ⁸
  id: totrans-240
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁸
- en: ''
  id: totrans-241
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We would have liked to use the common term “censored” for this issue, but in
    statistics the phrase *censored observations* is reserved for variables that have
    only been recorded up to a limit or bound. So it would be potentially confusing
    to use the term to describe missing observations.
  id: totrans-242
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们本想使用常见的术语“截断”来描述这个问题，但在统计学中，短语*censored observations*是保留给那些只记录到某个极限或界限的变量的。因此，使用该术语来描述缺失观察结果可能会造成混淆。
- en: For our sampling bias example, we’ll continue with the income example we started
    in [section B.4](../Text/B.xhtml#app02lev1sec4). Suppose through some happenstance
    we were studying only a high-earning subset of our original population (perhaps
    we polled them at some exclusive event). The following listing shows how, when
    we restrict to a high-earning set, it appears that earned income and capital gains
    are strongly anticorrelated. We get a correlation of -0.86 (so think of the anticorrelation
    as explaining about `(-0.86)^2 = 0.74 = 74%` of the variance; see [http://mng.bz/ndYf](http://mng.bz/ndYf))
    and a p-value very near 0 (so it’s unlikely the unknown true correlation of more
    data produced in this manner is in fact 0). The following listing demonstrates
    the calculation.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的抽样偏差示例，我们将继续使用我们在[B.4节](../Text/B.xhtml#app02lev1sec4)中开始讨论的收入示例。假设通过某种偶然，我们只研究我们原始人口中的高收入子集（也许我们在某个独家活动中对他们进行了民意调查）。以下列表显示了当我们限制为高收入集时，似乎收入和资本收益之间存在强烈的负相关性。我们得到的相关性为-0.86（因此，将负相关性视为解释了`(-0.86)^2
    = 0.74 = 74%`的方差；参见[http://mng.bz/ndYf](http://mng.bz/ndYf))，p值非常接近0（因此，不太可能以这种方式产生的更多未知真实相关性实际上为0）。以下列表展示了计算过程。
- en: Listing B.19\. Misleading significance result from biased observations
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 列表B.19\. 偏差观察结果导致的误导性显著性结果
- en: '[PRE21]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Some plots help to show what’s going on. [Figure B.8](#app02fig08) shows the
    original dataset with the best linear relation line run through. Note that the
    line is nearly flat (indicating change in `x` doesn’t predict change in `y`).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 一些图表有助于展示正在发生的事情。[图B.8](#app02fig08)显示了通过最佳线性关系线绘制的原始数据集。请注意，该线几乎是平的（表明`x`的变化不能预测`y`的变化）。
- en: Figure B.8\. Earned income versus capital gains
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.8\. 收入与资本收益
- en: '![](Images/app02fig08_alt.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/app02fig08_alt.jpg)'
- en: '[Figure B.9](#app02fig09) shows the best trend line run through the high income
    dataset. It also shows how cutting out the points below the line `x+y=500000`
    leaves a smattering of rare high-value events arranged in a direction that crudely
    approximates the slope of our cut line (–0.8678571 being a crude approximation
    for –1). It’s also interesting to note that the bits we suppressed aren’t correlated
    among themselves, so the effect wasn’t a matter of suppressing a correlated group
    out of an uncorrelated cloud to get a negative correlation.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[图B.9](#app02fig09)显示了穿过高收入数据集的最佳趋势线。它还显示了如何删除低于线`x+y=500000`的点，留下一些稀疏的高价值事件，这些事件按方向排列，粗略地近似我们的切割线（-0.8678571是-1的粗略近似）。值得注意的是，我们抑制的部分之间没有相关性，因此这种影响并不是通过从非相关云中抑制相关组来获得负相关。'
- en: Figure B.9\. Biased earned income vs. capital gains
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.9\. 偏差收入与资本收益
- en: '![](Images/app02fig09_alt.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/app02fig09_alt.jpg)'
- en: The code to produce [figures B.8](#app02fig08) and [B.9](#app02fig09) and calculate
    the correlation between suppressed points is shown in the following listing.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 生成[图B.8](#app02fig08)、[B.9](#app02fig09)并计算被抑制点之间相关性的代码如下所示。
- en: Listing B.20\. Plotting biased view of income and capital gains
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 列表B.20\. 绘制收入和资本收益的偏差视图
- en: '[PRE22]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Plots all of the income data with linear trend line (and uncertainty band)
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 以线性趋势线（以及不确定性带）绘制所有收入数据
- en: ❷ Plots the very high income data and linear trend line (also includes cut-off
    and portrayal of suppressed data)
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 绘制非常高的收入数据和线性趋势线（包括截止点和被抑制数据的描绘）
- en: ❸ Computes correlation of suppressed data
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算被抑制数据的相关性
- en: B.3.2\. Omitted variable bias
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3.2\. 漏掉变量偏差
- en: 'Many data science clients expect data science to be a quick process, where
    every convenient variable is thrown in at once and a best possible result is quickly
    obtained. Statisticians are rightfully wary of such an approach due to various
    negative effects such as omitted variable bias, collinear variables, confounding
    variables, and nuisance variables. In this section, we’ll discuss one of the more
    general issues: omitted variable bias.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据科学客户期望数据科学是一个快速的过程，其中一次性将所有方便的变量投入其中，并迅速获得最佳结果。统计学家有理由对此类方法持谨慎态度，因为各种负面效应，如漏变量偏差、共线性变量、混杂变量和干扰变量。在本节中，我们将讨论一个更普遍的问题：漏变量偏差。
- en: What is omitted variable bias?
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是漏变量偏差？
- en: In its simplest form, omitted variable bias occurs when a variable that isn’t
    included in the model is both correlated with what we’re trying to predict and
    correlated with a variable that’s included in our model. When this effect is strong,
    it causes problems, as the model-fitting procedure attempts to use the variables
    in the model to both directly predict the desired outcome and to stand in for
    the effects of the missing variable. This can introduce biases, create models
    that don’t quite make sense, and result in poor generalization performance.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在其最简单的形式中，漏变量偏差发生在模型中未包含的变量既与我们试图预测的内容相关联，又与模型中包含的变量相关联。当这种影响强烈时，会导致问题，因为模型拟合过程试图使用模型中的变量来直接预测所需的输出，并代表缺失变量的影响。这可能会引入偏差，创建出不太合理的模型，并导致泛化性能不佳。
- en: The effect of omitted variable bias is easiest to see in a regression example,
    but it can affect any type of model.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 漏变量偏差的影响在回归示例中最容易看到，但它可以影响任何类型的模型。
- en: An example of omitted variable bias
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 漏变量偏差的一个例子
- en: We’ve prepared a synthetic dataset called synth.RData (download from [https://github.com/WinVector/PDSwR2/tree/master/bioavailability](https://github.com/WinVector/PDSwR2/tree/master/bioavailability))
    that has an omitted variable problem typical for a data science project. To start,
    please download synth.RData and load it into R, as the next listing shows.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备了一个名为synth.RData的合成数据集（从[https://github.com/WinVector/PDSwR2/tree/master/bioavailability](https://github.com/WinVector/PDSwR2/tree/master/bioavailability)下载），它具有数据科学项目中典型的漏变量问题。首先，请下载synth.RData并将其加载到R中，如下所示。
- en: Listing B.21\. Summarizing our synthetic biological data
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 列表B.21. 总结我们的合成生物数据
- en: '[PRE23]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Displays a date in a spreadsheet-like window. View is one of the commands
    that has a much better implementation in RStudio than in basic R.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在类似电子表格的窗口中显示日期。视图是RStudio中比基本R有更好实现的命令之一。
- en: This loads synthetic data that’s supposed to represent a simplified view of
    the kind of data that might be collected over the history of a pharmaceutical
    ADME^([[9](#app02fn9)]) or bioavailability project. RStudio’s `View()` spreadsheet
    is shown in [figure B.10](#app02fig10). The columns of this dataset are described
    in [table B.1](#app02table01).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这加载了代表可能收集的药物ADME^([[9](#app02fn9)])或生物利用度项目历史数据的简化视图的合成数据。RStudio的`View()`电子表格显示在[图B.10](#app02fig10)。此数据集的列在[表B.1](#app02table01)中描述。
- en: ⁹
  id: totrans-269
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁹
- en: ''
  id: totrans-270
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ADME stands for absorption, distribution, metabolism, excretion; it helps determine
    which molecules make it into the human body through ingestion and thus could even
    be viable candidates for orally delivered drugs.
  id: totrans-271
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ADME代表吸收、分布、代谢、排泄；它有助于确定哪些分子可以通过摄入进入人体，因此甚至可能是口服药物的可行候选者。
- en: Figure B.10\. View of rows from the bioavailability dataset
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.10. 生物利用度数据集的行视图
- en: '![](Images/app02fig10_alt.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/app02fig10_alt.jpg)'
- en: Table B.1\. Bioavailability columns
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 表B.1. 生物利用度列
- en: '| Column | Description |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 列 | 描述 |'
- en: '| --- | --- |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| week | In this project, we suppose that a research group submits a new drug
    candidate molecule for assay each week. To keep things simple, we use the week
    number (in terms of weeks since the start of the project) as the identifier for
    the molecule and the data row. This is an optimization project, which means each
    proposed molecule is made using lessons learned from all of the previous molecules.
    This is typical of many projects, but it means the data rows aren’t mutually exchangeable
    (an important assumption that we often use to justify statistical and machine
    learning techniques). |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| week | 在这个项目中，我们假设一个研究小组每周提交一个新的候选药物分子进行检测。为了简化问题，我们使用周数（自项目开始以来的周数）作为分子的标识符和数据行的标识符。这是一个优化项目，这意味着每个提出的分子都是使用从所有先前分子中学到的经验制作的。这在许多项目中是典型的，但这意味着数据行不能互相交换（我们经常使用的重要假设，以证明统计和机器学习技术的合理性）。'
- en: '| Caco2A2BPapp | This is the first assay run (and the “cheap” one). The Caco2
    test measures how fast the candidate molecule passes through a membrane of cells
    derived from a specific large intestine carcinoma (cancers are often used for
    tests, as noncancerous human cells usually can’t be cultured indefinitely). The
    Caco2 test is a stand-in or analogy test. The test is thought to simulate one
    layer of the small intestine that it’s morphologically similar to (though it lacks
    a number of forms and mechanisms found in the actual small intestine). Think of
    Caco2 as a cheap test to evaluate a factor that correlates with bioavailability
    (the actual goal of the project). |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| Caco2A2BPapp | 这是我们进行的第一次检测（也是“便宜”的一次）。Caco2测试测量候选分子通过由特定大肠癌细胞系（癌症常用于测试，因为非癌性的人类细胞通常不能无限期地培养）衍生的细胞膜的速度。Caco2测试是一种替代或类比测试。该测试被认为模拟了一层与它形态相似的小肠层（尽管它缺少实际小肠中存在的一些形态和机制）。将Caco2视为一种便宜的测试，用于评估与生物利用度（项目的实际目标）相关的因素。'
- en: '| FractionHumanAbsorption | This is the second assay run and is what fraction
    of the drug candidate is absorbed by human test subjects. Obviously, these tests
    would be expensive to run and subject to a lot of safety protocols. For this example,
    optimizing absorption is the actual end goal of the project. |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| FractionHumanAbsorption | 这是第二次检测，表示药物候选物被人体测试对象吸收的比例。显然，这些测试的运行成本很高，并且受到许多安全协议的约束。在这个例子中，优化吸收是项目的实际最终目标。'
- en: We’ve constructed this synthetic data to represent a project that’s trying to
    optimize human absorption by working through small variations of a candidate drug
    molecule. At the start of the project, they have a molecule that’s highly optimized
    for the stand-in criteria Caco2 (which does correlate with human absorption),
    and through the history of the project, actual human absorption is greatly increased
    by altering factors that we’re not tracking in this simplistic model. During drug
    optimization, it’s common to have formerly dominant stand-in criteria revert to
    ostensibly less desirable values as other inputs start to dominate the outcome.
    So for our example project, the human absorption rate is rising (as the scientists
    successfully optimize for it) and the Caco2 rate is falling (as it started high,
    and we’re no longer optimizing for it, even though it *is* a useful feature).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了这组合成数据来代表一个试图通过候选药物分子的微小变化来优化人体吸收的项目。在项目开始时，他们有一个针对替代标准Caco2（它与人体吸收相关）高度优化的分子，并且在项目的历史过程中，通过改变我们在这个简单模型中未跟踪的因素，实际的人体吸收大大增加。在药物优化过程中，通常会出现曾经占主导地位的替代标准在其它输入开始主导结果时，其价值似乎变得不那么理想。因此，在我们的示例项目中，人体吸收率正在上升（因为科学家们成功地对其进行了优化），而Caco2率正在下降（因为它一开始就很高，而我们不再对其优化，尽管它*确实*是一个有用的特征）。
- en: One of the advantages of using synthetic data for these problem examples is
    that we can design the data to have a given structure, and then we know the model
    is correct if it picks this up and incorrect if it misses it. In particular, this
    dataset was designed such that Caco2 is always a positive contribution to fraction
    of absorption throughout the entire dataset. This data was generated using a random
    non-increasing sequence of plausible Caco2 measurements and then generating fictional
    absorption numbers, as shown next (the data frame `d` that you also loaded from
    synth.RData is the published graph we base our synthetic example on). We produce
    our synthetic data that’s known to improve over time in the next listing.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 使用合成数据为这些问题示例提供的一个优点是，我们可以设计数据以具有给定的结构，然后我们知道如果模型能够捕捉到这一点，那么模型就是正确的；如果它错过了这一点，那么模型就是错误的。特别是，这个数据集被设计成
    Caco2 在整个数据集中始终是吸收分数的正向贡献。这些数据是通过使用合理的 Caco2 测量值的随机非递增序列生成的，然后生成虚构的吸收数值，如下所示（从
    synth.RData 中加载的数据框 `d` 是我们基于合成示例发布的图形）。我们将在下一个列表中生成已知随时间改进的合成数据。
- en: Listing B.22\. Building data that improves over time
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.22\. 随时间改进的数据构建
- en: '[PRE24]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: ❶ Builds synthetic examples
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建合成示例
- en: '❷ Adds in Caco2 to the absorption relation learned from the original dataset.
    Note that the relation is positive: better Caco2 always drives better absorption
    in our synthetic dataset. We’re log transforming Caco2, as it has over 3 decades
    of range.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将 Caco2 添加到从原始数据集学习到的吸收关系中。请注意，这种关系是正向的：在我们的合成数据集中，更好的 Caco2 总是推动更好的吸收。我们正在对
    Caco2 进行对数变换，因为它有超过 30 年的范围。
- en: ❸ Adds in a mean-0 term that depends on time to simulate the effects of improvements
    as the project moves forward
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 添加一个依赖于时间的均值为 0 的项，以模拟项目推进过程中的改进效果
- en: ❹ Adds in a mean-0 noise term
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 添加一个均值为 0 的噪声项
- en: 'The design of this data is this: Caco2 always has a positive effect (identical
    to the source data we started with), but this gets hidden by the `week` factor
    (and Caco2 is negatively correlated with `week`, because `week` is increasing
    and Caco2 is sorted in decreasing order). Time is not a variable we at first wish
    to model (it isn’t something we usefully control), but analyses that omit time
    suffer from omitted variable bias. For the complete details, consult our GitHub
    example documentation ([https://github.com/WinVector/PDSwR2/tree/master/bioavailability](https://github.com/WinVector/PDSwR2/tree/master/bioavailability)).'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这组数据的设计是这样的：Caco2 总是具有正向效应（与我们的起始源数据相同），但这一效应被 `week` 因子所掩盖（因为 `week` 在增加，而
    Caco2 是按递减顺序排列的）。时间不是我们最初希望建模的变量（这不是我们可以有效控制的），但省略时间的分析会受到省略变量偏差的影响。关于完整细节，请参阅我们的
    GitHub 示例文档（[https://github.com/WinVector/PDSwR2/tree/master/bioavailability](https://github.com/WinVector/PDSwR2/tree/master/bioavailability)）。
- en: A spoiled analysis
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 一个被宠坏的分析
- en: In some situations, the true relationship between Caco2 and `FractionHumanAbsorption`
    is hidden because the variable `week` is positively correlated with `FractionHumanAbsorption`
    (as the absorption is being improved over time) and negatively correlated with
    Caco2 (as Caco2 is falling over time). `week` is a stand-in variable for all the
    other molecular factors driving human absorption that we’re not recording or modeling.
    [Listing B.23](#app02ex23) shows what happens when we try to model the relation
    between Caco2 and `FractionHumanAbsorption` without using the `week` variable
    or any other factors.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，Caco2 与 `FractionHumanAbsorption` 之间的真实关系被隐藏，因为变量 `week` 与 `FractionHumanAbsorption`
    正相关（因为吸收随时间改善）且与 Caco2 负相关（因为 Caco2 随时间下降）。`week` 是代表我们未记录或建模的所有其他驱动人类吸收的分子因素的替代变量。[列表
    B.23](#app02ex23) 展示了当我们尝试不使用 `week` 变量或任何其他因素来建模 Caco2 与 `FractionHumanAbsorption`
    之间的关系时会发生什么。
- en: Listing B.23\. A bad model (due to omitted variable bias)
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.23\. 一个糟糕的模型（由于省略变量偏差）
- en: '[PRE25]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: For details on how to read the `glm()` summary, please see [section 7.2](../Text/07.xhtml#ch07lev1sec2).
    Note that the sign of the Caco2 coefficient is negative, not what’s plausible
    or what we expected going in. This is because the Caco2 coefficient isn’t just
    recording the relation of Caco2 to `FractionHumanAbsorption`, but also having
    to record any relations that come through omitted correlated variables.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何阅读 `glm()` 摘要的详细信息，请参阅[第 7.2 节](../Text/07.xhtml#ch07lev1sec2)。注意，Caco2
    系数的符号是负的，而不是我们预期的或合理的。这是因为 Caco2 系数不仅记录了 Caco2 与 `FractionHumanAbsorption` 之间的关系，还必须记录任何通过省略的相关变量产生的任何关系。
- en: Working around omitted variable bias
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 解决省略变量偏差
- en: 'There are a number of ways to deal with omitted variable bias, the best ways
    being better experimental design and more variables. Other methods include use
    of fixed-effects models and hierarchical models. We’ll demonstrate one of the
    simplest methods: adding in possibly important omitted variables. In the following
    listing, we redo the analysis with `week` included.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种处理遗漏变量偏差的方法，最好的方法是更好的实验设计和更多的变量。其他方法包括使用固定效应模型和层次模型。我们将演示其中一种最简单的方法：添加可能重要的遗漏变量。在下面的列表中，我们包括了`week`变量重新进行了分析。
- en: Listing B.24\. A better model
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.24\. 一个更好的模型
- en: '[PRE26]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We recovered decent estimates of both the Caco2 and `week` coefficients, but
    we didn’t achieve statistical significance on the effect of Caco2\. Note that
    fixing omitted variable bias requires (even in our synthetic example) some domain
    knowledge to propose important omitted variables and the ability to measure the
    additional variables (and to try to remove their impact through the use of an
    offset; see `help('offset')`).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们恢复了Caco2和`week`系数的合理估计，但我们没有在Caco2的影响上达到统计显著性。请注意，修正遗漏变量偏差需要（即使在我们的合成示例中）一些领域知识来提出重要的遗漏变量，以及测量额外变量的能力（并尝试通过使用偏置来消除它们的影响；参见`help('offset')`）。
- en: At this point, you should have a more detailed intentional view of variables.
    There are, at the least, variables you can control (explanatory variables), important
    variables you can’t control (nuisance variables), and important variables you
    don’t know (omitted variables). Your knowledge of all of these variable types
    should affect your experimental design and analysis.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你应该对变量有一个更详细的意向性看法。至少，有你可以控制的变量（解释变量），重要的变量你无法控制（干扰变量），以及你不知道的重要变量（遗漏变量）。你对所有这些变量类型的了解应该影响你的实验设计和分析。
- en: B.4\. The takeaway
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.4\. 吸取的教训
- en: 'Statistics is a deep field with important implications for data science. Statistics
    includes the study of what can go wrong in modeling and analysis, and if you don’t
    prepare for what can go wrong, it tends to go wrong. We hope you will take this
    appendix as an invitation for further study. A book we recommend is *Statistical
    Models: Theory and Practice* by David Freedman (Cambridge Press, 2009).'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学是一个深奥的领域，对数据科学有重要的影响。统计学包括对建模和分析中可能出错的研究，如果你没有为可能出错的情况做好准备，它往往会出错。我们希望你能将这个附录视为进一步学习的邀请。我们推荐的一本书是David
    Freedman所著的《统计模型：理论与实践》（剑桥出版社，2009年）。
