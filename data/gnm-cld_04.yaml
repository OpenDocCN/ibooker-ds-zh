- en: Chapter 3\. Computing Technology Basics for Life Scientists
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章。生命科学家的计算技术基础
- en: In an ideal world, you wouldn’t need to worry too much about computing infrastructure
    when you’re pursuing your research. In fact, in later chapters we introduce you
    to systems that are specifically designed to abstract away the nitty-gritty of
    computing infrastructure in order to help you focus on your science. However,
    you will find that a certain amount of terminology and concepts are unavoidable
    in the real world. Investing some effort into learning them will help you to plan
    and execute your work more efficiently, address performance challenges, and achieve
    larger scale with less effort. In this chapter, we review the essential components
    that form the most common types of computing infrastructure, and we discuss how
    their strengths and limitations inform our strategies for getting work done efficiently
    at scale. We also go over key concepts such as parallel computing and pipelining,
    which are essential in genomics because of the need for automation and reproducibility.
    Finally, we introduce virtualization and lay out the case for cloud infrastructure.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想的世界里，当你追求研究时，你不需要太担心计算基础设施。事实上，在后面的章节中，我们会介绍一些专门设计的系统，以抽象掉计算基础设施的细枝末节，帮助你专注于科学研究。然而，在现实世界中，你会发现一定程度上无法避免某些术语和概念。投入一些精力学习它们将有助于你更高效地规划和执行工作，解决性能挑战，并以更少的努力实现更大的规模。在这一章中，我们回顾了构成最常见类型计算基础设施的基本组件，并讨论它们的优势和局限性如何指导我们在规模上高效完成工作的策略。我们还讨论了诸如并行计算和流水线处理等关键概念，这些概念在基因组学中是必不可少的，因为需要自动化和可重复性。最后，我们介绍了虚拟化技术，并提出了云基础设施的理由。
- en: The first few sections in this chapter are aimed at readers who have not had
    much training, if any, in informatics, programming, or systems administration.
    If you are a computational scientist or an IT professional, feel free to skip
    ahead until you encounter something that you don’t already know. The last two
    sections, which together cover pipelining, virtualization, and the cloud, are
    more specifically focused on the problems that we tackle in this book and should
    be informative for all readers regardless of background.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的前几节面向那些在信息学、编程或系统管理方面没有太多培训的读者。如果你是计算科学家或IT专业人员，请随意跳过，直到你遇到一些你还不知道的内容。最后两节，一起涵盖流水线处理、虚拟化和云计算，更专注于本书中我们解决的问题，应对不同背景读者都有益。
- en: Basic Infrastructure Components and Performance Bottlenecks
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础设施组件和性能瓶颈
- en: Don’t worry; we’re not going to make you sit through an exhaustive inventory
    of computer parts. Rather, we’ve put together a short list of the components,
    terminology, and concepts that you’re most likely to encounter in the course of
    your work. In relation to each of these, we’ve summarized the main performance
    challenges and the strategies that you might need to consider to use them effectively.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心；我们不会让你详细列举计算机部件清单。相反，我们已经整理了一个关于你工作中最有可能遇到的组件、术语和概念的简短列表。针对每一个这些，我们总结了主要的性能挑战以及你可能需要考虑的使用策略。
- en: Let’s begin with a brief overview of the types of processors that you might
    come across in scientific computing today.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从科学计算中可能遇到的处理器类型的简要概述开始。
- en: 'Types of Processor Hardware: CPU, GPU, TPU, FPGA, OMG'
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理器硬件类型：CPU、GPU、TPU、FPGA、OMG
- en: At its simplest, a *processor* is a component in your computer that performs
    computations. There are various types of processors, with the most common being
    the *central processing unit* (CPU) that serves as the main processor in general-use
    computers, including personal computers such as laptops. The CPU in your laptop
    may have multiple cores, subunits that can process operations more or less independently.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在其最简单的形式下，*处理器* 是计算机中执行计算的组件。有各种类型的处理器，其中最常见的是*中央处理单元*（CPU），它是一般用途计算机（包括笔记本电脑等个人电脑）的主要处理器。你笔记本电脑中的CPU可能有多个核心，可以更或多或少独立处理操作。
- en: In addition to a CPU, your personal computer also has a *graphical processing
    unit* (GPU) that processes the graphical information for display on your screen.
    GPUs came into the limelight with the development of modern video games, which
    require extremely fast processing to ensure smooth visual rendering of game action.
    In essence, the GPU solution outsources the rather specific type of processing
    involved in mathematical calculations like matrix and vector operations from the
    CPU to a secondary processing unit that specializes in handling certain types
    of calculations that are applied to graphical data very efficiently. As a result,
    GPUs are also becoming a popular option for certain types of scientific computing
    applications that involve a lot of matrix or vector operations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 除了CPU，你的个人电脑还有一个*图形处理单元*（GPU），用于处理屏幕上显示的图形信息。随着现代视频游戏的发展，GPU开始受到关注，这些游戏需要极快的处理速度，以确保游戏动作的流畅视觉呈现。从本质上讲，GPU解决方案将数学计算中涉及的矩阵和向量运算等特定类型的处理外包给了第二处理单元，后者专门处理某些类型的计算，这些计算对图形数据的应用非常高效。因此，GPU也成为某些涉及大量矩阵或向量运算的科学计算应用的热门选择。
- en: The third type of processor you should know about is called a *field-programmable
    gate array* (FPGA), which, despite breaking with the *PU naming convention, is
    also a type of processing unit; however, it’s unlikely that you’ll find one in
    your laptop. What’s interesting about FPGAs is that unlike GPUs, FPGAs were not
    developed for a specific type of application; quite the contrary, they were developed
    to be adaptable for custom types of computations. Hence “field-programmable” as
    part of their name.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该了解的第三种处理器类型称为*现场可编程门阵列*（FPGA），尽管与*PU命名惯例不同，但也是一种处理单元；然而，你不太可能在笔记本电脑中找到它。关于FPGA的有趣之处在于，与GPU不同，FPGA并非为特定类型的应用而开发；相反，它们被开发为适应定制类型的计算。因此，“现场可编程”是它们名称的一部分。
- en: On GCP, you might also come across something called a *tensor processing unit*
    (TPU), which is a kind of processor developed and branded by Google for machine
    learning applications that involve tensor data. A *tensor* is a mathematical concept
    used to represent and manipulate multiple layers of data related to vectors and
    matrices. Consider that a vector is a tensor with one dimension, and a matrix
    is a tensor with two dimensions; more generally, tensors can have arbitrary numbers
    of dimensions beyond that, so they are very popular in machine learning applications.
    TPUs belong to a category of processors called [application-specific integrated
    circuit](https://oreil.ly/bz4mv) (ASIC), which are custom designed for specialized
    uses rather than general use.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在GCP上，你可能还会遇到一种称为*张量处理单元*（TPU）的处理器，这是谷歌为涉及张量数据的机器学习应用开发和品牌化的一种处理器。*张量*是一个数学概念，用于表示和操作与向量和矩阵相关的多层数据。考虑到向量是一个具有一维的张量，矩阵是一个具有两维的张量；更一般地，张量可以具有超过这些维度的任意数量的维度，因此它们在机器学习应用中非常受欢迎。TPU属于一类称为[特定应用集成电路](https://oreil.ly/bz4mv)（ASIC）的处理器，这些处理器专为专用用途而设计，而不是通用用途。
- en: Now that you have the basic types of processors down, let’s talk about how they
    are organized in typical high-performance computing setups.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了基本类型的处理器，让我们来谈谈它们在典型高性能计算设置中是如何组织的。
- en: 'Levels of Compute Organization: Core, Node, Cluster, and Cloud'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算组织的层次：核心、节点、集群和云
- en: When you move beyond personal computers and into the world of high-performance
    computing, you’ll hear people talk about cores, nodes, and either clusters or
    clouds, as illustrated in [Figure 3-1](#levels_of_compute_organization). Let’s
    review what these mean and how they relate to one another.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当你超越个人电脑，进入高性能计算领域时，你会听到人们谈论核心、节点，以及集群或云，如[图3-1](#levels_of_compute_organization)所示。让我们来回顾一下它们的含义以及它们之间的关系。
- en: '![Levels of compute organization ](Images/gitc_0301.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![计算组织的层次](Images/gitc_0301.png)'
- en: Figure 3-1\. Levels of compute organization.
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1\. 计算组织的层次。
- en: 'Low level: core'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 低级别：核心
- en: 'A *core* is the smallest indivisible processing unit within a machine’s, or
    node’s, processor unit, which can comprise one or more cores. If your laptop or
    desktop is relatively recent, its CPU probably has at least two cores, and is
    therefore called *dual-core*. If it has four, it’s a *quad-core*, and so on. High-end
    consumer machines can have more than that; for example, the latest Mac Pro has
    a twelve-core CPU (which should be called dodeca-core if we follow the Latin terminology)
    but the CPUs on professional-grade machines can have tens or hundreds of cores,
    and GPUs typically have an order of magnitude more, into the thousands. Meanwhile,
    TPUs have core counts in the single digits like consumer CPUs, and FPGAs break
    the mold entirely: their cores are defined by how they are programmed, not by
    how they are built.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*核心*是机器或节点处理器单元内最小的不可分割处理单元，可以由一个或多个核心组成。如果你的笔记本电脑或台式电脑相对较新，它的CPU可能至少有两个核心，因此被称为*双核*。如果有四个核心，它就是*四核*，依此类推。高端消费者机器可以拥有更多核心；例如，最新的Mac
    Pro有一个十二核的CPU（如果我们遵循拉丁术语应称为十二核），而专业级机器上的CPU可以拥有数十个或数百个核心，而GPU通常有数千个核心。与此同时，TPU的核心数目与消费者CPU相似，而FPGA则完全打破了模式：它们的核心是根据它们的编程方式定义的，而不是根据它们的构建方式。
- en: 'Mid level: node/machine'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中层：节点/机器
- en: A *node* is really just a computer that is part of a cluster or cloud. It is
    analogous to the laptop or desktop computer that most of us interact with primarily
    in our day-to-day work, except without the dedicated monitor and peripherals we
    are used to seeing associated with personal computers. A node is also sometimes
    simply called a *machine*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*节点*实际上只是集群或云中的一台计算机。它类似于我们日常工作中主要与之交互的笔记本电脑或台式电脑，但没有我们通常与个人计算机关联的专用监视器和外设。一个节点有时也简单地称为*机器*。
- en: 'Top level: cluster and cloud'
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 顶层：集群和云
- en: A cluster and a cloud are both a collection of machines/nodes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 集群和云都是机器/节点的集合。
- en: A *cluster* is an HPC structure composed of nodes networked together to some
    extent. If you have access to a cluster, the chances are that either it belongs
    to your institution, or your company is renting time on it. A cluster can also
    be called a *server farm* or a *load-sharing facility*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*集群*是由节点部分网络连接在一起的HPC结构。如果你有权限访问一个集群，很可能是因为它属于你的机构，或者你的公司正在租用它。集群也可以称为*服务器农场*或*负载共享设施*。
- en: A *cloud* is different from a cluster in that in its resting state, its nodes
    are not explicitly networked together. Rather, it is a collection of independent
    machines that are available to be networked (or not) depending on your needs.
    We cover that in more detail in the final section of this chapter, along with
    the concept of virtualization, which gives us virtual machines (VMs), and containerization,
    which gives us Docker containers.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*云*与集群不同之处在于，在其休眠状态下，其节点不是显式地网络连接在一起的。相反，它是一组独立的机器，根据需要可以进行网络连接（或不连接）。我们将在本章的最后一节中更详细地讨论这一点，同时讨论虚拟化的概念，它为我们提供了虚拟机（VM）和容器化，它为我们提供了Docker容器。
- en: For now, however, we move on to the very common concern of how to use a given
    set of computing infrastructure effectively, which typically revolves around identifying
    and solving key computational bottlenecks. As with the rest of this chapter, an
    in-depth exploration of this topic would be beyond the scope of this book, so
    we’re aiming simply to familiarize you with the key concepts and terminology.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们转向如何有效使用给定的计算基础设施的非常普遍的问题，这通常涉及识别和解决关键的计算瓶颈。与本章的其余部分一样，深入探讨这个话题超出了本书的范围，所以我们的目标只是让你熟悉关键的概念和术语。
- en: Addressing Performance Bottlenecks
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决性能瓶颈
- en: You’ll occasionally find that some computing operations seem slow and you’ll
    need to figure out how to make them go faster (if possible). The solutions available
    to you will depend on the nature of the bottleneck you’re facing.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你会偶尔发现一些计算操作似乎很慢，需要找出如何让它们更快（如果可能的话）。可供选择的解决方案取决于你面对的瓶颈的性质。
- en: 'At a very high level, following are the main operations that the computer typically
    has to perform (not necessarily in a linear order):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在非常高的层次上，以下是计算机通常需要执行的主要操作（不一定是线性顺序）：
- en: Read some data into memory from the permanent storage where it resides at rest
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从永久存储中读取一些数据到内存中
- en: Have the processor execute instructions, transforming data and producing results
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让处理器执行指令，转换数据并生成结果
- en: Write results back to the permanent storage
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果写回永久存储
- en: 'Data storage and I/O operations: hard drive versus solid state'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据存储和I/O操作：硬盘与固态
- en: Steps 1 and 3 are called *I/O operations* (I/O stands for input/output). You
    might hear people describe some software programs as being “I/O-bound,” which
    means the part of the program that takes the longest is reading and writing data
    to and from relatively slow storage. This is typically the case for simple programs
    that do things like file format conversions, in which you’re just reading in some
    data and writing it out in a different shape, and you’re not doing any real computing
    (i.e., there’s little to no math involved). In those cases, you can speed up operation
    by using faster storage drives; for example, solid-state drives (SSDs) rather
    than hard-disk drives (HDDs). The key difference between them is that HDDs have
    physical disks called platters that spin and an armature that reads data from
    and writes it to the platter via magnetics—like a tiny high-tech turntable—whereas
    SSDs have no moving parts. That makes SSDs less prone to physical malfunctions
    and also quite a bit faster at accessing data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 第1步和第3步被称为*I/O操作*（I/O代表输入/输出）。您可能会听到一些人将某些软件程序描述为“I/O绑定”，这意味着程序中花费最长时间的部分是读取和写入数据到相对较慢的存储介质。这通常适用于执行简单任务的程序，比如文件格式转换，其中您只是读取一些数据并以不同的形式写出，而不进行任何真正的计算（即，几乎没有涉及数学）。在这些情况下，您可以通过使用更快的存储驱动器来加快操作速度；例如，固态驱动器（SSD）而不是硬盘驱动器（HDD）。它们之间的关键区别在于HDD具有称为盘片的物理磁盘和通过磁性从盘片读取数据并将数据写入盘片的臂，就像一个微型高科技唱片机一样，而SSD没有移动部件。这使得SSD不太容易发生物理故障，并且在访问数据时速度要快得多。
- en: If you’re working with a networked infrastructure in which the storage drives
    are not directly connected to the computing nodes, you will also be limited by
    the speed at which data can be transferred over the network connections. That
    can be determined by hardware factors as pedestrian as the kind of cables used
    to connect the network parts. Although you might not notice the difference when
    computing on small files, you definitely will notice it when running on whole
    genomes; and even on a network with very fast transfer speeds, transferring whole
    genomes will consume some noticeable time.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用网络基础架构，其中存储驱动器不直接连接到计算节点，您还将受到数据在网络连接上传输速度的限制。这可能由硬件因素决定，例如用于连接网络部件的电缆的种类。尽管在处理小文件时您可能不会注意到差异，但在运行整个基因组时，您肯定会注意到差异；即使在具有非常快传输速度的网络上，传输整个基因组也会消耗一些明显的时间。
- en: 'Memory: cache or crash'
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内存：缓存或崩溃
- en: Step 2 is where your program is taking data and applying some kind of transformation
    or calculation, aka the interesting part. For a lot of applications, the calculation
    requires holding a lot of information in memory. In those cases, if your machine
    doesn’t have enough memory, it might resort to *caching*, which is a way of using
    local storage space as a substitute for real memory. That allows you to keep working,
    but now your processes become I/O bound because they need to copy data back and
    forth to slow storage, which takes you back to the first bottleneck. In extreme
    cases, the program can stall indefinitely, fail to complete, or crash. Sometimes,
    it’s possible for a developer to rewrite the program to be smarter about the information
    it needs to see concurrently, but when it’s not, the solution is to simply add
    more memory. Fortunately, unlike memory in humans, computer memory is just hardware,
    and it comes relatively cheap.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是你的程序正在获取数据并应用某种转换或计算的地方，也就是有趣的部分。对于许多应用程序，计算需要在内存中保存大量信息。在这些情况下，如果您的计算机内存不足，它可能会诉诸于*缓存*，这是一种使用本地存储空间作为真实内存替代品的方式。这使您可以继续工作，但现在您的进程变得I/O绑定，因为它们需要在慢存储介质之间来回复制数据，这会让您回到第一个瓶颈。在极端情况下，程序可能会无限期地停滞、无法完成或崩溃。有时，开发人员可以重写程序，使其更加智能地处理同时需要查看的信息，但当无法做到这一点时，解决方案就是简单地增加更多内存。幸运的是，与人类的记忆不同，计算机内存只是硬件，而且相对便宜。
- en: 'Specialized hardware and code optimizations: navigating the trade-offs'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 专用硬件和代码优化：权衡导航
- en: At times, the nature of the program requires the processor itself to do a lot
    of heavy lifting. For example, in the widely used GATK tool `HaplotypeCaller`,
    an operation can calculate genotype likelihoods; we need to compute the likelihood
    of every single sequence read given each candidate allele using a hidden Markov
    model (HMM) called *PairHMM* (don’t worry if this sounds like gibberish at the
    moment—it’s just a bunch of genomics-specific math). In some areas of the genome,
    that leads us to do millions of computations per site across a very large number
    of sites. We know from performance profiling tests, which record how much time
    is spent in processing for each operation in the program, that PairHMM is by far
    the biggest bottleneck for this tool. We can reduce this bottleneck in some surface-level
    ways; for example, by making the program skip some of the computations for cases
    in which we can predict they will be unnecessary on uninformative. After all,
    the fastest way to calculate something is to not calculate it at all.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，程序的性质要求处理器本身进行大量的重活。例如，在广泛使用的 GATK 工具`HaplotypeCaller`中，一个操作可以计算基因型可能性；我们需要使用称为*PairHMM*的隐藏马尔可夫模型（HMM）来计算每个候选等位基因的每个序列读数的可能性（如果这一切听起来像无意义的话，请不要担心——这只是一堆基因组特定的数学）。在基因组的某些区域，这导致我们在非常多的位点上每个位点做数百万次计算。我们从性能分析测试中得知，这个工具中
    PairHMM 明显是最大的瓶颈。我们可以通过一些表面级的方法减少这个瓶颈；例如，通过使程序跳过一些预测它们在无信息情况下将不必要的计算。毕竟，计算某事物的最快方式是根本不计算它。
- en: Being lazy gets us only so far, however, so to get to the next level, we need
    to think about the kind of processor we can (or should) use for the work we need
    to do. Not just because some processors run faster than others, but also because
    it’s possible to write program instructions in a way that is very specific to
    a particular type and architecture of processor. If done well, the program will
    be extra efficient in that context and therefore run faster. That is what we call
    *code optimization*, and more specifically *native* code optimization because
    it must be written in a low-level language that the processor understands “natively”
    without going through additional translation layers.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 懒惰只能让我们走到这一步，因此，要达到下一个层次，我们需要考虑我们可以（或应该）为需要完成的工作使用的处理器类型。不仅因为某些处理器运行速度比其他处理器快，还因为可以以非常特定于特定类型和架构的处理器的方式编写程序指令。如果做得好，程序在这种环境中将更加高效，因此运行速度更快。这就是我们所说的*代码优化*，更具体地说是*本地*代码优化，因为它必须用处理器“本地”理解的低级语言编写，而无需经过额外的翻译层。
- en: Within a type of processor like CPUs, different manufacturers (e.g., Intel and
    AMD) develop different *architectures* for different generations of their products
    (e.g., Intel Skylake and Haswell), and these different architectures provide opportunities
    for optimizing the software. For example, the GATK package includes several code
    modules corresponding to alternative implementations of the PairHMM algorithm
    that are optimized for specific Intel processor architectures. The program automatically
    activates the most appropriate version when it finds itself running on Intel processors,
    which provides some useful speed gains.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在像 CPU 这样的处理器类型内部，不同的制造商（例如 Intel 和 AMD）为其产品的不同世代（例如 Intel Skylake 和 Haswell）开发了不同的*架构*，这些不同的架构提供了优化软件的机会。例如，GATK
    软件包包括了几个对应于特定 Intel 处理器架构优化的 PairHMM 算法的替代实现的代码模块。当程序在 Intel 处理器上运行时，它会自动激活最合适的版本，这提供了一些有用的速度增益。
- en: However, the benefits of hardware optimizations are most obvious across processor
    types; for example, if you compare how certain algorithms perform when implemented
    to run on FPGAs instead of CPUs. The Illumina DRAGEN toolkit (originally developed
    by Edico Genome) includes implementations of tools like `HaplotypeCaller` that
    are optimized to run on FPGAs and as a result are much faster than the original
    Java software version.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，硬件优化的好处在于处理器类型之间最为明显；例如，如果将某些算法的实现方式与在 FPGA 上运行相比较而实现的情况。Illumina DRAGEN
    工具包（最初由 Edico Genome 开发）包括了像`HaplotypeCaller`这样的工具的实现，这些工具经过了优化，可以在 FPGA 上运行，因此比原始的
    Java 软件版本快得多。
- en: The downside of hardware-optimized implementations is that by definition, they
    require specialized hardware. This can be a big problem for the many research
    labs that rely on shared institutional computing systems and don’t have access
    to other hardware. In contrast, applications written in Java, like GATK, can run
    on a wide range of hardware architectures because the Java Virtual Machine (JVM)
    translates the application code (called *bytecode* in the Java world) into instructions
    appropriate for the machine. This *separation of concerns* (SoC) between the bytecode
    of Java and what actually is executed on the machine is called an *abstraction
    layer* and it’s incredibly convenient for everyone involved. Developers don’t
    need to worry about exactly what kind of processor we have in our laptops, and
    we don’t need to worry about what kind of processor they had in mind when they
    wrote the code. It also guarantees that the software can be readily deployed on
    standard off-the-shelf hardware, which makes it usable by anyone in the world.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件优化实现的缺点在于，按定义需要专门的硬件。对于依赖于共享机构计算系统并且无法获得其他硬件的许多研究实验室来说，这可能是一个大问题。相比之下，像GATK这样用Java编写的应用程序可以运行在广泛的硬件架构上，因为Java虚拟机（JVM）将应用程序代码（在Java世界中称为*字节码*）转换为适合该机器的指令。Java字节码与实际在机器上执行的内容之间的这种*关注分离*（SoC）称为*抽象层*，对所有参与者来说都非常方便。开发人员无需担心我们的笔记本电脑上具体的处理器型号，我们也不需要担心他们编写代码时考虑的处理器类型。这还保证软件可以轻松部署在标准的现成硬件上，使其可以被世界上任何人使用。
- en: Sometimes, you’ll need to choose between different implementations of the same
    algorithms depending on what is most important to you, including how much you
    prize speed over portability and interoperability. Other times, you’ll be able
    to enjoy the best of both worlds. For example, the GATK team at the Broad Institute
    has entered into a collaboration with the DRAGEN team at Illumina, and the two
    teams are now working together to produce unified DRAGEN-GATK pipelines that will
    be available both as a free open source version (via Broad) and as a licensed
    hardware-accelerated version (via Illumina). A key goal of the collaboration is
    to make the two implementations functionally equivalent—meaning that you could
    run either version and get the same results within a margin of error considered
    to be insignificant. This will benefit the research community immensely in that
    it will be possible to combine samples analyzed by either pipeline into downstream
    analyses without having to worry about batch effects, which we discussed briefly
    in the previous chapter.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你需要根据你最看重的因素（包括速度、可移植性和互操作性）在同一算法的不同实现之间进行选择。其他时候，你可以同时兼得。例如，Broad Institute
    的GATK团队已与Illumina的DRAGEN团队展开合作，两个团队正在共同努力制定统一的DRAGEN-GATK流水线，这将作为免费开源版本（通过Broad提供）和经许可的硬件加速版本（通过Illumina提供）提供。合作的一个关键目标是使两种实现在功能上等效——这意味着你可以运行任何版本，并在被认为是微不足道的误差范围内获得相同的结果。这将极大地使研究社区受益，因为可以将任一流水线分析的样本组合到下游分析中，而不必担心批次效应，我们在前一章节中简要讨论过的问题。
- en: Parallel Computing
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行计算
- en: When you can’t go faster, go parallel. In the context of computing, *parallel
    computing*, or *parallelism*, is a way to make a program finish sooner by performing
    several operations in parallel rather than sequentially (i.e., waiting for each
    operation to finish before starting the next one). Imagine that you need to cook
    rice for 64 people, but your rice cooker can make enough rice for only 4 people
    at a time. If you need to cook all of the batches of rice sequentially, it’s going
    to take all night. But if you have eight rice cookers that you can use in parallel,
    you can finish up to eight times sooner.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当你不能更快时，就采用并行。在计算的背景下，*并行计算*或*并行性*是通过同时执行多个操作而不是顺序执行（即等待每个操作完成再开始下一个）来使程序尽快完成的一种方法。想象一下，你需要为64个人煮米饭，但你的电饭煲一次只能做够4个人吃的量。如果你需要依次煮所有批次的米饭，那将会花费整整一晚上。但如果你有八台电饭煲可以并行使用，你可以提前完成多达八倍的速度。
- en: 'This is a simple idea but it has a key requirement: you must be able to break
    the job into smaller tasks that can be performed independently. It’s easy enough
    to divide portions of rice because rice itself is a collection of discrete units.
    But you can’t always make that kind of division: for example, it takes one pregnant
    woman nine months to grow a baby, but you can’t do it in one month by having nine
    women share the work.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的想法，但它有一个关键要求：你必须能够将工作分解为可以独立执行的较小任务。将米饭分成部分很容易，因为米饭本身是一个离散单位的集合。但你并不总能做到这种分割：例如，一位孕妇需要九个月来孕育一个婴儿，但你不能让九个女人每人负责一个月来加快这个过程。
- en: The good news is that most genomic analyses are more like rice than like babies—they
    essentially consist of a series of many small independent operations that can
    be parallelized. So how do we get from cooking rice to executing programs?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，大多数基因组分析更像是处理米饭而不是生婴儿——它们实际上由许多小独立操作序列组成，可以并行化。那么我们如何从煮米饭过渡到执行程序呢？
- en: Parallelizing a Simple Analysis
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行化简单分析
- en: 'Consider that when you run an analysis program, you’re just telling the computer
    to execute a set of instructions.  Suppose that we have a text file and we want
    to count the number of lines in it. The set of instructions to do this can be
    as simple as this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到当您运行分析程序时，您只是告诉计算机执行一组指令。假设我们有一个文本文件，并且我们想计算其中的行数。执行此操作的指令可以简单如下：
- en: Open the file; count the number of lines in it; tell us the number; close the
    file.
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 打开文件；计算文件中的行数；告诉我们数量；关闭文件。
- en: Note that “tell us the number” can mean writing it to the console or storing
    it somewhere for use later on—let’s not worry about that right now.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，“告诉我们数量”可以意味着将其写入控制台或存储在某处以供以后使用——现在我们不要担心这个问题。
- en: 'Now suppose that we want to know the number of words on each line. The set
    of instructions would be as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们想知道每行的单词数。指令集如下：
- en: Open the file; read the first line; count the number of words; tell us the number;
    read the second line; count the number of words; tell us the number; read the
    third line; count the number of words; tell us the number.
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 打开文件；读取第一行；计算单词数；告诉我们数量；读取第二行；计算单词数；告诉我们数量；读取第三行；计算单词数；告诉我们数量。
- en: 'And so on until we’ve read all the lines, and then finally we can close the
    file. It’s pretty straightforward, but if our file has a lot of lines, it will
    take a long time, and it will probably not use all the computing power we have
    available. So, to parallelize this program and save time, we just cut up this
    set of instructions into separate subsets, like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一直这样做直到我们读取了所有行，最后我们可以关闭文件。这很简单直接，但是如果我们的文件有很多行，将会花费很长时间，而且可能不会充分利用我们可用的所有计算能力。因此，为了并行化这个程序并节省时间，我们只需将这组指令分割成独立的子集，就像这样：
- en: Open the file; index the lines.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打开文件；索引行。
- en: Read the first line; count the number of words; tell us the number.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取第一行；计算单词数；告诉我们数量。
- en: Read the second line; count the number of words; tell us the number.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取第二行；计算单词数；告诉我们数量。
- en: Read the third line; count the number of words; tell us the number.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取第三行；计算单词数；告诉我们数量。
- en: '[Repeat for all lines.]'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[对所有行重复。]'
- en: Collect final results and close the file.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集最终结果并关闭文件。
- en: Here, the “read the *N*th line” steps can be performed in parallel because they
    are all independent operations.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，“读取第 *N* 行”的步骤可以并行执行，因为它们都是独立的操作。
- en: You’ll notice that we added a step, “index the lines.” That’s a little bit of
    preliminary work that allows us to perform the “read the *N*th line” steps in
    parallel (or in any order we want) because it tells us how many lines there are
    and, importantly, where to find each one within the file. It makes the entire
    process much more efficient. As you will see in the following chapters, tools
    like GATK require index files for the main data files (reference genome, read
    data and variant calls). The reason is to have that indexing step already done
    so that we can have the program look up specific chunks of data by their position
    in the genome.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到我们增加了一个步骤：“索引行”。这是一点预备工作，使我们能够并行执行“读取第 *N* 行”的步骤（或按任意顺序执行），因为它告诉我们有多少行以及每一行在文件中的位置。这使整个过程更加高效。正如您将在以下章节中看到的，像GATK这样的工具需要主数据文件（参考基因组、读取数据和变体调用）的索引文件。原因在于已经完成索引步骤，以便我们可以让程序通过它们在基因组中的位置查找特定数据块。
- en: 'Anyway, that’s the general principle: you transform your linear set of instructions
    into several subsets of instructions. There’s usually one subset that has to be
    run first and one that has to be run last, but all the subsets in the middle can
    be run at the same time (in parallel) or in whatever order you want.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，这是一个一般的原则：你将你的线性指令集转化为若干子指令集。通常有一个子集需要首先运行，一个需要最后运行，但所有中间的子集可以同时（并行）运行，或者按照你想要的任何顺序运行。
- en: 'From Cores to Clusters and Clouds: Many Levels of Parallelism'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从核心到集群和云：多层次并行性
- en: So how do we go from rice cookers to parallelizing the execution of a genomic
    analysis program? Overall, the action of parallelizing computing operations consists
    of sending subsets of the work we want done to multiple cores for processing.
    We can do that by splitting up the work across the cores of a single multicore
    machine, or we can dispatch work to other machines if we have access to a cluster
    or cloud. In fact, we can combine the two ideas and dispatch work to multicore
    machines, in which the work is further split up among each machine’s cores. Going
    back to the rice-cooking example, it’s as if instead of cooking the rice yourself,
    you hired a catering company to do it for you. The company assigns the work to
    several people, who each have their own cooking station with multiple rice cookers.
    Now, you can feed a lot more people in the same amount of time! And you don’t
    even need to clean the dishes.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何从电饭锅到并行化执行基因组分析程序？总体而言，并行化计算操作的行动包括将我们想要完成的工作的子集发送到多个核心进行处理。我们可以通过将工作分配到单个多核机器的核心之间分割工作，或者如果我们可以访问集群或云，则可以将工作分发到其他机器。事实上，我们可以结合这两个想法，并将工作分派给多核机器，在这些机器的每个核心中进一步分割工作。回到煮饭的例子，这就好像不是自己做饭，而是雇用一个餐饮公司为您做饭。公司把工作分配给几个人，每个人都有自己的烹饪站，有多个电饭锅。现在，您可以在同样的时间内喂更多的人！而且您甚至不需要洗碗。
- en: 'Whether we want to distribute the work across multiple cores on a single machine
    or across multiple machines, we’re going to need a system that splits up the work,
    dispatches jobs for execution, monitors them for completion, and then compiles
    the results. Several kinds of systems can do that, falling broadly into two categories:
    internal or external to the analysis program itself. In the first case, the parallelization
    happens “inside” the program that we’re running: we run that program’s command
    line, and the parallelization happens without any additional “wrapping” on our
    part. We call that *multithreading*. In the second case, we need to use a separate
    program to run multiple instances of the program’s command line. An example of
    an external parallelization is writing a script that runs a given tool separately
    on the data from each chromosome in a genome and then combines the result with
    an additional merge step. We call that approach *scatter-gather*. We cover that
    in more detail in the next section when we introduce workflow management systems.
    In [Figure 3-2](#scatter_gather_allows_parallel_executio), you can see how we
    can use multithreading and scatter-gather parallelism in the course of an analysis.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们想要将工作分配到单台机器的多个核心上，还是跨多台机器分配工作，我们都需要一个系统来分割工作，分派执行任务，监控任务完成情况，然后编译结果。有几种系统可以做到这一点，大致分为两类：内部或外部于分析程序本身。在第一种情况下，并行化发生在我们运行的程序“内部”：我们运行该程序的命令行，而并行化无需我们额外的“包装”。我们称之为*多线程*。在第二种情况下，我们需要使用一个单独的程序来运行该程序的多个实例的命令行。外部并行化的一个例子是编写一个脚本，分别在基因组中的每条染色体上运行给定工具，然后通过额外的合并步骤组合结果。我们称之为*散集-收集*。在下一节介绍工作流管理系统时，我们将更详细地讨论这一点。在[图3-2](#scatter_gather_allows_parallel_executio)中，您可以看到我们如何在分析过程中使用多线程和散集并行性。
- en: '![Scatter-gather allows parallel execution of tasks on different CPU cores
    (on a single machine or multiple machines depending on how it’s implemented).](Images/gitc_0302.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![散集允许在不同的CPU核心上并行执行任务（在单台机器或多台机器上，具体取决于实现方式）。](Images/gitc_0302.png)'
- en: Figure 3-2\. Scatter-gather allows parallel execution of tasks on different
    CPU cores (on a single machine or multiple machines, depending on how it’s implemented).
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2\. 散集允许在不同的CPU核心上并行执行任务（在单台机器或多台机器上，具体取决于实现方式）。
- en: 'Trade-Offs of Parallelism: Speed, Efficiency, and Cost'
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行性的权衡：速度、效率和成本
- en: Parallelism is a great way to speed up processing on large amounts of data,
    but it has overhead costs. Without getting too technical at this point, let’s
    just say that parallelized jobs need to be managed, you need to set aside memory
    for them, regulate file access, collect results, and so on. So it’s important
    to balance the costs against the benefits, and avoid dividing the overall work
    into too many small jobs. Going back to our earlier example, you wouldn’t want
    to use a thousand tiny rice cookers that each boil a single grain of rice. They
    would take far too much space on your countertop, and the time required to distribute
    each grain and then collect it when it’s cooked would more than negate any benefits
    from parallelizing in the first place.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化是加速大量数据处理的一个很好的方法，但它有额外的开销。在这一点上不要过于技术化，我们只需说并行化的作业需要被管理，需要为它们保留内存，调节文件访问，收集结果等等。因此，平衡成本与收益非常重要，并避免将整体工作分解为过多的小作业。回到我们之前的例子，你不会想使用一千个只煮一粒米的小型电饭煲。它们会占用你台面上太多的空间，而且分发每一粒米并在煮好后收集它所需的时间将使并行化的任何好处都荡然无存。
- en: More generally, although it’s tempting to think of parallelism as a way to make
    things go faster, it’s important to remember that the impression of speed is entirely
    subjective to the observer. In reality, the computation being run on each piece
    of data is not going any faster. We’re just running more computations at the same
    time, and we’re limited by the parallel capacity of our computing setup (typically
    measured in number of nodes or cores) as well as hardware limitations like I/O
    and network speeds. It’s more realistic to think of parallelism as a way to optimize
    available resources in order to finish tasks *sooner*, rather than making individual
    tasks run *faster*.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地说，虽然把并行视为加快速度的一种方式很诱人，但重要的是要记住，速度的印象完全取决于观察者的主观感受。实际上，每个数据片段上运行的计算并没有变得更快。我们只是同时运行更多计算，并且受到我们计算设置的并行能力（通常以节点或核心数来衡量）以及像I/O和网络速度这样的硬件限制的限制。更现实的是，把并行视为一种优化可用资源的方式，以便更快地完成任务，而不是让单个任务运行得更*快*。
- en: This distinction might seem pedantic given that, from the point of view of the
    human at the keyboard, the elapsed time (often called *wall-clock time*; that
    is, “the time shown by the clock on the wall”) is shorter. And isn’t that what
    we all understand as going faster? However, from the point of view of the resources
    we utilize, if we add up the time spent doing computation by the processor across
    all the cores we use, we might find that the overall job takes *more* time to
    complete compared to purely sequential execution because of the overhead costs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这种区分在键盘前的人来看，这种区分可能显得很迂腐，因为经过的时间（通常称为*挂钟时间*；即“墙上时钟显示的时间”）较短。这不就是我们所理解的“更快”的方式吗？但是，从我们利用的资源的角度来看，如果我们将所有核心的计算时间相加，我们可能会发现整个作业花费的时间*更多*，因为有额外的开销。
- en: 'That brings us to another important question: what is the monetary cost of
    utilizing those resources? If we’re working with a dedicated machine that is just
    sitting there with multiple cores and nothing else to do, the parallelization
    is still absolutely worth it, even with the overhead. We’ll want to parallelize
    the heck out of everything we do on that machine in order to maximize efficiency.
    However, when we start working in the cloud environment, as we do in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud),
    and we need to start paying for itemized resources as we go, we’ll want to look
    more carefully at the trade-offs between minimizing wall-clock time and the size
    of the bill.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这带来了另一个重要问题：利用这些资源的经济成本是多少？如果我们使用的是专用机器，这台机器只是坐在那里，有多个核心，而没有其他事情可做，那么并行化仍然绝对值得，即使有额外的开销。我们将希望在这台机器上对我们做的每一件事情进行大量并行化，以最大化效率。然而，当我们开始在云环境中工作，正如我们在[第四章](ch04.xhtml#first_steps_in_the_cloud)中所做的那样，并且我们需要按照使用的资源来付费时，我们将更仔细地考虑最小化挂钟时间和账单大小之间的权衡。
- en: Pipelining for Parallelization and Automation
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行化用于并行化和自动化流水线
- en: Many genomic analyses involve running a lot of routine data-processing operations
    that need to be parallelized for efficiency and automated to reduce human error.
    We do this by describing the workflow in a machine-readable language, which we
    then can feed into a workflow management system for execution. We go over how
    this works in practice in [Chapter 8](ch08.xhtml#automating_analysis_execution_with_work),
    but first let’s set the stage by introducing basic concepts, definitions, and
    key software components. As we go, please keep in mind that this field currently
    has no such thing as a one-size-fits-all solution, and it’s ultimately up to you
    to review your needs and available options before picking a particular option.
    However, we can identify general principles to guide your selection, and we demonstrate
    these principles in action using the open source pipelining solution that is recommended
    by the GATK development team and used in production at the Broad Institute. As
    with most of this book, the goal here is not to prescribe the use of specific
    software, but to show through working examples how all of this fits together in
    practice.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 许多基因组分析涉及大量例行数据处理操作，需要并行化以提高效率，并自动化以减少人为错误。我们通过描述可由机器读取的工作流程来实现这一点，然后将其馈送到工作流程管理系统进行执行。我们将在[第8章](ch08.xhtml#automating_analysis_execution_with_work)中详细讨论其实际运作，但首先让我们通过介绍基本概念、定义和关键软件组件来为此做好准备。在我们进行时，请记住，当前领域并不存在一种适合所有情况的解决方案，最终选择特定选项取决于您审查需求和可用选项。然而，我们可以确定一般原则来指导您的选择，并展示这些原则在实际中如何运作，使用由GATK开发团队推荐并在Broad
    Institute生产中使用的开源流水线解决方案进行演示。与本书的大部分内容一样，这里的目标不是指定使用特定软件，而是通过工作示例展示所有这些如何实际运作。
- en: One tricky aspect is that we have dozens of scripting languages and workflow
    management systems to choose from in the bioinformatics world—likely hundreds
    if you look at a wider range of fields. It can be difficult to compare them directly
    because they tend to be developed with a particular type of audience in mind,
    leading to very different modalities of user experience. They are often tuned
    for particular use cases and are sometimes optimized to operate on certain classes
    of infrastructure. We often see one solution that is preferred by one group prove
    to be particularly difficult or frustrating to use for another. These various
    solutions are also generally not interoperable, meaning that you can’t take a
    workflow script written for one workflow management system and run it unmodified
    on the next one over. This lack of standardization is a topic of both humor and
    desperation in just about every field of research known to humankind, as is illustrated
    in [Figure 3-3](#xkcd_comic_on_the_proliferation_of_stan).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一个棘手的问题是，在生物信息学领域，我们有数十种脚本语言和工作流程管理系统可供选择——如果您看更广泛的领域，可能会有数百种。直接比较它们可能会很困难，因为它们往往是为特定类型的用户群体开发的，导致用户体验的模式非常不同。它们通常针对特定用例进行调优，有时还优化以在特定类别的基础设施上运行。我们经常看到一个解决方案对一个群体而言是首选的，但对另一个群体使用起来可能特别困难或令人沮丧。这些不同的解决方案通常也不具备互操作性，这意味着您不能将为一个工作流程管理系统编写的工作流脚本未经修改地运行在另一个系统上。这种缺乏标准化是人类已知的几乎每个研究领域的一个幽默和绝望的话题，正如在[图3-3](#xkcd_comic_on_the_proliferation_of_stan)中所说明的那样。
- en: '![XKCD comic on the proliferation of standards.](Images/gitc_0303.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![XKCD漫画，讨论标准的扩散。](Images/gitc_0303.png)'
- en: 'Figure 3-3\. XKCD comic on the proliferation of standards (source: https://xkcd.com/927).'
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-3\. XKCD漫画，讨论标准的扩散（来源：https://xkcd.com/927）。
- en: In recent years, we have seen some high-profile initiatives such as the Global
    Alliance GA4GH emerge with the explicit mission of developing common standards
    and consolidating efforts around a subset of solutions that have interoperability
    as a core value. For example, the GA4GH Cloud Work Stream has converged on a small
    set of workflow languages for its driver projects, including CWL, Nextflow, and
    WDL, which we use in this book. At the same time, given the recognition that no
    single language is likely to satisfy all needs and preferences, several groups
    are working to increase interoperability by building support for multiple workflow
    languages into their workflow management systems. The workflow management system
    we use in this book, Cromwell, supports both WDL and CWL, and it could be extended
    to support additional languages in the future.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，我们看到一些备受关注的倡议，如全球联盟GA4GH的出现，明确任务是制定共同标准并围绕一组具有互操作性作为核心价值的解决方案进行整合。例如，GA4GH云工作组已经就其驱动项目的一小组工作流语言达成一致，包括CWL、Nextflow和WDL，这些语言在本书中使用。同时，鉴于没有单一语言可能满足所有需求和偏好的认识，一些团体正在努力通过将对多种工作流语言的支持集成到其工作流管理系统中来增加互操作性。本书中使用的工作流管理系统Cromwell支持WDL和CWL，未来还可以扩展支持其他语言。
- en: Workflow Languages
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作流语言
- en: In principle, we could write our workflows in almost any programming language
    we like; but in practice, some are more amenable than others for describing workflows.
    Just like natural languages, programming languages also exhibit a fascinating
    diversity and can be classified in various ways including grammar, mode of execution,
    and the programming paradigms that they support.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，我们可以用几乎任何编程语言编写我们的工作流；但实际上，有些编程语言比其他语言更适合描述工作流。就像自然语言一样，编程语言也展现出令人着迷的多样性，并且可以按照语法、执行方式以及支持的编程范式等方式进行分类。
- en: From a practical standpoint, we begin by making a distinction between all-purpose
    programming languages, which are intended to be usable for a wide range of applications,
    and domain-specific languages (DSLs) that are, as the name indicates, specifically
    designed for a particular domain or activity. The latter are typically preloaded
    with things like specially formulated data structures (i.e., ways to represent
    and manipulate data that “understand” the nature of the underlying information)
    and convenience functions that act as shortcuts; for example, handling domain-specific
    file formats, applying common processing actions, and so on. As a result, a DSL
    can be an attractive option if your needs fit well within the intended scope of
    the language, especially if your computational background is limited, given that
    the DSL typically enables you to get your work done without having to learn a
    lot of programming concepts and syntax.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际角度出发，我们首先要区分通用编程语言和领域特定语言（DSLs）。通用编程语言旨在可用于各种应用程序，而DSLs则是专门为特定领域或活动设计的，正如其名称所示。后者通常预装有特别制定的数据结构（即表示和操作数据的方式，“理解”底层信息的性质）和方便函数，作为快捷方式；例如，处理特定领域的文件格式，应用常见处理操作等。因此，如果您的需求与语言的预期范围非常匹配，尤其是在计算背景有限的情况下，DSL可能是一个吸引人的选择，因为DSL通常使您能够在不必学习大量编程概念和语法的情况下完成工作。
- en: On the other hand, if your needs are more varied or you are used to having the
    more expansive toolbox of a general-purpose language at your disposal, you might
    find yourself uncomfortably constrained by the DSL. In that case, you might prefer
    to use a general-purpose language, especially one enriched with domain-specific
    libraries that provide relevant data structures and convenience functions (e.g.,
    Python with Biopython and related libraries). In fact, using a general-purpose
    language is more likely to enable you to use the same language for writing the
    data-processing tasks themselves and for managing the flow of operations, which
    is how many have traditionally done this kind of work. What we’re seeing now in
    the field, however, is a move toward separation of description and content, which
    manifests as increased adoption of DSLs specifically designed to describe workflows
    as well as of specialized workflow management systems. This evolution is strongly
    associated with the push for interoperability and portability.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果您的需求更加多样化，或者您习惯于使用通用语言的更广泛工具箱，那么您可能会感到领域特定语言的限制让您感到不适。在这种情况下，您可能更喜欢使用通用语言，尤其是那些丰富了领域特定库的通用语言，提供相关的数据结构和便利功能（例如，带有Biopython和相关库的Python）。事实上，使用通用语言更有可能使您能够使用相同的语言编写数据处理任务本身，并管理操作流程，这正是许多人传统上进行此类工作的方式。然而，我们现在在这个领域看到的趋势是，一种向描述和内容分离的趋势，这体现为特别设计用于描述工作流程以及专门的工作流管理系统的DSL的增加采用。这种进化与推动互操作性和可移植性的努力密切相关。
- en: Popular Pipelining Languages for Genomics
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流行的基因组学流水线语言
- en: 'When we look at the cross-section of people who find themselves at the intersection
    of bioinformatics and genomics, we see a wide range of backgrounds, computational
    experience, and needs. Some come from a software engineering background and prefer
    languages that are full featured and highly structured, offering great power at
    the cost of accessibility. Some come from systems administration and believe every
    problem can be solved with judicious application of Bash, sed, and awk, the duct
    tape of the Unix-verse. On the “bio” side of the fence, the more computationally
    trained tend to feel most at home with analyst favorites like Python and R, which
    have been gaining ground over old-time classics Perl and MATLAB; some also tend
    to gravitate toward DSLs. Meanwhile wetlab-trained researchers might find themselves
    baffled by all of this, on initial contact at least. (Author’s note and disclaimer:
    Geraldine identifies as one of the initially baffled, having trained as a traditional
    microbiologist and eventually learned the rudiments of Perl and Python in a desperate
    bid to escape the wetlab workbench. Spoiler: it worked!)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们看到那些位于生物信息学和基因组学交汇点的人群时，我们看到了各种背景、计算经验和需求的广泛范围。有些人来自软件工程背景，更喜欢功能齐全、高度结构化的语言，虽然强大但可访问性较差。有些人来自系统管理领域，认为一切问题都可以通过巧妙应用Bash、sed和awk来解决，这些在Unix世界中像胶带一样。在“生物”这一边，更多计算训练有素的人通常最喜欢分析师钟爱的Python和R，这两者在逐渐取代老牌经典Perl和MATLAB；一些人还倾向于领域特定语言。与此同时，湿实验室训练的研究人员可能在初次接触时对所有这些感到困惑。（作者注及免责声明：杰拉尔丁自认为最初感到困惑之一，曾接受传统微生物学训练，并最终在逃离湿实验室工作台时学习了Perl和Python的基础知识。剧透：这行得通了！）
- en: Based on recent polling, some of the languages that are most popular with workflow
    authors in the genomics space are SnakeMake and Nextflow. Both are noted for their
    high degree of flexibility and ease of use. Likewise, CWL and WDL are picking
    up steam because of their focus on portability and computational reproducibility.
    Of the two, CWL is more frequently preferred by people who have a technical background
    and enjoy its high level of abstraction and expressiveness. In contrast, WDL is
    generally considered to be more accessible to a wide audience.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 根据最近的调查，基因组学空间中最受工作流程作者欢迎的语言包括SnakeMake和Nextflow。这两者以其高度灵活性和易用性而闻名。同样，CWL和WDL也因其专注于可移植性和计算再现性而受到青睐。在这两者中，CWL更常被技术背景的人士偏爱，因为它具有高度的抽象和表现力。相反，WDL一般认为更易于广泛受众接受。
- en: 'At the end of the day, when it comes to picking a workflow language, we look
    at four main criteria: what kind of data structures the language supports (i.e.,
    how we can represent and pass around information), how it enables us to control
    the flow of operations, how accessible it is to read and write for the intended
    audience, and how it affects our ability to collaborate with others. Whatever
    we choose, it’s unlikely that we can satisfy everyone’s requirements. However,
    if we were to boil all this down to just one recommendation, it would be this:
    if you want your workflow scripts to be widely used and understood in your area
    of research, pick a language that is open and accessible enough to newcomers yet
    scales well enough to the ambitions of the more advanced. And, of course, try
    to pick a language that you can run across different workflow management systems
    and computing platforms, because you never know what environment you or your collaborators
    might find yourselves in next.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，在选择工作流语言时，我们考虑了四个主要标准：语言支持的数据结构类型（即我们如何表示和传递信息），它如何使我们控制操作流程，它对目标读写者的可读性和可写性如何，以及它如何影响我们与他人协作的能力。无论我们选择什么，都不太可能满足每个人的需求。然而，如果我们把所有这些总结成一个建议，那就是：如果你希望你的工作流脚本在你的研究领域被广泛使用和理解，选择一种对新手开放和易于理解，同时又能够满足更高级需求的语言。当然，尽量选择一种能够在不同的工作流管理系统和计算平台上运行的语言，因为你永远不知道你或你的合作者下一步会进入什么环境。
- en: Workflow Management Systems
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作流管理系统
- en: Many workflow management systems exist, but in general they follow the same
    basic pattern. First, the workflow engine reads and interprets the instructions
    laid out in the workflow script, translating the instruction calls into executable
    jobs that are associated with a list of inputs (including data and parameters).
    It then sends out each job with its list of inputs to another program, generally
    called a *job scheduler*, that is responsible for orchestrating the actual execution
    of the work on the designated computing environment. Finally, it retrieves any
    outputs produced when the job is done. Most workflow management systems have some
    built-in logic for controlling the flow of execution; that is, the order in which
    they dispatch jobs for execution and for determining how they deal with errors
    and communicate with the compute infrastructure.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 许多工作流管理系统存在，但总体上它们遵循相同的基本模式。首先，工作流引擎读取并解释工作流脚本中的指令，将指令调用转换为与一系列输入相关联的可执行作业（包括数据和参数）。然后，它将每个带有其输入列表的作业发送给另一个程序，通常称为*作业调度程序*，负责在指定的计算环境上编排实际工作的执行。最后，在作业完成时，它检索生成的任何输出。大多数工作流管理系统都具有一些用于控制执行流程的内置逻辑；即它们调度作业的顺序以及确定它们如何处理错误并与计算基础设施通信。
- en: Another important advance for increasing portability and interoperability of
    analyses is the adoption of container technology, which we cover in detail in
    the last section of this chapter. For now, assume that a container is a mechanism
    that allows you to encapsulate all software requirements for a particular task,
    from the deepest levels of the operating system (OS) all the way to library imports,
    environment variables, and accessory configuration files.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 增加分析的可移植性和互操作性的另一个重要进步是容器技术的采用，我们在本章的最后一节中详细介绍。现在，可以假设容器是一种机制，允许您封装特定任务的所有软件要求，从操作系统（OS）的最深层次到库导入、环境变量和辅助配置文件。
- en: Virtualization and the Cloud
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚拟化与云
- en: Up to this point, we have been assuming that whether you’re working with a single
    computer or a cluster, you’re dealing with “real” physical machines that are each
    set up with a given OS and software stack, as represented in [Figure 3-4](#representation_of_aright_parenthesis_th)
    A. Unfortunately, interacting with that kind of system has several disadvantages,
    especially in a shared environment like an institutional cluster. As an end user,
    you typically don’t have a choice regarding the OS, environment, and installed
    software packages. If you need to use something that isn’t available, you can
    ask an administrator to install it, but they might decline your request or the
    package you want might not be compatible with existing software. For the system
    administrators on the other side of the helpdesk, it can be a headache to keep
    track of what users want, manage versions, and deal with compatibility issues.
    Such systems take effort to update and scale.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直假设，无论您是在单台计算机上还是在集群上工作，您都在处理“真实”的物理机器，每台机器都设置有特定的操作系统和软件堆栈，如[图 3-4](#representation_of_aright_parenthesis_th)
    A所示。不幸的是，与这种类型的系统交互有几个缺点，特别是在像机构集群这样的共享环境中。作为终端用户，您通常没有选择关于操作系统、环境和已安装的软件包。如果您需要使用一些当前不可用的东西，您可以请求管理员安装它，但他们可能会拒绝您的请求或您想要的软件包可能与现有软件不兼容。对于位于帮助台另一侧的系统管理员来说，跟踪用户需求、管理版本并处理兼容性问题可能是一件头疼的事情。这些系统需要努力进行更新和扩展。
- en: That is why most modern systems use various degrees of *virtualization*, which
    is basically a clever bit of abstraction that makes it possible to run multiple
    different software configurations on top of the same hardware through virtual
    machines (VMs) and containers as represented in [Figure 3-4](#representation_of_aright_parenthesis_th)
    B and C respectively. These constructs can be utilized in many contexts, including
    optionally on local systems (you can even use containers on your laptop!), but
    they are absolutely essential for cloud infrastructure.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么大多数现代系统使用不同程度的*虚拟化*，这基本上是一种巧妙的抽象，通过虚拟机（VM）和容器使得在同一硬件上运行多个不同的软件配置成为可能，如[图 3-4](#representation_of_aright_parenthesis_th)
    B和C所示。这些构造可以在许多情境下使用，包括在本地系统上选择性地（你甚至可以在笔记本电脑上使用容器！），但它们对于云基础设施来说绝对是必不可少的。
- en: '![Representation of A) The software stack installed on a physical machine;
    B) a server providing clients with access to individual VMs; C) VMs and containers
    side by side comparison.](Images/gitc_0304.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![A) 安装在物理机上的软件堆栈；B) 提供客户访问个别VM的服务器；C) VM和容器并排比较的表示。](Images/gitc_0304.png)'
- en: Figure 3-4\. A) The software stack installed on a physical machine; B) a system
    hosting multiple VMs; C) a system hosting multiple containers.
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. A) 安装在物理机上的软件堆栈；B) 托管多个VM的系统；C) 托管多个容器的系统。
- en: VMs and Containers
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VM和容器
- en: A VM is an infrastructure-level construct that includes its own OS. The VM sits
    on top of a virtualization layer that runs on the actual OS of the underlying
    physical machine(s). In the simplest case, VMs can be run on a single physical
    machine, with the effect of turning that physical machine into multiple servers
    that share the underlying resources. However, the most robust systems utilize
    multiple physical machines to support the layer of VMs, with a complex layer between
    them that manages the allocation of physical resources. The good news is that
    for end users, this should not make any difference—all you need to know is that
    you can interact with a particular VM in isolation without worrying about what
    it’s sitting on.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机（VM）是一个基础设施级别的构造，包括其自己的操作系统。VM位于运行在底层物理机实际操作系统上的虚拟化层之上。在最简单的情况下，VM可以在单个物理机上运行，使得该物理机效果上成为多个共享底层资源的服务器。然而，最强大的系统利用多个物理机来支持VM层，它们之间有一个复杂的层来管理物理资源的分配。好消息是，对于终端用户来说，这并不会有任何区别——你只需要知道你可以与特定的VM隔离地交互，而不用担心它的底层环境。
- en: A container is similar in principle to a VM, but it is an application-level
    construct that is much lighter and more mobile, meaning that it can be deployed
    easily to different sites, whereas VMs are typically tied to a particular location’s
    infrastructure. Containers are intended to bundle all the software required to
    run a particular program or set of programs. This makes it a lot easier to reproduce
    the same analysis on any infrastructure that supports running the container, from
    your laptop to a cloud platform, without having to go through the pain of identifying
    and installing all the software dependencies involved. You can even have multiple
    containers running on the same machine, so you can easily switch between different
    environments if you need to run programs that have incompatible system requirements.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 容器在原理上类似于虚拟机，但它是一个应用级的构造，更轻量且更便携，意味着可以轻松部署到不同的站点，而虚拟机通常与特定位置的基础设施绑定。容器旨在捆绑运行特定程序或一组程序所需的所有软件。这使得在任何支持运行容器的基础设施上复制相同的分析变得更加容易，无论是从你的笔记本电脑到云平台，都不必去辛苦识别和安装所有涉及的软件依赖关系。你甚至可以在同一台机器上运行多个容器，因此如果需要运行具有不兼容系统要求的程序，可以轻松切换不同的环境。
- en: 'If you’re thinking, “These both sound great; which one should I use?” here’s
    some good news: you can use both in combination, as illustrated in [Figure 3-5](#representation_of_a_system_with_three_v).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在想：“这两个听起来都很不错；我应该使用哪一个呢？”好消息是你可以同时结合使用，如[图 3-5](#representation_of_a_system_with_three_v)所示。
- en: '![Representation of a system with three VMs, of which two are running containers.](Images/gitc_0305.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![表示一个系统有三个虚拟机，其中两个正在运行容器。](Images/gitc_0305.png)'
- en: 'Figure 3-5\. A system with three VMs: the one on the left is running two containers,
    serving App #1 and App #2; the middle is running a single container, serving App
    #3; the right is serving App #4 directly (no container).'
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 3-5\. 一个有三个虚拟机的系统：左边的虚拟机正在运行两个容器，为App #1 和 App #2 提供服务；中间的虚拟机正在运行一个容器，为App
    #3 提供服务；右边直接为App #4 提供服务（没有容器）。'
- en: There are several registries for sharing and obtaining containers, including
    [Docker Hub](https://hub.docker.com), [Quay.io](https://quay.io), and [GCR](https://cloud.google.com/container-registry),
    Google’s general-purpose container registry in GCP. In the registry, the container
    is packaged as an *image*. Note that this has nothing to do with pictures; here
    the word *image* is used in the same software-specific way that refers to a special
    type of file. You know how sometimes when you need to install new software on
    your computer, the download file is called a *disk image*? That’s because the
    file you download is in a format that your OS is going to treat as if it were
    a physical disk on your machine. This is basically the same thing. To use a container,
    you first tell the Docker program to download, or *pull*, a container image file
    from a registry—for example, Docker Hub (more on Docker shortly)—and then you
    tell it to initialize the container, which is conceptually equivalent to booting
    up a VM. And after the container is running, you can run any software within it
    that is installed on its system. You can also install additional packages or perform
    additional configurations as needed. [Figure 3-6](#the_relationship_between_containercomma)
    illustrates the relationship between container, image, and registry.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个注册表可用于共享和获取容器，包括[Docker Hub](https://hub.docker.com)，[Quay.io](https://quay.io)和[GCR](https://cloud.google.com/container-registry)，谷歌在GCP中的通用容器注册表。在注册表中，容器被打包成一个*镜像*。请注意，这与图片无关；这里的*镜像*一词在软件特定的语境中使用，指的是一种特殊类型的文件。你知道有时候当你需要在电脑上安装新软件时，下载的文件被称为*磁盘镜像*吗？这是因为你下载的文件是以一种格式存在，你的操作系统会把它当作是你机器上的一个物理磁盘。这基本上是一样的道理。要使用一个容器，你首先告诉Docker程序从注册表（例如，Docker
    Hub，稍后详细介绍Docker）下载或*拉取*一个容器镜像文件，然后告诉它初始化容器，概念上等同于启动一个虚拟机。容器运行后，你可以在其中运行安装在其系统上的任何软件。你还可以根据需要安装额外的软件包或进行额外的配置。[Figure 3-6](#the_relationship_between_containercomma)说明了容器、镜像和注册表之间的关系。
- en: '![The relationship between container, image, and registry.](Images/gitc_0306.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![容器、镜像和注册表之间的关系。](Images/gitc_0306.png)'
- en: Figure 3-6\. The relationship between registry, image, and container.
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-6\. 注册表、镜像和容器之间的关系。
- en: The most widely used brand of container systems is Docker, produced by the company
    of the same name. As a result of Docker’s ubiquitousness, people will often say
    “a docker” instead of “a container,” much like when “xerox” became a replacement
    for “copy machines” (in the US at least) because of the dominance of the Xerox
    company. However, `docker` with a lowercase *d* is also the command-line program
    that you install on your machine to run Docker containers. Similarly, although
    the action of bundling a software tool, package, or analysis into a Docker container
    should rightly be called “containerizing,” people often call it “dockerizing,”
    as in, “I dockerized my Python script.” Dockerizing a tool involves writing a
    script called a Dockerfile that describes all installations and environment configurations
    necessary to *build* the Docker image, as demonstrated in [Figure 3-7](#the_process_for_creating_a_docker_conta).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最广泛使用的容器系统品牌是由同名公司生产的Docker。由于Docker的普及，人们通常会说“一个docker”而不是“一个容器”，就像“xerox”在美国成为“复印机”的替代品一样，因为Xerox公司的主导地位。然而，小写*d*的`docker`也是您在本地安装以运行Docker容器的命令行程序。类似地，尽管将软件工具、包或分析打包到Docker容器中的行为应该被称为“containerizing”，但人们经常称之为“dockerizing”，比如，“我dockerized我的Python脚本”。Docker化一个工具涉及编写一个称为Dockerfile的脚本，描述构建Docker镜像所需的所有安装和环境配置，如[图 3-7](#the_process_for_creating_a_docker_conta)所示。
- en: '![The process for creating a Docker container.](Images/gitc_0307.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![创建Docker容器的过程。](Images/gitc_0307.png)'
- en: Figure 3-7\. The process for creating a Docker image.
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-7\. 创建Docker镜像的过程。
- en: As noted earlier, it is possible to use containers in various contexts, including
    local machines, HPC, and the cloud. One important restriction is that Docker specifically
    is usually not allowed in shared environments like most institutions’ HPCs, because
    it requires a very high level of access permissions called *root*. In that kind
    of setting, system administrators will prefer *Singularity*, an alternative system
    that achieves the same results. Fortunately, it is possible to run Docker containers
    within a Singularity system.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，可以在各种环境中使用容器，包括本地机器、HPC和云计算。一个重要的限制是，Docker通常不允许在共享环境中使用，比如大多数机构的HPC，因为它需要一个称为*root*的非常高级别的访问权限。在这种环境中，系统管理员会更倾向于使用*Singularity*，这是一个能达到相同效果的替代系统。幸运的是，可以在Singularity系统中运行Docker容器。
- en: Introducing the Cloud
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍云计算
- en: 'Finally, we get to the topic many of you have been waiting for: what is this
    cloud thing anyway? The surprisingly easy answer is that the cloud is a bunch
    of computers that you can rent. In practice, that means that as a user, you can
    easily launch a VM and select how much RAM, storage, and what CPUs you want. You
    want a VM with 1 TB of RAM and 32 CPUs for genome assembly? No problem! Most of
    the VMs in the cloud are running some form of Linux as the OS, which you get to
    choose when you launch it, and are typically accessed using a remote shell via
    Secure Shell (SSH).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们来到许多人都在等待的话题：云究竟是什么？令人惊讶的简单答案是，云计算就是一堆可以租用的计算机。在实践中，这意味着作为用户，您可以轻松启动一个虚拟机，并选择需要多少RAM、存储空间和CPU。您需要一个带有1TB
    RAM和32个CPU用于基因组装的虚拟机？没问题！大多数云中的虚拟机都运行某种形式的Linux作为操作系统，您可以在启动时选择，并且通常通过安全外壳（SSH）远程访问。
- en: Although some VMs include free storage, this is typically ephemeral and will
    go away when you stop and start your VM. Instead, use block storage (a persistent
    device) to store data, scripts, and so on on your VM. You can think of these very
    much like a USB thumb drive that you can have “plugged” into your VM whenever
    you like. Even when you terminate your VM, files on block storage will be OK and
    safely saved. Files can also be stored in object store—think of this more like
    Google Drive or Dropbox, where files can be read and written by multiple VMs at
    the same time, but you don’t typically use these as a normal filesystem. Instead,
    they are more akin to an SSH File Transfer Protocol (SFTP) server for sharing
    files between VMs, where you transfer files through a utility to and from the
    object storage system. The final basic component of a cloud is networking. With
    a virtual networking service, you can control who has access to your VMs, locking
    it down tightly to ensure that only you (or others you trust) have access.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一些虚拟机（VMs）包含免费存储空间，但这通常是暂时的，当您停止和启动虚拟机时会消失。相反，使用块存储（持久设备）来存储数据、脚本等内容在您的虚拟机上。您可以把它们想象成USB闪存驱动器，可以随时“插入”到您的虚拟机中。即使终止虚拟机，块存储上的文件也会安全保存。文件也可以存储在对象存储中——把它想象成更像是Google
    Drive或Dropbox，多个虚拟机可以同时读写文件，但您通常不会把它们当作普通的文件系统使用。相反，它们更像是用于在虚拟机之间共享文件的SSH文件传输协议（SFTP）服务器，您可以通过实用工具在对象存储系统之间传输文件。云的最后一个基本组成部分是网络。通过虚拟网络服务，您可以控制谁可以访问您的虚拟机，严格锁定以确保只有您（或其他受信任的人）能够访问。
- en: Clouds are not fluffy
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 云不是松软的
- en: When you think about clouds, they are fluffy, distant, and elusive, not at all
    concrete, real things that you can touch, feel, and capture. Unlike their namesake,
    the cloud infrastructure that most of us use directly (or indirectly) today ultimately
    is composed of real, physical computers racked up and blinking away in huge datacenters.
    What makes it different, though, from previous models for compute (and rings true
    to their name) is its ephemeral nature. Just like clouds coming and going—popping
    up, dumping their rain, and then blowing away—cloud computing is transient for
    the end user. The cloud allows you as a researcher, developer, or analyst to request
    computational infrastructure when you need it, to use it for computing as long
    as you need it, and then you can release all the resources when you’re done.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想到云时，它们是松散、遥远和难以捉摸的，根本不是您可以触摸、感受和捕捉的实体。与其同名相比，今天大多数人直接（或间接）使用的云基础设施最终由真实的物理计算机组成，这些计算机装在巨大的数据中心中不停地闪烁。然而，与以往的计算模型不同（也符合其名称），云计算具有短暂的特性。就像云朵的出现和消失一样——突然出现、释放雨水，然后迅速消散——云计算对最终用户而言也是短暂的。云允许您作为研究人员、开发人员或分析师在需要时请求计算基础设施，在需要时使用它进行计算，然后在完成后释放所有资源。
- en: This approach is great because it saves time and money insomuch as you can spin
    up a lot of resources at once, get your work done, and spin these back down, saving
    on the costs or running hardware continuously. You don’t need to think too much
    about where the servers are racked, how they are configured, the health of the
    hardware, power consumption, or myriad other infrastructure concerns. These are
    all *abstracted away* from you and are taken care of without you having to think
    about it too much. What you focus on, instead, is the computational work that
    you need to perform, the resources you need to do it, and how to most effectively
    use these resources both from a time and money perspective.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法很棒，因为它节省了时间和金钱，您可以一次性启动大量资源，完成工作后再关闭它们，节省连续运行硬件的成本。您不需要过多地考虑服务器放置在何处、它们的配置方式、硬件的健康状况、功耗或其他各种基础设施问题。这些都被从您身上“抽象化”出去，并且在您无需过多考虑的情况下得到照顾。相反，您应该关注的是您需要执行的计算工作、完成它所需的资源以及如何从时间和金钱的角度最有效地利用这些资源。
- en: Evolution of cloud infrastructure and services
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 云基础设施和服务的演变
- en: Amazon launched the first widely successful commercial public cloud service
    in 2006, but the basic idea has been around for a long time. Mainframes in the
    1960s were often rented for use, which made a ton of sense, given the massive
    costs of buying and operating them. Regardless of the invention of the personal
    computer, the idea of renting computing infrastructure has cropped up again over
    and over in the intervening decades. In academic groups and industry, the concept
    of shared grid computing in the 1990s and 2000s was the more modern equivalent
    of rented mainframe time. Groups banded together to build cheap but powerful Linux-based
    HPC clusters that were often centrally managed and allocated out to multiple groups
    based on some sort of financial split.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊于2006年推出了第一个广泛成功的商业公共云服务，但这个基本概念已经存在了很长时间。上世纪60年代，大型机通常是租用使用的，考虑到购买和运营的巨大成本，这是非常合理的做法。尽管个人电脑的发明，租用计算基础设施的概念在过去几十年中一再出现。在学术界和行业中，上世纪90年代和2000年代共享网格计算的概念是租用大型机时间的更现代等价物。团体联合建立了廉价但功能强大的基于Linux的高性能计算集群，通常是集中管理，并根据某种财务分割分配给多个团体。
- en: 'Today’s public clouds are different, though, in the level of abstraction. Hence,
    the adoption of the fluffy, amorphous name to reflect the fact that an understanding
    of the underlying details is not required in order to run large-scale analysis
    on clouds. When working with a given cloud, you might know the general region
    of the world that hosts your infrastructure (e.g., North Virginia for AWS `us-east-1`),
    but many of the details are hidden from you: how many people are using the underlying
    hardware of your VM, where the datacenter is really located, how the network is
    set up, and so on. What you do know are key details that affect service cost and
    job execution time, like how many CPUs are available, how much RAM the VM has,
    the uptime guarantees of the file storage system, and the regulations the system
    conforms to.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当今的公共云在抽象级别上有所不同。因此，采用了蓬松、无定形的名称来反映这样一个事实：在云上运行大规模分析时，并不需要理解底层细节。在使用特定云服务时，你可能知道托管基础设施的大致地理位置（例如，AWS的`us-east-1`位于北弗吉尼亚），但许多细节对你是隐藏的：你不知道有多少人正在使用你的虚拟机的基础硬件，数据中心真正的位置在哪里，网络如何设置等等。你所知道的是影响服务成本和作业执行时间的关键细节，比如有多少个CPU可用，虚拟机有多少RAM，文件存储系统的正常运行时间保证，以及系统符合的法规。
- en: 'There are now many public cloud providers—clouds available to anyone who can
    pay for the service. The most dominant currently in the Western hemisphere are
    AWS, Microsoft Azure, and GCP. Each provides a similar mix of services that range
    from simple VMs rentable by the hour (or minute), file storage services, and networking
    to more specialized services such as Google’s Cloud TPU service, which allows
    you to perform accelerated machine learning operations. The important feature,
    though, is that these resources are provided as services: you use what you need
    per hour, minute, second, or API call, and are charged accordingly.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有许多公共云提供商，即任何能够支付服务费用的人都可以使用的云服务。目前在西半球最主要的有AWS、微软Azure和GCP。每个提供商都提供类似的服务组合，从按小时（或分钟）租用的简单虚拟机，文件存储服务和网络服务到更专业的服务，比如谷歌的云TPU服务，用于加速机器学习操作。然而，重要的特点是这些资源作为服务提供：你根据需要使用，按小时、分钟、秒或API调用收费。
- en: Pros and cons of the cloud
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 云的优缺点
- en: One of the major advantages that many people point to when discussing the cloud
    is cost. When building a datacenter, the fixed costs are enormous. You must hire
    people to rack and maintain physical servers, monitor the network for intrusion,
    deal with power fluctuations, backups, air conditioning, and so on. Honestly,
    it is a lot of work! For a datacenter that supports hundreds of users, the costs
    associated with maintaining the infrastructure can be worth it. But many researchers,
    developers, analysts, and others are realizing that they don’t need to have hundreds
    of computers always available and running, just waiting for a task. Instead, it
    makes a lot more sense to use a cloud environment in which you can do local work
    on your laptop, without extensive resources, and then, when your analysis is ready,
    you can scale up to hundreds or thousands of machines. Commercial public clouds
    allow you to easily *burst* your capacity and do a huge analysis when you need
    to, as opposed to waiting weeks, months, or even years for a dedicated local cluster
    to finish your tasks. Likewise, you don’t need to pay for the maintenance of local
    infrastructure for all the time you spend developing your algorithms and perfecting
    your analysis locally.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人在讨论云计算时指出的一个主要优势是成本。建设数据中心时，固定成本是巨大的。您必须雇佣人员来安装和维护物理服务器，监视网络以防入侵，处理电力波动，备份，空调等等。说实话，这是一项繁重的工作！对于支持数百用户的数据中心，维护基础设施所需的成本可能是值得的。但许多研究人员、开发人员、分析师和其他人意识到，他们并不需要始终拥有数百台随时可用和运行的计算机，只等待任务。相反，使用云环境更合理，您可以在笔记本电脑上进行本地工作，无需大量资源，然后在分析完成时，可以扩展到数百甚至数千台机器。商业公共云允许您轻松地*扩展*您的容量，并在需要时进行大规模分析，而不是等待几周、几个月甚至几年才能完成专用本地集群的任务。同样，您无需为本地基础设施的维护支付所有时间，用于开发算法和本地完善分析。
- en: Finally, as a public cloud user, you have full control of your environment.
    Need a specific version of Python? Do you have a funky library that compiles only
    if very specific tool chains are installed? No problem! The cloud lets you have
    full control over your VMs, something that a shared, local infrastructure would
    never allow. Even with this control, when they are set up following cloud vendor
    best practices, public cloud solutions are invariably more secure than on-premises
    infrastructure because of the vast amount of resources dedicated to security services
    in these environments and the isolation between users afforded by virtualization.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，作为公共云用户，您对环境拥有完全控制权。需要特定版本的Python吗？是否有一个怪异的库，只有在安装了非常特定的工具链时才能编译？没问题！云允许您完全控制您的虚拟机，这是共享本地基础设施永远不允许的。即使在拥有此控制权时，遵循云供应商的最佳实践设置后，公共云解决方案由于在这些环境中专门用于安全服务的大量资源以及虚拟化所提供的用户隔离，通常比本地基础设施更安全。
- en: Although the public cloud platforms are amazing, powerful, flexible and, in
    many cases, can be used effectively to save a ton of money in the long run, there
    are some disadvantages to look out for. If you are looking to always process a
    fixed number of genomes produced by your sequencing group per month, the public
    cloud might be less attractive and it would make more sense to build a small local
    compute environment for this very predictable workload of data produced locally.
    This is assuming, of course, that you have IT professionals who can act as administrators.
    Another consideration is expertise. Using the cloud demands a certain level of
    expertise, and an unsuspecting novice user might accidentally use VMs with weak
    passwords, set up data storage buckets with weak security, share credentials in
    an insecure way, or just be totally lost in the process of managing a fleet of
    Linux VMs. Even these potential downfalls, though, are generally outweighed by
    the benefits of working flexibly on commercial cloud environments for many people.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管公共云平台令人惊叹、强大、灵活，而且在许多情况下，可以有效地节省大量资金，但也有一些需要注意的缺点。如果您希望始终处理您的测序组每月生成的固定数量的基因组，公共云可能不太吸引人，构建一个小型的本地计算环境以处理本地产生的这种非常可预测的工作负载会更有意义。当然，这是在假设您有能够充当管理员的IT专业人员的情况下。另一个考虑因素是专业知识。使用云计算需要一定水平的专业知识，一个毫无戒心的新手用户可能会意外使用具有弱密码的虚拟机，设置具有弱安全性的数据存储桶，以不安全的方式共享凭据，或在管理一群Linux虚拟机的过程中完全迷失方向。然而，即使存在这些潜在的缺陷，对于许多人来说，能够在商业云环境中灵活工作的好处通常超过了这些负面影响。
- en: Categories of Research Use Cases for Cloud Services
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云服务的研究用例类别
- en: The basic components of the cloud described in the previous section are really
    just the tip of the iceberg. Many more services are available on the main commercial
    cloud platforms. In fact, there are far too many services, some universal and
    some unique to a particular cloud, than we can describe here. But let’s take a
    look at how researchers might use the services or the cloud most commonly. [Table 3-1](#an_overview_of_the_types_of_usage_of_cl)
    provides an overall summary.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 之前章节描述的云基础组件实际上只是冰山一角。主要商业云平台上提供了许多更多的服务。事实上，有太多服务了，一些是通用的，一些是特定于某个云的，我们无法在这里详细描述。但让我们看看研究人员可能如何最常用到这些服务或云。[表格
    3-1](#an_overview_of_the_types_of_usage_of_cl) 提供了一个总体概述。
- en: Table 3-1\. An overview of the types of usage of cloud infrastructure
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 3-1\. 云基础设施使用类型概述
- en: '| Usage type | Cloud environment | Description | Positives | Negatives |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 使用类型 | 云环境 | 描述 | 优点 | 缺点 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Lightweight development | Google Cloud Shell | Using a simple-to-launch free
    VM for editing code and scripts |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 轻量级开发 | Google Cloud Shell | 使用一个简单启动的免费虚拟机编辑代码和脚本 |'
- en: Free
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 免费
- en: Extremely easy to launch and log in to
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动和登录极为简单
- en: '|'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Extremely limited VM
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟机极为有限
- en: '|'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Intermediate analysis and development | Single VM | Launching a single VM,
    logging in, performing development and analysis work |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 中级分析和开发 | 单个虚拟机 | 启动单个虚拟机，登录，进行开发和分析工作 |'
- en: Can control the resources on the VM launched
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以控制启动的虚拟机上的资源
- en: VMs can be powerful enough to perform realistic analysis
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟机可以足够强大以执行实际分析
- en: '|'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Launching a VM requires more configuration
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动虚拟机需要更多配置
- en: Larger VMs have increased costs
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更大的虚拟机会增加成本
- en: '|'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Batch analysis | Multiple VMs via batch system | Using a system like AWS
    Batch or Google Cloud Pipelines API to launch many VMs and analyze data in parallel
    |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 批量分析 | 通过批处理系统多个虚拟机 | 使用类似AWS Batch或Google Cloud Pipelines API这样的系统启动多个虚拟机并行分析数据
    |'
- en: Allows for parallel, scaled-up analysis
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许并行、扩展的分析
- en: Workflow management systems like Cromwell support these with little effort
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作流管理系统如Cromwell支持这些操作而不需要太多努力
- en: '|'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Increased costs and complexity
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本和复杂性增加
- en: '|'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Framework analysis | Multiple VMs via a framework | Using Spark, Hadoop,
    or other framework for data analysis |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 框架分析 | 通过框架多个虚拟机 | 使用Spark、Hadoop或其他框架进行数据分析 |'
- en: These frameworks allow for specialty analysis
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些框架允许进行专业分析
- en: '|'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Increased costs and complexity
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本和复杂性增加
- en: '|'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Lightweight development: Google Cloud Shell'
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 轻量级开发：Google Cloud Shell
- en: The cloud is a fantastic place for software development. Even though many researchers
    will want to use their own laptops or workstation for development, there can be
    some really compelling reasons for using the cloud as a primary development environment,
    especially for testing. On GCP, for example, you can use the Google Cloud Shell
    from the Google Cloud Console for light development and testing. This is a free
    (yes, *free*!) VM with one virtual CPU core and 5 GB of storage that you can use
    just by clicking the terminal icon in the web console. This is a fantastic environment
    for some light coding and testing; just remember to copy code off of your free
    instance (using Git, for example) because there are quotas for total runtime per
    week, and, if you don’t use the service for a while, your 5 GB volume might get
    cleaned out. Still, this is a great option for quickly getting started with the
    cloud and performing lightweight tasks. You just need a web browser, and the GCP
    tools are all preinstalled and configured for you. Many other tools that you might
    want to work with are already installed as well, including Git and Docker, along
    with languages like Java and Python. You’ll have a chance to try it out early
    on in the next chapter.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 云是软件开发的绝佳场所。尽管许多研究人员可能会想要使用自己的笔记本电脑或工作站进行开发，但使用云作为主要开发环境，特别是用于测试，确实有一些非常引人注目的理由。例如，在GCP上，您可以从Google
    Cloud控制台中使用Google Cloud Shell进行轻量级开发和测试。这是一个免费（是的，*免费*！）的虚拟机，拥有一个虚拟CPU核心和5 GB存储空间，您只需点击Web控制台中的终端图标即可使用。这是进行轻量级编码和测试的绝佳环境；只需记得将代码从您的免费实例中复制出来（例如使用Git），因为每周的总运行时间有限制，而且如果您一段时间不使用该服务，您的5
    GB存储空间可能会被清理掉。尽管如此，这仍然是快速开始使用云并执行轻量级任务的绝佳选择。您只需一个Web浏览器，而且GCP工具已预先安装和配置好。许多其他您可能想要使用的工具也已经安装好，包括Git和Docker，以及像Java和Python等编程语言。您将有机会在下一章的早期尝试它。
- en: 'Intermediate development and analysis: single VM'
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中级开发和分析：单个虚拟机
- en: 'Although the Google Cloud Shell is great for many purposes, easy to use, and
    free, sometimes you might need a bit more power, especially if you want to test
    your code or analysis at the next scale up, so you spin up your own dedicated
    VM. This is perhaps the most commonly used option because of the mix of flexibility
    and simplicity it offers: you can customize your VM, ensuring you have enough
    CPU cores, RAM, and local storage to accomplish your goal. Unlike the Google Cloud
    Shell, you must pay for each hour or minute you run this VM; however, you have
    full control over the nature of the VM. You might use this for software or algorithm
    development, testing your analysis approach, or spinning up a small fleet of these
    VMs to perform analysis on multiple VMs simultaneously. Keep in mind, however,
    that if you are manually launching these VMs, fewer tools will be preinstalled
    on them and ready to go for you. That makes using utilities such as Git and Docker
    very helpful for moving your analysis tasks from VM to VM. You’ll have a chance
    to use this extensively in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud) through
    [Chapter 7](ch07.xhtml#gatk_best_practices_for_somatic_variant).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Google Cloud Shell非常适合许多用途，易于使用且免费，但有时您可能需要更多的计算能力，特别是如果您想测试您的代码或在更大的规模上进行分析，因此您会启动自己的专用虚拟机。这可能是最常用的选项之一，因为它结合了灵活性和简单性：您可以自定义您的虚拟机，确保具有足够的CPU核心、RAM和本地存储来完成您的目标。与Google
    Cloud Shell不同，您必须为每小时或每分钟运行此虚拟机支付费用；但是，您可以完全控制虚拟机的性质。您可以将其用于软件或算法开发，测试您的分析方法，或者在多个虚拟机上同时运行小型虚拟机群来执行分析。然而，请记住，如果您手动启动这些虚拟机，它们将预先安装的工具较少，并准备好供您使用。这使得使用Git和Docker等实用工具非常有助于将您的分析任务从一个虚拟机转移到另一个虚拟机。您将有机会在[第4章](ch04.xhtml#first_steps_in_the_cloud)到[第7章](ch07.xhtml#gatk_best_practices_for_somatic_variant)中广泛使用这些工具。
- en: 'Batch analysis: multiple VMs via batch services'
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 批处理分析：通过批处理服务使用多个虚拟机
- en: This approach is really the sweet spot for most users who are aware of it. Although
    you might use your laptop or Google Cloud Shell for software and script development,
    and one or more VMs for testing them on appropriately sized hardware, you ultimately
    don’t want to manually manage VMs if your goal is to scale up your analysis. Imaging
    running 10,000 genome alignments at the same time; you need systems that can batch
    up the work, provision VMs automatically for you, and turn the VMs off when your
    work is done. Batch systems are designed just for this task; Google Cloud, for
    example, offers the Google Cloud Pipelines API, which you can use to submit a
    large batch of multiple jobs simultaneously. The service will take care of spinning
    up numerous VMs to perform your analysis and then automatically clean them up
    after collecting the output files. This is extremely convenient if you need to
    perform noninteractive analysis on a ton of samples. You’ll see in [Chapter 8](ch08.xhtml#automating_analysis_execution_with_work)
    through [Chapter 11](ch11.xhtml#running_many_workflows_conveniently_in) that workflow
    engines like Cromwell are designed to take advantage of these batch services,
    which take care of all the details of launching batch jobs. That makes it much
    easier for you to focus on the details of the analysis you’re performing rather
    than on the infrastructure involved.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数了解这一点的用户来说，这种方法确实是最合适的选择。尽管您可以使用笔记本电脑或Google Cloud Shell进行软件和脚本开发，并在适当大小的硬件上测试它们，甚至可以使用一个或多个虚拟机进行测试，但如果您的目标是扩展分析，最终您可能不希望手动管理虚拟机。想象一下同时运行10,000个基因组比对任务；您需要能够批量处理工作、自动为您提供虚拟机，并在工作完成后自动关闭虚拟机的系统。批处理系统专门设计用于此任务；例如，Google
    Cloud提供了Google Cloud Pipelines API，您可以使用它同时提交大量批处理作业。该服务将负责启动大量虚拟机来执行您的分析，然后在收集输出文件后自动清理它们。如果您需要对大量样本进行非交互式分析，这将非常方便。您将在[第8章](ch08.xhtml#automating_analysis_execution_with_work)到[第11章](ch11.xhtml#running_many_workflows_conveniently_in)中看到像Cromwell这样的工作流引擎是如何利用这些批处理服务的，这些服务负责处理启动批处理作业的所有细节。这使得您能够更容易地专注于正在执行的分析细节，而不是涉及的基础设施。
- en: 'Framework analysis: multiple VMs via framework services'
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 框架分析：通过框架服务使用多个虚拟机
- en: The final approach that many researchers will use involves interactive, iterative
    analysis. In genomics, you can use a batch system to perform large-scale alignment
    and variant calling but, after you have VCF files for your variants, you might
    choose to move to a Spark cluster, RStudio, Jupyter Notebook, or any of a large
    number of analytical environments for subsequent analysis. In [Chapter 12](ch12.xhtml#interactive_analysis_in_jupyter_noteboo),
    we explore how this works in Terra, which you can use to easily create a custom
    environment for data processing with a Jupyter interface for interactive analysis,
    generating plots for your publications, and sharing results with others.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究人员最终采用的方法是交互式迭代分析。在基因组学中，您可以使用批处理系统进行大规模比对和变异调用，但在获取变异的VCF文件后，您可能选择迁移到Spark集群、RStudio、Jupyter
    Notebook或任何大量分析环境中进行后续分析。在[第12章](ch12.xhtml#interactive_analysis_in_jupyter_noteboo)中，我们探讨了在Terra中的运作方式，您可以利用它轻松创建用于数据处理的自定义环境，使用Jupyter界面进行交互式分析，生成出版物的图表，并与他人分享结果。
- en: Wrap-Up and Next Steps
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结尾与下一步
- en: In this chapter, we completed the primer topics, which gave you a background
    on genomics ([Chapter 2](ch02.xhtml#genomics_in_a_nutshell_a_primer_for_new))
    and computing technologies (this chapter). We delved into the nitty-gritty details
    of computer hardware, parallel computing, and virtualization and gave you a glimpse
    of the power of using workflow execution systems to scale out your analysis on
    the cloud. In [Chapter 4](ch04.xhtml#first_steps_in_the_cloud), we take our first
    baby steps to the cloud environment and show you how to get started with your
    own VMs running in GCP.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们完成了引导性主题，为您提供了基因组学（[第2章](ch02.xhtml#genomics_in_a_nutshell_a_primer_for_new)）和计算技术（本章）的背景。我们深入探讨了计算机硬件、并行计算和虚拟化的细节，并为您展示了使用工作流执行系统在云上扩展分析的强大能力。在[第4章](ch04.xhtml#first_steps_in_the_cloud)中，我们迈出了云环境的第一步，并向您展示了如何在GCP上运行自己的虚拟机。
