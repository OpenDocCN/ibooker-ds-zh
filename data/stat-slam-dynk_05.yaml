- en: 5 Regression models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 个回归模型
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Identifying and treating outliers
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别和处理异常值
- en: Running and interpreting statistical tests of normality
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行和解释正态性统计测试
- en: Computing and visualizing correlations between continuous variables
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算和可视化连续变量之间的相关性
- en: Fitting and interpreting multiple linear regressions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整和解释多重线性回归
- en: Fitting and interpreting regression trees
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整和解释回归树
- en: In this chapter, we’ll demonstrate how to fit regression models, namely, multiple
    linear regressions and regression trees. Our dependent, or target, variable will
    be regular season wins, and our independent variables, or predictors, will be
    the full complement of hustle statistics that the NBA began recording during the
    2016-17 season. These statistics include but aren’t limited to blocked shots,
    deflections, and loose balls recovered. Hence, we’ll be regressing wins against
    an order of hustle statistics.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将展示如何拟合回归模型，即多重线性回归和回归树。我们的因变量，或目标变量，将是常规赛胜利，我们的自变量，或预测变量，将是NBA在2016-17赛季开始记录的完整忙碌统计数据集。这些统计数据包括但不限于盖帽、挡球和抢断。因此，我们将对胜利进行一系列忙碌统计数据的回归。
- en: Our hypothesis is that at least some of these hustle statistics have a meaningful
    influence on wins and losses, but which hustle statistics? And by how much? Following
    a thorough exploration of the data—during which we’ll be laser-focused on identifying
    and treating outliers, testing for normal distributions, and computing correlation
    coefficients—we’ll fit a multiple linear regression as a first test and then fit
    a regression tree as a second test.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的假设是，至少一些这些忙碌统计数据对胜负有有意义的影响，但哪些统计数据？以及影响有多大？在彻底探索数据的过程中——在此期间，我们将专注于识别和处理异常值、检验正态分布以及计算相关系数——我们将首先拟合多重线性回归作为初步测试，然后拟合回归树作为第二次测试。
- en: A multiple linear regression is a model that estimates the relationship between
    a continuous target variable, such as regular season wins, and two or more predictor
    (and usually continuous) variables by producing an equation that draws a straight
    line through the data. (A simple linear regression is a model that does the same
    but with just one predictor variable.) The goal is to understand and quantify
    how two or more predictors collectively influence variances in the target variable.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 多重线性回归是一个模型，通过产生一个穿过数据的直线方程来估计连续目标变量（如常规赛胜利）与两个或更多预测变量（通常是连续变量）之间的关系。（简单线性回归是一个模型，它执行相同的操作，但只有一个预测变量。）目标是理解和量化两个或更多预测变量共同如何影响目标变量的方差。
- en: A regression tree, on the other hand, often called a decision tree regression,
    generates a series of if-else rules to best fit the data. This type of model recursively
    partitions the data into subsets based on the values of the predictors and predicts
    the continuous value of the target variable for each subset. Results are displayed
    graphically and might best reflect our decision-making processes; thus, they are
    easier than linear regressions to interpret and then explain to others—but often
    less predictive. Which of the two might be best depends on the data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，回归树通常被称为决策树回归，它生成一系列的if-else规则以最佳拟合数据。此类模型根据预测变量的值递归地将数据划分为子集，并为每个子集预测目标变量的连续值。结果以图形方式显示，可能最能反映我们的决策过程；因此，它们比线性回归更容易解释并解释给他人——但通常预测性较差。哪一种可能更好取决于数据。
- en: 'Let’s further set your expectations before loading our packages, importing
    our data, and otherwise moving forward with our analysis and testing:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载我们的包、导入我们的数据以及继续我们的分析和测试之前，让我们进一步设定您的期望：
- en: Linear modeling is based on the assumption that a linear relationship exists
    between the target variable and the predictors. Only when that assumption holds
    true is linear modeling a best test for explaining the past and predicting the
    future. Outliers in the data are sometimes the root cause when this assumption
    is violated. Linear models are especially sensitive to outliers; in fact, just
    a few outliers in a long data set can drastically change the slope of the regression
    line and thus cause a linear model to miss the overall pattern in the data and
    return inaccurate results. That all being said, in section 5.4, we’ll identify
    and treat every outlier in our data.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性建模基于目标变量与预测变量之间存在线性关系的假设。只有当这个假设成立时，线性建模才是解释过去和预测未来的最佳检验。当这个假设被违反时，数据中的异常值有时是根本原因。线性模型对异常值特别敏感；实际上，在一个长数据集中，只有几个异常值就可以极大地改变回归线的斜率，从而使线性模型无法捕捉数据的整体模式，并返回不准确的结果。话虽如此，在5.4节中，我们将识别并处理数据中的每个异常值。
- en: Every variable, especially the predictors, should be normally distributed. Treating
    outliers may be enough to transform a continuous variable from assuming a non-normal
    to a normal distribution, or it might not. In section 5.5, after we’ve identified
    outliers and treated them accordingly, we’ll draw density plots and demonstrate
    how to run and interpret a common statistical test for normality. Predictors that
    fail our normality test will be excluded from model development.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个变量，尤其是预测变量，都应该呈正态分布。处理异常值可能足以将连续变量从非正态分布转换为正态分布，也可能不足以做到。在5.5节中，在识别出异常值并相应处理之后，我们将绘制密度图，并演示如何运行和解释一个常见的正态性统计检验。那些未能通过正态性检验的预测变量将被排除在模型开发之外。
- en: Predictors that are highly correlated with the target variable, positively or
    negatively, are more likely to have a statistically significant influence on target
    variable variances than other potential predictors. Thus, in section 5.6, we’ll
    compute the correlation coefficients between wins and our remaining predictor
    variables to isolate those that have strong, or relatively strong, relationships
    with wins and to discard from model development those that don’t.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与目标变量高度相关的预测变量，无论是正相关还是负相关，更有可能对目标变量的方差产生统计上显著的影响，比其他潜在的预测变量。因此，在5.6节中，我们将计算胜利与我们的剩余预测变量之间的相关系数，以隔离那些与胜利有强烈或相对强烈关系的变量，并将那些在模型开发中不具有这种关系的变量排除在外。
- en: We’ll fit our multiple linear regressions in section 5.7 and demonstrate how
    to interpret and apply the results. Along the way, we’ll also provide instructions
    on how to apply best practices before and after fitting our models.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将在5.7节中拟合我们的多元线性回归，并演示如何解释和应用结果。在这个过程中，我们还将提供在拟合模型前后应用最佳实践的指导。
- en: In section 5.8, we’ll fit and plot a regression tree and walk you through how
    to interpret the results and compare and contrast the same with our linear models.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在5.8节中，我们将拟合和绘制回归树，并指导您如何解释结果，以及如何将结果与我们的线性模型进行比较和对比。
- en: Now we can go about loading our packages, importing our data, and starting our
    analysis.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始加载我们的包，导入我们的数据，并开始我们的分析。
- en: 5.1 Loading packages
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 加载包
- en: With respect to our multiple linear regressions, we’ll call the base R `lm()`
    function to fit our models and then a combination of packaged functions to return
    the results. Conversely, with respect to our regression tree, we’ll call the `tree()`
    function from the `tree` package to fit the model and then call a pair of built-in
    functions to visualize the results.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们的多元线性回归，我们将调用基础R的`lm()`函数来拟合模型，然后调用一系列包装函数来返回结果。相反，关于我们的回归树，我们将从`tree`包中调用`tree()`函数来拟合模型，然后调用一对内置函数来可视化结果。
- en: 'Overall, we’re introducing four packages that haven’t been loaded or used previously,
    including the `tree` package and the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，我们介绍了四个之前未加载或使用的包，包括`tree`包和以下包：
- en: From the `GGally` package, which is a `ggplot2` extension, the `ggpairs()` function
    will be called to return a correlation matrix that visualizes at once the associations
    between every continuous or numeric variable in our data set. There are many ways
    in R by which to visualize correlations; `GGally` actually goes above and beyond
    the heat map we created back in chapter 2\.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`GGally`包，这是一个`ggplot2`的扩展，我们将调用`ggpairs()`函数来返回一个相关矩阵，该矩阵可以一次性可视化数据集中每个连续或数值变量之间的关系。在R中有很多方法可以可视化相关性；实际上，`GGally`的功能远超我们在第2章中创建的热图。
- en: From the `car` package, the `vif()` function, which is short for variance inflation
    factor, will be called to check for multicollinearity among the independent variables,
    or predictors, in our linear regressions. Multicollinearity refers to two or more
    predictors that are strongly correlated with one another. When multicollinearity
    exists, at least one of the predictors should be removed, and a new or reduced
    model should be fit to ensure the highest levels of validity and reliability.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`car`包中，将调用`vif()`函数，即方差膨胀因子，以检查我们的线性回归中独立变量或预测变量之间的多重共线性。多重共线性指的是两个或更多预测变量之间高度相关。当存在多重共线性时，至少应该移除一个预测变量，并拟合一个新的或简化的模型，以确保最高水平的有效性和可靠性。
- en: From the `broom` package, a series of functions will be called to return our
    linear model results.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`broom`包中，将调用一系列函数以返回我们的线性模型结果。
- en: 'These packages, along with the `tidyverse` and `patchwork` packages, are loaded
    by making successive calls to the `library()` function:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包，包括`tidyverse`和`patchwork`包，通过连续调用`library()`函数来加载：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: With our packages now loaded, we’re ready to use their functions and then move
    on to the next step.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经加载了这些包，我们准备使用它们的函数，然后继续下一步。
- en: 5.2 Importing data
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 导入数据
- en: 'We begin by creating an object or data set called hustle by calling the `readr`
    `read_csv()` function that imports a .csv file also called hustle. The hustle
    data set contains scraped data from the NBA’s official website ([www.nba.com](https://www.nba.com/)):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过调用`readr`的`read_csv()`函数创建一个名为hustle的对象或数据集，该函数导入一个也称为hustle的.csv文件。hustle数据集包含从NBA官方网站（[www.nba.com](https://www.nba.com/)）抓取的数据：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `read_csv()` function *automatically* imports the hustle data set at runtime
    because the file is stored in our default working directory. The preceding code
    would fail if hustle.csv were stored anywhere else.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_csv()`函数在运行时自动导入hustle数据集，因为文件存储在我们的默认工作目录中。如果hustle.csv存储在其他任何地方，前面的代码将失败。'
- en: 'There is more than one way to set or change your working directory. The best
    way—because other options can always change with subsequent software releases—is
    to call the base R `setwd()` function and add the full directory between a pair
    of single or double quotation marks:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 设置或更改工作目录的方式不止一种。最佳方式——因为其他选项可能会随着后续软件版本的发布而改变——是调用基础R的`setwd()`函数，并在一对单引号或双引号之间添加完整目录：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following line of code *interactively* imports a .csv file by substituting
    the base R `file.choose()` function for the working directory. This is a good
    option if your .csv file is stored outside your working directory or if you’ve
    chosen to not define a working directory at all:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码行通过用工作目录替换基础R的`file.choose()`函数来交互式地导入一个.csv文件。如果您的.csv文件存储在工作目录之外，或者您选择不定义工作目录，这是一个不错的选择：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: A dialog box opens at runtime prompting you to navigate your computer and then
    select the .csv file you want to import.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行时打开一个对话框，提示您导航计算机并选择要导入的.csv文件。
- en: 5.3 Knowing the data
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 了解数据
- en: 'Now that we’ve imported our data set, let’s go about getting to know it. As
    in previous chapters, the `glimpse()` function from the `dplyr` package is called
    to return a transposed version of the hustle data set:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经导入了数据集，让我们开始了解它。与前面的章节一样，我们调用`dplyr`包中的`glimpse()`函数，以返回hustle数据集的转置版本：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The hustle data set is 90 rows long and 14 columns wide. It contains the variables
    `team`, `season`, and `team_season` as character strings; several hustle statistics
    as numeric variables; and regular season wins.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: hustle数据集有90行长，14列宽。它包含作为字符字符串的变量`team`、`season`和`team_season`；几个hustle统计数据作为数值变量；以及常规赛胜利数。
- en: 'We have one required and immediate action: converting those first three variables
    from character strings to factors. Therefore, we make three calls to the base
    R `as.factor()` function. Once again, it’s a best practice to convert character
    strings to factors when the variables can otherwise assume just a fixed or finite
    set of values:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个必要且立即的行动：将前三个变量从字符字符串转换为因子。因此，我们调用基础R的`as.factor()`函数三次。再次强调，当变量可以假设仅为固定或有限集合的值时，将字符字符串转换为因子是一种最佳实践：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We then call the `summary()` function from base R to return basic or descriptive
    statistics on every variable in the hustle data set:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们调用基础R的`summary()`函数，以返回hustle数据集中每个变量的基本或描述性统计信息：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Some of what we can deduce from our data follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的数据中我们可以推断出以下内容：
- en: Our data set spans the last three NBA regular seasons, pre-COVID-19 (see the
    results on the `season` variable); the 2019-20 season was cut short, especially
    for those teams that failed to qualify for in-bubble play once the season resumed
    because of the pandemic. (Once the 2019-20 season resumed, all games were played
    at a neutral, controlled site in Orlando, Florida.)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的数据集涵盖了过去三个NBA常规赛赛季，即COVID-19之前（参见 `season` 变量的结果）；2019-20赛季因疫情而缩短，特别是那些在赛季恢复后未能进入泡泡比赛（in-bubble
    play）的球队。 (一旦2019-20赛季恢复，所有比赛都在佛罗里达州奥兰多的一个中立、受控的场地进行。)
- en: The variables `team` and `season` were concatenated to create an additional
    variable called `team_season` where, for instance, the 2016-17 Atlanta Hawks becomes
    ATL 17.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量 `team` 和 `season` 被连接起来创建了一个额外的变量 `team_season`，例如，2016-17赛季的亚特兰大老鹰队变为 ATL
    17。
- en: The variables `off_loose_balls` and `def_loose_balls`, offensive and defensive
    loose balls recovered, respectively, have minimums of 0, thereby suggesting that
    for at least one season, the NBA tracked total loose balls recovered only. A loose
    ball recovered is just that—the offensive team has lost control but not necessarily
    possession of the ball, which is then recovered and controlled by the offense
    or defense.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量 `off_loose_balls` 和 `def_loose_balls` 分别代表进攻和防守中失去的球，它们的取值范围最小为 0，这表明至少在一个赛季中，NBA
    只追踪了总失去的球数。一个被找回的球就是这样——进攻队失去了对球的控制，但不一定失去了球权，随后球被进攻方或防守方找回并控制。
- en: The statistics on the variable `charges` are modest, and the variances between
    them are negligible. When an offensive player in possession of the ball dribbles
    and drives toward the basket and there is contact between him and a defensive
    player, a personal foul is called (unless the contact was slight and didn’t severely
    affect the play). In the NBA, as opposed to college basketball, contact on dribble
    drives to the basket usually results in a blocking foul or a foul against the
    defense. But every now and then, the offense is instead called for the foul; when
    this occurs, the defense is credited with a charge, or more specifically a drawn
    charge. Such a variable, where the frequency is rare and the variance is small,
    is unlikely to have much influence on a target variable.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量 `charges` 上的统计数据不多，它们之间的差异可以忽略不计。当一个持球进攻球员在运球并向篮筐突破时，如果他与防守球员发生接触，就会被判个人犯规（除非接触轻微且没有严重影响比赛）。在NBA与大学篮球不同，运球突破到篮筐的接触通常会导致阻挡犯规或对防守方的犯规。但偶尔，进攻方会被判犯规；当这种情况发生时，防守方会被记为一次犯规，或者更具体地说，是一次引诱犯规。这样的变量，其频率很少且差异很小，不太可能对目标变量有太大影响。
- en: 'Other than `wins`, we see the most variance with the following variables:'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了 `wins`（胜利）之外，我们观察到以下变量的变化最大：
- en: '`screen_assists_pts`—This variable equals the total points scored per game
    when one player makes a shot (i.e., field goal) immediately after a teammate sets
    a screen by placing his body between his teammate and a defensive player.'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`screen_assists_pts`——这个变量等于每场比赛中，当一名球员在队友通过挡拆（将身体置于队友和防守球员之间）后立即投篮得分时的总得分。'
- en: '`contested_2pt`—This variable equals the average number of opponent two-point
    shot attempts that were closely defended.'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contested_2pt`——这个变量等于对手两分球尝试的平均防守紧密程度。'
- en: '`contested_shots`—This variable equals the average number of total shot attempts—two-pointers
    and three-pointers—that were closely defended. All shot (field goal) attempts
    are worth two or three points, depending on the distance from the basket.'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contested_shots`——这个变量等于总投篮尝试的平均次数——包括两分球和三分球——它们的防守紧密程度较高。所有投篮（投篮得分）尝试根据距离篮筐的距离，每球得分为两分或三分。'
- en: 'There is a moderate amount of variance with these variables:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些变量之间存在中等程度的差异：
- en: '`contested_3pt`—This variable equals the average number of opponent three-point
    shot attempts that were closely defended.'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contested_3pt`——这个变量等于对手三分球尝试的平均防守紧密程度。'
- en: '`screen_assists`—This variable equals the average number of screens set per
    game, regardless of what then happens on the floor.'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`screen_assists`——这个变量等于每场比赛中设置的挡拆平均次数，无论随后场上的情况如何。'
- en: '`deflections`—This variable equals the average number of opponent passes broken
    up, or deflected, per game.'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deflections`——这个变量等于每场比赛中平均破坏或挡掉对手传球次数。'
- en: 'Based on the inconsistent tracking of *offensive* loose balls recovered versus
    *defensive* loose balls recovered, we make a call to the `select()` function from
    the `dplyr` package to remove the variables `off_loose_balls` and `def_loose_balls`
    from the hustle data set; in this case, it’s much easier to tell R what to delete—hence
    the minus operator preceding a subsequent call to the `c()` function—rather than
    what to retain:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 基于对进攻性 loose balls 恢复与防御性 loose balls 恢复的不一致跟踪，我们调用`dplyr`包中的`select()`函数，从
    hustle 数据集中移除变量 `off_loose_balls` 和 `def_loose_balls`；在这种情况下，告诉R删除什么比保留什么要容易得多——因此，在随后的`c()`函数调用之前有一个减号运算符：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We then call the base R `dim()` function to confirm the success of this operation
    by returning the new dimension of our data set:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后调用基础R的`dim()`函数，通过返回数据集的新维度来确认此操作的执行成功：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Our data set now contains 90 rows and just 12 columns, whereas before it had
    14 columns.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集现在包含90行和仅12列，而之前它有14列。
- en: 5.4 Identifying outliers
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 识别异常值
- en: As previously mentioned, linear regression models assume—actually, demand—that
    the source data be free of any outliers. Just a few outliers, which, for all we
    know, may be due to measurement errors, data entry mistakes, or rare events, can
    overwhelm the influence of the remaining data points, thereby injecting bias into
    any regression model. Therefore, data points that significantly deviate from the
    overall pattern or distribution of the remaining data will be identified and subsequently
    modified to effectively eliminate them as outliers. This might seem excessive
    to some of you, but when working with short data sets such as hustle, changing
    extreme values (known as *winsorization*) is a perfectly acceptable and legitimate
    alternative to removing observations and reducing the length of the data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，线性回归模型假设——实际上，要求——源数据不包含任何异常值。仅仅几个异常值，我们可能知道，可能是由于测量错误、数据输入错误或罕见事件，可能会压倒剩余数据点的
    影响，从而给任何回归模型注入偏差。因此，将识别出与剩余数据整体模式或分布显著偏离的数据点，并随后对其进行修改，以有效地将其作为异常值消除。这可能会让一些人觉得过于夸张，但当我们处理
    hustle 这样的短数据集时，改变极端值（称为 *winsorization*）是删除观测值并缩短数据长度的完全可接受和合法的替代方案。
- en: 5.4.1 Prototype
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.1 原型
- en: 'There are *many* ways to go about identifying outliers. The visual approach
    might require the most work, but it’s the most effective means of understanding
    the data. The easiest approach might be one of two statistical tests: Dixon’s
    *Q* Test and Grubbs’ Test, both of which require the `outliers` package. However,
    Dixon’s *Q* only works with small data sets, where *n*, or the number of records,
    is less than 30; Grubbs’ Test, on the other hand, has greater extensibility, but
    it only returns the one most significant outlier, even if other outliers are present.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 识别异常值有 *很多* 方法。视觉方法可能需要最多的工作，但它是理解数据最有效的方法。最简单的方法可能是一种统计测试：Dixon的 *Q* 测试和Grubbs测试，两者都需要`outliers`包。然而，Dixon的
    *Q* 只适用于小数据集，其中 *n*，即记录数，小于30；另一方面，Grubbs测试具有更大的扩展性，但它只返回一个最显著的异常值，即使存在其他异常值。
- en: 'Let’s demonstrate the visual approach with the variable `deflections`. There
    are three visualization options for spotting outliers: scatterplot, histogram,
    and boxplot.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用变量 `deflections` 来演示视觉方法。有三种可视化选项可以用来发现异常值：散点图、直方图和箱线图。
- en: Creating a scatterplot with just an x-axis variable isn’t the same as creating
    a correlation plot, which visualizes the relationship between a pair of x-axis
    and y-axis variables. That being said, rather than calling the `ggplot()` function
    from the `ggplot2` package, we’ll first create our scatterplot by calling the
    `qplot()` function, which is short for quick plot. Second, we’ll pass the `seq_along()`
    function to `qplot()` to create a vector of evenly spaced numbers. The downside
    to scatterplots is that outliers won’t always be so obvious.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 仅使用x轴变量创建散点图与创建可视化x轴和y轴变量之间关系的关联图并不相同。话虽如此，我们不会调用`ggplot2`包中的`ggplot()`函数，而是首先通过调用`qplot()`函数创建我们的散点图，`qplot()`是快速绘图的意思。其次，我们将`seq_along()`函数传递给`qplot()`以创建一个均匀分布的数字向量。散点图的缺点是异常值并不总是那么明显。
- en: The same can be said of histograms. They are usually a first option for displaying
    the distribution of a continuous variable, but in the end, tagging (or not tagging)
    values along the tails as outliers is often a subjective exercise. By contrast,
    boxplots are specifically designed to isolate values outside the whiskers and
    to qualify them as outliers.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于直方图也是如此。它们通常是显示连续变量分布的第一个选项，但最终，在尾部标记（或不标记）值作为异常值通常是一个主观的练习。相比之下，箱线图专门设计用来隔离胡须外的值，并将它们确定为异常值。
- en: 'For comparison purposes, the following chunk of code returns a scatterplot
    (`sp1`), histogram (`hist1`), and boxplot (`bp1`) around the variable `deflections`
    (see figure 5.1). However, with respect to the remaining variables in the hustle
    data set, only boxplots will be created:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较目的，以下代码块返回了变量`deflections`周围的散点图（`sp1`）、直方图（`hist1`）和箱线图（`bp1`）（见图5.1）。然而，对于hustle数据集中的剩余变量，只将创建箱线图：
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![CH05_F01_Sutton](../../OEBPS/Images/CH05_F01_Sutton.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F01_Sutton](../../OEBPS/Images/CH05_F01_Sutton.png)'
- en: Figure 5.1 Left to right, a scatterplot, a histogram, and a boxplot around the
    variable `deflections` from the hustle data set. Identifying outliers can be subjective
    with respect to scatterplots and histograms, but not with boxplots.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 从左到右，hustle数据集中变量`deflections`周围的散点图、直方图和箱线图。与散点图和直方图相比，在识别异常值时，箱线图的主观性较低。
- en: 'The spaces between the opening quotation marks and the `Outliers` annotations
    (e.g., `" Outliers"`) are purposeful; they were inserted to best position the
    text within the histogram and boxplot for aesthetic reasons. Otherwise, the `plot_layout()`
    function from the `patchwork` package prints our three visualizations as a single
    horizontal object:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 开放引号和`Outliers`注释（例如，`" Outliers"`）之间的空格是有意为之的；它们被插入以最佳定位文本在直方图和箱线图中，出于美观考虑。否则，`plot_layout()`函数从`patchwork`包中打印出我们的三个可视化作为单个水平对象：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The variable `deflections` does contain a pair of outliers. Our next step is
    to therefore winsorize the data by reducing the values of the two outliers just
    enough so that they instead equal the maximum. Recall that the maximum on a boxplot
    is the top end of the whisker (and that the minimum is the endpoint of the bottom
    whisker).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`deflections`确实包含一对异常值。因此，我们的下一步是通过减少这两个异常值的值，使它们刚好等于最大值来winsorize数据。回想一下，箱线图上的最大值是胡须的顶端（而最小值是底部胡须的端点）。
- en: 'The following line of code modifies any values in the variable `deflections`
    greater than 17.8 to instead equal 17.8, the approximate endpoint of the top whisker
    from `bp1`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下行代码修改了变量`deflections`中大于17.8的任何值，使其等于17.8，这是`bp1`顶部胡须的大约端点：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The maximum value for the variable `deflections` was originally 18.70 (check
    the `summary()` function returns). The `max()` function from base R returns the
    new maximum of 17.8, so there’s no need to again call the `summary()` function
    when you just need a single statistic returned:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`deflections`的最大值最初为18.70（检查`summary()`函数返回）。基础R中的`max()`函数返回新的最大值17.8，因此当你只需要返回一个统计值时，无需再次调用`summary()`函数：
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'A second boxplot (see figure 5.2) displays the new distribution of the variable
    `deflections` post-winsorization:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个箱线图（见图5.2）显示了变量`deflections`在winsorization后的新分布：
- en: '[PRE13]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![CH05_F02_Sutton](../../OEBPS/Images/CH05_F02_Sutton.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F02_Sutton](../../OEBPS/Images/CH05_F02_Sutton.png)'
- en: Figure 5.2 The new or revised distribution of the variable `deflections` post-winsorization.
    Note the absence of outliers, that is, any data points beyond the length of the
    whiskers.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 变量`deflections`在winsorization后的新或修订分布。注意异常值（即任何超出胡须长度的数据点）的缺失。
- en: 'The following summarizes what we’ve done so far:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以下总结了我们迄今为止所做的工作：
- en: We selected a visual approach over a pair of statistical methods to spot outliers
    in the hustle data set.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们选择了一种视觉方法而不是两种统计方法来在hustle数据集中检测异常值。
- en: We then chose boxplots over scatterplots and histograms because identifying
    outliers in boxplots is less subjective than doing so with other visualization
    types. Furthermore, boxplots are better visuals than the alternatives when it
    comes to deciding how much to decrease or increase the values of outliers to effectively
    eliminate them as outliers.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们选择了箱线图而不是散点图和直方图，因为与使用其他可视化类型相比，在箱线图中识别异常值的主观性较低。此外，当决定如何减少或增加异常值的值以有效地消除它们时，箱线图比替代方案有更好的视觉效果。
- en: Rather than removing outliers from our data, we instead decided on winsorization
    due to the hustle data set being only 90 rows long.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们没有从数据中移除异常值，而是由于 hustle 数据集只有 90 行长，我们决定采用 winsorization。
- en: By calling the base R `max()` function and then creating a second boxplot, we
    twice confirmed that the outliers in the variable `deflections` are now gone.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过调用基础 R 的 `max()` 函数并创建第二个箱线图，我们两次确认变量 `deflections` 中的异常值已经消失。
- en: This process will be repeated in the following section against the remaining
    variables in the hustle data set.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，这个过程将对 hustle 数据集中的剩余变量重复进行。
- en: 5.4.2 Identifying other outliers
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.2 识别其他异常值
- en: 'In the long chunk of code that immediately follows, we’ll create a boxplot
    for every remaining variable in the hustle data set. For those variables that
    contain one or more outliers, our boxplots include a second theme by which a red
    trim is added along the border. Otherwise, the syntax is exactly the same for
    each plot, which means you can review the code for our first boxplot and then
    skip to where the narrative resumes, if you like:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在紧随其后的长段代码中，我们将为 hustle 数据集中的每个剩余变量创建一个箱线图。对于包含一个或多个异常值的变量，我们的箱线图包括一个第二主题，通过在边缘添加红色边条来表示。否则，每个图表的语法都是完全相同的，这意味着你可以查看我们第一个箱线图的代码，然后跳转到叙述继续的地方，如果你愿意的话：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The first four of our eight boxplots (see figure 5.3) are packed into a single
    graphical object by again calling the `plot_layout()` function from the `patchwork`
    package. The remaining four plots are then packed into a separate object (see
    figure 5.4). It usually doesn’t make sense—at least for aesthetic reasons if not
    also for practical purposes—to bundle more than four visualizations into one graphical
    representation:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的前四个箱线图（见图 5.3）通过再次调用 `plot_layout()` 函数从 `patchwork` 包中组合成一个单一的图形对象。然后，剩余的四个图表被组合成另一个对象（见图
    5.4）。将超过四个可视化组合成一个图形表示通常没有意义——至少从美学角度来看是这样，也许从实用角度来看也是如此：
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![CH05_F03_Sutton](../../OEBPS/Images/CH05_F03_Sutton.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F03_Sutton](../../OEBPS/Images/CH05_F03_Sutton.png)'
- en: Figure 5.3 Boxplots for the variables `wins`, `screens_assists`, `screen_assists_pts`,
    and `loose_balls`. There are no outliers present in any of these variables.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 变量 `wins`、`screens_assists`、`screen_assists_pts` 和 `loose_balls` 的箱线图。这些变量中没有任何异常值。
- en: 'Other than the variable `deflections`, just two other variables in the hustle
    data set contain outliers: `contested_2pt` and `contested_shots`. The variable
    `contested_2pt` has a single outlier beyond the maximum, and the variable `contested_shots`
    has a pair of outliers above the maximum and two more outliers below the minimum.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 除了变量 `deflections` 之外，hustle 数据集中只有另外两个变量包含异常值：`contested_2pt` 和 `contested_shots`。变量
    `contested_2pt` 有一个异常值超过了最大值，而变量 `contested_shots` 有成对的异常值高于最大值，还有两个异常值低于最小值。
- en: '![CH05_F04_Sutton](../../OEBPS/Images/CH05_F04_Sutton.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F04_Sutton](../../OEBPS/Images/CH05_F04_Sutton.png)'
- en: Figure 5.4 Boxplots for the hustle data set variables `charges`, `contested_2pt`,
    `contested_3pt`, and `contested_shots`. Outliers are present in two of these four
    variables.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 为 hustle 数据集中变量 `charges`、`contested_2pt`、`contested_3pt` 和 `contested_shots`
    的箱线图。其中有两个变量存在异常值。
- en: 'The next chunk of code decreases the values of those outliers above the maximum
    and increases the values of those outliers below the minimum:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 下一段代码将那些高于最大值的异常值降低，将那些低于最小值的异常值增加：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'A call to the `max()` function confirms that the maximum value for the variable
    `contested_2pt` has been reduced from 49.10 to 48.5:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对 `max()` 函数的调用确认了变量 `contested_2pt` 的最大值已从 49.10 降低到 48.5：
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'A second boxplot (see figure 5.5) is then drawn, showing that the variable
    `contested_2pt` is now free of any outliers:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然后绘制第二个箱线图（见图 5.5），显示变量 `contested_2pt` 现在没有任何异常值：
- en: '[PRE18]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![CH05_F05_Sutton](../../OEBPS/Images/CH05_F05_Sutton.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F05_Sutton](../../OEBPS/Images/CH05_F05_Sutton.png)'
- en: Figure 5.5 The new or revised distribution of the variable `contested_2pt` post-winsorization
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 winsorization 后变量 `contested_2pt` 的新或修订分布
- en: 'Another call to the `max()` function immediately followed by a call to the
    base R `min()` function returns the new maximum and minimum values for the variable
    `contested_shots`:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 紧接着对 `max()` 函数的调用之后，紧接着调用基础 R 的 `min()` 函数，返回变量 `contested_shots` 的新最大值和最小值：
- en: '[PRE19]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The maximum value for `contested_shots` decreased from 74.20 to 69.30, and the
    minimum increased from 55.30 to 57.40.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`contested_shots` 的最大值从 74.20 降低到 69.30，最小值从 55.30 增加到 57.40。'
- en: 'Our next visualization displays the new distribution for the variable `contested_
    shots`, which now no longer contains any outliers, whereas before, it contained
    four of them (see figure 5.6):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来的可视化显示了变量`contested_ shots`的新分布，现在它不再包含任何异常值，而之前它包含了四个（见图5.6）：
- en: '[PRE20]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![CH05_F06_Sutton](../../OEBPS/Images/CH05_F06_Sutton.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F06_Sutton](../../OEBPS/Images/CH05_F06_Sutton.png)'
- en: Figure 5.6 The new or revised distribution of the variable `contested_shots`
    post-winsorization
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 经过winsorization后的变量`contested_shots`的新或修订分布
- en: Linear regressions also expect the target variable and especially the predictor
    variables to be normally distributed to get best results (which is why non-normal
    variables are often transformed to make them normal). Although the hustle data
    set is now free of outliers, this by no means guarantees that our variables now
    assume normal or Gaussian distributions. Next, we’ll visualize the distribution
    of every variable with a series of density plots and complement our ongoing visual
    approach with a statistical test against each variable to determine whether each
    is normally distributed.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归也期望目标变量以及特别是预测变量呈正态分布以获得最佳结果（这就是为什么非正态变量通常会被转换以使其呈正态分布）。尽管hustle数据集现在没有异常值，但这并不意味着我们的变量现在具有正态或高斯分布。接下来，我们将使用一系列密度图来可视化每个变量的分布，并通过针对每个变量的统计测试来补充我们的持续视觉方法，以确定每个变量是否呈正态分布。
- en: 5.5 Checking for normality
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 检查正态性
- en: Now that outliers have been treated, we’ll next create a series of density plots
    as a means of visualizing each variable’s frequency distribution or shape. Additionally,
    the `shapiro.test()` function from base R will be called just before creating
    each density plot to run a Shapiro-Wilk test and determine whether each variable,
    regardless of how normal or not so normal their distributions may then appear,
    measures up. The Shapiro-Wilk test is just one of several normality tests, though
    no doubt the most common. Another fairly common normality test is the Kolmogorov-Smirnov
    test. R supports these and other similar tests.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经处理了异常值，接下来我们将创建一系列密度图，作为可视化每个变量频率分布或形状的手段。此外，在创建每个密度图之前，我们将调用基础R中的`shapiro.test()`函数来运行Shapiro-Wilk测试，以确定每个变量，无论其分布看起来是否正常或不太正常，是否满足正态分布。Shapiro-Wilk测试只是几种正态性测试中的一种，尽管无疑是最常见的。另一种相当常见的正态性测试是Kolmogorov-Smirnov测试。R支持这些和其他类似的测试。
- en: The null hypothesis for a Shapiro-Wilk test is that the data is normally distributed.
    So if the p-value—defined as the probability that an observed difference could
    have otherwise occurred by chance—is less than or equal to 0.05, we’ll reject
    the null hypothesis and conclude that the data is non-normal. Alternatively, when
    the p-value is greater than 0.05, we’ll instead conclude that the data is normally
    distributed and that the null hypothesis shouldn’t be rejected.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Shapiro-Wilk测试的零假设是数据呈正态分布。因此，如果p值——定义为观察到的差异可能偶然发生的概率——小于或等于0.05，我们将拒绝零假设，并得出结论说数据是非正态的。另一方面，当p值大于0.05时，我们反而会得出结论说数据是正态分布的，并且零假设不应该被拒绝。
- en: Hypothesis testing and p-values
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 假设检验和p值
- en: Let’s take a brief pause to raise a few additional points around hypothesis
    testing and p-values. Hypothesis testing, or statistical inference, is all about
    testing an assumption and drawing a conclusion from one or more data series. Hypothesis
    testing essentially evaluates how unusual or not so unusual the results are and
    whether they are too extreme or improbable to be the outcome of chance.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时休息一下，来讨论一下假设检验和p值的一些额外要点。假设检验，或称统计推断，主要是测试一个假设，并从一组或多组数据系列中得出结论。假设检验本质上评估结果有多不寻常或不太不寻常，以及它们是否过于极端或不可能是偶然的结果。
- en: Our starting assumption should always be what’s known as the null hypothesis,
    designated as H[0], which suggests that nothing statistically significant or out
    of the ordinary exists in one variable or between two data series. We therefore
    require extraordinary evidence to reject the null hypothesis and to instead accept
    the alternative hypothesis, designated as H[1]*.*
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该始终假设的是所谓的零假设，表示为H[0]，它表明在一个变量或两个数据系列之间不存在任何统计上显著或不寻常的情况。因此，我们需要非凡的证据来拒绝零假设，并接受备择假设，表示为H[1]**。
- en: That evidence is the p-value and specifically the generally accepted 5% threshold
    for significance. While 5% might be somewhat arbitrary, we can agree that it’s
    a very low number, so we’re setting a high bar to overturn or reject a null hypothesis.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这个证据是 p 值，特别是通常接受的 5% 的显著性阈值。虽然 5% 可能有些武断，但我们同意这是一个非常小的数字，所以我们设定了一个很高的标准来推翻或拒绝零假设。
- en: As previously mentioned, linear modeling expects variables to be normally distributed,
    so any predictors that have Shapiro-Wilk test results where the p-value is less
    than or equal to 0.05 will be withheld from model development. There will be no
    data transformations or other corrective action applied.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，线性建模期望变量是正态分布的，因此任何在 Shapiro-Wilk 测试结果中 p 值小于或等于 0.05 的预测变量将被排除在模型开发之外。将不会应用数据转换或其他纠正措施。
- en: 5.5.1 Prototype
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.1 原型
- en: Once again, we’ll use the variable `deflections` to prototype all this (see
    figure 5.7). But first, we make a call to the base R `options()` function to disable
    scientific notation; we prefer our results to be returned in full digit numerals
    rather than in scientific notation.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们将使用变量 `deflections` 来原型化所有这些（见图 5.7）。但首先，我们调用基础 R 的 `options()` 函数来禁用科学记数法；我们更喜欢结果以完整数字形式返回，而不是以科学记数法形式。
- en: '![CH05_F07_Sutton](../../OEBPS/Images/CH05_F07_Sutton.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F07_Sutton](../../OEBPS/Images/CH05_F07_Sutton.png)'
- en: Figure 5.7 Density plot for the variable `deflections`. Because the Shapiro-Wilk
    normality test returned a p-value greater than 0.05, we can conclude that `deflections`
    assumes a normal distribution.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 变量 `deflections` 的密度图。由于 Shapiro-Wilk 正态性测试返回的 p 值大于 0.05，我们可以得出结论，`deflections`
    假设正态分布。
- en: 'As a reminder, a density plot is a smoothed version of a histogram that doesn’t
    allow us to contort the distribution shape by experimenting with different bin
    counts. We pass just a single hustle variable to the `ggplot()` function and then
    call the `geom_density()` function to draw a density plot. R subsequently returns
    a plot, not with frequency or counts as the y-axis variable, but rather a probability
    density function as the y-axis variable, where the probability is low when the
    frequency is low and the probability is high when the frequency is high. Otherwise,
    the x-axis represents the range of values in the data, just as it does for histograms:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，密度图是直方图的平滑版本，不允许我们通过实验不同的箱数来扭曲分布形状。我们只向 `ggplot()` 函数传递一个 hustle 变量，然后调用
    `geom_density()` 函数来绘制密度图。R 随后返回一个图表，y 轴变量不是频率或计数，而是一个概率密度函数，其中频率低时概率低，频率高时概率高。否则，x
    轴代表数据中的值范围，就像直方图一样：
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The variable `deflections` *appears* to have a normal distribution and, based
    on the Shapiro-Wilk test results, where the p-value is significantly above the
    0.05 threshold for significance, *is* normally distributed. This same process,
    if it can be called that, will be repeated in the following section against every
    remaining variable in the hustle data set.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 `deflections` *似乎* 是正态分布的，并且根据 Shapiro-Wilk 测试结果，p 值显著高于 0.05 的显著性阈值，*是*
    正态分布的。如果可以称之为这个过程的话，它将在下一节中重复应用于 hustle 数据集中的每个剩余变量。
- en: 5.5.2 Checking other distributions for normality
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.2 检查其他分布的正态性
- en: 'In our next code chunk, we once more take a variable-by-variable approach.
    We’ll run a series of Shapiro-Wilk tests by calling the `shapiro.test()` function
    and also draw a sequence of density plots. The results are then divided into two
    panels (see figures 5.8 and 5.9). A red border will be drawn around any plot displaying
    a non-normal distribution, based on the Shapiro-Wilk test results. Once more,
    the code is more or less repeatable from one plot to the next:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的下一个代码块中，我们再次采取逐变量方法。我们将通过调用 `shapiro.test()` 函数运行一系列 Shapiro-Wilk 测试，并绘制一系列密度图。结果随后分为两个面板（见图
    5.8 和 5.9）。任何显示非正态分布的图表都将根据 Shapiro-Wilk 测试结果绘制红色边框。同样，代码在从一个图表到下一个图表之间几乎是可重复的：
- en: '[PRE22]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![CH05_F08_Sutton](../../OEBPS/Images/CH05_F08_Sutton.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F08_Sutton](../../OEBPS/Images/CH05_F08_Sutton.png)'
- en: Figure 5.8 Density plots for the variables `wins`, `screens_assists`, `screen_assists_pts`,
    and `loose_balls`. All four of these variables are normally distributed due to
    Shapiro-Wilk tests that returned p-values above the 0.05 threshold for significance.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 变量 `wins`、`screens_assists`、`screen_assists_pts` 和 `loose_balls` 的密度图。由于
    Shapiro-Wilk 测试返回的 p 值高于 0.05 的显著性阈值，这四个变量都是正态分布的。
- en: 'Our density plots are then packed into a pair of 4 × 2 matrices:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们的密度图被打包成一对 4 × 2 矩阵：
- en: '[PRE23]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![CH05_F09_Sutton](../../OEBPS/Images/CH05_F09_Sutton.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F09_Sutton](../../OEBPS/Images/CH05_F09_Sutton.png)'
- en: Figure 5.9 Density plots for the variables `charges`, `contested_2pt`, `contested_3pt`,
    and `contested_shots`. Only Charges Drawn isn’t normally distributed.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 变量 `charges`、`contested_2pt`、`contested_3pt` 和 `contested_shots` 的密度图。只有“Charges
    Drawn”不是正态分布。
- en: It turns out that only the variable `charges` has a non-normal distribution
    based on the Shapiro-Wilk tests, drawing a line in the sand where the p-value
    is equal to the predefined 5% threshold for significance. The variables `screen_assists_pts`
    and `contested_2pt` have Shapiro-Wilk p-values barely above 0.05, thereby indicating
    their respective distributions are almost non-normal. But again, we’re applying
    a p-value of 0.05 as a hard cutoff; therefore, we’ll *withhold* the variable charges
    from our linear modeling.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，只有变量 `charges` 的分布不符合正态分布，根据 Shapiro-Wilk 测试，在 p 值等于预定义的 5% 显著性阈值时划出了一条界线。变量
    `screen_assists_pts` 和 `contested_2pt` 的 Shapiro-Wilk p 值仅略高于 0.05，这表明它们的分布几乎是非正态的。但再次强调，我们正在应用
    0.05 的 p 值作为硬截止点；因此，我们将从线性建模中*保留*变量 `charges`。
- en: We nonetheless have several variables still in play. In the following section,
    we’ll visualize and test the correlations between our remaining predictors and
    the variable `wins` to determine which of these might be best candidates for explaining
    and even predicting regular season wins.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们仍有几个变量在考虑范围内。在下一节中，我们将可视化和测试剩余预测变量与变量 `wins` 之间的相关性，以确定其中哪些可能是最佳候选者，用于解释甚至预测常规赛的胜利。
- en: 5.6 Visualizing and testing correlations
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.6 可视化和测试相关性
- en: To recap, we first identified outliers in our data and then subsequently capped
    those same data points so that they equal the maximum or minimum. Second, we tested
    our variables for normality to determine which of these to carry forward and which
    to withhold from any further analysis and testing.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们首先识别了数据中的异常值，然后相应地将这些数据点限制在最大值或最小值。其次，我们测试了变量的正态性，以确定哪些可以继续使用，哪些需要从任何进一步的分析和测试中保留。
- en: Now, we’ll compute the correlation coefficients between the variable `wins`
    and the remaining variables and then visualize the same with a correlation matrix.
    The correlation coefficient will always equal some value between -1 and +1\. When
    a pair of variables has a correlation coefficient equal to or close to +1, we
    can conclude that a positive association exists between them; if their correlation
    coefficient instead equals -1 or close to that, we can alternately conclude that
    a negative association exists between them; and if their correlation coefficient
    is close to 0, then there is no meaningful association at all.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将计算变量 `wins` 与剩余变量之间的相关系数，并使用相关矩阵进行可视化。相关系数始终等于介于 -1 和 +1 之间的某个值。当一对变量的相关系数等于或接近
    +1 时，我们可以得出结论，它们之间存在正相关关系；如果它们的相关系数相反等于 -1 或接近那个值，我们可以交替得出结论，它们之间存在负相关关系；如果它们的相关系数接近
    0，那么它们之间根本不存在有意义的关联。
- en: Our purpose here is to identify which variables might be best fits, or not fits
    at all, as predictors in our linear regression models. This is an especially relevant
    exercise when working with wide data sets as it makes much more sense to further
    examine the data and identify high-potential predictors as opposed to including
    every independent variable in a model regardless of whether any value is being
    added.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里的目的在于确定哪些变量可能是最佳拟合，或者根本不适合，作为线性回归模型中的预测变量。当处理宽数据集时，这是一个特别相关的练习，因为它使得进一步检查数据并识别高潜力预测变量比在模型中包含每个独立变量（无论是否增加任何值）更有意义。
- en: 5.6.1 Prototype
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6.1 原型
- en: The variable `deflections` will again be used for demonstration purposes. The
    base R `cor()` function is called to compute the correlation coefficient between
    the variables `deflections` and `wins`.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 `deflections` 将再次用于演示目的。调用基本的 R `cor()` 函数来计算变量 `deflections` 和 `wins` 之间的相关系数。
- en: 'A `ggplot2` correlation plot is then created to visualize the relationship
    between these same two variables, where the x-axis variable is the potential predictor
    `deflections` and the y-axis variable is the future dependent, or target, variable
    `wins` (see figure 5.10). The correlation coefficient is added as a subtitle,
    and the `geom_smooth()` function is called to draw a regression line through the
    data. We get a correlation plot just like the one we drew in the previous chapter:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后创建一个 `ggplot2` 相关性图来可视化这两个相同变量之间的关系，其中 x 轴变量是潜在的预测变量 `deflections`，y 轴变量是未来的因变量或目标变量
    `wins`（见图 5.10）。相关系数被添加为副标题，并调用 `geom_smooth()` 函数来通过数据绘制回归线。我们得到一个相关性图，就像我们在上一章中绘制的那样：
- en: '[PRE24]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![CH05_F10_Sutton](../../OEBPS/Images/CH05_F10_Sutton.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F10_Sutton](../../OEBPS/Images/CH05_F10_Sutton.png)'
- en: Figure 5.10 A correlation plot that visualizes the relationship between the
    variables `deflections` and `wins`
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 一个可视化 `deflections` 和 `wins` 变量之间关系的相关性图
- en: With the correlation coefficient between `deflections` and `wins` equaling 0.24,
    there is a positive correlation between the two, but the association is otherwise
    unremarkable. Let’s see how this stacks up against other correlation coefficients
    between additional predictors and the variable `wins`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `deflections` 和 `wins` 之间的相关系数为 0.24 时，两者之间存在正相关，但除此之外，这种关联并不引人注目。让我们看看这种关联与其他预测变量与
    `wins` 变量之间的相关系数相比如何。
- en: 5.6.2 Visualizing and testing other correlations
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6.2 可视化和测试其他相关性
- en: As an alternative to plotting correlations serially, there is a big bang option
    that requires just two lines of code. In the first line of the next code chunk,
    we create a data set called hustle2, which is a copy of hustle minus the continuous
    variables `deflections` and `charges` and the factor variables `team`, `season`,
    and `team_season`. The discarded variables are in positions 1-3, 6, and 8.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 作为按顺序绘制相关性的替代方案，有一个大爆炸选项，只需要两行代码。在下一个代码块的第一行中，我们创建了一个名为 hustle2 的数据集，它是 hustle
    的副本，但不包括连续变量 `deflections` 和 `charges` 以及因子变量 `team`、`season` 和 `team_season`。被丢弃的变量位于
    1-3、6 和 8 位置。
- en: 'Then we make a call to the `ggpairs()` function from the `GGally` package,
    thereby producing a matrix that uses a `ggplot2` look and feel to visualize the
    correlations on the left, display the correlation coefficients on the right, and
    plot variable distributions in between. We then add or append a call to the `theme()`
    function in order to rotate our x-axis labels 90 degrees. (See figure 5.11.) Depending
    on your system, this could take several seconds to run:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们调用 `GGally` 包中的 `ggpairs()` 函数，从而生成一个矩阵，该矩阵使用 `ggplot2` 的外观和感觉来可视化左边的相关性，在右边显示相关系数，并在中间绘制变量分布。然后，我们添加或附加对
    `theme()` 函数的调用，以便将 x 轴标签旋转 90 度。（见图 5.11。）根据您的系统，这可能需要几秒钟才能运行：
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![CH05_F11_Sutton](../../OEBPS/Images/CH05_F11_Sutton.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F11_Sutton](../../OEBPS/Images/CH05_F11_Sutton.png)'
- en: Figure 5.11 A correlation matrix that visualizes and computes the correlations
    between a subset of the hustle data set variables
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 一个可视化并计算 hustle 数据集变量子集之间相关性的相关性矩阵
- en: It turns out that none of the remaining hustle variables have a strong correlation
    one way or the other with `wins`; in fact, none have correlation coefficients
    with `wins` equal to or as meaningful as the correlation coefficient between `deflections`
    and `wins`.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，剩余的 hustle 变量中没有任何一个与 `wins` 有强烈的正相关或负相关；事实上，没有一个与 `wins` 的相关系数等于或像 `deflections`
    和 `wins` 之间的相关系数那样有意义。
- en: 'A call to the base R `cor()` function returns a tabular view of these same
    results, which is a faster alternative to calling the `ggpairs()` function and
    rendering a correlation matrix:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 调用基础 R 的 `cor()` 函数返回这些相同结果的表格视图，这是调用 `ggpairs()` 函数并渲染相关性矩阵的更快的替代方案：
- en: '[PRE26]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: That concludes all the linear regression prework. We’ve identified and then
    adjusted outlying values, tested for normality and then determined which subset
    of hustle variables to move forward with, and tested the correlations between
    potential predictors and the variable `wins`. Through this, we’ve determined that
    `deflections`, `contested_2pt`, and `screen_assists_pts` might have greater influence
    on wins than other predictors due to their correlation coefficients, with `wins`
    being the furthest from perfectly neutral.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了所有线性回归的前期工作。我们已识别并调整了异常值，测试了正态性，然后确定了要向前推进的hustle变量子集，并测试了潜在预测变量与变量`wins`之间的相关性。通过这个过程，我们确定`deflections`、`contested_2pt`和`screen_assists_pts`可能比其他预测变量对胜利有更大的影响，因为它们的相关系数较高，而`wins`与完全中性的距离最远。
- en: 5.7 Multiple linear regression
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.7 多元线性回归
- en: Whereas a simple linear regression tests a target variable against just one
    predictor variable (e.g., `wins` against `deflections`), a multiple linear regression
    tests a target variable against two or more predictors. A linear regression *must*
    contain a continuous target variable; the predictors are usually continuous, but
    they can also be categorical. In other words, linear models are intended to predict
    changes in a target variable that can assume any value within some range, such
    as test scores on a scale of 0-100 or regular season wins on a scale of 0-82\.
    By contrast, a *logistic* regression (see chapter 14) contains a binary target
    variable, such as which students will or will not receive a passing grade or which
    NBA teams will or will not complete a regular season with a winning record.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 与仅对一个预测变量（例如`wins`对`deflections`）进行简单线性回归测试的目标变量不同，多元线性回归测试的目标变量与两个或更多预测变量。线性回归*必须*包含一个连续的目标变量；预测变量通常是连续的，但也可以是分类的。换句话说，线性模型旨在预测目标变量在某个范围内的变化，例如0-100分的测试分数或0-82分的常规赛胜利。相比之下，*逻辑回归*（见第14章）包含一个二元目标变量，例如哪些学生会或不会获得及格成绩，或者哪些NBA球队会或不会以胜利的记录完成常规赛。
- en: 'Our immediate objectives are to demonstrate the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要目标是展示以下内容：
- en: How to randomly divide observations in a data set into a pair of mutually exclusive
    subsets, one of which will then be used for model fitting and the other for generating
    predictions
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将数据集中的观测值随机分成两个互斥的子集，其中一个将用于模型拟合，另一个用于生成预测
- en: How to fit a multiple linear regression
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何拟合多元线性回归
- en: How to return model results and interpret the same
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何返回模型结果并解释
- en: How to check for multicollinearity
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何检查多重共线性
- en: How to run model diagnostics and interpret the plots
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何运行模型诊断并解释图表
- en: How to compare two competing linear models where the target variable is the
    same, but each model also contains a different mix of predictor variables
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何比较两个具有相同目标变量（即每个模型也包含不同混合的预测变量）的竞争性线性模型
- en: How to predict
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何预测
- en: That all being said, let’s get going with our regression testing.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，让我们开始我们的回归测试。
- en: 5.7.1 Subsetting data into train and test
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7.1 将数据子集到训练集和测试集
- en: Our multiple regression exercise starts by subsetting 75% of the hustle observations
    into a data set called train and the remaining 25% into test; we’ll fit our linear
    models against train and then predict on test. If instead we were to fit and predict
    on 100% of the records, we would run the risk of overfitting our models; that
    is, they would basically memorize the data and not necessarily respond well to
    new data.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的多元回归练习首先将75%的hustle观测值子集到一个名为train的数据集中，将剩余的25%子集到test中；我们将对train拟合线性模型，然后在test上进行预测。如果我们对100%的记录进行拟合和预测，我们就有可能过度拟合我们的模型；也就是说，它们基本上会记住数据，而不一定对新数据有良好的响应。
- en: 'The following chunk of `dplyr` code first extracts (i.e., filters) every fourth
    observation from the hustle data set and permanently casts the results into a
    new object called test; the row count for test, therefore, equals 23, or approximately
    25% of the 90 observations in hustle. We then call the `anti_join()` function
    to create an object called train that contains the 67 hustle observations not
    already assigned to test:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 以下`dplyr`代码块首先从hustle数据集中提取（即过滤）每第四个观测值，并将结果永久地转换到一个名为test的新对象中；因此，test的行数等于23，大约是hustle中90个观测值的25%。然后我们调用`anti_join()`函数创建一个名为train的对象，它包含67个尚未分配给test的hustle观测值：
- en: '[PRE27]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We then call the `dim()` function twice to return the dimensions of train and
    test, thereby confirming our train and test split worked as designed:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们两次调用`dim()`函数来返回train和test的维度，从而确认我们的训练和测试分割按设计工作：
- en: '[PRE28]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 5.7.2 Fitting the model
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7.2 拟合模型
- en: The `lm()` function from base R is called to fit linear models. Our first model,
    fit1, regresses `wins` against the variables `screen_assists_pts`, `deflections`,
    `loose_balls`, `contested_2pt`, and `contested_shots`. These variables were selected
    as predictors based on the correlation coefficients we just computed.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 来自基础R的`lm()`函数被用来拟合线性模型。我们的第一个模型，fit1，将`wins`对变量`screen_assists_pts`、`deflections`、`loose_balls`、`contested_2pt`和`contested_shots`进行回归。这些变量是基于我们刚刚计算出的相关系数被选为预测变量的。
- en: 'The syntax is simple and straightforward enough. The target variable is separated
    from the predictors by a tilde, the predictors are separated by the addition operator,
    and there’s a pointer to our data source:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 语法简单直接。目标变量通过波浪号与预测变量分隔，预测变量通过加号分隔，并指向我们的数据源：
- en: '[PRE29]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 5.7.3 Returning and interpreting the results
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7.3 返回和解释结果
- en: 'We then call a series of functions from the `broom` package to incrementally
    return the results. A call to the `tidy()` function specifically returns a 6 ×
    5 tibble that, most importantly, contains the coefficient estimates and the p-values:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们调用`broom`包中的一系列函数，逐步返回结果。`tidy()`函数的调用特别返回一个6 × 5的tibble，其中最重要的是包含系数估计和p值：
- en: '[PRE30]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Variables with p-values equal to or less than 0.05 have a statistically significant
    influence on variances in `wins`. We can otherwise combine the coefficient estimates
    returned from the `tidy()` function with actual values from the hustle data set
    to create a linear equation that takes the following form with respect to fit1:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: p值等于或小于0.05的变量对`wins`的方差有统计学上的显著影响。否则，我们可以将`tidy()`函数返回的系数估计与hustle数据集的实际值结合起来，创建一个线性方程，该方程相对于fit1具有以下形式：
- en: '*y* = *B*[0] + *B*[1]*X*[1] + *B*[2]*X*[2] + *B*[3]*X*[3] + *B*[4]*X*[4] +
    *B*[5]*X*[5]'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '*y* = *B*[0] + *B*[1]*X*[1] + *B*[2]*X*[2] + *B*[3]*X*[3] + *B*[4]*X*[4] +
    *B*[5]*X*[5]'
- en: 'In this equation, note the following:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，请注意以下内容：
- en: '*y* is the predicted value of the dependent variable `wins`.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y*是因变量`wins`的预测值。'
- en: '*B*[0] is the y-intercept, or constant term; it represents the value at which
    the fitted regression line crosses the y-axis.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*B*[0]是y截距，或常数项；它表示拟合回归线与y轴交叉的值。'
- en: '*B*[1]*X*[1] is the regression coefficient of the first fit1 predictor, `screen_assists_pts`,
    where *B*[1] equals 1.04, and *X*[1] is the average number of points scored per
    game off of set screens.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*B*[1]*X*[1]是第一个fit1预测变量`screen_assists_pts`的回归系数，其中*B*[1]等于1.04，而*X*[1]是每场比赛通过挡拆得分平均得分点数。'
- en: '*B*[2]*X*[2] is the regression coefficient of the second predictor, `deflections`,
    where *B*[2] equals 2.23, and *X*[2] is the average number of deflections per
    game.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*B*[2]*X*[2]是第二个预测变量`deflections`的回归系数，其中*B*[2]等于2.23，而*X*[2]是每场比赛的平均折返次数。'
- en: '*B*[3]*X*[3] is the regression coefficient of `loose_balls`, or 5.38 times
    the average number of loose balls recovered per game.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*B*[3]*X*[3]是`loose_balls`的回归系数，即5.38乘以每场比赛平均找回的松球次数。'
- en: '*B*[4]*X*[4] is the regression coefficient of `contested_2pt`, or 0.53 times
    the average number of two-point shot attempts contested per game.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*B*[4]*X*[4]是`contested_2pt`的回归系数，即0.53乘以每场比赛平均被争抢的两分投篮次数。'
- en: '*B*[5]*X*[5] is the regression coefficient of `contested_shots`, or -0.24 multiplied
    by the average number of total shot attempts contested per game.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*B*[5]*X*[5]是`contested_shots`的回归系数，即-0.24乘以每场比赛平均被争抢的总投篮次数。'
- en: 'Let’s insert the relevant hustle statistics for the 2016-17 Miami Heat into
    our fit1 linear equation to demonstrate these results. The Heat averaged 22.3
    points off screens, 14.2 deflections, 7.2 loose balls recovered, 45.5 two-point
    shot attempts contested, and 64.7 total shots contested per game during the 2016-17
    regular season. Successive calls to the `dplyr filter``()` and `select()` functions
    pull a subset of the MIA 17 record from the hustle data set:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将2016-17赛季迈阿密热火的相关hustle统计数据插入fit1线性方程中，以展示这些结果。在2016-17赛季常规赛中，热火每场比赛平均通过挡拆得分22.3分，14.2次折返，7.2次找回松球，45.5次被争抢的两分投篮次数，以及64.7次被争抢的总投篮次数。连续调用`dplyr
    filter()`和`select()`函数从hustle数据集中提取MIA 17记录的子集：
- en: '[PRE31]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Our linear regression would therefore “predict” (these figures were generated
    from train and not from test) Miami’s win total as such:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的线性回归将“预测”（这些数字是从训练数据生成的，而不是测试数据）迈阿密的胜场总数如下：
- en: '[PRE32]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Minus an error term, fit1 predicts 39 wins for the 2016-17 Heat (this was rounded
    to the nearest whole number by combining the `print()` function with the base
    R `round()` function), and the Heat actually won 41 games that season. That’s
    not bad; however, subsequent evidence will reveal that fit1 is *way* more accurate
    when it comes to predicting regular season wins for .500 teams such as the 2016-17
    Heat than for teams like the 2017-18 Houston Rockets, who won 65 games, or the
    2018-19 New York Knicks, who won just 17 games. (Every NBA team plays an 82-game
    regular-season schedule.)
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 减去误差项后，fit1 预测 2016-17 热队将赢得 39 场胜利（这是通过将 `print()` 函数与基础 R 的 `round()` 函数结合来四舍五入到最接近的整数），而该赛季热队实际上赢得了
    41 场比赛。这还不错；然而，后续的证据将揭示，fit1 在预测 .500 级别球队（如 2016-17 热队）的常规赛胜场数时比预测像 2017-18 胡斯顿火箭队（赢得
    65 场比赛）或 2018-19 纽约尼克斯队（仅赢得 17 场比赛）这样的球队时更加准确。（每个 NBA 球队都参加 82 场常规赛的比赛。）
- en: 'Let’s now pretend the Heat actually recovered 8.2 loose balls per game rather
    than 7.2; in that case, fit1 would instead predict 44 wins (again, this has been
    rounded to the nearest whole number). We get to this by changing out 7.2 for 8.2
    in our linear equation. More fundamentally, however, for every unit increase (or
    decrease) in the variable `loose_balls`, the predicted value for `wins` will increase
    (or decrease) by 5.38\. By the same token, if the Heat had managed to deflect
    one more pass per game, fit1 would then predict 2.23 more wins (everything else
    being equal):'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们假设热队实际上每场比赛回收了 8.2 个松散的球，而不是 7.2 个；在这种情况下，fit1 将预测 44 场胜利（同样，这已经被四舍五入到最接近的整数）。我们通过将线性方程中的
    7.2 替换为 8.2 来得到这个结果。然而，从根本上说，对于变量 `loose_balls` 的每单位增加（或减少），对 `wins` 的预测值将增加（或减少）5.38。同样，如果热队能够每场比赛多拦截一次传球，fit1
    将预测多赢得 2.23 场胜利（其他条件保持不变）：
- en: '[PRE33]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Not all fit1 predictors, however, have a statistically significant influence
    on wins. Only the variables `screen_assists_pts`, `deflections`, and `loose_balls`
    have p-values below the generally accepted and our predefined 0.05 threshold for
    significance, whereas the variables `contest_2pt` and `contested_shots` have p-values
    significantly above the 5% threshold. Therefore, our first multiple linear regression
    has revealed that only *some* hustle statistics have a significant influence on
    regular season win counts.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非所有 fit1 预测变量都对胜场数有统计学上的显著影响。只有 `screen_assists_pts`、`deflections` 和 `loose_balls`
    这三个变量的 p 值低于通常接受的和预定义的 0.05 显著性阈值，而 `contest_2pt` 和 `contested_shots` 这两个变量的 p
    值则显著高于 5% 的阈值。因此，我们的第一次多元线性回归揭示了只有 *一些* 疯狂统计数据对常规赛胜场数有显著影响。
- en: 'The `augment()` function from the `broom` package returns, among other things,
    actual values for wins as well as the fitted values for the same; the results
    are cast into a tibble called fit1_tbl. We then make a pair of calls to the `head()`
    function to return, at first, the top six values for the variable `wins`, and
    second, the top six values for the variable `.fitted`:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 `broom` 包的 `augment()` 函数返回了诸如实际胜场数以及相同数据的拟合值等数据；结果被转换为一个名为 fit1_tbl 的 tibble。然后我们调用
    `head()` 函数两次，首先返回变量 `wins` 的前六个值，其次返回变量 `.fitted` 的前六个值：
- en: '[PRE34]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Then, in the following chunk of `dplyr` code, we first call the `mutate()`
    function to create a new variable, `wins_dif`, which is the absolute difference
    (note the call to the base R `abs()` function) between the fit1_tbl variables
    `wins` and `.fitted`. We then call the `mean()` function from base R to compute
    the average difference between actual wins and fitted wins from fit1_tbl:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在下面的 `dplyr` 代码块中，我们首先调用 `mutate()` 函数创建一个新变量 `wins_dif`，它是 fit1_tbl 变量 `wins`
    和 `.fitted` 之间的绝对差值（注意对基础 R 的 `abs()` 函数的调用）。然后我们调用基础 R 的 `mean()` 函数来计算实际胜场数和拟合胜场数之间的平均差异：
- en: '[PRE35]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: On average, our fit1 linear equation returned regular season win counts that
    are 8.27 wins above or below actual regular season win counts.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 平均而言，我们的 fit1 线性方程返回的常规赛胜场数比实际常规赛胜场数多 8.27 场或少 8.27 场。
- en: Finally, the `glance()` function from the `broom` package returns, most significantly,
    the R-squared (R²) and adjusted R² statistics. R² is a statistical measure that
    represents the proportion of the variance in the target variable explained by
    the predictors. It therefore equals some number between 0 and 1, where a value
    of 1 indicates that the predictors explain all the variance, and a value of 0
    indicates that the predictors fail to explain any of the variance.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`broom`包中的`glance()`函数返回最重要的R-squared（R²）和调整后的R²统计量。R²是一个统计量，表示目标变量中由预测因子解释的方差比例。因此，它等于0到1之间的某个数字，其中1表示预测因子解释了所有方差，而0表示预测因子未能解释任何方差。
- en: 'Adjusted R² is a modified version of R² in that it takes into account the number
    of predictors. While R² will naturally increase as other predictors are added
    to a regression model, adjusted R² will actually decrease if those same predictors
    aren’t contributing to the model’s predictive power. The more complex the model,
    the more R² and adjusted R² will diverge:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 调整后的R²是R²的修改版，它考虑了预测因子的数量。虽然当其他预测因子被添加到回归模型中时，R²自然会增加，但如果这些相同的预测因子没有对模型的预测能力做出贡献，调整后的R²实际上会减少。模型越复杂，R²和调整后的R²的差异就越大：
- en: '[PRE36]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Because R² equals 0.20, the fit1 predictors collectively explain approximately
    20% of the variance in regular season wins, regardless of their respective p-values,
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 因为R²等于0.20，所以fit1预测因子共同解释了常规赛胜利变化的约20%，无论它们的各自p值如何。
- en: But the adjusted R² equals just 0.14, no doubt due to the fact that fit1 contains
    a pair of predictors, `contested_2pt` and `contested_shots`, that don’t have statistically
    significant influences on wins due to their respective p-values being above the
    5% threshold. In other words, our model contains noise. So based on this measure,
    it would actually be more accurate to say that fit1 best explains about 14%, rather
    than 20%, of the variance in wins.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 但调整后的R²仅为0.14，毫无疑问，这是由于fit1包含一对预测因子`contested_2pt`和`contested_shots`，由于它们的各自p值高于5%的阈值，因此对胜利没有统计学上的显著影响。换句话说，我们的模型包含噪声。因此，根据这个度量，实际上更准确的说法是fit1最好解释了胜利变化的14%，而不是20%。
- en: 5.7.4 Checking for multicollinearity
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7.4 检查多重共线性
- en: Let’s now check for multicollinearity in fit1\. Once more, multicollinearity
    is a situation in which two or more predictors are highly correlated; that is,
    the correlation coefficient between them is equal to or close to +1\. The most
    significant consequence of multicollinearity is that it artificially inflates
    the explained variance. As we just mentioned, R² will automatically and incrementally
    increase in value with each additional predictor; at the same time, adjusted R²
    will decrease, but not so much if the additional predictors by themselves are
    statistically significant. But where and when there is multicollinearity, we’re
    actually double counting; as a result, both the R² and adjusted R² measures will
    be artificially high.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查fit1中的多重共线性。再次强调，多重共线性是指两个或更多预测因子高度相关的情况；也就是说，它们之间的相关系数等于或接近+1。多重共线性的最显著后果是它人为地增加了解释的方差。正如我们刚才提到的，随着每个额外预测因子的增加，R²会自动和递增地增加；同时，调整后的R²会减少，但如果额外的预测因子本身在统计学上是显著的，那么减少的幅度不会很大。但是，当存在多重共线性时，我们实际上是在重复计算；因此，R²和调整后的R²度量都会被人为地提高。
- en: 'We make a call to the `vif()` function from the `car` package to test for multicollinearity.
    Based on the correlation tests we ran earlier, it’s doubtful fit1 contains a presence
    of multicollinearity, but it’s nevertheless a best practice to test for it to
    ensure we’re not overfitting:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`car`包中调用`vif()`函数来测试多重共线性。根据我们之前进行的相关性测试，fit1可能不包含多重共线性，但无论如何，测试它是一个最佳实践，以确保我们没有过度拟合：
- en: '[PRE37]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: If the variance inflation factor for any of the fit1 predictors is above 5,
    we should discard those variables and then fit a reduced model, that is, a model
    with fewer predictors. But as we can see, the variance inflation factor for all
    fit1 predictors is less than 5.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果fit1预测因子的方差膨胀因子中任何一个超过5，我们应该丢弃这些变量，然后拟合一个简化模型，即具有较少预测因子的模型。但正如我们所看到的，fit1所有预测因子的方差膨胀因子都小于5。
- en: 5.7.5 Running and interpreting model diagnostics
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7.5 运行和解释模型诊断
- en: 'The `plot()` function from base R returns the model diagnostics around linearity
    and normality (see figure 5.12). These are printed in a 2 × 2 matrix when `plot()`
    is preceded by the base R `par()` function. The plots confirm that fit1 satisfies
    prerequisites for linearity and normality, thereby validating the integrity of
    our first model, even if we might not be wholly satisfied with the results:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 来自基础R的`plot()`函数返回关于线性和正态性的模型诊断（见图5.12）。当`plot()`函数前有基础R的`par()`函数时，这些诊断信息会以2×2矩阵的形式打印出来。这些图表明fit1满足线性和正态性的先决条件，从而验证了我们第一个模型的完整性，即使我们可能对结果并不完全满意：
- en: '[PRE38]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '![CH05_F12_Sutton](../../OEBPS/Images/CH05_F12_Sutton.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F12_Sutton](../../OEBPS/Images/CH05_F12_Sutton.png)'
- en: Figure 5.12 Model diagnostics for the first multiple linear regression model
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.12 第一个多元线性回归模型的模型诊断
- en: Diagnostic plots help us assess the goodness of fit and validate going-in assumptions
    around linearity and normality. Let’s go through these one by one.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断图帮助我们评估拟合优度，并验证关于线性和正态性的初始假设。让我们逐一分析。
- en: The Residuals vs. Fitted plot in the upper-left quadrant displays the model
    residuals along the y-axis and the fitted values along the x-axis. A residual
    is a measure of the vertical distance from an actual value to the fitted regression
    line; the model residuals, or errors, should follow a normal distribution. The
    data points more or less hover around the horizontal line instead of following
    some obvious pattern, which is a good thing because it strongly suggests that
    the residuals do follow a normal distribution.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 上左象限的残差与拟合值图显示了模型残差沿y轴和拟合值沿x轴。残差是从实际值到拟合回归线的垂直距离的度量；模型残差或误差应该遵循正态分布。数据点大致围绕水平线浮动，而不是遵循某种明显的模式，这是好事，因为它强烈表明残差确实遵循正态分布。
- en: The Normal QQ plot in the upper-right quadrant is yet another check on whether
    the residuals follow a normal distribution. It compares the residuals, which are
    divided into quantiles, or four equal-sized proportions, against the quantiles
    of a theoretical normal distribution; the former is plotted along the y-axis,
    and the latter is plotted along the x-axis. Note that both data series have been
    converted to standardized scales. The residuals follow the diagonal line without
    any severe deviation, as they should. The alignment is hardly perfect, of course,
    and we do see some moderate deviation at both tails, but there’s nothing here
    to trigger any serious concerns about normality and linearity or lack thereof.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 右上象限的正常Q-Q图是检查残差是否遵循正态分布的另一种检查。它将残差（已分为分位数，或四个相等大小的比例）与理论正态分布的分位数进行比较；前者沿y轴绘制，后者沿x轴绘制。请注意，这两个数据系列都已转换为标准化尺度。残差应遵循对角线，没有任何严重的偏差，正如它们应该的那样。当然，对齐并不完美，我们确实看到两端有一些中等程度的偏差，但这里没有什么可以引起我们对正态性和线性或缺乏线性有任何严重担忧的。
- en: The Scale-Location plot in the lower-left quadrant, also known as a spread-location
    plot or a square root of standardized residual plot, is used to assess what’s
    called homoscedasticity. It also plots the square root of the standardized residuals
    along the y-axis and the fitted values along the x-axis. Homoscedasticity refers
    to a statistical assumption in regression analysis where the variance in the residuals—that
    is, the difference between the actual and fitted values—is constant across all
    levels of the predictors. In other words, it expects that the spread, or dispersion,
    of the residuals is more or less the same throughout the range of independent
    variables. The Scale-Location plot should and does resemble the Residuals vs.
    Fitted plot.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 左下象限的尺度-位置图，也称为散点-位置图或标准化残差的平方根图，用于评估所谓的同方差性。它还沿y轴绘制标准化残差的平方根，沿x轴绘制拟合值。同方差性是指回归分析中的一个统计假设，即残差（即实际值与拟合值之间的差异）的方差在所有预测变量的水平上都是恒定的。换句话说，它期望残差的分布或分散在整个独立变量的范围内大致相同。尺度-位置图应该并且确实类似于残差与拟合值图。
- en: The Residuals vs. Leverage plot in the lower-right quadrant, more frequently
    called a Cook’s Distance plot, is used to isolate any observations—outliers, basically—that
    have undue influence on the fitted regression line. It also plots the standardized
    residuals along the y-axis and what are called leverage values along the x-axis.
    Leverage values represent the influence of each observation. We’re particularly
    concerned about any data points that fall below the dashed horizontal line annotated
    as Cook’s Distance, and, of course, we have a few of those. But our actual concern
    should be focused on any data points below that line and in the lower-right corner,
    and we see only one observation that satisfies both criteria. Our results aren’t
    perfect (they rarely are in the real world), but we don’t have any cause for alarm
    or any reason to change course.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在右下象限的残差与杠杆作用图，更常被称为库克距离图，用于隔离任何观察值——基本上是异常值——它们对拟合回归线有过度的影响。它还沿 y 轴绘制了标准化残差，以及称为杠杆值的
    x 轴。杠杆值代表每个观察值的影响。我们特别关注任何低于标注为库克距离的虚线水平线的数据点，当然，我们有一些这样的数据点。但我们的实际关注点应该集中在那条线以下和右下角的数据点，我们看到只有一个观察值同时满足这两个条件。我们的结果并不完美（在现实世界中很少完美），但我们没有理由感到恐慌或改变方向。
- en: 5.7.6 Comparing models
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7.6 模型比较
- en: 'A logical next step would be to remove that one observation from train and
    then rerun our regression, but we’re going to take a bigger next step instead.
    Because only a subset of the fit1 predictors has a statistically significant influence
    on wins, we’ll now fit a second multiple regression where the predictors `screen_assist_pts`,
    `deflections`, and `loose_balls` remain in play, but the predictors `contested_2pt`
    and `contested_shots` are excluded. Therefore, our second regression, named fit2,
    is merely a reduced version of fit1\. Subsequent calls to the `tidy``()`, `augment``()`,
    `glance``()`, and other functions return the results, and figure 5.13 displays
    the diagnostics:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 合理的下一步是将那个观察值从训练数据中移除，然后重新运行我们的回归，但我们将采取更大的下一步。因为只有 fit1 预测器中的一部分对胜利有统计学上的显著影响，我们现在将拟合第二个多重回归模型，其中预测器
    `screen_assist_pts`、`deflections` 和 `loose_balls` 仍然有效，但预测器 `contested_2pt` 和
    `contested_shots` 被排除在外。因此，我们的第二个回归，命名为 fit2，仅仅是 fit1 的简化版本。随后的 `tidy()`、`augment()`、`glance()`
    等函数调用返回结果，图 5.13 显示了诊断结果：
- en: '[PRE39]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '![CH05_F13_Sutton](../../OEBPS/Images/CH05_F13_Sutton.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F13_Sutton](../../OEBPS/Images/CH05_F13_Sutton.png)'
- en: Figure 5.13 Model diagnostics for the second, or reduced, multiple linear regression
    model
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13 第二个，或简化的，多重线性回归模型模型诊断
- en: 'Of the two fitted regressions, fit2 is a better model than fit1, at least for
    the following reasons:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个拟合回归模型中，fit2 模型相对于 fit1 模型来说是一个更好的模型，至少有以下原因：
- en: There’s no noise in fit2—all fit2 predictors have p-values below the predefined
    0.05 threshold for significance.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fit2 模型中没有噪声——所有 fit2 预测器的 p 值都低于预定义的 0.05 显著性阈值。
- en: 'Our second regression is merely a reduced version of our first model, yet fit2
    better explains the variance in wins, albeit slightly, than fit1: the adjusted
    R² statistic for fit2 equals 0.16 versus 0.14 for fit1\. That isn’t to say fit2
    explains the variance in wins *well*—but hold that thought.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的第二个回归模型仅仅是第一个模型的简化版本，但 fit2 模型比 fit1 模型更好地解释了胜利的方差，尽管这种改善很小：fit2 的调整 R² 统计量为
    0.16，而 fit1 的为 0.14。这并不是说 fit2 能够很好地解释胜利的方差——但请记住这个想法。
- en: Our second model has a lower and therefore better Akaike Information Criterion
    (AIC) score than does our first model. AIC is one of the measures returned from
    the `glance()` function; alternatively, you can call the base R `AIC()` function
    to return the same. The best-fit model according to AIC is the one that explains
    most of the variance in a target variable using the smallest number of predictors;
    as such, it uses the independent variable count and the log-likelihood estimate—that
    is, the likelihood that a model could have generated observed y-values—as inputs.
    AIC is fairly meaningless by itself, but it’s a key measure for comparing competing
    models. Furthermore, there’s a rule of thumb that suggests that when one model
    has an AIC score two or more units lower than a competing model, the model with
    the lower AIC is a *significantly* better fit than the other model. Well, the
    AIC for fit1 equals 518, and the AIC for fit2 equals 514.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的第二个模型比第一个模型具有更低的AIC得分，因此更好。AIC是`glance()`函数返回的度量之一；或者，您也可以调用基础R的`AIC()`函数来返回相同的值。根据AIC，最佳拟合模型是使用最少的预测因子来解释目标变量中大部分变差的模型；因此，它使用独立变量计数和对数似然估计作为输入。AIC本身没有太大意义，但它是比较竞争模型的关键度量。此外，有一个经验法则表明，当一个模型的AIC得分比竞争模型低两个或更多单位时，具有较低AIC的模型比其他模型*显著*更好。嗯，fit1的AIC为518，fit2的AIC为514。
- en: The diagnostics are slightly better with fit2 than with fit1 primarily because
    the Residuals vs. Leverage plot doesn’t contain any observations below the Cook’s
    Distance line.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与fit1相比，fit2的诊断结果略好，主要是因为残差与杠杆作用图没有包含任何低于Cook距离线的观测值。
- en: However, the average difference between actual and fitted wins is slightly greater
    in fit2 (8.43) versus fit1 (8.27), but this is hardly anything to haggle over
    given all the other results.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，实际和拟合胜利次数之间的平均差异在fit2（8.43）中略大于fit1（8.27），但考虑到所有其他结果，这几乎微不足道。
- en: 5.7.7 Predicting
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7.7 预测
- en: Let’s now see how fit2 performs on test. We therefore make a call to the base
    R `predict()` function to predict regular season wins, bounded by a 95% lower
    and upper confidence interval (CI). The CI is a range of values less than and
    greater than the predicted value for y that we can be 95% confident contains the
    actual value for y.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看fit2在测试中的表现。因此，我们调用基础R的`predict()`函数来预测常规赛胜利次数，上下限分别为95%的置信区间（CI）。置信区间是一个范围，其中包含小于和大于预测值y的值，我们可以有95%的信心认为它包含y的实际值。
- en: 'Three arguments are passed to the `predict()` function: the model and the data
    source are required while the CI, defaulted to 95%, is optional. The results are
    cast into an object called fit2_pred, where fit equals the predicted number of
    regular season wins, `lwr` represents the low end of our CI, and `upr` represents
    the high end of our CI:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict()`函数传递了三个参数：模型和数据源是必需的，而置信区间（CI），默认为95%，是可选的。结果被转换成一个名为fit2_pred的对象，其中fit等于预测的常规赛胜利次数，`lwr`代表置信区间的下限，`upr`代表置信区间的上限：'
- en: '[PRE40]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We then call the `select()` function from the `dplyr` package to reduce the
    test data set to include only the variable `wins`:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们调用`dplyr`包中的`select()`函数，将测试数据集减少到只包含变量`wins`：
- en: '[PRE41]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Next, we call the `cbind()` function from base R to join fit2_pred and test
    vertically and then the `mutate()` function from `dplyr` to create a new variable
    called `wins_dif`, which equals the absolute difference between the variables
    `wins` and `fit`. The results are thrown into a new object called fit_tbl_pred.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们调用基础R中的`cbind()`函数将fit2_pred和test垂直连接，然后调用`dplyr`中的`mutate()`函数创建一个名为`wins_dif`的新变量，该变量等于变量`wins`和`fit`之间的绝对差值。结果被放入一个名为fit_tbl_pred的新对象中。
- en: 'Finally, we compute the average of `wins_dif` using the `mean()` function from
    base R. The result equals 9.94, thereby suggesting that our second regression
    performs worse on test than it did against train:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用基础R中的`mean()`函数计算`wins_dif`的平均值。结果等于9.94，这表明我们的第二个回归在测试中的表现不如在训练中好：
- en: '[PRE42]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'A `ggplot2` histogram plots the frequency distribution of the fit_tbl_pred
    variable `wins_dif`, or the difference between actual and predicted wins (see
    figure 5.14):'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '`ggplot2`直方图绘制了fit_tbl_pred变量`wins_dif`的频率分布，即实际和预测胜利次数之间的差异（见图5.14）：'
- en: '[PRE43]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![CH05_F14_Sutton](../../OEBPS/Images/CH05_F14_Sutton.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F14_Sutton](../../OEBPS/Images/CH05_F14_Sutton.png)'
- en: Figure 5.14 Frequency distribution displaying the absolute differences between
    predicted and actual regular season wins
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.14 显示预测胜利与实际常规赛胜利之间绝对差异的频率分布
- en: We get more accurate results when actual regular season wins equal 41 or thereabouts;
    conversely, we get less accurate results when teams won either very few or very
    many regular season games in an 82-game schedule.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 当实际常规赛胜利为 41 或左右时，我们得到更准确的结果；相反，当球队在一个 82 场的赛程中赢得的比赛非常少或非常多时，我们得到的结果就不那么准确了。
- en: 'The following short chunks of `dplyr` code return the fit_tbl_pred records
    where the variable `wins_dif` is greater than 15 and again where the same variable
    is less than 5:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 以下简短的 `dplyr` 代码块返回 `fit_tbl_pred` 记录，其中变量 `wins_dif` 大于 15，以及当同一变量小于 5 时的记录：
- en: '[PRE44]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: A second `ggplot2` object, a line chart, compares actual wins with predicted
    wins, with the shaded areas immediately above and below the predicted values representing
    the upper and lower CIs (see figure 5.15).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个 `ggplot2` 对象，一个折线图，比较实际胜利与预测胜利，预测值上方和下方的阴影区域代表上、下置信区间（见图 5.15）。
- en: '![CH05_F15_Sutton](../../OEBPS/Images/CH05_F15_Sutton.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F15_Sutton](../../OEBPS/Images/CH05_F15_Sutton.png)'
- en: Figure 5.15 Another view between predicted and actual regular season wins
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.15 预测胜利与实际常规赛胜利的另一种视角
- en: 'But first, we call the `dplyr arrange()` function to sort fit_tbl_pred by the
    variable `wins` in ascending order and then append a new variable called `row.num`.
    This approach helps to make it more obvious that fit2 does a much better job of
    predicting wins for teams that finished at or near .500 versus teams that had
    an extreme number of regular season wins:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，我们调用 `dplyr arrange()` 函数按变量 `wins` 的升序对 fit_tbl_pred 进行排序，然后添加一个名为 `row.num`
    的新变量。这种方法有助于更明显地看出 fit2 在预测胜率接近或等于 .500 的球队方面做得比极端常规赛胜利数的球队要好得多：
- en: '[PRE45]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: If our goal had been to fit a multiple linear regression to mostly account for
    the variance in wins from the 2016-17 to 2018-19 NBA regular seasons, then we
    would need a wider data set to include variables such as shots made and attempted,
    free throws made and attempted, turnover margin, and so on. Neither of our regressions,
    after all, adequately explain or predict regular season wins terribly well.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的目标是拟合一个多元线性回归，主要解释 2016-17 到 2018-19 NBA 常规赛季胜利的方差，那么我们需要一个更广泛的数据集来包括诸如投篮命中和尝试、罚球命中和尝试、失误率等变量。毕竟，我们的回归都没有很好地解释或预测常规赛胜利。
- en: But our goal was more modest, or at least quite different from this. Our purpose
    instead was to identify which hustle statistics might have a statistically significant
    influence on wins and to quantify the effect of that influence. To that purpose,
    we’ve shown that points off screens, deflections, and loose balls recovered explain
    roughly 16% of the variance in regular season wins, which is far from insignificant.
    We’ve also discovered where and when it makes the most sense for players to give
    100% efforts and where and when there isn’t an equal return. Now, let’s see what
    sort of insights a regression tree might reveal.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们的目标更为谦逊，或者至少与这个目标大相径庭。我们的目的是确定哪些 hustle 统计数据可能对胜利有统计学上的显著影响，并量化这种影响的效果。为此，我们已经表明，出界、折射和失球回收解释了常规赛胜利中大约
    16% 的方差，这远非微不足道。我们还发现了球员何时何地应该全力以赴，何时何地并不存在等价的回报。现在，让我们看看回归树可能揭示出什么样的见解。
- en: 5.8 Regression tree
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.8 回归树
- en: Regression trees, frequently referred to as decision tree regressions, are relatively
    easy to construct and just as easy to interpret and explain; their downside is
    that they are often less accurate than other supervised learning methods. For
    this reason, data scientists sometimes pivot toward bagging, random forest, and
    boosting models; each of these methods involves generating *many* trees, rather
    than just one, which are then combined to form a single prediction.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 回归树，通常被称为决策树回归，相对容易构建，同样容易解释和说明；它们的缺点是通常不如其他监督学习方法准确。因此，数据科学家有时会转向 bagging、随机森林和
    boosting 模型；这些方法中的每一种都涉及生成 *许多* 树，而不是仅仅一棵，然后将这些树组合起来形成一个单一的预测。
- en: 'At a very basic level, regression trees segment the data into multiple regions
    of predictor space. Jumping ahead, the top of our regression tree splits the data
    into two regions: one where `screen_assists_pts` is greater than 26.05, and another
    where the same variable is less than 26.05\. Splits at the top of the upside-down
    tree are more significant than splits at or near the bottom.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在非常基本的层面上，回归树将数据分割成多个预测空间区域。跳过一些内容，我们的回归树顶部将数据分割成两个区域：一个 `screen_assists_pts`
    大于26.05的区域，另一个是相同变量小于26.05的区域。倒置树顶部的分割比底部或接近底部的分割更显著。
- en: A regression tree is fit by calling the `tree()` function from the `tree` package.
    There are other R packages and functions, by the way, for fitting tree-based models
    and visualizing the results; in fact, with almost anything in R, there is usually
    more than one option or alternative, and one isn’t necessarily better or worse
    than the others.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从 `tree` 包调用 `tree()` 函数来拟合回归树。顺便说一句，还有其他R包和函数用于拟合基于树的模型并可视化结果；事实上，在R中，几乎所有事情通常都有不止一个选项或替代方案，而且一个不一定比其他的好或坏。
- en: 'Our model contains the five predictors from our original multiple linear regression;
    additionally, we’ll use the previous 75% split from the hustle data set called
    train as our data source. Note that the syntax is very similar to that of a multiple
    regression. A subsequent call to the `summary()` function returns the results:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模式包含来自原始多元线性回归的五个预测因子；此外，我们将从名为train的 hustle 数据集的前75%分割用作我们的数据源。请注意，语法与多元回归非常相似。对
    `summary()` 函数的后续调用返回结果：
- en: '[PRE46]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Not every regression tree is necessarily constructed using every predictor in
    the model, but based on the fit3 results, our tree will contain one or more branches
    for each predictor variable. We know this, or can at least assume as much, because
    the model output would have otherwise called out the *subset* of predictors used
    in constructing the tree. We also know that our tree will contain 10 terminal
    nodes (i.e., leaves)—these are the endpoints at the bottom of the tree to which
    predicted regular season wins are affixed. Finally, the square root of the residual
    mean deviance, equal to 9.10, is the rough equivalent to the average difference
    between predicted and actual wins from our multiple regressions, which makes fit3
    competitive to fit2, though less accurate.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 并非每个回归树都必须使用模型中的每个预测因子构建，但根据fit3的结果，我们的树将包含每个预测变量的一或多个分支。我们知道这一点，或者至少可以假设如此，因为模型输出否则会指出构建树时使用的
    *子集* 预测因子。我们还知道我们的树将包含10个终端节点（即叶子节点）——这些是树底部的端点，预测的常规赛胜利数将附加在这些端点上。最后，残差均方差的平方根，等于9.10，大致相当于我们多元回归中预测胜利数与实际胜利数之间的平均差异，这使得fit3与fit2具有竞争力，尽管精度较低。
- en: 'To plot our regression tree, we call the `plot``()` and `text()` functions
    from base R in succession (see figure 5.16); `plot()` draws the tree, and `text()`
    adds the variable names and conditions:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 要绘制我们的回归树，我们连续调用基础R中的 `plot()` 和 `text()` 函数（见图5.16）；`plot()` 绘制树，`text()` 添加变量名称和条件：
- en: '[PRE47]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '![CH05_F16_Sutton](../../OEBPS/Images/CH05_F16_Sutton.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F16_Sutton](../../OEBPS/Images/CH05_F16_Sutton.png)'
- en: Figure 5.16 The visualized results of our regression tree
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.16 我们回归树的可视化结果
- en: According to our regression tree
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的回归树
- en: Teams that average more than 26.05 points off screens per game can be expected
    to win 50 or 51 regular season games.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每场比赛平均得分超过26.05分的球队预计将在50或51场常规赛中获胜。
- en: Alternatively, teams that average fewer than 26.05 points off screens per game
    can be expected to win anywhere between 27 and 51 regular season games, depending
    on other variables and other splits.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者，每场比赛平均得分少于26.05分的球队预计将在27到51场常规赛中获胜，具体取决于其他变量和其他分割。
- en: Teams that average fewer than 26.05 points off screens and fewer than 12.85
    deflections per game can be expected to win somewhere between 27 and 37 regular
    season games.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每场比赛平均得分少于26.05分且防守反击次数少于12.85次的球队预计将在27到37场常规赛中获胜。
- en: Teams that average fewer than 26.05 points off screens but more than 12.85 deflections
    per game can be expected to win somewhere between 31 and 51 regular season games.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每场比赛平均得分少于26.05分但防守反击次数超过12.85次的球队预计将在31到51场常规赛中获胜。
- en: There’s a one-to-one correlation between if-else rules and splits in the tree.
    Our regression tree, therefore, produces results that tie back well to our multiple
    regressions *and* provide additional insights through a series of if-else rules
    that linear models can’t return. The predictors `screen_assists_pts`, `deflections`,
    and `loose_balls` are more significant than `contested_2pt` and `contested_shots`,
    according to both model types tested here. And while neither model predicts wins
    with much certainty, our goal was to identify which of these hustle statistics
    has more of an influence on regular season wins than other like statistics.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果-否则规则与树形图中的分支之间存在一一对应的关系。因此，我们的回归树产生的结果不仅与我们的多重回归相吻合，而且通过一系列如果-否则规则提供了线性模型无法提供的额外见解。根据这里测试的两种模型类型，预测因子`screen_assists_pts`、`deflections`和`loose_balls`比`contested_2pt`和`contested_shots`更为重要。尽管这两种模型都无法非常准确地预测胜利，但我们的目标是确定这些努力统计数据中哪一个对常规赛胜利的影响比其他类似统计数据更大。
- en: At the end of the day, we’ve determined that setting screens on offense, which
    creates unfettered shot opportunities; deflecting passes on defense, which disrupts
    the opponent’s offense; and grabbing loose balls while on offense or defense deserve
    a 100% effort, while other so-called hustle plays don’t. Thus, we’ve confirmed
    our hypothesis that *some* hustle statistics do, in fact, have a statistically
    significant effect on wins and losses.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们确定在进攻端设置掩护，创造无拘无束的投篮机会；在防守端挡掉传球，扰乱对手的进攻；以及在进攻或防守时抢断球，都值得付出百分之一百的努力，而其他所谓的努力表现则不然。因此，我们证实了我们的假设，即**某些**努力统计数据确实对胜负有统计学上的显著影响。
- en: So our linear regression and our regression tree isolated the same three variables—the
    same three hustle statistics—as having the most significant influence on wins.
    They also provided different insights. According to our reduced linear model,
    points off screens, pass deflections, and loose balls recovered account for approximately
    16% of the variance in regular season wins, based on a data set spanning three
    NBA seasons. Our regression tree, on the other hand, returned a series of predicted
    wins based on several if-else rules.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的线性回归和回归树隔离出相同的三个变量——相同的三个努力统计数据——对胜利影响最大。它们还提供了不同的见解。根据我们的简化线性模型，根据涵盖三个NBA赛季的数据集，掩护得分、传球挡截和抢断球数占常规赛胜利差异的大约16%。另一方面，我们的回归树基于一系列如果-否则规则返回了一系列预测胜利的结果。
- en: Going forward, we’ll challenge some conventional wisdom and demonstrate, with
    data and statistical techniques, that these accepted conventions aren’t necessarily
    true. In chapter 6, we’ll explore the idea that games are won in the fourth quarter.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来，我们将挑战一些传统智慧，并通过数据和统计技术来证明这些公认的惯例并不一定正确。在第6章中，我们将探讨一个观点，即比赛是在第四季度赢得的。
- en: Summary
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Linear regressions done right first require a thorough analysis of the data.
    Outliers should be identified and treated, variables with non-normal distributions
    should be transformed or disregarded altogether, and preferences should be given
    to those potential predictors that have the strongest correlations with the target
    variable, especially when you’re working with wide data sets.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确进行线性回归首先需要对数据进行彻底分析。应识别并处理异常值，对非正态分布的变量应进行转换或完全不予考虑，应优先考虑与目标变量相关性最强的潜在预测因子，尤其是在处理宽数据集时。
- en: It’s best to subset your data into two, developing your model against one and
    then predicting against the other, to avoid overfitting.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最好将您的数据分成两部分，用其中一部分来开发模型，然后用另一部分来预测，以避免过度拟合。
- en: Another way of avoiding overfitting is to check for multicollinearity and, if
    necessary, apply corrective action by then removing offending variables from your
    model.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免过度拟合的另一种方法是检查多重共线性，并在必要时采取纠正措施，通过从模型中移除违规变量来实施。
- en: Linear regressions draw a straight line that minimizes the differences between
    the regression and the data. While linear models are quite common and likely more
    prevalent than other model types where the dependent (i.e., target) variable is
    continuous, it’s important to understand that data isn’t always linear.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归绘制一条直线，以最小化回归与数据之间的差异。虽然线性模型相当常见，可能比其他模型类型更普遍，其中因变量（即目标变量）是连续的，但重要的是要理解数据并不总是线性的。
- en: Our linear regressions didn’t explain or predict wins with much accuracy, but
    we still successfully identified three hustle statistics—points off screens, pass
    deflections, and loose balls recovered—that collectively account for 16% of the
    variance in regular season wins over the three seasons tested. We therefore discovered
    where players should give 100% and where they can lay up, if necessary.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的线性回归模型并没有以很高的准确性解释或预测胜利，但我们仍然成功地识别出了三个 hustle 统计量——屏幕外的得分、传球拦截和失球回收——这三个统计量共同解释了在测试的三个赛季中常规赛胜利的
    16% 的变异性。因此，我们发现球员应该在哪些方面全力以赴，在必要时可以休息。
- en: Our regression tree isolated the same three variables as being more significant
    than the other hustle statistics in our data set; furthermore, it returned predicted
    regular season wins through a series of if-else rules.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的回归树将与我们数据集中其他 hustle 统计量相比，识别出相同的三个变量更为重要；此外，它通过一系列的 if-else 规则预测了常规赛的胜利。
- en: There are several use cases for linear regression, such as product sales based
    on a multichannel advertising strategy among online, radio, and television advertising;
    median price of a single-family home based on crime rates, average number of rooms
    per unit, and student-to-teacher ratios in local schools; marathon performance
    based on age, gender, and recent 10K and half-marathon paces; credit card default
    rates based on macroeconomic indicators; and CEO salaries based on years in position
    and year-over-year changes in stock prices. Linear regressions require a continuous
    target variable. In chapter 14, we’ll fit a logistic regression, which instead
    requires a binary target variable.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归有几种应用场景，例如基于在线、广播和电视广告的多渠道广告策略的产品销售；基于犯罪率、每单位平均房间数和当地学校师生比例的单户住宅中位数价格；基于年龄、性别和最近
    10K 和半程马拉松配速的马拉松表现；基于宏观经济指标信用卡违约率；以及基于职位年限和股价年度变化的 CEO 薪酬。线性回归需要一个连续的目标变量。在第 14
    章中，我们将拟合一个逻辑回归，它需要一个二进制目标变量。
- en: A tree-based model is a good alternative for these same use cases. Additionally,
    you can call the `tree()` function to also fit a classification tree; it has the
    same syntax as a regression tree, but your target variable must be binary rather
    than continuous.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于树的模型是这些相同用例的良好替代品。此外，您还可以调用 `tree()` 函数来拟合一个分类树；它的语法与回归树相同，但您的目标变量必须是二进制而不是连续的。
