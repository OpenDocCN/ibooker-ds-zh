- en: Part 2\. Building a reactive machine learning system
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二部分：构建反应式机器学习系统
- en: This is the heart of the book. This part will build up your knowledge of the
    components of a machine learning system, starting from raw data in the wild and
    looping all the way back around to acting on the real world.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本书的核心。这一部分将从原始数据开始，构建你对机器学习系统组件的知识，一直循环到对现实世界产生影响。
- en: '[Chapter 3](kindle_split_014.html#ch03) is about collecting data. It’s not
    a normal chapter for a machine learning book: instead of hand-waving away where
    data comes from, we’ll take a serious look at a range of data issues, concentrating
    on when that data is big, fast, and hairy.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[第3章](kindle_split_014.html#ch03) 讲述了收集数据的内容。这不是一本机器学习书籍的正常章节：我们不会对数据来源进行泛泛而谈，而是会认真审视一系列数据问题，重点关注数据量大、速度快、复杂度高的情况。'
- en: '[Chapter 4](kindle_split_015.html#ch04) explores deriving useful representations
    of data, called *features*. This is one of the most important skills a machine
    learning systems developer can have and is often the largest part of the work.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4章](kindle_split_015.html#ch04) 探讨了推导数据的有效表示，称为 *特征*。这是机器学习系统开发者最重要的技能之一，通常是工作中最大的一部分。'
- en: 'Once you get to [chapter 5](kindle_split_016.html#ch05), you should be ready
    to do what everyone focuses on in machine learning: learn some models. There are
    entire books about learning models, but this chapter represents a unique view
    and will give you an understanding of how this step connects to what came before
    and what comes after. I’ll introduce you to some useful techniques to employ when
    the pieces of your system aren’t as easy to join up as you’d like.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你到达 [第5章](kindle_split_016.html#ch05)，你应该准备好做机器学习中大家关注的重点：学习一些模型。关于学习模型有整本书的讨论，但这一章节提供了一个独特的视角，并将帮助你理解这一步骤如何与前后的内容相连接。我会介绍一些有用的技术，当你的系统组件难以连接时可以采用。
- en: '[Chapter 6](kindle_split_017.html#ch06) covers the rich topic of how to make
    decisions about machine learning models that you’ve produced. Not all models are
    created equal. There’s a range of common errors that you can make in learning
    about models, so I’ll attempt to arm you with tools you can use to figure out
    the differences between a good model and a bad one.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](kindle_split_017.html#ch06) 涵盖了如何对你生产的机器学习模型做出决策的丰富主题。并非所有模型都是平等的。在学习模型时，你可能会犯一系列常见的错误，因此我将尝试为你提供一些工具，帮助你区分好模型和坏模型之间的差异。'
- en: '[Chapter 7](kindle_split_018.html#ch07) discusses taking the models you’ve
    produced and getting them somewhere they can be useful. Models sitting on your
    laptop probably aren’t much use to anyone; they have to be available to be used
    by your customers, colleagues, and so on. This chapter shows you how to build
    services that can put your models to use.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](kindle_split_018.html#ch07) 讨论了如何将你生产的模型用于实际场景。坐在你笔记本电脑上的模型可能对任何人都没有太大用处；它们必须可供你的客户、同事等使用。这一章节将向你展示如何构建能够使用你的模型的服务。'
- en: 'Finally, in [chapter 8](kindle_split_019.html#ch08), you get to use your models
    to affect the real world. This is where the rubber hits the road: you’ve closed
    the loop in fulfilling your user’s request with a response. Reactive systems design
    is all about how you meet your users’ expectations. So, in [chapter 8](kindle_split_019.html#ch08),
    we turn our perspective solidly to the user of your machine learning system and
    see how you can realize those expectations.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在第8章 [chapter 8](kindle_split_019.html#ch08) 中，你可以使用你的模型来影响现实世界。这是“真金不怕火炼”的地方：你通过响应完成了用户的请求，实现了闭环。反应式系统设计完全关乎如何满足用户期望。因此，在第8章
    [chapter 8](kindle_split_019.html#ch08) 中，我们将视角坚定地转向你的机器学习系统用户，看看你如何实现这些期望。
- en: Chapter 3\. Collecting data
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3章：收集数据
- en: '*This chapter covers*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Collecting inherently uncertain data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集本质上不确定的数据
- en: Handling data collection at scale
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理大规模的数据收集
- en: Querying aggregates of uncertain data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询不确定数据的聚合
- en: Avoiding updating data after it’s been written to a database
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免在数据写入数据库后更新数据
- en: This chapter begins our journey through the components, or phases, of a machine
    learning system ([figure 3.1](#ch03fig01)). Until there’s data in your machine
    learning system, you can’t do anything, so we’ll begin with collecting data. As
    you saw in [chapter 1](kindle_split_011.html#ch01), the naive approach for getting
    data into a machine learning system can lead to all sorts of problems. This chapter
    will show you a much better way to collect data, one based on recording immutable
    facts. The approach in this chapter also assumes that the data being collected
    is intrinsically uncertain and effectively infinite.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章开始我们探索机器学习系统组件或阶段的旅程（[图3.1](#ch03fig01)）。在你机器学习系统中没有数据之前，你什么也做不了，因此我们将从收集数据开始。正如你在[第1章](kindle_split_011.html#ch01)中看到的，将数据引入机器学习系统的天真方法可能导致各种问题。本章将向你展示一种更好的数据收集方法，这种方法基于记录不可变的事实。本章中的方法还假设正在收集的数据本质上是不确定的，并且实际上是无限的。
- en: Figure 3.1\. Phases of machine learning
  id: totrans-15
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.1. 机器学习的阶段
- en: '![](03fig01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig01.jpg)'
- en: Many people don’t even mention data collection when they discuss building machine
    learning systems. At first glance, it doesn’t seem as exciting as learning models
    or making predictions. But collecting data is crucial and a lot harder than it
    looks. There are no easy shortcuts to building production-grade apps that can
    collect vast amounts of highly variable data in an environment of change. We need
    to bring the full power of reactive machine learning to bear on this problem to
    ensure that we have good, usable data that can be consumed by other components
    of our machine learning systems.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人讨论构建机器学习系统时甚至不提数据收集。乍一看，这似乎不如学习模型或做出预测那么令人兴奋。但收集数据至关重要，而且比看起来要困难得多。在变化的环境中，没有简单的捷径可以构建能够收集大量高度可变数据的生产级应用程序。我们需要将反应式机器学习的全部力量应用于这个问题，以确保我们有良好、可用的数据，可以被我们机器学习系统的其他组件消费。
- en: To go deeper into the world of reactive machine learning systems, we’re going
    to have to go beyond the problems of mere house pets. We’ll have to venture as
    far as the wilds of Africa. The challenge you’ll take on is recording the movements
    of animals during the largest terrestrial mammal migration on the planet. The
    Serengeti’s Great Migration is full of data that’s big, fast, and hairy. Let’s
    see how that can data be collected.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解反应式机器学习系统，我们必须超越普通家宠的问题。我们必须冒险深入非洲的荒野。你将面临的挑战是记录地球上最大的陆地哺乳动物迁徙期间动物的运动。塞伦盖蒂的大迁徙充满了庞大、快速且复杂的数据。让我们看看这些数据是如何被收集的。
- en: 3.1\. Sensing uncertain data
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1. 感知不确定数据
- en: In this chapter, you’ll play the role of a noble lion queen. As matriarch of
    your pride, you take your job very seriously.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将扮演一位尊贵的母狮王后。作为族群的族长，你非常认真地对待你的工作。
- en: 'You have an age-old problem, though: your food doesn’t stay still. Every spring,
    the wildebeests and zebras that you feed on have the annoying habit of leaving
    the southern grassland plains to migrate north. Then, every fall, these herbivores
    just turn around and head back south for the rainy season.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你有一个古老的问题：你的食物不会静止不动。每年春天，你赖以生存的角马和斑马都有一种令人烦恼的习惯，那就是离开南部的草原平原向北迁徙。然后，每年秋天，这些食草动物就会转身向南，回到雨季。
- en: '![](0044fig01.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图片](0044fig01.jpg)'
- en: As a responsible queen and mother, you must track the movements of this mass
    migration of your prey. If you didn’t, your pride would have nothing to eat. But
    the data-management problems of this job are severe, as shown in [figure 3.2](#ch03fig02).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一位负责任的王后和母亲，你必须跟踪你猎物的这种大规模迁徙运动。如果你不这样做，你的族群将一无所有可吃。但这项工作的数据管理问题非常严重，如图3.2所示。
- en: Figure 3.2\. Great Migration data
  id: totrans-24
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.2. 大迁徙数据
- en: '![](03fig02.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig02.jpg)'
- en: To get any sort of handle on this big, fast, and hairy data, you’re going to
    need to deploy some advanced technology. You have a long-term vision that you’ll
    one day be able to use this data to build a large-scale machine learning system
    that will predict where the prey will be next, so that your lionesses can be there
    waiting for them. But before you can even consider building systems on top of
    this data, you need to collect it and persist it somehow.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要对这种庞大、快速且复杂的数据有所把握，你需要部署一些先进的技术。你有一个长期愿景，有一天你将能够使用这些数据来构建一个大规模的机器学习系统，该系统能够预测猎物将在哪里，以便你的母狮们可以等待它们。但在你甚至考虑在这个数据之上构建系统之前，你需要收集并以某种方式持久化这些数据。
- en: Thanks to a recently signed contract with technology consultants Vulture Corp.,
    you now have access to some sensor data about the movement of land-bound animals
    ([figure 3.3](#ch03fig03)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢与技术顾问鹰科公司签订的最新合同，你现在可以访问一些关于陆生动物运动的数据（[图3.3](#ch03fig03)）。
- en: Figure 3.3\. Vulture Corp.
  id: totrans-28
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.3\. 鹰科公司。
- en: '![](03fig03.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig03.jpg)'
- en: 'The Vulture Corp. Eyes in the Skies system is based on an aerially deployed,
    distributed network of sensors. These sensors use a combination of body-heat detection
    and movement patterns to report back the number and kinds of different animals
    at any given location. Here’s an example of the sort of raw animal-sensor data
    that this system provides:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 鹰科公司的“天空之眼”系统基于空中部署的分布式传感器网络。这些传感器结合体温检测和运动模式来报告任何给定位置的动物数量和种类。以下是这个系统提供的原始动物-传感器数据的一个示例：
- en: '![](0045fig01_alt.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](0045fig01_alt.jpg)'
- en: '![](uncertain-data.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](uncertain-data.jpg)'
- en: But this raw schema isn’t really what the Eyes in the Skies system understands
    about the animals below. The sensors only provide an approximate view of what’s
    going on using body heat and movement. There will always be some uncertainty in
    that process.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但这个原始模式并不是“天空之眼”系统真正理解下面动物的方式。传感器仅通过体温和运动提供一个对发生情况的近似视图。在这个过程中总会有一些不确定性。
- en: 'After some further negotiation with (intimidation of) your technology consultants,
    you get access to a richer data feed. That data feed, shown here, is more explicit
    about the difficulty of being precise in raw sensor data like this:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在与（恐吓）你的技术顾问进行了一些进一步的谈判后，你获得了更丰富的数据流访问权限。这里显示的数据流，对于像这样的原始传感器数据的精确性难度有更明确的说明：
- en: '![](0046fig01_alt.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](0046fig01_alt.jpg)'
- en: This data model has far more statistical richness. It expresses that there may
    have been far fewer or far more than 20 animals at that location. A consultation
    of the Eyes in the Skies API documentation reveals that these are the upper and
    lower bounds of the probability distribution of the sensed data, at a 95% confidence
    level.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数据模型具有更多的统计丰富性。它表明在那个位置可能远少于或远多于20只动物。查阅“天空之眼”API文档可以发现，这些是感知数据的概率分布的上限和下限，置信水平为95%。
- en: '|  |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Confidence intervals**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**置信区间**'
- en: The uncertain data model shown in the diagram uses a *confidence interval*.
    This is a measure of the amount of uncertainty around the sensor reading. The
    confidence level refers to the percentage of all possible readings that would
    be expected to include the true count of animals. Right now, you don’t need to
    be concerned with how these values are calculated—we won’t spend much time on
    basic statistical techniques like confidence intervals in this book. Instead,
    we’ll focus on how to build systems that are aware of the need to express and
    respond to uncertainty. For a more in-depth introduction to statistics, many books
    and courses are available. *Think Like a Data Scientist* by Brian Godsey (Manning,
    2017) is a good book for building a deeper understanding of statistics, in the
    context of doing data-science work.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图表中显示的不确定性数据模型使用的是*置信区间*。这是衡量传感器读数周围不确定性的量度。置信水平指的是所有可能读数中预期包含真实动物数量的百分比。目前，你不需要担心这些值的计算方法——我们在这本书中不会花太多时间在基本统计技术，如置信区间上。相反，我们将专注于如何构建能够表达和响应不确定性的系统。对于更深入的统计学介绍，有许多书籍和课程可供选择。“像数据科学家一样思考”由Brian
    Godsey（Manning，2017）所著，是一本在数据科学工作中加深对统计学理解的优秀书籍。
- en: '|  |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: The difference between 16 and 24 prey animals might not sound big, and in some
    contexts it might not be. Some readings have lower bounds that are zero and upper
    bounds that are nonzero. For those locations, you could send lionesses to them
    expecting to find one or two wildebeests and find none at all when they arrive.
    Thanks to this explicitly uncertain data model, you as the lion queen can now
    make more-informed decisions about where to allocate your scarce hunting resources.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 16和24个猎物动物之间的差异可能听起来不大，在某些情况下可能确实如此。有些读数的下限为零，上限不为零。对于这些位置，你可以派遣母狮前往，预期会找到一两只角马，但到达时却一个也没有找到。多亏了这个明确的不确定性数据模型，你现在作为狮后，可以就如何分配你稀缺的狩猎资源做出更明智的决定。
- en: 'The difference between these two data models is an example of a *data transformation*.
    In a data-processing system, as in a machine learning system, many of the operations
    of the system are effectively data transformations. Transforming data is such
    a common task that I’ll spend all of [chapter 4](kindle_split_015.html#ch04) discussing
    how to do it in a reactive machine learning system. The original sensor data feed
    from the Eyes in the Skies system was a transformation of a more raw form of the
    data that was originally kept internal to Vulture Corp. As you saw, transforming
    this raw data caused you to lose information about the intrinsic uncertainty in
    the sensor readings. This is a common mistake that people make when implementing
    data-processing systems: people destroy valuable data by only persisting some
    derived version of the raw data.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种数据模型之间的差异是一个**数据转换**的例子。在数据处理系统，就像在机器学习系统中，系统的许多操作实际上都是数据转换。转换数据是一项如此常见的任务，以至于我将在[第4章](kindle_split_015.html#ch04)中全部讨论如何在反应式机器学习系统中完成它。来自“天空之眼”系统的原始传感器数据流是对Vulture
    Corp内部最初保留的更原始数据形式的转换。正如你所见，转换这些原始数据导致你失去了关于传感器读数内在不确定性的信息。这是人们在实施数据处理系统时常见的错误：人们通过只持久化原始数据的某些派生版本来破坏有价值的数据。
- en: 'Consider the following proposal from a young lioness working on the transformed
    sensor data from the Eyes in the Skies system:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下来自一位正在处理“天空之眼”系统转换后传感器数据的年轻狮子的提议：
- en: '![](0047fig01.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![0047fig01.jpg](0047fig01.jpg)'
- en: In this heavily transformed version of the data, the young lioness developer
    has decided to simplify things down to just a Boolean value representing whether
    there are more than 10 wildebeests in a given location. That’s the cutoff value
    that you’ve been using lately to decide whether a location should be hunted. Her
    thinking is that this is all you really need to know to make a decision anyway.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个高度转换的数据版本中，年轻的狮子开发者决定将事情简化为仅用一个布尔值来表示在特定位置是否有超过10只角马。这就是你最近用来决定是否应该狩猎某个位置的截止值。她的想法是，这实际上是你做出决定所需了解的一切。
- en: But you’re an experienced lion queen. In a bad year, you might go out to stalk
    a single zebra foal. The circle of life is always turning, and you can’t always
    know what the future will bring. You may need all the richness of the data model
    in the previous diagram to make the hard decisions when the time comes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 但你是一位经验丰富的狮子王后。在不好的年份，你可能会出去捕猎一只单独的斑马幼崽。生命之圈总是在转动，你不可能总是知道未来会带来什么。当需要做出艰难决定时，你可能需要之前图中展示的数据模型的所有丰富性。
- en: '![](immutable-facts.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![不可变事实](immutable-facts.jpg)'
- en: This is an illustration of a fundamental strategy in data collection. You should
    always collect data as immutable facts.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种数据收集的基本策略的说明。你应该始终以不可变的事实收集数据。
- en: A *fact* is merely a true record about something that happened. In the example
    of the Eyes in the Skies system, the thing that happened was that an aerial sensor
    sensed some animals. To know when that fact occurred, you should record the time
    when it occurred, although there are some interesting choices about how that time
    can be expressed. The example so far has used a simple timestamp to say when a
    sensor reading was recorded.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**事实**仅仅是关于某件事情发生过的真实记录。在“天空之眼”系统的例子中，发生的事情是一个空中传感器检测到了一些动物。要知道这个事实发生的时间，你应该记录它发生的时间，尽管关于如何表达这个时间有一些有趣的选择。到目前为止的例子使用了简单的时间戳来说明传感器读数被记录的时间。
- en: 'Similarly, it’s often a good idea to record the entity or entities that the
    fact relates to. In the animal-sensor data, you recorded both the entity from
    which the fact originated—the sensor—and the entity being described in the fact:
    the location. Even though there was some uncertainty around the sensor data collected,
    the facts will never need to be changed. They will always be a fact about the
    system’s view of the world at that point in time.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，记录与事实相关联的实体或实体通常是一个好主意。在动物-传感器数据中，你记录了事实起源的实体——传感器——以及事实中描述的实体：位置。尽管收集到的传感器数据周围存在一些不确定性，但事实永远不会需要更改。它们将始终是关于系统在那个时间点对世界看法的事实。
- en: Immutable facts are an important part of building a reactive machine learning
    system. Not only do they help you build a system that can manage uncertainty,
    they also form the foundation for strategies that deal with data-collection problems
    that only emerge once your system gets to a certain scale.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 不变事实是构建反应式机器学习系统的重要组成部分。它们不仅帮助你构建一个可以管理不确定性的系统，而且也是处理数据收集问题的策略的基础，这些问题只有在你的系统达到一定规模后才会出现。
- en: 3.2\. Collecting data at scale
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 规模化收集数据
- en: The amazing thing about the Great Migration is its scale. Millions of animals
    are all on the move at once. The wildebeests are the most numerous of these animals,
    but there are also hundreds of thousands of gazelles and zebras. Beyond these
    top three meals on hooves, there’s a long tail of lesser animals to consider.
    From high up on your headquarters on Lion Rock, you can only see so much. The
    Eyes in the Skies system has given you a starting point for understanding the
    state of the savannah, but it’s just a starting point. It’s clear that you need
    to begin processing this data into more useful representations if you want to
    be able to take action on any of it.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 大迁徙的惊人之处在于其规模。数百万动物同时移动。斑马是这些动物中最多的，但也有数十万只瞪羚和斑马。除了这些蹄类动物的前三种主要食物外，还有许多其他较小的动物需要考虑。从你在狮子岩总部的高处，你能看到的有限。天空之眼系统为你理解草原的状态提供了一个起点，但这只是一个起点。显然，如果你想对任何数据进行行动，你需要开始将这些数据加工成更有用的表示形式。
- en: You’ll start with exploring how to build *data aggregations*, derived data produced
    from multiple data points. The next section shows an initial approach toward building
    a data-aggregation system that won’t be the final strategy you’ll use. The techniques
    used will all work at a certain level of scale but then run into problems as scale
    increases. These ways of building a distributed data-processing system are the
    beginnings of a solution to problems of scale, and you’ll build on this section
    to handle even greater scale in [section 3.3](#ch03lev1sec3).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你将从探索如何构建 *数据聚合* 开始，这是从多个数据点产生的派生数据。下一节将展示构建数据聚合系统的初步方法，这不会是你最终使用的策略。所使用的所有技术都将在一个特定的规模级别上工作，但随着规模的增加会遇到问题。这些构建分布式数据处理系统的方法是解决规模问题的起点，你将在此基础上构建，以处理更大规模的[第
    3.3 节](#ch03lev1sec3)。
- en: 3.2.1\. Maintaining state in a distributed system
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1\. 在分布式系统中维护状态
- en: As a first project, you’ve decided to try to track the density of prey in each
    region. A region is a geographically contiguous set of locations, each with its
    own sensor feed. The density statistic that you’d like maintained could be simply
    expressed as in the following listing.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一个项目，你决定尝试追踪每个区域的猎物密度。区域是一个地理上连续的地点集合，每个地点都有自己的传感器数据。你希望保持的密度统计信息可以简单地表达如下。
- en: Listing 3.1\. Calculating location densities
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.1\. 计算位置密度
- en: '[PRE0]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '***1* Case class representing a reading of number of animals at a particular
    location and size of location**'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 表示特定位置和位置大小的动物数量读取的案例类**'
- en: '***2* Example instance of a reading**'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 读取示例实例**'
- en: '***3* Collection of readings**'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 读取集合**'
- en: '***4* Sum of all animals in a region**'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 区域内所有动物的总和**'
- en: '***5* Sum of square miles of all locations in a region**'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 区域内所有位置的平方英里总和**'
- en: '***6* Density in terms of animals/square mile—27.6 in this case**'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 动物/平方英里的密度——本例中为 27.6**'
- en: '|  |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Folding**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**折叠**'
- en: 'The summing operations in [listing 3.1](#ch03ex01) are implemented using a
    fold. *Folding* is a common functional programming technique. The `foldLeft` operator
    used begins with an initial sum of zero. The second argument is the higher-order
    function to be applied to each item in the set of readings. In a sum, this higher-order
    function is the addition of the running sum with the next item. But folding is
    a powerful technique that can be used for more than just summing. You’ll see it
    again, particularly in later chapters that use Spark. If you want to dive deep
    into why folding is such a powerful technique, check out the paper “A Tutorial
    on the Universality and Expressiveness of Fold” by Graham Hutton: [www.cs.nott.ac.uk/~pszgmh/fold.pdf](http://www.cs.nott.ac.uk/~pszgmh/fold.pdf).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[代码清单3.1](#ch03ex01)中的求和操作使用的是折叠。*折叠*是一种常见的函数式编程技术。使用的`foldLeft`操作符从零开始一个初始和。第二个参数是要应用于读数集中每个项目的的高阶函数。在求和中，这个高阶函数是运行总和与下一个项目的相加。但折叠是一种强大的技术，可以用于不仅仅是求和。你将在后面的章节中再次看到它，特别是在使用Spark的章节中。如果你想要深入了解为什么折叠是一种如此强大的技术，可以查看Graham
    Hutton的论文“关于折叠的普遍性和表达力的教程”：[www.cs.nott.ac.uk/~pszgmh/fold.pdf](http://www.cs.nott.ac.uk/~pszgmh/fold.pdf)。'
- en: '|  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: This sort of approach is reasonable in some ways. The code in [listing 3.1](#ch03ex01)
    uses only immutable data structures, so all values used in calculations can be
    thought of as facts. Summing is done using a pure, higher-order function, `+`,
    so there’s no chance of a side effect in the summing function causing unforeseen
    problems. But it’s not yet time for the lions to sleep tonight. Things are going
    to quickly get trickier.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法在某些方面是合理的。在[代码清单3.1](#ch03ex01)中的代码仅使用不可变数据结构，因此所有用于计算的价值都可以被视为事实。求和操作使用的是纯函数，高阶函数`+`，因此在求和函数中不会出现副作用导致未预见到的问题。但今晚狮子们还不能休息。事情将会很快变得复杂起来。
- en: For you to know which regions have the most density of prey without going out
    to where the sensor readings are being reported, you’ll need to aggregate all
    those readings in a single location—your headquarters at Lion Rock. To that end,
    you’ve signed a contract with the Cheetah Post message-delivery company ([figure
    3.4](#ch03fig04)).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了知道哪些区域有最多的猎物密度，而不必外出到传感器读数报告的地方，你需要将这些读数汇总到一个单一的位置——你的总部在狮子岩。为此，你已经与猎豹邮递公司签订了合同([图3.4](#ch03fig04))。
- en: Figure 3.4\. Cheetah Post
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.4\. 猎豹邮递
- en: '![](03fig04.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig04.jpg)'
- en: '![](message-driven.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](message-driven.jpg)'
- en: They’ll go out to each of the data-collection stations and get the latest reading.
    Then they’ll rush the message about that information back to Lion Rock. That latest
    sensor reading will then be added to the aggregate view of all the locations.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 他们将前往每个数据收集站，获取最新的读数。然后他们将会把有关该信息的消息迅速带回狮子岩。然后，最新的传感器读数将被添加到所有位置的聚合视图中。
- en: 'Anticipating problems with a bunch of cheetahs running back and forth, you
    decide to do what any seasoned leader would do: you put a pangolin in charge.
    In exchange for you agreeing not to eat him, the pangolin has agreed to maintain
    the current state of the density data as part of the system shown in [figure 3.5](#ch03fig05).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 预见到一群猎豹来回奔跑可能带来的问题，你决定做任何经验丰富的领导者都会做的事情：你让穿山甲负责。作为你同意不食用它的交换，穿山甲同意维持[图3.5](#ch03fig05)中所示系统的当前密度数据状态。
- en: Figure 3.5\. Simple density-data system architecture
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.5\. 简单的密度数据系统架构
- en: '![](03fig05_alt.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig05_alt.jpg)'
- en: The pangolin implements the state management process in [listing 3.2](#ch03ex02),
    which shows an example of how this aggregate view of the savannah can be maintained.
    The example update scenario is the receipt of a message about there being a high
    density of animals in Region 4.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 穿山甲在[代码清单3.2](#ch03ex02)中实现了状态管理过程，该清单展示了如何维护萨凡纳的这种聚合视图的示例。示例更新场景是收到有关区域4动物密度高的消息。
- en: Listing 3.2\. Aggregating regional densities
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.2\. 聚合区域密度
- en: '[PRE1]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '***1* Case class representing a region**'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 表示区域的案例类**'
- en: '***2* Mutable hash map storing the latest density values recorded by region**'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 存储最新密度值的可变哈希表**'
- en: '***3* This update will overwrite the previous value for Region 4 with a new
    value.**'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 此更新将用新值覆盖区域4的先前值。**'
- en: By putting a single pangolin in charge of this process, you’ve ensured that
    the cheetahs will never contend to make updates. Moreover, by making all the cheetahs
    line up to talk to the pangolin, you’ve ensured that all updates are processed
    in the order of their arrival.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 通过让一个穿山甲负责这个过程，你确保猎豹永远不会争夺更新。此外，通过让所有猎豹排队与穿山甲交谈，你确保所有更新都是按照到达顺序处理的。
- en: '![](replication.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![复制](replication.jpg)'
- en: But the number of animals constantly on the move leads to there being more cheetahs
    with more updates than you originally planned for. The process of recording these
    updates quickly becomes too much for one pangolin to handle.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，不断移动的动物数量导致有更多更新比最初计划的猎豹数量。记录这些更新的过程很快变得对一个穿山甲来说过于繁重。
- en: You decide to hire another pangolin. Now there are two pangolins and two queues
    that cheetahs can line up in to get their updates applied, as shown in [figure
    3.6](#ch03fig06).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你决定再雇佣一个穿山甲。现在有两个穿山甲和两个队列，猎豹可以排队等待应用他们的更新，如图[图3.6](#ch03fig06)所示。
- en: Figure 3.6\. Adding a queue
  id: totrans-88
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.6\. 添加队列
- en: '![](03fig06_alt.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig06_alt.jpg)'
- en: '![](elastic.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![弹性](elastic.jpg)'
- en: At first this seems like a good solution. After all, you can keep hiring more
    pangolins as your scale of data collection goes up. That gives you some ability
    to continue applying your updates in the same amount of time despite increasing
    load.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 起初这似乎是一个不错的解决方案。毕竟，随着数据收集规模的扩大，你可以继续雇佣更多的穿山甲。这让你能够在增加负载的同时，继续在相同的时间内应用更新。
- en: But that initial elasticity quickly fades. Part of the reason is that while
    one pangolin is making an update to the system, the other pangolin can only wait.
    Although pangolins do spend some time walking back and forth from queues of cheetahs
    to the update computer, they soon spend most of their time waiting for access
    to the single computer. This means updates about one region block updates about
    another region.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 但最初的弹性很快就会消失。部分原因是，当一个穿山甲正在对系统进行更新时，另一个穿山甲只能等待。尽管穿山甲确实会花费一些时间在猎豹队列和更新计算机之间来回走动，但他们很快就会花大部分时间等待访问单台计算机。这意味着一个区域的更新会阻塞另一个区域的更新。
- en: You decide to try adding more pangolins with more computers and implement the
    system shown in [figure 3.7](#ch03fig07).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你决定尝试添加更多的穿山甲和更多的计算机，并实现了如图[图3.7](#ch03fig07)所示的系统。
- en: Figure 3.7\. Concurrent access to a shared mutable state
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.7\. 对共享可变状态的并发访问
- en: '![](03fig07_alt.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig07_alt.jpg)'
- en: To enable multiple pangolins to make updates concurrently, you decide to change
    the data structure used to store the densities data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使多个穿山甲能够同时进行更新，你决定改变存储密度数据的所用数据结构。
- en: Listing 3.3\. Concurrently accessible densities
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.3\. 可并发访问的密度
- en: '[PRE2]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This implementation now allows for concurrent access to make updates to densities
    data using a system of locks that ensures that each thread of execution has the
    latest view of the data. Different pangolins can be at different computers making
    different updates, but each pangolin holds a lock for the time it takes to make
    their update. At first, this looks like an improvement, but the performance eventually
    is much like the old system. The synchronization process and its locking mechanism
    turn out to be quite similar to the old single-computer bottleneck. You’ve merely
    narrowed the scope of what the scarce resource is down to a lock on the mutable
    data structure. With this bottleneck, you can no longer add more pangolins to
    get more throughput; they would just contend for locks on the densities hash map.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这种实现现在允许通过一个确保每个执行线程都有数据最新视图的锁系统来并发访问密度数据以进行更新。不同的穿山甲可以在不同的计算机上做出不同的更新，但每个穿山甲在更新期间都持有锁。起初，这似乎是一个改进，但性能最终与旧系统相似。同步过程及其锁定机制最终证明与旧的单机瓶颈非常相似。你只是将稀缺资源的范围缩小到对可变数据结构的锁。有了这个瓶颈，你不能再添加更多的穿山甲来获得更多的吞吐量；他们只会争夺密度哈希表的锁。
- en: There’s another unfortunate outcome of this new system. Cheetahs can get in
    any queue they want. Some pangolins work faster than other pangolins. This system
    now allows some updates to be processed out of order.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新系统还有一个不幸的后果。猎豹可以进入他们想要的任何队列。有些穿山甲的工作速度比其他穿山甲快。这个系统现在允许一些更新以非顺序的方式处理。
- en: For example, Region 6 of the savannah had a high density of animals this morning
    before all the zebras moved on. If the updates about these sensor readings are
    applied in order, you’ll have an accurate view of this region, as shown in the
    following listing.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，今天早上，草原的6号区域动物密度很高，因为所有的斑马都已经移动了。如果按照[列表 3.4](#ch03ex04)中的方式应用这些传感器读数的更新，你将能够准确看到这个区域，如下面的列表所示。
- en: Listing 3.4\. In-order updates
  id: totrans-102
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.4\. 有序更新
- en: '[PRE3]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '***1* Morning update**'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 上午更新**'
- en: '***2* Afternoon update**'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 下午更新**'
- en: '***3* Returns 0.5**'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 返回值 0.5**'
- en: But now it’s also possible for updates to be applied out of order. A sequence
    of out-of-order updates gives you a very different view of the situation.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在更新也可能被乱序应用。一系列乱序更新会给你一个完全不同的局面观。
- en: Listing 3.5\. Out-of-order updates
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.5\. 乱序更新
- en: '[PRE4]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '***1* Afternoon update**'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 下午更新**'
- en: '***2* Morning update**'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 上午更新**'
- en: '***3* Returns 73.6**'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 返回值 73.6**'
- en: In this second scenario, you’re sending out your valuable lionesses to go hunt
    in an area where you should already know that all the animals have moved on.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个第二种场景中，你正在派遣你宝贵的雌狮去一个你应该已经知道所有动物都已经移动过的区域狩猎。
- en: If you look back at the first sequence of updates, it also has deficiencies.
    In the afternoon, you have an accurate view of the lack of prey in Region 6 if
    the updates are applied as in [listing 3.4](#ch03ex04). But what happened in the
    morning? There should have been lionesses out there in such a prey-rich region,
    but they were just lounging around. By the time the afternoon rolled around, all
    you knew was that there was no more prey in Region 6\. You had no idea that a
    few lazy lionesses missed the day’s best opportunity to hunt. There has to be
    a better way of organizing a hunt.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回顾一下第一次更新序列，它也存在缺陷。在下午，如果你按照[列表 3.4](#ch03ex04)中的方式应用更新，你将能够准确看到6号区域捕食物的缺失。但早上发生了什么？在这个捕食丰富的区域，应该有雌狮在那里，但她们只是闲逛。到了下午，你所知道的就是6号区域已经没有捕食物了。你不知道几只懒散的雌狮错过了当天最好的狩猎机会。必须有一种更好的组织狩猎的方式。
- en: 3.2.2\. Understanding data collection
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2\. 理解数据收集
- en: Where did things go wrong with the prey-density project? This system was supposed
    to answer basic questions about where animals were located on the savannah. Sure,
    the vulture consultants had proposed a follow-on project where this prey data
    would be used to create machine learning models of future prey locations. But
    you can’t even begin to consider future projects without figuring out what’s wrong
    with the current system and fixing it.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 预捕密度项目出了什么问题？这个系统原本是用来回答关于动物在草原上位置的基本问题的。当然，秃鹫顾问们提出了一个后续项目，其中将使用这些捕食数据来创建未来捕食位置的学习模型。但你不先找出当前系统的问题并修复它，就无法开始考虑未来的项目。
- en: 'You gather your team to dissect the prey-density system and figure out what
    you’ve learned about collecting data. You reach the following conclusions:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你召集团队剖析捕食密度系统，并找出你们在收集数据方面学到了什么。你得出以下结论：
- en: Data models that simplify real uncertainty throw away valuable data.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简化真实不确定性的数据模型会丢弃有价值的数据。
- en: A single data-collection processor can’t be scaled out to handle your real workload.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个数据收集处理器无法扩展以处理你的实际工作负载。
- en: Distributing your workload doesn’t scale much better if you use shared mutable
    state and locks.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你使用共享可变状态和锁来分配你的工作负载，那么扩展并不会好多少。
- en: Using mutation to update data destroys historical knowledge and can even cause
    you to overwrite new data with older data.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用变异来更新数据会破坏历史知识，甚至可能导致你用旧数据覆盖新数据。
- en: 'The team had all worked so hard to get this prey-data-collection system online,
    and yet it had some very real shortcomings. Are they going to be up for the challenges
    of fixing this system and taking it to the next level? They don’t call a group
    of lions a *pride* for nothing! Of course they can build on what they’ve learned.
    They’ve learned a lot about how to collect data. They’re ready for the next phase
    of building out a data-collection app: storing this data.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 团队为了上线这个捕食数据收集系统付出了巨大的努力，然而它确实存在一些真正的缺陷。他们是否能够应对修复这个系统并将其提升到下一个级别的挑战？他们不会无缘无故地把一群狮子称为*雄狮群*！当然，他们可以基于所学的内容进行建设。他们已经学到了很多关于如何收集数据的知识。他们已经准备好进入构建数据收集应用程序的下一阶段：存储这些数据。
- en: 3.3\. Persisting data
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 持久化数据
- en: To build the rest of your data-management systems, you’ll need a database. As
    you’ll see in the next chapter, machine learning pipelines usually start with
    some database of raw data. Although it may seem obvious, let’s try to understand
    what you need out of a database. You may already know some of this material, but
    bear with me while I explain databases from the perspective of reactive systems.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建你其余的数据管理系统，你需要一个数据库。正如你将在下一章中看到的，机器学习管道通常从一些原始数据数据库开始。尽管这看起来很明显，但让我们试着理解你需要从数据库中得到什么。你可能已经了解了一些这方面的内容，但请耐心听我解释，我从响应式系统的角度来解释数据库。
- en: Often people will discuss databases in terms of the operations that they support,
    so first and foremost, a database should allow you to store your data. In database
    terminology, this is usually called the *create* operation. For a database to
    store your data, that data must ultimately be *persisted*—it should still exist
    in the database after your program shuts down. Persistence also means that your
    data should survive things like a database server restart.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 人们通常会从数据库支持的操作来讨论数据库，因此首先，数据库应该允许你存储你的数据。在数据库术语中，这通常被称为 *创建* 操作。为了数据库能够存储你的数据，这些数据最终必须是
    *持久化的*——在程序关闭后，数据仍然应该存在于数据库中。持久化还意味着你的数据应该能够经受住诸如数据库服务器重启等事件。
- en: '![](responsive.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![响应性](responsive.jpg)'
- en: The other thing a database needs to do for you is return your data when you
    ask for it. This is referred to as the *read* operation. In reactive terms, this
    is just responsiveness again.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库需要为你做的另一件事是在你请求时返回你的数据。这被称为 *读取* 操作。在响应式术语中，这仅仅是响应性再次。
- en: No other property of a database would matter if it didn’t consistently return
    timely responses to your queries. People have different ideas about how data can
    and should be read from a database, and we’ll consider those options later in
    this chapter.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据库不能始终如一地及时响应你的查询，那么数据库的其他任何属性都不会重要。人们对如何从数据库中读取数据有不同的想法，我们将在本章后面考虑这些选项。
- en: '![](immutable-facts.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![不可变事实](immutable-facts.jpg)'
- en: There are some other things that databases can do that you won’t need to do.
    Some databases support the `update` operation, which changes data. As you’ve seen,
    mutating data can lead to all sorts of problems, so you’re going to avoid the
    `update` operation. Instead of changing data that has already been persisted,
    you’ll rely on writing new immutable facts.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库还可以做其他一些你不需要做的事情。一些数据库支持 *更新* 操作，这会改变数据。正如你所看到的，修改数据可能导致各种问题，所以你会避免 *更新*
    操作。你不会改变已经持久化的数据，而是依赖于写入新的不可变事实。
- en: '![](infinite-data.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![无限数据](infinite-data.jpg)'
- en: Similarly, some databases support an operation called `delete`. I know! That’s
    just horrifying. In the reactive machine=learning paradigm, we assume that our
    data is effectively infinite.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，一些数据库支持一个名为 *删除* 的操作。我知道！这真是太可怕了。在响应式机器学习范式下，我们假设我们的数据实际上是无限的。
- en: You won’t need that misguided `delete` operation, because you’ll build your
    system to handle unbounded amounts of data from the very beginning. Now let us
    never speak of deleting again.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要那个错误的 *删除* 操作，因为你会从构建你的系统开始，以处理无界的数据量。现在让我们永远不再谈论删除。
- en: 3.3.1\. Elastic and resilient databases
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1. 弹性和弹性数据库
- en: Now that you understand some basics of how you’re going to use a database, let’s
    get more specific about what will make a database work well in a reactive data-processing
    system. After all, you have a grand vision that you’ll eventually be able to use
    this prey data to build a large-scale machine learning system that will predict
    future prey movements. With all this big, fast, hairy data, you need to consider
    the reactive principles in your technology selection choices if you ever want
    to get that far.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经理解了如何使用数据库的一些基本知识，让我们更具体地了解什么会使数据库在响应式数据处理系统中工作得很好。毕竟，你有一个宏伟的愿景，你最终能够使用这些猎物数据来构建一个大规模的机器学习系统，该系统能够预测未来的猎物移动。面对所有这些庞大、快速、复杂的数据，如果你希望达到那个目标，你需要在技术选择上考虑响应式原则。
- en: '![](elastic.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![弹性](elastic.jpg)'
- en: As you saw in the initial attempt to collect the prey data, achieving elasticity
    is hard. You can’t just add more data-processing units, but that idea is on the
    right track.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在收集猎物数据的初始尝试中看到的，实现弹性是困难的。你不能只是添加更多的数据处理单元，但这个想法是正确的方向。
- en: You’ll need a *distributed database*, one with multiple servers working in concert
    to function as a single database. Rather than a bunch of cheetahs contending to
    write to the same pangolin-controlled computer, you’ll ideally use a database
    where multiple servers can write as well as read, something like [figure 3.8](#ch03fig08).
    True distribution of both `create` and `read` operations is the only way a database
    can scale.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 你将需要一个 *分布式数据库*，其中多个服务器协同工作以作为一个单一数据库运行。而不是一群争相写入同一只河马控制的计算机的猎豹，你理想上会使用一个数据库，其中多个服务器既可以写入也可以读取，就像[图3.8](#ch03fig08)所示。`创建`和`读取`操作的真正分布式是数据库可以扩展的唯一方式。
- en: '![](resilient.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![resilient.jpg](resilient.jpg)'
- en: Figure 3.8\. A distributed database
  id: totrans-140
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.8\. 分布式数据库
- en: '![](03fig08_alt.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![03fig08_alt.jpg](03fig08_alt.jpg)'
- en: The other reactive principle to consider is resilience. In the Serengeti, you
    know that resources can disappear. Some days the rivers will flood and water will
    be abundant. Other times, the ground will be scorched by the blazing African sun,
    and you’ll need to walk for days to find water.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的反应式原则是弹性。在塞伦盖提，你知道资源可能会消失。有些日子河流会泛滥，水源充足。其他时候，地面会被炽热的非洲太阳烤焦，你需要走几天才能找到水。
- en: Unfortunately, this is exactly how things work for distributed databases. With
    many servers responsible for storing and retrieving your data, it’s inevitable
    that one of them will fail. Maybe it will just fall asleep for a while like a
    lazy lioness neglecting her hunting duties for a midday nap. Or maybe it will
    be worse, and that server will be like Patrick Pangolin, who was last seen in
    the mouth of a hungry cheetah. That’s the circle of life.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这正是分布式数据库的工作方式。由于许多服务器负责存储和检索你的数据，其中之一必然会失败。也许它只是像一只懒惰的母狮在午睡时忽视她的狩猎职责一样，短暂地陷入沉睡。或者也许更糟，那个服务器就像最后被一只饥饿的猎豹吞噬的河马。这就是生命的循环。
- en: '![](replication.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![replication.jpg](replication.jpg)'
- en: 'You wind up in the same place that you were in your quest for elasticity: you
    need a distributed database, where your data is stored redundantly on multiple
    servers. Replication is a consistently relevant strategy when building reactive
    machine learning systems.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 你最终会回到你在弹性追求中的同一个地方：你需要一个分布式数据库，你的数据在多个服务器上冗余存储。在构建反应式机器学习系统时，复制是一个始终相关的策略。
- en: Thankfully, there are all sorts of databases that have many of the properties
    I just described. The one that we’ll use in this book is called Couchbase. It’s
    a distributed database that can both handle the scale of the Great Migration and
    deal with the inevitable failure of servers along the way. Couchbase has a wealth
    of capabilities, far beyond your minimum requirement to create and read large
    numbers of records. In fact, many other databases would work for the example in
    this chapter. The techniques of reactive machine learning are not tied to any
    specific technology. But Couchbase will make it easy for you to get started building
    your database of facts and could easily support any future projects like a prey-movement
    prediction system. As an additional benefit, Couchbase itself is a very reactive
    system, implemented using several reactive strategies. Later in this chapter,
    we’ll take a quick look at how Couchbase, as a highly reactive database, can support
    building reactive data-processing systems.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有许多数据库具有我刚刚描述的许多属性。我们将在这本书中使用的是Couchbase。它是一个可以处理大迁徙规模的分布式数据库，并且可以处理沿途服务器不可避免的故障。Couchbase具有丰富的功能，远远超出了创建和读取大量记录的最低要求。实际上，许多其他数据库也可以用于本章的示例。反应式机器学习的技巧并不绑定到任何特定的技术。但Couchbase将使你轻松开始构建你的事实数据库，并且可以轻松支持任何未来的项目，如猎物移动预测系统。作为额外的优势，Couchbase本身是一个非常反应式的系统，使用了多种反应式策略。在本章的后面，我们将快速看一下Couchbase作为高度反应式数据库如何支持构建反应式数据处理系统。
- en: 3.3.2\. Fact databases
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2\. 事实数据库
- en: '![](immutable-facts.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![不可变事实](immutable-facts.jpg)'
- en: One of the tools you’ll use to scale the prey-movement system is a *fact-based
    data model*. Earlier in this chapter, I talked about facts as a useful technique
    for raw-data capture. You can express the enriched data model you saw earlier
    in the form of a standard case class.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用的一种工具来扩展猎物移动系统是 *基于事实的数据模型*。在本章的早期，我谈到了事实作为原始数据捕获的有用技术。你可以将之前看到的丰富数据模型表达为标准的案例类。
- en: Listing 3.6\. Sensor-readings case class
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.6\. 传感器读数案例类
- en: '[PRE5]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This case class represents an individual sensor reading.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这个案例类代表了一个单独的传感器读数。
- en: You’ll store your data in the form of JSON documents. Databases that support
    this style of data model are sometimes called *document stores*. Couchbase uses
    a document data model where the documents are stored inside buckets. *Buckets*
    serve a similar purpose as tables do in traditional relational databases, but
    they don’t require the definition of the structure of those documents to be defined
    in the database itself. They’ll accept any documents that you choose to write.
    You don’t need to do anything to the database before it can accept documents of
    your readings for persistence. Not having to plan all aspects of your data model
    in advance can make it easier to deal with evolution in your data model, such
    as when you added richer information about sensor uncertainty. Chapter 11 discusses
    more about handling the evolution of a reactive machine learning system.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 你将以JSON文档的形式存储你的数据。支持这种数据模型风格的数据库有时被称为*文档存储*。Couchbase使用文档数据模型，其中文档存储在桶中。*桶*在传统的关系数据库中类似于表的作用，但它们不需要在数据库本身中定义这些文档的结构。它们将接受你选择的任何文档。在能够接受你的读数文档以进行持久化之前，你不需要对数据库进行任何操作。不必提前规划数据模型的各个方面可以使处理数据模型的变化（例如，当你添加有关传感器不确定性的更丰富信息时）变得更加容易。第11章讨论了更多关于处理反应式机器学习系统演变的内容。
- en: To persist instances of the sensor-reading case class, you have to define a
    formatter that can convert those instances into an equivalent JSON representation
    that can be stored in the database.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了持久化传感器读数案例类的实例，你必须定义一个可以将这些实例转换为等效的JSON表示的格式化器，该表示可以存储在数据库中。
- en: Listing 3.7\. Creating sensor-reading documents
  id: totrans-155
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.7\. 创建传感器读数文档
- en: '[PRE6]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '***1* Creates a database connection to the default bucket**'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建到默认桶的数据库连接**'
- en: '***2* Execution context to use with futures**'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 用于future的执行上下文**'
- en: '***3* Formatter to use to convert the case class into JSON**'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 用于将案例类转换为JSON的格式化器**'
- en: '***4* Helper function to create a composite primary key for PreyReading documents**'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 用于为PreyReading文档创建复合主键的辅助函数**'
- en: '***5* Example sensor reading**'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 示例传感器读数**'
- en: '***6* Operation to insert reading as a document that returns a Future**'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 将读数作为文档插入并返回Future的操作**'
- en: '***7* Prints the result of the insertion operation for illustrative purposes**'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 为了说明目的打印插入操作的结果**'
- en: '|  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Implicits**'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**隐式转换**'
- en: You may have noticed that [listing 3.7](#ch03ex07) uses *implicits*. The implicit
    formatter you created defines a way of converting the `PreyReading` case class
    into JSON. Had you not created this formatter, the library you use to interact
    with the database wouldn’t know how to perform this conversion and wouldn’t be
    able to save instances of sensor readings to the database. The `implicit` keyword
    makes that conversion available for use without requiring you to explicitly perform
    the conversion yourself. The compiler will infer that the formatter should be
    used to perform this conversion during the compilation of your program and insert
    the conversion code. Implicits are a unique and powerful feature of Scala. You’ll
    come across them all the time in idiomatically written Scala code. For a more
    thorough introduction to implicits and their use, check out *Scala in Depth* by
    Joshua D. Suereth (Manning Publications, 2012).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到[列表 3.7](#ch03ex07)使用了*隐式转换*。你创建的隐式格式化器定义了一种将`PreyReading`案例类转换为JSON的方式。如果你没有创建这个格式化器，你用来与数据库交互的库将不知道如何执行这种转换，并且无法将传感器读数实例保存到数据库中。`implicit`关键字使得这种转换可以在不要求你显式执行转换的情况下使用。编译器将在编译你的程序时推断出应该使用格式化器来执行这种转换，并插入转换代码。隐式转换是Scala的一个独特而强大的特性。你会在编写Scala代码时经常遇到它们。要更深入地了解隐式转换及其用法，请参阅Joshua
    D. Suereth（Manning Publications，2012年）所著的《Scala深度》。
- en: '|  |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '![](resilient.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](resilient.jpg)'
- en: Separating the definition of an action from the execution of that action is
    often a helpful idiom. In this case, it helps you encode that the insertion both
    is going to take time and could possibly fail. For example, you could replace
    the failure case in the pattern match with retry logic or some meaningful notification.
    Recognizing and encoding the possibility of failure is a key step toward building
    resilience into a system.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个动作的定义与其执行分离通常是一个有用的习语。在这种情况下，它有助于你编码插入操作将花费时间并且可能失败的可能性。例如，你可以在模式匹配中的失败情况替换为重试逻辑或一些有意义的通知。识别并编码失败的可能性是构建系统弹性的关键步骤。
- en: '![](elastic.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](elastic.jpg)'
- en: This style of database interaction relies on futures, a technique you saw in
    [chapter 2](kindle_split_012.html#ch02). One of the main benefits of this programming
    style comes out of operations like the database insertion being non-blocking.
    The call to `bucket.set` returns immediately. Because insertions into a remote
    database take time, the driver doesn’t tie up the main thread of execution of
    your program waiting on the data to travel to the remote database and a successful
    insertion message to come back. This future-based, non-blocking programming style
    works well with the goal of consistent operation under varying load.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数据库交互风格依赖于未来（futures），这是你在[第2章](kindle_split_012.html#ch02)中看到的技术。这种编程风格的主要好处之一来自于数据库插入的非阻塞操作。`bucket.set`的调用会立即返回。因为远程数据库的插入需要时间，驱动程序不会阻塞程序的主执行线程等待数据传输到远程数据库以及成功插入消息返回。这种基于未来的非阻塞编程风格非常适合在变化负载下保持一致操作的目标。
- en: There’s more in this approach to data collection that supports elasticity. Many
    different data-collection program instances can be writing to many different database
    nodes at the same time without any need to lock individual items and coordinate
    access. This is similar to the final architecture of multiple cheetahs talking
    to multiple pangolins that you saw in the previous section, but it’s even better.
    Thanks to the power of a non-blocking driver, it’s almost like the cheetahs can
    just drop off their messages and run away. They don’t need to wait for the slow
    pangolin to actually make the update. The cheetahs certainly don’t need to wait
    for the pangolins to coordinate access to the shared mutable state object among
    themselves, because there’s no shared mutable state. But how do you figure out
    the current state of the savannah from a database full of raw facts?
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种数据收集方法中，还有更多支持弹性的内容。许多不同的数据收集程序实例可以同时向许多不同的数据库节点写入数据，而无需锁定单个项目并协调访问。这与你在上一节中看到的多个猎豹与多个穿山甲通信的最终架构类似，但更好。多亏了非阻塞驱动程序的力量，几乎就像是猎豹们可以放下他们的消息然后跑掉。它们不需要等待慢吞吞的穿山甲实际进行更新。猎豹们当然不需要等待穿山甲们自己之间协调对共享可变状态对象的访问，因为根本不存在共享可变状态。但是，你如何从一个充满原始事实的数据库中确定撒哈拉草原的当前状态呢？
- en: 3.3.3\. Querying persisted facts
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.3\. 查询持久事实
- en: The easiest way to see data in your database is to define some structure on
    top of the data you’ve inserted. Being able to define this structure after you’ve
    inserted the data is one of the unique features of modern, flexible databases,
    in contrast to the more rigid relational databases you may be familiar with. You’ve
    been recording your data as JSON documents, and now you need to express some information
    about the structure of your documents using JavaScript. Don’t worry if you’re
    not familiar with JavaScript. You’ll only be writing simple JavaScript to define
    the structure of views on top of raw data. [Listing 3.8](#ch03ex08) defines a
    view on top of the data you’ve written to your database instance that allows you
    to retrieve documents by sensor ID. That view will be defined in terms of a *design
    document*, which is another way of saying *stored query*.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的数据库中查看数据的最简单方法是为你已插入的数据定义一些结构。在你插入数据后能够定义这种结构是现代灵活数据库的独特特性之一，与你可能熟悉的更严格的数据库关系型数据库相比。你一直以JSON文档的形式记录数据，现在你需要使用JavaScript来表示一些关于文档结构的信息。如果你不熟悉JavaScript，请不要担心。你只需编写简单的JavaScript来定义在原始数据之上的视图结构。[列表3.8](#ch03ex08)定义了一个视图，该视图允许你通过传感器ID检索文档。这个视图将以*设计文档*的形式定义，这另一种说法就是*存储查询*。
- en: Listing 3.8\. Creating a sensor ID view
  id: totrans-175
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.8\. 创建传感器ID视图
- en: '[PRE7]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '***1* Blocks to wait for the future to complete, for illustrative purposes**'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 用于等待未来完成的阻塞操作，仅用于说明**'
- en: '***2* Creates a design doc (in JavaScript) called prey**'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 创建一个名为“prey”的设计文档（JavaScript格式）**'
- en: '***3* Defines views in this design doc**'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 在这个设计文档中定义视图**'
- en: '***4* Creates a view by sensor ID**'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 通过传感器ID创建视图**'
- en: '***5* Creates a function to emit all documents with a sensor ID**'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 创建一个函数来发射所有具有传感器ID的文档**'
- en: By defining this view, you’ve created indexes on documents by their sensor IDs.
    This will make it simple and fast to look up documents by sensor ID.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 通过定义这个视图，你已经在文档的传感器ID上创建了索引。这将使得通过传感器ID查找文档变得简单快捷。
- en: '|  |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Blocking**'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**阻塞**'
- en: I’ve been calling out the benefits of non-blocking, futures-based interactions,
    so it may seem strange to be blocking to see these benefits. The reason you may
    want to use blocking in a small, exploratory context like this is that it allows
    you to see the results of the small piece of code you’re working on by forcing
    the future to complete. In a fully implemented and properly composed system, you
    wouldn’t want to rely on calls to `Await.result`. You’d want to use this technique
    primarily in an exploratory or debugging context.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我一直在强调基于非阻塞、未来交互的好处，所以看到这些好处需要阻塞可能看起来很奇怪。你可能想在这样一个小型的探索性环境中使用阻塞，因为这样可以强制未来完成，从而看到你正在工作的那小段代码的结果。在一个完全实现且正确组合的系统里，你不会想依赖于对
    `Await.result` 的调用。你主要想在这个探索或调试的上下文中使用这种技术。
- en: '|  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: In a fully populated database backing a real application, this view creation
    could take a meaningful amount of time to create the necessary data structures
    to return the data expressed in the view. In Couchbase, this issue is managed
    by separating a development view, what you’ve just created, from a production
    view. Different distributed databases choose to implement views differently or
    not at all, so it’s worth understanding the specifics of the database that you’re
    using when implementing a real system. But this query-centric workflow is common
    to a wide range of distributed non-relational databases.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在支持真实应用程序的完全填充的数据库中，这个视图创建可能需要花费相当长的时间来创建返回视图中所表达数据所需的数据结构。在 Couchbase 中，这个问题通过将开发视图（你刚刚创建的）与生产视图分开来管理。不同的分布式数据库选择以不同的方式实现视图或根本不实现，所以在实现真实系统时了解你使用的数据库的具体细节是值得的。但这个以查询为中心的工作流程在广泛的分布式非关系数据库中是常见的。
- en: '![](pure-functions.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](pure-functions.jpg)'
- en: Note that Couchbase views are defined in terms of higher-order functions using
    a map-reduce syntax, with both the map and reduce phases being expressed as higher-order
    functions. Defining views in terms of map-reduce operations may feel strange to
    you if you have experience with views in relational databases. Modern distributed
    non-relational databases often blur the lines between the data processing done
    by the application and the data processing done by the database. Certainly, you
    could implement this exact same view in your application code in Scala, but that
    would require you to effectively process the entire contents of the database for
    any given query. When your use of a distributed database reduces to a brute-force
    full-table scan for a query, usually there’s something wrong at the design level
    in your application (or the database!). It’s better to have the database take
    on this work itself, if for no other reason than that the view-maintenance work
    will be done only once per view rather than once per query.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Couchbase 视图是用 map-reduce 语法定义的，其中 map 和 reduce 阶段都表示为高阶函数。如果你在关系数据库中经验丰富，那么用
    map-reduce 操作来定义视图可能会让你感到奇怪。现代分布式非关系数据库通常模糊了应用程序执行的数据处理和数据库执行的数据处理之间的界限。当然，你可以在
    Scala 应用程序代码中实现这个完全相同的视图，但这将要求你有效地处理数据库的整个内容以进行任何给定的查询。当你的分布式数据库的使用简化为查询的全表扫描时，通常意味着你的应用程序（或数据库）在设计层面存在问题！如果只是为了视图维护工作只做一次而不是每次查询都做一次，那么让数据库自己承担这项工作会更好。
- en: Once you have this view, you can retrieve that last reading that you recorded
    in [listing 3.7](#ch03ex07). To do so, you can just find the reading with the
    matching sensor ID, using the code in the following listing.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了这个视图，你可以检索你在[列表 3.7](#ch03ex07)中记录的最后一次读取。为此，你可以使用以下列表中的代码找到匹配的传感器 ID 的读取。
- en: Listing 3.9\. All records for a sensor
  id: totrans-191
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.9\. 一个传感器的所有记录
- en: '[PRE8]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '***1* Searches for PreyReading values**'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 搜索 PreyReading 值**'
- en: '***2* Design document and view to use**'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 设计文档和视图以使用**'
- en: '***3* Creates a new query**'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 创建一个新的查询**'
- en: '***4* Defines the key of the document queried to be for sensor 36**'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 定义查询的文档键为传感器 36**'
- en: '***5* Forces the result to a list**'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 强制结果转换为列表**'
- en: '***6* Forces the result to a list**'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 强制结果转换为列表**'
- en: '***7* Prints the retrieved reading**'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 打印检索到的读取**'
- en: If you only wrote the sensor reading from [listing 3.7](#ch03ex07), then this
    query will just operate over that one document. But very similar querying syntax
    will return all the readings that have ever been recorded for that sensor.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只从[列表 3.7](#ch03ex07)中写入了传感器读取，那么这个查询将只在这个文档上操作。但非常相似的查询语法将返回该传感器所有曾经记录的读取。
- en: To see how operations on a large sequence of facts work, the next listing creates
    some synthetic data to play with.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解对大量事实的操作如何工作，下一个列表创建了一些用于玩耍的合成数据。
- en: Listing 3.10\. Inserting many random records
  id: totrans-202
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.10\. 插入大量随机记录
- en: '[PRE9]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '***1* Produces 100 random sensor readings**'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 生成 100 个随机传感器读数**'
- en: '***2* Inserts all the random readings as a stream**'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将所有随机读数作为流插入**'
- en: '***3* Maps over each result and prints the result**'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 遍历每个结果并打印结果**'
- en: Now you should have a lot more facts in your database to work with.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该有更多的事实在你的数据库中可以工作。
- en: '|  |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Enumerators**'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**枚举器**'
- en: '[Listing 3.10](#ch03ex10) uses `Enumerator` from the Play web framework. An
    *enumerator* is a source of data that pushes input into some recipient. Enumeration
    is simply operating over each item in the collection one by one. When complete,
    a Play `Enumerator` will return the final state of the recipient, using a futures-based
    programming technique called a `Promise` (discussed later in this book). In this
    case, you’re using enumerators as way of sending a stream of values to the database
    for persistence. In a real system, the data being enumerated would come from multiple
    sensors sending back sensor-reading data.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 3.10](#ch03ex10) 使用 Play 网络框架中的 `Enumerator`。一个 *enumerator* 是一个将输入推送到某个接收者的数据源。枚举就是逐个操作集合中的每个项目。当完成时，Play
    的 `Enumerator` 将使用基于未来的编程技术 `Promise`（本书稍后讨论）返回接收者的最终状态。在这种情况下，你使用枚举器作为将值流式传输到数据库以进行持久化的方式。在实际系统中，枚举的数据将来自多个发送传感器读数数据的传感器。'
- en: '|  |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: You can use this database of facts to answer questions about the current state
    of the savannah. For example, you can define a time-based view of readings from
    sensor 36 using the view in the following listing.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用这个事实数据库来回答关于萨瓦纳当前状态的问题。例如，你可以使用以下列表中的视图定义传感器 36 的基于时间的读数视图。
- en: Listing 3.11\. A time-based view of sensor readings
  id: totrans-213
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.11\. 基于时间的传感器读数视图
- en: '[PRE10]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '***1* Defines this view for sensor 36 only**'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 仅为此传感器 36 定义此视图**'
- en: Because you haven’t thrown away any data through mutating some state, it’s easy
    to get a picture of the recent readings and the way things have been trending.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你没有通过修改某些状态而丢弃任何数据，因此很容易了解最近的读数和事物的发展趋势。
- en: Listing 3.12\. The 10 most recent sensor readings
  id: totrans-217
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.12\. 最近的十个传感器读数
- en: '[PRE11]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '***1* Orders by the most recent readings**'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 按最近读数排序**'
- en: '***2* Takes only the 10 most recent readings**'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 只取最近的十个读数**'
- en: Or you can jump back to a specific point in time.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 或者你可以跳回到特定的时间点。
- en: Listing 3.13\. An individual old sensor reading
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.13\. 单个旧传感器读数
- en: '[PRE12]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '***1* Skips the nine most recent readings**'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 跳过最近的九个读数**'
- en: '***2* Only returns the tenth most recent reading**'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 只返回第十个最近的读数**'
- en: It’s important to note that this design gets around the problems shown with
    out-of-order updates you encountered in [listing 3.5](#ch03ex05). In the previous
    system, because you had scaled the data-collection system out to have multiple
    cheetahs bringing updates to multiple pangolins, an old update could get applied
    over a newer one and destroy any record of that fact. In the revised system, that’s
    not possible because you store all sensor readings without ever throwing any away.
    The code in the following listing shows how to intentionally insert the records
    out of order.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，这种设计绕过了你在 [列表 3.5](#ch03ex05) 中遇到的乱序更新的问题。在之前的系统中，由于你将数据收集系统扩展到有多个猎豹向多个穿山甲提供更新，一个旧更新可能会覆盖一个较新的更新并破坏该事实的任何记录。在修订后的系统中，这是不可能的，因为你存储了所有传感器读数，从未丢弃任何数据。以下列表中的代码显示了如何有意地乱序插入记录。
- en: Listing 3.14\. Inserting out-of-order readings
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.14\. 插入乱序读数
- en: '[PRE13]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '***1* First reading collected**'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 第一次收集读数**'
- en: '***2* Second reading collected**'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 第二次收集读数**'
- en: '***3* Defines a list of readings in the wrong order**'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 定义了一个顺序错误的读数列表**'
- en: '***4* Inserts readings out of order**'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 按顺序插入读数**'
- en: Insertion order doesn’t matter now, so all the queries shown here work exactly
    the same whether the records are inserted in order or out of order. You can see
    this by retrieving the last two sensor readings.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 插入顺序现在不重要，所以这里显示的所有查询，无论是按顺序还是乱序插入记录，都完全相同。你可以通过检索最后两个传感器读数来看到这一点。
- en: Listing 3.15\. Retrieving the last two readings
  id: totrans-234
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.15\. 获取最后两个读数
- en: '[PRE14]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This query returns the same result regardless of whether the records were inserted
    in order or out of order, because no data is lost and the sortation is determined
    by the query. You no longer have to risk an out-of-order update corrupting your
    view of the savannah by writing over old data with new. You’re free to scale out
    your data-collection operation to arbitrary scale without concern for insertion
    order of updates.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这个查询返回的结果不受记录是按顺序还是无序插入的影响，因为没有任何数据丢失，排序由查询决定。你不再需要冒险通过用新数据覆盖旧数据来破坏你对萨凡纳视图的有序更新。你可以自由地扩展你的数据收集操作到任意规模，而不必担心更新的插入顺序。
- en: 3.3.4\. Understanding distributed-fact databases
  id: totrans-237
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.4\. 理解分布式事实数据库
- en: '![](immutable-facts.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](immutable-facts.jpg)'
- en: Now that you’ve gotten your prey-data collection under control, it might help
    to zoom out and understand why this alternative approach works so much better.
    First, you’ve kept all the richness of your knowledge of the source data. Sensor
    readings are uncertain, and that uncertainty is persisted in your database.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经控制了你的猎物数据收集，可能有助于放大视角，理解为什么这种替代方法工作得如此之好。首先，你保留了你对源数据所有丰富知识。传感器读数是不确定的，这种不确定性被保存在你的数据库中。
- en: By not transforming your raw data before persisting it, you maintain a true
    record of the data the sensors collected. This history of facts is much richer
    and more useful than a single mutated value. An immutable-fact database can tell
    you anything you’ll ever want to know about the state of the savannah.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在持久化之前不转换原始数据，你保留了传感器收集数据的真实记录。这个事实的历史比单个突变值要丰富得多，也更有用。不可变事实数据库可以告诉你关于萨凡纳状态的任何你想要知道的事情。
- en: Next, you achieved true horizontal scalability thanks to the combination of
    a good data architecture and a very elastic database. You can continue to add
    data-collection applications, and your data model and your database will now support
    arbitrary increases in scale. In this respect, Couchbase gives you even stronger
    guarantees than many databases. Each node in your database cluster has the same
    responsibilities and capabilities, so the architecture of the final system is
    very close to the ideal shown in the original distributed-database diagram, shown
    in [figure 3.9](#ch03fig09).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你通过良好的数据架构和非常弹性的数据库的组合实现了真正的水平扩展。你可以继续添加数据收集应用程序，你的数据模型和数据库现在将支持任意规模的增加。在这方面，Couchbase
    给你比许多数据库更强的保证。你数据库集群中的每个节点都有相同的职责和能力，因此最终系统的架构非常接近原始分布式数据库图中的理想，如图 3.9 所示。
- en: '![](elastic.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](elastic.jpg)'
- en: Figure 3.9\. A distributed database
  id: totrans-243
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.9\. 分布式数据库
- en: '![](03fig09_alt.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig09_alt.jpg)'
- en: There’s no single throughput bottleneck for reads or writes. The fact-based
    data model ensures that multiple operations aren’t contending over a shared mutable
    value, so your ability to scale out is limited only by your infrastructure budget.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 读取或写入没有单一的吞吐量瓶颈。基于事实的数据模型确保多个操作不会争夺共享的可变值，因此你扩展能力的限制仅限于你的基础设施预算。
- en: '![](resilient.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](resilient.jpg)'
- en: This architecture also has important fault-tolerance capabilities. Should the
    network partition your nodes in some way, your database will remain usable.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构还具有重要的容错能力。如果网络以某种方式分区你的节点，你的数据库仍然可用。
- en: Tolerance to network partitions is a difficult property for a database design
    to support. Strategies for greater partition tolerance have been some of the most
    important innovations in database development. Moreover, your data model works
    in tandem with the capabilities provided by the database infrastructure. In the
    event of a network partition, the fact data that the database returns will be
    an accurate, if possibly incomplete, view of the data collected. The potential
    for an incomplete view of the data is unavoidable in a distributed database with
    partition tolerance. When the network prevents communication across the cluster,
    some portion of your data is unavailable; no database can change that. Instead
    of degrading responsiveness, databases like Couchbase choose to return the data
    that is available. That’s not a problem for your application. Consider the sequence
    of sensor readings about the count of zebras believed to be at Location 55, shown
    in [figure 3.10](#ch03fig10).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 对网络分区容忍度是数据库设计难以支持的一个特性。提高分区容忍度的策略是数据库发展中一些最重要的创新之一。此外，你的数据模型与数据库基础设施提供的功能协同工作。在网络分区的情况下，数据库返回的事实数据将是一个准确、可能不完整的收集数据的视图。在具有分区容忍度的分布式数据库中，数据不完整视图的可能性是不可避免的。当网络阻止集群间的通信时，你的数据中的一部分将不可用；没有任何数据库可以改变这一点。与降低响应性不同，像Couchbase这样的数据库选择返回可用的数据。这对你的应用程序来说不是问题。考虑关于位置55上被认为存在的斑马数量的传感器读取序列，如图3.10所示。
- en: Figure 3.10\. Complete zebra-sensor readings
  id: totrans-249
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.10。完整的斑马传感器读取
- en: '![](03fig10.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig10.jpg)'
- en: This series of readings relies on the data stored in all the nodes of the database
    cluster. Due to the uncertainties of the network, you could lose access to some
    of the nodes in your cluster ([figure 3.11](#ch03fig11)).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这一系列的读取依赖于数据库集群中所有节点存储的数据。由于网络的不可靠性，你可能会失去对集群中某些节点的访问权限（[图3.11](#ch03fig11)）。
- en: Figure 3.11\. A network partition
  id: totrans-252
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.11。网络分区
- en: '![](03fig11_alt.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig11_alt.jpg)'
- en: The database client library used in the update-processor program instances will
    route to the still reachable nodes. But because your data is distributed throughout
    the cluster, it’s possible that you might only have access to some of the data
    temporarily. For example, you may only have the readings shown in [figure 3.12](#ch03fig12).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 更新处理器程序实例中使用的数据库客户端库将路由到仍然可达的节点。但是，由于你的数据在集群中分布，你可能只能临时访问部分数据。例如，你可能只有[图3.12](#ch03fig12)中显示的读取。
- en: Figure 3.12\. Incomplete zebra sensor readings
  id: totrans-255
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.12。不完整的斑马传感器读取
- en: '![](03fig12.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig12.jpg)'
- en: 'For many applications, this partial view of the database would be entirely
    usable. After all, the facts recorded don’t reflect a current certainty that a
    definite number of zebras are present at Location 55\. You could even use a linear
    model to interpolate the missing value if you wanted to. The trend is the same,
    and the overall picture provided by a query over readings would present a similar
    view. The actions you would choose to take upon seeing this incomplete data are
    likely the same that you would take upon seeing the full dataset: you would send
    out some lionesses to go get you some lunch with stripes on it. By using a fact-based
    data model with explicit uncertainty, you’ve already built the ability to handle
    incomplete views of data into your usage of the database.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多应用来说，这个数据库的部分视图完全可以使用。毕竟，记录的事实并没有反映出当前在位置55确实有特定数量的斑马存在。如果你想要的话，甚至可以使用线性模型来插补缺失的值。趋势是相同的，查询读取所提供的整体图景将呈现类似的视图。当你看到这些不完整的数据时，你可能会采取的行动与看到完整数据集时采取的行动相同：你会派出一些带有条纹的雌狮去为你找一些午餐。通过使用基于事实的数据模型和显式的不确定性，你已经在数据库的使用中构建了处理数据不完整视图的能力。
- en: '![](replication.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图片](replication.jpg)'
- en: There are even more properties of this system that are worth highlighting. A
    database’s internal *concurrency models* are its plan for how to coordinate multiple
    users. Couchbase uses a concurrency model called *multiversion concurrency control*
    (MVCC). Systems that use MVCC don’t internally lock records for mutation but instead
    replicate data.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这个系统还有更多值得强调的特性。数据库的内部**并发模型**是其协调多个用户的计划。Couchbase使用一种称为**多版本并发控制**（MVCC）的并发模型。使用MVCC的系统在内部不会锁定记录以进行变更，而是复制数据。
- en: '![](message-driven.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![图片](message-driven.jpg)'
- en: As you’ve seen, locking gets in the way of scaling out write operations. A Couchbase
    cluster doesn’t have the problems of trying to hold locks across nodes, because
    within the cluster, actions are coordinated via message passing.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，锁定会阻碍写操作的扩展。Couchbase集群没有在节点之间尝试保持锁的问题，因为在集群内部，操作是通过消息传递进行协调的。
- en: '![](supervision.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![监督](supervision.jpg)'
- en: This message passing occurs within an actor system using a supervisory hierarchy.
    As you’ve seen before and we’ll discuss more in future chapters, using supervisory
    hierarchies is an excellent strategy for ensuring resilience in the face of failure.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这种消息传递是在一个actor系统中使用监督层次结构进行的。正如你之前看到的，我们将在未来的章节中进一步讨论，使用监督层次结构是确保面对失败时具有弹性的优秀策略。
- en: '|  |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Erlang and OTP**'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '**Erlang 和 OTP**'
- en: The actor model implementation in Couchbase isn’t Akka. Rather, it’s built in
    a language called Erlang using the OTP libraries. Erlang and OTP (the Open Telecom
    Platform) were originally built for telecommunications applications. More recently,
    Erlang and OTP have become popular within the implementation of distributed databases
    like Couchbase and Riak. But the actor-model implementations in both systems are
    closely related (for example, frequent use of pattern matching). In fact, Jonas
    Bonér created Akka based on his experiences with Erlang and OTP.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: Couchbase 中的actor模型实现不是Akka。相反，它是使用Erlang语言和OTP库构建的。Erlang 和 OTP（开放电信平台）最初是为电信应用而构建的。最近，Erlang
    和 OTP 在像Couchbase和Riak这样的分布式数据库实现中变得流行。但这两个系统中的actor模型实现密切相关（例如，频繁使用模式匹配）。事实上，Jonas
    Bonér就是基于他在Erlang和OTP方面的经验创建了Akka。
- en: '|  |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: All these characteristics of the database’s capabilities align with your larger
    goals in building a reactive machine learning system. This alignment of vision
    has a real impact on the performance you can expect from the database and the
    guarantees it provides. Because your data model no longer relies on shared mutable
    state that must be maintained with locks, you can take advantage of the extreme
    scalability capabilities of a database oriented around massive concurrency.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库功能的所有这些特性都与您构建反应式机器学习系统的更大目标相一致。这种愿景的一致性对您可以从数据库中期望的性能和它提供的保证有实际影响。因为您的数据模型不再依赖于必须使用锁来维护的共享可变状态，您可以利用围绕大量并发性构建的数据库的极端可扩展性能力。
- en: 'Finally, the main reason why this data architecture works so well is that it’s
    based on ideas that work well in reality, not just in software:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这种数据架构之所以如此有效，主要原因是它基于在现实中有效，而不仅仅是软件中的想法：
- en: '*Facts are always true*. Future facts don’t erase old facts. If there were
    gazelles down by the river this morning, that then that statement is always true,
    even after the gazelles have moved on. You don’t need to forget the gazelles from
    the morning just because you no longer go down there and eat them.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*事实总是真实的*。未来的事实不会抹去旧的事实。如果今天早上河边的羚羊还在，那么这个陈述就始终是真实的，即使羚羊已经离开了。你不需要因为不再去那里吃它们而忘记早上的羚羊。'
- en: '*Central control leads to contention*. Even though you’re the Lion Queen, you
    can’t make the impossible possible. A pangolin can only move so fast, and cheetahs
    don’t have the patience for data entry. They can’t all coordinate through a single
    point of control and still be all over the savannah at the same time. It’s the
    same reason you don’t have all your lionesses come back to you to ask if they
    should take down a slow-moving wildebeest. If everything had to go through a single
    point of control, whether that point of control is you or any other lion, nothing
    would ever get done.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*中央控制导致竞争*. 即使你是狮子女王，也无法让不可能的事情成为可能。穿山甲只能跑得这么快，猎豹对数据录入也没有耐心。它们不能通过一个控制点进行协调，同时还能在草原上四处游荡。这也是为什么你不会让所有的母狮都回来问你，是否应该捕杀行动缓慢的角马。如果所有的事情都必须通过一个控制点进行，无论这个控制点是您还是任何其他狮子，那么什么都不会完成。'
- en: '*You can’t know anything for certain*. The savannah is a sprawling, chaotic,
    distributed system, and the view from Lion Rock only stretches so far. Maybe the
    cheetahs didn’t really eat Patrick Pangolin. Who’s to say? All you or any other
    lion can do is record all the uncertain facts that come your way and do your best
    with the knowledge that you have. Being a responsible queen means acknowledging
    the limits of what you know, because the real world of Africa is uncertain. Acknowledging
    that you’re not omniscient is part of making good decisions on behalf of the pride.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你无法确定任何事情*。草原是一个广阔、混乱、分布式的系统，狮子岩的视野也只有那么远。也许猎豹并没有真正吃掉帕特里克· pangolin。谁又能说呢？你或任何其他狮子所能做的就是记录所有不确定的事实，并尽你所能利用你所拥有的知识。作为一个负责任的皇后，意味着承认你所知道的局限，因为非洲的真实世界是不确定的。承认你不是全知全能的是代表家族做出良好决策的一部分。'
- en: The principled but pragmatic approach you’ve taken to building out your data-collection
    capabilities has since paid off. You’ve been able to feed your pride more consistently
    and use your time more effectively. Predators across Africa are envious of your
    all-encompassing view of the savannah. The approaches you’ve used in this chapter
    have also put you in an excellent position to build new capabilities in the future.
    Next up, you’re considering building a feature-extraction system to power machine
    learning predictions. The work of a Lion Queen is never done, but you’ve done
    well for your pride. You should be proud.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 你在构建数据收集能力时所采取的既原则又实际的方法已经得到了回报。你能够更一致地满足你的自豪感，并更有效地利用你的时间。非洲的捕食者对你的整个草原观都感到羡慕。你在本章中使用的方法也使你处于一个极好的位置，可以未来构建新的能力。接下来，你正在考虑构建一个特征提取系统来支持机器学习预测。狮后女王的工作永远不会结束，但你已经为你的家族做得很好。你应该感到自豪。
- en: 3.4\. Applications
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4. 应用
- en: You may not live in the Serengeti. You may not operate a distributed sensor
    network. You may not even be a lion. Can you still apply the techniques used in
    this chapter? Of course you can.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能不住在塞伦盖提。你可能不会操作分布式传感器网络。你可能甚至不是一只狮子。你还能应用本章中使用的技巧吗？当然可以。
- en: 'All sorts of systems produce massive amounts of data that must be collected
    to be put to use. Cell phones are full of various sensors, many of which send
    data back to remote servers. For example, location data is collected by phones
    and used to guide location-specific recommendations. Even without the use of sensor
    hardware, most mobile apps send all sorts of data back to remote servers about
    interactions with the app: swipes, notification dismissals, and so on. This data
    can be used to determine things like application usage patterns and relate groups
    of users (for example, subway commuters).'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 各种系统产生大量数据，这些数据必须被收集起来才能投入使用。手机中充满了各种传感器，其中许多会将数据发送回远程服务器。例如，手机收集位置数据，用于提供特定位置的建议。即使没有使用传感器硬件，大多数移动应用也会将各种数据发送回远程服务器，关于与应用程序的交互：滑动、通知取消等。这些数据可以用来确定应用程序的使用模式，并将用户群体（例如，地铁通勤者）联系起来。
- en: And it’s not just phones and wildlife. A huge range of traditional products
    now produce data that can be collected and used in machine learning systems. We
    live in a world where robot vacuums and electric cars are real and even common.
    The amount of data we’re producing as a species has exploded over the past decades.
    As you’ve seen in this chapter, working with data at scale is different. The techniques
    demonstrated in this chapter offer real solutions to the problems of working with
    data at scale. If you’re working on an existing system that uses a different approach
    to handling data, it may not be clear that all the techniques used in this chapter
    are necessary. You may be working with data that isn’t as big, fast, or hairy
    as the data from a sensor network tracking the Great Migration. In that case,
    you may not need to use all the techniques shown in this chapter.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅限于手机和野生动物。现在，大量传统产品现在产生可以收集并用于机器学习系统中的数据。我们生活在一个机器人吸尘器和电动汽车真实甚至常见的世界里。作为物种，我们在过去几十年中产生的大量数据已经爆炸式增长。正如你在本章中看到的，大规模处理数据是不同的。本章中展示的技术为大规模处理数据的问题提供了真正的解决方案。如果你正在开发一个使用不同方法处理数据的现有系统，可能并不清楚本章中使用的所有技术都是必要的。你可能正在处理的数据并不像追踪大迁徙的传感器网络中的数据那样大、快或复杂。在这种情况下，你可能不需要使用本章中展示的所有技术。
- en: But even something as innocuous as a watch can now produce an effectively infinite
    amount of data of arbitrary complexity. Once you start looking for applications
    to apply these techniques, it’s not hard to find them. Any system with a concept
    of a user, such as an e-commerce site, could use a fact-based data model to record
    what users do. Even a modest-velocity business application recording customer
    transactions could potentially benefit from removing contention over locked data
    items. The tools in this chapter work incredibly well at scale, but they don’t
    *require* your application to be at scale. Now that you understand the reactive
    approach to data collection, I expect that you’ll find lots of places to put it
    to use.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，即使是像手表这样无害的东西现在也能产生大量任意复杂性的数据。一旦你开始寻找可以应用这些技术的应用，找到它们并不难。任何具有用户概念的系统，如电子商务网站，都可以使用基于事实的数据模型来记录用户的行为。即使是记录客户交易的低速业务应用也可能从移除对锁定数据项的竞争中获得潜在的好处。本章中的工具在规模上工作得非常好，但它们并不
    *要求* 你的应用达到规模。现在你了解了数据收集的反应式方法，我预计你会找到很多可以应用它的地方。
- en: 3.5\. Reactivities
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5. 反应性
- en: '![](dog-ball.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![狗球](dog-ball.jpg)'
- en: 'It’s time to go off on your own and explore the world of reactive data collection.
    This section’s “reactivities” are intended to point you in the direction of venturing
    even further beyond the plains of the Serengeti. There are no right answers for
    these questions; there are merely engaging problems that you can explore even
    more than I’ve had the room to discuss in the space of a book:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候独立探索反应式数据收集的世界了。本节中的“反应性”旨在引导你进一步探索塞伦盖提平原之外的领域。这些问题没有正确答案；它们只是你可以探索的问题，这些问题比我在这本书的空间里讨论的还要多：
- en: '*Implement your own reactive data-collection system.* Really. Start with the
    basics of recording facts. You can use any database you want. Pick whatever database
    you’re most familiar with. Then think about the consequences of that choice:'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实现你自己的反应式数据收集系统。* 真的。从记录事实的基本开始。你可以使用任何你想要的数据库。选择你最熟悉的数据库。然后考虑这个选择可能带来的后果：'
- en: What properties of the database will support making your system more responsive,
    resilient, elastic, and message-driven? In particular, think through how the database
    is going to handle massive increases in load.
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库的哪些属性将支持使你的系统更具响应性、弹性、弹性和消息驱动？特别是，思考数据库如何处理负载的大幅增加。
- en: What’s going to slow down and why?
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么会减慢速度，原因是什么？
- en: Think through the data model you’ve used for your facts—does it include uncertainty?
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想想你为事实使用的数据模型——它是否包括不确定性？
- en: If it didn’t before, how hard would it be to add an explicitly uncertain data
    model?
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果之前没有，添加一个明确的不确定性数据模型有多难？
- en: What sort of queries can you write against your database?
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能对你的数据库编写哪些类型的查询？
- en: If you deleted a bunch of records, how would the results of those queries change?
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你删除了大量记录，这些查询的结果会如何变化？
- en: '*Explore other open source data-collection systems.* They don’t have to be
    explicitly reactive. If you want to focus on the design pattern shown in this
    chapter, it often goes by the name of *event sourcing*. There are even databases
    specifically built around supporting event sourcing. This idea of collecting lots
    of fact data is commonly used in monitoring applications. Can you find any monitoring
    applications that persist all the events in the systems being monitored as databases
    of immutable facts? Try answering some of the same questions about these other
    implementations of data-collection systems that you asked of your own implementation:'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*探索其他开源数据收集系统。* 它们不必是明确反应式的。如果你想专注于本章中展示的设计模式，它通常被称为 *事件溯源*。甚至有专门为支持事件溯源而构建的数据库。收集大量事实数据的思想在监控应用中很常见。你能找到任何将监控系统中所有事件持久化为不可变事实数据库的监控应用吗？尝试回答关于这些其他数据收集系统实现的一些相同问题，就像你对自己的实现提出的问题一样：'
- en: How reactive is this system?
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个系统有多反应？
- en: If something failed, what would happen?
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果某些东西失败了，会发生什么？
- en: If the system were overwhelmed with traffic, would I still be able to query
    data?
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果系统被流量淹没，我还能查询数据吗？
- en: Would I ever want or need to rewrite a “fact” after it was written?
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我在写完“事实”之后，是否需要或需要重写它？
- en: What would happen if I kept pushing data into this system forever?
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我永远向这个系统推送数据，会发生什么？
- en: '|  |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-296
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 备注
- en: You got familiar with Couchbase in this chapter as a way of learning about databases
    in general. You won’t need more specific knowledge of this database for the rest
    of the book, but if you’re interested in the technology, there are several books
    on it.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 你在本章中熟悉了Couchbase，作为了解数据库的一般方式。你不需要对这本书的其余部分有更多关于这个数据库的特定知识，但如果你对这项技术感兴趣，有几本书可以阅读。
- en: '|  |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Summary
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Facts are immutable records of something that happened and the time that it
    happened:'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事实是不可变记录，记录了发生的事情及其发生的时间：
- en: Transforming facts during data collection results in information loss and should
    never be done.
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据收集过程中对事实进行转换会导致信息丢失，这是绝对不应该做的。
- en: Facts should encode any uncertainty about that information.
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事实应该编码关于该信息的任何不确定性。
- en: Data collection can’t work at scale with shared mutable state and locks.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据收集无法通过共享可变状态和锁进行大规模操作。
- en: 'Fact databases solve the problems of collecting data at scale:'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事实数据库解决了大规模收集数据的问题：
- en: Facts can always be written without blocking or using locks.
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事实可以无阻塞或使用锁来编写。
- en: Facts can be written in any order.
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事实可以按任何顺序编写。
- en: Futures-based programming handles the possibility that operations can take time
    and even fail.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于未来的编程处理操作可能需要时间甚至失败的可能性。
- en: In the next chapter, we’ll put all this raw fact data to use by deriving semantically
    meaningful features from it. These features will be the first step in our process
    of extracting insight from data. We’ll be using Spark again to show how to build
    feature-extraction pipelines that are both elegant and massively scalable.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将利用这些原始事实数据，通过从中提取语义上有意义的特征来将其投入使用。这些特征将是我们的数据洞察提取过程中的第一步。我们将再次使用Spark来展示如何构建既优雅又大规模可扩展的特征提取管道。
- en: Chapter 4\. Generating features
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四章\. 生成特征
- en: '*This chapter covers*'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Extracting features from raw data
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从原始数据中提取特征
- en: Transforming features to make them more useful
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将特征转换为更有用的形式
- en: Selecting among the features you’ve created
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你创建的特征中选择
- en: How to organize feature-generation code
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何组织特征生成代码
- en: This chapter is the next step on our journey through the components, or phases,
    of a machine learning system, shown in [figure 4.1](#ch04fig01). The chapter focuses
    on turning raw data into useful representations called *features*. The process
    of building systems that can generate features from data, sometimes called *feature
    engineering*, can be deceptively complex. Often, people begin with an intuitive
    understanding of *what* they want the features used in a system to be, with few
    plans for *how* those features will be produced. Without a solid plan, the process
    of feature engineering can easily get off track, as you saw in the Sniffable example
    from [chapter 1](kindle_split_011.html#ch01).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是我们探索机器学习系统组件或阶段旅程的下一步，如图4.1所示。本章重点在于将原始数据转换为有用的表示，称为*特征*。构建能够从数据中生成特征的系统（有时称为*特征工程*）的过程可能具有欺骗性的复杂性。通常，人们从对*想要系统中的特征是什么*的直观理解开始，而对*如何产生这些特征*的计划很少。没有坚实的计划，特征工程的过程很容易偏离轨道，正如你在第1章的Sniffable示例中看到的那样。
- en: Figure 4.1\. Phases of machine learning
  id: totrans-316
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.1\. 机器学习阶段
- en: '![](04fig01.jpg)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![](04fig01.jpg)'
- en: 'In this chapter, I’ll guide you through the three main types of operations
    in a feature pipeline: extraction, transformation, and selection. Not all systems
    do all the types of operations shown in this chapter, but all feature engineering
    techniques can be thought of as falling into one of these three buckets. I’ll
    use type signatures to assign techniques to groups and give our exploration some
    structure, as shown in [table 4.1](#ch04table01).'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将指导你了解特征管道中的三种主要操作类型：提取、转换和选择。并非所有系统都执行本章中显示的所有类型的操作，但所有特征工程技术都可以被视为属于这三个类别之一。我将使用类型签名将技术分配到组中，并为我们的探索提供一些结构，如图4.1表所示。
- en: Table 4.1\. Phases of feature generation
  id: totrans-319
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.1\. 特征生成阶段
- en: '| Phase | Input | Output |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 | 输入 | 输出 |'
- en: '| --- | --- | --- |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Extract | RawData | Feature |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 提取 | 原始数据 | 特征 |'
- en: '| Transform | Feature | Feature |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 转换 | 特征 | 特征 |'
- en: '| Select | Set[Feature] | Set[Feature] |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 选择 | 特征集 | 特征集 |'
- en: Real-world feature pipelines can have very complex structures. You’ll use these
    groupings to help you understand how you can build a feature-generation pipeline
    in the best way possible. As we explore these three types of feature-processing
    operations, I’ll introduce common techniques and design patterns that will keep
    your machine learning system from becoming a tangled, unmaintainable mess. Finally,
    we’ll consider some general properties of data pipelines when discussing the next
    component of machine learning systems discussed in [chapter 5](kindle_split_016.html#ch05),
    the model-learning pipeline.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的特征管道可能具有非常复杂的结构。您将使用这些分组来帮助您理解如何以最佳方式构建特征生成管道。当我们探索这三种特征处理操作类型时，我将介绍一些常见的技巧和设计模式，以防止您的机器学习系统变得混乱、难以维护。最后，在讨论第5章[第5章](kindle_split_016.html#ch05)中机器学习系统的下一个组件——模型学习管道时，我们将考虑数据管道的一些一般特性。
- en: '|  |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Type signatures**'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型签名**'
- en: 'You may not be familiar with the use of *types* to guide how you think about
    and implement programs. This technique is common in statically typed languages
    like Scala and Java. In Scala, functions are defined in terms of the inputs they
    take, the outputs they return, and the types of both. This is called a *type signature*.
    In this book, I mostly use a fairly simple form of signature notation that looks
    like this: `Grass => Milk`. You can read this as, “A function from an input of
    type Grass to an output of type Milk.” This would be the type signature of some
    function that behaves much like a cow.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能不熟悉使用*类型*来指导您思考程序和实现程序的方法。这种技术在Scala和Java等静态类型语言中很常见。在Scala中，函数是通过它们接受的输入、返回的输出以及两者的类型来定义的。这被称为*类型签名*。在这本书中，我主要使用一种相当简单的签名符号，看起来像这样：`Grass
    => Milk`。您可以将其读作，“一个从类型为Grass的输入到类型为Milk的输出的函数。”这将是某些行为类似于牛的函数的类型签名。
- en: '|  |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '![](pidgn.jpg)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![pidgn.jpg]'
- en: To cover this enormous scope of functionality, we need to rise above it all
    to gain some perspective on what features are all about. To that end, we’ll join
    the team of Pidg’n, a microblogging social network for tree-dwelling animals,
    not too different from Twitter.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 为了涵盖这个庞大的功能范围，我们需要超越它，以获得对特征本质的一些洞察。为此，我们将加入Pidg’n团队，这是一个为树栖动物设计的微型博客社交网络，与Twitter没有太大区别。
- en: We’ll look at how we can take the chaos of a short-form, text-based social network
    and build meaningful representations of that activity. Much like the forest itself,
    the world of features is diverse and rich, full of hidden complexity. We can,
    however, begin to peer through the leaves and capture insights about the lives
    of tree-dwelling animals using the power of reactive machine learning.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨如何从短格式、基于文本的社交网络的混乱中提取有意义的活动表示。就像森林本身一样，特征的世界是多样且丰富的，充满了隐藏的复杂性。然而，我们可以开始透过树叶窥视，利用反应式机器学习的力量捕捉关于树栖动物生活的洞察。
- en: 4.1\. Spark ML
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1. Spark ML
- en: Before we get started building features, I want to introduce you to more Spark
    functionality. The `spark.ml` package, sometimes called Spark ML, defines some
    high-level APIs that can be used to create machine learning pipelines. This functionality
    can reduce the amount of machine learning–specific code that you need to implement
    yourself, but using it does involve a change in how you structure your data.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始构建特征之前，我想向您介绍更多的Spark功能。`spark.ml`包，有时称为Spark ML，定义了一些高级API，可用于创建机器学习管道。此功能可以减少您需要自行实现的机器学习特定代码的数量，但使用它确实涉及您数据结构的变化。
- en: The Spark ML API uses mostly the same nomenclature for feature extraction, transformation,
    and selection that I use in this chapter, though there are subtle differences.
    If and when you read the Spark ML documentation, you may see something called
    a *transformation* operation, which I call an *extraction* operation. These are
    generally minor, unimportant differences that you can ignore. Different technologies
    name and structure this functionality differently, and you’ll see all sorts of
    different naming conventions in the machine learning literature. The type signature–based
    framework for dividing feature-generation functionality that I use in this chapter
    is just a tool to help you implement and organize your code. Once you’ve mastered
    the feature-generation concepts in this chapter, you’ll be better equipped to
    see through differences in nomenclature to the similarities in functionality.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML API 在特征提取、转换和选择方面主要使用与我本章中使用的相同的命名约定，尽管存在细微的差异。如果你阅读 Spark ML 文档，可能会看到称为
    *转换* 操作的内容，而我称之为 *提取* 操作。这些通常是微不足道的、不重要的差异，你可以忽略它们。不同的技术对这一功能的命名和结构不同，你会在机器学习文献中看到各种不同的命名约定。我在本章中使用的基于类型签名的框架来划分特征生成功能，只是一个帮助你实现和组织代码的工具。一旦你掌握了本章中的特征生成概念，你将更好地能够透过命名差异看到功能上的相似性。
- en: Much of the machine learning functionality in Spark is designed to be used with
    DataFrames, instead of the RDDs that you’ve seen up until this point. DataFrames
    are simply a higher-level API on top of RDDs that give you a richer set of operations.
    You can think of DataFrames as something like tables in relational databases.
    They have different columns, which you can define and then query. Much of the
    recent progress in performance and functionality within Spark has been focused
    on DataFrames, so to get access to the full power of things like MLlib’s machine
    learning capabilities, you’ll need to use DataFrames for some operations. The
    good news is that they’re very similar to the RDDs you’ve been working with and
    tabular data structures you may have used in other languages, such as pandas DataFrames
    in Python or R’s data frames.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 中大部分机器学习功能都是设计用来与 DataFrames 一起使用，而不是你迄今为止看到的 RDDs。DataFrames 简单来说是在 RDDs
    之上的一个高级 API，它为你提供了一组更丰富的操作。你可以将 DataFrames 想象成关系数据库中的表格。它们有不同的列，你可以定义并查询这些列。Spark
    在性能和功能方面的最近进展主要集中在 DataFrames 上，因此要完全访问 MLlib 的机器学习功能，你将需要使用 DataFrames 进行某些操作。好消息是，它们与你在其他语言中可能使用过的
    RDDs 和表格数据结构非常相似，例如 Python 中的 pandas DataFrames 或 R 的数据框。
- en: 4.2\. Extracting features
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2. 提取特征
- en: Now that I’ve introduced some of the tools, let’s begin to solve the problem.
    We’ll start our exploration of the feature engineering process at the very beginning,
    with raw data. In this chapter, you’ll take on the role of Lemmy, an engineer
    on the Pidg’n data team.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经介绍了一些工具，让我们开始解决问题。我们将从最开始的原始数据开始探索特征工程过程。在本章中，你将扮演 Lemmy 的角色，他是 Pidg’n
    数据团队的一名工程师。
- en: '![](0071fig01.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![图片](0071fig01.jpg)'
- en: 'Your team knows it wants to build all sorts of predictive models about user
    activity. You’re just getting started, though, and all you have are the basics
    of application data: squawks (text posts of 140 characters or less), user profiles,
    and the follower relationships. This is a rich dataset, for sure, but you’ve never
    put it to much analytical use. To start with, you’ve decided to focus on the problem
    of predicting which new users will become *Super Squawkers*, users with more than
    a million followers.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 你的团队知道它想要构建关于用户活动的各种预测模型。尽管如此，你才刚刚开始，你只有应用数据的基础：squawks（140个字符或更少的文本帖子）、用户资料和关注者关系。这确实是一个丰富的数据集，但你从未对其进行过太多的分析性使用。首先，你决定专注于预测哪些新用户将成为
    *超级 Squawkers*，即拥有超过一百万关注者的用户。
- en: 'To start this project, you’ll extract some features to use in the rest of your
    machine learning system. I define the process of feature extraction as taking
    in raw data of some sort and returning a feature. Using Scala type signatures,
    feature extraction can be represented like this: `RawData => Feature`. That type
    signature can be read as, “A function that takes raw data and returns a feature.”
    If you define a function that satisfies that type signature, it might look something
    like the stub in the following listing.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始这个项目，你需要提取一些特征来用于你机器学习系统的其余部分。我将特征提取的过程定义为接收某种原始数据并返回一个特征。使用 Scala 类型签名，特征提取可以表示为：`RawData
    => Feature`。这个类型签名可以读作，“一个接收原始数据并返回特征的函数。”如果你定义了一个满足该类型签名的函数，它可能看起来像以下列表中的存根。
- en: Listing 4.1\. Extracting features
  id: totrans-342
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.1\. 提取特征
- en: '[PRE15]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Put differently, any output produced from raw data is a potential feature, regardless
    of whether it ever gets used to learn a model.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，从原始数据产生的任何输出都是潜在的特征，无论它是否被用来学习模型。
- en: The Pidg’n data team has been collecting data since day one of the app as part
    of keeping the network running. You have the complete, unaltered record of all
    the actions ever taken by Pidg’n users, much like the data model discussed in
    [chapter 3](kindle_split_014.html#ch03). Your team has built a few aggregates
    of that data for basic analytical purposes. Now you want to take that system to
    the next level by generating semantically meaningful derived representations of
    that raw data—features. Once you have features of any kind, you can begin learning
    models to predict user behavior. In particular, you’re interested in seeing if
    you can understand what makes particular squawks and squawkers more popular than
    others. If a squawker has the potential to become very popular, you want to provide
    them with a more streamlined experience, free of advertisements, to encourage
    them to squawk more.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: Pidg’n 数据团队自应用程序的第一天起就开始收集数据，作为保持网络运行的一部分。你拥有 Pidg’n 用户所采取的所有行动的完整、未更改的记录，就像在第
    3 章中讨论的数据模型一样。你的团队已经为基本分析目的构建了一些数据的聚合。现在你希望通过生成原始数据的语义上有意义的派生表示——特征——将这个系统提升到下一个水平。一旦你有了任何类型的特征，你就可以开始学习模型来预测用户行为。特别是，你感兴趣的是了解是什么使得某些
    squawks 和 squawkers 比其他更受欢迎。如果一个 squawker 有可能变得非常受欢迎，你希望为他们提供一个更流畅的体验，无广告，以鼓励他们更多地
    squawk。
- en: Let’s begin by extracting features from the raw data of the text of squawks.
    You can start by defining a simple case class and extracting a single feature
    for a few squawks. [Listing 4.2](#ch04ex02) shows how to extract a feature consisting
    of the words in the text of a given squawk. This implementation will use Spark’s
    `Tokenizer` to break sentences into words. Tokenization is just one of several
    common text-processing utilities that come built into Spark that make writing
    code like this fast and easy. For advanced use cases, you may want to use a more
    sophisticated text-parsing library, but having common utilities easily available
    can be very helpful.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从提取 squawks 文本的原始数据特征开始。你可以通过定义一个简单的案例类并为几个 squawks 提取单个特征来开始。[列表 4.2](#ch04ex02)
    展示了如何提取由给定 squawk 文本中的单词组成的特征。这个实现将使用 Spark 的 `Tokenizer` 将句子拆分成单词。分词只是 Spark
    内置的几种常见文本处理工具之一，它使得编写这样的代码变得快速且简单。对于高级用例，你可能想使用更复杂的文本解析库，但拥有易于访问的常用工具可能非常有帮助。
- en: Listing 4.2\. Extracting word features from squawks
  id: totrans-347
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.2\. 从 squawks 中提取单词特征
- en: '[PRE16]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '***1* Case class to hold a basic data model of a squawk**'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 案例类以保存 squawk 的基本数据模型**'
- en: '***2* Creates a DataFrame from a sequence**'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 从序列创建 DataFrame**'
- en: '***3* Instantiates example instances of squawks**'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 实例化 squawks 的示例实例**'
- en: '***4* Names columns to place values in a DataFrame**'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 为放置值的 DataFrame 命名列**'
- en: '***5* Sets up a Tokenizer to split the text of squawks into words and put them
    in an output column**'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 设置分词器以将 squawks 的文本拆分成单词并将它们放入输出列**'
- en: '***6* Executes the Tokenizer and populates the words column in a DataFrame**'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 执行分词器并填充 DataFrame 中的单词列**'
- en: '***7* Executes the Tokenizer and populates the words column in a DataFrame**'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 执行分词器并填充 DataFrame 中的单词列**'
- en: The operations in [listing 4.2](#ch04ex02) give you a `DataFrame` that contains
    a column called `words`, which has all the words in the text of the squawk. You
    could call the values in the `words` column a *feature*. These values could be
    used to learn a model. But let’s make the semantics of the pipeline clearer using
    the Scala type system.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 4.2](#ch04ex02)中的操作为您提供了一个包含名为`words`的列的`DataFrame`，该列包含叫声文本中的所有单词。您可以将`words`列中的值称为*特征*。这些值可以用来学习模型。但让我们使用Scala类型系统来使管道的语义更清晰。'
- en: Using the code in [listing 4.3](#ch04ex03), you can define what a feature is
    and what specific sort of feature you’ve produced. Then, you can take the `words`
    column from that `DataFrame` and use it to instantiate instances of those feature
    classes. It’s the same words that the `Tokenizer` produced for you, but now you
    have richer representations that you can use to help build up a feature-generation
    pipeline.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[列表 4.3](#ch04ex03)中的代码，您可以定义什么是特征以及您产生了哪种特定类型的特征。然后，您可以从那个`DataFrame`的`words`列中提取它，并使用它来实例化这些特征类的实例。这些就是`Tokenizer`为您生成的相同单词，但现在您有了更丰富的表示，您可以使用它来帮助构建特征生成管道。
- en: Listing 4.3\. Extracting word features from squawks
  id: totrans-358
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.3\. 从叫声中提取单词特征
- en: '[PRE17]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '***1* Defines a base trait for all types of features**'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 定义所有特征类型的基特质**'
- en: '***2* Requires feature types to have names**'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 要求特征类型必须有名称**'
- en: '***3* Type parameter to hold the type of values generated by feature**'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 类型参数用于存储由特征生成的值的类型**'
- en: '***4* Defines a base trait for all features as an extension of feature types**'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 定义所有特征的基特质作为特征类型的扩展**'
- en: '***5* Requires that features have values of the type specified in the feature
    type**'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 要求特征具有在特征类型中指定的类型的值**'
- en: '***6* Defines a case class for features consisting of word sequences**'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 定义由单词序列组成的特征的case类**'
- en: '***7* Specifies that the type of features being generated is a sequence of
    strings (words)**'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 指定生成的特征类型是一个字符串（单词）序列**'
- en: '***8* Selects a words column from the DataFrame**'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 从DataFrame中选择words列**'
- en: '***9* Maps over rows and applies a function to each**'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 对行进行映射并应用函数**'
- en: '***10* Creates an instance of WordSequenceFeature named words**'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***10* 创建名为words的WordSequenceFeature实例**'
- en: '***11* Gets extracted words out of a row**'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***11* 从行中提取单词**'
- en: '***12* Prints features for inspection**'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***12* 打印用于检查的特征**'
- en: With this small bit of extra code, you can define your features in a way that’s
    more explicit and less tied to the specifics of the raw data in the original `DataFrame`.
    The resulting value is an RDD of `WordSequenceFeature`. You’ll see later how you
    can continue to use this `Feature` trait with specific case classes defining the
    different types of features in your pipeline.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这段额外的代码，您可以以更明确和与原始`DataFrame`中的原始数据具体细节更少的方式定义您的特征。结果值是一个`WordSequenceFeature`的RDD。您将在后面看到如何继续使用这个`Feature`特质，以及使用特定case类定义管道中不同类型的特征。
- en: '![](immutable-facts.jpg)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![](immutable-facts.jpg)'
- en: Also note that, when operating over the `DataFrame`, you can use a pure, anonymous,
    higher-order function to create instances of your features. The concepts of purity,
    anonymous functions, and higher-order functions may have sounded quite abstract
    when I introduced them in [chapter 1](kindle_split_011.html#ch01). But now that
    you’ve seen them put to use in several places, I hope it’s clear that they can
    be very simple to write. Now that you’ve gotten some Scala and Spark programming
    under your belt, I hope you’re finding it straightforward to think of data transformations
    like feature extraction in terms of pure functions with no side effects.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，当在`DataFrame`上操作时，您可以使用一个纯的、匿名的、高阶函数来创建您特征的实例。当我[在第1章](kindle_split_011.html#ch01)介绍这些概念时，纯度、匿名函数和高阶函数的概念可能听起来相当抽象。但现在您已经看到它们在几个地方被使用，我希望您已经清楚它们可以非常简单易写。现在您已经掌握了一些Scala和Spark编程，我希望您发现用纯函数和没有副作用的方式来思考数据转换，如特征提取，是直截了当的。
- en: You and the rest of the Pidg’n data team could now use these features in the
    next phase of the machine learning pipeline—model learning—but they probably wouldn’t
    be good enough to learn a model of Super Squawkers. These initial word features
    are just the beginning. You can encode far more of your understanding of what
    makes a squawker super into the features themselves.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您和Pidg’n数据团队的其他成员可以使用这些特征在机器学习管道的下一阶段——模型学习——中，但它们可能不足以学习超级叫声者的模型。这些初始单词特征只是开始。您可以将更多关于什么使叫声者超级的理解编码到特征本身中。
- en: To be clear, there are sophisticated model-learning algorithms, such as neural
    networks, that require very little feature engineering on the data that they consume.
    You *could* use the values you’ve just produced as features in a model-learning
    process. But many machine learning systems will require you to do far more with
    your features before using them in model learning if you want acceptable predictive
    performance. Different model-learning algorithms have different strengths and
    weaknesses, as we’ll explore in [chapter 5](kindle_split_016.html#ch05), but all
    of them will benefit from having base features transformed in ways that make the
    process of model learning simpler. We need to move on to see how to make features
    out of other features.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，有一些复杂的模型学习算法，如神经网络，对它们所消耗的数据进行非常少的特征工程。您 *可以* 使用您刚刚生成的值作为模型学习过程中的特征。但许多机器学习系统在您想要可接受的预测性能之前，将需要您对特征进行更多的处理。不同的模型学习算法有不同的优势和劣势，我们将在[第5章](kindle_split_016.html#ch05)中探讨，但所有这些算法都将从将基本特征以简化模型学习过程的方式进行转换中受益。我们需要继续前进，看看如何将特征转换为其他特征。
- en: 4.3\. Transforming features
  id: totrans-377
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 转换特征
- en: 'Now that you’ve extracted some basic features, let’s figure out how to make
    them useful. This process of taking a feature and producing a new feature from
    it is called *feature transformation*. In this section, I’ll introduce you to
    some common transform functions and discuss how they can be structured. Then I’ll
    show you a very important class of feature transformations: transforming features
    into concept labels.'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经提取了一些基本特征，让我们来看看如何使它们变得有用。这个过程是从一个特征中提取并生成一个新特征，称为 *特征转换*。在本节中，我将向您介绍一些常见的转换函数，并讨论它们如何被构建。然后，我将向您展示一个非常重要的特征转换类别：将特征转换为概念标签。
- en: What is feature transformation? In the form of a type signature, feature transformation
    can be expressed as `Feature => Feature`, a function that takes a feature and
    returns a feature. A stub implementation of a transformation function (sometimes
    called a *transform*) is shown in the next listing.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是特征转换？以类型签名形式，特征转换可以表示为 `Feature => Feature`，这是一个函数，它接受一个特征并返回一个特征。下面是一个转换函数（有时称为
    *transform*）的示例实现。
- en: Listing 4.4\. Transforming features
  id: totrans-380
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.4\. 转换特征
- en: '[PRE18]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the case of the Pidg’n data team, you’ve decided to build on your previous
    feature-engineering work by creating a feature consisting of the frequencies of
    given words in a squawk. This quantity is sometimes called a *term frequency*.
    Spark has built-in functionality that makes calculating this value easy.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 在Pidg’n数据团队的情况下，您决定通过创建一个由哨声中的给定单词频率组成的特征来构建在您之前特征工程工作之上的内容。这个数量有时被称为 *词频*。Spark内置了计算这个值的功能。
- en: Listing 4.5\. Transforming words to term frequencies
  id: totrans-383
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.5\. 将单词转换为词频
- en: '[PRE19]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '***1* Instantiates an instance of a class to calculate term frequencies**'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 实例化一个类来计算词频**'
- en: '***2* Defines an input column to read from when consuming DataFrames**'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 定义在消费DataFrame时读取的输入列**'
- en: '***3* Defines an output to put term frequencies in**'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 定义将词频放入的输出**'
- en: '***4* Executes the transformation**'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 执行转换**'
- en: '***5* Prints term frequencies for inspection**'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 打印词频以供检查**'
- en: It’s worth noting that the `hashingTF` implementation of term frequencies was
    implemented to consume the `DataFrame` you previously produced, not the features
    you designed later. Spark ML’s concept of a pipeline is focused on connecting
    operations on `DataFrame`s, so it can’t consume the features you produced before
    without more conversion code.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，词频的 `hashingTF` 实现是为了消耗您之前生成的 `DataFrame`，而不是您后来设计的特征。Spark ML的管道概念专注于连接对
    `DataFrame` 的操作，因此它不能在没有更多转换代码的情况下消耗您之前生成的特征。
- en: '![](infinite-data.jpg)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
  zh: '![](infinite-data.jpg)'
- en: '|  |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Feature hashing**'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征哈希**'
- en: The use of the term *hashing* in the Spark library refers to the technique of
    *feature hashing*. Although it’s not always used in feature-generation pipelines,
    feature hashing can be a critically important technique for building large numbers
    of features. In text-based features like term frequencies, there’s no way of knowing
    a priori what all the possible features could be. Squawkers can write anything
    they want in a squawk on Pidg’n. Even an English-language dictionary wouldn’t
    contain all the slang terms squawkers might use. Free-text input means that the
    universe of possible terms is effectively infinite.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark库中使用术语*哈希*指的是*特征哈希*技术。尽管它并不总是在特征生成管道中使用，但特征哈希对于构建大量特征可能是一个至关重要的技术。在基于文本的特征，如词频中，事先无法知道所有可能的特征。在Pidg’n的尖叫中，尖叫者可以写任何他们想写的内容。即使是一部英语词典也不会包含尖叫者可能使用的所有俚语。自由文本输入意味着可能的术语宇宙实际上是无限的。
- en: One solution is to define a hash range of the size of the total number of distinct
    features you want to use in your model. Then you can apply a deterministic hashing
    function to each input to produce a distinct value within the hash range, giving
    you a unique identifier for each feature. For example, suppose `hash("trees")`
    returns `65381`. That value will be passed to the model-learning function as the
    identifier of the feature. This might not seem much more useful than just using
    `"trees"` as the identifier, but it is. When I discuss prediction services in
    [chapter 7](kindle_split_018.html#ch07), I’ll talk about why you’ll want to be
    able to identify features that the system has possibly never seen before.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解决方案是定义一个哈希范围，其大小为你想在模型中使用的不同特征总数的哈希范围。然后你可以对每个输入应用一个确定的哈希函数，在哈希范围内产生一个独特的值，为你每个特征提供一个唯一标识符。例如，假设`hash("trees")`返回`65381`。这个值将被传递给模型学习函数作为特征的标识符。这可能看起来并不比仅仅使用`"trees"`作为标识符更有用，但实际上是有用的。当我讨论[第7章](kindle_split_018.html#ch07)中的预测服务时，我会谈到为什么你想要能够识别系统可能从未见过的特征。
- en: '|  |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Let’s take a look at how Spark ML’s `DataFrame`-focused API is intended to be
    used in connecting operations like this. You won’t be able to take full advantage
    of Spark ML until [chapter 5](kindle_split_016.html#ch05), where you’ll start
    learning models, but it’s still useful for feature generation. Some of the preceding
    code can be reimplemented using a `Pipeline` from Spark ML. That will allow you
    to set the tokenizer and the term frequency operations as stages within a pipeline.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看Spark ML的`DataFrame`关注API是如何打算用于连接此类操作的。你将无法在[第5章](kindle_split_016.html#ch05)中充分利用Spark
    ML，在那里你将开始学习模型，但它在特征生成方面仍然很有用。一些前面的代码可以使用Spark ML的`Pipeline`重新实现。这将允许你将分词器和词频操作作为管道中的阶段来设置。
- en: Listing 4.6\. Using Spark ML pipelines
  id: totrans-398
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.6\. 使用Spark ML管道
- en: '[PRE20]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '***1* Instantiates a new pipeline**'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 实例化一个新的管道**'
- en: '***2* Sets the two stages of this pipeline**'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 设置此管道的两个阶段**'
- en: '***3* Executes the pipeline**'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 执行管道**'
- en: '***4* Prints the type of the result of the pipeline, a PipelineModel**'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 打印管道结果的类型，一个PipelineModel**'
- en: This `Pipeline` doesn’t result in a set of features, or even a `DataFrame`.
    Instead, it returns a `PipelineModel`, which in this case won’t be able to do
    anything useful, because you haven’t learned a model yet. We’ll revisit this code
    in [chapter 5](kindle_split_016.html#ch05), where we can go all the way from feature
    generation through model learning. The main thing to note about this code at this
    point is that you can encode a pipeline as a clear abstraction within your application.
    A large fraction of machine learning work involves working with pipeline-like
    operations. With the Spark ML approach to pipelines, you can be very explicit
    about how your pipeline is composed by setting the stages of the pipeline in order.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`Pipeline`不会产生一组特征，甚至不是一个`DataFrame`。相反，它返回一个`PipelineModel`，在这种情况下，它将无法执行任何有用的操作，因为你还没有学习到一个模型。我们将在[第5章](kindle_split_016.html#ch05)中重新审视这段代码，在那里我们可以从特征生成一直学习到模型学习。目前需要注意的主要是，你可以在应用程序中将管道编码为一个清晰的抽象。机器学习工作中很大一部分涉及处理类似管道的操作。使用Spark
    ML的管道方法，你可以通过按顺序设置管道的阶段来非常明确地指定你的管道是如何组成的。
- en: 4.3.1\. Common feature transforms
  id: totrans-405
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1\. 常见特征转换
- en: Sometimes you don’t have library implementations of the feature transform that
    you need. A given feature transform might have semantics that are specific to
    your application, so you’ll often need to implement feature transforms yourself.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候你不会有你需要的特征转换的库实现。给定的特征转换可能具有特定于你应用的语义，所以你通常需要自己实现特征转换。
- en: 'Consider how you could build a feature to indicate that a given Pidg’n user
    was a Super Squawker (user with more than a million followers). The feature-extraction
    process will give you the raw data about the number of followers a given squawker
    has. If you used the number of followers as a feature, that would be called a
    *numerical* feature. That number would be an accurate snapshot of the data from
    the follower graph, but it wouldn’t necessarily be easy for all model-learning
    algorithms to use. Because your intention is to express the idea of a Super Squawker,
    you could use a far simpler representation: a Boolean value representing whether
    or not the squawker has more than a million followers.'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑如何构建一个特征来指示一个特定的Pidg’n用户是超级squawker（拥有超过一百万追随者的用户）。特征提取过程将给你关于给定squawker有多少追随者的原始数据。如果你使用追随者数量作为特征，那么这将被称为*数值*特征。这个数字将是追随者图数据的准确快照，但并不一定容易为所有模型学习算法使用。因为你的意图是表达超级squawker的概念，你可以使用一个更简单的表示：一个布尔值，表示squawker是否拥有超过一百万的追随者。
- en: The squirrel, a rather ordinary user, has very few followers. But the sloth
    is an terrific Super Squawker. To produce meaningful features about the differences
    between these two squawkers, you’ll follow the same process of going from raw
    data, to numeric features, and then to Boolean features. This series of data transformations
    is shown for the two users in [figure 4.2](#ch04fig02).
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 松鼠，一个相当普通的用户，追随者很少。但树懒是一个出色的超级squawker。为了产生关于这两个squawker之间差异的有意义特征，你需要遵循从原始数据到数值特征，再到布尔特征的相同过程。这一系列数据转换在[图4.2](#ch04fig02)中展示。
- en: Figure 4.2\. Feature transformations
  id: totrans-409
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.2\. 特征转换
- en: '![](04fig02_alt.jpg)'
  id: totrans-410
  prefs: []
  type: TYPE_IMG
  zh: '![](04fig02_alt.jpg)'
- en: The following listing shows how to implement this approach to binarization to
    produce a Super Squawker feature.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表展示了如何实现这种二值化方法以生成超级squawker特征。
- en: Listing 4.7\. Binarizing a numerical feature
  id: totrans-412
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.7\. 对数值特征进行二值化
- en: '[PRE21]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '***1* Case class representing a numerical feature where the value is an integer**'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 表示数值特征的案例类，其中值是整数**'
- en: '***2* Specifies that these are integer features**'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 指定这些是整数特征**'
- en: '***3* Case class representing a Boolean feature**'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 表示布尔特征的案例类**'
- en: '***4* Specifies that these are Boolean features**'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 指定这些是布尔特征**'
- en: '***5* Function that takes a numeric integer feature and threshold and returns
    a Boolean feature**'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 函数接受一个数值整数特征和阈值，并返回一个布尔特征**'
- en: '***6* Adds the name of the transform function to the resulting feature name**'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 将转换函数的名称添加到生成的特征名称中**'
- en: '***7* Constant defining the cutoff for a squawker to be super**'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 定义squawker成为超级squawker的截止值的常数**'
- en: '***8* Raw numbers of followers for the squirrel and the sloth**'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 松鼠和树懒的原始追随者数量**'
- en: '***9* Numeric integer feature representing the number of followers**'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 表示追随者数量的数值整数特征**'
- en: '***10* Boolean feature indicating the squirrel is not a Super Squawker**'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***10* 表示松鼠不是超级squawker的布尔特征**'
- en: '***11* Boolean feature indicating the sloth is a Super Squawker**'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***11* 表示树懒是超级squawker的布尔特征**'
- en: '![](pure-functions.jpg)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![](pure-functions.jpg)'
- en: The `binarize` function is a good example of a reusable transform function.
    It also ensures the resulting feature is somewhat self-describing by appending
    the name of the transform function to the resulting feature. Ensuring that we
    can identify the operations that were applied to produce a feature is an idea
    we’ll revisit in later chapters. Finally, note that the transformation function
    `binarize` is a pure function.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '`binarize`函数是一个很好的可重用转换函数的例子。它还通过将转换函数的名称附加到生成的特征上来确保生成的特征具有一定的自描述性。确保我们可以识别应用于生成特征的操作是我们将在后续章节中重新审视的想法。最后，请注意，转换函数`binarize`是一个纯函数。'
- en: Using only pure functions in feature transforms is an important part of establishing
    a coherent structure for feature-generation code. Separating feature extraction
    and feature transformation within a code base can be difficult, and the boundaries
    between the two can be hard to draw. Ideally, any I/O or side-effecting operations
    should be contained in the feature-extraction phase of the pipeline, with all
    transformations’ functionality being implemented as pure functions. As you’ll
    see later, pure transforms are simple to scale and easy to reuse across features
    and feature-extraction contexts (model learning and predicting).
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征转换中仅使用纯函数是建立特征生成代码一致结构的重要部分。在代码库中分离特征提取和特征转换可能很困难，两者之间的边界可能很难划分。理想情况下，任何I/O或副作用操作都应包含在管道的特征提取阶段，所有转换功能都应作为纯函数实现。正如你稍后将会看到的，纯转换易于扩展，并且易于在特征和特征提取环境中（模型学习和预测）重用。
- en: There’s a huge range of commonly used transformation functions. Similar to binarization,
    some approaches reduce continuous values to discrete labels. For example, a feature
    designed to express the time of day when a squawk was posted might not use the
    full timestamp. Instead, a more useful representation could be to transform all
    times into a limited set of labels, as shown in [table 4.2](#ch04table02).
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的转换函数范围非常广泛。与二值化类似，一些方法将连续值减少到离散标签。例如，一个旨在表达嘈杂声发布时间的特征可能不会使用完整的时间戳。相反，一个更有用的表示方法是将所有时间转换成有限标签集，如[表4.2](#ch04table02)所示。
- en: Table 4.2\. Transforming times into time labels
  id: totrans-429
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.2\. 将时间转换为时间标签
- en: '| Time | Label |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| 时间 | 标签 |'
- en: '| --- | --- |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 7:02 | Morning |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 7:02 | 早晨 |'
- en: '| 12:53 | Midday |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| 12:53 | 中午 |'
- en: '| 19:12 | Night |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 19:12 | 夜间 |'
- en: The implementation of a transform to do this is trivial and is naturally a pure
    function.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这种转换是微不足道的，并且自然是一个纯函数。
- en: There’s another variation on reducing continuous data to labels, called *binning*,
    in which the source feature is reduced to some arbitrary label defined by the
    range of values that it falls into. For example, you could take the number of
    squawks a given user has made and reduce it to one of three labels indicating
    how active the squawker is, as shown in [table 4.3](#ch04table03).
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 将连续数据减少到标签的一种另一种变体称为 *分箱（binning）*，其中源特征被减少到一些任意标签，这些标签由它所落入的值范围定义。例如，你可以取一个特定用户发出的嘈杂声的数量，并将其减少到三个标签之一，以指示嘈杂声的活跃程度，如[表4.3](#ch04table03)所示。
- en: Table 4.3\. Binning
  id: totrans-437
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.3\. 分箱
- en: '| Squawks | Label | Activity level |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| 嘈杂声 | 标签 | 活跃程度 |'
- en: '| --- | --- | --- |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 7 | 0_99 | Least active squawkers |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 0_99 | 最不活跃的嘈杂声发布者 |'
- en: '| 1,204 | 1000_99999 | Moderately active squawkers |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| 1,204 | 1000_99999 | 中度活跃的嘈杂声发布者 |'
- en: '| 2,344,910 | 1000000_UP | Most active squawkers |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 2,344,910 | 1000000_UP | 最活跃的嘈杂声发布者 |'
- en: 'Again, an implementation of such a transform would be trivial and naturally
    a pure function. Transforms *should* be easy to write and should correspond closely
    to their formulation in mathematical notation. When it comes to implementing transforms,
    you should always abide by the KISS principle: Keep It Simple, Sparrow. Reactive
    machine learning systems are hard enough to implement without implementing complicated
    transforms. Usually, an overly long transform implementation is a smell that someone
    has laid a rotten egg. In a few special cases, you may want to implement something
    like a transformer with more involved semantics. We’ll consider such circumstances
    later in this chapter and later in the book.'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这种转换的实现将是微不足道的，并且自然是一个纯函数。转换应该是容易编写的，并且应与数学符号中的公式紧密对应。在实现转换时，你应该始终遵守KISS原则：简单至上，Sparrow。在没有实现复杂的转换的情况下，实现反应式机器学习系统已经足够困难。通常，过长的转换实现是一个信号，表明有人放了一个臭鸡蛋。在少数特殊情况下，你可能想实现一个具有更复杂语义的转换器。我们将在本章和本书的后续部分考虑这种情况。
- en: 4.3.2\. Transforming concepts
  id: totrans-444
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2\. 转换概念
- en: 'Before we leave the topic of transformations, we need to consider one very
    common and critical class of feature transformations: the ones that produce concepts.
    As mentioned in [chapter 1](kindle_split_011.html#ch01), *concepts* are the things
    that a machine learning model is trying to predict. Although some machine learning
    algorithms can learn models of continuous concepts, such as the number of squawks
    a given user will write over the course of the next month, many machine learning
    systems are built to perform classification. In *classification* problems, the
    learning algorithm is trying to learn a discrete number of class labels, not continuous
    values. In such systems, the concept has to be produced from the raw data, during
    feature extraction, and then reduced to a class label via transformation. Concept
    class labels aren’t exactly the same thing as features, but often the difference
    is just a matter of how we use the piece of data. Typically, and ideally, the
    same code that might binarize a feature will also binarize a concept.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们离开转换主题之前，我们需要考虑一个非常常见且关键的特性转换类别：那些产生概念的转换。如[第 1 章](kindle_split_011.html#ch01)中所述，*概念*是机器学习模型试图预测的事物。尽管一些机器学习算法可以学习连续概念的模型，例如，在接下来的一个月内，特定用户将写多少次尖叫，但许多机器学习系统是构建来执行分类的。在*分类*问题中，学习算法试图学习一组离散的类别标签，而不是连续值。在这样的系统中，概念必须从原始数据中产生，在特征提取过程中，然后通过转换减少到类别标签。概念类别标签并不完全等同于特征，但通常差异只是我们如何使用数据片段的问题。通常，理想情况下，可能将特征二值化的相同代码也将概念二值化。
- en: Building on the code in [listing 4.7](#ch04ex07), in the next listing, take
    the Boolean feature about Super Squawkers and produce a Boolean concept label
    that classifies squawkers into super or not.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 在[列表 4.7](#ch04ex07)中的代码基础上，在下一个列表中，提取关于超级尖叫者的布尔特征，并生成一个布尔概念标签，将尖叫者分类为超级或非超级。
- en: Listing 4.8\. Creating concept labels from features
  id: totrans-447
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.8\. 从特征创建概念标签
- en: '[PRE22]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '***1* Defines labels as subtypes of features**'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 将标签定义为特征的子类型**'
- en: '***2* Creates a case class for Boolean labels**'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 创建布尔标签的案例类**'
- en: '***3* Defines a simple conversion function from Boolean features to Boolean
    labels**'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 定义一个从布尔特征到布尔标签的简单转换函数**'
- en: '***4* Converts Super Squawker feature values into concept labels**'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 将超级尖叫者特征值转换为概念标签**'
- en: '***5* Prints label values for inspection**'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 打印标签值以供检查**'
- en: 'In this code, you’ve defined concept labels as a special subtype of features.
    That’s not how features and labels are generally discussed, but it can be a helpful
    convention for code reuse in machine learning systems. Whether you intend to do
    so or not, any given feature value could be used as a concept label if it represents
    the concept class to be learned. The `Label` trait in [listing 4.8](#ch04ex08)
    doesn’t change the underlying structure of the data in a feature, but it does
    allow you to annotate when you’re using a feature as a concept label. The rest
    of the code is quite simple, and you arrive at the same conclusion again: people
    just aren’t that interested in what squirrels have to say.'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，您已将概念标签定义为特征的特殊子类型。这并不是特征和标签通常讨论的方式，但在机器学习系统中进行代码重用时，这可能是一个有用的约定。无论您是否打算这样做，任何给定的特征值都可以用作概念标签，如果它代表要学习的概念类别。在[列表
    4.8](#ch04ex08)中的`Label`特性不会改变特征中的数据的基本结构，但它确实允许您在将特征用作概念标签时进行注释。其余的代码相当简单，您再次得出相同的结论：人们并不那么感兴趣，想知道松鼠有什么要说的。
- en: 4.4\. Selecting features
  id: totrans-455
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. 选择特征
- en: 'Again, you find yourself in the same situation: if you’ve done all the work
    so far, you might now be finished. You could use the features you’ve already produced
    to learn a model. But sometimes it’s worthwhile to perform additional processing
    on features before beginning to learn a model. In the previous two phases of the
    feature-generation process, you produced all the features you *might* want to
    use to learn a model, sometimes called a *feature set*. Now that you have that
    feature set, you could consider throwing some of those features in the trash.'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，您发现自己处于相同的情况：如果您到目前为止已经完成了所有工作，您现在可能已经完成了。您可以使用您已经生成的特征来学习模型。但有时在开始学习模型之前对特征进行额外的处理是值得的。在前两个特征生成阶段，您已经生成了您可能想要用于学习模型的全部特征，有时称为*特征集*。现在您有了这个特征集，您可以考虑将这些特征中的某些扔进垃圾桶。
- en: The process of choosing from a feature set which features to use is known as
    *feature selection*. In type-signature form, it can be expressed `Set[Feature]
    => Set[Feature]`, a function that takes a set of features and returns another
    set of features. The next listing shows a stub implementation of a feature selector.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 从特征集中选择要使用的特征的过程称为 *特征选择*。在类型签名形式中，它可以表示为 `Set[Feature] => Set[Feature]`，这是一个函数，它接受一组特征并返回另一组特征。下一个列表显示了特征选择器的占位符实现。
- en: Listing 4.9\. A feature selector
  id: totrans-458
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.9\. 特征选择器
- en: '[PRE23]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](infinite-data.jpg)'
  id: totrans-460
  prefs: []
  type: TYPE_IMG
  zh: '![无限数据](infinite-data.jpg)'
- en: Why would you ever want to discard features? Aren’t they useful and valuable?
    In theory, a robust machine learning algorithm could take as input feature vectors
    containing arbitrary numbers of features and learn a model of the given concept.
    In reality, providing a machine learning algorithm with too many features is just
    going to make it take longer to learn a model and potentially degrade that model’s
    performance. You can find yourself needing to choose among features quite easily.
    By varying the parameters used in the transformation process, you could create
    an infinite number of features with a very small amount of code.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 你为什么想要丢弃特征？它们不是有用且宝贵的吗？从理论上讲，一个健壮的机器学习算法可以接受包含任意数量特征的输入特征向量，并学习给定概念的模式。然而，在现实中，向机器学习算法提供过多的特征只会使它学习模型的时间更长，并可能降低该模型的表现。你可能会很容易地需要在特征之间进行选择。通过改变转换过程中使用的参数，你可以用很少的代码创建无限数量的特征。
- en: Using a modern distributed data-processing framework like Spark makes handling
    arbitrarily sized datasets easy. It’s definitely to your benefit to consider a
    huge range of features during the feature extraction and transformation phases
    of your pipeline. And once you’ve produced all the features in your feature set,
    you can use some of the facilities in Spark to cut that feature set down to just
    those features that your model-learning algorithm will use to learn the model.
    There are implementations of feature-selection functionality in other machine
    learning libraries; Spark’s MLlib is one of many options and certainly not the
    oldest one. For some cases, the feature-selection functionality provided by MLlib
    might not be sufficient, but the principles of feature selection are the same
    whether you use a library implementation or something more bespoke. If you end
    up writing your own version of feature selection, it will still be conceptually
    similar to MLlib’s implementations.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 使用现代分布式数据处理框架，如 Spark，可以轻松处理任意大小的数据集。在特征提取和转换阶段考虑大量特征肯定对你有益。一旦你生成了特征集中的所有特征，你可以使用
    Spark 中的一些功能将特征集缩减到模型学习算法将用于学习模型的那些特征。其他机器学习库中也有特征选择功能的实现；Spark 的 MLlib 是许多选项之一，当然不是最老的一个。在某些情况下，MLlib
    提供的特征选择功能可能不足以满足需求，但无论你使用库实现还是更定制的解决方案，特征选择的原理都是相同的。如果你最终编写了自己的特征选择版本，它仍然在概念上与
    MLlib 的实现相似。
- en: 'Using the Spark functionality will again require you to leave behind your feature-case
    classes and the guarantees of static typing to use the machine learning functionality
    implemented around the high-level DataFrame API. To begin, you’ll need to construct
    a `DataFrame` of training instances. These instances will consist of three parts:
    an arbitrary identifier, a feature vector, and a concept label. The following
    listing shows how to build up this collection of instances. Instead of using real
    features, you’ll use some synthetic data, which you can imagine being about various
    properties of Squawkers.'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Spark 功能将再次要求你放弃特征案例类和静态类型保证，以使用围绕高级 DataFrame API 实现的机器学习功能。首先，你需要构建一个包含训练实例的
    `DataFrame`。这些实例将包括三个部分：一个任意标识符、一个特征向量和概念标签。以下列表显示了如何构建这个实例集合。你将不会使用真实特征，而是使用一些合成数据，你可以想象这些数据是关于
    Squawkers 的各种属性。
- en: Listing 4.10\. A `DataFrame` of instances
  id: totrans-464
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.10\. 实例的 DataFrame
- en: '[PRE24]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '***1* Defines a collection of instances**'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 定义实例集合**'
- en: '***2* Hardcodes some synthetic feature and concept label data**'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 硬编码一些合成特征和概念标签数据**'
- en: '***3* Names for features and label columns**'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 特征和标签列的名称**'
- en: '***4* Creates a DataFrame from the instances collection**'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 从实例集合创建 DataFrame**'
- en: '***5* Sets the name of each column in the DataFrame**'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 设置 DataFrame 中每列的名称**'
- en: Once you have a `DataFrame` of instances, you can take advantage of the feature-selection
    functionality built into MLlib. You can apply a chi-squared statistical test to
    rank the impact of each feature on the concept label. This is sometimes called
    *feature importance*. After the features are ranked by this criterion, the less
    impactful features can be discarded prior to model learning. The next listing
    shows how you can select the two most important features from your feature vectors.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了实例的`DataFrame`，你就可以利用MLlib内置的特征选择功能。你可以应用卡方统计测试来对每个特征对概念标签的影响进行排序。这有时被称为*特征重要性*。在根据这一标准对特征进行排序后，可以丢弃影响较小的特征，然后再进行模型学习。下面的列表展示了如何从你的特征向量中选择两个最重要的特征。
- en: Listing 4.11\. Chi-squared-based feature selection
  id: totrans-472
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.11\. 基于卡方的特征选择
- en: '[PRE25]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '***1* Creates a new feature selector**'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建一个新的特征选择器**'
- en: '***2* Sets the number of features to retain to 2**'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 设置要保留的特征数量为2**'
- en: '***3* Sets the column where features are**'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 设置特征所在的列**'
- en: '***4* Sets the column where concept labels are**'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 设置概念标签所在的列**'
- en: '***5* Sets the column to place results, the selected features**'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 设置放置结果的列，即选定的特征**'
- en: '***6* Fits a chi-squared model to the data**'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 将卡方模型拟合到数据**'
- en: '***7* Selects the most important features and returns a new DataFrame**'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 选择最重要的特征并返回一个新的DataFrame**'
- en: '***8* Prints the resulting DataFrame for inspection**'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 打印结果DataFrame以供检查**'
- en: As you can see, having standard feature-selection functionality available at
    a library call makes feature selection pretty convenient. If you had to implement
    chi-squared-based feature selection yourself, you’d find that the implementation
    was a lot longer than the code you just wrote.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，在库调用中提供标准特征选择功能使得特征选择变得非常方便。如果你不得不自己实现基于卡方的特征选择，你会发现实现代码比刚才写的代码要长得多。
- en: 4.5\. Structuring feature code
  id: totrans-483
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5\. 结构化特征代码
- en: In this chapter, you’ve written example implementations of all the most common
    components of a feature-generation pipeline. As you’ve seen, some of these components
    are simple and easy to build, and you could probably see yourself building quite
    a few of them without any difficulty. If you’ve Kept It Simple, Sparrow, you shouldn’t
    be intimidated by the prospect of producing lots of feature extraction, transformation,
    and selection functionality in your system. Or should you?
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你已经编写了特征生成管道所有最常见组件的示例实现。正如你所见，其中一些组件很简单，很容易构建，你可能会发现自己在没有任何困难的情况下构建了很多。如果你保持了简单性，那么在系统中生产大量的特征提取、转换和选择功能不应该让你感到害怕。或者，你应该感到害怕吗？
- en: Within a machine learning system, feature-generation code can often wind up
    being the largest part of the codebase by some measures. A typical Scala implementation
    might have a class for each extraction and transformation operation, and that
    can quickly become unwieldy as the number of classes grows. To prevent feature-generation
    code from becoming a confusing grab bag of various arbitrary operations, you need
    to start putting more of your understanding of the semantics of feature generation
    into the structure of your implementation of feature-generation functionality.
    The next section introduces one such strategy for structuring your feature-generation
    code.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习系统中，特征生成代码在某些度量上可能会成为代码库中最大的一部分。一个典型的Scala实现可能为每个提取和转换操作有一个类，随着类数量的增加，这会很快变得难以管理。为了防止特征生成代码变成一个包含各种任意操作的混乱集合，你需要开始在实现特征生成功能的结构中更多地融入你对特征生成语义的理解。下一节介绍了一种结构化你的特征生成代码的策略。
- en: 4.5.1\. Feature generators
  id: totrans-486
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.1\. 特征生成器
- en: At the most basic level, you need to define an implementation of what is a unit
    of feature-generation functionality. Let’s call this a *feature generator*. A
    feature generator can encompass either extraction or both extraction and transformation
    operations. The implementation of the extraction and transformation operations
    may not be very different from what you’ve seen before, but these operations will
    all be encapsulated in an independently executable unit of code that produces
    a feature. Your feature generators will be things that can take raw data and produce
    features that you want to use to learn a model.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 在最基本层面上，你需要定义一个实现，即特征生成功能单元的实现。让我们称这个为*特征生成器*。特征生成器可以包括提取或提取和转换操作。提取和转换操作的实施可能与之前看到的没有太大区别，但这些操作都将封装在一个独立可执行的代码单元中，该单元生成一个特征。你的特征生成器将是能够接受原始数据并生成你想要用于学习模型的特征的东西。
- en: Let’s implement your feature generators using a trait. In Scala, *traits* are
    used to define behaviors in the form of a type. A typical trait will include the
    signatures and possibly implementations of methods that define the common behavior
    to the trait. Scala traits are very similar to interfaces in Java, C++, and C#
    but are much easier and more flexible to use than interfaces in any of those languages.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用特质（trait）来实现你的特征生成器。在Scala中，*特质*用于以类型的形式定义行为。一个典型的特质将包括方法的签名和可能实现，这些方法定义了特质共有的行为。Scala的特质与Java、C++和C#中的接口非常相似，但使用起来比这些语言的接口更容易、更灵活。
- en: For the purpose of this section, let’s say that your raw data, from the perspective
    of your feature-generation system, consists of squawks. Feature generation will
    be the process of going from squawks to features. The corresponding feature-generator
    trait can be defined.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本节的目的，让我们假设你的原始数据，从你的特征生成系统角度来看，由鸣叫组成。特征生成将是将鸣叫转换为特征的过程。相应的特征生成器特质可以定义为。
- en: Listing 4.12\. A feature-generator trait
  id: totrans-490
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.12。一个特征生成器特质
- en: '[PRE26]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `Generator` trait defines a feature generator to be an object that implements
    a method, `generate`, that takes a squawk and returns a feature. This is a concrete
    way of defining the behavior of feature generation. A given implementation of
    feature generation might need all sorts of other functionality, but this is the
    part that will be common across all implementations of feature generation. Let’s
    look at one implementation of this trait.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '`Generator`特质定义了一个特征生成器为一个实现`generate`方法的对象，该方法接受一个鸣叫并返回一个特征。这是定义特征生成行为的一种具体方式。特征生成的给定实现可能需要所有
    sorts 的其他功能，但这是所有特征生成实现中都会共有的部分。让我们看看这个特质的其中一个实现。'
- en: Your team is interested in understanding how squawk length affects squawk popularity.
    There’s an intuition that even 140 characters is too much to read for some squawkers,
    such as hummingbirds. They just get bored too quickly. Conversely, vultures have
    been known to stare at the same squawk for hours on end, so long posts are rarely
    a problem for them. For you to be able to build a recommendation model that will
    surface relevant content to these disparate audiences, you’ll need to encode some
    of the data around squawk length as a feature. This can easily be implemented
    using the `Generator` trait.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 你的团队对了解鸣叫长度如何影响鸣叫受欢迎程度很感兴趣。有一种直觉认为，即使是140个字符对于一些鸣叫者来说也太多，比如蜂鸟。它们很快就感到无聊。相反，秃鹫被知会长时间盯着同一个鸣叫，因此对于它们来说，长篇帖子很少是问题。为了能够构建一个推荐模型，该模型可以向这些不同的受众展示相关内容，你需要将关于鸣叫长度的某些数据编码为特征。这可以很容易地使用`Generator`特质来实现。
- en: 'As discussed before, the idea of length can be captured using the technique
    of binning to reduce your numeric data to categories. There’s not much difference
    between a 72-character squawk and a 73-character squawk; you’re just trying to
    capture the approximate size of a squawk. You’ll divide squawks into three categories
    based on length: short, moderate, and long. You’ll define your thresholds between
    the categories to be at the thirds of the total possible length. Implemented according
    to your `Generator` trait, you get something like the following listing.'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，可以使用分箱技术来捕捉长度的概念，将你的数值数据减少到类别。72个字符的鸣叫和73个字符的鸣叫之间没有太大区别；你只是在尝试捕捉鸣叫的大致大小。你将根据长度将鸣叫分为三类：短、中、长。你将在类别之间定义阈值，使其位于总可能长度的三分之一处。根据你的`Generator`特质实现，你将得到以下类似列表。
- en: Listing 4.13\. A categorical feature generator
  id: totrans-495
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.13\. 一个分类特征生成器
- en: '[PRE27]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '***1* Defines a generator as an object that extends the Generator trait**'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 定义一个生成器为一个扩展 Generator 特质的对象**'
- en: '***2* Constant thresholds to compare against**'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 用于比较的常量阈值**'
- en: '***3* Extracting: uses the length of the squawk to instantiate an IntFeature**'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 提取：使用叫声的长度来实例化一个 IntFeature**'
- en: '***4* Transforming: takes the IntFeature of length, returns the IntFeature
    of category**'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 转换：接收长度的 IntFeature，返回类别的 IntFeature**'
- en: '***5* Uses a pattern-matching structure to determine which category the squawk
    length falls into**'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 使用模式匹配结构来确定叫声长度所属的类别**'
- en: '***6* Returns Int for a category (for ease of use in model learning)**'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 返回一个类别 Int（为了在模型学习中易于使用）**'
- en: '***7* Returns a category of 3, a long squawk, in all other cases**'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 在所有其他情况下返回一个类别 3，一个长而尖锐的叫声**'
- en: '***8* Returns a category as a new IntFeature**'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 返回一个作为新 IntFeature 的类别**'
- en: '***9* Generating: extracts a feature from the squawk and then transforms it
    to a categorical IntFeature**'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 生成：从叫声中提取一个特征，然后将其转换为分类的 IntFeature**'
- en: '![](pure-functions.jpg)'
  id: totrans-506
  prefs: []
  type: TYPE_IMG
  zh: '![](pure-functions.jpg)'
- en: This generator is defined in terms of a singleton object. You don’t need to
    use instances of a class, because all the generation operations are themselves
    pure functions.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 这个生成器是以一个单例对象定义的。你不需要使用类的实例，因为所有的生成操作本身都是纯函数。
- en: Internal to your implementation of the feature generator, you still used a concept
    of extraction and transformation, even though you now only expose a `generate`
    method as the public API to this object. Though that may not always seem necessary,
    it can be helpful to define all extraction and transformation operations in a
    consistent manner using feature-based type signatures. This can make it easier
    to compose and reuse code.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的特征生成器实现内部，你仍然使用了提取和转换的概念，尽管你现在只公开了一个`generate`方法作为此对象的公共 API。尽管这可能并不总是必要的，但使用基于特征的类型签名以一致的方式定义所有提取和转换操作可能是有帮助的。这可以使代码的组合和重用更容易。
- en: Reuse of code is a huge issue in feature-generation functionality. In a given
    system, many feature generators will be performing operations very similar to
    each other.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 代码重用是特征生成功能中的一个重大问题。在给定的系统中，许多特征生成器将执行非常相似的操作。
- en: A given transform might be used dozens of times if it’s factored out and reusable.
    If you don’t think about such concerns up front, you may find that your team has
    reimplemented some transform, like averaging five different times in subtly different
    ways across your feature-generation codebase. That can lead to tricky bugs and
    bloated code.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将一个转换因子化并使其可重用，它可能被使用数十次。如果你一开始没有考虑这样的问题，你可能会发现你的团队在特征生成代码库中微妙地以不同的方式重复实现了某些转换，比如平均五次。这可能导致棘手的错误和臃肿的代码。
- en: 'You don’t want your feature-generation code to be messier than a tree full
    of marmosets! Let’s take a closer look at the structure of your generator functionality.
    The `transform` function in [listing 4.13](#ch04ex13) was doing something you
    might wind up doing a lot in your codebase: categorizing according to some threshold.
    Let’s look at it again.'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 你不希望你的特征生成代码比满树松鼠还要混乱！让我们更仔细地看看你的生成器功能结构。在[列表 4.13](#ch04ex13)中的`transform`函数正在做你可能在代码库中经常做的事情：根据某个阈值进行分类。让我们再看一遍。
- en: Listing 4.14\. Categorization using pattern matching
  id: totrans-512
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.14\. 使用模式匹配进行分类
- en: '[PRE28]'
  id: totrans-513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: You definitely shouldn’t be implementing a comparison against thresholds more
    than once, so let’s find a way to pull that code out and make it reusable. It’s
    also weird that you had to define the class label integers yourself. Ideally,
    you’d just have to worry about your thresholds and nothing else.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 你绝对不应该多次实现比较阈值，所以让我们找到一种方法来提取这段代码并使其可重用。而且，你不得不自己定义类标签整数也很奇怪。理想情况下，你只需担心你的阈值，而无需担心其他任何事情。
- en: Let’s pull out the common parts of this code for reuse and make it more general
    in the process. The code in the next listing shows one way of doing this. It’s
    a little dense, so we’ll walk through it in detail.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们提取这段代码的公共部分以供重用，并在过程中使其更通用。下一段列表中的代码展示了这样做的一种方法。它有点密集，所以我们将详细地解释它。
- en: Listing 4.15\. Generalized categorization
  id: totrans-516
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.15\. 广义分类
- en: '[PRE29]'
  id: totrans-517
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '***1* Singleton object to hold a pure function**'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 单例对象来保存一个纯函数**'
- en: '***2* Only takes a list of thresholds as input**'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 只接受一个阈值列表作为输入**'
- en: '***3* Returns an anonymous categorization function that takes Int as an argument**'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 返回一个匿名分类函数，它接受 Int 作为参数**'
- en: '***4* Ensures that a list of thresholds is sorted, because categorization relies
    on it**'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 确保阈值列表是有序的，因为分类依赖于它**'
- en: '***5* Zips up a list of thresholds and corresponding indices (used as category
    labels)**'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 将一系列阈值和相应的索引（用作类别标签）组合在一起**'
- en: '***6* Finds an entry that satisfies the case clause predicate**'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 找到一个满足情况子句谓词的条目**'
- en: '***7* Defines a passing case as being when a data point is less than the threshold**'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 定义通过的情况为数据点小于阈值**'
- en: '***8* Gets a matching value out of an option or returns a sentinel value of
    –1 when matching fails**'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 从选项中获取匹配的值，或者在匹配失败时返回一个哨兵值 –1**'
- en: '***9* Takes a second element out of a tuple, which is the category label (in
    integer form)**'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 从元组中取出第二个元素，即类别标签（以整数形式）**'
- en: This solution uses a few techniques that you may not have seen before. For one,
    this function’s return type is `(Int) => Int`, a function that takes an integer
    and returns an integer. In this case, the function returned will categorize a
    given integer according to the thresholds previously provided.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案使用了一些你可能之前没有见过的技术。首先，这个函数的返回类型是 `(Int) => Int`，这是一个接受一个整数并返回一个整数的函数。在这种情况下，返回的函数将根据之前提供的阈值对给定的整数进行分类。
- en: The thresholds and categories are also zipped together so they can be operated
    on as a pair of related values (in the form of a tuple). *Zipping*, or *convolution*
    as it’s sometimes called, is a powerful technique that’s commonly used in Scala
    and other languages in the functional programming tradition. The name *zip* comes
    from the similarity to the action of a zipper. In this case, you’re using a special
    sort of zip operation that conveniently provides you indices corresponding to
    the number the elements in the collection being zipped over. This approach to
    producing indices is far more elegant than C-style iteration using a mutable counter,
    which you may have seen in other languages, such as Java and C++.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值和类别也被组合在一起，以便它们可以作为一对相关值（以元组的形式）进行操作。*组合*，或者有时被称为*卷积*，是一种在 Scala 和其他函数式编程传统语言中常用的强大技术。*zip*
    这个名字来源于与拉链动作的相似性。在这种情况下，你使用一种特殊的 zip 操作，它方便地为你提供与正在 zip 的集合中的元素数量相对应的索引。这种生成索引的方法比在其他语言（如
    Java 和 C++）中看到的 C 风格迭代使用可变计数器的方法要优雅得多。
- en: After zipping over the values, you use another new function, `find`, with which
    you can define the element of a collection you’re looking for in terms of a *predicate*.
    Predicates are Boolean functions that are either true or false, depending on their
    values. They’re commonly used in mathematics, logic, and various forms of programming
    such as logic and functional programming. In this usage, the predicate gives you
    a clear syntax for defining what constitutes falling into a category bucket.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 在对值进行 zip 操作之后，你使用另一个新函数 `find`，你可以用 *谓词* 来定义你正在寻找的集合中的元素。谓词是布尔函数，根据它们的值可以是真或假。它们在数学、逻辑以及各种形式的编程（如逻辑和函数式编程）中常用。在这个用法中，谓词为你提供了定义构成落入类别桶的清晰语法。
- en: This code also deals with uncertainty in external usage in ways that you haven’t
    before. Specifically, it sorts the categories, because they might not be provided
    in a sorted list, but your algorithm relies on operating on them in order. Also,
    the `find` function returns an `Option` because the `find` operation may or may
    not find a matching value. In this case, you use the value `–1` to indicate an
    unusable category, but how a categorization failure should be handled depends
    a lot on how the functionality will be integrated in the client generator code.
    When you factor out common feature transforms to shared functions like this, you
    should take into account the possibilities of future broad usage of the transform.
    By implementing it with these extra guarantees, you reduce the chances that someone
    will use your categorization functionality in the future and not get the results
    they wanted.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码还以你之前没有见过的处理方式处理外部使用中的不确定性。具体来说，它对类别进行排序，因为它们可能不是按顺序提供的，但你的算法依赖于按顺序操作它们。此外，`find`
    函数返回一个 `Option`，因为 `find` 操作可能找到或不找到匹配的值。在这种情况下，你使用值 `–1` 来表示不可用的类别，但如何处理分类失败在很大程度上取决于客户端生成代码中的功能如何集成。当你将常见的特征转换提取到共享函数（如这个函数）中时，你应该考虑到转换未来广泛使用的可能性。通过实施这些额外的保证，你减少了将来有人使用你的分类功能却得不到他们想要的结果的可能性。
- en: The code in [listing 4.15](#ch04ex15) might be a bit harder to understand than
    the original implementation in [listings 4.13](#ch04ex13) and [4.14](#ch04ex14).
    Your refactored version does more work to give you a more general and robust version
    of categorization. You may not expect every implementer of a feature generator
    to go through this much work for a simple transform, but because you’ve factored
    out this functionality to shared, reusable code, they don’t have to. Any feature-generation
    functionality needing to categorize values according to a list of thresholds can
    now call this function. The transform from [listings 4.13](#ch04ex13) and [4.14](#ch04ex14)
    can now be replaced with the very simple version in [listing 4.16](#ch04ex16).
    You still have a relatively complex implementation of categorization in [listing
    4.15](#ch04ex15), but now, that complex implementation has been factored out to
    a separate component, which is more general and reusable. As you can see in the
    next listing, the callers of that functionality, like this transform function,
    can be quite simple.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 4.15](#ch04ex15) 中的代码可能比 [列表 4.13](#ch04ex13) 和 [4.14](#ch04ex14) 中的原始实现更难理解。您重构的版本做了更多工作，为您提供了一个更通用和健壮的分类版本。您可能不会期望每个特征生成器的实现者都会为这样一个简单的转换做这么多工作，但因为你已经将这个功能分解为共享的可重用代码，他们不必这样做。现在，任何需要根据一系列阈值对值进行分类的特征生成功能都可以调用这个函数。[列表
    4.13](#ch04ex13) 和 [4.14](#ch04ex14) 中的转换现在可以用 [列表 4.16](#ch04ex16) 中的非常简单的版本替换。您仍然有一个相对复杂的分类实现
    [列表 4.15](#ch04ex15)，但现在，这个复杂的实现已经被分解到一个单独的组件中，这个组件更通用和可重用。正如您在下一条列表中可以看到的，该功能的调用者，如这个转换函数，可以相当简单。'
- en: Listing 4.16\. Refactored categorization transform
  id: totrans-532
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.16\. 重构的分类转换
- en: '[PRE30]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '***1* Creates the categorization function and applies it to the value for categorization**'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建分类函数并将其应用于分类值**'
- en: Once you have dozens of categorical features, this sort of design strategy will
    make your life a lot easier. Categorization is now simple to plug in and easy
    to refactor should you decide to change how you want it implemented.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有数十个分类特征，这种设计策略将使您的生活变得更加容易。现在，分类简单到可以插入，如果您决定更改实现方式，也容易重构。
- en: 4.5.2\. Feature set composition
  id: totrans-536
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.2\. 特征集组成
- en: You’ve seen how you can choose among the features you produced, but there’s
    actually a zeroth step that’s necessary in some machine learning systems. Before
    you even begin the process of feature generation, you may want to choose which
    feature generators should be executed. Different models need different features
    provided to them. Moreover, sometimes you need to apply specific overrides to
    your normal usage of data because of business rules, privacy concerns, or legal
    reasons.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经看到了如何从您产生的特征中选择，但实际上在某些机器学习系统中有一个必要的零步。在您开始特征生成过程之前，您可能想要选择应该执行哪些特征生成器。不同的模型需要提供不同的特征。此外，有时您需要根据业务规则、隐私问题或法律原因对您的数据正常使用应用特定的覆盖。
- en: In the case of Pidg’n, you have some unique challenges due to your global scale.
    Different regions have different regulatory regimes governing the use of their
    citizens’ data. Recently, a new government has come to power in the rainforests
    of Panama.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 在Pidg’n的情况下，由于您的全球规模，您面临一些独特的挑战。不同地区有不同的监管制度来管理其公民数据的用途。最近，巴拿马的雨林中出现了一个新政府。
- en: The new minister of commerce, an implacable poison-dart frog, has announced
    new regulation restricting the use of social-media user data for non-rainforest
    purposes. After consultation with your lawyers, you decide that the new law means
    that features using data from rainforest users should only be used in the context
    of models to be applied on recommendations for residents of the rainforest.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 新任商业部长，一只不屈不挠的毒箭蛙，宣布了一项新规定，限制将社交媒体用户数据用于非雨林目的。在与您的律师协商后，您决定新法律意味着使用雨林用户数据的特性应仅用于应用于雨林居民推荐模型的上下文中。
- en: Let’s look at what impact this change might have on your codebase. To make things
    a bit more concise, let’s define a simple trait to allow you to make simplified
    generators quickly. This will be a helper to allow you to skip over generator-implementation
    details that aren’t relevant to feature-set composition. The next listing defines
    a stub feature generator that returns random integers.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个变化可能对您的代码库产生什么影响。为了使事情更加简洁，让我们定义一个简单的特性，以便您快速创建简化的生成器。这将是一个辅助工具，允许您跳过与特征集组成无关的生成器实现细节。下一个列表定义了一个存根特征生成器，它返回随机整数。
- en: Listing 4.17\. A stub feature-generator trait
  id: totrans-541
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.17\. 存根特征生成器特性
- en: '[PRE31]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '***1* Implementation of the generate method for implementers of trait to use**'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 特性实现者的 generate 方法实现**'
- en: '***2* Returns random integers**'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 返回随机整数**'
- en: Using this simple helper trait, you can now explore some of the possible impacts
    that the rainforest data-usage rules might have on your feature-generation code.
    Let’s say the code responsible for assembling your feature generators looks like
    the following listing.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个简单的辅助特性，您现在可以探索雨林数据使用规则可能对您的特征生成代码产生的一些可能影响。假设负责组装您的特征生成器的代码如下所示。
- en: Listing 4.18\. Initial feature set composition
  id: totrans-546
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.18\. 初始特征集组成
- en: '[PRE32]'
  id: totrans-547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '***1* Normal feature generator about the language the squawk was written in**'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 关于哨声编写语言的正常特征生成器**'
- en: '***2* Normal feature generator about whether the squawk contains an image**'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 关于哨声是否包含图像的正常特征生成器**'
- en: '***3* User-data feature generator that must be changed**'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 必须更改的用户数据特征生成器**'
- en: '***4* Set of all the feature generators to execute to produce data**'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 需要执行以生成数据的所有特征生成器集**'
- en: Now you need to restructure this code to have one feature set produced for your
    normal, global models and one feature set for your rainforest models, as shown
    in [figure 4.3](#ch04fig03). The following listing shows an approach to defining
    these two different sets of feature generators.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您需要重构此代码，以便为您的正常、全局模型生成一个特征集，并为您的雨林模型生成一个特征集，如图 4.3 所示。以下列表显示了定义这两个不同特征生成器集的方法。
- en: Figure 4.3\. Multiple feature-generator sets
  id: totrans-553
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.3\. 多个特征生成器集
- en: '![](04fig03.jpg)'
  id: totrans-554
  prefs: []
  type: TYPE_IMG
  zh: '![](04fig03.jpg)'
- en: Listing 4.19\. Multiple feature sets
  id: totrans-555
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.19\. 多个特征集
- en: '[PRE33]'
  id: totrans-556
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '***1* User-data feature generator that will only access non-rainforest data**'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 仅访问非雨林数据的用户数据特征生成器**'
- en: '***2* User-data feature generator that will only access rainforest data**'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 仅访问雨林数据的用户数据特征生成器**'
- en: '***3* Set of features available to be used on global models**'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 可用于全局模型上的特征集**'
- en: '***4* Set of features available to be used on rainforest models**'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 可用于雨林模型上的特征集**'
- en: You could stop with this implementation if you chose. As long as the rainforest
    feature generators are being used for rainforest models, you’ve done what the
    frog asked. But there are reasons to keep working on this problem. Machine learning
    systems are incredibly complicated to implement. Common feature-generation functionality
    can get reused in all sorts of places. The implementation in [listing 4.19](#ch04ex19)
    is correct, but with Pidg’n’s rapid growth, new engineers unfamiliar with this
    data-usage issue might refactor this code in such a way as to misuse rainforest
    feature data.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择停止此实现，也可以。只要雨林特征生成器用于雨林模型，您就完成了青蛙的要求。但是，继续解决这个问题有原因。机器学习系统的实现非常复杂。常见的特征生成功能可以在各种地方重用。在[列表
    4.19](#ch04ex19)中的实现是正确的，但随着 Pidg’n 的快速增长，不熟悉此数据使用问题的新的工程师可能会以这种方式重构此代码，从而误用雨林特征数据。
- en: Let’s see if you can make misusing this data even harder by defining a trait
    that allows you to mark code as having rainforest user data in it.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看您是否可以通过定义一个特性来标记代码中包含雨林用户数据，从而使误用此数据变得更加困难。
- en: Listing 4.20\. Ensuring correct usage of rainforest data
  id: totrans-563
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.20\. 确保正确使用雨林数据
- en: '[PRE34]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '***1* Defines a trait for the usage of rainforest data**'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 定义了雨林数据使用的特性**'
- en: '***2* Says all instances of this trait must execute the following code**'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 表示此特性的所有实例都必须执行以下代码**'
- en: '***3* Requires that rainforest environment validation passes**'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 需要雨林环境验证通过**'
- en: '***4* Prints a message explaining disallowed usage in the event of not being
    in the rainforest context**'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 如果不在雨林环境中，则打印一条解释不允许使用的消息**'
- en: '***5* Validation method ensuring that the code is being called in the rainforest
    context**'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 验证方法确保代码在雨林环境中被调用**'
- en: '***6* Retrieves the rainforest environment variable**'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 获取雨林环境变量**'
- en: '***7* Checks that the value exists and is true**'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 检查值是否存在且为真**'
- en: '***8* Defines a feature generator for the rainforest user data**'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 为雨林用户数据定义一个特征生成器**'
- en: '***9* Assembles feature generators to use for the rainforest data**'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 组装用于雨林数据的特征生成器**'
- en: This code will throw an exception unless you’ve explicitly defined an environment
    variable `RAINFOREST` and set it to `TRUE`. If you want to see this switch in
    action, you can export that variable in a terminal window, if you’re using macOS
    or Linux.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有明确定义环境变量 `RAINFOREST` 并将其设置为 `TRUE`，此代码将抛出异常。如果你想看到这个开关的作用，如果你使用 macOS
    或 Linux，你可以在终端窗口中导出该变量。
- en: Listing 4.21\. Exporting an environment variable
  id: totrans-575
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.21\. 导出环境变量
- en: '[PRE35]'
  id: totrans-576
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Then you can execute the code from [listing 4.20](#ch04ex20) again, in the same
    terminal window, without getting exceptions. That’s similar to how you can use
    this in your production feature-generation jobs. Using any of several different
    mechanisms in your configuration, build, or job-orchestration functionality, you
    can ensure that this variable is set properly for rainforest feature-generation
    jobs and not set for global feature-generation jobs. A new engineer creating a
    new feature-generation job for some other purpose would have no reason to set
    this variable. If that engineer misused the rainforest feature generator, that
    misuse would immediately manifest the first time the job was executed in any form.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以在相同的终端窗口中再次执行[列表 4.20](#ch04ex20)中的代码，而不会出现异常。这类似于你如何在生产特征生成作业中使用它。通过配置、构建或作业编排功能中的任何几种不同机制，你可以确保这个变量为雨林特征生成作业正确设置，而不是为全局特征生成作业设置。一个创建新特征生成作业的新工程师可能没有理由设置这个变量。如果那位工程师误用了雨林特征生成器，那么这种误用将在作业以任何形式执行时立即显现。
- en: '|  |'
  id: totrans-578
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Configuration**'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '**配置**'
- en: Using environment variables is one of many different methods to configure components
    of your machine learning system. It has the advantage of being simple to get started
    with and broadly supported.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 使用环境变量是配置您机器学习系统组件的多种不同方法之一。它的优点是易于入门且广泛支持。
- en: As your machine learning system grows in complexity, you’ll want to ensure that
    you have a well-thought-out plan for dealing with configuration. After all, properties
    of your machine learning system set as configurations can determine a lot about
    whether it remains responsive in the face of errors or changes in load. [Part
    3](kindle_split_020.html#part03) of this book addresses most of these issues,
    where we consider the challenges of operating a machine learning system. The good
    news is that you’ll find a lot of versatile tools from the Scala and big data
    ecosystems that will help you tame some of the complexity of dealing with configurations.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你的机器学习系统复杂性增加，你将想要确保你有一个周全的计划来处理配置。毕竟，作为配置设置的机器学习系统的属性可以决定很多关于它是否在面对错误或负载变化时保持响应的问题。[第
    3 部分](kindle_split_020.html#part03)本书讨论了这些问题中的大多数，其中我们考虑了操作机器学习系统的挑战。好消息是，你将发现来自
    Scala 和大数据生态系统的许多多功能工具，这些工具将帮助你驯服处理配置的一些复杂性。
- en: '|  |'
  id: totrans-582
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 4.6\. Applications
  id: totrans-583
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6\. 应用
- en: You’re probably not an arboreal animal, and you may not even operate a microblogging
    service. But if you’re doing machine learning, you’re probably building features
    at some point.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能不是一种树栖动物，甚至可能没有运营一个微博服务。但如果你在做机器学习，你可能在某个时候构建特征。
- en: In advertising systems, you can build features that capture users’ past interactions
    with various types of products. If a user spends all afternoon looking at different
    laptops, you probably want to show them an ad for a laptop or maybe a case, but
    an ad for a sweater wouldn’t make a lot of sense. That feature about which types
    of products the user had been looking at would help the machine-learned model
    figure that out and make the right recommendation.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 在广告系统中，你可以构建捕捉用户与各种类型产品过去互动的特征。如果一个用户整个下午都在看不同的笔记本电脑，你可能想展示给他一台笔记本电脑或可能是一个外壳的广告，但一件毛衣的广告可能就没有太多意义。关于用户查看过哪些类型产品的这个特征将帮助机器学习模型弄清楚这一点，并做出正确的推荐。
- en: At a political polling organization, you could build features pertaining to
    the demographics of different voters. Things like the average income, education,
    and home property value could be encoded into features about voting districts.
    Then those features could be used to learn models about which party a given voting
    district is likely to vote for.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个政治民意调查组织中，你可以构建与不同选民人口统计相关的特征。像平均收入、教育和家庭房产价值这样的东西可以编码到关于选区的特征中。然后，这些特征可以用来学习关于哪个政党给定的选区可能投票的模型。
- en: The applications of features are as endless as the applications of machine learning
    as a technique. They allow you to encode human intelligence about the problem
    in a way that a model-learning algorithm can use that intelligence. Machine learning
    systems are not black-box systems that perform magic tricks. You, the system developer,
    are the one instructing it how to solve the problem, and features are a big part
    of how you encode that information.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 特征的应用与机器学习作为技术的方法的应用一样无限。它们允许你以模型学习算法可以使用的方式编码关于问题的人类智能。机器学习系统不是执行魔术的黑色盒子系统。你，作为系统开发者，是指导它如何解决问题的那个人，而特征是你编码这些信息的重要组成部分。
- en: 4.7\. Reactivities
  id: totrans-588
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7. 反应性
- en: '![](dog-ball.jpg)'
  id: totrans-589
  prefs: []
  type: TYPE_IMG
  zh: '![](dog-ball.jpg)'
- en: 'This chapter covered a lot, but if you’re still interested in learning more
    about features, there’s definitely more to explore. Here are some reactivities
    to take you even deeper into the world of features:'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了大量的内容，但如果你仍然想了解更多关于特征的知识，肯定还有更多可以探索。以下是一些反应性，可以带你更深入地了解特征的世界：
- en: '*Implement two or more feature extractors of your own*. To do this, you’ll
    probably want to choose some sort of base dataset to work with. If you don’t have
    anything meaningful at hand, you can often use text files and then extract features
    from the text. Spark has some basic text-processing functionality built in, which
    you may find helpful. Alternatively, random numbers organized into tabular data
    can work just as well for an activity like this. If you do want to use real data,
    the UCI Machine Learning Repository at [https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)
    is one of the best sources of datasets. Whatever data you use, the point is to
    decide for yourself what might be some interesting transformations to apply to
    this dataset.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实现两个或更多的自定义特征提取器*。为此，你可能需要选择某种类型的基数据集来工作。如果你手头没有有意义的东西，你通常可以使用文本文件，然后从文本中提取特征。Spark内置了一些基本的文本处理功能，这可能对你有帮助。或者，随机数字组织成表格数据也可以用于此类活动。如果你确实想使用真实数据，UCI机器学习仓库[https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)是数据集的最佳来源之一。无论你使用什么数据，关键是你自己决定可能对数据集应用的一些有趣的转换。'
- en: '*Implement feature-selection functionality*. Using the feature extractors you
    created in the previous reactivity (or some other extractors), define some basis
    for including or excluding a given feature within the final output. This could
    include criteria like the following:'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实现特征选择功能*。使用你在前面的反应性（或某些其他提取器）中创建的特征提取器，为包含或排除最终输出中的给定特征定义一些基础。这可能包括以下标准：'
- en: Proportion of nonzero values.
  id: totrans-593
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非零值的比例。
- en: Number of distinct values.
  id: totrans-594
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独特值的数量。
- en: Externally defined business rule/policy. The goal is to ensure that the instances
    produced by your feature-extraction functionality only include the features that
    you define as valid.
  id: totrans-595
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外部定义的业务规则/政策。目标是确保你特征提取功能产生的实例只包含你定义为有效的特征。
- en: '*Evaluate the reactivity of an existing feature-extraction pipeline*. If you
    did the previous two exercises, you can evaluate your own implementation. Alternatively,
    you can examine examples from open source projects like Spark. As you examine
    the feature-extraction pipeline, ask yourself questions like the following:'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*评估现有特征提取管道的反应性*。如果你完成了前面的两个练习，你可以评估自己的实现。或者，你可以检查来自像Spark这样的开源项目的示例。在检查特征提取管道时，你可以问自己以下问题：'
- en: Can I find the feature-transform function? Is it implemented as a pure function,
    or does it have some sort of side effects? Can I easily reuse this transform in
    other feature extractors?
  id: totrans-597
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我能找到特征转换函数吗？它是作为纯函数实现的，还是有某种副作用？我能否轻松地在其他特征提取器中重用这个转换？
- en: How will bad inputs be handled? Will errors be returned to the user?
  id: totrans-598
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何处理不良输入？是否会向用户返回错误？
- en: How will the pipeline behave when it has to handle a thousand records? A million?
    A billion?
  id: totrans-599
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当管道需要处理成千上万条记录时，它会如何表现？一百万条？十亿条？
- en: What can I discern about the feature extractors from the persisted output? Can
    I determine when the features were extracted? With which feature extractors?
  id: totrans-600
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我能从持久化的输出中辨别出关于特征提取器的哪些信息？我能否确定特征是在何时被提取的？使用的是哪些特征提取器？
- en: How could I use these feature extractors to make a prediction on a new instance
    of unseen data?
  id: totrans-601
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我如何使用这些特征提取器对新实例的未见数据做出预测？
- en: Summary
  id: totrans-602
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: Like chicks cracking through eggs and entering the world of real birds, features
    are our entry points into the process of building intelligence into a machine
    learning system. Although they haven’t always gotten the attention they deserve,
    features are a large and crucial part of a machine learning system.
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就像小鸡破壳而出，进入真实鸟类的世界一样，特征是我们进入将智能构建到机器学习系统过程中的切入点。尽管它们并未总是得到应有的关注，但特征是机器学习系统中的一个庞大且关键的部分。
- en: It’s easy to begin writing feature-generation functionality. But that doesn’t
    mean your feature-generation pipeline should be implemented with anything less
    than the same rigor you’d apply to your real-time predictive application. Feature-generation
    pipelines can and should be awesome applications that live up to all the reactive
    traits.
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始编写特征生成功能很容易。但这并不意味着你的特征生成管道应该用低于你在实时预测应用中应用的同样严谨性来实现。特征生成管道可以是并且应该是符合所有反应特性的优秀应用。
- en: Feature extraction is the process of producing semantically meaningful, derived
    representations of raw data.
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征提取是将原始数据转换为具有语义意义的派生表示的过程。
- en: Features can be transformed in various ways to make them easier to learn from.
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征可以通过各种方式转换，使其更容易学习。
- en: You can select among all the features you have to make the model-learning process
    easier and more successful.
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以从所有你拥有的特征中选择，使模型学习过程更容易、更成功。
- en: Feature extractors and transformers should be well structured for composition
    and reuse.
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征提取器和转换器应该具有良好的结构，以便于组合和重用。
- en: Feature-generation pipelines should be assembled into a series of immutable
    transformations (pure functions) that can easily be serialized and reused.
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征生成管道应该组装成一系列不可变的转换（纯函数），这些转换可以轻松序列化和重用。
- en: Features that rely on external resources should be built with resilience in
    mind.
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依赖于外部资源的特征应该具有容错性。
- en: We’re not remotely done with features. In [chapter 5](kindle_split_016.html#ch05),
    you’ll use features in the learning of models. In [chapter 6](kindle_split_017.html#ch06),
    you’ll generate features when you make predictions about unseen data. Beyond that,
    in [part 3](kindle_split_020.html#part03) of the book, we’ll get into more-advanced
    aspects of generating and using features.
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在特征方面还没有完成。在[第五章](kindle_split_016.html#ch05)中，你将在模型学习中使用特征。在[第六章](kindle_split_017.html#ch06)中，你将在对未见数据进行预测时生成特征。除此之外，在本书的[第三部分](kindle_split_020.html#part03)中，我们将探讨生成和使用特征的更高级方面。
- en: Chapter 5\. Learning models
  id: totrans-612
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第五章\. 学习模型
- en: '*This chapter covers*'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Implementing model-learning algorithms
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现模型学习算法
- en: Using Spark’s model-learning capabilities
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark的模型学习功能
- en: Handling third-party code
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理第三方代码
- en: Continuing on our journey through the phases of a machine learning system, we
    now arrive at model learning (see [figure 5.1](#ch05fig01)). You can think of
    this part as that day when you were very young and looked up at a dark sky and
    decided that, based on past experience, it just might rain. The model you learned
    was *dark clouds lead to rain*. Although you may not remember it well, you figured
    out that model by reasoning about your past experiences with dark and bright days
    and whether you got rained on.
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们穿越机器学习系统阶段的旅程中继续前进，我们现在到达了模型学习阶段（见图5.1）。你可以将这部分想象成你很小的时候仰望黑暗的天空，并基于过去的经验决定，它可能真的会下雨。你学到的模型是*乌云带来降雨*。尽管你可能记得不是很清楚，但你通过推理你过去对阴暗和晴朗的日子以及你是否被雨淋到的经验，得出了这个模型。
- en: Figure 5.1\. Phases of machine learning
  id: totrans-618
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.1\. 机器学习的阶段
- en: '![](05fig01.jpg)'
  id: totrans-619
  prefs: []
  type: TYPE_IMG
  zh: '![](05fig01.jpg)'
- en: That process you went through of reasoning about past experiences to develop
    a model that could be applied to future situations is analogous to what we do
    in the model-learning phase of a machine learning system. As I defined it in [chapter
    1](kindle_split_011.html#ch01), machine learning is learning from data, and this
    is the step where we do that learning. We’ll run a model-learning algorithm over
    our features to produce a model. In the context of a machine learning system,
    a *model* is a way of encoding the mapping from features to concepts. It’s a way
    of generalizing all the information in the training instances.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 你通过推理过去经历来开发一个可以应用于未来情境的模型的过程，这与我们在机器学习系统的模型学习阶段所做的工作类似。正如我在[第一章](kindle_split_011.html#ch01)中定义的，机器学习是从数据中学习，而这个步骤就是我们进行学习的阶段。我们将运行一个模型学习算法来处理我们的特征，从而生成一个模型。在机器学习系统的背景下，一个*模型*是编码特征到概念映射的方式。它是一种将训练实例中的所有信息进行归纳的方法。
- en: In software terms, a model is a program that was instantiated with instances
    that can now return predictions when called with features. This definition is
    shown in a stub implementation in the following listing.
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 从软件的角度来说，一个模型是一个实例化的程序，它可以现在在调用特征时返回预测。这个定义在下面的列表中展示了其简化的实现。
- en: Listing 5.1\. A stub model
  id: totrans-622
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.1. 一个简化的模型
- en: '[PRE36]'
  id: totrans-623
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '***1* Instantiates a model with a list of instances (features and concept labels)**'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1** 使用实例列表（特征和概念标签）实例化模型'
- en: '***2* Predicts labels when given new sets of features**'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2** 当给定新的特征集时预测标签'
- en: The implementations of model-learning algorithms are certainly far more complex
    than this stub implementation, but at a high level this is all we’re doing from
    a software perspective. There can be incredibly sophisticated algorithms behind
    the process instantiating a new model, and I’ll discuss some of them in this chapter.
    But the topic of how model-learning algorithms learn from data is huge and is
    the focus of countless other books. Accordingly, I’ll try to cover just enough
    for you to be able to understand what model-learning algorithms do.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 模型学习算法的实现当然比这个简化的实现要复杂得多，但从软件的角度来看，这就是我们正在做的所有事情。在实例化新模型的过程中可能存在极其复杂的算法，我将在本章中讨论其中的一些。但模型学习算法如何从数据中学习是一个巨大的主题，也是无数其他书籍的焦点。因此，我将尽力涵盖足够的内容，以便你能够理解模型学习算法做什么。
- en: 'Then we’ll do what most engineers do when implementing machine learning systems:
    call standard library implementations of common model-learning algorithms. Spark
    has some useful functionality for learning models in MLlib, its machine learning
    library. We’ll build on our usage of MLlib from [chapter 4](kindle_split_015.html#ch04)
    and take our pipelines all the way to learned models.'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将做大多数工程师在实现机器学习系统时所做的事情：调用标准库中常见模型学习算法的实现。Spark在它的机器学习库MLlib中提供了一些用于学习模型的有用功能。我们将基于[第四章](kindle_split_015.html#ch04)中我们对MLlib的使用，将我们的管道一直扩展到学习模型。
- en: MLlib isn’t the only machine learning library in the world, so we’ll also spend
    time exploring how to work with libraries that aren’t as easy to use from our
    Spark pipelines written in Scala. This is a common but challenging problem that
    data teams have to face all the time, and we’ll explore some tactics to reduce
    the pain involved.
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib不是世界上唯一的机器学习库，因此我们还将花时间探索如何使用那些不容易从用Scala编写的Spark管道中使用的库。这是数据团队必须经常面对的常见但具有挑战性的问题，我们将探讨一些减少相关痛苦的方法。
- en: 'Being able to learn models from data is an incredible capability. It’s one
    of the most significant achievements in the history of computer science. That’s
    why, in this chapter, we’re going to put it to use in the service of a noble goal:
    finding love.'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 能够从数据中学习模型是一种令人难以置信的能力。这是计算机科学史上最重大的成就之一。这就是为什么，在本章中，我们将将其用于一个崇高的目标：寻找爱情。
- en: 5.1\. Implementing learning algorithms
  id: totrans-630
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1. 实现学习算法
- en: Timber is a mobile dating app for bears. Single male and female bears who are
    looking for love post their pictures in their profile on Timber. Then they can
    see pictures of other single bears that the app recommends to them. If a bear
    likes what it sees, the bear swipes right on the picture of that bear.
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: Timber是一个专为熊设计的移动约会应用。单身男性和雌性熊可以在Timber的资料上发布他们的照片。然后他们可以看到应用推荐给他们的其他单身熊的照片。如果熊喜欢看到的东西，它就会在该熊的照片上向右滑动。
- en: Behind the scenes of all of this furry romance is a sophisticated recommendation
    model, built by your data-science team at Timber. This chapter follows along as
    you begin to build that model. The team’s goal is to predict which bears will
    like each other so that the Timber app can make recommendations to users. Only
    when two bears swipe right on each other are they connected, so it’s crucial for
    the health of the app that users keep getting introduced to new bears they’d like
    to meet.
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些毛茸茸的浪漫背后，是一个由Timber的数据科学团队构建的复杂推荐模型。本章将随着你开始构建这个模型而展开。团队的目标是预测哪些熊会相互喜欢，以便Timber应用可以向用户做出推荐。只有当两只熊互相右滑时，它们才会连接，因此对于应用的健康来说，用户不断被介绍给想要见面的新熊至关重要。
- en: When two bears like each other and both swipe right, indicating that they’d
    like to meet, this is called a *match* by your Timber data-science team. The team
    plans to run all possible pairs of active users through the model and get predictions
    of which ones are a likely match. Only those predicted as matches (paired) will
    be shown to the users.
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 当两只熊相互喜欢并且都右滑，表示他们想要见面时，你的Timber数据科学团队称之为*匹配*。团队计划将所有可能的活跃用户对通过模型运行，并预测哪些可能是匹配的。只有预测为匹配的（配对）用户才会被展示给用户。
- en: To begin building their model, your team only has its historical data about
    who their users are and which ones ended up matching. They decide to frame the
    problem of predicting which bears will match as a binary classification problem.
    Whether or not a given pair of users matched will be used as class label. All
    the data about the users will be used to build features.
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始构建他们的模型，你的团队只有关于他们的用户是谁以及哪些用户最终匹配的历史数据。他们决定将预测哪些熊会匹配的问题框架为一个二元分类问题。是否匹配将作为类别标签使用。所有关于用户的数据都将用于构建特征。
- en: 'As you saw in [chapter 4](kindle_split_015.html#ch04), building features can
    be a very complicated endeavor. The Timber team has decided to start by building
    features around user similarity. When a bear signs up on Timber, they answer various
    questions to fill out their profile on the app:'
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[第4章](kindle_split_015.html#ch04)中看到的，构建特征可能是一个非常复杂的过程。Timber团队决定从围绕用户相似性构建特征开始。当一只熊在Timber上注册时，他们回答各种问题以填写他们在应用上的个人资料：
- en: What’s your favorite food?
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你最喜欢的食物是什么？
- en: Do you like to go out or are you more of a cave-body?
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你喜欢外出还是更喜欢洞穴生活？
- en: Do you want to have cubs someday?
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将来想要有小熊吗？
- en: In the first version of their feature-generation functionality, your team compared
    the answers of each pair of users to produce features saying whether or not their
    answers were the same. For example, if two bears both answered that their favorite
    food was salmon, that would be recorded as a `true` feature value, but if one
    bear preferred salmon and another preferred berries, then that would be recorded
    as a `false` feature value. This produces instances like the ones shown in [table
    5.1](#ch05table01), which uses 0 for false and 1 for true.
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们特征生成功能的第一版中，你的团队比较了每一对用户的答案，以产生表示他们的答案是否相同的特征。例如，如果两只熊都回答说他们的最爱食物是三文鱼，那么这将记录为一个`true`特征值，但如果一只熊喜欢三文鱼而另一只熊喜欢浆果，那么这将记录为一个`false`特征值。这产生了类似于[表5.1](#ch05table01)中所示的一些实例，其中使用0表示假，1表示真。
- en: Table 5.1\. Similarity instances
  id: totrans-640
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.1\. 相似性实例
- en: '| Favorite food | Go out | Cubs | Match |'
  id: totrans-641
  prefs: []
  type: TYPE_TB
  zh: '| Favorite food | Go out | Cubs | Match |'
- en: '| --- | --- | --- | --- |'
  id: totrans-642
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1 | 0 | 0 | 0 |'
  id: totrans-643
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0 | 0 | 0 |'
- en: '| 1 | 1 | 1 | 1 |'
  id: totrans-644
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 1 | 1 |'
- en: '| 0 | 1 | 1 | 1 |'
  id: totrans-645
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1 | 1 | 1 |'
- en: '| 0 | 1 | 0 | 0 |'
  id: totrans-646
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1 | 0 | 0 |'
- en: '| 1 | 1 | 1 | 0 |'
  id: totrans-647
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 1 | 0 |'
- en: Using similarity data like this, you could perform all sorts of ad hoc analyses
    and develop manual rules. But Timber has lots of users and is growing fast. It
    needs an automated system to reason about this data at scale.
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这样的相似性数据，你可以执行各种临时的分析和制定手动规则。但Timber拥有大量用户，并且发展迅速。它需要一个自动化的系统来大规模地推理这些数据。
- en: 5.1.1\. Bayesian modeling
  id: totrans-649
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1\. 贝叶斯建模
- en: In their first implementation of the model-learning system, the team used a
    technique called *Naive Bayes*. Before we get into how Naive Bayes works and how
    it can be implemented, we need to cover *Bayes’ rule*, which is the basis for
    the Naive Bayes technique. Bayes’ rule is a foundational technique used in some
    forms of statistics.
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们模型学习系统的第一次实现中，团队使用了一种称为*朴素贝叶斯*的技术。在我们深入探讨朴素贝叶斯是如何工作以及如何实现它之前，我们需要了解*贝叶斯定理*，它是朴素贝叶斯技术的基石。贝叶斯定理是某些形式统计学中使用的基石技术。
- en: To understand Bayes’ rule, let’s simplify your data even more. Let’s assume
    that you only know whether two bears share the same favorite food and if they
    matched. Then your team could talk about the probability that two bears will match
    if they share the same favorite food.
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解贝叶斯定理，让我们进一步简化你的数据。假设你只知道两只熊是否分享了相同的喜爱食物，以及它们是否匹配。那么你的团队可以讨论两只熊如果分享了相同的喜爱食物，它们匹配的概率。
- en: The following listing introduces some notation to discuss how you could use
    Bayes’ rule in this case.
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表介绍了一些符号，以讨论在这种情况下如何使用贝叶斯定理。
- en: Listing 5.2\. Notation for Bayes’ rule
  id: totrans-653
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.2\. 贝叶斯定理的符号
- en: '[PRE37]'
  id: totrans-654
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '***1* Notation for the same favorite food**'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 相同喜爱食物的符号**'
- en: '***2* Notation for a match on the app**'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 应用程序中匹配的符号**'
- en: '***3* Probability of having the same favorite food, given they were a match**'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 在匹配的情况下拥有相同喜爱食物的概率**'
- en: '***4* Probability that two bears will be a match given they have same favorite
    food**'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 在两只熊有相同的喜爱食物的情况下匹配的概率**'
- en: '***5* Calculation for this probability**'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 这个概率的计算方法**'
- en: 'Bayes’ rule states that this probability can be calculated as follows: `P(F|M)*P(M)÷P(F)`,
    the probability of having the same favorite food, given that they were a match,
    multiplied by the probability of a match, divided by the probability of having
    the same favorite food.'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理表明，这个概率可以按照以下方式计算：`P(F| M)*P(M)÷P(F)`，即在它们匹配的情况下拥有相同喜爱食物的概率，乘以匹配的概率，除以拥有相同喜爱食物的概率。
- en: Using the data in [table 5.1](#ch05table01), you can calculate those values.
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 [表 5.1](#ch05table01) 中的数据，你可以计算出这些值。
- en: Listing 5.3\. Calculating an application of Bayes’ rule
  id: totrans-662
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.3\. 贝叶斯定理的应用计算
- en: '[PRE38]'
  id: totrans-663
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '***1* Probability of a match in that dataset**'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 该数据集中匹配的概率**'
- en: '***2* Probability of having the same favorite food**'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 拥有相同喜爱食物的概率**'
- en: '***3* Probability of having the same favorite food given they were a match**'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 在匹配的情况下拥有相同喜爱食物的概率**'
- en: '***4* Probability of being a match given two bears share the same favorite
    food**'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 在两只熊分享了相同的喜爱食物的情况下匹配的概率**'
- en: This calculation results in a 1/3 probability of being a match given that two
    bears share the same favorite food.
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: 这个计算结果是在两只熊分享了相同的喜爱食物的情况下，匹配的概率为 1/3。
- en: Bayes’ rule can be generalized to apply to many different features using the
    Naive Bayes technique. Let’s use `G` to represent both bears preferring to go
    out or stay in the den and `C` to indicate agreeing on the decision to have cubs.
    Let’s also refer to a specific combination of feature values as `V`. That’s meant
    to provide a way to talk about the probability of liking the same food and both
    liking to go out, but not agreeing on raising cubs (`true, true, false`) as different
    from bears who agree on everything (`true, true, true`).
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理可以通过朴素贝叶斯技术推广到许多不同的特征。让我们用 `G` 来表示两只熊更喜欢出去还是待在洞穴里，用 `C` 来表示是否同意生小熊。让我们还用
    `V` 来指代特征值的特定组合。这意味着要提供一个方式来讨论喜欢相同食物并且都喜欢出去，但不同意养小熊的概率（`true, true, false`）与所有事情都同意的熊（`true,
    true, true`）是不同的。
- en: With this notation in place, you can now use Bayes’ rule with all your team’s
    original features as `P(F|M)*P(G|M)*P(C|M)*P(M)÷P(V)`. By multiplying all the
    probabilities together, you can get the probability of a match, given the values
    of all of your features.
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种符号后，你现在可以使用贝叶斯定理，将你团队的所有原始特征作为 `P(F|M)*P(G|M)*P(C|M)*P(M)÷P(V)` 来使用。通过将所有概率相乘，你可以得到给定所有特征值的匹配概率。
- en: '|  |'
  id: totrans-671
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Independence**'
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: '**独立性**'
- en: It’s often *not* valid statistically to assume that you can multiply all those
    probabilities together. Doing so presumes that the probabilities of each feature
    value are independent from each other—that they never vary together. That’s why
    this technique is referred to as *naive*, because it fails to take into account
    the possibility of dependence between the features. Despite that limitation, Naive
    Bayes has been empirically shown to be a useful technique.
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学上，通常**不**成立假设你可以将所有这些概率相乘。这样做假设每个特征值的概率是相互独立的——它们永远不会一起变化。这就是为什么这种技术被称为**朴素**，因为它没有考虑到特征之间可能存在依赖性的可能性。尽管有这个限制，朴素贝叶斯已经被实证证明是一种有用的技术。
- en: '|  |'
  id: totrans-674
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '[Table 5.2](#ch05table02) shows what all those probabilities are, based on
    your dataset.'
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 5.2](#ch05table02) 展示了基于你的数据集的所有这些概率。'
- en: Table 5.2\. Probabilities
  id: totrans-676
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 5.2\. 概率
- en: '| Term | Fraction | Probability |'
  id: totrans-677
  prefs: []
  type: TYPE_TB
  zh: '| 术语 | 分数 | 概率 |'
- en: '| --- | --- | --- |'
  id: totrans-678
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| P(F&#124;M) | 1/2 | 0.5 |'
  id: totrans-679
  prefs: []
  type: TYPE_TB
  zh: '| P(F| M) | 1/2 | 0.5 |'
- en: '| P(G&#124;M) | 2/2 | 1.0 |'
  id: totrans-680
  prefs: []
  type: TYPE_TB
  zh: '| P(G|M) | 2/2 | 1.0 |'
- en: '| P(C&#124;M) | 2/2 | 1.0 |'
  id: totrans-681
  prefs: []
  type: TYPE_TB
  zh: '| P(C|M) | 2/2 | 1.0 |'
- en: '| P(M) | 2/5 | 0.4 |'
  id: totrans-682
  prefs: []
  type: TYPE_TB
  zh: '| P(M) | 2/5 | 0.4 |'
- en: To be able to calculate the probability of a given combination of feature values,
    `P(V)`, you’ll have to try to predict on some data.
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够计算给定特征值组合的概率 `P(V)`，你必须尝试在数据上预测。
- en: Let’s say you’re trying to compute the probability that Ping, a panda, and Greg,
    a grizzly bear, will be a match ([figure 5.2](#ch05fig02)). They don’t agree on
    food or whether they’d like to have cubs someday, but they are both den-bodies,
    not liking to go out much. Does the data indicate that these two are likely to
    be a match on Timber?
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在尝试计算 Ping，一只熊猫，和 Greg，一只灰熊，是否会匹配（[图 5.2](#ch05fig02)）。他们在食物或是否希望将来有幼崽的问题上意见不一致，但他们都是洞穴生物，不喜欢外出。数据表明这两个人在
    Timber 上很可能匹配吗？
- en: Figure 5.2\. Timber profile screens
  id: totrans-685
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.2\. 木材剖面屏幕
- en: '![](05fig02.jpg)'
  id: totrans-686
  prefs: []
  type: TYPE_IMG
  zh: '![](05fig02.jpg)'
- en: In this case, `P(V)` is the sum of 0.2, 0.1, and 0.2 or 0.5\. Now you can evaluate
    Bayes’ rule. Plugging in the values from [table 5.2](#ch05table02), you get `0.5
    * 1.0 * 1.0 * 0.4 / (0.2 + 0.1 + 0.2) = 0.4`. Bayes’ rule is modestly confident
    that the two of them will hit it off, so the app might recommend them to each
    other, depending on the scores of their other candidate matches.
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`P(V)` 是 0.2、0.1 和 0.2 的总和，即 0.5。现在你可以评估贝叶斯定理。将 [表 5.2](#ch05table02)
    中的值代入，你得到 `0.5 * 1.0 * 1.0 * 0.4 / (0.2 + 0.1 + 0.2) = 0.4`。贝叶斯定理对这两个人可能会相互吸引持适度信心，因此应用可能会根据他们其他候选匹配的分数向他们推荐对方。
- en: 5.1.2\. Implementing Naive Bayes
  id: totrans-688
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.2\. 实现朴素贝叶斯
- en: Now that you’ve seen how Naive Bayes works, let’s see how you can implement
    it so it can be run as part of Timber’s production model-learning pipeline. To
    begin, you need to build up some training instances to use to train your model.
    You’ll build on the techniques you learned in [chapter 4](kindle_split_015.html#ch04)
    for handling features and extend that code. The following listing shows some of
    the types you used to manage features and labels before, as well as a way of bringing
    them together into instances.
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了朴素贝叶斯是如何工作的，让我们看看你如何实现它，以便它可以作为 Timber 的生产模型学习流程的一部分运行。首先，你需要构建一些训练实例来训练你的模型。你将基于你在[第
    4 章](kindle_split_015.html#ch04)中学到的处理特征的技术，并扩展那段代码。以下列表显示了你在之前用来管理特征和标签的一些类型，以及将它们组合成实例的方法。
- en: Listing 5.4\. Features, labels, and instances
  id: totrans-690
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.4\. 特征、标签和实例
- en: '[PRE39]'
  id: totrans-691
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '***1* Feature-type implementation from [chapter 4](kindle_split_015.html#ch04),
    requiring a type and a name**'
  id: totrans-692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 来自[第 4 章](kindle_split_015.html#ch04)的特征类型实现，需要一个类型和一个名称**'
- en: '***2* Feature implementation from before, requiring a value of a given type**'
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 之前的特征实现，需要一个给定类型的值**'
- en: '***3* Label implementation from before, defining class labels as a special
    type of feature**'
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 之前的标签实现，将类标签定义为特殊类型的特征**'
- en: '***4* Defines Boolean features**'
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 定义布尔特征**'
- en: '***5* Defines Boolean labels**'
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 定义布尔标签**'
- en: '***6* Defines Boolean instances to contain sets of Boolean features and a Boolean
    label**'
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 定义布尔实例以包含布尔特征的集合和布尔标签**'
- en: This is all review from [chapter 4](kindle_split_015.html#ch04). With these
    types in place, you’ll be able to set up your model-learning algorithm to reason
    about features and labels in the form of instances.
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都是对[第 4 章](kindle_split_015.html#ch04)的复习。有了这些类型，你将能够设置你的模型学习算法，以实例的形式推理特征和标签。
- en: Now you can implement the Naive Bayes model. First, you’ll assume that you can
    initialize your implementation with some list of training instances. [Listing
    5.5](#ch05ex05) creates a simple training instance to allow you to get started.
    You’ll factor this out to a constructor parameter shortly, but this fixtured version
    of the data will allow you to start writing code to process the instances.
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以实现朴素贝叶斯模型了。首先，你将假设你可以使用一些训练实例的列表来初始化你的实现。[列表 5.5](#ch05ex05) 创建了一个简单的训练实例，让你开始编写处理实例的代码。你很快会将这个参数提取出来，但这个数据集的固定版本将允许你开始编写处理实例的代码。
- en: Listing 5.5\. Training instances
  id: totrans-700
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.5\. 训练实例
- en: '[PRE40]'
  id: totrans-701
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '***1* Creates a list containing only a single instance**'
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建一个只包含单个实例的列表**'
- en: '***2* Creates a set of all features**'
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 创建一组所有特征**'
- en: '***3* Creates a label value**'
  id: totrans-704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 创建一个标签值**'
- en: Then you’ll operate on the instances within your training set that have `true`
    labels and calculate `P(M)`, the overall probability of a match.
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你将在训练集中操作具有 `true` 标签的实例，并计算 `P(M)`，匹配的整体概率。
- en: Listing 5.6\. Positive training instances
  id: totrans-706
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.6\. 正面训练实例
- en: '[PRE41]'
  id: totrans-707
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '***1* Filters instances to only the ones with true class labels**'
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 过滤实例，仅保留具有真实类标签的实例**'
- en: '***2* Calculates P(M), the overall probability of a match**'
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 计算匹配的整体概率 P(M)**'
- en: Then you can build up the probabilities of each given feature, given a match
    (for example, `P(F|M)`, the probability of having the same favorite food given
    that a couple was a match). Because you could have an arbitrary number of features,
    you’ll build up the unique set of all features first and then produce the probabilities
    for each one you find.
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以构建每个给定特征的概率，给定一个匹配（例如，`P(F|M)`，即一对匹配的情侣有相同最喜欢的食物的概率）。因为你可能有任意数量的特征，所以首先构建所有特征的唯一集合，然后为找到的每个特征生成概率。
- en: Listing 5.7\. Feature probabilities
  id: totrans-711
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.7\. 特征概率
- en: '[PRE42]'
  id: totrans-712
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '***1* Builds a set of all unique feature types in the training set**'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 构建训练集中所有唯一特征类型的集合**'
- en: '***2* Maps over all distinct feature types**'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 遍历所有不同的特征类型**'
- en: '***3* For each feature, maps over all instances with true class labels**'
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 对于每个特征，遍历所有具有真实类标签的实例**'
- en: '***4* Uses a filter to match to a current feature by name**'
  id: totrans-716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 使用过滤器通过名称匹配当前特征**'
- en: '***5* Counts a feature value if it’s true**'
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 如果特征值为真，则计算特征值**'
- en: '***6* Sums up all positive examples, dividing by the total number of true instances**'
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 将所有正例相加，除以真实实例总数**'
- en: Now that you’ve calculated all the terms in the numerator of the equation, you
    can calculate the entire numerator. The following listing uses multiplication,
    `*`, as a higher-order function to reduce over your list of feature probabilities
    before multiplying by `P(M)`, the probability of a match.
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经计算了方程分子中的所有项，你可以计算整个分子。下面的列表使用乘法`*`作为高阶函数，在乘以`P(M)`，即匹配的概率之前，对特征概率列表进行归约。
- en: Listing 5.8\. Numerator
  id: totrans-720
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.8\. 分子
- en: '[PRE43]'
  id: totrans-721
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Now you just need to be able to calculate `P(V)`, the probability of a given
    feature vector. The next listing shows a simple function to perform that calculation
    for an arbitrary set of features.
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你只需要能够计算`P(V)`，即给定特征向量的概率。下面的列表显示了执行该计算的一个简单函数，用于任意一组特征。
- en: Listing 5.9\. Feature vector
  id: totrans-723
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.9\. 特征向量
- en: '[PRE44]'
  id: totrans-724
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '***1* Counts the instances with the matching feature values**'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 计算具有匹配特征值的实例数量**'
- en: '***2* Divides the number of matching instances over the total number of instances
    to get the P(V)**'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将匹配实例的数量除以实例总数以获得 P(V)**'
- en: With all the pieces now in place, writing the `predict` function is straightforward.
    Given a new feature vector, calculate the denominator and divide the numerator
    by it.
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: 现在所有部件都已就绪，编写`predict`函数就很简单了。给定一个新的特征向量，计算分母，然后除以分子。
- en: Listing 5.10\. Prediction function
  id: totrans-728
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.10\. 预测函数
- en: '[PRE45]'
  id: totrans-729
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '***1* Calculates probability by dividing a precomputed numerator by a denominator
    for a given instance**'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 通过将给定实例的预计算分子除以分母来计算概率**'
- en: As a final refactor, let’s put all this code inside a class and pass instances
    at the time of construction. The next listing shows all the modeling code from
    before, refactored into a class.
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的重构，让我们将这些代码放入一个类中，并在构造时传递实例。下面的列表显示了之前的所有建模代码，重构为一个类。
- en: Listing 5.11\. Naive Bayes model
  id: totrans-732
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.11\. 简单贝叶斯模型
- en: '[PRE46]'
  id: totrans-733
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '***1* Instantiates the model with training instances**'
  id: totrans-734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 使用训练实例实例化模型**'
- en: This implementation doesn’t need to do much work when new feature vectors come
    in for prediction. As part of the instantiation of the class, the model was effectively
    trained, and the model parameters, the various probabilities, are now held in
    the internal state of the given model instance.
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现对于预测新特征向量时不需要做太多工作。作为类实例化的部分，模型已经得到了有效训练，并且模型参数、各种概率现在被保存在给定模型实例的内部状态中。
- en: You can try out this code by writing a simple test.
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过编写一个简单的测试来尝试这段代码。
- en: Listing 5.12\. Testing the Naive Bayes model
  id: totrans-737
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.12\. 测试简单贝叶斯模型
- en: '[PRE47]'
  id: totrans-738
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '***1* Sets up a test of model learning and prediction**'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 设置模型学习和预测的测试**'
- en: '***2* Creates some training instances to learn the model with**'
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 创建一些训练实例以学习模型**'
- en: '***3* Creates a test feature vector to predict on**'
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 创建一个测试特征向量进行预测**'
- en: '***4* Instantiates a class and, thus, trains the model**'
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 实例化一个类，从而训练模型**'
- en: '***5* Predicts on the test feature vector**'
  id: totrans-743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 在测试特征向量上进行预测**'
- en: '***6* Asserts that the result is 0.5**'
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 断言结果为 0.5**'
- en: This implementation is a pretty good representation of the mathematical process
    that you went through by hand before. It took your Timber data-science team some
    time to get this implementation figured out. Though it definitely predicts matches,
    this implementation isn’t perfect. For one thing, it can only handle Boolean feature
    values and Boolean labels. It also doesn’t handle things like not finding the
    exact feature vector in the training instances that you’re trying to predict on
    now.
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 这种实现很好地代表了你在手工操作之前所经历的数学过程。Timber数据科学团队花了一些时间才弄清楚这个实现。尽管它确实可以预测匹配，但这种实现并不完美。首先，它只能处理布尔特征值和布尔标签。它也不处理诸如现在尝试预测的训练实例中找不到精确特征向量等问题。
- en: There are things to like about this approach to analyzing data. By implementing
    the mathematics of Naive Bayes as runnable code, you could run it over as many
    training instances with as many features as your server can handle. Of course,
    this implementation is consistent in its approach, as contrasted with any ad hoc,
    manual-analysis approach. Another nice feature of this implementation is that
    it’s verifiable—you can write more tests to demonstrate that this implementation
    is correct.
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种数据分析方法，有很多值得喜欢的地方。通过将朴素贝叶斯的数学实现为可运行的代码，你可以运行它，处理尽可能多的训练实例和特征，只要你的服务器能够处理。当然，这种实现的方法是一致的，与任何临时、手动分析的方法形成对比。这种实现的另一个优点是它是可验证的——你可以编写更多的测试来证明这种实现是正确的。
- en: I hope you agree that there’s a lot of benefit to using machine learning to
    build a recommendation model. You can certainly take things even further. Naive
    Bayes is just one algorithm; there’s no reason to believe that it’s the best algorithm
    for this problem. If you want to explore more learning algorithms (and I hope
    you do!), then you may not want to implement them all yourself. There’s no need
    to build everything from scratch. Tools like Spark and MLlib have a lot of functionality
    that you can use to explore model-learning algorithms even more.
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你们同意，使用机器学习来构建推荐模型有很多好处。当然，你可以更进一步。朴素贝叶斯只是一个算法；没有理由相信它是这个问题的最佳算法。如果你想探索更多的学习算法（我希望你确实如此！），你可能不想自己实现它们所有。没有必要从头开始构建一切。像Spark和MLlib这样的工具有很多功能，你可以使用它们来进一步探索模型学习算法。
- en: 5.2\. Using MLlib
  id: totrans-748
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 使用MLlib
- en: In [chapters 2](kindle_split_012.html#ch02) and [4](kindle_split_015.html#ch04),
    you got a taste of Spark’s machine learning capabilities from MLlib, its machine
    learning library. It has a wide range of machine learning functionality that can
    help you explore various modeling techniques.
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](kindle_split_012.html#ch02)和[第4章](kindle_split_015.html#ch04)中，你通过MLlib，Spark的机器学习库，体验了Spark的机器学习功能。它具有广泛的机器学习功能，可以帮助你探索各种建模技术。
- en: '![](infinite-data.jpg)'
  id: totrans-750
  prefs: []
  type: TYPE_IMG
  zh: '![无限数据](infinite-data.jpg)'
- en: For example, MLlib already has a very capable and sophisticated implementation
    of Naive Bayes. Perhaps most importantly, you can train the MLlib implementation
    of Naive Bayes over datasets of arbitrary size using Spark’s elasticity capabilities.
    The comparatively simpler implementation in the previous section is limited to
    a single Java process running on a single server.
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，MLlib已经有一个非常强大和复杂的朴素贝叶斯实现。也许最重要的是，你可以使用Spark的弹性能力在任意大小的数据集上训练MLlib的朴素贝叶斯实现。上一节中比较简单的实现仅限于在单个服务器上运行的单一Java进程。
- en: Engineers are often excited to port legacy model-learning implementations over
    to Spark implementations. The code becomes simpler, the job can become much more
    scalable, and taking advantage of other big data tools becomes easier. Data scientists
    also stand to gain from this transition. When production machine learning systems
    use MLlib functionality, data scientists can experiment with MLlib’s wide range
    of algorithms. When a modeling approach works well, incorporating it into the
    production-data pipelines is easy.
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: 工程师们通常很兴奋地将传统的模型学习实现迁移到Spark实现。代码变得更简单，工作可以变得更具可扩展性，利用其他大数据工具也变得更容易。数据科学家也能从这种过渡中受益。当生产机器学习系统使用MLlib功能时，数据科学家可以尝试MLlib的广泛算法。当一种建模方法效果良好时，将其纳入生产数据管道变得容易。
- en: 5.2.1\. Building an ML pipeline
  id: totrans-753
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1\. 构建机器学习管道
- en: Let’s get back to the problem of building a better recommendation model for
    bears seeking love. The Timber team begins to build out the second version of
    their model-learning functionality. This pipeline consumes the features and labels
    generated by the upstream feature-generation pipeline. The instances for training
    and testing the model are persisted in LIBSVM format in flat files. In the future,
    the team hopes to put this data into a database, but for this early stage of development,
    LIBSVM-formatted files work fine. The next listing shows a sample of that data.
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到构建更好的推荐模型以帮助寻求爱情的熊的问题。Timber 团队开始构建他们模型功能的第二个版本。此管道消耗上游特征生成管道生成的特征和标签。用于训练和测试模型的实例以
    LIBSVM 格式保存在平面文件中。在未来，团队希望将这些数据放入数据库中，但在这个早期开发阶段，LIBSVM 格式的文件工作得很好。下面的列表显示了该数据的一个样本。
- en: Listing 5.13\. Instances in LIBSVM format
  id: totrans-755
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.13\. LIBSVM 格式的实例
- en: '[PRE48]'
  id: totrans-756
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: As discussed in [chapter 1](kindle_split_011.html#ch01), instances record the
    label value in the first position, followed by pairs of feature identifiers to
    feature values.
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [第 1 章](kindle_split_011.html#ch01) 中所述，实例记录标签值在第一个位置，其后是特征标识符与特征值的成对出现。
- en: The first line of data in [listing 5.13](#ch05ex13) is a true instance with
    the value `3` for the first feature, the value `4` for the second feature, and
    the value `2` for the third feature. Formats for storing features like LIBSVM
    are known as *sparse formats*, meaning features can be absent if their values
    are `0` or unknown. Sparse formats are an alternative to *dense formats*, where
    all features must be present, regardless of their value. Sparse formats are intrinsically
    more flexible, so the Timber team decides to use LIBSVM for now. They hope that
    will make it easier when they eventually adapt their data architecture to persist
    this data in a document database, with a sparse representation of their features.
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 5.13](#ch05ex13) 中的第一行数据是一个真实实例，第一个特征值为 `3`，第二个特征值为 `4`，第三个特征值为 `2`。用于存储特征如
    LIBSVM 的格式称为 *稀疏格式*，这意味着如果特征值为 `0` 或未知，则特征可以不存在。稀疏格式是 *密集格式* 的替代品，在密集格式中，所有特征都必须存在，无论其值如何。稀疏格式本质上更灵活，因此
    Timber 团队决定现在使用 LIBSVM。他们希望这将在他们最终将数据架构调整为以文档数据库的形式持久化这些数据，并使用其特征的稀疏表示时，会更容易。'
- en: Data formatted in this way can easily be loaded into the new Spark pipeline,
    once you establish the standard configuration for the job.
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式格式化的数据可以轻松加载到新的 Spark 管道中，一旦您为作业建立了标准配置。
- en: Listing 5.14\. Loading LIBSVM instances
  id: totrans-760
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.14\. 加载 LIBSVM 实例
- en: '[PRE49]'
  id: totrans-761
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '***1* Creates a new Spark session for the job**'
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 为作业创建一个新的 Spark 会话***'
- en: '***2* Loads an instance data into a DataFrame**'
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将实例数据加载到 DataFrame 中***'
- en: The functionality that loads LIBSVM data understands the structure of the format,
    so a column named `features` and a column named `label` will be created automatically.
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: 加载 LIBSVM 数据的功能理解该格式的结构，因此将自动创建名为 `features` 和 `label` 的列。
- en: With this data loaded, depending on how you want to learn a model, you can use
    this `DataFrame` directly. In this case, let’s take full advantage of the capabilities
    of the Spark ML package to perform a bit of preprocessing. You can use two indexers
    to process the features and the labels in the `DataFrame` of instances. These
    indexers will analyze how many different values of features and labels it sees
    and put that metadata back into the `DataFrame`. In this example data, you have
    all categorical features, so the indexers will detect that and record that in
    the metadata in the `DataFrame`. These category values as well as the label values
    will be mapped to an internal representation of the values, which can improve
    the model-learning process. The values and their associated metadata will later
    be used by the model-learning algorithm.
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
  zh: 加载此数据后，根据您想要学习模型的方式，您可以直接使用此 `DataFrame`。在这种情况下，让我们充分利用 Spark ML 包的功能进行一些预处理。您可以使用两个索引器来处理实例
    `DataFrame` 中的特征和标签。这些索引器将分析它看到的不同特征和标签值，并将这些元数据放回 `DataFrame` 中。在这个示例数据中，您有所有分类特征，因此索引器将检测到这一点，并在
    `DataFrame` 的元数据中记录下来。这些类别值以及标签值将被映射到值的内部表示，这可以改善模型学习过程。这些值及其关联的元数据将随后由模型学习算法使用。
- en: Listing 5.15\. Detecting feature and label values
  id: totrans-766
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.15\. 检测特征和标签值
- en: '[PRE50]'
  id: totrans-767
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '***1* Sets up the StringIndexer to process labels in instances of DataFrame**'
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 为 DataFrame 中的实例设置 StringIndexer 以处理标签***'
- en: '***2* Reads from a label column**'
  id: totrans-769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 从标签列读取***'
- en: '***3* Writes transformed labels to the indexedLabel column**'
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 将转换后的标签写入 indexedLabel 列**'
- en: '***4* Sets the DataFrame to process**'
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 设置要处理的 DataFrame**'
- en: '***5* Sets up the VectorIndexer to process feature vectors in instances of
    DataFrame**'
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 设置 VectorIndexer 以处理 DataFrame 实例中的特征向量**'
- en: '***6* Reads from the features column created when the LIBSVM file was read
    and transformed into a DataFrame**'
  id: totrans-773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 从读取并转换为 DataFrame 的 LIBSVM 文件创建的特征列中读取**'
- en: '***7* Writes processed features to the indexedFeatures column**'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 将处理后的特征写入 indexedFeatures 列**'
- en: '***8* Sets the DataFrame to process**'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 将 DataFrame 设置为处理**'
- en: '![](laziness.jpg)'
  id: totrans-776
  prefs: []
  type: TYPE_IMG
  zh: '![](laziness.jpg)'
- en: It’s worth noting that nothing has been processed yet. Each of these is a `PipelineStage`
    that you’ll fully compose later and then execute. This is more of Spark’s lazy
    compositional style.
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，目前还没有进行任何处理。这些都是你将在稍后完全组合并执行的`PipelineStage`。这更多的是 Spark 的懒式组合风格。
- en: Next, you need to split your data into training and testing sets, as shown in
    [listing 5.16](#ch05ex16). With the testing set, you’ll perform predictions on
    data that your model hasn’t seen before. [Chapter 6](kindle_split_017.html#ch06)
    discusses the topic of testing models in more detail. For the moment, it’s enough
    to set aside a random 20% of your data for later use.
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要将你的数据分成训练集和测试集，如[代码清单 5.16](#ch05ex16)所示。使用测试集，你将在模型尚未见过的数据上执行预测。[第 6
    章](kindle_split_017.html#ch06)更详细地讨论了测试模型的话题。目前，将你数据的 20% 随机留出以备后用就足够了。
- en: Listing 5.16\. Splitting instances into training and testing sets
  id: totrans-779
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代码清单 5.16\. 将实例分割为训练集和测试集
- en: '[PRE51]'
  id: totrans-780
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '***1* Splits the data: 80% for training and 20% for testing**'
  id: totrans-781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 分割数据：80% 用于训练，20% 用于测试**'
- en: Now you can finally set up your model-learning algorithm. Your team at Timber
    decides to start with a decision-tree model. A *decision tree* is a technique
    that divides the classification decision into a series of decisions about each
    feature. Decision trees work well with categorical features like the ones you’re
    using, so the team is optimistic that decision trees may be a good place to start.
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你最终可以设置你的模型学习算法了。Timber 团队决定从决策树模型开始。*决策树*是一种将分类决策分解为一系列关于每个特征的决策的技术。决策树与像你正在使用的这样的分类特征很好地工作，因此团队乐观地认为决策树可能是一个好的起点。
- en: Listing 5.17\. Decision-tree model
  id: totrans-783
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代码清单 5.17\. 决策树模型
- en: '[PRE52]'
  id: totrans-784
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '***1* Sets up a new decision-tree classifier**'
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 设置一个新的决策树分类器**'
- en: '***2* Sets which column the label is in**'
  id: totrans-786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 设置标签所在的列**'
- en: '***3* Sets which column the features are in**'
  id: totrans-787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 设置特征所在的列**'
- en: Again, nothing has been learned here; this is just another `PipelineStage`.
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这里还没有学习到任何东西；这只是一个另一个的`PipelineStage`。
- en: Before you put this pipeline together and execute it, you need to put in one
    last stage to convert from the internal representation of labels to your original
    one. The indexers you used in [listing 5.16](#ch05ex16) have the ability to come
    up with new identifiers for the features and labels you provided. But that information
    isn’t lost, so you can turn all predictions made by the model back into your original
    representation, where 1 corresponded to a match. This stage, where you convert
    back from those internal label representations into the original labels, is shown
    in the following listing.
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: 在你将此管道组合并执行之前，你需要添加一个最后的阶段，将标签的内部表示转换为原始表示。你在[代码清单 5.16](#ch05ex16)中使用的索引器能够为提供的特征和标签生成新的标识符。但该信息并未丢失，因此你可以将模型做出的所有预测转换回你的原始表示，其中
    1 对应于匹配。这个阶段，将内部标签表示转换回原始标签，在下面的代码清单中展示。
- en: Listing 5.18\. Converting labels
  id: totrans-790
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代码清单 5.18\. 转换标签
- en: '[PRE53]'
  id: totrans-791
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '***1* Sets up the transformer to convert from the internal label value back
    to the original value**'
  id: totrans-792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 设置转换器，将内部标签值转换回原始值**'
- en: '***2* Sets the column where predictions can be found**'
  id: totrans-793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 设置可以找到预测的列**'
- en: '***3* Sets which column to write converted labels to**'
  id: totrans-794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 设置写入转换后的标签的列**'
- en: '***4* Sets what were original labels, using the label indexer**'
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 使用标签索引器设置原始标签**'
- en: Now the pipeline can be composed using Spark ML’s `Pipeline` construct. The
    next listing takes the four `PipelineStage`s that you’ve defined and composes
    them into a single runnable unit.
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，可以使用 Spark ML 的 `Pipeline` 构造来组合管道。下一个代码清单将你定义的四个 `PipelineStage` 组合成一个可运行的单元。
- en: Listing 5.19\. Composing a pipeline
  id: totrans-797
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代码清单 5.19\. 组合管道
- en: '[PRE54]'
  id: totrans-798
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '***1* Sets up a Pipeline**'
  id: totrans-799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 设置 Pipeline**'
- en: '***2* Sets the stages to execute in order**'
  id: totrans-800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 设置要按顺序执行的阶段**'
- en: This declarative method of assembling the phases of a pipeline to be run makes
    it very easy to create reusable pipeline stages and build variant versions of
    pipelines using those stages. With this composed pipeline, you can now execute
    the pipeline by processing your features and learning the model.
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
  zh: 这种声明式方法组装管道阶段以便运行，使得创建可重用的管道阶段和构建使用这些阶段的管道的变体版本变得非常容易。有了这个组合管道，你现在可以通过处理你的特征和学习模型来执行管道。
- en: Listing 5.20\. Learning the model
  id: totrans-802
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.20\. 学习模型
- en: '[PRE55]'
  id: totrans-803
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '***1* Executes the pipeline and learns the model**'
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 执行管道并学习模型**'
- en: After all that structuring and composition, this invocation of `fit` is the
    step that runs the whole model and eventually learns the model.
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些结构和组合之后，这个`fit`方法的调用是运行整个模型并最终学习模型的步骤。
- en: Now that you have a model, let’s demonstrate that it can do something useful.
    Typically, at this point in a pipeline, people attempt to evaluate the model over
    unseen data. This phase is called *testing* the model, as contrasted with *training*
    the model. [Chapter 6](kindle_split_017.html#ch06) discusses this process more,
    but let’s see a bit of what your model can do by getting it to predict on some
    of your testing data.
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有一个模型了，让我们展示它能够做一些有用的事情。通常，在这个管道的这一点，人们会尝试在未见过的数据上评估模型。这个阶段被称为*测试*模型，与*训练*模型相对。[第6章](kindle_split_017.html#ch06)讨论了这一过程，但让我们看看你的模型能做什么，通过让它预测一些你的测试数据来一探究竟。
- en: Listing 5.21\. Predicting
  id: totrans-807
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.21\. 预测
- en: '[PRE56]'
  id: totrans-808
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '***1* Uses the model to predict on testing data**'
  id: totrans-809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 使用模型对测试数据进行预测**'
- en: '***2* Prints one of the predictions, the true label, and the features used**'
  id: totrans-810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 打印出一个预测结果、真实标签和使用的特征**'
- en: This shows that your model has been learned and you can now predict on unseen
    data. At this point, you may be curious about what exactly this model is. Not
    all model-learning algorithms produce models that are easy for humans to reason
    about. But the decision tree that you used is something you can look at and understand
    the learned structure of decisions that the model will make.
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明你的模型已经学习到了，你现在可以预测未见过的数据。在这个时候，你可能对模型的确切内容感到好奇。并非所有的模型学习算法都能产生易于人类推理的模型。但你所使用的决策树是你可以查看并理解模型将做出的决策的学习结构的。
- en: Listing 5.22\. Inspecting the model
  id: totrans-812
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.22\. 检查模型
- en: '[PRE57]'
  id: totrans-813
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '***1* Gets a decision-tree model from the executed pipeline**'
  id: totrans-814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 从执行管道中获取决策树模型**'
- en: '***2* Casts it to an instance of the DecisionTreeClassificationModel**'
  id: totrans-815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将其转换为DecisionTreeClassificationModel的实例**'
- en: '***3* Prints the resulting model**'
  id: totrans-816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 打印出结果模型**'
- en: Printing the model should produce something like the model shown in the following
    listing.
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: 打印模型应该会产生如下列表中所示的内容。
- en: Listing 5.23\. Inspecting the model
  id: totrans-818
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.23\. 检查模型
- en: '[PRE58]'
  id: totrans-819
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '***1* Describes the type and structure of the model**'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 描述模型的类型和结构**'
- en: '***2* Explains the decision the tree model will make when predicting on new
    data**'
  id: totrans-821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 解释决策树模型在预测新数据时将做出的决策**'
- en: This is a simple model; you’re not working with much data, and you haven’t defined
    too many features. But all the code you just wrote could be used to scale up to
    more-complex models learned over more features, as you’ll see in the next section.
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的模型；你并没有处理很多数据，也没有定义太多特征。但你所写的所有代码都可以用来扩展到更复杂的模型，这些模型是在更多特征上学习到的，你将在下一节中看到。
- en: Beyond being a flexible implementation that can support easy changes in modeling
    approaches, this pipeline is also quite reactive, thanks to being built on top
    of all the powerful infrastructure provided by Spark. You could easily and quickly
    deploy this pipeline to production at scale in the same way you could for any
    other Spark application.
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: 除了是一个灵活的实现，可以支持建模方法中的轻松更改之外，这个管道还非常具有反应性，这得益于它建立在Spark提供的所有强大基础设施之上。你可以像对任何其他Spark应用程序一样轻松快速地将这个管道部署到生产环境中。
- en: 5.2.2\. Evolving modeling techniques
  id: totrans-824
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2\. 演化建模技术
- en: '![](possible-worlds.jpg)'
  id: totrans-825
  prefs: []
  type: TYPE_IMG
  zh: '![可能的世界](possible-worlds.jpg)'
- en: 'The other aspect of this design that the team is excited about is that evolving
    their approach to a given modeling problem is quick and easy. After this first
    decision-tree model-learning pipeline is completed, your team decides to try a
    related but more sophisticated technique: *random forests*. This technique still
    uses decision trees, but it uses many of them in combination. Using multiple models
    in combination with each other, called an *ensemble*, is one of the most powerful
    techniques in all of machine learning. Rather than trying to get a single model
    learned on a single dataset using a single set of model-learning parameters, ensemble
    modeling techniques improve performance by creating different models, potentially
    with different strengths in combination. This is a sort of possible-worlds technique,
    where you assume that different models might be right about different aspects
    of the concept.'
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: 团队对此设计兴奋的另一个方面是，将他们的方法演变成特定的建模问题既快又简单。在完成这个第一个决策树模型学习流程之后，你的团队决定尝试一个相关但更复杂的技术：*随机森林*。这项技术仍然使用决策树，但它结合使用了多个决策树。使用多个模型结合在一起，称为*集成*，是机器学习中最强大的技术之一。而不是试图使用单一的数据集和单一组模型学习参数来学习单个模型，集成建模技术通过创建不同的模型，可能具有不同的组合优势来提高性能。这是一种可能世界的技术，你假设不同的模型可能在概念的不同方面是正确的。
- en: Even though this technique is more sophisticated, and the implementation of
    the algorithm is more complicated, this isn’t any harder for you to use than the
    basic decision-tree model from before. The code is nearly identical to what you
    wrote earlier.
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这项技术更为复杂，算法的实现也更加复杂，但这并不比之前的基本决策树模型更难使用。代码几乎与你之前写的完全相同。
- en: Listing 5.24\. Learning a random-forest model
  id: totrans-828
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.24\. 学习随机森林模型
- en: '[PRE59]'
  id: totrans-829
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '***1* Sets up a random-forest classifier**'
  id: totrans-830
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 设置随机森林分类器**'
- en: '***2* Creates a slightly different pipeline, using a random-forest classifier**'
  id: totrans-831
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 创建了一个略微不同的流程，使用随机森林分类器**'
- en: '***3* Executes the pipeline**'
  id: totrans-832
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 执行流程**'
- en: '***4* Extracts the learned model from the pipeline for inspection**'
  id: totrans-833
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 从流程中提取学习到的模型以进行检查**'
- en: '***5* Prints a representation of the learned model**'
  id: totrans-834
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 打印出学习到的模型表示**'
- en: If you execute the code in [listing 5.24](#ch05ex24), you should see a much
    larger model printed than you saw for the simple decision-tree model.
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你执行了[列表 5.24](#ch05ex24)中的代码，你应该会看到一个比简单决策树模型更大的模型被打印出来。
- en: Listing 5.25\. A random forest model
  id: totrans-836
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.25\. 随机森林模型
- en: '[PRE60]'
  id: totrans-837
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '***1* Describes the type and structure of the model**'
  id: totrans-838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 描述了模型类型和结构**'
- en: '***2* Explains the various decision-tree models within the larger random-forest
    model**'
  id: totrans-839
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 解释了更大随机森林模型中的各种决策树模型**'
- en: '***3* Given decision tree within the forest, weighted equally to the other
    trees**'
  id: totrans-840
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 在森林中的决策树内，与其他树具有相同的权重**'
- en: '***4* First branch of a given decision tree, testing whether the feature is
    0**'
  id: totrans-841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 给定决策树的第一分支，测试特征是否为 0**'
- en: '***5* Predicts 0, or false**'
  id: totrans-842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 预测为 0，或假**'
- en: '***6* Second branch of the decision tree, when the feature is 1**'
  id: totrans-843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 决策树的第二分支，当特征为 1 时**'
- en: '***7* Predicts 1, or true**'
  id: totrans-844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 预测为 1，或真**'
- en: That’s a lot more modeling sophistication for a trivial change in your code!
    This is awesome power to have in a fast-growing dating-app startup. You can easily
    try out a wide range of modeling strategies without having to implement them all
    yourself, and when you find something that works, it can be rapidly deployed over
    your whole dataset. That should add up to a lot more happy ursine couples!
  id: totrans-845
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对你代码中一个微小的变化所增加的更多建模复杂性！这对于一个快速增长的约会应用初创公司来说是一种非常强大的功能。你可以轻松尝试各种建模策略，而无需自己实现它们，当你找到有效的方法时，它可以迅速部署到整个数据集上。这应该会带来更多快乐的熊熊情侣！
- en: 5.3\. Building facades
  id: totrans-846
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 建立立面
- en: With all these improvements in your model-learning pipeline, the team is looking
    to take on more-significant technical challenges. They decide they want to be
    able to use cutting-edge techniques like *deep learning*. Deep learning is a recently
    developed technique in machine learning that builds on earlier work in *neural
    networks*, a technique for building learning algorithms that mimic the structure
    of the brains of animals.
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的模型学习流程中有了所有这些改进之后，团队正在寻找承担更具挑战性的技术任务。他们决定他们想要能够使用像*深度学习*这样的尖端技术。深度学习是机器学习领域最近发展起来的技术，它建立在早期关于*神经网络*的工作之上，这是一种构建学习算法的技术，模仿动物大脑的结构。
- en: Although MLlib has support for some forms of neural networks, it doesn’t offer
    a lot of the deep learning functionality you may want out of the box, so you’ll
    need to figure out how to make that work. There are some efforts to enable deep
    learning on Spark, but your team really wants to be able to take advantage of
    the latest advances as they happen. The current fashion in deep learning research
    is to use technologies accessed via Python, so, ideally, you should find a way
    to use those technologies in cooperation with your existing Scala applications.
    Getting your Scala code to drive bleeding-edge Python research code certainly
    could be tricky, but you’ll be able to pull it off using a pattern called a *facade*.
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然MLlib支持某些形式的神经网络，但它并不提供您可能希望开箱即用的许多深度学习功能，因此您需要找出如何使其工作。有一些努力旨在在Spark上启用深度学习，但你们团队真正希望能够在发生时利用最新的进展。深度学习研究中的当前趋势是使用通过Python访问的技术，因此，理想情况下，您应该找到一种方法，将这些技术与现有的Scala应用程序合作使用。让您的Scala代码驱动最前沿的Python研究代码可能确实很棘手，但您可以使用一种称为“外观”的模式来实现这一点。
- en: The facade pattern (also known as a *wrapper*, an *adapter*, or a *connector*)
    is a relatively well-established technique for integrating third-party libraries.
    The idea is to write some new code in your application with the sole responsibility
    of acting as an intermediary between your application and a third-party library.
    This intermediary is the facade, and it’s in charge of harmonizing the API of
    the underlying library with the expectations of your application ([figure 5.3](#ch05fig03)).
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
  zh: 外观模式（也称为*包装器*、*适配器*或*连接器*）是一种相对成熟的集成第三方库的技术。想法是在您的应用程序中编写一些新的代码，其唯一责任是作为您应用程序和第三方库之间的中介。这个中介是外观，它负责协调底层库的API与您应用程序的期望（[图5.3](#ch05fig03)）。
- en: Figure 5.3\. Facade pattern
  id: totrans-850
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.3. 外观模式
- en: '![](05fig03.jpg)'
  id: totrans-851
  prefs: []
  type: TYPE_IMG
  zh: '![图片](05fig03.jpg)'
- en: 5.3.1\. Learning artistic style
  id: totrans-852
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1. 学习艺术风格
- en: For your first foray into the world of deep learning, you’ll transform user
    photos into the style of famous paintings. The idea is to help bears get beyond
    superficial first impressions and consider what inner beauty might be lurking
    just below the fur. To perform these image transformations, you’ll use an exciting
    new algorithm called a *neural algorithm of artistic style*, or just *style net*
    for short. What the style-net technique does is transfer the artistic style of
    a given image to the content of another image.
  id: totrans-853
  prefs: []
  type: TYPE_NORMAL
  zh: 在您首次进入深度学习的世界时，您将把用户照片转换成著名画家的风格。这个想法是帮助人们超越肤浅的第一印象，并考虑可能隐藏在皮毛之下的内在美。为了执行这些图像转换，您将使用一种名为“艺术风格神经网络算法”的新颖算法，简称“风格网”。风格网技术是将给定图像的艺术风格转移到另一个图像的内容上。
- en: The open source implementations of the style-net algorithm all rely on various
    deep learning frameworks. Your team has chosen to use an implementation that relies
    on the TensorFlow framework. TensorFlow is powerful machine learning framework
    with particularly good support for deep learning. It was originally developed
    at Google as part of the company’s research on machine learning, and deep learning,
    specifically.
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: 所有开源的style-net算法实现都依赖于各种深度学习框架。你们团队选择使用依赖于TensorFlow框架的实现。TensorFlow是一个强大的机器学习框架，特别支持深度学习。它最初是在谷歌公司作为公司对机器学习和深度学习研究的一部分而开发的。
- en: To install TensorFlow, follow the latest instructions at [www.tensorflow.org](http://www.tensorflow.org).
    Once you’ve installed TensorFlow, you’ll want to clone the implementation of the
    style-net algorithm I’ve provided ([https://github.com/jeffreyksmithjr/neural-art-tf](https://github.com/jeffreyksmithjr/neural-art-tf)).
    It’s an adaptation of an implementation called neural-art-tf ([https://github.com/woodrush/neural-art-tf](https://github.com/woodrush/neural-art-tf))
    with some important changes. If you want to clone both repositories for comparison’s
    sake, you can.
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装TensorFlow，请遵循[www.tensorflow.org](http://www.tensorflow.org)上的最新说明。一旦您安装了TensorFlow，您将想要克隆我提供的style-net算法的实现（[https://github.com/jeffreyksmithjr/neural-art-tf](https://github.com/jeffreyksmithjr/neural-art-tf)）。这是一个名为neural-art-tf的实现（[https://github.com/woodrush/neural-art-tf](https://github.com/woodrush/neural-art-tf)）的改编版本，其中包含一些重要的更改。如果您想为了比较而克隆这两个存储库，您也可以这样做。
- en: To begin learning new models, you first need to download an existing model.
    You’ll use this model as part of the input to learning a new model of a given
    style image—a famous painting, in this case. The approach you’ll use relies on
    a pretrained model from the Visual Geometry Group (VGG) at Oxford. You can download
    this model from [http://mng.bz/iYlL](http://mng.bz/iYlL). You’ll need the .caffemodel
    file, the model itself, and the .prototxt file, which describes the structure
    of the model.
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始学习新的模型，你首先需要下载一个现有模型。你将使用此模型作为学习给定风格图像的新模型的一部分输入——在这种情况下，是一幅著名的画作。你将使用的方法依赖于牛津大学视觉几何组（VGG）的预训练模型。你可以从
    [http://mng.bz/iYlL](http://mng.bz/iYlL) 下载此模型。你需要 .caffemodel 文件，即模型本身，以及 .prototxt
    文件，它描述了模型的架构。
- en: This model, a large, deep model originally intended for use in image recognition,
    is provided in Caffe format. Caffe is another deep learning framework, with different
    strengths and weaknesses than TensorFlow.
  id: totrans-857
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型，一个原本打算用于图像识别的大型深度模型，以 Caffe 格式提供。Caffe 是另一个深度学习框架，与 TensorFlow 有不同的优势和劣势。
- en: To make this model usable by the TensorFlow implementation, you’ll need to use
    a simple conversion utility in the neural-art-tf project.
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
  zh: 要使此模型可通过 TensorFlow 实现，你需要使用 neural-art-tf 项目中的简单转换实用程序。
- en: Listing 5.26\. Converting a Caffe model for TensorFlow
  id: totrans-859
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.26\. 将 Caffe 模型转换为 TensorFlow
- en: '[PRE61]'
  id: totrans-860
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '***1* Converts the model and saves it to a file called vgg**'
  id: totrans-861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 转换模型并将其保存到名为 vgg 的文件中**'
- en: Once you’ve converted the model file, you can begin learning the model of artistic
    style for a given painting to apply to a picture of a bear, using the original
    neural-art-tf implementation. It was originally intended to be used by being called
    as a command-line utility with various arguments for things like the path to the
    model, the file, and the number of iterations. Rather than take those arguments
    from the command line, let’s first move them up to be parameters in a method.
  id: totrans-862
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你转换了模型文件，你就可以开始学习给定绘画的艺术风格模型，并将其应用于熊的图片，使用原始的 neural-art-tf 实现。它最初是打算通过作为具有各种参数的命令行实用程序来使用的，例如模型路径、文件和迭代次数。而不是从命令行获取这些参数，让我们首先将它们提升为方法中的参数。
- en: Listing 5.27\. Method parameters
  id: totrans-863
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.27\. 方法参数
- en: '[PRE62]'
  id: totrans-864
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Then you need to find a way to make this method available to your Scala code.
    Let’s try to turn this simple script to run the code into a service that can be
    called by your primary pipeline. To do that, you’ll use a Python library called
    Pyro. Like most Python libraries, it’s pretty easy to install using `pip`.
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你需要找到一种方法，使这个方法对你的 Scala 代码可用。让我们尝试将这个简单的脚本转换为运行代码的服务，以便你的主管道可以调用它。为此，你将使用一个名为
    Pyro 的 Python 库。像大多数 Python 库一样，使用 `pip` 安装它相当简单。
- en: Listing 5.28\. Installing Pyro
  id: totrans-866
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.28\. 安装 Pyro
- en: '[PRE63]'
  id: totrans-867
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: With Pyro, you can take Python functionality in the scripts in neural-art-tf
    and make it available to clients accessing it via the network.
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Pyro，你可以将 neural-art-tf 脚本中的 Python 功能提供给通过网络访问它的客户端。
- en: Listing 5.29\. Setting up
  id: totrans-869
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.29\. 设置
- en: '[PRE64]'
  id: totrans-870
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '***1* Creates a class to represent your server**'
  id: totrans-871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建一个表示你的服务器类的类**'
- en: '***2* Defines a method to expose to clients**'
  id: totrans-872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 定义一个方法以向客户端公开**'
- en: '***3* Passes arguments to the underlying produce_art method**'
  id: totrans-873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 将参数传递给底层的 produce_art 方法**'
- en: '***4* Returns True as the status once the job has completed**'
  id: totrans-874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 在作业完成后返回 True 作为状态**'
- en: '***5* Sets up the Pyro daemon**'
  id: totrans-875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 设置 Pyro 守护进程**'
- en: '***6* Locates the name server**'
  id: totrans-876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 定位名称服务器**'
- en: '***7* Registers a server class with the Pyro daemon as a Pyro object**'
  id: totrans-877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 将服务器类注册到 Pyro 守护进程作为 Pyro 对象**'
- en: '***8* Registers the Pyro object with the name server**'
  id: totrans-878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 将 Pyro 对象注册到名称服务器**'
- en: '***9* Starts the event loop to wait for calls to the Pyro object**'
  id: totrans-879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 启动事件循环以等待对 Pyro 对象的调用**'
- en: All of [listing 5.29](#ch05ex29) makes it simple for other users of Pyro to
    find and use the method that runs the model-learning jobs. The script will run
    as a *daemon*, a small utility running in the background waiting to serve requests.
    You’ve named it `neuralserver` and attempted to register it with a name server.
    The name server will be responsible for routing requests for this Pyro object
    when it’s asked for by name. For all this to work, you’ll need to start up a Pyro
    name server and then start the revised server script.
  id: totrans-880
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 [列表 5.29](#ch05ex29) 都使得 Pyro 的其他用户可以轻松找到并使用运行模型学习作业的方法。该脚本将作为 *守护进程* 运行，这是一个在后台运行的小型实用程序，等待服务请求。你将其命名为
    `neuralserver` 并尝试将其注册到名称服务器。名称服务器将负责在请求按名称请求此 Pyro 对象时路由请求。为了使所有这些工作，你需要启动 Pyro
    名称服务器，然后启动修改后的服务器脚本。
- en: Listing 5.30\. Starting a name server
  id: totrans-881
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.30\. 启动一个名称服务器
- en: '[PRE65]'
  id: totrans-882
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '***1* Starts a name server**'
  id: totrans-883
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 启动一个名称服务器**'
- en: '***2* Starts a job-running server**'
  id: totrans-884
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 启动一个作业运行服务器**'
- en: Now let’s figure out how to send requests to run jobs from your Scala client
    application to this Python server application. One of the nice features of Pyro
    is that it provides client libraries for use with other runtimes. You can use
    the Java Pyrolite client library in your Scala code ([https://pythonhosted.org/Pyro4/pyrolite.html](https://pythonhosted.org/Pyro4/pyrolite.html)).
    This will allow you to build a facade around the Python code and the problems
    inherent in long-running jobs, using all the same reactive techniques you’ve used
    elsewhere in this book.
  id: totrans-885
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来了解一下如何从你的Scala客户端应用程序向这个Python服务器应用程序发送运行作业的请求。Pyro的一个很好的特性是它为其他运行时提供了客户端库。你可以在Scala代码中使用Java
    Pyrolite客户端库（[https://pythonhosted.org/Pyro4/pyrolite.html](https://pythonhosted.org/Pyro4/pyrolite.html)）。这将允许你围绕Python代码和长期运行作业固有的问题构建一个界面，并使用本书其他地方使用过的所有相同的反应式技术。
- en: To build a more reactive facade, the first thing you can do is ensure more type
    safety around the parameters being passed. For example, the command-line version
    of neural-art-tf uses a bunch of strongly typed arguments for things such as the
    type of model being used. The number of valid model types is tiny compared to
    the huge range of possible strings. In Scala, you can capture those arguments
    that can only take one of a known set of values as an enumeration.
  id: totrans-886
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个更反应灵敏的界面，你可以首先确保传递的参数具有更高的类型安全性。例如，neural-art-tf的命令行版本使用了一组强类型参数，用于指定所使用的模型类型。有效的模型类型数量与可能的字符串范围相比非常小。在Scala中，你可以将只能取已知集合中一个值的参数捕获为枚举。
- en: Listing 5.31\. A model-type enumeration
  id: totrans-887
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.31\. 一个模型类型枚举
- en: '[PRE66]'
  id: totrans-888
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '***1* Creates an Enumeration named ModelType**'
  id: totrans-889
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建一个名为ModelType的枚举**'
- en: '***2* Defines a ModelType value for use in the type system**'
  id: totrans-890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 定义一个用于类型系统的ModelType值**'
- en: '***3* Defines VGG as one valid type of model**'
  id: totrans-891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 定义VGG为一种有效的模型类型**'
- en: '***4* Defines I2V (for Image2Vector) as another type of model**'
  id: totrans-892
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 定义I2V（Image2Vector）为另一种模型类型**'
- en: You can then use type safety to create a better definition of what constitutes
    a valid configuration for your job. Let’s use a case class to encapsulate what
    is a valid job configuration. Moreover, in the following listing, let’s set some
    default values so you don’t have to pass all the knowledge about the job setup
    every time the job is run.
  id: totrans-893
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以使用类型安全性来创建一个更好的定义，以确定你的作业的有效配置。让我们使用案例类来封装有效的作业配置。此外，在下面的列表中，让我们设置一些默认值，这样你就不必每次运行作业时都传递所有关于作业设置的知识。
- en: Listing 5.32\. A job-configuration case class
  id: totrans-894
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.32\. 一个作业配置案例类
- en: '[PRE67]'
  id: totrans-895
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '***1* Path to the content image, user picture**'
  id: totrans-896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 内容图像的路径，用户图片**'
- en: '***2* Path to the style image, famous painting**'
  id: totrans-897
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 风格图像的路径，著名画作**'
- en: '***3* Path to the pretrained model to use**'
  id: totrans-898
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 要使用的预训练模型的路径**'
- en: '***4* Type of pretrained model**'
  id: totrans-899
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 预训练模型的类型**'
- en: '***5* Width of the resulting image, defaulting to 800 pixels**'
  id: totrans-900
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 结果图像的宽度，默认为800像素**'
- en: '***6* Alpha parameter, for weight of content, defaulting to 1.0**'
  id: totrans-901
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* Alpha参数，用于内容权重，默认为1.0**'
- en: '***7* Beta parameter, for weight of style, defaulting to 200.0**'
  id: totrans-902
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* Beta参数，用于风格权重，默认为200.0**'
- en: '***8* Number of iterations to learn the model over, defaulting to 5000**'
  id: totrans-903
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 学习模型所需的迭代次数，默认为5000**'
- en: Note that because the Pyrolite client library is a Java library, your case class
    needs to use Java types for doubles and integers. But beyond specifying that in
    the case-class type signatures, there’s nothing else you need to do; Scala will
    automatically perform the conversions from Scala types to the underlying Java
    types.
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于Pyrolite客户端库是一个Java库，你的案例类需要使用Java类型来表示双精度和整数。但除了在案例类类型签名中指定这一点之外，你不需要做任何事情；Scala将自动执行从Scala类型到底层Java类型的转换。
- en: Using this configuration case class makes it easier for you to ensure that your
    configurations are valid. With a valid configuration, such as the one in the next
    listing, you can submit your job with more confidence that the arguments are sufficient
    for the Python-server application.
  id: totrans-905
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种配置案例类，你可以更容易地确保你的配置是有效的。有了有效的配置，例如下述列表中的配置，你可以更有信心地提交你的作业，因为参数对于Python服务器应用程序来说是足够的。
- en: Listing 5.33\. A job configuration
  id: totrans-906
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.33\. 一个作业配置
- en: '[PRE68]'
  id: totrans-907
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '***1* Creates a configuration with content image of an attractive sloth bear**'
  id: totrans-908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建一个包含吸引人的树懒图像的内容图像配置**'
- en: '***2* Sets the style image to a famous painting**'
  id: totrans-909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将风格图像设置为著名画作**'
- en: '***3* Model file**'
  id: totrans-910
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 模型文件**'
- en: '***4* Type-safe model type**'
  id: totrans-911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 类型安全的模型类型**'
- en: '***5* Overrides the number of iterations**'
  id: totrans-912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 覆盖迭代次数**'
- en: Then locate the name server and connect to the Pyro object for your job server.
    In this example, you’re only using the networking capabilities of Pyro to give
    you a way of communicating between your Python program and your Scala program,
    so you won’t need to deal with any networking complexity, although the process
    would be similar in a distributed implementation.
  id: totrans-913
  prefs: []
  type: TYPE_NORMAL
  zh: 然后定位名称服务器并连接到你的作业服务器的 Pyro 对象。在这个例子中，你只使用 Pyro 的网络功能，以便在 Python 程序和 Scala 程序之间进行通信，因此你不需要处理任何网络复杂性，尽管在分布式实现中这个过程将是相似的。
- en: Listing 5.34\. Connecting to the server
  id: totrans-914
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.34\. 连接到服务器
- en: '[PRE69]'
  id: totrans-915
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '***1* Finds the name server on the same machine, passing in a null host**'
  id: totrans-916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 在同一台机器上查找名称服务器，传入一个空主机**'
- en: '***2* Looks up the Pyro object by its name, neuralserver**'
  id: totrans-917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 通过名称查找 Pyro 对象，neuralserver**'
- en: Now, you can send your configuration off to be processed—but let’s think through
    what that means first. That request is to a separate running process, and it could
    have just as easily been a separate process on another machine. The job might
    take quite a while to run. Deep learning techniques are famous for requiring very
    powerful hardware and taking a long time to execute. If you really want your application
    to be reactive, you should implement some sort of timeout. The duration of that
    timeout should be based on your expectation of the normal runtime of the model-learning
    algorithm. In the example in [listing 5.35](#ch05ex35), I’ve arbitrarily chosen
    one hour. With a timeout in place, you can detect whether the model-learning process
    has taken too long and should be treated as a failure.
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以将你的配置发送出去进行处理——但首先让我们思考一下这意味着什么。这个请求是针对一个独立运行的过程，它同样可能是在另一台机器上的一个独立过程。这个任务可能需要相当长的时间才能运行完成。深度学习技术因其需要非常强大的硬件和执行时间较长而闻名。如果你真的想让你的应用程序具有反应性，你应该实现某种超时机制。这个超时时间的长度应该基于你对模型学习算法正常运行时间的预期。在[列表
    5.35](#ch05ex35)的例子中，我任意选择了一个小时。有了超时机制，你可以检测模型学习过程是否耗时过长，并应该被视为失败。
- en: Listing 5.35\. Using a timeout
  id: totrans-919
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.35\. 使用超时
- en: '[PRE70]'
  id: totrans-920
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '***1* Sets up a one-hour timeout in milliseconds**'
  id: totrans-921
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 设置一个一小时的超时（以毫秒为单位**）'
- en: '***2* Creates a timeout future**'
  id: totrans-922
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 创建一个超时未来**'
- en: '***3* Returns a false value to indicate failure to complete in time**'
  id: totrans-923
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 返回一个 false 值以指示未能及时完成**'
- en: '***4* Creates a function to wrap calling of the Python server application**'
  id: totrans-924
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 创建一个函数来包装调用 Python 服务器应用程序**'
- en: '***5* Sets a timeout as the first future completed of the two**'
  id: totrans-925
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 将超时设置为两个未来中先完成的第一个**'
- en: '***6* The timeout future**'
  id: totrans-926
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 超时未来**'
- en: '***7* Sets up a future to call the method on the Pyro object**'
  id: totrans-927
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 设置一个未来来调用 Pyro 对象上的方法**'
- en: '***8* Casts the resulting value to a Boolean**'
  id: totrans-928
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 将结果值转换为 Boolean**'
- en: Because you’re dealing with a Python program on the other end of this call,
    you don’t get any type guarantees about what it’s going to send back, so you’ll
    need to typecast the return value to a `Boolean`. Because the model-learning process
    is going to occur in an entirely separate process, this Scala program will only
    ever know if that Python program sends back a true value to say that it’s been
    successful. Given that limited knowledge, this timeout mechanism prevents your
    Scala application from waiting forever in the event that something has gone wrong
    with the model-learning process.
  id: totrans-929
  prefs: []
  type: TYPE_NORMAL
  zh: 因为你在处理这个调用另一端的 Python 程序，你无法获得任何关于它将返回什么类型的保证，所以你需要将返回值类型转换为 `Boolean`。由于模型学习过程将在一个完全独立的进程中发生，这个
    Scala 程序将只会知道那个 Python 程序是否返回一个 true 值来表示它已经成功。考虑到这种有限的知识，这个超时机制防止了 Scala 应用程序在模型学习过程出现问题时永远等待。
- en: 'Finally, you can call this function:'
  id: totrans-930
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以调用这个函数：
- en: '[PRE71]'
  id: totrans-931
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '***1* Invokes the server-calling function with a sample configuration**'
  id: totrans-932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 使用样本配置调用服务器调用函数**'
- en: '![](containment.jpg)'
  id: totrans-933
  prefs: []
  type: TYPE_IMG
  zh: '![](containment.jpg)'
- en: The value in `result` is a `Future` of a `Boolean`, so you can then integrate
    the value of the future when it’s completed, with the rest of your reactive Scala
    application. All the details of how the Python implementation works are abstracted
    down to a small interface. The Scala pipeline code understands what valid job
    configurations are and how long they should take. Should any errors occur in the
    execution of the TensorFlow implementation of the style-net algorithm, the Scala
    application will detect them using a timeout and react accordingly. Those errors
    in the model-learning process will be fully contained with an entirely separate
    process. Any errors in the Python application can’t propagate back to the facade
    or any of its consumers.
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: '`result`中的值是一个`Boolean`的`Future`，因此你可以将未来的值在完成时与其他的响应式Scala应用程序集成。Python实现的详细工作原理都被抽象成一个小的接口。Scala管道代码理解有效的作业配置以及它们应该花费多长时间。如果在TensorFlow实现style-net算法的执行过程中发生任何错误，Scala应用程序将使用超时检测它们并相应地做出反应。模型学习过程中的这些错误将被完全包含在一个完全独立的进程中。Python应用程序中的任何错误都不能传播回门面或其消费者。'
- en: 5.4\. Reactivities
  id: totrans-935
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4. 反应性
- en: '![](dog-ball.jpg)'
  id: totrans-936
  prefs: []
  type: TYPE_IMG
  zh: '![狗球](dog-ball.jpg)'
- en: '*Implement a model-learning algorithm*. Machine learning textbooks often have
    detailed descriptions of various learning algorithms that you can use, in either
    pseudocode or some other language. For example, many decision-tree-based algorithms
    can be quite simple to implement. Once you have a rudimentary implementation in
    place, you can start to think about how reactive your implementation is or could
    be. Will your learning algorithm always complete within a given time? If not,
    how could you change that?'
  id: totrans-937
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实现一个模型学习算法*。机器学习教科书通常会详细描述各种你可以使用的学习算法，无论是伪代码还是其他语言。例如，许多基于决策树的算法实现起来相当简单。一旦你有了基本的实现，你就可以开始思考你的实现如何反应或可能如何反应。你的学习算法是否总是能在给定时间内完成？如果不是，你该如何改变这一点？'
- en: '*Dive deeper into building facades*. You built a simple facade for a machine
    learning algorithm in this chapter. In particular, you used a Python model-learning
    algorithm from an otherwise Scala codebase. That’s a pretty common real-world
    scenario. Lots of development on machine learning technologies occurs using Python.
    One of the most powerful technologies you can use for building machine learning
    models is TensorFlow, from Google. Although large portions of it are written in
    C++, the primary user API is written in Python. Because TensorFlow is so popular,
    many people have attempted to implement different ways of calling it from Scala.
    Examine one of the several libraries that allow you to access TensorFlow from
    Scala. Some of these may be focused on Spark specifically. Notable examples include
    TensorFlowOnSpark from Yahoo!, TensorFrames from Databricks, and MLeap. When you
    look into these implementations, ask yourself what guarantees hold about the behavior
    of the model-learning implementation. How does the use of multilanguage runtimes
    change what you can say confidently about the behavior of a model-learning pipeline
    written using one of these tools? Can you write a test that proves something about
    the library’s response to errors or high load?'
  id: totrans-938
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深入构建门面*。在本章中，你为机器学习算法构建了一个简单的门面。特别是，你使用了一个来自Scala代码库的Python模型学习算法。这是一个相当常见的现实世界场景。许多机器学习技术的开发都是使用Python进行的。你可以用来构建机器学习模型的最强大的技术之一是来自Google的TensorFlow。尽管它的大部分是用C++编写的，但主要的用户API是用Python编写的。由于TensorFlow非常受欢迎，许多人已经尝试了从Scala调用它的不同方法。检查允许你从Scala访问TensorFlow的几个库之一。其中一些可能专注于Spark。值得注意的例子包括Yahoo!的TensorFlowOnSpark、Databricks的TensorFrames和MLeap。当你研究这些实现时，问问自己关于模型学习实现的行为有哪些保证。使用多语言运行时如何改变你对使用这些工具之一编写的模型学习管道行为的信心？你能编写一个测试来证明关于库对错误或高负载响应的某些事情吗？'
- en: If you’re interested in learning more about TensorFlow specifically, check out
    *Machine Learning with TensorFlow* by Nishant Shukla (Manning, 2018) for a much
    deeper look into that technology ([www.manning.com/books/machine-learning-with-tensorflow](http://www.manning.com/books/machine-learning-with-tensorflow)).
  id: totrans-939
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要更深入地了解TensorFlow，可以查看Nishant Shukla（Manning，2018）所著的《Machine Learning with
    TensorFlow》（[www.manning.com/books/machine-learning-with-tensorflow](http://www.manning.com/books/machine-learning-with-tensorflow)）。
- en: Summary
  id: totrans-940
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: A model is a program that can make predictions about the future.
  id: totrans-941
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是一个可以预测未来的程序。
- en: Model learning consists of processing features and returning a model.
  id: totrans-942
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型学习包括处理特征并返回一个模型。
- en: Model learning must be implemented with an expectation of failure modes (for
    example, timeouts).
  id: totrans-943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型学习必须实施时考虑到失败模式（例如，超时）。
- en: Containment, using the facade pattern, is a crucial technique for integrating
    third-party code.
  id: totrans-944
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用外观模式进行封装是集成第三方代码的关键技术。
- en: Contained code wrapped in a facade can be integrated with the rest of your data
    pipeline using standard reactive-programming techniques.
  id: totrans-945
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 封装在外观中的代码可以使用标准的响应式编程技术集成到你的数据管道中。
- en: In the next chapter, we’ll take the models you’ve learned and analyze their
    performance so you can decide whether to use them.
  id: totrans-946
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将分析你学到的模型，以了解它们的性能，这样你可以决定是否使用它们。
- en: Chapter 6\. Evaluating models
  id: totrans-947
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第6章. 评估模型
- en: '*This chapter covers*'
  id: totrans-948
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Calculating model metrics
  id: totrans-949
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算模型指标
- en: Training versus testing data
  id: totrans-950
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据与测试数据
- en: Recording model metrics as messages
  id: totrans-951
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型指标记录为消息
- en: We’re over halfway done with our exploration of the phases of a machine learning
    system ([figure 6.1](#ch06fig01)). In this chapter, we’ll consider how to evaluate
    models. In the context of a machine learning system, to *evaluate* a model means
    to consider its performance before making it available for use in predictions.
    In this chapter, we’re going to ask a lot of questions about models.
  id: totrans-952
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了对机器学习系统阶段探索的一半以上（[图6.1](#ch06fig01)）。在本章中，我们将考虑如何评估模型。在机器学习系统的背景下，*评估*一个模型意味着在将其用于预测之前考虑其性能。在本章中，我们将对模型提出许多问题。
- en: Figure 6.1\. Phases of machine learning
  id: totrans-953
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.1. 机器学习阶段
- en: '![](06fig01.jpg)'
  id: totrans-954
  prefs: []
  type: TYPE_IMG
  zh: '![06fig01.jpg](06fig01.jpg)'
- en: '![](uncertain-data.jpg)'
  id: totrans-955
  prefs: []
  type: TYPE_IMG
  zh: '![不确定数据](uncertain-data.jpg)'
- en: Much of the work of evaluating models may not sound that necessary. If you’re
    in a hurry to build a prototype system, you might try to get by with something
    quite crude. But there’s real value in understanding the output of the upstream
    components of your machine learning system before you use that output. The data
    in a machine learning system is intrinsically and pervasively uncertain.
  id: totrans-956
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型的大部分工作可能听起来并不那么必要。如果你急于构建原型系统，你可能试图用一些相当粗糙的东西应付过去。但在使用输出之前理解你的机器学习系统上游组件的输出确实具有实际价值。机器学习系统中的数据本质上是不确定的，并且普遍存在。
- en: When you contemplate whether you want to use a model to make predictions, you
    face that uncertainty head on. There are no answers to look up from somewhere
    else. You need to implement the components of your system such that they make
    the right decisions—or suffer the consequences.
  id: totrans-957
  prefs: []
  type: TYPE_NORMAL
  zh: 当你考虑是否想使用模型进行预测时，你必须直面这种不确定性。没有其他地方可以查找答案。你需要实现你的系统组件，以便它们做出正确的决定——或者承担后果。
- en: 'Using machine-learned models can be high-stakes stuff. Machine learning systems
    are used to handle decisions of real consequence where failure could mean real
    losses to their users. We’re going to consider just such a problem, one with some
    very concrete financial consequences for success or failure: fraud detection.'
  id: totrans-958
  prefs: []
  type: TYPE_NORMAL
  zh: 使用机器学习模型可能是一项高风险的任务。机器学习系统被用于处理具有实际后果的决策，失败可能意味着用户会遭受实际损失。我们将考虑这样一个问题，一个成功或失败具有非常具体财务后果的问题：欺诈检测。
- en: 6.1\. Detecting fraud
  id: totrans-959
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1. 欺诈检测
- en: Kangaroo Kapital is the largest credit card company in Australia. Animals across
    the continent use Kangaroo Kapital credit cards to make all their daily purchases,
    racking up points in the company’s reward system. Because Australian animals have
    traditionally not worn much clothing, the challenges of carrying around cash are
    substantial. Only having to keep track of a single credit card is a big help for
    your average working wallaby; nevertheless, Australian animals have problems keeping
    track of even a single credit card. Cards are often misplaced, leading to a problem
    with theft and fraudulent use.
  id: totrans-960
  prefs: []
  type: TYPE_NORMAL
  zh: Kangaroo Kapital是澳大利亚最大的信用卡公司。整个大陆的动物都使用Kangaroo Kapital信用卡进行日常购物，为公司奖励系统积累积分。由于澳大利亚动物传统上穿得很少，携带现金的挑战很大。只需跟踪一张信用卡对普通工作袋鼠来说已经是一个很大的帮助；然而，澳大利亚动物在跟踪一张信用卡时仍然会遇到问题。卡片经常丢失，导致盗窃和欺诈使用的问题。
- en: The fraud team at Kangaroo Kapital is charged with detecting these cases of
    fraud. They use sophisticated analytical techniques to try to determine when a
    customer’s card has been stolen. If they can determine with sufficient confidence
    that a card has been stolen, they lock down the card and contact the customer.
    The benefits of being fast *and* correct are substantial. In the best-case scenario,
    the fraud team’s systems detect fraud the first time a card is misused, lock down
    the card, and then suffer no further losses ([figure 6.2](#ch06fig02)).
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: Kangaroo Kapital的欺诈团队负责检测这些欺诈案例。他们使用复杂的分析技术来尝试确定客户的卡片何时被盗。如果他们能够有足够的信心确定一张卡片被盗，他们就会锁定这张卡片并联系客户。快速且正确的好处是巨大的。在最佳情况下，欺诈团队的系统在卡片第一次被滥用时检测到欺诈，锁定卡片，然后不再遭受进一步的损失（[图6.2](#ch06fig02)）。
- en: Figure 6.2\. Successful fraud detection
  id: totrans-962
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.2\. 成功检测欺诈
- en: '![](06fig02.jpg)'
  id: totrans-963
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig02.jpg)'
- en: But if the system is too slow, the company eats the cost of those fraudulent
    transactions, not the customer. That can get expensive, because no one loves to
    spend quite like a duck-billed platypus with a stolen credit card ([figure 6.3](#ch06fig03)).
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果系统太慢，公司会承担那些欺诈交易的成本，而不是客户。这可能会变得很昂贵，因为没有人愿意像偷了信用卡的鸭嘴兽那样花钱（[图6.3](#ch06fig03)）。
- en: Figure 6.3\. Failing to detect fraud
  id: totrans-965
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.3\. 未检测到欺诈
- en: '![](06fig03.jpg)'
  id: totrans-966
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig03.jpg)'
- en: Being too eager can also be bad for the company. If the team is wrong, then
    they’ve locked down a card that a customer is attempting to use, greatly inconveniencing
    them. A Tasmanian devil who can’t pay his dinner bill due to a declined credit
    card is one unhappy customer. He’s likely to cancel his credit card, which would
    also lead to lost money for the company ([figure 6.4](#ch06fig04)).
  id: totrans-967
  prefs: []
  type: TYPE_NORMAL
  zh: 过于急切也可能对公司造成不利。如果团队判断错误，那么他们可能已经锁定了一张客户正在尝试使用的卡片，这给客户带来了极大的不便。一个因为信用卡被拒绝而无法支付晚餐账单的塔斯马尼亚魔鬼将是一个不快乐的客户。他可能会取消他的信用卡，这也会导致公司损失金钱（[图6.4](#ch06fig04)）。
- en: Figure 6.4\. Inaccurately detecting fraud
  id: totrans-968
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.4\. 错误检测欺诈
- en: '![](06fig04.jpg)'
  id: totrans-969
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig04.jpg)'
- en: This trade-off is often discussed in machine learning contexts using various
    metrics that can be calculated for a given model. Much of this chapter focuses
    on different model metrics, because metrics are a key part of how real-world machine
    learning systems are operated.
  id: totrans-970
  prefs: []
  type: TYPE_NORMAL
  zh: 这种权衡在机器学习环境中经常被讨论，使用各种可以针对给定模型计算的指标。本章的大部分内容都集中在不同的模型指标上，因为指标是现实世界机器学习系统操作的关键部分。
- en: 6.2\. Holding out data
  id: totrans-971
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 保留数据
- en: To understand model metrics for evaluating your models, you need to start by
    using some data that’s different than you’ve ever used before. In previous chapters,
    you saw how to collect and use data to train a machine learning model. But you
    typically don’t use all the data you’ve collected just for training the model.
    Instead, you usually leave some data aside for other purposes. That data is called
    *hold-out data*, meaning it wasn’t included in the data used to learn the model.
    Depending on what you’re trying to do with your machine learning system, you might
    do several different things with that held-out data, but usually you’ll need it
    for something.
  id: totrans-972
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解用于评估模型的模型指标，你需要从使用一些不同于你以前使用过的数据开始。在之前的章节中，你看到了如何收集和使用数据来训练机器学习模型。但通常你不会使用你收集的所有数据来仅用于训练模型。相反，你通常将一些数据留出用于其他目的。这些数据被称为*保留数据*，意味着它没有被包括在用于学习模型的数据中。根据你试图用你的机器学习系统做什么，你可能会对保留数据做几件不同的事情，但通常你需要它用于某些目的。
- en: There are big dangers in deciding which data to hold out and which data to use
    to learn your model. If you’re not careful about how you handle your data *at
    the system level*, you may find that your models will do terrible things when
    used to make live predictions in your production system. The ’roos at Kangaroo
    Kapital are a pretty conservative bunch, so they’ve tried to safely use hold-out
    data as much as possible. Their approach relies on a global concept of what is
    hold-out data and what is training data.
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定保留哪些数据以及使用哪些数据来学习模型时，存在很大的风险。如果你在系统层面上不仔细处理你的数据，你可能会发现，当你的模型在生产系统中用于实时预测时，会做出可怕的事情。Kangaroo
    Kapital的“袋鼠”们是一个非常保守的群体，所以他们尽可能地安全地使用保留数据。他们的方法依赖于一个全球性的概念，即什么是保留数据，什么是训练数据。
- en: To understand the Kangaroo Kapital implementation, let’s first set up a basic
    version of the domain model for the credit card–processing systems. The following
    listing shows some of the basics you’ll need to build code that could handle credit
    card transactions.
  id: totrans-974
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解 Kangaroo Kapital 的实现，我们首先为信用卡处理系统设置一个基本版本的领域模型。以下列表显示了构建可以处理信用卡交易代码所需的一些基础知识。
- en: Listing 6.1\. Credit card transactions utils
  id: totrans-975
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.1\. 信用卡交易工具
- en: '[PRE72]'
  id: totrans-976
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '***1* Type alias for a transaction identifier**'
  id: totrans-977
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 事务标识符的类型别名**'
- en: '***2* Type alias for a customer identifier**'
  id: totrans-978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 客户标识符的类型别名**'
- en: '***3* Type alias for a merchant identifier**'
  id: totrans-979
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 商家标识符的类型别名**'
- en: '***4* Case class for a transaction**'
  id: totrans-980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 事务的案例类**'
- en: '|  |'
  id: totrans-981
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Type aliases**'
  id: totrans-982
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型别名**'
- en: The identifiers of transactions, customers, and merchants are typed using *type
    aliases*. We haven’t used them before, but type aliases are simple utilities.
    They allow you to define arbitrary numeric identifiers using meaningful names
    for their types, without changing any of the underlying properties of the base
    type. A `CustomerId` is just a `Long`. You can perform all the same operations
    on a `CustomerId` that you can on a `Long`. But you can implement your code to
    describe when a given `Long` is in fact the identifier for a customer versus the
    identifier for a merchant. Being able to assign these descriptive types is often
    helpful for building up richer descriptions of the problem domain using types,
    as shown in [listing 6.1](#ch06ex01).
  id: totrans-983
  prefs: []
  type: TYPE_NORMAL
  zh: 事务、客户和商家的标识符使用 *类型别名* 进行类型化。我们之前没有使用过它们，但类型别名是简单的实用工具。它们允许你使用有意义的名称来定义任意数值标识符，而不改变任何基础类型的底层属性。`CustomerId`
    只是一个 `Long`。你可以在 `CustomerId` 上执行与在 `Long` 上相同的所有操作。但你可以实现你的代码来描述给定 `Long` 实际上是客户标识符还是商家标识符。能够分配这些描述性类型通常有助于使用类型构建更丰富的领域描述，如[列表6.1](#ch06ex01)所示。
- en: '|  |'
  id: totrans-984
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Using the basic domain model established in [listing 6.1](#ch06ex01), you can
    now implement your version of the code to split out training data from hold-out
    data. The implementation applies a deterministic hashing function, based on a
    stable identifier (the customer’s account number). All transactions for a given
    customer are always in either the training data or the held-out data. In less
    data-rich systems, that may not be the right approach. An alternative would be
    to split transactions between training data and held-out data. But Kangaroo Kapital
    has enormous market share in Australia, so splitting by customers is an acceptable
    choice for them.
  id: totrans-985
  prefs: []
  type: TYPE_NORMAL
  zh: 使用在[列表6.1](#ch06ex01)中建立的基领域模型，你现在可以实施你的代码版本，以从保留数据中分离出训练数据。该实现应用了一个基于稳定标识符（客户的账户号码）的确定性哈希函数。给定客户的全部交易总是位于训练数据或保留数据中。在数据较少的系统上，这可能不是正确的方法。一个替代方案是在训练数据和保留数据之间分割交易。但
    Kangaroo Kapital 在澳大利亚拥有巨大的市场份额，因此按客户分割对他们来说是一个可接受的选择。
- en: The next listing shows how a given transaction is assigned to either the training
    data or the held-out data.
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表显示了给定事务是如何分配到训练数据或保留数据的。
- en: Listing 6.2\. Assigning customers to the training set
  id: totrans-987
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.2\. 将客户分配到训练集
- en: '[PRE73]'
  id: totrans-988
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '***1* Percentage of customers to assign to training sets**'
  id: totrans-989
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 分配到训练集的客户百分比**'
- en: '***2* Function to determine whether a customer should be used in a training
    set**'
  id: totrans-990
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 确定客户是否应用于训练集的函数**'
- en: '***3* Uses the modulo 100 value of a hash value of a customer ID to produce
    a hash value**'
  id: totrans-991
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 使用客户ID的哈希值的100取模值来生成哈希值**'
- en: '***4* Compares the hash value for a customer with a constant percent**'
  id: totrans-992
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 将客户的哈希值与一个常数百分比进行比较**'
- en: '***5* Sample transaction to use for testing**'
  id: totrans-993
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 用于测试的示例事务**'
- en: '***6* Resulting dataset for the sample transaction**'
  id: totrans-994
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 样例事务的结果数据集**'
- en: '***7* Prints the results for inspection**'
  id: totrans-995
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 打印结果以供检查**'
- en: The `trainingCustomer` function could be implemented in several different places.
    At the moment, you’re concerned with transactions, so you could implement it on
    the `Transaction` class. Because it’s information about a customer, you could
    put it on the `Customer` class that presumably exists somewhere (but that you
    haven’t implemented). But `trainingCustomer` is a pure function that could be
    widely used across the system.
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: '`trainingCustomer` 函数可以在几个不同的地方实现。目前，你关注的是交易，因此你可以在 `Transaction` 类上实现它。因为这是关于客户的信息，你可以将其放在可能存在于某处（但你尚未实现）的
    `Customer` 类上。但 `trainingCustomer` 是一个纯函数，可以在整个系统中广泛使用。'
- en: The type signature ensures that it will only ever operate on customer IDs, as
    you intend, so let’s leave it on a utility object and allow consumers to import
    it as needed. If you have experience with object-oriented programming, that might
    strike you as bad style. But Scala unites both the object-oriented and functional
    programming paradigms, so this is entirely acceptable in Scala. In functional
    programming–style code, it’s not uncommon to have “bags of functions,” where an
    object may be a container for some functions that might all be used independently
    of each other. The object merely serves as a *namespace*—an identifier used for
    organizing code. This is in contrast to traditional object-oriented programming,
    which creates objects that are strongly cohesive units meant to be used as a whole.
  id: totrans-997
  prefs: []
  type: TYPE_NORMAL
  zh: 类型签名确保它将始终仅操作于客户ID，正如你的意图，所以让我们将其保留在工具对象上，并允许消费者按需导入。如果你有面向对象编程的经验，这可能会让你觉得这是一种不好的风格。但Scala结合了面向对象和函数式编程范式，所以在Scala中这是完全可以接受的。在函数式编程风格的代码中，拥有“函数包”并不罕见，其中对象可能是一些函数的容器，这些函数可能彼此独立使用。对象仅仅作为一个*命名空间*——用于组织代码的标识符。这与传统的面向对象编程形成对比，后者创建的是强内聚单元的对象，旨在整体使用。
- en: '![](pure-functions.jpg)'
  id: totrans-998
  prefs: []
  type: TYPE_IMG
  zh: '![](pure-functions.jpg)'
- en: Because your hashing function holds to certain properties, there’s no harm in
    allowing the function to be passed around throughout your codebase. It’s clearly
    *pure*, meaning it causes no side effects. The function is also *referentially
    transparent*, meaning it will always return the same value when called with the
    same argument. That’s an important property of mathematical functions that your
    functions must hold to. When you can structure your code as pure, referentially
    transparent functions, that can make code reuse quite easy and natural, as you
    can see with your hashing function.
  id: totrans-999
  prefs: []
  type: TYPE_NORMAL
  zh: 因为你的哈希函数遵循某些属性，允许函数在代码库中传递是没有害处的。它显然是*纯函数*，意味着它不会产生副作用。该函数也是*引用透明*的，意味着当用相同的参数调用时，它将始终返回相同的值。这是数学函数的一个重要属性，你的函数必须遵守。当你能够以纯、引用透明的函数结构化代码时，这可以使代码重用变得非常容易和自然，正如你可以从你的哈希函数中看到的那样。
- en: Note that your hashing function is implemented in such a way as to randomly
    assign instances to training or testing according to the proportions set by the
    training-proportion parameter. This strategy for splitting up the training and
    testing datasets avoids various common data-preparation problems that can result
    in poorly performing models.
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你的哈希函数是以一种方式实现的，它会根据训练比例参数设定的比例随机将实例分配到训练集或测试集。这种分割训练集和测试集的策略避免了可能导致模型性能不佳的各种常见数据准备问题。
- en: 6.3\. Model metrics
  id: totrans-1001
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3. 模型度量
- en: Now that you have the ability to divide up the data, you can use some of it
    to train your model and the rest to test or evaluate any learned models. You’ve
    already seen how models can be trained in [chapter 5](kindle_split_016.html#ch05).
    [Listing 6.3](#ch06ex03) recaps that model-learning process, again using Spark’s
    MLlib. You’ll start without using much new functionality from MLlib. Instead,
    you’ll focus on how the model-learning process from [chapter 5](kindle_split_016.html#ch05)
    connects to the work at hand. In this example, you’ll learn a binary classification
    model using logistic regression.
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了划分数据的能力，你可以用其中一部分来训练你的模型，其余的用于测试或评估任何学习到的模型。你已经看到了如何在第5章中训练模型。[列表6.3](#ch06ex03)回顾了该模型学习过程，再次使用Spark的MLlib。你将开始时不使用MLlib的新功能。相反，你将专注于第5章中描述的模型学习过程如何与当前的工作相关联。在这个例子中，你将使用逻辑回归学习一个二元分类模型。
- en: '|  |'
  id: totrans-1003
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Logistic regression**'
  id: totrans-1004
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑回归**'
- en: Although you haven’t seen it before in this book, *logistic regression* is a
    common model-learning algorithm. It’s a regression model used to predict categorical
    variables (for example, fraudulent versus nonfraudulent credit card charges).
    A deeper discussion of the details of the algorithm is beyond the scope of this
    book, but as usual, Wikipedia has a good introduction ([https://en.wikipedia.org/wiki/Logistic_regression](https://en.wikipedia.org/wiki/Logistic_regression)).
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你在这本书中没有见过它，但*逻辑回归*是一种常见的模型学习算法。它是一种回归模型，用于预测分类变量（例如，欺诈与非欺诈信用卡交易）。对算法细节的深入讨论超出了本书的范围，但像往常一样，维基百科有一个很好的介绍([https://en.wikipedia.org/wiki/Logistic_regression](https://en.wikipedia.org/wiki/Logistic_regression))。
- en: 'When it comes to building machine learning systems, logistic regression has
    several advantages: it’s widely implemented, there are efficient distributed implementations,
    the model size scales linearly with the number of features, the importance of
    features on the model is easily analyzable, and so on. In this case, using logistic
    regression allows you to use even more library functionality from MLlib to evaluate
    your learned model than is available for less popular or more sophisticated model-learning
    algorithms.'
  id: totrans-1006
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到构建机器学习系统时，逻辑回归有几个优点：它被广泛实现，有高效的分布式实现，模型大小与特征数量成线性比例，模型中特征的重要性易于分析，等等。在这种情况下，使用逻辑回归允许你使用比不流行的或更复杂的模型学习算法更多的
    MLlib 库功能来评估你的学习模型。
- en: '|  |'
  id: totrans-1007
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Listing 6.3\. Learning a model
  id: totrans-1008
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.3\. 学习一个模型
- en: '[PRE74]'
  id: totrans-1009
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '***1* Creates a new session**'
  id: totrans-1010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建一个新的会话**'
- en: '***2* Imports some useful implicit conversions for use with DataFrames**'
  id: totrans-1011
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 导入一些用于与 DataFrames 一起使用的有用隐式转换**'
- en: '***3* Loads some sample data, stored in LIBSVM format**'
  id: totrans-1012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 加载一些存储在 LIBSVM 格式的示例数据**'
- en: '***4* Randomly splits sample data into training and testing sets**'
  id: totrans-1013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 随机将样本数据分割成训练集和测试集**'
- en: '***5* Instantiates a new instance of a logistic-regression classifier**'
  id: totrans-1014
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 实例化一个新的逻辑回归分类器**'
- en: '***6* Learns a model over a training set**'
  id: totrans-1015
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 在训练集上学习一个模型**'
- en: '***7* Prints the parameters of the model for inspection**'
  id: totrans-1016
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 打印模型的参数以供检查**'
- en: In this case, you’ll use some standard sample data to stand in for the Kangaroo
    Kapital credit card data. You can refactor this code later to ingest from your
    statically typed transactional data. With this sample data, you can get the basics
    of your training and testing process set up quickly. Note that you’re also using
    a less sophisticated method of splitting the data between training and testing
    than you did before. Again, this is just to give you a simple but runnable prototype
    that you can refactor to use the credit card data later. Both the sample data
    and the random train/test splitting function are provided by the Spark project
    to make it easier to get started building models.
  id: totrans-1017
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你将使用一些标准样本数据来代替 Kangaroo Kapital 信用卡数据。你可以稍后重构此代码以从你的静态类型事务数据中获取数据。使用这些样本数据，你可以快速设置你的训练和测试过程的基本设置。请注意，你也在使用比之前更简单的方法来分割训练和测试数据。再次强调，这只是为了给你一个简单但可运行的原型，你可以重构它以使用信用卡数据。样本数据和随机训练/测试分割函数都由
    Spark 项目提供，以简化开始构建模型的过程。
- en: At the end of [listing 6.3](#ch06ex03), you produced an instance of a `LogisticRegressionModel`.
    You can now use some library functionality to inspect and reason about your model.
    At this point in the process, you have absolutely no idea what your model is like.
    The outcome of the model-learning process is by definition uncertain—you could
    have a very useful model or complete garbage.
  id: totrans-1018
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [列表 6.3](#ch06ex03) 的末尾，你创建了一个 `LogisticRegressionModel` 的实例。现在你可以使用一些库功能来检查和推理你的模型。在这个处理阶段，你绝对不知道你的模型是什么样的。模型学习过程的结果在定义上是不可确定的——你可能有一个非常有用的模型，或者完全是垃圾。
- en: First, we can understand some of the metrics that can be computed about the
    model’s performance on the training set, but to do that, we need to cover how
    to measure the performance of a classifier. Reviewing a bit from [chapter 5](kindle_split_016.html#ch05),
    in binary classification problems, we often refer to the two classes as *positive*
    and *negative*. In the case of Kangaroo Kapital, the positive case would be that
    fraud had occurred, and the negative case would be that no fraud had occurred.
    A given classifier can then be scored on its performance within those classes.
    This is true whether the classifier is a machine-learned model, a dingo making
    decisions based on smell, or just a flip of an Australian one-dollar coin. Conventional
    terminology calls correct predictions *true* and incorrect predictions *false*.
    Putting all this together yields the two-by-two matrix shown in [figure 6.5](#ch06fig05),
    known as a *confusion matrix*.
  id: totrans-1019
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以了解一些可以计算关于模型在训练集上性能的指标，但要做到这一点，我们需要了解如何衡量分类器的性能。回顾一下 [第 5 章](kindle_split_016.html#ch05)，在二元分类问题中，我们通常将两个类别称为
    *正* 和 *负*。在 Kangaroo Kapital 的例子中，正例是欺诈发生，负例是没有欺诈发生。然后，给定的分类器可以在这些类别中的性能上进行评分。这适用于分类器是一个基于嗅觉做出决策的野狗，或者只是一个澳大利亚一元硬币的翻转。传统术语将正确的预测称为
    *真*，错误的预测称为 *假*。将这些放在一起，就得到了 [图 6.5](#ch06fig05) 中所示的二维矩阵，称为 *混淆矩阵*。
- en: Figure 6.5\. Confusion matrix
  id: totrans-1020
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 6.5\. 混淆矩阵
- en: '![](06fig05.jpg)'
  id: totrans-1021
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig05.jpg)'
- en: A *true positive* is when the model predicts a fraud correctly. A *false positive*
    is when the model predicts a fraud incorrectly. A *true negative* is when the
    model predicts a normal (not fraudulent) transaction correctly. Finally, a *false
    negative* is when the model incorrectly predicts a normal transaction, when there
    was in fact fraud.
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
  zh: '*真阳性* 是指模型正确预测欺诈。*假阳性* 是指模型错误地预测欺诈。*真阴性* 是指模型正确预测正常（非欺诈）交易。最后，*假阴性* 是指模型错误地预测正常交易，而实际上存在欺诈。'
- en: 'With these four statistics, we can calculate a number of statistics to help
    us evaluate models. First, we can evaluate the *precision* of a model, which is
    defined as the number of true positives divided by the sum of all positive predictions:'
  id: totrans-1023
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这四个统计量，我们可以计算许多统计量来帮助我们评估模型。首先，我们可以评估模型的 *精确度*，定义为真阳性数量除以所有正预测的总和：
- en: '*precision = true positives / (true positives + false positives)*'
  id: totrans-1024
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*精确度 = 真阳性 / (真阳性 + 假阳性)*'
- en: Precision is important for the Kangaroo Kapital team. If their fraud model’s
    precision isn’t high enough, they’ll spend all their fraud investigation budget
    investigating normal, nonfraudulent transactions.
  id: totrans-1025
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度对于 Kangaroo Kapital 团队来说很重要。如果他们的欺诈模型精确度不够高，他们将花费所有欺诈调查预算来调查正常、非欺诈交易。
- en: There’s another statistic, called *recall*, that’s also important for the kangaroos.
    If the kangaroos’ fraud model’s recall isn’t high enough, it will be too easy
    for animals to commit credit card fraud and never get caught, and that will get
    expensive.
  id: totrans-1026
  prefs: []
  type: TYPE_NORMAL
  zh: 另有一个统计量，称为 *召回率*，对于袋鼠来说也非常重要。如果袋鼠的欺诈模型召回率不够高，动物们将很容易进行信用卡欺诈而不会被抓住，这将变得非常昂贵。
- en: 'Recall is defined as the number of true positives divided by the sum of all
    positives in the set:'
  id: totrans-1027
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率定义为真阳性数量除以集合中所有正数的总和：
- en: '*recall = true positives / (true positives + false negatives)*'
  id: totrans-1028
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*召回率 = 真阳性 / (真阳性 + 假阴性)*'
- en: 'Depending on the context, recall also goes by other names, such as the *true
    positive rate*. There’s another statistic related to recall called the *false
    positive rate*, or *drop-out*, which is defined as the number of false positives
    divided by the sum of all negatives in the set:'
  id: totrans-1029
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上下文，召回率也有其他名称，例如 *真正阳性率*。与召回率相关的另一个统计量称为 *假阳性率*，或 *流失率*，定义为假阳性数量除以集合中所有负数的总和：
- en: '*false positive rate = false positives / (true negatives + false positives)*'
  id: totrans-1030
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*假阳性率 = 假阳性 / (真阴性 + 假阳性)*'
- en: You can visualize how a model trades off the true-positive rate (recall) versus
    the false positive rate using a plot called an *ROC curve*.
  id: totrans-1031
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用称为 *ROC 曲线* 的图表来可视化模型在真正阳性率（召回率）与假阳性率之间的权衡。
- en: '|  |'
  id: totrans-1032
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-1033
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: '*ROC* stands for *receiver-operating characteristic*. The technique and the
    name originated in work on radar during World War II. Although the technique is
    still useful, the name has no relationship to its current common usage, so it’s
    rarely referred to by anything other than its acronym, ROC.'
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
  zh: '*ROC* 代表 *接收者操作特征*。这种技术和名称起源于二战期间对雷达的研究。尽管这种技术仍然有用，但名称与其当前常见用法无关，因此很少用其他名称来提及，除了其缩写
    ROC。'
- en: '|  |'
  id: totrans-1035
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: A typical ROC curve plot might look something like [figure 6.6](#ch06fig06).
  id: totrans-1036
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的 ROC 曲线图可能看起来像 [图 6.6](#ch06fig06)。
- en: Figure 6.6\. ROC curve
  id: totrans-1037
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 6.6\. ROC 曲线
- en: '![](06fig06.jpg)'
  id: totrans-1038
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig06.jpg)'
- en: The false positive rate is on the x-axis, and the true positive rate is on the
    y-axis. The diagonal line *x = y* represents the expected performance of a random
    model, so a usable model’s curve should be above that line. MLlib has some nice,
    built-in functionality to calculate the ROC curve for a binary classifier.
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: 假阳性率位于 x 轴上，真阳性率位于 y 轴上。对角线 *x = y* 代表随机模型的预期性能，因此可用的模型曲线应该高于该线。MLlib 有一些内置的、很好的功能来计算二元分类器的
    ROC 曲线。
- en: Listing 6.4\. Training-performance summary
  id: totrans-1040
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.4\. 训练性能摘要
- en: '[PRE75]'
  id: totrans-1041
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '***1* Produces a summary of a model’s performance**'
  id: totrans-1042
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 生成模型性能摘要**'
- en: '***2* Casts that summary to an appropriate type, BinaryLogisticRegressionSummary**'
  id: totrans-1043
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将该摘要转换为适当的类型，BinaryLogisticRegressionSummary**'
- en: '***3* ROC curve for the model**'
  id: totrans-1044
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 模型的 ROC 曲线**'
- en: '***4* Prints the ROC curve for inspection**'
  id: totrans-1045
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 打印用于检查的 ROC 曲线**'
- en: The model summary is relatively new functionality in MLlib, so it’s not available
    for all classes of models. There are also limitations to its implementation, such
    as the one that requires you to use `asInstanceOf` to cast the summary to the
    correct type. Make no mistake, using `asInstanceOf` like this is bad Scala style;
    it represents a subversion of the type system. But MLlib is still being rapidly
    developed, so this cast operation is just a sign of an incomplete implementation
    within MLlib. Development on MLlib is very active, but machine learning is an
    enormous domain for any one library to support. New functionality is being added
    at a rapid pace, and the overarching abstractions are being dramatically improved.
    Look for rough edges like this class cast to disappear in future versions of Spark.
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
  zh: 模型摘要功能是MLlib中相对较新的功能，因此并非所有模型类别都可用。它的实现也有一些限制，例如需要使用`asInstanceOf`将摘要转换为正确的类型。不要误解，像这样使用`asInstanceOf`是不好的Scala风格；它代表了类型系统的颠覆。但MLlib仍在快速发展，所以这种转换操作只是MLlib中不完整实现的一个标志。MLlib的开发非常活跃，但机器学习是一个庞大的领域，任何库都无法支持。新功能正在以快速的速度添加，并且总体抽象正在得到显著改进。期待未来版本的Spark中像这种类别转换这样的粗糙边缘消失。
- en: 'We’re building massively scalable machine learning systems that operate largely
    autonomously, so who has time to look at a graph and make a decision about what
    constitutes a good-enough model? Well, one of the uses of an ROC curve is to get
    a single number about the performance of a model: the area under the ROC curve.
    The higher this number, the better the model’s performance. You can even make
    strong assertions about a model’s utility using this calculation. Remember, a
    random model would be expected to perform according to the line *x = y* on the
    ROC curve. The area under that is 0.5, so any model with an area under the curve
    (AUC) of less than 0.5 can safely be discarded as being worse than a random model.'
  id: totrans-1047
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在构建大规模可扩展的机器学习系统，这些系统主要自主运行，那么谁有时间去查看图表并决定什么构成一个足够好的模型呢？嗯，ROC曲线的一个用途就是得到关于模型性能的单个数字：ROC曲线下的面积。这个数字越高，模型的性能越好。你甚至可以使用这个计算对模型的效用做出强有力的断言。记住，随机模型预计会在ROC曲线上的*x
    = y*线上表现。其下的面积是0.5，所以任何曲线下面积（AUC）小于0.5的模型都可以安全地丢弃，因为它们比随机模型更差。
- en: '[Figures 6.7](#ch06fig07), [6.8](#ch06fig08), and [6.9](#ch06fig09) show the
    differences in the area under the curve of a good, random, and worse-than-random
    model.'
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6.7](#ch06fig07)，[6.8](#ch06fig08)和[6.9](#ch06fig09)展示了良好、随机和劣于随机模型的曲线下面积差异。'
- en: Figure 6.7\. Good model
  id: totrans-1049
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.7\. 良好模型
- en: '![](06fig07.jpg)'
  id: totrans-1050
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig07.jpg)'
- en: Figure 6.8\. Random model
  id: totrans-1051
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.8\. 随机模型
- en: '![](06fig08.jpg)'
  id: totrans-1052
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig08.jpg)'
- en: Figure 6.9\. Bad model
  id: totrans-1053
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.9\. 恶劣模型
- en: '![](06fig09.jpg)'
  id: totrans-1054
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig09.jpg)'
- en: The next listing shows the implementation of validating for performance better
    than random.
  id: totrans-1055
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表展示了验证性能优于随机模型的实现。
- en: Listing 6.5\. Validating training performance
  id: totrans-1056
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.5\. 验证训练性能
- en: '[PRE76]'
  id: totrans-1057
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '***1* Defines a function to validate that a model is better than random**'
  id: totrans-1058
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 定义一个函数以验证模型是否优于随机模型**'
- en: '***2* Training summary**'
  id: totrans-1059
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 训练摘要**'
- en: '***3* Class casting**'
  id: totrans-1060
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 类别转换**'
- en: '***4* Area under the ROC curve**'
  id: totrans-1061
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* ROC曲线下的面积**'
- en: '***5* Tests whether the area under the curve is greater than the random model**'
  id: totrans-1062
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 测试曲线下面积是否大于随机模型**'
- en: '***6* Example call to validate a model**'
  id: totrans-1063
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 验证模型的示例调用**'
- en: This validation can serve as a useful safety feature in a machine learning system,
    preventing you from publishing a model that could be deeply detrimental. In the
    Kangaroo Kapital example, because fraud is so much rarer than normal transactions,
    a model that failed this test would very likely be falsely accusing a lot of angry
    animals of credit card fraud.
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
  zh: 这种验证可以作为机器学习系统中的一个有用的安全特性，防止你发布可能造成严重损害的模型。在Kangaroo Kapital的例子中，由于欺诈比正常交易要少得多，一个未能通过这项测试的模型很可能错误地指控许多愤怒的动物进行信用卡欺诈。
- en: This technique can be extended beyond basic sanity checks like this. If you
    record the historical performance of your published models, you can compare the
    performance of your newly trained models to them. Then a logical validation would
    be to not publish a model with meaningfully different performance than the current
    published model. I’ll discuss some more techniques for model validation a bit
    later.
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术可以扩展到基本的合理性检查之外。如果你记录了你已发布模型的性能历史，你可以将新训练的模型的性能与它们进行比较。那么，一个合理的验证方法就是不要发布与当前已发布模型性能有显著差异的模型。我稍后会讨论一些关于模型验证的更多技术。
- en: You’re not done asking questions about your model yet. You can consider other
    model metrics. The metrics you’ve seen so far try to capture an aspect of a model’s
    performance. In particular, it’s not hard to imagine a model that does a bit better
    on precision but not on recall or vice versa. An *F measure* (or sometimes *F1
    score*) is a statistic that tries to combine the concerns of precision and recall
    in the same metric. Specifically, it’s the harmonic mean of the precision and
    the recall. The next listing shows two ways of formulating the F measure.
  id: totrans-1066
  prefs: []
  type: TYPE_NORMAL
  zh: 你还没有完成对模型的提问。你可以考虑其他模型指标。你迄今为止看到的指标试图捕捉模型性能的一个方面。特别是，不难想象一个在精确度上做得更好但在召回率上没有或反之亦然的模型。*F度量*（有时也称为*F1分数*）是一个统计量，试图在同一个指标中结合精确度和召回率的关注点。具体来说，它是精确度和召回率的调和平均值。下一个列表显示了两种表述F度量的方式。
- en: Listing 6.6\. F measure
  id: totrans-1067
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.6\. F度量
- en: '[PRE77]'
  id: totrans-1068
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Using the F measure as a model metric may not always be appropriate. It trades
    off precision versus recall evenly, which may not correspond to the modeling and
    business objectives of the situation. But it does have the advantage of being
    a single number that can be used to implement automated decision making.
  id: totrans-1069
  prefs: []
  type: TYPE_NORMAL
  zh: 使用F度量作为模型指标可能并不总是合适的。它均衡地权衡了精确度与召回率，这可能与该情况下的建模和业务目标不符。但它确实有一个优点，即它是一个单一的数字，可以用来实现自动化决策。
- en: For example, one use of the F measure is to set the *threshold* that a logistic-regression
    model uses for binary classification. Internally, a logistic-regression model
    is producing probabilities. To turn them into predicted class labels, you need
    to set a threshold to divide positive (fraud) predictions from negative (not fraud)
    predictions. [Figure 6.10](#ch06fig10) shows some example prediction values from
    a logistic-regression model and how they could be divided into positive and negative
    predictions using different threshold values.
  id: totrans-1070
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，F度量的一种用途是设置逻辑回归模型用于二元分类的*阈值*。在内部，逻辑回归模型正在生成概率。要将它们转换为预测的类别标签，你需要设置一个阈值来区分正（欺诈）预测和负（非欺诈）预测。[图6.10](#ch06fig10)显示了一些来自逻辑回归模型的示例预测值以及如何使用不同的阈值值将它们分为正预测和负预测。
- en: Figure 6.10\. Threshold setting
  id: totrans-1071
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.10\. 阈值设置
- en: '![](06fig10.jpg)'
  id: totrans-1072
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig10.jpg)'
- en: The F measure isn’t the only way of setting a threshold, but it’s a useful one,
    so let’s see how to do it. The following listing shows how to set a threshold
    using the F measure of the model on the training set.
  id: totrans-1073
  prefs: []
  type: TYPE_NORMAL
  zh: F度量不是设置阈值的唯一方法，但它是有用的，所以让我们看看如何做。以下列表显示了如何使用训练集上的模型F度量来设置阈值。
- en: Listing 6.7\. Setting a threshold using the F measure
  id: totrans-1074
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.7\. 使用F度量设置阈值
- en: '[PRE78]'
  id: totrans-1075
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '***1* Retrieves the F measure for every possible threshold**'
  id: totrans-1076
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 获取每个可能阈值的F度量**'
- en: '***2* Finds the maximum F measure**'
  id: totrans-1077
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 找到最大的F度量**'
- en: '***3* Finds the threshold corresponding to the maximum F measure**'
  id: totrans-1078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 找到对应于最大F度量的阈值**'
- en: '***4* Sets that threshold on the model**'
  id: totrans-1079
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 在模型上设置该阈值**'
- en: Now the learned model will use the threshold selected on the basis of the F
    measure to distinguish between positive and negative predictions.
  id: totrans-1080
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，学习到的模型将使用基于F度量的阈值来区分正预测和负预测。
- en: 6.4\. Testing models
  id: totrans-1081
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4\. 测试模型
- en: 'Back in [listing 6.3](#ch06ex03), as part of preparing your data for learning,
    you set aside some of the data for the testing process. Now it’s time to use that
    hold-out data to test your model. When we test models, our goal is to get an accurate
    picture of the model’s performance in the wild. To do that, we must use data that
    the model has never seen before: our hold-out data.'
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
  zh: 在[列表6.3](#ch06ex03)中，作为准备学习数据的一部分，你留出了一部分数据用于测试过程。现在，是时候使用这些预留数据来测试你的模型了。当我们测试模型时，我们的目标是获得模型在野外性能的准确图景。为了做到这一点，我们必须使用模型从未见过的数据：我们的预留数据。
- en: You can use the existing model that you’ve already learned and set a threshold
    to make predictions on the hold-out data. The next listing shows how to produce
    predictions and inspect them.
  id: totrans-1083
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用你已学到的现有模型并设置一个阈值，对预留数据进行预测。下一个列表显示了如何生成预测并检查它们。
- en: Listing 6.8\. Predicting on hold-out data
  id: totrans-1084
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.8\. 在预留数据上预测
- en: '[PRE79]'
  id: totrans-1085
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '***1* Predicts over each row in a testing dataset**'
  id: totrans-1086
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 预测测试数据集中的每一行**'
- en: '***2* Prints a few predictions for inspection**'
  id: totrans-1087
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 打印一些预测结果以供检查**'
- en: 'Next, you’ll do something similar to what you did before: calculate some metrics
    about the model’s performance. In this case, let’s look at precision and recall
    again. To recap: a model with low precision resulted in a lot of angry Tasmanian
    devils who got their cards declined for totally normal, nonfraudulent usage. A
    model with low recall will result in a lot of happy platypi swimming away with
    all of Kangaroo Kapital’s money, because their fraud went undetected. Both are
    important, so we want a model that trades off both concerns well. To visualize
    how a model does with respect to precision and recall, we can look at another
    plot: the precision-recall curve, shown in [figure 6.11](#ch06fig11).'
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将做类似之前的事情：计算关于模型性能的一些指标。在这种情况下，让我们再次看看精确度和召回率。回顾一下：低精确度的模型会导致许多愤怒的塔斯马尼亚恶魔因为完全正常的、非欺诈性的使用而卡片被拒绝。低召回率的模型会导致许多快乐的鸭嘴兽带着所有袋鼠资本的钱游走，因为它们的欺诈没有被检测到。两者都很重要，所以我们希望模型在这两个方面的权衡都很好。为了可视化模型在精确度和召回率方面的表现，我们可以查看另一个图表：精确度-召回率曲线，如图6.11所示。
- en: Figure 6.11\. Precision-recall curve
  id: totrans-1089
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.11\. 精确度-召回率曲线
- en: '![](06fig11.jpg)'
  id: totrans-1090
  prefs: []
  type: TYPE_IMG
  zh: '![](06fig11.jpg)'
- en: Compared to the ROC curve we looked at before, the only difference is the metrics
    on the axes. Recall is on the x-axis, and precision is on the y-axis. Again, the
    diagonal line *x = y* represents the expected performance of a random model, so
    a usable model’s curve should be above that line.
  id: totrans-1091
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前看到的ROC曲线相比，唯一的区别是坐标轴上的指标。召回率在x轴上，精确度在y轴上。同样，对角线* x = y* 代表随机模型的预期性能，因此可用模型的曲线应该高于该线。
- en: As before, you want to be sure that the learned model is better than a random
    model for your chosen model metrics, so you’ll calculate the area under the precision-recall
    curve.
  id: totrans-1092
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，你想要确保学习到的模型在所选模型指标上优于随机模型，因此你将计算精确度-召回率曲线下的面积。
- en: Listing 6.9\. Using an evaluator
  id: totrans-1093
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.9\. 使用评估器
- en: '[PRE80]'
  id: totrans-1094
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '***1* Instantiates a new evaluator**'
  id: totrans-1095
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 实例化一个新的评估器**'
- en: '***2* Sets a column containing a class label**'
  id: totrans-1096
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 设置包含类别标签的列**'
- en: '***3* Sets a column containing predictions**'
  id: totrans-1097
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 设置包含预测的列**'
- en: '***4* Sets a metric to be calculated, the area under the precision-recall curve**'
  id: totrans-1098
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 设置要计算的指标，即精确度-召回率曲线下的面积**'
- en: '***5* Executes the evaluator**'
  id: totrans-1099
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 执行评估器**'
- en: The area under the precision-recall curve for a random model is 0.5, the same
    as a random model in an ROC curve, so you can define your validation function
    in the same way.
  id: totrans-1100
  prefs: []
  type: TYPE_NORMAL
  zh: 随机模型的精确度-召回率曲线下的面积是0.5，与ROC曲线中的随机模型相同，因此你可以以相同的方式定义你的验证函数。
- en: Listing 6.10\. Validating the model
  id: totrans-1101
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.10\. 验证模型
- en: '[PRE81]'
  id: totrans-1102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '***1* Defines a function to check the area under the precision-recall curve**'
  id: totrans-1103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 定义一个函数来检查精确度-召回率曲线下的面积**'
- en: '***2* Ensures that the area under the curve is greater than the random model**'
  id: totrans-1104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 确保曲线下的面积大于随机模型**'
- en: From the perspective of the code you had to write, the metrics on the hold-out
    data worked pretty much identically to calculating metrics on the training data.
    But it’s important to note that metrics calculated on training data give you a
    very different sort of picture than metrics calculated on hold-out data. The metrics
    you calculated on the training set represent *the best possible* performance of
    the model. During the training process, the model-learning algorithm had access
    to both the features and the class labels. Depending on the model-learning algorithm
    and the training dataset, it’s possible for a model to have 100% accuracy on a
    training dataset.
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
  zh: 从你不得不编写的代码的角度来看，在保留数据上计算的指标与在训练数据上计算指标几乎相同。但重要的是要注意，在训练数据上计算的指标与在保留数据上计算的指标给出的画面非常不同。你在训练集上计算的指标代表了模型**最佳可能**的性能。在训练过程中，模型学习算法可以访问特征和类别标签。根据模型学习算法和训练数据集，模型在训练数据集上可能达到100%的准确率。
- en: The hold-out data gives you a very different and more realistic view of how
    good your model is. Because the model has never seen any of this data, it should
    behave much the same as it would if you published it and used it in the real world.
    You can think of this as early access to the model’s true performance, much like
    the Manning Early Access Program ([www.manning.com/meap-program](http://www.manning.com/meap-program)),
    which gives readers access to books like this one before they’re actually printed
    on paper.
  id: totrans-1106
  prefs: []
  type: TYPE_NORMAL
  zh: 保留数据为你提供了一个非常不同且更真实的视角，了解你的模型有多好。因为模型从未见过这些数据，它的行为应该与你在现实世界中发布并使用它时非常相似。你可以将这视为对模型真实性能的早期访问，就像Manning
    Early Access Program ([www.manning.com/meap-program](http://www.manning.com/meap-program))，它允许读者在书籍真正印刷成纸之前就获得像这样一本书的访问权限。
- en: This early access to a model’s performance is crucial. It allows you to protect
    your production systems from fundamentally broken models that could wreak havoc
    with your overall system. It’s important that you don’t corrupt the integrity
    of the testing process. If you fail to adequately separate the data you use for
    training and testing processes, you can get a fundamentally inaccurate picture
    of your model’s performance. Otherwise, you can end up with the problem discussed
    in the next section.
  id: totrans-1107
  prefs: []
  type: TYPE_NORMAL
  zh: 提前了解模型性能至关重要。它允许你保护你的生产系统免受基本损坏的模型的影响，这些模型可能会对你的整体系统造成破坏。确保你不破坏测试过程的完整性非常重要。如果你未能充分分离用于训练和测试过程的数据，你可能会对你的模型性能有一个根本不准确的认识。否则，你可能会遇到下一节讨论的问题。
- en: 6.5\. Data leakage
  id: totrans-1108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5. 数据泄露
- en: A common data-handling error is called *data leakage*. It works something like
    this. You’ve separated your data for use in training and testing, but there’s
    a subtle problem. Knowledge about what’s in the hold-out data—in particular, the
    class labels—has *leaked* into the training data somehow. The result will be good
    performance on the training and testing data but potentially very bad performance
    on real-world data.
  id: totrans-1109
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的数据处理错误被称为“数据泄露”。它的工作原理大致如下。你已经将数据分开用于训练和测试，但有一个微妙的问题。关于保留数据中包含的内容——特别是类别标签——的知识以某种方式“泄露”到了训练数据中。结果将在训练和测试数据上表现良好，但在现实世界数据上可能表现非常糟糕。
- en: In the case of Kangaroo Kapital, consider a data scientist building a model
    on the transactions of long-term customers, for detecting fraud. Because the scientist
    has a lot of historical data on these customers, he decides to build a feature
    about the history of fraud for a certain user. The rationale is that past incidences
    of fraud on a customer’s account imply that she might not be very good at keeping
    her card in her pouch. The data scientist writes a feature to query the historical
    number of fraud reports for a customer, which looks something like the stub implementation
    in the following listing.
  id: totrans-1110
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kangaroo Kapital的情况下，考虑一个数据科学家正在基于长期客户的交易数据构建模型，用于检测欺诈。因为科学家有这些客户的大量历史数据，他决定为某个用户构建一个关于欺诈历史的特征。其逻辑是，客户账户上过去发生的欺诈事件表明她可能不太擅长保管她的卡片。数据科学家编写了一个特征来查询客户的欺诈报告历史数量，这类似于以下列表中的简略实现。
- en: Listing 6.11\. Past-fraud-reports feature
  id: totrans-1111
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.11. 过去欺诈报告特征
- en: '[PRE82]'
  id: totrans-1112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: The problem is that in the data scientist’s implementation, he has no date-range
    restriction on his query. The backing database that stores the fraud-report data
    that he’s querying employs a mutable data model. The result is that recently reported
    frauds are included in this feature, so the model can see those frauds and bias
    itself toward fraud in the training process. This approach continues to work just
    fine in the test set, where that feature about “past” frauds continues to do a
    good job of predicting where “future” frauds will occur. All the model metrics
    we’ve looked at will appear to indicate that this is a highly performant model—but
    they’ll be wrong. Once the model is published, its performance will be much lower
    than any previously calculated metrics would have implied. That’s because the
    model can no longer see the future data in the feature, so it can no longer rely
    on that feature to artificially inflate its performance.
  id: totrans-1113
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，在数据科学家的实现中，他的查询没有日期范围限制。他查询的存储欺诈报告数据的后端数据库采用可变数据模型。结果是，最近报告的欺诈行为被包含在这个特征中，因此模型可以看到这些欺诈行为，并在训练过程中偏向欺诈。这种方法在测试集中仍然表现良好，其中关于“过去”欺诈的特征继续很好地预测“未来”欺诈的发生地点。我们查看的所有模型指标似乎都表明这是一个高性能的模型——但它们是错误的。一旦模型发布，其性能将远低于之前计算的任何指标。这是因为模型无法再看到特征中的未来数据，因此它无法再依赖这个特征来人为地提高其性能。
- en: Data leakage can also take even more subtle forms than that. Remember, Kangaroo
    Kapital separates customers into either training or testing customers. That’s
    a generally sound strategy, but it’s not necessarily all that’s needed to ensure
    that data is handled properly.
  id: totrans-1114
  prefs: []
  type: TYPE_NORMAL
  zh: 数据泄露也可能比这更为微妙。记住，Kangaroo Kapital 将客户分为训练客户或测试客户。这通常是一个合理的策略，但并不一定足以确保数据得到妥善处理。
- en: There was an incident a while ago involving a ring of koala fraudsters. They
    slowly accumulated the account credentials of many of Kangaroo Kapital’s customers.
    Then, all at once, they rang up a huge amount of charges, costing the company
    millions. That’s a lot of eucalyptus!
  id: totrans-1115
  prefs: []
  type: TYPE_NORMAL
  zh: 不久前发生了一起涉及一群考拉诈骗犯的事件。他们慢慢地积累了 Kangaroo Kapital 许多客户的账户凭证。然后，他们突然发起大量收费，给公司造成了数百万的损失。这可是很多桉树啊！
- en: The problem with working with this historical dataset is that it happened at
    a particular point in time, for a particular subset of users. For some reason,
    the koala fraudsters targeted dingoes primarily. When the data is separated between
    training and testing usage by customer, plenty of dingoes are going to wind up
    in the training set, and it’s probable that the model will learn that accounts
    held by dingoes are likely to be targeted for fraud. The problem is that this
    knowledge is useless for the future. It was a single incident, at a single point
    in time. All the perpetrators have since been locked up (after a low-speed police
    chase). This knowledge is useless, and a dingo-centric model will now perform
    quite poorly in the wild.
  id: totrans-1116
  prefs: []
  type: TYPE_NORMAL
  zh: 与这个历史数据集合作的问题在于，它发生在特定的时间点，针对特定的用户子集。出于某种原因，考拉诈骗犯主要针对野狗。当数据在客户之间按训练和测试用途分开时，大量的野狗将最终出现在训练集中，模型很可能学会野狗持有的账户可能被用于欺诈。问题是这种知识对未来是无用的。这是一个单一事件，发生在特定的时间点。所有罪犯随后都被逮捕（在低速警察追捕后）。这种知识是无用的，以野狗为中心的模型现在在野外表现会很差。
- en: In cases of large events in the underlying dataset like this, you can use various
    techniques to mitigate the impact of this anomalous data. One approach is to divide
    your data by time, using the earlier data for training, while holding out the
    later data. This approach may result in quite poor performance during the testing
    phase, but that will be accurate. Machine learning models have a hard time predicting
    the unpredictable.
  id: totrans-1117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种底层数据集中发生大型事件的情况下，你可以使用各种技术来减轻这种异常数据的影响。一种方法是将数据按时间划分，使用较早的数据进行训练，同时保留较晚的数据。这种方法在测试阶段可能会产生相当差的表现，但那是准确的。机器学习模型很难预测不可预测的事情。
- en: Or you can discard this time period entirely on the grounds that you’re trying
    to build a model for the concept label of “normal-scale fraud,” which would typically
    be more evenly distributed across various species of customers. That doesn’t have
    to mean ignoring such forms of fraud entirely. You can still implement other types
    of models or even deterministic systems (for example, rate limits) to detect major
    fraud events like this. This approach lets your “normal-scale fraud” focus on
    the small and regular incidents of fraud that you were originally focusing on
    anyway.
  id: totrans-1118
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以完全忽略这个时间段，理由是你试图构建一个针对“正常规模欺诈”概念标签的模型，这通常会在各种客户群体中更均匀地分布。这并不意味着你必须完全忽略这种形式的欺诈。你仍然可以实施其他类型的模型或甚至确定性系统（例如，速率限制）来检测这种主要欺诈事件。这种方法让你的“正常规模欺诈”专注于你最初就关注的那些小而常规的欺诈事件。
- en: Regardless of the approaches you take, you’ll always want to make sure that
    any relevant knowledge from the hold-out data is kept *entirely* out of the training
    data. If you can succeed at that, your model-evaluation process should be accurate
    and useful.
  id: totrans-1119
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你采取什么方法，你总是想确保任何相关的知识都完全排除在训练数据之外。如果你能成功做到这一点，你的模型评估过程应该是准确和有用的。
- en: 6.6\. Recording provenance
  id: totrans-1120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6. 记录来源
- en: Now that you’ve asked all sorts of questions about your models to ensure that
    they’re predictive, you need to put those models to use. In [chapter 7](kindle_split_018.html#ch07),
    we’ll focus on the process of publishing models, making them available for use
    in predictions. But before we do that, let’s take a quick look at how to capture
    all the useful information that we considered in this chapter.
  id: totrans-1121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经提出了各种关于模型的问题以确保它们具有预测性，你需要开始使用这些模型。在[第7章](kindle_split_018.html#ch07)中，我们将关注发布模型的过程，使它们可用于预测。但在我们这样做之前，让我们快速看一下如何捕捉本章中考虑的所有有用信息。
- en: '![](uncertain-data.jpg)'
  id: totrans-1122
  prefs: []
  type: TYPE_IMG
  zh: '![不确定数据](uncertain-data.jpg)'
- en: If you look back at [chapter 4](kindle_split_015.html#ch04), [section 4.5](kindle_split_015.html#ch04lev1sec5),
    you can see that you needed to make decisions about which feature data could be
    used based on contextual information that couldn’t necessarily be established
    within source code and verified at compile time. We have a similar problem with
    models. Due to the intrinsic uncertainty of the model-learning process, we don’t
    know how good our model is going to turn out to be until after we’ve learned it
    and evaluated its results.
  id: totrans-1123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回顾[第4章](kindle_split_015.html#ch04)、[第4.5节](kindle_split_015.html#ch04lev1sec5)，你可以看到你需要根据无法在源代码中建立并编译时验证的上下文信息来做出决定，哪些特征数据可以使用。我们在模型上也面临类似的问题。由于模型学习过程的内在不确定性，我们在学习模型并评估其结果之前不知道我们的模型会变得多好。
- en: 'This chapter has shown several techniques for addressing this uncertainty through
    using statistical techniques to evaluate the performance of models. The results
    of those calculations need to be consumed by something, though. In this book,
    we’ll consider two downstream consumers of the data produced during model evaluation:
    the publishing process and the supervisory component of the prediction-serving
    application.'
  id: totrans-1124
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了通过使用统计技术评估模型性能来处理这种不确定性的几种技术。然而，这些计算的结果需要被某些东西消费。在这本书中，我们将考虑模型评估期间产生的数据的两个下游消费者：发布过程和预测服务应用的监督组件。
- en: The information that these other systems need to consider is a form of *provenance*
    (also known as *lineage*). In this context, the provenance of a model is the information
    about how the model was produced, including things like the performance metrics
    used to determine that a model should be published.
  id: totrans-1125
  prefs: []
  type: TYPE_NORMAL
  zh: 这些其他系统需要考虑的信息是一种 *来源信息*（也称为 *血缘*）。在这个上下文中，模型的来源信息是指关于模型是如何产生的信息，包括用于确定模型应该发布的性能指标等。
- en: One way to pass around this information is to attach the calculated metrics
    to the model itself inside a wrapper object of some kind. The next listing shows
    one way to do this for some of the statistics you’ve calculated in this chapter.
  id: totrans-1126
  prefs: []
  type: TYPE_NORMAL
  zh: 传递这种信息的一种方法是将计算出的指标附加到某种包装对象中的模型本身。下面的列表显示了本章中计算的一些统计信息的一种实现方式。
- en: Listing 6.12\. Evaluation-results case class
  id: totrans-1127
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.12. 评估结果案例类
- en: '[PRE83]'
  id: totrans-1128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '***1* The model itself**'
  id: totrans-1129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 模型本身**'
- en: '***2* Time at which the model was evaluated**'
  id: totrans-1130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 模型评估的时间**'
- en: '***3* Area under the ROC curve on the training set**'
  id: totrans-1131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 训练集下的ROC曲线下面积**'
- en: '***4* Area under the precision-recall curve on the testing set**'
  id: totrans-1132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 测试集上的精确度-召回率曲线下的面积**'
- en: These may not be precisely the metrics you want to record for your particular
    model-learning pipeline. Area under the curve is useful for deciding *if* we want
    to use a model, but downstream systems may be more concerned with *how* that model
    will behave. You might want to record the precision and recall on the testing
    set at the chosen threshold.
  id: totrans-1133
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可能不是你为特定模型学习管道记录的精确指标。曲线下的面积对于决定是否使用模型是有用的，但下游系统可能更关心该模型将如何表现。你可能会选择在选择的阈值上记录测试集上的精确度和召回率。
- en: Additionally, you may not be passing around the model object with its metadata.
    Sometimes you may choose to only refer to a model by a unique identifier and store
    the metadata in a different place than the model, such as in a database. The next
    listing shows an alternative way of modeling your evaluation results.
  id: totrans-1134
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你可能不会传递包含其元数据的模型对象。有时你可能会选择只通过一个唯一的标识符来引用模型，并将元数据存储在模型的不同位置，例如数据库中。下一个列表显示了建模评估结果的另一种方法。
- en: Listing 6.13\. Refactored evaluation-results case class
  id: totrans-1135
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.13\. 重构的评估结果案例类
- en: '[PRE84]'
  id: totrans-1136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '***1* Model identifier**'
  id: totrans-1137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 模型标识符**'
- en: '***2* Time at which the model was evaluated**'
  id: totrans-1138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 模型评估的时间**'
- en: '***3* Precision of the model on the testing set**'
  id: totrans-1139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 测试集上模型的精确度**'
- en: '***4* Recall of the model on the testing set**'
  id: totrans-1140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 测试集上模型的召回率**'
- en: '![](message-driven.jpg)'
  id: totrans-1141
  prefs: []
  type: TYPE_IMG
  zh: '![图片](message-driven.jpg)'
- en: 'This alternative approach is a bit closer to the message-oriented ideal preferred
    in a reactive machine learning system. This case class could easily be transmitted
    as a message via any number of technologies: queue, event bus, database, and so
    forth. There’s no need for any of the downstream systems needing to consume this
    data to be coupled any more tightly than simple message-passing. From the perspective
    of any consumers (receivers of `ResultsAlternate` messages), the model could have
    been learned by any library, in any language.'
  id: totrans-1142
  prefs: []
  type: TYPE_NORMAL
  zh: 这种替代方法更接近于在反应式机器学习系统中首选的消息导向的理想。这种案例类可以很容易地通过任何数量的技术作为消息传递：队列、事件总线、数据库等等。不需要任何下游系统比简单的消息传递更紧密地耦合来消费这些数据。从任何消费者（`ResultsAlternate`消息的接收者）的角度来看，模型可能是由任何库、任何语言学习的。
- en: '![](containment.jpg)'
  id: totrans-1143
  prefs: []
  type: TYPE_IMG
  zh: '![图片](containment.jpg)'
- en: If our model-evaluation process turned up that we had learned a useless model,
    we could send that information as a message about a model with low precision and/or
    recall. This message-passing form of communication keeps the failure of our model-learning
    process nicely contained. As you’ll see in the next chapter, we can build model-publishing
    systems that can act on messages about models and do the right thing to maintain
    reactivity in our machine learning systems.
  id: totrans-1144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的模型评估过程显示我们学到了一个无用的模型，我们可以将这一信息作为关于低精确度和/或召回率模型的短信发送。这种信息传递的通信方式可以很好地控制我们模型学习过程失败的风险。正如你将在下一章中看到的，我们可以构建可以处理关于模型信息的模型发布系统，并采取适当的措施来保持我们机器学习系统的反应性。
- en: 6.7\. Reactivities
  id: totrans-1145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.7\. 反应性
- en: '![](dog-ball.jpg)'
  id: totrans-1146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](dog-ball.jpg)'
- en: '*Calculate a different performance statistic for the performance of a given
    model on a dataset*. Believe it or not, there are more performance statistics
    that you can calculate. You can try calculating the positive and negative likelihood
    ratios, the G-measure, or something else. You’ll find descriptions of different
    statistics in various statistics references, in books and online. Then you can
    compare those values to the results of the other calculations we’ve explored in
    this chapter. What intuitions does this give you about the performance of the
    model?'
  id: totrans-1147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*计算给定数据集上给定模型的性能统计指标*。信不信由你，你可以计算更多的性能统计指标。你可以尝试计算正负似然比、G度量或其他指标。你将在各种统计参考书籍和在线资源中找到不同统计的描述。然后你可以将这些值与其他我们在本章中探索的计算结果进行比较。这对你关于模型性能的直觉有什么启示？'
- en: '*Try to build a “perfect” model on the training set*. This one is easier than
    it sounds. With a little work, many techniques can get perfect or near-perfect
    performance for a given dataset. Generally speaking, if your model has the same
    number or more of parameters as it does training instances, it can be possible
    for each parameter to end up effectively being a representation of a given instance.
    If you give every instance in your dataset an arbitrary identifier as a feature,
    then several model-learning techniques can use this single feature as a way of
    “remembering” which instance has which class label. If you get a model that’s
    been trained in this way, the interesting thing to do with it is to test it. Apply
    the model to your test set, and calculate its performance. Because you’ve engineered
    an overfit model, the performance is likely (but not guaranteed) to be pretty
    terrible. How does your model perform on the test set? If its performance isn’t
    too bad, how else could you detect that it might not do well on future unseen
    data?'
  id: totrans-1148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*尝试在训练集上构建一个“完美”的模型*。这比听起来容易。通过一点工作，许多技术可以为给定的数据集实现完美或接近完美的性能。一般来说，如果你的模型具有与训练实例相同的数量或更多的参数，那么每个参数最终可能有效地代表一个特定的实例。如果你给你的数据集中的每个实例分配一个任意的标识符作为特征，那么几种模型学习技术可以使用这个单一特征作为“记住”哪个实例具有哪个类标签的方式。如果你得到一个以这种方式训练的模型，对其有趣的事情就是测试它。将模型应用于测试集，并计算其性能。因为你已经构建了一个过度拟合的模型，所以性能可能（但不保证）相当糟糕。你的模型在测试集上的表现如何？如果它的表现不是太糟糕，你还能如何检测它可能在未来的未见数据上表现不佳？'
- en: Summary
  id: totrans-1149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: Models can be evaluated over hold-out data to assess their performance.
  id: totrans-1150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以在保留数据上评估模型以评估其性能。
- en: Statistics like accuracy, precision, recall, F-measure, and area under the curve
    can quantify model performance.
  id: totrans-1151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率、精确度、召回率、F 值和曲线下面积等统计数据可以量化模型性能。
- en: Failing to separate data used in training from testing can result in models
    that lack predictive capability.
  id: totrans-1152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未将用于训练的数据与测试数据分开可能导致模型缺乏预测能力。
- en: Recording the provenance of models allows you to pass messages to other systems
    about their performance.
  id: totrans-1153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录模型的来源允许你向其他系统传递关于其性能的消息。
- en: In the next chapter, you’ll see how to make your learned models available for
    use in predictions.
  id: totrans-1154
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将了解如何使你的学习模型可用于预测。
- en: Chapter 7\. Publishing models
  id: totrans-1155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 7 章\. 发布模型
- en: '*This chapter covers*'
  id: totrans-1156
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Persisting learned models
  id: totrans-1157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久化学习模型
- en: Modeling microservices using Akka HTTP
  id: totrans-1158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Akka HTTP 模拟微服务
- en: Containerization of services using Docker
  id: totrans-1159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Docker 容器化服务
- en: In this chapter, we’ll consider how to publish models (see [figure 7.1](#ch07fig01)).
    Throughout this book, you’ve been learning and using models, but making models
    available for use in a real machine learning system can involve some complexities
    that you haven’t yet seen. When you’re exploring models in a REPL like the Spark
    shell, you can directly call methods on the instance of a model already in memory.
    But in real-world systems, it’s common for a model to be learned in a pipeline,
    as you saw in [chapters 4](kindle_split_015.html#ch04) and [5](kindle_split_016.html#ch05),
    before being used in a completely different application. This chapter will show
    you how to make models available for use in the complex environment of a real-world
    machine learning system. We’ll work through an approach to packaging models into
    services and then making those services into independently deployable units.
  id: totrans-1160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将考虑如何发布模型（见[图 7.1](#ch07fig01)）。在整个本书中，你一直在学习和使用模型，但使模型可用于实际机器学习系统可能涉及一些你尚未看到的复杂性。当你在一个像
    Spark shell 这样的 REPL 中探索模型时，你可以直接调用内存中已存在的模型实例的方法。但在现实世界的系统中，一个模型通常是在管道中学习，正如你在[第
    4 章](kindle_split_015.html#ch04)和[第 5 章](kindle_split_016.html#ch05)中看到的，在完全不同的应用中使用之前。本章将向你展示如何在现实世界的复杂机器学习系统中使模型可用。我们将通过将模型打包成服务，然后使这些服务成为可独立部署的单元的方法来操作。
- en: Figure 7.1\. Phases of machine learning
  id: totrans-1161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 7.1\. 机器学习的阶段
- en: '![](07fig01.jpg)'
  id: totrans-1162
  prefs: []
  type: TYPE_IMG
  zh: '![图片](07fig01.jpg)'
- en: 7.1\. The uncertainty of farming
  id: totrans-1163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1\. 农业的不可预测性
- en: Machine learning is used in all sorts of industries, not just ones that you
    think of as having a lot of technology involved. The world of farming, for example,
    requires a great deal of technological sophistication. Consider Hareloom Farms,
    an organic farm, run entirely by rabbits. The rabbits grow fruits and vegetables,
    including celery, tomatoes, and, of course, carrots.
  id: totrans-1164
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习被应用于各种行业中，而不仅仅是那些你认为涉及大量技术的行业。例如，农业领域就需要大量的技术复杂性。以Hareloom农场为例，这是一个有机农场，完全由兔子运营。兔子种植水果和蔬菜，包括芹菜、番茄，当然还有胡萝卜。
- en: The business of farming is fraught with uncertainty. At Hareloom, an early freeze
    could destroy their tomatoes. Producing less kale than there is demand for could
    mean missing out on potential revenue. A sudden drop in the price of turnips could
    leave them with a crop that’s barely worth harvesting.
  id: totrans-1165
  prefs: []
  type: TYPE_NORMAL
  zh: 农业业务充满了不确定性。在Hareloom，早霜可能会摧毁他们的番茄。生产的甘蓝少于需求量可能会意味着错过潜在的收入。芜菁价格的突然下降可能会让他们手中的作物几乎不值得收获。
- en: 'For all these reasons, Hareloom Farms needs predictive capabilities to run
    their mostly nontechnology business. They have a data team consisting of data
    scientists and engineers (including you) who are smarter than the average hare.
    You build machine-learned models for all these problems using tools that you’ve
    seen before: Scala, Spark, and MLlib. Let’s see what you cooked up down on the
    farm.'
  id: totrans-1166
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有这些原因，Hareloom农场需要预测能力来运营他们主要非技术性的业务。他们有一个由数据科学家和工程师（包括你）组成的数据团队，这些人的智慧比普通兔子要高。你们使用之前见过的工具：Scala、Spark和MLlib，为所有这些问题构建机器学习模型。让我们看看你在农场里准备了些什么。
- en: '![](0136fig01.jpg)'
  id: totrans-1167
  prefs: []
  type: TYPE_IMG
  zh: '![](0136fig01.jpg)'
- en: 7.2\. Persisting models
  id: totrans-1168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2\. 持久化模型
- en: The farmers at Hareloom are very concerned with their crop *yields*—the amount
    of crops produced per unit of farmland. Lately, they’ve been trying to model the
    problem of how much carrot seed to use during planting. Carrot seed itself is
    a pretty low-cost ingredient for their operation, so they historically used it
    pretty freely. When they used too little carrot seed, they didn’t produce as many
    carrots as they’d like. But when they used too much, they saw issues with crowding,
    leading to unsatisfactorily small carrots.
  id: totrans-1169
  prefs: []
  type: TYPE_NORMAL
  zh: Hareloom的农民非常关注他们的作物*产量*——每单位农田产生的作物量。最近，他们一直在尝试建模种植胡萝卜种子数量的问题。胡萝卜种子本身是他们运营中成本相当低的原料，所以他们历史上使用它相当自由。当他们使用太少胡萝卜种子时，他们生产的胡萝卜没有他们想要的那么多。但当他们使用太多时，他们遇到了拥挤的问题，导致胡萝卜尺寸不令人满意。
- en: Your team recorded all of this historical data in the form of simple instances
    for training. For your single feature, you chose the number of seeds per inch
    of soil planted. For your concept label, you chose to use a single Boolean value
    to indicate whether that particular harvest was considered a success. This success
    label is manually produced by aggregating subjective judgments around the amount
    of carrots harvested, the size of the carrots, and the difficulty of harvesting
    them.
  id: totrans-1170
  prefs: []
  type: TYPE_NORMAL
  zh: 你们团队将所有这些历史数据以简单实例的形式记录下来用于训练。对于你的单个特征，你选择了每英寸土壤种植的种子数量。对于你的概念标签，你选择使用单个布尔值来指示该特定收获是否被认为是成功的。这个成功标签是通过汇总关于收获的胡萝卜数量、胡萝卜的大小以及收获它们的难度的主观判断手动产生的。
- en: With the modeling task defined, you can start to build up your Spark pipeline.
  id: totrans-1171
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了建模任务后，你可以开始构建你的Spark管道。
- en: Listing 7.1\. Loading data
  id: totrans-1172
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.1\. 加载数据
- en: '[PRE85]'
  id: totrans-1173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '***1* Sets up a SparkSession**'
  id: totrans-1174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 设置SparkSession**'
- en: '***2* Sequence of instances for training and evaluation**'
  id: totrans-1175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 训练和评估的实例序列**'
- en: '***3* Instances consist of an identifier, seeds used per inch, and a binary
    label for the success of the harvest.**'
  id: totrans-1176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 实例包括一个标识符、每英寸土壤使用的种子数量，以及收获成功的二进制标签。**'
- en: '***4* Creates a DataFrame from instances**'
  id: totrans-1177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 从实例创建DataFrame**'
- en: '***5* Names columns in the DataFrame**'
  id: totrans-1178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 在DataFrame中命名列**'
- en: The rabbits at Hareloom have more historical data than that, but this sample
    should be enough to get you started implementing your model. Note that you’re
    going to use the `DataFrame`-centric Spark ML API again.
  id: totrans-1179
  prefs: []
  type: TYPE_NORMAL
  zh: Hareloom的兔子有更多历史数据，但这个样本应该足以让你开始实现你的模型。请注意，你将再次使用以`DataFrame`为中心的Spark ML API。
- en: Once you have data loaded, you need to produce features from that data. In this
    case, the feature transform you’ll apply is the binning technique from [chapter
    4](kindle_split_015.html#ch04), this time using some MLlib library functionality,
    to reduce your feature values to three bins, as shown in the next listing. For
    more on the technique of binning features, see [section 4.3](kindle_split_015.html#ch04lev1sec3).
  id: totrans-1180
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您加载数据，您需要从该数据中生成特征。在这种情况下，您将应用的特征转换是来自[第4章](kindle_split_015.html#ch04)的分组技术，这次使用一些MLlib库功能，将特征值减少到三个分组，如下一列表所示。有关分组特征技术的更多信息，请参阅[4.3节](kindle_split_015.html#ch04lev1sec3)。
- en: Listing 7.2\. Preparing the features
  id: totrans-1181
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.2\. 准备特征
- en: '[PRE86]'
  id: totrans-1182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '***1* Sets up a QuantileDiscretizer for use in feature engineering**'
  id: totrans-1183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 设置QuantileDiscretizer以用于特征工程**'
- en: '***2* Takes as input the seed-density data**'
  id: totrans-1184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 以种子密度数据作为输入**'
- en: '***3* Sets an output column for the discretized data**'
  id: totrans-1185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 为离散化数据设置输出列**'
- en: '***4* Tells the discretizer to use three buckets**'
  id: totrans-1186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 告诉离散化器使用三个桶**'
- en: '***5* Sets up a VectorAssembler to format data for use as features**'
  id: totrans-1187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 设置一个VectorAssembler以格式化数据作为特征**'
- en: '***6* Sets input columns to be formatted**'
  id: totrans-1188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 设置要格式化的输入列**'
- en: '***7* Defines an output column**'
  id: totrans-1189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 定义输出列**'
- en: The `QuantileDiscretizer` performs the binning (or discretization) operation
    for you without requiring predefined boundaries between buckets. Instead, you
    specify the number of buckets, and the discretizer infers reasonable buckets by
    sampling the data.
  id: totrans-1190
  prefs: []
  type: TYPE_NORMAL
  zh: '`QuantileDiscretizer`为您执行分组（或离散化）操作，而无需在桶之间有预定义的边界。相反，您指定桶的数量，离散化器通过采样数据推断合理的桶。'
- en: Following the discretizer, you also called another bit of helper functionality
    from Spark, the `VectorAssembler`. Its purpose is to add a new column to your
    `DataFrame` containing the feature values wrapped in the necessary `Vector` type
    expected by other parts of the ML pipeline functionality.
  id: totrans-1191
  prefs: []
  type: TYPE_NORMAL
  zh: 在离散化器之后，您还从Spark中调用了一些辅助功能，即`VectorAssembler`。它的目的是为您的新`DataFrame`添加一个包含特征值的列，这些特征值被封装在ML管道功能其他部分所需的`Vector`类型中。
- en: Following that, you can now compose the remainder of your learning pipeline.
    In this example, you’ll be using a technique called *cross validation* to explore
    multiple models to determine which performs best. Cross validation is a technique
    based on dividing the data into random subsamples so that the results of the model-learning
    process can be evaluated on different portions of the data. This process can then
    be repeated with different hyperparameters.
  id: totrans-1192
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，您现在可以组合您学习管道的其余部分。在这个例子中，您将使用一种称为*交叉验证*的技术来探索多个模型，以确定哪个表现最好。交叉验证是一种基于将数据分成随机子样本的技术，以便模型学习过程的结果可以在数据的不同部分上评估。然后，可以使用不同的超参数重复此过程。
- en: You’ll need to set up an object to hold the parameters that will be used in
    different executions of the model-learning process. Then you can choose which
    parameters produce the best model, based on the performance of that model. The
    problem of finding the most effective parameters for the model-learning process
    is generally referred to as *hyperparameter optimization*. The technique you use
    in the example code is known as *grid search*, for the parameter grid being iterated
    through. Unlike some other applications of search that you may have seen, the
    form of search used here is a simple *exhaustive search*, meaning your pipeline
    will try all the parameters you provide to it. Although there are more sophisticated
    approaches to hyperparameter optimization that you could implement, the simple
    exhaustive search of the parameter grid is conveniently provided by MLlib and
    is effective for parameter grids of small size.
  id: totrans-1193
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要设置一个对象来保存将在模型学习过程的多次执行中使用的参数。然后，您可以根据该模型的表现选择产生最佳模型的参数。寻找模型学习过程中最有效的参数的问题通常被称为*超参数优化*。示例代码中使用的技巧被称为*网格搜索*，因为参数网格正在迭代。与您可能看到的某些其他搜索应用不同，这里使用的搜索形式是简单的*穷举搜索*，这意味着您的管道将尝试您提供的所有参数。尽管您可以实施更复杂的超参数优化方法，但MLlib提供的简单参数网格穷举搜索对于小尺寸的参数网格来说非常方便且有效。
- en: The following listing shows how these concepts come together in the remainder
    of your pipeline implementation.
  id: totrans-1194
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了这些概念如何在您管道实现的其余部分中结合在一起。
- en: Listing 7.3\. Composing the pipeline
  id: totrans-1195
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.3\. 组合管道
- en: '[PRE87]'
  id: totrans-1196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '***1* Instantiates a classifier to learn a logistic regression model**'
  id: totrans-1197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 实例化一个分类器以学习逻辑回归模型**'
- en: '***2* Limits the number of iterations it should use during model learning**'
  id: totrans-1198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 限制模型学习过程中使用的迭代次数**'
- en: '***3* Instantiates a pipeline**'
  id: totrans-1199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 实例化一个管道**'
- en: '***4* Sets stages of the pipeline**'
  id: totrans-1200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 设置管道的阶段**'
- en: '***5* Instantiates a ParamGridBuilder to set some parameters**'
  id: totrans-1201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 实例化一个ParamGridBuilder来设置一些参数**'
- en: '***6* Adds regularization parameters**'
  id: totrans-1202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 添加正则化参数**'
- en: '***7* Builds a map of parameters**'
  id: totrans-1203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 构建参数映射**'
- en: '***8* Sets up a BinaryClassificationEvaluator for evaluating learned models**'
  id: totrans-1204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 设置用于评估学习模型的BinaryClassificationEvaluator**'
- en: '***9* Sets up a CrossValidator to evaluate different models**'
  id: totrans-1205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 设置一个CrossValidator来评估不同的模型**'
- en: '***10* Sets an Estimator to use: previously instantiated pipeline**'
  id: totrans-1206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***10* 设置要使用的Estimator：之前实例化的pipeline**'
- en: '***11* Sets an Evaluator to use; previously instantiated BinaryClassificationEvaluator**'
  id: totrans-1207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***11* 设置要使用的评估器；之前实例化的BinaryClassificationEvaluator**'
- en: '***12* Sets the number of folds to use in cross validation**'
  id: totrans-1208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***12* 设置交叉验证中使用的折数**'
- en: '***13* Uses previously defined regularization parameters**'
  id: totrans-1209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***13* 使用之前定义的正则化参数**'
- en: The preceding example performs cross validation over different models using
    different regularization parameters. *Regularization* is a technique designed
    to produce simpler models that are more generally applicable, as shown in the
    next listing.
  id: totrans-1210
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的示例使用不同的正则化参数在不同的模型上执行交叉验证。*正则化*是一种旨在生成更简单且更通用的模型的技巧，如下一列表所示。
- en: Listing 7.4\. Learning and saving the model
  id: totrans-1211
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.4\. 学习和保存模型
- en: '[PRE88]'
  id: totrans-1212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '***1* Learns the model, executing all steps in the pipeline**'
  id: totrans-1213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 学习模型，执行管道中的所有步骤**'
- en: '***2* Persists the learned model to the directory named my-model**'
  id: totrans-1214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将学习到的模型持久化到名为my-model的目录**'
- en: The final `save` operation in this pipeline relies on new functionality added
    in Spark 2.0\. It makes saving and reusing models very easy. In previous chapters,
    you had to define case classes for the output of your work. These were often structured
    as pure data and were often intended to be used as immutable messages. The model-persistence
    functionality of Spark does that for you in a single `save` call.
  id: totrans-1215
  prefs: []
  type: TYPE_NORMAL
  zh: 在此管道中的最终`save`操作依赖于Spark 2.0中添加的新功能。这使得保存和重用模型变得非常容易。在之前的章节中，您必须为工作输出定义case类。这些通常被结构化为纯数据，并且通常旨在用作不可变消息。Spark的模型持久化功能在单个`save`调用中为您完成这项工作。
- en: To see exactly what it’s doing, poke around the my-model directory you created.
    What you’ll find are two types of files. The first is a metadata file in JSON
    format. You first saw the JSON format in [chapter 3](kindle_split_014.html#ch03),
    where you used it as a structure to translate your Scala case classes into, so
    that they could be persisted in your Couchbase document database. Here, JSON is
    used to record the metadata about various aspects of your pipeline. For example,
    you can open the my-model/bestModel/metadata directory and find a file like part-00000\.
    It should contain something like the model in the following listing.
  id: totrans-1216
  prefs: []
  type: TYPE_NORMAL
  zh: 要确切了解它在做什么，请检查您创建的my-model目录。您会发现两种类型的文件。第一种是JSON格式的元数据文件。您第一次在[第3章](kindle_split_014.html#ch03)中看到JSON格式，当时您将其用作结构，以便将Scala
    case类转换为，以便它们可以持久化到您的Couchbase文档数据库中。在这里，JSON用于记录有关管道各个方面的元数据。例如，您可以打开my-model/bestModel/metadata目录并找到一个名为part-00000的文件。它应该包含类似以下列表中的模型。
- en: Listing 7.5\. Pipeline metadata
  id: totrans-1217
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.5\. 管道元数据
- en: '[PRE89]'
  id: totrans-1218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '***1* Type of model being persisted: a PipelineModel**'
  id: totrans-1219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 正在持久化的模型类型：PipelineModel**'
- en: '***2* When the model was produced**'
  id: totrans-1220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 模型产生的时间**'
- en: '***3* Version of Spark it was produced with**'
  id: totrans-1221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 生成该模型的Spark版本**'
- en: '***4* Unique identifier for this model**'
  id: totrans-1222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 该模型的唯一标识符**'
- en: '***5* Parameters about the pipeline**'
  id: totrans-1223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 管道的相关参数**'
- en: '***6* Unique identifiers for each phase in the pipeline**'
  id: totrans-1224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 管道中每个阶段的唯一标识符**'
- en: After looking at this metadata, you can examine the my-model/bestModel/stages
    directory, where you should find directories corresponding to the identifier for
    each stage, as listed in your metadata file. If you look at the one for the logistic-regression
    phase, you should see something like the next listing.
  id: totrans-1225
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看这些元数据之后，您可以检查my-model/bestModel/stages目录，其中应该包含与元数据文件中列出的每个阶段的标识符相对应的目录。如果您查看logistic-regression阶段的目录，您应该会看到类似下一列表的内容。
- en: Listing 7.6\. Logistic-regression model metadata
  id: totrans-1226
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.6\. Logistic-regression模型元数据
- en: '[PRE90]'
  id: totrans-1227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '***1* Type of predictive model being persisted: a LogisticRegressionModel**'
  id: totrans-1228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 正在持久化的预测模型类型：LogisticRegressionModel**'
- en: '***2* Parameters about the model**'
  id: totrans-1229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 模型的相关参数**'
- en: '***3* Threshold of the model**'
  id: totrans-1230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 模型的阈值**'
- en: '***4* Various columns from the DataFrame used to produce the model**'
  id: totrans-1231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 用于生成模型的DataFrame的各种列**'
- en: Similar files are produced for the other stages of the pipeline.
  id: totrans-1232
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的其他阶段也会产生类似的文件。
- en: The use of a human-readable format like JSON makes exploring this data easier,
    but that’s not the primary purpose of these files, which is to allow you to load
    previously learned models that have been saved. In fact, these metadata files
    aren’t the models. That’s where the other type of files produced comes in.
  id: totrans-1233
  prefs: []
  type: TYPE_NORMAL
  zh: 使用类似JSON这样的人可读格式可以更容易地探索这些数据，但这不是这些文件的主要目的，这些文件的主要目的是让您能够加载已保存的先前学习的模型。实际上，这些元数据文件不是模型。这就是其他类型文件产生的用武之地。
- en: The other files use the Parquet format. Apache Parquet started as a joint project
    between engineers at Cloudera and Twitter. It’s commonly used in big data projects
    that use Hadoop or Spark because it’s an efficient method of serializing data,
    with wide support. Data stored in the Parquet format can very easily be used across
    different sorts of data-processing systems. In this case, you use it to store
    any of the data around the phases in your modeling pipeline. For a simple logistic-regression
    model without many features, like the one you built, the amount of data in a model
    is pretty modest, but the efficient compression capabilities of Parquet could
    be more useful for larger models requiring the persistence of more parameters.
  id: totrans-1234
  prefs: []
  type: TYPE_NORMAL
  zh: 其他文件使用Parquet格式。Apache Parquet最初是Cloudera和Twitter的工程师之间的联合项目。它常用于使用Hadoop或Spark的大数据项目中，因为它是一种高效的数据序列化方法，具有广泛的支持。存储在Parquet格式中的数据可以非常容易地用于不同类型的数据处理系统中。在这种情况下，您可以使用它来存储建模管道中任何阶段的数据。对于像您构建的没有许多特征的简单逻辑回归模型，模型中的数据量相当有限，但Parquet的高效压缩能力对于需要持久化更多参数的大型模型可能更有用。
- en: The point of all of this was to allow you to load a model after you had persisted
    it, as shown in the following listing.
  id: totrans-1235
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些的目的都是为了让您在持久化模型后能够加载它，如下面的列表所示。
- en: Listing 7.7\. Loading a persisted model
  id: totrans-1236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.7\. 加载持久化的模型
- en: '[PRE91]'
  id: totrans-1237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: In this example, that’s all it takes to restore the previously learned model
    from the files you inspected. In a full system implementation, this will allow
    the rabbits at Hareloom Farms to learn a model using a distributed model-learning
    pipeline running on a cluster of nodes and then later use that model in a predictive
    microservice, such as the kind discussed in the next chapter.
  id: totrans-1238
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，只需这样做就可以从您检查的文件中恢复之前学习的模型。在完整的系统实现中，这将允许Hareloom农场的兔子们使用在节点集群上运行的分布式模型学习管道学习一个模型，然后稍后在该模型中预测微服务中使用该模型，就像下一章中讨论的那样。
- en: 7.3\. Serving models
  id: totrans-1239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3\. 提供模型服务
- en: Now that you’ve seen how to persist and load models, let’s look at how you can
    use models to make predictions. The component of a machine learning system that
    you need to build now is called by various names, such as *model server* or *predictive
    service*, depending on the design of the component. Typically, model servers are
    applications that can make predictions using a *model library*, a collection of
    previously learned models. In contrast, a predictive service only serves predictions
    for a single model. However it’s designed, the model-serving component is crucial
    to having a useful machine learning system. Without this component, the rabbits
    would have no way of using their models to make predictions on new problems.
  id: totrans-1240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经看到了如何持久化和加载模型，让我们看看您如何使用模型进行预测。您现在需要构建的机器学习系统的组件被各种名称所称呼，如*模型服务器*或*预测服务*，具体取决于组件的设计。通常，模型服务器是能够使用*模型库*（一组先前学习的模型）进行预测的应用程序。相比之下，预测服务只为单个模型提供预测。但无论其设计如何，模型服务组件对于拥有有用的机器学习系统至关重要。没有这个组件，兔子们就没有使用他们的模型对新问题进行预测的方法。
- en: 'The Hareloom data-science stack has evolved using different technologies and
    designs. In the original model server, all the models that had ever been learned
    were stored in and served from a single server-side application. That approach
    had a number of problems: it was inflexible, changes in the model structure often
    meant changes to the model server, and it required that a lot of infrastructure
    be built around the management of the library of models.'
  id: totrans-1241
  prefs: []
  type: TYPE_NORMAL
  zh: Hareloom数据科学堆栈已经通过不同的技术和设计进行了演变。在原始模型服务器中，所有曾经学习过的模型都存储并从单个服务器端应用程序中提供。这种方法有几个问题：它不够灵活，模型结构的更改通常意味着模型服务器的更改，并且它需要围绕模型库的管理构建大量基础设施。
- en: 7.3.1\. Microservices
  id: totrans-1242
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.3.1\. 微服务
- en: Eventually, the team decides to abandon their old model-serving implementation
    when their load becomes too high and predictions can’t be quickly retrieved at
    peak scale. In the redesign, they decide to try a different approach using some
    new tools and techniques. Instead of having a monolithic server containing all
    their models, they choose to create a microservice per model. A *microservice*
    is an application that has very limited responsibilities. At the most extreme
    end, a microservice might do only one thing, holding to the *single responsibility
    principle*. When it was originally developed, the single responsibility principle
    was meant to apply to a small component like a class or a function. The principle
    was that a given system component should do only one thing. When you extend this
    principle to system design, you can create a service that does only one thing.
  id: totrans-1243
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，当团队发现他们的负载过高，预测在峰值规模下无法快速检索时，他们决定放弃他们旧的模型服务实现。在重新设计时，他们决定尝试使用一些新的工具和技术采取不同的方法。他们选择为每个模型创建一个微服务，而不是拥有包含所有模型的单体服务器。*微服务*是一个具有非常有限职责的应用程序。在最极端的情况下，一个微服务可能只做一件事，坚持*单一职责原则*。当这个原则最初被开发出来时，它的意图是应用于像类或函数这样的小组件。原则是，一个给定的系统组件应该只做一件事。当你将这个原则扩展到系统设计时，你可以创建一个只做一件事的服务。
- en: In the context of machine learning, the one thing you want your microservice
    to do is expose the model function. The team likes the simplicity of this “model
    function as a service” design because each microservice can focus on the specific
    needs of a given type of model, instead of having one application handle all types
    of models.
  id: totrans-1244
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的背景下，你希望你的微服务做的一件事是暴露模型函数。团队喜欢这种“模型函数作为服务”设计的简单性，因为每个微服务可以专注于特定类型模型的特定需求，而不是让一个应用程序处理所有类型的模型。
- en: Choosing to break up their library of models into separate microservices has
    solved some of their performance problems. If a given predictive service isn’t
    keeping up with its load, the team can deploy another instance. The pure functions
    of the team’s models are stateless, so you can have many of them running at once
    without any need to coordinate among instances. Later, I’ll discuss some of the
    infrastructural pieces that may help when working with arrays of services.
  id: totrans-1245
  prefs: []
  type: TYPE_NORMAL
  zh: 将他们的模型库拆分成单独的微服务已经解决了他们的一些性能问题。如果一个给定的预测服务无法跟上其负载，团队可以部署另一个实例。团队模型的纯函数是无状态的，因此你可以同时运行许多实例，而无需在实例之间进行任何协调。稍后，我将讨论一些可能有助于处理服务数组的基础设施组件。
- en: 7.3.2\. Akka HTTP
  id: totrans-1246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.3.2\. Akka HTTP
- en: Even given those advantages, the team wants to see if they can come up with
    a highly performant implementation of a model microservice. They turn to our old
    friend Akka to help construct the wrapping infrastructure around their models.
    Akka HTTP is the module in Akka that’s focused on building web services. It’s
    not a web application framework like Play. Instead, it’s more useful for building
    things like services that expose APIs over HTTP. It evolved from a previous framework
    built on top of Akka with a lot of the same goals, called Spray. Note that some
    parts of the functionality you’ll use in this chapter come from the older Spray
    project. The advantage of using Akka to build the predictive service is that you
    can take advantage of the powerful concurrency capabilities of Akka. Akka’s actor
    model provides substantial capability for efficiently using hardware to build
    performant services. For example, you can use many more actors to model concurrency
    in an application than you can use threads. That means you can serve many prediction
    requests at the same time, with the Akka framework doing most of the hard work
    of handling all the concurrent requests.
  id: totrans-1247
  prefs: []
  type: TYPE_NORMAL
  zh: 即使考虑到这些优势，团队仍然想看看他们是否能够提出一个高性能的模型微服务实现。他们转向我们老朋友Akka，以帮助构建围绕他们模型的包装基础设施。Akka
    HTTP是Akka中专注于构建Web服务的模块。它不是一个像Play那样的Web应用程序框架。相反，它对于构建像通过HTTP暴露API的服务这样的东西更有用。它是从一个基于Akka构建的先前框架演变而来的，这个框架具有很多相同的目标，称为Spray。请注意，你将在本章中使用的一些功能来自较旧的Spray项目。使用Akka构建预测服务的好处是你可以利用Akka强大的并发能力。Akka的actor模型提供了使用硬件高效构建高性能服务的能力。例如，你可以使用比线程更多的actor来模拟应用程序中的并发。这意味着你可以同时处理许多预测请求，而Akka框架则承担了处理所有并发请求的大部分繁重工作。
- en: Let’s begin by setting up the schema of what your predictions will look like,
    in a case class, as usual. This will also be used to define how your predictions
    can be serialized as JSON and deserialized back into case classes.
  id: totrans-1248
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从设置预测将如何看起来开始，在一个 case class 中，就像往常一样。这还将用于定义你的预测如何被序列化为 JSON 并反序列化回 case
    classes。
- en: Listing 7.8\. Predictions data
  id: totrans-1249
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.8\. 预测数据
- en: '[PRE92]'
  id: totrans-1250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '***1* Case class for predictions**'
  id: totrans-1251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 预测的 case class**'
- en: '***2* Uses JSON formatting functionality from Spray JSON**'
  id: totrans-1252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 使用 Spray JSON 的 JSON 格式化功能**'
- en: '***3* Defines an implicit formatter for the prediction case class using the
    Spray JSON helper function**'
  id: totrans-1253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 使用 Spray JSON 辅助函数定义预测案例类的隐式格式化器**'
- en: Then you can set up the predictive functionality itself. In this example, you’ll
    use a dummy model and a simplified representation of features. The string representation
    of the features is parsed from the API call and turned into a feature vector implemented
    as a `Map`.
  id: totrans-1254
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以设置预测功能本身。在这个例子中，你将使用一个虚拟模型和特征的一个简化表示。特征的字符串表示从 API 调用中解析出来，并转换为一个实现为 `Map`
    的特征向量。
- en: Listing 7.9\. Models and features
  id: totrans-1255
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.9\. 模型和特征
- en: '[PRE93]'
  id: totrans-1256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '***1* Defines a dummy model that operates on features structured as maps of
    characters to doubles**'
  id: totrans-1257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 定义一个操作特征为字符到双精度浮点数映射的虚拟模型**'
- en: '***2* Creates a map of feature identifiers to “coefficients”**'
  id: totrans-1258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 创建一个特征标识符到“系数”的映射**'
- en: '***3* Generates a prediction value by operating on all feature values**'
  id: totrans-1259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 通过操作所有特征值生成预测值**'
- en: '***4* Uses a case statement to bind names to each feature identifier and feature
    value**'
  id: totrans-1260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 使用情况语句将名称绑定到每个特征标识符和特征值**'
- en: '***5* Retrieves a model coefficient for a feature, multiplying it by the feature
    value**'
  id: totrans-1261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 获取一个特征的特征系数，并将其乘以特征值**'
- en: '***6* Sums feature values and divides by the number of features to produce
    an average prediction value**'
  id: totrans-1262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 对特征值求和，然后除以特征数量以产生平均预测值**'
- en: '***7* Instantiates, returning a prediction instance**'
  id: totrans-1263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 实例化，返回一个预测实例**'
- en: '***8* Defines a function to convert a feature passed as strings into maps of
    strings to doubles**'
  id: totrans-1264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 定义一个函数，将作为字符串传递的特征转换为字符串到双精度浮点数的映射**'
- en: '***9* Converts the feature strings, using a parser and a converter from Spray
    JSON**'
  id: totrans-1265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 使用解析器和 Spray JSON 的转换器将特征字符串转换为映射**'
- en: '***10* Defines a prediction function**'
  id: totrans-1266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***10* 定义一个预测函数**'
- en: '***11* Composes a model and feature parser to produce predictions**'
  id: totrans-1267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***11* 组合模型和特征解析器以生成预测**'
- en: Now you can wrap these functions in a service definition. Using Akka HTTP, the
    following listing defines an API route named `predict` that will take serialized
    string representations of features and return the predictions by your model.
  id: totrans-1268
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以在服务定义中包装这些函数。使用 Akka HTTP，以下列表定义了一个名为 `predict` 的 API 路由，它将接收特征序列化的字符串表示，并通过你的模型返回预测。
- en: Listing 7.10\. A service with routes
  id: totrans-1269
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.10\. 带有路由的服务
- en: '[PRE94]'
  id: totrans-1270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '***1* Creates a Service trait that contains your formatting functionality**'
  id: totrans-1271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建一个包含你的格式化功能的 Service 特质**'
- en: '***2* Requires an implicit actor system for Akka**'
  id: totrans-1272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 需要一个 Akka 的隐式 actor system**'
- en: '***3* Requires an implicit ExecutionContextExecutor for Akka**'
  id: totrans-1273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 需要一个 Akka 的隐式 ExecutionContextExecutor**'
- en: '***4* Requires an implicit Materializer for Akka**'
  id: totrans-1274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 需要一个 Akka 的隐式 Materializer**'
- en: '***5* Requires a logger**'
  id: totrans-1275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 需要一个日志记录器**'
- en: '***6* Defines routes of service**'
  id: totrans-1276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 定义服务的路由**'
- en: '***7* Logs each request and result to a service**'
  id: totrans-1277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 将每个请求和结果记录到服务中**'
- en: '***8* Defines the prefix of your route to be predict**'
  id: totrans-1278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 定义路由的前缀为 predict**'
- en: '***9* Defines that this path will receive gets only**'
  id: totrans-1279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 定义此路径仅接收 GET 请求**'
- en: '***10* Accepts features as a String of JSON**'
  id: totrans-1280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***10* 接受作为 JSON 字符串的特征**'
- en: '***11* Defines how to complete a request**'
  id: totrans-1281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***11* 定义如何完成请求**'
- en: '***12* Calls a prediction function and turns it into a response**'
  id: totrans-1282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***12* 调用一个预测函数并将其转换为响应**'
- en: Finally, the next listing instantiates an instance of that service, starts up
    logging, and binds your service with its `predict` route to a given port on your
    local machine.
  id: totrans-1283
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，下一个列表实例化了该服务的实例，启动了日志记录，并将你的服务与它的 `predict` 路由绑定到本地机器上的一个给定端口。
- en: Listing 7.11\. A model service
  id: totrans-1284
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.11\. 模型服务
- en: '[PRE95]'
  id: totrans-1285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '***1* Defines a model service as a runnable App using the Service trait you
    defined**'
  id: totrans-1286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 定义一个作为可运行的 App 使用你定义的 Service 特质的模型服务**'
- en: '***2* Instantiates an actor system for Akka**'
  id: totrans-1287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 实例化一个 Akka 的 actor 系统**'
- en: '***3* Instantiates an executor for Akka**'
  id: totrans-1288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 实例化一个 Akka 的 executor**'
- en: '***4* Instantiates a materializer for Akka**'
  id: totrans-1289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 实例化一个 Akka 的 materializer**'
- en: '***5* Instantiates a logger**'
  id: totrans-1290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 实例化一个日志记录器**'
- en: '***6* Starts a new HTTP server with defined routes at a given IP and port**'
  id: totrans-1291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 在指定的IP和端口启动一个新的带有定义路由的HTTP服务器**'
- en: This service can now accept requests for predictions on features and return
    the model’s predictions, from any program on a network that can produce a well-formed
    `GET` containing the necessary features (for example, a web browser, mobile app,
    and so on). That will make it a lot easier for your team at Hareloom to use their
    predictive models in other applications, even beyond the ones maintained by the
    data team. All they have to do is get this microservice running on a server somewhere.
  id: totrans-1292
  prefs: []
  type: TYPE_NORMAL
  zh: 此服务现在可以接受来自网络上任何可以产生包含必要特征的规范`GET`请求的程序（例如，网页浏览器、移动应用程序等）的预测请求，并返回模型的预测。这将使Hareloom团队在他们的应用程序中使用预测模型变得更加容易，甚至可以超出数据团队维护的应用程序。他们需要做的只是将这个微服务在某台服务器上运行起来。
- en: 7.4\. Containerizing applications
  id: totrans-1293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4\. 容器化应用程序
- en: The JVM ecosystem has an approach to building and distributing runnable applications.
    Applications can be built as JARs—archives of code—and then executed anywhere
    that has a Java runtime. Scala inherited all these capabilities from Java, and
    they work just fine.
  id: totrans-1294
  prefs: []
  type: TYPE_NORMAL
  zh: JVM生态系统有一种构建和分发可运行应用程序的方法。应用程序可以被构建为JAR文件——代码的归档，然后在任何有Java运行时的地方执行。Scala从Java继承了所有这些功能，并且它们运行得很好。
- en: But there are other options. Lately, many teams have been packaging and distributing
    applications in a way that maximizes portability and works for all types of runtimes,
    called containers. *Containers* are a way of virtualizing an entire server such
    that the resulting container can be run on top of another OS while still appearing
    internally as if it were directly operating on a server, without an intervening
    host. A container can guarantee a complete static snapshot of the state of the
    system, because all the necessary resources to run the application being contained
    are inside the container. Containers are an alternative to directly installing
    an application on a server within an OS running other programs.
  id: totrans-1295
  prefs: []
  type: TYPE_NORMAL
  zh: 但还有其他选择。最近，许多团队以最大化可移植性和适用于所有类型运行时的方式打包和分发应用程序，这被称为容器。*容器*是一种虚拟化整个服务器的方式，使得生成的容器可以在另一个操作系统上运行，同时内部看起来就像它是在服务器上直接运行，没有中间主机。容器可以保证系统状态的完整静态快照，因为运行被包含的应用程序所需的所有必要资源都在容器内部。容器是直接在运行其他程序的操作系统中的服务器上安装应用程序的替代方案。
- en: '![](containment.jpg)'
  id: totrans-1296
  prefs: []
  type: TYPE_IMG
  zh: '![图片](containment.jpg)'
- en: When using traditional methods of installing applications on servers, all sorts
    of aspects of the server state could affect the runtime of the application, such
    as environment variables, the installed libraries, networking configurations,
    and even system time. When using containers, developers get complete control over
    what’s inside the application’s view of the world and prevent the base OS or other
    running applications from interfering with proper operation of the application.
    Similarly, applications are very tightly limited in the resources they can consume
    inside a container, so there’s less chance of a containerized application interfering
    with another application.
  id: totrans-1297
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用传统的在服务器上安装应用程序的方法时，服务器状态的各个方面都可能影响应用程序的运行，例如环境变量、已安装的库、网络配置，甚至系统时间。当使用容器时，开发者可以完全控制应用程序视图中的内容，并防止基础操作系统或其他正在运行的应用程序干扰应用程序的正常运行。同样，应用程序在容器内可以非常严格地限制它们可以消耗的资源，因此容器化的应用程序干扰其他应用程序的机会更小。
- en: The Hareloom Farms team chooses to use Docker, a popular implementation of containers,
    as their standard method of packaging applications. One reason you choose Docker
    specifically is that a wealth of tooling and infrastructure has been built around
    Docker, some of which you’ll see in this chapter and some in the next.
  id: totrans-1298
  prefs: []
  type: TYPE_NORMAL
  zh: Hareloom农场团队选择使用Docker，这是一种流行的容器实现，作为他们打包应用程序的标准方法。选择Docker的具体原因之一是围绕Docker构建了大量工具和基础设施，其中一些将在本章和下一章中看到。
- en: 'For the latest instructions on how to install Docker, visit the Docker website:
    [www.docker.com](http://www.docker.com). This technology is evolving fast, and
    the setup details vary a great deal by OS. Regardless of how you choose to set
    up Docker, once you can run `docker run hello-world` and see a successful result,
    your installation is complete, and you can begin containerizing applications!'
  id: totrans-1299
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何安装 Docker 的最新说明，请访问 Docker 网站：[www.docker.com](http://www.docker.com)。这项技术发展迅速，根据操作系统设置细节有很大差异。无论你选择如何设置
    Docker，一旦你可以运行 `docker run hello-world` 并看到成功的结果，你的安装就完成了，你就可以开始容器化应用程序了！
- en: Next, you’ll need to set up some functionality within your build to help you
    containerize your model service. Sbt is a sophisticated build tool that you can
    use to do a lot of tasks related to building and deploying your code. For instructions
    on how to get started with sbt, see the Download section ([www.scala-sbt.org/download.html](http://www.scala-sbt.org/download.html))
    of the sbt website ([www.scala-sbt.org](http://www.scala-sbt.org)). In this case,
    you’ll use a plugin for sbt called sbt-docker that will help you work with Docker.
    To install this plugin, add it to your /project/plugins.sbt file.
  id: totrans-1300
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要在构建中设置一些功能来帮助你容器化你的模型服务。Sbt 是一个复杂的构建工具，你可以用它来完成许多与构建和部署你的代码相关的任务。有关如何开始使用
    sbt 的说明，请参阅 sbt 网站的下载部分 ([www.scala-sbt.org/download.html](http://www.scala-sbt.org/download.html))。在这种情况下，你将使用一个名为
    sbt-docker 的 sbt 插件，这将帮助你与 Docker 一起工作。要安装此插件，请将其添加到你的 /project/plugins.sbt 文件中。
- en: Listing 7.12\. Adding an sbt plugin
  id: totrans-1301
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.12\. 添加 sbt 插件
- en: '[PRE96]'
  id: totrans-1302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Then you’ll enable the plugin in your build by editing your build definition
    in build.sbt.
  id: totrans-1303
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你将通过编辑 build.sbt 中的构建定义来在你的构建中启用此插件。
- en: Listing 7.13\. Enabling an sbt plugin
  id: totrans-1304
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.13\. 启用 sbt 插件
- en: '[PRE97]'
  id: totrans-1305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: Now that you have the tools in place, you need to define a build for the project.
    This is stuff you need to do regardless of whether you use Docker, if you want
    to define how to build your code into a runnable artifact. For this build, you’ll
    use the standard `package` build task defined by default in sbt. But thanks to
    sbt-docker, you can take this further and define how you’d like the built JAR
    to be packaged into a Docker container.
  id: totrans-1306
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经准备好了工具，你需要为项目定义一个构建。这是无论你是否使用 Docker，如果你想定义如何将你的代码构建成可运行工件时都需要做的事情。对于这个构建，你将使用
    sbt 默认定义的标准的 `package` 构建任务。但是，多亏了 sbt-docker，你可以更进一步，定义你希望构建的 JAR 如何被打包进 Docker
    容器中。
- en: Listing 7.14\. Building a Docker image in sbt
  id: totrans-1307
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.14\. 在 sbt 中构建 Docker 镜像
- en: '[PRE98]'
  id: totrans-1308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '***1* Defines how to build a Dockerfile to be produced by a docker build task**'
  id: totrans-1309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 定义了如何构建由 docker build 任务生成的 Dockerfile**'
- en: '***2* The location to put the JAR in the output**'
  id: totrans-1310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将 JAR 放入输出位置的路径**'
- en: '***3* Looks up the classpath**'
  id: totrans-1311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 查找类路径**'
- en: '***4* Defines the main class, the runnable entry point of the build, to be
    PredictiveService**'
  id: totrans-1312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 定义了主类，构建的可运行入口点为 PredictiveService**'
- en: '***5* Looks up the location of the JAR file produced**'
  id: totrans-1313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 查找生成的 JAR 文件的位置**'
- en: '***6* Builds up a classpath string with the JAR on it**'
  id: totrans-1314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 构建包含 JAR 文件的类路径字符串**'
- en: '***7* Defines instructions for constructing a Dockerfile**'
  id: totrans-1315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 定义了构建 Dockerfile 的说明**'
- en: '***8* Base Docker image to build on top of**'
  id: totrans-1316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 构建的基础 Docker 镜像**'
- en: '***9* Adds all the dependencies files on the classpath and other resources
    in the app directory**'
  id: totrans-1317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 在类路径上添加所有依赖文件以及在应用程序目录中的其他资源**'
- en: '***10* Adds the built JAR**'
  id: totrans-1318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***10* 添加构建的 JAR**'
- en: '***11* Defines an entry point of the application to be running Java with the
    classpath to execute the main class**'
  id: totrans-1319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***11* 定义了应用程序的入口点，以运行 Java 并使用类路径来执行主类**'
- en: Now, with this build defined, run `sbt docker` to build the app as a JAR inside
    a Docker container that will start up the predictive service on initialization.
  id: totrans-1320
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，有了这个构建定义，运行 `sbt docker` 以在 Docker 容器内构建应用程序作为 JAR 文件，该容器将在初始化时启动预测服务。
- en: 'Using `sbt docker`, you skipped over one of the parts of building a Docker
    image that you might otherwise have done manually: defining a Dockerfile. The
    Dockerfile is essentially the instructions about how to build your Docker image
    from other Docker images and the unique resources used in your image. You can
    find the Dockerfile you produced in the target/docker directory of your project.
    When you open it, it should look something like the following listing (except
    much longer).'
  id: totrans-1321
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `sbt docker`，你跳过了构建 Docker 镜像过程中可能手动执行的部分之一：定义 Dockerfile。Dockerfile 实质上是关于如何从其他
    Docker 镜像以及你在镜像中使用的独特资源构建你的 Docker 镜像的指令。你可以在项目的 target/docker 目录中找到你生成的 Dockerfile。当你打开它时，它应该看起来像以下列表（但更长）。
- en: Listing 7.15\. Dockerfile
  id: totrans-1322
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.15\. Dockerfile
- en: '[PRE99]'
  id: totrans-1323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '***1* Base image being built on**'
  id: totrans-1324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 正在构建的基础镜像**'
- en: '***2* Adds the dependency JARs**'
  id: totrans-1325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 添加了依赖 JAR**'
- en: '***3* Adds an application JAR**'
  id: totrans-1326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 添加了应用 JAR**'
- en: '***4* Defines the entry point of the application to be running Java**'
  id: totrans-1327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 定义了要运行的应用的入口点，Java**'
- en: '***5* Indicates that Java should be run on the predictive service to start
    the application**'
  id: totrans-1328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 指示 Java 应在预测服务上运行以启动应用**'
- en: Your Dockerfile will be much longer, but it shouldn’t be any more complex than
    [listing 7.15](#ch07ex15). The Dockerfile lists out all the dependencies to be
    included in the image and then instructs Java where they are using the `-cp` (classpath)
    argument.
  id: totrans-1329
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 Dockerfile 会更长，但它的复杂度不应该比 [列表 7.15](#ch07ex15) 更高。Dockerfile 列出了要包含在镜像中的所有依赖项，然后使用
    `-cp`（类路径）参数指示 Java 它们的位置。
- en: Using this Dockerfile, Docker will build an image containing everything needed
    to run your predictive service inside a container and then place that image in
    your local Docker repository. In the production pipeline at Hareloom, your team
    uses their continuous-delivery infrastructure to push their Docker images to a
    remote repository as part of the build process, which works very similarly to
    the local build you just did.
  id: totrans-1330
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个 Dockerfile，Docker 将构建一个包含在容器内运行你的预测服务的所有必需内容的镜像，然后将该镜像放置在你的本地 Docker 仓库中。在
    Hareloom 的生产流程中，你的团队使用他们的持续交付基础设施，在构建过程中将他们的 Docker 镜像推送到远程仓库，这与你刚才进行的本地构建非常相似。
- en: You can run the service by calling `docker run default/chapter-7` or whatever
    Docker told you it had tagged the built image with as a name. Docker will then
    retrieve your built image from your local Docker repository and run it.
  id: totrans-1331
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过调用 `docker run default/chapter-7` 或 Docker 告诉你它用标签标记的构建镜像的名称来运行服务。然后 Docker
    将从你的本地 Docker 仓库检索你构建的镜像并运行它。
- en: There’s still a lot more you could do with this predictive microservice now
    that you have it packaged inside a Docker container. It can be deployed into all
    sorts of environments, at massive scale, taking advantage of sophisticated container-management
    systems. But we’ll leave the discussion of how to use machine-learned systems
    in your live system for [chapter 8](kindle_split_019.html#ch08).
  id: totrans-1332
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经将这个预测微服务打包到 Docker 容器中，你可以做很多事情。它可以部署到各种环境中，在巨大的规模上运行，利用复杂的容器管理系统。但我们将把如何在你的实时系统中使用机器学习系统的讨论留给第
    [8 章](kindle_split_019.html#ch08)。
- en: If you want to go deeper into how to use Docker, this book definitely shouldn’t
    be your last stop. *Docker in Action* by Jeff Nickoloff (Manning, 2016, [www.manning.com/books/docker-in-action](http://www.manning.com/books/docker-in-action))
    provides a deeper introduction to the larger process of working with Docker models,
    and *Docker in Practice* by Ian Miell and Aidan Hobson Sayers (Manning, 2016,
    [www.manning.com/books/docker-in-practice](http://www.manning.com/books/docker-in-practice),
    new edition forthcoming) can show you more-advanced aspects of deploying applications
    using Docker. Beyond those books, there’s an ever-increasing amount of resources
    for working with containers online.
  id: totrans-1333
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要深入了解如何使用 Docker，这本书绝对不应该成为你的最后一站。《Jeff Nickoloff 著的 *Docker in Action*》（Manning,
    2016, [www.manning.com/books/docker-in-action](http://www.manning.com/books/docker-in-action)）提供了对使用
    Docker 模型更大过程的更深入介绍，而 Ian Miell 和 Aidan Hobson Sayers 著的《Docker in Practice》（Manning,
    2016, [www.manning.com/books/docker-in-practice](http://www.manning.com/books/docker-in-practice)，即将推出新版本）可以展示使用
    Docker 部署应用的更高级方面。除了这些书籍之外，还有越来越多的在线资源可以用来处理容器。
- en: 7.5\. Reactivities
  id: totrans-1334
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5\. 反应性
- en: '![](dog-ball.jpg)'
  id: totrans-1335
  prefs: []
  type: TYPE_IMG
  zh: '![](dog-ball.jpg)'
- en: '*Build a microservice*. This book contains a number of examples of building
    services. As you’ve done before, you can implement your own microservice. You
    can either take some real functionality you’d like to deploy, like wrapping a
    machine-learned model, or you can take a dummy function just to focus on the service
    infrastructure. Often when I’m building systems, I take the latter approach and
    do something like a service that randomly returns either true or false. This “random
    model” allows me to focus on the properties of the service implementation, independent
    of the service functionality. Tools like Akka HTTP make it pretty easy to expose
    a given function to the web as a service, so this reactivity can be as simple
    or as complex as you choose. With this microservice, you can then begin to think
    through questions like how it can be deployed for high load, how failure would
    be detected and managed, how it might work in concert with other services, and
    so on.'
  id: totrans-1336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*构建微服务*。本书包含了许多构建服务的示例。正如你之前所做的那样，你可以实现自己的微服务。你可以选择一些你想要部署的真正功能，比如包装机器学习模型，或者你可以选择一个虚拟函数，仅为了关注服务基础设施。通常当我构建系统时，我会采取后一种方法，做一些像随机返回true或false的服务。这个“随机模型”让我能够专注于服务实现的属性，而与服务的功能无关。像Akka
    HTTP这样的工具使得将给定的函数作为服务暴露到网络上变得非常简单，因此这种反应性可以像你选择的那样简单或复杂。有了这个微服务，你就可以开始思考如何部署以应对高负载，如何检测和管理失败，它如何与其他服务协同工作等问题。'
- en: '*Containerize an application*. Take either the microservice from the previous
    reactivity or some other application and build it into a container. If you really
    want to dig into this process, begin with figuring out the requirements of your
    base image. What OS will your image contain? If you have a Scala service, how
    is the JVM installed and configured? Where do you pick up your dependencies from?
    When you make changes to your service, what parts of the image come from previously
    built layers versus having to be rebuilt? Can you tell if your application was
    built properly in the container build? How do you start your application inside
    your container?'
  id: totrans-1337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*容器化一个应用程序*。你可以选择之前反应性示例中的微服务或某个其他应用程序，并将其构建成一个容器。如果你真的想深入了解这个过程，首先需要确定你的基础镜像的需求。你的镜像将包含什么操作系统？如果你有一个Scala服务，JVM是如何安装和配置的？你从哪里获取你的依赖项？当你对你的服务进行更改时，镜像的哪些部分来自之前构建的层，而哪些部分需要重新构建？你能判断你的应用程序是否在容器构建中正确构建了吗？你如何在容器内启动你的应用程序？'
- en: Summary
  id: totrans-1338
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: Models, and even entire training pipelines, can be persisted for later use.
  id: totrans-1339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型，甚至整个训练管道，都可以持久化以供以后使用。
- en: Microservices are simple services that have very narrow responsibilities.
  id: totrans-1340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务是具有非常狭窄职责的简单服务。
- en: Models, as pure functions, can be encapsulated into microservices.
  id: totrans-1341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型，作为纯函数，可以被封装到微服务中。
- en: You can contain failure of a predictive service by only communicating via message
    passing.
  id: totrans-1342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过仅通过消息传递来通信，从而仅包含预测服务的失败。
- en: You can use an actor hierarchy to ensure resilience within a service.
  id: totrans-1343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用演员层次结构来确保服务内的弹性。
- en: Applications can be containerized using tools like Docker.
  id: totrans-1344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序可以使用像Docker这样的工具进行容器化。
- en: The full process of model publishing looks a lot different than reusing a model
    that you just learned in a REPL like the Spark shell. The tools and techniques
    you learned in this chapter will allow you to use machine-learned models in sophisticated
    real-time systems of all kinds, which is the topic of [chapter 8](kindle_split_019.html#ch08).
  id: totrans-1345
  prefs: []
  type: TYPE_NORMAL
  zh: 模型发布的完整过程看起来与在Spark shell这样的REPL中重用你刚刚学习的模型大不相同。本章中你学到的工具和技术将允许你在各种复杂的实时系统中使用机器学习模型，这是第8章的主题。[第8章](kindle_split_019.html#ch08)。
- en: Chapter 8\. Responding
  id: totrans-1346
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第8章。响应
- en: '*This chapter covers*'
  id: totrans-1347
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Using models to respond to user requests
  id: totrans-1348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用模型响应用户请求
- en: Managing containerized services
  id: totrans-1349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理容器化服务
- en: Designing for failure
  id: totrans-1350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计用于失败
- en: Now we come to the final component of a machine learning system—the part responsible
    for using models to respond to user requests and act on the real world (see [figure
    8.1](#ch08fig01)). In the last chapter, we began using models in a more real-world
    way than just playing with them on a laptop. The approach we took involved building
    predictive microservices that wrapped models and then putting those microservices
    into containers. This chapter continues that approach by using containerized predictive
    services in systems that are exposed to real requests for predictions.
  id: totrans-1351
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来到了机器学习系统的最后一个组成部分——负责使用模型响应用户请求并在现实世界中采取行动的部分（见图8.1）。在上章中，我们开始以一种比仅仅在笔记本电脑上玩模型更现实的方式使用模型。我们采取的方法是构建预测微服务，将模型包装起来，然后将这些微服务放入容器中。本章继续采用这种方法，在暴露于真实预测请求的系统中使用容器化的预测服务。
- en: Figure 8.1\. Phases of machine learning
  id: totrans-1352
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.1\. 机器学习的阶段
- en: '![](08fig01.jpg)'
  id: totrans-1353
  prefs: []
  type: TYPE_IMG
  zh: '![图片](08fig01.jpg)'
- en: 'Using models in the real world is tough. To learn about all the complexity
    of using models in the real world, we need to move from the quiet of the farm
    to the bustle of the big city. We’ll consider the fastest-moving animals in the
    city: turtles.'
  id: totrans-1354
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中使用模型是困难的。为了了解在现实世界中使用模型的复杂性，我们需要从农场中的宁静转移到大城市的喧嚣。我们将考虑城市中移动最快的动物：乌龟。
- en: 8.1\. Moving at the speed of turtles
  id: totrans-1355
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1\. 以乌龟的速度移动
- en: One of the most successful startups in the entire animal kingdom is Turtle Taxi,
    a technologically sophisticated take on the business model of taxis. In many major
    cities, they’ve largely displaced legacy transportation businesses like Caribou
    Cabs.
  id: totrans-1356
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个动物王国中，龟出租车是其中最成功的初创公司之一，它是对出租车商业模式的一种技术化改造。在许多主要城市，他们已经很大程度上取代了像Caribou Cabs这样的传统交通业务。
- en: '![](0150fig01.jpg)'
  id: totrans-1357
  prefs: []
  type: TYPE_IMG
  zh: '![图片](0150fig01.jpg)'
- en: Part of their success is due to their user-friendly mobile app, which allows
    riders to hail a taxi from anywhere at any time. But a less obvious part of their
    success is machine learning. Turtle Taxi employs a large team of semiaquatic data
    scientists and engineers (including you) who perform sophisticated online optimization
    of their transportation infrastructure. In comparison to something like a city
    bus or rail system, the Turtle Taxi fleet is a much harder system to manage. Because
    drivers have no fixed schedules and can drive whenever they choose to, the fleet
    of vehicles available to serve customers is always changing. Similarly, customers
    choose to hail a ride whenever they need one, so there are no static schedules
    like in a traditional public-transit system.
  id: totrans-1358
  prefs: []
  type: TYPE_NORMAL
  zh: 他们成功的一部分归功于用户友好的移动应用程序，这使得乘客可以在任何时间、任何地点叫车。但成功的一个不那么明显的原因是机器学习。龟出租车雇佣了一支由半水生数据科学家和工程师（包括你）组成的大型团队，他们负责对交通基础设施进行复杂的在线优化。与城市公交或铁路系统相比，龟出租车车队是一个更难管理的系统。因为司机没有固定的日程，可以随时驾驶，因此可供客户服务的车辆车队总是在变化。同样，客户在需要时选择叫车，因此在传统公共交通系统中没有静态的日程。
- en: 'This highly dynamic environment creates huge challenges for the data team at
    Turtle Taxi. They need to answer important business questions, including the following:'
  id: totrans-1359
  prefs: []
  type: TYPE_NORMAL
  zh: 这个高度动态的环境为龟出租车数据团队带来了巨大的挑战。他们需要回答重要的业务问题，包括以下内容：
- en: Are enough drivers on the road to serve demand?
  id: totrans-1360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有足够的司机在路上满足需求？
- en: Which driver should serve which request?
  id: totrans-1361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪位司机应该服务哪个请求？
- en: Should the price of a ride move up or down based on demand?
  id: totrans-1362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 出租车价格应该根据需求上涨还是下降？
- en: Are customers getting good or bad service?
  id: totrans-1363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户得到的是好服务还是坏服务？
- en: Are drivers in the right part of town to serve the demand?
  id: totrans-1364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 司机是否在城镇的合适位置以满足需求？
- en: The Turtle Taxi team has spent a lot of time and effort ensuring that their
    machine learning system holds to reactive properties. They learn a lot of models
    to help their systems make autonomous decisions about all those complex business
    problems, and their infrastructure helps them *use* those models in real time,
    at scale. We’ll begin with a simplified view of that infrastructure, leaving discussion
    of some of the more complex real-world issues for later in the chapter.
  id: totrans-1365
  prefs: []
  type: TYPE_NORMAL
  zh: 龟出租车团队投入了大量的时间和精力确保他们的机器学习系统保持反应性。他们学习了许多模型，以帮助系统就所有这些复杂业务问题做出自主决策，并且他们的基础设施帮助他们*使用*这些模型在实时、大规模的情况下。我们将从对该基础设施的简化视图开始，将一些更复杂的现实世界问题留到本章的后面讨论。
- en: 8.2\. Building services with tasks
  id: totrans-1366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2\. 使用任务构建服务
- en: In previous chapters, you’ve seen various techniques and tools for building
    services of different kinds. In [chapter 7](kindle_split_018.html#ch07) specifically,
    you used Akka HTTP, a component of the Akka toolkit, to build your services. Though
    Akka HTTP is an excellent choice for a lot of applications, this chapter introduces
    an alternative library for building services, called http4s.
  id: totrans-1367
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，你已经看到了构建不同类型服务的各种技术和工具。特别是在[第7章](kindle_split_018.html#ch07)中，你使用了Akka
    HTTP，这是Akka工具集的一个组件，来构建你的服务。尽管Akka HTTP对于许多应用来说是一个很好的选择，但本章介绍了一个用于构建服务的替代库，称为http4s。
- en: Whereas Akka HTTP developed from work using the actor model of concurrency,
    http4s provides a programming model influenced more by functional programming.
    The main difference between the two design philosophies manifests in the user
    API. When you use http4s, you don’t use actors or set up an execution context
    for an actor system. Http4s is part of the Typelevel family of projects ([http://typelevel.org](http://typelevel.org))
    and uses many other libraries from that group in its implementation. You can build
    very complex services using http4s, but you’ll use it here primarily for its simplicity.
  id: totrans-1368
  prefs: []
  type: TYPE_NORMAL
  zh: 与从使用并发actor模型的工作中发展而来的Akka HTTP不同，http4s提供了一个更多受到函数式编程影响的编程模型。这两种设计哲学之间的主要区别体现在用户API上。当你使用http4s时，你不会使用actor或为actor系统设置执行上下文。Http4s是Typelevel项目家族的一部分([http://typelevel.org](http://typelevel.org))，并在其实现中使用了该组中的许多其他库。你可以使用http4s构建非常复杂的服务，但在这里你将主要使用它的简单性。
- en: One new concept we should look into before exploring how to build services with
    http4s is tasks. *Tasks* are related to futures but are a more sophisticated construct
    that allows you to reason about things like failure and timeouts. Implemented
    and used properly, tasks can also be more performant than standard Scala futures
    due to how they interact with the underlying concurrency facilities provided by
    the JVM. In particular, with tasks you can express computation you might not ever
    execute. This section will show you how to use this capability in your programs.
  id: totrans-1369
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索如何使用http4s构建服务之前，我们应该先了解一个新概念。*任务*与未来相关，但是一个更复杂的结构，它允许你推理诸如失败和超时等问题。如果正确实现和使用，由于它们与JVM提供的底层并发设施如何交互，任务也可以比标准的Scala未来更高效。特别是，使用任务，你可以表达你可能永远不会执行的计算。本节将向你展示如何在程序中使用这种功能。
- en: The implementation of tasks in this chapter comes from the popular scalaz project.
    For those unfamiliar with scalaz, it’s a project focused on providing advanced
    functional programming features in Scala, similar to the goals of the Typelevel
    family of projects. Unfortunately, scalaz’s implementation of tasks is famously
    poorly documented, so I’ll provide you with the basic information necessary to
    use it here.
  id: totrans-1370
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中任务的实现来自流行的scalaz项目。对于那些不熟悉scalaz的人来说，它是一个专注于在Scala中提供高级函数式编程特性的项目，类似于Typelevel项目家族的目标。不幸的是，scalaz对任务的实现因其著名的文档不完整而闻名，所以我会为你提供在这里使用它所需的基本信息。
- en: '|  |'
  id: totrans-1371
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-1372
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: Tasks, like futures, are a powerful concurrency abstraction that can be implemented
    in various different ways. Monix ([https://monix.io](https://monix.io)), also
    from the Typelevel family of projects, is an alternative implementation of the
    concept of tasks.
  id: totrans-1373
  prefs: []
  type: TYPE_NORMAL
  zh: 任务，就像未来一样，是一种强大的并发抽象，可以以各种不同的方式实现。Monix ([https://monix.io](https://monix.io))，也是Typelevel项目家族的一部分，是任务概念的另一种实现。
- en: '|  |'
  id: totrans-1374
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Like futures, tasks allow you to execute asynchronous computation, but futures
    are eager, as opposed to lazy, by default. In this context, *eager* means execution
    begins immediately. Assuming that futures are lazy is a common and logical mistake,
    but though they’re asynchronous, they’re in fact eager. They start executing immediately,
    even if you might like to delay the start of execution. [Listing 8.1](#ch08ex01)
    demonstrates this sometimes undesirable property. In this listing and [listing
    8.2](#ch08ex02), which demonstrates tasks, assume that `doStuff` is an expensive,
    long-running computation that you only want to trigger when you’re ready to.
  id: totrans-1375
  prefs: []
  type: TYPE_NORMAL
  zh: 与未来一样，任务允许你执行异步计算，但与默认的懒惰不同，未来是贪婪的。在这个上下文中，*贪婪*意味着立即开始执行。假设未来是懒惰的是一个常见且合乎逻辑的错误，但尽管它们是异步的，实际上它们是贪婪的。它们会立即开始执行，即使你可能希望延迟执行的开始。[列表8.1](#ch08ex01)演示了这种有时不希望的特性。在这个列表和[列表8.2](#ch08ex02)中，假设`doStuff`是一个昂贵且运行时间长的计算，你只想在你准备好时触发它。
- en: Listing 8.1\. Eager futures
  id: totrans-1376
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表8.1\. 贪婪未来
- en: '[PRE100]'
  id: totrans-1377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '***1* Imports the execution context to be used for a Future**'
  id: totrans-1378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 导入用于Future的执行上下文**'
- en: '***2* Defines the function to represent your expensive work**'
  id: totrans-1379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 定义表示你昂贵工作的函数**'
- en: '***3* Instantiates a Future (and starts work)**'
  id: totrans-1380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 实例化一个Future（并开始工作）**'
- en: '***4* Waits 1 second to make apparent that the previous line has begun execution**'
  id: totrans-1381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 等待1秒以明显显示上一行已经开始执行**'
- en: '***5* Shows that the next line of code will execute only after work from the
    future has been submitted for execution**'
  id: totrans-1382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 显示下一行代码只有在将未来的工作提交给执行后才会执行**'
- en: 'If you execute this code on your console, you should see output like the following:'
  id: totrans-1383
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在这个控制台执行这段代码，你应该会看到以下类似的输出：
- en: '[PRE101]'
  id: totrans-1384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: Sometimes this property isn’t an issue, but sometimes it is. For example, if
    you wanted to define that long-running computation for all the requests that the
    service gets, but only run that computation 1% of the time, a `Future` would have
    your service doing 100 times the work you’d want to do. In a system where you
    have many models available to make predictions, you might only want to perform
    the prediction on a small subset of qualifying requests for any given model. It
    would be nice to have another option that doesn’t do work that you don’t want
    the system to do.
  id: totrans-1385
  prefs: []
  type: TYPE_NORMAL
  zh: 有时这个属性并不是问题，但有时它就是。例如，如果你想要为服务接收到的所有请求定义长时间运行的计算，但只想在1%的时间内运行这个计算，那么一个`Future`会让你的服务做100倍于你想要做的工。在一个有多个模型可供预测的系统里，你可能只想对任何给定模型的合格请求的小子集进行预测。有一个不执行你不想让系统执行的工作的另一个选项会很好。
- en: The next listing shows how tasks behave differently than futures.
  id: totrans-1386
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表显示了任务与Future的不同行为。
- en: Listing 8.2\. Lazy tasks
  id: totrans-1387
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表8.2. 懒任务
- en: '[PRE102]'
  id: totrans-1388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '***1* Instantiates a Task but doesn’t start work**'
  id: totrans-1389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 实例化一个Task但不开始工作**'
- en: '***2* Waits 1 second to make apparent that the previous line hasn’t yet begun
    execution**'
  id: totrans-1390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 等待1秒以明显显示上一行尚未开始执行**'
- en: '***3* Shows that an entire second has passed**'
  id: totrans-1391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 显示整个第二秒已经过去**'
- en: '***4* Executes the Task**'
  id: totrans-1392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 执行Task**'
- en: 'In contrast to [listing 8.1](#ch08ex01), this code, if executed, should produce
    output that looks like the following:'
  id: totrans-1393
  prefs: []
  type: TYPE_NORMAL
  zh: 与[列表8.1](#ch08ex01)相比，如果执行此代码，应该会产生以下类似的输出：
- en: '[PRE103]'
  id: totrans-1394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '![](laziness.jpg)'
  id: totrans-1395
  prefs: []
  type: TYPE_IMG
  zh: '![laziness.jpg](laziness.jpg)'
- en: Now you have control over when and *if* you do work like long-running computations.
    This is clearly a powerful feature of tasks, and it’s the basis for many of the
    rest of the more advanced features of tasks, such as cancelability. When you use
    http4s to build services, you don’t need to know too much more than this about
    tasks, but understanding the basis of the performance properties of the library
    is helpful.
  id: totrans-1396
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你控制了何时以及是否执行像长时间运行的计算这样的工作。这显然是任务的一个强大功能，也是许多其他更高级任务特性的基础，比如可取消性。当你使用http4s构建服务时，你不需要了解太多关于任务的知识，但理解库的性能属性的基础是有帮助的。
- en: '![](infinite-data.jpg)'
  id: totrans-1397
  prefs: []
  type: TYPE_IMG
  zh: '![infinite-data.jpg](infinite-data.jpg)'
- en: Tasks are just one aspect of the functionality that http4s provides for building
    performant services. The library also uses scalaz streams to process arbitrary
    amounts of data.
  id: totrans-1398
  prefs: []
  type: TYPE_NORMAL
  zh: 任务只是http4s为构建高性能服务提供的功能的一个方面。该库还使用scalaz streams来处理任意数量的数据。
- en: That’s just a taste of what you can do with these libraries, but it should be
    enough for you to start building predictive services.
  id: totrans-1399
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是你可以用这些库做到的一小部分，但应该足够你开始构建预测服务。
- en: 8.3\. Predicting traffic
  id: totrans-1400
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3. 预测交通
- en: Now that I’ve introduced the tools, let’s get back to solving the problem. In
    particular, let’s consider the problem of matching taxi drivers to riders. The
    Turtle Taxi team uses machine learning to predict successful driver-rider matches.
    For a given rider, their system will attempt to predict from a set of available
    drivers which one the rider will most likely enjoy riding with (as recorded by
    the driver rating on the mobile app). This section will walk through how your
    team can create a service to make predictions on this driver-rider match-success
    problem.
  id: totrans-1401
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经介绍了工具，让我们回到解决问题上来。特别是，让我们考虑匹配出租车司机与乘客的问题。Turtle Taxi团队使用机器学习来预测成功的司机-乘客匹配。对于给定的乘客，他们的系统将尝试从一组可用的司机中预测乘客最有可能享受与之共乘的司机（如通过移动应用上的司机评分记录）。本节将介绍你的团队如何创建一个服务来对这种司机-乘客匹配成功问题进行预测。
- en: To begin, you’ll need to create some models to work with. Because the past chapters
    have already covered several different ways to produce machine-learned models,
    I won’t repeat all that material here. To build the infrastructure you need for
    this chapter, you can use simple *stub* (fake) models.
  id: totrans-1402
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要创建一些模型来工作。由于前面的章节已经介绍了多种生成机器学习模型的方法，我不会在这里重复所有这些内容。为了构建本章所需的架构，你可以使用简单的
    *桩*（模拟）模型。
- en: The Turtle Taxi team uses a lot of models, so you’ll start with building support
    for multiple models from the beginning. As discussed in [chapter 5](kindle_split_016.html#ch05),
    using multiple models in combination is called an *ensemble*. In this section,
    you’ll do something a bit different than an ensemble. Instead of using your models
    in combination, you’ll use one or the other on any given prediction request. As
    you’ve seen in previous chapters, real-world machine learning systems use models
    in lots of different ways. Big data teams like Turtle Taxi’s often produce many
    models for different purposes. These models may have different strengths and weaknesses
    that the team figures out by using the models. Experimentation on different modeling
    techniques is an important part of the machine learning process. Your Turtle Taxi
    team has built the system to allow them to test different learned models in production,
    so you’ll approximate that implementation here. In particular, you’ll build a
    simple model experimentation system that will send some traffic to one model and
    some to another to evaluate model performance. [Figure 8.2](#ch08fig02) shows
    a simple form of what you’re going to build.
  id: totrans-1403
  prefs: []
  type: TYPE_NORMAL
  zh: Turtle Taxi 团队使用了大量模型，因此你将从一开始就构建对多个模型的支持。如第 5 章所述（kindle_split_016.html#ch05），组合使用多个模型称为集成。在本节中，你将做一些与集成略有不同的事情。你不会在任意的预测请求中使用你的模型组合，而是会根据需要使用一个或另一个模型。正如你在前面的章节中看到的，现实世界的机器学习系统以许多不同的方式使用模型。像
    Turtle Taxi 这样的大数据团队通常会为不同的目的生产许多模型。这些模型可能具有不同的优势和劣势，团队通过使用这些模型来找出这些优势和劣势。对不同建模技术的实验是机器学习过程中的一个重要部分。你的
    Turtle Taxi 团队已经构建了一个系统，允许他们在生产环境中测试不同的学习模型，所以你在这里将模拟这种实现。特别是，你将构建一个简单的模型实验系统，将一些流量发送到一个模型，一些发送到另一个模型，以评估模型性能。[图
    8.2](#ch08fig02) 展示了你将要构建的简单形式。
- en: Figure 8.2\. Model experimentation architecture
  id: totrans-1404
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 8.2\. 模型实验架构
- en: '![](08fig02.jpg)'
  id: totrans-1405
  prefs: []
  type: TYPE_IMG
  zh: '![](08fig02.jpg)'
- en: '[Listing 8.3](#ch08ex03) shows how to create two simple stub models that predict
    true or false, structured as services. They represent two different models of
    driver-rider match success.'
  id: totrans-1406
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 8.3](#ch08ex03) 展示了如何创建两个简单的桩模型，这些模型以服务的形式预测真或假。它们代表了两种不同的司机-乘客匹配成功模型。'
- en: Listing 8.3\. Stub models
  id: totrans-1407
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 8.3\. 桩模型
- en: '[PRE104]'
  id: totrans-1408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '***1* Defines a model as an HTTP service**'
  id: totrans-1409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 定义模型为一个 HTTP 服务**'
- en: '***2* Uses pattern matching to determine that the request to model A has been
    received**'
  id: totrans-1410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 使用模式匹配来确定是否收到了对模型 A 的请求**'
- en: '***3* Always responds true for model A**'
  id: totrans-1411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 模型 A 总是响应为真**'
- en: '***4* Returns an OK status code with a model’s prediction**'
  id: totrans-1412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 返回一个包含模型预测的 OK 状态码**'
- en: '***5* Defines a similar stub model service for model B**'
  id: totrans-1413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 为模型 B 定义了一个类似的桩模型服务**'
- en: '***6* Always returns false for model B**'
  id: totrans-1414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 模型 B 总是返回假**'
- en: Note that these models are constructed as HTTP services. Once you finish building
    all the necessary infrastructure, they’ll be independently accessible via any
    client capable of sending HTTP to them on the network (for example, your local
    computer).
  id: totrans-1415
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这些模型被构建为 HTTP 服务。一旦你完成所有必要的基础设施建设，它们将通过任何能够通过网络发送 HTTP 请求到它们的客户端（例如，你的本地计算机）独立访问。
- en: Though you haven’t done everything necessary to expose these models as services,
    let’s start to flesh out how you’d like to call these services. For development
    purposes, let’s assume you’re serving all of your predictive functionality from
    your local computer (localhost) on port 8080\. Let’s also namespace all your models
    using the name of a given model under a path named *models*.
  id: totrans-1416
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你还没有完成所有必要的步骤来将这些模型作为服务公开，但让我们先了解一下你希望如何调用这些服务。出于开发目的，让我们假设你从本地计算机（localhost）的
    8080 端口提供所有预测功能。我们还使用名为 *models* 的路径下给定模型的名称来命名所有你的模型。
- en: Using those assumptions, you can create some client helper functions to call
    your models from other parts of the system. It’s important to note that you define
    this client functionality in Scala in the same project purely as a convenience.
    Because you’re constructing these services as network-accessible HTTP services,
    other clients could easily be mobile apps implemented in Swift or Java, or a web
    frontend implemented in JavaScript. The client functionality in the next listing
    is an example of what a consumer of the success match-predictions functionality
    might look like.
  id: totrans-1417
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些假设，你可以创建一些客户端辅助函数，从系统的其他部分调用你的模型。重要的是要注意，你将这个客户端功能定义在 Scala 项目中，纯粹是为了方便。因为你是将这些服务构建为可网络访问的
    HTTP 服务，其他客户端可以很容易地是使用 Swift 或 Java 实现的移动应用，或者使用 JavaScript 实现的前端网页。下一个列表中的客户端功能是一个成功匹配预测功能消费者可能看起来像的例子。
- en: Listing 8.4\. Predictive clients
  id: totrans-1418
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 8.4\. 预测客户端
- en: '[PRE105]'
  id: totrans-1419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '***1* Creates an object to contain client helpers**'
  id: totrans-1420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建一个对象来包含客户端辅助函数**'
- en: '***2* Instantiates an HTTP client to call modeling services**'
  id: totrans-1421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 实例化一个 HTTP 客户端以调用建模服务**'
- en: '***3* Factors out the common steps of calling models to a helper function**'
  id: totrans-1422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 将调用模型的公共步骤提取到一个辅助函数中**'
- en: '***4* Dangerous technique: creates a URI to call a model from dynamic input
    and forces immediate optimistic parsing**'
  id: totrans-1423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 危险技术：从动态输入创建一个调用模型的 URI 并强制立即乐观解析**'
- en: '***5* Creates a Task to define a request**'
  id: totrans-1424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 创建一个任务来定义请求**'
- en: '***6* Creates a function to call model A**'
  id: totrans-1425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 创建一个调用模型 A 的函数**'
- en: '***7* Creates a function to call model B**'
  id: totrans-1426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 创建一个调用模型 B 的函数**'
- en: The use of `.toOption.get` in [listing 8.6](#ch08ex06) isn’t good style—I’m
    using it as a development convenience. The implementation of the URI-building
    functionality in http4s is trying to be a bit safer about dynamically generated
    values like the name of the model and the input data. A future refactor of this
    code could focus on more-sophisticated error handling or use a statically defined
    route, but for now you’ll accept that you could receive unprocessable input that
    would throw errors.
  id: totrans-1427
  prefs: []
  type: TYPE_NORMAL
  zh: 在[列表 8.6](#ch08ex06)中使用 `.toOption.get` 的做法并不好——我只是在开发中用它作为一个便利。http4s 中 URI
    构建功能的实现试图对动态生成的值（如模型名称和输入数据）更加安全。未来对这个代码的重构可能会关注更复杂的错误处理或使用静态定义的路由，但就目前而言，你将接受可能会收到无法处理的输入，这会导致错误。
- en: You want to expose a public API that abstracts over how many models you might
    have published to the server at any given time. Right now, the turtles want to
    have model A receiving 40% of the requests for predictions and model B receiving
    the remaining 60%. This is an arbitrary choice they’ve made for preferring model
    B until model A demonstrates superior performance. You’ll encode that split using
    a simple splitting function to divide traffic based on the hash code of the input
    data, similar to how you divided data in [chapter 6](kindle_split_017.html#ch06).
    The next listing shows the implementation of this hashing function.
  id: totrans-1428
  prefs: []
  type: TYPE_NORMAL
  zh: 你希望公开一个 API，该 API 抽象化了你可能在任何给定时间发布到服务器上的模型数量。目前，海龟们希望模型 A 接收 40% 的预测请求，模型 B
    接收剩余的 60%。这是他们为了在模型 A 展现出优越性能之前更偏好模型 B 而做出的任意选择。你将使用一个简单的分割函数来根据输入数据的哈希码来划分流量，类似于你在[第
    6 章](kindle_split_017.html#ch06)中划分数据的方式。下一个列表展示了这个哈希函数的实现。
- en: Listing 8.5\. Splitting prediction requests
  id: totrans-1429
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 8.5\. 分割预测请求
- en: '[PRE106]'
  id: totrans-1430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '***1* Function to split traffic based on input**'
  id: totrans-1431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 根据输入分割流量的函数**'
- en: '***2* Hashes the input and takes the modulus to determine which model to use**'
  id: totrans-1432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 对输入进行哈希处理并取模以确定使用哪个模型**'
- en: '***3* Uses pattern matching to select model A 40% of the time**'
  id: totrans-1433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 使用模式匹配在 40% 的时间内选择模型 A**'
- en: '***4* Uses model B in the remainder of cases**'
  id: totrans-1434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 在剩余情况下使用模型 B**'
- en: If you had more models deployed, you could extend this approach to something
    more dynamic based on the total number of models deployed and the amount of traffic
    they should receive.
  id: totrans-1435
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你部署了更多模型，你可以根据部署的总模型数量和它们应该接收的流量量来扩展这种方法，使其更加动态。
- en: Now that you have these pieces in place, you can bring all this together into
    a unified model server. In this case, you’ll define your public API as located
    at a path named *api* and the prediction functionality as specifically located
    under the predict path of api.
  id: totrans-1436
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有了这些组件，你可以将它们全部整合到一个统一模型服务器中。在这种情况下，你将定义你的公共 API 位于名为 *api* 的路径上，预测功能位于
    api 的 predict 路径下。
- en: Listing 8.6\. A model service
  id: totrans-1437
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 8.6\. 一个模型服务
- en: '[PRE107]'
  id: totrans-1438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '***1* Defines the model-serving service as a ServerApp for a graceful shutdown**'
  id: totrans-1439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 将模型服务定义为ServerApp以实现优雅的关闭**'
- en: '***2* Defines another HttpService to be the primary API endpoint for external
    use**'
  id: totrans-1440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 定义另一个HttpService作为外部使用的API主端点**'
- en: '***3* Uses pattern matching to define when a prediction request has been received**'
  id: totrans-1441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 使用模式匹配来定义何时收到预测请求**'
- en: '***4* Passes input data to a traffic-splitting function, immediately invoking
    it**'
  id: totrans-1442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 将输入数据传递给一个流量分配函数，立即调用它**'
- en: '***5* Passes through a response with an OK status**'
  id: totrans-1443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 通过具有OK状态的响应进行5次传递**'
- en: '***6* Defines the behavior of the server**'
  id: totrans-1444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 定义服务器的行为**'
- en: '***7* Uses the built-in backend from Blaze to build the server**'
  id: totrans-1445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 使用Blaze内置的后端构建服务器**'
- en: '***8* Binds to port 8080 on a local machine**'
  id: totrans-1446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 绑定到本地机器上的8080端口**'
- en: '***9* Mounts an API service to the path at /api**'
  id: totrans-1447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 在/api路径上挂载API服务**'
- en: '***10* Attaches a service for model A to the server at /models**'
  id: totrans-1448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***10* 将模型A的服务附加到/models服务器上**'
- en: '***11* Attaches a service for model B to the server at /models**'
  id: totrans-1449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***11* 将模型B的服务附加到/models服务器上**'
- en: '***12* Starts the server**'
  id: totrans-1450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***12* 启动服务器**'
- en: Now you can see your model server in action. If you’ve defined a way to build
    the application, you can build and run it.
  id: totrans-1451
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以看到你的模型服务器正在运行。如果你已经定义了构建应用程序的方法，你可以构建并运行它。
- en: For an example of how to set up a build for this application, see the online
    resources for this book ([www.manning.com/books/reactive-machine-learning-systems](http://www.manning.com/books/reactive-machine-learning-systems)
    or [https://github.com/jeffreyksmithjr/reactive-machine-learning-systems](https://github.com/jeffreyksmithjr/reactive-machine-learning-systems)).
    Once your application can be built, you can issue `sbt run`, and your service
    should start up and bind to port 8080 on your local machine.
  id: totrans-1452
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何为这个应用程序设置构建的示例，请参阅本书的在线资源([www.manning.com/books/reactive-machine-learning-systems](http://www.manning.com/books/reactive-machine-learning-systems)或[https://github.com/jeffreyksmithjr/reactive-machine-learning-systems](https://github.com/jeffreyksmithjr/reactive-machine-learning-systems))。一旦你的应用程序可以构建，你可以发出`sbt
    run`命令，你的服务应该启动并绑定到本地机器上的8080端口。
- en: You can test your service using a standard web browser and hitting the API endpoint
    with various endpoints. For example, if the string `abc` represents a valid feature
    vector for this service, then hitting http://localhost:8080/api/predict/abc produces
    a prediction of false (no match) from a prediction from model B.
  id: totrans-1453
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用标准的网络浏览器测试你的服务，并通过各种端点调用API端点。例如，如果字符串`abc`代表这个服务的有效特征向量，那么在http://localhost:8080/api/predict/abc上调用将产生模型B的预测结果（不匹配）。
- en: '![](elastic.jpg)'
  id: totrans-1454
  prefs: []
  type: TYPE_IMG
  zh: '![](elastic.jpg)'
- en: Looking back on what you just built, you see some useful functionality. It has
    a simple way of handling multiple models. Moreover, it should be pretty obvious
    how you could get at least some elasticity by starting up more instances of your
    model services and maybe putting them behind a load balancer.
  id: totrans-1455
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾你刚刚构建的内容，你会发现一些有用的功能。它有一种简单的方式来处理多个模型。此外，很明显，你可以通过启动更多模型服务的实例并可能将它们放在负载均衡器后面来获得至少一些弹性。
- en: You can see a sketch of such an architecture in [figure 8.3](#ch08fig03). It’s
    not a bad approach, but it still lacks some realism. Turtles are tough creatures
    who know how to prepare for the worst that life can throw at them. Let’s look
    at how they’ve hardened their machine learning systems.
  id: totrans-1456
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[图8.3](#ch08fig03)中看到这种架构的草图。这不是一个坏的方法，但它仍然缺乏一些现实感。乌龟是坚韧的生物，知道如何为生活中可能发生的最糟糕的事情做好准备。让我们看看它们是如何使他们的机器学习系统变得坚韧的。
- en: Figure 8.3\. Load-balanced model services
  id: totrans-1457
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.3\. 负载均衡的模型服务
- en: '![](08fig03.jpg)'
  id: totrans-1458
  prefs: []
  type: TYPE_IMG
  zh: '![](08fig03.jpg)'
- en: 8.4\. Handling failure
  id: totrans-1459
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4\. 处理故障
- en: As you’ve seen multiple times in this book, things fail. Whether those things
    are pangolins, poison dart frogs, or plain old databases, nothing runs without
    errors.
  id: totrans-1460
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在本书中多次看到的，事情会失败。无论是穿山甲、毒箭蛙，还是普通的数据库，没有错误就不会运行。
- en: Model services are no different. You get some nice properties from pulling apart
    the different components of your system, like containment and the ability to supervise
    components. But your current implementation is still vulnerable to the consequences
    of failure.
  id: totrans-1461
  prefs: []
  type: TYPE_NORMAL
  zh: 模型服务也没有不同。从你的系统不同组件中分离出一些很好的属性，如封装和监督组件的能力。但你的当前实现仍然容易受到失败后果的影响。
- en: 'Let’s examine how you can deal with failure by building a model that fails
    half the time. That should give you plenty of opportunity to deal with failures.
    [Listing 8.9](#ch08ex09) is another simplified stub model like the ones you built
    earlier, but with one important difference: it treats half of all requests as
    bad requests and fails to return a prediction.'
  id: totrans-1462
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何通过构建一个一半时间会失败的模型来处理故障。这应该会给你很多处理故障的机会。[列表 8.9](#ch08ex09) 是另一个像你之前构建的简化占位符模型，但有一个重要的区别：它将所有请求中的一半视为无效请求，并无法返回预测。
- en: Listing 8.7\. An unreliable model
  id: totrans-1463
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 8.7\. 一个不可靠的模型
- en: '[PRE108]'
  id: totrans-1464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '***1* Creates an HttpService for model C**'
  id: totrans-1465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 为模型 C 创建了一个 HttpService**'
- en: '***2* Defines the same GET endpoint as the other models**'
  id: totrans-1466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 定义与其它模型相同的 GET 端点**'
- en: '***3* Simulates an occasional failure with a random Boolean value**'
  id: totrans-1467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 使用随机的布尔值模拟偶尔的故障**'
- en: '***4* Always predicts true when the service works**'
  id: totrans-1468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 当服务正常工作时始终预测为真**'
- en: '***5* Determines whether the service is in a working or nonworking state**'
  id: totrans-1469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 确定服务是在工作状态还是非工作状态**'
- en: '***6* Returns a normal successful prediction**'
  id: totrans-1470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 返回正常的成功预测**'
- en: '***7* Fails to predict, returns a BadRequest status code**'
  id: totrans-1471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 无法预测，返回 BadRequest 状态码**'
- en: This irritatingly unreliable model is a good stand-in for the real possibility
    of failure in your system, so how could you handle the possibility of this failure?
    You can build the possibility of failure into your system using supervisory hierarchy,
    as you saw in [chapters 2](kindle_split_012.html#ch02) and [3](kindle_split_014.html#ch03).
  id: totrans-1472
  prefs: []
  type: TYPE_NORMAL
  zh: 这个令人烦恼的不可靠模型是系统中真实可能发生故障的良好替代品，那么你该如何处理这种故障的可能性呢？你可以通过监督层次结构将故障的可能性构建到你的系统中，正如你在第
    [2](kindle_split_012.html#ch02) 章和第 [3](kindle_split_014.html#ch03) 章中看到的。
- en: The next listing begins this refactor by tweaking how you call the model services.
  id: totrans-1473
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表通过调整调用模型服务的方式开始了这次重构。
- en: Listing 8.8\. Refactored calling services
  id: totrans-1474
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 8.8\. 重构的调用服务
- en: '[PRE109]'
  id: totrans-1475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '***1* Redefined call helper function**'
  id: totrans-1476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 重新定义了调用辅助函数**'
- en: '***2* Calls a target with a client and returns Task[Response]**'
  id: totrans-1477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 使用客户端调用目标并返回 Task[Response]**'
- en: '***3* Defines a helper function for calling model C**'
  id: totrans-1478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 定义了一个用于调用模型 C 的辅助函数**'
- en: 'After this refactor, the call to the service returns a `Task[Response]`. I
    think this approach is a bit more straightforward about what work you’re doing.
    Specifically, this new type signature encodes two bits of knowledge: that this
    call will take time to do, and that this call will return a `Response`, which
    might not be a successful one.'
  id: totrans-1479
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次重构之后，对服务的调用返回一个 `Task[Response]`。我认为这种方法更直接地说明了你正在做什么工作。具体来说，这个新的类型签名编码了两个知识点：这个调用将花费时间，并且这个调用将返回一个
    `Response`，这可能不是一个成功的响应。
- en: Next, let’s see how you can handle the possibility of failure at the top level.
    Before, you had a mere `ModelServer` whose job was just to handle passing around
    data from requests to models and back. With these changes, you’re beginning to
    build a `ModelSupervisor`, something with a hierarchical responsibility to decide
    what to do in the event of undesirable outcomes. In this context, you want to
    recognize when models fail and pass any messages about that failure back to the
    user. That’s a design choice. In other situations, you might want to do something
    different, such as return a default response. The point is that you now explicitly
    handle failure and make a decision *that you can see in source code* about what
    to do about it.
  id: totrans-1480
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看你如何在上层处理故障的可能性。在此之前，你只有一个简单的 `ModelServer`，其工作只是处理从请求到模型以及返回的数据。随着这些更改，你开始构建一个
    `ModelSupervisor`，它具有层次责任，在出现不理想结果时决定要做什么。在这种情况下，你想要识别模型何时失败，并将有关该故障的消息传递回用户。这是一个设计选择。在其他情况下，你可能想要做不同的事情，例如返回默认响应。重点是，你现在明确地处理故障，并在源代码中做出关于如何处理它的决定。
- en: Listing 8.9\. A model supervisor aware of failure modes
  id: totrans-1481
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 8.9\. 一种了解故障模式的模型管理员
- en: '[PRE110]'
  id: totrans-1482
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '***1* Redefined traffic-splitting function**'
  id: totrans-1483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 重新定义了流量分配函数**'
- en: '***2* Defines the last 40% of traffic as being allocated to model C**'
  id: totrans-1484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将最后 40% 的流量分配给模型 C**'
- en: '***3* Pattern matches on the result of calling a service**'
  id: totrans-1485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 在调用服务的结果上匹配模式**'
- en: '***4* Returns successful responses with the model’s prediction as the body
    of the responses**'
  id: totrans-1486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 返回包含模型预测作为响应体的成功响应**'
- en: '***5* Returns failed responses with a failure message as the body of the responses**'
  id: totrans-1487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 返回包含故障消息作为响应体的失败响应**'
- en: '***6* Adds model C to the services being served**'
  id: totrans-1488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 将模型 C 添加到正在提供的服务中**'
- en: '![](supervision.jpg)'
  id: totrans-1489
  prefs: []
  type: TYPE_IMG
  zh: '![](supervision.jpg)'
- en: Again, you can do whatever you choose in the `case` clause that defines how
    you handle failure, because now you have explicit control via the supervisory
    structure.
  id: totrans-1490
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，你可以在定义如何处理失败的`case`子句中做任何你想做的事情，因为现在你有通过监督结构进行明确控制的能力。
- en: Now let’s see how this structure works. To do the next phase of testing, I suggest
    we stop writing Scala code and instead use command-line utilities. Specifically,
    let’s use cURL, a useful, open source tool you may already have installed on your
    system (if you’re using macOS or Linux). If you’re using Windows, you may need
    to download the latest version from the cURL website ([https://curl.haxx.se](https://curl.haxx.se)).
  id: totrans-1491
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看这个结构是如何工作的。为了进行下一阶段的测试，我建议我们停止编写Scala代码，而是使用命令行工具。具体来说，让我们使用cURL，这是一个有用的开源工具，你可能已经安装在你的系统上（如果你使用的是macOS或Linux）。如果你使用的是Windows，你可能需要从cURL网站下载最新版本（[https://curl.haxx.se](https://curl.haxx.se)）。
- en: With cURL, you can send data to your API server and model services in the same
    way you were doing with the web browser before. The advantage of using cURL is
    that you can set more options around how you interact with your server-side applications
    and how you inspect their results. In the following examples, you’ll use the `-i`
    option to inspect the HTTP headers being returned from your services.
  id: totrans-1492
  prefs: []
  type: TYPE_NORMAL
  zh: 使用cURL，你可以以与之前使用网络浏览器相同的方式向你的API服务器和模型服务发送数据。使用cURL的优点是，你可以设置更多选项，以确定你如何与服务器端应用程序交互以及如何检查它们的结果。在以下示例中，你将使用`-i`选项来检查从你的服务返回的HTTP头部。
- en: The nest listing introduces how to use cURL by calling to an API endpoint that
    maps to a model that it’s behaving normally.
  id: totrans-1493
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表介绍了如何通过调用映射到表现正常的模型的API端点来使用cURL。
- en: Listing 8.10\. A successful response
  id: totrans-1494
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表8.10\. 成功的响应
- en: '[PRE111]'
  id: totrans-1495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '***1* Calls for a prediction and shows headers**'
  id: totrans-1496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 调用预测并显示头部**'
- en: '***2* OK status code from a header**'
  id: totrans-1497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 从头部返回的OK状态码**'
- en: '***3* Information about the response sent back**'
  id: totrans-1498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 返回响应的信息**'
- en: '***4* Prediction of model B**'
  id: totrans-1499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 模型B的预测**'
- en: That all works fine, but what if you use the periodically unreliable model C?
    In some cases, it will behave like this.
  id: totrans-1500
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都工作得很好，但如果你使用的是定期不可靠的模型C呢？在某些情况下，它会表现得像这样。
- en: Listing 8.11\. A possible successful response
  id: totrans-1501
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表8.11\. 可能的成功响应
- en: '[PRE112]'
  id: totrans-1502
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '***1* Calls for a different prediction, maps to a different model**'
  id: totrans-1503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 调用不同的预测，映射到不同的模型**'
- en: '***2* Successful response**'
  id: totrans-1504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 成功的响应**'
- en: '***3* Prediction of model C**'
  id: totrans-1505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 模型C的预测**'
- en: Everything is fine, and you see exactly what you expect to see. But the other
    half of the time, you should see a failed request that looks something like this.
  id: totrans-1506
  prefs: []
  type: TYPE_NORMAL
  zh: 一切正常，你看到的就是你期望看到的内容。但另一半的时间，你应该看到一个失败的请求，看起来像这样。
- en: Listing 8.12\. A possible failed response
  id: totrans-1507
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表8.12\. 可能的失败响应
- en: '[PRE113]'
  id: totrans-1508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '***1* A failed response from a prediction request**'
  id: totrans-1509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 来自预测请求的失败响应**'
- en: '***2* Failure message**'
  id: totrans-1510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 失败信息**'
- en: As expected, sometimes model C completely drops the ball. That’s bad news for
    taxi-driving turtles. This failure to predict could have very negative consequences
    for the rest of the system, depending on how the caller was implemented. At its
    worst, this failure could bring down the whole process of matching riders to drivers,
    and that could mean lost fares.
  id: totrans-1511
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，有时模型C完全掉链子。这对出租车乌龟来说是个坏消息。这种预测失败可能对整个系统产生非常负面的影响，具体取决于调用者的实现方式。在最坏的情况下，这种失败可能会使匹配乘客和司机的整个过程崩溃，这可能导致收入损失。
- en: Yet this failure, like lots of real-world failures, is ephemeral; the model
    doesn’t always fail to predict. When it does return a prediction, you have no
    reason to not use it. The model should be a pure, stateless function. You can
    still build a solution that accommodates the possibility of failure—it will just
    take a bit more effort. One possible solution could look like the following listing,
    which sets up retry logic.
  id: totrans-1512
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种失败，就像许多现实世界的失败一样，是短暂的；模型并不总是预测失败。当它返回预测时，你没有理由不使用它。模型应该是一个纯的、无状态的函数。你仍然可以构建一个能够适应失败可能性的解决方案——这只需要更多的努力。一个可能的解决方案可能如下所示，它设置了重试逻辑。
- en: Listing 8.13\. Adding a retry to calls to models
  id: totrans-1513
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表8.13\. 在调用模型时添加重试
- en: '[PRE114]'
  id: totrans-1514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '***1* Retries after 1 second for all failures**'
  id: totrans-1515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 所有失败在1秒后重试**'
- en: With this approach, you’ll immediately halve the failure rate by retrying once.
    For the dummy unreliable model, this retry strategy could asymptotically approach
    full reliability.
  id: totrans-1516
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，通过重试一次，你可以立即将失败率减半。对于这个不靠谱的模型，这种重试策略可以渐近地接近完全可靠性。
- en: 8.5\. Architecting response systems
  id: totrans-1517
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5\. 架构响应系统
- en: This chapter introduced some strategies for using models to respond to requests
    from users outside your machine learning system. I’ve tried to keep things realistic
    enough to be useful by including complications like multiple models and the possibility
    of failure. But believe it or not, the real Turtle Taxi machine learning system
    is more complicated than this. It has millions of users, with tens to hundreds
    of thousands of users active at a given time. Riders need to be connected to available
    drivers in their area within seconds and picked up within minutes—otherwise, the
    Turtle Taxi business will grind to a halt and fail. With all these demanding real-world
    needs, the team’s real infrastructure looks a bit more like [figure 8.4](#ch08fig04).
  id: totrans-1518
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了一些使用模型来响应来自你机器学习系统外用户请求的策略。我尽量使内容足够现实，以便有用，包括多个模型和失败的可能性等复杂情况。但信不信由你，真实的
    Turtle Taxi 机器学习系统比这更复杂。它拥有数百万用户，同时有数万到数十万用户活跃。乘客需要在几秒钟内连接到他们所在地区的可用司机，并在几分钟内被接走——否则，Turtle
    Taxi 业务将陷入停滞并失败。面对这些苛刻的现实需求，团队的真正基础设施看起来更像[图 8.4](#ch08fig04)。
- en: Figure 8.4\. Model-serving architecture
  id: totrans-1519
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 8.4\. 模型服务架构
- en: '![](08fig04.jpg)'
  id: totrans-1520
  prefs: []
  type: TYPE_IMG
  zh: '![图片](08fig04.jpg)'
- en: Just as you implemented in this chapter, all models are individual services,
    but each of those services is independently packaged in some form or another.
    Docker is a common choice, using techniques like you explored in the last chapter.
    But the JVM also contains an approach to packaging—building JARs—that can be used
    on some application-serving platforms. You worked with JARs a little in [chapter
    7](kindle_split_018.html#ch07), and in [chapter 9](kindle_split_021.html#ch09)
    you’ll work with them in more detail.
  id: totrans-1521
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在本章中实施的那样，所有模型都是独立的服务，但每个服务都以某种形式独立打包。Docker 是一个常见的选择，使用你在上一章中探索的技术。但 JVM
    也包含一种打包方法——构建 JAR 文件，这可以在某些应用服务平台上使用。你在[第 7 章](kindle_split_018.html#ch07)中稍微接触过
    JAR 文件，而在[第 9 章](kindle_split_021.html#ch09)中你将更详细地使用它们。
- en: '![](containment.jpg)'
  id: totrans-1522
  prefs: []
  type: TYPE_IMG
  zh: '![图片](containment.jpg)'
- en: Each of these model services is hosted on what I’m calling an *application-serving
    platform*, but is sometimes called a *container orchestration platform* (usually,
    when it’s focused on using Docker or other forms of containers). Examples of platforms
    like this are Marathon ([https://mesosphere.github.io/marathon](https://mesosphere.github.io/marathon))
    and Kubernetes ([http://kubernetes.io](http://kubernetes.io)), both open source
    software; Amazon’s EC2 Container Service ([https://aws.amazon.com/ecs](https://aws.amazon.com/ecs));
    Microsoft’s Azure Container Service ([https://azure.microsoft.com/en-us/services/container-service](https://azure.microsoft.com/en-us/services/container-service));
    and Kubernetes Engine ([https://cloud.google.com/kubernetes-engine](https://cloud.google.com/kubernetes-engine)),
    which are all cloud-hosted services. A key aspect of these solutions is that they
    allow you to host packaged applications and manage them using some interface.
    They all offer a level of intrinsic containment by isolating the resources used
    by any one application from all other applications, thus limiting the possibility
    of problems like error propagation.
  id: totrans-1523
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型服务都托管在我称之为“应用服务平台”的地方，但有时也被称为“容器编排平台”（通常，当它专注于使用 Docker 或其他形式的容器时）。这类平台的例子有
    Marathon ([https://mesosphere.github.io/marathon](https://mesosphere.github.io/marathon))
    和 Kubernetes ([http://kubernetes.io](http://kubernetes.io))，都是开源软件；亚马逊的 EC2 容器服务
    ([https://aws.amazon.com/ecs](https://aws.amazon.com/ecs))；微软的 Azure 容器服务 ([https://azure.microsoft.com/en-us/services/container-service](https://azure.microsoft.com/en-us/services/container-service))；以及
    Kubernetes 引擎 ([https://cloud.google.com/kubernetes-engine](https://cloud.google.com/kubernetes-engine))，这些都是云托管服务。这些解决方案的关键方面是它们允许你托管打包的应用程序，并使用某种界面来管理它们。它们都提供了一定程度的基本隔离，通过将任何单个应用程序使用的资源与其他所有应用程序隔离开来，从而限制了错误传播等问题发生的可能性。
- en: '![](supervision.jpg)'
  id: totrans-1524
  prefs: []
  type: TYPE_IMG
  zh: '![图片](supervision.jpg)'
- en: 'As you’ve seen in this chapter, once you have models available for use, there’s
    still a lot to figure out. [Figure 8.4](#ch08fig04) represents a lot of the functionality
    you worked on in this chapter as the model supervisor. It also makes clear that
    many of the networking components you implemented in Scala in this chapter are
    often handled by another component, which the diagram calls a *proxy*. The role
    of this component is purely to route requests for predictions to the specific
    service that should serve them. Examples of applications that can serve this role
    are NGINX ([www.nginx.com](http://www.nginx.com)) and HAProxy ([www.haproxy.org](http://www.haproxy.org)).
    In practice, many container-oriented platforms can also handle some amount of
    this networking complexity. Note that both the model supervisor and the proxy
    could in principle be hosted on the same application-serving platform as the model
    services. However it’s implemented, the job of this component is the same: to
    give the model supervisor the ability to manage models and the traffic sent to
    them.'
  id: totrans-1525
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在本章中看到的，一旦有了可用的模型，还有很多事情需要弄清楚。[图8.4](#ch08fig04)展示了本章中作为模型监督者所工作的许多功能。它还清楚地表明，在本章中用Scala实现的许多网络组件通常由另一个组件处理，该图称之为*代理*。这个组件的作用纯粹是路由预测请求到应该提供服务的特定服务。可以承担这种角色的应用程序示例包括NGINX([www.nginx.com](http://www.nginx.com))和HAProxy([www.haproxy.org](http://www.haproxy.org))。在实践中，许多面向容器的平台也可以处理一些网络复杂性。请注意，模型监督者和代理原则上可以托管在与模型服务相同的同一个应用服务平台上。然而，无论其实现方式如何，这个组件的工作职责是相同的：赋予模型监督者管理模型及其接收到的流量的能力。
- en: Architectures like this are nontrivial to implement. Typically, you’d need a
    whole team of smart turtles to stand up all these components and get them working
    effectively in concert.
  id: totrans-1526
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构的实现并不简单。通常情况下，你需要一支由聪明的小海龟组成的团队来搭建所有这些组件，并使它们有效地协同工作。
- en: But you can certainly build incrementally from the simplified designs you implemented
    in this chapter toward the more sophisticated approaches. The underlying principles
    of reactive design remain the same.
  id: totrans-1527
  prefs: []
  type: TYPE_NORMAL
  zh: 但你当然可以从本章中实现的简化设计中逐步构建到更复杂的方法。反应式设计的底层原则保持不变。
- en: 8.6\. Reactivities
  id: totrans-1528
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6. 反应性
- en: '![](dog-ball.jpg)'
  id: totrans-1529
  prefs: []
  type: TYPE_IMG
  zh: '![狗球](dog-ball.jpg)'
- en: '*Build a pipeline of data transformations using tasks*. Now that you’ve seen
    them in action, you may be interested in doing a bit more with tasks. One logical
    use case for tasks is compute-intensive data-transformation pipelines. Such pipelines
    are common in machine learning, especially (but not exclusively) in feature-generation
    pipelines. One of the nice things about tasks is that they can be composed in
    various ways and then run concurrently. You can try implementing things like y-shaped
    operation graphs in your pipeline, where two dependent steps must execute concurrently
    before a third can begin. If you want to dig deeper into the behavior of your
    pipeline, try introducing faults into one of the steps via bad data or some other
    technique:'
  id: totrans-1530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用任务构建数据转换的管道*。现在你已经看到了它们在实际中的应用，你可能对使用任务做更多的事情感兴趣。任务的一个合理用例是计算密集型的数据转换管道。这种管道在机器学习中很常见，尤其是在（但不限于）特征生成管道中。任务的一个优点是它们可以以各种方式组合，然后并发运行。你可以在管道中尝试实现像Y形操作图这样的东西，其中两个依赖步骤必须并发执行，然后第三个步骤才能开始。如果你想深入了解管道的行为，尝试通过不良数据或其他技术将故障引入其中一个步骤：'
- en: How does your pipeline react when it encounters bad input?
  id: totrans-1531
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你的管道遇到不良输入时，它会如何反应？
- en: Is that behavior what you want?
  id: totrans-1532
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那种行为是你想要的吗？
- en: If not, how could you change it?
  id: totrans-1533
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果不是，你该如何改变它？
- en: '*Deploy a containerized service to an application-serving platform*. If you’ve
    been following along in this book, you should have a service that builds inside
    a container. The great thing about containers is that they’re portable, so deploy
    that service somewhere. Quite a few different cloud vendors supply container-hosting
    services, and usually your initial usage is free (see [section 8.5](#ch08lev1sec5)
    for a few options). You can also choose to deploy your containers to an application-serving
    platform that you yourself are hosting. That’s a bit more involved, but if you
    happen to already have something like Marathon on a Mesos cluster running at your
    office, you can use one of those options as well. Once you’ve deployed the service,
    you can think through what it might mean to operate it on an ongoing basis:'
  id: totrans-1534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*将容器化服务部署到应用程序服务平台上*。如果你一直跟随这本书学习，你应该有一个在容器内构建的服务。容器的好处在于它们是可移植的，所以可以将该服务部署到任何地方。许多不同的云供应商提供容器托管服务，通常你的初始使用是免费的（有关一些选项，请参阅[第8.5节](#ch08lev1sec5)）。你也可以选择将你的容器部署到你自己托管的应用程序服务平台上。这稍微复杂一些，但如果你在办公室的Mesos集群上已经运行了类似Marathon的东西，你也可以使用这些选项之一。一旦部署了服务，你可以思考一下持续运营它可能意味着什么：'
- en: What would happen if requests to the service increased dramatically?
  id: totrans-1535
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果对服务的请求急剧增加，会发生什么？
- en: How can you tell that the deployed service is doing what it’s supposed to do?
  id: totrans-1536
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你如何知道部署的服务正在执行它应该执行的操作？
- en: How can you roll back to a previous version of your service?
  id: totrans-1537
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你如何回滚到服务的先前版本？
- en: What would happen to your service if one of the underlying servers for the application-serving
    platform went away? (If you don’t know the answer, you could always send a shutdown
    command to a server under your control and see what happens!)
  id: totrans-1538
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果应用程序服务平台的一个底层服务器消失了，你的服务会发生什么？（如果你不知道答案，你总是可以向你控制的服务器发送关机命令，看看会发生什么！）
- en: Summary
  id: totrans-1539
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: Tasks are useful lazy primitives for structuring expensive computations.
  id: totrans-1540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务是有用的懒惰原语，用于结构化昂贵的计算。
- en: Structuring models as services makes elastic architectures easier to build.
  id: totrans-1541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型作为服务构建可以使弹性架构更容易构建。
- en: Failing model services can be handled by a model supervisor.
  id: totrans-1542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型服务失败可以由模型管理员处理。
- en: The principles of containment and supervision can be applied at several levels
    of systems design to ensure reactive properties.
  id: totrans-1543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隔离和监督的原则可以应用于系统设计的多个层面，以确保反应性。
- en: This concludes [part 2](kindle_split_013.html#part02) of the book. In [part
    3](kindle_split_020.html#part03), we’ll explore some of the more advanced issues
    involved with keeping a machine learning system running, changing, and scaling.
  id: totrans-1544
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的[第二部分](kindle_split_013.html#part02)到此结束。在[第三部分](kindle_split_020.html#part03)中，我们将探讨一些与保持机器学习系统运行、改变和扩展相关的一些更高级的问题。
