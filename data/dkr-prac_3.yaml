- en: Part 4\. Orchestration from a single machine to the cloud
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4部分. 从单机到云端的编排
- en: '[Part 4](#part04) covers the essential area of orchestration. As soon as you
    run any number of containers in the same environment, you’ll need to think about
    how they’re managed in a consistent and reliable way, so we’ll look at some of
    the most popular tools currently available.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4部分](#part04) 涵盖了编排的基本领域。一旦你在同一环境中运行任意数量的容器，你就需要考虑如何以一致和可靠的方式管理它们，因此我们将探讨一些目前最流行的工具。'
- en: '[Chapter 11](kindle_split_023.xhtml#ch11) explains the significance of orchestration,
    and builds up from managing Docker based on a single host with systemd to using
    service discovery on a network with Consul and Registrator.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[第11章](kindle_split_023.xhtml#ch11) 解释了编排的重要性，并从使用systemd管理基于单个主机的Docker服务开始，逐步发展到使用Consul和Registrator在网络上进行服务发现。'
- en: '[Chapter 12](kindle_split_024.xhtml#ch12) moves into clustered Docker environments,
    where we’ll briefly cover Docker Swarm before going over Kubernetes, the most
    popular orchestrator around. Then we’ll reverse things by showing you how to use
    Docker to simulate AWS services locally. Finally, we’ll cover the building of
    a Docker framework on Mesos.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[第12章](kindle_split_024.xhtml#ch12) 讨论了集群化的Docker环境，我们将简要介绍Docker Swarm，然后讨论最流行的编排工具Kubernetes。然后我们将通过展示如何使用Docker在本地模拟AWS服务来反转这个过程。最后，我们将介绍在Mesos上构建Docker框架。'
- en: '[Chapter 13](kindle_split_025.xhtml#ch13) is an extended discussion of the
    factors that might be considered in choosing a Docker-based platform. The choices
    can be bewildering, but this might help you structure your thoughts and make a
    better decision, should you need to.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[第13章](kindle_split_025.xhtml#ch13) 对在选择基于Docker的平台时可能考虑的因素进行了深入讨论。选择可能会让人感到困惑，但这可能有助于你整理思路，并在需要时做出更好的决策。'
- en: Chapter 11\. A primer on container orchestration
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第11章. 容器编排入门
- en: '|  |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**This chapter covers**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**本章内容涵盖**'
- en: Managing simple Docker services with systemd
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用systemd管理简单的Docker服务
- en: Managing multi-host Docker services with Helios
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Helios管理多主机Docker服务
- en: Using Hashicorp’s Consul for service discovery
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hashicorp的Consul进行服务发现
- en: Service registration using Registrator
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Registrator进行服务注册
- en: '|  |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: The technology Docker is built on has existed for a while in different forms,
    but Docker is the solution that’s managed to grab the interest of the technology
    industry. This puts Docker in an enviable position—Docker’s mindshare did the
    initial job of kickstarting an ecosystem of tools, which became a self-perpetuating
    cycle of people being drawn into the ecosystem and contributing back to it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Docker所基于的技术以不同形式存在了一段时间，但Docker是成功吸引技术行业兴趣的解决方案。这使得Docker处于一个令人羡慕的位置——Docker的份额完成了启动工具生态系统的初始工作，这形成了一个自我维持的循环，吸引人们进入生态系统并为它做出贡献。
- en: This is particularly evident when it comes to orchestration. After seeing a
    list of company names with offerings in this space, you’d be forgiven for thinking
    that everyone has their own opinion on how to do things and has developed their
    own tool.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这在编排方面尤其明显。在看到提供该领域服务的公司名单后，你会认为每个人都对如何做事有自己的看法，并开发了他们自己的工具。
- en: Although the ecosystem is a huge strength of Docker (and is why we’ve been drawing
    from it so much in this book), the sheer quantity of possible orchestration tools
    can be overwhelming to novices and veterans alike. This chapter will tour some
    of the most notable tools and give you a feel for the high-level offerings, so
    you’re better informed when it comes to evaluating what you want a framework to
    do for you.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管生态系统是Docker（以及为什么我们在本书中如此频繁地从中汲取）的一个巨大优势，但可能的编排工具数量对于新手和资深人士来说都可能令人感到压倒性。本章将介绍一些最显著的工具，并让你对高级提供的内容有所了解，这样在评估你希望框架为你做什么时，你将更加了解。
- en: There are many ways of arranging family trees of the orchestration tools. [Figure
    11.1](#ch11fig01) shows some of the tools we’re familiar with. At the root of
    the tree is `docker run`, the most common way to start a container. Everything
    inspired by Docker is an offshoot of this. On the left side are tools that treat
    groups of containers as a single entity. The middle shows the tools focused on
    managing containers under the umbrella of systemd and service files. Finally,
    the right side treats individual containers as just that. As you move down the
    branches, the tools end up doing more for you, be it working across multiple hosts
    or taking the tedium of manual container deployment away from you.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 安排编排工具的家族树有许多方法。[图11.1](#ch11fig01)展示了我们熟悉的一些工具。树的根部是`docker run`，这是启动容器的最常见方式。所有受Docker启发的工具都是这个分支的延伸。左侧是那些将容器组视为单一实体的工具。中间展示了专注于在systemd和服务文件下管理容器的工具。最后，右侧将单个容器视为其本身。随着你向下移动分支，这些工具最终会为你做更多的事情，无论是跨多台主机工作还是从你手中移除手动容器部署的繁琐。
- en: Figure 11.1\. Orchestration tools in the Docker ecosystem
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.1\. Docker生态系统中的编排工具
- en: '![](Images/11fig01_alt.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/11fig01_alt.jpg)'
- en: 'You’ll note two seemingly isolated areas on the diagram—Mesos and the Consul/etcd/Zookeeper
    group. Mesos is an interesting case—it existed before Docker, and the support
    it has for Docker is an added feature rather than core functionality. It works
    very well, though, and should be evaluated carefully, if only to see what features
    from it you might want in other tools. By contrast, Consul, etcd, and Zookeeper
    aren’t orchestration tools at all. Instead, they provide the important complement
    to orchestration: service discovery.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到图中有两个看似孤立的区域——Mesos和Consul/etcd/Zookeeper组。Mesos是一个有趣的案例——它在Docker之前就存在了，它对Docker的支持是一个附加功能而不是核心功能。尽管如此，它工作得非常好，应该仔细评估，至少为了看看你可能在其他工具中想要哪些功能。相比之下，Consul、etcd和Zookeeper根本不是编排工具。相反，它们提供了编排的重要补充：服务发现。
- en: This chapter and the next will navigate this orchestration ecosystem. In this
    chapter we’ll introduce tools that give you more fine-grained control and may
    feel like less of a jump coming from managing containers manually. We’ll look
    at managing Docker containers on a single host and across multiple hosts, and
    then at saving and retrieving information about where containers have been deployed.
    Then, in the next chapter, we’ll look at more complete solutions that abstract
    away a lot of the detail.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本章和下一章将导航这个编排生态系统。在本章中，我们将介绍一些工具，这些工具可以让你有更细粒度的控制，并且可能感觉从手动管理容器过渡过来不那么跳跃。我们将查看在单个主机和多个主机上管理Docker容器，然后查看保存和检索容器部署位置信息的方法。然后，在下一章中，我们将查看更完整的解决方案，这些解决方案抽象了很多细节。
- en: As you read these two chapters, it might be helpful to take a step back as you
    come to each orchestration tool and try to come up with a scenario the tool would
    be useful in. This will help clarify whether a particular tool is relevant for
    you. We’ll offer some examples along the way to get you started.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读这两章时，当你遇到每个编排工具时，后退一步，尝试想出一个工具可能有用的场景可能会有所帮助。这将有助于明确某个特定工具对你是否相关。我们将沿途提供一些示例，帮助你开始。
- en: We’ll start slow by turning our gaze inward to a single computer.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从关注单个计算机开始，逐步深入。
- en: 11.1\. Simple single-host Docker
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1\. 简单的单主机Docker
- en: Managing the containers on your local machine can be a painful experience. The
    features provided by Docker for managing long-running containers are relatively
    primitive, and starting up containers with links and shared volumes can be a frustratingly
    manual process.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地机器上管理容器可能是一个痛苦的经历。Docker提供的用于管理长时间运行容器的功能相对原始，使用链接和共享卷启动容器可能是一个令人沮丧的手动过程。
- en: In [chapter 10](kindle_split_021.xhtml#ch10) we looked at using Docker Compose
    to make managing links easier, so we’ll deal with the other pain point now and
    see how the management of long-running containers on a single machine can be made
    more robust.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第10章](kindle_split_021.xhtml#ch10)中，我们探讨了使用Docker Compose来简化链接管理，因此现在我们将解决另一个痛点，看看如何在单台机器上管理长时间运行的容器，使其更加稳健。
- en: '|  |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Managing your host’s containers with systemd**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用systemd管理主机的容器**'
- en: In this technique we’ll take you through setting up a simple Docker service
    with systemd. If you’re already familiar with systemd, this chapter will be relatively
    easy to follow, but we assume no prior knowledge of the tool.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个技术中，我们将带你设置一个简单的Docker服务与systemd。如果你已经熟悉systemd，这一章将相对容易理解，但我们假设你对这个工具没有先前的知识。
- en: Using systemd to control Docker can be useful for a mature company with an operations
    team that prefers to stick to proven technologies that they already understand
    and have the tooling for.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 使用systemd来控制Docker对于拥有运营团队且更喜欢坚持使用他们已经理解和有工具支持的成熟技术的公司来说是有用的。
- en: '**PROBLEM**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You want to manage the running of Docker container services on your host.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你想要管理主机上运行的Docker容器服务。
- en: '**SOLUTION**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Use systemd to manage your container services.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 使用systemd来管理你的容器服务。
- en: systemd is a system-management daemon that replaced SysV init scripts in Fedora
    some time ago. It manages services on your system—everything from mount points
    to processes to one-shot scripts—as individual “units.” It’s growing in popularity
    as it spreads to other distributions and operating systems, though some systems
    (Gentoo being an example at the time of writing) may have problems installing
    and enabling it. It’s worth looking around for experiences other people have had
    with systemd on a setup similar to yours.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: systemd是一个系统管理守护进程，它在Fedora中取代了SysV init脚本。它管理你的系统上的服务——从挂载点到进程到一次性脚本，作为单独的“单元”。随着它传播到其他发行版和操作系统，它越来越受欢迎，尽管一些系统（以写作时的Gentoo为例）可能存在安装和启用它的问题。值得四处寻找其他人对你类似的设置中systemd的经验。
- en: In this technique we’ll demonstrate how the startup of your containers can be
    managed by systemd by running the to-do app from [chapter 1](kindle_split_010.xhtml#ch01).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个技术中，我们将演示如何通过运行第1章中的待办事项应用程序来由systemd管理你的容器的启动。
- en: '**Installing systemd**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**安装systemd**'
- en: If you don’t have systemd on your host system (you can check by running `systemctl
    status` and seeing whether you get a coherent response), you can install it directly
    on your host OS using your standard package manager.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的主机系统上没有systemd（你可以通过运行`systemctl status`来检查，看你是否能得到一个连贯的响应），你可以使用标准的软件包管理器直接在你的主机操作系统上安装它。
- en: If you’re not comfortable interfering with your host system in this way, the
    recommended way to play with it is to use Vagrant to provision a systemd-ready
    VM, as shown in the following listing. We’ll cover it briefly here, but see [appendix
    C](kindle_split_038.xhtml#app03) for more advice on installing Vagrant.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不喜欢以这种方式干扰你的主机系统，推荐的玩法是使用Vagrant来配置一个systemd就绪的虚拟机，如下面的列表所示。我们在这里简要介绍它，但请参阅[附录C](kindle_split_038.xhtml#app03)以获取有关安装Vagrant的更多建议。
- en: Listing 11.1\. A Vagrant setup
  id: totrans-39
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.1.一个Vagrant设置
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '***1*****Creates and enters a new folder**'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*****创建并进入一个新的文件夹**'
- en: '***2*****Initializes the folder for use as a Vagrant environment, specifying
    the Vagrant image**'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*****初始化文件夹以用作Vagrant环境，指定Vagrant镜像**'
- en: '***3*****Brings up the VM**'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*****启动虚拟机**'
- en: '***4*****SSHes into the VM**'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*****SSH连接到虚拟机**'
- en: '|  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: 'At the time of writing, jdiprizio/centos-docker-io is a suitable and available
    VM image. If it’s no longer available when you’re reading this, you can replace
    that string in the preceding listing with another image name. You can search for
    one on HashiCorp’s “Discover Vagrant Boxes” page: [https://app.vagrantup.com/boxes/search](https://app.vagrantup.com/boxes/search)
    (“box” is the terminology Vagrant uses to refer to a VM image). To find this image,
    we searched for “docker centos”. You may need to look up help for the command-line
    `vagrant box add` command to figure out how to download your new VM before attempting
    to start it.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在写作时，jdiprizio/centos-docker-io是一个合适且可用的虚拟机镜像。如果你在阅读时它不再可用，你可以将前面列表中的字符串替换为另一个镜像名称。你可以在HashiCorp的“Discover
    Vagrant Boxes”页面上搜索一个：[https://app.vagrantup.com/boxes/search](https://app.vagrantup.com/boxes/search)（“box”是Vagrant用来指代虚拟机镜像的术语）。为了找到这个镜像，我们搜索了“docker
    centos”。在尝试启动它之前，你可能需要查找有关命令行`vagrant box add`命令的帮助，以了解如何下载你的新虚拟机。
- en: '|  |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Setting up a simple Docker application under systemd**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**在systemd下设置简单的Docker应用程序**'
- en: Now that you have a machine with systemd and Docker on it, we’ll use it to run
    the to-do application from [chapter 1](kindle_split_010.xhtml#ch01).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有一个安装了systemd和Docker的机器，我们将使用它来运行第1章中的待办事项应用程序。
- en: Systemd works by reading configuration files in the simple INI file format.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: systemd通过读取简单的INI文件格式的配置文件来工作。
- en: '|  |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Tip
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 提示
- en: INI files are simple text files with a basic structure composed of sections,
    properties, and values.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: INI文件是简单的文本文件，其基本结构由部分、属性和值组成。
- en: '|  |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: First you need to create a service file as root in /etc/systemd/system/todo.service,
    as shown in the next listing. In this file you tell systemd to run the Docker
    container with the name “todo” on port 8000 on this host.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要以root用户在/etc/systemd/system/todo.service中创建一个服务文件，如下所示。在这个文件中，你告诉systemd在这个主机上以端口8000运行名为“todo”的Docker容器。
- en: Listing 11.2\. /etc/systemd/system/todo.service
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.2\. /etc/systemd/system/todo.service
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '***1*****The Unit section defines generic information about the systemd object.**'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*****单元部分定义了systemd对象的通用信息。**'
- en: '***2*****Starts this unit after the Docker service is started**'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*****在Docker服务启动后启动此单元。**'
- en: '***3*****The Docker service needs to be running for this unit to successfully
    run.**'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*****此单元要成功运行，Docker服务必须正在运行。**'
- en: '***4*****The Service section defines the configuration information specific
    to systemd service unit types.**'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*****服务部分定义了特定于systemd服务单元类型的配置信息。**'
- en: '***5*****If the service terminates, always restarts it.**'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*****如果服务终止，总是重新启动它。**'
- en: '***6*****If the service termExecStartPre defines a command that will be run
    before the unit is started. To ensure the container is removed before you start
    it, you remove it with prejudice here.inates, always restarts it.**'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6*****如果服务termExecStartPre定义了一个在单元启动前运行的命令。为了确保在启动之前删除容器，你在这里可以毫不犹豫地删除它。**'
- en: '***7*****Makes sure the image is downloaded before you run the container**'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7*****确保在运行容器之前已下载镜像。**'
- en: '***8*****ExecStart defines the command to be run when the service is started.**'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8*****ExecStart定义了在服务启动时运行的命令。**'
- en: '***9*****ExecStop defines the command to be run when the service is stopped.**'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9*****ExecStop定义了在服务停止时运行的命令。**'
- en: '***10*****The Install section contains information for systemd when enabling
    the unit.**'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***10*****安装部分包含systemd启用单元时的信息。**'
- en: '***11*****Informs systemd that you want this unit to be started when it enters
    the multi-user target stage**'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***11*****通知systemd，当它进入多用户目标阶段时，你想启动此单元。**'
- en: This configuration file should make it clear that systemd offers a simple declarative
    schema for managing processes, leaving the details of dependency management up
    to the systemd service. This doesn’t mean that you can ignore the details, but
    it does put a lot of tools at your disposal for managing Docker (and other) processes.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置文件应明确指出systemd提供了一种简单的声明性模式来管理进程，将依赖关系管理的细节留给systemd服务。这并不意味着你可以忽略细节，但它确实为你提供了大量管理Docker（和其他）进程的工具。
- en: '|  |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-72
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: Docker doesn’t set any container restart policies by default, but be aware that
    any you set will conflict with most process managers. Don’t set restart policies
    if you’re using a process manager.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Docker默认不设置任何容器重启策略，但请注意，你设置的任何策略都将与大多数进程管理器冲突。如果你正在使用进程管理器，请不要设置重启策略。
- en: '|  |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Enabling a new unit is just a matter of invoking the `systemctl enable` command.
    If you want this unit to start automatically when the system boots, you can also
    create a symlink in the multi-user.target.wants systemd directory. Once done,
    you can start the unit with `systemctl start`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 启用新单元只需调用`systemctl enable`命令。如果你想在这个单元启动时自动启动系统，你还可以在multi-user.target.wants
    systemd目录中创建一个符号链接。一旦完成，你可以使用`systemctl start`启动单元。
- en: '[PRE2]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Then just wait for it to start. If there’s a problem, you’ll be informed.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然后只需等待它启动。如果有问题，你会得到通知。
- en: 'To check that all is OK, use the `systemctl status` command. It will print
    out some general information about the unit, such as how long it’s been running
    and the process ID, followed by a number of log lines from the process. In this
    case, seeing `Swarm server started port 8000` is a good sign:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查一切是否正常，请使用`systemctl status`命令。它将打印出有关单元的一些一般信息，例如运行时间长短和进程ID，然后是来自进程的若干日志行。在这种情况下，看到`Swarm服务器启动端口8000`是一个好兆头：
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can now visit the server on port 8000.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以访问端口8000上的服务器。
- en: '**DISCUSSION**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: The principles in this technique can be applied to more than just systemd—most
    process managers, including other init systems, can be configured in a similar
    way. If you’re interested, you could leverage this to replace existing services
    running on your system (perhaps a PostgreSQL database) with dockerized ones.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术中的原则可以应用于不仅仅是systemd——大多数进程管理器，包括其他init系统，都可以以类似的方式进行配置。如果你感兴趣，你可以利用这一点来替换系统上运行的现有服务（可能是一个PostgreSQL数据库）的docker化版本。
- en: In the next technique, we’ll take this further by implementing in systemd the
    SQLite server we created in [technique 77](kindle_split_021.xhtml#ch10sb03).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个技术中，我们将进一步在systemd中实现我们在[技术77](kindle_split_021.xhtml#ch10sb03)中创建的SQLite服务器。
- en: '|  |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '|  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Orchestrating the startup of your host’s containers**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**编排宿主机的容器启动**'
- en: Unlike docker-compose (at the time of writing), systemd is a mature technology
    ready for production. In this technique we’ll show you how to achieve local orchestration
    functionality that’s similar to docker-compose using systemd.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 与docker-compose（截至写作时）不同，systemd是一种成熟的技术，适用于生产。在这个技术中，我们将向你展示如何使用systemd实现类似于docker-compose的本地编排功能。
- en: '|  |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: If you run into trouble with this technique, you may need to upgrade your version
    of Docker. Version 1.7.0 or greater should work fine.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遇到这个技术的问题，你可能需要升级你的Docker版本。版本1.7.0或更高版本应该可以正常工作。
- en: '|  |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**PROBLEM**'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You want to manage more complex container orchestration on one host in production.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你想在生产环境中在一个主机上管理更复杂的容器编排。
- en: '**SOLUTION**'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Use systemd with dependent services to manage your containers.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用具有依赖服务的systemd来管理你的容器。
- en: To demonstrate the use of systemd for a more complex scenario, we’re going to
    re-implement the SQLite TCP server example from [technique 77](kindle_split_021.xhtml#ch10sb03)
    in systemd. [Figure 11.2](#ch11fig02) illustrates the dependencies for our planned
    systemd service unit configuration.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示在更复杂场景下使用systemd的方法，我们将重新实现来自[技术77](kindle_split_021.xhtml#ch10sb03)的SQLite
    TCP服务器示例，并在systemd中实现。![图11.2](#ch11fig02)展示了我们计划中的systemd服务单元配置的依赖关系。
- en: Figure 11.2\. systemd unit dependency graph
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.2\. systemd单元依赖关系图
- en: '![](Images/11fig02_alt.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/11fig02_alt.jpg)'
- en: This is a similar schema to what you saw with the Docker Compose example in
    [technique 77](kindle_split_021.xhtml#ch10sb03). A key difference here is that
    rather than the SQLite service being treated as a single monolithic entity, each
    container is a discrete entity. In this scenario, the SQLite proxy can be stopped
    independently of the SQLite server.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这与你在[技术77](kindle_split_021.xhtml#ch10sb03)中看到的Docker Compose示例中的架构类似。这里的一个关键区别是，而不是将SQLite服务视为一个单一的单一实体，每个容器都是一个独立的实体。在这个场景中，SQLite代理可以独立于SQLite服务器停止。
- en: Here’s the listing for the SQLite server service. As before, it depends on the
    Docker service, but it has a couple of differences from the to-do example in the
    previous technique.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这是SQLite服务器服务的列表。和之前一样，它依赖于Docker服务，但与之前技术中的待办示例有一些不同。
- en: Listing 11.3\. /etc/systemd/system/sqliteserver.service
  id: totrans-101
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.3\. /etc/systemd/system/sqliteserver.service
- en: '[PRE4]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '***1*****The Unit section defines generic information about the systemd object.**'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*****单元部分定义了systemd对象的一般信息。**'
- en: '***2*****Starts this unit after the Docker service is started**'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*****在Docker服务启动后启动此单元**'
- en: '***3*****The Docker service needs to be running for this unit to successfully
    run.**'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*****此单元要成功运行，Docker服务必须正在运行。**'
- en: '***4*****These lines ensure that the SQLite database files exist before the
    service starts up. The dash before the touch command indicates to systemd that
    startup should fail if the command returns an error code.**'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*****这些行确保在服务启动之前SQLite数据库文件存在。touch命令前的破折号表示systemd，如果命令返回错误代码，则启动应失败。**'
- en: '***5*****ExecStartPre defines a command that will be run before the unit is
    started. To ensure the container is removed before you start it, you remove it
    with prejudice here.**'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*****ExecStartPre定义了在单元启动之前要运行的命令。为了确保在启动容器之前将其删除，你在这里有偏见地删除它。**'
- en: '***6*****Makes sure the image is downloaded before you run the container**'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6*****确保在运行容器之前下载了镜像**'
- en: '***7*****ExecStart defines the command to be run when the service is started.
    Note that we’ve wrapped the socat command in a “/bin/bash -c” call to avoid confusion,
    as the ExecStart line is run by systemd.**'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7*****ExecStart定义了服务启动时要运行的命令。请注意，我们将socat命令包装在“/bin/bash -c”调用中，以避免混淆，因为ExecStart行是由systemd运行的。**'
- en: '***8*****ExecStop defines the command to be run when the service is stopped.**'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8*****ExecStop定义了服务停止时要运行的命令。**'
- en: '|  |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Tip
  id: totrans-112
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 小贴士
- en: Paths must be absolute in systemd.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在systemd中，路径必须是绝对路径。
- en: Now comes the listing for the SQLite proxy service. The key difference here
    is that the proxy service depends on the server process you just defined, which
    in turn depends on the Docker service.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是SQLite代理服务的列表。这里的关键区别在于代理服务依赖于你刚刚定义的服务进程，而这个服务进程又依赖于Docker服务。
- en: '|  |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Listing 11.4\. /etc/systemd/system/sqliteproxy.service
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.4\. /etc/systemd/system/sqliteproxy.service
- en: '[PRE5]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '***1*****The proxy unit must run after the sqliteserver service defined previously.**'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*****代理单元必须在之前定义的sqliteserver服务之后运行。**'
- en: '***2*****The proxy requires that the server instance be running before you
    start it up.**'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*****代理要求在启动之前服务器实例必须正在运行。**'
- en: '***3*****Runs the container**'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*****运行容器**'
- en: 'With these two configuration files, we’ve laid the groundwork for installing
    and running the SQLite service under systemd’s control. Now we can enable these
    services:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两个配置文件，我们已经为在systemd的控制下安装和运行SQLite服务奠定了基础。现在我们可以启用这些服务：
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And start them up:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 并启动它们：
- en: '[PRE7]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that because the SQLite proxy service depends on the SQLite server service
    to run, you only need to start the proxy—the dependencies get started automatically.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于SQLite代理服务依赖于SQLite服务器服务来运行，你只需要启动代理——依赖项会自动启动。
- en: '**DISCUSSION**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: One of the challenges when administering a long-running application on a local
    machine is the management of dependency services. For example, a web application
    might expect to be running in the background as a service but might also depend
    on a database and a web server. This may sound familiar—you covered a web-app-db
    structure in [technique 13](kindle_split_013.xhtml#ch03sb04).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地机器上管理长期运行的应用程序时面临的挑战之一是依赖服务的管理。例如，一个Web应用程序可能期望作为服务在后台运行，但也可能依赖于数据库和Web服务器。这可能听起来很熟悉——你在[技术13](kindle_split_013.xhtml#ch03sb04)中覆盖了Web-app-db结构。
- en: '[Technique 76](kindle_split_021.xhtml#ch10sb02) showed how to set up this kind
    of structure with dependencies and so on, but tools like systemd have been working
    on this problem for a while and may offer flexibility that Docker Compose doesn’t.
    For example, once you’ve written your service files, you can start any of them
    you want, and systemd will handle starting up any dependent services, even starting
    the Docker daemon itself if necessary.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[技术76](kindle_split_021.xhtml#ch10sb02)展示了如何使用依赖关系等设置这种结构，但像systemd这样的工具已经在这个问题上工作了一段时间，并且可能提供Docker
    Compose不提供的灵活性。例如，一旦你写好了服务文件，你可以启动你想要的任何一个，systemd将处理启动任何依赖服务，甚至在必要时启动Docker守护进程本身。'
- en: '|  |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 11.2\. Manual multi-host Docker
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2\. 手动多主机Docker
- en: Now that you’re comfortable with some fairly complicated arrangements of Docker
    containers on a machine, it’s time to think bigger—let’s move on to the world
    of multiple hosts to enable us to use Docker on a larger scale.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经熟悉了在机器上一些相当复杂的Docker容器排列，是时候考虑更宏大的目标了——让我们进入多主机世界，以便我们能够在更大规模上使用Docker。
- en: In the rest of this chapter, you’re going to manually run a multi-host environment
    with Helios to introduce you to multi-host Docker concepts. In the next chapter,
    you’ll see more automated and sophisticated ways to achieve the same result and
    more.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分，你将手动使用Helios运行一个多主机环境，以介绍你多主机Docker的概念。在下一章，你将看到更多自动化和复杂的方法来实现相同的结果以及更多。
- en: '|  |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Manual multi-host Docker with Helios**'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用Helios手动多主机Docker**'
- en: It can be intimidating to hand over all control of provisioning a group of machines
    to an application, so it doesn’t hurt to ease yourself in with a more manual approach.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 将一组机器的所有控制权交给一个应用程序可能会让人感到害怕，所以用更手动的方法慢慢适应是有好处的。
- en: Helios is ideal for companies that have mostly static infrastructures and are
    interested in using Docker for their critical services but (understandably) want
    human oversight in the process.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些大部分基础设施都是静态的，并且对使用Docker运行关键服务感兴趣但（可以理解地）希望在过程中有人监督的公司来说，Helios是理想的。
- en: '**PROBLEM**'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You want to be able to provision multiple Docker hosts with containers but retain
    manual control over what runs where.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 你希望能够用容器配置多个Docker主机，但仍然保留对运行位置的手动控制。
- en: '**SOLUTION**'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Use the Helios tool from Spotify to precisely manage containers on other hosts.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Spotify的Helios工具来精确管理其他主机上的容器。
- en: Helios is the tool Spotify currently uses to manage their servers in production,
    and it has the pleasing property of being both easy to get started with and stable
    (as you’d hope). Helios allows you to manage the deployment of Docker containers
    across multiple hosts. It gives you a single command-line interface that you can
    use to specify what you want to run and where to run it, as well as the ability
    to take a look at the current state of play.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Helios 是 Spotify 目前用于在生产环境中管理服务器的一个工具，它有一个令人愉悦的特性，那就是易于上手且稳定（正如你所期望的）。Helios
    允许你管理跨多个主机的 Docker 容器的部署。它提供了一个单行命令界面，你可以使用它来指定你想要运行的内容以及运行的位置，以及查看当前状态的权限。
- en: Because we’re just introducing Helios, we’re going to run everything on a single
    node inside Docker for simplicity—don’t worry, anything relevant to running on
    multiple hosts will be clearly highlighted. The high-level architecture of Helios
    is outlined in [figure 11.3](#ch11fig03).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只是介绍 Helios，我们将为了简单起见在 Docker 内的单个节点上运行一切——请不要担心，任何与在多个主机上运行相关的内容都将被清楚地突出显示。Helios
    的高层次架构在[图 11.3](#ch11fig03)中概述。
- en: Figure 11.3\. A birds-eye view of a Helios installation
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.3\. Helios 安装的鸟瞰图
- en: '![](Images/11fig03_alt.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![Images/11fig03_alt.jpg]'
- en: 'As you can see, there’s only one additional service required when running Helios:
    Zookeeper. Helios uses Zookeeper to track the state of all of your hosts and as
    a communication channel between the masters and agents.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，运行 Helios 时只需要一个额外的服务：Zookeeper。Helios 使用 Zookeeper 来跟踪所有主机的状态，并在主节点和代理节点之间作为通信通道。
- en: '|  |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Tip
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 小贴士
- en: Zookeeper is a lightweight distributed database written in Java that’s optimized
    for storing configuration information. It’s part of the Apache suite of open source
    software products. It’s similar in functionality to etcd (which you learned about
    in [chapter 9](kindle_split_020.xhtml#ch09), and which you’ll see again in this
    chapter).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: Zookeeper 是一个用 Java 编写的轻量级分布式数据库，它针对存储配置信息进行了优化。它是 Apache 开源软件产品套件的一部分。它在功能上与
    etcd（你可以在第 9 章[chapter 9](kindle_split_020.xhtml#ch09)中了解到，本章你还将再次看到）相似。
- en: '|  |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: All you need to know for this technique is that Zookeeper stores data such that
    it can be distributed across multiple nodes (for both scalability and reliability)
    by running multiple Zookeeper instances. This may sound familiar to our description
    of etcd in [chapter 9](kindle_split_020.xhtml#ch09)—these two tools have significant
    overlap.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这项技术，你需要知道的是 Zookeeper 以一种方式存储数据，使得可以通过运行多个 Zookeeper 实例将其分布到多个节点上（既为了可扩展性也为了可靠性）。这听起来可能与我们第
    9 章[chapter 9](kindle_split_020.xhtml#ch09)中对 etcd 的描述相似——这两个工具有显著的相似之处。
- en: 'To start the single Zookeeper instance we’ll use in this technique, run the
    following command:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动我们将在这项技术中使用的单个 Zookeeper 实例，请运行以下命令：
- en: '[PRE8]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '|  |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-154
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: When starting a Zookeeper instance on its own node, you’ll want to expose ports
    to make it accessible to other hosts and use volumes to persist data. Take a look
    at the Dockerfile on the Docker Hub for details about which ports and folders
    you should use ([https://hub.docker.com/r/jplock/zookeeper/~/dockerfile/](https://hub.docker.com/r/jplock/zookeeper/~/dockerfile/)).
    It’s also likely you’ll want to run Zookeeper on multiple nodes, but configuring
    a Zookeeper cluster is beyond the scope of this technique.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当在一个单独的节点上启动 Zookeeper 实例时，你将想要暴露端口以便其他主机可以访问，并使用卷来持久化数据。查看 Docker Hub 上的 Dockerfile
    获取有关应使用哪些端口和文件夹的详细信息([https://hub.docker.com/r/jplock/zookeeper/~/dockerfile/](https://hub.docker.com/r/jplock/zookeeper/~/dockerfile/))。你也可能想在多个节点上运行
    Zookeeper，但配置 Zookeeper 集群超出了这项技术的范围。
- en: '|  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: You can inspect the data Zookeeper has stored by using the zkCli.sh tool, either
    interactively or by piping input to it. The initial startup is quite chatty, but
    it’ll drop you into an interactive prompt where you can run commands against the
    file-tree-like structure Zookeeper stores data in.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 zkCli.sh 工具检查 Zookeeper 存储的数据，无论是交互式地还是通过管道输入到它。初始启动时相当健谈，但它会带你进入一个交互式提示，你可以在其中运行针对
    Zookeeper 存储数据的类似文件树结构的命令。
- en: '[PRE9]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Nothing’s running against Zookeeper yet, so the only thing currently being stored
    is some internal Zookeeper information. Leave this prompt open, and we’ll revisit
    it as we progress.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 目前还没有任何进程针对 Zookeeper 运行，所以目前存储的只有一些内部 Zookeeper 信息。请保持此提示打开，随着我们的进展我们将重新访问它。
- en: 'Helios itself is split into three parts:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Helios 本身分为三个部分：
- en: '*The master*—This is used as an interface for making changes in Zookeeper.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*主节点*——这是用于在 Zookeeper 中进行更改的接口。'
- en: '*The agent*—This runs on every Docker host, starts and stops containers based
    on Zookeeper, and reports state back.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*代理*——这个代理在每个Docker主机上运行，根据Zookeeper启动和停止容器，并将状态信息反馈回来。'
- en: '*The command-line tools*—These are used to make requests to the master.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*命令行工具*——这些工具用于向主节点发送请求。'
- en: '[Figure 11.4](#ch11fig04) shows how the final system is strung together when
    we perform an operation against it (the arrows indicate data flow).'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11.4](#ch11fig04)展示了当我们对其执行操作时，最终系统是如何连接在一起的（箭头指示数据流）。'
- en: Figure 11.4\. Starting a container on a single-host Helios installation
  id: totrans-165
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.4\. 在单主机Helios安装上启动容器
- en: '![](Images/11fig04_alt.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/11fig04_alt.jpg)'
- en: 'Now that Zookeeper is running, it’s time to start Helios. We need to run the
    master while specifying the IP address of the Zookeeper node we started earlier:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在Zookeeper已经启动，是时候启动Helios了。我们需要在指定我们之前启动的Zookeeper节点IP地址的情况下运行主节点：
- en: '[PRE10]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now let’s see what’s new in Zookeeper:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看Zookeeper中有什么新变化：
- en: '[PRE11]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: It looks like the Helios master has created a bunch of new pieces of configuration,
    including registering itself as a master. Unfortunately we don’t have any hosts
    yet.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来Helios主节点创建了一系列新的配置项，包括将自己注册为主节点。不幸的是，我们目前还没有任何主机。
- en: 'Let’s solve this by starting up an agent that will use the current host’s Docker
    socket to start containers on:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过启动一个代理来解决这个问题，该代理将使用当前主机的Docker套接字在以下位置启动容器：
- en: '[PRE12]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Again, let’s check back in Zookeeper:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，让我们回到Zookeeper查看：
- en: '[PRE13]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You can see here that `/status/hosts` now contains one item. Descending into
    the Zookeeper directory for the host reveals the internal information Helios stores
    about the host.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，`/status/hosts`现在包含一个条目。进入主机对应的Zookeeper目录，可以揭示Helios存储的主机内部信息。
- en: '|  |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: When running on multiple hosts, you’ll want to pass `--name $(hostname -f)`
    as an argument to both the Helios master and agent. You’ll also need to expose
    ports 5801 and 5802 for the master and 5803 and 5804 for the agent.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 当在多个主机上运行时，您需要将`--name $(hostname -f)`作为参数传递给Helios主节点和代理。您还需要为主节点暴露端口5801和5802，为代理暴露端口5803和5804。
- en: '|  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'Let’s make it a bit easier to interact with Helios:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使与Helios的交互更加简单：
- en: '[PRE14]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The preceding alias means that invoking `helios` will start a throwaway container
    to perform the action you want, pointing at the correct Helios cluster to begin
    with. Note that the command-line interface needs to be pointed at the Helios master
    rather than Zookeeper.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的别名意味着调用`helios`将启动一个临时容器来执行您想要的操作，并首先指向正确的Helios集群。请注意，命令行界面需要指向Helios主节点而不是Zookeeper。
- en: Everything is now set up. We’re able to easily interact with our Helios cluster,
    so it’s time to try an example.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都已经设置好了。我们能够轻松地与我们的Helios集群交互，所以现在是时候尝试一个示例了。
- en: '[PRE15]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Helios is built around the concept of *jobs*—everything to be executed must
    be expressed as a job before it can be sent to a host to be executed. At a minimum,
    you need an image with the basics Helios needs to know to start the container:
    a command to execute and any port, volume, or environment options. You may also
    want a number of other advanced options, including health checks, expiry dates,
    and service registration.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Helios围绕*作业*的概念构建——在将任务发送到主机执行之前，必须将所有要执行的内容表达为作业。至少，您需要一个包含Helios启动容器所需的基本信息的镜像：要执行的命令以及任何端口、卷或环境选项。您可能还希望使用一些其他高级选项，包括健康检查、过期日期和服务注册。
- en: The previous command creates a job that will listen on port 8080, print “hello”
    to the first thing that connects to the port, and then terminate.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的命令创建了一个将在端口8080上监听、打印“hello”给第一个连接到端口的实体，然后终止的任务。
- en: 'You can use `helios hosts` to list hosts available for job deployment, and
    then actually perform the deployment with `helios deploy`. The `helios status`
    command then shows us that the job has successfully started:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`helios hosts`列出可用于作业部署的主机，然后使用`helios deploy`实际执行部署。然后`helios status`命令显示作业已成功启动：
- en: '[PRE16]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Of course, we now want to verify that the service works:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们现在想验证服务是否正常工作：
- en: '[PRE17]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The result of `curl` clearly tells us that the service is working, but `helios
    status` is now showing something interesting. When defining the job, we noted
    that after serving “hello”, the job would terminate, but the preceding output
    shows a `PULLING_IMAGE` status. This is down to how Helios manages jobs—once you’ve
    deployed to a host, Helios will do its best to keep the job running. The status
    you can see here is Helios going through the complete job startup process, which
    happens to involve ensuring the image is pulled.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`curl` 的结果清楚地告诉我们服务正在运行，但现在 `helios status` 显示了一些有趣的内容。在定义作业时，我们注意到在服务“hello”之后，作业将终止，但前面的输出显示了一个
    `PULLING_IMAGE` 状态。这是由于 Helios 管理作业的方式——一旦你部署到主机上，Helios 将尽力保持作业运行。你在这里看到的状态是
    Helios 正在完成完整的作业启动过程，这恰好涉及到确保图像被拉取。'
- en: Finally, we need to clear up after ourselves.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要清理自己的事情。
- en: '[PRE18]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We asked for the job to be removed from all nodes (terminating it if necessary,
    and stopping any more automatic restarts), and then we deleted the job itself,
    meaning it can’t be deployed to any more nodes.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要求将作业从所有节点中移除（如果需要，终止它并停止任何更多的自动重启），然后我们删除了作业本身，这意味着它不能再部署到任何其他节点。
- en: '**DISCUSSION**'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: Helios is a simple and reliable way of deploying your containers to multiple
    hosts. Unlike a number of techniques we’ll come to later on, there’s no magic
    going on behind the scenes to determine appropriate locations—Helios starts containers
    exactly where you want them with minimal fuss.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Helios 是将你的容器部署到多个主机的一种简单且可靠的方式。与我们在后面将要讨论的许多技术不同，背后没有魔法来确定适当的位置——Helios 以最小的麻烦在你想放置容器的确切位置启动容器。
- en: But this simplicity comes at a cost once you move to more advanced deployment
    scenarios—features like resource limits, dynamic scaling, and so on are currently
    missing, so you may find yourself reinventing parts of tools like Kubernetes ([technique
    88](kindle_split_024.xhtml#ch12sb03)) to achieve the behavior you want in your
    deployment.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 但这种简单性一旦你转移到更高级的部署场景中就会付出代价——像资源限制、动态扩展等功能目前都缺失，因此你可能发现自己需要重新发明部分像 Kubernetes
    ([技术 88](kindle_split_024.xhtml#ch12sb03)) 这样的工具来达到你想要的部署行为。
- en: '|  |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '11.3\. Service discovery: What have we here?'
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3. 服务发现：这里有什么？
- en: This chapter’s introduction referred to service discovery as the flip side of
    orchestration—being able to deploy your applications to hundreds of different
    machines is fine, but if you can’t then find out which applications are located
    where, you won’t be able to actually *use* them.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的引言将服务发现称为编排的另一方面——能够将你的应用程序部署到数百台不同的机器上是没有问题的，但如果你无法找出哪些应用程序位于何处，你就无法真正*使用*它们。
- en: Although it’s not nearly as saturated an area as orchestration, the service-discovery
    field still has a number of competitors. It doesn’t help that they all offer slightly
    different feature sets.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它不像编排那样饱和，但服务发现领域仍然有许多竞争对手。它们都提供略微不同的功能集并不利于这一领域。
- en: 'There are two pieces of functionality that are typically desirable when it
    comes to service discovery: a generic key/value store and a way of retrieving
    service endpoints via some convenient interface (likely DNS). etcd and Zookeeper
    are examples of the former, whereas SkyDNS (a tool we won’t go into) is an example
    of the latter. In fact, SkyDNS uses etcd to store the information it needs.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务发现方面，通常有两个功能是人们所期望的：一个通用的键/值存储和一个通过某些方便的接口（可能是 DNS）检索服务端点的方法。etcd 和 Zookeeper
    是前者的例子，而 SkyDNS（我们不会深入探讨的工具）是后者的例子。实际上，SkyDNS 使用 etcd 来存储它所需的信息。
- en: '|  |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Using Consul to discover services**'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 Consul 来发现服务**'
- en: 'etcd is a highly popular tool, but it does have one particular competitor that
    gets mentioned alongside it a lot: Consul. This is a little strange, because there
    are other tools more similar to etcd (Zookeeper has a similar feature set to etcd
    but is implemented in a different language), whereas Consul differentiates itself
    with some interesting additional features, like service discovery and health checks.
    In fact, if you squint, Consul might look a bit like etcd, SkyDNS, and Nagios
    all in one.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: etcd 是一个非常流行的工具，但它确实有一个特定的竞争对手经常被提及：Consul。这有点奇怪，因为还有其他工具与 etcd 更相似（Zookeeper
    与 etcd 有相似的功能集，但实现语言不同），而 Consul 通过一些有趣的功能来区分自己，如服务发现和健康检查。实际上，如果你眯起眼睛，Consul
    可能看起来有点像 etcd、SkyDNS 和 Nagios 的结合体。
- en: '**PROBLEM**'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You need to be able to distribute information to, discover services within,
    and monitor a collection of containers.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要能够分发信息到、在容器内发现服务以及监控一组容器。
- en: '**SOLUTION**'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Start a container with Consul on each Docker host to provide a service directory
    and configuration communication system.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个Docker主机上启动带有Consul的容器，以提供服务目录和配置通信系统。
- en: 'Consul tries to be a generic tool for doing some important tasks required when
    you need to coordinate a number of independent services. These tasks can be performed
    by other tools, but configuring them in one place can be useful. From a high level,
    Consul provides the following:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Consul试图成为一个通用的工具，用于执行在需要协调多个独立服务时所需的一些重要任务。这些任务可以通过其他工具执行，但在一个地方配置它们可能很有用。从高层次来看，Consul提供以下功能：
- en: '*Service configuration*—A key/value store for storing and sharing small values,
    like etcd and Zookeeper'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*服务配置*—一个用于存储和共享小值的键/值存储，例如etcd和Zookeeper'
- en: '*Service discovery*—An API for registering services and a DNS endpoint for
    discovering them, like SkyDNS'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*服务发现*—一个用于注册服务的API和一个用于发现它们的DNS端点，例如SkyDNS'
- en: '*Service monitoring*—An API for registering health checks, like Nagios'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*服务监控*—一个用于注册健康检查的API，例如Nagios'
- en: You can use all, some, or one of these features, as there’s no tie-in. If you
    have existing monitoring infrastructure, there’s no need to replace that with
    Consul.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用所有、一些或其中之一的功能，因为没有绑定。如果您有现有的监控基础设施，就没有必要用Consul替换它。
- en: This technique will cover the service-discovery and service-monitoring aspects
    of Consul, but not key/value storage. The strong similarities between etcd and
    Consul in this aspect make the two final techniques in [chapter 9](kindle_split_020.xhtml#ch09)
    ([techniques 74](kindle_split_020.xhtml#ch09sb06) and [75](kindle_split_020.xhtml#ch09sb07))
    transferrable with some perusal of the Consul documentation.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这个技术将涵盖Consul的服务发现和服务监控方面，但不涉及键/值存储。在这一点上，etcd和Consul之间有很强的相似性，使得[第9章](kindle_split_020.xhtml#ch09)中的最后两个技术（[技术74](kindle_split_020.xhtml#ch09sb06)和[75](kindle_split_020.xhtml#ch09sb07)）在阅读Consul文档后可以相互转换。
- en: '[Figure 11.5](#ch11fig05) shows a typical Consul setup.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11.5](#ch11fig05) 展示了一个典型的Consul配置。'
- en: Figure 11.5\. A typical Consul setup
  id: totrans-218
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.5\. 一个典型的Consul配置
- en: '![](Images/11fig05_alt.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/11fig05_alt.jpg)'
- en: The data stored in Consul is the responsibility of *server* agents. These are
    responsible for forming a *consensus* on the information stored—this concept is
    present in most distributed data-storage systems. In short, if you lose under
    half of your server agents, you’re guaranteed to be able to recover your data
    (see an example of this with etcd in [technique 74](kindle_split_020.xhtml#ch09sb06)).
    Because these servers are so important and have greater resource requirements,
    keeping them on dedicated machines is a typical choice.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 存储在Consul中的数据是*服务器*代理的责任。这些代理负责对存储的信息达成*共识*——这一概念存在于大多数分布式数据存储系统中。简而言之，如果您丢失了不到一半的服务器代理，您有保证能够恢复您的数据（参见[技术74](kindle_split_020.xhtml#ch09sb06)中关于etcd的示例）。因为这些服务器非常重要并且有更高的资源需求，将它们放在专用机器上是一个典型的选择。
- en: '|  |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: Although the commands in this technique will leave the Consul data directory
    (/data) inside the container, it’s generally a good idea to specify this directory
    as a volume for at least the servers, so you can keep backups.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个技术中的命令将把Consul数据目录（/data）留在容器内，但通常将此目录指定为至少服务器的卷是一个好主意，这样您可以保留备份。
- en: '|  |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: It’s recommended that all machines under your control that may want to interact
    with Consul should run a client agent. These agents forward requests on to the
    servers and run health checks.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 建议您控制的所有可能希望与Consul交互的机器都应该运行一个客户端代理。这些代理将请求转发到服务器并运行健康检查。
- en: 'The first step in getting Consul running is to start a server agent:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 启动Consul的第一步是启动一个服务器代理：
- en: '[PRE19]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Because we want to use Consul as a DNS server, we’ve inserted a file into the
    folder Consul reads the configuration from to request it listen on port 53 (the
    registered port for the DNS protocol). We’ve then used a command sequence you
    may recognize from earlier techniques to try to find the external-facing IP address
    of the machine for both communicating with other agents and listening for client
    requests.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们想将Consul用作DNS服务器，所以我们已将一个文件插入到Consul读取配置的文件夹中，以请求它监听端口53（DNS协议的注册端口）。然后我们使用您可能从早期技术中认识到的命令序列来尝试找到机器的外部IP地址，以便与其他代理通信并监听客户端请求。
- en: '|  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-230
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: The IP address `0.0.0.0` is typically used to indicate that an application should
    listen on all available interfaces on the machine. We’ve deliberately not done
    this, because some Linux distributions have a DNS-caching daemon listening on
    `127.0.0.1`, which disallows listening on `0.0.0.0:53`.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: IP地址`0.0.0.0`通常用于指示应用程序应在机器上的所有可用接口上监听。我们故意没有这样做，因为一些Linux发行版有一个监听在`127.0.0.1`的DNS缓存守护进程，这禁止在`0.0.0.0:53`上监听。
- en: '|  |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'There are three items of note in the preceding `docker run` command:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的`docker run`命令中有三个值得注意的事项：
- en: We’ve used `--net host`. Although this can be seen as a faux pas in the Docker
    world, the alternative is to expose up to eight ports on the command line—it’s
    a matter of personal preference, but we feel it’s justified here. It also helps
    bypass a potential issue with UDP communication. If you were to go the manual
    route, there’d be no need to set the DNS port—you could expose the default Consul
    DNS port (8600) as port 53 on the host.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用了`--net host`。虽然在Docker世界中这可能会被视为一个错误，但替代方案是在命令行上暴露多达八个端口——这是一个个人偏好的问题，但我们认为在这里是合理的。它还有助于绕过一个潜在的UDP通信问题。如果你选择手动操作，则不需要设置DNS端口——你可以将默认的Consul
    DNS端口（8600）在主机上暴露为端口53。
- en: The two `recursor` arguments tell Consul what DNS servers to look at if a requested
    address is unknown by Consul itself.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个`recursor`参数告诉Consul在请求的地址由Consul本身未知时，应该查看哪些DNS服务器。
- en: The `-bootstrap-expect 1` argument means the Consul cluster will start operating
    with only one agent, which is not robust. A typical setup would set this to 3
    (or more) to make sure the cluster doesn’t start until the required number of
    servers has joined. To start the additional server agents, add a `-join` argument,
    as we’ll discuss when we start a client.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-bootstrap-expect 1`参数意味着Consul集群将仅用一个代理启动，这并不稳健。典型的设置会将此设置为3（或更多），以确保集群在所需数量的服务器加入之前不会启动。要启动额外的服务器代理，请添加一个`-join`参数，正如我们将在启动客户端时讨论的那样。'
- en: Now let’s go to a second machine, start a client agent, and add it to our cluster.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们转到第二台机器，启动一个客户端代理，并将其添加到我们的集群中。
- en: '**warning** Because Consul expects to be able to listen on a particular set
    of ports when communicating with other agents, it’s tricky to set up multiple
    agents on a single machine while still demonstrating how it would work in the
    real world. We’ll use a different host now—if you decide to use an IP alias, ensure
    you pass a `-node newAgent`, because by default the hostname will be used, which
    will conflict.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告** 由于Consul期望在与其他代理通信时能够监听特定的端口集，因此在单个机器上设置多个代理同时展示其在现实世界中的工作方式是有些棘手的。我们现在将使用不同的主机——如果你决定使用IP别名，请确保传递一个`-node
    newAgent`，因为默认情况下将使用主机名，这可能会产生冲突。'
- en: '[PRE20]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '|  |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-241
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: The images we’ve used are based on gliderlabs/consul-server:0.5 and gliderlabs/consul-agent:0.5,
    and they come with a newer version of Consul to avoid possible problems with UDP
    communication, indicated by the constant logging of lines like “Refuting a suspect
    message.” When version 0.6 of the images is released, you can switch back to the
    images from gliderlabs.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的镜像基于gliderlabs/consul-server:0.5和gliderlabs/consul-agent:0.5，并包含一个Consul的新版本，以避免UDP通信中可能出现的“Refuting
    a suspect message”等日志记录的潜在问题。当镜像的0.6版本发布时，你可以切换回gliderlabs的镜像。
- en: '|  |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: All client services (HTTP, DNS, and so on) have been configured to listen on
    the Docker bridge IP address. This gives containers a known location from which
    they can retrieve information from Consul, and it only exposes Consul internally
    on the machine, forcing other machines to directly access the server agents rather
    than taking a slower route via a client agent to a server agent. To ensure the
    bridge IP address is consistent across all your hosts, you can look at the `--bip`
    argument to the Docker daemon.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 所有客户端服务（HTTP、DNS等）都已配置为在Docker桥接IP地址上监听。这为容器提供了一个已知的位置，它们可以从Consul检索信息，并且它只在机器内部暴露Consul，迫使其他机器直接访问服务器代理，而不是通过客户端代理到服务器代理的较慢路径。为确保桥接IP地址在所有主机上保持一致，你可以查看Docker守护进程的`--bip`参数。
- en: As before, we’ve found the external IP address and bound cluster communication
    to it. The `-join` argument tells Consul where to initially look to find the cluster.
    Don’t worry about micromanaging the cluster formation—when two agents initially
    meet each other, they’ll *gossip*, transferring information about finding the
    other agents in the cluster. The final `-recursor` arguments tell Consul what
    upstream DNS servers to use for DNS requests that aren’t trying to look up registered
    services.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们已经找到了外部IP地址并将集群通信绑定到它。`-join`参数告诉领事最初在哪里查找以找到集群。不用担心对集群形成进行微观管理——当两个代理最初相遇时，它们会进行“八卦”，传递有关在集群中找到其他代理的信息。最后的`-recursor`参数告诉领事用于DNS请求的DNS服务器（这些请求不是尝试查找已注册的服务）。
- en: Let’s verify that the agent has connected to the server with the HTTP API on
    the client machine. The API call we’ll use will return a list of members the client
    agent currently thinks are in the cluster. In large, quickly changing clusters,
    this may not always match the members of the cluster—there’s another (slower)
    API call for that.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证代理是否已通过客户端机器上的HTTP API连接到服务器。我们将使用的API调用将返回客户端代理当前认为在集群中的成员列表。在大型、快速变化的集群中，这可能并不总是与集群成员匹配——为此还有一个（较慢）的API调用。
- en: '[PRE21]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now that the Consul infrastructure is set up, it’s time to see how you can register
    and discover services. The typical process for registration is to get your app
    to make an API call against the local client agent after initializing, which prompts
    the client agent to distribute the information to the server agents. For demonstration
    purposes, we’ll perform the registration step manually.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 现在领事基础设施已经搭建完成，是时候看看您如何注册和发现服务了。注册的典型流程是在初始化后让您的应用程序对本地客户端代理进行API调用，这会提示客户端代理将信息分发到服务器代理。为了演示目的，我们将手动执行注册步骤。
- en: '[PRE22]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Here we’ve set up a simple HTTP server in a container, exposing it on port 8000
    on the host, and checked that it works. Then we used curl and the Consul HTTP
    API to register a service definition. The only thing absolutely necessary here
    is the name of the service—the port, along with the other fields listed in the
    Consul documentation, are all optional. The ID field is worth a mention—it defaults
    to the name of the service but must be unique across all services. If you want
    multiple instances of a service, you’ll need to specify it.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在容器中设置了一个简单的HTTP服务器，将其暴露在主机上的8000端口，并检查它是否工作。然后我们使用curl和领事HTTP API注册了一个服务定义。这里绝对必要的是服务的名称——端口，以及领事文档中列出的其他字段都是可选的。ID字段值得提一下——它默认为服务的名称，但必须在所有服务中是唯一的。如果您想有多个服务实例，您需要指定它。
- en: 'The log line from Consul has told us that the service is synced, so we should
    be able to retrieve the information about it from the service DNS interface. This
    information comes from the server agents, so it acts as validation that the service
    has been accepted into the Consul catalog. You can use the `dig` command to query
    service DNS information and check that it’s present:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 来自领事日志的行告诉我们服务已同步，因此我们应该能够从服务DNS接口检索有关它的信息。这些信息来自服务器代理，因此它作为验证，表明该服务已被接受到领事目录中。您可以使用`dig`命令查询服务DNS信息并检查其是否存在：
- en: '[PRE23]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '***1***Looks up the IP address of the files service from the server agent DNS.
    This DNS service is available to arbitrary machines not in your Consul cluster,
    allowing them to benefit from service discovery as well.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1***从服务器代理DNS查找文件服务的IP地址。此DNS服务对您的领事集群中的任意机器都可用，允许它们也能从服务发现中受益。'
- en: '***2***Looks up the IP address of the files service from the client agent DNS.
    If using $BRIDGEIP fails, you may wish to try with $EXTIP1.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2***从客户端代理DNS查找文件服务的IP地址。如果使用$BRIDGEIP失败，您可能希望尝试使用$EXTIP1。'
- en: '***3***Requests the SRV record of the files service from the client agent DNS'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3***从客户端代理DNS请求文件服务的SRV记录'
- en: '***4***Starts a container configured to use the local client agent as the only
    DNS server'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4***启动一个配置为仅使用本地客户端代理作为DNS服务器的容器'
- en: '***5***Verifies that lookup of external addresses still works'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5***验证外部地址的查找仍然有效'
- en: '***6***Verifies that service lookup works automatically inside the container'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6***验证服务查找在容器内自动工作'
- en: '|  |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-260
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: SRV records are a way of communicating service information by DNS, including
    protocol, port, and other entries. In the preceding case, you can see the port
    number in the response, and you’ve been given the canonical hostname of the machine
    providing the service rather than the IP address.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: SRV记录是通过DNS通信服务信息的一种方式，包括协议、端口和其他条目。在前面的例子中，您可以在响应中看到端口号，并且您得到了提供服务的机器的规范主机名而不是IP地址。
- en: '|  |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Advanced users may want to avoid manually setting the `--dns` argument by configuring
    the --dns and --bip arguments for the Docker daemon itself, but remember to override
    the defaults for the Consul agent, or you may end up with unexpected behavior.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 高级用户可能希望避免手动设置`--dns`参数，而是通过配置Docker守护进程本身的`--dns`和`--bip`参数来避免，但请记住覆盖Consul代理的默认值，否则您可能会遇到意外的行为。
- en: The similarities between the Consul DNS service and the Docker virtual networks
    in [technique 80](kindle_split_021.xhtml#ch10sb06) are interesting—both allow
    you to discover containers by a human-readable name, and Docker has the built-in
    ability to make this work across multiple nodes with overlay networks. The key
    difference is that Consul exists outside Docker and so may be easier to integrate
    into existing systems.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在[技术80](kindle_split_021.xhtml#ch10sb06)中，Consul DNS服务与Docker虚拟网络之间的相似之处很有趣——两者都允许您通过可读的名称发现容器，而Docker具有内置的跨多个节点使用overlay网络使此功能工作的能力。关键区别在于Consul存在于Docker之外，因此可能更容易集成到现有系统中。
- en: 'However, as mentioned at the beginning of this technique, Consul has another
    interesting feature we’ll take a look at: health checks.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如本技术的开头所述，Consul还有一个有趣的功能，我们将对其进行探讨：健康检查。
- en: Health checking is a big topic, so we’ll leave the minutiae for the comprehensive
    Consul documentation and look at one of the options for monitoring—a script check.
    This runs a command and sets the health based on the return value, with 0 for
    success, 1 for warning, and any other value for critical. You can register a health
    check when initially defining the service, or in a separate API call, as we’ll
    do here.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 健康检查是一个大主题，所以我们将在全面的Consul文档中留出细节，并查看监控的一个选项——脚本检查。它运行一个命令，并根据返回值设置健康状态，0表示成功，1表示警告，任何其他值表示关键。您可以在最初定义服务时注册健康检查，或者在我们这里这样做的一个单独的API调用中。
- en: '[PRE24]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '***1*****Creates a check script verifying that the HTTP status code from the
    service is “200 OK”. The service port is looked up from the service ID passed
    to the script as an argument.**'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*****创建一个检查脚本，验证服务的HTTP状态码是否为“200 OK”。服务端口从作为参数传递给脚本的服务ID中查找。**'
- en: '***2*****Copies the check script into the Consul agent container**'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*****将检查脚本复制到Consul代理容器中**'
- en: '***3*****Creates a health check definition to send to the Consul HTTP API.
    The service ID has to be specified in both the ServiceID field and the script
    command line.**'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*****创建一个用于发送到Consul HTTP API的健康检查定义。服务ID必须在ServiceID字段和脚本命令行中指定。**'
- en: '***4*****Submits the health check JSON to the Consul agent**'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*****将健康检查JSON提交给Consul代理**'
- en: '***5*****Waits for the check output to be communicated to the server agents**'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*****等待检查输出被传达给服务器代理**'
- en: '***6*****Retrieves health check information for the check you’ve registered**'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6*****检索您已注册的检查的健康检查信息**'
- en: '***7*****Attempts to look up the files service, with no results**'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7*****尝试查找文件服务，但没有结果**'
- en: '|  |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-276
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: Because output from health checks can change on every execution (if it includes
    timestamps, for example), Consul only synchronizes check output with the server
    on a status change, or every five minutes (though this interval is configurable).
    Because statuses start as critical, there’s no initial status change in this case,
    so you’ll need to wait out the interval to get output.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 由于健康检查的输出可能在每次执行时都会改变（例如，如果它包含时间戳），Consul仅在状态改变时或每五分钟（尽管这个间隔是可配置的）与服务器同步检查输出。因为状态最初是关键的，所以在这种情况下没有初始状态改变，因此您需要等待间隔以获取输出。
- en: '|  |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: We added a health check for the files service to be run every 10 seconds, but
    checking it shows the service as having a critical status. Because of this, Consul
    has automatically taken the failing endpoint out of the entries returned by DNS,
    leaving us with no serve. This is particularly helpful for automatically removing
    servers from a multiple-backend service in production.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为文件服务添加了一个每10秒运行一次的健康检查，但检查结果显示该服务处于关键状态。因此，Consul已自动将失败的端点从DNS返回的条目中移除，使我们没有服务可用。这在生产环境中自动从多后端服务中移除服务器特别有用。
- en: The root cause of the error we’ve hit is an important one to be aware of when
    running Consul inside a container. All checks are also run inside the container,
    so, as the check script had to be copied into the container, you also need to
    make sure any commands you need are installed in the container. In this particular
    case, we’re missing the `jq` command (a helpful utility for extracting information
    from JSON), which we can install manually, though the correct approach for production
    would be to add layers to the image.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器内运行Consul时遇到错误的原因是一个重要的注意事项。所有检查都在容器内运行，因此，由于检查脚本必须复制到容器中，你还需要确保任何需要的命令都已安装在容器中。在这种情况下，我们缺少`jq`命令（一个从JSON中提取信息的有用工具），我们可以手动安装，尽管对于生产环境来说，正确的方法是向镜像中添加层。
- en: '[PRE25]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We’ve now installed `jq` onto the image using the Alpine Linux (see [technique
    57](kindle_split_017.xhtml#ch07sb10)) package manager, verified that it works
    by manually executing the line that was previously failing in the script, and
    then waited for the check to rerun. It’s now successful!
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用Alpine Linux（见[技术57](kindle_split_017.xhtml#ch07sb10)）包管理器将`jq`安装到镜像中，通过手动执行脚本中之前失败的行来验证它是否工作，然后等待检查重新运行。现在它成功了！
- en: With script health checks, you now have a vital building block for constructing
    monitoring around your application. If you can express a health check as a series
    of commands you’d run in a terminal, you can get Consul to automatically run it—this
    isn’t limited to HTTP status. If you find yourself wanting to check the status
    code returned by an HTTP endpoint, you’re in luck, as this is such a common task
    that one of the three types of health checking in Consul is dedicated to it, and
    you don’t need to use a script health check (we did so above for illustrative
    purposes).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '使用脚本健康检查，你现在拥有了构建围绕应用程序的监控的关键构建块。如果你能将健康检查表达为一系列在终端中运行的命令，你就可以让Consul自动运行它——这不仅仅限于HTTP状态。如果你发现自己想要检查HTTP端点返回的状态码，那么你很幸运，因为这是一项如此常见的任务，以至于Consul中的三种健康检查类型之一就是专门为此设计的，而且你不需要使用脚本健康检查（我们上面为了说明目的这样做）。 '
- en: The final type of health check, time to live, requires a deeper integration
    with your application. The status must be periodically set to healthy, or the
    check will automatically be set to failing. Combining these three types of health
    check gives you the power to build comprehensive monitoring on top of your system.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一种健康检查类型，即生存时间，需要与你的应用程序进行更深入的集成。状态必须定期设置为健康，否则检查将自动设置为失败。结合这三种类型的健康检查，你可以在系统之上构建全面的监控。
- en: To round off this technique, we’ll look at the optional Consul web interface
    that comes with the server agent image. It provides a helpful insight into the
    current state of your cluster. You can visit this by going to port 8500 on the
    external IP address of a server agent. In this case you’d want to visit `$EXTIP1:8500`.
    Remember that even if you’re on a server agent host, `localhost` or `127.0.0.1`
    won’t work.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这项技术，我们将查看服务器代理镜像中包含的可选Consul Web界面。它提供了对集群当前状态的宝贵洞察。你可以通过访问服务器代理的外部IP地址上的端口8500来访问它。在这种情况下，你需要访问`$EXTIP1:8500`。记住，即使你在服务器代理主机上，`localhost`或`127.0.0.1`也不会工作。
- en: '**DISCUSSION**'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: We’ve covered a lot in this technique—Consul is a big topic! Fortunately, just
    as the knowledge you gained about utilizing key/value stores with etcd in [technique
    74](kindle_split_020.xhtml#ch09sb06) is transferable to other key/value stores
    (like Consul), this service-discovery knowledge is transferable to other tools
    offering DNS interfaces (SkyDNS being one you may come across).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个技术中涵盖了大量的内容——Consul是一个大主题！幸运的是，正如你在[技术74](kindle_split_020.xhtml#ch09sb06)中关于利用etcd中的键值存储所获得的知识可以迁移到其他键值存储（如Consul）一样，这个服务发现知识也可以迁移到其他提供DNS接口的工具（SkyDNS可能是你遇到的一个）。
- en: The subtleties we covered related to using the host network stack and using
    external IP addresses are also transferable. Most containerized distributed tools
    requiring discovery across multiple nodes may have similar problems, and it’s
    worth being aware of these potential issues.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所讨论的与使用主机网络堆栈和使用外部IP地址相关的细微差别也是可以迁移的。大多数需要跨多个节点进行发现的容器化分布式工具可能存在类似问题，因此了解这些潜在问题是有价值的。
- en: '|  |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '|  |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Automatic service registration with Registrator**'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用Registrator进行自动服务注册**'
- en: The obvious downside of Consul (and any service discovery tool) so far is the
    overhead of having to manage the creation and deletion of service entries. If
    you integrate this into your applications, you’ll have multiple implementations
    and multiple places it could go wrong.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，Consul（以及任何服务发现工具）的明显缺点是管理服务条目创建和删除的开销。如果你将其集成到你的应用程序中，你将有多处实现，并且有多个可能出错的地方。
- en: Integration also doesn’t work for applications you don’t have complete control
    over, so you’ll end up having to write wrapper scripts when starting up your database
    and the like.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 集成也不适用于你无法完全控制的程序，所以当你启动数据库等时，你最终将不得不编写包装脚本。
- en: '**PROBLEM**'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You don’t want to manually manage service entries and health checks in Consul.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 你不希望手动管理Consul中的服务条目和健康检查。
- en: '**SOLUTION**'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Use Registrator.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 使用注册器。
- en: This technique will build on top of the previous one and will assume you have
    a two-part Consul cluster available, as described previously. We’ll also assume
    there are no services in it, so you may want to recreate your containers to start
    from scratch.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术将在之前的技术基础上构建，并假设你有一个两部分的Consul集群可用，如之前所述。我们还将假设其中没有服务，所以你可能需要重新创建你的容器从头开始。
- en: Registrator ([http://gliderlabs.com/registrator/latest/](http://gliderlabs.com/registrator/latest/))
    takes away much of the complexity of managing Consul services—it watches for containers
    to start and stop, registering services based on exposed ports and container environment
    variables. The easiest way to see this in action is to jump in.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 注册器（[http://gliderlabs.com/registrator/latest/](http://gliderlabs.com/registrator/latest/))简化了管理Consul服务的复杂性——它监视容器的启动和停止，根据暴露的端口和容器环境变量注册服务。看到这一功能的最简单方法是亲自尝试。
- en: Everything we do will be on the machine with the client agent. As discussed
    previously, no containers except the server agent should be running on the other
    machine.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所做的一切都将是在具有客户端代理的机器上。如前所述，除了服务器代理之外，不应在其他机器上运行任何容器。
- en: 'The following commands are all you need to start up Registrator:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 启动注册器所需的命令如下：
- en: '[PRE26]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The first couple of commands here, for pulling the image and finding the external
    IP address, should look familiar. This IP address is given to Registrator so it
    knows what IP address to advertise for the services. The Docker socket is mounted
    to allow Registrator to be automatically notified of container starts and stops
    as they happen. We’ve also told Registrator how it can connect to a Consul agent,
    and that we want all containers to be refreshed every 60 seconds. Because Registrator
    should automatically be notified of container changes, this final setting is helpful
    in mitigating the impact of Registrator possibly missing updates.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这里前几个命令，用于拉取镜像和查找外部IP地址，应该看起来很熟悉。这个IP地址被提供给注册器，以便它知道为服务宣传哪个IP地址。Docker套接字被挂载，以便注册器能够自动通知容器启动和停止。我们还告诉注册器如何连接到Consul代理，并且我们希望所有容器每60秒刷新一次。由于注册器应该自动通知容器更改，因此此最终设置有助于减轻注册器可能错过更新的影响。
- en: Now that Registrator is running, it’s extremely easy to register a first service.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，注册器正在运行，注册第一个服务变得极其简单。
- en: '[PRE27]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The only effort we’ve had to put in when registering the service is passing
    an environment variable to tell Registrator what service name to use. By default,
    Registrator uses a name based on the container name component after the slash
    and before the tag: “mycorp.com/myteam/myimage:0.5” would have the name “myimage”.
    Whether this is useful or you want to specify something manually will depend on
    your naming conventions.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在注册服务时，我们唯一需要付出的努力是传递一个环境变量来告诉注册器使用哪个服务名称。默认情况下，注册器使用基于斜杠之后和标签之前的容器名称组件的名称：“mycorp.com/myteam/myimage:0.5”将具有名称“myimage”。这是否有用或者你想手动指定某些内容，将取决于你的命名约定。
- en: The rest of the values are pretty much as you’d hope. Registrator has discovered
    the port being listened on, added it to Consul, and set a service ID that tries
    to give a hint about where you can find the container (which is why the hostname
    was set in the Registrator container).
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的值基本上如您所期望的那样。注册器已经发现了正在监听的端口，将其添加到Consul，并设置了一个服务ID，试图给出你可以找到容器的提示（这就是为什么在注册器容器中设置了主机名）。
- en: '**DISCUSSION**'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: Registrator is excellent at giving you a handle on a swiftly changing environment
    with a high churn of containers, making sure you don’t need to worry about your
    service-creation checks being created.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: Registrator 在处理快速变化的环境和容器高周转率方面非常出色，确保你不需要担心你的服务创建检查被创建。
- en: In addition to service details, Registrator will pick up a number of pieces
    of information from environments if they’re present, including tags, service names
    per port (if multiple), and using health checks (if you’re using Consul as the
    data storage). All three types of Consul health checks can be enabled by specifying
    the check details in the environment in JSON—you can read more about this in the
    Consul section of the “Registrator Backends” documentation at [http://gliderlabs.com/registrator/latest/user/backends/#consul](http://gliderlabs.com/registrator/latest/user/backends/#consul),
    or revisit the previous technique to get a brief introduction to Consul health
    checks themselves.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 除了服务详情外，如果存在，Registrator 还会从环境中收集一些信息，包括标签、每个端口的（如果有多个）服务名称，以及使用健康检查（如果你使用 Consul
    作为数据存储）。通过在环境中指定检查详情的 JSON 格式，可以启用所有三种类型的 Consul 健康检查——你可以在“Registrator 后端”文档的
    Consul 部分[http://gliderlabs.com/registrator/latest/user/backends/#consul](http://gliderlabs.com/registrator/latest/user/backends/#consul)中了解更多信息，或者回顾先前的技术以获得对
    Consul 健康检查的简要介绍。
- en: '|  |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Summary
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: systemd units are useful for controlling container execution on a single machine.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: systemd 单元对于控制单台机器上的容器执行非常有用。
- en: Dependencies can be expressed in systemd units to provide startup orchestration.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以在 systemd 单元中表达依赖关系以提供启动编排。
- en: Helios is a production-quality, simple, multi-host orchestration solution.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Helios 是一个生产级、简单、多主机编排解决方案。
- en: Consul can hold information about your services, allowing dynamic service discovery.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Consul 可以存储有关你服务的信息，从而实现动态服务发现。
- en: Registrator can automatically register container-based services into Consul.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Registrator 可以自动将基于容器的服务注册到 Consul 中。
- en: Chapter 12\. The data center as an OS with Docker
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 12 章\. 以 Docker 为操作系统的数据中心
- en: '|  |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**This chapter covers**'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '**本章涵盖**'
- en: How to use the official Docker solution for orchestration
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用官方 Docker 解决方案进行编排
- en: The different ways Mesos can be used to manage Docker containers
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mesos 可以用来管理 Docker 容器的不同方式
- en: Two heavyweights in the Docker orchestration ecosystem, Kubernetes and OpenShift
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 编排生态系统中的两个重量级工具，Kubernetes 和 OpenShift
- en: '|  |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: If you look back at [figure 11.1](kindle_split_023.xhtml#ch11fig01) in the previous
    chapter, we’re now going to continue moving down the branches of the tree and
    on to tools that take away some of the detail to increase productivity. Most of
    these are designed with larger deployments across multiple machines in mind, but
    there’s no reason you can’t use them on one machine.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回顾一下上一章中的[图 11.1](kindle_split_023.xhtml#ch11fig01)，我们现在将继续沿着树的分支向下移动，并转向那些可以去除一些细节以提高生产力的工具。这些工具大多数都是针对跨多台机器的大规模部署而设计的，但你完全可以在一台机器上使用它们。
- en: As for the last chapter, we recommend trying to come up with a scenario for
    each tool, to clarify possible use cases in your environment. We’ll continue to
    give examples along the way as starting points.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 就像上一章一样，我们建议为每个工具尝试想出一个场景，以明确你环境中可能的用例。我们将继续在过程中给出示例作为起点。
- en: 12.1\. Multi-host Docker
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1\. 多主机 Docker
- en: The best process for moving Docker containers to target machines and starting
    them up is a matter of much debate in the Docker world. A number of well-known
    companies have created their own ways of doing things and have released them to
    the world. You can benefit massively from this, if you can decide what tools to
    use.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Docker 容器移动到目标机器并启动的最佳流程在 Docker 界是一个备受争议的话题。许多知名公司已经创建了他们自己的做事方式，并将其发布到世界。如果你能决定使用哪些工具，你将能从中获得巨大的益处。
- en: This is a fast moving topic—we’ve seen the birth and death of multiple orchestration
    tools for Docker, and we recommend caution when considering whether to move over
    to a brand-new tool. As a result, we’ve tried to select tools with significant
    stability or momentum (or both).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个快速发展的主题——我们见证了多个 Docker 编排工具的诞生和消亡，因此我们在考虑是否迁移到全新的工具时建议谨慎。因此，我们尝试选择了具有显著稳定性或动力的工具（或两者兼有）。
- en: '|  |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**A seamless Docker cluster with swarm mode**'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 swarm 模式的无缝 Docker 集群**'
- en: It’s great having complete control over your cluster, but sometimes the micromanagement
    isn’t necessary. In fact, if you have a number of applications with no complex
    requirements, you can take full advantage of the Docker promise of being able
    to run anywhere—there’s no reason you shouldn’t be able to throw containers at
    a cluster and let the cluster decide where to run them.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 能够完全控制您的集群是件好事，但有时微观管理并不是必要的。实际上，如果您有多个没有复杂要求的应用程序，您可以充分利用 Docker 在任何地方运行的承诺——没有理由您不能将容器投放到集群中，让集群决定在哪里运行它们。
- en: Swarm mode could be useful for a research lab if the lab were able to split
    up a computationally intensive problem into bite-size chunks. This would allow
    them to very easily run their problem on a cluster of machines.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 如果实验室能够将计算密集型问题分解成小块，Swarm 模式对于研究实验室可能很有用。这将使他们能够非常容易地在机器集群上运行他们的问题。
- en: '**PROBLEM**'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You have a number of hosts with Docker installed, and you want to be able to
    start containers without needing to micromanage where they’ll run.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 您有多个安装了 Docker 的主机，并且您希望能够在不需要微观管理它们运行位置的情况下启动容器。
- en: '**SOLUTION**'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Use swarm mode for Docker, a feature Docker itself has built in to tackle orchestration.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Docker 的 Swarm 模式，这是 Docker 本身构建的用于处理编排的功能。
- en: Swarm mode for Docker is the official solution from Docker Inc. to treat a cluster
    of hosts as a single Docker daemon and deploy services to them. It has a command
    line quite similar to one you’re familiar with from `docker run`. Swarm mode evolved
    from an official Docker tool that you’d use alongside Docker, and it was integrated
    into the Docker daemon itself. If you see old references to “Docker Swarm” anywhere,
    they may be referring to the older tool.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 的 Swarm 模式是 Docker Inc. 提供的官方解决方案，用于将一组主机视为单个 Docker 守护进程并将服务部署到它们。它的命令行与您熟悉的
    `docker run` 命令非常相似。Swarm 模式是从 Docker 官方工具演变而来的，您会将其与 Docker 一起使用，并且它已被集成到 Docker
    守护进程本身。如果您在任何地方看到对“Docker Swarm”的旧引用，它们可能指的是较旧的工具。
- en: A Docker swarm consists of a number of nodes. Each node may be a manager or
    a worker, and these roles are flexible and can be changed in the swarm at any
    time. A manager coordinates the deployment of services to available nodes, whereas
    workers will only run containers. By default, managers are available to run containers
    as well, but you’ll see how to alter that as well.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 集群由多个节点组成。每个节点可能是一个管理者或一个工作节点，这些角色是灵活的，可以在集群中随时更改。管理者负责协调服务部署到可用的节点，而工作节点只会运行容器。默认情况下，管理者也可以运行容器，但您将看到如何更改这一点。
- en: When the manager is started, it initializes some state for the swarm and then
    listens for incoming connections from additional nodes to add to the swarm.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 当管理者启动时，它会为集群初始化一些状态，然后监听来自其他节点以添加到集群的传入连接。
- en: '|  |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-342
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**注意**'
- en: All versions of Docker used in a swarm must be at least 1.12.0\. Ideally you
    should try to keep all versions exactly the same, or you may encounter issues
    due to version incompatibilities.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 集群中使用的所有 Docker 版本必须至少为 1.12.0。理想情况下，您应该尽量保持所有版本完全相同，否则您可能会遇到由于版本不兼容而产生的问题。
- en: '|  |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'First, let’s create a new swarm:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个新的集群：
- en: '[PRE28]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This has created a new swarm and set up the Docker daemon of the host `h1` to
    be a manager.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 这创建了一个新的集群，并将主机 `h1` 上的 Docker 守护进程设置为管理者。
- en: 'You can now inspect your newly created swarm:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以检查您新创建的集群：
- en: '[PRE29]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You can now make a Docker daemon on a different host join as a worker by running
    the command specified after the manager started:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以通过运行管理者启动后指定的命令，使不同主机上的 Docker 守护进程加入作为工作节点：
- en: '[PRE30]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '`h2` has now been added to our cluster as a worker. Running `docker info` on
    either host will reveal that the `Nodes` count has gone up to 2, and `docker node
    ls` will list both nodes.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '`h2` 现已作为工作节点添加到我们的集群中。在任一主机上运行 `docker info` 将会显示 `Nodes` 计数已增加到 2，而 `docker
    node ls` 将列出这两个节点。'
- en: Finally, let’s start a container. In swarm mode, this is referred to as deploying
    a service, because there are additional features that don’t make sense with a
    container. Before deploying the service, we’ll mark the manager as having availability
    `drain`—by default, all managers are available to run containers, but in this
    technique we want to demonstrate remote machine scheduling capabilities, so we’ll
    constrain things to avoid the manager. Drain will cause any containers already
    on the node to be redeployed elsewhere, and no new services will be scheduled
    on the node.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们启动一个容器。在Swarm模式中，这被称为部署服务，因为有一些额外的功能与容器不兼容。在部署服务之前，我们将标记管理器为具有可用性`drain`——默认情况下，所有管理器都可用于运行容器，但在这个技术中，我们想展示远程机器调度能力，所以我们将限制以避免管理器。Drain将导致节点上任何现有的容器重新部署到其他地方，并且不会在该节点上安排新的服务。
- en: '[PRE31]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: There are a few things to note here. The most important is that the swarm has
    automatically selected a machine to start the container on—if you had multiple
    workers, the manager would choose one based on load balancing. You probably also
    recognize some of the arguments to `docker service create` as familiar from `docker
    run`—a number of arguments are shared, but it’s worth reading the documentation.
    For example, the `--volume` argument to `docker run` has a different format in
    the `--mount` argument that you should read the documentation for.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个需要注意的事项。最重要的是，群集会自动选择一台机器来启动容器——如果你有多个工作节点，管理器会根据负载均衡选择一个。你可能也认出了`docker
    service create`的一些参数与`docker run`中的参数相似——许多参数是共享的，但阅读文档是值得的。例如，`docker run`中的`--volume`参数在`--mount`参数中有不同的格式，你应该阅读相关的文档。
- en: 'It’s now time to check and see if our service is up and running:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候检查并查看我们的服务是否正在运行：
- en: '[PRE32]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Swarm mode has a piece of additional functionality it enables by default, called
    the *routing mesh*. This allows each node in the swarm to appear as if it can
    serve requests for all services within the swarm that have published ports—any
    incoming connections are forwarded to an appropriate node.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm模式默认启用了一项附加功能，称为*路由网格*。这允许群集中的每个节点似乎都可以为群集中已发布端口的全部服务提供服务——任何传入的连接都会转发到适当的节点。
- en: 'For example, if you go back on the `h1` manager node again (which we know isn’t
    running the service, because it has availability `drain`), it will still respond
    on port 8000 to any requests:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你再次回到`h1`管理节点（我们知道它没有运行服务，因为它有可用性`drain`），它仍然会在端口8000上对任何请求做出响应：
- en: '[PRE33]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: This can be particularly useful for a simple kind of service discovery—as long
    as you know the address of one node, you can access all your services very easily.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于一种简单的服务发现尤其有用——只要你知道一个节点的地址，你就可以非常容易地访问所有服务。
- en: Once you’re finished with the swarm, you can shut down all services and delete
    the cluster.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成Swarm的使用，你可以关闭所有服务并删除集群。
- en: '[PRE34]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: As you can see here, swarm mode will warn you if you’re shutting down the last
    manager in a node, because all information on the swarm will be lost. You can
    override this warning with `--force`. You’ll need to run `docker swarm leave`
    on all worker nodes as well.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，如果正在关闭节点中的最后一个管理节点，Swarm模式会警告你，因为群集中的所有信息都将丢失。你可以使用`--force`来覆盖此警告。你还需要在所有工作节点上运行`docker
    swarm leave`。
- en: '**DISCUSSION**'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: This has been a brief introduction to swarm mode in Docker, and there’s a lot
    we haven’t covered here. For example, you may have noticed that the help text
    after we initialized the swarm mentioned the ability to connect additional masters
    to the swarm—this is useful for resilience. Additional subjects of interest are
    built-in pieces of functionality that store service configuration information
    (as you did with etcd in [technique 74](kindle_split_020.xhtml#ch09sb06)), using
    constraints to guide placement of containers, and information on how to upgrade
    containers with rollbacks on failure. We recommend you refer to the official documentation
    at [https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/)
    for more information.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对Docker中Swarm模式的简要介绍，这里还没有涵盖很多内容。例如，你可能已经注意到我们在初始化Swarm后提到的能够连接更多主节点到Swarm的能力——这对于弹性很有用。其他感兴趣的主题包括存储服务配置信息的内置功能（就像你在[技术74](kindle_split_020.xhtml#ch09sb06)中使用etcd一样），使用约束来引导容器的放置，以及有关如何在失败时回滚容器升级的信息。我们建议你参考[https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/)的官方文档以获取更多信息。
- en: '|  |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '|  |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Using a Kubernetes cluster**'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 Kubernetes 集群**'
- en: You’ve now seen two extremes in approaches to orchestration—the conservative
    approach of Helios and the much more free-form approach of Docker swarm. But some
    users and companies will expect a little more sophistication from their tooling.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经看到了两种极端的编排方法——Helios 的保守方法以及 Docker Swarm 的更自由的方法。但一些用户和公司可能会期望他们的工具更加复杂。
- en: This need for customizable orchestration can be fulfilled by many options, but
    there are a few that are used and discussed more than the others. In one case,
    that’s undoubtedly partially due to the company behind it, but one would hope
    that Google knows how to build orchestration software.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 这种可定制编排的需求可以通过许多选项来满足，但有一些选项比其他选项使用和讨论得更多。在一种情况下，这无疑部分归因于背后的公司，但人们希望 Google
    知道如何构建编排软件。
- en: '**PROBLEM**'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You want to manage Docker services across hosts.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 您想要跨主机管理 Docker 服务。
- en: '**SOLUTION**'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Use Kubernetes and its powerful abstractions to manage your fleet of containers.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 和其强大的抽象功能来管理您的容器集群。
- en: Kubernetes, a tool created by Google, is for companies that prefer to have clear
    guidance and best practices on how to arrange applications and state relationships
    between them. It allows you to use specially designed tools to manage a dynamic
    infrastructure based on a specified structure.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是由 Google 创建的一个工具，适用于那些希望获得清晰指导和建议，以及最佳实践来安排应用程序和它们之间状态关系的公司。它允许您使用专门设计的工具来管理基于指定结构的动态基础设施。
- en: Before we get going with Kubernetes, let’s take a quick look at Kubernetes’
    high-level architecture in [figure 12.1](#ch12fig01).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用 Kubernetes 之前，让我们快速看一下 Kubernetes 的高级架构，如图 12.1[图 12.1](#ch12fig01)。
- en: Figure 12.1\. Kubernetes high-level view
  id: totrans-378
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 12.1\. Kubernetes 高级视图
- en: '![](Images/12fig01_alt.jpg)'
  id: totrans-379
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig01_alt.jpg)'
- en: Kubernetes has a master-minion architecture. Master nodes are responsible for
    receiving orders about what should be run on the cluster and orchestrating its
    resources. Each minion has Docker installed on it, along with a *kubelet* service,
    which manages the pods (sets of containers) running on each node. Information
    about the cluster is maintained in etcd, a distributed key/value data store (see
    [technique 74](kindle_split_020.xhtml#ch09sb06)), and this is the cluster’s source
    of truth.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 采用主从架构。主节点负责接收有关在集群上运行什么的命令，并编排其资源。每个从节点上都安装了 Docker，以及一个 *kubelet*
    服务，该服务管理每个节点上运行的 pods（容器组）。集群的信息存储在 etcd 中，这是一个分布式键/值数据存储（见[技术 74](kindle_split_020.xhtml#ch09sb06)），这也是集群的真相来源。
- en: '|  |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Tip
  id: totrans-382
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 提示
- en: We’ll go over it again later in this technique, so don’t worry about it too
    much now, but a *pod* is a grouping of related containers. The concept exists
    to facilitate the management and maintenance of Docker containers.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本技术的后面再次讨论这个问题，所以现在不必过于担心，但一个 *pod* 是一组相关的容器。这个概念的存在是为了便于管理和维护 Docker 容器。
- en: '|  |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: The end goal of Kubernetes is to make running your containers at scale a simple
    matter of declaring what you want and letting Kubernetes ensure the cluster meets
    your needs. In this technique you’ll see how to scale a simple service to a given
    size by running one command.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的最终目标是使大规模运行容器变得简单，只需声明您想要的内容，让 Kubernetes 确保集群满足您的需求。在这个技术中，您将看到如何通过运行一个命令将一个简单的服务扩展到指定的大小。
- en: '|  |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-387
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: Kubernetes was originally developed by Google as a means for managing containers
    at scale. Google has been running containers for over a decade at scale, and it
    decided to develop this container orchestration system when Docker became popular.
    Kubernetes builds on the lessons learned from Google’s extensive experience. Kubernetes
    is also known as “K8s.”
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 最初是由 Google 开发的，作为一种在规模上管理容器的方法。Google 已经在规模上运行容器超过十年，当 Docker 变得流行时，它决定开发这个容器编排系统。Kubernetes
    建立在 Google 丰富经验的基础上。Kubernetes 也被称为“K8s”。
- en: '|  |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: A full treatment of Kubernetes’ installation, setup, and features is a big and
    fast-changing topic that’s beyond the scope of this book (and no doubt a book
    in itself, before too long). Here we’re going to focus on Kubernetes’ core concepts
    and set up a simple service so you can get a feel for it.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的安装、设置和功能的全面介绍是一个大且快速变化的话题，超出了本书的范围（无疑也将很快成为一本自己的书）。在这里，我们将专注于 Kubernetes
    的核心概念，并设置一个简单的服务，以便您可以了解它。
- en: '**Installing Kubernetes**'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '**安装 Kubernetes**'
- en: You can either install Kubernetes directly on your host via Minikube, which
    will give you a single-minion cluster, or use Vagrant to install a multi-minion
    cluster managed with VMs. In this technique we’ll focus on the first option—the
    latter is best achieved with research to identify the correct option for the latest
    version of Kubernetes.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以直接在主机上通过Minikube安装Kubernetes，这将为你提供一个单节点集群，或者使用Vagrant安装一个由虚拟机管理的多节点集群。在这个技术中，我们将关注第一种选项——后一种选项最好通过研究来识别Kubernetes最新版本的正确选项。
- en: The recommended approach for getting started locally with Kubernetes is to install
    a single-minion cluster on your host by following the official documentation for
    Minikube at [https://kubernetes.io/docs/tasks/tools/install-minikube/](https://kubernetes.io/docs/tasks/tools/install-minikube/).
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地开始使用Kubernetes的推荐方法是按照Minikube的官方文档在[https://kubernetes.io/docs/tasks/tools/install-minikube/](https://kubernetes.io/docs/tasks/tools/install-minikube/)上安装一个单节点集群。
- en: Minikube is a specialized tool from the Kubernetes project created to ease the
    process of local development, but it’s currently a bit limited. If you want to
    stretch yourself a bit more, we recommend searching for a guide to setting up
    a multi-node Kubernetes cluster with Vagrant—this process tends to change with
    the Kubernetes version, so we won’t give specific advice here (though, at time
    of writing, we found [https://github.com/Yolean/kubeadm-vagrant](https://github.com/Yolean/kubeadm-vagrant)
    to be a reasonable starting point).
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube是Kubernetes项目中的一个专用工具，旨在简化本地开发过程，但它目前有些受限。如果你想挑战自己更多，我们建议搜索设置使用Vagrant的多节点Kubernetes集群的指南——这个过程会随着Kubernetes版本的更新而变化，所以我们这里不会提供具体的建议（尽管，在撰写本文时，我们发现[https://github.com/Yolean/kubeadm-vagrant](https://github.com/Yolean/kubeadm-vagrant)是一个合理的起点）。
- en: Once you have Kubernetes installed, you can follow along from here. The following
    output will be based on a multi-node cluster. We’re going to start by creating
    a single container and using Kubernetes to scale it up.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在你安装了Kubernetes之后，你可以从这里开始。以下输出将基于一个多节点集群。我们将首先创建一个单个容器，并使用Kubernetes将其扩展。
- en: '**Scaling a single container**'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '**单个容器的扩展**'
- en: The command used to manage Kubernetes is `kubectl`. In this case you’re going
    to use the `run` subcommand to run a given image as a container within a pod.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 用于管理Kubernetes的命令是`kubectl`。在这种情况下，你将使用`run`子命令在pod内运行指定的镜像作为容器。
- en: '[PRE35]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '***1*** **“todo” is the name for the resulting pod, and the image to start
    is specified with the “--image” flag; here we’re using the todo image from [chapter
    1](kindle_split_010.xhtml#ch01).**'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** **“todo”是结果pod的名称，要启动的镜像通过“--image”标志指定；这里我们使用的是来自[第1章](kindle_split_010.xhtml#ch01)的todo镜像。**'
- en: '***2*** **The “get pods” subcommand to kubectl lists all pods. We’re only interested
    in the “todo” ones, so we grep for those and the header.**'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** **“get pods”子命令到kubectl列出所有pod。我们只对“todo”感兴趣，所以我们grep那些和标题。**'
- en: '***3*** **“todo-hmj8e” is the pod name.**'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** **“todo-hmj8e”是pod名称。**'
- en: '***4*** **Labels are name=value pairs associated with the pod, such as the
    “run” label here. The status of the pod is “Pending”, which means Kubernetes is
    preparing to run it, most likely because it’s downloading the image from the Docker
    Hub.**'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** **标签是与pod关联的name=value对，例如这里的“run”标签。pod的状态是“挂起”，这意味着Kubernetes正在准备运行它，很可能是由于它正在从Docker
    Hub下载镜像。**'
- en: Kubernetes picks a pod name by taking the name from the `run` command (`todo`
    in the preceding example), adding a dash and adding a random string. This ensures
    it doesn’t clash with other pod names.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes通过从`run`命令（在先前的例子中是`todo`）中获取名称，添加一个连字符，并添加一个随机字符串来选择pod名称。这确保了它不会与其他pod名称冲突。
- en: 'After waiting a few minutes for the todo image to download, you’ll eventually
    see that its status has changed to “Running”:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在等待几分钟下载todo镜像后，你最终会看到其状态已变为“运行”：
- en: '[PRE36]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This time the IP, CONTAINER(S), and IMAGE(S) columns are populated. The IP column
    gives the address of the pod (in this case `10.246.1.3`), and the container column
    has one row per container in the pod (in this case we have only one, `todo`).
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 这次IP、CONTAINER(S)和IMAGE(S)列都被填充了。IP列给出了pod的地址（在这种情况下是`10.246.1.3`），容器列中每行对应pod中的一个容器（在这种情况下我们只有一个，`todo`）。
- en: 'You can test that the container (todo) is indeed up and running and serving
    requests by hitting the IP address and port directly:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过直接点击IP地址和端口来测试容器（todo）确实已经启动并运行，并正在提供服务：
- en: '[PRE37]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'At this point we haven’t seen much difference from running a Docker container
    directly. To get your first taste of Kubernetes, you can scale up this service
    by running a `resize` command:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们还没有看到直接运行Docker容器时的太多区别。为了体验Kubernetes，您可以通过运行`resize`命令来扩展此服务：
- en: '[PRE38]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This command tells Kubernetes that you want the todo replication controller
    to ensure that there are three instances of the todo app running across the cluster.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令告诉Kubernetes，您希望todo副本控制器确保集群中运行着三个todo应用的实例。
- en: '|  |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Tip
  id: totrans-413
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 提示
- en: A replication controller is a Kubernetes service that ensures that the right
    number of pods is running across the cluster.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 一个副本控制器是Kubernetes服务，确保集群中运行着正确数量的pod。
- en: '|  |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'You can check that the additional instances of the todo app have been started
    with the `kubectl get pods` command:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`kubectl get pods`命令检查todo应用的额外实例是否已启动：
- en: '[PRE39]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Kubernetes has taken the `resize` instruction and the todo replication controller
    and ensured that the right number of pods is started up. Notice that it placed
    two on one host (10.245.1.4) and one on another (10.245.1.3). This is because
    Kubernetes’ default scheduler has an algorithm that spreads pods across nodes
    by default.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes已经采用了`resize`指令和todo副本控制器，并确保启动了正确数量的pod。注意，它在一个主机（10.245.1.4）上放置了两个，在另一个（10.245.1.3）上放置了一个。这是因为Kubernetes的默认调度器默认情况下有一个算法，它会将pod分散到各个节点上。
- en: '|  |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Tip
  id: totrans-420
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 提示
- en: A scheduler is a piece of software that decides where and when items of work
    should be run. For example, the Linux kernel has a scheduler that decides what
    task should be run next. Schedulers range from the stupidly simple to the incredibly
    complex.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 调度器是一种软件，它决定工作项应该在何时何地运行。例如，Linux内核有一个调度器，它决定下一个应该运行的任务。调度器从极其简单到极其复杂不等。
- en: '|  |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: You’ve started to see how Kubernetes can make managing containers easier across
    multiple hosts. Next we’ll dive into the core Kubernetes concept of pods.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经开始看到Kubernetes如何使跨多个主机管理容器变得更加容易。接下来，我们将深入探讨Kubernetes的核心概念——pod。
- en: '**Using pods**'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用pod**'
- en: A *pod* is a collection of containers that are designed to work together in
    some way and that share resources.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*pod*是一组设计成以某种方式协同工作并共享资源的容器。
- en: Each pod gets its own IP address and shares the same volumes and network port
    range. Because a pod’s containers share a localhost, the containers can rely on
    the different services being available and visible wherever they’re deployed.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 每个pod都有自己的IP地址，并共享相同的卷和网络端口范围。因为pod的容器共享localhost，所以容器可以依赖不同服务在部署的任何地方都是可用和可见的。
- en: '[Figure 12.2](#ch12fig02) illustrates this with two containers that share a
    volume. In the figure, container 1 might be a web server that reads data files
    from the shared volume, which is in turn updated by container 2\. Both containers
    are therefore stateless; state is stored in the shared volume.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.2](#ch12fig02) 使用两个共享卷的容器说明了这一点。在该图中，容器1可能是一个读取共享卷中数据文件的Web服务器，而共享卷则由容器2更新。因此，这两个容器都是无状态的；状态存储在共享卷中。'
- en: Figure 12.2\. A two-container pod
  id: totrans-428
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.2\. 一个包含两个容器的pod
- en: '![](Images/12fig02.jpg)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig02.jpg)'
- en: This design of separated responsibilities facilitates a microservices approach
    by allowing you to manage each part of your service separately. You can upgrade
    one container within a pod without needing to be concerned with the others.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分离责任的设计通过允许您分别管理服务的每个部分，从而促进了微服务方法。您可以在不关心其他容器的情况下升级pod中的一个容器。
- en: The following pod specification defines a complex pod with one container that
    writes random data (`simplewriter`) to a file every 5 seconds, and another container
    that reads from the same file. The file is shared via a volume (`pod-disk`).
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 以下pod规范定义了一个复杂的pod，其中一个容器（`simplewriter`）每5秒向文件写入随机数据，另一个容器从同一文件中读取。文件通过卷（`pod-disk`）共享。
- en: Listing 12.1\. complexpod.json
  id: totrans-432
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.1\. complexpod.json
- en: '[PRE40]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '***1*** **Gives the entity a name**'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** **为实体赋予名称**'
- en: '***2*** **Specifies the type of object this is**'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** **指定此对象的类型**'
- en: '***3*** **Specifies to Kubernetes the version the JSON is targeting**'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** **指定JSON针对的Kubernetes版本**'
- en: '***4*** **The meat of the pod’s specification is in the “desiredState” and
    “manifest” attributes.**'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** **pod规范的核心在于“desiredState”和“manifest”属性。**'
- en: '***5*** **Gives the entity a name**'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*** **为实体赋予名称**'
- en: '***6*** **Details of the containers in the pod are stored in this JSON array**'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6*** **pod中容器的详细信息存储在这个JSON数组中**'
- en: '***7*** **Each container has a name for reference, and the Docker image is
    specified in the “image” attribute.**'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7*** **每个容器都有一个用于参考的名称，Docker镜像在“image”属性中指定。**'
- en: '***8*** **Volume mount points are specified for each container.**'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8*** **每个容器都指定了卷挂载点。**'
- en: '***9*** **The mount path is the path to the volume mounted on the filesystem
    of the container. This could be set to a different location for each container.**'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9*** **挂载路径是挂载在容器文件系统上的卷的路径。这可以为每个容器设置不同的位置。**'
- en: '***10*** **The volume mount name refers to the name in the pod manifest’s “volumes”
    definition.**'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***10*** **卷挂载名称指的是pod清单中“volumes”定义中的名称。**'
- en: '***11*** **Volume mount points are specified for each container.**'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***11*** **每个容器都指定了卷挂载点。**'
- en: '***12*** **The mount path is the path to the volume mounted on the filesystem
    of the container. This could be set to a different location for each container.**'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***12*** **挂载路径是挂载在容器文件系统上的卷的路径。这可以为每个容器设置不同的位置。**'
- en: '***13*** **The volume mount name refers to the name in the pod manifest’s “volumes”
    definition.**'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***13*** **卷挂载名称指的是pod清单中“volumes”定义中的名称。**'
- en: '***14*** **The “volumes” attribute defines the volumes created for this pod.**'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***14*** **“volumes”属性定义了为此Pod创建的卷。**'
- en: '***15*** **The name of the volume is referred to in the previous “volumeMounts”
    entries.**'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***15*** **卷的名称在先前的“volumeMounts”条目中引用。**'
- en: '***16*** **A temporary directory that shares a pod’s lifetime**'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***16*** **一个与Pod生命周期共享的临时目录**'
- en: 'To load this pod specification, create a file with the preceding listing and
    run this command:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载此Pod规范，创建一个包含前面列表的文件，并运行此命令：
- en: '[PRE41]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: After waiting a minute for the images to download, you’ll see the log output
    of the container by running `kubectl log` and specifying first the pod and then
    the container you’re interested in.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 等待一分钟以下载镜像后，您可以通过运行`kubectl log`并指定感兴趣的Pod和容器来查看容器的日志输出。
- en: '[PRE42]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '**DISCUSSION**'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: We’ve only scratched the surface of Kubernetes’ capabilities and potential here,
    but this should give you a sense of what can be done with it and how it can make
    orchestrating Docker containers simpler.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里只是触及了Kubernetes功能和潜力的表面，但这应该让您对它能做什么以及它如何简化Docker容器的编排有一个概念。
- en: The next technique looks at directly taking advantage of some more features
    of Kubernetes. Kubernetes is also used behind the scenes as an orchestration engine
    by OpenShift in [techniques 90](#ch12sb05) and [99](kindle_split_027.xhtml#ch14sb08).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个技术将直接利用Kubernetes的一些更多功能。Kubernetes还作为OpenShift背后的编排引擎在[技术90](#ch12sb05)和[99](kindle_split_027.xhtml#ch14sb08)中使用。
- en: '|  |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '|  |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Accessing the Kubernetes API from within a pod**'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '**从Pod内部访问Kubernetes API**'
- en: Often it’s possible for pods to operate completely independently from each other,
    not even knowing that they’re running as part of a Kubernetes cluster. But Kubernetes
    does provide a rich API, and giving containers access to this opens the door to
    introspection and adaptive behavior, as well as the ability for containers to
    manage the Kubernetes cluster themselves.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，Pod可以完全独立于彼此运行，甚至不知道它们是作为Kubernetes集群的一部分运行的。但Kubernetes确实提供了一个丰富的API，并且允许容器访问这个API，这为自我检查和自适应行为打开了大门，同时也使得容器能够自行管理Kubernetes集群。
- en: '**PROBLEM**'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You want to access the Kubernetes API from within a pod.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 您想从Pod内部访问Kubernetes API。
- en: '**SOLUTION**'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Use `curl` to access the Kubernetes API from within a container in a pod, using
    authorization information made available to the container.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`curl`从Pod中的容器内部访问Kubernetes API，使用对容器可用的授权信息。
- en: This is one of the shorter techniques in the book, but it contains a lot to
    unpack. This is one of the reasons it’s a useful technique to study. Among other
    things, we’ll cover
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本书中较短的技巧之一，但它包含了很多内容。这也是为什么它是一个有用的技巧来研究。在其它方面，我们将涵盖
- en: The `kubectl` command
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl`命令'
- en: Starting Kubernetes pods
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动Kubernetes Pod
- en: Accessing Kubernetes pods
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问Kubernetes Pod
- en: A Kubernetes anti-pattern
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes的反模式
- en: Bearer tokens
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久令牌
- en: Kubernetes secrets
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes机密
- en: The Kubernetes “downwards API”
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes的“向下API”
- en: '**No Kubernetes cluster?**'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: '**没有Kubernetes集群？**'
- en: If you don’t have access to a Kubernetes cluster, you have a few options. There
    are many cloud providers that offer pay-as-you-go Kubernetes clusters. For the
    fewest dependencies, though, we recommend using Minikube (mentioned in the last
    technique), which doesn’t require a credit card.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有访问 Kubernetes 集群的权限，你有几种选择。许多云服务提供商提供按需付费的 Kubernetes 集群。然而，为了减少依赖，我们推荐使用
    Minikube（在上一技术中提到），它不需要信用卡。
- en: For information on how to install Minikube, see the documentation at [https://kubernetes.io/docs/tasks/tools/install-minikube/](https://kubernetes.io/docs/tasks/tools/install-minikube/).
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何安装 Minikube 的信息，请参阅[https://kubernetes.io/docs/tasks/tools/install-minikube/](https://kubernetes.io/docs/tasks/tools/install-minikube/)文档。
- en: '**Creating a pod**'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '**创建 pod**'
- en: First you’re going to create a container within the fresh `ubuntu` pod using
    the `kubectl` command, and then you’ll access a shell within that container on
    the command line. (`kubectl run` currently imposes a 1-1 relationship between
    pods and containers, though pods are more flexible than this in general.)
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你将使用 `kubectl` 命令在新的 `ubuntu` pod 内部创建一个容器，然后你将在命令行中访问该容器内的 shell。（`kubectl
    run` 目前在 pod 和容器之间强制执行 1-1 的关系，尽管在一般情况下 pod 的灵活性更高。）
- en: Listing 12.2\. Creating and setting up a container
  id: totrans-478
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.2\. 创建和设置容器
- en: '[PRE43]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '***1*** **The kubectl command using the -ti flag, naming the pod “ubuntu”,
    using the by-now familiar ubuntu:16.04 image, and telling Kubernetes not to restart
    once the pod/container has exited**'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** **使用 -ti 标志的 kubectl 命令，将 pod 命名为“ubuntu”，使用现在熟悉的 ubuntu:16.04 镜像，并告诉
    Kubernetes 一旦 pod/container 退出不要重启**'
- en: '***2*** **Kubectl helpfully tells you that your terminal may not show you the
    prompt unless you press Enter.**'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** **kubectl 有用地向你指出，除非你按下 Enter 键，否则你的终端可能不会显示提示。**'
- en: '***3*** **This is the prompt from within the container that you’ll see if you
    press Enter, and we’re updating the container’s package system and installing
    curl.**'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** **这是按下 Enter 键时在容器内看到的提示，我们正在更新容器的包系统并安装 curl。**'
- en: '***4*** **Once the install is complete, the prompt is returned.**'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** **安装完成后，将返回提示。**'
- en: You’re now in the container created by the `kubectl` command, and you’ve ensured
    that curl is installed.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在处于 `kubectl` 命令创建的容器中，并确保 curl 已安装。
- en: '|  |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Warning
  id: totrans-486
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 警告
- en: Accessing and modifying a pod from a shell is considered a Kubernetes anti-pattern.
    We use it here to demonstrate what is possible from within a pod, rather than
    how pods should be used.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 从 shell 访问和修改 pod 被视为 Kubernetes 的反模式。我们在这里使用它来演示 pod 内部可以做到什么，而不是 pod 应该如何使用。
- en: '|  |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Listing 12.3\. Access the Kubernetes API from a pod
  id: totrans-489
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.3\. 从 pod 访问 Kubernetes API
- en: '[PRE44]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '***1*** **Uses the curl command to access the Kubernetes API. The -k flag allows
    curl to work without certificates being deployed on the client, and the HTTP method
    used to talk to the API is specified as GET by the -X flag.**'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** **使用 curl 命令访问 Kubernetes API。-k 标志允许 curl 在客户端未部署证书的情况下工作，而与 API 通信所使用的
    HTTP 方法由 -X 标志指定为 GET。**'
- en: '***2*** **The -H flag adds an HTTP header to the request. This is an authentication
    token discussed shortly.**'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** **-H 标志向请求添加一个 HTTP 头部。这是一个将在稍后讨论的认证令牌。**'
- en: '***3*** **The URL to contact is constructed from environment variables available
    within the pod.**'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** **要联系的网络地址是由 pod 内可用的环境变量构建的。**'
- en: '***4*** **The default response for the API is to list the paths it offers for
    consumption.**'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** **API 的默认响应是列出它提供的可消费路径。**'
- en: '***5*** **Another request is made, this time to the /version path.**'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*** **这次请求是针对 /version 路径的。**'
- en: '***6*** **The response to the /version request is to specify the version of
    Kubernetes that’s running.**'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6*** **对 /version 请求的响应是指定正在运行的 Kubernetes 版本。**'
- en: The preceding listing covered a lot of new material, but we hope it gives a
    flavor of what can be done within Kubernetes pods dynamically, without any setup.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的列表涵盖了大量的新内容，但我们希望它能让你对在 Kubernetes pod 中动态执行的操作有一个大致的了解，而不需要任何设置。
- en: 'The key point to take from this listing is that information is made available
    to users within the pod, allowing the pod to make contact with the Kubernetes
    API. These items of information are collectively called the “downward API.” At
    present, the downward API consists of two classes of data: environment variables,
    and files exposed to the pod.'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个列表中可以得出的关键点是，信息被提供给 pod 内的用户，允许 pod 与 Kubernetes API 建立联系。这些信息项统称为“向下 API”。目前，向下
    API 包括两类数据：环境变量和暴露给 pod 的文件。
- en: 'A file is used in the preceding example to provide an authentication token
    to the Kubernetes API. This token is made available in the file /var/run/secrets/kubernetes.io/serviceaccount/token.
    In [listing 12.3](#ch12ex03), this file is run through `cat`, and the output of
    the `cat` command is supplied as part of the `Authorization:` HTTP header. This
    header specifies that the authorization used is of the `Bearer` type, and the
    bearer token is the output of `cat`, so the `-H` argument to `curl` is as follows:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，使用文件向Kubernetes API提供认证令牌。这个令牌在文件 /var/run/secrets/kubernetes.io/serviceaccount/token
    中可用。在[列表12.3](#ch12ex03)中，这个文件通过`cat`命令运行，`cat`命令的输出作为`Authorization:` HTTP头的一部分提供。此头指定使用的授权类型为`Bearer`，携带令牌是`cat`命令的输出，因此`curl`的`-H`参数如下：
- en: '[PRE45]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '|  |'
  id: totrans-501
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-502
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: '*Bearer tokens* are an authentication method that requires only that a specified
    token is given—no identification is required beyond that (such as username/password).
    *Bearer shares* operate on a similar principle, where the bearer of the shares
    is the one who has the right to sell them. Cash money works the same way—indeed
    on UK cash the notes have the phrase “I promise to pay the bearer on demand the
    sum of ...”'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '*Bearer tokens*是一种认证方法，它只需要提供一个指定的令牌——不需要提供更多的身份信息（如用户名/密码）。*Bearer shares*基于类似的原则，持有股份的人有权出售它们。现金也是同样的方式——实际上，在英国现金中，钞票上有“我承诺按需支付持票人...”的短语。'
- en: '|  |'
  id: totrans-504
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: The downward API items exposed are a form of Kubernetes “secret.” Any secret
    can be created using the Kubernetes API and exposed via a file in a pod. This
    mechanism allows for the separation of secrets from Docker images and Kubernetes
    pod or deployment configuration, meaning that permissions can be handled separately
    from those more open items.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 向下公开的API项是一种Kubernetes“秘密”。任何秘密都可以使用Kubernetes API创建并通过pod中的文件公开。这种机制允许将秘密与Docker镜像和Kubernetes
    pod或部署配置分离，这意味着权限可以独立于更开放的项目进行管理。
- en: '**DISCUSSION**'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: It’s worth paying attention to this technique, as it covers a lot of ground.
    The key point to grasp is that Kubernetes pods have information made available
    to them that allows them to interact with the Kubernetes API. This allows applications
    to run within Kubernetes that monitor and act on activities going on around the
    cluster. For example, you might have an infrastructure pod that watches the API
    for newly sprung-up pods, investigates their activities, and records that data
    somewhere else.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是这种技术，因为它涵盖了大量的内容。关键是要掌握的是，Kubernetes pods拥有可供它们使用的信息，允许它们与Kubernetes API交互。这允许应用程序在Kubernetes中运行，监控并针对集群周围的活动进行操作。例如，你可能有一个基础设施pod，它监视API以查找新出现的pods，调查它们的活动，并将这些数据记录在其他地方。
- en: Although role-based access control (RBAC) is outside the scope of this book,
    it’s worth mentioning that this has implications for security, as you don’t necessarily
    want just any user of your cluster to have this level of access. Therefore, parts
    of the API will require more than just a bearer token to gain access.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基于角色的访问控制（RBAC）不在此书的范围之内，但值得提一下，这会对安全性产生影响，因为你不希望集群中的任何用户都能拥有这种级别的访问权限。因此，API的部分部分将需要除了携带令牌之外的东西来获取访问权限。
- en: These security-related considerations make this technique related half to Kubernetes
    and half to security. Either way, this is an important technique for anyone looking
    to use Kubernetes “for real,” to help them understand how the API works and how
    it potentially can be abused.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 这些与安全相关的考虑使得这项技术与Kubernetes和安全各占一半。无论如何，这对于任何打算“真正”使用Kubernetes的人来说都是一个重要的技术，可以帮助他们了解API的工作原理以及它可能被滥用的潜在方式。
- en: '|  |'
  id: totrans-510
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '|  |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Using OpenShift to run AWS APIs locally**'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用OpenShift在本地运行AWS API**'
- en: One of the big challenges with local development is testing an application against
    other services. Docker can help with this if the service can be put in a container,
    but this leaves the large world of external third-party services unsolved.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地开发中，一个巨大的挑战是测试应用程序与其他服务的兼容性。如果服务可以被放入容器中，Docker可以提供帮助，但这仍然没有解决外部第三方服务的大范围问题。
- en: A common solution is to have test API instances, but these often provide fake
    responses—a more complete test of functionality isn’t possible if an application
    is built around a service. For example, imagine you want to use AWS S3 as an upload
    location for your application, where it then processes the uploads—testing this
    will cost money.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的解决方案是拥有测试API实例，但这些通常提供虚假的响应——如果应用程序围绕一个服务构建，则无法进行更完整的测试。例如，想象一下您想使用AWS
    S3作为应用程序的上传位置，然后处理上传——测试这一点将花费金钱。
- en: '**PROBLEM**'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You want to have AWS-like APIs available locally to develop against.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望在本地上有AWS类似的API可供开发使用。
- en: '**SOLUTION**'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Set up LocalStack and use the available AWS service equivalents.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 设置LocalStack并使用可用的AWS服务等效项。
- en: In this walkthrough you’re going to set up an OpenShift system using Minishift,
    and then run LocalStack in a pod on it. OpenShift is a RedHat-sponsored wrapper
    around Kubernetes that provides extra functionality more suited to enterprise
    production deployments of Kubernetes.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，您将使用Minishift设置一个OpenShift系统，然后在上面运行LocalStack的一个Pod。OpenShift是围绕Kubernetes的一个由RedHat赞助的包装器，它提供了更适合企业级Kubernetes生产部署的额外功能。
- en: In this technique we’ll cover
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 在本技术中，我们将介绍
- en: The creation of routes in OpenShift
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在OpenShift中创建路由
- en: Security context constraints
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全上下文约束
- en: Differences between OpenShift and Kubernetes
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenShift和Kubernetes之间的差异
- en: Testing AWS services using public Docker images
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用公共Docker镜像测试AWS服务
- en: '|  |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-526
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: To follow this technique you’ll need to install Minishift. Minishift is similar
    to Minikube, which you saw in [technique 89](#ch12sb04). The difference is that
    it contains an installation of OpenShift (covered comprehensively in [technique
    99](kindle_split_027.xhtml#ch14sb08)).
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 要遵循此技术，您需要安装Minishift。Minishift类似于您在[技术89](#ch12sb04)中看到的Minikube。区别在于它包含OpenShift的安装（在[技术99](kindle_split_027.xhtml#ch14sb08)中全面介绍）。
- en: '|  |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**LocalStack**'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: '**LocalStack**'
- en: LocalStack is a project that aims to give you as complete as possible a set
    of AWS APIs to develop against without incurring any cost. This is great for testing
    or trying code out before running it for real against AWS and potentially wasting
    time and money.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: LocalStack是一个项目，旨在为您提供尽可能完整的AWS API集，以便在没有成本的情况下进行开发。这对于测试或在运行真正的AWS之前尝试代码来说非常棒，可能避免浪费时间和金钱。
- en: 'LocalStack spins up the following core Cloud APIs on your local machine:'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: LocalStack在您的本地机器上启动以下核心云API：
- en: API Gateway at http://localhost:4567
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API网关在http://localhost:4567
- en: Kinesis at http://localhost:4568
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kinesis在http://localhost:4568
- en: DynamoDB at http://localhost:4569
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DynamoDB在http://localhost:4569
- en: DynamoDB Streams at http://localhost:4570
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DynamoDB Streams在http://localhost:4570
- en: Elasticsearch at http://localhost:4571
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elasticsearch在http://localhost:4571
- en: S3 at http://localhost:4572
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S3在http://localhost:4572
- en: Firehose at http://localhost:4573
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Firehose在http://localhost:4573
- en: Lambda at http://localhost:4574
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda在http://localhost:4574
- en: SNS at http://localhost:4575
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SNS在http://localhost:4575
- en: SQS at http://localhost:4576
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SQS在http://localhost:4576
- en: Redshift at http://localhost:4577
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redshift在http://localhost:4577
- en: ES (Elasticsearch Service) at http://localhost:4578
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ES（Elasticsearch Service）在http://localhost:4578
- en: SES at http://localhost:4579
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SES在http://localhost:4579
- en: Route53 at http://localhost:4580
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Route53在http://localhost:4580
- en: CloudFormation at http://localhost:4581
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CloudFormation在http://localhost:4581
- en: CloudWatch at http://localhost:4582
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CloudWatch在http://localhost:4582
- en: LocalStack supports running in a Docker container, or natively on a machine.
    It’s built on Moto, which is a mocking framework in turn built on Boto, which
    is a Python AWS SDK.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: LocalStack支持在Docker容器中运行，或直接在机器上运行。它基于Moto构建，而Moto又基于Boto构建，Boto是一个Python AWS
    SDK的模拟框架。
- en: Running within an OpenShift cluster gives you the capability to run many of
    these AWS API environments. You can then create distinct endpoints for each set
    of services, and isolate them from one another. Also, you can worry less about
    resource usage, as the cluster scheduler will take care of that. But LocalStack
    doesn’t run out of the box, so we’ll guide you through what needs to be done to
    get it to work.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenShift集群中运行可以让你运行许多这些AWS API环境。然后，你可以为每组服务创建不同的端点，并将它们彼此隔离。此外，你不必太担心资源使用，因为集群调度器会处理这个问题。但是LocalStack不是直接运行的，所以我们将指导您完成使其工作所需的所有步骤。
- en: '**Ensuring Minishift is set up**'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: '**确保Minishift已设置**'
- en: At this point we assume you have Minishift set up—you should look at the official
    documentation on getting started at [https://docs.openshift.org/latest/minishift/getting-started/index.html](https://docs.openshift.org/latest/minishift/getting-started/index.html).
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们假设你已经设置了 Minishift ——你应该查看官方文档以了解如何开始，请参阅[https://docs.openshift.org/latest/minishift/getting-started/index.html](https://docs.openshift.org/latest/minishift/getting-started/index.html)。
- en: Listing 12.4\. Check Minishift is set up OK
  id: totrans-552
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.4\. 检查 Minishift 是否设置正确
- en: '[PRE46]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '**Changing the default security context constraints**'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: '**更改默认安全上下文约束**'
- en: Security context constraints (SCCs) are an OpenShift concept that allows more
    granular control over Docker containers’ powers. They control SELinux contexts
    (see [technique 100](kindle_split_027.xhtml#ch14sb09)), can drop capabilities
    from running containers (see [technique 93](kindle_split_027.xhtml#ch14sb02)),
    can determine which user the pod can run as, and so on.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 安全上下文约束（SCCs）是 OpenShift 的一个概念，它允许对 Docker 容器的权限进行更细粒度的控制。它们控制 SELinux 上下文（参见[技术
    100](kindle_split_027.xhtml#ch14sb09)），可以从运行中的容器中删除能力（参见[技术 93](kindle_split_027.xhtml#ch14sb02)），可以确定
    pod 可以以哪个用户运行，等等。
- en: To get this running, you’re going to change the default `restricted` SCC. You
    could also create a separate SCC and apply it to a particular project, but you
    can try that on your own.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 要使此运行，你需要更改默认的 `restricted` SCC。你也可以创建一个单独的 SCC 并将其应用于特定项目，但你可以自己尝试。
- en: 'To change the ‘restricted` SCC, you’ll need to become a cluster administrator:'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 要更改 `restricted` SCC，你需要成为集群管理员：
- en: '[PRE47]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Then you need to edit the restricted SCC with the following command:'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你需要使用以下命令编辑受限 SCC：
- en: '[PRE48]'
  id: totrans-560
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: You’ll see the definition of the `restricted` SCC.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到 `restricted` SCC 的定义。
- en: 'At this point you’re going to have to do two things:'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你需要做两件事：
- en: Allow containers to run as any user (in this case `root`)
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许容器以任何用户（在这种情况下为 `root`）运行
- en: Prevent the SCC from restricting your capabilities to setuid and setgid
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防止 SCC 限制你的 setuid 和 setgid 能力
- en: '**Allowing RunAsAny**'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: '**允许 RunAsAny**'
- en: The LocalStack container runs as root by default, but for security reasons,
    OpenShift doesn’t allow containers to run as root by default. Instead it picks
    a UID within a very high range, and runs as that UID. Note that UIDs are numbers,
    as opposed to usernames, which are strings mapped to a UID.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: LocalStack 容器默认以 root 用户运行，但出于安全原因，OpenShift 默认不允许容器以 root 用户运行。相反，它会选择一个非常高的范围内的
    UID，并以该 UID 运行。请注意，UID 是数字，与映射到 UID 的字符串用户名不同。
- en: To simplify matters, and to allow the LocalStack container to run as root, change
    these lines,
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化问题，并允许 LocalStack 容器以 root 用户运行，更改以下行，
- en: '[PRE49]'
  id: totrans-568
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'to read as follows:'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 读取如下：
- en: '[PRE50]'
  id: totrans-570
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: This allows containers to run as *any* user, and not within a range of UIDs.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许容器以任何用户身份运行，而不是在 UID 范围内。
- en: '**Allowing SETUID and SETGID capabilities**'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '**允许 SETUID 和 SETGID 能力**'
- en: When LocalStack starts up, it needs to become another user to start ElastiCache.
    The ElastiCache service doesn’t start up as the root user.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 当 LocalStack 启动时，它需要成为另一个用户来启动 ElastiCache。ElastiCache 服务不会以 root 用户启动。
- en: 'To get around this, LocalStack `su`’s the startup command to the LocalStack
    user in the container. Because the `restricted` SCC explicitly disallows actions
    that change your user or group ID, you need to remove these restrictions. Do this
    by deleting these lines:'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，LocalStack 将启动命令 `su` 到容器中的 LocalStack 用户。由于 `restricted` SCC 明确禁止更改用户或组
    ID 的操作，你需要移除这些限制。通过删除以下行来完成此操作：
- en: '[PRE51]'
  id: totrans-575
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '**Saving the file**'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: '**保存文件**'
- en: Once you’ve completed those two steps, save the file.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这两个步骤后，保存文件。
- en: Make a note of the host. If you run this command,
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 记录主机信息。如果你运行此命令，
- en: '[PRE52]'
  id: totrans-579
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: you’ll get the host that the Minishift instance is accessible as from your machine.
    Note this host, as you’ll need to substitute it in later.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 你将获得 Minishift 实例从你的机器可访问的主机。注意这个主机，因为你稍后需要替换它。
- en: '**Deploying the pod**'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: '**部署 pod**'
- en: 'Deploying the LocalStack is as easy as running this command:'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 LocalStack 与运行以下命令一样简单：
- en: '[PRE53]'
  id: totrans-583
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '|  |'
  id: totrans-584
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-585
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 备注
- en: If you want to take a deeper look at the localstack image, it’s available at
    [https://github.com/localstack/localstack](https://github.com/localstack/localstack).
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要深入了解 localstack 镜像，它可在[https://github.com/localstack/localstack](https://github.com/localstack/localstack)找到。
- en: '|  |'
  id: totrans-587
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: This takes the localstack/localstack image and creates an OpenShift application
    around it for you, setting up internal services (based on the exposed ports in
    the LocalStack Docker image’s Dockerfile), running the container in a pod, and
    performing various other management tasks.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使用localstack/localstack镜像，并为您创建围绕它的OpenShift应用程序，设置内部服务（基于LocalStack Docker镜像的Dockerfile中公开的端口），在Pod中运行容器，并执行各种其他管理任务。
- en: '**Creating the routes**'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: '**创建路由**'
- en: 'If you want to access the services from outside, you need to create OpenShift
    routes, which create an external address for accessing services within the OpenShift
    network. For example, to create a route for the SQS service, create a file like
    the following, called route.yaml:'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想从外部访问服务，您需要创建OpenShift路由，这些路由为OpenShift网络内的服务创建外部地址。例如，要为SQS服务创建路由，创建一个如下所示的文件，称为route.yaml：
- en: Listing 12.5\. route.yaml
  id: totrans-591
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.5\. route.yaml
- en: '[PRE54]'
  id: totrans-592
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '***1*** **The Kubernetes API version is specified at the top of the yaml file.**'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** **yaml文件顶部指定了Kubernetes API版本。**'
- en: '***2*** **The kind of object being created is specified as a “Route”.**'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** **正在创建的对象类型被指定为“Route”。**'
- en: '***3*** **The metadata section contains information about the route rather
    than the specification of the route itself.**'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** **元数据部分包含有关路由的信息，而不是路由本身的规范。**'
- en: '***4*** **The route is given a name here.**'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** **在这里为路由指定了一个名称。**'
- en: '***5*** **The spec section specifies the details of the route.**'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*** **规范部分指定了路由的详细信息。**'
- en: '***6*** **The host is the URL the route will be mapped to, meaning the URL
    the client hits.**'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6*** **主机是路由将被映射到的URL，即客户端击中的URL。**'
- en: '***7*** **The port section identifies which port the route will go to on the
    service specified in the “to” section**'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7*** **端口部分标识了路由将前往“to”部分中指定的服务的哪个端口**'
- en: '***8*** **The “to” section identifies where requests will be routed to.**'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8*** **“to”部分标识了请求将被路由到的位置。**'
- en: '***9*** **In this case, it’s rooted to the LocalStack service.**'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9*** **在这种情况下，它基于LocalStack服务。**'
- en: Create the route by running this command,
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行此命令创建路由，
- en: '[PRE55]'
  id: totrans-603
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: which creates the route from the yaml file you just created. This process is
    then repeated for each service you want to set up.
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 这将根据您刚刚创建的yaml文件创建路由。然后，对于您想要设置的每个服务，都会重复此过程。
- en: 'Then run `oc get all` to see what you’ve created within your OpenShift project:'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行 `oc get all` 以查看您在OpenShift项目中创建的内容：
- en: '[PRE56]'
  id: totrans-606
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '***1*** **Returns the most significant items in your OpenShift project**'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** **返回您OpenShift项目中最重要的项目**'
- en: '***2*** **First listed are the image streams. These are objects that track
    the state of local or remote images.**'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** **首先列出的是图像流。这些对象跟踪本地或远程图像的状态。**'
- en: '***3*** **Next, the deployment configs are listed, which specify how a pod
    should be rolled out to the cluster.**'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** **接下来，列出部署配置，这些配置指定了Pod应该如何部署到集群中。**'
- en: '***4*** **The third class is the replication configs, which specify the replicated
    characteristics of the running pods.**'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** **第三类是复制配置，它指定了运行Pod的复制特性。**'
- en: '***5*** **The fourth class is the routes set up in your project.**'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*** **第四类是您项目中设置的路线。**'
- en: '***6*** **Services are the next class listed. Here you see the ports exposed
    in the Dockerfile result in exposed ports for the service.**'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6*** **接下来列出的是服务。在这里，您可以看到Dockerfile中公开的端口在服务中公开。**'
- en: '***7*** **Finally, the pods in the project are listed.**'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7*** **最后，列出项目中的Pod。**'
- en: Although technically not *all* the objects available within your project, the
    `oc get all` command shows the ones most significant to running applications.
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然技术上不是您项目中可用的所有对象，但`oc get all`命令显示了运行应用程序最重要的那些对象。
- en: The SQS-like AWS service is now accessible as a URL endpoint to test your code
    against.
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于SQS的AWS服务现在可以通过URL端点访问，以测试您的代码。
- en: '**Accessing the services**'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: '**访问服务**'
- en: 'You can now hit the services from your host. Here’s an example of creating
    an SQS stream:'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以从主机访问服务。以下是一个创建SQS流的示例：
- en: '[PRE57]'
  id: totrans-618
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '***1*** **The aws client application is used to hit the newly created endpoint,
    and it asks kinesis to list its streams.**'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*** **aws客户端应用程序用于访问新创建的端点，并要求kinesis列出其流。**'
- en: '***2*** **JSON output indicates that no streams exist.**'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*** **JSON输出指示不存在流。**'
- en: '***3*** **The aws client is called again to create an SQS stream called “teststream”
    with a shard-count of 2.**'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*** **再次调用aws客户端以创建一个名为“teststream”的SQS流，其分片数为2。**'
- en: '***4*** **Again, you ask for a list of kinesis streams.**'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*** **再次，您请求kinesis流的列表。**'
- en: '***5*** **JSON output indicates that a stream exists called “teststream”.**'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*** **JSON 输出指示存在一个名为“teststream”的流。**'
- en: '|  |'
  id: totrans-624
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-625
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: The `aws` client is an install you’ll need to make this work. Alternatively,
    you can curl the API endpoint directly, but we don’t advise this. It’s also assumed
    you have run `aws configure` and specified your AWS keys and default region. The
    actual values specified don’t matter to LocalStack, as it doesn’t do authentication.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: '`aws` 客户端是您需要安装以使此功能正常工作的组件。或者，您可以直接 curl API 端点，但我们不建议这样做。还假设您已经运行了 `aws configure`
    并指定了您的 AWS 密钥和默认区域。实际指定的值对 LocalStack 没有关系，因为它不进行身份验证。'
- en: '|  |'
  id: totrans-627
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Here we’ve covered only one type of service, but this technique is easily extended
    to the others listed at the beginning of this technique.
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只介绍了一种服务类型，但这种技术可以轻松扩展到本技术开头列出的其他服务。
- en: '**DISCUSSION**'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: This technique has given you a sense of the power of OpenShift (and Kubernetes,
    on which OpenShift is based). To get a useful application spun up with a usable
    endpoint and all the internal wiring taken care of is in many ways the realization
    of the promise of portability that Docker offers, scaled up to the data centre.
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术让您感受到了 OpenShift（以及 OpenShift 所基于的 Kubernetes）的力量。以一个可用的端点和所有内部连接都得到妥善处理的方式启动一个有用的应用程序，在许多方面是
    Docker 提供的可移植性承诺的实现，扩展到了数据中心层面。
- en: For example, this could be taken further, and multiple instances of LocalStack
    could be spun up on the same OpenShift cluster. Tests against AWS APIs can be
    done in parallel without necessarily costing more resources (depending on the
    size of your OpenShift cluster and the demands of your tests, of course). Because
    this is all code, continuous integration could be set up to dynamically spin up
    and spin down LocalStack instances to talk to on each commit of your AWS codebase.
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这可以进一步发展，可以在同一个 OpenShift 集群上启动多个 LocalStack 实例。对 AWS API 的测试可以在不必要增加更多资源的情况下并行进行（当然，这取决于您的
    OpenShift 集群大小和测试需求）。因为这些都是代码，持续集成可以设置成在每次提交 AWS 代码库时动态启动和关闭 LocalStack 实例以进行通信。
- en: As well as pointing out various aspects of Kubernetes, this particular technique
    also demonstrates that products such as OpenShift are building on top of Kubernetes
    to extend its functionality. For example, security context constraints are an
    OpenShift concept (although security contexts are also in Kubernetes) and “routes”
    was a concept OpenShift created on top of Kubernetes that was eventually adapted
    for implementation in Kubernetes directly. Over time, features that have been
    developed for OpenShift have been upstreamed to Kubernetes and have become part
    of its offering.
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 除了指出 Kubernetes 的各个方面外，这个特定的技术还展示了像 OpenShift 这样的产品是如何在 Kubernetes 上构建，以扩展其功能。例如，安全上下文约束是
    OpenShift 的概念（尽管安全上下文也在 Kubernetes 中），而“路由”是 OpenShift 在 Kubernetes 上创建的一个概念，最终被直接用于
    Kubernetes 的实现。随着时间的推移，为 OpenShift 开发的功能已经上传到 Kubernetes，并成为了其提供的一部分。
- en: You’ll see OpenShift again in [technique 99](kindle_split_027.xhtml#ch14sb08)
    where we’ll look at how it can serve as a platform to securely let users run containers.
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在[技术 99](kindle_split_027.xhtml#ch14sb08)中再次看到 OpenShift，我们将探讨它如何作为一个平台，安全地让用户运行容器。
- en: '|  |'
  id: totrans-634
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '|  |'
  id: totrans-635
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Building a framework on Mesos**'
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: '**在 Mesos 上构建框架**'
- en: 'When discussing the multitude of orchestration possibilities, you’ll probably
    find one, in particular, mentioned as an alternative to Kubernetes: Mesos. Typically
    this is followed by opaque statements like “Mesos is a framework for a framework”
    and “Kubernetes can be run on top of Mesos.”'
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: 当讨论众多编排可能性时，您可能会发现特别提到的一个替代 Kubernetes 的选项：Mesos。通常这后面会跟着一些晦涩难懂的说法，比如“Mesos
    是一个框架的框架”和“Kubernetes 可以在 Mesos 上运行”。
- en: The most apt analogy we’ve come across is to think of Mesos as providing the
    kernel for your data center. You can’t do anything useful with it alone—the value
    comes when you combine it with an init system and applications.
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遇到的最恰当的类比是将 Mesos 视为为您的数据中心提供内核。仅凭它本身，您无法做任何有用的事情——价值在于您将其与初始化系统和应用程序结合使用时。
- en: For a low-tech explanation, imagine you have a monkey sitting in front of a
    panel that controls of all of your machines and has the power to start and stop
    applications at will. Naturally, you’ll need to give the monkey a *very* clear
    list of instructions about what to do in particular situations, when to start
    an application up, and so on. You could do it all yourself, but that’s time-consuming
    and monkeys are cheap.
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个低技术含量的解释，想象一下您面前有一只猴子坐在控制所有机器的面板前，它有权随意启动和停止应用程序。当然，您需要给猴子一个非常清晰的指令列表，说明在特定情况下应该做什么，何时启动应用程序等等。您可以自己完成所有这些，但这很耗时，而猴子又便宜。
- en: Mesos is the monkey!
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos 是那只猴子！
- en: Mesos is ideal for a company with a highly dynamic and complex infrastructure,
    likely with experience at rolling their own production orchestration solutions.
    If you don’t meet these conditions, you may be better served by an off-the-shelf
    solution rather than spending time tailoring Mesos.
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos 对于具有高度动态和复杂基础设施的公司来说很理想，这些公司可能有过自行开发生产编排解决方案的经验。如果您不符合这些条件，您可能更适合使用现成的解决方案，而不是花费时间定制
    Mesos。
- en: '**PROBLEM**'
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You have a number of rules for controlling the startup of applications and jobs,
    and you want to enforce them without manually starting them on remote machines
    and keeping track of their status.
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 您有一系列规则用于控制应用程序和作业的启动，您希望在不手动在远程机器上启动它们并跟踪它们的状态的情况下强制执行这些规则。
- en: '**SOLUTION**'
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Use Mesos, a flexible and powerful tool that provides an abstraction of resource
    management.
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Mesos，这是一个灵活且强大的工具，它提供了资源管理的抽象。
- en: Mesos is a mature piece of software for providing an abstraction of resource
    management on multiple machines. It’s been battle-tested in production by companies
    you’ve heard of, and, as a result, it’s stable and reliable.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos 是一个成熟的软件，用于在多台机器上提供资源管理的抽象。它已经由您所熟知的公司在生产环境中进行了实战测试，因此它稳定且可靠。
- en: '|  |'
  id: totrans-647
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-648
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: You need Docker 1.6.2 or later for Mesos to be able to use the correct Docker
    API version.
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要 Docker 1.6.2 或更高版本，以便 Mesos 能够使用正确的 Docker API 版本。
- en: '|  |'
  id: totrans-650
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '[Figure 12.3](#ch12fig03) shows what a generic production Mesos setup looks
    like.'
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.3](#ch12fig03) 展示了一个通用的生产 Mesos 设置。'
- en: Figure 12.3\. A generic production Mesos setup
  id: totrans-652
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 12.3\. 一个通用的生产 Mesos 设置
- en: '![](Images/12fig03_alt.jpg)'
  id: totrans-653
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/12fig03_alt.jpg)'
- en: 'Referring to this figure, you can see what the basic Mesos lifecycle for starting
    a task looks like:'
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: 参考此图，您可以看到启动任务的基本 Mesos 生命周期如下：
- en: '***1*****A slave runs on a node, tracking resource availability and keeping
    the master informed.**'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1*****从节点在节点上运行，跟踪资源可用性并向主节点报告。**'
- en: '***2*****The master receives information from one or more slaves about available
    resources and makes resource offers to schedulers.**'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2*****主节点从一个或多个从节点接收有关可用资源的信息，并向调度器提供资源。**'
- en: '***3*****A scheduler receives resource offers from the master, decides where
    it wants to run tasks, and communicates this back to the master.**'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3*****调度器从主节点接收资源，决定在哪里运行任务，并将此信息反馈给主节点。**'
- en: '***4*****The master passes on the task information to the appropriate slaves.**'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4*****主节点将任务信息传递给适当的从节点。**'
- en: '***5*****Each slave passes the task information to an existing executor on
    the node or starts a new one.**'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5*****每个从节点将任务信息传递给节点上的现有执行器或启动一个新的执行器。**'
- en: '***6*****The executor reads the task information and starts the task on the
    node.**'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6*****执行器读取任务信息并在节点上启动任务。**'
- en: '***7*****The task runs.**'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7*****任务运行。**'
- en: The Mesos project provides the master and slave, as well as a built-in shell
    executor. It’s your job to provide a *framework* (or *application*), which consists
    of a scheduler (the “list of instructions” in our monkey analogy) and optionally
    a custom executor.
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos 项目提供了主节点和从节点，以及内置的 shell 执行器。您的任务是提供一个 *框架*（或 *应用程序*），它由一个调度器（在我们的猴子类比中的“指令列表”）和可选的自定义执行器组成。
- en: Many third-party projects provide frameworks you can drop into Mesos (and we’ll
    look at one in more detail in the next technique), but to get a better understanding
    of how you can fully harness the power of Mesos with Docker, we’re going to build
    our own framework consisting only of a scheduler. If you have highly complex logic
    for starting applications, this may be your final chosen route.
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 许多第三方项目提供了可以集成到 Mesos 中的框架（我们将在下一技术中更详细地探讨一个），但为了更好地理解如何充分利用 Mesos 和 Docker
    的功能，我们将构建一个仅包含调度器的框架。如果您有启动应用程序的高度复杂逻辑，这可能就是您的最终选择路线。
- en: '|  |'
  id: totrans-664
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-665
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: You don’t have to use Docker with Mesos, but since that’s what the book is about,
    we will. There’s a lot of detail we won’t go into because Mesos is so flexible.
    We’re also going to be running Mesos on a single computer, but we’ll try to keep
    it as realistic as possible and point out what you need to do to go live.
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: 您不必在 Mesos 中使用 Docker，但由于本书的主题是关于这个，我们将使用它。由于 Mesos 非常灵活，因此我们不会深入探讨许多细节。我们还将在一个计算机上运行
    Mesos，但我们会尽量使其尽可能真实，并指出您需要做什么才能投入使用。
- en: '|  |'
  id: totrans-667
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: We’ve not yet explained where Docker fits into the Mesos lifecycle—the final
    piece to this puzzle is that Mesos provides support for *containerizers*, allowing
    you to isolate your executors or tasks (or both). Docker isn’t the only tool that
    can be used here, but it’s so popular that Mesos has some Docker-specific features
    to get you started.
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尚未解释 Docker 在 Mesos 生命周期中的位置——这个谜题的最后一部分是 Mesos 提供了对 *containerizers* 的支持，允许您隔离您的执行器或任务（或两者）。Docker
    不是唯一可以在这里使用的工具，但由于它非常流行，Mesos 为您提供了一些特定的 Docker 功能来帮助您开始。
- en: Our example will only containerize the tasks we run, because we’re using the
    default executor. If you had a custom executor only running a language environment,
    where each task involves dynamically loading and executing some code, you might
    want to consider containerizing the executor instead. As an example use case,
    you might have a JVM running as an executor that loads and executes pieces of
    code on the fly, avoiding JVM startup overhead for potentially very small tasks.
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例将仅对运行的任务进行容器化，因为我们使用的是默认执行器。如果您有一个仅运行语言环境的自定义执行器，其中每个任务都涉及动态加载和执行一些代码，您可能需要考虑对执行器进行容器化。作为一个示例用例，您可能有一个作为执行器的
    JVM，它会在运行时加载和执行代码片段，从而避免为可能非常小的任务带来 JVM 启动开销。
- en: '[Figure 12.4](#ch12fig04) shows what will be going on behind the scenes in
    our example when a new dockerized task is created.'
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.4](#ch12fig04) 展示了在我们的示例中创建新的 Docker 化任务时幕后将发生什么。'
- en: Figure 12.4\. A single-host Mesos setup starting a container
  id: totrans-671
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 12.4\. 单主机 Mesos 设置启动容器
- en: '![](Images/12fig04_alt.jpg)'
  id: totrans-672
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/12fig04_alt.jpg)'
- en: 'Without any further ado, let’s get started. First you need to start up a master:'
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 不再拖延，让我们开始吧。首先您需要启动一个主节点：
- en: Listing 12.6\. Starting a master
  id: totrans-674
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.6\. 启动主节点
- en: '[PRE58]'
  id: totrans-675
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The master startup is a little verbose, but you should find it stops logging
    quickly. Keep this terminal open so you can see what happens when you start the
    other containers.
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点启动时有些冗长，但你应该会发现它很快就会停止记录日志。请保持此终端打开，以便您可以看到启动其他容器时发生了什么。
- en: '|  |'
  id: totrans-677
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-678
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: Usually a Mesos setup will have multiple Mesos masters (one active and several
    backups), along with a Zookeeper cluster. Setting this up is documented on the
    “Mesos High-Availability Mode” page on the Mesos site ([http://mesos.apache.org/documentation/latest/high-availability](http://mesos.apache.org/documentation/latest/high-availability)).
    You’d also need to expose port 5050 for external communications and use the work_dir
    folder as a volume to save persistent information. You also need a slave. Unfortunately
    this is a little fiddly. One of the defining characteristics of Mesos is the ability
    to enforce resource limits on tasks, which requires the slave to have the ability
    to freely inspect and manage processes. As a result, the command to run the slave
    needs a number of outer system details to be exposed inside the container.
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，Mesos 设置将具有多个 Mesos 主节点（一个活动节点和几个备份节点），以及一个 Zookeeper 集群。在 Mesos 网站上的“Mesos
    高可用性模式”页面（[http://mesos.apache.org/documentation/latest/high-availability](http://mesos.apache.org/documentation/latest/high-availability)）上有设置此内容的文档。您还需要公开端口
    5050 以进行外部通信，并使用 work_dir 文件夹作为卷来保存持久信息。您还需要一个从属节点。不幸的是，这有点麻烦。Mesos 的一个定义特征是能够对任务强制资源限制，这要求从属节点能够自由地检查和管理进程。因此，运行从属节点的命令需要将许多外部系统细节暴露在容器内部。
- en: '|  |'
  id: totrans-680
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Listing 12.7\. Starting a slave
  id: totrans-681
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.7\. 启动从属节点
- en: '[PRE59]'
  id: totrans-682
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'At this point you should also have seen some activity in the Mesos master terminal,
    starting with a couple of lines like these:'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，您也应该在 Mesos 主节点终端中看到一些活动，开始于几行像这样的内容：
- en: '[PRE60]'
  id: totrans-684
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: The output of these two logs shows that your slave has started and is connected
    to the master. If you don’t see these, stop and double-check your master IP address.
    It can be frustrating later on to try and debug why a framework isn’t starting
    any tasks, when there are no connected slaves to start them on.
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个日志的输出显示您的从属节点已启动并连接到主节点。如果您没有看到这些，请停止并仔细检查您的主节点 IP 地址。当没有连接的从属节点来启动任务时，尝试调试框架为什么无法启动任务可能会很令人沮丧。
- en: Anyway, there’s a lot going on in the command in [listing 12.7](#ch12ex07).
    The arguments after `run` and before `redjack/mesos:0.21.0` are all Docker arguments,
    and they mainly consist of giving the slave container lots of information about
    the outside world. The arguments after `mesos-slave` are more interesting. First,
    `master` tells your slave where to find your master (or your Zookeeper cluster).
    The next three arguments, `executor _registration_timeout`, `isolation`, and `containerizers`,
    are all tweaks to Mesos settings that should always be applied when working with
    Docker. Last, but certainly not least, you need to let the Mesos slave know what
    ports are acceptable to hand out as resources. By default, Mesos offers 31000–32000,
    but we want something a bit lower and more memorable.
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，命令中 [列表 12.7](#ch12ex07) 有很多内容。在 `run` 和 `redjack/mesos:0.21.0` 之间的所有参数都是
    Docker 参数，它们主要包含向从机容器提供大量关于外部世界的信息。在 `mesos-slave` 之后的参数更有趣。首先，`master` 告诉你的从机在哪里可以找到你的主机（或你的
    Zookeeper 集群）。接下来的三个参数，`executor _registration_timeout`、`isolation` 和 `containerizers`，都是针对
    Mesos 设置的调整，当与 Docker 一起工作时应该始终应用。最后，但同样重要的是，你需要让 Mesos 从机知道哪些端口是可以分配作为资源的。默认情况下，Mesos
    提供 31000–32000，但我们想要一个更低且更容易记住的。
- en: Now the easy steps are out of the way and we come to the final stage of setting
    up Mesos—creating a scheduler.
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 现在简单的步骤已经完成，我们来到了设置 Mesos 的最后阶段——创建一个调度器。
- en: Happily, we have an example framework ready for you to use. Let’s try it out,
    see what it does, and then explore how it works. Keep your two `docker logs -f`
    commands open on your master and slave containers so you can see the communication
    as it happens.
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们有一个现成的示例框架供你使用。让我们试试看它做了什么，然后探索它是如何工作的。请保持你的两个 `docker logs -f` 命令在你的主容器和从容器上打开，这样你就可以看到通信是如何发生的。
- en: The following commands will get the source repository for the example framework
    from GitHub and start it up.
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将从 GitHub 获取示例框架的源代码库并启动它。
- en: Listing 12.8\. Downloading and starting the example framework
  id: totrans-690
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.8\. 下载并启动示例框架
- en: '[PRE61]'
  id: totrans-691
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: You’ll note that we’ve mounted the Git repository inside the Mesos image. This
    is because it contains all the Mesos libraries we need. Unfortunately, it can
    be a little painful to install them otherwise.
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到我们已经将 Git 仓库挂载到 Mesos 镜像中。这是因为它包含了我们需要的所有 Mesos 库。不幸的是，如果不这样做，安装它们可能会有些痛苦。
- en: Our `mesos-nc` framework is designed to run `echo 'hello <task id>' | nc -l
    <port>` on all available hosts, on all available ports from 8000 to 8005\. Because
    of how netcat works, these “servers” will terminate as soon as you access them,
    be it by curl, Telnet, nc, or your browser. You can verify this by running `curl
    localhost:8003` in a new terminal. It will return the expected response, and your
    Mesos logs will show the spawning of a task to replace the terminated one. You
    can also keep track of which tasks are running with `docker ps`.
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `mesos-nc` 框架旨在在所有可用的主机上，从8000到8005的所有可用端口上运行 `echo 'hello <task id>' |
    nc -l <port>`。由于 netcat 的工作方式，这些“服务器”在你访问它们时就会终止，无论是通过 curl、Telnet、nc 还是你的浏览器。你可以通过在新终端中运行
    `curl localhost:8003` 来验证这一点。它将返回预期的响应，并且你的 Mesos 日志将显示正在生成一个任务来替换已终止的任务。你还可以使用
    `docker ps` 来跟踪正在运行的任务。
- en: 'It’s worth pointing out here the evidence of Mesos keeping track of allocated
    resources and marking them as available when a task terminates. In particular,
    when you accessed `localhost:8003` (feel free to try it again), take a close look
    at the `Received offer` line—it shows two port ranges (as they’re not connected),
    including the freshly freed one:'
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: 值得指出的是，Mesos 在这里跟踪分配的资源，并在任务终止时将其标记为可用。特别是，当你访问 `localhost:8003`（随时可以再次尝试）时，仔细看看
    `Received offer` 行——它显示了两个端口范围（因为它们没有连接），包括刚刚释放的那个：
- en: '[PRE62]'
  id: totrans-695
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '|  |'
  id: totrans-696
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Warning
  id: totrans-697
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 警告
- en: The Mesos slave names all the containers it starts with the prefix “mesos-”,
    and it assumes anything like that can be freely managed by the slave. Be careful
    with your container naming, or you might end up with the Mesos slave killing itself.
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos 从机使用前缀“mesos-”命名它启动的所有容器，并且它假设类似的东西可以被从机自由管理。请小心你的容器命名，否则你可能会让 Mesos 从机杀死自己。
- en: '|  |'
  id: totrans-699
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: The framework code (myframework.py) is well commented, in case you’re feeling
    adventurous. We’ll go through some of the high-level design.
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: 框架代码（myframework.py）注释良好，以防你感到好奇。我们将探讨一些高级设计。
- en: '[PRE63]'
  id: totrans-701
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: All Mesos schedulers subclass the base Mesos scheduler class, and they implement
    a number of methods that Mesos will call at appropriate points to let your framework
    react to events. Although we’ve implemented three in the preceding snippet, two
    of those are optional and have been implemented to add extra logging for demonstration
    purposes. The only method you *must* implement is `resourceOffers`—there’s not
    much point in a framework that doesn’t know when it can launch tasks. You’re free
    to add any additional methods for your own purposes, such as *init* and `_makeTask`,
    as long as they don’t conflict with any of the methods Mesos expects to use, so
    make sure you read the documentation ([http://mesos.apache.org/documentation/latest/app-framework-development-guide/](http://mesos.apache.org/documentation/latest/app-framework-development-guide/)).
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: 所有Mesos调度器都是基于基本Mesos调度器类的子类，并且它们实现了一系列方法，Mesos会在适当的时候调用这些方法，以便你的框架能够对事件做出反应。尽管我们在前面的代码片段中实现了三个方法，但其中两个是可选的，并且为了演示目的添加了额外的日志记录。你必须实现的方法是`resourceOffers`——如果一个框架不知道何时可以启动任务，那么它就没有多少意义。你可以自由地添加任何额外的用于你自己的目的的方法，例如`init`和`_makeTask`，只要它们不与Mesos期望使用的方法冲突，所以请确保你阅读了文档([http://mesos.apache.org/documentation/latest/app-framework-development-guide/](http://mesos.apache.org/documentation/latest/app-framework-development-guide/))。
- en: '|  |'
  id: totrans-703
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Tip
  id: totrans-704
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 小贴士
- en: If you end up writing your own framework, you’ll want to look at some documentation
    of methods and structures. Unfortunately, at time of writing, the only generated
    documentation is for Java methods. Readers looking for a starting point for digging
    into the structures may wish to begin with the include/mesos/mesos.proto file
    in the Mesos source code. Good luck!
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你最终编写了自己的框架，你可能需要查看一些方法和结构的相关文档。不幸的是，在撰写本文时，只有Java方法的文档被生成。寻找结构探索起点的读者可能希望从Mesos源代码中的include/mesos/mesos.proto文件开始。祝你好运！
- en: '|  |'
  id: totrans-706
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'Let’s look in a bit more detail at the main method of interest: `resourceOffers`.
    This is where the decision happens to launch tasks or decline an offer. [Figure
    12.5](#ch12fig05) shows the execution flow after `resourceOffers` in our framework
    is called by Mesos (usually because some resources have become available for use
    by the framework).'
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看我们感兴趣的主要方法：`resourceOffers`。这是决定启动任务或拒绝offer的地方。[图12.5](#ch12fig05)显示了在Mesos调用我们的框架中的`resourceOffers`之后执行的流程（通常是因为某些资源已可供框架使用）。
- en: Figure 12.5\. Framework `resourceOffers` execution flow
  id: totrans-708
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.5\. 框架`resourceOffers`执行流程
- en: '![](Images/12fig05_alt.jpg)'
  id: totrans-709
  prefs: []
  type: TYPE_IMG
  zh: '![图12.5的替代文本](Images/12fig05_alt.jpg)'
- en: '`resourceOffers` is given a list of offers, where each offer corresponds to
    a single Mesos slave. The offer contains details about the resources available
    to a task launched on the slave, and a typical implementation will use this information
    to identify the most appropriate places to launch the tasks it wants to run. Launching
    a task sends a message to the Mesos master, which then continues with the lifecycle
    outlined in [figure 12.3](#ch12fig03).'
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: '`resourceOffers` 接收一个包含多个offer的列表，其中每个offer对应一个Mesos slave。offer包含了在从节点上启动的任务可用的资源详情，典型的实现会使用这些信息来确定启动任务的最佳位置。启动任务会向Mesos
    master发送消息，然后master继续执行[图12.3](#ch12fig03)中概述的生命周期。'
- en: '**DISCUSSION**'
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: It’s important to note the flexibility of `resourceOffers`—your task-launching
    decisions can depend on any criteria you choose, from health checks of external
    services to the phase of the moon. This flexibility can be a burden, so premade
    frameworks exist to take some of this low-level detail away and simplify Mesos
    usage. One of these frameworks is covered in the next technique.
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是`resourceOffers`的灵活性——你的任务启动决策可以基于你选择的任何标准，从外部服务的健康检查到月亮的相位。这种灵活性可能是一个负担，因此存在预制的框架来移除一些低级细节并简化Mesos的使用。这些框架中的一个将在下一个技巧中介绍。
- en: You may want to consult Roger Ignazio’s *Mesos in Action* (Manning, 2016) for
    more details on what you can do with Mesos—we’ve only scratched the surface here,
    and you’ve seen how easily Docker slots in.
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想查阅Roger Ignazio的《Mesos in Action》（Manning，2016）以获取更多关于Mesos可以做什么的详细信息——我们在这里只是触及了表面，你看到了Docker如何轻松地嵌入其中。
- en: '|  |'
  id: totrans-714
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '|  |'
  id: totrans-715
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Micromanaging Mesos with Marathon**'
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用Marathon微管理Mesos**'
- en: By now you’ll have realized that there’s a lot you need to think about with
    Mesos, even for an extremely simple framework. Being able to rely on applications
    being deployed correctly is extremely important—the impact of a bug in a framework
    could range from the inability to deploy new applications to a full service outage.
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该已经意识到，即使是对于一个非常简单的框架，你也需要考虑很多关于Mesos的事情。能够依赖应用程序被正确部署非常重要——框架中一个错误的后果可能从无法部署新应用程序到整个服务中断。
- en: The stakes get higher as you scale up, and unless your team is used to writing
    reliable dynamic deployment code, you might want to consider a more battle-tested
    approach—Mesos itself is very stable, but an in-house bespoke framework may not
    be as reliable as you’d want.
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你规模的扩大，风险也在增加，除非你的团队习惯于编写可靠的动态部署代码，否则你可能想要考虑一个经过更多实战检验的方法——Mesos本身非常稳定，但一个定制的内部框架可能不如你期望的那样可靠。
- en: Marathon is suitable for a company without in-house deployment tooling experience
    but that needs a well-supported and easy-to-use solution for deploying containers
    in a somewhat dynamic environment.
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: Marathon适合没有内部部署工具经验的公司，但需要在一个相对动态的环境中部署容器时，需要一个支持良好且易于使用的解决方案。
- en: '**PROBLEM**'
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: You need a reliable way to harness the power of Mesos without getting bogged
    down in writing your own framework.
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一个可靠的方式来利用Mesos的力量，同时避免陷入编写自己框架的困境。
- en: '**SOLUTION**'
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决方案**'
- en: Use Marathon, a layer on top of Mesos that provides a simpler interface to get
    you productive faster.
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Marathon，这是Mesos之上的一层，提供了一个更简单的接口，让你更快地投入生产。
- en: Marathon is an Apache Mesos framework built by Mesosphere for managing long-running
    applications. The marketing materials describe it as the `init` or `upstart` daemon
    for your datacenter (where Mesos is the kernel). This is not an unreasonable analogy.
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: Marathon是由Mesosphere为管理长期运行的应用程序而构建的Apache Mesos框架。营销材料将其描述为数据中心（其中Mesos是内核）的`init`或`upstart`守护进程。这不是一个不合理的类比。
- en: Marathon makes it easy to get started by allowing you to start a single container
    with a Mesos master, Mesos slave, and Marathon itself inside. This is useful for
    demos, but it isn’t suitable for production Marathon deployments. To get a realistic
    Marathon setup, you’ll need a Mesos master and slave (from the previous technique)
    as well as a Zookeeper instance (from [technique 84](kindle_split_023.xhtml#ch11sb04)).
    Make sure you have all this running, and we’ll get started by running the Marathon
    container.
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: Marathon通过允许你启动一个包含Mesos master、Mesos slave以及Marathon本身的单个容器来简化入门过程。这对于演示很有用，但并不适合生产环境的Marathon部署。为了得到一个真实的Marathon设置，你需要一个Mesos
    master和slave（来自之前的技术）以及一个Zookeeper实例（来自[技术84](kindle_split_023.xhtml#ch11sb04)）。确保所有这些都在运行，然后我们将通过运行Marathon容器开始。
- en: '[PRE64]'
  id: totrans-726
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Like Mesos itself, Marathon is fairly chatty, but (also like Mesos) it stops
    fairly quickly. At this point, it will enter the loop you’re familiar with from
    writing your own framework—considering resource offers and deciding what to do
    with them. Because we haven’t launched anything yet, you should see no activity;
    hence the `declining 1` in the preceding log.
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: 就像Mesos本身一样，Marathon相当健谈，但（也像Mesos一样）它停止得相当快。在这个阶段，它将进入你从编写自己的框架中熟悉的循环——考虑资源提供并决定如何处理它们。因为我们还没有启动任何东西，你应该看不到任何活动；这就是为什么在先前的日志中看到`declining
    1`的原因。
- en: Marathon comes with a nice-looking web interface, which is why we exposed port
    8080 on the host—visit http://localhost:8080 in your browser to pull it up.
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: Marathon提供了一个看起来很不错的Web界面，这就是为什么我们在主机上暴露了8080端口——在你的浏览器中访问http://localhost:8080来打开它。
- en: We’re going to dive straight into Marathon, so let’s create a new application.
    To clarify a bit of terminology—an “app” in the Marathon world is a group of one
    or more tasks with exactly the same definition.
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将直接进入Marathon，因此让我们创建一个新的应用程序。为了澄清一些术语——在Marathon的世界里，“app”指的是一组具有完全相同定义的一个或多个任务。
- en: Click the New App button at the top right to bring up a dialog box you can use
    to define the app you want to start up. We’ll continue in the vein of the framework
    we created ourselves by setting the ID to “marathon-nc”, leaving CPU, memory,
    and disk space at their defaults (to match the resource limits imposed on our
    mesos-nc framework), and setting the command to `echo "hello $MESOS_TASK_ID" |
    nc -l $PORT0` (using environment variables available to the task—note, that’s
    the number zero). Set the Ports field to 8000 as an indication of where you want
    to listen. For now we’re going to skip over the other fields. Click Create.
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: 点击右上角的“新建应用”按钮，将弹出一个对话框，您可以使用它来定义您想要启动的应用。我们将继续使用我们自己创建的框架的风格，将ID设置为“marathon-nc”，保留CPU、内存和磁盘空间在默认值（以匹配我们对mesos-nc框架施加的资源限制），并将命令设置为`echo
    "hello $MESOS_TASK_ID" | nc -l $PORT0`（使用任务可用的环境变量——注意，这是数字零）。将端口字段设置为8000，以指示您想要监听的位置。目前我们将跳过其他字段。点击创建。
- en: Your newly defined application will now be listed on the web interface. The
    status will briefly show as “Deploying” before showing as “Running.” Your app
    is now started!
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 您新定义的应用现在将列在Web界面上。状态将短暂显示为“部署中”，然后显示为“运行中”。您的应用现在已启动！
- en: If you click on the “/marathon-nc” entry in the Apps list, you’ll see the unique
    ID of your app. You can get the full configuration from the REST API as shown
    in the following snippet and also verify that it’s running by curling the Mesos
    slave container on the appropriate port. Make sure you save the full configuration
    returned by the REST API, as it’ll come in handy later—it’s been saved to app.json
    in the following example.
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您点击“应用列表”中的“/marathon-nc”条目，您将看到您应用的唯一ID。您可以从以下片段中获取完整的配置，并通过curl适当的端口上的Mesos从节点容器来验证它是否正在运行。确保您保存REST
    API返回的完整配置，因为它将在以后很有用——在以下示例中已保存到app.json中。
- en: '[PRE65]'
  id: totrans-733
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Note the text following “hello” in the output from `curl`ing the app—it should
    match the unique ID in the interface. Be quick with checking, though—running that
    `curl` command will make the app terminate, Marathon will relaunch it, and the
    unique ID in the web interface will change. Once you’ve verified all this, go
    ahead and click the Destroy App button to remove marathon-nc.
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 注意从`curl`应用输出的“hello”后面的文本——它应该与界面中的唯一ID匹配。但是检查要快——运行那个`curl`命令将使应用终止，Marathon将重新启动它，并且Web界面中的唯一ID将改变。一旦您验证了所有这些，请继续点击“销毁应用”按钮以删除marathon-nc。
- en: This works OK, but you may have noticed that we’ve not achieved what we set
    out to do with Marathon—orchestrate Docker containers. Although our application
    is within a container, it’s been launched in the Mesos slave container rather
    than in a container of its own. Reading the Marathon documentation reveals that
    creating tasks inside Docker containers requires a little more configuration (as
    it did when writing our own framework).
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 这工作得很好，但你可能已经注意到，我们没有通过Marathon实现我们设定的目标——编排Docker容器。尽管我们的应用在容器内，但它是在Mesos从节点容器中启动的，而不是在自己的容器中。阅读Marathon文档揭示，在Docker容器内创建任务需要更多的配置（就像我们编写自己的框架时一样）。
- en: Happily, the Mesos slave we started previously has both the required settings,
    so we just need to alter some Marathon options—in particular, app options. By
    taking the Marathon API response from before (saved in app.json), we can focus
    on adding the Marathon settings that enable Docker usage. To perform the manipulation
    here, we’ll use the handy `jq` tool, though it’s equally easy to do it via a text
    editor.
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们之前启动的Mesos从节点已经具备所需的设置，所以我们只需要修改一些Marathon选项——特别是应用选项。通过使用之前保存的Marathon
    API响应（保存在app.json中），我们可以专注于添加启用Docker使用的Marathon设置。为了在这里进行操作，我们将使用方便的`jq`工具，尽管通过文本编辑器来做也同样简单。
- en: '[PRE66]'
  id: totrans-737
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We can now send the new app definition to the API and see Marathon launch it:'
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以将新的应用定义发送到API，并看到Marathon启动它：
- en: '[PRE67]'
  id: totrans-739
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: As with our custom framework in the last technique, Mesos has launched a Docker
    container for us with the application running. Running `curl` terminates the application
    and container, and a new one is automatically launched.
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前的技术中自定义的框架一样，Mesos已经为我们启动了一个运行应用的Docker容器。运行`curl`命令将终止应用和容器，然后自动启动一个新的容器。
- en: '**DISCUSSION**'
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: There are some significant differences between the custom framework from the
    last technique and Marathon. For example, in the custom framework we had extremely
    fine-grained control over accepting resource offers, to the point where we could
    pick and choose individual ports to listen on. In order to do a similar thing
    in Marathon, you’d need to impose the setting on each individual slave.
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的技术中的自定义框架和 Marathon 相比，存在一些显著的不同。例如，在自定义框架中，我们对接受资源出价有极其细粒度的控制，以至于我们可以挑选和选择要监听的各个端口。要在
    Marathon 中做类似的事情，你需要对每个单独的从节点施加设置。
- en: By contrast, Marathon comes with a lot of built-in features that would be error-prone
    to build yourself, including health checking, an event notification system, and
    a REST API. These aren’t trivial things to implement, and using Marathon lets
    you operate with the assurance that you aren’t the first one trying it. If nothing
    else, it’s a lot easier to get support for Marathon than for a bespoke framework,
    and we’ve found that the documentation for Marathon is more approachable than
    that for Mesos.
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，Marathon 内置了许多功能，这些功能如果自己构建可能会出错，包括健康检查、事件通知系统和 REST API。这些都不是简单的事情来实现，使用
    Marathon 可以让你有信心，你不是第一个尝试的人。至少，与定制框架相比，Marathon 的支持要容易得多，我们发现 Marathon 的文档比 Mesos
    的文档更容易接近。
- en: We’ve covered the basics of setting up and using Marathon, but there are many
    more things to see and do. One of the more interesting suggestions we’ve seen
    is to use Marathon to start up other Mesos frameworks, potentially including your
    own bespoke one! We encourage you to explore—Mesos is a high-quality tool for
    orchestration, and Marathon provides a usable layer on top of it.
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了设置和使用 Marathon 的基础知识，但还有许多更多的事情要查看和执行。我们看到的更有趣的建议之一是使用 Marathon 启动其他
    Mesos 框架，可能包括你自己的定制框架！我们鼓励你探索——Mesos 是一个高质量的编排工具，而 Marathon 在其之上提供了一个可用的层。
- en: '|  |'
  id: totrans-745
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Summary
  id: totrans-746
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: You can start services on a cluster of machines with Docker swarm mode.
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用 Docker Swarm 模式在机器集群上启动服务。
- en: Writing a custom framework for Mesos can give you fine-grained control over
    your container scheduling.
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为 Mesos 编写自定义框架可以让你对容器调度有细粒度的控制。
- en: The Marathon framework on top of Mesos provides a simple way to harness some
    of the power of Mesos.
  id: totrans-749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Mesos 之上的 Marathon 框架提供了一种简单的方式来利用 Mesos 的一些功能。
- en: Kubernetes is a production-quality orchestration tool and has an API you can
    leverage.
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 是一个生产质量的编排工具，并有一个你可以利用的 API。
- en: OpenShift can be used to set up a local version of some AWS services.
  id: totrans-751
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenShift 可以用来设置一些 AWS 服务的本地版本。
- en: Chapter 13\. Docker platforms
  id: totrans-752
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 13 章\. Docker 平台
- en: '|  |'
  id: totrans-753
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**This chapter covers**'
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: '**本章涵盖**'
- en: The factors that inform the choice of Docker platform
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 影响 Docker 平台选择的因素
- en: The areas of consideration needed when adopting Docker
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采用 Docker 时需要考虑的领域
- en: The state of the Docker vendor landscape as of 2018
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2018 年 Docker 供应商领域的状况
- en: '|  |'
  id: totrans-758
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: The title of this chapter might seem confusing. Did the previous chapter not
    cover Docker platforms like Kubernetes and Mesos already?
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的标题可能看起来有些令人困惑。前一章没有涵盖 Kubernetes 和 Mesos 这样的 Docker 平台吗？
- en: Well, yes and no. Although Kubernetes and Mesos are arguably platforms on which
    you can run Docker, in this book we’re taking a *platform* to mean a product (or
    integrated set of technologies) that allows you to run and manage the operation
    of Docker containers in a structured way. You could think of this chapter as being
    more infrastructural than purely technical.
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，是的，也不是。尽管 Kubernetes 和 Mesos 可以说是可以运行 Docker 的平台，但在本书中，我们将“平台”理解为一种产品（或集成技术集），它允许您以结构化的方式运行和管理
    Docker 容器的操作。您可以将本章视为比纯技术更偏向基础设施。
- en: 'As of the time of writing, there are several Docker platforms:'
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，存在几个 Docker 平台：
- en: AWS Fargate
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS Fargate
- en: AWS ECS (Elastic Container Service
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS ECS (弹性容器服务)
- en: AWS EKS (Elastic Kubernetes Service)
  id: totrans-764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS EKS (弹性 Kubernetes 服务)
- en: Azure AKS (Azure Kubernetes Service)
  id: totrans-765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure AKS (Azure Kubernetes 服务)
- en: OpenShift
  id: totrans-766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenShift
- en: Docker Datacenter
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 数据中心
- en: “Native” Kubernetes
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “原生” Kubernetes
- en: '|  |'
  id: totrans-769
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-770
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: “Native” Kubernetes means running and managing your own cluster on whichever
    underlying infrastructure you prefer. You might want to run it on dedicated hardware
    in your own data centre or on VMs on a cloud provider.
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: “原生” Kubernetes 意味着在您偏好的任何底层基础设施上运行和管理自己的集群。您可能希望在您自己的数据中心中的专用硬件上运行它，或者在云提供商的虚拟机上运行它。
- en: '|  |'
  id: totrans-772
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: The hard part of platform adoption is deciding which platform to choose, and
    knowing what to consider when looking at Docker adoption across an organization.
    This chapter will provide a map of the decisions that need to be made in order
    to make a sensible choice of platform. It’ll help you understand why you might
    choose OpenShift over Kubernetes, or AWS ECS over Kubernetes, and so on.
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
  zh: 平台采用的难点在于决定选择哪个平台，以及了解在组织内查看Docker采用时需要考虑什么。本章将提供一个决策图，以帮助做出合理的平台选择。它将帮助你理解为什么你可能会选择OpenShift而不是Kubernetes，或者AWS
    ECS而不是Kubernetes等等。
- en: This chapter is structured in three parts. The first part discusses the factors
    that inform decisions about which technologies or solutions are appropriate to
    an organization looking to adopt Docker. The second part discusses the areas that
    need to be considered when looking to adopt Docker. The third discusses the state
    of the vendor landscape as of 2018.
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: 本章分为三个部分。第一部分讨论了对于希望采用Docker的组织来说，哪些技术或解决方案是合适的决策因素。第二部分讨论了在考虑采用Docker时需要考虑的领域。第三部分讨论了截至2018年的供应商格局。
- en: We’ve deployed Docker in multiple organizations, and we’ve spoken about the
    challenges of adoption at numerous conferences as well as within these organizations.
    What these experiences have taught us is that although the combination of challenges
    these organizations face are unique, there are patterns of decisions and classes
    of challenges that need to be understood before you go on the container journey.
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已在多个组织中部署了Docker，并在多次会议以及在这些组织中讨论了采用的挑战。这些经验教会我们的是，尽管这些组织面临的挑战组合是独特的，但在开始容器之旅之前，需要理解决策模式和挑战类别。
- en: 13.1\. Organizational choice factors
  id: totrans-776
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1. 组织选择因素
- en: This section will outline some of the major factors within your organization
    that may drive your platform choice for Docker. [Figure 13.1](#ch13fig01) shows
    some of these factors and their interrelations.
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将概述一些可能影响你组织内Docker平台选择的重大因素。[图13.1](#ch13fig01)展示了这些因素及其相互关系。
- en: Figure 13.1\. Factors driving platform choice
  id: totrans-778
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图13.1. 驱动平台选择的因素
- en: '![](Images/13fig01_alt.jpg)'
  id: totrans-779
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/13fig01_alt.jpg)'
- en: Before discussing these factors in detail, we’ll briefly define each and what
    is meant by it. You may have considered all these factors before and understand
    what they are, but different terminology within and between organizations can
    make the terminology unclear, and some terms are more commonly used in some organizations
    than others.
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: 在详细讨论这些因素之前，我们将简要定义每个因素及其含义。你可能已经考虑过所有这些因素并理解了它们是什么，但组织内部和组织之间的不同术语可能会使术语变得不明确，并且某些术语在某些组织中比在其他组织中更常用。
- en: '*Buy vs. build*—This refers to a difference in approach that organizations
    have toward new software deployment. Some organizations prefer to buy solutions,
    and others prefer to build and maintain them themselves. This in turn can influence
    which platform (or platforms) are chosen.'
  id: totrans-781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*购买与自建*——这指的是组织在新的软件部署方面采取的不同方法。一些组织更喜欢购买解决方案，而另一些组织则更喜欢自己构建和维护。这反过来又可能影响选择哪个平台（或哪些平台）。'
- en: '*Technical drivers*—Some businesses differentiate themselves on the specific
    characteristics of their technology, such as high levels of performance or cost
    efficiency of operation. What underpins these characteristics can be very niche,
    and specific technical components may not be catered for by commodity services
    or tooling. This can drive more bespoke solutions that drive a “build” rather
    than “buy” approach.'
  id: totrans-782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*技术驱动因素*——一些企业通过其技术的特定特性来区分自己，例如高性能或运营成本效率。支撑这些特性的基础可能非常特定，而一些特定的技术组件可能无法由通用服务或工具提供支持。这可能导致更多定制化解决方案，从而推动“自建”而不是“购买”的方法。'
- en: '*Monolithic vs. piecemeal*—Again, this is a general cultural approach that
    organizations can take toward software solutions. Some prefer to centralize solutions
    in a single monolithic entity (a centralized server or service), and others prefer
    to tackle problems piece by piece. The latter approach can be seen as more flexible
    and adaptable, whereas the former can be more efficient at scale.'
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*单体与模块化*——这同样是一种组织可以采取的一般文化方法，针对软件解决方案。一些组织更喜欢将解决方案集中在一个单体实体中（一个集中的服务器或服务），而另一些组织则更喜欢逐个解决问题。后者方法可以被视为更灵活和适应性更强，而前者在规模上可能更有效率。'
- en: '*Time to market*—Frequently organizations feel a pressure (for commercial or
    cultural reasons) to deliver a solution to their users quickly. This pressure
    can favor certain platforms over others at the expense of cost or flexibility
    in the future.'
  id: totrans-784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*上市时间*—经常，组织（出于商业或文化原因）会感到压力，需要快速向用户交付解决方案。这种压力可能会在未来牺牲成本或灵活性，从而优先考虑某些平台而非其他平台。'
- en: '*Open source vs. licensed*—Organizations usually have a preference for open
    source over licensed products these days, but there can still be good reasons
    to license a product from a vendor. Another related subject that pushes organizations
    toward open source solutions is fear of lock-in to a particular vendor or platform,
    leading to increased license costs as dependency on that product persists over
    time.'
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开源与许可*—如今，组织通常更倾向于选择开源产品而非许可产品，但仍然有很好的理由从供应商那里许可产品。另一个推动组织向开源解决方案转变的相关主题是对特定供应商或平台的锁定恐惧，这可能导致随着时间的推移，对该产品的依赖性增加，从而增加许可成本。'
- en: '*Consumer independence*—The platform you deploy will have consumers. These
    could be individuals, teams, or entire business units. Whatever the size of these
    consumers, they will have a culture and mode of operation. Key questions to ask
    here are how technically self-managing are they in their operational context,
    and how bespoke are their development needs? Answers to these questions may determine
    the character of platform you decide to deploy.'
  id: totrans-786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*消费者独立性*—你部署的平台将会有消费者。这些可以是个人、团队或整个业务单元。无论这些消费者的规模如何，他们都将有自己的文化和运作模式。这里的关键问题是他们在运营环境中在技术上是多么自我管理，以及他们的开发需求是多么定制化？对这些问题的回答可能会决定你决定部署的平台特征。'
- en: '*Cloud strategy*—Few organizations have no position defined toward cloud computing
    these days. Whether you’re looking to move workloads to the cloud immediately
    or not, the degree to which a solution is cloud native can be a factor in your
    decision-making process. Even if you’ve decided to move to the cloud, you’ll still
    need to consider whether the strategy is limited to one cloud or is designed to
    be portable across clouds, and even back to the data center.'
  id: totrans-787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*云战略*—如今，很少有组织对云计算没有明确的立场。无论你是否打算立即将工作负载迁移到云中，解决方案是否为云原生可能会成为你决策过程中的一个因素。即使你已经决定迁移到云，你仍然需要考虑该战略是否仅限于一个云，或者是否设计为可以在云之间甚至返回数据中心的可移植性。'
- en: '*Security stance*—Increasingly, organizations are taking security more seriously
    as part of their IT strategy. Whether it’s state-sponsored actors, amateur (or
    professional) hackers, industrial espionage, or plain theft, security is something
    that everyone has a position on. The level of attention devoted to this area can
    vary, so this can play a part in platform choice.'
  id: totrans-788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*安全立场*—随着组织越来越重视安全作为其IT战略的一部分，越来越多的组织正在认真对待安全问题。无论是国家支持的行为者、业余（或专业）黑客、工业间谍活动还是简单的盗窃，安全是每个人都持有立场的问题。对这个领域的关注程度可能有所不同，因此这可能在平台选择中发挥作用。'
- en: '*Organizational structure*—Many of the preceding definitions will potentially
    mean more to you if you work for an enterprise organization than if you work for
    the opposite kind of organization.'
  id: totrans-789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*组织结构*—许多先前的定义，如果你在一家企业组织中工作，可能对你更有意义，而不是在相反类型的组织中工作。'
- en: In this book we’ve defined *enterprise* broadly as an organization in which
    there’s a low degree of independence between the separate functions within it.
    For example, if you run a centralized IT function, can you deploy solutions without
    reference to any other part of the business (such as security, development teams,
    dev tooling teams, finance, operations/DevOps teams) without consequence? If so,
    we regard that as the opposite of an enterprise organization. Enterprise organizations
    tend to be larger (so functions are more discrete), and more regulated (internally
    and externally), which tends to constrain their freedom to enact change with less
    consequence.
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将*企业*广泛定义为内部各个职能之间独立性程度较低的组织。例如，如果你运行一个集中的IT职能，你是否可以在不参考业务其他部分（如安全、开发团队、开发工具团队、财务、运营/DevOps团队）的情况下部署解决方案而不会产生后果？如果是这样，我们认为这正是一个企业组织的对立面。企业组织往往规模更大（因此职能更独立），并且受到更多的监管（内部和外部），这往往限制了它们实施变革的自由，从而减少了变革的后果。
- en: By contrast, a non-enterprise organization (in this book) is one in which functions
    are free to deploy solutions as they see fit, through a process of self-determination.
    By this definition, startups are often seen as non-enterprise organizations because
    they can make decisions quickly and without reference to—or with speedier determination
    of—others’ needs.
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，非企业组织（在本书中）是指那些通过自我决定过程自由部署解决方案的组织。根据这个定义，初创公司通常被视为非企业组织，因为它们可以快速做出决定，而不需要参考或更快地确定他人的需求。
- en: Although non-enterprise organizations tend to favor some strategies (such as
    build over buy), it can still pay to think about the consequences of such decisions
    for the business over the long term.
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然非企业组织倾向于偏好某些策略（如“构建”而非“购买”），但考虑这些决策对业务长期后果的影响仍然是有益的。
- en: Let’s look more specifically at how the various factors interact to militate
    for or against different platforms. Hopefully some of these will resonate with
    your experience or situation.
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更具体地看看各种因素如何相互作用，以支持或反对不同的平台。希望其中一些能与你或你的情况产生共鸣。
- en: After this discussion, we’ll go on to look at the specific challenges that running
    a Docker platform can bring. With these factors as context, you can come to an
    informed decision about what technology best fits your organization’s needs.
  id: totrans-794
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次讨论之后，我们将继续探讨运行Docker平台可能带来的具体挑战。有了这些因素作为背景，你可以做出明智的决定，选择最适合你组织需求的技术。
- en: 13.1.1\. Time to market
  id: totrans-795
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.1.1. 市场投放时间
- en: 'It may be helpful first to consider the simplest of the factors: time to market.
    Everyone working within an organization feels some pressure to deliver solutions
    quickly, but the extent to which this is negotiable or desirable can vary.'
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: 首先考虑最简单的因素：市场投放时间可能是有帮助的。组织内的每个人都感到一些压力，需要快速交付解决方案，但这种压力的可协商性或可取性可能会有所不同。
- en: If a direct competitor has adopted a containerization strategy and is using
    this successfully to drive down costs, then senior management can get interested
    in how long your solution is taking to deliver.
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: 如果直接竞争对手已经采用容器化策略，并成功地利用它来降低成本，那么高级管理层可能会对您的解决方案交付时间产生兴趣。
- en: Alternatively, if you work for a more conservative organization, a speedily
    delivered solution might be seen to result in negative effects, such as lock-in
    to a hastily delivered or flavor-of-the-month platform that can’t move with changing
    needs.
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果你为一家更保守的组织工作，快速交付的解决方案可能会被视为产生负面影响，例如锁定在匆忙交付或过时平台，这种平台无法随着需求的变化而变化。
- en: Wiser heads may counsel you to resist the urge to adopt the first credible solution
    in the face of these dangers.
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: 更有经验的人可能会建议你抵制在面临这些危险时采用第一个可信解决方案的冲动。
- en: In general, pressure to deliver quickly drives a move toward “buy” over “build”
    and “monolithic” over “piecemeal” solutions to complex enterprise challenges.
    (These choices will be discussed further in the next section.) These challenges
    can be met by assigning responsibility for solving them to those vendors’ solutions.
    But this isn’t always possible, especially if the product isn’t mature.
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，快速交付的压力推动人们倾向于“购买”而非“构建”，以及“单一”而非“分块”的解决方案来解决复杂的业务挑战。（这些选择将在下一节中进一步讨论。）这些挑战可以通过将解决问题的责任分配给这些供应商的解决方案来解决。但这并不总是可能的，尤其是如果产品还不够成熟。
- en: Pressure to deliver can also result in the hasty delivery of bespoke solutions
    that fulfill the short term needs of the business. This is especially prevalent
    in organizations with a highly technical focus, and it can be very effective,
    providing an edge over the competition through control over the core technologies
    and knowledge of their workings. If technology isn’t a critical differentiator
    for your business, though, this can result in white-elephant technology that becomes
    difficult to move away from later, should the industry outpace your leading edge.
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
  zh: 迫于交付的压力也可能导致匆忙交付定制解决方案，以满足企业短期需求。这在高度技术导向的组织中尤为普遍，并且可能非常有效，通过控制核心技术和了解其运作方式，在竞争中取得优势。然而，如果技术不是你业务的关键差异化因素，这可能会导致难以摆脱的“白象”技术，如果行业超过了你的领先地位，那么这种技术可能会变得难以移除。
- en: Similarly, adopting click-and-consume cloud technologies can reduce your time
    to market significantly. The downside can be a consequent lock-in to that provider’s
    solution, driving up costs as you scale, and the cost of any future move away.
    It can also reduce flexibility in technical features or solutions, making you
    dependent on the growth and development of the cloud vendor’s product.
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，采用点击即用的云技术可以显著缩短你的上市时间。缺点可能是随之而来的对该提供商解决方案的锁定，随着规模的扩大而增加成本，以及未来任何迁移的成本。它还可以减少技术特性或解决方案的灵活性，使你依赖于云供应商产品的增长和发展。
- en: 13.1.2\. Buy vs. build
  id: totrans-803
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.1.2. 购买与构建
- en: Buying a solution can be an effective strategy in a number of ways. As you’ve
    seen, it can result in reducing time to market. If your organization is constrained
    in terms of development staff, you can also leverage the product’s (presumably)
    expanding feature set to offer more to your customers with relatively little investment.
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: 购买解决方案可以以多种方式成为有效的策略。正如你所看到的，它可以缩短上市时间。如果你的组织在开发人员方面受到限制，你还可以利用产品的（假设）不断扩大的功能集，以相对较少的投资向客户提供更多服务。
- en: 'Buying can also take off the operational cost, if you choose to operate it
    off-premises, as a service provided by the vendor. The degree to which you’re
    able to take this path may be limited by your security stance: software may be
    considered safe to run only if it’s on hardware owned and operated by the organization
    using it.'
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择将其作为供应商提供的服务在本地以外的地方运营，购买解决方案还可以降低运营成本。你能够走这条道路的程度可能受到你的安全立场的限制：软件只有在运行在由使用该组织的硬件和运营下才被认为是安全的。
- en: Building a platform yourself, either from scratch or from existing open source
    software, may appeal to you, since you’re reading this book. You would undoubtedly
    learn a lot from the process, but there are numerous dangers in such an approach
    from a business point of view.
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
  zh: 自己搭建平台，无论是从头开始还是基于现有的开源软件，可能对你有吸引力，因为你正在阅读这本书。毫无疑问，你会在这一过程中学到很多东西，但从商业角度来看，这种方法存在许多风险。
- en: First, you’ll likely need a highly skilled staff to continue to build and maintain
    this product. It can be much harder than you think (especially if you’ve been
    surrounded by computer scientists at work and at university) to source people
    who can program and operate complex IT systems, especially in recent years when
    such skills have been in high demand.
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你可能需要一支高度熟练的团队来继续构建和维护这个产品。与你的想象相比，这可能要困难得多（尤其是如果你在工作中和大学里一直围绕着计算机科学家）去寻找能够编程和操作复杂IT系统的人，尤其是在近年来这些技能需求很高的时期。
- en: Second, as time goes on, the container platform world will mature, with established
    players offering similar feature sets and commoditized skills around them. Against
    these offerings, a bespoke solution built for a specific organization’s needs
    some years ago can seem needlessly expensive where once it was a market differentiator.
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，随着时间的推移，容器平台世界将成熟，现有玩家将提供类似的功能集和围绕它们商品化的技能。在这些产品面前，几年前为特定组织需求构建的定制解决方案可能会显得不必要地昂贵，而曾经它是市场差异化因素。
- en: One strategy that can be adopted is “build, then buy,” where an organization
    builds a platform to meet its immediate needs, but looks to buy when the market
    has settled on a product that looks to be a standard. Of course, there’s a danger
    that the built platform becomes a “pet” that’s difficult to give up. As of the
    time of writing, Kubernetes appears to have gained almost complete dominance as
    the basis of most popular Docker platforms. Therefore, you might drop your bespoke
    solution in favor of a Kubernetes one if you take the view that that’s a good
    bet for the future.
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: 可以采用的一种策略是“先建后买”，即组织为了满足其即时需求而构建一个平台，但等到市场已经确定了一个看起来将成为标准的产品时再考虑购买。当然，存在这样的风险，即构建的平台变成一个难以放弃的“宠物”。截至写作时，Kubernetes似乎已经几乎完全主导了大多数流行的Docker平台。因此，如果你认为这是一个对未来有利的赌注，你可能会放弃定制的解决方案，转而选择Kubernetes。
- en: One platform that made two bets early was OpenShift, which embraced Docker soon
    after it burst onto the tech scene. It rewrote its entire codebase around Docker
    and Kubernetes. It’s currently a very popular option with enterprises as a result.
    By contrast, Amazon used Mesos as the basis of its ECS solution, which increasingly
    appeared niche as Kubernetes became more prevalent.
  id: totrans-810
  prefs: []
  type: TYPE_NORMAL
  zh: 早期就下注的两个平台之一是OpenShift，它在Docker出现在技术舞台上后不久就拥抱了它。它围绕Docker和Kubernetes重写了其整个代码库。因此，它目前是企业中一个非常受欢迎的选择。相比之下，亚马逊使用Mesos作为其ECS解决方案的基础，随着Kubernetes的普及，它越来越显得小众。
- en: 13.1.3\. Monolithic vs. piecemeal
  id: totrans-811
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.1.3\. 单体与零散
- en: The question of whether to run a single “monolithic” platform for all your Docker
    needs or to build functionality up from separate “piecemeal” solutions is closely
    related to the “buy vs. build” question. When considering buying a monolithic
    solution from a vendor, time to market can be a compelling reason to throw your
    lot in with them. Again, there are trade-offs with this approach.
  id: totrans-812
  prefs: []
  type: TYPE_NORMAL
  zh: 是否运行一个针对所有Docker需求的单一“单体”平台，还是从独立的“零散”解决方案中构建功能，这个问题与“购买与自建”问题密切相关。当考虑从供应商那里购买单体解决方案时，上市时间可能是一个有力的理由来选择与他们合作。同样，这种方法也有其权衡之处。
- en: The biggest danger is so-called *lock-in*. Some vendors charge for each machine
    the solution is deployed on. If your Docker estate grows significantly over time,
    the licensing costs can become prohibitive, and the platform can become a financial
    millstone around your neck. Some vendors even refuse to support Docker containers
    delivered by other vendors, which makes realistic adoption of them almost impossible.
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: 最大的危险是所谓的“锁定”。一些供应商对每个部署解决方案的机器收费。如果你的Docker资产随着时间的推移而显著增长，许可费用可能会变得难以承受，平台可能会成为你脖子上的财务磨石。一些供应商甚至拒绝支持其他供应商提供的Docker容器，这使得它们的实际采用几乎成为不可能。
- en: Against this is the piecemeal approach. By piecemeal we mean that you can (for
    example) have one solution for building containers, another for storing containers
    (such as a Docker registry), another for scanning containers, and yet another
    for running containers (perhaps even multiple solutions for this or any of the
    preceding categories). We’ll go into more depth about what “pieces” might need
    solving for in the next section of this chapter.
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
  zh: 相反的是零散的方法。通过零散，我们指的是你可以（例如）有一个用于构建容器的解决方案，另一个用于存储容器（如Docker注册表），另一个用于扫描容器，还有一个用于运行容器（也许甚至为这个或任何前面的类别提供多个解决方案）。我们将在本章下一节中更深入地探讨可能需要解决的“部分”是什么。
- en: Again, if you’re a small (and perhaps cash-rich) operation that needs to move
    quickly, the monolithic approach can deliver for you. The piecemeal approach allows
    you to adopt different solutions for various pieces as the need arises, giving
    you more flexibility and focus in your efforts.
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，如果你是一个需要快速行动的小型（可能资金充裕）企业，单体方法可以为你提供帮助。零散的方法允许你在需要时采用不同的解决方案，为不同的部分提供更多灵活性和努力的重点。
- en: 13.1.4\. Open source vs. licensed
  id: totrans-816
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.1.4\. 开源与许可
- en: Open source has come a long way in the last decade, so that it’s now a standard
    requirement for vendored or supported solutions. This contains within it a danger
    that’s not often obvious. Although many solutions are open source, lock-in isn’t
    necessarily avoided. In theory, the intellectual property of the software is available
    to use if you fall out with a supporting vendor, but often the skills required
    to manage and support the codebase are not.
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，开源已经取得了长足的进步，现在已成为供应商或支持解决方案的标准要求。这其中包含了一个不常明显的危险。尽管许多解决方案是开源的，但锁定并不一定能够避免。理论上，如果你与支持供应商发生冲突，软件的知识产权可供使用，但通常管理和支持代码库所需的技能并不具备。
- en: As one conference speaker put it recently, “open source plus vendor support
    is the new lock-in.” One could argue that this is a valid justification for the
    value the vendor brings to your organization—if it takes a lot of rare skill to
    manage a required platform, you’ll need to pay for it one way or another.
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
  zh: 如最近一位会议演讲者所说，“开源加供应商支持是新的锁定。”有人可能会认为这是供应商为你的组织带来的价值的有效理由——如果你需要大量罕见技能来管理所需的平台，你无论如何都需要为此付费。
- en: An interesting addition to this mix is cloud computing solutions, which could
    be regarded as both open sourced and licensed. They’re often based on open source
    software and open standards (such as Amazon’s EKS), but they can tie you in to
    their particular implementation of those standards and technologies, and gain
    your lock-in that way.
  id: totrans-819
  prefs: []
  type: TYPE_NORMAL
  zh: 这个混合体中一个有趣的新增元素是云计算解决方案，它们可以被视为既开源又许可。它们通常基于开源软件和开放标准（如亚马逊的EKS），但它们可以将你锁定在其特定实现的标准和技术上，并以此方式获得你的锁定。
- en: Another interesting mix is seen with platforms like OpenShift from Red Hat.
    OpenShift is a vendor-supplied platform with licenses required to run it. But
    its code is available on GitHub, and contributions from the community can be accepted
    into the main line. What Red Hat supplies as a value-add is support, feature development,
    and maintenance of the historical codebase. In theory, therefore, you can move
    off their implementation if you feel you aren’t getting value from their offering.
  id: totrans-820
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的情况是红帽（Red Hat）的OpenShift平台。OpenShift是一个需要许可证才能运行的供应商提供的平台。但它的代码可在GitHub上获取，社区贡献可以被接受到主线中。因此，红帽提供的有价值的服务包括支持、功能开发和历史代码库的维护。从理论上讲，因此，如果你觉得他们的产品没有带来价值，你可以离开他们的实现。
- en: 13.1.5\. Security stance
  id: totrans-821
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.1.5\. 安全立场
- en: Security concerns can have a strong influence on platform choice. Enterprise
    vendors such as Red Hat have a strong history of managing security, and OpenShift
    adds in SELinux protection for container security on top of protections already
    supplied by native Kubernetes.
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: 安全问题可能会对平台选择产生重大影响。企业供应商如红帽（Red Hat）在安全管理方面有着强大的历史，OpenShift在原生Kubernetes提供的安全保护之上增加了SELinux保护，以增强容器安全。
- en: The degree to which security matters to you can vary enormously. We have been
    involved in companies where developers have full and trusted access to production
    databases, as well as companies where paranoia about security is at its highest.
    These different levels of concern drive very different behaviors in development
    and production, and therefore in platform choices.
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: 安全对你来说的重要性可能会有很大差异。我们参与过一些公司，其中开发人员对生产数据库拥有完全和信任的访问权限，也参与过一些公司，其中对安全的担忧达到了顶峰。这些不同的担忧程度在开发和生产中驱使出非常不同的行为，因此也会影响平台选择。
- en: 'To take one simple example: do you trust your data and code to Amazon Web Services’
    (AWS’s) security standards and products? We aren’t singling out AWS here—as far
    as we know and have experienced, their security standards are generally considered
    second to none in the cloud space. Moreover, do you trust your development teams
    to manage the responsibilities that necessarily lie with the application teams?
    There have been enough stories of private data being exposed on AWS S3 buckets
    for this to be a concern for many companies.'
  id: totrans-824
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个简单的例子来说明：你是否信任你的数据和代码符合亚马逊网络服务（AWS）的安全标准和产品？在此我们并没有特别指出AWS——据我们所知和所经历，他们的安全标准在云空间中通常被认为是首屈一指的。此外，你是否信任你的开发团队能够管理与应用团队相关的必要责任？关于AWS
    S3存储桶上暴露的私人数据已经有很多故事，这已经成为许多公司的关注点。
- en: '|  |'
  id: totrans-825
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-826
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 备注
- en: the responsibility for exposing data on S3 is firmly with the consumer of AWS,
    and not with AWS itself. AWS gives you comprehensive tools to manage security,
    but they can’t manage your security requirements and operations for you.
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: 在S3上暴露数据的责任明确属于AWS的消费者，而不是AWS本身。AWS为你提供了全面的安全管理工具，但他们无法为你管理安全和操作需求。
- en: '|  |'
  id: totrans-828
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 13.1.6\. Consumer independence
  id: totrans-829
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.1.6\. 消费者独立性
- en: One factor that’s not often considered is the degree to which teams wish to
    self-manage. In smaller organizations this tends to vary less than in larger organizations.
    In larger organizations you can get development teams ranging from highly skilled
    ones that demand cutting-edge technological platforms to less skilled ones that
    simply want a curated way to deploy simple and stable web applications.
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很少被考虑的因素是团队希望自我管理的程度。在较小的组织中，这种程度的变化通常小于在较大的组织中。在较大的组织中，你可以得到从高度熟练且要求尖端技术平台到不太熟练且只想以精心策划的方式部署简单稳定Web应用的开发团队。
- en: These differing demands can lead to different platform choices. For example,
    we’ve seen environments where one business unit is happy with a centralized, curated,
    and monolithic platform, whereas another business unit demands a high degree of
    control and has specific technical requirements. Such users may push you toward
    a more bespoke platform than the vendored ones. If those users are willing to
    help build and maintain the platform, a productive partnership can ensue.
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
  zh: 这些不同的需求可能导致不同的平台选择。例如，我们见过一些环境中，一个业务单元对集中式、精心策划和单一的平台感到满意，而另一个业务单元则要求高度的控制和特定的技术要求。这类用户可能会推动你选择比供应商提供的更定制的平台。如果这些用户愿意帮助构建和维护平台，就可以形成富有成效的合作伙伴关系。
- en: If you’re large enough, and your development community is heterogeneous enough,
    you may even want to consider pursuing multiple options for your Docker platforms.
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您足够大，并且您的开发社区足够多样化，您甚至可能需要考虑为您的Docker平台追求多个选项。
- en: 13.1.7\. Cloud strategy
  id: totrans-833
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.1.7\. 云战略
- en: Most companies that deal in IT have some kind of stance toward cloud platforms.
    Some have embraced it wholeheartedly, and others are still starting their journey
    toward it, are in the process of moving, or are even moving back to the old fashioned
    data centre.
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
  zh: '大多数从事IT业务的公司都对云平台持有某种立场。一些公司完全接受它，而另一些公司仍在开始走向它的旅程，正在迁移过程中，甚至正在回到老式的数据中心。 '
- en: Whether your organization adopts a cloud Docker platform can be determined by
    this stance. Factors to consider center around whether there’s a fear of so-called
    “cloud vendor lock-in,” where moving your applications and data from the cloud
    vendor’s data centers becomes too costly to countenance. This can be guarded against
    by using open standards and products, or even by running existing products atop
    the generic compute resources supplied by those cloud vendors (rather than using
    their curated and sometimes cloud vendor–specific products).
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
  zh: 您的组织是否采用云Docker平台可以通过这种立场来确定。需要考虑的因素集中在是否存在所谓的“云供应商锁定”的恐惧，即将应用程序和数据从云供应商的数据中心迁移变得过于昂贵而无法容忍。这可以通过使用开放标准和产品来防范，甚至可以通过在那些云供应商提供的通用计算资源上运行现有产品（而不是使用他们精选的有时是云供应商特定的产品）来防范。
- en: 13.1.8\. Organizational structure
  id: totrans-836
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.1.8\. 组织结构
- en: Organizational structure is a fundamental characteristic of any company, and
    it informs all the other factors here. For example, if development teams are separated
    from operations teams, this tends to argue for adopting a standardized platform
    that both teams can manage and work against.
  id: totrans-837
  prefs: []
  type: TYPE_NORMAL
  zh: 组织结构是任何公司的基本特征，它影响着这里的所有其他因素。例如，如果开发团队与运维团队分离，这往往意味着采用一个标准化的平台，两个团队都可以管理和与之工作。
- en: Similarly, if responsibility for different parts of the operation are atomized
    in different groups, this tends to support a piecemeal approach to platform delivery.
    One example of this that we’ve seen is the management of Docker registries in
    larger organizations. If there’s already a centrally managed artifact store, it
    can make sense to simply upgrade the existing one and use it as a Docker registry
    (assuming it supports that use case). That way the management and operation of
    the store is cheaper than building a separate solution for what is essentially
    the same challenge.
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，如果运营的不同部分被不同的团队原子化，这往往会导致平台交付的零散方法。我们看到的这种例子之一是在大型组织中管理Docker注册库。如果已经有一个集中管理的工件存储库，那么简单地升级现有的存储库并将其用作Docker注册库（假设它支持这种用途）是有意义的。这样，存储库的管理和运营成本比为本质上相同的挑战构建单独的解决方案要低。
- en: 13.1.9\. Multiple platforms?
  id: totrans-839
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.1.9\. 多个平台？
- en: One pattern that may be appropriate to mention at this point is that for large
    organizations with divergent needs, another approach is possible. You may have
    some consumers that prefer managed platforms they can use, and other consumers
    in the same organization may demand more bespoke solutions.
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上可能适当提及的一个模式是，对于有不同需求的大型组织，另一种方法是有可能的。您可能有一些消费者更喜欢他们可以使用的托管平台，而同一组织中的其他消费者可能要求更定制的解决方案。
- en: 'In such cases, it can make sense to provide a highly opinionated and easier-to-manage
    platform for the first set of users, and a more flexible and perhaps more self-managed
    solution for others. In one case we’re aware of, three options are available:
    a self-managed Nomad cluster, an AWS-managed solution, and an OpenShift option.'
  id: totrans-841
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，为第一组用户提供一个高度意见化且易于管理的平台，为其他人提供更灵活且可能更自我管理的解决方案是有意义的。在我们所了解的一个案例中，有三个选项可供选择：一个自我管理的Nomad集群、一个AWS管理的解决方案和一个OpenShift选项。
- en: The obvious difficulty with this approach is the increased cost of management
    in running multiple classes of platform and the challenges of communicating these
    options effectively across the organization.
  id: totrans-842
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的明显困难在于，管理多个平台类别的成本增加，以及在整个组织中有效沟通这些选项的挑战。
- en: 13.1.10\. Organizational factors conclusion
  id: totrans-843
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.1.10\. 组织因素结论
- en: Hopefully that discussion resonated with you, and gave some idea of the complexities
    of choosing an appropriate platform for Docker (or indeed any technology) within
    organizations with differing needs. Although it may have seemed somewhat abstract,
    the next section will be much less so, as we look at the specific challenges you
    may need to consider when choosing solutions for your business. This discussion
    has given us the appropriate lenses with which to evaluate those problems and
    their possible solutions.
  id: totrans-844
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这次讨论能引起你的共鸣，并给你一些关于在需求不同的组织中为Docker（或任何技术）选择适当平台复杂性的想法。尽管这可能看起来有些抽象，但下一节将更加具体，因为我们将探讨在选择业务解决方案时你可能需要考虑的具体挑战。这次讨论为我们提供了评估这些问题及其可能解决方案的适当视角。
- en: 13.2\. Areas to consider when adopting Docker
  id: totrans-845
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2. 采用Docker时需要考虑的领域
- en: Finally, we get to talking about the specific functional challenges that might
    need to be addressed when implementing a Docker platform.
  id: totrans-846
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将讨论在实施Docker平台时可能需要解决的具体功能挑战。
- en: 'It’s divided into three sections:'
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: 它分为三个部分：
- en: '*Security and control*—Looks at items that will depend on your organization’s
    security and control stance'
  id: totrans-848
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*安全和控制*—探讨将取决于你组织的安全和控制立场的项目'
- en: '*Building and shipping images*—Looks at some of the things you’ll need to consider
    regarding development and delivery of your images and workloads'
  id: totrans-849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*构建和推送镜像*—探讨在开发和交付镜像和工作负载时需要考虑的一些事项'
- en: '*Running containers*—Considers what needs to be thought about as you operate
    your platform'
  id: totrans-850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*运行容器*—考虑在操作平台时需要思考的问题'
- en: Along the way we’ll consider specific current technologies. Mentioning a product
    in no way implies our endorsement, nor will the products we mention be exhaustive.
    Software products can improve and decline, and can be replaced or merged. They’re
    mentioned here only to illustrate the practical consequences of your platform
    choices.
  id: totrans-851
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程中，我们将考虑一些具体的技术。提及一个产品并不意味着我们对其表示认可，我们提及的产品也不会详尽无遗。软件产品可以改进和衰落，可以被替换或合并。它们在这里被提及只是为了说明你平台选择的实际后果。
- en: If many of the items we discuss seem obscure, or irrelevant to your organization,
    it’s likely you don’t operate under many constraints and therefore have greater
    freedom to do as you please. If so, you can consider this chapter as offering
    insight into some of the challenges seen in large-scale and regulated enterprises.
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们讨论的许多项目看起来很神秘，或者与你的组织无关，那么很可能你的组织没有太多限制，因此你有更大的自由去做你想做的事情。如果是这样，你可以考虑这一章提供了对大型和受监管企业中看到的某些挑战的见解。
- en: 13.2.1\. Security and control
  id: totrans-853
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.2.1. 安全和控制
- en: We’ll deal with security first, because in many ways your security and control
    stance will fundamentally affect the way you approach all the other topics. Also,
    if your organization is less concerned with security than other organizations,
    you may be less concerned with solving the problems outlined in this section.
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先处理安全问题，因为从许多方面来看，你的安全和控制立场将从根本上影响你处理所有其他话题的方式。此外，如果你的组织对安全的关注不如其他组织，你可能对解决本节中概述的问题不太关心。
- en: '|  |'
  id: totrans-855
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-856
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: By “control” we mean the systems of governance that are overlaid on the development
    team’s and run team’s operations. This includes centrally managed software development
    life cycles, license management, security audits, general audits, and so on. Some
    organizations have a very light touch, and others are more heavyweight.
  id: totrans-857
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们提到“控制”时，指的是覆盖在开发团队和运行团队操作之上的治理系统。这包括集中管理的软件开发生命周期、许可证管理、安全审计、一般审计等。一些组织的管理较为宽松，而另一些则较为严格。
- en: '|  |'
  id: totrans-858
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Image scanning
  id: totrans-859
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 镜像扫描
- en: 'Wherever you store your images, you have a golden opportunity at the point
    of storage to check that these images are as you wish them to be. What you might
    want to check depends on your use case, but here are some examples of specific
    questions you might want answered in more or less real time:'
  id: totrans-860
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你在哪里存储你的镜像，你都有在存储点检查这些镜像是否符合你期望的黄金机会。你可能想要检查的内容取决于你的用例，但以下是一些你可能希望实时回答的具体问题的例子：
- en: Which images have a shellshock version of bash?
  id: totrans-861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些镜像使用了bash的shellshock版本？
- en: Is there an out-of-date SSL library on any image?
  id: totrans-862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何镜像上是否有过时的SSL库？
- en: Which images are based on a now-suspect base image?
  id: totrans-863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些镜像基于现在可疑的基础镜像？
- en: Which images have nonstandard (or plain wrong) development libraries or tools
    on them?
  id: totrans-864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些镜像上安装了非标准（或完全错误）的开发库或工具？
- en: '|  |'
  id: totrans-865
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-866
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: Shellshock was a particularly serious set of security flaws in bash discovered
    in 2014\. Security companies recorded millions of attacks and probes related to
    the bug in the days following the disclosure of the first of a series of related
    bugs.
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
  zh: Shellshock 是 2014 年发现的 bash 中的一个特别严重的安全漏洞。安全公司在披露一系列相关漏洞的第一天就记录了数百万次针对该漏洞的攻击和探测。
- en: '|  |'
  id: totrans-868
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '[Figure 13.2](#ch13fig02) shows the basic workflow for an image scan in the
    software development lifecycle. The image is built and pushed to the registry,
    and this triggers an image scan. The scanner can either inspect the image in place
    on the registry or download it and work on it. Depending on the level of paranoia
    you have about images, you can synchronously check the image and prevent it from
    being used until it’s got the OK, or you can check the image asynchronously and
    provide a report to the submitting user. Usually the paranoid approach is taken
    for images used in production, and the asynchronous advisory approach is used
    in development.'
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 13.2](#ch13fig02) 展示了软件开发生命周期中图像扫描的基本工作流程。图像被构建并推送到注册表，这会触发图像扫描。扫描器可以检查注册表上的图像，或者下载它并对其进行处理。根据你对图像的担忧程度，你可以同步检查图像并阻止其使用，直到它得到批准，或者你可以异步检查图像并向提交用户提供报告。通常，对于生产中使用的图像，采用偏执的方法，而在开发中使用异步建议方法。'
- en: Figure 13.2\. Image scanning workflow
  id: totrans-870
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 13.2. 图像扫描工作流程
- en: '![](Images/13fig02_alt.jpg)'
  id: totrans-871
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/13fig02_alt.jpg)'
- en: 'In the world of image scanning, there are plenty of options, but they aren’t
    all equal. The most important thing to understand is that scanners roughly divide
    into two categories: those that focus on packages installed, and those that are
    primarily designed for deep scanning the software in the image. Examples of the
    first are Clair and OpenSCAP, and examples of the second are Black Duck Software,
    Twistlock, Aqua Security, Docker Inc., and many others. There’s some overlap between
    the two categories, but the principal dividing line is cost: it’s more expensive
    to maintain the necessary databases of information to keep up with weaknesses
    in various types of libraries or binaries, so the deep scanners tend to be far
    more costly.'
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像扫描的世界里，有很多选择，但它们并不完全相同。最重要的是理解扫描器大致分为两类：一类专注于已安装的包，另一类主要是为深入扫描图像中的软件而设计的。第一类的例子有
    Clair 和 OpenSCAP，第二类的例子有 Black Duck Software、Twistlock、Aqua Security、Docker Inc.
    以及许多其他公司。这两类之间有一些重叠，但主要的分界线是成本：维护必要的信息数据库以跟上各种库或二进制文件中的弱点需要更高的成本，因此深度扫描器往往成本更高。
- en: This division might be relevant for your decision making. If your images are
    semi-trusted, you might be able to assume that users aren’t being malicious and
    use a simpler package scanner. This will give you metrics and information about
    standard packages and their appropriate level of risk without too much cost.
  id: totrans-873
  prefs: []
  type: TYPE_NORMAL
  zh: 这种划分可能对你的决策有相关性。如果你的图像是半可信的，你可能可以假设用户没有恶意，并使用一个更简单的包扫描器。这将为你提供有关标准包及其适当风险水平的指标和信息，而无需花费太多成本。
- en: Although scanners can reduce the risk of malicious or unwanted software in your
    images, they aren’t magic bullets. Our experience in evaluating them suggests
    that even the best ones aren’t perfect, and that they tend to be better at identifying
    issues with some types of binaries or libraries than others. For example, some
    might more successfully identify npm package issues than (say) ones written in
    C++, or vice versa. See [technique 94](kindle_split_027.xhtml#ch14sb03) in [chapter
    14](kindle_split_027.xhtml#ch14) for an image we’ve used to exercise and test
    these scanners.
  id: totrans-874
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然扫描器可以降低你图像中恶意或不受欢迎软件的风险，但它们并不是万能的。我们评估它们的经验表明，即使是最好的扫描器也不是完美的，并且它们在识别某些类型的二进制文件或库的问题上可能比其他类型更好。例如，有些可能比用
    C++ 编写的（比如说）更成功地识别 npm 包问题，反之亦然。参见第 14 章[技术 94](kindle_split_027.xhtml#ch14sb03)中的图像，我们用它来测试和验证这些扫描器。
- en: Another thing to be aware of is that although scanners can work on immutable
    images and examine the static content of those images, there’s still an outstanding
    risk that containers can build and run malicious software at runtime. Static image
    analysis can’t solve that problem, so you might need to consider runtime control
    also.
  id: totrans-875
  prefs: []
  type: TYPE_NORMAL
  zh: 另一点需要注意是，尽管扫描器可以在不可变图像上工作并检查这些图像的静态内容，但仍然存在一个风险，即容器可以在运行时构建和运行恶意软件。静态图像分析无法解决这个问题，因此你可能需要考虑运行时控制。
- en: As with all the topics in this section, you must think about what you want to
    achieve when choosing a scanner. You might want to
  id: totrans-876
  prefs: []
  type: TYPE_NORMAL
  zh: 就像本节中的所有主题一样，在选择扫描器时，你必须考虑你想要实现的目标。你可能想要
- en: Prevent malicious actors from inserting objects into your builds
  id: totrans-877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防止恶意行为者在构建中插入对象
- en: Enforce company-wide standards on software usage
  id: totrans-878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强制执行公司范围内的软件使用标准
- en: Quickly patch known and standard CVEs
  id: totrans-879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速修补已知的和标准的 CVE
- en: '|  |'
  id: totrans-880
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-881
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: A CVE is an identifier for a software vulnerability, to allow for common and
    unambiguous identification of specific faults.
  id: totrans-882
  prefs: []
  type: TYPE_NORMAL
  zh: CVE 是软件漏洞的标识符，用于允许对特定错误的通用和明确的识别。
- en: '|  |'
  id: totrans-883
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Finally, you might also want to consider the cost of integrating this tool into
    your DevOps pipeline. If you find a scanner you’re happy with, and it’s well-integrated
    with your platform (or other related DevOps tooling), that might be another factor
    in its favor.
  id: totrans-884
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可能还想要考虑将此工具集成到你的 DevOps 管道中的成本。如果你找到一个让你满意的扫描器，并且它与你的平台（或其他相关 DevOps 工具）很好地集成，那么这可能是它有利的一个因素。
- en: Image integrity
  id: totrans-885
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 镜像完整性
- en: Image integrity and image scanning are often confused, but they aren’t the same
    thing. Whereas *image scanning* determines what’s *in* an image, *image integrity*
    ensures that what’s *retrieved* from the Docker registry is the same as what was
    securely placed there. (*Image verification* is another common way to describe
    this requirement.)
  id: totrans-886
  prefs: []
  type: TYPE_NORMAL
  zh: 镜像完整性和镜像扫描经常被混淆，但它们并不是同一件事。而*镜像扫描*确定镜像中有什么，*镜像完整性*确保从 Docker 注册表中检索的内容与安全放置的内容相同。（*镜像验证*也是描述这一要求的另一种常见方式。）
- en: 'Imagine the following scenario: Alice places an image in a repository (image
    A), and after it has gone through whatever mandated process exists to check that
    image, Bob wishes to run that image on a server. Bob requests image A from the
    server, but unknown to him, an attacker (Carol) has compromised the network, and
    placed a proxy between Bob and the registry. When Bob downloads the image, he
    is actually handed a malicious image (image C) that will run code that siphons
    off confidential data to a third-party IP outside the network. (See [figure 13.3](#ch13fig03).)'
  id: totrans-887
  prefs: []
  type: TYPE_NORMAL
  zh: 想象以下场景：Alice 将一个镜像放入仓库（镜像 A），在它经过任何必须的流程以检查该镜像之后，Bob 想要在服务器上运行该镜像。Bob 从服务器请求镜像
    A，但Bob并不知道，攻击者（Carol）已经破坏了网络，并在Bob和注册表之间放置了一个代理。当Bob下载镜像时，他实际上得到了一个恶意镜像（镜像 C），该镜像会运行代码，将机密数据传输到网络外的第三方
    IP 地址。（见[图 13.3](#ch13fig03)。）
- en: Figure 13.3\. Image integrity compromise
  id: totrans-888
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 13.3\. 镜像完整性破坏
- en: '![](Images/13fig03_alt.jpg)'
  id: totrans-889
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/13fig03_alt.jpg)'
- en: 'The question arises: when a Docker image is downloaded, how can you be sure
    it’s the one you asked for? Being sure of this is what image integrity addresses.'
  id: totrans-890
  prefs: []
  type: TYPE_NORMAL
  zh: 问题随之而来：当下载 Docker 镜像时，你如何确保它就是你所请求的那个？确保这一点正是镜像完整性所解决的问题。
- en: Docker Inc. led the way here with their Content Trust product, also known as
    Notary. This product signs image manifests with a privately held key that ensures
    that when the content is decrypted with a public key, the content is the same
    as what was uploaded to the registry. Content Trust offers further functionality
    around delegation of key responsibility that we won’t go into here.
  id: totrans-891
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Inc. 在其 Content Trust 产品中带了个头，也称为 Notary。该产品使用私钥对镜像清单进行签名，确保当内容使用公钥解密时，内容与上传到注册表的内容相同。Content
    Trust 提供了关于密钥责任委派的其他功能，这里不会详细介绍。
- en: Outside of Docker’s offering, there’s not much to report as of 2018, which is
    something of a tribute to their engineering lead on this. Leading products like
    Kubernetes and OpenShift offer very little in this area out of the box, so if
    you don’t buy Docker’s products, you may have to integrate these yourself. For
    many organizations, such an endeavor isn’t worth the effort, so they’ll rely on
    existing (likely perimeter) defenses.
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Docker 提供的范围内，截至 2018 年没有太多可以报告的，这可以说是对他们在这一领域工程领导地位的致敬。像 Kubernetes 和 OpenShift
    这样的领先产品在出厂时提供的功能非常有限，所以如果你不购买 Docker 的产品，你可能必须自己集成这些。对于许多组织来说，这样的努力不值得付出努力，因此他们将依赖现有的（可能是外围的）防御措施。
- en: If you do manage to implement an image integrity solution, you still must consider
    how the keys will be managed within your organization. Organizations that care
    enough to get this far will probably have policies and solutions in place for
    this.
  id: totrans-893
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你设法实现了镜像完整性解决方案，你仍然必须考虑如何在你的组织中管理这些密钥。那些足够关心并走到这一步的组织可能已经为此制定了政策和解决方案。
- en: Third-party images
  id: totrans-894
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第三方镜像
- en: 'Keeping on the subject of images, another common challenge when providing a
    platform is how you’re going to approach the subject of external images. Again,
    the basic difficulty here is one of trust: if you have a vendor that wants to
    bring a Docker image to your platform, how can you be sure that it’s safe to run?
    This is an especially significant question in a multi-tenant environment, where
    different teams (who don’t necessarily trust each other) must run containers on
    the same hosts.'
  id: totrans-895
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续讨论图像的话题时，另一个在提供平台时常见的挑战是如何处理外部图像的问题。同样，这里的根本困难是信任问题：如果你有一个想要将Docker图像带入你平台的供应商，你如何确保它安全运行？在多租户环境中，这是一个特别重要的问题，因为不同的团队（他们不一定相互信任）必须在同一主机上运行容器。
- en: One approach is simply to ban all third-party images, and only allow images
    to be built from known and curated base images using code and artifacts stored
    within the corporate network. Some vendor images can still be made to work within
    this regime. If the vendor image is essentially a JAR (Java archive) file running
    under a standard JVM, the image can be recreated and built within the network
    from that artifact and run under an approved JVM image.
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法就是简单地禁止所有第三方图像，只允许使用存储在企业网络内的代码和工件构建已知和精选的基础图像。一些供应商的图像仍然可以在这种制度下运行。如果供应商图像本质上是一个在标准JVM（Java虚拟机）下运行的JAR（Java归档）文件，那么可以从该工件在网络上重新创建和构建该图像，并在批准的JVM图像下运行。
- en: 'Inevitably, though, not all images or vendors will be amenable to this approach.
    If the pressure to allow third-party images is strong enough (and in our experience
    it is), you have several options:'
  id: totrans-897
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，不可避免的是，并非所有图像或供应商都会接受这种方法。如果允许第三方图像的压力足够大（根据我们的经验，确实是这样的），你有几个选择：
- en: Trust your scanner
  id: totrans-898
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信任你的扫描仪
- en: Examine the image by eye
  id: totrans-899
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过肉眼检查图像
- en: Make the team bringing the image into the organization responsible for its management
  id: totrans-900
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让将图像带入组织的团队负责其管理
- en: It’s unlikely you’ll entirely trust your scanner to give you sufficient certainty
    about the safety of a third-party image without the image being fully embedded
    over time, so responsibility will possibly need to rest somewhere else.
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有图像完全嵌入到系统中之前，你不太可能完全信任扫描仪为你提供关于第三方图像安全性的充分确定性，因此责任可能需要放在其他地方。
- en: The second option, manually examining images, isn’t scalable and is prone to
    error. The last option is the simplest and easiest to implement.
  id: totrans-902
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种选择，手动检查图像，不可扩展且容易出错。最后一种选择是最简单且最容易实施的。
- en: We’ve seen environments where all three approaches are taken, with the platform-management
    team sanity-checking the image, but with final responsibility resting with the
    application team bringing it. Often there’s an existing process for bringing virtual
    machine images into the organization, so a simple approach is to copy this procedure
    for Docker images. One key difference worth pointing out here is that although
    VMs are multi-tenant in that they share a hypervisor with their fellow tenants,
    Docker images share a fully featured operating system, which gives attacks a much
    larger surface area (see [chapter 14](kindle_split_027.xhtml#ch14) on security
    for more about this).
  id: totrans-903
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到过采取所有三种方法的环境，平台管理团队对图像进行合理性检查，但最终责任落在将图像带入的组织应用团队。通常，组织中已经存在将虚拟机图像带入组织的流程，因此对于Docker图像，简单的方法是复制此程序。这里值得指出的一项关键差异是，尽管虚拟机是多租户的，因为它们与同租户共享一个虚拟机管理程序，但Docker图像共享一个功能齐全的操作系统，这为攻击提供了更大的攻击面（有关更多信息，请参阅第14章[chapter
    14](kindle_split_027.xhtml#ch14)关于安全的内容）。
- en: A further option is to sandbox the running of images on their own hardware environment,
    such as through labeling Kubernetes nodes on a cluster, or using separate instances
    of cloud products like ECS, or running an entirely separate platform on separate
    hardware or even networks.
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是在自己的硬件环境中沙箱化图像的运行，例如通过在集群上标记Kubernetes节点，或使用像ECS这样的云产品的单独实例，或者在不同的硬件甚至网络上运行一个完全独立的平台。
- en: Secrets
  id: totrans-905
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 秘密
- en: Somehow (and especially when you get to production), privileged information
    will need to be managed in a secure way. Privileged information includes files
    or data passed in to builds, such as
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: 以某种方式（尤其是在你进入生产阶段时），需要以安全的方式管理特权信息。特权信息包括传递给构建的文件或数据，例如
- en: SSL keys
  id: totrans-907
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SSL密钥
- en: Username/password combinations
  id: totrans-908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户名/密码组合
- en: Customer-identifying data
  id: totrans-909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户识别数据
- en: This passing of secret data into the software lifecycle can be done at several
    points. One approach is to embed the secrets into your images at build time. This
    approach is highly frowned upon, as it spreads the privileged data wherever the
    image goes.
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
  zh: 将秘密数据传递到软件生命周期中的做法可以在多个点进行。一种方法是在构建时将秘密嵌入到你的镜像中。这种方法被高度反对，因为它会将特权数据传播到镜像的任何地方。
- en: 'A more approved method is to have the platform place the secrets into your
    containers at runtime. There are various ways to do this, but several questions
    that need to be answered:'
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
  zh: 更受认可的方法是在运行时让平台将秘密放入你的容器中。有各种方法可以做到这一点，但需要回答几个问题：
- en: Is the secret encrypted when stored?
  id: totrans-912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 秘密在存储时是否被加密？
- en: Is the secret encrypted in transit?
  id: totrans-913
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 秘密在传输过程中是否被加密？
- en: Who has access to the secret (in the store or at runtime in the container)?
  id: totrans-914
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁可以访问秘密（在存储中或在容器运行时）？
- en: How is the secret exposed within the container?
  id: totrans-915
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在容器内暴露秘密？
- en: Can you track or audit who saw or used the secret?
  id: totrans-916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能否追踪或审计谁看到了或使用了秘密？
- en: Kubernetes has a so-called “secrets” capability. What surprises many about this
    is that it’s stored in plain text in the persistent store (an etcd database).
    Technically, it’s base64-encoded, but from a security point of view, this is plain
    text (not encrypted, and easily reversed). If someone were to walk off with a
    disk containing this information, they could get access to these secrets without
    difficulty.
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes有一个所谓的“秘密”功能。许多人对这一点感到惊讶的是，它在持久存储（一个etcd数据库）中以纯文本形式存储。技术上，它是base64编码的，但从安全角度来看，这是纯文本（未加密，且容易逆转）。如果有人带着包含这些信息的磁盘离开，他们可以轻松地访问这些秘密。
- en: As it stands, there are proof-of-concept implementations of applications like
    HashiCorp’s vault to integrate with Kubernetes. Docker Swarm has more secure secrets
    support out of the box, but Docker Inc. appears to have thrown its lot in with
    Kubernetes in late 2017.
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，有一些概念验证实现，如HashiCorp的vault与Kubernetes集成。Docker Swarm自带更安全的秘密支持，但Docker Inc.似乎在2017年底将宝押在了Kubernetes上。
- en: Audit
  id: totrans-919
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 审计
- en: When running in production (or any other sensitive environment) it can become
    key to demonstrate that you have control over who ran what command and when. This
    is something that can be non-obvious to developers, who aren’t so concerned with
    recovering this information.
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境（或任何其他敏感环境）中运行时，证明你对谁运行了什么命令以及何时运行可能变得至关重要。这对于开发者来说可能不是那么明显，因为开发者不太关心恢复此类信息。
- en: The reasons for this “root” problem are covered in [chapter 14](kindle_split_027.xhtml#ch14),
    but they can be briefly covered here by saying that giving users access to the
    Docker socket effectively gives them root control over the whole host. This is
    forbidden in many organizations, so access to Docker usually needs to be traceable
    at the very least.
  id: totrans-921
  prefs: []
  type: TYPE_NORMAL
  zh: 这个“根”问题的原因在[第14章](kindle_split_027.xhtml#ch14)中有详细说明，但可以简要地在这里说，给予用户对Docker套接字的访问实际上给了他们整个主机的root控制权。这在许多组织中是禁止的，因此至少需要可追溯地访问Docker。
- en: 'These are some of the questions you might be required to answer:'
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是你可能需要回答的一些问题：
- en: Who (or what) is able to run the `docker` command?
  id: totrans-923
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁（或什么）能够运行`docker`命令？
- en: What control do you have over who runs it?
  id: totrans-924
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你对谁运行它有什么控制权？
- en: What control do you have over what is run?
  id: totrans-925
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你对运行的内容有什么控制权？
- en: Solutions exist for this problem, but they’re relatively new and generally part
    of other larger solutions. OpenShift, for example, has led the way by adding robust
    RBAC (role-based access control) to Kubernetes. Kubernetes later added this to
    its core. Cloud providers usually have more cloud-native ways to achieve this
    kind of control through (in the case of AWS) use of IAM roles or similar features
    embedded in ECS or EKS.
  id: totrans-926
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题，存在一些解决方案，但它们相对较新，通常作为其他更大解决方案的一部分。例如，OpenShift通过为Kubernetes添加强大的RBAC（基于角色的访问控制）而走在前列。Kubernetes后来将其添加到其核心。云提供商通常有更多云原生的方法通过（在AWS的情况下）使用IAM角色或嵌入在ECS或EKS中的类似功能来实现这种控制。
- en: Container security tools provided by vendors such as Twistlock and Aqua Security
    offer a means of managing which particular Docker subcommands and flags can be
    run by whom, usually by adding an intermediary socket or other kind of proxy between
    you and the Docker socket that can broker access to Docker commands.
  id: totrans-927
  prefs: []
  type: TYPE_NORMAL
  zh: 由Twistlock和Aqua Security等供应商提供的容器安全工具提供了一种管理特定Docker子命令和标志可以由谁运行的方法，通常是通过在你和Docker套接字之间添加一个中间套接字或其他类型的代理来实现，该代理可以代理对Docker命令的访问。
- en: In terms of recording who did what, native functionality has been slow in coming
    in products like OpenShift, but it’s there now. If you look at other products,
    don’t assume functionality like this has been fully implemented!
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
  zh: 在记录谁做了什么方面，原生功能在OpenShift等产品中进展缓慢，但现在已经有了。如果你查看其他产品，不要假设这种功能已经完全实现！
- en: Runtime control
  id: totrans-929
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 运行时控制
- en: Runtime control can be considered as auditing at a higher level. Regulated enterprises
    are likely to want to be able to determine what’s running across their entire
    estate and to report on this. The output of such reports can be compared with
    an existing configuration management database (CMDB) to see whether there are
    any anomalies or running workloads that can’t be accounted for.
  id: totrans-930
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时控制可以被视为更高层次的审计。受监管的企业可能希望能够确定其整个环境中正在运行的内容，并对此进行报告。这些报告的输出可以与现有的配置管理数据库（CMDB）进行比较，以查看是否存在任何异常或无法解释的运行工作负载。
- en: 'At this level, these are the questions you may be asked to answer:'
  id: totrans-931
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个层面，你可能需要回答以下问题：
- en: How can you tell what’s running?
  id: totrans-932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你如何判断正在运行什么？
- en: Can you match that content up to your registry/registries and/or your CMDB?
  id: totrans-933
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能将内容与你的注册表/注册表和/或你的CMDB匹配起来吗？
- en: Have any containers changed critical files since startup?
  id: totrans-934
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自启动以来，是否有容器更改了关键文件？
- en: Again, this comes with some other products that might form part of your Docker
    strategy, so watch out for them. Or it may be a side-effect of your overall application
    deployment strategy and network architecture. For example, if you build and run
    containers with an Amazon VPC, establishing and reporting what’s in them is a
    relatively trivial problem to solve.
  id: totrans-935
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这可能与一些可能成为你Docker策略一部分的其他产品有关，所以要注意它们。或者，这可能是你整体应用程序部署策略和网络架构的副作用。例如，如果你使用Amazon
    VPC构建和运行容器，建立和报告其中的内容是一个相对简单的问题。
- en: Another frequently seen selling point in this space is anomaly detection. Security
    solutions offer fancy machine-learning solutions that claim to learn what a container
    is supposed to do, and they alert you if it appears to do something out of the
    ordinary, like connect to a foreign application port unrelated to the application.
  id: totrans-936
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域，另一个常见的卖点就是异常检测。安全解决方案提供了复杂的机器学习解决方案，声称能够学习容器应该做什么，如果它看起来做了不寻常的事情，比如连接到与应用程序无关的外部应用程序端口，它们会向你发出警报。
- en: This sounds great, but you need to think about how this will work operationally.
    You can get a lot of false positives, and these may require a lot of curation—are
    you resourced to handle that? Generally speaking, the larger and more security-conscious
    an organization, the more likely they are to be concerned with this.
  id: totrans-937
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来很棒，但你需要考虑这在操作层面上如何运作。你可能会得到很多误报，这些可能需要大量的维护——你有资源来处理这些吗？一般来说，组织越大，对安全的意识越强，就越有可能对此表示关注。
- en: Forensics
  id: totrans-938
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 法医
- en: Forensics is similar to auditing, but it’s much more focused. When a security
    incident occurs, various parties will want to know what happened. In the old world
    of physicals and VMs, there were a lot of safeguards in place to assist post-incident
    investigation. Agents and watcher processes of all descriptions might have been
    running on the OS, or taps could be placed at a network or even hardware level.
  id: totrans-939
  prefs: []
  type: TYPE_NORMAL
  zh: 法医类似于审计，但更加专注。当发生安全事件时，各方都想知道发生了什么。在物理和虚拟机旧世界中，有大量的安全措施来协助事件后的调查。各种描述的代理和监视进程可能已经在操作系统上运行，或者可以在网络甚至硬件级别放置监听器。
- en: 'These are some of the questions that a forensic team might want answered following
    a security incident:'
  id: totrans-940
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些安全事件发生后，法医团队可能希望得到解答的问题：
- en: Can you tell who ran a container?
  id: totrans-941
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能说出谁运行了容器吗？
- en: Can you tell who built a container?
  id: totrans-942
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能说出谁构建了容器吗？
- en: Can you determine what a container did once it’s gone?
  id: totrans-943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能确定容器消失后它做了什么吗？
- en: Can you determine what a container might have done once it’s gone?
  id: totrans-944
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能确定容器消失后可能做了什么吗？
- en: In this context you might want to mandate the use of specific logging solutions,
    to ensure that information about system activity persists across container instantiations.
  id: totrans-945
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个背景下，你可能需要强制使用特定的日志解决方案，以确保系统活动信息在容器实例化之间持续存在。
- en: 'Sysdig and their Falco tool (which is open source) is another interesting and
    promising product in this area. If you’re familiar with tcpdump, this tool looks
    very similar, allowing you to query syscalls in flight. Here’s an example of such
    a rule:'
  id: totrans-946
  prefs: []
  type: TYPE_NORMAL
  zh: Sysdig及其Falco工具（这是一个开源工具）是该领域另一个有趣且具有潜力的产品。如果你熟悉tcpdump，这个工具看起来非常相似，允许你查询正在进行的系统调用。以下是一个此类规则的示例：
- en: '[PRE68]'
  id: totrans-947
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: It matches if a bash shell is run in a container.
  id: totrans-948
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在容器中运行bash shell，则匹配。
- en: Sysdig’s commercial offering goes beyond monitoring to allow you to take actions
    based on the tracked behaviors against your defined rulesets.
  id: totrans-949
  prefs: []
  type: TYPE_NORMAL
  zh: Sysdig的商业产品不仅限于监控，还允许你根据定义的规则集对跟踪的行为采取行动。
- en: 13.2.2\. Building and shipping images
  id: totrans-950
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.2.2. 构建和分发镜像
- en: With security covered, we come to building and shipping. This section looks
    at what you might need to think about when constructing and distributing your
    images.
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: 在安全得到保障后，我们转向构建和分发。本节探讨了在构建和分发镜像时你可能需要考虑的事项。
- en: Building images
  id: totrans-952
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 构建镜像
- en: When it comes to building images, there are a few areas you might want to consider.
  id: totrans-953
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建镜像时，有几个领域你可能需要考虑。
- en: First, although Dockerfiles are the standard, other methods of building images
    exist (see [chapter 7](kindle_split_017.xhtml#ch07)), so it might be desirable
    to mandate a standard if a variety of ways might cause confusion or aren’t compatible
    with each other. You might also have a strategic configuration management tool
    that you’ll want to integrate with your standard OS deployment.
  id: totrans-954
  prefs: []
  type: TYPE_NORMAL
  zh: 第一，尽管Dockerfile是标准，但构建镜像的其他方法也存在（参见[第7章](kindle_split_017.xhtml#ch07)），因此如果多种方式可能会引起混淆或彼此不兼容，强制执行一个标准可能是可取的。你可能还有一个战略性的配置管理工具，你希望将其与标准操作系统部署集成。
- en: Our real-world experience suggests that the Dockerfile approach is deeply ingrained
    and popular with developers. The overhead of learning a more sophisticated CM
    tool to conform to company standards for VMs is often not something developers
    have time or inclination for. Methods like S2I or Chef/Puppet/Ansible are more
    generally used for convenience or code reuse. Supporting Dockerfiles will ensure
    that you’ll get fewer questions and pushback from the development community.
  id: totrans-955
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实际经验表明，Dockerfile方法在开发者中根深蒂固且受欢迎。学习更复杂的CM工具以符合公司对虚拟机的标准，通常不是开发者有时间或意愿去做的事情。S2I或Chef/Puppet/Ansible等方法更常用于便利或代码重用。支持Dockerfile将确保你将收到更少的问题和来自开发社区的反对。
- en: Second, in sensitive environments, you may not want the building of images to
    be open to all users, as images may be trusted by other teams internally or externally.
    Building can be limited by appropriate tagging or promotion of images (see below),
    or through role-based access control.
  id: totrans-956
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，在敏感环境中，你可能不希望所有用户都能构建镜像，因为镜像可能被内部或外部的其他团队信任。可以通过适当的标记或镜像提升（见下文）或基于角色的访问控制来限制构建。
- en: 'Third, it’s worth thinking about the developer experience. For security reasons,
    it’s not always possible to give users open access to download Docker images from
    public repositories, nor even the ability to run Docker tools in their local environment
    (see [chapter 14](kindle_split_027.xhtml#ch14)). If this is the case, there are
    several options you might want to pursue:'
  id: totrans-957
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，值得考虑的是开发者的体验。出于安全原因，并不总是可能允许用户从公共仓库下载Docker镜像，甚至无法在他们的本地环境中运行Docker工具（参见[第14章](kindle_split_027.xhtml#ch14)）。如果情况如此，你可能想要探索以下几种选项：
- en: Getting approval for the standard tooling. This can be costly and sometimes
    too costly to achieve due to the security challenges and demands of the business.
  id: totrans-958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得标准工具的批准。这可能会很昂贵，有时由于安全挑战和业务需求，成本过高以至于难以实现。
- en: Creating a throwaway sandbox in which Docker images can be built. If the VM
    is transient, locked down, and heavily audited, many security concerns are significantly
    alleviated.
  id: totrans-959
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个可丢弃的沙盒，其中可以构建Docker镜像。如果虚拟机是瞬时的、受限制的且经过严格审计，许多安全担忧将显著减轻。
- en: Offering remote access to the above-mentioned sandbox via any Docker client
    (but note that this does not necessarily significantly reduce many attack surfaces).
  id: totrans-960
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过任何Docker客户端提供对上述沙盒的远程访问（但请注意，这并不一定显著减少许多攻击面）。
- en: Fourth, it’s also worth thinking about the consistency of the developer experience
    when deploying the application. For example, if developers are using docker-compose
    on their laptop or test environments, they might balk at switching to Kubernetes
    deployments in production. (As time goes on, this last point is becoming increasingly
    moot, as Kubernetes becomes a standard.)
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: 第四，在部署应用程序时，开发者体验的一致性也值得考虑。例如，如果开发者在他们的笔记本电脑或测试环境中使用docker-compose，他们可能会对在生产环境中切换到Kubernetes部署感到抵触。（随着时间的推移，这个最后一点变得越来越不重要，因为Kubernetes已成为标准。）
- en: Registry
  id: totrans-962
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注册表
- en: It should be obvious by now that you’ll need a registry. There’s an open source
    example, Docker Distribution, but it is no longer the dominant choice, mainly
    because a Docker registry is an implementation of a well-known API. There are
    now numerous offerings out there to choose from if you want to pay for an enterprise
    registry, or if you want to run an open source one yourself.
  id: totrans-963
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，您应该很明显需要注册表。有一个开源示例，Docker Distribution，但它不再是主导选择，主要是因为Docker注册表是一个知名API的实现。如果您想付费购买企业注册表，或者想自己运行开源注册表，现在有众多选择可供选择。
- en: Docker Distribution comes as part of Docker’s Data Centre product, which has
    some compelling features (such as Content Trust).
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Distribution是Docker数据中心产品的一部分，它具有一些吸引人的功能（如内容信任）。
- en: 'Whichever product you choose, there are some potentially less obvious points
    to consider:'
  id: totrans-965
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您选择哪个产品，都有一些可能不那么明显的问题需要考虑：
- en: Does this registry play nicely with your authentication system?
  id: totrans-966
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个注册表与您的身份验证系统兼容吗？
- en: Does it have role-based access control (RBAC)?
  id: totrans-967
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是否有基于角色的访问控制（RBAC）？
- en: Authentication and authorization is a big deal for enterprises. A quick and
    cheap, free-for-all registry solution will do the job in development, but if you
    have security or RBAC standards to maintain, these requirements will come to the
    top of your list.
  id: totrans-968
  prefs: []
  type: TYPE_NORMAL
  zh: 认证和授权对企业来说非常重要。一个快速且便宜的免费注册表解决方案可以在开发中完成工作，但如果您有安全或RBAC标准需要维护，这些要求将排在您的列表之首。
- en: Some tools have less-fine-grained RBAC features, and this can be quite a hole
    to fill if you suddenly find yourself audited and found wanting.
  id: totrans-969
  prefs: []
  type: TYPE_NORMAL
  zh: 一些工具具有较粗粒度的RBAC功能，如果您突然发现自己正在接受审计并发现不足，这可能是一个很大的漏洞。
- en: '*Does it have a means of promoting images?*—All images are not created equal.
    Some are quick-and-dirty dev experiments where correctness isn’t a requirement,
    whereas others are intended for bulletproof production usage. Your organization’s
    workflows may require that you distinguish between the two, and a registry can
    help you with this by managing a process via separate instances, or through gates
    enforced by labels.'
  id: totrans-970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*它有推广图像的手段吗？*—并非所有图像都是平等的。有些是快速且草率的开发实验，其中正确性不是必需的，而有些则是为防弹的生产使用而设计的。您组织的流程可能需要您区分这两者，而注册表可以通过管理通过单独实例或通过标签强制执行的门来帮助您做到这一点。'
- en: '*Does it cohere well with your other artifact stores?*—You likely already have
    an artifact store for TAR files, internal packages, and the like. In an ideal
    world, your registry would simply be a feature within that. If that’s not an option,
    integration or management overhead will be a cost you should be aware of.'
  id: totrans-971
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*它与您的其他工件存储库兼容吗？*—您可能已经有了用于TAR文件、内部包等工件存储库。在一个理想的世界里，您的注册表可能只是那个存储库中的一个功能。如果这不是一个选项，集成或管理开销将是一个您应该注意的成本。'
- en: Base images
  id: totrans-972
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基础镜像
- en: If you’re thinking about standards, the base image (or images) that teams use
    might need some consideration.
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在考虑标准，团队使用的基镜像（或镜像）可能需要一些考虑。
- en: First, what root image do you want to use, and what should go into it? Usually
    organizations have a standard Linux distribution they prefer to use. If so, that
    one is likely to be mandated as a base.
  id: totrans-974
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您想使用哪个根镜像，以及应该包含什么？通常，组织会有一个他们偏好的标准Linux发行版。如果是这样，那么这个版本可能被强制作为基础。
- en: Second, how will you build and maintain these images? In the event of a vulnerability
    being found, who (or what) is responsible for identifying whether you’re affected
    or which images are affected? Who is responsible for patching the affected estate?
  id: totrans-975
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，您将如何构建和维护这些镜像？在发现漏洞的情况下，谁（或什么）负责确定您是否受到影响或哪些镜像受到影响？谁负责修补受影响的领域？
- en: Third, what should go into this base image? Is there a common set of tooling
    that all users will want, or do you want to leave that to individual teams to
    decide? Do you want to separate these requirements out into separate subimages?
  id: totrans-976
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，基础镜像中应该包含什么？是否有一组所有用户都想要的工具，或者你想让各个团队自己决定？你想将这些需求分离成单独的子镜像吗？
- en: Fourth, how will these images and subimages be rebuilt? Usually some sort of
    pipeline needs to be created. Typically this will use some kind of CI tool, such
    as Jenkins, to automatically build the base image (and subsequently from that
    any subimages) when some trigger is effected.
  id: totrans-977
  prefs: []
  type: TYPE_NORMAL
  zh: 第四，这些镜像和子镜像将如何重建？通常需要创建某种类型的管道。通常这会使用某种类型的持续集成工具，例如Jenkins，在触发某些事件时自动构建基础镜像（以及随后从该镜像构建任何子镜像）。
- en: If you’re responsible for a base image, you may be challenged frequently about
    the size of this image. It’s often argued that thin images are better. In some
    respects (such as security) this might be argued, but this “problem” is more often
    imagined than real, particularly with respect to performance. The paradoxical
    nature of this situation is discussed in [technique 60](kindle_split_017.xhtml#ch07sb13).
  id: totrans-978
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你负责基础镜像，你可能会经常被问到这个镜像的大小。人们经常争论说，瘦镜像更好。在某些方面（如安全性）可能会有这样的争论，但这个问题通常是被想象出来的，而不是真实的，尤其是在性能方面。这种情况的矛盾性质在[技术60](kindle_split_017.xhtml#ch07sb13)中进行了讨论。
- en: Software development lifecycle
  id: totrans-979
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 软件开发生命周期
- en: A software development lifecycle (SDLC) is the defined process for how software
    is procured, created, tested, deployed, and retired. In its ideal state, it exists
    to help reduce inefficiencies by ensuring software is consistently evaluated,
    bought, and used within a group with a common interest in pooling resources.
  id: totrans-980
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发生命周期（SDLC）是软件采购、创建、测试、部署和退役的既定流程。在其理想状态下，它旨在通过确保软件在具有共同利益并希望集中资源的团队中一致性地评估、购买和使用来减少低效率。
- en: If you already have SDLC processes, how does Docker fit in? One can get into
    philosophical discussions about whether a Docker container is a package (like
    an rpm) or an entire Linux distribution (because its contents are arguably under
    the developer’s control). Either way, the key point of contention is usually over
    ownership. Who is responsible for what in the image? This is where Docker’s layered
    filesystem (see [chapter 1](kindle_split_010.xhtml#ch01)) comes into its own.
    Because who created what within the final image is completely auditable (assuming
    the content is trusted), then tracking back to who is responsible for what part
    of the software stack is relatively straightforward.
  id: totrans-981
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经有SDLC流程，Docker如何融入其中？人们可能会陷入哲学讨论，即Docker容器是一个包（如rpm）还是一个完整的Linux发行版（因为其内容可能在开发者的控制之下）。无论如何，争论的关键点通常是所有权。谁对镜像中的什么负责？这就是Docker分层文件系统（见[第1章](kindle_split_010.xhtml#ch01)）发挥作用的地方。因为最终镜像中创建的内容是完全可审计的（假设内容是可信的），所以追踪到谁负责软件栈的哪个部分相对简单。
- en: 'Once responsibility is identified, you can consider how patches will be handled:'
  id: totrans-982
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了责任，你可以考虑如何处理补丁：
- en: '*How do you identify which images need updating?*—A scanner can help here,
    or any tool that can identify files in artifacts that may be of interest.'
  id: totrans-983
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你如何确定哪些镜像需要更新？*—一个扫描器可以在这里帮助，或者任何可以识别可能感兴趣的工件中文件的工具。'
- en: '*How do you update them?*—Some platforms allow you to trigger rebuilds and
    deployments of containers (such as OpenShift, or possibly your hand-rolled pipeline).'
  id: totrans-984
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你如何更新它们？*—一些平台允许你触发容器的重建和部署（如OpenShift，或者可能是你手工制作的管道）。'
- en: '*How do you tell teams to update?*—Is an email sufficient? Or do you need an
    identifiable person as an owner. Again, your corporate policy will likely be your
    guide here. Existing policies should exist for more traditional software that’s
    deployed.'
  id: totrans-985
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你如何告诉团队进行更新？*—一封电子邮件足够吗？或者你需要一个可识别的负责人。再次强调，你的公司政策可能会在这里起到指导作用。现有的政策应该适用于更传统的已部署软件。'
- en: The key point in this new world is that the number of teams responsible for
    containers may be higher than in the past, and the number of containers to assess
    or update may be significantly higher also. All this can place a high burden on
    your infrastructure teams if you don’t have the processes in place to handle this
    uptick in software deliveries. If push comes to shove, you may need to force users
    to update by adding layers to their images if they don’t get in line. This is
    especially important if you run a shared platform. You could even consider using
    your orchestration tools to put “naughty” containers on specific isolated hosts
    to reduce risk. Usually these things are considered too late, and an answer must
    be improvised.
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个新世界中，关键点是负责容器的团队数量可能比过去更多，需要评估或更新的容器数量也可能显著增加。如果你没有建立相应的流程来处理软件交付的增加，所有这些都可能给你的基础设施团队带来沉重的负担。如果情况恶化，你可能需要通过向用户的镜像中添加层来强制他们更新，如果他们不排队的话。如果你运行的是共享平台，这一点尤为重要。你甚至可以考虑使用你的编排工具将“顽皮”的容器放在特定的隔离主机上以降低风险。通常，这些事情都是考虑得太晚，必须即兴发挥。
- en: 13.2.3\. Running containers
  id: totrans-987
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.2.3\. 运行容器
- en: Now we’ll look at the running of containers. In many respects, running containers
    is little different from running individual processes, but the introduction of
    Docker can bring its own challenges, and the changes of behavior that Docker enables
    can also force you to think about other aspects of your infrastructure.
  id: totrans-988
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将探讨容器的运行。在许多方面，运行容器与运行单个进程几乎没有区别，但Docker的引入可能会带来自己的挑战，Docker所启用的行为变化也可能迫使你思考基础设施的其他方面。
- en: Operating system
  id: totrans-989
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 操作系统
- en: The operating system you run can become significant when running your Docker
    platform. Enterprise operating systems can lag behind the latest and greatest
    kernel versions, and as you’ll see in [chapter 16](kindle_split_029.xhtml#ch16),
    the kernel version being run can be very significant for your application.
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行Docker平台时，你运行的操作系统可能变得很重要。企业操作系统可能落后于最新的内核版本，正如你将在第16章（[chapter 16](kindle_split_029.xhtml#ch16)）中看到的，运行的内核版本对你的应用程序可能非常重要。
- en: Historically, Docker has been a very fast-moving codebase, and not all curated
    OSes have been able to keep up (1.10 was a particularly painful transition for
    us, with significant changes to the storage format of images). It’s worth checking
    which versions of Docker (and related technologies, such as Kubernetes) are available
    to you in your package managers before you promise vendors their applications
    will run on your Kubernetes cluster.
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，Docker是一个非常快速发展的代码库，并不是所有的精选操作系统都能够跟上（1.10对我们来说是一个特别痛苦的过渡，因为对镜像的存储格式进行了重大更改）。在你向供应商承诺他们的应用程序将在你的Kubernetes集群上运行之前，检查你的包管理器中可用的Docker（和相关技术，如Kubernetes）的版本是值得的。
- en: Shared storage
  id: totrans-992
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 共享存储
- en: As soon as your users start deploying applications, one of the first things
    they’ll be concerned about is where their data goes. Docker has in its core the
    use of volumes (see [chapter 5](kindle_split_015.xhtml#ch05)) that are independent
    of the running containers.
  id: totrans-993
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的用户开始部署应用程序时，他们首先关心的一件事就是他们的数据去哪里。Docker的核心使用的是与运行中的容器无关的卷（见第5章[chapter 5](kindle_split_015.xhtml#ch05)）。
- en: These volumes can be backed by numerous kinds of storage mounted locally or
    remotely, but the key point is that the storage can be shared by multiple containers,
    which makes it ideal for running databases that persist across container cycles.
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
  zh: 这些卷可以由多种类型的存储支持，这些存储可以是本地或远程挂载的，但关键点是存储可以被多个容器共享，这使得它非常适合运行跨容器周期持久化的数据库。
- en: '*Is shared storage easy to provision?*—Shared storage can be expensive to maintain
    and provision, both in terms of the infrastructure required and the hourly cost.
    In many organizations, provisioning storage is not simply a matter of calling
    an API and waiting a few seconds, as it can be with cloud providers like AWS.'
  id: totrans-995
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*共享存储是否容易配置？*——共享存储在维护和配置方面可能很昂贵，无论是从所需的基础设施还是按小时成本来看。在许多组织中，配置存储不仅仅是调用API并等待几秒钟的事情，就像在AWS这样的云提供商中那样。'
- en: '*Is shared storage support ready for increased demand?*—Because it’s so easy
    to deploy Docker containers and fresh environments for development or test, demand
    on shared storage can increase dramatically. It’s worth considering whether you’re
    ready for this.'
  id: totrans-996
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*共享存储支持是否准备好应对增加的需求？*——因为部署Docker容器和开发或测试的新环境非常容易，对共享存储的需求可能会急剧增加。考虑你是否为此做好了准备是值得的。'
- en: '*Is shared storage available across deployment locations?*—You might have multiple
    data centers or cloud providers, or even a mix of the two. Can all these locations
    talk to each other seamlessly? Is it a requirement that they do? Or is it a requirement
    that they do not? Regulatory constraints and a desire to enable capabilities to
    your developers can both create work for you.'
  id: totrans-997
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*共享存储是否可在部署位置之间使用？*——你可能拥有多个数据中心或云提供商，甚至两者混合。所有这些位置能否无缝通信？这是否是一个要求？或者，这是一个不要求的要求？监管约束和为开发者启用功能的需求都可能为你创造工作。'
- en: Networking
  id: totrans-998
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 网络
- en: Regarding networking, there are a few things you might need to think about when
    implementing a Docker platform.
  id: totrans-999
  prefs: []
  type: TYPE_NORMAL
  zh: 关于网络，在实施 Docker 平台时，你可能需要考虑以下几点。
- en: As seen in [chapter 10](kindle_split_021.xhtml#ch10), by default each Docker
    container has its own IP address allocated from a reserved set of IP addresses.
    If you’re bringing in a product that manages the running of containers on your
    network, other sets of network addresses may be reserved. For example, Kubernetes’
    service layer uses a set of network addresses to maintain and route to stable
    endpoints across its cluster of nodes.
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [第 10 章](kindle_split_021.xhtml#ch10) 所见，默认情况下，每个 Docker 容器都会从预留的 IP 地址集中分配一个
    IP 地址。如果你引入了一个管理你网络上容器运行的产品，可能还有其他网络地址集被预留。例如，Kubernetes 的服务层使用一组网络地址来维护和路由其节点集群中的稳定端点。
- en: Some organizations reserve IP ranges for their own purposes, so you need to
    be wary of clashes. If an IP address range is reserved for a particular set of
    databases, for example, applications that use the IP range within your cluster
    for their containers or services may take over those IPs and prevent other applications
    within the cluster from gaining access to that set of databases. Traffic intended
    for those databases would end up being routed within the cluster to the container
    or service IPs.
  id: totrans-1001
  prefs: []
  type: TYPE_NORMAL
  zh: 一些组织为特定目的预留 IP 范围，因此你需要警惕冲突。例如，如果某个 IP 地址范围被预留用于特定的数据库集，那么使用你集群内 IP 范围的容器或服务可能接管这些
    IP，从而阻止集群内其他应用程序访问该数据库集。这些数据库的流量最终会被路由到集群内的容器或服务 IP。
- en: Network performance can also become significant. If you have software-defined
    networks (SDNs, such as Nuage or Calico) layered on top of your network already,
    adding more SDNs for Docker platforms (such as OpenVSwitch or even another Calico
    layer) can noticeably reduce performance.
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 网络性能也可能变得非常重要。如果你已经在网络上部署了软件定义网络（SDN，例如 Nuage 或 Calico），再为 Docker 平台添加更多 SDN（例如
    OpenVSwitch 或甚至另一个 Calico 层）可能会明显降低性能。
- en: Containers can also affect networking in ways you might not expect. Many applications
    have traditionally used a stable source IP address as part of authentication to
    external services. In the container world, however, the source IP presented from
    the container may be either the container IP or the IP of the host on which the
    container runs (which performs network address translation [NAT] back to the container).
    Furthermore, if it comes from a cluster of hosts, the IP that’s presented can’t
    be guaranteed to be stable. There are ways of ensuring the stability of IP presentation,
    but they usually need some design and implementation effort.
  id: totrans-1003
  prefs: []
  type: TYPE_NORMAL
  zh: 容器也可能以你意想不到的方式影响网络。许多应用程序传统上使用稳定的源 IP 地址作为外部服务认证的一部分。然而，在容器世界中，容器提供的源 IP 可能是容器
    IP 或容器运行的宿主机的 IP（该宿主机执行网络地址转换 [NAT] 回到容器）。此外，如果它来自主机集群，提供的 IP 不能保证是稳定的。确保 IP 展示稳定性的方法存在，但通常需要一些设计和实施工作。
- en: 'Load balancing is another area that potentially requires a great deal of effort.
    There’s so much to cover on this topic that it might well be the subject for another
    book, but here’s a brief list:'
  id: totrans-1004
  prefs: []
  type: TYPE_NORMAL
  zh: 负载均衡是另一个可能需要大量努力的领域。关于这个话题有很多内容要涵盖，它可能成为另一本书的主题，但这里有一个简要的列表：
- en: Which product is preferred/standard (for example, NGinx, F5s, HAProxy, HTTPD)?
  id: totrans-1005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪个产品更受欢迎/是标准产品（例如，NGinx、F5s、HAProxy、HTTPD）？
- en: How and where will you handle SSL termination?
  id: totrans-1006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将如何处理 SSL 终止？
- en: Do you need a mutual authentication TLS solution?
  id: totrans-1007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是否需要一个相互认证的 TLS 解决方案？
- en: How will certificates be generated and managed across your platform?
  id: totrans-1008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证书将在你的平台上如何生成和管理？
- en: Does your load balancer affect headers in a way that’s consistent with other
    applications across the business (be prepared to do a lot of debugging here if
    it doesn’t)?
  id: totrans-1009
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的负载均衡器是否以与其他业务应用程序一致的方式影响头部信息（如果不一致，请准备进行大量的调试）？
- en: Finally, if you’re using a cloud provider in addition to any data centers you
    already own or use, you may need to consider whether and how users will connect
    back to on-premises services from the cloud provider.
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您除了已经拥有或使用的任何数据中心外，还在使用云服务提供商，您可能需要考虑用户如何从云服务提供商连接回本地服务。
- en: Logging
  id: totrans-1011
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 记录
- en: Pretty much every application will have log files associated with it. Most applications
    will want to access those logs in a persistent way (especially in production),
    so some kind of centralized logging service is usually required. Because containers
    are ephemeral (where VMs and dedicated servers are usually not), such logging
    data can be lost if the container dies and logs are stored on its filesystem.
    Moving to the containerized world might bring the logging challenge more to the
    fore for these reasons.
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎每个应用程序都会与其相关的日志文件。大多数应用程序都希望以持久的方式访问这些日志（尤其是在生产环境中），因此通常需要某种集中式日志记录服务。由于容器是短暂的（而虚拟机和专用服务器通常不是），如果容器死亡且日志存储在其文件系统上，这些日志数据可能会丢失。因此，转向容器化世界可能会因为这些原因而使日志记录挑战更加突出。
- en: Because logging is such a core and common piece of application functionality,
    it often makes sense to centralize and standardize it. Containers can provide
    an opportunity to do just that.
  id: totrans-1013
  prefs: []
  type: TYPE_NORMAL
  zh: 由于记录是应用程序功能的核心和常见部分，因此集中化和标准化它通常是有意义的。容器提供了实现这一目标的机会。
- en: Monitoring
  id: totrans-1014
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 监控
- en: Most applications will need to be monitored to a greater or lesser extent, and
    there is a bewildering array of vendors and products related to container monitoring.
    This is still an emerging area.
  id: totrans-1015
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数应用程序在某种程度上都需要进行监控，与容器监控相关的供应商和产品种类繁多。这仍然是一个新兴领域。
- en: One product that has a great deal of traction in the Docker space is Prometheus.
    Originally developed by SoundCloud, it has grown in popularity over time, particularly
    since it became part of the Cloud Native Computing Foundation.
  id: totrans-1016
  prefs: []
  type: TYPE_NORMAL
  zh: 在Docker领域有一个产品非常受欢迎，那就是Prometheus。它最初由SoundCloud开发，随着时间的推移越来越受欢迎，尤其是在它成为云原生计算基金会的一部分之后。
- en: Because containers aren’t the same as VMs or physical machines, traditional
    monitoring tools won’t necessarily work well inside containers, as sidecars, or
    on the host if they’re not container-aware.
  id: totrans-1017
  prefs: []
  type: TYPE_NORMAL
  zh: 由于容器与虚拟机或物理机器不同，传统的监控工具在容器内部、作为边车，或者在主机上（如果它们不具备容器感知能力）可能不会很好地工作。
- en: Having said that, if you’re running a cluster of hosts and need to maintain
    them, traditional, established, mature monitoring tools will come in handy. Likely,
    they’ll be relied on heavily as you try to squeeze the maximum performance out
    of your cluster for the end users. That’s assuming the platform is a success.
    Our experience suggests that demand often far exceeds supply.
  id: totrans-1018
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，如果您正在运行一组主机并需要维护它们，传统的、成熟的监控工具将非常有用。很可能，在您试图从集群中榨取最大性能以供最终用户使用时，它们会被大量依赖。这是假设平台成功的前提下。我们的经验表明，需求往往远超过供应。
- en: 13.3\. Vendors, organizations, and products
  id: totrans-1019
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3. 供应商、组织和产品
- en: There’s no shortage of companies and organizations looking to make money from
    Docker. Here we’ll look at the biggest and most significant players as of 2018,
    and we’ll attempt to describe where their efforts are focused and how their products
    might work for you.
  id: totrans-1020
  prefs: []
  type: TYPE_NORMAL
  zh: 想从Docker中赚钱的公司和组织并不少见。在这里，我们将探讨截至2018年最大的和最有影响力的参与者，并尝试描述他们的努力方向以及他们的产品可能如何为您服务。
- en: 13.3.1\. The Cloud Native Computing Foundation (CNCF)
  id: totrans-1021
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.3.1. 云原生计算基金会（CNCF）
- en: The first of these organizations is different in that it’s not a company, but
    it’s probably the most influential player in this space. The CNCF was set up in
    2015 to promote common standards in container technology. Founding members included
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组织中的第一个不同之处在于它不是一个公司，但可能是这个领域最有影响力的参与者。CNCF（云原生计算基金会）成立于2015年，旨在推广容器技术的共同标准。创始成员包括
- en: Google
  id: totrans-1023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谷歌
- en: Twitter
  id: totrans-1024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推特
- en: Intel
  id: totrans-1025
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英特尔
- en: Cisco
  id: totrans-1026
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思科
- en: IBM
  id: totrans-1027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 国际商业机器公司（IBM）
- en: Docker
  id: totrans-1028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker
- en: VMWare
  id: totrans-1029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟机软件公司（VMWare）
- en: Its creation coincided with the release of Kubernetes 1.0, which was donated
    by Google to the CNCF (although it had already been open sourced by Google some
    time before).
  id: totrans-1030
  prefs: []
  type: TYPE_NORMAL
  zh: 它的成立与Kubernetes 1.0的发布相吻合，Kubernetes 1.0是由谷歌捐赠给CNCF的（尽管谷歌在之前一段时间就已经开源了它）。
- en: 'The CNCF’s role in the container space is really that of kingmaker. Because
    the collective might of the various players involved is so great, when the CNCF
    gets behind a technology, you know two things about it: it’s going to have investment
    and support behind it, and it’s unlikely that one vendor will be favored over
    another. The latter factor is particularly important to the Docker platform consumer,
    as it means that your technology choice is unlikely to be obsolete in the foreseeable
    future.'
  id: totrans-1031
  prefs: []
  type: TYPE_NORMAL
  zh: CNCF 在容器领域的作用实际上是“造王者”。由于涉及的各种玩家的集体力量如此之大，当 CNCF 支持一项技术时，你知道关于它的两件事：它将得到投资和支持，而且不太可能有一个供应商比另一个供应商更受青睐。后一个因素对
    Docker 平台消费者尤其重要，因为它意味着你的技术选择在可预见的未来不太可能过时。
- en: 'There’s a long (and growing) list of technologies that the CNCF has endorsed.
    We’ll look at some of the most significant ones:'
  id: totrans-1032
  prefs: []
  type: TYPE_NORMAL
  zh: CNCF 已经批准了大量的技术。我们将探讨其中一些最重要的：
- en: Kubernetes
  id: totrans-1033
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes
- en: CNI
  id: totrans-1034
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNI
- en: Containerd
  id: totrans-1035
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Containerd
- en: Envoy
  id: totrans-1036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Envoy
- en: Notary
  id: totrans-1037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Notary
- en: Prometheus
  id: totrans-1038
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus
- en: Kubernetes
  id: totrans-1039
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Kubernetes
- en: Kubernetes was the founding and most significant technology that’s part of the
    CNCF. It was donated by Google to the community, first as open source, and then
    to the CNCF.
  id: totrans-1040
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是 CNCF 的创始和最重要的技术之一。它是由谷歌捐赠给社区的，最初是作为开源软件，然后是给 CNCF。
- en: Although it’s open source, its donation to the community is part of Google’s
    strategy to commodify cloud technologies and make it easier for consumers to move
    away from other cloud providers, the most dominant of which is AWS.
  id: totrans-1041
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它是开源的，但其对社区的捐赠是谷歌将云技术商品化并使消费者更容易离开其他云服务提供商（其中最突出的是AWS）的策略的一部分。
- en: Kubernetes is the foundation technology of most Docker platforms, most notably
    OpenShift, but also Rancher, and even Docker Inc.’s own Docker Datacenter, because
    they support Kubernetes in addition to Swarm.
  id: totrans-1042
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是大多数 Docker 平台的基础技术，最著名的是 OpenShift，还有 Rancher，甚至是 Docker Inc. 自己的
    Docker Datacenter，因为它们除了支持 Swarm 之外，还支持 Kubernetes。
- en: CNI
  id: totrans-1043
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: CNI
- en: CNI stands for Container Network Interface. This project provides a standard
    interface for managing network interfaces for containers. As you saw in [chapter
    10](kindle_split_021.xhtml#ch10), networking can be a complex area for container
    management, and this project is an attempt to help simplify its management.
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
  zh: CNI 代表容器网络接口。该项目为容器管理网络接口提供了一个标准接口。正如你在第 [10](kindle_split_021.xhtml#ch10) 章节中看到的，网络对于容器管理来说可能是一个复杂的领域，而这个项目就是试图帮助简化其管理。
- en: 'Here’s a (very) simple example that defines a loopback interface:'
  id: totrans-1045
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个（非常）简单的示例，它定义了一个环回接口：
- en: '[PRE69]'
  id: totrans-1046
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: This file might be placed into /etc/cni/net.d/99-loopback.conf and used to configure
    the loopback network interface.
  id: totrans-1047
  prefs: []
  type: TYPE_NORMAL
  zh: 此文件可能被放置在 /etc/cni/net.d/99-loopback.conf 中，并用于配置环回网络接口。
- en: 'More complex examples are available at the Git repository here: [https://github.com/containernetworking/cni](https://github.com/containernetworking/cni).'
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的示例可以在以下 Git 仓库中找到：[https://github.com/containernetworking/cni](https://github.com/containernetworking/cni)。
- en: Containerd
  id: totrans-1049
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Containerd
- en: Containerd is the community version of the Docker daemon. It manages containers’
    life cycles. Runc is its sister project, which is the runtime responsible for
    running the container itself.
  id: totrans-1050
  prefs: []
  type: TYPE_NORMAL
  zh: Containerd 是 Docker 守护进程的社区版本。它管理容器的生命周期。Runc 是其姐妹项目，负责运行容器本身。
- en: Envoy
  id: totrans-1051
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Envoy
- en: Originally built at Lyft to move their architecture away from a monolithic to
    a micro-services architecture, Envoy is a high-performance open source edge and
    service proxy that makes the network transparent to applications.
  id: totrans-1052
  prefs: []
  type: TYPE_NORMAL
  zh: Envoy 是在 Lyft 建立的，以将他们的架构从单体架构迁移到微服务架构。它是一个高性能的开源边缘和服务代理，使网络对应用程序透明。
- en: It allows straightforward management of key networking and integration challenges
    such as load balancing, proxying, and distributed tracing.
  id: totrans-1053
  prefs: []
  type: TYPE_NORMAL
  zh: 它允许直接管理关键的网络和集成挑战，如负载均衡、代理和分布式跟踪。
- en: Notary
  id: totrans-1054
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Notary
- en: Notary is the tool originally designed and built by Docker Inc. to sign and
    verify the integrity of container images. (Please refer to page [317](#ch13lev3sec2),
    “[Image integrity](#ch13lev3sec2).”)
  id: totrans-1055
  prefs: []
  type: TYPE_NORMAL
  zh: Notary 是 Docker Inc. 设计和构建的工具，用于签名和验证容器镜像的完整性。（请参阅第 [317](#ch13lev3sec2) 页，“[镜像完整性](#ch13lev3sec2)。”）
- en: Prometheus
  id: totrans-1056
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Prometheus
- en: Prometheus is a monitoring tool that operates nicely with containers. It’s gaining
    currency in the community, with (for example) Red Hat switching from Hawkular
    to Prometheus in their OpenShift platform.
  id: totrans-1057
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 是一个与容器配合得很好的监控工具。它在社区中越来越受欢迎，例如，Red Hat 在他们的 OpenShift 平台上从 Hawkular
    切换到 Prometheus。
- en: 13.3.2\. Docker, Inc.
  id: totrans-1058
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.3.2\. Docker, Inc.
- en: Docker, Inc. is the commercial entity that seeks to profit from the open source
    Docker project.
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Inc.是寻求从开源Docker项目中获利的商业实体。
- en: '|  |'
  id: totrans-1060
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-1061
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: The open source Docker project has been renamed Moby by Docker Inc. in an attempt
    to reserve the Docker name for profit-making purposes. So far this name hasn’t
    caught on, so you won’t see much mention of Moby in this book.
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
  zh: 开源Docker项目已被Docker Inc.更名为Moby，试图为盈利目的保留Docker名称。到目前为止，这个名字还没有流行起来，所以在这本书中您不会看到太多关于Moby的提及。
- en: '|  |'
  id: totrans-1063
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Docker Inc. was an early leader in the Docker product space, as you might expect.
    They put together several of their products into a monolithic product called Docker
    Datacenter. This included support, integration, and features for Notary, the registry,
    Swarm, and several other projects that Docker had open sourced. Latterly, Kubernetes
    support has been forthcoming.
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所预期的那样，Docker Inc.在Docker产品空间中是一个早期的领导者。他们将多个产品组合成一个名为Docker Datacenter的单一产品。这包括对Notary、注册表、Swarm以及Docker开源的几个其他项目的支持、集成和功能。最近，Kubernetes的支持已经提供。
- en: Because Docker was early to the party and its technical reputation was strong
    in the early days of Docker, their product was very compelling on the “getting
    to production quickly” metric. Over time Docker’s product has lost ground as others
    have caught up. Docker’s business model has been difficult to sell internally
    due to its “take it all or leave it” strategy, and to its cost-per server model,
    which opens up customers to a strong dependency on one vendor that could hold
    them to ransom for their entire Docker platform.
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Docker在早期就加入了这个领域，并且其在Docker早期就拥有强大的技术声誉，因此他们的产品在“快速进入生产”这一指标上非常吸引人。随着时间的推移，Docker的产品在其他人赶上之后失去了优势。由于其“全要全不要”的策略和按服务器计费的模式，Docker的业务模式在内部销售上遇到了困难，这使客户对单一供应商产生了强烈的依赖，该供应商可能对他们整个Docker平台进行勒索。
- en: 13.3.3\. Google
  id: totrans-1066
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.3.3\. Google
- en: Kubernetes was created by Google in 2014 after Docker blew up in popularity.
    It was intended to bring the principles behind Google’s internal container platform
    (Borg) to a wider audience.
  id: totrans-1067
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是由谷歌在2014年创建的，当时Docker的流行度激增。它的目的是将谷歌内部容器平台（Borg）背后的原则带给更广泛的受众。
- en: At around the same time, the Google Cloud service came into being. The promotion
    of Kubernetes was part of their cloud strategy. (Please refer to page [327](#ch13lev3sec17),
    “[Kubernetes](#ch13lev3sec17).”)
  id: totrans-1068
  prefs: []
  type: TYPE_NORMAL
  zh: 大约在同一时间，谷歌云服务诞生了。推广Kubernetes是他们云战略的一部分。（请参阅第[327](#ch13lev3sec17)页，“[Kubernetes](#ch13lev3sec17)。”）
- en: Google has a paid service for managing Kubernetes clusters called Google Kubernetes
    Engine (GKE), similar to AWS’s EKS.
  id: totrans-1069
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌提供了一项名为Google Kubernetes Engine (GKE)的付费服务，用于管理Kubernetes集群，类似于AWS的EKS。
- en: Google’s cloud offering is a key business priority for them, and Kubernetes
    support and encouragement is a central part of that strategy.
  id: totrans-1070
  prefs: []
  type: TYPE_NORMAL
  zh: 对于谷歌来说，其云服务是他们的一项关键业务优先事项，而Kubernetes的支持和鼓励是该战略的核心部分。
- en: 13.3.4\. Microsoft
  id: totrans-1071
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.3.4\. Microsoft
- en: Microsoft has been involved with Docker on several fronts, all with a view to
    expanding its Azure cloud offering.
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
  zh: 微软在多个方面参与了Docker，所有这些都有助于扩展其Azure云服务。
- en: First, Microsoft has implemented the Docker API to containers natively on the
    Windows platform from Windows 10 onward. This allows Windows containers to be
    built and run. Kubernetes support for Windows nodes is planned, but at the time
    of writing it’s still in the early stages.
  id: totrans-1073
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，从Windows 10开始，微软已经在Windows平台上原生实现了Docker API到容器的支持。这使得Windows容器可以被构建和运行。对于Windows节点上的Kubernetes支持已有计划，但截至写作时，它仍处于早期阶段。
- en: Second, Microsoft has worked on an offering of its .NET platform, called Dotnet
    Core (or .NET Core if you prefer), that provides support for .NET codebases on
    Linux. Not all .NET libraries are supported, so moving your Windows application
    is far from trivial (so far), but many organizations will be interested in the
    possibility of running their Windows code on a Linux platform, and even in the
    possibility of building from the ground up to run on either platform.
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，微软在其.NET平台的基础上推出了一项名为Dotnet Core（如果您更喜欢，可以称为.NET Core）的产品，该产品为Linux上的.NET代码库提供支持。并非所有.NET库都受到支持，因此将您的Windows应用程序迁移过去绝非易事（到目前为止），但许多组织会对在Linux平台上运行他们的Windows代码的可能性感兴趣，甚至对从头开始构建以在任一平台上运行的可能性感兴趣。
- en: Third, an Azure offering exists for Kubernetes (AKS), also similar to AWS’s
    EKS and Google Cloud’s GKE.
  id: totrans-1075
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，Azure提供了一种针对Kubernetes（AKS）的产品，也类似于AWS的EKS和谷歌云的GKE。
- en: All these efforts can be seen as designed to encourage users to move to the
    Azure cloud. The ability to run similar workloads on Windows or Linux (or even
    the same on both) is attractive to many organizations. This is especially true
    if the data already sits on their data centers. In addition, Microsoft is in a
    good position to offer attractive license bundles to organizations already heavily
    invested in Microsoft technologies looking to go to the cloud.
  id: totrans-1076
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些努力都可以看作是为了鼓励用户迁移到Azure云。能够在Windows或Linux（甚至两者都相同）上运行类似的工作负载对许多组织来说很有吸引力。特别是如果数据已经存储在他们自己的数据中心中。此外，微软处于一个很好的位置，可以向已经在微软技术上有大量投资并希望迁移到云的组织提供有吸引力的许可证套餐。
- en: 13.3.5\. Amazon
  id: totrans-1077
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.3.5\. 亚马逊
- en: Amazon now has several container offerings but arguably was somewhat late to
    the party. Its first offering was the Elastic Container Service (ECS) which used
    Mesos under the hood to manage the deployment of containers and their hosts.
  id: totrans-1078
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊现在有几款容器产品，但可以说它在容器领域起步较晚。它的第一个产品是弹性容器服务（ECS），它使用Mesos在底层来管理容器的部署及其宿主机的管理。
- en: This had some initial traction but was soon overtaken in the industry by the
    popularity of Kubernetes. Amazon responded in late 2017 by announcing the Elastic
    Kubernetes Service (EKS), which (like the GKE and AKS services mentioned previously)
    is a curated Kubernetes service. ECS is still supported, but it seems only natural
    to think that EKS will be the more strategic service for them. Also announced
    in late 2017 was Fargate, a service that runs containers natively without the
    need to manage any EC2 instances.
  id: totrans-1079
  prefs: []
  type: TYPE_NORMAL
  zh: 这最初获得了一些关注，但很快在行业中被Kubernetes的流行所超越。亚马逊在2017年底通过宣布弹性Kubernetes服务（EKS）做出了回应，该服务（就像之前提到的GKE和AKS服务一样）是一个精选的Kubernetes服务。ECS仍然得到支持，但似乎很自然地认为EKS将是它们更具战略性的服务。在2017年底还宣布了Fargate，这是一个无需管理任何EC2实例即可原生运行容器的服务。
- en: All of these services offer tight integration with other AWS services, which
    is very convenient if you see AWS as a long-term platform for your software. Obviously,
    AWS’s commercial aim is to ensure you want to continue to pay for their services,
    but their broad support for the Kubernetes API can give consumers some comfort
    that the ties to the AWS platform can be looser than with other services.
  id: totrans-1080
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些服务都提供了与其他AWS服务的紧密集成，如果你将AWS视为你软件的长期平台，这将非常方便。显然，AWS的商业目标是确保你愿意继续支付他们的服务费用，但他们对Kubernetes
    API的广泛支持可以给消费者一些安慰，即与AWS平台的联系可以比其他服务更松散。
- en: 13.3.6\. Red Hat
  id: totrans-1081
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13.3.6\. 红帽
- en: Red Hat’s commercial strategy is to curate, support, and manage core software
    for their customers, the so-called “open source sommelier” strategy. Red Hat is
    different from the other commercial players in that they don’t have a generic
    cloud service to offer consumers (though OpenShift online can be viewed as a cloud
    offering because it’s an externally hosted service).
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
  zh: 红帽的商业战略是为客户定制、支持和管理工作核心软件，所谓的“开源品酒师”战略。红帽与其他商业玩家不同，它们不提供通用的云服务供消费者使用（尽管OpenShift
    online可以被视为云服务，因为它是一个外部托管的服务）。
- en: Red Hat’s container focus is in two areas. The first is OpenShift, which is
    a product wrapping around Kubernetes that can be run and supported in multiple
    environments, such as on-prem with the cloud providers mentioned here (as well
    as some others), and as a service with Red Hat’s OpenShift Online service.
  id: totrans-1083
  prefs: []
  type: TYPE_NORMAL
  zh: 红帽在两个领域关注容器。第一个是OpenShift，这是一个围绕Kubernetes的产品，可以在多个环境中运行和支持，例如在本地上与这里提到的云提供商（以及一些其他提供商）一起运行，以及作为Red
    Hat的OpenShift Online服务的一部分。
- en: OpenShift development has introduced various enterprise features (such as RBAC,
    built-in image storage, and pod deployment triggers), which have found their way
    into core Kubernetes.
  id: totrans-1084
  prefs: []
  type: TYPE_NORMAL
  zh: OpenShift的开发引入了各种企业功能（如RBAC、内置镜像存储和Pod部署触发器），这些功能已经融入到核心Kubernetes中。
- en: Summary
  id: totrans-1085
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: Some of the major determining factors that inform your choice of Docker platform
    might include your “buy” versus “build” stance, your security stance, your cloud
    strategy, and whether your organization tends to solve technical challenges with
    “monolithic” or “piecemeal” products.
  id: totrans-1086
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 影响你选择Docker平台的一些主要决定因素可能包括你的“购买”与“构建”立场、你的安全立场、你的云战略，以及你的组织是否倾向于用“单体”或“零散”的产品来解决技术挑战。
- en: These factors can in turn be affected by the technical drivers of your software,
    time-to-market demands, the level of consumer independence, your open source strategy,
    and your organizational structure.
  id: totrans-1087
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些因素反过来又可能受到你的软件的技术驱动因素、上市时间要求、消费者独立性的水平、你的开源策略以及你的组织结构的影响。
- en: In a larger organization, a multiplatform approach can make sense, but care
    might need to be taken to ensure consistency of approach across these platforms
    to reduce later organizational inefficiencies.
  id: totrans-1088
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一个较大的组织中，采用多平台方法可能是有意义的，但可能需要小心确保这些平台之间方法的一致性，以减少未来的组织低效率。
- en: The major functional areas that might be considered when implementing a Docker
    platform include how images will be built, image scanning and integrity, secrets
    management, image registries, and the underlying OS.
  id: totrans-1089
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实施 Docker 平台时可能需要考虑的主要功能区域包括如何构建镜像、镜像扫描和完整性、密钥管理、镜像注册以及底层操作系统。
- en: The significant players in the Docker platform space include Docker Inc., the
    three big cloud providers (AWS, Google Cloud Platform, and Microsoft Azure), and
    the Cloud Native Computing Foundation (CNCF).
  id: totrans-1090
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 平台领域的显著参与者包括 Docker Inc.、三大云服务提供商（AWS、Google Cloud Platform 和 Microsoft
    Azure）以及云原生计算基金会（CNCF）。
- en: The CNCF is a highly influential organization that incubates and supports the
    key open source technical components of Docker platforms. Full acceptance by the
    CNCF is a signal that the technology will be sustainable.
  id: totrans-1091
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNCF 是一个极具影响力的组织，它孵化并支持 Docker 平台的关键开源技术组件。CNCF 的全面认可是一个信号，表明这项技术将是可持续的。
