- en: 2 Machine learning for regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 回归机器学习
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Creating a car-price prediction project with a linear regression model
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线性回归模型创建汽车价格预测项目
- en: Doing an initial exploratory data analysis with Jupyter notebooks
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Jupyter笔记本进行初步的探索性数据分析
- en: Setting up a validation framework
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置验证框架
- en: Implementing the linear regression model from scratch
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从头实现线性回归模型
- en: Performing simple feature engineering for the model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为模型执行简单的特征工程
- en: Keeping the model under control with regularization
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正则化来控制模型
- en: Using the model to predict car prices
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用模型预测汽车价格
- en: In chapter 1, we talked about supervised machine learning, in which we teach
    machine learning models how to identify patterns in data by giving them examples.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1章中，我们讨论了监督机器学习，其中我们通过给他们示例来教机器学习模型如何在数据中识别模式。
- en: Suppose that we have a dataset with descriptions of cars, like make, model,
    and age, and we would like to use machine learning to predict their prices. These
    characteristics of cars are called *features*, and the price is the *target* *variable*—something
    we want to predict. Then the model gets the features and combines them to output
    the price.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个包含汽车描述的数据集，如制造商、型号和年龄，我们希望使用机器学习来预测它们的价格。这些汽车的特征被称为*特征*，价格是*目标* *变量*——我们想要预测的东西。然后模型获取特征并将它们组合起来输出价格。
- en: 'This is an example of supervised learning: we have some information about the
    price of some cars, and we can use it to predict the price of others. In chapter
    1, we also talked about different types of supervised learning: regression and
    classification. When the target variable is numerical, we have a regression problem,
    and when the target variable is categorical, we have a classification problem.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个监督学习的例子：我们有一些关于某些汽车价格的信息，我们可以用它来预测其他汽车的价格。在第1章中，我们也讨论了不同类型的监督学习：回归和分类。当目标变量是数值时，我们有一个回归问题，而当目标变量是分类变量时，我们有一个分类问题。
- en: 'In this chapter, we create a regression model, starting with the simplest one:
    linear regression. We implement the algorithms ourselves, which is simple enough
    to do in a few lines of code. At the same time, it’s very illustrative, and it
    will teach you how to deal with NumPy arrays and perform basic matrix operations
    such as matrix multiplication and matrix inversion. We also come across problems
    of numerical instability when inverting a matrix and see how regularization helps
    solve them.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们创建一个回归模型，从最简单的一个开始：线性回归。我们亲自实现算法，这足以用几行代码完成。同时，它非常具有说明性，它将教会你如何处理NumPy数组并执行基本的矩阵运算，如矩阵乘法和矩阵求逆。我们还遇到了在求逆矩阵时的数值不稳定性问题，并看到正则化如何帮助解决这些问题。
- en: 2.1 Car-price prediction project
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 汽车价格预测项目
- en: The problem we solve in this chapter is predicting the price of a car. Suppose
    that we have a website where people can sell and buy used cars. When posting an
    ad on our website, sellers often struggle to come up with a meaningful price.
    We want to help our users with automatic price recommendations. We ask the sellers
    to specify the model, make, year, mileage, and other important characteristics
    of a car, and based on that information, we want to suggest the best price.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章解决的问题是在预测汽车价格。假设我们有一个人们可以买卖二手汽车的网站。当在网站上发布广告时，卖家经常难以提出一个有意义的定价。我们希望帮助我们的用户通过自动价格推荐。我们要求卖家指定汽车的型号、制造商、年份、里程和其他重要特征，然后根据这些信息，我们希望提出最佳价格。
- en: One of the product managers in the company accidentally came across an open
    dataset with car prices and asked us to have a look at it. We checked the data
    and saw that it contained all the important features as well as the recommended
    price—exactly what we needed for our use case. Thus, we decided to use this dataset
    for building the price-recommendation algorithm.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 公司的一名产品经理偶然发现了一个包含汽车价格的公开数据集，并要求我们看看它。我们检查了数据，发现它包含了所有重要的特征以及推荐的价格——这正是我们用例所需要的。因此，我们决定使用这个数据集来构建价格推荐算法。
- en: 'The plan for the project is the following:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 项目的计划如下：
- en: First, we download the dataset.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们下载数据集。
- en: Next, we do some preliminary analysis of the data.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们对数据进行初步分析。
- en: After that, we set up a validation strategy to make sure our model produces
    correct predictions.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们设置一个验证策略，以确保我们的模型产生正确的预测。
- en: Then we implement a linear regression model in Python and NumPy.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们使用Python和NumPy实现线性回归模型。
- en: Next, we cover feature engineering to extract important features from the data
    to improve the model.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍特征工程，从数据中提取重要特征以改进模型。
- en: Finally, we see how to make our model stable with regularization and use it
    to predict car prices.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将了解如何通过正则化使我们的模型稳定，并使用它来预测汽车价格。
- en: 2.1.1 Downloading the dataset
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.1 下载数据集
- en: 'The first thing we do for this project is install all the required libraries:
    Python, NumPy, Pandas, and Jupyter Notebook. The easiest way to do it is to use
    a Python distribution called Anaconda ([https://www.anaconda.com](https://www.anaconda.com/)).
    Please refer to appendix A for installation guidelines.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，我们首先要做的是安装所有必需的库：Python、NumPy、Pandas 和 Jupyter Notebook。最简单的方法是使用一个名为
    Anaconda 的 Python 发行版（[https://www.anaconda.com](https://www.anaconda.com/)）。请参阅附录
    A 以获取安装指南。
- en: After the libraries are installed, we need to download the dataset. We have
    multiple options for doing this. You can download it manually through the Kaggle
    web interface, available at [https://www.kaggle.com/CooperUnion/cardataset](https://www.kaggle.com/CooperUnion/cardataset).
    (You can read more about the dataset and the way it was collected at [https://www.kaggle.com/jshih7/car-price-prediction](https://www.kaggle.com/jshih7/car-price-prediction).)
    Go there, open it, and click the download link. The other option is using the
    Kaggle command-line interface (CLI), which is a tool for programmatic access to
    all datasets available via Kaggle. For this chapter, we will use the second option.
    We describe how to configure the Kaggle CLI in appendix A.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装了库之后，我们需要下载数据集。我们有多种方法可以做到这一点。您可以通过 Kaggle 网络界面手动下载，网址为 [https://www.kaggle.com/CooperUnion/cardataset](https://www.kaggle.com/CooperUnion/cardataset)。（您可以在
    [https://www.kaggle.com/jshih7/car-price-prediction](https://www.kaggle.com/jshih7/car-price-prediction)
    上了解更多关于数据集及其收集方式的信息。）前往该网站，打开它，然后点击下载链接。另一种选择是使用 Kaggle 命令行界面（CLI），这是一个用于通过 Kaggle
    访问所有数据集的工具。对于本章，我们将使用第二种方法。我们将在附录 A 中描述如何配置 Kaggle CLI。
- en: Note Kaggle is an online community for people who are interested in machine
    learning. It is mostly known for hosting machine learning competitions, but it
    is also a data-sharing platform where anyone can share a dataset. More than 16,000
    datasets are available for anyone to use. It is a great source of project ideas
    and very useful for machine learning projects.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 Kaggle 是一个面向对机器学习感兴趣的人的在线社区。它最出名的是举办机器学习竞赛，但它也是一个数据共享平台，任何人都可以分享数据集。有超过 16,000
    个数据集可供任何人使用。它是项目想法的绝佳来源，并且对于机器学习项目非常有用。
- en: In this chapter, as well as throughout the book, we will actively use NumPy.
    We cover all necessary NumPy operations as we go along, but please refer to appendix
    C for a more in-depth introduction.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章以及整本书中，我们将积极使用 NumPy。我们将随着内容的展开介绍所有必要的 NumPy 操作，但请参阅附录 C 以获取更深入的介绍。
- en: The source code for this project is available in the book’s repository in GitHub
    at [https://github.com/alexeygrigorev/mlbookcamp-code](https://github.com/alexeygrigorev/mlbookcamp-code)
    in chapter-02-car-price.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的源代码可在 GitHub 上的书籍仓库中找到，网址为 [https://github.com/alexeygrigorev/mlbookcamp-code](https://github.com/alexeygrigorev/mlbookcamp-code)，在
    chapter-02-car-price 章节中。
- en: 'As the first step, we will create a folder for this project. We can give it
    any name, such as chapter-02-car-price:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们将为这个项目创建一个文件夹。我们可以给它起任何名字，例如 chapter-02-car-price：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then we download the dataset:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们下载数据集：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This command downloads the cardataset.zip file, which is a zip archive. Let’s
    unpack it:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令下载 cardataset.zip 文件，这是一个压缩文件。让我们解压缩它：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Inside, there’s one file: data.csv.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在里面，有一个文件：data.csv。
- en: 'When we have the dataset, let’s move on to the next step: understanding it.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有了数据集后，让我们继续下一步：理解它。
- en: 2.2 Exploratory data analysis
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 探索性数据分析
- en: Understanding data is an important step in the machine learning process. Before
    we can train any model, we need to know what kind of data we have and whether
    it is useful. We do this with exploratory data analysis (EDA).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 理解数据是机器学习过程中的重要一步。在我们能够训练任何模型之前，我们需要知道我们有什么样的数据以及它是否有用。我们通过探索性数据分析（EDA）来完成这项工作。
- en: We look at the dataset to learn
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们查看数据集以学习
- en: The distribution of the target variable
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标变量的分布
- en: The features in this dataset
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个数据集中的特征
- en: The distribution of values in these features
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些特征中值的分布
- en: The quality of the data
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的质量
- en: The number of missing values
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值的数量
- en: 2.2.1 Exploratory data analysis toolbox
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.1 探索性数据分析工具箱
- en: 'The main tools for this analysis are Jupyter Notebook, Matplotlib, and Pandas:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分析的主要工具是 Jupyter Notebook、Matplotlib 和 Pandas：
- en: 'Jupyter Notebook is a tool for interactive execution of Python code. It allows
    us to execute a piece of code and immediately see the outcome. In addition, we
    can display charts and add notes with comments in free text. It also supports
    other languages such as R or Julia (hence the name: Jupyter stands for Julia,
    Python, R), but we will use it only for Python.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jupyter Notebook 是一个用于交互式执行 Python 代码的工具。它允许我们执行一段代码并立即看到结果。此外，我们可以在自由文本中显示图表并添加注释。它还支持其他语言，如
    R 或 Julia（因此得名：Jupyter 代表 Julia、Python、R），但我们将仅使用它来执行 Python。
- en: Matplotlib is a library for plotting. It is very powerful and allows you to
    create different types of visualizations, such as line charts, bar charts, and
    histograms.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib 是一个用于绘图的库。它非常强大，允许你创建不同类型的可视化，如折线图、条形图和直方图。
- en: Pandas is a library for working with tabular data. It can read data from any
    source, be it a CSV file, a JSON file, or a database.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas 是一个用于处理表格数据的库。它可以读取来自任何来源的数据，无论是 CSV 文件、JSON 文件还是数据库。
- en: We will also use Seaborn, another tool for plotting that is built on top of
    Matplotlib and makes it easier to draw charts.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用 Seaborn，这是另一个基于 Matplotlib 构建的绘图工具，它使得绘制图表变得更加容易。
- en: 'Let’s start a Jupyter Notebook by executing the following command:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过执行以下命令来启动一个 Jupyter Notebook：
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This command starts a Jupyter Notebook server in the current directory and opens
    it in the default web browser (figure 2.1).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令在当前目录中启动 Jupyter Notebook 服务器，并在默认的网页浏览器中打开它（图 2.1）。
- en: '![](../Images/02_01.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_01.png)'
- en: Figure 2.1 The starting screen of the Jupyter Notebook service
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 Jupyter Notebook 服务的起始屏幕
- en: If Jupyter is running on a remote server, it requires additional configuration.
    Please refer to appendix A for details on the setup.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Jupyter 在远程服务器上运行，则需要额外的配置。请参阅附录 A 了解设置详情。
- en: Now let’s create a notebook for this project. Click New, then select Python
    3 in the Notebooks section. We can call it chapter-02-car-price-project—click
    the current title (Untitled), and replace it with the new one.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们为这个项目创建一个笔记本。点击“新建”，然后在“笔记本”部分选择 Python 3。我们可以将其命名为 chapter-02-car-price-project—点击当前标题（未命名），并将其替换为新的名称。
- en: 'First, we need to import all the libraries required for this project. Write
    the following in the first cell:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要导入这个项目所需的所有库。在第一个单元格中写下以下内容：
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '❶ Imports NumPy: a library for numerical operation'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 导入 NumPy：一个用于数值计算的库
- en: '❷ Imports Pandas: a library for tabular data'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 导入 Pandas：一个用于表格数据的库
- en: '❸ Imports plotting libraries: Matplotlib and Seaborn'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 导入绘图库：Matplotlib 和 Seaborn
- en: ❹ Makes sure that plots are rendered correctly in Jupyter Notebooks
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 确保在 Jupyter Notebooks 中正确渲染图表
- en: 'The first two lines, ❶ and ❷, are imports for required libraries: NumPy for
    numeric operations and Pandas for tabular data. The convention is to import these
    libraries using shorter aliases (such as `pd` in `import` `pandas` `as` `pd`).
    This convention is common in the Python machine learning community, and everybody
    follows it.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 前两行，❶ 和 ❷，是导入所需库的语句：NumPy 用于数值操作，Pandas 用于表格数据。惯例是使用较短的别名（如 `pd` 在 `import pandas
    as pd` 中）来导入这些库。这种惯例在 Python 机器学习社区中很常见，每个人都遵循它。
- en: The next two lines, ❸, are imports for plotting libraries. The first one, Matplotlib,
    is a library for creating good-quality visualizations. It’s not always easy to
    use this library as is. Some libraries make using Matplotlib simpler, and Seaborn
    is one of them.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两行，❸，是导入绘图库的语句。第一个，Matplotlib，是一个用于创建高质量可视化的库。直接使用这个库可能并不总是容易。一些库使使用 Matplotlib
    更加简单，而 Seaborn 就是其中之一。
- en: Finally, `%matplotlib` `inline` in line ❹ tells Jupyter to expect plots in the
    notebook, so it will be able to render them when we need them.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，行 ❹ 的 `%matplotlib inline` 告诉 Jupyter Notebook 期望在笔记本中渲染图表，因此当需要时它将能够渲染它们。
- en: Press Shift+Enter or click Run to execute the content of the selected cell.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 按下 Shift+Enter 或点击运行来执行所选单元格的内容。
- en: We will not get into more detail about Jupyter Notebooks. Check the official
    website ([https://jupyter.org](https://jupyter.org/)) to learn more about it.
    The site has plenty of documentation and examples that will help you master it.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入探讨 Jupyter Notebooks 的细节。请访问官方网站 ([https://jupyter.org](https://jupyter.org/))
    了解更多信息。该网站提供了丰富的文档和示例，可以帮助你掌握它。
- en: 2.2.2 Reading and preparing data
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.2 读取和准备数据
- en: 'Now let’s read our dataset. We can use the `read_csv` function from Pandas
    for that purpose. Put the following code in the next cell and again press Shift+Enter:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们读取我们的数据集。我们可以使用 Pandas 的 `read_csv` 函数来完成此操作。将以下代码放入下一个单元格，并再次按下 Shift+Enter：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This line of code reads the CSV file and writes the results to a variable named
    `df`, which is short for *DataFrame*. Now we can check how many rows there are.
    Let’s use the `len` function:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这行代码读取 CSV 文件并将结果写入名为 `df` 的变量中，`df` 是 *DataFrame* 的简称。现在我们可以检查有多少行。让我们使用 `len`
    函数：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The function prints 11914, which means that there are almost 12,000 cars in
    this dataset (figure 2.2).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数打印出 11914，这意味着在这个数据集中几乎有 12,000 辆汽车（图 2.2）。
- en: '![](../Images/02_02.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_02.png)'
- en: Figure 2.2 Jupyter Notebooks are interactive. We can type some code in a cell,
    execute it, and see the results immediately, which is ideal for exploratory data
    analysis.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 Jupyter Notebooks 是交互式的。我们可以在一个单元中输入一些代码，执行它，并立即看到结果，这对于探索性数据分析来说非常理想。
- en: Now let’s use `df.head``()` to look at the first five rows of our DataFrame
    (figure 2.3).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 `df.head()` 来查看 DataFrame 的前五行（图 2.3）。
- en: '![](../Images/02_03.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_03.png)'
- en: 'Figure 2.3 The output of the `head()` function of a Pandas DataFrame: it shows
    the first five rows of the dataset. This output allows us to understand what the
    data looks like.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 Pandas DataFrame 的 `head()` 函数输出：它显示了数据集的前五行。这个输出使我们能够了解数据的外观。
- en: 'This gives us an idea of what the data looks like. We can already see that
    there are some inconsistencies in this dataset: the column names sometimes have
    spaces, and sometimes have underscores (_). The same is true for feature values:
    sometimes they’re capitalized, and sometimes they are short strings with spaces.
    This is inconvenient and confusing, but we can solve this by normalizing them—replacing
    all spaces with underscores and lowercase all letters:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我们对数据的外观有了初步的了解。我们已能看到这个数据集中存在一些不一致性：列名有时有空格，有时有下划线（_）。特征值也是如此：有时它们是大写的，有时是带有空格的短字符串。这很不方便且令人困惑，但我们可以通过规范化来解决这些问题——将所有空格替换为下划线并将所有字母转换为小写：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Lowercases all the column names, and replaces spaces with underscores
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将所有列名转换为小写，并将空格替换为下划线
- en: ❷ Selects only columns with string values
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 仅选择具有字符串值的列
- en: ❸ Lowercases and replaces spaces with underscores for values in all string columns
    of the DataFrame
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将 DataFrame 中所有字符串列的值转换为小写，并将空格替换为下划线
- en: In ❶ and ❸, we use the special `str` attribute. Using it, we can apply string
    operations to the entire column at that same time without writing any `for` loops.
    We use it to lowercase the column names and the content of these columns as well
    as to replace spaces with underscores.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ❶ 和 ❸ 中，我们使用了特殊的 `str` 属性。使用它，我们可以同时对该列的整个字符串值应用字符串操作，而无需编写任何 `for` 循环。我们用它将列名和这些列的内容转换为小写，并将空格替换为下划线。
- en: We can use this attribute only for columns with string values inside. This is
    exactly why we first select such columns in ❷.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只能使用此属性来处理具有字符串值的列。这正是为什么我们在 ❷ 中首先选择这样的列。
- en: NOTE In this chapter and subsequent chapters, we cover relevant Pandas operations
    as we go along, but at a fairly high level. Please refer to appendix D for a more
    consistent and in-depth introduction to Pandas.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在本章及后续章节中，我们将随着内容的展开介绍相关的 Pandas 操作，但会保持较高的概括性。请参考附录 D 以获得对 Pandas 的更一致和深入的介绍。
- en: After this initial preprocessing, the DataFrame looks more uniform (figure 2.4).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在此初步预处理之后，DataFrame 看起来更加统一（图 2.4）。
- en: '![](../Images/02_04.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_04.png)'
- en: 'Figure 2.4 The result of preprocessing the data. The column names and values
    are normalized: they are lowercase, and the spaces are converted to underscores.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 数据预处理的结果。列名和值已规范化：它们都是小写，并且空格被转换为下划线。
- en: 'As we see, this dataset contains multiple columns:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，这个数据集包含多个列：
- en: 'make: make of a car (BMW, Toyota, and so on)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: make：汽车的制造商（宝马、丰田等）
- en: 'model: model of a car'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: model：汽车的型号
- en: 'year: year when the car was manufactured'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: year：汽车制造的年份
- en: 'engine_fuel_type: type of fuel the engine needs (diesel, electric, and so on)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: engine_fuel_type：发动机所需的燃料类型（柴油、电动等）
- en: 'engine_hp: horsepower of the engine'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: engine_hp：发动机马力
- en: 'engine_cylinders: number of cylinders in the engine'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: engine_cylinders：发动机的气缸数
- en: 'transmission_type: type of transmission (automatic or manual)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: transmission_type：变速器类型（自动或手动）
- en: 'driven_wheels: front, rear, all'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: driven_wheels：前轮驱动、后轮驱动、全轮驱动
- en: 'number_of_doors: number of doors a car has'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: number_of_doors：汽车的门数
- en: 'market_category: luxury, crossover, and so on'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: market_category：豪华、跨界等
- en: 'vehicle_size: compact, midsize, or large'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: vehicle_size：紧凑型、中型或大型
- en: 'vehicle_style: sedan or convertible'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: vehicle_style：轿车或敞篷车
- en: 'highway_mpg: miles per gallon (mpg) on the highway'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: highway_mpg：高速公路上的每加仑英里数（mpg）
- en: 'city_mpg: miles per gallon in the city'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: city_mpg：城市每加仑英里数
- en: 'popularity: number of times the car was mentioned in a Twitter stream'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: popularity：汽车在Twitter流中提到的次数
- en: 'msrp: manufacturer’s suggested retail price'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: msrp：制造商建议零售价
- en: 'For us, the most interesting column here is the last one: MSRP (manufacturer’s
    suggested retail price, or simply the price of a car). We will use this column
    for predicting the prices of a car.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们来说，这里最有趣的列是最后一个：MSRP（制造商建议零售价，或简称为汽车价格）。我们将使用这个列来预测汽车的价格。
- en: 2.2.3 Target variable analysis
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.3 目标变量分析
- en: The MSRP column contains the important information—it’s our target variable,
    the *y*, which is the value that we want to learn to predict.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: MSRP列包含重要信息——它是我们的目标变量，即*y*，这是我们想要学习预测的值。
- en: 'One of the first steps of exploratory data analysis should always be to look
    at what the values of *y* look like. We typically do this by checking the distribution
    of *y*: a visual description of what the possible values of *y* can be and how
    often they occur. This type of visualization is called a *histogram*.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 探索性数据分析的第一步始终是查看*y*的值看起来如何。我们通常通过检查*y*的分布来完成此操作：对*y*的可能值及其发生频率的视觉描述。这种可视化类型称为*直方图*。
- en: 'We will use Seaborn to plot the histogram, so type the following in the Jupyter
    Notebook:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Seaborn来绘制直方图，所以请在Jupyter Notebook中输入以下内容：
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: After plotting this graph, we immediately notice that the distribution of prices
    has a very long tail. There are many cars with low prices on the left side, but
    the number quickly drops, and there’s a long tail of very few cars with high prices
    (see figure 2.5).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制这个图表后，我们立即注意到价格分布有一个非常长的尾巴。左侧有许多低价汽车，但数量迅速下降，并且有一个高价汽车数量非常少的长期尾巴（见图2.5）。
- en: '![](../Images/02_05.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_05.png)'
- en: Figure 2.5 The distribution of the prices in the dataset. We see many values
    at the low end of the price axis and almost nothing at the high end. This is a
    long tail distribution, which is a typical situation for many items with low prices
    and very few expensive ones.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 数据集中价格分布。我们看到价格轴低端的许多值，而高端几乎没有。这是一个长尾分布，这是许多低价且少量高价物品的典型情况。
- en: 'We can have a closer look by zooming in a bit and looking at values below $100,000
    (figure 2.6):'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过稍微放大并查看低于10万美元的值来更仔细地观察（图2.6）：
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/02_06.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_06.png)'
- en: Figure 2.6 The distribution of the prices for cars below $100,000\. Looking
    only at car prices below $100,000 allows us to see the head of the distribution
    better. We also notice a lot of cars that cost $1,000.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6 低于10万美元的汽车价格分布。仅查看低于10万美元的汽车价格，我们可以更好地看到分布的头部。我们也注意到很多价格为1000美元的汽车。
- en: 'The long tail makes it quite difficult for us to see the distribution, but
    it has an even stronger effect on a model: such distribution can greatly confuse
    the model, so it won’t learn well enough. One way to solve this problem is log
    transformation. If we apply the log function to the prices, it removes the undesired
    effect (figure 2.7).'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 长尾使得我们很难看到分布，但它对模型的影响更大：这种分布可以极大地混淆模型，因此它不会很好地学习。解决这个问题的方法之一是取对数转换。如果我们对价格应用对数函数，它将消除不希望的效果（图2.7）。
- en: '![](../Images/02_06-Equation_2-1.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_06-Equation_2-1.png)'
- en: '![](../Images/02_07.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_07.png)'
- en: Figure 2.7 The logarithm of the price. The effect of the long tail is removed,
    and we can see the entire distribution in one plot.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7 价格的对数。长尾效应被消除，我们可以在一个图中看到整个分布。
- en: The +1 part is important in cases that have zeros. The logarithm of zero is
    minus infinity, but the logarithm of one is zero. If our values are all non-negative,
    by adding 1, we make sure that the transformed values do not go below zero.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在有零值的情况下，+1部分很重要。零的对数是负无穷大，但一的对数是零。如果我们的值都是非负的，通过加1，我们确保转换后的值不会低于零。
- en: 'For our specific case, zero values are not an issue—all the prices we have
    start at $1,000—but it’s still a convention that we follow. NumPy has a function
    that performs this transformation:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的具体情况，零值不是问题——我们所有的价格都从1000美元开始——但这是我们遵循的惯例。NumPy有一个执行这种转换的函数：
- en: '[PRE10]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To look at the distribution of the prices after the transformation, we can
    use the same `histplot` function (figure 2.7):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看转换后的价格分布，我们可以使用相同的`histplot`函数（图2.7）：
- en: '[PRE11]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As we see, this transformation removes the long tail, and now the distribution
    resembles a bell-shaped curve. This distribution is not normal, of course, because
    of the large peak in lower prices, but the model can deal with it more easily.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，这种转换去除了长尾，现在分布看起来像钟形曲线。当然，由于低价的大峰值，这个分布不是正态分布，但模型可以更容易地处理它。
- en: NOTE Generally, it’s good when the target distribution looks like the normal
    distribution (figure 2.8). Under this condition, models such as linear regression
    perform well.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：一般来说，当目标分布看起来像正态分布（图2.8）时是很好的。在这种情况下，线性回归等模型表现良好。
- en: '![](../Images/02_08.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_08.png)'
- en: Figure 2.8 The normal distribution, also known as Gaussian, follows the bell-shaped
    curve, which is symmetrical and has a peak in the center.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 正态分布，也称为高斯分布，遵循钟形曲线，它是对称的，并且在中心有一个峰值。
- en: Exercise 2.1
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 练习2.1
- en: The head of a distribution is a range where there are many values. What is a
    long tail of a distribution?
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 分布的头部是一个有很多值的范围。那么，分布的长尾是什么？
- en: a) A big peak around 1,000 USD
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: a) 大约在1,000美元左右的峰值
- en: b) A case when many values are spread very far from the head—and these values
    visually appear as a “tail” on the histogram
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: b) 当许多值非常远离头部分散时的情况——这些值在直方图上视觉上看起来像“尾部”
- en: c) A lot of very similar values packed together within a short range
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: c) 在一个很短的范围内紧密堆积的许多非常相似的价值
- en: 2.2.4 Checking for missing values
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.4 检查缺失值
- en: We will look more closely at other features a bit later, but one thing we should
    do now is check for missing values in the data. This step is important because,
    typically, machine learning models cannot deal with missing values automatically.
    We need to know whether we need to do anything special to handle those values.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后会更仔细地查看其他特征，但现在我们应该做的一件事是检查数据中的缺失值。这一步很重要，因为通常机器学习模型无法自动处理缺失值。我们需要知道是否需要对这些值进行特殊处理。
- en: 'Pandas has a convenient function that checks for missing values:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas有一个方便的函数可以检查缺失值：
- en: '[PRE12]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This function shows
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数显示了
- en: '[PRE13]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The first thing we see is that MSRP—our target variable—doesn’t have any missing
    values. This result is good, because otherwise, such records won’t be useful to
    us: we always need to know the target value of an observation to use it for training
    the model. Also, a few columns have missing values, especially market_category,
    in which we have almost 4,000 rows with missing values.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先看到的是，MSRP——我们的目标变量——没有任何缺失值。这个结果是好的，因为否则，这样的记录对我们来说将没有用处：我们总是需要知道观察到的目标值才能用于训练模型。此外，一些列有缺失值，特别是市场类别，其中我们几乎有4,000行缺失值。
- en: 'We need to deal with missing values later when we train the model, so we should
    keep this problem in mind. For now, we don’t do anything else with these features
    and proceed to the next step: setting up the validation framework so that we can
    train and test machine learning models.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在训练模型时需要处理缺失值，所以我们应该记住这个问题。现在，我们不对这些特征做任何其他操作，继续到下一步：设置验证框架，以便我们可以训练和测试机器学习模型。
- en: 2.2.5 Validation framework
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.5 验证框架
- en: As we learned previously, it’s important to set up the validation framework
    as early as possible to make sure that the models we train are good and can generalize—that
    is, that the model can be applied to new, unseen data. To do that, we put aside
    some data and train the model only on one part. Then we use the held-out dataset—the
    one we didn’t use for training—to make sure that the predictions of the model
    make sense.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所学的，尽早设置验证框架很重要，以确保我们训练的模型是好的，并且可以泛化——也就是说，模型可以应用于新的、未见过的数据。为了做到这一点，我们留出一部分数据，只在一个部分上训练模型。然后我们使用留出的数据集——我们没有用于训练的数据集——来确保模型的预测是有意义的。
- en: This step is important because we train the model by using optimization methods
    that fit the function *g*(*X* ) to the data *X*. Sometimes these optimization
    methods pick up spurious patterns—patterns that appear to be real patterns to
    the model but in reality are random fluctuations. If we have a small training
    dataset in which all BMW cars cost only $10,000, for example, the model will think
    that this is true for all BMW cars in the world.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步骤很重要，因为我们通过使用优化方法来训练模型，这些方法将函数 *g*(*X*) 与数据 *X* 相拟合。有时这些优化方法会捕捉到虚假模式——这些模式在模型看来似乎是真实模式，但实际上是随机波动。例如，如果我们有一个小的训练数据集，其中所有宝马车的价格仅为10,000美元，那么模型会认为这是世界上所有宝马车的真实情况。
- en: To ensure that this doesn’t happen, we use validation. Because the validation
    dataset is not used for training the model, the optimization method did not see
    this data. When we apply the model to this data, it emulates the case of applying
    the model to new data that we’ve never seen. If the validation dataset has BMW
    cars with prices higher than $10,000, but our model will predict $10,000 on them,
    we will notice that the model doesn’t perform well on these examples.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保这一点，我们使用验证。因为验证数据集没有用于训练模型，优化方法没有看到这些数据。当我们将模型应用于这些数据时，它模拟了将模型应用于我们从未见过的新的数据的情况。如果验证数据集中有价格高于
    10,000 美元的宝马车，但我们的模型将预测它们为 10,000 美元，我们将注意到模型在这些示例上的表现不佳。
- en: 'As we already know, we need to split the dataset into three parts: train, validation,
    and test (figure 2.9).'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，我们需要将数据集分为三个部分：训练集、验证集和测试集（图 2.9）。
- en: '![](../Images/02_09.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_09.png)'
- en: 'Figure 2.9 The entire dataset is split into three parts: train, validation
    and test.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9 整个数据集分为三部分：训练集、验证集和测试集。
- en: Let’s split the DataFrame such that
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将 DataFrame 分割成以下形式
- en: 20% of data goes to validation.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 20% 的数据用于验证。
- en: 20% goes to test.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 20% 用于测试。
- en: The remaining 60% goes to train.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剩余的 60% 用于训练。
- en: Listing 2.1 Splitting Data into validation, test, and training sets
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 2.1 将数据分为验证集、测试集和训练集
- en: '[PRE14]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Gets the number of rows in the DataFrame
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取 DataFrame 中的行数
- en: ❷ Calculates how many rows should go to train, validation, and test
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算应该有多少行用于训练、验证和测试
- en: ❸ Fixes the random seed to make sure that the results are reproducible
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 固定随机种子以确保结果可重复
- en: ❹ Creates a NumPy array with indices from 0 to (n–1), and shuffles it
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 创建一个包含从 0 到 (n-1) 的索引的 NumPy 数组，并对其进行打乱
- en: ❺ Uses the array with indices to get a shuffled DataFrame
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 使用索引数组获取打乱的 DataFrame
- en: ❻ Splits the shuffled DataFrame into train, validation, and test
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 将打乱顺序的 DataFrame 分割为训练集、验证集和测试集
- en: Let’s take a closer look at this code and clarify a few things.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看这段代码，并澄清一些事情。
- en: 'In ❹, we create an array and then shuffle it. Let’s see what happens there.
    We can take a smaller array of five elements and shuffle it:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ❹ 中，我们创建一个数组并将其打乱。让我们看看那里会发生什么。我们可以取一个包含五个元素的较小数组并对其进行打乱：
- en: '[PRE15]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If we run it, it prints something similar to
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行它，它将打印出类似的内容
- en: '[PRE16]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If we run it again, however, the results will be different:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们再次运行它，结果将不同：
- en: '[PRE17]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To make sure that every time we run it, the results are the same, in ❸ we fix
    the random seed:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保每次运行它时结果都相同，在 ❸ 中我们固定随机种子：
- en: '[PRE18]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The function `np.random.seed` takes in any number and uses this number as the
    starting seed for all the generated data inside NumPy’s random package.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `np.random.seed` 接收任何数字，并使用此数字作为 NumPy 随机包内生成所有数据的起始种子。
- en: When we execute this code, it prints
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们执行此代码时，它将打印
- en: '[PRE19]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In this case the results are still random, but when we re-execute it, the result
    turns out to be the same as the previous run:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，结果仍然是随机的，但当我们重新执行时，结果与之前的运行相同：
- en: '[PRE20]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This is good for reproducibility. If we want somebody else to run this code
    and get the same results, we need to make sure that everything is fixed, even
    the “random” component of our code.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这有利于可重复性。如果我们希望其他人运行此代码并获得相同的结果，我们需要确保一切固定，即使是代码中的“随机”部分。
- en: Note This makes the results reproducible on the same computer. With a different
    operating system and a different version of NumPy, the result may be different.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这使结果在同一台计算机上可重复。在不同的操作系统和不同的 NumPy 版本下，结果可能不同。
- en: 'After we create an array with indices `idx`, we can use it to get a shuffled
    version of our initial DataFrame. For that purpose in ❺, we use `iloc`, which
    is a way to access the rows of the DataFrame by their numbers:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们创建一个索引数组 `idx` 之后，我们可以使用它来获取初始 DataFrame 的打乱版本。为此，在 ❺ 中，我们使用 `iloc`，这是一种通过行号访问
    DataFrame 的方法：
- en: '[PRE21]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: If `idx` contains shuffled consequent numbers, this code will produce a shuffled
    DataFrame (figure 2.10).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `idx` 包含打乱的连续数字，此代码将生成一个打乱的 DataFrame（图 2.10）。
- en: '![](../Images/02_10.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_10.png)'
- en: Figure 2.10 Using `iloc` to shuffle a DataFrame. When used with a shuffled array
    of indices, it creates a shuffled DataFrame.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10 使用 `iloc` 打乱 DataFrame。当与打乱的索引数组一起使用时，它创建一个打乱的 DataFrame。
- en: 'In this example, we used `iloc` with a list of indices. We can also use ranges
    with the colon operator (:), and this is exactly what we do in ❻ for splitting
    the shuffled DataFrame into train, validation, and test:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用了 `iloc` 和一个索引列表。我们也可以使用冒号运算符（:）来指定范围，这正是我们在 ❻ 中对打乱顺序的DataFrame进行拆分以创建训练、验证和测试集时所做的事情：
- en: '[PRE22]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now the DataFrame is split into three parts, and we can continue. Our initial
    analysis showed a long tail in the distribution of prices, and to remove its effect,
    we need to apply the log transformation. We can do that for each DataFrame separately:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在DataFrame被分成三部分，我们可以继续。我们的初步分析显示价格分布有一个长尾，为了消除其影响，我们需要应用对数变换。我们可以为每个DataFrame单独做这件事：
- en: '[PRE23]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To avoid accidentally using the target variable later, let’s remove it from
    the dataframes:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免不小心在以后使用目标变量，让我们从数据框中移除它：
- en: '[PRE24]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Note Removing the target variable is an optional step. But it’s helpful to
    make sure that we don’t use it when training a model: if that happens, we’d use
    price for predicting the price, and our model would have perfect accuracy.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：移除目标变量是一个可选步骤。但确保我们在训练模型时不会使用它是很有帮助的：如果那样做了，我们会用价格来预测价格，我们的模型将具有完美的准确性。
- en: 'When the validation split is done, we can go to the next step: training a model.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 当完成验证拆分后，我们可以进行下一步：训练模型。
- en: 2.3 Machine learning for regression
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 回归问题的机器学习
- en: 'After performing the initial data analysis, we are ready to train a model.
    The problem we are solving is a regression problem: the goal is to predict a number—the
    price of a car. For this project we will use the simplest regression model: linear
    regression.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行初步数据分析后，我们准备训练一个模型。我们正在解决的问题是一个回归问题：目标是预测一个数字——汽车的价格。对于这个项目，我们将使用最简单的回归模型：线性回归。
- en: 2.3.1 Linear regression
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.1 线性回归
- en: 'To predict the price of a car, we need to use a machine learning model. To
    do this, we will use linear regression, which we will implement ourselves. Typically,
    we don’t do this by hand; instead, we let a framework do this for us. In this
    chapter, however, we want to show that there is no magic inside these frameworks:
    it’s just code. Linear regression is a perfect model because it’s relatively simple
    and can be implemented with just a few lines of NumPy code.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测汽车的价格，我们需要使用机器学习模型。为了做到这一点，我们将使用线性回归，我们将自己实现它。通常，我们不手动做这件事；相反，我们让一个框架为我们做这件事。然而，在本章中，我们想表明这些框架中并没有什么魔法：这只是代码。线性回归是一个完美的模型，因为它相对简单，可以用几行NumPy代码实现。
- en: First, let’s understand how linear regression works. As we know from chapter
    1, a supervised machine learning model has the form
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们了解线性回归是如何工作的。正如我们从第一章所知，一个监督机器学习模型的形式是
- en: '![](../Images/02_10-Equation_2-2.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![方程式 2-2](../Images/02_10-Equation_2-2.png)'
- en: This is a matrix form. *X* is a matrix where the features of observations are
    rows of the matrix, and *y* is a vector with the values we want to predict.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个矩阵形式。*X* 是一个矩阵，其中观测的特征是矩阵的行，而 *y* 是一个包含我们想要预测的值的向量。
- en: These matrices and vectors may sound confusing, so let’s take a step back and
    consider what happens with a single observation *x[i]* and the value *y[i]* that
    we want to predict. The index *i* here means that this is an observation number
    *i*, one of *m* observations that we have in our training dataset.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这些矩阵和向量可能听起来很复杂，所以让我们退一步，考虑单个观测 *x[i]* 和我们想要预测的值 *y[i]* 发生了什么。这里的索引 *i* 表示这是一个观测编号
    *i*，是我们训练数据集中 *m* 个观测中的一个。
- en: Then, for this single observation, the previous formula looks like
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于这个单个观测，前面的公式看起来是这样的
- en: '![](../Images/02_10-Equation_2-3.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![方程式 2-3](../Images/02_10-Equation_2-3.png)'
- en: 'If we have *n* features, our vector *x[i]* is *n*-dimensional, so it has *n*
    components:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有 *n* 个特征，我们的向量 *x[i]* 是 *n*-维的，因此它有 *n* 个分量：
- en: '![](../Images/02_10-Equation_2-4.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![方程式 2-4](../Images/02_10-Equation_2-4.png)'
- en: 'Because it has *n* components, we can write the function *g* as a function
    with *n* parameters, which is the same as the previous formula:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它有 *n* 个分量，我们可以将函数 *g* 写成一个具有 *n* 个参数的函数，这与前面的公式相同：
- en: '![](../Images/02_10-Equation_2-5.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![方程式 2-5](../Images/02_10-Equation_2-5.png)'
- en: 'For our case, we have 7,150 cars in the training dataset. This means that *m*
    = 7,150, and *i* can be any number between 0 and 7,149\. For *i =* 10, for example,
    we have the following car:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的案例，我们在训练数据集中有 7,150 辆车。这意味着 *m* = 7,150，而 *i* 可以是 0 到 7,149 之间的任何数字。例如，当
    *i =* 10 时，我们有一辆以下这样的车：
- en: '[PRE25]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let’s pick a few numerical features and ignore the rest for now. We can start
    with horsepower, MPG in the city, and popularity:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们挑选几个数值特征，暂时忽略其他特征。我们可以从马力、城市油耗和受欢迎程度开始：
- en: '[PRE26]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Then let’s assign these features to *x*[*i*1], *x*[i2], and *x*[i3], respectively.
    This way, we get the feature vector *x[i]* with three components:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将这些特征分别分配给 *x*[i1]，*x*[i2]，和 *x*[i3]。这样，我们得到具有三个分量的特征向量 *x[i]*：
- en: '![](../Images/02_10-Equation_2-6.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_10-Equation_2-6.png)'
- en: 'To make it easier to understand, we can translate this mathematical notation
    to Python. In our case, the function *g* has the following signature:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易理解，我们可以将这种数学符号翻译成 Python。在我们的例子中，函数 *g* 具有以下签名：
- en: '[PRE27]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In this code, the variable `xi` is our vector *x[i]*. Depending on implementation,
    `xi` could be a list with *n* elements or a NumPy array of size *n*.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，变量 `xi` 是我们的向量 *x[i]*。根据实现方式，`xi` 可能是一个包含 *n* 个元素的列表或一个大小为 *n* 的 NumPy
    数组。
- en: 'For the car described previously, `xi` is a list with three elements:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 对于之前描述的汽车，`xi` 是一个包含三个元素的列表：
- en: '[PRE28]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'When we apply the function `g` to a vector `xi`, it produces `y_pred` as the
    output, which is the `g`’s prediction for `xi`:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将函数 `g` 应用到向量 `xi` 上时，它会产生 `y_pred` 作为输出，这是 `g` 对 `xi` 的预测：
- en: '[PRE29]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We expect this prediction to be as close as possible to *y[i]*, which is the
    real price of the car.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望这个预测尽可能接近 *y[i]*，即汽车的实际价格。
- en: Note In this section, we will use Python to illustrate the ideas behind mathematical
    formulas. We don’t need to use these code snippets for doing the project. On the
    other hand, taking this code, putting it into Jupyter, and trying to run it could
    be helpful for understanding the concepts.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在本节中，我们将使用 Python 来说明数学公式背后的思想。我们不需要使用这些代码片段来完成项目。另一方面，将此代码放入 Jupyter 中并尝试运行它可能有助于理解这些概念。
- en: There are many ways the function *g* could look, and the choice of a machine
    learning algorithm defines the way it works.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 *g* 可以有多种形式，机器学习算法的选择定义了它的工作方式。
- en: 'If *g* is the linear regression model, it has the following form:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *g* 是线性回归模型，它具有以下形式：
- en: '![](../Images/02_10-Equation_2-7.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_10-Equation_2-7.png)'
- en: 'The variables *w*[0], *w*[1], *w*[2], ..., *w[n]* are the parameters of the
    model:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 *w*[0]，*w*[1]，*w*[2]，...，*w*[n]* 是模型的参数：
- en: '*w*[0] is the *bias* term.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[0] 是 *偏置* 项。'
- en: '*w*[1], *w*[2], ..., *w[n]* are the *weights* for each feature *x*[*i*1], *x*[*i*2],
    ..., *x*[in].'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[1]，*w*[2]，...，*w*[n] 是每个特征 *x*[i1]，*x*[i2]，...，*x*[in] 的 *权重*。'
- en: These parameters define exactly how the model should combine the features so
    that the predictions at the end are as good as possible. It’s okay if the meaning
    behind these parameters is not clear yet, because we will cover them later in
    this section.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这些参数定义了模型如何组合特征，以便最终预测尽可能好。这些参数背后的含义可能还不清楚，因为我们将在这个部分稍后讨论它们。
- en: 'To keep the formula shorter, let’s use sum notation:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使公式更短，让我们使用求和符号：
- en: Exercise 2.2
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 2.2
- en: For supervised learning, we use a machine learning model for a single observation
    *y[i]* ≈ *g*(*x[i]*). What are *x[i]* and *y[i]* for this project?
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 对于监督学习，我们使用机器学习模型对单个观察值 *y[i]* ≈ *g*(*x[i]*)。在这个项目中，*x[i]* 和 *y[i]* 是什么？
- en: a) *x[i]* is a feature vector—a vector that contains a few numbers that describe
    the object (a car)—and *y[i]* is the logarithm of the price of this car.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: a) *x[i]* 是一个特征向量——一个包含描述对象（汽车）的几个数字的向量——而 *y[i]* 是这辆车的价格的对数。
- en: b) *y[i]* is a feature vector—a vector that contains a few numbers that describe
    the object (a car)—and *x[i]* is the logarithm of the price of this car.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: b) *y[i]* 是一个特征向量——一个包含描述对象（汽车）的几个数字的向量——而 *x[i]* 是这辆车的价格的对数。
- en: '![](../Images/02_10-Equation_2-8.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_10-Equation_2-8.png)'
- en: These weights are what the model learns when we train it. To better understand
    how the model uses these weights, let’s consider the following values (table 2.1).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这些权重是我们在训练模型时模型学习的。为了更好地理解模型如何使用这些权重，让我们考虑以下值（表 2.1）。
- en: Table 2.1 An example of weights that a linear regression model learned
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.1 线性回归模型学习到的权重示例
- en: '| w[0] | w[1] | w[2] | w[3] |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| w[0] | w[1] | w[2] | w[3] |'
- en: '| 7.17 | 0.01 | 0.04 | 0.002 |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 7.17 | 0.01 | 0.04 | 0.002 |'
- en: 'So if we want to translate this model to Python, it will look like this:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们想将这个模型翻译成 Python，它将看起来像这样：
- en: '[PRE30]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We put all the feature weights inside a single list `w`—just like we did with
    `xi` previously. All we need to do now is loop over these weights and multiply
    them by the corresponding feature values. This is nothing else but the direct
    translation of the previous formula to Python.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们把所有特征权重放在一个单独的列表`w`中——就像我们之前对`xi`所做的那样。我们现在需要做的就是遍历这些权重并将它们乘以相应的特征值。这不过是将之前的公式直接翻译成Python。
- en: 'This is easy to see. Have another look at the formula:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这很容易看出。再看一下公式：
- en: '![](../Images/02_10-Equation_2-9.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_10-Equation_2-9.png)'
- en: Our example has three features, so *n =* 3, and we have
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的例子有三个特征，所以*n =* 3，我们有
- en: '![](../Images/02_10-Equation_2-10.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_10-Equation_2-10.png)'
- en: This is exactly what we have in the code
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是代码中的内容
- en: '[PRE31]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: with the simple exception that indexing in Python starts with 0, *x*[*i*1] becomes
    `xi[0]` and *w*[1] is `w[0]`.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Python中的索引从0开始之外，*x*[*i*1]变为`xi[0]`，而*w*[1]是`w[0]`。
- en: 'Now let’s see what happens when we apply the model to our observation *x[i]*
    and replace the weights with their values:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看当我们将模型应用于我们的观察结果*x[i]*并替换权重为它们的值时会发生什么：
- en: '![](../Images/02_10-Equation_2-11.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_10-Equation_2-11.png)'
- en: 'The prediction we get for this observation is 12.31\. Remember that during
    preprocessing, we applied the logarithmic transformation to our target variable
    *y*. This is why the model we trained on this data also predicts the logarithm
    of the price. To undo the transformation, we need to take the exponent of the
    logarithm. In our case, when we do it, the prediction becomes $603,000:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个观察结果，我们得到的预测是12.31。记住，在预处理过程中，我们对目标变量*y*应用了对数变换。这就是为什么在这个数据上训练的模型也预测了价格的对数。为了撤销变换，我们需要取对数的指数。在我们的情况下，当我们这样做时，预测变为$603,000：
- en: exp(12.31 + 1) = 603,000
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: exp(12.31 + 1) = 603,000
- en: The bias term (7.17) is the value we would predict if we didn’t know anything
    about the car; it serves as a baseline.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差项（7.17）是我们对汽车一无所知时预测的值；它作为基准。
- en: 'We do know something about the car, however: horsepower, MPG in the city, and
    popularity. These features are the *x*[*i*1], *x*[i2], and *x*[i3] features, each
    of which tells us something about the car. We use this information to adjust the
    baseline.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确实对汽车有一些了解：马力、城市每加仑英里数和流行度。这些特征是*x*[*i*1]，*x*[i2]，和*x*[i3]特征，每个特征都告诉我们关于汽车的一些信息。我们使用这些信息来调整基准。
- en: 'Let’s consider the first feature: horsepower. The weight for this feature is
    0.01, which means that for each extra unit of horsepower, we adjust the baseline
    by adding 0.01\. Because we have 453 horses in the engine, we add 4.53 to the
    baseline: 453 horses · 0.01 = 4.53.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑第一个特征：马力。这个特征的权重是0.01，这意味着对于每个额外的马力单位，我们通过添加0.01来调整基准。因为我们有453匹马在引擎中，所以我们向基准添加4.53：453匹马
    · 0.01 = 4.53。
- en: 'The same happens with MPG. Each additional mile per gallon increases the price
    by 0.04, so we add 0.44: 11 MPG · 0.04 = 0.44.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，对于每加仑多行驶一英里，价格会增加0.04，所以我们加上0.44：11 MPG · 0.04 = 0.44。
- en: Finally, we take popularity into account. In our example, each mention in the
    Twitter stream results in a 0.002 increase. In total, popularity contributes 0.172
    to the final prediction.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们考虑流行度。在我们的例子中，Twitter流中的每一次提及都会导致0.002的增加。总的来说，流行度对最终预测的贡献为0.172。
- en: This is exactly why we get 12.31 when we combine everything (figure 2.11).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是为什么当我们结合所有内容时得到12.31的原因（图2.11）。
- en: '![](../Images/02_11.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_11.png)'
- en: Figure 2.11 The prediction of linear regression is the baseline of 7.17 (the
    bias term) adjusted by information we have from the features. Horsepower contributes
    4.53 to the final prediction; MPG, 0.44; and popularity, 0.172.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.11 线性回归的预测是基准值7.17（偏差项）加上我们从特征中获得的信息调整后的结果。马力对最终预测的贡献为4.53；每加仑英里数，0.44；流行度，0.172。
- en: 'Now, let’s remember that we are actually dealing with vectors, not individual
    numbers. We know that *x[i]* is a vector with *n* components:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们记住我们实际上处理的是向量，而不是单个数字。我们知道*x[i]*是一个有*n*个分量的向量：
- en: '![](../Images/02_11-Equation_2-12.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_11-Equation_2-12.png)'
- en: 'We can also put all the weights together in a single vector *w* :'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将所有权重合并到一个单独的向量*w*中：
- en: '![](../Images/02_11-Equation_2-13.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_11-Equation_2-13.png)'
- en: 'In fact, we already did that in the Python example when we put all the weights
    in a list, which was a vector of dimensionality 3 with weights for each individual
    feature. This is how the vectors look for our example:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们在Python示例中已经那样做了，当时我们把所有的权重放在一个列表中，这是一个维度为3的向量，包含每个单个特征的权重。这就是我们的例子中向量的样子：
- en: '![](../Images/02_11-Equation_2-14.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_11-Equation_2-14.png)'
- en: '![](../Images/02_11-Equation_2-15.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_11-Equation_2-15.png)'
- en: 'Because we now think of both features and weights as vectors *x[i]* and *w*,
    respectively, we can replace the sum of the elements of these vectors with a dot
    product between them:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 因为现在我们将特征和权重都视为向量 *x[i]* 和 *w*，我们可以用它们之间的点积替换这些向量的元素之和：
- en: '![](../Images/02_11-Equation_2-16.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_11-Equation_2-16.png)'
- en: 'The dot product is a way of multiplying two vectors: we multiply corresponding
    elements of the vectors and then sum the results. Refer to appendix C for more
    details about vector-vector multiplication.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 点积是乘以两个向量的方式：我们乘以向量的对应元素，然后将结果相加。有关向量-向量乘法的更多详细信息，请参阅附录 C。
- en: 'The translation of the formula for dot product to the code is straightforward:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 将点积公式的翻译转换为代码是直接的：
- en: '[PRE32]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Using the new notation, we can rewrite the entire equation for linear regression
    as
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新的符号，我们可以将线性回归的整个方程重新写为
- en: '![](../Images/02_11-Equation_2-17.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_11-Equation_2-17.png)'
- en: where
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '*w*[0] is the bias term.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[0] 是偏置项。'
- en: '*w* is the *n*-dimensional vector of weights.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w* 是 *n*-维权重向量。'
- en: 'Now we can use the new `dot` function, so the linear regression function in
    Python becomes very short:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用新的 `dot` 函数，因此 Python 中的线性回归函数变得非常简短：
- en: '[PRE33]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Alternatively, if `xi` and `w` are NumPy arrays, we can use the built-in `dot`
    method for multiplication:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果 `xi` 和 `w` 是 NumPy 数组，我们可以使用内置的 `dot` 方法进行乘法：
- en: '[PRE34]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To make it even shorter, we can combine *w*[0] and *w* into one (*n+*1)-dimensional
    vector by prepending *w*[0] to *w* right in front of *w*[1]:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使其更短，我们可以通过在 *w*[1] 前面添加 *w*[0] 来将 *w*[0] 和 *w* 合并成一个 (*n+*1)-维向量：
- en: '![](../Images/02_11-Equation_2-18.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_11-Equation_2-18.png)'
- en: Here, we have a new weights vector *w* that consists of the bias term *w*[0]
    followed by the weights *w*[1], *w*[2]*, ...* from the original weights vector
    *w*.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有一个新的权重向量 *w*，它由偏置项 *w*[0] 后跟原始权重向量 *w* 中的权重 *w*[1]，*w*[2]*，... 组成。
- en: 'In Python, this is very easy to do. If we already have the old weights in a
    list `w`, all we need to do is the following:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，这很容易做到。如果我们已经有一个包含旧权重的列表 `w`，我们只需要做以下操作：
- en: '[PRE35]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Remember that the plus operator in Python concatenates lists, so `[1]` `+`
    `[2,` `3,` `4]` will create a new list with four elements: `[1,` `2,` `3,` `4]`.
    In our case, `w` is already a list, so we create a new `w` with one extra element
    at the beginning: `w0`.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，Python 中的加号运算符用于连接列表，所以 `[1]` `+` `[2,` `3,` `4]` 将创建一个包含四个元素的新列表：`[1,` `2,`
    `3,` `4]`。在我们的例子中，`w` 已经是一个列表，所以我们创建一个新的 `w`，在开头添加一个额外的元素：`w0`。
- en: 'Because now *w* becomes a (*n*+1)-dimensional vector, we also need to adjust
    the feature vector *x[i]* so that the dot product between them still works. We
    can do this easily by adding a dummy feature *x*[i 0], which always takes the
    value 1\. Then we prepend this new dummy feature to *x[i]* right before *x*[i
    1]:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 因为现在 *w* 成为一个 (*n*+1)-维向量，我们还需要调整特征向量 *x[i]*，以便它们之间的点积仍然有效。我们可以通过添加一个虚拟特征 *x*[i
    0]，它始终取值为 1 来轻松完成此操作。然后，我们在 *x*[i 1] 之前将这个新的虚拟特征添加到 *x[i]* 中：
- en: '![](../Images/02_11-Equation_2-19.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_11-Equation_2-19.png)'
- en: 'Or, in code:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，用代码表示：
- en: '[PRE36]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We create a new list `xi` with 1 as the first element followed by all the elements
    from the old list `xi`.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个新的列表 `xi`，其第一个元素为 1，后跟旧列表 `xi` 中的所有元素。
- en: 'With these modifications, we can express the model as the dot product between
    the new *x[i]* and the new *w*:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些修改，我们可以将模型表示为新的 *x[i]* 和新的 *w* 之间的点积：
- en: '![](../Images/02_11-Equation_2-20.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_11-Equation_2-20.png)'
- en: 'The translation to the code is simple:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的转换很简单：
- en: '[PRE37]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: These formulas for linear regressions are equivalent because the first feature
    of the new *x[i]* is 1, so when we multiply the first component of *x[i]* by the
    first component of *w*, we get the bias term, because *w*[0] · 1 = *w*[0].
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 这些线性回归公式是等价的，因为新 *x[i]* 的第一个特征是 1，所以当我们乘以 *x[i]* 的第一个分量和 *w* 的第一个分量时，我们得到偏置项，因为
    *w*[0] · 1 = *w*[0]。
- en: 'We are ready to consider the bigger picture again and talk about the matrix
    form. There are many observations and *x[i]* is one of them. Thus, we have *m*
    feature vectors *x*[1], *x*[2], ..., *x[i]* , ..., *x*[m], and each of these vectors
    consists of *n*+1 features:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以再次考虑更大的图景，并讨论矩阵形式。有许多观察结果，*x[i]* 是其中之一。因此，我们有了 *m* 个特征向量 *x*[1]，*x*[2]，...，*x[i]*，...，*x*[m]，并且这些向量中的每一个都包含
    *n*+1 个特征：
- en: '![](../Images/02_11-Equation_2-21.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_11-Equation_2-21.png)'
- en: We can put these vectors together as rows of a matrix. Let’s call this matrix
    *X* (figure 2.12).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些向量组合成矩阵的行。让我们称这个矩阵为 *X*（见图2.12）。
- en: '![](../Images/02_12.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_12.png)'
- en: Figure 2.12 Matrix *X*, in which observations *x*[1], *x*[2], ..., *x*[m] are
    rows
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.12 矩阵 *X*，其中观测值 *x*[1]、*x*[2]、...、*x*[m] 是行
- en: 'Let’s see how it looks in code. We can take a few rows from the training dataset,
    such as the first, second, and tenth:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看代码中的样子。我们可以从训练数据集中取几行，例如第一行、第二行和第十行：
- en: '[PRE38]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now let’s put the rows together in another list:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将这些行组合成另一个列表：
- en: '[PRE39]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'List `X` now contains three lists. We can think of it as a 3x4 matrix—a matrix
    with three rows and four columns:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 `X` 现在包含三个列表。我们可以将其视为一个3x4矩阵——一个有三行四列的矩阵：
- en: '[PRE40]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Each column of this matrix is a feature:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 这个矩阵的每一列都是一个特征：
- en: The first column is a dummy feature with “1.”
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一列是一个虚拟特征，值为“1。”
- en: The second column is the engine horsepower.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二列是引擎马力。
- en: The third—MPG in the city.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三列——城市油耗。
- en: And the last one—popularity, or the number of mentions in a Twitter stream.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个——流行度，或Twitter流中提及的数量。
- en: 'We already learned that to make a prediction for a single feature vector, we
    need to calculate the dot product between this feature vector and the weights
    vector. Now we have a matrix `X`, which in Python is a list of feature vectors.
    To make predictions for all the rows of the matrix, we can simply iterate over
    all rows of `X` and compute the dot product:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解到，为了对一个单个特征向量进行预测，我们需要计算这个特征向量与权重向量之间的点积。现在我们有一个矩阵 `X`，在Python中它是一个特征向量的列表。为了对矩阵的所有行进行预测，我们可以简单地遍历
    `X` 的所有行并计算点积：
- en: '[PRE41]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In linear algebra, this is the matrix-vector multiplication: we multiply the
    matrix *X* by the vector *w*. The formula for linear regression becomes'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性代数中，这是矩阵-向量乘法：我们用向量 *w* 乘以矩阵 *X*。线性回归的公式变为
- en: '![](../Images/02_12-Equation_2-22.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_12-Equation_2-22.png)'
- en: The result is an array with predictions for each row of *X*. Refer to appendix
    C for more details about matrix-vector multiplication.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个数组，包含 *X* 每一行的预测。有关矩阵-向量乘法的更多详细信息，请参阅附录C。
- en: 'With this matrix formulation, the code for applying linear regression to make
    predictions becomes very simple. The translation to NumPy becomes straightforward:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种矩阵公式，将线性回归应用于预测的代码变得非常简单。将其转换为NumPy变得直截了当：
- en: '[PRE42]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Exercise 2.3
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 练习2.3
- en: When we multiply the matrix *X* by the weights vector *w*, we get
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将矩阵 *X* 与权重向量 *w* 相乘时，我们得到
- en: a) A vector *y* with the actual price
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: a) 包含实际价格的向量 *y*
- en: b) A vector *y* with price predictions
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: b) 一个包含价格预测的向量 *y*
- en: c) A single number *y* with price predictions
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: c) 一个包含价格预测的单个数字 *y*
- en: 2.3.2 Training linear regression model
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.2 训练线性回归模型
- en: So far, we’ve only covered making predictions. To be able to do that, we need
    to know the weights *w*. How do we get them?
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只介绍了如何进行预测。为了能够做到这一点，我们需要知道权重 *w*。我们如何得到它们？
- en: 'We learn the weights from data: we use the target variable *y* to find such
    *w* that combines the features of *X* in the best possible way. “Best possible”
    in the case of linear regression means that it minimizes the error between the
    predictions *g*(*X* ) and the actual target *y*.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从数据中学习权重：我们使用目标变量 *y* 来找到这样的 *w*，它能以最佳方式结合 *X* 的特征。“最佳方式”在线性回归的情况下意味着它最小化了预测
    *g*(*X*) 与实际目标 *y* 之间的误差。
- en: 'We have multiple ways to do that. We will use normal equation, which is the
    simplest method to implement. The weight vector *w* can be computed with the following
    formula:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有多种方法可以实现这一点。我们将使用正则方程，这是实现起来最简单的方法。权重向量 *w* 可以用以下公式计算：
- en: '![](../Images/02_12-Equation_2-23.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_12-Equation_2-23.png)'
- en: Note Covering the derivation of the normal equation is out of scope for this
    book. We give a bit of intuition of how it works in appendix C, but you should
    consult a machine learning textbook for a more in-depth introduction. *The Elements
    of Statistical Learning*, 2nd edition by Hastie, Tibshirani, and Friedman is a
    good start.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本书不涵盖正则方程的推导过程。我们仅在附录C中简要介绍了其工作原理，但为了更深入的了解，你应该查阅机器学习教材。《统计学习基础》，第二版，作者Hastie、Tibshirani和Friedman，是一个很好的起点。
- en: 'This piece of math may appear scary or confusing, but it’s quite easy to translate
    to NumPy:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 这段数学可能看起来令人害怕或困惑，但它很容易翻译成NumPy：
- en: '*X^T* is the transpose of *X*. In NumPy, it’s `X.T`.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X^T* 是 *X* 的转置。在NumPy中，它是 `X.T`。'
- en: '*X^T**X* is a matrix–matrix multiplication, which we can do with the `dot`
    method from NumPy: `X.T.dot(X)`.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X^T**X* 是矩阵-矩阵乘法，我们可以使用 NumPy 的 `dot` 方法来完成：`X.T.dot(X)`。'
- en: '*X*^(–1) is the inverse of *X*. We can use `np.linalg.inv` function to calculate
    the inverse.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X*^(–1) 是 *X* 的逆。我们可以使用 `np.linalg.inv` 函数来计算逆。'
- en: So the formula above translates directly to
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，上述公式可以直接转换为
- en: '[PRE43]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Please refer to appendix C for more details about this equation.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅附录 C 了解有关此方程的更多详细信息。
- en: 'To implement the normal equation, we need to do the following:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现正规方程，我们需要做以下几步：
- en: Create a function that takes in a matrix *X* with features and a vector *y*
    with the target.
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，该函数接受一个包含特征矩阵 *X* 和一个包含目标向量 *y*。
- en: Add a dummy column (the feature that is always set to 1) to the matrix *X*.
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向矩阵 *X* 添加一个虚拟列（始终设置为 1 的特征）。
- en: 'Train the model: compute the weights *w* by using the normal equation.'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型：通过使用正规方程计算权重 *w*。
- en: Split this *w* into the bias *w*[0] and the rest of the weights, and return
    them.
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这个 *w* 分解为偏置 *w*[0] 和其余权重，并返回它们。
- en: The last step—splitting *w* into the bias term and the rest—is optional and
    mostly for convenience; otherwise, we need to add the dummy column every time
    we want to make predictions instead of doing it once during training.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步——将 *w* 分解为偏置项和其余部分——是可选的，主要为了方便；否则，每次我们想要进行预测时，都需要添加一个虚拟列，而不是在训练期间一次性完成。
- en: Let’s implement it.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来实现它。
- en: Listing 2.2 Linear regression implemented with NumPy
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 2.2 使用 NumPy 实现的线性回归
- en: '[PRE44]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: ❶ Creates an array that contains only ones
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个只包含一个的数组
- en: ❷ Adds the array of 1s as the first column of X
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将包含一个的数组作为 X 的第一列添加
- en: ❸ Computes *X^TX*
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算 *X^TX*
- en: ❹ Computes the inverse of *X^TX*
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 计算 *X^TX* 的逆
- en: ❺ Computes the rest of the normal equation
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 计算正规方程的其余部分
- en: ❻ Splits the weights vector into the bias and the rest of the weights
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 将权重向量分为偏置和其余权重
- en: With six lines of code, we have implemented our first machine learning algorithm.
    In ❶, we create a vector containing only ones, which we append to the matrix *X*
    as the first column; this is the dummy feature in ❷. Next, we compute *X^TX* in
    ❸ and its inverse in ❹, and we put them together to calculate *w* in ❺. Finally,
    we split the weights into the bias *w*[0] and the remaining weights *w* in ❻.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 通过六行代码，我们已经实现了我们的第一个机器学习算法。在❶中，我们创建了一个只包含一个的向量，并将其作为第一列附加到矩阵 *X* 上；这是❷中的虚拟特征。接下来，我们在❸中计算
    *X^TX* 并在❹中计算其逆，然后将它们组合起来计算❺中的 *w*。最后，我们在❻中将权重分为偏置 *w*[0] 和其余权重 *w*。
- en: 'The `column_stack` function from NumPy that we used for adding a column of
    ones might be confusing at first, so let’s have a closer look at it:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用于添加一个包含一个的列的 `column_stack` 函数可能一开始会让人困惑，所以让我们更仔细地看看它：
- en: '[PRE45]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: It takes in a list of NumPy arrays, which in our case contains `ones` and `X`
    and stacks them (figure 2.13).
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 它接受一个 NumPy 数组的列表，在我们的情况下包含 `ones` 和 `X` 并将它们堆叠（图 2.13）。
- en: '![](../Images/02_13.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_13.png)'
- en: Figure 2.13 The function `column_stack` takes a list of NumPy arrays and stacks
    them in columns. In our case, the function appends the array with ones as the
    first column of the matrix.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.13](../Images/02_13.png) 函数 `column_stack` 接受一个 NumPy 数组的列表并将它们按列堆叠。在我们的情况下，该函数将包含一个的数组作为矩阵的第一列附加。'
- en: 'If weights are split into the bias term and the rest, the linear regression
    formula for making predictions changes slightly:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将权重分解为偏置项和其余部分，则用于预测的线性回归公式略有变化：
- en: '![](../Images/02_12-Equation_2-24.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![方程 2-24](../Images/02_12-Equation_2-24.png)'
- en: 'This is still very easy to translate to NumPy:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 这仍然很容易翻译成 NumPy：
- en: '[PRE46]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Let’s use it for our project!
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用它来为我们的项目服务！
- en: 2.4 Predicting the price
  id: totrans-367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 预测价格
- en: 'We’ve covered a great deal of theory, so let’s come back to our project: predicting
    the price of a car. We now have a function for training a linear regression model
    at our disposal, so let’s use it to build a simple baseline solution.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涵盖了大量的理论，现在让我们回到我们的项目：预测汽车的价格。我们现在有一个用于训练线性回归模型的函数可供使用，所以让我们用它来构建一个简单的基线解决方案。
- en: 2.4.1 Baseline solution
  id: totrans-369
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.1 基线解决方案
- en: 'To be able to use it, however, we need to have some data: a matrix *X* and
    a vector with the target variable *y*. We have already prepared the *y*, but we
    still don’t have the *X*: what we have right now is a data frame, not a matrix.
    So we need to extract some features from our dataset to create this matrix *X*.'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，要使用它，我们需要有一些数据：一个矩阵 *X* 和一个包含目标变量 *y* 的向量。我们已经准备好了 *y*，但我们还没有 *X*：我们现在有一个数据框，而不是一个矩阵。因此，我们需要从我们的数据集中提取一些特征来创建这个矩阵
    *X*。
- en: 'We will start with a very naive way of creating features: select a few numerical
    features, and form the matrix *X* from them. In the previous example, we used
    only three features. This time, we include a couple more features and use the
    following columns:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个非常简单的方式来创建特征开始：选择一些数值特征，并从它们中形成矩阵 *X*。在上一个例子中，我们只使用了三个特征。这次，我们包括一些额外的特征，并使用以下列：
- en: engine_hp
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: engine_hp
- en: engine_cylinders
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: engine_cylinders
- en: highway_mpg
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: highway_mpg
- en: city_mpg
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: city_mpg
- en: popularity
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: popularity
- en: 'Let’s select the features from the data frame and write them to a new variable,
    `df_num`:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从数据框中选择特征并将它们写入一个新的变量 `df_num`：
- en: '[PRE47]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: As discussed in the section on exploratory data analysis, the dataset has missing
    values. We need to do something because the linear regression model cannot deal
    with missing values automatically.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 如在探索性数据分析部分所述，数据集有缺失值。我们需要做些事情，因为线性回归模型不能自动处理缺失值。
- en: One option is to drop all the rows that contain at least one missing value.
    This approach, however, has some disadvantages. Most important, we will lose the
    information that we have in the other columns. Even though we may not know the
    number of doors of a car, we still know other things about the car, such as make,
    model, age, and other things that we don’t want to throw away.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 一个选择是删除包含至少一个缺失值的所有行。然而，这种方法有一些缺点。最重要的是，我们将失去其他列中的信息。即使我们可能不知道一辆车的车门数量，我们仍然知道其他关于这辆车的信息，比如制造商、型号、年龄以及其他我们不希望丢弃的东西。
- en: 'The other option is filling the missing values with some other value. This
    way, we don’t lose the information in other columns and still can make predictions,
    even if the row has missing values. The simplest possible approach is to fill
    the missing values with zeros. We can use the `fillna` method from Pandas:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是将缺失值填充为某个其他值。这样，我们不会失去其他列中的信息，并且即使行中有缺失值，仍然可以进行预测。最简单的方法是将缺失值填充为零。我们可以使用
    Pandas 的 `fillna` 方法：
- en: '[PRE48]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: This method may not be the best way to deal with missing values, but often,
    it’s good enough. If we set the missing feature value to zero, the respective
    feature is simply ignored.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可能不是处理缺失值的最佳方式，但通常来说，它已经足够好了。如果我们把缺失的特征值设为零，相应的特征就会被简单地忽略。
- en: 'Note An alternative option is to replace the missing values with the average
    values. For some variables, for example, the number of cylinders, the value of
    zero doesn’t make much sense: a car cannot have zero cylinders. However, this
    will make our code more complex and won’t have a significant impact on the results.
    That’s why we follow a simpler approach and replace the missing values with zeros.'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：另一种选择是将缺失值替换为平均值。对于某些变量，例如汽缸数，零值没有太多意义：一辆车不可能没有汽缸。然而，这将使我们的代码更加复杂，并且不会对结果产生重大影响。这就是为什么我们遵循一个更简单的方法，将缺失值替换为零。
- en: It’s not difficult to see why setting a feature to zero is the same as ignoring
    it. Let’s recall the formula for linear regression. In our case, we have five
    features, so the formula is
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易看出为什么将一个特征设为零等同于忽略它。让我们回顾一下线性回归的公式。在我们的情况下，我们有五个特征，所以公式是
- en: '![](../Images/02_13-Equation_2-25.png)'
  id: totrans-386
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_13-Equation_2-25.png)'
- en: 'If feature three is missing, and we fill it with zero, *x*[i 3] becomes zero:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第三个特征缺失，并且我们用零填充它，*x*[i 3] 就变成了零：
- en: '![](../Images/02_13-Equation_2-26.png)'
  id: totrans-388
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_13-Equation_2-26.png)'
- en: 'In this case, regardless of the weight *w*[3] for this feature, the product
    *x*[i 3]*w*[3] will always be zero. In other words, this feature will have no
    contribution to the final prediction, and we will base our prediction only on
    features that aren’t missing:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，无论这个特征的权重 *w*[3] 如何，乘积 *x*[i 3]*w*[3] 总是会是零。换句话说，这个特征对最终预测没有任何贡献，我们将只基于没有缺失的特征进行预测：
- en: '![](../Images/02_13-Equation_2-27.png)'
  id: totrans-390
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_13-Equation_2-27.png)'
- en: 'Now we need to convert this DataFrame to a NumPy array. The easiest way to
    do it is to use its `values` property:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要将这个 DataFrame 转换为一个 NumPy 数组。最简单的方法是使用它的 `values` 属性：
- en: '[PRE49]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '`X_train` is a matrix—a two-dimensional NumPy array. It’s something we can
    use as input to our `linear_regresson` function. Let’s call it'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '`X_train` 是一个矩阵——一个二维的 NumPy 数组。它是我们可以将它作为输入传递给 `linear_regresson` 函数的东西。让我们称它为'
- en: '[PRE50]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We have just trained the first model! Now we can apply it to the training data
    to see how well it predicts:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚训练了第一个模型！现在我们可以将其应用于训练数据以查看其预测效果：
- en: '[PRE51]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'To see how good the predictions are, we can use `histplot`—a function from
    Seaborn for plotting histograms that we used previously—to plot the predicted
    values and compare them with the actual prices:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看到预测有多好，我们可以使用`histplot`——这是Seaborn中用于绘制直方图的函数，我们之前已经使用过——来绘制预测值并与实际价格进行比较：
- en: '[PRE52]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We can see from the plot (figure 2.14) that the distribution of values we predicted
    looks quite different from the actual values. This result may indicate that the
    model is not powerful enough to capture the distribution of the target variable.
    This shouldn’t be a surprise to us: the model we used is quite basic and includes
    only five very simple features.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表（图2.14）中我们可以看到，我们预测的值的分布与实际值看起来相当不同。这个结果可能表明，模型没有足够的能力来捕捉目标变量的分布。这对我们来说不应该是个惊喜：我们使用的模型相当基础，只包括五个非常简单的特征。
- en: '![](../Images/02_14.png)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_14.png)'
- en: Figure 2.14 The distribution of the predicted values (light gray) and the actual
    values (dark gray). We see that our predictions aren’t very good; they are very
    different from the actual distribution.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.14 预测值（浅灰色）和实际值（深灰色）的分布。我们看到我们的预测并不很好；它们与实际分布差异很大。
- en: '2.4.2 RMSE: Evaluating model quality'
  id: totrans-402
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.2 RMSE：评估模型质量
- en: Looking at plots and comparing the distributions of the actual target variable
    with the predictions is a good way to evaluate quality, but we cannot do this
    every time we change something in the model. Instead, we need to use a metric
    that quantifies the quality of the model. We can use many metrics to evaluate
    how well a regression model behaves. The most commonly used one is *root mean
    squared error*—RMSE for short.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 观察图表并比较实际目标变量的分布与预测的分布是评估质量的好方法，但我们在每次更改模型中的任何内容时都不能这样做。相反，我们需要使用一个量化模型质量的指标。我们可以使用许多指标来评估回归模型的表现。最常用的一种是*均方根误差*——简称RMSE。
- en: 'RMSE tells us how large the errors are that our model makes. It’s computed
    with the following formula:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: RMSE告诉我们我们的模型犯的错误有多大。它是通过以下公式计算的：
- en: '![](../Images/02_14-Equation_2-28.png)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_14-Equation_2-28.png)'
- en: Let’s try to understand what’s going on here. First, let’s look inside the sum.
    We have
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试理解这里发生了什么。首先，让我们看看总和内部。我们有
- en: '![](../Images/02_14-Equation_2-29.png)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_14-Equation_2-29.png)'
- en: This is the difference between the prediction we make for the observation and
    the actual target value for that observation (figure 2.15).
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们对观测的预测与该观测的实际目标值之间的差异（图2.15）。
- en: '![](../Images/02_15.png)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_15.png)'
- en: Figure 2.15 The difference between the predictions *g*(*x[i]*) and the actual
    values *y[i]*
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.15 预测值 *g*(*x[i]*) 和实际值 *y[i]* 之间的差异
- en: Then we use the square of the difference, which gives a lot more weight to larger
    differences. If we predict 9.5, for example, and the actual value is 9.6, the
    difference is 0.1, so its square is 0.01, which is quite small. But if we predict
    7.3, and the actual value is 10.3, the difference is 3, and the square of the
    difference is 9 (figure 2.16).
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用差的平方，这给较大的差异赋予了更多的权重。例如，如果我们预测9.5，而实际值是9.6，差异是0.1，所以它的平方是0.01，相当小。但如果我们预测7.3，而实际值是10.3，差异是3，差的平方是9（图2.16）。
- en: This is the SE part (*squared error*) of RMSE.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 这是RMSE中的SE部分（*平方误差*）。
- en: '![](../Images/02_16.png)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_16.png)'
- en: Figure 2.16 The square of the difference between the predictions and the actual
    values. For large differences, the square is quite big.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.16 预测值和实际值之间差的平方。对于大的差异，平方相当大。
- en: 'Next, we have a sum:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有一个总和：
- en: '![](../Images/02_16-Equation_2-30.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_16-Equation_2-30.png)'
- en: This summation goes over all *m* observations and puts all the squared errors
    together (figure 2.17) into a single number.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 这个求和遍历所有*m*个观测值，并将所有平方误差（图2.17）组合成一个单一的数字。
- en: '![](../Images/02_17.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_17.png)'
- en: Figure 2.17 The result of the summation of all the square differences is a single
    number.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.17 所有平方差之和是一个单一的数字。
- en: 'If we divide this sum by *m*, we get the mean squared error:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这个总和除以*m*，我们得到均方误差：
- en: '![](../Images/02_17-Equation_2-31.png)'
  id: totrans-421
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_17-Equation_2-31.png)'
- en: This is the squared error that our model makes on average—the M part (*mean*)
    of RMSE, or *mean squared error* (MSE). MSE is also a good metric on its own (figure
    2.18).
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们的模型在平均意义上的平方误差——RMSE中的M部分（*平均*），或*均方误差*（MSE）。MSE本身也是一个很好的指标（图2.18）。
- en: '![](../Images/02_18.png)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_18.png)'
- en: Figure 2.18 MSE is computed by calculating the mean of the squared errors.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.18 MSE是通过计算平方误差的平均值来计算的。
- en: 'Finally, we take the square root of that:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算其平方根：
- en: '![](../Images/02_18-Equation_2-32.png)'
  id: totrans-426
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_18-Equation_2-32.png)'
- en: This is the R part (*root*) of RMSE (figure 2.19).
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 这是RMSE中的R部分（*根*）（图2.19）。
- en: '![](../Images/02_19.png)'
  id: totrans-428
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_19.png)'
- en: 'Figure 2.19 RMSE: we first compute MSE and then calculate its square root.'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.19 RMSE：我们首先计算均方误差（MSE），然后计算其平方根。
- en: 'When using NumPy to implement RMSE, we can take advantage of *vectorization*:
    the process of applying the same operation to all elements of one or more NumPy
    arrays. We get multiple benefits from using vectorization. First, the code is
    more concise: we don’t have to write any loops to apply the same operation to
    each element of the array. Second, vectorized operations are a lot faster than
    simple Python for loops.'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用NumPy实现RMSE时，我们可以利用*向量化*：将相同的操作应用于一个或多个NumPy数组中所有元素的过程。使用向量化可以获得多个好处。首先，代码更加简洁：我们不需要编写任何循环来对数组中的每个元素应用相同的操作。其次，向量化操作比简单的Python循环要快得多。
- en: Consider the following implementation.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下实现。
- en: Listing 2.3 The implementation of root mean squared error
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.3 根均方误差的实现
- en: '[PRE53]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: ❶ Computes the difference between the prediction and the target
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算预测值与目标之间的差异
- en: '❷ Computes MSE: first computes the squared error, and then calculates its mean'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算MSE：首先计算平方误差，然后计算其平均值
- en: ❸ Takes the square root to get RMSE
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算平方根以获得RMSE
- en: 'In ❶, we compute element-wise difference between the vector with predictions
    and the vector with the target variable. The result is a new NumPy array `error`
    that contains the differences. In ❷, we do two operations in one line: compute
    the square of each element of the `error` array and then get the mean value of
    the result, which gives us MSE. In ❸, we compute the square root to get RMSE.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 在❶中，我们计算预测向量与目标变量向量之间的逐元素差异。结果是包含差异的新NumPy数组`error`。在❷中，我们在一行中执行两个操作：计算`error`数组中每个元素的平方，然后计算结果的平均值，这给我们MSE。在❸中，我们计算平方根以获得RMSE。
- en: Element-wise operations in NumPy and Pandas are quite convenient. We can apply
    an operation to an entire NumPy array (or a Pandas series) without writing loops.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy和Pandas中的逐元素操作非常方便。我们可以对整个NumPy数组（或Pandas序列）应用操作，而无需编写循环。
- en: 'In the first line of our `rmse` function, for example, we compute the difference
    between the predictions and the actual prices:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在我们的`rmse`函数的第一行中，我们计算预测值与实际价格之间的差异：
- en: '[PRE54]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: What happens here is that for each element of `y_pred`, we subtract the corresponding
    element of `y` and then put the result to the new array `error` (figure 2.20).
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生的情况是，对于`y_pred`的每个元素，我们减去相应的`y`元素，然后将结果放入新的数组`error`（图2.20）。
- en: '![](../Images/02_20.png)'
  id: totrans-442
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_20.png)'
- en: Figure 2.20 The element-wise difference between `y_pred` and `y`. The result
    is written to the `error` array.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.20 `y_pred`和`y`之间的逐元素差异。结果写入`error`数组。
- en: Next, we compute the square of each element of the `error` array and then calculate
    its mean to get the mean squared error of our model (figure 2.21).
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们计算`error`数组中每个元素的平方，然后计算其平均值以获得我们模型的均方误差（图2.21）。
- en: '![](../Images/02_21.png)'
  id: totrans-445
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_21.png)'
- en: Figure 2.21 To calculate MSE, we first compute the square of each element in
    the error array and then compute the mean value of the result.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.21 计算MSE，我们首先计算误差数组中每个元素的平方，然后计算结果的平均值。
- en: To see exactly what happens, we need to know that the power operator (**) is
    also applied element-wise, so the result is another array in which all elements
    of the original array are squared. When we have this new array with squared elements,
    we simply compute its mean by using the `mean()` method (figure 2.22).
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 要确切了解发生了什么，我们需要知道幂运算符（**）也是逐元素应用的，因此结果是另一个数组，其中原始数组的所有元素都被平方。当我们有这个包含平方元素的新的数组时，我们只需使用`mean()`方法计算其平均值（图2.22）。
- en: '![](../Images/02_22.png)'
  id: totrans-448
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_22.png)'
- en: Figure 2.22 The power operator (**) applied element-wise to the error array.
    The result is another array in which each element is squared. Then we compute
    the mean of the array with the squared error to compute MSE.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.22 功运算符（**）逐元素应用于误差数组。结果是另一个数组，其中每个元素都是平方的。然后我们计算平方误差数组的平均值以计算MSE。
- en: 'Finally, we compute the square root of the mean value to get RMSE:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算平均值平方根以获得RMSE：
- en: '[PRE55]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now we can use RMSE to evaluate the quality of the model:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用RMSE来评估模型的质量：
- en: '[PRE56]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The code prints 0.75\. This number tells us that on average, the model’s predictions
    are off by 0.75\. This result alone may not be very useful, but we can use it
    to compare this model with other models. If one model has a better (lower) RMSE
    than the other, it indicates that model is better.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 代码打印出0.75。这个数字告诉我们，平均而言，模型的预测偏差为0.75。这个结果本身可能不是非常有用，但我们可以用它来比较这个模型与其他模型。如果一个模型的RMSE（均方根误差）比另一个模型更好（更低），这表明该模型更好。
- en: 2.4.3 Validating the model
  id: totrans-455
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.3 验证模型
- en: In the example from the previous section we computed RMSE on the training set.
    The result is useful to know but doesn’t reflect the way the model will be used
    later. The model will be used to predict the price of cars that it didn’t see
    before. For that purpose, we set aside a validation dataset. We intentionally
    don’t use it for training and keep it for validating the model.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节的例子中，我们在训练集上计算了RMSE。这个结果是有用的，但它并不反映模型将如何被使用。模型将被用来预测它之前没有见过的汽车价格。为此目的，我们留出了一部分验证数据集。我们故意不使用它进行训练，而是保留它来验证模型。
- en: 'We have already split our data into multiple parts: `df_train`, `df_val`, and
    `df_test`. We have also created a matrix `X_train` from `df_train` and used `X_train`
    and `y_train` to train the model. Now we need to do the same steps to get `X_val`—a
    matrix with features computed from the validation dataset. Then we can apply the
    model to `X_val` to get predictions and compare them with `y_val`.'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将数据分成多个部分：`df_train`、`df_val`和`df_test`。我们还从`df_train`创建了一个矩阵`X_train`，并使用`X_train`和`y_train`来训练模型。现在我们需要执行相同的步骤来获取`X_val`——一个从验证数据集计算出的特征矩阵。然后我们可以将模型应用于`X_val`以获取预测结果，并将其与`y_val`进行比较。
- en: 'First, we create the `X_val` matrix, following the same steps as for `X_train`:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建`X_val`矩阵，遵循与`X_train`相同的步骤：
- en: '[PRE57]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We’re ready to apply the model to `X_val` to get predictions:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好将模型应用于`X_val`以获取预测结果：
- en: '[PRE58]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The `y_pred` array contains the predictions for the validation dataset. Now
    we use `y_pred` and compare it with the actual prices from `y_val`, using the
    RMSE function that we implemented previously:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: '`y_pred`数组包含验证数据集的预测结果。现在我们使用`y_pred`并将其与`y_val`中的实际价格进行比较，使用我们之前实现的RMSE函数：'
- en: '[PRE59]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The value this code prints is 0.76, which is the number we should use for comparing
    models.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码打印的值是0.76，这是我们用于比较模型的数字。
- en: 'In the previous code we already see some duplication: training and validation
    tests require the same preprocessing, and we wrote the same code twice. Thus,
    it makes sense to move this logic to a separate function and avoid duplicating
    the code.'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码中，我们已经看到了一些重复：训练和验证测试需要相同的预处理，我们重复编写了相同的代码。因此，将此逻辑移动到单独的函数中并避免代码重复是有意义的。
- en: We can call this function `prepare_X` because it creates a matrix `X` from a
    DataFrame.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以称这个函数为`prepare_X`，因为它从一个DataFrame创建了一个矩阵`X`。
- en: Listing 2.4 The `prepare_X` function for converting a DataFrame into a matrix
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.4 将DataFrame转换为矩阵的`prepare_X`函数
- en: '[PRE60]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Now the whole training and evaluation becomes simpler and looks like this:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，整个训练和评估过程变得更简单，看起来像这样：
- en: '[PRE61]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: ❶ Trains the model
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 训练模型
- en: ❷ Applies the model to the validation dataset
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将模型应用于验证数据集
- en: ❸ Computes RMSE on the validation data
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在验证数据上计算RMSE
- en: This gives us a way to check whether any model adjustments lead to improvements
    in the predictive quality of the model. As the next step, let’s add more features
    and check whether it gets lower RMSE scores.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了一种检查任何模型调整是否会导致模型预测质量改进的方法。作为下一步，让我们添加更多特征并检查它是否得到更低的RMSE分数。
- en: 2.4.4 Simple feature engineering
  id: totrans-475
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.4 简单特征工程
- en: 'We already have a simple baseline model with simple features. To improve our
    model further, we can add more features to the model: we create others and add
    them to the existing features. As we already know, this process is called *feature
    engineering*.'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有一个具有简单特征的简单基线模型。为了进一步提高我们的模型，我们可以向模型添加更多特征：我们创建其他特征并将它们添加到现有特征中。正如我们已经知道的，这个过程被称为*特征工程*。
- en: Because we have already set up the validation framework, we can easily verify
    whether adding new features improves the quality of the model. Our aim is to improve
    the RMSE calculated on the validation data.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经设置了验证框架，我们可以轻松地验证添加新特征是否提高了模型的质量。我们的目标是提高在验证数据上计算的RMSE。
- en: 'First, we create a new feature, “age,” from the feature “year.” The age of
    a car should be very helpful when predicting its price: intuitively, the newer
    the car, the more expensive it should be.'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从特征“年份”创建一个新的特征，“年龄”。一辆车的年龄在预测其价格时应该非常有帮助：直观地讲，车越新，价格应该越贵。
- en: 'Because the dataset was created in 2017 (which we can verify by checking `df_train.year.max()`),
    we can calculate the age by subtracting the year when the car was made from 2017:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 因为数据集是在2017年创建的（我们可以通过检查`df_train.year.max()`来验证），我们可以通过从2017年减去汽车制造的年份来计算年龄：
- en: '[PRE62]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: This operation is an element-wise operation. We calculate the difference between
    2017 and each element of the year series. The result is a new Pandas series containing
    the differences, which we write back to the dataframe as the age column.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作是一个逐元素操作。我们计算2017年与年序列中每个元素的差值。结果是包含差值的新Pandas序列，我们将它写回dataframe作为年龄列。
- en: 'We already know that we will need to apply the same preprocessing twice: to
    the training and validation sets. Because we don’t want to repeat the feature
    extraction code multiple times, let’s put this logic into the `prepare_X` function.'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道我们需要将相同的预处理应用两次：训练集和验证集。因为我们不希望多次重复特征提取代码，所以让我们将这个逻辑放入`prepare_X`函数中。
- en: Listing 2.5 Creating the age feature in the `prepare_X` function
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.5 在`prepare_X`函数中创建年龄特征
- en: '[PRE63]'
  id: totrans-484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: ❶ Creates a copy of the input parameter to prevent side effects
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建输入参数的副本以防止副作用
- en: ❷ Creates a copy of the base list with the basic features
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建包含基本特征的基列表的副本
- en: ❸ Computes the age feature
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算年龄特征
- en: ❹ Appends age to the list of feature names we use for the model
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将年龄添加到我们用于模型的特征名称列表中
- en: 'The way we implement the function this time is slightly different from the
    previous version. Let’s look at these differences. First, in ❶, we create a copy
    of the DataFrame `df` that we pass in the function. Later in the code, we modify
    `df` by adding extra rows in ❸. This kind of behavior is known as a *side effect*:
    the caller of the function may not expect the function to change the DataFrame.
    To prevent the unpleasant surprise, we instead modify the copy of the original
    DataFrame. In ❷, we create a copy for the list with the base features for the
    same reason. Later, we extend this list with new features ❹, but we don’t want
    to change the original list. The rest of the code is the same as previously.'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 这次我们实现函数的方式与之前的版本略有不同。让我们看看这些差异。首先，在❶中，我们创建了一个传入函数的DataFrame `df`的副本。在代码的后面部分，我们通过添加额外的行来修改`df`
    ❸。这种行为被称为*副作用*：函数的调用者可能不会期望函数会改变DataFrame。为了避免不愉快的惊喜，我们改而修改原始DataFrame的副本。在❷中，我们出于同样的原因创建了一个包含基本特征的列表的副本。稍后，我们通过添加新特征
    ❹ 扩展这个列表，但我们不希望改变原始列表。其余的代码与之前相同。
- en: 'Let’s test if adding the feature “age” leads to any improvements:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试添加“年龄”特征是否会导致任何改进：
- en: '[PRE64]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: The code prints
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 代码打印
- en: '[PRE65]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The validation error is 0.517, which is a good improvement from 0.76—the value
    we had in the baseline solution. Thus, we conclude that adding “age” is indeed
    helpful when making predictions.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 验证错误是0.517，这比基线解决方案中的0.76有很好的改进。因此，我们得出结论，添加“年龄”确实有助于进行预测。
- en: 'We can also look at the distribution of the predicted values:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看预测值的分布：
- en: '[PRE66]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: We see (figure 2.23) that the distribution of the predictions follows the target
    distribution a lot more closely than previously. Indeed, the validation RMSE score
    confirms it.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到（图2.23），预测值的分布比之前更接近目标分布。确实，验证RMSE分数证实了这一点。
- en: '![](../Images/02_23.png)'
  id: totrans-498
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_23.png)'
- en: Figure 2.23 The distribution of predicted (light gray) versus actual (dark gray).
    With the new features, the model follows the original distribution closer than
    previously.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.23 预测值（浅灰色）与实际值（深灰色）的分布。有了新特征，模型比之前更接近原始分布。
- en: 2.4.5 Handling categorical variables
  id: totrans-500
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.5 处理分类变量
- en: 'We see that adding “age” is quite helpful for the model. Let’s continue adding
    more features. One of the columns we can use next is the number of doors. This
    variable appears to be numeric and can take three values: 2, 3, and 4 doors. Even
    though it’s tempting to put the variable to the model as is, it’s not really a
    numeric variable: we cannot say that by adding one more door, the price of a car
    grows (or drops) by a certain amount of money. Rather, the variable is categorical.'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到添加“年龄”对模型非常有帮助。让我们继续添加更多特征。我们可以使用的下一个列之一是门数。这个变量看起来是数值的，可以取三个值：2、3和4扇门。尽管直接将变量放入模型很有吸引力，但这实际上并不是一个数值变量：我们不能说增加一扇门，汽车的价格就会增长（或下降）一定的金额。相反，这个变量是分类的。
- en: '*Categorical variables* describe characteristics of objects and can take one
    of a few possible values. The make of a car is a categorical variable; for example,
    it can be Toyota, BWM, Ford, or any other make. It’s easy to recognize a categorical
    variable by its values, which typically are strings and not numbers. That’s not
    always the case, however. The number of doors, for example, is categorical: it
    can take only one of the three possible values (2, 3, and 4).'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '*分类变量*描述了对象的特征，可以取几个可能的值之一。汽车的品牌是一个分类变量；例如，它可以是丰田、宝马、福特或任何其他品牌。通过其值很容易识别分类变量，这些值通常是字符串而不是数字。然而，情况并不总是这样。例如，门数是分类的：它只能取三个可能的值（2、3和4）。'
- en: We can use categorical variables in a machine learning model in multiple ways.
    One of the simplest ways is to encode such variables by a set of binary features,
    with a separate feature for each distinct value.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用多种方式在机器学习模型中使用分类变量。其中一种最简单的方法是将这样的变量通过一组二元特征进行编码，每个不同的值都有一个单独的特征。
- en: 'In our case, we will create three binary features: `num_doors_2`, `num_doors_3`,
    and `num_doors_4`. If the car has two doors, `num_doors_2` will be set to 1, and
    the rest will be 0\. If the car has three doors, `num_doors_3` will get the value
    1, and the same goes for `num_doors_4`.'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们将创建三个二元特征：`num_doors_2`、`num_doors_3`和`num_doors_4`。如果汽车有两扇门，`num_doors_2`将被设置为1，其余的将被设置为0。如果汽车有三扇门，`num_doors_3`将获得值1，对`num_doors_4`也是如此。
- en: 'This method of encoding categorical variables is called *one-hot encoding*.
    We will learn more about this way of encoding categorical variables in chapter
    3\. For now, let’s choose the simplest way to do this encoding: looping over the
    possible values (2, 3, and 4) and, for each value, checking whether the value
    of the observation matches it.'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对分类变量进行编码的方法被称为*独热编码*。我们将在第3章中更深入地了解这种编码分类变量的方法。现在，让我们选择最简单的方式来执行这种编码：遍历可能的值（2、3和4），并对每个值进行检查，看观察值的值是否与之匹配。
- en: 'Let’s add these lines to the `prepare_X` function:'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这些行添加到`prepare_X`函数中：
- en: '[PRE67]'
  id: totrans-507
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: ❶ Iterates over possible values of the “number of doors” variable
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 遍历“门数”变量的可能值
- en: ❷ Gives a feature a meaningful name, such as “num_doors_2” for v=2
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 为特征赋予一个有意义的名称，例如，对于`v=2`使用“num_doors_2”
- en: ❸ Creates the one-hot encoding feature
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建独热编码特征
- en: ❹ Adds the feature back to the dataframe, using the name from ❷
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用❷中的名称将特征添加回数据框
- en: 'This code may be difficult to understand, so let’s take a closer look at what’s
    going on here. The most difficult line is ❸:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码可能难以理解，所以让我们更仔细地看看这里发生了什么。最困难的一行是❸：
- en: '[PRE68]'
  id: totrans-513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Two things happen here. The first one is the expression inside the parentheses,
    where we use the equals (==) operator. This operation is also an element-wise
    operation, like the ones we used previously when computing RMSE. In this case,
    the operation creates a new Pandas series. If elements of the original series
    equal `v`, the corresponding elements in the result is True; otherwise, the elements
    are False. The operation creates a series of True/False values. Because `v` has
    three values (2, 3, and 4), and we apply this operation to every value of `v`,
    we create three series (figure 2.24).
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生了两件事。第一件事是括号内的表达式，我们使用了等于（==）运算符。这种操作也是一种元素级操作，就像我们在计算RMSE时之前使用的那样。在这种情况下，操作创建了一个新的Pandas系列。如果原始系列中的元素等于`v`，则结果中的对应元素为True；否则，元素为False。该操作创建了一个True/False值的系列。因为`v`有三个值（2、3和4），并且我们将此操作应用于`v`的每个值，因此我们创建了三个系列（图2.24）。
- en: '![](../Images/02_24.png)'
  id: totrans-515
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_24.png)'
- en: 'Figure 2.24 We use the == operator to create the new series from the original
    one: one for two doors, one for three doors, and one for four doors.'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.24 我们使用==运算符从原始系列中创建新的系列：一个用于两扇门，一个用于三扇门，一个用于四扇门。
- en: Next, we convert the Boolean series to integers in such a way that True becomes
    1 and False becomes 0, which is easy to do with the `astype(int)` method (figure
    2.25). Now we can use the results as features and put them into linear regression.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将布尔序列转换为整数，使得 True 变为 1，False 变为 0，这可以通过 `astype(int)` 方法轻松完成（图 2.25）。现在我们可以将结果用作特征，并将它们放入线性回归中。
- en: '![](../Images/02_25.png)'
  id: totrans-518
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_25.png)'
- en: Figure 2.25 Using `astype(int)` to convert series with Boolean values to integers
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.25 使用 `astype(int)` 将具有布尔值的序列转换为整数
- en: The number of doors, as we discussed, is a categorical variable that appears
    to be numerical because the values are integers (2, 3 and 4). All the remaining
    categorical variables we have in the dataset are strings.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 车门数量，正如我们讨论的，是一个分类变量，看起来像是数值变量，因为其值是整数（2、3 和 4）。数据集中我们拥有的所有其他分类变量都是字符串。
- en: 'We can use the same approach to encode other categorical variables. Let’s start
    with `make`. For our purposes, it should be enough to get and use only the most
    frequently occurring values. Let’s find out what the five most frequent values
    are:'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用相同的方法来编码其他分类变量。让我们从 `make` 开始。为了我们的目的，获取和使用最频繁出现的值就足够了。让我们找出五个最频繁出现的值：
- en: '[PRE69]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: The code prints
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 代码打印
- en: '[PRE70]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: We take these values and use them to encode `make` in the same way that we encoded
    the number of doors.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些值取出来，并像编码车门数量一样编码 `make`。
- en: 'Next, we create five new variables called `is_make_chevrolet`, `is_make_ford`,
    `is_` `make_volkswagen`, `is_make_toyota`, and `is_make_dodge`:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建五个新变量，分别命名为 `is_make_chevrolet`、`is_make_ford`、`is_` `make_volkswagen`、`is_make_toyota`
    和 `is_make_dodge`：
- en: '[PRE71]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Now the whole `prepare_X` should look like the following.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，整个 `prepare_X` 应该看起来像以下这样。
- en: Listing 2.6 Handling categorical variables `number` `of` `doors` and `make`
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 2.6 处理分类变量 `number` `of` `doors` 和 `make`
- en: '[PRE72]'
  id: totrans-530
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: ❶ Encodes the number of doors variable
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 编码车门数量变量
- en: ❷ Encodes the make variable
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 编码 `make` 变量
- en: 'Let’s check whether this code improves the RMSE of the model:'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查这段代码是否提高了模型的 RMSE：
- en: '[PRE73]'
  id: totrans-534
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: The code prints
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 代码打印
- en: '[PRE74]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: The previous value was 0.517, so we managed to improve the RMSE score further.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的值是 0.517，所以我们成功进一步提高了 RMSE 分数。
- en: 'We can use a few more variables: `engine_fuel_type`, `transmission_type`, `driven_`
    `wheels`, `market_category`, `vehicle_size`, and `vehicle_style`. Let’s do the
    same thing for them. After the modifications, the `prepare_X` starts looking a
    bit more complex.'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用更多变量：`engine_fuel_type`、`transmission_type`、`driven_` `wheels`、`market_category`、`vehicle_size`
    和 `vehicle_style`。让我们对它们做同样的事情。修改后，`prepare_X` 开始看起来更复杂一些。
- en: Listing 2.7 Handling more categorical variables in the `prepare_X` function
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 2.7 在 `prepare_X` 函数中处理更多分类变量
- en: '[PRE75]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: ❶ Encodes the type variable
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 编码类型变量
- en: ❷ Encodes the transmission variable
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 编码变速器变量
- en: ❸ Encodes the number of driven wheels
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 编码驱动轮数量
- en: ❹ Encodes the market category
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 编码市场类别
- en: ❺ Encodes the size
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 编码大小
- en: ❻ Encodes the style
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 编码风格
- en: 'Let’s test it:'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试一下：
- en: '[PRE76]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: The number we see is significantly worse than before. We get 34.2, which is
    a lot more than the 0.5 we had before.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到的结果比之前差得多。我们得到 34.2，这比之前的 0.5 多得多。
- en: NOTE The number you get may be different, depending on the Python version, the
    NumPy version, the versions of NumPy dependencies, the OS, and other factors.
    But the jump in the validation metric from 0.5 to something significantly bigger
    should always alert us.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：你得到的结果可能因 Python 版本、NumPy 版本、NumPy 依赖项的版本、操作系统和其他因素而异。但从 0.5 到显著更大的验证指标跳跃应该总是提醒我们。
- en: Instead of helping, the new features made the score a lot worse. Luckily, we
    have validation to help us spot this problem. In the next section, we will see
    why it happens and how to deal with it.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 新特征不仅没有帮助，反而使分数变得更差。幸运的是，我们有验证来帮助我们发现问题。在下一节中，我们将看到为什么会发生这种情况以及如何处理它。
- en: 2.4.6 Regularization
  id: totrans-552
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.6 正则化
- en: 'We saw that adding new features does not always help, and in our case, it made
    things a lot worse. The reason for this behavior is numerical instability. Recall
    the formula of the normal equation:'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到添加新特征并不总是有帮助，在我们的例子中，它使事情变得更糟。这种行为的原因是数值不稳定性。回想一下正则方程的公式：
- en: '![](../Images/02_25-Equation_2-33.png)'
  id: totrans-554
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_25-Equation_2-33.png)'
- en: 'One of the terms in the equation is the inverse of the *X^TX* matrix:'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 方程中的一个项是 *X^TX* 矩阵的逆：
- en: '![](../Images/02_25-Equation_2-34.png)'
  id: totrans-556
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_25-Equation_2-34.png)'
- en: The inversion is the issue in our case. Sometimes, when adding new columns to
    *X*, we can accidentally add a column that is a combination of other columns.
    For example, if we already have the MPG in the city feature and decide to add
    kilometers per liter in the city, the second feature is the same as the first
    one but multiplied by a constant.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，问题是矩阵的求逆。有时，当我们向 *X* 添加新列时，我们可能会不小心添加一个由其他列组合而成的列。例如，如果我们已经有了城市中的MPG特征，并决定添加城市中的每升公里数，第二个特征与第一个特征相同，但乘以一个常数。
- en: 'When this happens, *X^TX* becomes *undetermined* or *singular*, which means
    that it’s not possible to find an inverse for this matrix. If we try to invert
    a singular matrix, NumPy will tell us about that by raising a `LinAlgError`:'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 当这种情况发生时，*X^TX* 变得 *不定* 或 *奇异*，这意味着无法找到这个矩阵的逆。如果我们尝试求一个奇异矩阵的逆，NumPy将通过引发一个 `LinAlgError`
    来告诉我们：
- en: '[PRE77]'
  id: totrans-559
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Our code didn’t raise any exceptions, however. It happened because we don’t
    typically have columns that are perfect linear combinations of other columns.
    The real data is often noisy, with measurement errors (such as recording 1.3 instead
    of 13 for MPG), rounding errors (such as storing 0.0999999 instead of 0.1), and
    many other errors. Technically, such matrices are not singular, so NumPy doesn’t
    complain.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的代码没有引发任何异常，然而这种情况发生是因为我们通常没有那些完美线性组合其他列的列。真实数据往往很嘈杂，存在测量误差（例如，将MPG记录为1.3而不是13），舍入误差（例如，存储0.0999999而不是0.1），以及许多其他错误。从技术上讲，这样的矩阵不是奇异的，所以NumPy不会报错。
- en: For this reason, however, some of the values in the weights become extremely
    large—a lot larger than they are supposed to be.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于这个原因，权重中的某些值变得极其大——比它们应有的值大得多。
- en: If we look at the values of our *w*[0] and *w*, we see that this is indeed the
    case. The bias term *w*[0] has the value 5788519290303866.0, for example (the
    value may vary depending on the machine, OS, and version of NumPy), and a few
    components of *w* have extremely large negative values as well.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看我们的 *w*[0] 和 *w* 的值，我们会看到这确实如此。例如，偏差项 *w*[0] 的值为5788519290303866.0（这个值可能取决于机器、操作系统和NumPy的版本），*w*
    的一些分量也有极其大的负值。
- en: 'In numerical linear algebra, such issues are called *numerical instability
    issues*, and they are typically solved with regularization techniques. The aim
    of *regularization* is to make sure that the inverse exists by forcing the matrix
    to be invertible. Regularization is an important concept in machine learning:
    it means “controlling”—controlling the weights of the model so that they behave
    correctly and don’t grow too large, as in our case.'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 在数值线性代数中，这类问题被称为 *数值不稳定性问题*，通常通过正则化技术来解决。正则化的目的是通过强制矩阵可逆来确保其逆的存在。正则化是机器学习中的一个重要概念：它意味着“控制”——控制模型的权重，使它们表现正确，并且不会变得过大，就像我们案例中那样。
- en: 'One way to do regularization is to add a small number to each diagonal element
    of the matrix. Then we get the following formula for linear regression:'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化的一种方法是在矩阵的每个对角元素上添加一个很小的数。然后我们得到以下线性回归的公式：
- en: '![](../Images/02_25-Equation_2-35.png)'
  id: totrans-565
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_25-Equation_2-35.png)'
- en: NOTE Regularized linear regression is often called *ridge regression*. Many
    libraries, including Scikit-learn, use *ridge* to refer to regularized linear
    regression and *linear regression* to refer to the unregularized model.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：正则化线性回归通常被称为 *岭回归*。许多库，包括Scikit-learn，使用 *ridge* 来指代正则化线性回归，而 *线性回归* 则指未正则化的模型。
- en: 'Let’s look at the part that changed: the matrix that we need to invert. This
    is how it looks:'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看变化的部分：我们需要求逆的矩阵。它看起来是这样的：
- en: '![](../Images/02_25-Equation_2-36.png)'
  id: totrans-568
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02_25-Equation_2-36.png)'
- en: This formula says that we need *I*—an *identity matrix*, which is a matrix with
    ones on the main diagonal and zeros everywhere else. We multiply this identity
    matrix by a number *α*. This way, all the ones on the diagonal of *I* become *α*.
    Then we sum *α**I* and *X^TX*, which adds *α* to all the diagonal elements of
    *X^TX*.
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式说明我们需要 *I*——一个 *单位矩阵*，这是一个对角线上的元素为1，其他地方为0的矩阵。我们将这个单位矩阵乘以一个数 *α*。这样，*I*
    对角线上的所有1都变成了 *α*。然后我们求 *α**I* 和 *X^TX* 的和，这会将 *α* 添加到 *X^TX* 的所有对角元素上。
- en: 'This formula can directly translate to NumPy code:'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式可以直接转换为NumPy代码：
- en: '[PRE78]'
  id: totrans-571
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: The `np.eye` function creates a two-dimensional NumPy array that is also an
    identity matrix. When we multiply by 0.01, the ones on the diagonal become 0.01,
    so when we add this matrix to `XTX`, we add only 0.01 to its main diagonal (figure
    2.26).
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '`np.eye`函数创建一个二维NumPy数组，它也是一个单位矩阵。当我们乘以0.01时，对角线上的1变成了0.01，因此当我们把这个矩阵加到`XTX`上时，我们只向它的主对角线添加了0.01（图2.26）。'
- en: '![](../Images/02_26a.png)'
  id: totrans-573
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_26a.png)'
- en: (A) The eye function from NumPy creates an identity matrix.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: (A) NumPy中的eye函数创建一个单位矩阵。
- en: '![](../Images/02_26b.png)'
  id: totrans-575
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_26b.png)'
- en: (B) When we multiply the identity matrix by a number, this number goes to the
    main diagonal of the result.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: (B) 当我们将单位矩阵乘以一个数时，这个数会出现在结果的主对角线上。
- en: '![](../Images/02_26c.png)'
  id: totrans-577
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/02_26c.png)'
- en: (C) The effect of adding an identity matrix multiplied by 0.01 to another matrix
    is the same as adding 0.01 to the main diagonal of that matrix.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: (C) 将乘以0.01的单位矩阵加到另一个矩阵上的效果与将该数加到该矩阵的主对角线上的效果相同。
- en: Figure 2.26 Using an identity matrix to add 0.01 to the main diagonal of a square
    matrix
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.26 使用单位矩阵向正方形矩阵的主对角线添加0.01
- en: Let’s create a new function that uses this idea and implements linear regression
    with regularization.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个新的函数，它使用这个想法并实现带正则化的线性回归。
- en: Listing 2.8 Linear regression with regularization
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.8 带正则化的线性回归
- en: '[PRE79]'
  id: totrans-582
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: ❶ Controls the amount of regularization by using the parameter r
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 通过使用参数r来控制正则化的程度
- en: ❷ Adds r to the main diagonal of XTX
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将r加到XTX的主对角线上
- en: The function is very similar to linear regression, but a few lines are different.
    First, there’s an extra parameter `r` that controls the amount of regularization—this
    corresponds to the number *α* in the formula that we add to the main diagonal
    of *X^TX*.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数与线性回归非常相似，但有几行是不同的。首先，有一个额外的参数`r`，它控制正则化的程度——这对应于我们添加到`X^TX`主对角线上的公式中的数*α*。
- en: Regularization affects the final solution by making the components of *w* smaller.
    We can see that the more regularization we add, the smaller the weights become.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化通过使`w`的分量更小来影响最终解。我们可以看到，添加的正则化越多，权重就越小。
- en: 'Let’s check what happens with our weights for different values of `r`:'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查不同`r`值下的权重会发生什么：
- en: '[PRE80]'
  id: totrans-588
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: The code prints
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 代码打印
- en: '[PRE81]'
  id: totrans-590
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'We start with 0, which is an unregularized solution, and get very large numbers.
    Then we try 0.001 and increase it 10 times on each step: 0.01, 0.1, 1, and 10\.
    We see that the values that we selected become smaller as `r` grows.'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从0开始，这是一个无正则化解，得到非常大的数字。然后我们尝试0.001，并将它增加10倍：0.01、0.1、1和10。我们看到，随着`r`的增长，我们选择的值变得越小。
- en: 'Now let’s check whether regularization helps with our problem and what RMSE
    we get after that. Let’s run it with r=0.001:'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们检查正则化是否有助于我们的问题，以及添加正则化后我们得到的RMSE是多少。让我们用r=0.001运行它：
- en: '[PRE82]'
  id: totrans-593
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: The code prints
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 代码打印
- en: '[PRE83]'
  id: totrans-595
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'This result is an improvement over the previous score: 0.507.'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果比之前的分数有所改进：0.507。
- en: 'NOTE Sometimes, when adding a new feature causes performance degradation, simply
    removing this feature may be enough to solve the problem. Having a validation
    dataset is important to decide whether to add regularization, remove the feature,
    or do both: we use the score on the validation data to choose the best option.
    In our particular case, we see that adding regularization helps: it improves the
    score we had previously.'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：有时，当添加新功能导致性能下降时，简单地移除此功能可能就足以解决问题。拥有验证数据集对于决定是否添加正则化、移除特征或两者都做非常重要：我们使用验证数据上的分数来选择最佳选项。在我们特定的案例中，我们发现添加正则化有帮助：它提高了我们之前的分数。
- en: 'We tried using `r`=0.001, but we should try other values as well. Let’s try
    a couple of different ones to select the best parameter `r`:'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试使用`r`=0.001，但也应该尝试其他值。让我们尝试几个不同的值来选择最佳参数`r`：
- en: '[PRE84]'
  id: totrans-599
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'We see that the best performance is achieved with a smaller `r`:'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，较小的`r`可以实现最佳性能：
- en: '[PRE85]'
  id: totrans-601
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: We also notice that the performance for values below 0.1 don’t change much except
    in the sixth digit, which we shouldn’t consider to be significant.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还注意到，对于小于0.1的值，性能变化不大，除了第六位数字，我们不应该认为它具有显著性。
- en: 'Let’s take the model with `r`=0.01 as the final model. Now we can check it
    against the test dataset to verify if the model works:'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将`r`=0.01的模型作为最终模型。现在我们可以将其与测试数据集进行比较，以验证模型是否有效：
- en: '[PRE86]'
  id: totrans-604
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: The code prints
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 代码打印
- en: '[PRE87]'
  id: totrans-606
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Because these two numbers are pretty close, we conclude that the model can generalize
    well to the new unseen data.
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这两个数字非常接近，我们得出结论，该模型可以很好地泛化到新的未见数据。
- en: Exercise 2.4
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 练习2.4
- en: Regularization is needed because
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化是必需的，因为
- en: a) It can control the weights of the model and not let them grow too large.
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: a) 它可以控制模型的权重，不让它们增长过大。
- en: b) Real-world data is noisy.
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: b) 现实世界的数据是有噪声的。
- en: c) We often have numerical instability problems.
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: c) 我们经常遇到数值不稳定性问题。
- en: Multiple answers are possible.
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个可能的答案。
- en: 2.4.7 Using the model
  id: totrans-614
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.7 使用模型
- en: Because we now have a model, we can start using it for predicting the price
    of a car.
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们现在有一个模型，我们可以开始用它来预测汽车的价格。
- en: 'Suppose that a user posts the following ad on our website:'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一个用户在我们的网站上发布了以下广告：
- en: '[PRE88]'
  id: totrans-617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'We’d like to suggest the price for this car. For that, we use our model:'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想建议这辆车的价格。为此，我们使用我们的模型：
- en: '[PRE89]'
  id: totrans-619
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: First, we create a small DataFrame with one row. This row contains all the values
    of the `ad` dictionary we created earlier. Next, we convert this DataFrame to
    a matrix.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建一个包含一行的小型数据框。这一行包含我们之前创建的`ad`字典中的所有值。接下来，我们将这个数据框转换为矩阵。
- en: 'Now we can apply our model to the matrix to predict the price of this car:'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将我们的模型应用于矩阵来预测这辆车的价格：
- en: '[PRE90]'
  id: totrans-622
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'This prediction is not the final price, however; it''s the logarithm of the
    price. To get the actual price, we need to undo the logarithm and apply the exponent
    function:'
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个预测不是最终价格；它是价格的对数。为了得到实际价格，我们需要取消对数并应用指数函数：
- en: '[PRE91]'
  id: totrans-624
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: The output is 28,294.13\. The real price of this car is $31,120, so our model
    is not far from the actual price.
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是 28,294.13。这辆车的实际价格是 $31,120，所以我们的模型离实际价格不远。
- en: 2.5 Next steps
  id: totrans-626
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 下一步
- en: 2.5.1 Exercises
  id: totrans-627
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5.1 练习
- en: 'You can try the following things to make the model better:'
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试以下方法来提高模型：
- en: '*Write a function for binary encoding.* In this chapter we implemented the
    category encoding manually: we looked at the top five values, wrote them in a
    list, and then looped over the list to create binary features. Doing it this way
    is cumbersome, which is why it’s a good idea to write a function that will do
    this automatically. It should have multiple arguments: the dataframe, the name
    of the categorical variable, and the number of most frequent values it should
    consider. This function should also help us do the previous exercise.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*编写一个二进制编码的函数。* 在本章中，我们手动实现了类别编码：我们查看前五个值，将它们写入一个列表，然后遍历列表以创建二进制特征。这样做很麻烦，这就是为什么编写一个自动执行此操作的函数是个好主意。这个函数应该有多个参数：数据框、类别变量的名称以及它应该考虑的最频繁值数量。这个函数还应该帮助我们完成之前的练习。'
- en: '*Try more feature engineering.* When implementing category encoding, we included
    only the top five values for each categorical variable. Including more values
    during the encoding process might improve the model. Try doing that, and reevaluate
    the quality of the model in terms of RMSE.'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*尝试更多的特征工程。* 在实现类别编码时，我们只包括了每个类别变量前五个值。在编码过程中包括更多值可能会提高模型。尝试这样做，并重新评估模型的RMSE质量。'
- en: 2.5.2 Other projects
  id: totrans-631
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5.2 其他项目
- en: 'There are other projects you can do now:'
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以做其他一些项目：
- en: Predict the price of a house. You can take the New York City Airbnb Open Data
    dataset from [https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data)
    or the California housing dataset from [https://scikit-learn.org/stable/modules/
    generated/sklearn.datasets.fetch_california_housing.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html).
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测房屋的价格。你可以从 [https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data)
    获取纽约市Airbnb开放数据集，或者从 [https://scikit-learn.org/stable/modules/ generated/sklearn.datasets.fetch_california_housing.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)
    获取加利福尼亚住房数据集。
- en: Check other datasets, such as [https://archive.ics.uci.edu/ml/datasets.php?task
    =reg](https://archive.ics.uci.edu/ml/datasets.php?task=reg), that have numerical
    target values. For example, we can use the data from the student performance dataset
    ([http://archive.ics.uci.edu/ml/datasets/ Student+Performance](http://archive.ics.uci.edu/ml/datasets/Student+Performance))
    to train a model for determining the performance of students.
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查其他数据集，例如 [https://archive.ics.uci.edu/ml/datasets.php?task =reg](https://archive.ics.uci.edu/ml/datasets.php?task=reg)，它们有数值目标值。例如，我们可以使用学生表现数据集（[http://archive.ics.uci.edu/ml/datasets/
    Student+Performance](http://archive.ics.uci.edu/ml/datasets/Student+Performance)）中的数据来训练一个模型，以确定学生的表现。
- en: Summary
  id: totrans-635
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Doing simple initial exploratory analysis is important. Among other things,
    it helps us find out whether the data has missing values. It’s not possible to
    train a linear regression model when there are missing values, so it’s important
    to check our data and fill in the missing values if necessary.
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行简单的初步探索性分析非常重要。其中之一是帮助我们找出数据是否有缺失值。当存在缺失值时，无法训练线性回归模型，因此检查我们的数据并在必要时填充缺失值非常重要。
- en: As a part of exploratory data analysis, we need to check the distribution of
    the target variable. If the target distribution has a long tail, we need to apply
    the log transformation. Without it, we may get inaccurate and misleading predictions
    from the linear regression model.
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为探索性数据分析的一部分，我们需要检查目标变量的分布。如果目标分布有一个长尾，我们需要应用对数变换。没有它，我们可能会从线性回归模型中得到不准确和误导性的预测。
- en: The train/validation/test split is the best way to check our models. It gives
    us a way to measure the performance of the model reliably, and things like numerical
    instability issues won’t go unnoticed.
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练/验证/测试数据划分是检查我们模型的最佳方式。它为我们提供了一种可靠地衡量模型性能的方法，并且像数值不稳定性等问题不会被人忽视。
- en: The linear regression model is based on a simple mathematical formula, and understanding
    this formula is the key to successful application of the model. Knowing these
    details helps us learn how the model works before coding it.
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归模型基于一个简单的数学公式，理解这个公式是成功应用模型的关键。了解这些细节有助于我们在编码之前了解模型的工作原理。
- en: 'It’s not difficult to implement linear regression from scratch using Python
    and NumPy. Doing so helps us understand that there''s no magic behind machine
    learning: it’s simple math translated to code.'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python和NumPy从头实现线性回归并不困难。这样做有助于我们理解机器学习背后没有魔法：它只是简单的数学转换成代码。
- en: RMSE gives us a way to measure the predictive performance of our model on the
    validation set. It lets us confirm that the model is good and helps us compare
    multiple models to find the best one.
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RMSE为我们提供了一种衡量模型在验证集上的预测性能的方法。它让我们确认模型是好的，并帮助我们比较多个模型以找到最佳模型。
- en: Feature engineering is the process of creating new features. Adding new features
    is important for improving the performance of a model. While adding new features,
    we always need to use the validation set to make sure that our model indeed improves.
    Without constant monitoring, we risk getting mediocre or very bad performance.
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程是创建新特征的过程。添加新特征对于提高模型性能很重要。在添加新特征时，我们始终需要使用验证集来确保我们的模型确实得到了改进。没有持续的监控，我们可能会得到平庸或非常糟糕的性能。
- en: Sometimes, we face numerical instability issues that we can solve with regularization.
    Having a good way to validate models is crucial for spotting a problem before
    it’s too late.
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时，我们会遇到可以通过正则化解决的问题数值不稳定性问题。有一个好的方法来验证模型对于在问题变得太晚之前发现问题至关重要。
- en: After the model is trained and validated, we can use it to make predictions,
    such as applying it to cars with unknown prices to estimate how much they may
    cost.
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型训练和验证后，我们可以用它来做出预测，例如将其应用于价格未知的汽车，以估计它们可能的价值。
- en: In chapter 3, we will learn how to do classification with machine learning,
    using logistic regression to predict customer churn.
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3章中，我们将学习如何使用机器学习进行分类，使用逻辑回归来预测客户流失。
- en: Answers to exercises
  id: totrans-646
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习答案
- en: Exercise 2.1 B) Values spread far from the head.
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习2.1 B) 值分布远离头部。
- en: Exercise 2.2 A) *x[i]* is a feature vector and *y[i]* is the logarithm of the
    price.
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习2.2 A) *x[i]* 是一个特征向量，*y[i]* 是价格的对数。
- en: Exercise 2.3 B) A vector *y* with price predictions.
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习2.3 B) 一个包含价格预测的向量 *y*。
- en: Exercise 2.4 A), B), and C) All three answers are correct.
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习2.4 A)，B），C）所有三个答案都是正确的。
